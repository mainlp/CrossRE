{"doc_key": "ai-train-1", "ner": [[3, 7, "product"], [13, 14, "field"], [16, 17, "task"], [19, 20, "task"], [24, 26, "task"], [29, 30, "field"], [31, 33, "researcher"], [35, 37, "researcher"], [39, 40, "researcher"], [42, 43, "researcher"], [45, 47, "researcher"], [49, 50, "researcher"], [52, 53, "researcher"], [55, 56, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[3, 7, 13, 14, "part-of", "", false, false], [3, 7, 13, 14, "usage", "", false, false], [3, 7, 16, 17, "part-of", "", false, false], [3, 7, 16, 17, "usage", "", false, false], [3, 7, 19, 20, "part-of", "", false, false], [3, 7, 19, 20, "usage", "", false, false], [3, 7, 29, 30, "part-of", "", false, false], [3, 7, 29, 30, "usage", "", false, false], [24, 26, 19, 20, "part-of", "", false, false], [24, 26, 19, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Popular", "approaches", "of", "opinion", "-", "based", "recommendation", "system", "use", "various", "techniques", ",", "including", "text", "mining", ",", "information", "retrieval", ",", "sentiment", "analysis", "(", "see", "also", "multimodal", "sentiment", "analysis", ")", "and", "deep", "learning", "X.Y", ".", "Feng", ",", "H", ".", "Zhang", ",", "Y.J.", "Ren", ",", "P.H.", "Shang", ",", "Y", ".", "Zhu", ",", "Y.C.", "Liang", ",", "R.C.", "Guan", ",", "D.", "Xu", ",", "(", "2019", ")", ",", "21", "(", "5", ")", ":", "e12957", "."], "sentence-detokenized": "Popular approaches of opinion-based recommendation system use various techniques, including text mining, information retrieval, sentiment analysis (see also multimodal sentiment analysis) and deep learning X.Y. Feng, H. Zhang, Y.J. Ren, P.H. Shang, Y. Zhu, Y.C. Liang, R.C. Guan, D. Xu, (2019), 21 (5): e12957.", "token2charspan": [[0, 7], [8, 18], [19, 21], [22, 29], [29, 30], [30, 35], [36, 50], [51, 57], [58, 61], [62, 69], [70, 80], [80, 81], [82, 91], [92, 96], [97, 103], [103, 104], [105, 116], [117, 126], [126, 127], [128, 137], [138, 146], [147, 148], [148, 151], [152, 156], [157, 167], [168, 177], [178, 186], [186, 187], [188, 191], [192, 196], [197, 205], [206, 209], [209, 210], [211, 215], [215, 216], [217, 218], [218, 219], [220, 225], [225, 226], [227, 231], [232, 235], [235, 236], [237, 241], [242, 247], [247, 248], [249, 250], [250, 251], [252, 255], [255, 256], [257, 261], [262, 267], [267, 268], [269, 273], [274, 278], [278, 279], [280, 282], [283, 285], [285, 286], [287, 288], [288, 292], [292, 293], [293, 294], [295, 297], [298, 299], [299, 300], [300, 301], [301, 302], [303, 309], [309, 310]]}
{"doc_key": "ai-train-2", "ner": [[8, 8, "university"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 8, 8, "physical", "", false, false], [14, 15, 8, 8, "role", "", false, false], [17, 18, 8, 8, "physical", "", false, false], [17, 18, 8, 8, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Advocates", "of", "procedural", "representations", "were", "mainly", "concentrated", "at", "MIT", ",", "under", "the", "leadership", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "."], "sentence-detokenized": "Advocates of procedural representations were mainly concentrated at MIT, under the leadership of Marvin Minsky and Seymour Papert.", "token2charspan": [[0, 9], [10, 12], [13, 23], [24, 39], [40, 44], [45, 51], [52, 64], [65, 67], [68, 71], [71, 72], [73, 78], [79, 82], [83, 93], [94, 96], [97, 103], [104, 110], [111, 114], [115, 122], [123, 129], [129, 130]]}
{"doc_key": "ai-train-3", "ner": [[10, 10, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "standard", "interface", "and", "the", "calculator", "interface", "are", "written", "in", "Java", "."], "sentence-detokenized": "The standard interface and the calculator interface are written in Java.", "token2charspan": [[0, 3], [4, 12], [13, 22], [23, 26], [27, 30], [31, 41], [42, 51], [52, 55], [56, 63], [64, 66], [67, 71], [71, 72]]}
{"doc_key": "ai-train-4", "ner": [[0, 0, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 24, 24, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["Octave", "helps", "in", "numerical", "solution", "of", "linear", "and", "non-linear", "problems", ",", "and", "for", "performing", "other", "numerical", "experiments", "using", "one", "that", "is", "mostly", "compatible", "with", "MATLAB", "."], "sentence-detokenized": "Octave helps in numerical solution of linear and non-linear problems, and for performing other numerical experiments using one that is mostly compatible with MATLAB.", "token2charspan": [[0, 6], [7, 12], [13, 15], [16, 25], [26, 34], [35, 37], [38, 44], [45, 48], [49, 59], [60, 68], [68, 69], [70, 73], [74, 77], [78, 88], [89, 94], [95, 104], [105, 116], [117, 122], [123, 126], [127, 131], [132, 134], [135, 141], [142, 152], [153, 157], [158, 164], [164, 165]]}
{"doc_key": "ai-train-5", "ner": [[3, 7, "algorithm"], [9, 10, "misc"], [12, 13, "researcher"], [18, 20, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 7, 12, 13, "origin", "", false, false], [9, 10, 12, 13, "origin", "", false, false], [12, 13, 18, 20, "physical", "", false, false], [12, 13, 18, 20, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Variants", "of", "the", "backpropagation", "algorithm", ",", "as", "well", "as", "unsupervised", "methods", "by", "Geoff", "Hinton", "and", "colleagues", "at", "the", "University", "of", "Toronto", "can", "be", "used", "to", "train", "deep", ",", "highly", "nonlinear", "neural", "architectures", ",", "{", "{{", "citizen", "journal"], "sentence-detokenized": "Variants of the backpropagation algorithm, as well as unsupervised methods by Geoff Hinton and colleagues at the University of Toronto can be used to train deep, highly nonlinear neural architectures, {{{citizen journal", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 31], [32, 41], [41, 42], [43, 45], [46, 50], [51, 53], [54, 66], [67, 74], [75, 77], [78, 83], [84, 90], [91, 94], [95, 105], [106, 108], [109, 112], [113, 123], [124, 126], [127, 134], [135, 138], [139, 141], [142, 146], [147, 149], [150, 155], [156, 160], [160, 161], [162, 168], [169, 178], [179, 185], [186, 199], [199, 200], [201, 202], [202, 204], [204, 211], [212, 219]]}
{"doc_key": "ai-train-6", "ner": [[4, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "equivalent", "using", "the", "DCG", "notation", ":"], "sentence-detokenized": "or equivalent using the DCG notation:", "token2charspan": [[0, 2], [3, 13], [14, 19], [20, 23], [24, 27], [28, 36], [36, 37]]}
{"doc_key": "ai-train-7", "ner": [[0, 3, "algorithm"], [7, 9, "algorithm"], [14, 16, "algorithm"], [19, 21, "algorithm"], [25, 25, "algorithm"], [27, 28, "algorithm"], [42, 44, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 7, 9, "type-of", "", false, false], [0, 3, 14, 16, "usage", "part-of?", true, false], [14, 16, 19, 21, "compare", "", false, false], [25, 25, 19, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Self", "-", "organised", "maps", "differ", "from", "other", "artificial", "neural", "networks", "in", "that", "they", "apply", "competitive", "learning", "as", "opposed", "to", "error", "-correction", "learning", ",", "such", "as", "backpropagation", "with", "gradient", "descent", ")", ",", "and", "in", "that", "they", "use", "a", "neighbourhood", "function", "to", "preserve", "the", "topological", "properties", "of", "the", "input", "space", "."], "sentence-detokenized": "Self-organised maps differ from other artificial neural networks in that they apply competitive learning as opposed to error-correction learning, such as backpropagation with gradient descent), and in that they use a neighbourhood function to preserve the topological properties of the input space.", "token2charspan": [[0, 4], [4, 5], [5, 14], [15, 19], [20, 26], [27, 31], [32, 37], [38, 48], [49, 55], [56, 64], [65, 67], [68, 72], [73, 77], [78, 83], [84, 95], [96, 104], [105, 107], [108, 115], [116, 118], [119, 124], [124, 135], [136, 144], [144, 145], [146, 150], [151, 153], [154, 169], [170, 174], [175, 183], [184, 191], [191, 192], [192, 193], [194, 197], [198, 200], [201, 205], [206, 210], [211, 214], [215, 216], [217, 230], [231, 239], [240, 242], [243, 251], [252, 255], [256, 267], [268, 278], [279, 281], [282, 285], [286, 291], [292, 297], [297, 298]]}
{"doc_key": "ai-train-8", "ner": [[15, 17, "organisation"], [27, 28, "misc"], [37, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "the", "early", "1990s", ",", "it", "has", "been", "recommended", "by", "various", "authorities", ",", "including", "the", "Audio", "Engineering", "Society", ",", "that", "dynamic", "range", "measurements", "be", "made", "with", "an", "audio", "signal", "present", ",", "which", "is", "then", "filtered", "in", "the", "noise", "floor", "measurement", "used", "in", "the", "dynamic", "range", "determination", ".", "This", "avoids", "questionable", "measurements", "based", "on", "the", "use", "of", "blank", "media", ",", "or", "muting", "circuits", "."], "sentence-detokenized": "Since the early 1990s, it has been recommended by various authorities, including the Audio Engineering Society, that dynamic range measurements be made with an audio signal present, which is then filtered in the noise floor measurement used in the dynamic range determination. This avoids questionable measurements based on the use of blank media, or muting circuits.", "token2charspan": [[0, 5], [6, 9], [10, 15], [16, 21], [21, 22], [23, 25], [26, 29], [30, 34], [35, 46], [47, 49], [50, 57], [58, 69], [69, 70], [71, 80], [81, 84], [85, 90], [91, 102], [103, 110], [110, 111], [112, 116], [117, 124], [125, 130], [131, 143], [144, 146], [147, 151], [152, 156], [157, 159], [160, 165], [166, 172], [173, 180], [180, 181], [182, 187], [188, 190], [191, 195], [196, 204], [205, 207], [208, 211], [212, 217], [218, 223], [224, 235], [236, 240], [241, 243], [244, 247], [248, 255], [256, 261], [262, 275], [275, 276], [277, 281], [282, 288], [289, 301], [302, 314], [315, 320], [321, 323], [324, 327], [328, 331], [332, 334], [335, 340], [341, 346], [346, 347], [348, 350], [351, 357], [358, 366], [366, 367]]}
{"doc_key": "ai-train-9", "ner": [[7, 8, "misc"], [19, 20, "task"], [22, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 32, "task"], [34, 36, "task"], [38, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[7, 8, 19, 20, "part-of", "concept_used_in", true, false], [7, 8, 22, 23, "part-of", "concept_used_in", false, false], [7, 8, 25, 26, "part-of", "concept_used_in", false, false], [7, 8, 28, 29, "part-of", "concept_used_in", false, false], [7, 8, 31, 32, "part-of", "concept_used_in", false, false], [7, 8, 34, 36, "part-of", "concept_used_in", false, false], [7, 8, 38, 40, "part-of", "concept_used_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "technique", "used", "in", "the", "creation", "of", "own", "faces", "and", "their", "use", "for", "recognition", "is", "also", "used", "outside", "of", "face", "recognition", ":", "handwriting", "recognition", ",", "lip", "reading", ",", "voice", "recognition", ",", "sign", "language", "/", "hand", "gesture", "interpretation", "and", "medical", "image", "analysis", "."], "sentence-detokenized": "The technique used in the creation of own faces and their use for recognition is also used outside of face recognition: handwriting recognition, lip reading, voice recognition, sign language / hand gesture interpretation and medical image analysis.", "token2charspan": [[0, 3], [4, 13], [14, 18], [19, 21], [22, 25], [26, 34], [35, 37], [38, 41], [42, 47], [48, 51], [52, 57], [58, 61], [62, 65], [66, 77], [78, 80], [81, 85], [86, 90], [91, 98], [99, 101], [102, 106], [107, 118], [118, 119], [120, 131], [132, 143], [143, 144], [145, 148], [149, 156], [156, 157], [158, 163], [164, 175], [175, 176], [177, 181], [182, 190], [191, 192], [193, 197], [198, 205], [206, 220], [221, 224], [225, 232], [233, 238], [239, 247], [247, 248]]}
{"doc_key": "ai-train-10", "ner": [[1, 3, "organisation"], [9, 13, "organisation"], [15, 15, "organisation"], [19, 22, "organisation"], [28, 29, "organisation"], [32, 35, "organisation"], [39, 42, "organisation"], [44, 44, "organisation"], [49, 52, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[9, 13, 1, 3, "part-of", "", false, false], [15, 15, 9, 13, "named", "", false, false], [19, 22, 1, 3, "part-of", "", false, false], [28, 29, 1, 3, "part-of", "", false, false], [32, 35, 1, 3, "part-of", "", false, false], [39, 42, 1, 3, "part-of", "", false, false], [44, 44, 39, 42, "named", "", false, false], [49, 52, 1, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "National", "Science", "Foundation", "was", "an", "umbrella", "for", "the", "National", "Aeronautics", "and", "Space", "Administration", "(", "NASA", ")", ",", "the", "US", "Department", "of", "Energy", ",", "the", "US", "Department", "of", "Commerce", "NIST", ",", "the", "US", "Department", "of", "Defense", ",", "the", "Defense", "Advanced", "Research", "Projects", "Agency", "(", "DARPA", ")", ",", "and", "the", "Office", "of", "Naval", "Research", "coordinated", "studies", "to", "inform", "strategic", "planners", "in", "their", "deliberations", "."], "sentence-detokenized": "The National Science Foundation was an umbrella for the National Aeronautics and Space Administration (NASA), the US Department of Energy, the US Department of Commerce NIST, the US Department of Defense, the Defense Advanced Research Projects Agency (DARPA), and the Office of Naval Research coordinated studies to inform strategic planners in their deliberations.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 35], [36, 38], [39, 47], [48, 51], [52, 55], [56, 64], [65, 76], [77, 80], [81, 86], [87, 101], [102, 103], [103, 107], [107, 108], [108, 109], [110, 113], [114, 116], [117, 127], [128, 130], [131, 137], [137, 138], [139, 142], [143, 145], [146, 156], [157, 159], [160, 168], [169, 173], [173, 174], [175, 178], [179, 181], [182, 192], [193, 195], [196, 203], [203, 204], [205, 208], [209, 216], [217, 225], [226, 234], [235, 243], [244, 250], [251, 252], [252, 257], [257, 258], [258, 259], [260, 263], [264, 267], [268, 274], [275, 277], [278, 283], [284, 292], [293, 304], [305, 312], [313, 315], [316, 322], [323, 332], [333, 341], [342, 344], [345, 350], [351, 364], [364, 365]]}
{"doc_key": "ai-train-11", "ner": [[5, 6, "metrics"], [10, 11, "algorithm"], [15, 16, "researcher"], [21, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 10, 11, "part-of", "", false, false], [15, 16, 21, 21, "related-to", "added_appendix_to_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "fast", "method", "for", "computing", "maximum", "likelihood", "estimates", "for", "the", "probit", "model", "was", "proposed", "by", "Ronald", "Fisher", "as", "an", "appendix", "to", "Bliss", "'", "work", "in", "1935", "."], "sentence-detokenized": "A fast method for computing maximum likelihood estimates for the probit model was proposed by Ronald Fisher as an appendix to Bliss' work in 1935.", "token2charspan": [[0, 1], [2, 6], [7, 13], [14, 17], [18, 27], [28, 35], [36, 46], [47, 56], [57, 60], [61, 64], [65, 71], [72, 77], [78, 81], [82, 90], [91, 93], [94, 100], [101, 107], [108, 110], [111, 113], [114, 122], [123, 125], [126, 131], [131, 132], [133, 137], [138, 140], [141, 145], [145, 146]]}
{"doc_key": "ai-train-12", "ner": [[9, 10, "product"], [13, 14, "product"], [17, 17, "organisation"], [18, 19, "product"], [22, 22, "organisation"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 19, 13, 14, "usage", "uses_software", false, false], [18, 19, 17, 17, "artifact", "", false, false], [18, 19, 24, 24, "named", "", false, false], [24, 24, 22, 22, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Several", "such", "programs", "are", "available", "online", ",", "such", "as", "Google", "Translate", "and", "the", "SYSTRAN", "system", "that", "powers", "AltaVista", "'s", "BabelFish", "(", "now", "Yahoo", "'s", "Babelfish", "as", "of", "9", "May", "2008", ")", "."], "sentence-detokenized": "Several such programs are available online, such as Google Translate and the SYSTRAN system that powers AltaVista's BabelFish (now Yahoo's Babelfish as of 9 May 2008).", "token2charspan": [[0, 7], [8, 12], [13, 21], [22, 25], [26, 35], [36, 42], [42, 43], [44, 48], [49, 51], [52, 58], [59, 68], [69, 72], [73, 76], [77, 84], [85, 91], [92, 96], [97, 103], [104, 113], [113, 115], [116, 125], [126, 127], [127, 130], [131, 136], [136, 138], [139, 148], [149, 151], [152, 154], [155, 156], [157, 160], [161, 165], [165, 166], [166, 167]]}
{"doc_key": "ai-train-13", "ner": [[2, 2, "researcher"], [5, 6, "researcher"], [8, 9, "researcher"], [18, 20, "field"], [24, 25, "misc"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 18, 20, "related-to", "", true, false], [2, 2, 24, 25, "related-to", "", true, false], [2, 2, 27, 28, "related-to", "", true, false], [5, 6, 18, 20, "related-to", "", true, false], [5, 6, 24, 25, "related-to", "", true, false], [5, 6, 27, 28, "related-to", "", true, false], [8, 9, 18, 20, "related-to", "", true, false], [8, 9, 24, 25, "related-to", "", true, false], [8, 9, 27, 28, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "2002", "Hutter", ",", "with", "J\u00fcrgen", "Schmidhuber", "and", "Shane", "Legg", ",", "developed", "and", "published", "a", "mathematical", "theory", "of", "artificial", "general", "intelligence", "based", "on", "idealised", "intelligent", "agents", "and", "reinforcement", "learning", "with", "war", "motivation", "."], "sentence-detokenized": "In 2002 Hutter, with J\u00fcrgen Schmidhuber and Shane Legg, developed and published a mathematical theory of artificial general intelligence based on idealised intelligent agents and reinforcement learning with war motivation.", "token2charspan": [[0, 2], [3, 7], [8, 14], [14, 15], [16, 20], [21, 27], [28, 39], [40, 43], [44, 49], [50, 54], [54, 55], [56, 65], [66, 69], [70, 79], [80, 81], [82, 94], [95, 101], [102, 104], [105, 115], [116, 123], [124, 136], [137, 142], [143, 145], [146, 155], [156, 167], [168, 174], [175, 178], [179, 192], [193, 201], [202, 206], [207, 210], [211, 221], [221, 222]]}
{"doc_key": "ai-train-14", "ner": [[11, 11, "metrics"], [13, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 11, 13, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "most", "common", "way", "is", "to", "use", "the", "so", "-", "called", "ROUGE", "(", "Recall", "-", "Oriented", "Understudy", "for", "Gisting", "Evaluation", ")", "measure", "."], "sentence-detokenized": "The most common way is to use the so-called ROUGE (Recall-Oriented Understudy for Gisting Evaluation) measure.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 19], [20, 22], [23, 25], [26, 29], [30, 33], [34, 36], [36, 37], [37, 43], [44, 49], [50, 51], [51, 57], [57, 58], [58, 66], [67, 77], [78, 81], [82, 89], [90, 100], [100, 101], [102, 109], [109, 110]]}
{"doc_key": "ai-train-15", "ner": [[0, 0, "product"], [13, 13, "programlang"], [15, 16, "programlang"], [18, 19, "researcher"], [21, 22, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 13, 13, "related-to", "", false, false], [0, 0, 15, 16, "related-to", "", false, false], [18, 19, 21, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["RapidMiner", "provides", "learning", "schemes", ",", "models", "and", "algorithms", "and", "can", "be", "extended", "using", "R", "and", "Python", "scripts", ".", "David", "Norris", ",", "Bloor", "Research", ",", "13", "November", "2013", "."], "sentence-detokenized": "RapidMiner provides learning schemes, models and algorithms and can be extended using R and Python scripts. David Norris, Bloor Research, 13 November 2013.", "token2charspan": [[0, 10], [11, 19], [20, 28], [29, 36], [36, 37], [38, 44], [45, 48], [49, 59], [60, 63], [64, 67], [68, 70], [71, 79], [80, 85], [86, 87], [88, 91], [92, 98], [99, 106], [106, 107], [108, 113], [114, 120], [120, 121], [122, 127], [128, 136], [136, 137], [138, 140], [141, 149], [150, 154], [154, 155]]}
{"doc_key": "ai-train-16", "ner": [[4, 6, "programlang"], [9, 10, "product"]], "ner_mapping_to_source": [4, 5], "relations": [[9, 10, 4, 6, "general-affiliation", "", true, false]], "relations_mapping_to_source": [4], "sentence": ["but", "the", "latest", "fully", "Java", "-", "based", "version", "(", "Weka", "3", ")", ",", "whose", "development", "began", "in", "1997", ",", "is", "now", "used", "in", "many", "different", "application", "areas", ",", "in", "particular", "for", "educational", "and", "research", "purposes", "."], "sentence-detokenized": "but the latest fully Java-based version (Weka 3), whose development began in 1997, is now used in many different application areas, in particular for educational and research purposes.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 20], [21, 25], [25, 26], [26, 31], [32, 39], [40, 41], [41, 45], [46, 47], [47, 48], [48, 49], [50, 55], [56, 67], [68, 73], [74, 76], [77, 81], [81, 82], [83, 85], [86, 89], [90, 94], [95, 97], [98, 102], [103, 112], [113, 124], [125, 130], [130, 131], [132, 134], [135, 145], [146, 149], [150, 161], [162, 165], [166, 174], [175, 183], [183, 184]]}
{"doc_key": "ai-train-17", "ner": [[0, 0, "product"], [13, 20, "misc"], [23, 25, "misc"], [28, 35, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 20, 0, 0, "topic", "", false, false], [13, 20, 23, 25, "win-defeat", "", false, false], [23, 25, 28, 35, "temporal", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Eurisko", "made", "many", "interesting", "discoveries", "and", "enjoyed", "significant", "acclaim", ",", "with", "his", "paper", "Heuretics", ":", "Theoretical", "and", "Study", "of", "Heuristic", "Rules", "winning", "the", "Best", "Paper", "award", "at", "the", "1982", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "Eurisko made many interesting discoveries and enjoyed significant acclaim, with his paper Heuretics: Theoretical and Study of Heuristic Rules winning the Best Paper award at the 1982 Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 7], [8, 12], [13, 17], [18, 29], [30, 41], [42, 45], [46, 53], [54, 65], [66, 73], [73, 74], [75, 79], [80, 83], [84, 89], [90, 99], [99, 100], [101, 112], [113, 116], [117, 122], [123, 125], [126, 135], [136, 141], [142, 149], [150, 153], [154, 158], [159, 164], [165, 170], [171, 173], [174, 177], [178, 182], [183, 194], [195, 198], [199, 202], [203, 214], [215, 217], [218, 228], [229, 241], [241, 242]]}
{"doc_key": "ai-train-18", "ner": [[8, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["To", "allow", "for", "multiple", "entities", ",", "a", "separate", "hinge", "loss", "is", "computed", "for", "each", "capsule", "."], "sentence-detokenized": "To allow for multiple entities, a separate hinge loss is computed for each capsule.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 21], [22, 30], [30, 31], [32, 33], [34, 42], [43, 48], [49, 53], [54, 56], [57, 65], [66, 69], [70, 74], [75, 82], [82, 83]]}
{"doc_key": "ai-train-19", "ner": [[8, 10, "product"], [12, 13, "product"], [15, 16, "product"], [18, 19, "product"], [21, 23, "product"], [25, 26, "product"], [35, 39, "product"], [42, 43, "product"], [45, 46, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 10, 25, 26, "type-of", "", false, false], [12, 13, 25, 26, "type-of", "", false, false], [15, 16, 25, 26, "type-of", "", false, false], [18, 19, 25, 26, "type-of", "", false, false], [21, 23, 25, 26, "type-of", "", false, false], [42, 43, 35, 39, "type-of", "", false, false], [45, 46, 35, 39, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["With", "the", "emergence", "of", "conversational", "assistants", "such", "as", "Apple", "'s", "Siri", ",", "Amazon", "Alexa", ",", "Google", "Assistant", ",", "Microsoft", "Cortana", "and", "Samsung", "'s", "Bixby", ",", "Voice", "Portals", "can", "now", "be", "accessed", "through", "mobile", "devices", "and", "Far", "Field", "smart", "voice", "speakers", "such", "as", "Amazon", "Echo", "and", "Google", "Home", "."], "sentence-detokenized": "With the emergence of conversational assistants such as Apple's Siri, Amazon Alexa, Google Assistant, Microsoft Cortana and Samsung's Bixby, Voice Portals can now be accessed through mobile devices and Far Field smart voice speakers such as Amazon Echo and Google Home.", "token2charspan": [[0, 4], [5, 8], [9, 18], [19, 21], [22, 36], [37, 47], [48, 52], [53, 55], [56, 61], [61, 63], [64, 68], [68, 69], [70, 76], [77, 82], [82, 83], [84, 90], [91, 100], [100, 101], [102, 111], [112, 119], [120, 123], [124, 131], [131, 133], [134, 139], [139, 140], [141, 146], [147, 154], [155, 158], [159, 162], [163, 165], [166, 174], [175, 182], [183, 189], [190, 197], [198, 201], [202, 205], [206, 211], [212, 217], [218, 223], [224, 232], [233, 237], [238, 240], [241, 247], [248, 252], [253, 256], [257, 263], [264, 268], [268, 269]]}
{"doc_key": "ai-train-20", "ner": [[2, 3, "field"], [5, 7, "algorithm"], [9, 11, "algorithm"], [13, 14, "algorithm"], [17, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 7, 2, 3, "type-of", "", false, false], [9, 11, 2, 3, "type-of", "", false, false], [13, 14, 2, 3, "type-of", "", false, false], [17, 17, 2, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Examples", "of", "supervised", "learning", "are", "Naive", "Bayes", "classifier", ",", "support", "vector", "machine", ",", "Gaussian", "mixture", ",", "and", "network", "."], "sentence-detokenized": "Examples of supervised learning are Naive Bayes classifier, support vector machine, Gaussian mixture, and network.", "token2charspan": [[0, 8], [9, 11], [12, 22], [23, 31], [32, 35], [36, 41], [42, 47], [48, 58], [58, 59], [60, 67], [68, 74], [75, 82], [82, 83], [84, 92], [93, 100], [100, 101], [102, 105], [106, 113], [113, 114]]}
{"doc_key": "ai-train-21", "ner": [[4, 5, "algorithm"], [25, 27, "algorithm"], [29, 29, "task"], [35, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 25, 27, "part-of", "", true, false], [35, 36, 29, 29, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["One", "can", "use", "the", "OSD", "algorithm", "to", "derive", "the", "maths", "O", "(", "sqrt", "{", "T", "}", ")", "/", "maths", "for", "the", "online", "version", "of", "the", "support", "vector", "machine", "for", "classification", ",", "which", "uses", "the", "maths", "loss", "hinge", "v", "_t", "(", "w", ")", "==", "max", "/", "maths"], "sentence-detokenized": "One can use the OSD algorithm to derive the maths O (sqrt {T}) / maths for the online version of the support vector machine for classification, which uses the maths loss hinge v _t (w) == max / maths", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 15], [16, 19], [20, 29], [30, 32], [33, 39], [40, 43], [44, 49], [50, 51], [52, 53], [53, 57], [58, 59], [59, 60], [60, 61], [61, 62], [63, 64], [65, 70], [71, 74], [75, 78], [79, 85], [86, 93], [94, 96], [97, 100], [101, 108], [109, 115], [116, 123], [124, 127], [128, 142], [142, 143], [144, 149], [150, 154], [155, 158], [159, 164], [165, 169], [170, 175], [176, 177], [178, 180], [181, 182], [182, 183], [183, 184], [185, 187], [188, 191], [192, 193], [194, 199]]}
{"doc_key": "ai-train-22", "ner": [[2, 3, "task"], [5, 6, "task"], [8, 8, "task"], [10, 11, "task"], [13, 14, "task"], [16, 17, "task"], [19, 20, "task"], [22, 24, "task"], [26, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Applications", "include", "object", "recognition", ",", "robotic", "mapping", "and", "navigation", ",", "image", "stitching", ",", "3D", "modelling", ",", "gesture", "recognition", ",", "video", "tracking", ",", "individual", "wildlife", "identification", "and", "matchmaking", "."], "sentence-detokenized": "Applications include object recognition, robotic mapping and navigation, image stitching, 3D modelling, gesture recognition, video tracking, individual wildlife identification and matchmaking.", "token2charspan": [[0, 12], [13, 20], [21, 27], [28, 39], [39, 40], [41, 48], [49, 56], [57, 60], [61, 71], [71, 72], [73, 78], [79, 88], [88, 89], [90, 92], [93, 102], [102, 103], [104, 111], [112, 123], [123, 124], [125, 130], [131, 139], [139, 140], [141, 151], [152, 160], [161, 175], [176, 179], [180, 191], [191, 192]]}
{"doc_key": "ai-train-23", "ner": [[6, 7, "task"], [12, 13, "university"], [15, 16, "university"], [19, 20, "university"], [22, 22, "university"], [27, 32, "university"], [33, 34, "university"], [36, 38, "university"], [40, 41, "university"], [17, 48, "university"], [50, 50, "university"], [54, 58, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[6, 7, 12, 13, "related-to", "", true, false], [6, 7, 15, 16, "related-to", "", true, false], [6, 7, 19, 20, "related-to", "", true, false], [6, 7, 22, 22, "related-to", "", true, false], [6, 7, 27, 32, "related-to", "", true, false], [6, 7, 33, 34, "related-to", "", true, false], [6, 7, 36, 38, "related-to", "", true, false], [6, 7, 40, 41, "related-to", "", true, false], [6, 7, 17, 48, "related-to", "", true, false], [6, 7, 50, 50, "related-to", "", true, false], [6, 7, 54, 58, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Several", "groups", "and", "companies", "are", "researching", "pose", "estimation", ",", "including", "groups", "at", "Brown", "University", ",", "Carnegie", "Mellon", "University", ",", "MPI", "Saarbruecken", ",", "Stanford", "University", ",", "University", "of", "California", ",", "San", "Diego", ",", "University", "of", "Toronto", ",", "\u00c9cole", "Centrale", "Paris", ",", "ETH", "Zurich", ",", "National", "University", "of", "Science", "and", "Technology", "(", "NUST", ")", ",", "and", "University", "of", "California", ",", "Irvine", "."], "sentence-detokenized": "Several groups and companies are researching pose estimation, including groups at Brown University, Carnegie Mellon University, MPI Saarbruecken, Stanford University, University of California, San Diego, University of Toronto, \u00c9cole Centrale Paris, ETH Zurich, National University of Science and Technology (NUST), and University of California, Irvine.", "token2charspan": [[0, 7], [8, 14], [15, 18], [19, 28], [29, 32], [33, 44], [45, 49], [50, 60], [60, 61], [62, 71], [72, 78], [79, 81], [82, 87], [88, 98], [98, 99], [100, 108], [109, 115], [116, 126], [126, 127], [128, 131], [132, 144], [144, 145], [146, 154], [155, 165], [165, 166], [167, 177], [178, 180], [181, 191], [191, 192], [193, 196], [197, 202], [202, 203], [204, 214], [215, 217], [218, 225], [225, 226], [227, 232], [233, 241], [242, 247], [247, 248], [249, 252], [253, 259], [259, 260], [261, 269], [270, 280], [281, 283], [284, 291], [292, 295], [296, 306], [307, 308], [308, 312], [312, 313], [313, 314], [315, 318], [319, 329], [330, 332], [333, 343], [343, 344], [345, 351], [351, 352]]}
{"doc_key": "ai-train-24", "ner": [[0, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sigmoid", "function", "The", "cross", "entropy", "loss", "is", "used", "to", "predict", "independent", "K", "probability", "values", "in", "maths", "0.1", "/", "maths", "."], "sentence-detokenized": "Sigmoid function The cross entropy loss is used to predict independent K probability values in maths 0.1 / maths.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 26], [27, 34], [35, 39], [40, 42], [43, 47], [48, 50], [51, 58], [59, 70], [71, 72], [73, 84], [85, 91], [92, 94], [95, 100], [101, 104], [105, 106], [107, 112], [112, 113]]}
{"doc_key": "ai-train-25", "ner": [[3, 5, "misc"], [7, 7, "field"], [9, 10, "field"], [13, 16, "university"], [18, 18, "country"], [21, 23, "misc"], [26, 29, "university"], [31, 31, "country"], [37, 37, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 5, 7, 7, "topic", "", false, false], [3, 5, 9, 10, "topic", "", false, false], [3, 5, 13, 16, "physical", "", true, false], [13, 16, 18, 18, "physical", "", false, false], [21, 23, 26, 29, "physical", "", true, false], [26, 29, 31, 31, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "held", "the", "Johann", "Bernoulli", "Chair", "in", "Mathematics", "and", "Computer", "Science", "at", "the", "University", "of", "Groningen", "in", "the", "Netherlands", "and", "the", "Toshiba", "Endowed", "Chair", "at", "the", "Tokyo", "Institute", "of", "Technology", "in", "Japan", "before", "becoming", "a", "Professor", "at", "Cambridge", "."], "sentence-detokenized": "He held the Johann Bernoulli Chair in Mathematics and Computer Science at the University of Groningen in the Netherlands and the Toshiba Endowed Chair at the Tokyo Institute of Technology in Japan before becoming a Professor at Cambridge.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 18], [19, 28], [29, 34], [35, 37], [38, 49], [50, 53], [54, 62], [63, 70], [71, 73], [74, 77], [78, 88], [89, 91], [92, 101], [102, 104], [105, 108], [109, 120], [121, 124], [125, 128], [129, 136], [137, 144], [145, 150], [151, 153], [154, 157], [158, 163], [164, 173], [174, 176], [177, 187], [188, 190], [191, 196], [197, 203], [204, 212], [213, 214], [215, 224], [225, 227], [228, 237], [237, 238]]}
{"doc_key": "ai-train-26", "ner": [[5, 6, "algorithm"], [11, 14, "algorithm"], [17, 17, "algorithm"], [20, 21, "researcher"], [23, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 11, 14, "usage", "", true, false], [11, 14, 20, 21, "origin", "", false, false], [11, 14, 23, 24, "origin", "", false, false], [17, 17, 11, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Another", "technique", "particularly", "used", "for", "recurrent", "neural", "networks", "is", "the", "1997", "long", "-", "term", "memory", "network", "(", "LSTM", ")", "by", "Sepp", "Hochreiter", "&", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Another technique particularly used for recurrent neural networks is the 1997 long-term memory network (LSTM) by Sepp Hochreiter & J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 7], [8, 17], [18, 30], [31, 35], [36, 39], [40, 49], [50, 56], [57, 65], [66, 68], [69, 72], [73, 77], [78, 82], [82, 83], [83, 87], [88, 94], [95, 102], [103, 104], [104, 108], [108, 109], [110, 112], [113, 117], [118, 128], [129, 130], [131, 137], [138, 149], [149, 150]]}
{"doc_key": "ai-train-27", "ner": [[4, 5, "programlang"], [8, 9, "product"], [14, 14, "product"], [46, 46, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 4, 5, "general-affiliation", "", false, false], [8, 9, 14, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "inclusion", "of", "a", "C", "++", "interpreter", "(", "CI", "NT", "until", "version", "5.34", ",", "Cling", "from", "version", "6", "onwards", ")", "makes", "this", "package", "very", "versatile", "as", "it", "can", "be", "used", "in", "interactive", ",", "scripted", "and", "compiled", "modes", "in", "a", "similar", "way", "to", "commercial", "products", "such", "as", "MATLAB", "."], "sentence-detokenized": "The inclusion of a C++ interpreter (CINT until version 5.34, Cling from version 6 onwards) makes this package very versatile as it can be used in interactive, scripted and compiled modes in a similar way to commercial products such as MATLAB.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 18], [19, 20], [20, 22], [23, 34], [35, 36], [36, 38], [38, 40], [41, 46], [47, 54], [55, 59], [59, 60], [61, 66], [67, 71], [72, 79], [80, 81], [82, 89], [89, 90], [91, 96], [97, 101], [102, 109], [110, 114], [115, 124], [125, 127], [128, 130], [131, 134], [135, 137], [138, 142], [143, 145], [146, 157], [157, 158], [159, 167], [168, 171], [172, 180], [181, 186], [187, 189], [190, 191], [192, 199], [200, 203], [204, 206], [207, 217], [218, 226], [227, 231], [232, 234], [235, 241], [241, 242]]}
{"doc_key": "ai-train-28", "ner": [[0, 2, "product"], [21, 23, "field"], [27, 28, "task"], [30, 31, "task"], [33, 34, "task"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 21, 23, "related-to", "", false, false], [27, 28, 21, 23, "part-of", "", false, false], [30, 31, 21, 23, "part-of", "", false, false], [33, 34, 21, 23, "part-of", "", false, false], [36, 37, 21, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Voice", "user", "interfaces", "that", "interpret", "and", "manage", "conversational", "state", "are", "challenging", "to", "design", "due", "to", "the", "inherent", "difficulty", "of", "integrating", "complex", "natural", "language", "processing", "tasks", "such", "as", "reference", "resolution", ",", "identity", "recognition", ",", "information", "retrieval", "and", "dialogue", "management", "."], "sentence-detokenized": "Voice user interfaces that interpret and manage conversational state are challenging to design due to the inherent difficulty of integrating complex natural language processing tasks such as reference resolution, identity recognition, information retrieval and dialogue management.", "token2charspan": [[0, 5], [6, 10], [11, 21], [22, 26], [27, 36], [37, 40], [41, 47], [48, 62], [63, 68], [69, 72], [73, 84], [85, 87], [88, 94], [95, 98], [99, 101], [102, 105], [106, 114], [115, 125], [126, 128], [129, 140], [141, 148], [149, 156], [157, 165], [166, 176], [177, 182], [183, 187], [188, 190], [191, 200], [201, 211], [211, 212], [213, 221], [222, 233], [233, 234], [235, 246], [247, 256], [257, 260], [261, 269], [270, 280], [280, 281]]}
{"doc_key": "ai-train-29", "ner": [[6, 7, "algorithm"], [10, 13, "algorithm"], [17, 18, "researcher"], [24, 27, "organisation"], [31, 32, "field"], [34, 36, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 17, 18, "origin", "", false, false], [6, 7, 31, 32, "part-of", "", false, false], [6, 7, 34, 36, "part-of", "", false, false], [10, 13, 17, 18, "origin", "", false, false], [10, 13, 31, 32, "part-of", "", false, false], [10, 13, 34, 36, "part-of", "", false, false], [17, 18, 24, 27, "physical", "", false, false], [17, 18, 24, 27, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Between", "2009", "and", "2012", ",", "the", "recurrent", "neural", "networks", "and", "deep", "-", "feedback", "neural", "networks", "developed", "in", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "Swiss", "AI", "Lab", "IDSIA", "won", "eight", "international", "pattern", "recognition", "and", "machine", "learning", "competitions", "."], "sentence-detokenized": "Between 2009 and 2012, the recurrent neural networks and deep-feedback neural networks developed in J\u00fcrgen Schmidhuber's research group at the Swiss AI Lab IDSIA won eight international pattern recognition and machine learning competitions.", "token2charspan": [[0, 7], [8, 12], [13, 16], [17, 21], [21, 22], [23, 26], [27, 36], [37, 43], [44, 52], [53, 56], [57, 61], [61, 62], [62, 70], [71, 77], [78, 86], [87, 96], [97, 99], [100, 106], [107, 118], [118, 120], [121, 129], [130, 135], [136, 138], [139, 142], [143, 148], [149, 151], [152, 155], [156, 161], [162, 165], [166, 171], [172, 185], [186, 193], [194, 205], [206, 209], [210, 217], [218, 226], [227, 239], [239, 240]]}
{"doc_key": "ai-train-30", "ner": [[1, 3, "product"], [7, 8, "product"], [10, 11, "product"], [15, 18, "task"], [15, 15, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 7, 8, "usage", "", false, false], [1, 3, 10, 11, "usage", "", false, false], [1, 3, 15, 18, "usage", "", true, false], [1, 3, 15, 15, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Modern", "Windows", "desktop", "systems", "can", "use", "the", "SAPI", "4", "and", "SAPI", "5", "components", "to", "support", "speech", "and", "voice", "synthesis", "."], "sentence-detokenized": "Modern Windows desktop systems can use the SAPI 4 and SAPI 5 components to support speech and voice synthesis.", "token2charspan": [[0, 6], [7, 14], [15, 22], [23, 30], [31, 34], [35, 38], [39, 42], [43, 47], [48, 49], [50, 53], [54, 58], [59, 60], [61, 71], [72, 74], [75, 82], [83, 89], [90, 93], [94, 99], [100, 109], [109, 110]]}
{"doc_key": "ai-train-31", "ner": [[7, 12, "misc"], [14, 14, "field"], [17, 20, "university"], [26, 29, "field"], [31, 34, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 12, 14, 14, "topic", "topic_of_award", false, false], [7, 12, 17, 20, "origin", "", true, false], [26, 29, 31, 34, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "received", "two", "honorary", "degrees", ",", "a", "S.", "V.", "della", "laurea", "ad", "honorem", "in", "Psychology", "from", "the", "University", "of", "Padua", "in", "1995", "and", "a", "doctorate", "in", "Industrial", "Design", "and", "Engineering", "from", "Delft", "University", "of", "Technology", "."], "sentence-detokenized": "He received two honorary degrees, a S. V. della laurea ad honorem in Psychology from the University of Padua in 1995 and a doctorate in Industrial Design and Engineering from Delft University of Technology.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 24], [25, 32], [32, 33], [34, 35], [36, 38], [39, 41], [42, 47], [48, 54], [55, 57], [58, 65], [66, 68], [69, 79], [80, 84], [85, 88], [89, 99], [100, 102], [103, 108], [109, 111], [112, 116], [117, 120], [121, 122], [123, 132], [133, 135], [136, 146], [147, 153], [154, 157], [158, 169], [170, 174], [175, 180], [181, 191], [192, 194], [195, 205], [205, 206]]}
{"doc_key": "ai-train-32", "ner": [[5, 6, "researcher"], [12, 15, "organisation"], [17, 17, "location"], [19, 19, "researcher"], [30, 31, "misc"], [44, 46, "misc"], [62, 63, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 6, 12, 15, "physical", "", false, false], [5, 6, 12, 15, "role", "", false, false], [12, 15, 17, 17, "physical", "", false, false], [19, 19, 30, 31, "related-to", "works_with", true, false], [19, 19, 44, 46, "related-to", "works_with", true, false], [19, 19, 62, 63, "related-to", "works_with", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["With", "long", "-", "time", "collaborator", "Laurent", "Cohen", ",", "a", "neurologist", "at", "the", "Piti\u00e9", "-", "Salp\u00eatri\u00e8re", "Hospital", "in", "Paris", ",", "Dehaene", "also", "identified", "patients", "with", "lesions", "in", "different", "regions", "of", "the", "parietal", "lobe", "with", "impaired", "multiplication", "but", "preserved", "subtraction", "(", "associated", "with", "lesions", "of", "the", "inferior", "parietal", "lobe", ")", "and", "others", "with", "impaired", "subtraction", "but", "preserved", "multiplication", "(", "associated", "with", "lesions", "of", "the", "intraparietal", "sulcus", ")", "."], "sentence-detokenized": "With long-time collaborator Laurent Cohen, a neurologist at the Piti\u00e9-Salp\u00eatri\u00e8re Hospital in Paris, Dehaene also identified patients with lesions in different regions of the parietal lobe with impaired multiplication but preserved subtraction (associated with lesions of the inferior parietal lobe) and others with impaired subtraction but preserved multiplication (associated with lesions of the intraparietal sulcus).", "token2charspan": [[0, 4], [5, 9], [9, 10], [10, 14], [15, 27], [28, 35], [36, 41], [41, 42], [43, 44], [45, 56], [57, 59], [60, 63], [64, 69], [69, 70], [70, 81], [82, 90], [91, 93], [94, 99], [99, 100], [101, 108], [109, 113], [114, 124], [125, 133], [134, 138], [139, 146], [147, 149], [150, 159], [160, 167], [168, 170], [171, 174], [175, 183], [184, 188], [189, 193], [194, 202], [203, 217], [218, 221], [222, 231], [232, 243], [244, 245], [245, 255], [256, 260], [261, 268], [269, 271], [272, 275], [276, 284], [285, 293], [294, 298], [298, 299], [300, 303], [304, 310], [311, 315], [316, 324], [325, 336], [337, 340], [341, 350], [351, 365], [366, 367], [367, 377], [378, 382], [383, 390], [391, 393], [394, 397], [398, 411], [412, 418], [418, 419], [419, 420]]}
{"doc_key": "ai-train-33", "ner": [[6, 8, "product"], [13, 16, "misc"], [18, 19, "misc"], [26, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 16, 6, 8, "topic", "", false, false], [18, 19, 6, 8, "topic", "", false, false], [26, 26, 6, 8, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["More", "recently", ",", "fictional", "depictions", "of", "artificially", "intelligent", "robots", "in", "films", "such", "as", "A.I", ".", "Artificial", "Intelligence", "and", "Ex", "Machina", "and", "the", "2016", "TV", "adaptation", "of", "Westworld", "have", "drawn", "public", "sympathy", "for", "robots", "themselves", "."], "sentence-detokenized": "More recently, fictional depictions of artificially intelligent robots in films such as A.I. Artificial Intelligence and Ex Machina and the 2016 TV adaptation of Westworld have drawn public sympathy for robots themselves.", "token2charspan": [[0, 4], [5, 13], [13, 14], [15, 24], [25, 35], [36, 38], [39, 51], [52, 63], [64, 70], [71, 73], [74, 79], [80, 84], [85, 87], [88, 91], [91, 92], [93, 103], [104, 116], [117, 120], [121, 123], [124, 131], [132, 135], [136, 139], [140, 144], [145, 147], [148, 158], [159, 161], [162, 171], [172, 176], [177, 182], [183, 189], [190, 198], [199, 202], [203, 209], [210, 220], [220, 221]]}
{"doc_key": "ai-train-34", "ner": [[7, 8, "field"], [10, 12, "algorithm"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 12, 7, 8, "part-of", "", false, false], [14, 15, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "of", "the", "main", "methods", "used", "in", "unsupervised", "learning", "are", "principal", "component", "analysis", "and", "cluster", "analysis", "."], "sentence-detokenized": "Two of the main methods used in unsupervised learning are principal component analysis and cluster analysis.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 15], [16, 23], [24, 28], [29, 31], [32, 44], [45, 53], [54, 57], [58, 67], [68, 77], [78, 86], [87, 90], [91, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-train-35", "ner": [[0, 3, "organisation"], [23, 24, "misc"], [29, 30, "misc"], [32, 34, "person"], [39, 40, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[23, 24, 0, 3, "artifact", "", false, false], [29, 30, 0, 3, "artifact", "", false, false], [29, 30, 32, 34, "role", "director_of", false, false], [29, 30, 39, 40, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Walt", "Disney", "Company", "also", "initiated", "the", "more", "prominent", "use", "of", "3D", "films", "in", "special", "locations", "to", "wow", "audiences", ",", "notable", "examples", "being", "Magic", "Journeys", "(", "1982", ")", "and", "Captain", "EO", "(", "Francis", "Ford", "Coppola", ",", "1986", ",", "starring", "Michael", "Jackson", ")", "."], "sentence-detokenized": "The Walt Disney Company also initiated the more prominent use of 3D films in special locations to wow audiences, notable examples being Magic Journeys (1982) and Captain EO (Francis Ford Coppola, 1986, starring Michael Jackson).", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 23], [24, 28], [29, 38], [39, 42], [43, 47], [48, 57], [58, 61], [62, 64], [65, 67], [68, 73], [74, 76], [77, 84], [85, 94], [95, 97], [98, 101], [102, 111], [111, 112], [113, 120], [121, 129], [130, 135], [136, 141], [142, 150], [151, 152], [152, 156], [156, 157], [158, 161], [162, 169], [170, 172], [173, 174], [174, 181], [182, 186], [187, 194], [194, 195], [196, 200], [200, 201], [202, 210], [211, 218], [219, 226], [226, 227], [227, 228]]}
{"doc_key": "ai-train-36", "ner": [[12, 14, "field"], [19, 24, "task"], [26, 27, "task"], [29, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 24, 12, 14, "part-of", "", false, false], [26, 27, 12, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Since", "2002", ",", "perceptron", "training", "has", "become", "popular", "in", "the", "field", "of", "natural", "language", "processing", "for", "tasks", "such", "as", "part", "-", "of", "-", "speech", "labelling", "and", "syntactic", "analysis", "(", "Collins", ",", "2002", ")", "."], "sentence-detokenized": "Since 2002, perceptron training has become popular in the field of natural language processing for tasks such as part-of-speech labelling and syntactic analysis (Collins, 2002).", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 22], [23, 31], [32, 35], [36, 42], [43, 50], [51, 53], [54, 57], [58, 63], [64, 66], [67, 74], [75, 83], [84, 94], [95, 98], [99, 104], [105, 109], [110, 112], [113, 117], [117, 118], [118, 120], [120, 121], [121, 127], [128, 137], [138, 141], [142, 151], [152, 160], [161, 162], [162, 169], [169, 170], [171, 175], [175, 176], [176, 177]]}
{"doc_key": "ai-train-37", "ner": [[2, 3, "product"], [9, 13, "organisation"], [15, 16, "organisation"], [18, 18, "country"], [22, 25, "product"], [29, 30, "researcher"], [40, 40, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 13, 2, 3, "role", "introduces_to_market", true, false], [15, 16, 2, 3, "role", "introduces_to_market", true, false], [15, 16, 18, 18, "physical", "", false, false], [22, 25, 40, 40, "related-to", "sold_to", true, false], [29, 30, 22, 25, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "first", "palletising", "robot", "was", "introduced", "in", "1963", "by", "Fuji", "Yusoki", "Kogyo", "Company", ".", "by", "KUKA", "robotics", "in", "Germany", ",", "and", "the", "Programmable", "Universal", "Assembly", "Machine", "was", "invented", "by", "Victor", "Scheinman", "in", "1976", ",", "and", "the", "project", "was", "sold", "to", "Unimation", "."], "sentence-detokenized": "The first palletising robot was introduced in 1963 by Fuji Yusoki Kogyo Company. by KUKA robotics in Germany, and the Programmable Universal Assembly Machine was invented by Victor Scheinman in 1976, and the project was sold to Unimation.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 27], [28, 31], [32, 42], [43, 45], [46, 50], [51, 53], [54, 58], [59, 65], [66, 71], [72, 79], [79, 80], [81, 83], [84, 88], [89, 97], [98, 100], [101, 108], [108, 109], [110, 113], [114, 117], [118, 130], [131, 140], [141, 149], [150, 157], [158, 161], [162, 170], [171, 173], [174, 180], [181, 190], [191, 193], [194, 198], [198, 199], [200, 203], [204, 207], [208, 215], [216, 219], [220, 224], [225, 227], [228, 237], [237, 238]]}
{"doc_key": "ai-train-38", "ner": [[10, 10, "conference"], [12, 12, "researcher"], [19, 19, "field"], [35, 36, "researcher"], [43, 44, "researcher"], [57, 57, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 12, 10, 10, "role", "president_of", false, false], [12, 12, 35, 36, "role", "colleagues", false, false], [19, 19, 57, 57, "named", "same", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "mid-1990s", ",", "while", "serving", "as", "president", "of", "the", "AAAI", ",", "Hayes", "initiated", "a", "series", "of", "attacks", "on", "AI", "critics", ",", "mostly", "couched", "in", "an", "ironic", "light", ",", "and", "(", "along", "with", "his", "colleague", "Kenneth", "Ford", ")", "invented", "a", "prize", "named", "after", "Simon", "Newcomb", "to", "be", "given", "for", "the", "most", "ridiculous", "argument", "refuting", "the", "possibility", "of", "AI", "."], "sentence-detokenized": "In the mid-1990s, while serving as president of the AAAI, Hayes initiated a series of attacks on AI critics, mostly couched in an ironic light, and (along with his colleague Kenneth Ford) invented a prize named after Simon Newcomb to be given for the most ridiculous argument refuting the possibility of AI.", "token2charspan": [[0, 2], [3, 6], [7, 16], [16, 17], [18, 23], [24, 31], [32, 34], [35, 44], [45, 47], [48, 51], [52, 56], [56, 57], [58, 63], [64, 73], [74, 75], [76, 82], [83, 85], [86, 93], [94, 96], [97, 99], [100, 107], [107, 108], [109, 115], [116, 123], [124, 126], [127, 129], [130, 136], [137, 142], [142, 143], [144, 147], [148, 149], [149, 154], [155, 159], [160, 163], [164, 173], [174, 181], [182, 186], [186, 187], [188, 196], [197, 198], [199, 204], [205, 210], [211, 216], [217, 222], [223, 230], [231, 233], [234, 236], [237, 242], [243, 246], [247, 250], [251, 255], [256, 266], [267, 275], [276, 284], [285, 288], [289, 300], [301, 303], [304, 306], [306, 307]]}
{"doc_key": "ai-train-39", "ner": [[12, 14, "algorithm"], [36, 37, "algorithm"], [49, 51, "algorithm"], [55, 58, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 14, 36, 37, "named", "same", false, false], [49, 51, 12, 14, "type-of", "", false, false], [55, 58, 12, 14, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["An", "optimal", "value", "for", "alpha", "/", "mathematics", "can", "be", "found", "using", "a", "line", "search", "algorithm", ",", "i.e.", "the", "magnitude", "of", "alpha", "/", "mathematics", "is", "determined", "by", "finding", "the", "value", "that", "minimizes", "S", ",", "usually", "using", "a", "line", "search", "in", "the", "range", "alpha", "0", "alpha", "1", "/", "mathematics", "or", "a", "backtracking", "line", "search", "such", "as", "the", "Armijo", "-", "line", "search", "."], "sentence-detokenized": "An optimal value for alpha/mathematics can be found using a line search algorithm, i.e. the magnitude of alpha/mathematics is determined by finding the value that minimizes S, usually using a line search in the range alpha 0 alpha 1/mathematics or a backtracking line search such as the Armijo-line search.", "token2charspan": [[0, 2], [3, 10], [11, 16], [17, 20], [21, 26], [26, 27], [27, 38], [39, 42], [43, 45], [46, 51], [52, 57], [58, 59], [60, 64], [65, 71], [72, 81], [81, 82], [83, 87], [88, 91], [92, 101], [102, 104], [105, 110], [110, 111], [111, 122], [123, 125], [126, 136], [137, 139], [140, 147], [148, 151], [152, 157], [158, 162], [163, 172], [173, 174], [174, 175], [176, 183], [184, 189], [190, 191], [192, 196], [197, 203], [204, 206], [207, 210], [211, 216], [217, 222], [223, 224], [225, 230], [231, 232], [232, 233], [233, 244], [245, 247], [248, 249], [250, 262], [263, 267], [268, 274], [275, 279], [280, 282], [283, 286], [287, 293], [293, 294], [294, 298], [299, 305], [305, 306]]}
{"doc_key": "ai-train-40", "ner": [[2, 9, "algorithm"], [6, 8, "algorithm"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "discusses", "Breadth", "-", "first", "and", "Depth", "-", "first", "search", "techniques", ",", "but", "eventually", "concludes", "that", "the", "results", "represent", "expert", "systems", "that", "embody", "a", "lot", "of", "technical", "knowledge", ",", "but", "do", "not", "shed", "much", "light", "on", "the", "mental", "processes", "that", "humans", "use", "to", "solve", "such", "puzzles", "."], "sentence-detokenized": "He discusses Breadth-first and Depth-first search techniques, but eventually concludes that the results represent expert systems that embody a lot of technical knowledge, but do not shed much light on the mental processes that humans use to solve such puzzles.", "token2charspan": [[0, 2], [3, 12], [13, 20], [20, 21], [21, 26], [27, 30], [31, 36], [36, 37], [37, 42], [43, 49], [50, 60], [60, 61], [62, 65], [66, 76], [77, 86], [87, 91], [92, 95], [96, 103], [104, 113], [114, 120], [121, 128], [129, 133], [134, 140], [141, 142], [143, 146], [147, 149], [150, 159], [160, 169], [169, 170], [171, 174], [175, 177], [178, 181], [182, 186], [187, 191], [192, 197], [198, 200], [201, 204], [205, 211], [212, 221], [222, 226], [227, 233], [234, 237], [238, 240], [241, 246], [247, 251], [252, 259], [259, 260]]}
{"doc_key": "ai-train-41", "ner": [[0, 1, "task"], [3, 4, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Speech", "recognition", "and", "speech", "synthesis", "deal", "with", "how", "spoken", "language", "can", "be", "understood", "or", "created", "using", "computers", "."], "sentence-detokenized": "Speech recognition and speech synthesis deal with how spoken language can be understood or created using computers.", "token2charspan": [[0, 6], [7, 18], [19, 22], [23, 29], [30, 39], [40, 44], [45, 49], [50, 53], [54, 60], [61, 69], [70, 73], [74, 76], [77, 87], [88, 90], [91, 98], [99, 104], [105, 114], [114, 115]]}
{"doc_key": "ai-train-42", "ner": [[12, 13, "algorithm"], [32, 34, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "theta", "^", "^", "maths", "/", "maths", "is", "usually", "estimated", "using", "a", "Maximum", "Likelihood", "procedure", "(", "theta", "^", "^", "{", "*}", "maths", "==", "theta", "^", "{", "ML", "}", "/", "maths", ")", "or", "Maximum", "A", "Posteriori", "(", "theta", "^", "{", "*}", "maths", "==", "theta", "^", "^", "{", "MAP", "}", "/", "maths", ")", "."], "sentence-detokenized": "This theta ^ ^ maths / maths is usually estimated using a Maximum Likelihood procedure (theta ^ ^ {*} maths == theta ^ {ML} / maths) or Maximum A Posteriori (theta ^ {*} maths == theta ^ ^ {MAP} / maths).", "token2charspan": [[0, 4], [5, 10], [11, 12], [13, 14], [15, 20], [21, 22], [23, 28], [29, 31], [32, 39], [40, 49], [50, 55], [56, 57], [58, 65], [66, 76], [77, 86], [87, 88], [88, 93], [94, 95], [96, 97], [98, 99], [99, 101], [102, 107], [108, 110], [111, 116], [117, 118], [119, 120], [120, 122], [122, 123], [124, 125], [126, 131], [131, 132], [133, 135], [136, 143], [144, 145], [146, 156], [157, 158], [158, 163], [164, 165], [166, 167], [167, 169], [170, 175], [176, 178], [179, 184], [185, 186], [187, 188], [189, 190], [190, 193], [193, 194], [195, 196], [197, 202], [202, 203], [203, 204]]}
{"doc_key": "ai-train-43", "ner": [[8, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "lesser", "spoken", "languages", "use", "the", "open", "source", "eSpeak", "synthesizer", "for", "their", "speech", ";", "producing", "a", "robotic", ",", "awkward", "voice", "that", "can", "be", "difficult", "to", "understand", "."], "sentence-detokenized": "Some lesser spoken languages use the open source eSpeak synthesizer for their speech; producing a robotic, awkward voice that can be difficult to understand.", "token2charspan": [[0, 4], [5, 11], [12, 18], [19, 28], [29, 32], [33, 36], [37, 41], [42, 48], [49, 55], [56, 67], [68, 71], [72, 77], [78, 84], [84, 85], [86, 95], [96, 97], [98, 105], [105, 106], [107, 114], [115, 120], [121, 125], [126, 129], [130, 132], [133, 142], [143, 145], [146, 156], [156, 157]]}
{"doc_key": "ai-train-44", "ner": [[19, 19, "programlang"], [35, 36, "programlang"], [38, 38, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 19, 35, 36, "compare", "", false, false], [19, 19, 38, 38, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Although", "used", "primarily", "by", "statisticians", "and", "other", "professionals", "who", "require", "an", "environment", "for", "statistical", "computing", "and", "software", "development", ",", "R", "can", "also", "operate", "as", "a", "general", "matrix", "computation", "toolbox", "-", "with", "performance", "standards", "comparable", "to", "GNU", "Octave", "or", "MATLAB", "."], "sentence-detokenized": "Although used primarily by statisticians and other professionals who require an environment for statistical computing and software development, R can also operate as a general matrix computation toolbox - with performance standards comparable to GNU Octave or MATLAB.", "token2charspan": [[0, 8], [9, 13], [14, 23], [24, 26], [27, 40], [41, 44], [45, 50], [51, 64], [65, 68], [69, 76], [77, 79], [80, 91], [92, 95], [96, 107], [108, 117], [118, 121], [122, 130], [131, 142], [142, 143], [144, 145], [146, 149], [150, 154], [155, 162], [163, 165], [166, 167], [168, 175], [176, 182], [183, 194], [195, 202], [203, 204], [205, 209], [210, 221], [222, 231], [232, 242], [243, 245], [246, 249], [250, 256], [257, 259], [260, 266], [266, 267]]}
{"doc_key": "ai-train-45", "ner": [[0, 0, "algorithm"], [3, 4, "field"], [8, 11, "misc"], [12, 13, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 4, "part-of", "", false, false], [0, 0, 12, 13, "origin", "", false, false], [8, 11, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Heterodyning", "is", "a", "signal", "processing", "technique", "invented", "by", "Canadian", "inventor", "-", "engineer", "Reginald", "Fessenden", "that", "creates", "new", "frequencies", "by", "combining", "two", "frequencies", "."], "sentence-detokenized": "Heterodyning is a signal processing technique invented by Canadian inventor-engineer Reginald Fessenden that creates new frequencies by combining two frequencies.", "token2charspan": [[0, 12], [13, 15], [16, 17], [18, 24], [25, 35], [36, 45], [46, 54], [55, 57], [58, 66], [67, 75], [75, 76], [76, 84], [85, 93], [94, 103], [104, 108], [109, 116], [117, 120], [121, 132], [133, 135], [136, 145], [146, 149], [150, 161], [161, 162]]}
{"doc_key": "ai-train-46", "ner": [[15, 16, "person"], [17, 17, "misc"], [22, 24, "organisation"], [27, 27, "organisation"], [29, 31, "misc"], [33, 34, "person"], [37, 37, "organisation"], [38, 41, "misc"], [43, 44, "person"], [46, 47, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[15, 16, 17, 17, "role", "actor_in", false, false], [17, 17, 22, 24, "artifact", "", false, false], [29, 31, 27, 27, "artifact", "", false, false], [33, 34, 29, 31, "role", "actor_in", false, false], [38, 41, 37, 37, "artifact", "", false, false], [43, 44, 38, 41, "role", "actor_in", false, false], [46, 47, 38, 41, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Several", "other", "features", "that", "helped", "put", "3D", "back", "on", "the", "map", "that", "month", "were", "the", "John", "Wayne", "Hondo", "feature", "(", "distributed", "by", "Warner", "Bros", ".", ")", ",", "Columbia", "'s", "Miss", "Sadie", "Thompson", "with", "Rita", "Hayworth", ",", "and", "Paramount", "'s", "Money", "From", "Home", "with", "Dean", "Martin", "and", "Jerry", "Lewis", "."], "sentence-detokenized": "Several other features that helped put 3D back on the map that month were the John Wayne Hondo feature (distributed by Warner Bros. ), Columbia's Miss Sadie Thompson with Rita Hayworth, and Paramount's Money From Home with Dean Martin and Jerry Lewis.", "token2charspan": [[0, 7], [8, 13], [14, 22], [23, 27], [28, 34], [35, 38], [39, 41], [42, 46], [47, 49], [50, 53], [54, 57], [58, 62], [63, 68], [69, 73], [74, 77], [78, 82], [83, 88], [89, 94], [95, 102], [103, 104], [104, 115], [116, 118], [119, 125], [126, 130], [130, 131], [132, 133], [133, 134], [135, 143], [143, 145], [146, 150], [151, 156], [157, 165], [166, 170], [171, 175], [176, 184], [184, 185], [186, 189], [190, 199], [199, 201], [202, 207], [208, 212], [213, 217], [218, 222], [223, 227], [228, 234], [235, 238], [239, 244], [245, 250], [250, 251]]}
{"doc_key": "ai-train-47", "ner": [[0, 0, "product"], [3, 4, "field"], [5, 6, "task"], [14, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "general-affiliation", "", false, false], [0, 0, 14, 14, "artifact", "", false, false], [5, 6, 3, 4, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["DeepFace", "is", "a", "deep", "learning", "facial", "recognition", "system", "created", "by", "a", "research", "group", "at", "Facebook", "."], "sentence-detokenized": "DeepFace is a deep learning facial recognition system created by a research group at Facebook.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 18], [19, 27], [28, 34], [35, 46], [47, 53], [54, 61], [62, 64], [65, 66], [67, 75], [76, 81], [82, 84], [85, 93], [93, 94]]}
{"doc_key": "ai-train-48", "ner": [[0, 1, "field"], [8, 8, "conference"], [15, 16, "field"], [0, 28, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 15, 16, "part-of", "subfield", false, false], [8, 8, 0, 1, "topic", "", false, false], [0, 28, 0, 1, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Geometry", "processing", "is", "a", "common", "research", "topic", "at", "SIGGRAPH", ",", "the", "leading", "academic", "conference", "on", "computer", "graphics", ",", "and", "the", "main", "topic", "of", "the", "annual", "Symposium", "on", "Geometry", "Processing", "."], "sentence-detokenized": "Geometry processing is a common research topic at SIGGRAPH, the leading academic conference on computer graphics, and the main topic of the annual Symposium on Geometry Processing.", "token2charspan": [[0, 8], [9, 19], [20, 22], [23, 24], [25, 31], [32, 40], [41, 46], [47, 49], [50, 58], [58, 59], [60, 63], [64, 71], [72, 80], [81, 91], [92, 94], [95, 103], [104, 112], [112, 113], [114, 117], [118, 121], [122, 126], [127, 132], [133, 135], [136, 139], [140, 146], [147, 156], [157, 159], [160, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-train-49", "ner": [[0, 1, "task"], [3, 4, "task"], [13, 15, "algorithm"], [17, 17, "algorithm"], [20, 22, "algorithm"], [24, 24, "algorithm"], [27, 29, "algorithm"], [31, 31, "algorithm"], [36, 36, "misc"], [41, 43, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[13, 15, 36, 36, "general-affiliation", "", false, false], [17, 17, 13, 15, "named", "", false, false], [20, 22, 36, 36, "general-affiliation", "", false, false], [24, 24, 20, 22, "named", "", false, false], [27, 29, 36, 36, "general-affiliation", "", false, false], [31, 31, 27, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Feature", "extraction", "and", "dimension", "reduction", "can", "be", "combined", "in", "a", "single", "step", "using", "Principal", "Component", "Analysis", "(", "PCA", ")", ",", "linear", "discriminant", "analysis", "(", "LDA", ")", "or", "canonical", "correlation", "analysis", "(", "CCA", ")", "techniques", "as", "a", "pre-processing", "step", ",", "followed", "by", "k", "-", "NN", "clustering", "into", "feature", "vectors", "in", "reduced", "dimension", "space", "."], "sentence-detokenized": "Feature extraction and dimension reduction can be combined in a single step using Principal Component Analysis (PCA), linear discriminant analysis (LDA) or canonical correlation analysis (CCA) techniques as a pre-processing step, followed by k -NN clustering into feature vectors in reduced dimension space.", "token2charspan": [[0, 7], [8, 18], [19, 22], [23, 32], [33, 42], [43, 46], [47, 49], [50, 58], [59, 61], [62, 63], [64, 70], [71, 75], [76, 81], [82, 91], [92, 101], [102, 110], [111, 112], [112, 115], [115, 116], [116, 117], [118, 124], [125, 137], [138, 146], [147, 148], [148, 151], [151, 152], [153, 155], [156, 165], [166, 177], [178, 186], [187, 188], [188, 191], [191, 192], [193, 203], [204, 206], [207, 208], [209, 223], [224, 228], [228, 229], [230, 238], [239, 241], [242, 243], [244, 245], [245, 247], [248, 258], [259, 263], [264, 271], [272, 279], [280, 282], [283, 290], [291, 300], [301, 306], [306, 307]]}
{"doc_key": "ai-train-50", "ner": [[0, 2, "algorithm"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 10, "related-to", "good_at", true, false], [0, 2, 12, 13, "related-to", "good_at", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Artificial", "neural", "networks", "are", "computational", "models", "that", "excel", "in", "machine", "learning", "and", "pattern", "recognition", "."], "sentence-detokenized": "Artificial neural networks are computational models that excel in machine learning and pattern recognition.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 30], [31, 44], [45, 51], [52, 56], [57, 62], [63, 65], [66, 73], [74, 82], [83, 86], [87, 94], [95, 106], [106, 107]]}
{"doc_key": "ai-train-51", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 11, "misc"], [13, 17, "conference"], [19, 19, "conference"], [35, 38, "algorithm"], [39, 40, "researcher"], [42, 44, "researcher"], [46, 52, "misc"], [54, 63, "conference"], [65, 65, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[7, 11, 0, 2, "artifact", "", false, false], [7, 11, 4, 5, "artifact", "", false, false], [7, 11, 13, 17, "temporal", "", false, false], [19, 19, 13, 17, "named", "", false, false], [46, 52, 35, 38, "topic", "", false, false], [46, 52, 39, 40, "artifact", "", false, false], [46, 52, 42, 44, "artifact", "", false, false], [46, 52, 54, 63, "temporal", "", false, false], [65, 65, 54, 63, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["C", ".", "Papageorgiou", "and", "T.", "Poggio", ",", "A", "Trainable", "Pedestrian", "Detection", "system", ",", "International", "Journal", "of", "Computer", "Vision", "(", "IJCV", ")", ",", "pages", "1", ":", "15", "-", "33", ",", "2000", "others", "use", "local", "features", "as", "histogram", "of", "oriented", "gradients", "N.", "Dalal", ",", "B", ".", "Triggs", ",", "Histograms", "of", "oriented", "gradients", "for", "human", "detection", ",", "IEEE", "Computer", "Society", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", ",", "pages", "1", ":", "886-", "893", ",", "2005", "descriptors", "."], "sentence-detokenized": "C. Papageorgiou and T. Poggio, A Trainable Pedestrian Detection system, International Journal of Computer Vision (IJCV), pages 1: 15-33, 2000 others use local features as histogram of oriented gradients N. Dalal, B. Triggs, Histograms of oriented gradients for human detection, IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), pages 1: 886-893, 2005 descriptors.", "token2charspan": [[0, 1], [1, 2], [3, 15], [16, 19], [20, 22], [23, 29], [29, 30], [31, 32], [33, 42], [43, 53], [54, 63], [64, 70], [70, 71], [72, 85], [86, 93], [94, 96], [97, 105], [106, 112], [113, 114], [114, 118], [118, 119], [119, 120], [121, 126], [127, 128], [128, 129], [130, 132], [132, 133], [133, 135], [135, 136], [137, 141], [142, 148], [149, 152], [153, 158], [159, 167], [168, 170], [171, 180], [181, 183], [184, 192], [193, 202], [203, 205], [206, 211], [211, 212], [213, 214], [214, 215], [216, 222], [222, 223], [224, 234], [235, 237], [238, 246], [247, 256], [257, 260], [261, 266], [267, 276], [276, 277], [278, 282], [283, 291], [292, 299], [300, 310], [311, 313], [314, 322], [323, 329], [330, 333], [334, 341], [342, 353], [354, 355], [355, 359], [359, 360], [360, 361], [362, 367], [368, 369], [369, 370], [371, 375], [375, 378], [378, 379], [380, 384], [385, 396], [396, 397]]}
{"doc_key": "ai-train-52", "ner": [[1, 1, "algorithm"], [6, 8, "algorithm"], [12, 14, "task"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 6, 8, "type-of", "", false, false], [12, 14, 1, 1, "usage", "", true, false], [12, 14, 16, 17, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["An", "autoencoder", "is", "a", "type", "of", "artificial", "neural", "network", "used", "to", "learn", "Feature", "Learning", "in", "an", "unsupervised", "way", "."], "sentence-detokenized": "An autoencoder is a type of artificial neural network used to learn Feature Learning in an unsupervised way.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 19], [20, 24], [25, 27], [28, 38], [39, 45], [46, 53], [54, 58], [59, 61], [62, 67], [68, 75], [76, 84], [85, 87], [88, 90], [91, 103], [104, 107], [107, 108]]}
{"doc_key": "ai-train-53", "ner": [[0, 0, "researcher"], [6, 6, "organisation"], [11, 12, "field"], [14, 16, "field"], [21, 25, "organisation"], [27, 27, "organisation"], [33, 34, "field"], [36, 37, "field"], [42, 42, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 6, 6, "role", "fellow_of", false, false], [0, 0, 11, 12, "related-to", "contributes_to", false, false], [0, 0, 14, 16, "related-to", "contributes_to", false, false], [0, 0, 21, 25, "role", "fellow_of", false, false], [0, 0, 33, 34, "related-to", "contributes_to", false, false], [0, 0, 36, 37, "related-to", "contributes_to", false, false], [27, 27, 21, 25, "named", "", false, false], [42, 42, 21, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Haralick", "is", "a", "Fellow", "of", "the", "IEEE", "for", "his", "contributions", "in", "computer", "vision", "and", "image", "processing", "and", "a", "Fellow", "of", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", "for", "his", "contributions", "in", "pattern", "recognition", ",", "image", "processing", ",", "and", "service", "to", "IAPR", "."], "sentence-detokenized": "Haralick is a Fellow of the IEEE for his contributions in computer vision and image processing and a Fellow of the International Association for Pattern Recognition (IAPR) for his contributions in pattern recognition, image processing, and service to IAPR.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 20], [21, 23], [24, 27], [28, 32], [33, 36], [37, 40], [41, 54], [55, 57], [58, 66], [67, 73], [74, 77], [78, 83], [84, 94], [95, 98], [99, 100], [101, 107], [108, 110], [111, 114], [115, 128], [129, 140], [141, 144], [145, 152], [153, 164], [165, 166], [166, 170], [170, 171], [172, 175], [176, 179], [180, 193], [194, 196], [197, 204], [205, 216], [216, 217], [218, 223], [224, 234], [234, 235], [236, 239], [240, 247], [248, 250], [251, 255], [255, 256]]}
{"doc_key": "ai-train-54", "ner": [[4, 9, "task"], [13, 15, "algorithm"], [17, 17, "algorithm"], [23, 24, "researcher"], [26, 27, "organisation"], [29, 30, "researcher"], [33, 35, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 9, 13, 15, "usage", "", false, false], [13, 15, 23, 24, "origin", "", true, false], [13, 15, 29, 30, "origin", "", true, false], [17, 17, 13, 15, "named", "", false, false], [23, 24, 26, 27, "physical", "", false, false], [23, 24, 26, 27, "role", "", false, false], [29, 30, 33, 35, "physical", "", false, false], [29, 30, 33, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "first", "attempt", "at", "end", "-", "to", "-", "end", "ASR", "was", "with", "the", "Temporal", "Connectionist", "Classification", "(", "CTC", ")", "based", "systems", "introduced", "by", "Alex", "Graves", "of", "Google", "DeepMind", "and", "Navdeep", "Jaitly", "of", "the", "University", "of", "Toronto", "in", "2014", "."], "sentence-detokenized": "The first attempt at end-to-end ASR was with the Temporal Connectionist Classification (CTC) based systems introduced by Alex Graves of Google DeepMind and Navdeep Jaitly of the University of Toronto in 2014.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 20], [21, 24], [24, 25], [25, 27], [27, 28], [28, 31], [32, 35], [36, 39], [40, 44], [45, 48], [49, 57], [58, 71], [72, 86], [87, 88], [88, 91], [91, 92], [93, 98], [99, 106], [107, 117], [118, 120], [121, 125], [126, 132], [133, 135], [136, 142], [143, 151], [152, 155], [156, 163], [164, 170], [171, 173], [174, 177], [178, 188], [189, 191], [192, 199], [200, 202], [203, 207], [207, 208]]}
{"doc_key": "ai-train-55", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "algorithm"], [13, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 0, 2, "named", "", false, false], [10, 11, 0, 2, "type-of", "", false, false], [13, 13, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Linear-", "fractional", "programming", "(", "LFP", ")", "is", "a", "generalisation", "of", "linear", "programming", "(", "LP", ")", "."], "sentence-detokenized": "Linear-fractional programming (LFP) is a generalisation of linear programming (LP).", "token2charspan": [[0, 7], [7, 17], [18, 29], [30, 31], [31, 34], [34, 35], [36, 38], [39, 40], [41, 55], [56, 58], [59, 65], [66, 77], [78, 79], [79, 81], [81, 82], [82, 83]]}
{"doc_key": "ai-train-56", "ner": [[0, 0, "researcher"], [8, 13, "misc"], [16, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 13, "win-defeat", "", false, false], [8, 13, 16, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lafferty", "has", "received", "numerous", "awards", ",", "including", "two", "Test", "-", "of", "-", "Time", "awards", "at", "the", "2011", "&", "2012", "International", "Conference", "on", "Machine", "Learning", ","], "sentence-detokenized": "Lafferty has received numerous awards, including two Test-of-Time awards at the 2011 & 2012 International Conference on Machine Learning,", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 30], [31, 37], [37, 38], [39, 48], [49, 52], [53, 57], [57, 58], [58, 60], [60, 61], [61, 65], [66, 72], [73, 75], [76, 79], [80, 84], [85, 86], [87, 91], [92, 105], [106, 116], [117, 119], [120, 127], [128, 136], [136, 137]]}
{"doc_key": "ai-train-57", "ner": [[10, 10, "product"], [12, 12, "programlang"], [24, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["With", "the", "advent", "of", "component", "-", "based", "frameworks", "such", "as", ".NET", "and", "Java", ",", "component", "-", "based", "development", "environments", "are", "able", "to", "deploy", "the", "neural", "network", "developed", "for", "these", "frameworks", "as", "hereditary", "components", "."], "sentence-detokenized": "With the advent of component-based frameworks such as .NET and Java, component-based development environments are able to deploy the neural network developed for these frameworks as hereditary components.", "token2charspan": [[0, 4], [5, 8], [9, 15], [16, 18], [19, 28], [28, 29], [29, 34], [35, 45], [46, 50], [51, 53], [54, 58], [59, 62], [63, 67], [67, 68], [69, 78], [78, 79], [79, 84], [85, 96], [97, 109], [110, 113], [114, 118], [119, 121], [122, 128], [129, 132], [133, 139], [140, 147], [148, 157], [158, 161], [162, 167], [168, 178], [179, 181], [182, 192], [193, 203], [203, 204]]}
{"doc_key": "ai-train-58", "ner": [[2, 2, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "in", "BLEU", ",", "the", "basic", "unit", "of", "evaluation", "is", "the", "sentence", ",", "the", "algorithm", "first", "creates", "an", "alignment", "(", "see", "illustrations", ")", "between", "two", "sentences", ",", "the", "candidate", "translation", "string", ",", "and", "the", "reference", "translation", "string", "."], "sentence-detokenized": "Since in BLEU, the basic unit of evaluation is the sentence, the algorithm first creates an alignment (see illustrations) between two sentences, the candidate translation string, and the reference translation string.", "token2charspan": [[0, 5], [6, 8], [9, 13], [13, 14], [15, 18], [19, 24], [25, 29], [30, 32], [33, 43], [44, 46], [47, 50], [51, 59], [59, 60], [61, 64], [65, 74], [75, 80], [81, 88], [89, 91], [92, 101], [102, 103], [103, 106], [107, 120], [120, 121], [122, 129], [130, 133], [134, 143], [143, 144], [145, 148], [149, 158], [159, 170], [171, 177], [177, 178], [179, 182], [183, 186], [187, 196], [197, 208], [209, 215], [215, 216]]}
{"doc_key": "ai-train-59", "ner": [[7, 11, "conference"], [22, 22, "task"], [24, 25, "task"], [29, 30, "metrics"], [32, 38, "metrics"], [43, 46, "conference"], [48, 48, "conference"], [51, 51, "location"], [53, 53, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 11, 22, 22, "related-to", "subject_at", false, false], [7, 11, 24, 25, "related-to", "subject_at", false, false], [29, 30, 7, 11, "temporal", "", false, false], [32, 38, 29, 30, "named", "", true, false], [48, 48, 43, 46, "named", "", false, false], [51, 51, 53, 53, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["One", "of", "the", "metrics", "used", "at", "the", "annual", "NIST", "Document", "Understanding", "Conferences", ",", "at", "which", "research", "groups", "submit", "their", "systems", "for", "both", "summarization", "and", "translation", "tasks", ",", "is", "the", "ROUGE", "metric", "(", "Recall", "-", "Oriented", "Understudy", "for", "Gisting", "Evaluation", ",", "In", "Advances", "of", "Neural", "Information", "Processing", "Systems", "(", "NIPS", ")", ",", "Montreal", ",", "Canada", ",", "December", "-", "2014", "."], "sentence-detokenized": "One of the metrics used at the annual NIST Document Understanding Conferences, at which research groups submit their systems for both summarization and translation tasks, is the ROUGE metric (Recall-Oriented Understudy for Gisting Evaluation, In Advances of Neural Information Processing Systems (NIPS), Montreal, Canada, December - 2014.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 18], [19, 23], [24, 26], [27, 30], [31, 37], [38, 42], [43, 51], [52, 65], [66, 77], [77, 78], [79, 81], [82, 87], [88, 96], [97, 103], [104, 110], [111, 116], [117, 124], [125, 128], [129, 133], [134, 147], [148, 151], [152, 163], [164, 169], [169, 170], [171, 173], [174, 177], [178, 183], [184, 190], [191, 192], [192, 198], [198, 199], [199, 207], [208, 218], [219, 222], [223, 230], [231, 241], [241, 242], [243, 245], [246, 254], [255, 257], [258, 264], [265, 276], [277, 287], [288, 295], [296, 297], [297, 301], [301, 302], [302, 303], [304, 312], [312, 313], [314, 320], [320, 321], [322, 330], [331, 332], [333, 337], [337, 338]]}
{"doc_key": "ai-train-60", "ner": [[7, 7, "programlang"], [9, 9, "product"], [11, 12, "programlang"], [16, 16, "product"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 7, 11, 12, "type-of", "", false, false], [7, 7, 22, 22, "named", "", false, false], [9, 9, 11, 12, "part-of", "", false, false], [9, 9, 16, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "same", "implementation", ",", "to", "run", "in", "Java", "with", "JShell", "(", "Java", "9", "minimum", ")", ":", "codejshell", "scriptfile", "/", "codesyntaxhighlight", "lang", "=", "java"], "sentence-detokenized": "The same implementation, to run in Java with JShell (Java 9 minimum): codejshell scriptfile / codesyntaxhighlight lang = java", "token2charspan": [[0, 3], [4, 8], [9, 23], [23, 24], [25, 27], [28, 31], [32, 34], [35, 39], [40, 44], [45, 51], [52, 53], [53, 57], [58, 59], [60, 67], [67, 68], [68, 69], [70, 80], [81, 91], [92, 93], [94, 113], [114, 118], [119, 120], [121, 125]]}
{"doc_key": "ai-train-61", "ner": [[1, 2, "metrics"], [7, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 7, 8, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "NIST", "metric", "is", "based", "on", "the", "BLEU", "metric", ",", "but", "with", "some", "changes", "."], "sentence-detokenized": "The NIST metric is based on the BLEU metric, but with some changes.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 18], [19, 24], [25, 27], [28, 31], [32, 36], [37, 43], [43, 44], [45, 48], [49, 53], [54, 58], [59, 66], [66, 67]]}
{"doc_key": "ai-train-62", "ner": [[6, 6, "country"], [9, 11, "university"], [13, 15, "university"], [22, 23, "product"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 11, 6, 6, "physical", "", false, false], [13, 15, 6, 6, "physical", "", false, false], [22, 23, 9, 11, "origin", "", false, false], [22, 23, 13, 15, "origin", "", false, false], [22, 23, 27, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "late", "1980s", ",", "two", "Dutch", "universities", ",", "University", "of", "Groningen", "and", "University", "of", "Twente", ",", "jointly", "started", "a", "project", "called", "Knowledge", "Graphs", ",", "which", "are", "semantic", "networks", ",", "but", "with", "the", "additional", "restriction", "that", "edges", "are", "restricted", "to", "be", "of", "a", "limited", "set", "of", "possible", "relations", ",", "to", "facilitate", "algebras", "in", "the", "graph", "."], "sentence-detokenized": "In the late 1980s, two Dutch universities, University of Groningen and University of Twente, jointly started a project called Knowledge Graphs, which are semantic networks, but with the additional restriction that edges are restricted to be of a limited set of possible relations, to facilitate algebras in the graph.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 17], [17, 18], [19, 22], [23, 28], [29, 41], [41, 42], [43, 53], [54, 56], [57, 66], [67, 70], [71, 81], [82, 84], [85, 91], [91, 92], [93, 100], [101, 108], [109, 110], [111, 118], [119, 125], [126, 135], [136, 142], [142, 143], [144, 149], [150, 153], [154, 162], [163, 171], [171, 172], [173, 176], [177, 181], [182, 185], [186, 196], [197, 208], [209, 213], [214, 219], [220, 223], [224, 234], [235, 237], [238, 240], [241, 243], [244, 245], [246, 253], [254, 257], [258, 260], [261, 269], [270, 279], [279, 280], [281, 283], [284, 294], [295, 303], [304, 306], [307, 310], [311, 316], [316, 317]]}
{"doc_key": "ai-train-63", "ner": [[0, 1, "product"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Grammar", "checkers", "are", "most", "often", "implemented", "as", "a", "feature", "of", "a", "larger", "program", ",", "such", "as", "a", "word", "processor", ",", "but", "are", "also", "available", "as", "a", "stand", "-", "alone", "application", "that", "can", "be", "activated", "from", "within", "programs", "that", "work", "with", "editable", "text", "."], "sentence-detokenized": "Grammar checkers are most often implemented as a feature of a larger program, such as a word processor, but are also available as a stand-alone application that can be activated from within programs that work with editable text.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 31], [32, 43], [44, 46], [47, 48], [49, 56], [57, 59], [60, 61], [62, 68], [69, 76], [76, 77], [78, 82], [83, 85], [86, 87], [88, 92], [93, 102], [102, 103], [104, 107], [108, 111], [112, 116], [117, 126], [127, 129], [130, 131], [132, 137], [137, 138], [138, 143], [144, 155], [156, 160], [161, 164], [165, 167], [168, 177], [178, 182], [183, 189], [190, 198], [199, 203], [204, 208], [209, 213], [214, 222], [223, 227], [227, 228]]}
{"doc_key": "ai-train-64", "ner": [[6, 12, "organisation"], [10, 20, "conference"], [23, 25, "organisation"], [30, 32, "conference"], [34, 36, "conference"], [39, 41, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ",", "and", "Cognitive", "Science", "Society", ",", "and", "editor", "of", "J.", "Automated", "Reasoning", ",", "J.", "Learning", "Sciences", ",", "and", "J.", "Applied", "Ontology", "."], "sentence-detokenized": "He is a member of the American Association for the Advancement of Science, Association for the Advancement of Artificial Intelligence, and Cognitive Science Society, and editor of J. Automated Reasoning, J. Learning Sciences, and J. Applied Ontology.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 42], [43, 46], [47, 50], [51, 62], [63, 65], [66, 73], [73, 74], [75, 86], [87, 90], [91, 94], [95, 106], [107, 109], [110, 120], [121, 133], [133, 134], [135, 138], [139, 148], [149, 156], [157, 164], [164, 165], [166, 169], [170, 176], [177, 179], [180, 182], [183, 192], [193, 202], [202, 203], [204, 206], [207, 215], [216, 224], [224, 225], [226, 229], [230, 232], [233, 240], [241, 249], [249, 250]]}
{"doc_key": "ai-train-65", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "task"], [20, 21, "researcher"], [23, 24, "university"], [26, 28, "researcher"], [29, 32, "organisation"], [34, 34, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 10, 11, "type-of", "", false, false], [0, 2, 20, 21, "origin", "", false, false], [0, 2, 26, 28, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [20, 21, 23, 24, "physical", "", false, false], [20, 21, 23, 24, "role", "", false, false], [26, 28, 29, 32, "role", "", false, false], [34, 34, 29, 32, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", ",", "a", "form", "of", "speech", "coding", ",", "began", "to", "be", "developed", "with", "the", "work", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", "."], "sentence-detokenized": "Linear predictive coding (LPC), a form of speech coding, began to be developed with the work Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 38], [39, 41], [42, 48], [49, 55], [55, 56], [57, 62], [63, 65], [66, 68], [69, 78], [79, 83], [84, 87], [88, 92], [93, 101], [102, 109], [110, 112], [113, 119], [120, 130], [131, 134], [135, 140], [141, 146], [147, 149], [150, 156], [157, 166], [167, 170], [171, 180], [181, 182], [182, 185], [185, 186], [187, 189], [190, 194], [194, 195]]}
{"doc_key": "ai-train-66", "ner": [[52, 55, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "signal", "is", "more", "ergodic", ",", "all", "sample", "paths", "exhibit", "the", "same", "time", "average", "and", "thus", "maths", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "tau", ")", "=}", "widehat", "{", "R", "}", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "tau", ")", "/", "maths", "in", "mean", "square", "error", "sense", "."], "sentence-detokenized": "If the signal is more ergodic, all sample paths exhibit the same time average and thus maths _ x ^ {n / T _ 0} (tau) =} widehat {R} _ x ^ {n / T _ 0} (tau) / maths in mean square error sense.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 21], [22, 29], [29, 30], [31, 34], [35, 41], [42, 47], [48, 55], [56, 59], [60, 64], [65, 69], [70, 77], [78, 81], [82, 86], [87, 92], [93, 94], [95, 96], [97, 98], [99, 100], [100, 101], [102, 103], [104, 105], [106, 107], [108, 109], [109, 110], [111, 112], [112, 115], [115, 116], [117, 119], [120, 127], [128, 129], [129, 130], [130, 131], [132, 133], [134, 135], [136, 137], [138, 139], [139, 140], [141, 142], [143, 144], [145, 146], [147, 148], [148, 149], [150, 151], [151, 154], [154, 155], [156, 157], [158, 163], [164, 166], [167, 171], [172, 178], [179, 184], [185, 190], [190, 191]]}
{"doc_key": "ai-train-67", "ner": [[0, 1, "task"], [3, 4, "task"], [13, 15, "algorithm"], [17, 17, "algorithm"], [20, 22, "algorithm"], [24, 24, "algorithm"], [27, 29, "algorithm"], [31, 31, "algorithm"], [34, 36, "algorithm"], [38, 38, "algorithm"], [43, 44, "misc"], [47, 49, "algorithm"], [52, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[13, 15, 43, 44, "related-to", "", false, false], [17, 17, 13, 15, "named", "", false, false], [20, 22, 43, 44, "related-to", "", false, false], [24, 24, 20, 22, "named", "", false, false], [27, 29, 43, 44, "related-to", "", false, false], [31, 31, 27, 29, "named", "", false, false], [34, 36, 43, 44, "related-to", "", false, false], [38, 38, 34, 36, "named", "", false, false], [47, 49, 52, 53, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Feature", "extraction", "and", "dimension", "reduction", "can", "be", "combined", "in", "a", "single", "step", "using", "principal", "component", "analysis", "(", "PCA", ")", ",", "linear", "discriminant", "analysis", "(", "LDA", ")", ",", "canonical", "correlation", "analysis", "(", "CCA", ")", "or", "non-negative", "matrix", "factorisation", "(", "NMF", ")", "techniques", "as", "a", "pre-processing", "step", "followed", "by", "K", "-", "NN", "clustering", "into", "feature", "vectors", "in", "reduced", "dimension", "space", "."], "sentence-detokenized": "Feature extraction and dimension reduction can be combined in a single step using principal component analysis (PCA), linear discriminant analysis (LDA), canonical correlation analysis (CCA) or non-negative matrix factorisation (NMF) techniques as a pre-processing step followed by K-NN clustering into feature vectors in reduced dimension space.", "token2charspan": [[0, 7], [8, 18], [19, 22], [23, 32], [33, 42], [43, 46], [47, 49], [50, 58], [59, 61], [62, 63], [64, 70], [71, 75], [76, 81], [82, 91], [92, 101], [102, 110], [111, 112], [112, 115], [115, 116], [116, 117], [118, 124], [125, 137], [138, 146], [147, 148], [148, 151], [151, 152], [152, 153], [154, 163], [164, 175], [176, 184], [185, 186], [186, 189], [189, 190], [191, 193], [194, 206], [207, 213], [214, 227], [228, 229], [229, 232], [232, 233], [234, 244], [245, 247], [248, 249], [250, 264], [265, 269], [270, 278], [279, 281], [282, 283], [283, 284], [284, 286], [287, 297], [298, 302], [303, 310], [311, 318], [319, 321], [322, 329], [330, 339], [340, 345], [345, 346]]}
{"doc_key": "ai-train-68", "ner": [[3, 3, "programlang"], [5, 5, "programlang"], [7, 7, "programlang"], [9, 9, "programlang"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 15, 3, 3, "related-to", "program_type_compatible_with", false, false], [15, 15, 5, 5, "related-to", "program_type_compatible_with", false, false], [15, 15, 7, 7, "related-to", "program_type_compatible_with", false, false], [15, 15, 9, 9, "related-to", "program_type_compatible_with", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Libraries", "written", "in", "Perl", ",", "Java", ",", "ActiveX", "or", ".NET", "can", "be", "called", "directly", "from", "MATLAB", ","], "sentence-detokenized": "Libraries written in Perl, Java, ActiveX or .NET can be called directly from MATLAB,", "token2charspan": [[0, 9], [10, 17], [18, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 40], [41, 43], [44, 48], [49, 52], [53, 55], [56, 62], [63, 71], [72, 76], [77, 83], [83, 84]]}
{"doc_key": "ai-train-69", "ner": [[3, 8, "task"], [10, 12, "task"], [31, 32, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 8, 10, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "task", "of", "recognising", "named", "entities", "in", "the", "text", "is", "Named", "Entity", "Recognition", ",", "while", "the", "task", "of", "determining", "the", "identity", "of", "the", "named", "entities", "mentioned", "in", "the", "text", "is", "called", "Linked", "Entity", "."], "sentence-detokenized": "The task of recognising named entities in the text is Named Entity Recognition, while the task of determining the identity of the named entities mentioned in the text is called Linked Entity.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 23], [24, 29], [30, 38], [39, 41], [42, 45], [46, 50], [51, 53], [54, 59], [60, 66], [67, 78], [78, 79], [80, 85], [86, 89], [90, 94], [95, 97], [98, 109], [110, 113], [114, 122], [123, 125], [126, 129], [130, 135], [136, 144], [145, 154], [155, 157], [158, 161], [162, 166], [167, 169], [170, 176], [177, 183], [184, 190], [190, 191]]}
{"doc_key": "ai-train-70", "ner": [[1, 1, "algorithm"], [29, 29, "programlang"], [28, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 28, 28, "part-of", "", true, false], [28, 28, 29, 29, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "sigmoid", "functions", "and", "derivatives", "used", "in", "the", "package", "were", "originally", "included", "in", "the", "package", ",", "from", "version", "0.8.0", "onwards", ",", "these", "have", "been", "released", "in", "a", "separate", "sigmoid", "R", "package", ",", "with", "the", "intention", "of", "allowing", "more", "general", "use", "."], "sentence-detokenized": "The sigmoid functions and derivatives used in the package were originally included in the package, from version 0.8.0 onwards, these have been released in a separate sigmoid R package, with the intention of allowing more general use.", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 25], [26, 37], [38, 42], [43, 45], [46, 49], [50, 57], [58, 62], [63, 73], [74, 82], [83, 85], [86, 89], [90, 97], [97, 98], [99, 103], [104, 111], [112, 117], [118, 125], [125, 126], [127, 132], [133, 137], [138, 142], [143, 151], [152, 154], [155, 156], [157, 165], [166, 173], [174, 175], [176, 183], [183, 184], [185, 189], [190, 193], [194, 203], [204, 206], [207, 215], [216, 220], [221, 228], [229, 232], [232, 233]]}
{"doc_key": "ai-train-71", "ner": [[0, 1, "programlang"], [7, 11, "organisation"], [13, 13, "organisation"], [17, 17, "location"], [19, 19, "location"], [24, 25, "researcher"], [27, 28, "researcher"], [30, 31, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 24, 25, "artifact", "", true, false], [0, 1, 27, 28, "artifact", "", true, false], [0, 1, 30, 31, "artifact", "", true, false], [13, 13, 7, 11, "named", "", false, false], [13, 13, 17, 17, "physical", "", false, false], [17, 17, 19, 19, "physical", "", false, false], [24, 25, 7, 11, "role", "", false, false], [27, 28, 7, 11, "role", "", false, false], [30, 31, 7, 11, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "logo", "was", "created", "in", "1967", "at", "Bolt", ",", "Beranek", "and", "Newman", "(", "BBN", ")", ",", "a", "Cambridge", ",", "Massachusetts", "research", "firm", ",", "by", "Wally", "Feurzeig", ",", "Cynthia", "Solomon", "and", "Seymour", "Papert", "."], "sentence-detokenized": "The logo was created in 1967 at Bolt, Beranek and Newman (BBN), a Cambridge, Massachusetts research firm, by Wally Feurzeig, Cynthia Solomon and Seymour Papert.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 20], [21, 23], [24, 28], [29, 31], [32, 36], [36, 37], [38, 45], [46, 49], [50, 56], [57, 58], [58, 61], [61, 62], [62, 63], [64, 65], [66, 75], [75, 76], [77, 90], [91, 99], [100, 104], [104, 105], [106, 108], [109, 114], [115, 123], [123, 124], [125, 132], [133, 140], [141, 144], [145, 152], [153, 159], [159, 160]]}
{"doc_key": "ai-train-72", "ner": [[0, 0, "misc"], [8, 9, "field"], [18, 19, "field"], [23, 24, "algorithm"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 9, "part-of", "", false, false], [0, 0, 18, 19, "compare", "", false, false], [23, 24, 18, 19, "part-of", "", false, false], [27, 28, 18, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Neuroevolution", "is", "commonly", "used", "as", "part", "of", "the", "reinforcement", "learning", "paradigm", ",", "and", "can", "be", "contrasted", "with", "conventional", "deep", "learning", "techniques", "that", "use", "gradual", "descent", "in", "a", "neural", "network", "with", "a", "fixed", "topology", "."], "sentence-detokenized": "Neuroevolution is commonly used as part of the reinforcement learning paradigm, and can be contrasted with conventional deep learning techniques that use gradual descent in a neural network with a fixed topology.", "token2charspan": [[0, 14], [15, 17], [18, 26], [27, 31], [32, 34], [35, 39], [40, 42], [43, 46], [47, 60], [61, 69], [70, 78], [78, 79], [80, 83], [84, 87], [88, 90], [91, 101], [102, 106], [107, 119], [120, 124], [125, 133], [134, 144], [145, 149], [150, 153], [154, 161], [162, 169], [170, 172], [173, 174], [175, 181], [182, 189], [190, 194], [195, 196], [197, 202], [203, 211], [211, 212]]}
{"doc_key": "ai-train-73", "ner": [[3, 4, "algorithm"], [56, 58, "metrics"], [60, 60, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[60, 60, 56, 58, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["If", "we", "use", "least", "squares", "to", "fit", "a", "function", "in", "the", "form", "of", "a", "hyperplane", "\u0177", "=", "a", "+", "\u03b2", "supT", "/", "sup", "x", "to", "the", "data", "(", "x", "sub", "i", "/", "sub", ",", "y", "sub", "i", "/", "sub", ")", "sub", "1", "\u2264", "i", "\u2264n", "/", "sub", ",", "we", "could", "then", "evaluate", "the", "fit", "using", "the", "mean", "square", "error", "(", "MSE", ")", "."], "sentence-detokenized": "If we use least squares to fit a function in the form of a hyperplane \u0177 = a + \u03b2 supT / sup x to the data (x sub i / sub, y sub i / sub) sub 1 \u2264 i \u2264n / sub, we could then evaluate the fit using the mean square error (MSE).", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 15], [16, 23], [24, 26], [27, 30], [31, 32], [33, 41], [42, 44], [45, 48], [49, 53], [54, 56], [57, 58], [59, 69], [70, 71], [72, 73], [74, 75], [76, 77], [78, 79], [80, 84], [85, 86], [87, 90], [91, 92], [93, 95], [96, 99], [100, 104], [105, 106], [106, 107], [108, 111], [112, 113], [114, 115], [116, 119], [119, 120], [121, 122], [123, 126], [127, 128], [129, 130], [131, 134], [134, 135], [136, 139], [140, 141], [142, 143], [144, 145], [146, 148], [149, 150], [151, 154], [154, 155], [156, 158], [159, 164], [165, 169], [170, 178], [179, 182], [183, 186], [187, 192], [193, 196], [197, 201], [202, 208], [209, 214], [215, 216], [216, 219], [219, 220], [220, 221]]}
{"doc_key": "ai-train-74", "ner": [[6, 6, "country"], [8, 8, "country"], [10, 10, "country"], [12, 12, "country"], [14, 14, "country"], [16, 16, "country"], [18, 18, "country"], [20, 20, "country"], [22, 22, "country"], [24, 24, "country"], [26, 26, "country"], [28, 28, "country"], [30, 30, "country"], [32, 32, "country"], [34, 34, "country"], [36, 37, "country"], [39, 39, "country"], [41, 41, "country"], [43, 43, "country"], [45, 45, "country"], [47, 48, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "company", "has", "international", "locations", "in", "Australia", ",", "Brazil", ",", "Canada", ",", "China", ",", "Germany", ",", "India", ",", "Italy", ",", "Japan", ",", "Korea", ",", "Lithuania", ",", "Poland", ",", "Malaysia", ",", "Philippines", ",", "Russia", ",", "Singapore", ",", "South", "Africa", ",", "Spain", ",", "Taiwan", ",", "Thailand", ",", "Turkey", "and", "the", "UK", "."], "sentence-detokenized": "The company has international locations in Australia, Brazil, Canada, China, Germany, India, Italy, Japan, Korea, Lithuania, Poland, Malaysia, Philippines, Russia, Singapore, South Africa, Spain, Taiwan, Thailand, Turkey and the UK.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 29], [30, 39], [40, 42], [43, 52], [52, 53], [54, 60], [60, 61], [62, 68], [68, 69], [70, 75], [75, 76], [77, 84], [84, 85], [86, 91], [91, 92], [93, 98], [98, 99], [100, 105], [105, 106], [107, 112], [112, 113], [114, 123], [123, 124], [125, 131], [131, 132], [133, 141], [141, 142], [143, 154], [154, 155], [156, 162], [162, 163], [164, 173], [173, 174], [175, 180], [181, 187], [187, 188], [189, 194], [194, 195], [196, 202], [202, 203], [204, 212], [212, 213], [214, 220], [221, 224], [225, 228], [229, 231], [231, 232]]}
{"doc_key": "ai-train-75", "ner": [[3, 3, "misc"], [5, 8, "field"], [13, 13, "organisation"], [16, 20, "university"], [28, 30, "organisation"], [32, 39, "university"], [43, 44, "university"], [46, 47, "university"], [50, 52, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 3, 5, 8, "topic", "", false, false], [3, 3, 13, 13, "origin", "", false, false], [3, 3, 16, 20, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "holds", "a", "degree", "in", "electrical", "and", "computer", "engineering", "(", "2000", ")", "from", "Inria", "and", "the", "University", "of", "Nice", "Sophia", "Antipolis", ",", "and", "has", "held", "permanent", "positions", "at", "Siemens", "Corporate", "Technology", ",", "\u00c9cole", "des", "ponts", "ParisTech", ",", "as", "well", "as", "visiting", "positions", "at", "Rutgers", "University", ",", "Yale", "University", "and", "the", "University", "of", "Houston", "."], "sentence-detokenized": "He holds a degree in electrical and computer engineering (2000) from Inria and the University of Nice Sophia Antipolis, and has held permanent positions at Siemens Corporate Technology, \u00c9cole des ponts ParisTech, as well as visiting positions at Rutgers University, Yale University and the University of Houston.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 17], [18, 20], [21, 31], [32, 35], [36, 44], [45, 56], [57, 58], [58, 62], [62, 63], [64, 68], [69, 74], [75, 78], [79, 82], [83, 93], [94, 96], [97, 101], [102, 108], [109, 118], [118, 119], [120, 123], [124, 127], [128, 132], [133, 142], [143, 152], [153, 155], [156, 163], [164, 173], [174, 184], [184, 185], [186, 191], [192, 195], [196, 201], [202, 211], [211, 212], [213, 215], [216, 220], [221, 223], [224, 232], [233, 242], [243, 245], [246, 253], [254, 264], [264, 265], [266, 270], [271, 281], [282, 285], [286, 289], [290, 300], [301, 303], [304, 311], [311, 312]]}
{"doc_key": "ai-train-76", "ner": [[7, 8, "researcher"], [10, 10, "researcher"], [14, 15, "product"], [18, 19, "country"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 10, 7, 8, "role", "licensing_patent_to", false, false], [10, 10, 18, 19, "physical", "", false, false], [22, 22, 10, 10, "artifact", "", false, false], [22, 22, 14, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Licensing", "the", "original", "patent", "granted", "to", "inventor", "George", "Devol", ",", "Engelberger", "developed", "the", "first", "industrial", "robot", "in", "the", "United", "States", ",", "the", "Unimate", ",", "in", "the", "1950s", "."], "sentence-detokenized": "Licensing the original patent granted to inventor George Devol, Engelberger developed the first industrial robot in the United States, the Unimate, in the 1950s.", "token2charspan": [[0, 9], [10, 13], [14, 22], [23, 29], [30, 37], [38, 40], [41, 49], [50, 56], [57, 62], [62, 63], [64, 75], [76, 85], [86, 89], [90, 95], [96, 106], [107, 112], [113, 115], [116, 119], [120, 126], [127, 133], [133, 134], [135, 138], [139, 146], [146, 147], [148, 150], [151, 154], [155, 160], [160, 161]]}
{"doc_key": "ai-train-77", "ner": [[4, 5, "task"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "input", "is", "called", "speech", "recognition", "and", "the", "output", "is", "called", "speech", "synthesis", "."], "sentence-detokenized": "The input is called speech recognition and the output is called speech synthesis.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 26], [27, 38], [39, 42], [43, 46], [47, 53], [54, 56], [57, 63], [64, 70], [71, 80], [80, 81]]}
{"doc_key": "ai-train-78", "ner": [[3, 3, "programlang"], [6, 6, "programlang"], [14, 14, "programlang"], [17, 17, "programlang"], [28, 28, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 14, 14, "named", "", false, false], [6, 6, 3, 3, "origin", "descendant_of", false, false], [6, 6, 17, 17, "general-affiliation", "", false, false], [6, 6, 28, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Descendants", "of", "the", "CLIPS", "language", "include", "Jess", "(", "the", "rules", "-", "based", "part", "of", "CLIPS", "rewritten", "into", "Java", ",", "which", "later", "grew", "in", "a", "different", "direction", ")", ",", "JESS", "was", "originally", "inspired", "by"], "sentence-detokenized": "Descendants of the CLIPS language include Jess (the rules-based part of CLIPS rewritten into Java, which later grew in a different direction), JESS was originally inspired by", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 24], [25, 33], [34, 41], [42, 46], [47, 48], [48, 51], [52, 57], [57, 58], [58, 63], [64, 68], [69, 71], [72, 77], [78, 87], [88, 92], [93, 97], [97, 98], [99, 104], [105, 110], [111, 115], [116, 118], [119, 120], [121, 130], [131, 140], [140, 141], [141, 142], [143, 147], [148, 151], [152, 162], [163, 171], [172, 174]]}
{"doc_key": "ai-train-79", "ner": [[6, 6, "product"], [11, 13, "product"], [16, 17, "organisation"], [21, 22, "product"], [41, 42, "product"], [44, 46, "product"], [62, 63, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 13, 6, 6, "type-of", "", false, false], [16, 17, 11, 13, "usage", "", false, false], [21, 22, 16, 17, "artifact", "", false, false], [41, 42, 16, 17, "origin", "", true, false], [41, 42, 62, 63, "related-to", "", true, false], [44, 46, 16, 17, "origin", "", true, false], [44, 46, 62, 63, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["It", "has", "also", "created", "flexible", "intelligent", "AGV", "applications", ",", "designing", "the", "motivity", "control", "system", "used", "by", "RMT", "Robotics", "to", "develop", "its", "ADAM", "iAGV", "(", "Self", "-", "Guided", "Vehicle", ")", ",", "used", "for", "complex", "pick", "and", "place", "operations", ",", "in", "conjunction", "with", "gantry", "systems", "and", "industrial", "robot", "arms", ",", "used", "in", "prime", "automotive", "supply", "plants", "to", "move", "products", "from", "process", "to", "process", "in", "non-linear", "layouts", "."], "sentence-detokenized": "It has also created flexible intelligent AGV applications, designing the motivity control system used by RMT Robotics to develop its ADAM iAGV (Self-Guided Vehicle), used for complex pick and place operations, in conjunction with gantry systems and industrial robot arms, used in prime automotive supply plants to move products from process to process in non-linear layouts.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 28], [29, 40], [41, 44], [45, 57], [57, 58], [59, 68], [69, 72], [73, 81], [82, 89], [90, 96], [97, 101], [102, 104], [105, 108], [109, 117], [118, 120], [121, 128], [129, 132], [133, 137], [138, 142], [143, 144], [144, 148], [148, 149], [149, 155], [156, 163], [163, 164], [164, 165], [166, 170], [171, 174], [175, 182], [183, 187], [188, 191], [192, 197], [198, 208], [208, 209], [210, 212], [213, 224], [225, 229], [230, 236], [237, 244], [245, 248], [249, 259], [260, 265], [266, 270], [270, 271], [272, 276], [277, 279], [280, 285], [286, 296], [297, 303], [304, 310], [311, 313], [314, 318], [319, 327], [328, 332], [333, 340], [341, 343], [344, 351], [352, 354], [355, 365], [366, 373], [373, 374]]}
{"doc_key": "ai-train-80", "ner": [[7, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "\u03b2", "parameters", "are", "typically", "estimated", "by", "maximum", "likelihood", "."], "sentence-detokenized": "The \u03b2 parameters are typically estimated by maximum likelihood.", "token2charspan": [[0, 3], [4, 5], [6, 16], [17, 20], [21, 30], [31, 40], [41, 43], [44, 51], [52, 62], [62, 63]]}
{"doc_key": "ai-train-81", "ner": [[0, 5, "task"], [6, 6, "metrics"], [8, 8, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 0, 5, "part-of", "", false, false], [8, 8, 0, 5, "part-of", "", false, false], [10, 10, 0, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Information", "retrieval", "metrics", ",", "such", "as", "precision", "and", "recall", "or", "DCG", ",", "are", "useful", "for", "assessing", "the", "quality", "of", "a", "recommendation", "method", "."], "sentence-detokenized": "Information retrieval metrics, such as precision and recall or DCG, are useful for assessing the quality of a recommendation method.", "token2charspan": [[0, 11], [12, 21], [22, 29], [29, 30], [31, 35], [36, 38], [39, 48], [49, 52], [53, 59], [60, 62], [63, 66], [66, 67], [68, 71], [72, 78], [79, 82], [83, 92], [93, 96], [97, 104], [105, 107], [108, 109], [110, 124], [125, 131], [131, 132]]}
{"doc_key": "ai-train-82", "ner": [[6, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "typical", "factory", "contains", "hundreds", "of", "industrial", "robots", "working", "on", "fully", "automated", "production", "lines", ",", "with", "one", "robot", "for", "every", "ten", "human", "workers", "."], "sentence-detokenized": "A typical factory contains hundreds of industrial robots working on fully automated production lines, with one robot for every ten human workers.", "token2charspan": [[0, 1], [2, 9], [10, 17], [18, 26], [27, 35], [36, 38], [39, 49], [50, 56], [57, 64], [65, 67], [68, 73], [74, 83], [84, 94], [95, 100], [100, 101], [102, 106], [107, 110], [111, 116], [117, 120], [121, 126], [127, 130], [131, 136], [137, 144], [144, 145]]}
{"doc_key": "ai-train-83", "ner": [[5, 5, "product"], [13, 14, "field"], [18, 19, "task"], [21, 22, "task"], [24, 25, "task"], [27, 28, "task"], [30, 31, "task"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[13, 14, 5, 5, "usage", "", false, true], [18, 19, 13, 14, "part-of", "", false, false], [21, 22, 13, 14, "part-of", "", false, false], [24, 25, 13, 14, "part-of", "", false, false], [27, 28, 13, 14, "part-of", "", false, false], [30, 31, 13, 14, "part-of", "", false, false], [33, 34, 13, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["During", "the", "last", "decade", ",", "PCNNs", "have", "been", "used", "in", "a", "variety", "of", "image", "processing", "applications", "including", ":", "image", "segmentation", ",", "feature", "generation", ",", "face", "extraction", ",", "motion", "detection", ",", "region", "growing", "and", "noise", "reduction", "."], "sentence-detokenized": "During the last decade, PCNNs have been used in a variety of image processing applications including: image segmentation, feature generation, face extraction, motion detection, region growing and noise reduction.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [22, 23], [24, 29], [30, 34], [35, 39], [40, 44], [45, 47], [48, 49], [50, 57], [58, 60], [61, 66], [67, 77], [78, 90], [91, 100], [100, 101], [102, 107], [108, 120], [120, 121], [122, 129], [130, 140], [140, 141], [142, 146], [147, 157], [157, 158], [159, 165], [166, 175], [175, 176], [177, 183], [184, 191], [192, 195], [196, 201], [202, 211], [211, 212]]}
{"doc_key": "ai-train-84", "ner": [[0, 1, "researcher"], [16, 18, "field"], [21, 23, "misc"], [26, 32, "conference"], [34, 34, "conference"], [39, 41, "misc"], [44, 50, "conference"], [51, 52, "conference"], [54, 58, "conference"], [60, 60, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 1, 16, 18, "related-to", "contributes_to", false, false], [0, 1, 21, 23, "win-defeat", "", false, false], [0, 1, 39, 41, "win-defeat", "", false, false], [21, 23, 26, 32, "temporal", "", false, false], [34, 34, 26, 32, "named", "", false, false], [39, 41, 44, 50, "temporal", "", false, false], [39, 41, 54, 58, "temporal", "", false, false], [51, 52, 44, 50, "named", "", false, false], [60, 60, 54, 58, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Xu", "has", "published", "more", "than", "50", "papers", "in", "international", "conferences", "and", "journals", "in", "the", "field", "of", "computer", "vision", "and", "won", "the", "Best", "Paper", "Award", "at", "the", "international", "conference", "on", "Non-Photorealistic", "Rendering", "and", "Animation", "(", "NPAR", ")", "2012", "and", "the", "Best", "Reviewer", "Award", "at", "the", "international", "conferences", "Asian", "Conference", "on", "Computer", "Vision", "ACCV", "2012", "and", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "2015", "."], "sentence-detokenized": "Xu has published more than 50 papers in international conferences and journals in the field of computer vision and won the Best Paper Award at the international conference on Non-Photorealistic Rendering and Animation (NPAR) 2012 and the Best Reviewer Award at the international conferences Asian Conference on Computer Vision ACCV 2012 and International Conference on Computer Vision (ICCV) 2015.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 21], [22, 26], [27, 29], [30, 36], [37, 39], [40, 53], [54, 65], [66, 69], [70, 78], [79, 81], [82, 85], [86, 91], [92, 94], [95, 103], [104, 110], [111, 114], [115, 118], [119, 122], [123, 127], [128, 133], [134, 139], [140, 142], [143, 146], [147, 160], [161, 171], [172, 174], [175, 193], [194, 203], [204, 207], [208, 217], [218, 219], [219, 223], [223, 224], [225, 229], [230, 233], [234, 237], [238, 242], [243, 251], [252, 257], [258, 260], [261, 264], [265, 278], [279, 290], [291, 296], [297, 307], [308, 310], [311, 319], [320, 326], [327, 331], [332, 336], [337, 340], [341, 354], [355, 365], [366, 368], [369, 377], [378, 384], [385, 386], [386, 390], [390, 391], [392, 396], [396, 397]]}
{"doc_key": "ai-train-85", "ner": [[0, 0, "programlang"], [2, 3, "field"], [5, 6, "field"], [9, 10, "misc"], [13, 14, "researcher"], [16, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 2, 3, "part-of", "", false, false], [0, 0, 5, 6, "part-of", "", false, false], [0, 0, 9, 10, "type-of", "", false, false], [16, 18, 0, 0, "usage", "", false, false], [16, 18, 13, 14, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["CycL", "in", "computer", "science", "and", "artificial", "intelligence", "is", "an", "ontology", "language", "used", "by", "Doug", "Lenat", "'s", "artificial", "Cyc", "project", "."], "sentence-detokenized": "CycL in computer science and artificial intelligence is an ontology language used by Doug Lenat's artificial Cyc project.", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 24], [25, 28], [29, 39], [40, 52], [53, 55], [56, 58], [59, 67], [68, 76], [77, 81], [82, 84], [85, 89], [90, 95], [95, 97], [98, 108], [109, 112], [113, 120], [120, 121]]}
{"doc_key": "ai-train-86", "ner": [[2, 3, "task"], [6, 8, "metrics"], [14, 17, "metrics"], [19, 26, "metrics"], [36, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 2, 3, "part-of", "", false, false], [14, 17, 6, 8, "named", "", false, false], [19, 26, 6, 8, "named", "", false, false], [36, 38, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Also", "in", "regression", "analysis", ",", "the", "mean", "square", "error", ",", "often", "referred", "to", "as", "mean", "square", "prediction", "error", "or", "mean", "square", "out", "-", "of", "-", "sample", "error", ",", "can", "refer", "to", "the", "mean", "value", "of", "the", "squared", "deviations", "of", "predictions", "from", "TRUE", "values", ",", "over", "an", "out", "-", "of", "-", "sample", "test", "space", ",", "generated", "by", "a", "model", "estimated", "over", "a", "given", "sample", "space", "."], "sentence-detokenized": "Also in regression analysis, the mean square error, often referred to as mean square prediction error or mean square out-of-sample error, can refer to the mean value of the squared deviations of predictions from TRUE values, over an out-of-sample test space, generated by a model estimated over a given sample space.", "token2charspan": [[0, 4], [5, 7], [8, 18], [19, 27], [27, 28], [29, 32], [33, 37], [38, 44], [45, 50], [50, 51], [52, 57], [58, 66], [67, 69], [70, 72], [73, 77], [78, 84], [85, 95], [96, 101], [102, 104], [105, 109], [110, 116], [117, 120], [120, 121], [121, 123], [123, 124], [124, 130], [131, 136], [136, 137], [138, 141], [142, 147], [148, 150], [151, 154], [155, 159], [160, 165], [166, 168], [169, 172], [173, 180], [181, 191], [192, 194], [195, 206], [207, 211], [212, 216], [217, 223], [223, 224], [225, 229], [230, 232], [233, 236], [236, 237], [237, 239], [239, 240], [240, 246], [247, 251], [252, 257], [257, 258], [259, 268], [269, 271], [272, 273], [274, 279], [280, 289], [290, 294], [295, 296], [297, 302], [303, 309], [310, 315], [315, 316]]}
{"doc_key": "ai-train-87", "ner": [[6, 8, "algorithm"], [10, 11, "algorithm"], [19, 22, "algorithm"], [34, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 8, 10, 11, "compare", "", false, false], [6, 8, 19, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "for", "the", "results", ",", "the", "C", "-", "HOG", "and", "R-", "HOG", "block", "descriptors", "perform", "comparably", ",", "with", "the", "C", "-", "HOG", "descriptors", "maintaining", "a", "slight", "advantage", "in", "the", "detection", "failure", "rate", "with", "fixed", "positive", "FALSE", "rates", "in", "both", "datasets", "."], "sentence-detokenized": "As for the results, the C-HOG and R-HOG block descriptors perform comparably, with the C-HOG descriptors maintaining a slight advantage in the detection failure rate with fixed positive FALSE rates in both datasets.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 18], [18, 19], [20, 23], [24, 25], [25, 26], [26, 29], [30, 33], [34, 36], [36, 39], [40, 45], [46, 57], [58, 65], [66, 76], [76, 77], [78, 82], [83, 86], [87, 88], [88, 89], [89, 92], [93, 104], [105, 116], [117, 118], [119, 125], [126, 135], [136, 138], [139, 142], [143, 152], [153, 160], [161, 165], [166, 170], [171, 176], [177, 185], [186, 191], [192, 197], [198, 200], [201, 205], [206, 214], [214, 215]]}
{"doc_key": "ai-train-88", "ner": [[4, 6, "algorithm"], [8, 8, "misc"], [10, 12, "algorithm"], [14, 15, "algorithm"], [18, 19, "algorithm"], [22, 24, "algorithm"], [26, 28, "algorithm"], [30, 31, "misc"], [34, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[4, 6, 8, 8, "usage", "", false, false], [10, 12, 30, 31, "usage", "", false, false], [14, 15, 30, 31, "usage", "", false, false], [18, 19, 30, 31, "usage", "", false, false], [22, 24, 30, 31, "usage", "", false, false], [26, 28, 30, 31, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Popular", "recognition", "algorithms", "include", "principal", "component", "analysis", "using", "eigenfaces", ",", "linear", "discriminant", "analysis", ",", "elastic", "matching", "using", "the", "Fisherface", "algorithm", ",", "the", "hidden", "Markov", "model", ",", "multilinear", "subspace", "learning", "using", "tensor", "representation", ",", "and", "dynamic", "motivated", "neuronal", "linkage", "matching", "."], "sentence-detokenized": "Popular recognition algorithms include principal component analysis using eigenfaces, linear discriminant analysis, elastic matching using the Fisherface algorithm, the hidden Markov model, multilinear subspace learning using tensor representation, and dynamic motivated neuronal linkage matching.", "token2charspan": [[0, 7], [8, 19], [20, 30], [31, 38], [39, 48], [49, 58], [59, 67], [68, 73], [74, 84], [84, 85], [86, 92], [93, 105], [106, 114], [114, 115], [116, 123], [124, 132], [133, 138], [139, 142], [143, 153], [154, 163], [163, 164], [165, 168], [169, 175], [176, 182], [183, 188], [188, 189], [190, 201], [202, 210], [211, 219], [220, 225], [226, 232], [233, 247], [247, 248], [249, 252], [253, 260], [261, 270], [271, 279], [280, 287], [288, 296], [296, 297]]}
{"doc_key": "ai-train-89", "ner": [[3, 7, "misc"], [15, 17, "location"], [34, 36, "location"], [48, 48, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 17, 3, 7, "temporal", "", false, false], [34, 36, 3, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Starting", "with", "the", "2019", "Toronto", "International", "Film", "Festival", ",", "films", "can", "be", "screened", "at", "the", "Scotiabank", "Theatre", "Toronto", "-", "one", "of", "the", "festival", "'s", "main", "venues", "-", "and", "shown", "elsewhere", "(", "such", "as", "the", "TIFF", "Bell", "Lightbox", "and", "other", "local", "cinemas", ")", "if", "distributed", "by", "a", "service", "like", "Netflix", "."], "sentence-detokenized": "Starting with the 2019 Toronto International Film Festival, films can be screened at the Scotiabank Theatre Toronto - one of the festival's main venues - and shown elsewhere (such as the TIFF Bell Lightbox and other local cinemas) if distributed by a service like Netflix.", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 22], [23, 30], [31, 44], [45, 49], [50, 58], [58, 59], [60, 65], [66, 69], [70, 72], [73, 81], [82, 84], [85, 88], [89, 99], [100, 107], [108, 115], [116, 117], [118, 121], [122, 124], [125, 128], [129, 137], [137, 139], [140, 144], [145, 151], [152, 153], [154, 157], [158, 163], [164, 173], [174, 175], [175, 179], [180, 182], [183, 186], [187, 191], [192, 196], [197, 205], [206, 209], [210, 215], [216, 221], [222, 229], [229, 230], [231, 233], [234, 245], [246, 248], [249, 250], [251, 258], [259, 263], [264, 271], [271, 272]]}
{"doc_key": "ai-train-90", "ner": [[0, 0, "organisation"], [2, 3, "researcher"], [5, 6, "organisation"], [12, 13, "researcher"], [23, 27, "product"], [38, 38, "researcher"], [39, 49, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 6, "related-to", "purchases", false, false], [2, 3, 12, 13, "named", "same", false, false], [2, 3, 38, 38, "named", "same", false, false], [5, 6, 2, 3, "origin", "founded_by", false, false], [23, 27, 0, 0, "artifact", "", false, false], [39, 49, 38, 38, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "acquired", "Victor", "Scheinman", "'s", "Vicarm", "Inc.", "in", "1977", ",", "and", "with", "Scheinman", "'s", "help", ",", "the", "company", "created", "and", "began", "producing", "the", "Programmable", "Universal", "Machine", "for", "Assembly", ",", "a", "new", "model", "of", "robotic", "arm", ",", "and", "using", "Scheinman", "'s", "state", "-", "of", "-", "the", "-", "art", "VAL", "programming", "language", "."], "sentence-detokenized": "Unimation acquired Victor Scheinman's Vicarm Inc. in 1977, and with Scheinman's help, the company created and began producing the Programmable Universal Machine for Assembly, a new model of robotic arm, and using Scheinman's state-of-the-art VAL programming language.", "token2charspan": [[0, 9], [10, 18], [19, 25], [26, 35], [35, 37], [38, 44], [45, 49], [50, 52], [53, 57], [57, 58], [59, 62], [63, 67], [68, 77], [77, 79], [80, 84], [84, 85], [86, 89], [90, 97], [98, 105], [106, 109], [110, 115], [116, 125], [126, 129], [130, 142], [143, 152], [153, 160], [161, 164], [165, 173], [173, 174], [175, 176], [177, 180], [181, 186], [187, 189], [190, 197], [198, 201], [201, 202], [203, 206], [207, 212], [213, 222], [222, 224], [225, 230], [230, 231], [231, 233], [233, 234], [234, 237], [237, 238], [238, 241], [242, 245], [246, 257], [258, 266], [266, 267]]}
{"doc_key": "ai-train-91", "ner": [[0, 1, "product"], [6, 6, "programlang"], [10, 13, "algorithm"], [14, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 6, "general-affiliation", "", false, false], [0, 1, 10, 13, "origin", "implementation_of", false, false], [0, 1, 14, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["J", "48", "is", "an", "open", "source", "Java", "implementation", "of", "the", "C4.5", "algorithm", "in", "the", "Weka", "data", "mining", "tool", "."], "sentence-detokenized": "J48 is an open source Java implementation of the C4.5 algorithm in the Weka data mining tool.", "token2charspan": [[0, 1], [1, 3], [4, 6], [7, 9], [10, 14], [15, 21], [22, 26], [27, 41], [42, 44], [45, 48], [49, 53], [54, 63], [64, 66], [67, 70], [71, 75], [76, 80], [81, 87], [88, 92], [92, 93]]}
{"doc_key": "ai-train-92", "ner": [[1, 1, "metrics"], [12, 13, "product"], [19, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 12, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SSIM", "2004", "paper", "was", "cited", "more", "than", "20,000", "times", "according", "to", "Google", "Scholar", ",", "It", "also", "received", "the", "IEEE", "Signal", "Processing", "Society", "Sustained", "Impact", "Award", "for", "2016", ",", "indicative", "of", "a", "paper", "having", "an", "exceptionally", "high", "impact", "for", "at", "least", "10", "years", "after", "its", "publication", "."], "sentence-detokenized": "The SSIM 2004 paper was cited more than 20,000 times according to Google Scholar, It also received the IEEE Signal Processing Society Sustained Impact Award for 2016, indicative of a paper having an exceptionally high impact for at least 10 years after its publication.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 19], [20, 23], [24, 29], [30, 34], [35, 39], [40, 46], [47, 52], [53, 62], [63, 65], [66, 72], [73, 80], [80, 81], [82, 84], [85, 89], [90, 98], [99, 102], [103, 107], [108, 114], [115, 125], [126, 133], [134, 143], [144, 150], [151, 156], [157, 160], [161, 165], [165, 166], [167, 177], [178, 180], [181, 182], [183, 188], [189, 195], [196, 198], [199, 212], [213, 217], [218, 224], [225, 228], [229, 231], [232, 237], [238, 240], [241, 246], [247, 252], [253, 256], [257, 268], [268, 269]]}
{"doc_key": "ai-train-93", "ner": [[0, 1, "task"], [17, 18, "product"], [33, 35, "product"], [38, 38, "organisation"], [39, 39, "product"], [44, 44, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 38, 38, "artifact", "", false, false], [17, 18, 0, 1, "related-to", "performs", false, false], [17, 18, 33, 35, "part-of", "", false, false], [38, 38, 44, 44, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Speech", "synthesis", "is", "about", "to", "be", "completely", "indistinguishable", "from", "an", "actual", "human", "voice", "with", "the", "introduction", "of", "Adobe", "Voco", "voice", "editing", "and", "generation", "software", ",", "a", "prototype", "slated", "to", "be", "part", "of", "the", "Adobe", "Creative", "Suite", ",", "and", "DeepMind", "WaveNet", ",", "a", "prototype", "from", "Google", "."], "sentence-detokenized": "Speech synthesis is about to be completely indistinguishable from an actual human voice with the introduction of Adobe Voco voice editing and generation software, a prototype slated to be part of the Adobe Creative Suite, and DeepMind WaveNet, a prototype from Google.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 25], [26, 28], [29, 31], [32, 42], [43, 60], [61, 65], [66, 68], [69, 75], [76, 81], [82, 87], [88, 92], [93, 96], [97, 109], [110, 112], [113, 118], [119, 123], [124, 129], [130, 137], [138, 141], [142, 152], [153, 161], [161, 162], [163, 164], [165, 174], [175, 181], [182, 184], [185, 187], [188, 192], [193, 195], [196, 199], [200, 205], [206, 214], [215, 220], [220, 221], [222, 225], [226, 234], [235, 242], [242, 243], [244, 245], [246, 255], [256, 260], [261, 267], [267, 268]]}
{"doc_key": "ai-train-94", "ner": [[0, 0, "researcher"], [7, 9, "organisation"], [15, 20, "organisation"], [26, 26, "conference"], [33, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 7, 9, "role", "", false, false], [0, 0, 15, 20, "role", "", false, false], [0, 0, 26, 26, "role", "", false, false], [0, 0, 33, 37, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Poggio", "is", "an", "honorary", "member", "of", "the", "Neuroscience", "Research", "Program", ",", "a", "Fellow", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "a", "founding", "member", "of", "AAAI", "and", "a", "founding", "member", "of", "the", "McGovern", "Institute", "for", "Brain", "Research", "."], "sentence-detokenized": "Poggio is an honorary member of the Neuroscience Research Program, a Fellow of the American Academy of Arts and Sciences and a founding member of AAAI and a founding member of the McGovern Institute for Brain Research.", "token2charspan": [[0, 6], [7, 9], [10, 12], [13, 21], [22, 28], [29, 31], [32, 35], [36, 48], [49, 57], [58, 65], [65, 66], [67, 68], [69, 75], [76, 78], [79, 82], [83, 91], [92, 99], [100, 102], [103, 107], [108, 111], [112, 120], [121, 124], [125, 126], [127, 135], [136, 142], [143, 145], [146, 150], [151, 154], [155, 156], [157, 165], [166, 172], [173, 175], [176, 179], [180, 188], [189, 198], [199, 202], [203, 208], [209, 217], [217, 218]]}
{"doc_key": "ai-train-95", "ner": [[9, 9, "task"], [8, 11, "task"], [15, 16, "task"], [23, 25, "misc"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 15, 16, "cause-effect", "", false, false], [8, 11, 15, 16, "cause-effect", "", false, false], [24, 25, 15, 16, "topic", "", false, false], [24, 25, 23, 25, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "the", "1990s", ",", "encouraged", "by", "successes", "in", "speech", "recognition", "and", "synthesis", ",", "research", "on", "speech", "translation", "began", "with", "the", "development", "of", "the", "German", "Verbmobil", "project", "."], "sentence-detokenized": "During the 1990s, encouraged by successes in speech recognition and synthesis, research on speech translation began with the development of the German Verbmobil project.", "token2charspan": [[0, 6], [7, 10], [11, 16], [16, 17], [18, 28], [29, 31], [32, 41], [42, 44], [45, 51], [52, 63], [64, 67], [68, 77], [77, 78], [79, 87], [88, 90], [91, 97], [98, 109], [110, 115], [116, 120], [121, 124], [125, 136], [137, 139], [140, 143], [144, 150], [151, 160], [161, 168], [168, 169]]}
{"doc_key": "ai-train-96", "ner": [[3, 4, "researcher"], [8, 9, "researcher"], [11, 12, "researcher"], [15, 16, "algorithm"], [20, 21, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 8, 9, "role", "", false, false], [15, 16, 3, 4, "origin", "", false, false], [15, 16, 8, 9, "origin", "", false, false], [15, 16, 11, 12, "origin", "", false, false], [15, 16, 25, 25, "part-of", "", false, false], [20, 21, 15, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "1999", ",", "Felix", "Gers", "and", "his", "adviser", "J\u00fcrgen", "Schmidhuber", "and", "Fred", "Cummins", "introduced", "the", "oblivion", "gate", "(", "also", "called", "keep", "gate", ")", "into", "the", "LSTM", "architecture", ","], "sentence-detokenized": "In 1999, Felix Gers and his adviser J\u00fcrgen Schmidhuber and Fred Cummins introduced the oblivion gate (also called keep gate) into the LSTM architecture,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 19], [20, 23], [24, 27], [28, 35], [36, 42], [43, 54], [55, 58], [59, 63], [64, 71], [72, 82], [83, 86], [87, 95], [96, 100], [101, 102], [102, 106], [107, 113], [114, 118], [119, 123], [123, 124], [125, 129], [130, 133], [134, 138], [139, 151], [151, 152]]}
{"doc_key": "ai-train-97", "ner": [[1, 3, "field"], [5, 6, "field"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 11, 1, 3, "part-of", "", false, false], [9, 11, 5, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "digital", "signal", "processing", "and", "information", "theory", ",", "the", "normalised", "sinc", "function", "is", "commonly", "defined", "by"], "sentence-detokenized": "In digital signal processing and information theory, the normalised sinc function is commonly defined by", "token2charspan": [[0, 2], [3, 10], [11, 17], [18, 28], [29, 32], [33, 44], [45, 51], [51, 52], [53, 56], [57, 67], [68, 72], [73, 81], [82, 84], [85, 93], [94, 101], [102, 104]]}
{"doc_key": "ai-train-98", "ner": [[2, 3, "field"], [9, 10, "researcher"], [18, 21, "conference"], [24, 28, "organisation"], [30, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 10, "origin", "coined_term", false, false], [9, 10, 18, 21, "role", "", false, false], [9, 10, 24, 28, "role", "", false, false], [30, 30, 24, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "computational", "linguistics", "itself", "was", "first", "coined", "by", "David", "Hays", ",", "a", "founding", "member", "of", "both", "the", "Association", "for", "Computational", "Linguistics", "and", "the", "International", "Committee", "for", "Computational", "Linguistics", "(", "ICCL", ")", "."], "sentence-detokenized": "The term computational linguistics itself was first coined by David Hays, a founding member of both the Association for Computational Linguistics and the International Committee for Computational Linguistics (ICCL).", "token2charspan": [[0, 3], [4, 8], [9, 22], [23, 34], [35, 41], [42, 45], [46, 51], [52, 58], [59, 61], [62, 67], [68, 72], [72, 73], [74, 75], [76, 84], [85, 91], [92, 94], [95, 99], [100, 103], [104, 115], [116, 119], [120, 133], [134, 145], [146, 149], [150, 153], [154, 167], [168, 177], [178, 181], [182, 195], [196, 207], [208, 209], [209, 213], [213, 214], [214, 215]]}
{"doc_key": "ai-train-99", "ner": [[8, 11, "misc"], [16, 16, "misc"], [33, 35, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[37, 37, 33, 35, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["59", ",", "pp.", "2547-2553", ",", "Oct.", "2011", "In", "one", "-dimensional", "polynomial", "memory", "(", "or", "memoryless", ")", "DPD", ",", "in", "order", "to", "solve", "for", "the", "polynomial", "coefficients", "of", "the", "digital", "predistortioner", "and", "minimize", "the", "mean", "square", "error", "(", "MSE", ")", ",", "the", "distorted", "output", "of", "the", "nonlinear", "system", "must", "be", "oversampled", "at", "a", "rate", "that", "allows", "the", "nonlinear", "products", "of", "the", "order", "of", "the", "digital", "predistortioner", "to", "be", "captured", "."], "sentence-detokenized": "59, pp. 2547-2553, Oct. 2011 In one-dimensional polynomial memory (or memoryless) DPD, in order to solve for the polynomial coefficients of the digital predistortioner and minimize the mean square error (MSE), the distorted output of the nonlinear system must be oversampled at a rate that allows the nonlinear products of the order of the digital predistortioner to be captured.", "token2charspan": [[0, 2], [2, 3], [4, 7], [8, 17], [17, 18], [19, 23], [24, 28], [29, 31], [32, 35], [35, 47], [48, 58], [59, 65], [66, 67], [67, 69], [70, 80], [80, 81], [82, 85], [85, 86], [87, 89], [90, 95], [96, 98], [99, 104], [105, 108], [109, 112], [113, 123], [124, 136], [137, 139], [140, 143], [144, 151], [152, 167], [168, 171], [172, 180], [181, 184], [185, 189], [190, 196], [197, 202], [203, 204], [204, 207], [207, 208], [208, 209], [210, 213], [214, 223], [224, 230], [231, 233], [234, 237], [238, 247], [248, 254], [255, 259], [260, 262], [263, 274], [275, 277], [278, 279], [280, 284], [285, 289], [290, 296], [297, 300], [301, 310], [311, 319], [320, 322], [323, 326], [327, 332], [333, 335], [336, 339], [340, 347], [348, 363], [364, 366], [367, 369], [370, 378], [378, 379]]}
{"doc_key": "ai-train-100", "ner": [[0, 1, "researcher"], [12, 13, "location"], [15, 16, "country"], [22, 22, "country"], [37, 43, "organisation"], [46, 49, "organisation"], [51, 51, "location"], [58, 59, "organisation"]], "ner_mapping_to_source": [0, 2, 3, 5, 6, 7, 8, 9], "relations": [[0, 1, 46, 49, "physical", "", false, false], [0, 1, 58, 59, "role", "", false, false], [12, 13, 15, 16, "physical", "", false, false], [37, 43, 46, 49, "part-of", "", false, false], [46, 49, 51, 51, "physical", "", false, false], [58, 59, 37, 43, "part-of", "", false, false]], "relations_mapping_to_source": [1, 2, 4, 5, 6, 7], "sentence": ["Boris", "Katz", ",", "(", "born", "October", "5", ",", "1947", ",", "Chi\u0219in\u0103u", ",", "Moldavian", "SSR", ",", "Soviet", "Union", ",", "(", "now", "Chi\u0219in\u0103u", ",", "Moldova", ")", ")", "is", "the", "American", "principal", "research", "scientist", "(", "computer", "scientist", ")", "at", "the", "MIT", "Computer", "Science", "and", "Artificial", "Intelligence", "Laboratory", "at", "the", "Massachusetts", "Institute", "of", "Technology", "in", "Cambridge", "and", "head", "of", "the", "Laboratory", "'s", "InfoLab", "Group", "."], "sentence-detokenized": "Boris Katz, (born October 5, 1947, Chi\u0219in\u0103u, Moldavian SSR, Soviet Union, (now Chi\u0219in\u0103u, Moldova)) is the American principal research scientist (computer scientist) at the MIT Computer Science and Artificial Intelligence Laboratory at the Massachusetts Institute of Technology in Cambridge and head of the Laboratory's InfoLab Group.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 13], [13, 17], [18, 25], [26, 27], [27, 28], [29, 33], [33, 34], [35, 43], [43, 44], [45, 54], [55, 58], [58, 59], [60, 66], [67, 72], [72, 73], [74, 75], [75, 78], [79, 87], [87, 88], [89, 96], [96, 97], [97, 98], [99, 101], [102, 105], [106, 114], [115, 124], [125, 133], [134, 143], [144, 145], [145, 153], [154, 163], [163, 164], [165, 167], [168, 171], [172, 175], [176, 184], [185, 192], [193, 196], [197, 207], [208, 220], [221, 231], [232, 234], [235, 238], [239, 252], [253, 262], [263, 265], [266, 276], [277, 279], [280, 289], [290, 293], [294, 298], [299, 301], [302, 305], [306, 316], [316, 318], [319, 326], [327, 332], [332, 333]]}
