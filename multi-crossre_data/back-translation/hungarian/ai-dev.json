{"doc_key": "ai-dev-1", "ner": [[2, 3, "metrics"], [7, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 2, 3, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Here", ",", "accuracy", "is", "measured", "by", "the", "error", "rate", ",", "which", "is", "defined", "as", ":"], "sentence-detokenized": "Here, accuracy is measured by the error rate, which is defined as:", "token2charspan": [[0, 4], [4, 5], [6, 14], [15, 17], [18, 26], [27, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 51], [52, 54], [55, 62], [63, 65], [65, 66]]}
{"doc_key": "ai-dev-2", "ner": [[4, 5, "algorithm"], [11, 12, "misc"], [16, 18, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 11, 12, "type-of", "", false, false], [4, 5, 16, 18, "related-to", "", false, false], [4, 5, 19, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "this", "respect", ",", "SVM", "is", "closely", "related", "to", "other", "basic", "classification", "algorithms", ",", "such", "as", "regularised", "least", "squares", "logistic", "regression", "."], "sentence-detokenized": "In this respect, SVM is closely related to other basic classification algorithms, such as regularised least squares logistic regression.", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 20], [21, 23], [24, 31], [32, 39], [40, 42], [43, 48], [49, 54], [55, 69], [70, 80], [80, 81], [82, 86], [87, 89], [90, 101], [102, 107], [108, 115], [116, 124], [125, 135], [135, 136]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [4, 5, "person"], [14, 16, "person"], [17, 18, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 0, 1, "named", "actor_plays_character", false, false], [4, 5, 0, 1, "origin", "actor_plays_character", false, false], [17, 18, 14, 16, "named", "actor_plays_character", false, false], [17, 18, 14, 16, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "will", "play", "Leon", "Kowalski", ",", "the", "fighting", "and", "working", "replicant", ",", "and", "Joanna", "Cassidy", "will", "play", "Zhora", ",", "the", "assassin", "replicant", "."], "sentence-detokenized": "Brion James will play Leon Kowalski, the fighting and working replicant, and Joanna Cassidy will play Zhora, the assassin replicant.", "token2charspan": [[0, 5], [6, 11], [12, 16], [17, 21], [22, 26], [27, 35], [35, 36], [37, 40], [41, 49], [50, 53], [54, 61], [62, 71], [71, 72], [73, 76], [77, 83], [84, 91], [92, 96], [97, 101], [102, 107], [107, 108], [109, 112], [113, 121], [122, 131], [131, 132]]}
{"doc_key": "ai-dev-4", "ner": [[17, 17, "product"], [16, 21, "product"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 15, 15, "physical", "", false, false], [16, 21, 17, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "image", "scanned", ",", "stored", "and", "recreated", "in", "digital", "pixels", "was", "displayed", "on", "the", "NIST", "Standardization", "East", "Automatic", "Computer", "(", "SEAC", ")", "."], "sentence-detokenized": "The first image scanned, stored and recreated in digital pixels was displayed on the NIST Standardization East Automatic Computer (SEAC).", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [23, 24], [25, 31], [32, 35], [36, 45], [46, 48], [49, 56], [57, 63], [64, 67], [68, 77], [78, 80], [81, 84], [85, 89], [90, 105], [106, 110], [111, 120], [121, 129], [130, 131], [131, 135], [135, 136], [136, 137]]}
{"doc_key": "ai-dev-5", "ner": [[0, 7, "task"], [21, 22, "task"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 7, 21, 22, "part-of", "", false, false], [0, 7, 24, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Segmenting", "the", "text", "into", "topics", "or", "discourse", "turns", "can", "be", "useful", "in", "certain", "natural", "processing", "tasks", ":", "it", "can", "significantly", "improve", "information", "retrieval", "or", "speech", "recognition", "(", "by", "indexing", "/", "recognizing", "documents", "more", "accurately", "or", "by", "returning", "a", "specific", "part", "of", "the", "document", "corresponding", "to", "the", "query", "as", "a", "result", ")", "."], "sentence-detokenized": "Segmenting the text into topics or discourse turns can be useful in certain natural processing tasks: it can significantly improve information retrieval or speech recognition (by indexing/recognizing documents more accurately or by returning a specific part of the document corresponding to the query as a result).", "token2charspan": [[0, 10], [11, 14], [15, 19], [20, 24], [25, 31], [32, 34], [35, 44], [45, 50], [51, 54], [55, 57], [58, 64], [65, 67], [68, 75], [76, 83], [84, 94], [95, 100], [100, 101], [102, 104], [105, 108], [109, 122], [123, 130], [131, 142], [143, 152], [153, 155], [156, 162], [163, 174], [175, 176], [176, 178], [179, 187], [187, 188], [188, 199], [200, 209], [210, 214], [215, 225], [226, 228], [229, 231], [232, 241], [242, 243], [244, 252], [253, 257], [258, 260], [261, 264], [265, 273], [274, 287], [288, 290], [291, 294], [295, 300], [301, 303], [304, 305], [306, 312], [312, 313], [313, 314]]}
{"doc_key": "ai-dev-6", "ner": [[6, 8, "university"], [22, 25, "conference"], [15, 17, "university"], [26, 27, "researcher"], [29, 30, "researcher"], [32, 33, "researcher"], [35, 36, "researcher"], [38, 39, "researcher"], [41, 42, "researcher"], [44, 46, "researcher"], [48, 50, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[22, 25, 15, 17, "physical", "", false, false], [26, 27, 22, 25, "physical", "", false, false], [26, 27, 22, 25, "role", "", false, false], [26, 27, 22, 25, "temporal", "", false, false], [29, 30, 22, 25, "physical", "", false, false], [29, 30, 22, 25, "role", "", false, false], [29, 30, 22, 25, "temporal", "", false, false], [32, 33, 22, 25, "physical", "", false, false], [32, 33, 22, 25, "role", "", false, false], [32, 33, 22, 25, "temporal", "", false, false], [35, 36, 22, 25, "physical", "", false, false], [35, 36, 22, 25, "role", "", false, false], [35, 36, 22, 25, "temporal", "", false, false], [38, 39, 22, 25, "physical", "", false, false], [38, 39, 22, 25, "role", "", false, false], [38, 39, 22, 25, "temporal", "", false, false], [41, 42, 22, 25, "physical", "", false, false], [41, 42, 22, 25, "role", "", false, false], [41, 42, 22, 25, "temporal", "", false, false], [44, 46, 22, 25, "physical", "", false, false], [44, 46, 22, 25, "role", "", false, false], [44, 46, 22, 25, "temporal", "", false, false], [48, 50, 22, 25, "physical", "", false, false], [48, 50, 22, 25, "role", "", false, false], [48, 50, 22, 25, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["He", "organized", "such", "a", "symposium", "at", "Indiana", "University", "in", "1999", "and", "a", "larger", "symposium", "at", "Stanford", "University", "in", "April", "2000", ",", "entitled", "Spiritual", "Robots", ",", "with", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", "and", "John", "Koza", "as", "moderators", "."], "sentence-detokenized": "He organized such a symposium at Indiana University in 1999 and a larger symposium at Stanford University in April 2000, entitled Spiritual Robots, with Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland and John Koza as moderators.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 19], [20, 29], [30, 32], [33, 40], [41, 51], [52, 54], [55, 59], [60, 63], [64, 65], [66, 72], [73, 82], [83, 85], [86, 94], [95, 105], [106, 108], [109, 114], [115, 119], [119, 120], [121, 129], [130, 139], [140, 146], [146, 147], [148, 152], [153, 156], [157, 165], [165, 166], [167, 171], [172, 179], [179, 180], [181, 186], [187, 192], [192, 193], [194, 199], [200, 206], [206, 207], [208, 212], [213, 216], [216, 217], [218, 223], [224, 229], [229, 230], [231, 235], [236, 241], [242, 249], [250, 253], [254, 258], [259, 263], [264, 266], [267, 277], [277, 278]]}
{"doc_key": "ai-dev-7", "ner": [[5, 8, "metrics"], [10, 10, "metrics"], [13, 15, "metrics"], [17, 18, "metrics"], [23, 25, "metrics"], [45, 45, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 8, 23, 25, "named", "", false, false], [10, 10, 5, 8, "named", "", false, false], [13, 15, 45, 45, "named", "", false, false], [17, 18, 13, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["To", "calculate", "the", "score", ",", "the", "accuracy", "of", "the", "test", "p", "and", "the", "recall", "of", "the", "test", "r", "are", "taken", "into", "account", ":", "p", "is", "the", "number", "of", "correct", "positive", "results", "divided", "by", "the", "total", "number", "of", "positive", "results", "returned", "by", "the", "classifier", ",", "and", "r", "is", "the", "number", "of", "correct", "positive", "results", "divided", "by", "the", "total", "number", "of", "relevant", "samples", "(", "all", "samples", "that", "should", "have", "been", "identified", "as", "positive", ")", "."], "sentence-detokenized": "To calculate the score, the accuracy of the test p and the recall of the test r are taken into account: p is the number of correct positive results divided by the total number of positive results returned by the classifier, and r is the number of correct positive results divided by the total number of relevant samples (all samples that should have been identified as positive).", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 22], [22, 23], [24, 27], [28, 36], [37, 39], [40, 43], [44, 48], [49, 50], [51, 54], [55, 58], [59, 65], [66, 68], [69, 72], [73, 77], [78, 79], [80, 83], [84, 89], [90, 94], [95, 102], [102, 103], [104, 105], [106, 108], [109, 112], [113, 119], [120, 122], [123, 130], [131, 139], [140, 147], [148, 155], [156, 158], [159, 162], [163, 168], [169, 175], [176, 178], [179, 187], [188, 195], [196, 204], [205, 207], [208, 211], [212, 222], [222, 223], [224, 227], [228, 229], [230, 232], [233, 236], [237, 243], [244, 246], [247, 254], [255, 263], [264, 271], [272, 279], [280, 282], [283, 286], [287, 292], [293, 299], [300, 302], [303, 311], [312, 319], [320, 321], [321, 324], [325, 332], [333, 337], [338, 344], [345, 349], [350, 354], [355, 365], [366, 368], [369, 377], [377, 378], [378, 379]]}
{"doc_key": "ai-dev-8", "ner": [[4, 4, "organisation"], [26, 26, "product"], [34, 35, "person"], [41, 41, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 26, 26, "artifact", "", false, false], [26, 26, 34, 35, "win-defeat", "", false, false], [26, 26, 41, 41, "win-defeat", "", true, false], [34, 35, 41, 41, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "the", "acquisition", "of", "Google", ",", "the", "company", "has", "made", "a", "number", "of", "significant", "achievements", ",", "perhaps", "the", "most", "notable", "of", "which", "is", "the", "creation", "of", "AlphaGo", ",", "a", "program", "that", "beat", "world", "champion", "Lee", "Sedol", "in", "a", "complex", "game", "of", "Go", "."], "sentence-detokenized": "Since the acquisition of Google, the company has made a number of significant achievements, perhaps the most notable of which is the creation of AlphaGo, a program that beat world champion Lee Sedol in a complex game of Go.", "token2charspan": [[0, 5], [6, 9], [10, 21], [22, 24], [25, 31], [31, 32], [33, 36], [37, 44], [45, 48], [49, 53], [54, 55], [56, 62], [63, 65], [66, 77], [78, 90], [90, 91], [92, 99], [100, 103], [104, 108], [109, 116], [117, 119], [120, 125], [126, 128], [129, 132], [133, 141], [142, 144], [145, 152], [152, 153], [154, 155], [156, 163], [164, 168], [169, 173], [174, 179], [180, 188], [189, 192], [193, 198], [199, 201], [202, 203], [204, 211], [212, 216], [217, 219], [220, 222], [222, 223]]}
{"doc_key": "ai-dev-9", "ner": [[13, 14, "misc"], [30, 32, "product"], [49, 50, "misc"], [54, 55, "misc"], [58, 58, "product"]], "ner_mapping_to_source": [0, 2, 3, 4, 5], "relations": [[13, 14, 54, 55, "named", "same", false, false], [30, 32, 49, 50, "related-to", "", false, false], [30, 32, 54, 55, "usage", "", false, false], [30, 32, 58, 58, "usage", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4], "sentence": ["The", "representation", "of", "words", "in", "context", "using", "fixed", "-", "size", "dense", "vectors", "(", "word", "embeddings", ")", "has", "become", "one", "of", "the", "most", "fundamental", "blocks", "in", "many", "NLP", "systems", ".", "An", "unsupervised", "disambiguation", "system", "uses", "the", "similarity", "between", "word", "meanings", "in", "a", "fixed", "context", "window", "to", "select", "the", "most", "appropriate", "word", "meaning", "using", "a", "pre-trained", "word", "embedding", "model", "and", "WordNet", "."], "sentence-detokenized": "The representation of words in context using fixed-size dense vectors (word embeddings) has become one of the most fundamental blocks in many NLP systems. An unsupervised disambiguation system uses the similarity between word meanings in a fixed context window to select the most appropriate word meaning using a pre-trained word embedding model and WordNet.", "token2charspan": [[0, 3], [4, 18], [19, 21], [22, 27], [28, 30], [31, 38], [39, 44], [45, 50], [50, 51], [51, 55], [56, 61], [62, 69], [70, 71], [71, 75], [76, 86], [86, 87], [88, 91], [92, 98], [99, 102], [103, 105], [106, 109], [110, 114], [115, 126], [127, 133], [134, 136], [137, 141], [142, 145], [146, 153], [153, 154], [155, 157], [158, 170], [171, 185], [186, 192], [193, 197], [198, 201], [202, 212], [213, 220], [221, 225], [226, 234], [235, 237], [238, 239], [240, 245], [246, 253], [254, 260], [261, 263], [264, 270], [271, 274], [275, 279], [280, 291], [292, 296], [297, 304], [305, 310], [311, 312], [313, 324], [325, 329], [330, 339], [340, 345], [346, 349], [350, 357], [357, 358]]}
{"doc_key": "ai-dev-10", "ner": [[0, 1, "field"], [5, 5, "field"], [7, 7, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 1, "part-of", "", false, false], [7, 7, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "techniques", ",", "whether", "supervised", "or", "unsupervised", ",", "have", "been", "used", "to", "automatically", "generate", "such", "rules", "."], "sentence-detokenized": "Machine learning techniques, whether supervised or unsupervised, have been used to automatically generate such rules.", "token2charspan": [[0, 7], [8, 16], [17, 27], [27, 28], [29, 36], [37, 47], [48, 50], [51, 63], [63, 64], [65, 69], [70, 74], [75, 79], [80, 82], [83, 96], [97, 105], [106, 110], [111, 116], [116, 117]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1969", ",", "Scheinman", "invented", "the", "Stanford", "lever", ","], "sentence-detokenized": "In 1969, Scheinman invented the Stanford lever,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 27], [28, 31], [32, 40], [41, 46], [46, 47]]}
{"doc_key": "ai-dev-12", "ner": [[2, 3, "metrics"], [8, 11, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "the", "Log", "loss", "is", "differentiable", ",", "a", "gradient", "-", "based", "method", "can", "be", "used", "to", "optimise", "the", "model", "."], "sentence-detokenized": "Since the Log loss is differentiable, a gradient-based method can be used to optimise the model.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 18], [19, 21], [22, 36], [36, 37], [38, 39], [40, 48], [48, 49], [49, 54], [55, 61], [62, 65], [66, 68], [69, 73], [74, 76], [77, 85], [86, 89], [90, 95], [95, 96]]}
{"doc_key": "ai-dev-13", "ner": [[0, 2, "field"], [4, 6, "algorithm"], [8, 8, "algorithm"], [13, 15, "algorithm"], [18, 19, "field"], [27, 28, "task"], [30, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 6, 18, 19, "part-of", "", false, false], [8, 8, 4, 6, "named", "", false, false], [13, 15, 4, 6, "named", "", false, false], [18, 19, 0, 2, "part-of", "subfield", false, false], [27, 28, 18, 19, "part-of", "", false, false], [30, 31, 18, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "machine", "learning", ",", "support", "vector", "machines", "(", "SVMs", ",", "also", "known", "as", "support", "vector", "networks", ")", "are", "supervised", "learning", "models", "with", "learning", "algorithms", "that", "analyse", "data", "for", "classification", "and", "regression", "analysis", "."], "sentence-detokenized": "In machine learning, support vector machines (SVMs, also known as support vector networks) are supervised learning models with learning algorithms that analyse data for classification and regression analysis.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 28], [29, 35], [36, 44], [45, 46], [46, 50], [50, 51], [52, 56], [57, 62], [63, 65], [66, 73], [74, 80], [81, 89], [89, 90], [91, 94], [95, 105], [106, 114], [115, 121], [122, 126], [127, 135], [136, 146], [147, 151], [152, 159], [160, 164], [165, 168], [169, 183], [184, 187], [188, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-dev-14", "ner": [[11, 11, "task"], [10, 13, "task"], [30, 30, "metrics"], [32, 32, "metrics"], [34, 34, "researcher"], [36, 36, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 13, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": [",", "(", "2002", ")", "as", "an", "automatic", "measure", "for", "evaluating", "machine", "translation", "(", "MT", ")", ",", "several", "other", "methods", "have", "been", "proposed", "to", "revise", "or", "improve", "it", ",", "such", "as", "TER", ",", "METEOR", ",", "Banerjee", "and", "Lavie", ",", "(", "2005", ")", ",", "etc", "."], "sentence-detokenized": ", (2002) as an automatic measure for evaluating machine translation (MT), several other methods have been proposed to revise or improve it, such as TER, METEOR, Banerjee and Lavie, (2005), etc.", "token2charspan": [[0, 1], [2, 3], [3, 7], [7, 8], [9, 11], [12, 14], [15, 24], [25, 32], [33, 36], [37, 47], [48, 55], [56, 67], [68, 69], [69, 71], [71, 72], [72, 73], [74, 81], [82, 87], [88, 95], [96, 100], [101, 105], [106, 114], [115, 117], [118, 124], [125, 127], [128, 135], [136, 138], [138, 139], [140, 144], [145, 147], [148, 151], [151, 152], [153, 159], [159, 160], [161, 169], [170, 173], [174, 179], [179, 180], [181, 182], [182, 186], [186, 187], [187, 188], [189, 192], [192, 193]]}
{"doc_key": "ai-dev-15", "ner": [[3, 4, "misc"], [8, 8, "organisation"], [9, 9, "organisation"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 9, 9, "origin", "", false, false], [9, 9, 8, 8, "part-of", "", false, false], [15, 16, 9, 9, "role", "", false, false], [18, 19, 9, 9, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "includes", "a", "top", "ontology", "created", "by", "the", "IEEE", "P1600.1", "working", "group", "(", "originally", "by", "Ian", "Niles", "and", "Adam", "Pease", ")", "."], "sentence-detokenized": "It includes a top ontology created by the IEEE P1600.1 working group (originally by Ian Niles and Adam Pease).", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 17], [18, 26], [27, 34], [35, 37], [38, 41], [42, 46], [47, 54], [55, 62], [63, 68], [69, 70], [70, 80], [81, 83], [84, 87], [88, 93], [94, 97], [98, 102], [103, 108], [108, 109], [109, 110]]}
{"doc_key": "ai-dev-16", "ner": [[0, 5, "misc"], [32, 34, "algorithm"], [36, 37, "algorithm"], [40, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[32, 34, 0, 5, "part-of", "", true, false], [36, 37, 0, 5, "part-of", "", true, false], [40, 41, 36, 37, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "cryoelectron", "tomography", ",", "where", "a", "limited", "number", "of", "projections", "are", "taken", "due", "to", "hardware", "limitations", "and", "to", "avoid", "damage", "to", "the", "biological", "sample", ",", "it", "can", "be", "used", "in", "conjunction", "with", "compressive", "sensing", "techniques", "or", "regularization", "functions", "(", "e.g.", "Huber", "loss", ")", "to", "improve", "reconstruction", "for", "better", "interpretation", "."], "sentence-detokenized": "In cryoelectron tomography, where a limited number of projections are taken due to hardware limitations and to avoid damage to the biological sample, it can be used in conjunction with compressive sensing techniques or regularization functions (e.g. Huber loss) to improve reconstruction for better interpretation.", "token2charspan": [[0, 2], [3, 15], [16, 26], [26, 27], [28, 33], [34, 35], [36, 43], [44, 50], [51, 53], [54, 65], [66, 69], [70, 75], [76, 79], [80, 82], [83, 91], [92, 103], [104, 107], [108, 110], [111, 116], [117, 123], [124, 126], [127, 130], [131, 141], [142, 148], [148, 149], [150, 152], [153, 156], [157, 159], [160, 164], [165, 167], [168, 179], [180, 184], [185, 196], [197, 204], [205, 215], [216, 218], [219, 233], [234, 243], [244, 245], [245, 249], [250, 255], [256, 260], [260, 261], [262, 264], [265, 272], [273, 287], [288, 291], [292, 298], [299, 313], [313, 314]]}
{"doc_key": "ai-dev-17", "ner": [[3, 3, "misc"], [6, 6, "programlang"], [9, 10, "algorithm"], [12, 15, "algorithm"], [17, 18, "algorithm"], [22, 26, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 6, 6, "part-of", "", false, false], [9, 10, 3, 3, "type-of", "", false, false], [12, 15, 3, 3, "type-of", "", false, false], [17, 18, 3, 3, "type-of", "", false, false], [22, 26, 6, 6, "general-affiliation", "", true, false], [22, 26, 6, 6, "part-of", "", true, false], [28, 29, 22, 26, "role", "publishes", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Implementations", "of", "several", "whitening", "procedures", "in", "R", ",", "including", "ZCA", "whitening", "and", "PCA", "whitening", ",", "but", "also", "CCA", "whitening", ",", "are", "available", "in", "the", "whitening", "R", "package", "published", "on", "CRAN", "."], "sentence-detokenized": "Implementations of several whitening procedures in R, including ZCA whitening and PCA whitening, but also CCA whitening, are available in the whitening R package published on CRAN.", "token2charspan": [[0, 15], [16, 18], [19, 26], [27, 36], [37, 47], [48, 50], [51, 52], [52, 53], [54, 63], [64, 67], [68, 77], [78, 81], [82, 85], [86, 95], [95, 96], [97, 100], [101, 105], [106, 109], [110, 119], [119, 120], [121, 124], [125, 134], [135, 137], [138, 141], [142, 151], [152, 153], [154, 161], [162, 171], [172, 174], [175, 179], [179, 180]]}
{"doc_key": "ai-dev-18", "ner": [[28, 28, "product"], [30, 30, "product"], [32, 32, "product"], [34, 34, "product"], [36, 36, "product"], [38, 38, "product"], [41, 41, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[28, 28, 32, 32, "compare", "", false, false], [28, 28, 34, 34, "compare", "", false, false], [28, 28, 36, 36, "compare", "", false, false], [28, 28, 38, 38, "compare", "", false, false], [28, 28, 41, 41, "compare", "", false, false], [30, 30, 32, 32, "compare", "", false, false], [30, 30, 34, 34, "compare", "", false, false], [30, 30, 36, 36, "compare", "", false, false], [30, 30, 38, 38, "compare", "", false, false], [30, 30, 41, 41, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Today", ",", "this", "field", "has", "become", "even", "more", "daunting", "and", "complex", "with", "the", "emergence", "of", "circuit", ",", "system", "and", "signal", "analysis", "and", "design", "languages", "and", "software", ",", "from", "MATLAB", "and", "Simulink", "to", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "and", "even", "Assembly", "."], "sentence-detokenized": "Today, this field has become even more daunting and complex with the emergence of circuit, system and signal analysis and design languages and software, from MATLAB and Simulink to NumPy, VHDL, PSpice, Verilog and even Assembly.", "token2charspan": [[0, 5], [5, 6], [7, 11], [12, 17], [18, 21], [22, 28], [29, 33], [34, 38], [39, 47], [48, 51], [52, 59], [60, 64], [65, 68], [69, 78], [79, 81], [82, 89], [89, 90], [91, 97], [98, 101], [102, 108], [109, 117], [118, 121], [122, 128], [129, 138], [139, 142], [143, 151], [151, 152], [153, 157], [158, 164], [165, 168], [169, 177], [178, 180], [181, 186], [186, 187], [188, 192], [192, 193], [194, 200], [200, 201], [202, 209], [210, 213], [214, 218], [219, 227], [227, 228]]}
{"doc_key": "ai-dev-19", "ner": [[5, 6, "person"], [19, 22, "person"], [10, 14, "organisation"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 14, 19, 22, "origin", "", false, false], [24, 24, 10, 14, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "company", "was", "founded", "by", "Kiichiro", "Toyoda", "in", "1937", ",", "from", "Toyota", "Industries", ",", "a", "spin", "-", "off", "from", "Sakichi", "Toyoda", ",", "to", "create", "cars", "."], "sentence-detokenized": "The company was founded by Kiichiro Toyoda in 1937, from Toyota Industries, a spin-off from Sakichi Toyoda, to create cars.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 35], [36, 42], [43, 45], [46, 50], [50, 51], [52, 56], [57, 63], [64, 74], [74, 75], [76, 77], [78, 82], [82, 83], [83, 86], [87, 91], [92, 99], [100, 106], [106, 107], [108, 110], [111, 117], [118, 122], [122, 123]]}
{"doc_key": "ai-dev-20", "ner": [[0, 6, "field"], [51, 52, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[51, 52, 0, 6, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Unsupervised", "learning", ",", "on", "the", "other", "hand", ",", "assumes", "training", "data", "that", "has", "not", "been", "manually", "labeled", "and", "tries", "to", "find", "inherent", "patterns", "in", "the", "data", "that", "can", "be", "used", "to", "determine", "the", "correct", "output", "of", "new", "data", "instances", "...", "A", "combination", "of", "the", "two", "that", "has", "been", "studied", "recently", "is", "semi-supervised", "learning", ",", "which", "uses", "a", "combination", "of", "labeled", "and", "unlabeled", "data", "(", "typically", "a", "small", "amount", "of", "labeled", "data", "is", "combined", "with", "a", "large", "amount", "of", "unlabeled", "data", ")", "."], "sentence-detokenized": "Unsupervised learning, on the other hand, assumes training data that has not been manually labeled and tries to find inherent patterns in the data that can be used to determine the correct output of new data instances... A combination of the two that has been studied recently is semi-supervised learning, which uses a combination of labeled and unlabeled data (typically a small amount of labeled data is combined with a large amount of unlabeled data).", "token2charspan": [[0, 12], [13, 21], [21, 22], [23, 25], [26, 29], [30, 35], [36, 40], [40, 41], [42, 49], [50, 58], [59, 63], [64, 68], [69, 72], [73, 76], [77, 81], [82, 90], [91, 98], [99, 102], [103, 108], [109, 111], [112, 116], [117, 125], [126, 134], [135, 137], [138, 141], [142, 146], [147, 151], [152, 155], [156, 158], [159, 163], [164, 166], [167, 176], [177, 180], [181, 188], [189, 195], [196, 198], [199, 202], [203, 207], [208, 217], [217, 220], [221, 222], [223, 234], [235, 237], [238, 241], [242, 245], [246, 250], [251, 254], [255, 259], [260, 267], [268, 276], [277, 279], [280, 295], [296, 304], [304, 305], [306, 311], [312, 316], [317, 318], [319, 330], [331, 333], [334, 341], [342, 345], [346, 355], [356, 360], [361, 362], [362, 371], [372, 373], [374, 379], [380, 386], [387, 389], [390, 397], [398, 402], [403, 405], [406, 414], [415, 419], [420, 421], [422, 427], [428, 434], [435, 437], [438, 447], [448, 452], [452, 453], [453, 454]]}
{"doc_key": "ai-dev-21", "ner": [[20, 20, "organisation"], [21, 21, "product"], [24, 25, "organisation"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 20, 20, "artifact", "", false, false], [24, 25, 26, 26, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Despite", "humanoid", "robots", "for", "profit", ",", "there", "are", "also", "humanoid", "robots", "that", "are", "designed", "for", "entertainment", ",", "such", "as", "the", "Sony", "QRIO", "and", "the", "Wow", "Wee", "RoboSapien", "."], "sentence-detokenized": "Despite humanoid robots for profit, there are also humanoid robots that are designed for entertainment, such as the Sony QRIO and the Wow Wee RoboSapien.", "token2charspan": [[0, 7], [8, 16], [17, 23], [24, 27], [28, 34], [34, 35], [36, 41], [42, 45], [46, 50], [51, 59], [60, 66], [67, 71], [72, 75], [76, 84], [85, 88], [89, 102], [102, 103], [104, 108], [109, 111], [112, 115], [116, 120], [121, 125], [126, 129], [130, 133], [134, 137], [138, 141], [142, 152], [152, 153]]}
{"doc_key": "ai-dev-22", "ner": [[0, 0, "researcher"], [6, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 12, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Webber", "became", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "in", "1991", ","], "sentence-detokenized": "Webber became a member of the Association for the Advancement of Artificial Intelligence in 1991,", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 49], [50, 61], [62, 64], [65, 75], [76, 88], [89, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-dev-23", "ner": [[6, 7, "field"], [21, 24, "task"]], "ner_mapping_to_source": [0, 2], "relations": [[21, 24, 6, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["With", "this", "company", ",", "he", "developed", "data", "mining", "and", "database", "technology", ",", "more", "specifically", "high", "-", "level", "ontologies", "for", "intelligence", "and", "automatic", "natural", "language", "understanding", "."], "sentence-detokenized": "With this company, he developed data mining and database technology, more specifically high-level ontologies for intelligence and automatic natural language understanding.", "token2charspan": [[0, 4], [5, 9], [10, 17], [17, 18], [19, 21], [22, 31], [32, 36], [37, 43], [44, 47], [48, 56], [57, 67], [67, 68], [69, 73], [74, 86], [87, 91], [91, 92], [92, 97], [98, 108], [109, 112], [113, 125], [126, 129], [130, 139], [140, 147], [148, 156], [157, 170], [170, 171]]}
{"doc_key": "ai-dev-24", "ner": [[24, 25, "misc"], [28, 31, "misc"], [33, 34, "misc"], [35, 36, "country"], [39, 40, "organisation"], [41, 42, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[24, 25, 35, 36, "physical", "", false, false], [28, 31, 35, 36, "physical", "", false, false], [33, 34, 35, 36, "physical", "", false, false], [39, 40, 41, 42, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["However", ",", "in", "recent", "years", ",", "we", "have", "witnessed", "the", "emergence", "of", "various", "e-services", "and", "related", "initiatives", "in", "developing", "countries", ",", "such", "as", "the", "Nemmadi", "project", ",", "the", "MCA21", "Mission", "Mode", "project", "or", "Digital", "India", "in", "India", ";", "the", "e-Government", "Directorate", "in", "Pakistan", ",", "etc."], "sentence-detokenized": "However, in recent years, we have witnessed the emergence of various e-services and related initiatives in developing countries, such as the Nemmadi project, the MCA21 Mission Mode project or Digital India in India; the e-Government Directorate in Pakistan, etc.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 18], [19, 24], [24, 25], [26, 28], [29, 33], [34, 43], [44, 47], [48, 57], [58, 60], [61, 68], [69, 79], [80, 83], [84, 91], [92, 103], [104, 106], [107, 117], [118, 127], [127, 128], [129, 133], [134, 136], [137, 140], [141, 148], [149, 156], [156, 157], [158, 161], [162, 167], [168, 175], [176, 180], [181, 188], [189, 191], [192, 199], [200, 205], [206, 208], [209, 214], [214, 215], [216, 219], [220, 232], [233, 244], [245, 247], [248, 256], [256, 257], [258, 262]]}
{"doc_key": "ai-dev-25", "ner": [[12, 13, "misc"], [14, 15, "field"], [17, 19, "field"], [20, 22, "university"], [24, 28, "university"], [5, 9, "university"], [33, 33, "misc"], [35, 36, "field"], [37, 37, "misc"], [38, 43, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10], "relations": [[12, 13, 14, 15, "topic", "", false, false], [12, 13, 17, 19, "topic", "", false, false], [12, 13, 20, 22, "origin", "", false, false], [20, 22, 24, 28, "part-of", "", false, false], [5, 9, 20, 22, "part-of", "", false, false], [33, 33, 35, 36, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["As", "a", "student", "at", "the", "Indian", "Statistical", "Institute", ",", "he", "obtained", "a", "PhD", "in", "radio", "physics", "and", "electronics", "from", "the", "Rajabazar", "Science", "College", ",", "University", "of", "Calcutta", ",", "in", "1979", ",", "and", "another", "PhD", "in", "electrical", "engineering", "from", "Imperial", "College", ",", "University", "of", "London", ",", "in", "1982", "."], "sentence-detokenized": "As a student at the Indian Statistical Institute, he obtained a PhD in radio physics and electronics from the Rajabazar Science College, University of Calcutta, in 1979, and another PhD in electrical engineering from Imperial College, University of London, in 1982.", "token2charspan": [[0, 2], [3, 4], [5, 12], [13, 15], [16, 19], [20, 26], [27, 38], [39, 48], [48, 49], [50, 52], [53, 61], [62, 63], [64, 67], [68, 70], [71, 76], [77, 84], [85, 88], [89, 100], [101, 105], [106, 109], [110, 119], [120, 127], [128, 135], [135, 136], [137, 147], [148, 150], [151, 159], [159, 160], [161, 163], [164, 168], [168, 169], [170, 173], [174, 181], [182, 185], [186, 188], [189, 199], [200, 211], [212, 216], [217, 225], [226, 233], [233, 234], [235, 245], [246, 248], [249, 255], [255, 256], [257, 259], [260, 264], [264, 265]]}
{"doc_key": "ai-dev-26", "ner": [[0, 5, "location"], [21, 24, "misc"], [30, 31, "misc"], [32, 35, "person"], [37, 38, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 24, 0, 5, "temporal", "", false, false], [30, 31, 0, 5, "temporal", "", false, false], [32, 35, 30, 31, "role", "actor_in", false, false], [37, 38, 30, 31, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Expo", "II", "was", "announced", "as", "the", "venue", "for", "the", "world", "premiere", "of", "several", "films", "never", "before", "seen", "in", "3D", ",", "including", "The", "Wizard", "of", "Diamonds", "and", "Universal", "'s", "short", "film", "Hawaiian", "Nights", "with", "Mamie", "Van", "Doren", "and", "Pinky", "Lee", "."], "sentence-detokenized": "Expo II was announced as the venue for the world premiere of several films never before seen in 3D, including The Wizard of Diamonds and Universal's short film Hawaiian Nights with Mamie Van Doren and Pinky Lee.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 24], [25, 28], [29, 34], [35, 38], [39, 42], [43, 48], [49, 57], [58, 60], [61, 68], [69, 74], [75, 80], [81, 87], [88, 92], [93, 95], [96, 98], [98, 99], [100, 109], [110, 113], [114, 120], [121, 123], [124, 132], [133, 136], [137, 146], [146, 148], [149, 154], [155, 159], [160, 168], [169, 175], [176, 180], [181, 186], [187, 190], [191, 196], [197, 200], [201, 206], [207, 210], [210, 211]]}
{"doc_key": "ai-dev-27", "ner": [[7, 8, "researcher"], [15, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 15, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "maximum", "subarray", "problem", "was", "proposed", "by", "Ulf", "Grenander", "in", "1977", "as", "a", "simplified", "model", "for", "maximum", "likelihood", "estimation", "of", "samples", "of", "digitized", "images", "."], "sentence-detokenized": "The maximum subarray problem was proposed by Ulf Grenander in 1977 as a simplified model for maximum likelihood estimation of samples of digitized images.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 28], [29, 32], [33, 41], [42, 44], [45, 48], [49, 58], [59, 61], [62, 66], [67, 69], [70, 71], [72, 82], [83, 88], [89, 92], [93, 100], [101, 111], [112, 122], [123, 125], [126, 133], [134, 136], [137, 146], [147, 153], [153, 154]]}
{"doc_key": "ai-dev-28", "ner": [[1, 2, "product"], [4, 5, "product"], [7, 9, "product"], [11, 12, "product"], [14, 16, "product"], [18, 21, "product"], [32, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[32, 32, 1, 2, "part-of", "", false, false], [32, 32, 4, 5, "part-of", "", false, false], [32, 32, 7, 9, "part-of", "", false, false], [32, 32, 11, 12, "part-of", "", false, false], [32, 32, 14, 16, "part-of", "", false, false], [32, 32, 18, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "iPhone", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", ",", "iPod", "Touch", "5", "G", "and", "newer", "all", "come", "with", "an", "advanced", "voice", "assistant", "called", "Siri", "."], "sentence-detokenized": "The iPhone 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G, iPod Touch 5G and newer all come with an advanced voice assistant called Siri.", "token2charspan": [[0, 3], [4, 10], [11, 13], [13, 14], [15, 19], [20, 21], [21, 22], [23, 27], [28, 32], [33, 35], [35, 36], [37, 41], [42, 45], [45, 46], [47, 51], [52, 55], [56, 58], [58, 59], [60, 64], [65, 70], [71, 72], [72, 73], [74, 77], [78, 83], [84, 87], [88, 92], [93, 97], [98, 100], [101, 109], [110, 115], [116, 125], [126, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-dev-29", "ner": [[7, 8, "metrics"], [11, 14, "metrics"], [16, 17, "metrics"], [36, 39, "metrics"], [42, 47, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 14, 36, 39, "named", "", false, false], [16, 17, 11, 14, "named", "", false, false], [36, 39, 42, 47, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["It", "is", "easy", "to", "verify", "that", "the", "logistic", "loss", "and", "the", "binary", "cross", "-entropy", "loss", "(", "Log", "loss", ")", "are", "in", "fact", "the", "same", "(", "up", "to", "a", "multiplicative", "constant", "math\\frac", "{", "1", "}", "{", "The", "cross", "-entropy", "loss", "is", "closely", "related", "to", "the", "Kullback", "-", "Leibler", "divergence", "between", "the", "empirical", "distribution", "and", "the", "predicted", "distribution", "."], "sentence-detokenized": "It is easy to verify that the logistic loss and the binary cross-entropy loss (Log loss) are in fact the same (up to a multiplicative constant math\\frac {1} {The cross-entropy loss is closely related to the Kullback-Leibler divergence between the empirical distribution and the predicted distribution.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 20], [21, 25], [26, 29], [30, 38], [39, 43], [44, 47], [48, 51], [52, 58], [59, 64], [64, 72], [73, 77], [78, 79], [79, 82], [83, 87], [87, 88], [89, 92], [93, 95], [96, 100], [101, 104], [105, 109], [110, 111], [111, 113], [114, 116], [117, 118], [119, 133], [134, 142], [143, 152], [153, 154], [154, 155], [155, 156], [157, 158], [158, 161], [162, 167], [167, 175], [176, 180], [181, 183], [184, 191], [192, 199], [200, 202], [203, 206], [207, 215], [215, 216], [216, 223], [224, 234], [235, 242], [243, 246], [247, 256], [257, 269], [270, 273], [274, 277], [278, 287], [288, 300], [300, 301]]}
{"doc_key": "ai-dev-30", "ner": [[1, 2, "algorithm"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 1, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "EM", "algorithm", "is", "used", "to", "find", "the", "(", "local", ")", "maximum", "likelihood", "parameters", "of", "a", "statistical", "model", "in", "cases", "where", "the", "equations", "can", "not", "be", "solved", "directly", "."], "sentence-detokenized": "The EM algorithm is used to find the (local) maximum likelihood parameters of a statistical model in cases where the equations cannot be solved directly.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 32], [33, 36], [37, 38], [38, 43], [43, 44], [45, 52], [53, 63], [64, 74], [75, 77], [78, 79], [80, 91], [92, 97], [98, 100], [101, 106], [107, 112], [113, 116], [117, 126], [127, 130], [130, 133], [134, 136], [137, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-dev-31", "ner": [[12, 13, "task"], [15, 19, "task"], [24, 25, "task"], [27, 27, "task"], [31, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "research", "has", "been", "fundamental", "in", "the", "development", "of", "modern", "techniques", "of", "speech", "synthesis", ",", "reading", "machines", "for", "the", "blind", ",", "the", "study", "of", "speech", "perception", "and", "recognition", ",", "and", "the", "motor", "theory", "of", "speech", "perception", "."], "sentence-detokenized": "This research has been fundamental in the development of modern techniques of speech synthesis, reading machines for the blind, the study of speech perception and recognition, and the motor theory of speech perception.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 22], [23, 34], [35, 37], [38, 41], [42, 53], [54, 56], [57, 63], [64, 74], [75, 77], [78, 84], [85, 94], [94, 95], [96, 103], [104, 112], [113, 116], [117, 120], [121, 126], [126, 127], [128, 131], [132, 137], [138, 140], [141, 147], [148, 158], [159, 162], [163, 174], [174, 175], [176, 179], [180, 183], [184, 189], [190, 196], [197, 199], [200, 206], [207, 217], [217, 218]]}
{"doc_key": "ai-dev-32", "ner": [[1, 1, "product"], [4, 4, "misc"], [2, 6, "misc"], [10, 12, "misc"], [15, 15, "product"], [17, 17, "product"], [19, 20, "product"], [25, 25, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 4, 1, 1, "origin", "", false, false], [4, 4, 10, 12, "type-of", "", false, false], [4, 4, 15, 15, "related-to", "program_for", false, false], [4, 4, 17, 17, "related-to", "program_for", false, false], [4, 4, 19, 20, "related-to", "program_for", false, false], [4, 4, 25, 25, "related-to", "program_for", false, false], [2, 6, 4, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "Arduino", "Integrated", "Development", "Environment", "(", "IDE", ")", "is", "a", "cross", "-platform", "application", "(", "for", "Windows", ",", "macOS", "and", "Linux", "operating", "systems", ")", "written", "in", "Java", "programming", "language", "."], "sentence-detokenized": "The Arduino Integrated Development Environment (IDE) is a cross-platform application (for Windows, macOS and Linux operating systems) written in Java programming language.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 57], [58, 63], [63, 72], [73, 84], [85, 86], [86, 89], [90, 97], [97, 98], [99, 104], [105, 108], [109, 114], [115, 124], [125, 132], [132, 133], [134, 141], [142, 144], [145, 149], [150, 161], [162, 170], [170, 171]]}
{"doc_key": "ai-dev-33", "ner": [[2, 3, "algorithm"], [9, 10, "field"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 9, 10, "opposite", "", false, false], [13, 14, 9, 10, "related-to", "works_with", false, false], [16, 17, 9, 10, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Research", "on", "neural", "networks", "stagnated", "after", "the", "publication", "of", "machine", "learning", "research", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", "."], "sentence-detokenized": "Research on neural networks stagnated after the publication of machine learning research by Marvin Minsky and Seymour Papert (1969).", "token2charspan": [[0, 8], [9, 11], [12, 18], [19, 27], [28, 37], [38, 43], [44, 47], [48, 59], [60, 62], [63, 70], [71, 79], [80, 88], [89, 91], [92, 98], [99, 105], [106, 109], [110, 117], [118, 124], [125, 126], [126, 130], [130, 131], [131, 132]]}
{"doc_key": "ai-dev-34", "ner": [[25, 27, "country"], [20, 23, "organisation"], [32, 32, "country"], [29, 31, "organisation"], [36, 36, "country"], [34, 34, "organisation"]], "ner_mapping_to_source": [3, 4, 5, 6, 7, 8], "relations": [[20, 23, 25, 27, "general-affiliation", "", false, false], [29, 31, 32, 32, "general-affiliation", "", false, false], [34, 34, 36, 36, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["In", "the", "end", ",", "only", "a", "few", "non-Japanese", "companies", "managed", "to", "survive", "in", "this", "market", ",", "the", "most", "important", "being", "ABB", "Asea", "Brown", "Boveri", "of", "Sweden", "-", "Switzerland", ",", "KUKA", "Robotics", "of", "Germany", "and", "Comau", "of", "Italy", "."], "sentence-detokenized": "In the end, only a few non-Japanese companies managed to survive in this market, the most important being ABB Asea Brown Boveri of Sweden-Switzerland, KUKA Robotics of Germany and Comau of Italy.", "token2charspan": [[0, 2], [3, 6], [7, 10], [10, 11], [12, 16], [17, 18], [19, 22], [23, 35], [36, 45], [46, 53], [54, 56], [57, 64], [65, 67], [68, 72], [73, 79], [79, 80], [81, 84], [85, 89], [90, 99], [100, 105], [106, 109], [110, 114], [115, 120], [121, 127], [128, 130], [131, 137], [137, 138], [138, 149], [149, 150], [151, 155], [156, 164], [165, 167], [168, 175], [176, 179], [180, 185], [186, 188], [189, 194], [194, 195]]}
{"doc_key": "ai-dev-35", "ner": [[9, 10, "conference"], [14, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Research", "activities", "include", "an", "annual", "research", "conference", ",", "the", "RuleML", "Symposium", ",", "also", "known", "as", "RuleML", "for", "short", "."], "sentence-detokenized": "Research activities include an annual research conference, the RuleML Symposium, also known as RuleML for short.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 30], [31, 37], [38, 46], [47, 57], [57, 58], [59, 62], [63, 69], [70, 79], [79, 80], [81, 85], [86, 91], [92, 94], [95, 101], [102, 105], [106, 111], [111, 112]]}
{"doc_key": "ai-dev-36", "ner": [[9, 9, "field"], [11, 12, "field"], [14, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Concepts", "are", "used", "as", "formal", "tools", "or", "models", "in", "mathematics", ",", "computer", "science", ",", "databases", "and", "artificial", "intelligence", ",", "where", "they", "are", "sometimes", "called", "classes", ",", "schemas", "or", "categories", "."], "sentence-detokenized": "Concepts are used as formal tools or models in mathematics, computer science, databases and artificial intelligence, where they are sometimes called classes, schemas or categories.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 33], [34, 36], [37, 43], [44, 46], [47, 58], [58, 59], [60, 68], [69, 76], [76, 77], [78, 87], [88, 91], [92, 102], [103, 115], [115, 116], [117, 122], [123, 127], [128, 131], [132, 141], [142, 148], [149, 156], [156, 157], [158, 165], [166, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-dev-37", "ner": [[7, 10, "organisation"], [13, 16, "organisation"], [19, 19, "organisation"], [20, 25, "organisation"], [28, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "recipient", "of", "awards", "from", "the", "American", "Psychological", "Association", ",", "the", "National", "Academy", "of", "Sciences", ",", "the", "Royal", "Society", ",", "the", "Cognitive", "Neuroscience", "Society", "and", "the", "American", "Humanist", "Association", "."], "sentence-detokenized": "He is a recipient of awards from the American Psychological Association, the National Academy of Sciences, the Royal Society, the Cognitive Neuroscience Society and the American Humanist Association.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 17], [18, 20], [21, 27], [28, 32], [33, 36], [37, 45], [46, 59], [60, 71], [71, 72], [73, 76], [77, 85], [86, 93], [94, 96], [97, 105], [105, 106], [107, 110], [111, 116], [117, 124], [124, 125], [126, 129], [130, 139], [140, 152], [153, 160], [161, 164], [165, 168], [169, 177], [178, 186], [187, 198], [198, 199]]}
{"doc_key": "ai-dev-38", "ner": [[4, 5, "person"], [7, 8, "person"], [10, 13, "person"], [17, 21, "person"], [23, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[23, 29, 17, 21, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "film", ",", "starring", "Harrison", "Ford", ",", "Rutger", "Hauer", "and", "Sean", "Young", ",", "is", "loosely", "based", "on", "Philip", "K", ".", "Dick", "'s", "novel", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "?", "(", "1968", ")", "."], "sentence-detokenized": "The film, starring Harrison Ford, Rutger Hauer and Sean Young, is loosely based on Philip K. Dick's novel Do Androids Dream of Electric Sheep? (1968).", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 18], [19, 27], [28, 32], [32, 33], [34, 40], [41, 46], [47, 50], [51, 55], [56, 61], [61, 62], [63, 65], [66, 73], [74, 79], [80, 82], [83, 89], [90, 91], [91, 92], [93, 97], [97, 99], [100, 105], [106, 108], [109, 117], [118, 123], [124, 126], [127, 135], [136, 141], [141, 142], [143, 144], [144, 148], [148, 149], [149, 150]]}
{"doc_key": "ai-dev-39", "ner": [[0, 1, "task"], [3, 6, "algorithm"], [11, 12, "field"], [14, 15, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 3, 6, "usage", "", false, false], [0, 1, 11, 12, "part-of", "task_part_of_field", false, false], [0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Image", "segmentation", "using", "k-means", "clustering", "algorithms", "has", "long", "been", "used", "in", "pattern", "recognition", ",", "object", "detection", "and", "medical", "imaging", "."], "sentence-detokenized": "Image segmentation using k-means clustering algorithms has long been used in pattern recognition, object detection and medical imaging.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 32], [33, 43], [44, 54], [55, 58], [59, 63], [64, 68], [69, 73], [74, 76], [77, 84], [85, 96], [96, 97], [98, 104], [105, 114], [115, 118], [119, 126], [127, 134], [134, 135]]}
{"doc_key": "ai-dev-40", "ner": [[13, 13, "algorithm"], [16, 17, "algorithm"], [20, 20, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Generalized", "sampling", "from", "truncated", "normals", "can", "be", "achieved", "using", "approximations", "of", "the", "normal", "CDF", "and", "the", "probit", "function", ",", "and", "R", "has", "a", "codertnorm", "(", ")", "/", "code", "for", "generating", "truncated", "normal", "samples", "."], "sentence-detokenized": "Generalized sampling from truncated normals can be achieved using approximations of the normal CDF and the probit function, and R has a codertnorm() / code for generating truncated normal samples.", "token2charspan": [[0, 11], [12, 20], [21, 25], [26, 35], [36, 43], [44, 47], [48, 50], [51, 59], [60, 65], [66, 80], [81, 83], [84, 87], [88, 94], [95, 98], [99, 102], [103, 106], [107, 113], [114, 122], [122, 123], [124, 127], [128, 129], [130, 133], [134, 135], [136, 146], [146, 147], [147, 148], [149, 150], [151, 155], [156, 159], [160, 170], [171, 180], [181, 187], [188, 195], [195, 196]]}
{"doc_key": "ai-dev-41", "ner": [[8, 8, "university"], [10, 10, "university"], [12, 13, "university"], [15, 16, "university"], [4, 18, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "holds", "honorary", "doctorates", "from", "the", "Universities", "of", "Newcastle", ",", "Surrey", ",", "Tel", "Aviv", ",", "Simon", "Fraser", "and", "Troms\u00f8", "."], "sentence-detokenized": "He holds honorary doctorates from the Universities of Newcastle, Surrey, Tel Aviv, Simon Fraser and Troms\u00f8.", "token2charspan": [[0, 2], [3, 8], [9, 17], [18, 28], [29, 33], [34, 37], [38, 50], [51, 53], [54, 63], [63, 64], [65, 71], [71, 72], [73, 76], [77, 81], [81, 82], [83, 88], [89, 95], [96, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-dev-42", "ner": [[1, 1, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "Java", "implementation", "that", "uses", "zero", "-", "based", "array", "indexes", "and", "a", "convenient", "way", "to", "print", "the", "resolved", "order", "of", "operations", ":"], "sentence-detokenized": "A Java implementation that uses zero-based array indexes and a convenient way to print the resolved order of operations:", "token2charspan": [[0, 1], [2, 6], [7, 21], [22, 26], [27, 31], [32, 36], [36, 37], [37, 42], [43, 48], [49, 56], [57, 60], [61, 62], [63, 73], [74, 77], [78, 80], [81, 86], [87, 90], [91, 99], [100, 105], [106, 108], [109, 119], [119, 120]]}
{"doc_key": "ai-dev-43", "ner": [[7, 8, "metrics"], [11, 12, "metrics"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Such", "networks", "are", "usually", "trained", "in", "a", "cross", "-entropy", "(", "or", "cross", "-entropy", ")", "regime", ",", "which", "gives", "a", "nonlinear", "version", "of", "multinomial", "logistic", "regression", "."], "sentence-detokenized": "Such networks are usually trained in a cross-entropy (or cross-entropy) regime, which gives a nonlinear version of multinomial logistic regression.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 25], [26, 33], [34, 36], [37, 38], [39, 44], [44, 52], [53, 54], [54, 56], [57, 62], [62, 70], [70, 71], [72, 78], [78, 79], [80, 85], [86, 91], [92, 93], [94, 103], [104, 111], [112, 114], [115, 126], [127, 135], [136, 146], [146, 147]]}
{"doc_key": "ai-dev-44", "ner": [[3, 3, "misc"], [4, 13, "conference"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACL", "has", "a", "European", "chapter", "(", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ")", "."], "sentence-detokenized": "ACL has a European chapter (European Chapter of the Association for Computational Linguistics).", "token2charspan": [[0, 3], [4, 7], [8, 9], [10, 18], [19, 26], [27, 28], [28, 36], [37, 44], [45, 47], [48, 51], [52, 63], [64, 67], [68, 81], [82, 93], [93, 94], [94, 95]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 11, "researcher"], [22, 22, "misc"], [21, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 22, 22, "role", "", false, false], [6, 11, 22, 22, "role", "", false, false], [22, 22, 21, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "professors", ",", "Hal", "Abelson", "and", "Gerald", "Jay", "Sussman", ",", "decided", "to", "remain", "neutral", "-", "their", "group", "was", "variously", "known", "as", "Project", "Switzerland", "and", "Project", "MAC", "for", "the", "next", "30", "years", "."], "sentence-detokenized": "Two professors, Hal Abelson and Gerald Jay Sussman, decided to remain neutral - their group was variously known as Project Switzerland and Project MAC for the next 30 years.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 50], [50, 51], [52, 59], [60, 62], [63, 69], [70, 77], [78, 79], [80, 85], [86, 91], [92, 95], [96, 105], [106, 111], [112, 114], [115, 122], [123, 134], [135, 138], [139, 146], [147, 150], [151, 154], [155, 158], [159, 163], [164, 166], [167, 172], [172, 173]]}
{"doc_key": "ai-dev-46", "ner": [[2, 3, "misc"], [10, 10, "researcher"], [11, 16, "university"], [20, 20, "organisation"], [25, 27, "organisation"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 10, 10, "temporal", "", false, false], [10, 10, 20, 20, "physical", "", false, false], [10, 10, 20, 20, "role", "", false, false], [10, 10, 25, 27, "role", "", false, false], [25, 27, 11, 16, "part-of", "", false, false], [29, 30, 25, 27, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["After", "completing", "his", "PhD", "in", "1995", ",", "he", "moved", "to", "the", "University", "of", "Toronto", ",", "where", "he", "worked", "as", "an", "ITRC", "postdoctoral", "fellow", "in", "the", "Artificial", "Intelligence", "Laboratory", "with", "Geoffrey", "Hinton", "."], "sentence-detokenized": "After completing his PhD in 1995, he moved to the University of Toronto, where he worked as an ITRC postdoctoral fellow in the Artificial Intelligence Laboratory with Geoffrey Hinton.", "token2charspan": [[0, 5], [6, 16], [17, 20], [21, 24], [25, 27], [28, 32], [32, 33], [34, 36], [37, 42], [43, 45], [46, 49], [50, 60], [61, 63], [64, 71], [71, 72], [73, 78], [79, 81], [82, 88], [89, 91], [92, 94], [95, 99], [100, 112], [113, 119], [120, 122], [123, 126], [127, 137], [138, 150], [151, 161], [162, 166], [167, 175], [176, 182], [182, 183]]}
{"doc_key": "ai-dev-47", "ner": [[23, 23, "metrics"], [22, 25, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[22, 25, 23, 23, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Subsequent", "work", "focused", "on", "solving", "these", "problems", ",", "but", "it", "was", "only", "after", "the", "advent", "of", "modern", "computers", "and", "the", "popularisation", "of", "Maximum", "Likelihood", "(", "MLE", ")", "parameterisation", "techniques", "that", "research", "really", "took", "off", "."], "sentence-detokenized": "Subsequent work focused on solving these problems, but it was only after the advent of modern computers and the popularisation of Maximum Likelihood (MLE) parameterisation techniques that research really took off.", "token2charspan": [[0, 10], [11, 15], [16, 23], [24, 26], [27, 34], [35, 40], [41, 49], [49, 50], [51, 54], [55, 57], [58, 61], [62, 66], [67, 72], [73, 76], [77, 83], [84, 86], [87, 93], [94, 103], [104, 107], [108, 111], [112, 126], [127, 129], [130, 137], [138, 148], [149, 150], [150, 153], [153, 154], [155, 171], [172, 182], [183, 187], [188, 196], [197, 203], [204, 208], [209, 212], [212, 213]]}
{"doc_key": "ai-dev-48", "ner": [[2, 6, "person"], [9, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "series", "was", "produced", "by", "David", "Fincher", "and", "starred", "Kevin", "Spacey", "."], "sentence-detokenized": "The series was produced by David Fincher and starred Kevin Spacey.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 40], [41, 44], [45, 52], [53, 58], [59, 65], [65, 66]]}
{"doc_key": "ai-dev-49", "ner": [[16, 17, "metrics"], [23, 24, "algorithm"], [29, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 29, 35, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Due", "to", "limitations", "in", "computational", "power", ",", "current", "in", "silico", "methods", "generally", "have", "to", "trade", "speed", "for", "accuracy", ";", "for", "example", ",", "fast", "protein", "docking", "methods", "must", "be", "used", "instead", "of", "computationally", "intensive", "free", "energy", "calculations", "."], "sentence-detokenized": "Due to limitations in computational power, current in silico methods generally have to trade speed for accuracy; for example, fast protein docking methods must be used instead of computationally intensive free energy calculations.", "token2charspan": [[0, 3], [4, 6], [7, 18], [19, 21], [22, 35], [36, 41], [41, 42], [43, 50], [51, 53], [54, 60], [61, 68], [69, 78], [79, 83], [84, 86], [87, 92], [93, 98], [99, 102], [103, 111], [111, 112], [113, 116], [117, 124], [124, 125], [126, 130], [131, 138], [139, 146], [147, 154], [155, 159], [160, 162], [163, 167], [168, 175], [176, 178], [179, 194], [195, 204], [205, 209], [210, 216], [217, 229], [229, 230]]}
{"doc_key": "ai-dev-50", "ner": [[8, 9, "country"], [11, 11, "country"], [13, 13, "country"], [15, 15, "country"], [17, 17, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "had", "more", "than", "30", "locations", "in", "the", "United", "States", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "sentence-detokenized": "It had more than 30 locations in the United States, Canada, Mexico, Brazil and Argentina.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 19], [20, 29], [30, 32], [33, 36], [37, 43], [44, 50], [50, 51], [52, 58], [58, 59], [60, 66], [66, 67], [68, 74], [75, 78], [79, 88], [88, 89]]}
{"doc_key": "ai-dev-51", "ner": [[5, 6, "field"], [9, 11, "product"], [13, 15, "algorithm"], [18, 20, "task"], [22, 23, "task"], [29, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 11, 5, 6, "part-of", "", false, false], [9, 11, 13, 15, "usage", "", false, false], [18, 20, 5, 6, "part-of", "task_part_of_field", false, false], [18, 20, 29, 30, "related-to", "performs", false, false], [22, 23, 5, 6, "part-of", "task_part_of_field", false, false], [22, 23, 29, 30, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["An", "example", "of", "a", "typical", "computer", "vision", "computation", "pipeline", "for", "face", "recognition", "using", "k", "-", "NN", ",", "including", "the", "typical", "extraction", "and", "dimension", "reduction", "preprocessing", "steps", "(", "usually", "implemented", "with", "OpenCV", ")", ":"], "sentence-detokenized": "An example of a typical computer vision computation pipeline for face recognition using k -NN, including the typical extraction and dimension reduction preprocessing steps (usually implemented with OpenCV):", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 23], [24, 32], [33, 39], [40, 51], [52, 60], [61, 64], [65, 69], [70, 81], [82, 87], [88, 89], [90, 91], [91, 93], [93, 94], [95, 104], [105, 108], [109, 116], [117, 127], [128, 131], [132, 141], [142, 151], [152, 165], [166, 171], [172, 173], [173, 180], [181, 192], [193, 197], [198, 204], [204, 205], [205, 206]]}
{"doc_key": "ai-dev-52", "ner": [[8, 11, "algorithm"], [13, 13, "misc"], [15, 16, "misc"], [18, 18, "misc"], [20, 20, "programlang"], [22, 22, "product"], [27, 28, "algorithm"], [30, 31, "misc"], [33, 33, "misc"], [35, 35, "misc"], [37, 37, "misc"], [44, 44, "misc"], [45, 47, "misc"], [49, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "a", "rich", "feature", "set", ",", "libraries", "for", "constraint", "logic", "programming", ",", "multithreading", ",", "unit", "testing", ",", "GUI", ",", "Java", ",", "ODBC", "and", "other", "interfaces", ",", "scriptable", "programming", ",", "web", "server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "development", "tools", "(", "including", "an", "IDE", "with", "GUI", "debugger", "and", "GUI", "profiler", ")", ",", "and", "extensive", "documentation", "."], "sentence-detokenized": "It has a rich feature set, libraries for constraint logic programming, multithreading, unit testing, GUI, Java, ODBC and other interfaces, scriptable programming, web server, SGML, RDF, RDFS, development tools (including an IDE with GUI debugger and GUI profiler), and extensive documentation.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 13], [14, 21], [22, 25], [25, 26], [27, 36], [37, 40], [41, 51], [52, 57], [58, 69], [69, 70], [71, 85], [85, 86], [87, 91], [92, 99], [99, 100], [101, 104], [104, 105], [106, 110], [110, 111], [112, 116], [117, 120], [121, 126], [127, 137], [137, 138], [139, 149], [150, 161], [161, 162], [163, 166], [167, 173], [173, 174], [175, 179], [179, 180], [181, 184], [184, 185], [186, 190], [190, 191], [192, 203], [204, 209], [210, 211], [211, 220], [221, 223], [224, 227], [228, 232], [233, 236], [237, 245], [246, 249], [250, 253], [254, 262], [262, 263], [263, 264], [265, 268], [269, 278], [279, 292], [292, 293]]}
{"doc_key": "ai-dev-53", "ner": [[1, 2, "field"], [4, 7, "field"], [10, 12, "misc"], [14, 17, "misc"], [20, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 1, 2, "part-of", "", true, false], [10, 12, 4, 7, "part-of", "", false, false], [10, 12, 20, 24, "type-of", "", false, false], [14, 17, 1, 2, "part-of", "", false, false], [14, 17, 4, 7, "part-of", "", false, false], [14, 17, 20, 24, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "computer", "vision", "and", "image", "processing", ",", "the", "concepts", "of", "scaled", "spatial", "representation", "and", "Gaussian", "-", "derived", "operators", "are", "represented", "as", "canonical", "multi", "-scale", "representations", "."], "sentence-detokenized": "In computer vision and image processing, the concepts of scaled spatial representation and Gaussian-derived operators are represented as canonical multi-scale representations.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 22], [23, 28], [29, 39], [39, 40], [41, 44], [45, 53], [54, 56], [57, 63], [64, 71], [72, 86], [87, 90], [91, 99], [99, 100], [100, 107], [108, 117], [118, 121], [122, 133], [134, 136], [137, 146], [147, 152], [152, 158], [159, 174], [174, 175]]}
{"doc_key": "ai-dev-54", "ner": [[7, 11, "organisation"], [20, 24, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 11, 20, 24, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "also", "the", "President", "of", "the", "Neural", "Information", "Processing", "Systems", "Foundation", ",", "a", "non-profit", "organisation", "that", "oversees", "the", "annual", "Neural", "Information", "Processing", "Systems", "Conference", "."], "sentence-detokenized": "He is also the President of the Neural Information Processing Systems Foundation, a non-profit organisation that oversees the annual Neural Information Processing Systems Conference.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 14], [15, 24], [25, 27], [28, 31], [32, 38], [39, 50], [51, 61], [62, 69], [70, 80], [80, 81], [82, 83], [84, 94], [95, 107], [108, 112], [113, 121], [122, 125], [126, 132], [133, 139], [140, 151], [152, 162], [163, 170], [171, 181], [181, 182]]}
{"doc_key": "ai-dev-55", "ner": [[1, 2, "task"], [6, 7, "metrics"], [11, 14, "misc"], [17, 18, "task"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 6, 7, "usage", "", false, false], [6, 7, 11, 14, "type-of", "", false, false], [17, 18, 20, 20, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["For", "regression", "analysis", "problems", ",", "the", "squared", "error", "can", "be", "used", "as", "a", "loss", "function", ",", "and", "for", "classification", ",", "cross-entropy", "."], "sentence-detokenized": "For regression analysis problems, the squared error can be used as a loss function, and for classification, cross-entropy.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 32], [32, 33], [34, 37], [38, 45], [46, 51], [52, 55], [56, 58], [59, 63], [64, 66], [67, 68], [69, 73], [74, 82], [82, 83], [84, 87], [88, 91], [92, 106], [106, 107], [108, 121], [121, 122]]}
{"doc_key": "ai-dev-56", "ner": [[0, 0, "researcher"], [19, 24, "conference"], [34, 35, "university"], [38, 39, "field"], [48, 52, "conference"]], "ner_mapping_to_source": [0, 2, 3, 4, 5], "relations": [[0, 0, 34, 35, "physical", "", false, false], [0, 0, 34, 35, "role", "", false, false], [0, 0, 48, 52, "role", "", false, false], [34, 35, 38, 39, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [1, 2, 3, 5], "sentence": ["Lafferty", "has", "held", "a", "number", "of", "prestigious", "positions", ",", "including", ":", "co", "-chair", "and", "general", "co-chair", "of", "the", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", ")", "Foundation", "Conferences", "program", ";", "2", ")", "co-director", "of", "CMU", "'s", "new", "PhD", "machine", "learning", "doctoral", "program", ";", "3", ")", "co-editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research", "."], "sentence-detokenized": "Lafferty has held a number of prestigious positions, including: co-chair and general co-chair of the (Conference on Neural Information Processing Systems) Foundation Conferences program; 2) co-director of CMU's new PhD machine learning doctoral program; 3) co-editor of the Journal of Machine Learning Research.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 19], [20, 26], [27, 29], [30, 41], [42, 51], [51, 52], [53, 62], [62, 63], [64, 66], [66, 72], [73, 76], [77, 84], [85, 93], [94, 96], [97, 100], [101, 102], [102, 112], [113, 115], [116, 122], [123, 134], [135, 145], [146, 153], [153, 154], [155, 165], [166, 177], [178, 185], [185, 186], [187, 188], [188, 189], [190, 201], [202, 204], [205, 208], [208, 210], [211, 214], [215, 218], [219, 226], [227, 235], [236, 244], [245, 252], [252, 253], [254, 255], [255, 256], [257, 266], [267, 269], [270, 273], [274, 281], [282, 284], [285, 292], [293, 301], [302, 310], [310, 311]]}
{"doc_key": "ai-dev-57", "ner": [[0, 1, "misc"], [5, 5, "algorithm"], [7, 7, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 1, "type-of", "", false, false], [7, 7, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Convex", "algorithms", ",", "such", "as", "AdaBoost", "and", "LogitBoost", ",", "can", "be", "overwhelmed", "by", "random", "noise", ",", "and", "thus", "fail", "to", "learn", "basic", "and", "learnable", "combinations", "of", "weak", "hypotheses", "."], "sentence-detokenized": "Convex algorithms, such as AdaBoost and LogitBoost, can be overwhelmed by random noise, and thus fail to learn basic and learnable combinations of weak hypotheses.", "token2charspan": [[0, 6], [7, 17], [17, 18], [19, 23], [24, 26], [27, 35], [36, 39], [40, 50], [50, 51], [52, 55], [56, 58], [59, 70], [71, 73], [74, 80], [81, 86], [86, 87], [88, 91], [92, 96], [97, 101], [102, 104], [105, 110], [111, 116], [117, 120], [121, 130], [131, 143], [144, 146], [147, 151], [152, 162], [162, 163]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [3, 9, "product"], [11, 14, "algorithm"], [21, 21, "algorithm"], [24, 28, "task"], [31, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 9, "type-of", "", false, false], [0, 0, 11, 14, "usage", "", false, false], [0, 0, 21, 21, "usage", "", false, false], [21, 21, 24, 28, "related-to", "used_for", true, false], [21, 21, 31, 35, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "is", "a", "shallow", "-", "translation", "machine", "translation", "system", "that", "uses", "finite", "-", "state", "transducers", "for", "all", "lexical", "transformations", ",", "and", "hidden", "Markov", "models", "to", "label", "parts", "of", "speech", "or", "to", "resolve", "word", "-", "genre", "categories", "."], "sentence-detokenized": "Apertium is a shallow-translation machine translation system that uses finite-state transducers for all lexical transformations, and hidden Markov models to label parts of speech or to resolve word-genre categories.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 21], [21, 22], [22, 33], [34, 41], [42, 53], [54, 60], [61, 65], [66, 70], [71, 77], [77, 78], [78, 83], [84, 95], [96, 99], [100, 103], [104, 111], [112, 127], [127, 128], [129, 132], [133, 139], [140, 146], [147, 153], [154, 156], [157, 162], [163, 168], [169, 171], [172, 178], [179, 181], [182, 184], [185, 192], [193, 197], [197, 198], [198, 203], [204, 214], [214, 215]]}
{"doc_key": "ai-dev-59", "ner": [[1, 3, "misc"], [16, 18, "metrics"], [30, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 3, 16, 18, "related-to", "", true, false], [16, 18, 30, 32, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "natural", "gradient", "of", "mathE", "f", "(", "x", ")", "/", "math", ",", "which", "corresponds", "to", "the", "Fisher", "information", "metric", "(", "the", "information", "distance", "measure", "between", "probability", "distributions", "and", "the", "curve", "of", "relative", "entropy", ")", ",", "is", "now"], "sentence-detokenized": "The natural gradient of mathE f (x) / math, which corresponds to the Fisher information metric (the information distance measure between probability distributions and the curve of relative entropy), is now", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 23], [24, 29], [30, 31], [32, 33], [33, 34], [34, 35], [36, 37], [38, 42], [42, 43], [44, 49], [50, 61], [62, 64], [65, 68], [69, 75], [76, 87], [88, 94], [95, 96], [96, 99], [100, 111], [112, 120], [121, 128], [129, 136], [137, 148], [149, 162], [163, 166], [167, 170], [171, 176], [177, 179], [180, 188], [189, 196], [196, 197], [197, 198], [199, 201], [202, 205]]}
{"doc_key": "ai-dev-60", "ner": [[1, 3, "programlang"], [6, 9, "product"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 1, 3, "origin", "", false, false], [11, 11, 1, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "S", "programming", "language", "inspired", "the", "S", "'", "-", "PLUS", "and", "R", "systems", "."], "sentence-detokenized": "The S programming language inspired the S '-PLUS and R systems.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 26], [27, 35], [36, 39], [40, 41], [42, 43], [43, 44], [44, 48], [49, 52], [53, 54], [55, 62], [62, 63]]}
{"doc_key": "ai-dev-61", "ner": [[5, 5, "product"], [10, 10, "product"], [12, 14, "product"], [18, 20, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 10, 10, "named", "same", false, false], [12, 14, 10, 10, "origin", "derived_from", false, false], [12, 14, 18, 20, "origin", "", false, false], [12, 14, 22, 23, "origin", "", false, false], [12, 14, 25, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "most", "influential", "implementation", "of", "Planner", "was", "a", "subset", "of", "Planner", "called", "Micro", "-", "Planner", ",", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "."], "sentence-detokenized": "The most influential implementation of Planner was a subset of Planner called Micro-Planner, implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 35], [36, 38], [39, 46], [47, 50], [51, 52], [53, 59], [60, 62], [63, 70], [71, 77], [78, 83], [83, 84], [84, 91], [91, 92], [93, 104], [105, 107], [108, 114], [115, 118], [119, 126], [126, 127], [128, 134], [135, 143], [144, 147], [148, 153], [154, 162], [162, 163]]}
{"doc_key": "ai-dev-62", "ner": [[4, 6, "country"], [8, 10, "researcher"], [20, 20, "misc"], [21, 26, "university"], [33, 36, "misc"], [41, 41, "misc"], [46, 48, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[8, 10, 4, 6, "general-affiliation", "from_country", false, false], [21, 26, 20, 20, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1779", ",", "the", "German", "-", "Danish", "scientist", "Christian", "Gottlieb", "Kratzenstein", "won", "first", "prize", "in", "a", "competition", "organised", "by", "the", "Russian", "Imperial", "Academy", "of", "Sciences", "and", "Arts", "for", "his", "model", "of", "a", "human", "vocal", "cord", "capable", "of", "producing", "the", "five", "long", "vowels", "(", "nominated", "by", "the", "International", "Phonetic", "Alphabet", ":"], "sentence-detokenized": "In 1779, the German-Danish scientist Christian Gottlieb Kratzenstein won first prize in a competition organised by the Russian Imperial Academy of Sciences and Arts for his model of a human vocal cord capable of producing the five long vowels (nominated by the International Phonetic Alphabet:", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [19, 20], [20, 26], [27, 36], [37, 46], [47, 55], [56, 68], [69, 72], [73, 78], [79, 84], [85, 87], [88, 89], [90, 101], [102, 111], [112, 114], [115, 118], [119, 126], [127, 135], [136, 143], [144, 146], [147, 155], [156, 159], [160, 164], [165, 168], [169, 172], [173, 178], [179, 181], [182, 183], [184, 189], [190, 195], [196, 200], [201, 208], [209, 211], [212, 221], [222, 225], [226, 230], [231, 235], [236, 242], [243, 244], [244, 253], [254, 256], [257, 260], [261, 274], [275, 283], [284, 292], [292, 293]]}
{"doc_key": "ai-dev-63", "ner": [[2, 4, "product"], [6, 7, "misc"], [10, 14, "misc"], [32, 34, "misc"], [53, 54, "task"], [59, 60, "product"], [62, 62, "product"], [66, 66, "task"], [68, 69, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 4, 59, 60, "related-to", "supports_program", false, false], [2, 4, 62, 62, "related-to", "supports_program", false, false], [6, 7, 2, 4, "part-of", "", false, false], [10, 14, 2, 4, "part-of", "", false, false], [32, 34, 2, 4, "part-of", "", false, false], [53, 54, 2, 4, "part-of", "", false, false], [66, 66, 2, 4, "part-of", "", false, false], [68, 69, 2, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["New", "features", "in", "Office", "XP", "include", "smart", "tags", ",", "a", "selection", "-", "based", "search", "function", "that", "recognizes", "different", "types", "of", "text", "in", "a", "document", "so", "users", "can", "perform", "additional", "actions", ";", "a", "taskbar", "interface", "that", "summarizes", "popular", "menu", "bar", "commands", "on", "the", "right", "side", "of", "the", "screen", "to", "facilitate", "quick", "access", ";", "new", "document", "collaboration", "options", ",", "support", "for", "MSN", "Groups", "and", "SharePoint", ";", "and", "integrated", "handwriting", "and", "speech", "recognition", "features", "."], "sentence-detokenized": "New features in Office XP include smart tags, a selection-based search function that recognizes different types of text in a document so users can perform additional actions; a taskbar interface that summarizes popular menu bar commands on the right side of the screen to facilitate quick access; new document collaboration options, support for MSN Groups and SharePoint; and integrated handwriting and speech recognition features.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 25], [26, 33], [34, 39], [40, 44], [44, 45], [46, 47], [48, 57], [57, 58], [58, 63], [64, 70], [71, 79], [80, 84], [85, 95], [96, 105], [106, 111], [112, 114], [115, 119], [120, 122], [123, 124], [125, 133], [134, 136], [137, 142], [143, 146], [147, 154], [155, 165], [166, 173], [173, 174], [175, 176], [177, 184], [185, 194], [195, 199], [200, 210], [211, 218], [219, 223], [224, 227], [228, 236], [237, 239], [240, 243], [244, 249], [250, 254], [255, 257], [258, 261], [262, 268], [269, 271], [272, 282], [283, 288], [289, 295], [295, 296], [297, 300], [301, 309], [310, 323], [324, 331], [331, 332], [333, 340], [341, 344], [345, 348], [349, 355], [356, 359], [360, 370], [370, 371], [372, 375], [376, 386], [387, 398], [399, 402], [403, 409], [410, 421], [422, 430], [430, 431]]}
{"doc_key": "ai-dev-64", "ner": [[9, 11, "algorithm"], [12, 15, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 12, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "many", "applications", ",", "units", "of", "these", "networks", "use", "a", "sigmoid", "function", "as", "the", "activation", "function", "."], "sentence-detokenized": "In many applications, units of these networks use a sigmoid function as the activation function.", "token2charspan": [[0, 2], [3, 7], [8, 20], [20, 21], [22, 27], [28, 30], [31, 36], [37, 45], [46, 49], [50, 51], [52, 59], [60, 68], [69, 71], [72, 75], [76, 86], [87, 95], [95, 96]]}
{"doc_key": "ai-dev-65", "ner": [[3, 3, "researcher"], [12, 17, "organisation"], [30, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 12, 17, "role", "", false, false], [3, 3, 30, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2001", ",", "Mehler", "was", "elected", "an", "Honorary", "Foreign", "Member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "in", "2003", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In 2001, Mehler was elected an Honorary Foreign Member of the American Academy of Arts and Sciences and in 2003, he was elected a Fellow of the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 27], [28, 30], [31, 39], [40, 47], [48, 54], [55, 57], [58, 61], [62, 70], [71, 78], [79, 81], [82, 86], [87, 90], [91, 99], [100, 103], [104, 106], [107, 111], [111, 112], [113, 115], [116, 119], [120, 127], [128, 129], [130, 136], [137, 139], [140, 143], [144, 152], [153, 164], [165, 168], [169, 172], [173, 184], [185, 187], [188, 195], [195, 196]]}
{"doc_key": "ai-dev-66", "ner": [[5, 8, "task"], [12, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 8, 12, 13, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "extension", "of", "this", "concept", "to", "non", "-binary", "classifications", "results", "in", "the", "confusion", "matrix", "."], "sentence-detokenized": "An extension of this concept to non-binary classifications results in the confusion matrix.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 20], [21, 28], [29, 31], [32, 35], [35, 42], [43, 58], [59, 66], [67, 69], [70, 73], [74, 83], [84, 90], [90, 91]]}
{"doc_key": "ai-dev-67", "ner": [[1, 3, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["From", "the", "maximum", "likelihood", "calculation", ",", "an", "updated", "measurement", "noise", "variance", "estimate", "can", "be", "obtained", "."], "sentence-detokenized": "From the maximum likelihood calculation, an updated measurement noise variance estimate can be obtained.", "token2charspan": [[0, 4], [5, 8], [9, 16], [17, 27], [28, 39], [39, 40], [41, 43], [44, 51], [52, 63], [64, 69], [70, 78], [79, 87], [88, 91], [92, 94], [95, 103], [103, 104]]}
{"doc_key": "ai-dev-68", "ner": [[0, 2, "field"], [5, 6, "algorithm"], [10, 10, "field"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 10, 10, "usage", "", true, false], [5, 6, 13, 14, "related-to", "", true, false], [10, 10, 0, 2, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "machine", "learning", ",", "a", "perceptron", "is", "an", "algorithm", "for", "supervised", "learning", "of", "binary", "classifications", "."], "sentence-detokenized": "In machine learning, a perceptron is an algorithm for supervised learning of binary classifications.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 22], [23, 33], [34, 36], [37, 39], [40, 49], [50, 53], [54, 64], [65, 73], [74, 76], [77, 83], [84, 99], [99, 100]]}
{"doc_key": "ai-dev-69", "ner": [[11, 12, "field"], [14, 14, "field"], [18, 23, "conference"], [25, 29, "conference"], [31, 37, "conference"], [39, 43, "conference"], [46, 50, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[18, 23, 11, 12, "topic", "", false, false], [18, 23, 14, 14, "topic", "", false, false], [25, 29, 11, 12, "topic", "", false, false], [25, 29, 14, 14, "topic", "", false, false], [31, 37, 11, 12, "topic", "", false, false], [31, 37, 14, 14, "topic", "", false, false], [39, 43, 11, 12, "topic", "", false, false], [39, 43, 14, 14, "topic", "", false, false], [46, 50, 11, 12, "topic", "", false, false], [46, 50, 14, 14, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["He", "has", "also", "served", "as", "regional", "chair", "of", "several", "conferences", "on", "machine", "learning", "and", "vision", ",", "including", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "International", "Conference", "on", "Learning", "Representations", ",", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "International", "Conference", "on", "Computer", "Vision", ",", "and", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "He has also served as regional chair of several conferences on machine learning and vision, including the Conference on Neural Information Processing Systems, International Conference on Learning Representations, Conference on Computer Vision and Pattern Recognition, International Conference on Computer Vision, and European Conference on Computer Vision.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 21], [22, 30], [31, 36], [37, 39], [40, 47], [48, 59], [60, 62], [63, 70], [71, 79], [80, 83], [84, 90], [90, 91], [92, 101], [102, 105], [106, 116], [117, 119], [120, 126], [127, 138], [139, 149], [150, 157], [157, 158], [159, 172], [173, 183], [184, 186], [187, 195], [196, 211], [211, 212], [213, 223], [224, 226], [227, 235], [236, 242], [243, 246], [247, 254], [255, 266], [266, 267], [268, 281], [282, 292], [293, 295], [296, 304], [305, 311], [311, 312], [313, 316], [317, 325], [326, 336], [337, 339], [340, 348], [349, 355], [355, 356]]}
{"doc_key": "ai-dev-70", "ner": [[1, 2, "algorithm"], [7, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 1, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "compression", "algorithm", "has", "also", "been", "used", "for", "face", "recognition", "in", "video", "sequences", "."], "sentence-detokenized": "The compression algorithm has also been used for face recognition in video sequences.", "token2charspan": [[0, 3], [4, 15], [16, 25], [26, 29], [30, 34], [35, 39], [40, 44], [45, 48], [49, 53], [54, 65], [66, 68], [69, 74], [75, 84], [84, 85]]}
{"doc_key": "ai-dev-71", "ner": [[0, 2, "task"], [6, 6, "organisation"], [16, 16, "conference"], [20, 24, "academicjournal"], [28, 28, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 16, 0, 2, "topic", "", false, false], [16, 16, 6, 6, "origin", "", false, false], [20, 24, 0, 2, "topic", "", false, false], [20, 24, 6, 6, "origin", "", true, false], [28, 28, 20, 24, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Information", "dissemination", "is", "also", "part", "of", "ELRA", "'s", "mission", ",", "which", "is", "carried", "out", "through", "the", "LREC", "conference", "and", "the", "Language", "Resources", "and", "Evaluation", "Journal", ",", "edited", "by", "Springer", "."], "sentence-detokenized": "Information dissemination is also part of ELRA's mission, which is carried out through the LREC conference and the Language Resources and Evaluation Journal, edited by Springer.", "token2charspan": [[0, 11], [12, 25], [26, 28], [29, 33], [34, 38], [39, 41], [42, 46], [46, 48], [49, 56], [56, 57], [58, 63], [64, 66], [67, 74], [75, 78], [79, 86], [87, 90], [91, 95], [96, 106], [107, 110], [111, 114], [115, 123], [124, 133], [134, 137], [138, 148], [149, 156], [156, 157], [158, 164], [165, 167], [168, 176], [176, 177]]}
{"doc_key": "ai-dev-72", "ner": [[0, 8, "field"], [10, 11, "field"], [13, 15, "field"], [17, 53, "field"], [54, 56, "field"], [60, 60, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 8, 54, 56, "named", "", false, false], [13, 15, 0, 8, "named", "", false, false], [60, 60, 10, 11, "part-of", "", true, false], [60, 60, 13, 15, "part-of", "", true, false], [60, 60, 54, 56, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "linear", "time", "invariant", "(", "LTI", ")", "systems", "theory", ",", "control", "theory", "and", "digital", "signal", "processing", "or", "signal", "processing", ",", "the", "relationship", "between", "the", "input", "signal", ",", "math", "\\", "displaystyle", "x", "(", "t", ")", "/", "math", ",", "and", "the", "output", "signal", ",", "math", "\\", "displaystyle", "y", "(", "t", ")", "/", "math", ",", "of", "an", "LTI", "system", "is", "governed", "by", "the", "convolution", "operation", ":"], "sentence-detokenized": "In linear time invariant (LTI) systems theory, control theory and digital signal processing or signal processing, the relationship between the input signal, math\\ displaystyle x(t)/math, and the output signal, math\\ displaystyle y(t)/math, of an LTI system is governed by the convolution operation:", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 24], [25, 26], [26, 29], [29, 30], [31, 38], [39, 45], [45, 46], [47, 54], [55, 61], [62, 65], [66, 73], [74, 80], [81, 91], [92, 94], [95, 101], [102, 112], [112, 113], [114, 117], [118, 130], [131, 138], [139, 142], [143, 148], [149, 155], [155, 156], [157, 161], [161, 162], [163, 175], [176, 177], [177, 178], [178, 179], [179, 180], [180, 181], [181, 185], [185, 186], [187, 190], [191, 194], [195, 201], [202, 208], [208, 209], [210, 214], [214, 215], [216, 228], [229, 230], [230, 231], [231, 232], [232, 233], [233, 234], [234, 238], [238, 239], [240, 242], [243, 245], [246, 249], [250, 256], [257, 259], [260, 268], [269, 271], [272, 275], [276, 287], [288, 297], [297, 298]]}
{"doc_key": "ai-dev-73", "ner": [[17, 18, "field"], [20, 21, "field"], [23, 24, "field"], [26, 27, "field"], [29, 32, "field"], [34, 35, "product"], [37, 38, "field"], [40, 40, "field"], [42, 43, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Because", "of", "its", "generality", ",", "the", "field", "is", "also", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multiobjective", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Because of its generality, the field is also studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimisation, multiobjective systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [25, 26], [27, 30], [31, 36], [37, 39], [40, 44], [45, 52], [53, 55], [56, 60], [61, 66], [67, 78], [78, 79], [80, 84], [85, 87], [88, 92], [93, 99], [99, 100], [101, 108], [109, 115], [115, 116], [117, 127], [128, 136], [136, 137], [138, 149], [150, 156], [156, 157], [158, 168], [168, 169], [169, 174], [175, 187], [187, 188], [189, 203], [204, 211], [211, 212], [213, 218], [219, 231], [231, 232], [233, 243], [244, 247], [248, 255], [256, 266], [266, 267]]}
{"doc_key": "ai-dev-74", "ner": [[0, 4, "algorithm"], [14, 16, "field"], [22, 23, "algorithm"], [26, 27, "algorithm"], [31, 32, "algorithm"], [35, 35, "algorithm"], [36, 38, "researcher"], [40, 41, "researcher"], [43, 45, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[14, 16, 0, 4, "usage", "", true, false], [22, 23, 14, 16, "part-of", "", true, false], [26, 27, 14, 16, "part-of", "", true, false], [31, 32, 14, 16, "part-of", "", true, false], [35, 35, 14, 16, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Stochastic", "gradient", "descent", "is", "a", "popular", "algorithm", "for", "training", "a", "wide", "range", "of", "models", "in", "machine", "learning", ",", "including", "(", "linear", ")", "support", "vector", "machines", ",", "logistic", "regression", "(", "see", "e.g.", "Vowpal", "Wabbit", ")", "and", "graphical", "models.Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastic gradient descent is a popular algorithm for training a wide range of models in machine learning, including (linear) support vector machines, logistic regression (see e.g. Vowpal Wabbit) and graphical models.Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 30], [31, 32], [33, 40], [41, 50], [51, 54], [55, 63], [64, 65], [66, 70], [71, 76], [77, 79], [80, 86], [87, 89], [90, 97], [98, 106], [106, 107], [108, 117], [118, 119], [119, 125], [125, 126], [127, 134], [135, 141], [142, 150], [150, 151], [152, 160], [161, 171], [172, 173], [173, 176], [177, 181], [182, 188], [189, 195], [195, 196], [197, 200], [201, 210], [211, 223], [224, 228], [229, 235], [235, 236], [237, 241], [242, 249], [249, 250], [251, 262], [263, 265], [266, 273], [274, 275], [275, 279], [279, 280], [280, 281]]}
{"doc_key": "ai-dev-75", "ner": [[8, 8, "organisation"], [12, 13, "product"], [17, 17, "country"], [20, 22, "university"], [23, 24, "location"], [26, 29, "university"], [30, 30, "location"], [32, 33, "university"], [34, 35, "location"], [37, 40, "university"], [41, 41, "location"], [43, 44, "university"], [45, 46, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 20, 22, "role", "donates_to", false, false], [8, 8, 26, 29, "role", "donates_to", false, false], [8, 8, 32, 33, "role", "donates_to", false, false], [8, 8, 37, 40, "role", "donates_to", false, false], [8, 8, 43, 44, "role", "donates_to", false, false], [12, 13, 8, 8, "origin", "donates", true, false], [20, 22, 23, 24, "physical", "", false, false], [23, 24, 17, 17, "physical", "", false, false], [26, 29, 30, 30, "physical", "", false, false], [30, 30, 17, 17, "physical", "", false, false], [32, 33, 34, 35, "physical", "", false, false], [34, 35, 17, 17, "physical", "", false, false], [37, 40, 41, 41, "physical", "", false, false], [41, 41, 17, 17, "physical", "", false, false], [43, 44, 45, 46, "physical", "", false, false], [45, 46, 17, 17, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["In", "August", "2011", ",", "it", "was", "announced", "that", "Hitachi", "would", "donate", "one", "electron", "microscope", "each", "to", "five", "Indonesian", "universities", "(", "North", "Sumatra", "University", "in", "Medan", ",", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Padjadjaran", "University", "in", "Bandung", ",", "Jenderal", "Soedirman", "University", "in", "Purwokerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "sentence-detokenized": "In August 2011, it was announced that Hitachi would donate one electron microscope each to five Indonesian universities (North Sumatra University in Medan, Indonesian Christian University in Jakarta, Padjadjaran University in Bandung, Jenderal Soedirman University in Purwokerto and Muhammadiyah University in Malang).", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 32], [33, 37], [38, 45], [46, 51], [52, 58], [59, 62], [63, 71], [72, 82], [83, 87], [88, 90], [91, 95], [96, 106], [107, 119], [120, 121], [121, 126], [127, 134], [135, 145], [146, 148], [149, 154], [154, 155], [156, 166], [167, 176], [177, 187], [188, 190], [191, 198], [198, 199], [200, 211], [212, 222], [223, 225], [226, 233], [233, 234], [235, 243], [244, 253], [254, 264], [265, 267], [268, 278], [279, 282], [283, 295], [296, 306], [307, 309], [310, 316], [316, 317], [317, 318]]}
{"doc_key": "ai-dev-76", "ner": [[0, 0, "field"], [3, 4, "field"], [8, 9, "algorithm"], [11, 14, "algorithm"], [21, 22, "field"], [24, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 4, "part-of", "", false, false], [0, 0, 21, 22, "related-to", "", true, false], [0, 0, 24, 28, "related-to", "", true, false], [8, 9, 0, 0, "type-of", "", false, false], [11, 14, 0, 0, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Optimization", "techniques", "from", "operations", "research", ",", "such", "as", "linear", "programming", "or", "dynamic", "programming", ",", "are", "often", "impractical", "for", "large", "-", "scale", "software", "development", "problems", "because", "of", "their", "computational", "complexity", "."], "sentence-detokenized": "Optimization techniques from operations research, such as linear programming or dynamic programming, are often impractical for large-scale software development problems because of their computational complexity.", "token2charspan": [[0, 12], [13, 23], [24, 28], [29, 39], [40, 48], [48, 49], [50, 54], [55, 57], [58, 64], [65, 76], [77, 79], [80, 87], [88, 99], [99, 100], [101, 104], [105, 110], [111, 122], [123, 126], [127, 132], [132, 133], [133, 138], [139, 147], [148, 159], [160, 168], [169, 176], [177, 179], [180, 185], [186, 199], [200, 210], [210, 211]]}
{"doc_key": "ai-dev-77", "ner": [[0, 1, "metrics"], [6, 6, "metrics"], [8, 10, "metrics"], [15, 17, "metrics"], [22, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 6, "compare", "", false, false], [0, 1, 8, 10, "compare", "", false, false], [15, 17, 8, 10, "part-of", "", false, false], [22, 26, 8, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sensitivity", "is", "not", "the", "same", "as", "precision", "or", "positive", "predictive", "value", "(", "the", "proportion", "of", "TRUE", "positive", "results", "compared", "to", "the", "combined", "TRUE", "and", "HAMIS", "positive", "results", ")", ",", "which", "is", "as", "much", "about", "the", "proportion", "of", "true", "positives", "in", "the", "population", "tested", "as", "it", "is", "about", "the", "test", "."], "sentence-detokenized": "Sensitivity is not the same as precision or positive predictive value (the proportion of TRUE positive results compared to the combined TRUE and HAMIS positive results), which is as much about the proportion of true positives in the population tested as it is about the test.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 22], [23, 27], [28, 30], [31, 40], [41, 43], [44, 52], [53, 63], [64, 69], [70, 71], [71, 74], [75, 85], [86, 88], [89, 93], [94, 102], [103, 110], [111, 119], [120, 122], [123, 126], [127, 135], [136, 140], [141, 144], [145, 150], [151, 159], [160, 167], [167, 168], [168, 169], [170, 175], [176, 178], [179, 181], [182, 186], [187, 192], [193, 196], [197, 207], [208, 210], [211, 215], [216, 225], [226, 228], [229, 232], [233, 243], [244, 250], [251, 253], [254, 256], [257, 259], [260, 265], [266, 269], [270, 274], [274, 275]]}
{"doc_key": "ai-dev-78", "ner": [[0, 1, "person"], [8, 8, "product"], [11, 11, "person"], [26, 26, "person"], [33, 34, "person"], [39, 40, "person"], [45, 46, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 39, 40, "named", "same", false, false], [8, 8, 0, 1, "artifact", "", false, false], [33, 34, 45, 46, "role", "convinces", false, false], [45, 46, 8, 8, "role", "producer", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Hampton", "Fancher", "'s", "script", "--", "not", "originally", "titled", "Android", "-", "see", "Sammon", ",", "pp.", "32", "and", "38", "for", "an", "explanation", "--", "was", "optioned", "in", "1977", ".", "Sammon", ",", "pp.", "23", "-", "30", "Producer", "Michael", "Deeley", "took", "an", "interest", "in", "Fancher", "'s", "draft", "and", "convinced", "director", "Ridley", "Scott", "to", "film", "it", "."], "sentence-detokenized": "Hampton Fancher's script -- not originally titled Android - see Sammon, pp. 32 and 38 for an explanation -- was optioned in 1977. Sammon, pp. 23-30 Producer Michael Deeley took an interest in Fancher's draft and convinced director Ridley Scott to film it.", "token2charspan": [[0, 7], [8, 15], [15, 17], [18, 24], [25, 27], [28, 31], [32, 42], [43, 49], [50, 57], [58, 59], [60, 63], [64, 70], [70, 71], [72, 75], [76, 78], [79, 82], [83, 85], [86, 89], [90, 92], [93, 104], [105, 107], [108, 111], [112, 120], [121, 123], [124, 128], [128, 129], [130, 136], [136, 137], [138, 141], [142, 144], [144, 145], [145, 147], [148, 156], [157, 164], [165, 171], [172, 176], [177, 179], [180, 188], [189, 191], [192, 199], [199, 201], [202, 207], [208, 211], [212, 221], [222, 230], [231, 237], [238, 243], [244, 246], [247, 251], [252, 254], [254, 255]]}
{"doc_key": "ai-dev-79", "ner": [[0, 1, "field"], [3, 4, "task"], [6, 7, "task"], [11, 14, "misc"], [16, 17, "field"], [19, 21, "task"], [23, 24, "task"], [26, 27, "field"], [30, 33, "task"], [35, 35, "task"], [37, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [6, 7, 0, 1, "part-of", "", false, false], [11, 14, 0, 1, "part-of", "", false, false], [16, 17, 0, 1, "part-of", "", false, false], [19, 21, 0, 1, "part-of", "", false, false], [23, 24, 0, 1, "part-of", "", false, false], [26, 27, 0, 1, "part-of", "", false, false], [30, 33, 0, 1, "part-of", "", false, false], [35, 35, 0, 1, "part-of", "", false, false], [37, 38, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Text", "analysis", "involves", "information", "retrieval", ",", "lexical", "analysis", "to", "study", "the", "frequency", "distribution", "of", "words", ",", "pattern", "recognition", ",", "tagging", "/", "annotation", ",", "information", "extraction", ",", "data", "mining", "techniques", "including", "relationship", "and", "association", "analysis", ",", "visualisation", "and", "predictive", "analysis", "."], "sentence-detokenized": "Text analysis involves information retrieval, lexical analysis to study the frequency distribution of words, pattern recognition, tagging/annotation, information extraction, data mining techniques including relationship and association analysis, visualisation and predictive analysis.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 34], [35, 44], [44, 45], [46, 53], [54, 62], [63, 65], [66, 71], [72, 75], [76, 85], [86, 98], [99, 101], [102, 107], [107, 108], [109, 116], [117, 128], [128, 129], [130, 137], [137, 138], [138, 148], [148, 149], [150, 161], [162, 172], [172, 173], [174, 178], [179, 185], [186, 196], [197, 206], [207, 219], [220, 223], [224, 235], [236, 244], [244, 245], [246, 259], [260, 263], [264, 274], [275, 283], [283, 284]]}
{"doc_key": "ai-dev-80", "ner": [[3, 3, "product"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Many", "measures", "use", "WordNet", ",", "a", "manually", "edited", "lexical", "database", "of", "English", "words", "."], "sentence-detokenized": "Many measures use WordNet, a manually edited lexical database of English words.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 25], [25, 26], [27, 28], [29, 37], [38, 44], [45, 52], [53, 61], [62, 64], [65, 72], [73, 78], [78, 79]]}
{"doc_key": "ai-dev-81", "ner": [[6, 7, "field"], [9, 10, "task"], [12, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "system", "uses", "a", "combination", "of", "computational", "linguistics", ",", "information", "retrieval", "and", "knowledge", "representation", "techniques", "to", "find", "answers", "."], "sentence-detokenized": "The system uses a combination of computational linguistics, information retrieval and knowledge representation techniques to find answers.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 17], [18, 29], [30, 32], [33, 46], [47, 58], [58, 59], [60, 71], [72, 81], [82, 85], [86, 95], [96, 110], [111, 121], [122, 124], [125, 129], [130, 137], [137, 138]]}
{"doc_key": "ai-dev-82", "ner": [[0, 1, "metrics"], [11, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 11, 14, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Uncertainty", "coefficient", "as", "a", "performance", "measure", "has", "the", "advantage", "over", "simple", "accuracy", "that", "it", "is", "not", "affected", "by", "the", "relative", "size", "of", "different", "classes", "."], "sentence-detokenized": "Uncertainty coefficient as a performance measure has the advantage over simple accuracy that it is not affected by the relative size of different classes.", "token2charspan": [[0, 11], [12, 23], [24, 26], [27, 28], [29, 40], [41, 48], [49, 52], [53, 56], [57, 66], [67, 71], [72, 78], [79, 87], [88, 92], [93, 95], [96, 98], [99, 102], [103, 111], [112, 114], [115, 118], [119, 127], [128, 132], [133, 135], [136, 145], [146, 153], [153, 154]]}
{"doc_key": "ai-dev-83", "ner": [[8, 9, "algorithm"], [11, 12, "algorithm"], [14, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Researchers", "have", "tried", "many", "methods", ",", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "hidden", "Markov", "models", ",", "etc", "."], "sentence-detokenized": "Researchers have tried many methods, such as optical flow, Kalman filtering, hidden Markov models, etc.", "token2charspan": [[0, 11], [12, 16], [17, 22], [23, 27], [28, 35], [35, 36], [37, 41], [42, 44], [45, 52], [53, 57], [57, 58], [59, 65], [66, 75], [75, 76], [77, 83], [84, 90], [91, 97], [97, 98], [99, 102], [102, 103]]}
{"doc_key": "ai-dev-84", "ner": [[12, 16, "conference"], [29, 31, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "served", "as", "President", ",", "Vice", "-", "President", "and", "Treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "and", "as", "a", "member", "of", "the", "Board", "and", "Secretary", "of", "the", "Computing", "Research", "Association", "."], "sentence-detokenized": "He has served as President, Vice-President and Treasurer of the Association for Computational Linguistics, and as a member of the Board and Secretary of the Computing Research Association.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 26], [26, 27], [28, 32], [32, 33], [33, 42], [43, 46], [47, 56], [57, 59], [60, 63], [64, 75], [76, 79], [80, 93], [94, 105], [105, 106], [107, 110], [111, 113], [114, 115], [116, 122], [123, 125], [126, 129], [130, 135], [136, 139], [140, 149], [150, 152], [153, 156], [157, 166], [167, 175], [176, 187], [187, 188]]}
{"doc_key": "ai-dev-85", "ner": [[6, 6, "programlang"], [0, 8, "product"], [10, 10, "programlang"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 10, 10, "compare", "", false, false], [6, 6, 12, 13, "related-to", "supports", false, false], [0, 8, 10, 10, "compare", "", false, false], [0, 8, 12, 13, "related-to", "supports", false, false], [10, 10, 12, 13, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Like", "other", "similar", "languages", "such", "as", "APL", "and", "MATLAB", ",", "R", "supports", "matrix", "arithmetic", "."], "sentence-detokenized": "Like other similar languages such as APL and MATLAB, R supports matrix arithmetic.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 28], [29, 33], [34, 36], [37, 40], [41, 44], [45, 51], [51, 52], [53, 54], [55, 63], [64, 70], [71, 81], [81, 82]]}
{"doc_key": "ai-dev-86", "ner": [[8, 9, "misc"], [6, 7, "organisation"], [14, 15, "researcher"], [18, 20, "university"], [24, 29, "misc"], [34, 34, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 6, 7, "physical", "", false, false], [8, 9, 24, 29, "temporal", "", false, false], [14, 15, 8, 9, "role", "arranges", false, false], [14, 15, 18, 20, "role", "works_for", false, false], [34, 34, 8, 9, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "7", "June", "2014", ",", "the", "Royal", "Society", "Turing", "Test", "competition", ",", "organised", "by", "Kevin", "Warwick", "of", "the", "University", "of", "Reading", "to", "mark", "the", "60th", "anniversary", "of", "Turing", "'s", "death", ",", "was", "won", "by", "Goostman", "after", "33", "%", "of", "the", "judges", "were", "convinced", "that", "the", "robot", "was", "human", "."], "sentence-detokenized": "On 7 June 2014, the Royal Society Turing Test competition, organised by Kevin Warwick of the University of Reading to mark the 60th anniversary of Turing's death, was won by Goostman after 33% of the judges were convinced that the robot was human.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 14], [14, 15], [16, 19], [20, 25], [26, 33], [34, 40], [41, 45], [46, 57], [57, 58], [59, 68], [69, 71], [72, 77], [78, 85], [86, 88], [89, 92], [93, 103], [104, 106], [107, 114], [115, 117], [118, 122], [123, 126], [127, 131], [132, 143], [144, 146], [147, 153], [153, 155], [156, 161], [161, 162], [163, 166], [167, 170], [171, 173], [174, 182], [183, 188], [189, 191], [191, 192], [193, 195], [196, 199], [200, 206], [207, 211], [212, 221], [222, 226], [227, 230], [231, 236], [237, 240], [241, 246], [246, 247]]}
{"doc_key": "ai-dev-87", "ner": [[1, 2, "product"], [4, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "collaborative", "robot", "or", "cobot", "is", "a", "robot", "that", "can", "safely", "and", "efficiently", "interact", "with", "human", "workers", "while", "performing", "simple", "industrial", "tasks", "."], "sentence-detokenized": "A collaborative robot or cobot is a robot that can safely and efficiently interact with human workers while performing simple industrial tasks.", "token2charspan": [[0, 1], [2, 15], [16, 21], [22, 24], [25, 30], [31, 33], [34, 35], [36, 41], [42, 46], [47, 50], [51, 57], [58, 61], [62, 73], [74, 82], [83, 87], [88, 93], [94, 101], [102, 107], [108, 118], [119, 125], [126, 136], [137, 142], [142, 143]]}
{"doc_key": "ai-dev-88", "ner": [[11, 12, "field"], [16, 17, "task"], [19, 20, "task"], [22, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 32, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[16, 17, 11, 12, "part-of", "task_part_of_field", false, false], [19, 20, 11, 12, "part-of", "task_part_of_field", false, false], [22, 23, 11, 12, "part-of", "task_part_of_field", false, false], [25, 26, 11, 12, "part-of", "task_part_of_field", false, false], [28, 29, 11, 12, "part-of", "task_part_of_field", false, false], [31, 32, 11, 12, "part-of", "task_part_of_field", false, false], [35, 36, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "comprehensive", "framework", "has", "been", "applied", "to", "a", "wide", "range", "of", "computer", "vision", "problems", ",", "including", "feature", "detection", ",", "feature", "classification", ",", "image", "segmentation", ",", "image", "matching", ",", "motion", "estimation", ",", "shape", "computation", ",", "and", "object", "recognition", "."], "sentence-detokenized": "This comprehensive framework has been applied to a wide range of computer vision problems, including feature detection, feature classification, image segmentation, image matching, motion estimation, shape computation, and object recognition.", "token2charspan": [[0, 4], [5, 18], [19, 28], [29, 32], [33, 37], [38, 45], [46, 48], [49, 50], [51, 55], [56, 61], [62, 64], [65, 73], [74, 80], [81, 89], [89, 90], [91, 100], [101, 108], [109, 118], [118, 119], [120, 127], [128, 142], [142, 143], [144, 149], [150, 162], [162, 163], [164, 169], [170, 178], [178, 179], [180, 186], [187, 197], [197, 198], [199, 204], [205, 216], [216, 217], [218, 221], [222, 228], [229, 240], [240, 241]]}
{"doc_key": "ai-dev-89", "ner": [[6, 8, "task"], [9, 11, "algorithm"], [14, 15, "algorithm"], [27, 27, "algorithm"], [32, 33, "algorithm"], [37, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 8, 9, 11, "part-of", "", false, false], [6, 8, 14, 15, "usage", "", false, false], [9, 11, 27, 27, "named", "same", false, false], [27, 27, 32, 33, "related-to", "", false, false], [27, 27, 37, 38, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "many", "practical", "applications", ",", "the", "parameter", "estimation", "of", "naive", "Bayesian", "models", "uses", "the", "maximum", "likelihood", "method", ";", "in", "other", "words", ",", "one", "can", "work", "with", "a", "naive", "Bayesian", "model", "without", "accepting", "Bayesian", "likelihood", "or", "using", "any", "Bayesian", "method", "."], "sentence-detokenized": "In many practical applications, the parameter estimation of naive Bayesian models uses the maximum likelihood method; in other words, one can work with a naive Bayesian model without accepting Bayesian likelihood or using any Bayesian method.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 30], [30, 31], [32, 35], [36, 45], [46, 56], [57, 59], [60, 65], [66, 74], [75, 81], [82, 86], [87, 90], [91, 98], [99, 109], [110, 116], [116, 117], [118, 120], [121, 126], [127, 132], [132, 133], [134, 137], [138, 141], [142, 146], [147, 151], [152, 153], [154, 159], [160, 168], [169, 174], [175, 182], [183, 192], [193, 201], [202, 212], [213, 215], [216, 221], [222, 225], [226, 234], [235, 241], [241, 242]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [12, 15, "university"], [17, 19, "researcher"], [21, 21, "misc"], [24, 24, "university"], [26, 26, "university"], [28, 28, "misc"], [35, 37, "university"], [41, 44, "misc"], [46, 49, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 4, 12, 15, "physical", "", false, false], [2, 4, 12, 15, "role", "", false, false], [2, 4, 17, 19, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [17, 19, 24, 24, "physical", "", false, false], [17, 19, 24, 24, "role", "", false, false], [17, 19, 26, 26, "physical", "", false, false], [17, 19, 26, 26, "role", "", false, false], [17, 19, 35, 37, "physical", "", false, false], [17, 19, 35, 37, "role", "", false, false], [21, 21, 17, 19, "named", "", false, false], [28, 28, 17, 19, "origin", "", false, false], [41, 44, 17, 19, "artifact", "", false, false], [41, 44, 46, 49, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Brothers", "-", "Victor", "Gershevich", "Katz", ",", "American", "mathematician", ",", "professor", "at", "the", "Massachusetts", "Institute", "of", "Technology", ";", "Mikhail", "Gershevich", "Katz", ",", "Israeli", "mathematician", ",", "Harvard", "and", "Columbia", "(", "Ph.D.", ",", "1984", ")", ",", "professor", "at", "Bar-", "Ilan", "University", ",", "author", "of", "Systolic", "Geometry", "and", "Topology", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", "."], "sentence-detokenized": "Brothers - Victor Gershevich Katz, American mathematician, professor at the Massachusetts Institute of Technology; Mikhail Gershevich Katz, Israeli mathematician, Harvard and Columbia (Ph.D. , 1984), professor at Bar-Ilan University, author of Systolic Geometry and Topology (Mathematical Surveys and Monographs, vol.", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 28], [29, 33], [33, 34], [35, 43], [44, 57], [57, 58], [59, 68], [69, 71], [72, 75], [76, 89], [90, 99], [100, 102], [103, 113], [113, 114], [115, 122], [123, 133], [134, 138], [138, 139], [140, 147], [148, 161], [161, 162], [163, 170], [171, 174], [175, 183], [184, 185], [185, 190], [191, 192], [193, 197], [197, 198], [198, 199], [200, 209], [210, 212], [213, 217], [217, 221], [222, 232], [232, 233], [234, 240], [241, 243], [244, 252], [253, 261], [262, 265], [266, 274], [275, 276], [276, 288], [289, 296], [297, 300], [301, 311], [311, 312], [313, 316], [316, 317]]}
{"doc_key": "ai-dev-91", "ner": [[3, 4, "person"], [13, 14, "conference"], [19, 22, "organisation"], [23, 24, "location"], [28, 28, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 13, 14, "physical", "", false, false], [3, 4, 13, 14, "role", "", false, false], [3, 4, 19, 22, "role", "", false, false], [19, 22, 23, 24, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2000", ",", "Manuel", "Toharia", ",", "one", "of", "the", "speakers", "at", "the", "previous", "Campus", "Parties", "and", "director", "of", "the", "Pr\u00edncipe", "Felipe", "Science", "Museum", "in", "Valencia", ",", "suggested", "that", "Ragagageles", "should", "expand", "and", "internationalise", "the", "event", "by", "moving", "it", "to", "the", "famous", "museum", "."], "sentence-detokenized": "In 2000, Manuel Toharia, one of the speakers at the previous Campus Parties and director of the Pr\u00edncipe Felipe Science Museum in Valencia, suggested that Ragagageles should expand and internationalise the event by moving it to the famous museum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 23], [23, 24], [25, 28], [29, 31], [32, 35], [36, 44], [45, 47], [48, 51], [52, 60], [61, 67], [68, 75], [76, 79], [80, 88], [89, 91], [92, 95], [96, 104], [105, 111], [112, 119], [120, 126], [127, 129], [130, 138], [138, 139], [140, 149], [150, 154], [155, 166], [167, 173], [174, 180], [181, 184], [185, 201], [202, 205], [206, 211], [212, 214], [215, 221], [222, 224], [225, 227], [228, 231], [232, 238], [239, 245], [245, 246]]}
{"doc_key": "ai-dev-92", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Within", "20", "minutes", ",", "the", "facial", "recognition", "system", "identifies", "personal", "data", ",", "including", "surname", ",", "ID", "card", "number", "and", "address", ",", "which", "are", "displayed", "on", "an", "advertising", "screen", "on", "the", "street", "."], "sentence-detokenized": "Within 20 minutes, the facial recognition system identifies personal data, including surname, ID card number and address, which are displayed on an advertising screen on the street.", "token2charspan": [[0, 6], [7, 9], [10, 17], [17, 18], [19, 22], [23, 29], [30, 41], [42, 48], [49, 59], [60, 68], [69, 73], [73, 74], [75, 84], [85, 92], [92, 93], [94, 96], [97, 101], [102, 108], [109, 112], [113, 120], [120, 121], [122, 127], [128, 131], [132, 141], [142, 144], [145, 147], [148, 159], [160, 166], [167, 169], [170, 173], [174, 180], [180, 181]]}
{"doc_key": "ai-dev-93", "ner": [[6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "research", "has", "increasingly", "focused", "on", "unsupervised", "learning", "and", "semi-supervised", "learning", "algorithms", "."], "sentence-detokenized": "Recent research has increasingly focused on unsupervised learning and semi-supervised learning algorithms.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 32], [33, 40], [41, 43], [44, 56], [57, 65], [66, 69], [70, 85], [86, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-94", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Calculate", "the", "example", "with", "Python", "code", ":"], "sentence-detokenized": "Calculate the example with Python code:", "token2charspan": [[0, 9], [10, 13], [14, 21], [22, 26], [27, 33], [34, 38], [38, 39]]}
{"doc_key": "ai-dev-95", "ner": [[7, 8, "task"], [15, 16, "field"], [19, 22, "algorithm"], [24, 24, "algorithm"], [28, 30, "algorithm"], [34, 35, "researcher"], [37, 39, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[19, 22, 15, 16, "part-of", "", false, false], [19, 22, 28, 30, "type-of", "", false, false], [19, 22, 34, 35, "origin", "", false, false], [19, 22, 37, 39, "origin", "", false, false], [24, 24, 19, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Today", ",", "however", ",", "many", "aspects", "of", "speech", "recognition", "have", "been", "taken", "over", "by", "the", "deep", "learning", "method", "Long", "short", "-", "term", "memory", "(", "LSTM", ")", ",", "a", "recurrent", "neural", "network", ",", "published", "by", "Sepp", "Hochreiter", "&", "J\u00fcrgen", "Schmidhuber", "in", "1997", "."], "sentence-detokenized": "Today, however, many aspects of speech recognition have been taken over by the deep learning method Long short-term memory (LSTM), a recurrent neural network, published by Sepp Hochreiter & J\u00fcrgen Schmidhuber in 1997.", "token2charspan": [[0, 5], [5, 6], [7, 14], [14, 15], [16, 20], [21, 28], [29, 31], [32, 38], [39, 50], [51, 55], [56, 60], [61, 66], [67, 71], [72, 74], [75, 78], [79, 83], [84, 92], [93, 99], [100, 104], [105, 110], [110, 111], [111, 115], [116, 122], [123, 124], [124, 128], [128, 129], [129, 130], [131, 132], [133, 142], [143, 149], [150, 157], [157, 158], [159, 168], [169, 171], [172, 176], [177, 187], [188, 189], [190, 196], [197, 208], [209, 211], [212, 216], [216, 217]]}
{"doc_key": "ai-dev-96", "ner": [[8, 8, "algorithm"], [10, 11, "algorithm"], [17, 17, "algorithm"], [22, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 10, 11, "compare", "", false, false], [8, 8, 22, 22, "named", "same", false, false], [17, 17, 22, 22, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Preliminary", "experimental", "results", "with", "noisy", "datasets", "show", "that", "BrownBoost", "outperformed", "AdaBoost", "in", "generalization", "error", ";", "however", ",", "LogitBoost", "performed", "as", "well", "as", "BrownBoost", "."], "sentence-detokenized": "Preliminary experimental results with noisy datasets show that BrownBoost outperformed AdaBoost in generalization error; however, LogitBoost performed as well as BrownBoost.", "token2charspan": [[0, 11], [12, 24], [25, 32], [33, 37], [38, 43], [44, 52], [53, 57], [58, 62], [63, 73], [74, 86], [87, 95], [96, 98], [99, 113], [114, 119], [119, 120], [121, 128], [128, 129], [130, 140], [141, 150], [151, 153], [154, 158], [159, 161], [162, 172], [172, 173]]}
{"doc_key": "ai-dev-97", "ner": [[0, 1, "algorithm"], [9, 11, "researcher"], [6, 11, "country"], [14, 17, "researcher"], [20, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 9, 11, "part-of", "", false, false], [9, 11, 6, 11, "physical", "", false, false], [20, 22, 14, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evolutionary", "programming", "was", "introduced", "in", "the", "United", "States", "by", "Lawrence", "J.", "Fogel", ",", "and", "John", "Henry", "Holland", "called", "his", "method", "the", "genetic", "algorithm", "."], "sentence-detokenized": "Evolutionary programming was introduced in the United States by Lawrence J. Fogel, and John Henry Holland called his method the genetic algorithm.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 39], [40, 42], [43, 46], [47, 53], [54, 60], [61, 63], [64, 72], [73, 75], [76, 81], [81, 82], [83, 86], [87, 91], [92, 97], [98, 105], [106, 112], [113, 116], [117, 123], [124, 127], [128, 135], [136, 145], [145, 146]]}
{"doc_key": "ai-dev-98", "ner": [[5, 5, "researcher"], [7, 7, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 13, 14, "role", "", false, false], [5, 5, 16, 17, "role", "", false, false], [5, 5, 19, 20, "role", "", false, false], [5, 5, 22, 23, "role", "", false, false], [7, 7, 13, 14, "role", "", false, false], [7, 7, 16, 17, "role", "", false, false], [7, 7, 19, 20, "role", "", false, false], [7, 7, 22, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Envelope", "-", "based", "calculations", "by", "Doug", ",", "Alan", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", "and", "John", "McCarthy", ")", "showed", "that", "this", "effort", "would", "require", "1000-3000", "man", "-", "years", "of", "effort", ",", "far", "beyond", "the", "usual", "academic", "project", "model", "."], "sentence-detokenized": "Envelope-based calculations by Doug, Alan and their colleagues (including Marvin Minsky, Allen Newell, Edward Feigenbaum and John McCarthy) showed that this effort would require 1000-3000 man-years of effort, far beyond the usual academic project model.", "token2charspan": [[0, 8], [8, 9], [9, 14], [15, 27], [28, 30], [31, 35], [35, 36], [37, 41], [42, 45], [46, 51], [52, 62], [63, 64], [64, 73], [74, 80], [81, 87], [87, 88], [89, 94], [95, 101], [101, 102], [103, 109], [110, 120], [121, 124], [125, 129], [130, 138], [138, 139], [140, 146], [147, 151], [152, 156], [157, 163], [164, 169], [170, 177], [178, 187], [188, 191], [191, 192], [192, 197], [198, 200], [201, 207], [207, 208], [209, 212], [213, 219], [220, 223], [224, 229], [230, 238], [239, 246], [247, 252], [252, 253]]}
{"doc_key": "ai-dev-99", "ner": [[5, 7, "metrics"], [10, 12, "metrics"], [15, 17, "metrics"], [19, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 10, 12, "part-of", "implemented_in", false, false], [15, 17, 19, 21, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "general", "criteria", "are", "the", "mean", "squared", "error", "criterion", "implemented", "in", "the", "MSECriterion", "and", "the", "cross", "-entropy", "criterion", "implemented", "in", "the", "NLLCriterion", "."], "sentence-detokenized": "The general criteria are the mean squared error criterion implemented in the MSECriterion and the cross-entropy criterion implemented in the NLLCriterion.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 24], [25, 28], [29, 33], [34, 41], [42, 47], [48, 57], [58, 69], [70, 72], [73, 76], [77, 89], [90, 93], [94, 97], [98, 103], [103, 111], [112, 121], [122, 133], [134, 136], [137, 140], [141, 153], [153, 154]]}
{"doc_key": "ai-dev-100", "ner": [[0, 0, "researcher"], [11, 11, "organisation"], [14, 24, "misc"], [30, 34, "conference"], [44, 45, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 11, 11, "role", "", false, false], [0, 0, 30, 34, "role", "", false, false], [0, 0, 44, 45, "role", "", false, false], [14, 24, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zurada", "has", "served", "the", "engineering", "profession", "as", "a", "long", "-", "time", "IEEE", "volunteer", ":", "as", "IEEE", "Technical", "Vice", "President", "(", "TAB", "Chair", ")", "in", "2014", ",", "as", "President", "of", "the", "IEEE", "Computational", "Intelligence", "Society", "in", "2004", "-", "05", ",", "and", "as", "a", "member", "of", "ADCOM", "in", "2009", "-", "14", ",", "2016", "-", "18", ",", "and", "earlier", "."], "sentence-detokenized": "Zurada has served the engineering profession as a long-time IEEE volunteer: as IEEE Technical Vice President (TAB Chair) in 2014, as President of the IEEE Computational Intelligence Society in 2004-05, and as a member of ADCOM in 2009-14, 2016-18, and earlier.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 21], [22, 33], [34, 44], [45, 47], [48, 49], [50, 54], [54, 55], [55, 59], [60, 64], [65, 74], [74, 75], [76, 78], [79, 83], [84, 93], [94, 98], [99, 108], [109, 110], [110, 113], [114, 119], [119, 120], [121, 123], [124, 128], [128, 129], [130, 132], [133, 142], [143, 145], [146, 149], [150, 154], [155, 168], [169, 181], [182, 189], [190, 192], [193, 197], [197, 198], [198, 200], [200, 201], [202, 205], [206, 208], [209, 210], [211, 217], [218, 220], [221, 226], [227, 229], [230, 234], [234, 235], [235, 237], [237, 238], [239, 243], [243, 244], [244, 246], [246, 247], [248, 251], [252, 259], [259, 260]]}
{"doc_key": "ai-dev-101", "ner": [[0, 2, "field"], [7, 8, "field"], [10, 11, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 0, 2, "part-of", "", false, false], [10, 11, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Computational", "linguistics", "in", "general", "involves", "linguists", ",", "computer", "scientists", ",", "artificial", "intelligence", "experts", ",", "mathematicians", ",", "logicians", ",", "philosophers", ",", "cognitive", "scientists", ",", "cognitive", "psychologists", ",", "psycholinguists", ",", "anthropologists", "and", "neuroscientists", ",", "among", "others", "."], "sentence-detokenized": "Computational linguistics in general involves linguists, computer scientists, artificial intelligence experts, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists and neuroscientists, among others.", "token2charspan": [[0, 13], [14, 25], [26, 28], [29, 36], [37, 45], [46, 55], [55, 56], [57, 65], [66, 76], [76, 77], [78, 88], [89, 101], [102, 109], [109, 110], [111, 125], [125, 126], [127, 136], [136, 137], [138, 150], [150, 151], [152, 161], [162, 172], [172, 173], [174, 183], [184, 197], [197, 198], [199, 214], [214, 215], [216, 231], [232, 235], [236, 251], [251, 252], [253, 258], [259, 265], [265, 266]]}
{"doc_key": "ai-dev-102", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "correlations", "between", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long short-term memory are often used to exploit correlations between frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [83, 88], [88, 89], [89, 93], [94, 100], [101, 104], [105, 110], [111, 115], [116, 118], [119, 126], [127, 139], [140, 147], [148, 154], [154, 155]]}
{"doc_key": "ai-dev-103", "ner": [[0, 0, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "was", "the", "first", "industrial", "robot", ","], "sentence-detokenized": "Unimate was the first industrial robot,", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 21], [22, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-dev-104", "ner": [[7, 8, "researcher"], [10, 11, "researcher"], [0, 0, "researcher"], [3, 5, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 3, 5, "win-defeat", "", false, false], [10, 11, 3, 5, "win-defeat", "", false, false], [0, 0, 3, 5, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Bengio", "won", "the", "2018", "Turing", "Prize", "alongside", "Geoffrey", "Hinton", "and", "Yann", "LeCun", "."], "sentence-detokenized": "Bengio won the 2018 Turing Prize alongside Geoffrey Hinton and Yann LeCun.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 19], [20, 26], [27, 32], [33, 42], [43, 51], [52, 58], [59, 62], [63, 67], [68, 73], [73, 74]]}
{"doc_key": "ai-dev-105", "ner": [[4, 6, "country"], [19, 22, "misc"], [24, 24, "country"], [28, 29, "organisation"], [33, 34, "person"], [37, 38, "person"], [44, 46, "misc"], [47, 47, "country"], [53, 53, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[19, 22, 4, 6, "physical", "filmed_in", false, false], [33, 34, 28, 29, "role", "host", false, false], [37, 38, 28, 29, "role", "reporter", false, false], [44, 46, 4, 6, "physical", "filmed_in", false, false], [44, 46, 47, 47, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "series", "were", "filmed", "in", "the", "UK", "for", "specific", "sectors", "of", "the", "global", "market", ",", "including", "two", "series", "of", "Robot", "Wars", "Extreme", "Warriors", "with", "US", "contestants", "for", "the", "TNN", "network", "(", "hosted", "by", "Mick", "Foley", ",", "reporter", "Rebecca", "Grant", ")", ",", "two", "series", "of", "Robot", "Wars", "for", "Dutch", "distribution", "and", "one", "series", "for", "Germany", "."], "sentence-detokenized": "Other series were filmed in the UK for specific sectors of the global market, including two series of Robot Wars Extreme Warriors with US contestants for the TNN network (hosted by Mick Foley, reporter Rebecca Grant), two series of Robot Wars for Dutch distribution and one series for Germany.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 24], [25, 27], [28, 31], [32, 34], [35, 38], [39, 47], [48, 55], [56, 58], [59, 62], [63, 69], [70, 76], [76, 77], [78, 87], [88, 91], [92, 98], [99, 101], [102, 107], [108, 112], [113, 120], [121, 129], [130, 134], [135, 137], [138, 149], [150, 153], [154, 157], [158, 161], [162, 169], [170, 171], [171, 177], [178, 180], [181, 185], [186, 191], [191, 192], [193, 201], [202, 209], [210, 215], [215, 216], [216, 217], [218, 221], [222, 228], [229, 231], [232, 237], [238, 242], [243, 246], [247, 252], [253, 265], [266, 269], [270, 273], [274, 280], [281, 284], [285, 292], [292, 293]]}
{"doc_key": "ai-dev-106", "ner": [[6, 6, "researcher"], [11, 11, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 11, 11, "role", "", false, false], [26, 27, 11, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "many", "years", "from", "1986", ",", "Miller", "led", "the", "development", "of", "WordNet", ",", "a", "large", "computer", "-", "readable", "electronic", "reference", "for", "use", "in", "applications", "such", "as", "search", "engines", "."], "sentence-detokenized": "For many years from 1986, Miller led the development of WordNet, a large computer-readable electronic reference for use in applications such as search engines.", "token2charspan": [[0, 3], [4, 8], [9, 14], [15, 19], [20, 24], [24, 25], [26, 32], [33, 36], [37, 40], [41, 52], [53, 55], [56, 63], [63, 64], [65, 66], [67, 72], [73, 81], [81, 82], [82, 90], [91, 101], [102, 111], [112, 115], [116, 119], [120, 122], [123, 135], [136, 140], [141, 143], [144, 150], [151, 158], [158, 159]]}
{"doc_key": "ai-dev-107", "ner": [[3, 4, "algorithm"], [7, 10, "algorithm"], [13, 14, "researcher"], [18, 25, "organisation"], [30, 32, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 13, 14, "origin", "", false, false], [3, 4, 30, 32, "win-defeat", "", false, false], [7, 10, 13, 14, "origin", "", false, false], [7, 10, 30, 32, "win-defeat", "", false, false], [13, 14, 18, 25, "physical", "", false, false], [13, 14, 18, 25, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Since", "2009", ",", "recurrent", "neural", "networks", "and", "deep", "feedforward", "neural", "networks", "developed", "in", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "Swiss", "Artificial", "Intelligence", "Laboratory", "(", "IDSIA", ")", "have", "won", "several", "international", "handwriting", "competitions", "."], "sentence-detokenized": "Since 2009, recurrent neural networks and deep feedforward neural networks developed in J\u00fcrgen Schmidhuber's research group at the Swiss Artificial Intelligence Laboratory (IDSIA) have won several international handwriting competitions.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 21], [22, 28], [29, 37], [38, 41], [42, 46], [47, 58], [59, 65], [66, 74], [75, 84], [85, 87], [88, 94], [95, 106], [106, 108], [109, 117], [118, 123], [124, 126], [127, 130], [131, 136], [137, 147], [148, 160], [161, 171], [172, 173], [173, 178], [178, 179], [180, 184], [185, 188], [189, 196], [197, 210], [211, 222], [223, 235], [235, 236]]}
{"doc_key": "ai-dev-108", "ner": [[5, 6, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "is", "implemented", "in", "C", "++", "and", "is", "packaged", "in", "Python", "."], "sentence-detokenized": "The software is implemented in C++ and is packaged in Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 30], [31, 32], [32, 34], [35, 38], [39, 41], [42, 50], [51, 53], [54, 60], [60, 61]]}
{"doc_key": "ai-dev-109", "ner": [[8, 9, "country"], [14, 15, "misc"], [20, 21, "misc"], [33, 33, "misc"], [36, 37, "misc"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 8, 9, "temporal", "", false, false], [20, 21, 14, 15, "artifact", "", false, false], [20, 21, 38, 38, "physical", "", false, false], [36, 37, 33, 33, "named", "", false, false], [36, 37, 38, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1857", ",", "at", "the", "request", "of", "the", "Tokugawa", "shogunate", ",", "a", "group", "of", "Dutch", "engineers", "began", "construction", "of", "the", "Nagasaki", "Yotetsusho", ",", "a", "modern", "Western", "-", "style", "foundry", "and", "shipyard", "near", "the", "Dutch", "settlement", "of", "Dejima", "in", "Nagasaki", "."], "sentence-detokenized": "In 1857, at the request of the Tokugawa shogunate, a group of Dutch engineers began construction of the Nagasaki Yotetsusho, a modern Western-style foundry and shipyard near the Dutch settlement of Dejima in Nagasaki.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 39], [40, 49], [49, 50], [51, 52], [53, 58], [59, 61], [62, 67], [68, 77], [78, 83], [84, 96], [97, 99], [100, 103], [104, 112], [113, 123], [123, 124], [125, 126], [127, 133], [134, 141], [141, 142], [142, 147], [148, 155], [156, 159], [160, 168], [169, 173], [174, 177], [178, 183], [184, 194], [195, 197], [198, 204], [205, 207], [208, 216], [216, 217]]}
{"doc_key": "ai-dev-110", "ner": [[10, 12, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["We", "make", "it", "as", "accurate", "as", "possible", "by", "measuring", "the", "mean", "squared", "error", "between", "math", "/", "math", "and", "math", "_", "six", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "we", "want", "math", "(", "y", "-", "_", "six", "{", "f", "}", "(", "x", ";", "D", ")", ")", "^", "2", "/", "math", "to", "be", "minimal", ",", "both", "for", "points", "mathx", "_", "1,\\", ",", "x", "_n", "/", "math", ",", "and", "for", "points", "outside", "our", "sample", "."], "sentence-detokenized": "We make it as accurate as possible by measuring the mean squared error between math / math and math _ six {f} (x; D) / math: we want math (y - _ six {f} (x; D)) ^ 2 / math to be minimal, both for points mathx _ 1,\\, x _n / math, and for points outside our sample.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 13], [14, 22], [23, 25], [26, 34], [35, 37], [38, 47], [48, 51], [52, 56], [57, 64], [65, 70], [71, 78], [79, 83], [84, 85], [86, 90], [91, 94], [95, 99], [100, 101], [102, 105], [106, 107], [107, 108], [108, 109], [110, 111], [111, 112], [112, 113], [114, 115], [115, 116], [117, 118], [119, 123], [123, 124], [125, 127], [128, 132], [133, 137], [138, 139], [139, 140], [141, 142], [143, 144], [145, 148], [149, 150], [150, 151], [151, 152], [153, 154], [154, 155], [155, 156], [157, 158], [158, 159], [159, 160], [161, 162], [163, 164], [165, 166], [167, 171], [172, 174], [175, 177], [178, 185], [185, 186], [187, 191], [192, 195], [196, 202], [203, 208], [209, 210], [211, 214], [214, 215], [216, 217], [218, 220], [221, 222], [223, 227], [227, 228], [229, 232], [233, 236], [237, 243], [244, 251], [252, 255], [256, 262], [262, 263]]}
{"doc_key": "ai-dev-111", "ner": [[3, 4, "researcher"], [10, 12, "organisation"], [16, 19, "product"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 10, 12, "role", "", false, false], [16, 19, 10, 12, "temporal", "", false, false], [16, 19, 27, 29, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "then", "invited", "Wydner", "to", "the", "annual", "meeting", "of", "the", "American", "Translators", "Association", ",", "where", "the", "Weidner", "Machine", "Translation", "System", "was", "the", "hoped", "-", "for", "breakthrough", "in", "machine", "translation", "the", "following", "October", "."], "sentence-detokenized": "He then invited Wydner to the annual meeting of the American Translators Association, where the Weidner Machine Translation System was the hoped-for breakthrough in machine translation the following October.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 22], [23, 25], [26, 29], [30, 36], [37, 44], [45, 47], [48, 51], [52, 60], [61, 72], [73, 84], [84, 85], [86, 91], [92, 95], [96, 103], [104, 111], [112, 123], [124, 130], [131, 134], [135, 138], [139, 144], [144, 145], [145, 148], [149, 161], [162, 164], [165, 172], [173, 184], [185, 188], [189, 198], [199, 206], [206, 207]]}
{"doc_key": "ai-dev-112", "ner": [[0, 7, "conference"], [3, 9, "conference"], [12, 12, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 9, 0, 7, "named", "", false, false], [3, 9, 0, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["At", "the", "2018", "Neural", "Information", "Processing", "Systems", "Conference", "(", "NeurIPS", ")", ",", "Google", "researchers", "presented", "their", "work", "."], "sentence-detokenized": "At the 2018 Neural Information Processing Systems Conference (NeurIPS), Google researchers presented their work.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 30], [31, 41], [42, 49], [50, 60], [61, 62], [62, 69], [69, 70], [70, 71], [72, 78], [79, 90], [91, 100], [101, 106], [107, 111], [111, 112]]}
{"doc_key": "ai-dev-113", "ner": [[1, 4, "algorithm"], [10, 11, "algorithm"], [12, 25, "metrics"], [18, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 4, 10, 11, "usage", "", false, false], [10, 11, 12, 25, "related-to", "", true, false], [12, 25, 18, 20, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Baum", "-", "Welch", "algorithm", "uses", "the", "well", "-", "known", "EM", "algorithm", "to", "estimate", "the", "parameters", "of", "a", "hidden", "Markov", "model", "with", "maximum", "likelihood", "given", "a", "set", "of", "observed", "feature", "vectors", "."], "sentence-detokenized": "The Baum-Welch algorithm uses the well-known EM algorithm to estimate the parameters of a hidden Markov model with maximum likelihood given a set of observed feature vectors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [15, 24], [25, 29], [30, 33], [34, 38], [38, 39], [39, 44], [45, 47], [48, 57], [58, 60], [61, 69], [70, 73], [74, 84], [85, 87], [88, 89], [90, 96], [97, 103], [104, 109], [110, 114], [115, 122], [123, 133], [134, 139], [140, 141], [142, 145], [146, 148], [149, 157], [158, 165], [166, 173], [173, 174]]}
{"doc_key": "ai-dev-114", "ner": [[0, 9, "product"], [11, 11, "product"], [28, 30, "misc"], [36, 45, "product"], [51, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[0, 9, 11, 11, "compare", "", false, false], [28, 30, 11, 11, "part-of", "", false, false], [36, 45, 11, 11, "part-of", "", false, false], [51, 56, 11, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": [")", "In", "addition", "to", "the", "taxonomic", "information", "contained", "in", "OpenCyc", ",", "ResearchCyc", "contains", "significantly", "more", "semantic", "knowledge", "(", "i.e.", "additional", "facts", "and", "rules", ")", "about", "the", "concepts", "in", "its", "knowledge", "base", ";", "it", "also", "includes", "a", "large", "lexicon", ",", "English", "-", "language", "parsing", "and", "generation", "tools", ",", "and", "Java", "-", "based", "interfaces", "for", "editing", "and", "querying", "knowledge", "."], "sentence-detokenized": ") In addition to the taxonomic information contained in OpenCyc, ResearchCyc contains significantly more semantic knowledge (i.e. additional facts and rules) about the concepts in its knowledge base; it also includes a large lexicon, English-language parsing and generation tools, and Java-based interfaces for editing and querying knowledge.", "token2charspan": [[0, 1], [2, 4], [5, 13], [14, 16], [17, 20], [21, 30], [31, 42], [43, 52], [53, 55], [56, 63], [63, 64], [65, 76], [77, 85], [86, 99], [100, 104], [105, 113], [114, 123], [124, 125], [125, 129], [130, 140], [141, 146], [147, 150], [151, 156], [156, 157], [158, 163], [164, 167], [168, 176], [177, 179], [180, 183], [184, 193], [194, 198], [198, 199], [200, 202], [203, 207], [208, 216], [217, 218], [219, 224], [225, 232], [232, 233], [234, 241], [241, 242], [242, 250], [251, 258], [259, 262], [263, 273], [274, 279], [279, 280], [281, 284], [285, 289], [289, 290], [290, 295], [296, 306], [307, 310], [311, 318], [319, 322], [323, 331], [332, 341], [341, 342]]}
{"doc_key": "ai-dev-115", "ner": [[0, 2, "algorithm"], [4, 5, "task"], [8, 10, "field"], [12, 13, "field"], [15, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 4, 5, "type-of", "", false, false], [4, 5, 8, 10, "part-of", "task_part_of_field", false, false], [4, 5, 12, 13, "part-of", "task_part_of_field", false, false], [4, 5, 15, 17, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Hough", "transform", "is", "a", "feature", "extraction", "technique", "used", "in", "image", "analysis", ",", "computer", "vision", "and", "digital", "image", "processing", "."], "sentence-detokenized": "Hough transform is a feature extraction technique used in image analysis, computer vision and digital image processing.", "token2charspan": [[0, 5], [6, 15], [16, 18], [19, 20], [21, 28], [29, 39], [40, 49], [50, 54], [55, 57], [58, 63], [64, 72], [72, 73], [74, 82], [83, 89], [90, 93], [94, 101], [102, 107], [108, 118], [118, 119]]}
{"doc_key": "ai-dev-116", "ner": [[4, 4, "product"], [6, 10, "product"], [16, 16, "organisation"], [21, 21, "product"], [23, 24, "researcher"], [27, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 6, 10, "named", "", false, false], [4, 4, 16, 16, "artifact", "", false, false], [4, 4, 21, 21, "origin", "developed_from", false, false], [21, 21, 23, 24, "artifact", "", false, false], [27, 28, 16, 16, "role", "supported", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1978", ",", "the", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "robot", "was", "developed", "by", "Unimation", "with", "the", "support", "of", "Vicarm", "(", "Victor", "Scheinman", ")", "and", "General", "Motors", "."], "sentence-detokenized": "In 1978, the PUMA (Programmable Universal Machine for Assembly) robot was developed by Unimation with the support of Vicarm (Victor Scheinman) and General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 19], [19, 31], [32, 41], [42, 49], [50, 53], [54, 62], [62, 63], [64, 69], [70, 73], [74, 83], [84, 86], [87, 96], [97, 101], [102, 105], [106, 113], [114, 116], [117, 123], [124, 125], [125, 131], [132, 141], [141, 142], [143, 146], [147, 154], [155, 161], [161, 162]]}
{"doc_key": "ai-dev-117", "ner": [[0, 1, "algorithm"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 7, 8, "origin", "", false, false], [0, 1, 10, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "LSTM", "was", "proposed", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "The LSTM was proposed in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 21], [22, 24], [25, 29], [30, 32], [33, 37], [38, 48], [49, 52], [53, 59], [60, 71], [71, 72]]}
{"doc_key": "ai-dev-118", "ner": [[11, 12, "metrics"], [14, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "expressed", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be expressed in a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 33], [34, 36], [37, 38], [39, 40], [41, 42], [43, 44], [45, 56], [57, 62], [63, 65], [66, 75], [76, 82], [83, 85], [86, 93], [93, 94]]}
{"doc_key": "ai-dev-119", "ner": [[10, 10, "conference"], [13, 14, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "also", "contributed", "a", "lot", "through", "the", "creation", "of", "ELRA", "and", "the", "LREC", "conference", "."], "sentence-detokenized": "It has also contributed a lot through the creation of ELRA and the LREC conference.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 23], [24, 25], [26, 29], [30, 37], [38, 41], [42, 50], [51, 53], [54, 58], [59, 62], [63, 66], [67, 71], [72, 82], [82, 83]]}
{"doc_key": "ai-dev-120", "ner": [[18, 19, "misc"], [21, 22, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 22, 18, 19, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "popular", "application", "of", "mass", "-produced", "robots", "in", "today", "'s", "industry", "is", "the", "pick", "-", "and", "-", "place", "assembly", "robot", "called", "SCARA", "robot", "with", "four", "degrees", "of", "freedom", "."], "sentence-detokenized": "A popular application of mass-produced robots in today's industry is the pick-and-place assembly robot called SCARA robot with four degrees of freedom.", "token2charspan": [[0, 1], [2, 9], [10, 21], [22, 24], [25, 29], [29, 38], [39, 45], [46, 48], [49, 54], [54, 56], [57, 65], [66, 68], [69, 72], [73, 77], [77, 78], [78, 81], [81, 82], [82, 87], [88, 96], [97, 102], [103, 109], [110, 115], [116, 121], [122, 126], [127, 131], [132, 139], [140, 142], [143, 150], [150, 151]]}
{"doc_key": "ai-dev-121", "ner": [[14, 24, "conference"], [13, 26, "conference"], [20, 21, "conference"], [29, 33, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 26, 14, 24, "named", "", false, false], [29, 33, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "a", "founding", "member", "and", "former", "chair", "(", "2006-2008", ")", "of", "the", "Special", "Interest", "Group", "of", "the", "Society", "for", "Computational", "Linguistics", "Web", "as", "Corpus", "(", "SIGWAC", ")", "and", "a", "founding", "organiser", "of", "SENSEVAL", "."], "sentence-detokenized": "He was a founding member and former chair (2006-2008) of the Special Interest Group of the Society for Computational Linguistics Web as Corpus (SIGWAC) and a founding organiser of SENSEVAL.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 17], [18, 24], [25, 28], [29, 35], [36, 41], [42, 43], [43, 52], [52, 53], [54, 56], [57, 60], [61, 68], [69, 77], [78, 83], [84, 86], [87, 90], [91, 98], [99, 102], [103, 116], [117, 128], [129, 132], [133, 135], [136, 142], [143, 144], [144, 150], [150, 151], [152, 155], [156, 157], [158, 166], [167, 176], [177, 179], [180, 188], [188, 189]]}
{"doc_key": "ai-dev-122", "ner": [[4, 4, "product"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 4, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "platform", ",", "LinguaStream", "provides", "an", "extensive", "Java", "API", "."], "sentence-detokenized": "As a platform, LinguaStream provides an extensive Java API.", "token2charspan": [[0, 2], [3, 4], [5, 13], [13, 14], [15, 27], [28, 36], [37, 39], [40, 49], [50, 54], [55, 58], [58, 59]]}
{"doc_key": "ai-dev-123", "ner": [[12, 12, "programlang"], [15, 17, "misc"], [20, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 20, 22, "type-of", "", false, false], [15, 17, 20, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "robot", "kit", "is", "Android", "-", "based", "and", "can", "be", "programmed", "using", "Java", ",", "the", "Blocks", "programming", "interface", "or", "other", "Android", "programming", "systems", "."], "sentence-detokenized": "The robot kit is Android-based and can be programmed using Java, the Blocks programming interface or other Android programming systems.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 16], [17, 24], [24, 25], [25, 30], [31, 34], [35, 38], [39, 41], [42, 52], [53, 58], [59, 63], [63, 64], [65, 68], [69, 75], [76, 87], [88, 97], [98, 100], [101, 106], [107, 114], [115, 126], [127, 134], [134, 135]]}
{"doc_key": "ai-dev-124", "ner": [[11, 14, "algorithm"], [9, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "method", "of", "defining", "the", "linked", "list", "determines", "the", "use", "of", "depth", "-", "first", "search", "or", "breadth", "-", "first", "search", "."], "sentence-detokenized": "The method of defining the linked list determines the use of depth-first search or breadth-first search.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 22], [23, 26], [27, 33], [34, 38], [39, 49], [50, 53], [54, 57], [58, 60], [61, 66], [66, 67], [67, 72], [73, 79], [80, 82], [83, 90], [90, 91], [91, 96], [97, 103], [103, 104]]}
{"doc_key": "ai-dev-125", "ner": [[21, 22, "task"], [26, 28, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "regions", "can", "indicate", "the", "presence", "of", "objects", "or", "parts", "of", "objects", "in", "the", "image", "area", "and", "can", "be", "used", "for", "object", "detection", "and", "/", "or", "object", "video", "tracking", "."], "sentence-detokenized": "These regions can indicate the presence of objects or parts of objects in the image area and can be used for object detection and/or object video tracking.", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 26], [27, 30], [31, 39], [40, 42], [43, 50], [51, 53], [54, 59], [60, 62], [63, 70], [71, 73], [74, 77], [78, 83], [84, 88], [89, 92], [93, 96], [97, 99], [100, 104], [105, 108], [109, 115], [116, 125], [126, 129], [129, 130], [130, 132], [133, 139], [140, 145], [146, 154], [154, 155]]}
{"doc_key": "ai-dev-126", "ner": [[4, 5, "algorithm"], [7, 7, "product"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 4, 5, "type-of", "", false, false], [7, 7, 14, 15, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "semantic", "network", "is", "WordNet", ",", "the", "lexical", "database", "of", "the", "English", "language", "."], "sentence-detokenized": "An example of a semantic network is WordNet, the lexical database of the English language.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 32], [33, 35], [36, 43], [43, 44], [45, 48], [49, 56], [57, 65], [66, 68], [69, 72], [73, 80], [81, 89], [89, 90]]}
{"doc_key": "ai-dev-127", "ner": [[0, 2, "task"], [7, 8, "field"], [10, 12, "field"], [21, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 7, 8, "part-of", "", false, false], [0, 2, 10, 12, "named", "same", false, false], [0, 2, 10, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Speech", "recognition", "is", "an", "interdisciplinary", "subfield", "of", "computer", "science", "and", "computational", "linguistics", "that", "develops", "methods", "and", "technologies", "that", "enable", "the", "computer", "recognition", "and", "translation", "of", "spoken", "language", "into", "text", "."], "sentence-detokenized": "Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methods and technologies that enable the computer recognition and translation of spoken language into text.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 24], [25, 42], [43, 51], [52, 54], [55, 63], [64, 71], [72, 75], [76, 89], [90, 101], [102, 106], [107, 115], [116, 123], [124, 127], [128, 140], [141, 145], [146, 152], [153, 156], [157, 165], [166, 177], [178, 181], [182, 193], [194, 196], [197, 203], [204, 212], [213, 217], [218, 222], [222, 223]]}
{"doc_key": "ai-dev-128", "ner": [[0, 1, "field"], [10, 12, "misc"], [16, 18, "field"], [20, 20, "task"], [22, 23, "task"], [45, 46, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 45, 46, "named", "same", false, false], [16, 18, 0, 1, "part-of", "subfield", false, false], [20, 20, 0, 1, "part-of", "", false, false], [20, 20, 16, 18, "part-of", "", false, false], [22, 23, 16, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Artificial", "intelligence", "has", "received", "the", "most", "attention", "in", "terms", "of", "applied", "ontology", "in", "subfields", "such", "as", "natural", "language", "processing", "within", "machine", "and", "knowledge", "representation", ",", "but", "ontology", "editors", "are", "often", "used", "in", "many", "domains", ",", "such", "as", "education", ",", "without", "the", "intention", "of", "contributing", "to", "artificial", "intelligence", "."], "sentence-detokenized": "Artificial intelligence has received the most attention in terms of applied ontology in subfields such as natural language processing within machine and knowledge representation, but ontology editors are often used in many domains, such as education, without the intention of contributing to artificial intelligence.", "token2charspan": [[0, 10], [11, 23], [24, 27], [28, 36], [37, 40], [41, 45], [46, 55], [56, 58], [59, 64], [65, 67], [68, 75], [76, 84], [85, 87], [88, 97], [98, 102], [103, 105], [106, 113], [114, 122], [123, 133], [134, 140], [141, 148], [149, 152], [153, 162], [163, 177], [177, 178], [179, 182], [183, 191], [192, 199], [200, 203], [204, 209], [210, 214], [215, 217], [218, 222], [223, 230], [230, 231], [232, 236], [237, 239], [240, 249], [249, 250], [251, 258], [259, 262], [263, 272], [273, 275], [276, 288], [289, 291], [292, 302], [303, 315], [315, 316]]}
{"doc_key": "ai-dev-129", "ner": [[6, 8, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 11, 12, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "update", "rule", "is", "actually", "a", "stochastic", "gradient", "descent", "update", "of", "linear", "regression", "."], "sentence-detokenized": "This update rule is actually a stochastic gradient descent update of linear regression.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 28], [29, 30], [31, 41], [42, 50], [51, 58], [59, 65], [66, 68], [69, 75], [76, 86], [86, 87]]}
{"doc_key": "ai-dev-130", "ner": [[6, 11, "organisation"], [14, 18, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "been", "elected", "to", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "the", "National", "Academy", "of", "Sciences", "and", "has", "received", "numerous", "awards", ":"], "sentence-detokenized": "He has been elected to the American Academy of Arts and Sciences and the National Academy of Sciences and has received numerous awards:", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 22], [23, 26], [27, 35], [36, 43], [44, 46], [47, 51], [52, 55], [56, 64], [65, 68], [69, 72], [73, 81], [82, 89], [90, 92], [93, 101], [102, 105], [106, 109], [110, 118], [119, 127], [128, 134], [134, 135]]}
{"doc_key": "ai-dev-131", "ner": [[5, 6, "organisation"], [12, 13, "person"], [8, 18, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 12, 13, "related-to", "written_about_by", false, false], [5, 6, 8, 18, "related-to", "written_about_by", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "recent", "thinking", "on", "Honda", "'s", "strategy", "was", "put", "forward", "by", "Gary", "Hamel", "and", "C.", "K", ".", "Prahalad", "in", "1989", "."], "sentence-detokenized": "The most recent thinking on Honda's strategy was put forward by Gary Hamel and C. K. Prahalad in 1989.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 24], [25, 27], [28, 33], [33, 35], [36, 44], [45, 48], [49, 52], [53, 60], [61, 63], [64, 68], [69, 74], [75, 78], [79, 81], [82, 83], [83, 84], [85, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-dev-132", "ner": [[1, 1, "metrics"], [4, 6, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 4, 6, "related-to", "calculates", true, false], [1, 1, 16, 16, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "BLEU", "simply", "calculates", "the", "accuracy", "of", "n-", "grams", ",", "giving", "equal", "weight", "to", "each", ",", "NIST", "also", "calculates", "how", "informative", "a", "given", "n-", "gram", "is", "."], "sentence-detokenized": "While BLEU simply calculates the accuracy of n-grams, giving equal weight to each, NIST also calculates how informative a given n-gram is.", "token2charspan": [[0, 5], [6, 10], [11, 17], [18, 28], [29, 32], [33, 41], [42, 44], [45, 47], [47, 52], [52, 53], [54, 60], [61, 66], [67, 73], [74, 76], [77, 81], [81, 82], [83, 87], [88, 92], [93, 103], [104, 107], [108, 119], [120, 121], [122, 127], [128, 130], [130, 134], [135, 137], [137, 138]]}
{"doc_key": "ai-dev-133", "ner": [[4, 8, "misc"], [9, 13, "conference"], [10, 15, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 8, 9, 13, "temporal", "", false, false], [10, 15, 9, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "awarded", "the", "2019", "Lifetime", "Achievement", "Award", "by", "the", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "He was awarded the 2019 Lifetime Achievement Award by the Association for Computational Linguistics (ACL).", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 18], [19, 23], [24, 32], [33, 44], [45, 50], [51, 53], [54, 57], [58, 69], [70, 73], [74, 87], [88, 99], [100, 101], [101, 104], [104, 105], [105, 106]]}
{"doc_key": "ai-dev-134", "ner": [[0, 2, "researcher"], [8, 11, "organisation"], [6, 13, "organisation"], [20, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 8, 11, "role", "", false, false], [0, 2, 20, 21, "role", "", false, false], [6, 13, 8, 11, "named", "", false, false], [23, 23, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "is", "a", "member", "of", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "and", "the", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara is a member of the Institute of Electrical and Electronics Engineers (IEEE) and the American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 18], [19, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 65], [66, 75], [76, 77], [77, 81], [81, 82], [83, 86], [87, 90], [91, 99], [100, 111], [112, 115], [116, 126], [127, 139], [140, 141], [141, 145], [145, 146], [146, 147]]}
{"doc_key": "ai-dev-135", "ner": [[12, 12, "misc"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "MATLAB", "code", "presents", "a", "concrete", "solution", "to", "the", "system", "of", "nonlinear", "equations", "presented", "in", "the", "previous", "section", "."], "sentence-detokenized": "The following MATLAB code presents a concrete solution to the system of nonlinear equations presented in the previous section.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 34], [35, 36], [37, 45], [46, 54], [55, 57], [58, 61], [62, 68], [69, 71], [72, 81], [82, 91], [92, 101], [102, 104], [105, 108], [109, 117], [118, 125], [125, 126]]}
{"doc_key": "ai-dev-136", "ner": [[4, 6, "product"], [14, 15, "field"], [37, 38, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 14, 15, "related-to", "trained_by", true, false], [4, 6, 37, 38, "related-to", "trained_by", true, false], [14, 15, 37, 38, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "many", "cases", ",", "pattern", "recognition", "systems", "are", "trained", "from", "labelled", "training", "data", "(", "supervised", "learning", ")", ",", "but", "if", "no", "labelled", "data", "is", "available", ",", "other", "algorithms", "can", "be", "used", "to", "discover", "previously", "unknown", "patterns", "(", "unsupervised", "learning", ")", "."], "sentence-detokenized": "In many cases, pattern recognition systems are trained from labelled training data (supervised learning), but if no labelled data is available, other algorithms can be used to discover previously unknown patterns (unsupervised learning).", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 22], [23, 34], [35, 42], [43, 46], [47, 54], [55, 59], [60, 68], [69, 77], [78, 82], [83, 84], [84, 94], [95, 103], [103, 104], [104, 105], [106, 109], [110, 112], [113, 115], [116, 124], [125, 129], [130, 132], [133, 142], [142, 143], [144, 149], [150, 160], [161, 164], [165, 167], [168, 172], [173, 175], [176, 184], [185, 195], [196, 203], [204, 212], [213, 214], [214, 226], [227, 235], [235, 236], [236, 237]]}
{"doc_key": "ai-dev-137", "ner": [[5, 9, "researcher"], [10, 12, "country"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 9, 10, 12, "physical", "", false, false], [5, 9, 24, 25, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "was", "first", "used", "by", "Lawrence", "J.", "Fogel", "in", "the", "United", "States", "in", "1960", "to", "apply", "simulated", "evolution", "as", "a", "learning", "process", "to", "create", "artificial", "intelligence", "."], "sentence-detokenized": "It was first used by Lawrence J. Fogel in the United States in 1960 to apply simulated evolution as a learning process to create artificial intelligence.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 17], [18, 20], [21, 29], [30, 32], [33, 38], [39, 41], [42, 45], [46, 52], [53, 59], [60, 62], [63, 67], [68, 70], [71, 76], [77, 86], [87, 96], [97, 99], [100, 101], [102, 110], [111, 118], [119, 121], [122, 128], [129, 139], [140, 152], [152, 153]]}
{"doc_key": "ai-dev-138", "ner": [[0, 2, "field"], [8, 9, "field"], [13, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 8, 9, "part-of", "", false, false], [13, 14, 8, 9, "part-of", "", false, false], [16, 17, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Reinforcement", "learning", "is", "one", "of", "the", "three", "basic", "machine", "learning", "paradigms", ",", "alongside", "supervised", "learning", "and", "unsupervised", "learning", "."], "sentence-detokenized": "Reinforcement learning is one of the three basic machine learning paradigms, alongside supervised learning and unsupervised learning.", "token2charspan": [[0, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 42], [43, 48], [49, 56], [57, 65], [66, 75], [75, 76], [77, 86], [87, 97], [98, 106], [107, 110], [111, 123], [124, 132], [132, 133]]}
{"doc_key": "ai-dev-139", "ner": [[4, 5, "field"], [11, 11, "programlang"], [29, 30, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 29, 30, "usage", "applies", false, false], [11, 11, 29, 30, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "such", "cases", ",", "cloud", "computing", "and", "the", "open", "-", "source", "R", "programming", "language", "can", "help", "smaller", "banks", "to", "implement", "risk", "analytics", "and", "support", "branch", "-", "level", "monitoring", "using", "predictive", "analytics", "."], "sentence-detokenized": "In such cases, cloud computing and the open-source R programming language can help smaller banks to implement risk analytics and support branch-level monitoring using predictive analytics.", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 20], [21, 30], [31, 34], [35, 38], [39, 43], [43, 44], [44, 50], [51, 52], [53, 64], [65, 73], [74, 77], [78, 82], [83, 90], [91, 96], [97, 99], [100, 109], [110, 114], [115, 124], [125, 128], [129, 136], [137, 143], [143, 144], [144, 149], [150, 160], [161, 166], [167, 177], [178, 187], [187, 188]]}
{"doc_key": "ai-dev-140", "ner": [[9, 10, "researcher"], [14, 15, "algorithm"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 19, 20, "named", "same", false, false], [14, 15, 9, 10, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "first", "version", "of", "the", "theorem", "was", "proved", "by", "George", "Cybenko", "in", "1989", "for", "sigmoid", "function", "activation", "functions", ".", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "A first version of the theorem was proved by George Cybenko in 1989 for sigmoid function activation functions. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 1], [2, 7], [8, 15], [16, 18], [19, 22], [23, 30], [31, 34], [35, 41], [42, 44], [45, 51], [52, 59], [60, 62], [63, 67], [68, 71], [72, 79], [80, 88], [89, 99], [100, 109], [109, 110], [111, 118], [119, 121], [122, 123], [123, 127], [127, 128], [128, 129], [130, 131], [132, 133], [133, 134], [134, 135], [135, 136], [137, 144], [144, 145]]}
{"doc_key": "ai-dev-141", "ner": [[5, 6, "algorithm"], [9, 10, "metrics"], [13, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 5, 6, "part-of", "", false, false], [13, 22, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "procedure", ",", "called", "cross", "-checking", ",", "the", "MSE", "is", "often", "called", "the", "mean", "squared", "error", "of", "prediction", "and", "is", "calculated", "as", "follows"], "sentence-detokenized": "In this procedure, called cross-checking, the MSE is often called the mean squared error of prediction and is calculated as follows", "token2charspan": [[0, 2], [3, 7], [8, 17], [17, 18], [19, 25], [26, 31], [31, 40], [40, 41], [42, 45], [46, 49], [50, 52], [53, 58], [59, 65], [66, 69], [70, 74], [75, 82], [83, 88], [89, 91], [92, 102], [103, 106], [107, 109], [110, 120], [121, 123], [124, 131]]}
{"doc_key": "ai-dev-142", "ner": [[0, 0, "task"], [5, 5, "task"], [4, 8, "task"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 5, "compare", "", false, false], [5, 5, 18, 19, "part-of", "", false, false], [4, 8, 5, 5, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OMR", "generally", "differs", "from", "optical", "character", "recognition", "(", "OCR", ")", "in", "that", "it", "does", "not", "require", "a", "complex", "pattern", "recognition", "engine", "."], "sentence-detokenized": "OMR generally differs from optical character recognition (OCR) in that it does not require a complex pattern recognition engine.", "token2charspan": [[0, 3], [4, 13], [14, 21], [22, 26], [27, 34], [35, 44], [45, 56], [57, 58], [58, 61], [61, 62], [63, 65], [66, 70], [71, 73], [74, 78], [79, 82], [83, 90], [91, 92], [93, 100], [101, 108], [109, 120], [121, 127], [127, 128]]}
{"doc_key": "ai-dev-143", "ner": [[9, 10, "location"], [12, 12, "location"], [14, 16, "location"], [18, 19, "location"], [7, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 14, 16, "physical", "", false, false], [18, 19, 12, 12, "physical", "", false, false], [7, 22, 12, 12, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2018", "and", "2019", ",", "the", "championships", "were", "held", "in", "Houston", "and", "Detroit", ",", "Michigan", ",", "at", "the", "TCF", "Center", "and", "Ford", "Field", ",", "respectively", "."], "sentence-detokenized": "In 2018 and 2019, the championships were held in Houston and Detroit, Michigan, at the TCF Center and Ford Field, respectively.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 16], [16, 17], [18, 21], [22, 35], [36, 40], [41, 45], [46, 48], [49, 56], [57, 60], [61, 68], [68, 69], [70, 78], [78, 79], [80, 82], [83, 86], [87, 90], [91, 97], [98, 101], [102, 106], [107, 112], [112, 113], [114, 126], [126, 127]]}
{"doc_key": "ai-dev-144", "ner": [[0, 2, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 2, "part-of", "", false, false], [12, 13, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "understood", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multiclass", "classification", "."], "sentence-detokenized": "Classification can be understood as two separate problems - binary classification and multiclass classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 96], [97, 111], [111, 112]]}
{"doc_key": "ai-dev-145", "ner": [[4, 6, "product"], [8, 9, "product"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 6, "type-of", "", false, false], [12, 13, 4, 6, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "examples", "of", "popular", "parallel", "robots", "are", "the", "Stewart", "platform", "and", "the", "Delta", "robot", "."], "sentence-detokenized": "Two examples of popular parallel robots are the Stewart platform and the Delta robot.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 23], [24, 32], [33, 39], [40, 43], [44, 47], [48, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-146", "ner": [[4, 9, "algorithm"], [21, 22, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 9, 21, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "However", ",", "the", "ReLU", "activation", "function", ",", "which", "is", "not", "differentiable", "at", "0", ",", "has", "become", "quite", "popular", ",", "e.g.", "in", "AlexNet", ".", ")"], "sentence-detokenized": "(However, the ReLU activation function, which is not differentiable at 0, has become quite popular, e.g. in AlexNet.)", "token2charspan": [[0, 1], [1, 8], [8, 9], [10, 13], [14, 18], [19, 29], [30, 38], [38, 39], [40, 45], [46, 48], [49, 52], [53, 67], [68, 70], [71, 72], [72, 73], [74, 77], [78, 84], [85, 90], [91, 98], [98, 99], [100, 104], [105, 107], [108, 115], [115, 116], [116, 117]]}
{"doc_key": "ai-dev-147", "ner": [[1, 4, "metrics"], [9, 10, "task"], [14, 14, "task"], [16, 17, "task"], [19, 20, "task"], [24, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 4, 24, 26, "named", "", true, false], [9, 10, 1, 4, "usage", "", true, false], [14, 14, 9, 10, "part-of", "", false, false], [16, 17, 9, 10, "part-of", "", false, false], [19, 20, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "F", "-", "score", "is", "often", "used", "in", "the", "information", "retrieval", "domain", "to", "measure", "search", ",", "document", "classification", "and", "query", "classification", "performance", ",", "so", "F_beta", "has", "a", "wide", "range", "of", "applications", "."], "sentence-detokenized": "The F-score is often used in the information retrieval domain to measure search, document classification and query classification performance, so F_beta has a wide range of applications.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 20], [21, 25], [26, 28], [29, 32], [33, 44], [45, 54], [55, 61], [62, 64], [65, 72], [73, 79], [79, 80], [81, 89], [90, 104], [105, 108], [109, 114], [115, 129], [130, 141], [141, 142], [143, 145], [146, 152], [153, 156], [157, 158], [159, 163], [164, 169], [170, 172], [173, 185], [185, 186]]}
{"doc_key": "ai-dev-148", "ner": [[19, 19, "algorithm"], [18, 21, "algorithm"], [24, 25, "algorithm"], [27, 27, "algorithm"], [31, 32, "algorithm"], [34, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 21, 19, 19, "named", "", false, false], [27, 27, 24, 25, "named", "", false, false], [34, 36, 31, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "is", "done", "by", "modelling", "the", "received", "signal", ",", "and", "then", "using", "a", "statistical", "estimation", "method", "such", "as", "maximum", "likelihood", "(", "ML", ")", ",", "majority", "voting", "(", "MV", ")", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "to", "decide", "which", "target", "in", "the", "library", "best", "fits", "the", "model", "built", "from", "the", "received", "signal", "."], "sentence-detokenized": "This is done by modelling the received signal, and then using a statistical estimation method such as maximum likelihood (ML), majority voting (MV) or maximum a posteriori (MAP) to decide which target in the library best fits the model built from the received signal.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 25], [26, 29], [30, 38], [39, 45], [45, 46], [47, 50], [51, 55], [56, 61], [62, 63], [64, 75], [76, 86], [87, 93], [94, 98], [99, 101], [102, 109], [110, 120], [121, 122], [122, 124], [124, 125], [125, 126], [127, 135], [136, 142], [143, 144], [144, 146], [146, 147], [148, 150], [151, 158], [159, 160], [161, 171], [172, 173], [173, 176], [176, 177], [178, 180], [181, 187], [188, 193], [194, 200], [201, 203], [204, 207], [208, 215], [216, 220], [221, 225], [226, 229], [230, 235], [236, 241], [242, 246], [247, 250], [251, 259], [260, 266], [266, 267]]}
{"doc_key": "ai-dev-149", "ner": [[0, 0, "researcher"], [1, 2, "misc"], [3, 5, "field"], [6, 10, "university"], [14, 14, "field"], [17, 22, "university"], [27, 27, "misc"], [28, 32, "field"], [33, 35, "university"], [39, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10], "relations": [[0, 0, 6, 10, "physical", "", false, false], [0, 0, 6, 10, "role", "", false, false], [0, 0, 17, 22, "physical", "", false, false], [0, 0, 17, 22, "role", "", false, false], [0, 0, 33, 35, "physical", "", false, false], [0, 0, 33, 35, "role", "", false, false], [1, 2, 0, 0, "origin", "", false, false], [1, 2, 3, 5, "topic", "", false, false], [27, 27, 0, 0, "origin", "", false, false], [27, 27, 28, 32, "topic", "", false, false], [39, 47, 27, 27, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12], "sentence": ["Sowa", "graduated", "in", "mathematics", "from", "the", "Massachusetts", "Institute", "of", "Technology", "in", "1962", ",", "in", "applied", "mathematics", "from", "Harvard", "University", "in", "1966", ",", "and", "in", "1999", "received", "a", "PhD", "in", "computer", "science", "from", "the", "Vrije", "Universiteit", "Brussel", "with", "his", "dissertation", "Knowledge", "Representation", ":", "logical", ",", "philosophical", "and", "computational", "foundations", "."], "sentence-detokenized": "Sowa graduated in mathematics from the Massachusetts Institute of Technology in 1962, in applied mathematics from Harvard University in 1966, and in 1999 received a PhD in computer science from the Vrije Universiteit Brussel with his dissertation Knowledge Representation: logical, philosophical and computational foundations.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 29], [30, 34], [35, 38], [39, 52], [53, 62], [63, 65], [66, 76], [77, 79], [80, 84], [84, 85], [86, 88], [89, 96], [97, 108], [109, 113], [114, 121], [122, 132], [133, 135], [136, 140], [140, 141], [142, 145], [146, 148], [149, 153], [154, 162], [163, 164], [165, 168], [169, 171], [172, 180], [181, 188], [189, 193], [194, 197], [198, 203], [204, 216], [217, 224], [225, 229], [230, 233], [234, 246], [247, 256], [257, 271], [271, 272], [273, 280], [280, 281], [282, 295], [296, 299], [300, 313], [314, 325], [325, 326]]}
{"doc_key": "ai-dev-150", "ner": [[1, 4, "task"], [11, 11, "task"], [20, 20, "metrics"], [22, 23, "metrics"], [25, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 4, 11, 11, "general-affiliation", "", false, false], [20, 20, 1, 4, "part-of", "", true, false], [22, 23, 1, 4, "part-of", "", true, false], [25, 26, 1, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "the", "detection", "of", "paraphrases", "can", "also", "be", "raised", "as", "a", "classification", "problem", ",", "most", "standard", "evaluation", "metrics", "such", "as", "accuracy", ",", "f1", "score", "or", "ROC", "curve", "are", "relatively", "well", "suited", "."], "sentence-detokenized": "Since the detection of paraphrases can also be raised as a classification problem, most standard evaluation metrics such as accuracy, f1 score or ROC curve are relatively well suited.", "token2charspan": [[0, 5], [6, 9], [10, 19], [20, 22], [23, 34], [35, 38], [39, 43], [44, 46], [47, 53], [54, 56], [57, 58], [59, 73], [74, 81], [81, 82], [83, 87], [88, 96], [97, 107], [108, 115], [116, 120], [121, 123], [124, 132], [132, 133], [134, 136], [137, 142], [143, 145], [146, 149], [150, 155], [156, 159], [160, 170], [171, 175], [176, 182], [182, 183]]}
{"doc_key": "ai-dev-151", "ner": [[7, 7, "algorithm"], [25, 26, "algorithm"], [28, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 25, 26, "opposite", "not_suited_for", false, false], [7, 7, 28, 29, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "makes", "it", "practical", "for", "analysing", "and", "bootstrapping", "large", "datasets", "(", "hundreds", "or", "thousands", "of", "taxa", ")", ",", "for", "which", "other", "analysis", "methods", "(", "e.g.", "maximum", "parsimony", ",", "maximum", "likelihood", ")", "may", "be", "too", "computationally", "burdensome", "."], "sentence-detokenized": "This makes it practical for analysing and bootstrapping large datasets (hundreds or thousands of taxa), for which other analysis methods (e.g. maximum parsimony, maximum likelihood) may be too computationally burdensome.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 37], [38, 41], [42, 55], [56, 61], [62, 70], [71, 72], [72, 80], [81, 83], [84, 93], [94, 96], [97, 101], [101, 102], [102, 103], [104, 107], [108, 113], [114, 119], [120, 128], [129, 136], [137, 138], [138, 142], [143, 150], [151, 160], [160, 161], [162, 169], [170, 180], [180, 181], [182, 185], [186, 188], [189, 192], [193, 208], [209, 219], [219, 220]]}
{"doc_key": "ai-dev-152", "ner": [[4, 5, "programlang"], [7, 7, "programlang"], [9, 14, "organisation"], [11, 19, "organisation"], [23, 23, "programlang"], [28, 38, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 23, 23, "named", "same", false, false], [11, 19, 9, 14, "named", "", false, false], [28, 38, 4, 5, "role", "submits", true, false], [28, 38, 7, 7, "role", "submits", true, false], [28, 38, 9, 14, "role", "submits_to", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2002", "submission", "of", "the", "DAML", "+", "OIL", "language", "to", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", "is", "the", "work", "of", "the", "DAML", "Contracting", "Parties", "and", "the", "ad", "hoc", "European", "Union", "/", "United", "States", "Markup", "Languages", "Joint", "Committee", "."], "sentence-detokenized": "The 2002 submission of the DAML + OIL language to the World Wide Web Consortium (W3C) is the work of the DAML Contracting Parties and the ad hoc European Union/United States Markup Languages Joint Committee.", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 22], [23, 26], [27, 31], [32, 33], [34, 37], [38, 46], [47, 49], [50, 53], [54, 59], [60, 64], [65, 68], [69, 79], [80, 81], [81, 84], [84, 85], [86, 88], [89, 92], [93, 97], [98, 100], [101, 104], [105, 109], [110, 121], [122, 129], [130, 133], [134, 137], [138, 140], [141, 144], [145, 153], [154, 159], [159, 160], [160, 166], [167, 173], [174, 180], [181, 190], [191, 196], [197, 206], [206, 207]]}
{"doc_key": "ai-dev-153", "ner": [[2, 6, "misc"], [9, 9, "misc"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 2, 6, "part-of", "", true, false], [12, 13, 2, 6, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "non-linear", "normalization", "is", "when", "the", "normalization", "follows", "a", "sigmoid", "function", ",", "in", "which", "case", "the", "normalized", "image", "is", "calculated", "according", "to", "the", "following", "formula"], "sentence-detokenized": "An example of a non-linear normalization is when the normalization follows a sigmoid function, in which case the normalized image is calculated according to the following formula", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 26], [27, 40], [41, 43], [44, 48], [49, 52], [53, 66], [67, 74], [75, 76], [77, 84], [85, 93], [93, 94], [95, 97], [98, 103], [104, 108], [109, 112], [113, 123], [124, 129], [130, 132], [133, 143], [144, 153], [154, 156], [157, 160], [161, 170], [171, 178]]}
{"doc_key": "ai-dev-154", "ner": [[4, 5, "metrics"], [8, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 8, 10, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "pointed", "out", "that", "punctuality", "is", "usually", "linked", "to", "recall", "to", "overcome", "this", "problem", "."], "sentence-detokenized": "They pointed out that punctuality is usually linked to recall to overcome this problem.", "token2charspan": [[0, 4], [5, 12], [13, 16], [17, 21], [22, 33], [34, 36], [37, 44], [45, 51], [52, 54], [55, 61], [62, 64], [65, 73], [74, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-dev-155", "ner": [[7, 9, "metrics"], [6, 17, "metrics"], [23, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 6, 17, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "commonly", "used", "metrics", "are", "the", "root", "mean", "square", "error", "and", "the", "root", "mean", "square", "error", ",", "the", "latter", "being", "used", "in", "the", "Netflix", "Prize", "."], "sentence-detokenized": "The commonly used metrics are the root mean square error and the root mean square error, the latter being used in the Netflix Prize.", "token2charspan": [[0, 3], [4, 12], [13, 17], [18, 25], [26, 29], [30, 33], [34, 38], [39, 43], [44, 50], [51, 56], [57, 60], [61, 64], [65, 69], [70, 74], [75, 81], [82, 87], [87, 88], [89, 92], [93, 99], [100, 105], [106, 110], [111, 113], [114, 117], [118, 125], [126, 131], [131, 132]]}
{"doc_key": "ai-dev-156", "ner": [[10, 13, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "August", "2016", ",", "they", "announced", "a", "research", "programme", "with", "University", "College", "Hospital", "to", "develop", "an", "algorithm", "that", "can", "automatically", "distinguish", "between", "healthy", "and", "cancerous", "tissue", "in", "the", "head", "and", "neck", "."], "sentence-detokenized": "In August 2016, they announced a research programme with University College Hospital to develop an algorithm that can automatically distinguish between healthy and cancerous tissue in the head and neck.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 20], [21, 30], [31, 32], [33, 41], [42, 51], [52, 56], [57, 67], [68, 75], [76, 84], [85, 87], [88, 95], [96, 98], [99, 108], [109, 113], [114, 117], [118, 131], [132, 143], [144, 151], [152, 159], [160, 163], [164, 173], [174, 180], [181, 183], [184, 187], [188, 192], [193, 196], [197, 201], [201, 202]]}
{"doc_key": "ai-dev-157", "ner": [[0, 1, "researcher"], [13, 15, "organisation"], [18, 21, "organisation"], [24, 27, "organisation"], [30, 35, "organisation"], [38, 44, "organisation"], [48, 51, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 13, 15, "role", "", false, false], [0, 1, 18, 21, "role", "", false, false], [0, 1, 24, 27, "role", "", false, false], [0, 1, 30, 35, "role", "", false, false], [0, 1, 38, 44, "role", "", false, false], [0, 1, 48, 51, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Posner", "'s", "theoretical", "and", "empirical", "contributions", "have", "been", "recognized", "by", "fellowships", "from", "the", "American", "Psychological", "Association", ",", "the", "Society", "for", "Psychological", "Science", ",", "the", "Society", "of", "Experimental", "Psychologists", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Posner's theoretical and empirical contributions have been recognized by fellowships from the American Psychological Association, the Society for Psychological Science, the Society of Experimental Psychologists, the American Academy of Arts and Sciences, the American Association for the Advancement of Science, and the National Academy of Sciences.", "token2charspan": [[0, 6], [6, 8], [9, 20], [21, 24], [25, 34], [35, 48], [49, 53], [54, 58], [59, 69], [70, 72], [73, 84], [85, 89], [90, 93], [94, 102], [103, 116], [117, 128], [128, 129], [130, 133], [134, 141], [142, 145], [146, 159], [160, 167], [167, 168], [169, 172], [173, 180], [181, 183], [184, 196], [197, 210], [210, 211], [212, 215], [216, 224], [225, 232], [233, 235], [236, 240], [241, 244], [245, 253], [253, 254], [255, 258], [259, 267], [268, 279], [280, 283], [284, 287], [288, 299], [300, 302], [303, 310], [310, 311], [312, 315], [316, 319], [320, 328], [329, 336], [337, 339], [340, 348], [348, 349]]}
{"doc_key": "ai-dev-158", "ner": [[2, 2, "product"], [3, 8, "field"], [12, 13, "task"], [17, 17, "task"], [19, 19, "task"], [22, 24, "task"], [26, 26, "task"], [29, 30, "field"], [32, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 2, 3, 8, "usage", "", false, false], [12, 13, 3, 8, "part-of", "", false, false], [17, 17, 3, 8, "part-of", "", false, false], [19, 19, 17, 17, "named", "", false, false], [22, 24, 3, 8, "part-of", "", false, false], [26, 26, 22, 24, "named", "", false, false], [29, 30, 3, 8, "part-of", "", false, false], [32, 33, 3, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["These", "intelligent", "chatbots", "use", "all", "kinds", "of", "artificial", "intelligence", ",", "such", "as", "image", "moderation", "and", "natural", "language", "understanding", "(", "NLU", ")", ",", "natural", "language", "generation", "(", "NLG", ")", ",", "machine", "learning", "and", "deep", "learning", "."], "sentence-detokenized": "These intelligent chatbots use all kinds of artificial intelligence, such as image moderation and natural language understanding (NLU), natural language generation (NLG), machine learning and deep learning.", "token2charspan": [[0, 5], [6, 17], [18, 26], [27, 30], [31, 34], [35, 40], [41, 43], [44, 54], [55, 67], [67, 68], [69, 73], [74, 76], [77, 82], [83, 93], [94, 97], [98, 105], [106, 114], [115, 128], [129, 130], [130, 133], [133, 134], [134, 135], [136, 143], [144, 152], [153, 163], [164, 165], [165, 168], [168, 169], [169, 170], [171, 178], [179, 187], [188, 191], [192, 196], [197, 205], [205, 206]]}
{"doc_key": "ai-dev-159", "ner": [[6, 6, "metrics"], [7, 10, "metrics"], [15, 15, "metrics"], [18, 24, "metrics"], [29, 31, "metrics"], [33, 33, "metrics"], [36, 43, "metrics"], [47, 48, "metrics"], [50, 50, "metrics"], [53, 60, "metrics"], [64, 66, "metrics"], [68, 68, "metrics"], [71, 78, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[7, 10, 6, 6, "named", "", false, false], [15, 15, 6, 6, "named", "", false, false], [18, 24, 6, 6, "named", "", false, false], [33, 33, 29, 31, "named", "", false, false], [36, 43, 29, 31, "named", "", false, false], [50, 50, 47, 48, "named", "", false, false], [53, 60, 47, 48, "named", "", false, false], [68, 68, 64, 66, "named", "", false, false], [71, 78, 64, 66, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "ratios", "in", "the", "row", "are", "Positive", "Predictive", "Value", "(", "PPV", ",", "also", "known", "as", "precision", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "plus", "the", "HIBA", "Discovery", "Ratio", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "and", "Negative", "Predictive", "Value", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "plus", "the", "HIBA", "Dropout", "Ratio", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "The ratios in the row are Positive Predictive Value (PPV, also known as precision) (TP / (TP + FP)), plus the HIBA Discovery Ratio (FDR) (FP / (TP + FP)); and Negative Predictive Value (NPV) (TN / (TN + FN)), plus the HIBA Dropout Ratio (FOR) (FN / (TN + FN)).", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 17], [18, 21], [22, 25], [26, 34], [35, 45], [46, 51], [52, 53], [53, 56], [56, 57], [58, 62], [63, 68], [69, 71], [72, 81], [81, 82], [83, 84], [84, 86], [87, 88], [89, 90], [90, 92], [93, 94], [95, 97], [97, 98], [98, 99], [99, 100], [101, 105], [106, 109], [110, 114], [115, 124], [125, 130], [131, 132], [132, 135], [135, 136], [137, 138], [138, 140], [141, 142], [143, 144], [144, 146], [147, 148], [149, 151], [151, 152], [152, 153], [153, 154], [155, 158], [159, 167], [168, 178], [179, 184], [185, 186], [186, 189], [189, 190], [191, 192], [192, 194], [195, 196], [197, 198], [198, 200], [201, 202], [203, 205], [205, 206], [206, 207], [207, 208], [209, 213], [214, 217], [218, 222], [223, 230], [231, 236], [237, 238], [238, 241], [241, 242], [243, 244], [244, 246], [247, 248], [249, 250], [250, 252], [253, 254], [255, 257], [257, 258], [258, 259], [259, 260]]}
{"doc_key": "ai-dev-160", "ner": [[8, 10, "misc"], [14, 17, "algorithm"], [22, 22, "algorithm"], [20, 24, "algorithm"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[20, 24, 22, 22, "named", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["The", "information", "is", "a", "mixture", "of", "sitemaps", "and", "RSS", "and", "is", "generated", "using", "the", "Information", "Model", "(", "IM", ")", "and", "Biomedical", "Resource", "Ontology", "(", "BRO", ")", "."], "sentence-detokenized": "The information is a mixture of sitemaps and RSS and is generated using the Information Model (IM) and Biomedical Resource Ontology (BRO).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 20], [21, 28], [29, 31], [32, 40], [41, 44], [45, 48], [49, 52], [53, 55], [56, 65], [66, 71], [72, 75], [76, 87], [88, 93], [94, 95], [95, 97], [97, 98], [99, 102], [103, 113], [114, 122], [123, 131], [132, 133], [133, 136], [136, 137], [137, 138]]}
{"doc_key": "ai-dev-161", "ner": [[1, 2, "task"], [6, 9, "algorithm"], [11, 15, "algorithm"], [22, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 11, 15, "origin", "based_on", false, false], [11, 15, 6, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Recent", "text", "recognition", "is", "based", "on", "a", "recurrent", "neural", "network", "(", "long", "short", "-", "term", "memory", ")", "and", "does", "not", "require", "a", "language", "model", "."], "sentence-detokenized": "Recent text recognition is based on a recurrent neural network (long short-term memory) and does not require a language model.", "token2charspan": [[0, 6], [7, 11], [12, 23], [24, 26], [27, 32], [33, 35], [36, 37], [38, 47], [48, 54], [55, 62], [63, 64], [64, 68], [69, 74], [74, 75], [75, 79], [80, 86], [86, 87], [88, 91], [92, 96], [97, 100], [101, 108], [109, 110], [111, 119], [120, 125], [125, 126]]}
{"doc_key": "ai-dev-162", "ner": [[1, 2, "misc"], [4, 5, "metrics"], [8, 9, "algorithm"], [12, 13, "metrics"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 1, 2, "type-of", "", false, false], [8, 9, 4, 5, "related-to", "", true, false], [12, 13, 1, 2, "type-of", "", false, false], [16, 17, 12, 13, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Popular", "loss", "functions", "include", "hinge", "loss", "(", "for", "linear", "SVMs", ")", "and", "log", "loss", "(", "for", "logistic", "regression", ")", "."], "sentence-detokenized": "Popular loss functions include hinge loss (for linear SVMs) and log loss (for logistic regression).", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 30], [31, 36], [37, 41], [42, 43], [43, 46], [47, 53], [54, 58], [58, 59], [60, 63], [64, 67], [68, 72], [73, 74], [74, 77], [78, 86], [87, 97], [97, 98], [98, 99]]}
{"doc_key": "ai-dev-163", "ner": [[0, 2, "metrics"], [9, 14, "metrics"], [16, 16, "metrics"], [20, 21, "metrics"], [19, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 9, 14, "compare", "", false, false], [0, 2, 20, 21, "compare", "", false, false], [16, 16, 9, 14, "named", "", false, false], [19, 23, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "aims", "to", "improve", "on", "traditional", "methods", "such", "as", "signal", "-", "to", "-", "noise", "ratio", "(", "PSNR", ")", "and", "mean", "squared", "error", "(", "MSE", ")", "."], "sentence-detokenized": "SSIM aims to improve on traditional methods such as signal-to-noise ratio (PSNR) and mean squared error (MSE).", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 20], [21, 23], [24, 35], [36, 43], [44, 48], [49, 51], [52, 58], [58, 59], [59, 61], [61, 62], [62, 67], [68, 73], [74, 75], [75, 79], [79, 80], [81, 84], [85, 89], [90, 97], [98, 103], [104, 105], [105, 108], [108, 109], [109, 110]]}
{"doc_key": "ai-dev-164", "ner": [[11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "has", "inspired", "later", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "His work has inspired later generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 21], [22, 27], [28, 39], [40, 42], [43, 51], [52, 63], [64, 68], [69, 71], [72, 78], [79, 85], [85, 86], [87, 91], [92, 99], [100, 103], [104, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-dev-165", "ner": [[18, 19, "algorithm"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Furthermore", ",", "impulse", "training", "is", "not", "differentiable", ",", "which", "rules", "out", "backpropagation", "-", "based", "training", "methods", "such", "as", "gradient", "descent", "."], "sentence-detokenized": "Furthermore, impulse training is not differentiable, which rules out backpropagation-based training methods such as gradient descent.", "token2charspan": [[0, 11], [11, 12], [13, 20], [21, 29], [30, 32], [33, 36], [37, 51], [51, 52], [53, 58], [59, 64], [65, 68], [69, 84], [84, 85], [85, 90], [91, 99], [100, 107], [108, 112], [113, 115], [116, 124], [125, 132], [132, 133]]}
{"doc_key": "ai-dev-166", "ner": [[7, 8, "metrics"], [15, 17, "metrics"], [19, 19, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 15, 17, "related-to", "describes", false, false], [15, 17, 19, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "relationship", "is", "easily", "represented", "by", "a", "perturbation", "matrix", ",", "which", "is", "a", "table", "describing", "the", "accuracy", "of", "a", "classification", "model", "."], "sentence-detokenized": "This relationship is easily represented by a perturbation matrix, which is a table describing the accuracy of a classification model.", "token2charspan": [[0, 4], [5, 17], [18, 20], [21, 27], [28, 39], [40, 42], [43, 44], [45, 57], [58, 64], [64, 65], [66, 71], [72, 74], [75, 76], [77, 82], [83, 93], [94, 97], [98, 106], [107, 109], [110, 111], [112, 126], [127, 132], [132, 133]]}
{"doc_key": "ai-dev-167", "ner": [[0, 7, "conference"], [3, 9, "conference"], [12, 12, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 9, 0, 7, "named", "", false, false], [12, 12, 0, 7, "physical", "", false, false], [12, 12, 0, 7, "role", "", false, false], [12, 12, 0, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["At", "the", "2018", "Neural", "Information", "Processing", "Systems", "Conference", "(", "NeurIPS", ")", ",", "Google", "researchers", "presented", "their", "work", "."], "sentence-detokenized": "At the 2018 Neural Information Processing Systems Conference (NeurIPS), Google researchers presented their work.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 30], [31, 41], [42, 49], [50, 60], [61, 62], [62, 69], [69, 70], [70, 71], [72, 78], [79, 90], [91, 100], [101, 106], [107, 111], [111, 112]]}
{"doc_key": "ai-dev-168", "ner": [[3, 4, "university"], [15, 15, "product"], [21, 24, "misc"], [20, 20, "conference"], [31, 34, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 15, 21, 24, "win-defeat", "", false, false], [21, 24, 20, 20, "temporal", "", false, false], [31, 34, 20, 20, "part-of", "", false, false], [31, 34, 20, 20, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "his", "time", "at", "Duke", ",", "he", "worked", "on", "an", "automated", "crossword", "puzzle", "program", "called", "PROVERB", ",", "which", "won", "the", "AAAI", "Outstanding", "Paper", "Award", "in", "1999", ",", "and", "participated", "in", "the", "American", "Crossword", "Puzzle", "Tournament", "."], "sentence-detokenized": "During his time at Duke, he worked on an automated crossword puzzle program called PROVERB, which won the AAAI Outstanding Paper Award in 1999, and participated in the American Crossword Puzzle Tournament.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 18], [19, 23], [23, 24], [25, 27], [28, 34], [35, 37], [38, 40], [41, 50], [51, 60], [61, 67], [68, 75], [76, 82], [83, 90], [90, 91], [92, 97], [98, 101], [102, 105], [106, 110], [111, 122], [123, 128], [129, 134], [135, 137], [138, 142], [142, 143], [144, 147], [148, 160], [161, 163], [164, 167], [168, 176], [177, 186], [187, 193], [194, 204], [204, 205]]}
{"doc_key": "ai-dev-169", "ner": [[2, 3, "location"], [5, 7, "location"], [14, 15, "country"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 5, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Headquartered", "in", "Rochester", "Hills", ",", "Michigan", ",", "it", "had", "10", "regional", "offices", "in", "the", "United", "States", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "sentence-detokenized": "Headquartered in Rochester Hills, Michigan, it had 10 regional offices in the United States, Canada, Mexico and Brazil.", "token2charspan": [[0, 13], [14, 16], [17, 26], [27, 32], [32, 33], [34, 42], [42, 43], [44, 46], [47, 50], [51, 53], [54, 62], [63, 70], [71, 73], [74, 77], [78, 84], [85, 91], [91, 92], [93, 99], [99, 100], [101, 107], [108, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-dev-170", "ner": [[13, 13, "product"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "robot", "joins", "a", "collection", "of", "historically", "important", "robots", ",", "including", "an", "early", "Unimate", "and", "the", "Odetics", "Odex", "1", "."], "sentence-detokenized": "The robot joins a collection of historically important robots, including an early Unimate and the Odetics Odex 1.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 17], [18, 28], [29, 31], [32, 44], [45, 54], [55, 61], [61, 62], [63, 72], [73, 75], [76, 81], [82, 89], [90, 93], [94, 97], [98, 105], [106, 110], [111, 112], [112, 113]]}
{"doc_key": "ai-dev-171", "ner": [[8, 9, "researcher"], [12, 13, "organisation"], [15, 16, "researcher"], [18, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 12, 13, "physical", "", false, false], [8, 9, 12, 13, "role", "", false, false], [15, 16, 12, 13, "physical", "", false, false], [15, 16, 12, 13, "role", "", false, false], [15, 16, 18, 25, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "guest", "editor", "for", "this", "issue", "will", "be", "David", "'s", "former", "colleague", "at", "NIST", ",", "Judah", "Levine", ",", "winner", "of", "the", "recent", "I.I.I", ".", "Rabi", "Award", "."], "sentence-detokenized": "The guest editor for this issue will be David's former colleague at NIST, Judah Levine, winner of the recent I.I.I. Rabi Award.", "token2charspan": [[0, 3], [4, 9], [10, 16], [17, 20], [21, 25], [26, 31], [32, 36], [37, 39], [40, 45], [45, 47], [48, 54], [55, 64], [65, 67], [68, 72], [72, 73], [74, 79], [80, 86], [86, 87], [88, 94], [95, 97], [98, 101], [102, 108], [109, 114], [114, 115], [116, 120], [121, 126], [126, 127]]}
{"doc_key": "ai-dev-172", "ner": [[12, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "can", "be", "arranged", "in", "a", "2", "\u00d7", "2", "contingency", "table", "(", "perturbation", "matrix", ")", ",", "where", "the", "vertical", "axis", "is", "the", "test", "result", "and", "the", "horizontal", "axis", "is", "the", "actual", "state", "."], "sentence-detokenized": "These can be arranged in a 2 \u00d7 2 contingency table (perturbation matrix), where the vertical axis is the test result and the horizontal axis is the actual state.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 21], [22, 24], [25, 26], [27, 28], [29, 30], [31, 32], [33, 44], [45, 50], [51, 52], [52, 64], [65, 71], [71, 72], [72, 73], [74, 79], [80, 83], [84, 92], [93, 97], [98, 100], [101, 104], [105, 109], [110, 116], [117, 120], [121, 124], [125, 135], [136, 140], [141, 143], [144, 147], [148, 154], [155, 160], [160, 161]]}
{"doc_key": "ai-dev-173", "ner": [[0, 4, "product"], [9, 9, "product"], [11, 11, "product"], [6, 14, "product"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 9, 9, "part-of", "", false, false], [0, 4, 11, 11, "part-of", "", false, false], [0, 4, 6, 14, "part-of", "", false, false], [0, 4, 17, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Apple", "'s", "iOS", "operating", "system", ",", "used", "by", "the", "iPhone", ",", "iPad", "and", "iPod", "Touch", ",", "uses", "VoiceOver", "speech", "synthesis", "accessibility", "."], "sentence-detokenized": "Apple's iOS operating system, used by the iPhone, iPad and iPod Touch, uses VoiceOver speech synthesis accessibility.", "token2charspan": [[0, 5], [5, 7], [8, 11], [12, 21], [22, 28], [28, 29], [30, 34], [35, 37], [38, 41], [42, 48], [48, 49], [50, 54], [55, 58], [59, 63], [64, 69], [69, 70], [71, 75], [76, 85], [86, 92], [93, 102], [103, 116], [116, 117]]}
{"doc_key": "ai-dev-174", "ner": [[7, 9, "conference"], [12, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "the", "best", "system", "typing", "MUC", "-", "7", "achieved", "an", "F-", "measure", "of", "93.39", "%", ",", "while", "the", "human", "annotators", "achieved", "97.6", "%", "and", "96.95", "%", "respectively", "."], "sentence-detokenized": "For example, the best system typing MUC-7 achieved an F-measure of 93.39%, while the human annotators achieved 97.6% and 96.95% respectively.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 35], [36, 39], [39, 40], [40, 41], [42, 50], [51, 53], [54, 56], [56, 63], [64, 66], [67, 72], [72, 73], [73, 74], [75, 80], [81, 84], [85, 90], [91, 101], [102, 110], [111, 115], [115, 116], [117, 120], [121, 126], [126, 127], [128, 140], [140, 141]]}
{"doc_key": "ai-dev-175", "ner": [[11, 13, "algorithm"], [3, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 15, 11, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "done", "using", "standard", "neural", "network", "building", "algorithms", "such", "as", "stochastic", "gradient", "descent", "and", "backpropagation", "."], "sentence-detokenized": "This is done using standard neural network building algorithms such as stochastic gradient descent and backpropagation.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 18], [19, 27], [28, 34], [35, 42], [43, 51], [52, 62], [63, 67], [68, 70], [71, 81], [82, 90], [91, 98], [99, 102], [103, 118], [118, 119]]}
{"doc_key": "ai-dev-176", "ner": [[0, 1, "organisation"], [25, 25, "country"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 25, 25, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "is", "ranked", "in", "the", "top", "1000", "by", "the", "website", "Alexa", ",", "in", "the", "top", "400", "globally", "and", "in", "the", "top", "150", "in", "the", "US", "."], "sentence-detokenized": "Rotten Tomatoes is ranked in the top 1000 by the website Alexa, in the top 400 globally and in the top 150 in the US.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 25], [26, 28], [29, 32], [33, 36], [37, 41], [42, 44], [45, 48], [49, 56], [57, 62], [62, 63], [64, 66], [67, 70], [71, 74], [75, 78], [79, 87], [88, 91], [92, 94], [95, 98], [99, 102], [103, 106], [107, 109], [110, 113], [114, 116], [116, 117]]}
{"doc_key": "ai-dev-177", "ner": [[14, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "general", ",", "all", "learning", "exhibits", "incremental", "change", "over", "time", ",", "but", "describes", "a", "simmoid", "function", "that", "appears", "differently", "depending", "on", "the", "timescale", "of", "the", "observation", "."], "sentence-detokenized": "In general, all learning exhibits incremental change over time, but describes a simmoid function that appears differently depending on the timescale of the observation.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 24], [25, 33], [34, 45], [46, 52], [53, 57], [58, 62], [62, 63], [64, 67], [68, 77], [78, 79], [80, 87], [88, 96], [97, 101], [102, 109], [110, 121], [122, 131], [132, 134], [135, 138], [139, 148], [149, 151], [152, 155], [156, 167], [167, 168]]}
{"doc_key": "ai-dev-178", "ner": [[0, 0, "metrics"], [4, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 6, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["SSD", "is", "also", "called", "mean", "square", "error", "."], "sentence-detokenized": "SSD is also called mean square error.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 18], [19, 23], [24, 30], [31, 36], [36, 37]]}
{"doc_key": "ai-dev-179", "ner": [[0, 2, "algorithm"], [4, 5, "algorithm"], [7, 9, "algorithm"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 20, 21, "related-to", "can_be_related_to", true, false], [4, 5, 20, 21, "related-to", "can_be_related_to", true, false], [7, 9, 20, 21, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", ",", "neural", "networks", "or", "na\u00efve", "Bayes", "classifiers", "can", "be", "combined", "with", "measures", "of", "model", "quality", "such", "as", "balanced", "accuracy", "."], "sentence-detokenized": "Decision tree learning, neural networks or na\u00efve Bayes classifiers can be combined with measures of model quality such as balanced accuracy.", "token2charspan": [[0, 8], [9, 13], [14, 22], [22, 23], [24, 30], [31, 39], [40, 42], [43, 48], [49, 54], [55, 66], [67, 70], [71, 73], [74, 82], [83, 87], [88, 96], [97, 99], [100, 105], [106, 113], [114, 118], [119, 121], [122, 130], [131, 139], [139, 140]]}
{"doc_key": "ai-dev-180", "ner": [[16, 16, "conference"], [19, 26, "conference"], [27, 31, "misc"], [33, 40, "product"], [44, 47, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[27, 31, 19, 26, "origin", "", false, false], [27, 31, 19, 26, "temporal", "", false, false], [33, 40, 27, 31, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "is", "a", "past", "president", "(", "1979", ")", "and", "first", "member", "(", "2011", ")", "of", "the", "ACL", ",", "a", "1992", "co-winner", "of", "the", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "for", "his", "contributions", "to", "the", "Interlisp", "programming", "system", ",", "and", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "He is a past president (1979) and first member (2011) of the ACL, a 1992 co-winner of the Association for Computing Machinery Software Systems Award for his contributions to the Interlisp programming system, and a member of the Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 22], [23, 24], [24, 28], [28, 29], [30, 33], [34, 39], [40, 46], [47, 48], [48, 52], [52, 53], [54, 56], [57, 60], [61, 64], [64, 65], [66, 67], [68, 72], [73, 82], [83, 85], [86, 89], [90, 101], [102, 105], [106, 115], [116, 125], [126, 134], [135, 142], [143, 148], [149, 152], [153, 156], [157, 170], [171, 173], [174, 177], [178, 187], [188, 199], [200, 206], [206, 207], [208, 211], [212, 213], [214, 220], [221, 223], [224, 227], [228, 239], [240, 243], [244, 253], [254, 263], [263, 264]]}
{"doc_key": "ai-dev-181", "ner": [[1, 2, "researcher"], [4, 5, "researcher"], [10, 11, "researcher"], [7, 8, "researcher"], [23, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 23, 26, "related-to", "", false, false], [4, 5, 23, 26, "related-to", "", false, false], [10, 11, 23, 26, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Alongside", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Cade", "Metz", "counts", "Bengio", "as", "one", "of", "the", "three", "people", "most", "responsible", "for", "the", "development", "of", "deep", "learning", "in", "the", "1990s", "and", "2000s", "."], "sentence-detokenized": "Alongside Geoffrey Hinton and Yann LeCun, Cade Metz counts Bengio as one of the three people most responsible for the development of deep learning in the 1990s and 2000s.", "token2charspan": [[0, 9], [10, 18], [19, 25], [26, 29], [30, 34], [35, 40], [40, 41], [42, 46], [47, 51], [52, 58], [59, 65], [66, 68], [69, 72], [73, 75], [76, 79], [80, 85], [86, 92], [93, 97], [98, 109], [110, 113], [114, 117], [118, 129], [130, 132], [133, 137], [138, 146], [147, 149], [150, 153], [154, 159], [160, 163], [164, 169], [169, 170]]}
{"doc_key": "ai-dev-182", "ner": [[0, 2, "field"], [4, 5, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "information", "theory", "and", "computer", "science", ",", "code", "is", "generally", "considered", "to", "be", "an", "algorithm", "that", "represents", "the", "symbols", "of", "some", "source", "alphabet", "by", "encoded", "strings", "of", "characters", "that", "may", "be", "in", "another", "target", "alphabet", "."], "sentence-detokenized": "In information theory and computer science, code is generally considered to be an algorithm that represents the symbols of some source alphabet by encoded strings of characters that may be in another target alphabet.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 48], [49, 51], [52, 61], [62, 72], [73, 75], [76, 78], [79, 81], [82, 91], [92, 96], [97, 107], [108, 111], [112, 119], [120, 122], [123, 127], [128, 134], [135, 143], [144, 146], [147, 154], [155, 162], [163, 165], [166, 176], [177, 181], [182, 185], [186, 188], [189, 191], [192, 199], [200, 206], [207, 215], [215, 216]]}
{"doc_key": "ai-dev-183", "ner": [[8, 12, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 15, 8, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "fairly", "simple", "non", "-linear", "function", ",", "the", "sigmoid", "function", ",", "such", "as", "the", "logistic", "function", ",", "also", "has", "an", "easily", "computable", "derivative", ",", "which", "can", "be", "important", "when", "calculating", "weight", "updates", "for", "a", "network", "."], "sentence-detokenized": "A fairly simple non-linear function, the sigmoid function, such as the logistic function, also has an easily computable derivative, which can be important when calculating weight updates for a network.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 19], [19, 26], [27, 35], [35, 36], [37, 40], [41, 48], [49, 57], [57, 58], [59, 63], [64, 66], [67, 70], [71, 79], [80, 88], [88, 89], [90, 94], [95, 98], [99, 101], [102, 108], [109, 119], [120, 130], [130, 131], [132, 137], [138, 141], [142, 144], [145, 154], [155, 159], [160, 171], [172, 178], [179, 186], [187, 190], [191, 192], [193, 200], [200, 201]]}
{"doc_key": "ai-dev-184", "ner": [[0, 0, "person"], [6, 6, "location"], [6, 10, "location"], [12, 14, "country"], [17, 17, "country"], [21, 22, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 6, "physical", "", false, false], [6, 6, 6, 10, "physical", "", false, false], [6, 10, 12, 14, "physical", "", false, false], [6, 10, 17, 17, "physical", "", false, false], [6, 10, 21, 22, "physical", "", false, false], [17, 17, 12, 14, "origin", "", false, false], [21, 22, 17, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "was", "born", "in", "1887", "in", "Hronov", "in", "the", "Czech", "Republic", "(", "Austria", "-", "Hungary", ",", "later", "Czechoslovakia", ",", "now", "the", "Czech", "Republic", ")", "."], "sentence-detokenized": "\u010capek was born in 1887 in Hronov in the Czech Republic (Austria-Hungary, later Czechoslovakia, now the Czech Republic).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 22], [23, 25], [26, 32], [33, 35], [36, 39], [40, 45], [46, 54], [55, 56], [56, 63], [63, 64], [64, 71], [71, 72], [73, 78], [79, 93], [93, 94], [95, 98], [99, 102], [103, 108], [109, 117], [117, 118], [118, 119]]}
{"doc_key": "ai-dev-185", "ner": [[5, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "special", "software", "can", "narrate", "RSS", "."], "sentence-detokenized": "Some special software can narrate RSS.", "token2charspan": [[0, 4], [5, 12], [13, 21], [22, 25], [26, 33], [34, 37], [37, 38]]}
{"doc_key": "ai-dev-186", "ner": [[7, 8, "task"], [12, 13, "task"], [15, 15, "task"], [18, 18, "task"], [20, 22, "task"], [29, 30, "task"], [32, 34, "task"], [39, 42, "task"], [43, 45, "product"], [47, 48, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 8, 12, 13, "related-to", "", true, false], [7, 8, 15, 15, "related-to", "", true, false], [7, 8, 18, 18, "related-to", "", true, false], [32, 34, 29, 30, "usage", "", true, false], [43, 45, 39, 42, "type-of", "", false, false], [47, 48, 39, 42, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Aspects", "of", "the", "ontology", "editors", "include", ":", "visual", "navigation", "options", "in", "the", "knowledge", "model", ",", "inference", "engines", "and", "extraction", ";", "support", "for", "modules", ";", "import", "and", "export", "of", "foreign", "knowledge", "representation", "languages", "for", "ontology", "insertion", ";", "and", "support", "for", "meta", "-ontologies", "such", "as", "OWL", "-", "S", ",", "Dublin", "Core", ",", "etc", "."], "sentence-detokenized": "Aspects of the ontology editors include: visual navigation options in the knowledge model, inference engines and extraction; support for modules; import and export of foreign knowledge representation languages for ontology insertion; and support for meta-ontologies such as OWL-S, Dublin Core, etc.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 23], [24, 31], [32, 39], [39, 40], [41, 47], [48, 58], [59, 66], [67, 69], [70, 73], [74, 83], [84, 89], [89, 90], [91, 100], [101, 108], [109, 112], [113, 123], [123, 124], [125, 132], [133, 136], [137, 144], [144, 145], [146, 152], [153, 156], [157, 163], [164, 166], [167, 174], [175, 184], [185, 199], [200, 209], [210, 213], [214, 222], [223, 232], [232, 233], [234, 237], [238, 245], [246, 249], [250, 254], [254, 265], [266, 270], [271, 273], [274, 277], [277, 278], [278, 279], [279, 280], [281, 287], [288, 292], [292, 293], [294, 297], [297, 298]]}
{"doc_key": "ai-dev-187", "ner": [[0, 1, "organisation"], [5, 10, "misc"], [14, 16, "task"], [21, 21, "field"], [24, 24, "misc"], [26, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 10, 0, 1, "origin", "", false, false], [14, 16, 5, 10, "part-of", "", false, false], [21, 21, 5, 10, "part-of", "", false, false], [24, 24, 21, 21, "type-of", "", false, false], [26, 28, 21, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "FBI", "has", "also", "launched", "its", "next", "-", "generation", "identification", "program", ",", "which", "includes", "facial", "recognition", "as", "well", "as", "more", "traditional", "biometrics", "such", "as", "fingerprints", "and", "iris", "scans", "that", "can", "be", "derived", "from", "both", "criminal", "and", "civil", "databases", "."], "sentence-detokenized": "The FBI has also launched its next-generation identification program, which includes facial recognition as well as more traditional biometrics such as fingerprints and iris scans that can be derived from both criminal and civil databases.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 25], [26, 29], [30, 34], [34, 35], [35, 45], [46, 60], [61, 68], [68, 69], [70, 75], [76, 84], [85, 91], [92, 103], [104, 106], [107, 111], [112, 114], [115, 119], [120, 131], [132, 142], [143, 147], [148, 150], [151, 163], [164, 167], [168, 172], [173, 178], [179, 183], [184, 187], [188, 190], [191, 198], [199, 203], [204, 208], [209, 217], [218, 221], [222, 227], [228, 237], [237, 238]]}
{"doc_key": "ai-dev-188", "ner": [[5, 6, "person"], [8, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "2016", "season", ",", "Samantha", "Ponder", "replaced", "Molly", "McGrath", "as", "host", "."], "sentence-detokenized": "For the 2016 season, Samantha Ponder replaced Molly McGrath as host.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 19], [19, 20], [21, 29], [30, 36], [37, 45], [46, 51], [52, 59], [60, 62], [63, 67], [67, 68]]}
{"doc_key": "ai-dev-189", "ner": [[3, 7, "algorithm"], [19, 23, "misc"], [25, 25, "misc"], [27, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "adversarial", "search", "algorithm", "that", "is", "commonly", "used", "for", "machine", "play", "of", "two", "-", "player", "games", "(", "Tic", "-", "tac", "-", "toe", ",", "chess", ",", "Go", ",", "etc.", ")", "."], "sentence-detokenized": "This is an adversarial search algorithm that is commonly used for machine play of two-player games (Tic-tac-toe, chess, Go, etc.).", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 29], [30, 39], [40, 44], [45, 47], [48, 56], [57, 61], [62, 65], [66, 73], [74, 78], [79, 81], [82, 85], [85, 86], [86, 92], [93, 98], [99, 100], [100, 103], [103, 104], [104, 107], [107, 108], [108, 111], [111, 112], [113, 118], [118, 119], [120, 122], [122, 123], [124, 128], [128, 129], [129, 130]]}
{"doc_key": "ai-dev-190", "ner": [[0, 3, "field"], [5, 6, "field"], [8, 9, "field"], [16, 17, "field"], [19, 20, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "covers", "computer", "vision", "or", "machine", "vision", "and", "medical", "imaging", ",", "and", "makes", "extensive", "use", "of", "pattern", "recognition", ",", "digital", "geometry", "and", "signal", "processing", "."], "sentence-detokenized": "It covers computer vision or machine vision and medical imaging, and makes extensive use of pattern recognition, digital geometry and signal processing.", "token2charspan": [[0, 2], [3, 9], [10, 18], [19, 25], [26, 28], [29, 36], [37, 43], [44, 47], [48, 55], [56, 63], [63, 64], [65, 68], [69, 74], [75, 84], [85, 88], [89, 91], [92, 99], [100, 111], [111, 112], [113, 120], [121, 129], [130, 133], [134, 140], [141, 151], [151, 152]]}
{"doc_key": "ai-dev-191", "ner": [[0, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "a", "facial", "recognition", "system", ",", "for", "example", ",", "the", "input", "would", "be", "a", "person", "'s", "face", "and", "the", "output", "would", "be", "the", "person", "'s", "name", "."], "sentence-detokenized": "In a facial recognition system, for example, the input would be a person's face and the output would be the person's name.", "token2charspan": [[0, 2], [3, 4], [5, 11], [12, 23], [24, 30], [30, 31], [32, 35], [36, 43], [43, 44], [45, 48], [49, 54], [55, 60], [61, 63], [64, 65], [66, 72], [72, 74], [75, 79], [80, 83], [84, 87], [88, 94], [95, 100], [101, 103], [104, 107], [108, 114], [114, 116], [117, 121], [121, 122]]}
{"doc_key": "ai-dev-192", "ner": [[0, 6, "organisation"], [3, 5, "product"], [8, 10, "product"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 6, 3, 5, "artifact", "", false, false], [3, 5, 8, 10, "part-of", "", false, false], [8, 10, 3, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc.", "introduced", "Face", "ID", "on", "the", "flagship", "i", "Phone", "X", "as", "the", "successor", "to", "Touch", "ID", ",", "the", "fingerprint", "-", "based", "biometric", "authentication", "system", "."], "sentence-detokenized": "Apple Inc. introduced Face ID on the flagship iPhone X as the successor to Touch ID, the fingerprint-based biometric authentication system.", "token2charspan": [[0, 5], [6, 10], [11, 21], [22, 26], [27, 29], [30, 32], [33, 36], [37, 45], [46, 47], [47, 52], [53, 54], [55, 57], [58, 61], [62, 71], [72, 74], [75, 80], [81, 83], [83, 84], [85, 88], [89, 100], [100, 101], [101, 106], [107, 116], [117, 131], [132, 138], [138, 139]]}
{"doc_key": "ai-dev-193", "ner": [[3, 5, "metrics"], [6, 9, "metrics"], [25, 28, "metrics"], [29, 34, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Either", "combine", "the", "F", "-", "measure", "with", "the", "R-", "squared", "evaluated", "on", "the", "output", "of", "the", "raw", "model", "and", "the", "target", "value", ";", "or", "the", "cost", "/", "benefit", "matrix", "with", "the", "correlation", "coefficient", ",", "and", "so", "on", "."], "sentence-detokenized": "Either combine the F-measure with the R-squared evaluated on the output of the raw model and the target value; or the cost/benefit matrix with the correlation coefficient, and so on.", "token2charspan": [[0, 6], [7, 14], [15, 18], [19, 20], [20, 21], [21, 28], [29, 33], [34, 37], [38, 40], [40, 47], [48, 57], [58, 60], [61, 64], [65, 71], [72, 74], [75, 78], [79, 82], [83, 88], [89, 92], [93, 96], [97, 103], [104, 109], [109, 110], [111, 113], [114, 117], [118, 122], [122, 123], [123, 130], [131, 137], [138, 142], [143, 146], [147, 158], [159, 170], [170, 171], [172, 175], [176, 178], [179, 181], [181, 182]]}
{"doc_key": "ai-dev-194", "ner": [[0, 11, "conference"], [17, 19, "location"], [21, 21, "location"], [24, 28, "location"], [29, 29, "location"], [31, 31, "country"], [38, 40, "location"], [44, 48, "location"], [43, 43, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 11, 17, 19, "physical", "", false, false], [0, 11, 24, 28, "physical", "", false, false], [0, 11, 38, 40, "physical", "", false, false], [0, 11, 44, 48, "physical", "", false, false], [17, 19, 21, 21, "physical", "", false, false], [24, 28, 29, 29, "physical", "", false, false], [29, 29, 31, 31, "physical", "", false, false], [38, 40, 43, 43, "physical", "", false, false], [44, 48, 43, 43, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "Spanish", "edition", "of", "the", "Campus", "Party", "has", "been", "held", "for", "the", "past", "15", "years", "at", "the", "Colegio", "Miguel", "Hern\u00e1ndez", "in", "Ceulaj", "and", "the", "Benalm\u00e1dena", "Municipal", "Sports", "Arena", "in", "M\u00e1laga", ",", "Spain", ",", "as", "well", "as", "at", "the", "Valencia", "County", "Fair", "and", "the", "Valencia", "City", "of", "Arts", "and", "Sciences", "."], "sentence-detokenized": "The Spanish edition of the Campus Party has been held for the past 15 years at the Colegio Miguel Hern\u00e1ndez in Ceulaj and the Benalm\u00e1dena Municipal Sports Arena in M\u00e1laga, Spain, as well as at the Valencia County Fair and the Valencia City of Arts and Sciences.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 22], [23, 26], [27, 33], [34, 39], [40, 43], [44, 48], [49, 53], [54, 57], [58, 61], [62, 66], [67, 69], [70, 75], [76, 78], [79, 82], [83, 90], [91, 97], [98, 107], [108, 110], [111, 117], [118, 121], [122, 125], [126, 137], [138, 147], [148, 154], [155, 160], [161, 163], [164, 170], [170, 171], [172, 177], [177, 178], [179, 181], [182, 186], [187, 189], [190, 192], [193, 196], [197, 205], [206, 212], [213, 217], [218, 221], [222, 225], [226, 234], [235, 239], [240, 242], [243, 247], [248, 251], [252, 260], [260, 261]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [13, 13, "programlang"], [17, 17, "product"], [19, 19, "product"], [23, 23, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 0, 0, "general-affiliation", "", false, false], [17, 17, 13, 13, "part-of", "", false, false], [19, 19, 13, 13, "part-of", "", false, false], [23, 23, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["gnuplot", "can", "be", "used", "to", "graph", "data", "from", "various", "programming", "languages", ",", "including", "Perl", "(", "via", "the", "PDL", "and", "CPAN", "packages", ")", ",", "Python", "(", "via", "the", ".", ")"], "sentence-detokenized": "gnuplot can be used to graph data from various programming languages, including Perl (via the PDL and CPAN packages), Python (via the.)", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 19], [20, 22], [23, 28], [29, 33], [34, 38], [39, 46], [47, 58], [59, 68], [68, 69], [70, 79], [80, 84], [85, 86], [86, 89], [90, 93], [94, 97], [98, 101], [102, 106], [107, 115], [115, 116], [116, 117], [118, 124], [125, 126], [126, 129], [130, 133], [133, 134], [134, 135]]}
{"doc_key": "ai-dev-196", "ner": [[3, 6, "product"], [19, 19, "conference"], [21, 21, "conference"], [35, 35, "conference"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 3, 6, "topic", "", false, false], [21, 21, 3, 6, "topic", "", false, false], [35, 35, 3, 6, "topic", "", false, false], [37, 37, 3, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "field", "of", "spoken", "dialogue", "systems", "is", "quite", "large", ",", "and", "includes", "research", "(", "at", "academic", "conferences", "such", "as", "SIGdial", "and", "Interspeech", ")", "and", "a", "large", "industrial", "sector", "(", "with", "its", "own", "meetings", "such", "as", "SpeechTek", "and", "AVIOS", ")", "."], "sentence-detokenized": "The field of spoken dialogue systems is quite large, and includes research (at academic conferences such as SIGdial and Interspeech) and a large industrial sector (with its own meetings such as SpeechTek and AVIOS).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 28], [29, 36], [37, 39], [40, 45], [46, 51], [51, 52], [53, 56], [57, 65], [66, 74], [75, 76], [76, 78], [79, 87], [88, 99], [100, 104], [105, 107], [108, 115], [116, 119], [120, 131], [131, 132], [133, 136], [137, 138], [139, 144], [145, 155], [156, 162], [163, 164], [164, 168], [169, 172], [173, 176], [177, 185], [186, 190], [191, 193], [194, 203], [204, 207], [208, 213], [213, 214], [214, 215]]}
{"doc_key": "ai-dev-197", "ner": [[0, 2, "field"], [6, 7, "task"], [9, 11, "task"], [13, 15, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 0, 2, "part-of", "task_part_of_field", false, false], [9, 11, 0, 2, "part-of", "task_part_of_field", false, false], [13, 15, 0, 2, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Natural", "language", "processing", "challenges", "often", "include", "speech", "recognition", ",", "natural", "language", "understanding", "and", "natural", "language", "generation", "."], "sentence-detokenized": "Natural language processing challenges often include speech recognition, natural language understanding and natural language generation.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 38], [39, 44], [45, 52], [53, 59], [60, 71], [71, 72], [73, 80], [81, 89], [90, 103], [104, 107], [108, 115], [116, 124], [125, 135], [135, 136]]}
{"doc_key": "ai-dev-198", "ner": [[9, 9, "product"], [6, 7, "product"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 6, 7, "part-of", "", false, false], [9, 9, 33, 34, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "such", "as", "the", "iOS", "operating", "system", "Siri", ",", "use", "a", "similar", "pattern", "recognition", "technique", "to", "text", "-", "based", "systems", ",", "but", "in", "the", "former", ",", "user", "input", "is", "provided", "via", "speech", "recognition", "."], "sentence-detokenized": "These systems, such as the iOS operating system Siri, use a similar pattern recognition technique to text-based systems, but in the former, user input is provided via speech recognition.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 26], [27, 30], [31, 40], [41, 47], [48, 52], [52, 53], [54, 57], [58, 59], [60, 67], [68, 75], [76, 87], [88, 97], [98, 100], [101, 105], [105, 106], [106, 111], [112, 119], [119, 120], [121, 124], [125, 127], [128, 131], [132, 138], [138, 139], [140, 144], [145, 150], [151, 153], [154, 162], [163, 166], [167, 173], [174, 185], [185, 186]]}
{"doc_key": "ai-dev-199", "ner": [[0, 3, "algorithm"], [16, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 16, 17, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["More", "exotic", "fitness", "functions", "that", "reveal", "the", "granularity", "of", "the", "model", "include", "the", "area", "under", "the", "ROC", "curve", "and", "the", "ranking", "."], "sentence-detokenized": "More exotic fitness functions that reveal the granularity of the model include the area under the ROC curve and the ranking.", "token2charspan": [[0, 4], [5, 11], [12, 19], [20, 29], [30, 34], [35, 41], [42, 45], [46, 57], [58, 60], [61, 64], [65, 70], [71, 78], [79, 82], [83, 87], [88, 93], [94, 97], [98, 101], [102, 107], [108, 111], [112, 115], [116, 123], [123, 124]]}
{"doc_key": "ai-dev-200", "ner": [[3, 4, "product"], [9, 12, "researcher"], [17, 19, "product"], [25, 27, "organisation"], [29, 29, "organisation"], [39, 41, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 9, 12, "origin", "", false, false], [9, 12, 25, 27, "role", "", false, false], [17, 19, 9, 12, "origin", "", false, false], [29, 29, 25, 27, "named", "", false, false], [39, 41, 25, 27, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "term", "\"", "semantic", "web", "\"", "was", "coined", "by", "Tim", "Berners", "-", "Lee", ",", "inventor", "of", "the", "World", "Wide", "Web", "and", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "oversees", "the", "development", "of", "the", "proposed", "semantic", "web", "standards", "."], "sentence-detokenized": "The term \"semantic web\" was coined by Tim Berners-Lee, inventor of the World Wide Web and director of the World Wide Web Consortium (W3C), which oversees the development of the proposed semantic web standards.", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 18], [19, 22], [22, 23], [24, 27], [28, 34], [35, 37], [38, 41], [42, 49], [49, 50], [50, 53], [53, 54], [55, 63], [64, 66], [67, 70], [71, 76], [77, 81], [82, 85], [86, 89], [90, 98], [99, 101], [102, 105], [106, 111], [112, 116], [117, 120], [121, 131], [132, 133], [133, 136], [136, 137], [137, 138], [139, 144], [145, 153], [154, 157], [158, 169], [170, 172], [173, 176], [177, 185], [186, 194], [195, 198], [199, 208], [208, 209]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [5, 5, "task"], [12, 13, "product"], [17, 19, "product"], [15, 21, "product"], [24, 25, "product"], [32, 34, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 12, 13, "opposite", "", false, false], [0, 1, 17, 19, "opposite", "", false, false], [0, 1, 24, 25, "opposite", "", false, false], [0, 1, 32, 34, "part-of", "", false, false], [5, 5, 0, 1, "named", "", false, false], [15, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Machine", "translation", ",", "sometimes", "abbreviated", "MT", "(", "not", "to", "be", "confused", "with", "computer-assisted", "translation", ",", "machine", "-", "assisted", "human", "translation", "(", "MAHT", ")", "or", "interactive", "translation", ")", ",", "is", "a", "subfield", "of", "computational", "linguistics", "that", "studies", "how", "software", "translates", "text", "or", "speech", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Machine translation, sometimes abbreviated MT (not to be confused with computer-assisted translation, machine-assisted human translation (MAHT) or interactive translation), is a subfield of computational linguistics that studies how software translates text or speech from one language to another.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 30], [31, 42], [43, 45], [46, 47], [47, 50], [51, 53], [54, 56], [57, 65], [66, 70], [71, 88], [89, 100], [100, 101], [102, 109], [109, 110], [110, 118], [119, 124], [125, 136], [137, 138], [138, 142], [142, 143], [144, 146], [147, 158], [159, 170], [170, 171], [171, 172], [173, 175], [176, 177], [178, 186], [187, 189], [190, 203], [204, 215], [216, 220], [221, 228], [229, 232], [233, 241], [242, 252], [253, 257], [258, 260], [261, 267], [268, 272], [273, 276], [277, 285], [286, 288], [289, 296], [296, 297]]}
{"doc_key": "ai-dev-202", "ner": [[2, 5, "product"], [8, 11, "university"], [14, 15, "researcher"], [17, 18, "researcher"], [40, 42, "location"], [43, 44, "location"], [48, 51, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 5, 14, 15, "artifact", "", false, false], [2, 5, 17, 18, "artifact", "", false, false], [14, 15, 8, 11, "physical", "", false, false], [14, 15, 8, 11, "role", "", false, false], [17, 18, 8, 11, "physical", "", false, false], [17, 18, 8, 11, "role", "", false, false], [40, 42, 43, 44, "physical", "", false, false], [48, 51, 40, 42, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "early", "interlingual", "MT", "systems", "were", "also", "built", "at", "Stanford", "in", "the", "1970s", "by", "Roger", "Schank", "and", "Yorick", "Wilks", ";", "the", "former", "became", "the", "basis", "for", "a", "commercial", "money", "transfer", "system", ",", "and", "the", "latter", "'s", "code", "is", "preserved", "in", "The", "Computer", "Museum", "in", "Boston", "as", "the", "first", "interlingual", "machine", "translation", "system", "."], "sentence-detokenized": "The early interlingual MT systems were also built at Stanford in the 1970s by Roger Schank and Yorick Wilks; the former became the basis for a commercial money transfer system, and the latter's code is preserved in The Computer Museum in Boston as the first interlingual machine translation system.", "token2charspan": [[0, 3], [4, 9], [10, 22], [23, 25], [26, 33], [34, 38], [39, 43], [44, 49], [50, 52], [53, 61], [62, 64], [65, 68], [69, 74], [75, 77], [78, 83], [84, 90], [91, 94], [95, 101], [102, 107], [107, 108], [109, 112], [113, 119], [120, 126], [127, 130], [131, 136], [137, 140], [141, 142], [143, 153], [154, 159], [160, 168], [169, 175], [175, 176], [177, 180], [181, 184], [185, 191], [191, 193], [194, 198], [199, 201], [202, 211], [212, 214], [215, 218], [219, 227], [228, 234], [235, 237], [238, 244], [245, 247], [248, 251], [252, 257], [258, 270], [271, 278], [279, 290], [291, 297], [297, 298]]}
{"doc_key": "ai-dev-203", "ner": [[0, 1, "researcher"], [6, 10, "conference"], [7, 13, "conference"], [20, 25, "conference"], [27, 28, "conference"], [34, 37, "organisation"], [42, 42, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 6, 10, "role", "", false, false], [0, 1, 20, 25, "role", "", false, false], [0, 1, 34, 37, "role", "", false, false], [0, 1, 42, 42, "role", "", false, false], [7, 13, 6, 10, "named", "", false, false], [27, 28, 20, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sycara", "was", "Program", "Chair", "of", "the", "Second", "International", "Semantic", "Web", "Conference", "(", "ISWC", "2003", ")", ";", "General", "Chair", "of", "the", "Second", "International", "Conference", "on", "Autonomous", "Agents", "(", "Agents", "98", ")", ";", "Chair", "of", "the", "Agents", "Conference", "Steering", "Committee", "(", "1999-2001", ")", ";", "AAAI", "Fellowship", "Chair", "(", "1993-1999", ")", ";"], "sentence-detokenized": "Sycara was Program Chair of the Second International Semantic Web Conference (ISWC 2003); General Chair of the Second International Conference on Autonomous Agents (Agents 98); Chair of the Agents Conference Steering Committee (1999-2001); AAAI Fellowship Chair (1993-1999);", "token2charspan": [[0, 6], [7, 10], [11, 18], [19, 24], [25, 27], [28, 31], [32, 38], [39, 52], [53, 61], [62, 65], [66, 76], [77, 78], [78, 82], [83, 87], [87, 88], [88, 89], [90, 97], [98, 103], [104, 106], [107, 110], [111, 117], [118, 131], [132, 142], [143, 145], [146, 156], [157, 163], [164, 165], [165, 171], [172, 174], [174, 175], [175, 176], [177, 182], [183, 185], [186, 189], [190, 196], [197, 207], [208, 216], [217, 226], [227, 228], [228, 237], [237, 238], [238, 239], [240, 244], [245, 255], [256, 261], [262, 263], [263, 272], [272, 273], [273, 274]]}
{"doc_key": "ai-dev-204", "ner": [[7, 7, "conference"], [9, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 12, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2016", ",", "he", "was", "awarded", "the", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "Lifetime", "Achievement", "Award", "."], "sentence-detokenized": "In 2016, he was awarded the ACL (Association for Computational Linguistics) Lifetime Achievement Award.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 27], [28, 31], [32, 33], [33, 44], [45, 48], [49, 62], [63, 74], [74, 75], [76, 84], [85, 96], [97, 102], [102, 103]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P.", "Frasconi", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 30], [31, 39], [40, 43], [44, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-206", "ner": [[0, 3, "product"], [7, 8, "misc"], [10, 10, "programlang"], [17, 18, "product"], [31, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 10, 10, "usage", "", false, false], [10, 10, 7, 8, "type-of", "", false, false], [10, 10, 17, 18, "related-to", "", false, false], [31, 31, 0, 3, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A.L.I.C.E.", ",", "for", "example", ",", "uses", "a", "markup", "language", "called", "AIML", ",", "which", "is", "specific", "to", "the", "dialogue", "system", "feature", "and", "has", "since", "been", "adopted", "by", "many", "other", "so", "-", "called", "Alicebot", "developers", "."], "sentence-detokenized": "A.L.I.C.E., for example, uses a markup language called AIML, which is specific to the dialogue system feature and has since been adopted by many other so-called Alicebot developers.", "token2charspan": [[0, 10], [10, 11], [12, 15], [16, 23], [23, 24], [25, 29], [30, 31], [32, 38], [39, 47], [48, 54], [55, 59], [59, 60], [61, 66], [67, 69], [70, 78], [79, 81], [82, 85], [86, 94], [95, 101], [102, 109], [110, 113], [114, 117], [118, 123], [124, 128], [129, 136], [137, 139], [140, 144], [145, 150], [151, 153], [153, 154], [154, 160], [161, 169], [170, 180], [180, 181]]}
{"doc_key": "ai-dev-207", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2000", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2000, he was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-dev-208", "ner": [[2, 2, "misc"], [0, 6, "misc"], [10, 16, "misc"], [24, 25, "algorithm"], [34, 35, "field"], [37, 38, "field"], [41, 42, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 2, 10, 16, "type-of", "", false, false], [2, 2, 34, 35, "related-to", "performs", true, false], [2, 2, 37, 38, "related-to", "performs", true, false], [2, 2, 41, 42, "related-to", "performs", true, false], [0, 6, 2, 2, "named", "", false, false], [24, 25, 10, 16, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Learning", "Classification", "Systems", "(", "LCS", ")", "are", "a", "family", "of", "rule", "-", "based", "machine", "learning", "algorithms", "that", "combine", "a", "discovery", "component", ",", "typically", "a", "genetic", "algorithm", ",", "with", "a", "learning", "component", "that", "performs", "either", "supervised", "learning", ",", "reinforcement", "learning", ",", "or", "unsupervised", "learning", "."], "sentence-detokenized": "Learning Classification Systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a genetic algorithm, with a learning component that performs either supervised learning, reinforcement learning, or unsupervised learning.", "token2charspan": [[0, 8], [9, 23], [24, 31], [32, 33], [33, 36], [36, 37], [38, 41], [42, 43], [44, 50], [51, 53], [54, 58], [58, 59], [59, 64], [65, 72], [73, 81], [82, 92], [93, 97], [98, 105], [106, 107], [108, 117], [118, 127], [127, 128], [129, 138], [139, 140], [141, 148], [149, 158], [158, 159], [160, 164], [165, 166], [167, 175], [176, 185], [186, 190], [191, 199], [200, 206], [207, 217], [218, 226], [226, 227], [228, 241], [242, 250], [250, 251], [252, 254], [255, 267], [268, 276], [276, 277]]}
{"doc_key": "ai-dev-209", "ner": [[15, 16, "algorithm"], [14, 18, "algorithm"], [27, 28, "algorithm"], [29, 31, "misc"], [40, 42, "algorithm"], [46, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 16, 27, 28, "origin", "", false, false], [15, 16, 29, 31, "usage", "", false, false], [14, 18, 15, 16, "named", "", false, false], [40, 42, 29, 31, "type-of", "", false, false], [40, 42, 46, 50, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "unknown", "parameters", "of", "each", "\u03b2subk", "/", "sub", "vector", "are", "typically", "jointly", "estimated", "using", "maximum", "a", "posteriori", "(", "MAP", ")", "estimation", ",", "which", "is", "an", "extension", "of", "maximum", "likelihood", "by", "regularizing", "the", "weights", "to", "avoid", "pathological", "solutions", "(", "usually", "a", "quadratic", "regularization", "function", "equivalent", "to", "a", "zero-mean", "Gaussian", "prior", "distribution", "of", "weights", ",", "but", "other", "distributions", "are", "possible", ")", "."], "sentence-detokenized": "The unknown parameters of each \u03b2subk/sub vector are typically jointly estimated using maximum a posteriori (MAP) estimation, which is an extension of maximum likelihood by regularizing the weights to avoid pathological solutions (usually a quadratic regularization function equivalent to a zero-mean Gaussian prior distribution of weights, but other distributions are possible).", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 30], [31, 36], [36, 37], [37, 40], [41, 47], [48, 51], [52, 61], [62, 69], [70, 79], [80, 85], [86, 93], [94, 95], [96, 106], [107, 108], [108, 111], [111, 112], [113, 123], [123, 124], [125, 130], [131, 133], [134, 136], [137, 146], [147, 149], [150, 157], [158, 168], [169, 171], [172, 184], [185, 188], [189, 196], [197, 199], [200, 205], [206, 218], [219, 228], [229, 230], [230, 237], [238, 239], [240, 249], [250, 264], [265, 273], [274, 284], [285, 287], [288, 289], [290, 299], [300, 308], [309, 314], [315, 327], [328, 330], [331, 338], [338, 339], [340, 343], [344, 349], [350, 363], [364, 367], [368, 376], [376, 377], [377, 378]]}
{"doc_key": "ai-dev-210", "ner": [[9, 9, "researcher"], [11, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 9, 9, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "hierarchical", "structure", "of", "words", "is", "explicitly", "mapped", "by", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "The hierarchical structure of words is explicitly mapped by George Miller's Wordnet.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 29], [30, 35], [36, 38], [39, 49], [50, 56], [57, 59], [60, 66], [67, 73], [73, 75], [76, 83], [83, 84]]}
{"doc_key": "ai-dev-211", "ner": [[6, 13, "conference"], [16, 19, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 19, 6, 13, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Their", "capabilities", "are", "illustrated", "by", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", ",", "a", "benchmark", "for", "object", "classification", "and", "recognition", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "Their capabilities are illustrated by the ImageNet Large Scale Visual Recognition Challenge, a benchmark for object classification and recognition, with millions of images and hundreds of object classes.", "token2charspan": [[0, 5], [6, 18], [19, 22], [23, 34], [35, 37], [38, 41], [42, 50], [51, 56], [57, 62], [63, 69], [70, 81], [82, 91], [91, 92], [93, 94], [95, 104], [105, 108], [109, 115], [116, 130], [131, 134], [135, 146], [146, 147], [148, 152], [153, 161], [162, 164], [165, 171], [172, 175], [176, 184], [185, 187], [188, 194], [195, 202], [202, 203]]}
{"doc_key": "ai-dev-212", "ner": [[1, 2, "misc"], [24, 24, "misc"], [27, 30, "person"], [32, 32, "misc"], [38, 39, "person"], [43, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[24, 24, 1, 2, "general-affiliation", "", false, false], [32, 32, 1, 2, "general-affiliation", "", false, false], [32, 32, 27, 30, "artifact", "", false, false], [43, 45, 1, 2, "general-affiliation", "", false, false], [43, 45, 38, 39, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "science", "fiction", "literature", ",", "robots", "with", "a", "female", "appearance", "are", "often", "used", "as", "domestic", "servants", "and", "sex", "slaves", ",", "as", "in", "the", "film", "Westworld", ",", "in", "Paul", "J.", "McAuley", "'s", "novel", "Fairyland", "(", "1995", ")", "and", "in", "Lester", "del", "Rey", "'s", "novel", "Helen", "O'", "Loy", "(", "1938", ")", ",", "and", "sometimes", "as", "warriors", ",", "murderers", "or", "workers", "."], "sentence-detokenized": "In science fiction literature, robots with a female appearance are often used as domestic servants and sex slaves, as in the film Westworld, in Paul J. McAuley's novel Fairyland (1995) and in Lester del Rey's novel Helen O'Loy (1938), and sometimes as warriors, murderers or workers.", "token2charspan": [[0, 2], [3, 10], [11, 18], [19, 29], [29, 30], [31, 37], [38, 42], [43, 44], [45, 51], [52, 62], [63, 66], [67, 72], [73, 77], [78, 80], [81, 89], [90, 98], [99, 102], [103, 106], [107, 113], [113, 114], [115, 117], [118, 120], [121, 124], [125, 129], [130, 139], [139, 140], [141, 143], [144, 148], [149, 151], [152, 159], [159, 161], [162, 167], [168, 177], [178, 179], [179, 183], [183, 184], [185, 188], [189, 191], [192, 198], [199, 202], [203, 206], [206, 208], [209, 214], [215, 220], [221, 223], [223, 226], [227, 228], [228, 232], [232, 233], [233, 234], [235, 238], [239, 248], [249, 251], [252, 260], [260, 261], [262, 271], [272, 274], [275, 282], [282, 283]]}
{"doc_key": "ai-dev-213", "ner": [[0, 1, "task"], [3, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["question", "answering", ",", "speech", "recognition", "and", "machine", "translation", "."], "sentence-detokenized": "question answering, speech recognition and machine translation.", "token2charspan": [[0, 8], [9, 18], [18, 19], [20, 26], [27, 38], [39, 42], [43, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-214", "ner": [[5, 8, "researcher"], [9, 13, "organisation"], [15, 18, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 8, 9, 13, "role", "", false, false], [9, 13, 15, 18, "physical", "", false, false], [15, 18, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "a", "pioneering", "study", ",", "Harry", "Blum", "of", "the", "Air", "Force", "Cambridge", "Research", "Laboratories", "at", "Hanscom", "Air", "Force", "Base", "in", "Bedford", ",", "Massachusetts", ",", "defined", "the", "central", "axis", "to", "calculate", "the", "skeleton", "of", "a", "shape", "using", "an", "intuitive", "model", "of", "fire", "spread", "in", "a", "grassy", "field", ",", "where", "the", "field", "represents", "the", "shape", "of", "the", "shape", "."], "sentence-detokenized": "In a pioneering study, Harry Blum of the Air Force Cambridge Research Laboratories at Hanscom Air Force Base in Bedford, Massachusetts, defined the central axis to calculate the skeleton of a shape using an intuitive model of fire spread in a grassy field, where the field represents the shape of the shape.", "token2charspan": [[0, 2], [3, 4], [5, 15], [16, 21], [21, 22], [23, 28], [29, 33], [34, 36], [37, 40], [41, 44], [45, 50], [51, 60], [61, 69], [70, 82], [83, 85], [86, 93], [94, 97], [98, 103], [104, 108], [109, 111], [112, 119], [119, 120], [121, 134], [134, 135], [136, 143], [144, 147], [148, 155], [156, 160], [161, 163], [164, 173], [174, 177], [178, 186], [187, 189], [190, 191], [192, 197], [198, 203], [204, 206], [207, 216], [217, 222], [223, 225], [226, 230], [231, 237], [238, 240], [241, 242], [243, 249], [250, 255], [255, 256], [257, 262], [263, 266], [267, 272], [273, 283], [284, 287], [288, 293], [294, 296], [297, 300], [301, 306], [306, 307]]}
{"doc_key": "ai-dev-215", "ner": [[14, 14, "algorithm"], [0, 16, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 19, 20, "compare", "", false, false], [0, 16, 19, 20, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "unlike", "boosting", "algorithms", "that", "analytically", "minimize", "the", "convex", "loss", "function", "(", "e.g.", "AdaBoost", "and", "LogitBoost", ")", ",", "Brown", "Boost", "solves", "a", "system", "of", "two", "equations", "and", "two", "unknowns", "using", "standard", "numerical", "methods", "."], "sentence-detokenized": "However, unlike boosting algorithms that analytically minimize the convex loss function (e.g. AdaBoost and LogitBoost), BrownBoost solves a system of two equations and two unknowns using standard numerical methods.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 24], [25, 35], [36, 40], [41, 53], [54, 62], [63, 66], [67, 73], [74, 78], [79, 87], [88, 89], [89, 93], [94, 102], [103, 106], [107, 117], [117, 118], [118, 119], [120, 125], [125, 130], [131, 137], [138, 139], [140, 146], [147, 149], [150, 153], [154, 163], [164, 167], [168, 171], [172, 180], [181, 186], [187, 195], [196, 205], [206, 213], [213, 214]]}
{"doc_key": "ai-dev-216", "ner": [[0, 2, "researcher"], [12, 18, "misc"], [25, 28, "conference"], [30, 30, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 12, 18, "win-defeat", "", false, false], [0, 2, 25, 28, "role", "", false, false], [30, 30, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getoor", "is", "a", "multiple", "winner", "of", "the", "Best", "Paper", "Award", ",", "the", "NSF", "Career", "Achievement", "Award", ",", "and", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Getoor is a multiple winner of the Best Paper Award, the NSF Career Achievement Award, and a member of the Association for the Advancement of Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 20], [21, 27], [28, 30], [31, 34], [35, 39], [40, 45], [46, 51], [51, 52], [53, 56], [57, 60], [61, 67], [68, 79], [80, 85], [85, 86], [87, 90], [91, 92], [93, 99], [100, 102], [103, 106], [107, 118], [119, 122], [123, 126], [127, 138], [139, 141], [142, 152], [153, 165], [166, 167], [167, 171], [171, 172], [172, 173]]}
{"doc_key": "ai-dev-217", "ner": [[0, 1, "misc"], [6, 10, "misc"], [15, 16, "misc"], [21, 25, "misc"], [35, 36, "misc"], [30, 34, "university"], [44, 52, "misc"], [57, 65, "misc"], [70, 74, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACM", "Fellow", "(", "2015", ")", "br", "Association", "for", "Computational", "Linguistics", "Fellow", "(", "2011", ")", "br", "AAAI", "Fellow", "(", "1994", ")", "br", "International", "Speech", "Communication", "Association", "Fellow", "(", "2011", ")", "br", "KTH", "Royal", "Institute", "of", "Technology", "honorary", "doctorate", "(", "Hedersdoktor", ")", "(", "2007", ")", "br", "Columbia", "Engineering", "School", "Alumni", "Association", "Distinguished", "Faculty", "Teaching", "award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Speech", "and", "Audio", "Processing", "Award", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")"], "sentence-detokenized": "ACM Fellow (2015) br Association for Computational Linguistics Fellow (2011) br AAAI Fellow (1994) br International Speech Communication Association Fellow (2011) br KTH Royal Institute of Technology honorary doctorate (Hedersdoktor) (2007) br Columbia Engineering School Alumni Association Distinguished Faculty Teaching award (2009) br IEEE James L. Flanagan Speech and Audio Processing Award (2011) br ISCA Medal for Scientific Achievement (2011)", "token2charspan": [[0, 3], [4, 10], [11, 12], [12, 16], [16, 17], [18, 20], [21, 32], [33, 36], [37, 50], [51, 62], [63, 69], [70, 71], [71, 75], [75, 76], [77, 79], [80, 84], [85, 91], [92, 93], [93, 97], [97, 98], [99, 101], [102, 115], [116, 122], [123, 136], [137, 148], [149, 155], [156, 157], [157, 161], [161, 162], [163, 165], [166, 169], [170, 175], [176, 185], [186, 188], [189, 199], [200, 208], [209, 218], [219, 220], [220, 232], [232, 233], [234, 235], [235, 239], [239, 240], [241, 243], [244, 252], [253, 264], [265, 271], [272, 278], [279, 290], [291, 304], [305, 312], [313, 321], [322, 327], [328, 329], [329, 333], [333, 334], [335, 337], [338, 342], [343, 348], [349, 351], [352, 360], [361, 367], [368, 371], [372, 377], [378, 388], [389, 394], [395, 396], [396, 400], [400, 401], [402, 404], [405, 409], [410, 415], [416, 419], [420, 430], [431, 442], [443, 444], [444, 448], [448, 449]]}
{"doc_key": "ai-dev-218", "ner": [[6, 6, "university"], [14, 16, "task"], [30, 37, "metrics"], [26, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[30, 37, 26, 29, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["A", "frustrating", "result", "of", "the", "same", "Stanford", "study", "(", "and", "other", "attempts", "to", "improve", "name", "recognition", "translation", ")", "is", "that", "often", "the", "inclusion", "of", "methods", "for", "translating", "named", "entities", "in", "bilingual", "assessments", "results", "in", "a", "reduction", "of", "under-estimated", "translation", "scores", "."], "sentence-detokenized": "A frustrating result of the same Stanford study (and other attempts to improve name recognition translation) is that often the inclusion of methods for translating named entities in bilingual assessments results in a reduction of under-estimated translation scores.", "token2charspan": [[0, 1], [2, 13], [14, 20], [21, 23], [24, 27], [28, 32], [33, 41], [42, 47], [48, 49], [49, 52], [53, 58], [59, 67], [68, 70], [71, 78], [79, 83], [84, 95], [96, 107], [107, 108], [109, 111], [112, 116], [117, 122], [123, 126], [127, 136], [137, 139], [140, 147], [148, 151], [152, 163], [164, 169], [170, 178], [179, 181], [182, 191], [192, 203], [204, 211], [212, 214], [215, 216], [217, 226], [227, 229], [230, 245], [246, 257], [258, 264], [264, 265]]}
{"doc_key": "ai-dev-219", "ner": [[0, 0, "organisation"], [12, 14, "organisation"], [16, 21, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 14, "role", "works_with", false, false], [0, 0, 16, 21, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "will", "use", "the", "PM", "data", "collected", "and", "collaborate", "with", "researchers", "at", "Johns", "Hopkins", "Hospital", "and", "Washington", "University", "School", "of", "Medicine", "to", "help", "answer", "specific", "questions", "about", "heart", "disease", ",", "such", "as", "whether", "a", "weak", "heart", "causes", "arrhythmias", "or", "vice", "versa", "."], "sentence-detokenized": "Medtronic will use the PM data collected and collaborate with researchers at Johns Hopkins Hospital and Washington University School of Medicine to help answer specific questions about heart disease, such as whether a weak heart causes arrhythmias or vice versa.", "token2charspan": [[0, 9], [10, 14], [15, 18], [19, 22], [23, 25], [26, 30], [31, 40], [41, 44], [45, 56], [57, 61], [62, 73], [74, 76], [77, 82], [83, 90], [91, 99], [100, 103], [104, 114], [115, 125], [126, 132], [133, 135], [136, 144], [145, 147], [148, 152], [153, 159], [160, 168], [169, 178], [179, 184], [185, 190], [191, 198], [198, 199], [200, 204], [205, 207], [208, 215], [216, 217], [218, 222], [223, 228], [229, 235], [236, 247], [248, 250], [251, 255], [256, 261], [261, 262]]}
{"doc_key": "ai-dev-220", "ner": [[4, 5, "organisation"], [10, 10, "misc"], [13, 14, "person"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 4, 5, "artifact", "made_by_studio", false, false], [13, 14, 10, 10, "role", "", false, false], [16, 17, 10, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "was", "followed", "by", "Paramount", "'s", "first", "feature", "film", ",", "Sangaree", ",", "starring", "Fernando", "Lamas", "and", "Arlene", "Dahl", "."], "sentence-detokenized": "This was followed by Paramount's first feature film, Sangaree, starring Fernando Lamas and Arlene Dahl.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 30], [30, 32], [33, 38], [39, 46], [47, 51], [51, 52], [53, 61], [61, 62], [63, 71], [72, 80], [81, 86], [87, 90], [91, 97], [98, 102], [102, 103]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [8, 10, "researcher"], [12, 13, "researcher"], [15, 16, "organisation"], [18, 19, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 10, "origin", "", false, false], [0, 0, 12, 13, "origin", "", false, false], [8, 10, 15, 16, "physical", "", false, false], [8, 10, 15, 16, "role", "", false, false], [12, 13, 18, 19, "physical", "", false, false], [12, 13, 18, 19, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "is", "a", "knowledge", "representation", "language", "developed", "by", "Daniel", "G.", "Bobrow", "and", "Terry", "Winograd", "at", "Xerox", "PARC", "and", "Stanford", "University", "."], "sentence-detokenized": "KRL is a knowledge representation language developed by Daniel G. Bobrow and Terry Winograd at Xerox PARC and Stanford University.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 18], [19, 33], [34, 42], [43, 52], [53, 55], [56, 62], [63, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 94], [95, 100], [101, 105], [106, 109], [110, 118], [119, 129], [129, 130]]}
{"doc_key": "ai-dev-222", "ner": [[3, 10, "conference"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 24, "researcher"], [32, 33, "task"], [35, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 10, 32, 33, "topic", "", true, false], [12, 13, 3, 10, "physical", "", false, false], [12, 13, 3, 10, "role", "", false, false], [12, 13, 3, 10, "temporal", "", false, false], [15, 16, 3, 10, "physical", "", false, false], [15, 16, 3, 10, "role", "", false, false], [15, 16, 3, 10, "temporal", "", false, false], [18, 19, 3, 10, "physical", "", false, false], [18, 19, 3, 10, "role", "", false, false], [18, 19, 3, 10, "temporal", "", false, false], [21, 24, 3, 10, "physical", "", false, false], [21, 24, 3, 10, "role", "", false, false], [21, 24, 3, 10, "temporal", "", false, false], [32, 33, 35, 36, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["At", "the", "2006", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", "and", "Kwang", "-", "Ting", "Cheng", "presented", "an", "algorithm", "that", "significantly", "speeds", "up", "human", "recognition", "using", "HOG", "descriptors", "."], "sentence-detokenized": "At the 2006 IEEE Conference on Computer Vision and Pattern Recognition, Qiang Zhu, Shai Avidan, Mei-Chen Yeh and Kwang-Ting Cheng presented an algorithm that significantly speeds up human recognition using HOG descriptors.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 27], [28, 30], [31, 39], [40, 46], [47, 50], [51, 58], [59, 70], [70, 71], [72, 77], [78, 81], [81, 82], [83, 87], [88, 94], [94, 95], [96, 104], [105, 108], [109, 112], [113, 118], [118, 119], [119, 123], [124, 129], [130, 139], [140, 142], [143, 152], [153, 157], [158, 171], [172, 178], [179, 181], [182, 187], [188, 199], [200, 205], [206, 209], [210, 221], [221, 222]]}
{"doc_key": "ai-dev-223", "ner": [[0, 2, "researcher"], [6, 6, "conference"], [9, 11, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 6, "role", "", false, false], [0, 2, 9, 11, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "is", "a", "founding", "member", "of", "AAAI", "and", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Hayes is a founding member of AAAI and the Cognitive Science Society.", "token2charspan": [[0, 5], [6, 8], [9, 10], [11, 19], [20, 26], [27, 29], [30, 34], [35, 38], [39, 42], [43, 52], [53, 60], [61, 68], [68, 69]]}
{"doc_key": "ai-dev-224", "ner": [[0, 1, "misc"], [4, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 32, "field"], [44, 45, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 1, 4, 5, "part-of", "", false, false], [0, 1, 4, 5, "usage", "", false, false], [0, 1, 7, 8, "part-of", "", false, false], [0, 1, 7, 8, "usage", "", false, false], [0, 1, 10, 11, "part-of", "", false, false], [0, 1, 10, 11, "usage", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [0, 1, 13, 13, "usage", "", false, false], [0, 1, 15, 16, "part-of", "", false, false], [0, 1, 15, 16, "usage", "", false, false], [0, 1, 18, 19, "part-of", "", false, false], [0, 1, 18, 19, "usage", "", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 21, 22, "usage", "", false, false], [0, 1, 24, 24, "part-of", "", false, false], [0, 1, 24, 24, "usage", "", false, false], [0, 1, 26, 27, "part-of", "", false, false], [0, 1, 26, 27, "usage", "", false, false], [0, 1, 29, 29, "part-of", "", false, false], [0, 1, 29, 29, "usage", "", false, false], [0, 1, 31, 32, "part-of", "", false, false], [0, 1, 31, 32, "usage", "", false, false], [0, 1, 44, 45, "part-of", "", false, false], [0, 1, 44, 45, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", "and", ",", "to", "a", "large", "extent", ",", "in", "all", "fields", "of", "applied", "science", "and", "engineering", "where", "time", "measurements", "are", "made", "."], "sentence-detokenized": "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering and, to a large extent, in all fields of applied science and engineering where time measurements are made.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 23], [24, 34], [34, 35], [36, 42], [43, 53], [53, 54], [55, 62], [63, 74], [74, 75], [76, 88], [88, 89], [90, 102], [103, 110], [110, 111], [112, 119], [120, 131], [131, 132], [133, 143], [144, 154], [154, 155], [156, 178], [178, 179], [180, 187], [188, 199], [199, 200], [201, 210], [210, 211], [212, 226], [227, 238], [239, 242], [242, 243], [244, 246], [247, 248], [249, 254], [255, 261], [261, 262], [263, 265], [266, 269], [270, 276], [277, 279], [280, 287], [288, 295], [296, 299], [300, 311], [312, 317], [318, 322], [323, 335], [336, 339], [340, 344], [344, 345]]}
{"doc_key": "ai-dev-225", "ner": [[9, 10, "metrics"], [34, 36, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "principle", ",", "exact", "recovery", "can", "be", "solved", "with", "maximum", "likelihood", "in", "the", "feasible", "range", ",", "but", "this", "implies", "solving", "a", "constrained", "or", "regularized", "pruning", "problem", "such", "as", "minimum", "pruning", ",", "which", "is", "typically", "NP", "-", "complete", "."], "sentence-detokenized": "In principle, exact recovery can be solved with maximum likelihood in the feasible range, but this implies solving a constrained or regularized pruning problem such as minimum pruning, which is typically NP-complete.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 19], [20, 28], [29, 32], [33, 35], [36, 42], [43, 47], [48, 55], [56, 66], [67, 69], [70, 73], [74, 82], [83, 88], [88, 89], [90, 93], [94, 98], [99, 106], [107, 114], [115, 116], [117, 128], [129, 131], [132, 143], [144, 151], [152, 159], [160, 164], [165, 167], [168, 175], [176, 183], [183, 184], [185, 190], [191, 193], [194, 203], [204, 206], [206, 207], [207, 215], [215, 216]]}
{"doc_key": "ai-dev-226", "ner": [[4, 5, "task"], [11, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["in", "their", "work", "on", "pedestrian", "detection", ",", "first", "presented", "at", "the", "BMVC", "in", "2009", "."], "sentence-detokenized": "in their work on pedestrian detection, first presented at the BMVC in 2009.", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 16], [17, 27], [28, 37], [37, 38], [39, 44], [45, 54], [55, 57], [58, 61], [62, 66], [67, 69], [70, 74], [74, 75]]}
{"doc_key": "ai-dev-227", "ner": [[17, 22, "conference"], [3, 3, "researcher"], [7, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 17, 22, "physical", "", false, false], [3, 3, 17, 22, "role", "", false, false], [3, 3, 7, 15, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2007", ",", "Terzopoulos", "was", "awarded", "the", "first", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "at", "the", "International", "Computer", "Vision", "Conference", "for", "his", "pioneering", "and", "sustainable", "research", "on", "deformable", "models", "and", "their", "applications", "."], "sentence-detokenized": "In 2007, Terzopoulos was awarded the first IEEE PAMI Computer Vision Distinguished Researcher Award at the International Computer Vision Conference for his pioneering and sustainable research on deformable models and their applications.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 24], [25, 32], [33, 36], [37, 42], [43, 47], [48, 52], [53, 61], [62, 68], [69, 82], [83, 93], [94, 99], [100, 102], [103, 106], [107, 120], [121, 129], [130, 136], [137, 147], [148, 151], [152, 155], [156, 166], [167, 170], [171, 182], [183, 191], [192, 194], [195, 205], [206, 212], [213, 216], [217, 222], [223, 235], [235, 236]]}
{"doc_key": "ai-dev-228", "ner": [[0, 1, "task"], [4, 4, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 4, 4, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cluster", "analysis", "or", "cluster", "analysis", "means", "assigning", "data", "points", "to", "clusters", "so", "that", "items", "in", "the", "same", "cluster", "are", "as", "similar", "as", "possible", "and", "items", "in", "different", "clusters", "are", "as", "different", "as", "possible", "."], "sentence-detokenized": "Cluster analysis or cluster analysis means assigning data points to clusters so that items in the same cluster are as similar as possible and items in different clusters are as different as possible.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 36], [37, 42], [43, 52], [53, 57], [58, 64], [65, 67], [68, 76], [77, 79], [80, 84], [85, 90], [91, 93], [94, 97], [98, 102], [103, 110], [111, 114], [115, 117], [118, 125], [126, 128], [129, 137], [138, 141], [142, 147], [148, 150], [151, 160], [161, 169], [170, 173], [174, 176], [177, 186], [187, 189], [190, 198], [198, 199]]}
{"doc_key": "ai-dev-229", "ner": [[8, 9, "field"], [15, 16, "field"], [18, 19, "task"], [21, 22, "field"], [25, 25, "field"], [27, 27, "field"], [28, 28, "field"], [33, 34, "task"], [36, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 9, 15, 16, "named", "", false, false], [8, 9, 21, 22, "named", "", false, false], [8, 9, 27, 27, "named", "", false, false], [18, 19, 15, 16, "part-of", "task_part_of_field", false, false], [25, 25, 21, 22, "part-of", "", false, false], [28, 28, 27, 27, "part-of", "", false, false], [33, 34, 28, 28, "part-of", "", false, false], [36, 36, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["(", "2005", ")", ",", "three", "different", "approaches", "to", "text", "mining", "can", "be", "distinguished", ",", "namely", "text", "mining", "as", "information", "extraction", ",", "text", "mining", "as", "text", "mining", "and", "text", "mining", "as", "a", "process", "of", "knowledge", "discovery", "in", "databases.Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005), three different approaches to text mining can be distinguished, namely text mining as information extraction, text mining as text mining and text mining as a process of knowledge discovery in databases.Hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [6, 7], [8, 13], [14, 23], [24, 34], [35, 37], [38, 42], [43, 49], [50, 53], [54, 56], [57, 70], [70, 71], [72, 78], [79, 83], [84, 90], [91, 93], [94, 105], [106, 116], [116, 117], [118, 122], [123, 129], [130, 132], [133, 137], [138, 144], [145, 148], [149, 153], [154, 160], [161, 163], [164, 165], [166, 173], [174, 176], [177, 186], [187, 196], [197, 199], [200, 215], [215, 216], [217, 219], [219, 220], [221, 231], [231, 232], [233, 235], [236, 239], [240, 244], [244, 245], [246, 248], [249, 250], [250, 254], [254, 255], [255, 256]]}
{"doc_key": "ai-dev-230", "ner": [[1, 2, "product"], [12, 19, "location"], [21, 21, "location"], [22, 23, "location"], [33, 35, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 12, 19, "related-to", "developed_for", false, false], [12, 19, 21, 21, "physical", "", false, false], [21, 21, 22, 23, "physical", "", false, false], [33, 35, 1, 2, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Rancho", "Arm", "robotic", "arm", "was", "developed", "to", "assist", "patients", "with", "disabilities", "at", "the", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Center", "in", "Downey", ",", "California", ";", "this", "computer", "-", "controlled", "arm", "was", "purchased", "by", "Stanford", "University", "in", "1963", "."], "sentence-detokenized": "The Rancho Arm robotic arm was developed to assist patients with disabilities at the Rancho Los Amigos National Rehabilitation Center in Downey, California; this computer-controlled arm was purchased by Stanford University in 1963.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 22], [23, 26], [27, 30], [31, 40], [41, 43], [44, 50], [51, 59], [60, 64], [65, 77], [78, 80], [81, 84], [85, 91], [92, 95], [96, 102], [103, 111], [112, 126], [127, 133], [134, 136], [137, 143], [143, 144], [145, 155], [155, 156], [157, 161], [162, 170], [170, 171], [171, 181], [182, 185], [186, 189], [190, 199], [200, 202], [203, 211], [212, 222], [223, 225], [226, 230], [230, 231]]}
{"doc_key": "ai-dev-231", "ner": [[0, 1, "university"], [3, 3, "researcher"], [11, 14, "organisation"], [22, 24, "organisation"], [28, 29, "researcher"], [31, 33, "researcher"], [46, 46, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 0, 1, "physical", "", false, false], [3, 3, 0, 1, "role", "", false, false], [3, 3, 11, 14, "role", "founder", false, false], [3, 3, 22, 24, "role", "founder", false, false], [22, 24, 46, 46, "physical", "", false, false], [28, 29, 22, 24, "role", "founder", false, false], [31, 33, 22, 24, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["At", "UCSD", ",", "Norman", "was", "one", "of", "the", "founders", "of", "the", "Institute", "for", "Cognitive", "Science", "and", "one", "of", "the", "organizers", "of", "the", "Cognitive", "Science", "Society", "(", "along", "with", "Roger", "Schank", ",", "Allan", "M.", "Collins", "and", "others", ")", ",", "which", "held", "it", "s", "first", "meeting", "on", "the", "UCSD", "campus", "in", "1979", "."], "sentence-detokenized": "At UCSD, Norman was one of the founders of the Institute for Cognitive Science and one of the organizers of the Cognitive Science Society (along with Roger Schank, Allan M. Collins and others), which held its first meeting on the UCSD campus in 1979.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 23], [24, 26], [27, 30], [31, 39], [40, 42], [43, 46], [47, 56], [57, 60], [61, 70], [71, 78], [79, 82], [83, 86], [87, 89], [90, 93], [94, 104], [105, 107], [108, 111], [112, 121], [122, 129], [130, 137], [138, 139], [139, 144], [145, 149], [150, 155], [156, 162], [162, 163], [164, 169], [170, 172], [173, 180], [181, 184], [185, 191], [191, 192], [192, 193], [194, 199], [200, 204], [205, 207], [207, 208], [209, 214], [215, 222], [223, 225], [226, 229], [230, 234], [235, 241], [242, 244], [245, 249], [249, 250]]}
{"doc_key": "ai-dev-232", "ner": [[7, 8, "product"], [10, 11, "product"], [13, 14, "product"], [16, 18, "product"], [20, 21, "product"], [23, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 16, 18, "type-of", "", false, false], [23, 28, 16, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "commonly", "used", "robot", "configurations", "are", "articulated", "robots", ",", "SCARA", "robots", ",", "delta", "robots", "and", "Cartesian", "coordinate", "robots", "(", "gantry", "robots", "or", "x", "-", "y", "-", "z", "robots", ")", "."], "sentence-detokenized": "The most commonly used robot configurations are articulated robots, SCARA robots, delta robots and Cartesian coordinate robots (gantry robots or x-y-z robots).", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 28], [29, 43], [44, 47], [48, 59], [60, 66], [66, 67], [68, 73], [74, 80], [80, 81], [82, 87], [88, 94], [95, 98], [99, 108], [109, 119], [120, 126], [127, 128], [128, 134], [135, 141], [142, 144], [145, 146], [146, 147], [147, 148], [148, 149], [149, 150], [151, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-dev-233", "ner": [[8, 8, "programlang"], [9, 10, "misc"], [15, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 8, 8, "part-of", "", false, false], [15, 15, 9, 10, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Alternatively", ",", "it", "can", "be", "used", "directly", "with", "Perl", "Module", "TM", "(", "which", "also", "supports", "LTM", ")", "."], "sentence-detokenized": "Alternatively, it can be used directly with Perl Module TM (which also supports LTM).", "token2charspan": [[0, 13], [13, 14], [15, 17], [18, 21], [22, 24], [25, 29], [30, 38], [39, 43], [44, 48], [49, 55], [56, 58], [59, 60], [60, 65], [66, 70], [71, 79], [80, 83], [83, 84], [84, 85]]}
{"doc_key": "ai-dev-234", "ner": [[10, 11, "country"], [5, 6, "organisation"], [19, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 10, 11, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "won", "by", "the", "Newton", "Labs", "team", "from", "the", "United", "States", ",", "and", "the", "competition", "was", "featured", "on", "CNN", "."], "sentence-detokenized": "It was won by the Newton Labs team from the United States, and the competition was featured on CNN.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 17], [18, 24], [25, 29], [30, 34], [35, 39], [40, 43], [44, 50], [51, 57], [57, 58], [59, 62], [63, 66], [67, 78], [79, 82], [83, 91], [92, 94], [95, 98], [98, 99]]}
{"doc_key": "ai-dev-235", "ner": [[0, 6, "misc"], [11, 12, "person"], [15, 16, "person"], [18, 23, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 0, 6, "role", "directs", false, false], [15, 16, 0, 6, "role", "acts_in", false, false], [18, 23, 0, 6, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Butler", "'s", "in", "Love", ",", "a", "short", "film", "directed", "by", "David", "Arquette", "and", "starring", "Elizabeth", "Berkley", "and", "Thomas", "Jane", ",", "was", "released", "on", "23", "June", "2008", "."], "sentence-detokenized": "The Butler's in Love, a short film directed by David Arquette and starring Elizabeth Berkley and Thomas Jane, was released on 23 June 2008.", "token2charspan": [[0, 3], [4, 10], [10, 12], [13, 15], [16, 20], [20, 21], [22, 23], [24, 29], [30, 34], [35, 43], [44, 46], [47, 52], [53, 61], [62, 65], [66, 74], [75, 84], [85, 92], [93, 96], [97, 103], [104, 108], [108, 109], [110, 113], [114, 122], [123, 125], [126, 128], [129, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-dev-236", "ner": [[0, 0, "product"], [7, 7, "field"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 13, 13, "general-affiliation", "", false, false], [7, 7, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "for", "example", ",", "is", "a", "taxonomy", "resource", "with", "the", "meanings", "of", "English", "words", "."], "sentence-detokenized": "WordNet, for example, is a taxonomy resource with the meanings of English words.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 20], [20, 21], [22, 24], [25, 26], [27, 35], [36, 44], [45, 49], [50, 53], [54, 62], [63, 65], [66, 73], [74, 79], [79, 80]]}
{"doc_key": "ai-dev-237", "ner": [[1, 3, "product"], [7, 7, "product"], [9, 9, "product"], [14, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 1, 3, "type-of", "", false, false], [7, 7, 14, 16, "related-to", "ability_to", false, false], [9, 9, 1, 3, "type-of", "", false, false], [9, 9, 14, 16, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Existing", "humanoid", "robotic", "systems", ",", "such", "as", "ASIMO", "and", "QRIO", ",", "use", "many", "motors", "to", "move", "around", "."], "sentence-detokenized": "Existing humanoid robotic systems, such as ASIMO and QRIO, use many motors to move around.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 33], [33, 34], [35, 39], [40, 42], [43, 48], [49, 52], [53, 57], [57, 58], [59, 62], [63, 67], [68, 74], [75, 77], [78, 82], [83, 89], [89, 90]]}
{"doc_key": "ai-dev-238", "ner": [[0, 1, "metrics"], [9, 10, "metrics"], [12, 12, "metrics"], [14, 19, "misc"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 10, 0, 1, "part-of", "", false, false], [12, 12, 0, 1, "part-of", "", false, false], [14, 19, 0, 1, "part-of", "", false, false], [21, 21, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "is", "designed", "based", "on", "the", "factors", "of", "increased", "length", "penalty", ",", "accuracy", ",", "n", "-", "gram", "word", "order", "penalty", "and", "recall", "."], "sentence-detokenized": "LEPOR is designed based on the factors of increased length penalty, accuracy, n-gram word order penalty and recall.", "token2charspan": [[0, 5], [6, 8], [9, 17], [18, 23], [24, 26], [27, 30], [31, 38], [39, 41], [42, 51], [52, 58], [59, 66], [66, 67], [68, 76], [76, 77], [78, 79], [79, 80], [80, 84], [85, 89], [90, 95], [96, 103], [104, 107], [108, 114], [114, 115]]}
{"doc_key": "ai-dev-239", "ner": [[1, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "bilingual", "assessment", "is", "based", "on", "the", "student", "metrics", ",", "but", "with", "some", "changes", "."], "sentence-detokenized": "The bilingual assessment is based on the student metrics, but with some changes.", "token2charspan": [[0, 3], [4, 13], [14, 24], [25, 27], [28, 33], [34, 36], [37, 40], [41, 48], [49, 56], [56, 57], [58, 61], [62, 66], [67, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-dev-240", "ner": [[6, 6, "product"], [8, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "of", "a", "MATLAB", "/", "Octave", "implementation", ":"], "sentence-detokenized": "This is an example of a MATLAB / Octave implementation:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 23], [24, 30], [31, 32], [33, 39], [40, 54], [54, 55]]}
{"doc_key": "ai-dev-241", "ner": [[14, 14, "programlang"], [16, 16, "programlang"], [18, 18, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "designed", "to", "be", "used", "across", "a", "range", "of", "computer", "languages", ",", "including", "Python", ",", "Ruby", "and", "Scheme", "."], "sentence-detokenized": "It is designed to be used across a range of computer languages, including Python, Ruby and Scheme.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 20], [21, 25], [26, 32], [33, 34], [35, 40], [41, 43], [44, 52], [53, 62], [62, 63], [64, 73], [74, 80], [80, 81], [82, 86], [87, 90], [91, 97], [97, 98]]}
{"doc_key": "ai-dev-242", "ner": [[0, 0, "researcher"], [7, 7, "organisation"], [14, 14, "conference"], [19, 20, "academicjournal"], [25, 27, "organisation"], [32, 36, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 7, 7, "role", "", false, false], [0, 0, 14, 14, "role", "", false, false], [0, 0, 19, 20, "role", "", false, false], [0, 0, 25, 27, "role", "", false, false], [0, 0, 32, 36, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "has", "served", "as", "Secretary", "of", "the", "AISB", ",", "President", "and", "Trustee", "of", "the", "IJCAI", ",", "Associate", "Editor", "of", "Artificial", "Intelligence", ",", "Governor", "of", "the", "Cognitive", "Science", "Society", "and", "President", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes has served as Secretary of the AISB, President and Trustee of the IJCAI, Associate Editor of Artificial Intelligence, Governor of the Cognitive Science Society and President of the American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 32], [33, 36], [37, 41], [41, 42], [43, 52], [53, 56], [57, 64], [65, 67], [68, 71], [72, 77], [77, 78], [79, 88], [89, 95], [96, 98], [99, 109], [110, 122], [122, 123], [124, 132], [133, 135], [136, 139], [140, 149], [150, 157], [158, 165], [166, 169], [170, 179], [180, 182], [183, 186], [187, 195], [196, 207], [208, 211], [212, 222], [223, 235], [235, 236]]}
{"doc_key": "ai-dev-243", "ner": [[5, 15, "misc"], [3, 19, "misc"], [24, 25, "person"], [28, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[24, 25, 5, 15, "role", "directed_by", false, false], [24, 25, 3, 19, "role", "directed_by", false, false], [24, 25, 28, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "of", "these", "films", ",", "Now", "is", "the", "Time", "(", "to", "Put", "On", "Your", "Glasses", ")", "and", "Around", "is", "Around", ",", "were", "directed", "by", "Norman", "McLaren", "for", "the", "Canadian", "National", "Film", "Board", "in", "1951", "."], "sentence-detokenized": "Two of these films, Now is the Time (to Put On Your Glasses) and Around is Around, were directed by Norman McLaren for the Canadian National Film Board in 1951.", "token2charspan": [[0, 3], [4, 6], [7, 12], [13, 18], [18, 19], [20, 23], [24, 26], [27, 30], [31, 35], [36, 37], [37, 39], [40, 43], [44, 46], [47, 51], [52, 59], [59, 60], [61, 64], [65, 71], [72, 74], [75, 81], [81, 82], [83, 87], [88, 96], [97, 99], [100, 106], [107, 114], [115, 118], [119, 122], [123, 131], [132, 140], [141, 145], [146, 151], [152, 154], [155, 159], [159, 160]]}
{"doc_key": "ai-dev-244", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "purpose", "of", "a", "recommendation", "system", "is", "to", "predict", "the", "target", "user", "'s", "preference", "for", "a", "product", "."], "sentence-detokenized": "The purpose of a recommendation system is to predict the target user's preference for a product.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 16], [17, 31], [32, 38], [39, 41], [42, 44], [45, 52], [53, 56], [57, 63], [64, 68], [68, 70], [71, 81], [82, 85], [86, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-dev-245", "ner": [[0, 1, "algorithm"], [7, 7, "field"], [9, 9, "field"], [11, 12, "field"], [14, 16, "field"], [18, 18, "field"], [20, 21, "field"], [23, 23, "field"], [4, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 1, 7, 7, "part-of", "", true, false], [0, 1, 9, 9, "part-of", "", true, false], [0, 1, 11, 12, "part-of", "", true, false], [0, 1, 14, 16, "part-of", "", true, false], [0, 1, 18, 18, "part-of", "", true, false], [0, 1, 20, 21, "part-of", "", true, false], [0, 1, 23, 23, "part-of", "", true, false], [0, 1, 4, 26, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Convolution", "has", "applications", "in", "fields", "such", "as", "probability", ",", "statistics", ",", "computer", "vision", ",", "natural", "language", "processing", ",", "image", "and", "signal", "processing", ",", "engineering", "and", "differential", "equations", "."], "sentence-detokenized": "Convolution has applications in fields such as probability, statistics, computer vision, natural language processing, image and signal processing, engineering and differential equations.", "token2charspan": [[0, 11], [12, 15], [16, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 58], [58, 59], [60, 70], [70, 71], [72, 80], [81, 87], [87, 88], [89, 96], [97, 105], [106, 116], [116, 117], [118, 123], [124, 127], [128, 134], [135, 145], [145, 146], [147, 158], [159, 162], [163, 175], [176, 185], [185, 186]]}
{"doc_key": "ai-dev-246", "ner": [[2, 2, "field"], [4, 6, "task"], [8, 9, "task"], [11, 11, "task"], [12, 13, "task"], [15, 16, "task"], [18, 19, "task"], [21, 22, "task"], [24, 24, "task"], [27, 28, "task"], [30, 30, "field"], [32, 32, "field"], [34, 36, "field"], [38, 38, "field"], [40, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[2, 2, 4, 6, "part-of", "", true, false], [2, 2, 8, 9, "part-of", "", true, false], [2, 2, 11, 11, "part-of", "", true, false], [2, 2, 12, 13, "part-of", "", true, false], [2, 2, 15, 16, "part-of", "", true, false], [2, 2, 18, 19, "part-of", "", true, false], [2, 2, 21, 22, "part-of", "", true, false], [2, 2, 24, 24, "part-of", "", true, false], [2, 2, 27, 28, "part-of", "", true, false], [2, 2, 30, 30, "part-of", "", true, false], [2, 2, 32, 32, "part-of", "", true, false], [2, 2, 34, 36, "part-of", "", true, false], [2, 2, 38, 38, "part-of", "", true, false], [2, 2, 40, 40, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Applications", "for", "DSP", "include", "audio", "signal", "processing", ",", "audio", "compression", ",", "digital", "image", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communications", ",", "digital", "synthesizers", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", "and", "biomedicine", "."], "sentence-detokenized": "Applications for DSP include audio signal processing, audio compression, digital image processing, video compression, speech processing, speech recognition, digital communications, digital synthesizers, radar, sonar, financial signal processing, seismology and biomedicine.", "token2charspan": [[0, 12], [13, 16], [17, 20], [21, 28], [29, 34], [35, 41], [42, 52], [52, 53], [54, 59], [60, 71], [71, 72], [73, 80], [81, 86], [87, 97], [97, 98], [99, 104], [105, 116], [116, 117], [118, 124], [125, 135], [135, 136], [137, 143], [144, 155], [155, 156], [157, 164], [165, 179], [179, 180], [181, 188], [189, 201], [201, 202], [203, 208], [208, 209], [210, 215], [215, 216], [217, 226], [227, 233], [234, 244], [244, 245], [246, 256], [257, 260], [261, 272], [272, 273]]}
{"doc_key": "ai-dev-247", "ner": [[13, 14, "misc"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "February", "20", ",", "1912", "-", "August", "11", ",", "2011", ")", "was", "an", "American", "inventor", "best", "known", "for", "creating", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "(February 20, 1912 - August 11, 2011) was an American inventor best known for creating Unimate, the first industrial robot.", "token2charspan": [[0, 1], [1, 9], [10, 12], [12, 13], [14, 18], [19, 20], [21, 27], [28, 30], [30, 31], [32, 36], [36, 37], [38, 41], [42, 44], [45, 53], [54, 62], [63, 67], [68, 73], [74, 77], [78, 86], [87, 94], [94, 95], [96, 99], [100, 105], [106, 116], [117, 122], [122, 123]]}
{"doc_key": "ai-dev-248", "ner": [[2, 5, "researcher"], [7, 9, "researcher"], [20, 22, "algorithm"], [24, 26, "algorithm"], [30, 31, "task"], [33, 35, "algorithm"], [41, 42, "researcher"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7], "relations": [[2, 5, 20, 22, "related-to", "writes_about", true, false], [7, 9, 20, 22, "related-to", "writes_about", true, false], [20, 22, 24, 26, "related-to", "", true, false], [30, 31, 33, 35, "related-to", "", true, false], [41, 42, 33, 35, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 3, 4, 5], "sentence": ["He", "co-authored", "with", "David", "E.", "Rumelhart", "and", "Ronald", "J.", "Williams", "a", "highly", "cited", "paper", "published", "in", "1986", "that", "popularized", "the", "backpropagation", "algorithm", "for", "training", "multilayer", "neural", "networks", ",", "The", "dramatic", "image", "recognition", "landmark", "AlexNet", ",", "which", "was", "developed", "by", "his", "student", "Alex", "Krizhevsky", "{{", "cite", "web"], "sentence-detokenized": "He co-authored with David E. Rumelhart and Ronald J. Williams a highly cited paper published in 1986 that popularized the backpropagation algorithm for training multilayer neural networks, The dramatic image recognition landmark AlexNet, which was developed by his student Alex Krizhevsky {{cite web", "token2charspan": [[0, 2], [3, 14], [15, 19], [20, 25], [26, 28], [29, 38], [39, 42], [43, 49], [50, 52], [53, 61], [62, 63], [64, 70], [71, 76], [77, 82], [83, 92], [93, 95], [96, 100], [101, 105], [106, 117], [118, 121], [122, 137], [138, 147], [148, 151], [152, 160], [161, 171], [172, 178], [179, 187], [187, 188], [189, 192], [193, 201], [202, 207], [208, 219], [220, 228], [229, 236], [236, 237], [238, 243], [244, 247], [248, 257], [258, 260], [261, 264], [265, 272], [273, 277], [278, 288], [289, 291], [291, 295], [296, 299]]}
{"doc_key": "ai-dev-249", "ner": [[10, 12, "metrics"], [15, 20, "metrics"], [23, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "predicted", "value", "has", "a", "continuous", "distribution", ",", "the", "mean", "squared", "error", ",", "the", "root", "mean", "square", "of", "the", "error", "or", "the", "median", "of", "the", "absolute", "deviation", "can", "be", "used", "to", "sum", "the", "errors", "."], "sentence-detokenized": "If the predicted value has a continuous distribution, the mean squared error, the root mean square of the error or the median of the absolute deviation can be used to sum the errors.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 22], [23, 26], [27, 28], [29, 39], [40, 52], [52, 53], [54, 57], [58, 62], [63, 70], [71, 76], [76, 77], [78, 81], [82, 86], [87, 91], [92, 98], [99, 101], [102, 105], [106, 111], [112, 114], [115, 118], [119, 125], [126, 128], [129, 132], [133, 141], [142, 151], [152, 155], [156, 158], [159, 163], [164, 166], [167, 170], [171, 174], [175, 181], [181, 182]]}
{"doc_key": "ai-dev-250", "ner": [[0, 2, "algorithm"], [9, 10, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 10, "part-of", "", true, false], [0, 2, 13, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Conceptual", "clustering", "emerged", "primarily", "in", "the", "1980s", "as", "a", "machine", "learning", "paradigm", "for", "unsupervised", "learning", "."], "sentence-detokenized": "Conceptual clustering emerged primarily in the 1980s as a machine learning paradigm for unsupervised learning.", "token2charspan": [[0, 10], [11, 21], [22, 29], [30, 39], [40, 42], [43, 46], [47, 52], [53, 55], [56, 57], [58, 65], [66, 74], [75, 83], [84, 87], [88, 100], [101, 109], [109, 110]]}
{"doc_key": "ai-dev-251", "ner": [[10, 13, "product"], [28, 31, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "named", "entities", "can", "not", "be", "recognised", "by", "the", "machine", "translator", ",", "they", "may", "be", "mistakenly", "translated", "as", "common", "nouns", ",", "which", "is", "unlikely", "to", "affect", "the", "bilingual", "evaluation", "of", "the", "translation", ",", "but", "will", "alter", "the", "human", "readability", "of", "the", "text", "."], "sentence-detokenized": "If the named entities cannot be recognised by the machine translator, they may be mistakenly translated as common nouns, which is unlikely to affect the bilingual evaluation of the translation, but will alter the human readability of the text.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 21], [22, 25], [25, 28], [29, 31], [32, 42], [43, 45], [46, 49], [50, 57], [58, 68], [68, 69], [70, 74], [75, 78], [79, 81], [82, 92], [93, 103], [104, 106], [107, 113], [114, 119], [119, 120], [121, 126], [127, 129], [130, 138], [139, 141], [142, 148], [149, 152], [153, 162], [163, 173], [174, 176], [177, 180], [181, 192], [192, 193], [194, 197], [198, 202], [203, 208], [209, 212], [213, 218], [219, 230], [231, 233], [234, 237], [238, 242], [242, 243]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 22, "location"], [24, 24, "country"], [38, 39, "researcher"], [45, 45, "researcher"], [49, 50, "university"], [54, 55, "researcher"], [57, 58, "researcher"], [60, 61, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 22, "physical", "", false, false], [20, 22, 24, 24, "physical", "", false, false], [45, 45, 49, 50, "physical", "", false, false], [45, 45, 49, 50, "role", "", false, false], [54, 55, 49, 50, "physical", "", false, false], [54, 55, 49, 50, "role", "", false, false], [57, 58, 49, 50, "physical", "", false, false], [57, 58, 49, 50, "role", "", false, false], [60, 61, 49, 50, "physical", "", false, false], [60, 61, 49, 50, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng", "-", "S\u00e4by", ",", "Sweden", ",", "pp.1-", "3", "This", "model", ",", "influenced", "in", "part", "by", "the", "work", "of", "Sydney", "Lamb", ",", "was", "widely", "used", "by", "Schank", "'s", "students", "at", "Yale", "University", ",", "such", "as", "Robert", "Wilensky", ",", "Wendy", "Lehnert", "and", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, pp.1-3 This model, influenced in part by the work of Sydney Lamb, was widely used by Schank's students at Yale University, such as Robert Wilensky, Wendy Lehnert and Janet Kolodner.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 130], [130, 131], [131, 135], [135, 136], [137, 143], [143, 144], [145, 150], [150, 151], [152, 156], [157, 162], [162, 163], [164, 174], [175, 177], [178, 182], [183, 185], [186, 189], [190, 194], [195, 197], [198, 204], [205, 209], [209, 210], [211, 214], [215, 221], [222, 226], [227, 229], [230, 236], [236, 238], [239, 247], [248, 250], [251, 255], [256, 266], [266, 267], [268, 272], [273, 275], [276, 282], [283, 291], [291, 292], [293, 298], [299, 306], [307, 310], [311, 316], [317, 325], [325, 326]]}
{"doc_key": "ai-dev-253", "ner": [[3, 4, "algorithm"], [6, 6, "algorithm"], [13, 13, "algorithm"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 3, 4, "named", "", false, false], [13, 13, 3, 4, "named", "", false, false], [15, 16, 3, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "improved", "maximum", "likelihood", "method", "(", "IMLM", ")", "is", "a", "combination", "of", "two", "MLM", "(", "maximum", "likelihood", ")", "estimators", "."], "sentence-detokenized": "The improved maximum likelihood method (IMLM) is a combination of two MLM (maximum likelihood) estimators.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 38], [39, 40], [40, 44], [44, 45], [46, 48], [49, 50], [51, 62], [63, 65], [66, 69], [70, 73], [74, 75], [75, 82], [83, 93], [93, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-254", "ner": [[22, 23, "metrics"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[26, 27, 22, 23, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "methods", "can", "also", "analyse", "the", "output", "of", "the", "program", "and", "its", "usefulness", ",", "and", "may", "therefore", "include", "an", "analysis", "of", "the", "perturbation", "matrix", "(", "or", "perturbation", "table", ")", "."], "sentence-detokenized": "These methods can also analyse the output of the program and its usefulness, and may therefore include an analysis of the perturbation matrix (or perturbation table).", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 22], [23, 30], [31, 34], [35, 41], [42, 44], [45, 48], [49, 56], [57, 60], [61, 64], [65, 75], [75, 76], [77, 80], [81, 84], [85, 94], [95, 102], [103, 105], [106, 114], [115, 117], [118, 121], [122, 134], [135, 141], [142, 143], [143, 145], [146, 158], [159, 164], [164, 165], [165, 166]]}
{"doc_key": "ai-dev-255", "ner": [[0, 1, "product"], [5, 6, "researcher"], [8, 9, "researcher"], [11, 13, "researcher"], [18, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "origin", "", false, false], [0, 1, 8, 9, "origin", "", false, false], [0, 1, 11, 13, "origin", "", false, false], [0, 1, 18, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "was", "first", "published", "by", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", "and", "Luc", "Van", "Gool", "and", "presented", "at", "the", "2006", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "SURF was first published by Herbert Bay, Tinne Tuytelaars and Luc Van Gool and presented at the 2006 European Conference on Computer Vision.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 39], [39, 40], [41, 46], [47, 57], [58, 61], [62, 65], [66, 69], [70, 74], [75, 78], [79, 88], [89, 91], [92, 95], [96, 100], [101, 109], [110, 120], [121, 123], [124, 132], [133, 139], [139, 140]]}
{"doc_key": "ai-dev-256", "ner": [[0, 2, "task"], [6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 6, 7, "part-of", "", false, false], [0, 2, 9, 10, "part-of", "", false, false], [0, 2, 12, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "is", "a", "research", "field", "in", "pattern", "recognition", ",", "artificial", "intelligence", "and", "computer", "vision", "."], "sentence-detokenized": "OCR is a research field in pattern recognition, artificial intelligence and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 17], [18, 23], [24, 26], [27, 34], [35, 46], [46, 47], [48, 58], [59, 71], [72, 75], [76, 84], [85, 91], [91, 92]]}
{"doc_key": "ai-dev-257", "ner": [[5, 7, "metrics"], [9, 12, "algorithm"], [14, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 16, 9, 12, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Continuing", "the", "example", "using", "the", "maximum", "likelihood", "estimator", ",", "the", "probability", "density", "function", "(", "pdf", ")", "of", "noise", "for", "a", "sample", "mathwn", "/", "math", "is"], "sentence-detokenized": "Continuing the example using the maximum likelihood estimator, the probability density function (pdf) of noise for a sample mathwn / math is", "token2charspan": [[0, 10], [11, 14], [15, 22], [23, 28], [29, 32], [33, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 78], [79, 86], [87, 95], [96, 97], [97, 100], [100, 101], [102, 104], [105, 110], [111, 114], [115, 116], [117, 123], [124, 130], [131, 132], [133, 137], [138, 140]]}
{"doc_key": "ai-dev-258", "ner": [[2, 3, "field"], [5, 6, "task"], [8, 9, "task"], [11, 12, "task"], [14, 15, "task"], [17, 19, "task"], [21, 21, "task"], [23, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 6, 2, 3, "part-of", "", false, false], [8, 9, 2, 3, "part-of", "", false, false], [11, 12, 2, 3, "part-of", "", false, false], [14, 15, 2, 3, "part-of", "", false, false], [17, 19, 2, 3, "part-of", "", false, false], [21, 21, 2, 3, "part-of", "", false, false], [23, 23, 2, 3, "part-of", "", false, false], [25, 26, 2, 3, "part-of", "", false, false], [28, 29, 2, 3, "part-of", "", false, false], [31, 33, 2, 3, "part-of", "", false, false], [35, 36, 2, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Subfields", "of", "computer", "vision", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "3D", "pose", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "servoing", ",", "3D", "scene", "modelling", "and", "image", "restoration", "."], "sentence-detokenized": "Subfields of computer vision include scene reconstruction, event detection, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual servoing, 3D scene modelling and image restoration.", "token2charspan": [[0, 9], [10, 12], [13, 21], [22, 28], [29, 36], [37, 42], [43, 57], [57, 58], [59, 64], [65, 74], [74, 75], [76, 81], [82, 90], [90, 91], [92, 98], [99, 110], [110, 111], [112, 114], [115, 119], [120, 130], [130, 131], [132, 140], [140, 141], [142, 150], [150, 151], [152, 158], [159, 169], [169, 170], [171, 177], [178, 186], [186, 187], [188, 190], [191, 196], [197, 206], [207, 210], [211, 216], [217, 228], [228, 229]]}
{"doc_key": "ai-dev-259", "ner": [[3, 9, "conference"], [11, 11, "researcher"], [12, 15, "misc"], [18, 18, "conference"], [28, 28, "researcher"], [30, 30, "researcher"], [22, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 9, 18, 18, "named", "", false, false], [11, 11, 12, 15, "win-defeat", "", false, false], [11, 11, 22, 22, "related-to", "writes_about", true, false], [12, 15, 3, 9, "temporal", "", false, false], [28, 28, 12, 15, "win-defeat", "", false, true], [28, 28, 22, 22, "related-to", "writes_about", true, false], [30, 30, 12, 15, "win-defeat", "", false, true], [30, 30, 22, 22, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["In", "2013", ",", "at", "the", "International", "Conference", "on", "Computer", "Vision", ",", "Terzopoulos", "received", "the", "Helmholtz", "Prize", "for", "his", "1987", "ICCV", "paper", "on", "active", "contour", "models", ",", "co-authored", "with", "Kass", "and", "Witkin", "."], "sentence-detokenized": "In 2013, at the International Conference on Computer Vision, Terzopoulos received the Helmholtz Prize for his 1987 ICCV paper on active contour models, co-authored with Kass and Witkin.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 40], [41, 43], [44, 52], [53, 59], [59, 60], [61, 72], [73, 81], [82, 85], [86, 95], [96, 101], [102, 105], [106, 109], [110, 114], [115, 119], [120, 125], [126, 128], [129, 135], [136, 143], [144, 150], [150, 151], [152, 163], [164, 168], [169, 173], [174, 177], [178, 184], [184, 185]]}
{"doc_key": "ai-dev-260", "ner": [[13, 15, "task"], [20, 22, "algorithm"], [24, 25, "algorithm"], [27, 29, "algorithm"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 15, 20, 22, "usage", "", true, false], [13, 15, 24, 25, "usage", "", true, false], [13, 15, 27, 29, "usage", "", true, false], [13, 15, 31, 32, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["If", "the", "regularisation", "function", "There", "are", "several", "algorithms", "for", "solving", "such", "problems", ";", "for", "linear", "classification", ",", "popular", "ones", "are", "stochastic", "gradient", "descent", ",", "gradient", "descent", ",", "L", "-", "BFGS", ",", "coordinate", "descent", "and", "Newton", "methods", "."], "sentence-detokenized": "If the regularisation function There are several algorithms for solving such problems; for linear classification, popular ones are stochastic gradient descent, gradient descent, L-BFGS, coordinate descent and Newton methods.", "token2charspan": [[0, 2], [3, 6], [7, 21], [22, 30], [31, 36], [37, 40], [41, 48], [49, 59], [60, 63], [64, 71], [72, 76], [77, 85], [85, 86], [87, 90], [91, 97], [98, 112], [112, 113], [114, 121], [122, 126], [127, 130], [131, 141], [142, 150], [151, 158], [158, 159], [160, 168], [169, 176], [176, 177], [178, 179], [179, 180], [180, 184], [184, 185], [186, 196], [197, 204], [205, 208], [209, 215], [216, 223], [223, 224]]}
{"doc_key": "ai-dev-261", "ner": [[0, 6, "algorithm"], [12, 13, "researcher"], [15, 17, "researcher"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Long", "Short", "-", "Term", "Memory", "(", "LSTM", ")", "networks", "were", "invented", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "and", "have", "set", "accuracy", "records", "in", "several", "applications", "."], "sentence-detokenized": "Long Short-Term Memory (LSTM) networks were invented by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997 and have set accuracy records in several applications.", "token2charspan": [[0, 4], [5, 10], [10, 11], [11, 15], [16, 22], [23, 24], [24, 28], [28, 29], [30, 38], [39, 43], [44, 52], [53, 55], [56, 60], [61, 71], [72, 75], [76, 82], [83, 94], [95, 97], [98, 102], [103, 106], [107, 111], [112, 115], [116, 124], [125, 132], [133, 135], [136, 143], [144, 156], [156, 157]]}
{"doc_key": "ai-dev-262", "ner": [[0, 1, "product"], [4, 7, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 4, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "TN", "was", "developed", "at", "Massachusetts", "General", "Hospital", "and", "tested", "in", "several", "scenarios", ",", "including", "smoking", "status", ",", "extraction", "of", "family", "history", "of", "coronary", "heart", "disease", ",", "and", "identification", "of", "patients", "with", "sleep", "disorders", ","], "sentence-detokenized": "The TN was developed at Massachusetts General Hospital and tested in several scenarios, including smoking status, extraction of family history of coronary heart disease, and identification of patients with sleep disorders,", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 20], [21, 23], [24, 37], [38, 45], [46, 54], [55, 58], [59, 65], [66, 68], [69, 76], [77, 86], [86, 87], [88, 97], [98, 105], [106, 112], [112, 113], [114, 124], [125, 127], [128, 134], [135, 142], [143, 145], [146, 154], [155, 160], [161, 168], [168, 169], [170, 173], [174, 188], [189, 191], [192, 200], [201, 205], [206, 211], [212, 221], [221, 222]]}
{"doc_key": "ai-dev-263", "ner": [[3, 3, "researcher"], [8, 8, "product"], [14, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 8, "role", "sells", false, false], [8, 8, 14, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 86], [87, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-dev-264", "ner": [[0, 2, "conference"], [11, 15, "location"], [16, 16, "location"], [18, 18, "country"], [30, 31, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 11, 15, "physical", "", false, false], [11, 15, 16, 16, "physical", "", false, false], [16, 16, 18, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Campus", "Party", "Europe", "took", "place", "from", "14", "-", "18", "April", "2010", "at", "the", "Caja", "M\u00e1gica", "in", "Madrid", ",", "Spain", ",", "with", "800", "participants", "from", "the", "27", "Member", "States", "of", "the", "European", "Union", "."], "sentence-detokenized": "Campus Party Europe took place from 14-18 April 2010 at the Caja M\u00e1gica in Madrid, Spain, with 800 participants from the 27 Member States of the European Union.", "token2charspan": [[0, 6], [7, 12], [13, 19], [20, 24], [25, 30], [31, 35], [36, 38], [38, 39], [39, 41], [42, 47], [48, 52], [53, 55], [56, 59], [60, 64], [65, 71], [72, 74], [75, 81], [81, 82], [83, 88], [88, 89], [90, 94], [95, 98], [99, 111], [112, 116], [117, 120], [121, 123], [124, 130], [131, 137], [138, 140], [141, 144], [145, 153], [154, 159], [159, 160]]}
{"doc_key": "ai-dev-265", "ner": [[7, 7, "organisation"], [9, 11, "organisation"], [16, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 20, 7, 7, "origin", "", false, false], [16, 20, 9, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2016", ",", "a", "collaboration", "between", "DeepMind", "and", "Moorfields", "Eye", "Hospital", "was", "announced", "to", "develop", "artificial", "intelligence", "for", "healthcare", "applications", "."], "sentence-detokenized": "In July 2016, a collaboration between DeepMind and Moorfields Eye Hospital was announced to develop artificial intelligence for healthcare applications.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 15], [16, 29], [30, 37], [38, 46], [47, 50], [51, 61], [62, 65], [66, 74], [75, 78], [79, 88], [89, 91], [92, 99], [100, 110], [111, 123], [124, 127], [128, 138], [139, 151], [151, 152]]}
{"doc_key": "ai-dev-266", "ner": [[3, 3, "misc"], [12, 14, "university"], [16, 16, "university"], [18, 19, "university"], [21, 22, "university"], [24, 24, "university"], [26, 26, "university"], [29, 32, "university"], [34, 35, "university"], [37, 38, "university"], [40, 40, "university"], [43, 45, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[3, 3, 12, 14, "physical", "", false, false], [3, 3, 16, 16, "physical", "", false, false], [3, 3, 18, 19, "physical", "", false, false], [3, 3, 21, 22, "physical", "", false, false], [3, 3, 24, 24, "physical", "", false, false], [3, 3, 26, 26, "physical", "", false, false], [3, 3, 29, 32, "physical", "", false, false], [3, 3, 34, 35, "physical", "", false, false], [3, 3, 37, 38, "physical", "", false, false], [3, 3, 40, 40, "physical", "", false, false], [3, 3, 43, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Finally", ",", "eleven", "PR2s", "were", "awarded", "to", "various", "institutions", ",", "including", "the", "University", "of", "Freiburg", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "the", "Technical", "University", "of", "Munich", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", "and", "the", "University", "of", "Tokyo", "."], "sentence-detokenized": "Finally, eleven PR2s were awarded to various institutions, including the University of Freiburg, Bosch, Georgia Tech, KU Leuven, MIT, Stanford, the Technical University of Munich, UC Berkeley, U Penn, USC and the University of Tokyo.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 20], [21, 25], [26, 33], [34, 36], [37, 44], [45, 57], [57, 58], [59, 68], [69, 72], [73, 83], [84, 86], [87, 95], [95, 96], [97, 102], [102, 103], [104, 111], [112, 116], [116, 117], [118, 120], [121, 127], [127, 128], [129, 132], [132, 133], [134, 142], [142, 143], [144, 147], [148, 157], [158, 168], [169, 171], [172, 178], [178, 179], [180, 182], [183, 191], [191, 192], [193, 194], [195, 199], [199, 200], [201, 204], [205, 208], [209, 212], [213, 223], [224, 226], [227, 232], [232, 233]]}
{"doc_key": "ai-dev-267", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [7, 7, "metrics"], [9, 9, "metrics"], [17, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 17, 19, "part-of", "", false, false], [5, 5, 17, 19, "part-of", "", false, false], [7, 7, 17, 19, "part-of", "", false, false], [9, 9, 17, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "values", "of", "TP", ",", "TN", ",", "FP", "and", "FN", "are", "usually", "kept", "in", "a", "table", "called", "a", "perturbation", "matrix", "."], "sentence-detokenized": "The values of TP, TN, FP and FN are usually kept in a table called a perturbation matrix.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 16], [16, 17], [18, 20], [20, 21], [22, 24], [25, 28], [29, 31], [32, 35], [36, 43], [44, 48], [49, 51], [52, 53], [54, 59], [60, 66], [67, 68], [69, 81], [82, 88], [88, 89]]}
{"doc_key": "ai-dev-268", "ner": [[0, 1, "metrics"], [3, 3, "metrics"], [5, 6, "metrics"], [8, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Information", "gain", ",", "crossentropy", ",", "mutual", "information", "and", "odds", "ratio", "are", "commonly", "used", "as", "feature", "sets", "."], "sentence-detokenized": "Information gain, crossentropy, mutual information and odds ratio are commonly used as feature sets.", "token2charspan": [[0, 11], [12, 16], [16, 17], [18, 30], [30, 31], [32, 38], [39, 50], [51, 54], [55, 59], [60, 65], [66, 69], [70, 78], [79, 83], [84, 86], [87, 94], [95, 99], [99, 100]]}
{"doc_key": "ai-dev-269", "ner": [[10, 11, "task"], [13, 14, "task"], [16, 16, "task"], [18, 18, "task"], [20, 20, "task"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[22, 22, 20, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "successfully", "applied", "to", "various", "problems", ",", "including", "robot", "control", ",", "lift", "scheduling", ",", "telecommunications", ",", "checkers", "and", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "It has been successfully applied to various problems, including robot control, lift scheduling, telecommunications, checkers and Go (AlphaGo).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 32], [33, 35], [36, 43], [44, 52], [52, 53], [54, 63], [64, 69], [70, 77], [77, 78], [79, 83], [84, 94], [94, 95], [96, 114], [114, 115], [116, 124], [125, 128], [129, 131], [132, 133], [133, 140], [140, 141], [141, 142]]}
{"doc_key": "ai-dev-270", "ner": [[12, 13, "misc"], [20, 24, "university"], [25, 25, "location"], [27, 27, "location"], [31, 37, "location"], [38, 41, "location"], [42, 42, "location"], [44, 44, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[12, 13, 20, 24, "physical", "", false, false], [20, 24, 25, 25, "physical", "", false, false], [25, 25, 27, 27, "physical", "", false, false], [31, 37, 38, 41, "physical", "", false, false], [38, 41, 42, 42, "physical", "", false, false], [42, 42, 44, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "the", "inaugural", "year", "of", "the", "8th", "Mission", ",", "the", "US", "location", "was", "on", "the", "campus", "of", "the", "Georgia", "Institute", "of", "Technology", "in", "Atlanta", ",", "Georgia", ",", "and", "the", "Asia", "/", "Pacific", "location", "was", "at", "the", "Beihang", "University", "Gymnasium", "in", "Beijing", ",", "China", "."], "sentence-detokenized": "In 2018, the inaugural year of the 8th Mission, the US location was on the campus of the Georgia Institute of Technology in Atlanta, Georgia, and the Asia/Pacific location was at the Beihang University Gymnasium in Beijing, China.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 34], [35, 38], [39, 46], [46, 47], [48, 51], [52, 54], [55, 63], [64, 67], [68, 70], [71, 74], [75, 81], [82, 84], [85, 88], [89, 96], [97, 106], [107, 109], [110, 120], [121, 123], [124, 131], [131, 132], [133, 140], [140, 141], [142, 145], [146, 149], [150, 154], [154, 155], [155, 162], [163, 171], [172, 175], [176, 178], [179, 182], [183, 190], [191, 201], [202, 211], [212, 214], [215, 222], [222, 223], [224, 229], [229, 230]]}
{"doc_key": "ai-dev-271", "ner": [[0, 2, "field"], [6, 7, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 7, "origin", "", false, false], [0, 2, 6, 7, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "is", "closely", "related", "to", "pattern", "recognition", "and", "comes", "from", "artificial", "intelligence", "."], "sentence-detokenized": "Machine learning is closely related to pattern recognition and comes from artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 35], [36, 38], [39, 46], [47, 58], [59, 62], [63, 68], [69, 73], [74, 84], [85, 97], [97, 98]]}
{"doc_key": "ai-dev-272", "ner": [[18, 19, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "device", "includes", "3", "Java", "games", "that", "can", "be", "controlled", "by", "the", "remote", "control", "and", "displayed", "on", "the", "LCD", "screen", "."], "sentence-detokenized": "The device includes 3 Java games that can be controlled by the remote control and displayed on the LCD screen.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 21], [22, 26], [27, 32], [33, 37], [38, 41], [42, 44], [45, 55], [56, 58], [59, 62], [63, 69], [70, 77], [78, 81], [82, 91], [92, 94], [95, 98], [99, 102], [103, 109], [109, 110]]}
{"doc_key": "ai-dev-273", "ner": [[5, 13, "task"], [14, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 16, 5, 13, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "commercially", "successful", "but", "specialised", "articulated", "pose", "estimation", "technique", "based", "on", "computer", "vision", "is", "optical", "motion", "capture", "."], "sentence-detokenized": "A commercially successful but specialised articulated pose estimation technique based on computer vision is optical motion capture.", "token2charspan": [[0, 1], [2, 14], [15, 25], [26, 29], [30, 41], [42, 53], [54, 58], [59, 69], [70, 79], [80, 85], [86, 88], [89, 97], [98, 104], [105, 107], [108, 115], [116, 122], [123, 130], [130, 131]]}
{"doc_key": "ai-dev-274", "ner": [[1, 2, "organisation"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 9, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SMC", "is", "very", "similar", "to", "the", "more", "popular", "Jaccard", "index", "."], "sentence-detokenized": "The SMC is very similar to the more popular Jaccard index.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 23], [24, 26], [27, 30], [31, 35], [36, 43], [44, 51], [52, 57], [57, 58]]}
{"doc_key": "ai-dev-275", "ner": [[1, 1, "product"], [3, 7, "product"], [10, 13, "product"], [22, 23, "researcher"], [29, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 10, 13, "named", "", false, false], [1, 1, 22, 23, "artifact", "", false, false], [1, 1, 29, 29, "artifact", "", false, false], [3, 7, 1, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ",", "or", "Programmable", "Universal", "Manipulation", "Arm", ")", "is", "an", "industrial", "robotic", "arm", "developed", "by", "Victor", "Scheinman", "at", "the", "pioneering", "robotics", "company", "Unimation", "."], "sentence-detokenized": "The PUMA (Programmable Universal Machine for Assembly, or Programmable Universal Manipulation Arm) is an industrial robotic arm developed by Victor Scheinman at the pioneering robotics company Unimation.", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 22], [23, 32], [33, 40], [41, 44], [45, 53], [53, 54], [55, 57], [58, 70], [71, 80], [81, 93], [94, 97], [97, 98], [99, 101], [102, 104], [105, 115], [116, 123], [124, 127], [128, 137], [138, 140], [141, 147], [148, 157], [158, 160], [161, 164], [165, 175], [176, 184], [185, 192], [193, 202], [202, 203]]}
{"doc_key": "ai-dev-276", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "written", "in", "Python", "."], "sentence-detokenized": "It is written in Python.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 23], [23, 24]]}
{"doc_key": "ai-dev-277", "ner": [[0, 0, "misc"], [3, 7, "misc"], [15, 15, "field"], [17, 18, "field"], [20, 20, "field"], [23, 23, "field"], [26, 27, "field"], [29, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 3, 7, "related-to", "metric_for", true, false], [0, 0, 15, 15, "part-of", "", false, false], [0, 0, 17, 18, "part-of", "", false, false], [0, 0, 20, 20, "part-of", "", false, false], [0, 0, 23, 23, "part-of", "", false, false], [0, 0, 26, 27, "part-of", "", false, false], [0, 0, 29, 32, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Bandwidth", ",", "expressed", "in", "hertz", ",", "is", "a", "central", "concept", "in", "many", "fields", ",", "including", "electronics", ",", "information", "theory", ",", "digital", "communications", ",", "radio", "communications", ",", "signal", "processing", "and", "spectroscopy", ",", "and", "is", "one", "of", "the", "determinants", "of", "the", "capacity", "of", "a", "communication", "channel", "."], "sentence-detokenized": "Bandwidth, expressed in hertz, is a central concept in many fields, including electronics, information theory, digital communications, radio communications, signal processing and spectroscopy, and is one of the determinants of the capacity of a communication channel.", "token2charspan": [[0, 9], [9, 10], [11, 20], [21, 23], [24, 29], [29, 30], [31, 33], [34, 35], [36, 43], [44, 51], [52, 54], [55, 59], [60, 66], [66, 67], [68, 77], [78, 89], [89, 90], [91, 102], [103, 109], [109, 110], [111, 118], [119, 133], [133, 134], [135, 140], [141, 155], [155, 156], [157, 163], [164, 174], [175, 178], [179, 191], [191, 192], [193, 196], [197, 199], [200, 203], [204, 206], [207, 210], [211, 223], [224, 226], [227, 230], [231, 239], [240, 242], [243, 244], [245, 258], [259, 266], [266, 267]]}
{"doc_key": "ai-dev-278", "ner": [[9, 9, "algorithm"], [11, 11, "algorithm"], [17, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 17, 20, "part-of", "", false, false], [11, 11, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "a", "convex", "loss", "is", "used", "(", "as", "in", "AdaBoost", ",", "LogitBoost", "and", "all", "members", "of", "the", "AnyBoost", "family", "of", "algorithms", ")", ",", "the", "example", "with", "the", "larger", "margin", "is", "given", "less", "(", "or", "the", "same", ")", "weight", "as", "the", "example", "with", "the", "smaller", "margin", "."], "sentence-detokenized": "If a convex loss is used (as in AdaBoost, LogitBoost and all members of the AnyBoost family of algorithms), the example with the larger margin is given less (or the same) weight as the example with the smaller margin.", "token2charspan": [[0, 2], [3, 4], [5, 11], [12, 16], [17, 19], [20, 24], [25, 26], [26, 28], [29, 31], [32, 40], [40, 41], [42, 52], [53, 56], [57, 60], [61, 68], [69, 71], [72, 75], [76, 84], [85, 91], [92, 94], [95, 105], [105, 106], [106, 107], [108, 111], [112, 119], [120, 124], [125, 128], [129, 135], [136, 142], [143, 145], [146, 151], [152, 156], [157, 158], [158, 160], [161, 164], [165, 169], [169, 170], [171, 177], [178, 180], [181, 184], [185, 192], [193, 197], [198, 201], [202, 209], [210, 216], [216, 217]]}
{"doc_key": "ai-dev-279", "ner": [[0, 1, "researcher"], [5, 6, "researcher"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sepp", "Hochreiter", "'s", "1991", "thesis", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Sepp Hochreiter's 1991 thesis Sepp Hochreiter.", "token2charspan": [[0, 4], [5, 15], [15, 17], [18, 22], [23, 29], [30, 34], [35, 45], [45, 46]]}
{"doc_key": "ai-dev-280", "ner": [[5, 5, "algorithm"], [4, 7, "algorithm"], [10, 10, "algorithm"], [14, 14, "algorithm"], [17, 19, "algorithm"], [18, 21, "algorithm"], [26, 28, "algorithm"], [31, 32, "algorithm"], [34, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[4, 7, 5, 5, "named", "", false, false], [14, 14, 10, 10, "named", "", false, false], [17, 19, 26, 28, "related-to", "", true, false], [18, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Typical", "discriminative", "models", "include", "logistic", "regression", "(", "LR", ")", ",", "support", "vector", "machines", "(", "SVM", ")", ",", "conditional", "random", "fields", "(", "CRF", ")", "(", "defined", "over", "an", "undirected", "graph", ")", ",", "decision", "trees", ",", "neural", "networks", "and", "many", "others", "."], "sentence-detokenized": "Typical discriminative models include logistic regression (LR), support vector machines (SVM), conditional random fields (CRF) (defined over an undirected graph), decision trees, neural networks and many others.", "token2charspan": [[0, 7], [8, 22], [23, 29], [30, 37], [38, 46], [47, 57], [58, 59], [59, 61], [61, 62], [62, 63], [64, 71], [72, 78], [79, 87], [88, 89], [89, 92], [92, 93], [93, 94], [95, 106], [107, 113], [114, 120], [121, 122], [122, 125], [125, 126], [127, 128], [128, 135], [136, 140], [141, 143], [144, 154], [155, 160], [160, 161], [161, 162], [163, 171], [172, 177], [177, 178], [179, 185], [186, 194], [195, 198], [199, 203], [204, 210], [210, 211]]}
{"doc_key": "ai-dev-281", "ner": [[12, 14, "metrics"], [33, 36, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "then", "also", "possible", "to", "use", "these", "probabilities", "to", "evaluate", "the", "mean", "squared", "error", "(", "or", "other", "similar", "measure", ")", "between", "the", "probabilities", "and", "the", "actual", "values", ",", "and", "then", "combine", "this", "with", "the", "confusion", "matrix", "to", "create", "very", "efficient", "fit", "functions", "for", "logistic", "regression", "."], "sentence-detokenized": "It is then also possible to use these probabilities to evaluate the mean squared error (or other similar measure) between the probabilities and the actual values, and then combine this with the confusion matrix to create very efficient fit functions for logistic regression.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 15], [16, 24], [25, 27], [28, 31], [32, 37], [38, 51], [52, 54], [55, 63], [64, 67], [68, 72], [73, 80], [81, 86], [87, 88], [88, 90], [91, 96], [97, 104], [105, 112], [112, 113], [114, 121], [122, 125], [126, 139], [140, 143], [144, 147], [148, 154], [155, 161], [161, 162], [163, 166], [167, 171], [172, 179], [180, 184], [185, 189], [190, 193], [194, 203], [204, 210], [211, 213], [214, 220], [221, 225], [226, 235], [236, 239], [240, 249], [250, 253], [254, 262], [263, 273], [273, 274]]}
{"doc_key": "ai-dev-282", "ner": [[0, 0, "product"], [6, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "first", "appeared", "in", "2005", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "."], "sentence-detokenized": "VoiceOver first appeared in 2005 in Mac OS X Tiger (10.4).", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 27], [28, 32], [33, 35], [36, 39], [40, 42], [43, 44], [45, 50], [51, 52], [52, 56], [56, 57], [57, 58]]}
{"doc_key": "ai-dev-283", "ner": [[12, 14, "algorithm"], [19, 20, "misc"], [23, 26, "metrics"], [29, 31, "algorithm"], [61, 63, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 14, 19, 20, "related-to", "applied_to", false, false], [23, 26, 19, 20, "type-of", "", false, false], [23, 26, 29, 31, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "practice", ",", "machine", "learning", "algorithms", "solve", "this", "either", "by", "using", "a", "convex", "approximation", "of", "the", "0", "-", "1", "loss", "function", "(", "like", "hinge", "loss", "in", "the", "case", "of", "support", "vector", "machines", ")", ",", "which", "is", "easier", "to", "optimize", ",", "or", "by", "making", "assumptions", "on", "the", "mathP", "(", "x", ",", "y", ")", "/", "math", "distribution", "(", "and", "thus", "cease", "to", "be", "agnostic", "learning", "algorithms", ",", "for", "which", "the", "above", "result", "holds", ")", "."], "sentence-detokenized": "In practice, machine learning algorithms solve this either by using a convex approximation of the 0-1 loss function (like hinge loss in the case of support vector machines), which is easier to optimize, or by making assumptions on the mathP(x, y)/math distribution (and thus cease to be agnostic learning algorithms, for which the above result holds).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 29], [30, 40], [41, 46], [47, 51], [52, 58], [59, 61], [62, 67], [68, 69], [70, 76], [77, 90], [91, 93], [94, 97], [98, 99], [99, 100], [100, 101], [102, 106], [107, 115], [116, 117], [117, 121], [122, 127], [128, 132], [133, 135], [136, 139], [140, 144], [145, 147], [148, 155], [156, 162], [163, 171], [171, 172], [172, 173], [174, 179], [180, 182], [183, 189], [190, 192], [193, 201], [201, 202], [203, 205], [206, 208], [209, 215], [216, 227], [228, 230], [231, 234], [235, 240], [240, 241], [241, 242], [242, 243], [244, 245], [245, 246], [246, 247], [247, 251], [252, 264], [265, 266], [266, 269], [270, 274], [275, 280], [281, 283], [284, 286], [287, 295], [296, 304], [305, 315], [315, 316], [317, 320], [321, 326], [327, 330], [331, 336], [337, 343], [344, 349], [349, 350], [350, 351]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [11, 13, "field"], [16, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "usage", "", false, false], [0, 0, 16, 22, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Westworld", "(", "1973", ")", "was", "the", "first", "feature", "film", "to", "use", "digital", "image", "processing", "to", "simulate", "the", "point", "of", "view", "of", "an", "android", "."], "sentence-detokenized": "Westworld (1973) was the first feature film to use digital image processing to simulate the point of view of an android.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 20], [21, 24], [25, 30], [31, 38], [39, 43], [44, 46], [47, 50], [51, 58], [59, 64], [65, 75], [76, 78], [79, 87], [88, 91], [92, 97], [98, 100], [101, 105], [106, 108], [109, 111], [112, 119], [119, 120]]}
{"doc_key": "ai-dev-285", "ner": [[5, 7, "task"], [9, 10, "task"], [12, 12, "task"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "now", "commonly", "used", "in", "speech", "recognition", ",", "speech", "synthesis", ",", "logging", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "It is now commonly used in speech recognition, speech synthesis, logging, Xavier Anguera et al.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 18], [19, 23], [24, 26], [27, 33], [34, 45], [45, 46], [47, 53], [54, 63], [63, 64], [65, 72], [72, 73], [74, 80], [81, 88], [89, 91], [92, 94], [94, 95]]}
{"doc_key": "ai-dev-286", "ner": [[9, 11, "algorithm"], [16, 17, "algorithm"], [20, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 17, 9, 11, "type-of", "", false, false], [20, 22, 9, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Here", ",", "math", "\\", "sigma", "/", "math", "is", "a", "per-element", "activation", "function", ",", "such", "as", "a", "sigmoid", "function", "or", "a", "rectified", "linear", "unit", "."], "sentence-detokenized": "Here, math\\ sigma / math is a per-element activation function, such as a sigmoid function or a rectified linear unit.", "token2charspan": [[0, 4], [4, 5], [6, 10], [10, 11], [12, 17], [18, 19], [20, 24], [25, 27], [28, 29], [30, 41], [42, 52], [53, 61], [61, 62], [63, 67], [68, 70], [71, 72], [73, 80], [81, 89], [90, 92], [93, 94], [95, 104], [105, 111], [112, 116], [116, 117]]}
{"doc_key": "ai-dev-287", "ner": [[7, 8, "algorithm"], [21, 21, "misc"], [23, 23, "misc"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "phonetic", "-", "based", "(", "i.e.", "all", "Hidden", "Markov", "Model", "-", "based", ")", "approaches", "required", "separate", "components", "and", "training", "for", "the", "pronunciation", ",", "acoustic", "and", "linguistic", "models", "."], "sentence-detokenized": "Traditional phonetic-based (i.e. all Hidden Markov Model-based) approaches required separate components and training for the pronunciation, acoustic and linguistic models.", "token2charspan": [[0, 11], [12, 20], [20, 21], [21, 26], [27, 28], [28, 32], [33, 36], [37, 43], [44, 50], [51, 56], [56, 57], [57, 62], [62, 63], [64, 74], [75, 83], [84, 92], [93, 103], [104, 107], [108, 116], [117, 120], [121, 124], [125, 138], [138, 139], [140, 148], [149, 152], [153, 163], [164, 170], [170, 171]]}
{"doc_key": "ai-dev-288", "ner": [[1, 4, "algorithm"], [6, 8, "field"], [10, 11, "field"], [12, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 4, 12, 14, "related-to", "used_for", false, false], [6, 8, 1, 4, "usage", "", false, false], [10, 11, 1, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Roberts", "cross", "operator", "is", "used", "in", "image", "processing", "and", "computer", "vision", "for", "edge", "detection", "."], "sentence-detokenized": "The Roberts cross operator is used in image processing and computer vision for edge detection.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 37], [38, 43], [44, 54], [55, 58], [59, 67], [68, 74], [75, 78], [79, 83], [84, 93], [93, 94]]}
{"doc_key": "ai-dev-289", "ner": [[0, 0, "metrics"], [2, 2, "metrics"], [23, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 23, 23, "opposite", "", false, false], [2, 2, 23, 23, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Sensitivity", "and", "specificity", "values", "do", "not", "depend", "on", "the", "percentage", "of", "positive", "cases", "in", "the", "population", "tested", "(", "unlike", ",", "for", "example", ",", "accuracy", ")", "."], "sentence-detokenized": "Sensitivity and specificity values do not depend on the percentage of positive cases in the population tested (unlike, for example, accuracy).", "token2charspan": [[0, 11], [12, 15], [16, 27], [28, 34], [35, 37], [38, 41], [42, 48], [49, 51], [52, 55], [56, 66], [67, 69], [70, 78], [79, 84], [85, 87], [88, 91], [92, 102], [103, 109], [110, 111], [111, 117], [117, 118], [119, 122], [123, 130], [130, 131], [132, 140], [140, 141], [141, 142]]}
{"doc_key": "ai-dev-290", "ner": [[3, 5, "algorithm"], [17, 17, "misc"], [10, 11, "researcher"], [13, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 17, 3, 5, "topic", "", false, false], [17, 17, 10, 11, "artifact", "", false, false], [17, 17, 13, 15, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "the", "perceptron", "models", "were", "made", "very", "unpopular", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "'s", "book", "Perceptrons", ",", "published", "in", "1969", "."], "sentence-detokenized": "However, the perceptron models were made very unpopular by Marvin Minsky and Seymour Papert's book Perceptrons, published in 1969.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 23], [24, 30], [31, 35], [36, 40], [41, 45], [46, 55], [56, 58], [59, 65], [66, 72], [73, 76], [77, 84], [85, 91], [91, 93], [94, 98], [99, 110], [110, 111], [112, 121], [122, 124], [125, 129], [129, 130]]}
{"doc_key": "ai-dev-291", "ner": [[3, 5, "conference"], [0, 1, "organisation"], [18, 20, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 18, 20, "topic", "", false, false], [0, 1, 3, 5, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["NIST", "'s", "annual", "Document", "Understanding", "Conferences", "have", "developed", "sophisticated", "evaluation", "criteria", "for", "techniques", "that", "capture", "the", "challenge", "of", "summarizing", "multiple", "documents", "."], "sentence-detokenized": "NIST's annual Document Understanding Conferences have developed sophisticated evaluation criteria for techniques that capture the challenge of summarizing multiple documents.", "token2charspan": [[0, 4], [4, 6], [7, 13], [14, 22], [23, 36], [37, 48], [49, 53], [54, 63], [64, 77], [78, 88], [89, 97], [98, 101], [102, 112], [113, 117], [118, 125], [126, 129], [130, 139], [140, 142], [143, 154], [155, 163], [164, 173], [173, 174]]}
{"doc_key": "ai-dev-292", "ner": [[0, 1, "product"], [25, 28, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 25, 28, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Parallel", "manipulators", "are", "designed", "so", "that", "the", "individual", "chains", "are", "generally", "short", "and", "simple", ",", "and", "so", "can", "be", "rigid", "against", "unwanted", "movements", ",", "unlike", "in", "-", "line", "manipulators", "."], "sentence-detokenized": "Parallel manipulators are designed so that the individual chains are generally short and simple, and so can be rigid against unwanted movements, unlike in-line manipulators.", "token2charspan": [[0, 8], [9, 21], [22, 25], [26, 34], [35, 37], [38, 42], [43, 46], [47, 57], [58, 64], [65, 68], [69, 78], [79, 84], [85, 88], [89, 95], [95, 96], [97, 100], [101, 103], [104, 107], [108, 110], [111, 116], [117, 124], [125, 133], [134, 143], [143, 144], [145, 151], [152, 154], [154, 155], [155, 159], [160, 172], [172, 173]]}
{"doc_key": "ai-dev-293", "ner": [[26, 26, "misc"], [28, 30, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "the", "manipulator", "that", "makes", "the", "robot", "move", ",", "and", "the", "design", "of", "these", "systems", "can", "be", "classified", "into", "several", "general", "types", ",", "such", "as", "SCARA", "and", "Cartesian", "coordinate", "robots", ",", "which", "use", "different", "coordinate", "systems", "to", "control", "the", "machine", "'s", "arms", "."], "sentence-detokenized": "It is the manipulator that makes the robot move, and the design of these systems can be classified into several general types, such as SCARA and Cartesian coordinate robots, which use different coordinate systems to control the machine's arms.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 21], [22, 26], [27, 32], [33, 36], [37, 42], [43, 47], [47, 48], [49, 52], [53, 56], [57, 63], [64, 66], [67, 72], [73, 80], [81, 84], [85, 87], [88, 98], [99, 103], [104, 111], [112, 119], [120, 125], [125, 126], [127, 131], [132, 134], [135, 140], [141, 144], [145, 154], [155, 165], [166, 172], [172, 173], [174, 179], [180, 183], [184, 193], [194, 204], [205, 212], [213, 215], [216, 223], [224, 227], [228, 235], [235, 237], [238, 242], [242, 243]]}
{"doc_key": "ai-dev-294", "ner": [[0, 6, "country"], [11, 14, "organisation"], [17, 22, "organisation"], [25, 27, "organisation"], [30, 32, "organisation"], [35, 41, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 14, 0, 6, "physical", "", false, false], [17, 22, 0, 6, "physical", "", false, false], [25, 27, 0, 6, "physical", "", false, false], [30, 32, 0, 6, "physical", "", false, false], [35, 41, 0, 6, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "United", "States", ",", "he", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Linguistic", "Association", ",", "the", "American", "Philosophical", "Association", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In the United States, he is a member of the National Academy of Sciences, the American Academy of Arts and Sciences, the American Linguistic Association, the American Philosophical Association and the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 20], [20, 21], [22, 24], [25, 27], [28, 29], [30, 36], [37, 39], [40, 43], [44, 52], [53, 60], [61, 63], [64, 72], [72, 73], [74, 77], [78, 86], [87, 94], [95, 97], [98, 102], [103, 106], [107, 115], [115, 116], [117, 120], [121, 129], [130, 140], [141, 152], [152, 153], [154, 157], [158, 166], [167, 180], [181, 192], [193, 196], [197, 200], [201, 209], [210, 221], [222, 225], [226, 229], [230, 241], [242, 244], [245, 252], [252, 253]]}
{"doc_key": "ai-dev-295", "ner": [[11, 13, "algorithm"], [15, 15, "algorithm"], [23, 24, "algorithm"], [27, 28, "algorithm"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 13, 23, 24, "named", "", false, false], [15, 15, 11, 13, "named", "", false, false], [23, 24, 27, 28, "compare", "", false, false], [23, 24, 33, 34, "related-to", "performs", false, false], [27, 28, 33, 34, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["They", "gained", "great", "popularity", "in", "the", "1990s", "with", "the", "popularity", "of", "support", "vector", "machines", "(", "SVMs", ")", ",", "when", "it", "was", "shown", "that", "SVMs", "could", "compete", "with", "neural", "networks", "in", "tasks", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "They gained great popularity in the 1990s with the popularity of support vector machines (SVMs), when it was shown that SVMs could compete with neural networks in tasks such as handwriting recognition.", "token2charspan": [[0, 4], [5, 11], [12, 17], [18, 28], [29, 31], [32, 35], [36, 41], [42, 46], [47, 50], [51, 61], [62, 64], [65, 72], [73, 79], [80, 88], [89, 90], [90, 94], [94, 95], [95, 96], [97, 101], [102, 104], [105, 108], [109, 114], [115, 119], [120, 124], [125, 130], [131, 138], [139, 143], [144, 150], [151, 159], [160, 162], [163, 168], [169, 173], [174, 176], [177, 188], [189, 200], [200, 201]]}
{"doc_key": "ai-dev-296", "ner": [[2, 4, "misc"], [9, 9, "misc"], [13, 16, "algorithm"], [22, 23, "misc"], [27, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 9, 9, "usage", "", false, false], [2, 4, 22, 23, "usage", "", false, false], [9, 9, 13, 16, "origin", "result_of_algorithm", false, false], [22, 23, 27, 29, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "empirical", "bleaching", "transformation", "is", "obtained", "by", "estimating", "the", "covariance", "(", "e.g.", ",", "maximum", "likelihood", ")", "and", "then", "constructing", "the", "corresponding", "estimated", "bleaching", "matrix", "(", "e.g.", ",", "by", "Cholesky", "decomposition", ")", "."], "sentence-detokenized": "The empirical bleaching transformation is obtained by estimating the covariance (e.g., maximum likelihood) and then constructing the corresponding estimated bleaching matrix (e.g., by Cholesky decomposition).", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 38], [39, 41], [42, 50], [51, 53], [54, 64], [65, 68], [69, 79], [80, 81], [81, 85], [85, 86], [87, 94], [95, 105], [105, 106], [107, 110], [111, 115], [116, 128], [129, 132], [133, 146], [147, 156], [157, 166], [167, 173], [174, 175], [175, 179], [179, 180], [181, 183], [184, 192], [193, 206], [206, 207], [207, 208]]}
{"doc_key": "ai-dev-297", "ner": [[0, 2, "organisation"], [8, 12, "product"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 12, 0, 2, "artifact", "", false, false], [22, 23, 0, 2, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "is", "the", "world", "'s", "largest", "manufacturer", "of", "Cartesian", "coordinate", "robots", "and", "a", "leader", "in", "low", "-", "cost", ",", "high", "-", "performance", "SCARA", "robots", "."], "sentence-detokenized": "IAI is the world's largest manufacturer of Cartesian coordinate robots and a leader in low-cost, high-performance SCARA robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [16, 18], [19, 26], [27, 39], [40, 42], [43, 52], [53, 63], [64, 70], [71, 74], [75, 76], [77, 83], [84, 86], [87, 90], [90, 91], [91, 95], [95, 96], [97, 101], [101, 102], [102, 113], [114, 119], [120, 126], [126, 127]]}
{"doc_key": "ai-dev-298", "ner": [[10, 11, "field"], [13, 14, "field"], [16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 28, "field"], [7, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formal", "concept", "analysis", "has", "practical", "applications", "in", "fields", "such", "as", "data", "mining", ",", "text", "mining", ",", "machine", "learning", ",", "knowledge", "management", ",", "semantic", "web", ",", "software", "development", ",", "chemistry", "and", "biology", "."], "sentence-detokenized": "Formal concept analysis has practical applications in fields such as data mining, text mining, machine learning, knowledge management, semantic web, software development, chemistry and biology.", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 27], [28, 37], [38, 50], [51, 53], [54, 60], [61, 65], [66, 68], [69, 73], [74, 80], [80, 81], [82, 86], [87, 93], [93, 94], [95, 102], [103, 111], [111, 112], [113, 122], [123, 133], [133, 134], [135, 143], [144, 147], [147, 148], [149, 157], [158, 169], [169, 170], [171, 180], [181, 184], [185, 192], [192, 193]]}
{"doc_key": "ai-dev-299", "ner": [[0, 2, "field"], [4, 6, "field"], [10, 13, "field"], [17, 19, "field"], [30, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 17, 19, "part-of", "", false, false], [4, 6, 30, 31, "topic", "", false, false], [10, 13, 4, 6, "named", "", false, false], [17, 19, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", ",", "computational", "learning", "theory", "(", "or", "simply", "learning", "theory", ")", "is", "a", "subfield", "of", "artificial", "intelligence", "that", "deals", "with", "the", "study", "of", "the", "design", "and", "analysis", "of", "machine", "learning", "algorithms", "."], "sentence-detokenized": "In computer science, computational learning theory (or simply learning theory) is a subfield of artificial intelligence that deals with the study of the design and analysis of machine learning algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 34], [35, 43], [44, 50], [51, 52], [52, 54], [55, 61], [62, 70], [71, 77], [77, 78], [79, 81], [82, 83], [84, 92], [93, 95], [96, 106], [107, 119], [120, 124], [125, 130], [131, 135], [136, 139], [140, 145], [146, 148], [149, 152], [153, 159], [160, 163], [164, 172], [173, 175], [176, 183], [184, 192], [193, 203], [203, 204]]}
{"doc_key": "ai-dev-300", "ner": [[0, 6, "algorithm"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Collaborative", "filtering", "(", "CF", ")", "is", "a", "technique", "used", "by", "recommender", "systems", "."], "sentence-detokenized": "Collaborative filtering (CF) is a technique used by recommender systems.", "token2charspan": [[0, 13], [14, 23], [24, 25], [25, 27], [27, 28], [29, 31], [32, 33], [34, 43], [44, 48], [49, 51], [52, 63], [64, 71], [71, 72]]}
{"doc_key": "ai-dev-301", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "HAMIS", "positive", "rate", "is", "the", "ratio", "of", "positive", "test", "results", "to", "all", "negative", "results", ",", "i.e.", "the", "conditional", "probability", "of", "a", "positive", "test", "result", "for", "an", "event", "that", "was", "not", "present", "."], "sentence-detokenized": "The HAMIS positive rate is the ratio of positive test results to all negative results, i.e. the conditional probability of a positive test result for an event that was not present.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 23], [24, 26], [27, 30], [31, 36], [37, 39], [40, 48], [49, 53], [54, 61], [62, 64], [65, 68], [69, 77], [78, 85], [85, 86], [87, 91], [92, 95], [96, 107], [108, 119], [120, 122], [123, 124], [125, 133], [134, 138], [139, 145], [146, 149], [150, 152], [153, 158], [159, 163], [164, 167], [168, 171], [172, 179], [179, 180]]}
{"doc_key": "ai-dev-302", "ner": [[1, 15, "misc"], [34, 34, "metrics"], [38, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 15, 34, 34, "topic", "", false, false], [1, 15, 38, 38, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "VLDB", "'", "8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pages", "422--433", ".", "showed", "that", "mathC", "/", "math", "and", "mathK", "/", "math", "values", "are", "generally", "relatively", "low", "precision", "for", "iteratively", "computed", "SimRank", "scores", "."], "sentence-detokenized": "In VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, pages 422--433. showed that mathC/math and mathK/math values are generally relatively low precision for iteratively computed SimRank scores.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [10, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 79], [80, 85], [85, 86], [87, 92], [93, 101], [101, 102], [103, 109], [110, 114], [115, 120], [120, 121], [121, 125], [126, 129], [130, 135], [135, 136], [136, 140], [141, 147], [148, 151], [152, 161], [162, 172], [173, 176], [177, 186], [187, 190], [191, 202], [203, 211], [212, 219], [220, 226], [226, 227]]}
{"doc_key": "ai-dev-303", "ner": [[5, 9, "misc"], [9, 9, "misc"], [15, 16, "person"], [18, 20, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 5, 9, "general-affiliation", "", false, false], [9, 9, 15, 16, "artifact", "", false, false], [9, 9, 18, 20, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "June", "2015", ",", "the", "sci", "-", "fi", "drama", "Sense8", ",", "written", "and", "produced", "by", "the", "Wachowskis", "and", "J.", "Michael", "Straczynski", ",", "debuted", "."], "sentence-detokenized": "In June 2015, the sci-fi drama Sense8, written and produced by the Wachowskis and J. Michael Straczynski, debuted.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 21], [21, 22], [22, 24], [25, 30], [31, 37], [37, 38], [39, 46], [47, 50], [51, 59], [60, 62], [63, 66], [67, 77], [78, 81], [82, 84], [85, 92], [93, 104], [104, 105], [106, 113], [113, 114]]}
{"doc_key": "ai-dev-304", "ner": [[1, 1, "misc"], [7, 8, "product"], [26, 28, "misc"], [36, 36, "country"], [38, 38, "country"], [40, 40, "country"], [42, 42, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 1, 7, 8, "topic", "", false, false], [36, 36, 26, 28, "type-of", "", false, false], [38, 38, 26, 28, "type-of", "", false, false], [40, 40, 26, 28, "type-of", "", false, false], [42, 42, 26, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Although", "Eurotra", "has", "never", "delivered", "a", "working", "MT", "system", ",", "the", "project", "has", "had", "a", "major", "long", "-", "term", "impact", "on", "the", "nascent", "language", "industry", "in", "European", "Member", "States", ",", "especially", "in", "the", "southern", "countries", "of", "Greece", ",", "Italy", ",", "Spain", "and", "Portugal", "."], "sentence-detokenized": "Although Eurotra has never delivered a working MT system, the project has had a major long-term impact on the nascent language industry in European Member States, especially in the southern countries of Greece, Italy, Spain and Portugal.", "token2charspan": [[0, 8], [9, 16], [17, 20], [21, 26], [27, 36], [37, 38], [39, 46], [47, 49], [50, 56], [56, 57], [58, 61], [62, 69], [70, 73], [74, 77], [78, 79], [80, 85], [86, 90], [90, 91], [91, 95], [96, 102], [103, 105], [106, 109], [110, 117], [118, 126], [127, 135], [136, 138], [139, 147], [148, 154], [155, 161], [161, 162], [163, 173], [174, 176], [177, 180], [181, 189], [190, 199], [200, 202], [203, 209], [209, 210], [211, 216], [216, 217], [218, 223], [224, 227], [228, 236], [236, 237]]}
{"doc_key": "ai-dev-305", "ner": [[0, 1, "algorithm"], [6, 11, "task"], [17, 21, "task"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[6, 11, 0, 1, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Automatic", "coding", "has", "been", "successfully", "applied", "to", "machine", "translation", "of", "human", "languages", ",", "commonly", "referred", "to", "as", "neural", "machine", "translation", "(", "NMT", ")", "."], "sentence-detokenized": "Automatic coding has been successfully applied to machine translation of human languages, commonly referred to as neural machine translation (NMT).", "token2charspan": [[0, 9], [10, 16], [17, 20], [21, 25], [26, 38], [39, 46], [47, 49], [50, 57], [58, 69], [70, 72], [73, 78], [79, 88], [88, 89], [90, 98], [99, 107], [108, 110], [111, 113], [114, 120], [121, 128], [129, 140], [141, 142], [142, 145], [145, 146], [146, 147]]}
{"doc_key": "ai-dev-306", "ner": [[9, 11, "metrics"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "examples", "of", "probability", "-", "based", "fitness", "functions", "include", "maximum", "likelihood", "estimation", "and", "hinge", "loss", "."], "sentence-detokenized": "Popular examples of probability-based fitness functions include maximum likelihood estimation and hinge loss.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 31], [31, 32], [32, 37], [38, 45], [46, 55], [56, 63], [64, 71], [72, 82], [83, 93], [94, 97], [98, 103], [104, 108], [108, 109]]}
{"doc_key": "ai-dev-307", "ner": [[0, 1, "field"], [9, 11, "task"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 11, 0, 1, "part-of", "", false, false], [13, 14, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "mining", "is", "a", "related", "discipline", "that", "focuses", "on", "exploratory", "data", "analysis", "through", "unsupervised", "learning", "."], "sentence-detokenized": "Data mining is a related discipline that focuses on exploratory data analysis through unsupervised learning.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 16], [17, 24], [25, 35], [36, 40], [41, 48], [49, 51], [52, 63], [64, 68], [69, 77], [78, 85], [86, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-dev-308", "ner": [[0, 2, "algorithm"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 15, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "involves", "techniques", "that", "pair", "people", "with", "similar", "interests", "and", "use", "them", "to", "create", "a", "recommendation", "system", "."], "sentence-detokenized": "Collaborative filtering involves techniques that pair people with similar interests and use them to create a recommendation system.", "token2charspan": [[0, 13], [14, 23], [24, 32], [33, 43], [44, 48], [49, 53], [54, 60], [61, 65], [66, 73], [74, 83], [84, 87], [88, 91], [92, 96], [97, 99], [100, 106], [107, 108], [109, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-dev-309", "ner": [[0, 13, "algorithm"], [2, 3, "product"]], "ner_mapping_to_source": [0, 2], "relations": [[2, 3, 0, 13, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["On", "WordNet", "::", "Similarity", ",", "a", "number", "of", "WordNet", "-", "based", "word", "similarity", "algorithms", "are", "implemented", "in", "the", "Perl", "package", "."], "sentence-detokenized": "On WordNet:: Similarity, a number of WordNet-based word similarity algorithms are implemented in the Perl package.", "token2charspan": [[0, 2], [3, 10], [10, 12], [13, 23], [23, 24], [25, 26], [27, 33], [34, 36], [37, 44], [44, 45], [45, 50], [51, 55], [56, 66], [67, 77], [78, 81], [82, 93], [94, 96], [97, 100], [101, 105], [106, 113], [113, 114]]}
{"doc_key": "ai-dev-310", "ner": [[4, 6, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Another", "paper", "presented", "at", "CVPR", "(", "CVPR", ")", "2000", "by", "Erik", "Miller", ",", "Nicholas", "Matsakis", "and", "Paul", "Viola", "will", "be", "discussed", "."], "sentence-detokenized": "Another paper presented at CVPR (CVPR) 2000 by Erik Miller, Nicholas Matsakis and Paul Viola will be discussed.", "token2charspan": [[0, 7], [8, 13], [14, 23], [24, 26], [27, 31], [32, 33], [33, 37], [37, 38], [39, 43], [44, 46], [47, 51], [52, 58], [58, 59], [60, 68], [69, 77], [78, 81], [82, 86], [87, 92], [93, 97], [98, 100], [101, 110], [110, 111]]}
{"doc_key": "ai-dev-311", "ner": [[0, 1, "algorithm"], [9, 10, "misc"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 14, 15, "compare", "", false, false], [14, 15, 9, 10, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "QC", "has", "not", "been", "evaluated", "against", "traditional", "modern", "clustering", "algorithms", "other", "than", "the", "Jaccard", "index", "."], "sentence-detokenized": "The QC has not been evaluated against traditional modern clustering algorithms other than the Jaccard index.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 14], [15, 19], [20, 29], [30, 37], [38, 49], [50, 56], [57, 67], [68, 78], [79, 84], [85, 89], [90, 93], [94, 101], [102, 107], [107, 108]]}
{"doc_key": "ai-dev-312", "ner": [[2, 7, "misc"], [8, 18, "misc"], [15, 16, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 18, 2, 7, "physical", "", false, false], [8, 18, 15, 16, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "the", "VEX", "Robotics", "World", "Championships", ",", "the", "Parade", "of", "Nations", "will", "take", "place", "in", "Freedom", "Hall", ",", "with", "hundreds", "of", "students", "from", "more", "than", "30", "countries", "."], "sentence-detokenized": "During the VEX Robotics World Championships, the Parade of Nations will take place in Freedom Hall, with hundreds of students from more than 30 countries.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 23], [24, 29], [30, 43], [43, 44], [45, 48], [49, 55], [56, 58], [59, 66], [67, 71], [72, 76], [77, 82], [83, 85], [86, 93], [94, 98], [98, 99], [100, 104], [105, 113], [114, 116], [117, 125], [126, 130], [131, 135], [136, 140], [141, 143], [144, 153], [153, 154]]}
{"doc_key": "ai-dev-313", "ner": [[6, 8, "metrics"], [5, 10, "metrics"], [14, 15, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 10, 6, 8, "named", "", false, false], [17, 17, 14, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Other", "measures", "of", "accuracy", "include", "single", "word", "error", "rate", "(", "SWER", ")", "and", "command", "success", "rate", "(", "CSR", ")", "."], "sentence-detokenized": "Other measures of accuracy include single word error rate (SWER) and command success rate (CSR).", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [27, 34], [35, 41], [42, 46], [47, 52], [53, 57], [58, 59], [59, 63], [63, 64], [65, 68], [69, 76], [77, 84], [85, 89], [90, 91], [91, 94], [94, 95], [95, 96]]}
{"doc_key": "ai-dev-314", "ner": [[7, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Their", "methodology", "and", "results", "were", "presented", "at", "SIGGRAPH", "2000", "."], "sentence-detokenized": "Their methodology and results were presented at SIGGRAPH 2000.", "token2charspan": [[0, 5], [6, 17], [18, 21], [22, 29], [30, 34], [35, 44], [45, 47], [48, 56], [57, 61], [61, 62]]}
{"doc_key": "ai-dev-315", "ner": [[1, 2, "conference"], [7, 7, "misc"], [9, 13, "misc"], [17, 19, "conference"], [23, 28, "researcher"], [37, 38, "researcher"], [42, 44, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 2, 7, 7, "origin", "", false, false], [7, 7, 17, 19, "physical", "", false, false], [7, 7, 17, 19, "temporal", "", false, false], [7, 7, 23, 28, "origin", "", false, false], [7, 7, 37, 38, "origin", "", false, false], [9, 13, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "KDD", "conference", "grew", "out", "of", "the", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "workshops", "of", "the", "AAAI", "conferences", ",", "started", "by", "Gregory", "I", ".", "Piatetsky", "-", "Shapiro", "in", "1989", ",", "1991", "and", "1993", ",", "and", "Usama", "Fayyad", "in", "1994", ".", "Machines", "|", "ACM", "."], "sentence-detokenized": "The KDD conference grew out of the KDD (Knowledge Discovery and Data Mining) workshops of the AAAI conferences, started by Gregory I. Piatetsky-Shapiro in 1989, 1991 and 1993, and Usama Fayyad in 1994. Machines | ACM.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 23], [24, 27], [28, 30], [31, 34], [35, 38], [39, 40], [40, 49], [50, 59], [60, 63], [64, 68], [69, 75], [75, 76], [77, 86], [87, 89], [90, 93], [94, 98], [99, 110], [110, 111], [112, 119], [120, 122], [123, 130], [131, 132], [132, 133], [134, 143], [143, 144], [144, 151], [152, 154], [155, 159], [159, 160], [161, 165], [166, 169], [170, 174], [174, 175], [176, 179], [180, 185], [186, 192], [193, 195], [196, 200], [200, 201], [202, 210], [211, 212], [213, 216], [216, 217]]}
{"doc_key": "ai-dev-316", "ner": [[7, 11, "conference"], [13, 13, "conference"], [19, 22, "organisation"], [17, 24, "organisation"], [31, 32, "conference"], [28, 34, "conference"], [38, 44, "conference"], [46, 46, "conference"], [53, 55, "conference"], [57, 57, "conference"], [63, 66, "conference"], [68, 68, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[13, 13, 7, 11, "named", "", false, false], [17, 24, 19, 22, "named", "", false, false], [28, 34, 31, 32, "named", "", false, false], [46, 46, 38, 44, "named", "", false, false], [57, 57, 53, 55, "named", "", false, false], [68, 68, 63, 66, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "has", "been", "elected", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "the", "American", "Association", "for", "Advancement", "of", "Science", "(", "AAAS", ")", "and", "the", "Society", "for", "Optics", "and", "Photonics", "Technology", "(", "SPIE", ")", "."], "sentence-detokenized": "He has been elected a Fellow of the Association for Computing Machinery (ACM), the Institute of Electrical and Electronics Engineers (IEEE), the International Association for Pattern Recognition (IAPR), the Association for the Advancement of Artificial Intelligence (AAAI), the American Association for Advancement of Science (AAAS) and the Society for Optics and Photonics Technology (SPIE).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 21], [22, 28], [29, 31], [32, 35], [36, 47], [48, 51], [52, 61], [62, 71], [72, 73], [73, 76], [76, 77], [77, 78], [79, 82], [83, 92], [93, 95], [96, 106], [107, 110], [111, 122], [123, 132], [133, 134], [134, 138], [138, 139], [139, 140], [141, 144], [145, 158], [159, 170], [171, 174], [175, 182], [183, 194], [195, 196], [196, 200], [200, 201], [201, 202], [203, 206], [207, 218], [219, 222], [223, 226], [227, 238], [239, 241], [242, 252], [253, 265], [266, 267], [267, 271], [271, 272], [272, 273], [274, 277], [278, 286], [287, 298], [299, 302], [303, 314], [315, 317], [318, 325], [326, 327], [327, 331], [331, 332], [333, 336], [337, 340], [341, 348], [349, 352], [353, 359], [360, 363], [364, 373], [374, 384], [385, 386], [386, 390], [390, 391], [391, 392]]}
{"doc_key": "ai-dev-317", "ner": [[0, 1, "field"], [3, 4, "field"], [16, 17, "field"], [29, 30, "field"], [49, 52, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 17, "named", "", false, false], [3, 4, 29, 30, "named", "", false, false], [29, 30, 49, 52, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "and", "data", "mining", "often", "use", "the", "same", "methods", "and", "overlap", "significantly", ",", "but", "while", "machine", "learning", "focuses", "on", "predicting", "from", "known", "features", "learned", "from", "training", "data", ",", "data", "mining", "focuses", "on", "discovering", "(", "previously", ")", "unknown", "features", "of", "the", "data", "(", "this", "is", "the", "analytical", "step", "of", "knowledge", "discovery", "in", "databases", ")", "."], "sentence-detokenized": "Machine learning and data mining often use the same methods and overlap significantly, but while machine learning focuses on predicting from known features learned from training data, data mining focuses on discovering (previously) unknown features of the data (this is the analytical step of knowledge discovery in databases).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 59], [60, 63], [64, 71], [72, 85], [85, 86], [87, 90], [91, 96], [97, 104], [105, 113], [114, 121], [122, 124], [125, 135], [136, 140], [141, 146], [147, 155], [156, 163], [164, 168], [169, 177], [178, 182], [182, 183], [184, 188], [189, 195], [196, 203], [204, 206], [207, 218], [219, 220], [220, 230], [230, 231], [232, 239], [240, 248], [249, 251], [252, 255], [256, 260], [261, 262], [262, 266], [267, 269], [270, 273], [274, 284], [285, 289], [290, 292], [293, 302], [303, 312], [313, 315], [316, 325], [325, 326], [326, 327]]}
{"doc_key": "ai-dev-318", "ner": [[0, 1, "product"], [4, 4, "programlang"], [12, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 4, 4, "general-affiliation", "", false, false], [0, 1, 4, 4, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "is", "written", "in", "Java", ",", "so", "it", "runs", "on", "most", "modern", "operating", "systems", "."], "sentence-detokenized": "Indy is written in Java, so it runs on most modern operating systems.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 23], [23, 24], [25, 27], [28, 30], [31, 35], [36, 38], [39, 43], [44, 50], [51, 60], [61, 68], [68, 69]]}
{"doc_key": "ai-dev-319", "ner": [[0, 1, "algorithm"], [7, 7, "algorithm"], [6, 10, "algorithm"], [16, 17, "algorithm"], [18, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 7, 7, "type-of", "", true, false], [6, 10, 7, 7, "named", "", false, false], [16, 17, 7, 7, "type-of", "", true, false], [18, 20, 16, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "NMF", "is", "an", "instance", "of", "non-negative", "quadratic", "programming", "(", "NQP", ")", ",", "as", "is", "the", "support", "vector", "machine", "(", "SVM", ")", "."], "sentence-detokenized": "The NMF is an instance of non-negative quadratic programming (NQP), as is the support vector machine (SVM).", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 13], [14, 22], [23, 25], [26, 38], [39, 48], [49, 60], [61, 62], [62, 65], [65, 66], [66, 67], [68, 70], [71, 73], [74, 77], [78, 85], [86, 92], [93, 100], [101, 102], [102, 105], [105, 106], [106, 107]]}
{"doc_key": "ai-dev-320", "ner": [[8, 9, "misc"], [12, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 12, 14, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "method", "is", "based", "on", "the", "estimation", "of", "conditional", "probabilities", "using", "the", "non-parametric", "maximum", "likelihood", "method", ",", "which", "leads", "to"], "sentence-detokenized": "The method is based on the estimation of conditional probabilities using the non-parametric maximum likelihood method, which leads to", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 26], [27, 37], [38, 40], [41, 52], [53, 66], [67, 72], [73, 76], [77, 91], [92, 99], [100, 110], [111, 117], [117, 118], [119, 124], [125, 130], [131, 133]]}
{"doc_key": "ai-dev-321", "ner": [[7, 7, "algorithm"], [9, 11, "algorithm"], [13, 15, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "basic", "concepts", "of", "spectral", "estimation", "include", "autocorrelation", ",", "multivariate", "Fourier", "transform", ",", "mean", "squared", "error", "and", "entropy", "."], "sentence-detokenized": "The basic concepts of spectral estimation include autocorrelation, multivariate Fourier transform, mean squared error and entropy.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 21], [22, 30], [31, 41], [42, 49], [50, 65], [65, 66], [67, 79], [80, 87], [88, 97], [97, 98], [99, 103], [104, 111], [112, 117], [118, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-dev-322", "ner": [[3, 5, "algorithm"], [9, 9, "field"], [11, 11, "algorithm"], [13, 15, "algorithm"], [17, 18, "task"], [20, 20, "field"], [22, 22, "field"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 5, 9, 9, "part-of", "", false, false], [3, 5, 11, 11, "part-of", "", false, false], [3, 5, 13, 15, "part-of", "", false, false], [3, 5, 17, 18, "part-of", "", false, false], [3, 5, 20, 20, "part-of", "", false, false], [3, 5, 22, 22, "part-of", "", false, false], [3, 5, 24, 25, "part-of", "", false, false], [3, 5, 27, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "applications", "of", "kernel", "methods", "are", "diverse", ",", "including", "geostatistics", ",", "kriging", ",", "inverse", "distance", "weighting", ",", "3D", "reconstruction", ",", "bioinformatics", ",", "chemoinformatics", ",", "information", "extraction", "and", "handwriting", "recognition", "."], "sentence-detokenized": "The applications of kernel methods are diverse, including geostatistics, kriging, inverse distance weighting, 3D reconstruction, bioinformatics, chemoinformatics, information extraction and handwriting recognition.", "token2charspan": [[0, 3], [4, 16], [17, 19], [20, 26], [27, 34], [35, 38], [39, 46], [46, 47], [48, 57], [58, 71], [71, 72], [73, 80], [80, 81], [82, 89], [90, 98], [99, 108], [108, 109], [110, 112], [113, 127], [127, 128], [129, 143], [143, 144], [145, 161], [161, 162], [163, 174], [175, 185], [186, 189], [190, 201], [202, 213], [213, 214]]}
{"doc_key": "ai-dev-323", "ner": [[16, 17, "organisation"], [18, 21, "product"], [19, 23, "product"], [27, 27, "organisation"], [28, 32, "product"], [34, 37, "product"], [38, 39, "product"], [42, 44, "product"], [46, 48, "product"], [50, 52, "product"], [56, 57, "product"], [59, 60, "product"], [62, 68, "product"], [72, 73, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[18, 21, 16, 17, "artifact", "", false, false], [18, 21, 38, 39, "compare", "", false, false], [18, 21, 42, 44, "compare", "", false, false], [18, 21, 46, 48, "compare", "", false, false], [18, 21, 50, 52, "compare", "", false, false], [18, 21, 56, 57, "compare", "", false, false], [18, 21, 59, 60, "compare", "", false, false], [18, 21, 62, 68, "compare", "", false, false], [18, 21, 72, 73, "compare", "", false, false], [19, 23, 18, 21, "named", "", false, false], [28, 32, 27, 27, "artifact", "", false, false], [28, 32, 38, 39, "compare", "", false, false], [28, 32, 42, 44, "compare", "", false, false], [28, 32, 46, 48, "compare", "", false, false], [28, 32, 50, 52, "compare", "", false, false], [28, 32, 56, 57, "compare", "", false, false], [28, 32, 59, 60, "compare", "", false, false], [28, 32, 62, 68, "compare", "", false, false], [28, 32, 72, 73, "compare", "", false, false], [34, 37, 28, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["The", "robots", "can", "be", "autonomous", "or", "semi-autonomous", ",", "and", "range", "from", "humanoids", ",", "such", "as", "the", "Honda", "Advanced", "Step", "in", "Innovative", "Mobility", "(", "ASIMO", ")", "and", "the", "TOSY", "TOSY", "Ping", "Pong", "Playing", "Robot", "(", "TOPIO", ")", ",", "to", "industrial", "robots", ",", "to", "medical", "operating", "robots", ",", "patient", "care", "robots", ",", "dog", "therapy", "robots", ",", "collectively", "programmed", "robot", "swarms", ",", "UAV", "drones", "like", "the", "General", "Atomics", "MQ", "-", "1", "Predator", ",", "and", "even", "microscopic", "nanorobots", "."], "sentence-detokenized": "The robots can be autonomous or semi-autonomous, and range from humanoids, such as the Honda Advanced Step in Innovative Mobility (ASIMO) and the TOSY TOSY Ping Pong Playing Robot (TOPIO), to industrial robots, to medical operating robots, patient care robots, dog therapy robots, collectively programmed robot swarms, UAV drones like the General Atomics MQ-1 Predator, and even microscopic nanorobots.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 17], [18, 28], [29, 31], [32, 47], [47, 48], [49, 52], [53, 58], [59, 63], [64, 73], [73, 74], [75, 79], [80, 82], [83, 86], [87, 92], [93, 101], [102, 106], [107, 109], [110, 120], [121, 129], [130, 131], [131, 136], [136, 137], [138, 141], [142, 145], [146, 150], [151, 155], [156, 160], [161, 165], [166, 173], [174, 179], [180, 181], [181, 186], [186, 187], [187, 188], [189, 191], [192, 202], [203, 209], [209, 210], [211, 213], [214, 221], [222, 231], [232, 238], [238, 239], [240, 247], [248, 252], [253, 259], [259, 260], [261, 264], [265, 272], [273, 279], [279, 280], [281, 293], [294, 304], [305, 310], [311, 317], [317, 318], [319, 322], [323, 329], [330, 334], [335, 338], [339, 346], [347, 354], [355, 357], [357, 358], [358, 359], [360, 368], [368, 369], [370, 373], [374, 378], [379, 390], [391, 401], [401, 402]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 3, "product"], [19, 29, "university"], [8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 8, 9, "artifact", "", false, false], [0, 0, 11, 12, "artifact", "", false, false], [0, 0, 14, 15, "artifact", "", false, false], [0, 0, 17, 18, "artifact", "", false, false], [2, 3, 8, 9, "artifact", "", false, false], [2, 3, 11, 12, "artifact", "", false, false], [2, 3, 14, 15, "artifact", "", false, false], [2, 3, 17, 18, "artifact", "", false, false], [8, 9, 19, 29, "physical", "", false, false], [11, 12, 19, 29, "physical", "", false, false], [14, 15, 19, 29, "physical", "", false, false], [17, 18, 19, 29, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "and", "Freddy", "II", "were", "robots", "built", "by", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "and", "Donald", "Mitchie", "at", "the", "University", "of", "Edinburgh", "'s", "School", "of", "Computing", ",", "which", "could", "assemble", "wooden", "blocks", "in", "hours", "."], "sentence-detokenized": "Freddy and Freddy II were robots built by Pat Ambler, Robin Popplestone, Austin Tate and Donald Mitchie at the University of Edinburgh's School of Computing, which could assemble wooden blocks in hours.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 25], [26, 32], [33, 38], [39, 41], [42, 45], [46, 52], [52, 53], [54, 59], [60, 71], [71, 72], [73, 79], [80, 84], [85, 88], [89, 95], [96, 103], [104, 106], [107, 110], [111, 121], [122, 124], [125, 134], [134, 136], [137, 143], [144, 146], [147, 156], [156, 157], [158, 163], [164, 169], [170, 178], [179, 185], [186, 192], [193, 195], [196, 201], [201, 202]]}
{"doc_key": "ai-dev-325", "ner": [[5, 5, "location"], [6, 7, "country"], [14, 17, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 6, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "spent", "his", "childhood", "in", "Paris", ",", "France", ",", "where", "his", "parents", "had", "emigrated", "from", "Lithuania", "in", "the", "early", "1920s", "."], "sentence-detokenized": "He spent his childhood in Paris, France, where his parents had emigrated from Lithuania in the early 1920s.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 22], [23, 25], [26, 31], [31, 32], [33, 39], [39, 40], [41, 46], [47, 50], [51, 58], [59, 62], [63, 72], [73, 77], [78, 87], [88, 90], [91, 94], [95, 100], [101, 106], [106, 107]]}
{"doc_key": "ai-dev-326", "ner": [[2, 3, "researcher"], [6, 10, "misc"], [14, 20, "organisation"], [11, 13, "university"], [28, 33, "university"], [41, 42, "university"], [45, 48, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 3, 6, 10, "role", "", false, false], [2, 3, 11, 13, "physical", "", false, false], [2, 3, 28, 33, "role", "", false, false], [2, 3, 41, 42, "role", "", false, false], [2, 3, 45, 48, "role", "", false, false], [6, 10, 14, 20, "part-of", "", false, false], [14, 20, 11, 13, "part-of", "", false, false], [41, 42, 28, 33, "part-of", "", false, false], [45, 48, 28, 33, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Previously", ",", "Dr.", "Paulos", "was", "the", "Cooper-", "Siegel", "Associate", "Professor", "at", "Carnegie", "Mellon", "University", "'s", "School", "of", "Computer", "Science", ",", "where", "he", "was", "a", "faculty", "member", "in", "the", "Institute", "for", "Human", "-", "Computer", "Interaction", ",", "and", "a", "faculty", "member", "in", "the", "Robotics", "Institute", "and", "the", "Center", "for", "Entertainment", "Technology", "."], "sentence-detokenized": "Previously, Dr. Paulos was the Cooper-Siegel Associate Professor at Carnegie Mellon University's School of Computer Science, where he was a faculty member in the Institute for Human-Computer Interaction, and a faculty member in the Robotics Institute and the Center for Entertainment Technology.", "token2charspan": [[0, 10], [10, 11], [12, 15], [16, 22], [23, 26], [27, 30], [31, 38], [38, 44], [45, 54], [55, 64], [65, 67], [68, 76], [77, 83], [84, 94], [94, 96], [97, 103], [104, 106], [107, 115], [116, 123], [123, 124], [125, 130], [131, 133], [134, 137], [138, 139], [140, 147], [148, 154], [155, 157], [158, 161], [162, 171], [172, 175], [176, 181], [181, 182], [182, 190], [191, 202], [202, 203], [204, 207], [208, 209], [210, 217], [218, 224], [225, 227], [228, 231], [232, 240], [241, 250], [251, 254], [255, 258], [259, 265], [266, 269], [270, 283], [284, 294], [294, 295]]}
{"doc_key": "ai-dev-327", "ner": [[3, 4, "researcher"], [6, 7, "university"], [10, 11, "product"], [18, 22, "product"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 6, 7, "physical", "", false, false], [3, 4, 6, 7, "role", "", false, false], [10, 11, 3, 4, "artifact", "", false, false], [10, 11, 18, 22, "type-of", "", false, false], [10, 11, 26, 27, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1969", ",", "Victor", "Scheinman", "at", "Stanford", "University", "invented", "the", "Stanford", "arm", ",", "an", "all", "-", "electric", ",", "6", "-", "axis", "articulated", "robot", "designed", "to", "enable", "arm", "unlocking", "."], "sentence-detokenized": "In 1969, Victor Scheinman at Stanford University invented the Stanford arm, an all-electric, 6-axis articulated robot designed to enable arm unlocking.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 25], [26, 28], [29, 37], [38, 48], [49, 57], [58, 61], [62, 70], [71, 74], [74, 75], [76, 78], [79, 82], [82, 83], [83, 91], [91, 92], [93, 94], [94, 95], [95, 99], [100, 111], [112, 117], [118, 126], [127, 129], [130, 136], [137, 140], [141, 150], [150, 151]]}
{"doc_key": "ai-dev-328", "ner": [[5, 8, "product"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 8, 15, 16, "related-to", "", false, false], [5, 8, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "creation", "and", "implementation", "of", "chatbots", "is", "still", "an", "evolving", "field", ",", "strongly", "linked", "to", "artificial", "intelligence", "and", "machine", "learning", ",", "so", "the", "solutions", "offered", ",", "while", "having", "obvious", "advantages", ",", "have", "significant", "limitations", "in", "terms", "of", "functionality", "and", "use", "cases", "."], "sentence-detokenized": "The creation and implementation of chatbots is still an evolving field, strongly linked to artificial intelligence and machine learning, so the solutions offered, while having obvious advantages, have significant limitations in terms of functionality and use cases.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 31], [32, 34], [35, 43], [44, 46], [47, 52], [53, 55], [56, 64], [65, 70], [70, 71], [72, 80], [81, 87], [88, 90], [91, 101], [102, 114], [115, 118], [119, 126], [127, 135], [135, 136], [137, 139], [140, 143], [144, 153], [154, 161], [161, 162], [163, 168], [169, 175], [176, 183], [184, 194], [194, 195], [196, 200], [201, 212], [213, 224], [225, 227], [228, 233], [234, 236], [237, 250], [251, 254], [255, 258], [259, 264], [264, 265]]}
{"doc_key": "ai-dev-329", "ner": [[6, 9, "university"], [10, 11, "product"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 6, 9, "part-of", "", true, false], [23, 24, 10, 11, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Among", "the", "freely", "available", "resources", ",", "Carnegie", "Mellon", "University", "'s", "Sphinx", "toolkit", "is", "one", "of", "the", "starting", "points", "for", "learning", "and", "experimenting", "with", "speech", "recognition", "."], "sentence-detokenized": "Among the freely available resources, Carnegie Mellon University's Sphinx toolkit is one of the starting points for learning and experimenting with speech recognition.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 26], [27, 36], [36, 37], [38, 46], [47, 53], [54, 64], [64, 66], [67, 73], [74, 81], [82, 84], [85, 88], [89, 91], [92, 95], [96, 104], [105, 111], [112, 115], [116, 124], [125, 128], [129, 142], [143, 147], [148, 154], [155, 166], [166, 167]]}
{"doc_key": "ai-dev-330", "ner": [[2, 4, "misc"], [15, 19, "misc"], [14, 21, "misc"], [26, 27, "university"], [28, 28, "location"], [29, 30, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 4, 15, 19, "temporal", "", false, false], [14, 21, 15, 19, "named", "", false, false], [14, 21, 28, 28, "physical", "", false, false], [26, 27, 14, 21, "role", "", false, false], [28, 28, 29, 30, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "official", "RoboCup", "competition", "was", "preceded", "by", "the", "(", "often", "unrecognised", ")", "first", "International", "Micro", "Robot", "World", "Cup", "Football", "Tournament", "(", "MIROSOT", ")", ",", "organised", "by", "KAIST", "in", "Taejon", ",", "Korea", ",", "in", "November", "1996", "."], "sentence-detokenized": "The official RoboCup competition was preceded by the (often unrecognised) first International Micro Robot World Cup Football Tournament (MIROSOT), organised by KAIST in Taejon, Korea, in November 1996.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 32], [33, 36], [37, 45], [46, 48], [49, 52], [53, 54], [54, 59], [60, 72], [72, 73], [74, 79], [80, 93], [94, 99], [100, 105], [106, 111], [112, 115], [116, 124], [125, 135], [136, 137], [137, 144], [144, 145], [145, 146], [147, 156], [157, 159], [160, 165], [166, 168], [169, 175], [175, 176], [177, 182], [182, 183], [184, 186], [187, 195], [196, 200], [200, 201]]}
{"doc_key": "ai-dev-331", "ner": [[5, 6, "metrics"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "standard", "wrist", "loss", "math", "(", "1-", "yf", "(", "x", ")", ")", "_", "+", "/", "math", "for", "labeled", "data", ",", "a", "loss", "function", "math", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "math", "for", "unlabeled", "data", "is", "also", "introduced", "using", "the", "mathy", "=\\", "operator", "called", "{", "sign", "}", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "In addition to the standard wrist loss math (1-yf (x)) _ + / math for labeled data, a loss function math (-1 | f (x) |) _ + / math for unlabeled data is also introduced using the mathy =\\ operator called {sign} {f (x)} / math.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 27], [28, 33], [34, 38], [39, 43], [44, 45], [45, 47], [47, 49], [50, 51], [51, 52], [52, 53], [53, 54], [55, 56], [57, 58], [59, 60], [61, 65], [66, 69], [70, 77], [78, 82], [82, 83], [84, 85], [86, 90], [91, 99], [100, 104], [105, 106], [106, 107], [107, 108], [109, 110], [111, 112], [113, 114], [114, 115], [115, 116], [117, 118], [118, 119], [120, 121], [122, 123], [124, 125], [126, 130], [131, 134], [135, 144], [145, 149], [150, 152], [153, 157], [158, 168], [169, 174], [175, 178], [179, 184], [185, 187], [188, 196], [197, 203], [204, 205], [205, 209], [209, 210], [211, 212], [212, 213], [214, 215], [215, 216], [216, 217], [217, 218], [219, 220], [221, 225], [225, 226]]}
{"doc_key": "ai-dev-332", "ner": [[0, 2, "misc"], [7, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 7, 9, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "RLS", "is", "designed", "to", "minimize", "the", "mean", "squared", "error", "between", "the", "predicted", "values", "and", "the", "TRUE", "labels", ",", "according", "to", "the", "regularization", "."], "sentence-detokenized": "The RLS is designed to minimize the mean squared error between the predicted values and the TRUE labels, according to the regularization.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 19], [20, 22], [23, 31], [32, 35], [36, 40], [41, 48], [49, 54], [55, 62], [63, 66], [67, 76], [77, 83], [84, 87], [88, 91], [92, 96], [97, 103], [103, 104], [105, 114], [115, 117], [118, 121], [122, 136], [136, 137]]}
{"doc_key": "ai-dev-333", "ner": [[3, 5, "algorithm"], [8, 10, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 5, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "essentially", "combines", "maximum", "likelihood", "estimation", "with", "a", "regularisation", "procedure", "that", "favours", "simpler", "models", "over", "more", "complex", "ones", "."], "sentence-detokenized": "This essentially combines maximum likelihood estimation with a regularisation procedure that favours simpler models over more complex ones.", "token2charspan": [[0, 4], [5, 16], [17, 25], [26, 33], [34, 44], [45, 55], [56, 60], [61, 62], [63, 77], [78, 87], [88, 92], [93, 100], [101, 108], [109, 115], [116, 120], [121, 125], [126, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-dev-334", "ner": [[1, 4, "metrics"], [8, 8, "metrics"], [10, 10, "metrics"], [15, 17, "misc"], [18, 22, "misc"], [26, 30, "algorithm"], [38, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[8, 8, 1, 4, "named", "", false, false], [10, 10, 1, 4, "named", "", false, false], [15, 17, 18, 22, "related-to", "", false, false], [15, 17, 26, 30, "related-to", "ratio", false, false], [26, 30, 38, 40, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "true", "-", "positive", "ratio", "(", "also", "called", "sensitivity", ",", "recall", ",", "or", "the", "mathematical", "probability", "of", "detection", "relative", "to", "the", "discrimination", "threshold", ")", "is", "the", "cumulative", "distribution", "function", "of", "the", "detection", "probability", "on", "the", "y-axis", "and", "the", "false", "alarm", "probability", "on", "the", "x-", "axis", "."], "sentence-detokenized": "The true-positive ratio (also called sensitivity, recall, or the mathematical probability of detection relative to the discrimination threshold) is the cumulative distribution function of the detection probability on the y-axis and the false alarm probability on the x-axis.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 17], [18, 23], [24, 25], [25, 29], [30, 36], [37, 48], [48, 49], [50, 56], [56, 57], [58, 60], [61, 64], [65, 77], [78, 89], [90, 92], [93, 102], [103, 111], [112, 114], [115, 118], [119, 133], [134, 143], [143, 144], [145, 147], [148, 151], [152, 162], [163, 175], [176, 184], [185, 187], [188, 191], [192, 201], [202, 213], [214, 216], [217, 220], [221, 227], [228, 231], [232, 235], [236, 241], [242, 247], [248, 259], [260, 262], [263, 266], [267, 269], [269, 273], [273, 274]]}
{"doc_key": "ai-dev-335", "ner": [[1, 1, "misc"], [3, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 1, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "English", ",", "Word", "Net", "is", "an", "example", "of", "a", "semantic", "network", "."], "sentence-detokenized": "In English, WordNet is an example of a semantic network.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [16, 19], [20, 22], [23, 25], [26, 33], [34, 36], [37, 38], [39, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-dev-336", "ner": [[5, 7, "product"], [12, 13, "product"], [29, 32, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[29, 32, 5, 7, "usage", "", false, false], [29, 32, 12, 13, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "-", "term", "use", "of", "speech", "recognition", "software", "in", "combination", "with", "a", "word", "processor", "has", "been", "shown", "to", "be", "beneficial", "for", "short", "-", "term", "memory", "consolidation", "in", "patients", "with", "AVM", "of", "the", "brain", "treated", "by", "resection", "."], "sentence-detokenized": "Long-term use of speech recognition software in combination with a word processor has been shown to be beneficial for short-term memory consolidation in patients with AVM of the brain treated by resection.", "token2charspan": [[0, 4], [4, 5], [5, 9], [10, 13], [14, 16], [17, 23], [24, 35], [36, 44], [45, 47], [48, 59], [60, 64], [65, 66], [67, 71], [72, 81], [82, 85], [86, 90], [91, 96], [97, 99], [100, 102], [103, 113], [114, 117], [118, 123], [123, 124], [124, 128], [129, 135], [136, 149], [150, 152], [153, 161], [162, 166], [167, 170], [171, 173], [174, 177], [178, 183], [184, 191], [192, 194], [195, 204], [204, 205]]}
{"doc_key": "ai-dev-337", "ner": [[8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "founding", "editors", "-", "in", "-", "chief", "were", "Ron", "Sun", ",", "Vasant", "Honavar", "and", "Gregg", "Oden", "(", "from", "1999", "to", "2014", ")", "."], "sentence-detokenized": "The founding editors-in-chief were Ron Sun, Vasant Honavar and Gregg Oden (from 1999 to 2014).", "token2charspan": [[0, 3], [4, 12], [13, 20], [20, 21], [21, 23], [23, 24], [24, 29], [30, 34], [35, 38], [39, 42], [42, 43], [44, 50], [51, 58], [59, 62], [63, 68], [69, 73], [74, 75], [75, 79], [80, 84], [85, 87], [88, 92], [92, 93], [93, 94]]}
{"doc_key": "ai-dev-338", "ner": [[0, 4, "product"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 14, 15, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "contrast", "to", "serial", "manipulators", ",", "their", "\"", "parallel", "\"", "distinction", "is", "that", "the", "end", "device", "(", "or", "\"", "hand", "\"", ")", "of", "the", "link", "(", "or", "\"", "arm", "\"", ")", "is", "directly", "connected", "to", "it", "s", "base", "by", "several", "(", "usually", "three", "or", "six", ")", "separate", "and", "independent", "links", "operating", "simultaneously", "."], "sentence-detokenized": "In contrast to serial manipulators, their \"parallel\" distinction is that the end device (or \"hand\") of the link (or \"arm\") is directly connected to its base by several (usually three or six) separate and independent links operating simultaneously.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 21], [22, 34], [34, 35], [36, 41], [42, 43], [43, 51], [51, 52], [53, 64], [65, 67], [68, 72], [73, 76], [77, 80], [81, 87], [88, 89], [89, 91], [92, 93], [93, 97], [97, 98], [98, 99], [100, 102], [103, 106], [107, 111], [112, 113], [113, 115], [116, 117], [117, 120], [120, 121], [121, 122], [123, 125], [126, 134], [135, 144], [145, 147], [148, 150], [150, 151], [152, 156], [157, 159], [160, 167], [168, 169], [169, 176], [177, 182], [183, 185], [186, 189], [189, 190], [191, 199], [200, 203], [204, 215], [216, 221], [222, 231], [232, 246], [246, 247]]}
{"doc_key": "ai-dev-339", "ner": [[5, 6, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [24, 25, "researcher"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "thesis", "advisor", "was", "Professor", "Cordell", "Green", ",", "and", "his", "thesis", "/", "oral", "committee", "included", "Edward", "Feigenbaum", ",", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", ",", "Herbert", "Simon", ",", "."], "sentence-detokenized": "His thesis advisor was Professor Cordell Green, and his thesis/oral committee included Edward Feigenbaum, Joshua Lederberg, Paul Cohen, Allen Newell, Herbert Simon,.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 22], [23, 32], [33, 40], [41, 46], [46, 47], [48, 51], [52, 55], [56, 62], [62, 63], [63, 67], [68, 77], [78, 86], [87, 93], [94, 104], [104, 105], [106, 112], [113, 122], [122, 123], [124, 128], [129, 134], [134, 135], [136, 141], [142, 148], [148, 149], [150, 157], [158, 163], [163, 164], [164, 165]]}
{"doc_key": "ai-dev-340", "ner": [[5, 7, "metrics"], [9, 12, "metrics"], [14, 16, "metrics"], [18, 20, "metrics"], [22, 25, "metrics"], [27, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Examples", "of", "such", "functions", "are", "mean", "squared", "error", ",", "root", "mean", "squared", "error", ",", "mean", "absolute", "error", ",", "relative", "squared", "error", ",", "root", "mean", "squared", "error", ",", "relative", "absolute", "error", "and", "others", "."], "sentence-detokenized": "Examples of such functions are mean squared error, root mean squared error, mean absolute error, relative squared error, root mean squared error, relative absolute error and others.", "token2charspan": [[0, 8], [9, 11], [12, 16], [17, 26], [27, 30], [31, 35], [36, 43], [44, 49], [49, 50], [51, 55], [56, 60], [61, 68], [69, 74], [74, 75], [76, 80], [81, 89], [90, 95], [95, 96], [97, 105], [106, 113], [114, 119], [119, 120], [121, 125], [126, 130], [131, 138], [139, 144], [144, 145], [146, 154], [155, 163], [164, 169], [170, 173], [174, 180], [180, 181]]}
{"doc_key": "ai-dev-341", "ner": [[2, 2, "programlang"], [4, 4, "programlang"], [6, 6, "product"], [8, 8, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "Python", ",", "Java", "and", "MATLAB", "/", "OCTAVE", "language", "bindings", "."], "sentence-detokenized": "There are Python, Java and MATLAB / OCTAVE language bindings.", "token2charspan": [[0, 5], [6, 9], [10, 16], [16, 17], [18, 22], [23, 26], [27, 33], [34, 35], [36, 42], [43, 51], [52, 60], [60, 61]]}
{"doc_key": "ai-dev-342", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "MATLAB", "implementation", "can", "be", "found", "at", "."], "sentence-detokenized": "The MATLAB implementation can be found at.", "token2charspan": [[0, 3], [4, 10], [11, 25], [26, 29], [30, 32], [33, 38], [39, 41], [41, 42]]}
{"doc_key": "ai-dev-343", "ner": [[0, 1, "researcher"], [9, 10, "field"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 10, 0, 1, "origin", "", false, false], [9, 10, 14, 15, "origin", "", false, false], [9, 10, 17, 18, "origin", "", false, false], [9, 10, 20, 21, "origin", "", false, false], [9, 10, 23, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "is", "one", "of", "the", "founding", "fathers", "of", "artificial", "intelligence", ",", "along", "with", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", "and", "Herbert", "A", ".", "Simon", "."], "sentence-detokenized": "John McCarthy is one of the founding fathers of artificial intelligence, along with Alan Turing, Marvin Minsky, Allen Newell and Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 36], [37, 44], [45, 47], [48, 58], [59, 71], [71, 72], [73, 78], [79, 83], [84, 88], [89, 95], [95, 96], [97, 103], [104, 110], [110, 111], [112, 117], [118, 124], [125, 128], [129, 136], [137, 138], [138, 139], [140, 145], [145, 146]]}
{"doc_key": "ai-dev-344", "ner": [[10, 13, "product"], [20, 21, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "parallel", "manipulator", "is", "a", "mechanical", "system", "that", "uses", "multiple", "in", "-", "line", "manipulators", "to", "support", "a", "single", "platform", "or", "end", "support", "."], "sentence-detokenized": "A parallel manipulator is a mechanical system that uses multiple in-line manipulators to support a single platform or end support.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 27], [28, 38], [39, 45], [46, 50], [51, 55], [56, 64], [65, 67], [67, 68], [68, 72], [73, 85], [86, 88], [89, 96], [97, 98], [99, 105], [106, 114], [115, 117], [118, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [3, 18, "task"], [7, 7, "product"], [9, 15, "product"], [22, 22, "misc"], [25, 25, "misc"], [28, 29, "misc"], [32, 37, "task"], [40, 43, "product"], [46, 47, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 7, 0, 0, "part-of", "", false, false], [7, 7, 3, 18, "type-of", "", false, false], [9, 15, 7, 7, "named", "", false, false], [22, 22, 7, 7, "part-of", "", false, false], [25, 25, 7, 7, "part-of", "", false, false], [28, 29, 7, 7, "part-of", "", false, false], [32, 37, 7, 7, "part-of", "", false, false], [40, 43, 7, 7, "part-of", "", false, false], [46, 47, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "includes", "an", "information", "extraction", "system", "called", "ANNIE", "(", "A", "Nearly", "-", "New", "Information", "Extraction", "System", ")", ",", "which", "consists", "of", "a", "tokenizer", ",", "a", "gazetteer", ",", "a", "sentence", "splitter", ",", "a", "part", "-", "of", "-", "speech", "tagger", ",", "a", "named", "entity", "recognition", "converter", "and", "a", "coreference", "tagger", "."], "sentence-detokenized": "GATE includes an information extraction system called ANNIE (A Nearly-New Information Extraction System), which consists of a tokenizer, a gazetteer, a sentence splitter, a part-of-speech tagger, a named entity recognition converter and a coreference tagger.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 28], [29, 39], [40, 46], [47, 53], [54, 59], [60, 61], [61, 62], [63, 69], [69, 70], [70, 73], [74, 85], [86, 96], [97, 103], [103, 104], [104, 105], [106, 111], [112, 120], [121, 123], [124, 125], [126, 135], [135, 136], [137, 138], [139, 148], [148, 149], [150, 151], [152, 160], [161, 169], [169, 170], [171, 172], [173, 177], [177, 178], [178, 180], [180, 181], [181, 187], [188, 194], [194, 195], [196, 197], [198, 203], [204, 210], [211, 222], [223, 232], [233, 236], [237, 238], [239, 250], [251, 257], [257, 258]]}
{"doc_key": "ai-dev-346", "ner": [[3, 7, "university"], [11, 13, "country"], [22, 25, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["After", "graduating", "from", "Moscow", "State", "University", ",", "he", "left", "for", "the", "United", "States", "in", "November", "1978", "thanks", "to", "the", "personal", "intervention", "of", "Senator", "Edward", "M.", "Kennedy", "."], "sentence-detokenized": "After graduating from Moscow State University, he left for the United States in November 1978 thanks to the personal intervention of Senator Edward M. Kennedy.", "token2charspan": [[0, 5], [6, 16], [17, 21], [22, 28], [29, 34], [35, 45], [45, 46], [47, 49], [50, 54], [55, 58], [59, 62], [63, 69], [70, 76], [77, 79], [80, 88], [89, 93], [94, 100], [101, 103], [104, 107], [108, 116], [117, 129], [130, 132], [133, 140], [141, 147], [148, 150], [151, 158], [158, 159]]}
{"doc_key": "ai-dev-347", "ner": [[3, 6, "organisation"], [9, 12, "misc"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 6, 9, 12, "win-defeat", "", false, false], [9, 12, 17, 17, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "DeepMind", "'s", "AlphaGo", "team", "received", "the", "IJCAI", "Marvin", "Minsky", "Medal", "for", "outstanding", "achievements", "in", "AI", "."], "sentence-detokenized": "In 2017, DeepMind's AlphaGo team received the IJCAI Marvin Minsky Medal for outstanding achievements in AI.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 17], [17, 19], [20, 27], [28, 32], [33, 41], [42, 45], [46, 51], [52, 58], [59, 65], [66, 71], [72, 75], [76, 87], [88, 100], [101, 103], [104, 106], [106, 107]]}
{"doc_key": "ai-dev-348", "ner": [[3, 4, "misc"], [6, 10, "misc"], [18, 20, "misc"], [25, 25, "misc"], [29, 31, "misc"]], "ner_mapping_to_source": [0, 1, 3, 4, 5], "relations": [[3, 4, 6, 10, "related-to", "is_recorded_by", false, false], [6, 10, 18, 20, "physical", "", false, false], [6, 10, 29, 31, "physical", "", false, false]], "relations_mapping_to_source": [0, 3, 4], "sentence": ["Other", "modes", "of", "anomalous", "propagation", "include", "tropospheric", "craters", "that", "cause", "tropospheric", "irregularities", ",", "scattering", "by", "meteors", ",", "refraction", "in", "ionised", "regions", "and", "layers", "of", "the", "ionosphere", ",", "and", "reflection", "from", "the", "ionosphere", "."], "sentence-detokenized": "Other modes of anomalous propagation include tropospheric craters that cause tropospheric irregularities, scattering by meteors, refraction in ionised regions and layers of the ionosphere, and reflection from the ionosphere.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 24], [25, 36], [37, 44], [45, 57], [58, 65], [66, 70], [71, 76], [77, 89], [90, 104], [104, 105], [106, 116], [117, 119], [120, 127], [127, 128], [129, 139], [140, 142], [143, 150], [151, 158], [159, 162], [163, 169], [170, 172], [173, 176], [177, 187], [187, 188], [189, 192], [193, 203], [204, 208], [209, 212], [213, 223], [223, 224]]}
{"doc_key": "ai-dev-349", "ner": [[0, 2, "field"], [4, 6, "field"], [10, 10, "field"], [12, 13, "field"], [15, 16, "field"], [18, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 10, 10, "part-of", "", false, false], [0, 2, 12, 13, "part-of", "", false, false], [0, 2, 15, 16, "part-of", "", false, false], [0, 2, 18, 20, "part-of", "", false, false], [4, 6, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Natural", "language", "processing", "(", "NLP", ")", "is", "a", "subfield", "of", "linguistics", ",", "computer", "science", ",", "information", "technology", "and", "artificial", "intelligence", "that", "deals", "with", "the", "interactions", "between", "computers", "and", "human", "(", "natural", ")", "languages", ",", "in", "particular", "how", "computers", "can", "be", "programmed", "to", "process", "and", "analyse", "large", "amounts", "of", "natural", "language", "data", "."], "sentence-detokenized": "Natural language processing (NLP) is a subfield of linguistics, computer science, information technology and artificial intelligence that deals with the interactions between computers and human (natural) languages, in particular how computers can be programmed to process and analyse large amounts of natural language data.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [29, 32], [32, 33], [34, 36], [37, 38], [39, 47], [48, 50], [51, 62], [62, 63], [64, 72], [73, 80], [80, 81], [82, 93], [94, 104], [105, 108], [109, 119], [120, 132], [133, 137], [138, 143], [144, 148], [149, 152], [153, 165], [166, 173], [174, 183], [184, 187], [188, 193], [194, 195], [195, 202], [202, 203], [204, 213], [213, 214], [215, 217], [218, 228], [229, 232], [233, 242], [243, 246], [247, 249], [250, 260], [261, 263], [264, 271], [272, 275], [276, 283], [284, 289], [290, 297], [298, 300], [301, 308], [309, 317], [318, 322], [322, 323]]}
{"doc_key": "ai-dev-350", "ner": [[9, 10, "organisation"], [12, 13, "organisation"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "active", "youth", "-", "led", "climate", "action", "groups", "include", "Extinction", "Rebellion", ",", "Sunrise", "Movement", ",", "SustainUS", ",", "and", "others", "working", "at", "transnational", "and", "local", "levels", "."], "sentence-detokenized": "Other active youth-led climate action groups include Extinction Rebellion, Sunrise Movement, SustainUS, and others working at transnational and local levels.", "token2charspan": [[0, 5], [6, 12], [13, 18], [18, 19], [19, 22], [23, 30], [31, 37], [38, 44], [45, 52], [53, 63], [64, 73], [73, 74], [75, 82], [83, 91], [91, 92], [93, 102], [102, 103], [104, 107], [108, 114], [115, 122], [123, 125], [126, 139], [140, 143], [144, 149], [150, 156], [156, 157]]}
