{"doc_key": "ai-test-1", "ner": [[5, 7, "algorithm"], [9, 10, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "generative", "model", "approaches", "include", "na\u00efve", "Bayes", "classifiers", ",", "Gaussian", "mixture", "models", ",", "variational", "auto-encoders", "and", "others", "."], "sentence-detokenized": "Typical generative model approaches include na\u00efve Bayes classifiers, Gaussian mixture models, variational auto-encoders and others.", "token2charspan": [[0, 7], [8, 18], [19, 24], [25, 35], [36, 43], [44, 49], [50, 55], [56, 67], [67, 68], [69, 77], [78, 85], [86, 92], [92, 93], [94, 105], [106, 119], [120, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-2", "ner": [[5, 5, "organisation"], [7, 7, "conference"], [10, 16, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 7, 7, "role", "", false, false], [10, 16, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Finally", ",", "every", "two", "years", "ELRA", "organises", "LREC", ",", "the", "International", "Conference", "on", "Language", "Resources", "and", "Evaluation", "."], "sentence-detokenized": "Finally, every two years ELRA organises LREC, the International Conference on Language Resources and Evaluation.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 18], [19, 24], [25, 29], [30, 39], [40, 44], [44, 45], [46, 49], [50, 63], [64, 74], [75, 77], [78, 86], [87, 96], [97, 100], [101, 111], [111, 112]]}
{"doc_key": "ai-test-3", "ner": [[6, 11, "algorithm"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "task", "is", "usually", "to", "derive", "a", "maximum", "likelihood", "estimate", "of", "the", "HMM", "parameters", "from", "the", "output", "sequences", "."], "sentence-detokenized": "The task is usually to derive a maximum likelihood estimate of the HMM parameters from the output sequences.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 22], [23, 29], [30, 31], [32, 39], [40, 50], [51, 59], [60, 62], [63, 66], [67, 70], [71, 81], [82, 86], [87, 90], [91, 97], [98, 107], [107, 108]]}
{"doc_key": "ai-test-4", "ner": [[3, 3, "algorithm"], [6, 8, "algorithm"], [11, 11, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 11, 11, "compare", "", false, false], [6, 8, 11, 11, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "contrast", "to", "neural", "networks", "and", "support", "vector", "machines", ",", "the", "AdaBoost", "training", "process", "selects", "only", "those", "features", "known", "to", "improve", "the", "predictive", "ability", "of", "the", "model", ",", "reducing", "dimensionality", "and", "potentially", "improving", "execution", "time", ",", "as", "irrelevant", "features", "do", "not", "need", "to", "be", "computed", "."], "sentence-detokenized": "In contrast to neural networks and support vector machines, the AdaBoost training process selects only those features known to improve the predictive ability of the model, reducing dimensionality and potentially improving execution time, as irrelevant features do not need to be computed.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 21], [22, 30], [31, 34], [35, 42], [43, 49], [50, 58], [58, 59], [60, 63], [64, 72], [73, 81], [82, 89], [90, 97], [98, 102], [103, 108], [109, 117], [118, 123], [124, 126], [127, 134], [135, 138], [139, 149], [150, 157], [158, 160], [161, 164], [165, 170], [170, 171], [172, 180], [181, 195], [196, 199], [200, 211], [212, 221], [222, 231], [232, 236], [236, 237], [238, 240], [241, 251], [252, 260], [261, 263], [264, 267], [268, 272], [273, 275], [276, 278], [279, 287], [287, 288]]}
{"doc_key": "ai-test-5", "ner": [[0, 1, "misc"], [11, 11, "misc"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 11, 11, "part-of", "", false, false], [11, 11, 15, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponymy", "is", "one", "of", "the", "possible", "relations", "between", "verbs", "in", "the", "semantic", "network", "of", "the", "Word", "Net", "database", "."], "sentence-detokenized": "Troponymy is one of the possible relations between verbs in the semantic network of the WordNet database.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 19], [20, 23], [24, 32], [33, 42], [43, 50], [51, 56], [57, 59], [60, 63], [64, 72], [73, 80], [81, 83], [84, 87], [88, 92], [92, 95], [96, 104], [104, 105]]}
{"doc_key": "ai-test-6", "ner": [[6, 8, "task"], [9, 11, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 9, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Framework", "language", "is", "the", "technology", "used", "to", "represent", "knowledge", "in", "artificial", "intelligence", "."], "sentence-detokenized": "Framework language is the technology used to represent knowledge in artificial intelligence.", "token2charspan": [[0, 9], [10, 18], [19, 21], [22, 25], [26, 36], [37, 41], [42, 44], [45, 54], [55, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-7", "ner": [[0, 12, "metrics"], [5, 16, "metrics"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 12, 5, 16, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "the", "Bilingual", "evaluation", "understudy", "in", "the", "calculation", "of", "the", "shortness", "penalty", ",", "as", "small", "variations", "in", "translation", "length", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from the Bilingual evaluation understudy in the calculation of the shortness penalty, as small variations in translation length do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 26], [27, 36], [37, 47], [48, 58], [59, 61], [62, 65], [66, 77], [78, 80], [81, 84], [85, 94], [95, 102], [102, 103], [104, 106], [107, 112], [113, 123], [124, 126], [127, 138], [139, 145], [146, 148], [149, 152], [153, 159], [160, 163], [164, 171], [172, 177], [178, 180], [181, 185], [185, 186]]}
{"doc_key": "ai-test-8", "ner": [[15, 16, "algorithm"], [19, 26, "algorithm"], [31, 32, "field"], [40, 41, "algorithm"], [43, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 16, 31, 32, "usage", "", false, false], [19, 26, 31, 32, "usage", "", false, false], [40, 41, 31, 32, "type-of", "", false, false], [43, 45, 31, 32, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "model", "is", "initially", "fitted", "on", "a", "training", "dataset", ",", "The", "model", "(", "e.g.", "a", "neural", "network", "or", "a", "naive", "Bayes", "classifier", ")", "is", "trained", "on", "the", "training", "dataset", "using", "a", "supervised", "learning", "method", ",", "such", "as", "optimization", "methods", "like", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The model is initially fitted on a training dataset, The model (e.g. a neural network or a naive Bayes classifier) is trained on the training dataset using a supervised learning method, such as optimization methods like gradient descent or stochastic gradient descent.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 22], [23, 29], [30, 32], [33, 34], [35, 43], [44, 51], [51, 52], [53, 56], [57, 62], [63, 64], [64, 68], [69, 70], [71, 77], [78, 85], [86, 88], [89, 90], [91, 96], [97, 102], [103, 113], [113, 114], [115, 117], [118, 125], [126, 128], [129, 132], [133, 141], [142, 149], [150, 155], [156, 157], [158, 168], [169, 177], [178, 184], [184, 185], [186, 190], [191, 193], [194, 206], [207, 214], [215, 219], [220, 228], [229, 236], [237, 239], [240, 250], [251, 259], [260, 267], [267, 268]]}
{"doc_key": "ai-test-9", "ner": [[0, 0, "product"], [8, 9, "task"], [11, 11, "task"], [13, 15, "task"], [17, 18, "task"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 0, "usage", "", true, false], [11, 11, 0, 0, "usage", "", true, false], [13, 15, 0, 0, "usage", "", true, false], [17, 18, 0, 0, "usage", "", true, false], [27, 29, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "has", "been", "used", "in", "applications", "such", "as", "question", "answering", ",", "paraphrasing", ",", "text", "consistency", "detection", "and", "information", "retrieval", ",", "either", "directly", "or", "with", "the", "help", "of", "semantic", "role", "labeling", "tools", "."], "sentence-detokenized": "FrameNet has been used in applications such as question answering, paraphrasing, text consistency detection and information retrieval, either directly or with the help of semantic role labeling tools.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 25], [26, 38], [39, 43], [44, 46], [47, 55], [56, 65], [65, 66], [67, 79], [79, 80], [81, 85], [86, 97], [98, 107], [108, 111], [112, 123], [124, 133], [133, 134], [135, 141], [142, 150], [151, 153], [154, 158], [159, 162], [163, 167], [168, 170], [171, 179], [180, 184], [185, 193], [194, 199], [199, 200]]}
{"doc_key": "ai-test-10", "ner": [[5, 6, "field"], [14, 14, "product"], [17, 17, "misc"], [20, 20, "product"], [23, 24, "field"], [27, 27, "product"], [30, 32, "misc"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [42, 43, "misc"], [46, 47, "product"], [49, 50, "product"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[20, 20, 17, 17, "general-affiliation", "", false, false], [27, 27, 23, 24, "general-affiliation", "", false, false], [35, 35, 30, 32, "type-of", "", false, false], [37, 37, 30, 32, "type-of", "", false, false], [39, 39, 30, 32, "type-of", "", false, false], [46, 47, 42, 43, "general-affiliation", "", false, false], [49, 50, 42, 43, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "sentence": ["These", "include", "programs", "such", "as", "data", "analysis", "and", "extraction", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "general", "auditing", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "e.g.", "Crystal", "Reports", "and", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "These include programs such as data analysis and extraction tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), general auditing software (e.g. ACL, Arbutus, EAS), business intelligence (e.g. Crystal Reports and Business Objects), etc.", "token2charspan": [[0, 5], [6, 13], [14, 22], [23, 27], [28, 30], [31, 35], [36, 44], [45, 48], [49, 59], [60, 65], [65, 66], [67, 79], [80, 81], [81, 85], [86, 91], [91, 92], [92, 93], [94, 103], [104, 105], [105, 109], [110, 116], [116, 117], [117, 118], [119, 130], [131, 139], [140, 141], [141, 145], [146, 149], [149, 150], [150, 151], [152, 159], [160, 168], [169, 177], [178, 179], [179, 183], [184, 187], [187, 188], [189, 196], [196, 197], [198, 201], [201, 202], [202, 203], [204, 212], [213, 225], [226, 227], [227, 231], [232, 239], [240, 247], [248, 251], [252, 260], [261, 268], [268, 269], [269, 270], [271, 274], [274, 275]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 6, "researcher"], [10, 10, "organisation"], [13, 14, "product"], [19, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "origin", "", false, false], [5, 6, 10, 10, "role", "", false, false], [13, 14, 19, 20, "type-of", "", false, false], [19, 20, 5, 6, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", "-", "founded", "by", "Rodney", "Brooks", ",", "formerly", "of", "iRobot", "-", "unveiled", "Baxter", "in", "September", "2012", ",", "an", "industrial", "robot", "designed", "to", "safely", "interact", "with", "human", "workers", "in", "the", "neighbourhood", "and", "programmable", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "Rethink Robotics - founded by Rodney Brooks, formerly of iRobot - unveiled Baxter in September 2012, an industrial robot designed to safely interact with human workers in the neighbourhood and programmable to perform simple tasks.", "token2charspan": [[0, 7], [8, 16], [17, 18], [19, 26], [27, 29], [30, 36], [37, 43], [43, 44], [45, 53], [54, 56], [57, 63], [64, 65], [66, 74], [75, 81], [82, 84], [85, 94], [95, 99], [99, 100], [101, 103], [104, 114], [115, 120], [121, 129], [130, 132], [133, 139], [140, 148], [149, 153], [154, 159], [160, 167], [168, 170], [171, 174], [175, 188], [189, 192], [193, 205], [206, 208], [209, 216], [217, 223], [224, 229], [229, 230]]}
{"doc_key": "ai-test-12", "ner": [[1, 2, "field"], [5, 6, "task"], [8, 9, "task"], [11, 14, "task"], [16, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 28, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 6, 1, 2, "part-of", "task_part_of_field", false, false], [8, 9, 1, 2, "part-of", "task_part_of_field", false, false], [11, 14, 1, 2, "part-of", "task_part_of_field", false, false], [16, 18, 1, 2, "part-of", "task_part_of_field", false, false], [20, 21, 1, 2, "part-of", "task_part_of_field", false, false], [23, 24, 1, 2, "part-of", "task_part_of_field", false, false], [26, 28, 1, 2, "part-of", "task_part_of_field", false, false], [35, 36, 1, 2, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Typical", "text", "mining", "tasks", "include", "text", "categorisation", ",", "text", "clustering", ",", "concept", "/", "entity", "extraction", ",", "granular", "taxonomy", "generation", ",", "sentiment", "analysis", ",", "document", "summarisation", "and", "entity", "relationship", "modelling", "(", "i.e.", "learning", "the", "relationships", "between", "named", "entities", ")", "."], "sentence-detokenized": "Typical text mining tasks include text categorisation, text clustering, concept/entity extraction, granular taxonomy generation, sentiment analysis, document summarisation and entity relationship modelling (i.e. learning the relationships between named entities).", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 25], [26, 33], [34, 38], [39, 53], [53, 54], [55, 59], [60, 70], [70, 71], [72, 79], [79, 80], [80, 86], [87, 97], [97, 98], [99, 107], [108, 116], [117, 127], [127, 128], [129, 138], [139, 147], [147, 148], [149, 157], [158, 171], [172, 175], [176, 182], [183, 195], [196, 205], [206, 207], [207, 211], [212, 220], [221, 224], [225, 238], [239, 246], [247, 252], [253, 261], [261, 262], [262, 263]]}
{"doc_key": "ai-test-13", "ner": [[5, 6, "metrics"], [9, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "stem", "crushing", "reduces", "the", "accuracy", "or", "the", "REAL", "negative", "rate", "for", "such", "systems", "."], "sentence-detokenized": "However, stem crushing reduces the accuracy or the REAL negative rate for such systems.", "token2charspan": [[0, 7], [7, 8], [9, 13], [14, 22], [23, 30], [31, 34], [35, 43], [44, 46], [47, 50], [51, 55], [56, 64], [65, 69], [70, 73], [74, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-test-14", "ner": [[4, 7, "task"], [11, 12, "misc"], [18, 19, "misc"], [31, 31, "product"], [33, 33, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 12, 4, 7, "temporal", "", false, false], [18, 19, 11, 12, "named", "", false, false], [31, 31, 11, 12, "usage", "", false, false], [33, 33, 11, 12, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "special", "case", "of", "keyword", "discovery", "is", "the", "recognition", "of", "a", "wake", "word", "(", "also", "known", "as", "a", "hot", "word", ")", ",", "which", "is", "used", "by", "personal", "digital", "assistants", "such", "as", "Alexa", "or", "Siri", "to", "wake", "you", "up", "when", "you", "say", "your", "name", "."], "sentence-detokenized": "A special case of keyword discovery is the recognition of a wake word (also known as a hot word), which is used by personal digital assistants such as Alexa or Siri to wake you up when you say your name.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 17], [18, 25], [26, 35], [36, 38], [39, 42], [43, 54], [55, 57], [58, 59], [60, 64], [65, 69], [70, 71], [71, 75], [76, 81], [82, 84], [85, 86], [87, 90], [91, 95], [95, 96], [96, 97], [98, 103], [104, 106], [107, 111], [112, 114], [115, 123], [124, 131], [132, 142], [143, 147], [148, 150], [151, 156], [157, 159], [160, 164], [165, 167], [168, 172], [173, 176], [177, 179], [180, 184], [185, 188], [189, 192], [193, 197], [198, 202], [202, 203]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [9, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "and", "Java", "."], "sentence-detokenized": "Prova is an open source programming language that combines Prolog and Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 16], [17, 23], [24, 35], [36, 44], [45, 49], [50, 58], [59, 65], [66, 69], [70, 74], [74, 75]]}
{"doc_key": "ai-test-16", "ner": [[6, 7, "organisation"], [3, 4, "organisation"], [13, 15, "product"], [25, 26, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 3, 4, "part-of", "", false, false], [6, 7, 3, 4, "role", "sells", false, false], [6, 7, 25, 26, "role", "sells_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1987", ",", "Toshiba", "'s", "subsidiary", "Tocibai", "Machine", "was", "accused", "of", "illegally", "selling", "CNC", "sawmill", "parts", "used", "to", "make", "very", "quiet", "submarine", "propellers", "to", "the", "Soviet", "Union", "in", "violation", "of", "the", "CoCom", "agreement", ",", "an", "international", "embargo", "on", "certain", "countries", "."], "sentence-detokenized": "In 1987, Toshiba's subsidiary Tocibai Machine was accused of illegally selling CNC sawmill parts used to make very quiet submarine propellers to the Soviet Union in violation of the CoCom agreement, an international embargo on certain countries.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [16, 18], [19, 29], [30, 37], [38, 45], [46, 49], [50, 57], [58, 60], [61, 70], [71, 78], [79, 82], [83, 90], [91, 96], [97, 101], [102, 104], [105, 109], [110, 114], [115, 120], [121, 130], [131, 141], [142, 144], [145, 148], [149, 155], [156, 161], [162, 164], [165, 174], [175, 177], [178, 181], [182, 187], [188, 197], [197, 198], [199, 201], [202, 215], [216, 223], [224, 226], [227, 234], [235, 244], [244, 245]]}
{"doc_key": "ai-test-17", "ner": [[0, 1, "researcher"], [7, 10, "product"], [16, 20, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 0, 1, "artifact", "", false, false], [7, 10, 16, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Engelberger", "'s", "most", "famous", "invention", ",", "the", "Unimate", "industrial", "robot", "arm", ",", "was", "inducted", "into", "the", "Robot", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberger's most famous invention, the Unimate industrial robot arm, was inducted into the Robot Hall of Fame in 2003.", "token2charspan": [[0, 11], [11, 13], [14, 18], [19, 25], [26, 35], [35, 36], [37, 40], [41, 48], [49, 59], [60, 65], [66, 69], [69, 70], [71, 74], [75, 83], [84, 88], [89, 92], [93, 98], [99, 103], [104, 106], [107, 111], [112, 114], [115, 119], [119, 120]]}
{"doc_key": "ai-test-18", "ner": [[3, 4, "misc"], [8, 8, "misc"], [10, 11, "person"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 8, 8, "usage", "", false, false], [10, 11, 18, 19, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Originally", "controlled", "through", "static", "html", "web", "pages", "using", "CGI", ",", "Dalton", "'s", "work", "introduced", "a", "Java", "-", "based", "augmented", "reality", "interface", "that", "has", "had", "limited", "success", "."], "sentence-detokenized": "Originally controlled through static html web pages using CGI, Dalton's work introduced a Java-based augmented reality interface that has had limited success.", "token2charspan": [[0, 10], [11, 21], [22, 29], [30, 36], [37, 41], [42, 45], [46, 51], [52, 57], [58, 61], [61, 62], [63, 69], [69, 71], [72, 76], [77, 87], [88, 89], [90, 94], [94, 95], [95, 100], [101, 110], [111, 118], [119, 128], [129, 133], [134, 137], [138, 141], [142, 149], [150, 157], [157, 158]]}
{"doc_key": "ai-test-19", "ner": [[3, 8, "task"], [5, 5, "organisation"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 8, 5, 5, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "publication", "on", "the", "ISO", "ratified", "LMF", "specification", "(", "this", "article", "became", "(", "in", "2015", ")", "the", "9th", "most", "cited", "article", "at", "LREC", "conferences", "among", "LREC", "documents", ")", ":"], "sentence-detokenized": "The first publication on the ISO ratified LMF specification (this article became (in 2015) the 9th most cited article at LREC conferences among LREC documents):", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 24], [25, 28], [29, 32], [33, 41], [42, 45], [46, 59], [60, 61], [61, 65], [66, 73], [74, 80], [81, 82], [82, 84], [85, 89], [89, 90], [91, 94], [95, 98], [99, 103], [104, 109], [110, 117], [118, 120], [121, 125], [126, 137], [138, 143], [144, 148], [149, 158], [158, 159], [159, 160]]}
{"doc_key": "ai-test-20", "ner": [[1, 2, "metrics"], [11, 13, "metrics"], [14, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 13, 1, 2, "usage", "", false, false], [11, 13, 14, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "perturbation", "matrix", "or", "correspondence", "matrix", "is", "often", "used", "to", "validate", "the", "accuracy", "of", "k", "-", "NN", "classification", "."], "sentence-detokenized": "A perturbation matrix or correspondence matrix is often used to validate the accuracy of k -NN classification.", "token2charspan": [[0, 1], [2, 14], [15, 21], [22, 24], [25, 39], [40, 46], [47, 49], [50, 55], [56, 60], [61, 63], [64, 72], [73, 76], [77, 85], [86, 88], [89, 90], [91, 92], [92, 94], [95, 109], [109, 110]]}
{"doc_key": "ai-test-21", "ner": [[0, 1, "algorithm"], [12, 12, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 15, "part-of", "", false, false], [0, 1, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", "is", "one", "of", "the", "predictive", "modelling", "approaches", "used", "in", "statistics", ",", "data", "mining", "and", "machine", "learning", "."], "sentence-detokenized": "Decision tree learning is one of the predictive modelling approaches used in statistics, data mining and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 47], [48, 57], [58, 68], [69, 73], [74, 76], [77, 87], [87, 88], [89, 93], [94, 100], [101, 104], [105, 112], [113, 121], [121, 122]]}
{"doc_key": "ai-test-22", "ner": [[4, 7, "misc"], [16, 17, "field"], [21, 23, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 7, 16, 17, "related-to", "", true, false], [21, 23, 16, 17, "type-of", "", false, false], [25, 25, 16, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["At", "runtime", ",", "the", "target", "prosody", "of", "the", "sentence", "is", "mapped", "to", "these", "minimum", "units", "using", "signal", "processing", "techniques", "such", "as", "linear", "predictive", "coding", ",", "PSOLA"], "sentence-detokenized": "At runtime, the target prosody of the sentence is mapped to these minimum units using signal processing techniques such as linear predictive coding, PSOLA", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 22], [23, 30], [31, 33], [34, 37], [38, 46], [47, 49], [50, 56], [57, 59], [60, 65], [66, 73], [74, 79], [80, 85], [86, 92], [93, 103], [104, 114], [115, 119], [120, 122], [123, 129], [130, 140], [141, 147], [147, 148], [149, 154]]}
{"doc_key": "ai-test-23", "ner": [[3, 4, "field"], [6, 9, "field"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 3, 4, "usage", "", true, false], [17, 18, 6, 9, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "approach", "used", "artificial", "intelligence", "and", "machine", "learning", "to", "allow", "researchers", "to", "visually", "compare", "traditional", "and", "thermal", "facial", "images", "."], "sentence-detokenized": "This approach used artificial intelligence and machine learning to allow researchers to visually compare traditional and thermal facial images.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 29], [30, 42], [43, 46], [47, 54], [55, 63], [64, 66], [67, 72], [73, 84], [85, 87], [88, 96], [97, 104], [105, 116], [117, 120], [121, 128], [129, 135], [136, 142], [142, 143]]}
{"doc_key": "ai-test-24", "ner": [[0, 2, "field"], [4, 7, "algorithm"], [10, 11, "task"], [15, 16, "misc"], [22, 23, "field"], [25, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 7, 0, 2, "part-of", "", false, false], [4, 7, 10, 11, "topic", "", false, false], [10, 11, 15, 16, "origin", "", false, false], [22, 23, 0, 2, "part-of", "", false, false], [22, 23, 4, 7, "topic", "", false, false], [25, 27, 0, 2, "part-of", "", false, false], [25, 27, 4, 7, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "computer", "science", ",", "evolutionary", "computation", "is", "the", "family", "of", "global", "optimization", "algorithms", "inspired", "by", "biological", "evolution", ",", "and", "the", "subfield", "of", "artificial", "intelligence", "and", "soft", "computing", "that", "studies", "these", "algorithms", "."], "sentence-detokenized": "In computer science, evolutionary computation is the family of global optimization algorithms inspired by biological evolution, and the subfield of artificial intelligence and soft computing that studies these algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 33], [34, 45], [46, 48], [49, 52], [53, 59], [60, 62], [63, 69], [70, 82], [83, 93], [94, 102], [103, 105], [106, 116], [117, 126], [126, 127], [128, 131], [132, 135], [136, 144], [145, 147], [148, 158], [159, 171], [172, 175], [176, 180], [181, 190], [191, 195], [196, 203], [204, 209], [210, 220], [220, 221]]}
{"doc_key": "ai-test-25", "ner": [[11, 12, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "we", "can", "combine", "some", "measure", "based", "on", "the", "perturbation", "matrix", "with", "the", "mean", "squared", "error", "evaluated", "between", "the", "raw", "model", "outputs", "and", "the", "actual", "values", "."], "sentence-detokenized": "For example, we can combine some measure based on the perturbation matrix with the mean squared error evaluated between the raw model outputs and the actual values.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 19], [20, 27], [28, 32], [33, 40], [41, 46], [47, 49], [50, 53], [54, 66], [67, 73], [74, 78], [79, 82], [83, 87], [88, 95], [96, 101], [102, 111], [112, 119], [120, 123], [124, 127], [128, 133], [134, 141], [142, 145], [146, 149], [150, 156], [157, 163], [163, 164]]}
{"doc_key": "ai-test-26", "ner": [[10, 11, "product"], [14, 14, "researcher"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 14, 14, "origin", "", false, false], [10, 11, 21, 21, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "most", "cases", ",", "they", "are", "the", "results", "of", "the", "word2vec", "model", "developed", "by", "Mikolov", "et", "al", ".", "or", "versions", "of", "word2vec", "."], "sentence-detokenized": "In most cases, they are the results of the word2vec model developed by Mikolov et al. or versions of word2vec.", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 19], [20, 23], [24, 27], [28, 35], [36, 38], [39, 42], [43, 51], [52, 57], [58, 67], [68, 70], [71, 78], [79, 81], [82, 84], [84, 85], [86, 88], [89, 97], [98, 100], [101, 109], [109, 110]]}
{"doc_key": "ai-test-27", "ner": [[13, 13, "conference"], [17, 20, "conference"], [16, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 22, 17, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["During", "this", "time", ",", "a", "total", "of", "43", "publications", "have", "been", "recognized", "by", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "During this time, a total of 43 publications have been recognized by CVPR and the International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 6], [7, 11], [12, 16], [16, 17], [18, 19], [20, 25], [26, 28], [29, 31], [32, 44], [45, 49], [50, 54], [55, 65], [66, 68], [69, 73], [74, 77], [78, 81], [82, 95], [96, 106], [107, 109], [110, 118], [119, 125], [126, 127], [127, 131], [131, 132], [132, 133]]}
{"doc_key": "ai-test-28", "ner": [[0, 1, "product"], [12, 13, "field"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 12, 13, "general-affiliation", "platform_for_education_about", false, false], [23, 24, 0, 1, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["AIBO", "is", "used", "by", "many", "as", "a", "low", "-", "cost", "platform", "for", "artificial", "intelligence", "education", "and", "research", ",", "as", "it", "integrates", "computer", ",", "computer", "vision", "and", "articulators", "in", "a", "much", "cheaper", "package", "than", "traditional", "research", "robots", "."], "sentence-detokenized": "AIBO is used by many as a low-cost platform for artificial intelligence education and research, as it integrates computer, computer vision and articulators in a much cheaper package than traditional research robots.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 20], [21, 23], [24, 25], [26, 29], [29, 30], [30, 34], [35, 43], [44, 47], [48, 58], [59, 71], [72, 81], [82, 85], [86, 94], [94, 95], [96, 98], [99, 101], [102, 112], [113, 121], [121, 122], [123, 131], [132, 138], [139, 142], [143, 155], [156, 158], [159, 160], [161, 165], [166, 173], [174, 181], [182, 186], [187, 198], [199, 207], [208, 214], [214, 215]]}
{"doc_key": "ai-test-29", "ner": [[6, 12, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "served", "as", "Programme", "Chair", "for", "the", "2021", "International", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "He served as Programme Chair for the 2021 International Conference on Computer Vision.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 22], [23, 28], [29, 32], [33, 36], [37, 41], [42, 55], [56, 66], [67, 69], [70, 78], [79, 85], [85, 86]]}
{"doc_key": "ai-test-30", "ner": [[0, 0, "researcher"], [6, 7, "organisation"], [16, 17, "organisation"], [27, 29, "organisation"], [33, 34, "product"], [35, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 7, "role", "", false, false], [0, 0, 16, 17, "role", "", true, false], [16, 17, 27, 29, "role", "develops_with", false, false], [33, 34, 16, 17, "artifact", "", false, false], [35, 40, 33, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Scheinman", ",", "after", "receiving", "a", "grant", "from", "Unimation", "to", "develop", "his", "designs", ",", "sold", "these", "designs", "to", "Unimation", ",", "which", "further", "developed", "them", "with", "the", "support", "of", "General", "Motors", "and", "later", "marketed", "them", "as", "the", "Programmable", "Universal", "Assembly", "Machine", "(", "PUMA", ")", "."], "sentence-detokenized": "Scheinman, after receiving a grant from Unimation to develop his designs, sold these designs to Unimation, which further developed them with the support of General Motors and later marketed them as the Programmable Universal Assembly Machine (PUMA).", "token2charspan": [[0, 9], [9, 10], [11, 16], [17, 26], [27, 28], [29, 34], [35, 39], [40, 49], [50, 52], [53, 60], [61, 64], [65, 72], [72, 73], [74, 78], [79, 84], [85, 92], [93, 95], [96, 105], [105, 106], [107, 112], [113, 120], [121, 130], [131, 135], [136, 140], [141, 144], [145, 152], [153, 155], [156, 163], [164, 170], [171, 174], [175, 180], [181, 189], [190, 194], [195, 197], [198, 201], [202, 214], [215, 224], [225, 233], [234, 241], [242, 243], [243, 247], [247, 248], [248, 249]]}
{"doc_key": "ai-test-31", "ner": [[6, 7, "task"], [9, 12, "task"], [16, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 16, 6, 7, "general-affiliation", "works_with", false, false], [16, 16, 9, 12, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "overview", "of", "calibration", "methods", "for", "binary", "classification", "and", "multiclass", "classification", "classification", "tasks", "is", "given", "by", "Gebel", "(", "2009", ")", "."], "sentence-detokenized": "An overview of calibration methods for binary classification and multiclass classification classification tasks is given by Gebel (2009).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 34], [35, 38], [39, 45], [46, 60], [61, 64], [65, 75], [76, 90], [91, 105], [106, 111], [112, 114], [115, 120], [121, 123], [124, 129], [130, 131], [131, 135], [135, 136], [136, 137]]}
{"doc_key": "ai-test-32", "ner": [[6, 10, "task"], [13, 14, "task"], [16, 17, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "works", "in", "areas", "such", "as", "optical", "character", "recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "speech", "recognition", "technology", "and", "electronic", "keyboards", "."], "sentence-detokenized": "He works in areas such as optical character recognition (OCR), speech synthesis, speech recognition technology and electronic keyboards.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 17], [18, 22], [23, 25], [26, 33], [34, 43], [44, 55], [56, 57], [57, 60], [60, 61], [61, 62], [63, 69], [70, 79], [79, 80], [81, 87], [88, 99], [100, 110], [111, 114], [115, 125], [126, 135], [135, 136]]}
{"doc_key": "ai-test-33", "ner": [[9, 10, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "latest", "and", "most", "advanced", "techniques", ",", "the", "Kaldi", "toolkit", "can", "be", "used", "."], "sentence-detokenized": "For the latest and most advanced techniques, the Kaldi toolkit can be used.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 18], [19, 23], [24, 32], [33, 43], [43, 44], [45, 48], [49, 54], [55, 62], [63, 66], [67, 69], [70, 74], [74, 75]]}
{"doc_key": "ai-test-34", "ner": [[0, 4, "researcher"], [8, 10, "organisation"], [16, 17, "organisation"], [23, 24, "organisation"], [27, 27, "researcher"], [32, 34, "organisation"], [40, 42, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 4, 8, 10, "role", "", false, false], [0, 4, 16, 17, "role", "", false, false], [0, 4, 23, 24, "role", "", false, false], [0, 4, 32, 34, "role", "", false, false], [0, 4, 40, 42, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson", "-", "Laird", "is", "a", "Fellow", "of", "the", "American", "Philosophical", "Society", ",", "a", "Fellow", "of", "the", "Royal", "Society", ",", "a", "Fellow", "of", "the", "British", "Academy", ",", "a", "William", "James", "Fellow", "of", "the", "Psychological", "Science", "Society", "and", "a", "Fellow", "of", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Johnson-Laird is a Fellow of the American Philosophical Society, a Fellow of the Royal Society, a Fellow of the British Academy, a William James Fellow of the Psychological Science Society and a Fellow of the Cognitive Science Society.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 66], [67, 73], [74, 76], [77, 80], [81, 86], [87, 94], [94, 95], [96, 97], [98, 104], [105, 107], [108, 111], [112, 119], [120, 127], [127, 128], [129, 130], [131, 138], [139, 144], [145, 151], [152, 154], [155, 158], [159, 172], [173, 180], [181, 188], [189, 192], [193, 194], [195, 201], [202, 204], [205, 208], [209, 218], [219, 226], [227, 234], [234, 235]]}
{"doc_key": "ai-test-35", "ner": [[3, 8, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [20, 21, "algorithm"], [22, 27, "task"], [23, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 3, 8, "physical", "", false, false], [10, 11, 3, 8, "temporal", "", false, false], [13, 14, 3, 8, "physical", "", false, false], [13, 14, 3, 8, "temporal", "", false, false], [16, 17, 3, 8, "physical", "", false, false], [16, 17, 3, 8, "temporal", "", false, false], [20, 21, 16, 17, "role", "extends", false, false], [22, 27, 16, 17, "role", "extends", false, false], [23, 29, 22, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["At", "the", "2010", "IEEE", "International", "Conference", "on", "Image", "Processing", ",", "Rui", "Hu", ",", "Mark", "Banard", "and", "John", "Collomosse", "extended", "the", "HOG", "descriptor", "to", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the 2010 IEEE International Conference on Image Processing, Rui Hu, Mark Banard and John Collomosse extended the HOG descriptor to sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 30], [31, 41], [42, 44], [45, 50], [51, 61], [61, 62], [63, 66], [67, 69], [69, 70], [71, 75], [76, 82], [83, 86], [87, 91], [92, 102], [103, 111], [112, 115], [116, 119], [120, 130], [131, 133], [134, 140], [140, 141], [141, 146], [147, 152], [153, 162], [163, 164], [164, 168], [168, 169], [169, 170]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "uses", "a", "modified", "form", "of", "accuracy", "to", "compare", "a", "candidate", "translation", "with", "several", "reference", "translations", "."], "sentence-detokenized": "BLEU uses a modified form of accuracy to compare a candidate translation with several reference translations.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 20], [21, 25], [26, 28], [29, 37], [38, 40], [41, 48], [49, 50], [51, 60], [61, 72], [73, 77], [78, 85], [86, 95], [96, 108], [108, 109]]}
{"doc_key": "ai-test-37", "ner": [[29, 30, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "a", "general", "base", "space", "math", "(", "Y", ",\\", "mathcal", "{", "B", "},\\", "nu", ")", "/", "math", "(", "i.e.", "a", "non", "countable", "base", "space", ")", ",", "we", "typically", "consider", "relative", "entropy", "."], "sentence-detokenized": "For a general base space math (Y,\\ mathcal {B},\\ nu) / math (i.e. a non countable base space), we typically consider relative entropy.", "token2charspan": [[0, 3], [4, 5], [6, 13], [14, 18], [19, 24], [25, 29], [30, 31], [31, 32], [32, 34], [35, 42], [43, 44], [44, 45], [45, 48], [49, 51], [51, 52], [53, 54], [55, 59], [60, 61], [61, 65], [66, 67], [68, 71], [72, 81], [82, 86], [87, 92], [92, 93], [93, 94], [95, 97], [98, 107], [108, 116], [117, 125], [126, 133], [133, 134]]}
{"doc_key": "ai-test-38", "ner": [[12, 12, "organisation"], [10, 14, "organisation"], [9, 9, "country"], [18, 18, "organisation"], [20, 20, "organisation"], [24, 26, "organisation"], [29, 34, "organisation"], [36, 38, "organisation"], [44, 44, "misc"], [45, 45, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11], "relations": [[10, 14, 12, 12, "named", "", false, false], [18, 18, 9, 9, "physical", "", false, false], [20, 20, 18, 18, "named", "", false, false], [36, 38, 29, 34, "named", "", false, false], [44, 44, 45, 45, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 5, 6], "sentence": ["In", "October", "2011", ",", "the", "existing", "partnerships", "with", "the", "US", "National", "Park", "Service", "(", "NPS", ")", ",", "Historic", "Scotland", "(", "HS", ")", ",", "the", "World", "Monuments", "Fund", "and", "the", "Instituto", "Nacional", "de", "Antropolog\u00eda", "y", "Historia", "(", "INAH", ")", "in", "Mexico", "were", "significantly", "expanded", ",", "CyArk", "website", "."], "sentence-detokenized": "In October 2011, the existing partnerships with the US National Park Service (NPS), Historic Scotland (HS), the World Monuments Fund and the Instituto Nacional de Antropolog\u00eda y Historia (INAH) in Mexico were significantly expanded, CyArk website.", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [17, 20], [21, 29], [30, 42], [43, 47], [48, 51], [52, 54], [55, 63], [64, 68], [69, 76], [77, 78], [78, 81], [81, 82], [82, 83], [84, 92], [93, 101], [102, 103], [103, 105], [105, 106], [106, 107], [108, 111], [112, 117], [118, 127], [128, 132], [133, 136], [137, 140], [141, 150], [151, 159], [160, 162], [163, 175], [176, 177], [178, 186], [187, 188], [188, 192], [192, 193], [194, 196], [197, 203], [204, 208], [209, 222], [223, 231], [231, 232], [233, 238], [239, 246], [246, 247]]}
{"doc_key": "ai-test-39", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [11, 11, "product"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 11, 11, "part-of", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [11, 11, 6, 7, "general-affiliation", "", false, false], [13, 13, 6, 7, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kernel", "SVMs", "are", "available", "in", "many", "machine", "learning", "toolkits", ",", "including", "LIBSVM", ",", "MATLAB", "and", "others", "."], "sentence-detokenized": "Kernel SVMs are available in many machine learning toolkits, including LIBSVM, MATLAB and others.", "token2charspan": [[0, 6], [7, 11], [12, 15], [16, 25], [26, 28], [29, 33], [34, 41], [42, 50], [51, 59], [59, 60], [61, 70], [71, 77], [77, 78], [79, 85], [86, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-test-40", "ner": [[2, 7, "misc"], [13, 14, "location"], [16, 16, "location"], [21, 21, "country"], [22, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 7, 13, 14, "physical", "", false, false], [2, 7, 22, 24, "temporal", "", false, false], [13, 14, 16, 16, "physical", "", false, false], [16, 16, 21, 21, "physical", "", false, false], [22, 24, 13, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2009", "Loebner", "Prize", "competition", "took", "place", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", ",", "Brighton", ",", "in", "conjunction", "with", "the", "Interspeech", "2009", "conference", "."], "sentence-detokenized": "The 2009 Loebner Prize competition took place on 6 September 2009 at the Brighton Centre, Brighton, in conjunction with the Interspeech 2009 conference.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 34], [35, 39], [40, 45], [46, 48], [49, 50], [51, 60], [61, 65], [66, 68], [69, 72], [73, 81], [82, 88], [88, 89], [90, 98], [98, 99], [100, 102], [103, 114], [115, 119], [120, 123], [124, 135], [136, 140], [141, 151], [151, 152]]}
{"doc_key": "ai-test-41", "ner": [[2, 4, "product"], [10, 11, "product"], [15, 17, "product"], [18, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[18, 20, 2, 4, "part-of", "", false, false], [18, 20, 10, 11, "part-of", "", false, false], [18, 20, 15, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "humanoid", "QRIO", "robot", "is", "designed", "as", "a", "successor", "to", "AIBO", "and", "uses", "the", "same", "R", "-", "CODE", "Aperios", "operating", "system", "."], "sentence-detokenized": "The humanoid QRIO robot is designed as a successor to AIBO and uses the same R-CODE Aperios operating system.", "token2charspan": [[0, 3], [4, 12], [13, 17], [18, 23], [24, 26], [27, 35], [36, 38], [39, 40], [41, 50], [51, 53], [54, 58], [59, 62], [63, 67], [68, 71], [72, 76], [77, 78], [78, 79], [79, 83], [84, 91], [92, 101], [102, 108], [108, 109]]}
{"doc_key": "ai-test-42", "ner": [[0, 2, "misc"], [7, 7, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 0, 2, "cause-effect", "", true, false], [11, 12, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "speech", "waveforms", "are", "generated", "from", "the", "HMMs", "themselves", "using", "the", "maximum", "likelihood", "criterion", "."], "sentence-detokenized": "The speech waveforms are generated from the HMMs themselves using the maximum likelihood criterion.", "token2charspan": [[0, 3], [4, 10], [11, 20], [21, 24], [25, 34], [35, 39], [40, 43], [44, 48], [49, 59], [60, 65], [66, 69], [70, 77], [78, 88], [89, 98], [98, 99]]}
{"doc_key": "ai-test-43", "ner": [[0, 3, "product"], [5, 8, "task"], [10, 12, "task"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 5, 8, "type-of", "", false, false], [0, 3, 10, 12, "type-of", "", false, false], [0, 3, 16, 18, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "is", "a", "free", "multilingual", "statistical", "machine", "translation", "and", "neural", "machine", "translation", "service", "developed", "by", "Google", "that", "translates", "texts", "and", "websites", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Google Translate is a free multilingual statistical machine translation and neural machine translation service developed by Google that translates texts and websites from one language to another.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 39], [40, 51], [52, 59], [60, 71], [72, 75], [76, 82], [83, 90], [91, 102], [103, 110], [111, 120], [121, 123], [124, 130], [131, 135], [136, 146], [147, 152], [153, 156], [157, 165], [166, 170], [171, 174], [175, 183], [184, 186], [187, 194], [194, 195]]}
{"doc_key": "ai-test-44", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [14, 16, "field"], [21, 23, "task"], [25, 26, "task"], [20, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[21, 23, 5, 6, "part-of", "", false, true], [21, 23, 8, 9, "part-of", "", false, true], [21, 23, 11, 12, "part-of", "", false, true], [25, 26, 5, 6, "part-of", "", false, true], [25, 26, 8, 9, "part-of", "", false, true], [25, 26, 11, 12, "part-of", "", false, true], [20, 31, 5, 6, "part-of", "", false, true], [20, 31, 8, 9, "part-of", "", false, true], [20, 31, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Skeletons", "are", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", "and", "digital", "image", "processing", ",", "for", "example", "for", "optical", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", "or", "compression", "."], "sentence-detokenized": "Skeletons are widely used in computer vision, image analysis, pattern recognition and digital image processing, for example for optical character recognition, fingerprint recognition, visual inspection or compression.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 25], [26, 28], [29, 37], [38, 44], [44, 45], [46, 51], [52, 60], [60, 61], [62, 69], [70, 81], [82, 85], [86, 93], [94, 99], [100, 110], [110, 111], [112, 115], [116, 123], [124, 127], [128, 135], [136, 145], [146, 157], [157, 158], [159, 170], [171, 182], [182, 183], [184, 190], [191, 201], [202, 204], [205, 216], [216, 217]]}
{"doc_key": "ai-test-45", "ner": [[1, 6, "conference"], [11, 14, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 6, 11, 14, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "is", "the", "benchmark", "for", "object", "classification", "and", "recognition", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge is the benchmark for object classification and recognition, with millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 60], [61, 70], [71, 74], [75, 81], [82, 96], [97, 100], [101, 112], [112, 113], [114, 118], [119, 127], [128, 130], [131, 137], [138, 141], [142, 150], [151, 153], [154, 160], [161, 168], [168, 169]]}
{"doc_key": "ai-test-46", "ner": [[0, 0, "researcher"], [8, 9, "researcher"], [11, 12, "researcher"], [14, 19, "misc"], [1, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 14, 19, "part-of", "", false, false], [0, 0, 1, 25, "part-of", "", false, false], [8, 9, 14, 19, "part-of", "", false, false], [8, 9, 1, 25, "part-of", "", false, false], [11, 12, 14, 19, "part-of", "", false, false], [11, 12, 1, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", "has", "been", "hailed", "by", "some", ",", "alongside", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "as", "the", "godfather", "of", "artificial", "intelligence", "and", "the", "godfather", "of", "deep", "learning", "."], "sentence-detokenized": "Bengio has been hailed by some, alongside Geoffrey Hinton and Yann LeCun, as the godfather of artificial intelligence and the godfather of deep learning.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [23, 25], [26, 30], [30, 31], [32, 41], [42, 50], [51, 57], [58, 61], [62, 66], [67, 72], [72, 73], [74, 76], [77, 80], [81, 90], [91, 93], [94, 104], [105, 117], [118, 121], [122, 125], [126, 135], [136, 138], [139, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-test-47", "ner": [[0, 0, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["IEEE", "Life", "Fellow", "."], "sentence-detokenized": "IEEE Life Fellow.", "token2charspan": [[0, 4], [5, 9], [10, 16], [16, 17]]}
{"doc_key": "ai-test-48", "ner": [[0, 1, "organisation"], [15, 20, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 15, 20, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NSA", "Bethesda", "is", "responsible", "for", "operational", "support", "of", "the", "base", "for", "the", "main", "tenant", ",", "Walter", "Reed", "National", "Military", "Medical", "Center", "."], "sentence-detokenized": "NSA Bethesda is responsible for operational support of the base for the main tenant, Walter Reed National Military Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 31], [32, 43], [44, 51], [52, 54], [55, 58], [59, 63], [64, 67], [68, 71], [72, 76], [77, 83], [83, 84], [85, 91], [92, 96], [97, 105], [106, 114], [115, 122], [123, 129], [129, 130]]}
{"doc_key": "ai-test-49", "ner": [[6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "three", "main", "learning", "paradigms", "are", "supervised", "learning", ",", "unsupervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "The three main learning paradigms are supervised learning, unsupervised learning and reinforcement learning.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 23], [24, 33], [34, 37], [38, 48], [49, 57], [57, 58], [59, 71], [72, 80], [81, 84], [85, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-50", "ner": [[2, 2, "task"], [4, 6, "task"], [11, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Examples", "include", "control", ",", "planning", "and", "scheduling", ",", "the", "ability", "to", "answer", "diagnostic", "and", "consumer", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", "and", "face", "recognition", "."], "sentence-detokenized": "Examples include control, planning and scheduling, the ability to answer diagnostic and consumer questions, handwriting recognition, natural language understanding, speech recognition and face recognition.", "token2charspan": [[0, 8], [9, 16], [17, 24], [24, 25], [26, 34], [35, 38], [39, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 72], [73, 83], [84, 87], [88, 96], [97, 106], [106, 107], [108, 119], [120, 131], [131, 132], [133, 140], [141, 149], [150, 163], [163, 164], [165, 171], [172, 183], [184, 187], [188, 192], [193, 204], [204, 205]]}
{"doc_key": "ai-test-51", "ner": [[9, 15, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", "he", "was", "elected", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "founding", "member", ")", "."], "sentence-detokenized": "In 1991 he was elected a member of the Association for the Advancement of Artificial Intelligence (1990, founding member).", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 24], [25, 31], [32, 34], [35, 38], [39, 50], [51, 54], [55, 58], [59, 70], [71, 73], [74, 84], [85, 97], [98, 99], [99, 103], [103, 104], [105, 113], [114, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-test-52", "ner": [[12, 13, "misc"], [16, 20, "algorithm"], [27, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "if", "we", "formulate", "the", "problem", "as", "a", "solution", "to", "a", "Toeplitz", "matrix", "and", "use", "Levinson", "'s", "approximation", ",", "we", "can", "estimate", "a", "filter", "relatively", "quickly", "with", "the", "smallest", "possible", "mean", "squared", "error", "."], "sentence-detokenized": "However, if we formulate the problem as a solution to a Toeplitz matrix and use Levinson's approximation, we can estimate a filter relatively quickly with the smallest possible mean squared error.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 14], [15, 24], [25, 28], [29, 36], [37, 39], [40, 41], [42, 50], [51, 53], [54, 55], [56, 64], [65, 71], [72, 75], [76, 79], [80, 88], [88, 90], [91, 104], [104, 105], [106, 108], [109, 112], [113, 121], [122, 123], [124, 130], [131, 141], [142, 149], [150, 154], [155, 158], [159, 167], [168, 176], [177, 181], [182, 189], [190, 195], [195, 196]]}
{"doc_key": "ai-test-53", "ner": [[5, 8, "conference"], [14, 19, "location"], [20, 20, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 8, 14, 19, "physical", "", false, false], [14, 19, 20, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2011", ",", "the", "15th", "Campus", "Party", "Spain", "will", "take", "place", "in", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "In July 2011, the 15th Campus Party Spain will take place in the City of Arts and Sciences in Valencia.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 22], [23, 29], [30, 35], [36, 41], [42, 46], [47, 51], [52, 57], [58, 60], [61, 64], [65, 69], [70, 72], [73, 77], [78, 81], [82, 90], [91, 93], [94, 102], [102, 103]]}
{"doc_key": "ai-test-54", "ner": [[14, 14, "product"], [16, 20, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Often", "this", "is", "only", "possible", "at", "the", "very", "end", "of", "complex", "games", "such", "as", "chess", "or", "go", ",", "as", "it", "is", "not", "computationally", "possible", "to", "look", "ahead", "to", "the", "end", "of", "the", "game", "except", "towards", "the", "end", ",", "and", "instead", "positions", "are", "given", "finite", "values", "as", "an", "estimate", "of", "how", "likely", "they", "are", "to", "lead", "to", "a", "win", "for", "one", "player", "or", "another", "."], "sentence-detokenized": "Often this is only possible at the very end of complex games such as chess or go, as it is not computationally possible to look ahead to the end of the game except towards the end, and instead positions are given finite values as an estimate of how likely they are to lead to a win for one player or another.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 18], [19, 27], [28, 30], [31, 34], [35, 39], [40, 43], [44, 46], [47, 54], [55, 60], [61, 65], [66, 68], [69, 74], [75, 77], [78, 80], [80, 81], [82, 84], [85, 87], [88, 90], [91, 94], [95, 110], [111, 119], [120, 122], [123, 127], [128, 133], [134, 136], [137, 140], [141, 144], [145, 147], [148, 151], [152, 156], [157, 163], [164, 171], [172, 175], [176, 179], [179, 180], [181, 184], [185, 192], [193, 202], [203, 206], [207, 212], [213, 219], [220, 226], [227, 229], [230, 232], [233, 241], [242, 244], [245, 248], [249, 255], [256, 260], [261, 264], [265, 267], [268, 272], [273, 275], [276, 277], [278, 281], [282, 285], [286, 289], [290, 296], [297, 299], [300, 307], [307, 308]]}
{"doc_key": "ai-test-55", "ner": [[4, 6, "algorithm"], [23, 24, "algorithm"], [26, 27, "algorithm"], [30, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 23, 24, "compare", "", false, false], [4, 6, 26, 27, "compare", "", false, false], [4, 6, 30, 32, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "difference", "between", "the", "multinomial", "logit", "model", "and", "many", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "with", "the", "same", "basic", "setup", "(", "perceptron", "algorithm", ",", "support", "vector", "machines", ",", "linear", "discriminant", "analysis", ",", "etc", "."], "sentence-detokenized": "The difference between the multinomial logit model and many other methods, models, algorithms, etc. with the same basic setup (perceptron algorithm, support vector machines, linear discriminant analysis, etc.", "token2charspan": [[0, 3], [4, 14], [15, 22], [23, 26], [27, 38], [39, 44], [45, 50], [51, 54], [55, 59], [60, 65], [66, 73], [73, 74], [75, 81], [81, 82], [83, 93], [93, 94], [95, 99], [100, 104], [105, 108], [109, 113], [114, 119], [120, 125], [126, 127], [127, 137], [138, 147], [147, 148], [149, 156], [157, 163], [164, 172], [172, 173], [174, 180], [181, 193], [194, 202], [202, 203], [204, 207], [207, 208]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "published", "by", "the"], "sentence-detokenized": "Association for Computational Linguistics, published by the", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 52], [53, 55], [56, 59]]}
{"doc_key": "ai-test-57", "ner": [[0, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "a", "computer", "face", "recognition", "system", ",", "each", "face", "is", "represented", "by", "a", "large", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In a computer face recognition system, each face is represented by a large number of pixel values.", "token2charspan": [[0, 2], [3, 4], [5, 13], [14, 18], [19, 30], [31, 37], [37, 38], [39, 43], [44, 48], [49, 51], [52, 63], [64, 66], [67, 68], [69, 74], [75, 81], [82, 84], [85, 90], [91, 97], [97, 98]]}
{"doc_key": "ai-test-58", "ner": [[5, 8, "person"], [9, 11, "organisation"], [18, 19, "country"], [22, 22, "person"], [33, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 8, 9, 11, "role", "", false, false], [5, 8, 18, 19, "physical", "", false, false], [22, 22, 33, 35, "origin", "", false, false], [22, 22, 33, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2002", ",", "his", "son", "Daniel", "Pearl", ",", "a", "Wall", "Street", "Journal", "journalist", ",", "was", "kidnapped", "and", "murdered", "in", "Pakistan", ",", "prompting", "Judea", ",", "other", "family", "members", "and", "friends", "to", "set", "up", "the", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "In 2002, his son Daniel Pearl, a Wall Street Journal journalist, was kidnapped and murdered in Pakistan, prompting Judea, other family members and friends to set up the Daniel Pearl Foundation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 23], [24, 29], [29, 30], [31, 32], [33, 37], [38, 44], [45, 52], [53, 63], [63, 64], [65, 68], [69, 78], [79, 82], [83, 91], [92, 94], [95, 103], [103, 104], [105, 114], [115, 120], [120, 121], [122, 127], [128, 134], [135, 142], [143, 146], [147, 154], [155, 157], [158, 161], [162, 164], [165, 168], [169, 175], [176, 181], [182, 192], [192, 193]]}
{"doc_key": "ai-test-59", "ner": [[4, 6, "organisation"], [17, 18, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 17, 18, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["From", "late", "2006", ",", "Red", "Envelope", "Entertainment", "expanded", "into", "original", "content", "production", ",", "with", "filmmakers", "such", "as", "John", "Waters", "."], "sentence-detokenized": "From late 2006, Red Envelope Entertainment expanded into original content production, with filmmakers such as John Waters.", "token2charspan": [[0, 4], [5, 9], [10, 14], [14, 15], [16, 19], [20, 28], [29, 42], [43, 51], [52, 56], [57, 65], [66, 73], [74, 84], [84, 85], [86, 90], [91, 101], [102, 106], [107, 109], [110, 114], [115, 121], [121, 122]]}
{"doc_key": "ai-test-60", "ner": [[7, 11, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "building", "is", "now", "part", "of", "the", "Beth", "Israel", "Deaconess", "Medical", "Center", "."], "sentence-detokenized": "The building is now part of the Beth Israel Deaconess Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 31], [32, 36], [37, 43], [44, 53], [54, 61], [62, 68], [68, 69]]}
{"doc_key": "ai-test-61", "ner": [[16, 17, "field"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "common", "theme", "of", "these", "works", "is", "the", "application", "of", "a", "phenomenological", "perspective", "to", "issues", "of", "artificial", "intelligence", "and", "knowledge", "representation", "."], "sentence-detokenized": "The common theme of these works is the application of a phenomenological perspective to issues of artificial intelligence and knowledge representation.", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 19], [20, 25], [26, 31], [32, 34], [35, 38], [39, 50], [51, 53], [54, 55], [56, 72], [73, 84], [85, 87], [88, 94], [95, 97], [98, 108], [109, 121], [122, 125], [126, 135], [136, 150], [150, 151]]}
{"doc_key": "ai-test-62", "ner": [[2, 6, "task"], [22, 24, "task"], [44, 45, "task"], [47, 48, "task"], [53, 56, "task"], [58, 58, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [[44, 45, 53, 56, "part-of", "", false, false], [47, 48, 53, 56, "part-of", "", false, false], [53, 56, 22, 24, "type-of", "", false, false], [58, 58, 53, 56, "named", "", false, false]], "relations_mapping_to_source": [4, 5, 6, 7], "sentence": ["The", "term", "neural", "machine", "translation", "(", "NMT", ")", ",", "for", "example", ",", "emphasises", "the", "fact", "that", "deep", "learning", "-", "based", "approaches", "to", "machine", "translation", "learn", "sequence", "-", "to", "-", "sequence", "transformations", "directly", ",", "so", "that", "there", "is", "no", "need", "for", "intermediate", "steps", "such", "as", "word", "alignment", "and", "language", "modelling", ",", "which", "are", "used", "in", "statistical", "machine", "translation", "(", "SMT", ")", "."], "sentence-detokenized": "The term neural machine translation (NMT), for example, emphasises the fact that deep learning-based approaches to machine translation learn sequence-to-sequence transformations directly, so that there is no need for intermediate steps such as word alignment and language modelling, which are used in statistical machine translation (SMT).", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 23], [24, 35], [36, 37], [37, 40], [40, 41], [41, 42], [43, 46], [47, 54], [54, 55], [56, 66], [67, 70], [71, 75], [76, 80], [81, 85], [86, 94], [94, 95], [95, 100], [101, 111], [112, 114], [115, 122], [123, 134], [135, 140], [141, 149], [149, 150], [150, 152], [152, 153], [153, 161], [162, 177], [178, 186], [186, 187], [188, 190], [191, 195], [196, 201], [202, 204], [205, 207], [208, 212], [213, 216], [217, 229], [230, 235], [236, 240], [241, 243], [244, 248], [249, 258], [259, 262], [263, 271], [272, 281], [281, 282], [283, 288], [289, 292], [293, 297], [298, 300], [301, 312], [313, 320], [321, 332], [333, 334], [334, 337], [337, 338], [338, 339]]}
{"doc_key": "ai-test-63", "ner": [[4, 8, "field"], [10, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 8, 10, 11, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "of", "the", "research", "in", "the", "field", "of", "WSD", "uses", "Word", "Net", "as", "a", "reference", "dictionary", "."], "sentence-detokenized": "Most of the research in the field of WSD uses WordNet as a reference dictionary.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 20], [21, 23], [24, 27], [28, 33], [34, 36], [37, 40], [41, 45], [46, 50], [50, 53], [54, 56], [57, 58], [59, 68], [69, 79], [79, 80]]}
{"doc_key": "ai-test-64", "ner": [[11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Notable", "former", "PhD", "students", "and", "postdoctoral", "researchers", "in", "his", "group", "include", "Richard", "Zemel", "and", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Notable former PhD students and postdoctoral researchers in his group include Richard Zemel and Zoubin Ghahramani.", "token2charspan": [[0, 7], [8, 14], [15, 18], [19, 27], [28, 31], [32, 44], [45, 56], [57, 59], [60, 63], [64, 69], [70, 77], [78, 85], [86, 91], [92, 95], [96, 102], [103, 113], [113, 114]]}
{"doc_key": "ai-test-65", "ner": [[6, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Each", "prediction", "result", "or", "instance", "of", "the", "perturbation", "matrix", "represents", "a", "point", "in", "the", "ROC", "space", "."], "sentence-detokenized": "Each prediction result or instance of the perturbation matrix represents a point in the ROC space.", "token2charspan": [[0, 4], [5, 15], [16, 22], [23, 25], [26, 34], [35, 37], [38, 41], [42, 54], [55, 61], [62, 72], [73, 74], [75, 80], [81, 83], [84, 87], [88, 91], [92, 97], [97, 98]]}
{"doc_key": "ai-test-66", "ner": [[3, 3, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [16, 20, "product"], [21, 24, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 21, 24, "physical", "", false, false], [6, 7, 21, 24, "physical", "", false, false], [9, 10, 21, 24, "physical", "", false, false], [16, 20, 3, 3, "artifact", "", false, false], [16, 20, 6, 7, "artifact", "", false, false], [16, 20, 9, 10, "artifact", "", false, false], [16, 20, 21, 24, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1997", ",", "Thrun", "and", "colleagues", "Wolfram", "Burgard", "and", "Dieter", "Fox", "developed", "the", "world", "'s", "first", "robot", "tour", "guide", "at", "the", "Deutsches", "Museum", "in", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "In 1997, Thrun and colleagues Wolfram Burgard and Dieter Fox developed the world's first robot tour guide at the Deutsches Museum in Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 18], [19, 29], [30, 37], [38, 45], [46, 49], [50, 56], [57, 60], [61, 70], [71, 74], [75, 80], [80, 82], [83, 88], [89, 94], [95, 99], [100, 105], [106, 108], [109, 112], [113, 122], [123, 129], [130, 132], [133, 137], [138, 139], [139, 143], [143, 144], [144, 145]]}
{"doc_key": "ai-test-67", "ner": [[0, 1, "product"], [7, 7, "misc"], [20, 22, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 1, "part-of", "", false, false], [20, 22, 0, 1, "usage", "", false, false], [24, 25, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "containing", "semantic", "relationships", "between", "words", "in", "over", "200", "languages.Its", "primary", "uses", "are", "in", "automatic", "natural", "language", "processing", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database containing semantic relationships between words in over 200 languages.Its primary uses are in automatic natural language processing and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 40], [41, 49], [50, 63], [64, 71], [72, 77], [78, 80], [81, 85], [86, 89], [90, 103], [104, 111], [112, 116], [117, 120], [121, 123], [124, 133], [134, 141], [142, 150], [151, 161], [162, 165], [166, 176], [177, 189], [190, 202], [202, 203]]}
{"doc_key": "ai-test-68", "ner": [[2, 7, "field"], [9, 12, "conference"], [15, 23, "conference"], [25, 25, "conference"], [27, 27, "conference"], [35, 36, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 12, 2, 7, "topic", "", false, false], [9, 12, 35, 36, "topic", "", false, false], [15, 23, 2, 7, "topic", "", false, false], [15, 23, 35, 36, "topic", "", false, false], [25, 25, 2, 7, "topic", "", false, false], [25, 25, 35, 36, "topic", "", false, false], [27, 27, 2, 7, "topic", "", false, false], [27, 27, 35, 36, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Conferences", "on", "natural", "language", "processing", ",", "such", "as", "the", "Association", "for", "Computational", "Linguistics", ",", "the", "North", "American", "chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", "and", "HLT", ",", "are", "beginning", "to", "include", "papers", "on", "speech", "processing", "."], "sentence-detokenized": "Conferences on natural language processing, such as the Association for Computational Linguistics, the North American chapter of the Association for Computational Linguistics, EMNLP and HLT, are beginning to include papers on speech processing.", "token2charspan": [[0, 11], [12, 14], [15, 22], [23, 31], [32, 42], [42, 43], [44, 48], [49, 51], [52, 55], [56, 67], [68, 71], [72, 85], [86, 97], [97, 98], [99, 102], [103, 108], [109, 117], [118, 125], [126, 128], [129, 132], [133, 144], [145, 148], [149, 162], [163, 174], [174, 175], [176, 181], [182, 185], [186, 189], [189, 190], [191, 194], [195, 204], [205, 207], [208, 215], [216, 222], [223, 225], [226, 232], [233, 243], [243, 244]]}
{"doc_key": "ai-test-69", "ner": [[18, 20, "misc"], [31, 33, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "number", "of", "Java", "programs", "use", "the", "lexicon", "to", "process", "variations", "of", "biomedical", "texts", "by", "linking", "words", "by", "parts", "of", "speech", ",", "which", "can", "be", "useful", "for", "web", "searching", "or", "searching", "electronic", "medical", "records", "."], "sentence-detokenized": "A number of Java programs use the lexicon to process variations of biomedical texts by linking words by parts of speech, which can be useful for web searching or searching electronic medical records.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 16], [17, 25], [26, 29], [30, 33], [34, 41], [42, 44], [45, 52], [53, 63], [64, 66], [67, 77], [78, 83], [84, 86], [87, 94], [95, 100], [101, 103], [104, 109], [110, 112], [113, 119], [119, 120], [121, 126], [127, 130], [131, 133], [134, 140], [141, 144], [145, 148], [149, 158], [159, 161], [162, 171], [172, 182], [183, 190], [191, 198], [198, 199]]}
{"doc_key": "ai-test-70", "ner": [[7, 7, "algorithm"], [9, 9, "algorithm"], [11, 11, "algorithm"], [13, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Many", "newer", "algorithms", "exist", ",", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", "and", "others", "."], "sentence-detokenized": "Many newer algorithms exist, such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost and others.", "token2charspan": [[0, 4], [5, 10], [11, 21], [22, 27], [27, 28], [29, 33], [34, 36], [37, 44], [44, 45], [46, 56], [56, 57], [58, 68], [68, 69], [70, 77], [77, 78], [79, 88], [89, 92], [93, 99], [99, 100]]}
{"doc_key": "ai-test-71", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "implementation", "in", "Python", ":"], "sentence-detokenized": "This is an example implementation in Python:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 33], [34, 36], [37, 43], [43, 44]]}
{"doc_key": "ai-test-72", "ner": [[0, 0, "organisation"], [2, 2, "product"], [7, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 0, 0, "artifact", "made_by_company", false, false], [7, 9, 2, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mattel", "'s", "Intellivision", "game", "console", "offered", "the", "Intellivoice", "sound", "synthesis", "module", "in", "1982", "."], "sentence-detokenized": "Mattel's Intellivision game console offered the Intellivoice sound synthesis module in 1982.", "token2charspan": [[0, 6], [6, 8], [9, 22], [23, 27], [28, 35], [36, 43], [44, 47], [48, 60], [61, 66], [67, 76], [77, 83], [84, 86], [87, 91], [91, 92]]}
{"doc_key": "ai-test-73", "ner": [[5, 6, "task"], [9, 15, "task"], [17, 18, "field"], [20, 22, "task"], [25, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 15, 5, 6, "part-of", "", false, false], [17, 18, 5, 6, "part-of", "", false, false], [20, 22, 5, 6, "part-of", "", false, false], [25, 29, 20, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "has", "also", "worked", "on", "machine", "translation", ",", "both", "high", "-", "precision", "knowledge", "-", "based", "MT", "and", "machine", "learning", "for", "statistical", "machine", "translation", "(", "e.g.", "generalised", "example", "-", "based", "MT", ")", "."], "sentence-detokenized": "He has also worked on machine translation, both high-precision knowledge-based MT and machine learning for statistical machine translation (e.g. generalised example-based MT).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 21], [22, 29], [30, 41], [41, 42], [43, 47], [48, 52], [52, 53], [53, 62], [63, 72], [72, 73], [73, 78], [79, 81], [82, 85], [86, 93], [94, 102], [103, 106], [107, 118], [119, 126], [127, 138], [139, 140], [140, 144], [145, 156], [157, 164], [164, 165], [165, 170], [171, 173], [173, 174], [174, 175]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [4, 4, "misc"], [19, 20, "algorithm"], [22, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 31, "field"], [33, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 19, 20, "general-affiliation", "", false, false], [0, 1, 22, 23, "general-affiliation", "", false, false], [0, 1, 25, 26, "general-affiliation", "", false, false], [0, 1, 28, 28, "general-affiliation", "", false, false], [0, 1, 30, 31, "general-affiliation", "", false, false], [0, 1, 33, 33, "general-affiliation", "", false, false], [4, 4, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "usually", "Mathematica", ")", "is", "a", "modern", "technical", "computing", "system", "that", "covers", "most", "technical", "fields", "-", "including", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "data", "science", ",", "visualization", "and", "others", "."], "sentence-detokenized": "Wolfram Mathematica (usually Mathematica) is a modern technical computing system that covers most technical fields - including neural networks, machine learning, image processing, geometry, data science, visualization and others.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 28], [29, 40], [40, 41], [42, 44], [45, 46], [47, 53], [54, 63], [64, 73], [74, 80], [81, 85], [86, 92], [93, 97], [98, 107], [108, 114], [115, 116], [117, 126], [127, 133], [134, 142], [142, 143], [144, 151], [152, 160], [160, 161], [162, 167], [168, 178], [178, 179], [180, 188], [188, 189], [190, 194], [195, 202], [202, 203], [204, 217], [218, 221], [222, 228], [228, 229]]}
{"doc_key": "ai-test-75", "ner": [[2, 8, "product"], [10, 12, "researcher"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 2, 8, "type-of", "", false, false], [17, 17, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "digitally", "operated", "and", "programmable", "robot", "was", "invented", "by", "George", "Devol", "in", "1954", "and", "eventually", "named", "Unimate", "."], "sentence-detokenized": "The first digitally operated and programmable robot was invented by George Devol in 1954 and eventually named Unimate.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 28], [29, 32], [33, 45], [46, 51], [52, 55], [56, 64], [65, 67], [68, 74], [75, 80], [81, 83], [84, 88], [89, 92], [93, 103], [104, 109], [110, 117], [117, 118]]}
{"doc_key": "ai-test-76", "ner": [[2, 2, "algorithm"], [4, 4, "algorithm"], [18, 19, "task"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 4, 4, "compare", "", false, false], [4, 4, 18, 19, "general-affiliation", "", false, false], [4, 4, 21, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Similar", "to", "DBNs", ",", "DBMs", "can", "learn", "complex", "and", "abstract", "internal", "representations", "of", "input", "in", "tasks", "such", "as", "object", "recognition", "or", "speech", "recognition", ",", "using", "limited", ",", "labelled", "data", "to", "fine", "-", "tune", "representations", "built", "using", "large", "amounts", "of", "unlabelled", "sensory", "input", "."], "sentence-detokenized": "Similar to DBNs, DBMs can learn complex and abstract internal representations of input in tasks such as object recognition or speech recognition, using limited, labelled data to fine-tune representations built using large amounts of unlabelled sensory input.", "token2charspan": [[0, 7], [8, 10], [11, 15], [15, 16], [17, 21], [22, 25], [26, 31], [32, 39], [40, 43], [44, 52], [53, 61], [62, 77], [78, 80], [81, 86], [87, 89], [90, 95], [96, 100], [101, 103], [104, 110], [111, 122], [123, 125], [126, 132], [133, 144], [144, 145], [146, 151], [152, 159], [159, 160], [161, 169], [170, 174], [175, 177], [178, 182], [182, 183], [183, 187], [188, 203], [204, 209], [210, 215], [216, 221], [222, 229], [230, 232], [233, 243], [244, 251], [252, 257], [257, 258]]}
{"doc_key": "ai-test-77", "ner": [[7, 11, "task"], [0, 0, "conference"], [2, 2, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 7, 11, "topic", "", false, false], [2, 2, 7, 11, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["ICCV", "and", "CVPR", "are", "scientific", "conferences", "where", "vision", "-", "based", "activity", "recognition", "papers", "are", "often", "presented", "."], "sentence-detokenized": "ICCV and CVPR are scientific conferences where vision-based activity recognition papers are often presented.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 17], [18, 28], [29, 40], [41, 46], [47, 53], [53, 54], [54, 59], [60, 68], [69, 80], [81, 87], [88, 91], [92, 97], [98, 107], [107, 108]]}
{"doc_key": "ai-test-78", "ner": [[0, 3, "field"], [4, 6, "algorithm"], [8, 8, "algorithm"], [18, 18, "metrics"], [21, 21, "metrics"], [20, 34, "metrics"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 6, 0, 3, "part-of", "", false, false], [4, 6, 18, 18, "related-to", "finds", false, false], [4, 6, 21, 21, "related-to", "finds", false, false], [4, 6, 38, 39, "related-to", "", false, false], [8, 8, 4, 6, "named", "", false, false], [20, 34, 21, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "statistics", ",", "the", "Expectation", "-", "Maximization", "(", "EM", ")", "algorithm", "is", "an", "iterative", "method", "for", "finding", "maximum", "likelihood", "or", "maximum", "posterior", "(", "MAP", ")", "estimates", "of", "the", "parameters", "of", "statistical", "models", "where", "the", "model", "depends", "on", "unobserved", "latent", "variables", "."], "sentence-detokenized": "In statistics, the Expectation-Maximization (EM) algorithm is an iterative method for finding maximum likelihood or maximum posterior (MAP) estimates of the parameters of statistical models where the model depends on unobserved latent variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 30], [30, 31], [31, 43], [44, 45], [45, 47], [47, 48], [49, 58], [59, 61], [62, 64], [65, 74], [75, 81], [82, 85], [86, 93], [94, 101], [102, 112], [113, 115], [116, 123], [124, 133], [134, 135], [135, 138], [138, 139], [140, 149], [150, 152], [153, 156], [157, 167], [168, 170], [171, 182], [183, 189], [190, 195], [196, 199], [200, 205], [206, 213], [214, 216], [217, 227], [228, 234], [235, 244], [244, 245]]}
{"doc_key": "ai-test-79", "ner": [[7, 9, "metrics"], [8, 14, "metrics"], [15, 17, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 14, 7, 9, "named", "", false, false], [19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Similarly", ",", "investigators", "sometimes", "report", "both", "the", "HAMIS", "positive", "rate", "(", "FPR", ")", "and", "the", "HAMIS", "negative", "rate", "(", "FNR", ")", "."], "sentence-detokenized": "Similarly, investigators sometimes report both the HAMIS positive rate (FPR) and the HAMIS negative rate (FNR).", "token2charspan": [[0, 9], [9, 10], [11, 24], [25, 34], [35, 41], [42, 46], [47, 50], [51, 56], [57, 65], [66, 70], [71, 72], [72, 75], [75, 76], [77, 80], [81, 84], [85, 90], [91, 99], [100, 104], [105, 106], [106, 109], [109, 110], [110, 111]]}
{"doc_key": "ai-test-80", "ner": [[6, 11, "metrics"], [13, 16, "field"], [19, 20, "metrics"], [22, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 16, 6, 11, "usage", "", false, false], [22, 24, 19, 20, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "concept", "is", "similar", "to", "the", "signal", "-", "to", "-", "noise", "ratio", "used", "in", "the", "natural", "sciences", "and", "the", "noise", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "The concept is similar to the signal-to-noise ratio used in the natural sciences and the noise matrix used in artificial intelligence.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 25], [26, 29], [30, 36], [36, 37], [37, 39], [39, 40], [40, 45], [46, 51], [52, 56], [57, 59], [60, 63], [64, 71], [72, 80], [81, 84], [85, 88], [89, 94], [95, 101], [102, 106], [107, 109], [110, 120], [121, 133], [133, 134]]}
{"doc_key": "ai-test-81", "ner": [[24, 26, "field"], [3, 4, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [31, 36, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[24, 26, 3, 4, "general-affiliation", "", false, false], [24, 26, 11, 12, "general-affiliation", "", false, false], [24, 26, 14, 15, "general-affiliation", "", false, false], [31, 36, 24, 26, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Originally", "proposed", "by", "Steve", "Mann", "in", "2004", "and", "further", "developed", "by", "Ray", "Kurzweil", "and", "Marvin", "Minsky", "in", "2013", ",", "the", "Code", "of", "Ethics", "for", "Human", "Augmentation", "was", "finally", "ratified", "at", "the", "Virtual", "Reality", "Conference", "in", "Toronto", "on", "25", "June", "2017", "."], "sentence-detokenized": "Originally proposed by Steve Mann in 2004 and further developed by Ray Kurzweil and Marvin Minsky in 2013, the Code of Ethics for Human Augmentation was finally ratified at the Virtual Reality Conference in Toronto on 25 June 2017.", "token2charspan": [[0, 10], [11, 19], [20, 22], [23, 28], [29, 33], [34, 36], [37, 41], [42, 45], [46, 53], [54, 63], [64, 66], [67, 70], [71, 79], [80, 83], [84, 90], [91, 97], [98, 100], [101, 105], [105, 106], [107, 110], [111, 115], [116, 118], [119, 125], [126, 129], [130, 135], [136, 148], [149, 152], [153, 160], [161, 169], [170, 172], [173, 176], [177, 184], [185, 192], [193, 203], [204, 206], [207, 214], [215, 217], [218, 220], [221, 225], [226, 230], [230, 231]]}
{"doc_key": "ai-test-82", "ner": [[2, 4, "person"], [10, 11, "organisation"], [17, 18, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 4, 10, 11, "role", "directed_for", false, false], [2, 4, 17, 18, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", "Walter", "R.", "Booth", "directed", "10", "films", "for", "the", "British", "Kinoplastikon", ",", "presumably", "in", "collaboration", "with", "Cecil", "Hepworth", "."], "sentence-detokenized": "In 1913 Walter R. Booth directed 10 films for the British Kinoplastikon, presumably in collaboration with Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 17], [18, 23], [24, 32], [33, 35], [36, 41], [42, 45], [46, 49], [50, 57], [58, 71], [71, 72], [73, 83], [84, 86], [87, 100], [101, 105], [106, 111], [112, 120], [120, 121]]}
{"doc_key": "ai-test-83", "ner": [[12, 14, "location"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Their", "new", "robot", "was", "unveiled", "in", "1961", "at", "an", "exhibition", "at", "the", "Cow", "Palace", "in", "Chicago", "."], "sentence-detokenized": "Their new robot was unveiled in 1961 at an exhibition at the Cow Palace in Chicago.", "token2charspan": [[0, 5], [6, 9], [10, 15], [16, 19], [20, 28], [29, 31], [32, 36], [37, 39], [40, 42], [43, 53], [54, 56], [57, 60], [61, 64], [65, 71], [72, 74], [75, 82], [82, 83]]}
{"doc_key": "ai-test-84", "ner": [[6, 7, "task"], [10, 12, "field"], [16, 17, "field"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["While", "some", "chatbot", "applications", "use", "extensive", "word", "classification", "processes", ",", "natural", "language", "processing", "engines", "and", "sophisticated", "artificial", "intelligence", ",", "others", "simply", "search", "for", "generic", "keywords", "and", "generate", "answers", "using", "generic", "phrases", "from", "a", "related", "library", "or", "database", "."], "sentence-detokenized": "While some chatbot applications use extensive word classification processes, natural language processing engines and sophisticated artificial intelligence, others simply search for generic keywords and generate answers using generic phrases from a related library or database.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 31], [32, 35], [36, 45], [46, 50], [51, 65], [66, 75], [75, 76], [77, 84], [85, 93], [94, 104], [105, 112], [113, 116], [117, 130], [131, 141], [142, 154], [154, 155], [156, 162], [163, 169], [170, 176], [177, 180], [181, 188], [189, 197], [198, 201], [202, 210], [211, 218], [219, 224], [225, 232], [233, 240], [241, 245], [246, 247], [248, 255], [256, 263], [264, 266], [267, 275], [275, 276]]}
{"doc_key": "ai-test-85", "ner": [[1, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "WaveNet", "model", "proposed", "in", "2016", "offers", "great", "performance", "in", "terms", "of", "speech", "quality", "."], "sentence-detokenized": "The WaveNet model proposed in 2016 offers great performance in terms of speech quality.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 41], [42, 47], [48, 59], [60, 62], [63, 68], [69, 71], [72, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-test-86", "ner": [[4, 4, "product"], [5, 7, "misc"], [9, 10, "misc"], [12, 17, "misc"], [19, 20, "misc"], [23, 25, "organisation"], [27, 27, "organisation"], [29, 30, "organisation"], [34, 34, "organisation"], [36, 39, "organisation"], [41, 42, "organisation"], [44, 44, "organisation"], [46, 48, "organisation"], [51, 51, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 4, 5, 7, "general-affiliation", "", false, false], [4, 4, 9, 10, "general-affiliation", "", false, false], [4, 4, 12, 17, "general-affiliation", "", false, false], [4, 4, 19, 20, "general-affiliation", "", false, false], [23, 25, 4, 4, "usage", "", false, false], [27, 27, 4, 4, "usage", "", false, false], [29, 30, 4, 4, "usage", "", false, false], [34, 34, 4, 4, "usage", "", false, false], [36, 39, 4, 4, "usage", "", false, false], [41, 42, 4, 4, "usage", "", false, false], [44, 44, 4, 4, "usage", "", false, false], [46, 48, 4, 4, "usage", "", false, false], [51, 51, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organizations", "known", "to", "use", "ALE", "for", "emergency", "management", ",", "disaster", "relief", ",", "day", "-", "to", "-", "day", "communications", "or", "emergency", "response", "include", "the", "American", "Red", "Cross", ",", "FEMA", ",", "Disaster", "Medical", "Assistance", "Teams", ",", "NATO", ",", "Federal", "Bureau", "of", "Investigation", ",", "United", "Nations", ",", "AT&T", ",", "Civil", "Air", "Patrol", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organizations known to use ALE for emergency management, disaster relief, day-to-day communications or emergency response include the American Red Cross, FEMA, Disaster Medical Assistance Teams, NATO, Federal Bureau of Investigation, United Nations, AT&T, Civil Air Patrol, (ARES).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 30], [31, 34], [35, 44], [45, 55], [55, 56], [57, 65], [66, 72], [72, 73], [74, 77], [77, 78], [78, 80], [80, 81], [81, 84], [85, 99], [100, 102], [103, 112], [113, 121], [122, 129], [130, 133], [134, 142], [143, 146], [147, 152], [152, 153], [154, 158], [158, 159], [160, 168], [169, 176], [177, 187], [188, 193], [193, 194], [195, 199], [199, 200], [201, 208], [209, 215], [216, 218], [219, 232], [232, 233], [234, 240], [241, 248], [248, 249], [250, 254], [254, 255], [256, 261], [262, 265], [266, 272], [272, 273], [274, 275], [275, 279], [279, 280], [280, 281]]}
{"doc_key": "ai-test-87", "ner": [[8, 9, "algorithm"], [17, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", ",", "for", "simplicity", ",", "we", "use", "the", "Kronecker", "delta", "(", "cf", ".", "the", "derivative", "of", "the", "sigmoid", "function", "expressed", "by", "the", "function", "itself", ")", "."], "sentence-detokenized": "Here, for simplicity, we use the Kronecker delta (cf. the derivative of the sigmoid function expressed by the function itself).", "token2charspan": [[0, 4], [4, 5], [6, 9], [10, 20], [20, 21], [22, 24], [25, 28], [29, 32], [33, 42], [43, 48], [49, 50], [50, 52], [52, 53], [54, 57], [58, 68], [69, 71], [72, 75], [76, 83], [84, 92], [93, 102], [103, 105], [106, 109], [110, 118], [119, 125], [125, 126], [126, 127]]}
{"doc_key": "ai-test-88", "ner": [[9, 10, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "theory", "is", "philosophically", "based", "and", "was", "founded", "by", "Ray", "Solomonoff", "around", "1960", ".", "Samuel", "Rathmanner", "and", "Marcus", "Hutter", "."], "sentence-detokenized": "The theory is philosophically based and was founded by Ray Solomonoff around 1960. Samuel Rathmanner and Marcus Hutter.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 29], [30, 35], [36, 39], [40, 43], [44, 51], [52, 54], [55, 58], [59, 69], [70, 76], [77, 81], [81, 82], [83, 89], [90, 100], [101, 104], [105, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [8, 11, "misc"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 11, "type-of", "", false, false], [0, 0, 14, 15, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "a", "freely", "accessible", "database", "originally", "designed", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "has", "been", "extended", "with", "definitions", "and", "can", "now", "be", "considered", "a", "dictionary", "."], "sentence-detokenized": "WordNet, a freely accessible database originally designed as a semantic network based on psycholinguistic principles, has been extended with definitions and can now be considered a dictionary.", "token2charspan": [[0, 7], [7, 8], [9, 10], [11, 17], [18, 28], [29, 37], [38, 48], [49, 57], [58, 60], [61, 62], [63, 71], [72, 79], [80, 85], [86, 88], [89, 105], [106, 116], [116, 117], [118, 121], [122, 126], [127, 135], [136, 140], [141, 152], [153, 156], [157, 160], [161, 164], [165, 167], [168, 178], [179, 180], [181, 191], [191, 192]]}
{"doc_key": "ai-test-90", "ner": [[2, 3, "field"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 2, 3, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Progress", "in", "computational", "imaging", "research", "is", "presented", "in", "several", "venues", ",", "including", "SIGGRAPH", "and", "."], "sentence-detokenized": "Progress in computational imaging research is presented in several venues, including SIGGRAPH and.", "token2charspan": [[0, 8], [9, 11], [12, 25], [26, 33], [34, 42], [43, 45], [46, 55], [56, 58], [59, 66], [67, 73], [73, 74], [75, 84], [85, 93], [94, 97], [97, 98]]}
{"doc_key": "ai-test-91", "ner": [[0, 2, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 2, "part-of", "", false, false], [12, 13, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "understood", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multiclass", "classification", "."], "sentence-detokenized": "Classification can be understood as two separate problems - binary classification and multiclass classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 96], [97, 111], [111, 112]]}
{"doc_key": "ai-test-92", "ner": [[11, 11, "algorithm"], [16, 16, "algorithm"], [20, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 16, 11, 11, "type-of", "", false, false], [20, 20, 16, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Advanced", "gene", "finders", "of", "prokaryotic", "and", "eukaryotic", "genomes", "usually", "use", "complex", "probabilistic", "models", ",", "such", "as", "hidden", "Markov", "models", "(", "HMM", ")", ",", "to", "combine", "information", "from", "different", "signal", "and", "content", "measurements", "."], "sentence-detokenized": "Advanced gene finders of prokaryotic and eukaryotic genomes usually use complex probabilistic models, such as hidden Markov models (HMM), to combine information from different signal and content measurements.", "token2charspan": [[0, 8], [9, 13], [14, 21], [22, 24], [25, 36], [37, 40], [41, 51], [52, 59], [60, 67], [68, 71], [72, 79], [80, 93], [94, 100], [100, 101], [102, 106], [107, 109], [110, 116], [117, 123], [124, 130], [131, 132], [132, 135], [135, 136], [136, 137], [138, 140], [141, 148], [149, 160], [161, 165], [166, 175], [176, 182], [183, 186], [187, 194], [195, 207], [207, 208]]}
{"doc_key": "ai-test-93", "ner": [[0, 1, "misc"], [3, 4, "misc"], [8, 9, "field"], [12, 13, "algorithm"], [17, 17, "algorithm"], [20, 20, "algorithm"], [30, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 8, 9, "part-of", "", false, false], [0, 1, 12, 13, "usage", "", false, false], [3, 4, 0, 1, "named", "", false, false], [17, 17, 0, 1, "origin", "", true, false], [20, 20, 17, 17, "named", "", false, false], [30, 31, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Neuro", "-evolution", "or", "neuro-evolution", "is", "a", "form", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "create", "artificial", "neural", "networks", "(", "ANNs", ")", ",", "parameters", ",", "topology", "and", "rules", ".", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuro-evolution or neuro-evolution is a form of artificial intelligence that uses evolutionary algorithms to create artificial neural networks (ANNs), parameters, topology and rules. and evolutionary robotics.", "token2charspan": [[0, 5], [5, 15], [16, 18], [19, 34], [35, 37], [38, 39], [40, 44], [45, 47], [48, 58], [59, 71], [72, 76], [77, 81], [82, 94], [95, 105], [106, 108], [109, 115], [116, 126], [127, 133], [134, 142], [143, 144], [144, 148], [148, 149], [149, 150], [151, 161], [161, 162], [163, 171], [172, 175], [176, 181], [181, 182], [183, 186], [187, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [6, 6, "metrics"], [8, 8, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "IBM", "proposed", "and", "implemented", "the", "BLEU", "system", "Papineni", "et", "al", "."], "sentence-detokenized": "Since IBM proposed and implemented the BLEU system Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 34], [35, 38], [39, 43], [44, 50], [51, 59], [60, 62], [63, 65], [65, 66]]}
{"doc_key": "ai-test-95", "ner": [[13, 16, "conference"], [10, 18, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 18, 13, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "experts", "attended", "a", "conference", "organised", "by", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "to", "discuss", "whether", "computers", "and", "robots", "will", "be", "able", "to", "gain", "autonomy", "and", "how", "much", "of", "a", "threat", "or", "danger", "these", "capabilities", "could", "pose", "."], "sentence-detokenized": "In 2009, experts attended a conference organised by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether computers and robots will be able to gain autonomy and how much of a threat or danger these capabilities could pose.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 25], [26, 27], [28, 38], [39, 48], [49, 51], [52, 55], [56, 67], [68, 71], [72, 75], [76, 87], [88, 90], [91, 101], [102, 114], [115, 116], [116, 120], [120, 121], [122, 124], [125, 132], [133, 140], [141, 150], [151, 154], [155, 161], [162, 166], [167, 169], [170, 174], [175, 177], [178, 182], [183, 191], [192, 195], [196, 199], [200, 204], [205, 207], [208, 209], [210, 216], [217, 219], [220, 226], [227, 232], [233, 245], [246, 251], [252, 256], [256, 257]]}
{"doc_key": "ai-test-96", "ner": [[22, 23, "researcher"], [25, 26, "researcher"], [28, 33, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[28, 33, 22, 23, "artifact", "", false, false], [28, 33, 25, 26, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["After", "amplification", ",", "a", "classifier", "built", "from", "200", "features", "could", "produce", "a", "95", "%", "recognition", "rate", "^", "{", "-", "5", "}", "/", "P.", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "After amplification, a classifier built from 200 features could produce a 95% recognition rate ^ {-5} / P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 19], [19, 20], [21, 22], [23, 33], [34, 39], [40, 44], [45, 48], [49, 57], [58, 63], [64, 71], [72, 73], [74, 76], [76, 77], [78, 89], [90, 94], [95, 96], [97, 98], [98, 99], [99, 100], [100, 101], [102, 103], [104, 106], [107, 112], [112, 113], [114, 116], [117, 122], [122, 123], [124, 130], [131, 135], [135, 136], [136, 140], [141, 147], [148, 157], [157, 158], [159, 163], [163, 164]]}
{"doc_key": "ai-test-97", "ner": [[9, 9, "organisation"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "website", "was", "originally", "Perl", "-", "based", ",", "but", "IMDb", "no", "longer", "discloses", "what", "software", "it", "uses", "for", "security", "reasons", "."], "sentence-detokenized": "The website was originally Perl-based, but IMDb no longer discloses what software it uses for security reasons.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 26], [27, 31], [31, 32], [32, 37], [37, 38], [39, 42], [43, 47], [48, 50], [51, 57], [58, 67], [68, 72], [73, 81], [82, 84], [85, 89], [90, 93], [94, 102], [103, 110], [110, 111]]}
{"doc_key": "ai-test-98", "ner": [[5, 6, "researcher"], [8, 9, "researcher"], [2, 12, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "startup", "was", "founded", "by", "Demis", "Hassabis", ",", "Shane", "Legg", "and", "Mustafa", "Suleyman", "in", "2010", "."], "sentence-detokenized": "The startup was founded by Demis Hassabis, Shane Legg and Mustafa Suleyman in 2010.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 32], [33, 41], [41, 42], [43, 48], [49, 53], [54, 57], [58, 65], [66, 74], [75, 77], [78, 82], [82, 83]]}
{"doc_key": "ai-test-99", "ner": [[4, 5, "misc"], [8, 10, "metrics"], [25, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 4, 5, "type-of", "", false, false], [25, 26, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "very", "commonly", "used", "loss", "functions", "are", "the", "mean", "squared", "error", ",", "mathL", "(", "a", ")", "=", "a", "^", "2", "/", "math", ",", "and", "the", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Two very commonly used loss functions are the mean squared error, mathL (a) = a ^ 2 / math, and the absolute loss, mathL (a) = | a | / math.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 27], [28, 37], [38, 41], [42, 45], [46, 50], [51, 58], [59, 64], [64, 65], [66, 71], [72, 73], [73, 74], [74, 75], [76, 77], [78, 79], [80, 81], [82, 83], [84, 85], [86, 90], [90, 91], [92, 95], [96, 99], [100, 108], [109, 113], [113, 114], [115, 120], [121, 122], [122, 123], [123, 124], [125, 126], [127, 128], [129, 130], [131, 132], [133, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-test-100", "ner": [[3, 5, "algorithm"], [14, 15, "algorithm"], [13, 19, "algorithm"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 14, 15, "type-of", "example_of", false, false], [14, 15, 20, 21, "related-to", "", false, false], [13, 19, 14, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "soft", "-margin", "support", "vector", "machine", "described", "above", "is", "an", "example", "of", "an", "empirical", "risk", "minimization", "(", "ERM", ")", "for", "hinge", "loss", "."], "sentence-detokenized": "The soft-margin support vector machine described above is an example of an empirical risk minimization (ERM) for hinge loss.", "token2charspan": [[0, 3], [4, 8], [8, 15], [16, 23], [24, 30], [31, 38], [39, 48], [49, 54], [55, 57], [58, 60], [61, 68], [69, 71], [72, 74], [75, 84], [85, 89], [90, 102], [103, 104], [104, 107], [107, 108], [109, 112], [113, 118], [119, 123], [123, 124]]}
{"doc_key": "ai-test-101", "ner": [[2, 2, "field"], [0, 0, "task"], [8, 13, "task"], [21, 21, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 13, 2, 2, "origin", "", false, false], [8, 13, 0, 0, "type-of", "", false, false], [21, 21, 8, 13, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["MT", "'s", "deep", "learning", "-", "based", "approach", ",", "neural", "machine", "translation", ",", "has", "made", "rapid", "progress", "in", "recent", "years", ",", "and", "Google", "has", "announced", "that", "its", "translation", "services", "now", "use", "this", "technology", "instead", "of", "the", "statistical", "methods", "of", "the", "past", "."], "sentence-detokenized": "MT's deep learning-based approach, neural machine translation, has made rapid progress in recent years, and Google has announced that its translation services now use this technology instead of the statistical methods of the past.", "token2charspan": [[0, 2], [2, 4], [5, 9], [10, 18], [18, 19], [19, 24], [25, 33], [33, 34], [35, 41], [42, 49], [50, 61], [61, 62], [63, 66], [67, 71], [72, 77], [78, 86], [87, 89], [90, 96], [97, 102], [102, 103], [104, 107], [108, 114], [115, 118], [119, 128], [129, 133], [134, 137], [138, 149], [150, 158], [159, 162], [163, 166], [167, 171], [172, 182], [183, 190], [191, 193], [194, 197], [198, 209], [210, 217], [218, 220], [221, 224], [225, 229], [229, 230]]}
{"doc_key": "ai-test-102", "ner": [[14, 14, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "usually", "results", "in", "very", "large", "performance", "gains", "when", "working", "with", "large", "corpora", "like", "WordNet", "."], "sentence-detokenized": "This usually results in very large performance gains when working with large corpora like WordNet.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 23], [24, 28], [29, 34], [35, 46], [47, 52], [53, 57], [58, 65], [66, 70], [71, 76], [77, 84], [85, 89], [90, 97], [97, 98]]}
{"doc_key": "ai-test-103", "ner": [[0, 1, "task"], [4, 5, "field"], [18, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 18, 20, "part-of", "", false, false], [18, 20, 4, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Face", "recognition", "is", "used", "in", "biometrics", ",", "often", "as", "part", "of", "(", "or", "in", "combination", "with", ")", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Face recognition is used in biometrics, often as part of (or in combination with) a facial recognition system.", "token2charspan": [[0, 4], [5, 16], [17, 19], [20, 24], [25, 27], [28, 38], [38, 39], [40, 45], [46, 48], [49, 53], [54, 56], [57, 58], [58, 60], [61, 63], [64, 75], [76, 80], [80, 81], [82, 83], [84, 90], [91, 102], [103, 109], [109, 110]]}
{"doc_key": "ai-test-104", "ner": [[1, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["trained", "with", "maximum", "likelihood", "estimation", "."], "sentence-detokenized": "trained with maximum likelihood estimation.", "token2charspan": [[0, 7], [8, 12], [13, 20], [21, 31], [32, 42], [42, 43]]}
{"doc_key": "ai-test-105", "ner": [[2, 3, "country"], [5, 9, "organisation"], [12, 13, "location"], [15, 15, "country"], [17, 20, "organisation"], [21, 24, "country"], [28, 28, "organisation"], [32, 34, "organisation"], [36, 36, "country"], [47, 51, "organisation"], [52, 53, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 9, 12, 13, "physical", "", false, false], [12, 13, 15, 15, "physical", "", false, false], [17, 20, 21, 24, "physical", "", false, false], [32, 34, 36, 36, "physical", "", false, false], [47, 51, 52, 53, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd", ".", "in", "Thailand", ";", "Komatsu", "(", "Shanghai", ")", "Ltd.", "in", "1996", "in", "Shanghai", ",", "China", ";", "Industrial", "Power", "Alliance", "Ltd.", "in", "Japan", ",", "a", "joint", "venture", "with", "Cummins", "in", "1998", ";", "L&T-", "Komatsu", "Limited", "in", "India", "in", "1998", "(", "shares", "sold", "in", "2013", ")", ";", "and", "Komatsu", "Brasil", "International", "Ltda", ".", "Brazil", "in", "1998", "."], "sentence-detokenized": "Ltd. in Thailand; Komatsu (Shanghai) Ltd. in 1996 in Shanghai, China; Industrial Power Alliance Ltd. in Japan, a joint venture with Cummins in 1998; L&T-Komatsu Limited in India in 1998 (shares sold in 2013); and Komatsu Brasil International Ltda. Brazil in 1998.", "token2charspan": [[0, 3], [3, 4], [5, 7], [8, 16], [16, 17], [18, 25], [26, 27], [27, 35], [35, 36], [37, 41], [42, 44], [45, 49], [50, 52], [53, 61], [61, 62], [63, 68], [68, 69], [70, 80], [81, 86], [87, 95], [96, 100], [101, 103], [104, 109], [109, 110], [111, 112], [113, 118], [119, 126], [127, 131], [132, 139], [140, 142], [143, 147], [147, 148], [149, 153], [153, 160], [161, 168], [169, 171], [172, 177], [178, 180], [181, 185], [186, 187], [187, 193], [194, 198], [199, 201], [202, 206], [206, 207], [207, 208], [209, 212], [213, 220], [221, 227], [228, 241], [242, 246], [246, 247], [248, 254], [255, 257], [258, 262], [262, 263]]}
{"doc_key": "ai-test-106", "ner": [[0, 1, "organisation"], [5, 6, "misc"], [11, 12, "person"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[11, 12, 0, 1, "physical", "", false, false], [11, 12, 5, 6, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "dgp", "also", "occasionally", "hosts", "resident", "artists", "(", "e.g.", "Oscar-", "winner", "Chris", "Landreth", "."], "sentence-detokenized": "The dgp also occasionally hosts resident artists (e.g. Oscar-winner Chris Landreth.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 25], [26, 31], [32, 40], [41, 48], [49, 50], [50, 54], [55, 61], [61, 67], [68, 73], [74, 82], [82, 83]]}
{"doc_key": "ai-test-107", "ner": [[7, 9, "misc"], [12, 14, "misc"], [17, 20, "misc"], [24, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "currently", "includes", "four", "sub-competitions", ":", "the", "RoboMaster", "Robotics", "Competition", ",", "the", "RoboMaster", "Technical", "Challenge", ",", "the", "ICRA", "RoboMaster", "AI", "Challenge", "and", "the", "new", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "It currently includes four sub-competitions: the RoboMaster Robotics Competition, the RoboMaster Technical Challenge, the ICRA RoboMaster AI Challenge and the new RoboMaster Youth Tournament.", "token2charspan": [[0, 2], [3, 12], [13, 21], [22, 26], [27, 43], [43, 44], [45, 48], [49, 59], [60, 68], [69, 80], [80, 81], [82, 85], [86, 96], [97, 106], [107, 116], [116, 117], [118, 121], [122, 126], [127, 137], [138, 140], [141, 150], [151, 154], [155, 158], [159, 162], [163, 173], [174, 179], [180, 190], [190, 191]]}
{"doc_key": "ai-test-108", "ner": [[7, 8, "field"], [13, 17, "algorithm"], [21, 22, "algorithm"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 21, 22, "usage", "", false, false], [7, 8, 24, 25, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["By", "the", "early", "2000s", ",", "the", "dominant", "speech", "processing", "strategy", "began", "to", "shift", "from", "the", "hidden", "Markov", "model", "towards", "more", "modern", "neural", "networks", "and", "deep", "learning", "."], "sentence-detokenized": "By the early 2000s, the dominant speech processing strategy began to shift from the hidden Markov model towards more modern neural networks and deep learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 18], [18, 19], [20, 23], [24, 32], [33, 39], [40, 50], [51, 59], [60, 65], [66, 68], [69, 74], [75, 79], [80, 83], [84, 90], [91, 97], [98, 103], [104, 111], [112, 116], [117, 123], [124, 130], [131, 139], [140, 143], [144, 148], [149, 157], [157, 158]]}
{"doc_key": "ai-test-109", "ner": [[3, 7, "misc"], [11, 13, "metrics"], [16, 18, "metrics"], [25, 27, "metrics"], [30, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 13, 16, 18, "related-to", "equal", false, false], [25, 27, 30, 32, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "equivalent", "expression", "for", "a", "binary", "target", "ratio", "is", "that", "the", "IGAZ", "positive", "ratio", "and", "the", "HAMIS", "positive", "ratio", "are", "equal", "(", "and", "therefore", "the", "HAMIS", "negative", "ratio", "and", "the", "IGAZ", "negative", "ratio", "are", "equal", ")", "for", "all", "values", "of", "the", "sensitive", "characteristics", ":"], "sentence-detokenized": "Another equivalent expression for a binary target ratio is that the IGAZ positive ratio and the HAMIS positive ratio are equal (and therefore the HAMIS negative ratio and the IGAZ negative ratio are equal) for all values of the sensitive characteristics:", "token2charspan": [[0, 7], [8, 18], [19, 29], [30, 33], [34, 35], [36, 42], [43, 49], [50, 55], [56, 58], [59, 63], [64, 67], [68, 72], [73, 81], [82, 87], [88, 91], [92, 95], [96, 101], [102, 110], [111, 116], [117, 120], [121, 126], [127, 128], [128, 131], [132, 141], [142, 145], [146, 151], [152, 160], [161, 166], [167, 170], [171, 174], [175, 179], [180, 188], [189, 194], [195, 198], [199, 204], [204, 205], [206, 209], [210, 213], [214, 220], [221, 223], [224, 227], [228, 237], [238, 253], [253, 254]]}
{"doc_key": "ai-test-110", "ner": [[1, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "MATLAB", "function", ","], "sentence-detokenized": "The MATLAB function,", "token2charspan": [[0, 3], [4, 10], [11, 19], [19, 20]]}
{"doc_key": "ai-test-111", "ner": [[1, 4, "product"], [18, 19, "product"]], "ner_mapping_to_source": [0, 2], "relations": [[18, 19, 1, 4, "type-of", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["An", "articulated", "robot", "is", "a", "robot", "that", "has", "a", "rotary", "joint", "(", "e.g.", "a", "legged", "robot", "or", "an", "industrial", "robot", ")", "."], "sentence-detokenized": "An articulated robot is a robot that has a rotary joint (e.g. a legged robot or an industrial robot).", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 23], [24, 25], [26, 31], [32, 36], [37, 40], [41, 42], [43, 49], [50, 55], [56, 57], [57, 61], [62, 63], [64, 70], [71, 76], [77, 79], [80, 82], [83, 93], [94, 99], [99, 100], [100, 101]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [5, 6, "product"], [8, 9, "product"], [13, 13, "misc"], [17, 19, "product"], [26, 31, "misc"], [32, 32, "location"], [33, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 13, 13, "general-affiliation", "nationality", false, false], [0, 0, 26, 31, "usage", "", false, false], [0, 0, 32, 32, "physical", "", false, false], [5, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [32, 32, 33, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "also", "known", "as", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "an", "American", "music", "streaming", "and", "automatic", "recommendation", "system", "internet", "radio", "service", "operated", "by", "the", "Music", "Genome", "Project", ",", "based", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (also known as Pandora Media or Pandora Radio) is an American music streaming and automatic recommendation system internet radio service operated by the Music Genome Project, based in Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 30], [31, 36], [37, 39], [40, 47], [48, 53], [53, 54], [55, 57], [58, 60], [61, 69], [70, 75], [76, 85], [86, 89], [90, 99], [100, 114], [115, 121], [122, 130], [131, 136], [137, 144], [145, 153], [154, 156], [157, 160], [161, 166], [167, 173], [174, 181], [181, 182], [183, 188], [189, 191], [192, 199], [199, 200], [201, 211], [211, 212]]}
{"doc_key": "ai-test-113", "ner": [[8, 12, "organisation"], [17, 19, "organisation"], [24, 25, "conference"], [40, 40, "conference"], [42, 42, "conference"], [44, 44, "conference"], [46, 46, "conference"], [48, 48, "conference"], [50, 50, "conference"], [52, 52, "conference"], [54, 54, "conference"], [56, 56, "conference"], [59, 59, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "served", "as", "a", "board", "member", "of", "the", "International", "Machine", "Learning", "Society", ",", "member", "of", "the", "AAAI", "Executive", "Council", ",", "co-chair", "of", "the", "ICML", "2011", "PC", ",", "and", "has", "served", "as", "a", "senior", "PC", "member", "of", "conferences", "such", "as", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", ",", "and", "WWW", "."], "sentence-detokenized": "He has served as a board member of the International Machine Learning Society, member of the AAAI Executive Council, co-chair of the ICML 2011 PC, and has served as a senior PC member of conferences such as AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM, and WWW.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 18], [19, 24], [25, 31], [32, 34], [35, 38], [39, 52], [53, 60], [61, 69], [70, 77], [77, 78], [79, 85], [86, 88], [89, 92], [93, 97], [98, 107], [108, 115], [115, 116], [117, 125], [126, 128], [129, 132], [133, 137], [138, 142], [143, 145], [145, 146], [147, 150], [151, 154], [155, 161], [162, 164], [165, 166], [167, 173], [174, 176], [177, 183], [184, 186], [187, 198], [199, 203], [204, 206], [207, 211], [211, 212], [213, 217], [217, 218], [219, 224], [224, 225], [226, 230], [230, 231], [232, 235], [235, 236], [237, 243], [243, 244], [245, 248], [248, 249], [250, 254], [254, 255], [256, 260], [260, 261], [262, 265], [266, 269], [269, 270]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [8, 10, "organisation"], [5, 12, "organisation"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 8, 10, "role", "", false, false], [5, 12, 8, 10, "named", "", false, false], [16, 16, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "developed", "the", "Robocrane", ",", "where", "the", "platform", "hangs", "on", "six", "cables", "instead", "of", "being", "supported", "by", "six", "connectors", "."], "sentence-detokenized": "James S. Albus of the National Institute of Standards and Technology (NIST) developed the Robocrane, where the platform hangs on six cables instead of being supported by six connectors.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [74, 75], [76, 85], [86, 89], [90, 99], [99, 100], [101, 106], [107, 110], [111, 119], [120, 125], [126, 128], [129, 132], [133, 139], [140, 147], [148, 150], [151, 156], [157, 166], [167, 169], [170, 173], [174, 184], [184, 185]]}
{"doc_key": "ai-test-115", "ner": [[3, 5, "algorithm"], [8, 9, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 5, "type-of", "", false, false], [13, 14, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "class", "of", "direct", "search", "algorithms", "are", "various", "evolutionary", "algorithms", ",", "such", "as", "genetic", "algorithms", "."], "sentence-detokenized": "Another class of direct search algorithms are various evolutionary algorithms, such as genetic algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 23], [24, 30], [31, 41], [42, 45], [46, 53], [54, 66], [67, 77], [77, 78], [79, 83], [84, 86], [87, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-test-116", "ner": [[0, 2, "organisation"], [3, 3, "misc"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 2, "named", "", false, false], [6, 7, 0, 2, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "industrial", "robots", "and", "factory", "automation", "solutions", "."], "sentence-detokenized": "KUKA is a German manufacturer of industrial robots and factory automation solutions.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-117", "ner": [[3, 4, "misc"], [10, 10, "person"], [13, 19, "misc"], [21, 21, "person"], [24, 24, "misc"], [26, 26, "person"], [29, 30, "misc"], [32, 33, "person"], [35, 37, "misc"], [39, 40, "person"], [43, 46, "misc"], [48, 48, "person"], [51, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[10, 10, 3, 4, "usage", "", false, false], [13, 19, 10, 10, "artifact", "", false, false], [21, 21, 3, 4, "usage", "", false, false], [24, 24, 21, 21, "artifact", "", false, false], [26, 26, 3, 4, "usage", "", false, false], [29, 30, 26, 26, "artifact", "", false, false], [32, 33, 3, 4, "usage", "", false, false], [35, 37, 32, 33, "artifact", "", false, false], [39, 40, 3, 4, "usage", "", false, false], [43, 46, 39, 40, "artifact", "", false, false], [48, 48, 3, 4, "usage", "", false, false], [51, 54, 48, 48, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Other", "films", "shot", "on", "IMAX", "between", "2016", "and", "2020", "include", "Zack", "Snyder", "'s", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", ",", "Clint", "Eastwood", "'s", "Sully", ",", "Damien", "Chazelle", "'s", "First", "Man", ",", "Patty", "Jenkins", "'", "Wonder", "Woman", "1984", ",", "Cary", "Joji", "Fukunaga", "'s", "No", "Time", "to", "Die", "and", "Joseph", "Kosinski", "'s", "Top", "Gun", ":", "Maverick", "."], "sentence-detokenized": "Other films shot on IMAX between 2016 and 2020 include Zack Snyder's Batman v Superman: Dawn of Justice, Clint Eastwood's Sully, Damien Chazelle's First Man, Patty Jenkins' Wonder Woman 1984, Cary Joji Fukunaga's No Time to Die and Joseph Kosinski's Top Gun: Maverick.", "token2charspan": [[0, 5], [6, 11], [12, 16], [17, 19], [20, 24], [25, 32], [33, 37], [38, 41], [42, 46], [47, 54], [55, 59], [60, 66], [66, 68], [69, 75], [76, 77], [78, 86], [86, 87], [88, 92], [93, 95], [96, 103], [103, 104], [105, 110], [111, 119], [119, 121], [122, 127], [127, 128], [129, 135], [136, 144], [144, 146], [147, 152], [153, 156], [156, 157], [158, 163], [164, 171], [171, 172], [173, 179], [180, 185], [186, 190], [190, 191], [192, 196], [197, 201], [202, 210], [210, 212], [213, 215], [216, 220], [221, 223], [224, 227], [228, 231], [232, 238], [239, 247], [247, 249], [250, 253], [254, 257], [257, 258], [259, 267], [267, 268]]}
{"doc_key": "ai-test-118", "ner": [[0, 1, "misc"], [4, 8, "organisation"], [10, 12, "organisation"], [28, 30, "country"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[4, 8, 0, 1, "usage", "", false, false], [4, 8, 28, 30, "physical", "", false, false], [10, 12, 4, 8, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["MICR", "E13B", "was", "presented", "to", "the", "American", "Bankers", "Association", "(", "ABA", ")", "in", "July", "1956", ",", "which", "adopted", "it", "as", "the", "MICR", "standard", "for", "negotiable", "documents", "in", "the", "United", "States", "in", "1958", "."], "sentence-detokenized": "MICR E13B was presented to the American Bankers Association (ABA) in July 1956, which adopted it as the MICR standard for negotiable documents in the United States in 1958.", "token2charspan": [[0, 4], [5, 9], [10, 13], [14, 23], [24, 26], [27, 30], [31, 39], [40, 47], [48, 59], [60, 61], [61, 64], [64, 65], [66, 68], [69, 73], [74, 78], [78, 79], [80, 85], [86, 93], [94, 96], [97, 99], [100, 103], [104, 108], [109, 117], [118, 121], [122, 132], [133, 142], [143, 145], [146, 149], [150, 156], [157, 163], [164, 166], [167, 171], [171, 172]]}
{"doc_key": "ai-test-119", "ner": [[0, 2, "misc"], [15, 16, "field"], [20, 21, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 16, 0, 2, "usage", "", false, false], [20, 21, 15, 16, "part-of", "", false, false], [24, 24, 0, 2, "usage", "", false, false], [26, 27, 0, 2, "usage", "", false, false], [29, 29, 0, 2, "usage", "", false, false], [31, 31, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "are", "widely", "applied", "to", "many", "difficult", "computational", "problems", ",", "including", "problems", "in", "computer", "science", "(", "in", "particular", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms are widely applied to many difficult computational problems, including problems in computer science (in particular artificial intelligence), mathematics, operations research, engineering and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 27], [28, 34], [35, 42], [43, 45], [46, 50], [51, 60], [61, 74], [75, 83], [83, 84], [85, 94], [95, 103], [104, 106], [107, 115], [116, 123], [124, 125], [125, 127], [128, 138], [139, 149], [150, 162], [162, 163], [163, 164], [165, 176], [176, 177], [178, 188], [189, 197], [197, 198], [199, 210], [211, 214], [215, 229], [229, 230]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [9, 9, "location"], [11, 11, "country"], [15, 15, "country"], [23, 24, "algorithm"], [21, 26, "algorithm"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 9, 9, "physical", "", false, false], [0, 1, 15, 15, "general-affiliation", "nationality", false, false], [0, 1, 23, 24, "general-affiliation", "topic_of_study", false, false], [0, 1, 21, 26, "general-affiliation", "topic_of_study", false, false], [9, 9, 11, 11, "physical", "", false, false], [21, 26, 27, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "born", "September", "3", ",", "1947", ",", "Wallersdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "has", "studied", "the", "use", "of", "bounded", "rationality", "and", "heuristics", "in", "decision", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (born September 3, 1947, Wallersdorf, Germany) is a German psychologist who has studied the use of bounded rationality and heuristics in decision making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 21], [22, 31], [32, 33], [33, 34], [35, 39], [39, 40], [41, 52], [52, 53], [54, 61], [61, 62], [63, 65], [66, 67], [68, 74], [75, 87], [88, 91], [92, 95], [96, 103], [104, 107], [108, 111], [112, 114], [115, 122], [123, 134], [135, 138], [139, 149], [150, 152], [153, 161], [162, 168], [168, 169]]}
{"doc_key": "ai-test-121", "ner": [[3, 6, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["to", "minimise", "the", "root", "mean", "square", "error", "."], "sentence-detokenized": "to minimise the root mean square error.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [21, 25], [26, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-test-122", "ner": [[13, 14, "misc"], [15, 18, "organisation"], [28, 36, "field"], [48, 50, "misc"], [56, 59, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 14, 15, 18, "origin", "", false, false], [48, 50, 56, 59, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["But", "even", "a", "formal", "language", "that", "has", "a", "regulatory", "academy", ",", "such", "as", "standard", "French", "with", "the", "Acad\u00e9mie", "fran\u00e7aise", ",", "is", "a", "natural", "language", "(", "for", "example", ",", "in", "the", "field", "of", "natural", "language", "processing", ")", "because", "its", "prescriptive", "points", "do", "not", "make", "it", "sufficiently", "constructed", "to", "be", "a", "constructed", "language", "or", "sufficiently", "regulated", "to", "be", "a", "regulated", "natural", "language", "."], "sentence-detokenized": "But even a formal language that has a regulatory academy, such as standard French with the Acad\u00e9mie fran\u00e7aise, is a natural language (for example, in the field of natural language processing) because its prescriptive points do not make it sufficiently constructed to be a constructed language or sufficiently regulated to be a regulated natural language.", "token2charspan": [[0, 3], [4, 8], [9, 10], [11, 17], [18, 26], [27, 31], [32, 35], [36, 37], [38, 48], [49, 56], [56, 57], [58, 62], [63, 65], [66, 74], [75, 81], [82, 86], [87, 90], [91, 99], [100, 109], [109, 110], [111, 113], [114, 115], [116, 123], [124, 132], [133, 134], [134, 137], [138, 145], [145, 146], [147, 149], [150, 153], [154, 159], [160, 162], [163, 170], [171, 179], [180, 190], [190, 191], [192, 199], [200, 203], [204, 216], [217, 223], [224, 226], [227, 230], [231, 235], [236, 238], [239, 251], [252, 263], [264, 266], [267, 269], [270, 271], [272, 283], [284, 292], [293, 295], [296, 308], [309, 318], [319, 321], [322, 324], [325, 326], [327, 336], [337, 344], [345, 353], [353, 354]]}
{"doc_key": "ai-test-123", "ner": [[11, 11, "metrics"], [17, 17, "metrics"], [34, 38, "metrics"]], "ner_mapping_to_source": [0, 2, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "a", "number", "of", "other", "measures", ",", "the", "simplest", "being", "accuracy", "or", "the", "Correct-", "Confraction", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "all", "instances", "correctly", "categorised", ";", "its", "complement", "is", "the", "Incorrect", "-", "Confraction", "(", "FiC", ")", "."], "sentence-detokenized": "There are a number of other measures, the simplest being accuracy or the Correct-Confraction (FC), which measures the proportion of all instances correctly categorised; its complement is the Incorrect-Confraction (FiC).", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 18], [19, 21], [22, 27], [28, 36], [36, 37], [38, 41], [42, 50], [51, 56], [57, 65], [66, 68], [69, 72], [73, 81], [81, 92], [93, 94], [94, 96], [96, 97], [97, 98], [99, 104], [105, 113], [114, 117], [118, 128], [129, 131], [132, 135], [136, 145], [146, 155], [156, 167], [167, 168], [169, 172], [173, 183], [184, 186], [187, 190], [191, 200], [200, 201], [201, 212], [213, 214], [214, 217], [217, 218], [218, 219]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [6, 10, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 10, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "became", "a", "member", "of", "the", "Society", "for", "Computational", "Linguistics", "in", "2016", "."], "sentence-detokenized": "Cardie became a member of the Society for Computational Linguistics in 2016.", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 37], [38, 41], [42, 55], [56, 67], [68, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-test-125", "ner": [[11, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Learning", "of", "the", "parameters", "math", "\\", "theta", "/", "math", "is", "usually", "done", "by", "maximum", "likelihood", "learning", "for", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";\\", "theta", ")", "/", "math", "."], "sentence-detokenized": "Learning of the parameters math\\ theta / math is usually done by maximum likelihood learning for mathp (Y _ i | X _ i;\\ theta) / math.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 26], [27, 31], [31, 32], [33, 38], [39, 40], [41, 45], [46, 48], [49, 56], [57, 61], [62, 64], [65, 72], [73, 83], [84, 92], [93, 96], [97, 102], [103, 104], [104, 105], [106, 107], [108, 109], [110, 111], [112, 113], [114, 115], [116, 117], [117, 119], [120, 125], [125, 126], [127, 128], [129, 133], [133, 134]]}
{"doc_key": "ai-test-126", "ner": [[0, 1, "task"], [3, 5, "algorithm"], [6, 8, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 8, 0, 1, "usage", "", true, false], [6, 8, 3, 5, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cluster", "analysis", "and", "non-negative", "matrix", "factorization", "for", "descriptive", "mining", "."], "sentence-detokenized": "Cluster analysis and non-negative matrix factorization for descriptive mining.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 33], [34, 40], [41, 54], [55, 58], [59, 70], [71, 77], [77, 78]]}
{"doc_key": "ai-test-127", "ner": [[6, 7, "field"], [10, 11, "field"], [21, 24, "field"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 24, 6, 7, "part-of", "", false, false], [21, 24, 10, 11, "part-of", "", false, false], [26, 27, 6, 7, "part-of", "", false, false], [26, 27, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "long", "-", "standing", "challenge", "in", "computer", "science", "and", "the", "information", "technology", "it", "has", "enabled", "has", "been", "the", "ability", "of", "computers", "to", "process", "natural", "language", "and", "machine", "learning", "."], "sentence-detokenized": "A long-standing challenge in computer science and the information technology it has enabled has been the ability of computers to process natural language and machine learning.", "token2charspan": [[0, 1], [2, 6], [6, 7], [7, 15], [16, 25], [26, 28], [29, 37], [38, 45], [46, 49], [50, 53], [54, 65], [66, 76], [77, 79], [80, 83], [84, 91], [92, 95], [96, 100], [101, 104], [105, 112], [113, 115], [116, 125], [126, 128], [129, 136], [137, 144], [145, 153], [154, 157], [158, 165], [166, 174], [174, 175]]}
{"doc_key": "ai-test-128", "ner": [[6, 9, "algorithm"], [0, 2, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 9, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "In", "MATLAB", ",", "the", "code", "to", "extract", "Gabor", "features", "from", "images", "can", "be", "found", "at"], "sentence-detokenized": "(In MATLAB, the code to extract Gabor features from images can be found at", "token2charspan": [[0, 1], [1, 3], [4, 10], [10, 11], [12, 15], [16, 20], [21, 23], [24, 31], [32, 37], [38, 46], [47, 51], [52, 58], [59, 62], [63, 65], [66, 71], [72, 74]]}
{"doc_key": "ai-test-129", "ner": [[0, 0, "misc"], [15, 18, "algorithm"], [20, 20, "task"], [22, 22, "task"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 15, 18, "general-affiliation", "", false, false], [0, 0, 20, 20, "related-to", "solves_problem_of_type", false, false], [0, 0, 22, 22, "related-to", "solves_problem_of_type", false, false], [0, 0, 24, 25, "related-to", "solves_problem_of_type", false, false], [0, 0, 27, 28, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["NeuralExpert", "focuses", "the", "design", "specifications", "around", "the", "type", "of", "problem", "the", "user", "wants", "to", "solve", "with", "the", "neural", "network", "(", "classification", ",", "prediction", ",", "function", "approximation", "or", "cluster", "analysis", ")", "."], "sentence-detokenized": "NeuralExpert focuses the design specifications around the type of problem the user wants to solve with the neural network (classification, prediction, function approximation or cluster analysis).", "token2charspan": [[0, 12], [13, 20], [21, 24], [25, 31], [32, 46], [47, 53], [54, 57], [58, 62], [63, 65], [66, 73], [74, 77], [78, 82], [83, 88], [89, 91], [92, 97], [98, 102], [103, 106], [107, 113], [114, 121], [122, 123], [123, 137], [137, 138], [139, 149], [149, 150], [151, 159], [160, 173], [174, 176], [177, 184], [185, 193], [193, 194], [194, 195]]}
{"doc_key": "ai-test-130", "ner": [[2, 4, "misc"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "quantization", "step", "size", "(", "\u0394", ")", "is", "small", "relative", "to", "the", "change", "in", "the", "signal", "to", "be", "quantized", ",", "it", "is", "relatively", "easy", "to", "show", "that", "the", "mean", "squared", "error", "caused", "by", "such", "a", "rounding", "operation", "is", "approximately", "math", "\\", "Delta", "^", "2", "/", "12", "/", "math.math", "."], "sentence-detokenized": "If the quantization step size (\u0394) is small relative to the change in the signal to be quantized, it is relatively easy to show that the mean squared error caused by such a rounding operation is approximately math\\ Delta ^ 2 / 12 / math.math.", "token2charspan": [[0, 2], [3, 6], [7, 19], [20, 24], [25, 29], [30, 31], [31, 32], [32, 33], [34, 36], [37, 42], [43, 51], [52, 54], [55, 58], [59, 65], [66, 68], [69, 72], [73, 79], [80, 82], [83, 85], [86, 95], [95, 96], [97, 99], [100, 102], [103, 113], [114, 118], [119, 121], [122, 126], [127, 131], [132, 135], [136, 140], [141, 148], [149, 154], [155, 161], [162, 164], [165, 169], [170, 171], [172, 180], [181, 190], [191, 193], [194, 207], [208, 212], [212, 213], [214, 219], [220, 221], [222, 223], [224, 225], [226, 228], [229, 230], [231, 240], [240, 241]]}
{"doc_key": "ai-test-131", "ner": [[17, 17, "product"], [27, 30, "researcher"], [32, 33, "researcher"], [35, 37, "researcher"], [39, 40, "researcher"], [42, 44, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "creation", "of", "a", "rich", "lexicon", "with", "a", "proper", "ontology", "requires", "considerable", "effort", ",", "for", "example", "the", "Wordnet", "lexicon", "required", "many", "man", "-", "years", "of", "work", ".", "G.", "A", ".", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "The creation of a rich lexicon with a proper ontology requires considerable effort, for example the Wordnet lexicon required many man-years of work. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 17], [18, 22], [23, 30], [31, 35], [36, 37], [38, 44], [45, 53], [54, 62], [63, 75], [76, 82], [82, 83], [84, 87], [88, 95], [96, 99], [100, 107], [108, 115], [116, 124], [125, 129], [130, 133], [133, 134], [134, 139], [140, 142], [143, 147], [147, 148], [149, 151], [152, 153], [153, 154], [155, 161], [161, 162], [163, 165], [166, 174], [174, 175], [176, 178], [179, 181], [182, 190], [190, 191], [192, 194], [195, 200], [200, 201], [202, 203], [203, 204], [205, 211], [211, 212]]}
{"doc_key": "ai-test-132", "ner": [[0, 0, "organisation"], [15, 16, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kawasaki", "'s", "portfolio", "also", "includes", "retractable", "roofs", ",", "floors", "and", "other", "giant", "structures", ",", "the", "Sapporo", "Dome", "\"", "retractable", "surface", "\"", "is", "one", "example", "."], "sentence-detokenized": "Kawasaki's portfolio also includes retractable roofs, floors and other giant structures, the Sapporo Dome \"retractable surface\" is one example.", "token2charspan": [[0, 8], [8, 10], [11, 20], [21, 25], [26, 34], [35, 46], [47, 52], [52, 53], [54, 60], [61, 64], [65, 70], [71, 76], [77, 87], [87, 88], [89, 92], [93, 100], [101, 105], [106, 107], [107, 118], [119, 126], [126, 127], [128, 130], [131, 134], [135, 142], [142, 143]]}
{"doc_key": "ai-test-133", "ner": [[0, 1, "metrics"], [5, 6, "metrics"], [8, 9, "metrics"], [15, 16, "metrics"], [40, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 15, 16, "related-to", "", false, false], [0, 1, 40, 40, "opposite", "alternative_to", false, false], [5, 6, 0, 1, "type-of", "", false, false], [8, 9, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa", "statistics", ",", "such", "as", "Fleiss", "kappa", "and", "Cohen", "kappa", ",", "are", "methods", "for", "calculating", "inter-rater", "reliability", "based", "on", "different", "assumptions", "about", "marginal", "or", "prior", "distributions", ",", "and", "are", "increasingly", "used", "in", "other", "contexts", "as", "a", "randomly", "adjusted", "alternative", "to", "precision", "."], "sentence-detokenized": "Kappa statistics, such as Fleiss kappa and Cohen kappa, are methods for calculating inter-rater reliability based on different assumptions about marginal or prior distributions, and are increasingly used in other contexts as a randomly adjusted alternative to precision.", "token2charspan": [[0, 5], [6, 16], [16, 17], [18, 22], [23, 25], [26, 32], [33, 38], [39, 42], [43, 48], [49, 54], [54, 55], [56, 59], [60, 67], [68, 71], [72, 83], [84, 95], [96, 107], [108, 113], [114, 116], [117, 126], [127, 138], [139, 144], [145, 153], [154, 156], [157, 162], [163, 176], [176, 177], [178, 181], [182, 185], [186, 198], [199, 203], [204, 206], [207, 212], [213, 221], [222, 224], [225, 226], [227, 235], [236, 244], [245, 256], [257, 259], [260, 269], [269, 270]]}
{"doc_key": "ai-test-134", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [18, 18, "researcher"], [27, 29, "algorithm"], [32, 34, "algorithm"], [31, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 18, 18, "role", "student_of", false, false], [7, 8, 18, 18, "role", "student_of", false, false], [10, 11, 18, 18, "role", "student_of", false, false], [13, 14, 18, 18, "role", "student_of", false, false], [32, 34, 4, 5, "origin", "", false, false], [32, 34, 7, 8, "origin", "", false, false], [32, 34, 10, 11, "origin", "", false, false], [32, 34, 13, 14, "origin", "", false, false], [32, 34, 18, 18, "origin", "", false, false], [32, 34, 27, 29, "type-of", "", false, false], [31, 37, 32, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Together", "with", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "and", "others", ",", "Schmidhuber", "published", "increasingly", "sophisticated", "versions", "of", "a", "type", "of", "recurrent", "neural", "network", "called", "long", "short", "-", "term", "memory", "(", "LSTM", ")", "."], "sentence-detokenized": "Together with his students Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves and others, Schmidhuber published increasingly sophisticated versions of a type of recurrent neural network called long short-term memory (LSTM).", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 26], [27, 31], [32, 42], [42, 43], [44, 49], [50, 54], [54, 55], [56, 60], [61, 68], [68, 69], [70, 74], [75, 81], [82, 85], [86, 92], [92, 93], [94, 105], [106, 115], [116, 128], [129, 142], [143, 151], [152, 154], [155, 156], [157, 161], [162, 164], [165, 174], [175, 181], [182, 189], [190, 196], [197, 201], [202, 207], [207, 208], [208, 212], [213, 219], [220, 221], [221, 225], [225, 226], [226, 227]]}
{"doc_key": "ai-test-135", "ner": [[6, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "Launch", "of", "the", "first", "Cobot", "KUKA", "LBR", "3", "."], "sentence-detokenized": "2004 - Launch of the first Cobot KUKA LBR 3.", "token2charspan": [[0, 4], [5, 6], [7, 13], [14, 16], [17, 20], [21, 26], [27, 32], [33, 37], [38, 41], [42, 43], [43, 44]]}
{"doc_key": "ai-test-136", "ner": [[10, 12, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "superficial", "approaches", "used", "for", "training", "and", "then", "decomposition", "are", "Naive", "Bayes", "classifier", "and", "decision", "trees", "."], "sentence-detokenized": "Two superficial approaches used for training and then decomposition are Naive Bayes classifier and decision trees.", "token2charspan": [[0, 3], [4, 15], [16, 26], [27, 31], [32, 35], [36, 44], [45, 48], [49, 53], [54, 67], [68, 71], [72, 77], [78, 83], [84, 94], [95, 98], [99, 107], [108, 113], [113, 114]]}
{"doc_key": "ai-test-137", "ner": [[5, 5, "misc"], [12, 13, "person"], [15, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 12, 13, "origin", "", false, false], [5, 5, 15, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "practical", "forms", "of", "photography", "were", "introduced", "in", "January", "1839", "by", "Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "The first practical forms of photography were introduced in January 1839 by Louis Daguerre and Henry Fox Talbot.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 25], [26, 28], [29, 40], [41, 45], [46, 56], [57, 59], [60, 67], [68, 72], [73, 75], [76, 81], [82, 90], [91, 94], [95, 100], [101, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-138", "ner": [[3, 4, "task"], [7, 8, "task"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 15, 16, "part-of", "task_part_of_field", false, false], [7, 8, 15, 16, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "speech", "synthesis", "combined", "with", "speech", "recognition", "allows", "interaction", "with", "mobile", "devices", "through", "language", "processing", "interfaces", "."], "sentence-detokenized": "For example, speech synthesis combined with speech recognition allows interaction with mobile devices through language processing interfaces.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [30, 38], [39, 43], [44, 50], [51, 62], [63, 69], [70, 81], [82, 86], [87, 93], [94, 101], [102, 109], [110, 118], [119, 129], [130, 140], [140, 141]]}
{"doc_key": "ai-test-139", "ner": [[0, 0, "product"], [15, 15, "programlang"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 15, 15, "general-affiliation", "", false, false], [0, 0, 16, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Phidgets", "can", "be", "programmed", "with", "a", "wide", "range", "of", "software", "and", "programming", "languages", ",", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "Phidgets can be programmed with a wide range of software and programming languages, from Java to Microsoft Excel.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 26], [27, 31], [32, 33], [34, 38], [39, 44], [45, 47], [48, 56], [57, 60], [61, 72], [73, 82], [82, 83], [84, 88], [89, 93], [94, 96], [97, 106], [107, 112], [112, 113]]}
{"doc_key": "ai-test-140", "ner": [[3, 4, "field"], [11, 12, "researcher"], [23, 26, "misc"], [17, 18, "field"], [20, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 11, 12, "origin", "", false, false], [11, 12, 17, 18, "general-affiliation", "topic_of_study", false, false], [11, 12, 20, 22, "general-affiliation", "topic_of_study", false, false], [23, 26, 11, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "'", "machine", "learning", "'", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "a", "pioneer", "of", "computer", "games", "and", "artificial", "intelligence", "at", "IBM", "in", "the", "US", "."], "sentence-detokenized": "The term 'machine learning' was coined in 1959 by Arthur Samuel, a pioneer of computer games and artificial intelligence at IBM in the US.", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 17], [18, 26], [26, 27], [28, 31], [32, 38], [39, 41], [42, 46], [47, 49], [50, 56], [57, 63], [63, 64], [65, 66], [67, 74], [75, 77], [78, 86], [87, 92], [93, 96], [97, 107], [108, 120], [121, 123], [124, 127], [128, 130], [131, 134], [135, 137], [137, 138]]}
{"doc_key": "ai-test-141", "ner": [[0, 2, "misc"], [3, 4, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Israeli", "poet", "David", "Avidan", ",", "fascinated", "by", "future", "technologies", "and", "their", "relationship", "with", "art", ",", "wanted", "to", "explore", "the", "use", "of", "computers", "for", "writing", "literature", "."], "sentence-detokenized": "The Israeli poet David Avidan, fascinated by future technologies and their relationship with art, wanted to explore the use of computers for writing literature.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 22], [23, 29], [29, 30], [31, 41], [42, 44], [45, 51], [52, 64], [65, 68], [69, 74], [75, 87], [88, 92], [93, 96], [96, 97], [98, 104], [105, 107], [108, 115], [116, 119], [120, 123], [124, 126], [127, 136], [137, 140], [141, 148], [149, 159], [159, 160]]}
{"doc_key": "ai-test-142", "ner": [[7, 8, "misc"], [10, 10, "organisation"], [16, 17, "location"], [30, 33, "location"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[10, 10, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2017", ",", "as", "part", "of", "the", "GATEway", "project", ",", "Oxbotica", "trialled", "seven", "autonomous", "bus", "services", "in", "Greenwich", ",", "which", "navigated", "a", "two", "-", "mile", "riverside", "path", "near", "London", "'s", "O2", "Arena", "on", "a", "route", "used", "by", "pedestrians", "and", "cyclists", "."], "sentence-detokenized": "In 2017, as part of the GATEway project, Oxbotica trialled seven autonomous bus services in Greenwich, which navigated a two-mile riverside path near London's O2 Arena on a route used by pedestrians and cyclists.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 16], [17, 19], [20, 23], [24, 31], [32, 39], [39, 40], [41, 49], [50, 58], [59, 64], [65, 75], [76, 79], [80, 88], [89, 91], [92, 101], [101, 102], [103, 108], [109, 118], [119, 120], [121, 124], [124, 125], [125, 129], [130, 139], [140, 144], [145, 149], [150, 156], [156, 158], [159, 161], [162, 167], [168, 170], [171, 172], [173, 178], [179, 183], [184, 186], [187, 198], [199, 202], [203, 211], [211, 212]]}
{"doc_key": "ai-test-143", "ner": [[11, 14, "task"], [15, 17, "metrics"], [26, 26, "misc"], [29, 29, "metrics"], [31, 31, "metrics"], [34, 34, "metrics"], [36, 36, "metrics"], [38, 40, "metrics"], [43, 43, "metrics"], [45, 45, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[15, 17, 26, 26, "related-to", "is_a", false, false], [15, 17, 29, 29, "usage", "", false, false], [15, 17, 31, 31, "usage", "", false, false], [29, 29, 34, 34, "named", "same", false, false], [31, 31, 45, 45, "named", "same", false, false], [34, 34, 43, 43, "opposite", "", false, false], [34, 34, 45, 45, "opposite", "", false, false], [36, 36, 34, 34, "named", "", false, false], [38, 40, 34, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["An", "independent", "but", "often", "used", "combination", "of", "the", "basic", "statistics", "of", "information", "retrieval", "is", "the", "F", "-", "score", ",", "which", "is", "the", "(", "possibly", "weighted", ")", "harmonic", "mean", "of", "recall", "and", "precision", ",", "where", "recall", "=", "sensitivity", "=", "TRUE", "positive", "ratio", ",", "but", "specificity", "and", "precision", "are", "completely", "different", "measures", "."], "sentence-detokenized": "An independent but often used combination of the basic statistics of information retrieval is the F-score, which is the (possibly weighted) harmonic mean of recall and precision, where recall = sensitivity = TRUE positive ratio, but specificity and precision are completely different measures.", "token2charspan": [[0, 2], [3, 14], [15, 18], [19, 24], [25, 29], [30, 41], [42, 44], [45, 48], [49, 54], [55, 65], [66, 68], [69, 80], [81, 90], [91, 93], [94, 97], [98, 99], [99, 100], [100, 105], [105, 106], [107, 112], [113, 115], [116, 119], [120, 121], [121, 129], [130, 138], [138, 139], [140, 148], [149, 153], [154, 156], [157, 163], [164, 167], [168, 177], [177, 178], [179, 184], [185, 191], [192, 193], [194, 205], [206, 207], [208, 212], [213, 221], [222, 227], [227, 228], [229, 232], [233, 244], [245, 248], [249, 258], [259, 262], [263, 273], [274, 283], [284, 292], [292, 293]]}
{"doc_key": "ai-test-144", "ner": [[0, 1, "field"], [10, 10, "field"], [12, 12, "field"], [14, 14, "field"], [16, 17, "field"], [19, 20, "field"], [28, 29, "product"], [31, 34, "product"], [36, 37, "product"], [39, 40, "product"], [49, 53, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 10, "origin", "takes_inspiration_from", false, false], [0, 1, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 1, 14, 14, "origin", "takes_inspiration_from", false, false], [0, 1, 16, 17, "origin", "takes_inspiration_from", false, false], [0, 1, 19, 20, "origin", "takes_inspiration_from", false, false], [28, 29, 0, 1, "origin", "", false, false], [31, 34, 0, 1, "origin", "", false, false], [36, 37, 0, 1, "origin", "", false, false], [39, 40, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "is", "an", "interdisciplinary", "subject", "that", "draws", "inspiration", "from", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", "and", "electronics", "engineering", "to", "design", "artificial", "neural", "systems", "such", "as", "vision", "systems", ",", "head", "-", "eye", "systems", ",", "auditory", "processors", "and", "autonomous", "robots", ",", "whose", "physical", "architecture", "and", "design", "principles", "are", "based", "on", "biological", "nervous", "systems", "."], "sentence-detokenized": "Neuromorphic engineering is an interdisciplinary subject that draws inspiration from biology, physics, mathematics, computer science and electronics engineering to design artificial neural systems such as vision systems, head-eye systems, auditory processors and autonomous robots, whose physical architecture and design principles are based on biological nervous systems.", "token2charspan": [[0, 12], [13, 24], [25, 27], [28, 30], [31, 48], [49, 56], [57, 61], [62, 67], [68, 79], [80, 84], [85, 92], [92, 93], [94, 101], [101, 102], [103, 114], [114, 115], [116, 124], [125, 132], [133, 136], [137, 148], [149, 160], [161, 163], [164, 170], [171, 181], [182, 188], [189, 196], [197, 201], [202, 204], [205, 211], [212, 219], [219, 220], [221, 225], [225, 226], [226, 229], [230, 237], [237, 238], [239, 247], [248, 258], [259, 262], [263, 273], [274, 280], [280, 281], [282, 287], [288, 296], [297, 309], [310, 313], [314, 320], [321, 331], [332, 335], [336, 341], [342, 344], [345, 355], [356, 363], [364, 371], [371, 372]]}
{"doc_key": "ai-test-145", "ner": [[3, 5, "metrics"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 3, 5, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Specifically", ",", "the", "BIBO", "stability", "criterion", "requires", "that", "the", "ROC", "of", "the", "system", "includes", "the", "unit", "circle", "."], "sentence-detokenized": "Specifically, the BIBO stability criterion requires that the ROC of the system includes the unit circle.", "token2charspan": [[0, 12], [12, 13], [14, 17], [18, 22], [23, 32], [33, 42], [43, 51], [52, 56], [57, 60], [61, 64], [65, 67], [68, 71], [72, 78], [79, 87], [88, 91], [92, 96], [97, 103], [103, 104]]}
{"doc_key": "ai-test-146", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "The", "program", "was", "rewritten", "in", "Java", "from", "1998", "onwards", "."], "sentence-detokenized": "2 The program was rewritten in Java from 1998 onwards.", "token2charspan": [[0, 1], [2, 5], [6, 13], [14, 17], [18, 27], [28, 30], [31, 35], [36, 40], [41, 45], [46, 53], [53, 54]]}
{"doc_key": "ai-test-147", "ner": [[1, 1, "metrics"], [6, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 6, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "MCC", "can", "be", "calculated", "directly", "from", "the", "perturbation", "matrix", "using", "the", "formula", ":"], "sentence-detokenized": "The MCC can be calculated directly from the perturbation matrix using the formula:", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 25], [26, 34], [35, 39], [40, 43], [44, 56], [57, 63], [64, 69], [70, 73], [74, 81], [81, 82]]}
{"doc_key": "ai-test-148", "ner": [[9, 16, "organisation"], [21, 26, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 16, 21, 26, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "program", "was", "developed", "by", "a", "team", "at", "the", "MIT", "-", "IBM", "Watson", "AI", "Lab", "and", "was", "first", "presented", "at", "the", "2018", "International", "Conference", "on", "Learning", "Representations", "."], "sentence-detokenized": "The program was developed by a team at the MIT-IBM Watson AI Lab and was first presented at the 2018 International Conference on Learning Representations.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 25], [26, 28], [29, 30], [31, 35], [36, 38], [39, 42], [43, 46], [46, 47], [47, 50], [51, 57], [58, 60], [61, 64], [65, 68], [69, 72], [73, 78], [79, 88], [89, 91], [92, 95], [96, 100], [101, 114], [115, 125], [126, 128], [129, 137], [138, 153], [153, 154]]}
{"doc_key": "ai-test-149", "ner": [[2, 4, "metrics"], [16, 18, "metrics"], [20, 22, "metrics"], [49, 49, "metrics"], [51, 51, "metrics"], [56, 58, "metrics"], [61, 61, "metrics"], [63, 63, "metrics"], [65, 67, "metrics"], [72, 72, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[16, 18, 49, 49, "type-of", "", false, false], [16, 18, 56, 58, "related-to", "collapses_to_identity", false, false], [20, 22, 51, 51, "type-of", "", false, false], [20, 22, 56, 58, "related-to", "collapses_to_identity", false, false], [20, 22, 65, 67, "named", "same", false, false], [61, 61, 72, 72, "related-to", "collapses_to_identity", false, false], [63, 63, 72, 72, "related-to", "collapses_to_identity", false, false], [65, 67, 72, 72, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["If", "the", "TRUE", "prevalences", "of", "the", "two", "positive", "variables", "are", "the", "same", ",", "as", "implied", "by", "Fleiss", "'", "kappa", "and", "F", "-", "score", ",", "i.e.", "the", "number", "of", "positive", "predictions", "equals", "the", "number", "of", "positive", "classes", "in", "the", "dichotomous", "(", "two", "-", "class", ")", "case", ",", "then", "the", "different", "kappa", "and", "correlation", "measures", "fall", "into", "identity", "with", "Youden", "J", ",", "and", "recall", ",", "precision", "and", "F", "-", "score", "are", "similarly", "identical", "with", "precision", "."], "sentence-detokenized": "If the TRUE prevalences of the two positive variables are the same, as implied by Fleiss' kappa and F-score, i.e. the number of positive predictions equals the number of positive classes in the dichotomous (two-class) case, then the different kappa and correlation measures fall into identity with Youden J, and recall, precision and F-score are similarly identical with precision.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 23], [24, 26], [27, 30], [31, 34], [35, 43], [44, 53], [54, 57], [58, 61], [62, 66], [66, 67], [68, 70], [71, 78], [79, 81], [82, 88], [88, 89], [90, 95], [96, 99], [100, 101], [101, 102], [102, 107], [107, 108], [109, 113], [114, 117], [118, 124], [125, 127], [128, 136], [137, 148], [149, 155], [156, 159], [160, 166], [167, 169], [170, 178], [179, 186], [187, 189], [190, 193], [194, 205], [206, 207], [207, 210], [210, 211], [211, 216], [216, 217], [218, 222], [222, 223], [224, 228], [229, 232], [233, 242], [243, 248], [249, 252], [253, 264], [265, 273], [274, 278], [279, 283], [284, 292], [293, 297], [298, 304], [305, 306], [306, 307], [308, 311], [312, 318], [318, 319], [320, 329], [330, 333], [334, 335], [335, 336], [336, 341], [342, 345], [346, 355], [356, 365], [366, 370], [371, 380], [380, 381]]}
{"doc_key": "ai-test-150", "ner": [[5, 9, "misc"], [3, 7, "misc"], [1, 1, "conference"], [13, 16, "task"], [17, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 9, 1, 1, "part-of", "", false, false], [5, 9, 1, 1, "physical", "", false, false], [5, 9, 1, 1, "temporal", "", false, false], [3, 7, 5, 9, "named", "", false, false], [13, 16, 5, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "NAACL", "2013", "Building", "Educational", "Applications", "(", "BEA", ")", "workshop", "hosted", "the", "first", "joint", "NLI", "exercise", ".", "Tetreault", "et", "al", ",", "2013", "The", "competition", "attracted", "29", "teams", "from", "around", "the", "world", ",", "24", "of", "which", "published", "a", "paper", "describing", "their", "systems", "and", "approaches", "."], "sentence-detokenized": "The NAACL 2013 Building Educational Applications (BEA) workshop hosted the first joint NLI exercise. Tetreault et al, 2013 The competition attracted 29 teams from around the world, 24 of which published a paper describing their systems and approaches.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 23], [24, 35], [36, 48], [49, 50], [50, 53], [53, 54], [55, 63], [64, 70], [71, 74], [75, 80], [81, 86], [87, 90], [91, 99], [99, 100], [101, 110], [111, 113], [114, 116], [116, 117], [118, 122], [123, 126], [127, 138], [139, 148], [149, 151], [152, 157], [158, 162], [163, 169], [170, 173], [174, 179], [179, 180], [181, 183], [184, 186], [187, 192], [193, 202], [203, 204], [205, 210], [211, 221], [222, 227], [228, 235], [236, 239], [240, 250], [250, 251]]}
{"doc_key": "ai-test-151", "ner": [[1, 2, "algorithm"], [5, 7, "algorithm"], [15, 16, "misc"], [19, 21, "misc"], [45, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 6], "relations": [[1, 2, 5, 7, "type-of", "", false, false], [1, 2, 15, 16, "related-to", "finds", false, false], [19, 21, 15, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Viterbi", "algorithm", "is", "a", "dynamic", "programming", "algorithm", "for", "finding", "the", "most", "probable", "sequence", "of", "hidden", "states", ",", "called", "the", "Viterbi", "path", ",", "which", "results", "in", "a", "sequence", "of", "observed", "events", ",", "especially", "in", "the", "context", "of", "Markov", "information", "sources", "and", "hidden", "Markov", "models", "(", "HMMs", ")", "."], "sentence-detokenized": "The Viterbi algorithm is a dynamic programming algorithm for finding the most probable sequence of hidden states, called the Viterbi path, which results in a sequence of observed events, especially in the context of Markov information sources and hidden Markov models (HMMs).", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 24], [25, 26], [27, 34], [35, 46], [47, 56], [57, 60], [61, 68], [69, 72], [73, 77], [78, 86], [87, 95], [96, 98], [99, 105], [106, 112], [112, 113], [114, 120], [121, 124], [125, 132], [133, 137], [137, 138], [139, 144], [145, 152], [153, 155], [156, 157], [158, 166], [167, 169], [170, 178], [179, 185], [185, 186], [187, 197], [198, 200], [201, 204], [205, 212], [213, 215], [216, 222], [223, 234], [235, 242], [243, 246], [247, 253], [254, 260], [261, 267], [268, 269], [269, 273], [273, 274], [274, 275]]}
{"doc_key": "ai-test-152", "ner": [[0, 1, "field"], [3, 5, "algorithm"], [8, 9, "misc"], [12, 13, "algorithm"], [14, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 0, 1, "part-of", "", false, false], [3, 5, 8, 9, "general-affiliation", "", false, false], [3, 5, 12, 13, "related-to", "generalizes_from", false, false], [3, 5, 14, 18, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "multinomial", "logistic", "regression", "is", "a", "classification", "method", "that", "generalises", "logistic", "regression", "to", "multiclass", "classification", ",", "i.e.", "with", "more", "than", "two", "possible", "discrete", "outcomes", "."], "sentence-detokenized": "In statistics, multinomial logistic regression is a classification method that generalises logistic regression to multiclass classification, i.e. with more than two possible discrete outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 26], [27, 35], [36, 46], [47, 49], [50, 51], [52, 66], [67, 73], [74, 78], [79, 90], [91, 99], [100, 110], [111, 113], [114, 124], [125, 139], [139, 140], [141, 145], [146, 150], [151, 155], [156, 160], [161, 164], [165, 173], [174, 182], [183, 191], [191, 192]]}
{"doc_key": "ai-test-153", "ner": [[0, 2, "algorithm"], [6, 7, "field"], [9, 11, "field"], [15, 15, "task"], [17, 17, "task"], [19, 20, "task"], [22, 23, "researcher"], [25, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 6, 7, "part-of", "", false, false], [0, 2, 9, 11, "part-of", "", false, false], [15, 15, 0, 2, "usage", "", true, false], [17, 17, 0, 2, "usage", "", true, false], [19, 20, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden", "Markov", "models", "are", "known", "for", "reinforcement", "learning", "and", "temporal", "pattern", "recognition", ",", "such", "as", "speech", ",", "handwriting", "and", "gesture", "recognition", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov models are known for reinforcement learning and temporal pattern recognition, such as speech, handwriting and gesture recognition, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 30], [31, 34], [35, 48], [49, 57], [58, 61], [62, 70], [71, 78], [79, 90], [90, 91], [92, 96], [97, 99], [100, 106], [106, 107], [108, 119], [120, 123], [124, 131], [132, 143], [143, 144], [145, 149], [150, 157], [157, 158], [159, 163], [164, 172], [172, 173]]}
{"doc_key": "ai-test-154", "ner": [[5, 7, "misc"], [28, 31, "metrics"], [34, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 34, 35, "named", "", false, false], [28, 31, 34, 35, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "essentially", "means", "that", "if", "n", "-", "grams", "have", "occurred", "more", "than", "k", "times", "during", "training", ",", "then", "the", "conditional", "probability", "of", "the", "word", "is", "proportional", "to", "the", "maximum", "likelihood", "estimate", "of", "that", "n", "-", "gram", "given", "the", "history", "."], "sentence-detokenized": "This essentially means that if n -grams have occurred more than k times during training, then the conditional probability of the word is proportional to the maximum likelihood estimate of that n -gram given the history.", "token2charspan": [[0, 4], [5, 16], [17, 22], [23, 27], [28, 30], [31, 32], [33, 34], [34, 39], [40, 44], [45, 53], [54, 58], [59, 63], [64, 65], [66, 71], [72, 78], [79, 87], [87, 88], [89, 93], [94, 97], [98, 109], [110, 121], [122, 124], [125, 128], [129, 133], [134, 136], [137, 149], [150, 152], [153, 156], [157, 164], [165, 175], [176, 184], [185, 187], [188, 192], [193, 194], [195, 196], [196, 200], [201, 206], [207, 210], [211, 218], [218, 219]]}
{"doc_key": "ai-test-155", "ner": [[4, 5, "task"], [7, 9, "task"], [11, 13, "task"], [18, 20, "task"], [26, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[26, 30, 18, 20, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "knowledge", "representation", ",", "common", "sense", "reasoning", "and", "natural", "language", "understanding", ",", "and", "believes", "that", "deep", "language", "understanding", "can", "currently", "only", "be", "achieved", "by", "significant", "manual", "design", "of", "semantically", "rich", "formalisms", "coupled", "with", "statistical", "preferences", "."], "sentence-detokenized": "He is interested in knowledge representation, common sense reasoning and natural language understanding, and believes that deep language understanding can currently only be achieved by significant manual design of semantically rich formalisms coupled with statistical preferences.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 29], [30, 44], [44, 45], [46, 52], [53, 58], [59, 68], [69, 72], [73, 80], [81, 89], [90, 103], [103, 104], [105, 108], [109, 117], [118, 122], [123, 127], [128, 136], [137, 150], [151, 154], [155, 164], [165, 169], [170, 172], [173, 181], [182, 184], [185, 196], [197, 203], [204, 210], [211, 213], [214, 226], [227, 231], [232, 242], [243, 250], [251, 255], [256, 267], [268, 279], [279, 280]]}
{"doc_key": "ai-test-156", "ner": [[0, 0, "programlang"], [2, 2, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["JavaScript", ",", "Python", "or"], "sentence-detokenized": "JavaScript, Python or", "token2charspan": [[0, 10], [10, 11], [12, 18], [19, 21]]}
{"doc_key": "ai-test-157", "ner": [[1, 2, "misc"], [5, 7, "misc"], [11, 11, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 5, 7, "part-of", "", false, false], [5, 7, 11, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "Awards", "are", "announced", "in", "AI", "Magazine", ",", "published", "by", "AAAI", "."], "sentence-detokenized": "The Newcomb Awards are announced in AI Magazine, published by AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 32], [33, 35], [36, 38], [39, 47], [47, 48], [49, 58], [59, 61], [62, 66], [66, 67]]}
{"doc_key": "ai-test-158", "ner": [[1, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "squared", "error", "on", "the", "test", "set", "of", "100", "examples", "is", "0.084", ",", "which", "is", "smaller", "than", "the", "unnormalised", "error", "."], "sentence-detokenized": "The mean squared error on the test set of 100 examples is 0.084, which is smaller than the unnormalised error.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 25], [26, 29], [30, 34], [35, 38], [39, 41], [42, 45], [46, 54], [55, 57], [58, 63], [63, 64], [65, 70], [71, 73], [74, 81], [82, 86], [87, 90], [91, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-test-159", "ner": [[0, 4, "metrics"], [9, 11, "field"], [18, 19, "task"], [18, 22, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 11, 0, 4, "usage", "", false, false], [18, 19, 9, 11, "part-of", "task_part_of_field", false, false], [18, 22, 18, 19, "named", "", false, false], [25, 26, 9, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "F", "-", "score", "is", "widely", "used", "in", "the", "natural", "language", "processing", "literature", ",", "for", "example", "to", "evaluate", "Named", "Entity", "Recognition", "(", "NER", ")", "and", "word", "segmentation", "."], "sentence-detokenized": "The F-score is widely used in the natural language processing literature, for example to evaluate Named Entity Recognition (NER) and word segmentation.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 21], [22, 26], [27, 29], [30, 33], [34, 41], [42, 50], [51, 61], [62, 72], [72, 73], [74, 77], [78, 85], [86, 88], [89, 97], [98, 103], [104, 110], [111, 122], [123, 124], [124, 127], [127, 128], [129, 132], [133, 137], [138, 150], [150, 151]]}
{"doc_key": "ai-test-160", "ner": [[0, 1, "product"], [4, 6, "product"], [18, 19, "misc"], [21, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 18, 19, "related-to", "performs_task", false, false], [0, 1, 21, 22, "related-to", "performs_task", false, false], [4, 6, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "typically", "used", "in", "conversational", "systems", "for", "a", "variety", "of", "purposes", ",", "such", "as", "customer", "service", ",", "relaying", "requests", "or", "gathering", "information", "."], "sentence-detokenized": "Chatbots are typically used in conversational systems for a variety of purposes, such as customer service, relaying requests or gathering information.", "token2charspan": [[0, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 45], [46, 53], [54, 57], [58, 59], [60, 67], [68, 70], [71, 79], [79, 80], [81, 85], [86, 88], [89, 97], [98, 105], [105, 106], [107, 115], [116, 124], [125, 127], [128, 137], [138, 149], [149, 150]]}
{"doc_key": "ai-test-161", "ner": [[3, 9, "conference"], [13, 21, "conference"], [27, 37, "conference"], [43, 43, "conference"], [47, 50, "conference"], [53, 54, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 21, 3, 9, "named", "", false, false], [27, 37, 3, 9, "named", "", false, false], [43, 43, 27, 37, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Important", "journals", "include", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "later", "renamed", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", ",", "and", "since", "September", "2014", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "after", "merging", "with", "an", "ACM", "publication", ")", ",", "Computer", "Speech", "and", "Language", ",", "and", "Speech", "Communication", "."], "sentence-detokenized": "Important journals include IEEE Transactions on Speech and Audio Processing (later renamed IEEE Transactions on Audio, Speech and Language Processing, and since September 2014 IEEE/ACM Transactions on Audio, Speech and Language Processing - after merging with an ACM publication), Computer Speech and Language, and Speech Communication.", "token2charspan": [[0, 9], [10, 18], [19, 26], [27, 31], [32, 44], [45, 47], [48, 54], [55, 58], [59, 64], [65, 75], [76, 77], [77, 82], [83, 90], [91, 95], [96, 108], [109, 111], [112, 117], [117, 118], [119, 125], [126, 129], [130, 138], [139, 149], [149, 150], [151, 154], [155, 160], [161, 170], [171, 175], [176, 180], [180, 181], [181, 184], [185, 197], [198, 200], [201, 206], [206, 207], [208, 214], [215, 218], [219, 227], [228, 238], [239, 240], [241, 246], [247, 254], [255, 259], [260, 262], [263, 266], [267, 278], [278, 279], [279, 280], [281, 289], [290, 296], [297, 300], [301, 309], [309, 310], [311, 314], [315, 321], [322, 335], [335, 336]]}
{"doc_key": "ai-test-162", "ner": [[0, 1, "algorithm"], [4, 6, "task"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 0, 1, "usage", "", false, false], [4, 6, 8, 9, "part-of", "task_part_of_field", false, false], [4, 6, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "is", "often", "used", "for", "data", "clustering", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "EM is often used for data clustering in machine learning and computer vision.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 20], [21, 25], [26, 36], [37, 39], [40, 47], [48, 56], [57, 60], [61, 69], [70, 76], [76, 77]]}
{"doc_key": "ai-test-163", "ner": [[9, 11, "metrics"], [26, 29, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 26, 29, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["Although", "there", "is", "no", "perfect", "way", "to", "describe", "the", "confusion", "matrix", "of", "the", "IGAZ", "and", "HAMIS", "positive", "and", "negative", "results", "with", "a", "single", "number", ",", "the", "Matthews", "correlation", "coefficient", "is", "generally", "considered", "one", "of", "the", "best", "such", "measures", "."], "sentence-detokenized": "Although there is no perfect way to describe the confusion matrix of the IGAZ and HAMIS positive and negative results with a single number, the Matthews correlation coefficient is generally considered one of the best such measures.", "token2charspan": [[0, 8], [9, 14], [15, 17], [18, 20], [21, 28], [29, 32], [33, 35], [36, 44], [45, 48], [49, 58], [59, 65], [66, 68], [69, 72], [73, 77], [78, 81], [82, 87], [88, 96], [97, 100], [101, 109], [110, 117], [118, 122], [123, 124], [125, 131], [132, 138], [138, 139], [140, 143], [144, 152], [153, 164], [165, 176], [177, 179], [180, 189], [190, 200], [201, 204], [205, 207], [208, 211], [212, 216], [217, 221], [222, 230], [230, 231]]}
{"doc_key": "ai-test-164", "ner": [[12, 13, "field"], [27, 28, "field"], [31, 36, "field"], [40, 41, "algorithm"], [43, 44, "task"], [46, 47, "algorithm"], [52, 53, "algorithm"], [55, 56, "algorithm"], [62, 64, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[31, 36, 27, 28, "part-of", "subfield", false, false], [40, 41, 31, 36, "part-of", "", false, true], [43, 44, 31, 36, "part-of", "", false, true], [46, 47, 31, 36, "part-of", "", false, true], [52, 53, 31, 36, "part-of", "", false, true], [55, 56, 31, 36, "part-of", "", false, true], [62, 64, 31, 36, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "the", "size", "and", "complexity", "of", "data", "sets", "increased", ",", "direct", "practical", "data", "analysis", "was", "complemented", "by", "indirect", "automated", "data", "processing", ",", "aided", "by", "other", "discoveries", "in", "computer", "science", ",", "particularly", "in", "the", "field", "of", "machine", "learning", ",", "such", "as", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "decision", "trees", "and", "decision", "rules", "(", "1960s", ")", ",", "and", "support", "vector", "machines", "(", "1990s", ")", "."], "sentence-detokenized": "As the size and complexity of data sets increased, direct practical data analysis was complemented by indirect automated data processing, aided by other discoveries in computer science, particularly in the field of machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision trees and decision rules (1960s), and support vector machines (1990s).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 15], [16, 26], [27, 29], [30, 34], [35, 39], [40, 49], [49, 50], [51, 57], [58, 67], [68, 72], [73, 81], [82, 85], [86, 98], [99, 101], [102, 110], [111, 120], [121, 125], [126, 136], [136, 137], [138, 143], [144, 146], [147, 152], [153, 164], [165, 167], [168, 176], [177, 184], [184, 185], [186, 198], [199, 201], [202, 205], [206, 211], [212, 214], [215, 222], [223, 231], [231, 232], [233, 237], [238, 240], [241, 247], [248, 256], [256, 257], [258, 265], [266, 274], [274, 275], [276, 283], [284, 294], [295, 296], [296, 301], [301, 302], [302, 303], [304, 312], [313, 318], [319, 322], [323, 331], [332, 337], [338, 339], [339, 344], [344, 345], [345, 346], [347, 350], [351, 358], [359, 365], [366, 374], [375, 376], [376, 381], [381, 382], [382, 383]]}
{"doc_key": "ai-test-165", "ner": [[6, 6, "researcher"], [10, 11, "misc"], [18, 19, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 11, 6, 6, "artifact", "", false, false], [10, 11, 18, 19, "artifact", "", false, false], [10, 11, 21, 22, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "autumn", "of", "2005", ",", "Thrun", "published", "the", "textbook", "Probabilistic", "Robotics", "with", "his", "long", "-", "term", "collaborators", "Dieter", "Fox", "and", "Wolfram", "Burgard", "."], "sentence-detokenized": "In the autumn of 2005, Thrun published the textbook Probabilistic Robotics with his long-term collaborators Dieter Fox and Wolfram Burgard.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 21], [21, 22], [23, 28], [29, 38], [39, 42], [43, 51], [52, 65], [66, 74], [75, 79], [80, 83], [84, 88], [88, 89], [89, 93], [94, 107], [108, 114], [115, 118], [119, 122], [123, 130], [131, 138], [138, 139]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereiramath", "as", "follows", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereiramath as follows:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 49], [50, 52], [53, 60], [60, 61]]}
{"doc_key": "ai-test-167", "ner": [[0, 1, "task"], [3, 3, "task"], [7, 8, "field"], [14, 15, "field"], [18, 19, "field"], [10, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 18, 19, "part-of", "task_part_of_field", false, false], [3, 3, 0, 1, "named", "", false, false], [14, 15, 7, 8, "part-of", "subfield", false, false], [18, 19, 7, 8, "part-of", "subfield", false, false], [10, 24, 18, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Question", "answering", "(", "QA", ")", "is", "a", "computer", "science", "discipline", "in", "the", "field", "of", "information", "retrieval", "and", "natural", "language", "processing", "(", "NLP", ")", ",", "which", "deals", "with", "the", "creation", "of", "systems", "that", "automatically", "answer", "questions", "asked", "by", "humans", "in", "natural", "language", "."], "sentence-detokenized": "Question answering (QA) is a computer science discipline in the field of information retrieval and natural language processing (NLP), which deals with the creation of systems that automatically answer questions asked by humans in natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 37], [38, 45], [46, 56], [57, 59], [60, 63], [64, 69], [70, 72], [73, 84], [85, 94], [95, 98], [99, 106], [107, 115], [116, 126], [127, 128], [128, 131], [131, 132], [132, 133], [134, 139], [140, 145], [146, 150], [151, 154], [155, 163], [164, 166], [167, 174], [175, 179], [180, 193], [194, 200], [201, 210], [211, 216], [217, 219], [220, 226], [227, 229], [230, 237], [238, 246], [246, 247]]}
{"doc_key": "ai-test-168", "ner": [[6, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "the", "metric", "used", "in", "NIST", "'s", "evaluations", "prior", "to", "2009", "used", "the", "shortest", "reference", "term", "."], "sentence-detokenized": "However, the metric used in NIST's evaluations prior to 2009 used the shortest reference term.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 19], [20, 24], [25, 27], [28, 32], [32, 34], [35, 46], [47, 52], [53, 55], [56, 60], [61, 65], [66, 69], [70, 78], [79, 88], [89, 93], [93, 94]]}
{"doc_key": "ai-test-169", "ner": [[5, 5, "person"], [15, 15, "organisation"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 16, 16, "related-to", "invests_in", false, false], [16, 16, 15, 15, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["On", "27", "August", "2018", ",", "Toyota", "announced", "that", "it", "will", "invest", "$", "500", "million", "in", "Uber", "autonomous", "cars", "."], "sentence-detokenized": "On 27 August 2018, Toyota announced that it will invest $500 million in Uber autonomous cars.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 17], [17, 18], [19, 25], [26, 35], [36, 40], [41, 43], [44, 48], [49, 55], [56, 57], [57, 60], [61, 68], [69, 71], [72, 76], [77, 87], [88, 92], [92, 93]]}
{"doc_key": "ai-test-170", "ner": [[5, 11, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sample", "maximum", "is", "the", "maximum", "likelihood", "estimator", "of", "the", "population", "maximum", ",", "but", ",", "as", "mentioned", "above", ",", "it", "is", "biased", "."], "sentence-detokenized": "The sample maximum is the maximum likelihood estimator of the population maximum, but, as mentioned above, it is biased.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 25], [26, 33], [34, 44], [45, 54], [55, 57], [58, 61], [62, 72], [73, 80], [80, 81], [82, 85], [85, 86], [87, 89], [90, 99], [100, 105], [105, 106], [107, 109], [110, 112], [113, 119], [119, 120]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [3, 3, "misc"], [6, 6, "metrics"], [17, 19, "algorithm"], [21, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 3, "related-to", "overcomes", false, false], [0, 0, 6, 6, "related-to", "increases", false, false], [3, 3, 17, 19, "opposite", "", false, false], [3, 3, 21, 23, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "helps", "overcome", "synonymy", "by", "increasing", "recall", ",", "which", "is", "one", "of", "the", "most", "problematic", "limitations", "of", "Boolean", "keyword", "queries", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI helps overcome synonymy by increasing recall, which is one of the most problematic limitations of Boolean keyword queries and vector space models.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 27], [28, 30], [31, 41], [42, 48], [48, 49], [50, 55], [56, 58], [59, 62], [63, 65], [66, 69], [70, 74], [75, 86], [87, 98], [99, 101], [102, 109], [110, 117], [118, 125], [126, 129], [130, 136], [137, 142], [143, 149], [149, 150]]}
{"doc_key": "ai-test-172", "ner": [[0, 1, "task"], [18, 18, "programlang"], [20, 20, "programlang"], [22, 22, "programlang"], [24, 25, "programlang"], [27, 27, "programlang"], [29, 29, "programlang"], [31, 31, "programlang"], [33, 33, "programlang"], [35, 35, "programlang"], [37, 37, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 18, 18, "general-affiliation", "", false, false], [0, 1, 20, 20, "general-affiliation", "", false, false], [0, 1, 22, 22, "general-affiliation", "", false, false], [0, 1, 24, 25, "general-affiliation", "", false, false], [0, 1, 27, 27, "general-affiliation", "", false, false], [0, 1, 29, 29, "general-affiliation", "", false, false], [0, 1, 31, 31, "general-affiliation", "", false, false], [0, 1, 33, 33, "general-affiliation", "", false, false], [0, 1, 35, 35, "general-affiliation", "", false, false], [0, 1, 37, 37, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Data", "collection", "applications", "are", "usually", "driven", "by", "software", "developed", "using", "various", "general", "-", "purpose", "programming", "languages", "such", "as", "Assembly", ",", "BASIC", ",", "C", ",", "C", "++", ",", "C#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc", "."], "sentence-detokenized": "Data collection applications are usually driven by software developed using various general-purpose programming languages such as Assembly, BASIC, C, C++, C#, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 32], [33, 40], [41, 47], [48, 50], [51, 59], [60, 69], [70, 75], [76, 83], [84, 91], [91, 92], [92, 99], [100, 111], [112, 121], [122, 126], [127, 129], [130, 138], [138, 139], [140, 145], [145, 146], [147, 148], [148, 149], [150, 151], [151, 153], [153, 154], [155, 157], [157, 158], [159, 166], [166, 167], [168, 172], [172, 173], [174, 181], [181, 182], [183, 187], [187, 188], [189, 195], [195, 196], [197, 200], [200, 201]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [9, 9, "product"], [10, 12, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 3, 3, "artifact", "", false, false], [9, 9, 10, 12, "physical", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2003", ",", "Honda", "released", "an", "advertisement", "for", "the", "Cog", "in", "the", "UK", "and", "on", "the", "Internet", "."], "sentence-detokenized": "In 2003, Honda released an advertisement for the Cog in the UK and on the Internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 26], [27, 40], [41, 44], [45, 48], [49, 52], [53, 55], [56, 59], [60, 62], [63, 66], [67, 69], [70, 73], [74, 82], [82, 83]]}
{"doc_key": "ai-test-174", "ner": [[1, 4, "conference"], [6, 7, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 4, 6, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Association", "for", "Computational", "Linguistics", "defines", "computational", "linguistics", "as", ":"], "sentence-detokenized": "The Association for Computational Linguistics defines computational linguistics as:", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 45], [46, 53], [54, 67], [68, 79], [80, 82], [82, 83]]}
{"doc_key": "ai-test-175", "ner": [[0, 2, "algorithm"], [9, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 12, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Expectation", "-maximization", "algorithms", "can", "be", "applied", "to", "compute", "approximate", "maximum", "likelihood", "estimates", "of", "unknown", "state", "-", "space", "parameters", "within", "minimum", "variance", "filters", "and", "smoothers", "."], "sentence-detokenized": "Expectation-maximization algorithms can be applied to compute approximate maximum likelihood estimates of unknown state-space parameters within minimum variance filters and smoothers.", "token2charspan": [[0, 11], [11, 24], [25, 35], [36, 39], [40, 42], [43, 50], [51, 53], [54, 61], [62, 73], [74, 81], [82, 92], [93, 102], [103, 105], [106, 113], [114, 119], [119, 120], [120, 125], [126, 136], [137, 143], [144, 151], [152, 160], [161, 168], [169, 172], [173, 182], [182, 183]]}
{"doc_key": "ai-test-176", "ner": [[14, 14, "misc"], [4, 6, "person"], [8, 9, "person"], [11, 12, "person"], [15, 16, "misc"], [17, 18, "person"], [21, 22, "person"], [26, 26, "person"], [28, 29, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[4, 6, 14, 14, "role", "actor_in", false, false], [8, 9, 14, 14, "role", "actor_in", false, false], [11, 12, 14, 14, "role", "actor_in", false, false], [17, 18, 15, 16, "role", "model_for", false, false], [26, 26, 28, 29, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["His", "pen", "pals", "included", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "and", "Traci", "Bingham", ",", "former", "Playboy", "Playmate", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", "and", "identical", "twins", "Randy", "and", "Jason", "Sklar", "."], "sentence-detokenized": "His pen pals included Donna D'Errico, Carmen Electra and Traci Bingham, former Playboy Playmate Heidi Mark, comedian Arj Barker and identical twins Randy and Jason Sklar.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 21], [22, 27], [28, 30], [30, 36], [36, 37], [38, 44], [45, 52], [53, 56], [57, 62], [63, 70], [70, 71], [72, 78], [79, 86], [87, 95], [96, 101], [102, 106], [106, 107], [108, 116], [117, 120], [121, 127], [128, 131], [132, 141], [142, 147], [148, 153], [154, 157], [158, 163], [164, 169], [169, 170]]}
{"doc_key": "ai-test-177", "ner": [[6, 7, "task"], [9, 9, "task"], [14, 17, "product"], [20, 21, "task"], [23, 23, "task"], [29, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 9, 6, 7, "named", "", false, false], [14, 17, 6, 7, "general-affiliation", "", false, false], [23, 23, 20, 21, "named", "", false, false], [29, 30, 20, 21, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "is", "commonly", "used", "to", "generate", "speech", "recognition", "(", "ASR", ")", ",", "such", "as", "CMU", "'s", "Sphinx", "system", ",", "and", "speech", "synthesis", "(", "TTS", ")", ",", "such", "as", "the", "Festival", "system", ",", "representations", "."], "sentence-detokenized": "It is commonly used to generate speech recognition (ASR), such as CMU's Sphinx system, and speech synthesis (TTS), such as the Festival system, representations.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 19], [20, 22], [23, 31], [32, 38], [39, 50], [51, 52], [52, 55], [55, 56], [56, 57], [58, 62], [63, 65], [66, 69], [69, 71], [72, 78], [79, 85], [85, 86], [87, 90], [91, 97], [98, 107], [108, 109], [109, 112], [112, 113], [113, 114], [115, 119], [120, 122], [123, 126], [127, 135], [136, 142], [142, 143], [144, 159], [159, 160]]}
{"doc_key": "ai-test-178", "ner": [[0, 0, "metrics"], [2, 4, "metrics"], [6, 6, "metrics"], [12, 12, "metrics"], [24, 25, "metrics"], [27, 27, "metrics"], [39, 39, "metrics"], [41, 41, "metrics"], [43, 45, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 4, 0, 0, "named", "", false, false], [6, 6, 2, 4, "named", "", false, false], [12, 12, 0, 0, "named", "", false, false], [27, 27, 24, 25, "named", "", false, false], [41, 41, 39, 39, "named", "", false, false], [43, 45, 39, 39, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sensitivity", "or", "TRUE", "Positive", "Rate", "(", "TPR", ")", ",", "also", "known", "as", "recall", ",", "is", "the", "proportion", "of", "people", "who", "test", "positive", "and", "are", "TRUE", "Positive", "(", "TP", ")", "compared", "to", "the", "total", "number", "of", "people", "who", "are", "Condition", "Positive", "(", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "Sensitivity or TRUE Positive Rate (TPR), also known as recall, is the proportion of people who test positive and are TRUE Positive (TP) compared to the total number of people who are Condition Positive (CP = TP + FN).", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 28], [29, 33], [34, 35], [35, 38], [38, 39], [39, 40], [41, 45], [46, 51], [52, 54], [55, 61], [61, 62], [63, 65], [66, 69], [70, 80], [81, 83], [84, 90], [91, 94], [95, 99], [100, 108], [109, 112], [113, 116], [117, 121], [122, 130], [131, 132], [132, 134], [134, 135], [136, 144], [145, 147], [148, 151], [152, 157], [158, 164], [165, 167], [168, 174], [175, 178], [179, 182], [183, 192], [193, 201], [202, 203], [203, 205], [206, 207], [208, 210], [211, 212], [213, 215], [215, 216], [216, 217]]}
{"doc_key": "ai-test-179", "ner": [[1, 2, "task"], [11, 11, "conference"], [13, 14, "conference"], [16, 16, "conference"], [18, 20, "conference"], [22, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6], "relations": [[11, 11, 1, 2, "topic", "", false, false], [13, 14, 1, 2, "topic", "", false, false], [16, 16, 1, 2, "topic", "", false, false], [18, 20, 1, 2, "topic", "", false, false], [22, 23, 1, 2, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5], "sentence": ["Popular", "speech", "recognition", "conferences", "held", "annually", "or", "every", "two", "years", "include", "SpeechTEK", "and", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "and", "IEEE", "ASRU", "."], "sentence-detokenized": "Popular speech recognition conferences held annually or every two years include SpeechTEK and SpeechTEK Europe, ICASSP, Interspeech/Eurospeech and IEEE ASRU.", "token2charspan": [[0, 7], [8, 14], [15, 26], [27, 38], [39, 43], [44, 52], [53, 55], [56, 61], [62, 65], [66, 71], [72, 79], [80, 89], [90, 93], [94, 103], [104, 110], [110, 111], [112, 118], [118, 119], [120, 131], [131, 132], [132, 142], [143, 146], [147, 151], [152, 156], [156, 157]]}
{"doc_key": "ai-test-180", "ner": [[3, 3, "researcher"], [4, 4, "researcher"], [17, 19, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 3, 3, "artifact", "", false, false], [22, 22, 4, 4, "artifact", "", false, false], [22, 22, 17, 19, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "collaborated", "with", "Devol", "Engelberger", ",", "who", "was", "president", "of", "the", "company", ",", "to", "design", "and", "manufacture", "an", "industrial", "robot", "under", "the", "Unimate", "brand", "."], "sentence-detokenized": "He collaborated with Devol Engelberger, who was president of the company, to design and manufacture an industrial robot under the Unimate brand.", "token2charspan": [[0, 2], [3, 15], [16, 20], [21, 26], [27, 38], [38, 39], [40, 43], [44, 47], [48, 57], [58, 60], [61, 64], [65, 72], [72, 73], [74, 76], [77, 83], [84, 87], [88, 99], [100, 102], [103, 113], [114, 119], [120, 125], [126, 129], [130, 137], [138, 143], [143, 144]]}
{"doc_key": "ai-test-181", "ner": [[1, 2, "algorithm"], [5, 5, "algorithm"], [9, 13, "algorithm"], [24, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 9, 13, "general-affiliation", "", false, false], [5, 5, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "hidden", "Markov", "model", "(", "HMM", ")", "is", "a", "statistical", "Markov", "model", "in", "which", "the", "system", "to", "be", "modelled", "is", "assumed", "to", "be", "a", "Markov", "process", "with", "unobserved", "(", "hidden", ")", "states", "."], "sentence-detokenized": "A hidden Markov model (HMM) is a statistical Markov model in which the system to be modelled is assumed to be a Markov process with unobserved (hidden) states.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [22, 23], [23, 26], [26, 27], [28, 30], [31, 32], [33, 44], [45, 51], [52, 57], [58, 60], [61, 66], [67, 70], [71, 77], [78, 80], [81, 83], [84, 92], [93, 95], [96, 103], [104, 106], [107, 109], [110, 111], [112, 118], [119, 126], [127, 131], [132, 142], [143, 144], [144, 150], [150, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-test-182", "ner": [[17, 19, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "property", "is", "undesirable", "in", "many", "applications", ",", "and", "has", "led", "researchers", "to", "use", "alternatives", "such", "as", "mean", "absolute", "error", "or", "median", "-", "based", "errors", "."], "sentence-detokenized": "This property is undesirable in many applications, and has led researchers to use alternatives such as mean absolute error or median-based errors.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 28], [29, 31], [32, 36], [37, 49], [49, 50], [51, 54], [55, 58], [59, 62], [63, 74], [75, 77], [78, 81], [82, 94], [95, 99], [100, 102], [103, 107], [108, 116], [117, 122], [123, 125], [126, 132], [132, 133], [133, 138], [139, 145], [145, 146]]}
{"doc_key": "ai-test-183", "ner": [[20, 23, "algorithm"], [30, 31, "field"], [34, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 23, 30, 31, "part-of", "", false, false], [20, 23, 34, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Such", "a", "sequence", "(", "which", "at", "each", "stage", "depends", "on", "the", "outcome", "of", "the", "previous", "attribute", "test", ")", "is", "called", "a", "decision", "tree", "and", "is", "used", "in", "the", "field", "of", "machine", "learning", "known", "as", "decision", "tree", "learning", "."], "sentence-detokenized": "Such a sequence (which at each stage depends on the outcome of the previous attribute test) is called a decision tree and is used in the field of machine learning known as decision tree learning.", "token2charspan": [[0, 4], [5, 6], [7, 15], [16, 17], [17, 22], [23, 25], [26, 30], [31, 36], [37, 44], [45, 47], [48, 51], [52, 59], [60, 62], [63, 66], [67, 75], [76, 85], [86, 90], [90, 91], [92, 94], [95, 101], [102, 103], [104, 112], [113, 117], [118, 121], [122, 124], [125, 129], [130, 132], [133, 136], [137, 142], [143, 145], [146, 153], [154, 162], [163, 168], [169, 171], [172, 180], [181, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-test-184", "ner": [[1, 2, "task"], [4, 5, "algorithm"], [14, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 4, 5, "compare", "", false, false], [14, 16, 4, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Like", "factor", "analysis", ",", "LCA", "can", "be", "used", "to", "classify", "cases", "according", "to", "their", "maximum", "likelihood", "of", "belonging", "to", "a", "class", "."], "sentence-detokenized": "Like factor analysis, LCA can be used to classify cases according to their maximum likelihood of belonging to a class.", "token2charspan": [[0, 4], [5, 11], [12, 20], [20, 21], [22, 25], [26, 29], [30, 32], [33, 37], [38, 40], [41, 49], [50, 55], [56, 65], [66, 68], [69, 74], [75, 82], [83, 93], [94, 96], [97, 106], [107, 109], [110, 111], [112, 117], [117, 118]]}
{"doc_key": "ai-test-185", "ner": [[0, 2, "algorithm"], [8, 9, "metrics"], [7, 11, "metrics"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 8, 9, "usage", "", false, false], [8, 9, 13, 14, "related-to", "", false, false], [7, 11, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Supervised", "neural", "networks", ",", "which", "use", "a", "mean", "squared", "error", "(", "MSE", ")", "cost", "function", ",", "can", "use", "formal", "statistical", "methods", "to", "determine", "the", "reliability", "of", "the", "trained", "model", "."], "sentence-detokenized": "Supervised neural networks, which use a mean squared error (MSE) cost function, can use formal statistical methods to determine the reliability of the trained model.", "token2charspan": [[0, 10], [11, 17], [18, 26], [26, 27], [28, 33], [34, 37], [38, 39], [40, 44], [45, 52], [53, 58], [59, 60], [60, 63], [63, 64], [65, 69], [70, 78], [78, 79], [80, 83], [84, 87], [88, 94], [95, 106], [107, 114], [115, 117], [118, 127], [128, 131], [132, 143], [144, 146], [147, 150], [151, 158], [159, 164], [164, 165]]}
{"doc_key": "ai-test-186", "ner": [[16, 18, "algorithm"], [20, 22, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 18, 20, 22, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "expressed", "directly", "as", "a", "linear", "program", ",", "but", "is", "also", "equivalent", "to", "the", "Tikhonov", "regularization", "with", "the", "joint", "loss", "function", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=\\", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "This can be expressed directly as a linear program, but is also equivalent to the Tikhonov regularization with the joint loss function, mathV (f (x), y) =\\ max (0, 1 - yf (x)) / math:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 21], [22, 30], [31, 33], [34, 35], [36, 42], [43, 50], [50, 51], [52, 55], [56, 58], [59, 63], [64, 74], [75, 77], [78, 81], [82, 90], [91, 105], [106, 110], [111, 114], [115, 120], [121, 125], [126, 134], [134, 135], [136, 141], [142, 143], [143, 144], [145, 146], [146, 147], [147, 148], [148, 149], [150, 151], [151, 152], [153, 155], [156, 159], [160, 161], [161, 162], [162, 163], [164, 165], [166, 167], [168, 170], [171, 172], [172, 173], [173, 174], [174, 175], [176, 177], [178, 182], [182, 183]]}
{"doc_key": "ai-test-187", "ner": [[6, 6, "researcher"], [14, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "technique", "was", "described", "by", "Breiman", "in", "his", "original", "paper", "and", "is", "implemented", "in", "the", "randomForest", "R", "package", "."], "sentence-detokenized": "The following technique was described by Breiman in his original paper and is implemented in the randomForest R package.", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 27], [28, 37], [38, 40], [41, 48], [49, 51], [52, 55], [56, 64], [65, 70], [71, 74], [75, 77], [78, 89], [90, 92], [93, 96], [97, 109], [110, 111], [112, 119], [119, 120]]}
{"doc_key": "ai-test-188", "ner": [[7, 7, "metrics"], [37, 37, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "image", "quality", "measurements", ",", "such", "as", "PSNR", ",", "are", "typically", "performed", "on", "fixed", "resolution", "images", "and", "do", "not", "take", "into", "account", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "changes", "in", "spatial", "resolution", "on", "the", "retina", "."], "sentence-detokenized": "Traditional image quality measurements, such as PSNR, are typically performed on fixed resolution images and do not take into account aspects of the human visual system, such as changes in spatial resolution on the retina.", "token2charspan": [[0, 11], [12, 17], [18, 25], [26, 38], [38, 39], [40, 44], [45, 47], [48, 52], [52, 53], [54, 57], [58, 67], [68, 77], [78, 80], [81, 86], [87, 97], [98, 104], [105, 108], [109, 111], [112, 115], [116, 120], [121, 125], [126, 133], [134, 141], [142, 144], [145, 148], [149, 154], [155, 161], [162, 168], [168, 169], [170, 174], [175, 177], [178, 185], [186, 188], [189, 196], [197, 207], [208, 210], [211, 214], [215, 221], [221, 222]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [10, 12, "person"], [16, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 19, "role", "", false, false], [3, 4, 16, 19, "role", "", false, false], [6, 7, 16, 19, "role", "", false, false], [16, 19, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "and", "Macdonald", "Carey", "starred", "in", "Jack", "Broder", "'s", "colour", "production", "of", "Hannah", "Lee", ",", "which", "premiered", "on", "19", "June", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru and Macdonald Carey starred in Jack Broder's colour production of Hannah Lee, which premiered on 19 June 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 55], [56, 60], [61, 67], [67, 69], [70, 76], [77, 87], [88, 90], [91, 97], [98, 101], [101, 102], [103, 108], [109, 118], [119, 121], [122, 124], [125, 129], [130, 134], [134, 135]]}
{"doc_key": "ai-test-190", "ner": [[4, 5, "task"], [11, 12, "field"], [17, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 11, 12, "usage", "", false, false], [17, 17, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "process", "is", "called", "image", "registration", "and", "uses", "various", "methods", "of", "computer", "vision", ",", "mostly", "related", "to", "tracking", "."], "sentence-detokenized": "This process is called image registration and uses various methods of computer vision, mostly related to tracking.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 22], [23, 28], [29, 41], [42, 45], [46, 50], [51, 58], [59, 66], [67, 69], [70, 78], [79, 85], [85, 86], [87, 93], [94, 101], [102, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-191", "ner": [[17, 18, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Now", "let", "'s", "start", "explaining", "the", "different", "possible", "relationships", "between", "the", "predicted", "and", "the", "actual", "outcome", ":", "confusion", "matrix"], "sentence-detokenized": "Now let's start explaining the different possible relationships between the predicted and the actual outcome: confusion matrix", "token2charspan": [[0, 3], [4, 7], [7, 9], [10, 15], [16, 26], [27, 30], [31, 40], [41, 49], [50, 63], [64, 71], [72, 75], [76, 85], [86, 89], [90, 93], [94, 100], [101, 108], [108, 109], [110, 119], [120, 126]]}
{"doc_key": "ai-test-192", "ner": [[2, 2, "product"], [3, 5, "misc"], [1, 1, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 3, 5, "part-of", "", false, false], [2, 2, 3, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "MATLAB", "VOICEBOX", "speech", "processing", "toolkit", "implements", "the", "conversion", "and", "its", "inverse", "as", "follows", ":"], "sentence-detokenized": "The MATLAB VOICEBOX speech processing toolkit implements the conversion and its inverse as follows:", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 26], [27, 37], [38, 45], [46, 56], [57, 60], [61, 71], [72, 75], [76, 79], [80, 87], [88, 90], [91, 98], [98, 99]]}
{"doc_key": "ai-test-193", "ner": [[0, 2, "programlang"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 8, 9, "general-affiliation", "", false, false], [0, 2, 11, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logic", "programming", "language", "related", "to", "artificial", "intelligence", "and", "computer", "linguistics", "."], "sentence-detokenized": "Prolog is a logic programming language related to artificial intelligence and computer linguistics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 17], [18, 29], [30, 38], [39, 46], [47, 49], [50, 60], [61, 73], [74, 77], [78, 86], [87, 98], [98, 99]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [9, 9, "field"], [11, 11, "field"], [17, 20, "organisation"], [23, 26, "organisation"], [29, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 9, 9, "related-to", "works_with_topic", false, false], [0, 0, 11, 11, "related-to", "works_with_topic", false, false], [0, 0, 17, 20, "role", "", false, false], [0, 0, 23, 26, "role", "", false, false], [0, 0, 29, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "numerous", "awards", "for", "his", "contributions", "to", "neuroscience", "and", "psychology", ",", "including", "Fellowships", "of", "the", "Royal", "Society", "of", "London", ",", "the", "Royal", "Society", "of", "Canada", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received numerous awards for his contributions to neuroscience and psychology, including Fellowships of the Royal Society of London, the Royal Society of Canada and the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 35], [36, 39], [40, 43], [44, 57], [58, 60], [61, 73], [74, 77], [78, 88], [88, 89], [90, 99], [100, 111], [112, 114], [115, 118], [119, 124], [125, 132], [133, 135], [136, 142], [142, 143], [144, 147], [148, 153], [154, 161], [162, 164], [165, 171], [172, 175], [176, 179], [180, 188], [189, 196], [197, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-test-195", "ner": [[13, 14, "field"], [18, 19, "task"], [21, 22, "task"], [24, 25, "task"], [27, 28, "task"], [30, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 19, 13, 14, "part-of", "task_part_of_field", false, false], [21, 22, 13, 14, "part-of", "task_part_of_field", false, false], [24, 25, 13, 14, "part-of", "task_part_of_field", false, false], [27, 28, 13, 14, "part-of", "task_part_of_field", false, false], [30, 30, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["By", "combining", "these", "operators", ",", "algorithms", "can", "be", "obtained", "for", "a", "variety", "of", "image", "processing", "tasks", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "sharpening", ",", "image", "filtering", "and", "classification", "."], "sentence-detokenized": "By combining these operators, algorithms can be obtained for a variety of image processing tasks such as feature extraction, image segmentation, image sharpening, image filtering and classification.", "token2charspan": [[0, 2], [3, 12], [13, 18], [19, 28], [28, 29], [30, 40], [41, 44], [45, 47], [48, 56], [57, 60], [61, 62], [63, 70], [71, 73], [74, 79], [80, 90], [91, 96], [97, 101], [102, 104], [105, 112], [113, 123], [123, 124], [125, 130], [131, 143], [143, 144], [145, 150], [151, 161], [161, 162], [163, 168], [169, 178], [179, 182], [183, 197], [197, 198]]}
{"doc_key": "ai-test-196", "ner": [[6, 8, "university"], [17, 20, "organisation"], [15, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 17, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "has", "been", "Professor", "at", "the", "Coll\u00e8ge", "de", "France", "since", "2017", "and", "Director", "of", "the", "Cognitive", "Neuroimaging", "Unit", "562", "at", "INSERM", "since", "1989", "."], "sentence-detokenized": "He has been Professor at the Coll\u00e8ge de France since 2017 and Director of the Cognitive Neuroimaging Unit 562 at INSERM since 1989.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 21], [22, 24], [25, 28], [29, 36], [37, 39], [40, 46], [47, 52], [53, 57], [58, 61], [62, 70], [71, 73], [74, 77], [78, 87], [88, 100], [101, 105], [106, 109], [110, 112], [113, 119], [120, 125], [126, 130], [130, 131]]}
{"doc_key": "ai-test-197", "ner": [[11, 13, "algorithm"], [15, 18, "algorithm"], [23, 23, "algorithm"], [25, 31, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 25, 31, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "several", "approaches", "to", "learning", "these", "embeddings", ",", "notably", "using", "Bayesian", "clustering", "frameworks", "or", "energy", "-", "based", "frameworks", ",", "and", "more", "recently", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", "2013", ")", "."], "sentence-detokenized": "There are several approaches to learning these embeddings, notably using Bayesian clustering frameworks or energy-based frameworks, and more recently TransE (Conference on Neural Information Processing Systems 2013).", "token2charspan": [[0, 5], [6, 9], [10, 17], [18, 28], [29, 31], [32, 40], [41, 46], [47, 57], [57, 58], [59, 66], [67, 72], [73, 81], [82, 92], [93, 103], [104, 106], [107, 113], [113, 114], [114, 119], [120, 130], [130, 131], [132, 135], [136, 140], [141, 149], [150, 156], [157, 158], [158, 168], [169, 171], [172, 178], [179, 190], [191, 201], [202, 209], [210, 214], [214, 215], [215, 216]]}
{"doc_key": "ai-test-198", "ner": [[6, 7, "metrics"], [8, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 8, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "an", "alternative", "to", "the", "Word", "Error", "Rate", "used", "in", "many", "countries", "."], "sentence-detokenized": "This is an alternative to the Word Error Rate used in many countries.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 25], [26, 29], [30, 34], [35, 40], [41, 45], [46, 50], [51, 53], [54, 58], [59, 68], [68, 69]]}
{"doc_key": "ai-test-199", "ner": [[0, 0, "algorithm"], [11, 12, "task"], [14, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 27, "task"], [29, 32, "task"], [42, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 0, 0, "usage", "", false, false], [14, 15, 0, 0, "usage", "", false, false], [17, 18, 0, 0, "usage", "", false, false], [20, 22, 0, 0, "usage", "", false, false], [24, 27, 0, 0, "usage", "", false, false], [29, 32, 0, 0, "usage", "", false, false], [42, 42, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "are", "used", "for", "a", "wide", "range", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "social", "and", "video", "games", ",", "medical", "diagnostics", ",", "and", "even", "activities", "traditionally", "reserved", "for", "humans", ",", "such", "as", "painting", "."], "sentence-detokenized": "ANNs are used for a wide range of tasks, including computer vision, speech recognition, machine translation, social network filtering, social and video games, medical diagnostics, and even activities traditionally reserved for humans, such as painting.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 17], [18, 19], [20, 24], [25, 30], [31, 33], [34, 39], [39, 40], [41, 50], [51, 59], [60, 66], [66, 67], [68, 74], [75, 86], [86, 87], [88, 95], [96, 107], [107, 108], [109, 115], [116, 123], [124, 133], [133, 134], [135, 141], [142, 145], [146, 151], [152, 157], [157, 158], [159, 166], [167, 178], [178, 179], [180, 183], [184, 188], [189, 199], [200, 213], [214, 222], [223, 226], [227, 233], [233, 234], [235, 239], [240, 242], [243, 251], [251, 252]]}
{"doc_key": "ai-test-200", "ner": [[0, 4, "product"], [6, 6, "product"], [24, 26, "field"], [28, 28, "field"], [33, 33, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 24, 26, "related-to", "", false, false], [0, 4, 33, 33, "general-affiliation", "", false, false], [6, 6, 0, 4, "named", "", false, false], [28, 28, 24, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "is", "an", "open", "source", "research", "platform", "and", "a", "collection", "of", "voice", ",", "speech", ",", "text", "and", "natural", "language", "processing", "(", "NLP", ")", "algorithms", "written", "in", "Java", ",", "organized", "in", "a", "modular", "and", "extensible", "framework", "that", "attempts", "to", "facilitate", "the", "addition", "of", "new", "algorithms", "."], "sentence-detokenized": "The Modular Audio Recognition Framework (MARF) is an open source research platform and a collection of voice, speech, text and natural language processing (NLP) algorithms written in Java, organized in a modular and extensible framework that attempts to facilitate the addition of new algorithms.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 29], [30, 39], [40, 41], [41, 45], [45, 46], [47, 49], [50, 52], [53, 57], [58, 64], [65, 73], [74, 82], [83, 86], [87, 88], [89, 99], [100, 102], [103, 108], [108, 109], [110, 116], [116, 117], [118, 122], [123, 126], [127, 134], [135, 143], [144, 154], [155, 156], [156, 159], [159, 160], [161, 171], [172, 179], [180, 182], [183, 187], [187, 188], [189, 198], [199, 201], [202, 203], [204, 211], [212, 215], [216, 226], [227, 236], [237, 241], [242, 250], [251, 253], [254, 264], [265, 268], [269, 277], [278, 280], [281, 284], [285, 295], [295, 296]]}
{"doc_key": "ai-test-201", "ner": [[11, 13, "organisation"], [21, 23, "organisation"], [26, 27, "organisation"], [31, 32, "task"], [44, 46, "organisation"], [50, 52, "task"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6], "relations": [[21, 23, 31, 32, "usage", "", false, false], [21, 23, 44, 46, "named", "", false, false], [26, 27, 31, 32, "usage", "", false, false], [44, 46, 50, 52, "usage", "", false, false]], "relations_mapping_to_source": [1, 2, 4, 5], "sentence": ["In", "2018", ",", "a", "report", "by", "civil", "liberties", "and", "rights", "organisation", "Big", "Brother", "Watch", "revealed", "that", "two", "UK", "police", "forces", ",", "South", "Wales", "Police", "and", "the", "Metropolitan", "Police", ",", "use", "live", "facial", "recognition", "at", "public", "events", "and", "in", "public", "areas.In", "September", "2019", ",", "the", "South", "Wales", "Police", "'s", "use", "of", "facial", "recognition", "was", "ruled", "lawful", "."], "sentence-detokenized": "In 2018, a report by civil liberties and rights organisation Big Brother Watch revealed that two UK police forces, South Wales Police and the Metropolitan Police, use live facial recognition at public events and in public areas.In September 2019, the South Wales Police's use of facial recognition was ruled lawful.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 20], [21, 26], [27, 36], [37, 40], [41, 47], [48, 60], [61, 64], [65, 72], [73, 78], [79, 87], [88, 92], [93, 96], [97, 99], [100, 106], [107, 113], [113, 114], [115, 120], [121, 126], [127, 133], [134, 137], [138, 141], [142, 154], [155, 161], [161, 162], [163, 166], [167, 171], [172, 178], [179, 190], [191, 193], [194, 200], [201, 207], [208, 211], [212, 214], [215, 221], [222, 230], [231, 240], [241, 245], [245, 246], [247, 250], [251, 256], [257, 262], [263, 269], [269, 271], [272, 275], [276, 278], [279, 285], [286, 297], [298, 301], [302, 307], [308, 314], [314, 315]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [5, 5, "programlang"], [14, 15, "field"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 5, "general-affiliation", "", false, false], [0, 0, 14, 15, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "has", "been", "ported", "to", "R", ",", "a", "freely", "available", "language", "and", "environment", "for", "statistical", "calculations", "and", "graphics", "."], "sentence-detokenized": "ANIMAL has been ported to R, a freely available language and environment for statistical calculations and graphics.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [23, 25], [26, 27], [27, 28], [29, 30], [31, 37], [38, 47], [48, 56], [57, 60], [61, 72], [73, 76], [77, 88], [89, 101], [102, 105], [106, 114], [114, 115]]}
{"doc_key": "ai-test-203", "ner": [[0, 6, "algorithm"], [1, 17, "algorithm"], [18, 19, "algorithm"], [21, 21, "algorithm"], [23, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 18, 19, "opposite", "alternative to", false, false], [1, 17, 0, 6, "named", "", false, false], [21, 21, 18, 19, "named", "", false, false], [23, 26, 0, 6, "usage", "", false, false], [23, 26, 18, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "time", "-", "inhomogeneous", "hidden", "Bernoulli", "model", "(", "TI", "-", "HBM", ")", "is", "an", "alternative", "to", "the", "hidden", "Markov", "model", "(", "HMM", ")", "for", "automatic", "speech", "recognition", "."], "sentence-detokenized": "The time-inhomogeneous hidden Bernoulli model (TI-HBM) is an alternative to the hidden Markov model (HMM) for automatic speech recognition.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 22], [23, 29], [30, 39], [40, 45], [46, 47], [47, 49], [49, 50], [50, 53], [53, 54], [55, 57], [58, 60], [61, 72], [73, 75], [76, 79], [80, 86], [87, 93], [94, 99], [100, 101], [101, 104], [104, 105], [106, 109], [110, 119], [120, 126], [127, 138], [138, 139]]}
{"doc_key": "ai-test-204", "ner": [[4, 4, "organisation"], [13, 13, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 13, 13, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "Nvidia", "unveiled", "a", "new", "method", "of", "foveated", "rendering", "at", "SIGGRAPH", ",", "which", "is", "supposed", "to", "be", "invisible", "to", "users", "."], "sentence-detokenized": "In July 2016, Nvidia unveiled a new method of foveated rendering at SIGGRAPH, which is supposed to be invisible to users.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 29], [30, 31], [32, 35], [36, 42], [43, 45], [46, 54], [55, 64], [65, 67], [68, 76], [76, 77], [78, 83], [84, 86], [87, 95], [96, 98], [99, 101], [102, 111], [112, 114], [115, 120], [120, 121]]}
{"doc_key": "ai-test-205", "ner": [[4, 7, "misc"], [10, 11, "researcher"], [19, 20, "researcher"], [22, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 7, 10, 11, "origin", "", false, false], [4, 7, 19, 20, "origin", "", false, false], [4, 7, 22, 24, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Both", "are", "based", "on", "the", "speech", "act", "theory", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "further", "developed", "by", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both are based on the speech act theory developed by John Searle in the 1960s and further developed by Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 17], [18, 21], [22, 28], [29, 32], [33, 39], [40, 49], [50, 52], [53, 57], [58, 64], [65, 67], [68, 71], [72, 77], [78, 81], [82, 89], [90, 99], [100, 102], [103, 108], [109, 117], [118, 121], [122, 128], [129, 131], [132, 135], [136, 141], [141, 142]]}
{"doc_key": "ai-test-206", "ner": [[0, 3, "algorithm"], [20, 20, "researcher"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 20, 20, "related-to", "", false, false], [22, 23, 20, 20, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "knowledge", "structure", "have", "opened", "up", "powerful", "hierarchical", "models", "of", "knowledge", "organisation", "such", "as", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "Neural network models of concept formation and knowledge structure have opened up powerful hierarchical models of knowledge organisation such as George Miller's Wordnet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 56], [57, 66], [67, 71], [72, 78], [79, 81], [82, 90], [91, 103], [104, 110], [111, 113], [114, 123], [124, 136], [137, 141], [142, 144], [145, 151], [152, 158], [158, 160], [161, 168], [168, 169]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [12, 13, "field"], [16, 18, "product"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 13, "part-of", "", false, false], [0, 1, 21, 23, "part-of", "", false, false], [16, 18, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Template", "matching", "has", "many", "applications", "and", "is", "used", "in", "areas", "such", "as", "facial", "recognition", "(", "see", "facial", "recognition", "system", ")", "and", "medical", "image", "processing", "."], "sentence-detokenized": "Template matching has many applications and is used in areas such as facial recognition (see facial recognition system) and medical image processing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 26], [27, 39], [40, 43], [44, 46], [47, 51], [52, 54], [55, 60], [61, 65], [66, 68], [69, 75], [76, 87], [88, 89], [89, 92], [93, 99], [100, 111], [112, 118], [118, 119], [120, 123], [124, 131], [132, 137], [138, 148], [148, 149]]}
{"doc_key": "ai-test-208", "ner": [[12, 13, "researcher"], [15, 16, "researcher"], [21, 30, "organisation"], [32, 32, "organisation"], [40, 45, "algorithm"], [47, 50, "conference"], [46, 52, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 13, 21, 30, "role", "", false, false], [12, 13, 47, 50, "physical", "", false, false], [12, 13, 47, 50, "temporal", "", false, false], [12, 13, 46, 52, "physical", "", false, false], [15, 16, 21, 30, "role", "", false, false], [15, 16, 47, 50, "temporal", "", false, false], [32, 32, 21, 30, "named", "", false, false], [47, 50, 40, 45, "topic", "", false, false], [46, 52, 47, 50, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "it", "s", "use", "only", "became", "widespread", "in", "2005", ",", "when", "Navneet", "Dalal", "and", "Bill", "Triggs", ",", "researchers", "at", "the", "French", "National", "Institute", "for", "Research", "in", "Computer", "Science", "and", "Automation", "(", "INRIA", ")", ",", "presented", "their", "complementary", "work", "on", "HOG", "descriptors", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "However, its use only became widespread in 2005, when Navneet Dalal and Bill Triggs, researchers at the French National Institute for Research in Computer Science and Automation (INRIA), presented their complementary work on HOG descriptors at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 7], [7, 8], [9, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 39], [40, 42], [43, 47], [47, 48], [49, 53], [54, 61], [62, 67], [68, 71], [72, 76], [77, 83], [83, 84], [85, 96], [97, 99], [100, 103], [104, 110], [111, 119], [120, 129], [130, 133], [134, 142], [143, 145], [146, 154], [155, 162], [163, 166], [167, 177], [178, 179], [179, 184], [184, 185], [185, 186], [187, 196], [197, 202], [203, 216], [217, 221], [222, 224], [225, 228], [229, 240], [241, 243], [244, 247], [248, 258], [259, 261], [262, 270], [271, 277], [278, 281], [282, 289], [290, 301], [302, 303], [303, 307], [307, 308], [308, 309]]}
{"doc_key": "ai-test-209", "ner": [[4, 4, "university"], [17, 19, "organisation"], [21, 22, "organisation"], [29, 29, "field"], [39, 41, "researcher"], [43, 45, "researcher"], [48, 50, "researcher"], [53, 56, "organisation"], [59, 68, "organisation"], [72, 73, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[21, 22, 29, 29, "related-to", "", false, false], [39, 41, 21, 22, "physical", "", false, false], [39, 41, 21, 22, "role", "", false, false], [43, 45, 21, 22, "physical", "", false, false], [43, 45, 21, 22, "role", "", false, false], [48, 50, 21, 22, "physical", "", false, false], [48, 50, 21, 22, "role", "", false, false], [72, 73, 59, 68, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Prior", "to", "joining", "the", "Penn", "faculty", "in", "2002", ",", "he", "spent", "a", "decade", "(", "1991-2001", ")", "at", "AT", "&T", "Labs", "and", "Bell", "Labs", ",", "including", "as", "head", "of", "the", "AI", "Division", ",", "where", "he", "worked", "with", "colleagues", "such", "as", "Michael", "L.", "Littman", ",", "David", "A.", "McAllester", ",", "and", "Richard", "S.", "Sutton", ";", "the", "Secure", "Systems", "Research", "Division", ";", "and", "as", "head", "of", "the", "Machine", "Learning", "Division", ",", "which", "included", "members", "such", "as", "Michael", "Collins", "and", "Chief", ")", "."], "sentence-detokenized": "Prior to joining the Penn faculty in 2002, he spent a decade (1991-2001) at AT&T Labs and Bell Labs, including as head of the AI Division, where he worked with colleagues such as Michael L. Littman, David A. McAllester, and Richard S. Sutton; the Secure Systems Research Division; and as head of the Machine Learning Division, which included members such as Michael Collins and Chief).", "token2charspan": [[0, 5], [6, 8], [9, 16], [17, 20], [21, 25], [26, 33], [34, 36], [37, 41], [41, 42], [43, 45], [46, 51], [52, 53], [54, 60], [61, 62], [62, 71], [71, 72], [73, 75], [76, 78], [78, 80], [81, 85], [86, 89], [90, 94], [95, 99], [99, 100], [101, 110], [111, 113], [114, 118], [119, 121], [122, 125], [126, 128], [129, 137], [137, 138], [139, 144], [145, 147], [148, 154], [155, 159], [160, 170], [171, 175], [176, 178], [179, 186], [187, 189], [190, 197], [197, 198], [199, 204], [205, 207], [208, 218], [218, 219], [220, 223], [224, 231], [232, 234], [235, 241], [241, 242], [243, 246], [247, 253], [254, 261], [262, 270], [271, 279], [279, 280], [281, 284], [285, 287], [288, 292], [293, 295], [296, 299], [300, 307], [308, 316], [317, 325], [325, 326], [327, 332], [333, 341], [342, 349], [350, 354], [355, 357], [358, 365], [366, 373], [374, 377], [378, 383], [383, 384], [384, 385]]}
{"doc_key": "ai-test-210", "ner": [[6, 8, "field"], [13, 14, "field"], [23, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 8, 13, 14, "compare", "", false, false], [23, 25, 13, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "the", "data", "is", "unlabeled", ",", "supervised", "learning", "is", "not", "possible", "and", "an", "unsupervised", "learning", "approach", "is", "needed", "that", "tries", "to", "find", "natural", "cluster", "analysis", "in", "the", "groups", "and", "then", "assign", "new", "data", "to", "these", "formed", "groups", "."], "sentence-detokenized": "If the data is unlabeled, supervised learning is not possible and an unsupervised learning approach is needed that tries to find natural cluster analysis in the groups and then assign new data to these formed groups.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 24], [24, 25], [26, 36], [37, 45], [46, 48], [49, 52], [53, 61], [62, 65], [66, 68], [69, 81], [82, 90], [91, 99], [100, 102], [103, 109], [110, 114], [115, 120], [121, 123], [124, 128], [129, 136], [137, 144], [145, 153], [154, 156], [157, 160], [161, 167], [168, 171], [172, 176], [177, 183], [184, 187], [188, 192], [193, 195], [196, 201], [202, 208], [209, 215], [215, 216]]}
{"doc_key": "ai-test-211", "ner": [[3, 7, "field"], [15, 18, "organisation"], [25, 26, "field"], [28, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 7, 15, 18, "origin", "", false, false], [3, 7, 25, 26, "part-of", "", false, false], [3, 7, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "field", "of", "computer", "science", "emerged", "in", "the", "1950s", "in", "academic", "institutions", "such", "as", "the", "MIT", "A.I", ".", "Lab", ",", "originally", "as", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "This field of computer science emerged in the 1950s in academic institutions such as the MIT A.I. Lab, originally as a branch of artificial intelligence and robotics.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 30], [31, 38], [39, 41], [42, 45], [46, 51], [52, 54], [55, 63], [64, 76], [77, 81], [82, 84], [85, 88], [89, 92], [93, 96], [96, 97], [98, 101], [101, 102], [103, 113], [114, 116], [117, 118], [119, 125], [126, 128], [129, 139], [140, 152], [153, 156], [157, 165], [165, 166]]}
{"doc_key": "ai-test-212", "ner": [[7, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "can", "be", "replaced", "by", "the", "following", "Log", "loss", "equation", ":"], "sentence-detokenized": "This can be replaced by the following Log loss equation:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 20], [21, 23], [24, 27], [28, 37], [38, 41], [42, 46], [47, 55], [55, 56]]}
{"doc_key": "ai-test-213", "ner": [[1, 3, "organisation"], [7, 10, "organisation"], [14, 18, "university"], [20, 20, "university"], [22, 23, "university"], [26, 28, "university"], [29, 33, "country"], [39, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 3, 39, 39, "related-to", "research_leader_in_field", false, false], [7, 10, 1, 3, "named", "", false, false], [7, 10, 39, 39, "related-to", "research_leader_in_field", false, false], [14, 18, 39, 39, "related-to", "research_leader_in_field", false, false], [20, 20, 39, 39, "related-to", "research_leader_in_field", false, false], [22, 23, 39, 39, "related-to", "research_leader_in_field", false, false], [26, 28, 29, 33, "physical", "", false, false], [26, 28, 39, 39, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "Shirley", "Ryan", "AbilityLab", "(", "formerly", "the", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "the", "University", "of", "California", "at", "Berkeley", ",", "MIT", ",", "Stanford", "University", "and", "the", "University", "of", "Twente", "in", "the", "Netherlands", "are", "at", "the", "forefront", "of", "research", "in", "biomechatronics", "."], "sentence-detokenized": "The Shirley Ryan AbilityLab (formerly the Rehabilitation Institute of Chicago), the University of California at Berkeley, MIT, Stanford University and the University of Twente in the Netherlands are at the forefront of research in biomechatronics.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 27], [28, 29], [29, 37], [38, 41], [42, 56], [57, 66], [67, 69], [70, 77], [77, 78], [78, 79], [80, 83], [84, 94], [95, 97], [98, 108], [109, 111], [112, 120], [120, 121], [122, 125], [125, 126], [127, 135], [136, 146], [147, 150], [151, 154], [155, 165], [166, 168], [169, 175], [176, 178], [179, 182], [183, 194], [195, 198], [199, 201], [202, 205], [206, 215], [216, 218], [219, 227], [228, 230], [231, 246], [246, 247]]}
{"doc_key": "ai-test-214", "ner": [[22, 25, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "a", "corresponding", "set", "of", "forecast", "values", "and", "actual", "values", "of", "X", "for", "different", "periods", ",", "the", "general", "evaluation", "technique", "is", "the", "mean", "squared", "forecast", "error", ";", "other", "measures", "are", "also", "available", "(", "see", "Forecast", "#", "Forecast", "accuracy", ")", "."], "sentence-detokenized": "For a corresponding set of forecast values and actual values of X for different periods, the general evaluation technique is the mean squared forecast error; other measures are also available (see Forecast # Forecast accuracy).", "token2charspan": [[0, 3], [4, 5], [6, 19], [20, 23], [24, 26], [27, 35], [36, 42], [43, 46], [47, 53], [54, 60], [61, 63], [64, 65], [66, 69], [70, 79], [80, 87], [87, 88], [89, 92], [93, 100], [101, 111], [112, 121], [122, 124], [125, 128], [129, 133], [134, 141], [142, 150], [151, 156], [156, 157], [158, 163], [164, 172], [173, 176], [177, 181], [182, 191], [192, 193], [193, 196], [197, 205], [206, 207], [208, 216], [217, 225], [225, 226], [226, 227]]}
{"doc_key": "ai-test-215", "ner": [[14, 17, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "measures", ",", "such", "as", "the", "proportion", "of", "correct", "predictions", "(", "also", "known", "as", "accuracy", ")", ",", "are", "not", "useful", "if", "the", "two", "classes", "are", "very", "different", "in", "size", "."], "sentence-detokenized": "Other measures, such as the proportion of correct predictions (also known as accuracy), are not useful if the two classes are very different in size.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 20], [21, 23], [24, 27], [28, 38], [39, 41], [42, 49], [50, 61], [62, 63], [63, 67], [68, 73], [74, 76], [77, 85], [85, 86], [86, 87], [88, 91], [92, 95], [96, 102], [103, 105], [106, 109], [110, 113], [114, 121], [122, 125], [126, 130], [131, 140], [141, 143], [144, 148], [148, 149]]}
{"doc_key": "ai-test-216", "ner": [[5, 9, "product"], [12, 17, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 9, 12, 17, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "released", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "in", "2000", ",", "followed", "by", "five", "beta", "versions", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was released at the Conference on Computer Vision and Pattern Recognition in 2000, followed by five beta versions between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 46], [47, 49], [50, 53], [54, 64], [65, 67], [68, 76], [77, 83], [84, 87], [88, 95], [96, 107], [108, 110], [111, 115], [115, 116], [117, 125], [126, 128], [129, 133], [134, 138], [139, 147], [148, 155], [156, 160], [161, 164], [165, 169], [169, 170]]}
{"doc_key": "ai-test-217", "ner": [[20, 21, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "results", "presented", "show", "a", "correlation", "of", "up", "to", "0.964", "with", "human", "judgments", "at", "the", "corpus", "level", ",", "compared", "to", "BLEU", "'s", "result", "of", "0.817", "on", "the", "same", "dataset", "."], "sentence-detokenized": "The results presented show a correlation of up to 0.964 with human judgments at the corpus level, compared to BLEU's result of 0.817 on the same dataset.", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 26], [27, 28], [29, 40], [41, 43], [44, 46], [47, 49], [50, 55], [56, 60], [61, 66], [67, 76], [77, 79], [80, 83], [84, 90], [91, 96], [96, 97], [98, 106], [107, 109], [110, 114], [114, 116], [117, 123], [124, 126], [127, 132], [133, 135], [136, 139], [140, 144], [145, 152], [152, 153]]}
{"doc_key": "ai-test-218", "ner": [[4, 4, "metrics"], [19, 19, "metrics"], [21, 23, "metrics"], [25, 29, "metrics"], [37, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 19, 19, "compare", "", false, false], [4, 4, 21, 23, "compare", "", false, false], [4, 4, 25, 29, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["An", "early", "version", "of", "VMAF", "has", "been", "shown", "to", "outperform", "other", "image", "and", "video", "quality", "metrics", ",", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", "and", "VQM", "-", "VFD", ",", "in", "three", "out", "of", "four", "datasets", ",", "in", "terms", "of", "predictive", "accuracy", "compared", "to", "subjective", "ratings", "."], "sentence-detokenized": "An early version of VMAF has been shown to outperform other image and video quality metrics, such as SSIM, PSNR -HVS and VQM-VFD, in three out of four datasets, in terms of predictive accuracy compared to subjective ratings.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 19], [20, 24], [25, 28], [29, 33], [34, 39], [40, 42], [43, 53], [54, 59], [60, 65], [66, 69], [70, 75], [76, 83], [84, 91], [91, 92], [93, 97], [98, 100], [101, 105], [105, 106], [107, 111], [112, 113], [113, 116], [117, 120], [121, 124], [124, 125], [125, 128], [128, 129], [130, 132], [133, 138], [139, 142], [143, 145], [146, 150], [151, 159], [159, 160], [161, 163], [164, 169], [170, 172], [173, 183], [184, 192], [193, 201], [202, 204], [205, 215], [216, 223], [223, 224]]}
{"doc_key": "ai-test-219", "ner": [[18, 22, "task"], [25, 27, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 22, 25, 27, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "of", "\"", "mouse", "\"", "(", "animal", "or", "tool", ")", "is", "not", "relevant", "in", "machine", "translation", ",", "but", "it", "is", "relevant", "in", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity of \"mouse\" (animal or tool) is not relevant in machine translation, but it is relevant in information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 31], [31, 36], [36, 37], [38, 39], [39, 45], [46, 48], [49, 53], [53, 54], [55, 57], [58, 61], [62, 70], [71, 73], [74, 81], [82, 93], [93, 94], [95, 98], [99, 101], [102, 104], [105, 113], [114, 116], [117, 128], [129, 138], [138, 139]]}
{"doc_key": "ai-test-220", "ner": [[0, 2, "algorithm"], [12, 13, "field"], [9, 11, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 0, 2, "usage", "", false, false], [9, 11, 12, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "hashing", "was", "originally", "proposed", "for", "2D", "and", "3D", "object", "recognition", "in", "computer", "vision", ","], "sentence-detokenized": "Geometric hashing was originally proposed for 2D and 3D object recognition in computer vision,", "token2charspan": [[0, 9], [10, 17], [18, 21], [22, 32], [33, 41], [42, 45], [46, 48], [49, 52], [53, 55], [56, 62], [63, 74], [75, 77], [78, 86], [87, 93], [93, 94]]}
{"doc_key": "ai-test-221", "ner": [[8, 9, "field"], [12, 13, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 8, 9, "part-of", "subfield", false, false], [15, 16, 8, 9, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "is", "one", "of", "three", "main", "categories", "of", "machine", "learning", ",", "alongside", "supervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "It is one of three main categories of machine learning, alongside supervised learning and reinforcement learning.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 12], [13, 18], [19, 23], [24, 34], [35, 37], [38, 45], [46, 54], [54, 55], [56, 65], [66, 76], [77, 85], [86, 89], [90, 103], [104, 112], [112, 113]]}
{"doc_key": "ai-test-222", "ner": [[5, 7, "field"], [17, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 31, "field"], [33, 34, "field"], [36, 37, "field"], [39, 39, "field"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[5, 7, 17, 17, "part-of", "subfield", false, false], [5, 7, 19, 20, "part-of", "subfield", false, false], [5, 7, 22, 23, "part-of", "subfield", false, false], [5, 7, 25, 26, "part-of", "subfield", false, false], [5, 7, 28, 31, "part-of", "subfield", false, false], [5, 7, 33, 34, "part-of", "subfield", false, false], [5, 7, 36, 37, "part-of", "subfield", false, false], [5, 7, 39, 39, "part-of", "subfield", false, false], [5, 7, 41, 42, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Because", "of", "its", "generality", ",", "reinforcement", "learning", "is", "also", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "games", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multiagent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Because of its generality, reinforcement learning is also studied in many other disciplines, such as games, control theory, operations research, information theory, simulation-based optimisation, multiagent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [25, 26], [27, 40], [41, 49], [50, 52], [53, 57], [58, 65], [66, 68], [69, 73], [74, 79], [80, 91], [91, 92], [93, 97], [98, 100], [101, 106], [106, 107], [108, 115], [116, 122], [122, 123], [124, 134], [135, 143], [143, 144], [145, 156], [157, 163], [163, 164], [165, 175], [175, 176], [176, 181], [182, 194], [194, 195], [196, 206], [207, 214], [214, 215], [216, 221], [222, 234], [234, 235], [236, 246], [247, 250], [251, 258], [259, 269], [269, 270]]}
{"doc_key": "ai-test-223", "ner": [[0, 2, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 7, "related-to", "", false, false], [0, 2, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pattern", "recognition", "is", "closely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ","], "sentence-detokenized": "Pattern recognition is closely related to artificial intelligence and machine learning,", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 38], [39, 41], [42, 52], [53, 65], [66, 69], [70, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-224", "ner": [[10, 11, "algorithm"], [14, 17, "field"], [16, 16, "field"], [27, 28, "task"], [30, 30, "task"], [32, 33, "task"], [35, 36, "algorithm"], [38, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 14, 17, "related-to", "", false, false], [10, 11, 16, 16, "related-to", "", false, false], [27, 28, 10, 11, "usage", "", true, false], [30, 30, 10, 11, "usage", "", true, false], [32, 33, 10, 11, "usage", "", true, false], [35, 36, 10, 11, "usage", "", true, false], [38, 40, 10, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "software", "is", "used", "for", "designing", ",", "training", "and", "deploying", "neural", "network", "models", "(", "supervised", "and", "unsupervised", "learning", ")", "for", "a", "wide", "range", "of", "tasks", "such", "as", "data", "mining", ",", "classification", ",", "function", "approximation", ",", "multivariate", "regression", "and", "time", "series", "prediction", "."], "sentence-detokenized": "The software is used for designing, training and deploying neural network models (supervised and unsupervised learning) for a wide range of tasks such as data mining, classification, function approximation, multivariate regression and time series prediction.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [21, 24], [25, 34], [34, 35], [36, 44], [45, 48], [49, 58], [59, 65], [66, 73], [74, 80], [81, 82], [82, 92], [93, 96], [97, 109], [110, 118], [118, 119], [120, 123], [124, 125], [126, 130], [131, 136], [137, 139], [140, 145], [146, 150], [151, 153], [154, 158], [159, 165], [165, 166], [167, 181], [181, 182], [183, 191], [192, 205], [205, 206], [207, 219], [220, 230], [231, 234], [235, 239], [240, 246], [247, 257], [257, 258]]}
{"doc_key": "ai-test-225", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016, he was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-test-226", "ner": [[6, 9, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", "and", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", ","], "sentence-detokenized": "He is a member of the National Academy of Sciences (since 2005) and the American Academy of Arts and Sciences (since 2009),", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 50], [51, 52], [52, 57], [58, 62], [62, 63], [64, 67], [68, 71], [72, 80], [81, 88], [89, 91], [92, 96], [97, 100], [101, 109], [110, 111], [111, 116], [117, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-test-227", "ner": [[0, 5, "misc"], [10, 14, "product"], [19, 19, "country"], [21, 21, "country"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 14, 0, 5, "temporal", "", false, false], [10, 14, 19, 19, "physical", "", false, false], [10, 14, 21, 21, "physical", "", false, false], [10, 14, 26, 27, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "the", "1973", "Yom", "Kippur", "War", ",", "Soviet", "-", "backed", "surface", "-", "to", "-", "air", "missile", "batteries", "stationed", "in", "Egypt", "and", "Syria", "inflicted", "heavy", "damage", "on", "Israeli", "fighters", "."], "sentence-detokenized": "During the 1973 Yom Kippur War, Soviet-backed surface-to-air missile batteries stationed in Egypt and Syria inflicted heavy damage on Israeli fighters.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 26], [27, 30], [30, 31], [32, 38], [38, 39], [39, 45], [46, 53], [53, 54], [54, 56], [56, 57], [57, 60], [61, 68], [69, 78], [79, 88], [89, 91], [92, 97], [98, 101], [102, 107], [108, 117], [118, 123], [124, 130], [131, 133], [134, 141], [142, 150], [150, 151]]}
{"doc_key": "ai-test-228", "ner": [[10, 11, "product"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "(", "free", ",", "but", "copyrighted", ")", "resource", "is", "the", "HTK", "book", "(", "and", "its", "accompanying", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another (free, but copyrighted) resource is the HTK book (and its accompanying HTK toolkit).", "token2charspan": [[0, 7], [8, 9], [9, 13], [13, 14], [15, 18], [19, 30], [30, 31], [32, 40], [41, 43], [44, 47], [48, 51], [52, 56], [57, 58], [58, 61], [62, 65], [66, 78], [79, 82], [83, 90], [90, 91], [91, 92]]}
{"doc_key": "ai-test-229", "ner": [[0, 6, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "took", "place", "at", "the", "2004", "AAAI", "Spring", "Symposium", ",", "where", "linguists", ",", "computer", "scientists", "and", "other", "interested", "researchers", "first", "reconciled", "their", "interests", "and", "proposed", "common", "tasks", "and", "reference", "data", "sets", "for", "systematic", "computational", "research", "on", "emotions", ",", "affections", ",", "subjectivity", "and", "sentiments", "in", "text", "."], "sentence-detokenized": "- took place at the 2004 AAAI Spring Symposium, where linguists, computer scientists and other interested researchers first reconciled their interests and proposed common tasks and reference data sets for systematic computational research on emotions, affections, subjectivity and sentiments in text.", "token2charspan": [[0, 1], [2, 6], [7, 12], [13, 15], [16, 19], [20, 24], [25, 29], [30, 36], [37, 46], [46, 47], [48, 53], [54, 63], [63, 64], [65, 73], [74, 84], [85, 88], [89, 94], [95, 105], [106, 117], [118, 123], [124, 134], [135, 140], [141, 150], [151, 154], [155, 163], [164, 170], [171, 176], [177, 180], [181, 190], [191, 195], [196, 200], [201, 204], [205, 215], [216, 229], [230, 238], [239, 241], [242, 250], [250, 251], [252, 262], [262, 263], [264, 276], [277, 280], [281, 291], [292, 294], [295, 299], [299, 300]]}
{"doc_key": "ai-test-230", "ner": [[9, 10, "task"], [15, 16, "task"], [18, 20, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "single", "grid", "can", "be", "analysed", "both", "content-wise", "(", "visual", "inspection", ")", "and", "structurally", "(", "cluster", "analysis", ",", "principal", "component", "analysis", "and", "various", "structural", "indicators", "of", "the", "complexity", "and", "scope", "of", "ratings", "are", "the", "main", "techniques", "used", ")", "."], "sentence-detokenized": "A single grid can be analysed both content-wise (visual inspection) and structurally (cluster analysis, principal component analysis and various structural indicators of the complexity and scope of ratings are the main techniques used).", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 17], [18, 20], [21, 29], [30, 34], [35, 47], [48, 49], [49, 55], [56, 66], [66, 67], [68, 71], [72, 84], [85, 86], [86, 93], [94, 102], [102, 103], [104, 113], [114, 123], [124, 132], [133, 136], [137, 144], [145, 155], [156, 166], [167, 169], [170, 173], [174, 184], [185, 188], [189, 194], [195, 197], [198, 205], [206, 209], [210, 213], [214, 218], [219, 229], [230, 234], [234, 235], [235, 236]]}
{"doc_key": "ai-test-231", "ner": [[3, 3, "organisation"], [10, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", ",", "Toyota", "was", "seen", "as", "lagging", "behind", "in", "self", "-", "driving", "cars", "and", "in", "need", "of", "innovation", "."], "sentence-detokenized": "In 2018, Toyota was seen as lagging behind in self-driving cars and in need of innovation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 24], [25, 27], [28, 35], [36, 42], [43, 45], [46, 50], [50, 51], [51, 58], [59, 63], [64, 67], [68, 70], [71, 75], [76, 78], [79, 89], [89, 90]]}
{"doc_key": "ai-test-232", "ner": [[40, 41, "misc"], [43, 44, "misc"], [46, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "targets", "include", "natural", "objects", "such", "as", "the", "ground", ",", "the", "sea", ",", "precipitation", "(", "such", "as", "rain", ",", "snow", "or", "hail", ")", ",", "sandstorms", ",", "animals", "(", "especially", "birds", ")", ",", "atmospheric", "turbulence", "and", "other", "atmospheric", "effects", "such", "as", "ionospheric", "reflections", ",", "meteor", "trails", "and", "three", "-", "body", "scattering", "spikes", "."], "sentence-detokenized": "Such targets include natural objects such as the ground, the sea, precipitation (such as rain, snow or hail), sandstorms, animals (especially birds), atmospheric turbulence and other atmospheric effects such as ionospheric reflections, meteor trails and three-body scattering spikes.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 28], [29, 36], [37, 41], [42, 44], [45, 48], [49, 55], [55, 56], [57, 60], [61, 64], [64, 65], [66, 79], [80, 81], [81, 85], [86, 88], [89, 93], [93, 94], [95, 99], [100, 102], [103, 107], [107, 108], [108, 109], [110, 120], [120, 121], [122, 129], [130, 131], [131, 141], [142, 147], [147, 148], [148, 149], [150, 161], [162, 172], [173, 176], [177, 182], [183, 194], [195, 202], [203, 207], [208, 210], [211, 222], [223, 234], [234, 235], [236, 242], [243, 249], [250, 253], [254, 259], [259, 260], [260, 264], [265, 275], [276, 282], [282, 283]]}
{"doc_key": "ai-test-233", "ner": [[22, 22, "product"], [42, 43, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["From", "a", "design", "and", "control", "point", "of", "view", ",", "the", "fundamental", "difference", "between", "humanoids", "and", "other", "types", "of", "robots", "(", "such", "as", "industrial", "robots", ")", "is", "that", "the", "robot", "'s", "movements", "must", "be", "human", "-", "like", ",", "using", "leg", "movements", ",", "especially", "bipedal", "walking", "."], "sentence-detokenized": "From a design and control point of view, the fundamental difference between humanoids and other types of robots (such as industrial robots) is that the robot's movements must be human-like, using leg movements, especially bipedal walking.", "token2charspan": [[0, 4], [5, 6], [7, 13], [14, 17], [18, 25], [26, 31], [32, 34], [35, 39], [39, 40], [41, 44], [45, 56], [57, 67], [68, 75], [76, 85], [86, 89], [90, 95], [96, 101], [102, 104], [105, 111], [112, 113], [113, 117], [118, 120], [121, 131], [132, 138], [138, 139], [140, 142], [143, 147], [148, 151], [152, 157], [157, 159], [160, 169], [170, 174], [175, 177], [178, 183], [183, 184], [184, 188], [188, 189], [190, 195], [196, 199], [200, 209], [209, 210], [211, 221], [222, 229], [230, 237], [237, 238]]}
{"doc_key": "ai-test-234", "ner": [[1, 2, "algorithm"], [10, 13, "misc"], [15, 15, "metrics"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "gradient", "descent", "can", "take", "many", "iterations", "to", "compute", "a", "local", "minimum", "with", "the", "required", "accuracy", "if", "the", "curvature", "in", "the", "different", "directions", "is", "very", "different", "for", "a", "given", "function", "."], "sentence-detokenized": "The gradient descent can take many iterations to compute a local minimum with the required accuracy if the curvature in the different directions is very different for a given function.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 24], [25, 29], [30, 34], [35, 45], [46, 48], [49, 56], [57, 58], [59, 64], [65, 72], [73, 77], [78, 81], [82, 90], [91, 99], [100, 102], [103, 106], [107, 116], [117, 119], [120, 123], [124, 133], [134, 144], [145, 147], [148, 152], [153, 162], [163, 166], [167, 168], [169, 174], [175, 183], [183, 184]]}
{"doc_key": "ai-test-235", "ner": [[1, 6, "misc"], [10, 10, "misc"], [18, 27, "conference"], [31, 31, "location"], [33, 35, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 6, 10, 10, "part-of", "", true, false], [18, 27, 31, 31, "physical", "", false, true], [31, 31, 33, 35, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "1997", "RoboCup", "2D", "Soccer", "Simulation", "League", "was", "the", "first", "RoboCup", "tournament", ",", "and", "was", "held", "in", "conjunction", "with", "the", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", ",", "which", "took", "place", "in", "Nagoya", ",", "Japan", ",", "from", "23", "-", "29", "August", "1997", "."], "sentence-detokenized": "The 1997 RoboCup 2D Soccer Simulation League was the first RoboCup tournament, and was held in conjunction with the International Joint Conference on Artificial Intelligence, which took place in Nagoya, Japan, from 23-29 August 1997.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 19], [20, 26], [27, 37], [38, 44], [45, 48], [49, 52], [53, 58], [59, 66], [67, 77], [77, 78], [79, 82], [83, 86], [87, 91], [92, 94], [95, 106], [107, 111], [112, 115], [116, 129], [130, 135], [136, 146], [147, 149], [150, 160], [161, 173], [173, 174], [175, 180], [181, 185], [186, 191], [192, 194], [195, 201], [201, 202], [203, 208], [208, 209], [210, 214], [215, 217], [217, 218], [218, 220], [221, 227], [228, 232], [232, 233]]}
{"doc_key": "ai-test-236", "ner": [[6, 6, "programlang"], [9, 9, "programlang"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Additional", "programming", "options", "include", "an", "embedded", "Python", "environment", "and", "R", "console", ",", "as", "well", "as", "support", "for", "Rserve", "."], "sentence-detokenized": "Additional programming options include an embedded Python environment and R console, as well as support for Rserve.", "token2charspan": [[0, 10], [11, 22], [23, 30], [31, 38], [39, 41], [42, 50], [51, 57], [58, 69], [70, 73], [74, 75], [76, 83], [83, 84], [85, 87], [88, 92], [93, 95], [96, 103], [104, 107], [108, 114], [114, 115]]}
{"doc_key": "ai-test-237", "ner": [[0, 1, "location"], [9, 10, "field"], [12, 12, "field"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [27, 28, "field"], [32, 33, "field"], [36, 37, "field"], [42, 42, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[17, 18, 12, 12, "related-to", "contributes_to_field", true, false], [20, 21, 12, 12, "related-to", "contributes_to_field", true, false], [23, 24, 12, 12, "related-to", "contributes_to_field", true, false], [36, 37, 32, 33, "part-of", "", false, false], [42, 42, 36, 37, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["From", "Bonn", ",", "he", "has", "made", "fundamental", "contributions", "to", "artificial", "intelligence", "and", "robotics", "(", "among", "his", "students", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Thrun", ")", ",", "software", "development", ",", "especially", "in", "civil", "engineering", ",", "and", "information", "systems", "development", ",", "especially", "in", "geosciences", "."], "sentence-detokenized": "From Bonn, he has made fundamental contributions to artificial intelligence and robotics (among his students Wolfram Burgard, Dieter Fox, Sebastian Thrun), software development, especially in civil engineering, and information systems development, especially in geosciences.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 13], [14, 17], [18, 22], [23, 34], [35, 48], [49, 51], [52, 62], [63, 75], [76, 79], [80, 88], [89, 90], [90, 95], [96, 99], [100, 108], [109, 116], [117, 124], [124, 125], [126, 132], [133, 136], [136, 137], [138, 147], [148, 153], [153, 154], [154, 155], [156, 164], [165, 176], [176, 177], [178, 188], [189, 191], [192, 197], [198, 209], [209, 210], [211, 214], [215, 226], [227, 234], [235, 246], [246, 247], [248, 258], [259, 261], [262, 273], [273, 274]]}
{"doc_key": "ai-test-238", "ner": [[2, 9, "conference"], [17, 19, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 9, 17, 19, "physical", "", false, false], [17, 19, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "US", "edition", "of", "Campus", "Party", "will", "take", "place", "from", "20", "to", "22", "August", "at", "the", "TCF", "Center", "in", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "The first US edition of Campus Party will take place from 20 to 22 August at the TCF Center in Detroit, Michigan.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 20], [21, 23], [24, 30], [31, 36], [37, 41], [42, 46], [47, 52], [53, 57], [58, 60], [61, 63], [64, 66], [67, 73], [74, 76], [77, 80], [81, 84], [85, 91], [92, 94], [95, 102], [102, 103], [104, 112], [112, 113]]}
{"doc_key": "ai-test-239", "ner": [[3, 5, "researcher"], [7, 8, "researcher"], [0, 0, "researcher"], [13, 14, "misc"], [23, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 13, 14, "win-defeat", "", false, false], [7, 8, 13, 14, "win-defeat", "", false, false], [0, 0, 13, 14, "win-defeat", "", false, false], [13, 14, 23, 26, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Hinton", ",", "along", "with", "Yann", "LeCunn", "and", "Yoshua", "Bengio", ",", "won", "the", "2018", "Turing", "Prize", "for", "conceptual", "and", "engineering", "breakthroughs", "that", "have", "made", "deep", "neural", "networks", "a", "critical", "part", "of", "computing", "."], "sentence-detokenized": "Hinton, along with Yann LeCunn and Yoshua Bengio, won the 2018 Turing Prize for conceptual and engineering breakthroughs that have made deep neural networks a critical part of computing.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 23], [24, 30], [31, 34], [35, 41], [42, 48], [48, 49], [50, 53], [54, 57], [58, 62], [63, 69], [70, 75], [76, 79], [80, 90], [91, 94], [95, 106], [107, 120], [121, 125], [126, 130], [131, 135], [136, 140], [141, 147], [148, 156], [157, 158], [159, 167], [168, 172], [173, 175], [176, 185], [185, 186]]}
{"doc_key": "ai-test-240", "ner": [[0, 2, "product"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Euler", "Math", "Toolbox", "uses", "a", "matrix", "language", "similar", "to", "MATLAB", ",", "which", "has", "been", "developed", "since", "the", "1970s", "."], "sentence-detokenized": "Euler Math Toolbox uses a matrix language similar to MATLAB, which has been developed since the 1970s.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 23], [24, 25], [26, 32], [33, 41], [42, 49], [50, 52], [53, 59], [59, 60], [61, 66], [67, 70], [71, 75], [76, 85], [86, 91], [92, 95], [96, 101], [101, 102]]}
{"doc_key": "ai-test-241", "ner": [[10, 10, "programlang"], [12, 13, "programlang"], [15, 15, "programlang"], [17, 17, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "languages", "allow", "this", "in", "a", "portable", "way", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "or", "D", ")", "."], "sentence-detokenized": "Some languages allow this in a portable way (e.g. Scheme, Common Lisp, Perl or D).", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 25], [26, 28], [29, 30], [31, 39], [40, 43], [44, 45], [45, 49], [50, 56], [56, 57], [58, 64], [65, 69], [69, 70], [71, 75], [76, 78], [79, 80], [80, 81], [81, 82]]}
{"doc_key": "ai-test-242", "ner": [[6, 7, "misc"], [8, 9, "researcher"], [11, 12, "researcher"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 8, 9, "artifact", "", false, false], [6, 7, 11, 12, "artifact", "", false, false], [6, 7, 26, 27, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1969", ",", "the", "famous", "book", "Perceptrons", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "showed", "that", "it", "is", "impossible", "for", "this", "class", "of", "networks", "to", "learn", "the", "XOR", "function", "."], "sentence-detokenized": "In 1969, the famous book Perceptrons by Marvin Minsky and Seymour Papert showed that it is impossible for this class of networks to learn the XOR function.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [20, 24], [25, 36], [37, 39], [40, 46], [47, 53], [54, 57], [58, 65], [66, 72], [73, 79], [80, 84], [85, 87], [88, 90], [91, 101], [102, 105], [106, 110], [111, 116], [117, 119], [120, 128], [129, 131], [132, 137], [138, 141], [142, 145], [146, 154], [154, 155]]}
{"doc_key": "ai-test-243", "ner": [[10, 14, "misc"], [4, 4, "product"], [21, 25, "organisation"], [29, 34, "organisation"], [35, 41, "location"], [42, 42, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[21, 25, 4, 4, "usage", "", false, false], [21, 25, 35, 41, "physical", "", false, false], [29, 34, 21, 25, "named", "", false, false], [35, 41, 42, 42, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["With", "the", "help", "of", "SYSTRAN", ",", "a", "large", "number", "of", "Russian", "scientific", "and", "technical", "documents", "were", "translated", "under", "the", "auspices", "of", "the", "USAF", "Foreign", "Technology", "Division", "(", "later", "the", "National", "Aerospace", "Intelligence", "Center", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", "in", "Ohio", "."], "sentence-detokenized": "With the help of SYSTRAN, a large number of Russian scientific and technical documents were translated under the auspices of the USAF Foreign Technology Division (later the National Aerospace Intelligence Center) at Wright-Patterson Air Force Base in Ohio.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 24], [24, 25], [26, 27], [28, 33], [34, 40], [41, 43], [44, 51], [52, 62], [63, 66], [67, 76], [77, 86], [87, 91], [92, 102], [103, 108], [109, 112], [113, 121], [122, 124], [125, 128], [129, 133], [134, 141], [142, 152], [153, 161], [162, 163], [163, 168], [169, 172], [173, 181], [182, 191], [192, 204], [205, 211], [211, 212], [213, 215], [216, 222], [222, 223], [223, 232], [233, 236], [237, 242], [243, 247], [248, 250], [251, 255], [255, 256]]}
{"doc_key": "ai-test-244", "ner": [[0, 1, "field"], [4, 5, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-supervised", "learning", "falls", "between", "unsupervised", "learning", "(", "without", "labelled", "training", "data", ")", "and", "supervised", "learning", "(", "with", "fully", "labelled", "training", "data", ")", "."], "sentence-detokenized": "Semi-supervised learning falls between unsupervised learning (without labelled training data) and supervised learning (with fully labelled training data).", "token2charspan": [[0, 15], [16, 24], [25, 30], [31, 38], [39, 51], [52, 60], [61, 62], [62, 69], [70, 78], [79, 87], [88, 92], [92, 93], [94, 97], [98, 108], [109, 117], [118, 119], [119, 123], [124, 129], [130, 138], [139, 147], [148, 152], [152, 153], [153, 154]]}
{"doc_key": "ai-test-245", "ner": [[0, 4, "algorithm"], [9, 11, "algorithm"], [24, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 9, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Ann", "-", "gram", "model", "is", "a", "kind", "of", "probabilistic", "language", "model", "that", "is", "used", "to", "predict", "the", "next", "element", "of", "such", "a", "sequence", "in", "the", "form", "of", "an", "(", "n", "-", "1", ")", "-order", "Markov", "model", ".effectively", "."], "sentence-detokenized": "The Ann -gram model is a kind of probabilistic language model that is used to predict the next element of such a sequence in the form of an (n - 1)-order Markov model .effectively.", "token2charspan": [[0, 3], [4, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 24], [25, 29], [30, 32], [33, 46], [47, 55], [56, 61], [62, 66], [67, 69], [70, 74], [75, 77], [78, 85], [86, 89], [90, 94], [95, 102], [103, 105], [106, 110], [111, 112], [113, 121], [122, 124], [125, 128], [129, 133], [134, 136], [137, 139], [140, 141], [141, 142], [143, 144], [145, 146], [146, 147], [147, 153], [154, 160], [161, 166], [167, 179], [179, 180]]}
{"doc_key": "ai-test-246", "ner": [[1, 2, "organisation"], [5, 5, "product"], [8, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 5, 5, "usage", "", false, false], [8, 17, 1, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "has", "used", "Cyc", "to", "develop", "a", "natural", "language", "query", "interface", "for", "biomedical", "information", ",", "which", "includes", "decades", "of", "information", "on", "cardiothoracic", "surgery", "."], "sentence-detokenized": "The Cleveland Clinic has used Cyc to develop a natural language query interface for biomedical information, which includes decades of information on cardiothoracic surgery.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 24], [25, 29], [30, 33], [34, 36], [37, 44], [45, 46], [47, 54], [55, 63], [64, 69], [70, 79], [80, 83], [84, 94], [95, 106], [106, 107], [108, 113], [114, 122], [123, 130], [131, 133], [134, 145], [146, 148], [149, 163], [164, 171], [171, 172]]}
{"doc_key": "ai-test-247", "ner": [[6, 7, "country"], [9, 10, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 9, 10, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "incident", "strained", "relations", "between", "the", "United", "States", "and", "Japan", "and", "led", "to", "the", "arrest", "and", "prosecution", "of", "two", "senior", "executives", "and", "the", "imposition", "of", "sanctions", "against", "the", "company", "by", "both", "countries", "."], "sentence-detokenized": "The incident strained relations between the United States and Japan and led to the arrest and prosecution of two senior executives and the imposition of sanctions against the company by both countries.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 31], [32, 39], [40, 43], [44, 50], [51, 57], [58, 61], [62, 67], [68, 71], [72, 75], [76, 78], [79, 82], [83, 89], [90, 93], [94, 105], [106, 108], [109, 112], [113, 119], [120, 130], [131, 134], [135, 138], [139, 149], [150, 152], [153, 162], [163, 170], [171, 174], [175, 182], [183, 185], [186, 190], [191, 200], [200, 201]]}
{"doc_key": "ai-test-248", "ner": [[4, 7, "algorithm"], [10, 11, "field"], [17, 17, "misc"], [16, 28, "misc"], [32, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 7, 10, 11, "type-of", "", false, false], [17, 17, 10, 11, "part-of", "", true, false], [16, 28, 10, 11, "part-of", "", true, false], [32, 33, 10, 11, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["When", "modelling", "is", "done", "with", "artificial", "neural", "networks", "or", "other", "machine", "learning", ",", "parameter", "optimisation", "is", "called", "training", ",", "while", "optimisation", "of", "the", "model", "'s", "hyperparameters", "is", "called", "tuning", ",", "and", "often", "cross-validation", "is", "used", "."], "sentence-detokenized": "When modelling is done with artificial neural networks or other machine learning, parameter optimisation is called training, while optimisation of the model's hyperparameters is called tuning, and often cross-validation is used.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 22], [23, 27], [28, 38], [39, 45], [46, 54], [55, 57], [58, 63], [64, 71], [72, 80], [80, 81], [82, 91], [92, 104], [105, 107], [108, 114], [115, 123], [123, 124], [125, 130], [131, 143], [144, 146], [147, 150], [151, 156], [156, 158], [159, 174], [175, 177], [178, 184], [185, 191], [191, 192], [193, 196], [197, 202], [203, 219], [220, 222], [223, 227], [227, 228]]}
{"doc_key": "ai-test-249", "ner": [[17, 18, "country"], [20, 20, "country"], [22, 22, "country"], [4, 5, "organisation"], [7, 9, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 7, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Following", "the", "acquisition", "of", "Rotten", "Tomatoes", "by", "Fandango", ",", "the", "localised", "versions", "of", "the", "site", "available", "in", "the", "UK", ",", "India", "and", "Australia", "have", "been", "discontinued", "."], "sentence-detokenized": "Following the acquisition of Rotten Tomatoes by Fandango, the localised versions of the site available in the UK, India and Australia have been discontinued.", "token2charspan": [[0, 9], [10, 13], [14, 25], [26, 28], [29, 35], [36, 44], [45, 47], [48, 56], [56, 57], [58, 61], [62, 71], [72, 80], [81, 83], [84, 87], [88, 92], [93, 102], [103, 105], [106, 109], [110, 112], [112, 113], [114, 119], [120, 123], [124, 133], [134, 138], [139, 143], [144, 156], [156, 157]]}
{"doc_key": "ai-test-250", "ner": [[12, 13, "metrics"], [22, 23, "task"]], "ner_mapping_to_source": [1, 2], "relations": [[12, 13, 22, 23, "related-to", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["The", "NER", "model", "is", "one", "of", "several", "methods", "used", "to", "determine", "the", "accuracy", "of", "live", "captioning", "of", "television", "broadcasts", "and", "events", "using", "speech", "recognition", "."], "sentence-detokenized": "The NER model is one of several methods used to determine the accuracy of live captioning of television broadcasts and events using speech recognition.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 31], [32, 39], [40, 44], [45, 47], [48, 57], [58, 61], [62, 70], [71, 73], [74, 78], [79, 89], [90, 92], [93, 103], [104, 114], [115, 118], [119, 125], [126, 131], [132, 138], [139, 150], [150, 151]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [5, 7, "university"], [10, 12, "university"], [13, 13, "location"], [16, 20, "university"], [23, 25, "university"], [26, 26, "location"], [30, 35, "university"], [36, 38, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 5, 7, "physical", "", false, false], [0, 0, 5, 7, "role", "", false, false], [0, 0, 10, 12, "physical", "", false, false], [0, 0, 10, 12, "role", "", false, false], [0, 0, 16, 20, "physical", "", false, false], [0, 0, 16, 20, "role", "", false, false], [0, 0, 23, 25, "physical", "", false, false], [0, 0, 23, 25, "role", "", false, false], [0, 0, 30, 35, "physical", "", false, false], [0, 0, 30, 35, "role", "", false, false], [10, 12, 13, 13, "physical", "", false, false], [16, 20, 26, 26, "physical", "", false, false], [23, 25, 26, 26, "physical", "", false, false], [30, 35, 36, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "has", "taught", "at", "the", "University", "of", "Cambridge", ",", "the", "Hebrew", "University", "of", "Jerusalem", ",", "the", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "and", "the", "\u00c9cole", "Polytechnique", "in", "Paris", ",", "and", "the", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "."], "sentence-detokenized": "Atran has taught at the University of Cambridge, the Hebrew University of Jerusalem, the \u00c9cole pratique des hautes \u00e9tudes and the \u00c9cole Polytechnique in Paris, and the John Jay College of Criminal Justice in New York.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 47], [47, 48], [49, 52], [53, 59], [60, 70], [71, 73], [74, 83], [83, 84], [85, 88], [89, 94], [95, 103], [104, 107], [108, 114], [115, 121], [122, 125], [126, 129], [130, 135], [136, 149], [150, 152], [153, 158], [158, 159], [160, 163], [164, 167], [168, 172], [173, 176], [177, 184], [185, 187], [188, 196], [197, 204], [205, 207], [208, 211], [212, 216], [216, 217]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [4, 6, "task"], [11, 12, "researcher"], [13, 15, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "origin", "", false, false], [0, 0, 4, 6, "related-to", "", false, false], [4, 6, 13, 15, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "was", "an", "early", "natural", "language", "understanding", "computer", "program", "developed", "by", "Terry", "Winograd", "at", "MIT", "in", "1968", "-", "1970", "."], "sentence-detokenized": "SHRDLU was an early natural language understanding computer program developed by Terry Winograd at MIT in 1968-1970.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 19], [20, 27], [28, 36], [37, 50], [51, 59], [60, 67], [68, 77], [78, 80], [81, 86], [87, 95], [96, 98], [99, 102], [103, 105], [106, 110], [110, 111], [111, 115], [115, 116]]}
{"doc_key": "ai-test-253", "ner": [[4, 5, "misc"], [6, 9, "field"], [10, 14, "university"], [15, 16, "location"], [18, 18, "country"], [25, 27, "university"], [37, 40, "field"], [42, 43, "university"], [47, 54, "misc"], [49, 52, "field"], [55, 57, "misc"], [61, 65, "university"], [70, 71, "field"], [75, 76, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[4, 5, 6, 9, "topic", "", false, false], [4, 5, 10, 14, "origin", "", false, false], [10, 14, 15, 16, "physical", "", false, false], [10, 14, 25, 27, "role", "affiliated_with", false, false], [15, 16, 18, 18, "physical", "", false, false], [47, 54, 49, 52, "topic", "", false, false], [55, 57, 61, 65, "origin", "", false, false], [55, 57, 70, 71, "topic", "", false, false], [75, 76, 61, 65, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 7, 8, 9, 10], "sentence": ["In", "1982", ",", "he", "graduated", "in", "Electronics", "Engineering", "from", "the", "B.M.S", ".", "College", "of", "Engineering", "in", "Bangalore", ",", "India", ",", "when", "it", "was", "still", "part", "of", "Bangalore", "University", ".", "In", "1984", ",", "he", "received", "a", "B.S.", "in", "electrical", "and", "computer", "engineering", "from", "Drexel", "University", ",", "followed", "by", "a", "Ph.D.", "in", "computer", "science", "in", "1989", "and", "a", "Ph.D.", "in", "1990", "from", "the", "University", "of", "Wisconsin", "-", "Madison", ",", "where", "he", "studied", "artificial", "intelligence", "and", "worked", "with", "Leonard", "Uhr", "."], "sentence-detokenized": "In 1982, he graduated in Electronics Engineering from the B.M.S. College of Engineering in Bangalore, India, when it was still part of Bangalore University. In 1984, he received a B.S. in electrical and computer engineering from Drexel University, followed by a Ph.D. in computer science in 1989 and a Ph.D. in 1990 from the University of Wisconsin-Madison, where he studied artificial intelligence and worked with Leonard Uhr.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 21], [22, 24], [25, 36], [37, 48], [49, 53], [54, 57], [58, 63], [63, 64], [65, 72], [73, 75], [76, 87], [88, 90], [91, 100], [100, 101], [102, 107], [107, 108], [109, 113], [114, 116], [117, 120], [121, 126], [127, 131], [132, 134], [135, 144], [145, 155], [155, 156], [157, 159], [160, 164], [164, 165], [166, 168], [169, 177], [178, 179], [180, 184], [185, 187], [188, 198], [199, 202], [203, 211], [212, 223], [224, 228], [229, 235], [236, 246], [246, 247], [248, 256], [257, 259], [260, 261], [262, 267], [268, 270], [271, 279], [280, 287], [288, 290], [291, 295], [296, 299], [300, 301], [302, 307], [308, 310], [311, 315], [316, 320], [321, 324], [325, 335], [336, 338], [339, 348], [348, 349], [349, 356], [356, 357], [358, 363], [364, 366], [367, 374], [375, 385], [386, 398], [399, 402], [403, 409], [410, 414], [415, 422], [423, 426], [426, 427]]}
{"doc_key": "ai-test-254", "ner": [[7, 8, "metrics"], [6, 10, "metrics"], [19, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 10, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "usually", "measured", "by", "the", "word", "error", "rate", "(", "WER", ")", ",", "while", "speed", "is", "measured", "by", "the", "real", "time", "factor", "."], "sentence-detokenized": "Accuracy is usually measured by the word error rate (WER), while speed is measured by the real time factor.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 28], [29, 31], [32, 35], [36, 40], [41, 46], [47, 51], [52, 53], [53, 56], [56, 57], [57, 58], [59, 64], [65, 70], [71, 73], [74, 82], [83, 85], [86, 89], [90, 94], [95, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [8, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", ",", "Terry", "Winograd", "developed", "an", "early", "natural", "language", "processing", "engine", "that", "could", "interpret", "naturally", "written", "commands", "in", "a", "simple", "rule", "-", "driven", "environment", "."], "sentence-detokenized": "In 1971, Terry Winograd developed an early natural language processing engine that could interpret naturally written commands in a simple rule-driven environment.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 33], [34, 36], [37, 42], [43, 50], [51, 59], [60, 70], [71, 77], [78, 82], [83, 88], [89, 98], [99, 108], [109, 116], [117, 125], [126, 128], [129, 130], [131, 137], [138, 142], [142, 143], [143, 149], [150, 161], [161, 162]]}
{"doc_key": "ai-test-256", "ner": [[4, 5, "field"], [7, 8, "researcher"], [10, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 7, 8, "related-to", "", false, false], [4, 5, 10, 13, "related-to", "", false, false], [4, 5, 15, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "field", "of", "artificial", "intelligence", ",", "Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "and", "Allen", "Newell", "are", "outstanding", "."], "sentence-detokenized": "In the field of artificial intelligence, Marvin Minsky, Herbert A. Simon and Allen Newell are outstanding.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 26], [27, 39], [39, 40], [41, 47], [48, 54], [54, 55], [56, 63], [64, 65], [65, 66], [67, 72], [73, 76], [77, 82], [83, 89], [90, 93], [94, 105], [105, 106]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [31, 32, "field"], [34, 35, "field"], [38, 39, "field"], [47, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[31, 32, 9, 10, "origin", "", true, false], [31, 32, 9, 10, "part-of", "", false, false], [31, 32, 38, 39, "compare", "", false, false], [34, 35, 9, 10, "origin", "", true, false], [34, 35, 9, 10, "part-of", "", false, false], [34, 35, 38, 39, "compare", "", false, false], [38, 39, 9, 10, "origin", "", true, false], [38, 39, 9, 10, "part-of", "", false, false], [38, 39, 47, 50, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "the", "second", "half", "of", "the", "20th", "century", ",", "electrical", "engineering", "itself", "split", "into", "several", "disciplines", "specialising", "in", "the", "design", "and", "analysis", "of", "systems", "that", "manipulate", "physical", "signals", ",", "such", "as", "electronic", "engineering", "and", "computer", "science", ";", "while", "design", "engineering", "was", "concerned", "with", "the", "functional", "design", "of", "user", "-", "machine", "interfaces", "."], "sentence-detokenized": "In the second half of the 20th century, electrical engineering itself split into several disciplines specialising in the design and analysis of systems that manipulate physical signals, such as electronic engineering and computer science; while design engineering was concerned with the functional design of user-machine interfaces.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 30], [31, 38], [38, 39], [40, 50], [51, 62], [63, 69], [70, 75], [76, 80], [81, 88], [89, 100], [101, 113], [114, 116], [117, 120], [121, 127], [128, 131], [132, 140], [141, 143], [144, 151], [152, 156], [157, 167], [168, 176], [177, 184], [184, 185], [186, 190], [191, 193], [194, 204], [205, 216], [217, 220], [221, 229], [230, 237], [237, 238], [239, 244], [245, 251], [252, 263], [264, 267], [268, 277], [278, 282], [283, 286], [287, 297], [298, 304], [305, 307], [308, 312], [312, 313], [313, 320], [321, 331], [331, 332]]}
{"doc_key": "ai-test-258", "ner": [[6, 6, "metrics"], [8, 10, "metrics"], [12, 12, "metrics"], [45, 47, "metrics"], [54, 56, "metrics"], [60, 66, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 12, 8, 10, "named", "", false, false], [45, 47, 54, 56, "named", "", false, false], [54, 56, 60, 66, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Perhaps", "the", "simplest", "statistic", "is", "the", "accuracy", "or", "correct", "classification", "rate", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "correctly", "categorised", "cases", ";", "this", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "total", "population", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Perhaps the simplest statistic is the accuracy or correct classification rate (FC), which measures the proportion of correctly categorised cases; this is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN) / total population = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 30], [31, 33], [34, 37], [38, 46], [47, 49], [50, 57], [58, 72], [73, 77], [78, 79], [79, 81], [81, 82], [82, 83], [84, 89], [90, 98], [99, 102], [103, 113], [114, 116], [117, 126], [127, 138], [139, 144], [144, 145], [146, 150], [151, 153], [154, 157], [158, 163], [164, 166], [167, 170], [171, 177], [178, 180], [181, 188], [189, 204], [205, 207], [208, 211], [212, 217], [218, 224], [225, 227], [228, 235], [236, 238], [239, 248], [249, 264], [264, 265], [266, 267], [267, 269], [270, 271], [272, 274], [274, 275], [276, 277], [278, 283], [284, 294], [295, 296], [297, 298], [298, 300], [301, 302], [303, 305], [305, 306], [307, 308], [309, 310], [310, 312], [313, 314], [315, 317], [318, 319], [320, 322], [323, 324], [325, 327], [327, 328], [328, 329]]}
{"doc_key": "ai-test-259", "ner": [[15, 23, "conference"], [25, 27, "conference"], [31, 32, "location"], [36, 36, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 23, 31, 32, "physical", "", false, false], [25, 27, 15, 23, "named", "", false, false], [36, 36, 15, 23, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "main", "forums", "for", "research", "in", "the", "scientific", "community", "began", "in", "1995", ",", "when", "the", "first", "international", "conference", "on", "data", "mining", "and", "knowledge", "discovery", "(", "KDD", "-", "95", ")", "was", "launched", "in", "Montreal", ",", "sponsored", "by", "AAAI", "."], "sentence-detokenized": "The main forums for research in the scientific community began in 1995, when the first international conference on data mining and knowledge discovery (KDD-95) was launched in Montreal, sponsored by AAAI.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 19], [20, 28], [29, 31], [32, 35], [36, 46], [47, 56], [57, 62], [63, 65], [66, 70], [70, 71], [72, 76], [77, 80], [81, 86], [87, 100], [101, 111], [112, 114], [115, 119], [120, 126], [127, 130], [131, 140], [141, 150], [151, 152], [152, 155], [155, 156], [156, 158], [158, 159], [160, 163], [164, 172], [173, 175], [176, 184], [184, 185], [186, 195], [196, 198], [199, 203], [203, 204]]}
{"doc_key": "ai-test-260", "ner": [[9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "approach", ",", "models", "are", "developed", "using", "various", "data", "mining", ",", "machine", "learning", "algorithms", "to", "predict", "users", "'", "ratings", "of", "unrated", "items", "."], "sentence-detokenized": "In this approach, models are developed using various data mining, machine learning algorithms to predict users' ratings of unrated items.", "token2charspan": [[0, 2], [3, 7], [8, 16], [16, 17], [18, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 57], [58, 64], [64, 65], [66, 73], [74, 82], [83, 93], [94, 96], [97, 104], [105, 110], [110, 111], [112, 119], [120, 122], [123, 130], [131, 136], [136, 137]]}
{"doc_key": "ai-test-261", "ner": [[13, 13, "algorithm"], [18, 19, "algorithm"], [21, 22, "algorithm"], [26, 28, "misc"], [32, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 18, 19, "related-to", "equivalent", false, false], [18, 19, 21, 22, "usage", "", false, false], [21, 22, 32, 33, "usage", "", false, false], [32, 33, 26, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "light", "of", "the", "above", "discussion", ",", "we", "can", "see", "that", "the", "SVM", "technique", "is", "equivalent", "to", "empirical", "risk", "with", "Tikhonov", "regularization", ",", "where", "the", "loss", "function", "in", "this", "case", "is", "hinge", "loss", "."], "sentence-detokenized": "In the light of the above discussion, we can see that the SVM technique is equivalent to empirical risk with Tikhonov regularization, where the loss function in this case is hinge loss.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 19], [20, 25], [26, 36], [36, 37], [38, 40], [41, 44], [45, 48], [49, 53], [54, 57], [58, 61], [62, 71], [72, 74], [75, 85], [86, 88], [89, 98], [99, 103], [104, 108], [109, 117], [118, 132], [132, 133], [134, 139], [140, 143], [144, 148], [149, 157], [158, 160], [161, 165], [166, 170], [171, 173], [174, 179], [180, 184], [184, 185]]}
{"doc_key": "ai-test-262", "ner": [[3, 7, "person"], [11, 12, "person"], [17, 18, "person"]], "ner_mapping_to_source": [0, 1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "2015", "edition", "was", "hosted", "by", "Molly", "McGrath", "and", "commentated", "by", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "."], "sentence-detokenized": "The 2015 edition was hosted by Molly McGrath and commentated by Chris Rose and former UFC fighter Kenny Florian.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 27], [28, 30], [31, 36], [37, 44], [45, 48], [49, 60], [61, 63], [64, 69], [70, 74], [75, 78], [79, 85], [86, 89], [90, 97], [98, 103], [104, 111], [111, 112]]}
{"doc_key": "ai-test-263", "ner": [[3, 5, "product"], [9, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [18, 18, "researcher"], [22, 22, "researcher"], [31, 32, "researcher"], [33, 35, "task"], [37, 37, "product"], [39, 39, "researcher"], [44, 45, "task"], [47, 49, "researcher"], [52, 53, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[3, 5, 9, 11, "origin", "", false, false], [3, 5, 13, 14, "origin", "", false, false], [3, 5, 16, 17, "origin", "", false, false], [3, 5, 18, 18, "origin", "", false, false], [13, 14, 39, 39, "named", "same", false, false], [16, 17, 22, 22, "named", "same", false, false], [16, 17, 31, 32, "named", "same", false, false], [33, 35, 37, 37, "related-to", "", false, false], [37, 37, 31, 32, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "subset", "called", "Micro", "-", "Planner", "was", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "Sussman", ",", ",", "and", "Winograd", "in", "1971", ",", "and", "has", "been", "used", "in", "Winograd", "'s", "natural", "language", "understanding", "program", "SHRDLU", ",", "Eugene", "Charniak", "'s", "work", "on", "story", "understanding", ",", "Thorne", "McCarty", "'s", "work", "on", "legal", "reasoning", ",", "and", "a", "few", "other", "projects", "."], "sentence-detokenized": "The subset called Micro-Planner was implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd Sussman,, and Winograd in 1971, and has been used in Winograd's natural language understanding program SHRDLU, Eugene Charniak's work on story understanding, Thorne McCarty's work on legal reasoning, and a few other projects.", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 23], [23, 24], [24, 31], [32, 35], [36, 47], [48, 50], [51, 57], [58, 61], [62, 69], [69, 70], [71, 77], [78, 86], [87, 90], [91, 96], [97, 105], [106, 113], [113, 114], [114, 115], [116, 119], [120, 128], [129, 131], [132, 136], [136, 137], [138, 141], [142, 145], [146, 150], [151, 155], [156, 158], [159, 167], [167, 169], [170, 177], [178, 186], [187, 200], [201, 208], [209, 215], [215, 216], [217, 223], [224, 232], [232, 234], [235, 239], [240, 242], [243, 248], [249, 262], [262, 263], [264, 270], [271, 278], [278, 280], [281, 285], [286, 288], [289, 294], [295, 304], [304, 305], [306, 309], [310, 311], [312, 315], [316, 321], [322, 330], [330, 331]]}
{"doc_key": "ai-test-264", "ner": [[0, 1, "product"], [5, 7, "product"], [14, 16, "task"], [18, 19, "task"], [21, 23, "task"], [25, 26, "task"], [28, 29, "task"], [32, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[5, 7, 0, 1, "usage", "", true, false], [14, 16, 5, 7, "part-of", "", true, false], [18, 19, 5, 7, "part-of", "", true, false], [21, 23, 5, 7, "part-of", "", true, false], [25, 26, 5, 7, "part-of", "", true, false], [28, 29, 5, 7, "part-of", "", true, false], [32, 34, 5, 7, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "is", "used", "in", "information", "systems", "for", "a", "variety", "of", "purposes", ",", "including", "word", "sense", "disambiguation", ",", "information", "retrieval", ",", "automatic", "text", "classification", ",", "automatic", "summarization", ",", "machine", "translation", "and", "even", "automatic", "crossword", "generation", "."], "sentence-detokenized": "WordNet is used in information systems for a variety of purposes, including word sense disambiguation, information retrieval, automatic text classification, automatic summarization, machine translation and even automatic crossword generation.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 15], [16, 18], [19, 30], [31, 38], [39, 42], [43, 44], [45, 52], [53, 55], [56, 64], [64, 65], [66, 75], [76, 80], [81, 86], [87, 101], [101, 102], [103, 114], [115, 124], [124, 125], [126, 135], [136, 140], [141, 155], [155, 156], [157, 166], [167, 180], [180, 181], [182, 189], [190, 201], [202, 205], [206, 210], [211, 220], [221, 230], [231, 241], [241, 242]]}
{"doc_key": "ai-test-265", "ner": [[0, 0, "researcher"], [7, 8, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 8, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "was", "elected", "a", "Fellow", "of", "the", "IEEE", "in", "1996", "."], "sentence-detokenized": "Keutzer was elected a Fellow of the IEEE in 1996.", "token2charspan": [[0, 7], [8, 11], [12, 19], [20, 21], [22, 28], [29, 31], [32, 35], [36, 40], [41, 43], [44, 48], [48, 49]]}
{"doc_key": "ai-test-266", "ner": [[8, 10, "algorithm"], [54, 56, "misc"], [66, 67, "algorithm"], [69, 70, "algorithm"], [72, 73, "algorithm"], [75, 76, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[66, 67, 54, 56, "type-of", "", false, false], [69, 70, 54, 56, "type-of", "", false, false], [72, 73, 54, 56, "type-of", "", false, false], [75, 76, 54, 56, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "widely", "used", "type", "of", "composition", "is", "the", "nonlinear", "weighted", "sum", ",", "where", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "left", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "right", ")", "/", "math", ",", "where", "math", "\\", "textstyle", "K", "/", "math", "(", "usually", "called", "the", "activation", "function", ")", "is", "some", "predefined", "function", ",", "such", "as", "a", "hyperbolic", "tangent", ",", "sigmoid", "function", ",", "softmax", "function", "or", "rectifying", "function", "."], "sentence-detokenized": "A widely used type of composition is the nonlinear weighted sum, where math\\ textstyle f (x) = K\\ left (\\ sum _ i w _ i g _ i (x)\\ right) / math, where math\\ textstyle K / math (usually called the activation function) is some predefined function, such as a hyperbolic tangent, sigmoid function, softmax function or rectifying function.", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 18], [19, 21], [22, 33], [34, 36], [37, 40], [41, 50], [51, 59], [60, 63], [63, 64], [65, 70], [71, 75], [75, 76], [77, 86], [87, 88], [89, 90], [90, 91], [91, 92], [93, 94], [95, 96], [96, 97], [98, 102], [103, 104], [104, 105], [106, 109], [110, 111], [112, 113], [114, 115], [116, 117], [118, 119], [120, 121], [122, 123], [124, 125], [126, 127], [127, 128], [128, 129], [129, 130], [131, 136], [136, 137], [138, 139], [140, 144], [144, 145], [146, 151], [152, 156], [156, 157], [158, 167], [168, 169], [170, 171], [172, 176], [177, 178], [178, 185], [186, 192], [193, 196], [197, 207], [208, 216], [216, 217], [218, 220], [221, 225], [226, 236], [237, 245], [245, 246], [247, 251], [252, 254], [255, 256], [257, 267], [268, 275], [275, 276], [277, 284], [285, 293], [293, 294], [295, 302], [303, 311], [312, 314], [315, 325], [326, 334], [334, 335]]}
{"doc_key": "ai-test-267", "ner": [[3, 3, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "movie", "Westworld", ",", "female", "robots", "actually", "had", "intercourse", "with", "human", "men", "as", "part", "of", "an", "imaginary", "vacation", "world", "paid", "for", "by", "human", "customers", "."], "sentence-detokenized": "In the movie Westworld, female robots actually had intercourse with human men as part of an imaginary vacation world paid for by human customers.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [22, 23], [24, 30], [31, 37], [38, 46], [47, 50], [51, 62], [63, 67], [68, 73], [74, 77], [78, 80], [81, 85], [86, 88], [89, 91], [92, 101], [102, 110], [111, 116], [117, 121], [122, 125], [126, 128], [129, 134], [135, 144], [144, 145]]}
{"doc_key": "ai-test-268", "ner": [[5, 10, "task"], [24, 29, "task"], [31, 32, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 10, 24, 29, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "process", "typically", "starts", "with", "terminology", "extraction", "and", "the", "extraction", "of", "concepts", "or", "noun", "phrases", "from", "plain", "text", ",", "using", "language", "processors", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "phrase", "chunking", "."], "sentence-detokenized": "The process typically starts with terminology extraction and the extraction of concepts or noun phrases from plain text, using language processors such as part-of-speech tagging and phrase chunking.", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 28], [29, 33], [34, 45], [46, 56], [57, 60], [61, 64], [65, 75], [76, 78], [79, 87], [88, 90], [91, 95], [96, 103], [104, 108], [109, 114], [115, 119], [119, 120], [121, 126], [127, 135], [136, 146], [147, 151], [152, 154], [155, 159], [159, 160], [160, 162], [162, 163], [163, 169], [170, 177], [178, 181], [182, 188], [189, 197], [197, 198]]}
{"doc_key": "ai-test-269", "ner": [[12, 13, "field"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 18, 12, 13, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["Its", "performance", "has", "been", "demonstrated", "on", "several", "problems", "of", "interest", "to", "the", "machine", "learning", "community", ",", "including", "handwriting", "recognition", "."], "sentence-detokenized": "Its performance has been demonstrated on several problems of interest to the machine learning community, including handwriting recognition.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 24], [25, 37], [38, 40], [41, 48], [49, 57], [58, 60], [61, 69], [70, 72], [73, 76], [77, 84], [85, 93], [94, 103], [103, 104], [105, 114], [115, 126], [127, 138], [138, 139]]}
{"doc_key": "ai-test-270", "ner": [[1, 2, "university"], [4, 4, "researcher"], [9, 10, "researcher"], [20, 20, "product"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 1, 2, "physical", "", false, false], [4, 4, 1, 2, "role", "", false, false], [20, 20, 9, 10, "origin", "", false, false], [20, 20, 17, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "at", "Stanford", ",", "Scheinman", "received", "a", "scholarship", "from", "George", "Devol", ",", "the", "inventor", "of", "the", "first", "industrial", "robot", ",", "Unimate", "."], "sentence-detokenized": "While at Stanford, Scheinman received a scholarship from George Devol, the inventor of the first industrial robot, Unimate.", "token2charspan": [[0, 5], [6, 8], [9, 17], [17, 18], [19, 28], [29, 37], [38, 39], [40, 51], [52, 56], [57, 63], [64, 69], [69, 70], [71, 74], [75, 83], [84, 86], [87, 90], [91, 96], [97, 107], [108, 113], [113, 114], [115, 122], [122, 123]]}
{"doc_key": "ai-test-271", "ner": [[4, 5, "task"], [9, 12, "metrics"], [8, 16, "metrics"], [23, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 9, 12, "usage", "", true, false], [8, 16, 9, 12, "named", "", false, false], [23, 26, 9, 12, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Originally", "used", "for", "evaluating", "machine", "translations", ",", "the", "Bilingual", "Evaluation", "Under", "-", "test", "(", "BLEU", ")", "has", "also", "been", "successfully", "used", "to", "evaluate", "paraphrase", "-", "generating", "models", "."], "sentence-detokenized": "Originally used for evaluating machine translations, the Bilingual Evaluation Under-test (BLEU) has also been successfully used to evaluate paraphrase-generating models.", "token2charspan": [[0, 10], [11, 15], [16, 19], [20, 30], [31, 38], [39, 51], [51, 52], [53, 56], [57, 66], [67, 77], [78, 83], [83, 84], [84, 88], [89, 90], [90, 94], [94, 95], [96, 99], [100, 104], [105, 109], [110, 122], [123, 127], [128, 130], [131, 139], [140, 150], [150, 151], [151, 161], [162, 168], [168, 169]]}
{"doc_key": "ai-test-272", "ner": [[0, 0, "organisation"], [6, 8, "organisation"], [10, 10, "organisation"], [14, 14, "product"], [15, 16, "country"], [18, 18, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 8, "role", "licenses_to", false, false], [0, 0, 10, 10, "role", "licenses_to", false, false], [6, 8, 15, 16, "physical", "", false, false], [10, 10, 18, 18, "physical", "", false, false], [14, 14, 6, 8, "artifact", "produces", false, false], [14, 14, 10, 10, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "later", "licensed", "its", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "who", "manufactured", "Unimates", "in", "Japan", "and", "England", "."], "sentence-detokenized": "Unimation later licensed its technology to Kawasaki Heavy Industries and GKN, who manufactured Unimates in Japan and England.", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 57], [58, 68], [69, 72], [73, 76], [76, 77], [78, 81], [82, 94], [95, 103], [104, 106], [107, 112], [113, 116], [117, 124], [124, 125]]}
{"doc_key": "ai-test-273", "ner": [[19, 21, "conference"], [32, 34, "field"], [51, 54, "field"], [49, 56, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[32, 34, 51, 54, "compare", "", false, false], [49, 56, 51, 54, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "confusion", "between", "the", "two", "research", "communities", "(", "which", "often", "have", "separate", "conferences", "and", "separate", "journals", ",", "ECML", "PKDD", "being", "a", "notable", "exception", ")", "stems", "from", "their", "underlying", "assumptions", ":", "in", "machine", "learning", ",", "performance", "is", "generally", "evaluated", "on", "the", "ability", "to", "reproduce", "known", "knowledge", ",", "while", "in", "knowledge", "discovery", "and", "data", "mining", "(", "KDD", ")", "the", "key", "task", "is", "to", "discover", "previously", "unknown", "knowledge", "."], "sentence-detokenized": "Much of the confusion between the two research communities (which often have separate conferences and separate journals, ECML PKDD being a notable exception) stems from their underlying assumptions: in machine learning, performance is generally evaluated on the ability to reproduce known knowledge, while in knowledge discovery and data mining (KDD) the key task is to discover previously unknown knowledge.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 29], [30, 33], [34, 37], [38, 46], [47, 58], [59, 60], [60, 65], [66, 71], [72, 76], [77, 85], [86, 97], [98, 101], [102, 110], [111, 119], [119, 120], [121, 125], [126, 130], [131, 136], [137, 138], [139, 146], [147, 156], [156, 157], [158, 163], [164, 168], [169, 174], [175, 185], [186, 197], [197, 198], [199, 201], [202, 209], [210, 218], [218, 219], [220, 231], [232, 234], [235, 244], [245, 254], [255, 257], [258, 261], [262, 269], [270, 272], [273, 282], [283, 288], [289, 298], [298, 299], [300, 305], [306, 308], [309, 318], [319, 328], [329, 332], [333, 337], [338, 344], [345, 346], [346, 349], [349, 350], [351, 354], [355, 358], [359, 363], [364, 366], [367, 369], [370, 378], [379, 389], [390, 397], [398, 407], [407, 408]]}
{"doc_key": "ai-test-274", "ner": [[0, 0, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hidden", "Markov", "models", "form", "the", "basis", "of", "most", "modern", "automatic", "speech", "recognition", "systems", "."], "sentence-detokenized": "Hidden Markov models form the basis of most modern automatic speech recognition systems.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 25], [26, 29], [30, 35], [36, 38], [39, 43], [44, 50], [51, 60], [61, 67], [68, 79], [80, 87], [87, 88]]}
{"doc_key": "ai-test-275", "ner": [[2, 2, "location"], [4, 4, "country"], [10, 11, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 4, 4, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": [",", "a", "Bangalore", "(", "India", ")", "company", "specialising", "in", "online", "handwriting", "recognition", "software", "."], "sentence-detokenized": ", a Bangalore (India) company specialising in online handwriting recognition software.", "token2charspan": [[0, 1], [2, 3], [4, 13], [14, 15], [15, 20], [20, 21], [22, 29], [30, 42], [43, 45], [46, 52], [53, 64], [65, 76], [77, 85], [85, 86]]}
{"doc_key": "ai-test-276", "ner": [[27, 28, "misc"], [51, 51, "metrics"], [53, 55, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[51, 51, 53, 55, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Do", "the", "repeated", "translations", "converge", "to", "a", "single", "term", "in", "both", "languages", "?", "That", "is", ",", "does", "the", "translation", "method", "show", "stationarity", "or", "does", "it", "produce", "a", "canonical", "form", "?", "Does", "the", "translation", "become", "stationary", "without", "losing", "the", "original", "meaning", "?", "This", "metric", "has", "been", "criticised", "for", "not", "correlating", "well", "with", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "scores", "."], "sentence-detokenized": "Do the repeated translations converge to a single term in both languages? That is, does the translation method show stationarity or does it produce a canonical form? Does the translation become stationary without losing the original meaning? This metric has been criticised for not correlating well with BLEU (BiLingual Evaluation Understudy) scores.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 28], [29, 37], [38, 40], [41, 42], [43, 49], [50, 54], [55, 57], [58, 62], [63, 72], [72, 73], [74, 78], [79, 81], [81, 82], [83, 87], [88, 91], [92, 103], [104, 110], [111, 115], [116, 128], [129, 131], [132, 136], [137, 139], [140, 147], [148, 149], [150, 159], [160, 164], [164, 165], [166, 170], [171, 174], [175, 186], [187, 193], [194, 204], [205, 212], [213, 219], [220, 223], [224, 232], [233, 240], [240, 241], [242, 246], [247, 253], [254, 257], [258, 262], [263, 273], [274, 277], [278, 281], [282, 293], [294, 298], [299, 303], [304, 308], [309, 310], [310, 319], [320, 330], [331, 341], [341, 342], [343, 349], [349, 350]]}
{"doc_key": "ai-test-277", "ner": [[7, 11, "organisation"], [15, 18, "organisation"], [13, 14, "university"], [20, 20, "university"], [21, 22, "field"], [26, 30, "organisation"], [33, 37, "organisation"], [44, 47, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[15, 18, 13, 14, "part-of", "", false, false], [20, 20, 21, 22, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "has", "been", "a", "fellow", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", ",", "Stanford", "University", "Behavioral", "Science", "Research", "Center", ",", "MIT", "Cognitive", "Science", "Center", ",", "the", "Canadian", "Institute", "for", "Advanced", "Research", ",", "the", "Canadian", "Psychological", "Society", ",", "and", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Canadian", "Society", "in", "1998", "."], "sentence-detokenized": "He has been a fellow of the American Association for Artificial Intelligence, Stanford University Behavioral Science Research Center, MIT Cognitive Science Center, the Canadian Institute for Advanced Research, the Canadian Psychological Society, and was elected a Fellow of the Royal Canadian Society in 1998.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 13], [14, 20], [21, 23], [24, 27], [28, 36], [37, 48], [49, 52], [53, 63], [64, 76], [76, 77], [78, 86], [87, 97], [98, 108], [109, 116], [117, 125], [126, 132], [132, 133], [134, 137], [138, 147], [148, 155], [156, 162], [162, 163], [164, 167], [168, 176], [177, 186], [187, 190], [191, 199], [200, 208], [208, 209], [210, 213], [214, 222], [223, 236], [237, 244], [244, 245], [246, 249], [250, 253], [254, 261], [262, 263], [264, 270], [271, 273], [274, 277], [278, 283], [284, 292], [293, 300], [301, 303], [304, 308], [308, 309]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [14, 19, "misc"], [10, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 14, 19, "part-of", "", false, false], [0, 0, 10, 25, "part-of", "", false, false], [4, 5, 14, 19, "part-of", "", false, false], [4, 5, 10, 25, "part-of", "", false, false], [7, 8, 14, 19, "part-of", "", false, false], [7, 8, 10, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", ",", "along", "with", "Yoshua", "Bengio", "and", "Yann", "LeCun", ",", "is", "hailed", "by", "some", "as", "the", "godfather", "of", "artificial", "intelligence", "and", "the", "godfather", "of", "deep", "learning", "."], "sentence-detokenized": "Hinton, along with Yoshua Bengio and Yann LeCun, is hailed by some as the godfather of artificial intelligence and the godfather of deep learning.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 25], [26, 32], [33, 36], [37, 41], [42, 47], [47, 48], [49, 51], [52, 58], [59, 61], [62, 66], [67, 69], [70, 73], [74, 83], [84, 86], [87, 97], [98, 110], [111, 114], [115, 118], [119, 128], [129, 131], [132, 136], [137, 145], [145, 146]]}
{"doc_key": "ai-test-279", "ner": [[4, 4, "product"], [18, 18, "misc"], [20, 21, "misc"], [22, 23, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 18, 18, "related-to", "", false, false], [4, 4, 20, 21, "related-to", "", false, false], [18, 18, 22, 23, "named", "same", false, false], [28, 29, 22, 23, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "lightweight", ",", "open-source", "eSpeak", "speech", "project", ",", "which", "has", "its", "own", "synthesis", "approach", ",", "has", "experimented", "with", "Mandarin", "and", "Cantonese", ".", "eSpeak", "has", "also", "been", "used", "by", "Google", "Translate", "since", "May", "20102010", "."], "sentence-detokenized": "The lightweight, open-source eSpeak speech project, which has its own synthesis approach, has experimented with Mandarin and Cantonese. eSpeak has also been used by Google Translate since May 20102010.", "token2charspan": [[0, 3], [4, 15], [15, 16], [17, 28], [29, 35], [36, 42], [43, 50], [50, 51], [52, 57], [58, 61], [62, 65], [66, 69], [70, 79], [80, 88], [88, 89], [90, 93], [94, 106], [107, 111], [112, 120], [121, 124], [125, 134], [134, 135], [136, 142], [143, 146], [147, 151], [152, 156], [157, 161], [162, 164], [165, 171], [172, 181], [182, 187], [188, 191], [192, 200], [200, 201]]}
{"doc_key": "ai-test-280", "ner": [[5, 7, "product"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 17, 19, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Also", "released", "in", "1982", ",", "Software", "Automatic", "Mouth", "was", "the", "first", "commercially", "available", "fully", "software", "-", "based", "sound", "synthesis", "program", "."], "sentence-detokenized": "Also released in 1982, Software Automatic Mouth was the first commercially available fully software-based sound synthesis program.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 21], [21, 22], [23, 31], [32, 41], [42, 47], [48, 51], [52, 55], [56, 61], [62, 74], [75, 84], [85, 90], [91, 99], [99, 100], [100, 105], [106, 111], [112, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-test-281", "ner": [[5, 7, "metrics"], [9, 9, "metrics"], [12, 12, "metrics"], [14, 14, "metrics"], [17, 24, "metrics"], [28, 30, "metrics"], [29, 29, "metrics"], [32, 41, "metrics"], [45, 47, "metrics"], [46, 49, "metrics"], [52, 54, "metrics"], [57, 64, "metrics"], [68, 70, "metrics"], [72, 72, "metrics"], [75, 82, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15], "relations": [[9, 9, 5, 7, "named", "", false, false], [12, 12, 5, 7, "named", "", false, false], [14, 14, 5, 7, "named", "", false, false], [17, 24, 5, 7, "named", "", false, false], [29, 29, 28, 30, "named", "", false, false], [32, 41, 28, 30, "named", "", false, false], [46, 49, 45, 47, "named", "", false, false], [52, 54, 45, 47, "named", "", false, false], [57, 64, 45, 47, "named", "", false, false], [72, 72, 68, 70, "named", "", false, false], [75, 82, 68, 70, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11], "sentence": ["The", "column", "rates", "are", ":", "TRUE", "Positive", "Rate", "(", "TPR", ",", "i.e.", "sensitivity", "or", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "supplemented", "by", "FALSE", "Negative", "Rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "and", "TRUE", "Negative", "Rate", "(", "TNR", ",", "i.e.", "specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "supplemented", "by", "FALSE", "Positive", "Rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "The column rates are: TRUE Positive Rate (TPR, i.e. sensitivity or recall) (TP/(TP + FN)), supplemented by FALSE Negative Rate (FNR) (FN/(TP + FN)); and TRUE Negative Rate (TNR, i.e. specificity, SPC) (TN/(TN + FP)), supplemented by FALSE Positive Rate (FPR) (FP/(TN + FP)).", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 20], [20, 21], [22, 26], [27, 35], [36, 40], [41, 42], [42, 45], [45, 46], [47, 51], [52, 63], [64, 66], [67, 73], [73, 74], [75, 76], [76, 78], [78, 79], [79, 80], [80, 82], [83, 84], [85, 87], [87, 88], [88, 89], [89, 90], [91, 103], [104, 106], [107, 112], [113, 121], [122, 126], [127, 128], [128, 131], [131, 132], [133, 134], [134, 136], [136, 137], [137, 138], [138, 140], [141, 142], [143, 145], [145, 146], [146, 147], [147, 148], [149, 152], [153, 157], [158, 166], [167, 171], [172, 173], [173, 176], [176, 177], [178, 182], [183, 194], [194, 195], [196, 199], [199, 200], [201, 202], [202, 204], [204, 205], [205, 206], [206, 208], [209, 210], [211, 213], [213, 214], [214, 215], [215, 216], [217, 229], [230, 232], [233, 238], [239, 247], [248, 252], [253, 254], [254, 257], [257, 258], [259, 260], [260, 262], [262, 263], [263, 264], [264, 266], [267, 268], [269, 271], [271, 272], [272, 273], [273, 274]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 18, 18, "role", "working_with", false, false], [2, 2, 18, 18, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "and", "Weber", "have", "also", "worked", "with", "a", "number", "of", "other", "robots", ",", "and", "their", "experience", "working", "with", "Kismet"], "sentence-detokenized": "Edsinger and Weber have also worked with a number of other robots, and their experience working with Kismet", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 28], [29, 35], [36, 40], [41, 42], [43, 49], [50, 52], [53, 58], [59, 65], [65, 66], [67, 70], [71, 76], [77, 87], [88, 95], [96, 100], [101, 107]]}
{"doc_key": "ai-test-283", "ner": [[0, 0, "programlang"], [12, 12, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 12, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["R", "functionality", "is", "also", "available", "in", "many", "scripting", "languages", ",", "such", "as", "Python", "."], "sentence-detokenized": "R functionality is also available in many scripting languages, such as Python.", "token2charspan": [[0, 1], [2, 15], [16, 18], [19, 23], [24, 33], [34, 36], [37, 41], [42, 51], [52, 61], [61, 62], [63, 67], [68, 70], [71, 77], [77, 78]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [9, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "was", "one", "of", "the", "first", "robot", "languages", "used", "in", "Unimate", "robots", "."], "sentence-detokenized": "VAL was one of the first robot languages used in Unimate robots.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 24], [25, 30], [31, 40], [41, 45], [46, 48], [49, 56], [57, 63], [63, 64]]}
{"doc_key": "ai-test-285", "ner": [[10, 20, "conference"], [11, 17, "conference"], [21, 21, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 20, 21, 21, "physical", "", false, false], [11, 17, 10, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Their", "database", "was", "first", "presented", "as", "a", "poster", "at", "the", "2009", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "conference", "in", "Florida", "."], "sentence-detokenized": "Their database was first presented as a poster at the 2009 Computer Vision and Pattern Recognition (CVPR) conference in Florida.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 24], [25, 34], [35, 37], [38, 39], [40, 46], [47, 49], [50, 53], [54, 58], [59, 67], [68, 74], [75, 78], [79, 86], [87, 98], [99, 100], [100, 104], [104, 105], [106, 116], [117, 119], [120, 127], [127, 128]]}
{"doc_key": "ai-test-286", "ner": [[0, 1, "misc"], [6, 7, "task"], [9, 10, "field"], [5, 13, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 0, 1, "type-of", "", false, false], [9, 10, 0, 1, "type-of", "", false, false], [5, 13, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Categorization", "tasks", "without", "labels", "are", "called", "unsupervised", "classification", ",", "unsupervised", "learning", ",", "cluster", "analysis", "."], "sentence-detokenized": "Categorization tasks without labels are called unsupervised classification, unsupervised learning, cluster analysis.", "token2charspan": [[0, 14], [15, 20], [21, 28], [29, 35], [36, 39], [40, 46], [47, 59], [60, 74], [74, 75], [76, 88], [89, 97], [97, 98], [99, 106], [107, 115], [115, 116]]}
{"doc_key": "ai-test-287", "ner": [[2, 3, "task"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "needs", "object", "recognition", ",", "people", "recognition", "and", "location", ",", "and", "emotion", "recognition", "."], "sentence-detokenized": "It needs object recognition, people recognition and location, and emotion recognition.", "token2charspan": [[0, 2], [3, 8], [9, 15], [16, 27], [27, 28], [29, 35], [36, 47], [48, 51], [52, 60], [60, 61], [62, 65], [66, 73], [74, 85], [85, 86]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [8, 8, "misc"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "process", "is", "complex", "and", "involves", "encoding", "and", "recall", "or", "retrieval", "."], "sentence-detokenized": "The process is complex and involves encoding and recall or retrieval.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 26], [27, 35], [36, 44], [45, 48], [49, 55], [56, 58], [59, 68], [68, 69]]}
{"doc_key": "ai-test-289", "ner": [[7, 8, "product"], [12, 13, "product"], [30, 32, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 12, 13, "named", "", false, false], [7, 8, 30, 32, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Also", "known", "as", "parallel", "robots", "or", "generalised", "Stewart", "platforms", "(", "in", "the", "Stewart", "platform", ",", "actuators", "are", "paired", "on", "both", "the", "base", "and", "the", "platform", ")", ",", "these", "systems", "are", "articulated", "robots", "that", "use", "similar", "mechanisms", "to", "move", "the", "robot", "on", "the", "base", "or", "one", "or", "more", "manipulator", "arms", "."], "sentence-detokenized": "Also known as parallel robots or generalised Stewart platforms (in the Stewart platform, actuators are paired on both the base and the platform), these systems are articulated robots that use similar mechanisms to move the robot on the base or one or more manipulator arms.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 29], [30, 32], [33, 44], [45, 52], [53, 62], [63, 64], [64, 66], [67, 70], [71, 78], [79, 87], [87, 88], [89, 98], [99, 102], [103, 109], [110, 112], [113, 117], [118, 121], [122, 126], [127, 130], [131, 134], [135, 143], [143, 144], [144, 145], [146, 151], [152, 159], [160, 163], [164, 175], [176, 182], [183, 187], [188, 191], [192, 199], [200, 210], [211, 213], [214, 218], [219, 222], [223, 228], [229, 231], [232, 235], [236, 240], [241, 243], [244, 247], [248, 250], [251, 255], [256, 267], [268, 272], [272, 273]]}
{"doc_key": "ai-test-290", "ner": [[0, 1, "field"], [4, 5, "field"], [9, 11, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 5, "part-of", "subfield", false, false], [0, 1, 9, 11, "compare", "", false, false], [9, 11, 18, 19, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "vision", "as", "a", "systems", "engineering", "discipline", "is", "distinct", "from", "computer", "vision", ",", "which", "is", "a", "form", "of", "computer", "science", "."], "sentence-detokenized": "Machine vision as a systems engineering discipline is distinct from computer vision, which is a form of computer science.", "token2charspan": [[0, 7], [8, 14], [15, 17], [18, 19], [20, 27], [28, 39], [40, 50], [51, 53], [54, 62], [63, 67], [68, 76], [77, 83], [83, 84], [85, 90], [91, 93], [94, 95], [96, 100], [101, 103], [104, 112], [113, 120], [120, 121]]}
{"doc_key": "ai-test-291", "ner": [[4, 5, "algorithm"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 9, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "activation", "function", "of", "LSTM", "gates", "is", "often", "the", "logistic", "sigmoid", "function", "."], "sentence-detokenized": "The activation function of LSTM gates is often the logistic sigmoid function.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 26], [27, 31], [32, 37], [38, 40], [41, 46], [47, 50], [51, 59], [60, 67], [68, 76], [76, 77]]}
{"doc_key": "ai-test-292", "ner": [[5, 8, "metrics"], [21, 23, "metrics"], [20, 25, "metrics"], [33, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 8, 21, 23, "named", "", false, false], [5, 8, 33, 35, "named", "", false, false], [20, 25, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "the", "(", "necessarily", "unique", ")", "efficient", "estimator", ",", "and", "thus", "also", "the", "minimum", "variance", "unbiased", "estimator", "(", "MVUE", ")", ",", "in", "addition", "to", "being", "the", "maximum", "likelihood", "estimator", "."], "sentence-detokenized": "In other words, the sample mean is the (necessarily unique) efficient estimator, and thus also the minimum variance unbiased estimator (MVUE), in addition to being the maximum likelihood estimator.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 38], [39, 40], [40, 51], [52, 58], [58, 59], [60, 69], [70, 79], [79, 80], [81, 84], [85, 89], [90, 94], [95, 98], [99, 106], [107, 115], [116, 124], [125, 134], [135, 136], [136, 140], [140, 141], [141, 142], [143, 145], [146, 154], [155, 157], [158, 163], [164, 167], [168, 175], [176, 186], [187, 196], [196, 197]]}
{"doc_key": "ai-test-293", "ner": [[4, 6, "academicjournal"], [8, 10, "researcher"], [12, 13, "researcher"], [15, 16, "researcher"], [24, 24, "product"], [27, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 6, 24, 24, "topic", "", false, false], [4, 6, 27, 28, "topic", "", false, false], [8, 10, 4, 6, "role", "", false, false], [12, 13, 4, 6, "role", "", false, false], [15, 16, 4, 6, "role", "", false, false], [24, 24, 27, 28, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "a", "2001", "article", "in", "Scientific", "American", ",", "Berners", "-", "Lee", ",", "James", "Hendler", "and", "Ora", "Lassila", "described", "the", "expected", "evolution", "of", "the", "existing", "web", "towards", "a", "semantic", "web", "."], "sentence-detokenized": "In a 2001 article in Scientific American, Berners-Lee, James Hendler and Ora Lassila described the expected evolution of the existing web towards a semantic web.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 17], [18, 20], [21, 31], [32, 40], [40, 41], [42, 49], [49, 50], [50, 53], [53, 54], [55, 60], [61, 68], [69, 72], [73, 76], [77, 84], [85, 94], [95, 98], [99, 107], [108, 117], [118, 120], [121, 124], [125, 133], [134, 137], [138, 145], [146, 147], [148, 156], [157, 160], [160, 161]]}
{"doc_key": "ai-test-294", "ner": [[0, 0, "misc"], [14, 15, "person"], [17, 17, "person"], [30, 30, "person"], [41, 41, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 15, 0, 0, "role", "actor_in_work", false, false], [17, 17, 14, 15, "named", "", false, false], [17, 17, 14, 15, "origin", "", false, false], [30, 30, 17, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Pengefuto", "employed", "several", "actors", "who", "were", "less", "well", "-", "known", "at", "the", "time", ":", "Sean", "Young", "plays", "Rachael", ",", "the", "experimental", "replicant", "who", "has", "been", "implanted", "with", "the", "memories", "of", "Tyrell", "'s", "niece", "and", "who", "therefore", "believes", "she", "is", "human", ";", "Sammon", ",", "pp.", "92", "-", "93", "."], "sentence-detokenized": "Pengefuto employed several actors who were less well-known at the time: Sean Young plays Rachael, the experimental replicant who has been implanted with the memories of Tyrell's niece and who therefore believes she is human; Sammon, pp. 92-93.", "token2charspan": [[0, 9], [10, 18], [19, 26], [27, 33], [34, 37], [38, 42], [43, 47], [48, 52], [52, 53], [53, 58], [59, 61], [62, 65], [66, 70], [70, 71], [72, 76], [77, 82], [83, 88], [89, 96], [96, 97], [98, 101], [102, 114], [115, 124], [125, 128], [129, 132], [133, 137], [138, 147], [148, 152], [153, 156], [157, 165], [166, 168], [169, 175], [175, 177], [178, 183], [184, 187], [188, 191], [192, 201], [202, 210], [211, 214], [215, 217], [218, 223], [223, 224], [225, 231], [231, 232], [233, 236], [237, 239], [239, 240], [240, 242], [242, 243]]}
{"doc_key": "ai-test-295", "ner": [[3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 13, "researcher"], [16, 18, "university"], [27, 29, "product"], [32, 32, "product"], [48, 48, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 4, 16, 18, "physical", "", false, false], [6, 7, 16, 18, "physical", "", false, false], [9, 10, 16, 18, "physical", "", false, false], [12, 13, 16, 18, "physical", "", false, false], [16, 18, 48, 48, "physical", "", true, false], [27, 29, 16, 18, "temporal", "", false, false], [32, 32, 16, 18, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1971", ",", "Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "and", "Terry", "Winograd", "visited", "the", "University", "of", "Edinburgh", ",", "where", "they", "spread", "the", "word", "about", "the", "Micro", "-", "Planner", "and", "the", "SHRDLU", ",", "and", "challenged", "the", "single", "proof", "approach", "to", "resolution", "that", "was", "the", "mainstay", "of", "the", "Edinburgh", "logicians", "."], "sentence-detokenized": "In 1971, Gerry Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited the University of Edinburgh, where they spread the word about the Micro-Planner and the SHRDLU, and challenged the single proof approach to resolution that was the mainstay of the Edinburgh logicians.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 22], [22, 23], [24, 30], [31, 39], [39, 40], [41, 48], [49, 55], [56, 59], [60, 65], [66, 74], [75, 82], [83, 86], [87, 97], [98, 100], [101, 110], [110, 111], [112, 117], [118, 122], [123, 129], [130, 133], [134, 138], [139, 144], [145, 148], [149, 154], [154, 155], [155, 162], [163, 166], [167, 170], [171, 177], [177, 178], [179, 182], [183, 193], [194, 197], [198, 204], [205, 210], [211, 219], [220, 222], [223, 233], [234, 238], [239, 242], [243, 246], [247, 255], [256, 258], [259, 262], [263, 272], [273, 282], [282, 283]]}
{"doc_key": "ai-test-296", "ner": [[0, 1, "researcher"], [9, 9, "field"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 13, 14, "role", "inspires", false, false], [0, 1, 16, 17, "role", "inspires", false, false], [0, 1, 19, 20, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Walter", "'s", "work", "has", "inspired", "the", "next", "generation", "of", "robotics", "researchers", ",", "including", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work has inspired the next generation of robotics researchers, including Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 17], [18, 26], [27, 30], [31, 35], [36, 46], [47, 49], [50, 58], [59, 70], [70, 71], [72, 81], [82, 88], [89, 95], [95, 96], [97, 101], [102, 109], [110, 113], [114, 118], [119, 125], [125, 126]]}
{"doc_key": "ai-test-297", "ner": [[2, 3, "researcher"], [14, 19, "event"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Subsequently", ",", "Alex", "Krizhevsky", "and", "colleagues", "'", "similar", "GPU", "-", "based", "CNN", "won", "the", "2012", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "."], "sentence-detokenized": "Subsequently, Alex Krizhevsky and colleagues' similar GPU-based CNN won the 2012 ImageNet Large Scale Visual Recognition Challenge.", "token2charspan": [[0, 12], [12, 13], [14, 18], [19, 29], [30, 33], [34, 44], [44, 45], [46, 53], [54, 57], [57, 58], [58, 63], [64, 67], [68, 71], [72, 75], [76, 80], [81, 89], [90, 95], [96, 101], [102, 108], [109, 120], [121, 130], [130, 131]]}
{"doc_key": "ai-test-298", "ner": [[0, 1, "misc"], [9, 10, "metrics"], [13, 14, "metrics"], [20, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 0, 1, "type-of", "", false, false], [13, 14, 0, 1, "type-of", "", false, false], [13, 14, 20, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Loss", "functions", "commonly", "used", "for", "probability", "classification", "include", "the", "log", "loss", "and", "the", "Brier", "score", "between", "the", "predicted", "and", "the", "TRUE", "probability", "distributions", "."], "sentence-detokenized": "Loss functions commonly used for probability classification include the log loss and the Brier score between the predicted and the TRUE probability distributions.", "token2charspan": [[0, 4], [5, 14], [15, 23], [24, 28], [29, 32], [33, 44], [45, 59], [60, 67], [68, 71], [72, 75], [76, 80], [81, 84], [85, 88], [89, 94], [95, 100], [101, 108], [109, 112], [113, 122], [123, 126], [127, 130], [131, 135], [136, 147], [148, 161], [161, 162]]}
{"doc_key": "ai-test-299", "ner": [[4, 4, "organisation"], [18, 19, "field"], [13, 14, "organisation"], [9, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 18, 19, "general-affiliation", "field_of_study", false, false], [4, 4, 9, 10, "part-of", "", false, false], [13, 14, 4, 4, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "May", "2016", ",", "NtechLab", "was", "one", "of", "three", "Russian", "companies", "selected", "by", "NIST", "for", "official", "testing", "of", "biometric", "technology", "."], "sentence-detokenized": "In May 2016, NtechLab was one of three Russian companies selected by NIST for official testing of biometric technology.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [22, 25], [26, 29], [30, 32], [33, 38], [39, 46], [47, 56], [57, 65], [66, 68], [69, 73], [74, 77], [78, 86], [87, 94], [95, 97], [98, 107], [108, 118], [118, 119]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["But", "floating", "point", "numbers", "only", "have", "a", "certain", "mathematical", "precision", "."], "sentence-detokenized": "But floating point numbers only have a certain mathematical precision.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 26], [27, 31], [32, 36], [37, 38], [39, 46], [47, 59], [60, 69], [69, 70]]}
{"doc_key": "ai-test-301", "ner": [[4, 4, "organisation"], [9, 16, "conference"], [12, 18, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 9, 16, "role", "contributes_to", false, false], [12, 18, 9, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2015", ",", "several", "SenseTime", "papers", "were", "accepted", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "In 2015, several SenseTime papers were accepted at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 26], [27, 33], [34, 38], [39, 47], [48, 50], [51, 54], [55, 65], [66, 68], [69, 77], [78, 84], [85, 88], [89, 96], [97, 108], [109, 110], [110, 114], [114, 115], [115, 116]]}
{"doc_key": "ai-test-302", "ner": [[8, 9, "task"], [7, 11, "task"], [14, 15, "task"], [17, 20, "task"], [22, 23, "field"], [25, 27, "misc"], [29, 35, "conference"], [43, 45, "misc"], [47, 48, "conference"], [64, 66, "misc"], [68, 68, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[8, 9, 22, 23, "part-of", "task_part_of_field", false, false], [7, 11, 8, 9, "named", "", false, false], [14, 15, 22, 23, "part-of", "task_part_of_field", false, false], [17, 20, 14, 15, "named", "", false, false], [25, 27, 29, 35, "temporal", "", false, false], [43, 45, 47, 48, "temporal", "", false, false], [64, 66, 68, 68, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["He", "was", "co-developer", "of", "optimal", "algorithms", "for", "Structure", "From", "Motion", "(", "SFM", ",", "or", "Visual", "SLAM", ",", "simultaneous", "localization", "and", "mapping", ",", "in", "robotics", ";", "Best", "Paper", "Award", "at", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "1998", ")", ",", "characterized", "its", "ambiguities", "(", "David", "Marr", "Prize", "at", "ICCV", "1999", ")", ",", "and", "characterized", "the", "identifiability", "and", "observability", "of", "visual", "-", "inertial", "sensor", "fusion", "(", "Best", "Paper", "Award", "at", "Robotics", "2015", ")", "."], "sentence-detokenized": "He was co-developer of optimal algorithms for Structure From Motion (SFM, or Visual SLAM, simultaneous localization and mapping, in robotics; Best Paper Award at Conference on Computer Vision and Pattern Recognition 1998), characterized its ambiguities (David Marr Prize at ICCV 1999), and characterized the identifiability and observability of visual-inertial sensor fusion (Best Paper Award at Robotics 2015).", "token2charspan": [[0, 2], [3, 6], [7, 19], [20, 22], [23, 30], [31, 41], [42, 45], [46, 55], [56, 60], [61, 67], [68, 69], [69, 72], [72, 73], [74, 76], [77, 83], [84, 88], [88, 89], [90, 102], [103, 115], [116, 119], [120, 127], [127, 128], [129, 131], [132, 140], [140, 141], [142, 146], [147, 152], [153, 158], [159, 161], [162, 172], [173, 175], [176, 184], [185, 191], [192, 195], [196, 203], [204, 215], [216, 220], [220, 221], [221, 222], [223, 236], [237, 240], [241, 252], [253, 254], [254, 259], [260, 264], [265, 270], [271, 273], [274, 278], [279, 283], [283, 284], [284, 285], [286, 289], [290, 303], [304, 307], [308, 323], [324, 327], [328, 341], [342, 344], [345, 351], [351, 352], [352, 360], [361, 367], [368, 374], [375, 376], [376, 380], [381, 386], [387, 392], [393, 395], [396, 404], [405, 409], [409, 410], [410, 411]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 11, "field"], [13, 14, "field"], [21, 22, "task"], [18, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 7, 8, "part-of", "task_part_of_field", false, false], [0, 1, 10, 11, "part-of", "task_part_of_field", false, false], [0, 1, 13, 14, "part-of", "task_part_of_field", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 18, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "a", "fundamental", "tool", "for", "image", "processing", ",", "machine", "vision", "and", "computer", "vision", ",", "especially", "in", "the", "areas", "of", "feature", "detection", "and", "feature", "extraction", "."], "sentence-detokenized": "Edge detection is a fundamental tool for image processing, machine vision and computer vision, especially in the areas of feature detection and feature extraction.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 19], [20, 31], [32, 36], [37, 40], [41, 46], [47, 57], [57, 58], [59, 66], [67, 73], [74, 77], [78, 86], [87, 93], [93, 94], [95, 105], [106, 108], [109, 112], [113, 118], [119, 121], [122, 129], [130, 139], [140, 143], [144, 151], [152, 162], [162, 163]]}
{"doc_key": "ai-test-305", "ner": [[11, 12, "misc"], [27, 30, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "example", "of", "this", "might", "be", "a", "variable", "such", "as", "the", "outside", "temperature", "(", "mathtemp", "/", "math", ")", ",", "which", "in", "a", "given", "application", "can", "be", "recorded", "to", "several", "decimal", "places", "(", "depending", "on", "the", "sensing", "device", ")", "."], "sentence-detokenized": "An example of this might be a variable such as the outside temperature (mathtemp / math), which in a given application can be recorded to several decimal places (depending on the sensing device).", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 18], [19, 24], [25, 27], [28, 29], [30, 38], [39, 43], [44, 46], [47, 50], [51, 58], [59, 70], [71, 72], [72, 80], [81, 82], [83, 87], [87, 88], [88, 89], [90, 95], [96, 98], [99, 100], [101, 106], [107, 118], [119, 122], [123, 125], [126, 134], [135, 137], [138, 145], [146, 153], [154, 160], [161, 162], [162, 171], [172, 174], [175, 178], [179, 186], [187, 193], [193, 194], [194, 195]]}
{"doc_key": "ai-test-306", "ner": [[3, 4, "person"], [6, 7, "person"], [9, 10, "person"], [17, 18, "person"], [20, 20, "misc"], [24, 24, "misc"], [26, 27, "person"], [29, 29, "organisation"], [32, 33, "person"], [37, 38, "person"], [40, 40, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11], "relations": [[26, 27, 20, 20, "part-of", "", false, false], [26, 27, 24, 24, "role", "", false, false], [32, 33, 29, 29, "role", "", false, false], [40, 40, 37, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4], "sentence": ["Returning", "judges", "are", "Fon", "Davis", ",", "Jessica", "Chobot", "and", "Leland", "Melvin", ",", "and", "celebrity", "guests", "include", "actor", "Clark", "Gregg", ",", "MythBusters", "host", "and", "former", "Battlebots", "builder", "Adam", "Savage", ",", "NFL", "tight", "end", "Vernon", "Davis", "and", "YouTube", "star", "Michael", "Stevens", "aka", "Vsauce", "."], "sentence-detokenized": "Returning judges are Fon Davis, Jessica Chobot and Leland Melvin, and celebrity guests include actor Clark Gregg, MythBusters host and former Battlebots builder Adam Savage, NFL tight end Vernon Davis and YouTube star Michael Stevens aka Vsauce.", "token2charspan": [[0, 9], [10, 16], [17, 20], [21, 24], [25, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 57], [58, 64], [64, 65], [66, 69], [70, 79], [80, 86], [87, 94], [95, 100], [101, 106], [107, 112], [112, 113], [114, 125], [126, 130], [131, 134], [135, 141], [142, 152], [153, 160], [161, 165], [166, 172], [172, 173], [174, 177], [178, 183], [184, 187], [188, 194], [195, 200], [201, 204], [205, 212], [213, 217], [218, 225], [226, 233], [234, 237], [238, 244], [244, 245]]}
{"doc_key": "ai-test-307", "ner": [[15, 16, "algorithm"], [19, 21, "algorithm"], [17, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 17, 25, "part-of", "", false, false], [19, 21, 17, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "these", "methods", "have", "never", "triumphed", "over", "the", "non-uniform", ",", "internally", "hand", "-", "crafted", "Gaussian", "mixture", "model", "/", "hidden", "Markov", "model", "(", "GMM", "-", "HMM", ")", "technology", ",", "which", "is", "based", "on", "generative", ",", "discriminatively", "trained", "models", "of", "speech", "."], "sentence-detokenized": "However, these methods have never triumphed over the non-uniform, internally hand-crafted Gaussian mixture model/hidden Markov model (GMM-HMM) technology, which is based on generative, discriminatively trained models of speech.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 22], [23, 27], [28, 33], [34, 43], [44, 48], [49, 52], [53, 64], [64, 65], [66, 76], [77, 81], [81, 82], [82, 89], [90, 98], [99, 106], [107, 112], [112, 113], [113, 119], [120, 126], [127, 132], [133, 134], [134, 137], [137, 138], [138, 141], [141, 142], [143, 153], [153, 154], [155, 160], [161, 163], [164, 169], [170, 172], [173, 183], [183, 184], [185, 201], [202, 209], [210, 216], [217, 219], [220, 226], [226, 227]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "and", "SciPy", "provide", "a", "convenient", "way", "to", "apply", "these", "different", "methods", "."], "sentence-detokenized": "Software packages such as MATLAB, GNU Octave, Scilab and SciPy provide a convenient way to apply these different methods.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [53, 56], [57, 62], [63, 70], [71, 72], [73, 83], [84, 87], [88, 90], [91, 96], [97, 102], [103, 112], [113, 120], [120, 121]]}
{"doc_key": "ai-test-309", "ner": [[1, 2, "algorithm"], [0, 4, "algorithm"], [8, 9, "task"], [16, 17, "researcher"], [19, 20, "university"], [22, 23, "researcher"], [25, 28, "organisation"], [30, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 2, 8, 9, "related-to", "", false, false], [1, 2, 16, 17, "origin", "", false, false], [1, 2, 22, 23, "origin", "", false, false], [0, 4, 1, 2, "named", "", false, false], [16, 17, 19, 20, "physical", "", false, false], [16, 17, 19, 20, "role", "", false, false], [22, 23, 25, 28, "physical", "", false, false], [22, 23, 25, 28, "role", "", false, false], [30, 30, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Linear", "Predictive", "Coding", "(", "LPC", ")", ",", "a", "speech", "processing", "algorithm", ",", "was", "first", "proposed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", "."], "sentence-detokenized": "Linear Predictive Coding (LPC), a speech processing algorithm, was first proposed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 72], [73, 81], [82, 84], [85, 93], [94, 101], [102, 104], [105, 111], [112, 122], [123, 126], [127, 132], [133, 138], [139, 141], [142, 148], [149, 158], [159, 162], [163, 172], [173, 174], [174, 177], [177, 178], [179, 181], [182, 186], [186, 187]]}
{"doc_key": "ai-test-310", "ner": [[22, 31, "conference"], [20, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 20, 22, 31, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2006", ",", "on", "the", "occasion", "of", "the", "25th", "anniversary", "of", "the", "algorithm", ",", "a", "workshop", "was", "organised", "at", "the", "CVPR", "(", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ")", "to", "summarise", "recent", "contributions", "and", "variations", "of", "the", "original", "algorithm", ",", "aimed", "primarily", "at", "improving", "the", "speed", "of", "the", "algorithm", ",", "the", "robustness", "and", "accuracy", "of", "the", "estimated", "solution", ",", "and", "reducing", "the", "dependence", "on", "user", "-", "defined", "constants", "."], "sentence-detokenized": "In 2006, on the occasion of the 25th anniversary of the algorithm, a workshop was organised at the CVPR (International Conference on Computer Vision and Pattern Recognition) to summarise recent contributions and variations of the original algorithm, aimed primarily at improving the speed of the algorithm, the robustness and accuracy of the estimated solution, and reducing the dependence on user-defined constants.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 24], [25, 27], [28, 31], [32, 36], [37, 48], [49, 51], [52, 55], [56, 65], [65, 66], [67, 68], [69, 77], [78, 81], [82, 91], [92, 94], [95, 98], [99, 103], [104, 105], [105, 118], [119, 129], [130, 132], [133, 141], [142, 148], [149, 152], [153, 160], [161, 172], [172, 173], [174, 176], [177, 186], [187, 193], [194, 207], [208, 211], [212, 222], [223, 225], [226, 229], [230, 238], [239, 248], [248, 249], [250, 255], [256, 265], [266, 268], [269, 278], [279, 282], [283, 288], [289, 291], [292, 295], [296, 305], [305, 306], [307, 310], [311, 321], [322, 325], [326, 334], [335, 337], [338, 341], [342, 351], [352, 360], [360, 361], [362, 365], [366, 374], [375, 378], [379, 389], [390, 392], [393, 397], [397, 398], [398, 405], [406, 415], [415, 416]]}
{"doc_key": "ai-test-311", "ner": [[4, 6, "university"], [9, 12, "organisation"], [14, 16, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Members", "went", "to", "the", "University", "of", "Debrecen", ",", "the", "Hungarian", "Academy", "of", "Sciences", ",", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "University", ",", "etc", "."], "sentence-detokenized": "Members went to the University of Debrecen, the Hungarian Academy of Sciences, E\u00f6tv\u00f6s Lor\u00e1nd University, etc.", "token2charspan": [[0, 7], [8, 12], [13, 15], [16, 19], [20, 30], [31, 33], [34, 42], [42, 43], [44, 47], [48, 57], [58, 65], [66, 68], [69, 77], [77, 78], [79, 85], [86, 92], [93, 103], [103, 104], [105, 108], [108, 109]]}
{"doc_key": "ai-test-312", "ner": [[3, 6, "algorithm"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 6, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "extend", "the", "SVM", "to", "cases", "where", "the", "data", "can", "not", "be", "linearly", "separated", ",", "we", "introduce", "the", "loss", "function", ","], "sentence-detokenized": "To extend the SVM to cases where the data cannot be linearly separated, we introduce the loss function,", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 17], [18, 20], [21, 26], [27, 32], [33, 36], [37, 41], [42, 45], [45, 48], [49, 51], [52, 60], [61, 70], [70, 71], [72, 74], [75, 84], [85, 88], [89, 93], [94, 102], [102, 103]]}
{"doc_key": "ai-test-313", "ner": [[0, 0, "programlang"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 10, 11, "origin", "", false, false], [0, 0, 13, 14, "origin", "", false, false], [0, 0, 16, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "is", "an", "educational", "programming", "language", "designed", "in", "1967", "by", "Wally", "Feurzeig", ",", "Seymour", "Papert", "and", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo is an educational programming language designed in 1967 by Wally Feurzeig, Seymour Papert and Cynthia Solomon.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 34], [35, 43], [44, 52], [53, 55], [56, 60], [61, 63], [64, 69], [70, 78], [78, 79], [80, 87], [88, 94], [95, 98], [99, 106], [107, 114], [114, 115]]}
{"doc_key": "ai-test-314", "ner": [[0, 3, "organisation"], [13, 17, "organisation"], [18, 21, "location"], [23, 23, "location"], [24, 27, "location"], [37, 41, "product"], [43, 53, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 13, 17, "role", "works_for", false, false], [13, 17, 18, 21, "physical", "", false, false], [18, 21, 23, 23, "physical", "", false, false], [23, 23, 24, 27, "physical", "", false, false], [37, 41, 0, 3, "origin", "", false, false], [43, 53, 37, 41, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "Eyring", "Research", "Institute", "played", "an", "important", "role", "in", "helping", "the", "United", "States", "Air", "Force", "Missile", "Command", "at", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", ",", "to", "produce", ",", "in", "the", "highest", "military", "secrecy", ",", "the", "Intelligent", "Systems", "Technology", "Software", "that", "formed", "the", "basis", "of", "what", "Reagan", "later", "called", "the", "Star", "Wars", "programme", "."], "sentence-detokenized": "The Eyring Research Institute played an important role in helping the United States Air Force Missile Command at Hill Air Force Base near Ogden, Utah, to produce, in the highest military secrecy, the Intelligent Systems Technology Software that formed the basis of what Reagan later called the Star Wars programme.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 29], [30, 36], [37, 39], [40, 49], [50, 54], [55, 57], [58, 65], [66, 69], [70, 76], [77, 83], [84, 87], [88, 93], [94, 101], [102, 109], [110, 112], [113, 117], [118, 121], [122, 127], [128, 132], [133, 137], [138, 143], [143, 144], [145, 149], [149, 150], [151, 153], [154, 161], [161, 162], [163, 165], [166, 169], [170, 177], [178, 186], [187, 194], [194, 195], [196, 199], [200, 211], [212, 219], [220, 230], [231, 239], [240, 244], [245, 251], [252, 255], [256, 261], [262, 264], [265, 269], [270, 276], [277, 282], [283, 289], [290, 293], [294, 298], [299, 303], [304, 313], [313, 314]]}
{"doc_key": "ai-test-315", "ner": [[8, 9, "field"], [26, 29, "researcher"], [31, 32, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Over", "the", "decades", ",", "the", "emerging", "fields", "of", "computing", "have", "been", "researched", "and", "developed", "in", "the", "areas", "of", "compilers", ",", "programming", "languages", "and", "system", "architecture", "by", "John", "F", ".", "Sowa", "and", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "Over the decades, the emerging fields of computing have been researched and developed in the areas of compilers, programming languages and system architecture by John F. Sowa and John Zachman (1992).", "token2charspan": [[0, 4], [5, 8], [9, 16], [16, 17], [18, 21], [22, 30], [31, 37], [38, 40], [41, 50], [51, 55], [56, 60], [61, 71], [72, 75], [76, 85], [86, 88], [89, 92], [93, 98], [99, 101], [102, 111], [111, 112], [113, 124], [125, 134], [135, 138], [139, 145], [146, 158], [159, 161], [162, 166], [167, 168], [168, 169], [170, 174], [175, 178], [179, 183], [184, 191], [192, 193], [193, 197], [197, 198], [198, 199]]}
{"doc_key": "ai-test-316", "ner": [[1, 2, "algorithm"], [7, 11, "algorithm"], [13, 14, "algorithm"], [18, 20, "field"], [22, 23, "field"], [26, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 11, 1, 2, "named", "", false, false], [13, 14, 1, 2, "named", "", false, false], [18, 20, 1, 2, "usage", "", false, false], [22, 23, 1, 2, "usage", "", false, false], [26, 29, 1, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Sobel", "operator", ",", "also", "sometimes", "called", "the", "Sobel", "-", "Feldman", "operator", "or", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "particularly", "in", "edge", "detection", "algorithms", ",", "where", "it", "produces", "an", "image", "that", "highlights", "edges", "."], "sentence-detokenized": "The Sobel operator, also sometimes called the Sobel-Feldman operator or Sobel filter, is used in image processing and computer vision, particularly in edge detection algorithms, where it produces an image that highlights edges.", "token2charspan": [[0, 3], [4, 9], [10, 18], [18, 19], [20, 24], [25, 34], [35, 41], [42, 45], [46, 51], [51, 52], [52, 59], [60, 68], [69, 71], [72, 77], [78, 84], [84, 85], [86, 88], [89, 93], [94, 96], [97, 102], [103, 113], [114, 117], [118, 126], [127, 133], [133, 134], [135, 147], [148, 150], [151, 155], [156, 165], [166, 176], [176, 177], [178, 183], [184, 186], [187, 195], [196, 198], [199, 204], [205, 209], [210, 220], [221, 226], [226, 227]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [3, 4, "field"], [15, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 4, "compare", "", false, false], [0, 0, 3, 4, "type-of", "", false, false], [0, 0, 15, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "is", "a", "supervised", "learning", "algorithm", "that", "uses", "the", "labels", "in", "the", "data", ",", "while", "PCA", "is", "a", "learning", "algorithm", "that", "ignores", "the", "labels", "."], "sentence-detokenized": "LDA is a supervised learning algorithm that uses the labels in the data, while PCA is a learning algorithm that ignores the labels.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 19], [20, 28], [29, 38], [39, 43], [44, 48], [49, 52], [53, 59], [60, 62], [63, 66], [67, 71], [71, 72], [73, 78], [79, 82], [83, 85], [86, 87], [88, 96], [97, 106], [107, 111], [112, 119], [120, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "linear", "classification", "algorithms", "include", "Winnow", ",", "support", "vector", "machine", "and", "logistic", "regression", "."], "sentence-detokenized": "Other linear classification algorithms include Winnow, support vector machine and logistic regression.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 38], [39, 46], [47, 53], [53, 54], [55, 62], [63, 69], [70, 77], [78, 81], [82, 90], [91, 101], [101, 102]]}
{"doc_key": "ai-test-319", "ner": [[0, 1, "product"], [5, 6, "programlang"], [16, 18, "product"], [20, 20, "programlang"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "general-affiliation", "", true, false], [0, 1, 16, 18, "general-affiliation", "", true, false], [0, 1, 20, 20, "general-affiliation", "", true, false], [0, 1, 22, 22, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "VTK", "consists", "of", "a", "C", "++", "class", "library", "and", "several", "interpreted", "interface", "layers", ",", "including", "Tcl", "/", "Tk", ",", "Java", "and", "Python", "."], "sentence-detokenized": "The VTK consists of a C++ class library and several interpreted interface layers, including Tcl/Tk, Java and Python.", "token2charspan": [[0, 3], [4, 7], [8, 16], [17, 19], [20, 21], [22, 23], [23, 25], [26, 31], [32, 39], [40, 43], [44, 51], [52, 63], [64, 73], [74, 80], [80, 81], [82, 91], [92, 95], [95, 96], [96, 98], [98, 99], [100, 104], [105, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-320", "ner": [[3, 5, "task"], [15, 19, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Text", "produced", "by", "automatic", "speech", "recognition", "processing", "of", "spontaneous", "speech", "and", "printed", "or", "handwritten", "text", "produced", "by", "optical", "character", "recognition", "also", "contain", "processing", "noise", "."], "sentence-detokenized": "Text produced by automatic speech recognition processing of spontaneous speech and printed or handwritten text produced by optical character recognition also contain processing noise.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 26], [27, 33], [34, 45], [46, 56], [57, 59], [60, 71], [72, 78], [79, 82], [83, 90], [91, 93], [94, 105], [106, 110], [111, 119], [120, 122], [123, 130], [131, 140], [141, 152], [153, 157], [158, 165], [166, 176], [177, 182], [182, 183]]}
{"doc_key": "ai-test-321", "ner": [[0, 1, "researcher"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 10, 10, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "has", "written", "several", "books", "and", "led", "the", "development", "of", "WordNet", ",", "an", "online", "word", "association", "database", "for", "computer", "programs", "."], "sentence-detokenized": "Miller has written several books and led the development of WordNet, an online word association database for computer programs.", "token2charspan": [[0, 6], [7, 10], [11, 18], [19, 26], [27, 32], [33, 36], [37, 40], [41, 44], [45, 56], [57, 59], [60, 67], [67, 68], [69, 71], [72, 78], [79, 83], [84, 95], [96, 104], [105, 108], [109, 117], [118, 126], [126, 127]]}
{"doc_key": "ai-test-322", "ner": [[1, 1, "field"], [8, 10, "organisation"], [6, 7, "country"], [16, 17, "person"], [19, 21, "person"], [23, 24, "person"], [26, 27, "person"], [37, 40, "location"], [33, 34, "misc"], [35, 36, "person"], [46, 47, "person"], [43, 45, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12], "relations": [[8, 10, 6, 7, "physical", "", false, false], [37, 40, 1, 1, "general-affiliation", "", false, false], [37, 40, 35, 36, "artifact", "", false, false], [33, 34, 35, 36, "named", "", false, false], [46, 47, 43, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 5, 6, 7, 8], "sentence": ["Contemporary", "automatons", "are", "represented", "in", "the", "UK", "by", "Cabaret", "Mechanical", "Theatre", ",", "in", "the", "US", "by", "Dug", "North", "and", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", ",", "in", "the", "US", "by", "French", "artist", "Jacques", "Monestier's", "Le", "D\u00e9fenseur", "du", "Temps", ",", "and", "in", "Switzerland", "by", "Fran\u00e7ois", "Junod", "."], "sentence-detokenized": "Contemporary automatons are represented in the UK by Cabaret Mechanical Theatre, in the US by Dug North and Chomick + Meder, Arthur Ganson, Joe Jones, in the US by French artist Jacques Monestier's Le D\u00e9fenseur du Temps, and in Switzerland by Fran\u00e7ois Junod.", "token2charspan": [[0, 12], [13, 23], [24, 27], [28, 39], [40, 42], [43, 46], [47, 49], [50, 52], [53, 60], [61, 71], [72, 79], [79, 80], [81, 83], [84, 87], [88, 90], [91, 93], [94, 97], [98, 103], [104, 107], [108, 115], [116, 117], [118, 123], [123, 124], [125, 131], [132, 138], [138, 139], [140, 143], [144, 149], [149, 150], [151, 153], [154, 157], [158, 160], [161, 163], [164, 170], [171, 177], [178, 185], [186, 197], [198, 200], [201, 210], [211, 213], [214, 219], [219, 220], [221, 224], [225, 227], [228, 239], [240, 242], [243, 251], [252, 257], [257, 258]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 21, 21, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "includes", "standard", "codefor", "/", "code", "and", "codewhile", "/", "code", "loops", ",", "but", "(", "as", "in", "other", "similar", "applications", "such", "as", "R", ")", ",", "the", "use", "of", "vectorized", "notation", "is", "recommended", "and", "is", "often", "faster", "to", "implement", "."], "sentence-detokenized": "MATLAB includes standard codefor/code and codewhile/code loops, but (as in other similar applications such as R), the use of vectorized notation is recommended and is often faster to implement.", "token2charspan": [[0, 6], [7, 15], [16, 24], [25, 32], [32, 33], [33, 37], [38, 41], [42, 51], [51, 52], [52, 56], [57, 62], [62, 63], [64, 67], [68, 69], [69, 71], [72, 74], [75, 80], [81, 88], [89, 101], [102, 106], [107, 109], [110, 111], [111, 112], [112, 113], [114, 117], [118, 121], [122, 124], [125, 135], [136, 144], [145, 147], [148, 159], [160, 163], [164, 166], [167, 172], [173, 179], [180, 182], [183, 192], [192, 193]]}
{"doc_key": "ai-test-324", "ner": [[3, 3, "researcher"], [7, 14, "conference"], [16, 19, "field"], [22, 28, "misc"], [31, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 22, 28, "win-defeat", "", false, false], [3, 3, 31, 40, "win-defeat", "", false, false], [22, 28, 7, 14, "temporal", "", false, false], [22, 28, 16, 19, "topic", "", false, false], [31, 40, 7, 14, "temporal", "", false, false], [31, 40, 16, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2007", ",", "Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "for", "his", "achievements", "in", "computer", "science", "education", ":", "the", "Karl", "V", ".", "Karlstrom", "Outstanding", "Educator", "Award", "and", "the", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contributions", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "In 2007, Pausch received two awards from the Association for Computing Machinery for his achievements in computer science education: the Karl V. Karlstrom Outstanding Educator Award and the ACM SIGCSE Award for Outstanding Contributions to Computer Science Education.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 24], [25, 28], [29, 35], [36, 40], [41, 44], [45, 56], [57, 60], [61, 70], [71, 80], [81, 84], [85, 88], [89, 101], [102, 104], [105, 113], [114, 121], [122, 131], [131, 132], [133, 136], [137, 141], [142, 143], [143, 144], [145, 154], [155, 166], [167, 175], [176, 181], [182, 185], [186, 189], [190, 193], [194, 200], [201, 206], [207, 210], [211, 222], [223, 236], [237, 239], [240, 248], [249, 256], [257, 266], [266, 267]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [8, 8, "product"], [9, 12, "product"], [14, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 8, "role", "sells", false, false], [8, 8, 9, 12, "general-affiliation", "", false, false], [8, 8, 14, 16, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 86], [87, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-test-326", "ner": [[0, 1, "algorithm"], [5, 7, "field"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 1, "usage", "", false, false], [11, 12, 5, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantic", "networks", "are", "used", "in", "natural", "language", "processing", "applications", "such", "as", "semantic", "analysis", "."], "sentence-detokenized": "Semantic networks are used in natural language processing applications such as semantic analysis.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 26], [27, 29], [30, 37], [38, 46], [47, 57], [58, 70], [71, 75], [76, 78], [79, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-327", "ner": [[4, 5, "field"], [7, 8, "field"], [10, 11, "task"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 8, 4, 5, "usage", "", false, false], [10, 11, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Some", "successful", "applications", "of", "deep", "learning", "are", "computer", "vision", "and", "speech", "recognition", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Some successful applications of deep learning are computer vision and speech recognition. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 31], [32, 36], [37, 45], [46, 49], [50, 58], [59, 65], [66, 69], [70, 76], [77, 88], [88, 89], [90, 97], [98, 101], [101, 102], [103, 108], [109, 115], [115, 116], [117, 123], [124, 133], [133, 134], [135, 141], [142, 143], [143, 144], [145, 147], [147, 148]]}
{"doc_key": "ai-test-328", "ner": [[4, 12, "product"], [16, 16, "misc"], [19, 22, "misc"], [25, 25, "product"], [29, 30, "task"], [32, 33, "task"], [35, 36, "task"], [38, 40, "field"], [42, 44, "task"], [46, 47, "field"], [49, 50, "task"], [52, 53, "task"], [55, 56, "task"], [58, 58, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 12, 16, 16, "physical", "travels_to", false, false], [4, 12, 19, 22, "physical", "travels_to", false, false], [25, 25, 4, 12, "part-of", "", false, false], [25, 25, 4, 12, "role", "maintains", false, false], [25, 25, 29, 30, "related-to", "has_ability_to", false, false], [25, 25, 32, 33, "related-to", "has_ability_to", false, false], [25, 25, 35, 36, "related-to", "has_ability_to", false, false], [25, 25, 38, 40, "related-to", "has_ability_to", false, false], [25, 25, 42, 44, "related-to", "has_ability_to", false, false], [25, 25, 46, 47, "related-to", "has_ability_to", false, false], [25, 25, 49, 50, "related-to", "has_ability_to", false, false], [25, 25, 52, 53, "related-to", "has_ability_to", false, false], [25, 25, 55, 56, "related-to", "has_ability_to", false, false], [25, 25, 58, 58, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "addition", "to", "maintaining", "the", "systems", "of", "the", "Discovery", "One", "spacecraft", "on", "its", "interplanetary", "mission", "to", "Jupiter", "(", "or", "Saturn", "in", "the", "novel", ")", ",", "HAL", "is", "capable", "of", "speech", "synthesis", ",", "speech", "recognition", ",", "facial", "recognition", ",", "natural", "language", "processing", ",", "lip", "-", "reading", ",", "art", "appreciation", ",", "affective", "computing", ",", "automated", "thinking", ",", "spacecraft", "navigation", "and", "chess", "."], "sentence-detokenized": "In addition to maintaining the systems of the Discovery One spacecraft on its interplanetary mission to Jupiter (or Saturn in the novel), HAL is capable of speech synthesis, speech recognition, facial recognition, natural language processing, lip-reading, art appreciation, affective computing, automated thinking, spacecraft navigation and chess.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 38], [39, 41], [42, 45], [46, 55], [56, 59], [60, 70], [71, 73], [74, 77], [78, 92], [93, 100], [101, 103], [104, 111], [112, 113], [113, 115], [116, 122], [123, 125], [126, 129], [130, 135], [135, 136], [136, 137], [138, 141], [142, 144], [145, 152], [153, 155], [156, 162], [163, 172], [172, 173], [174, 180], [181, 192], [192, 193], [194, 200], [201, 212], [212, 213], [214, 221], [222, 230], [231, 241], [241, 242], [243, 246], [246, 247], [247, 254], [254, 255], [256, 259], [260, 272], [272, 273], [274, 283], [284, 293], [293, 294], [295, 304], [305, 313], [313, 314], [315, 325], [326, 336], [337, 340], [341, 346], [346, 347]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [3, 6, "country"], [7, 8, "country"], [11, 11, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 3, 6, "physical", "", false, false], [0, 1, 7, 8, "physical", "", false, false], [0, 1, 11, 11, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr", "Julesz", "emigrated", "from", "Hungary", "to", "the", "United", "States", "after", "the", "Soviet", "invasion", "of", "1956", "."], "sentence-detokenized": "Dr Julesz emigrated from Hungary to the United States after the Soviet invasion of 1956.", "token2charspan": [[0, 2], [3, 9], [10, 19], [20, 24], [25, 32], [33, 35], [36, 39], [40, 46], [47, 53], [54, 59], [60, 63], [64, 70], [71, 79], [80, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-test-330", "ner": [[0, 2, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "simmoid", "function", "activation", "functions", "use", "a", "second", "nonlinearity", "for", "large", "inputs", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+\\", "exp", "(", "-", "v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "The simmoid function activation functions use a second nonlinearity for large inputs: math\\ phi (v _ i) = (1 +\\ exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 31], [32, 41], [42, 45], [46, 47], [48, 54], [55, 67], [68, 71], [72, 77], [78, 84], [84, 85], [86, 90], [90, 91], [92, 95], [96, 97], [97, 98], [99, 100], [101, 102], [102, 103], [104, 105], [106, 107], [107, 108], [109, 111], [112, 115], [116, 117], [117, 118], [118, 119], [120, 121], [122, 123], [123, 124], [124, 125], [126, 127], [128, 129], [129, 131], [131, 132], [133, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-test-331", "ner": [[12, 14, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "probabilities", "are", "used", "to", "determine", "what", "the", "target", "is", "using", "the", "maximum", "likelihood", "decision", "."], "sentence-detokenized": "These probabilities are used to determine what the target is using the maximum likelihood decision.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 46], [47, 50], [51, 57], [58, 60], [61, 66], [67, 70], [71, 78], [79, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-332", "ner": [[7, 9, "university"], [15, 17, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1984", "he", "was", "admitted", "to", "the", "University", "of", "Konstanz", "and", "in", "1990", "to", "the", "University", "of", "Salzburg", "."], "sentence-detokenized": "In 1984 he was admitted to the University of Konstanz and in 1990 to the University of Salzburg.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 23], [24, 26], [27, 30], [31, 41], [42, 44], [45, 53], [54, 57], [58, 60], [61, 65], [66, 68], [69, 72], [73, 83], [84, 86], [87, 95], [95, 96]]}
{"doc_key": "ai-test-333", "ner": [[7, 8, "metrics"], [10, 12, "metrics"], [14, 16, "metrics"], [18, 18, "metrics"], [20, 21, "metrics"], [23, 25, "metrics"], [28, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 12, 7, 8, "origin", "based_on", false, false], [14, 16, 7, 8, "origin", "based_on", false, false], [18, 18, 7, 8, "origin", "based_on", false, false], [20, 21, 7, 8, "origin", "based_on", false, false], [23, 25, 7, 8, "origin", "based_on", false, false], [28, 31, 7, 8, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Some", "popular", "fitness", "functions", "based", "on", "the", "confusion", "matrix", "include", "sensitivity", "/", "specificity", ",", "recall", "/", "accuracy", ",", "F-measure", ",", "Jaccard", "similarity", ",", "Matthews", "correlation", "coefficient", "and", "the", "cost", "/", "profit", "matrix", ",", "which", "combines", "the", "costs", "and", "profits", "associated", "with", "4", "different", "types", "of", "classification", "."], "sentence-detokenized": "Some popular fitness functions based on the confusion matrix include sensitivity/specificity, recall/accuracy, F-measure, Jaccard similarity, Matthews correlation coefficient and the cost/profit matrix, which combines the costs and profits associated with 4 different types of classification.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 30], [31, 36], [37, 39], [40, 43], [44, 53], [54, 60], [61, 68], [69, 80], [80, 81], [81, 92], [92, 93], [94, 100], [100, 101], [101, 109], [109, 110], [111, 120], [120, 121], [122, 129], [130, 140], [140, 141], [142, 150], [151, 162], [163, 174], [175, 178], [179, 182], [183, 187], [187, 188], [188, 194], [195, 201], [201, 202], [203, 208], [209, 217], [218, 221], [222, 227], [228, 231], [232, 239], [240, 250], [251, 255], [256, 257], [258, 267], [268, 273], [274, 276], [277, 291], [291, 292]]}
{"doc_key": "ai-test-334", "ner": [[7, 7, "product"], [9, 9, "product"], [11, 11, "product"], [13, 13, "product"], [16, 17, "programlang"], [27, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[27, 29, 7, 7, "part-of", "", false, false], [27, 29, 9, 9, "part-of", "", false, false], [27, 29, 11, 11, "part-of", "", false, false], [27, 29, 13, 13, "part-of", "", false, false], [27, 29, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Common", "numerical", "programming", "environments", ",", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "and", "the", "R", "language", ",", "provide", "some", "simpler", "feature", "extraction", "techniques", "(", "e.g.", "principal", "component", "analysis", ")", "using", "built", "-", "in", "commands", "."], "sentence-detokenized": "Common numerical programming environments, such as MATLAB, SciLab, NumPy, Sklearn and the R language, provide some simpler feature extraction techniques (e.g. principal component analysis) using built-in commands.", "token2charspan": [[0, 6], [7, 16], [17, 28], [29, 41], [41, 42], [43, 47], [48, 50], [51, 57], [57, 58], [59, 65], [65, 66], [67, 72], [72, 73], [74, 81], [82, 85], [86, 89], [90, 91], [92, 100], [100, 101], [102, 109], [110, 114], [115, 122], [123, 130], [131, 141], [142, 152], [153, 154], [154, 158], [159, 168], [169, 178], [179, 187], [187, 188], [189, 194], [195, 200], [200, 201], [201, 203], [204, 212], [212, 213]]}
{"doc_key": "ai-test-335", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "have", "been", "introduced", "to", "work", "with", "humans", "to", "perform", "industrial", "manufacturing", "tasks", "."], "sentence-detokenized": "Industrial robots have been introduced to work with humans to perform industrial manufacturing tasks.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 27], [28, 38], [39, 41], [42, 46], [47, 51], [52, 58], [59, 61], [62, 69], [70, 80], [81, 94], [95, 100], [100, 101]]}
{"doc_key": "ai-test-336", "ner": [[5, 6, "field"], [8, 11, "researcher"], [21, 22, "field"], [24, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 21, 22, "related-to", "", false, false], [5, 6, 24, 25, "related-to", "", false, false], [5, 6, 27, 28, "related-to", "", false, false], [8, 11, 5, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "first", "published", "paper", "on", "CGs", ",", "John", "F", ".", "Sowa", "applied", "them", "to", "a", "wide", "range", "of", "topics", "in", "artificial", "intelligence", ",", "computer", "science", "and", "cognitive", "science", "."], "sentence-detokenized": "In his first published paper on CGs, John F. Sowa applied them to a wide range of topics in artificial intelligence, computer science and cognitive science.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [23, 28], [29, 31], [32, 35], [35, 36], [37, 41], [42, 43], [43, 44], [45, 49], [50, 57], [58, 62], [63, 65], [66, 67], [68, 72], [73, 78], [79, 81], [82, 88], [89, 91], [92, 102], [103, 115], [115, 116], [117, 125], [126, 133], [134, 137], [138, 147], [148, 155], [155, 156]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [4, 4, "metrics"], [10, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "in", "the", "calculation", "of", "the", "brevity", "penalty", ",", "as", "small", "variations", "in", "translation", "length", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from BLEU in the calculation of the brevity penalty, as small variations in translation length do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 46], [47, 49], [50, 53], [54, 61], [62, 69], [69, 70], [71, 73], [74, 79], [80, 90], [91, 93], [94, 105], [106, 112], [113, 115], [116, 119], [120, 126], [127, 130], [131, 138], [139, 144], [145, 147], [148, 152], [152, 153]]}
{"doc_key": "ai-test-338", "ner": [[1, 7, "misc"], [13, 13, "conference"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 7, 13, 13, "temporal", "", false, false], [1, 7, 24, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "IJCAI", "Award", "for", "Research", "Excellence", "is", "presented", "every", "two", "years", "at", "the", "IJCAI", "conference", "to", "recognise", "excellence", "in", "the", "careers", "of", "researchers", "in", "artificial", "intelligence", "."], "sentence-detokenized": "The IJCAI Award for Research Excellence is presented every two years at the IJCAI conference to recognise excellence in the careers of researchers in artificial intelligence.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 28], [29, 39], [40, 42], [43, 52], [53, 58], [59, 62], [63, 68], [69, 71], [72, 75], [76, 81], [82, 92], [93, 95], [96, 105], [106, 116], [117, 119], [120, 123], [124, 131], [132, 134], [135, 146], [147, 149], [150, 160], [161, 173], [173, 174]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [6, 6, "conference"], [16, 24, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 6, "role", "", false, false], [0, 0, 16, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "was", "one", "of", "the", "original", "AAAI", "fellows", "and", "is", "the", "only", "person", "to", "have", "served", "on", "the", "Scientific", "Advisory", "Boards", "of", "Microsoft", "and", "Apple", "."], "sentence-detokenized": "Lenat was one of the original AAAI fellows and is the only person to have served on the Scientific Advisory Boards of Microsoft and Apple.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 16], [17, 20], [21, 29], [30, 34], [35, 42], [43, 46], [47, 49], [50, 53], [54, 58], [59, 65], [66, 68], [69, 73], [74, 80], [81, 83], [84, 87], [88, 98], [99, 107], [108, 114], [115, 117], [118, 127], [128, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-test-340", "ner": [[0, 1, "algorithm"], [6, 7, "misc"], [11, 14, "metrics"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 7, "related-to", "minimise", false, false], [11, 14, 6, 7, "type-of", "", false, false], [18, 19, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Automatic", "coders", "are", "trained", "to", "minimise", "reconstruction", "errors", "(", "such", "as", "the", "mean", "squared", "error", ")", ",", "often", "called", "loss", ":"], "sentence-detokenized": "Automatic coders are trained to minimise reconstruction errors (such as the mean squared error), often called loss:", "token2charspan": [[0, 9], [10, 16], [17, 20], [21, 28], [29, 31], [32, 40], [41, 55], [56, 62], [63, 64], [64, 68], [69, 71], [72, 75], [76, 80], [81, 88], [89, 94], [94, 95], [95, 96], [97, 102], [103, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-test-341", "ner": [[26, 28, "misc"], [22, 32, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[22, 32, 26, 28, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "to", "using", "definitions", "is", "to", "take", "into", "account", "the", "general", "word-interpretation", "relatedness", "and", "calculate", "the", "similarity", "of", "each", "word-interpretation", "pair", "based", "on", "a", "given", "lexical", "knowledge", "base", ",", "such", "as", "WordNet", "."], "sentence-detokenized": "An alternative to using definitions is to take into account the general word-interpretation relatedness and calculate the similarity of each word-interpretation pair based on a given lexical knowledge base, such as WordNet.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 23], [24, 35], [36, 38], [39, 41], [42, 46], [47, 51], [52, 59], [60, 63], [64, 71], [72, 91], [92, 103], [104, 107], [108, 117], [118, 121], [122, 132], [133, 135], [136, 140], [141, 160], [161, 165], [166, 171], [172, 174], [175, 176], [177, 182], [183, 190], [191, 200], [201, 205], [205, 206], [207, 211], [212, 214], [215, 222], [222, 223]]}
{"doc_key": "ai-test-342", "ner": [[0, 2, "algorithm"], [9, 11, "researcher"], [15, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 11, "origin", "", false, false], [9, 11, 15, 17, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "invented", "by", "Richard", "S.", "Sutton", ",", "based", "on", "Arthur", "Samuel", "'s", "earlier", "work", "on", "temporal", "difference", "learning", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm invented by Richard S. Sutton, based on Arthur Samuel's earlier work on temporal difference learning.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 42], [43, 45], [46, 53], [54, 56], [57, 63], [63, 64], [65, 70], [71, 73], [74, 80], [81, 87], [87, 89], [90, 97], [98, 102], [103, 105], [106, 114], [115, 125], [126, 134], [134, 135]]}
{"doc_key": "ai-test-343", "ner": [[0, 2, "field"], [4, 4, "field"], [6, 7, "task"], [13, 14, "task"], [12, 19, "task"], [22, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 0, 2, "part-of", "task_part_of_field", false, false], [6, 7, 4, 4, "part-of", "task_part_of_field", false, false], [13, 14, 6, 7, "named", "", false, false], [12, 19, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "data", "mining", "and", "statistics", ",", "hierarchical", "clustering", "(", "also", "known", "as", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "method", "of", "cluster", "analysis", "that", "seeks", "to", "build", "a", "hierarchy", "of", "clusters", "."], "sentence-detokenized": "In data mining and statistics, hierarchical clustering (also known as hierarchical cluster analysis or HCA) is a method of cluster analysis that seeks to build a hierarchy of clusters.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 29], [29, 30], [31, 43], [44, 54], [55, 56], [56, 60], [61, 66], [67, 69], [70, 82], [83, 90], [91, 99], [100, 102], [103, 106], [106, 107], [108, 110], [111, 112], [113, 119], [120, 122], [123, 130], [131, 139], [140, 144], [145, 150], [151, 153], [154, 159], [160, 161], [162, 171], [172, 174], [175, 183], [183, 184]]}
{"doc_key": "ai-test-344", "ner": [[3, 4, "algorithm"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "concept", "of", "deconvolution", "is", "widely", "used", "in", "signal", "processing", "and", "image", "processing", "techniques", "."], "sentence-detokenized": "The concept of deconvolution is widely used in signal processing and image processing techniques.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 53], [54, 64], [65, 68], [69, 74], [75, 85], [86, 96], [96, 97]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [21, 22, "misc"], [26, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 21, 22, "related-to", "enhances", false, false], [0, 1, 21, 22, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "are", "used", "to", "build", "and", "accumulate", "spatial", "knowledge", ",", "allowing", "the", "mind", "'s", "eye", "to", "visualise", "images", "to", "reduce", "cognitive", "load", ",", "enhance", "information", "recall", "and", "learning", "."], "sentence-detokenized": "Cognitive maps are used to build and accumulate spatial knowledge, allowing the mind's eye to visualise images to reduce cognitive load, enhance information recall and learning.", "token2charspan": [[0, 9], [10, 14], [15, 18], [19, 23], [24, 26], [27, 32], [33, 36], [37, 47], [48, 55], [56, 65], [65, 66], [67, 75], [76, 79], [80, 84], [84, 86], [87, 90], [91, 93], [94, 103], [104, 110], [111, 113], [114, 120], [121, 130], [131, 135], [135, 136], [137, 144], [145, 156], [157, 163], [164, 167], [168, 176], [176, 177]]}
{"doc_key": "ai-test-346", "ner": [[6, 6, "programlang"], [8, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "typically", "for", "languages", "such", "as", "Python", ",", "C", "++", ",", "Java", ")", "."], "sentence-detokenized": ", typically for languages such as Python, C++, Java).", "token2charspan": [[0, 1], [2, 11], [12, 15], [16, 25], [26, 30], [31, 33], [34, 40], [40, 41], [42, 43], [43, 45], [45, 46], [47, 51], [51, 52], [52, 53]]}
{"doc_key": "ai-test-347", "ner": [[1, 5, "product"], [16, 19, "task"], [24, 26, "task"], [32, 37, "task"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "voice", "user", "interface", "(", "VUI", ")", "enables", "speech", "-", "based", "human", "interaction", "with", "computers", ",", "using", "speech", "recognition", "to", "understand", "spoken", "commands", "and", "responses", "to", "questions", ",", "typically", "translating", "the", "response", "into", "text", "-", "to", "-", "speech", "."], "sentence-detokenized": "A voice user interface (VUI) enables speech-based human interaction with computers, using speech recognition to understand spoken commands and responses to questions, typically translating the response into text-to-speech.", "token2charspan": [[0, 1], [2, 7], [8, 12], [13, 22], [23, 24], [24, 27], [27, 28], [29, 36], [37, 43], [43, 44], [44, 49], [50, 55], [56, 67], [68, 72], [73, 82], [82, 83], [84, 89], [90, 96], [97, 108], [109, 111], [112, 122], [123, 129], [130, 138], [139, 142], [143, 152], [153, 155], [156, 165], [165, 166], [167, 176], [177, 188], [189, 192], [193, 201], [202, 206], [207, 211], [211, 212], [212, 214], [214, 215], [215, 221], [221, 222]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 6, "misc"], [7, 7, "programlang"], [12, 15, "researcher"], [16, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 6, "general-affiliation", "is_a", false, false], [0, 0, 7, 7, "general-affiliation", "made_with", false, false], [0, 0, 12, 15, "origin", "", false, false], [12, 15, 16, 18, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Jess", "is", "a", "rules", "engine", "for", "the", "Java", "platform", ",", "developed", "by", "Ernest", "Friedman", "-", "Hill", "at", "Sandia", "National", "."], "sentence-detokenized": "Jess is a rules engine for the Java platform, developed by Ernest Friedman-Hill at Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 15], [16, 22], [23, 26], [27, 30], [31, 35], [36, 44], [44, 45], [46, 55], [56, 58], [59, 65], [66, 74], [74, 75], [75, 79], [80, 82], [83, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-349", "ner": [[1, 2, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 16, 16, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "multilayer", "perceptrons", ",", "where", "a", "hidden", "layer", "exists", ",", "more", "sophisticated", "algorithms", ",", "such", "as", "backpropagation", ",", "must", "be", "used", "."], "sentence-detokenized": "For multilayer perceptrons, where a hidden layer exists, more sophisticated algorithms, such as backpropagation, must be used.", "token2charspan": [[0, 3], [4, 14], [15, 26], [26, 27], [28, 33], [34, 35], [36, 42], [43, 48], [49, 55], [55, 56], [57, 61], [62, 75], [76, 86], [86, 87], [88, 92], [93, 95], [96, 111], [111, 112], [113, 117], [118, 120], [121, 125], [125, 126]]}
{"doc_key": "ai-test-350", "ner": [[0, 1, "product"], [3, 6, "product"], [12, 20, "algorithm"], [23, 24, "field"], [27, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 0, 1, "part-of", "", false, false], [3, 6, 12, 20, "usage", "", false, true], [12, 20, 23, 24, "related-to", "performs", false, false], [27, 34, 23, 24, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "Translate", "'s", "neural", "machine", "translation", "system", "uses", "a", "large", "-", "scale", ",", "end", "-", "to", "-", "end", "artificial", "neural", "network", "that", "performs", "deep", "learning", ",", "especially", "with", "networks", "with", "long", "short", "-", "term", "memory", "."], "sentence-detokenized": "Google Translate's neural machine translation system uses a large-scale, end-to-end artificial neural network that performs deep learning, especially with networks with long short-term memory.", "token2charspan": [[0, 6], [7, 16], [16, 18], [19, 25], [26, 33], [34, 45], [46, 52], [53, 57], [58, 59], [60, 65], [65, 66], [66, 71], [71, 72], [73, 76], [76, 77], [77, 79], [79, 80], [80, 83], [84, 94], [95, 101], [102, 109], [110, 114], [115, 123], [124, 128], [129, 137], [137, 138], [139, 149], [150, 154], [155, 163], [164, 168], [169, 173], [174, 179], [179, 180], [180, 184], [185, 191], [191, 192]]}
{"doc_key": "ai-test-351", "ner": [[7, 7, "researcher"], [9, 9, "researcher"], [11, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "1980s", "and", "early", "1990s", ",", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "and", "others", "developed", "different", "methods", "to", "do", "this", "."], "sentence-detokenized": "In the 1980s and early 1990s, Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter and others developed different methods to do this.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 16], [17, 22], [23, 28], [28, 29], [30, 36], [36, 37], [38, 46], [46, 47], [48, 56], [56, 57], [58, 64], [65, 76], [76, 77], [78, 82], [83, 93], [93, 94], [95, 106], [107, 110], [111, 117], [118, 127], [128, 137], [138, 145], [146, 148], [149, 151], [152, 156], [156, 157]]}
{"doc_key": "ai-test-352", "ner": [[1, 1, "organisation"], [2, 3, "organisation"], [7, 8, "organisation"], [11, 12, "task"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 7, 8, "role", "licenses_from", false, false], [2, 3, 1, 1, "named", "", false, false], [16, 16, 1, 1, "origin", "", false, false], [16, 16, 11, 12, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc.", "originally", "licensed", "software", "from", "Nuance", "to", "provide", "speech", "recognition", "capabilities", "for", "its", "Siri", "digital", "assistant", "."], "sentence-detokenized": "| Apple Apple Inc. originally licensed software from Nuance to provide speech recognition capabilities for its Siri digital assistant.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 18], [19, 29], [30, 38], [39, 47], [48, 52], [53, 59], [60, 62], [63, 70], [71, 77], [78, 89], [90, 102], [103, 106], [107, 110], [111, 115], [116, 123], [124, 133], [133, 134]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [5, 7, "misc"], [11, 12, "person"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 7, "role", "releases_movies_in_genre", false, false], [11, 12, 0, 0, "role", "directs_for", false, false], [16, 17, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "has", "also", "released", "several", "3D", "Western", "films", ",", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia has also released several 3D Western films, produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 26], [27, 34], [35, 37], [38, 45], [46, 51], [51, 52], [53, 61], [62, 64], [65, 68], [69, 76], [77, 80], [81, 89], [90, 92], [93, 100], [101, 107], [107, 108]]}
{"doc_key": "ai-test-354", "ner": [[9, 10, "field"], [12, 12, "field"], [14, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "includes", "knowledge", "and", "research", "in", "the", "fields", "of", "information", "technology", ",", "linguistics", "and", "computing", "."], "sentence-detokenized": "It includes knowledge and research in the fields of information technology, linguistics and computing.", "token2charspan": [[0, 2], [3, 11], [12, 21], [22, 25], [26, 34], [35, 37], [38, 41], [42, 48], [49, 51], [52, 63], [64, 74], [74, 75], [76, 87], [88, 91], [92, 101], [101, 102]]}
{"doc_key": "ai-test-355", "ner": [[5, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", "is", "an", "example", "of", "R", "code", ":"], "sentence-detokenized": "Here is an example of R code:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 23], [24, 28], [28, 29]]}
{"doc_key": "ai-test-356", "ner": [[0, 7, "metrics"], [8, 10, "metrics"], [12, 12, "metrics"], [18, 18, "metrics"], [16, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 7, 8, 10, "part-of", "plotted_into", false, false], [0, 7, 18, 18, "part-of", "plotted_into", false, false], [12, 12, 8, 10, "named", "", false, false], [16, 20, 18, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "ROC", "curve", "is", "generated", "by", "plotting", "the", "TRUE", "positive", "rate", "(", "TPR", ")", "and", "the", "FALSE", "positive", "rate", "(", "FPR", ")", "at", "different", "thresholds", "."], "sentence-detokenized": "The ROC curve is generated by plotting the TRUE positive rate (TPR) and the FALSE positive rate (FPR) at different thresholds.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 26], [27, 29], [30, 38], [39, 42], [43, 47], [48, 56], [57, 61], [62, 63], [63, 66], [66, 67], [68, 71], [72, 75], [76, 81], [82, 90], [91, 95], [96, 97], [97, 100], [100, 101], [102, 104], [105, 114], [115, 125], [125, 126]]}
{"doc_key": "ai-test-357", "ner": [[4, 5, "field"], [8, 9, "researcher"], [11, 12, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "related-to", "researches_field", false, false], [11, 12, 4, 5, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Research", "stagnated", "after", "the", "machine", "learning", "research", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", ","], "sentence-detokenized": "Research stagnated after the machine learning research of Marvin Minsky and Seymour Papert (1969),", "token2charspan": [[0, 8], [9, 18], [19, 24], [25, 28], [29, 36], [37, 45], [46, 54], [55, 57], [58, 64], [65, 71], [72, 75], [76, 83], [84, 90], [91, 92], [92, 96], [96, 97], [97, 98]]}
{"doc_key": "ai-test-358", "ner": [[9, 10, "programlang"], [12, 14, "product"], [16, 17, "programlang"], [19, 19, "product"], [21, 21, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "environments", "used", "to", "build", "DAQ", "applications", "include", "Ladder", "Logic", ",", "Visual", "C", "++", ",", "Visual", "Basic", ",", "LabVIEW", "and", "MATLAB", "."], "sentence-detokenized": "Other programming environments used to build DAQ applications include Ladder Logic, Visual C++, Visual Basic, LabVIEW and MATLAB.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 38], [39, 44], [45, 48], [49, 61], [62, 69], [70, 76], [77, 82], [82, 83], [84, 90], [91, 92], [92, 94], [94, 95], [96, 102], [103, 108], [108, 109], [110, 117], [118, 121], [122, 128], [128, 129]]}
{"doc_key": "ai-test-359", "ner": [[11, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "metric", "is", "designed", "to", "address", "some", "of", "the", "problems", "found", "in", "the", "more", "popular", "BLEU", "metric", ",", "and", "to", "produce", "a", "good", "correlation", "with", "human", "judgement", "at", "the", "sentence", "or", "segment", "level", "."], "sentence-detokenized": "The metric is designed to address some of the problems found in the more popular BLEU metric, and to produce a good correlation with human judgement at the sentence or segment level.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 22], [23, 25], [26, 33], [34, 38], [39, 41], [42, 45], [46, 54], [55, 60], [61, 63], [64, 67], [68, 72], [73, 80], [81, 85], [86, 92], [92, 93], [94, 97], [98, 100], [101, 108], [109, 110], [111, 115], [116, 127], [128, 132], [133, 138], [139, 148], [149, 151], [152, 155], [156, 164], [165, 167], [168, 175], [176, 181], [181, 182]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "the", "semantic", "relationships", "between", "successive", "video", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long short-term memory are often used to exploit the semantic relationships between successive video frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [83, 88], [88, 89], [89, 93], [94, 100], [101, 104], [105, 110], [111, 115], [116, 118], [119, 126], [127, 130], [131, 139], [140, 153], [154, 161], [162, 172], [173, 178], [179, 185], [185, 186]]}
{"doc_key": "ai-test-361", "ner": [[3, 7, "product"], [13, 19, "product"], [23, 23, "product"], [39, 39, "product"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[23, 23, 13, 19, "part-of", "", false, false]], "relations_mapping_to_source": [3], "sentence": ["Mass", "-", "produced", "printed", "circuit", "boards", "(", "PCBs", ")", "are", "manufactured", "almost", "exclusively", "by", "pick", "-", "and", "-", "place", "robots", ",", "typically", "using", "SCARA", "manipulators", ",", "which", "pick", "tiny", "electronic", "components", "from", "strips", "or", "trays", "and", "place", "them", "on", "PCBs", "with", "high", "precision", "."], "sentence-detokenized": "Mass-produced printed circuit boards (PCBs) are manufactured almost exclusively by pick-and-place robots, typically using SCARA manipulators, which pick tiny electronic components from strips or trays and place them on PCBs with high precision.", "token2charspan": [[0, 4], [4, 5], [5, 13], [14, 21], [22, 29], [30, 36], [37, 38], [38, 42], [42, 43], [44, 47], [48, 60], [61, 67], [68, 79], [80, 82], [83, 87], [87, 88], [88, 91], [91, 92], [92, 97], [98, 104], [104, 105], [106, 115], [116, 121], [122, 127], [128, 140], [140, 141], [142, 147], [148, 152], [153, 157], [158, 168], [169, 179], [180, 184], [185, 191], [192, 194], [195, 200], [201, 204], [205, 210], [211, 215], [216, 218], [219, 223], [224, 228], [229, 233], [234, 243], [243, 244]]}
{"doc_key": "ai-test-362", "ner": [[0, 6, "field"], [12, 12, "algorithm"], [18, 19, "researcher"], [21, 22, "researcher"], [24, 27, "researcher"], [31, 35, "algorithm"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 12, 0, 6, "part-of", "", false, false], [12, 12, 18, 19, "origin", "", false, false], [12, 12, 21, 22, "origin", "", false, false], [12, 12, 24, 27, "origin", "", false, false], [12, 12, 31, 35, "type-of", "", false, false], [31, 35, 36, 37, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "machine", "learning", ",", "where", "it", "is", "most", "widely", "used", "today", ",", "LDA", "was", "rediscovered", "in", "2003", "by", "David", "Blei", ",", "Andrew", "Ng", "and", "Michael", "I", ".", "Jordan", ",", "and", "presented", "as", "a", "graphical", "model", "of", "topic", "search", "."], "sentence-detokenized": "In machine learning, where it is most widely used today, LDA was rediscovered in 2003 by David Blei, Andrew Ng and Michael I. Jordan, and presented as a graphical model of topic search.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 26], [27, 29], [30, 32], [33, 37], [38, 44], [45, 49], [50, 55], [55, 56], [57, 60], [61, 64], [65, 77], [78, 80], [81, 85], [86, 88], [89, 94], [95, 99], [99, 100], [101, 107], [108, 110], [111, 114], [115, 122], [123, 124], [124, 125], [126, 132], [132, 133], [134, 137], [138, 147], [148, 150], [151, 152], [153, 162], [163, 168], [169, 171], [172, 177], [178, 184], [184, 185]]}
{"doc_key": "ai-test-363", "ner": [[6, 6, "task"], [13, 13, "misc"], [16, 16, "metrics"], [18, 18, "metrics"], [20, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 13, 13, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "performance", "of", "the", "eight", "na\u00efve", "WSIs", "on", "test", "data", "for", "the", "different", "tauopathies", "resulted", "in", "recall", ",", "accuracy", "and", "F1", "scores", "of", "0.92", ",", "0.72", "and", "0.81", ",", "respectively", "."], "sentence-detokenized": "The performance of the eight na\u00efve WSIs on test data for the different tauopathies resulted in recall, accuracy and F1 scores of 0.92, 0.72 and 0.81, respectively.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 22], [23, 28], [29, 34], [35, 39], [40, 42], [43, 47], [48, 52], [53, 56], [57, 60], [61, 70], [71, 82], [83, 91], [92, 94], [95, 101], [101, 102], [103, 111], [112, 115], [116, 118], [119, 125], [126, 128], [129, 133], [133, 134], [135, 139], [140, 143], [144, 148], [148, 149], [150, 162], [162, 163]]}
{"doc_key": "ai-test-364", "ner": [[6, 7, "field"], [15, 16, "task"]], "ner_mapping_to_source": [1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Through", "advanced", "AR", "technologies", "(", "e.g.", "computer", "vision", ",", "AR", "cameras", "embedded", "in", "smartphones", "and", "object", "recognition", ")", ",", "information", "about", "the", "real", "world", "around", "the", "user", "becomes", "interactive", "and", "digitally", "manipulable", "."], "sentence-detokenized": "Through advanced AR technologies (e.g. computer vision, AR cameras embedded in smartphones and object recognition), information about the real world around the user becomes interactive and digitally manipulable.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 32], [33, 34], [34, 38], [39, 47], [48, 54], [54, 55], [56, 58], [59, 66], [67, 75], [76, 78], [79, 90], [91, 94], [95, 101], [102, 113], [113, 114], [114, 115], [116, 127], [128, 133], [134, 137], [138, 142], [143, 148], [149, 155], [156, 159], [160, 164], [165, 172], [173, 184], [185, 188], [189, 198], [199, 210], [210, 211]]}
{"doc_key": "ai-test-365", "ner": [[2, 2, "researcher"], [4, 4, "organisation"], [13, 15, "field"], [24, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 4, 4, "role", "forms_company", false, false], [4, 4, 13, 15, "related-to", "works_with", false, false], [4, 4, 24, 26, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2014", "Schmidhuber", "founded", "Nnaisense", ",", "a", "company", "working", "on", "commercial", "applications", "of", "artificial", "intelligence", "in", "areas", "such", "as", "finance", ",", "heavy", "industry", "and", "self", "-", "driving", "cars", "."], "sentence-detokenized": "In 2014 Schmidhuber founded Nnaisense, a company working on commercial applications of artificial intelligence in areas such as finance, heavy industry and self-driving cars.", "token2charspan": [[0, 2], [3, 7], [8, 19], [20, 27], [28, 37], [37, 38], [39, 40], [41, 48], [49, 56], [57, 59], [60, 70], [71, 83], [84, 86], [87, 97], [98, 110], [111, 113], [114, 119], [120, 124], [125, 127], [128, 135], [135, 136], [137, 142], [143, 151], [152, 155], [156, 160], [160, 161], [161, 168], [169, 173], [173, 174]]}
{"doc_key": "ai-test-366", "ner": [[25, 28, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Not", "only", "will", "this", "change", "the", "performance", "of", "all", "subsequent", "tests", "on", "the", "retained", "explanatory", "model", ",", "it", "may", "also", "introduce", "bias", "and", "change", "the", "mean", "squared", "error", "of", "the", "estimate", "."], "sentence-detokenized": "Not only will this change the performance of all subsequent tests on the retained explanatory model, it may also introduce bias and change the mean squared error of the estimate.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 18], [19, 25], [26, 29], [30, 41], [42, 44], [45, 48], [49, 59], [60, 65], [66, 68], [69, 72], [73, 81], [82, 93], [94, 99], [99, 100], [101, 103], [104, 107], [108, 112], [113, 122], [123, 127], [128, 131], [132, 138], [139, 142], [143, 147], [148, 155], [156, 161], [162, 164], [165, 168], [169, 177], [177, 178]]}
{"doc_key": "ai-test-367", "ner": [[4, 4, "misc"], [10, 10, "algorithm"], [0, 2, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 4, 4, "usage", "", false, false], [10, 10, 0, 2, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "speech", "recognition", ",", "bigrams", "are", "used", "in", "most", "successful", "language", "models", "."], "sentence-detokenized": "For speech recognition, bigrams are used in most successful language models.", "token2charspan": [[0, 3], [4, 10], [11, 22], [22, 23], [24, 31], [32, 35], [36, 40], [41, 43], [44, 48], [49, 59], [60, 68], [69, 75], [75, 76]]}
{"doc_key": "ai-test-368", "ner": [[64, 65, "field"], [7, 9, "misc"], [15, 17, "misc"], [4, 6, "organisation"], [27, 29, "misc"], [23, 26, "organisation"], [35, 39, "misc"], [40, 43, "organisation"], [49, 52, "misc"], [54, 56, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 9, 64, 65, "topic", "", false, false], [15, 17, 4, 6, "origin", "", false, false], [27, 29, 23, 26, "origin", "", false, false], [35, 39, 40, 43, "origin", "", false, false], [49, 52, 54, 56, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["He", "has", "received", "the", "American", "Psychological", "Association", "Early", "Career", "Award", "(", "1984", ")", "and", "the", "Boyd", "McCandless", "Award", "(", "1986", ")", ",", "the", "National", "Academy", "of", "Sciences", "Troland", "Research", "Award", "(", "1993", ")", ",", "the", "Henry", "Dale", "Prize", "of", "the", "Royal", "Institution", "of", "Science", "(", "2004", ")", "and", "the", "George", "Miller", "Prize", "of", "the", "Cognitive", "Neuroscience", "Society", "(", "2010", ")", "for", "his", "research", "in", "cognitive", "psychology", "."], "sentence-detokenized": "He has received the American Psychological Association Early Career Award (1984) and the Boyd McCandless Award (1986), the National Academy of Sciences Troland Research Award (1993), the Henry Dale Prize of the Royal Institution of Science (2004) and the George Miller Prize of the Cognitive Neuroscience Society (2010) for his research in cognitive psychology.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 19], [20, 28], [29, 42], [43, 54], [55, 60], [61, 67], [68, 73], [74, 75], [75, 79], [79, 80], [81, 84], [85, 88], [89, 93], [94, 104], [105, 110], [111, 112], [112, 116], [116, 117], [117, 118], [119, 122], [123, 131], [132, 139], [140, 142], [143, 151], [152, 159], [160, 168], [169, 174], [175, 176], [176, 180], [180, 181], [181, 182], [183, 186], [187, 192], [193, 197], [198, 203], [204, 206], [207, 210], [211, 216], [217, 228], [229, 231], [232, 239], [240, 241], [241, 245], [245, 246], [247, 250], [251, 254], [255, 261], [262, 268], [269, 274], [275, 277], [278, 281], [282, 291], [292, 304], [305, 312], [313, 314], [314, 318], [318, 319], [320, 323], [324, 327], [328, 336], [337, 339], [340, 349], [350, 360], [360, 361]]}
{"doc_key": "ai-test-369", "ner": [[1, 1, "misc"], [7, 7, "misc"], [8, 10, "product"], [14, 14, "researcher"], [16, 16, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"], [28, 30, "task"], [32, 35, "researcher"], [37, 41, "researcher"], [42, 43, "task"], [45, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[1, 1, 7, 7, "named", "", false, false], [1, 1, 45, 45, "named", "", false, false], [7, 7, 14, 14, "origin", "", false, false], [7, 7, 16, 16, "origin", "", false, false], [7, 7, 28, 30, "related-to", "used_for", false, false], [8, 10, 7, 7, "usage", "", false, false], [8, 10, 42, 43, "named", "", false, false], [23, 24, 7, 7, "usage", "", false, false], [23, 24, 32, 35, "named", "same", false, false], [26, 27, 7, 7, "usage", "", false, false], [26, 27, 37, 41, "named", "same", false, false], [42, 43, 45, 45, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["An", "eigenface", "(", "An", "approach", "to", "using", "eigenfaces", "for", "face", "recognition", "was", "developed", "by", "Sirovich", "and", "Kirby", "(", "1987", ")", "and", "used", "by", "Matthew", "Turk", "and", "Alex", "Pentland", "to", "classify", "faces", ".", "Turk", ",", "Matthew", "A", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "An eigenface (An approach to using eigenfaces for face recognition was developed by Sirovich and Kirby (1987) and used by Matthew Turk and Alex Pentland to classify faces. Turk, Matthew A and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 2], [3, 12], [13, 14], [14, 16], [17, 25], [26, 28], [29, 34], [35, 45], [46, 49], [50, 54], [55, 66], [67, 70], [71, 80], [81, 83], [84, 92], [93, 96], [97, 102], [103, 104], [104, 108], [108, 109], [110, 113], [114, 118], [119, 121], [122, 129], [130, 134], [135, 138], [139, 143], [144, 152], [153, 155], [156, 164], [165, 170], [170, 171], [172, 176], [176, 177], [178, 185], [186, 187], [188, 191], [192, 200], [200, 201], [202, 206], [207, 208], [208, 209], [210, 214], [215, 226], [227, 232], [233, 243], [243, 244]]}
{"doc_key": "ai-test-370", "ner": [[6, 10, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Then", "a", "lexical", "dictionary", "such", "as", "Word", "Net", "can", "be", "used", "to", "understand", "the", "context", "."], "sentence-detokenized": "Then a lexical dictionary such as WordNet can be used to understand the context.", "token2charspan": [[0, 4], [5, 6], [7, 14], [15, 25], [26, 30], [31, 33], [34, 38], [38, 41], [42, 45], [46, 48], [49, 53], [54, 56], [57, 67], [68, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-test-371", "ner": [[0, 0, "misc"], [8, 8, "misc"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 8, "part-of", "", false, false], [8, 8, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hyponymy", "is", "the", "most", "commonly", "coded", "relationship", "between", "synsets", "used", "in", "lexical", "databases", "such", "as", "WordNet", "."], "sentence-detokenized": "Hyponymy is the most commonly coded relationship between synsets used in lexical databases such as WordNet.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 20], [21, 29], [30, 35], [36, 48], [49, 56], [57, 64], [65, 69], [70, 72], [73, 80], [81, 90], [91, 95], [96, 98], [99, 106], [106, 107]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [6, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 7, "general-affiliation", "", false, false], [0, 0, 9, 9, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "offers", "open", "source", "libraries", "in", "C", "++", "and", "Java", ",", "but", "many", "customers", "rely", "on", "community", "-", "developed", "libraries", ",", "for", "example", ",", "libraries", "with", "embedded", "capabilities", "for", "(", "array", ")", "data", "retrieval", "from", "DAP", "servers", "."], "sentence-detokenized": "OPeNDAP offers open source libraries in C++ and Java, but many customers rely on community-developed libraries, for example, libraries with embedded capabilities for (array) data retrieval from DAP servers.", "token2charspan": [[0, 7], [8, 14], [15, 19], [20, 26], [27, 36], [37, 39], [40, 41], [41, 43], [44, 47], [48, 52], [52, 53], [54, 57], [58, 62], [63, 72], [73, 77], [78, 80], [81, 90], [90, 91], [91, 100], [101, 110], [110, 111], [112, 115], [116, 123], [123, 124], [125, 134], [135, 139], [140, 148], [149, 161], [162, 165], [166, 167], [167, 172], [172, 173], [174, 178], [179, 188], [189, 193], [194, 197], [198, 205], [205, 206]]}
{"doc_key": "ai-test-373", "ner": [[4, 7, "misc"], [8, 8, "product"], [30, 33, "misc"], [47, 47, "product"], [49, 49, "organisation"], [50, 53, "product"]], "ner_mapping_to_source": [0, 1, 3, 5, 6, 7], "relations": [[30, 33, 8, 8, "part-of", "", false, false], [50, 53, 49, 49, "artifact", "", false, false]], "relations_mapping_to_source": [2, 4], "sentence": ["On", "this", "page", ",", "Samurai", "Damashii", "presented", "the", "Senkousha", "as", "a", "crystallization", "of", "four", "thousand", "years", "of", "China", "'s", "scientific", "knowledge", ",", "commented", "on", "its", "crude", "design", "(", "e.g.", "the", "Chinese", "cannon", "on", "its", "groin", ")", ",", "and", "placed", "it", "s", "image", "between", "images", "from", "the", "Honda", "ASIMO", "and", "Sony", "QRIO", "SDR", "-", "3X", "to", "contrast", "it", "."], "sentence-detokenized": "On this page, Samurai Damashii presented the Senkousha as a crystallization of four thousand years of China's scientific knowledge, commented on its crude design (e.g. the Chinese cannon on its groin), and placed its image between images from the Honda ASIMO and Sony QRIO SDR-3X to contrast it.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 21], [22, 30], [31, 40], [41, 44], [45, 54], [55, 57], [58, 59], [60, 75], [76, 78], [79, 83], [84, 92], [93, 98], [99, 101], [102, 107], [107, 109], [110, 120], [121, 130], [130, 131], [132, 141], [142, 144], [145, 148], [149, 154], [155, 161], [162, 163], [163, 167], [168, 171], [172, 179], [180, 186], [187, 189], [190, 193], [194, 199], [199, 200], [200, 201], [202, 205], [206, 212], [213, 215], [215, 216], [217, 222], [223, 230], [231, 237], [238, 242], [243, 246], [247, 252], [253, 258], [259, 262], [263, 267], [268, 272], [273, 276], [276, 277], [277, 279], [280, 282], [283, 291], [292, 294], [294, 295]]}
{"doc_key": "ai-test-374", "ner": [[9, 10, "algorithm"], [21, 21, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 21, 21, "part-of", "includes_functionality_of", false, false], [9, 10, 23, 23, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "also", "a", "number", "of", "programming", "libraries", "containing", "neural", "network", "functions", "that", "can", "be", "used", "in", "custom", "implementations", "(", "e.g.", "TensorFlow", ",", "Theano", ",", "etc", "."], "sentence-detokenized": "There are also a number of programming libraries containing neural network functions that can be used in custom implementations (e.g. TensorFlow, Theano, etc.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 16], [17, 23], [24, 26], [27, 38], [39, 48], [49, 59], [60, 66], [67, 74], [75, 84], [85, 89], [90, 93], [94, 96], [97, 101], [102, 104], [105, 111], [112, 127], [128, 129], [129, 133], [134, 144], [144, 145], [146, 152], [152, 153], [154, 157], [157, 158]]}
{"doc_key": "ai-test-375", "ner": [[5, 9, "conference"], [11, 11, "organisation"], [13, 19, "conference"], [21, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", "and", "SPIE", "."], "sentence-detokenized": "He is a member of the Association for Computing Machinery, IEEE, American Association for the Advancement of Science, IAPR and SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 33], [34, 37], [38, 47], [48, 57], [57, 58], [59, 63], [63, 64], [65, 73], [74, 85], [86, 89], [90, 93], [94, 105], [106, 108], [109, 116], [116, 117], [118, 122], [123, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-376", "ner": [[0, 1, "organisation"], [5, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 5, 6, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["RET", "'s", "2011", "experiment", "with", "face", "recognition", "cameras", "on", "trams", "ensured", "that", "people", "banned", "from", "city", "trams", "were", "not", "sneaking", "up", "anyway", "."], "sentence-detokenized": "RET's 2011 experiment with face recognition cameras on trams ensured that people banned from city trams were not sneaking up anyway.", "token2charspan": [[0, 3], [3, 5], [6, 10], [11, 21], [22, 26], [27, 31], [32, 43], [44, 51], [52, 54], [55, 60], [61, 68], [69, 73], [74, 80], [81, 87], [88, 92], [93, 97], [98, 103], [104, 108], [109, 112], [113, 121], [122, 124], [125, 131], [131, 132]]}
{"doc_key": "ai-test-377", "ner": [[5, 7, "person"], [13, 14, "person"], [16, 19, "person"], [25, 26, "person"], [28, 29, "person"], [31, 32, "person"], [34, 35, "person"], [37, 38, "person"], [24, 41, "person"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "film", ",", "based", "on", "Cole", "Porter", "'s", "popular", "Broadway", "musical", ",", "starred", "Howard", "Keel", "and", "Kathryn", "Grayson", ",", "the", "MGM", "singing", "duo", ",", "alongside", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "and", "Tommy", "Rall", "."], "sentence-detokenized": "The film, based on Cole Porter's popular Broadway musical, starred Howard Keel and Kathryn Grayson, the MGM singing duo, alongside Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar and Tommy Rall.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 15], [16, 18], [19, 23], [24, 30], [30, 32], [33, 40], [41, 49], [50, 57], [57, 58], [59, 66], [67, 73], [74, 78], [79, 82], [83, 90], [91, 98], [98, 99], [100, 103], [104, 107], [108, 115], [116, 119], [119, 120], [121, 130], [131, 134], [135, 141], [141, 142], [143, 149], [150, 154], [154, 155], [156, 161], [162, 165], [165, 166], [167, 172], [173, 181], [181, 182], [183, 187], [188, 195], [196, 199], [200, 205], [206, 210], [210, 211]]}
{"doc_key": "ai-test-378", "ner": [[19, 23, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "applications", "should", "simplify", "call", "flow", ",", "minimize", "prompts", ",", "eliminate", "unnecessary", "repetition", ",", "and", "allow", "for", "an", "elaborate", "mixed", "-initiative", "dialogue", "system", "that", "allows", "callers", "to", "provide", "more", "information", "in", "a", "single", "sentence", ",", "in", "any", "order", "or", "combination", "."], "sentence-detokenized": "Such applications should simplify call flow, minimize prompts, eliminate unnecessary repetition, and allow for an elaborate mixed-initiative dialogue system that allows callers to provide more information in a single sentence, in any order or combination.", "token2charspan": [[0, 4], [5, 17], [18, 24], [25, 33], [34, 38], [39, 43], [43, 44], [45, 53], [54, 61], [61, 62], [63, 72], [73, 84], [85, 95], [95, 96], [97, 100], [101, 106], [107, 110], [111, 113], [114, 123], [124, 129], [129, 140], [141, 149], [150, 156], [157, 161], [162, 168], [169, 176], [177, 179], [180, 187], [188, 192], [193, 204], [205, 207], [208, 209], [210, 216], [217, 225], [225, 226], [227, 229], [230, 233], [234, 239], [240, 242], [243, 254], [254, 255]]}
{"doc_key": "ai-test-379", "ner": [[3, 4, "algorithm"], [7, 9, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 3, 4, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Thus", ",", "traditional", "gradient", "descent", "(", "or", "stochastic", "gradient", "descent", ")", "methods", "can", "be", "adapted", ",", "where", "instead", "of", "stepping", "in", "the", "direction", "of", "the", "gradient", "of", "the", "function", ",", "a", "step", "is", "taken", "in", "the", "direction", "of", "the", "vector", "chosen", "from", "the", "subgradient", "of", "the", "function", "."], "sentence-detokenized": "Thus, traditional gradient descent (or stochastic gradient descent) methods can be adapted, where instead of stepping in the direction of the gradient of the function, a step is taken in the direction of the vector chosen from the subgradient of the function.", "token2charspan": [[0, 4], [4, 5], [6, 17], [18, 26], [27, 34], [35, 36], [36, 38], [39, 49], [50, 58], [59, 66], [66, 67], [68, 75], [76, 79], [80, 82], [83, 90], [90, 91], [92, 97], [98, 105], [106, 108], [109, 117], [118, 120], [121, 124], [125, 134], [135, 137], [138, 141], [142, 150], [151, 153], [154, 157], [158, 166], [166, 167], [168, 169], [170, 174], [175, 177], [178, 183], [184, 186], [187, 190], [191, 200], [201, 203], [204, 207], [208, 214], [215, 221], [222, 226], [227, 230], [231, 242], [243, 245], [246, 249], [250, 258], [258, 259]]}
{"doc_key": "ai-test-380", "ner": [[8, 12, "metrics"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "we", "assume", "that", "the", "bias", "is", "measured", "by", "the", "mean", "squared", "error", ",", "then", "the", "bias", "D", "is", "given", "by", ":"], "sentence-detokenized": "If we assume that the bias is measured by the mean squared error, then the bias D is given by:", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 17], [18, 21], [22, 26], [27, 29], [30, 38], [39, 41], [42, 45], [46, 50], [51, 58], [59, 64], [64, 65], [66, 70], [71, 74], [75, 79], [80, 81], [82, 84], [85, 90], [91, 93], [93, 94]]}
{"doc_key": "ai-test-381", "ner": [[0, 0, "algorithm"], [4, 5, "field"], [20, 21, "task"], [23, 24, "task"], [26, 26, "task"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 5, "part-of", "", false, false], [20, 21, 0, 0, "part-of", "", false, false], [23, 24, 0, 0, "part-of", "", false, false], [26, 26, 0, 0, "part-of", "", false, false], [30, 31, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["MLPs", "were", "a", "popular", "machine", "learning", "solution", "in", "the", "1980s", ",", "and", "found", "applications", "in", "many", "areas", ",", "such", "as", "speech", "recognition", ",", "image", "recognition", "and", "machine", "translation", "software", ",", "neural", "networks", "."], "sentence-detokenized": "MLPs were a popular machine learning solution in the 1980s, and found applications in many areas, such as speech recognition, image recognition and machine translation software, neural networks.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 19], [20, 27], [28, 36], [37, 45], [46, 48], [49, 52], [53, 58], [58, 59], [60, 63], [64, 69], [70, 82], [83, 85], [86, 90], [91, 96], [96, 97], [98, 102], [103, 105], [106, 112], [113, 124], [124, 125], [126, 131], [132, 143], [144, 147], [148, 155], [156, 167], [168, 176], [176, 177], [178, 184], [185, 193], [193, 194]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [1, 4, "misc"], [6, 9, "university"], [16, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 9, "physical", "", false, false], [0, 0, 6, 9, "role", "", false, false], [1, 4, 0, 0, "origin", "", false, false], [16, 18, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "received", "his", "PhD", "from", "the", "University", "of", "Toronto", "in", "1979", ",", "under", "the", "supervision", "of", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen received his PhD from the University of Toronto in 1979, under the supervision of C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 22], [23, 27], [28, 31], [32, 42], [43, 45], [46, 53], [54, 56], [57, 61], [61, 62], [63, 68], [69, 72], [73, 84], [85, 87], [88, 90], [91, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [5, 7, "field"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [19, 19, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 7, "related-to", "supports", false, false], [10, 10, 5, 7, "type-of", "", true, false], [12, 12, 5, 7, "type-of", "", true, false], [14, 14, 5, 7, "type-of", "", true, false], [14, 14, 19, 19, "related-to", "converting_to", true, false], [22, 22, 5, 7, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["OpenCV", "supports", "certain", "models", "of", "deep", "learning", "frameworks", "such", "as", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "after", "conversion", "to", "ONNX", ")", "and", "Caffe", "according", "to", "a", "defined", "list", "of", "supported", "layers", "."], "sentence-detokenized": "OpenCV supports certain models of deep learning frameworks such as TensorFlow, Torch, PyTorch (after conversion to ONNX) and Caffe according to a defined list of supported layers.", "token2charspan": [[0, 6], [7, 15], [16, 23], [24, 30], [31, 33], [34, 38], [39, 47], [48, 58], [59, 63], [64, 66], [67, 77], [77, 78], [79, 84], [84, 85], [86, 93], [94, 95], [95, 100], [101, 111], [112, 114], [115, 119], [119, 120], [121, 124], [125, 130], [131, 140], [141, 143], [144, 145], [146, 153], [154, 158], [159, 161], [162, 171], [172, 178], [178, 179]]}
{"doc_key": "ai-test-384", "ner": [[2, 2, "researcher"], [10, 12, "organisation"], [9, 14, "organisation"], [24, 28, "organisation"], [21, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 10, 12, "role", "", false, false], [2, 2, 24, 28, "role", "", false, false], [2, 2, 21, 21, "related-to", "lectures_in", false, false], [9, 14, 10, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Previously", ",", "Christensen", "was", "the", "founding", "President", "of", "the", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "and", "a", "Distinguished", "Lecturer", "in", "Robotics", "at", "the", "IEEE", "Robotics", "and", "Automation", "Society", "."], "sentence-detokenized": "Previously, Christensen was the founding President of the European Robotics Research Network (EURON) and a Distinguished Lecturer in Robotics at the IEEE Robotics and Automation Society.", "token2charspan": [[0, 10], [10, 11], [12, 23], [24, 27], [28, 31], [32, 40], [41, 50], [51, 53], [54, 57], [58, 66], [67, 75], [76, 84], [85, 92], [93, 94], [94, 99], [99, 100], [101, 104], [105, 106], [107, 120], [121, 129], [130, 132], [133, 141], [142, 144], [145, 148], [149, 153], [154, 162], [163, 166], [167, 177], [178, 185], [185, 186]]}
{"doc_key": "ai-test-385", "ner": [[6, 8, "field"], [11, 13, "university"], [15, 15, "location"], [17, 20, "country"], [23, 25, "misc"], [26, 27, "field"], [31, 35, "organisation"], [36, 36, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 13, 15, 15, "physical", "", false, false], [15, 15, 17, 20, "physical", "", false, false], [23, 25, 26, 27, "topic", "", false, false], [31, 35, 36, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "obtained", "a", "Master", "'s", "degree", "in", "mathematics", "in", "1958", "from", "Samarkand", "State", "University", "(", "Samarkand", ",", "Uzbek", "Soviet", "Socialist", "Republic", ")", "and", "a", "PhD", "in", "statistics", "in", "1964", "from", "the", "Institute", "of", "Control", "Sciences", "in", "Moscow", "."], "sentence-detokenized": "He obtained a Master's degree in mathematics in 1958 from Samarkand State University (Samarkand, Uzbek Soviet Socialist Republic) and a PhD in statistics in 1964 from the Institute of Control Sciences in Moscow.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 20], [20, 22], [23, 29], [30, 32], [33, 44], [45, 47], [48, 52], [53, 57], [58, 67], [68, 73], [74, 84], [85, 86], [86, 95], [95, 96], [97, 102], [103, 109], [110, 119], [120, 128], [128, 129], [130, 133], [134, 135], [136, 139], [140, 142], [143, 153], [154, 156], [157, 161], [162, 166], [167, 170], [171, 180], [181, 183], [184, 191], [192, 200], [201, 203], [204, 210], [210, 211]]}
{"doc_key": "ai-test-386", "ner": [[4, 7, "organisation"], [11, 15, "product"], [33, 34, "field"], [36, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 7, 33, 34, "usage", "", false, false], [4, 7, 36, 38, "usage", "", false, false], [11, 15, 4, 7, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "the", "work", "at", "Cycorp", "is", "increasingly", "focused", "on", "the", "Cyc", "system", "'s", "ability", "to", "communicate", "with", "end", "users", "in", "natural", "language", ",", "and", "to", "support", "the", "continuous", "knowledge", "acquisition", "process", "through", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "However, the work at Cycorp is increasingly focused on the Cyc system's ability to communicate with end users in natural language, and to support the continuous knowledge acquisition process through machine learning and natural language understanding.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 30], [31, 43], [44, 51], [52, 54], [55, 58], [59, 62], [63, 69], [69, 71], [72, 79], [80, 82], [83, 94], [95, 99], [100, 103], [104, 109], [110, 112], [113, 120], [121, 129], [129, 130], [131, 134], [135, 137], [138, 145], [146, 149], [150, 160], [161, 170], [171, 182], [183, 190], [191, 198], [199, 206], [207, 215], [216, 219], [220, 227], [228, 236], [237, 250], [250, 251]]}
{"doc_key": "ai-test-387", "ner": [[52, 52, "metrics"], [54, 54, "metrics"], [56, 56, "metrics"], [58, 60, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "if", "we", "are", "looking", "for", "the", "most", "appropriate", "classifier", "for", "the", "problem", ",", "we", "use", "the", "training", "dataset", "to", "train", "the", "candidate", "algorithms", ",", "the", "validation", "dataset", "to", "compare", "their", "performance", "and", "decide", "which", "one", "to", "choose", ",", "and", "finally", "the", "test", "dataset", "to", "determine", "performance", "characteristics", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", ",", "F", "-", "score", ",", "etc", "."], "sentence-detokenized": "For example, if we are looking for the most appropriate classifier for the problem, we use the training dataset to train the candidate algorithms, the validation dataset to compare their performance and decide which one to choose, and finally the test dataset to determine performance characteristics such as accuracy, sensitivity, specificity, F-score, etc.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 18], [19, 22], [23, 30], [31, 34], [35, 38], [39, 43], [44, 55], [56, 66], [67, 70], [71, 74], [75, 82], [82, 83], [84, 86], [87, 90], [91, 94], [95, 103], [104, 111], [112, 114], [115, 120], [121, 124], [125, 134], [135, 145], [145, 146], [147, 150], [151, 161], [162, 169], [170, 172], [173, 180], [181, 186], [187, 198], [199, 202], [203, 209], [210, 215], [216, 219], [220, 222], [223, 229], [229, 230], [231, 234], [235, 242], [243, 246], [247, 251], [252, 259], [260, 262], [263, 272], [273, 284], [285, 300], [301, 305], [306, 308], [309, 317], [317, 318], [319, 330], [330, 331], [332, 343], [343, 344], [345, 346], [346, 347], [347, 352], [352, 353], [354, 357], [357, 358]]}
{"doc_key": "ai-test-388", "ner": [[1, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "squared", "error", "is", "0.15", "."], "sentence-detokenized": "The mean squared error is 0.15.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 25], [26, 30], [30, 31]]}
{"doc_key": "ai-test-389", "ner": [[7, 8, "misc"], [4, 4, "organisation"], [14, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 7, 8, "role", "", false, false], [14, 14, 7, 8, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1979", ",", "the", "IEEE", "organised", "a", "Micromouse", "competition", ",", "which", "was", "featured", "in", "Spectrum", "magazine", "."], "sentence-detokenized": "In 1979, the IEEE organised a Micromouse competition, which was featured in Spectrum magazine.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 27], [28, 29], [30, 40], [41, 52], [52, 53], [54, 59], [60, 63], [64, 72], [73, 75], [76, 84], [85, 93], [93, 94]]}
{"doc_key": "ai-test-390", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [11, 13, "task"], [15, 16, "task"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 7, "part-of", "", false, false], [11, 13, 6, 7, "part-of", "task_part_of_field", false, false], [15, 16, 6, 7, "part-of", "task_part_of_field", false, false], [18, 19, 6, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Gabor", "space", "is", "very", "useful", "in", "image", "processing", "applications", "such", "as", "optical", "character", "recognition", ",", "iris", "recognition", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "Gabor space is very useful in image processing applications such as optical character recognition, iris recognition and fingerprint recognition.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 19], [20, 26], [27, 29], [30, 35], [36, 46], [47, 59], [60, 64], [65, 67], [68, 75], [76, 85], [86, 97], [97, 98], [99, 103], [104, 115], [116, 119], [120, 131], [132, 143], [143, 144]]}
{"doc_key": "ai-test-391", "ner": [[7, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "through", "high", "-", "level", "interfaces", "in", "Java", "and", "Tcl", "."], "sentence-detokenized": "or through high-level interfaces in Java and Tcl.", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [16, 21], [22, 32], [33, 35], [36, 40], [41, 44], [45, 48], [48, 49]]}
{"doc_key": "ai-test-392", "ner": [[12, 14, "algorithm"], [22, 22, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 14, 22, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Recent", "research", "has", "shown", "that", "kernel", "-", "based", "methods", ",", "such", "as", "support", "vector", "machines", ",", "have", "shown", "excellent", "performance", "in", "a", "supervised", "system", "."], "sentence-detokenized": "Recent research has shown that kernel-based methods, such as support vector machines, have shown excellent performance in a supervised system.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 25], [26, 30], [31, 37], [37, 38], [38, 43], [44, 51], [51, 52], [53, 57], [58, 60], [61, 68], [69, 75], [76, 84], [84, 85], [86, 90], [91, 96], [97, 106], [107, 118], [119, 121], [122, 123], [124, 134], [135, 141], [141, 142]]}
{"doc_key": "ai-test-393", "ner": [[14, 14, "misc"], [23, 23, "researcher"], [25, 25, "researcher"], [31, 32, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 31, 32, "usage", "", false, false], [25, 25, 31, 32, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "illustrate", "the", "basic", "principles", "of", "bagging", ",", "an", "analysis", "of", "the", "relationship", "between", "ozone", "and", "temperature", "is", "presented", "below", "(", "data", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "analysis", "in", "R", ")", "."], "sentence-detokenized": "To illustrate the basic principles of bagging, an analysis of the relationship between ozone and temperature is presented below (data from Rousseeuw and Leroy (1986), analysis in R).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 34], [35, 37], [38, 45], [45, 46], [47, 49], [50, 58], [59, 61], [62, 65], [66, 78], [79, 86], [87, 92], [93, 96], [97, 108], [109, 111], [112, 121], [122, 127], [128, 129], [129, 133], [134, 138], [139, 148], [149, 152], [153, 158], [159, 160], [160, 164], [164, 165], [165, 166], [167, 175], [176, 178], [179, 180], [180, 181], [181, 182]]}
{"doc_key": "ai-test-394", "ner": [[0, 2, "organisation"], [16, 17, "product"], [19, 21, "product"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[16, 17, 0, 2, "artifact", "", false, false], [19, 21, 0, 2, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["The", "Denso", "Wave", "subsidiary", "produces", "automatic", "identification", "products", "(", "barcode", "readers", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "The Denso Wave subsidiary produces automatic identification products (barcode readers and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 25], [26, 34], [35, 44], [45, 59], [60, 68], [69, 70], [70, 77], [78, 85], [86, 89], [90, 97], [98, 106], [106, 107], [107, 108], [109, 119], [120, 126], [127, 130], [131, 143], [144, 149], [150, 161], [161, 162]]}
{"doc_key": "ai-test-395", "ner": [[1, 4, "metrics"], [7, 9, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 4, 20, 20, "compare", "", false, false], [7, 9, 1, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "the", "Bilingual", "evaluation", "understudy", "simply", "calculates", "the", "accuracy", "of", "then", "-", "grams", ",", "giving", "equal", "weight", "to", "each", ",", "NIST", "also", "calculates", "how", "informative", "a", "givenn", "-", "gram", "is", "."], "sentence-detokenized": "While the Bilingual evaluation understudy simply calculates the accuracy of then-grams, giving equal weight to each, NIST also calculates how informative a givenn-gram is.", "token2charspan": [[0, 5], [6, 9], [10, 19], [20, 30], [31, 41], [42, 48], [49, 59], [60, 63], [64, 72], [73, 75], [76, 80], [80, 81], [81, 86], [86, 87], [88, 94], [95, 100], [101, 107], [108, 110], [111, 115], [115, 116], [117, 121], [122, 126], [127, 137], [138, 141], [142, 153], [154, 155], [156, 162], [162, 163], [163, 167], [168, 170], [170, 171]]}
{"doc_key": "ai-test-396", "ner": [[14, 14, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "particular", ",", "they", "are", "used", "in", "the", "calculation", "of", "tree", "likelihoods", "(", "in", "Bayesian", "and", "maximum", "likelihood", "tree", "estimation", "approaches", ")", "and", "to", "estimate", "the", "evolutionary", "distance", "between", "sequences", "from", "the", "observed", "differences", "between", "sequences", "."], "sentence-detokenized": "In particular, they are used in the calculation of tree likelihoods (in Bayesian and maximum likelihood tree estimation approaches) and to estimate the evolutionary distance between sequences from the observed differences between sequences.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 19], [20, 23], [24, 28], [29, 31], [32, 35], [36, 47], [48, 50], [51, 55], [56, 67], [68, 69], [69, 71], [72, 80], [81, 84], [85, 92], [93, 103], [104, 108], [109, 119], [120, 130], [130, 131], [132, 135], [136, 138], [139, 147], [148, 151], [152, 164], [165, 173], [174, 181], [182, 191], [192, 196], [197, 200], [201, 209], [210, 221], [222, 229], [230, 239], [239, 240]]}
{"doc_key": "ai-test-397", "ner": [[1, 3, "conference"], [20, 21, "misc"], [23, 23, "misc"], [46, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Audio", "Engineering", "Society", "recommends", "a", "sampling", "rate", "of", "48", "kHz", "for", "most", "applications", ",", "but", "recognizes", "44.1", "kHz", "for", "Compact", "Disc", "(", "CD", ")", "and", "other", "consumer", "applications", ",", "32", "kHz", "for", "transmission", "-", "related", "applications", ",", "and", "96", "kHz", "for", "higher", "bandwidth", "or", "looser", "anti-aliasing", "filters", "."], "sentence-detokenized": "The Audio Engineering Society recommends a sampling rate of 48 kHz for most applications, but recognizes 44.1 kHz for Compact Disc (CD) and other consumer applications, 32 kHz for transmission-related applications, and 96 kHz for higher bandwidth or looser anti-aliasing filters.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 40], [41, 42], [43, 51], [52, 56], [57, 59], [60, 62], [63, 66], [67, 70], [71, 75], [76, 88], [88, 89], [90, 93], [94, 104], [105, 109], [110, 113], [114, 117], [118, 125], [126, 130], [131, 132], [132, 134], [134, 135], [136, 139], [140, 145], [146, 154], [155, 167], [167, 168], [169, 171], [172, 175], [176, 179], [180, 192], [192, 193], [193, 200], [201, 213], [213, 214], [215, 218], [219, 221], [222, 225], [226, 229], [230, 236], [237, 246], [247, 249], [250, 256], [257, 270], [271, 278], [278, 279]]}
{"doc_key": "ai-test-398", "ner": [[9, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Resources", "on", "the", "affectivity", "of", "words", "and", "concepts", "in", "WordNet", "{", "{", "cite", "journal"], "sentence-detokenized": "Resources on the affectivity of words and concepts in WordNet {{cite journal", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 28], [29, 31], [32, 37], [38, 41], [42, 50], [51, 53], [54, 61], [62, 63], [63, 64], [64, 68], [69, 76]]}
{"doc_key": "ai-test-399", "ner": [[0, 7, "misc"], [25, 26, "person"], [31, 34, "person"], [39, 41, "person"], [44, 47, "organisation"], [67, 69, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[31, 34, 39, 41, "role", "acts_in", false, false], [44, 47, 39, 41, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "a", "red", "and", "green", "anaglyph", ",", "the", "audience", "was", "treated", "to", "three", "reels", "of", "test", "footage", ",", "including", "rural", "scenes", ",", "test", "footage", "of", "Marie", "Doro", ",", "an", "excerpt", "of", "John", "B", ".", "Mason", "performing", "some", "scenes", "from", "Jim", "the", "Penman", "(", "a", "Famous", "Players", "-", "Lasky", "film", "released", "that", "year", ",", "but", "not", "in", "3D", ")", ",", "oriental", "dancers", ",", "and", "a", "reel", "of", "footage", "of", "Niagara", "Falls", "."], "sentence-detokenized": "In a red and green anaglyph, the audience was treated to three reels of test footage, including rural scenes, test footage of Marie Doro, an excerpt of John B. Mason performing some scenes from Jim the Penman (a Famous Players-Lasky film released that year, but not in 3D), oriental dancers, and a reel of footage of Niagara Falls.", "token2charspan": [[0, 2], [3, 4], [5, 8], [9, 12], [13, 18], [19, 27], [27, 28], [29, 32], [33, 41], [42, 45], [46, 53], [54, 56], [57, 62], [63, 68], [69, 71], [72, 76], [77, 84], [84, 85], [86, 95], [96, 101], [102, 108], [108, 109], [110, 114], [115, 122], [123, 125], [126, 131], [132, 136], [136, 137], [138, 140], [141, 148], [149, 151], [152, 156], [157, 158], [158, 159], [160, 165], [166, 176], [177, 181], [182, 188], [189, 193], [194, 197], [198, 201], [202, 208], [209, 210], [210, 211], [212, 218], [219, 226], [226, 227], [227, 232], [233, 237], [238, 246], [247, 251], [252, 256], [256, 257], [258, 261], [262, 265], [266, 268], [269, 271], [271, 272], [272, 273], [274, 282], [283, 290], [290, 291], [292, 295], [296, 297], [298, 302], [303, 305], [306, 313], [314, 316], [317, 324], [325, 330], [330, 331]]}
{"doc_key": "ai-test-400", "ner": [[7, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "specific", "way", "of", "implementing", "maximum", "likelihood", "estimation", "for", "this", "problem", "."], "sentence-detokenized": "This is a specific way of implementing maximum likelihood estimation for this problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 18], [19, 22], [23, 25], [26, 38], [39, 46], [47, 57], [58, 68], [69, 72], [73, 77], [78, 85], [85, 86]]}
{"doc_key": "ai-test-401", "ner": [[5, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "integrates", "the", "functionality", "of", "crawler", "web", "servers", ",", "sitemaps", "and", "RSS", "feeds", "into", "a", "decentralised", "mechanism", "that", "allows", "computational", "biologists", "and", "bioinformaticians", "to", "openly", "publish", "and", "retrieve", "metadata", "on", "biomedical", "resources", "."], "sentence-detokenized": "It integrates the functionality of crawler web servers, sitemaps and RSS feeds into a decentralised mechanism that allows computational biologists and bioinformaticians to openly publish and retrieve metadata on biomedical resources.", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 31], [32, 34], [35, 42], [43, 46], [47, 54], [54, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 83], [84, 85], [86, 99], [100, 109], [110, 114], [115, 121], [122, 135], [136, 146], [147, 150], [151, 168], [169, 171], [172, 178], [179, 186], [187, 190], [191, 199], [200, 208], [209, 211], [212, 222], [223, 232], [232, 233]]}
{"doc_key": "ai-test-402", "ner": [[0, 8, "misc"], [10, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "American", "National", "Institute", "of", "Standards", "/", "NISO", "Z39.50", "and", "International", "Standard", "23950", "apply", "."], "sentence-detokenized": "The American National Institute of Standards / NISO Z39.50 and International Standard 23950 apply.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 31], [32, 34], [35, 44], [45, 46], [47, 51], [52, 58], [59, 62], [63, 76], [77, 85], [86, 91], [92, 97], [97, 98]]}
{"doc_key": "ai-test-403", "ner": [[13, 17, "misc"], [23, 23, "metrics"], [26, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "encoder", "and", "decoder", "are", "trained", "to", "take", "a", "sentence", "and", "reproduce", "the", "one", "-", "hot", "distribution", "of", "the", "corresponding", "paraphrase", "by", "minimizing", "perplexity", "using", "simple", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The encoder and decoder are trained to take a sentence and reproduce the one-hot distribution of the corresponding paraphrase by minimizing perplexity using simple stochastic gradient descent.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 45], [46, 54], [55, 58], [59, 68], [69, 72], [73, 76], [76, 77], [77, 80], [81, 93], [94, 96], [97, 100], [101, 114], [115, 125], [126, 128], [129, 139], [140, 150], [151, 156], [157, 163], [164, 174], [175, 183], [184, 191], [191, 192]]}
{"doc_key": "ai-test-404", "ner": [[4, 5, "field"], [8, 10, "task"], [12, 17, "task"], [28, 33, "task"], [35, 41, "task"], [44, 50, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 10, 4, 5, "part-of", "task_part_of_field", false, false], [12, 17, 4, 5, "part-of", "task_part_of_field", false, false], [28, 33, 4, 5, "part-of", "task_part_of_field", false, false], [35, 41, 4, 5, "part-of", "task_part_of_field", false, false], [44, 50, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "typical", "applications", "of", "pattern", "recognition", "techniques", "include", "automatic", "speech", "recognition", ",", "classification", "of", "texts", "into", "multiple", "categories", "(", "e.g.", "spam", "/", "not", "spam", "email", "messages", ")", ",", "recognition", "of", "handwriting", "on", "postal", "envelopes", ",", "automatic", "recognition", "of", "images", "of", "human", "faces", ",", "or", "extraction", "of", "handwriting", "images", "from", "medical", "forms", "."], "sentence-detokenized": "Other typical applications of pattern recognition techniques include automatic speech recognition, classification of texts into multiple categories (e.g. spam/not spam email messages), recognition of handwriting on postal envelopes, automatic recognition of images of human faces, or extraction of handwriting images from medical forms.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 29], [30, 37], [38, 49], [50, 60], [61, 68], [69, 78], [79, 85], [86, 97], [97, 98], [99, 113], [114, 116], [117, 122], [123, 127], [128, 136], [137, 147], [148, 149], [149, 153], [154, 158], [158, 159], [159, 162], [163, 167], [168, 173], [174, 182], [182, 183], [183, 184], [185, 196], [197, 199], [200, 211], [212, 214], [215, 221], [222, 231], [231, 232], [233, 242], [243, 254], [255, 257], [258, 264], [265, 267], [268, 273], [274, 279], [279, 280], [281, 283], [284, 294], [295, 297], [298, 309], [310, 316], [317, 321], [322, 329], [330, 335], [335, 336]]}
{"doc_key": "ai-test-405", "ner": [[0, 3, "algorithm"], [14, 15, "field"], [17, 18, "task"], [20, 21, "task"], [23, 25, "task"], [27, 31, "task"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 15, 0, 3, "usage", "", false, false], [17, 18, 0, 3, "usage", "", false, false], [20, 21, 0, 3, "usage", "", false, false], [23, 25, 0, 3, "usage", "", false, false], [27, 31, 0, 3, "usage", "", false, false], [33, 34, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Artificial", "neural", "networks", "have", "been", "used", "for", "a", "wide", "range", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "social", "and", "video", "game", "playback", "and", "medical", "diagnostics", "."], "sentence-detokenized": "Artificial neural networks have been used for a wide range of tasks, including computer vision, speech recognition, machine translation, social network filtering, social and video game playback and medical diagnostics.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 36], [37, 41], [42, 45], [46, 47], [48, 52], [53, 58], [59, 61], [62, 67], [67, 68], [69, 78], [79, 87], [88, 94], [94, 95], [96, 102], [103, 114], [114, 115], [116, 123], [124, 135], [135, 136], [137, 143], [144, 151], [152, 161], [161, 162], [163, 169], [170, 173], [174, 179], [180, 184], [185, 193], [194, 197], [198, 205], [206, 217], [217, 218]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [11, 11, "product"], [18, 18, "organisation"], [19, 20, "product"], [22, 22, "product"], [24, 26, "product"], [28, 28, "product"], [30, 30, "programlang"], [37, 39, "field"], [45, 45, "product"], [49, 49, "algorithm"], [51, 51, "algorithm"], [53, 53, "algorithm"], [56, 56, "product"], [62, 63, "task"], [68, 69, "algorithm"], [73, 73, "product"], [75, 75, "product"], [77, 79, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [4, 4, 11, 11, "named", "same", false, false], [4, 4, 45, 45, "named", "same", false, false], [30, 30, 37, 39, "related-to", "used_for", false, false], [49, 49, 30, 30, "part-of", "", true, false], [49, 49, 45, 45, "origin", "", true, false], [51, 51, 30, 30, "part-of", "", true, false], [51, 51, 45, 45, "origin", "", true, false], [53, 53, 30, 30, "part-of", "", true, false], [53, 53, 45, 45, "origin", "", true, false], [56, 56, 62, 63, "related-to", "used_for", false, false], [68, 69, 56, 56, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Examples", "include", "Salford", "Systems", "CART", "(", "which", "has", "licensed", "the", "original", "CART", "authors", "'", "own", "code", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "source", "software", "framework", "for", "statistical", "computing", ")", ",", "which", "includes", "several", "CART", "implementations", "such", "as", "rpart", ",", "party", "and", "randomForest", ")", ",", "Weka", "(", "free", "and", "open", "source", "data", "mining", "package", ",", "including", "several", "decision", "tree", "algorithms", ")", ",", "Orange", ",", "KNIME", ",", "Microsoft", "SQL", "Server", "programming", "language", ")", "."], "sentence-detokenized": "Examples include Salford Systems CART (which has licensed the original CART authors' own code), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open source software framework for statistical computing), which includes several CART implementations such as rpart, party and randomForest), Weka (free and open source data mining package, including several decision tree algorithms), Orange, KNIME, Microsoft SQL Server programming language).", "token2charspan": [[0, 8], [9, 16], [17, 24], [25, 32], [33, 37], [38, 39], [39, 44], [45, 48], [49, 57], [58, 61], [62, 70], [71, 75], [76, 83], [83, 84], [85, 88], [89, 93], [93, 94], [94, 95], [96, 99], [100, 104], [105, 112], [112, 113], [114, 124], [124, 125], [126, 129], [130, 140], [141, 146], [146, 147], [148, 154], [154, 155], [156, 157], [158, 159], [159, 161], [162, 166], [167, 173], [174, 182], [183, 192], [193, 196], [197, 208], [209, 218], [218, 219], [219, 220], [221, 226], [227, 235], [236, 243], [244, 248], [249, 264], [265, 269], [270, 272], [273, 278], [278, 279], [280, 285], [286, 289], [290, 302], [302, 303], [303, 304], [305, 309], [310, 311], [311, 315], [316, 319], [320, 324], [325, 331], [332, 336], [337, 343], [344, 351], [351, 352], [353, 362], [363, 370], [371, 379], [380, 384], [385, 395], [395, 396], [396, 397], [398, 404], [404, 405], [406, 411], [411, 412], [413, 422], [423, 426], [427, 433], [434, 445], [446, 454], [454, 455], [455, 456]]}
{"doc_key": "ai-test-407", "ner": [[1, 2, "algorithm"], [0, 4, "algorithm"], [10, 11, "researcher"], [13, 14, "university"], [17, 18, "researcher"], [20, 23, "organisation"], [25, 25, "organisation"], [35, 37, "researcher"], [39, 41, "researcher"], [42, 46, "organisation"], [57, 62, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[1, 2, 10, 11, "origin", "", false, false], [1, 2, 17, 18, "origin", "", false, false], [1, 2, 35, 37, "origin", "", false, false], [1, 2, 39, 41, "origin", "", false, false], [0, 4, 1, 2, "named", "", false, false], [10, 11, 13, 14, "physical", "", false, false], [10, 11, 13, 14, "role", "", false, false], [17, 18, 20, 23, "physical", "", false, false], [17, 18, 20, 23, "role", "", false, false], [25, 25, 20, 23, "named", "", false, false], [35, 37, 42, 46, "physical", "", false, false], [35, 37, 42, 46, "role", "", false, false], [39, 41, 42, 46, "physical", "", false, false], [39, 41, 42, 46, "role", "", false, false], [57, 62, 1, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Linear", "Predictive", "Coding", "(", "LPC", ")", "was", "first", "developed", "by", "Fumitada", "Itakura", "(", "Nagoya", "University", ")", "and", "Shuzo", "Saito", "(", "Nippon", "Telegraph", "and", "Telephone", ",", "NTT", ")", "in", "1966", ",", "and", "was", "further", "developed", "by", "Bishnu", "S.", "Atal", "and", "Manfred", "R.", "Schroeder", "at", "Bell", "Labs", "in", "the", "early", "to", "mid-1970s", ",", "becoming", "the", "basis", "for", "the", "first", "speech", "synthesizer", "DSP", "chips", "in", "the", "late", "1970s", "."], "sentence-detokenized": "Linear Predictive Coding (LPC) was first developed by Fumitada Itakura (Nagoya University) and Shuzo Saito (Nippon Telegraph and Telephone, NTT) in 1966, and was further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs in the early to mid-1970s, becoming the basis for the first speech synthesizer DSP chips in the late 1970s.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 40], [41, 50], [51, 53], [54, 62], [63, 70], [71, 72], [72, 78], [79, 89], [89, 90], [91, 94], [95, 100], [101, 106], [107, 108], [108, 114], [115, 124], [125, 128], [129, 138], [138, 139], [140, 143], [143, 144], [145, 147], [148, 152], [152, 153], [154, 157], [158, 161], [162, 169], [170, 179], [180, 182], [183, 189], [190, 192], [193, 197], [198, 201], [202, 209], [210, 212], [213, 222], [223, 225], [226, 230], [231, 235], [236, 238], [239, 242], [243, 248], [249, 251], [252, 261], [261, 262], [263, 271], [272, 275], [276, 281], [282, 285], [286, 289], [290, 295], [296, 302], [303, 314], [315, 318], [319, 324], [325, 327], [328, 331], [332, 336], [337, 342], [342, 343]]}
{"doc_key": "ai-test-408", "ner": [[1, 4, "metrics"], [8, 8, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 1, 4, "part-of", "", false, false], [10, 10, 1, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "F", "-", "score", "is", "a", "combination", "of", "accuracy", "and", "recall", ",", "which", "gives", "a", "single", "score", "."], "sentence-detokenized": "The F-score is a combination of accuracy and recall, which gives a single score.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 16], [17, 28], [29, 31], [32, 40], [41, 44], [45, 51], [51, 52], [53, 58], [59, 64], [65, 66], [67, 73], [74, 79], [79, 80]]}
{"doc_key": "ai-test-409", "ner": [[0, 1, "field"], [8, 13, "task"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 13, 0, 1, "part-of", "task_part_of_field", false, false], [16, 17, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Image", "analysis", "tasks", "can", "be", "as", "simple", "as", "reading", "barcode", "d", "tags", "or", "as", "sophisticated", "as", "facial", "recognition", "."], "sentence-detokenized": "Image analysis tasks can be as simple as reading barcode d tags or as sophisticated as facial recognition.", "token2charspan": [[0, 5], [6, 14], [15, 20], [21, 24], [25, 27], [28, 30], [31, 37], [38, 40], [41, 48], [49, 56], [57, 58], [59, 63], [64, 66], [67, 69], [70, 83], [84, 86], [87, 93], [94, 105], [105, 106]]}
{"doc_key": "ai-test-410", "ner": [[5, 7, "algorithm"], [22, 23, "algorithm"], [31, 33, "algorithm"], [37, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[31, 33, 22, 23, "type-of", "", false, false], [37, 37, 31, 33, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "special", "case", "of", "linear", "support", "vector", "machines", "can", "be", "solved", "more", "efficiently", "with", "the", "same", "algorithms", "as", "its", "close", "relative", ",", "logistic", "regression", "optimization", ";", "this", "class", "of", "algorithms", "includes", "stochastic", "gradient", "descent", "(", "e.g.", ",", "PEGASOS", ")", "."], "sentence-detokenized": "The special case of linear support vector machines can be solved more efficiently with the same algorithms as its close relative, logistic regression optimization; this class of algorithms includes stochastic gradient descent (e.g., PEGASOS).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 34], [35, 41], [42, 50], [51, 54], [55, 57], [58, 64], [65, 69], [70, 81], [82, 86], [87, 90], [91, 95], [96, 106], [107, 109], [110, 113], [114, 119], [120, 128], [128, 129], [130, 138], [139, 149], [150, 162], [162, 163], [164, 168], [169, 174], [175, 177], [178, 188], [189, 197], [198, 208], [209, 217], [218, 225], [226, 227], [227, 231], [231, 232], [233, 240], [240, 241], [241, 242]]}
{"doc_key": "ai-test-411", "ner": [[1, 1, "product"], [1, 5, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 1, 5, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["When", "Siri", "on", "an", "iOS", "device", "asks", "you", "if", "you", "have", "a", "pet", ",", "one", "of", "the", "answers", "is", "that", "I", "had", "an", "AIBO", "."], "sentence-detokenized": "When Siri on an iOS device asks you if you have a pet, one of the answers is that I had an AIBO.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 15], [16, 19], [20, 26], [27, 31], [32, 35], [36, 38], [39, 42], [43, 47], [48, 49], [50, 53], [53, 54], [55, 58], [59, 61], [62, 65], [66, 73], [74, 76], [77, 81], [82, 83], [84, 87], [88, 90], [91, 95], [95, 96]]}
{"doc_key": "ai-test-412", "ner": [[0, 2, "task"], [5, 8, "metrics"], [10, 10, "metrics"], [12, 14, "metrics"], [15, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 8, 0, 2, "part-of", "", false, false], [10, 10, 5, 8, "named", "", false, false], [12, 14, 0, 2, "part-of", "", false, false], [15, 15, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "information", "retrieval", ",", "a", "positive", "predictive", "value", "is", "called", "precision", "and", "sensitivity", "is", "called", "recall", "."], "sentence-detokenized": "In information retrieval, a positive predictive value is called precision and sensitivity is called recall.", "token2charspan": [[0, 2], [3, 14], [15, 24], [24, 25], [26, 27], [28, 36], [37, 47], [48, 53], [54, 56], [57, 63], [64, 73], [74, 77], [78, 89], [90, 92], [93, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-413", "ner": [[11, 12, "field"], [14, 14, "task"], [16, 16, "task"], [18, 19, "task"], [27, 28, "task"], [30, 31, "task"], [33, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 14, 11, 12, "part-of", "task_part_of_field", false, false], [16, 16, 11, 12, "part-of", "task_part_of_field", false, false], [18, 19, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "particular", ",", "his", "research", "has", "focused", "on", "areas", "such", "as", "text", "mining", "(", "extraction", ",", "categorisation", ",", "novelty", "detection", ")", "and", "new", "theoretical", "frameworks", "such", "as", "information", "retrieval", ",", "automatic", "summarisation", ",", "free", "-", "text", "question", "answering", "and", "a", "unified", "utility", "-", "based", "theory", "of", "related", "tasks", "."], "sentence-detokenized": "In particular, his research has focused on areas such as text mining (extraction, categorisation, novelty detection) and new theoretical frameworks such as information retrieval, automatic summarisation, free-text question answering and a unified utility-based theory of related tasks.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 27], [28, 31], [32, 39], [40, 42], [43, 48], [49, 53], [54, 56], [57, 61], [62, 68], [69, 70], [70, 80], [80, 81], [82, 96], [96, 97], [98, 105], [106, 115], [115, 116], [117, 120], [121, 124], [125, 136], [137, 147], [148, 152], [153, 155], [156, 167], [168, 177], [177, 178], [179, 188], [189, 202], [202, 203], [204, 208], [208, 209], [209, 213], [214, 222], [223, 232], [233, 236], [237, 238], [239, 246], [247, 254], [254, 255], [255, 260], [261, 267], [268, 270], [271, 278], [279, 284], [284, 285]]}
{"doc_key": "ai-test-414", "ner": [[0, 1, "product"], [6, 8, "product"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 8, 0, 1, "part-of", "", false, false], [15, 16, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Delta", "robots", "have", "base", "-", "mounted", "rotary", "actuators", "that", "move", "a", "lightweight", ",", "rigid", ",", "parallel", "arm", "."], "sentence-detokenized": "Delta robots have base-mounted rotary actuators that move a lightweight, rigid, parallel arm.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 22], [22, 23], [23, 30], [31, 37], [38, 47], [48, 52], [53, 57], [58, 59], [60, 71], [71, 72], [73, 78], [78, 79], [80, 88], [89, 92], [92, 93]]}
{"doc_key": "ai-test-415", "ner": [[8, 12, "metrics"], [14, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "expressed", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be expressed in a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 33], [34, 36], [37, 38], [39, 40], [41, 42], [43, 44], [45, 56], [57, 62], [63, 65], [66, 75], [76, 82], [83, 85], [86, 93], [93, 94]]}
{"doc_key": "ai-test-416", "ner": [[2, 3, "field"], [30, 31, "task"], [37, 38, "task"], [43, 45, "task"], [47, 49, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[30, 31, 2, 3, "part-of", "task_part_of_field", false, false], [37, 38, 2, 3, "part-of", "task_part_of_field", false, false], [43, 45, 2, 3, "part-of", "task_part_of_field", false, false], [47, 49, 2, 3, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "actual", "data", "mining", "task", "is", "the", "semi-automated", "or", "automated", "analysis", "of", "large", "amounts", "of", "data", "to", "extract", "unknown", ",", "interesting", "patterns", ",", "such", "as", "groups", "of", "data", "records", "(", "cluster", "analysis", ")", ",", "unusual", "records", "(", "anomaly", "detection", ")", "and", "dependencies", "(", "association", "rule", "mining", ",", "sequential", "pattern", "mining", ")", "."], "sentence-detokenized": "The actual data mining task is the semi-automated or automated analysis of large amounts of data to extract unknown, interesting patterns, such as groups of data records (cluster analysis), unusual records (anomaly detection) and dependencies (association rule mining, sequential pattern mining).", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 22], [23, 27], [28, 30], [31, 34], [35, 49], [50, 52], [53, 62], [63, 71], [72, 74], [75, 80], [81, 88], [89, 91], [92, 96], [97, 99], [100, 107], [108, 115], [115, 116], [117, 128], [129, 137], [137, 138], [139, 143], [144, 146], [147, 153], [154, 156], [157, 161], [162, 169], [170, 171], [171, 178], [179, 187], [187, 188], [188, 189], [190, 197], [198, 205], [206, 207], [207, 214], [215, 224], [224, 225], [226, 229], [230, 242], [243, 244], [244, 255], [256, 260], [261, 267], [267, 268], [269, 279], [280, 287], [288, 294], [294, 295], [295, 296]]}
{"doc_key": "ai-test-417", "ner": [[0, 3, "product"], [5, 6, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 5, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "a", "recommender", "system", ",", "sentiment", "analysis", "has", "proven", "to", "be", "a", "valuable", "technique", "."], "sentence-detokenized": "For a recommender system, sentiment analysis has proven to be a valuable technique.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 24], [24, 25], [26, 35], [36, 44], [45, 48], [49, 55], [56, 58], [59, 61], [62, 63], [64, 72], [73, 82], [82, 83]]}
{"doc_key": "ai-test-418", "ner": [[0, 1, "misc"], [9, 10, "product"], [30, 30, "organisation"], [34, 35, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 9, 10, "usage", "", false, false], [30, 30, 34, 35, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Germans", "inadvertently", "chose", "the", "wrong", "frequency", "for", "the", "Wotan", "system", ";", "it", "was", "operating", "on", "45", "MHz", ",", "which", "happened", "to", "be", "the", "frequency", "of", "the", "powerful", "but", "dormant", "BBC", "television", "station", "at", "Alexandra", "Palace", "."], "sentence-detokenized": "The Germans inadvertently chose the wrong frequency for the Wotan system; it was operating on 45 MHz, which happened to be the frequency of the powerful but dormant BBC television station at Alexandra Palace.", "token2charspan": [[0, 3], [4, 11], [12, 25], [26, 31], [32, 35], [36, 41], [42, 51], [52, 55], [56, 59], [60, 65], [66, 72], [72, 73], [74, 76], [77, 80], [81, 90], [91, 93], [94, 96], [97, 100], [100, 101], [102, 107], [108, 116], [117, 119], [120, 122], [123, 126], [127, 136], [137, 139], [140, 143], [144, 152], [153, 156], [157, 164], [165, 168], [169, 179], [180, 187], [188, 190], [191, 200], [201, 207], [207, 208]]}
{"doc_key": "ai-test-419", "ner": [[8, 12, "metrics"], [14, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "expressed", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be expressed in a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 33], [34, 36], [37, 38], [39, 40], [41, 42], [43, 44], [45, 56], [57, 62], [63, 65], [66, 75], [76, 82], [83, 85], [86, 93], [93, 94]]}
{"doc_key": "ai-test-420", "ner": [[0, 3, "misc"], [10, 12, "misc"], [14, 14, "product"], [16, 16, "product"], [18, 20, "product"], [28, 30, "misc"], [41, 42, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 14, 10, 12, "usage", "", false, false], [16, 16, 10, 12, "usage", "", false, false], [18, 20, 16, 16, "named", "", false, false], [28, 30, 10, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "semantic", "web", "applications", "and", "in", "relatively", "popular", "applications", "of", "RDF", ",", "such", "as", "RSS", "and", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "resources", "are", "usually", "represented", "by", "URIs", "that", "are", "intentionally", "marked", "up", "and", "used", "to", "access", "actual", "data", "on", "the", "web", "."], "sentence-detokenized": "In semantic web applications and in relatively popular applications of RDF, such as RSS and FOAF (Friend a Friend), resources are usually represented by URIs that are intentionally marked up and used to access actual data on the web.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 28], [29, 32], [33, 35], [36, 46], [47, 54], [55, 67], [68, 70], [71, 74], [74, 75], [76, 80], [81, 83], [84, 87], [88, 91], [92, 96], [97, 98], [98, 104], [105, 106], [107, 113], [113, 114], [114, 115], [116, 125], [126, 129], [130, 137], [138, 149], [150, 152], [153, 157], [158, 162], [163, 166], [167, 180], [181, 187], [188, 190], [191, 194], [195, 199], [200, 202], [203, 209], [210, 216], [217, 221], [222, 224], [225, 228], [229, 232], [232, 233]]}
{"doc_key": "ai-test-421", "ner": [[1, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "has", "studied", "this", "issue", "in", "depth", "."], "sentence-detokenized": "The Association for the Advancement of Artificial Intelligence has studied this issue in depth.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 74], [75, 79], [80, 85], [86, 88], [89, 94], [94, 95]]}
{"doc_key": "ai-test-422", "ner": [[0, 6, "product"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 18, 0, 6, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Apple", "'s", "Macintosh", "speech", "system", ",", "which", "started", "out", "as", "a", "curiosity", ",", "has", "evolved", "into", "PlainTalk", ",", "a", "fully", "supported", "program", "for", "people", "with", "visual", "impairments", "."], "sentence-detokenized": "Apple's Macintosh speech system, which started out as a curiosity, has evolved into PlainTalk, a fully supported program for people with visual impairments.", "token2charspan": [[0, 5], [5, 7], [8, 17], [18, 24], [25, 31], [31, 32], [33, 38], [39, 46], [47, 50], [51, 53], [54, 55], [56, 65], [65, 66], [67, 70], [71, 78], [79, 83], [84, 93], [93, 94], [95, 96], [97, 102], [103, 112], [113, 120], [121, 124], [125, 131], [132, 136], [137, 143], [144, 155], [155, 156]]}
{"doc_key": "ai-test-423", "ner": [[5, 5, "field"], [7, 8, "task"], [10, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 5, 5, "part-of", "task_part_of_field", false, false], [10, 11, 5, 5, "part-of", "task_part_of_field", false, false], [13, 14, 5, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "uses", "of", "ontologies", "within", "NLP", "include", "information", "retrieval", ",", "information", "extraction", "and", "automatic", "summarisation", "."], "sentence-detokenized": "Other uses of ontologies within NLP include information retrieval, information extraction and automatic summarisation.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 24], [25, 31], [32, 35], [36, 43], [44, 55], [56, 65], [65, 66], [67, 78], [79, 89], [90, 93], [94, 103], [104, 117], [117, 118]]}
{"doc_key": "ai-test-424", "ner": [[6, 14, "organisation"], [17, 21, "organisation"], [24, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "institute", "works", "closely", "with", "the", "Janelia", "Farm", "Campus", "of", "the", "Howard", "Hughes", "Medical", "Institute", ",", "the", "Allen", "Institute", "for", "Brain", "Science", "and", "the", "National", "Institutes", "of", "Health", "to", "develop", "better", "methods", "for", "reconstructing", "neuronal", "architectures", "."], "sentence-detokenized": "The institute works closely with the Janelia Farm Campus of the Howard Hughes Medical Institute, the Allen Institute for Brain Science and the National Institutes of Health to develop better methods for reconstructing neuronal architectures.", "token2charspan": [[0, 3], [4, 13], [14, 19], [20, 27], [28, 32], [33, 36], [37, 44], [45, 49], [50, 56], [57, 59], [60, 63], [64, 70], [71, 77], [78, 85], [86, 95], [95, 96], [97, 100], [101, 106], [107, 116], [117, 120], [121, 126], [127, 134], [135, 138], [139, 142], [143, 151], [152, 162], [163, 165], [166, 172], [173, 175], [176, 183], [184, 190], [191, 198], [199, 202], [203, 217], [218, 226], [227, 240], [240, 241]]}
{"doc_key": "ai-test-425", "ner": [[0, 0, "organisation"], [4, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 0, 0, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Google", "recently", "announced", "that", "Google", "Translate", "translates", "roughly", "enough", "text", "to", "load", "1", "million", "books", "in", "a", "day", "(", "2012", ")", "."], "sentence-detokenized": "Google recently announced that Google Translate translates roughly enough text to load 1 million books in a day (2012).", "token2charspan": [[0, 6], [7, 15], [16, 25], [26, 30], [31, 37], [38, 47], [48, 58], [59, 66], [67, 73], [74, 78], [79, 81], [82, 86], [87, 88], [89, 96], [97, 102], [103, 105], [106, 107], [108, 111], [112, 113], [113, 117], [117, 118], [118, 119]]}
{"doc_key": "ai-test-426", "ner": [[14, 14, "country"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"], [23, 23, "country"], [25, 26, "country"], [35, 36, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "events", "are", "held", "all", "over", "the", "world", "and", "are", "most", "popular", "in", "the", "UK", ",", "the", "US", ",", "Japan", ",", "Singapore", ",", "India", ",", "South", "Korea", "and", "increasingly", "popular", "in", "subcontinent", "countries", "such", "as", "Sri", "Lanka", "."], "sentence-detokenized": "The events are held all over the world and are most popular in the UK, the US, Japan, Singapore, India, South Korea and increasingly popular in subcontinent countries such as Sri Lanka.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 19], [20, 23], [24, 28], [29, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 59], [60, 62], [63, 66], [67, 69], [69, 70], [71, 74], [75, 77], [77, 78], [79, 84], [84, 85], [86, 95], [95, 96], [97, 102], [102, 103], [104, 109], [110, 115], [116, 119], [120, 132], [133, 140], [141, 143], [144, 156], [157, 166], [167, 171], [172, 174], [175, 178], [179, 184], [184, 185]]}
{"doc_key": "ai-test-427", "ner": [[6, 6, "programlang"], [12, 12, "programlang"], [14, 14, "programlang"], [16, 17, "programlang"], [19, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "mainly", "developed", "in", "R", ",", "but", "sometimes", "also", "in", "Java", ",", "C", ",", "C", "++", "and", "Fortran", "."], "sentence-detokenized": "These packages are mainly developed in R, but sometimes also in Java, C, C++ and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 25], [26, 35], [36, 38], [39, 40], [40, 41], [42, 45], [46, 55], [56, 60], [61, 63], [64, 68], [68, 69], [70, 71], [71, 72], [73, 74], [74, 76], [77, 80], [81, 88], [88, 89]]}
{"doc_key": "ai-test-428", "ner": [[2, 7, "conference"], [3, 9, "conference"], [12, 12, "researcher"], [14, 14, "researcher"], [18, 19, "researcher"], [22, 23, "algorithm"], [28, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 9, 2, 7, "named", "", false, false], [12, 12, 2, 7, "physical", "", false, false], [12, 12, 2, 7, "role", "", false, false], [12, 12, 18, 19, "role", "teams_up_with", false, false], [12, 12, 22, 23, "usage", "", false, false], [14, 14, 2, 7, "physical", "", false, false], [14, 14, 2, 7, "role", "", false, false], [14, 14, 18, 19, "role", "teams_up_with", false, false], [14, 14, 22, 23, "usage", "", false, false], [18, 19, 2, 7, "physical", "", false, false], [18, 19, 2, 7, "role", "", false, false], [18, 19, 22, 23, "usage", "", false, false], [22, 23, 28, 33, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["At", "the", "2006", "European", "Conference", "on", "Computer", "Vision", "(", "ECCV", ")", ",", "Dalal", "and", "Triggs", ",", "together", "with", "Cordelia", "Schmid", ",", "applied", "HOG", "detectors", "to", "the", "problem", "of", "recognising", "people", "in", "films", "and", "videos", "."], "sentence-detokenized": "At the 2006 European Conference on Computer Vision (ECCV), Dalal and Triggs, together with Cordelia Schmid, applied HOG detectors to the problem of recognising people in films and videos.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 31], [32, 34], [35, 43], [44, 50], [51, 52], [52, 56], [56, 57], [57, 58], [59, 64], [65, 68], [69, 75], [75, 76], [77, 85], [86, 90], [91, 99], [100, 106], [106, 107], [108, 115], [116, 119], [120, 129], [130, 132], [133, 136], [137, 144], [145, 147], [148, 159], [160, 166], [167, 169], [170, 175], [176, 179], [180, 186], [186, 187]]}
{"doc_key": "ai-test-429", "ner": [[3, 3, "metrics"], [5, 7, "metrics"], [11, 12, "task"], [18, 19, "metrics"], [20, 24, "metrics"], [30, 30, "metrics"], [35, 36, "metrics"], [15, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 3, 11, 12, "related-to", "measured_with", false, false], [5, 7, 11, 12, "related-to", "measured_with", false, false], [18, 19, 11, 12, "related-to", "measured_with", false, false], [20, 24, 18, 19, "named", "", false, false], [30, 30, 18, 19, "named", "", false, false], [15, 38, 35, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "addition", "to", "sensitivity", "and", "specificity", ",", "the", "performance", "of", "a", "binary", "classification", "test", "can", "also", "be", "measured", "by", "the", "positive", "predictive", "value", "(", "PPV", ")", ",", "also", "known", "as", "precision", ",", "and", "the", "negative", "predictive", "value", "(", "NPV", ")", "."], "sentence-detokenized": "In addition to sensitivity and specificity, the performance of a binary classification test can also be measured by the positive predictive value (PPV), also known as precision, and the negative predictive value (NPV).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 42], [42, 43], [44, 47], [48, 59], [60, 62], [63, 64], [65, 71], [72, 86], [87, 91], [92, 95], [96, 100], [101, 103], [104, 112], [113, 115], [116, 119], [120, 128], [129, 139], [140, 145], [146, 147], [147, 150], [150, 151], [151, 152], [153, 157], [158, 163], [164, 166], [167, 176], [176, 177], [178, 181], [182, 185], [186, 194], [195, 205], [206, 211], [212, 213], [213, 216], [216, 217], [217, 218]]}
{"doc_key": "ai-test-430", "ner": [[16, 18, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "models", "can", "give", "partial", "credit", "for", "overlapping", "matches", "(", "for", "example", ",", "by", "using", "the", "Jaccard", "index", "criterion", ")", "."], "sentence-detokenized": "Such models can give partial credit for overlapping matches (for example, by using the Jaccard index criterion).", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 28], [29, 35], [36, 39], [40, 51], [52, 59], [60, 61], [61, 64], [65, 72], [72, 73], [74, 76], [77, 82], [83, 86], [87, 94], [95, 100], [101, 110], [110, 111], [111, 112]]}
{"doc_key": "ai-test-431", "ner": [[13, 19, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Furthermore", ",", "it", "presents", "philosophical", "issues", "and", "possible", "misunderstandings", "in", "the", "use", "of", "maximum", "likelihood", "estimators", "and", "likelihood", "functions", "for", "single", "-", "sample", "estimation", "."], "sentence-detokenized": "Furthermore, it presents philosophical issues and possible misunderstandings in the use of maximum likelihood estimators and likelihood functions for single-sample estimation.", "token2charspan": [[0, 11], [11, 12], [13, 15], [16, 24], [25, 38], [39, 45], [46, 49], [50, 58], [59, 76], [77, 79], [80, 83], [84, 87], [88, 90], [91, 98], [99, 109], [110, 120], [121, 124], [125, 135], [136, 145], [146, 149], [150, 156], [156, 157], [157, 163], [164, 174], [174, 175]]}
