{"doc_key": "ai-dev-1", "ner": [[0, 0, "metrics"], [6, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 9, 0, 0, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "measured", "here", "by", "the", "error", "rate", ",", "which", "is", "defined", "as", ":"], "sentence-detokenized": "Accuracy is measured here by the error rate, which is defined as:", "token2charspan": [[0, 8], [9, 11], [12, 20], [21, 25], [26, 28], [29, 32], [33, 38], [39, 43], [43, 44], [45, 50], [51, 53], [54, 61], [62, 64], [64, 65]]}
{"doc_key": "ai-dev-2", "ner": [[4, 4, "algorithm"], [11, 13, "misc"], [15, 17, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 11, 13, "type-of", "", false, false], [4, 4, 15, 17, "related-to", "", false, false], [4, 4, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["From", "this", "perspective", ",", "SVM", "is", "closely", "related", "to", "other", "basic", "classification", "algorithms", "such", "as", "regularized", "least", "squares", "logistic", "regression", "."], "sentence-detokenized": "From this perspective, SVM is closely related to other basic classification algorithms such as regularized least squares logistic regression.", "token2charspan": [[0, 4], [5, 9], [10, 21], [21, 22], [23, 26], [27, 29], [30, 37], [38, 45], [46, 48], [49, 54], [55, 60], [61, 75], [76, 86], [87, 91], [92, 94], [95, 106], [107, 112], [113, 120], [121, 129], [130, 140], [140, 141]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [3, 4, "person"], [13, 14, "person"], [16, 16, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 0, 1, "named", "actor_plays_character", false, false], [3, 4, 0, 1, "origin", "actor_plays_character", false, false], [16, 16, 13, 14, "named", "actor_plays_character", false, false], [16, 16, 13, 14, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "portrays", "Leon", "Kowalski", ",", "a", "combat", "and", "worker", "replicant", ",", "and", "Joanna", "Cassidy", "portrays", "Zhora", ",", "a", "killer", "replicant", "."], "sentence-detokenized": "Brion James portrays Leon Kowalski, a combat and worker replicant, and Joanna Cassidy portrays Zhora, a killer replicant.", "token2charspan": [[0, 5], [6, 11], [12, 20], [21, 25], [26, 34], [34, 35], [36, 37], [38, 44], [45, 48], [49, 55], [56, 65], [65, 66], [67, 70], [71, 77], [78, 85], [86, 94], [95, 100], [100, 101], [102, 103], [104, 110], [111, 120], [120, 121]]}
{"doc_key": "ai-dev-4", "ner": [[18, 24, "product"], [19, 19, "product"], [27, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 24, 27, 27, "physical", "", false, false], [19, 19, 18, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "image", ",", "which", "was", "scanned", ",", "saved", "and", "recreated", "in", "digital", "pixels", ",", "was", "displayed", "on", "the", "SEAC", "(", "Standards", "Eastern", "Automatic", "Computer", ")", "at", "NIST", "."], "sentence-detokenized": "The first image, which was scanned, saved and recreated in digital pixels, was displayed on the SEAC (Standards Eastern Automatic Computer) at NIST.", "token2charspan": [[0, 3], [4, 9], [10, 15], [15, 16], [17, 22], [23, 26], [27, 34], [34, 35], [36, 41], [42, 45], [46, 55], [56, 58], [59, 66], [67, 73], [73, 74], [75, 78], [79, 88], [89, 91], [92, 95], [96, 100], [101, 102], [102, 111], [112, 119], [120, 129], [130, 138], [138, 139], [140, 142], [143, 147], [147, 148]]}
{"doc_key": "ai-dev-5", "ner": [[0, 6, "task"], [20, 21, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 20, 21, "part-of", "", false, false], [0, 6, 23, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Segmenting", "text", "into", "topics", "or", "discourse", "turns", "can", "be", "useful", "in", "some", "natural", "processing", "tasks", ":", "it", "can", "significantly", "improve", "information", "retrieval", "or", "speech", "recognition", "(", "by", "indexing", "/", "document", "recognition", "more", "accurately", ",", "or", "by", "providing", "as", "a", "result", "a", "specific", "part", "of", "the", "document", "corresponding", "to", "the", "query", ")", "."], "sentence-detokenized": "Segmenting text into topics or discourse turns can be useful in some natural processing tasks: it can significantly improve information retrieval or speech recognition (by indexing/document recognition more accurately, or by providing as a result a specific part of the document corresponding to the query).", "token2charspan": [[0, 10], [11, 15], [16, 20], [21, 27], [28, 30], [31, 40], [41, 46], [47, 50], [51, 53], [54, 60], [61, 63], [64, 68], [69, 76], [77, 87], [88, 93], [93, 94], [95, 97], [98, 101], [102, 115], [116, 123], [124, 135], [136, 145], [146, 148], [149, 155], [156, 167], [168, 169], [169, 171], [172, 180], [180, 181], [181, 189], [190, 201], [202, 206], [207, 217], [217, 218], [219, 221], [222, 224], [225, 234], [235, 237], [238, 239], [240, 246], [247, 248], [249, 257], [258, 262], [263, 265], [266, 269], [270, 278], [279, 292], [293, 295], [296, 299], [300, 305], [305, 306], [306, 307]]}
{"doc_key": "ai-dev-6", "ner": [[8, 12, "university"], [21, 22, "conference"], [24, 27, "university"], [34, 35, "researcher"], [37, 38, "researcher"], [40, 41, "researcher"], [43, 44, "researcher"], [46, 47, "researcher"], [49, 50, "researcher"], [52, 54, "researcher"], [57, 58, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[21, 22, 24, 27, "physical", "", false, false], [34, 35, 21, 22, "physical", "", false, false], [34, 35, 21, 22, "role", "", false, false], [34, 35, 21, 22, "temporal", "", false, false], [37, 38, 21, 22, "physical", "", false, false], [37, 38, 21, 22, "role", "", false, false], [37, 38, 21, 22, "temporal", "", false, false], [40, 41, 21, 22, "physical", "", false, false], [40, 41, 21, 22, "role", "", false, false], [40, 41, 21, 22, "temporal", "", false, false], [43, 44, 21, 22, "physical", "", false, false], [43, 44, 21, 22, "role", "", false, false], [43, 44, 21, 22, "temporal", "", false, false], [46, 47, 21, 22, "physical", "", false, false], [46, 47, 21, 22, "role", "", false, false], [46, 47, 21, 22, "temporal", "", false, false], [49, 50, 21, 22, "physical", "", false, false], [49, 50, 21, 22, "role", "", false, false], [49, 50, 21, 22, "temporal", "", false, false], [52, 54, 21, 22, "physical", "", false, false], [52, 54, 21, 22, "role", "", false, false], [52, 54, 21, 22, "temporal", "", false, false], [57, 58, 21, 22, "physical", "", false, false], [57, 58, 21, 22, "role", "", false, false], [57, 58, 21, 22, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["In", "1999", "he", "organized", "such", "a", "symposium", "at", "Indiana", "University", ",", "and", "in", "April", "2000", "he", "organized", "a", "larger", "symposium", "called", "Spiritual", "Robots", "at", "Stanford", "University", ",", "where", "he", "moderated", "a", "panel", "consisting", "of", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", ",", "and", "John", "Koza", "."], "sentence-detokenized": "In 1999 he organized such a symposium at Indiana University, and in April 2000 he organized a larger symposium called Spiritual Robots at Stanford University, where he moderated a panel consisting of Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland, and John Koza.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 20], [21, 25], [26, 27], [28, 37], [38, 40], [41, 48], [49, 59], [59, 60], [61, 64], [65, 67], [68, 73], [74, 78], [79, 81], [82, 91], [92, 93], [94, 100], [101, 110], [111, 117], [118, 127], [128, 134], [135, 137], [138, 146], [147, 157], [157, 158], [159, 164], [165, 167], [168, 177], [178, 179], [180, 185], [186, 196], [197, 199], [200, 203], [204, 212], [212, 213], [214, 218], [219, 226], [226, 227], [228, 233], [234, 239], [239, 240], [241, 246], [247, 253], [253, 254], [255, 259], [260, 263], [263, 264], [265, 270], [271, 276], [276, 277], [278, 282], [283, 288], [289, 296], [296, 297], [298, 301], [302, 306], [307, 311], [311, 312]]}
{"doc_key": "ai-dev-7", "ner": [[10, 10, "metrics"], [11, 11, "metrics"], [14, 14, "metrics"], [15, 15, "metrics"], [20, 20, "metrics"], [41, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 10, 20, 20, "named", "", false, false], [11, 11, 10, 10, "named", "", false, false], [14, 14, 41, 41, "named", "", false, false], [15, 15, 14, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "calculation", "of", "the", "score", "takes", "into", "account", "both", "the", "precision", "p", "and", "the", "feedback", "r", "of", "the", "test", ":", "p", "is", "the", "number", "of", "correct", "positive", "results", "divided", "by", "the", "number", "of", "all", "positive", "results", "returned", "by", "the", "classifier", "and", "r", "is", "the", "number", "of", "correct", "positive", "results", "divided", "by", "the", "number", "of", "all", "relevant", "samples", "(", "all", "samples", "that", "should", "have", "been", "identified", "as", "positive", ")", "."], "sentence-detokenized": "The calculation of the score takes into account both the precision p and the feedback r of the test: p is the number of correct positive results divided by the number of all positive results returned by the classifier and r is the number of correct positive results divided by the number of all relevant samples (all samples that should have been identified as positive).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 22], [23, 28], [29, 34], [35, 39], [40, 47], [48, 52], [53, 56], [57, 66], [67, 68], [69, 72], [73, 76], [77, 85], [86, 87], [88, 90], [91, 94], [95, 99], [99, 100], [101, 102], [103, 105], [106, 109], [110, 116], [117, 119], [120, 127], [128, 136], [137, 144], [145, 152], [153, 155], [156, 159], [160, 166], [167, 169], [170, 173], [174, 182], [183, 190], [191, 199], [200, 202], [203, 206], [207, 217], [218, 221], [222, 223], [224, 226], [227, 230], [231, 237], [238, 240], [241, 248], [249, 257], [258, 265], [266, 273], [274, 276], [277, 280], [281, 287], [288, 290], [291, 294], [295, 303], [304, 311], [312, 313], [313, 316], [317, 324], [325, 329], [330, 336], [337, 341], [342, 346], [347, 357], [358, 360], [361, 369], [369, 370], [370, 371]]}
{"doc_key": "ai-dev-8", "ner": [[4, 6, "organisation"], [22, 24, "product"], [35, 37, "person"], [34, 34, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 22, 24, "artifact", "", false, false], [22, 24, 35, 37, "win-defeat", "", false, false], [22, 24, 34, 34, "win-defeat", "", true, false], [35, 37, 34, 34, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "its", "acquisition", "by", "Google", ",", "the", "company", "has", "had", "a", "number", "of", "notable", "successes", ",", "perhaps", "most", "notably", "the", "creation", "of", "AlphaGo", ",", "which", "beat", "the", "world", "champion", "at", "the", "complex", "game", "of", "Go", ",", "Lee", "Sedol", "."], "sentence-detokenized": "Since its acquisition by Google, the company has had a number of notable successes, perhaps most notably the creation of AlphaGo, which beat the world champion at the complex game of Go, Lee Sedol.", "token2charspan": [[0, 5], [6, 9], [10, 21], [22, 24], [25, 31], [31, 32], [33, 36], [37, 44], [45, 48], [49, 52], [53, 54], [55, 61], [62, 64], [65, 72], [73, 82], [82, 83], [84, 91], [92, 96], [97, 104], [105, 108], [109, 117], [118, 120], [121, 128], [128, 129], [130, 135], [136, 140], [141, 144], [145, 150], [151, 159], [160, 162], [163, 166], [167, 174], [175, 179], [180, 182], [183, 185], [185, 186], [187, 190], [191, 196], [196, 197]]}
{"doc_key": "ai-dev-9", "ner": [[15, 16, "misc"], [29, 29, "field"], [31, 33, "product"], [50, 51, "misc"], [55, 56, "misc"], [59, 59, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 16, 29, 29, "part-of", "", false, false], [15, 16, 55, 56, "named", "same", false, false], [31, 33, 50, 51, "related-to", "", false, false], [31, 33, 55, 56, "usage", "", false, false], [31, 33, 59, 59, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Representation", "of", "words", "with", "respect", "to", "their", "context", "through", "dense", "fixed", "-", "size", "vectors", "(", "word", "embeddings", ")", "has", "become", "one", "of", "the", "most", "fundamental", "building", "blocks", "in", "several", "NLP", "systems.The", "unsupervised", "disambiguation", "system", "uses", "the", "similarity", "between", "word", "meanings", "in", "a", "fixed", "context", "window", "to", "select", "the", "most", "appropriate", "word", "meaning", "using", "a", "pre-trained", "word", "embedding", "model", "and", "WordNet", "."], "sentence-detokenized": "Representation of words with respect to their context through dense fixed-size vectors (word embeddings) has become one of the most fundamental building blocks in several NLP systems.The unsupervised disambiguation system uses the similarity between word meanings in a fixed context window to select the most appropriate word meaning using a pre-trained word embedding model and WordNet.", "token2charspan": [[0, 14], [15, 17], [18, 23], [24, 28], [29, 36], [37, 39], [40, 45], [46, 53], [54, 61], [62, 67], [68, 73], [73, 74], [74, 78], [79, 86], [87, 88], [88, 92], [93, 103], [103, 104], [105, 108], [109, 115], [116, 119], [120, 122], [123, 126], [127, 131], [132, 143], [144, 152], [153, 159], [160, 162], [163, 170], [171, 174], [175, 186], [187, 199], [200, 214], [215, 221], [222, 226], [227, 230], [231, 241], [242, 249], [250, 254], [255, 263], [264, 266], [267, 268], [269, 274], [275, 282], [283, 289], [290, 292], [293, 299], [300, 303], [304, 308], [309, 320], [321, 325], [326, 333], [334, 339], [340, 341], [342, 353], [354, 358], [359, 368], [369, 374], [375, 378], [379, 386], [386, 387]]}
{"doc_key": "ai-dev-10", "ner": [[0, 11, "field"], [12, 12, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 0, 11, "part-of", "", false, false], [15, 16, 0, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "techniques", "are", "used", "to", "automatically", "generate", "such", "rules", ",", "either", "supervised", "learning", "or", "unsupervised", "learning", "."], "sentence-detokenized": "Machine learning techniques are used to automatically generate such rules, either supervised learning or unsupervised learning.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 31], [32, 36], [37, 39], [40, 53], [54, 62], [63, 67], [68, 73], [73, 74], [75, 81], [82, 92], [93, 101], [102, 104], [105, 117], [118, 126], [126, 127]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1969", ",", "Scheinman", "invented", "the", "Stanford", "arm", ","], "sentence-detokenized": "In 1969, Scheinman invented the Stanford arm,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 27], [28, 31], [32, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-dev-12", "ner": [[2, 3, "metrics"], [8, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "the", "Log", "loss", "is", "differentiable", ",", "a", "gradient", "-", "based", "method", "can", "be", "used", "to", "optimize", "the", "model", "."], "sentence-detokenized": "Since the Log loss is differentiable, a gradient-based method can be used to optimize the model.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 18], [19, 21], [22, 36], [36, 37], [38, 39], [40, 48], [48, 49], [49, 54], [55, 61], [62, 65], [66, 68], [69, 73], [74, 76], [77, 85], [86, 89], [90, 95], [95, 96]]}
{"doc_key": "ai-dev-13", "ner": [[1, 2, "field"], [4, 6, "algorithm"], [8, 8, "algorithm"], [11, 13, "algorithm"], [16, 19, "field"], [27, 27, "task"], [29, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 6, 16, 19, "part-of", "", false, false], [8, 8, 4, 6, "named", "", false, false], [11, 13, 4, 6, "named", "", false, false], [16, 19, 1, 2, "part-of", "subfield", false, false], [27, 27, 16, 19, "part-of", "", false, false], [29, 30, 16, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "machine", "learning", ",", "support", "vector", "machines", "(", "SVMs", ",", "also", "support", "vector", "networks", ")", "are", "supervised", "learning", "models", "with", "learning", "algorithms", "that", "analyze", "data", "used", "for", "classification", "and", "regression", "analysis", "."], "sentence-detokenized": "In machine learning, support vector machines (SVMs, also support vector networks) are supervised learning models with learning algorithms that analyze data used for classification and regression analysis.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 28], [29, 35], [36, 44], [45, 46], [46, 50], [50, 51], [52, 56], [57, 64], [65, 71], [72, 80], [80, 81], [82, 85], [86, 96], [97, 105], [106, 112], [113, 117], [118, 126], [127, 137], [138, 142], [143, 150], [151, 155], [156, 160], [161, 164], [165, 179], [180, 183], [184, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-dev-14", "ner": [[8, 9, "task"], [11, 13, "task"], [29, 29, "metrics"], [31, 31, "metrics"], [33, 33, "researcher"], [35, 35, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 13, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "2002", ")", "as", "an", "automatic", "metric", "for", "machine", "translation", "(", "MT", ")", "evaluation", ",", "many", "other", "methods", "have", "been", "proposed", "to", "revise", "or", "improve", "it", ",", "e.g.", ",", "TER", ",", "METEOR", ",", "Banerjee", "and", "Lavie", ",", "(", "2005", ")", "etc", "."], "sentence-detokenized": "(2002) as an automatic metric for machine translation (MT) evaluation, many other methods have been proposed to revise or improve it, e.g., TER, METEOR, Banerjee and Lavie, (2005) etc.", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 9], [10, 12], [13, 22], [23, 29], [30, 33], [34, 41], [42, 53], [54, 55], [55, 57], [57, 58], [59, 69], [69, 70], [71, 75], [76, 81], [82, 89], [90, 94], [95, 99], [100, 108], [109, 111], [112, 118], [119, 121], [122, 129], [130, 132], [132, 133], [134, 138], [138, 139], [140, 143], [143, 144], [145, 151], [151, 152], [153, 161], [162, 165], [166, 171], [171, 172], [173, 174], [174, 178], [178, 179], [180, 183], [183, 184]]}
{"doc_key": "ai-dev-15", "ner": [[3, 5, "misc"], [8, 8, "organisation"], [9, 9, "organisation"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 9, 9, "origin", "", false, false], [9, 9, 8, 8, "part-of", "", false, false], [15, 16, 9, 9, "role", "", false, false], [18, 19, 9, 9, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "contains", "the", "upper", "ontology", "created", "by", "the", "IEEE", "P1600.1", "working", "group", "(", "originally", "by", "Ian", "Niles", "and", "Adam", "Pease", ")", "."], "sentence-detokenized": "It contains the upper ontology created by the IEEE P1600.1 working group (originally by Ian Niles and Adam Pease).", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 21], [22, 30], [31, 38], [39, 41], [42, 45], [46, 50], [51, 58], [59, 66], [67, 72], [73, 74], [74, 84], [85, 87], [88, 91], [92, 97], [98, 101], [102, 106], [107, 112], [112, 113], [113, 114]]}
{"doc_key": "ai-dev-16", "ner": [[1, 5, "misc"], [33, 35, "algorithm"], [37, 38, "algorithm"], [42, 45, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[33, 35, 1, 5, "part-of", "", true, false], [37, 38, 1, 5, "part-of", "", true, false], [42, 45, 37, 38, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "cryoelectron", "tomography", ",", "where", "a", "limited", "number", "of", "projections", "are", "acquired", "due", "to", "hardware", "limitations", "and", "where", "damage", "to", "the", "biological", "sample", "must", "be", "avoided", ",", "it", "can", "be", "used", "together", "with", "compression", "scanning", "techniques", "or", "regularization", "functions", "(", "e.g.", ",", "Huber", "loss", ")", "to", "improve", "reconstruction", "for", "better", "interpretation", "."], "sentence-detokenized": "In cryoelectron tomography, where a limited number of projections are acquired due to hardware limitations and where damage to the biological sample must be avoided, it can be used together with compression scanning techniques or regularization functions (e.g., Huber loss) to improve reconstruction for better interpretation.", "token2charspan": [[0, 2], [3, 15], [16, 26], [26, 27], [28, 33], [34, 35], [36, 43], [44, 50], [51, 53], [54, 65], [66, 69], [70, 78], [79, 82], [83, 85], [86, 94], [95, 106], [107, 110], [111, 116], [117, 123], [124, 126], [127, 130], [131, 141], [142, 148], [149, 153], [154, 156], [157, 164], [164, 165], [166, 168], [169, 172], [173, 175], [176, 180], [181, 189], [190, 194], [195, 206], [207, 215], [216, 226], [227, 229], [230, 244], [245, 254], [255, 256], [256, 260], [260, 261], [262, 267], [268, 272], [272, 273], [274, 276], [277, 284], [285, 299], [300, 303], [304, 310], [311, 325], [325, 326]]}
{"doc_key": "ai-dev-17", "ner": [[3, 5, "misc"], [6, 8, "programlang"], [9, 12, "algorithm"], [11, 12, "algorithm"], [16, 17, "algorithm"], [23, 25, "product"], [28, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 5, 6, 8, "part-of", "", false, false], [9, 12, 3, 5, "type-of", "", false, false], [11, 12, 3, 5, "type-of", "", false, false], [16, 17, 3, 5, "type-of", "", false, false], [23, 25, 6, 8, "general-affiliation", "", true, false], [23, 25, 6, 8, "part-of", "", true, false], [28, 28, 23, 25, "role", "publishes", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Implementation", "of", "several", "whitening", "procedures", "in", "R", ",", "including", "ZCA", "and", "PCA", "whitening", ",", "but", "also", "CCA", "whitening", ",", "is", "available", "in", "the", "R", "whitening", "package", "published", "on", "CRAN", "."], "sentence-detokenized": "Implementation of several whitening procedures in R, including ZCA and PCA whitening, but also CCA whitening, is available in the R whitening package published on CRAN.", "token2charspan": [[0, 14], [15, 17], [18, 25], [26, 35], [36, 46], [47, 49], [50, 51], [51, 52], [53, 62], [63, 66], [67, 70], [71, 74], [75, 84], [84, 85], [86, 89], [90, 94], [95, 98], [99, 108], [108, 109], [110, 112], [113, 122], [123, 125], [126, 129], [130, 131], [132, 141], [142, 149], [150, 159], [160, 162], [163, 167], [167, 168]]}
{"doc_key": "ai-dev-18", "ner": [[29, 29, "product"], [31, 31, "product"], [33, 33, "product"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [42, 42, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[29, 29, 33, 33, "compare", "", false, false], [29, 29, 35, 35, "compare", "", false, false], [29, 29, 37, 37, "compare", "", false, false], [29, 29, 39, 39, "compare", "", false, false], [29, 29, 42, 42, "compare", "", false, false], [31, 31, 33, 33, "compare", "", false, false], [31, 31, 35, 35, "compare", "", false, false], [31, 31, 37, 37, "compare", "", false, false], [31, 31, 39, 39, "compare", "", false, false], [31, 31, 42, 42, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Today", ",", "the", "field", "is", "even", "more", "challenging", "and", "complex", ",", "with", "the", "addition", "of", "languages", "and", "software", "for", "circuit", ",", "system", "and", "signal", "analysis", "and", "design", ",", "from", "MATLAB", "and", "Simulink", "to", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "and", "even", "Assembly", "."], "sentence-detokenized": "Today, the field is even more challenging and complex, with the addition of languages and software for circuit, system and signal analysis and design, from MATLAB and Simulink to NumPy, VHDL, PSpice, Verilog and even Assembly.", "token2charspan": [[0, 5], [5, 6], [7, 10], [11, 16], [17, 19], [20, 24], [25, 29], [30, 41], [42, 45], [46, 53], [53, 54], [55, 59], [60, 63], [64, 72], [73, 75], [76, 85], [86, 89], [90, 98], [99, 102], [103, 110], [110, 111], [112, 118], [119, 122], [123, 129], [130, 138], [139, 142], [143, 149], [149, 150], [151, 155], [156, 162], [163, 166], [167, 175], [176, 178], [179, 184], [184, 185], [186, 190], [190, 191], [192, 198], [198, 199], [200, 207], [208, 211], [212, 216], [217, 225], [225, 226]]}
{"doc_key": "ai-dev-19", "ner": [[5, 7, "person"], [15, 16, "person"], [18, 21, "organisation"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[18, 21, 15, 16, "origin", "", false, false], [23, 23, 18, 21, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "company", "was", "founded", "by", "Kiichiro", "Toyoda", "in", "1937", "as", "a", "spin", "-", "off", "of", "Sakichi", "Toyoda", "'s", "Toyota", "Industries", ",", "which", "manufactured", "automobiles", "."], "sentence-detokenized": "The company was founded by Kiichiro Toyoda in 1937 as a spin-off of Sakichi Toyoda's Toyota Industries, which manufactured automobiles.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 35], [36, 42], [43, 45], [46, 50], [51, 53], [54, 55], [56, 60], [60, 61], [61, 64], [65, 67], [68, 75], [76, 82], [82, 84], [85, 91], [92, 102], [102, 103], [104, 109], [110, 122], [123, 134], [134, 135]]}
{"doc_key": "ai-dev-20", "ner": [[0, 6, "field"], [55, 58, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[55, 58, 0, 6, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Unsupervised", "learning", ",", "on", "the", "other", "hand", ",", "assumes", "training", "data", "that", "has", "not", "been", "manually", "labeled", "and", "attempts", "to", "find", "inherent", "patterns", "in", "the", "data", "that", "can", "then", "be", "used", "to", "determine", "the", "correct", "output", "value", "for", "new", "data", "instances", ".", "A", "combination", "of", "these", "two", "learning", "methods", "that", "has", "recently", "been", "explored", "is", "semi-direct", "learning", ",", "which", "uses", "a", "combination", "of", "labeled", "and", "unlabeled", "data", "(", "typically", "a", "small", "set", "of", "labeled", "data", "combined", "with", "a", "large", "amount", "of", "unlabeled", "data", ")", "."], "sentence-detokenized": "Unsupervised learning, on the other hand, assumes training data that has not been manually labeled and attempts to find inherent patterns in the data that can then be used to determine the correct output value for new data instances. A combination of these two learning methods that has recently been explored is semi-direct learning, which uses a combination of labeled and unlabeled data (typically a small set of labeled data combined with a large amount of unlabeled data).", "token2charspan": [[0, 12], [13, 21], [21, 22], [23, 25], [26, 29], [30, 35], [36, 40], [40, 41], [42, 49], [50, 58], [59, 63], [64, 68], [69, 72], [73, 76], [77, 81], [82, 90], [91, 98], [99, 102], [103, 111], [112, 114], [115, 119], [120, 128], [129, 137], [138, 140], [141, 144], [145, 149], [150, 154], [155, 158], [159, 163], [164, 166], [167, 171], [172, 174], [175, 184], [185, 188], [189, 196], [197, 203], [204, 209], [210, 213], [214, 217], [218, 222], [223, 232], [232, 233], [234, 235], [236, 247], [248, 250], [251, 256], [257, 260], [261, 269], [270, 277], [278, 282], [283, 286], [287, 295], [296, 300], [301, 309], [310, 312], [313, 324], [325, 333], [333, 334], [335, 340], [341, 345], [346, 347], [348, 359], [360, 362], [363, 370], [371, 374], [375, 384], [385, 389], [390, 391], [391, 400], [401, 402], [403, 408], [409, 412], [413, 415], [416, 423], [424, 428], [429, 437], [438, 442], [443, 444], [445, 450], [451, 457], [458, 460], [461, 470], [471, 475], [475, 476], [476, 477]]}
{"doc_key": "ai-dev-21", "ner": [[22, 22, "product"], [24, 26, "organisation"], [27, 27, "product"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[24, 26, 27, 27, "artifact", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Despite", "these", "humanoid", "robots", "for", "utilitarian", "purposes", ",", "there", "are", "humanoid", "robots", "that", "are", "designed", "for", "entertainment", ",", "such", "as", "Sony", "'s", "QRIO", "and", "Wow", "Wee", "'s", "RoboSapien", "."], "sentence-detokenized": "Despite these humanoid robots for utilitarian purposes, there are humanoid robots that are designed for entertainment, such as Sony's QRIO and Wow Wee's RoboSapien.", "token2charspan": [[0, 7], [8, 13], [14, 22], [23, 29], [30, 33], [34, 45], [46, 54], [54, 55], [56, 61], [62, 65], [66, 74], [75, 81], [82, 86], [87, 90], [91, 99], [100, 103], [104, 117], [117, 118], [119, 123], [124, 126], [127, 131], [131, 133], [134, 138], [139, 142], [143, 146], [147, 150], [150, 152], [153, 163], [163, 164]]}
{"doc_key": "ai-dev-22", "ner": [[2, 2, "researcher"], [8, 14, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 8, 14, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1991", "Webber", "became", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "In 1991 Webber became a member of the Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 21], [22, 23], [24, 30], [31, 33], [34, 37], [38, 49], [50, 53], [54, 57], [58, 69], [70, 72], [73, 83], [84, 96], [96, 97]]}
{"doc_key": "ai-dev-23", "ner": [[6, 7, "field"], [9, 12, "field"], [20, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 23, 6, 7, "part-of", "task_part_of_field", false, false], [20, 23, 9, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["At", "this", "company", ",", "he", "developed", "data", "mining", "and", "database", "technologies", ",", "specifically", "high", "-", "level", "ontologies", "for", "intelligence", "and", "automated", "natural", "language", "understanding", "."], "sentence-detokenized": "At this company, he developed data mining and database technologies, specifically high-level ontologies for intelligence and automated natural language understanding.", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 19], [20, 29], [30, 34], [35, 41], [42, 45], [46, 54], [55, 67], [67, 68], [69, 81], [82, 86], [86, 87], [87, 92], [93, 103], [104, 107], [108, 120], [121, 124], [125, 134], [135, 142], [143, 151], [152, 165], [165, 166]]}
{"doc_key": "ai-dev-24", "ner": [[21, 22, "misc"], [24, 27, "misc"], [31, 33, "misc"], [34, 34, "country"], [36, 38, "organisation"], [40, 40, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[21, 22, 34, 34, "physical", "", false, false], [24, 27, 34, 34, "physical", "", false, false], [31, 33, 34, 34, "physical", "", false, false], [36, 38, 40, 40, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["However", ",", "in", "recent", "years", ",", "we", "have", "seen", "various", "e-services", "and", "related", "initiatives", "emerging", "in", "developing", "countries", "such", "as", "the", "Nemmadi", "project", ",", "MCA21", "Mission", "Mode", "project", "or", "more", "so", "Digital", "India", "in", "India", ";", "Electronic", "Government", "Directorate", "in", "Pakistan", "etc", "."], "sentence-detokenized": "However, in recent years, we have seen various e-services and related initiatives emerging in developing countries such as the Nemmadi project, MCA21 Mission Mode project or more so Digital India in India; Electronic Government Directorate in Pakistan etc.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 18], [19, 24], [24, 25], [26, 28], [29, 33], [34, 38], [39, 46], [47, 57], [58, 61], [62, 69], [70, 81], [82, 90], [91, 93], [94, 104], [105, 114], [115, 119], [120, 122], [123, 126], [127, 134], [135, 142], [142, 143], [144, 149], [150, 157], [158, 162], [163, 170], [171, 173], [174, 178], [179, 181], [182, 189], [190, 195], [196, 198], [199, 204], [204, 205], [206, 216], [217, 227], [228, 239], [240, 242], [243, 251], [252, 255], [255, 256]]}
{"doc_key": "ai-dev-25", "ner": [[3, 4, "misc"], [5, 5, "field"], [7, 7, "field"], [9, 11, "university"], [12, 15, "university"], [23, 45, "university"], [28, 28, "misc"], [30, 31, "field"], [35, 37, "misc"], [39, 40, "university"], [42, 46, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 4, 5, 5, "topic", "", false, false], [3, 4, 7, 7, "topic", "", false, false], [3, 4, 9, 11, "origin", "", false, false], [9, 11, 12, 15, "part-of", "", false, false], [23, 45, 9, 11, "part-of", "", false, false], [28, 28, 30, 31, "topic", "", false, false], [28, 28, 39, 40, "origin", "", false, false], [35, 37, 39, 40, "origin", "", false, false], [39, 40, 42, 46, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["He", "received", "his", "Ph.D.", "in", "Radiophysics", "and", "Electronics", "from", "Rajabazar", "Science", "College", ",", "University", "of", "Calcutta", "in", "1979", "as", "a", "student", "of", "the", "Indian", "Statistical", "Institute", "and", "another", "Ph.D.", "in", "Electrical", "Engineering", "along", "with", "an", "Imperial", "College", "Diploma", "from", "Imperial", "College", ",", "University", "of", "London", "in", "1982", "."], "sentence-detokenized": "He received his Ph.D. in Radiophysics and Electronics from Rajabazar Science College, University of Calcutta in 1979 as a student of the Indian Statistical Institute and another Ph.D. in Electrical Engineering along with an Imperial College Diploma from Imperial College, University of London in 1982.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 21], [22, 24], [25, 37], [38, 41], [42, 53], [54, 58], [59, 68], [69, 76], [77, 84], [84, 85], [86, 96], [97, 99], [100, 108], [109, 111], [112, 116], [117, 119], [120, 121], [122, 129], [130, 132], [133, 136], [137, 143], [144, 155], [156, 165], [166, 169], [170, 177], [178, 183], [184, 186], [187, 197], [198, 209], [210, 215], [216, 220], [221, 223], [224, 232], [233, 240], [241, 248], [249, 253], [254, 262], [263, 270], [270, 271], [272, 282], [283, 285], [286, 292], [293, 295], [296, 300], [300, 301]]}
{"doc_key": "ai-dev-26", "ner": [[0, 3, "location"], [22, 24, "misc"], [30, 31, "misc"], [33, 35, "person"], [37, 38, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[22, 24, 0, 3, "temporal", "", false, false], [30, 31, 0, 3, "temporal", "", false, false], [33, 35, 30, 31, "role", "actor_in", false, false], [37, 38, 30, 31, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Expo", "II", "has", "been", "announced", "as", "the", "site", "of", "the", "world", "premiere", "of", "several", "films", "not", "yet", "seen", "in", "3D", ",", "including", "The", "Diamond", "Wizard", "and", "Universal", "'s", "short", "film", "Hawaiian", "Nights", "starring", "Mamie", "Van", "Doren", "and", "Pinky", "Lee", "."], "sentence-detokenized": "Expo II has been announced as the site of the world premiere of several films not yet seen in 3D, including The Diamond Wizard and Universal's short film Hawaiian Nights starring Mamie Van Doren and Pinky Lee.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 16], [17, 26], [27, 29], [30, 33], [34, 38], [39, 41], [42, 45], [46, 51], [52, 60], [61, 63], [64, 71], [72, 77], [78, 81], [82, 85], [86, 90], [91, 93], [94, 96], [96, 97], [98, 107], [108, 111], [112, 119], [120, 126], [127, 130], [131, 140], [140, 142], [143, 148], [149, 153], [154, 162], [163, 169], [170, 178], [179, 184], [185, 188], [189, 194], [195, 198], [199, 204], [205, 208], [208, 209]]}
{"doc_key": "ai-dev-27", "ner": [[7, 10, "researcher"], [16, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 10, 16, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "maximum", "subfield", "problem", "was", "proposed", "by", "Ulf", "Grenander", "in", "1977", "as", "a", "simplified", "model", "for", "maximum", "likelihood", "pattern", "estimation", "in", "digitized", "images", "."], "sentence-detokenized": "The maximum subfield problem was proposed by Ulf Grenander in 1977 as a simplified model for maximum likelihood pattern estimation in digitized images.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 28], [29, 32], [33, 41], [42, 44], [45, 48], [49, 58], [59, 61], [62, 66], [67, 69], [70, 71], [72, 82], [83, 88], [89, 92], [93, 100], [101, 111], [112, 119], [120, 130], [131, 133], [134, 143], [144, 150], [150, 151]]}
{"doc_key": "ai-dev-28", "ner": [[0, 1, "product"], [3, 4, "product"], [6, 8, "product"], [10, 11, "product"], [14, 15, "product"], [17, 20, "product"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[27, 27, 0, 1, "part-of", "", false, false], [27, 27, 3, 4, "part-of", "", false, false], [27, 27, 6, 8, "part-of", "", false, false], [27, 27, 10, 11, "part-of", "", false, false], [27, 27, 14, 15, "part-of", "", false, false], [27, 27, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["iPhones", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", ",", "iPod", "Touch", "5", "G", "and", "later", "feature", "the", "more", "advanced", "Siri", "voice", "assistant", "."], "sentence-detokenized": "iPhones 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G, iPod Touch 5G and later feature the more advanced Siri voice assistant.", "token2charspan": [[0, 7], [8, 10], [10, 11], [12, 16], [17, 18], [18, 19], [20, 24], [25, 29], [30, 32], [32, 33], [34, 38], [39, 42], [42, 43], [44, 48], [49, 52], [53, 55], [55, 56], [57, 61], [62, 67], [68, 69], [69, 70], [71, 74], [75, 80], [81, 88], [89, 92], [93, 97], [98, 106], [107, 111], [112, 117], [118, 127], [127, 128]]}
{"doc_key": "ai-dev-29", "ner": [[7, 8, "metrics"], [11, 14, "metrics"], [16, 21, "metrics"], [50, 52, "metrics"], [58, 61, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 14, 50, 52, "named", "", false, false], [16, 21, 11, 14, "named", "", false, false], [50, 52, 58, 61, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["It", "is", "easy", "to", "verify", "that", "the", "logistic", "loss", "and", "the", "binary", "cross", "-entropy", "loss", "(", "Log", "loss", ")", "are", "in", "fact", "the", "same", "(", "except", "for", "the", "multiplicative", "constant", "math", "\\", "frac", "{", "1", "}", ")", ".", "{", "\\", "log", "(", "2", ")", "}", "/", "math", ")", ".", "The", "cross", "-entropy", "loss", "is", "closely", "related", "to", "the", "Kullback", "-", "Leibler", "divergence", "between", "the", "empirical", "and", "predicted", "distributions", "."], "sentence-detokenized": "It is easy to verify that the logistic loss and the binary cross-entropy loss (Log loss) are in fact the same (except for the multiplicative constant math\\ frac {1}). {\\ log (2)} / math). The cross-entropy loss is closely related to the Kullback-Leibler divergence between the empirical and predicted distributions.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 20], [21, 25], [26, 29], [30, 38], [39, 43], [44, 47], [48, 51], [52, 58], [59, 64], [64, 72], [73, 77], [78, 79], [79, 82], [83, 87], [87, 88], [89, 92], [93, 95], [96, 100], [101, 104], [105, 109], [110, 111], [111, 117], [118, 121], [122, 125], [126, 140], [141, 149], [150, 154], [154, 155], [156, 160], [161, 162], [162, 163], [163, 164], [164, 165], [165, 166], [167, 168], [168, 169], [170, 173], [174, 175], [175, 176], [176, 177], [177, 178], [179, 180], [181, 185], [185, 186], [186, 187], [188, 191], [192, 197], [197, 205], [206, 210], [211, 213], [214, 221], [222, 229], [230, 232], [233, 236], [237, 245], [245, 246], [246, 253], [254, 264], [265, 272], [273, 276], [277, 286], [287, 290], [291, 300], [301, 314], [314, 315]]}
{"doc_key": "ai-dev-30", "ner": [[0, 3, "algorithm"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "EM", "algorithm", "is", "used", "to", "find", "the", "(", "local", ")", "maximum", "likelihood", "parameters", "of", "a", "statistical", "model", "in", "cases", "where", "the", "equations", "can", "not", "be", "solved", "directly", "."], "sentence-detokenized": "The EM algorithm is used to find the (local) maximum likelihood parameters of a statistical model in cases where the equations cannot be solved directly.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 32], [33, 36], [37, 38], [38, 43], [43, 44], [45, 52], [53, 63], [64, 74], [75, 77], [78, 79], [80, 91], [92, 97], [98, 100], [101, 106], [107, 112], [113, 116], [117, 126], [127, 130], [130, 133], [134, 136], [137, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-dev-31", "ner": [[10, 11, "task"], [14, 20, "task"], [23, 24, "task"], [26, 27, "task"], [34, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "research", "has", "been", "fundamental", "to", "the", "development", "of", "modern", "speech", "synthesis", "techniques", ",", "reading", "machines", "for", "the", "blind", ",", "the", "study", "of", "speech", "perception", "and", "speech", "recognition", ",", "and", "the", "development", "of", "a", "motor", "theory", "of", "speech", "perception", "."], "sentence-detokenized": "This research has been fundamental to the development of modern speech synthesis techniques, reading machines for the blind, the study of speech perception and speech recognition, and the development of a motor theory of speech perception.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 22], [23, 34], [35, 37], [38, 41], [42, 53], [54, 56], [57, 63], [64, 70], [71, 80], [81, 91], [91, 92], [93, 100], [101, 109], [110, 113], [114, 117], [118, 123], [123, 124], [125, 128], [129, 134], [135, 137], [138, 144], [145, 155], [156, 159], [160, 166], [167, 178], [178, 179], [180, 183], [184, 187], [188, 199], [200, 202], [203, 204], [205, 210], [211, 217], [218, 220], [221, 227], [228, 238], [238, 239]]}
{"doc_key": "ai-dev-32", "ner": [[0, 1, "product"], [2, 4, "misc"], [6, 6, "misc"], [10, 12, "misc"], [15, 15, "product"], [17, 17, "product"], [19, 19, "product"], [24, 24, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 0, 1, "origin", "", false, false], [2, 4, 10, 12, "type-of", "", false, false], [2, 4, 15, 15, "related-to", "program_for", false, false], [2, 4, 17, 17, "related-to", "program_for", false, false], [2, 4, 19, 19, "related-to", "program_for", false, false], [2, 4, 24, 24, "related-to", "program_for", false, false], [6, 6, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "Arduino", "Integrated", "Development", "Environment", "(", "IDE", ")", "is", "a", "cross", "-platform", "application", "(", "for", "Windows", ",", "MacOS", "and", "Linux", ")", "written", "in", "the", "Java", "programming", "language", "."], "sentence-detokenized": "The Arduino Integrated Development Environment (IDE) is a cross-platform application (for Windows, MacOS and Linux) written in the Java programming language.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 57], [58, 63], [63, 72], [73, 84], [85, 86], [86, 89], [90, 97], [97, 98], [99, 104], [105, 108], [109, 114], [114, 115], [116, 123], [124, 126], [127, 130], [131, 135], [136, 147], [148, 156], [156, 157]]}
{"doc_key": "ai-dev-33", "ner": [[0, 1, "algorithm"], [8, 9, "field"], [11, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 8, 9, "opposite", "", false, false], [11, 13, 8, 9, "related-to", "works_with", false, false], [15, 16, 8, 9, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Neural", "network", "research", "stagnated", "after", "the", "publication", "of", "machine", "learning", "research", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", "."], "sentence-detokenized": "Neural network research stagnated after the publication of machine learning research by Marvin Minsky and Seymour Papert (1969).", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 33], [34, 39], [40, 43], [44, 55], [56, 58], [59, 66], [67, 75], [76, 84], [85, 87], [88, 94], [95, 101], [102, 105], [106, 113], [114, 120], [121, 122], [122, 126], [126, 127], [127, 128]]}
{"doc_key": "ai-dev-34", "ner": [[21, 22, "organisation"], [24, 24, "organisation"], [26, 28, "country"], [30, 33, "organisation"], [35, 35, "country"], [37, 38, "organisation"], [40, 40, "country"], [42, 42, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[30, 33, 26, 28, "general-affiliation", "", false, false], [37, 38, 35, 35, "general-affiliation", "", false, false], [42, 42, 40, 40, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["In", "the", "end", ",", "only", "a", "few", "non-Japanese", "companies", "have", "established", "themselves", "in", "this", "market", ",", "the", "main", "ones", "being", ":", "Adept", "Technology", ",", "St\u00e4ubli", ",", "Swedish", "-", "Swiss", "company", "ABB", "Asea", "Brown", "Boveri", ",", "German", "company", "KUKA", "Robotics", "and", "Italian", "company", "Comau", "."], "sentence-detokenized": "In the end, only a few non-Japanese companies have established themselves in this market, the main ones being: Adept Technology, St\u00e4ubli, Swedish-Swiss company ABB Asea Brown Boveri, German company KUKA Robotics and Italian company Comau.", "token2charspan": [[0, 2], [3, 6], [7, 10], [10, 11], [12, 16], [17, 18], [19, 22], [23, 35], [36, 45], [46, 50], [51, 62], [63, 73], [74, 76], [77, 81], [82, 88], [88, 89], [90, 93], [94, 98], [99, 103], [104, 109], [109, 110], [111, 116], [117, 127], [127, 128], [129, 136], [136, 137], [138, 145], [145, 146], [146, 151], [152, 159], [160, 163], [164, 168], [169, 174], [175, 181], [181, 182], [183, 189], [190, 197], [198, 202], [203, 211], [212, 215], [216, 223], [224, 231], [232, 237], [237, 238]]}
{"doc_key": "ai-dev-35", "ner": [[5, 10, "conference"], [13, 13, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 13, 5, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Research", "activities", "include", "the", "annual", "RuleML", "Symposium", "research", "conference", ",", "also", "known", "as", "RuleML", "."], "sentence-detokenized": "Research activities include the annual RuleML Symposium research conference, also known as RuleML.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 31], [32, 38], [39, 45], [46, 55], [56, 64], [65, 75], [75, 76], [77, 81], [82, 87], [88, 90], [91, 97], [97, 98]]}
{"doc_key": "ai-dev-36", "ner": [[9, 9, "field"], [11, 12, "field"], [14, 14, "field"], [16, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Concepts", "are", "used", "as", "formal", "tools", "or", "models", "in", "mathematics", ",", "computer", "science", ",", "databases", "and", "artificial", "intelligence", ",", "where", "they", "are", "sometimes", "called", "classes", ",", "schemas", "or", "categories", "."], "sentence-detokenized": "Concepts are used as formal tools or models in mathematics, computer science, databases and artificial intelligence, where they are sometimes called classes, schemas or categories.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 33], [34, 36], [37, 43], [44, 46], [47, 58], [58, 59], [60, 68], [69, 76], [76, 77], [78, 87], [88, 91], [92, 102], [103, 115], [115, 116], [117, 122], [123, 127], [128, 131], [132, 141], [142, 148], [149, 156], [156, 157], [158, 165], [166, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-dev-37", "ner": [[6, 8, "organisation"], [11, 14, "organisation"], [17, 20, "organisation"], [21, 24, "organisation"], [28, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "received", "awards", "from", "the", "American", "Psychological", "Association", ",", "the", "National", "Academy", "of", "Sciences", ",", "the", "Royal", "Society", ",", "the", "Society", "for", "Cognitive", "Neuroscience", ",", "and", "the", "American", "Humanist", "Association", "."], "sentence-detokenized": "He has received awards from the American Psychological Association, the National Academy of Sciences, the Royal Society, the Society for Cognitive Neuroscience, and the American Humanist Association.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 22], [23, 27], [28, 31], [32, 40], [41, 54], [55, 66], [66, 67], [68, 71], [72, 80], [81, 88], [89, 91], [92, 100], [100, 101], [102, 105], [106, 111], [112, 119], [119, 120], [121, 124], [125, 132], [133, 136], [137, 146], [147, 159], [159, 160], [161, 164], [165, 168], [169, 177], [178, 186], [187, 198], [198, 199]]}
{"doc_key": "ai-dev-38", "ner": [[4, 5, "person"], [7, 8, "person"], [10, 13, "person"], [19, 47, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "film", ",", "starring", "Harrison", "Ford", ",", "Rutger", "Hauer", "and", "Sean", "Young", ",", "is", "loosely", "based", "on", "the", "novel", "by", "Philip", "K", ".", "Dick", "'s", "film", ",", "which", "is", "based", "on", "a", "film", "written", "by", "Philip", "K", ".", "Ford", "and", "based", "on", "a", "film", "by", "Philip", "K.", "Ford.", "(", "1968", ")", "."], "sentence-detokenized": "The film, starring Harrison Ford, Rutger Hauer and Sean Young, is loosely based on the novel by Philip K. Dick's film, which is based on a film written by Philip K. Ford and based on a film by Philip K. Ford. (1968).", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 18], [19, 27], [28, 32], [32, 33], [34, 40], [41, 46], [47, 50], [51, 55], [56, 61], [61, 62], [63, 65], [66, 73], [74, 79], [80, 82], [83, 86], [87, 92], [93, 95], [96, 102], [103, 104], [104, 105], [106, 110], [110, 112], [113, 117], [117, 118], [119, 124], [125, 127], [128, 133], [134, 136], [137, 138], [139, 143], [144, 151], [152, 154], [155, 161], [162, 163], [163, 164], [165, 169], [170, 173], [174, 179], [180, 182], [183, 184], [185, 189], [190, 192], [193, 199], [200, 202], [203, 208], [209, 210], [210, 214], [214, 215], [215, 216]]}
{"doc_key": "ai-dev-39", "ner": [[0, 1, "task"], [3, 5, "algorithm"], [11, 12, "field"], [14, 15, "task"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 3, 5, "usage", "", false, false], [0, 1, 11, 12, "part-of", "task_part_of_field", false, false], [0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 18, 19, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Image", "segmentation", "using", "k-means", "clustering", "algorithms", "has", "long", "been", "used", "for", "pattern", "recognition", ",", "object", "detection", ",", "and", "medical", "imaging", "."], "sentence-detokenized": "Image segmentation using k-means clustering algorithms has long been used for pattern recognition, object detection, and medical imaging.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 32], [33, 43], [44, 54], [55, 58], [59, 63], [64, 68], [69, 73], [74, 77], [78, 85], [86, 97], [97, 98], [99, 105], [106, 115], [115, 116], [117, 120], [121, 128], [129, 136], [136, 137]]}
{"doc_key": "ai-dev-40", "ner": [[14, 14, "algorithm"], [17, 18, "algorithm"], [31, 31, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["General", "sampling", "from", "the", "truncated", "normal", "can", "be", "done", "using", "approximations", "of", "the", "normal", "CDF", "and", "the", "probit", "function", ",", "and", "there", "is", "a", "codertnorm", "(", ")", "/", "code", "function", "in", "R", "for", "generating", "truncated", "normal", "samples", "."], "sentence-detokenized": "General sampling from the truncated normal can be done using approximations of the normal CDF and the probit function, and there is a codertnorm()/code function in R for generating truncated normal samples.", "token2charspan": [[0, 7], [8, 16], [17, 21], [22, 25], [26, 35], [36, 42], [43, 46], [47, 49], [50, 54], [55, 60], [61, 75], [76, 78], [79, 82], [83, 89], [90, 93], [94, 97], [98, 101], [102, 108], [109, 117], [117, 118], [119, 122], [123, 128], [129, 131], [132, 133], [134, 144], [144, 145], [145, 146], [146, 147], [147, 151], [152, 160], [161, 163], [164, 165], [166, 169], [170, 180], [181, 190], [191, 197], [198, 205], [205, 206]]}
{"doc_key": "ai-dev-41", "ner": [[8, 10, "university"], [12, 12, "university"], [14, 15, "university"], [17, 19, "university"], [22, 24, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "also", "received", "honorary", "doctorates", "from", "the", "Universities", "of", "Newcastle", ",", "Surrey", ",", "Tel", "Aviv", ",", "Simon", "Fraser", "University", "and", "the", "University", "of", "Troms\u00f8", "."], "sentence-detokenized": "He has also received honorary doctorates from the Universities of Newcastle, Surrey, Tel Aviv, Simon Fraser University and the University of Troms\u00f8.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 29], [30, 40], [41, 45], [46, 49], [50, 62], [63, 65], [66, 75], [75, 76], [77, 83], [83, 84], [85, 88], [89, 93], [93, 94], [95, 100], [101, 107], [108, 118], [119, 122], [123, 126], [127, 137], [138, 140], [141, 147], [147, 148]]}
{"doc_key": "ai-dev-42", "ner": [[0, 1, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "Java", "implementation", "using", "zero", "-", "based", "array", "indices", "along", "with", "a", "convenient", "method", "for", "listing", "the", "resolved", "order", "of", "operations", ":"], "sentence-detokenized": "A Java implementation using zero-based array indices along with a convenient method for listing the resolved order of operations:", "token2charspan": [[0, 1], [2, 6], [7, 21], [22, 27], [28, 32], [32, 33], [33, 38], [39, 44], [45, 52], [53, 58], [59, 63], [64, 65], [66, 76], [77, 83], [84, 87], [88, 95], [96, 99], [100, 108], [109, 114], [115, 117], [118, 128], [128, 129]]}
{"doc_key": "ai-dev-43", "ner": [[6, 7, "metrics"], [10, 16, "metrics"], [21, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 16, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Such", "networks", "are", "commonly", "trained", "in", "cross", "-entropy", "(", "or", "cross", "-entropy", ")", "mode", ",", "which", "is", "a", "nonlinear", "variant", "of", "multinomial", "logistic", "regression", "."], "sentence-detokenized": "Such networks are commonly trained in cross-entropy (or cross-entropy) mode, which is a nonlinear variant of multinomial logistic regression.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 26], [27, 34], [35, 37], [38, 43], [43, 51], [52, 53], [53, 55], [56, 61], [61, 69], [69, 70], [71, 75], [75, 76], [77, 82], [83, 85], [86, 87], [88, 97], [98, 105], [106, 108], [109, 120], [121, 129], [130, 140], [140, 141]]}
{"doc_key": "ai-dev-44", "ner": [[0, 0, "conference"], [3, 5, "misc"], [7, 10, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["ACL", "has", "a", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", "."], "sentence-detokenized": "ACL has a European Chapter of the Association for Computational Linguistics.", "token2charspan": [[0, 3], [4, 7], [8, 9], [10, 18], [19, 26], [27, 29], [30, 33], [34, 45], [46, 49], [50, 63], [64, 75], [75, 76]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 11, "researcher"], [22, 22, "misc"], [24, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 22, 22, "role", "", false, false], [6, 11, 22, 22, "role", "", false, false], [22, 22, 24, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "professors", ",", "Hal", "Abelson", "and", "Gerald", "Jay", "Sussman", ",", "chose", "to", "remain", "neutral", "-", "their", "group", "was", "referred", "to", "variously", "as", "Switzerland", "and", "Project", "MAC", "for", "the", "next", "30", "years", "."], "sentence-detokenized": "Two professors, Hal Abelson and Gerald Jay Sussman, chose to remain neutral - their group was referred to variously as Switzerland and Project MAC for the next 30 years.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 50], [50, 51], [52, 57], [58, 60], [61, 67], [68, 75], [76, 77], [78, 83], [84, 89], [90, 93], [94, 102], [103, 105], [106, 115], [116, 118], [119, 130], [131, 134], [135, 142], [143, 146], [147, 150], [151, 154], [155, 159], [160, 162], [163, 168], [168, 169]]}
{"doc_key": "ai-dev-46", "ner": [[1, 3, "misc"], [5, 5, "researcher"], [9, 11, "university"], [16, 20, "organisation"], [21, 25, "organisation"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 3, 5, 5, "temporal", "", false, false], [5, 5, 16, 20, "physical", "", false, false], [5, 5, 16, 20, "role", "", false, false], [5, 5, 21, 25, "role", "", false, false], [21, 25, 9, 11, "part-of", "", false, false], [27, 28, 21, 25, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["After", "earning", "his", "PhD", ",", "Ghahramani", "moved", "to", "the", "University", "of", "Toronto", "in", "1995", "as", "an", "ITRC", "postdoctoral", "fellow", "in", "the", "Artificial", "Intelligence", "Lab", ",", "working", "with", "Geoffrey", "Hinton", "."], "sentence-detokenized": "After earning his PhD, Ghahramani moved to the University of Toronto in 1995 as an ITRC postdoctoral fellow in the Artificial Intelligence Lab, working with Geoffrey Hinton.", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 21], [21, 22], [23, 33], [34, 39], [40, 42], [43, 46], [47, 57], [58, 60], [61, 68], [69, 71], [72, 76], [77, 79], [80, 82], [83, 87], [88, 100], [101, 107], [108, 110], [111, 114], [115, 125], [126, 138], [139, 142], [142, 143], [144, 151], [152, 156], [157, 165], [166, 172], [172, 173]]}
{"doc_key": "ai-dev-47", "ner": [[23, 24, "metrics"], [27, 27, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[27, 27, 23, 24, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Subsequent", "work", "focused", "on", "solving", "these", "problems", ",", "but", "it", "was", "only", "with", "the", "advent", "of", "the", "modern", "computer", "and", "the", "popularization", "of", "maximum", "likelihood", "parameterization", "(", "MLE", ")", "techniques", "that", "research", "really", "took", "off", "."], "sentence-detokenized": "Subsequent work focused on solving these problems, but it was only with the advent of the modern computer and the popularization of maximum likelihood parameterization (MLE) techniques that research really took off.", "token2charspan": [[0, 10], [11, 15], [16, 23], [24, 26], [27, 34], [35, 40], [41, 49], [49, 50], [51, 54], [55, 57], [58, 61], [62, 66], [67, 71], [72, 75], [76, 82], [83, 85], [86, 89], [90, 96], [97, 105], [106, 109], [110, 113], [114, 128], [129, 131], [132, 139], [140, 150], [151, 167], [168, 169], [169, 172], [172, 173], [174, 184], [185, 189], [190, 198], [199, 205], [206, 210], [211, 214], [214, 215]]}
{"doc_key": "ai-dev-48", "ner": [[5, 7, "person"], [9, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "series", "was", "produced", "by", "David", "Fincher", "and", "starred", "Kevin", "Spacey", "."], "sentence-detokenized": "The series was produced by David Fincher and starred Kevin Spacey.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 40], [41, 44], [45, 52], [53, 58], [59, 65], [65, 66]]}
{"doc_key": "ai-dev-49", "ner": [[16, 19, "metrics"], [22, 23, "algorithm"], [31, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 23, 31, 33, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Due", "to", "limited", "computational", "power", ",", "current", "in", "silico", "methods", "usually", "have", "to", "trade", "speed", "for", "accuracy", ";", "for", "example", ",", "fast", "protein", "docking", "methods", "are", "used", "instead", "of", "computationally", "expensive", "free", "energy", "calculations", "."], "sentence-detokenized": "Due to limited computational power, current in silico methods usually have to trade speed for accuracy; for example, fast protein docking methods are used instead of computationally expensive free energy calculations.", "token2charspan": [[0, 3], [4, 6], [7, 14], [15, 28], [29, 34], [34, 35], [36, 43], [44, 46], [47, 53], [54, 61], [62, 69], [70, 74], [75, 77], [78, 83], [84, 89], [90, 93], [94, 102], [102, 103], [104, 107], [108, 115], [115, 116], [117, 121], [122, 129], [130, 137], [138, 145], [146, 149], [150, 154], [155, 162], [163, 165], [166, 181], [182, 191], [192, 196], [197, 203], [204, 216], [216, 217]]}
{"doc_key": "ai-dev-50", "ner": [[8, 8, "country"], [10, 10, "country"], [12, 12, "country"], [14, 14, "country"], [16, 16, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "had", "more", "than", "30", "branches", "in", "the", "USA", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "sentence-detokenized": "It had more than 30 branches in the USA, Canada, Mexico, Brazil and Argentina.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 19], [20, 28], [29, 31], [32, 35], [36, 39], [39, 40], [41, 47], [47, 48], [49, 55], [55, 56], [57, 63], [64, 67], [68, 77], [77, 78]]}
{"doc_key": "ai-dev-51", "ner": [[4, 9, "field"], [10, 12, "product"], [14, 16, "algorithm"], [19, 20, "task"], [22, 23, "task"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 12, 4, 9, "part-of", "", false, false], [10, 12, 14, 16, "usage", "", false, false], [19, 20, 4, 9, "part-of", "task_part_of_field", false, false], [19, 20, 30, 30, "related-to", "performs", false, false], [22, 23, 4, 9, "part-of", "task_part_of_field", false, false], [22, 23, 30, 30, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Example", "of", "a", "typical", "computer", "vision", "computational", "pipeline", "for", "a", "face", "recognition", "system", "using", "k", "-", "NN", ",", "including", "feature", "extraction", "and", "dimension", "reduction", "preprocessing", "steps", "(", "typically", "implemented", "using", "OpenCV", ")", ":"], "sentence-detokenized": "Example of a typical computer vision computational pipeline for a face recognition system using k -NN, including feature extraction and dimension reduction preprocessing steps (typically implemented using OpenCV):", "token2charspan": [[0, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 36], [37, 50], [51, 59], [60, 63], [64, 65], [66, 70], [71, 82], [83, 89], [90, 95], [96, 97], [98, 99], [99, 101], [101, 102], [103, 112], [113, 120], [121, 131], [132, 135], [136, 145], [146, 155], [156, 169], [170, 175], [176, 177], [177, 186], [187, 198], [199, 204], [205, 211], [211, 212], [212, 213]]}
{"doc_key": "ai-dev-52", "ner": [[9, 10, "algorithm"], [12, 13, "misc"], [15, 16, "misc"], [18, 20, "misc"], [24, 24, "programlang"], [26, 26, "product"], [30, 31, "algorithm"], [33, 34, "misc"], [36, 36, "misc"], [38, 38, "misc"], [40, 40, "misc"], [47, 47, "misc"], [49, 51, "misc"], [53, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "a", "rich", "feature", "set", ",", "libraries", "for", "constraint", "programming", ",", "multi-threaded", "programming", ",", "unit", "testing", ",", "graphical", "user", "interface", ",", "interfacing", "with", "Java", ",", "ODBC", "and", "others", ",", "literate", "programming", ",", "web", "server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "developer", "tools", "(", "including", "an", "IDE", "with", "graphical", "debugging", "interface", "and", "graphical", "profiler", ")", "and", "extensive", "documentation", "."], "sentence-detokenized": "It has a rich feature set, libraries for constraint programming, multi-threaded programming, unit testing, graphical user interface, interfacing with Java, ODBC and others, literate programming, web server, SGML, RDF, RDFS, developer tools (including an IDE with graphical debugging interface and graphical profiler) and extensive documentation.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 13], [14, 21], [22, 25], [25, 26], [27, 36], [37, 40], [41, 51], [52, 63], [63, 64], [65, 79], [80, 91], [91, 92], [93, 97], [98, 105], [105, 106], [107, 116], [117, 121], [122, 131], [131, 132], [133, 144], [145, 149], [150, 154], [154, 155], [156, 160], [161, 164], [165, 171], [171, 172], [173, 181], [182, 193], [193, 194], [195, 198], [199, 205], [205, 206], [207, 211], [211, 212], [213, 216], [216, 217], [218, 222], [222, 223], [224, 233], [234, 239], [240, 241], [241, 250], [251, 253], [254, 257], [258, 262], [263, 272], [273, 282], [283, 292], [293, 296], [297, 306], [307, 315], [315, 316], [317, 320], [321, 330], [331, 344], [344, 345]]}
{"doc_key": "ai-dev-53", "ner": [[1, 2, "field"], [4, 17, "field"], [10, 12, "misc"], [14, 18, "misc"], [21, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 1, 2, "part-of", "", true, false], [10, 12, 4, 17, "part-of", "", false, false], [10, 12, 21, 24, "type-of", "", false, false], [14, 18, 1, 2, "part-of", "", false, false], [14, 18, 4, 17, "part-of", "", false, false], [14, 18, 21, 24, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "computer", "vision", "and", "image", "processing", ",", "the", "notion", "of", "scale", "space", "representation", "and", "Gaussian", "derivative", "operators", "are", "used", "as", "a", "canonical", "multi", "-scale", "representation", "."], "sentence-detokenized": "In computer vision and image processing, the notion of scale space representation and Gaussian derivative operators are used as a canonical multi-scale representation.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 22], [23, 28], [29, 39], [39, 40], [41, 44], [45, 51], [52, 54], [55, 60], [61, 66], [67, 81], [82, 85], [86, 94], [95, 105], [106, 115], [116, 119], [120, 124], [125, 127], [128, 129], [130, 139], [140, 145], [145, 151], [152, 166], [166, 167]]}
{"doc_key": "ai-dev-54", "ner": [[6, 10, "organisation"], [19, 24, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 10, 19, 24, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "also", "president", "of", "the", "Neural", "Information", "Processing", "Systems", "Foundation", ",", "a", "non-profit", "organization", "that", "sponsors", "an", "annual", "conference", "on", "neural", "information", "processing", "systems", "."], "sentence-detokenized": "He is also president of the Neural Information Processing Systems Foundation, a non-profit organization that sponsors an annual conference on neural information processing systems.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 20], [21, 23], [24, 27], [28, 34], [35, 46], [47, 57], [58, 65], [66, 76], [76, 77], [78, 79], [80, 90], [91, 103], [104, 108], [109, 117], [118, 120], [121, 127], [128, 138], [139, 141], [142, 148], [149, 160], [161, 171], [172, 179], [179, 180]]}
{"doc_key": "ai-dev-55", "ner": [[1, 2, "task"], [6, 17, "metrics"], [9, 14, "misc"], [24, 24, "task"], [18, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 6, 17, "usage", "", false, false], [6, 17, 9, 14, "type-of", "", false, false], [24, 24, 18, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["For", "regression", "analysis", "problems", ",", "the", "quadratic", "error", "can", "be", "used", "as", "the", "loss", "function", ",", "and", "the", "cross", "entropy", "can", "be", "used", "for", "classification", "."], "sentence-detokenized": "For regression analysis problems, the quadratic error can be used as the loss function, and the cross entropy can be used for classification.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 32], [32, 33], [34, 37], [38, 47], [48, 53], [54, 57], [58, 60], [61, 65], [66, 68], [69, 72], [73, 77], [78, 86], [86, 87], [88, 91], [92, 95], [96, 101], [102, 109], [110, 113], [114, 116], [117, 121], [122, 125], [126, 140], [140, 141]]}
{"doc_key": "ai-dev-56", "ner": [[0, 0, "researcher"], [23, 23, "university"], [18, 22, "field"], [34, 119, "conference"]], "ner_mapping_to_source": [0, 3, 4, 5], "relations": [[0, 0, 23, 23, "physical", "", false, false], [0, 0, 23, 23, "role", "", false, false], [0, 0, 34, 119, "role", "", false, false], [23, 23, 18, 22, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [1, 2, 3, 5], "sentence": ["Lafferty", "has", "held", "a", "number", "of", "prestigious", "positions", ",", "including", ":", "2", ")", "Co-", "Director", "of", "the", "new", "Machine", "Learning", "PhD", "program", "at", "CMU", ";", "3", ")", "Deputy", "Editor", "-", "in", "-", "Chief", "of", "the", "Journal", "of", "Machine", "Learning", "Research", ";", "4", ")", "Deputy", "Editor", "-", "in", "-", "Chief", "of", "the", "Journal", "of", "Machine", "Learning", "Research", ";", "5", ")", "Deputy", "Editor", "-", "in", "-", "Chief", "of", "the", "Journal", "of", "Machine", "Learning", "Research", ";", "6", ")", "Deputy", "Editor", "-", "in", "-", "Chief", "of", "the", "Journal", "of", "Machine", "Learning", "Research", ";", "7", ")", "Deputy", "Editor", "-", "in", "-", "Chief", "of", "the", "Journal", "of", "Machine", "Learning", "Research", ";", "8", ")", "Deputy", "Editor", "-", "in", "-", "Chief", "of", "the", "Journal", "of", "Machine", "Learning", "Research", "."], "sentence-detokenized": "Lafferty has held a number of prestigious positions, including: 2) Co-Director of the new Machine Learning PhD program at CMU; 3) Deputy Editor-in-Chief of the Journal of Machine Learning Research; 4) Deputy Editor-in-Chief of the Journal of Machine Learning Research; 5) Deputy Editor-in-Chief of the Journal of Machine Learning Research; 6) Deputy Editor-in-Chief of the Journal of Machine Learning Research; 7) Deputy Editor-in-Chief of the Journal of Machine Learning Research; 8) Deputy Editor-in-Chief of the Journal of Machine Learning Research.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 19], [20, 26], [27, 29], [30, 41], [42, 51], [51, 52], [53, 62], [62, 63], [64, 65], [65, 66], [67, 70], [70, 78], [79, 81], [82, 85], [86, 89], [90, 97], [98, 106], [107, 110], [111, 118], [119, 121], [122, 125], [125, 126], [127, 128], [128, 129], [130, 136], [137, 143], [143, 144], [144, 146], [146, 147], [147, 152], [153, 155], [156, 159], [160, 167], [168, 170], [171, 178], [179, 187], [188, 196], [196, 197], [198, 199], [199, 200], [201, 207], [208, 214], [214, 215], [215, 217], [217, 218], [218, 223], [224, 226], [227, 230], [231, 238], [239, 241], [242, 249], [250, 258], [259, 267], [267, 268], [269, 270], [270, 271], [272, 278], [279, 285], [285, 286], [286, 288], [288, 289], [289, 294], [295, 297], [298, 301], [302, 309], [310, 312], [313, 320], [321, 329], [330, 338], [338, 339], [340, 341], [341, 342], [343, 349], [350, 356], [356, 357], [357, 359], [359, 360], [360, 365], [366, 368], [369, 372], [373, 380], [381, 383], [384, 391], [392, 400], [401, 409], [409, 410], [411, 412], [412, 413], [414, 420], [421, 427], [427, 428], [428, 430], [430, 431], [431, 436], [437, 439], [440, 443], [444, 451], [452, 454], [455, 462], [463, 471], [472, 480], [480, 481], [482, 483], [483, 484], [485, 491], [492, 498], [498, 499], [499, 501], [501, 502], [502, 507], [508, 510], [511, 514], [515, 522], [523, 525], [526, 533], [534, 542], [543, 551], [551, 552]]}
{"doc_key": "ai-dev-57", "ner": [[0, 3, "misc"], [4, 4, "algorithm"], [6, 6, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 0, 3, "type-of", "", false, false], [6, 6, 0, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Convex", "algorithms", "such", "as", "AdaBoost", "and", "LogitBoost", "can", "be", "defeated", "by", "random", "noise", ",", "so", "they", "can", "not", "learn", "basic", "and", "learnable", "combinations", "of", "weak", "hypotheses", "."], "sentence-detokenized": "Convex algorithms such as AdaBoost and LogitBoost can be defeated by random noise, so they cannot learn basic and learnable combinations of weak hypotheses.", "token2charspan": [[0, 6], [7, 17], [18, 22], [23, 25], [26, 34], [35, 38], [39, 49], [50, 53], [54, 56], [57, 65], [66, 68], [69, 75], [76, 81], [81, 82], [83, 85], [86, 90], [91, 94], [94, 97], [98, 103], [104, 109], [110, 113], [114, 123], [124, 136], [137, 139], [140, 144], [145, 155], [155, 156]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [3, 7, "product"], [9, 13, "algorithm"], [14, 15, "algorithm"], [22, 25, "task"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 7, "type-of", "", false, false], [0, 0, 9, 13, "usage", "", false, false], [0, 0, 14, 15, "usage", "", false, false], [14, 15, 22, 25, "related-to", "used_for", true, false], [14, 15, 27, 29, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "is", "a", "shallow", "machine", "translation", "system", "that", "uses", "finite", "-", "state", "transducers", "and", "hidden", "Markov", "models", "for", "all", "lexical", "transformations", "to", "label", "parts", "of", "speech", "or", "disambiguate", "word", "categories", "."], "sentence-detokenized": "Apertium is a shallow machine translation system that uses finite-state transducers and hidden Markov models for all lexical transformations to label parts of speech or disambiguate word categories.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 21], [22, 29], [30, 41], [42, 48], [49, 53], [54, 58], [59, 65], [65, 66], [66, 71], [72, 83], [84, 87], [88, 94], [95, 101], [102, 108], [109, 112], [113, 116], [117, 124], [125, 140], [141, 143], [144, 149], [150, 155], [156, 158], [159, 165], [166, 168], [169, 181], [182, 186], [187, 197], [197, 198]]}
{"doc_key": "ai-dev-59", "ner": [[0, 2, "misc"], [13, 16, "metrics"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 13, 16, "related-to", "", true, false], [13, 16, 29, 31, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "natural", "gradient", "mathE", "f", "(", "x", ")", "/", "math", ",", "corresponding", "to", "Fisher", "'s", "information", "metric", "(", "an", "information", "measure", "of", "the", "distance", "between", "probability", "distributions", "and", "the", "relative", "entropy", "curve", ")", ",", "now", "reads"], "sentence-detokenized": "The natural gradient mathE f (x) / math, corresponding to Fisher's information metric (an information measure of the distance between probability distributions and the relative entropy curve), now reads", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 26], [27, 28], [29, 30], [30, 31], [31, 32], [33, 34], [35, 39], [39, 40], [41, 54], [55, 57], [58, 64], [64, 66], [67, 78], [79, 85], [86, 87], [87, 89], [90, 101], [102, 109], [110, 112], [113, 116], [117, 125], [126, 133], [134, 145], [146, 159], [160, 163], [164, 167], [168, 176], [177, 184], [185, 190], [190, 191], [191, 192], [193, 196], [197, 202]]}
{"doc_key": "ai-dev-60", "ner": [[0, 3, "programlang"], [6, 9, "product"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 0, 3, "origin", "", false, false], [11, 11, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "S", "programming", "language", "inspired", "the", "S", "'", "-", "PLUS", "and", "R", "systems", "."], "sentence-detokenized": "The S programming language inspired the S '-PLUS and R systems.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 26], [27, 35], [36, 39], [40, 41], [42, 43], [43, 44], [44, 48], [49, 52], [53, 54], [55, 62], [62, 63]]}
{"doc_key": "ai-dev-61", "ner": [[5, 6, "product"], [7, 7, "product"], [10, 14, "product"], [16, 18, "researcher"], [20, 21, "researcher"], [24, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 7, 7, "named", "same", false, false], [10, 14, 7, 7, "origin", "derived_from", false, false], [10, 14, 16, 18, "origin", "", false, false], [10, 14, 20, 21, "origin", "", false, false], [10, 14, 24, 25, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "most", "influential", "implementation", "of", "Planner", "was", "a", "subset", "called", "Micro", "-", "Planner", ",", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", ",", "and", "Terry", "Winograd", "."], "sentence-detokenized": "The most influential implementation of Planner was a subset called Micro-Planner, implemented by Gerald Jay Sussman, Eugene Charniak, and Terry Winograd.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 35], [36, 38], [39, 46], [47, 50], [51, 52], [53, 59], [60, 66], [67, 72], [72, 73], [73, 80], [80, 81], [82, 93], [94, 96], [97, 103], [104, 107], [108, 115], [115, 116], [117, 123], [124, 132], [132, 133], [134, 137], [138, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-dev-62", "ner": [[3, 6, "country"], [8, 10, "researcher"], [19, 20, "misc"], [21, 28, "university"], [33, 35, "misc"], [40, 40, "misc"], [47, 49, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[8, 10, 3, 6, "general-affiliation", "from_country", false, false], [21, 28, 19, 20, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1779", ",", "the", "German", "-", "Danish", "scientist", "Christian", "Gottlieb", "Kratzenstein", "won", "first", "prize", "in", "a", "competition", "held", "by", "the", "Russian", "Imperial", "Academy", "of", "Sciences", "and", "Arts", "for", "his", "models", "of", "the", "human", "vocal", "tract", "that", "could", "produce", "five", "long", "vowels", "(", "in", "the", "notation", "of", "the", "International", "Phonetic", "Alphabet", ":"], "sentence-detokenized": "In 1779, the German-Danish scientist Christian Gottlieb Kratzenstein won first prize in a competition held by the Russian Imperial Academy of Sciences and Arts for his models of the human vocal tract that could produce five long vowels (in the notation of the International Phonetic Alphabet:", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [19, 20], [20, 26], [27, 36], [37, 46], [47, 55], [56, 68], [69, 72], [73, 78], [79, 84], [85, 87], [88, 89], [90, 101], [102, 106], [107, 109], [110, 113], [114, 121], [122, 130], [131, 138], [139, 141], [142, 150], [151, 154], [155, 159], [160, 163], [164, 167], [168, 174], [175, 177], [178, 181], [182, 187], [188, 193], [194, 199], [200, 204], [205, 210], [211, 218], [219, 223], [224, 228], [229, 235], [236, 237], [237, 239], [240, 243], [244, 252], [253, 255], [256, 259], [260, 273], [274, 282], [283, 291], [291, 292]]}
{"doc_key": "ai-dev-63", "ner": [[3, 4, "product"], [6, 7, "misc"], [10, 15, "misc"], [32, 35, "misc"], [53, 55, "task"], [59, 60, "product"], [62, 62, "product"], [66, 69, "task"], [68, 70, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 4, 59, 60, "related-to", "supports_program", false, false], [3, 4, 62, 62, "related-to", "supports_program", false, false], [6, 7, 3, 4, "part-of", "", false, false], [10, 15, 3, 4, "part-of", "", false, false], [32, 35, 3, 4, "part-of", "", false, false], [53, 55, 3, 4, "part-of", "", false, false], [66, 69, 3, 4, "part-of", "", false, false], [68, 70, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["New", "features", "in", "Office", "XP", "include", "smart", "tags", ",", "a", "selection", "-", "based", "search", "feature", "that", "recognizes", "different", "types", "of", "text", "in", "a", "document", "so", "users", "can", "perform", "additional", "actions", ";", "a", "task", "pane", "interface", "that", "groups", "popular", "menu", "bar", "commands", "on", "the", "right", "side", "of", "the", "screen", "for", "quick", "access", ";", "new", "document", "collaboration", "capabilities", ",", "support", "for", "MSN", "Groups", "and", "SharePoint", ";", "and", "integrated", "handwriting", "and", "speech", "recognition", "features", "."], "sentence-detokenized": "New features in Office XP include smart tags, a selection-based search feature that recognizes different types of text in a document so users can perform additional actions; a task pane interface that groups popular menu bar commands on the right side of the screen for quick access; new document collaboration capabilities, support for MSN Groups and SharePoint; and integrated handwriting and speech recognition features.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 25], [26, 33], [34, 39], [40, 44], [44, 45], [46, 47], [48, 57], [57, 58], [58, 63], [64, 70], [71, 78], [79, 83], [84, 94], [95, 104], [105, 110], [111, 113], [114, 118], [119, 121], [122, 123], [124, 132], [133, 135], [136, 141], [142, 145], [146, 153], [154, 164], [165, 172], [172, 173], [174, 175], [176, 180], [181, 185], [186, 195], [196, 200], [201, 207], [208, 215], [216, 220], [221, 224], [225, 233], [234, 236], [237, 240], [241, 246], [247, 251], [252, 254], [255, 258], [259, 265], [266, 269], [270, 275], [276, 282], [282, 283], [284, 287], [288, 296], [297, 310], [311, 323], [323, 324], [325, 332], [333, 336], [337, 340], [341, 347], [348, 351], [352, 362], [362, 363], [364, 367], [368, 378], [379, 390], [391, 394], [395, 401], [402, 413], [414, 422], [422, 423]]}
{"doc_key": "ai-dev-64", "ner": [[11, 15, "algorithm"], [14, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 15, 14, 14, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "many", "applications", ",", "the", "units", "of", "these", "networks", "use", "the", "sigmoid", "as", "an", "activation", "function", "."], "sentence-detokenized": "In many applications, the units of these networks use the sigmoid as an activation function.", "token2charspan": [[0, 2], [3, 7], [8, 20], [20, 21], [22, 25], [26, 31], [32, 34], [35, 40], [41, 49], [50, 53], [54, 57], [58, 65], [66, 68], [69, 71], [72, 82], [83, 91], [91, 92]]}
{"doc_key": "ai-dev-65", "ner": [[3, 3, "researcher"], [12, 21, "organisation"], [29, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 12, 21, "role", "", false, false], [3, 3, 29, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2001", ",", "Mehler", "was", "elected", "a", "foreign", "honorary", "member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "and", "in", "2003", "he", "was", "elected", "a", "fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In 2001, Mehler was elected a foreign honorary member of the American Academy of Arts and Sciences, and in 2003 he was elected a fellow of the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 27], [28, 29], [30, 37], [38, 46], [47, 53], [54, 56], [57, 60], [61, 69], [70, 77], [78, 80], [81, 85], [86, 89], [90, 98], [98, 99], [100, 103], [104, 106], [107, 111], [112, 114], [115, 118], [119, 126], [127, 128], [129, 135], [136, 138], [139, 142], [143, 151], [152, 163], [164, 167], [168, 171], [172, 183], [184, 186], [187, 194], [194, 195]]}
{"doc_key": "ai-dev-66", "ner": [[4, 6, "task"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 11, 12, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Extending", "this", "concept", "to", "non", "-binary", "classifications", ",", "we", "obtain", "a", "confusion", "matrix", "."], "sentence-detokenized": "Extending this concept to non-binary classifications, we obtain a confusion matrix.", "token2charspan": [[0, 9], [10, 14], [15, 22], [23, 25], [26, 29], [29, 36], [37, 52], [52, 53], [54, 56], [57, 63], [64, 65], [66, 75], [76, 82], [82, 83]]}
{"doc_key": "ai-dev-67", "ner": [[13, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "updated", "estimate", "of", "the", "measurement", "noise", "variance", "can", "be", "obtained", "from", "the", "maximum", "likelihood", "calculation", "."], "sentence-detokenized": "An updated estimate of the measurement noise variance can be obtained from the maximum likelihood calculation.", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 22], [23, 26], [27, 38], [39, 44], [45, 53], [54, 57], [58, 60], [61, 69], [70, 74], [75, 78], [79, 86], [87, 97], [98, 109], [109, 110]]}
{"doc_key": "ai-dev-68", "ner": [[1, 4, "field"], [5, 5, "algorithm"], [11, 11, "field"], [8, 9, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 11, 11, "usage", "", true, false], [5, 5, 8, 9, "related-to", "", true, false], [11, 11, 1, 4, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "machine", "learning", ",", "the", "perceptron", "algorithm", "for", "binary", "classification", "is", "supervised", "."], "sentence-detokenized": "In machine learning, the perceptron algorithm for binary classification is supervised.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 24], [25, 35], [36, 45], [46, 49], [50, 56], [57, 71], [72, 74], [75, 85], [85, 86]]}
{"doc_key": "ai-dev-69", "ner": [[11, 12, "field"], [14, 14, "field"], [18, 23, "conference"], [26, 30, "conference"], [33, 39, "conference"], [42, 46, "conference"], [50, 54, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[18, 23, 11, 12, "topic", "", false, false], [18, 23, 14, 14, "topic", "", false, false], [26, 30, 11, 12, "topic", "", false, false], [26, 30, 14, 14, "topic", "", false, false], [33, 39, 11, 12, "topic", "", false, false], [33, 39, 14, 14, "topic", "", false, false], [42, 46, 11, 12, "topic", "", false, false], [42, 46, 14, 14, "topic", "", false, false], [50, 54, 11, 12, "topic", "", false, false], [50, 54, 14, 14, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["She", "has", "also", "served", "as", "the", "chair", "of", "several", "conferences", "on", "machine", "learning", "and", "vision", ",", "including", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "the", "International", "Conference", "on", "Learning", "Representations", ",", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "the", "International", "Conference", "on", "Computer", "Vision", ",", "and", "the", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "She has also served as the chair of several conferences on machine learning and vision, including the Conference on Neural Information Processing Systems, the International Conference on Learning Representations, the Conference on Computer Vision and Pattern Recognition, the International Conference on Computer Vision, and the European Conference on Computer Vision.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 19], [20, 22], [23, 26], [27, 32], [33, 35], [36, 43], [44, 55], [56, 58], [59, 66], [67, 75], [76, 79], [80, 86], [86, 87], [88, 97], [98, 101], [102, 112], [113, 115], [116, 122], [123, 134], [135, 145], [146, 153], [153, 154], [155, 158], [159, 172], [173, 183], [184, 186], [187, 195], [196, 211], [211, 212], [213, 216], [217, 227], [228, 230], [231, 239], [240, 246], [247, 250], [251, 258], [259, 270], [270, 271], [272, 275], [276, 289], [290, 300], [301, 303], [304, 312], [313, 319], [319, 320], [321, 324], [325, 328], [329, 337], [338, 348], [349, 351], [352, 360], [361, 367], [367, 368]]}
{"doc_key": "ai-dev-70", "ner": [[0, 2, "algorithm"], [8, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "condensation", "algorithm", "was", "also", "used", "for", "the", "face", "recognition", "system", "in", "the", "video", "sequence", "."], "sentence-detokenized": "The condensation algorithm was also used for the face recognition system in the video sequence.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 30], [31, 35], [36, 40], [41, 44], [45, 48], [49, 53], [54, 65], [66, 72], [73, 75], [76, 79], [80, 85], [86, 94], [94, 95]]}
{"doc_key": "ai-dev-71", "ner": [[0, 13, "task"], [3, 7, "organisation"], [16, 16, "conference"], [20, 24, "academicjournal"], [27, 27, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 16, 0, 13, "topic", "", false, false], [16, 16, 3, 7, "origin", "", false, false], [20, 24, 0, 13, "topic", "", false, false], [20, 24, 3, 7, "origin", "", true, false], [27, 27, 20, 24, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Dissemination", "of", "information", "is", "also", "part", "of", "ELRA", "'s", "mission", "and", "is", "carried", "out", "through", "the", "LREC", "conference", "and", "the", "Language", "Resources", "and", "Evaluation", "Journal", "published", "by", "Springer", "."], "sentence-detokenized": "Dissemination of information is also part of ELRA's mission and is carried out through the LREC conference and the Language Resources and Evaluation Journal published by Springer.", "token2charspan": [[0, 13], [14, 16], [17, 28], [29, 31], [32, 36], [37, 41], [42, 44], [45, 49], [49, 51], [52, 59], [60, 63], [64, 66], [67, 74], [75, 78], [79, 86], [87, 90], [91, 95], [96, 106], [107, 110], [111, 114], [115, 123], [124, 133], [134, 137], [138, 148], [149, 156], [157, 166], [167, 169], [170, 178], [178, 179]]}
{"doc_key": "ai-dev-72", "ner": [[1, 8, "field"], [10, 11, "field"], [14, 16, "field"], [15, 18, "field"], [51, 54, "field"], [58, 59, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 8, 51, 54, "named", "", false, false], [14, 16, 1, 8, "named", "", false, false], [58, 59, 10, 11, "part-of", "", true, false], [58, 59, 14, 16, "part-of", "", true, false], [58, 59, 51, 54, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "linear", "time", "invariant", "(", "LTI", ")", "systems", "theory", ",", "control", "theory", ",", "and", "digital", "signal", "processing", ",", "the", "relationship", "between", "the", "input", "signal", ",", "math", "\\", "displayystyle", "x", "(", "t", ")", "/", "math", ",", "and", "the", "output", "signal", ",", "math", "\\", "displayystyle", "y", "(", "t", ")", "/", "math", ",", "of", "an", "LTI", "system", "is", "governed", "by", "the", "convolution", "operation", ":"], "sentence-detokenized": "In linear time invariant (LTI) systems theory, control theory, and digital signal processing, the relationship between the input signal, math\\ displayystyle x(t)/math, and the output signal, math\\ displayystyle y(t)/math, of an LTI system is governed by the convolution operation:", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 24], [25, 26], [26, 29], [29, 30], [31, 38], [39, 45], [45, 46], [47, 54], [55, 61], [61, 62], [63, 66], [67, 74], [75, 81], [82, 92], [92, 93], [94, 97], [98, 110], [111, 118], [119, 122], [123, 128], [129, 135], [135, 136], [137, 141], [141, 142], [143, 156], [157, 158], [158, 159], [159, 160], [160, 161], [161, 162], [162, 166], [166, 167], [168, 171], [172, 175], [176, 182], [183, 189], [189, 190], [191, 195], [195, 196], [197, 210], [211, 212], [212, 213], [213, 214], [214, 215], [215, 216], [216, 220], [220, 221], [222, 224], [225, 227], [228, 231], [232, 238], [239, 241], [242, 250], [251, 253], [254, 257], [258, 269], [270, 279], [279, 280]]}
{"doc_key": "ai-dev-73", "ner": [[15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"], [27, 30, "field"], [32, 33, "product"], [35, 36, "field"], [38, 38, "field"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Because", "of", "its", "generality", ",", "this", "field", "is", "studied", "in", "many", "other", "disciplines", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimization", ",", "multiagent", "systems", ",", "swarm", "intelligence", ",", "statistics", ",", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Because of its generality, this field is studied in many other disciplines such as game theory, control theory, operations research, information theory, simulation-based optimization, multiagent systems, swarm intelligence, statistics, and genetic algorithms.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [25, 26], [27, 31], [32, 37], [38, 40], [41, 48], [49, 51], [52, 56], [57, 62], [63, 74], [75, 79], [80, 82], [83, 87], [88, 94], [94, 95], [96, 103], [104, 110], [110, 111], [112, 122], [123, 131], [131, 132], [133, 144], [145, 151], [151, 152], [153, 163], [163, 164], [164, 169], [170, 182], [182, 183], [184, 194], [195, 202], [202, 203], [204, 209], [210, 222], [222, 223], [224, 234], [234, 235], [236, 239], [240, 247], [248, 258], [258, 259]]}
{"doc_key": "ai-dev-74", "ner": [[0, 2, "algorithm"], [15, 16, "field"], [22, 23, "algorithm"], [26, 27, "algorithm"], [31, 32, "algorithm"], [35, 35, "algorithm"], [36, 40, "researcher"], [42, 43, "researcher"], [45, 47, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[15, 16, 0, 2, "usage", "", true, false], [22, 23, 15, 16, "part-of", "", true, false], [26, 27, 15, 16, "part-of", "", true, false], [31, 32, 15, 16, "part-of", "", true, false], [35, 35, 15, 16, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Stochastic", "gradient", "descent", "is", "a", "popular", "algorithm", "for", "training", "a", "wide", "range", "of", "models", "in", "machine", "learning", ",", "including", "(", "linear", ")", "support", "vector", "machines", ",", "logistic", "regression", "(", "see", "e.g.", "Vowpal", "Wabbit", ")", "and", "graphical", "models", ".", "Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastic gradient descent is a popular algorithm for training a wide range of models in machine learning, including (linear) support vector machines, logistic regression (see e.g. Vowpal Wabbit) and graphical models. Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 30], [31, 32], [33, 40], [41, 50], [51, 54], [55, 63], [64, 65], [66, 70], [71, 76], [77, 79], [80, 86], [87, 89], [90, 97], [98, 106], [106, 107], [108, 117], [118, 119], [119, 125], [125, 126], [127, 134], [135, 141], [142, 150], [150, 151], [152, 160], [161, 171], [172, 173], [173, 176], [177, 181], [182, 188], [189, 195], [195, 196], [197, 200], [201, 210], [211, 217], [217, 218], [219, 224], [225, 229], [230, 236], [236, 237], [238, 242], [243, 250], [250, 251], [252, 263], [264, 266], [267, 274], [275, 276], [276, 280], [280, 281], [281, 282]]}
{"doc_key": "ai-dev-75", "ner": [[8, 9, "organisation"], [12, 13, "product"], [17, 17, "country"], [20, 23, "university"], [25, 25, "location"], [27, 29, "university"], [31, 31, "location"], [33, 34, "university"], [36, 36, "location"], [38, 40, "university"], [42, 42, "location"], [44, 45, "university"], [47, 47, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 9, 20, 23, "role", "donates_to", false, false], [8, 9, 27, 29, "role", "donates_to", false, false], [8, 9, 33, 34, "role", "donates_to", false, false], [8, 9, 38, 40, "role", "donates_to", false, false], [8, 9, 44, 45, "role", "donates_to", false, false], [12, 13, 8, 9, "origin", "donates", true, false], [20, 23, 25, 25, "physical", "", false, false], [25, 25, 17, 17, "physical", "", false, false], [27, 29, 31, 31, "physical", "", false, false], [31, 31, 17, 17, "physical", "", false, false], [33, 34, 36, 36, "physical", "", false, false], [36, 36, 17, 17, "physical", "", false, false], [38, 40, 42, 42, "physical", "", false, false], [42, 42, 17, 17, "physical", "", false, false], [44, 45, 47, 47, "physical", "", false, false], [47, 47, 17, 17, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["In", "August", "2011", ",", "it", "was", "announced", "that", "Hitachi", "would", "donate", "one", "electron", "microscope", "each", "to", "five", "Indonesian", "universities", "(", "University", "of", "North", "Sumatra", "in", "Medan", ",", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Padjadjaran", "University", "in", "Bandung", ",", "Jenderal", "Soedirman", "University", "in", "Purwokerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "sentence-detokenized": "In August 2011, it was announced that Hitachi would donate one electron microscope each to five Indonesian universities (University of North Sumatra in Medan, Indonesian Christian University in Jakarta, Padjadjaran University in Bandung, Jenderal Soedirman University in Purwokerto and Muhammadiyah University in Malang).", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 32], [33, 37], [38, 45], [46, 51], [52, 58], [59, 62], [63, 71], [72, 82], [83, 87], [88, 90], [91, 95], [96, 106], [107, 119], [120, 121], [121, 131], [132, 134], [135, 140], [141, 148], [149, 151], [152, 157], [157, 158], [159, 169], [170, 179], [180, 190], [191, 193], [194, 201], [201, 202], [203, 214], [215, 225], [226, 228], [229, 236], [236, 237], [238, 246], [247, 256], [257, 267], [268, 270], [271, 281], [282, 285], [286, 298], [299, 309], [310, 312], [313, 319], [319, 320], [320, 321]]}
{"doc_key": "ai-dev-76", "ner": [[2, 2, "field"], [0, 5, "field"], [7, 8, "algorithm"], [10, 11, "algorithm"], [20, 21, "field"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 0, 5, "part-of", "", false, false], [2, 2, 20, 21, "related-to", "", true, false], [2, 2, 26, 27, "related-to", "", true, false], [7, 8, 2, 2, "type-of", "", false, false], [10, 11, 2, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Operations", "research", "optimization", "techniques", ",", "such", "as", "linear", "programming", "or", "dynamic", "programming", ",", "are", "often", "impractical", "for", "large", "-", "scale", "software", "engineering", "problems", "due", "to", "their", "computational", "complexity", "."], "sentence-detokenized": "Operations research optimization techniques, such as linear programming or dynamic programming, are often impractical for large-scale software engineering problems due to their computational complexity.", "token2charspan": [[0, 10], [11, 19], [20, 32], [33, 43], [43, 44], [45, 49], [50, 52], [53, 59], [60, 71], [72, 74], [75, 82], [83, 94], [94, 95], [96, 99], [100, 105], [106, 117], [118, 121], [122, 127], [127, 128], [128, 133], [134, 142], [143, 154], [155, 163], [164, 167], [168, 170], [171, 176], [177, 190], [191, 201], [201, 202]]}
{"doc_key": "ai-dev-77", "ner": [[0, 0, "metrics"], [6, 6, "metrics"], [8, 10, "metrics"], [18, 19, "metrics"], [25, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 6, "compare", "", false, false], [0, 0, 8, 10, "compare", "", false, false], [18, 19, 8, 10, "part-of", "", false, false], [25, 33, 8, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sensitivity", "is", "not", "the", "same", "as", "accuracy", "or", "positive", "predictive", "value", "(", "the", "ratio", "of", "the", "number", "of", "true", "positives", "to", "the", "number", "of", "combined", "true", "and", "false", "positives", ")", ",", "which", "is", "as", "much", "about", "the", "proportion", "of", "true", "positives", "in", "the", "population", "tested", "as", "it", "is", "about", "the", "test", "."], "sentence-detokenized": "Sensitivity is not the same as accuracy or positive predictive value (the ratio of the number of true positives to the number of combined true and false positives), which is as much about the proportion of true positives in the population tested as it is about the test.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 22], [23, 27], [28, 30], [31, 39], [40, 42], [43, 51], [52, 62], [63, 68], [69, 70], [70, 73], [74, 79], [80, 82], [83, 86], [87, 93], [94, 96], [97, 101], [102, 111], [112, 114], [115, 118], [119, 125], [126, 128], [129, 137], [138, 142], [143, 146], [147, 152], [153, 162], [162, 163], [163, 164], [165, 170], [171, 173], [174, 176], [177, 181], [182, 187], [188, 191], [192, 202], [203, 205], [206, 210], [211, 220], [221, 223], [224, 227], [228, 238], [239, 245], [246, 248], [249, 251], [252, 254], [255, 260], [261, 264], [265, 269], [269, 270]]}
{"doc_key": "ai-dev-78", "ner": [[0, 1, "person"], [11, 11, "product"], [14, 14, "person"], [29, 29, "person"], [37, 39, "person"], [43, 44, "person"], [49, 51, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 43, 44, "named", "same", false, false], [11, 11, 0, 1, "artifact", "", false, false], [37, 39, 49, 51, "role", "convinces", false, false], [49, 51, 11, 11, "role", "producer", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Hampton", "Fancher", "'s", "script", "!", "--", "It", "was", "not", "originally", "titled", "Android", "--", "see", "Sammon", ",", "pages", "32", "and", "38", "for", "an", "explanation", "--", "was", "optioned", "in", "1977", ".", "Sammon", ",", "pp.", "23", "-", "30", ".", "Producer", "Michael", "Deeley", "took", "an", "interest", "in", "Fancher", "'s", "draft", "and", "convinced", "director", "Ridley", "Scott", "to", "film", "it", "."], "sentence-detokenized": "Hampton Fancher's script! -- It was not originally titled Android -- see Sammon, pages 32 and 38 for an explanation -- was optioned in 1977. Sammon, pp. 23-30. Producer Michael Deeley took an interest in Fancher's draft and convinced director Ridley Scott to film it.", "token2charspan": [[0, 7], [8, 15], [15, 17], [18, 24], [24, 25], [26, 28], [29, 31], [32, 35], [36, 39], [40, 50], [51, 57], [58, 65], [66, 68], [69, 72], [73, 79], [79, 80], [81, 86], [87, 89], [90, 93], [94, 96], [97, 100], [101, 103], [104, 115], [116, 118], [119, 122], [123, 131], [132, 134], [135, 139], [139, 140], [141, 147], [147, 148], [149, 152], [153, 155], [155, 156], [156, 158], [158, 159], [160, 168], [169, 176], [177, 183], [184, 188], [189, 191], [192, 200], [201, 203], [204, 211], [211, 213], [214, 219], [220, 223], [224, 233], [234, 242], [243, 249], [250, 255], [256, 258], [259, 263], [264, 266], [266, 267]]}
{"doc_key": "ai-dev-79", "ner": [[0, 1, "field"], [3, 4, "task"], [6, 7, "task"], [10, 12, "misc"], [14, 15, "field"], [17, 19, "task"], [21, 22, "task"], [24, 25, "field"], [28, 31, "task"], [33, 33, "task"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [6, 7, 0, 1, "part-of", "", false, false], [10, 12, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false], [17, 19, 0, 1, "part-of", "", false, false], [21, 22, 0, 1, "part-of", "", false, false], [24, 25, 0, 1, "part-of", "", false, false], [28, 31, 0, 1, "part-of", "", false, false], [33, 33, 0, 1, "part-of", "", false, false], [36, 37, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Text", "analysis", "includes", "information", "retrieval", ",", "lexical", "analysis", "to", "study", "word", "frequency", "distribution", ",", "pattern", "recognition", ",", "tagging", "/", "annotation", ",", "information", "extraction", ",", "data", "mining", "techniques", "including", "link", "and", "association", "analysis", ",", "visualization", ",", "and", "predictive", "analysis", "."], "sentence-detokenized": "Text analysis includes information retrieval, lexical analysis to study word frequency distribution, pattern recognition, tagging/annotation, information extraction, data mining techniques including link and association analysis, visualization, and predictive analysis.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 34], [35, 44], [44, 45], [46, 53], [54, 62], [63, 65], [66, 71], [72, 76], [77, 86], [87, 99], [99, 100], [101, 108], [109, 120], [120, 121], [122, 129], [129, 130], [130, 140], [140, 141], [142, 153], [154, 164], [164, 165], [166, 170], [171, 177], [178, 188], [189, 198], [199, 203], [204, 207], [208, 219], [220, 228], [228, 229], [230, 243], [243, 244], [245, 248], [249, 259], [260, 268], [268, 269]]}
{"doc_key": "ai-dev-80", "ner": [[3, 5, "product"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 3, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Some", "metrics", "use", "WordNet", ",", "a", "hand", "-", "crafted", "lexical", "database", "of", "English", "words", "."], "sentence-detokenized": "Some metrics use WordNet, a hand-crafted lexical database of English words.", "token2charspan": [[0, 4], [5, 12], [13, 16], [17, 24], [24, 25], [26, 27], [28, 32], [32, 33], [33, 40], [41, 48], [49, 57], [58, 60], [61, 68], [69, 74], [74, 75]]}
{"doc_key": "ai-dev-81", "ner": [[6, 7, "field"], [9, 10, "task"], [12, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "system", "uses", "a", "combination", "of", "computational", "linguistics", ",", "information", "retrieval", "and", "knowledge", "representation", "techniques", "to", "retrieve", "answers", "."], "sentence-detokenized": "The system uses a combination of computational linguistics, information retrieval and knowledge representation techniques to retrieve answers.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 17], [18, 29], [30, 32], [33, 46], [47, 58], [58, 59], [60, 71], [72, 81], [82, 85], [86, 95], [96, 110], [111, 121], [122, 124], [125, 133], [134, 141], [141, 142]]}
{"doc_key": "ai-dev-82", "ner": [[0, 2, "metrics"], [9, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 15, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "uncertainty", "factor", "as", "a", "performance", "metric", "has", "the", "advantage", "over", "simple", "accuracy", "that", "it", "is", "not", "affected", "by", "the", "relative", "size", "of", "the", "different", "classes", "."], "sentence-detokenized": "The uncertainty factor as a performance metric has the advantage over simple accuracy that it is not affected by the relative size of the different classes.", "token2charspan": [[0, 3], [4, 15], [16, 22], [23, 25], [26, 27], [28, 39], [40, 46], [47, 50], [51, 54], [55, 64], [65, 69], [70, 76], [77, 85], [86, 90], [91, 93], [94, 96], [97, 100], [101, 109], [110, 112], [113, 116], [117, 125], [126, 130], [131, 133], [134, 137], [138, 147], [148, 155], [155, 156]]}
{"doc_key": "ai-dev-83", "ner": [[9, 10, "algorithm"], [12, 13, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Researchers", "have", "attempted", "a", "number", "of", "methods", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "hidden", "Markov", "models", ",", "etc", "."], "sentence-detokenized": "Researchers have attempted a number of methods such as optical flow, Kalman filtering, hidden Markov models, etc.", "token2charspan": [[0, 11], [12, 16], [17, 26], [27, 28], [29, 35], [36, 38], [39, 46], [47, 51], [52, 54], [55, 62], [63, 67], [67, 68], [69, 75], [76, 85], [85, 86], [87, 93], [94, 100], [101, 107], [107, 108], [109, 112], [112, 113]]}
{"doc_key": "ai-dev-84", "ner": [[14, 18, "conference"], [32, 36, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "has", "served", "as", "President", ",", "Vice", "President", ",", "and", "Secretary", "-", "Treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "has", "been", "a", "member", "and", "Secretary", "of", "the", "Board", "of", "Directors", "of", "the", "Association", "for", "Computational", "Research", "."], "sentence-detokenized": "She has served as President, Vice President, and Secretary-Treasurer of the Association for Computational Linguistics and has been a member and Secretary of the Board of Directors of the Association for Computational Research.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 17], [18, 27], [27, 28], [29, 33], [34, 43], [43, 44], [45, 48], [49, 58], [58, 59], [59, 68], [69, 71], [72, 75], [76, 87], [88, 91], [92, 105], [106, 117], [118, 121], [122, 125], [126, 130], [131, 132], [133, 139], [140, 143], [144, 153], [154, 156], [157, 160], [161, 166], [167, 169], [170, 179], [180, 182], [183, 186], [187, 198], [199, 202], [203, 216], [217, 225], [225, 226]]}
{"doc_key": "ai-dev-85", "ner": [[6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 10, 10, "compare", "", false, false], [6, 6, 12, 13, "related-to", "supports", false, false], [8, 8, 10, 10, "compare", "", false, false], [8, 8, 12, 13, "related-to", "supports", false, false], [10, 10, 12, 13, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Like", "other", "similar", "languages", "such", "as", "APL", "and", "MATLAB", ",", "R", "supports", "matrix", "arithmetic", "."], "sentence-detokenized": "Like other similar languages such as APL and MATLAB, R supports matrix arithmetic.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 28], [29, 33], [34, 36], [37, 40], [41, 44], [45, 51], [51, 52], [53, 54], [55, 63], [64, 70], [71, 81], [81, 82]]}
{"doc_key": "ai-dev-86", "ner": [[10, 11, "misc"], [7, 23, "organisation"], [16, 17, "researcher"], [20, 31, "university"], [26, 31, "misc"], [33, 33, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 11, 7, 23, "physical", "", false, false], [10, 11, 26, 31, "temporal", "", false, false], [16, 17, 10, 11, "role", "arranges", false, false], [16, 17, 20, 31, "role", "works_for", false, false], [33, 33, 10, 11, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "7", "June", "2014", ",", "in", "the", "Royal", "Society", "'s", "Turing", "Test", "competition", ",", "organised", "by", "Kevin", "Warwick", "of", "the", "University", "of", "Reading", "to", "mark", "the", "60th", "anniversary", "of", "Turing", "'s", "death", ",", "Goostman", "won", "when", "33", "%", "of", "the", "judges", "were", "convinced", "that", "the", "robot", "was", "human", "."], "sentence-detokenized": "On 7 June 2014, in the Royal Society's Turing Test competition, organised by Kevin Warwick of the University of Reading to mark the 60th anniversary of Turing's death, Goostman won when 33% of the judges were convinced that the robot was human.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 28], [29, 36], [36, 38], [39, 45], [46, 50], [51, 62], [62, 63], [64, 73], [74, 76], [77, 82], [83, 90], [91, 93], [94, 97], [98, 108], [109, 111], [112, 119], [120, 122], [123, 127], [128, 131], [132, 136], [137, 148], [149, 151], [152, 158], [158, 160], [161, 166], [166, 167], [168, 176], [177, 180], [181, 185], [186, 188], [188, 189], [190, 192], [193, 196], [197, 203], [204, 208], [209, 218], [219, 223], [224, 227], [228, 233], [234, 237], [238, 243], [243, 244]]}
{"doc_key": "ai-dev-87", "ner": [[0, 2, "product"], [5, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "collaborative", "robot", ",", "or", "cobot", ",", "is", "a", "robot", "that", "can", "safely", "and", "efficiently", "work", "with", "human", "workers", "to", "perform", "simple", "industrial", "tasks", "."], "sentence-detokenized": "A collaborative robot, or cobot, is a robot that can safely and efficiently work with human workers to perform simple industrial tasks.", "token2charspan": [[0, 1], [2, 15], [16, 21], [21, 22], [23, 25], [26, 31], [31, 32], [33, 35], [36, 37], [38, 43], [44, 48], [49, 52], [53, 59], [60, 63], [64, 75], [76, 80], [81, 85], [86, 91], [92, 99], [100, 102], [103, 110], [111, 117], [118, 128], [129, 134], [134, 135]]}
{"doc_key": "ai-dev-88", "ner": [[12, 13, "field"], [16, 17, "task"], [19, 20, "task"], [22, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 33, "task"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[16, 17, 12, 13, "part-of", "task_part_of_field", false, false], [19, 20, 12, 13, "part-of", "task_part_of_field", false, false], [22, 23, 12, 13, "part-of", "task_part_of_field", false, false], [25, 26, 12, 13, "part-of", "task_part_of_field", false, false], [28, 29, 12, 13, "part-of", "task_part_of_field", false, false], [31, 33, 12, 13, "part-of", "task_part_of_field", false, false], [36, 37, 12, 13, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "general", "framework", "has", "been", "applied", "to", "a", "variety", "of", "problems", "in", "computer", "vision", ",", "including", "feature", "detection", ",", "feature", "classification", ",", "image", "segmentation", ",", "image", "matching", ",", "motion", "estimation", ",", "shape", "signal", "computation", ",", "and", "object", "recognition", "."], "sentence-detokenized": "This general framework has been applied to a variety of problems in computer vision, including feature detection, feature classification, image segmentation, image matching, motion estimation, shape signal computation, and object recognition.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 26], [27, 31], [32, 39], [40, 42], [43, 44], [45, 52], [53, 55], [56, 64], [65, 67], [68, 76], [77, 83], [83, 84], [85, 94], [95, 102], [103, 112], [112, 113], [114, 121], [122, 136], [136, 137], [138, 143], [144, 156], [156, 157], [158, 163], [164, 172], [172, 173], [174, 180], [181, 191], [191, 192], [193, 198], [199, 205], [206, 217], [217, 218], [219, 222], [223, 229], [230, 241], [241, 242]]}
{"doc_key": "ai-dev-89", "ner": [[12, 15, "task"], [16, 18, "algorithm"], [6, 7, "algorithm"], [25, 26, "algorithm"], [35, 36, "algorithm"], [39, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 15, 16, 18, "part-of", "", false, false], [12, 15, 6, 7, "usage", "", false, false], [16, 18, 25, 26, "named", "same", false, false], [25, 26, 35, 36, "related-to", "", false, false], [25, 26, 39, 40, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "many", "practical", "applications", ",", "the", "maximum", "likelihood", "method", "is", "used", "in", "estimating", "the", "parameters", "of", "naive", "Bayes", "models", ";", "in", "other", "words", ",", "a", "naive", "Bayes", "model", "can", "be", "handled", "without", "having", "to", "assume", "Bayesian", "likelihood", "or", "use", "Bayesian", "methods", "."], "sentence-detokenized": "In many practical applications, the maximum likelihood method is used in estimating the parameters of naive Bayes models; in other words, a naive Bayes model can be handled without having to assume Bayesian likelihood or use Bayesian methods.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 30], [30, 31], [32, 35], [36, 43], [44, 54], [55, 61], [62, 64], [65, 69], [70, 72], [73, 83], [84, 87], [88, 98], [99, 101], [102, 107], [108, 113], [114, 120], [120, 121], [122, 124], [125, 130], [131, 136], [136, 137], [138, 139], [140, 145], [146, 151], [152, 157], [158, 161], [162, 164], [165, 172], [173, 180], [181, 187], [188, 190], [191, 197], [198, 206], [207, 217], [218, 220], [221, 224], [225, 233], [234, 241], [241, 242]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [12, 15, "university"], [17, 19, "researcher"], [21, 22, "misc"], [26, 26, "university"], [28, 28, "university"], [31, 31, "misc"], [38, 40, "university"], [46, 49, "misc"], [51, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 4, 12, 15, "physical", "", false, false], [2, 4, 12, 15, "role", "", false, false], [2, 4, 17, 19, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [17, 19, 26, 26, "physical", "", false, false], [17, 19, 26, 26, "role", "", false, false], [17, 19, 28, 28, "physical", "", false, false], [17, 19, 28, 28, "role", "", false, false], [17, 19, 38, 40, "physical", "", false, false], [17, 19, 38, 40, "role", "", false, false], [21, 22, 17, 19, "named", "", false, false], [31, 31, 17, 19, "origin", "", false, false], [46, 49, 17, 19, "artifact", "", false, false], [46, 49, 51, 54, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Brothers", "-", "Victor", "Gershevich", "Katz", ",", "American", "mathematician", ",", "professor", "at", "the", "Massachusetts", "Institute", "of", "Technology", ";", "Mikhail", "Gershevich", "Katz", ",", "Israeli", "mathematician", ",", "graduate", "of", "Harvard", "and", "Columbia", "Universities", "(", "Ph.D.", ",", "1984", ")", ",", "professor", "at", "Bar-", "Ilan", "University", ",", "author", "of", "the", "monograph", "Systolic", "Geometry", "and", "Topology", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", "."], "sentence-detokenized": "Brothers - Victor Gershevich Katz, American mathematician, professor at the Massachusetts Institute of Technology; Mikhail Gershevich Katz, Israeli mathematician, graduate of Harvard and Columbia Universities (Ph.D. , 1984), professor at Bar-Ilan University, author of the monograph Systolic Geometry and Topology (Mathematical Surveys and Monographs, vol.", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 28], [29, 33], [33, 34], [35, 43], [44, 57], [57, 58], [59, 68], [69, 71], [72, 75], [76, 89], [90, 99], [100, 102], [103, 113], [113, 114], [115, 122], [123, 133], [134, 138], [138, 139], [140, 147], [148, 161], [161, 162], [163, 171], [172, 174], [175, 182], [183, 186], [187, 195], [196, 208], [209, 210], [210, 215], [216, 217], [218, 222], [222, 223], [223, 224], [225, 234], [235, 237], [238, 242], [242, 246], [247, 257], [257, 258], [259, 265], [266, 268], [269, 272], [273, 282], [283, 291], [292, 300], [301, 304], [305, 313], [314, 315], [315, 327], [328, 335], [336, 339], [340, 350], [350, 351], [352, 355], [355, 356]]}
{"doc_key": "ai-dev-91", "ner": [[3, 6, "person"], [10, 11, "conference"], [15, 19, "organisation"], [21, 27, "location"], [31, 31, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 10, 11, "physical", "", false, false], [3, 6, 10, 11, "role", "", false, false], [3, 6, 15, 19, "role", "", false, false], [15, 19, 21, 27, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2000", ",", "Manuel", "Toharia", ",", "a", "speaker", "at", "previous", "Campus", "Parties", "and", "director", "of", "the", "Pr\u00edncipe", "Felipe", "Science", "Museum", "in", "Valencia", "'s", "City", "of", "Arts", "and", "Sciences", ",", "suggested", "that", "Ragageles", "expand", "and", "make", "the", "event", "more", "international", "by", "moving", "it", "to", "the", "famous", "museum", "."], "sentence-detokenized": "In 2000, Manuel Toharia, a speaker at previous Campus Parties and director of the Pr\u00edncipe Felipe Science Museum in Valencia's City of Arts and Sciences, suggested that Ragageles expand and make the event more international by moving it to the famous museum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 23], [23, 24], [25, 26], [27, 34], [35, 37], [38, 46], [47, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 81], [82, 90], [91, 97], [98, 105], [106, 112], [113, 115], [116, 124], [124, 126], [127, 131], [132, 134], [135, 139], [140, 143], [144, 152], [152, 153], [154, 163], [164, 168], [169, 178], [179, 185], [186, 189], [190, 194], [195, 198], [199, 204], [205, 209], [210, 223], [224, 226], [227, 233], [234, 236], [237, 239], [240, 243], [244, 250], [251, 257], [257, 258]]}
{"doc_key": "ai-dev-92", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Within", "20", "minutes", ",", "the", "facial", "recognition", "system", "identifies", "personal", "details", "including", "surname", ",", "ID", "number", "and", "address", ",", "which", "are", "displayed", "on", "the", "street", "on", "an", "advertising", "screen", "."], "sentence-detokenized": "Within 20 minutes, the facial recognition system identifies personal details including surname, ID number and address, which are displayed on the street on an advertising screen.", "token2charspan": [[0, 6], [7, 9], [10, 17], [17, 18], [19, 22], [23, 29], [30, 41], [42, 48], [49, 59], [60, 68], [69, 76], [77, 86], [87, 94], [94, 95], [96, 98], [99, 105], [106, 109], [110, 117], [117, 118], [119, 124], [125, 128], [129, 138], [139, 141], [142, 145], [146, 152], [153, 155], [156, 158], [159, 170], [171, 177], [177, 178]]}
{"doc_key": "ai-dev-93", "ner": [[6, 10, "field"], [8, 11, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "research", "has", "increasingly", "focused", "on", "unsupervised", "and", "partially", "supervised", "learning", "algorithms", "."], "sentence-detokenized": "Recent research has increasingly focused on unsupervised and partially supervised learning algorithms.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 32], [33, 40], [41, 43], [44, 56], [57, 60], [61, 70], [71, 81], [82, 90], [91, 101], [101, 102]]}
{"doc_key": "ai-dev-94", "ner": [[4, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Calculating", "this", "example", "using", "Python", "code", ":"], "sentence-detokenized": "Calculating this example using Python code:", "token2charspan": [[0, 11], [12, 16], [17, 24], [25, 30], [31, 37], [38, 42], [42, 43]]}
{"doc_key": "ai-dev-95", "ner": [[7, 8, "task"], [14, 15, "field"], [18, 21, "algorithm"], [23, 23, "algorithm"], [27, 30, "algorithm"], [34, 35, "researcher"], [37, 38, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[18, 21, 14, 15, "part-of", "", false, false], [18, 21, 27, 30, "type-of", "", false, false], [18, 21, 34, 35, "origin", "", false, false], [18, 21, 37, 38, "origin", "", false, false], [23, 23, 18, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Today", ",", "however", ",", "many", "aspects", "of", "speech", "recognition", "have", "been", "adopted", "by", "a", "deep", "learning", "method", "called", "Long", "Short", "Term", "Memory", "(", "LSTM", ")", ",", "a", "recurrent", "neural", "network", "published", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Today, however, many aspects of speech recognition have been adopted by a deep learning method called Long Short Term Memory (LSTM), a recurrent neural network published in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 5], [5, 6], [7, 14], [14, 15], [16, 20], [21, 28], [29, 31], [32, 38], [39, 50], [51, 55], [56, 60], [61, 68], [69, 71], [72, 73], [74, 78], [79, 87], [88, 94], [95, 101], [102, 106], [107, 112], [113, 117], [118, 124], [125, 126], [126, 130], [130, 131], [131, 132], [133, 134], [135, 144], [145, 151], [152, 159], [160, 169], [170, 172], [173, 177], [178, 180], [181, 185], [186, 196], [197, 200], [201, 207], [208, 219], [219, 220]]}
{"doc_key": "ai-dev-96", "ner": [[7, 8, "algorithm"], [13, 14, "algorithm"], [18, 18, "algorithm"], [23, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 13, 14, "compare", "", false, false], [7, 8, 23, 23, "named", "same", false, false], [18, 18, 23, 23, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "preliminary", "experimental", "results", "with", "noisy", "datasets", ",", "BrownBoost", "outperformed", "the", "generalization", "error", "of", "AdaBoost", ";", "however", ",", "LogitBoost", "performed", "as", "well", "as", "BrownBoost", "."], "sentence-detokenized": "In preliminary experimental results with noisy datasets, BrownBoost outperformed the generalization error of AdaBoost; however, LogitBoost performed as well as BrownBoost.", "token2charspan": [[0, 2], [3, 14], [15, 27], [28, 35], [36, 40], [41, 46], [47, 55], [55, 56], [57, 67], [68, 80], [81, 84], [85, 99], [100, 105], [106, 108], [109, 117], [117, 118], [119, 126], [126, 127], [128, 138], [139, 148], [149, 151], [152, 156], [157, 159], [160, 170], [170, 171]]}
{"doc_key": "ai-dev-97", "ner": [[0, 1, "algorithm"], [5, 7, "researcher"], [10, 10, "country"], [13, 15, "researcher"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 7, "part-of", "", false, false], [5, 7, 10, 10, "physical", "", false, false], [19, 21, 13, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evolutionary", "programming", "was", "introduced", "by", "Lawrence", "J.", "Fogel", "in", "the", "USA", ",", "while", "John", "Henry", "Holland", "called", "his", "method", "the", "genetic", "algorithm", "."], "sentence-detokenized": "Evolutionary programming was introduced by Lawrence J. Fogel in the USA, while John Henry Holland called his method the genetic algorithm.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 54], [55, 60], [61, 63], [64, 67], [68, 71], [71, 72], [73, 78], [79, 83], [84, 89], [90, 97], [98, 104], [105, 108], [109, 115], [116, 119], [120, 127], [128, 137], [137, 138]]}
{"doc_key": "ai-dev-98", "ner": [[2, 2, "researcher"], [4, 4, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 11, 12, "role", "", false, false], [2, 2, 14, 15, "role", "", false, false], [2, 2, 17, 18, "role", "", false, false], [2, 2, 21, 22, "role", "", false, false], [4, 4, 11, 12, "role", "", false, false], [4, 4, 14, 15, "role", "", false, false], [4, 4, 17, 18, "role", "", false, false], [4, 4, 21, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Calculations", "by", "Doug", ",", "Alan", ",", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", ",", "and", "John", "McCarthy", ")", "showed", "that", "this", "effort", "would", "require", "1,000", "to", "3,000", "person", "-", "years", "of", "work", ",", "far", "beyond", "the", "standard", "academic", "project", "model", "."], "sentence-detokenized": "Calculations by Doug, Alan, and their colleagues (including Marvin Minsky, Allen Newell, Edward Feigenbaum, and John McCarthy) showed that this effort would require 1,000 to 3,000 person-years of work, far beyond the standard academic project model.", "token2charspan": [[0, 12], [13, 15], [16, 20], [20, 21], [22, 26], [26, 27], [28, 31], [32, 37], [38, 48], [49, 50], [50, 59], [60, 66], [67, 73], [73, 74], [75, 80], [81, 87], [87, 88], [89, 95], [96, 106], [106, 107], [108, 111], [112, 116], [117, 125], [125, 126], [127, 133], [134, 138], [139, 143], [144, 150], [151, 156], [157, 164], [165, 170], [171, 173], [174, 179], [180, 186], [186, 187], [187, 192], [193, 195], [196, 200], [200, 201], [202, 205], [206, 212], [213, 216], [217, 225], [226, 234], [235, 242], [243, 248], [248, 249]]}
{"doc_key": "ai-dev-99", "ner": [[4, 6, "metrics"], [10, 10, "metrics"], [13, 15, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 10, 10, "part-of", "implemented_in", false, false], [13, 15, 18, 18, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Common", "criteria", "are", "the", "mean", "squared", "error", "criterion", "implemented", "in", "MSECriterion", "and", "the", "cross", "entropy", "criterion", "implemented", "in", "NLLCriterion", "."], "sentence-detokenized": "Common criteria are the mean squared error criterion implemented in MSECriterion and the cross entropy criterion implemented in NLLCriterion.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 23], [24, 28], [29, 36], [37, 42], [43, 52], [53, 64], [65, 67], [68, 80], [81, 84], [85, 88], [89, 94], [95, 102], [103, 112], [113, 124], [125, 127], [128, 140], [140, 141]]}
{"doc_key": "ai-dev-100", "ner": [[0, 0, "researcher"], [8, 22, "organisation"], [12, 25, "misc"], [29, 32, "conference"], [43, 44, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 22, "role", "", false, false], [0, 0, 29, 32, "role", "", false, false], [0, 0, 43, 44, "role", "", false, false], [12, 25, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zurada", "serves", "the", "engineering", "profession", "as", "a", "longtime", "IEEE", "volunteer", ":", "as", "IEEE", "Vice", "President", "for", "Technical", "Activities", "(", "TAB", "Chair", ")", "in", "2014", ",", "as", "President", "of", "the", "IEEE", "Computational", "Intelligence", "Society", "in", "2004", "-", "05", ",", "and", "as", "a", "member", "of", "ADCOM", "in", "2009", "-", "14", ",", "2016", "-", "18", ",", "and", "in", "previous", "years", "."], "sentence-detokenized": "Zurada serves the engineering profession as a longtime IEEE volunteer: as IEEE Vice President for Technical Activities (TAB Chair) in 2014, as President of the IEEE Computational Intelligence Society in 2004-05, and as a member of ADCOM in 2009-14, 2016-18, and in previous years.", "token2charspan": [[0, 6], [7, 13], [14, 17], [18, 29], [30, 40], [41, 43], [44, 45], [46, 54], [55, 59], [60, 69], [69, 70], [71, 73], [74, 78], [79, 83], [84, 93], [94, 97], [98, 107], [108, 118], [119, 120], [120, 123], [124, 129], [129, 130], [131, 133], [134, 138], [138, 139], [140, 142], [143, 152], [153, 155], [156, 159], [160, 164], [165, 178], [179, 191], [192, 199], [200, 202], [203, 207], [207, 208], [208, 210], [210, 211], [212, 215], [216, 218], [219, 220], [221, 227], [228, 230], [231, 236], [237, 239], [240, 244], [244, 245], [245, 247], [247, 248], [249, 253], [253, 254], [254, 256], [256, 257], [258, 261], [262, 264], [265, 273], [274, 279], [279, 280]]}
{"doc_key": "ai-dev-101", "ner": [[3, 5, "field"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 5, "part-of", "", false, false], [11, 12, 3, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "general", ",", "computational", "linguistics", "involves", "linguists", ",", "computer", "scientists", ",", "artificial", "intelligence", "experts", ",", "mathematicians", ",", "logicians", ",", "philosophers", ",", "cognitive", "scientists", ",", "cognitive", "psychologists", ",", "psycholinguists", ",", "anthropologists", ",", "and", "neuroscientists", ",", "among", "others", "."], "sentence-detokenized": "In general, computational linguistics involves linguists, computer scientists, artificial intelligence experts, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists, and neuroscientists, among others.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 25], [26, 37], [38, 46], [47, 56], [56, 57], [58, 66], [67, 77], [77, 78], [79, 89], [90, 102], [103, 110], [110, 111], [112, 126], [126, 127], [128, 137], [137, 138], [139, 151], [151, 152], [153, 162], [163, 173], [173, 174], [175, 184], [185, 198], [198, 199], [200, 215], [215, 216], [217, 232], [232, 233], [234, 237], [238, 253], [253, 254], [255, 260], [261, 267], [267, 268]]}
{"doc_key": "ai-dev-102", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "inter", "-", "frame", "correlations", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long short-term memory are often used to exploit inter-frame correlations.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [83, 88], [88, 89], [89, 93], [94, 100], [101, 104], [105, 110], [111, 115], [116, 118], [119, 126], [127, 132], [132, 133], [133, 138], [139, 151], [151, 152]]}
{"doc_key": "ai-dev-103", "ner": [[0, 0, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "was", "the", "first", "industrial", "robot", ","], "sentence-detokenized": "Unimate was the first industrial robot,", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 21], [22, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-dev-104", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 11, 13, "win-defeat", "", false, false], [5, 6, 11, 13, "win-defeat", "", false, false], [8, 8, 11, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "won", "the", "2018", "Turing", "Award", "."], "sentence-detokenized": "Along with Geoffrey Hinton and Yann LeCun, Bengio won the 2018 Turing Award.", "token2charspan": [[0, 5], [6, 10], [11, 19], [20, 26], [27, 30], [31, 35], [36, 41], [41, 42], [43, 49], [50, 53], [54, 57], [58, 62], [63, 69], [70, 75], [75, 76]]}
{"doc_key": "ai-dev-105", "ner": [[8, 8, "country"], [21, 24, "misc"], [29, 30, "country"], [33, 34, "organisation"], [37, 38, "person"], [40, 43, "person"], [51, 53, "misc"], [58, 58, "country"], [63, 63, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[21, 24, 8, 8, "physical", "filmed_in", false, false], [37, 38, 33, 34, "role", "host", false, false], [40, 43, 33, 34, "role", "reporter", false, false], [51, 53, 8, 8, "physical", "filmed_in", false, false], [51, 53, 58, 58, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "series", "were", "filmed", "on", "location", "in", "the", "UK", "for", "specific", "sectors", "of", "the", "global", "market", ",", "including", "two", "series", "of", "Robot", "Wars", "Extreme", "Warriors", "with", "contestants", "from", "the", "United", "States", "for", "the", "TNN", "network", "(", "presenter", "Mick", "Foley", "and", "Rebecca", "Grant", "as", "a", "box", "reporter", ")", ",", "two", "series", "of", "Dutch", "Robot", "Wars", "for", "distribution", "in", "the", "Netherlands", "and", "one", "series", "for", "Germany", "."], "sentence-detokenized": "Other series were filmed on location in the UK for specific sectors of the global market, including two series of Robot Wars Extreme Warriors with contestants from the United States for the TNN network (presenter Mick Foley and Rebecca Grant as a box reporter), two series of Dutch Robot Wars for distribution in the Netherlands and one series for Germany.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 24], [25, 27], [28, 36], [37, 39], [40, 43], [44, 46], [47, 50], [51, 59], [60, 67], [68, 70], [71, 74], [75, 81], [82, 88], [88, 89], [90, 99], [100, 103], [104, 110], [111, 113], [114, 119], [120, 124], [125, 132], [133, 141], [142, 146], [147, 158], [159, 163], [164, 167], [168, 174], [175, 181], [182, 185], [186, 189], [190, 193], [194, 201], [202, 203], [203, 212], [213, 217], [218, 223], [224, 227], [228, 235], [236, 241], [242, 244], [245, 246], [247, 250], [251, 259], [259, 260], [260, 261], [262, 265], [266, 272], [273, 275], [276, 281], [282, 287], [288, 292], [293, 296], [297, 309], [310, 312], [313, 316], [317, 328], [329, 332], [333, 336], [337, 343], [344, 347], [348, 355], [355, 356]]}
{"doc_key": "ai-dev-106", "ner": [[4, 6, "researcher"], [12, 14, "product"], [32, 33, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 12, 14, "role", "", false, false], [32, 33, 12, 14, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Beginning", "in", "1986", ",", "Miller", "directed", "for", "many", "years", "the", "development", "of", "WordNet", ",", "a", "large", "-", "scale", "computer", "-", "readable", "electronic", "reference", "that", "can", "be", "used", ",", "for", "example", ",", "in", "search", "engines", "."], "sentence-detokenized": "Beginning in 1986, Miller directed for many years the development of WordNet, a large-scale computer-readable electronic reference that can be used, for example, in search engines.", "token2charspan": [[0, 9], [10, 12], [13, 17], [17, 18], [19, 25], [26, 34], [35, 38], [39, 43], [44, 49], [50, 53], [54, 65], [66, 68], [69, 76], [76, 77], [78, 79], [80, 85], [85, 86], [86, 91], [92, 100], [100, 101], [101, 109], [110, 120], [121, 130], [131, 135], [136, 139], [140, 142], [143, 147], [147, 148], [149, 152], [153, 160], [160, 161], [162, 164], [165, 171], [172, 179], [179, 180]]}
{"doc_key": "ai-dev-107", "ner": [[3, 5, "algorithm"], [7, 10, "algorithm"], [13, 15, "researcher"], [20, 24, "organisation"], [28, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 13, 15, "origin", "", false, false], [3, 5, 28, 30, "win-defeat", "", false, false], [7, 10, 13, 15, "origin", "", false, false], [7, 10, 28, 30, "win-defeat", "", false, false], [13, 15, 20, 24, "physical", "", false, false], [13, 15, 20, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Since", "2009", ",", "recurrent", "neural", "networks", "and", "deep", "feedforward", "neural", "networks", "developed", "in", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "Swiss", "artificial", "intelligence", "laboratory", "IDSIA", "have", "won", "several", "international", "handwriting", "competitions", "."], "sentence-detokenized": "Since 2009, recurrent neural networks and deep feedforward neural networks developed in J\u00fcrgen Schmidhuber's research group at the Swiss artificial intelligence laboratory IDSIA have won several international handwriting competitions.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 21], [22, 28], [29, 37], [38, 41], [42, 46], [47, 58], [59, 65], [66, 74], [75, 84], [85, 87], [88, 94], [95, 106], [106, 108], [109, 117], [118, 123], [124, 126], [127, 130], [131, 136], [137, 147], [148, 160], [161, 171], [172, 177], [178, 182], [183, 186], [187, 194], [195, 208], [209, 220], [221, 233], [233, 234]]}
{"doc_key": "ai-dev-108", "ner": [[5, 6, "programlang"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "is", "implemented", "in", "C", "++", "and", "packaged", "for", "Python", "."], "sentence-detokenized": "The software is implemented in C++ and packaged for Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 30], [31, 32], [32, 34], [35, 38], [39, 47], [48, 51], [52, 58], [58, 59]]}
{"doc_key": "ai-dev-109", "ner": [[7, 9, "country"], [3, 15, "misc"], [27, 28, "misc"], [34, 34, "misc"], [37, 37, "misc"], [39, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[27, 28, 7, 9, "temporal", "", false, false], [27, 28, 3, 15, "artifact", "", false, false], [27, 28, 39, 39, "physical", "", false, false], [37, 37, 34, 34, "named", "", false, false], [37, 37, 39, 39, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1857", ",", "at", "the", "request", "of", "the", "Tokugawa", "shogunate", ",", "a", "group", "of", "Dutch", "engineers", "began", "work", "on", "the", "construction", "of", "the", "modern", "western", "-", "style", "Nagasaki", "Yotetsusho", "foundry", "and", "shipyard", "near", "the", "Dutch", "settlement", "of", "Dejima", "in", "Nagasaki", "."], "sentence-detokenized": "In 1857, at the request of the Tokugawa shogunate, a group of Dutch engineers began work on the construction of the modern western-style Nagasaki Yotetsusho foundry and shipyard near the Dutch settlement of Dejima in Nagasaki.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 39], [40, 49], [49, 50], [51, 52], [53, 58], [59, 61], [62, 67], [68, 77], [78, 83], [84, 88], [89, 91], [92, 95], [96, 108], [109, 111], [112, 115], [116, 122], [123, 130], [130, 131], [131, 136], [137, 145], [146, 156], [157, 164], [165, 168], [169, 177], [178, 182], [183, 186], [187, 192], [193, 203], [204, 206], [207, 213], [214, 216], [217, 225], [225, 226]]}
{"doc_key": "ai-dev-110", "ner": [[8, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "accurately", "as", "possible", ",", "we", "measure", "the", "mean", "squared", "error", "between", "math", "/", "math", "and", "math", "\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "we", "want", "math", "(", "y", "-\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", ".", "^", "2", "/", "math", "to", "be", "minimal", ",", "both", "for", "mathx", "_", "1", ",\\", "dots", ",", "x", "_n", "/", "math", ",", "and", "for", "points", "outside", "our", "sample", "."], "sentence-detokenized": "As accurately as possible, we measure the mean squared error between math / math and math\\ hat {f} (x; D) / math: we want math (y -\\ hat {f} (x; D)). ^ 2 / math to be minimal, both for mathx _ 1,\\ dots, x _n / math, and for points outside our sample.", "token2charspan": [[0, 2], [3, 13], [14, 16], [17, 25], [25, 26], [27, 29], [30, 37], [38, 41], [42, 46], [47, 54], [55, 60], [61, 68], [69, 73], [74, 75], [76, 80], [81, 84], [85, 89], [89, 90], [91, 94], [95, 96], [96, 97], [97, 98], [99, 100], [100, 101], [101, 102], [103, 104], [104, 105], [106, 107], [108, 112], [112, 113], [114, 116], [117, 121], [122, 126], [127, 128], [128, 129], [130, 132], [133, 136], [137, 138], [138, 139], [139, 140], [141, 142], [142, 143], [143, 144], [145, 146], [146, 147], [147, 148], [148, 149], [150, 151], [152, 153], [154, 155], [156, 160], [161, 163], [164, 166], [167, 174], [174, 175], [176, 180], [181, 184], [185, 190], [191, 192], [193, 194], [194, 196], [197, 201], [201, 202], [203, 204], [205, 207], [208, 209], [210, 214], [214, 215], [216, 219], [220, 223], [224, 230], [231, 238], [239, 242], [243, 249], [249, 250]]}
{"doc_key": "ai-dev-111", "ner": [[3, 5, "researcher"], [10, 14, "organisation"], [20, 24, "product"], [32, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 10, 14, "role", "", false, false], [20, 24, 10, 14, "temporal", "", false, false], [20, 24, 32, 33, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "subsequently", "invited", "Vydner", "to", "the", "annual", "meeting", "of", "the", "American", "Translators", "Association", ",", "held", "the", "following", "October", ",", "where", "Weidner", "'s", "machine", "translation", "system", "was", "hailed", "as", "a", "promising", "breakthrough", "in", "machine", "translation", "."], "sentence-detokenized": "He subsequently invited Vydner to the annual meeting of the American Translators Association, held the following October, where Weidner's machine translation system was hailed as a promising breakthrough in machine translation.", "token2charspan": [[0, 2], [3, 15], [16, 23], [24, 30], [31, 33], [34, 37], [38, 44], [45, 52], [53, 55], [56, 59], [60, 68], [69, 80], [81, 92], [92, 93], [94, 98], [99, 102], [103, 112], [113, 120], [120, 121], [122, 127], [128, 135], [135, 137], [138, 145], [146, 157], [158, 164], [165, 168], [169, 175], [176, 178], [179, 180], [181, 190], [191, 203], [204, 206], [207, 214], [215, 226], [226, 227]]}
{"doc_key": "ai-dev-112", "ner": [[8, 14, "conference"], [16, 16, "conference"], [18, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 16, 8, 14, "named", "", false, false], [16, 16, 8, 14, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Researchers", "from", "Google", "presented", "this", "work", "at", "the", "2018", "Conference", "on", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "."], "sentence-detokenized": "Researchers from Google presented this work at the 2018 Conference on Neural Information Processing Systems (NeurIPS).", "token2charspan": [[0, 11], [12, 16], [17, 23], [24, 33], [34, 38], [39, 43], [44, 46], [47, 50], [51, 55], [56, 66], [67, 69], [70, 76], [77, 88], [89, 99], [100, 107], [108, 109], [109, 116], [116, 117], [117, 118]]}
{"doc_key": "ai-dev-113", "ner": [[0, 4, "algorithm"], [10, 12, "algorithm"], [15, 18, "metrics"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 10, 12, "usage", "", false, false], [10, 12, 15, 18, "related-to", "", true, false], [15, 18, 23, 25, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Baum", "-", "Welch", "algorithm", "uses", "the", "well", "-", "known", "EM", "algorithm", "to", "find", "the", "maximum", "likelihood", "estimate", "of", "the", "parameters", "of", "the", "hidden", "Markov", "model", "given", "a", "set", "of", "observed", "feature", "vectors", "."], "sentence-detokenized": "The Baum-Welch algorithm uses the well-known EM algorithm to find the maximum likelihood estimate of the parameters of the hidden Markov model given a set of observed feature vectors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [15, 24], [25, 29], [30, 33], [34, 38], [38, 39], [39, 44], [45, 47], [48, 57], [58, 60], [61, 65], [66, 69], [70, 77], [78, 88], [89, 97], [98, 100], [101, 104], [105, 115], [116, 118], [119, 122], [123, 129], [130, 136], [137, 142], [143, 148], [149, 150], [151, 154], [155, 157], [158, 166], [167, 174], [175, 182], [182, 183]]}
{"doc_key": "ai-dev-114", "ner": [[9, 9, "product"], [11, 11, "product"], [30, 31, "misc"], [37, 46, "product"], [57, 57, "programlang"], [50, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 9, 11, 11, "compare", "", false, false], [30, 31, 11, 11, "part-of", "", false, false], [37, 46, 11, 11, "part-of", "", false, false], [50, 56, 11, 11, "part-of", "", false, false], [50, 56, 57, 57, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": [")", "In", "addition", "to", "the", "taxonomic", "information", "contained", "in", "OpenCyc", ",", "ResearchCyc", "contains", "considerably", "more", "semantic", "knowledge", "(", "i.e.", ",", "additional", "facts", "and", "rules", ")", "involving", "the", "concepts", "in", "its", "knowledge", "base", ";", "it", "also", "contains", "an", "extensive", "lexicon", ",", "tools", "for", "parsing", "and", "generating", "English", "text", ",", "and", "an", "interface", "for", "knowledge", "editing", "and", "querying", "in", "Java", "."], "sentence-detokenized": ") In addition to the taxonomic information contained in OpenCyc, ResearchCyc contains considerably more semantic knowledge (i.e., additional facts and rules) involving the concepts in its knowledge base; it also contains an extensive lexicon, tools for parsing and generating English text, and an interface for knowledge editing and querying in Java.", "token2charspan": [[0, 1], [2, 4], [5, 13], [14, 16], [17, 20], [21, 30], [31, 42], [43, 52], [53, 55], [56, 63], [63, 64], [65, 76], [77, 85], [86, 98], [99, 103], [104, 112], [113, 122], [123, 124], [124, 128], [128, 129], [130, 140], [141, 146], [147, 150], [151, 156], [156, 157], [158, 167], [168, 171], [172, 180], [181, 183], [184, 187], [188, 197], [198, 202], [202, 203], [204, 206], [207, 211], [212, 220], [221, 223], [224, 233], [234, 241], [241, 242], [243, 248], [249, 252], [253, 260], [261, 264], [265, 275], [276, 283], [284, 288], [288, 289], [290, 293], [294, 296], [297, 306], [307, 310], [311, 320], [321, 328], [329, 332], [333, 341], [342, 344], [345, 349], [349, 350]]}
{"doc_key": "ai-dev-115", "ner": [[0, 1, "algorithm"], [4, 5, "task"], [9, 10, "field"], [12, 13, "field"], [15, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 4, 5, "type-of", "", false, false], [4, 5, 9, 10, "part-of", "task_part_of_field", false, false], [4, 5, 12, 13, "part-of", "task_part_of_field", false, false], [4, 5, 15, 17, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Hough", "transform", "is", "a", "feature", "extraction", "technique", "used", "in", "image", "analysis", ",", "computer", "vision", "and", "digital", "image", "processing", "."], "sentence-detokenized": "Hough transform is a feature extraction technique used in image analysis, computer vision and digital image processing.", "token2charspan": [[0, 5], [6, 15], [16, 18], [19, 20], [21, 28], [29, 39], [40, 49], [50, 54], [55, 57], [58, 63], [64, 72], [72, 73], [74, 82], [83, 89], [90, 93], [94, 101], [102, 107], [108, 118], [118, 119]]}
{"doc_key": "ai-dev-116", "ner": [[6, 6, "product"], [8, 12, "product"], [3, 3, "organisation"], [16, 16, "product"], [18, 19, "researcher"], [24, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 8, 12, "named", "", false, false], [6, 6, 3, 3, "artifact", "", false, false], [6, 6, 16, 16, "origin", "developed_from", false, false], [16, 16, 18, 19, "artifact", "", false, false], [24, 25, 3, 3, "role", "supported", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1978", ",", "Unimation", "developed", "the", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "robot", "from", "Vicarm", "(", "Victor", "Scheinman", ")", "with", "support", "from", "General", "Motors", "."], "sentence-detokenized": "In 1978, Unimation developed the PUMA (Programmable Universal Machine for Assembly) robot from Vicarm (Victor Scheinman) with support from General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 28], [29, 32], [33, 37], [38, 39], [39, 51], [52, 61], [62, 69], [70, 73], [74, 82], [82, 83], [84, 89], [90, 94], [95, 101], [102, 103], [103, 109], [110, 119], [119, 120], [121, 125], [126, 133], [134, 138], [139, 146], [147, 153], [153, 154]]}
{"doc_key": "ai-dev-117", "ner": [[0, 1, "algorithm"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 7, 8, "origin", "", false, false], [0, 1, 10, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "LSTM", "was", "designed", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "The LSTM was designed in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 21], [22, 24], [25, 29], [30, 32], [33, 37], [38, 48], [49, 52], [53, 59], [60, 71], [71, 72]]}
{"doc_key": "ai-dev-118", "ner": [[11, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "into", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated into a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 39], [40, 41], [42, 43], [44, 45], [46, 47], [48, 59], [60, 65], [66, 68], [69, 78], [79, 85], [86, 88], [89, 96], [96, 97]]}
{"doc_key": "ai-dev-119", "ner": [[8, 8, "conference"], [11, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "also", "instrumental", "in", "the", "founding", "of", "ELRA", "and", "the", "LREC", "conference", "."], "sentence-detokenized": "He was also instrumental in the founding of ELRA and the LREC conference.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 27], [28, 31], [32, 40], [41, 43], [44, 48], [49, 52], [53, 56], [57, 61], [62, 72], [72, 73]]}
{"doc_key": "ai-dev-120", "ner": [[17, 18, "misc"], [24, 27, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[24, 27, 17, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "popular", "application", "of", "serial", "robots", "in", "today", "'s", "industry", "is", "the", "pick", "-", "and", "-", "place", "assembly", "robot", ",", "the", "so", "-", "called", "SCARA", "robot", ",", "which", "has", "four", "degrees", "of", "freedom", "."], "sentence-detokenized": "A popular application of serial robots in today's industry is the pick-and-place assembly robot, the so-called SCARA robot, which has four degrees of freedom.", "token2charspan": [[0, 1], [2, 9], [10, 21], [22, 24], [25, 31], [32, 38], [39, 41], [42, 47], [47, 49], [50, 58], [59, 61], [62, 65], [66, 70], [70, 71], [71, 74], [74, 75], [75, 80], [81, 89], [90, 95], [95, 96], [97, 100], [101, 103], [103, 104], [104, 110], [111, 116], [117, 122], [122, 123], [124, 129], [130, 133], [134, 138], [139, 146], [147, 149], [150, 157], [157, 158]]}
{"doc_key": "ai-dev-121", "ner": [[15, 21, "conference"], [23, 23, "conference"], [27, 30, "conference"], [38, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 15, 21, "named", "", false, false], [38, 38, 27, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "one", "of", "the", "founding", "members", "and", "former", "chair", "(", "2006-2008", ")", "of", "the", "Special", "Interest", "Group", "on", "Web", "as", "Corpus", "(", "SIGWAC", ")", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "one", "of", "the", "founding", "organizers", "of", "SENSEVAL", "."], "sentence-detokenized": "He was one of the founding members and former chair (2006-2008) of the Special Interest Group on Web as Corpus (SIGWAC) of the Association for Computational Linguistics and one of the founding organizers of SENSEVAL.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 17], [18, 26], [27, 34], [35, 38], [39, 45], [46, 51], [52, 53], [53, 62], [62, 63], [64, 66], [67, 70], [71, 78], [79, 87], [88, 93], [94, 96], [97, 100], [101, 103], [104, 110], [111, 112], [112, 118], [118, 119], [120, 122], [123, 126], [127, 138], [139, 142], [143, 156], [157, 168], [169, 172], [173, 176], [177, 179], [180, 183], [184, 192], [193, 203], [204, 206], [207, 215], [215, 216]]}
{"doc_key": "ai-dev-122", "ner": [[4, 4, "product"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 4, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "platform", ",", "LinguaStream", "provides", "an", "extensive", "Java", "API", "."], "sentence-detokenized": "As a platform, LinguaStream provides an extensive Java API.", "token2charspan": [[0, 2], [3, 4], [5, 13], [13, 14], [15, 27], [28, 36], [37, 39], [40, 49], [50, 54], [55, 58], [58, 59]]}
{"doc_key": "ai-dev-123", "ner": [[11, 13, "programlang"], [14, 16, "misc"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 13, 19, 21, "type-of", "", false, false], [14, 16, 19, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "robotic", "kit", "is", "based", "on", "Android", "and", "is", "programmed", "using", "Java", ",", "the", "Blocks", "programming", "interface", "or", "other", "Android", "programming", "systems", "."], "sentence-detokenized": "The robotic kit is based on Android and is programmed using Java, the Blocks programming interface or other Android programming systems.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 18], [19, 24], [25, 27], [28, 35], [36, 39], [40, 42], [43, 53], [54, 59], [60, 64], [64, 65], [66, 69], [70, 76], [77, 88], [89, 98], [99, 101], [102, 107], [108, 115], [116, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-dev-124", "ner": [[11, 13, "algorithm"], [15, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "method", "of", "defining", "a", "linked", "list", "determines", "the", "use", "of", "depth", "-", "first", "or", "breadth", "-", "first", "searching", "."], "sentence-detokenized": "The method of defining a linked list determines the use of depth-first or breadth-first searching.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 22], [23, 24], [25, 31], [32, 36], [37, 47], [48, 51], [52, 55], [56, 58], [59, 64], [64, 65], [65, 70], [71, 73], [74, 81], [81, 82], [82, 87], [88, 97], [97, 98]]}
{"doc_key": "ai-dev-125", "ner": [[19, 20, "task"], [24, 27, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "areas", "could", "indicate", "the", "presence", "of", "objects", "or", "parts", "of", "objects", "in", "the", "image", "area", "for", "use", "in", "object", "recognition", "and", "/", "or", "object", "tracking", "on", "video", "."], "sentence-detokenized": "These areas could indicate the presence of objects or parts of objects in the image area for use in object recognition and/or object tracking on video.", "token2charspan": [[0, 5], [6, 11], [12, 17], [18, 26], [27, 30], [31, 39], [40, 42], [43, 50], [51, 53], [54, 59], [60, 62], [63, 70], [71, 73], [74, 77], [78, 83], [84, 88], [89, 92], [93, 96], [97, 99], [100, 106], [107, 118], [119, 122], [122, 123], [123, 125], [126, 132], [133, 141], [142, 144], [145, 150], [150, 151]]}
{"doc_key": "ai-dev-126", "ner": [[4, 5, "algorithm"], [7, 9, "product"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 4, 5, "type-of", "", false, false], [7, 9, 13, 13, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "semantic", "network", "is", "WordNet", ",", "a", "lexical", "database", "of", "English", "."], "sentence-detokenized": "An example of a semantic network is WordNet, a lexical database of English.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 32], [33, 35], [36, 43], [43, 44], [45, 46], [47, 54], [55, 63], [64, 66], [67, 74], [74, 75]]}
{"doc_key": "ai-dev-127", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 15, "field"], [24, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 7, 8, "part-of", "", false, false], [0, 1, 10, 15, "named", "same", false, false], [0, 1, 10, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Speech", "recognition", "is", "an", "interdisciplinary", "subfield", "of", "computer", "science", "and", "computational", "linguistics", "that", "deals", "with", "the", "development", "of", "methodologies", "and", "technologies", "that", "enable", "the", "recognition", "and", "conversion", "of", "spoken", "speech", "to", "text", "using", "computers", "."], "sentence-detokenized": "Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that deals with the development of methodologies and technologies that enable the recognition and conversion of spoken speech to text using computers.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 24], [25, 42], [43, 51], [52, 54], [55, 63], [64, 71], [72, 75], [76, 89], [90, 101], [102, 106], [107, 112], [113, 117], [118, 121], [122, 133], [134, 136], [137, 150], [151, 154], [155, 167], [168, 172], [173, 179], [180, 183], [184, 195], [196, 199], [200, 210], [211, 213], [214, 220], [221, 227], [228, 230], [231, 235], [236, 241], [242, 251], [251, 252]]}
{"doc_key": "ai-dev-128", "ner": [[0, 1, "field"], [11, 13, "misc"], [17, 19, "field"], [21, 21, "task"], [23, 26, "task"], [44, 44, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 44, 44, "named", "same", false, false], [17, 19, 0, 1, "part-of", "subfield", false, false], [21, 21, 0, 1, "part-of", "", false, false], [21, 21, 17, 19, "part-of", "", false, false], [23, 26, 17, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Artificial", "Intelligence", "has", "retained", "most", "of", "the", "attention", "in", "terms", "of", "applied", "ontology", "in", "subfields", "such", "as", "natural", "language", "processing", "within", "machine", "and", "knowledge", "representation", ",", "but", "ontology", "editors", "are", "often", "used", "in", "many", "areas", "such", "as", "education", "without", "the", "goal", "of", "contributing", "to", "AI", "."], "sentence-detokenized": "Artificial Intelligence has retained most of the attention in terms of applied ontology in subfields such as natural language processing within machine and knowledge representation, but ontology editors are often used in many areas such as education without the goal of contributing to AI.", "token2charspan": [[0, 10], [11, 23], [24, 27], [28, 36], [37, 41], [42, 44], [45, 48], [49, 58], [59, 61], [62, 67], [68, 70], [71, 78], [79, 87], [88, 90], [91, 100], [101, 105], [106, 108], [109, 116], [117, 125], [126, 136], [137, 143], [144, 151], [152, 155], [156, 165], [166, 180], [180, 181], [182, 185], [186, 194], [195, 202], [203, 206], [207, 212], [213, 217], [218, 220], [221, 225], [226, 231], [232, 236], [237, 239], [240, 249], [250, 257], [258, 261], [262, 266], [267, 269], [270, 282], [283, 285], [286, 288], [288, 289]]}
{"doc_key": "ai-dev-129", "ner": [[7, 11, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 11, 12, 13, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "updating", "rule", "is", "in", "fact", "a", "stochastic", "gradient", "descent", "update", "for", "linear", "regression", "."], "sentence-detokenized": "This updating rule is in fact a stochastic gradient descent update for linear regression.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 21], [22, 24], [25, 29], [30, 31], [32, 42], [43, 51], [52, 59], [60, 66], [67, 70], [71, 77], [78, 88], [88, 89]]}
{"doc_key": "ai-dev-130", "ner": [[7, 12, "organisation"], [15, 18, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "elected", "a", "member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "the", "National", "Academy", "of", "Sciences", "and", "received", "numerous", "awards", ":"], "sentence-detokenized": "He was elected a member of the American Academy of Arts and Sciences and the National Academy of Sciences and received numerous awards:", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 16], [17, 23], [24, 26], [27, 30], [31, 39], [40, 47], [48, 50], [51, 55], [56, 59], [60, 68], [69, 72], [73, 76], [77, 85], [86, 93], [94, 96], [97, 105], [106, 109], [110, 118], [119, 127], [128, 134], [134, 135]]}
{"doc_key": "ai-dev-131", "ner": [[0, 11, "organisation"], [12, 13, "person"], [15, 20, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 11, 12, 13, "related-to", "written_about_by", false, false], [0, 11, 15, 20, "related-to", "written_about_by", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Honda", "'s", "most", "recent", "school", "of", "thought", "on", "strategy", "was", "introduced", "by", "Gary", "Hamel", "and", "C.", "K", ".", "Prahalad", "in", "1989", "."], "sentence-detokenized": "Honda's most recent school of thought on strategy was introduced by Gary Hamel and C. K. Prahalad in 1989.", "token2charspan": [[0, 5], [5, 7], [8, 12], [13, 19], [20, 26], [27, 29], [30, 37], [38, 40], [41, 49], [50, 53], [54, 64], [65, 67], [68, 72], [73, 78], [79, 82], [83, 85], [86, 87], [87, 88], [89, 97], [98, 100], [101, 105], [105, 106]]}
{"doc_key": "ai-dev-132", "ner": [[0, 1, "metrics"], [5, 6, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 5, 6, "related-to", "calculates", true, false], [0, 1, 17, 17, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Where", "BLEU", "simply", "calculates", "the", "precision", "of", "the", "n-grams", "and", "gives", "each", "of", "them", "equal", "weight", ",", "NIST", "also", "calculates", "how", "informative", "a", "given", "n-", "gram", "is", "."], "sentence-detokenized": "Where BLEU simply calculates the precision of the n-grams and gives each of them equal weight, NIST also calculates how informative a given n-gram is.", "token2charspan": [[0, 5], [6, 10], [11, 17], [18, 28], [29, 32], [33, 42], [43, 45], [46, 49], [50, 57], [58, 61], [62, 67], [68, 72], [73, 75], [76, 80], [81, 86], [87, 93], [93, 94], [95, 99], [100, 104], [105, 115], [116, 119], [120, 131], [132, 133], [134, 139], [140, 142], [142, 146], [147, 149], [149, 150]]}
{"doc_key": "ai-dev-133", "ner": [[0, 9, "misc"], [12, 15, "conference"], [17, 17, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 9, 12, 15, "temporal", "", false, false], [17, 17, 12, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2019", ",", "he", "was", "awarded", "the", "Lifetime", "Achievement", "Award", "from", "the", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "In 2019, he was awarded the Lifetime Achievement Award from the Association for Computational Linguistics (ACL).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 27], [28, 36], [37, 48], [49, 54], [55, 59], [60, 63], [64, 75], [76, 79], [80, 93], [94, 105], [106, 107], [107, 110], [110, 111], [111, 112]]}
{"doc_key": "ai-dev-134", "ner": [[0, 0, "researcher"], [5, 11, "organisation"], [13, 13, "organisation"], [20, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 11, "role", "", false, false], [0, 0, 20, 24, "role", "", false, false], [13, 13, 5, 11, "named", "", false, false], [26, 26, 20, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "is", "a", "Fellow", "of", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "and", "a", "member", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara is a Fellow of the Institute of Electrical and Electronics Engineers (IEEE) and a member of the American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 18], [19, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 65], [66, 75], [76, 77], [77, 81], [81, 82], [83, 86], [87, 88], [89, 95], [96, 98], [99, 102], [103, 111], [112, 123], [124, 127], [128, 138], [139, 151], [152, 153], [153, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-dev-135", "ner": [[2, 2, "product"], [10, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 10, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "following", "MATLAB", "code", "demonstrates", "a", "concrete", "solution", "to", "the", "nonlinear", "system", "of", "equations", "presented", "in", "the", "previous", "section", "."], "sentence-detokenized": "The following MATLAB code demonstrates a concrete solution to the nonlinear system of equations presented in the previous section.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 38], [39, 40], [41, 49], [50, 58], [59, 61], [62, 65], [66, 75], [76, 82], [83, 85], [86, 95], [96, 105], [106, 108], [109, 112], [113, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-dev-136", "ner": [[4, 6, "product"], [14, 18, "field"], [37, 38, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 14, 18, "related-to", "trained_by", true, false], [4, 6, 37, 38, "related-to", "trained_by", true, false], [14, 18, 37, 38, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "many", "cases", ",", "pattern", "recognition", "systems", "are", "trained", "on", "labeled", "training", "data", "(", "supervised", "learning", ")", ",", "but", "if", "no", "labeled", "data", "is", "available", ",", "other", "algorithms", "can", "be", "used", "to", "discover", "previously", "unknown", "patterns", "(", "unsupervised", "learning", ")", "."], "sentence-detokenized": "In many cases, pattern recognition systems are trained on labeled training data (supervised learning), but if no labeled data is available, other algorithms can be used to discover previously unknown patterns (unsupervised learning).", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 22], [23, 34], [35, 42], [43, 46], [47, 54], [55, 57], [58, 65], [66, 74], [75, 79], [80, 81], [81, 91], [92, 100], [100, 101], [101, 102], [103, 106], [107, 109], [110, 112], [113, 120], [121, 125], [126, 128], [129, 138], [138, 139], [140, 145], [146, 156], [157, 160], [161, 163], [164, 168], [169, 171], [172, 180], [181, 191], [192, 199], [200, 208], [209, 210], [210, 222], [223, 231], [231, 232], [232, 233]]}
{"doc_key": "ai-dev-137", "ner": [[5, 7, "researcher"], [10, 11, "country"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 10, 11, "physical", "", false, false], [5, 7, 23, 24, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "was", "first", "used", "by", "Lawrence", "J.", "Fogel", "in", "the", "USA", "in", "1960", "to", "use", "simulated", "evolution", "as", "a", "learning", "process", "to", "create", "artificial", "intelligence", "."], "sentence-detokenized": "It was first used by Lawrence J. Fogel in the USA in 1960 to use simulated evolution as a learning process to create artificial intelligence.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 17], [18, 20], [21, 29], [30, 32], [33, 38], [39, 41], [42, 45], [46, 49], [50, 52], [53, 57], [58, 60], [61, 64], [65, 74], [75, 84], [85, 87], [88, 89], [90, 98], [99, 106], [107, 109], [110, 116], [117, 127], [128, 140], [140, 141]]}
{"doc_key": "ai-dev-138", "ner": [[0, 1, "field"], [10, 11, "field"], [14, 16, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 10, 11, "part-of", "", false, false], [14, 16, 10, 11, "part-of", "", false, false], [17, 18, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Reinforcement", "learning", "is", "one", "of", "the", "three", "basic", "paradigms", "of", "machine", "learning", ",", "alongside", "supervised", "learning", "and", "unsupervised", "learning", "."], "sentence-detokenized": "Reinforcement learning is one of the three basic paradigms of machine learning, alongside supervised learning and unsupervised learning.", "token2charspan": [[0, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 42], [43, 48], [49, 58], [59, 61], [62, 69], [70, 78], [78, 79], [80, 89], [90, 100], [101, 109], [110, 113], [114, 126], [127, 135], [135, 136]]}
{"doc_key": "ai-dev-139", "ner": [[4, 5, "field"], [12, 12, "programlang"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 27, 28, "usage", "applies", false, false], [12, 12, 27, 28, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "such", "cases", ",", "cloud", "computing", "and", "the", "open", "source", "programming", "language", "R", "can", "help", "smaller", "banks", "implement", "risk", "analysis", "and", "support", "branch", "-", "level", "monitoring", "through", "predictive", "analytics", "."], "sentence-detokenized": "In such cases, cloud computing and the open source programming language R can help smaller banks implement risk analysis and support branch-level monitoring through predictive analytics.", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 20], [21, 30], [31, 34], [35, 38], [39, 43], [44, 50], [51, 62], [63, 71], [72, 73], [74, 77], [78, 82], [83, 90], [91, 96], [97, 106], [107, 111], [112, 120], [121, 124], [125, 132], [133, 139], [139, 140], [140, 145], [146, 156], [157, 164], [165, 175], [176, 185], [185, 186]]}
{"doc_key": "ai-dev-140", "ner": [[11, 14, "researcher"], [20, 22, "algorithm"], [24, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 14, 24, 25, "named", "same", false, false], [20, 22, 11, 14, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["One", "of", "the", "first", "versions", "of", "the", "theorem", "was", "proved", "by", "George", "Cybenko", "in", "1989", "for", "the", "activation", "function", "of", "the", "sigmoid", "function", ".", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "One of the first versions of the theorem was proved by George Cybenko in 1989 for the activation function of the sigmoid function. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 25], [26, 28], [29, 32], [33, 40], [41, 44], [45, 51], [52, 54], [55, 61], [62, 69], [70, 72], [73, 77], [78, 81], [82, 85], [86, 96], [97, 105], [106, 108], [109, 112], [113, 120], [121, 129], [129, 130], [131, 138], [139, 141], [142, 143], [143, 147], [147, 148], [148, 149], [150, 151], [152, 153], [153, 154], [154, 155], [155, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-dev-141", "ner": [[6, 8, "algorithm"], [9, 11, "metrics"], [14, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 11, 6, 8, "part-of", "", false, false], [14, 18, 9, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "process", ",", "known", "as", "cross-validation", ",", "the", "MSE", "is", "often", "called", "the", "mean", "square", "error", "of", "prediction", "and", "is", "calculated", "as"], "sentence-detokenized": "In this process, known as cross-validation, the MSE is often called the mean square error of prediction and is calculated as", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 22], [23, 25], [26, 42], [42, 43], [44, 47], [48, 51], [52, 54], [55, 60], [61, 67], [68, 71], [72, 76], [77, 83], [84, 89], [90, 92], [93, 103], [104, 107], [108, 110], [111, 121], [122, 124]]}
{"doc_key": "ai-dev-142", "ner": [[0, 0, "task"], [4, 6, "task"], [8, 10, "task"], [18, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "compare", "", false, false], [4, 6, 18, 20, "part-of", "", false, false], [8, 10, 4, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OMR", "generally", "differs", "from", "optical", "character", "recognition", "(", "OCR", ")", "in", "that", "it", "does", "not", "require", "a", "complex", "pattern", "recognition", "machine", "."], "sentence-detokenized": "OMR generally differs from optical character recognition (OCR) in that it does not require a complex pattern recognition machine.", "token2charspan": [[0, 3], [4, 13], [14, 21], [22, 26], [27, 34], [35, 44], [45, 56], [57, 58], [58, 61], [61, 62], [63, 65], [66, 70], [71, 73], [74, 78], [79, 82], [83, 90], [91, 92], [93, 100], [101, 108], [109, 120], [121, 128], [128, 129]]}
{"doc_key": "ai-dev-143", "ner": [[10, 10, "location"], [12, 12, "location"], [14, 14, "location"], [16, 17, "location"], [19, 20, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 14, 14, "physical", "", false, false], [16, 17, 12, 12, "physical", "", false, false], [19, 20, 12, 12, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2018", "and", "2019", ",", "the", "championship", "was", "held", "in", "Houston", "and", "Detroit", ",", "Michigan", "at", "TCF", "Center", "and", "Ford", "Field", "."], "sentence-detokenized": "In 2018 and 2019, the championship was held in Houston and Detroit, Michigan at TCF Center and Ford Field.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 16], [16, 17], [18, 21], [22, 34], [35, 38], [39, 43], [44, 46], [47, 54], [55, 58], [59, 66], [66, 67], [68, 76], [77, 79], [80, 83], [84, 90], [91, 94], [95, 99], [100, 105], [105, 106]]}
{"doc_key": "ai-dev-144", "ner": [[0, 0, "task"], [10, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 0, 0, "part-of", "", false, false], [13, 14, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "thought", "of", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multi-class", "classification", "."], "sentence-detokenized": "Classification can be thought of as two separate problems - binary classification and multi-class classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 29], [30, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 97], [98, 112], [112, 113]]}
{"doc_key": "ai-dev-145", "ner": [[4, 5, "product"], [8, 9, "product"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "type-of", "", false, false], [12, 13, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "examples", "of", "popular", "parallel", "robots", "are", "the", "Stewart", "platform", "and", "the", "Delta", "robot", "."], "sentence-detokenized": "Two examples of popular parallel robots are the Stewart platform and the Delta robot.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 23], [24, 32], [33, 39], [40, 43], [44, 47], [48, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-146", "ner": [[3, 8, "algorithm"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 8, 22, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "However", ",", "the", "ReLU", "activation", "function", ",", "which", "is", "nondifferentiable", "at", "0", ",", "has", "become", "quite", "popular", ",", "e.g.", "in", "the", "Alex", "Net", "network", ")", "."], "sentence-detokenized": "(However, the ReLU activation function, which is nondifferentiable at 0, has become quite popular, e.g. in the AlexNet network).", "token2charspan": [[0, 1], [1, 8], [8, 9], [10, 13], [14, 18], [19, 29], [30, 38], [38, 39], [40, 45], [46, 48], [49, 66], [67, 69], [70, 71], [71, 72], [73, 76], [77, 83], [84, 89], [90, 97], [97, 98], [99, 103], [104, 106], [107, 110], [111, 115], [115, 118], [119, 126], [126, 127], [127, 128]]}
{"doc_key": "ai-dev-147", "ner": [[0, 4, "metrics"], [7, 8, "task"], [11, 11, "task"], [14, 15, "task"], [18, 21, "task"], [23, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 4, 23, 23, "named", "", true, false], [7, 8, 0, 4, "usage", "", true, false], [11, 11, 7, 8, "part-of", "", false, false], [14, 15, 7, 8, "part-of", "", false, false], [18, 21, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["F", "-", "scores", "are", "often", "used", "in", "information", "retrieval", "to", "measure", "search", "performance", ",", "document", "classification", ",", "and", "query", "classification", ",", "and", "therefore", "F_beta", "has", "wide", "application", "."], "sentence-detokenized": "F-scores are often used in information retrieval to measure search performance, document classification, and query classification, and therefore F_beta has wide application.", "token2charspan": [[0, 1], [1, 2], [2, 8], [9, 12], [13, 18], [19, 23], [24, 26], [27, 38], [39, 48], [49, 51], [52, 59], [60, 66], [67, 78], [78, 79], [80, 88], [89, 103], [103, 104], [105, 108], [109, 114], [115, 129], [129, 130], [131, 134], [135, 144], [145, 151], [152, 155], [156, 160], [161, 172], [172, 173]]}
{"doc_key": "ai-dev-148", "ner": [[17, 18, "algorithm"], [20, 20, "algorithm"], [23, 24, "algorithm"], [26, 26, "algorithm"], [30, 32, "algorithm"], [34, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 20, 17, 18, "named", "", false, false], [26, 26, 23, 24, "named", "", false, false], [34, 34, 30, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "is", "done", "by", "modeling", "the", "received", "signal", "and", "then", "using", "a", "statistical", "estimation", "method", "such", "as", "maximum", "likelihood", "(", "ML", ")", ",", "majority", "voting", "(", "MV", ")", ",", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "to", "decide", "which", "target", "in", "the", "library", "best", "fits", "the", "model", "built", "based", "on", "the", "received", "signal", "."], "sentence-detokenized": "This is done by modeling the received signal and then using a statistical estimation method such as maximum likelihood (ML), majority voting (MV), or maximum a posteriori (MAP) to decide which target in the library best fits the model built based on the received signal.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 24], [25, 28], [29, 37], [38, 44], [45, 48], [49, 53], [54, 59], [60, 61], [62, 73], [74, 84], [85, 91], [92, 96], [97, 99], [100, 107], [108, 118], [119, 120], [120, 122], [122, 123], [123, 124], [125, 133], [134, 140], [141, 142], [142, 144], [144, 145], [145, 146], [147, 149], [150, 157], [158, 159], [160, 170], [171, 172], [172, 175], [175, 176], [177, 179], [180, 186], [187, 192], [193, 199], [200, 202], [203, 206], [207, 214], [215, 219], [220, 224], [225, 228], [229, 234], [235, 240], [241, 246], [247, 249], [250, 253], [254, 262], [263, 269], [269, 270]]}
{"doc_key": "ai-dev-149", "ner": [[0, 2, "researcher"], [3, 3, "misc"], [5, 5, "field"], [8, 12, "university"], [16, 16, "misc"], [18, 19, "field"], [21, 24, "university"], [28, 29, "misc"], [30, 31, "field"], [34, 36, "university"], [43, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 8, 12, "physical", "", false, false], [0, 2, 8, 12, "role", "", false, false], [0, 2, 21, 24, "physical", "", false, false], [0, 2, 21, 24, "role", "", false, false], [0, 2, 34, 36, "physical", "", false, false], [0, 2, 34, 36, "role", "", false, false], [3, 3, 0, 2, "origin", "", false, false], [3, 3, 5, 5, "topic", "", false, false], [16, 16, 0, 2, "origin", "", false, false], [16, 16, 18, 19, "topic", "", false, false], [28, 29, 0, 2, "origin", "", false, false], [28, 29, 30, 31, "topic", "", false, false], [43, 55, 28, 29, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Sowa", "received", "a", "B.S.", "in", "mathematics", "from", "the", "Massachusetts", "Institute", "of", "Technology", "in", "1962", ",", "an", "M.S.", "in", "applied", "mathematics", "from", "Harvard", "University", "in", "1966", ",", "and", "a", "Ph.D.", "in", "computer", "science", "from", "the", "Vrije", "Universiteit", "Brussel", "in", "1999", "for", "his", "dissertation", ",", "Knowledge", "Representation", ":", "and", "its", "title", "is", "Logical", ",", "Philosophical", "and", "Computational", "Foundations", "."], "sentence-detokenized": "Sowa received a B.S. in mathematics from the Massachusetts Institute of Technology in 1962, an M.S. in applied mathematics from Harvard University in 1966, and a Ph.D. in computer science from the Vrije Universiteit Brussel in 1999 for his dissertation, Knowledge Representation: and its title is Logical, Philosophical and Computational Foundations.", "token2charspan": [[0, 4], [5, 13], [14, 15], [16, 20], [21, 23], [24, 35], [36, 40], [41, 44], [45, 58], [59, 68], [69, 71], [72, 82], [83, 85], [86, 90], [90, 91], [92, 94], [95, 99], [100, 102], [103, 110], [111, 122], [123, 127], [128, 135], [136, 146], [147, 149], [150, 154], [154, 155], [156, 159], [160, 161], [162, 167], [168, 170], [171, 179], [180, 187], [188, 192], [193, 196], [197, 202], [203, 215], [216, 223], [224, 226], [227, 231], [232, 235], [236, 239], [240, 252], [252, 253], [254, 263], [264, 278], [278, 279], [280, 283], [284, 287], [288, 293], [294, 296], [297, 304], [304, 305], [306, 319], [320, 323], [324, 337], [338, 349], [349, 350]]}
{"doc_key": "ai-dev-150", "ner": [[1, 2, "task"], [7, 7, "task"], [16, 16, "metrics"], [18, 19, "metrics"], [21, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 7, 7, "general-affiliation", "", false, false], [16, 16, 1, 2, "part-of", "", true, false], [18, 19, 1, 2, "part-of", "", true, false], [21, 22, 1, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "paraphrase", "recognition", "can", "be", "considered", "a", "classification", "problem", ",", "most", "standard", "evaluation", "metrics", "such", "as", "accuracy", ",", "f1", "score", "or", "ROC", "curve", "perform", "relatively", "well", "."], "sentence-detokenized": "Since paraphrase recognition can be considered a classification problem, most standard evaluation metrics such as accuracy, f1 score or ROC curve perform relatively well.", "token2charspan": [[0, 5], [6, 16], [17, 28], [29, 32], [33, 35], [36, 46], [47, 48], [49, 63], [64, 71], [71, 72], [73, 77], [78, 86], [87, 97], [98, 105], [106, 110], [111, 113], [114, 122], [122, 123], [124, 126], [127, 132], [133, 135], [136, 139], [140, 145], [146, 153], [154, 164], [165, 169], [169, 170]]}
{"doc_key": "ai-dev-151", "ner": [[19, 21, "algorithm"], [29, 30, "algorithm"], [32, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 21, 29, 30, "opposite", "not_suited_for", false, false], [19, 21, 32, 33, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "makes", "it", "practical", "for", "the", "analysis", "of", "large", "datasets", "(", "hundreds", "or", "thousands", "of", "taxa", ")", "and", "for", "bootstrapping", ",", "for", "which", "other", "analysis", "methods", "(", "e.g.", ",", "maximum", "parsimony", ",", "maximum", "likelihood", ")", "may", "be", "computationally", "prohibitive", "."], "sentence-detokenized": "This makes it practical for the analysis of large datasets (hundreds or thousands of taxa) and for bootstrapping, for which other analysis methods (e.g., maximum parsimony, maximum likelihood) may be computationally prohibitive.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 31], [32, 40], [41, 43], [44, 49], [50, 58], [59, 60], [60, 68], [69, 71], [72, 81], [82, 84], [85, 89], [89, 90], [91, 94], [95, 98], [99, 112], [112, 113], [114, 117], [118, 123], [124, 129], [130, 138], [139, 146], [147, 148], [148, 152], [152, 153], [154, 161], [162, 171], [171, 172], [173, 180], [181, 191], [191, 192], [193, 196], [197, 199], [200, 215], [216, 227], [227, 228]]}
{"doc_key": "ai-dev-152", "ner": [[3, 5, "programlang"], [8, 12, "organisation"], [14, 16, "organisation"], [22, 22, "programlang"], [26, 37, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[14, 16, 8, 12, "named", "", false, false], [26, 37, 3, 5, "role", "submits", true, false], [26, 37, 8, 12, "role", "submits_to", true, false]], "relations_mapping_to_source": [1, 3, 4], "sentence": ["Submission", "of", "the", "DAML", "+", "OIL", "language", "to", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", "in", "2002", ",", "work", "done", "by", "DAML", "vendors", "and", "the", "ad", "hoc", "European", "Union", "/", "United", "States", "Joint", "Committee", "on", "Markup", "Languages", "."], "sentence-detokenized": "Submission of the DAML+OIL language to the World Wide Web Consortium (W3C) in 2002, work done by DAML vendors and the ad hoc European Union/United States Joint Committee on Markup Languages.", "token2charspan": [[0, 10], [11, 13], [14, 17], [18, 22], [22, 23], [23, 26], [27, 35], [36, 38], [39, 42], [43, 48], [49, 53], [54, 57], [58, 68], [69, 70], [70, 73], [73, 74], [75, 77], [78, 82], [82, 83], [84, 88], [89, 93], [94, 96], [97, 101], [102, 109], [110, 113], [114, 117], [118, 120], [121, 124], [125, 133], [134, 139], [139, 140], [140, 146], [147, 153], [154, 159], [160, 169], [170, 172], [173, 179], [180, 189], [189, 190]]}
{"doc_key": "ai-dev-153", "ner": [[3, 7, "misc"], [9, 9, "misc"], [15, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 3, 7, "part-of", "", true, false], [15, 18, 3, 7, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "non-linear", "normalization", "is", "the", "case", "where", "normalization", "is", "performed", "according", "to", "a", "sigmoid", "function", ",", "in", "this", "case", "the", "normalized", "image", "is", "calculated", "according", "to", "the", "formula"], "sentence-detokenized": "An example of non-linear normalization is the case where normalization is performed according to a sigmoid function, in this case the normalized image is calculated according to the formula", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 38], [39, 41], [42, 45], [46, 50], [51, 56], [57, 70], [71, 73], [74, 83], [84, 93], [94, 96], [97, 98], [99, 106], [107, 115], [115, 116], [117, 119], [120, 124], [125, 129], [130, 133], [134, 144], [145, 150], [151, 153], [154, 164], [165, 174], [175, 177], [178, 181], [182, 189]]}
{"doc_key": "ai-dev-154", "ner": [[5, 5, "metrics"], [10, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 10, 11, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "pointed", "out", "that", "accuracy", "is", "usually", "associated", "with", "recall", "to", "overcome", "this", "problem", "."], "sentence-detokenized": "It was pointed out that accuracy is usually associated with recall to overcome this problem.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 18], [19, 23], [24, 32], [33, 35], [36, 43], [44, 54], [55, 59], [60, 66], [67, 69], [70, 78], [79, 83], [84, 91], [91, 92]]}
{"doc_key": "ai-dev-155", "ner": [[4, 6, "metrics"], [8, 15, "metrics"], [21, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 22, 8, 15, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Commonly", "used", "metrics", "are", "mean", "square", "error", "and", "root", "mean", "square", "error", ",", "the", "latter", "of", "which", "was", "used", "in", "the", "Netflix", "price", "."], "sentence-detokenized": "Commonly used metrics are mean square error and root mean square error, the latter of which was used in the Netflix price.", "token2charspan": [[0, 8], [9, 13], [14, 21], [22, 25], [26, 30], [31, 37], [38, 43], [44, 47], [48, 52], [53, 57], [58, 64], [65, 70], [70, 71], [72, 75], [76, 82], [83, 85], [86, 91], [92, 95], [96, 100], [101, 103], [104, 107], [108, 115], [116, 121], [121, 122]]}
{"doc_key": "ai-dev-156", "ner": [[8, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "August", "2016", ",", "a", "research", "programme", "with", "University", "College", "Hospital", "was", "announced", "to", "develop", "an", "algorithm", "that", "can", "automatically", "distinguish", "between", "healthy", "and", "cancerous", "tissue", "in", "the", "head", "and", "neck", "region", "."], "sentence-detokenized": "In August 2016, a research programme with University College Hospital was announced to develop an algorithm that can automatically distinguish between healthy and cancerous tissue in the head and neck region.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 17], [18, 26], [27, 36], [37, 41], [42, 52], [53, 60], [61, 69], [70, 73], [74, 83], [84, 86], [87, 94], [95, 97], [98, 107], [108, 112], [113, 116], [117, 130], [131, 142], [143, 150], [151, 158], [159, 162], [163, 172], [173, 179], [180, 182], [183, 186], [187, 191], [192, 195], [196, 200], [201, 207], [207, 208]]}
{"doc_key": "ai-dev-157", "ner": [[3, 4, "researcher"], [16, 18, "organisation"], [21, 24, "organisation"], [27, 30, "organisation"], [33, 38, "organisation"], [41, 47, "organisation"], [51, 54, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 4, 16, 18, "role", "", false, false], [3, 4, 21, 24, "role", "", false, false], [3, 4, 27, 30, "role", "", false, false], [3, 4, 33, 38, "role", "", false, false], [3, 4, 41, 47, "role", "", false, false], [3, 4, 51, 54, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "impact", "of", "Posner", "'s", "theoretical", "and", "empirical", "contributions", "has", "been", "recognized", "through", "membership", "in", "the", "American", "Psychological", "Association", ",", "the", "Association", "for", "Psychological", "Science", ",", "the", "Society", "of", "Experimental", "Psychologists", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "The impact of Posner's theoretical and empirical contributions has been recognized through membership in the American Psychological Association, the Association for Psychological Science, the Society of Experimental Psychologists, the American Academy of Arts and Sciences, the American Association for the Advancement of Science, and the National Academy of Sciences.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 20], [20, 22], [23, 34], [35, 38], [39, 48], [49, 62], [63, 66], [67, 71], [72, 82], [83, 90], [91, 101], [102, 104], [105, 108], [109, 117], [118, 131], [132, 143], [143, 144], [145, 148], [149, 160], [161, 164], [165, 178], [179, 186], [186, 187], [188, 191], [192, 199], [200, 202], [203, 215], [216, 229], [229, 230], [231, 234], [235, 243], [244, 251], [252, 254], [255, 259], [260, 263], [264, 272], [272, 273], [274, 277], [278, 286], [287, 298], [299, 302], [303, 306], [307, 318], [319, 321], [322, 329], [329, 330], [331, 334], [335, 338], [339, 347], [348, 355], [356, 358], [359, 367], [367, 368]]}
{"doc_key": "ai-dev-158", "ner": [[2, 3, "product"], [7, 9, "field"], [11, 12, "task"], [14, 16, "task"], [18, 18, "task"], [21, 23, "task"], [25, 25, "task"], [28, 29, "field"], [31, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 3, 7, 9, "usage", "", false, false], [11, 12, 7, 9, "part-of", "", false, false], [14, 16, 7, 9, "part-of", "", false, false], [18, 18, 14, 16, "named", "", false, false], [21, 23, 7, 9, "part-of", "", false, false], [25, 25, 21, 23, "named", "", false, false], [28, 29, 7, 9, "part-of", "", false, false], [31, 32, 7, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["These", "intelligent", "chatbots", "use", "all", "kinds", "of", "artificial", "intelligence", "such", "as", "image", "moderation", "and", "natural", "language", "understanding", "(", "NLU", ")", ",", "natural", "language", "generation", "(", "NLG", ")", ",", "machine", "learning", "and", "deep", "learning", "."], "sentence-detokenized": "These intelligent chatbots use all kinds of artificial intelligence such as image moderation and natural language understanding (NLU), natural language generation (NLG), machine learning and deep learning.", "token2charspan": [[0, 5], [6, 17], [18, 26], [27, 30], [31, 34], [35, 40], [41, 43], [44, 54], [55, 67], [68, 72], [73, 75], [76, 81], [82, 92], [93, 96], [97, 104], [105, 113], [114, 127], [128, 129], [129, 132], [132, 133], [133, 134], [135, 142], [143, 151], [152, 162], [163, 164], [164, 167], [167, 168], [168, 169], [170, 177], [178, 186], [187, 190], [191, 195], [196, 204], [204, 205]]}
{"doc_key": "ai-dev-159", "ner": [[5, 7, "metrics"], [9, 9, "metrics"], [12, 12, "metrics"], [15, 22, "metrics"], [27, 29, "metrics"], [31, 31, "metrics"], [34, 41, "metrics"], [45, 47, "metrics"], [49, 49, "metrics"], [52, 59, "metrics"], [64, 66, "metrics"], [68, 68, "metrics"], [71, 77, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[9, 9, 5, 7, "named", "", false, false], [12, 12, 5, 7, "named", "", false, false], [15, 22, 5, 7, "named", "", false, false], [31, 31, 27, 29, "named", "", false, false], [34, 41, 27, 29, "named", "", false, false], [49, 49, 45, 47, "named", "", false, false], [52, 59, 45, 47, "named", "", false, false], [68, 68, 64, 66, "named", "", false, false], [71, 77, 64, 66, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "ordinal", "ratios", "are", "the", "positive", "predictive", "value", "(", "PPV", ",", "or", "precision", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "with", "the", "complement", "FALSE", "Discovery", "Rate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "and", "the", "negative", "predictive", "value", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "with", "the", "complement", "FALSE", "Omission", "Rate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "The ordinal ratios are the positive predictive value (PPV, or precision) (TP / (TP + FP)), with the complement FALSE Discovery Rate (FDR) (FP / (TP + FP)); and the negative predictive value (NPV) (TN / (TN + FN)), with the complement FALSE Omission Rate (FOR) (FN / (TN + FN)).", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 26], [27, 35], [36, 46], [47, 52], [53, 54], [54, 57], [57, 58], [59, 61], [62, 71], [71, 72], [73, 74], [74, 76], [77, 78], [79, 80], [80, 82], [83, 84], [85, 87], [87, 88], [88, 89], [89, 90], [91, 95], [96, 99], [100, 110], [111, 116], [117, 126], [127, 131], [132, 133], [133, 136], [136, 137], [138, 139], [139, 141], [142, 143], [144, 145], [145, 147], [148, 149], [150, 152], [152, 153], [153, 154], [154, 155], [156, 159], [160, 163], [164, 172], [173, 183], [184, 189], [190, 191], [191, 194], [194, 195], [196, 197], [197, 199], [200, 201], [202, 203], [203, 205], [206, 207], [208, 210], [210, 211], [211, 212], [212, 213], [214, 218], [219, 222], [223, 233], [234, 239], [240, 248], [249, 253], [254, 255], [255, 258], [258, 259], [260, 261], [261, 263], [264, 265], [266, 267], [267, 269], [270, 271], [272, 274], [274, 275], [275, 276], [276, 277]]}
{"doc_key": "ai-dev-160", "ner": [[8, 9, "misc"], [15, 16, "algorithm"], [18, 18, "algorithm"], [22, 24, "algorithm"], [26, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[18, 18, 15, 16, "named", "", false, false], [26, 26, 22, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "information", "is", "a", "mixture", "of", "sitemaps", "and", "RSS", "feeds", "and", "is", "created", "using", "an", "Information", "Model", "(", "IM", ")", "and", "a", "Biomedical", "Resource", "Ontology", "(", "BRO", ")", "."], "sentence-detokenized": "The information is a mixture of sitemaps and RSS feeds and is created using an Information Model (IM) and a Biomedical Resource Ontology (BRO).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 20], [21, 28], [29, 31], [32, 40], [41, 44], [45, 48], [49, 54], [55, 58], [59, 61], [62, 69], [70, 75], [76, 78], [79, 90], [91, 96], [97, 98], [98, 100], [100, 101], [102, 105], [106, 107], [108, 118], [119, 127], [128, 136], [137, 138], [138, 141], [141, 142], [142, 143]]}
{"doc_key": "ai-dev-161", "ner": [[2, 3, "task"], [8, 10, "algorithm"], [12, 16, "algorithm"], [23, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 12, 16, "origin", "based_on", false, false], [12, 16, 8, 10, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "latest", "text", "recognition", "is", "based", "on", "a", "recurrent", "neural", "network", "(", "long", "short", "-", "term", "memory", ")", "and", "does", "not", "require", "a", "language", "model", "."], "sentence-detokenized": "The latest text recognition is based on a recurrent neural network (long short-term memory) and does not require a language model.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 27], [28, 30], [31, 36], [37, 39], [40, 41], [42, 51], [52, 58], [59, 66], [67, 68], [68, 72], [73, 78], [78, 79], [79, 83], [84, 90], [90, 91], [92, 95], [96, 100], [101, 104], [105, 112], [113, 114], [115, 123], [124, 129], [129, 130]]}
{"doc_key": "ai-dev-162", "ner": [[1, 2, "misc"], [4, 6, "metrics"], [9, 10, "algorithm"], [13, 14, "metrics"], [17, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 1, 2, "type-of", "", false, false], [9, 10, 4, 6, "related-to", "", true, false], [13, 14, 1, 2, "type-of", "", false, false], [17, 18, 13, 14, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Popular", "loss", "functions", "include", "joi", "nt", "loss", "(", "for", "linear", "SVM", ")", "and", "logarithmic", "loss", "(", "for", "logistic", "regression", ")", "."], "sentence-detokenized": "Popular loss functions include joint loss (for linear SVM) and logarithmic loss (for logistic regression).", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 30], [31, 34], [34, 36], [37, 41], [42, 43], [43, 46], [47, 53], [54, 57], [57, 58], [59, 62], [63, 74], [75, 79], [80, 81], [81, 84], [85, 93], [94, 104], [104, 105], [105, 106]]}
{"doc_key": "ai-dev-163", "ner": [[0, 0, "metrics"], [10, 16, "metrics"], [18, 18, "metrics"], [21, 23, "metrics"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 10, 16, "compare", "", false, false], [0, 0, 21, 23, "compare", "", false, false], [18, 18, 10, 16, "named", "", false, false], [25, 25, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "is", "designed", "to", "improve", "on", "traditional", "methods", "such", "as", "peak", "signal", "-", "to", "-", "noise", "ratio", "(", "PSNR", ")", "and", "mean", "square", "error", "(", "MSE", ")", "."], "sentence-detokenized": "SSIM is designed to improve on traditional methods such as peak signal-to-noise ratio (PSNR) and mean square error (MSE).", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 27], [28, 30], [31, 42], [43, 50], [51, 55], [56, 58], [59, 63], [64, 70], [70, 71], [71, 73], [73, 74], [74, 79], [80, 85], [86, 87], [87, 91], [91, 92], [93, 96], [97, 101], [102, 108], [109, 114], [115, 116], [116, 119], [119, 120], [120, 121]]}
{"doc_key": "ai-dev-164", "ner": [[9, 10, "researcher"], [12, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "inspired", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "His work inspired generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 29], [30, 32], [33, 41], [42, 53], [54, 58], [59, 61], [62, 68], [69, 75], [75, 76], [77, 81], [82, 89], [90, 93], [94, 98], [99, 105], [105, 106]]}
{"doc_key": "ai-dev-165", "ner": [[10, 12, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 10, 12, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["Further", "pulse", "training", "is", "not", "differentiatable", ",", "which", "rules", "out", "back", "-", "propagation", "based", "training", "methods", "such", "as", "gradient", "descent", "."], "sentence-detokenized": "Further pulse training is not differentiatable, which rules out back-propagation based training methods such as gradient descent.", "token2charspan": [[0, 7], [8, 13], [14, 22], [23, 25], [26, 29], [30, 46], [46, 47], [48, 53], [54, 59], [60, 63], [64, 68], [68, 69], [69, 80], [81, 86], [87, 95], [96, 103], [104, 108], [109, 111], [112, 120], [121, 128], [128, 129]]}
{"doc_key": "ai-dev-166", "ner": [[8, 11, "metrics"], [16, 18, "metrics"], [19, 19, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 16, 18, "related-to", "describes", false, false], [16, 18, 19, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "relationships", "can", "be", "easily", "represented", "using", "the", "confusion", "matrix", ",", "a", "table", "that", "describes", "the", "accuracy", "of", "the", "classification", "model", "."], "sentence-detokenized": "These relationships can be easily represented using the confusion matrix, a table that describes the accuracy of the classification model.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 26], [27, 33], [34, 45], [46, 51], [52, 55], [56, 65], [66, 72], [72, 73], [74, 75], [76, 81], [82, 86], [87, 96], [97, 100], [101, 109], [110, 112], [113, 116], [117, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-dev-167", "ner": [[2, 10, "conference"], [8, 8, "conference"], [14, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 2, 10, "named", "", false, false], [14, 14, 2, 10, "physical", "", false, false], [14, 14, 2, 10, "role", "", false, false], [14, 14, 2, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["At", "the", "2018", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "conference", ",", "researchers", "from", "Google", "presented", "work"], "sentence-detokenized": "At the 2018 Neural Information Processing Systems (NeurIPS) conference, researchers from Google presented work", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 30], [31, 41], [42, 49], [50, 51], [51, 58], [58, 59], [60, 70], [70, 71], [72, 83], [84, 88], [89, 95], [96, 105], [106, 110]]}
{"doc_key": "ai-dev-168", "ner": [[4, 4, "university"], [10, 13, "product"], [21, 22, "misc"], [19, 19, "conference"], [27, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 13, 21, 22, "win-defeat", "", false, false], [21, 22, 19, 19, "temporal", "", false, false], [27, 30, 19, 19, "part-of", "", false, false], [27, 30, 19, 19, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "his", "time", "at", "Duke", ",", "he", "worked", "on", "the", "PROVERB", "automatic", "crossword", "solver", ",", "which", "won", "the", "1999", "AAAI", "Award", "for", "Excellence", "and", "participated", "in", "the", "American", "Crossword", "Puzzle", "Tournament", "."], "sentence-detokenized": "During his time at Duke, he worked on the PROVERB automatic crossword solver, which won the 1999 AAAI Award for Excellence and participated in the American Crossword Puzzle Tournament.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 18], [19, 23], [23, 24], [25, 27], [28, 34], [35, 37], [38, 41], [42, 49], [50, 59], [60, 69], [70, 76], [76, 77], [78, 83], [84, 87], [88, 91], [92, 96], [97, 101], [102, 107], [108, 111], [112, 122], [123, 126], [127, 139], [140, 142], [143, 146], [147, 155], [156, 165], [166, 172], [173, 183], [183, 184]]}
{"doc_key": "ai-dev-169", "ner": [[5, 6, "location"], [8, 8, "location"], [16, 16, "country"], [18, 18, "country"], [20, 20, "country"], [22, 22, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 8, 8, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "company", "was", "headquartered", "in", "Rochester", "Hills", ",", "Michigan", "and", "had", "10", "regional", "offices", "in", "the", "US", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "sentence-detokenized": "The company was headquartered in Rochester Hills, Michigan and had 10 regional offices in the US, Canada, Mexico and Brazil.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 29], [30, 32], [33, 42], [43, 48], [48, 49], [50, 58], [59, 62], [63, 66], [67, 69], [70, 78], [79, 86], [87, 89], [90, 93], [94, 96], [96, 97], [98, 104], [104, 105], [106, 112], [113, 116], [117, 123], [123, 124]]}
{"doc_key": "ai-dev-170", "ner": [[12, 12, "product"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "joins", "a", "collection", "of", "historically", "significant", "robots", "that", "includes", "the", "early", "Unimate", "and", "Odetics", "Odex", "1", "."], "sentence-detokenized": "It joins a collection of historically significant robots that includes the early Unimate and Odetics Odex 1.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 21], [22, 24], [25, 37], [38, 49], [50, 56], [57, 61], [62, 70], [71, 74], [75, 80], [81, 88], [89, 92], [93, 100], [101, 105], [106, 107], [107, 108]]}
{"doc_key": "ai-dev-171", "ner": [[7, 8, "researcher"], [10, 10, "organisation"], [12, 13, "researcher"], [23, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 10, 10, "physical", "", false, false], [7, 8, 10, 10, "role", "", false, false], [12, 13, 10, 10, "physical", "", false, false], [12, 13, 10, 10, "role", "", false, false], [12, 13, 23, 28, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["This", "issue", "'s", "guest", "editor", "will", "be", "David", "'s", "former", "NIST", "colleague", "Judah", "Levine", ",", "who", "is", "the", "most", "recent", "recipient", "of", "the", "I", ".", "I", ".", "Rabi", "Award", "."], "sentence-detokenized": "This issue's guest editor will be David's former NIST colleague Judah Levine, who is the most recent recipient of the I. I. Rabi Award.", "token2charspan": [[0, 4], [5, 10], [10, 12], [13, 18], [19, 25], [26, 30], [31, 33], [34, 39], [39, 41], [42, 48], [49, 53], [54, 63], [64, 69], [70, 76], [76, 77], [78, 81], [82, 84], [85, 88], [89, 93], [94, 100], [101, 110], [111, 113], [114, 117], [118, 119], [119, 120], [121, 122], [122, 123], [124, 128], [129, 134], [134, 135]]}
{"doc_key": "ai-dev-172", "ner": [[12, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "can", "be", "arranged", "in", "a", "2", "\u00d7", "2", "contingency", "table", "(", "confusion", "matrix", ")", ",", "usually", "with", "the", "test", "result", "on", "the", "vertical", "axis", "and", "the", "actual", "condition", "on", "the", "horizontal", "axis", "."], "sentence-detokenized": "These can be arranged in a 2 \u00d7 2 contingency table (confusion matrix), usually with the test result on the vertical axis and the actual condition on the horizontal axis.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 21], [22, 24], [25, 26], [27, 28], [29, 30], [31, 32], [33, 44], [45, 50], [51, 52], [52, 61], [62, 68], [68, 69], [69, 70], [71, 78], [79, 83], [84, 87], [88, 92], [93, 99], [100, 102], [103, 106], [107, 115], [116, 120], [121, 124], [125, 128], [129, 135], [136, 145], [146, 148], [149, 152], [153, 163], [164, 168], [168, 169]]}
{"doc_key": "ai-dev-173", "ner": [[0, 4, "product"], [7, 7, "product"], [9, 9, "product"], [11, 12, "product"], [15, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 7, 7, "part-of", "", false, false], [0, 4, 9, 9, "part-of", "", false, false], [0, 4, 11, 12, "part-of", "", false, false], [0, 4, 15, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Apple", "'s", "iOS", "operating", "system", "used", "in", "iPhone", ",", "iPad", "and", "iPod", "Touch", "devices", "uses", "VoiceOver", "speech", "synthesis", "accessibility", "."], "sentence-detokenized": "Apple's iOS operating system used in iPhone, iPad and iPod Touch devices uses VoiceOver speech synthesis accessibility.", "token2charspan": [[0, 5], [5, 7], [8, 11], [12, 21], [22, 28], [29, 33], [34, 36], [37, 43], [43, 44], [45, 49], [50, 53], [54, 58], [59, 64], [65, 72], [73, 77], [78, 87], [88, 94], [95, 104], [105, 118], [118, 119]]}
{"doc_key": "ai-dev-174", "ner": [[7, 9, "conference"], [13, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "the", "best", "system", "entering", "MUC", "-", "7", "achieved", "93.39", "%", "F", "-", "measure", ",", "while", "the", "human", "annotators", "achieved", "97.6", "%", "and", "96.95", "%", "."], "sentence-detokenized": "For example, the best system entering MUC-7 achieved 93.39% F-measure, while the human annotators achieved 97.6% and 96.95%.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 37], [38, 41], [41, 42], [42, 43], [44, 52], [53, 58], [58, 59], [60, 61], [61, 62], [62, 69], [69, 70], [71, 76], [77, 80], [81, 86], [87, 97], [98, 106], [107, 111], [111, 112], [113, 116], [117, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-dev-175", "ner": [[11, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 11, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "do", "this", ",", "standard", "neural", "network", "training", "algorithms", "such", "as", "stochastic", "gradient", "descent", "with", "backpropagation", "are", "used", "."], "sentence-detokenized": "To do this, standard neural network training algorithms such as stochastic gradient descent with backpropagation are used.", "token2charspan": [[0, 2], [3, 5], [6, 10], [10, 11], [12, 20], [21, 27], [28, 35], [36, 44], [45, 55], [56, 60], [61, 63], [64, 74], [75, 83], [84, 91], [92, 96], [97, 112], [113, 116], [117, 121], [121, 122]]}
{"doc_key": "ai-dev-176", "ner": [[0, 5, "organisation"], [23, 23, "country"], [2, 2, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 5, 23, 23, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "ranks", "Rotten", "Tomatoes", "as", "one", "of", "the", "top", "1000", "most", "visited", "websites", ",", "ranking", "around", "400th", "globally", "and", "150th", "in", "the", "US", "alone", "."], "sentence-detokenized": "Rotten Tomatoes ranks Rotten Tomatoes as one of the top 1000 most visited websites, ranking around 400th globally and 150th in the US alone.", "token2charspan": [[0, 6], [7, 15], [16, 21], [22, 28], [29, 37], [38, 40], [41, 44], [45, 47], [48, 51], [52, 55], [56, 60], [61, 65], [66, 73], [74, 82], [82, 83], [84, 91], [92, 98], [99, 104], [105, 113], [114, 117], [118, 123], [124, 126], [127, 130], [131, 133], [134, 139], [139, 140]]}
{"doc_key": "ai-dev-177", "ner": [[14, 16, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "general", ",", "all", "learning", "exhibits", "gradual", "changes", "over", "time", ",", "but", "describes", "a", "sigmoid", "function", "that", "takes", "different", "forms", "depending", "on", "the", "time", "scale", "of", "the", "observation", "."], "sentence-detokenized": "In general, all learning exhibits gradual changes over time, but describes a sigmoid function that takes different forms depending on the time scale of the observation.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 24], [25, 33], [34, 41], [42, 49], [50, 54], [55, 59], [59, 60], [61, 64], [65, 74], [75, 76], [77, 84], [85, 93], [94, 98], [99, 104], [105, 114], [115, 120], [121, 130], [131, 133], [134, 137], [138, 142], [143, 148], [149, 151], [152, 155], [156, 167], [167, 168]]}
{"doc_key": "ai-dev-178", "ner": [[0, 1, "metrics"], [8, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 8, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SSD", "is", "also", "referred", "to", "as", "the", "root", "mean", "square", "error", "."], "sentence-detokenized": "The SSD is also referred to as the root mean square error.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 24], [25, 27], [28, 30], [31, 34], [35, 39], [40, 44], [45, 51], [52, 57], [57, 58]]}
{"doc_key": "ai-dev-179", "ner": [[0, 3, "algorithm"], [5, 6, "algorithm"], [8, 13, "algorithm"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 23, 24, "related-to", "can_be_related_to", true, false], [5, 6, 23, 24, "related-to", "can_be_related_to", true, false], [8, 13, 23, 24, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Learning", "with", "decision", "trees", ",", "neural", "networks", "or", "naive", "Bayes", "classifier", "could", "be", "used", "in", "combination", "with", "measures", "of", "model", "quality", "such", "as", "balanced", "accuracy", "."], "sentence-detokenized": "Learning with decision trees, neural networks or naive Bayes classifier could be used in combination with measures of model quality such as balanced accuracy.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 28], [28, 29], [30, 36], [37, 45], [46, 48], [49, 54], [55, 60], [61, 71], [72, 77], [78, 80], [81, 85], [86, 88], [89, 100], [101, 105], [106, 114], [115, 117], [118, 123], [124, 131], [132, 136], [137, 139], [140, 148], [149, 157], [157, 158]]}
{"doc_key": "ai-dev-180", "ner": [[15, 18, "conference"], [23, 30, "conference"], [27, 29, "misc"], [34, 36, "product"], [42, 46, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[27, 29, 23, 30, "origin", "", false, false], [27, 29, 23, 30, "temporal", "", false, false], [34, 36, 27, 29, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "is", "a", "past", "president", "(", "1979", ")", "and", "first", "fellow", "(", "2011", ")", "of", "the", "ACL", ",", "a", "co-recipient", "of", "the", "1992", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "for", "contributions", "to", "the", "Interlisp", "programming", "system", ",", "and", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "He is a past president (1979) and first fellow (2011) of the ACL, a co-recipient of the 1992 Association for Computing Machinery Software Systems Award for contributions to the Interlisp programming system, and a Fellow of the Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 22], [23, 24], [24, 28], [28, 29], [30, 33], [34, 39], [40, 46], [47, 48], [48, 52], [52, 53], [54, 56], [57, 60], [61, 64], [64, 65], [66, 67], [68, 80], [81, 83], [84, 87], [88, 92], [93, 104], [105, 108], [109, 118], [119, 128], [129, 137], [138, 145], [146, 151], [152, 155], [156, 169], [170, 172], [173, 176], [177, 186], [187, 198], [199, 205], [205, 206], [207, 210], [211, 212], [213, 219], [220, 222], [223, 226], [227, 238], [239, 242], [243, 252], [253, 262], [262, 263]]}
{"doc_key": "ai-dev-181", "ner": [[2, 3, "researcher"], [5, 9, "researcher"], [8, 8, "researcher"], [12, 15, "researcher"], [27, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 27, 30, "related-to", "", false, false], [5, 9, 27, 30, "related-to", "", false, false], [8, 8, 27, 30, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "is", "considered", "by", "Cade", "Metz", "to", "be", "one", "of", "the", "three", "people", "most", "instrumental", "in", "the", "development", "of", "deep", "learning", "in", "the", "1990s", "and", "2000s", "."], "sentence-detokenized": "Along with Geoffrey Hinton and Yann LeCun, Bengio is considered by Cade Metz to be one of the three people most instrumental in the development of deep learning in the 1990s and 2000s.", "token2charspan": [[0, 5], [6, 10], [11, 19], [20, 26], [27, 30], [31, 35], [36, 41], [41, 42], [43, 49], [50, 52], [53, 63], [64, 66], [67, 71], [72, 76], [77, 79], [80, 82], [83, 86], [87, 89], [90, 93], [94, 99], [100, 106], [107, 111], [112, 124], [125, 127], [128, 131], [132, 143], [144, 146], [147, 151], [152, 160], [161, 163], [164, 167], [168, 173], [174, 177], [178, 183], [183, 184]]}
{"doc_key": "ai-dev-182", "ner": [[1, 2, "field"], [4, 12, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "information", "theory", "and", "computer", "science", ",", "a", "code", "is", "usually", "considered", "to", "be", "an", "algorithm", "that", "uniquely", "represents", "symbols", "from", "some", "source", "alphabet", "using", "encoded", "strings", "that", "may", "be", "in", "some", "other", "target", "alphabet", "."], "sentence-detokenized": "In information theory and computer science, a code is usually considered to be an algorithm that uniquely represents symbols from some source alphabet using encoded strings that may be in some other target alphabet.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 45], [46, 50], [51, 53], [54, 61], [62, 72], [73, 75], [76, 78], [79, 81], [82, 91], [92, 96], [97, 105], [106, 116], [117, 124], [125, 129], [130, 134], [135, 141], [142, 150], [151, 156], [157, 164], [165, 172], [173, 177], [178, 181], [182, 184], [185, 187], [188, 192], [193, 198], [199, 205], [206, 214], [214, 215]]}
{"doc_key": "ai-dev-183", "ner": [[7, 8, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 7, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "relatively", "simple", "nonlinear", "function", ",", "a", "sigmoid", "function", "such", "as", "the", "logistic", "function", ",", "also", "has", "an", "easily", "computable", "derivative", ",", "which", "can", "be", "important", "when", "computing", "updates", "to", "weights", "in", "a", "network", "."], "sentence-detokenized": "A relatively simple nonlinear function, a sigmoid function such as the logistic function, also has an easily computable derivative, which can be important when computing updates to weights in a network.", "token2charspan": [[0, 1], [2, 12], [13, 19], [20, 29], [30, 38], [38, 39], [40, 41], [42, 49], [50, 58], [59, 63], [64, 66], [67, 70], [71, 79], [80, 88], [88, 89], [90, 94], [95, 98], [99, 101], [102, 108], [109, 119], [120, 130], [130, 131], [132, 137], [138, 141], [142, 144], [145, 154], [155, 159], [160, 169], [170, 177], [178, 180], [181, 188], [189, 191], [192, 193], [194, 201], [201, 202]]}
{"doc_key": "ai-dev-184", "ner": [[0, 0, "person"], [6, 6, "location"], [8, 8, "location"], [10, 12, "country"], [15, 15, "country"], [19, 20, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 6, "physical", "", false, false], [6, 6, 8, 8, "physical", "", false, false], [8, 8, 10, 12, "physical", "", false, false], [8, 8, 15, 15, "physical", "", false, false], [8, 8, 19, 20, "physical", "", false, false], [15, 15, 10, 12, "origin", "", false, false], [19, 20, 15, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "was", "born", "in", "1887", "in", "Hronov", "in", "Bohemia", "(", "Austria", "-", "Hungary", ",", "later", "Czechoslovakia", ",", "now", "the", "Czech", "Republic", ")", "."], "sentence-detokenized": "\u010capek was born in 1887 in Hronov in Bohemia (Austria-Hungary, later Czechoslovakia, now the Czech Republic).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 22], [23, 25], [26, 32], [33, 35], [36, 43], [44, 45], [45, 52], [52, 53], [53, 60], [60, 61], [62, 67], [68, 82], [82, 83], [84, 87], [88, 91], [92, 97], [98, 106], [106, 107], [107, 108]]}
{"doc_key": "ai-dev-185", "ner": [[5, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "specialized", "software", "can", "tell", "RSS", "feeds", "."], "sentence-detokenized": "Some specialized software can tell RSS feeds.", "token2charspan": [[0, 4], [5, 16], [17, 25], [26, 29], [30, 34], [35, 38], [39, 44], [44, 45]]}
{"doc_key": "ai-dev-186", "ner": [[6, 9, "task"], [11, 12, "task"], [14, 14, "task"], [16, 16, "task"], [18, 19, "task"], [26, 29, "task"], [30, 31, "task"], [36, 38, "task"], [40, 42, "product"], [44, 45, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[6, 9, 11, 12, "related-to", "", true, false], [6, 9, 14, 14, "related-to", "", true, false], [6, 9, 16, 16, "related-to", "", true, false], [30, 31, 26, 29, "usage", "", true, false], [40, 42, 36, 38, "type-of", "", false, false], [44, 45, 36, 38, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Aspects", "of", "ontology", "editors", "include", ":", "visual", "navigation", "capabilities", "within", "the", "knowledge", "model", ",", "inference", "and", "extraction", ",", "module", "support", ",", "import", "and", "export", "of", "foreign", "knowledge", "representation", "languages", "for", "ontology", "matching", ",", "and", "support", "for", "meta", "-ontologies", "such", "as", "OWL", "-", "S", ",", "Dublin", "Core", ",", "etc", "."], "sentence-detokenized": "Aspects of ontology editors include: visual navigation capabilities within the knowledge model, inference and extraction, module support, import and export of foreign knowledge representation languages for ontology matching, and support for meta-ontologies such as OWL-S, Dublin Core, etc.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 27], [28, 35], [35, 36], [37, 43], [44, 54], [55, 67], [68, 74], [75, 78], [79, 88], [89, 94], [94, 95], [96, 105], [106, 109], [110, 120], [120, 121], [122, 128], [129, 136], [136, 137], [138, 144], [145, 148], [149, 155], [156, 158], [159, 166], [167, 176], [177, 191], [192, 201], [202, 205], [206, 214], [215, 223], [223, 224], [225, 228], [229, 236], [237, 240], [241, 245], [245, 256], [257, 261], [262, 264], [265, 268], [268, 269], [269, 270], [270, 271], [272, 278], [279, 283], [283, 284], [285, 288], [288, 289]]}
{"doc_key": "ai-dev-187", "ner": [[0, 1, "organisation"], [6, 11, "misc"], [13, 15, "task"], [18, 20, "field"], [22, 22, "misc"], [24, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 11, 0, 1, "origin", "", false, false], [13, 15, 6, 11, "part-of", "", false, false], [18, 20, 6, 11, "part-of", "", false, false], [22, 22, 18, 20, "type-of", "", false, false], [24, 27, 18, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "FBI", "has", "also", "implemented", "a", "next", "-", "generation", "identification", "program", "that", "includes", "facial", "recognition", "and", "more", "traditional", "biometrics", ",", "such", "as", "fingerprints", "and", "iris", "scans", ",", "which", "can", "be", "drawn", "from", "criminal", "and", "civil", "databases", "."], "sentence-detokenized": "The FBI has also implemented a next-generation identification program that includes facial recognition and more traditional biometrics, such as fingerprints and iris scans, which can be drawn from criminal and civil databases.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 28], [29, 30], [31, 35], [35, 36], [36, 46], [47, 61], [62, 69], [70, 74], [75, 83], [84, 90], [91, 102], [103, 106], [107, 111], [112, 123], [124, 134], [134, 135], [136, 140], [141, 143], [144, 156], [157, 160], [161, 165], [166, 171], [171, 172], [173, 178], [179, 182], [183, 185], [186, 191], [192, 196], [197, 205], [206, 209], [210, 215], [216, 225], [225, 226]]}
{"doc_key": "ai-dev-188", "ner": [[7, 10, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "2016", "season", "saw", "the", "arrival", "of", "Samantha", "Ponder", "as", "host", ",", "replacing", "Molly", "McGrath", "."], "sentence-detokenized": "The 2016 season saw the arrival of Samantha Ponder as host, replacing Molly McGrath.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 19], [20, 23], [24, 31], [32, 34], [35, 43], [44, 50], [51, 53], [54, 58], [58, 59], [60, 69], [70, 75], [76, 83], [83, 84]]}
{"doc_key": "ai-dev-189", "ner": [[3, 9, "algorithm"], [17, 21, "misc"], [23, 23, "misc"], [25, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "adversarial", "search", "algorithm", "that", "is", "commonly", "used", "for", "two", "-", "player", "machine", "games", "(", "tic", "-", "tac", "-", "toe", ",", "Chess", ",", "Go", ",", "etc.", ")", "."], "sentence-detokenized": "This is an adversarial search algorithm that is commonly used for two-player machine games (tic-tac-toe, Chess, Go, etc.).", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 29], [30, 39], [40, 44], [45, 47], [48, 56], [57, 61], [62, 65], [66, 69], [69, 70], [70, 76], [77, 84], [85, 90], [91, 92], [92, 95], [95, 96], [96, 99], [99, 100], [100, 103], [103, 104], [105, 110], [110, 111], [112, 114], [114, 115], [116, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-dev-190", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 17, "field"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "covers", "the", "fields", "of", "computer", "vision", "or", "machine", "vision", "and", "medical", "imaging", "and", "makes", "extensive", "use", "of", "pattern", "recognition", ",", "digital", "geometry", "and", "signal", "processing", "."], "sentence-detokenized": "It covers the fields of computer vision or machine vision and medical imaging and makes extensive use of pattern recognition, digital geometry and signal processing.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 20], [21, 23], [24, 32], [33, 39], [40, 42], [43, 50], [51, 57], [58, 61], [62, 69], [70, 77], [78, 81], [82, 87], [88, 97], [98, 101], [102, 104], [105, 112], [113, 124], [124, 125], [126, 133], [134, 142], [143, 146], [147, 153], [154, 164], [164, 165]]}
{"doc_key": "ai-dev-191", "ner": [[5, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "in", "a", "facial", "recognition", "system", ",", "the", "input", "would", "be", "a", "picture", "of", "a", "person", "'s", "face", "and", "the", "output", "would", "be", "their", "name", "."], "sentence-detokenized": "For example, in a facial recognition system, the input would be a picture of a person's face and the output would be their name.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 17], [18, 24], [25, 36], [37, 43], [43, 44], [45, 48], [49, 54], [55, 60], [61, 63], [64, 65], [66, 73], [74, 76], [77, 78], [79, 85], [85, 87], [88, 92], [93, 96], [97, 100], [101, 107], [108, 113], [114, 116], [117, 122], [123, 127], [127, 128]]}
{"doc_key": "ai-dev-192", "ner": [[0, 1, "organisation"], [4, 5, "product"], [9, 11, "product"], [16, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 5, "artifact", "", false, false], [4, 5, 9, 11, "part-of", "", false, false], [9, 11, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc.", "has", "introduced", "Face", "ID", "in", "its", "flagship", "i", "Phone", "X", "as", "a", "successor", "to", "Touch", "ID", "biometric", "authentication", ",", "a", "fingerprint", "-", "based", "system", "."], "sentence-detokenized": "Apple Inc. has introduced Face ID in its flagship iPhone X as a successor to Touch ID biometric authentication, a fingerprint-based system.", "token2charspan": [[0, 5], [6, 10], [11, 14], [15, 25], [26, 30], [31, 33], [34, 36], [37, 40], [41, 49], [50, 51], [51, 56], [57, 58], [59, 61], [62, 63], [64, 73], [74, 76], [77, 82], [83, 85], [86, 95], [96, 110], [110, 111], [112, 113], [114, 125], [125, 126], [126, 131], [132, 138], [138, 139]]}
{"doc_key": "ai-dev-193", "ner": [[3, 5, "metrics"], [8, 9, "metrics"], [22, 25, "metrics"], [28, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Or", "combine", "the", "F", "-", "measure", "with", "the", "R-", "squared", "evaluated", "for", "the", "raw", "model", "output", "and", "the", "target", ";", "or", "the", "cost", "/", "benefit", "matrix", "with", "the", "correlation", "coefficient", ",", "and", "so", "on", "."], "sentence-detokenized": "Or combine the F-measure with the R-squared evaluated for the raw model output and the target; or the cost/benefit matrix with the correlation coefficient, and so on.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 16], [16, 17], [17, 24], [25, 29], [30, 33], [34, 36], [36, 43], [44, 53], [54, 57], [58, 61], [62, 65], [66, 71], [72, 78], [79, 82], [83, 86], [87, 93], [93, 94], [95, 97], [98, 101], [102, 106], [106, 107], [107, 114], [115, 121], [122, 126], [127, 130], [131, 142], [143, 154], [154, 155], [156, 159], [160, 162], [163, 165], [165, 166]]}
{"doc_key": "ai-dev-194", "ner": [[0, 10, "conference"], [17, 19, "location"], [21, 21, "location"], [24, 27, "location"], [29, 29, "location"], [31, 31, "country"], [36, 37, "location"], [40, 44, "location"], [46, 46, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 10, 17, 19, "physical", "", false, false], [0, 10, 24, 27, "physical", "", false, false], [0, 10, 36, 37, "physical", "", false, false], [0, 10, 40, 44, "physical", "", false, false], [17, 19, 21, 21, "physical", "", false, false], [24, 27, 29, 29, "physical", "", false, false], [29, 29, 31, 31, "physical", "", false, false], [36, 37, 46, 46, "physical", "", false, false], [40, 44, 46, 46, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "Spanish", "edition", "of", "the", "Campus", "Party", "has", "been", "held", "for", "the", "past", "15", "years", "at", "the", "Colegio", "Miguel", "Hern\u00e1ndez", ",", "Ceulaj", "and", "the", "Benalm\u00e1dena", "Municipal", "Sports", "Arena", "in", "M\u00e1laga", ",", "Spain", ",", "and", "at", "the", "Valencia", "Fair", "and", "the", "City", "of", "Arts", "and", "Science", "in", "Valencia", "."], "sentence-detokenized": "The Spanish edition of the Campus Party has been held for the past 15 years at the Colegio Miguel Hern\u00e1ndez, Ceulaj and the Benalm\u00e1dena Municipal Sports Arena in M\u00e1laga, Spain, and at the Valencia Fair and the City of Arts and Science in Valencia.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 22], [23, 26], [27, 33], [34, 39], [40, 43], [44, 48], [49, 53], [54, 57], [58, 61], [62, 66], [67, 69], [70, 75], [76, 78], [79, 82], [83, 90], [91, 97], [98, 107], [107, 108], [109, 115], [116, 119], [120, 123], [124, 135], [136, 145], [146, 152], [153, 158], [159, 161], [162, 168], [168, 169], [170, 175], [175, 176], [177, 180], [181, 183], [184, 187], [188, 196], [197, 201], [202, 205], [206, 209], [210, 214], [215, 217], [218, 222], [223, 226], [227, 234], [235, 237], [238, 246], [246, 247]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [15, 15, "programlang"], [19, 19, "product"], [21, 22, "product"], [25, 25, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 15, 0, 0, "general-affiliation", "", false, false], [19, 19, 15, 15, "part-of", "", false, false], [21, 22, 15, 15, "part-of", "", false, false], [25, 25, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Gnuplot", "can", "be", "used", "to", "create", "graphs", "from", "a", "variety", "of", "programming", "languages", ",", "including", "Perl", "(", "via", "the", "PDL", "and", "CPAN", "packages", ")", ",", "Python", "(", "via", ")", "."], "sentence-detokenized": "Gnuplot can be used to create graphs from a variety of programming languages, including Perl (via the PDL and CPAN packages), Python (via).", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 19], [20, 22], [23, 29], [30, 36], [37, 41], [42, 43], [44, 51], [52, 54], [55, 66], [67, 76], [76, 77], [78, 87], [88, 92], [93, 94], [94, 97], [98, 101], [102, 105], [106, 109], [110, 114], [115, 123], [123, 124], [124, 125], [126, 132], [133, 134], [134, 137], [137, 138], [138, 139]]}
{"doc_key": "ai-dev-196", "ner": [[3, 5, "product"], [19, 19, "conference"], [21, 21, "conference"], [35, 35, "conference"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 3, 5, "topic", "", false, false], [21, 21, 3, 5, "topic", "", false, false], [35, 35, 3, 5, "topic", "", false, false], [37, 37, 3, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "field", "of", "spoken", "dialogue", "systems", "is", "quite", "large", "and", "includes", "research", "(", "presented", "at", "scientific", "conferences", "such", "as", "SIGdial", "and", "Interspeech", ")", "and", "a", "large", "industrial", "sector", "(", "with", "its", "own", "meetings", "such", "as", "SpeechTek", "and", "AVIOS", ")", "."], "sentence-detokenized": "The field of spoken dialogue systems is quite large and includes research (presented at scientific conferences such as SIGdial and Interspeech) and a large industrial sector (with its own meetings such as SpeechTek and AVIOS).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 28], [29, 36], [37, 39], [40, 45], [46, 51], [52, 55], [56, 64], [65, 73], [74, 75], [75, 84], [85, 87], [88, 98], [99, 110], [111, 115], [116, 118], [119, 126], [127, 130], [131, 142], [142, 143], [144, 147], [148, 149], [150, 155], [156, 166], [167, 173], [174, 175], [175, 179], [180, 183], [184, 187], [188, 196], [197, 201], [202, 204], [205, 214], [215, 218], [219, 224], [224, 225], [225, 226]]}
{"doc_key": "ai-dev-197", "ner": [[2, 4, "field"], [7, 8, "task"], [10, 12, "task"], [14, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 2, 4, "part-of", "task_part_of_field", false, false], [10, 12, 2, 4, "part-of", "task_part_of_field", false, false], [14, 16, 2, 4, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Challenges", "in", "natural", "language", "processing", "often", "include", "speech", "recognition", ",", "natural", "language", "understanding", "and", "natural", "language", "generation", "."], "sentence-detokenized": "Challenges in natural language processing often include speech recognition, natural language understanding and natural language generation.", "token2charspan": [[0, 10], [11, 13], [14, 21], [22, 30], [31, 41], [42, 47], [48, 55], [56, 62], [63, 74], [74, 75], [76, 83], [84, 92], [93, 106], [107, 110], [111, 118], [119, 127], [128, 138], [138, 139]]}
{"doc_key": "ai-dev-198", "ner": [[10, 10, "product"], [6, 9, "product"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 6, 9, "part-of", "", false, false], [10, 10, 36, 37, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "such", "as", "the", "iOS", "operating", "system", "'s", "Siri", ",", "work", "with", "a", "similar", "pattern", "recognition", "technique", "as", "text", "-", "based", "systems", ",", "but", "in", "the", "former", "case", ",", "user", "input", "is", "made", "through", "speech", "recognition", "."], "sentence-detokenized": "These systems, such as the iOS operating system's Siri, work with a similar pattern recognition technique as text-based systems, but in the former case, user input is made through speech recognition.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 26], [27, 30], [31, 40], [41, 47], [47, 49], [50, 54], [54, 55], [56, 60], [61, 65], [66, 67], [68, 75], [76, 83], [84, 95], [96, 105], [106, 108], [109, 113], [113, 114], [114, 119], [120, 127], [127, 128], [129, 132], [133, 135], [136, 139], [140, 146], [147, 151], [151, 152], [153, 157], [158, 163], [164, 166], [167, 171], [172, 179], [180, 186], [187, 198], [198, 199]]}
{"doc_key": "ai-dev-199", "ner": [[0, 8, "algorithm"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 8, 20, 21, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["More", "exotic", "goodness", "-", "of", "-", "fit", "functions", "that", "examine", "the", "granularity", "of", "the", "model", "include", "the", "area", "under", "the", "ROC", "curve", "and", "the", "order", "measure", "."], "sentence-detokenized": "More exotic goodness-of-fit functions that examine the granularity of the model include the area under the ROC curve and the order measure.", "token2charspan": [[0, 4], [5, 11], [12, 20], [20, 21], [21, 23], [23, 24], [24, 27], [28, 37], [38, 42], [43, 50], [51, 54], [55, 66], [67, 69], [70, 73], [74, 79], [80, 87], [88, 91], [92, 96], [97, 102], [103, 106], [107, 110], [111, 116], [117, 120], [121, 124], [125, 130], [131, 138], [138, 139]]}
{"doc_key": "ai-dev-200", "ner": [[2, 3, "product"], [7, 10, "researcher"], [14, 18, "product"], [22, 25, "organisation"], [27, 30, "organisation"], [36, 38, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 7, 10, "origin", "", false, false], [7, 10, 22, 25, "role", "", false, false], [14, 18, 7, 10, "origin", "", false, false], [27, 30, 22, 25, "named", "", false, false], [36, 38, 22, 25, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "term", "Semantic", "Web", "was", "coined", "by", "Tim", "Berners", "-", "Lee", ",", "inventor", "of", "the", "World", "Wide", "Web", "and", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "oversees", "the", "development", "of", "proposed", "Semantic", "Web", "standards", "."], "sentence-detokenized": "The term Semantic Web was coined by Tim Berners-Lee, inventor of the World Wide Web and director of the World Wide Web Consortium (W3C), which oversees the development of proposed Semantic Web standards.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 25], [26, 32], [33, 35], [36, 39], [40, 47], [47, 48], [48, 51], [51, 52], [53, 61], [62, 64], [65, 68], [69, 74], [75, 79], [80, 83], [84, 87], [88, 96], [97, 99], [100, 103], [104, 109], [110, 114], [115, 118], [119, 129], [130, 131], [131, 134], [134, 135], [135, 136], [137, 142], [143, 151], [152, 155], [156, 167], [168, 170], [171, 179], [180, 188], [189, 192], [193, 202], [202, 203]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [5, 5, "task"], [12, 15, "product"], [17, 21, "product"], [23, 23, "product"], [26, 27, "product"], [34, 36, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 12, 15, "opposite", "", false, false], [0, 1, 17, 21, "opposite", "", false, false], [0, 1, 26, 27, "opposite", "", false, false], [0, 1, 34, 36, "part-of", "", false, false], [5, 5, 0, 1, "named", "", false, false], [23, 23, 17, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Machine", "translation", ",", "sometimes", "abbreviated", "MT", "(", "not", "to", "be", "confused", "with", "computer", "-", "aided", "translation", ",", "machine", "-", "aided", "human", "translation", "(", "MAHT", ")", "or", "interactive", "translation", ")", ",", "is", "a", "subfield", "of", "computational", "linguistics", "that", "studies", "the", "use", "of", "software", "to", "translate", "text", "or", "speech", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Machine translation, sometimes abbreviated MT (not to be confused with computer-aided translation, machine-aided human translation (MAHT) or interactive translation), is a subfield of computational linguistics that studies the use of software to translate text or speech from one language to another.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 30], [31, 42], [43, 45], [46, 47], [47, 50], [51, 53], [54, 56], [57, 65], [66, 70], [71, 79], [79, 80], [80, 85], [86, 97], [97, 98], [99, 106], [106, 107], [107, 112], [113, 118], [119, 130], [131, 132], [132, 136], [136, 137], [138, 140], [141, 152], [153, 164], [164, 165], [165, 166], [167, 169], [170, 171], [172, 180], [181, 183], [184, 197], [198, 209], [210, 214], [215, 222], [223, 226], [227, 230], [231, 233], [234, 242], [243, 245], [246, 255], [256, 260], [261, 263], [264, 270], [271, 275], [276, 279], [280, 288], [289, 291], [292, 299], [299, 300]]}
{"doc_key": "ai-dev-202", "ner": [[1, 3, "product"], [14, 14, "university"], [8, 9, "researcher"], [11, 12, "researcher"], [40, 41, "location"], [43, 43, "location"], [47, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 3, 8, 9, "artifact", "", false, false], [1, 3, 11, 12, "artifact", "", false, false], [8, 9, 14, 14, "physical", "", false, false], [8, 9, 14, 14, "role", "", false, false], [11, 12, 14, 14, "physical", "", false, false], [11, 12, 14, 14, "role", "", false, false], [40, 41, 43, 43, "physical", "", false, false], [47, 50, 40, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Early", "MT", "interlanguage", "systems", "were", "also", "developed", "by", "Roger", "Schank", "and", "Yorick", "Wilks", "at", "Stanford", "in", "the", "1970s", ";", "the", "former", "became", "the", "basis", "of", "a", "commercial", "remittance", "system", ",", "and", "the", "code", "of", "the", "latter", "is", "preserved", "at", "the", "Computer", "Museum", "in", "Boston", "as", "the", "first", "interlanguage", "machine", "translation", "system", "."], "sentence-detokenized": "Early MT interlanguage systems were also developed by Roger Schank and Yorick Wilks at Stanford in the 1970s; the former became the basis of a commercial remittance system, and the code of the latter is preserved at the Computer Museum in Boston as the first interlanguage machine translation system.", "token2charspan": [[0, 5], [6, 8], [9, 22], [23, 30], [31, 35], [36, 40], [41, 50], [51, 53], [54, 59], [60, 66], [67, 70], [71, 77], [78, 83], [84, 86], [87, 95], [96, 98], [99, 102], [103, 108], [108, 109], [110, 113], [114, 120], [121, 127], [128, 131], [132, 137], [138, 140], [141, 142], [143, 153], [154, 164], [165, 171], [171, 172], [173, 176], [177, 180], [181, 185], [186, 188], [189, 192], [193, 199], [200, 202], [203, 212], [213, 215], [216, 219], [220, 228], [229, 235], [236, 238], [239, 245], [246, 248], [249, 252], [253, 258], [259, 272], [273, 280], [281, 292], [293, 299], [299, 300]]}
{"doc_key": "ai-dev-203", "ner": [[0, 0, "researcher"], [7, 11, "conference"], [13, 14, "conference"], [21, 26, "conference"], [28, 29, "conference"], [35, 40, "organisation"], [49, 49, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 7, 11, "role", "", false, false], [0, 0, 21, 26, "role", "", false, false], [0, 0, 35, 40, "role", "", false, false], [0, 0, 49, 49, "role", "", false, false], [13, 14, 7, 11, "named", "", false, false], [28, 29, 21, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sycara", "served", "as", "Program", "Chair", "of", "the", "Second", "International", "Semantic", "Web", "Conference", "(", "ISWC", "2003", ")", ",", "General", "Chair", "of", "the", "Second", "International", "Conference", "on", "Autonomous", "Agents", "(", "Agents", "98", ")", ",", "Chair", "of", "the", "Steering", "Committee", "of", "the", "Agents", "Conference", "(", "1999-2001", ")", ",", "and", "Chair", "of", "the", "AAAI", "Scholarship", "Committee", "(", "1993-1999", ")", ";"], "sentence-detokenized": "Sycara served as Program Chair of the Second International Semantic Web Conference (ISWC 2003), General Chair of the Second International Conference on Autonomous Agents (Agents 98), Chair of the Steering Committee of the Agents Conference (1999-2001), and Chair of the AAAI Scholarship Committee (1993-1999);", "token2charspan": [[0, 6], [7, 13], [14, 16], [17, 24], [25, 30], [31, 33], [34, 37], [38, 44], [45, 58], [59, 67], [68, 71], [72, 82], [83, 84], [84, 88], [89, 93], [93, 94], [94, 95], [96, 103], [104, 109], [110, 112], [113, 116], [117, 123], [124, 137], [138, 148], [149, 151], [152, 162], [163, 169], [170, 171], [171, 177], [178, 180], [180, 181], [181, 182], [183, 188], [189, 191], [192, 195], [196, 204], [205, 214], [215, 217], [218, 221], [222, 228], [229, 239], [240, 241], [241, 250], [250, 251], [251, 252], [253, 256], [257, 262], [263, 265], [266, 269], [270, 274], [275, 286], [287, 296], [297, 298], [298, 307], [307, 308], [308, 309]]}
{"doc_key": "ai-dev-204", "ner": [[11, 11, "conference"], [13, 16, "conference"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 11, 11, "named", "", false, false], [18, 20, 11, 11, "part-of", "", false, false], [18, 20, 11, 11, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2016", ",", "she", "was", "selected", "as", "the", "recipient", "of", "the", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "Lifetime", "Achievement", "Award", "."], "sentence-detokenized": "In 2016, she was selected as the recipient of the ACL (Association for Computational Linguistics) Lifetime Achievement Award.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 25], [26, 28], [29, 32], [33, 42], [43, 45], [46, 49], [50, 53], [54, 55], [55, 66], [67, 70], [71, 84], [85, 96], [96, 97], [98, 106], [107, 118], [119, 124], [124, 125]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P.", "Frasconi", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 30], [31, 39], [40, 43], [44, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-206", "ner": [[0, 5, "product"], [8, 12, "misc"], [8, 8, "programlang"], [14, 15, "product"], [31, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 8, 8, "usage", "", false, false], [8, 8, 8, 12, "type-of", "", false, false], [8, 8, 14, 15, "related-to", "", false, false], [31, 31, 0, 5, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["For", "example", ",", "the", "A.L.I.C.E.", "system", "uses", "the", "AIML", "markup", "language", "specific", "to", "its", "dialog", "system", "function", ",", "which", "has", "since", "been", "adopted", "by", "various", "other", "developers", "of", "so", "-", "called", "Alicebots", "."], "sentence-detokenized": "For example, the A.L.I.C.E. system uses the AIML markup language specific to its dialog system function, which has since been adopted by various other developers of so-called Alicebots.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 27], [28, 34], [35, 39], [40, 43], [44, 48], [49, 55], [56, 64], [65, 73], [74, 76], [77, 80], [81, 87], [88, 94], [95, 103], [103, 104], [105, 110], [111, 114], [115, 120], [121, 125], [126, 133], [134, 136], [137, 144], [145, 150], [151, 161], [162, 164], [165, 167], [167, 168], [168, 174], [175, 184], [184, 185]]}
{"doc_key": "ai-dev-207", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2000", ",", "she", "was", "elected", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2000, she was elected a member of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 24], [25, 26], [27, 33], [34, 36], [37, 40], [41, 52], [53, 56], [57, 60], [61, 72], [73, 75], [76, 86], [87, 99], [99, 100]]}
{"doc_key": "ai-dev-208", "ner": [[0, 2, "misc"], [4, 4, "misc"], [10, 16, "misc"], [24, 25, "algorithm"], [34, 35, "field"], [37, 38, "field"], [41, 42, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 10, 16, "type-of", "", false, false], [0, 2, 34, 35, "related-to", "performs", true, false], [0, 2, 37, 38, "related-to", "performs", true, false], [0, 2, 41, 42, "related-to", "performs", true, false], [4, 4, 0, 2, "named", "", false, false], [24, 25, 10, 16, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Learning", "Classification", "Systems", "(", "LCS", ")", "are", "a", "family", "of", "rule", "-", "based", "machine", "learning", "algorithms", "that", "combine", "a", "discovery", "component", ",", "usually", "a", "genetic", "algorithm", ",", "with", "a", "learning", "component", "that", "performs", "either", "supervised", "learning", ",", "reinforcement", "learning", ",", "or", "unsupervised", "learning", "."], "sentence-detokenized": "Learning Classification Systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, usually a genetic algorithm, with a learning component that performs either supervised learning, reinforcement learning, or unsupervised learning.", "token2charspan": [[0, 8], [9, 23], [24, 31], [32, 33], [33, 36], [36, 37], [38, 41], [42, 43], [44, 50], [51, 53], [54, 58], [58, 59], [59, 64], [65, 72], [73, 81], [82, 92], [93, 97], [98, 105], [106, 107], [108, 117], [118, 127], [127, 128], [129, 136], [137, 138], [139, 146], [147, 156], [156, 157], [158, 162], [163, 164], [165, 173], [174, 183], [184, 188], [189, 197], [198, 204], [205, 215], [216, 224], [224, 225], [226, 239], [240, 248], [248, 249], [250, 252], [253, 265], [266, 274], [274, 275]]}
{"doc_key": "ai-dev-209", "ner": [[14, 16, "algorithm"], [18, 18, "algorithm"], [27, 28, "algorithm"], [30, 31, "misc"], [40, 46, "algorithm"], [51, 60, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 16, 27, 28, "origin", "", false, false], [14, 16, 30, 31, "usage", "", false, false], [18, 18, 14, 16, "named", "", false, false], [40, 46, 30, 31, "type-of", "", false, false], [40, 46, 51, 60, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "unknown", "parameters", "in", "each", "\u03b2subk", "/", "sub", "vector", "are", "usually", "jointly", "estimated", "using", "maximum", "and", "posterior", "(", "MAP", ")", "estimation", ",", "which", "is", "an", "extension", "of", "maximum", "likelihood", "using", "regularization", "of", "the", "weights", "to", "avoid", "pathological", "solutions", "(", "usually", "a", "quadratic", "regularization", "function", ",", "which", "is", "equivalent", "to", "putting", "a", "Gaussian", "distribution", "with", "zero", "mean", "on", "the", "weights", ",", "but", "other", "distributions", "are", "possible", ")", "."], "sentence-detokenized": "The unknown parameters in each \u03b2subk/sub vector are usually jointly estimated using maximum and posterior (MAP) estimation, which is an extension of maximum likelihood using regularization of the weights to avoid pathological solutions (usually a quadratic regularization function, which is equivalent to putting a Gaussian distribution with zero mean on the weights, but other distributions are possible).", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 30], [31, 36], [36, 37], [37, 40], [41, 47], [48, 51], [52, 59], [60, 67], [68, 77], [78, 83], [84, 91], [92, 95], [96, 105], [106, 107], [107, 110], [110, 111], [112, 122], [122, 123], [124, 129], [130, 132], [133, 135], [136, 145], [146, 148], [149, 156], [157, 167], [168, 173], [174, 188], [189, 191], [192, 195], [196, 203], [204, 206], [207, 212], [213, 225], [226, 235], [236, 237], [237, 244], [245, 246], [247, 256], [257, 271], [272, 280], [280, 281], [282, 287], [288, 290], [291, 301], [302, 304], [305, 312], [313, 314], [315, 323], [324, 336], [337, 341], [342, 346], [347, 351], [352, 354], [355, 358], [359, 366], [366, 367], [368, 371], [372, 377], [378, 391], [392, 395], [396, 404], [404, 405], [405, 406]]}
{"doc_key": "ai-dev-210", "ner": [[9, 11, "researcher"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 9, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "hierarchical", "structure", "of", "words", "was", "explicitly", "mapped", "in", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "The hierarchical structure of words was explicitly mapped in George Miller's Wordnet.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 29], [30, 35], [36, 39], [40, 50], [51, 57], [58, 60], [61, 67], [68, 74], [74, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-dev-211", "ner": [[0, 16, "conference"], [19, 23, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 23, 0, 16, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "is", "an", "illustration", "of", "their", "abilities", ";", "it", "is", "a", "benchmark", "in", "object", "classification", "and", "detection", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge is an illustration of their abilities; it is a benchmark in object classification and detection with millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 59], [60, 72], [73, 75], [76, 81], [82, 91], [91, 92], [93, 95], [96, 98], [99, 100], [101, 110], [111, 113], [114, 120], [121, 135], [136, 139], [140, 149], [150, 154], [155, 163], [164, 166], [167, 173], [174, 177], [178, 186], [187, 189], [190, 196], [197, 204], [204, 205]]}
{"doc_key": "ai-dev-212", "ner": [[1, 8, "misc"], [22, 22, "misc"], [24, 26, "person"], [29, 29, "misc"], [35, 37, "person"], [40, 42, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[22, 22, 1, 8, "general-affiliation", "", false, false], [29, 29, 1, 8, "general-affiliation", "", false, false], [29, 29, 24, 26, "artifact", "", false, false], [40, 42, 1, 8, "general-affiliation", "", false, false], [40, 42, 35, 37, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "science", "fiction", "literature", ",", "female", "robots", "are", "often", "produced", "as", "domestic", "servants", "and", "sex", "slaves", ",", "as", "seen", "in", "the", "film", "Westworld", ",", "Paul", "J.", "McAuley", "'s", "novel", "Fairyland", "(", "1995", ")", ",", "and", "Lester", "del", "Rey's", "short", "story", "Helen", "O'", "Loy", "(", "1938", ")", ",", "and", "sometimes", "as", "warriors", ",", "assassins", ",", "or", "laborers", "."], "sentence-detokenized": "In science fiction literature, female robots are often produced as domestic servants and sex slaves, as seen in the film Westworld, Paul J. McAuley's novel Fairyland (1995), and Lester del Rey's short story Helen O'Loy (1938), and sometimes as warriors, assassins, or laborers.", "token2charspan": [[0, 2], [3, 10], [11, 18], [19, 29], [29, 30], [31, 37], [38, 44], [45, 48], [49, 54], [55, 63], [64, 66], [67, 75], [76, 84], [85, 88], [89, 92], [93, 99], [99, 100], [101, 103], [104, 108], [109, 111], [112, 115], [116, 120], [121, 130], [130, 131], [132, 136], [137, 139], [140, 147], [147, 149], [150, 155], [156, 165], [166, 167], [167, 171], [171, 172], [172, 173], [174, 177], [178, 184], [185, 188], [189, 194], [195, 200], [201, 206], [207, 212], [213, 215], [215, 218], [219, 220], [220, 224], [224, 225], [225, 226], [227, 230], [231, 240], [241, 243], [244, 252], [252, 253], [254, 263], [263, 264], [265, 267], [268, 276], [276, 277]]}
{"doc_key": "ai-dev-213", "ner": [[0, 1, "task"], [3, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["question", "answering", ",", "speech", "recognition", "and", "machine", "translation", "."], "sentence-detokenized": "question answering, speech recognition and machine translation.", "token2charspan": [[0, 8], [9, 18], [18, 19], [20, 26], [27, 38], [39, 42], [43, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-214", "ner": [[5, 6, "researcher"], [9, 13, "organisation"], [15, 19, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 9, 13, "role", "", false, false], [9, 13, 15, 19, "physical", "", false, false], [15, 19, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "seminal", "work", ",", "Harry", "Blum", "of", "the", "Air", "Force", "Cambridge", "Research", "Laboratories", "at", "Hanscom", "Air", "Force", "Base", "in", "Bedford", ",", "Massachusetts", ",", "defined", "a", "central", "axis", "for", "calculating", "the", "skeleton", "of", "a", "shape", "using", "an", "intuitive", "model", "of", "fire", "spread", "in", "a", "grass", "field", "where", "the", "field", "has", "a", "given", "shape", "."], "sentence-detokenized": "In his seminal work, Harry Blum of the Air Force Cambridge Research Laboratories at Hanscom Air Force Base in Bedford, Massachusetts, defined a central axis for calculating the skeleton of a shape using an intuitive model of fire spread in a grass field where the field has a given shape.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 19], [19, 20], [21, 26], [27, 31], [32, 34], [35, 38], [39, 42], [43, 48], [49, 58], [59, 67], [68, 80], [81, 83], [84, 91], [92, 95], [96, 101], [102, 106], [107, 109], [110, 117], [117, 118], [119, 132], [132, 133], [134, 141], [142, 143], [144, 151], [152, 156], [157, 160], [161, 172], [173, 176], [177, 185], [186, 188], [189, 190], [191, 196], [197, 202], [203, 205], [206, 215], [216, 221], [222, 224], [225, 229], [230, 236], [237, 239], [240, 241], [242, 247], [248, 253], [254, 259], [260, 263], [264, 269], [270, 273], [274, 275], [276, 281], [282, 287], [287, 288]]}
{"doc_key": "ai-dev-215", "ner": [[15, 15, "algorithm"], [17, 17, "algorithm"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 20, 21, "compare", "", false, false], [17, 17, 20, 21, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "unlike", "boosting", "algorithms", "that", "analytically", "minimize", "a", "convex", "loss", "function", "(", "e.g.", ",", "AdaBoost", "and", "LogitBoost", ")", ",", "Brown", "Boost", "solves", "a", "system", "of", "two", "equations", "and", "two", "unknowns", "using", "standard", "numerical", "methods", "."], "sentence-detokenized": "However, unlike boosting algorithms that analytically minimize a convex loss function (e.g., AdaBoost and LogitBoost), BrownBoost solves a system of two equations and two unknowns using standard numerical methods.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 24], [25, 35], [36, 40], [41, 53], [54, 62], [63, 64], [65, 71], [72, 76], [77, 85], [86, 87], [87, 91], [91, 92], [93, 101], [102, 105], [106, 116], [116, 117], [117, 118], [119, 124], [124, 129], [130, 136], [137, 138], [139, 145], [146, 148], [149, 152], [153, 162], [163, 166], [167, 170], [171, 179], [180, 185], [186, 194], [195, 204], [205, 212], [212, 213]]}
{"doc_key": "ai-dev-216", "ner": [[0, 2, "researcher"], [9, 11, "misc"], [19, 25, "conference"], [27, 27, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 9, 11, "win-defeat", "", false, false], [0, 2, 19, 25, "role", "", false, false], [27, 27, 19, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getoor", "has", "won", "several", "best", "paper", "awards", ",", "an", "NSF", "Career", "Award", ",", "and", "is", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Getoor has won several best paper awards, an NSF Career Award, and is a member of the Association for the Advancement of Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 22], [23, 27], [28, 33], [34, 40], [40, 41], [42, 44], [45, 48], [49, 55], [56, 61], [61, 62], [63, 66], [67, 69], [70, 71], [72, 78], [79, 81], [82, 85], [86, 97], [98, 101], [102, 105], [106, 117], [118, 120], [121, 131], [132, 144], [145, 146], [146, 150], [150, 151], [151, 152]]}
{"doc_key": "ai-dev-217", "ner": [[0, 1, "misc"], [6, 10, "misc"], [15, 16, "misc"], [21, 25, "misc"], [30, 31, "misc"], [35, 39, "university"], [44, 52, "misc"], [57, 65, "misc"], [70, 74, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACM", "Fellow", "(", "2015", ")", "br", "Association", "for", "Computational", "Linguistics", "Fellow", "(", "2011", ")", "br", "AAAI", "Fellow", "(", "1994", ")", "br", "International", "Speech", "Communication", "Association", "Fellow", "(", "2011", ")", "br", "Honorary", "Doctorate", "(", "Hedersdoctor", ")", "KTH", "Royal", "Institute", "of", "Technology", "(", "2007", ")", "br", "Columbia", "Engineering", "School", "Alumni", "Association", "Distinguished", "Faculty", "Teaching", "award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Speech", "and", "Audio", "Processing", "Award", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")"], "sentence-detokenized": "ACM Fellow (2015) br Association for Computational Linguistics Fellow (2011) br AAAI Fellow (1994) br International Speech Communication Association Fellow (2011) br Honorary Doctorate (Hedersdoctor) KTH Royal Institute of Technology (2007) br Columbia Engineering School Alumni Association Distinguished Faculty Teaching award (2009) br IEEE James L. Flanagan Speech and Audio Processing Award (2011) br ISCA Medal for Scientific Achievement (2011)", "token2charspan": [[0, 3], [4, 10], [11, 12], [12, 16], [16, 17], [18, 20], [21, 32], [33, 36], [37, 50], [51, 62], [63, 69], [70, 71], [71, 75], [75, 76], [77, 79], [80, 84], [85, 91], [92, 93], [93, 97], [97, 98], [99, 101], [102, 115], [116, 122], [123, 136], [137, 148], [149, 155], [156, 157], [157, 161], [161, 162], [163, 165], [166, 174], [175, 184], [185, 186], [186, 198], [198, 199], [200, 203], [204, 209], [210, 219], [220, 222], [223, 233], [234, 235], [235, 239], [239, 240], [241, 243], [244, 252], [253, 264], [265, 271], [272, 278], [279, 290], [291, 304], [305, 312], [313, 321], [322, 327], [328, 329], [329, 333], [333, 334], [335, 337], [338, 342], [343, 348], [349, 351], [352, 360], [361, 367], [368, 371], [372, 377], [378, 388], [389, 394], [395, 396], [396, 400], [400, 401], [402, 404], [405, 409], [410, 415], [416, 419], [420, 430], [431, 442], [443, 444], [444, 448], [448, 449]]}
{"doc_key": "ai-dev-218", "ner": [[6, 7, "university"], [15, 21, "task"], [25, 26, "metrics"], [38, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 26, 38, 40, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["A", "frustrating", "result", "of", "the", "same", "Stanford", "University", "study", "(", "and", "other", "attempts", "to", "improve", "named", "entity", "translation", ")", "is", "that", "in", "many", "cases", ",", "bilingual", "incomplete", "translation", "scores", "are", "reduced", "as", "a", "result", "of", "the", "inclusion", "of", "named", "entity", "translation", "methods", "."], "sentence-detokenized": "A frustrating result of the same Stanford University study (and other attempts to improve named entity translation) is that in many cases, bilingual incomplete translation scores are reduced as a result of the inclusion of named entity translation methods.", "token2charspan": [[0, 1], [2, 13], [14, 20], [21, 23], [24, 27], [28, 32], [33, 41], [42, 52], [53, 58], [59, 60], [60, 63], [64, 69], [70, 78], [79, 81], [82, 89], [90, 95], [96, 102], [103, 114], [114, 115], [116, 118], [119, 123], [124, 126], [127, 131], [132, 137], [137, 138], [139, 148], [149, 159], [160, 171], [172, 178], [179, 182], [183, 190], [191, 193], [194, 195], [196, 202], [203, 205], [206, 209], [210, 219], [220, 222], [223, 228], [229, 235], [236, 247], [248, 255], [255, 256]]}
{"doc_key": "ai-dev-219", "ner": [[0, 0, "organisation"], [12, 14, "organisation"], [16, 21, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 14, "role", "works_with", false, false], [0, 0, 16, 21, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "is", "using", "the", "PM", "data", "collected", "and", "working", "with", "researchers", "at", "Johns", "Hopkins", "Hospital", "and", "Washington", "University", "School", "of", "Medicine", "to", "help", "answer", "specific", "questions", "about", "heart", "disease", ",", "such", "as", "whether", "a", "weak", "heart", "causes", "arrhythmia", "or", "vice", "versa", "."], "sentence-detokenized": "Medtronic is using the PM data collected and working with researchers at Johns Hopkins Hospital and Washington University School of Medicine to help answer specific questions about heart disease, such as whether a weak heart causes arrhythmia or vice versa.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 22], [23, 25], [26, 30], [31, 40], [41, 44], [45, 52], [53, 57], [58, 69], [70, 72], [73, 78], [79, 86], [87, 95], [96, 99], [100, 110], [111, 121], [122, 128], [129, 131], [132, 140], [141, 143], [144, 148], [149, 155], [156, 164], [165, 174], [175, 180], [181, 186], [187, 194], [194, 195], [196, 200], [201, 203], [204, 211], [212, 213], [214, 218], [219, 224], [225, 231], [232, 242], [243, 245], [246, 250], [251, 256], [256, 257]]}
{"doc_key": "ai-dev-220", "ner": [[4, 5, "organisation"], [9, 10, "misc"], [13, 14, "person"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 4, 5, "artifact", "made_by_studio", false, false], [13, 14, 9, 10, "role", "", false, false], [16, 17, 9, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "was", "followed", "by", "Paramount", "'s", "first", "feature", "film", ",", "Sangaree", ",", "starring", "Fernando", "Lamas", "and", "Arlene", "Dahl", "."], "sentence-detokenized": "This was followed by Paramount's first feature film, Sangaree, starring Fernando Lamas and Arlene Dahl.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 30], [30, 32], [33, 38], [39, 46], [47, 51], [51, 52], [53, 61], [61, 62], [63, 71], [72, 80], [81, 86], [87, 90], [91, 97], [98, 102], [102, 103]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [8, 10, "researcher"], [12, 13, "researcher"], [18, 19, "organisation"], [21, 22, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 10, "origin", "", false, false], [0, 0, 12, 13, "origin", "", false, false], [8, 10, 18, 19, "physical", "", false, false], [8, 10, 18, 19, "role", "", false, false], [12, 13, 21, 22, "physical", "", false, false], [12, 13, 21, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "is", "a", "knowledge", "representation", "language", "developed", "by", "Daniel", "G.", "Bobrow", "and", "Terry", "Winograd", "during", "their", "time", "at", "Xerox", "PARC", "and", "Stanford", "University", "."], "sentence-detokenized": "KRL is a knowledge representation language developed by Daniel G. Bobrow and Terry Winograd during their time at Xerox PARC and Stanford University.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 18], [19, 33], [34, 42], [43, 52], [53, 55], [56, 62], [63, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 98], [99, 104], [105, 109], [110, 112], [113, 118], [119, 123], [124, 127], [128, 136], [137, 147], [147, 148]]}
{"doc_key": "ai-dev-222", "ner": [[2, 10, "conference"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [23, 26, "researcher"], [34, 35, "task"], [37, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 10, 34, 35, "topic", "", true, false], [13, 14, 2, 10, "physical", "", false, false], [13, 14, 2, 10, "role", "", false, false], [13, 14, 2, 10, "temporal", "", false, false], [16, 17, 2, 10, "physical", "", false, false], [16, 17, 2, 10, "role", "", false, false], [16, 17, 2, 10, "temporal", "", false, false], [19, 20, 2, 10, "physical", "", false, false], [19, 20, 2, 10, "role", "", false, false], [19, 20, 2, 10, "temporal", "", false, false], [23, 26, 2, 10, "physical", "", false, false], [23, 26, 2, 10, "role", "", false, false], [23, 26, 2, 10, "temporal", "", false, false], [34, 35, 37, 39, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["At", "the", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "in", "2006", ",", "Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", ",", "and", "Kwang", "-", "Ting", "Cheng", "presented", "an", "algorithm", "to", "significantly", "speed", "up", "human", "detection", "using", "HOG", "descriptor", "methods", "."], "sentence-detokenized": "At the IEEE Conference on Computer Vision and Pattern Recognition in 2006, Qiang Zhu, Shai Avidan, Mei-Chen Yeh, and Kwang-Ting Cheng presented an algorithm to significantly speed up human detection using HOG descriptor methods.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 22], [23, 25], [26, 34], [35, 41], [42, 45], [46, 53], [54, 65], [66, 68], [69, 73], [73, 74], [75, 80], [81, 84], [84, 85], [86, 90], [91, 97], [97, 98], [99, 107], [108, 111], [111, 112], [113, 116], [117, 122], [122, 123], [123, 127], [128, 133], [134, 143], [144, 146], [147, 156], [157, 159], [160, 173], [174, 179], [180, 182], [183, 188], [189, 198], [199, 204], [205, 208], [209, 219], [220, 227], [227, 228]]}
{"doc_key": "ai-dev-223", "ner": [[0, 0, "researcher"], [6, 8, "conference"], [9, 12, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 8, "role", "", false, false], [0, 0, 9, 12, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "is", "a", "founding", "member", "of", "AAAI", "and", "the", "Society", "for", "Cognitive", "Science", "."], "sentence-detokenized": "Hayes is a founding member of AAAI and the Society for Cognitive Science.", "token2charspan": [[0, 5], [6, 8], [9, 10], [11, 19], [20, 26], [27, 29], [30, 34], [35, 38], [39, 42], [43, 50], [51, 54], [55, 64], [65, 72], [72, 73]]}
{"doc_key": "ai-dev-224", "ner": [[0, 2, "misc"], [5, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 35, "field"], [39, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 2, 5, 5, "part-of", "", false, false], [0, 2, 5, 5, "usage", "", false, false], [0, 2, 7, 8, "part-of", "", false, false], [0, 2, 7, 8, "usage", "", false, false], [0, 2, 10, 11, "part-of", "", false, false], [0, 2, 10, 11, "usage", "", false, false], [0, 2, 13, 13, "part-of", "", false, false], [0, 2, 13, 13, "usage", "", false, false], [0, 2, 15, 16, "part-of", "", false, false], [0, 2, 15, 16, "usage", "", false, false], [0, 2, 18, 19, "part-of", "", false, false], [0, 2, 18, 19, "usage", "", false, false], [0, 2, 21, 22, "part-of", "", false, false], [0, 2, 21, 22, "usage", "", false, false], [0, 2, 24, 24, "part-of", "", false, false], [0, 2, 24, 24, "usage", "", false, false], [0, 2, 26, 27, "part-of", "", false, false], [0, 2, 26, 27, "usage", "", false, false], [0, 2, 29, 29, "part-of", "", false, false], [0, 2, 29, 29, "usage", "", false, false], [0, 2, 31, 35, "part-of", "", false, false], [0, 2, 31, 35, "usage", "", false, false], [0, 2, 39, 40, "part-of", "", false, false], [0, 2, 39, 40, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", ",", "and", "basically", "all", "areas", "of", "applied", "science", "and", "engineering", "that", "involve", "time", "measurements", "."], "sentence-detokenized": "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering, and basically all areas of applied science and engineering that involve time measurements.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 23], [24, 34], [34, 35], [36, 42], [43, 53], [53, 54], [55, 62], [63, 74], [74, 75], [76, 88], [88, 89], [90, 102], [103, 110], [110, 111], [112, 119], [120, 131], [131, 132], [133, 143], [144, 154], [154, 155], [156, 178], [178, 179], [180, 187], [188, 199], [199, 200], [201, 210], [210, 211], [212, 226], [227, 238], [238, 239], [240, 243], [244, 253], [254, 257], [258, 263], [264, 266], [267, 274], [275, 282], [283, 286], [287, 298], [299, 303], [304, 311], [312, 316], [317, 329], [329, 330]]}
{"doc_key": "ai-dev-225", "ner": [[13, 16, "metrics"], [35, 37, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Exact", "recovery", "can", "in", "principle", "be", "solved", "within", "it", "s", "feasible", "range", "using", "maximum", "likelihood", ",", "but", "this", "amounts", "to", "solving", "a", "constrained", "or", "regularized", "cut", "problem", "such", "as", "minimum", "bisection", ",", "which", "is", "usually", "NP", "-", "complete", "."], "sentence-detokenized": "Exact recovery can in principle be solved within its feasible range using maximum likelihood, but this amounts to solving a constrained or regularized cut problem such as minimum bisection, which is usually NP-complete.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 21], [22, 31], [32, 34], [35, 41], [42, 48], [49, 51], [51, 52], [53, 61], [62, 67], [68, 73], [74, 81], [82, 92], [92, 93], [94, 97], [98, 102], [103, 110], [111, 113], [114, 121], [122, 123], [124, 135], [136, 138], [139, 150], [151, 154], [155, 162], [163, 167], [168, 170], [171, 178], [179, 188], [188, 189], [190, 195], [196, 198], [199, 206], [207, 209], [209, 210], [210, 218], [218, 219]]}
{"doc_key": "ai-dev-226", "ner": [[4, 7, "task"], [13, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 15, 4, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["in", "their", "work", "on", "pedestrian", "detection", ",", "which", "was", "first", "described", "at", "the", "BMVC", "in", "2009", "."], "sentence-detokenized": "in their work on pedestrian detection, which was first described at the BMVC in 2009.", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 16], [17, 27], [28, 37], [37, 38], [39, 44], [45, 48], [49, 54], [55, 64], [65, 67], [68, 71], [72, 76], [77, 79], [80, 84], [84, 85]]}
{"doc_key": "ai-dev-227", "ner": [[16, 22, "conference"], [3, 3, "researcher"], [6, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 16, 22, "physical", "", false, false], [3, 3, 16, 22, "role", "", false, false], [3, 3, 6, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2007", ",", "Terzopoulos", "received", "the", "first", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "at", "the", "International", "Conference", "on", "Computer", "Vision", "for", "his", "pioneering", "and", "sustained", "research", "on", "deformable", "models", "and", "their", "applications", "."], "sentence-detokenized": "In 2007, Terzopoulos received the first IEEE PAMI Computer Vision Distinguished Researcher Award at the International Conference on Computer Vision for his pioneering and sustained research on deformable models and their applications.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 29], [30, 33], [34, 39], [40, 44], [45, 49], [50, 58], [59, 65], [66, 79], [80, 90], [91, 96], [97, 99], [100, 103], [104, 117], [118, 128], [129, 131], [132, 140], [141, 147], [148, 151], [152, 155], [156, 166], [167, 170], [171, 180], [181, 189], [190, 192], [193, 203], [204, 210], [211, 214], [215, 220], [221, 233], [233, 234]]}
{"doc_key": "ai-dev-228", "ner": [[0, 1, "task"], [3, 4, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 3, 4, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cluster", "analysis", "or", "cluster", "analysis", "involves", "assigning", "data", "points", "to", "clusters", "so", "that", "items", "in", "the", "same", "cluster", "are", "as", "similar", "as", "possible", ",", "while", "items", "belonging", "to", "different", "clusters", "are", "as", "different", "as", "possible", "."], "sentence-detokenized": "Cluster analysis or cluster analysis involves assigning data points to clusters so that items in the same cluster are as similar as possible, while items belonging to different clusters are as different as possible.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 36], [37, 45], [46, 55], [56, 60], [61, 67], [68, 70], [71, 79], [80, 82], [83, 87], [88, 93], [94, 96], [97, 100], [101, 105], [106, 113], [114, 117], [118, 120], [121, 128], [129, 131], [132, 140], [140, 141], [142, 147], [148, 153], [154, 163], [164, 166], [167, 176], [177, 185], [186, 189], [190, 192], [193, 202], [203, 205], [206, 214], [214, 215]]}
{"doc_key": "ai-dev-229", "ner": [[11, 14, "field"], [15, 15, "field"], [18, 19, "task"], [21, 22, "field"], [25, 26, "field"], [28, 29, "field"], [34, 35, "field"], [37, 38, "task"], [40, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[11, 14, 15, 15, "named", "", false, false], [11, 14, 21, 22, "named", "", false, false], [11, 14, 28, 29, "named", "", false, false], [18, 19, 15, 15, "part-of", "task_part_of_field", false, false], [25, 26, 21, 22, "part-of", "", false, false], [34, 35, 28, 29, "part-of", "", false, false], [37, 38, 34, 35, "part-of", "", false, false], [40, 40, 34, 35, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["(", "2005", ")", ",", "we", "can", "distinguish", "three", "different", "views", "of", "text", "mining", ",", "namely", "text", "mining", "as", "information", "extraction", ",", "text", "mining", "as", "text", "data", "mining", "and", "text", "mining", "as", "a", "process", "of", "Data", "mining", "(", "Knowledge", "Discovery", "in", "Databases", ")", ".", "Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005), we can distinguish three different views of text mining, namely text mining as information extraction, text mining as text data mining and text mining as a process of Data mining (Knowledge Discovery in Databases). Hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [6, 7], [8, 10], [11, 14], [15, 26], [27, 32], [33, 42], [43, 48], [49, 51], [52, 56], [57, 63], [63, 64], [65, 71], [72, 76], [77, 83], [84, 86], [87, 98], [99, 109], [109, 110], [111, 115], [116, 122], [123, 125], [126, 130], [131, 135], [136, 142], [143, 146], [147, 151], [152, 158], [159, 161], [162, 163], [164, 171], [172, 174], [175, 179], [180, 186], [187, 188], [188, 197], [198, 207], [208, 210], [211, 220], [220, 221], [221, 222], [223, 228], [228, 229], [230, 232], [232, 233], [234, 244], [244, 245], [246, 248], [249, 252], [253, 257], [257, 258], [259, 261], [262, 263], [263, 267], [267, 268], [268, 269]]}
{"doc_key": "ai-dev-230", "ner": [[0, 3, "product"], [15, 20, "location"], [22, 22, "location"], [24, 26, "location"], [36, 37, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 15, 20, "related-to", "developed_for", false, false], [15, 20, 22, 22, "physical", "", false, false], [22, 22, 24, 26, "physical", "", false, false], [36, 37, 0, 3, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Rancho", "Arm", "was", "developed", "as", "a", "robotic", "arm", "to", "assist", "disabled", "patients", "at", "the", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Center", "in", "Downey", ",", "California", ";", "in", "1963", "this", "computer", "-", "controlled", "arm", "was", "purchased", "by", "Stanford", "University", "."], "sentence-detokenized": "The Rancho Arm was developed as a robotic arm to assist disabled patients at the Rancho Los Amigos National Rehabilitation Center in Downey, California; in 1963 this computer-controlled arm was purchased by Stanford University.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 18], [19, 28], [29, 31], [32, 33], [34, 41], [42, 45], [46, 48], [49, 55], [56, 64], [65, 73], [74, 76], [77, 80], [81, 87], [88, 91], [92, 98], [99, 107], [108, 122], [123, 129], [130, 132], [133, 139], [139, 140], [141, 151], [151, 152], [153, 155], [156, 160], [161, 165], [166, 174], [174, 175], [175, 185], [186, 189], [190, 193], [194, 203], [204, 206], [207, 215], [216, 226], [226, 227]]}
{"doc_key": "ai-dev-231", "ner": [[1, 1, "university"], [3, 3, "researcher"], [9, 12, "organisation"], [20, 23, "organisation"], [27, 28, "researcher"], [30, 32, "researcher"], [44, 44, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 1, 1, "physical", "", false, false], [3, 3, 1, 1, "role", "", false, false], [3, 3, 9, 12, "role", "founder", false, false], [3, 3, 20, 23, "role", "founder", false, false], [20, 23, 44, 44, "physical", "", false, false], [27, 28, 20, 23, "role", "founder", false, false], [30, 32, 20, 23, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["At", "UCSD", ",", "Norman", "was", "a", "founder", "of", "the", "Institute", "for", "Cognitive", "Science", "and", "one", "of", "the", "organizers", "of", "the", "Society", "for", "Cognitive", "Science", "(", "along", "with", "Roger", "Schank", ",", "Allan", "M.", "Collins", ",", "and", "others", ")", ",", "whose", "first", "meeting", "was", "held", "at", "UCSD", "in", "1979", "."], "sentence-detokenized": "At UCSD, Norman was a founder of the Institute for Cognitive Science and one of the organizers of the Society for Cognitive Science (along with Roger Schank, Allan M. Collins, and others), whose first meeting was held at UCSD in 1979.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 21], [22, 29], [30, 32], [33, 36], [37, 46], [47, 50], [51, 60], [61, 68], [69, 72], [73, 76], [77, 79], [80, 83], [84, 94], [95, 97], [98, 101], [102, 109], [110, 113], [114, 123], [124, 131], [132, 133], [133, 138], [139, 143], [144, 149], [150, 156], [156, 157], [158, 163], [164, 166], [167, 174], [174, 175], [176, 179], [180, 186], [186, 187], [187, 188], [189, 194], [195, 200], [201, 208], [209, 212], [213, 217], [218, 220], [221, 225], [226, 228], [229, 233], [233, 234]]}
{"doc_key": "ai-dev-232", "ner": [[7, 8, "product"], [10, 11, "product"], [13, 14, "product"], [16, 19, "product"], [21, 22, "product"], [24, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[21, 22, 16, 19, "type-of", "", false, false], [24, 29, 16, 19, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "commonly", "used", "robot", "configurations", "are", "articulated", "robots", ",", "SCARA", "robots", ",", "delta", "robots", "and", "robots", "with", "Cartesian", "coordinates", "(", "gantry", "robots", "or", "x", "-", "y", "-", "z", "robots", ")", "."], "sentence-detokenized": "The most commonly used robot configurations are articulated robots, SCARA robots, delta robots and robots with Cartesian coordinates (gantry robots or x-y-z robots).", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 28], [29, 43], [44, 47], [48, 59], [60, 66], [66, 67], [68, 73], [74, 80], [80, 81], [82, 87], [88, 94], [95, 98], [99, 105], [106, 110], [111, 120], [121, 132], [133, 134], [134, 140], [141, 147], [148, 150], [151, 152], [152, 153], [153, 154], [154, 155], [155, 156], [157, 163], [163, 164], [164, 165]]}
{"doc_key": "ai-dev-233", "ner": [[9, 9, "programlang"], [10, 11, "misc"], [16, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 9, 9, "part-of", "", false, false], [16, 16, 10, 11, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Alternatively", ",", "it", "can", "be", "used", "directly", "with", "the", "Perl", "TM", "module", "(", "which", "also", "supports", "LTM", ")", "."], "sentence-detokenized": "Alternatively, it can be used directly with the Perl TM module (which also supports LTM).", "token2charspan": [[0, 13], [13, 14], [15, 17], [18, 21], [22, 24], [25, 29], [30, 38], [39, 43], [44, 47], [48, 52], [53, 55], [56, 62], [63, 64], [64, 69], [70, 74], [75, 83], [84, 87], [87, 88], [88, 89]]}
{"doc_key": "ai-dev-234", "ner": [[5, 6, "country"], [9, 11, "organisation"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 11, 5, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "competition", "was", "won", "by", "an", "American", "team", "from", "Newton", "Labs", "and", "was", "broadcast", "on", "CNN", "."], "sentence-detokenized": "The competition was won by an American team from Newton Labs and was broadcast on CNN.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 26], [27, 29], [30, 38], [39, 43], [44, 48], [49, 55], [56, 60], [61, 64], [65, 68], [69, 78], [79, 81], [82, 85], [85, 86]]}
{"doc_key": "ai-dev-235", "ner": [[0, 4, "misc"], [11, 14, "person"], [15, 16, "person"], [18, 21, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 14, 0, 4, "role", "directs", false, false], [15, 16, 0, 4, "role", "acts_in", false, false], [18, 21, 0, 4, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Butler", "'s", "in", "Love", ",", "a", "short", "film", "directed", "by", "David", "Arquette", "and", "starring", "Elizabeth", "Berkley", "and", "Thomas", "Jane", ",", "was", "released", "on", "23", "June", "2008", "."], "sentence-detokenized": "The Butler's in Love, a short film directed by David Arquette and starring Elizabeth Berkley and Thomas Jane, was released on 23 June 2008.", "token2charspan": [[0, 3], [4, 10], [10, 12], [13, 15], [16, 20], [20, 21], [22, 23], [24, 29], [30, 34], [35, 43], [44, 46], [47, 52], [53, 61], [62, 65], [66, 74], [75, 84], [85, 92], [93, 96], [97, 103], [104, 108], [108, 109], [110, 113], [114, 122], [123, 125], [126, 128], [129, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-dev-236", "ner": [[3, 4, "product"], [10, 11, "field"], [17, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 17, 17, "general-affiliation", "", false, false], [10, 11, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "Word", "Net", "is", "a", "resource", "containing", "a", "taxonomy", "whose", "elements", "are", "the", "meanings", "of", "English", "words", "."], "sentence-detokenized": "For example, WordNet is a resource containing a taxonomy whose elements are the meanings of English words.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [17, 20], [21, 23], [24, 25], [26, 34], [35, 45], [46, 47], [48, 56], [57, 62], [63, 71], [72, 75], [76, 79], [80, 88], [89, 91], [92, 99], [100, 105], [105, 106]]}
{"doc_key": "ai-dev-237", "ner": [[1, 5, "product"], [7, 7, "product"], [9, 9, "product"], [16, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 1, 5, "type-of", "", false, false], [7, 7, 16, 16, "related-to", "ability_to", false, false], [9, 9, 1, 5, "type-of", "", false, false], [9, 9, 16, 16, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Existing", "humanoid", "robotic", "systems", ",", "such", "as", "ASIMO", "and", "QRIO", ",", "use", "many", "motors", "to", "achieve", "locomotion", "."], "sentence-detokenized": "Existing humanoid robotic systems, such as ASIMO and QRIO, use many motors to achieve locomotion.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 33], [33, 34], [35, 39], [40, 42], [43, 48], [49, 52], [53, 57], [57, 58], [59, 62], [63, 67], [68, 74], [75, 77], [78, 85], [86, 96], [96, 97]]}
{"doc_key": "ai-dev-238", "ner": [[0, 0, "metrics"], [8, 9, "metrics"], [11, 12, "metrics"], [14, 18, "misc"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 9, 0, 0, "part-of", "", false, false], [11, 12, 0, 0, "part-of", "", false, false], [14, 18, 0, 0, "part-of", "", false, false], [20, 20, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "is", "designed", "with", "the", "factors", "of", "extended", "length", "penalty", ",", "precision", "penalty", ",", "n-", "gram", "word", "order", "penalty", "and", "recall", "."], "sentence-detokenized": "LEPOR is designed with the factors of extended length penalty, precision penalty, n-gram word order penalty and recall.", "token2charspan": [[0, 5], [6, 8], [9, 17], [18, 22], [23, 26], [27, 34], [35, 37], [38, 46], [47, 53], [54, 61], [61, 62], [63, 72], [73, 80], [80, 81], [82, 84], [84, 88], [89, 93], [94, 99], [100, 107], [108, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-dev-239", "ner": [[5, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "based", "on", "the", "bilingual", "student", "assessment", "metric", ",", "but", "with", "some", "changes", "."], "sentence-detokenized": "It is based on the bilingual student assessment metric, but with some changes.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 14], [15, 18], [19, 28], [29, 36], [37, 47], [48, 54], [54, 55], [56, 59], [60, 64], [65, 69], [70, 77], [77, 78]]}
{"doc_key": "ai-dev-240", "ner": [[6, 6, "product"], [8, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "implementation", "in", "MATLAB", "/", "Octave", ":"], "sentence-detokenized": "This is an example implementation in MATLAB / Octave:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 33], [34, 36], [37, 43], [44, 45], [46, 52], [52, 53]]}
{"doc_key": "ai-dev-241", "ner": [[14, 14, "programlang"], [16, 16, "programlang"], [18, 18, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "designed", "to", "be", "used", "in", "a", "variety", "of", "computer", "languages", ",", "including", "Python", ",", "Ruby", "and", "Scheme", "."], "sentence-detokenized": "It is designed to be used in a variety of computer languages, including Python, Ruby and Scheme.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 20], [21, 25], [26, 28], [29, 30], [31, 38], [39, 41], [42, 50], [51, 60], [60, 61], [62, 71], [72, 78], [78, 79], [80, 84], [85, 88], [89, 95], [95, 96]]}
{"doc_key": "ai-dev-242", "ner": [[0, 0, "researcher"], [6, 7, "organisation"], [13, 14, "conference"], [19, 20, "academicjournal"], [25, 27, "organisation"], [33, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 7, "role", "", false, false], [0, 0, 13, 14, "role", "", false, false], [0, 0, 19, 20, "role", "", false, false], [0, 0, 25, 27, "role", "", false, false], [0, 0, 33, 37, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "has", "served", "as", "secretary", "of", "the", "AISB", ",", "chair", "and", "trustee", "of", "the", "IJCAI", ",", "associate", "editor", "of", "Artificial", "Intelligence", ",", "governor", "of", "the", "Cognitive", "Science", "Society", ",", "and", "president", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes has served as secretary of the AISB, chair and trustee of the IJCAI, associate editor of Artificial Intelligence, governor of the Cognitive Science Society, and president of the American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 32], [33, 36], [37, 41], [41, 42], [43, 48], [49, 52], [53, 60], [61, 63], [64, 67], [68, 73], [73, 74], [75, 84], [85, 91], [92, 94], [95, 105], [106, 118], [118, 119], [120, 128], [129, 131], [132, 135], [136, 145], [146, 153], [154, 161], [161, 162], [163, 166], [167, 176], [177, 179], [180, 183], [184, 192], [193, 204], [205, 208], [209, 219], [220, 232], [232, 233]]}
{"doc_key": "ai-dev-243", "ner": [[4, 14, "misc"], [16, 18, "misc"], [23, 26, "person"], [29, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 26, 4, 14, "role", "directed_by", false, false], [23, 26, 16, 18, "role", "directed_by", false, false], [23, 26, 29, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "of", "them", ",", "Now", "is", "the", "Time", "(", "to", "Put", "On", "Your", "Glasses", ")", "and", "Around", "is", "Around", ",", "were", "directed", "by", "Norman", "McLaren", "in", "1951", "for", "the", "National", "Film", "Board", "of", "Canada", "."], "sentence-detokenized": "Two of them, Now is the Time (to Put On Your Glasses) and Around is Around, were directed by Norman McLaren in 1951 for the National Film Board of Canada.", "token2charspan": [[0, 3], [4, 6], [7, 11], [11, 12], [13, 16], [17, 19], [20, 23], [24, 28], [29, 30], [30, 32], [33, 36], [37, 39], [40, 44], [45, 52], [52, 53], [54, 57], [58, 64], [65, 67], [68, 74], [74, 75], [76, 80], [81, 89], [90, 92], [93, 99], [100, 107], [108, 110], [111, 115], [116, 119], [120, 123], [124, 132], [133, 137], [138, 143], [144, 146], [147, 153], [153, 154]]}
{"doc_key": "ai-dev-244", "ner": [[4, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "goal", "of", "the", "recommender", "system", "is", "to", "predict", "the", "preferences", "of", "the", "target", "user", "."], "sentence-detokenized": "The goal of the recommender system is to predict the preferences of the target user.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 15], [16, 27], [28, 34], [35, 37], [38, 40], [41, 48], [49, 52], [53, 64], [65, 67], [68, 71], [72, 78], [79, 83], [83, 84]]}
{"doc_key": "ai-dev-245", "ner": [[0, 0, "algorithm"], [4, 4, "field"], [6, 6, "field"], [8, 9, "field"], [11, 13, "field"], [15, 18, "field"], [17, 17, "field"], [20, 20, "field"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 4, "part-of", "", true, false], [0, 0, 6, 6, "part-of", "", true, false], [0, 0, 8, 9, "part-of", "", true, false], [0, 0, 11, 13, "part-of", "", true, false], [0, 0, 15, 18, "part-of", "", true, false], [0, 0, 17, 17, "part-of", "", true, false], [0, 0, 20, 20, "part-of", "", true, false], [0, 0, 23, 24, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Convolution", "has", "applications", "in", "probability", ",", "statistics", ",", "computer", "vision", ",", "natural", "language", "processing", ",", "image", "and", "signal", "processing", ",", "engineering", ",", "and", "differential", "equations", "."], "sentence-detokenized": "Convolution has applications in probability, statistics, computer vision, natural language processing, image and signal processing, engineering, and differential equations.", "token2charspan": [[0, 11], [12, 15], [16, 28], [29, 31], [32, 43], [43, 44], [45, 55], [55, 56], [57, 65], [66, 72], [72, 73], [74, 81], [82, 90], [91, 101], [101, 102], [103, 108], [109, 112], [113, 119], [120, 130], [130, 131], [132, 143], [143, 144], [145, 148], [149, 161], [162, 171], [171, 172]]}
{"doc_key": "ai-dev-246", "ner": [[0, 0, "field"], [3, 5, "task"], [7, 8, "task"], [10, 10, "task"], [11, 11, "task"], [12, 12, "task"], [14, 15, "task"], [17, 18, "task"], [20, 21, "task"], [23, 23, "task"], [26, 27, "task"], [29, 29, "field"], [31, 31, "field"], [33, 35, "field"], [37, 37, "field"], [40, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[0, 0, 3, 5, "part-of", "", true, false], [0, 0, 7, 8, "part-of", "", true, false], [0, 0, 10, 10, "part-of", "", true, false], [0, 0, 11, 11, "part-of", "", true, false], [0, 0, 12, 12, "part-of", "", true, false], [0, 0, 14, 15, "part-of", "", true, false], [0, 0, 17, 18, "part-of", "", true, false], [0, 0, 20, 21, "part-of", "", true, false], [0, 0, 23, 23, "part-of", "", true, false], [0, 0, 26, 27, "part-of", "", true, false], [0, 0, 29, 29, "part-of", "", true, false], [0, 0, 31, 31, "part-of", "", true, false], [0, 0, 33, 35, "part-of", "", true, false], [0, 0, 37, 37, "part-of", "", true, false], [0, 0, 40, 40, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["DSP", "applications", "include", "audio", "signal", "processing", ",", "audio", "compression", ",", "digital", "image", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communications", ",", "digital", "synthesizers", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", ",", "and", "biomedicine", "."], "sentence-detokenized": "DSP applications include audio signal processing, audio compression, digital image processing, video compression, speech processing, speech recognition, digital communications, digital synthesizers, radar, sonar, financial signal processing, seismology, and biomedicine.", "token2charspan": [[0, 3], [4, 16], [17, 24], [25, 30], [31, 37], [38, 48], [48, 49], [50, 55], [56, 67], [67, 68], [69, 76], [77, 82], [83, 93], [93, 94], [95, 100], [101, 112], [112, 113], [114, 120], [121, 131], [131, 132], [133, 139], [140, 151], [151, 152], [153, 160], [161, 175], [175, 176], [177, 184], [185, 197], [197, 198], [199, 204], [204, 205], [206, 211], [211, 212], [213, 222], [223, 229], [230, 240], [240, 241], [242, 252], [252, 253], [254, 257], [258, 269], [269, 270]]}
{"doc_key": "ai-dev-247", "ner": [[13, 14, "misc"], [24, 25, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "February", "20", ",", "1912", "-", "August", "11", ",", "2011", ")", "was", "an", "American", "inventor", ",", "best", "known", "for", "creating", "the", "first", "industrial", "robot", ",", "Unimate", "."], "sentence-detokenized": "(February 20, 1912 - August 11, 2011) was an American inventor, best known for creating the first industrial robot, Unimate.", "token2charspan": [[0, 1], [1, 9], [10, 12], [12, 13], [14, 18], [19, 20], [21, 27], [28, 30], [30, 31], [32, 36], [36, 37], [38, 41], [42, 44], [45, 53], [54, 62], [62, 63], [64, 68], [69, 74], [75, 78], [79, 87], [88, 91], [92, 97], [98, 108], [109, 114], [114, 115], [116, 123], [123, 124]]}
{"doc_key": "ai-dev-248", "ner": [[2, 4, "researcher"], [6, 8, "researcher"], [10, 10, "researcher"], [20, 25, "algorithm"], [28, 30, "algorithm"], [38, 39, "task"], [32, 32, "algorithm"], [44, 45, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 20, 25, "related-to", "writes_about", true, false], [6, 8, 20, 25, "related-to", "writes_about", true, false], [10, 10, 20, 25, "related-to", "writes_about", true, false], [20, 25, 28, 30, "related-to", "", true, false], [38, 39, 32, 32, "related-to", "", true, false], [44, 45, 32, 32, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Along", "with", "David", "E.", "Rumelhart", "and", "Ronald", "J.", "Williams", ",", "Hinton", "co-authored", "a", "highly", "cited", "paper", "published", "in", "1986", "that", "popularized", "a", "back", "-", "propagation", "algorithm", "for", "training", "multilayer", "neural", "networks", ",", "AlexNet", ",", "a", "dramatic", "milestone", "in", "image", "recognition", "designed", "by", "his", "student", "Alex", "Krizhevsky", "{{", "cite", "web"], "sentence-detokenized": "Along with David E. Rumelhart and Ronald J. Williams, Hinton co-authored a highly cited paper published in 1986 that popularized a back-propagation algorithm for training multilayer neural networks, AlexNet, a dramatic milestone in image recognition designed by his student Alex Krizhevsky {{cite web", "token2charspan": [[0, 5], [6, 10], [11, 16], [17, 19], [20, 29], [30, 33], [34, 40], [41, 43], [44, 52], [52, 53], [54, 60], [61, 72], [73, 74], [75, 81], [82, 87], [88, 93], [94, 103], [104, 106], [107, 111], [112, 116], [117, 128], [129, 130], [131, 135], [135, 136], [136, 147], [148, 157], [158, 161], [162, 170], [171, 181], [182, 188], [189, 197], [197, 198], [199, 206], [206, 207], [208, 209], [210, 218], [219, 228], [229, 231], [232, 237], [238, 249], [250, 258], [259, 261], [262, 265], [266, 273], [274, 278], [279, 289], [290, 292], [292, 296], [297, 300]]}
{"doc_key": "ai-dev-249", "ner": [[9, 12, "metrics"], [14, 16, "metrics"], [18, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "predicted", "value", "is", "continuously", "distributed", ",", "the", "root", "mean", "square", "error", ",", "mean", "squared", "error", "or", "median", "absolute", "deviation", "can", "be", "used", "to", "summarise", "the", "errors", "."], "sentence-detokenized": "If the predicted value is continuously distributed, the root mean square error, mean squared error or median absolute deviation can be used to summarise the errors.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 22], [23, 25], [26, 38], [39, 50], [50, 51], [52, 55], [56, 60], [61, 65], [66, 72], [73, 78], [78, 79], [80, 84], [85, 92], [93, 98], [99, 101], [102, 108], [109, 117], [118, 127], [128, 131], [132, 134], [135, 139], [140, 142], [143, 152], [153, 156], [157, 163], [163, 164]]}
{"doc_key": "ai-dev-250", "ner": [[0, 2, "algorithm"], [9, 12, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 12, "part-of", "", true, false], [0, 2, 13, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Conceptual", "clustering", "evolved", "primarily", "in", "the", "1980s", "as", "a", "machine", "learning", "paradigm", "for", "unsupervised", "learning", "."], "sentence-detokenized": "Conceptual clustering evolved primarily in the 1980s as a machine learning paradigm for unsupervised learning.", "token2charspan": [[0, 10], [11, 21], [22, 29], [30, 39], [40, 42], [43, 46], [47, 52], [53, 55], [56, 57], [58, 65], [66, 74], [75, 83], [84, 87], [88, 100], [101, 109], [109, 110]]}
{"doc_key": "ai-dev-251", "ner": [[8, 10, "product"], [31, 38, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "named", "entities", "are", "not", "recognized", "by", "the", "machine", "translator", ",", "they", "may", "be", "mistranslated", "as", "common", "nouns", ",", "which", "would", "most", "likely", "not", "affect", "the", "evaluation", "of", "the", "translation", "by", "the", "bilingual", "evaluation", "doublet", ",", "but", "would", "change", "the", "human", "readability", "of", "the", "text", "."], "sentence-detokenized": "If the named entities are not recognized by the machine translator, they may be mistranslated as common nouns, which would most likely not affect the evaluation of the translation by the bilingual evaluation doublet, but would change the human readability of the text.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 21], [22, 25], [26, 29], [30, 40], [41, 43], [44, 47], [48, 55], [56, 66], [66, 67], [68, 72], [73, 76], [77, 79], [80, 93], [94, 96], [97, 103], [104, 109], [109, 110], [111, 116], [117, 122], [123, 127], [128, 134], [135, 138], [139, 145], [146, 149], [150, 160], [161, 163], [164, 167], [168, 179], [180, 182], [183, 186], [187, 196], [197, 207], [208, 215], [215, 216], [217, 220], [221, 226], [227, 233], [234, 237], [238, 243], [244, 255], [256, 258], [259, 262], [263, 267], [267, 268]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 22, "location"], [24, 24, "country"], [39, 42, "researcher"], [46, 47, "researcher"], [50, 51, "university"], [54, 55, "researcher"], [57, 58, "researcher"], [61, 62, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 22, "physical", "", false, false], [20, 22, 24, 24, "physical", "", false, false], [46, 47, 50, 51, "physical", "", false, false], [46, 47, 50, 51, "role", "", false, false], [54, 55, 50, 51, "physical", "", false, false], [54, 55, 50, 51, "role", "", false, false], [57, 58, 50, 51, "physical", "", false, false], [57, 58, 50, 51, "role", "", false, false], [61, 62, 50, 51, "physical", "", false, false], [61, 62, 50, 51, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng", "-", "S\u00e4by", ",", "Sweden", ",", "pages", "1-", "3", "This", "model", ",", "influenced", "in", "part", "by", "the", "work", "of", "Sydney", "Lamb", ",", "was", "used", "extensively", "by", "Schank", "'s", "students", "at", "Yale", "University", ",", "including", "Robert", "Wilensky", ",", "Wendy", "Lehnert", ",", "and", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, pages 1-3 This model, influenced in part by the work of Sydney Lamb, was used extensively by Schank's students at Yale University, including Robert Wilensky, Wendy Lehnert, and Janet Kolodner.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 130], [130, 131], [131, 135], [135, 136], [137, 143], [143, 144], [145, 150], [151, 153], [153, 154], [155, 159], [160, 165], [165, 166], [167, 177], [178, 180], [181, 185], [186, 188], [189, 192], [193, 197], [198, 200], [201, 207], [208, 212], [212, 213], [214, 217], [218, 222], [223, 234], [235, 237], [238, 244], [244, 246], [247, 255], [256, 258], [259, 263], [264, 274], [274, 275], [276, 285], [286, 292], [293, 301], [301, 302], [303, 308], [309, 316], [316, 317], [318, 321], [322, 327], [328, 336], [336, 337]]}
{"doc_key": "ai-dev-253", "ner": [[2, 4, "algorithm"], [6, 6, "algorithm"], [13, 13, "algorithm"], [15, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 2, 4, "named", "", false, false], [13, 13, 2, 4, "named", "", false, false], [15, 18, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "improved", "maximum", "likelihood", "method", "(", "IMLM", ")", "is", "a", "combination", "of", "two", "MLM", "(", "maximum", "likelihood", ")", "estimators", "."], "sentence-detokenized": "The improved maximum likelihood method (IMLM) is a combination of two MLM (maximum likelihood) estimators.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 38], [39, 40], [40, 44], [44, 45], [46, 48], [49, 50], [51, 62], [63, 65], [66, 69], [70, 73], [74, 75], [75, 82], [83, 93], [93, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-254", "ner": [[22, 23, "metrics"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[26, 27, 22, 23, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "methods", "may", "also", "analyse", "the", "output", "of", "a", "program", "and", "its", "utility", ",", "and", "therefore", "may", "include", "an", "analysis", "of", "its", "confusion", "matrix", "(", "or", "confusion", "table", ")", "."], "sentence-detokenized": "These methods may also analyse the output of a program and its utility, and therefore may include an analysis of its confusion matrix (or confusion table).", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 22], [23, 30], [31, 34], [35, 41], [42, 44], [45, 46], [47, 54], [55, 58], [59, 62], [63, 70], [70, 71], [72, 75], [76, 85], [86, 89], [90, 97], [98, 100], [101, 109], [110, 112], [113, 116], [117, 126], [127, 133], [134, 135], [135, 137], [138, 147], [148, 153], [153, 154], [154, 155]]}
{"doc_key": "ai-dev-255", "ner": [[0, 1, "product"], [5, 6, "researcher"], [8, 9, "researcher"], [11, 13, "researcher"], [18, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "origin", "", false, false], [0, 1, 8, 9, "origin", "", false, false], [0, 1, 11, 13, "origin", "", false, false], [0, 1, 18, 24, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "was", "first", "published", "by", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", "and", "Luc", "Van", "Gool", "and", "presented", "at", "the", "European", "Conference", "on", "Computer", "Vision", "in", "2006", "."], "sentence-detokenized": "SURF was first published by Herbert Bay, Tinne Tuytelaars and Luc Van Gool and presented at the European Conference on Computer Vision in 2006.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 39], [39, 40], [41, 46], [47, 57], [58, 61], [62, 65], [66, 69], [70, 74], [75, 78], [79, 88], [89, 91], [92, 95], [96, 104], [105, 115], [116, 118], [119, 127], [128, 134], [135, 137], [138, 142], [142, 143]]}
{"doc_key": "ai-dev-256", "ner": [[0, 0, "task"], [7, 8, "field"], [10, 11, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 8, "part-of", "", false, false], [0, 0, 10, 11, "part-of", "", false, false], [0, 0, 13, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "is", "an", "area", "of", "research", "in", "pattern", "recognition", ",", "artificial", "intelligence", "and", "computer", "vision", "."], "sentence-detokenized": "OCR is an area of research in pattern recognition, artificial intelligence and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 14], [15, 17], [18, 26], [27, 29], [30, 37], [38, 49], [49, 50], [51, 61], [62, 74], [75, 78], [79, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-dev-257", "ner": [[5, 7, "metrics"], [10, 12, "algorithm"], [14, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 10, 12, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Continuing", "with", "the", "example", "using", "maximum", "likelihood", "estimation", ",", "the", "probability", "density", "function", "(", "pdf", ")", "of", "the", "noise", "for", "a", "single", "mathwn", "/", "math", "sample", "is", "as", "follows"], "sentence-detokenized": "Continuing with the example using maximum likelihood estimation, the probability density function (pdf) of the noise for a single mathwn/math sample is as follows", "token2charspan": [[0, 10], [11, 15], [16, 19], [20, 27], [28, 33], [34, 41], [42, 52], [53, 63], [63, 64], [65, 68], [69, 80], [81, 88], [89, 97], [98, 99], [99, 102], [102, 103], [104, 106], [107, 110], [111, 116], [117, 120], [121, 122], [123, 129], [130, 136], [136, 137], [137, 141], [142, 148], [149, 151], [152, 154], [155, 162]]}
{"doc_key": "ai-dev-258", "ner": [[2, 3, "field"], [5, 6, "task"], [8, 9, "task"], [11, 12, "task"], [14, 15, "task"], [17, 19, "task"], [21, 21, "task"], [23, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 33, "task"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 6, 2, 3, "part-of", "", false, false], [8, 9, 2, 3, "part-of", "", false, false], [11, 12, 2, 3, "part-of", "", false, false], [14, 15, 2, 3, "part-of", "", false, false], [17, 19, 2, 3, "part-of", "", false, false], [21, 21, 2, 3, "part-of", "", false, false], [23, 23, 2, 3, "part-of", "", false, false], [25, 26, 2, 3, "part-of", "", false, false], [28, 29, 2, 3, "part-of", "", false, false], [31, 33, 2, 3, "part-of", "", false, false], [36, 37, 2, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Sub-areas", "of", "computer", "vision", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "3D", "pose", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "servoing", ",", "3D", "scene", "modeling", ",", "and", "image", "restoration", "."], "sentence-detokenized": "Sub-areas of computer vision include scene reconstruction, event detection, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual servoing, 3D scene modeling, and image restoration.", "token2charspan": [[0, 9], [10, 12], [13, 21], [22, 28], [29, 36], [37, 42], [43, 57], [57, 58], [59, 64], [65, 74], [74, 75], [76, 81], [82, 90], [90, 91], [92, 98], [99, 110], [110, 111], [112, 114], [115, 119], [120, 130], [130, 131], [132, 140], [140, 141], [142, 150], [150, 151], [152, 158], [159, 169], [169, 170], [171, 177], [178, 186], [186, 187], [188, 190], [191, 196], [197, 205], [205, 206], [207, 210], [211, 216], [217, 228], [228, 229]]}
{"doc_key": "ai-dev-259", "ner": [[11, 15, "conference"], [3, 4, "researcher"], [7, 8, "misc"], [18, 19, "conference"], [23, 23, "researcher"], [25, 25, "researcher"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 15, 18, 19, "named", "", false, false], [3, 4, 7, 8, "win-defeat", "", false, false], [3, 4, 27, 28, "related-to", "writes_about", true, false], [7, 8, 11, 15, "temporal", "", false, false], [23, 23, 7, 8, "win-defeat", "", false, true], [23, 23, 27, 28, "related-to", "writes_about", true, false], [25, 25, 7, 8, "win-defeat", "", false, true], [25, 25, 27, 28, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["In", "2013", ",", "Terzopoulos", "was", "awarded", "the", "Helmholtz", "Prize", "at", "the", "International", "Conference", "on", "Computer", "Vision", "for", "his", "1987", "ICCV", "paper", "co-authored", "with", "Kass", "and", "Witkin", "on", "active", "contour", "models", "."], "sentence-detokenized": "In 2013, Terzopoulos was awarded the Helmholtz Prize at the International Conference on Computer Vision for his 1987 ICCV paper co-authored with Kass and Witkin on active contour models.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 24], [25, 32], [33, 36], [37, 46], [47, 52], [53, 55], [56, 59], [60, 73], [74, 84], [85, 87], [88, 96], [97, 103], [104, 107], [108, 111], [112, 116], [117, 121], [122, 127], [128, 139], [140, 144], [145, 149], [150, 153], [154, 160], [161, 163], [164, 170], [171, 178], [179, 185], [185, 186]]}
{"doc_key": "ai-dev-260", "ner": [[16, 17, "task"], [19, 23, "algorithm"], [26, 27, "algorithm"], [29, 29, "algorithm"], [32, 33, "algorithm"], [36, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[16, 17, 19, 23, "usage", "", true, false], [16, 17, 26, 27, "usage", "", true, false], [16, 17, 29, 29, "usage", "", true, false], [16, 17, 32, 33, "usage", "", true, false], [16, 17, 36, 36, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["If", "the", "regular", "function", "There", "are", "many", "algorithms", "for", "solving", "these", "problems", ";", "popular", "algorithms", "for", "linear", "classification", "include", "stochastic", "gradient", "descent", "(", "SGD", ")", ",", "gradient", "descent", "(", "L-BFGS", ")", ",", "coordinate", "descent", ",", "and", "Newton", "methods", "."], "sentence-detokenized": "If the regular function There are many algorithms for solving these problems; popular algorithms for linear classification include stochastic gradient descent (SGD), gradient descent (L-BFGS), coordinate descent, and Newton methods.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 23], [24, 29], [30, 33], [34, 38], [39, 49], [50, 53], [54, 61], [62, 67], [68, 76], [76, 77], [78, 85], [86, 96], [97, 100], [101, 107], [108, 122], [123, 130], [131, 141], [142, 150], [151, 158], [159, 160], [160, 163], [163, 164], [164, 165], [166, 174], [175, 182], [183, 184], [184, 190], [190, 191], [191, 192], [193, 203], [204, 211], [211, 212], [213, 216], [217, 223], [224, 231], [231, 232]]}
{"doc_key": "ai-dev-261", "ner": [[0, 4, "algorithm"], [6, 6, "algorithm"], [12, 13, "researcher"], [15, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 12, 13, "origin", "", false, false], [6, 6, 0, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "Short", "-", "Term", "Memory", "(", "LSTM", ")", "networks", "were", "invented", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "and", "have", "achieved", "accuracy", "records", "in", "many", "application", "areas", "."], "sentence-detokenized": "Long Short-Term Memory (LSTM) networks were invented by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997 and have achieved accuracy records in many application areas.", "token2charspan": [[0, 4], [5, 10], [10, 11], [11, 15], [16, 22], [23, 24], [24, 28], [28, 29], [30, 38], [39, 43], [44, 52], [53, 55], [56, 60], [61, 71], [72, 75], [76, 82], [83, 94], [95, 97], [98, 102], [103, 106], [107, 111], [112, 120], [121, 129], [130, 137], [138, 140], [141, 145], [146, 157], [158, 163], [163, 164]]}
{"doc_key": "ai-dev-262", "ner": [[0, 2, "product"], [5, 7, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 5, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "TN", "was", "developed", "at", "Massachusetts", "General", "Hospital", "and", "has", "been", "tested", "in", "several", "scenarios", ",", "including", "identifying", "smoking", "status", ",", "family", "history", "of", "coronary", "artery", "disease", ",", "and", "identifying", "patients", "with", "sleep", "disorders", ","], "sentence-detokenized": "The TN was developed at Massachusetts General Hospital and has been tested in several scenarios, including identifying smoking status, family history of coronary artery disease, and identifying patients with sleep disorders,", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 20], [21, 23], [24, 37], [38, 45], [46, 54], [55, 58], [59, 62], [63, 67], [68, 74], [75, 77], [78, 85], [86, 95], [95, 96], [97, 106], [107, 118], [119, 126], [127, 133], [133, 134], [135, 141], [142, 149], [150, 152], [153, 161], [162, 168], [169, 176], [176, 177], [178, 181], [182, 193], [194, 202], [203, 207], [208, 213], [214, 223], [223, 224]]}
{"doc_key": "ai-dev-263", "ner": [[3, 3, "researcher"], [8, 11, "product"], [15, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 11, "role", "sells", false, false], [8, 11, 15, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 86], [87, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-dev-264", "ner": [[0, 2, "conference"], [13, 14, "location"], [16, 16, "location"], [18, 20, "country"], [28, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 13, 14, "physical", "", false, false], [13, 14, 16, 16, "physical", "", false, false], [16, 16, 18, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Campus", "Party", "Europe", "took", "place", "from", "14", "-", "18", "April", "2010", "at", "the", "Caja", "M\u00e1gica", "in", "Madrid", ",", "Spain", ",", "with", "800", "participants", "from", "27", "EU", "Member", "States", "."], "sentence-detokenized": "Campus Party Europe took place from 14-18 April 2010 at the Caja M\u00e1gica in Madrid, Spain, with 800 participants from 27 EU Member States.", "token2charspan": [[0, 6], [7, 12], [13, 19], [20, 24], [25, 30], [31, 35], [36, 38], [38, 39], [39, 41], [42, 47], [48, 52], [53, 55], [56, 59], [60, 64], [65, 71], [72, 74], [75, 81], [81, 82], [83, 88], [88, 89], [90, 94], [95, 98], [99, 111], [112, 116], [117, 119], [120, 122], [123, 129], [130, 136], [136, 137]]}
{"doc_key": "ai-dev-265", "ner": [[9, 10, "organisation"], [11, 14, "organisation"], [16, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 20, 9, 10, "origin", "", false, false], [16, 20, 11, 14, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2016", ",", "a", "collaboration", "was", "announced", "between", "DeepMind", "and", "Moorfields", "Eye", "Hospital", "to", "develop", "artificial", "intelligence", "applications", "for", "healthcare", "."], "sentence-detokenized": "In July 2016, a collaboration was announced between DeepMind and Moorfields Eye Hospital to develop artificial intelligence applications for healthcare.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 15], [16, 29], [30, 33], [34, 43], [44, 51], [52, 60], [61, 64], [65, 75], [76, 79], [80, 88], [89, 91], [92, 99], [100, 110], [111, 123], [124, 136], [137, 140], [141, 151], [151, 152]]}
{"doc_key": "ai-dev-266", "ner": [[7, 9, "misc"], [14, 17, "university"], [19, 19, "university"], [21, 22, "university"], [24, 25, "university"], [27, 27, "university"], [29, 29, "university"], [31, 34, "university"], [36, 37, "university"], [39, 40, "university"], [42, 42, "university"], [45, 47, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[7, 9, 14, 17, "physical", "", false, false], [7, 9, 19, 19, "physical", "", false, false], [7, 9, 21, 22, "physical", "", false, false], [7, 9, 24, 25, "physical", "", false, false], [7, 9, 27, 27, "physical", "", false, false], [7, 9, 29, 29, "physical", "", false, false], [7, 9, 31, 34, "physical", "", false, false], [7, 9, 36, 37, "physical", "", false, false], [7, 9, 39, 40, "physical", "", false, false], [7, 9, 42, 42, "physical", "", false, false], [7, 9, 45, 47, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["In", "the", "end", ",", "they", "awarded", "eleven", "PR2", "prizes", "to", "different", "institutions", ",", "including", "the", "University", "of", "Freiburg", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "Technical", "University", "of", "Munich", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", "and", "the", "University", "of", "Tokyo", "."], "sentence-detokenized": "In the end, they awarded eleven PR2 prizes to different institutions, including the University of Freiburg, Bosch, Georgia Tech, KU Leuven, MIT, Stanford, Technical University of Munich, UC Berkeley, U Penn, USC and the University of Tokyo.", "token2charspan": [[0, 2], [3, 6], [7, 10], [10, 11], [12, 16], [17, 24], [25, 31], [32, 35], [36, 42], [43, 45], [46, 55], [56, 68], [68, 69], [70, 79], [80, 83], [84, 94], [95, 97], [98, 106], [106, 107], [108, 113], [113, 114], [115, 122], [123, 127], [127, 128], [129, 131], [132, 138], [138, 139], [140, 143], [143, 144], [145, 153], [153, 154], [155, 164], [165, 175], [176, 178], [179, 185], [185, 186], [187, 189], [190, 198], [198, 199], [200, 201], [202, 206], [206, 207], [208, 211], [212, 215], [216, 219], [220, 230], [231, 233], [234, 239], [239, 240]]}
{"doc_key": "ai-dev-267", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [7, 7, "metrics"], [9, 9, "metrics"], [19, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 19, 20, "part-of", "", false, false], [5, 5, 19, 20, "part-of", "", false, false], [7, 7, 19, 20, "part-of", "", false, false], [9, 9, 19, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "numbers", "of", "TP", ",", "TN", ",", "FP", "and", "FN", "are", "usually", "stored", "in", "a", "table", "known", "as", "a", "substitution", "matrix", "."], "sentence-detokenized": "The numbers of TP, TN, FP and FN are usually stored in a table known as a substitution matrix.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 17], [17, 18], [19, 21], [21, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 44], [45, 51], [52, 54], [55, 56], [57, 62], [63, 68], [69, 71], [72, 73], [74, 86], [87, 93], [93, 94]]}
{"doc_key": "ai-dev-268", "ner": [[0, 1, "metrics"], [3, 4, "metrics"], [6, 7, "metrics"], [9, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Information", "gain", ",", "cross", "entropy", ",", "mutual", "information", "and", "odds", "ratio", "are", "usually", "used", "as", "a", "set", "of", "attributes", "."], "sentence-detokenized": "Information gain, cross entropy, mutual information and odds ratio are usually used as a set of attributes.", "token2charspan": [[0, 11], [12, 16], [16, 17], [18, 23], [24, 31], [31, 32], [33, 39], [40, 51], [52, 55], [56, 60], [61, 66], [67, 70], [71, 78], [79, 83], [84, 86], [87, 88], [89, 92], [93, 95], [96, 106], [106, 107]]}
{"doc_key": "ai-dev-269", "ner": [[12, 13, "task"], [15, 16, "task"], [18, 18, "task"], [20, 20, "task"], [23, 26, "task"], [28, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[28, 28, 23, 26, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "successfully", "applied", "to", "a", "variety", "of", "problems", ",", "including", "robot", "control", ",", "elevator", "planning", ",", "telecommunications", ",", "checkers", ",", "and", "the", "game", "of", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "It has been successfully applied to a variety of problems, including robot control, elevator planning, telecommunications, checkers, and the game of Go (AlphaGo).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 32], [33, 35], [36, 37], [38, 45], [46, 48], [49, 57], [57, 58], [59, 68], [69, 74], [75, 82], [82, 83], [84, 92], [93, 101], [101, 102], [103, 121], [121, 122], [123, 131], [131, 132], [133, 136], [137, 140], [141, 145], [146, 148], [149, 151], [152, 153], [153, 160], [160, 161], [161, 162]]}
{"doc_key": "ai-dev-270", "ner": [[11, 14, "misc"], [19, 23, "university"], [25, 25, "location"], [27, 30, "location"], [31, 33, "location"], [39, 41, "location"], [43, 43, "location"], [45, 45, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 14, 19, 23, "physical", "", false, false], [19, 23, 25, 25, "physical", "", false, false], [25, 25, 27, 30, "physical", "", false, false], [31, 33, 39, 41, "physical", "", false, false], [39, 41, 43, 43, "physical", "", false, false], [43, 43, 45, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "the", "first", "year", "of", "Mission", "8", ",", "the", "U.S.", "competition", "was", "held", "on", "the", "campus", "of", "the", "Georgia", "Institute", "of", "Technology", "in", "Atlanta", ",", "Georgia", ",", "and", "the", "Asia", "-", "Pacific", "competition", "was", "held", "at", "the", "Beihang", "University", "Gymnasium", "in", "Beijing", ",", "China", "."], "sentence-detokenized": "In 2018, the first year of Mission 8, the U.S. competition was held on the campus of the Georgia Institute of Technology in Atlanta, Georgia, and the Asia-Pacific competition was held at the Beihang University Gymnasium in Beijing, China.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 18], [19, 23], [24, 26], [27, 34], [35, 36], [36, 37], [38, 41], [42, 46], [47, 58], [59, 62], [63, 67], [68, 70], [71, 74], [75, 81], [82, 84], [85, 88], [89, 96], [97, 106], [107, 109], [110, 120], [121, 123], [124, 131], [131, 132], [133, 140], [140, 141], [142, 145], [146, 149], [150, 154], [154, 155], [155, 162], [163, 174], [175, 178], [179, 183], [184, 186], [187, 190], [191, 198], [199, 209], [210, 219], [220, 222], [223, 230], [230, 231], [232, 237], [237, 238]]}
{"doc_key": "ai-dev-271", "ner": [[0, 1, "field"], [6, 7, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "origin", "", false, false], [0, 1, 6, 7, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "is", "closely", "related", "to", "pattern", "recognition", "and", "is", "based", "on", "artificial", "intelligence", "."], "sentence-detokenized": "Machine learning is closely related to pattern recognition and is based on artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 35], [36, 38], [39, 46], [47, 58], [59, 62], [63, 65], [66, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-dev-272", "ner": [[2, 2, "programlang"], [14, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Includes", "3", "Java", "games", "that", "are", "controlled", "by", "remote", "control", "and", "displayed", "on", "the", "LCD", "screen", "."], "sentence-detokenized": "Includes 3 Java games that are controlled by remote control and displayed on the LCD screen.", "token2charspan": [[0, 8], [9, 10], [11, 15], [16, 21], [22, 26], [27, 30], [31, 41], [42, 44], [45, 51], [52, 59], [60, 63], [64, 73], [74, 76], [77, 80], [81, 84], [85, 91], [91, 92]]}
{"doc_key": "ai-dev-273", "ner": [[7, 15, "task"], [16, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 18, 7, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "commercially", "successful", "but", "specialized", "technique", "for", "estimating", "articular", "body", "position", "based", "on", "computer", "vision", "is", "optical", "motion", "sensing", "."], "sentence-detokenized": "A commercially successful but specialized technique for estimating articular body position based on computer vision is optical motion sensing.", "token2charspan": [[0, 1], [2, 14], [15, 25], [26, 29], [30, 41], [42, 51], [52, 55], [56, 66], [67, 76], [77, 81], [82, 90], [91, 96], [97, 99], [100, 108], [109, 115], [116, 118], [119, 126], [127, 133], [134, 141], [141, 142]]}
{"doc_key": "ai-dev-274", "ner": [[0, 0, "organisation"], [8, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 8, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["SMC", "is", "very", "similar", "to", "the", "more", "popular", "Jaccard", "index", "."], "sentence-detokenized": "SMC is very similar to the more popular Jaccard index.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 19], [20, 22], [23, 26], [27, 31], [32, 39], [40, 47], [48, 53], [53, 54]]}
{"doc_key": "ai-dev-275", "ner": [[0, 0, "product"], [2, 6, "product"], [8, 11, "product"], [20, 21, "researcher"], [27, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 11, "named", "", false, false], [0, 0, 20, 21, "artifact", "", false, false], [0, 0, 27, 27, "artifact", "", false, false], [2, 6, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", "or", "Programmable", "Universal", "Manipulation", "Arm", ")", "is", "an", "industrial", "robotic", "arm", "developed", "by", "Victor", "Scheinman", "at", "the", "pioneering", "robotics", "company", "Unimation", "."], "sentence-detokenized": "PUMA (Programmable Universal Machine for Assembly or Programmable Universal Manipulation Arm) is an industrial robotic arm developed by Victor Scheinman at the pioneering robotics company Unimation.", "token2charspan": [[0, 4], [5, 6], [6, 18], [19, 28], [29, 36], [37, 40], [41, 49], [50, 52], [53, 65], [66, 75], [76, 88], [89, 92], [92, 93], [94, 96], [97, 99], [100, 110], [111, 118], [119, 122], [123, 132], [133, 135], [136, 142], [143, 152], [153, 155], [156, 159], [160, 170], [171, 179], [180, 187], [188, 197], [197, 198]]}
{"doc_key": "ai-dev-276", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "written", "in", "Python", "."], "sentence-detokenized": "It is written in Python.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 23], [23, 24]]}
{"doc_key": "ai-dev-277", "ner": [[0, 1, "misc"], [2, 2, "misc"], [12, 12, "field"], [14, 15, "field"], [17, 17, "field"], [23, 24, "field"], [27, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7], "relations": [[0, 1, 2, 2, "related-to", "metric_for", true, false], [0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 15, "part-of", "", false, false], [0, 1, 17, 17, "part-of", "", false, false], [0, 1, 23, 24, "part-of", "", false, false], [0, 1, 27, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6], "sentence": ["Bandwidth", "in", "hertz", "is", "a", "central", "concept", "in", "many", "fields", ",", "including", "electronics", ",", "information", "theory", ",", "digital", "communications", ",", "radio", "communications", ",", "signal", "processing", ",", "and", "spectroscopy", ",", "and", "is", "one", "of", "the", "determinants", "of", "the", "capacity", "of", "a", "given", "communications", "channel", "."], "sentence-detokenized": "Bandwidth in hertz is a central concept in many fields, including electronics, information theory, digital communications, radio communications, signal processing, and spectroscopy, and is one of the determinants of the capacity of a given communications channel.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 21], [22, 23], [24, 31], [32, 39], [40, 42], [43, 47], [48, 54], [54, 55], [56, 65], [66, 77], [77, 78], [79, 90], [91, 97], [97, 98], [99, 106], [107, 121], [121, 122], [123, 128], [129, 143], [143, 144], [145, 151], [152, 162], [162, 163], [164, 167], [168, 180], [180, 181], [182, 185], [186, 188], [189, 192], [193, 195], [196, 199], [200, 212], [213, 215], [216, 219], [220, 228], [229, 231], [232, 233], [234, 239], [240, 254], [255, 262], [262, 263]]}
{"doc_key": "ai-dev-278", "ner": [[8, 8, "algorithm"], [10, 10, "algorithm"], [17, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 17, 23, "part-of", "", false, false], [10, 10, 17, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "convex", "loss", "is", "used", "(", "as", "in", "AdaBoost", ",", "LogitBoost", ",", "and", "all", "members", "of", "the", "AnyBoost", "family", "of", "algorithms", ")", ",", "then", "the", "higher", "-", "margin", "example", "receives", "less", "(", "or", "equal", ")", "weight", "than", "the", "lower", "-", "margin", "example", "."], "sentence-detokenized": "If convex loss is used (as in AdaBoost, LogitBoost, and all members of the AnyBoost family of algorithms), then the higher-margin example receives less (or equal) weight than the lower-margin example.", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 17], [18, 22], [23, 24], [24, 26], [27, 29], [30, 38], [38, 39], [40, 50], [50, 51], [52, 55], [56, 59], [60, 67], [68, 70], [71, 74], [75, 83], [84, 90], [91, 93], [94, 104], [104, 105], [105, 106], [107, 111], [112, 115], [116, 122], [122, 123], [123, 129], [130, 137], [138, 146], [147, 151], [152, 153], [153, 155], [156, 161], [161, 162], [163, 169], [170, 174], [175, 178], [179, 184], [184, 185], [185, 191], [192, 199], [199, 200]]}
{"doc_key": "ai-dev-279", "ner": [[0, 2, "researcher"], [5, 6, "researcher"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sepp", "Hochreiter", "'s", "1991", "thesis", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Sepp Hochreiter's 1991 thesis Sepp Hochreiter.", "token2charspan": [[0, 4], [5, 15], [15, 17], [18, 22], [23, 29], [30, 34], [35, 45], [45, 46]]}
{"doc_key": "ai-dev-280", "ner": [[4, 5, "algorithm"], [7, 7, "algorithm"], [10, 12, "algorithm"], [14, 14, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [27, 28, "algorithm"], [31, 32, "algorithm"], [34, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 7, 4, 5, "named", "", false, false], [14, 14, 10, 12, "named", "", false, false], [17, 19, 27, 28, "related-to", "", true, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Typical", "discriminant", "models", "include", "logistic", "regression", "(", "LR", ")", ",", "support", "vector", "machines", "(", "SVM", ")", ",", "conditional", "random", "fields", "(", "CRF", ")", "(", "specified", "over", "an", "undirected", "graph", ")", ",", "decision", "trees", ",", "neural", "networks", ",", "and", "many", "others", "."], "sentence-detokenized": "Typical discriminant models include logistic regression (LR), support vector machines (SVM), conditional random fields (CRF) (specified over an undirected graph), decision trees, neural networks, and many others.", "token2charspan": [[0, 7], [8, 20], [21, 27], [28, 35], [36, 44], [45, 55], [56, 57], [57, 59], [59, 60], [60, 61], [62, 69], [70, 76], [77, 85], [86, 87], [87, 90], [90, 91], [91, 92], [93, 104], [105, 111], [112, 118], [119, 120], [120, 123], [123, 124], [125, 126], [126, 135], [136, 140], [141, 143], [144, 154], [155, 160], [160, 161], [161, 162], [163, 171], [172, 177], [177, 178], [179, 185], [186, 194], [194, 195], [196, 199], [200, 204], [205, 211], [211, 212]]}
{"doc_key": "ai-dev-281", "ner": [[12, 15, "metrics"], [35, 37, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "then", "also", "possible", "to", "use", "these", "probabilities", "to", "evaluate", "the", "root", "mean", "square", "error", "(", "or", "other", "similar", "measure", ")", "between", "the", "probabilities", "and", "the", "true", "values", "and", "then", "combine", "it", "with", "the", "confusion", "matrix", "to", "produce", "a", "very", "efficient", "fitness", "function", "for", "logistic", "regression", "."], "sentence-detokenized": "It is then also possible to use these probabilities to evaluate the root mean square error (or other similar measure) between the probabilities and the true values and then combine it with the confusion matrix to produce a very efficient fitness function for logistic regression.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 15], [16, 24], [25, 27], [28, 31], [32, 37], [38, 51], [52, 54], [55, 63], [64, 67], [68, 72], [73, 77], [78, 84], [85, 90], [91, 92], [92, 94], [95, 100], [101, 108], [109, 116], [116, 117], [118, 125], [126, 129], [130, 143], [144, 147], [148, 151], [152, 156], [157, 163], [164, 167], [168, 172], [173, 180], [181, 183], [184, 188], [189, 192], [193, 202], [203, 209], [210, 212], [213, 220], [221, 222], [223, 227], [228, 237], [238, 245], [246, 254], [255, 258], [259, 267], [268, 278], [278, 279]]}
{"doc_key": "ai-dev-282", "ner": [[0, 4, "product"], [6, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 6, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "first", "appeared", "in", "2005", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "."], "sentence-detokenized": "VoiceOver first appeared in 2005 in Mac OS X Tiger (10.4).", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 27], [28, 32], [33, 35], [36, 39], [40, 42], [43, 44], [45, 50], [51, 52], [52, 56], [56, 57], [57, 58]]}
{"doc_key": "ai-dev-283", "ner": [[13, 16, "algorithm"], [19, 21, "misc"], [26, 27, "metrics"], [30, 36, "algorithm"], [62, 66, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 16, 19, 21, "related-to", "applied_to", false, false], [26, 27, 19, 21, "type-of", "", false, false], [26, 27, 30, 36, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "practice", ",", "machine", "learning", "algorithms", "deal", "with", "this", "either", "by", "using", "a", "convex", "approximation", "of", "the", "0", "-", "1", "loss", "function", "(", "such", "as", "the", "joint", "loss", "for", "the", "Support", "vector", "machine", ")", ",", "which", "is", "easier", "to", "optimize", ",", "or", "by", "introducing", "assumptions", "on", "the", "mathP", "(", "x", ",", "y", ")", "/", "math", "distribution", "(", "and", "thus", "ceasing", "to", "be", "agnostic", "learning", "algorithms", ",", "for", "which", "the", "above", "result", "holds", ")", "."], "sentence-detokenized": "In practice, machine learning algorithms deal with this either by using a convex approximation of the 0-1 loss function (such as the joint loss for the Support vector machine), which is easier to optimize, or by introducing assumptions on the mathP (x, y)/math distribution (and thus ceasing to be agnostic learning algorithms, for which the above result holds).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 29], [30, 40], [41, 45], [46, 50], [51, 55], [56, 62], [63, 65], [66, 71], [72, 73], [74, 80], [81, 94], [95, 97], [98, 101], [102, 103], [103, 104], [104, 105], [106, 110], [111, 119], [120, 121], [121, 125], [126, 128], [129, 132], [133, 138], [139, 143], [144, 147], [148, 151], [152, 159], [160, 166], [167, 174], [174, 175], [175, 176], [177, 182], [183, 185], [186, 192], [193, 195], [196, 204], [204, 205], [206, 208], [209, 211], [212, 223], [224, 235], [236, 238], [239, 242], [243, 248], [249, 250], [250, 251], [251, 252], [253, 254], [254, 255], [255, 256], [256, 260], [261, 273], [274, 275], [275, 278], [279, 283], [284, 291], [292, 294], [295, 297], [298, 306], [307, 315], [316, 326], [326, 327], [328, 331], [332, 337], [338, 341], [342, 347], [348, 354], [355, 360], [360, 361], [361, 362]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [11, 13, "field"], [18, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "usage", "", false, false], [0, 0, 18, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Westworld", "(", "1973", ")", "was", "the", "first", "feature", "film", "to", "use", "digital", "imaging", "to", "simulate", "the", "viewpoint", "of", "an", "android", "."], "sentence-detokenized": "Westworld (1973) was the first feature film to use digital imaging to simulate the viewpoint of an android.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 20], [21, 24], [25, 30], [31, 38], [39, 43], [44, 46], [47, 50], [51, 58], [59, 66], [67, 69], [70, 78], [79, 82], [83, 92], [93, 95], [96, 98], [99, 106], [106, 107]]}
{"doc_key": "ai-dev-285", "ner": [[8, 9, "task"], [11, 12, "task"], [14, 14, "task"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nowadays", ",", "it", "is", "also", "commonly", "used", "in", "speech", "recognition", ",", "speech", "synthesis", ",", "diarization", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "Nowadays, it is also commonly used in speech recognition, speech synthesis, diarization, Xavier Anguera et al.", "token2charspan": [[0, 8], [8, 9], [10, 12], [13, 15], [16, 20], [21, 29], [30, 34], [35, 37], [38, 44], [45, 56], [56, 57], [58, 64], [65, 74], [74, 75], [76, 87], [87, 88], [89, 95], [96, 103], [104, 106], [107, 109], [109, 110]]}
{"doc_key": "ai-dev-286", "ner": [[9, 17, "algorithm"], [20, 21, "algorithm"], [24, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 21, 9, 17, "type-of", "", false, false], [24, 26, 9, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "math", "/", "sigma", "/", "math", "here", "is", "an", "activation", "function", "with", "a", "distribution", "of", "elements", ",", "such", "as", "a", "sigmoid", "function", "or", "a", "rectified", "linear", "unit", "."], "sentence-detokenized": "The math/sigma/math here is an activation function with a distribution of elements, such as a sigmoid function or a rectified linear unit.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [14, 15], [15, 19], [20, 24], [25, 27], [28, 30], [31, 41], [42, 50], [51, 55], [56, 57], [58, 70], [71, 73], [74, 82], [82, 83], [84, 88], [89, 91], [92, 93], [94, 101], [102, 110], [111, 113], [114, 115], [116, 125], [126, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-dev-287", "ner": [[9, 11, "algorithm"], [20, 20, "misc"], [22, 22, "misc"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "phonetics", "-", "based", "approaches", "(", "i.e.", ",", "all", "Hidden", "Markov", "Models", ")", "required", "separate", "components", "and", "training", "for", "the", "pronunciation", ",", "acoustic", ",", "and", "language", "models", "."], "sentence-detokenized": "Traditional phonetics-based approaches (i.e., all Hidden Markov Models) required separate components and training for the pronunciation, acoustic, and language models.", "token2charspan": [[0, 11], [12, 21], [21, 22], [22, 27], [28, 38], [39, 40], [40, 44], [44, 45], [46, 49], [50, 56], [57, 63], [64, 70], [70, 71], [72, 80], [81, 89], [90, 100], [101, 104], [105, 113], [114, 117], [118, 121], [122, 135], [135, 136], [137, 145], [145, 146], [147, 150], [151, 159], [160, 166], [166, 167]]}
{"doc_key": "ai-dev-288", "ner": [[0, 5, "algorithm"], [7, 8, "field"], [10, 11, "field"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 5, 13, 14, "related-to", "used_for", false, false], [7, 8, 0, 5, "usage", "", false, false], [10, 11, 0, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Roberts", "cross", "operator", "is", "used", "in", "image", "processing", "and", "computer", "vision", "to", "detect", "edges", "."], "sentence-detokenized": "The Roberts cross operator is used in image processing and computer vision to detect edges.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 37], [38, 43], [44, 54], [55, 58], [59, 67], [68, 74], [75, 77], [78, 84], [85, 90], [90, 91]]}
{"doc_key": "ai-dev-289", "ner": [[0, 0, "metrics"], [2, 2, "metrics"], [19, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 19, 22, "opposite", "", false, false], [2, 2, 19, 22, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Sensitivity", "and", "specificity", "values", "are", "independent", "of", "the", "percentage", "of", "positive", "cases", "in", "the", "population", "of", "interest", "(", "unlike", "accuracy", ",", "for", "example", ")", "."], "sentence-detokenized": "Sensitivity and specificity values are independent of the percentage of positive cases in the population of interest (unlike accuracy, for example).", "token2charspan": [[0, 11], [12, 15], [16, 27], [28, 34], [35, 38], [39, 50], [51, 53], [54, 57], [58, 68], [69, 71], [72, 80], [81, 86], [87, 89], [90, 93], [94, 104], [105, 107], [108, 116], [117, 118], [118, 124], [125, 133], [133, 134], [135, 138], [139, 146], [146, 147], [147, 148]]}
{"doc_key": "ai-dev-290", "ner": [[2, 4, "algorithm"], [11, 11, "misc"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 2, 4, "topic", "", false, false], [11, 11, 13, 14, "artifact", "", false, false], [11, 11, 16, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "perceptron", "models", "became", "very", "unpopular", "thanks", "to", "the", "book", "Perceptrons", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", ",", "published", "in", "1969", "."], "sentence-detokenized": "However, perceptron models became very unpopular thanks to the book Perceptrons by Marvin Minsky and Seymour Papert, published in 1969.", "token2charspan": [[0, 7], [7, 8], [9, 19], [20, 26], [27, 33], [34, 38], [39, 48], [49, 55], [56, 58], [59, 62], [63, 67], [68, 79], [80, 82], [83, 89], [90, 96], [97, 100], [101, 108], [109, 115], [115, 116], [117, 126], [127, 129], [130, 134], [134, 135]]}
{"doc_key": "ai-dev-291", "ner": [[0, 5, "conference"], [8, 8, "organisation"], [23, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 5, 23, 25, "topic", "", false, false], [8, 8, 0, 5, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Document", "Understanding", "Conferences", ",", "hosted", "annually", "by", "NIST", ",", "have", "developed", "sophisticated", "criteria", "for", "evaluating", "techniques", "that", "take", "on", "the", "challenge", "of", "summarizing", "multiple", "documents", "."], "sentence-detokenized": "The Document Understanding Conferences, hosted annually by NIST, have developed sophisticated criteria for evaluating techniques that take on the challenge of summarizing multiple documents.", "token2charspan": [[0, 3], [4, 12], [13, 26], [27, 38], [38, 39], [40, 46], [47, 55], [56, 58], [59, 63], [63, 64], [65, 69], [70, 79], [80, 93], [94, 102], [103, 106], [107, 117], [118, 128], [129, 133], [134, 138], [139, 141], [142, 145], [146, 155], [156, 158], [159, 170], [171, 179], [180, 189], [189, 190]]}
{"doc_key": "ai-dev-292", "ner": [[0, 2, "product"], [29, 30, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 29, 30, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "parallel", "manipulator", "is", "designed", "in", "such", "a", "way", "that", "each", "chain", "is", "usually", "short", ",", "simple", ",", "and", "can", "thus", "be", "fixed", "against", "unwanted", "movement", "compared", "to", "the", "serial", "manipulator", "."], "sentence-detokenized": "The parallel manipulator is designed in such a way that each chain is usually short, simple, and can thus be fixed against unwanted movement compared to the serial manipulator.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 27], [28, 36], [37, 39], [40, 44], [45, 46], [47, 50], [51, 55], [56, 60], [61, 66], [67, 69], [70, 77], [78, 83], [83, 84], [85, 91], [91, 92], [93, 96], [97, 100], [101, 105], [106, 108], [109, 114], [115, 122], [123, 131], [132, 140], [141, 149], [150, 152], [153, 156], [157, 163], [164, 175], [175, 176]]}
{"doc_key": "ai-dev-293", "ner": [[25, 25, "misc"], [27, 31, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "manipulator", "is", "what", "makes", "the", "robot", "move", ",", "and", "the", "design", "of", "these", "systems", "can", "be", "divided", "into", "several", "common", "types", ",", "such", "as", "SCARA", "and", "Cartesian", "coordinate", "robot", ",", "which", "use", "different", "coordinate", "systems", "to", "control", "the", "machine", "arms", "."], "sentence-detokenized": "The manipulator is what makes the robot move, and the design of these systems can be divided into several common types, such as SCARA and Cartesian coordinate robot, which use different coordinate systems to control the machine arms.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 23], [24, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 49], [50, 53], [54, 60], [61, 63], [64, 69], [70, 77], [78, 81], [82, 84], [85, 92], [93, 97], [98, 105], [106, 112], [113, 118], [118, 119], [120, 124], [125, 127], [128, 133], [134, 137], [138, 147], [148, 158], [159, 164], [164, 165], [166, 171], [172, 175], [176, 185], [186, 196], [197, 204], [205, 207], [208, 215], [216, 219], [220, 227], [228, 232], [232, 233]]}
{"doc_key": "ai-dev-294", "ner": [[5, 6, "country"], [11, 14, "organisation"], [17, 24, "organisation"], [25, 27, "organisation"], [30, 32, "organisation"], [36, 42, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 14, 5, 6, "physical", "", false, false], [17, 24, 5, 6, "physical", "", false, false], [25, 27, 5, 6, "physical", "", false, false], [30, 32, 5, 6, "physical", "", false, false], [36, 42, 5, 6, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "United", "States", ",", "he", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Linguistic", "Society", ",", "the", "American", "Philosophical", "Association", ",", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In the United States, he is a member of the National Academy of Sciences, the American Academy of Arts and Sciences, the American Linguistic Society, the American Philosophical Association, and the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 20], [20, 21], [22, 24], [25, 27], [28, 29], [30, 36], [37, 39], [40, 43], [44, 52], [53, 60], [61, 63], [64, 72], [72, 73], [74, 77], [78, 86], [87, 94], [95, 97], [98, 102], [103, 106], [107, 115], [115, 116], [117, 120], [121, 129], [130, 140], [141, 148], [148, 149], [150, 153], [154, 162], [163, 176], [177, 188], [188, 189], [190, 193], [194, 197], [198, 206], [207, 218], [219, 222], [223, 226], [227, 238], [239, 241], [242, 249], [249, 250]]}
{"doc_key": "ai-dev-295", "ner": [[8, 10, "algorithm"], [12, 16, "algorithm"], [19, 19, "algorithm"], [26, 28, "algorithm"], [32, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 10, 19, 19, "named", "", false, false], [12, 16, 8, 10, "named", "", false, false], [19, 19, 26, 28, "compare", "", false, false], [19, 19, 32, 33, "related-to", "performs", false, false], [26, 28, 32, 33, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Their", "popularity", "increased", "with", "the", "popularity", "of", "the", "support", "vector", "machine", "(", "SVM", ")", "in", "the", "1990s", ",", "when", "SVM", "was", "found", "to", "be", "competitive", "with", "neural", "networks", "in", "tasks", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "Their popularity increased with the popularity of the support vector machine (SVM) in the 1990s, when SVM was found to be competitive with neural networks in tasks such as handwriting recognition.", "token2charspan": [[0, 5], [6, 16], [17, 26], [27, 31], [32, 35], [36, 46], [47, 49], [50, 53], [54, 61], [62, 68], [69, 76], [77, 78], [78, 81], [81, 82], [83, 85], [86, 89], [90, 95], [95, 96], [97, 101], [102, 105], [106, 109], [110, 115], [116, 118], [119, 121], [122, 133], [134, 138], [139, 145], [146, 154], [155, 157], [158, 163], [164, 168], [169, 171], [172, 183], [184, 195], [195, 196]]}
{"doc_key": "ai-dev-296", "ner": [[2, 4, "misc"], [9, 11, "misc"], [13, 15, "algorithm"], [23, 24, "misc"], [28, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 9, 11, "usage", "", false, false], [2, 4, 23, 24, "usage", "", false, false], [9, 11, 13, 15, "origin", "result_of_algorithm", false, false], [23, 24, 28, 29, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "empirical", "whitening", "transform", "is", "obtained", "by", "estimating", "the", "covariance", "(", "e.g.", ",", "maximum", "likelihood", "method", ")", "and", "then", "constructing", "the", "corresponding", "estimated", "whitening", "matrix", "(", "e.g.", ",", "Cholesky", "decomposition", ")", "."], "sentence-detokenized": "The empirical whitening transform is obtained by estimating the covariance (e.g., maximum likelihood method) and then constructing the corresponding estimated whitening matrix (e.g., Cholesky decomposition).", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 33], [34, 36], [37, 45], [46, 48], [49, 59], [60, 63], [64, 74], [75, 76], [76, 80], [80, 81], [82, 89], [90, 100], [101, 107], [107, 108], [109, 112], [113, 117], [118, 130], [131, 134], [135, 148], [149, 158], [159, 168], [169, 175], [176, 177], [177, 181], [181, 182], [183, 191], [192, 205], [205, 206], [206, 207]]}
{"doc_key": "ai-dev-297", "ner": [[0, 0, "organisation"], [8, 10, "product"], [23, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 0, 0, "artifact", "", false, false], [23, 24, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "is", "the", "world", "'s", "largest", "manufacturer", "of", "Cartesian", "coordinate", "robots", "and", "a", "recognized", "leader", "in", "low", "-", "cost", ",", "high", "-", "performance", "SCARA", "robots", "."], "sentence-detokenized": "IAI is the world's largest manufacturer of Cartesian coordinate robots and a recognized leader in low-cost, high-performance SCARA robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [16, 18], [19, 26], [27, 39], [40, 42], [43, 52], [53, 63], [64, 70], [71, 74], [75, 76], [77, 87], [88, 94], [95, 97], [98, 101], [101, 102], [102, 106], [106, 107], [108, 112], [112, 113], [113, 124], [125, 130], [131, 137], [137, 138]]}
{"doc_key": "ai-dev-298", "ner": [[10, 11, "field"], [13, 14, "field"], [16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formal", "conceptual", "analysis", "finds", "practical", "applications", "in", "areas", "such", "as", "data", "mining", ",", "text", "mining", ",", "machine", "learning", ",", "knowledge", "management", ",", "semantic", "web", ",", "software", "development", ",", "chemistry", "and", "biology", "."], "sentence-detokenized": "Formal conceptual analysis finds practical applications in areas such as data mining, text mining, machine learning, knowledge management, semantic web, software development, chemistry and biology.", "token2charspan": [[0, 6], [7, 17], [18, 26], [27, 32], [33, 42], [43, 55], [56, 58], [59, 64], [65, 69], [70, 72], [73, 77], [78, 84], [84, 85], [86, 90], [91, 97], [97, 98], [99, 106], [107, 115], [115, 116], [117, 126], [127, 137], [137, 138], [139, 147], [148, 151], [151, 152], [153, 161], [162, 173], [173, 174], [175, 184], [185, 188], [189, 196], [196, 197]]}
{"doc_key": "ai-dev-299", "ner": [[0, 2, "field"], [6, 7, "field"], [13, 15, "field"], [26, 28, "field"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[0, 2, 13, 15, "part-of", "", false, false], [0, 2, 26, 28, "topic", "", false, false], [6, 7, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "theory", "(", "or", "just", "learning", "theory", ")", "is", "a", "subfield", "of", "artificial", "intelligence", "that", "deals", "with", "the", "study", "of", "the", "design", "and", "analysis", "of", "machine", "learning", "algorithms", "."], "sentence-detokenized": "Machine learning theory (or just learning theory) is a subfield of artificial intelligence that deals with the study of the design and analysis of machine learning algorithms.", "token2charspan": [[0, 7], [8, 16], [17, 23], [24, 25], [25, 27], [28, 32], [33, 41], [42, 48], [48, 49], [50, 52], [53, 54], [55, 63], [64, 66], [67, 77], [78, 90], [91, 95], [96, 101], [102, 106], [107, 110], [111, 116], [117, 119], [120, 123], [124, 130], [131, 134], [135, 143], [144, 146], [147, 154], [155, 163], [164, 174], [174, 175]]}
{"doc_key": "ai-dev-300", "ner": [[0, 1, "algorithm"], [3, 3, "algorithm"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 1, "named", "", false, false], [10, 10, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Collaborative", "filtering", "(", "CF", ")", "is", "a", "technique", "used", "in", "recommender", "systems", "."], "sentence-detokenized": "Collaborative filtering (CF) is a technique used in recommender systems.", "token2charspan": [[0, 13], [14, 23], [24, 25], [25, 27], [27, 28], [29, 31], [32, 33], [34, 43], [44, 48], [49, 51], [52, 63], [64, 71], [71, 72]]}
{"doc_key": "ai-dev-301", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "False", "Positive", "Rate", "is", "the", "proportion", "of", "all", "negative", "results", "that", "still", "yield", "a", "positive", "test", "result", ",", "i.e.", "the", "conditional", "probability", "of", "a", "positive", "test", "result", "assuming", "the", "event", "was", "not", "present", "."], "sentence-detokenized": "The False Positive Rate is the proportion of all negative results that still yield a positive test result, i.e. the conditional probability of a positive test result assuming the event was not present.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 23], [24, 26], [27, 30], [31, 41], [42, 44], [45, 48], [49, 57], [58, 65], [66, 70], [71, 76], [77, 82], [83, 84], [85, 93], [94, 98], [99, 105], [105, 106], [107, 111], [112, 115], [116, 127], [128, 139], [140, 142], [143, 144], [145, 153], [154, 158], [159, 165], [166, 174], [175, 178], [179, 184], [185, 188], [189, 192], [193, 200], [200, 201]]}
{"doc_key": "ai-dev-302", "ner": [[1, 15, "misc"], [37, 38, "metrics"], [41, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 15, 37, 38, "topic", "", false, false], [1, 15, 41, 41, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "VLDB", "'", "8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pages", "422--433", ".", "showed", "that", "the", "given", "values", "for", "mathC", "/", "math", "and", "mathK", "/", "math", "generally", "imply", "relatively", "low", "accuracy", "of", "iteratively", "computed", "SimRank", "results", "."], "sentence-detokenized": "In VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, pages 422--433. showed that the given values for mathC/math and mathK/math generally imply relatively low accuracy of iteratively computed SimRank results.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [10, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 79], [80, 85], [85, 86], [87, 92], [93, 101], [101, 102], [103, 109], [110, 114], [115, 118], [119, 124], [125, 131], [132, 135], [136, 141], [141, 142], [142, 146], [147, 150], [151, 156], [156, 157], [157, 161], [162, 171], [172, 177], [178, 188], [189, 192], [193, 201], [202, 204], [205, 216], [217, 225], [226, 233], [234, 241], [241, 242]]}
{"doc_key": "ai-dev-303", "ner": [[0, 4, "misc"], [5, 5, "misc"], [11, 12, "person"], [14, 16, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 0, 4, "general-affiliation", "", false, false], [5, 5, 11, 12, "artifact", "", false, false], [5, 5, 14, 16, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "sci", "-", "fi", "drama", "Sense8", ",", "written", "and", "produced", "by", "the", "Wachowskis", "and", "J.", "Michael", "Straczynski", ",", "debuted", "in", "June", "2015", "."], "sentence-detokenized": "The sci-fi drama Sense8, written and produced by the Wachowskis and J. Michael Straczynski, debuted in June 2015.", "token2charspan": [[0, 3], [4, 7], [7, 8], [8, 10], [11, 16], [17, 23], [23, 24], [25, 32], [33, 36], [37, 45], [46, 48], [49, 52], [53, 63], [64, 67], [68, 70], [71, 78], [79, 90], [90, 91], [92, 99], [100, 102], [103, 107], [108, 112], [112, 113]]}
{"doc_key": "ai-dev-304", "ner": [[1, 1, "misc"], [6, 9, "product"], [27, 31, "misc"], [37, 37, "country"], [39, 39, "country"], [41, 41, "country"], [43, 43, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 1, 6, 9, "topic", "", false, false], [37, 37, 27, 31, "type-of", "", false, false], [39, 39, 27, 31, "type-of", "", false, false], [41, 41, 27, 31, "type-of", "", false, false], [43, 43, 27, 31, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Although", "Eurotra", "never", "delivered", "a", "working", "MT", "system", ",", "the", "project", "had", "a", "long", "-", "lasting", "and", "far", "-", "reaching", "impact", "on", "the", "emerging", "language", "sector", "in", "European", "Member", "States", ",", "especially", "in", "southern", "countries", "such", "as", "Greece", ",", "Italy", ",", "Spain", "and", "Portugal", "."], "sentence-detokenized": "Although Eurotra never delivered a working MT system, the project had a long-lasting and far-reaching impact on the emerging language sector in European Member States, especially in southern countries such as Greece, Italy, Spain and Portugal.", "token2charspan": [[0, 8], [9, 16], [17, 22], [23, 32], [33, 34], [35, 42], [43, 45], [46, 52], [52, 53], [54, 57], [58, 65], [66, 69], [70, 71], [72, 76], [76, 77], [77, 84], [85, 88], [89, 92], [92, 93], [93, 101], [102, 108], [109, 111], [112, 115], [116, 124], [125, 133], [134, 140], [141, 143], [144, 152], [153, 159], [160, 166], [166, 167], [168, 178], [179, 181], [182, 190], [191, 200], [201, 205], [206, 208], [209, 215], [215, 216], [217, 222], [222, 223], [224, 229], [230, 233], [234, 242], [242, 243]]}
{"doc_key": "ai-dev-305", "ner": [[0, 1, "algorithm"], [7, 9, "task"], [19, 21, "task"], [23, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 9, 0, 1, "usage", "", true, false], [19, 21, 7, 9, "named", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "autoencoder", "has", "been", "successfully", "used", "for", "machine", "translation", "of", "human", "languages", ",", "which", "is", "usually", "referred", "to", "as", "neural", "machine", "translation", "(", "NMT", ")", "."], "sentence-detokenized": "The autoencoder has been successfully used for machine translation of human languages, which is usually referred to as neural machine translation (NMT).", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 24], [25, 37], [38, 42], [43, 46], [47, 54], [55, 66], [67, 69], [70, 75], [76, 85], [85, 86], [87, 92], [93, 95], [96, 103], [104, 112], [113, 115], [116, 118], [119, 125], [126, 133], [134, 145], [146, 147], [147, 150], [150, 151], [151, 152]]}
{"doc_key": "ai-dev-306", "ner": [[9, 11, "metrics"], [13, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "examples", "of", "probability", "-", "based", "fitness", "functions", "include", "maximum", "likelihood", "estimation", "and", "joi", "nt", "loss", "."], "sentence-detokenized": "Popular examples of probability-based fitness functions include maximum likelihood estimation and joint loss.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 31], [31, 32], [32, 37], [38, 45], [46, 55], [56, 63], [64, 71], [72, 82], [83, 93], [94, 97], [98, 101], [101, 103], [104, 108], [108, 109]]}
{"doc_key": "ai-dev-307", "ner": [[0, 1, "field"], [9, 11, "task"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 11, 0, 1, "part-of", "", false, false], [13, 14, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "mining", "is", "a", "related", "field", "that", "focuses", "on", "exploratory", "data", "analysis", "through", "unsupervised", "learning", "."], "sentence-detokenized": "Data mining is a related field that focuses on exploratory data analysis through unsupervised learning.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 35], [36, 43], [44, 46], [47, 58], [59, 63], [64, 72], [73, 80], [81, 93], [94, 102], [102, 103]]}
{"doc_key": "ai-dev-308", "ner": [[0, 1, "algorithm"], [13, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "involves", "techniques", "for", "matching", "people", "with", "similar", "interests", "and", "building", "a", "recommender", "system", "based", "on", "this", "."], "sentence-detokenized": "Collaborative filtering involves techniques for matching people with similar interests and building a recommender system based on this.", "token2charspan": [[0, 13], [14, 23], [24, 32], [33, 43], [44, 47], [48, 56], [57, 63], [64, 68], [69, 76], [77, 86], [87, 90], [91, 99], [100, 101], [102, 113], [114, 120], [121, 126], [127, 129], [130, 134], [134, 135]]}
{"doc_key": "ai-dev-309", "ner": [[3, 8, "algorithm"], [13, 13, "programlang"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 18, 3, 8, "type-of", "", false, false], [16, 18, 13, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "number", "of", "WordNet", "-", "based", "word", "similarity", "algorithms", "are", "implemented", "in", "a", "Perl", "package", "called", "WordNet", "::", "Similarity", "."], "sentence-detokenized": "A number of WordNet-based word similarity algorithms are implemented in a Perl package called WordNet::Similarity.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 19], [19, 20], [20, 25], [26, 30], [31, 41], [42, 52], [53, 56], [57, 68], [69, 71], [72, 73], [74, 78], [79, 86], [87, 93], [94, 101], [101, 103], [103, 113], [113, 114]]}
{"doc_key": "ai-dev-310", "ner": [[5, 5, "conference"], [9, 10, "researcher"], [12, 13, "researcher"], [15, 18, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Another", "paper", "presented", "at", "the", "CVPR", "2000", "conference", "by", "Erik", "Miller", ",", "Nicholas", "Matsakis", "and", "Paul", "Viola", "will", "also", "be", "discussed", "."], "sentence-detokenized": "Another paper presented at the CVPR 2000 conference by Erik Miller, Nicholas Matsakis and Paul Viola will also be discussed.", "token2charspan": [[0, 7], [8, 13], [14, 23], [24, 26], [27, 30], [31, 35], [36, 40], [41, 51], [52, 54], [55, 59], [60, 66], [66, 67], [68, 76], [77, 85], [86, 89], [90, 94], [95, 100], [101, 105], [106, 110], [111, 113], [114, 123], [123, 124]]}
{"doc_key": "ai-dev-311", "ner": [[0, 0, "algorithm"], [7, 8, "misc"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 13, 14, "compare", "", false, false], [13, 14, 7, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["QC", "was", "not", "evaluated", "against", "traditional", "modern", "clustering", "algorithms", ",", "except", "for", "the", "Jaccard", "index", "."], "sentence-detokenized": "QC was not evaluated against traditional modern clustering algorithms, except for the Jaccard index.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 20], [21, 28], [29, 40], [41, 47], [48, 58], [59, 69], [69, 70], [71, 77], [78, 81], [82, 85], [86, 93], [94, 99], [99, 100]]}
{"doc_key": "ai-dev-312", "ner": [[2, 13, "misc"], [8, 10, "misc"], [14, 15, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 2, 13, "physical", "", false, false], [8, 10, 14, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "the", "VEX", "Robotics", "World", "Championships", ",", "the", "Parade", "of", "Nations", "is", "held", "at", "Freedom", "Hall", ",", "with", "hundreds", "of", "students", "from", "more", "than", "30", "countries", "participating", "."], "sentence-detokenized": "During the VEX Robotics World Championships, the Parade of Nations is held at Freedom Hall, with hundreds of students from more than 30 countries participating.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 23], [24, 29], [30, 43], [43, 44], [45, 48], [49, 55], [56, 58], [59, 66], [67, 69], [70, 74], [75, 77], [78, 85], [86, 90], [90, 91], [92, 96], [97, 105], [106, 108], [109, 117], [118, 122], [123, 127], [128, 132], [133, 135], [136, 145], [146, 159], [159, 160]]}
{"doc_key": "ai-dev-313", "ner": [[6, 9, "metrics"], [4, 4, "metrics"], [14, 16, "metrics"], [12, 12, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 6, 9, "named", "", false, false], [12, 12, 14, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Other", "accuracy", "measures", "include", "SWER", "(", "Single", "Word", "Error", "Rate", ")", "and", "CSR", "(", "Command", "Success", "Rate", ")", "."], "sentence-detokenized": "Other accuracy measures include SWER (Single Word Error Rate) and CSR (Command Success Rate).", "token2charspan": [[0, 5], [6, 14], [15, 23], [24, 31], [32, 36], [37, 38], [38, 44], [45, 49], [50, 55], [56, 60], [60, 61], [62, 65], [66, 69], [70, 71], [71, 78], [79, 86], [87, 91], [91, 92], [92, 93]]}
{"doc_key": "ai-dev-314", "ner": [[8, 9, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "presented", "their", "method", "and", "results", "at", "the", "SIGGRAPH", "2000", "conference", "."], "sentence-detokenized": "They presented their method and results at the SIGGRAPH 2000 conference.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 27], [28, 31], [32, 39], [40, 42], [43, 46], [47, 55], [56, 60], [61, 71], [71, 72]]}
{"doc_key": "ai-dev-315", "ner": [[0, 6, "conference"], [7, 7, "misc"], [9, 17, "misc"], [18, 19, "conference"], [22, 35, "researcher"], [37, 39, "researcher"], [41, 43, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 6, 7, 7, "origin", "", false, false], [7, 7, 18, 19, "physical", "", false, false], [7, 7, 18, 19, "temporal", "", false, false], [7, 7, 22, 35, "origin", "", false, false], [7, 7, 37, 39, "origin", "", false, false], [9, 17, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "KDD", "conference", "grew", "out", "of", "the", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "workshops", "at", "the", "AAAI", "conferences", "founded", "by", "Gregory", "I", "in", "1989", ",", "1991", "and", "1993", ".", "Piatetsky", "-", "Shapiro", "and", "in", "1994", "by", "Osama", "Fayyad", ".", "Machinery", "|", "ACM", "."], "sentence-detokenized": "The KDD conference grew out of the KDD (Knowledge Discovery and Data Mining) workshops at the AAAI conferences founded by Gregory I in 1989, 1991 and 1993. Piatetsky-Shapiro and in 1994 by Osama Fayyad. Machinery | ACM.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 23], [24, 27], [28, 30], [31, 34], [35, 38], [39, 40], [40, 49], [50, 59], [60, 63], [64, 68], [69, 75], [75, 76], [77, 86], [87, 89], [90, 93], [94, 98], [99, 110], [111, 118], [119, 121], [122, 129], [130, 131], [132, 134], [135, 139], [139, 140], [141, 145], [146, 149], [150, 154], [154, 155], [156, 165], [165, 166], [166, 173], [174, 177], [178, 180], [181, 185], [186, 188], [189, 194], [195, 201], [201, 202], [203, 212], [213, 214], [215, 218], [218, 219]]}
{"doc_key": "ai-dev-316", "ner": [[7, 10, "conference"], [12, 12, "conference"], [16, 21, "organisation"], [23, 23, "organisation"], [27, 31, "conference"], [33, 33, "conference"], [37, 43, "conference"], [45, 45, "conference"], [49, 55, "conference"], [57, 57, "conference"], [62, 67, "conference"], [69, 69, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[12, 12, 7, 10, "named", "", false, false], [23, 23, 16, 21, "named", "", false, false], [33, 33, 27, 31, "named", "", false, false], [45, 45, 37, 43, "named", "", false, false], [57, 57, 49, 55, "named", "", false, false], [69, 69, 62, 67, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "(", "AAAS", ")", ",", "and", "the", "Society", "for", "Optics", "and", "Photonics", "Technology", "(", "SPIE", ")", "."], "sentence-detokenized": "He was elected a Fellow of the Association for Computing Machinery (ACM), the Institute of Electrical and Electronics Engineers (IEEE), the International Association for Pattern Recognition (IAPR), the Association for the Advancement of Artificial Intelligence (AAAI), the American Association for the Advancement of Science (AAAS), and the Society for Optics and Photonics Technology (SPIE).", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 16], [17, 23], [24, 26], [27, 30], [31, 42], [43, 46], [47, 56], [57, 66], [67, 68], [68, 71], [71, 72], [72, 73], [74, 77], [78, 87], [88, 90], [91, 101], [102, 105], [106, 117], [118, 127], [128, 129], [129, 133], [133, 134], [134, 135], [136, 139], [140, 153], [154, 165], [166, 169], [170, 177], [178, 189], [190, 191], [191, 195], [195, 196], [196, 197], [198, 201], [202, 213], [214, 217], [218, 221], [222, 233], [234, 236], [237, 247], [248, 260], [261, 262], [262, 266], [266, 267], [267, 268], [269, 272], [273, 281], [282, 293], [294, 297], [298, 301], [302, 313], [314, 316], [317, 324], [325, 326], [326, 330], [330, 331], [331, 332], [333, 336], [337, 340], [341, 348], [349, 352], [353, 359], [360, 363], [364, 373], [374, 384], [385, 386], [386, 390], [390, 391], [391, 392]]}
{"doc_key": "ai-dev-317", "ner": [[0, 1, "field"], [3, 4, "field"], [16, 18, "field"], [30, 32, "field"], [50, 53, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 18, "named", "", false, false], [3, 4, 30, 32, "named", "", false, false], [30, 32, 50, 53, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "and", "data", "mining", "often", "use", "the", "same", "methods", "and", "overlap", "significantly", ",", "but", "while", "machine", "learning", "focuses", "on", "prediction", "based", "on", "known", "features", "extracted", "from", "training", "data", ",", "data", "mining", "focuses", "on", "discovering", "(", "previously", ")", "unknown", "features", "in", "the", "data", "(", "this", "is", "the", "analysis", "step", "in", "knowledge", "discovery", "in", "databases", ")", "."], "sentence-detokenized": "Machine learning and data mining often use the same methods and overlap significantly, but while machine learning focuses on prediction based on known features extracted from training data, data mining focuses on discovering (previously) unknown features in the data (this is the analysis step in knowledge discovery in databases).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 59], [60, 63], [64, 71], [72, 85], [85, 86], [87, 90], [91, 96], [97, 104], [105, 113], [114, 121], [122, 124], [125, 135], [136, 141], [142, 144], [145, 150], [151, 159], [160, 169], [170, 174], [175, 183], [184, 188], [188, 189], [190, 194], [195, 201], [202, 209], [210, 212], [213, 224], [225, 226], [226, 236], [236, 237], [238, 245], [246, 254], [255, 257], [258, 261], [262, 266], [267, 268], [268, 272], [273, 275], [276, 279], [280, 288], [289, 293], [294, 296], [297, 306], [307, 316], [317, 319], [320, 329], [329, 330], [330, 331]]}
{"doc_key": "ai-dev-318", "ner": [[0, 1, "product"], [4, 6, "programlang"], [11, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 4, 6, "general-affiliation", "", false, false], [0, 1, 4, 6, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "is", "written", "in", "Java", "and", "therefore", "works", "on", "most", "modern", "operating", "systems", "."], "sentence-detokenized": "Indy is written in Java and therefore works on most modern operating systems.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 23], [24, 27], [28, 37], [38, 43], [44, 46], [47, 51], [52, 58], [59, 68], [69, 76], [76, 77]]}
{"doc_key": "ai-dev-319", "ner": [[0, 1, "algorithm"], [6, 8, "algorithm"], [10, 13, "algorithm"], [16, 18, "algorithm"], [20, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 8, "type-of", "", true, false], [10, 13, 6, 8, "named", "", false, false], [16, 18, 6, 8, "type-of", "", true, false], [20, 20, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "NMF", "is", "an", "instance", "of", "non-negative", "quadratic", "programming", "(", "NQP", ")", ",", "as", "is", "the", "support", "vector", "machine", "(", "SVM", ")", "."], "sentence-detokenized": "The NMF is an instance of non-negative quadratic programming (NQP), as is the support vector machine (SVM).", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 13], [14, 22], [23, 25], [26, 38], [39, 48], [49, 60], [61, 62], [62, 65], [65, 66], [66, 67], [68, 70], [71, 73], [74, 77], [78, 85], [86, 92], [93, 100], [101, 102], [102, 105], [105, 106], [106, 107]]}
{"doc_key": "ai-dev-320", "ner": [[8, 9, "misc"], [12, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 12, 17, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "method", "is", "based", "on", "the", "estimation", "of", "conditional", "probabilities", "using", "a", "non-parametric", "maximum", "likelihood", "method", ",", "which", "leads", "to"], "sentence-detokenized": "The method is based on the estimation of conditional probabilities using a non-parametric maximum likelihood method, which leads to", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 26], [27, 37], [38, 40], [41, 52], [53, 66], [67, 72], [73, 74], [75, 89], [90, 97], [98, 108], [109, 115], [115, 116], [117, 122], [123, 128], [129, 131]]}
{"doc_key": "ai-dev-321", "ner": [[8, 8, "algorithm"], [10, 12, "algorithm"], [14, 17, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "basic", "concepts", "involved", "in", "spectral", "estimation", "include", "autocorrelation", ",", "multidimensional", "Fourier", "transform", ",", "root", "mean", "square", "error", "and", "entropy", "."], "sentence-detokenized": "The basic concepts involved in spectral estimation include autocorrelation, multidimensional Fourier transform, root mean square error and entropy.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 27], [28, 30], [31, 39], [40, 50], [51, 58], [59, 74], [74, 75], [76, 92], [93, 100], [101, 110], [110, 111], [112, 116], [117, 121], [122, 128], [129, 134], [135, 138], [139, 146], [146, 147]]}
{"doc_key": "ai-dev-322", "ner": [[4, 5, "algorithm"], [10, 10, "field"], [12, 12, "algorithm"], [14, 16, "algorithm"], [18, 19, "task"], [21, 21, "field"], [23, 23, "field"], [25, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[4, 5, 10, 10, "part-of", "", false, false], [4, 5, 12, 12, "part-of", "", false, false], [4, 5, 14, 16, "part-of", "", false, false], [4, 5, 18, 19, "part-of", "", false, false], [4, 5, 21, 21, "part-of", "", false, false], [4, 5, 23, 23, "part-of", "", false, false], [4, 5, 25, 26, "part-of", "", false, false], [4, 5, 28, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "application", "areas", "of", "kernel", "methods", "are", "diverse", "and", "include", "geostatistics", ",", "kriging", ",", "inverse", "distance", "weighting", ",", "3D", "reconstruction", ",", "bioinformatics", ",", "chemoinformatics", ",", "information", "extraction", "and", "handwriting", "recognition", "."], "sentence-detokenized": "The application areas of kernel methods are diverse and include geostatistics, kriging, inverse distance weighting, 3D reconstruction, bioinformatics, chemoinformatics, information extraction and handwriting recognition.", "token2charspan": [[0, 3], [4, 15], [16, 21], [22, 24], [25, 31], [32, 39], [40, 43], [44, 51], [52, 55], [56, 63], [64, 77], [77, 78], [79, 86], [86, 87], [88, 95], [96, 104], [105, 114], [114, 115], [116, 118], [119, 133], [133, 134], [135, 149], [149, 150], [151, 167], [167, 168], [169, 180], [181, 191], [192, 195], [196, 207], [208, 219], [219, 220]]}
{"doc_key": "ai-dev-323", "ner": [[12, 12, "organisation"], [14, 18, "product"], [20, 20, "product"], [23, 23, "organisation"], [25, 28, "product"], [30, 30, "product"], [33, 34, "product"], [36, 38, "product"], [40, 42, "product"], [44, 46, "product"], [50, 51, "product"], [53, 54, "product"], [56, 61, "product"], [65, 66, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[14, 18, 12, 12, "artifact", "", false, false], [14, 18, 33, 34, "compare", "", false, false], [14, 18, 36, 38, "compare", "", false, false], [14, 18, 40, 42, "compare", "", false, false], [14, 18, 44, 46, "compare", "", false, false], [14, 18, 50, 51, "compare", "", false, false], [14, 18, 53, 54, "compare", "", false, false], [14, 18, 56, 61, "compare", "", false, false], [14, 18, 65, 66, "compare", "", false, false], [20, 20, 14, 18, "named", "", false, false], [25, 28, 23, 23, "artifact", "", false, false], [25, 28, 33, 34, "compare", "", false, false], [25, 28, 36, 38, "compare", "", false, false], [25, 28, 40, 42, "compare", "", false, false], [25, 28, 44, 46, "compare", "", false, false], [25, 28, 50, 51, "compare", "", false, false], [25, 28, 53, 54, "compare", "", false, false], [25, 28, 56, 61, "compare", "", false, false], [25, 28, 65, 66, "compare", "", false, false], [30, 30, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Robots", "can", "be", "autonomous", "or", "semi-autonomous", "and", "range", "from", "humanoids", "such", "as", "Honda", "'s", "Advanced", "Step", "in", "Innovative", "Mobility", "(", "ASIMO", ")", "and", "TOSY", "'s", "Ping", "Pong", "Playing", "Robot", "(", "TOPIO", ")", "to", "industrial", "robots", ",", "medical", "surgical", "robots", ",", "patient", "assistance", "robots", ",", "therapy", "dog", "robots", ",", "collectively", "programmed", "swarm", "robots", ",", "drones", "such", "as", "General", "Atomics", "MQ", "-", "1", "Predator", ",", "and", "even", "microscopic", "nanorobots", "."], "sentence-detokenized": "Robots can be autonomous or semi-autonomous and range from humanoids such as Honda's Advanced Step in Innovative Mobility (ASIMO) and TOSY's Ping Pong Playing Robot (TOPIO) to industrial robots, medical surgical robots, patient assistance robots, therapy dog robots, collectively programmed swarm robots, drones such as General Atomics MQ-1 Predator, and even microscopic nanorobots.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 24], [25, 27], [28, 43], [44, 47], [48, 53], [54, 58], [59, 68], [69, 73], [74, 76], [77, 82], [82, 84], [85, 93], [94, 98], [99, 101], [102, 112], [113, 121], [122, 123], [123, 128], [128, 129], [130, 133], [134, 138], [138, 140], [141, 145], [146, 150], [151, 158], [159, 164], [165, 166], [166, 171], [171, 172], [173, 175], [176, 186], [187, 193], [193, 194], [195, 202], [203, 211], [212, 218], [218, 219], [220, 227], [228, 238], [239, 245], [245, 246], [247, 254], [255, 258], [259, 265], [265, 266], [267, 279], [280, 290], [291, 296], [297, 303], [303, 304], [305, 311], [312, 316], [317, 319], [320, 327], [328, 335], [336, 338], [338, 339], [339, 340], [341, 349], [349, 350], [351, 354], [355, 359], [360, 371], [372, 382], [382, 383]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 3, "product"], [20, 26, "university"], [8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 8, 9, "artifact", "", false, false], [0, 0, 11, 12, "artifact", "", false, false], [0, 0, 14, 15, "artifact", "", false, false], [0, 0, 17, 29, "artifact", "", false, false], [2, 3, 8, 9, "artifact", "", false, false], [2, 3, 11, 12, "artifact", "", false, false], [2, 3, 14, 15, "artifact", "", false, false], [2, 3, 17, 29, "artifact", "", false, false], [8, 9, 20, 26, "physical", "", false, false], [11, 12, 20, 26, "physical", "", false, false], [14, 15, 20, 26, "physical", "", false, false], [17, 29, 20, 26, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "and", "Freddy", "II", "were", "robots", "built", "by", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "and", "Donald", "Mitchie", "at", "Edinburgh", "University", "'s", "School", "of", "Computer", "Science", ",", "who", "could", "assemble", "wooden", "blocks", "in", "a", "matter", "of", "hours", "."], "sentence-detokenized": "Freddy and Freddy II were robots built by Pat Ambler, Robin Popplestone, Austin Tate and Donald Mitchie at Edinburgh University's School of Computer Science, who could assemble wooden blocks in a matter of hours.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 25], [26, 32], [33, 38], [39, 41], [42, 45], [46, 52], [52, 53], [54, 59], [60, 71], [71, 72], [73, 79], [80, 84], [85, 88], [89, 95], [96, 103], [104, 106], [107, 116], [117, 127], [127, 129], [130, 136], [137, 139], [140, 148], [149, 156], [156, 157], [158, 161], [162, 167], [168, 176], [177, 183], [184, 190], [191, 193], [194, 195], [196, 202], [203, 205], [206, 211], [211, 212]]}
{"doc_key": "ai-dev-325", "ner": [[5, 5, "location"], [6, 7, "country"], [12, 14, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 6, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "spent", "his", "childhood", "in", "Paris", ",", "where", "his", "parents", "emigrated", "from", "Lithuania", "in", "the", "early", "1920s", "."], "sentence-detokenized": "He spent his childhood in Paris, where his parents emigrated from Lithuania in the early 1920s.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 22], [23, 25], [26, 31], [31, 32], [33, 38], [39, 42], [43, 50], [51, 60], [61, 65], [66, 75], [76, 78], [79, 82], [83, 88], [89, 94], [94, 95]]}
{"doc_key": "ai-dev-326", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 15, "organisation"], [17, 22, "university"], [28, 32, "university"], [39, 40, "university"], [43, 45, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 10, 11, "role", "", false, false], [0, 1, 17, 22, "physical", "", false, false], [0, 1, 28, 32, "role", "", false, false], [0, 1, 39, 40, "role", "", false, false], [0, 1, 43, 45, "role", "", false, false], [10, 11, 12, 15, "part-of", "", false, false], [12, 15, 17, 22, "part-of", "", false, false], [39, 40, 28, 32, "part-of", "", false, false], [43, 45, 28, 32, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Dr.", "Paulos", "previously", "served", "as", "an", "Associate", "Professor", "in", "the", "Cooper-", "Siegel", "School", "of", "Computer", "Science", "at", "Carnegie", "Mellon", "University", ",", "where", "he", "was", "a", "member", "of", "the", "Human", "-", "Computer", "Interaction", "Institute", "and", "has", "also", "served", "on", "the", "Robotics", "Institute", "and", "the", "Entertainment", "Technology", "Center", "."], "sentence-detokenized": "Dr. Paulos previously served as an Associate Professor in the Cooper-Siegel School of Computer Science at Carnegie Mellon University, where he was a member of the Human-Computer Interaction Institute and has also served on the Robotics Institute and the Entertainment Technology Center.", "token2charspan": [[0, 3], [4, 10], [11, 21], [22, 28], [29, 31], [32, 34], [35, 44], [45, 54], [55, 57], [58, 61], [62, 69], [69, 75], [76, 82], [83, 85], [86, 94], [95, 102], [103, 105], [106, 114], [115, 121], [122, 132], [132, 133], [134, 139], [140, 142], [143, 146], [147, 148], [149, 155], [156, 158], [159, 162], [163, 168], [168, 169], [169, 177], [178, 189], [190, 199], [200, 203], [204, 207], [208, 212], [213, 219], [220, 222], [223, 226], [227, 235], [236, 245], [246, 249], [250, 253], [254, 267], [268, 278], [279, 285], [285, 286]]}
{"doc_key": "ai-dev-327", "ner": [[3, 4, "researcher"], [6, 7, "university"], [10, 13, "product"], [17, 21, "product"], [24, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 6, 7, "physical", "", false, false], [3, 4, 6, 7, "role", "", false, false], [10, 13, 3, 4, "artifact", "", false, false], [10, 13, 17, 21, "type-of", "", false, false], [10, 13, 24, 27, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1969", ",", "Victor", "Scheinman", "at", "Stanford", "University", "invented", "the", "Stanford", "Arm", ",", "an", "all", "-", "electric", "six-", "axis", "articulated", "robot", "that", "allowed", "the", "arm", "to", "be", "solved", "."], "sentence-detokenized": "In 1969, Victor Scheinman at Stanford University invented the Stanford Arm, an all-electric six-axis articulated robot that allowed the arm to be solved.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 25], [26, 28], [29, 37], [38, 48], [49, 57], [58, 61], [62, 70], [71, 74], [74, 75], [76, 78], [79, 82], [82, 83], [83, 91], [92, 96], [96, 100], [101, 112], [113, 118], [119, 123], [124, 131], [132, 135], [136, 139], [140, 142], [143, 145], [146, 152], [152, 153]]}
{"doc_key": "ai-dev-328", "ner": [[5, 5, "product"], [17, 18, "field"], [20, 21, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 17, 18, "related-to", "", false, false], [5, 5, 20, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "creation", "and", "implementation", "of", "chatbots", "is", "an", "ever", "-", "evolving", "field", "that", "is", "strongly", "linked", "to", "artificial", "intelligence", "and", "machine", "learning", ",", "so", "while", "the", "solutions", "provided", "have", "obvious", "advantages", ",", "they", "also", "have", "some", "significant", "limitations", "in", "terms", "of", "features", "and", "use", "cases", "."], "sentence-detokenized": "The creation and implementation of chatbots is an ever-evolving field that is strongly linked to artificial intelligence and machine learning, so while the solutions provided have obvious advantages, they also have some significant limitations in terms of features and use cases.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 31], [32, 34], [35, 43], [44, 46], [47, 49], [50, 54], [54, 55], [55, 63], [64, 69], [70, 74], [75, 77], [78, 86], [87, 93], [94, 96], [97, 107], [108, 120], [121, 124], [125, 132], [133, 141], [141, 142], [143, 145], [146, 151], [152, 155], [156, 165], [166, 174], [175, 179], [180, 187], [188, 198], [198, 199], [200, 204], [205, 209], [210, 214], [215, 219], [220, 231], [232, 243], [244, 246], [247, 252], [253, 255], [256, 264], [265, 268], [269, 272], [273, 278], [278, 279]]}
{"doc_key": "ai-dev-329", "ner": [[11, 13, "university"], [8, 9, "product"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 11, 13, "part-of", "", true, false], [20, 21, 8, 9, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "terms", "of", "freely", "available", "resources", ",", "the", "Sphinx", "toolkit", "from", "Carnegie", "Mellon", "University", "is", "one", "place", "to", "learn", "about", "speech", "recognition", "and", "start", "experimenting", "with", "it", "."], "sentence-detokenized": "In terms of freely available resources, the Sphinx toolkit from Carnegie Mellon University is one place to learn about speech recognition and start experimenting with it.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 18], [19, 28], [29, 38], [38, 39], [40, 43], [44, 50], [51, 58], [59, 63], [64, 72], [73, 79], [80, 90], [91, 93], [94, 97], [98, 103], [104, 106], [107, 112], [113, 118], [119, 125], [126, 137], [138, 141], [142, 147], [148, 161], [162, 166], [167, 169], [169, 170]]}
{"doc_key": "ai-dev-330", "ner": [[2, 3, "misc"], [13, 24, "misc"], [14, 14, "misc"], [26, 27, "university"], [31, 33, "location"], [32, 33, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 13, 24, "temporal", "", false, false], [14, 14, 13, 24, "named", "", false, false], [14, 14, 31, 33, "physical", "", false, false], [26, 27, 14, 14, "role", "", false, false], [31, 33, 32, 33, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "official", "RoboCup", "competition", "was", "preceded", "by", "the", "(", "often", "unacknowledged", ")", "first", "international", "MIROSOT", "(", "Micro", "Robot", "World", "Cup", "Soccer", "Tournament", ")", ",", "organized", "by", "KAIST", "in", "November", "1996", "in", "Taejon", ",", "Korea", "."], "sentence-detokenized": "The official RoboCup competition was preceded by the (often unacknowledged) first international MIROSOT (Micro Robot World Cup Soccer Tournament), organized by KAIST in November 1996 in Taejon, Korea.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 32], [33, 36], [37, 45], [46, 48], [49, 52], [53, 54], [54, 59], [60, 74], [74, 75], [76, 81], [82, 95], [96, 103], [104, 105], [105, 110], [111, 116], [117, 122], [123, 126], [127, 133], [134, 144], [144, 145], [145, 146], [147, 156], [157, 159], [160, 165], [166, 168], [169, 177], [178, 182], [183, 185], [186, 192], [192, 193], [194, 199], [199, 200]]}
{"doc_key": "ai-dev-331", "ner": [[5, 9, "metrics"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "standard", "loss", "math", "in", "the", "hinge", "(", "1-", "yf", "(", "x", ")", ")", "_", "+", "/", "math", "for", "signed", "data", ",", "the", "loss", "function", "math", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "math", "is", "introduced", "over", "unsigned", "data", "by", "letting", "math", "=\\", "operatorname", "{", "sign", "}", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "In addition to the standard loss math in the hinge (1-yf (x)) _ + / math for signed data, the loss function math (-1 | f (x) |) _ + / math is introduced over unsigned data by letting math =\\ operatorname {sign} {f (x)} / math.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 27], [28, 32], [33, 37], [38, 40], [41, 44], [45, 50], [51, 52], [52, 54], [54, 56], [57, 58], [58, 59], [59, 60], [60, 61], [62, 63], [64, 65], [66, 67], [68, 72], [73, 76], [77, 83], [84, 88], [88, 89], [90, 93], [94, 98], [99, 107], [108, 112], [113, 114], [114, 115], [115, 116], [117, 118], [119, 120], [121, 122], [122, 123], [123, 124], [125, 126], [126, 127], [128, 129], [130, 131], [132, 133], [134, 138], [139, 141], [142, 152], [153, 157], [158, 166], [167, 171], [172, 174], [175, 182], [183, 187], [188, 190], [191, 203], [204, 205], [205, 209], [209, 210], [211, 212], [212, 213], [214, 215], [215, 216], [216, 217], [217, 218], [219, 220], [221, 225], [225, 226]]}
{"doc_key": "ai-dev-332", "ner": [[0, 1, "misc"], [7, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 7, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "RLS", "is", "designed", "to", "minimize", "the", "root", "mean", "square", "error", "between", "the", "predicted", "values", "and", "the", "true", "labels", ",", "subject", "to", "regularization", "."], "sentence-detokenized": "The RLS is designed to minimize the root mean square error between the predicted values and the true labels, subject to regularization.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 19], [20, 22], [23, 31], [32, 35], [36, 40], [41, 45], [46, 52], [53, 58], [59, 66], [67, 70], [71, 80], [81, 87], [88, 91], [92, 95], [96, 100], [101, 107], [107, 108], [109, 116], [117, 119], [120, 134], [134, 135]]}
{"doc_key": "ai-dev-333", "ner": [[7, 9, "algorithm"], [12, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 12, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Essentially", ",", "it", "is", "a", "combination", "of", "maximum", "likelihood", "estimation", "with", "a", "regularization", "procedure", "that", "favors", "simpler", "models", "over", "more", "complex", "ones", "."], "sentence-detokenized": "Essentially, it is a combination of maximum likelihood estimation with a regularization procedure that favors simpler models over more complex ones.", "token2charspan": [[0, 11], [11, 12], [13, 15], [16, 18], [19, 20], [21, 32], [33, 35], [36, 43], [44, 54], [55, 65], [66, 70], [71, 72], [73, 87], [88, 97], [98, 102], [103, 109], [110, 117], [118, 124], [125, 129], [130, 134], [135, 142], [143, 147], [147, 148]]}
{"doc_key": "ai-dev-334", "ner": [[0, 4, "metrics"], [10, 10, "metrics"], [12, 12, "metrics"], [14, 16, "misc"], [20, 21, "misc"], [34, 37, "algorithm"], [38, 42, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 10, 0, 4, "named", "", false, false], [12, 12, 0, 4, "named", "", false, false], [14, 16, 20, 21, "related-to", "", false, false], [14, 16, 34, 37, "related-to", "ratio", false, false], [34, 37, 38, 42, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "rate", "of", "true", "positives", "is", "also", "known", "as", "the", "sensitivity", ",", "recall", "or", "probability", "of", "detection", "mathematically", "to", "the", "discrimination", "threshold", ")", "of", "the", "probability", "of", "detection", "on", "the", "y", "-axis", "versus", "the", "cumulative", "distribution", "function", "of", "the", "probability", "of", "false", "alarm", "on", "the", "x-", "axis", "."], "sentence-detokenized": "The rate of true positives is also known as the sensitivity, recall or probability of detection mathematically to the discrimination threshold) of the probability of detection on the y-axis versus the cumulative distribution function of the probability of false alarm on the x-axis.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 16], [17, 26], [27, 29], [30, 34], [35, 40], [41, 43], [44, 47], [48, 59], [59, 60], [61, 67], [68, 70], [71, 82], [83, 85], [86, 95], [96, 110], [111, 113], [114, 117], [118, 132], [133, 142], [142, 143], [144, 146], [147, 150], [151, 162], [163, 165], [166, 175], [176, 178], [179, 182], [183, 184], [184, 189], [190, 196], [197, 200], [201, 211], [212, 224], [225, 233], [234, 236], [237, 240], [241, 252], [253, 255], [256, 261], [262, 267], [268, 270], [271, 274], [275, 277], [277, 281], [281, 282]]}
{"doc_key": "ai-dev-335", "ner": [[1, 1, "misc"], [3, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 11, 1, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "English", ",", "Word", "Net", "is", "an", "example", "of", "a", "semantic", "network", "."], "sentence-detokenized": "In English, WordNet is an example of a semantic network.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [16, 19], [20, 22], [23, 25], [26, 33], [34, 36], [37, 38], [39, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-dev-336", "ner": [[5, 8, "product"], [11, 13, "product"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[26, 27, 5, 8, "usage", "", false, false], [26, 27, 11, 13, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "-", "term", "use", "of", "speech", "recognition", "software", "in", "conjunction", "with", "word", "processing", "software", "has", "shown", "benefits", "for", "enhancing", "short", "-", "term", "memory", "in", "patients", "with", "brain", "AVMs", "who", "have", "been", "treated", "with", "resection", "."], "sentence-detokenized": "Long-term use of speech recognition software in conjunction with word processing software has shown benefits for enhancing short-term memory in patients with brain AVMs who have been treated with resection.", "token2charspan": [[0, 4], [4, 5], [5, 9], [10, 13], [14, 16], [17, 23], [24, 35], [36, 44], [45, 47], [48, 59], [60, 64], [65, 69], [70, 80], [81, 89], [90, 93], [94, 99], [100, 108], [109, 112], [113, 122], [123, 128], [128, 129], [129, 133], [134, 140], [141, 143], [144, 152], [153, 157], [158, 163], [164, 168], [169, 172], [173, 177], [178, 182], [183, 190], [191, 195], [196, 205], [205, 206]]}
{"doc_key": "ai-dev-337", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Its", "founding", "editors", "were", "Ron", "Sun", ",", "Vasant", "Honavar", "and", "Gregg", "Oden", "(", "from", "1999", "to", "2014", ")", "."], "sentence-detokenized": "Its founding editors were Ron Sun, Vasant Honavar and Gregg Oden (from 1999 to 2014).", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 25], [26, 29], [30, 33], [33, 34], [35, 41], [42, 49], [50, 53], [54, 59], [60, 64], [65, 66], [66, 70], [71, 75], [76, 78], [79, 83], [83, 84], [84, 85]]}
{"doc_key": "ai-dev-338", "ner": [[7, 8, "product"], [12, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 12, 20, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Their", "\"", "parallel", "\"", "difference", "from", "the", "serial", "manipulator", "is", "that", "the", "end", "effector", "(", "or", "\"", "arm", "\"", ")", "of", "this", "linkage", "(", "or", "\"", "arm", "\"", ")", "is", "directly", "connected", "to", "the", "base", "by", "several", "(", "usually", "three", "or", "six", ")", "separate", "and", "independent", "linkages", "operating", "simultaneously", "."], "sentence-detokenized": "Their \"parallel\" difference from the serial manipulator is that the end effector (or \"arm\") of this linkage (or \"arm\") is directly connected to the base by several (usually three or six) separate and independent linkages operating simultaneously.", "token2charspan": [[0, 5], [6, 7], [7, 15], [15, 16], [17, 27], [28, 32], [33, 36], [37, 43], [44, 55], [56, 58], [59, 63], [64, 67], [68, 71], [72, 80], [81, 82], [82, 84], [85, 86], [86, 89], [89, 90], [90, 91], [92, 94], [95, 99], [100, 107], [108, 109], [109, 111], [112, 113], [113, 116], [116, 117], [117, 118], [119, 121], [122, 130], [131, 140], [141, 143], [144, 147], [148, 152], [153, 155], [156, 163], [164, 165], [165, 172], [173, 178], [179, 181], [182, 185], [185, 186], [187, 195], [196, 199], [200, 211], [212, 220], [221, 230], [231, 245], [245, 246]]}
{"doc_key": "ai-dev-339", "ner": [[5, 6, "researcher"], [17, 18, "researcher"], [19, 20, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"], [28, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "thesis", "advisor", "was", "Professor", "Cordell", "Green", ",", "and", "his", "thesis", "/", "oral", "committee", "consisted", "of", "Professors", "Edward", "Feigenbaum", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", ",", "Herbert", "Simon", ",", "."], "sentence-detokenized": "His thesis advisor was Professor Cordell Green, and his thesis/oral committee consisted of Professors Edward Feigenbaum Joshua Lederberg, Paul Cohen, Allen Newell, Herbert Simon,.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 22], [23, 32], [33, 40], [41, 46], [46, 47], [48, 51], [52, 55], [56, 62], [62, 63], [63, 67], [68, 77], [78, 87], [88, 90], [91, 101], [102, 108], [109, 119], [120, 126], [127, 136], [136, 137], [138, 142], [143, 148], [148, 149], [150, 155], [156, 162], [162, 163], [164, 171], [172, 177], [177, 178], [178, 179]]}
{"doc_key": "ai-dev-340", "ner": [[3, 5, "metrics"], [7, 10, "metrics"], [12, 14, "metrics"], [16, 18, "metrics"], [20, 23, "metrics"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "functions", "include", "mean", "square", "error", ",", "root", "mean", "square", "error", ",", "mean", "absolute", "error", ",", "relative", "square", "error", ",", "root", "relative", "square", "error", ",", "relative", "absolute", "error", ",", "and", "others", "."], "sentence-detokenized": "These functions include mean square error, root mean square error, mean absolute error, relative square error, root relative square error, relative absolute error, and others.", "token2charspan": [[0, 5], [6, 15], [16, 23], [24, 28], [29, 35], [36, 41], [41, 42], [43, 47], [48, 52], [53, 59], [60, 65], [65, 66], [67, 71], [72, 80], [81, 86], [86, 87], [88, 96], [97, 103], [104, 109], [109, 110], [111, 115], [116, 124], [125, 131], [132, 137], [137, 138], [139, 147], [148, 156], [157, 162], [162, 163], [164, 167], [168, 174], [174, 175]]}
{"doc_key": "ai-dev-341", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "bindings", "in", "Python", ",", "Java", "and", "MATLAB", "/", "OCTAVE", "."], "sentence-detokenized": "There are bindings in Python, Java and MATLAB / OCTAVE.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 21], [22, 28], [28, 29], [30, 34], [35, 38], [39, 45], [46, 47], [48, 54], [54, 55]]}
{"doc_key": "ai-dev-342", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "MATLAB", "implementation", "can", "be", "found", "at", "."], "sentence-detokenized": "The MATLAB implementation can be found at.", "token2charspan": [[0, 3], [4, 10], [11, 25], [26, 29], [30, 32], [33, 38], [39, 41], [41, 42]]}
{"doc_key": "ai-dev-343", "ner": [[0, 5, "researcher"], [8, 9, "field"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 5, "origin", "", false, false], [8, 9, 13, 14, "origin", "", false, false], [8, 9, 16, 17, "origin", "", false, false], [8, 9, 19, 20, "origin", "", false, false], [8, 9, 22, 25, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "is", "one", "of", "the", "founders", "of", "artificial", "intelligence", ",", "along", "with", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", "and", "Herbert", "A", ".", "Simon", "."], "sentence-detokenized": "John McCarthy is one of the founders of artificial intelligence, along with Alan Turing, Marvin Minsky, Allen Newell and Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 36], [37, 39], [40, 50], [51, 63], [63, 64], [65, 70], [71, 75], [76, 80], [81, 87], [87, 88], [89, 95], [96, 102], [102, 103], [104, 109], [110, 116], [117, 120], [121, 128], [129, 130], [130, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-dev-344", "ner": [[10, 12, "product"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "parallel", "manipulator", "is", "a", "mechanical", "system", "that", "uses", "multiple", "serial", "manipulators", "to", "support", "a", "single", "platform", "or", "end", "effector", "."], "sentence-detokenized": "A parallel manipulator is a mechanical system that uses multiple serial manipulators to support a single platform or end effector.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 27], [28, 38], [39, 45], [46, 50], [51, 55], [56, 64], [65, 71], [72, 84], [85, 87], [88, 95], [96, 97], [98, 104], [105, 113], [114, 116], [117, 120], [121, 129], [129, 130]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [3, 4, "task"], [7, 7, "product"], [9, 20, "product"], [26, 26, "misc"], [28, 28, "misc"], [30, 31, "misc"], [33, 38, "task"], [40, 43, "product"], [46, 47, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 7, 0, 0, "part-of", "", false, false], [7, 7, 3, 4, "type-of", "", false, false], [9, 20, 7, 7, "named", "", false, false], [26, 26, 7, 7, "part-of", "", false, false], [28, 28, 7, 7, "part-of", "", false, false], [30, 31, 7, 7, "part-of", "", false, false], [33, 38, 7, 7, "part-of", "", false, false], [40, 43, 7, 7, "part-of", "", false, false], [46, 47, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "includes", "an", "information", "extraction", "system", "called", "ANNIE", "(", "A", "Nearly", "-", "New", "Information", "Extraction", "System", ")", ",", "which", "is", "a", "set", "of", "modules", "including", "a", "tokenizer", ",", "gazetteer", ",", "sentence", "splitter", ",", "part", "-", "of", "-", "speech", "tagger", ",", "named", "entity", "recognition", "converter", ",", "and", "coherence", "tagger", "."], "sentence-detokenized": "GATE includes an information extraction system called ANNIE (A Nearly-New Information Extraction System), which is a set of modules including a tokenizer, gazetteer, sentence splitter, part-of-speech tagger, named entity recognition converter, and coherence tagger.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 28], [29, 39], [40, 46], [47, 53], [54, 59], [60, 61], [61, 62], [63, 69], [69, 70], [70, 73], [74, 85], [86, 96], [97, 103], [103, 104], [104, 105], [106, 111], [112, 114], [115, 116], [117, 120], [121, 123], [124, 131], [132, 141], [142, 143], [144, 153], [153, 154], [155, 164], [164, 165], [166, 174], [175, 183], [183, 184], [185, 189], [189, 190], [190, 192], [192, 193], [193, 199], [200, 206], [206, 207], [208, 213], [214, 220], [221, 232], [233, 242], [242, 243], [244, 247], [248, 257], [258, 264], [264, 265]]}
{"doc_key": "ai-dev-346", "ner": [[3, 12, "university"], [10, 11, "country"], [21, 24, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "graduated", "from", "Moscow", "State", "University", "and", "left", "for", "the", "United", "States", "in", "November", "1978", "thanks", "to", "the", "personal", "intervention", "of", "Senator", "Edward", "M.", "Kennedy", "."], "sentence-detokenized": "He graduated from Moscow State University and left for the United States in November 1978 thanks to the personal intervention of Senator Edward M. Kennedy.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 24], [25, 30], [31, 41], [42, 45], [46, 50], [51, 54], [55, 58], [59, 65], [66, 72], [73, 75], [76, 84], [85, 89], [90, 96], [97, 99], [100, 103], [104, 112], [113, 125], [126, 128], [129, 136], [137, 143], [144, 146], [147, 154], [154, 155]]}
{"doc_key": "ai-dev-347", "ner": [[4, 6, "organisation"], [9, 14, "misc"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 9, 14, "win-defeat", "", false, false], [9, 14, 21, 22, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "the", "DeepMind", "AlphaGo", "team", "won", "the", "first", "IJCAI", "Marvin", "Minsky", "Medal", "for", "outstanding", "achievements", "in", "the", "field", "of", "artificial", "intelligence", "."], "sentence-detokenized": "In 2017, the DeepMind AlphaGo team won the first IJCAI Marvin Minsky Medal for outstanding achievements in the field of artificial intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 21], [22, 29], [30, 34], [35, 38], [39, 42], [43, 48], [49, 54], [55, 61], [62, 68], [69, 74], [75, 78], [79, 90], [91, 103], [104, 106], [107, 110], [111, 116], [117, 119], [120, 130], [131, 143], [143, 144]]}
{"doc_key": "ai-dev-348", "ner": [[4, 6, "misc"], [9, 9, "misc"], [14, 14, "misc"], [23, 24, "misc"], [28, 29, "misc"], [35, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 6, 9, 9, "related-to", "is_recorded_by", false, false], [9, 9, 14, 14, "cause-effect", "", false, false], [9, 9, 14, 14, "physical", "", false, false], [9, 9, 23, 24, "physical", "", false, false], [9, 9, 35, 35, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "ways", "in", "which", "anomalous", "propagation", "is", "recorded", "are", "troposcatterers", "causing", "irregularities", "in", "the", "troposphere", ",", "scattering", "caused", "by", "meteors", ",", "refraction", "in", "ionized", "regions", "and", "layers", "of", "the", "ionosphere", ",", "and", "reflection", "from", "the", "ionosphere", "."], "sentence-detokenized": "Other ways in which anomalous propagation is recorded are troposcatterers causing irregularities in the troposphere, scattering caused by meteors, refraction in ionized regions and layers of the ionosphere, and reflection from the ionosphere.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 19], [20, 29], [30, 41], [42, 44], [45, 53], [54, 57], [58, 73], [74, 81], [82, 96], [97, 99], [100, 103], [104, 115], [115, 116], [117, 127], [128, 134], [135, 137], [138, 145], [145, 146], [147, 157], [158, 160], [161, 168], [169, 176], [177, 180], [181, 187], [188, 190], [191, 194], [195, 205], [205, 206], [207, 210], [211, 221], [222, 226], [227, 230], [231, 241], [241, 242]]}
{"doc_key": "ai-dev-349", "ner": [[0, 2, "field"], [4, 4, "field"], [10, 10, "field"], [12, 13, "field"], [15, 16, "field"], [18, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 10, 10, "part-of", "", false, false], [0, 2, 12, 13, "part-of", "", false, false], [0, 2, 15, 16, "part-of", "", false, false], [0, 2, 18, 23, "part-of", "", false, false], [4, 4, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Natural", "language", "processing", "(", "NLP", ")", "is", "a", "subfield", "of", "linguistics", ",", "computer", "science", ",", "information", "engineering", "and", "artificial", "intelligence", "that", "deals", "with", "the", "interaction", "between", "computers", "and", "human", "(", "natural", ")", "languages", ",", "in", "particular", "how", "to", "program", "computers", "to", "process", "and", "analyze", "large", "amounts", "of", "data", "in", "natural", "language", "."], "sentence-detokenized": "Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering and artificial intelligence that deals with the interaction between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of data in natural language.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [29, 32], [32, 33], [34, 36], [37, 38], [39, 47], [48, 50], [51, 62], [62, 63], [64, 72], [73, 80], [80, 81], [82, 93], [94, 105], [106, 109], [110, 120], [121, 133], [134, 138], [139, 144], [145, 149], [150, 153], [154, 165], [166, 173], [174, 183], [184, 187], [188, 193], [194, 195], [195, 202], [202, 203], [204, 213], [213, 214], [215, 217], [218, 228], [229, 232], [233, 235], [236, 243], [244, 253], [254, 256], [257, 264], [265, 268], [269, 276], [277, 282], [283, 290], [291, 293], [294, 298], [299, 301], [302, 309], [310, 318], [318, 319]]}
{"doc_key": "ai-dev-350", "ner": [[8, 9, "organisation"], [12, 13, "organisation"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "active", "youth", "-", "led", "climate", "groups", "include", "Extinction", "Rebellion", ",", "the", "Sunrise", "Movement", ",", "SustainUS", "and", "others", "that", "operate", "at", "both", "the", "transnational", "and", "local", "levels", "."], "sentence-detokenized": "Other active youth-led climate groups include Extinction Rebellion, the Sunrise Movement, SustainUS and others that operate at both the transnational and local levels.", "token2charspan": [[0, 5], [6, 12], [13, 18], [18, 19], [19, 22], [23, 30], [31, 37], [38, 45], [46, 56], [57, 66], [66, 67], [68, 71], [72, 79], [80, 88], [88, 89], [90, 99], [100, 103], [104, 110], [111, 115], [116, 123], [124, 126], [127, 131], [132, 135], [136, 149], [150, 153], [154, 159], [160, 166], [166, 167]]}
