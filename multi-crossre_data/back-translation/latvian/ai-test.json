{"doc_key": "ai-test-1", "ner": [[6, 8, "algorithm"], [10, 11, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "approaches", "to", "generative", "models", "include", "naive", "Bayes", "classifiers", ",", "Gaussian", "mixture", "models", ",", "variational", "autoencoders", "and", "others", "."], "sentence-detokenized": "Typical approaches to generative models include naive Bayes classifiers, Gaussian mixture models, variational autoencoders and others.", "token2charspan": [[0, 7], [8, 18], [19, 21], [22, 32], [33, 39], [40, 47], [48, 53], [54, 59], [60, 71], [71, 72], [73, 81], [82, 89], [90, 96], [96, 97], [98, 109], [110, 122], [123, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-test-2", "ner": [[5, 5, "organisation"], [10, 11, "conference"], [14, 19, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 10, 11, "role", "", false, false], [14, 19, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Finally", ",", "every", "second", "year", "ELRA", "organises", "a", "major", "conference", ",", "LREC", "-", "the", "International", "Language", "Resources", "and", "Evaluation", "Conference", "."], "sentence-detokenized": "Finally, every second year ELRA organises a major conference, LREC - the International Language Resources and Evaluation Conference.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 21], [22, 26], [27, 31], [32, 41], [42, 43], [44, 49], [50, 60], [60, 61], [62, 66], [67, 68], [69, 72], [73, 86], [87, 95], [96, 105], [106, 109], [110, 120], [121, 131], [131, 132]]}
{"doc_key": "ai-test-3", "ner": [[7, 10, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "task", "is", "usually", "to", "obtain", "a", "maximum", "likelihood", "estimate", "of", "the", "HMM", "parameters", "given", "the", "output", "sequences", "."], "sentence-detokenized": "The task is usually to obtain a maximum likelihood estimate of the HMM parameters given the output sequences.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 22], [23, 29], [30, 31], [32, 39], [40, 50], [51, 59], [60, 62], [63, 66], [67, 70], [71, 81], [82, 87], [88, 91], [92, 98], [99, 108], [108, 109]]}
{"doc_key": "ai-test-4", "ner": [[1, 1, "algorithm"], [4, 8, "algorithm"], [9, 9, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 9, 9, "compare", "", false, false], [4, 8, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Unlike", "neural", "networks", "and", "support", "vector", "machines", ",", "the", "AdaBoost", "training", "process", "selects", "only", "those", "features", "that", "are", "known", "to", "improve", "the", "predictive", "power", "of", "the", "model", "by", "reducing", "dimensionality", "and", "potentially", "improving", "runtime", ",", "as", "irrelevant", "features", "do", "not", "need", "to", "be", "computed", "."], "sentence-detokenized": "Unlike neural networks and support vector machines, the AdaBoost training process selects only those features that are known to improve the predictive power of the model by reducing dimensionality and potentially improving runtime, as irrelevant features do not need to be computed.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 26], [27, 34], [35, 41], [42, 50], [50, 51], [52, 55], [56, 64], [65, 73], [74, 81], [82, 89], [90, 94], [95, 100], [101, 109], [110, 114], [115, 118], [119, 124], [125, 127], [128, 135], [136, 139], [140, 150], [151, 156], [157, 159], [160, 163], [164, 169], [170, 172], [173, 181], [182, 196], [197, 200], [201, 212], [213, 222], [223, 230], [230, 231], [232, 234], [235, 245], [246, 254], [255, 257], [258, 261], [262, 266], [267, 269], [270, 272], [273, 281], [281, 282]]}
{"doc_key": "ai-test-5", "ner": [[0, 0, "misc"], [10, 14, "misc"], [15, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 14, "part-of", "", false, false], [10, 14, 15, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponymy", "is", "one", "of", "the", "possible", "word", "-", "class", "relationships", "in", "the", "semantic", "network", "of", "the", "Word", "Net", "database", "."], "sentence-detokenized": "Troponymy is one of the possible word-class relationships in the semantic network of the WordNet database.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 19], [20, 23], [24, 32], [33, 37], [37, 38], [38, 43], [44, 57], [58, 60], [61, 64], [65, 73], [74, 81], [82, 84], [85, 88], [89, 93], [93, 96], [97, 105], [105, 106]]}
{"doc_key": "ai-test-6", "ner": [[6, 8, "task"], [9, 11, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 9, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Frame", "language", "is", "a", "technology", "used", "to", "represent", "knowledge", "in", "artificial", "intelligence", "."], "sentence-detokenized": "Frame language is a technology used to represent knowledge in artificial intelligence.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 19], [20, 30], [31, 35], [36, 38], [39, 48], [49, 58], [59, 61], [62, 72], [73, 85], [85, 86]]}
{"doc_key": "ai-test-7", "ner": [[0, 1, "metrics"], [5, 7, "metrics"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 5, 7, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "the", "bilingual", "evaluation", "study", "in", "the", "calculation", "of", "the", "brevity", "penalty", ",", "as", "small", "variations", "in", "translation", "length", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from the bilingual evaluation study in the calculation of the brevity penalty, as small variations in translation length do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 26], [27, 36], [37, 47], [48, 53], [54, 56], [57, 60], [61, 72], [73, 75], [76, 79], [80, 87], [88, 95], [95, 96], [97, 99], [100, 105], [106, 116], [117, 119], [120, 131], [132, 138], [139, 141], [142, 145], [146, 152], [153, 156], [157, 164], [165, 170], [171, 173], [174, 178], [178, 179]]}
{"doc_key": "ai-test-8", "ner": [[15, 16, "algorithm"], [19, 21, "algorithm"], [31, 32, "field"], [42, 43, "algorithm"], [45, 47, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 16, 31, 32, "usage", "", false, false], [19, 21, 31, 32, "usage", "", false, false], [42, 43, 31, 32, "type-of", "", false, false], [45, 47, 31, 32, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "model", "is", "initially", "fitted", "to", "a", "training", "dataset", ",", "The", "model", "(", "e.g.", "a", "neural", "network", "or", "a", "naive", "Bayes", "classifier", ")", "is", "trained", "on", "the", "training", "dataset", "using", "a", "supervised", "learning", "method", ",", "for", "example", "using", "optimisation", "techniques", "such", "as", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The model is initially fitted to a training dataset, The model (e.g. a neural network or a naive Bayes classifier) is trained on the training dataset using a supervised learning method, for example using optimisation techniques such as gradient descent or stochastic gradient descent.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 22], [23, 29], [30, 32], [33, 34], [35, 43], [44, 51], [51, 52], [53, 56], [57, 62], [63, 64], [64, 68], [69, 70], [71, 77], [78, 85], [86, 88], [89, 90], [91, 96], [97, 102], [103, 113], [113, 114], [115, 117], [118, 125], [126, 128], [129, 132], [133, 141], [142, 149], [150, 155], [156, 157], [158, 168], [169, 177], [178, 184], [184, 185], [186, 189], [190, 197], [198, 203], [204, 216], [217, 227], [228, 232], [233, 235], [236, 244], [245, 252], [253, 255], [256, 266], [267, 275], [276, 283], [283, 284]]}
{"doc_key": "ai-test-9", "ner": [[0, 0, "product"], [8, 9, "task"], [11, 11, "task"], [13, 15, "task"], [17, 18, "task"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 0, "usage", "", true, false], [11, 11, 0, 0, "usage", "", true, false], [13, 15, 0, 0, "usage", "", true, false], [17, 18, 0, 0, "usage", "", true, false], [24, 26, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "has", "been", "used", "in", "applications", "such", "as", "question", "answering", ",", "paraphrasing", ",", "text", "inference", "recognition", "and", "information", "extraction", ",", "either", "directly", "or", "through", "semantic", "role", "labelling", "tools", "."], "sentence-detokenized": "FrameNet has been used in applications such as question answering, paraphrasing, text inference recognition and information extraction, either directly or through semantic role labelling tools.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 25], [26, 38], [39, 43], [44, 46], [47, 55], [56, 65], [65, 66], [67, 79], [79, 80], [81, 85], [86, 95], [96, 107], [108, 111], [112, 123], [124, 134], [134, 135], [136, 142], [143, 151], [152, 154], [155, 162], [163, 171], [172, 176], [177, 186], [187, 192], [192, 193]]}
{"doc_key": "ai-test-10", "ner": [[5, 6, "field"], [11, 11, "misc"], [14, 14, "product"], [17, 17, "misc"], [20, 20, "product"], [23, 24, "field"], [27, 27, "product"], [30, 32, "misc"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [42, 43, "misc"], [47, 48, "product"], [50, 51, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[14, 14, 11, 11, "general-affiliation", "", false, false], [20, 20, 17, 17, "general-affiliation", "", false, false], [27, 27, 23, 24, "general-affiliation", "", false, false], [35, 35, 30, 32, "type-of", "", false, false], [37, 37, 30, 32, "type-of", "", false, false], [39, 39, 30, 32, "type-of", "", false, false], [47, 48, 42, 43, "general-affiliation", "", false, false], [50, 51, 42, 43, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["This", "includes", "software", "such", "as", "data", "analysis", "and", "extraction", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "general", "audit", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "software", "(", "e.g.", "Crystal", "Reports", "and", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "This includes software such as data analysis and extraction tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), general audit software (e.g. ACL, Arbutus, EAS), business intelligence software (e.g. Crystal Reports and Business Objects), etc.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 27], [28, 30], [31, 35], [36, 44], [45, 48], [49, 59], [60, 65], [65, 66], [67, 79], [80, 81], [81, 85], [86, 91], [91, 92], [92, 93], [94, 103], [104, 105], [105, 109], [110, 116], [116, 117], [117, 118], [119, 130], [131, 139], [140, 141], [141, 145], [146, 149], [149, 150], [150, 151], [152, 159], [160, 165], [166, 174], [175, 176], [176, 180], [181, 184], [184, 185], [186, 193], [193, 194], [195, 198], [198, 199], [199, 200], [201, 209], [210, 222], [223, 231], [232, 233], [233, 237], [238, 245], [246, 253], [254, 257], [258, 266], [267, 274], [274, 275], [275, 276], [277, 280], [280, 281]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 8, "researcher"], [10, 10, "organisation"], [14, 15, "product"], [20, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 8, "origin", "", false, false], [5, 8, 10, 10, "role", "", false, false], [14, 15, 20, 21, "type-of", "", false, false], [20, 21, 5, 8, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", ",", "founded", "by", "Rodney", "Brooks", "(", "formerly", "of", "iRobot", ")", ",", "introduced", "Baxter", "in", "September", "2012", ",", "an", "industrial", "robot", "designed", "to", "interact", "safely", "with", "people", "working", "nearby", "and", "programmable", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "Rethink Robotics, founded by Rodney Brooks (formerly of iRobot), introduced Baxter in September 2012, an industrial robot designed to interact safely with people working nearby and programmable to perform simple tasks.", "token2charspan": [[0, 7], [8, 16], [16, 17], [18, 25], [26, 28], [29, 35], [36, 42], [43, 44], [44, 52], [53, 55], [56, 62], [62, 63], [63, 64], [65, 75], [76, 82], [83, 85], [86, 95], [96, 100], [100, 101], [102, 104], [105, 115], [116, 121], [122, 130], [131, 133], [134, 142], [143, 149], [150, 154], [155, 161], [162, 169], [170, 176], [177, 180], [181, 193], [194, 196], [197, 204], [205, 211], [212, 217], [217, 218]]}
{"doc_key": "ai-test-12", "ner": [[1, 2, "field"], [5, 6, "task"], [8, 9, "task"], [11, 14, "task"], [16, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 30, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 6, 1, 2, "part-of", "task_part_of_field", false, false], [8, 9, 1, 2, "part-of", "task_part_of_field", false, false], [11, 14, 1, 2, "part-of", "task_part_of_field", false, false], [16, 18, 1, 2, "part-of", "task_part_of_field", false, false], [20, 21, 1, 2, "part-of", "task_part_of_field", false, false], [23, 24, 1, 2, "part-of", "task_part_of_field", false, false], [26, 30, 1, 2, "part-of", "task_part_of_field", false, false], [35, 36, 1, 2, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Typical", "text", "mining", "tasks", "include", "text", "categorisation", ",", "text", "clustering", ",", "concept", "/", "entity", "extraction", ",", "granular", "taxonomy", "construction", ",", "sentiment", "analysis", ",", "document", "summarisation", "and", "entity", "relationship", "modelling", "(", "i.e.", "learning", "the", "relationships", "between", "named", "entities", ")", "."], "sentence-detokenized": "Typical text mining tasks include text categorisation, text clustering, concept/entity extraction, granular taxonomy construction, sentiment analysis, document summarisation and entity relationship modelling (i.e. learning the relationships between named entities).", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 25], [26, 33], [34, 38], [39, 53], [53, 54], [55, 59], [60, 70], [70, 71], [72, 79], [79, 80], [80, 86], [87, 97], [97, 98], [99, 107], [108, 116], [117, 129], [129, 130], [131, 140], [141, 149], [149, 150], [151, 159], [160, 173], [174, 177], [178, 184], [185, 197], [198, 207], [208, 209], [209, 213], [214, 222], [223, 226], [227, 240], [241, 248], [249, 254], [255, 263], [263, 264], [264, 265]]}
{"doc_key": "ai-test-13", "ner": [[9, 9, "metrics"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "for", "such", "systems", ",", "highlighting", "reduces", "the", "accuracy", "or", "negative", "TRUE", "."], "sentence-detokenized": "However, for such systems, highlighting reduces the accuracy or negative TRUE.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 17], [18, 25], [25, 26], [27, 39], [40, 47], [48, 51], [52, 60], [61, 63], [64, 72], [73, 77], [77, 78]]}
{"doc_key": "ai-test-14", "ner": [[4, 5, "task"], [7, 8, "misc"], [13, 14, "misc"], [25, 25, "product"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 4, 5, "temporal", "", false, false], [13, 14, 7, 8, "named", "", false, false], [25, 25, 7, 8, "usage", "", false, false], [27, 27, 7, 8, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "special", "case", "of", "keyword", "spotting", "is", "wake", "word", "(", "also", "known", "as", "hot", "word", ")", "detection", ",", "used", "by", "personal", "digital", "assistants", "such", "as", "Alexa", "or", "Siri", "to", "wake", "up", "when", "their", "name", "is", "spoken", "."], "sentence-detokenized": "A special case of keyword spotting is wake word (also known as hot word) detection, used by personal digital assistants such as Alexa or Siri to wake up when their name is spoken.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 17], [18, 25], [26, 34], [35, 37], [38, 42], [43, 47], [48, 49], [49, 53], [54, 59], [60, 62], [63, 66], [67, 71], [71, 72], [73, 82], [82, 83], [84, 88], [89, 91], [92, 100], [101, 108], [109, 119], [120, 124], [125, 127], [128, 133], [134, 136], [137, 141], [142, 144], [145, 149], [150, 152], [153, 157], [158, 163], [164, 168], [169, 171], [172, 178], [178, 179]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [9, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "and", "Java", "."], "sentence-detokenized": "Prova is an open source programming language that combines Prolog and Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 16], [17, 23], [24, 35], [36, 44], [45, 49], [50, 58], [59, 65], [66, 69], [70, 74], [74, 75]]}
{"doc_key": "ai-test-16", "ner": [[3, 4, "organisation"], [9, 9, "organisation"], [16, 19, "product"], [20, 23, "country"], [38, 38, "organisation"], [49, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 9, 9, "part-of", "", false, false], [3, 4, 9, 9, "role", "sells", false, false], [3, 4, 20, 23, "role", "sells_to", false, false], [38, 38, 49, 50, "opposite", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "1987", ",", "Tocibai", "Machine", ",", "a", "subsidiary", "of", "Toshiba", ",", "was", "accused", "of", "illegally", "selling", "CNC", "milling", "cutters", "to", "the", "Soviet", "Union", "for", "use", "in", "the", "manufacture", "of", "very", "quiet", "submarine", "propellers", ",", "in", "violation", "of", "the", "CoCom", "Agreement", "-", "an", "international", "embargo", "imposed", "on", "certain", "countries", "by", "the", "COMECON", "countries", "."], "sentence-detokenized": "In 1987, Tocibai Machine, a subsidiary of Toshiba, was accused of illegally selling CNC milling cutters to the Soviet Union for use in the manufacture of very quiet submarine propellers, in violation of the CoCom Agreement - an international embargo imposed on certain countries by the COMECON countries.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 24], [24, 25], [26, 27], [28, 38], [39, 41], [42, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 75], [76, 83], [84, 87], [88, 95], [96, 103], [104, 106], [107, 110], [111, 117], [118, 123], [124, 127], [128, 131], [132, 134], [135, 138], [139, 150], [151, 153], [154, 158], [159, 164], [165, 174], [175, 185], [185, 186], [187, 189], [190, 199], [200, 202], [203, 206], [207, 212], [213, 222], [223, 224], [225, 227], [228, 241], [242, 249], [250, 257], [258, 260], [261, 268], [269, 278], [279, 281], [282, 285], [286, 293], [294, 303], [303, 304]]}
{"doc_key": "ai-test-17", "ner": [[0, 1, "researcher"], [7, 10, "product"], [20, 25, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 0, 1, "artifact", "", false, false], [7, 10, 20, 25, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Engelberger", "'s", "most", "famous", "co-invention", ",", "the", "industrial", "robotic", "arm", "Unimate", ",", "was", "one", "of", "the", "first", "inductees", "into", "the", "Robot", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberger's most famous co-invention, the industrial robotic arm Unimate, was one of the first inductees into the Robot Hall of Fame in 2003.", "token2charspan": [[0, 11], [11, 13], [14, 18], [19, 25], [26, 38], [38, 39], [40, 43], [44, 54], [55, 62], [63, 66], [67, 74], [74, 75], [76, 79], [80, 83], [84, 86], [87, 90], [91, 96], [97, 106], [107, 111], [112, 115], [116, 121], [122, 126], [127, 129], [130, 134], [135, 137], [138, 142], [142, 143]]}
{"doc_key": "ai-test-18", "ner": [[3, 4, "misc"], [10, 10, "misc"], [12, 12, "person"], [17, 18, "field"], [19, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 10, 10, "usage", "", false, false], [12, 12, 17, 18, "role", "", false, false], [17, 18, 19, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Initially", "based", "on", "static", "html", "control", "of", "web", "pages", "using", "CGI", ",", "Dalton", "'s", "work", "introduced", "an", "augmented", "reality", "Java", "interface", "with", "limited", "success", "."], "sentence-detokenized": "Initially based on static html control of web pages using CGI, Dalton's work introduced an augmented reality Java interface with limited success.", "token2charspan": [[0, 9], [10, 15], [16, 18], [19, 25], [26, 30], [31, 38], [39, 41], [42, 45], [46, 51], [52, 57], [58, 61], [61, 62], [63, 69], [69, 71], [72, 76], [77, 87], [88, 90], [91, 100], [101, 108], [109, 113], [114, 123], [124, 128], [129, 136], [137, 144], [144, 145]]}
{"doc_key": "ai-test-19", "ner": [[4, 6, "task"], [11, 11, "organisation"], [24, 24, "conference"], [28, 28, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 11, 11, "origin", "", false, false], [24, 24, 28, 28, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["First", "publication", "on", "the", "LMF", "specification", "since", "it", "was", "ratified", "by", "ISO", "(", "this", "paper", "became", "(", "in", "2015", ")", "the", "9th", "most", "cited", "LREC", "conference", "paper", "among", "LREC", "papers", ")", ":"], "sentence-detokenized": "First publication on the LMF specification since it was ratified by ISO (this paper became (in 2015) the 9th most cited LREC conference paper among LREC papers):", "token2charspan": [[0, 5], [6, 17], [18, 20], [21, 24], [25, 28], [29, 42], [43, 48], [49, 51], [52, 55], [56, 64], [65, 67], [68, 71], [72, 73], [73, 77], [78, 83], [84, 90], [91, 92], [92, 94], [95, 99], [99, 100], [101, 104], [105, 108], [109, 113], [114, 119], [120, 124], [125, 135], [136, 141], [142, 147], [148, 152], [153, 159], [159, 160], [160, 161]]}
{"doc_key": "ai-test-20", "ner": [[0, 2, "metrics"], [16, 18, "metrics"], [19, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 18, 0, 2, "usage", "", false, false], [16, 18, 19, 22, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "hash", "matrix", "or", "a", "matching", "matrix", "is", "often", "used", "as", "a", "tool", "to", "validate", "the", "accuracy", "of", "a", "k", "-", "NN", "classification", "."], "sentence-detokenized": "A hash matrix or a matching matrix is often used as a tool to validate the accuracy of a k -NN classification.", "token2charspan": [[0, 1], [2, 6], [7, 13], [14, 16], [17, 18], [19, 27], [28, 34], [35, 37], [38, 43], [44, 48], [49, 51], [52, 53], [54, 58], [59, 61], [62, 70], [71, 74], [75, 83], [84, 86], [87, 88], [89, 90], [91, 92], [92, 94], [95, 109], [109, 110]]}
{"doc_key": "ai-test-21", "ner": [[0, 1, "algorithm"], [12, 12, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 15, "part-of", "", false, false], [0, 1, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", "is", "one", "of", "the", "predictive", "modelling", "approaches", "used", "in", "statistics", ",", "data", "mining", "and", "machine", "learning", "."], "sentence-detokenized": "Decision tree learning is one of the predictive modelling approaches used in statistics, data mining and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 47], [48, 57], [58, 68], [69, 73], [74, 76], [77, 87], [87, 88], [89, 93], [94, 100], [101, 104], [105, 112], [113, 121], [121, 122]]}
{"doc_key": "ai-test-22", "ner": [[4, 4, "misc"], [15, 16, "field"], [20, 22, "algorithm"], [24, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 15, 16, "related-to", "", true, false], [20, 22, 15, 16, "type-of", "", false, false], [24, 24, 15, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["At", "runtime", ",", "the", "prosody", "of", "the", "sentence", "is", "superimposed", "on", "these", "minimal", "units", "using", "signal", "processing", "techniques", "such", "as", "linear", "predicative", "coding", ",", "PSOLA", "."], "sentence-detokenized": "At runtime, the prosody of the sentence is superimposed on these minimal units using signal processing techniques such as linear predicative coding, PSOLA.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 39], [40, 42], [43, 55], [56, 58], [59, 64], [65, 72], [73, 78], [79, 84], [85, 91], [92, 102], [103, 113], [114, 118], [119, 121], [122, 128], [129, 140], [141, 147], [147, 148], [149, 154], [154, 155]]}
{"doc_key": "ai-test-23", "ner": [[3, 4, "field"], [6, 8, "field"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 3, 4, "usage", "", true, false], [17, 18, 6, 8, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "approach", "used", "artificial", "intelligence", "and", "machine", "learning", "to", "allow", "researchers", "to", "visually", "compare", "normal", "and", "thermal", "facial", "images", "."], "sentence-detokenized": "This approach used artificial intelligence and machine learning to allow researchers to visually compare normal and thermal facial images.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 29], [30, 42], [43, 46], [47, 54], [55, 63], [64, 66], [67, 72], [73, 84], [85, 87], [88, 96], [97, 104], [105, 111], [112, 115], [116, 123], [124, 130], [131, 137], [137, 138]]}
{"doc_key": "ai-test-24", "ner": [[0, 2, "field"], [4, 5, "algorithm"], [10, 11, "task"], [15, 18, "misc"], [24, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 0, 2, "part-of", "", false, false], [4, 5, 10, 11, "topic", "", false, false], [10, 11, 15, 18, "origin", "", false, false], [24, 25, 0, 2, "part-of", "", false, false], [24, 25, 4, 5, "topic", "", false, false], [27, 28, 0, 2, "part-of", "", false, false], [27, 28, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "computer", "science", ",", "evolutionary", "computation", "is", "a", "group", "of", "global", "optimisation", "algorithms", "inspired", "by", "biological", "evolution", ",", "as", "well", "as", "a", "sub-discipline", "of", "artificial", "intelligence", "and", "soft", "computing", "that", "studies", "these", "algorithms", "."], "sentence-detokenized": "In computer science, evolutionary computation is a group of global optimisation algorithms inspired by biological evolution, as well as a sub-discipline of artificial intelligence and soft computing that studies these algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 33], [34, 45], [46, 48], [49, 50], [51, 56], [57, 59], [60, 66], [67, 79], [80, 90], [91, 99], [100, 102], [103, 113], [114, 123], [123, 124], [125, 127], [128, 132], [133, 135], [136, 137], [138, 152], [153, 155], [156, 166], [167, 179], [180, 183], [184, 188], [189, 198], [199, 203], [204, 211], [212, 217], [218, 228], [228, 229]]}
{"doc_key": "ai-test-25", "ner": [[8, 9, "metrics"], [15, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "a", "measurement", "based", "on", "a", "mixing", "matrix", "can", "be", "combined", "with", "the", "root", "mean", "square", "error", "estimated", "between", "the", "raw", "model", "results", "and", "the", "actual", "values", "."], "sentence-detokenized": "For example, a measurement based on a mixing matrix can be combined with the root mean square error estimated between the raw model results and the actual values.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 14], [15, 26], [27, 32], [33, 35], [36, 37], [38, 44], [45, 51], [52, 55], [56, 58], [59, 67], [68, 72], [73, 76], [77, 81], [82, 86], [87, 93], [94, 99], [100, 109], [110, 117], [118, 121], [122, 125], [126, 131], [132, 139], [140, 143], [144, 147], [148, 154], [155, 161], [161, 162]]}
{"doc_key": "ai-test-26", "ner": [[5, 7, "product"], [10, 10, "researcher"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 10, 10, "origin", "", false, false], [5, 7, 17, 17, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Most", "are", "the", "results", "of", "the", "word2vec", "model", "developed", "by", "Mikolov", "et", "al", ".", "or", "variants", "of", "word2vec", "."], "sentence-detokenized": "Most are the results of the word2vec model developed by Mikolov et al. or variants of word2vec.", "token2charspan": [[0, 4], [5, 8], [9, 12], [13, 20], [21, 23], [24, 27], [28, 36], [37, 42], [43, 52], [53, 55], [56, 63], [64, 66], [67, 69], [69, 70], [71, 73], [74, 82], [83, 85], [86, 94], [94, 95]]}
{"doc_key": "ai-test-27", "ner": [[0, 12, "conference"], [15, 19, "conference"], [21, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 21, 15, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["During", "this", "period", ",", "a", "total", "of", "43", "publications", "were", "recognised", "by", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "During this period, a total of 43 publications were recognised by CVPR and the International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 6], [7, 11], [12, 18], [18, 19], [20, 21], [22, 27], [28, 30], [31, 33], [34, 46], [47, 51], [52, 62], [63, 65], [66, 70], [71, 74], [75, 78], [79, 92], [93, 103], [104, 106], [107, 115], [116, 122], [123, 124], [124, 128], [128, 129], [129, 130]]}
{"doc_key": "ai-test-28", "ner": [[0, 0, "product"], [12, 12, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 12, "general-affiliation", "platform_for_education_about", false, false], [22, 23, 0, 0, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["AIBO", "has", "been", "widely", "used", "as", "a", "low", "-", "cost", "platform", "for", "AI", "education", "and", "research", "because", "it", "integrates", "a", "computer", ",", "computer", "vision", "and", "articulators", "that", "are", "much", "cheaper", "than", "conventional", "research", "robots", "."], "sentence-detokenized": "AIBO has been widely used as a low-cost platform for AI education and research because it integrates a computer, computer vision and articulators that are much cheaper than conventional research robots.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 20], [21, 25], [26, 28], [29, 30], [31, 34], [34, 35], [35, 39], [40, 48], [49, 52], [53, 55], [56, 65], [66, 69], [70, 78], [79, 86], [87, 89], [90, 100], [101, 102], [103, 111], [111, 112], [113, 121], [122, 128], [129, 132], [133, 145], [146, 150], [151, 154], [155, 159], [160, 167], [168, 172], [173, 185], [186, 194], [195, 201], [201, 202]]}
{"doc_key": "ai-test-29", "ner": [[6, 11, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "was", "Programme", "Chair", "of", "the", "International", "Conference", "on", "Computer", "Vision", "2021", "."], "sentence-detokenized": "She was Programme Chair of the International Conference on Computer Vision 2021.", "token2charspan": [[0, 3], [4, 7], [8, 17], [18, 23], [24, 26], [27, 30], [31, 44], [45, 55], [56, 58], [59, 67], [68, 74], [75, 79], [79, 80]]}
{"doc_key": "ai-test-30", "ner": [[1, 1, "researcher"], [6, 7, "organisation"], [16, 18, "organisation"], [24, 25, "organisation"], [36, 39, "product"], [41, 41, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 1, 6, 7, "role", "", false, false], [1, 1, 16, 18, "role", "", true, false], [16, 18, 24, 25, "role", "develops_with", false, false], [36, 39, 16, 18, "artifact", "", false, false], [41, 41, 36, 39, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["After", "Scheinman", "received", "a", "grant", "from", "Unimation", "to", "develop", "his", "designs", ",", "he", "sold", "them", "to", "Unimation", ",", "which", ",", "with", "the", "support", "of", "General", "Motors", ",", "further", "developed", "them", "and", "later", "marketed", "them", "as", "the", "Programmable", "Universal", "Assembly", "Machine", "(", "PUMA", ")", "."], "sentence-detokenized": "After Scheinman received a grant from Unimation to develop his designs, he sold them to Unimation, which, with the support of General Motors, further developed them and later marketed them as the Programmable Universal Assembly Machine (PUMA).", "token2charspan": [[0, 5], [6, 15], [16, 24], [25, 26], [27, 32], [33, 37], [38, 47], [48, 50], [51, 58], [59, 62], [63, 70], [70, 71], [72, 74], [75, 79], [80, 84], [85, 87], [88, 97], [97, 98], [99, 104], [104, 105], [106, 110], [111, 114], [115, 122], [123, 125], [126, 133], [134, 140], [140, 141], [142, 149], [150, 159], [160, 164], [165, 168], [169, 174], [175, 183], [184, 188], [189, 191], [192, 195], [196, 208], [209, 218], [219, 227], [228, 235], [236, 237], [237, 241], [241, 242], [242, 243]]}
{"doc_key": "ai-test-31", "ner": [[11, 12, "task"], [14, 16, "task"], [0, 0, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 12, "general-affiliation", "works_with", false, false], [0, 0, 14, 16, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Gebel", "(", "2009", ")", "gives", "an", "overview", "of", "calibration", "methods", "for", "binary", "classification", "and", "multiclass", "classification", "tasks", "."], "sentence-detokenized": "Gebel (2009) gives an overview of calibration methods for binary classification and multiclass classification tasks.", "token2charspan": [[0, 5], [6, 7], [7, 11], [11, 12], [13, 18], [19, 21], [22, 30], [31, 33], [34, 45], [46, 53], [54, 57], [58, 64], [65, 79], [80, 83], [84, 94], [95, 109], [110, 115], [115, 116]]}
{"doc_key": "ai-test-32", "ner": [[4, 6, "task"], [8, 8, "task"], [11, 12, "task"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 4, 6, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["His", "research", "interests", "include", "optical", "character", "recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "speech", "recognition", "technology", "and", "electronic", "keyboard", "tools", "."], "sentence-detokenized": "His research interests include optical character recognition (OCR), speech synthesis, speech recognition technology and electronic keyboard tools.", "token2charspan": [[0, 3], [4, 12], [13, 22], [23, 30], [31, 38], [39, 48], [49, 60], [61, 62], [62, 65], [65, 66], [66, 67], [68, 74], [75, 84], [84, 85], [86, 92], [93, 104], [105, 115], [116, 119], [120, 130], [131, 139], [140, 145], [145, 146]]}
{"doc_key": "ai-test-33", "ner": [[8, 12, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "newer", "and", "more", "advanced", "methods", ",", "the", "Kaldi", "toolkit", "can", "be", "used", "."], "sentence-detokenized": "For newer and more advanced methods, the Kaldi toolkit can be used.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 18], [19, 27], [28, 35], [35, 36], [37, 40], [41, 46], [47, 54], [55, 58], [59, 61], [62, 66], [66, 67]]}
{"doc_key": "ai-test-34", "ner": [[0, 2, "researcher"], [8, 10, "organisation"], [16, 17, "organisation"], [22, 24, "organisation"], [27, 28, "researcher"], [32, 35, "organisation"], [40, 44, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 8, 10, "role", "", false, false], [0, 2, 16, 17, "role", "", false, false], [0, 2, 22, 24, "role", "", false, false], [0, 2, 32, 35, "role", "", false, false], [0, 2, 40, 44, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson", "-", "Laird", "is", "a", "Fellow", "of", "the", "American", "Philosophical", "Society", ",", "a", "Fellow", "of", "the", "Royal", "Society", ",", "a", "Fellow", "of", "the", "British", "Academy", ",", "a", "William", "James", "Fellow", "of", "the", "Association", "for", "Psychological", "Science", "and", "a", "Fellow", "of", "the", "Society", "for", "Cognitive", "Science", "."], "sentence-detokenized": "Johnson-Laird is a Fellow of the American Philosophical Society, a Fellow of the Royal Society, a Fellow of the British Academy, a William James Fellow of the Association for Psychological Science and a Fellow of the Society for Cognitive Science.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 66], [67, 73], [74, 76], [77, 80], [81, 86], [87, 94], [94, 95], [96, 97], [98, 104], [105, 107], [108, 111], [112, 119], [120, 127], [127, 128], [129, 130], [131, 138], [139, 144], [145, 151], [152, 154], [155, 158], [159, 170], [171, 174], [175, 188], [189, 196], [197, 200], [201, 202], [203, 209], [210, 212], [213, 216], [217, 224], [225, 228], [229, 238], [239, 246], [246, 247]]}
{"doc_key": "ai-test-35", "ner": [[0, 8, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [20, 22, "algorithm"], [25, 29, "task"], [31, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 0, 8, "physical", "", false, false], [10, 11, 0, 8, "temporal", "", false, false], [13, 14, 0, 8, "physical", "", false, false], [13, 14, 0, 8, "temporal", "", false, false], [16, 17, 0, 8, "physical", "", false, false], [16, 17, 0, 8, "temporal", "", false, false], [20, 22, 16, 17, "role", "extends", false, false], [25, 29, 16, 17, "role", "extends", false, false], [31, 31, 25, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["At", "the", "2010", "IEEE", "International", "Conference", "on", "Image", "Processing", ",", "Rui", "Hu", ",", "Mark", "Banard", "and", "John", "Collomos", "extended", "the", "HOG", "descriptor", "for", "use", "in", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the 2010 IEEE International Conference on Image Processing, Rui Hu, Mark Banard and John Collomos extended the HOG descriptor for use in sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 30], [31, 41], [42, 44], [45, 50], [51, 61], [61, 62], [63, 66], [67, 69], [69, 70], [71, 75], [76, 82], [83, 86], [87, 91], [92, 100], [101, 109], [110, 113], [114, 117], [118, 128], [129, 132], [133, 136], [137, 139], [140, 146], [146, 147], [147, 152], [153, 158], [159, 168], [169, 170], [170, 174], [174, 175], [175, 176]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 7, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "uses", "a", "modified", "form", "of", "accuracy", "to", "compare", "a", "candidate", "translation", "with", "several", "reference", "translations", "."], "sentence-detokenized": "BLEU uses a modified form of accuracy to compare a candidate translation with several reference translations.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 20], [21, 25], [26, 28], [29, 37], [38, 40], [41, 48], [49, 50], [51, 60], [61, 72], [73, 77], [78, 85], [86, 95], [96, 108], [108, 109]]}
{"doc_key": "ai-test-37", "ner": [[31, 35, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "case", "of", "a", "general", "basis", "space", "math", "(", "Y", ",\\", "mathcal", "{", "B", "},\\", "nu", ")", "/", "math", "(", "i.e.", "a", "basis", "space", "that", "is", "not", "countable", ")", ",", "relative", "entropy", "is", "usually", "considered", "."], "sentence-detokenized": "In the case of a general basis space math (Y,\\ mathcal {B},\\ nu) / math (i.e. a basis space that is not countable), relative entropy is usually considered.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 36], [37, 41], [42, 43], [43, 44], [44, 46], [47, 54], [55, 56], [56, 57], [57, 60], [61, 63], [63, 64], [65, 66], [67, 71], [72, 73], [73, 77], [78, 79], [80, 85], [86, 91], [92, 96], [97, 99], [100, 103], [104, 113], [113, 114], [114, 115], [116, 124], [125, 132], [133, 135], [136, 143], [144, 154], [154, 155]]}
{"doc_key": "ai-test-38", "ner": [[8, 8, "country"], [9, 11, "organisation"], [13, 13, "organisation"], [21, 21, "country"], [16, 17, "organisation"], [19, 19, "organisation"], [23, 25, "organisation"], [28, 28, "country"], [29, 34, "organisation"], [36, 36, "organisation"], [42, 42, "misc"], [43, 43, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[9, 11, 8, 8, "physical", "", false, false], [13, 13, 9, 11, "named", "", false, false], [16, 17, 21, 21, "physical", "", false, false], [19, 19, 16, 17, "named", "", false, false], [29, 34, 28, 28, "physical", "", false, false], [36, 36, 29, 34, "named", "", false, false], [42, 42, 43, 43, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "October", "2011", ",", "existing", "partnerships", "with", "the", "US", "National", "Park", "Service", "(", "NPS", ")", ",", "Historic", "Scotland", "(", "HS", ")", ",", "the", "World", "Monuments", "Fund", "and", "the", "Mexican", "National", "Institute", "of", "Anthropology", "and", "History", "(", "INAH", ")", "were", "significantly", "expanded", ",", "CyArk", "website", "."], "sentence-detokenized": "In October 2011, existing partnerships with the US National Park Service (NPS), Historic Scotland (HS), the World Monuments Fund and the Mexican National Institute of Anthropology and History (INAH) were significantly expanded, CyArk website.", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [17, 25], [26, 38], [39, 43], [44, 47], [48, 50], [51, 59], [60, 64], [65, 72], [73, 74], [74, 77], [77, 78], [78, 79], [80, 88], [89, 97], [98, 99], [99, 101], [101, 102], [102, 103], [104, 107], [108, 113], [114, 123], [124, 128], [129, 132], [133, 136], [137, 144], [145, 153], [154, 163], [164, 166], [167, 179], [180, 183], [184, 191], [192, 193], [193, 197], [197, 198], [199, 203], [204, 217], [218, 226], [226, 227], [228, 233], [234, 241], [241, 242]]}
{"doc_key": "ai-test-39", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [11, 11, "product"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 11, 11, "part-of", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [11, 11, 6, 7, "general-affiliation", "", false, false], [13, 13, 6, 7, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kernel", "SVMs", "are", "available", "in", "many", "machine", "learning", "toolkits", ",", "including", "LIBSVM", ",", "MATLAB", "and", "others", "."], "sentence-detokenized": "Kernel SVMs are available in many machine learning toolkits, including LIBSVM, MATLAB and others.", "token2charspan": [[0, 6], [7, 11], [12, 15], [16, 25], [26, 28], [29, 33], [34, 41], [42, 50], [51, 59], [59, 60], [61, 70], [71, 77], [77, 78], [79, 85], [86, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-test-40", "ner": [[2, 3, "misc"], [12, 13, "location"], [15, 15, "location"], [17, 17, "country"], [22, 25, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 12, 13, "physical", "", false, false], [2, 3, 22, 25, "temporal", "", false, false], [12, 13, 15, 15, "physical", "", false, false], [15, 15, 17, 17, "physical", "", false, false], [22, 25, 12, 13, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2009", "Leebner", "Prize", "was", "held", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", ",", "Brighton", ",", "UK", ",", "in", "conjunction", "with", "the", "Interspeech", "2009", "conference", "."], "sentence-detokenized": "The 2009 Leebner Prize was held on 6 September 2009 at the Brighton Centre, Brighton, UK, in conjunction with the Interspeech 2009 conference.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 26], [27, 31], [32, 34], [35, 36], [37, 46], [47, 51], [52, 54], [55, 58], [59, 67], [68, 74], [74, 75], [76, 84], [84, 85], [86, 88], [88, 89], [90, 92], [93, 104], [105, 109], [110, 113], [114, 125], [126, 130], [131, 141], [141, 142]]}
{"doc_key": "ai-test-41", "ner": [[0, 3, "product"], [10, 10, "product"], [18, 21, "product"], [16, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 22, 0, 3, "part-of", "", false, false], [16, 22, 10, 10, "part-of", "", false, false], [16, 22, 18, 21, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "QRIO", "humanoid", "robot", "was", "developed", "as", "a", "successor", "to", "AIBO", "and", "runs", "the", "same", "base", "operating", "system", ",", "R", "-", "CODE", "Aperios", "."], "sentence-detokenized": "The QRIO humanoid robot was developed as a successor to AIBO and runs the same base operating system, R-CODE Aperios.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 23], [24, 27], [28, 37], [38, 40], [41, 42], [43, 52], [53, 55], [56, 60], [61, 64], [65, 69], [70, 73], [74, 78], [79, 83], [84, 93], [94, 100], [100, 101], [102, 103], [103, 104], [104, 108], [109, 116], [116, 117]]}
{"doc_key": "ai-test-42", "ner": [[0, 1, "misc"], [6, 6, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 0, 1, "cause-effect", "", true, false], [11, 12, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Speech", "waveforms", "are", "generated", "from", "the", "HMMs", "themselves", "based", "on", "the", "maximum", "likelihood", "criterion", "."], "sentence-detokenized": "Speech waveforms are generated from the HMMs themselves based on the maximum likelihood criterion.", "token2charspan": [[0, 6], [7, 16], [17, 20], [21, 30], [31, 35], [36, 39], [40, 44], [45, 55], [56, 61], [62, 64], [65, 68], [69, 76], [77, 87], [88, 97], [97, 98]]}
{"doc_key": "ai-test-43", "ner": [[0, 1, "product"], [5, 8, "task"], [10, 12, "task"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 5, 8, "type-of", "", false, false], [0, 1, 10, 12, "type-of", "", false, false], [0, 1, 16, 16, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "is", "a", "free", "multilingual", "statistical", "machine", "translation", "and", "neural", "machine", "translation", "service", "developed", "by", "Google", "to", "translate", "text", "and", "websites", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Google Translate is a free multilingual statistical machine translation and neural machine translation service developed by Google to translate text and websites from one language to another.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 39], [40, 51], [52, 59], [60, 71], [72, 75], [76, 82], [83, 90], [91, 102], [103, 110], [111, 120], [121, 123], [124, 130], [131, 133], [134, 143], [144, 148], [149, 152], [153, 161], [162, 166], [167, 170], [171, 179], [180, 182], [183, 190], [190, 191]]}
{"doc_key": "ai-test-44", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [14, 16, "field"], [21, 23, "task"], [25, 26, "task"], [28, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[21, 23, 5, 6, "part-of", "", false, true], [21, 23, 8, 9, "part-of", "", false, true], [21, 23, 11, 12, "part-of", "", false, true], [25, 26, 5, 6, "part-of", "", false, true], [25, 26, 8, 9, "part-of", "", false, true], [25, 26, 11, 12, "part-of", "", false, true], [28, 31, 5, 6, "part-of", "", false, true], [28, 31, 8, 9, "part-of", "", false, true], [28, 31, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Skeletons", "are", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", "and", "digital", "image", "processing", "for", "purposes", "such", "as", "optical", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", "or", "compression", "."], "sentence-detokenized": "Skeletons are widely used in computer vision, image analysis, pattern recognition and digital image processing for purposes such as optical character recognition, fingerprint recognition, visual inspection or compression.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 25], [26, 28], [29, 37], [38, 44], [44, 45], [46, 51], [52, 60], [60, 61], [62, 69], [70, 81], [82, 85], [86, 93], [94, 99], [100, 110], [111, 114], [115, 123], [124, 128], [129, 131], [132, 139], [140, 149], [150, 161], [161, 162], [163, 174], [175, 186], [186, 187], [188, 194], [195, 205], [206, 208], [209, 220], [220, 221]]}
{"doc_key": "ai-test-45", "ner": [[0, 7, "conference"], [12, 15, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 7, 12, 15, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["ImageNet", "'s", "large", "-", "scale", "visual", "recognition", "challenge", "is", "a", "benchmark", "for", "object", "classification", "and", "detection", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "ImageNet's large-scale visual recognition challenge is a benchmark for object classification and detection with millions of images and hundreds of object classes.", "token2charspan": [[0, 8], [8, 10], [11, 16], [16, 17], [17, 22], [23, 29], [30, 41], [42, 51], [52, 54], [55, 56], [57, 66], [67, 70], [71, 77], [78, 92], [93, 96], [97, 106], [107, 111], [112, 120], [121, 123], [124, 130], [131, 134], [135, 143], [144, 146], [147, 153], [154, 161], [161, 162]]}
{"doc_key": "ai-test-46", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [17, 20, "misc"], [22, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 17, 20, "part-of", "", false, false], [0, 0, 22, 23, "part-of", "", false, false], [4, 5, 17, 20, "part-of", "", false, false], [4, 5, 22, 23, "part-of", "", false, false], [7, 8, 17, 20, "part-of", "", false, false], [7, 8, 22, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "along", "with", "Jeffrey", "Hinton", "and", "Jan", "Lekun", ",", "are", "considered", "by", "some", "to", "be", "the", "godfathers", "of", "artificial", "intelligence", "and", "deep", "learning", "."], "sentence-detokenized": "Bengio, along with Jeffrey Hinton and Jan Lekun, are considered by some to be the godfathers of artificial intelligence and deep learning.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 26], [27, 33], [34, 37], [38, 41], [42, 47], [47, 48], [49, 52], [53, 63], [64, 66], [67, 71], [72, 74], [75, 77], [78, 81], [82, 92], [93, 95], [96, 106], [107, 119], [120, 123], [124, 128], [129, 137], [137, 138]]}
{"doc_key": "ai-test-47", "ner": [[6, 7, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "Life", "Member", "of", "the", "IEEE", "."], "sentence-detokenized": "He is a Life Member of the IEEE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 19], [20, 22], [23, 26], [27, 31], [31, 32]]}
{"doc_key": "ai-test-48", "ner": [[0, 1, "organisation"], [15, 20, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 15, 20, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NSA", "Bethesda", "is", "responsible", "for", "the", "base", "'s", "operational", "support", "to", "its", "main", "tenant", ",", "Walter", "Reed", "National", "Military", "Medical", "Center", "."], "sentence-detokenized": "NSA Bethesda is responsible for the base's operational support to its main tenant, Walter Reed National Military Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 31], [32, 35], [36, 40], [40, 42], [43, 54], [55, 62], [63, 65], [66, 69], [70, 74], [75, 81], [81, 82], [83, 89], [90, 94], [95, 103], [104, 112], [113, 120], [121, 127], [127, 128]]}
{"doc_key": "ai-test-49", "ner": [[6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "three", "main", "learning", "paradigms", "are", "supervised", "learning", ",", "unsupervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "The three main learning paradigms are supervised learning, unsupervised learning and reinforcement learning.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 23], [24, 33], [34, 37], [38, 48], [49, 57], [57, 58], [59, 71], [72, 80], [81, 84], [85, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-50", "ner": [[3, 3, "task"], [5, 7, "task"], [11, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "control", ",", "planning", "and", "scheduling", ",", "ability", "to", "answer", "diagnostic", "and", "consumer", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", "and", "facial", "recognition", "."], "sentence-detokenized": "For example, control, planning and scheduling, ability to answer diagnostic and consumer questions, handwriting recognition, natural language understanding, speech recognition and facial recognition.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 20], [20, 21], [22, 30], [31, 34], [35, 45], [45, 46], [47, 54], [55, 57], [58, 64], [65, 75], [76, 79], [80, 88], [89, 98], [98, 99], [100, 111], [112, 123], [123, 124], [125, 132], [133, 141], [142, 155], [155, 156], [157, 163], [164, 175], [176, 179], [180, 186], [187, 198], [198, 199]]}
{"doc_key": "ai-test-51", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "he", "became", "its", "founder", "in", "1990", ")", "."], "sentence-detokenized": "In 1991, he was elected a Fellow of the Association for the Advancement of Artificial Intelligence (he became its founder in 1990).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [99, 100], [100, 102], [103, 109], [110, 113], [114, 121], [122, 124], [125, 129], [129, 130], [130, 131]]}
{"doc_key": "ai-test-52", "ner": [[8, 9, "misc"], [13, 14, "algorithm"], [25, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "by", "formulating", "the", "problem", "as", "a", "Toeplitz", "matrix", "solution", "and", "using", "Levinson", "recursion", ",", "we", "can", "estimate", "the", "filter", "with", "the", "smallest", "possible", "mean", "squared", "error", "relatively", "quickly", "."], "sentence-detokenized": "However, by formulating the problem as a Toeplitz matrix solution and using Levinson recursion, we can estimate the filter with the smallest possible mean squared error relatively quickly.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 23], [24, 27], [28, 35], [36, 38], [39, 40], [41, 49], [50, 56], [57, 65], [66, 69], [70, 75], [76, 84], [85, 94], [94, 95], [96, 98], [99, 102], [103, 111], [112, 115], [116, 122], [123, 127], [128, 131], [132, 140], [141, 149], [150, 154], [155, 162], [163, 168], [169, 179], [180, 187], [187, 188]]}
{"doc_key": "ai-test-53", "ner": [[0, 6, "conference"], [14, 19, "location"], [20, 21, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 14, 19, "physical", "", false, false], [14, 19, 20, 21, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "15th", "edition", "of", "Campus", "Party", "Spain", "will", "take", "place", "in", "July", "2011", "in", "the", "city", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "The 15th edition of Campus Party Spain will take place in July 2011 in the city of Arts and Sciences in Valencia.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 19], [20, 26], [27, 32], [33, 38], [39, 43], [44, 48], [49, 54], [55, 57], [58, 62], [63, 67], [68, 70], [71, 74], [75, 79], [80, 82], [83, 87], [88, 91], [92, 100], [101, 103], [104, 112], [112, 113]]}
{"doc_key": "ai-test-54", "ner": [[15, 15, "product"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Often", "this", "is", "usually", "only", "possible", "at", "the", "very", "end", "of", "complex", "games", "such", "as", "chess", "or", "go", ",", "because", "there", "is", "no", "computational", "way", "of", "looking", "ahead", "to", "the", "end", "of", "the", "game", ",", "except", "at", "the", "end", ",", "and", "instead", "positions", "are", "assigned", "finite", "values", "as", "estimates", "of", "the", "degree", "of", "certainty", "that", "they", "will", "allow", "one", "player", "or", "the", "other", "to", "win", "."], "sentence-detokenized": "Often this is usually only possible at the very end of complex games such as chess or go, because there is no computational way of looking ahead to the end of the game, except at the end, and instead positions are assigned finite values as estimates of the degree of certainty that they will allow one player or the other to win.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 21], [22, 26], [27, 35], [36, 38], [39, 42], [43, 47], [48, 51], [52, 54], [55, 62], [63, 68], [69, 73], [74, 76], [77, 82], [83, 85], [86, 88], [88, 89], [90, 97], [98, 103], [104, 106], [107, 109], [110, 123], [124, 127], [128, 130], [131, 138], [139, 144], [145, 147], [148, 151], [152, 155], [156, 158], [159, 162], [163, 167], [167, 168], [169, 175], [176, 178], [179, 182], [183, 186], [186, 187], [188, 191], [192, 199], [200, 209], [210, 213], [214, 222], [223, 229], [230, 236], [237, 239], [240, 249], [250, 252], [253, 256], [257, 263], [264, 266], [267, 276], [277, 281], [282, 286], [287, 291], [292, 297], [298, 301], [302, 308], [309, 311], [312, 315], [316, 321], [322, 324], [325, 328], [328, 329]]}
{"doc_key": "ai-test-55", "ner": [[3, 5, "algorithm"], [24, 25, "algorithm"], [27, 28, "algorithm"], [31, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 24, 25, "compare", "", false, false], [3, 5, 27, 28, "compare", "", false, false], [3, 5, 31, 33, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Difference", "between", "the", "multinomial", "logit", "model", "and", "many", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "with", "the", "same", "basic", "set", "-", "up", "(", "perceptron", "algorithm", ",", "support", "vector", "machines", ",", "linear", "discriminant", "analysis", ",", "etc.", ")", "."], "sentence-detokenized": "Difference between the multinomial logit model and many other methods, models, algorithms, etc. with the same basic set-up (perceptron algorithm, support vector machines, linear discriminant analysis, etc.).", "token2charspan": [[0, 10], [11, 18], [19, 22], [23, 34], [35, 40], [41, 46], [47, 50], [51, 55], [56, 61], [62, 69], [69, 70], [71, 77], [77, 78], [79, 89], [89, 90], [91, 95], [96, 100], [101, 104], [105, 109], [110, 115], [116, 119], [119, 120], [120, 122], [123, 124], [124, 134], [135, 144], [144, 145], [146, 153], [154, 160], [161, 169], [169, 170], [171, 177], [178, 190], [191, 199], [199, 200], [201, 205], [205, 206], [206, 207]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "publishes"], "sentence-detokenized": "Association for Computational Linguistics, publishes", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 52]]}
{"doc_key": "ai-test-57", "ner": [[3, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "a", "computerised", "face", "recognition", "system", ",", "each", "face", "is", "represented", "by", "a", "large", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In a computerised face recognition system, each face is represented by a large number of pixel values.", "token2charspan": [[0, 2], [3, 4], [5, 17], [18, 22], [23, 34], [35, 41], [41, 42], [43, 47], [48, 52], [53, 55], [56, 67], [68, 70], [71, 72], [73, 78], [79, 85], [86, 88], [89, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-58", "ner": [[5, 8, "person"], [12, 15, "organisation"], [21, 22, "country"], [25, 25, "person"], [35, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 8, 12, 15, "role", "", false, false], [5, 8, 21, 22, "physical", "", false, false], [25, 25, 35, 37, "origin", "", false, false], [25, 25, 35, 37, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2002", ",", "his", "son", "Daniel", "Pearl", ",", "a", "journalist", "working", "for", "the", "Wall", "Street", "Journal", ",", "was", "kidnapped", "and", "killed", "in", "Pakistan", ",", "so", "Judy", "and", "other", "family", "members", "and", "friends", "set", "up", "the", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "In 2002, his son Daniel Pearl, a journalist working for the Wall Street Journal, was kidnapped and killed in Pakistan, so Judy and other family members and friends set up the Daniel Pearl Foundation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 23], [24, 29], [29, 30], [31, 32], [33, 43], [44, 51], [52, 55], [56, 59], [60, 64], [65, 71], [72, 79], [79, 80], [81, 84], [85, 94], [95, 98], [99, 105], [106, 108], [109, 117], [117, 118], [119, 121], [122, 126], [127, 130], [131, 136], [137, 143], [144, 151], [152, 155], [156, 163], [164, 167], [168, 170], [171, 174], [175, 181], [182, 187], [188, 198], [198, 199]]}
{"doc_key": "ai-test-59", "ner": [[6, 8, "organisation"], [21, 22, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 21, 22, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "the", "end", "of", "2006", ",", "Red", "Envelope", "Entertainment", "has", "expanded", "its", "activities", "to", "produce", "original", "content", "with", "filmmakers", "such", "as", "John", "Waters", "."], "sentence-detokenized": "Since the end of 2006, Red Envelope Entertainment has expanded its activities to produce original content with filmmakers such as John Waters.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 16], [17, 21], [21, 22], [23, 26], [27, 35], [36, 49], [50, 53], [54, 62], [63, 66], [67, 77], [78, 80], [81, 88], [89, 97], [98, 105], [106, 110], [111, 121], [122, 126], [127, 129], [130, 134], [135, 141], [141, 142]]}
{"doc_key": "ai-test-60", "ner": [[6, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "building", "is", "now", "part", "of", "Beth", "Israel", "Deaconess", "Medical", "Centre", "."], "sentence-detokenized": "The building is now part of Beth Israel Deaconess Medical Centre.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 32], [33, 39], [40, 49], [50, 57], [58, 64], [64, 65]]}
{"doc_key": "ai-test-61", "ner": [[16, 16, "field"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "common", "theme", "of", "these", "works", "is", "the", "adoption", "of", "a", "sign", "-", "theoretic", "perspective", "on", "AI", "and", "knowledge", "representation", "."], "sentence-detokenized": "The common theme of these works is the adoption of a sign-theoretic perspective on AI and knowledge representation.", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 19], [20, 25], [26, 31], [32, 34], [35, 38], [39, 47], [48, 50], [51, 52], [53, 57], [57, 58], [58, 67], [68, 79], [80, 82], [83, 85], [86, 89], [90, 99], [100, 114], [114, 115]]}
{"doc_key": "ai-test-62", "ner": [[5, 7, "task"], [9, 9, "task"], [20, 22, "task"], [36, 37, "task"], [39, 42, "task"], [45, 47, "task"], [49, 49, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 7, 20, 22, "type-of", "", false, false], [5, 7, 45, 47, "compare", "", false, false], [5, 7, 45, 47, "opposite", "", false, false], [9, 9, 5, 7, "named", "", false, false], [36, 37, 45, 47, "part-of", "", false, false], [39, 42, 45, 47, "part-of", "", false, false], [45, 47, 20, 22, "type-of", "", false, false], [49, 49, 45, 47, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["For", "example", ",", "the", "term", "neural", "machine", "translation", "(", "NMT", ")", "emphasises", "the", "fact", "that", "deep", "learning", "-", "based", "approaches", "to", "machine", "translation", "learn", "sequence", "transformations", "directly", ",", "eliminating", "the", "need", "for", "intermediate", "steps", "such", "as", "word", "alignment", "and", "language", "modelling", "that", "were", "used", "in", "statistical", "machine", "translation", "(", "SMT", ")", "."], "sentence-detokenized": "For example, the term neural machine translation (NMT) emphasises the fact that deep learning-based approaches to machine translation learn sequence transformations directly, eliminating the need for intermediate steps such as word alignment and language modelling that were used in statistical machine translation (SMT).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 36], [37, 48], [49, 50], [50, 53], [53, 54], [55, 65], [66, 69], [70, 74], [75, 79], [80, 84], [85, 93], [93, 94], [94, 99], [100, 110], [111, 113], [114, 121], [122, 133], [134, 139], [140, 148], [149, 164], [165, 173], [173, 174], [175, 186], [187, 190], [191, 195], [196, 199], [200, 212], [213, 218], [219, 223], [224, 226], [227, 231], [232, 241], [242, 245], [246, 254], [255, 264], [265, 269], [270, 274], [275, 279], [280, 282], [283, 294], [295, 302], [303, 314], [315, 316], [316, 319], [319, 320], [320, 321]]}
{"doc_key": "ai-test-63", "ner": [[6, 6, "field"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 6, 12, 13, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "of", "the", "research", "in", "the", "WSD", "area", "is", "carried", "out", "using", "Word", "Net", "as", "a", "reference", "sense", "inventory", "."], "sentence-detokenized": "Most of the research in the WSD area is carried out using WordNet as a reference sense inventory.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 20], [21, 23], [24, 27], [28, 31], [32, 36], [37, 39], [40, 47], [48, 51], [52, 57], [58, 62], [62, 65], [66, 68], [69, 70], [71, 80], [81, 86], [87, 96], [96, 97]]}
{"doc_key": "ai-test-64", "ner": [[10, 11, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Former", "PhD", "students", "and", "postdoctoral", "researchers", "in", "his", "group", "include", "Richard", "Zemel", "and", "Zubin", "Gahramani", "."], "sentence-detokenized": "Former PhD students and postdoctoral researchers in his group include Richard Zemel and Zubin Gahramani.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 23], [24, 36], [37, 48], [49, 51], [52, 55], [56, 61], [62, 69], [70, 77], [78, 83], [84, 87], [88, 93], [94, 103], [103, 104]]}
{"doc_key": "ai-test-65", "ner": [[4, 5, "metrics"], [12, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 12, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Each", "prediction", "result", "or", "hash", "matrix", "instance", "is", "one", "point", "in", "the", "ROC", "space", "."], "sentence-detokenized": "Each prediction result or hash matrix instance is one point in the ROC space.", "token2charspan": [[0, 4], [5, 15], [16, 22], [23, 25], [26, 30], [31, 37], [38, 46], [47, 49], [50, 53], [54, 59], [60, 62], [63, 66], [67, 70], [71, 76], [76, 77]]}
{"doc_key": "ai-test-66", "ner": [[3, 3, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [17, 18, "product"], [19, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 19, 23, "physical", "", false, false], [7, 8, 19, 23, "physical", "", false, false], [10, 11, 19, 23, "physical", "", false, false], [17, 18, 3, 3, "artifact", "", false, false], [17, 18, 7, 8, "artifact", "", false, false], [17, 18, 10, 11, "artifact", "", false, false], [17, 18, 19, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1997", ",", "Trun", "and", "his", "colleagues", "Wolfram", "Burgard", "and", "Dieter", "Fox", "developed", "the", "world", "'s", "first", "robotic", "guide", "at", "the", "Deutsches", "Museum", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "In 1997, Trun and his colleagues Wolfram Burgard and Dieter Fox developed the world's first robotic guide at the Deutsches Museum Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 13], [14, 17], [18, 21], [22, 32], [33, 40], [41, 48], [49, 52], [53, 59], [60, 63], [64, 73], [74, 77], [78, 83], [83, 85], [86, 91], [92, 99], [100, 105], [106, 108], [109, 112], [113, 122], [123, 129], [130, 134], [135, 136], [136, 140], [140, 141], [141, 142]]}
{"doc_key": "ai-test-67", "ner": [[0, 1, "product"], [7, 7, "misc"], [23, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 1, "part-of", "", false, false], [23, 25, 0, 1, "usage", "", false, false], [27, 28, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "of", "semantic", "relations", "between", "words", "in", "more", "than", "200", "languages", ".", "It", "s", "main", "applications", "are", "automatic", "natural", "language", "processing", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database of semantic relations between words in more than 200 languages. Its main applications are automatic natural language processing and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 32], [33, 41], [42, 51], [52, 59], [60, 65], [66, 68], [69, 73], [74, 78], [79, 82], [83, 92], [92, 93], [94, 96], [96, 97], [98, 102], [103, 115], [116, 119], [120, 129], [130, 137], [138, 146], [147, 157], [158, 161], [162, 172], [173, 185], [186, 198], [198, 199]]}
{"doc_key": "ai-test-68", "ner": [[14, 16, "field"], [22, 26, "conference"], [29, 37, "conference"], [39, 39, "conference"], [41, 41, "conference"], [2, 4, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[22, 26, 14, 16, "topic", "", false, false], [22, 26, 2, 4, "topic", "", false, false], [29, 37, 14, 16, "topic", "", false, false], [29, 37, 2, 4, "topic", "", false, false], [39, 39, 14, 16, "topic", "", false, false], [39, 39, 2, 4, "topic", "", false, false], [41, 41, 14, 16, "topic", "", false, false], [41, 41, 2, 4, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Papers", "on", "speech", "processing", "are", "starting", "to", "appear", "at", "conferences", "in", "the", "field", "of", "natural", "language", "processing", ",", "such", "as", "those", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "the", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", "and", "HLT", "."], "sentence-detokenized": "Papers on speech processing are starting to appear at conferences in the field of natural language processing, such as those of the Association for Computational Linguistics, the North American Chapter of the Association for Computational Linguistics, EMNLP and HLT.", "token2charspan": [[0, 6], [7, 9], [10, 16], [17, 27], [28, 31], [32, 40], [41, 43], [44, 50], [51, 53], [54, 65], [66, 68], [69, 72], [73, 78], [79, 81], [82, 89], [90, 98], [99, 109], [109, 110], [111, 115], [116, 118], [119, 124], [125, 127], [128, 131], [132, 143], [144, 147], [148, 161], [162, 173], [173, 174], [175, 178], [179, 184], [185, 193], [194, 201], [202, 204], [205, 208], [209, 220], [221, 224], [225, 238], [239, 250], [250, 251], [252, 257], [258, 261], [262, 265], [265, 266]]}
{"doc_key": "ai-test-69", "ner": [[3, 3, "programlang"], [19, 27, "misc"], [33, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "set", "of", "Java", "programs", "uses", "a", "lexicon", "to", "process", "variations", "of", "biomedical", "texts", ",", "linking", "words", "by", "their", "parts", "of", "speech", ",", "which", "can", "be", "useful", "for", "web", "searches", "or", "searches", "in", "electronic", "medical", "records", "."], "sentence-detokenized": "A set of Java programs uses a lexicon to process variations of biomedical texts, linking words by their parts of speech, which can be useful for web searches or searches in electronic medical records.", "token2charspan": [[0, 1], [2, 5], [6, 8], [9, 13], [14, 22], [23, 27], [28, 29], [30, 37], [38, 40], [41, 48], [49, 59], [60, 62], [63, 73], [74, 79], [79, 80], [81, 88], [89, 94], [95, 97], [98, 103], [104, 109], [110, 112], [113, 119], [119, 120], [121, 126], [127, 130], [131, 133], [134, 140], [141, 144], [145, 148], [149, 157], [158, 160], [161, 169], [170, 172], [173, 183], [184, 191], [192, 199], [199, 200]]}
{"doc_key": "ai-test-70", "ner": [[7, 7, "algorithm"], [9, 9, "algorithm"], [11, 11, "algorithm"], [13, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "many", "newer", "algorithms", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", "and", "others", "."], "sentence-detokenized": "There are many newer algorithms such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost and others.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 20], [21, 31], [32, 36], [37, 39], [40, 47], [47, 48], [49, 59], [59, 60], [61, 71], [71, 72], [73, 80], [80, 81], [82, 91], [92, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-test-71", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "implementation", "in", "Python", ":"], "sentence-detokenized": "This is an example implementation in Python:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 33], [34, 36], [37, 43], [43, 44]]}
{"doc_key": "ai-test-72", "ner": [[3, 4, "organisation"], [5, 5, "product"], [10, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 3, 4, "artifact", "made_by_company", false, false], [10, 12, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1982", ",", "Mattel", "'s", "Intellivision", "game", "console", "featured", "the", "Intellivoice", "voice", "synthesis", "module", "."], "sentence-detokenized": "In 1982, Mattel's Intellivision game console featured the Intellivoice voice synthesis module.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [15, 17], [18, 31], [32, 36], [37, 44], [45, 53], [54, 57], [58, 70], [71, 76], [77, 86], [87, 93], [93, 94]]}
{"doc_key": "ai-test-73", "ner": [[4, 5, "task"], [8, 14, "task"], [16, 17, "field"], [18, 21, "task"], [24, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 14, 4, 5, "part-of", "", false, false], [16, 17, 4, 5, "part-of", "", false, false], [18, 21, 4, 5, "part-of", "", false, false], [24, 28, 18, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "also", "worked", "on", "machine", "translation", ",", "both", "high", "-", "fidelity", "knowledge", "-", "based", "MT", "and", "machine", "learning", "for", "statistical", "machine", "translation", "(", "e.g.", "generalised", "example", "-", "based", "MT", ")", "."], "sentence-detokenized": "He also worked on machine translation, both high-fidelity knowledge-based MT and machine learning for statistical machine translation (e.g. generalised example-based MT).", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 17], [18, 25], [26, 37], [37, 38], [39, 43], [44, 48], [48, 49], [49, 57], [58, 67], [67, 68], [68, 73], [74, 76], [77, 80], [81, 88], [89, 97], [98, 101], [102, 113], [114, 121], [122, 133], [134, 135], [135, 139], [140, 151], [152, 159], [159, 160], [160, 165], [166, 168], [168, 169], [169, 170]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [7, 7, "misc"], [28, 29, "algorithm"], [31, 32, "field"], [34, 35, "field"], [37, 37, "field"], [39, 40, "field"], [42, 42, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 28, 29, "general-affiliation", "", false, false], [0, 1, 31, 32, "general-affiliation", "", false, false], [0, 1, 34, 35, "general-affiliation", "", false, false], [0, 1, 37, 37, "general-affiliation", "", false, false], [0, 1, 39, 40, "general-affiliation", "", false, false], [0, 1, 42, 42, "general-affiliation", "", false, false], [7, 7, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "commonly", "referred", "to", "as", "Mathematica", ")", "is", "a", "state", "-", "of", "-", "the", "-", "art", "technical", "computing", "framework", "that", "covers", "most", "technical", "areas", "-", "including", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "data", "science", ",", "visualisation", "and", "more", "."], "sentence-detokenized": "Wolfram Mathematica (commonly referred to as Mathematica) is a state-of-the-art technical computing framework that covers most technical areas - including neural networks, machine learning, image processing, geometry, data science, visualisation and more.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 29], [30, 38], [39, 41], [42, 44], [45, 56], [56, 57], [58, 60], [61, 62], [63, 68], [68, 69], [69, 71], [71, 72], [72, 75], [75, 76], [76, 79], [80, 89], [90, 99], [100, 109], [110, 114], [115, 121], [122, 126], [127, 136], [137, 142], [143, 144], [145, 154], [155, 161], [162, 170], [170, 171], [172, 179], [180, 188], [188, 189], [190, 195], [196, 206], [206, 207], [208, 216], [216, 217], [218, 222], [223, 230], [230, 231], [232, 245], [246, 249], [250, 254], [254, 255]]}
{"doc_key": "ai-test-75", "ner": [[2, 6, "product"], [10, 11, "researcher"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 2, 6, "type-of", "", false, false], [17, 17, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "digitally", "controlled", "and", "programmable", "robot", "was", "invented", "by", "George", "Devol", "in", "1954", "and", "eventually", "named", "Unimate", "."], "sentence-detokenized": "The first digitally controlled and programmable robot was invented by George Devol in 1954 and eventually named Unimate.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 30], [31, 34], [35, 47], [48, 53], [54, 57], [58, 66], [67, 69], [70, 76], [77, 82], [83, 85], [86, 90], [91, 94], [95, 105], [106, 111], [112, 119], [119, 120]]}
{"doc_key": "ai-test-76", "ner": [[1, 1, "algorithm"], [3, 3, "algorithm"], [16, 17, "task"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 3, 3, "compare", "", false, false], [3, 3, 16, 17, "general-affiliation", "", false, false], [3, 3, 19, 20, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Like", "DBNs", ",", "DBM", "can", "learn", "complex", "and", "abstract", "internal", "input", "representations", "in", "tasks", "such", "as", "Object", "Recognition", "or", "Speech", "Recognition", ",", "using", "limited", ",", "labelled", "data", "to", "refine", "representations", "created", "using", "a", "large", "unlabelled", "sensory", "input", "dataset", "."], "sentence-detokenized": "Like DBNs, DBM can learn complex and abstract internal input representations in tasks such as Object Recognition or Speech Recognition, using limited, labelled data to refine representations created using a large unlabelled sensory input dataset.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 14], [15, 18], [19, 24], [25, 32], [33, 36], [37, 45], [46, 54], [55, 60], [61, 76], [77, 79], [80, 85], [86, 90], [91, 93], [94, 100], [101, 112], [113, 115], [116, 122], [123, 134], [134, 135], [136, 141], [142, 149], [149, 150], [151, 159], [160, 164], [165, 167], [168, 174], [175, 190], [191, 198], [199, 204], [205, 206], [207, 212], [213, 223], [224, 231], [232, 237], [238, 245], [245, 246]]}
{"doc_key": "ai-test-77", "ner": [[6, 7, "task"], [11, 11, "conference"], [13, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 6, 7, "topic", "", false, false], [13, 13, 6, 7, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Scientific", "conferences", "where", "papers", "based", "on", "vision", "recognition", "often", "appear", "are", "ICCV", "and", "CVPR", "."], "sentence-detokenized": "Scientific conferences where papers based on vision recognition often appear are ICCV and CVPR.", "token2charspan": [[0, 10], [11, 22], [23, 28], [29, 35], [36, 41], [42, 44], [45, 51], [52, 63], [64, 69], [70, 76], [77, 80], [81, 85], [86, 89], [90, 94], [94, 95]]}
{"doc_key": "ai-test-78", "ner": [[0, 3, "field"], [4, 5, "algorithm"], [7, 7, "algorithm"], [16, 17, "metrics"], [19, 21, "metrics"], [23, 23, "metrics"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 5, 0, 3, "part-of", "", false, false], [4, 5, 16, 17, "related-to", "finds", false, false], [4, 5, 19, 21, "related-to", "finds", false, false], [4, 5, 38, 39, "related-to", "", false, false], [7, 7, 4, 5, "named", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "statistics", ",", "the", "expectation", "maximisation", "(", "EM", ")", "algorithm", "is", "an", "iterative", "method", "for", "finding", "maximum", "likelihood", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "estimates", "of", "the", "parameters", "of", "statistical", "models", "when", "the", "model", "depends", "on", "unobservable", "latent", "variables", "."], "sentence-detokenized": "In statistics, the expectation maximisation (EM) algorithm is an iterative method for finding maximum likelihood or maximum a posteriori (MAP) estimates of the parameters of statistical models when the model depends on unobservable latent variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 30], [31, 43], [44, 45], [45, 47], [47, 48], [49, 58], [59, 61], [62, 64], [65, 74], [75, 81], [82, 85], [86, 93], [94, 101], [102, 112], [113, 115], [116, 123], [124, 125], [126, 136], [137, 138], [138, 141], [141, 142], [143, 152], [153, 155], [156, 159], [160, 170], [171, 173], [174, 185], [186, 192], [193, 197], [198, 201], [202, 207], [208, 215], [216, 218], [219, 231], [232, 238], [239, 248], [248, 249]]}
{"doc_key": "ai-test-79", "ner": [[4, 6, "metrics"], [8, 10, "metrics"], [11, 13, "metrics"], [15, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 10, 4, 6, "named", "", false, false], [15, 15, 11, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Investigators", "also", "sometimes", "report", "false", "positive", "rates", "(", "FPR", ")", "and", "false", "negative", "rates", "(", "FNR", ")", "."], "sentence-detokenized": "Investigators also sometimes report false positive rates (FPR) and false negative rates (FNR).", "token2charspan": [[0, 13], [14, 18], [19, 28], [29, 35], [36, 41], [42, 50], [51, 56], [57, 58], [58, 61], [61, 62], [63, 66], [67, 72], [73, 81], [82, 87], [88, 89], [89, 92], [92, 93], [93, 94]]}
{"doc_key": "ai-test-80", "ner": [[6, 11, "metrics"], [13, 14, "field"], [17, 18, "metrics"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 14, 6, 11, "usage", "", false, false], [21, 22, 17, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "concept", "is", "similar", "to", "the", "signal", "-", "to", "-", "noise", "ratio", "used", "in", "science", "and", "the", "mixing", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "This concept is similar to the signal-to-noise ratio used in science and the mixing matrix used in artificial intelligence.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 23], [24, 26], [27, 30], [31, 37], [37, 38], [38, 40], [40, 41], [41, 46], [47, 52], [53, 57], [58, 60], [61, 68], [69, 72], [73, 76], [77, 83], [84, 90], [91, 95], [96, 98], [99, 109], [110, 122], [122, 123]]}
{"doc_key": "ai-test-81", "ner": [[5, 6, "field"], [11, 15, "researcher"], [18, 19, "researcher"], [21, 23, "researcher"], [35, 39, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 11, 15, "general-affiliation", "", false, false], [5, 6, 18, 19, "general-affiliation", "", false, false], [5, 6, 21, 23, "general-affiliation", "", false, false], [35, 39, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Code", "of", "Conduct", "on", "Human", "Augmentation", ",", "originally", "introduced", "by", "Steve", "Mann", "in", "2004", "and", "refined", "by", "Ray", "Kurzweil", "and", "Marvin", "Minsky", "in", "2013", ",", "was", "finally", "ratified", "on", "25", "June", "2017", "at", "the", "Virtual", "Reality", "Conference", "in", "Toronto", "."], "sentence-detokenized": "The Code of Conduct on Human Augmentation, originally introduced by Steve Mann in 2004 and refined by Ray Kurzweil and Marvin Minsky in 2013, was finally ratified on 25 June 2017 at the Virtual Reality Conference in Toronto.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 22], [23, 28], [29, 41], [41, 42], [43, 53], [54, 64], [65, 67], [68, 73], [74, 78], [79, 81], [82, 86], [87, 90], [91, 98], [99, 101], [102, 105], [106, 114], [115, 118], [119, 125], [126, 132], [133, 135], [136, 140], [140, 141], [142, 145], [146, 153], [154, 162], [163, 165], [166, 168], [169, 173], [174, 178], [179, 181], [182, 185], [186, 193], [194, 201], [202, 212], [213, 215], [216, 223], [223, 224]]}
{"doc_key": "ai-test-82", "ner": [[3, 5, "person"], [6, 13, "organisation"], [19, 20, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 6, 13, "role", "directed_for", false, false], [3, 5, 19, 20, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", ",", "Walter", "R.", "Booth", "made", "10", "films", "for", "the", "UK", "'s", "Kinoplastikon", ",", "probably", "in", "collaboration", "with", "Cecil", "Hepworth", "."], "sentence-detokenized": "In 1913, Walter R. Booth made 10 films for the UK's Kinoplastikon, probably in collaboration with Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 18], [19, 24], [25, 29], [30, 32], [33, 38], [39, 42], [43, 46], [47, 49], [49, 51], [52, 65], [65, 66], [67, 75], [76, 78], [79, 92], [93, 97], [98, 103], [104, 112], [112, 113]]}
{"doc_key": "ai-test-83", "ner": [[11, 12, "location"], [9, 10, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 11, 12, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "presented", "their", "new", "robot", "in", "1961", "at", "the", "Cow", "Palace", "in", "Chicago", "."], "sentence-detokenized": "They presented their new robot in 1961 at the Cow Palace in Chicago.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 24], [25, 30], [31, 33], [34, 38], [39, 41], [42, 45], [46, 49], [50, 56], [57, 59], [60, 67], [67, 68]]}
{"doc_key": "ai-test-84", "ner": [[1, 1, "product"], [5, 6, "task"], [9, 10, "field"], [14, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 5, 6, "usage", "", false, false], [1, 1, 9, 10, "usage", "", false, false], [1, 1, 14, 17, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Some", "chatbot", "applications", "use", "extensive", "word", "classification", "processes", ",", "natural", "language", "processors", "and", "sophisticated", "artificial", "intelligence", ",", "while", "others", "simply", "scan", "generic", "keywords", "and", "generate", "answers", "using", "common", "phrases", "extracted", "from", "a", "linked", "library", "or", "database", "."], "sentence-detokenized": "Some chatbot applications use extensive word classification processes, natural language processors and sophisticated artificial intelligence, while others simply scan generic keywords and generate answers using common phrases extracted from a linked library or database.", "token2charspan": [[0, 4], [5, 12], [13, 25], [26, 29], [30, 39], [40, 44], [45, 59], [60, 69], [69, 70], [71, 78], [79, 87], [88, 98], [99, 102], [103, 116], [117, 127], [128, 140], [140, 141], [142, 147], [148, 154], [155, 161], [162, 166], [167, 174], [175, 183], [184, 187], [188, 196], [197, 204], [205, 210], [211, 217], [218, 225], [226, 235], [236, 240], [241, 242], [243, 249], [250, 257], [258, 260], [261, 269], [269, 270]]}
{"doc_key": "ai-test-85", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "WaveNet", "model", ",", "proposed", "in", "2016", ",", "provides", "excellent", "speech", "quality", "."], "sentence-detokenized": "The WaveNet model, proposed in 2016, provides excellent speech quality.", "token2charspan": [[0, 3], [4, 11], [12, 17], [17, 18], [19, 27], [28, 30], [31, 35], [35, 36], [37, 45], [46, 55], [56, 62], [63, 70], [70, 71]]}
{"doc_key": "ai-test-86", "ner": [[4, 4, "product"], [5, 7, "misc"], [9, 10, "misc"], [12, 13, "misc"], [15, 16, "misc"], [19, 21, "organisation"], [23, 23, "organisation"], [25, 28, "organisation"], [30, 30, "organisation"], [32, 35, "organisation"], [37, 38, "organisation"], [40, 40, "organisation"], [42, 44, "organisation"], [47, 47, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 4, 5, 7, "general-affiliation", "", false, false], [4, 4, 9, 10, "general-affiliation", "", false, false], [4, 4, 12, 13, "general-affiliation", "", false, false], [4, 4, 15, 16, "general-affiliation", "", false, false], [19, 21, 4, 4, "usage", "", false, false], [23, 23, 4, 4, "usage", "", false, false], [25, 28, 4, 4, "usage", "", false, false], [30, 30, 4, 4, "usage", "", false, false], [32, 35, 4, 4, "usage", "", false, false], [37, 38, 4, 4, "usage", "", false, false], [40, 40, 4, 4, "usage", "", false, false], [42, 44, 4, 4, "usage", "", false, false], [47, 47, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organisations", "known", "to", "use", "ALE", "for", "emergency", "management", ",", "disaster", "recovery", ",", "routine", "communications", "or", "emergency", "response", ":", "the", "American", "Red", "Cross", ",", "FEMA", ",", "Disaster", "Medical", "Assistance", "Teams", ",", "NATO", ",", "Federal", "Bureau", "of", "Investigation", ",", "United", "Nations", ",", "AT&T", ",", "Civil", "Air", "Patrol", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organisations known to use ALE for emergency management, disaster recovery, routine communications or emergency response: the American Red Cross, FEMA, Disaster Medical Assistance Teams, NATO, Federal Bureau of Investigation, United Nations, AT&T, Civil Air Patrol, (ARES).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 30], [31, 34], [35, 44], [45, 55], [55, 56], [57, 65], [66, 74], [74, 75], [76, 83], [84, 98], [99, 101], [102, 111], [112, 120], [120, 121], [122, 125], [126, 134], [135, 138], [139, 144], [144, 145], [146, 150], [150, 151], [152, 160], [161, 168], [169, 179], [180, 185], [185, 186], [187, 191], [191, 192], [193, 200], [201, 207], [208, 210], [211, 224], [224, 225], [226, 232], [233, 240], [240, 241], [242, 246], [246, 247], [248, 253], [254, 257], [258, 264], [264, 265], [266, 267], [267, 271], [271, 272], [272, 273]]}
{"doc_key": "ai-test-87", "ner": [[4, 8, "algorithm"], [15, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "simplicity", ",", "the", "Kronecker", "delta", "is", "used", "here", "(", "cf", ".", "the", "derivative", "of", "the", "sigmoidal", "function", ",", "which", "is", "expressed", "in", "terms", "of", "the", "function", "itself", ")", "."], "sentence-detokenized": "For simplicity, the Kronecker delta is used here (cf. the derivative of the sigmoidal function, which is expressed in terms of the function itself).", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 29], [30, 35], [36, 38], [39, 43], [44, 48], [49, 50], [50, 52], [52, 53], [54, 57], [58, 68], [69, 71], [72, 75], [76, 85], [86, 94], [94, 95], [96, 101], [102, 104], [105, 114], [115, 117], [118, 123], [124, 126], [127, 130], [131, 139], [140, 146], [146, 147], [147, 148]]}
{"doc_key": "ai-test-88", "ner": [[11, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "theory", "is", "based", "on", "philosophical", "foundations", "and", "was", "developed", "by", "Ray", "Solomonoff", "around", "1960", ".", "Samuel", "Ratmanner", "and", "Markus", "Hatter", "."], "sentence-detokenized": "This theory is based on philosophical foundations and was developed by Ray Solomonoff around 1960. Samuel Ratmanner and Markus Hatter.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 20], [21, 23], [24, 37], [38, 49], [50, 53], [54, 57], [58, 67], [68, 70], [71, 74], [75, 85], [86, 92], [93, 97], [97, 98], [99, 105], [106, 115], [116, 119], [120, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [10, 12, "misc"], [14, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 12, "type-of", "", false, false], [0, 0, 14, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "a", "freely", "accessible", "database", "originally", "designed", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "has", "been", "expanded", "to", "include", "definitions", "and", "is", "now", "also", "considered", "a", "dictionary", "."], "sentence-detokenized": "WordNet, a freely accessible database originally designed as a semantic network based on psycholinguistic principles, has been expanded to include definitions and is now also considered a dictionary.", "token2charspan": [[0, 7], [7, 8], [9, 10], [11, 17], [18, 28], [29, 37], [38, 48], [49, 57], [58, 60], [61, 62], [63, 71], [72, 79], [80, 85], [86, 88], [89, 105], [106, 116], [116, 117], [118, 121], [122, 126], [127, 135], [136, 138], [139, 146], [147, 158], [159, 162], [163, 165], [166, 169], [170, 174], [175, 185], [186, 187], [188, 198], [198, 199]]}
{"doc_key": "ai-test-90", "ner": [[2, 3, "field"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 2, 3, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Advances", "in", "computational", "imaging", "research", "are", "reported", "in", "several", "places", ",", "including", "SIGGRAPH", "publications", "and", "."], "sentence-detokenized": "Advances in computational imaging research are reported in several places, including SIGGRAPH publications and.", "token2charspan": [[0, 8], [9, 11], [12, 25], [26, 33], [34, 42], [43, 46], [47, 55], [56, 58], [59, 66], [67, 73], [73, 74], [75, 84], [85, 93], [94, 106], [107, 110], [110, 111]]}
{"doc_key": "ai-test-91", "ner": [[0, 0, "task"], [9, 10, "task"], [13, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [13, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "seen", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multi-class", "classification", "."], "sentence-detokenized": "Classification can be seen as two separate problems - binary classification and multi-class classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 26], [27, 29], [30, 33], [34, 42], [43, 51], [52, 53], [54, 60], [61, 75], [76, 79], [80, 91], [92, 106], [106, 107]]}
{"doc_key": "ai-test-92", "ner": [[12, 12, "algorithm"], [17, 18, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 12, 12, "type-of", "", false, false], [21, 21, 17, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Advanced", "gene", "finders", "for", "both", "prokaryotic", "and", "eukaryotic", "genomes", "typically", "use", "complex", "probabilistic", "models", ",", "such", "as", "Hidden", "Markov", "Models", "(", "HMMs", ")", ",", "to", "combine", "information", "from", "different", "signal", "and", "content", "measurements", "."], "sentence-detokenized": "Advanced gene finders for both prokaryotic and eukaryotic genomes typically use complex probabilistic models, such as Hidden Markov Models (HMMs), to combine information from different signal and content measurements.", "token2charspan": [[0, 8], [9, 13], [14, 21], [22, 25], [26, 30], [31, 42], [43, 46], [47, 57], [58, 65], [66, 75], [76, 79], [80, 87], [88, 101], [102, 108], [108, 109], [110, 114], [115, 117], [118, 124], [125, 131], [132, 138], [139, 140], [140, 144], [144, 145], [145, 146], [147, 149], [150, 157], [158, 169], [170, 174], [175, 184], [185, 191], [192, 195], [196, 203], [204, 216], [216, 217]]}
{"doc_key": "ai-test-93", "ner": [[0, 0, "misc"], [3, 7, "field"], [9, 11, "algorithm"], [13, 14, "algorithm"], [17, 20, "algorithm"], [28, 29, "algorithm"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6], "relations": [[0, 0, 3, 7, "part-of", "", false, false], [0, 0, 9, 11, "usage", "", false, false], [13, 14, 0, 0, "origin", "", true, false], [17, 20, 13, 14, "named", "", false, false], [28, 29, 0, 0, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 3, 4, 5], "sentence": ["Neuroevolution", "is", "a", "type", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "generate", "artificial", "neural", "networks", "(", "ANNs", ")", ",", "their", "parameters", ",", "topology", "and", "rules", ".", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuroevolution is a type of artificial intelligence that uses evolutionary algorithms to generate artificial neural networks (ANNs), their parameters, topology and rules. and evolutionary robotics.", "token2charspan": [[0, 14], [15, 17], [18, 19], [20, 24], [25, 27], [28, 38], [39, 51], [52, 56], [57, 61], [62, 74], [75, 85], [86, 88], [89, 97], [98, 108], [109, 115], [116, 124], [125, 126], [126, 130], [130, 131], [131, 132], [133, 138], [139, 149], [149, 150], [151, 159], [160, 163], [164, 169], [169, 170], [171, 174], [175, 187], [188, 196], [196, 197]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [6, 6, "metrics"], [8, 8, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "IBM", "proposed", "and", "implemented", "the", "BLEU", "system", "Papineni", "et", "al", "."], "sentence-detokenized": "Since IBM proposed and implemented the BLEU system Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 34], [35, 38], [39, 43], [44, 50], [51, 59], [60, 62], [63, 65], [65, 66]]}
{"doc_key": "ai-test-95", "ner": [[9, 16, "conference"], [18, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 20, 9, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "experts", "attended", "a", "conference", "organised", "by", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "to", "discuss", "whether", "computers", "and", "robots", "could", "gain", "autonomy", "and", "to", "what", "extent", "this", "capability", "could", "pose", "a", "threat", "or", "danger", "."], "sentence-detokenized": "In 2009, experts attended a conference organised by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether computers and robots could gain autonomy and to what extent this capability could pose a threat or danger.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 25], [26, 27], [28, 38], [39, 48], [49, 51], [52, 55], [56, 67], [68, 71], [72, 75], [76, 87], [88, 90], [91, 101], [102, 114], [115, 116], [116, 120], [120, 121], [122, 124], [125, 132], [133, 140], [141, 150], [151, 154], [155, 161], [162, 167], [168, 172], [173, 181], [182, 185], [186, 188], [189, 193], [194, 200], [201, 205], [206, 216], [217, 222], [223, 227], [228, 229], [230, 236], [237, 239], [240, 246], [246, 247]]}
{"doc_key": "ai-test-96", "ner": [[23, 24, "researcher"], [26, 27, "researcher"], [29, 34, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[29, 34, 23, 24, "artifact", "", false, false], [29, 34, 26, 27, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["After", "boosting", ",", "a", "classifier", "built", "from", "200", "features", "could", "give", "a", "95", "%", "detection", "rate", "if", "^", "{", "-", "5", "}", "/", "P.", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "After boosting, a classifier built from 200 features could give a 95% detection rate if ^ {-5} / P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 17], [18, 28], [29, 34], [35, 39], [40, 43], [44, 52], [53, 58], [59, 63], [64, 65], [66, 68], [68, 69], [70, 79], [80, 84], [85, 87], [88, 89], [90, 91], [91, 92], [92, 93], [93, 94], [95, 96], [97, 99], [100, 105], [105, 106], [107, 109], [110, 115], [115, 116], [117, 123], [124, 128], [128, 129], [129, 133], [134, 140], [141, 150], [150, 151], [152, 156], [156, 157]]}
{"doc_key": "ai-test-97", "ner": [[6, 6, "programlang"], [12, 12, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "site", "was", "originally", "based", "on", "Perl", ",", "but", "for", "security", "reasons", "IMDb", "no", "longer", "discloses", "what", "software", "it", "uses", "."], "sentence-detokenized": "The site was originally based on Perl, but for security reasons IMDb no longer discloses what software it uses.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 23], [24, 29], [30, 32], [33, 37], [37, 38], [39, 42], [43, 46], [47, 55], [56, 63], [64, 68], [69, 71], [72, 78], [79, 88], [89, 93], [94, 102], [103, 105], [106, 110], [110, 111]]}
{"doc_key": "ai-test-98", "ner": [[9, 10, "researcher"], [12, 13, "researcher"], [15, 16, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "start", "-", "up", "was", "founded", "in", "2010", "by", "Demis", "Hassabis", ",", "Shein", "Legg", "and", "Mustafa", "Suleiman", "."], "sentence-detokenized": "The start-up was founded in 2010 by Demis Hassabis, Shein Legg and Mustafa Suleiman.", "token2charspan": [[0, 3], [4, 9], [9, 10], [10, 12], [13, 16], [17, 24], [25, 27], [28, 32], [33, 35], [36, 41], [42, 50], [50, 51], [52, 57], [58, 62], [63, 66], [67, 74], [75, 83], [83, 84]]}
{"doc_key": "ai-test-99", "ner": [[4, 5, "misc"], [8, 11, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 4, 5, "type-of", "", false, false], [24, 25, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "very", "commonly", "used", "loss", "functions", "are", "the", "root", "mean", "square", "error", ",", "mathL", "(", "a", ")", "=", "a^2", "/", "math", ",", "and", "the", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Two very commonly used loss functions are the root mean square error, mathL (a) = a^2/math, and the absolute loss, mathL (a) = | a | / math.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 27], [28, 37], [38, 41], [42, 45], [46, 50], [51, 55], [56, 62], [63, 68], [68, 69], [70, 75], [76, 77], [77, 78], [78, 79], [80, 81], [82, 85], [85, 86], [86, 90], [90, 91], [92, 95], [96, 99], [100, 108], [109, 113], [113, 114], [115, 120], [121, 122], [122, 123], [123, 124], [125, 126], [127, 128], [129, 130], [131, 132], [133, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-test-100", "ner": [[0, 5, "algorithm"], [14, 16, "algorithm"], [18, 20, "algorithm"], [21, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 5, 14, 16, "type-of", "example_of", false, false], [14, 16, 21, 23, "related-to", "", false, false], [18, 20, 14, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "support", "vector", "machine", "with", "a", "soft", "boundary", "described", "above", "is", "an", "example", "of", "empirical", "risk", "minimisation", "(", "ERM", ")", "for", "hinge", "loss", "detection", "."], "sentence-detokenized": "The support vector machine with a soft boundary described above is an example of empirical risk minimisation (ERM) for hinge loss detection.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 26], [27, 31], [32, 33], [34, 38], [39, 47], [48, 57], [58, 63], [64, 66], [67, 69], [70, 77], [78, 80], [81, 90], [91, 95], [96, 108], [109, 110], [110, 113], [113, 114], [115, 118], [119, 124], [125, 129], [130, 139], [139, 140]]}
{"doc_key": "ai-test-101", "ner": [[5, 6, "field"], [9, 9, "task"], [11, 19, "task"], [20, 20, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 19, 5, 6, "origin", "", false, false], [11, 19, 9, 9, "type-of", "", false, false], [20, 20, 11, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "recent", "years", ",", "the", "deep", "learning", "approach", "to", "MT", "-", "neural", "machine", "translation", "-", "has", "developed", "rapidly", ",", "and", "Google", "has", "announced", "that", "its", "translation", "services", "now", "use", "this", "technology", "instead", "of", "the", "previous", "statistical", "methods", "."], "sentence-detokenized": "In recent years, the deep learning approach to MT - neural machine translation - has developed rapidly, and Google has announced that its translation services now use this technology instead of the previous statistical methods.", "token2charspan": [[0, 2], [3, 9], [10, 15], [15, 16], [17, 20], [21, 25], [26, 34], [35, 43], [44, 46], [47, 49], [50, 51], [52, 58], [59, 66], [67, 78], [79, 80], [81, 84], [85, 94], [95, 102], [102, 103], [104, 107], [108, 114], [115, 118], [119, 128], [129, 133], [134, 137], [138, 149], [150, 158], [159, 162], [163, 166], [167, 171], [172, 182], [183, 190], [191, 193], [194, 197], [198, 206], [207, 218], [219, 226], [226, 227]]}
{"doc_key": "ai-test-102", "ner": [[7, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "working", "with", "large", "corpora", "such", "as", "WordNet", ",", "this", "usually", "results", "in", "very", "large", "performance", "gains", "."], "sentence-detokenized": "When working with large corpora such as WordNet, this usually results in very large performance gains.", "token2charspan": [[0, 4], [5, 12], [13, 17], [18, 23], [24, 31], [32, 36], [37, 39], [40, 47], [47, 48], [49, 53], [54, 61], [62, 69], [70, 72], [73, 77], [78, 83], [84, 95], [96, 101], [101, 102]]}
{"doc_key": "ai-test-103", "ner": [[0, 1, "task"], [5, 7, "field"], [18, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 18, 20, "part-of", "", false, false], [18, 20, 5, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Face", "detection", "is", "used", "in", "biometrics", ",", "often", "as", "part", "of", "(", "or", "in", "combination", "with", ")", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Face detection is used in biometrics, often as part of (or in combination with) a facial recognition system.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 22], [23, 25], [26, 36], [36, 37], [38, 43], [44, 46], [47, 51], [52, 54], [55, 56], [56, 58], [59, 61], [62, 73], [74, 78], [78, 79], [80, 81], [82, 88], [89, 100], [101, 107], [107, 108]]}
{"doc_key": "ai-test-104", "ner": [[2, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["trained", "using", "maximum", "likelihood", "estimates"], "sentence-detokenized": "trained using maximum likelihood estimates", "token2charspan": [[0, 7], [8, 13], [14, 21], [22, 32], [33, 42]]}
{"doc_key": "ai-test-105", "ner": [[2, 2, "country"], [4, 8, "organisation"], [11, 12, "location"], [14, 14, "country"], [16, 20, "organisation"], [21, 21, "country"], [27, 27, "organisation"], [32, 34, "organisation"], [35, 36, "country"], [46, 50, "organisation"], [51, 51, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[4, 8, 11, 12, "physical", "", false, false], [11, 12, 14, 14, "physical", "", false, false], [16, 20, 21, 21, "physical", "", false, false], [32, 34, 35, 36, "physical", "", false, false], [46, 50, 51, 51, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd", ".", "Thailand", ",", "Komatsu", "(", "Shanghai", ")", "Ltd.", "in", "1996", "in", "Shanghai", ",", "China", ",", "Industrial", "Power", "Alliance", "Ltd", ".", "Japan", ",", "a", "joint", "venture", "with", "Cummins", ",", "in", "1998", ",", "L&T-", "Komatsu", "Limited", "in", "India", "in", "1998", "(", "shares", "sold", "in", "2013", ")", "and", "Komatsu", "Brasil", "International", "Ltda", ".", "Brazil", "in", "1998", "."], "sentence-detokenized": "Ltd. Thailand, Komatsu (Shanghai) Ltd. in 1996 in Shanghai, China, Industrial Power Alliance Ltd. Japan, a joint venture with Cummins, in 1998, L&T-Komatsu Limited in India in 1998 (shares sold in 2013) and Komatsu Brasil International Ltda. Brazil in 1998.", "token2charspan": [[0, 3], [3, 4], [5, 13], [13, 14], [15, 22], [23, 24], [24, 32], [32, 33], [34, 38], [39, 41], [42, 46], [47, 49], [50, 58], [58, 59], [60, 65], [65, 66], [67, 77], [78, 83], [84, 92], [93, 96], [96, 97], [98, 103], [103, 104], [105, 106], [107, 112], [113, 120], [121, 125], [126, 133], [133, 134], [135, 137], [138, 142], [142, 143], [144, 148], [148, 155], [156, 163], [164, 166], [167, 172], [173, 175], [176, 180], [181, 182], [182, 188], [189, 193], [194, 196], [197, 201], [201, 202], [203, 206], [207, 214], [215, 221], [222, 235], [236, 240], [240, 241], [242, 248], [249, 251], [252, 256], [256, 257]]}
{"doc_key": "ai-test-106", "ner": [[0, 0, "organisation"], [4, 9, "misc"], [10, 11, "misc"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 14, 0, 0, "physical", "", false, false], [13, 14, 4, 9, "general-affiliation", "", false, false], [13, 14, 10, 11, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["dgp", "also", "occasionally", "hosts", "artists", "in", "residence", "(", "such", "as", "Academy", "Award", "winner", "Chris", "Landreth", ")", "."], "sentence-detokenized": "dgp also occasionally hosts artists in residence (such as Academy Award winner Chris Landreth).", "token2charspan": [[0, 3], [4, 8], [9, 21], [22, 27], [28, 35], [36, 38], [39, 48], [49, 50], [50, 54], [55, 57], [58, 65], [66, 71], [72, 78], [79, 84], [85, 93], [93, 94], [94, 95]]}
{"doc_key": "ai-test-107", "ner": [[7, 9, "misc"], [12, 14, "misc"], [17, 20, "misc"], [24, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "currently", "has", "four", "sub-competitions", "-", "the", "RoboMaster", "Robotics", "Competition", ",", "the", "RoboMaster", "Technical", "Challenge", ",", "the", "ICRA", "RoboMaster", "AI", "Challenge", "and", "the", "new", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "It currently has four sub-competitions - the RoboMaster Robotics Competition, the RoboMaster Technical Challenge, the ICRA RoboMaster AI Challenge and the new RoboMaster Youth Tournament.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 21], [22, 38], [39, 40], [41, 44], [45, 55], [56, 64], [65, 76], [76, 77], [78, 81], [82, 92], [93, 102], [103, 112], [112, 113], [114, 117], [118, 122], [123, 133], [134, 136], [137, 146], [147, 150], [151, 154], [155, 158], [159, 169], [170, 175], [176, 186], [186, 187]]}
{"doc_key": "ai-test-108", "ner": [[7, 8, "field"], [15, 17, "algorithm"], [21, 22, "algorithm"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 21, 22, "usage", "", false, false], [7, 8, 24, 25, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["By", "the", "early", "2000s", ",", "the", "dominant", "speech", "processing", "strategy", "began", "to", "change", "from", "the", "hidden", "Markov", "model", "to", "more", "advanced", "neural", "networks", "and", "deep", "learning", "."], "sentence-detokenized": "By the early 2000s, the dominant speech processing strategy began to change from the hidden Markov model to more advanced neural networks and deep learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 18], [18, 19], [20, 23], [24, 32], [33, 39], [40, 50], [51, 59], [60, 65], [66, 68], [69, 75], [76, 80], [81, 84], [85, 91], [92, 98], [99, 104], [105, 107], [108, 112], [113, 121], [122, 128], [129, 137], [138, 141], [142, 146], [147, 155], [155, 156]]}
{"doc_key": "ai-test-109", "ner": [[5, 7, "misc"], [11, 13, "metrics"], [16, 19, "metrics"], [26, 28, "metrics"], [31, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 13, 16, 19, "related-to", "equal", false, false], [26, 28, 31, 33, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "equivalent", "expression", "for", "a", "binary", "target", "indicator", "is", "that", "the", "TRUE", "positive", "indicator", "and", "the", "FALSE", "positive", "indicator", "are", "the", "same", "(", "and", "therefore", "the", "FALSE", "negative", "indicator", "and", "the", "TRUE", "negative", "indicator", "are", "the", "same", ")", "for", "each", "value", "of", "the", "sensitive", "characteristics", ":"], "sentence-detokenized": "Another equivalent expression for a binary target indicator is that the TRUE positive indicator and the FALSE positive indicator are the same (and therefore the FALSE negative indicator and the TRUE negative indicator are the same) for each value of the sensitive characteristics:", "token2charspan": [[0, 7], [8, 18], [19, 29], [30, 33], [34, 35], [36, 42], [43, 49], [50, 59], [60, 62], [63, 67], [68, 71], [72, 76], [77, 85], [86, 95], [96, 99], [100, 103], [104, 109], [110, 118], [119, 128], [129, 132], [133, 136], [137, 141], [142, 143], [143, 146], [147, 156], [157, 160], [161, 166], [167, 175], [176, 185], [186, 189], [190, 193], [194, 198], [199, 207], [208, 217], [218, 221], [222, 225], [226, 230], [230, 231], [232, 235], [236, 240], [241, 246], [247, 249], [250, 253], [254, 263], [264, 279], [279, 280]]}
{"doc_key": "ai-test-110", "ner": [[0, 0, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["MATLAB", "function", ","], "sentence-detokenized": "MATLAB function,", "token2charspan": [[0, 6], [7, 15], [15, 16]]}
{"doc_key": "ai-test-111", "ner": [[0, 2, "product"], [7, 11, "misc"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 11, 0, 2, "part-of", "", false, false], [16, 17, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "articulated", "robot", "is", "a", "robot", "with", "rotating", "joints", "(", "e.g.", "a", "leg", "robot", "or", "an", "industrial", "robot", ")", "."], "sentence-detokenized": "An articulated robot is a robot with rotating joints (e.g. a leg robot or an industrial robot).", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 23], [24, 25], [26, 31], [32, 36], [37, 45], [46, 52], [53, 54], [54, 58], [59, 60], [61, 64], [65, 70], [71, 73], [74, 76], [77, 87], [88, 93], [93, 94], [94, 95]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [5, 6, "product"], [8, 9, "product"], [13, 13, "misc"], [17, 19, "product"], [26, 28, "misc"], [32, 32, "location"], [34, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 13, 13, "general-affiliation", "nationality", false, false], [0, 0, 26, 28, "usage", "", false, false], [0, 0, 32, 32, "physical", "", false, false], [5, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [32, 32, 34, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "also", "known", "as", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "an", "American", "streaming", "music", "and", "automatic", "recommendation", "system", "internet", "radio", "service", "powered", "by", "the", "Music", "Genome", "Project", "and", "headquartered", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (also known as Pandora Media or Pandora Radio) is an American streaming music and automatic recommendation system internet radio service powered by the Music Genome Project and headquartered in Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 30], [31, 36], [37, 39], [40, 47], [48, 53], [53, 54], [55, 57], [58, 60], [61, 69], [70, 79], [80, 85], [86, 89], [90, 99], [100, 114], [115, 121], [122, 130], [131, 136], [137, 144], [145, 152], [153, 155], [156, 159], [160, 165], [166, 172], [173, 180], [181, 184], [185, 198], [199, 201], [202, 209], [209, 210], [211, 221], [221, 222]]}
{"doc_key": "ai-test-113", "ner": [[10, 14, "organisation"], [22, 24, "organisation"], [28, 29, "conference"], [38, 38, "conference"], [40, 40, "conference"], [42, 42, "conference"], [44, 44, "conference"], [46, 46, "conference"], [48, 48, "conference"], [50, 50, "conference"], [52, 52, "conference"], [54, 54, "conference"], [56, 56, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "member", "of", "the", "Board", "of", "Directors", "of", "the", "International", "Machine", "Learning", "Society", ",", "has", "been", "a", "member", "of", "the", "AAAI", "Executive", "Council", ",", "co-chair", "of", "ICML", "2011", ",", "and", "a", "senior", "member", "of", "conferences", "including", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", "and", "WWW", "."], "sentence-detokenized": "She is a member of the Board of Directors of the International Machine Learning Society, has been a member of the AAAI Executive Council, co-chair of ICML 2011, and a senior member of conferences including AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM and WWW.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 15], [16, 18], [19, 22], [23, 28], [29, 31], [32, 41], [42, 44], [45, 48], [49, 62], [63, 70], [71, 79], [80, 87], [87, 88], [89, 92], [93, 97], [98, 99], [100, 106], [107, 109], [110, 113], [114, 118], [119, 128], [129, 136], [136, 137], [138, 146], [147, 149], [150, 154], [155, 159], [159, 160], [161, 164], [165, 166], [167, 173], [174, 180], [181, 183], [184, 195], [196, 205], [206, 210], [210, 211], [212, 216], [216, 217], [218, 223], [223, 224], [225, 229], [229, 230], [231, 234], [234, 235], [236, 242], [242, 243], [244, 247], [247, 248], [249, 253], [253, 254], [255, 259], [260, 263], [264, 267], [267, 268]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [5, 10, "organisation"], [12, 12, "organisation"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 10, "role", "", false, false], [12, 12, 5, 10, "named", "", false, false], [16, 18, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "developed", "a", "robocrane", "in", "which", "the", "platform", "hangs", "from", "six", "cables", "instead", "of", "being", "supported", "by", "six", "jacks", "."], "sentence-detokenized": "James S. Albus of the National Institute of Standards and Technology (NIST) developed a robocrane in which the platform hangs from six cables instead of being supported by six jacks.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [74, 75], [76, 85], [86, 87], [88, 97], [98, 100], [101, 106], [107, 110], [111, 119], [120, 125], [126, 130], [131, 134], [135, 141], [142, 149], [150, 152], [153, 158], [159, 168], [169, 171], [172, 175], [176, 181], [181, 182]]}
{"doc_key": "ai-test-115", "ner": [[3, 5, "algorithm"], [8, 9, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 5, "type-of", "", false, false], [13, 14, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "class", "of", "direct", "search", "algorithms", "are", "various", "evolutionary", "algorithms", ",", "such", "as", "genetic", "algorithms", "."], "sentence-detokenized": "Another class of direct search algorithms are various evolutionary algorithms, such as genetic algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 23], [24, 30], [31, 41], [42, 45], [46, 53], [54, 66], [67, 77], [77, 78], [79, 83], [84, 86], [87, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-test-116", "ner": [[0, 0, "organisation"], [3, 5, "misc"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 0, 0, "named", "", false, false], [6, 7, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "industrial", "robots", "and", "solutions", "for", "factory", "automation", "."], "sentence-detokenized": "KUKA is a German manufacturer of industrial robots and solutions for factory automation.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 43], [44, 50], [51, 54], [55, 64], [65, 68], [69, 76], [77, 87], [87, 88]]}
{"doc_key": "ai-test-117", "ner": [[5, 5, "misc"], [12, 14, "person"], [15, 21, "misc"], [23, 24, "person"], [26, 26, "misc"], [28, 29, "person"], [31, 32, "misc"], [34, 35, "person"], [37, 39, "misc"], [41, 43, "person"], [45, 48, "misc"], [50, 52, "person"], [53, 56, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[12, 14, 5, 5, "usage", "", false, false], [15, 21, 12, 14, "artifact", "", false, false], [23, 24, 5, 5, "usage", "", false, false], [26, 26, 23, 24, "artifact", "", false, false], [28, 29, 5, 5, "usage", "", false, false], [31, 32, 28, 29, "artifact", "", false, false], [34, 35, 5, 5, "usage", "", false, false], [37, 39, 34, 35, "artifact", "", false, false], [41, 43, 5, 5, "usage", "", false, false], [45, 48, 41, 43, "artifact", "", false, false], [50, 52, 5, 5, "usage", "", false, false], [53, 56, 50, 52, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Other", "films", "shot", "with", "an", "IMAX", "camera", "between", "2016", "and", "2020", "include", "Zack", "Snyder", "'s", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", ",", "Clint", "Eastwood", "'s", "Sully", ",", "Damien", "Chazelle", "'s", "First", "Man", ",", "Patty", "Jenkins", "'", "Wonder", "Woman", "1984", ",", "Kari", "Joji", "Fukunaga", "'s", "No", "Time", "to", "Die", "and", "Joseph", "Kosinski", "'s", "Top", "Gun", ":", "Maverick", "."], "sentence-detokenized": "Other films shot with an IMAX camera between 2016 and 2020 include Zack Snyder's Batman v Superman: Dawn of Justice, Clint Eastwood's Sully, Damien Chazelle's First Man, Patty Jenkins' Wonder Woman 1984, Kari Joji Fukunaga's No Time to Die and Joseph Kosinski's Top Gun: Maverick.", "token2charspan": [[0, 5], [6, 11], [12, 16], [17, 21], [22, 24], [25, 29], [30, 36], [37, 44], [45, 49], [50, 53], [54, 58], [59, 66], [67, 71], [72, 78], [78, 80], [81, 87], [88, 89], [90, 98], [98, 99], [100, 104], [105, 107], [108, 115], [115, 116], [117, 122], [123, 131], [131, 133], [134, 139], [139, 140], [141, 147], [148, 156], [156, 158], [159, 164], [165, 168], [168, 169], [170, 175], [176, 183], [183, 184], [185, 191], [192, 197], [198, 202], [202, 203], [204, 208], [209, 213], [214, 222], [222, 224], [225, 227], [228, 232], [233, 235], [236, 239], [240, 243], [244, 250], [251, 259], [259, 261], [262, 265], [266, 269], [269, 270], [271, 279], [279, 280]]}
{"doc_key": "ai-test-118", "ner": [[4, 5, "misc"], [10, 12, "organisation"], [14, 20, "organisation"], [25, 25, "misc"], [30, 34, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 25, 25, "named", "", false, false], [10, 12, 4, 5, "usage", "", false, false], [10, 12, 30, 34, "physical", "", false, false], [14, 20, 10, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "trial", "version", "of", "MICR", "E13B", "was", "demonstrated", "to", "the", "American", "Bankers", "Association", "(", "ABA", ")", "in", "July", "1956", ",", "which", "adopted", "it", "as", "the", "MICR", "standard", "for", "negotiable", "documents", "in", "the", "USA", "in", "1958", "."], "sentence-detokenized": "A trial version of MICR E13B was demonstrated to the American Bankers Association (ABA) in July 1956, which adopted it as the MICR standard for negotiable documents in the USA in 1958.", "token2charspan": [[0, 1], [2, 7], [8, 15], [16, 18], [19, 23], [24, 28], [29, 32], [33, 45], [46, 48], [49, 52], [53, 61], [62, 69], [70, 81], [82, 83], [83, 86], [86, 87], [88, 90], [91, 95], [96, 100], [100, 101], [102, 107], [108, 115], [116, 118], [119, 121], [122, 125], [126, 130], [131, 139], [140, 143], [144, 154], [155, 164], [165, 167], [168, 171], [172, 175], [176, 178], [179, 183], [183, 184]]}
{"doc_key": "ai-test-119", "ner": [[0, 2, "misc"], [13, 14, "field"], [17, 18, "field"], [21, 21, "field"], [23, 24, "field"], [26, 26, "field"], [28, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 14, 0, 2, "usage", "", false, false], [17, 18, 13, 14, "part-of", "", false, false], [21, 21, 0, 2, "usage", "", false, false], [23, 24, 0, 2, "usage", "", false, false], [26, 26, 0, 2, "usage", "", false, false], [28, 28, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "are", "widely", "used", "for", "many", "complex", "computational", "problems", ",", "including", "computer", "science", "(", "especially", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms are widely used for many complex computational problems, including computer science (especially artificial intelligence), mathematics, operations research, engineering and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 27], [28, 34], [35, 39], [40, 43], [44, 48], [49, 56], [57, 70], [71, 79], [79, 80], [81, 90], [91, 99], [100, 107], [108, 109], [109, 119], [120, 130], [131, 143], [143, 144], [144, 145], [146, 157], [157, 158], [159, 169], [170, 178], [178, 179], [180, 191], [192, 195], [196, 210], [210, 211]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [7, 8, "location"], [10, 10, "country"], [14, 14, "country"], [22, 23, "algorithm"], [25, 26, "algorithm"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 7, 8, "physical", "", false, false], [0, 1, 14, 14, "general-affiliation", "nationality", false, false], [0, 1, 22, 23, "general-affiliation", "topic_of_study", false, false], [0, 1, 25, 26, "general-affiliation", "topic_of_study", false, false], [7, 8, 10, 10, "physical", "", false, false], [25, 26, 27, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "born", "3", "September", "1947", "in", "Wallersdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "has", "studied", "the", "use", "of", "bounded", "rationality", "and", "heuristics", "in", "decision", "-", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (born 3 September 1947 in Wallersdorf, Germany) is a German psychologist who has studied the use of bounded rationality and heuristics in decision-making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 21], [22, 23], [24, 33], [34, 38], [39, 41], [42, 53], [53, 54], [55, 62], [62, 63], [64, 66], [67, 68], [69, 75], [76, 88], [89, 92], [93, 96], [97, 104], [105, 108], [109, 112], [113, 115], [116, 123], [124, 135], [136, 139], [140, 150], [151, 153], [154, 162], [162, 163], [163, 169], [169, 170]]}
{"doc_key": "ai-test-121", "ner": [[3, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["to", "reduce", "the", "mean", "squared", "error", "."], "sentence-detokenized": "to reduce the mean squared error.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 18], [19, 26], [27, 32], [32, 33]]}
{"doc_key": "ai-test-122", "ner": [[14, 16, "misc"], [19, 20, "organisation"], [34, 36, "field"], [52, 53, "misc"], [62, 64, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 16, 19, 20, "origin", "", false, false], [52, 53, 62, 64, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "even", "an", "official", "language", "with", "a", "regulating", "academy", ",", "such", "as", "the", "French", "language", "standard", "with", "the", "French", "Academy", ",", "is", "classified", "as", "a", "natural", "language", "(", "e.g.", "in", "the", "field", "of", "natural", "language", "processing", ")", "because", "its", "prescriptive", "clauses", "make", "it", "neither", "sufficiently", "constructed", "to", "be", "classified", "as", "a", "constructed", "language", "nor", "sufficiently", "controlled", "to", "be", "classified", "as", "a", "controlled", "natural", "language", "."], "sentence-detokenized": "However, even an official language with a regulating academy, such as the French language standard with the French Academy, is classified as a natural language (e.g. in the field of natural language processing) because its prescriptive clauses make it neither sufficiently constructed to be classified as a constructed language nor sufficiently controlled to be classified as a controlled natural language.", "token2charspan": [[0, 7], [7, 8], [9, 13], [14, 16], [17, 25], [26, 34], [35, 39], [40, 41], [42, 52], [53, 60], [60, 61], [62, 66], [67, 69], [70, 73], [74, 80], [81, 89], [90, 98], [99, 103], [104, 107], [108, 114], [115, 122], [122, 123], [124, 126], [127, 137], [138, 140], [141, 142], [143, 150], [151, 159], [160, 161], [161, 165], [166, 168], [169, 172], [173, 178], [179, 181], [182, 189], [190, 198], [199, 209], [209, 210], [211, 218], [219, 222], [223, 235], [236, 243], [244, 248], [249, 251], [252, 259], [260, 272], [273, 284], [285, 287], [288, 290], [291, 301], [302, 304], [305, 306], [307, 318], [319, 327], [328, 331], [332, 344], [345, 355], [356, 358], [359, 361], [362, 372], [373, 375], [376, 377], [378, 388], [389, 396], [397, 405], [405, 406]]}
{"doc_key": "ai-test-123", "ner": [[10, 10, "metrics"], [12, 13, "metrics"], [15, 18, "metrics"], [32, 32, "metrics"], [34, 34, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 18, 12, 13, "named", "", false, false], [34, 34, 32, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "several", "other", "metrics", ",", "the", "most", "basic", "being", "accuracy", "or", "Fraction", "Correct", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "all", "cases", "categorised", "correctly", ";", "the", "complement", "is", "Fraction", "Incorrect", "(", "FiC", ")", "."], "sentence-detokenized": "There are several other metrics, the most basic being accuracy or Fraction Correct (FC), which measures the proportion of all cases categorised correctly; the complement is Fraction Incorrect (FiC).", "token2charspan": [[0, 5], [6, 9], [10, 17], [18, 23], [24, 31], [31, 32], [33, 36], [37, 41], [42, 47], [48, 53], [54, 62], [63, 65], [66, 74], [75, 82], [83, 84], [84, 86], [86, 87], [87, 88], [89, 94], [95, 103], [104, 107], [108, 118], [119, 121], [122, 125], [126, 131], [132, 143], [144, 153], [153, 154], [155, 158], [159, 169], [170, 172], [173, 181], [182, 191], [192, 193], [193, 196], [196, 197], [197, 198]]}
{"doc_key": "ai-test-124", "ner": [[0, 3, "researcher"], [9, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 9, 12, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2016", ",", "Cardy", "became", "a", "member", "of", "the", "Association", "for", "Computational", "Linguistics", "."], "sentence-detokenized": "In 2016, Cardy became a member of the Association for Computational Linguistics.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 21], [22, 23], [24, 30], [31, 33], [34, 37], [38, 49], [50, 53], [54, 67], [68, 79], [79, 80]]}
{"doc_key": "ai-test-125", "ner": [[14, 16, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "teaching", "of", "the", "parameters", "math", "\\", "theta", "/", "math", "is", "usually", "done", "using", "maximum", "likelihood", "teaching", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";\\", "theta", ")", "/", "math", "."], "sentence-detokenized": "The teaching of the parameters math\\ theta / math is usually done using maximum likelihood teaching mathp (Y _ i | X _ i;\\ theta) / math.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 30], [31, 35], [35, 36], [37, 42], [43, 44], [45, 49], [50, 52], [53, 60], [61, 65], [66, 71], [72, 79], [80, 90], [91, 99], [100, 105], [106, 107], [107, 108], [109, 110], [111, 112], [113, 114], [115, 116], [117, 118], [119, 120], [120, 122], [123, 128], [128, 129], [130, 131], [132, 136], [136, 137]]}
{"doc_key": "ai-test-126", "ner": [[0, 1, "task"], [3, 5, "algorithm"], [6, 8, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 8, 0, 1, "usage", "", true, false], [6, 8, 3, 5, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cluster", "analysis", "and", "non-negative", "matrix", "factorisation", "for", "descriptive", "mining", "."], "sentence-detokenized": "Cluster analysis and non-negative matrix factorisation for descriptive mining.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 33], [34, 40], [41, 54], [55, 58], [59, 70], [71, 77], [77, 78]]}
{"doc_key": "ai-test-127", "ner": [[0, 2, "field"], [5, 7, "field"], [25, 27, "field"], [29, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 27, 0, 2, "part-of", "", false, false], [25, 27, 5, 7, "part-of", "", false, false], [29, 30, 0, 2, "part-of", "", false, false], [29, 30, 5, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", "and", "the", "information", "technology", "it", "provides", ",", "it", "has", "been", "a", "long", "-", "term", "challenge", "to", "the", "ability", "of", "computers", "to", "perform", "natural", "language", "processing", "and", "machine", "learning", "."], "sentence-detokenized": "In computer science and the information technology it provides, it has been a long-term challenge to the ability of computers to perform natural language processing and machine learning.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 23], [24, 27], [28, 39], [40, 50], [51, 53], [54, 62], [62, 63], [64, 66], [67, 70], [71, 75], [76, 77], [78, 82], [82, 83], [83, 87], [88, 97], [98, 100], [101, 104], [105, 112], [113, 115], [116, 125], [126, 128], [129, 136], [137, 144], [145, 153], [154, 164], [165, 168], [169, 176], [177, 185], [185, 186]]}
{"doc_key": "ai-test-128", "ner": [[4, 7, "algorithm"], [8, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 7, 8, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "The", "code", "for", "extracting", "Gabor", "features", "from", "MATLAB", "images", "can", "be", "found", "at"], "sentence-detokenized": "(The code for extracting Gabor features from MATLAB images can be found at", "token2charspan": [[0, 1], [1, 4], [5, 9], [10, 13], [14, 24], [25, 30], [31, 39], [40, 44], [45, 51], [52, 58], [59, 62], [63, 65], [66, 71], [72, 74]]}
{"doc_key": "ai-test-129", "ner": [[0, 0, "misc"], [14, 15, "algorithm"], [19, 19, "task"], [21, 21, "task"], [23, 24, "task"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 14, 15, "general-affiliation", "", false, false], [0, 0, 19, 19, "related-to", "solves_problem_of_type", false, false], [0, 0, 21, 21, "related-to", "solves_problem_of_type", false, false], [0, 0, 23, 24, "related-to", "solves_problem_of_type", false, false], [0, 0, 26, 27, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["NeuralExpert", "focuses", "the", "design", "specifications", "on", "the", "type", "of", "problem", "the", "user", "wants", "the", "neural", "network", "to", "solve", "(", "classification", ",", "prediction", ",", "feature", "approximation", "or", "cluster", "analysis", ")", "."], "sentence-detokenized": "NeuralExpert focuses the design specifications on the type of problem the user wants the neural network to solve (classification, prediction, feature approximation or cluster analysis).", "token2charspan": [[0, 12], [13, 20], [21, 24], [25, 31], [32, 46], [47, 49], [50, 53], [54, 58], [59, 61], [62, 69], [70, 73], [74, 78], [79, 84], [85, 88], [89, 95], [96, 103], [104, 106], [107, 112], [113, 114], [114, 128], [128, 129], [130, 140], [140, 141], [142, 149], [150, 163], [164, 166], [167, 174], [175, 183], [183, 184], [184, 185]]}
{"doc_key": "ai-test-130", "ner": [[2, 6, "misc"], [31, 35, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "size", "of", "the", "quantisation", "step", "(", "\u0394", ")", "is", "small", "relative", "to", "the", "variation", "of", "the", "signal", "to", "be", "quantised", ",", "it", "is", "relatively", "straightforward", "to", "show", "that", "the", "root", "mean", "square", "error", "of", "such", "a", "rounding", "operation", "will", "be", "approximately", "math", "\\", "Delta^2/12/math.math."], "sentence-detokenized": "If the size of the quantisation step (\u0394) is small relative to the variation of the signal to be quantised, it is relatively straightforward to show that the root mean square error of such a rounding operation will be approximately math\\ Delta^2/12/math.math.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 18], [19, 31], [32, 36], [37, 38], [38, 39], [39, 40], [41, 43], [44, 49], [50, 58], [59, 61], [62, 65], [66, 75], [76, 78], [79, 82], [83, 89], [90, 92], [93, 95], [96, 105], [105, 106], [107, 109], [110, 112], [113, 123], [124, 139], [140, 142], [143, 147], [148, 152], [153, 156], [157, 161], [162, 166], [167, 173], [174, 179], [180, 182], [183, 187], [188, 189], [190, 198], [199, 208], [209, 213], [214, 216], [217, 230], [231, 235], [235, 236], [237, 258]]}
{"doc_key": "ai-test-131", "ner": [[15, 15, "product"], [25, 28, "researcher"], [30, 31, "researcher"], [33, 35, "researcher"], [37, 38, "researcher"], [40, 42, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["To", "build", "a", "rich", "lexicon", "with", "a", "suitable", "ontology", "requires", "considerable", "effort", ",", "e.g.", "the", "Wordnet", "lexicon", "took", "many", "man", "-", "years", "of", "work", ".", "G.", "A", ".", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "To build a rich lexicon with a suitable ontology requires considerable effort, e.g. the Wordnet lexicon took many man-years of work. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 15], [16, 23], [24, 28], [29, 30], [31, 39], [40, 48], [49, 57], [58, 70], [71, 77], [77, 78], [79, 83], [84, 87], [88, 95], [96, 103], [104, 108], [109, 113], [114, 117], [117, 118], [118, 123], [124, 126], [127, 131], [131, 132], [133, 135], [136, 137], [137, 138], [139, 145], [145, 146], [147, 149], [150, 158], [158, 159], [160, 162], [163, 165], [166, 174], [174, 175], [176, 178], [179, 184], [184, 185], [186, 187], [187, 188], [189, 195], [195, 196]]}
{"doc_key": "ai-test-132", "ner": [[0, 0, "organisation"], [15, 16, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kawasaki", "'s", "portfolio", "also", "includes", "retractable", "roofs", ",", "floors", "and", "other", "giant", "structures", ",", "the", "Sapporo", "Dome", "\"", "retractable", "surface", "\"", "being", "one", "example", "."], "sentence-detokenized": "Kawasaki's portfolio also includes retractable roofs, floors and other giant structures, the Sapporo Dome \"retractable surface\" being one example.", "token2charspan": [[0, 8], [8, 10], [11, 20], [21, 25], [26, 34], [35, 46], [47, 52], [52, 53], [54, 60], [61, 64], [65, 70], [71, 76], [77, 87], [87, 88], [89, 92], [93, 100], [101, 105], [106, 107], [107, 118], [119, 126], [126, 127], [128, 133], [134, 137], [138, 145], [145, 146]]}
{"doc_key": "ai-test-133", "ner": [[0, 3, "metrics"], [5, 6, "metrics"], [8, 10, "metrics"], [16, 19, "metrics"], [34, 34, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 16, 19, "related-to", "", false, false], [0, 3, 34, 34, "opposite", "alternative_to", false, false], [5, 6, 0, 3, "type-of", "", false, false], [8, 10, 0, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa", "statistics", ",", "such", "as", "Fleiss", "kappa", "and", "Cohen", "'s", "kappa", ",", "are", "methods", "that", "calculate", "inter-rater", "reliability", "based", "on", "different", "assumptions", "about", "the", "extreme", "or", "prior", "distributions", "and", "are", "increasingly", "used", "as", "randomized", "accuracy", "alternatives", "in", "other", "contexts", "."], "sentence-detokenized": "Kappa statistics, such as Fleiss kappa and Cohen's kappa, are methods that calculate inter-rater reliability based on different assumptions about the extreme or prior distributions and are increasingly used as randomized accuracy alternatives in other contexts.", "token2charspan": [[0, 5], [6, 16], [16, 17], [18, 22], [23, 25], [26, 32], [33, 38], [39, 42], [43, 48], [48, 50], [51, 56], [56, 57], [58, 61], [62, 69], [70, 74], [75, 84], [85, 96], [97, 108], [109, 114], [115, 117], [118, 127], [128, 139], [140, 145], [146, 149], [150, 157], [158, 160], [161, 166], [167, 180], [181, 184], [185, 188], [189, 201], [202, 206], [207, 209], [210, 220], [221, 229], [230, 242], [243, 245], [246, 251], [252, 260], [260, 261]]}
{"doc_key": "ai-test-134", "ner": [[3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 13, "researcher"], [17, 17, "researcher"], [26, 28, "algorithm"], [30, 34, "algorithm"], [36, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 4, 17, 17, "role", "student_of", false, false], [6, 7, 17, 17, "role", "student_of", false, false], [9, 10, 17, 17, "role", "student_of", false, false], [12, 13, 17, 17, "role", "student_of", false, false], [30, 34, 3, 4, "origin", "", false, false], [30, 34, 6, 7, "origin", "", false, false], [30, 34, 9, 10, "origin", "", false, false], [30, 34, 12, 13, "origin", "", false, false], [30, 34, 17, 17, "origin", "", false, false], [30, 34, 26, 28, "type-of", "", false, false], [36, 36, 30, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["With", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Greaves", "and", "others", ",", "Schmidhuber", "published", "increasingly", "sophisticated", "versions", "of", "a", "type", "of", "recurrent", "neural", "network", "called", "long", "short", "-", "term", "memory", "(", "LSTM", ")", "."], "sentence-detokenized": "With his students Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Greaves and others, Schmidhuber published increasingly sophisticated versions of a type of recurrent neural network called long short-term memory (LSTM).", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 22], [23, 33], [33, 34], [35, 40], [41, 45], [45, 46], [47, 51], [52, 59], [59, 60], [61, 65], [66, 73], [74, 77], [78, 84], [84, 85], [86, 97], [98, 107], [108, 120], [121, 134], [135, 143], [144, 146], [147, 148], [149, 153], [154, 156], [157, 166], [167, 173], [174, 181], [182, 188], [189, 193], [194, 199], [199, 200], [200, 204], [205, 211], [212, 213], [213, 217], [217, 218], [218, 219]]}
{"doc_key": "ai-test-135", "ner": [[4, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "The", "first", "Cobot", "KUKA", "LBR", "3", "is", "launched", "."], "sentence-detokenized": "2004 - The first Cobot KUKA LBR 3 is launched.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 22], [23, 27], [28, 31], [32, 33], [34, 36], [37, 45], [45, 46]]}
{"doc_key": "ai-test-136", "ner": [[11, 13, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "shallow", "approaches", "used", "to", "train", "and", "then", "separate", "are", "the", "Naive", "Bayes", "classifier", "and", "decision", "trees", "."], "sentence-detokenized": "Two shallow approaches used to train and then separate are the Naive Bayes classifier and decision trees.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 27], [28, 30], [31, 36], [37, 40], [41, 45], [46, 54], [55, 58], [59, 62], [63, 68], [69, 74], [75, 85], [86, 89], [90, 98], [99, 104], [104, 105]]}
{"doc_key": "ai-test-137", "ner": [[3, 3, "misc"], [10, 11, "person"], [13, 15, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 10, 11, "origin", "", false, false], [3, 3, 13, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "practical", "photograph", "was", "taken", "in", "January", "1839", "by", "Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "The first practical photograph was taken in January 1839 by Louis Daguerre and Henry Fox Talbot.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 30], [31, 34], [35, 40], [41, 43], [44, 51], [52, 56], [57, 59], [60, 65], [66, 74], [75, 78], [79, 84], [85, 88], [89, 95], [95, 96]]}
{"doc_key": "ai-test-138", "ner": [[3, 4, "task"], [7, 8, "task"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 15, 16, "part-of", "task_part_of_field", false, false], [7, 8, 15, 16, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "speech", "synthesis", "combined", "with", "speech", "recognition", "allows", "interactions", "with", "mobile", "devices", "through", "language", "processing", "interfaces", "."], "sentence-detokenized": "For example, speech synthesis combined with speech recognition allows interactions with mobile devices through language processing interfaces.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [30, 38], [39, 43], [44, 50], [51, 62], [63, 69], [70, 82], [83, 87], [88, 94], [95, 102], [103, 110], [111, 119], [120, 130], [131, 141], [141, 142]]}
{"doc_key": "ai-test-139", "ner": [[0, 0, "product"], [14, 14, "programlang"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 14, "general-affiliation", "", false, false], [0, 0, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Phidgets", "can", "be", "programmed", "using", "a", "variety", "of", "software", "and", "programming", "languages", ",", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "Phidgets can be programmed using a variety of software and programming languages, from Java to Microsoft Excel.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 26], [27, 32], [33, 34], [35, 42], [43, 45], [46, 54], [55, 58], [59, 70], [71, 80], [80, 81], [82, 86], [87, 91], [92, 94], [95, 104], [105, 110], [110, 111]]}
{"doc_key": "ai-test-140", "ner": [[3, 4, "field"], [11, 12, "researcher"], [13, 17, "misc"], [22, 23, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 11, 12, "origin", "", false, false], [11, 12, 22, 23, "general-affiliation", "topic_of_study", false, false], [11, 12, 25, 26, "general-affiliation", "topic_of_study", false, false], [13, 17, 11, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "\"", "machine", "learning", "\"", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "an", "American", "IBM", "employee", "and", "a", "pioneer", "in", "computer", "games", "and", "artificial", "intelligence", "."], "sentence-detokenized": "The term \"machine learning\" was coined in 1959 by Arthur Samuel, an American IBM employee and a pioneer in computer games and artificial intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 17], [18, 26], [26, 27], [28, 31], [32, 38], [39, 41], [42, 46], [47, 49], [50, 56], [57, 63], [63, 64], [65, 67], [68, 76], [77, 80], [81, 89], [90, 93], [94, 95], [96, 103], [104, 106], [107, 115], [116, 121], [122, 125], [126, 136], [137, 149], [149, 150]]}
{"doc_key": "ai-test-141", "ner": [[0, 1, "misc"], [2, 3, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Israeli", "poet", "David", "Avidan", ",", "fascinated", "by", "future", "technologies", "and", "their", "relationship", "to", "art", ",", "wanted", "to", "explore", "the", "use", "of", "computers", "in", "writing", "literature", "."], "sentence-detokenized": "Israeli poet David Avidan, fascinated by future technologies and their relationship to art, wanted to explore the use of computers in writing literature.", "token2charspan": [[0, 7], [8, 12], [13, 18], [19, 25], [25, 26], [27, 37], [38, 40], [41, 47], [48, 60], [61, 64], [65, 70], [71, 83], [84, 86], [87, 90], [90, 91], [92, 98], [99, 101], [102, 109], [110, 113], [114, 117], [118, 120], [121, 130], [131, 133], [134, 141], [142, 152], [152, 153]]}
{"doc_key": "ai-test-142", "ner": [[3, 8, "misc"], [10, 10, "organisation"], [15, 16, "location"], [27, 28, "location"], [29, 32, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 10, 3, 8, "part-of", "", false, false], [29, 32, 27, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "as", "part", "of", "the", "GATEway", "project", ",", "Oxbotica", "trialled", "seven", "autonomous", "buses", "in", "Greenwich", ",", "travelling", "along", "a", "two", "-", "mile", "river", "path", "near", "London", "'s", "O2", "arena", "on", "a", "route", "also", "used", "by", "pedestrians", "and", "cyclists", "."], "sentence-detokenized": "In 2017, as part of the GATEway project, Oxbotica trialled seven autonomous buses in Greenwich, travelling along a two-mile river path near London's O2 arena on a route also used by pedestrians and cyclists.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 16], [17, 19], [20, 23], [24, 31], [32, 39], [39, 40], [41, 49], [50, 58], [59, 64], [65, 75], [76, 81], [82, 84], [85, 94], [94, 95], [96, 106], [107, 112], [113, 114], [115, 118], [118, 119], [119, 123], [124, 129], [130, 134], [135, 139], [140, 146], [146, 148], [149, 151], [152, 157], [158, 160], [161, 162], [163, 168], [169, 173], [174, 178], [179, 181], [182, 193], [194, 197], [198, 206], [206, 207]]}
{"doc_key": "ai-test-143", "ner": [[8, 9, "task"], [13, 17, "metrics"], [24, 26, "misc"], [27, 27, "metrics"], [29, 29, "metrics"], [32, 32, "metrics"], [34, 34, "metrics"], [36, 38, "metrics"], [41, 41, "metrics"], [43, 43, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[13, 17, 24, 26, "related-to", "is_a", false, false], [13, 17, 27, 27, "usage", "", false, false], [13, 17, 29, 29, "usage", "", false, false], [27, 27, 32, 32, "named", "same", false, false], [29, 29, 43, 43, "named", "same", false, false], [32, 32, 41, 41, "opposite", "", false, false], [32, 32, 43, 43, "opposite", "", false, false], [34, 34, 32, 32, "named", "", false, false], [36, 38, 32, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["An", "unrelated", "but", "frequently", "used", "combination", "of", "basic", "information", "retrieval", "statistics", "is", "the", "F", "-", "score", ",", "which", "is", "a", "(", "possibly", "weighted", ")", "harmonic", "mean", "of", "recall", "and", "precision", ",", "where", "recall", "=", "sensitivity", "=", "true", "hit", "rate", ",", "and", "specificity", "and", "precision", "are", "completely", "different", "indicators", "."], "sentence-detokenized": "An unrelated but frequently used combination of basic information retrieval statistics is the F-score, which is a (possibly weighted) harmonic mean of recall and precision, where recall = sensitivity = true hit rate, and specificity and precision are completely different indicators.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 27], [28, 32], [33, 44], [45, 47], [48, 53], [54, 65], [66, 75], [76, 86], [87, 89], [90, 93], [94, 95], [95, 96], [96, 101], [101, 102], [103, 108], [109, 111], [112, 113], [114, 115], [115, 123], [124, 132], [132, 133], [134, 142], [143, 147], [148, 150], [151, 157], [158, 161], [162, 171], [171, 172], [173, 178], [179, 185], [186, 187], [188, 199], [200, 201], [202, 206], [207, 210], [211, 215], [215, 216], [217, 220], [221, 232], [233, 236], [237, 246], [247, 250], [251, 261], [262, 271], [272, 282], [282, 283]]}
{"doc_key": "ai-test-144", "ner": [[0, 1, "field"], [10, 10, "field"], [12, 12, "field"], [14, 14, "field"], [16, 17, "field"], [19, 21, "field"], [28, 29, "product"], [31, 34, "product"], [37, 37, "product"], [39, 41, "product"], [51, 54, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 10, "origin", "takes_inspiration_from", false, false], [0, 1, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 1, 14, 14, "origin", "takes_inspiration_from", false, false], [0, 1, 16, 17, "origin", "takes_inspiration_from", false, false], [0, 1, 19, 21, "origin", "takes_inspiration_from", false, false], [28, 29, 0, 1, "origin", "", false, false], [31, 34, 0, 1, "origin", "", false, false], [37, 37, 0, 1, "origin", "", false, false], [39, 41, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "is", "an", "interdisciplinary", "subject", "that", "draws", "inspiration", "from", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", "and", "electronic", "engineering", "to", "develop", "artificial", "nervous", "systems", "such", "as", "vision", "systems", ",", "head", "and", "eye", "systems", ",", "auditory", "processors", "and", "autonomous", "robots", "whose", "physical", "architecture", "and", "design", "principles", "are", "based", "on", "those", "of", "biological", "nervous", "systems", "."], "sentence-detokenized": "Neuromorphic engineering is an interdisciplinary subject that draws inspiration from biology, physics, mathematics, computer science and electronic engineering to develop artificial nervous systems such as vision systems, head and eye systems, auditory processors and autonomous robots whose physical architecture and design principles are based on those of biological nervous systems.", "token2charspan": [[0, 12], [13, 24], [25, 27], [28, 30], [31, 48], [49, 56], [57, 61], [62, 67], [68, 79], [80, 84], [85, 92], [92, 93], [94, 101], [101, 102], [103, 114], [114, 115], [116, 124], [125, 132], [133, 136], [137, 147], [148, 159], [160, 162], [163, 170], [171, 181], [182, 189], [190, 197], [198, 202], [203, 205], [206, 212], [213, 220], [220, 221], [222, 226], [227, 230], [231, 234], [235, 242], [242, 243], [244, 252], [253, 263], [264, 267], [268, 278], [279, 285], [286, 291], [292, 300], [301, 313], [314, 317], [318, 324], [325, 335], [336, 339], [340, 345], [346, 348], [349, 354], [355, 357], [358, 368], [369, 376], [377, 384], [384, 385]]}
{"doc_key": "ai-test-145", "ner": [[4, 6, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 10, 4, 6, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["More", "specifically", ",", "the", "BIBO", "stability", "criterion", "requires", "that", "the", "ROC", "of", "the", "system", "contains", "a", "unit", "circle", "."], "sentence-detokenized": "More specifically, the BIBO stability criterion requires that the ROC of the system contains a unit circle.", "token2charspan": [[0, 4], [5, 17], [17, 18], [19, 22], [23, 27], [28, 37], [38, 47], [48, 56], [57, 61], [62, 65], [66, 69], [70, 72], [73, 76], [77, 83], [84, 92], [93, 94], [95, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-146", "ner": [[6, 8, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "The", "programme", "was", "rewritten", "in", "Java", "from", "1998", "onwards", "."], "sentence-detokenized": "2 The programme was rewritten in Java from 1998 onwards.", "token2charspan": [[0, 1], [2, 5], [6, 15], [16, 19], [20, 29], [30, 32], [33, 37], [38, 42], [43, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-test-147", "ner": [[0, 1, "metrics"], [8, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 8, 11, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "MCC", "can", "be", "calculated", "directly", "from", "the", "mixing", "matrix", "using", "the", "formula", ":"], "sentence-detokenized": "The MCC can be calculated directly from the mixing matrix using the formula:", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 25], [26, 34], [35, 39], [40, 43], [44, 50], [51, 57], [58, 63], [64, 67], [68, 75], [75, 76]]}
{"doc_key": "ai-test-148", "ner": [[5, 10, "organisation"], [17, 22, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 10, 17, 22, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "developed", "by", "the", "MIT", "-", "IBM", "Watson", "AI", "Lab", "team", "and", "first", "presented", "at", "the", "2018", "International", "Conference", "on", "Learning", "Representations", "."], "sentence-detokenized": "It was developed by the MIT-IBM Watson AI Lab team and first presented at the 2018 International Conference on Learning Representations.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 23], [24, 27], [27, 28], [28, 31], [32, 38], [39, 41], [42, 45], [46, 50], [51, 54], [55, 60], [61, 70], [71, 73], [74, 77], [78, 82], [83, 96], [97, 107], [108, 110], [111, 119], [120, 135], [135, 136]]}
{"doc_key": "ai-test-149", "ner": [[2, 4, "metrics"], [15, 17, "metrics"], [19, 24, "metrics"], [48, 48, "metrics"], [50, 50, "metrics"], [56, 58, "metrics"], [61, 61, "metrics"], [63, 63, "metrics"], [65, 67, "metrics"], [72, 72, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[15, 17, 48, 48, "type-of", "", false, false], [15, 17, 56, 58, "related-to", "collapses_to_identity", false, false], [19, 24, 50, 50, "type-of", "", false, false], [19, 24, 56, 58, "related-to", "collapses_to_identity", false, false], [19, 24, 65, 67, "named", "same", false, false], [61, 61, 72, 72, "related-to", "collapses_to_identity", false, false], [63, 63, 72, 72, "related-to", "collapses_to_identity", false, false], [65, 67, 72, 72, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["If", "the", "true", "prevalences", "of", "the", "two", "positive", "variables", "are", "equal", ",", "as", "assumed", "for", "the", "Fleiss", "kappa", "and", "F", "-", "score", ",", "i.e.", "the", "number", "of", "positive", "predictions", "coincides", "with", "the", "number", "of", "positive", "classes", "in", "the", "dichotomous", "(", "two", "-", "class", ")", "case", ",", "the", "different", "kappa", "and", "correlation", "measure", "collapse", "to", "identity", "with", "Juden", "'s", "J", ",", "and", "recall", ",", "precision", "and", "F", "-", "score", "are", "similarly", "identical", "with", "precision", "."], "sentence-detokenized": "If the true prevalences of the two positive variables are equal, as assumed for the Fleiss kappa and F-score, i.e. the number of positive predictions coincides with the number of positive classes in the dichotomous (two-class) case, the different kappa and correlation measure collapse to identity with Juden's J, and recall, precision and F-score are similarly identical with precision.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 23], [24, 26], [27, 30], [31, 34], [35, 43], [44, 53], [54, 57], [58, 63], [63, 64], [65, 67], [68, 75], [76, 79], [80, 83], [84, 90], [91, 96], [97, 100], [101, 102], [102, 103], [103, 108], [108, 109], [110, 114], [115, 118], [119, 125], [126, 128], [129, 137], [138, 149], [150, 159], [160, 164], [165, 168], [169, 175], [176, 178], [179, 187], [188, 195], [196, 198], [199, 202], [203, 214], [215, 216], [216, 219], [219, 220], [220, 225], [225, 226], [227, 231], [231, 232], [233, 236], [237, 246], [247, 252], [253, 256], [257, 268], [269, 276], [277, 285], [286, 288], [289, 297], [298, 302], [303, 308], [308, 310], [311, 312], [312, 313], [314, 317], [318, 324], [324, 325], [326, 335], [336, 339], [340, 341], [341, 342], [342, 347], [348, 351], [352, 361], [362, 371], [372, 376], [377, 386], [386, 387]]}
{"doc_key": "ai-test-150", "ner": [[13, 15, "misc"], [18, 18, "misc"], [9, 9, "conference"], [2, 20, "task"], [21, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 15, 9, 9, "part-of", "", false, false], [13, 15, 9, 9, "physical", "", false, false], [13, 15, 9, 9, "temporal", "", false, false], [18, 18, 13, 15, "named", "", false, false], [2, 20, 13, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "first", "NLI", "Joint", "Exercise", "took", "place", "at", "the", "NAACL", "2013", "Workshop", "\"", "Building", "Educational", "Applications", "\"", "(", "BEA", ")", ".", "Tetreault", "et", "al", ",", "2013", "29", "teams", "from", "all", "over", "the", "world", "participated", "in", "the", "competition", ",", "24", "of", "which", "also", "published", "a", "paper", "describing", "their", "systems", "and", "approaches", "."], "sentence-detokenized": "The first NLI Joint Exercise took place at the NAACL 2013 Workshop \"Building Educational Applications\" (BEA). Tetreault et al, 2013 29 teams from all over the world participated in the competition, 24 of which also published a paper describing their systems and approaches.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 19], [20, 28], [29, 33], [34, 39], [40, 42], [43, 46], [47, 52], [53, 57], [58, 66], [67, 68], [68, 76], [77, 88], [89, 101], [101, 102], [103, 104], [104, 107], [107, 108], [108, 109], [110, 119], [120, 122], [123, 125], [125, 126], [127, 131], [132, 134], [135, 140], [141, 145], [146, 149], [150, 154], [155, 158], [159, 164], [165, 177], [178, 180], [181, 184], [185, 196], [196, 197], [198, 200], [201, 203], [204, 209], [210, 214], [215, 224], [225, 226], [227, 232], [233, 243], [244, 249], [250, 257], [258, 261], [262, 272], [272, 273]]}
{"doc_key": "ai-test-151", "ner": [[0, 2, "algorithm"], [5, 8, "algorithm"], [15, 16, "misc"], [20, 26, "misc"], [37, 38, "misc"], [41, 42, "algorithm"], [45, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 5, 8, "type-of", "", false, false], [0, 2, 15, 16, "related-to", "finds", false, false], [20, 26, 15, 16, "type-of", "", false, false], [45, 45, 41, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Viterbi", "algorithm", "is", "a", "dynamic", "programming", "algorithm", "for", "finding", "the", "most", "likely", "sequence", "of", "hidden", "states", ",", "called", "the", "Viterbi", "path", ",", "which", "results", "in", "a", "sequence", "of", "observable", "events", ",", "especially", "in", "the", "context", "of", "Markov", "information", "sources", "and", "Hidden", "Markov", "Models", "(", "HMMs", ")", "."], "sentence-detokenized": "The Viterbi algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states, called the Viterbi path, which results in a sequence of observable events, especially in the context of Markov information sources and Hidden Markov Models (HMMs).", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 24], [25, 26], [27, 34], [35, 46], [47, 56], [57, 60], [61, 68], [69, 72], [73, 77], [78, 84], [85, 93], [94, 96], [97, 103], [104, 110], [110, 111], [112, 118], [119, 122], [123, 130], [131, 135], [135, 136], [137, 142], [143, 150], [151, 153], [154, 155], [156, 164], [165, 167], [168, 178], [179, 185], [185, 186], [187, 197], [198, 200], [201, 204], [205, 212], [213, 215], [216, 222], [223, 234], [235, 242], [243, 246], [247, 253], [254, 260], [261, 267], [268, 269], [269, 273], [273, 274], [274, 275]]}
{"doc_key": "ai-test-152", "ner": [[0, 1, "field"], [3, 5, "algorithm"], [8, 10, "misc"], [12, 13, "algorithm"], [15, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 0, 1, "part-of", "", false, false], [3, 5, 8, 10, "general-affiliation", "", false, false], [3, 5, 12, 13, "related-to", "generalizes_from", false, false], [3, 5, 15, 18, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "multinomial", "logistic", "regression", "is", "a", "classification", "method", "that", "generalises", "logistic", "regression", "to", "multiclass", "classification", ",", "i.e.", "with", "more", "than", "two", "possible", "discrete", "outcomes", "."], "sentence-detokenized": "In statistics, multinomial logistic regression is a classification method that generalises logistic regression to multiclass classification, i.e. with more than two possible discrete outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 26], [27, 35], [36, 46], [47, 49], [50, 51], [52, 66], [67, 73], [74, 78], [79, 90], [91, 99], [100, 110], [111, 113], [114, 124], [125, 139], [139, 140], [141, 145], [146, 150], [151, 155], [156, 160], [161, 164], [165, 173], [174, 182], [183, 191], [191, 192]]}
{"doc_key": "ai-test-153", "ner": [[0, 2, "algorithm"], [9, 10, "field"], [12, 16, "field"], [17, 17, "task"], [19, 20, "task"], [22, 23, "task"], [25, 26, "researcher"], [28, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 9, 10, "part-of", "", false, false], [0, 2, 12, 16, "part-of", "", false, false], [17, 17, 0, 2, "usage", "", true, false], [19, 20, 0, 2, "usage", "", true, false], [22, 23, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden", "Markov", "models", "are", "known", "for", "their", "applications", "in", "reinforcement", "learning", "and", "temporal", "pattern", "recognition", ",", "e.g.", "speech", ",", "handwriting", "recognition", ",", "gesture", "recognition", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov models are known for their applications in reinforcement learning and temporal pattern recognition, e.g. speech, handwriting recognition, gesture recognition, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 30], [31, 34], [35, 40], [41, 53], [54, 56], [57, 70], [71, 79], [80, 83], [84, 92], [93, 100], [101, 112], [112, 113], [114, 118], [119, 125], [125, 126], [127, 138], [139, 150], [150, 151], [152, 159], [160, 171], [171, 172], [173, 177], [178, 185], [185, 186], [187, 191], [192, 200], [200, 201]]}
{"doc_key": "ai-test-154", "ner": [[7, 10, "misc"], [33, 37, "metrics"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 38, 39, "named", "", false, false], [33, 37, 38, 39, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "essence", ",", "this", "means", "that", "if", "a", "given", "grammar", "is", "seen", "more", "than", "k", "times", "during", "training", ",", "the", "conditional", "probability", "of", "the", "word", ",", "given", "its", "history", ",", "is", "proportional", "to", "the", "maximum", "likelihood", "estimate", "of", "that", "grammar", "."], "sentence-detokenized": "In essence, this means that if a given grammar is seen more than k times during training, the conditional probability of the word, given its history, is proportional to the maximum likelihood estimate of that grammar.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [17, 22], [23, 27], [28, 30], [31, 32], [33, 38], [39, 46], [47, 49], [50, 54], [55, 59], [60, 64], [65, 66], [67, 72], [73, 79], [80, 88], [88, 89], [90, 93], [94, 105], [106, 117], [118, 120], [121, 124], [125, 129], [129, 130], [131, 136], [137, 140], [141, 148], [148, 149], [150, 152], [153, 165], [166, 168], [169, 172], [173, 180], [181, 191], [192, 200], [201, 203], [204, 208], [209, 216], [216, 217]]}
{"doc_key": "ai-test-155", "ner": [[4, 5, "task"], [7, 7, "task"], [9, 11, "task"], [15, 19, "task"], [33, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[33, 36, 15, 19, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "knowledge", "representation", ",", "reasoning", "and", "natural", "language", "understanding", ",", "believing", "that", "a", "deeper", "understanding", "of", "language", "can", "currently", "only", "be", "achieved", "through", "a", "significant", "amount", "of", "semantically", "rich", "formalism", "hand", "-", "engineered", "with", "statistical", "preferences", "."], "sentence-detokenized": "He is interested in knowledge representation, reasoning and natural language understanding, believing that a deeper understanding of language can currently only be achieved through a significant amount of semantically rich formalism hand-engineered with statistical preferences.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 29], [30, 44], [44, 45], [46, 55], [56, 59], [60, 67], [68, 76], [77, 90], [90, 91], [92, 101], [102, 106], [107, 108], [109, 115], [116, 129], [130, 132], [133, 141], [142, 145], [146, 155], [156, 160], [161, 163], [164, 172], [173, 180], [181, 182], [183, 194], [195, 201], [202, 204], [205, 217], [218, 222], [223, 232], [233, 237], [237, 238], [238, 248], [249, 253], [254, 265], [266, 277], [277, 278]]}
{"doc_key": "ai-test-156", "ner": [[0, 0, "programlang"], [2, 2, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["JavaScript", ",", "Python", "or"], "sentence-detokenized": "JavaScript, Python or", "token2charspan": [[0, 10], [10, 11], [12, 18], [19, 21]]}
{"doc_key": "ai-test-157", "ner": [[2, 2, "misc"], [6, 11, "misc"], [11, 11, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 6, 11, "part-of", "", false, false], [6, 11, 11, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "Awards", "are", "announced", "in", "AI", "Magazine", ",", "published", "by", "AAAI", "."], "sentence-detokenized": "The Newcomb Awards are announced in AI Magazine, published by AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 32], [33, 35], [36, 38], [39, 47], [47, 48], [49, 58], [59, 61], [62, 66], [66, 67]]}
{"doc_key": "ai-test-158", "ner": [[0, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "root", "mean", "square", "error", "for", "a", "test", "set", "of", "100", "copies", "is", "0.084", ",", "which", "is", "less", "than", "the", "unnormalised", "error", "."], "sentence-detokenized": "The root mean square error for a test set of 100 copies is 0.084, which is less than the unnormalised error.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 20], [21, 26], [27, 30], [31, 32], [33, 37], [38, 41], [42, 44], [45, 48], [49, 55], [56, 58], [59, 64], [64, 65], [66, 71], [72, 74], [75, 79], [80, 84], [85, 88], [89, 101], [102, 107], [107, 108]]}
{"doc_key": "ai-test-159", "ner": [[0, 2, "metrics"], [9, 11, "field"], [16, 18, "task"], [20, 20, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 11, 0, 2, "usage", "", false, false], [16, 18, 9, 11, "part-of", "task_part_of_field", false, false], [20, 20, 16, 18, "named", "", false, false], [23, 24, 9, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["F", "-", "score", "has", "been", "widely", "used", "in", "the", "natural", "language", "processing", "literature", ",", "e.g.", "in", "named", "entity", "recognition", "(", "NER", ")", "and", "word", "segmentation", "evaluation", "."], "sentence-detokenized": "F-score has been widely used in the natural language processing literature, e.g. in named entity recognition (NER) and word segmentation evaluation.", "token2charspan": [[0, 1], [1, 2], [2, 7], [8, 11], [12, 16], [17, 23], [24, 28], [29, 31], [32, 35], [36, 43], [44, 52], [53, 63], [64, 74], [74, 75], [76, 80], [81, 83], [84, 89], [90, 96], [97, 108], [109, 110], [110, 113], [113, 114], [115, 118], [119, 123], [124, 136], [137, 147], [147, 148]]}
{"doc_key": "ai-test-160", "ner": [[0, 0, "product"], [5, 7, "product"], [17, 18, "misc"], [20, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 17, 18, "related-to", "performs_task", false, false], [0, 0, 20, 21, "related-to", "performs_task", false, false], [5, 7, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "commonly", "used", "in", "dialogue", "systems", "for", "a", "variety", "of", "purposes", ",", "including", "customer", "service", ",", "request", "routing", "or", "information", "gathering", "."], "sentence-detokenized": "Chatbots are commonly used in dialogue systems for a variety of purposes, including customer service, request routing or information gathering.", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 26], [27, 29], [30, 38], [39, 46], [47, 50], [51, 52], [53, 60], [61, 63], [64, 72], [72, 73], [74, 83], [84, 92], [93, 100], [100, 101], [102, 109], [110, 117], [118, 120], [121, 132], [133, 142], [142, 143]]}
{"doc_key": "ai-test-161", "ner": [[3, 9, "conference"], [13, 21, "conference"], [27, 37, "conference"], [43, 43, "conference"], [47, 50, "conference"], [52, 53, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 21, 3, 9, "named", "", false, false], [27, 37, 3, 9, "named", "", false, false], [43, 43, 27, 37, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Important", "journals", "include", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "later", "renamed", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "and", "since", "September", "2014", "renamed", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "after", "the", "merger", "with", "ACM", "Publications", ")", ",", "Computer", "Speech", "and", "Language", "and", "Speech", "Communication", "."], "sentence-detokenized": "Important journals include IEEE Transactions on Speech and Audio Processing (later renamed IEEE Transactions on Audio, Speech and Language Processing and since September 2014 renamed IEEE/ACM Transactions on Audio, Speech and Language Processing - after the merger with ACM Publications), Computer Speech and Language and Speech Communication.", "token2charspan": [[0, 9], [10, 18], [19, 26], [27, 31], [32, 44], [45, 47], [48, 54], [55, 58], [59, 64], [65, 75], [76, 77], [77, 82], [83, 90], [91, 95], [96, 108], [109, 111], [112, 117], [117, 118], [119, 125], [126, 129], [130, 138], [139, 149], [150, 153], [154, 159], [160, 169], [170, 174], [175, 182], [183, 187], [187, 188], [188, 191], [192, 204], [205, 207], [208, 213], [213, 214], [215, 221], [222, 225], [226, 234], [235, 245], [246, 247], [248, 253], [254, 257], [258, 264], [265, 269], [270, 273], [274, 286], [286, 287], [287, 288], [289, 297], [298, 304], [305, 308], [309, 317], [318, 321], [322, 328], [329, 342], [342, 343]]}
{"doc_key": "ai-test-162", "ner": [[0, 2, "algorithm"], [4, 6, "task"], [7, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 0, 2, "usage", "", false, false], [4, 6, 7, 9, "part-of", "task_part_of_field", false, false], [4, 6, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "is", "often", "used", "for", "data", "clustering", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "EM is often used for data clustering in machine learning and computer vision.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 20], [21, 25], [26, 36], [37, 39], [40, 47], [48, 56], [57, 60], [61, 69], [70, 76], [76, 77]]}
{"doc_key": "ai-test-163", "ner": [[9, 18, "metrics"], [24, 26, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 18, 24, 26, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["Although", "there", "is", "no", "perfect", "way", "to", "describe", "the", "matrix", "of", "TRUE", "and", "FALSE", "positive", "and", "negative", "results", "in", "a", "single", "number", ",", "the", "Matthews", "correlation", "coefficient", "is", "generally", "considered", "to", "be", "one", "of", "the", "best", "such", "indicators", "."], "sentence-detokenized": "Although there is no perfect way to describe the matrix of TRUE and FALSE positive and negative results in a single number, the Matthews correlation coefficient is generally considered to be one of the best such indicators.", "token2charspan": [[0, 8], [9, 14], [15, 17], [18, 20], [21, 28], [29, 32], [33, 35], [36, 44], [45, 48], [49, 55], [56, 58], [59, 63], [64, 67], [68, 73], [74, 82], [83, 86], [87, 95], [96, 103], [104, 106], [107, 108], [109, 115], [116, 122], [122, 123], [124, 127], [128, 136], [137, 148], [149, 160], [161, 163], [164, 173], [174, 184], [185, 187], [188, 190], [191, 194], [195, 197], [198, 201], [202, 206], [207, 211], [212, 222], [222, 223]]}
{"doc_key": "ai-test-164", "ner": [[13, 14, "field"], [28, 32, "field"], [34, 35, "field"], [39, 40, "algorithm"], [42, 43, "task"], [45, 46, "algorithm"], [51, 53, "algorithm"], [55, 56, "algorithm"], [62, 64, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[34, 35, 28, 32, "part-of", "subfield", false, false], [39, 40, 34, 35, "part-of", "", false, true], [42, 43, 34, 35, "part-of", "", false, true], [45, 46, 34, 35, "part-of", "", false, true], [51, 53, 34, 35, "part-of", "", false, true], [55, 56, 34, 35, "part-of", "", false, true], [62, 64, 34, 35, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "the", "size", "and", "complexity", "of", "datasets", "grew", ",", "direct", "hands", "-", "on", "data", "analysis", "was", "complemented", "by", "indirect", ",", "automated", "data", "processing", ",", "driven", "by", "other", "breakthroughs", "in", "computer", "science", ",", "especially", "in", "machine", "learning", ",", "such", "as", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "decision", "tree", "learning", "and", "decision", "rules", "(", "1960", "s", ")", "and", "support", "vector", "machines", "(", "1990", "s", ")", "."], "sentence-detokenized": "As the size and complexity of datasets grew, direct hands-on data analysis was complemented by indirect, automated data processing, driven by other breakthroughs in computer science, especially in machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision tree learning and decision rules (1960s) and support vector machines (1990s).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 15], [16, 26], [27, 29], [30, 38], [39, 43], [43, 44], [45, 51], [52, 57], [57, 58], [58, 60], [61, 65], [66, 74], [75, 78], [79, 91], [92, 94], [95, 103], [103, 104], [105, 114], [115, 119], [120, 130], [130, 131], [132, 138], [139, 141], [142, 147], [148, 161], [162, 164], [165, 173], [174, 181], [181, 182], [183, 193], [194, 196], [197, 204], [205, 213], [213, 214], [215, 219], [220, 222], [223, 229], [230, 238], [238, 239], [240, 247], [248, 256], [256, 257], [258, 265], [266, 276], [277, 278], [278, 283], [283, 284], [284, 285], [286, 294], [295, 299], [300, 308], [309, 312], [313, 321], [322, 327], [328, 329], [329, 333], [333, 334], [334, 335], [336, 339], [340, 347], [348, 354], [355, 363], [364, 365], [365, 369], [369, 370], [370, 371], [371, 372]]}
{"doc_key": "ai-test-165", "ner": [[4, 4, "researcher"], [23, 24, "misc"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 24, 4, 4, "artifact", "", false, false], [23, 24, 13, 14, "artifact", "", false, false], [23, 24, 16, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "autumn", "2005", ",", "Trun", ",", "together", "with", "his", "long", "-", "time", "colleagues", "Dieter", "Fox", "and", "Wolfram", "Burgard", ",", "published", "a", "textbook", "entitled", "Probabilistic", "Robotics", "."], "sentence-detokenized": "In autumn 2005, Trun, together with his long-time colleagues Dieter Fox and Wolfram Burgard, published a textbook entitled Probabilistic Robotics.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 20], [20, 21], [22, 30], [31, 35], [36, 39], [40, 44], [44, 45], [45, 49], [50, 60], [61, 67], [68, 71], [72, 75], [76, 83], [84, 91], [91, 92], [93, 102], [103, 104], [105, 113], [114, 122], [123, 136], [137, 145], [145, 146]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereiramath", "as", "follows", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereiramath as follows:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 49], [50, 52], [53, 60], [60, 61]]}
{"doc_key": "ai-test-167", "ner": [[0, 1, "task"], [3, 3, "task"], [7, 8, "field"], [14, 15, "field"], [17, 19, "field"], [21, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 17, 19, "part-of", "task_part_of_field", false, false], [3, 3, 0, 1, "named", "", false, false], [14, 15, 7, 8, "part-of", "subfield", false, false], [17, 19, 7, 8, "part-of", "subfield", false, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Question", "Answering", "(", "QA", ")", "is", "a", "computer", "science", "discipline", "in", "the", "field", "of", "information", "retrieval", "and", "natural", "language", "processing", "(", "NLP", ")", "that", "deals", "with", "the", "design", "of", "systems", "that", "automatically", "answer", "questions", "posed", "by", "humans", "in", "natural", "language", "."], "sentence-detokenized": "Question Answering (QA) is a computer science discipline in the field of information retrieval and natural language processing (NLP) that deals with the design of systems that automatically answer questions posed by humans in natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 37], [38, 45], [46, 56], [57, 59], [60, 63], [64, 69], [70, 72], [73, 84], [85, 94], [95, 98], [99, 106], [107, 115], [116, 126], [127, 128], [128, 131], [131, 132], [133, 137], [138, 143], [144, 148], [149, 152], [153, 159], [160, 162], [163, 170], [171, 175], [176, 189], [190, 196], [197, 206], [207, 212], [213, 215], [216, 222], [223, 225], [226, 233], [234, 242], [242, 243]]}
{"doc_key": "ai-test-168", "ner": [[12, 12, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "until", "2009", ",", "the", "version", "of", "the", "metric", "used", "in", "NIST", "assessments", "used", "the", "shorter", "reference", "sentence", "instead", "."], "sentence-detokenized": "However, until 2009, the version of the metric used in NIST assessments used the shorter reference sentence instead.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 19], [19, 20], [21, 24], [25, 32], [33, 35], [36, 39], [40, 46], [47, 51], [52, 54], [55, 59], [60, 71], [72, 76], [77, 80], [81, 88], [89, 98], [99, 107], [108, 115], [115, 116]]}
{"doc_key": "ai-test-169", "ner": [[5, 5, "person"], [13, 13, "organisation"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 14, 14, "related-to", "invests_in", false, false], [14, 14, 13, 13, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["On", "27", "August", "2018", ",", "Toyota", "announced", "a", "USD", "500", "million", "investment", "in", "Uber", "autonomous", "cars", "."], "sentence-detokenized": "On 27 August 2018, Toyota announced a USD 500 million investment in Uber autonomous cars.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 17], [17, 18], [19, 25], [26, 35], [36, 37], [38, 41], [42, 45], [46, 53], [54, 64], [65, 67], [68, 72], [73, 83], [84, 88], [88, 89]]}
{"doc_key": "ai-test-170", "ner": [[5, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sample", "maximum", "is", "an", "estimate", "of", "the", "maximum", "likelihood", "of", "the", "population", "maximum", ",", "but", "as", "mentioned", "above", ",", "it", "is", "biased", "."], "sentence-detokenized": "The sample maximum is an estimate of the maximum likelihood of the population maximum, but as mentioned above, it is biased.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 24], [25, 33], [34, 36], [37, 40], [41, 48], [49, 59], [60, 62], [63, 66], [67, 77], [78, 85], [85, 86], [87, 90], [91, 93], [94, 103], [104, 109], [109, 110], [111, 113], [114, 116], [117, 123], [123, 124]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [4, 5, "misc"], [7, 10, "metrics"], [17, 19, "algorithm"], [21, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 4, 5, "related-to", "overcomes", false, false], [0, 0, 7, 10, "related-to", "increases", false, false], [4, 5, 17, 19, "opposite", "", false, false], [4, 5, 21, 23, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "helps", "to", "overcome", "synonymy", "by", "increasing", "recall", ",", "which", "is", "one", "of", "the", "most", "problematic", "constraints", "in", "keyword", "queries", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI helps to overcome synonymy by increasing recall, which is one of the most problematic constraints in keyword queries and vector space models.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 21], [22, 30], [31, 33], [34, 44], [45, 51], [51, 52], [53, 58], [59, 61], [62, 65], [66, 68], [69, 72], [73, 77], [78, 89], [90, 101], [102, 104], [105, 112], [113, 120], [121, 124], [125, 131], [132, 137], [138, 144], [144, 145]]}
{"doc_key": "ai-test-172", "ner": [[0, 1, "task"], [19, 19, "programlang"], [21, 21, "programlang"], [23, 23, "programlang"], [25, 26, "programlang"], [28, 28, "programlang"], [30, 30, "programlang"], [32, 32, "programlang"], [34, 34, "programlang"], [36, 36, "programlang"], [38, 38, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 19, 19, "general-affiliation", "", false, false], [0, 1, 21, 21, "general-affiliation", "", false, false], [0, 1, 23, 23, "general-affiliation", "", false, false], [0, 1, 25, 26, "general-affiliation", "", false, false], [0, 1, 28, 28, "general-affiliation", "", false, false], [0, 1, 30, 30, "general-affiliation", "", false, false], [0, 1, 32, 32, "general-affiliation", "", false, false], [0, 1, 34, 34, "general-affiliation", "", false, false], [0, 1, 36, 36, "general-affiliation", "", false, false], [0, 1, 38, 38, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Data", "mining", "applications", "are", "typically", "driven", "by", "software", "programmes", "developed", "using", "various", "general", "-", "purpose", "programming", "languages", "such", "as", "Assembly", ",", "BASIC", ",", "C", ",", "C", "++", ",", "C#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "Data mining applications are typically driven by software programmes developed using various general-purpose programming languages such as Assembly, BASIC, C, C++, C#, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 4], [5, 11], [12, 24], [25, 28], [29, 38], [39, 45], [46, 48], [49, 57], [58, 68], [69, 78], [79, 84], [85, 92], [93, 100], [100, 101], [101, 108], [109, 120], [121, 130], [131, 135], [136, 138], [139, 147], [147, 148], [149, 154], [154, 155], [156, 157], [157, 158], [159, 160], [160, 162], [162, 163], [164, 166], [166, 167], [168, 175], [175, 176], [177, 181], [181, 182], [183, 190], [190, 191], [192, 196], [196, 197], [198, 204], [204, 205], [206, 210]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [6, 6, "product"], [8, 10, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 3, 3, "artifact", "", false, false], [6, 6, 8, 10, "physical", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2003", ",", "Honda", "launched", "its", "Cog", "commercial", "in", "the", "UK", "and", "on", "the", "internet", "."], "sentence-detokenized": "In 2003, Honda launched its Cog commercial in the UK and on the internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 27], [28, 31], [32, 42], [43, 45], [46, 49], [50, 52], [53, 56], [57, 59], [60, 63], [64, 72], [72, 73]]}
{"doc_key": "ai-test-174", "ner": [[0, 4, "conference"], [6, 8, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 6, 8, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Association", "for", "Computational", "Linguistics", "defines", "computational", "linguistics", "as", ":"], "sentence-detokenized": "The Association for Computational Linguistics defines computational linguistics as:", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 45], [46, 53], [54, 67], [68, 79], [80, 82], [82, 83]]}
{"doc_key": "ai-test-175", "ner": [[0, 2, "algorithm"], [10, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 10, 14, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Expectation", "maximisation", "algorithms", "can", "be", "used", "to", "calculate", "minimum", "bias", "maximum", "likelihood", "estimates", "of", "the", "unknown", "state", "space", "parameters", "in", "filters", "and", "equalisers", "."], "sentence-detokenized": "Expectation maximisation algorithms can be used to calculate minimum bias maximum likelihood estimates of the unknown state space parameters in filters and equalisers.", "token2charspan": [[0, 11], [12, 24], [25, 35], [36, 39], [40, 42], [43, 47], [48, 50], [51, 60], [61, 68], [69, 73], [74, 81], [82, 92], [93, 102], [103, 105], [106, 109], [110, 117], [118, 123], [124, 129], [130, 140], [141, 143], [144, 151], [152, 155], [156, 166], [166, 167]]}
{"doc_key": "ai-test-176", "ner": [[3, 3, "misc"], [5, 7, "person"], [9, 10, "person"], [12, 13, "person"], [16, 17, "misc"], [18, 19, "person"], [22, 23, "person"], [27, 27, "person"], [29, 30, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 7, 3, 3, "role", "actor_in", false, false], [9, 10, 3, 3, "role", "actor_in", false, false], [12, 13, 3, 3, "role", "actor_in", false, false], [18, 19, 16, 17, "role", "model_for", false, false], [27, 27, 29, 30, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Correspondents", "included", "former", "Baywatch", "actresses", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "and", "Traci", "Bingham", ",", "former", "Playboy", "Playmate", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", "and", "identical", "twins", "Randy", "and", "Jason", "Sklar", "."], "sentence-detokenized": "Correspondents included former Baywatch actresses Donna D'Errico, Carmen Electra and Traci Bingham, former Playboy Playmate Heidi Mark, comedian Arj Barker and identical twins Randy and Jason Sklar.", "token2charspan": [[0, 14], [15, 23], [24, 30], [31, 39], [40, 49], [50, 55], [56, 58], [58, 64], [64, 65], [66, 72], [73, 80], [81, 84], [85, 90], [91, 98], [98, 99], [100, 106], [107, 114], [115, 123], [124, 129], [130, 134], [134, 135], [136, 144], [145, 148], [149, 155], [156, 159], [160, 169], [170, 175], [176, 181], [182, 185], [186, 191], [192, 197], [197, 198]]}
{"doc_key": "ai-test-177", "ner": [[8, 9, "task"], [11, 11, "task"], [17, 19, "product"], [23, 24, "task"], [26, 29, "task"], [32, 33, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [17, 19, 8, 9, "general-affiliation", "", false, false], [26, 29, 23, 24, "named", "", false, false], [32, 33, 23, 24, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "is", "commonly", "used", "to", "generate", "representations", "for", "speech", "recognition", "(", "ASR", ")", ",", "e.g.", "in", "the", "CMU", "Sphinx", "system", ",", "and", "for", "speech", "synthesis", "(", "TTS", ")", ",", "e.g.", "in", "the", "Festival", "system", "."], "sentence-detokenized": "It is commonly used to generate representations for speech recognition (ASR), e.g. in the CMU Sphinx system, and for speech synthesis (TTS), e.g. in the Festival system.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 19], [20, 22], [23, 31], [32, 47], [48, 51], [52, 58], [59, 70], [71, 72], [72, 75], [75, 76], [76, 77], [78, 82], [83, 85], [86, 89], [90, 93], [94, 100], [101, 107], [107, 108], [109, 112], [113, 116], [117, 123], [124, 133], [134, 135], [135, 138], [138, 139], [139, 140], [141, 145], [146, 148], [149, 152], [153, 161], [162, 168], [168, 169]]}
{"doc_key": "ai-test-178", "ner": [[0, 1, "metrics"], [5, 15, "metrics"], [3, 3, "metrics"], [14, 15, "metrics"], [26, 27, "metrics"], [29, 29, "metrics"], [40, 41, "metrics"], [43, 43, "metrics"], [45, 47, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 15, 0, 1, "named", "", false, false], [3, 3, 5, 15, "named", "", false, false], [14, 15, 0, 1, "named", "", false, false], [29, 29, 26, 27, "named", "", false, false], [43, 43, 40, 41, "named", "", false, false], [45, 47, 40, 41, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "sensitivity", "or", "TPR", "(", "TRUE", "Positive", "Rate", ")", ",", "also", "known", "as", "the", "recall", "rate", ",", "is", "the", "proportion", "of", "people", "who", "test", "positive", "(", "TRUE", "Positive", ",", "TP", ")", "out", "of", "all", "people", "who", "actually", "test", "positive", "(", "Condition", "Positive", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "The sensitivity or TPR (TRUE Positive Rate), also known as the recall rate, is the proportion of people who test positive (TRUE Positive, TP) out of all people who actually test positive (Condition Positive, CP = TP + FN).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 22], [23, 24], [24, 28], [29, 37], [38, 42], [42, 43], [43, 44], [45, 49], [50, 55], [56, 58], [59, 62], [63, 69], [70, 74], [74, 75], [76, 78], [79, 82], [83, 93], [94, 96], [97, 103], [104, 107], [108, 112], [113, 121], [122, 123], [123, 127], [128, 136], [136, 137], [138, 140], [140, 141], [142, 145], [146, 148], [149, 152], [153, 159], [160, 163], [164, 172], [173, 177], [178, 186], [187, 188], [188, 197], [198, 206], [206, 207], [208, 210], [211, 212], [213, 215], [216, 217], [218, 220], [220, 221], [221, 222]]}
{"doc_key": "ai-test-179", "ner": [[1, 2, "task"], [11, 11, "conference"], [13, 14, "conference"], [16, 16, "conference"], [18, 20, "conference"], [22, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6], "relations": [[11, 11, 1, 2, "topic", "", false, false], [13, 14, 1, 2, "topic", "", false, false], [16, 16, 1, 2, "topic", "", false, false], [18, 20, 1, 2, "topic", "", false, false], [22, 23, 1, 2, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5], "sentence": ["Popular", "speech", "recognition", "conferences", "held", "annually", "or", "every", "other", "year", "include", "SpeechTEK", "and", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "and", "IEEE", "ASRU", "."], "sentence-detokenized": "Popular speech recognition conferences held annually or every other year include SpeechTEK and SpeechTEK Europe, ICASSP, Interspeech/Eurospeech and IEEE ASRU.", "token2charspan": [[0, 7], [8, 14], [15, 26], [27, 38], [39, 43], [44, 52], [53, 55], [56, 61], [62, 67], [68, 72], [73, 80], [81, 90], [91, 94], [95, 104], [105, 111], [111, 112], [113, 119], [119, 120], [121, 132], [132, 133], [133, 143], [144, 147], [148, 152], [153, 157], [157, 158]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [3, 5, "researcher"], [16, 20, "product"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 0, 0, "artifact", "", false, false], [21, 21, 3, 5, "artifact", "", false, false], [21, 21, 16, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "collaborated", "with", "Engelberger", ",", "who", "was", "the", "company", "'s", "president", ",", "to", "develop", "and", "produce", "an", "industrial", "robot", "under", "the", "Unimate", "brand", "."], "sentence-detokenized": "Devol collaborated with Engelberger, who was the company's president, to develop and produce an industrial robot under the Unimate brand.", "token2charspan": [[0, 5], [6, 18], [19, 23], [24, 35], [35, 36], [37, 40], [41, 44], [45, 48], [49, 56], [56, 58], [59, 68], [68, 69], [70, 72], [73, 80], [81, 84], [85, 92], [93, 95], [96, 106], [107, 112], [113, 118], [119, 122], [123, 130], [131, 136], [136, 137]]}
{"doc_key": "ai-test-181", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [9, 14, "algorithm"], [23, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 9, 14, "general-affiliation", "", false, false], [5, 5, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "Hidden", "Markov", "Model", "(", "HMM", ")", "is", "a", "statistical", "Markov", "model", "in", "which", "the", "system", "to", "be", "modelled", "is", "treated", "as", "a", "Markov", "process", "with", "unobservable", "(", "hidden", ")", "states", "."], "sentence-detokenized": "A Hidden Markov Model (HMM) is a statistical Markov model in which the system to be modelled is treated as a Markov process with unobservable (hidden) states.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [22, 23], [23, 26], [26, 27], [28, 30], [31, 32], [33, 44], [45, 51], [52, 57], [58, 60], [61, 66], [67, 70], [71, 77], [78, 80], [81, 83], [84, 92], [93, 95], [96, 103], [104, 106], [107, 108], [109, 115], [116, 123], [124, 128], [129, 141], [142, 143], [143, 149], [149, 150], [151, 157], [157, 158]]}
{"doc_key": "ai-test-182", "ner": [[19, 21, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "feature", ",", "which", "is", "not", "desirable", "in", "many", "applications", ",", "has", "encouraged", "researchers", "to", "use", "alternatives", "such", "as", "mean", "absolute", "error", "or", "median", "-", "based", "alternatives", "."], "sentence-detokenized": "This feature, which is not desirable in many applications, has encouraged researchers to use alternatives such as mean absolute error or median-based alternatives.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 19], [20, 22], [23, 26], [27, 36], [37, 39], [40, 44], [45, 57], [57, 58], [59, 62], [63, 73], [74, 85], [86, 88], [89, 92], [93, 105], [106, 110], [111, 113], [114, 118], [119, 127], [128, 133], [134, 136], [137, 143], [143, 144], [144, 149], [150, 162], [162, 163]]}
{"doc_key": "ai-test-183", "ner": [[19, 21, "algorithm"], [28, 29, "field"], [32, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 21, 28, 29, "part-of", "", false, false], [19, 21, 32, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "sequence", "(", "which", "depends", "on", "the", "results", "of", "previous", "attribute", "exploration", "at", "each", "stage", ")", "is", "called", "a", "decision", "tree", "and", "is", "used", "in", "the", "field", "of", "machine", "learning", "known", "as", "decision", "tree", "learning", "."], "sentence-detokenized": "This sequence (which depends on the results of previous attribute exploration at each stage) is called a decision tree and is used in the field of machine learning known as decision tree learning.", "token2charspan": [[0, 4], [5, 13], [14, 15], [15, 20], [21, 28], [29, 31], [32, 35], [36, 43], [44, 46], [47, 55], [56, 65], [66, 77], [78, 80], [81, 85], [86, 91], [91, 92], [93, 95], [96, 102], [103, 104], [105, 113], [114, 118], [119, 122], [123, 125], [126, 130], [131, 133], [134, 137], [138, 143], [144, 146], [147, 154], [155, 163], [164, 169], [170, 172], [173, 181], [182, 186], [187, 195], [195, 196]]}
{"doc_key": "ai-test-184", "ner": [[2, 3, "task"], [5, 5, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 5, 5, "compare", "", false, false], [15, 16, 5, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "in", "factor", "analysis", ",", "LCA", "can", "be", "used", "to", "classify", "cases", "according", "to", "their", "maximum", "likelihood", "class", "membership", "."], "sentence-detokenized": "As in factor analysis, LCA can be used to classify cases according to their maximum likelihood class membership.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 21], [21, 22], [23, 26], [27, 30], [31, 33], [34, 38], [39, 41], [42, 50], [51, 56], [57, 66], [67, 69], [70, 75], [76, 83], [84, 94], [95, 100], [101, 111], [111, 112]]}
{"doc_key": "ai-test-185", "ner": [[0, 3, "algorithm"], [5, 7, "metrics"], [9, 9, "metrics"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 5, 7, "usage", "", false, false], [5, 7, 11, 12, "related-to", "", false, false], [9, 9, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Supervised", "neural", "networks", "using", "the", "mean", "square", "error", "(", "MSE", ")", "cost", "function", "can", "use", "formal", "statistical", "methods", "to", "determine", "the", "reliability", "of", "the", "trained", "model", "."], "sentence-detokenized": "Supervised neural networks using the mean square error (MSE) cost function can use formal statistical methods to determine the reliability of the trained model.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 32], [33, 36], [37, 41], [42, 48], [49, 54], [55, 56], [56, 59], [59, 60], [61, 65], [66, 74], [75, 78], [79, 82], [83, 89], [90, 101], [102, 109], [110, 112], [113, 122], [123, 126], [127, 138], [139, 141], [142, 145], [146, 153], [154, 159], [159, 160]]}
{"doc_key": "ai-test-186", "ner": [[17, 20, "algorithm"], [21, 23, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 20, 21, 23, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "expressed", "directly", "as", "a", "linear", "program", ",", "but", "it", "is", "also", "equivalent", "to", "a", "Tikhonov", "regularisation", "with", "a", "hinge", "loss", "function", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", ".", "/", "math", ":"], "sentence-detokenized": "This can be expressed directly as a linear program, but it is also equivalent to a Tikhonov regularisation with a hinge loss function, mathV (f (x), y) = max (0, 1 - yf (x)). / math:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 21], [22, 30], [31, 33], [34, 35], [36, 42], [43, 50], [50, 51], [52, 55], [56, 58], [59, 61], [62, 66], [67, 77], [78, 80], [81, 82], [83, 91], [92, 106], [107, 111], [112, 113], [114, 119], [120, 124], [125, 133], [133, 134], [135, 140], [141, 142], [142, 143], [144, 145], [145, 146], [146, 147], [147, 148], [149, 150], [150, 151], [152, 153], [154, 157], [158, 159], [159, 160], [160, 161], [162, 163], [164, 165], [166, 168], [169, 170], [170, 171], [171, 172], [172, 173], [173, 174], [175, 176], [177, 181], [181, 182]]}
{"doc_key": "ai-test-187", "ner": [[5, 6, "researcher"], [13, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "method", "is", "described", "in", "Breiman", "'s", "original", "paper", "and", "is", "implemented", "in", "the", "R", "package", "randomForest", "."], "sentence-detokenized": "This method is described in Breiman's original paper and is implemented in the R package randomForest.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 24], [25, 27], [28, 35], [35, 37], [38, 46], [47, 52], [53, 56], [57, 59], [60, 71], [72, 74], [75, 78], [79, 80], [81, 88], [89, 101], [101, 102]]}
{"doc_key": "ai-test-188", "ner": [[7, 12, "metrics"], [36, 37, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "image", "quality", "measurements", ",", "such", "as", "PSNR", ",", "are", "usually", "performed", "on", "fixed", "resolution", "images", "and", "do", "not", "take", "into", "account", "some", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "spatial", "resolution", "changes", "in", "the", "retina", "."], "sentence-detokenized": "Traditional image quality measurements, such as PSNR, are usually performed on fixed resolution images and do not take into account some aspects of the human visual system, such as spatial resolution changes in the retina.", "token2charspan": [[0, 11], [12, 17], [18, 25], [26, 38], [38, 39], [40, 44], [45, 47], [48, 52], [52, 53], [54, 57], [58, 65], [66, 75], [76, 78], [79, 84], [85, 95], [96, 102], [103, 106], [107, 109], [110, 113], [114, 118], [119, 123], [124, 131], [132, 136], [137, 144], [145, 147], [148, 151], [152, 157], [158, 164], [165, 171], [171, 172], [173, 177], [178, 180], [181, 188], [189, 199], [200, 207], [208, 210], [211, 214], [215, 221], [221, 222]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [10, 12, "person"], [15, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 15, 20, "role", "", false, false], [3, 4, 15, 20, "role", "", false, false], [6, 7, 15, 20, "role", "", false, false], [15, 20, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Drew", "and", "Macdonald", "Carey", "starred", "in", "Jack", "Broder", "'s", "colour", "play", "Hannah", "Lee", ",", "which", "opened", "on", "19", "June", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Drew and Macdonald Carey starred in Jack Broder's colour play Hannah Lee, which opened on 19 June 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 25], [26, 29], [30, 39], [40, 45], [46, 53], [54, 56], [57, 61], [62, 68], [68, 70], [71, 77], [78, 82], [83, 89], [90, 93], [93, 94], [95, 100], [101, 107], [108, 110], [111, 113], [114, 118], [119, 123], [123, 124]]}
{"doc_key": "ai-test-190", "ner": [[4, 6, "task"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 9, 10, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "process", "is", "called", "image", "registration", "and", "uses", "various", "computer", "vision", "techniques", ",", "mainly", "related", "to", "tracking", "."], "sentence-detokenized": "This process is called image registration and uses various computer vision techniques, mainly related to tracking.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 22], [23, 28], [29, 41], [42, 45], [46, 50], [51, 58], [59, 67], [68, 74], [75, 85], [85, 86], [87, 93], [94, 101], [102, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-191", "ner": [[17, 19, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Now", "let", "'s", "start", "explaining", "the", "different", "possible", "relationships", "between", "the", "predicted", "and", "the", "actual", "outcome", ":", "the", "Uncertainty", "Matrix"], "sentence-detokenized": "Now let's start explaining the different possible relationships between the predicted and the actual outcome: the Uncertainty Matrix", "token2charspan": [[0, 3], [4, 7], [7, 9], [10, 15], [16, 26], [27, 30], [31, 40], [41, 49], [50, 63], [64, 71], [72, 75], [76, 85], [86, 89], [90, 93], [94, 100], [101, 108], [108, 109], [110, 113], [114, 125], [126, 132]]}
{"doc_key": "ai-test-192", "ner": [[0, 1, "product"], [2, 4, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 2, 4, "part-of", "", false, false], [0, 1, 2, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "VOICEBOX", "speech", "processing", "toolbox", "for", "MATLAB", "implements", "the", "conversion", "and", "its", "inverse", "as", ":"], "sentence-detokenized": "The VOICEBOX speech processing toolbox for MATLAB implements the conversion and its inverse as:", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 30], [31, 38], [39, 42], [43, 49], [50, 60], [61, 64], [65, 75], [76, 79], [80, 83], [84, 91], [92, 94], [94, 95]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "general-affiliation", "", false, false], [0, 0, 11, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logic", "programming", "language", "related", "to", "artificial", "intelligence", "and", "computational", "linguistics", "."], "sentence-detokenized": "Prolog is a logic programming language related to artificial intelligence and computational linguistics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 17], [18, 29], [30, 38], [39, 46], [47, 49], [50, 60], [61, 73], [74, 77], [78, 91], [92, 103], [103, 104]]}
{"doc_key": "ai-test-194", "ner": [[0, 1, "researcher"], [9, 9, "field"], [11, 11, "field"], [17, 20, "organisation"], [23, 26, "organisation"], [29, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 9, 9, "related-to", "works_with_topic", false, false], [0, 1, 11, 11, "related-to", "works_with_topic", false, false], [0, 1, 17, 20, "role", "", false, false], [0, 1, 23, 26, "role", "", false, false], [0, 1, 29, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "numerous", "awards", "for", "her", "contributions", "to", "neuroscience", "and", "psychology", ",", "including", "Fellowship", "of", "the", "Royal", "Society", "of", "London", ",", "the", "Royal", "Society", "of", "Canada", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received numerous awards for her contributions to neuroscience and psychology, including Fellowship of the Royal Society of London, the Royal Society of Canada and the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 35], [36, 39], [40, 43], [44, 57], [58, 60], [61, 73], [74, 77], [78, 88], [88, 89], [90, 99], [100, 110], [111, 113], [114, 117], [118, 123], [124, 131], [132, 134], [135, 141], [141, 142], [143, 146], [147, 152], [153, 160], [161, 163], [164, 170], [171, 174], [175, 178], [179, 187], [188, 195], [196, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-195", "ner": [[8, 9, "field"], [14, 15, "task"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 15, 8, 9, "part-of", "task_part_of_field", false, false], [17, 18, 8, 9, "part-of", "task_part_of_field", false, false], [20, 21, 8, 9, "part-of", "task_part_of_field", false, false], [23, 24, 8, 9, "part-of", "task_part_of_field", false, false], [26, 26, 8, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Combining", "these", "operators", "can", "yield", "algorithms", "for", "many", "image", "processing", "tasks", ",", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "sharpening", ",", "image", "filtering", "and", "classification", "."], "sentence-detokenized": "Combining these operators can yield algorithms for many image processing tasks, such as feature extraction, image segmentation, image sharpening, image filtering and classification.", "token2charspan": [[0, 9], [10, 15], [16, 25], [26, 29], [30, 35], [36, 46], [47, 50], [51, 55], [56, 61], [62, 72], [73, 78], [78, 79], [80, 84], [85, 87], [88, 95], [96, 106], [106, 107], [108, 113], [114, 126], [126, 127], [128, 133], [134, 144], [144, 145], [146, 151], [152, 161], [162, 165], [166, 180], [180, 181]]}
{"doc_key": "ai-test-196", "ner": [[5, 7, "university"], [13, 15, "organisation"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 13, 15, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "Professor", "at", "the", "College", "de", "France", "since", "2017", "and", "Director", "of", "INSERM", "Unit", "562", "\"", "Cognitive", "Neuroimaging", "\"", "since", "1989", "."], "sentence-detokenized": "He is Professor at the College de France since 2017 and Director of INSERM Unit 562 \"Cognitive Neuroimaging\" since 1989.", "token2charspan": [[0, 2], [3, 5], [6, 15], [16, 18], [19, 22], [23, 30], [31, 33], [34, 40], [41, 46], [47, 51], [52, 55], [56, 64], [65, 67], [68, 74], [75, 79], [80, 83], [84, 85], [85, 94], [95, 107], [107, 108], [109, 114], [115, 119], [119, 120]]}
{"doc_key": "ai-test-197", "ner": [[12, 14, "algorithm"], [16, 21, "algorithm"], [24, 26, "algorithm"], [27, 32, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[24, 26, 27, 32, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "many", "approaches", "to", "learning", "these", "embeddings", ",", "in", "particular", "using", "Bayesian", "clustering", "frameworks", "or", "energy", "-", "based", "frameworks", ",", "and", "more", "recently", "TransE", "(", "2013", "Conference", "on", "Neural", "Information", "Processing", "Systems", ")", "."], "sentence-detokenized": "There are many approaches to learning these embeddings, in particular using Bayesian clustering frameworks or energy-based frameworks, and more recently TransE (2013 Conference on Neural Information Processing Systems).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 25], [26, 28], [29, 37], [38, 43], [44, 54], [54, 55], [56, 58], [59, 69], [70, 75], [76, 84], [85, 95], [96, 106], [107, 109], [110, 116], [116, 117], [117, 122], [123, 133], [133, 134], [135, 138], [139, 143], [144, 152], [153, 159], [160, 161], [161, 165], [166, 176], [177, 179], [180, 186], [187, 198], [199, 209], [210, 217], [217, 218], [218, 219]]}
{"doc_key": "ai-test-198", "ner": [[6, 8, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 13, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "is", "an", "alternative", "to", "the", "Word", "Error", "Rate", "used", "in", "several", "countries", "."], "sentence-detokenized": "It is an alternative to the Word Error Rate used in several countries.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 23], [24, 27], [28, 32], [33, 38], [39, 43], [44, 48], [49, 51], [52, 59], [60, 69], [69, 70]]}
{"doc_key": "ai-test-199", "ner": [[0, 0, "algorithm"], [10, 11, "task"], [13, 14, "task"], [16, 17, "task"], [19, 21, "task"], [23, 26, "task"], [28, 29, "task"], [44, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 0, 0, "usage", "", false, false], [13, 14, 0, 0, "usage", "", false, false], [16, 17, 0, 0, "usage", "", false, false], [19, 21, 0, 0, "usage", "", false, false], [23, 26, 0, 0, "usage", "", false, false], [28, 29, 0, 0, "usage", "", false, false], [44, 44, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "have", "been", "used", "in", "a", "variety", "of", "tasks", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "board", "and", "video", "gaming", ",", "medical", "diagnostics", "and", "even", "activities", "that", "were", "traditionally", "thought", "to", "be", "for", "humans", ",", "such", "as", "painting", "."], "sentence-detokenized": "ANNs have been used in a variety of tasks including computer vision, speech recognition, machine translation, social network filtering, board and video gaming, medical diagnostics and even activities that were traditionally thought to be for humans, such as painting.", "token2charspan": [[0, 4], [5, 9], [10, 14], [15, 19], [20, 22], [23, 24], [25, 32], [33, 35], [36, 41], [42, 51], [52, 60], [61, 67], [67, 68], [69, 75], [76, 87], [87, 88], [89, 96], [97, 108], [108, 109], [110, 116], [117, 124], [125, 134], [134, 135], [136, 141], [142, 145], [146, 151], [152, 158], [158, 159], [160, 167], [168, 179], [180, 183], [184, 188], [189, 199], [200, 204], [205, 209], [210, 223], [224, 231], [232, 234], [235, 237], [238, 241], [242, 248], [248, 249], [250, 254], [255, 257], [258, 266], [266, 267]]}
{"doc_key": "ai-test-200", "ner": [[0, 4, "product"], [6, 6, "product"], [26, 28, "field"], [30, 30, "field"], [35, 35, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 26, 28, "related-to", "", false, false], [0, 4, 35, 35, "general-affiliation", "", false, false], [6, 6, 0, 4, "named", "", false, false], [30, 30, 26, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "is", "an", "open", "source", "research", "platform", "and", "a", "collection", "of", "voice", ",", "sound", ",", "speech", ",", "text", "and", "natural", "language", "processing", "(", "NLP", ")", "algorithms", "written", "in", "Java", "and", "organised", "in", "a", "modular", "and", "extensible", "framework", "that", "seeks", "to", "facilitate", "the", "addition", "of", "new", "algorithms", "."], "sentence-detokenized": "The Modular Audio Recognition Framework (MARF) is an open source research platform and a collection of voice, sound, speech, text and natural language processing (NLP) algorithms written in Java and organised in a modular and extensible framework that seeks to facilitate the addition of new algorithms.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 29], [30, 39], [40, 41], [41, 45], [45, 46], [47, 49], [50, 52], [53, 57], [58, 64], [65, 73], [74, 82], [83, 86], [87, 88], [89, 99], [100, 102], [103, 108], [108, 109], [110, 115], [115, 116], [117, 123], [123, 124], [125, 129], [130, 133], [134, 141], [142, 150], [151, 161], [162, 163], [163, 166], [166, 167], [168, 178], [179, 186], [187, 189], [190, 194], [195, 198], [199, 208], [209, 211], [212, 213], [214, 221], [222, 225], [226, 236], [237, 246], [247, 251], [252, 257], [258, 260], [261, 271], [272, 275], [276, 284], [285, 287], [288, 291], [292, 302], [302, 303]]}
{"doc_key": "ai-test-201", "ner": [[11, 13, "organisation"], [17, 17, "country"], [21, 23, "organisation"], [26, 27, "organisation"], [31, 32, "task"], [43, 45, "organisation"], [51, 52, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[21, 23, 17, 17, "physical", "", false, false], [21, 23, 31, 32, "usage", "", false, false], [21, 23, 43, 45, "named", "", false, false], [26, 27, 17, 17, "physical", "", false, false], [26, 27, 31, 32, "usage", "", false, false], [43, 45, 51, 52, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "a", "report", "by", "civil", "liberties", "and", "rights", "organisation", "Big", "Brother", "Watch", "revealed", "that", "two", "UK", "police", "forces", "-", "South", "Wales", "Police", "and", "the", "Metropolitan", "Police", "-", "used", "live", "facial", "recognition", "at", "public", "events", "and", "in", "public", "places.In", "September", "2019", ",", "South", "Wales", "Police", "ruled", "that", "the", "use", "of", "facial", "recognition", "was", "legal", "."], "sentence-detokenized": "In 2018, a report by civil liberties and rights organisation Big Brother Watch revealed that two UK police forces - South Wales Police and the Metropolitan Police - used live facial recognition at public events and in public places.In September 2019, South Wales Police ruled that the use of facial recognition was legal.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 20], [21, 26], [27, 36], [37, 40], [41, 47], [48, 60], [61, 64], [65, 72], [73, 78], [79, 87], [88, 92], [93, 96], [97, 99], [100, 106], [107, 113], [114, 115], [116, 121], [122, 127], [128, 134], [135, 138], [139, 142], [143, 155], [156, 162], [163, 164], [165, 169], [170, 174], [175, 181], [182, 193], [194, 196], [197, 203], [204, 210], [211, 214], [215, 217], [218, 224], [225, 234], [235, 244], [245, 249], [249, 250], [251, 256], [257, 262], [263, 269], [270, 275], [276, 280], [281, 284], [285, 288], [289, 291], [292, 298], [299, 310], [311, 314], [315, 320], [320, 321]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [5, 7, "programlang"], [13, 15, "field"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 7, "general-affiliation", "", false, false], [0, 0, 13, 15, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "has", "been", "ported", "to", "R", ",", "a", "freely", "available", "language", "and", "environment", "for", "statistical", "computing", "and", "graphics", "."], "sentence-detokenized": "ANIMAL has been ported to R, a freely available language and environment for statistical computing and graphics.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [23, 25], [26, 27], [27, 28], [29, 30], [31, 37], [38, 47], [48, 56], [57, 60], [61, 72], [73, 76], [77, 88], [89, 98], [99, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-test-203", "ner": [[0, 5, "algorithm"], [7, 9, "algorithm"], [15, 18, "algorithm"], [20, 20, "algorithm"], [22, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 15, 18, "opposite", "alternative to", false, false], [7, 9, 0, 5, "named", "", false, false], [20, 20, 15, 18, "named", "", false, false], [22, 25, 0, 5, "usage", "", false, false], [22, 25, 15, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "temporally", "heterogeneous", "Hidden", "Bernoulli", "Model", "(", "TI", "-", "HBM", ")", "is", "an", "alternative", "to", "the", "Hidden", "Markov", "Model", "(", "HMM", ")", "for", "automatic", "speech", "recognition", "."], "sentence-detokenized": "The temporally heterogeneous Hidden Bernoulli Model (TI-HBM) is an alternative to the Hidden Markov Model (HMM) for automatic speech recognition.", "token2charspan": [[0, 3], [4, 14], [15, 28], [29, 35], [36, 45], [46, 51], [52, 53], [53, 55], [55, 56], [56, 59], [59, 60], [61, 63], [64, 66], [67, 78], [79, 81], [82, 85], [86, 92], [93, 99], [100, 105], [106, 107], [107, 110], [110, 111], [112, 115], [116, 125], [126, 132], [133, 144], [144, 145]]}
{"doc_key": "ai-test-204", "ner": [[0, 4, "organisation"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 12, 12, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "Nvidia", "demonstrated", "a", "new", "foveated", "rendering", "method", "at", "SIGGRAPH", ",", "which", "it", "claimed", "was", "invisible", "to", "users", "."], "sentence-detokenized": "In July 2016, Nvidia demonstrated a new foveated rendering method at SIGGRAPH, which it claimed was invisible to users.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 33], [34, 35], [36, 39], [40, 48], [49, 58], [59, 65], [66, 68], [69, 77], [77, 78], [79, 84], [85, 87], [88, 95], [96, 99], [100, 109], [110, 112], [113, 118], [118, 119]]}
{"doc_key": "ai-test-205", "ner": [[4, 7, "misc"], [10, 15, "researcher"], [18, 19, "researcher"], [21, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 7, 10, 15, "origin", "", false, false], [4, 7, 18, 19, "origin", "", false, false], [4, 7, 21, 24, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Both", "are", "based", "on", "the", "speech", "act", "theory", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "refined", "by", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both are based on the speech act theory developed by John Searle in the 1960s and refined by Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 17], [18, 21], [22, 28], [29, 32], [33, 39], [40, 49], [50, 52], [53, 57], [58, 64], [65, 67], [68, 71], [72, 77], [78, 81], [82, 89], [90, 92], [93, 98], [99, 107], [108, 111], [112, 118], [119, 121], [122, 125], [126, 131], [131, 132]]}
{"doc_key": "ai-test-206", "ner": [[0, 2, "algorithm"], [20, 22, "researcher"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 20, 22, "related-to", "", false, false], [23, 23, 20, 22, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "knowledge", "structure", "have", "revealed", "powerful", "hierarchical", "models", "of", "knowledge", "organisation", ",", "such", "as", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "Neural network models of concept formation and knowledge structure have revealed powerful hierarchical models of knowledge organisation, such as George Miller's Wordnet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 56], [57, 66], [67, 71], [72, 80], [81, 89], [90, 102], [103, 109], [110, 112], [113, 122], [123, 135], [135, 136], [137, 141], [142, 144], [145, 151], [152, 158], [158, 160], [161, 168], [168, 169]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [14, 15, "field"], [18, 20, "product"], [23, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 14, 15, "part-of", "", false, false], [0, 1, 23, 25, "part-of", "", false, false], [18, 20, 14, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Pattern", "matching", "has", "a", "variety", "of", "applications", "and", "is", "used", "in", "areas", "such", "as", "face", "recognition", "(", "see", "facial", "recognition", "system", ")", "and", "medical", "image", "processing", "."], "sentence-detokenized": "Pattern matching has a variety of applications and is used in areas such as face recognition (see facial recognition system) and medical image processing.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 22], [23, 30], [31, 33], [34, 46], [47, 50], [51, 53], [54, 58], [59, 61], [62, 67], [68, 72], [73, 75], [76, 80], [81, 92], [93, 94], [94, 97], [98, 104], [105, 116], [117, 123], [123, 124], [125, 128], [129, 136], [137, 142], [143, 153], [153, 154]]}
{"doc_key": "ai-test-208", "ner": [[16, 17, "researcher"], [19, 21, "researcher"], [22, 31, "organisation"], [33, 33, "organisation"], [40, 41, "algorithm"], [46, 50, "conference"], [52, 52, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[16, 17, 22, 31, "role", "", false, false], [16, 17, 46, 50, "physical", "", false, false], [16, 17, 46, 50, "temporal", "", false, false], [16, 17, 52, 52, "physical", "", false, false], [19, 21, 22, 31, "role", "", false, false], [19, 21, 46, 50, "temporal", "", false, false], [33, 33, 22, 31, "named", "", false, false], [46, 50, 40, 41, "topic", "", false, false], [52, 52, 46, 50, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "it", "was", "only", "in", "2005", "that", "the", "use", "became", "more", "widespread", ",", "when", "researchers", "Navneet", "Dalal", "and", "Bill", "Triggs", "of", "the", "French", "National", "Research", "Institute", "for", "Computer", "Vision", "and", "Automation", "(", "INRIA", ")", "presented", "their", "complementary", "work", "on", "HOG", "descriptors", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "However, it was only in 2005 that the use became more widespread, when researchers Navneet Dalal and Bill Triggs of the French National Research Institute for Computer Vision and Automation (INRIA) presented their complementary work on HOG descriptors at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 15], [16, 20], [21, 23], [24, 28], [29, 33], [34, 37], [38, 41], [42, 48], [49, 53], [54, 64], [64, 65], [66, 70], [71, 82], [83, 90], [91, 96], [97, 100], [101, 105], [106, 112], [113, 115], [116, 119], [120, 126], [127, 135], [136, 144], [145, 154], [155, 158], [159, 167], [168, 174], [175, 178], [179, 189], [190, 191], [191, 196], [196, 197], [198, 207], [208, 213], [214, 227], [228, 232], [233, 235], [236, 239], [240, 251], [252, 254], [255, 258], [259, 269], [270, 272], [273, 281], [282, 288], [289, 292], [293, 300], [301, 312], [313, 314], [314, 318], [318, 319], [319, 320]]}
{"doc_key": "ai-test-209", "ner": [[3, 3, "university"], [11, 12, "organisation"], [14, 15, "organisation"], [26, 27, "field"], [33, 36, "researcher"], [38, 41, "researcher"], [43, 45, "researcher"], [48, 51, "organisation"], [54, 58, "organisation"], [61, 62, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[14, 15, 26, 27, "related-to", "", false, false], [33, 36, 14, 15, "physical", "", false, false], [33, 36, 14, 15, "role", "", false, false], [38, 41, 14, 15, "physical", "", false, false], [38, 41, 14, 15, "role", "", false, false], [43, 45, 14, 15, "physical", "", false, false], [43, 45, 14, 15, "role", "", false, false], [61, 62, 54, 58, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Before", "joining", "the", "Penn", "faculty", "in", "2002", ",", "he", "worked", "at", "AT&T", "Labs", "and", "Bell", "Labs", "for", "ten", "years", "(", "1991-2001", ")", ",", "including", "leading", "the", "Artificial", "Intelligence", "Division", "with", "colleagues", "such", "as", "Michael", "L", ".", "Littman", ",", "David", "A", ".", "McAllester", "and", "Richard", "S.", "Sutton", ",", "the", "Secure", "Systems", "Research", "Division", "and", "the", "Machine", "Learning", "Division", "with", "members", "such", "as", "Michael", "Collins", "and", "supervisors", ".", ")"], "sentence-detokenized": "Before joining the Penn faculty in 2002, he worked at AT&T Labs and Bell Labs for ten years (1991-2001), including leading the Artificial Intelligence Division with colleagues such as Michael L. Littman, David A. McAllester and Richard S. Sutton, the Secure Systems Research Division and the Machine Learning Division with members such as Michael Collins and supervisors.)", "token2charspan": [[0, 6], [7, 14], [15, 18], [19, 23], [24, 31], [32, 34], [35, 39], [39, 40], [41, 43], [44, 50], [51, 53], [54, 58], [59, 63], [64, 67], [68, 72], [73, 77], [78, 81], [82, 85], [86, 91], [92, 93], [93, 102], [102, 103], [103, 104], [105, 114], [115, 122], [123, 126], [127, 137], [138, 150], [151, 159], [160, 164], [165, 175], [176, 180], [181, 183], [184, 191], [192, 193], [193, 194], [195, 202], [202, 203], [204, 209], [210, 211], [211, 212], [213, 223], [224, 227], [228, 235], [236, 238], [239, 245], [245, 246], [247, 250], [251, 257], [258, 265], [266, 274], [275, 283], [284, 287], [288, 291], [292, 299], [300, 308], [309, 317], [318, 322], [323, 330], [331, 335], [336, 338], [339, 346], [347, 354], [355, 358], [359, 370], [370, 371], [371, 372]]}
{"doc_key": "ai-test-210", "ner": [[6, 7, "field"], [14, 15, "field"], [25, 28, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 14, 15, "compare", "", false, false], [25, 28, 14, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "the", "data", "is", "unlabelled", ",", "supervised", "learning", "is", "not", "possible", ",", "and", "an", "unsupervised", "learning", "approach", "is", "needed", ",", "which", "tries", "to", "find", "natural", "clusters", "for", "cluster", "analysis", "and", "then", "maps", "new", "data", "to", "these", "established", "clusters", "."], "sentence-detokenized": "If the data is unlabelled, supervised learning is not possible, and an unsupervised learning approach is needed, which tries to find natural clusters for cluster analysis and then maps new data to these established clusters.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 25], [25, 26], [27, 37], [38, 46], [47, 49], [50, 53], [54, 62], [62, 63], [64, 67], [68, 70], [71, 83], [84, 92], [93, 101], [102, 104], [105, 111], [111, 112], [113, 118], [119, 124], [125, 127], [128, 132], [133, 140], [141, 149], [150, 153], [154, 161], [162, 170], [171, 174], [175, 179], [180, 184], [185, 188], [189, 193], [194, 196], [197, 202], [203, 214], [215, 223], [223, 224]]}
{"doc_key": "ai-test-211", "ner": [[3, 4, "field"], [14, 17, "organisation"], [24, 25, "field"], [27, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 14, 17, "origin", "", false, false], [3, 4, 24, 25, "part-of", "", false, false], [3, 4, 27, 27, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "area", "of", "computer", "science", "developed", "in", "the", "1950s", "at", "academic", "institutions", "such", "as", "MIT", "A.I", ".", "Lab", ",", "initially", "as", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "This area of computer science developed in the 1950s at academic institutions such as MIT A.I. Lab, initially as a branch of artificial intelligence and robotics.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 21], [22, 29], [30, 39], [40, 42], [43, 46], [47, 52], [53, 55], [56, 64], [65, 77], [78, 82], [83, 85], [86, 89], [90, 93], [93, 94], [95, 98], [98, 99], [100, 109], [110, 112], [113, 114], [115, 121], [122, 124], [125, 135], [136, 148], [149, 152], [153, 161], [161, 162]]}
{"doc_key": "ai-test-212", "ner": [[8, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "can", "also", "be", "replaced", "by", "the", "following", "Log", "loss", "equation", ":"], "sentence-detokenized": "This can also be replaced by the following Log loss equation:", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 25], [26, 28], [29, 32], [33, 42], [43, 46], [47, 51], [52, 60], [60, 61]]}
{"doc_key": "ai-test-213", "ner": [[0, 2, "organisation"], [5, 9, "organisation"], [13, 17, "university"], [19, 19, "university"], [21, 22, "university"], [25, 28, "university"], [29, 30, "country"], [36, 36, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 36, 36, "related-to", "research_leader_in_field", false, false], [5, 9, 0, 2, "named", "", false, false], [5, 9, 36, 36, "related-to", "research_leader_in_field", false, false], [13, 17, 36, 36, "related-to", "research_leader_in_field", false, false], [19, 19, 36, 36, "related-to", "research_leader_in_field", false, false], [21, 22, 36, 36, "related-to", "research_leader_in_field", false, false], [25, 28, 29, 30, "physical", "", false, false], [25, 28, 36, 36, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Shirley", "Ryan", "AbilityLab", "(", "formerly", "the", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "the", "University", "of", "California", "at", "Berkeley", ",", "MIT", ",", "Stanford", "University", "and", "the", "University", "of", "Twente", "in", "the", "Netherlands", "are", "at", "the", "forefront", "of", "biomechatronics", "research", "."], "sentence-detokenized": "Shirley Ryan AbilityLab (formerly the Rehabilitation Institute of Chicago), the University of California at Berkeley, MIT, Stanford University and the University of Twente in the Netherlands are at the forefront of biomechatronics research.", "token2charspan": [[0, 7], [8, 12], [13, 23], [24, 25], [25, 33], [34, 37], [38, 52], [53, 62], [63, 65], [66, 73], [73, 74], [74, 75], [76, 79], [80, 90], [91, 93], [94, 104], [105, 107], [108, 116], [116, 117], [118, 121], [121, 122], [123, 131], [132, 142], [143, 146], [147, 150], [151, 161], [162, 164], [165, 171], [172, 174], [175, 178], [179, 190], [191, 194], [195, 197], [198, 201], [202, 211], [212, 214], [215, 230], [231, 239], [239, 240]]}
{"doc_key": "ai-test-214", "ner": [[21, 33, "metrics"], [38, 39, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Given", "a", "set", "of", "predicted", "values", "and", "a", "corresponding", "set", "of", "actual", "values", "of", "X", "for", "different", "time", "periods", ",", "the", "mean", "squared", "prediction", "error", "is", "usually", "used", ";", "other", "measures", "are", "also", "available", "(", "see", "prediction", "#", "prediction", "accuracy", ")", "."], "sentence-detokenized": "Given a set of predicted values and a corresponding set of actual values of X for different time periods, the mean squared prediction error is usually used; other measures are also available (see prediction # prediction accuracy).", "token2charspan": [[0, 5], [6, 7], [8, 11], [12, 14], [15, 24], [25, 31], [32, 35], [36, 37], [38, 51], [52, 55], [56, 58], [59, 65], [66, 72], [73, 75], [76, 77], [78, 81], [82, 91], [92, 96], [97, 104], [104, 105], [106, 109], [110, 114], [115, 122], [123, 133], [134, 139], [140, 142], [143, 150], [151, 155], [155, 156], [157, 162], [163, 171], [172, 175], [176, 180], [181, 190], [191, 192], [192, 195], [196, 206], [207, 208], [209, 219], [220, 228], [228, 229], [229, 230]]}
{"doc_key": "ai-test-215", "ner": [[13, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "indicators", ",", "such", "as", "the", "proportion", "of", "correct", "predictions", "(", "also", "called", "accuracy", ")", ",", "are", "not", "useful", "if", "the", "two", "classes", "are", "very", "different", "in", "size", "."], "sentence-detokenized": "Other indicators, such as the proportion of correct predictions (also called accuracy), are not useful if the two classes are very different in size.", "token2charspan": [[0, 5], [6, 16], [16, 17], [18, 22], [23, 25], [26, 29], [30, 40], [41, 43], [44, 51], [52, 63], [64, 65], [65, 69], [70, 76], [77, 85], [85, 86], [86, 87], [88, 91], [92, 95], [96, 102], [103, 105], [106, 109], [110, 113], [114, 121], [122, 125], [126, 130], [131, 140], [141, 143], [144, 148], [148, 149]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [14, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 14, 20, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "released", "in", "2000", "at", "a", "conference", "on", "computer", "vision", "and", "image", "recognition", ",", "and", "five", "beta", "versions", "were", "released", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was released in 2000 at a conference on computer vision and image recognition, and five beta versions were released between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 46], [47, 49], [50, 54], [55, 57], [58, 59], [60, 70], [71, 73], [74, 82], [83, 89], [90, 93], [94, 99], [100, 111], [111, 112], [113, 116], [117, 121], [122, 126], [127, 135], [136, 140], [141, 149], [150, 157], [158, 162], [163, 166], [167, 171], [171, 172]]}
{"doc_key": "ai-test-217", "ner": [[21, 21, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Results", "are", "presented", "that", "give", "a", "correlation", "of", "up", "to", "0.964", "with", "human", "scores", "at", "corpus", "level", ",", "compared", "to", "a", "BLEU", "achievement", "of", "0.817", "in", "the", "same", "dataset", "."], "sentence-detokenized": "Results are presented that give a correlation of up to 0.964 with human scores at corpus level, compared to a BLEU achievement of 0.817 in the same dataset.", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 26], [27, 31], [32, 33], [34, 45], [46, 48], [49, 51], [52, 54], [55, 60], [61, 65], [66, 71], [72, 78], [79, 81], [82, 88], [89, 94], [94, 95], [96, 104], [105, 107], [108, 109], [110, 114], [115, 126], [127, 129], [130, 135], [136, 138], [139, 142], [143, 147], [148, 155], [155, 156]]}
{"doc_key": "ai-test-218", "ner": [[3, 4, "metrics"], [18, 18, "metrics"], [20, 22, "metrics"], [24, 26, "metrics"], [27, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 18, 18, "compare", "", false, false], [3, 4, 20, 22, "compare", "", false, false], [3, 4, 24, 26, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "early", "version", "of", "VMAF", "has", "been", "shown", "to", "outperform", "other", "image", "and", "video", "quality", "metrics", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", "and", "VQM", "-", "VFD", "in", "terms", "of", "predictive", "accuracy", "in", "three", "out", "of", "four", "datasets", "when", "compared", "to", "subjective", "ratings", "."], "sentence-detokenized": "The early version of VMAF has been shown to outperform other image and video quality metrics such as SSIM, PSNR -HVS and VQM-VFD in terms of predictive accuracy in three out of four datasets when compared to subjective ratings.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 20], [21, 25], [26, 29], [30, 34], [35, 40], [41, 43], [44, 54], [55, 60], [61, 66], [67, 70], [71, 76], [77, 84], [85, 92], [93, 97], [98, 100], [101, 105], [105, 106], [107, 111], [112, 113], [113, 116], [117, 120], [121, 124], [124, 125], [125, 128], [129, 131], [132, 137], [138, 140], [141, 151], [152, 160], [161, 163], [164, 169], [170, 173], [174, 176], [177, 181], [182, 190], [191, 195], [196, 204], [205, 207], [208, 218], [219, 226], [226, 227]]}
{"doc_key": "ai-test-219", "ner": [[19, 23, "task"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 23, 27, 29, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "of", "the", "word", "\"", "mouse", "\"", "(", "animal", "or", "device", ")", "is", "not", "relevant", "for", "machine", "translation", ",", "but", "it", "is", "relevant", "for", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity of the word \"mouse\" (animal or device) is not relevant for machine translation, but it is relevant for information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 33], [34, 38], [39, 40], [40, 45], [45, 46], [47, 48], [48, 54], [55, 57], [58, 64], [64, 65], [66, 68], [69, 72], [73, 81], [82, 85], [86, 93], [94, 105], [105, 106], [107, 110], [111, 113], [114, 116], [117, 125], [126, 129], [130, 141], [142, 151], [151, 152]]}
{"doc_key": "ai-test-220", "ner": [[0, 3, "algorithm"], [9, 10, "field"], [11, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 3, "usage", "", false, false], [11, 16, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "hashing", "was", "originally", "proposed", "in", "the", "field", "of", "computer", "vision", "for", "2D", "and", "3D", "object", "recognition", ","], "sentence-detokenized": "Geometric hashing was originally proposed in the field of computer vision for 2D and 3D object recognition,", "token2charspan": [[0, 9], [10, 17], [18, 21], [22, 32], [33, 41], [42, 44], [45, 48], [49, 54], [55, 57], [58, 66], [67, 73], [74, 77], [78, 80], [81, 84], [85, 87], [88, 94], [95, 106], [106, 107]]}
{"doc_key": "ai-test-221", "ner": [[9, 10, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 9, 10, "part-of", "subfield", false, false], [17, 18, 9, 10, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "is", "one", "of", "the", "three", "main", "categories", "of", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "It is one of the three main categories of machine learning, along with supervised learning and reinforcement learning.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 12], [13, 16], [17, 22], [23, 27], [28, 38], [39, 41], [42, 49], [50, 58], [58, 59], [60, 65], [66, 70], [71, 81], [82, 90], [91, 94], [95, 108], [109, 117], [117, 118]]}
{"doc_key": "ai-test-222", "ner": [[0, 1, "field"], [16, 16, "field"], [17, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 31, "field"], [33, 34, "field"], [36, 37, "field"], [39, 39, "field"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 1, 16, 16, "part-of", "subfield", false, false], [0, 1, 17, 20, "part-of", "subfield", false, false], [0, 1, 22, 23, "part-of", "subfield", false, false], [0, 1, 25, 26, "part-of", "subfield", false, false], [0, 1, 28, 31, "part-of", "subfield", false, false], [0, 1, 33, 34, "part-of", "subfield", false, false], [0, 1, 36, 37, "part-of", "subfield", false, false], [0, 1, 39, 39, "part-of", "subfield", false, false], [0, 1, 41, 42, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Reinforcement", "learning", ",", "because", "of", "its", "generality", ",", "is", "studied", "in", "many", "other", "disciplines", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Reinforcement learning, because of its generality, is studied in many other disciplines such as game theory, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 13], [14, 22], [22, 23], [24, 31], [32, 34], [35, 38], [39, 49], [49, 50], [51, 53], [54, 61], [62, 64], [65, 69], [70, 75], [76, 87], [88, 92], [93, 95], [96, 100], [101, 107], [107, 108], [109, 116], [117, 123], [123, 124], [125, 135], [136, 144], [144, 145], [146, 157], [158, 164], [164, 165], [166, 176], [176, 177], [177, 182], [183, 195], [195, 196], [197, 208], [209, 216], [216, 217], [218, 223], [224, 236], [236, 237], [238, 248], [249, 252], [253, 260], [261, 271], [271, 272]]}
{"doc_key": "ai-test-223", "ner": [[0, 1, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "related-to", "", false, false], [0, 1, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Feature", "recognition", "is", "closely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ","], "sentence-detokenized": "Feature recognition is closely related to artificial intelligence and machine learning,", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 38], [39, 41], [42, 52], [53, 65], [66, 69], [70, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-224", "ner": [[10, 11, "algorithm"], [14, 15, "field"], [17, 21, "field"], [27, 28, "task"], [30, 30, "task"], [32, 33, "task"], [35, 36, "algorithm"], [38, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 14, 15, "related-to", "", false, false], [10, 11, 17, 21, "related-to", "", false, false], [27, 28, 10, 11, "usage", "", true, false], [30, 30, 10, 11, "usage", "", true, false], [32, 33, 10, 11, "usage", "", true, false], [35, 36, 10, 11, "usage", "", true, false], [38, 40, 10, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "software", "is", "used", "to", "develop", ",", "train", "and", "deploy", "neural", "network", "models", "(", "supervised", "learning", "and", "unsupervised", "learning", ")", "for", "a", "variety", "of", "tasks", "such", "as", "data", "mining", ",", "classification", ",", "feature", "approximation", ",", "multi-factor", "regression", "and", "time", "series", "forecasting", "."], "sentence-detokenized": "The software is used to develop, train and deploy neural network models (supervised learning and unsupervised learning) for a variety of tasks such as data mining, classification, feature approximation, multi-factor regression and time series forecasting.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [21, 23], [24, 31], [31, 32], [33, 38], [39, 42], [43, 49], [50, 56], [57, 64], [65, 71], [72, 73], [73, 83], [84, 92], [93, 96], [97, 109], [110, 118], [118, 119], [120, 123], [124, 125], [126, 133], [134, 136], [137, 142], [143, 147], [148, 150], [151, 155], [156, 162], [162, 163], [164, 178], [178, 179], [180, 187], [188, 201], [201, 202], [203, 215], [216, 226], [227, 230], [231, 235], [236, 242], [243, 254], [254, 255]]}
{"doc_key": "ai-test-225", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016, he was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-test-226", "ner": [[6, 9, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", "and", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", ","], "sentence-detokenized": "She is a member of the National Academy of Sciences (since 2005) and the American Academy of Arts and Sciences (since 2009),", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 15], [16, 18], [19, 22], [23, 31], [32, 39], [40, 42], [43, 51], [52, 53], [53, 58], [59, 63], [63, 64], [65, 68], [69, 72], [73, 81], [82, 89], [90, 92], [93, 97], [98, 101], [102, 110], [111, 112], [112, 117], [118, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-test-227", "ner": [[3, 5, "misc"], [9, 14, "product"], [16, 17, "country"], [19, 19, "country"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 14, 3, 5, "temporal", "", false, false], [9, 14, 16, 17, "physical", "", false, false], [9, 14, 19, 19, "physical", "", false, false], [9, 14, 24, 25, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "the", "1973", "Yom", "Kippur", "War", ",", "Soviet", "-supplied", "surface", "-", "to", "-", "air", "missile", "batteries", "in", "Egypt", "and", "Syria", "caused", "severe", "damage", "to", "Israeli", "fighters", "."], "sentence-detokenized": "During the 1973 Yom Kippur War, Soviet-supplied surface-to-air missile batteries in Egypt and Syria caused severe damage to Israeli fighters.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 26], [27, 30], [30, 31], [32, 38], [38, 47], [48, 55], [55, 56], [56, 58], [58, 59], [59, 62], [63, 70], [71, 80], [81, 83], [84, 89], [90, 93], [94, 99], [100, 106], [107, 113], [114, 120], [121, 123], [124, 131], [132, 140], [140, 141]]}
{"doc_key": "ai-test-228", "ner": [[10, 11, "product"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "resource", "(", "free", "but", "copyright", "protected", ")", "is", "the", "HTK", "book", "(", "and", "the", "accompanying", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another resource (free but copyright protected) is the HTK book (and the accompanying HTK toolkit).", "token2charspan": [[0, 7], [8, 16], [17, 18], [18, 22], [23, 26], [27, 36], [37, 46], [46, 47], [48, 50], [51, 54], [55, 58], [59, 63], [64, 65], [65, 68], [69, 72], [73, 85], [86, 89], [90, 97], [97, 98], [98, 99]]}
{"doc_key": "ai-test-229", "ner": [[0, 4, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "At", "the", "2004", "AAAI", "Spring", "Symposium", ",", "linguists", ",", "computer", "scientists", "and", "other", "interested", "researchers", "for", "the", "first", "time", "aligned", "interests", "and", "proposed", "common", "tasks", "and", "benchmark", "datasets", "for", "systematic", "computational", "research", "on", "affect", ",", "attractiveness", ",", "subjectivity", "and", "sentiment", "in", "texts", "."], "sentence-detokenized": "- At the 2004 AAAI Spring Symposium, linguists, computer scientists and other interested researchers for the first time aligned interests and proposed common tasks and benchmark datasets for systematic computational research on affect, attractiveness, subjectivity and sentiment in texts.", "token2charspan": [[0, 1], [2, 4], [5, 8], [9, 13], [14, 18], [19, 25], [26, 35], [35, 36], [37, 46], [46, 47], [48, 56], [57, 67], [68, 71], [72, 77], [78, 88], [89, 100], [101, 104], [105, 108], [109, 114], [115, 119], [120, 127], [128, 137], [138, 141], [142, 150], [151, 157], [158, 163], [164, 167], [168, 177], [178, 186], [187, 190], [191, 201], [202, 215], [216, 224], [225, 227], [228, 234], [234, 235], [236, 250], [250, 251], [252, 264], [265, 268], [269, 278], [279, 281], [282, 287], [287, 288]]}
{"doc_key": "ai-test-230", "ner": [[13, 16, "task"], [24, 25, "task"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "single", "table", "can", "be", "analysed", "both", "in", "terms", "of", "content", "(", "at", "a", "glance", ")", "and", "structure", "(", "the", "main", "methods", "used", "are", "cluster", "analysis", ",", "principal", "component", "analysis", "and", "various", "structural", "indicators", "related", "to", "the", "complexity", "and", "range", "of", "ratings", ")", "."], "sentence-detokenized": "A single table can be analysed both in terms of content (at a glance) and structure (the main methods used are cluster analysis, principal component analysis and various structural indicators related to the complexity and range of ratings).", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 18], [19, 21], [22, 30], [31, 35], [36, 38], [39, 44], [45, 47], [48, 55], [56, 57], [57, 59], [60, 61], [62, 68], [68, 69], [70, 73], [74, 83], [84, 85], [85, 88], [89, 93], [94, 101], [102, 106], [107, 110], [111, 118], [119, 127], [127, 128], [129, 138], [139, 148], [149, 157], [158, 161], [162, 169], [170, 180], [181, 191], [192, 199], [200, 202], [203, 206], [207, 217], [218, 221], [222, 227], [228, 230], [231, 238], [238, 239], [239, 240]]}
{"doc_key": "ai-test-231", "ner": [[3, 3, "organisation"], [10, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", ",", "Toyota", "was", "seen", "as", "lagging", "behind", "in", "self", "-", "driving", "cars", "and", "in", "need", "of", "innovation", "."], "sentence-detokenized": "In 2018, Toyota was seen as lagging behind in self-driving cars and in need of innovation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 24], [25, 27], [28, 35], [36, 42], [43, 45], [46, 50], [50, 51], [51, 58], [59, 63], [64, 67], [68, 70], [71, 75], [76, 78], [79, 89], [89, 90]]}
{"doc_key": "ai-test-232", "ner": [[37, 38, "misc"], [40, 41, "misc"], [43, 48, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "targets", "are", "natural", "objects", "such", "as", "land", ",", "sea", ",", "precipitation", "(", "e.g.", "rain", ",", "snow", "or", "hail", ")", ",", "sandstorms", ",", "animals", "(", "especially", "birds", ")", ",", "atmospheric", "turbulence", "and", "other", "atmospheric", "effects", "such", "as", "ionospheric", "reflections", ",", "meteor", "trails", "and", "a", "three", "-", "body", "scattering", "spike", "."], "sentence-detokenized": "These targets are natural objects such as land, sea, precipitation (e.g. rain, snow or hail), sandstorms, animals (especially birds), atmospheric turbulence and other atmospheric effects such as ionospheric reflections, meteor trails and a three-body scattering spike.", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 25], [26, 33], [34, 38], [39, 41], [42, 46], [46, 47], [48, 51], [51, 52], [53, 66], [67, 68], [68, 72], [73, 77], [77, 78], [79, 83], [84, 86], [87, 91], [91, 92], [92, 93], [94, 104], [104, 105], [106, 113], [114, 115], [115, 125], [126, 131], [131, 132], [132, 133], [134, 145], [146, 156], [157, 160], [161, 166], [167, 178], [179, 186], [187, 191], [192, 194], [195, 206], [207, 218], [218, 219], [220, 226], [227, 233], [234, 237], [238, 239], [240, 245], [245, 246], [246, 250], [251, 261], [262, 267], [267, 268]]}
{"doc_key": "ai-test-233", "ner": [[21, 26, "product"], [42, 43, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "area", "of", "planning", "and", "control", ",", "the", "most", "important", "difference", "between", "humanoids", "and", "other", "types", "of", "robots", "(", "e.g.", "industrial", "robots", ")", "is", "that", "the", "robot", "'s", "movements", "must", "be", "human", "-", "like", ",", "using", "leg", "movements", ",", "in", "particular", "bipedal", "gait", "."], "sentence-detokenized": "In the area of planning and control, the most important difference between humanoids and other types of robots (e.g. industrial robots) is that the robot's movements must be human-like, using leg movements, in particular bipedal gait.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 23], [24, 27], [28, 35], [35, 36], [37, 40], [41, 45], [46, 55], [56, 66], [67, 74], [75, 84], [85, 88], [89, 94], [95, 100], [101, 103], [104, 110], [111, 112], [112, 116], [117, 127], [128, 134], [134, 135], [136, 138], [139, 143], [144, 147], [148, 153], [153, 155], [156, 165], [166, 170], [171, 173], [174, 179], [179, 180], [180, 184], [184, 185], [186, 191], [192, 195], [196, 205], [205, 206], [207, 209], [210, 220], [221, 228], [229, 233], [233, 234]]}
{"doc_key": "ai-test-234", "ner": [[8, 11, "misc"], [13, 13, "metrics"], [16, 17, "misc"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Many", "iterations", "may", "be", "needed", "to", "calculate", "the", "local", "minimum", "with", "the", "required", "accuracy", "if", "the", "curvature", "of", "the", "given", "function", "varies", "widely", "in", "different", "directions", "."], "sentence-detokenized": "Many iterations may be needed to calculate the local minimum with the required accuracy if the curvature of the given function varies widely in different directions.", "token2charspan": [[0, 4], [5, 15], [16, 19], [20, 22], [23, 29], [30, 32], [33, 42], [43, 46], [47, 52], [53, 60], [61, 65], [66, 69], [70, 78], [79, 87], [88, 90], [91, 94], [95, 104], [105, 107], [108, 111], [112, 117], [118, 126], [127, 133], [134, 140], [141, 143], [144, 153], [154, 164], [164, 165]]}
{"doc_key": "ai-test-235", "ner": [[0, 6, "misc"], [10, 10, "misc"], [17, 24, "conference"], [26, 26, "location"], [28, 28, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 10, 10, "part-of", "", true, false], [17, 24, 26, 26, "physical", "", false, true], [26, 26, 28, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "1997", "RoboCup", "2D", "Football", "Simulation", "League", "was", "the", "first", "RoboCup", "competition", "held", "in", "conjunction", "with", "the", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", ",", "held", "in", "Nagoya", ",", "Japan", ",", "from", "23", "to", "29", "August", "1997", "."], "sentence-detokenized": "The 1997 RoboCup 2D Football Simulation League was the first RoboCup competition held in conjunction with the International Joint Conference on Artificial Intelligence, held in Nagoya, Japan, from 23 to 29 August 1997.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 19], [20, 28], [29, 39], [40, 46], [47, 50], [51, 54], [55, 60], [61, 68], [69, 80], [81, 85], [86, 88], [89, 100], [101, 105], [106, 109], [110, 123], [124, 129], [130, 140], [141, 143], [144, 154], [155, 167], [167, 168], [169, 173], [174, 176], [177, 183], [183, 184], [185, 190], [190, 191], [192, 196], [197, 199], [200, 202], [203, 205], [206, 212], [213, 217], [217, 218]]}
{"doc_key": "ai-test-236", "ner": [[8, 8, "programlang"], [11, 11, "programlang"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "features", "include", "a", "built", "-", "in", "Python", "environment", "and", "R", "console", ",", "as", "well", "as", "Rserve", "support", "."], "sentence-detokenized": "Other programming features include a built-in Python environment and R console, as well as Rserve support.", "token2charspan": [[0, 5], [6, 17], [18, 26], [27, 34], [35, 36], [37, 42], [42, 43], [43, 45], [46, 52], [53, 64], [65, 68], [69, 70], [71, 78], [78, 79], [80, 82], [83, 87], [88, 90], [91, 97], [98, 105], [105, 106]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [12, 13, "field"], [15, 15, "field"], [18, 19, "researcher"], [21, 22, "researcher"], [24, 28, "researcher"], [35, 36, "field"], [40, 41, "field"], [47, 48, "field"], [52, 53, "field"], [59, 62, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[18, 19, 15, 15, "related-to", "contributes_to_field", true, false], [21, 22, 15, 15, "related-to", "contributes_to_field", true, false], [24, 28, 15, 15, "related-to", "contributes_to_field", true, false], [47, 48, 40, 41, "part-of", "", false, false], [52, 53, 47, 48, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["From", "Bonn", ",", "he", "has", "made", "significant", "contributions", "to", "the", "development", "of", "artificial", "intelligence", "and", "robotics", "(", "with", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Trun", ")", ",", "as", "well", "as", "to", "the", "development", "of", "software", "engineering", ",", "especially", "in", "civil", "engineering", ",", "and", "the", "development", "of", "information", "systems", ",", "especially", "in", "the", "geosciences.In", "2016-2014", ",", "he", "won", "the", "AAAI", "Classic", "Paper", "Award", "."], "sentence-detokenized": "From Bonn, he has made significant contributions to the development of artificial intelligence and robotics (with Wolfram Burgard, Dieter Fox, Sebastian Trun), as well as to the development of software engineering, especially in civil engineering, and the development of information systems, especially in the geosciences.In 2016-2014, he won the AAAI Classic Paper Award.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 13], [14, 17], [18, 22], [23, 34], [35, 48], [49, 51], [52, 55], [56, 67], [68, 70], [71, 81], [82, 94], [95, 98], [99, 107], [108, 109], [109, 113], [114, 121], [122, 129], [129, 130], [131, 137], [138, 141], [141, 142], [143, 152], [153, 157], [157, 158], [158, 159], [160, 162], [163, 167], [168, 170], [171, 173], [174, 177], [178, 189], [190, 192], [193, 201], [202, 213], [213, 214], [215, 225], [226, 228], [229, 234], [235, 246], [246, 247], [248, 251], [252, 255], [256, 267], [268, 270], [271, 282], [283, 290], [290, 291], [292, 302], [303, 305], [306, 309], [310, 324], [325, 334], [334, 335], [336, 338], [339, 342], [343, 346], [347, 351], [352, 359], [360, 365], [366, 371], [371, 372]]}
{"doc_key": "ai-test-238", "ner": [[2, 8, "conference"], [14, 16, "location"], [17, 18, "location"], [20, 20, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 8, 14, 16, "physical", "", false, false], [14, 16, 17, 18, "physical", "", false, false], [17, 18, 20, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "US", "Campus", "Party", "will", "take", "place", "from", "20", "-", "22", "August", "at", "the", "TCF", "Centre", "in", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "The first US Campus Party will take place from 20-22 August at the TCF Centre in Detroit, Michigan.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 25], [26, 30], [31, 35], [36, 41], [42, 46], [47, 49], [49, 50], [50, 52], [53, 59], [60, 62], [63, 66], [67, 70], [71, 77], [78, 80], [81, 88], [88, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-239", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 14, "misc"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 12, 14, "win-defeat", "", false, false], [5, 6, 12, 14, "win-defeat", "", false, false], [8, 8, 12, 14, "win-defeat", "", false, false], [12, 14, 22, 24, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Together", "with", "Jan", "Lekun", "and", "Joshua", "Bengio", ",", "Hinton", "received", "the", "2018", "Turing", "Prize", "for", "conceptual", "and", "engineering", "breakthroughs", "that", "have", "made", "deep", "neural", "networks", "an", "essential", "component", "of", "computing", "."], "sentence-detokenized": "Together with Jan Lekun and Joshua Bengio, Hinton received the 2018 Turing Prize for conceptual and engineering breakthroughs that have made deep neural networks an essential component of computing.", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 23], [24, 27], [28, 34], [35, 41], [41, 42], [43, 49], [50, 58], [59, 62], [63, 67], [68, 74], [75, 80], [81, 84], [85, 95], [96, 99], [100, 111], [112, 125], [126, 130], [131, 135], [136, 140], [141, 145], [146, 152], [153, 161], [162, 164], [165, 174], [175, 184], [185, 187], [188, 197], [197, 198]]}
{"doc_key": "ai-test-240", "ner": [[0, 3, "product"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 10, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Euler", "Math", "Toolbox", "uses", "a", "matrix", "language", "similar", "to", "MATLAB", ",", "a", "system", "developed", "since", "the", "1970s", "."], "sentence-detokenized": "The Euler Math Toolbox uses a matrix language similar to MATLAB, a system developed since the 1970s.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 22], [23, 27], [28, 29], [30, 36], [37, 45], [46, 53], [54, 56], [57, 63], [63, 64], [65, 66], [67, 73], [74, 83], [84, 89], [90, 93], [94, 99], [99, 100]]}
{"doc_key": "ai-test-241", "ner": [[8, 8, "programlang"], [10, 11, "programlang"], [13, 13, "programlang"], [15, 15, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "some", "languages", "this", "is", "possible", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "or", "D", ")", "."], "sentence-detokenized": "In some languages this is possible (e.g. Scheme, Common Lisp, Perl or D).", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 22], [23, 25], [26, 34], [35, 36], [36, 40], [41, 47], [47, 48], [49, 55], [56, 60], [60, 61], [62, 66], [67, 69], [70, 71], [71, 72], [72, 73]]}
{"doc_key": "ai-test-242", "ner": [[12, 12, "misc"], [3, 4, "researcher"], [6, 8, "researcher"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 12, 3, 4, "artifact", "", false, false], [12, 12, 6, 8, "artifact", "", false, false], [12, 12, 24, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1969", ",", "Marvin", "Minsky", "and", "Seymour", "Papert", "'s", "famous", "book", "\"", "Perceptrons", "\"", "showed", "that", "this", "class", "of", "networks", "can", "not", "learn", "the", "XOR", "function", "."], "sentence-detokenized": "In 1969, Marvin Minsky and Seymour Papert's famous book \"Perceptrons\" showed that this class of networks cannot learn the XOR function.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 22], [23, 26], [27, 34], [35, 41], [41, 43], [44, 50], [51, 55], [56, 57], [57, 68], [68, 69], [70, 76], [77, 81], [82, 86], [87, 92], [93, 95], [96, 104], [105, 108], [108, 111], [112, 117], [118, 121], [122, 125], [126, 134], [134, 135]]}
{"doc_key": "ai-test-243", "ner": [[9, 14, "misc"], [0, 3, "product"], [19, 25, "organisation"], [28, 36, "organisation"], [37, 42, "location"], [44, 44, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[19, 25, 0, 3, "usage", "", false, false], [19, 25, 37, 42, "physical", "", false, false], [28, 36, 19, 25, "named", "", false, false], [37, 42, 44, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SYSTRAN", "was", "used", "to", "translate", "a", "large", "number", "of", "Russian", "scientific", "and", "technical", "documents", "under", "the", "auspices", "of", "the", "US", "Air", "Force", "'s", "Foreign", "Technology", "Division", "(", "later", "the", "National", "Air", "and", "Space", "Intelligence", "Centre", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", ",", "Ohio", "."], "sentence-detokenized": "SYSTRAN was used to translate a large number of Russian scientific and technical documents under the auspices of the US Air Force's Foreign Technology Division (later the National Air and Space Intelligence Centre) at Wright-Patterson Air Force Base, Ohio.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 29], [30, 31], [32, 37], [38, 44], [45, 47], [48, 55], [56, 66], [67, 70], [71, 80], [81, 90], [91, 96], [97, 100], [101, 109], [110, 112], [113, 116], [117, 119], [120, 123], [124, 129], [129, 131], [132, 139], [140, 150], [151, 159], [160, 161], [161, 166], [167, 170], [171, 179], [180, 183], [184, 187], [188, 193], [194, 206], [207, 213], [213, 214], [215, 217], [218, 224], [224, 225], [225, 234], [235, 238], [239, 244], [245, 249], [249, 250], [251, 255], [255, 256]]}
{"doc_key": "ai-test-244", "ner": [[0, 1, "field"], [4, 5, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-supervised", "learning", "is", "between", "unsupervised", "learning", "(", "without", "labelled", "learning", "data", ")", "and", "supervised", "learning", "(", "with", "fully", "labelled", "learning", "data", ")", "."], "sentence-detokenized": "Semi-supervised learning is between unsupervised learning (without labelled learning data) and supervised learning (with fully labelled learning data).", "token2charspan": [[0, 15], [16, 24], [25, 27], [28, 35], [36, 48], [49, 57], [58, 59], [59, 66], [67, 75], [76, 84], [85, 89], [89, 90], [91, 94], [95, 105], [106, 114], [115, 116], [116, 120], [121, 126], [127, 135], [136, 144], [145, 149], [149, 150], [150, 151]]}
{"doc_key": "ai-test-245", "ner": [[0, 4, "algorithm"], [7, 10, "algorithm"], [30, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 7, 10, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Ann", "-", "gram", "model", "is", "a", "probabilistic", "language", "model", "that", "allows", "efficient", "prediction", "of", "the", "next", "element", "in", "this", "sequence", "(", "n", "-", "1", ")", "in", "the", "form", "of", "a", "Markov", "model", "."], "sentence-detokenized": "The Ann -gram model is a probabilistic language model that allows efficient prediction of the next element in this sequence (n - 1) in the form of a Markov model.", "token2charspan": [[0, 3], [4, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 24], [25, 38], [39, 47], [48, 53], [54, 58], [59, 65], [66, 75], [76, 86], [87, 89], [90, 93], [94, 98], [99, 106], [107, 109], [110, 114], [115, 123], [124, 125], [125, 126], [127, 128], [129, 130], [130, 131], [132, 134], [135, 138], [139, 143], [144, 146], [147, 148], [149, 155], [156, 161], [161, 162]]}
{"doc_key": "ai-test-246", "ner": [[0, 2, "organisation"], [5, 6, "product"], [9, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 5, 6, "usage", "", false, false], [9, 18, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "has", "used", "Cyc", "to", "develop", "a", "natural", "language", "query", "interface", "for", "biomedical", "information", ",", "covering", "decades", "of", "information", "on", "cardiothoracic", "surgery", "."], "sentence-detokenized": "The Cleveland Clinic has used Cyc to develop a natural language query interface for biomedical information, covering decades of information on cardiothoracic surgery.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 24], [25, 29], [30, 33], [34, 36], [37, 44], [45, 46], [47, 54], [55, 63], [64, 69], [70, 79], [80, 83], [84, 94], [95, 106], [106, 107], [108, 116], [117, 124], [125, 127], [128, 139], [140, 142], [143, 157], [158, 165], [165, 166]]}
{"doc_key": "ai-test-247", "ner": [[6, 7, "country"], [9, 13, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 9, 13, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "incident", "inflamed", "relations", "between", "the", "United", "States", "and", "Japan", ",", "leading", "to", "the", "arrest", "and", "prosecution", "of", "two", "senior", "executives", "and", "the", "imposition", "of", "sanctions", "on", "the", "company", "by", "both", "countries", "."], "sentence-detokenized": "The incident inflamed relations between the United States and Japan, leading to the arrest and prosecution of two senior executives and the imposition of sanctions on the company by both countries.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 31], [32, 39], [40, 43], [44, 50], [51, 57], [58, 61], [62, 67], [67, 68], [69, 76], [77, 79], [80, 83], [84, 90], [91, 94], [95, 106], [107, 109], [110, 113], [114, 120], [121, 131], [132, 135], [136, 139], [140, 150], [151, 153], [154, 163], [164, 166], [167, 170], [171, 178], [179, 181], [182, 186], [187, 196], [196, 197]]}
{"doc_key": "ai-test-248", "ner": [[4, 6, "algorithm"], [9, 13, "field"], [20, 22, "misc"], [32, 34, "misc"], [35, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 9, 13, "type-of", "", false, false], [20, 22, 9, 13, "part-of", "", true, false], [32, 34, 9, 13, "part-of", "", true, false], [35, 36, 9, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["When", "modelling", "with", "an", "artificial", "neural", "network", "or", "other", "machine", "learning", "method", ",", "the", "optimisation", "of", "the", "parameters", "is", "called", "training", ",", "while", "the", "optimisation", "of", "the", "model", "'s", "hyperparameters", "is", "called", "tuning", ",", "and", "cross", "-checking", "is", "often", "used", "."], "sentence-detokenized": "When modelling with an artificial neural network or other machine learning method, the optimisation of the parameters is called training, while the optimisation of the model's hyperparameters is called tuning, and cross-checking is often used.", "token2charspan": [[0, 4], [5, 14], [15, 19], [20, 22], [23, 33], [34, 40], [41, 48], [49, 51], [52, 57], [58, 65], [66, 74], [75, 81], [81, 82], [83, 86], [87, 99], [100, 102], [103, 106], [107, 117], [118, 120], [121, 127], [128, 136], [136, 137], [138, 143], [144, 147], [148, 160], [161, 163], [164, 167], [168, 173], [173, 175], [176, 191], [192, 194], [195, 201], [202, 208], [208, 209], [210, 213], [214, 219], [219, 228], [229, 231], [232, 237], [238, 242], [242, 243]]}
{"doc_key": "ai-test-249", "ner": [[10, 10, "country"], [12, 12, "country"], [14, 16, "country"], [23, 24, "organisation"], [19, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[23, 24, 19, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "localised", "versions", "of", "the", "site", ",", "available", "in", "the", "UK", ",", "India", "and", "Australia", ",", "were", "discontinued", "after", "Fandango", "was", "acquired", "by", "Rotten", "Tomatoes", "."], "sentence-detokenized": "The localised versions of the site, available in the UK, India and Australia, were discontinued after Fandango was acquired by Rotten Tomatoes.", "token2charspan": [[0, 3], [4, 13], [14, 22], [23, 25], [26, 29], [30, 34], [34, 35], [36, 45], [46, 48], [49, 52], [53, 55], [55, 56], [57, 62], [63, 66], [67, 76], [76, 77], [78, 82], [83, 95], [96, 101], [102, 110], [111, 114], [115, 123], [124, 126], [127, 133], [134, 142], [142, 143]]}
{"doc_key": "ai-test-250", "ner": [[0, 1, "task"], [11, 12, "metrics"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 11, 12, "related-to", "", false, false], [11, 12, 24, 25, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "NER", "model", "is", "one", "of", "several", "methods", "for", "determining", "the", "accuracy", "of", "live", "subtitles", "for", "television", "programmes", "and", "events", "that", "are", "produced", "using", "speech", "recognition", "."], "sentence-detokenized": "The NER model is one of several methods for determining the accuracy of live subtitles for television programmes and events that are produced using speech recognition.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 31], [32, 39], [40, 43], [44, 55], [56, 59], [60, 68], [69, 71], [72, 76], [77, 86], [87, 90], [91, 101], [102, 112], [113, 116], [117, 123], [124, 128], [129, 132], [133, 141], [142, 147], [148, 154], [155, 166], [166, 167]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [4, 7, "university"], [10, 12, "university"], [13, 13, "location"], [16, 20, "university"], [23, 24, "university"], [25, 26, "location"], [30, 35, "university"], [36, 38, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 7, "physical", "", false, false], [0, 0, 4, 7, "role", "", false, false], [0, 0, 10, 12, "physical", "", false, false], [0, 0, 10, 12, "role", "", false, false], [0, 0, 16, 20, "physical", "", false, false], [0, 0, 16, 20, "role", "", false, false], [0, 0, 23, 24, "physical", "", false, false], [0, 0, 23, 24, "role", "", false, false], [0, 0, 30, 35, "physical", "", false, false], [0, 0, 30, 35, "role", "", false, false], [10, 12, 13, 13, "physical", "", false, false], [16, 20, 25, 26, "physical", "", false, false], [23, 24, 25, 26, "physical", "", false, false], [30, 35, 36, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "has", "taught", "at", "the", "University", "of", "Cambridge", ",", "the", "Hebrew", "University", "of", "Jerusalem", ",", "the", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "and", "the", "\u00c9cole", "Polytechnique", "in", "Paris", ",", "and", "the", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "."], "sentence-detokenized": "Atran has taught at the University of Cambridge, the Hebrew University of Jerusalem, the \u00c9cole pratique des hautes \u00e9tudes and the \u00c9cole Polytechnique in Paris, and the John Jay College of Criminal Justice in New York.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 47], [47, 48], [49, 52], [53, 59], [60, 70], [71, 73], [74, 83], [83, 84], [85, 88], [89, 94], [95, 103], [104, 107], [108, 114], [115, 121], [122, 125], [126, 129], [130, 135], [136, 149], [150, 152], [153, 158], [158, 159], [160, 163], [164, 167], [168, 172], [173, 176], [177, 184], [185, 187], [188, 196], [197, 204], [205, 207], [208, 211], [212, 216], [216, 217]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [4, 6, "task"], [11, 18, "researcher"], [14, 15, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "origin", "", false, false], [0, 0, 4, 6, "related-to", "", false, false], [4, 6, 14, 15, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "was", "an", "early", "natural", "language", "understanding", "computer", "program", "developed", "by", "Terry", "Winograd", "at", "MIT", "in", "1968", "-", "1970", "."], "sentence-detokenized": "SHRDLU was an early natural language understanding computer program developed by Terry Winograd at MIT in 1968-1970.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 19], [20, 27], [28, 36], [37, 50], [51, 59], [60, 67], [68, 77], [78, 80], [81, 86], [87, 95], [96, 98], [99, 102], [103, 105], [106, 110], [110, 111], [111, 115], [115, 116]]}
{"doc_key": "ai-test-253", "ner": [[3, 3, "misc"], [5, 7, "field"], [8, 12, "university"], [13, 14, "location"], [16, 18, "country"], [26, 29, "university"], [30, 31, "misc"], [32, 36, "field"], [38, 41, "university"], [44, 45, "misc"], [46, 48, "field"], [54, 54, "misc"], [57, 66, "university"], [68, 69, "field"], [73, 74, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[3, 3, 5, 7, "topic", "", false, false], [3, 3, 8, 12, "origin", "", false, false], [8, 12, 13, 14, "physical", "", false, false], [8, 12, 26, 29, "role", "affiliated_with", false, false], [13, 14, 16, 18, "physical", "", false, false], [30, 31, 32, 36, "topic", "", false, false], [30, 31, 38, 41, "origin", "", false, false], [44, 45, 46, 48, "topic", "", false, false], [54, 54, 57, 66, "origin", "", false, false], [54, 54, 68, 69, "topic", "", false, false], [73, 74, 57, 66, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["He", "received", "his", "B.Sc", ".", "in", "Electronics", "Engineering", "from", "B.M.S", ".", "Engineering", "College", ",", "Bangalore", ",", "India", ",", "in", "1982", ",", "when", "it", "was", "affiliated", "to", "Bangalore", "University", ",", "his", "M.Sc", ".", "in", "Electrical", "and", "Computer", "Engineering", "from", "Drexel", "University", "in", "1984", "and", "his", "M.Sc", ".", "in", "Computer", "Science", "in", "1989", ",", "and", "his", "Ph.D.", "in", "1990", "from", "the", "University", "of", "Wisconsin", "-", "Madison", ",", "where", "he", "studied", "Artificial", "Intelligence", "and", "worked", "with", "Leonard", "Ure", "."], "sentence-detokenized": "He received his B.Sc. in Electronics Engineering from B.M.S. Engineering College, Bangalore, India, in 1982, when it was affiliated to Bangalore University, his M.Sc. in Electrical and Computer Engineering from Drexel University in 1984 and his M.Sc. in Computer Science in 1989, and his Ph.D. in 1990 from the University of Wisconsin-Madison, where he studied Artificial Intelligence and worked with Leonard Ure.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [20, 21], [22, 24], [25, 36], [37, 48], [49, 53], [54, 59], [59, 60], [61, 72], [73, 80], [80, 81], [82, 91], [91, 92], [93, 98], [98, 99], [100, 102], [103, 107], [107, 108], [109, 113], [114, 116], [117, 120], [121, 131], [132, 134], [135, 144], [145, 155], [155, 156], [157, 160], [161, 165], [165, 166], [167, 169], [170, 180], [181, 184], [185, 193], [194, 205], [206, 210], [211, 217], [218, 228], [229, 231], [232, 236], [237, 240], [241, 244], [245, 249], [249, 250], [251, 253], [254, 262], [263, 270], [271, 273], [274, 278], [278, 279], [280, 283], [284, 287], [288, 293], [294, 296], [297, 301], [302, 306], [307, 310], [311, 321], [322, 324], [325, 334], [334, 335], [335, 342], [342, 343], [344, 349], [350, 352], [353, 360], [361, 371], [372, 384], [385, 388], [389, 395], [396, 400], [401, 408], [409, 412], [412, 413]]}
{"doc_key": "ai-test-254", "ner": [[6, 8, "metrics"], [10, 13, "metrics"], [19, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 13, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "usually", "measured", "by", "the", "word", "error", "rate", "(", "WER", ")", ",", "while", "speed", "is", "measured", "by", "the", "real", "-", "time", "rate", "."], "sentence-detokenized": "Accuracy is usually measured by the word error rate (WER), while speed is measured by the real-time rate.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 28], [29, 31], [32, 35], [36, 40], [41, 46], [47, 51], [52, 53], [53, 56], [56, 57], [57, 58], [59, 64], [65, 70], [71, 73], [74, 82], [83, 85], [86, 89], [90, 94], [94, 95], [95, 99], [100, 104], [104, 105]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [8, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", ",", "Terry", "Winograd", "developed", "an", "early", "natural", "language", "processing", "engine", "that", "could", "interpret", "naturally", "written", "commands", "in", "a", "simple", ",", "rule", "-", "governed", "environment", "."], "sentence-detokenized": "In 1971, Terry Winograd developed an early natural language processing engine that could interpret naturally written commands in a simple, rule-governed environment.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 33], [34, 36], [37, 42], [43, 50], [51, 59], [60, 70], [71, 77], [78, 82], [83, 88], [89, 98], [99, 108], [109, 116], [117, 125], [126, 128], [129, 130], [131, 137], [137, 138], [139, 143], [143, 144], [144, 152], [153, 164], [164, 165]]}
{"doc_key": "ai-test-256", "ner": [[16, 18, "field"], [0, 1, "researcher"], [3, 6, "researcher"], [8, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 18, 0, 1, "related-to", "", false, false], [16, 18, 3, 6, "related-to", "", false, false], [16, 18, 8, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "and", "Allen", "Newell", "are", "all", "prominent", "in", "the", "field", "of", "artificial", "intelligence", "."], "sentence-detokenized": "Marvin Minsky, Herbert A. Simon and Allen Newell are all prominent in the field of artificial intelligence.", "token2charspan": [[0, 6], [7, 13], [13, 14], [15, 22], [23, 24], [24, 25], [26, 31], [32, 35], [36, 41], [42, 48], [49, 52], [53, 56], [57, 66], [67, 69], [70, 73], [74, 79], [80, 82], [83, 93], [94, 106], [106, 107]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [31, 32, "field"], [34, 35, "field"], [38, 39, "field"], [48, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[31, 32, 9, 10, "origin", "", true, false], [31, 32, 9, 10, "part-of", "", false, false], [31, 32, 38, 39, "compare", "", false, false], [34, 35, 9, 10, "origin", "", true, false], [34, 35, 9, 10, "part-of", "", false, false], [34, 35, 38, 39, "compare", "", false, false], [38, 39, 9, 10, "origin", "", true, false], [38, 39, 9, 10, "part-of", "", false, false], [38, 39, 48, 51, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "the", "second", "half", "of", "the", "20th", "century", ",", "electrical", "engineering", "itself", "split", "into", "several", "disciplines", "specialising", "in", "the", "design", "and", "analysis", "of", "systems", "that", "manipulate", "physical", "signals", ";", "examples", "include", "electronic", "engineering", "and", "computer", "engineering", ";", "while", "design", "engineering", "evolved", "to", "deal", "with", "the", "functional", "design", "of", "user", "-", "machine", "interfaces", "."], "sentence-detokenized": "In the second half of the 20th century, electrical engineering itself split into several disciplines specialising in the design and analysis of systems that manipulate physical signals; examples include electronic engineering and computer engineering; while design engineering evolved to deal with the functional design of user-machine interfaces.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 30], [31, 38], [38, 39], [40, 50], [51, 62], [63, 69], [70, 75], [76, 80], [81, 88], [89, 100], [101, 113], [114, 116], [117, 120], [121, 127], [128, 131], [132, 140], [141, 143], [144, 151], [152, 156], [157, 167], [168, 176], [177, 184], [184, 185], [186, 194], [195, 202], [203, 213], [214, 225], [226, 229], [230, 238], [239, 250], [250, 251], [252, 257], [258, 264], [265, 276], [277, 284], [285, 287], [288, 292], [293, 297], [298, 301], [302, 312], [313, 319], [320, 322], [323, 327], [327, 328], [328, 335], [336, 346], [346, 347]]}
{"doc_key": "ai-test-258", "ner": [[6, 6, "metrics"], [10, 11, "metrics"], [13, 16, "metrics"], [47, 49, "metrics"], [56, 58, "metrics"], [62, 68, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 16, 10, 11, "named", "", false, false], [47, 49, 56, 58, "named", "", false, false], [56, 58, 62, 68, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Perhaps", "the", "simplest", "statistic", "is", "the", "accuracy", ",", "or", "the", "fraction", "correct", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "all", "cases", "correctly", "classified", ";", "it", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "total", "population", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Perhaps the simplest statistic is the accuracy, or the fraction correct (FC), which measures the proportion of all cases correctly classified; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN) / total population = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 30], [31, 33], [34, 37], [38, 46], [46, 47], [48, 50], [51, 54], [55, 63], [64, 71], [72, 73], [73, 75], [75, 76], [76, 77], [78, 83], [84, 92], [93, 96], [97, 107], [108, 110], [111, 114], [115, 120], [121, 130], [131, 141], [141, 142], [143, 145], [146, 148], [149, 152], [153, 158], [159, 161], [162, 165], [166, 172], [173, 175], [176, 183], [184, 199], [200, 202], [203, 206], [207, 212], [213, 219], [220, 222], [223, 230], [231, 233], [234, 243], [244, 259], [259, 260], [261, 262], [262, 264], [265, 266], [267, 269], [269, 270], [271, 272], [273, 278], [279, 289], [290, 291], [292, 293], [293, 295], [296, 297], [298, 300], [300, 301], [302, 303], [304, 305], [305, 307], [308, 309], [310, 312], [313, 314], [315, 317], [318, 319], [320, 322], [322, 323], [323, 324]]}
{"doc_key": "ai-test-259", "ner": [[12, 20, "conference"], [22, 31, "conference"], [26, 27, "location"], [31, 31, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 20, 26, 27, "physical", "", false, false], [22, 31, 12, 20, "named", "", false, false], [31, 31, 12, 20, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "academia", ",", "the", "main", "research", "fora", "began", "in", "1995", "with", "the", "first", "international", "conference", "on", "data", "mining", "and", "knowledge", "discovery", "(", "KDD", "-", "95", ")", "in", "Montreal", ",", "sponsored", "by", "AAAI", "."], "sentence-detokenized": "In academia, the main research fora began in 1995 with the first international conference on data mining and knowledge discovery (KDD-95) in Montreal, sponsored by AAAI.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 16], [17, 21], [22, 30], [31, 35], [36, 41], [42, 44], [45, 49], [50, 54], [55, 58], [59, 64], [65, 78], [79, 89], [90, 92], [93, 97], [98, 104], [105, 108], [109, 118], [119, 128], [129, 130], [130, 133], [133, 134], [134, 136], [136, 137], [138, 140], [141, 149], [149, 150], [151, 160], [161, 163], [164, 168], [168, 169]]}
{"doc_key": "ai-test-260", "ner": [[6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "approach", "develops", "models", "using", "various", "data", "mining", ",", "machine", "learning", "algorithms", "to", "predict", "user", "ratings", "on", "unrated", "items", "."], "sentence-detokenized": "This approach develops models using various data mining, machine learning algorithms to predict user ratings on unrated items.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 29], [30, 35], [36, 43], [44, 48], [49, 55], [55, 56], [57, 64], [65, 73], [74, 84], [85, 87], [88, 95], [96, 100], [101, 108], [109, 111], [112, 119], [120, 125], [125, 126]]}
{"doc_key": "ai-test-261", "ner": [[10, 10, "algorithm"], [15, 18, "algorithm"], [20, 23, "algorithm"], [28, 29, "misc"], [32, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 10, 15, 18, "related-to", "equivalent", false, false], [15, 18, 20, 23, "usage", "", false, false], [20, 23, 32, 33, "usage", "", false, false], [32, 33, 28, 29, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "view", "of", "the", "above", ",", "we", "see", "that", "the", "SVM", "method", "is", "equivalent", "to", "the", "empirical", "risk", "method", "with", "Tikhonov", "regularisation", ",", "where", "in", "this", "case", "the", "loss", "function", "is", "the", "hinge", "loss", "."], "sentence-detokenized": "In view of the above, we see that the SVM method is equivalent to the empirical risk method with Tikhonov regularisation, where in this case the loss function is the hinge loss.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 20], [20, 21], [22, 24], [25, 28], [29, 33], [34, 37], [38, 41], [42, 48], [49, 51], [52, 62], [63, 65], [66, 69], [70, 79], [80, 84], [85, 91], [92, 96], [97, 105], [106, 120], [120, 121], [122, 127], [128, 130], [131, 135], [136, 140], [141, 144], [145, 149], [150, 158], [159, 161], [162, 165], [166, 171], [172, 176], [176, 177]]}
{"doc_key": "ai-test-262", "ner": [[6, 7, "person"], [10, 11, "person"], [14, 14, "organisation"], [16, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 19, 14, 14, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "2015", "edition", "was", "hosted", "by", "Molly", "McGrath", ",", "with", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "as", "commentators", "."], "sentence-detokenized": "The 2015 edition was hosted by Molly McGrath, with Chris Rose and former UFC fighter Kenny Florian as commentators.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 27], [28, 30], [31, 36], [37, 44], [44, 45], [46, 50], [51, 56], [57, 61], [62, 65], [66, 72], [73, 76], [77, 84], [85, 90], [91, 98], [99, 101], [102, 114], [114, 115]]}
{"doc_key": "ai-test-263", "ner": [[3, 5, "product"], [9, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [18, 18, "researcher"], [23, 23, "researcher"], [32, 33, "researcher"], [34, 36, "task"], [38, 39, "product"], [41, 43, "researcher"], [44, 45, "task"], [48, 50, "researcher"], [53, 54, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[3, 5, 9, 11, "origin", "", false, false], [3, 5, 13, 14, "origin", "", false, false], [3, 5, 16, 17, "origin", "", false, false], [3, 5, 18, 18, "origin", "", false, false], [13, 14, 41, 43, "named", "same", false, false], [16, 17, 23, 23, "named", "same", false, false], [16, 17, 32, 33, "named", "same", false, false], [34, 36, 38, 39, "related-to", "", false, false], [38, 39, 32, 33, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["A", "subset", "called", "Micro", "-", "Planner", "was", "introduced", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "Sussman", ",", ",", ",", "and", "Winograd", "in", "1971", ",", "and", "has", "been", "used", "in", "Winograd", "'s", "natural", "language", "understanding", "programme", "at", "SHRDLU", ",", "Eugene", "Charniak", "'s", "story", "comprehension", "work", ",", "Thorne", "McCarty", "'s", "work", "on", "legal", "reasoning", "and", "a", "few", "other", "projects", "."], "sentence-detokenized": "A subset called Micro-Planner was introduced by Gerald Jay Sussman, Eugene Charniak and Terry Winograd Sussman,,, and Winograd in 1971, and has been used in Winograd's natural language understanding programme at SHRDLU, Eugene Charniak's story comprehension work, Thorne McCarty's work on legal reasoning and a few other projects.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [21, 22], [22, 29], [30, 33], [34, 44], [45, 47], [48, 54], [55, 58], [59, 66], [66, 67], [68, 74], [75, 83], [84, 87], [88, 93], [94, 102], [103, 110], [110, 111], [111, 112], [112, 113], [114, 117], [118, 126], [127, 129], [130, 134], [134, 135], [136, 139], [140, 143], [144, 148], [149, 153], [154, 156], [157, 165], [165, 167], [168, 175], [176, 184], [185, 198], [199, 208], [209, 211], [212, 218], [218, 219], [220, 226], [227, 235], [235, 237], [238, 243], [244, 257], [258, 262], [262, 263], [264, 270], [271, 278], [278, 280], [281, 285], [286, 288], [289, 294], [295, 304], [305, 308], [309, 310], [311, 314], [315, 320], [321, 329], [329, 330]]}
{"doc_key": "ai-test-264", "ner": [[0, 1, "product"], [9, 10, "product"], [14, 16, "task"], [18, 19, "task"], [21, 23, "task"], [25, 26, "task"], [28, 29, "task"], [32, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 10, 0, 1, "usage", "", true, false], [14, 16, 9, 10, "part-of", "", true, false], [18, 19, 9, 10, "part-of", "", true, false], [21, 23, 9, 10, "part-of", "", true, false], [25, 26, 9, 10, "part-of", "", true, false], [28, 29, 9, 10, "part-of", "", true, false], [32, 35, 9, 10, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "has", "been", "used", "for", "a", "number", "of", "information", "system", "purposes", ",", "including", "word", "sense", "disambiguation", ",", "information", "retrieval", ",", "automatic", "text", "classification", ",", "automatic", "summarisation", ",", "machine", "translation", "and", "even", "automatic", "crossword", "puzzle", "generation", "."], "sentence-detokenized": "WordNet has been used for a number of information system purposes, including word sense disambiguation, information retrieval, automatic text classification, automatic summarisation, machine translation and even automatic crossword puzzle generation.", "token2charspan": [[0, 4], [4, 7], [8, 11], [12, 16], [17, 21], [22, 25], [26, 27], [28, 34], [35, 37], [38, 49], [50, 56], [57, 65], [65, 66], [67, 76], [77, 81], [82, 87], [88, 102], [102, 103], [104, 115], [116, 125], [125, 126], [127, 136], [137, 141], [142, 156], [156, 157], [158, 167], [168, 181], [181, 182], [183, 190], [191, 202], [203, 206], [207, 211], [212, 221], [222, 231], [232, 238], [239, 249], [249, 250]]}
{"doc_key": "ai-test-265", "ner": [[3, 3, "researcher"], [6, 6, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 6, 6, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1996", ",", "Keutzer", "was", "awarded", "IEEE", "Fellow", "status", "."], "sentence-detokenized": "In 1996, Keutzer was awarded IEEE Fellow status.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 20], [21, 28], [29, 33], [34, 40], [41, 47], [47, 48]]}
{"doc_key": "ai-test-266", "ner": [[8, 10, "algorithm"], [55, 56, "misc"], [65, 66, "algorithm"], [68, 69, "algorithm"], [71, 72, "algorithm"], [74, 75, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[65, 66, 55, 56, "type-of", "", false, false], [68, 69, 55, 56, "type-of", "", false, false], [71, 72, 55, 56, "type-of", "", false, false], [74, 75, 55, 56, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "widely", "used", "form", "of", "composition", "is", "the", "non-linear", "weighted", "sum", ",", "where", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "left", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "right", ")", "/", "math", ",", "where", "math", "\\", "textstyle", "K", "/", "math", "(", "usually", "called", "the", "activation", "function", ")", "is", "some", "predefined", "function", "such", "as", "the", "hyperbolic", "tangent", ",", "sigmoid", "function", ",", "softmax", "function", "or", "rectilinear", "function", "."], "sentence-detokenized": "A widely used form of composition is the non-linear weighted sum, where math\\ textstyle f (x) = K\\ left (\\ sum _ i w _ i g _ i (x)\\ right) / math, where math\\ textstyle K / math (usually called the activation function) is some predefined function such as the hyperbolic tangent, sigmoid function, softmax function or rectilinear function.", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 18], [19, 21], [22, 33], [34, 36], [37, 40], [41, 51], [52, 60], [61, 64], [64, 65], [66, 71], [72, 76], [76, 77], [78, 87], [88, 89], [90, 91], [91, 92], [92, 93], [94, 95], [96, 97], [97, 98], [99, 103], [104, 105], [105, 106], [107, 110], [111, 112], [113, 114], [115, 116], [117, 118], [119, 120], [121, 122], [123, 124], [125, 126], [127, 128], [128, 129], [129, 130], [130, 131], [132, 137], [137, 138], [139, 140], [141, 145], [145, 146], [147, 152], [153, 157], [157, 158], [159, 168], [169, 170], [171, 172], [173, 177], [178, 179], [179, 186], [187, 193], [194, 197], [198, 208], [209, 217], [217, 218], [219, 221], [222, 226], [227, 237], [238, 246], [247, 251], [252, 254], [255, 258], [259, 269], [270, 277], [277, 278], [279, 286], [287, 295], [295, 296], [297, 304], [305, 313], [314, 316], [317, 328], [329, 337], [337, 338]]}
{"doc_key": "ai-test-267", "ner": [[1, 1, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "Westworld", ",", "female", "robots", "did", "have", "sex", "with", "male", "humans", "as", "part", "of", "a", "fictional", "holiday", "world", "paid", "for", "by", "human", "clients", "."], "sentence-detokenized": "In Westworld, female robots did have sex with male humans as part of a fictional holiday world paid for by human clients.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 20], [21, 27], [28, 31], [32, 36], [37, 40], [41, 45], [46, 50], [51, 57], [58, 60], [61, 65], [66, 68], [69, 70], [71, 80], [81, 88], [89, 94], [95, 99], [100, 103], [104, 106], [107, 112], [113, 120], [120, 121]]}
{"doc_key": "ai-test-268", "ner": [[5, 13, "task"], [20, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 13, 20, 25, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "process", "usually", "starts", "with", "extracting", "terminology", "and", "concepts", "or", "noun", "phrases", "from", "the", "text", "using", "linguistic", "processors", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "phrase", "splitting", "."], "sentence-detokenized": "The process usually starts with extracting terminology and concepts or noun phrases from the text using linguistic processors such as part-of-speech tagging and phrase splitting.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 26], [27, 31], [32, 42], [43, 54], [55, 58], [59, 67], [68, 70], [71, 75], [76, 83], [84, 88], [89, 92], [93, 97], [98, 103], [104, 114], [115, 125], [126, 130], [131, 133], [134, 138], [138, 139], [139, 141], [141, 142], [142, 148], [149, 156], [157, 160], [161, 167], [168, 177], [177, 178]]}
{"doc_key": "ai-test-269", "ner": [[11, 12, "field"], [16, 17, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "demonstrated", "its", "performance", "on", "several", "problems", "of", "interest", "to", "the", "machine", "learning", "community", ",", "including", "handwriting", "recognition", "."], "sentence-detokenized": "They demonstrated its performance on several problems of interest to the machine learning community, including handwriting recognition.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 33], [34, 36], [37, 44], [45, 53], [54, 56], [57, 65], [66, 68], [69, 72], [73, 80], [81, 89], [90, 99], [99, 100], [101, 110], [111, 122], [123, 134], [134, 135]]}
{"doc_key": "ai-test-270", "ner": [[2, 2, "university"], [4, 4, "researcher"], [10, 11, "researcher"], [15, 15, "product"], [19, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 2, 2, "physical", "", false, false], [4, 4, 2, 2, "role", "", false, false], [15, 15, 10, 11, "origin", "", false, false], [15, 15, 19, 20, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "at", "Stanford", ",", "Steinman", "received", "a", "scholarship", "sponsored", "by", "George", "Devol", ",", "inventor", "of", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "While at Stanford, Steinman received a scholarship sponsored by George Devol, inventor of Unimate, the first industrial robot.", "token2charspan": [[0, 5], [6, 8], [9, 17], [17, 18], [19, 27], [28, 36], [37, 38], [39, 50], [51, 60], [61, 63], [64, 70], [71, 76], [76, 77], [78, 86], [87, 89], [90, 97], [97, 98], [99, 102], [103, 108], [109, 119], [120, 125], [125, 126]]}
{"doc_key": "ai-test-271", "ner": [[7, 8, "task"], [11, 13, "metrics"], [15, 15, "metrics"], [26, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 11, 13, "usage", "", true, false], [15, 15, 11, 13, "named", "", false, false], [26, 28, 11, 13, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Although", "originally", "used", "for", "the", "evaluation", "of", "machine", "translations", ",", "the", "bilingual", "evaluation", "method", "(", "BLEU", ")", "has", "also", "been", "successfully", "used", "for", "the", "evaluation", "of", "paraphrase", "generation", "models", "."], "sentence-detokenized": "Although originally used for the evaluation of machine translations, the bilingual evaluation method (BLEU) has also been successfully used for the evaluation of paraphrase generation models.", "token2charspan": [[0, 8], [9, 19], [20, 24], [25, 28], [29, 32], [33, 43], [44, 46], [47, 54], [55, 67], [67, 68], [69, 72], [73, 82], [83, 93], [94, 100], [101, 102], [102, 106], [106, 107], [108, 111], [112, 116], [117, 121], [122, 134], [135, 139], [140, 143], [144, 147], [148, 158], [159, 161], [162, 172], [173, 183], [184, 190], [190, 191]]}
{"doc_key": "ai-test-272", "ner": [[0, 0, "organisation"], [6, 8, "organisation"], [10, 10, "organisation"], [14, 14, "product"], [15, 16, "country"], [18, 18, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 8, "role", "licenses_to", false, false], [0, 0, 10, 10, "role", "licenses_to", false, false], [6, 8, 15, 16, "physical", "", false, false], [10, 10, 18, 18, "physical", "", false, false], [14, 14, 6, 8, "artifact", "produces", false, false], [14, 14, 10, 10, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "later", "licensed", "its", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "which", "manufacture", "Unimates", "in", "Japan", "and", "England", "respectively", "."], "sentence-detokenized": "Unimation later licensed its technology to Kawasaki Heavy Industries and GKN, which manufacture Unimates in Japan and England respectively.", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 57], [58, 68], [69, 72], [73, 76], [76, 77], [78, 83], [84, 95], [96, 104], [105, 107], [108, 113], [114, 117], [118, 125], [126, 138], [138, 139]]}
{"doc_key": "ai-test-273", "ner": [[19, 20, "conference"], [37, 38, "field"], [56, 60, "field"], [62, 62, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[37, 38, 56, 60, "compare", "", false, false], [62, 62, 56, 60, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "confusion", "between", "these", "two", "research", "communities", "(", "which", "often", "have", "separate", "conferences", "and", "separate", "journals", ",", "ECML", "PKDD", "being", "a", "major", "exception", ")", "stems", "from", "the", "underlying", "assumptions", "with", "which", "they", "work", ":", "in", "machine", "learning", ",", "performance", "is", "usually", "judged", "in", "terms", "of", "the", "ability", "to", "reproduce", "known", "knowledge", ",", "whereas", "in", "knowledge", "discovery", "and", "data", "mining", "(", "KDD", ")", ",", "the", "focus", "is", "on", "discovering", "previously", "unknown", "knowledge", "."], "sentence-detokenized": "Much of the confusion between these two research communities (which often have separate conferences and separate journals, ECML PKDD being a major exception) stems from the underlying assumptions with which they work: in machine learning, performance is usually judged in terms of the ability to reproduce known knowledge, whereas in knowledge discovery and data mining (KDD), the focus is on discovering previously unknown knowledge.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 29], [30, 35], [36, 39], [40, 48], [49, 60], [61, 62], [62, 67], [68, 73], [74, 78], [79, 87], [88, 99], [100, 103], [104, 112], [113, 121], [121, 122], [123, 127], [128, 132], [133, 138], [139, 140], [141, 146], [147, 156], [156, 157], [158, 163], [164, 168], [169, 172], [173, 183], [184, 195], [196, 200], [201, 206], [207, 211], [212, 216], [216, 217], [218, 220], [221, 228], [229, 237], [237, 238], [239, 250], [251, 253], [254, 261], [262, 268], [269, 271], [272, 277], [278, 280], [281, 284], [285, 292], [293, 295], [296, 305], [306, 311], [312, 321], [321, 322], [323, 330], [331, 333], [334, 343], [344, 353], [354, 357], [358, 362], [363, 369], [370, 371], [371, 374], [374, 375], [375, 376], [377, 380], [381, 386], [387, 389], [390, 392], [393, 404], [405, 415], [416, 423], [424, 433], [433, 434]]}
{"doc_key": "ai-test-274", "ner": [[0, 1, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hidden", "Markov", "models", "are", "the", "basis", "of", "most", "modern", "automatic", "speech", "recognition", "systems", "."], "sentence-detokenized": "Hidden Markov models are the basis of most modern automatic speech recognition systems.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 28], [29, 34], [35, 37], [38, 42], [43, 49], [50, 59], [60, 66], [67, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-test-275", "ner": [[3, 4, "location"], [6, 6, "country"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 6, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": [",", "a", "company", "in", "Bangalore", ",", "India", ",", "specialising", "in", "online", "handwriting", "recognition", "software", "."], "sentence-detokenized": ", a company in Bangalore, India, specialising in online handwriting recognition software.", "token2charspan": [[0, 1], [2, 3], [4, 11], [12, 14], [15, 24], [24, 25], [26, 31], [31, 32], [33, 45], [46, 48], [49, 55], [56, 67], [68, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-276", "ner": [[22, 23, "misc"], [48, 48, "metrics"], [50, 52, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[48, 48, 50, 52, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Do", "the", "repeated", "translations", "in", "both", "languages", "match", "the", "same", "expression", "?", "I.e.", "does", "the", "translation", "method", "show", "stationarity", "or", "produce", "a", "canonical", "form", "?", "Does", "the", "translation", "become", "stationary", "without", "losing", "the", "original", "meaning", "?", "This", "metric", "has", "been", "criticised", "because", "it", "does", "not", "correlate", "well", "with", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "indicators", "."], "sentence-detokenized": "Do the repeated translations in both languages match the same expression? I.e. does the translation method show stationarity or produce a canonical form? Does the translation become stationary without losing the original meaning? This metric has been criticised because it does not correlate well with BLEU (BiLingual Evaluation Understudy) indicators.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 28], [29, 31], [32, 36], [37, 46], [47, 52], [53, 56], [57, 61], [62, 72], [72, 73], [74, 78], [79, 83], [84, 87], [88, 99], [100, 106], [107, 111], [112, 124], [125, 127], [128, 135], [136, 137], [138, 147], [148, 152], [152, 153], [154, 158], [159, 162], [163, 174], [175, 181], [182, 192], [193, 200], [201, 207], [208, 211], [212, 220], [221, 228], [228, 229], [230, 234], [235, 241], [242, 245], [246, 250], [251, 261], [262, 269], [270, 272], [273, 277], [278, 281], [282, 291], [292, 296], [297, 301], [302, 306], [307, 308], [308, 317], [318, 328], [329, 339], [339, 340], [341, 351], [351, 352]]}
{"doc_key": "ai-test-277", "ner": [[6, 10, "organisation"], [15, 22, "organisation"], [12, 14, "university"], [24, 25, "university"], [27, 29, "field"], [32, 36, "organisation"], [39, 41, "organisation"], [49, 52, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[15, 22, 12, 14, "part-of", "", false, false], [24, 25, 27, 29, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "is", "a", "Fellow", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", ",", "Stanford", "University", "'s", "Centre", "for", "Advanced", "Study", "in", "the", "Behavioural", "Sciences", ",", "MIT", "'s", "Centre", "for", "Cognitive", "Science", ",", "the", "Canadian", "Institute", "for", "Advanced", "Study", ",", "the", "Canadian", "Psychological", "Association", "and", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "in", "1998", "."], "sentence-detokenized": "He is a Fellow of the American Association for Artificial Intelligence, Stanford University's Centre for Advanced Study in the Behavioural Sciences, MIT's Centre for Cognitive Science, the Canadian Institute for Advanced Study, the Canadian Psychological Association and was elected a Fellow of the Royal Society of Canada in 1998.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 42], [43, 46], [47, 57], [58, 70], [70, 71], [72, 80], [81, 91], [91, 93], [94, 100], [101, 104], [105, 113], [114, 119], [120, 122], [123, 126], [127, 138], [139, 147], [147, 148], [149, 152], [152, 154], [155, 161], [162, 165], [166, 175], [176, 183], [183, 184], [185, 188], [189, 197], [198, 207], [208, 211], [212, 220], [221, 226], [226, 227], [228, 231], [232, 240], [241, 254], [255, 266], [267, 270], [271, 274], [275, 282], [283, 284], [285, 291], [292, 294], [295, 298], [299, 304], [305, 312], [313, 315], [316, 322], [323, 325], [326, 330], [330, 331]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [17, 20, "misc"], [22, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 17, 20, "part-of", "", false, false], [0, 0, 22, 23, "part-of", "", false, false], [4, 5, 17, 20, "part-of", "", false, false], [4, 5, 22, 23, "part-of", "", false, false], [7, 8, 17, 20, "part-of", "", false, false], [7, 8, 22, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "-", "along", "with", "Joshua", "Bengio", "and", "Jan", "Lekun", "-", "are", "considered", "by", "some", "to", "be", "the", "godfathers", "of", "artificial", "intelligence", "and", "deep", "learning", "."], "sentence-detokenized": "Hinton - along with Joshua Bengio and Jan Lekun - are considered by some to be the godfathers of artificial intelligence and deep learning.", "token2charspan": [[0, 6], [7, 8], [9, 14], [15, 19], [20, 26], [27, 33], [34, 37], [38, 41], [42, 47], [48, 49], [50, 53], [54, 64], [65, 67], [68, 72], [73, 75], [76, 78], [79, 82], [83, 93], [94, 96], [97, 107], [108, 120], [121, 124], [125, 129], [130, 138], [138, 139]]}
{"doc_key": "ai-test-279", "ner": [[6, 8, "product"], [19, 19, "misc"], [21, 22, "misc"], [23, 27, "product"], [25, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 19, 19, "related-to", "", false, false], [6, 8, 21, 22, "related-to", "", false, false], [19, 19, 23, 27, "named", "same", false, false], [25, 31, 23, 27, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "lightweight", "open", "source", "speech", "project", "eSpeak", ",", "which", "has", "its", "own", "approach", "to", "synthesis", ",", "has", "experimented", "with", "Mandarin", "and", "Cantonese", ".", "eSpeak", "used", "Google", "Translate", "from", "May", "2010", "to", "2010", "."], "sentence-detokenized": "The lightweight open source speech project eSpeak, which has its own approach to synthesis, has experimented with Mandarin and Cantonese. eSpeak used Google Translate from May 2010 to 2010.", "token2charspan": [[0, 3], [4, 15], [16, 20], [21, 27], [28, 34], [35, 42], [43, 49], [49, 50], [51, 56], [57, 60], [61, 64], [65, 68], [69, 77], [78, 80], [81, 90], [90, 91], [92, 95], [96, 108], [109, 113], [114, 122], [123, 126], [127, 136], [136, 137], [138, 144], [145, 149], [150, 156], [157, 166], [167, 171], [172, 175], [176, 180], [181, 183], [184, 188], [188, 189]]}
{"doc_key": "ai-test-280", "ner": [[6, 8, "product"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["1982", "also", "saw", "the", "release", "of", "Software", "Automatic", "Mouth", ",", "the", "first", "commercial", "fully", "software", "voice", "synthesis", "programme", "."], "sentence-detokenized": "1982 also saw the release of Software Automatic Mouth, the first commercial fully software voice synthesis programme.", "token2charspan": [[0, 4], [5, 9], [10, 13], [14, 17], [18, 25], [26, 28], [29, 37], [38, 47], [48, 53], [53, 54], [55, 58], [59, 64], [65, 75], [76, 81], [82, 90], [91, 96], [97, 106], [107, 116], [116, 117]]}
{"doc_key": "ai-test-281", "ner": [[4, 6, "metrics"], [8, 8, "metrics"], [11, 11, "metrics"], [13, 13, "metrics"], [16, 25, "metrics"], [27, 29, "metrics"], [31, 31, "metrics"], [34, 40, "metrics"], [44, 46, "metrics"], [48, 48, "metrics"], [51, 51, "metrics"], [53, 53, "metrics"], [56, 65, "metrics"], [67, 69, "metrics"], [71, 71, "metrics"], [74, 80, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[8, 8, 4, 6, "named", "", false, false], [11, 11, 4, 6, "named", "", false, false], [13, 13, 4, 6, "named", "", false, false], [16, 25, 4, 6, "named", "", false, false], [31, 31, 27, 29, "named", "", false, false], [34, 40, 27, 29, "named", "", false, false], [48, 48, 44, 46, "named", "", false, false], [51, 51, 44, 46, "named", "", false, false], [53, 53, 44, 46, "named", "", false, false], [56, 65, 44, 46, "named", "", false, false], [71, 71, 67, 69, "named", "", false, false], [74, 80, 67, 69, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["The", "column", "coefficients", "are", "TRUE", "Positive", "Rate", "(", "TPR", ",", "or", "sensitivity", "or", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "complemented", "by", "FALSE", "Negative", "Rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "and", "TRUE", "Negative", "Rate", "(", "TNR", ",", "or", "specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "complemented", "by", "FALSE", "Positive", "Rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "The column coefficients are TRUE Positive Rate (TPR, or sensitivity or recall) (TP / (TP + FN)), complemented by FALSE Negative Rate (FNR) (FN / (TP + FN)); and TRUE Negative Rate (TNR, or specificity, SPC) (TN / (TN + FP)), complemented by FALSE Positive Rate (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 3], [4, 10], [11, 23], [24, 27], [28, 32], [33, 41], [42, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 67], [68, 70], [71, 77], [77, 78], [79, 80], [80, 82], [83, 84], [85, 86], [86, 88], [89, 90], [91, 93], [93, 94], [94, 95], [95, 96], [97, 109], [110, 112], [113, 118], [119, 127], [128, 132], [133, 134], [134, 137], [137, 138], [139, 140], [140, 142], [143, 144], [145, 146], [146, 148], [149, 150], [151, 153], [153, 154], [154, 155], [155, 156], [157, 160], [161, 165], [166, 174], [175, 179], [180, 181], [181, 184], [184, 185], [186, 188], [189, 200], [200, 201], [202, 205], [205, 206], [207, 208], [208, 210], [211, 212], [213, 214], [214, 216], [217, 218], [219, 221], [221, 222], [222, 223], [223, 224], [225, 237], [238, 240], [241, 246], [247, 255], [256, 260], [261, 262], [262, 265], [265, 266], [267, 268], [268, 270], [271, 272], [273, 274], [274, 276], [277, 278], [279, 281], [281, 282], [282, 283], [283, 284]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 14, "role", "working_with", false, false], [2, 2, 14, 14, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "and", "Weber", "also", "collaborated", "on", "many", "other", "robots", ",", "and", "their", "experience", "with", "Kismet"], "sentence-detokenized": "Edsinger and Weber also collaborated on many other robots, and their experience with Kismet", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 36], [37, 39], [40, 44], [45, 50], [51, 57], [57, 58], [59, 62], [63, 68], [69, 79], [80, 84], [85, 91]]}
{"doc_key": "ai-test-283", "ner": [[0, 0, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 11, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["R", "functionality", "is", "also", "available", "from", "several", "scripting", "languages", "such", "as", "Python", "."], "sentence-detokenized": "R functionality is also available from several scripting languages such as Python.", "token2charspan": [[0, 1], [2, 15], [16, 18], [19, 23], [24, 33], [34, 38], [39, 46], [47, 56], [57, 66], [67, 71], [72, 74], [75, 81], [81, 82]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "was", "one", "of", "the", "first", "robot", "languages", "and", "was", "used", "in", "Unimate", "robots", "."], "sentence-detokenized": "VAL was one of the first robot languages and was used in Unimate robots.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 24], [25, 30], [31, 40], [41, 44], [45, 48], [49, 53], [54, 56], [57, 64], [65, 71], [71, 72]]}
{"doc_key": "ai-test-285", "ner": [[6, 14, "conference"], [16, 16, "conference"], [18, 19, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 14, 18, 19, "physical", "", false, false], [16, 16, 6, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["They", "first", "presented", "their", "database", "at", "the", "2009", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "in", "Florida", "."], "sentence-detokenized": "They first presented their database at the 2009 Conference on Computer Vision and Pattern Recognition (CVPR) in Florida.", "token2charspan": [[0, 4], [5, 10], [11, 20], [21, 26], [27, 35], [36, 38], [39, 42], [43, 47], [48, 58], [59, 61], [62, 70], [71, 77], [78, 81], [82, 89], [90, 101], [102, 103], [103, 107], [107, 108], [109, 111], [112, 119], [119, 120]]}
{"doc_key": "ai-test-286", "ner": [[0, 3, "misc"], [9, 10, "task"], [12, 13, "field"], [16, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 0, 3, "type-of", "", false, false], [12, 13, 0, 3, "type-of", "", false, false], [16, 16, 0, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Categorisation", "tasks", "that", "do", "not", "provide", "labels", "are", "called", "unsupervised", "classification", ",", "unsupervised", "learning", ",", "cluster", "analysis", "."], "sentence-detokenized": "Categorisation tasks that do not provide labels are called unsupervised classification, unsupervised learning, cluster analysis.", "token2charspan": [[0, 14], [15, 20], [21, 25], [26, 28], [29, 32], [33, 40], [41, 47], [48, 51], [52, 58], [59, 71], [72, 86], [86, 87], [88, 100], [101, 109], [109, 110], [111, 118], [119, 127], [127, 128]]}
{"doc_key": "ai-test-287", "ner": [[2, 3, "task"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "requires", "Object", "recognition", ",", "people", "recognition", "and", "location", ",", "and", "emotion", "recognition", "."], "sentence-detokenized": "This requires Object recognition, people recognition and location, and emotion recognition.", "token2charspan": [[0, 4], [5, 13], [14, 20], [21, 32], [32, 33], [34, 40], [41, 52], [53, 56], [57, 65], [65, 66], [67, 70], [71, 78], [79, 90], [90, 91]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [8, 8, "misc"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "process", "is", "complex", "and", "involves", "encoding", "and", "recall", "or", "retrieval", "."], "sentence-detokenized": "The process is complex and involves encoding and recall or retrieval.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 26], [27, 35], [36, 44], [45, 48], [49, 55], [56, 58], [59, 68], [68, 69]]}
{"doc_key": "ai-test-289", "ner": [[9, 10, "product"], [14, 15, "product"], [30, 32, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 14, 15, "named", "", false, false], [9, 10, 30, 32, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "also", "called", "parallel", "robots", "or", "generalised", "Stewart", "platforms", "(", "in", "a", "Stewart", "platform", ",", "actuators", "are", "paired", "on", "both", "the", "base", "and", "the", "platform", ")", ",", "are", "articulated", "robots", "that", "use", "similar", "mechanisms", "to", "move", "either", "the", "robot", "base", "or", "one", "or", "more", "manipulator", "arms", "."], "sentence-detokenized": "These systems, also called parallel robots or generalised Stewart platforms (in a Stewart platform, actuators are paired on both the base and the platform), are articulated robots that use similar mechanisms to move either the robot base or one or more manipulator arms.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 26], [27, 35], [36, 42], [43, 45], [46, 57], [58, 65], [66, 75], [76, 77], [77, 79], [80, 81], [82, 89], [90, 98], [98, 99], [100, 109], [110, 113], [114, 120], [121, 123], [124, 128], [129, 132], [133, 137], [138, 141], [142, 145], [146, 154], [154, 155], [155, 156], [157, 160], [161, 172], [173, 179], [180, 184], [185, 188], [189, 196], [197, 207], [208, 210], [211, 215], [216, 222], [223, 226], [227, 232], [233, 237], [238, 240], [241, 244], [245, 247], [248, 252], [253, 264], [265, 269], [269, 270]]}
{"doc_key": "ai-test-290", "ner": [[0, 1, "field"], [6, 7, "field"], [14, 17, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 7, "part-of", "subfield", false, false], [0, 1, 14, 17, "compare", "", false, false], [14, 17, 22, 23, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "vision", "as", "a", "discipline", "of", "systems", "engineering", "can", "be", "seen", "as", "distinct", "from", "computer", "vision", ",", "which", "is", "a", "type", "of", "computer", "science", "."], "sentence-detokenized": "Machine vision as a discipline of systems engineering can be seen as distinct from computer vision, which is a type of computer science.", "token2charspan": [[0, 7], [8, 14], [15, 17], [18, 19], [20, 30], [31, 33], [34, 41], [42, 53], [54, 57], [58, 60], [61, 65], [66, 68], [69, 77], [78, 82], [83, 91], [92, 98], [98, 99], [100, 105], [106, 108], [109, 110], [111, 115], [116, 118], [119, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-test-291", "ner": [[0, 2, "algorithm"], [8, 10, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "LSTM", "gate", "activation", "function", "is", "often", "a", "logical", "sigmoid", "function", "."], "sentence-detokenized": "The LSTM gate activation function is often a logical sigmoid function.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 24], [25, 33], [34, 36], [37, 42], [43, 44], [45, 52], [53, 60], [61, 69], [69, 70]]}
{"doc_key": "ai-test-292", "ner": [[5, 6, "metrics"], [18, 21, "metrics"], [23, 27, "metrics"], [31, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 18, 21, "named", "", false, false], [5, 6, 31, 33, "named", "", false, false], [23, 27, 18, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "(", "necessarily", "the", "only", ")", "efficient", "estimator", "and", "hence", "the", "minimum", "variance", "biased", "estimator", "(", "MVUE", ")", ",", "and", "it", "is", "also", "the", "maximum", "likelihood", "estimator", "."], "sentence-detokenized": "In other words, the sample mean is (necessarily the only) efficient estimator and hence the minimum variance biased estimator (MVUE), and it is also the maximum likelihood estimator.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 36], [36, 47], [48, 51], [52, 56], [56, 57], [58, 67], [68, 77], [78, 81], [82, 87], [88, 91], [92, 99], [100, 108], [109, 115], [116, 125], [126, 127], [127, 131], [131, 132], [132, 133], [134, 137], [138, 140], [141, 143], [144, 148], [149, 152], [153, 160], [161, 171], [172, 181], [181, 182]]}
{"doc_key": "ai-test-293", "ner": [[2, 2, "academicjournal"], [5, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [22, 22, "product"], [25, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 22, 22, "topic", "", false, false], [2, 2, 25, 26, "topic", "", false, false], [5, 8, 2, 2, "role", "", false, false], [10, 11, 2, 2, "role", "", false, false], [13, 14, 2, 2, "role", "", false, false], [22, 22, 25, 26, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["A", "2001", "Scientific", "American", "article", "by", "Berners", "-", "Lee", ",", "James", "Hendler", "and", "Ora", "Lassila", "described", "the", "imminent", "evolution", "of", "the", "current", "web", "to", "the", "Semantic", "Web", "."], "sentence-detokenized": "A 2001 Scientific American article by Berners-Lee, James Hendler and Ora Lassila described the imminent evolution of the current web to the Semantic Web.", "token2charspan": [[0, 1], [2, 6], [7, 17], [18, 26], [27, 34], [35, 37], [38, 45], [45, 46], [46, 49], [49, 50], [51, 56], [57, 64], [65, 68], [69, 72], [73, 80], [81, 90], [91, 94], [95, 103], [104, 113], [114, 116], [117, 120], [121, 128], [129, 132], [133, 135], [136, 139], [140, 148], [149, 152], [152, 153]]}
{"doc_key": "ai-test-294", "ner": [[0, 1, "misc"], [14, 15, "person"], [17, 19, "person"], [27, 27, "person"], [38, 38, "person"], [45, 46, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 15, 0, 1, "role", "actor_in_work", false, false], [17, 19, 14, 15, "named", "", false, false], [17, 19, 14, 15, "origin", "", false, false], [27, 27, 17, 19, "part-of", "", false, false], [45, 46, 17, 19, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Blade", "Runner", "used", "a", "number", "of", "lesser", "-", "known", "actors", "at", "the", "time", ":", "Sean", "Young", "plays", "Rachel", ",", "an", "experimental", "replicant", "implanted", "with", "the", "memories", "of", "Tyrell", "'s", "niece", ",", "making", "her", "think", "she", "is", "human", ";", "Sammon", ",", "pp.", "92", "-", "93", ",", "Nina", "Axelrod", "auditioned", "for", "the", "role", "."], "sentence-detokenized": "Blade Runner used a number of lesser-known actors at the time: Sean Young plays Rachel, an experimental replicant implanted with the memories of Tyrell's niece, making her think she is human; Sammon, pp. 92-93, Nina Axelrod auditioned for the role.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 19], [20, 26], [27, 29], [30, 36], [36, 37], [37, 42], [43, 49], [50, 52], [53, 56], [57, 61], [61, 62], [63, 67], [68, 73], [74, 79], [80, 86], [86, 87], [88, 90], [91, 103], [104, 113], [114, 123], [124, 128], [129, 132], [133, 141], [142, 144], [145, 151], [151, 153], [154, 159], [159, 160], [161, 167], [168, 171], [172, 177], [178, 181], [182, 184], [185, 190], [190, 191], [192, 198], [198, 199], [200, 203], [204, 206], [206, 207], [207, 209], [209, 210], [211, 215], [216, 223], [224, 234], [235, 238], [239, 242], [243, 247], [247, 248]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [13, 17, "university"], [23, 25, "product"], [27, 27, "product"], [33, 47, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 13, 17, "physical", "", false, false], [3, 4, 13, 17, "physical", "", false, false], [6, 7, 13, 17, "physical", "", false, false], [9, 10, 13, 17, "physical", "", false, false], [13, 17, 33, 47, "physical", "", true, false], [23, 25, 13, 17, "temporal", "", false, false], [27, 27, 13, 17, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "and", "Terry", "Winograd", "visited", "the", "University", "of", "Edinburgh", "in", "1971", ",", "spreading", "the", "word", "about", "Micro", "-", "Planner", "and", "SHRDLU", "and", "calling", "into", "question", "the", "Edinburgh", "Logicians", "'", "single", "proof", "procedure", "approach", ",", "which", "was", "the", "mainstay", "of", "the", "Edinburgh", "Logicians", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited the University of Edinburgh in 1971, spreading the word about Micro-Planner and SHRDLU and calling into question the Edinburgh Logicians' single proof procedure approach, which was the mainstay of the Edinburgh Logicians.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 56], [57, 65], [66, 73], [74, 77], [78, 88], [89, 91], [92, 101], [102, 104], [105, 109], [109, 110], [111, 120], [121, 124], [125, 129], [130, 135], [136, 141], [141, 142], [142, 149], [150, 153], [154, 160], [161, 164], [165, 172], [173, 177], [178, 186], [187, 190], [191, 200], [201, 210], [210, 211], [212, 218], [219, 224], [225, 234], [235, 243], [243, 244], [245, 250], [251, 254], [255, 258], [259, 267], [268, 270], [271, 274], [275, 284], [285, 294], [294, 295]]}
{"doc_key": "ai-test-296", "ner": [[0, 1, "researcher"], [7, 7, "field"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 11, 12, "role", "inspires", false, false], [0, 1, 14, 15, "role", "inspires", false, false], [0, 1, 17, 18, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Walter", "'s", "work", "inspired", "future", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Morawetz", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work inspired future generations of robotics researchers such as Rodney Brooks, Hans Morawetz and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 22], [23, 29], [30, 41], [42, 44], [45, 53], [54, 65], [66, 70], [71, 73], [74, 80], [81, 87], [87, 88], [89, 93], [94, 102], [103, 106], [107, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-test-297", "ner": [[7, 7, "algorithm"], [10, 11, "researcher"], [18, 24, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 10, 11, "origin", "", false, false], [7, 7, 18, 24, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Subsequently", ",", "a", "similar", "GPU", "-", "based", "CNN", "developed", "by", "Alex", "Krizhevsky", "et", "al", ".", "won", "the", "2012", "ImageNet", "Large", "-", "Scale", "Visual", "Recognition", "Competition", "."], "sentence-detokenized": "Subsequently, a similar GPU-based CNN developed by Alex Krizhevsky et al. won the 2012 ImageNet Large-Scale Visual Recognition Competition.", "token2charspan": [[0, 12], [12, 13], [14, 15], [16, 23], [24, 27], [27, 28], [28, 33], [34, 37], [38, 47], [48, 50], [51, 55], [56, 66], [67, 69], [70, 72], [72, 73], [74, 77], [78, 81], [82, 86], [87, 95], [96, 101], [101, 102], [102, 107], [108, 114], [115, 126], [127, 138], [138, 139]]}
{"doc_key": "ai-test-298", "ner": [[2, 3, "misc"], [8, 9, "metrics"], [12, 13, "metrics"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 2, 3, "type-of", "", false, false], [12, 13, 2, 3, "type-of", "", false, false], [12, 13, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Commonly", "used", "loss", "functions", "for", "probabilistic", "classification", "include", "logarithmic", "loss", "and", "the", "Brier", "score", "between", "the", "expected", "and", "true", "probability", "distribution", "."], "sentence-detokenized": "Commonly used loss functions for probabilistic classification include logarithmic loss and the Brier score between the expected and true probability distribution.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 28], [29, 32], [33, 46], [47, 61], [62, 69], [70, 81], [82, 86], [87, 90], [91, 94], [95, 100], [101, 106], [107, 114], [115, 118], [119, 127], [128, 131], [132, 136], [137, 148], [149, 161], [161, 162]]}
{"doc_key": "ai-test-299", "ner": [[4, 4, "organisation"], [13, 13, "field"], [8, 8, "organisation"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 13, 13, "general-affiliation", "field_of_study", false, false], [4, 4, 17, 18, "part-of", "", false, false], [8, 8, 4, 4, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "May", "2016", ",", "NtechLab", "was", "accepted", "by", "NIST", "for", "official", "testing", "of", "biometric", "technologies", "among", "three", "Russian", "companies", "."], "sentence-detokenized": "In May 2016, NtechLab was accepted by NIST for official testing of biometric technologies among three Russian companies.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [22, 25], [26, 34], [35, 37], [38, 42], [43, 46], [47, 55], [56, 63], [64, 66], [67, 76], [77, 89], [90, 95], [96, 101], [102, 109], [110, 119], [119, 120]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "floating", "-", "point", "numbers", "only", "have", "a", "certain", "mathematical", "precision", "."], "sentence-detokenized": "However, floating-point numbers only have a certain mathematical precision.", "token2charspan": [[0, 7], [7, 8], [9, 17], [17, 18], [18, 23], [24, 31], [32, 36], [37, 41], [42, 43], [44, 51], [52, 64], [65, 74], [74, 75]]}
{"doc_key": "ai-test-301", "ner": [[4, 4, "organisation"], [12, 16, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 12, 16, "role", "contributes_to", false, false], [18, 18, 12, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2015", ",", "many", "SenseTime", "papers", "were", "accepted", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "In 2015, many SenseTime papers were accepted at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 13], [14, 23], [24, 30], [31, 35], [36, 44], [45, 47], [48, 51], [52, 62], [63, 65], [66, 74], [75, 81], [82, 85], [86, 93], [94, 105], [106, 107], [107, 111], [111, 112], [112, 113]]}
{"doc_key": "ai-test-302", "ner": [[10, 14, "task"], [16, 16, "task"], [18, 19, "task"], [21, 24, "task"], [26, 26, "field"], [30, 32, "misc"], [33, 86, "conference"], [50, 52, "misc"], [53, 60, "conference"], [74, 76, "misc"], [87, 89, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[10, 14, 26, 26, "part-of", "task_part_of_field", false, false], [16, 16, 10, 14, "named", "", false, false], [18, 19, 26, 26, "part-of", "task_part_of_field", false, false], [21, 24, 18, 19, "named", "", false, false], [30, 32, 33, 86, "temporal", "", false, false], [50, 52, 53, 60, "temporal", "", false, false], [74, 76, 87, 89, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["He", "is", "one", "of", "the", "authors", "of", "optimal", "algorithms", "for", "structure", "-", "from", "-", "motion", "(", "SFM", "or", "visual", "SLAM", ",", "simultaneous", "localisation", "and", "mapping", ",", "Robotics", ";", "1998", ".", "Best", "Paper", "Award", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "in", "2015", ")", ",", "characterized", "its", "ambiguities", "(", "David", "Marr", "Award", "at", "the", "ICCV", "in", "1999", ")", ",", "and", "described", "the", "identifiability", "and", "observability", "of", "fusion", "of", "visual", "and", "inertial", "sensors", "(", "Best", "Paper", "Award", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "in", "Robotics", "in", "2015", ")", "."], "sentence-detokenized": "He is one of the authors of optimal algorithms for structure-from-motion (SFM or visual SLAM, simultaneous localisation and mapping, Robotics; 1998. Best Paper Award at the Conference on Computer Vision and Pattern Recognition in 2015), characterized its ambiguities (David Marr Award at the ICCV in 1999), and described the identifiability and observability of fusion of visual and inertial sensors (Best Paper Award at the Conference on Computer Vision and Pattern Recognition in Robotics in 2015).", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 12], [13, 16], [17, 24], [25, 27], [28, 35], [36, 46], [47, 50], [51, 60], [60, 61], [61, 65], [65, 66], [66, 72], [73, 74], [74, 77], [78, 80], [81, 87], [88, 92], [92, 93], [94, 106], [107, 119], [120, 123], [124, 131], [131, 132], [133, 141], [141, 142], [143, 147], [147, 148], [149, 153], [154, 159], [160, 165], [166, 168], [169, 172], [173, 183], [184, 186], [187, 195], [196, 202], [203, 206], [207, 214], [215, 226], [227, 229], [230, 234], [234, 235], [235, 236], [237, 250], [251, 254], [255, 266], [267, 268], [268, 273], [274, 278], [279, 284], [285, 287], [288, 291], [292, 296], [297, 299], [300, 304], [304, 305], [305, 306], [307, 310], [311, 320], [321, 324], [325, 340], [341, 344], [345, 358], [359, 361], [362, 368], [369, 371], [372, 378], [379, 382], [383, 391], [392, 399], [400, 401], [401, 405], [406, 411], [412, 417], [418, 420], [421, 424], [425, 435], [436, 438], [439, 447], [448, 454], [455, 458], [459, 466], [467, 478], [479, 481], [482, 490], [491, 493], [494, 498], [498, 499], [499, 500]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 1, "task"], [6, 8, "field"], [10, 11, "field"], [13, 14, "field"], [22, 23, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 6, 8, "part-of", "task_part_of_field", false, false], [0, 1, 10, 11, "part-of", "task_part_of_field", false, false], [0, 1, 13, 14, "part-of", "task_part_of_field", false, false], [0, 1, 22, 23, "part-of", "", false, false], [0, 1, 25, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "a", "fundamental", "tool", "in", "image", "processing", ",", "machine", "vision", "and", "computer", "vision", ",", "in", "particular", "in", "the", "field", "of", "feature", "detection", "and", "feature", "extraction", "."], "sentence-detokenized": "Edge detection is a fundamental tool in image processing, machine vision and computer vision, in particular in the field of feature detection and feature extraction.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 19], [20, 31], [32, 36], [37, 39], [40, 45], [46, 56], [56, 57], [58, 65], [66, 72], [73, 76], [77, 85], [86, 92], [92, 93], [94, 96], [97, 107], [108, 110], [111, 114], [115, 120], [121, 123], [124, 131], [132, 141], [142, 145], [146, 153], [154, 164], [164, 165]]}
{"doc_key": "ai-test-305", "ner": [[7, 8, "misc"], [21, 22, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "example", "is", "a", "variable", "such", "as", "outdoor", "temperature", "(", "mathtemp", "/", "math", ")", ",", "which", "can", "be", "recorded", "to", "several", "decimal", "places", "(", "depending", "on", "the", "sensor", ")", "in", "a", "given", "application", "."], "sentence-detokenized": "An example is a variable such as outdoor temperature (mathtemp / math), which can be recorded to several decimal places (depending on the sensor) in a given application.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 29], [30, 32], [33, 40], [41, 52], [53, 54], [54, 62], [63, 64], [65, 69], [69, 70], [70, 71], [72, 77], [78, 81], [82, 84], [85, 93], [94, 96], [97, 104], [105, 112], [113, 119], [120, 121], [121, 130], [131, 133], [134, 137], [138, 144], [144, 145], [146, 148], [149, 150], [151, 156], [157, 168], [168, 169]]}
{"doc_key": "ai-test-306", "ner": [[1, 2, "person"], [4, 5, "person"], [7, 13, "person"], [18, 19, "person"], [21, 21, "misc"], [25, 25, "misc"], [27, 28, "person"], [30, 30, "organisation"], [37, 38, "person"], [40, 40, "organisation"], [42, 42, "person"], [45, 45, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[27, 28, 21, 21, "part-of", "", false, false], [27, 28, 25, 25, "role", "", false, false], [37, 38, 30, 30, "role", "", false, false], [42, 42, 40, 40, "role", "youtuber", false, false], [45, 45, 42, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Judges", "Von", "Davis", ",", "Jessica", "Chobot", "and", "Leland", "Melvin", "return", ",", "as", "well", "as", "celebrity", "guests", "-", "actor", "Clark", "Gregg", ",", "MythBusters", "host", "and", "former", "Battlebots", "builder", "Adam", "Savage", ",", "NFL", "play", "-", "by", "-", "play", "announcer", "Vernon", "Davis", "and", "YouTube", "star", "Michael", "Stevens", "aka", "Vsauce", "."], "sentence-detokenized": "Judges Von Davis, Jessica Chobot and Leland Melvin return, as well as celebrity guests - actor Clark Gregg, MythBusters host and former Battlebots builder Adam Savage, NFL play-by-play announcer Vernon Davis and YouTube star Michael Stevens aka Vsauce.", "token2charspan": [[0, 6], [7, 10], [11, 16], [16, 17], [18, 25], [26, 32], [33, 36], [37, 43], [44, 50], [51, 57], [57, 58], [59, 61], [62, 66], [67, 69], [70, 79], [80, 86], [87, 88], [89, 94], [95, 100], [101, 106], [106, 107], [108, 119], [120, 124], [125, 128], [129, 135], [136, 146], [147, 154], [155, 159], [160, 166], [166, 167], [168, 171], [172, 176], [176, 177], [177, 179], [179, 180], [180, 184], [185, 194], [195, 201], [202, 207], [208, 211], [212, 219], [220, 224], [225, 232], [233, 240], [241, 244], [245, 251], [251, 252]]}
{"doc_key": "ai-test-307", "ner": [[8, 9, "algorithm"], [10, 14, "algorithm"], [16, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 16, 18, "part-of", "", false, false], [10, 14, 16, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "these", "methods", "have", "never", "beaten", "the", "Gaussian", "Mixture", "Model", "/", "Hidden", "Markov", "Models", "(", "GMM", "-", "HMM", ")", "technology", "of", "unequal", "inner", "processing", "based", "on", "discriminatively", "trained", "generative", "speech", "models", "."], "sentence-detokenized": "However, these methods have never beaten the Gaussian Mixture Model/Hidden Markov Models (GMM-HMM) technology of unequal inner processing based on discriminatively trained generative speech models.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 22], [23, 27], [28, 33], [34, 40], [41, 44], [45, 53], [54, 61], [62, 67], [67, 68], [68, 74], [75, 81], [82, 88], [89, 90], [90, 93], [93, 94], [94, 97], [97, 98], [99, 109], [110, 112], [113, 120], [121, 126], [127, 137], [138, 143], [144, 146], [147, 163], [164, 171], [172, 182], [183, 189], [190, 196], [196, 197]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "and", "SciPy", "provide", "convenient", "ways", "to", "use", "these", "different", "methods", "."], "sentence-detokenized": "Software packages such as MATLAB, GNU Octave, Scilab and SciPy provide convenient ways to use these different methods.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [53, 56], [57, 62], [63, 70], [71, 81], [82, 86], [87, 89], [90, 93], [94, 99], [100, 109], [110, 117], [117, 118]]}
{"doc_key": "ai-test-309", "ner": [[5, 7, "algorithm"], [9, 9, "algorithm"], [0, 2, "task"], [18, 19, "researcher"], [21, 22, "university"], [24, 25, "researcher"], [27, 30, "organisation"], [32, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[5, 7, 0, 2, "related-to", "", false, false], [5, 7, 18, 19, "origin", "", false, false], [5, 7, 24, 25, "origin", "", false, false], [9, 9, 5, 7, "named", "", false, false], [18, 19, 21, 22, "physical", "", false, false], [18, 19, 21, 22, "role", "", false, false], [24, 25, 27, 30, "physical", "", false, false], [24, 25, 27, 30, "role", "", false, false], [32, 32, 27, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["A", "speech", "processing", "algorithm", ",", "Linear", "Predicative", "Coding", "(", "LPC", ")", ",", "was", "first", "proposed", "in", "1966", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "."], "sentence-detokenized": "A speech processing algorithm, Linear Predicative Coding (LPC), was first proposed in 1966 by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT).", "token2charspan": [[0, 1], [2, 8], [9, 19], [20, 29], [29, 30], [31, 37], [38, 49], [50, 56], [57, 58], [58, 61], [61, 62], [62, 63], [64, 67], [68, 73], [74, 82], [83, 85], [86, 90], [91, 93], [94, 102], [103, 110], [111, 113], [114, 120], [121, 131], [132, 135], [136, 141], [142, 147], [148, 150], [151, 157], [158, 167], [168, 171], [172, 181], [182, 183], [183, 186], [186, 187], [187, 188]]}
{"doc_key": "ai-test-310", "ner": [[18, 25, "conference"], [27, 29, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[27, 29, 18, 25, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2006", ",", "to", "celebrate", "the", "25th", "anniversary", "of", "the", "algorithm", ",", "a", "workshop", "was", "organised", "at", "the", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "to", "summarise", "recent", "contributions", "and", "variations", "of", "the", "original", "algorithm", ",", "mainly", "designed", "to", "improve", "the", "speed", "of", "the", "algorithm", ",", "the", "robustness", "and", "accuracy", "of", "the", "estimated", "solution", "and", "to", "reduce", "dependence", "on", "user", "-", "defined", "constants", "."], "sentence-detokenized": "In 2006, to celebrate the 25th anniversary of the algorithm, a workshop was organised at the International Conference on Computer Vision and Pattern Recognition (CVPR) to summarise recent contributions and variations of the original algorithm, mainly designed to improve the speed of the algorithm, the robustness and accuracy of the estimated solution and to reduce dependence on user-defined constants.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 21], [22, 25], [26, 30], [31, 42], [43, 45], [46, 49], [50, 59], [59, 60], [61, 62], [63, 71], [72, 75], [76, 85], [86, 88], [89, 92], [93, 106], [107, 117], [118, 120], [121, 129], [130, 136], [137, 140], [141, 148], [149, 160], [161, 162], [162, 166], [166, 167], [168, 170], [171, 180], [181, 187], [188, 201], [202, 205], [206, 216], [217, 219], [220, 223], [224, 232], [233, 242], [242, 243], [244, 250], [251, 259], [260, 262], [263, 270], [271, 274], [275, 280], [281, 283], [284, 287], [288, 297], [297, 298], [299, 302], [303, 313], [314, 317], [318, 326], [327, 329], [330, 333], [334, 343], [344, 352], [353, 356], [357, 359], [360, 366], [367, 377], [378, 380], [381, 385], [385, 386], [386, 393], [394, 403], [403, 404]]}
{"doc_key": "ai-test-311", "ner": [[4, 6, "university"], [9, 12, "organisation"], [14, 18, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Members", "travelled", "to", "the", "University", "of", "Debrecen", ",", "the", "Hungarian", "Academy", "of", "Sciences", ",", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "University", ",", "etc", "."], "sentence-detokenized": "Members travelled to the University of Debrecen, the Hungarian Academy of Sciences, E\u00f6tv\u00f6s Lor\u00e1nd University, etc.", "token2charspan": [[0, 7], [8, 17], [18, 20], [21, 24], [25, 35], [36, 38], [39, 47], [47, 48], [49, 52], [53, 62], [63, 70], [71, 73], [74, 82], [82, 83], [84, 90], [91, 97], [98, 108], [108, 109], [110, 113], [113, 114]]}
{"doc_key": "ai-test-312", "ner": [[3, 3, "algorithm"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 17, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "extend", "the", "SVM", "to", "cases", "where", "the", "data", "are", "not", "linearly", "separable", ",", "we", "introduce", "a", "loss", "function", ","], "sentence-detokenized": "To extend the SVM to cases where the data are not linearly separable, we introduce a loss function,", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 17], [18, 20], [21, 26], [27, 32], [33, 36], [37, 41], [42, 45], [46, 49], [50, 58], [59, 68], [68, 69], [70, 72], [73, 82], [83, 84], [85, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-313", "ner": [[0, 0, "programlang"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 10, 11, "origin", "", false, false], [0, 0, 13, 14, "origin", "", false, false], [0, 0, 16, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "is", "an", "educational", "programming", "language", "developed", "in", "1967", "by", "Wally", "Feurzeig", ",", "Seymour", "Papert", "and", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo is an educational programming language developed in 1967 by Wally Feurzeig, Seymour Papert and Cynthia Solomon.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 34], [35, 43], [44, 53], [54, 56], [57, 61], [62, 64], [65, 70], [71, 79], [79, 80], [81, 88], [89, 95], [96, 99], [100, 107], [108, 115], [115, 116]]}
{"doc_key": "ai-test-314", "ner": [[0, 3, "organisation"], [5, 10, "organisation"], [11, 15, "location"], [17, 17, "location"], [19, 19, "location"], [23, 31, "product"], [32, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 5, 10, "role", "works_for", false, false], [5, 10, 11, 15, "physical", "", false, false], [11, 15, 17, 17, "physical", "", false, false], [17, 17, 19, 19, "physical", "", false, false], [23, 31, 0, 3, "origin", "", false, false], [32, 40, 23, 31, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "Eyring", "Research", "Institute", "helped", "the", "US", "Air", "Force", "Missile", "Directorate", "at", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", ",", "develop", "the", "intelligent", "systems", "technology", "software", "that", "was", "the", "basis", "for", "Reagan", "'s", "later", "-", "named", "Star", "Wars", "programme", "in", "top", "military", "secrecy", "."], "sentence-detokenized": "The Eyring Research Institute helped the US Air Force Missile Directorate at Hill Air Force Base near Ogden, Utah, develop the intelligent systems technology software that was the basis for Reagan's later-named Star Wars programme in top military secrecy.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 29], [30, 36], [37, 40], [41, 43], [44, 47], [48, 53], [54, 61], [62, 73], [74, 76], [77, 81], [82, 85], [86, 91], [92, 96], [97, 101], [102, 107], [107, 108], [109, 113], [113, 114], [115, 122], [123, 126], [127, 138], [139, 146], [147, 157], [158, 166], [167, 171], [172, 175], [176, 179], [180, 185], [186, 189], [190, 196], [196, 198], [199, 204], [204, 205], [205, 210], [211, 215], [216, 220], [221, 230], [231, 233], [234, 237], [238, 246], [247, 254], [254, 255]]}
{"doc_key": "ai-test-315", "ner": [[12, 13, "field"], [24, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "several", "decades", "he", "has", "been", "researching", "and", "developing", "new", "areas", "of", "computer", "science", ",", "ranging", "from", "compiler", ",", "programming", "language", "and", "system", "architecture", "John", "F", ".", "Sowa", "and", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "For several decades he has been researching and developing new areas of computer science, ranging from compiler, programming language and system architecture John F. Sowa and John Zachman (1992).", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 22], [23, 26], [27, 31], [32, 43], [44, 47], [48, 58], [59, 62], [63, 68], [69, 71], [72, 80], [81, 88], [88, 89], [90, 97], [98, 102], [103, 111], [111, 112], [113, 124], [125, 133], [134, 137], [138, 144], [145, 157], [158, 162], [163, 164], [164, 165], [166, 170], [171, 174], [175, 179], [180, 187], [188, 189], [189, 193], [193, 194], [194, 195]]}
{"doc_key": "ai-test-316", "ner": [[0, 2, "algorithm"], [7, 10, "algorithm"], [12, 15, "algorithm"], [18, 19, "field"], [21, 22, "field"], [26, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 10, 0, 2, "named", "", false, false], [12, 15, 0, 2, "named", "", false, false], [18, 19, 0, 2, "usage", "", false, false], [21, 22, 0, 2, "usage", "", false, false], [26, 30, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Sobel", "operator", ",", "sometimes", "called", "the", "Sobel", "-", "Feldman", "operator", "or", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "particularly", "in", "edge", "detection", "algorithms", ",", "where", "it", "produces", "an", "image", "with", "emphasised", "edges", "."], "sentence-detokenized": "The Sobel operator, sometimes called the Sobel-Feldman operator or Sobel filter, is used in image processing and computer vision, particularly in edge detection algorithms, where it produces an image with emphasised edges.", "token2charspan": [[0, 3], [4, 9], [10, 18], [18, 19], [20, 29], [30, 36], [37, 40], [41, 46], [46, 47], [47, 54], [55, 63], [64, 66], [67, 72], [73, 79], [79, 80], [81, 83], [84, 88], [89, 91], [92, 97], [98, 108], [109, 112], [113, 121], [122, 128], [128, 129], [130, 142], [143, 145], [146, 150], [151, 160], [161, 171], [171, 172], [173, 178], [179, 181], [182, 190], [191, 193], [194, 199], [200, 204], [205, 215], [216, 221], [221, 222]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [3, 4, "field"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 4, "compare", "", false, false], [0, 0, 3, 4, "type-of", "", false, false], [0, 0, 12, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "is", "a", "supervised", "learning", "algorithm", "that", "uses", "data", "labels", ",", "while", "PCA", "is", "a", "learning", "algorithm", "that", "ignores", "labels", "."], "sentence-detokenized": "LDA is a supervised learning algorithm that uses data labels, while PCA is a learning algorithm that ignores labels.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 19], [20, 28], [29, 38], [39, 43], [44, 48], [49, 53], [54, 60], [60, 61], [62, 67], [68, 71], [72, 74], [75, 76], [77, 85], [86, 95], [96, 100], [101, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "linear", "classification", "algorithms", "include", "Winnow", ",", "support", "vector", "machine", "and", "statistical", "regression", "."], "sentence-detokenized": "Other linear classification algorithms include Winnow, support vector machine and statistical regression.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 38], [39, 46], [47, 53], [53, 54], [55, 62], [63, 69], [70, 77], [78, 81], [82, 93], [94, 104], [104, 105]]}
{"doc_key": "ai-test-319", "ner": [[0, 4, "product"], [5, 6, "programlang"], [17, 19, "product"], [21, 21, "programlang"], [23, 23, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 5, 6, "general-affiliation", "", true, false], [0, 4, 17, 19, "general-affiliation", "", true, false], [0, 4, 21, 21, "general-affiliation", "", true, false], [0, 4, 23, 23, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "VTK", "consists", "of", "a", "C", "++", "class", "library", "and", "several", "layers", "of", "interpreted", "interfaces", ",", "including", "Tcl", "/", "Tk", ",", "Java", "and", "Python", "."], "sentence-detokenized": "The VTK consists of a C++ class library and several layers of interpreted interfaces, including Tcl/Tk, Java and Python.", "token2charspan": [[0, 3], [4, 7], [8, 16], [17, 19], [20, 21], [22, 23], [23, 25], [26, 31], [32, 39], [40, 43], [44, 51], [52, 58], [59, 61], [62, 73], [74, 84], [84, 85], [86, 95], [96, 99], [99, 100], [100, 102], [102, 103], [104, 108], [109, 112], [113, 119], [119, 120]]}
{"doc_key": "ai-test-320", "ner": [[7, 10, "task"], [16, 18, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Text", "produced", "by", "processing", "spontaneous", "speech", "using", "automatic", "speech", "recognition", "and", "printed", "or", "handwritten", "text", "using", "optical", "character", "recognition", "also", "contain", "processing", "noise", "."], "sentence-detokenized": "Text produced by processing spontaneous speech using automatic speech recognition and printed or handwritten text using optical character recognition also contain processing noise.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 27], [28, 39], [40, 46], [47, 52], [53, 62], [63, 69], [70, 81], [82, 85], [86, 93], [94, 96], [97, 108], [109, 113], [114, 119], [120, 127], [128, 137], [138, 149], [150, 154], [155, 162], [163, 173], [174, 179], [179, 180]]}
{"doc_key": "ai-test-321", "ner": [[0, 0, "researcher"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 9, 9, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "wrote", "several", "books", "and", "led", "the", "development", "of", "WordNet", ",", "an", "online", "database", "of", "word", "links", "that", "can", "be", "used", "with", "computer", "programs", "."], "sentence-detokenized": "Miller wrote several books and led the development of WordNet, an online database of word links that can be used with computer programs.", "token2charspan": [[0, 6], [7, 12], [13, 20], [21, 26], [27, 30], [31, 34], [35, 38], [39, 50], [51, 53], [54, 61], [61, 62], [63, 65], [66, 72], [73, 81], [82, 84], [85, 89], [90, 95], [96, 100], [101, 104], [105, 107], [108, 112], [113, 117], [118, 126], [127, 135], [135, 136]]}
{"doc_key": "ai-test-322", "ner": [[1, 1, "field"], [5, 7, "organisation"], [8, 11, "country"], [13, 14, "person"], [16, 18, "person"], [20, 21, "person"], [23, 24, "person"], [25, 28, "country"], [30, 33, "location"], [34, 38, "misc"], [35, 37, "person"], [40, 41, "person"], [43, 43, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[5, 7, 8, 11, "physical", "", false, false], [13, 14, 25, 28, "physical", "", false, false], [16, 18, 25, 28, "physical", "", false, false], [20, 21, 25, 28, "physical", "", false, false], [23, 24, 25, 28, "physical", "", false, false], [30, 33, 1, 1, "general-affiliation", "", false, false], [30, 33, 35, 37, "artifact", "", false, false], [34, 38, 35, 37, "named", "", false, false], [40, 41, 43, 43, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Contemporary", "automata", "are", "represented", "by", "Cabaret", "Mechanical", "Theatre", "in", "the", "United", "Kingdom", ",", "Dug", "North", "and", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "in", "the", "United", "States", ",", "Le", "D\u00e9fenseur", "du", "Temps", "by", "Jacques", "Monestier", "in", "France", "and", "Fran\u00e7ois", "Junod", "in", "Switzerland", "."], "sentence-detokenized": "Contemporary automata are represented by Cabaret Mechanical Theatre in the United Kingdom, Dug North and Chomick + Meder, Arthur Ganson, Joe Jones in the United States, Le D\u00e9fenseur du Temps by Jacques Monestier in France and Fran\u00e7ois Junod in Switzerland.", "token2charspan": [[0, 12], [13, 21], [22, 25], [26, 37], [38, 40], [41, 48], [49, 59], [60, 67], [68, 70], [71, 74], [75, 81], [82, 89], [89, 90], [91, 94], [95, 100], [101, 104], [105, 112], [113, 114], [115, 120], [120, 121], [122, 128], [129, 135], [135, 136], [137, 140], [141, 146], [147, 149], [150, 153], [154, 160], [161, 167], [167, 168], [169, 171], [172, 181], [182, 184], [185, 190], [191, 193], [194, 201], [202, 211], [212, 214], [215, 221], [222, 225], [226, 234], [235, 240], [241, 243], [244, 255], [255, 256]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 21, 21, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "has", "standard", "codefor", "/", "code", "and", "codewhile", "/", "code", "loops", ",", "but", "(", "as", "in", "other", "similar", "applications", "such", "as", "R", ")", "vectorised", "notation", "is", "recommended", "and", "is", "often", "faster", "to", "execute", "."], "sentence-detokenized": "MATLAB has standard codefor/code and codewhile/code loops, but (as in other similar applications such as R) vectorised notation is recommended and is often faster to execute.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 27], [27, 28], [28, 32], [33, 36], [37, 46], [46, 47], [47, 51], [52, 57], [57, 58], [59, 62], [63, 64], [64, 66], [67, 69], [70, 75], [76, 83], [84, 96], [97, 101], [102, 104], [105, 106], [106, 107], [108, 118], [119, 127], [128, 130], [131, 142], [143, 146], [147, 149], [150, 155], [156, 162], [163, 165], [166, 173], [173, 174]]}
{"doc_key": "ai-test-324", "ner": [[3, 3, "researcher"], [8, 12, "conference"], [17, 19, "field"], [22, 28, "misc"], [31, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 22, 28, "win-defeat", "", false, false], [3, 3, 31, 40, "win-defeat", "", false, false], [22, 28, 8, 12, "temporal", "", false, false], [22, 28, 17, 19, "topic", "", false, false], [31, 40, 8, 12, "temporal", "", false, false], [31, 40, 17, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2007", ",", "Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "for", "his", "achievements", "in", "computer", "science", "education", ":", "the", "Karl", "V", ".", "Karlstrom", "Outstanding", "Educator", "Award", "and", "the", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contributions", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "In 2007, Pausch received two awards from the Association for Computing Machinery for his achievements in computer science education: the Karl V. Karlstrom Outstanding Educator Award and the ACM SIGCSE Award for Outstanding Contributions to Computer Science Education.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 24], [25, 28], [29, 35], [36, 40], [41, 44], [45, 56], [57, 60], [61, 70], [71, 80], [81, 84], [85, 88], [89, 101], [102, 104], [105, 113], [114, 121], [122, 131], [131, 132], [133, 136], [137, 141], [142, 143], [143, 144], [145, 154], [155, 166], [167, 175], [176, 181], [182, 185], [186, 189], [190, 193], [194, 200], [201, 206], [207, 210], [211, 222], [223, 236], [237, 239], [240, 248], [249, 256], [257, 266], [266, 267]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [8, 8, "product"], [9, 11, "product"], [15, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 8, "role", "sells", false, false], [8, 8, 9, 11, "general-affiliation", "", false, false], [8, 8, 15, 18, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 86], [87, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-test-326", "ner": [[0, 1, "algorithm"], [5, 7, "field"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 1, "usage", "", false, false], [11, 12, 5, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantic", "networks", "are", "used", "in", "natural", "language", "processing", "applications", "such", "as", "semantic", "parsing", "."], "sentence-detokenized": "Semantic networks are used in natural language processing applications such as semantic parsing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 26], [27, 29], [30, 37], [38, 46], [47, 57], [58, 70], [71, 75], [76, 78], [79, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-327", "ner": [[4, 5, "field"], [7, 8, "field"], [10, 11, "task"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 8, 4, 5, "usage", "", false, false], [10, 11, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Some", "successful", "applications", "of", "deep", "learning", "are", "computer", "vision", "and", "speech", "recognition", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Some successful applications of deep learning are computer vision and speech recognition. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 31], [32, 36], [37, 45], [46, 49], [50, 58], [59, 65], [66, 69], [70, 76], [77, 88], [88, 89], [90, 97], [98, 101], [101, 102], [103, 108], [109, 115], [115, 116], [117, 123], [124, 133], [133, 134], [135, 141], [142, 143], [143, 144], [145, 147], [147, 148]]}
{"doc_key": "ai-test-328", "ner": [[0, 9, "product"], [15, 15, "misc"], [21, 22, "misc"], [23, 23, "product"], [26, 27, "task"], [29, 30, "task"], [32, 33, "task"], [35, 37, "field"], [39, 40, "task"], [42, 43, "field"], [45, 46, "task"], [48, 49, "task"], [51, 52, "task"], [54, 55, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[0, 9, 15, 15, "physical", "travels_to", false, false], [0, 9, 21, 22, "physical", "travels_to", false, false], [23, 23, 0, 9, "part-of", "", false, false], [23, 23, 0, 9, "role", "maintains", false, false], [23, 23, 26, 27, "related-to", "has_ability_to", false, false], [23, 23, 29, 30, "related-to", "has_ability_to", false, false], [23, 23, 32, 33, "related-to", "has_ability_to", false, false], [23, 23, 35, 37, "related-to", "has_ability_to", false, false], [23, 23, 39, 40, "related-to", "has_ability_to", false, false], [23, 23, 42, 43, "related-to", "has_ability_to", false, false], [23, 23, 45, 46, "related-to", "has_ability_to", false, false], [23, 23, 48, 49, "related-to", "has_ability_to", false, false], [23, 23, 51, 52, "related-to", "has_ability_to", false, false], [23, 23, 54, 55, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "addition", "to", "maintaining", "the", "Discovery", "One", "spacecraft", "'s", "systems", "during", "its", "interplanetary", "mission", "to", "Jupiter", "(", "Saturn", "in", "the", "novel", ")", ",", "HAL", "can", "perform", "speech", "synthesis", ",", "speech", "recognition", ",", "facial", "recognition", ",", "natural", "language", "processing", ",", "lip", "reading", ",", "art", "appreciation", ",", "affective", "computing", ",", "automated", "reasoning", ",", "spacecraft", "piloting", "and", "chess", "playing", "."], "sentence-detokenized": "In addition to maintaining the Discovery One spacecraft's systems during its interplanetary mission to Jupiter (Saturn in the novel), HAL can perform speech synthesis, speech recognition, facial recognition, natural language processing, lip reading, art appreciation, affective computing, automated reasoning, spacecraft piloting and chess playing.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 40], [41, 44], [45, 55], [55, 57], [58, 65], [66, 72], [73, 76], [77, 91], [92, 99], [100, 102], [103, 110], [111, 112], [112, 118], [119, 121], [122, 125], [126, 131], [131, 132], [132, 133], [134, 137], [138, 141], [142, 149], [150, 156], [157, 166], [166, 167], [168, 174], [175, 186], [186, 187], [188, 194], [195, 206], [206, 207], [208, 215], [216, 224], [225, 235], [235, 236], [237, 240], [241, 248], [248, 249], [250, 253], [254, 266], [266, 267], [268, 277], [278, 287], [287, 288], [289, 298], [299, 308], [308, 309], [310, 320], [321, 329], [330, 333], [334, 339], [340, 347], [347, 348]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [4, 4, "country"], [7, 8, "country"], [11, 11, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 4, "physical", "", false, false], [0, 1, 7, 8, "physical", "", false, false], [0, 1, 11, 11, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr", "Julesz", "emigrated", "from", "Hungary", "to", "the", "United", "States", "after", "the", "Soviet", "invasion", "in", "1956", "."], "sentence-detokenized": "Dr Julesz emigrated from Hungary to the United States after the Soviet invasion in 1956.", "token2charspan": [[0, 2], [3, 9], [10, 19], [20, 24], [25, 32], [33, 35], [36, 39], [40, 46], [47, 53], [54, 59], [60, 63], [64, 70], [71, 79], [80, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-test-330", "ner": [[2, 2, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "sigmoid", "activation", "functions", ",", "a", "second", "non-linearity", "is", "used", "for", "large", "input", "values", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+\\", "exp", "(", "-", "v", "_", "i", ")", ")", ".", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "In the sigmoid activation functions, a second non-linearity is used for large input values: math\\ phi (v _ i) = (1 +\\ exp (-v _ i)). ^ {-1} / math.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 25], [26, 35], [35, 36], [37, 38], [39, 45], [46, 59], [60, 62], [63, 67], [68, 71], [72, 77], [78, 83], [84, 90], [90, 91], [92, 96], [96, 97], [98, 101], [102, 103], [103, 104], [105, 106], [107, 108], [108, 109], [110, 111], [112, 113], [113, 114], [115, 117], [118, 121], [122, 123], [123, 124], [124, 125], [126, 127], [128, 129], [129, 130], [130, 131], [131, 132], [133, 134], [135, 136], [136, 138], [138, 139], [140, 141], [142, 146], [146, 147]]}
{"doc_key": "ai-test-331", "ner": [[12, 14, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "probabilities", "are", "used", "to", "determine", "what", "the", "target", "is", "using", "a", "maximum", "likelihood", "decision", "."], "sentence-detokenized": "These probabilities are used to determine what the target is using a maximum likelihood decision.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 46], [47, 50], [51, 57], [58, 60], [61, 66], [67, 68], [69, 76], [77, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-332", "ner": [[4, 11, "university"], [12, 14, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "moved", "to", "the", "University", "of", "Konstanz", "in", "1984", "and", "to", "the", "University", "of", "Salzburg", "in", "1990", "."], "sentence-detokenized": "He moved to the University of Konstanz in 1984 and to the University of Salzburg in 1990.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 15], [16, 26], [27, 29], [30, 38], [39, 41], [42, 46], [47, 50], [51, 53], [54, 57], [58, 68], [69, 71], [72, 80], [81, 83], [84, 88], [88, 89]]}
{"doc_key": "ai-test-333", "ner": [[7, 8, "metrics"], [10, 12, "metrics"], [14, 16, "metrics"], [18, 18, "metrics"], [20, 21, "metrics"], [23, 25, "metrics"], [28, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 12, 7, 8, "origin", "based_on", false, false], [14, 16, 7, 8, "origin", "based_on", false, false], [18, 18, 7, 8, "origin", "based_on", false, false], [20, 21, 7, 8, "origin", "based_on", false, false], [23, 25, 7, 8, "origin", "based_on", false, false], [28, 33, 7, 8, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Some", "popular", "suitability", "functions", "based", "on", "the", "mixing", "matrix", "are", "sensitivity", "/", "specificity", ",", "recall", "/", "accuracy", ",", "F-measure", ",", "Jaccard", "similarity", ",", "Matthews", "correlation", "coefficient", "and", "the", "cost", "/", "benefit", "matrix", ",", "which", "combines", "costs", "and", "benefits", "assigned", "to", "4", "different", "classifications", "."], "sentence-detokenized": "Some popular suitability functions based on the mixing matrix are sensitivity/specificity, recall/accuracy, F-measure, Jaccard similarity, Matthews correlation coefficient and the cost/benefit matrix, which combines costs and benefits assigned to 4 different classifications.", "token2charspan": [[0, 4], [5, 12], [13, 24], [25, 34], [35, 40], [41, 43], [44, 47], [48, 54], [55, 61], [62, 65], [66, 77], [77, 78], [78, 89], [89, 90], [91, 97], [97, 98], [98, 106], [106, 107], [108, 117], [117, 118], [119, 126], [127, 137], [137, 138], [139, 147], [148, 159], [160, 171], [172, 175], [176, 179], [180, 184], [184, 185], [185, 192], [193, 199], [199, 200], [201, 206], [207, 215], [216, 221], [222, 225], [226, 234], [235, 243], [244, 246], [247, 248], [249, 258], [259, 274], [274, 275]]}
{"doc_key": "ai-test-334", "ner": [[6, 6, "product"], [8, 8, "product"], [10, 10, "product"], [12, 12, "product"], [15, 16, "programlang"], [25, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[25, 27, 6, 6, "part-of", "", false, false], [25, 27, 8, 8, "part-of", "", false, false], [25, 27, 10, 10, "part-of", "", false, false], [25, 27, 12, 12, "part-of", "", false, false], [25, 27, 15, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Common", "numerical", "programming", "environments", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "and", "the", "R", "language", "provide", "some", "simpler", "feature", "extraction", "methods", "(", "e.g.", "principal", "component", "analysis", ")", "using", "built", "-", "in", "commands", "."], "sentence-detokenized": "Common numerical programming environments such as MATLAB, SciLab, NumPy, Sklearn and the R language provide some simpler feature extraction methods (e.g. principal component analysis) using built-in commands.", "token2charspan": [[0, 6], [7, 16], [17, 28], [29, 41], [42, 46], [47, 49], [50, 56], [56, 57], [58, 64], [64, 65], [66, 71], [71, 72], [73, 80], [81, 84], [85, 88], [89, 90], [91, 99], [100, 107], [108, 112], [113, 120], [121, 128], [129, 139], [140, 147], [148, 149], [149, 153], [154, 163], [164, 173], [174, 182], [182, 183], [184, 189], [190, 195], [195, 196], [196, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-335", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "have", "been", "introduced", "to", "interact", "with", "humans", "and", "perform", "industrial", "production", "tasks", "."], "sentence-detokenized": "Industrial robots have been introduced to interact with humans and perform industrial production tasks.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 27], [28, 38], [39, 41], [42, 50], [51, 55], [56, 62], [63, 66], [67, 74], [75, 85], [86, 96], [97, 102], [102, 103]]}
{"doc_key": "ai-test-336", "ner": [[6, 6, "field"], [7, 11, "researcher"], [21, 22, "field"], [24, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 21, 22, "related-to", "", false, false], [6, 6, 24, 25, "related-to", "", false, false], [6, 6, 27, 28, "related-to", "", false, false], [7, 11, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "first", "published", "work", "on", "CG", ",", "John", "F", ".", "Sowa", "applied", "CG", "to", "a", "wide", "range", "of", "topics", "in", "artificial", "intelligence", ",", "computer", "science", "and", "cognitive", "science", "."], "sentence-detokenized": "In his first published work on CG, John F. Sowa applied CG to a wide range of topics in artificial intelligence, computer science and cognitive science.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [23, 27], [28, 30], [31, 33], [33, 34], [35, 39], [40, 41], [41, 42], [43, 47], [48, 55], [56, 58], [59, 61], [62, 63], [64, 68], [69, 74], [75, 77], [78, 84], [85, 87], [88, 98], [99, 111], [111, 112], [113, 121], [122, 129], [130, 133], [134, 143], [144, 151], [151, 152]]}
{"doc_key": "ai-test-337", "ner": [[0, 1, "metrics"], [4, 4, "metrics"], [10, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 4, 4, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "in", "the", "calculation", "of", "the", "brevity", "penalty", ",", "as", "small", "variations", "in", "translation", "length", "do", "not", "affect", "the", "overall", "result", "as", "much", "."], "sentence-detokenized": "NIST also differs from BLEU in the calculation of the brevity penalty, as small variations in translation length do not affect the overall result as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 46], [47, 49], [50, 53], [54, 61], [62, 69], [69, 70], [71, 73], [74, 79], [80, 90], [91, 93], [94, 105], [106, 112], [113, 115], [116, 119], [120, 126], [127, 130], [131, 138], [139, 145], [146, 148], [149, 153], [153, 154]]}
{"doc_key": "ai-test-338", "ner": [[0, 4, "misc"], [12, 12, "conference"], [15, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 12, 12, "temporal", "", false, false], [0, 4, 15, 15, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "IJCAI", "Research", "Excellence", "Award", "is", "a", "biannual", "award", "presented", "at", "the", "IJCAI", "conference", "to", "AI", "researchers", "for", "excellence", "in", "their", "careers", "."], "sentence-detokenized": "The IJCAI Research Excellence Award is a biannual award presented at the IJCAI conference to AI researchers for excellence in their careers.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 29], [30, 35], [36, 38], [39, 40], [41, 49], [50, 55], [56, 65], [66, 68], [69, 72], [73, 78], [79, 89], [90, 92], [93, 95], [96, 107], [108, 111], [112, 122], [123, 125], [126, 131], [132, 139], [139, 140]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [6, 6, "conference"], [19, 24, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 6, "role", "", false, false], [0, 0, 19, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "was", "one", "of", "the", "first", "AAAI", "Fellows", "and", "is", "the", "only", "person", "to", "have", "served", "on", "both", "the", "Microsoft", "and", "Apple", "Scientific", "Advisory", "Boards", "."], "sentence-detokenized": "Lenat was one of the first AAAI Fellows and is the only person to have served on both the Microsoft and Apple Scientific Advisory Boards.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 16], [17, 20], [21, 26], [27, 31], [32, 39], [40, 43], [44, 46], [47, 50], [51, 55], [56, 62], [63, 65], [66, 70], [71, 77], [78, 80], [81, 85], [86, 89], [90, 99], [100, 103], [104, 109], [110, 120], [121, 129], [130, 136], [136, 137]]}
{"doc_key": "ai-test-340", "ner": [[0, 0, "algorithm"], [5, 6, "misc"], [9, 15, "metrics"], [19, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "related-to", "minimise", false, false], [9, 15, 5, 6, "type-of", "", false, false], [19, 19, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoders", "are", "trained", "to", "reduce", "reconstruction", "errors", "(", "e.g.", "root", "mean", "square", "error", ")", ",", "often", "referred", "to", "as", "losses", ":"], "sentence-detokenized": "Autoencoders are trained to reduce reconstruction errors (e.g. root mean square error), often referred to as losses:", "token2charspan": [[0, 12], [13, 16], [17, 24], [25, 27], [28, 34], [35, 49], [50, 56], [57, 58], [58, 62], [63, 67], [68, 72], [73, 79], [80, 85], [85, 86], [86, 87], [88, 93], [94, 102], [103, 105], [106, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-341", "ner": [[30, 34, "misc"], [36, 36, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[36, 36, 30, 34, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "to", "using", "definitions", "is", "to", "take", "into", "account", "the", "general", "relatedness", "of", "word", "meanings", "and", "calculate", "the", "similarity", "of", "each", "pair", "of", "word", "meanings", "based", "on", "a", "given", "lexical", "knowledge", "base", ",", "such", "as", "WordNet", "."], "sentence-detokenized": "An alternative to using definitions is to take into account the general relatedness of word meanings and calculate the similarity of each pair of word meanings based on a given lexical knowledge base, such as WordNet.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 23], [24, 35], [36, 38], [39, 41], [42, 46], [47, 51], [52, 59], [60, 63], [64, 71], [72, 83], [84, 86], [87, 91], [92, 100], [101, 104], [105, 114], [115, 118], [119, 129], [130, 132], [133, 137], [138, 142], [143, 145], [146, 150], [151, 159], [160, 165], [166, 168], [169, 170], [171, 176], [177, 184], [185, 194], [195, 199], [199, 200], [201, 205], [206, 208], [209, 216], [216, 217]]}
{"doc_key": "ai-test-342", "ner": [[0, 2, "algorithm"], [9, 12, "researcher"], [22, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 12, "origin", "", false, false], [9, 12, 22, 23, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "invented", "by", "Richard", "S.", "Sutton", "based", "on", "earlier", "work", "on", "time", "-", "difference", "learning", "by", "Arthur", "Samuel", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm invented by Richard S. Sutton based on earlier work on time-difference learning by Arthur Samuel.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 42], [43, 45], [46, 53], [54, 56], [57, 63], [64, 69], [70, 72], [73, 80], [81, 85], [86, 88], [89, 93], [93, 94], [94, 104], [105, 113], [114, 116], [117, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-343", "ner": [[0, 2, "field"], [4, 4, "field"], [6, 7, "task"], [11, 13, "task"], [15, 15, "task"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 0, 2, "part-of", "task_part_of_field", false, false], [6, 7, 4, 4, "part-of", "task_part_of_field", false, false], [11, 13, 6, 7, "named", "", false, false], [15, 15, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "data", "mining", "and", "statistics", ",", "hierarchical", "clustering", "(", "also", "called", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "cluster", "analysis", "technique", "that", "aims", "to", "create", "a", "hierarchy", "of", "clusters", "."], "sentence-detokenized": "In data mining and statistics, hierarchical clustering (also called hierarchical cluster analysis or HCA) is a cluster analysis technique that aims to create a hierarchy of clusters.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 29], [29, 30], [31, 43], [44, 54], [55, 56], [56, 60], [61, 67], [68, 80], [81, 88], [89, 97], [98, 100], [101, 104], [104, 105], [106, 108], [109, 110], [111, 118], [119, 127], [128, 137], [138, 142], [143, 147], [148, 150], [151, 157], [158, 159], [160, 169], [170, 172], [173, 181], [181, 182]]}
{"doc_key": "ai-test-344", "ner": [[3, 3, "algorithm"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "concept", "of", "deconvolution", "is", "widely", "used", "in", "signal", "processing", "and", "image", "processing", "techniques", "."], "sentence-detokenized": "The concept of deconvolution is widely used in signal processing and image processing techniques.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 53], [54, 64], [65, 68], [69, 74], [75, 85], [86, 96], [96, 97]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [21, 22, "misc"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 21, 22, "related-to", "enhances", false, false], [0, 1, 21, 22, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "are", "used", "to", "construct", "and", "store", "spatial", "knowledge", ",", "allowing", "the", "mind", "'s", "eye", "to", "visualise", "images", "to", "reduce", "cognitive", "load", ",", "improve", "recall", "and", "learning", "."], "sentence-detokenized": "Cognitive maps are used to construct and store spatial knowledge, allowing the mind's eye to visualise images to reduce cognitive load, improve recall and learning.", "token2charspan": [[0, 9], [10, 14], [15, 18], [19, 23], [24, 26], [27, 36], [37, 40], [41, 46], [47, 54], [55, 64], [64, 65], [66, 74], [75, 78], [79, 83], [83, 85], [86, 89], [90, 92], [93, 102], [103, 109], [110, 112], [113, 119], [120, 129], [130, 134], [134, 135], [136, 143], [144, 150], [151, 154], [155, 163], [163, 164]]}
{"doc_key": "ai-test-346", "ner": [[9, 9, "programlang"], [11, 12, "programlang"], [14, 14, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "which", "usually", "provides", "bindings", "for", "languages", "such", "as", "Python", ",", "C", "++", ",", "Java", ")", "."], "sentence-detokenized": ", which usually provides bindings for languages such as Python, C++, Java).", "token2charspan": [[0, 1], [2, 7], [8, 15], [16, 24], [25, 33], [34, 37], [38, 47], [48, 52], [53, 55], [56, 62], [62, 63], [64, 65], [65, 67], [67, 68], [69, 73], [73, 74], [74, 75]]}
{"doc_key": "ai-test-347", "ner": [[0, 3, "product"], [5, 5, "product"], [14, 16, "task"], [21, 22, "task"], [27, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 14, 16, "usage", "", false, false], [0, 3, 21, 22, "usage", "", false, false], [0, 3, 27, 31, "usage", "", false, false], [5, 5, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Voice", "and", "User", "Interface", "(", "VUI", ")", "enables", "human", "-", "computer", "interaction", "by", "using", "speech", "recognition", "to", "understand", "spoken", "commands", "and", "answer", "questions", ",", "and", "usually", "also", "translating", "text", "into", "speech", "to", "echo", "back", "a", "response", "."], "sentence-detokenized": "Voice and User Interface (VUI) enables human-computer interaction by using speech recognition to understand spoken commands and answer questions, and usually also translating text into speech to echo back a response.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 24], [25, 26], [26, 29], [29, 30], [31, 38], [39, 44], [44, 45], [45, 53], [54, 65], [66, 68], [69, 74], [75, 81], [82, 93], [94, 96], [97, 107], [108, 114], [115, 123], [124, 127], [128, 134], [135, 144], [144, 145], [146, 149], [150, 157], [158, 162], [163, 174], [175, 179], [180, 184], [185, 191], [192, 194], [195, 199], [200, 204], [205, 206], [207, 215], [215, 216]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [5, 6, "misc"], [3, 3, "programlang"], [9, 12, "researcher"], [14, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 6, "general-affiliation", "is_a", false, false], [0, 0, 3, 3, "general-affiliation", "made_with", false, false], [0, 0, 9, 12, "origin", "", false, false], [9, 12, 14, 15, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Jess", "is", "a", "Java", "platform", "rule", "engine", "developed", "by", "Ernest", "Friedman", "-", "Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "Jess is a Java platform rule engine developed by Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 14], [15, 23], [24, 28], [29, 35], [36, 45], [46, 48], [49, 55], [56, 64], [64, 65], [65, 69], [70, 72], [73, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-349", "ner": [[0, 2, "algorithm"], [17, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 17, 17, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "multilayer", "perceptrons", ",", "where", "there", "is", "a", "hidden", "layer", ",", "more", "complex", "algorithms", "such", "as", "the", "backflow", "algorithm", "must", "be", "used", "."], "sentence-detokenized": "For multilayer perceptrons, where there is a hidden layer, more complex algorithms such as the backflow algorithm must be used.", "token2charspan": [[0, 3], [4, 14], [15, 26], [26, 27], [28, 33], [34, 39], [40, 42], [43, 44], [45, 51], [52, 57], [57, 58], [59, 63], [64, 71], [72, 82], [83, 87], [88, 90], [91, 94], [95, 103], [104, 113], [114, 118], [119, 121], [122, 126], [126, 127]]}
{"doc_key": "ai-test-350", "ner": [[0, 2, "product"], [3, 6, "product"], [10, 13, "algorithm"], [17, 18, "field"], [22, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 0, 2, "part-of", "", false, false], [3, 6, 10, 13, "usage", "", false, true], [10, 13, 17, 18, "related-to", "performs", false, false], [22, 29, 17, 18, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "Translate", "'s", "neural", "machine", "translation", "system", "uses", "a", "large", "artificial", "neural", "network", "that", "attempts", "to", "perform", "deep", "learning", ",", "in", "particular", "long", "-", "term", "short", "-", "term", "memory", "networks", "."], "sentence-detokenized": "Google Translate's neural machine translation system uses a large artificial neural network that attempts to perform deep learning, in particular long-term short-term memory networks.", "token2charspan": [[0, 6], [7, 16], [16, 18], [19, 25], [26, 33], [34, 45], [46, 52], [53, 57], [58, 59], [60, 65], [66, 76], [77, 83], [84, 91], [92, 96], [97, 105], [106, 108], [109, 116], [117, 121], [122, 130], [130, 131], [132, 134], [135, 145], [146, 150], [150, 151], [151, 155], [156, 161], [161, 162], [162, 166], [167, 173], [174, 182], [182, 183]]}
{"doc_key": "ai-test-351", "ner": [[14, 14, "researcher"], [16, 16, "researcher"], [18, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Different", "methods", "of", "doing", "this", "were", "developed", "in", "the", "1980s", "and", "early", "1990s", "by", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "and", "others", "."], "sentence-detokenized": "Different methods of doing this were developed in the 1980s and early 1990s by Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter and others.", "token2charspan": [[0, 9], [10, 17], [18, 20], [21, 26], [27, 31], [32, 36], [37, 46], [47, 49], [50, 53], [54, 59], [60, 63], [64, 69], [70, 75], [76, 78], [79, 85], [85, 86], [87, 95], [95, 96], [97, 105], [105, 106], [107, 113], [114, 125], [125, 126], [127, 131], [132, 142], [142, 143], [144, 155], [156, 159], [160, 166], [166, 167]]}
{"doc_key": "ai-test-352", "ner": [[1, 1, "organisation"], [2, 3, "organisation"], [8, 9, "organisation"], [11, 12, "task"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 8, 9, "role", "licenses_from", false, false], [2, 3, 1, 1, "named", "", false, false], [18, 18, 1, 1, "origin", "", false, false], [18, 18, 11, 12, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc", "originally", "licensed", "software", "from", "Nuance", "to", "provide", "speech", "recognition", "capabilities", "for", "its", "digital", "assistant", "Siri", "."], "sentence-detokenized": "| Apple Apple Inc originally licensed software from Nuance to provide speech recognition capabilities for its digital assistant Siri.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 17], [18, 28], [29, 37], [38, 46], [47, 51], [52, 58], [59, 61], [62, 69], [70, 76], [77, 88], [89, 101], [102, 105], [106, 109], [110, 117], [118, 127], [128, 132], [132, 133]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [6, 8, "person"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 4, "role", "releases_movies_in_genre", false, false], [6, 8, 0, 0, "role", "directs_for", false, false], [12, 13, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "released", "several", "3D", "westerns", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia released several 3D westerns produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 28], [29, 37], [38, 46], [47, 49], [50, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-test-354", "ner": [[6, 7, "field"], [9, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "includes", "knowledge", "and", "research", "in", "computer", "science", ",", "linguistics", "and", "computer", "engineering", "."], "sentence-detokenized": "It includes knowledge and research in computer science, linguistics and computer engineering.", "token2charspan": [[0, 2], [3, 11], [12, 21], [22, 25], [26, 34], [35, 37], [38, 46], [47, 54], [54, 55], [56, 67], [68, 71], [72, 80], [81, 92], [92, 93]]}
{"doc_key": "ai-test-355", "ner": [[5, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", "is", "an", "example", "of", "R", "code", ":"], "sentence-detokenized": "Here is an example of R code:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 23], [24, 28], [28, 29]]}
{"doc_key": "ai-test-356", "ner": [[0, 2, "metrics"], [8, 12, "metrics"], [14, 14, "metrics"], [18, 22, "metrics"], [24, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 8, 12, "part-of", "plotted_into", false, false], [0, 2, 18, 22, "part-of", "plotted_into", false, false], [14, 14, 8, 12, "named", "", false, false], [24, 24, 18, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "ROC", "curve", "is", "generated", "by", "plotting", "the", "number", "of", "TRUE", "positive", "cases", "(", "TPR", ")", "against", "the", "number", "of", "FALSE", "positive", "cases", "(", "FPR", ")", "at", "different", "threshold", "settings", "."], "sentence-detokenized": "The ROC curve is generated by plotting the number of TRUE positive cases (TPR) against the number of FALSE positive cases (FPR) at different threshold settings.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 26], [27, 29], [30, 38], [39, 42], [43, 49], [50, 52], [53, 57], [58, 66], [67, 72], [73, 74], [74, 77], [77, 78], [79, 86], [87, 90], [91, 97], [98, 100], [101, 106], [107, 115], [116, 121], [122, 123], [123, 126], [126, 127], [128, 130], [131, 140], [141, 150], [151, 159], [159, 160]]}
{"doc_key": "ai-test-357", "ner": [[10, 11, "field"], [1, 2, "researcher"], [4, 6, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 10, 11, "related-to", "researches_field", false, false], [4, 6, 10, 11, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["After", "Marvin", "Minsky", "and", "Seymour", "Papert", "'s", "(", "1969", ")", "machine", "learning", "research", "stopped", ","], "sentence-detokenized": "After Marvin Minsky and Seymour Papert's (1969) machine learning research stopped,", "token2charspan": [[0, 5], [6, 12], [13, 19], [20, 23], [24, 31], [32, 38], [38, 40], [41, 42], [42, 46], [46, 47], [48, 55], [56, 64], [65, 73], [74, 81], [81, 82]]}
{"doc_key": "ai-test-358", "ner": [[6, 6, "task"], [9, 10, "programlang"], [12, 14, "product"], [16, 17, "programlang"], [19, 19, "product"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 9, 10, "related-to", "used_to_build", false, false], [6, 6, 12, 14, "related-to", "used_to_build", false, false], [6, 6, 16, 17, "related-to", "used_to_build", false, false], [6, 6, 19, 19, "related-to", "used_to_build", false, false], [6, 6, 21, 21, "related-to", "used_to_build", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "programming", "environments", "used", "to", "build", "DAQ", "applications", "are", "ladder", "logic", ",", "Visual", "C", "++", ",", "Visual", "Basic", ",", "LabVIEW", "and", "MATLAB", "."], "sentence-detokenized": "Other programming environments used to build DAQ applications are ladder logic, Visual C++, Visual Basic, LabVIEW and MATLAB.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 38], [39, 44], [45, 48], [49, 61], [62, 65], [66, 72], [73, 78], [78, 79], [80, 86], [87, 88], [88, 90], [90, 91], [92, 98], [99, 104], [104, 105], [106, 113], [114, 117], [118, 124], [124, 125]]}
{"doc_key": "ai-test-359", "ner": [[15, 21, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "metric", "was", "developed", "to", "overcome", "some", "of", "the", "problems", "found", "in", "the", "most", "popular", "BLEU", "metric", ",", "as", "well", "as", "to", "provide", "a", "good", "correlation", "with", "human", "judgement", "at", "sentence", "or", "segment", "level", "."], "sentence-detokenized": "This metric was developed to overcome some of the problems found in the most popular BLEU metric, as well as to provide a good correlation with human judgement at sentence or segment level.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 25], [26, 28], [29, 37], [38, 42], [43, 45], [46, 49], [50, 58], [59, 64], [65, 67], [68, 71], [72, 76], [77, 84], [85, 89], [90, 96], [96, 97], [98, 100], [101, 105], [106, 108], [109, 111], [112, 119], [120, 121], [122, 126], [127, 138], [139, 143], [144, 149], [150, 159], [160, 162], [163, 171], [172, 174], [175, 182], [183, 188], [188, 189]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "-", "term", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "semantic", "correlations", "between", "consecutive", "video", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long-term short-term memory are often used to exploit semantic correlations between consecutive video frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [82, 83], [83, 87], [88, 93], [93, 94], [94, 98], [99, 105], [106, 109], [110, 115], [116, 120], [121, 123], [124, 131], [132, 140], [141, 153], [154, 161], [162, 173], [174, 179], [180, 186], [186, 187]]}
{"doc_key": "ai-test-361", "ner": [[3, 4, "product"], [7, 7, "product"], [14, 19, "product"], [22, 22, "product"], [38, 41, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 14, 19, "artifact", "", false, false], [3, 4, 38, 41, "named", "", false, false], [7, 7, 3, 4, "named", "", false, false], [22, 22, 14, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Mass", "-", "produced", "printed", "circuit", "boards", "(", "PCBs", ")", "are", "manufactured", "almost", "exclusively", "by", "pick", "-", "and", "-", "place", "robots", ",", "usually", "SCARA", "manipulators", ",", "which", "remove", "tiny", "electronic", "parts", "from", "strips", "or", "trays", "and", "insert", "them", "into", "PCBs", "with", "great", "precision", "."], "sentence-detokenized": "Mass-produced printed circuit boards (PCBs) are manufactured almost exclusively by pick-and-place robots, usually SCARA manipulators, which remove tiny electronic parts from strips or trays and insert them into PCBs with great precision.", "token2charspan": [[0, 4], [4, 5], [5, 13], [14, 21], [22, 29], [30, 36], [37, 38], [38, 42], [42, 43], [44, 47], [48, 60], [61, 67], [68, 79], [80, 82], [83, 87], [87, 88], [88, 91], [91, 92], [92, 97], [98, 104], [104, 105], [106, 113], [114, 119], [120, 132], [132, 133], [134, 139], [140, 146], [147, 151], [152, 162], [163, 168], [169, 173], [174, 180], [181, 183], [184, 189], [190, 193], [194, 200], [201, 205], [206, 210], [211, 215], [216, 220], [221, 226], [227, 236], [236, 237]]}
{"doc_key": "ai-test-362", "ner": [[4, 5, "field"], [15, 15, "algorithm"], [22, 23, "researcher"], [25, 26, "researcher"], [28, 31, "researcher"], [36, 37, "algorithm"], [38, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 4, 5, "part-of", "", false, false], [15, 15, 22, 23, "origin", "", false, false], [15, 15, 25, 26, "origin", "", false, false], [15, 15, 28, 31, "origin", "", false, false], [15, 15, 36, 37, "type-of", "", false, false], [36, 37, 38, 40, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "context", "of", "machine", "learning", ",", "where", "it", "is", "currently", "most", "widely", "used", ",", "LDA", "was", "independently", "discovered", "in", "2003", "by", "David", "Blais", ",", "Andrew", "Ng", "and", "Michael", "I", ".", "Jordan", "and", "presented", "as", "a", "graphical", "model", "for", "topic", "discovery", "."], "sentence-detokenized": "In the context of machine learning, where it is currently most widely used, LDA was independently discovered in 2003 by David Blais, Andrew Ng and Michael I. Jordan and presented as a graphical model for topic discovery.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 25], [26, 34], [34, 35], [36, 41], [42, 44], [45, 47], [48, 57], [58, 62], [63, 69], [70, 74], [74, 75], [76, 79], [80, 83], [84, 97], [98, 108], [109, 111], [112, 116], [117, 119], [120, 125], [126, 131], [131, 132], [133, 139], [140, 142], [143, 146], [147, 154], [155, 156], [156, 157], [158, 164], [165, 168], [169, 178], [179, 181], [182, 183], [184, 193], [194, 199], [200, 203], [204, 209], [210, 219], [219, 220]]}
{"doc_key": "ai-test-363", "ner": [[8, 8, "task"], [12, 12, "misc"], [19, 20, "metrics"], [22, 22, "metrics"], [24, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 8, 12, 12, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "measured", "performance", "using", "data", "from", "eight", "naive", "WSI", "tests", "for", "different", "tauopathies", "was", "0.92", ",", "0.72", "and", "0.81", "for", "recall", ",", "precision", "and", "F1", ",", "respectively", "."], "sentence-detokenized": "The measured performance using data from eight naive WSI tests for different tauopathies was 0.92, 0.72 and 0.81 for recall, precision and F1, respectively.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 30], [31, 35], [36, 40], [41, 46], [47, 52], [53, 56], [57, 62], [63, 66], [67, 76], [77, 88], [89, 92], [93, 97], [97, 98], [99, 103], [104, 107], [108, 112], [113, 116], [117, 123], [123, 124], [125, 134], [135, 138], [139, 141], [141, 142], [143, 155], [155, 156]]}
{"doc_key": "ai-test-364", "ner": [[2, 2, "field"], [7, 8, "field"], [10, 10, "field"], [13, 17, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 10, 10, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Using", "advanced", "AR", "technologies", "(", "e.g.", "adding", "computer", "vision", ",", "AR", "cameras", "and", "object", "recognition", "to", "a", "smartphone", ")", ",", "information", "about", "the", "real", "world", "around", "the", "user", "becomes", "interactive", "and", "digitally", "manipulable", "."], "sentence-detokenized": "Using advanced AR technologies (e.g. adding computer vision, AR cameras and object recognition to a smartphone), information about the real world around the user becomes interactive and digitally manipulable.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 30], [31, 32], [32, 36], [37, 43], [44, 52], [53, 59], [59, 60], [61, 63], [64, 71], [72, 75], [76, 82], [83, 94], [95, 97], [98, 99], [100, 110], [110, 111], [111, 112], [113, 124], [125, 130], [131, 134], [135, 139], [140, 145], [146, 152], [153, 156], [157, 161], [162, 169], [170, 181], [182, 185], [186, 195], [196, 207], [207, 208]]}
{"doc_key": "ai-test-365", "ner": [[0, 3, "researcher"], [5, 6, "organisation"], [12, 12, "field"], [22, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 5, 6, "role", "forms_company", false, false], [5, 6, 12, 12, "related-to", "works_with", false, false], [5, 6, 22, 24, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2014", ",", "Schmidhuber", "founded", "Nnaisense", "to", "work", "on", "commercial", "applications", "of", "AI", "in", "areas", "such", "as", "finance", ",", "heavy", "industry", "and", "self", "-", "driving", "cars", "."], "sentence-detokenized": "In 2014, Schmidhuber founded Nnaisense to work on commercial applications of AI in areas such as finance, heavy industry and self-driving cars.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 28], [29, 38], [39, 41], [42, 46], [47, 49], [50, 60], [61, 73], [74, 76], [77, 79], [80, 82], [83, 88], [89, 93], [94, 96], [97, 104], [104, 105], [106, 111], [112, 120], [121, 124], [125, 129], [129, 130], [130, 137], [138, 142], [142, 143]]}
{"doc_key": "ai-test-366", "ner": [[24, 28, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "not", "only", "changes", "the", "results", "of", "all", "subsequent", "tests", "on", "the", "retained", "explanatory", "model", ",", "but", "can", "also", "introduce", "bias", "and", "change", "the", "root", "mean", "square", "error", "of", "the", "estimates", "."], "sentence-detokenized": "This not only changes the results of all subsequent tests on the retained explanatory model, but can also introduce bias and change the root mean square error of the estimates.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 21], [22, 25], [26, 33], [34, 36], [37, 40], [41, 51], [52, 57], [58, 60], [61, 64], [65, 73], [74, 85], [86, 91], [91, 92], [93, 96], [97, 100], [101, 105], [106, 115], [116, 120], [121, 124], [125, 131], [132, 135], [136, 140], [141, 145], [146, 152], [153, 158], [159, 161], [162, 165], [166, 175], [175, 176]]}
{"doc_key": "ai-test-367", "ner": [[0, 0, "misc"], [6, 6, "algorithm"], [8, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 0, 0, "usage", "", false, false], [6, 6, 8, 10, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Bigrams", "are", "used", "in", "most", "successful", "language", "models", "for", "speech", "recognition", "."], "sentence-detokenized": "Bigrams are used in most successful language models for speech recognition.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 24], [25, 35], [36, 44], [45, 51], [52, 55], [56, 62], [63, 74], [74, 75]]}
{"doc_key": "ai-test-368", "ner": [[3, 4, "field"], [11, 13, "misc"], [19, 21, "misc"], [8, 13, "organisation"], [31, 33, "misc"], [27, 30, "organisation"], [39, 41, "misc"], [47, 51, "organisation"], [55, 57, "misc"], [61, 66, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[11, 13, 3, 4, "topic", "", false, false], [19, 21, 8, 13, "origin", "", false, false], [31, 33, 27, 30, "origin", "", false, false], [39, 41, 47, 51, "origin", "", false, false], [55, 57, 61, 66, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["His", "research", "in", "cognitive", "psychology", "has", "won", "the", "American", "Psychological", "Association", "Early", "Career", "Award", "(", "1984", ")", "and", "the", "Boyd", "McCandless", "Award", "(", "1986", ")", ",", "the", "National", "Academy", "of", "Sciences", "Troland", "Research", "Award", "(", "1993", ")", ",", "the", "Henry", "Dale", "Award", "(", "2004", ")", "of", "the", "Royal", "Institute", "of", "the", "UK", ",", "and", "the", "George", "Miller", "Award", "(", "2010", ")", "of", "the", "Society", "for", "Cognitive", "Neuroscience", "."], "sentence-detokenized": "His research in cognitive psychology has won the American Psychological Association Early Career Award (1984) and the Boyd McCandless Award (1986), the National Academy of Sciences Troland Research Award (1993), the Henry Dale Award (2004) of the Royal Institute of the UK, and the George Miller Award (2010) of the Society for Cognitive Neuroscience.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 25], [26, 36], [37, 40], [41, 44], [45, 48], [49, 57], [58, 71], [72, 83], [84, 89], [90, 96], [97, 102], [103, 104], [104, 108], [108, 109], [110, 113], [114, 117], [118, 122], [123, 133], [134, 139], [140, 141], [141, 145], [145, 146], [146, 147], [148, 151], [152, 160], [161, 168], [169, 171], [172, 180], [181, 188], [189, 197], [198, 203], [204, 205], [205, 209], [209, 210], [210, 211], [212, 215], [216, 221], [222, 226], [227, 232], [233, 234], [234, 238], [238, 239], [240, 242], [243, 246], [247, 252], [253, 262], [263, 265], [266, 269], [270, 272], [272, 273], [274, 277], [278, 281], [282, 288], [289, 295], [296, 301], [302, 303], [303, 307], [307, 308], [309, 311], [312, 315], [316, 323], [324, 327], [328, 337], [338, 350], [350, 351]]}
{"doc_key": "ai-test-369", "ner": [[0, 1, "misc"], [3, 5, "product"], [9, 9, "researcher"], [11, 11, "researcher"], [20, 22, "researcher"], [24, 25, "researcher"], [18, 19, "task"], [27, 30, "researcher"], [32, 36, "researcher"], [37, 38, "task"], [40, 40, "misc"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[0, 1, 40, 40, "named", "", false, false], [3, 5, 37, 38, "named", "", false, false], [20, 22, 27, 30, "named", "same", false, false], [24, 25, 32, 36, "named", "same", false, false], [37, 38, 40, 40, "usage", "", false, false]], "relations_mapping_to_source": [1, 6, 8, 10, 11], "sentence": ["The", "eigenface", "approach", "to", "face", "recognition", "was", "developed", "by", "Sirovich", "and", "Kirby", "(", "1987", ")", "and", "used", "in", "face", "classification", "by", "Matthew", "Turk", "and", "Alex", "Pentland", ".", "Turk", ",", "Matthew", "A", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "The eigenface approach to face recognition was developed by Sirovich and Kirby (1987) and used in face classification by Matthew Turk and Alex Pentland. Turk, Matthew A and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 3], [4, 13], [14, 22], [23, 25], [26, 30], [31, 42], [43, 46], [47, 56], [57, 59], [60, 68], [69, 72], [73, 78], [79, 80], [80, 84], [84, 85], [86, 89], [90, 94], [95, 97], [98, 102], [103, 117], [118, 120], [121, 128], [129, 133], [134, 137], [138, 142], [143, 151], [151, 152], [153, 157], [157, 158], [159, 166], [167, 168], [169, 172], [173, 181], [181, 182], [183, 187], [188, 189], [189, 190], [191, 195], [196, 207], [208, 213], [214, 224], [224, 225]]}
{"doc_key": "ai-test-370", "ner": [[5, 14, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "lexical", "dictionary", "such", "as", "Word", "Net", "can", "then", "be", "used", "to", "understand", "the", "context", "."], "sentence-detokenized": "A lexical dictionary such as WordNet can then be used to understand the context.", "token2charspan": [[0, 1], [2, 9], [10, 20], [21, 25], [26, 28], [29, 33], [33, 36], [37, 40], [41, 45], [46, 48], [49, 53], [54, 56], [57, 67], [68, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-test-371", "ner": [[0, 0, "misc"], [8, 10, "misc"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 10, "part-of", "", false, false], [8, 10, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hyponymy", "is", "the", "most", "commonly", "encoded", "link", "between", "syntheses", "used", "in", "lexical", "databases", "such", "as", "WordNet", "."], "sentence-detokenized": "Hyponymy is the most commonly encoded link between syntheses used in lexical databases such as WordNet.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 20], [21, 29], [30, 37], [38, 42], [43, 50], [51, 60], [61, 65], [66, 68], [69, 76], [77, 86], [87, 91], [92, 94], [95, 102], [102, 103]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [6, 7, "programlang"], [9, 9, "programlang"], [39, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 7, "general-affiliation", "", false, false], [0, 0, 9, 9, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "offers", "open", "source", "libraries", "in", "C", "++", "and", "Java", ",", "but", "many", "customers", "rely", "on", "libraries", "developed", "by", "the", "community", ",", "e.g.", "the", "libraries", "have", "built", "-", "in", "facilities", "for", "extracting", "(", "array", "-", "type", ")", "data", "from", "DAP", "servers", "."], "sentence-detokenized": "OPeNDAP offers open source libraries in C++ and Java, but many customers rely on libraries developed by the community, e.g. the libraries have built-in facilities for extracting (array-type) data from DAP servers.", "token2charspan": [[0, 7], [8, 14], [15, 19], [20, 26], [27, 36], [37, 39], [40, 41], [41, 43], [44, 47], [48, 52], [52, 53], [54, 57], [58, 62], [63, 72], [73, 77], [78, 80], [81, 90], [91, 100], [101, 103], [104, 107], [108, 117], [117, 118], [119, 123], [124, 127], [128, 137], [138, 142], [143, 148], [148, 149], [149, 151], [152, 162], [163, 166], [167, 177], [178, 179], [179, 184], [184, 185], [185, 189], [189, 190], [191, 195], [196, 200], [201, 204], [205, 212], [212, 213]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [10, 11, "product"], [17, 17, "country"], [30, 31, "misc"], [44, 44, "product"], [46, 46, "organisation"], [47, 51, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6, 7], "relations": [[4, 5, 17, 17, "opposite", "", false, false], [10, 11, 17, 17, "artifact", "", false, false], [30, 31, 10, 11, "part-of", "", false, false], [47, 51, 46, 46, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4], "sentence": ["On", "this", "page", ",", "Samurai", "Damashii", "exaggerated", "the", "crystallisation", "of", "the", "Senkousha", "as", "four", "thousand", "years", "of", "Chinese", "scientific", "knowledge", ",", "commented", "on", "the", "crude", "design", "(", "such", "as", "the", "Chinese", "cannon", "on", "its", "crotch", ")", "and", "put", "it", "s", "image", "between", "the", "Honda", "ASIMO", "and", "Sony", "QRIO", "SDR", "-", "3", "X", "images", "to", "compare", "them", "."], "sentence-detokenized": "On this page, Samurai Damashii exaggerated the crystallisation of the Senkousha as four thousand years of Chinese scientific knowledge, commented on the crude design (such as the Chinese cannon on its crotch) and put its image between the Honda ASIMO and Sony QRIO SDR-3X images to compare them.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 21], [22, 30], [31, 42], [43, 46], [47, 62], [63, 65], [66, 69], [70, 79], [80, 82], [83, 87], [88, 96], [97, 102], [103, 105], [106, 113], [114, 124], [125, 134], [134, 135], [136, 145], [146, 148], [149, 152], [153, 158], [159, 165], [166, 167], [167, 171], [172, 174], [175, 178], [179, 186], [187, 193], [194, 196], [197, 200], [201, 207], [207, 208], [209, 212], [213, 216], [217, 219], [219, 220], [221, 226], [227, 234], [235, 238], [239, 244], [245, 250], [251, 254], [255, 259], [260, 264], [265, 268], [268, 269], [269, 270], [270, 271], [272, 278], [279, 281], [282, 289], [290, 294], [294, 295]]}
{"doc_key": "ai-test-374", "ner": [[8, 9, "algorithm"], [20, 20, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 20, 20, "part-of", "includes_functionality_of", false, false], [8, 9, 22, 22, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "also", "many", "programming", "libraries", "that", "contain", "neural", "network", "functionality", "and", "can", "be", "used", "in", "custom", "implementations", "(", "e.g.", "TensorFlow", ",", "Theano", ",", "etc", "."], "sentence-detokenized": "There are also many programming libraries that contain neural network functionality and can be used in custom implementations (e.g. TensorFlow, Theano, etc.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 31], [32, 41], [42, 46], [47, 54], [55, 61], [62, 69], [70, 83], [84, 87], [88, 91], [92, 94], [95, 99], [100, 102], [103, 109], [110, 125], [126, 127], [127, 131], [132, 142], [142, 143], [144, 150], [150, 151], [152, 155], [155, 156]]}
{"doc_key": "ai-test-375", "ner": [[6, 9, "conference"], [11, 11, "organisation"], [13, 19, "conference"], [21, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", "and", "SPIE", "."], "sentence-detokenized": "He is a member of the Association for Computing Machinery, IEEE, American Association for the Advancement of Science, IAPR and SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 33], [34, 37], [38, 47], [48, 57], [57, 58], [59, 63], [63, 64], [65, 73], [74, 85], [86, 89], [90, 93], [94, 105], [106, 108], [109, 116], [116, 117], [118, 122], [123, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-376", "ner": [[2, 2, "organisation"], [5, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 5, 6, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "2011", "RET", "trial", "with", "facial", "recognition", "cameras", "installed", "on", "trams", "ensured", "that", "people", "who", "were", "banned", "from", "the", "city", "'s", "trams", "still", "did", "not", "escape", "."], "sentence-detokenized": "A 2011 RET trial with facial recognition cameras installed on trams ensured that people who were banned from the city's trams still did not escape.", "token2charspan": [[0, 1], [2, 6], [7, 10], [11, 16], [17, 21], [22, 28], [29, 40], [41, 48], [49, 58], [59, 61], [62, 67], [68, 75], [76, 80], [81, 87], [88, 91], [92, 96], [97, 103], [104, 108], [109, 112], [113, 117], [117, 119], [120, 125], [126, 131], [132, 135], [136, 139], [140, 146], [146, 147]]}
{"doc_key": "ai-test-377", "ner": [[6, 8, "person"], [10, 10, "organisation"], [18, 19, "person"], [21, 24, "person"], [26, 27, "person"], [29, 30, "person"], [32, 33, "person"], [35, 36, "person"], [38, 39, "person"], [41, 42, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[6, 8, 10, 10, "role", "works_for", false, false], [18, 19, 10, 10, "role", "works_for", false, false], [21, 24, 10, 10, "role", "works_for", false, false], [26, 27, 10, 10, "role", "works_for", false, false], [29, 30, 10, 10, "role", "works_for", false, false], [32, 33, 10, 10, "role", "works_for", false, false], [35, 36, 10, 10, "role", "works_for", false, false], [38, 39, 10, 10, "role", "works_for", false, false], [41, 42, 10, 10, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "film", ",", "an", "adaptation", "of", "Cole", "Porter", "'s", "popular", "Broadway", "musical", ",", "starred", "MGM", "'s", "songwriting", "team", "Howard", "Keele", "and", "Katherine", "Grayson", ",", "assisted", "by", "Anna", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Wang", ",", "James", "Whitmore", ",", "Kurt", "Kasnar", "and", "Tommy", "Rall", "."], "sentence-detokenized": "The film, an adaptation of Cole Porter's popular Broadway musical, starred MGM's songwriting team Howard Keele and Katherine Grayson, assisted by Anna Miller, Keenan Wynn, Bobby Wang, James Whitmore, Kurt Kasnar and Tommy Rall.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 12], [13, 23], [24, 26], [27, 31], [32, 38], [38, 40], [41, 48], [49, 57], [58, 65], [65, 66], [67, 74], [75, 78], [78, 80], [81, 92], [93, 97], [98, 104], [105, 110], [111, 114], [115, 124], [125, 132], [132, 133], [134, 142], [143, 145], [146, 150], [151, 157], [157, 158], [159, 165], [166, 170], [170, 171], [172, 177], [178, 182], [182, 183], [184, 189], [190, 198], [198, 199], [200, 204], [205, 211], [212, 215], [216, 221], [222, 226], [226, 227]]}
{"doc_key": "ai-test-378", "ner": [[22, 26, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "applications", "should", "streamline", "call", "flows", ",", "minimise", "the", "number", "of", "prompts", ",", "avoid", "unnecessary", "repetition", "and", "allow", "the", "development", "of", "a", "mixed", "-initiative", "dialogue", "system", "that", "allows", "callers", "to", "enter", "multiple", "pieces", "of", "information", "in", "any", "order", "or", "combination", "in", "a", "single", "utterance", "."], "sentence-detokenized": "Such applications should streamline call flows, minimise the number of prompts, avoid unnecessary repetition and allow the development of a mixed-initiative dialogue system that allows callers to enter multiple pieces of information in any order or combination in a single utterance.", "token2charspan": [[0, 4], [5, 17], [18, 24], [25, 35], [36, 40], [41, 46], [46, 47], [48, 56], [57, 60], [61, 67], [68, 70], [71, 78], [78, 79], [80, 85], [86, 97], [98, 108], [109, 112], [113, 118], [119, 122], [123, 134], [135, 137], [138, 139], [140, 145], [145, 156], [157, 165], [166, 172], [173, 177], [178, 184], [185, 192], [193, 195], [196, 201], [202, 210], [211, 217], [218, 220], [221, 232], [233, 235], [236, 239], [240, 245], [246, 248], [249, 260], [261, 263], [264, 265], [266, 272], [273, 282], [282, 283]]}
{"doc_key": "ai-test-379", "ner": [[6, 7, "algorithm"], [10, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 12, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "adapted", "from", "traditional", "gradient", "descent", "(", "or", "stochastic", "gradient", "descent", ")", "methods", ",", "where", "the", "step", "is", "not", "taken", "in", "the", "direction", "of", "the", "gradient", "of", "the", "function", ",", "but", "in", "the", "direction", "of", "a", "vector", "chosen", "from", "the", "subgradient", "of", "the", "function", "."], "sentence-detokenized": "This can be adapted from traditional gradient descent (or stochastic gradient descent) methods, where the step is not taken in the direction of the gradient of the function, but in the direction of a vector chosen from the subgradient of the function.", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 19], [20, 24], [25, 36], [37, 45], [46, 53], [54, 55], [55, 57], [58, 68], [69, 77], [78, 85], [85, 86], [87, 94], [94, 95], [96, 101], [102, 105], [106, 110], [111, 113], [114, 117], [118, 123], [124, 126], [127, 130], [131, 140], [141, 143], [144, 147], [148, 156], [157, 159], [160, 163], [164, 172], [172, 173], [174, 177], [178, 180], [181, 184], [185, 194], [195, 197], [198, 199], [200, 206], [207, 213], [214, 218], [219, 222], [223, 234], [235, 237], [238, 241], [242, 250], [250, 251]]}
{"doc_key": "ai-test-380", "ner": [[10, 13, "metrics"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "distortion", "is", "assumed", "to", "be", "measured", "by", "the", "root", "mean", "square", "error", ",", "then", "the", "distortion", "D", "is", "determined", ":"], "sentence-detokenized": "If the distortion is assumed to be measured by the root mean square error, then the distortion D is determined:", "token2charspan": [[0, 2], [3, 6], [7, 17], [18, 20], [21, 28], [29, 31], [32, 34], [35, 43], [44, 46], [47, 50], [51, 55], [56, 60], [61, 67], [68, 73], [73, 74], [75, 79], [80, 83], [84, 94], [95, 96], [97, 99], [100, 110], [110, 111]]}
{"doc_key": "ai-test-381", "ner": [[4, 4, "algorithm"], [8, 9, "field"], [19, 20, "task"], [22, 23, "task"], [25, 26, "task"], [29, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 8, 9, "part-of", "", false, false], [19, 20, 4, 4, "part-of", "", false, false], [22, 23, 4, 4, "part-of", "", false, false], [25, 26, 4, 4, "part-of", "", false, false], [29, 29, 4, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "1980s", ",", "MLP", "was", "a", "popular", "machine", "learning", "solution", "that", "was", "used", "in", "various", "fields", "such", "as", "speech", "recognition", ",", "image", "recognition", "and", "machine", "translation", "software", ",", "neural", "networks", "."], "sentence-detokenized": "In the 1980s, MLP was a popular machine learning solution that was used in various fields such as speech recognition, image recognition and machine translation software, neural networks.", "token2charspan": [[0, 2], [3, 6], [7, 12], [12, 13], [14, 17], [18, 21], [22, 23], [24, 31], [32, 39], [40, 48], [49, 57], [58, 62], [63, 66], [67, 71], [72, 74], [75, 82], [83, 89], [90, 94], [95, 97], [98, 104], [105, 116], [116, 117], [118, 123], [124, 135], [136, 139], [140, 147], [148, 159], [160, 168], [168, 169], [170, 176], [177, 185], [185, 186]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [3, 3, "misc"], [4, 9, "university"], [11, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 9, "physical", "", false, false], [0, 0, 4, 9, "role", "", false, false], [3, 3, 0, 0, "origin", "", false, false], [11, 17, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "received", "his", "PhD", "from", "the", "University", "of", "Toronto", "in", "1979", "under", "the", "supervision", "of", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen received his PhD from the University of Toronto in 1979 under the supervision of C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 22], [23, 27], [28, 31], [32, 42], [43, 45], [46, 53], [54, 56], [57, 61], [62, 67], [68, 71], [72, 83], [84, 86], [87, 89], [90, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [5, 7, "field"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [19, 19, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 7, "related-to", "supports", false, false], [10, 10, 5, 7, "type-of", "", true, false], [12, 12, 5, 7, "type-of", "", true, false], [14, 14, 5, 7, "type-of", "", true, false], [14, 14, 19, 19, "related-to", "converting_to", true, false], [23, 23, 5, 7, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["OpenCV", "supports", "some", "models", "from", "deep", "learning", "systems", "such", "as", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "after", "conversion", "to", "ONNX", "model", ")", "and", "Caffe", "according", "to", "a", "defined", "list", "of", "supported", "layers", "."], "sentence-detokenized": "OpenCV supports some models from deep learning systems such as TensorFlow, Torch, PyTorch (after conversion to ONNX model) and Caffe according to a defined list of supported layers.", "token2charspan": [[0, 6], [7, 15], [16, 20], [21, 27], [28, 32], [33, 37], [38, 46], [47, 54], [55, 59], [60, 62], [63, 73], [73, 74], [75, 80], [80, 81], [82, 89], [90, 91], [91, 96], [97, 107], [108, 110], [111, 115], [116, 121], [121, 122], [123, 126], [127, 132], [133, 142], [143, 145], [146, 147], [148, 155], [156, 160], [161, 163], [164, 173], [174, 180], [180, 181]]}
{"doc_key": "ai-test-384", "ner": [[2, 4, "researcher"], [9, 12, "organisation"], [14, 14, "organisation"], [22, 28, "organisation"], [20, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 9, 12, "role", "", false, false], [2, 4, 22, 28, "role", "", false, false], [2, 4, 20, 21, "related-to", "lectures_in", false, false], [14, 14, 9, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Previously", ",", "Kristensen", "was", "a", "founding", "member", "of", "the", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "and", "a", "Distinguished", "Lecturer", "in", "Robotics", "at", "the", "IEEE", "Robotics", "and", "Automation", "Society", "."], "sentence-detokenized": "Previously, Kristensen was a founding member of the European Robotics Research Network (EURON) and a Distinguished Lecturer in Robotics at the IEEE Robotics and Automation Society.", "token2charspan": [[0, 10], [10, 11], [12, 22], [23, 26], [27, 28], [29, 37], [38, 44], [45, 47], [48, 51], [52, 60], [61, 69], [70, 78], [79, 86], [87, 88], [88, 93], [93, 94], [95, 98], [99, 100], [101, 114], [115, 123], [124, 126], [127, 135], [136, 138], [139, 142], [143, 147], [148, 156], [157, 160], [161, 171], [172, 179], [179, 180]]}
{"doc_key": "ai-test-385", "ner": [[9, 10, "field"], [11, 15, "university"], [16, 17, "location"], [19, 25, "country"], [29, 29, "misc"], [30, 32, "field"], [33, 38, "organisation"], [34, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 15, 16, 17, "physical", "", false, false], [16, 17, 19, 25, "physical", "", false, false], [29, 29, 30, 32, "topic", "", false, false], [33, 38, 34, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "1958", ",", "he", "obtained", "a", "master", "'s", "degree", "in", "mathematics", "from", "the", "Samarkand", "State", "University", "in", "Samarkand", ",", "Soviet", "Socialist", "Republic", "of", "Uzbekistan", ",", "and", "in", "1964", "a", "doctorate", "in", "statistics", "from", "the", "Moscow", "Institute", "of", "Management", "Sciences", "."], "sentence-detokenized": "In 1958, he obtained a master's degree in mathematics from the Samarkand State University in Samarkand, Soviet Socialist Republic of Uzbekistan, and in 1964 a doctorate in statistics from the Moscow Institute of Management Sciences.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 20], [21, 22], [23, 29], [29, 31], [32, 38], [39, 41], [42, 53], [54, 58], [59, 62], [63, 72], [73, 78], [79, 89], [90, 92], [93, 102], [102, 103], [104, 110], [111, 120], [121, 129], [130, 132], [133, 143], [143, 144], [145, 148], [149, 151], [152, 156], [157, 158], [159, 168], [169, 171], [172, 182], [183, 187], [188, 191], [192, 198], [199, 208], [209, 211], [212, 222], [223, 231], [231, 232]]}
{"doc_key": "ai-test-386", "ner": [[3, 4, "organisation"], [11, 13, "product"], [31, 32, "field"], [34, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 31, 32, "usage", "", false, false], [3, 4, 34, 36, "usage", "", false, false], [11, 13, 3, 4, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "increasingly", "Cycorp", "'s", "work", "is", "about", "the", "ability", "of", "the", "Cyc", "system", "to", "communicate", "with", "end-users", "in", "natural", "language", "and", "to", "assist", "in", "the", "continuous", "knowledge", "creation", "process", "through", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "However, increasingly Cycorp's work is about the ability of the Cyc system to communicate with end-users in natural language and to assist in the continuous knowledge creation process through machine learning and natural language understanding.", "token2charspan": [[0, 7], [7, 8], [9, 21], [22, 28], [28, 30], [31, 35], [36, 38], [39, 44], [45, 48], [49, 56], [57, 59], [60, 63], [64, 67], [68, 74], [75, 77], [78, 89], [90, 94], [95, 104], [105, 107], [108, 115], [116, 124], [125, 128], [129, 131], [132, 138], [139, 141], [142, 145], [146, 156], [157, 166], [167, 175], [176, 183], [184, 191], [192, 199], [200, 208], [209, 212], [213, 220], [221, 229], [230, 243], [243, 244]]}
{"doc_key": "ai-test-387", "ner": [[53, 53, "metrics"], [55, 55, "metrics"], [57, 57, "metrics"], [59, 62, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "when", "looking", "for", "the", "most", "appropriate", "classifier", "for", "a", "problem", ",", "the", "training", "dataset", "is", "used", "to", "train", "candidate", "algorithms", ",", "the", "validation", "dataset", "is", "used", "to", "compare", "their", "performance", "and", "decide", "which", "one", "to", "choose", ",", "and", "finally", "the", "test", "dataset", "is", "used", "to", "obtain", "performance", "characteristics", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", ",", "F-", "measure", ",", "etc", "."], "sentence-detokenized": "For example, when looking for the most appropriate classifier for a problem, the training dataset is used to train candidate algorithms, the validation dataset is used to compare their performance and decide which one to choose, and finally the test dataset is used to obtain performance characteristics such as accuracy, sensitivity, specificity, F-measure, etc.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [18, 25], [26, 29], [30, 33], [34, 38], [39, 50], [51, 61], [62, 65], [66, 67], [68, 75], [75, 76], [77, 80], [81, 89], [90, 97], [98, 100], [101, 105], [106, 108], [109, 114], [115, 124], [125, 135], [135, 136], [137, 140], [141, 151], [152, 159], [160, 162], [163, 167], [168, 170], [171, 178], [179, 184], [185, 196], [197, 200], [201, 207], [208, 213], [214, 217], [218, 220], [221, 227], [227, 228], [229, 232], [233, 240], [241, 244], [245, 249], [250, 257], [258, 260], [261, 265], [266, 268], [269, 275], [276, 287], [288, 303], [304, 308], [309, 311], [312, 320], [320, 321], [322, 333], [333, 334], [335, 346], [346, 347], [348, 350], [350, 357], [357, 358], [359, 362], [362, 363]]}
{"doc_key": "ai-test-388", "ner": [[0, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "root", "mean", "square", "error", "is", "0.15", "."], "sentence-detokenized": "The root mean square error is 0.15.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 20], [21, 26], [27, 29], [30, 34], [34, 35]]}
{"doc_key": "ai-test-389", "ner": [[7, 12, "misc"], [0, 4, "organisation"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 7, 12, "role", "", false, false], [15, 16, 7, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1979", ",", "the", "IEEE", "held", "a", "micro", "-mile", "competition", ",", "which", "was", "featured", "in", "Spectrum", "magazine", "."], "sentence-detokenized": "In 1979, the IEEE held a micro-mile competition, which was featured in Spectrum magazine.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 22], [23, 24], [25, 30], [30, 35], [36, 47], [47, 48], [49, 54], [55, 58], [59, 67], [68, 70], [71, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-390", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [11, 13, "task"], [15, 16, "task"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 7, "part-of", "", false, false], [11, 13, 6, 7, "part-of", "task_part_of_field", false, false], [15, 16, 6, 7, "part-of", "task_part_of_field", false, false], [18, 19, 6, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Gabor", "space", "is", "very", "useful", "in", "image", "processing", "applications", "such", "as", "optical", "character", "recognition", ",", "iris", "recognition", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "Gabor space is very useful in image processing applications such as optical character recognition, iris recognition and fingerprint recognition.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 19], [20, 26], [27, 29], [30, 35], [36, 46], [47, 59], [60, 64], [65, 67], [68, 75], [76, 85], [86, 97], [97, 98], [99, 103], [104, 115], [116, 119], [120, 131], [132, 143], [143, 144]]}
{"doc_key": "ai-test-391", "ner": [[7, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "using", "high", "-", "level", "interfaces", "with", "Java", "and", "Tcl", "."], "sentence-detokenized": "or using high-level interfaces with Java and Tcl.", "token2charspan": [[0, 2], [3, 8], [9, 13], [13, 14], [14, 19], [20, 30], [31, 35], [36, 40], [41, 44], [45, 48], [48, 49]]}
{"doc_key": "ai-test-392", "ner": [[10, 11, "algorithm"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "recent", "studies", ",", "kernel", "-", "based", "methods", "such", "as", "support", "vector", "machines", "have", "shown", "superior", "performance", "in", "monitoring", "."], "sentence-detokenized": "In recent studies, kernel-based methods such as support vector machines have shown superior performance in monitoring.", "token2charspan": [[0, 2], [3, 9], [10, 17], [17, 18], [19, 25], [25, 26], [26, 31], [32, 39], [40, 44], [45, 47], [48, 55], [56, 62], [63, 71], [72, 76], [77, 82], [83, 91], [92, 103], [104, 106], [107, 117], [117, 118]]}
{"doc_key": "ai-test-393", "ner": [[14, 14, "misc"], [23, 23, "researcher"], [25, 25, "researcher"], [32, 32, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 32, 32, "usage", "", false, false], [25, 25, 32, 32, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "illustrate", "the", "basic", "principles", "of", "bagging", ",", "an", "analysis", "of", "the", "relationship", "between", "ozone", "and", "temperature", "is", "presented", "below", "(", "data", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "analysed", "in", "R", ")", "."], "sentence-detokenized": "To illustrate the basic principles of bagging, an analysis of the relationship between ozone and temperature is presented below (data from Rousseeuw and Leroy (1986), analysed in R).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 34], [35, 37], [38, 45], [45, 46], [47, 49], [50, 58], [59, 61], [62, 65], [66, 78], [79, 86], [87, 92], [93, 96], [97, 108], [109, 111], [112, 121], [122, 127], [128, 129], [129, 133], [134, 138], [139, 148], [149, 152], [153, 158], [159, 160], [160, 164], [164, 165], [165, 166], [167, 175], [176, 178], [179, 180], [180, 181], [181, 182]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [11, 11, "product"], [18, 19, "product"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 0, 1, "artifact", "", false, false], [18, 19, 0, 1, "artifact", "", false, false], [21, 23, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Denso", "Wave", "is", "a", "subsidiary", "that", "manufactures", "automatic", "identification", "products", "(", "barcode", "readers", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "Denso Wave is a subsidiary that manufactures automatic identification products (barcode readers and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 15], [16, 26], [27, 31], [32, 44], [45, 54], [55, 69], [70, 78], [79, 80], [80, 87], [88, 95], [96, 99], [100, 107], [108, 116], [116, 117], [117, 118], [119, 129], [130, 136], [137, 140], [141, 153], [154, 159], [160, 171], [171, 172]]}
{"doc_key": "ai-test-395", "ner": [[2, 4, "metrics"], [8, 12, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 4, 20, 20, "compare", "", false, false], [8, 12, 2, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "the", "bilingual", "evaluation", "study", "simply", "calculates", "the", "accuracy", "of", "the", "n-grammes", "by", "giving", "each", "one", "the", "same", "weight", ",", "NIST", "also", "calculates", "how", "informative", "a", "given", "n-", "gramme", "is", "."], "sentence-detokenized": "If the bilingual evaluation study simply calculates the accuracy of the n-grammes by giving each one the same weight, NIST also calculates how informative a given n-gramme is.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 27], [28, 33], [34, 40], [41, 51], [52, 55], [56, 64], [65, 67], [68, 71], [72, 81], [82, 84], [85, 91], [92, 96], [97, 100], [101, 104], [105, 109], [110, 116], [116, 117], [118, 122], [123, 127], [128, 138], [139, 142], [143, 154], [155, 156], [157, 162], [163, 165], [165, 171], [172, 174], [174, 175]]}
{"doc_key": "ai-test-396", "ner": [[11, 11, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "particular", ",", "they", "are", "used", "to", "calculate", "tree", "probabilities", "(", "Bayesian", "and", "maximum", "likelihood", "approaches", "to", "tree", "estimation", ")", "and", "they", "are", "used", "to", "estimate", "the", "evolutionary", "distance", "between", "sequences", "based", "on", "the", "observed", "differences", "between", "sequences", "."], "sentence-detokenized": "In particular, they are used to calculate tree probabilities (Bayesian and maximum likelihood approaches to tree estimation) and they are used to estimate the evolutionary distance between sequences based on the observed differences between sequences.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 46], [47, 60], [61, 62], [62, 70], [71, 74], [75, 82], [83, 93], [94, 104], [105, 107], [108, 112], [113, 123], [123, 124], [125, 128], [129, 133], [134, 137], [138, 142], [143, 145], [146, 154], [155, 158], [159, 171], [172, 180], [181, 188], [189, 198], [199, 204], [205, 207], [208, 211], [212, 220], [221, 232], [233, 240], [241, 250], [250, 251]]}
{"doc_key": "ai-test-397", "ner": [[0, 4, "conference"], [20, 22, "misc"], [24, 24, "misc"], [41, 48, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[24, 24, 20, 22, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Society", "of", "Audio", "Engineers", "recommends", "a", "sampling", "frequency", "of", "48", "kHz", "for", "most", "applications", ",", "but", "recognises", "44.1", "kHz", "for", "compact", "disc", "(", "CD", ")", "and", "other", "consumer", "applications", ",", "32", "kHz", "for", "transmission", "-", "related", "applications", "and", "96", "kHz", "for", "higher", "bandwidth", "or", "relaxed", "equalisation", "filter", "applications", "."], "sentence-detokenized": "The Society of Audio Engineers recommends a sampling frequency of 48 kHz for most applications, but recognises 44.1 kHz for compact disc (CD) and other consumer applications, 32 kHz for transmission-related applications and 96 kHz for higher bandwidth or relaxed equalisation filter applications.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 20], [21, 30], [31, 41], [42, 43], [44, 52], [53, 62], [63, 65], [66, 68], [69, 72], [73, 76], [77, 81], [82, 94], [94, 95], [96, 99], [100, 110], [111, 115], [116, 119], [120, 123], [124, 131], [132, 136], [137, 138], [138, 140], [140, 141], [142, 145], [146, 151], [152, 160], [161, 173], [173, 174], [175, 177], [178, 181], [182, 185], [186, 198], [198, 199], [199, 206], [207, 219], [220, 223], [224, 226], [227, 230], [231, 234], [235, 241], [242, 251], [252, 254], [255, 262], [263, 275], [276, 282], [283, 295], [295, 296]]}
{"doc_key": "ai-test-398", "ner": [[9, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Word", "and", "concept", "affectivity", "resources", "have", "been", "created", "in", "WordNet", "{", "{{", "cite", "journal"], "sentence-detokenized": "Word and concept affectivity resources have been created in WordNet {{{cite journal", "token2charspan": [[0, 4], [5, 8], [9, 16], [17, 28], [29, 38], [39, 43], [44, 48], [49, 56], [57, 59], [60, 67], [68, 69], [69, 71], [71, 75], [76, 83]]}
{"doc_key": "ai-test-399", "ner": [[0, 6, "misc"], [18, 19, "person"], [24, 27, "person"], [32, 33, "person"], [36, 39, "organisation"], [60, 61, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[24, 27, 32, 33, "role", "acts_in", false, false], [36, 39, 32, 33, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "red", "and", "green", "anaglyph", "showed", "the", "audience", "three", "test", "reels", "of", "rural", "scenes", ",", "test", "footage", "of", "Marie", "Doro", ",", "an", "excerpt", "of", "John", "B", ".", "Mason", "playing", "several", "excerpts", "from", "Jim", "Penman", "(", "a", "Famous", "Players", "-", "Lasky", "film", "released", "the", "same", "year", "but", "not", "in", "3D", ")", ",", "an", "oriental", "dancer", "and", "a", "reel", "of", "footage", "of", "Niagara", "Falls", "."], "sentence-detokenized": "The red and green anaglyph showed the audience three test reels of rural scenes, test footage of Marie Doro, an excerpt of John B. Mason playing several excerpts from Jim Penman (a Famous Players-Lasky film released the same year but not in 3D), an oriental dancer and a reel of footage of Niagara Falls.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 17], [18, 26], [27, 33], [34, 37], [38, 46], [47, 52], [53, 57], [58, 63], [64, 66], [67, 72], [73, 79], [79, 80], [81, 85], [86, 93], [94, 96], [97, 102], [103, 107], [107, 108], [109, 111], [112, 119], [120, 122], [123, 127], [128, 129], [129, 130], [131, 136], [137, 144], [145, 152], [153, 161], [162, 166], [167, 170], [171, 177], [178, 179], [179, 180], [181, 187], [188, 195], [195, 196], [196, 201], [202, 206], [207, 215], [216, 219], [220, 224], [225, 229], [230, 233], [234, 237], [238, 240], [241, 243], [243, 244], [244, 245], [246, 248], [249, 257], [258, 264], [265, 268], [269, 270], [271, 275], [276, 278], [279, 286], [287, 289], [290, 297], [298, 303], [303, 304]]}
{"doc_key": "ai-test-400", "ner": [[8, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "specific", "way", "of", "implementing", "the", "maximum", "likelihood", "assessment", "for", "this", "problem", "."], "sentence-detokenized": "This is a specific way of implementing the maximum likelihood assessment for this problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 18], [19, 22], [23, 25], [26, 38], [39, 42], [43, 50], [51, 61], [62, 72], [73, 76], [77, 81], [82, 89], [89, 90]]}
{"doc_key": "ai-test-401", "ner": [[0, 9, "product"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Web", "servers", "that", "are", "web", "-", "browser", "friendly", "and", "integrate", "site", "maps", "and", "RSS", "feeds", "into", "a", "decentralised", "mechanism", "for", "computational", "biologists", "and", "bioinformaticians", "to", "openly", "transmit", "and", "extract", "metadata", "about", "biomedical", "resources", "."], "sentence-detokenized": "Web servers that are web-browser friendly and integrate site maps and RSS feeds into a decentralised mechanism for computational biologists and bioinformaticians to openly transmit and extract metadata about biomedical resources.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 20], [21, 24], [24, 25], [25, 32], [33, 41], [42, 45], [46, 55], [56, 60], [61, 65], [66, 69], [70, 73], [74, 79], [80, 84], [85, 86], [87, 100], [101, 110], [111, 114], [115, 128], [129, 139], [140, 143], [144, 161], [162, 164], [165, 171], [172, 180], [181, 184], [185, 192], [193, 201], [202, 207], [208, 218], [219, 228], [228, 229]]}
{"doc_key": "ai-test-402", "ner": [[5, 12, "misc"], [15, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "covered", "by", "the", "American", "National", "Standards", "Institute", "/", "NISO", "standard", "Z39.50", "and", "the", "International", "Organization", "for", "Standardization", "standard", "23950", "."], "sentence-detokenized": "It is covered by the American National Standards Institute / NISO standard Z39.50 and the International Organization for Standardization standard 23950.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 20], [21, 29], [30, 38], [39, 48], [49, 58], [59, 60], [61, 65], [66, 74], [75, 81], [82, 85], [86, 89], [90, 103], [104, 116], [117, 120], [121, 136], [137, 145], [146, 151], [151, 152]]}
{"doc_key": "ai-test-403", "ner": [[18, 24, "misc"], [27, 27, "metrics"], [12, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "encoder", "and", "decoder", "are", "trained", "to", "take", "a", "phrase", "using", "simple", "stochastic", "gradient", "descent", "and", "to", "reproduce", "a", "single", "split", "of", "the", "corresponding", "paraphrase", ",", "minimising", "perplexity", "."], "sentence-detokenized": "The encoder and decoder are trained to take a phrase using simple stochastic gradient descent and to reproduce a single split of the corresponding paraphrase, minimising perplexity.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 45], [46, 52], [53, 58], [59, 65], [66, 76], [77, 85], [86, 93], [94, 97], [98, 100], [101, 110], [111, 112], [113, 119], [120, 125], [126, 128], [129, 132], [133, 146], [147, 157], [157, 158], [159, 169], [170, 180], [180, 181]]}
{"doc_key": "ai-test-404", "ner": [[5, 5, "field"], [8, 10, "task"], [12, 16, "task"], [26, 30, "task"], [32, 37, "task"], [39, 45, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 10, 5, 5, "part-of", "task_part_of_field", false, false], [12, 16, 5, 5, "part-of", "task_part_of_field", false, false], [26, 30, 5, 5, "part-of", "task_part_of_field", false, false], [32, 37, 5, 5, "part-of", "task_part_of_field", false, false], [39, 45, 5, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "typical", "applications", "of", "pattern", "recognition", "techniques", "include", "automatic", "speech", "recognition", ",", "text", "classification", "into", "multiple", "categories", "(", "e.g.", "spam", "/", "non", "-spam", "emails", ")", ",", "handwriting", "recognition", "on", "postal", "envelopes", ",", "automatic", "recognition", "of", "human", "facial", "images", "or", "extraction", "of", "handwritten", "images", "from", "medical", "forms", "."], "sentence-detokenized": "Other typical applications of pattern recognition techniques include automatic speech recognition, text classification into multiple categories (e.g. spam/non-spam emails), handwriting recognition on postal envelopes, automatic recognition of human facial images or extraction of handwritten images from medical forms.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 29], [30, 37], [38, 49], [50, 60], [61, 68], [69, 78], [79, 85], [86, 97], [97, 98], [99, 103], [104, 118], [119, 123], [124, 132], [133, 143], [144, 145], [145, 149], [150, 154], [154, 155], [155, 158], [158, 163], [164, 170], [170, 171], [171, 172], [173, 184], [185, 196], [197, 199], [200, 206], [207, 216], [216, 217], [218, 227], [228, 239], [240, 242], [243, 248], [249, 255], [256, 262], [263, 265], [266, 276], [277, 279], [280, 291], [292, 298], [299, 303], [304, 311], [312, 317], [317, 318]]}
{"doc_key": "ai-test-405", "ner": [[0, 2, "algorithm"], [12, 13, "field"], [15, 16, "task"], [18, 19, "task"], [21, 23, "task"], [25, 28, "task"], [30, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 13, 0, 2, "usage", "", false, false], [15, 16, 0, 2, "usage", "", false, false], [18, 19, 0, 2, "usage", "", false, false], [21, 23, 0, 2, "usage", "", false, false], [25, 28, 0, 2, "usage", "", false, false], [30, 31, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Artificial", "neural", "networks", "have", "been", "used", "in", "a", "variety", "of", "tasks", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "board", "and", "video", "gaming", "and", "medical", "diagnostics", "."], "sentence-detokenized": "Artificial neural networks have been used in a variety of tasks including computer vision, speech recognition, machine translation, social network filtering, board and video gaming and medical diagnostics.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 36], [37, 41], [42, 44], [45, 46], [47, 54], [55, 57], [58, 63], [64, 73], [74, 82], [83, 89], [89, 90], [91, 97], [98, 109], [109, 110], [111, 118], [119, 130], [130, 131], [132, 138], [139, 146], [147, 156], [156, 157], [158, 163], [164, 167], [168, 173], [174, 180], [181, 184], [185, 192], [193, 204], [204, 205]]}
{"doc_key": "ai-test-406", "ner": [[3, 4, "organisation"], [5, 5, "product"], [15, 15, "product"], [19, 19, "organisation"], [20, 21, "product"], [23, 23, "product"], [25, 27, "product"], [29, 29, "product"], [31, 31, "programlang"], [39, 41, "field"], [44, 44, "product"], [48, 48, "algorithm"], [50, 50, "algorithm"], [52, 52, "algorithm"], [56, 56, "product"], [63, 64, "task"], [69, 70, "algorithm"], [74, 74, "product"], [76, 76, "product"], [78, 80, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[5, 5, 3, 4, "origin", "", false, false], [5, 5, 15, 15, "named", "same", false, false], [5, 5, 44, 44, "named", "same", false, false], [31, 31, 39, 41, "related-to", "used_for", false, false], [48, 48, 31, 31, "part-of", "", true, false], [48, 48, 44, 44, "origin", "", true, false], [50, 50, 31, 31, "part-of", "", true, false], [50, 50, 44, 44, "origin", "", true, false], [52, 52, 31, 31, "part-of", "", true, false], [52, 52, 44, 44, "origin", "", true, false], [56, 56, 63, 64, "related-to", "used_for", false, false], [69, 70, 56, 56, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["For", "example", ",", "Salford", "Systems", "CART", "(", "which", "licensed", "the", "proprietary", "code", "of", "the", "original", "CART", "authors", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "source", "software", "environment", "for", "statistical", "computing", "that", "includes", "several", "CART", "implementations", "such", "as", "rpart", ",", "party", "and", "randomForest", "packages", ")", ",", "Weka", "(", "a", "free", "and", "open", "source", "data", "mining", "suite", "that", "includes", "many", "decision", "tree", "algorithms", ")", ",", "Orange", ",", "KNIME", ",", "Microsoft", "SQL", "Server", "programming", "language", ")", "."], "sentence-detokenized": "For example, Salford Systems CART (which licensed the proprietary code of the original CART authors), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open source software environment for statistical computing that includes several CART implementations such as rpart, party and randomForest packages), Weka (a free and open source data mining suite that includes many decision tree algorithms), Orange, KNIME, Microsoft SQL Server programming language).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 20], [21, 28], [29, 33], [34, 35], [35, 40], [41, 49], [50, 53], [54, 65], [66, 70], [71, 73], [74, 77], [78, 86], [87, 91], [92, 99], [99, 100], [100, 101], [102, 105], [106, 110], [111, 118], [118, 119], [120, 130], [130, 131], [132, 135], [136, 146], [147, 152], [152, 153], [154, 160], [160, 161], [162, 163], [164, 165], [165, 167], [168, 172], [173, 179], [180, 188], [189, 200], [201, 204], [205, 216], [217, 226], [227, 231], [232, 240], [241, 248], [249, 253], [254, 269], [270, 274], [275, 277], [278, 283], [283, 284], [285, 290], [291, 294], [295, 307], [308, 316], [316, 317], [317, 318], [319, 323], [324, 325], [325, 326], [327, 331], [332, 335], [336, 340], [341, 347], [348, 352], [353, 359], [360, 365], [366, 370], [371, 379], [380, 384], [385, 393], [394, 398], [399, 409], [409, 410], [410, 411], [412, 418], [418, 419], [420, 425], [425, 426], [427, 436], [437, 440], [441, 447], [448, 459], [460, 468], [468, 469], [469, 470]]}
{"doc_key": "ai-test-407", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [12, 13, "researcher"], [15, 16, "university"], [18, 19, "researcher"], [21, 24, "organisation"], [26, 29, "organisation"], [33, 35, "researcher"], [37, 40, "researcher"], [41, 43, "organisation"], [56, 63, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 12, 13, "origin", "", false, false], [0, 2, 18, 19, "origin", "", false, false], [0, 2, 33, 35, "origin", "", false, false], [0, 2, 37, 40, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [12, 13, 15, 16, "physical", "", false, false], [12, 13, 15, 16, "role", "", false, false], [18, 19, 21, 24, "physical", "", false, false], [18, 19, 21, 24, "role", "", false, false], [26, 29, 21, 24, "named", "", false, false], [33, 35, 41, 43, "physical", "", false, false], [33, 35, 41, 43, "role", "", false, false], [37, 40, 41, 43, "physical", "", false, false], [37, 40, 41, 43, "role", "", false, false], [56, 63, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Linear", "Predicative", "Coding", "(", "LPC", ")", "was", "first", "developed", "in", "1966", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", ",", "and", "further", "developed", "by", "Bishnu", "S.", "Atal", "and", "Manfred", "R.", "Schroeder", "of", "Bell", "Labs", "in", "the", "early", "and", "mid-1970s", ",", "and", "became", "the", "basis", "for", "the", "first", "speech", "synthesiser", "DSP", "chips", "in", "the", "late", "1970s", "."], "sentence-detokenized": "Linear Predicative Coding (LPC) was first developed in 1966 by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT), and further developed by Bishnu S. Atal and Manfred R. Schroeder of Bell Labs in the early and mid-1970s, and became the basis for the first speech synthesiser DSP chips in the late 1970s.", "token2charspan": [[0, 6], [7, 18], [19, 25], [26, 27], [27, 30], [30, 31], [32, 35], [36, 41], [42, 51], [52, 54], [55, 59], [60, 62], [63, 71], [72, 79], [80, 82], [83, 89], [90, 100], [101, 104], [105, 110], [111, 116], [117, 119], [120, 126], [127, 136], [137, 140], [141, 150], [151, 152], [152, 155], [155, 156], [156, 157], [158, 161], [162, 169], [170, 179], [180, 182], [183, 189], [190, 192], [193, 197], [198, 201], [202, 209], [210, 212], [213, 222], [223, 225], [226, 230], [231, 235], [236, 238], [239, 242], [243, 248], [249, 252], [253, 262], [262, 263], [264, 267], [268, 274], [275, 278], [279, 284], [285, 288], [289, 292], [293, 298], [299, 305], [306, 317], [318, 321], [322, 327], [328, 330], [331, 334], [335, 339], [340, 345], [345, 346]]}
{"doc_key": "ai-test-408", "ner": [[0, 3, "metrics"], [8, 8, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 0, 3, "part-of", "", false, false], [10, 10, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "F", "-", "score", "is", "the", "combination", "of", "precision", "and", "recall", ",", "which", "form", "a", "single", "score", "."], "sentence-detokenized": "The F-score is the combination of precision and recall, which form a single score.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 18], [19, 30], [31, 33], [34, 43], [44, 47], [48, 54], [54, 55], [56, 61], [62, 66], [67, 68], [69, 75], [76, 81], [81, 82]]}
{"doc_key": "ai-test-409", "ner": [[0, 1, "field"], [8, 12, "task"], [18, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 12, 0, 1, "part-of", "task_part_of_field", false, false], [18, 20, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Image", "analysis", "tasks", "can", "be", "as", "simple", "as", "reading", "a", "barcode", "d", "tag", "or", "as", "complex", "as", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Image analysis tasks can be as simple as reading a barcode d tag or as complex as a facial recognition system.", "token2charspan": [[0, 5], [6, 14], [15, 20], [21, 24], [25, 27], [28, 30], [31, 37], [38, 40], [41, 48], [49, 50], [51, 58], [59, 60], [61, 64], [65, 67], [68, 70], [71, 78], [79, 81], [82, 83], [84, 90], [91, 102], [103, 109], [109, 110]]}
{"doc_key": "ai-test-410", "ner": [[5, 7, "algorithm"], [25, 26, "algorithm"], [33, 37, "algorithm"], [38, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[33, 37, 25, 26, "type-of", "", false, false], [38, 38, 33, 37, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "special", "case", "of", "linear", "support", "vector", "machines", "can", "be", "solved", "more", "efficiently", "by", "the", "same", "type", "of", "algorithms", "that", "optimise", "its", "close", "relative", ",", "logistic", "regression", ";", "this", "class", "of", "algorithms", "includes", "stochastic", "gradient", "descent", "(", "e.g.", "PEGASOS", ")", "."], "sentence-detokenized": "The special case of linear support vector machines can be solved more efficiently by the same type of algorithms that optimise its close relative, logistic regression; this class of algorithms includes stochastic gradient descent (e.g. PEGASOS).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 34], [35, 41], [42, 50], [51, 54], [55, 57], [58, 64], [65, 69], [70, 81], [82, 84], [85, 88], [89, 93], [94, 98], [99, 101], [102, 112], [113, 117], [118, 126], [127, 130], [131, 136], [137, 145], [145, 146], [147, 155], [156, 166], [166, 167], [168, 172], [173, 178], [179, 181], [182, 192], [193, 201], [202, 212], [213, 221], [222, 229], [230, 231], [231, 235], [236, 243], [243, 244], [244, 245]]}
{"doc_key": "ai-test-411", "ner": [[1, 1, "product"], [3, 5, "product"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 3, 5, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["When", "Siri", "on", "iOS", "asks", "the", "question", "Do", "you", "have", "a", "pet", "?", ",", "one", "of", "the", "answers", "is", "\"", "I", "used", "to", "have", "an", "AIBO", "\"", "."], "sentence-detokenized": "When Siri on iOS asks the question Do you have a pet?, one of the answers is \"I used to have an AIBO\".", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 16], [17, 21], [22, 25], [26, 34], [35, 37], [38, 41], [42, 46], [47, 48], [49, 52], [52, 53], [53, 54], [55, 58], [59, 61], [62, 65], [66, 73], [74, 76], [77, 78], [78, 79], [80, 84], [85, 87], [88, 92], [93, 95], [96, 100], [100, 101], [101, 102]]}
{"doc_key": "ai-test-412", "ner": [[0, 2, "task"], [4, 7, "metrics"], [10, 10, "metrics"], [12, 12, "metrics"], [15, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 7, 0, 2, "part-of", "", false, false], [10, 10, 4, 7, "named", "", false, false], [12, 12, 0, 2, "part-of", "", false, false], [15, 15, 12, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "information", "retrieval", ",", "a", "positive", "predictive", "value", "is", "called", "precision", "and", "sensitivity", "is", "called", "recall", "."], "sentence-detokenized": "In information retrieval, a positive predictive value is called precision and sensitivity is called recall.", "token2charspan": [[0, 2], [3, 14], [15, 24], [24, 25], [26, 27], [28, 36], [37, 47], [48, 53], [54, 56], [57, 63], [64, 73], [74, 77], [78, 89], [90, 92], [93, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-413", "ner": [[10, 11, "field"], [13, 13, "task"], [15, 15, "task"], [17, 18, "task"], [33, 34, "task"], [36, 37, "task"], [39, 43, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 13, 10, 11, "part-of", "task_part_of_field", false, false], [15, 15, 10, 11, "part-of", "task_part_of_field", false, false], [17, 18, 10, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "particular", ",", "his", "research", "focused", "on", "areas", "such", "as", "text", "mining", "(", "extraction", ",", "categorisation", ",", "novelty", "detection", ")", "and", "new", "theoretical", "frameworks", "such", "as", "a", "unified", "utility", "-", "based", "theory", "combining", "information", "retrieval", ",", "automatic", "summarisation", ",", "free", "-", "text", "question", "answering", "and", "related", "tasks", "."], "sentence-detokenized": "In particular, his research focused on areas such as text mining (extraction, categorisation, novelty detection) and new theoretical frameworks such as a unified utility-based theory combining information retrieval, automatic summarisation, free-text question answering and related tasks.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 27], [28, 35], [36, 38], [39, 44], [45, 49], [50, 52], [53, 57], [58, 64], [65, 66], [66, 76], [76, 77], [78, 92], [92, 93], [94, 101], [102, 111], [111, 112], [113, 116], [117, 120], [121, 132], [133, 143], [144, 148], [149, 151], [152, 153], [154, 161], [162, 169], [169, 170], [170, 175], [176, 182], [183, 192], [193, 204], [205, 214], [214, 215], [216, 225], [226, 239], [239, 240], [241, 245], [245, 246], [246, 250], [251, 259], [260, 269], [270, 273], [274, 281], [282, 287], [287, 288]]}
{"doc_key": "ai-test-414", "ner": [[0, 1, "product"], [8, 10, "product"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 0, 1, "part-of", "", false, false], [16, 17, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Delta", "robots", "are", "equipped", "with", "base", "-", "mounted", "rotary", "actuators", "that", "move", "a", "light", ",", "rigid", "parallelogram", "arm", "."], "sentence-detokenized": "Delta robots are equipped with base-mounted rotary actuators that move a light, rigid parallelogram arm.", "token2charspan": [[0, 5], [6, 12], [13, 16], [17, 25], [26, 30], [31, 35], [35, 36], [36, 43], [44, 50], [51, 60], [61, 65], [66, 70], [71, 72], [73, 78], [78, 79], [80, 85], [86, 99], [100, 103], [103, 104]]}
{"doc_key": "ai-test-415", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "mixing", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated in a 2 \u00d7 2 contingency table or mixing matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 73], [74, 80], [81, 83], [84, 91], [91, 92]]}
{"doc_key": "ai-test-416", "ner": [[2, 3, "field"], [30, 31, "task"], [37, 38, "task"], [43, 45, "task"], [47, 49, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[30, 31, 2, 3, "part-of", "task_part_of_field", false, false], [37, 38, 2, 3, "part-of", "task_part_of_field", false, false], [43, 45, 2, 3, "part-of", "task_part_of_field", false, false], [47, 49, 2, 3, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "actual", "data", "mining", "task", "is", "the", "semi-automatic", "or", "automatic", "analysis", "of", "large", "amounts", "of", "data", "to", "extract", "unknown", "patterns", "of", "interest", ",", "such", "as", "groups", "of", "data", "records", "(", "cluster", "analysis", ")", ",", "unusual", "records", "(", "anomaly", "detection", ")", "and", "dependencies", "(", "association", "rule", "extraction", ",", "sequential", "pattern", "extraction", ")", "."], "sentence-detokenized": "The actual data mining task is the semi-automatic or automatic analysis of large amounts of data to extract unknown patterns of interest, such as groups of data records (cluster analysis), unusual records (anomaly detection) and dependencies (association rule extraction, sequential pattern extraction).", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 22], [23, 27], [28, 30], [31, 34], [35, 49], [50, 52], [53, 62], [63, 71], [72, 74], [75, 80], [81, 88], [89, 91], [92, 96], [97, 99], [100, 107], [108, 115], [116, 124], [125, 127], [128, 136], [136, 137], [138, 142], [143, 145], [146, 152], [153, 155], [156, 160], [161, 168], [169, 170], [170, 177], [178, 186], [186, 187], [187, 188], [189, 196], [197, 204], [205, 206], [206, 213], [214, 223], [223, 224], [225, 228], [229, 241], [242, 243], [243, 254], [255, 259], [260, 270], [270, 271], [272, 282], [283, 290], [291, 301], [301, 302], [302, 303]]}
{"doc_key": "ai-test-417", "ner": [[2, 12, "product"], [0, 1, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 12, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sentiment", "analysis", "has", "proven", "to", "be", "a", "valuable", "technique", "for", "the", "recommender", "system", "."], "sentence-detokenized": "Sentiment analysis has proven to be a valuable technique for the recommender system.", "token2charspan": [[0, 9], [10, 18], [19, 22], [23, 29], [30, 32], [33, 35], [36, 37], [38, 46], [47, 56], [57, 60], [61, 64], [65, 76], [77, 83], [83, 84]]}
{"doc_key": "ai-test-418", "ner": [[0, 1, "misc"], [11, 11, "product"], [29, 29, "organisation"], [33, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 11, 11, "usage", "", false, false], [29, 29, 33, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Germans", "had", "inadvertently", "chosen", "a", "very", "poor", "frequency", "for", "the", "Wotan", "system", ";", "it", "operated", "at", "45", "MHz", ",", "exactly", "the", "same", "frequency", "as", "the", "powerful", "but", "non-functioning", "BBC", "television", "transmitter", "at", "Alexandra", "Palace", "."], "sentence-detokenized": "The Germans had inadvertently chosen a very poor frequency for the Wotan system; it operated at 45 MHz, exactly the same frequency as the powerful but non-functioning BBC television transmitter at Alexandra Palace.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 29], [30, 36], [37, 38], [39, 43], [44, 48], [49, 58], [59, 62], [63, 66], [67, 72], [73, 79], [79, 80], [81, 83], [84, 92], [93, 95], [96, 98], [99, 102], [102, 103], [104, 111], [112, 115], [116, 120], [121, 130], [131, 133], [134, 137], [138, 146], [147, 150], [151, 166], [167, 170], [171, 181], [182, 193], [194, 196], [197, 206], [207, 213], [213, 214]]}
{"doc_key": "ai-test-419", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "mixing", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated in a 2 \u00d7 2 contingency table or mixing matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 73], [74, 80], [81, 83], [84, 91], [91, 92]]}
{"doc_key": "ai-test-420", "ner": [[0, 3, "misc"], [7, 7, "misc"], [11, 11, "product"], [13, 13, "product"], [15, 17, "product"], [25, 26, "misc"], [41, 41, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 11, 7, 7, "usage", "", false, false], [13, 13, 7, 7, "usage", "", false, false], [15, 17, 13, 13, "named", "", false, false], [25, 26, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "Semantic", "Web", "applications", "and", "relatively", "popular", "RDF", "applications", "such", "as", "RSS", "and", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "resources", "are", "usually", "represented", "by", "URIs", "that", "are", "targeted", "and", "can", "be", "used", "to", "access", "actual", "data", "on", "the", "World", "Wide", "Web", "."], "sentence-detokenized": "In Semantic Web applications and relatively popular RDF applications such as RSS and FOAF (Friend a Friend), resources are usually represented by URIs that are targeted and can be used to access actual data on the World Wide Web.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 28], [29, 32], [33, 43], [44, 51], [52, 55], [56, 68], [69, 73], [74, 76], [77, 80], [81, 84], [85, 89], [90, 91], [91, 97], [98, 99], [100, 106], [106, 107], [107, 108], [109, 118], [119, 122], [123, 130], [131, 142], [143, 145], [146, 150], [151, 155], [156, 159], [160, 168], [169, 172], [173, 176], [177, 179], [180, 184], [185, 187], [188, 194], [195, 201], [202, 206], [207, 209], [210, 213], [214, 219], [220, 224], [225, 228], [228, 229]]}
{"doc_key": "ai-test-421", "ner": [[0, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "has", "studied", "this", "topic", "in", "depth", "."], "sentence-detokenized": "The Association for the Advancement of Artificial Intelligence has studied this topic in depth.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 74], [75, 79], [80, 85], [86, 88], [89, 94], [94, 95]]}
{"doc_key": "ai-test-422", "ner": [[0, 6, "product"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 0, 6, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Apple", "'s", "Macintosh", "speech", "system", ",", "which", "started", "out", "as", "a", "curiosity", ",", "has", "become", "PlainTalk", ",", "a", "fully", "supported", "programme", "for", "people", "with", "vision", "problems", "."], "sentence-detokenized": "Apple's Macintosh speech system, which started out as a curiosity, has become PlainTalk, a fully supported programme for people with vision problems.", "token2charspan": [[0, 5], [5, 7], [8, 17], [18, 24], [25, 31], [31, 32], [33, 38], [39, 46], [47, 50], [51, 53], [54, 55], [56, 65], [65, 66], [67, 70], [71, 77], [78, 87], [87, 88], [89, 90], [91, 96], [97, 106], [107, 116], [117, 120], [121, 127], [128, 132], [133, 139], [140, 148], [148, 149]]}
{"doc_key": "ai-test-423", "ner": [[5, 5, "field"], [7, 8, "task"], [10, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 5, 5, "part-of", "task_part_of_field", false, false], [10, 11, 5, 5, "part-of", "task_part_of_field", false, false], [13, 14, 5, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "uses", "of", "ontologies", "in", "NLP", "include", "information", "retrieval", ",", "information", "extraction", "and", "automatic", "aggregation", "."], "sentence-detokenized": "Other uses of ontologies in NLP include information retrieval, information extraction and automatic aggregation.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 24], [25, 27], [28, 31], [32, 39], [40, 51], [52, 61], [61, 62], [63, 74], [75, 85], [86, 89], [90, 99], [100, 111], [111, 112]]}
{"doc_key": "ai-test-424", "ner": [[7, 17, "organisation"], [18, 22, "organisation"], [25, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Institute", "has", "worked", "closely", "with", "the", "Janelia", "Farm", "Campus", "of", "the", "Howard", "Hughes", "Medical", "Institute", ",", "the", "Allen", "Institute", "for", "Brain", "Science", "and", "the", "National", "Institutes", "of", "Health", "to", "develop", "better", "methods", "for", "reconstructing", "neural", "architecture", "."], "sentence-detokenized": "The Institute has worked closely with the Janelia Farm Campus of the Howard Hughes Medical Institute, the Allen Institute for Brain Science and the National Institutes of Health to develop better methods for reconstructing neural architecture.", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 24], [25, 32], [33, 37], [38, 41], [42, 49], [50, 54], [55, 61], [62, 64], [65, 68], [69, 75], [76, 82], [83, 90], [91, 100], [100, 101], [102, 105], [106, 111], [112, 121], [122, 125], [126, 131], [132, 139], [140, 143], [144, 147], [148, 156], [157, 167], [168, 170], [171, 177], [178, 180], [181, 188], [189, 195], [196, 203], [204, 207], [208, 222], [223, 229], [230, 242], [242, 243]]}
{"doc_key": "ai-test-425", "ner": [[0, 0, "organisation"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 0, 0, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Google", "recently", "announced", "that", "Google", "Translate", "translates", "about", "enough", "text", "to", "translate", "1", "million", "books", "in", "one", "day", "(", "2012", ")", "."], "sentence-detokenized": "Google recently announced that Google Translate translates about enough text to translate 1 million books in one day (2012).", "token2charspan": [[0, 6], [7, 15], [16, 25], [26, 30], [31, 37], [38, 47], [48, 58], [59, 64], [65, 71], [72, 76], [77, 79], [80, 89], [90, 91], [92, 99], [100, 105], [106, 108], [109, 112], [113, 116], [117, 118], [118, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-test-426", "ner": [[14, 15, "country"], [18, 19, "country"], [21, 21, "country"], [23, 23, "country"], [25, 25, "country"], [27, 28, "country"], [38, 39, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Events", "are", "held", "all", "over", "the", "world", ",", "with", "the", "most", "popular", "in", "the", "United", "Kingdom", ",", "the", "United", "States", ",", "Japan", ",", "Singapore", ",", "India", ",", "South", "Korea", "and", "increasingly", "in", "countries", "in", "the", "subcontinent", "such", "as", "Sri", "Lanka", "."], "sentence-detokenized": "Events are held all over the world, with the most popular in the United Kingdom, the United States, Japan, Singapore, India, South Korea and increasingly in countries in the subcontinent such as Sri Lanka.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 24], [25, 28], [29, 34], [34, 35], [36, 40], [41, 44], [45, 49], [50, 57], [58, 60], [61, 64], [65, 71], [72, 79], [79, 80], [81, 84], [85, 91], [92, 98], [98, 99], [100, 105], [105, 106], [107, 116], [116, 117], [118, 123], [123, 124], [125, 130], [131, 136], [137, 140], [141, 153], [154, 156], [157, 166], [167, 169], [170, 173], [174, 186], [187, 191], [192, 194], [195, 198], [199, 204], [204, 205]]}
{"doc_key": "ai-test-427", "ner": [[6, 8, "programlang"], [12, 12, "programlang"], [14, 14, "programlang"], [16, 17, "programlang"], [19, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "mainly", "developed", "in", "R", ",", "but", "sometimes", "also", "in", "Java", ",", "C", ",", "C", "++", "and", "Fortran", "."], "sentence-detokenized": "These packages are mainly developed in R, but sometimes also in Java, C, C++ and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 25], [26, 35], [36, 38], [39, 40], [40, 41], [42, 45], [46, 55], [56, 60], [61, 63], [64, 68], [68, 69], [70, 71], [71, 72], [73, 74], [74, 76], [77, 80], [81, 88], [88, 89]]}
{"doc_key": "ai-test-428", "ner": [[0, 7, "conference"], [9, 9, "conference"], [12, 12, "researcher"], [14, 14, "researcher"], [17, 18, "researcher"], [21, 22, "algorithm"], [27, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 9, 0, 7, "named", "", false, false], [12, 12, 0, 7, "physical", "", false, false], [12, 12, 0, 7, "role", "", false, false], [12, 12, 17, 18, "role", "teams_up_with", false, false], [12, 12, 21, 22, "usage", "", false, false], [14, 14, 0, 7, "physical", "", false, false], [14, 14, 0, 7, "role", "", false, false], [14, 14, 17, 18, "role", "teams_up_with", false, false], [14, 14, 21, 22, "usage", "", false, false], [17, 18, 0, 7, "physical", "", false, false], [17, 18, 0, 7, "role", "", false, false], [17, 18, 21, 22, "usage", "", false, false], [21, 22, 27, 32, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["At", "the", "2006", "European", "Conference", "on", "Computer", "Vision", "(", "ECCV", ")", ",", "Dalal", "and", "Trigg", "collaborated", "with", "Cordelia", "Schmid", "to", "apply", "HOG", "detectors", "to", "the", "problem", "of", "human", "detection", "in", "film", "and", "video", "."], "sentence-detokenized": "At the 2006 European Conference on Computer Vision (ECCV), Dalal and Trigg collaborated with Cordelia Schmid to apply HOG detectors to the problem of human detection in film and video.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 31], [32, 34], [35, 43], [44, 50], [51, 52], [52, 56], [56, 57], [57, 58], [59, 64], [65, 68], [69, 74], [75, 87], [88, 92], [93, 101], [102, 108], [109, 111], [112, 117], [118, 121], [122, 131], [132, 134], [135, 138], [139, 146], [147, 149], [150, 155], [156, 165], [166, 168], [169, 173], [174, 177], [178, 183], [183, 184]]}
{"doc_key": "ai-test-429", "ner": [[3, 3, "metrics"], [5, 7, "metrics"], [10, 11, "task"], [18, 20, "metrics"], [22, 25, "metrics"], [28, 28, "metrics"], [32, 34, "metrics"], [36, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 3, 10, 11, "related-to", "measured_with", false, false], [5, 7, 10, 11, "related-to", "measured_with", false, false], [18, 20, 10, 11, "related-to", "measured_with", false, false], [22, 25, 18, 20, "named", "", false, false], [28, 28, 18, 20, "named", "", false, false], [36, 36, 32, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "addition", "to", "sensitivity", "and", "specificity", ",", "the", "performance", "of", "binary", "classification", "tests", "can", "be", "assessed", "by", "the", "positive", "predictive", "value", "(", "PPV", ")", ",", "also", "known", "as", "accuracy", ",", "and", "the", "negative", "predictive", "value", "(", "NPV", ")", "."], "sentence-detokenized": "In addition to sensitivity and specificity, the performance of binary classification tests can be assessed by the positive predictive value (PPV), also known as accuracy, and the negative predictive value (NPV).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 42], [42, 43], [44, 47], [48, 59], [60, 62], [63, 69], [70, 84], [85, 90], [91, 94], [95, 97], [98, 106], [107, 109], [110, 113], [114, 122], [123, 133], [134, 139], [140, 141], [141, 144], [144, 145], [145, 146], [147, 151], [152, 157], [158, 160], [161, 169], [169, 170], [171, 174], [175, 178], [179, 187], [188, 198], [199, 204], [205, 206], [206, 209], [209, 210], [210, 211]]}
{"doc_key": "ai-test-430", "ner": [[13, 15, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "models", "may", "partially", "award", "credit", "for", "matching", "coincidences", "(", "e.g.", "using", "the", "Jaccard", "index", "criterion", ")", "."], "sentence-detokenized": "Such models may partially award credit for matching coincidences (e.g. using the Jaccard index criterion).", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 25], [26, 31], [32, 38], [39, 42], [43, 51], [52, 64], [65, 66], [66, 70], [71, 76], [77, 80], [81, 88], [89, 94], [95, 104], [104, 105], [105, 106]]}
{"doc_key": "ai-test-431", "ner": [[22, 27, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Moreover", ",", "in", "the", "case", "of", "single", "-", "sample", "estimation", ",", "it", "highlights", "philosophical", "issues", "and", "potential", "misunderstandings", "in", "the", "use", "of", "maximum", "likelihood", "estimators", "and", "likelihood", "functions", "."], "sentence-detokenized": "Moreover, in the case of single-sample estimation, it highlights philosophical issues and potential misunderstandings in the use of maximum likelihood estimators and likelihood functions.", "token2charspan": [[0, 8], [8, 9], [10, 12], [13, 16], [17, 21], [22, 24], [25, 31], [31, 32], [32, 38], [39, 49], [49, 50], [51, 53], [54, 64], [65, 78], [79, 85], [86, 89], [90, 99], [100, 117], [118, 120], [121, 124], [125, 128], [129, 131], [132, 139], [140, 150], [151, 161], [162, 165], [166, 176], [177, 186], [186, 187]]}
