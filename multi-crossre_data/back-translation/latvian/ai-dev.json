{"doc_key": "ai-dev-1", "ner": [[2, 2, "metrics"], [7, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 2, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Here", ",", "accuracy", "is", "measured", "by", "the", "error", "rate", ",", "defined", "as", ":"], "sentence-detokenized": "Here, accuracy is measured by the error rate, defined as:", "token2charspan": [[0, 4], [4, 5], [6, 14], [15, 17], [18, 26], [27, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 53], [54, 56], [56, 57]]}
{"doc_key": "ai-dev-2", "ner": [[6, 6, "algorithm"], [13, 15, "misc"], [17, 19, "algorithm"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 13, 15, "type-of", "", false, false], [6, 6, 17, 19, "related-to", "", false, false], [6, 6, 20, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["From", "this", "point", "of", "view", ",", "SVM", "is", "closely", "related", "to", "other", "fundamental", "classification", "algorithms", "such", "as", "regular", "least", "squares", "logistic", "regression", "."], "sentence-detokenized": "From this point of view, SVM is closely related to other fundamental classification algorithms such as regular least squares logistic regression.", "token2charspan": [[0, 4], [5, 9], [10, 15], [16, 18], [19, 23], [23, 24], [25, 28], [29, 31], [32, 39], [40, 47], [48, 50], [51, 56], [57, 68], [69, 83], [84, 94], [95, 99], [100, 102], [103, 110], [111, 116], [117, 124], [125, 133], [134, 144], [144, 145]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [3, 4, "person"], [15, 17, "person"], [18, 20, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 0, 1, "named", "actor_plays_character", false, false], [3, 4, 0, 1, "origin", "actor_plays_character", false, false], [18, 20, 15, 17, "named", "actor_plays_character", false, false], [18, 20, 15, 17, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "plays", "Leon", "Kowalski", ",", "a", "replicant", "of", "the", "combatants", "and", "workers", ",", "and", "Joanne", "Cassidy", "plays", "Zhora", ",", "a", "replicant", "of", "the", "assassins", "."], "sentence-detokenized": "Brion James plays Leon Kowalski, a replicant of the combatants and workers, and Joanne Cassidy plays Zhora, a replicant of the assassins.", "token2charspan": [[0, 5], [6, 11], [12, 17], [18, 22], [23, 31], [31, 32], [33, 34], [35, 44], [45, 47], [48, 51], [52, 62], [63, 66], [67, 74], [74, 75], [76, 79], [80, 86], [87, 94], [95, 100], [101, 106], [106, 107], [108, 109], [110, 119], [120, 122], [123, 126], [127, 136], [136, 137]]}
{"doc_key": "ai-dev-4", "ner": [[16, 19, "product"], [21, 21, "product"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 19, 15, 15, "physical", "", false, false], [21, 21, 16, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "image", "scanned", ",", "saved", "and", "rendered", "into", "digital", "pixels", "was", "displayed", "on", "the", "NIST", "Standardisation", "Eastern", "Automated", "Computer", "(", "SEAC", ")", "."], "sentence-detokenized": "The first image scanned, saved and rendered into digital pixels was displayed on the NIST Standardisation Eastern Automated Computer (SEAC).", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [23, 24], [25, 30], [31, 34], [35, 43], [44, 48], [49, 56], [57, 63], [64, 67], [68, 77], [78, 80], [81, 84], [85, 89], [90, 105], [106, 113], [114, 123], [124, 132], [133, 134], [134, 138], [138, 139], [139, 140]]}
{"doc_key": "ai-dev-5", "ner": [[0, 6, "task"], [20, 21, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 20, 21, "part-of", "", false, false], [0, 6, 23, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Segmenting", "text", "into", "topics", "or", "discourse", "turns", "can", "be", "useful", "in", "some", "natural", "processing", "tasks", ":", "it", "can", "significantly", "improve", "information", "retrieval", "or", "speech", "recognition", "(", "by", "indexing", "/", "recognising", "documents", "more", "accurately", "or", "by", "providing", "a", "specific", "part", "of", "a", "document", "as", "a", "result", "that", "matches", "the", "query", ")", "."], "sentence-detokenized": "Segmenting text into topics or discourse turns can be useful in some natural processing tasks: it can significantly improve information retrieval or speech recognition (by indexing/recognising documents more accurately or by providing a specific part of a document as a result that matches the query).", "token2charspan": [[0, 10], [11, 15], [16, 20], [21, 27], [28, 30], [31, 40], [41, 46], [47, 50], [51, 53], [54, 60], [61, 63], [64, 68], [69, 76], [77, 87], [88, 93], [93, 94], [95, 97], [98, 101], [102, 115], [116, 123], [124, 135], [136, 145], [146, 148], [149, 155], [156, 167], [168, 169], [169, 171], [172, 180], [180, 181], [181, 192], [193, 202], [203, 207], [208, 218], [219, 221], [222, 224], [225, 234], [235, 236], [237, 245], [246, 250], [251, 253], [254, 255], [256, 264], [265, 267], [268, 269], [270, 276], [277, 281], [282, 289], [290, 293], [294, 299], [299, 300], [300, 301]]}
{"doc_key": "ai-dev-6", "ner": [[7, 9, "university"], [25, 26, "conference"], [15, 17, "university"], [36, 37, "researcher"], [39, 40, "researcher"], [42, 43, "researcher"], [45, 46, "researcher"], [48, 49, "researcher"], [51, 52, "researcher"], [54, 56, "researcher"], [58, 59, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[25, 26, 15, 17, "physical", "", false, false], [36, 37, 25, 26, "physical", "", false, false], [36, 37, 25, 26, "role", "", false, false], [36, 37, 25, 26, "temporal", "", false, false], [39, 40, 25, 26, "physical", "", false, false], [39, 40, 25, 26, "role", "", false, false], [39, 40, 25, 26, "temporal", "", false, false], [42, 43, 25, 26, "physical", "", false, false], [42, 43, 25, 26, "role", "", false, false], [42, 43, 25, 26, "temporal", "", false, false], [45, 46, 25, 26, "physical", "", false, false], [45, 46, 25, 26, "role", "", false, false], [45, 46, 25, 26, "temporal", "", false, false], [48, 49, 25, 26, "physical", "", false, false], [48, 49, 25, 26, "role", "", false, false], [48, 49, 25, 26, "temporal", "", false, false], [51, 52, 25, 26, "physical", "", false, false], [51, 52, 25, 26, "role", "", false, false], [51, 52, 25, 26, "temporal", "", false, false], [54, 56, 25, 26, "physical", "", false, false], [54, 56, 25, 26, "role", "", false, false], [54, 56, 25, 26, "temporal", "", false, false], [58, 59, 25, 26, "physical", "", false, false], [58, 59, 25, 26, "role", "", false, false], [58, 59, 25, 26, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["In", "1999", "he", "organised", "such", "a", "symposium", "at", "Indiana", "University", ",", "and", "in", "April", "2000", "at", "Stanford", "University", "he", "organised", "a", "larger", "symposium", "on", "\"", "Spiritual", "Robots", "\"", ",", "in", "which", "he", "chaired", "a", "panel", "with", "Ray", "Kurzweil", ",", "Hans", "Morawetz", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joey", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", "and", "John", "Koza", "."], "sentence-detokenized": "In 1999 he organised such a symposium at Indiana University, and in April 2000 at Stanford University he organised a larger symposium on \"Spiritual Robots\", in which he chaired a panel with Ray Kurzweil, Hans Morawetz, Kevin Kelly, Ralph Merkle, Bill Joey, Frank Drake, John Henry Holland and John Koza.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 20], [21, 25], [26, 27], [28, 37], [38, 40], [41, 48], [49, 59], [59, 60], [61, 64], [65, 67], [68, 73], [74, 78], [79, 81], [82, 90], [91, 101], [102, 104], [105, 114], [115, 116], [117, 123], [124, 133], [134, 136], [137, 138], [138, 147], [148, 154], [154, 155], [155, 156], [157, 159], [160, 165], [166, 168], [169, 176], [177, 178], [179, 184], [185, 189], [190, 193], [194, 202], [202, 203], [204, 208], [209, 217], [217, 218], [219, 224], [225, 230], [230, 231], [232, 237], [238, 244], [244, 245], [246, 250], [251, 255], [255, 256], [257, 262], [263, 268], [268, 269], [270, 274], [275, 280], [281, 288], [289, 292], [293, 297], [298, 302], [302, 303]]}
{"doc_key": "ai-dev-7", "ner": [[7, 7, "metrics"], [8, 8, "metrics"], [11, 13, "metrics"], [12, 12, "metrics"], [21, 21, "metrics"], [40, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 7, 21, 21, "named", "", false, false], [8, 8, 7, 7, "named", "", false, false], [11, 13, 40, 40, "named", "", false, false], [12, 12, 11, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["To", "calculate", "the", "score", ",", "both", "the", "precision", "p", "and", "the", "recovery", "r", "of", "the", "test", "are", "taken", "into", "account", ":", "p", "is", "the", "number", "of", "true", "positives", "divided", "by", "the", "number", "of", "all", "positives", "given", "by", "the", "classifier", "and", "r", "is", "the", "number", "of", "true", "positives", "divided", "by", "the", "number", "of", "all", "matched", "samples", "(", "all", "samples", "that", "should", "have", "been", "identified", "as", "positive", ")", "."], "sentence-detokenized": "To calculate the score, both the precision p and the recovery r of the test are taken into account: p is the number of true positives divided by the number of all positives given by the classifier and r is the number of true positives divided by the number of all matched samples (all samples that should have been identified as positive).", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 22], [22, 23], [24, 28], [29, 32], [33, 42], [43, 44], [45, 48], [49, 52], [53, 61], [62, 63], [64, 66], [67, 70], [71, 75], [76, 79], [80, 85], [86, 90], [91, 98], [98, 99], [100, 101], [102, 104], [105, 108], [109, 115], [116, 118], [119, 123], [124, 133], [134, 141], [142, 144], [145, 148], [149, 155], [156, 158], [159, 162], [163, 172], [173, 178], [179, 181], [182, 185], [186, 196], [197, 200], [201, 202], [203, 205], [206, 209], [210, 216], [217, 219], [220, 224], [225, 234], [235, 242], [243, 245], [246, 249], [250, 256], [257, 259], [260, 263], [264, 271], [272, 279], [280, 281], [281, 284], [285, 292], [293, 297], [298, 304], [305, 309], [310, 314], [315, 325], [326, 328], [329, 337], [337, 338], [338, 339]]}
{"doc_key": "ai-dev-8", "ner": [[4, 4, "organisation"], [22, 22, "product"], [28, 29, "person"], [35, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 22, 22, "artifact", "", false, false], [22, 22, 28, 29, "win-defeat", "", false, false], [22, 22, 35, 35, "win-defeat", "", true, false], [28, 29, 35, 35, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "its", "acquisition", "by", "Google", ",", "the", "company", "has", "made", "a", "number", "of", "significant", "achievements", ",", "perhaps", "most", "notably", "the", "creation", "of", "AlphaGo", ",", "which", "defeated", "world", "champion", "Lee", "Sedol", "in", "the", "difficult", "game", "of", "Go", "."], "sentence-detokenized": "Since its acquisition by Google, the company has made a number of significant achievements, perhaps most notably the creation of AlphaGo, which defeated world champion Lee Sedol in the difficult game of Go.", "token2charspan": [[0, 5], [6, 9], [10, 21], [22, 24], [25, 31], [31, 32], [33, 36], [37, 44], [45, 48], [49, 53], [54, 55], [56, 62], [63, 65], [66, 77], [78, 90], [90, 91], [92, 99], [100, 104], [105, 112], [113, 116], [117, 125], [126, 128], [129, 136], [136, 137], [138, 143], [144, 152], [153, 158], [159, 167], [168, 171], [172, 177], [178, 180], [181, 184], [185, 194], [195, 199], [200, 202], [203, 205], [205, 206]]}
{"doc_key": "ai-dev-9", "ner": [[11, 14, "misc"], [24, 24, "field"], [26, 28, "product"], [45, 48, "misc"], [50, 51, "misc"], [54, 54, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 14, 24, 24, "part-of", "", false, false], [11, 14, 50, 51, "named", "same", false, false], [26, 28, 45, 48, "related-to", "", false, false], [26, 28, 50, 51, "usage", "", false, false], [26, 28, 54, 54, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Representing", "words", "in", "context", "using", "fixed", "-", "size", "dense", "vectors", "(", "word", "embeddings", ")", "has", "become", "one", "of", "the", "key", "building", "blocks", "in", "several", "NLP", "systems.The", "unsupervised", "disambiguation", "system", "uses", "the", "similarity", "between", "word", "meanings", "in", "a", "fixed", "context", "window", "to", "select", "the", "most", "appropriate", "word", "meaning", "using", "a", "pre-trained", "word", "embedding", "model", "and", "WordNet", "."], "sentence-detokenized": "Representing words in context using fixed-size dense vectors (word embeddings) has become one of the key building blocks in several NLP systems.The unsupervised disambiguation system uses the similarity between word meanings in a fixed context window to select the most appropriate word meaning using a pre-trained word embedding model and WordNet.", "token2charspan": [[0, 12], [13, 18], [19, 21], [22, 29], [30, 35], [36, 41], [41, 42], [42, 46], [47, 52], [53, 60], [61, 62], [62, 66], [67, 77], [77, 78], [79, 82], [83, 89], [90, 93], [94, 96], [97, 100], [101, 104], [105, 113], [114, 120], [121, 123], [124, 131], [132, 135], [136, 147], [148, 160], [161, 175], [176, 182], [183, 187], [188, 191], [192, 202], [203, 210], [211, 215], [216, 224], [225, 227], [228, 229], [230, 235], [236, 243], [244, 250], [251, 253], [254, 260], [261, 264], [265, 269], [270, 281], [282, 286], [287, 294], [295, 300], [301, 302], [303, 314], [315, 319], [320, 329], [330, 335], [336, 339], [340, 347], [347, 348]]}
{"doc_key": "ai-dev-10", "ner": [[0, 1, "field"], [5, 7, "field"], [8, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 0, 1, "part-of", "", false, false], [8, 17, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "techniques", "-", "either", "supervised", "learning", "or", "unsupervised", "learning", "-", "are", "used", "to", "automatically", "detect", "such", "rules", "."], "sentence-detokenized": "Machine learning techniques - either supervised learning or unsupervised learning - are used to automatically detect such rules.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [30, 36], [37, 47], [48, 56], [57, 59], [60, 72], [73, 81], [82, 83], [84, 87], [88, 92], [93, 95], [96, 109], [110, 116], [117, 121], [122, 127], [127, 128]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1969", ",", "Steinmann", "invented", "the", "Stanford", "Hand", ","], "sentence-detokenized": "In 1969, Steinmann invented the Stanford Hand,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 27], [28, 31], [32, 40], [41, 45], [45, 46]]}
{"doc_key": "ai-dev-12", "ner": [[1, 2, "metrics"], [7, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "Log", "losses", "are", "differentiable", ",", "a", "gradient", "-", "based", "method", "can", "be", "used", "to", "optimise", "the", "model", "."], "sentence-detokenized": "As Log losses are differentiable, a gradient-based method can be used to optimise the model.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 17], [18, 32], [32, 33], [34, 35], [36, 44], [44, 45], [45, 50], [51, 57], [58, 61], [62, 64], [65, 69], [70, 72], [73, 81], [82, 85], [86, 91], [91, 92]]}
{"doc_key": "ai-dev-13", "ner": [[0, 2, "field"], [4, 6, "algorithm"], [8, 8, "algorithm"], [11, 13, "algorithm"], [16, 17, "field"], [27, 27, "task"], [29, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 6, 16, 17, "part-of", "", false, false], [8, 8, 4, 6, "named", "", false, false], [11, 13, 4, 6, "named", "", false, false], [16, 17, 0, 2, "part-of", "subfield", false, false], [27, 27, 16, 17, "part-of", "", false, false], [29, 30, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "machine", "learning", ",", "support", "vector", "machines", "(", "SVMs", ",", "also", "support", "vector", "networks", ")", "are", "supervised", "learning", "models", "with", "learning", "algorithms", "that", "analyse", "data", "used", "for", "classification", "and", "regression", "analysis", "."], "sentence-detokenized": "In machine learning, support vector machines (SVMs, also support vector networks) are supervised learning models with learning algorithms that analyse data used for classification and regression analysis.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 28], [29, 35], [36, 44], [45, 46], [46, 50], [50, 51], [52, 56], [57, 64], [65, 71], [72, 80], [80, 81], [82, 85], [86, 96], [97, 105], [106, 112], [113, 117], [118, 126], [127, 137], [138, 142], [143, 150], [151, 155], [156, 160], [161, 164], [165, 179], [180, 183], [184, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-dev-14", "ner": [[8, 9, "task"], [11, 11, "task"], [29, 29, "metrics"], [31, 31, "metrics"], [33, 33, "researcher"], [35, 35, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "2002", ")", "as", "an", "automatic", "metric", "for", "machine", "translation", "(", "MT", ")", "evaluation", ",", "many", "other", "methods", "have", "been", "proposed", "to", "revise", "or", "improve", "it", ",", "such", "as", "TER", ",", "METEOR", ",", "Banerjee", "and", "Lavie", ",", "(", "2005", ")", ",", "etc", "."], "sentence-detokenized": "(2002) as an automatic metric for machine translation (MT) evaluation, many other methods have been proposed to revise or improve it, such as TER, METEOR, Banerjee and Lavie, (2005), etc.", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 9], [10, 12], [13, 22], [23, 29], [30, 33], [34, 41], [42, 53], [54, 55], [55, 57], [57, 58], [59, 69], [69, 70], [71, 75], [76, 81], [82, 89], [90, 94], [95, 99], [100, 108], [109, 111], [112, 118], [119, 121], [122, 129], [130, 132], [132, 133], [134, 138], [139, 141], [142, 145], [145, 146], [147, 153], [153, 154], [155, 163], [164, 167], [168, 173], [173, 174], [175, 176], [176, 180], [180, 181], [181, 182], [183, 186], [186, 187]]}
{"doc_key": "ai-dev-15", "ner": [[3, 7, "misc"], [8, 8, "organisation"], [11, 11, "organisation"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 7, 11, 11, "origin", "", false, false], [11, 11, 8, 8, "part-of", "", false, false], [15, 16, 11, 11, "role", "", false, false], [18, 19, 11, 11, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "incorporates", "the", "upper", "ontology", "developed", "by", "the", "IEEE", "working", "group", "P1600.1", "(", "originally", "by", "Ian", "Niles", "and", "Adam", "Pease", ")", "."], "sentence-detokenized": "It incorporates the upper ontology developed by the IEEE working group P1600.1 (originally by Ian Niles and Adam Pease).", "token2charspan": [[0, 2], [3, 15], [16, 19], [20, 25], [26, 34], [35, 44], [45, 47], [48, 51], [52, 56], [57, 64], [65, 70], [71, 78], [79, 80], [80, 90], [91, 93], [94, 97], [98, 103], [104, 107], [108, 112], [113, 118], [118, 119], [119, 120]]}
{"doc_key": "ai-dev-16", "ner": [[0, 2, "misc"], [32, 34, "algorithm"], [36, 37, "algorithm"], [40, 43, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[32, 34, 0, 2, "part-of", "", true, false], [36, 37, 0, 2, "part-of", "", true, false], [40, 43, 36, 37, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "cryoelectron", "tomography", ",", "where", "a", "limited", "number", "of", "projections", "are", "obtained", "due", "to", "hardware", "limitations", "and", "to", "avoid", "damage", "to", "the", "biological", "sample", ",", "it", "can", "be", "used", "in", "combination", "with", "compression", "capture", "techniques", "or", "regularisation", "functions", "(", "e.g.", "Huber", "losses", ")", "to", "enhance", "the", "reconstruction", "for", "better", "interpretation", "."], "sentence-detokenized": "In cryoelectron tomography, where a limited number of projections are obtained due to hardware limitations and to avoid damage to the biological sample, it can be used in combination with compression capture techniques or regularisation functions (e.g. Huber losses) to enhance the reconstruction for better interpretation.", "token2charspan": [[0, 2], [3, 15], [16, 26], [26, 27], [28, 33], [34, 35], [36, 43], [44, 50], [51, 53], [54, 65], [66, 69], [70, 78], [79, 82], [83, 85], [86, 94], [95, 106], [107, 110], [111, 113], [114, 119], [120, 126], [127, 129], [130, 133], [134, 144], [145, 151], [151, 152], [153, 155], [156, 159], [160, 162], [163, 167], [168, 170], [171, 182], [183, 187], [188, 199], [200, 207], [208, 218], [219, 221], [222, 236], [237, 246], [247, 248], [248, 252], [253, 258], [259, 265], [265, 266], [267, 269], [270, 277], [278, 281], [282, 296], [297, 300], [301, 307], [308, 322], [322, 323]]}
{"doc_key": "ai-dev-17", "ner": [[3, 3, "misc"], [5, 6, "programlang"], [9, 10, "algorithm"], [12, 14, "algorithm"], [15, 16, "algorithm"], [22, 24, "product"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 5, 6, "part-of", "", false, false], [9, 10, 3, 3, "type-of", "", false, false], [12, 14, 3, 3, "type-of", "", false, false], [15, 16, 3, 3, "type-of", "", false, false], [22, 24, 5, 6, "general-affiliation", "", true, false], [22, 24, 5, 6, "part-of", "", true, false], [27, 27, 22, 24, "role", "publishes", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Implementations", "of", "several", "whitening", "procedures", "in", "R", ",", "including", "ZCA", "whitening", ",", "PCA", "whitening", "and", "CCA", "whitening", ",", "are", "available", "in", "the", "R", "package", "whitening", "published", "by", "CRAN", "."], "sentence-detokenized": "Implementations of several whitening procedures in R, including ZCA whitening, PCA whitening and CCA whitening, are available in the R package whitening published by CRAN.", "token2charspan": [[0, 15], [16, 18], [19, 26], [27, 36], [37, 47], [48, 50], [51, 52], [52, 53], [54, 63], [64, 67], [68, 77], [77, 78], [79, 82], [83, 92], [93, 96], [97, 100], [101, 110], [110, 111], [112, 115], [116, 125], [126, 128], [129, 132], [133, 134], [135, 142], [143, 152], [153, 162], [163, 165], [166, 170], [170, 171]]}
{"doc_key": "ai-dev-18", "ner": [[29, 29, "product"], [31, 31, "product"], [33, 33, "product"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [42, 43, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[29, 29, 33, 33, "compare", "", false, false], [29, 29, 35, 35, "compare", "", false, false], [29, 29, 37, 37, "compare", "", false, false], [29, 29, 39, 39, "compare", "", false, false], [29, 29, 42, 43, "compare", "", false, false], [31, 31, 33, 33, "compare", "", false, false], [31, 31, 35, 35, "compare", "", false, false], [31, 31, 37, 37, "compare", "", false, false], [31, 31, 39, 39, "compare", "", false, false], [31, 31, 42, 43, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Nowadays", ",", "the", "field", "has", "become", "even", "more", "complex", "and", "sophisticated", ",", "with", "the", "addition", "of", "circuit", ",", "system", "and", "signal", "analysis", "and", "design", "languages", "and", "software", "ranging", "from", "MATLAB", "and", "Simulink", "to", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "and", "even", "Assembly", "language", "."], "sentence-detokenized": "Nowadays, the field has become even more complex and sophisticated, with the addition of circuit, system and signal analysis and design languages and software ranging from MATLAB and Simulink to NumPy, VHDL, PSpice, Verilog and even Assembly language.", "token2charspan": [[0, 8], [8, 9], [10, 13], [14, 19], [20, 23], [24, 30], [31, 35], [36, 40], [41, 48], [49, 52], [53, 66], [66, 67], [68, 72], [73, 76], [77, 85], [86, 88], [89, 96], [96, 97], [98, 104], [105, 108], [109, 115], [116, 124], [125, 128], [129, 135], [136, 145], [146, 149], [150, 158], [159, 166], [167, 171], [172, 178], [179, 182], [183, 191], [192, 194], [195, 200], [200, 201], [202, 206], [206, 207], [208, 214], [214, 215], [216, 223], [224, 227], [228, 232], [233, 241], [242, 250], [250, 251]]}
{"doc_key": "ai-dev-19", "ner": [[7, 10, "person"], [15, 16, "person"], [18, 20, "organisation"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[18, 20, 15, 16, "origin", "", false, false], [22, 22, 18, 20, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "company", "was", "founded", "in", "1937", "by", "Kiichiro", "Toyoda", "as", "a", "spin", "-", "off", "from", "Sakichi", "Toyoda", "'s", "Toyota", "Industries", "to", "produce", "cars", "."], "sentence-detokenized": "The company was founded in 1937 by Kiichiro Toyoda as a spin-off from Sakichi Toyoda's Toyota Industries to produce cars.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 31], [32, 34], [35, 43], [44, 50], [51, 53], [54, 55], [56, 60], [60, 61], [61, 64], [65, 69], [70, 77], [78, 84], [84, 86], [87, 93], [94, 104], [105, 107], [108, 115], [116, 120], [120, 121]]}
{"doc_key": "ai-dev-20", "ner": [[0, 4, "field"], [55, 58, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[55, 58, 0, 4, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Unsupervised", "learning", ",", "on", "the", "other", "hand", ",", "uses", "training", "data", "that", "is", "not", "labelled", "by", "hand", "and", "tries", "to", "find", "patterns", "in", "the", "data", "that", "can", "then", "be", "used", "to", "determine", "the", "correct", "output", "value", "for", "new", "instances", "of", "the", "data", ".", "Recently", ",", "a", "combination", "of", "these", "two", "types", "has", "been", "investigated", "-", "semi-supervised", "learning", ",", "which", "uses", "a", "combination", "of", "labelled", "and", "unlabelled", "data", "(", "typically", "a", "small", "set", "of", "labelled", "data", "together", "with", "a", "large", "amount", "of", "unlabelled", "data", ")", "."], "sentence-detokenized": "Unsupervised learning, on the other hand, uses training data that is not labelled by hand and tries to find patterns in the data that can then be used to determine the correct output value for new instances of the data. Recently, a combination of these two types has been investigated - semi-supervised learning, which uses a combination of labelled and unlabelled data (typically a small set of labelled data together with a large amount of unlabelled data).", "token2charspan": [[0, 12], [13, 21], [21, 22], [23, 25], [26, 29], [30, 35], [36, 40], [40, 41], [42, 46], [47, 55], [56, 60], [61, 65], [66, 68], [69, 72], [73, 81], [82, 84], [85, 89], [90, 93], [94, 99], [100, 102], [103, 107], [108, 116], [117, 119], [120, 123], [124, 128], [129, 133], [134, 137], [138, 142], [143, 145], [146, 150], [151, 153], [154, 163], [164, 167], [168, 175], [176, 182], [183, 188], [189, 192], [193, 196], [197, 206], [207, 209], [210, 213], [214, 218], [218, 219], [220, 228], [228, 229], [230, 231], [232, 243], [244, 246], [247, 252], [253, 256], [257, 262], [263, 266], [267, 271], [272, 284], [285, 286], [287, 302], [303, 311], [311, 312], [313, 318], [319, 323], [324, 325], [326, 337], [338, 340], [341, 349], [350, 353], [354, 364], [365, 369], [370, 371], [371, 380], [381, 382], [383, 388], [389, 392], [393, 395], [396, 404], [405, 409], [410, 418], [419, 423], [424, 425], [426, 431], [432, 438], [439, 441], [442, 452], [453, 457], [457, 458], [458, 459]]}
{"doc_key": "ai-dev-21", "ner": [[19, 20, "organisation"], [21, 21, "product"], [23, 24, "organisation"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 19, 20, "artifact", "", false, false], [23, 24, 26, 26, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Despite", "these", "humanoid", "robots", "for", "utilitarian", "use", ",", "there", "are", "some", "humanoid", "robots", "aimed", "at", "entertainment", ",", "such", "as", "Sony", "'s", "QRIO", "and", "Wow", "Wee", "'s", "RoboSapien", "."], "sentence-detokenized": "Despite these humanoid robots for utilitarian use, there are some humanoid robots aimed at entertainment, such as Sony's QRIO and Wow Wee's RoboSapien.", "token2charspan": [[0, 7], [8, 13], [14, 22], [23, 29], [30, 33], [34, 45], [46, 49], [49, 50], [51, 56], [57, 60], [61, 65], [66, 74], [75, 81], [82, 87], [88, 90], [91, 104], [104, 105], [106, 110], [111, 113], [114, 118], [118, 120], [121, 125], [126, 129], [130, 133], [134, 137], [137, 139], [140, 150], [150, 151]]}
{"doc_key": "ai-dev-22", "ner": [[3, 3, "researcher"], [9, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 9, 15, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1991", ",", "Weber", "became", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "In 1991, Weber became a member of the Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 21], [22, 23], [24, 30], [31, 33], [34, 37], [38, 49], [50, 53], [54, 57], [58, 69], [70, 72], [73, 83], [84, 96], [96, 97]]}
{"doc_key": "ai-dev-23", "ner": [[3, 4, "field"], [6, 6, "field"], [21, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 24, 3, 4, "part-of", "task_part_of_field", false, false], [21, 24, 6, 6, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "he", "developed", "data", "mining", "and", "database", "technologies", ",", "as", "well", "as", "more", "specific", "high", "-", "level", "ontologies", "for", "intelligence", "and", "automated", "natural", "language", "understanding", "."], "sentence-detokenized": "There he developed data mining and database technologies, as well as more specific high-level ontologies for intelligence and automated natural language understanding.", "token2charspan": [[0, 5], [6, 8], [9, 18], [19, 23], [24, 30], [31, 34], [35, 43], [44, 56], [56, 57], [58, 60], [61, 65], [66, 68], [69, 73], [74, 82], [83, 87], [87, 88], [88, 93], [94, 104], [105, 108], [109, 121], [122, 125], [126, 135], [136, 143], [144, 152], [153, 166], [166, 167]]}
{"doc_key": "ai-dev-24", "ner": [[20, 21, "misc"], [24, 27, "misc"], [29, 30, "misc"], [31, 32, "country"], [35, 36, "organisation"], [37, 40, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 31, 32, "physical", "", false, false], [24, 27, 31, 32, "physical", "", false, false], [29, 30, 31, 32, "physical", "", false, false], [35, 36, 37, 40, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["However", ",", "in", "recent", "years", ",", "various", "e-services", "and", "related", "initiatives", "have", "emerged", "in", "developing", "countries", ",", "such", "as", "the", "Nemmadi", "Project", ",", "the", "MCA21", "Mission", "Mode", "Project", "or", "Digital", "India", "in", "India", ";", "the", "e-Governance", "Directorate", "in", "Pakistan", ",", "etc", "."], "sentence-detokenized": "However, in recent years, various e-services and related initiatives have emerged in developing countries, such as the Nemmadi Project, the MCA21 Mission Mode Project or Digital India in India; the e-Governance Directorate in Pakistan, etc.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 18], [19, 24], [24, 25], [26, 33], [34, 44], [45, 48], [49, 56], [57, 68], [69, 73], [74, 81], [82, 84], [85, 95], [96, 105], [105, 106], [107, 111], [112, 114], [115, 118], [119, 126], [127, 134], [134, 135], [136, 139], [140, 145], [146, 153], [154, 158], [159, 166], [167, 169], [170, 177], [178, 183], [184, 186], [187, 192], [192, 193], [194, 197], [198, 210], [211, 222], [223, 225], [226, 234], [234, 235], [236, 239], [239, 240]]}
{"doc_key": "ai-dev-25", "ner": [[3, 3, "misc"], [4, 5, "field"], [7, 9, "field"], [14, 16, "university"], [10, 13, "university"], [24, 29, "university"], [31, 31, "misc"], [32, 35, "field"], [36, 53, "misc"], [51, 52, "university"], [38, 41, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 3, 4, 5, "topic", "", false, false], [3, 3, 7, 9, "topic", "", false, false], [3, 3, 14, 16, "origin", "", false, false], [14, 16, 10, 13, "part-of", "", false, false], [24, 29, 14, 16, "part-of", "", false, false], [31, 31, 32, 35, "topic", "", false, false], [31, 31, 51, 52, "origin", "", false, false], [36, 53, 51, 52, "origin", "", false, false], [51, 52, 38, 41, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["He", "obtained", "his", "PhD", "in", "Radiophysics", "and", "Electronics", "from", "the", "University", "of", "Calcutta", "'s", "Rajabazar", "Science", "College", "campus", "in", "1979", ",", "while", "studying", "at", "the", "Indian", "Statistical", "Institute", ",", "and", "his", "PhD", "in", "Electrical", "Engineering", "from", "Imperial", "College", ",", "University", "of", "London", ",", "in", "1982", ",", "while", "also", "obtaining", "a", "Diploma", "from", "Imperial", "College", "."], "sentence-detokenized": "He obtained his PhD in Radiophysics and Electronics from the University of Calcutta's Rajabazar Science College campus in 1979, while studying at the Indian Statistical Institute, and his PhD in Electrical Engineering from Imperial College, University of London, in 1982, while also obtaining a Diploma from Imperial College.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 19], [20, 22], [23, 35], [36, 39], [40, 51], [52, 56], [57, 60], [61, 71], [72, 74], [75, 83], [83, 85], [86, 95], [96, 103], [104, 111], [112, 118], [119, 121], [122, 126], [126, 127], [128, 133], [134, 142], [143, 145], [146, 149], [150, 156], [157, 168], [169, 178], [178, 179], [180, 183], [184, 187], [188, 191], [192, 194], [195, 205], [206, 217], [218, 222], [223, 231], [232, 239], [239, 240], [241, 251], [252, 254], [255, 261], [261, 262], [263, 265], [266, 270], [270, 271], [272, 277], [278, 282], [283, 292], [293, 294], [295, 302], [303, 307], [308, 316], [317, 324], [324, 325]]}
{"doc_key": "ai-dev-26", "ner": [[0, 1, "location"], [19, 23, "misc"], [31, 32, "misc"], [35, 37, "person"], [39, 40, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 23, 0, 1, "temporal", "", false, false], [31, 32, 0, 1, "temporal", "", false, false], [35, 37, 31, 32, "role", "actor_in", false, false], [39, 40, 31, 32, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Expo", "II", "saw", "the", "announcement", "of", "the", "world", "premiere", "of", "several", "films", "never", "before", "seen", "in", "3D", ",", "including", "\"", "The", "Wizard", "of", "Diamonds", "\"", "and", "Universal", "'s", "short", "film", "\"", "Hawaiian", "Nights", "\"", "starring", "Mami", "Van", "Doren", "and", "Pinky", "Lee", "."], "sentence-detokenized": "Expo II saw the announcement of the world premiere of several films never before seen in 3D, including \"The Wizard of Diamonds\" and Universal's short film \"Hawaiian Nights\" starring Mami Van Doren and Pinky Lee.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 15], [16, 28], [29, 31], [32, 35], [36, 41], [42, 50], [51, 53], [54, 61], [62, 67], [68, 73], [74, 80], [81, 85], [86, 88], [89, 91], [91, 92], [93, 102], [103, 104], [104, 107], [108, 114], [115, 117], [118, 126], [126, 127], [128, 131], [132, 141], [141, 143], [144, 149], [150, 154], [155, 156], [156, 164], [165, 171], [171, 172], [173, 181], [182, 186], [187, 190], [191, 196], [197, 200], [201, 206], [207, 210], [210, 211]]}
{"doc_key": "ai-dev-27", "ner": [[3, 4, "researcher"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 15, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1977", ",", "Ulf", "Grenander", "proposed", "the", "maximum", "subspace", "problem", "as", "a", "simplified", "model", "for", "estimating", "maximum", "likelihood", "models", "in", "digitised", "images", "."], "sentence-detokenized": "In 1977, Ulf Grenander proposed the maximum subspace problem as a simplified model for estimating maximum likelihood models in digitised images.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 22], [23, 31], [32, 35], [36, 43], [44, 52], [53, 60], [61, 63], [64, 65], [66, 76], [77, 82], [83, 86], [87, 97], [98, 105], [106, 116], [117, 123], [124, 126], [127, 136], [137, 143], [143, 144]]}
{"doc_key": "ai-dev-28", "ner": [[0, 1, "product"], [3, 4, "product"], [6, 8, "product"], [10, 11, "product"], [14, 15, "product"], [17, 20, "product"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[26, 26, 0, 1, "part-of", "", false, false], [26, 26, 3, 4, "part-of", "", false, false], [26, 26, 6, 8, "part-of", "", false, false], [26, 26, 10, 11, "part-of", "", false, false], [26, 26, 14, 15, "part-of", "", false, false], [26, 26, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["iPhone", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", ",", "iPod", "Touch", "5", "G", "and", "newer", "models", "come", "with", "Siri", ",", "a", "more", "advanced", "voice", "assistant", "."], "sentence-detokenized": "iPhone 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G, iPod Touch 5G and newer models come with Siri, a more advanced voice assistant.", "token2charspan": [[0, 6], [7, 9], [9, 10], [11, 15], [16, 17], [17, 18], [19, 23], [24, 28], [29, 31], [31, 32], [33, 37], [38, 41], [41, 42], [43, 47], [48, 51], [52, 54], [54, 55], [56, 60], [61, 66], [67, 68], [68, 69], [70, 73], [74, 79], [80, 86], [87, 91], [92, 96], [97, 101], [101, 102], [103, 104], [105, 109], [110, 118], [119, 124], [125, 134], [134, 135]]}
{"doc_key": "ai-dev-29", "ner": [[7, 8, "metrics"], [11, 14, "metrics"], [16, 21, "metrics"], [47, 49, "metrics"], [55, 58, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 14, 47, 49, "named", "", false, false], [16, 21, 11, 14, "named", "", false, false], [47, 49, 55, 58, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["It", "is", "easy", "to", "verify", "that", "the", "log", "loss", "and", "the", "binary", "cross", "entropy", "loss", "(", "Log", "loss", ")", "are", "in", "fact", "the", "same", "(", "up", "to", "a", "multiplicative", "constant", "math", "\\", "frac", "{", "1", "}", "{", "\\", "log", "(", "2", ")", "}", "/", "math", ")", ".", "Cross", "-entropy", "losses", "are", "closely", "related", "to", "the", "Kullback", "-", "Leibler", "divergence", "between", "the", "empirical", "distribution", "and", "the", "predicted", "distribution", "."], "sentence-detokenized": "It is easy to verify that the log loss and the binary cross entropy loss (Log loss) are in fact the same (up to a multiplicative constant math\\ frac {1} {\\ log (2)} / math). Cross-entropy losses are closely related to the Kullback-Leibler divergence between the empirical distribution and the predicted distribution.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 20], [21, 25], [26, 29], [30, 33], [34, 38], [39, 42], [43, 46], [47, 53], [54, 59], [60, 67], [68, 72], [73, 74], [74, 77], [78, 82], [82, 83], [84, 87], [88, 90], [91, 95], [96, 99], [100, 104], [105, 106], [106, 108], [109, 111], [112, 113], [114, 128], [129, 137], [138, 142], [142, 143], [144, 148], [149, 150], [150, 151], [151, 152], [153, 154], [154, 155], [156, 159], [160, 161], [161, 162], [162, 163], [163, 164], [165, 166], [167, 171], [171, 172], [172, 173], [174, 179], [179, 187], [188, 194], [195, 198], [199, 206], [207, 214], [215, 217], [218, 221], [222, 230], [230, 231], [231, 238], [239, 249], [250, 257], [258, 261], [262, 271], [272, 284], [285, 288], [289, 292], [293, 302], [303, 315], [315, 316]]}
{"doc_key": "ai-dev-30", "ner": [[0, 2, "algorithm"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "EM", "algorithm", "is", "used", "to", "find", "the", "(", "local", ")", "maximum", "likelihood", "parameters", "of", "a", "statistical", "model", "when", "the", "equations", "can", "not", "be", "solved", "directly", "."], "sentence-detokenized": "The EM algorithm is used to find the (local) maximum likelihood parameters of a statistical model when the equations cannot be solved directly.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 32], [33, 36], [37, 38], [38, 43], [43, 44], [45, 52], [53, 63], [64, 74], [75, 77], [78, 79], [80, 91], [92, 97], [98, 102], [103, 106], [107, 116], [117, 120], [120, 123], [124, 126], [127, 133], [134, 142], [142, 143]]}
{"doc_key": "ai-dev-31", "ner": [[9, 10, "task"], [13, 17, "task"], [19, 20, "task"], [22, 23, "task"], [5, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "studies", "were", "fundamental", "in", "the", "development", "of", "modern", "speech", "synthesis", "methods", ",", "reading", "devices", "for", "the", "blind", ",", "speech", "perception", "and", "speech", "recognition", "research", ",", "and", "motor", "theory", "of", "speech", "perception", "."], "sentence-detokenized": "These studies were fundamental in the development of modern speech synthesis methods, reading devices for the blind, speech perception and speech recognition research, and motor theory of speech perception.", "token2charspan": [[0, 5], [6, 13], [14, 18], [19, 30], [31, 33], [34, 37], [38, 49], [50, 52], [53, 59], [60, 66], [67, 76], [77, 84], [84, 85], [86, 93], [94, 101], [102, 105], [106, 109], [110, 115], [115, 116], [117, 123], [124, 134], [135, 138], [139, 145], [146, 157], [158, 166], [166, 167], [168, 171], [172, 177], [178, 184], [185, 187], [188, 194], [195, 205], [205, 206]]}
{"doc_key": "ai-dev-32", "ner": [[0, 1, "product"], [2, 4, "misc"], [6, 6, "misc"], [10, 12, "misc"], [14, 14, "product"], [16, 16, "product"], [18, 18, "product"], [23, 23, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 0, 1, "origin", "", false, false], [2, 4, 10, 12, "type-of", "", false, false], [2, 4, 14, 14, "related-to", "program_for", false, false], [2, 4, 16, 16, "related-to", "program_for", false, false], [2, 4, 18, 18, "related-to", "program_for", false, false], [2, 4, 23, 23, "related-to", "program_for", false, false], [6, 6, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "Arduino", "Integrated", "Development", "Environment", "(", "IDE", ")", "is", "a", "cross", "-platform", "application", "(", "Windows", ",", "macOS", "and", "Linux", ")", "written", "in", "the", "Java", "programming", "language", "."], "sentence-detokenized": "The Arduino Integrated Development Environment (IDE) is a cross-platform application (Windows, macOS and Linux) written in the Java programming language.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 57], [58, 63], [63, 72], [73, 84], [85, 86], [86, 93], [93, 94], [95, 100], [101, 104], [105, 110], [110, 111], [112, 119], [120, 122], [123, 126], [127, 131], [132, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-dev-33", "ner": [[17, 18, "algorithm"], [10, 11, "field"], [4, 5, "researcher"], [7, 9, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 18, 10, 11, "opposite", "", false, false], [4, 5, 10, 11, "related-to", "works_with", false, false], [7, 9, 10, 11, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["After", "the", "publication", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "'s", "machine", "learning", "research", "(", "1969", ")", ",", "neural", "network", "research", "came", "to", "a", "standstill", "."], "sentence-detokenized": "After the publication of Marvin Minsky and Seymour Papert's machine learning research (1969), neural network research came to a standstill.", "token2charspan": [[0, 5], [6, 9], [10, 21], [22, 24], [25, 31], [32, 38], [39, 42], [43, 50], [51, 57], [57, 59], [60, 67], [68, 76], [77, 85], [86, 87], [87, 91], [91, 92], [92, 93], [94, 100], [101, 108], [109, 117], [118, 122], [123, 125], [126, 127], [128, 138], [138, 139]]}
{"doc_key": "ai-dev-34", "ner": [[17, 18, "organisation"], [20, 20, "organisation"], [23, 23, "country"], [25, 25, "country"], [26, 29, "organisation"], [32, 32, "country"], [33, 34, "organisation"], [37, 37, "country"], [38, 38, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[26, 29, 23, 23, "general-affiliation", "", false, false], [26, 29, 25, 25, "general-affiliation", "", false, false], [33, 34, 32, 32, "general-affiliation", "", false, false], [38, 38, 37, 37, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Only", "a", "few", "non-Japanese", "companies", "have", "managed", "to", "survive", "in", "this", "market", ",", "the", "main", "ones", "being", "Adept", "Technology", ",", "St\u00e4ubli", ",", "the", "Swedish", "and", "Swiss", "ABB", "Asea", "Brown", "Boveri", ",", "the", "German", "KUKA", "Robotics", "and", "the", "Italian", "Comau", "."], "sentence-detokenized": "Only a few non-Japanese companies have managed to survive in this market, the main ones being Adept Technology, St\u00e4ubli, the Swedish and Swiss ABB Asea Brown Boveri, the German KUKA Robotics and the Italian Comau.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 23], [24, 33], [34, 38], [39, 46], [47, 49], [50, 57], [58, 60], [61, 65], [66, 72], [72, 73], [74, 77], [78, 82], [83, 87], [88, 93], [94, 99], [100, 110], [110, 111], [112, 119], [119, 120], [121, 124], [125, 132], [133, 136], [137, 142], [143, 146], [147, 151], [152, 157], [158, 164], [164, 165], [166, 169], [170, 176], [177, 181], [182, 190], [191, 194], [195, 198], [199, 206], [207, 212], [212, 213]]}
{"doc_key": "ai-dev-35", "ner": [[9, 12, "conference"], [15, 17, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 17, 9, 12, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Research", "activities", "include", "an", "annual", "research", "conference", "-", "the", "RuleML", "Symposium", ",", "also", "known", "as", "RuleML", "for", "short", "."], "sentence-detokenized": "Research activities include an annual research conference - the RuleML Symposium, also known as RuleML for short.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 30], [31, 37], [38, 46], [47, 57], [58, 59], [60, 63], [64, 70], [71, 80], [80, 81], [82, 86], [87, 92], [93, 95], [96, 102], [103, 106], [107, 112], [112, 113]]}
{"doc_key": "ai-dev-36", "ner": [[8, 9, "field"], [11, 12, "field"], [14, 14, "field"], [16, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Concepts", "are", "used", "as", "formal", "tools", "or", "models", "in", "mathematics", ",", "computer", "science", ",", "databases", "and", "artificial", "intelligence", ",", "where", "they", "are", "sometimes", "called", "classes", ",", "schemas", "or", "categories", "."], "sentence-detokenized": "Concepts are used as formal tools or models in mathematics, computer science, databases and artificial intelligence, where they are sometimes called classes, schemas or categories.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 33], [34, 36], [37, 43], [44, 46], [47, 58], [58, 59], [60, 68], [69, 76], [76, 77], [78, 87], [88, 91], [92, 102], [103, 115], [115, 116], [117, 122], [123, 127], [128, 131], [132, 141], [142, 148], [149, 156], [156, 157], [158, 165], [166, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-dev-37", "ner": [[6, 8, "organisation"], [11, 14, "organisation"], [17, 19, "organisation"], [20, 21, "organisation"], [24, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "received", "awards", "from", "the", "American", "Psychological", "Association", ",", "the", "National", "Academy", "of", "Sciences", ",", "the", "Royal", "Society", "for", "Cognitive", "Neuroscience", "and", "the", "American", "Humanist", "Association", "."], "sentence-detokenized": "He has received awards from the American Psychological Association, the National Academy of Sciences, the Royal Society for Cognitive Neuroscience and the American Humanist Association.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 22], [23, 27], [28, 31], [32, 40], [41, 54], [55, 66], [66, 67], [68, 71], [72, 80], [81, 88], [89, 91], [92, 100], [100, 101], [102, 105], [106, 111], [112, 119], [120, 123], [124, 133], [134, 146], [147, 150], [151, 154], [155, 163], [164, 172], [173, 184], [184, 185]]}
{"doc_key": "ai-dev-38", "ner": [[1, 2, "person"], [4, 5, "person"], [7, 8, "person"], [16, 19, "person"], [23, 32, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[23, 32, 16, 19, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starring", "Harrison", "Ford", ",", "Rutger", "Hauer", "and", "Sean", "Young", ",", "the", "film", "is", "loosely", "based", "on", "Philip", "K", ".", "Dick", "'s", "novel", "\"", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "?", "\"", "(", "1968", ")", "."], "sentence-detokenized": "Starring Harrison Ford, Rutger Hauer and Sean Young, the film is loosely based on Philip K. Dick's novel \"Do Androids Dream of Electric Sheep?\" (1968).", "token2charspan": [[0, 8], [9, 17], [18, 22], [22, 23], [24, 30], [31, 36], [37, 40], [41, 45], [46, 51], [51, 52], [53, 56], [57, 61], [62, 64], [65, 72], [73, 78], [79, 81], [82, 88], [89, 90], [90, 91], [92, 96], [96, 98], [99, 104], [105, 106], [106, 108], [109, 117], [118, 123], [124, 126], [127, 135], [136, 141], [141, 142], [142, 143], [144, 145], [145, 149], [149, 150], [150, 151]]}
{"doc_key": "ai-dev-39", "ner": [[0, 2, "task"], [3, 6, "algorithm"], [11, 12, "field"], [14, 15, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 3, 6, "usage", "", false, false], [0, 2, 11, 12, "part-of", "task_part_of_field", false, false], [0, 2, 14, 15, "part-of", "task_part_of_field", false, false], [0, 2, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Image", "segmentation", "using", "k-means", "clustering", "algorithms", "has", "long", "been", "used", "in", "pattern", "recognition", ",", "object", "detection", "and", "medical", "imaging", "."], "sentence-detokenized": "Image segmentation using k-means clustering algorithms has long been used in pattern recognition, object detection and medical imaging.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 32], [33, 43], [44, 54], [55, 58], [59, 63], [64, 68], [69, 73], [74, 76], [77, 84], [85, 96], [96, 97], [98, 104], [105, 114], [115, 118], [119, 126], [127, 134], [134, 135]]}
{"doc_key": "ai-dev-40", "ner": [[16, 16, "algorithm"], [19, 20, "algorithm"], [23, 23, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["General", "sampling", "from", "a", "truncated", "normal", "value", "can", "be", "done", "using", "approximations", "of", "the", "normal", "value", "CDF", "and", "the", "probit", "function", ",", "and", "R", "is", "a", "function", "codertnorm", "(", ")", "/", "code", "for", "sampling", "the", "truncated", "normal", "value", "."], "sentence-detokenized": "General sampling from a truncated normal value can be done using approximations of the normal value CDF and the probit function, and R is a function codertnorm()/code for sampling the truncated normal value.", "token2charspan": [[0, 7], [8, 16], [17, 21], [22, 23], [24, 33], [34, 40], [41, 46], [47, 50], [51, 53], [54, 58], [59, 64], [65, 79], [80, 82], [83, 86], [87, 93], [94, 99], [100, 103], [104, 107], [108, 111], [112, 118], [119, 127], [127, 128], [129, 132], [133, 134], [135, 137], [138, 139], [140, 148], [149, 159], [159, 160], [160, 161], [161, 162], [162, 166], [167, 170], [171, 179], [180, 183], [184, 193], [194, 200], [201, 206], [206, 207]]}
{"doc_key": "ai-dev-41", "ner": [[7, 7, "university"], [9, 9, "university"], [11, 13, "university"], [15, 17, "university"], [19, 20, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "also", "received", "honorary", "doctorates", "from", "Newcastle", ",", "Surrey", ",", "Tel", "Aviv", "University", ",", "Simon", "Fraser", "University", "and", "Tromso", "University", "."], "sentence-detokenized": "He has also received honorary doctorates from Newcastle, Surrey, Tel Aviv University, Simon Fraser University and Tromso University.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 29], [30, 40], [41, 45], [46, 55], [55, 56], [57, 63], [63, 64], [65, 68], [69, 73], [74, 84], [84, 85], [86, 91], [92, 98], [99, 109], [110, 113], [114, 120], [121, 131], [131, 132]]}
{"doc_key": "ai-dev-42", "ner": [[0, 1, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "Java", "implementation", "that", "uses", "zero", "-", "based", "array", "indexes", "together", "with", "a", "convenient", "method", "for", "printing", "the", "sequence", "of", "solved", "operations", ":"], "sentence-detokenized": "A Java implementation that uses zero-based array indexes together with a convenient method for printing the sequence of solved operations:", "token2charspan": [[0, 1], [2, 6], [7, 21], [22, 26], [27, 31], [32, 36], [36, 37], [37, 42], [43, 48], [49, 56], [57, 65], [66, 70], [71, 72], [73, 83], [84, 90], [91, 94], [95, 103], [104, 107], [108, 116], [117, 119], [120, 126], [127, 137], [137, 138]]}
{"doc_key": "ai-dev-43", "ner": [[7, 8, "metrics"], [11, 12, "metrics"], [21, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Such", "networks", "are", "usually", "trained", "in", "the", "Cross", "Entropy", "(", "or", "Cross", "Entropy", ")", "mode", ",", "yielding", "a", "non-linear", "variant", "of", "multinomial", "logistic", "regression", "."], "sentence-detokenized": "Such networks are usually trained in the Cross Entropy (or Cross Entropy) mode, yielding a non-linear variant of multinomial logistic regression.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 25], [26, 33], [34, 36], [37, 40], [41, 46], [47, 54], [55, 56], [56, 58], [59, 64], [65, 72], [72, 73], [74, 78], [78, 79], [80, 88], [89, 90], [91, 101], [102, 109], [110, 112], [113, 124], [125, 133], [134, 144], [144, 145]]}
{"doc_key": "ai-dev-44", "ner": [[0, 1, "conference"], [4, 4, "misc"], [5, 11, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ACL", "is", "the", "European", "chapter", "of", "the", "Association", "for", "Computational", "Linguistics", "."], "sentence-detokenized": "The ACL is the European chapter of the Association for Computational Linguistics.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 14], [15, 23], [24, 31], [32, 34], [35, 38], [39, 50], [51, 54], [55, 68], [69, 80], [80, 81]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 8, "researcher"], [19, 19, "misc"], [21, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 19, 19, "role", "", false, false], [6, 8, 19, 19, "role", "", false, false], [19, 19, 21, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "professors", ",", "Hal", "Abelson", "and", "Gerald", "Jay", "Sussman", ",", "chose", "to", "remain", "neutral", "-", "their", "group", "was", "called", "Switzerland", "and", "Project", "MAC", "for", "the", "next", "30", "years", "."], "sentence-detokenized": "Two professors, Hal Abelson and Gerald Jay Sussman, chose to remain neutral - their group was called Switzerland and Project MAC for the next 30 years.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 50], [50, 51], [52, 57], [58, 60], [61, 67], [68, 75], [76, 77], [78, 83], [84, 89], [90, 93], [94, 100], [101, 112], [113, 116], [117, 124], [125, 128], [129, 132], [133, 136], [137, 141], [142, 144], [145, 150], [150, 151]]}
{"doc_key": "ai-dev-46", "ner": [[1, 4, "misc"], [7, 7, "researcher"], [11, 19, "university"], [20, 20, "organisation"], [23, 27, "organisation"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 4, 7, 7, "temporal", "", false, false], [7, 7, 20, 20, "physical", "", false, false], [7, 7, 20, 20, "role", "", false, false], [7, 7, 23, 27, "role", "", false, false], [23, 27, 11, 19, "part-of", "", false, false], [29, 30, 23, 27, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["After", "completing", "his", "PhD", "in", "1995", ",", "Ghahramani", "moved", "to", "the", "University", "of", "Toronto", ",", "where", "he", "worked", "on", "an", "ITRC", "postdoctoral", "fellowship", "in", "the", "Artificial", "Intelligence", "Lab", "with", "Jeffrey", "Hinton", "."], "sentence-detokenized": "After completing his PhD in 1995, Ghahramani moved to the University of Toronto, where he worked on an ITRC postdoctoral fellowship in the Artificial Intelligence Lab with Jeffrey Hinton.", "token2charspan": [[0, 5], [6, 16], [17, 20], [21, 24], [25, 27], [28, 32], [32, 33], [34, 44], [45, 50], [51, 53], [54, 57], [58, 68], [69, 71], [72, 79], [79, 80], [81, 86], [87, 89], [90, 96], [97, 99], [100, 102], [103, 107], [108, 120], [121, 131], [132, 134], [135, 138], [139, 149], [150, 162], [163, 166], [167, 171], [172, 179], [180, 186], [186, 187]]}
{"doc_key": "ai-dev-47", "ner": [[22, 23, "metrics"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[25, 25, 22, 23, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Subsequent", "work", "focused", "on", "solving", "these", "problems", ",", "but", "it", "was", "only", "with", "the", "advent", "of", "modern", "computers", "and", "the", "popularisation", "of", "maximum", "likelihood", "(", "MLE", ")", "parameterisation", "methods", "that", "research", "really", "took", "off", "."], "sentence-detokenized": "Subsequent work focused on solving these problems, but it was only with the advent of modern computers and the popularisation of maximum likelihood (MLE) parameterisation methods that research really took off.", "token2charspan": [[0, 10], [11, 15], [16, 23], [24, 26], [27, 34], [35, 40], [41, 49], [49, 50], [51, 54], [55, 57], [58, 61], [62, 66], [67, 71], [72, 75], [76, 82], [83, 85], [86, 92], [93, 102], [103, 106], [107, 110], [111, 125], [126, 128], [129, 136], [137, 147], [148, 149], [149, 152], [152, 153], [154, 170], [171, 178], [179, 183], [184, 192], [193, 199], [200, 204], [205, 208], [208, 209]]}
{"doc_key": "ai-dev-48", "ner": [[5, 7, "person"], [9, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "series", "was", "produced", "by", "David", "Fincher", "and", "starred", "Kevin", "Spacey", "."], "sentence-detokenized": "The series was produced by David Fincher and starred Kevin Spacey.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 40], [41, 44], [45, 52], [53, 58], [59, 65], [65, 66]]}
{"doc_key": "ai-dev-49", "ner": [[16, 18, "metrics"], [21, 22, "algorithm"], [28, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 22, 28, 30, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Due", "to", "computational", "power", "constraints", ",", "current", "in", "silico", "methods", "typically", "have", "to", "trade", "speed", "for", "accuracy", ",", "e.g.", "using", "fast", "protein", "splicing", "methods", "rather", "than", "computationally", "expensive", "free", "energy", "calculations", "."], "sentence-detokenized": "Due to computational power constraints, current in silico methods typically have to trade speed for accuracy, e.g. using fast protein splicing methods rather than computationally expensive free energy calculations.", "token2charspan": [[0, 3], [4, 6], [7, 20], [21, 26], [27, 38], [38, 39], [40, 47], [48, 50], [51, 57], [58, 65], [66, 75], [76, 80], [81, 83], [84, 89], [90, 95], [96, 99], [100, 108], [108, 109], [110, 114], [115, 120], [121, 125], [126, 133], [134, 142], [143, 150], [151, 157], [158, 162], [163, 178], [179, 188], [189, 193], [194, 200], [201, 213], [213, 214]]}
{"doc_key": "ai-dev-50", "ner": [[7, 8, "country"], [10, 10, "country"], [12, 12, "country"], [14, 14, "country"], [16, 16, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "had", "more", "than", "30", "branches", "in", "the", "USA", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "sentence-detokenized": "It had more than 30 branches in the USA, Canada, Mexico, Brazil and Argentina.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 19], [20, 28], [29, 31], [32, 35], [36, 39], [39, 40], [41, 47], [47, 48], [49, 55], [55, 56], [57, 63], [64, 67], [68, 77], [77, 78]]}
{"doc_key": "ai-dev-51", "ner": [[4, 5, "field"], [8, 13, "product"], [14, 16, "algorithm"], [19, 20, "task"], [22, 23, "task"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 13, 4, 5, "part-of", "", false, false], [8, 13, 14, 16, "usage", "", false, false], [19, 20, 4, 5, "part-of", "task_part_of_field", false, false], [19, 20, 30, 30, "related-to", "performs", false, false], [22, 23, 4, 5, "part-of", "task_part_of_field", false, false], [22, 23, 30, 30, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Example", "of", "a", "typical", "computer", "vision", "computational", "pipeline", "for", "a", "face", "recognition", "system", "using", "k", "-", "NNs", ",", "including", "feature", "extraction", "and", "dimension", "reduction", "pre-processing", "steps", "(", "typically", "implemented", "with", "OpenCV", ")", ":"], "sentence-detokenized": "Example of a typical computer vision computational pipeline for a face recognition system using k -NNs, including feature extraction and dimension reduction pre-processing steps (typically implemented with OpenCV):", "token2charspan": [[0, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 36], [37, 50], [51, 59], [60, 63], [64, 65], [66, 70], [71, 82], [83, 89], [90, 95], [96, 97], [98, 99], [99, 102], [102, 103], [104, 113], [114, 121], [122, 132], [133, 136], [137, 146], [147, 156], [157, 171], [172, 177], [178, 179], [179, 188], [189, 200], [201, 205], [206, 212], [212, 213], [213, 214]]}
{"doc_key": "ai-dev-52", "ner": [[8, 11, "algorithm"], [13, 13, "misc"], [15, 16, "misc"], [18, 18, "misc"], [22, 22, "programlang"], [24, 24, "product"], [28, 28, "algorithm"], [30, 31, "misc"], [33, 33, "misc"], [35, 35, "misc"], [37, 37, "misc"], [43, 43, "misc"], [45, 46, "misc"], [48, 49, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "a", "rich", "feature", "set", ",", "libraries", "for", "constraint", "logic", "programming", ",", "multithreading", ",", "unit", "testing", ",", "GUI", ",", "interface", "to", "Java", ",", "ODBC", "and", "others", ",", "typing", ",", "web", "server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "developer", "tools", "(", "including", "IDE", "with", "GUI", "debugger", "and", "GUI", "profiler", ")", "and", "extensive", "documentation", "."], "sentence-detokenized": "It has a rich feature set, libraries for constraint logic programming, multithreading, unit testing, GUI, interface to Java, ODBC and others, typing, web server, SGML, RDF, RDFS, developer tools (including IDE with GUI debugger and GUI profiler) and extensive documentation.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 13], [14, 21], [22, 25], [25, 26], [27, 36], [37, 40], [41, 51], [52, 57], [58, 69], [69, 70], [71, 85], [85, 86], [87, 91], [92, 99], [99, 100], [101, 104], [104, 105], [106, 115], [116, 118], [119, 123], [123, 124], [125, 129], [130, 133], [134, 140], [140, 141], [142, 148], [148, 149], [150, 153], [154, 160], [160, 161], [162, 166], [166, 167], [168, 171], [171, 172], [173, 177], [177, 178], [179, 188], [189, 194], [195, 196], [196, 205], [206, 209], [210, 214], [215, 218], [219, 227], [228, 231], [232, 235], [236, 244], [244, 245], [246, 249], [250, 259], [260, 273], [273, 274]]}
{"doc_key": "ai-dev-53", "ner": [[0, 2, "field"], [4, 5, "field"], [10, 13, "misc"], [15, 17, "misc"], [20, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 13, 0, 2, "part-of", "", true, false], [10, 13, 4, 5, "part-of", "", false, false], [10, 13, 20, 22, "type-of", "", false, false], [15, 17, 0, 2, "part-of", "", false, false], [15, 17, 4, 5, "part-of", "", false, false], [15, 17, 20, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "computer", "vision", "and", "image", "processing", ",", "the", "concept", "of", "scale", "-", "space", "representation", "and", "Gaussian", "derivative", "operators", "are", "the", "canonical", "multiscale", "representation", "."], "sentence-detokenized": "In computer vision and image processing, the concept of scale-space representation and Gaussian derivative operators are the canonical multiscale representation.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 22], [23, 28], [29, 39], [39, 40], [41, 44], [45, 52], [53, 55], [56, 61], [61, 62], [62, 67], [68, 82], [83, 86], [87, 95], [96, 106], [107, 116], [117, 120], [121, 124], [125, 134], [135, 145], [146, 160], [160, 161]]}
{"doc_key": "ai-dev-54", "ner": [[5, 11, "organisation"], [20, 25, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 11, 20, 25, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "also", "President", "of", "the", "Foundation", "for", "Neural", "Information", "Processing", "Systems", ",", "a", "non-profit", "organisation", "that", "oversees", "the", "annual", "conference", "on", "neural", "information", "processing", "systems", "."], "sentence-detokenized": "He is also President of the Foundation for Neural Information Processing Systems, a non-profit organisation that oversees the annual conference on neural information processing systems.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 20], [21, 23], [24, 27], [28, 38], [39, 42], [43, 49], [50, 61], [62, 72], [73, 80], [80, 81], [82, 83], [84, 94], [95, 107], [108, 112], [113, 121], [122, 125], [126, 132], [133, 143], [144, 146], [147, 153], [154, 165], [166, 176], [177, 184], [184, 185]]}
{"doc_key": "ai-dev-55", "ner": [[0, 2, "task"], [6, 16, "metrics"], [13, 14, "misc"], [18, 18, "task"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 6, 16, "usage", "", false, false], [6, 16, 13, 14, "type-of", "", false, false], [18, 18, 22, 23, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["For", "regression", "analysis", "tasks", ",", "the", "squared", "error", "can", "be", "used", "as", "the", "loss", "function", ",", "and", "for", "classification", "tasks", ",", "the", "cross", "entropy", "can", "be", "used", "."], "sentence-detokenized": "For regression analysis tasks, the squared error can be used as the loss function, and for classification tasks, the cross entropy can be used.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 29], [29, 30], [31, 34], [35, 42], [43, 48], [49, 52], [53, 55], [56, 60], [61, 63], [64, 67], [68, 72], [73, 81], [81, 82], [83, 86], [87, 90], [91, 105], [106, 111], [111, 112], [113, 116], [117, 122], [123, 130], [131, 134], [135, 137], [138, 142], [142, 143]]}
{"doc_key": "ai-dev-56", "ner": [[0, 0, "researcher"], [18, 21, "conference"], [16, 17, "conference"], [30, 30, "university"], [33, 35, "field"], [44, 48, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 18, 21, "role", "", false, false], [0, 0, 30, 30, "physical", "", false, false], [0, 0, 30, 30, "role", "", false, false], [0, 0, 44, 48, "role", "", false, false], [18, 21, 16, 17, "named", "same", false, false], [30, 30, 33, 35, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Lafferty", "has", "held", "many", "prestigious", "positions", ",", "including", ":", "co", "-chair", "and", "overall", "co-chair", "of", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", "Foundation", "conference", "program", ";", "2", ")", "co-director", "of", "CMU", "'s", "new", "Machine", "Learning", "PhD", "program", ";", "3", ")", "associate", "editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research"], "sentence-detokenized": "Lafferty has held many prestigious positions, including: co-chair and overall co-chair of the Conference on Neural Information Processing Systems Foundation conference program; 2) co-director of CMU's new Machine Learning PhD program; 3) associate editor of the Journal of Machine Learning Research", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 34], [35, 44], [44, 45], [46, 55], [55, 56], [57, 59], [59, 65], [66, 69], [70, 77], [78, 86], [87, 89], [90, 93], [94, 104], [105, 107], [108, 114], [115, 126], [127, 137], [138, 145], [146, 156], [157, 167], [168, 175], [175, 176], [177, 178], [178, 179], [180, 191], [192, 194], [195, 198], [198, 200], [201, 204], [205, 212], [213, 221], [222, 225], [226, 233], [233, 234], [235, 236], [236, 237], [238, 247], [248, 254], [255, 257], [258, 261], [262, 269], [270, 272], [273, 280], [281, 289], [290, 298]]}
{"doc_key": "ai-dev-57", "ner": [[0, 3, "misc"], [4, 4, "algorithm"], [6, 6, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 0, 3, "type-of", "", false, false], [6, 6, 0, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Convex", "algorithms", "such", "as", "AdaBoost", "and", "LogitBoost", "can", "be", "destroyed", "by", "random", "noise", "and", "are", "therefore", "unable", "to", "learn", "basic", "and", "learnable", "combinations", "of", "weak", "hypotheses", "."], "sentence-detokenized": "Convex algorithms such as AdaBoost and LogitBoost can be destroyed by random noise and are therefore unable to learn basic and learnable combinations of weak hypotheses.", "token2charspan": [[0, 6], [7, 17], [18, 22], [23, 25], [26, 34], [35, 38], [39, 49], [50, 53], [54, 56], [57, 66], [67, 69], [70, 76], [77, 82], [83, 86], [87, 90], [91, 100], [101, 107], [108, 110], [111, 116], [117, 122], [123, 126], [127, 136], [137, 149], [150, 152], [153, 157], [158, 168], [168, 169]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [3, 7, "product"], [10, 12, "algorithm"], [18, 19, "algorithm"], [21, 27, "task"], [29, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 7, "type-of", "", false, false], [0, 0, 10, 12, "usage", "", false, false], [0, 0, 18, 19, "usage", "", false, false], [18, 19, 21, 27, "related-to", "used_for", true, false], [18, 19, 29, 31, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "is", "a", "shallow", "transfer", "machine", "translation", "system", "that", "uses", "finite", "state", "transducers", "for", "all", "lexical", "transformations", "and", "hidden", "Markov", "models", "for", "part", "-", "of", "-", "speech", "tagging", "or", "word", "category", "disambiguation", "."], "sentence-detokenized": "Apertium is a shallow transfer machine translation system that uses finite state transducers for all lexical transformations and hidden Markov models for part-of-speech tagging or word category disambiguation.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 21], [22, 30], [31, 38], [39, 50], [51, 57], [58, 62], [63, 67], [68, 74], [75, 80], [81, 92], [93, 96], [97, 100], [101, 108], [109, 124], [125, 128], [129, 135], [136, 142], [143, 149], [150, 153], [154, 158], [158, 159], [159, 161], [161, 162], [162, 168], [169, 176], [177, 179], [180, 184], [185, 193], [194, 208], [208, 209]]}
{"doc_key": "ai-dev-59", "ner": [[0, 2, "misc"], [14, 17, "metrics"], [33, 34, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 14, 17, "related-to", "", true, false], [14, 17, 33, 34, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "natural", "gradient", "mathE", "f", "(", "x", ")", "/", "math", ",", "which", "corresponds", "to", "the", "Fisher", "information", "metric", "(", "a", "measure", "of", "the", "informative", "distance", "between", "probability", "distributions", "and", "the", "curvature", "of", "the", "relative", "entropy", ")", ",", "is", "now", "as", "follows", "."], "sentence-detokenized": "The natural gradient mathE f (x) / math, which corresponds to the Fisher information metric (a measure of the informative distance between probability distributions and the curvature of the relative entropy), is now as follows.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 26], [27, 28], [29, 30], [30, 31], [31, 32], [33, 34], [35, 39], [39, 40], [41, 46], [47, 58], [59, 61], [62, 65], [66, 72], [73, 84], [85, 91], [92, 93], [93, 94], [95, 102], [103, 105], [106, 109], [110, 121], [122, 130], [131, 138], [139, 150], [151, 164], [165, 168], [169, 172], [173, 182], [183, 185], [186, 189], [190, 198], [199, 206], [206, 207], [207, 208], [209, 211], [212, 215], [216, 218], [219, 226], [226, 227]]}
{"doc_key": "ai-dev-60", "ner": [[0, 3, "programlang"], [6, 9, "product"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 0, 3, "origin", "", false, false], [11, 11, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "S", "programming", "language", "inspired", "the", "S", "'", "-", "PLUS", "and", "R", "systems", "."], "sentence-detokenized": "The S programming language inspired the S '-PLUS and R systems.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 26], [27, 35], [36, 39], [40, 41], [42, 43], [43, 44], [44, 48], [49, 52], [53, 54], [55, 62], [62, 63]]}
{"doc_key": "ai-dev-61", "ner": [[3, 3, "product"], [9, 9, "product"], [11, 15, "product"], [17, 19, "researcher"], [21, 22, "researcher"], [24, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 9, 9, "named", "same", false, false], [11, 15, 9, 9, "origin", "derived_from", false, false], [11, 15, 17, 19, "origin", "", false, false], [11, 15, 21, 22, "origin", "", false, false], [11, 15, 24, 25, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "most", "successful", "Planner", "implementation", "was", "a", "subset", "of", "Planner", "called", "Micro", "-", "Planner", ",", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "."], "sentence-detokenized": "The most successful Planner implementation was a subset of Planner called Micro-Planner, implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd.", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 27], [28, 42], [43, 46], [47, 48], [49, 55], [56, 58], [59, 66], [67, 73], [74, 79], [79, 80], [80, 87], [87, 88], [89, 100], [101, 103], [104, 110], [111, 114], [115, 122], [122, 123], [124, 130], [131, 139], [140, 143], [144, 149], [150, 158], [158, 159]]}
{"doc_key": "ai-dev-62", "ner": [[4, 6, "country"], [8, 11, "researcher"], [20, 20, "misc"], [21, 27, "university"], [32, 36, "misc"], [39, 40, "misc"], [42, 45, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[8, 11, 4, 6, "general-affiliation", "from_country", false, false], [21, 27, 20, 20, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1779", ",", "the", "German", "-", "Danish", "scientist", "Christian", "Gottlieb", "Kratzenstein", "won", "first", "prize", "in", "a", "competition", "launched", "by", "the", "Russian", "Imperial", "Academy", "of", "Sciences", "and", "Arts", "for", "models", "of", "the", "human", "vocal", "tract", "that", "could", "produce", "five", "long", "vowel", "sounds", "(", "International", "Phonetic", "Alphabetic", "System", "notes", ":"], "sentence-detokenized": "In 1779, the German-Danish scientist Christian Gottlieb Kratzenstein won first prize in a competition launched by the Russian Imperial Academy of Sciences and Arts for models of the human vocal tract that could produce five long vowel sounds (International Phonetic Alphabetic System notes:", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [19, 20], [20, 26], [27, 36], [37, 46], [47, 55], [56, 68], [69, 72], [73, 78], [79, 84], [85, 87], [88, 89], [90, 101], [102, 110], [111, 113], [114, 117], [118, 125], [126, 134], [135, 142], [143, 145], [146, 154], [155, 158], [159, 163], [164, 167], [168, 174], [175, 177], [178, 181], [182, 187], [188, 193], [194, 199], [200, 204], [205, 210], [211, 218], [219, 223], [224, 228], [229, 234], [235, 241], [242, 243], [243, 256], [257, 265], [266, 276], [277, 283], [284, 289], [289, 290]]}
{"doc_key": "ai-dev-63", "ner": [[3, 4, "product"], [6, 7, "misc"], [10, 15, "misc"], [31, 34, "misc"], [54, 55, "task"], [60, 61, "product"], [63, 63, "product"], [67, 68, "task"], [70, 71, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 4, 60, 61, "related-to", "supports_program", false, false], [3, 4, 63, 63, "related-to", "supports_program", false, false], [6, 7, 3, 4, "part-of", "", false, false], [10, 15, 3, 4, "part-of", "", false, false], [31, 34, 3, 4, "part-of", "", false, false], [54, 55, 3, 4, "part-of", "", false, false], [67, 68, 3, 4, "part-of", "", false, false], [70, 71, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["New", "features", "in", "Office", "XP", "include", "smart", "tags", ",", "a", "selection", "-", "based", "search", "function", "that", "recognises", "different", "types", "of", "text", "in", "a", "document", "so", "users", "can", "take", "additional", "actions", ";", "a", "taskbar", "interface", "that", "combines", "popular", "menu", "bar", "commands", "on", "the", "right", "-", "hand", "side", "of", "the", "screen", "for", "quick", "access", ";", "new", "document", "collaboration", "capabilities", ",", "support", "for", "MSN", "Groups", "and", "SharePoint", ",", "and", "integrated", "handwriting", "recognition", "and", "speech", "recognition", "capabilities", "."], "sentence-detokenized": "New features in Office XP include smart tags, a selection-based search function that recognises different types of text in a document so users can take additional actions; a taskbar interface that combines popular menu bar commands on the right-hand side of the screen for quick access; new document collaboration capabilities, support for MSN Groups and SharePoint, and integrated handwriting recognition and speech recognition capabilities.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 25], [26, 33], [34, 39], [40, 44], [44, 45], [46, 47], [48, 57], [57, 58], [58, 63], [64, 70], [71, 79], [80, 84], [85, 95], [96, 105], [106, 111], [112, 114], [115, 119], [120, 122], [123, 124], [125, 133], [134, 136], [137, 142], [143, 146], [147, 151], [152, 162], [163, 170], [170, 171], [172, 173], [174, 181], [182, 191], [192, 196], [197, 205], [206, 213], [214, 218], [219, 222], [223, 231], [232, 234], [235, 238], [239, 244], [244, 245], [245, 249], [250, 254], [255, 257], [258, 261], [262, 268], [269, 272], [273, 278], [279, 285], [285, 286], [287, 290], [291, 299], [300, 313], [314, 326], [326, 327], [328, 335], [336, 339], [340, 343], [344, 350], [351, 354], [355, 365], [365, 366], [367, 370], [371, 381], [382, 393], [394, 405], [406, 409], [410, 416], [417, 428], [429, 441], [441, 442]]}
{"doc_key": "ai-dev-64", "ner": [[5, 8, "algorithm"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 8, 11, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "many", "applications", ",", "the", "sigmoid", "function", "is", "used", "as", "the", "activation", "function", "in", "these", "network", "blocks", "."], "sentence-detokenized": "In many applications, the sigmoid function is used as the activation function in these network blocks.", "token2charspan": [[0, 2], [3, 7], [8, 20], [20, 21], [22, 25], [26, 33], [34, 42], [43, 45], [46, 50], [51, 53], [54, 57], [58, 68], [69, 77], [78, 80], [81, 86], [87, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-dev-65", "ner": [[3, 3, "researcher"], [12, 17, "organisation"], [29, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 12, 17, "role", "", false, false], [3, 3, 29, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2001", ",", "Mehler", "was", "elected", "a", "Foreign", "Honorary", "Member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "and", "in", "2003", "he", "was", "elected", "a", "Fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In 2001, Mehler was elected a Foreign Honorary Member of the American Academy of Arts and Sciences, and in 2003 he was elected a Fellow of the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 27], [28, 29], [30, 37], [38, 46], [47, 53], [54, 56], [57, 60], [61, 69], [70, 77], [78, 80], [81, 85], [86, 89], [90, 98], [98, 99], [100, 103], [104, 106], [107, 111], [112, 114], [115, 118], [119, 126], [127, 128], [129, 135], [136, 138], [139, 142], [143, 151], [152, 163], [164, 167], [168, 171], [172, 183], [184, 186], [187, 194], [194, 195]]}
{"doc_key": "ai-dev-66", "ner": [[4, 7, "task"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 7, 9, 10, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Extending", "this", "concept", "to", "non", "-binary", "classifications", "yields", "a", "mixing", "matrix", "."], "sentence-detokenized": "Extending this concept to non-binary classifications yields a mixing matrix.", "token2charspan": [[0, 9], [10, 14], [15, 22], [23, 25], [26, 29], [29, 36], [37, 52], [53, 59], [60, 61], [62, 68], [69, 75], [75, 76]]}
{"doc_key": "ai-dev-67", "ner": [[15, 16, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "updated", "estimate", "of", "the", "noise", "variance", "of", "the", "measurements", "can", "be", "obtained", "from", "the", "maximum", "likelihood", "calculation", "."], "sentence-detokenized": "An updated estimate of the noise variance of the measurements can be obtained from the maximum likelihood calculation.", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 22], [23, 26], [27, 32], [33, 41], [42, 44], [45, 48], [49, 61], [62, 65], [66, 68], [69, 77], [78, 82], [83, 86], [87, 94], [95, 105], [106, 117], [117, 118]]}
{"doc_key": "ai-dev-68", "ner": [[2, 4, "field"], [0, 1, "algorithm"], [9, 11, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 9, 11, "usage", "", true, false], [0, 1, 12, 13, "related-to", "", true, false], [9, 11, 2, 4, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "perceptron", "in", "machine", "learning", "is", "an", "algorithm", "for", "supervised", "learning", "of", "binary", "classifications", "."], "sentence-detokenized": "A perceptron in machine learning is an algorithm for supervised learning of binary classifications.", "token2charspan": [[0, 1], [2, 12], [13, 15], [16, 23], [24, 32], [33, 35], [36, 38], [39, 48], [49, 52], [53, 63], [64, 72], [73, 75], [76, 82], [83, 98], [98, 99]]}
{"doc_key": "ai-dev-69", "ner": [[5, 6, "field"], [8, 8, "field"], [13, 18, "conference"], [21, 25, "conference"], [28, 34, "conference"], [37, 41, "conference"], [44, 48, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 18, 5, 6, "topic", "", false, false], [13, 18, 8, 8, "topic", "", false, false], [21, 25, 5, 6, "topic", "", false, false], [21, 25, 8, 8, "topic", "", false, false], [28, 34, 5, 6, "topic", "", false, false], [28, 34, 8, 8, "topic", "", false, false], [37, 41, 5, 6, "topic", "", false, false], [37, 41, 8, 8, "topic", "", false, false], [44, 48, 5, 6, "topic", "", false, false], [44, 48, 8, 8, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["She", "has", "also", "chaired", "several", "machine", "learning", "and", "vision", "conferences", ",", "including", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "the", "International", "Conference", "on", "Learning", "Representations", ",", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "the", "International", "Conference", "on", "Computer", "Vision", "and", "the", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "She has also chaired several machine learning and vision conferences, including the Conference on Neural Information Processing Systems, the International Conference on Learning Representations, the Conference on Computer Vision and Pattern Recognition, the International Conference on Computer Vision and the European Conference on Computer Vision.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 20], [21, 28], [29, 36], [37, 45], [46, 49], [50, 56], [57, 68], [68, 69], [70, 79], [80, 83], [84, 94], [95, 97], [98, 104], [105, 116], [117, 127], [128, 135], [135, 136], [137, 140], [141, 154], [155, 165], [166, 168], [169, 177], [178, 193], [193, 194], [195, 198], [199, 209], [210, 212], [213, 221], [222, 228], [229, 232], [233, 240], [241, 252], [252, 253], [254, 257], [258, 271], [272, 282], [283, 285], [286, 294], [295, 301], [302, 305], [306, 309], [310, 318], [319, 329], [330, 332], [333, 341], [342, 348], [348, 349]]}
{"doc_key": "ai-dev-70", "ner": [[0, 2, "algorithm"], [8, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "condensation", "algorithm", "has", "also", "been", "used", "for", "face", "recognition", "in", "video", "sequences", "."], "sentence-detokenized": "The condensation algorithm has also been used for face recognition in video sequences.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 30], [31, 35], [36, 40], [41, 45], [46, 49], [50, 54], [55, 66], [67, 69], [70, 75], [76, 85], [85, 86]]}
{"doc_key": "ai-dev-71", "ner": [[0, 1, "task"], [6, 7, "organisation"], [13, 13, "conference"], [19, 24, "academicjournal"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 0, 1, "topic", "", false, false], [13, 13, 6, 7, "origin", "", false, false], [19, 24, 0, 1, "topic", "", false, false], [19, 24, 6, 7, "origin", "", true, false], [18, 18, 19, 24, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Disseminating", "information", "is", "also", "one", "of", "ELRA", "'s", "tasks", ",", "both", "through", "the", "LREC", "conference", "and", "through", "the", "Springer", "journal", "Language", "Resources", "and", "Evaluation", "Journal", "."], "sentence-detokenized": "Disseminating information is also one of ELRA's tasks, both through the LREC conference and through the Springer journal Language Resources and Evaluation Journal.", "token2charspan": [[0, 13], [14, 25], [26, 28], [29, 33], [34, 37], [38, 40], [41, 45], [45, 47], [48, 53], [53, 54], [55, 59], [60, 67], [68, 71], [72, 76], [77, 87], [88, 91], [92, 99], [100, 103], [104, 112], [113, 120], [121, 129], [130, 139], [140, 143], [144, 154], [155, 162], [162, 163]]}
{"doc_key": "ai-dev-72", "ner": [[0, 9, "field"], [11, 12, "field"], [14, 16, "field"], [18, 19, "field"], [54, 56, "field"], [61, 61, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 9, 54, 56, "named", "", false, false], [14, 16, 0, 9, "named", "", false, false], [61, 61, 11, 12, "part-of", "", true, false], [61, 61, 14, 16, "part-of", "", true, false], [61, 61, 54, 56, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "linear", "time", "-", "invariant", "(", "LTI", ")", "system", "theory", ",", "control", "theory", "and", "digital", "signal", "processing", "or", "signal", "processing", ",", "the", "relationship", "between", "the", "input", "signal", ",", "math", "\\", "displaystyle", "x", "(", "t", ")", "/", "math", ",", "and", "the", "output", "signal", ",", "math", "\\", "displaystyle", "y", "(", "t", ")", "/", "math", ",", "of", "an", "LTI", "system", "is", "determined", "by", "a", "convolution", "operation", ":"], "sentence-detokenized": "In linear time-invariant (LTI) system theory, control theory and digital signal processing or signal processing, the relationship between the input signal, math\\ displaystyle x (t) / math, and the output signal, math\\ displaystyle y (t) / math, of an LTI system is determined by a convolution operation:", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [15, 24], [25, 26], [26, 29], [29, 30], [31, 37], [38, 44], [44, 45], [46, 53], [54, 60], [61, 64], [65, 72], [73, 79], [80, 90], [91, 93], [94, 100], [101, 111], [111, 112], [113, 116], [117, 129], [130, 137], [138, 141], [142, 147], [148, 154], [154, 155], [156, 160], [160, 161], [162, 174], [175, 176], [177, 178], [178, 179], [179, 180], [181, 182], [183, 187], [187, 188], [189, 192], [193, 196], [197, 203], [204, 210], [210, 211], [212, 216], [216, 217], [218, 230], [231, 232], [233, 234], [234, 235], [235, 236], [237, 238], [239, 243], [243, 244], [245, 247], [248, 250], [251, 254], [255, 261], [262, 264], [265, 275], [276, 278], [279, 280], [281, 292], [293, 302], [302, 303]]}
{"doc_key": "ai-dev-73", "ner": [[16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 31, "field"], [33, 34, "product"], [36, 37, "field"], [39, 39, "field"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Due", "to", "its", "generality", ",", "this", "area", "is", "being", "explored", "in", "many", "other", "disciplines", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "family", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Due to its generality, this area is being explored in many other disciplines such as game theory, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, family intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 21], [21, 22], [23, 27], [28, 32], [33, 35], [36, 41], [42, 50], [51, 53], [54, 58], [59, 64], [65, 76], [77, 81], [82, 84], [85, 89], [90, 96], [96, 97], [98, 105], [106, 112], [112, 113], [114, 124], [125, 133], [133, 134], [135, 146], [147, 153], [153, 154], [155, 165], [165, 166], [166, 171], [172, 184], [184, 185], [186, 197], [198, 205], [205, 206], [207, 213], [214, 226], [226, 227], [228, 238], [239, 242], [243, 250], [251, 261], [261, 262]]}
{"doc_key": "ai-dev-74", "ner": [[0, 2, "algorithm"], [10, 11, "field"], [18, 19, "algorithm"], [22, 23, "algorithm"], [27, 28, "algorithm"], [31, 31, "algorithm"], [32, 36, "researcher"], [38, 39, "researcher"], [41, 43, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[10, 11, 0, 2, "usage", "", true, false], [18, 19, 10, 11, "part-of", "", true, false], [22, 23, 10, 11, "part-of", "", true, false], [27, 28, 10, 11, "part-of", "", true, false], [31, 31, 10, 11, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Stochastic", "gradient", "descent", "is", "a", "popular", "algorithm", "for", "training", "various", "machine", "learning", "models", ",", "including", "(", "linear", ")", "support", "vector", "machines", ",", "logistic", "regression", "(", "see", "e.g.", "Vowpal", "Wabbit", ")", "and", "graphical", "models", ".", "Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastic gradient descent is a popular algorithm for training various machine learning models, including (linear) support vector machines, logistic regression (see e.g. Vowpal Wabbit) and graphical models. Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 30], [31, 32], [33, 40], [41, 50], [51, 54], [55, 63], [64, 71], [72, 79], [80, 88], [89, 95], [95, 96], [97, 106], [107, 108], [108, 114], [114, 115], [116, 123], [124, 130], [131, 139], [139, 140], [141, 149], [150, 160], [161, 162], [162, 165], [166, 170], [171, 177], [178, 184], [184, 185], [186, 189], [190, 199], [200, 206], [206, 207], [208, 213], [214, 218], [219, 225], [225, 226], [227, 231], [232, 239], [239, 240], [241, 252], [253, 255], [256, 263], [264, 265], [265, 269], [269, 270], [270, 271]]}
{"doc_key": "ai-dev-75", "ner": [[8, 8, "organisation"], [12, 13, "product"], [19, 19, "country"], [22, 24, "university"], [25, 26, "location"], [28, 31, "university"], [32, 32, "location"], [34, 36, "university"], [37, 37, "location"], [39, 41, "university"], [42, 43, "location"], [45, 46, "university"], [47, 48, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 22, 24, "role", "donates_to", false, false], [8, 8, 28, 31, "role", "donates_to", false, false], [8, 8, 34, 36, "role", "donates_to", false, false], [8, 8, 39, 41, "role", "donates_to", false, false], [8, 8, 45, 46, "role", "donates_to", false, false], [12, 13, 8, 8, "origin", "donates", true, false], [22, 24, 25, 26, "physical", "", false, false], [25, 26, 19, 19, "physical", "", false, false], [28, 31, 32, 32, "physical", "", false, false], [32, 32, 19, 19, "physical", "", false, false], [34, 36, 37, 37, "physical", "", false, false], [37, 37, 19, 19, "physical", "", false, false], [39, 41, 42, 43, "physical", "", false, false], [42, 43, 19, 19, "physical", "", false, false], [45, 46, 47, 48, "physical", "", false, false], [47, 48, 19, 19, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["In", "August", "2011", ",", "it", "was", "announced", "that", "Hitachi", "would", "donate", "an", "electron", "microscope", "to", "each", "of", "the", "five", "Indonesian", "universities", "(", "North", "Sumatra", "University", "in", "Medan", ",", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Padjadjaran", "University", "in", "Bandung", ",", "Jenderal", "Soedirman", "University", "in", "Purwokerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "sentence-detokenized": "In August 2011, it was announced that Hitachi would donate an electron microscope to each of the five Indonesian universities (North Sumatra University in Medan, Indonesian Christian University in Jakarta, Padjadjaran University in Bandung, Jenderal Soedirman University in Purwokerto and Muhammadiyah University in Malang).", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 32], [33, 37], [38, 45], [46, 51], [52, 58], [59, 61], [62, 70], [71, 81], [82, 84], [85, 89], [90, 92], [93, 96], [97, 101], [102, 112], [113, 125], [126, 127], [127, 132], [133, 140], [141, 151], [152, 154], [155, 160], [160, 161], [162, 172], [173, 182], [183, 193], [194, 196], [197, 204], [204, 205], [206, 217], [218, 228], [229, 231], [232, 239], [239, 240], [241, 249], [250, 259], [260, 270], [271, 273], [274, 284], [285, 288], [289, 301], [302, 312], [313, 315], [316, 322], [322, 323], [323, 324]]}
{"doc_key": "ai-dev-76", "ner": [[2, 2, "field"], [0, 1, "field"], [6, 7, "algorithm"], [9, 12, "algorithm"], [18, 19, "field"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 0, 1, "part-of", "", false, false], [2, 2, 18, 19, "related-to", "", true, false], [2, 2, 24, 25, "related-to", "", true, false], [6, 7, 2, 2, "type-of", "", false, false], [9, 12, 2, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Operations", "research", "optimisation", "techniques", "such", "as", "linear", "programming", "or", "dynamic", "programming", "are", "often", "impractical", "for", "large", "-", "scale", "software", "engineering", "problems", "due", "to", "their", "computational", "complexity", "."], "sentence-detokenized": "Operations research optimisation techniques such as linear programming or dynamic programming are often impractical for large-scale software engineering problems due to their computational complexity.", "token2charspan": [[0, 10], [11, 19], [20, 32], [33, 43], [44, 48], [49, 51], [52, 58], [59, 70], [71, 73], [74, 81], [82, 93], [94, 97], [98, 103], [104, 115], [116, 119], [120, 125], [125, 126], [126, 131], [132, 140], [141, 152], [153, 161], [162, 165], [166, 168], [169, 174], [175, 188], [189, 199], [199, 200]]}
{"doc_key": "ai-dev-77", "ner": [[0, 0, "metrics"], [6, 6, "metrics"], [8, 10, "metrics"], [15, 16, "metrics"], [19, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 6, "compare", "", false, false], [0, 0, 8, 10, "compare", "", false, false], [15, 16, 8, 10, "part-of", "", false, false], [19, 26, 8, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sensitivity", "is", "not", "the", "same", "as", "accuracy", "or", "positive", "predictive", "value", "(", "the", "ratio", "of", "TRUE", "positives", "to", "combined", "TRUE", "and", "FALSE", "positives", ")", ",", "which", "is", "as", "much", "a", "statement", "about", "the", "proportion", "of", "actual", "positives", "in", "the", "test", "population", "as", "it", "is", "about", "the", "test", "."], "sentence-detokenized": "Sensitivity is not the same as accuracy or positive predictive value (the ratio of TRUE positives to combined TRUE and FALSE positives), which is as much a statement about the proportion of actual positives in the test population as it is about the test.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 22], [23, 27], [28, 30], [31, 39], [40, 42], [43, 51], [52, 62], [63, 68], [69, 70], [70, 73], [74, 79], [80, 82], [83, 87], [88, 97], [98, 100], [101, 109], [110, 114], [115, 118], [119, 124], [125, 134], [134, 135], [135, 136], [137, 142], [143, 145], [146, 148], [149, 153], [154, 155], [156, 165], [166, 171], [172, 175], [176, 186], [187, 189], [190, 196], [197, 206], [207, 209], [210, 213], [214, 218], [219, 229], [230, 232], [233, 235], [236, 238], [239, 244], [245, 248], [249, 253], [253, 254]]}
{"doc_key": "ai-dev-78", "ner": [[0, 2, "person"], [9, 9, "product"], [13, 13, "person"], [29, 29, "person"], [37, 38, "person"], [42, 42, "person"], [48, 49, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 42, 42, "named", "same", false, false], [9, 9, 0, 2, "artifact", "", false, false], [37, 38, 48, 49, "role", "convinces", false, false], [48, 49, 9, 9, "role", "producer", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Hampton", "Fancher", "scenario", "!", "--", "Originally", "untitled", "\"", "Android", "\"", "-", "see", "Sammon", ",", "pp.", "32", "and", "38", ",", "for", "an", "explanation", "-", "was", "bought", "in", "1977", ".", "Sammon", ",", "pp.", "23", "-", "30", ".", "Producer", "Michael", "Deeley", "became", "interested", "in", "Fancher", "'s", "draft", "and", "persuaded", "director", "Ridley", "Scott", "to", "screen", "it", "."], "sentence-detokenized": "The Hampton Fancher scenario! -- Originally untitled \"Android\" - see Sammon, pp. 32 and 38, for an explanation - was bought in 1977. Sammon, pp. 23-30. Producer Michael Deeley became interested in Fancher's draft and persuaded director Ridley Scott to screen it.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 28], [28, 29], [30, 32], [33, 43], [44, 52], [53, 54], [54, 61], [61, 62], [63, 64], [65, 68], [69, 75], [75, 76], [77, 80], [81, 83], [84, 87], [88, 90], [90, 91], [92, 95], [96, 98], [99, 110], [111, 112], [113, 116], [117, 123], [124, 126], [127, 131], [131, 132], [133, 139], [139, 140], [141, 144], [145, 147], [147, 148], [148, 150], [150, 151], [152, 160], [161, 168], [169, 175], [176, 182], [183, 193], [194, 196], [197, 204], [204, 206], [207, 212], [213, 216], [217, 226], [227, 235], [236, 242], [243, 248], [249, 251], [252, 258], [259, 261], [261, 262]]}
{"doc_key": "ai-dev-79", "ner": [[0, 1, "field"], [3, 4, "task"], [6, 8, "task"], [10, 12, "misc"], [14, 15, "field"], [17, 19, "task"], [21, 22, "task"], [24, 25, "field"], [28, 31, "task"], [33, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [6, 8, 0, 1, "part-of", "", false, false], [10, 12, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false], [17, 19, 0, 1, "part-of", "", false, false], [21, 22, 0, 1, "part-of", "", false, false], [24, 25, 0, 1, "part-of", "", false, false], [28, 31, 0, 1, "part-of", "", false, false], [33, 33, 0, 1, "part-of", "", false, false], [35, 36, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Text", "analysis", "includes", "information", "retrieval", ",", "lexical", "analysis", "to", "study", "word", "frequency", "distribution", ",", "pattern", "recognition", ",", "tagging", "/", "annotation", ",", "information", "extraction", ",", "data", "mining", "techniques", "including", "link", "and", "association", "analysis", ",", "visualisation", "and", "predictive", "analysis", "."], "sentence-detokenized": "Text analysis includes information retrieval, lexical analysis to study word frequency distribution, pattern recognition, tagging/annotation, information extraction, data mining techniques including link and association analysis, visualisation and predictive analysis.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 34], [35, 44], [44, 45], [46, 53], [54, 62], [63, 65], [66, 71], [72, 76], [77, 86], [87, 99], [99, 100], [101, 108], [109, 120], [120, 121], [122, 129], [129, 130], [130, 140], [140, 141], [142, 153], [154, 164], [164, 165], [166, 170], [171, 177], [178, 188], [189, 198], [199, 203], [204, 207], [208, 219], [220, 228], [228, 229], [230, 243], [244, 247], [248, 258], [259, 267], [267, 268]]}
{"doc_key": "ai-dev-80", "ner": [[3, 3, "product"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Several", "metrics", "use", "WordNet", ",", "a", "manually", "built", "lexical", "database", "of", "English", "words", "."], "sentence-detokenized": "Several metrics use WordNet, a manually built lexical database of English words.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 27], [27, 28], [29, 30], [31, 39], [40, 45], [46, 53], [54, 62], [63, 65], [66, 73], [74, 79], [79, 80]]}
{"doc_key": "ai-dev-81", "ner": [[3, 4, "field"], [6, 7, "task"], [9, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "system", "uses", "computational", "linguistics", ",", "information", "retrieval", "and", "knowledge", "representation", "techniques", "to", "find", "answers", "."], "sentence-detokenized": "The system uses computational linguistics, information retrieval and knowledge representation techniques to find answers.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 29], [30, 41], [41, 42], [43, 54], [55, 64], [65, 68], [69, 78], [79, 93], [94, 104], [105, 107], [108, 112], [113, 120], [120, 121]]}
{"doc_key": "ai-dev-82", "ner": [[0, 2, "metrics"], [12, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 12, 14, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "uncertainty", "factor", "as", "a", "performance", "indicator", "has", "an", "advantage", "over", "simple", "accuracy", "in", "that", "it", "is", "not", "affected", "by", "the", "relative", "magnitude", "of", "the", "different", "classes", "."], "sentence-detokenized": "The uncertainty factor as a performance indicator has an advantage over simple accuracy in that it is not affected by the relative magnitude of the different classes.", "token2charspan": [[0, 3], [4, 15], [16, 22], [23, 25], [26, 27], [28, 39], [40, 49], [50, 53], [54, 56], [57, 66], [67, 71], [72, 78], [79, 87], [88, 90], [91, 95], [96, 98], [99, 101], [102, 105], [106, 114], [115, 117], [118, 121], [122, 130], [131, 140], [141, 143], [144, 147], [148, 157], [158, 165], [165, 166]]}
{"doc_key": "ai-dev-83", "ner": [[7, 8, "algorithm"], [10, 11, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Researchers", "have", "tried", "several", "methods", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "hidden", "Markov", "models", ",", "etc", "."], "sentence-detokenized": "Researchers have tried several methods such as optical flow, Kalman filtering, hidden Markov models, etc.", "token2charspan": [[0, 11], [12, 16], [17, 22], [23, 30], [31, 38], [39, 43], [44, 46], [47, 54], [55, 59], [59, 60], [61, 67], [68, 77], [77, 78], [79, 85], [86, 92], [93, 99], [99, 100], [101, 104], [104, 105]]}
{"doc_key": "ai-dev-84", "ner": [[14, 33, "conference"], [30, 30, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "has", "served", "as", "President", ",", "Vice", "-", "President", "and", "Secretary", "-", "Treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "as", "well", "as", "Board", "Member", "and", "Board", "Secretary", "of", "the", "Association", "for", "Computational", "Linguistics", "."], "sentence-detokenized": "She has served as President, Vice-President and Secretary-Treasurer of the Association for Computational Linguistics, as well as Board Member and Board Secretary of the Association for Computational Linguistics.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 17], [18, 27], [27, 28], [29, 33], [33, 34], [34, 43], [44, 47], [48, 57], [57, 58], [58, 67], [68, 70], [71, 74], [75, 86], [87, 90], [91, 104], [105, 116], [116, 117], [118, 120], [121, 125], [126, 128], [129, 134], [135, 141], [142, 145], [146, 151], [152, 161], [162, 164], [165, 168], [169, 180], [181, 184], [185, 198], [199, 210], [210, 211]]}
{"doc_key": "ai-dev-85", "ner": [[6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 10, 10, "compare", "", false, false], [6, 6, 12, 13, "related-to", "supports", false, false], [8, 8, 10, 10, "compare", "", false, false], [8, 8, 12, 13, "related-to", "supports", false, false], [10, 10, 12, 13, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Like", "other", "similar", "languages", "such", "as", "APL", "and", "MATLAB", ",", "R", "supports", "matrix", "arithmetic", "."], "sentence-detokenized": "Like other similar languages such as APL and MATLAB, R supports matrix arithmetic.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 28], [29, 33], [34, 36], [37, 40], [41, 44], [45, 51], [51, 52], [53, 54], [55, 63], [64, 70], [71, 81], [81, 82]]}
{"doc_key": "ai-dev-86", "ner": [[2, 3, "misc"], [7, 9, "organisation"], [16, 17, "researcher"], [20, 22, "university"], [26, 29, "misc"], [31, 31, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 7, 9, "physical", "", false, false], [2, 3, 26, 29, "temporal", "", false, false], [16, 17, 2, 3, "role", "arranges", false, false], [16, 17, 20, 22, "role", "works_for", false, false], [31, 31, 2, 3, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "Turing", "Test", "competition", "at", "the", "Royal", "Society", "on", "7", "June", "2014", ",", "organised", "by", "Kevin", "Warwick", "of", "the", "University", "of", "Reading", "to", "celebrate", "the", "60th", "anniversary", "of", "Turing", ",", "Gostman", "won", "because", "33", "%", "of", "the", "judges", "were", "convinced", "that", "the", "robot", "was", "human", "."], "sentence-detokenized": "In the Turing Test competition at the Royal Society on 7 June 2014, organised by Kevin Warwick of the University of Reading to celebrate the 60th anniversary of Turing, Gostman won because 33% of the judges were convinced that the robot was human.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 30], [31, 33], [34, 37], [38, 43], [44, 51], [52, 54], [55, 56], [57, 61], [62, 66], [66, 67], [68, 77], [78, 80], [81, 86], [87, 94], [95, 97], [98, 101], [102, 112], [113, 115], [116, 123], [124, 126], [127, 136], [137, 140], [141, 145], [146, 157], [158, 160], [161, 167], [167, 168], [169, 176], [177, 180], [181, 188], [189, 191], [191, 192], [193, 195], [196, 199], [200, 206], [207, 211], [212, 221], [222, 226], [227, 230], [231, 236], [237, 240], [241, 246], [246, 247]]}
{"doc_key": "ai-dev-87", "ner": [[0, 2, "product"], [5, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "collaborative", "robot", ",", "or", "cobot", ",", "is", "a", "robot", "that", "can", "safely", "and", "efficiently", "interact", "with", "a", "human", "to", "perform", "simple", "industrial", "tasks", "."], "sentence-detokenized": "A collaborative robot, or cobot, is a robot that can safely and efficiently interact with a human to perform simple industrial tasks.", "token2charspan": [[0, 1], [2, 15], [16, 21], [21, 22], [23, 25], [26, 31], [31, 32], [33, 35], [36, 37], [38, 43], [44, 48], [49, 52], [53, 59], [60, 63], [64, 75], [76, 84], [85, 89], [90, 91], [92, 97], [98, 100], [101, 108], [109, 115], [116, 126], [127, 132], [132, 133]]}
{"doc_key": "ai-dev-88", "ner": [[9, 10, "field"], [14, 15, "task"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 31, "task"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[14, 15, 9, 10, "part-of", "task_part_of_field", false, false], [17, 18, 9, 10, "part-of", "task_part_of_field", false, false], [20, 21, 9, 10, "part-of", "task_part_of_field", false, false], [23, 24, 9, 10, "part-of", "task_part_of_field", false, false], [26, 27, 9, 10, "part-of", "task_part_of_field", false, false], [29, 31, 9, 10, "part-of", "task_part_of_field", false, false], [33, 34, 9, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "general", "framework", "has", "been", "applied", "to", "many", "different", "computer", "vision", "problems", ",", "including", "feature", "detection", ",", "feature", "classification", ",", "image", "segmentation", ",", "image", "matching", ",", "motion", "estimation", ",", "shape", "cue", "computation", "and", "object", "recognition", "."], "sentence-detokenized": "This general framework has been applied to many different computer vision problems, including feature detection, feature classification, image segmentation, image matching, motion estimation, shape cue computation and object recognition.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 26], [27, 31], [32, 39], [40, 42], [43, 47], [48, 57], [58, 66], [67, 73], [74, 82], [82, 83], [84, 93], [94, 101], [102, 111], [111, 112], [113, 120], [121, 135], [135, 136], [137, 142], [143, 155], [155, 156], [157, 162], [163, 171], [171, 172], [173, 179], [180, 190], [190, 191], [192, 197], [198, 201], [202, 213], [214, 217], [218, 224], [225, 236], [236, 237]]}
{"doc_key": "ai-dev-89", "ner": [[12, 14, "task"], [15, 17, "algorithm"], [6, 7, "algorithm"], [28, 29, "algorithm"], [33, 34, "algorithm"], [37, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 14, 15, 17, "part-of", "", false, false], [12, 14, 6, 7, "usage", "", false, false], [15, 17, 28, 29, "named", "same", false, false], [28, 29, 33, 34, "related-to", "", false, false], [28, 29, 37, 38, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "many", "practical", "applications", ",", "the", "maximum", "likelihood", "method", "is", "used", "for", "parameter", "estimation", "for", "naive", "Bayesian", "models", ";", "in", "other", "words", ",", "you", "can", "work", "with", "a", "naive", "Bayesian", "model", "without", "assuming", "Bayesian", "likelihoods", "or", "using", "Bayesian", "methods", "."], "sentence-detokenized": "In many practical applications, the maximum likelihood method is used for parameter estimation for naive Bayesian models; in other words, you can work with a naive Bayesian model without assuming Bayesian likelihoods or using Bayesian methods.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 30], [30, 31], [32, 35], [36, 43], [44, 54], [55, 61], [62, 64], [65, 69], [70, 73], [74, 83], [84, 94], [95, 98], [99, 104], [105, 113], [114, 120], [120, 121], [122, 124], [125, 130], [131, 136], [136, 137], [138, 141], [142, 145], [146, 150], [151, 155], [156, 157], [158, 163], [164, 172], [173, 178], [179, 186], [187, 195], [196, 204], [205, 216], [217, 219], [220, 225], [226, 234], [235, 242], [242, 243]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [12, 15, "university"], [17, 19, "researcher"], [21, 22, "misc"], [26, 26, "university"], [28, 28, "university"], [31, 33, "misc"], [38, 40, "university"], [47, 50, "misc"], [53, 56, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 4, 12, 15, "physical", "", false, false], [2, 4, 12, 15, "role", "", false, false], [2, 4, 17, 19, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [17, 19, 26, 26, "physical", "", false, false], [17, 19, 26, 26, "role", "", false, false], [17, 19, 28, 28, "physical", "", false, false], [17, 19, 28, 28, "role", "", false, false], [17, 19, 38, 40, "physical", "", false, false], [17, 19, 38, 40, "role", "", false, false], [21, 22, 17, 19, "named", "", false, false], [31, 33, 17, 19, "origin", "", false, false], [47, 50, 17, 19, "artifact", "", false, false], [47, 50, 53, 56, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Brothers", "-", "Victor", "Gershevich", "Katz", ",", "American", "mathematician", ",", "professor", "at", "the", "Massachusetts", "Institute", "of", "Technology", ";", "Mikhail", "Gershevich", "Katz", ",", "Israeli", "mathematician", ",", "graduate", "of", "Harvard", "and", "Columbia", "Universities", "(", "Ph.D.", ",", "1984", ")", ",", "professor", "at", "Bar-", "Ilan", "University", ",", "author", "of", "the", "monograph", "\"", "Systematic", "Geometry", "and", "Topology", "\"", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", "."], "sentence-detokenized": "Brothers - Victor Gershevich Katz, American mathematician, professor at the Massachusetts Institute of Technology; Mikhail Gershevich Katz, Israeli mathematician, graduate of Harvard and Columbia Universities (Ph.D., 1984), professor at Bar-Ilan University, author of the monograph \"Systematic Geometry and Topology\" (Mathematical Surveys and Monographs, vol.", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 28], [29, 33], [33, 34], [35, 43], [44, 57], [57, 58], [59, 68], [69, 71], [72, 75], [76, 89], [90, 99], [100, 102], [103, 113], [113, 114], [115, 122], [123, 133], [134, 138], [138, 139], [140, 147], [148, 161], [161, 162], [163, 171], [172, 174], [175, 182], [183, 186], [187, 195], [196, 208], [209, 210], [210, 215], [215, 216], [217, 221], [221, 222], [222, 223], [224, 233], [234, 236], [237, 241], [241, 245], [246, 256], [256, 257], [258, 264], [265, 267], [268, 271], [272, 281], [282, 283], [283, 293], [294, 302], [303, 306], [307, 315], [315, 316], [317, 318], [318, 330], [331, 338], [339, 342], [343, 353], [353, 354], [355, 358], [358, 359]]}
{"doc_key": "ai-dev-91", "ner": [[3, 4, "person"], [10, 11, "conference"], [15, 19, "organisation"], [20, 28, "location"], [33, 33, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 10, 11, "physical", "", false, false], [3, 4, 10, 11, "role", "", false, false], [3, 4, 15, 19, "role", "", false, false], [15, 19, 20, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2000", ",", "Manuel", "Toharia", ",", "lecturer", "of", "the", "previous", "Campus", "Parties", "and", "Director", "of", "the", "Pr\u00edncipe", "Felipe", "Science", "Museum", "in", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", ",", "proposed", "to", "expand", "Ragagel", "and", "make", "the", "event", "international", "by", "moving", "it", "to", "the", "famous", "museum", "."], "sentence-detokenized": "In 2000, Manuel Toharia, lecturer of the previous Campus Parties and Director of the Pr\u00edncipe Felipe Science Museum in the City of Arts and Sciences in Valencia, proposed to expand Ragagel and make the event international by moving it to the famous museum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 23], [23, 24], [25, 33], [34, 36], [37, 40], [41, 49], [50, 56], [57, 64], [65, 68], [69, 77], [78, 80], [81, 84], [85, 93], [94, 100], [101, 108], [109, 115], [116, 118], [119, 122], [123, 127], [128, 130], [131, 135], [136, 139], [140, 148], [149, 151], [152, 160], [160, 161], [162, 170], [171, 173], [174, 180], [181, 188], [189, 192], [193, 197], [198, 201], [202, 207], [208, 221], [222, 224], [225, 231], [232, 234], [235, 237], [238, 241], [242, 248], [249, 255], [255, 256]]}
{"doc_key": "ai-dev-92", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Within", "20", "minutes", ",", "the", "facial", "recognition", "system", "identifies", "personal", "information", ",", "including", "name", ",", "personal", "identification", "number", "and", "address", ",", "which", "is", "displayed", "on", "a", "street", "advertising", "screen", "."], "sentence-detokenized": "Within 20 minutes, the facial recognition system identifies personal information, including name, personal identification number and address, which is displayed on a street advertising screen.", "token2charspan": [[0, 6], [7, 9], [10, 17], [17, 18], [19, 22], [23, 29], [30, 41], [42, 48], [49, 59], [60, 68], [69, 80], [80, 81], [82, 91], [92, 96], [96, 97], [98, 106], [107, 121], [122, 128], [129, 132], [133, 140], [140, 141], [142, 147], [148, 150], [151, 160], [161, 163], [164, 165], [166, 172], [173, 184], [185, 191], [191, 192]]}
{"doc_key": "ai-dev-93", "ner": [[6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "research", "has", "increasingly", "focused", "on", "unsupervised", "learning", "and", "semi-supervised", "learning", "algorithms", "."], "sentence-detokenized": "Recent research has increasingly focused on unsupervised learning and semi-supervised learning algorithms.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 32], [33, 40], [41, 43], [44, 56], [57, 65], [66, 69], [70, 85], [86, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-94", "ner": [[5, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Calculation", "of", "this", "example", "using", "Python", "code", ":"], "sentence-detokenized": "Calculation of this example using Python code:", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 27], [28, 33], [34, 40], [41, 45], [45, 46]]}
{"doc_key": "ai-dev-95", "ner": [[6, 7, "task"], [14, 15, "field"], [20, 24, "algorithm"], [18, 18, "algorithm"], [28, 31, "algorithm"], [35, 36, "researcher"], [38, 39, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[20, 24, 14, 15, "part-of", "", false, false], [20, 24, 28, 31, "type-of", "", false, false], [20, 24, 35, 36, "origin", "", false, false], [20, 24, 38, 39, "origin", "", false, false], [18, 18, 20, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["However", ",", "nowadays", "many", "aspects", "of", "speech", "recognition", "have", "been", "taken", "over", "by", "a", "deep", "learning", "technique", "called", "LSTM", "(", "Long", "short", "-", "term", "memory", ")", ",", "a", "recurrent", "neural", "network", "published", "in", "1997", "by", "Sepp", "Hochreiter", "&", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "However, nowadays many aspects of speech recognition have been taken over by a deep learning technique called LSTM (Long short-term memory), a recurrent neural network published in 1997 by Sepp Hochreiter & J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 7], [7, 8], [9, 17], [18, 22], [23, 30], [31, 33], [34, 40], [41, 52], [53, 57], [58, 62], [63, 68], [69, 73], [74, 76], [77, 78], [79, 83], [84, 92], [93, 102], [103, 109], [110, 114], [115, 116], [116, 120], [121, 126], [126, 127], [127, 131], [132, 138], [138, 139], [139, 140], [141, 142], [143, 152], [153, 159], [160, 167], [168, 177], [178, 180], [181, 185], [186, 188], [189, 193], [194, 204], [205, 206], [207, 213], [214, 225], [225, 226]]}
{"doc_key": "ai-dev-96", "ner": [[8, 8, "algorithm"], [10, 10, "algorithm"], [17, 17, "algorithm"], [22, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 10, 10, "compare", "", false, false], [8, 8, 22, 22, "named", "same", false, false], [17, 17, 22, 22, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "initial", "experimental", "results", "with", "noisy", "datasets", ",", "BrownBoost", "outperformed", "AdaBoost", "in", "generalisation", "error", ";", "however", ",", "LogitBoost", "performed", "as", "well", "as", "BrownBoost", "."], "sentence-detokenized": "In initial experimental results with noisy datasets, BrownBoost outperformed AdaBoost in generalisation error; however, LogitBoost performed as well as BrownBoost.", "token2charspan": [[0, 2], [3, 10], [11, 23], [24, 31], [32, 36], [37, 42], [43, 51], [51, 52], [53, 63], [64, 76], [77, 85], [86, 88], [89, 103], [104, 109], [109, 110], [111, 118], [118, 119], [120, 130], [131, 140], [141, 143], [144, 148], [149, 151], [152, 162], [162, 163]]}
{"doc_key": "ai-dev-97", "ner": [[0, 1, "algorithm"], [8, 10, "researcher"], [5, 6, "country"], [13, 15, "researcher"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 8, 10, "part-of", "", false, false], [8, 10, 5, 6, "physical", "", false, false], [20, 21, 13, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evolutionary", "programming", "was", "introduced", "in", "the", "USA", "by", "Lawrence", "J.", "Fogel", ",", "and", "John", "Henry", "Holland", "called", "his", "method", "the", "genetic", "algorithm", "."], "sentence-detokenized": "Evolutionary programming was introduced in the USA by Lawrence J. Fogel, and John Henry Holland called his method the genetic algorithm.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 39], [40, 42], [43, 46], [47, 50], [51, 53], [54, 62], [63, 65], [66, 71], [71, 72], [73, 76], [77, 81], [82, 87], [88, 95], [96, 102], [103, 106], [107, 113], [114, 117], [118, 125], [126, 135], [135, 136]]}
{"doc_key": "ai-dev-98", "ner": [[2, 2, "researcher"], [4, 4, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 10, 11, "role", "", false, false], [2, 2, 13, 14, "role", "", false, false], [2, 2, 16, 17, "role", "", false, false], [2, 2, 19, 20, "role", "", false, false], [4, 4, 10, 11, "role", "", false, false], [4, 4, 13, 14, "role", "", false, false], [4, 4, 16, 17, "role", "", false, false], [4, 4, 19, 20, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Estimates", "by", "Doug", ",", "Alan", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", "and", "John", "McCarthy", ")", "showed", "that", "such", "an", "effort", "would", "require", "between", "1000", "and", "3000", "man", "-", "years", "of", "work", ",", "far", "beyond", "the", "standard", "academic", "project", "model", "."], "sentence-detokenized": "Estimates by Doug, Alan and their colleagues (including Marvin Minsky, Allen Newell, Edward Feigenbaum and John McCarthy) showed that such an effort would require between 1000 and 3000 man-years of work, far beyond the standard academic project model.", "token2charspan": [[0, 9], [10, 12], [13, 17], [17, 18], [19, 23], [24, 27], [28, 33], [34, 44], [45, 46], [46, 55], [56, 62], [63, 69], [69, 70], [71, 76], [77, 83], [83, 84], [85, 91], [92, 102], [103, 106], [107, 111], [112, 120], [120, 121], [122, 128], [129, 133], [134, 138], [139, 141], [142, 148], [149, 154], [155, 162], [163, 170], [171, 175], [176, 179], [180, 184], [185, 188], [188, 189], [189, 194], [195, 197], [198, 202], [202, 203], [204, 207], [208, 214], [215, 218], [219, 227], [228, 236], [237, 244], [245, 250], [250, 251]]}
{"doc_key": "ai-dev-99", "ner": [[5, 7, "metrics"], [11, 11, "metrics"], [14, 16, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 11, 11, "part-of", "implemented_in", false, false], [14, 16, 19, 19, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Commonly", "used", "criteria", "are", "the", "mean", "squared", "error", "criterion", "implemented", "by", "MSECriterion", "and", "the", "cross", "-entropy", "criterion", "implemented", "by", "NLLCriterion", "."], "sentence-detokenized": "Commonly used criteria are the mean squared error criterion implemented by MSECriterion and the cross-entropy criterion implemented by NLLCriterion.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 26], [27, 30], [31, 35], [36, 43], [44, 49], [50, 59], [60, 71], [72, 74], [75, 87], [88, 91], [92, 95], [96, 101], [101, 109], [110, 119], [120, 131], [132, 134], [135, 147], [147, 148]]}
{"doc_key": "ai-dev-100", "ner": [[0, 0, "researcher"], [11, 11, "organisation"], [14, 21, "misc"], [32, 36, "conference"], [43, 44, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 11, 11, "role", "", false, false], [0, 0, 32, 36, "role", "", false, false], [0, 0, 43, 44, "role", "", false, false], [14, 21, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zurada", "has", "served", "the", "engineering", "profession", "as", "a", "long", "-", "time", "IEEE", "volunteer", ":", "he", "was", "IEEE", "Vice", "President", "for", "Technical", "Activities", "(", "TAB", "Chair", ")", "in", "2014", ",", "President", "of", "the", "IEEE", "Computational", "Intelligence", "Society", "in", "2004-2005", ",", "and", "a", "member", "of", "ADCOM", "in", "2009-2014", ",", "2016-2018", ",", "and", "prior", "years", "."], "sentence-detokenized": "Zurada has served the engineering profession as a long-time IEEE volunteer: he was IEEE Vice President for Technical Activities (TAB Chair) in 2014, President of the IEEE Computational Intelligence Society in 2004-2005, and a member of ADCOM in 2009-2014, 2016-2018, and prior years.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 21], [22, 33], [34, 44], [45, 47], [48, 49], [50, 54], [54, 55], [55, 59], [60, 64], [65, 74], [74, 75], [76, 78], [79, 82], [83, 87], [88, 92], [93, 102], [103, 106], [107, 116], [117, 127], [128, 129], [129, 132], [133, 138], [138, 139], [140, 142], [143, 147], [147, 148], [149, 158], [159, 161], [162, 165], [166, 170], [171, 184], [185, 197], [198, 205], [206, 208], [209, 218], [218, 219], [220, 223], [224, 225], [226, 232], [233, 235], [236, 241], [242, 244], [245, 254], [254, 255], [256, 265], [265, 266], [267, 270], [271, 276], [277, 282], [282, 283]]}
{"doc_key": "ai-dev-101", "ner": [[3, 5, "field"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 5, "part-of", "", false, false], [11, 12, 3, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "general", ",", "computer", "linguistics", "involves", "linguists", ",", "computer", "scientists", ",", "artificial", "intelligence", "specialists", ",", "mathematicians", ",", "logicians", ",", "philosophers", ",", "cognitive", "scientists", ",", "cognitive", "psychologists", ",", "psycholinguists", ",", "anthropologists", ",", "neuroscientists", "and", "others", "."], "sentence-detokenized": "In general, computer linguistics involves linguists, computer scientists, artificial intelligence specialists, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists, neuroscientists and others.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 20], [21, 32], [33, 41], [42, 51], [51, 52], [53, 61], [62, 72], [72, 73], [74, 84], [85, 97], [98, 109], [109, 110], [111, 125], [125, 126], [127, 136], [136, 137], [138, 150], [150, 151], [152, 161], [162, 172], [172, 173], [174, 183], [184, 197], [197, 198], [199, 214], [214, 215], [216, 231], [231, 232], [233, 248], [249, 252], [253, 259], [259, 260]]}
{"doc_key": "ai-dev-102", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "-", "term", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "inter", "-", "frame", "correlations", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long-term short-term memory are often used to exploit inter-frame correlations.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [82, 83], [83, 87], [88, 93], [93, 94], [94, 98], [99, 105], [106, 109], [110, 115], [116, 120], [121, 123], [124, 131], [132, 137], [137, 138], [138, 143], [144, 156], [156, 157]]}
{"doc_key": "ai-dev-103", "ner": [[0, 0, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "was", "the", "first", "industrial", "robot", ","], "sentence-detokenized": "Unimate was the first industrial robot,", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 21], [22, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-dev-104", "ner": [[8, 9, "researcher"], [11, 12, "researcher"], [0, 0, "researcher"], [3, 5, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 3, 5, "win-defeat", "", false, false], [11, 12, 3, 5, "win-defeat", "", false, false], [0, 0, 3, 5, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Bengio", "received", "the", "2018", "Turing", "Award", "along", "with", "Jeffrey", "Hinton", "and", "Jan", "Lekun", "."], "sentence-detokenized": "Bengio received the 2018 Turing Award along with Jeffrey Hinton and Jan Lekun.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 24], [25, 31], [32, 37], [38, 43], [44, 48], [49, 56], [57, 63], [64, 67], [68, 71], [72, 77], [77, 78]]}
{"doc_key": "ai-dev-105", "ner": [[6, 6, "country"], [17, 19, "misc"], [22, 22, "country"], [24, 27, "organisation"], [31, 32, "person"], [34, 36, "person"], [41, 44, "misc"], [47, 49, "country"], [53, 54, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[17, 19, 6, 6, "physical", "filmed_in", false, false], [31, 32, 24, 27, "role", "host", false, false], [34, 36, 24, 27, "role", "reporter", false, false], [41, 44, 6, 6, "physical", "filmed_in", false, false], [41, 44, 47, 49, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Additional", "series", "were", "made", "in", "the", "UK", "for", "specific", "market", "sectors", "around", "the", "world", ",", "including", "two", "Robot", "Wars", "Extreme", "series", "with", "US", "competitors", "for", "the", "TNN", "network", "(", "hosted", "by", "Mick", "Foley", "with", "Rebecca", "Grant", "as", "reporter", ")", ",", "two", "Dutch", "Robot", "Wars", "series", "for", "distribution", "in", "the", "Netherlands", "and", "one", "series", "for", "Germany", "."], "sentence-detokenized": "Additional series were made in the UK for specific market sectors around the world, including two Robot Wars Extreme series with US competitors for the TNN network (hosted by Mick Foley with Rebecca Grant as reporter), two Dutch Robot Wars series for distribution in the Netherlands and one series for Germany.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 37], [38, 41], [42, 50], [51, 57], [58, 65], [66, 72], [73, 76], [77, 82], [82, 83], [84, 93], [94, 97], [98, 103], [104, 108], [109, 116], [117, 123], [124, 128], [129, 131], [132, 143], [144, 147], [148, 151], [152, 155], [156, 163], [164, 165], [165, 171], [172, 174], [175, 179], [180, 185], [186, 190], [191, 198], [199, 204], [205, 207], [208, 216], [216, 217], [217, 218], [219, 222], [223, 228], [229, 234], [235, 239], [240, 246], [247, 250], [251, 263], [264, 266], [267, 270], [271, 282], [283, 286], [287, 290], [291, 297], [298, 301], [302, 309], [309, 310]]}
{"doc_key": "ai-dev-106", "ner": [[8, 8, "researcher"], [13, 13, "product"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 13, 13, "role", "", false, false], [30, 31, 13, 13, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "many", "years", ",", "starting", "in", "1986", ",", "Miller", "led", "the", "development", "of", "WordNet", ",", "a", "large", "computer", "-", "readable", "electronic", "reference", "that", "can", "be", "used", "in", "applications", "such", "as", "search", "engines", "."], "sentence-detokenized": "For many years, starting in 1986, Miller led the development of WordNet, a large computer-readable electronic reference that can be used in applications such as search engines.", "token2charspan": [[0, 3], [4, 8], [9, 14], [14, 15], [16, 24], [25, 27], [28, 32], [32, 33], [34, 40], [41, 44], [45, 48], [49, 60], [61, 63], [64, 71], [71, 72], [73, 74], [75, 80], [81, 89], [89, 90], [90, 98], [99, 109], [110, 119], [120, 124], [125, 128], [129, 131], [132, 136], [137, 139], [140, 152], [153, 157], [158, 160], [161, 167], [168, 175], [175, 176]]}
{"doc_key": "ai-dev-107", "ner": [[3, 4, "algorithm"], [7, 10, "algorithm"], [13, 15, "researcher"], [18, 24, "organisation"], [28, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 13, 15, "origin", "", false, false], [3, 4, 28, 30, "win-defeat", "", false, false], [7, 10, 13, 15, "origin", "", false, false], [7, 10, 28, 30, "win-defeat", "", false, false], [13, 15, 18, 24, "physical", "", false, false], [13, 15, 18, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Since", "2009", ",", "recurrent", "neural", "networks", "and", "deep", "feedforward", "neural", "networks", "developed", "by", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "Swiss", "artificial", "intelligence", "laboratory", "IDSIA", "have", "won", "several", "international", "manuscript", "competitions", "."], "sentence-detokenized": "Since 2009, recurrent neural networks and deep feedforward neural networks developed by J\u00fcrgen Schmidhuber's research group at the Swiss artificial intelligence laboratory IDSIA have won several international manuscript competitions.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 21], [22, 28], [29, 37], [38, 41], [42, 46], [47, 58], [59, 65], [66, 74], [75, 84], [85, 87], [88, 94], [95, 106], [106, 108], [109, 117], [118, 123], [124, 126], [127, 130], [131, 136], [137, 147], [148, 160], [161, 171], [172, 177], [178, 182], [183, 186], [187, 194], [195, 208], [209, 219], [220, 232], [232, 233]]}
{"doc_key": "ai-dev-108", "ner": [[5, 6, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "is", "implemented", "in", "C", "+++", "and", "is", "wrapped", "in", "Python", "."], "sentence-detokenized": "The software is implemented in C+++ and is wrapped in Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 30], [31, 32], [32, 35], [36, 39], [40, 42], [43, 50], [51, 53], [54, 60], [60, 61]]}
{"doc_key": "ai-dev-109", "ner": [[7, 9, "country"], [14, 15, "misc"], [20, 21, "misc"], [37, 37, "misc"], [40, 40, "misc"], [33, 33, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 7, 9, "temporal", "", false, false], [20, 21, 14, 15, "artifact", "", false, false], [20, 21, 33, 33, "physical", "", false, false], [40, 40, 37, 37, "named", "", false, false], [40, 40, 33, 33, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1857", ",", "at", "the", "request", "of", "the", "Tokugawa", "shogunate", ",", "a", "group", "of", "Dutch", "engineers", "began", "construction", "of", "the", "Nagasaki", "Yotetsusho", ",", "a", "modern", ",", "western", "-", "style", "foundry", "and", "shipyard", "in", "Nagasaki", ",", "near", "the", "Dutch", "settlement", "of", "Dejima", "."], "sentence-detokenized": "In 1857, at the request of the Tokugawa shogunate, a group of Dutch engineers began construction of the Nagasaki Yotetsusho, a modern, western-style foundry and shipyard in Nagasaki, near the Dutch settlement of Dejima.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 39], [40, 49], [49, 50], [51, 52], [53, 58], [59, 61], [62, 67], [68, 77], [78, 83], [84, 96], [97, 99], [100, 103], [104, 112], [113, 123], [123, 124], [125, 126], [127, 133], [133, 134], [135, 142], [142, 143], [143, 148], [149, 156], [157, 160], [161, 169], [170, 172], [173, 181], [181, 182], [183, 187], [188, 191], [192, 197], [198, 208], [209, 211], [212, 218], [218, 219]]}
{"doc_key": "ai-dev-110", "ner": [[7, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["We", "measure", "as", "accurately", "as", "possible", "the", "mean", "squared", "error", "between", "mathy", "/", "math", "and", "math", "\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "we", "want", "math", "(", "y", "-\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", ".", "^", "2", "/", "math", "should", "be", "minimal", "for", "both", "mathx", "_", "1", ",\\", "points", ",", "x", "_n", "/", "math", ",", "and", "points", "outside", "our", "sample", "."], "sentence-detokenized": "We measure as accurately as possible the mean squared error between mathy/math and math\\ hat {f} (x; D) / math: we want math (y -\\ hat {f} (x; D)). ^ 2 / math should be minimal for both mathx _ 1,\\ points, x _n / math, and points outside our sample.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 27], [28, 36], [37, 40], [41, 45], [46, 53], [54, 59], [60, 67], [68, 73], [73, 74], [74, 78], [79, 82], [83, 87], [87, 88], [89, 92], [93, 94], [94, 95], [95, 96], [97, 98], [98, 99], [99, 100], [101, 102], [102, 103], [104, 105], [106, 110], [110, 111], [112, 114], [115, 119], [120, 124], [125, 126], [126, 127], [128, 130], [131, 134], [135, 136], [136, 137], [137, 138], [139, 140], [140, 141], [141, 142], [143, 144], [144, 145], [145, 146], [146, 147], [148, 149], [150, 151], [152, 153], [154, 158], [159, 165], [166, 168], [169, 176], [177, 180], [181, 185], [186, 191], [192, 193], [194, 195], [195, 197], [198, 204], [204, 205], [206, 207], [208, 210], [211, 212], [213, 217], [217, 218], [219, 222], [223, 229], [230, 237], [238, 241], [242, 248], [248, 249]]}
{"doc_key": "ai-dev-111", "ner": [[3, 3, "researcher"], [10, 13, "organisation"], [19, 23, "product"], [30, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 10, 13, "role", "", false, false], [19, 23, 10, 13, "temporal", "", false, false], [19, 23, 30, 31, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "then", "invited", "Widner", "to", "attend", "the", "annual", "meeting", "of", "the", "American", "Translators", "Association", "the", "following", "October", ",", "where", "Widner", "'s", "machine", "translation", "system", "was", "hailed", "as", "the", "breakthrough", "in", "machine", "translation", "that", "had", "been", "hoped", "for", "."], "sentence-detokenized": "He then invited Widner to attend the annual meeting of the American Translators Association the following October, where Widner's machine translation system was hailed as the breakthrough in machine translation that had been hoped for.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 22], [23, 25], [26, 32], [33, 36], [37, 43], [44, 51], [52, 54], [55, 58], [59, 67], [68, 79], [80, 91], [92, 95], [96, 105], [106, 113], [113, 114], [115, 120], [121, 127], [127, 129], [130, 137], [138, 149], [150, 156], [157, 160], [161, 167], [168, 170], [171, 174], [175, 187], [188, 190], [191, 198], [199, 210], [211, 215], [216, 219], [220, 224], [225, 230], [231, 234], [234, 235]]}
{"doc_key": "ai-dev-112", "ner": [[6, 13, "conference"], [15, 15, "conference"], [0, 0, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 6, 13, "named", "", false, false], [15, 15, 6, 13, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Google", "researchers", "presented", "this", "work", "at", "the", "2018", "Conference", "on", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "."], "sentence-detokenized": "Google researchers presented this work at the 2018 Conference on Neural Information Processing Systems (NeurIPS).", "token2charspan": [[0, 6], [7, 18], [19, 28], [29, 33], [34, 38], [39, 41], [42, 45], [46, 50], [51, 61], [62, 64], [65, 71], [72, 83], [84, 94], [95, 102], [103, 104], [104, 111], [111, 112], [112, 113]]}
{"doc_key": "ai-dev-113", "ner": [[0, 4, "algorithm"], [10, 12, "algorithm"], [15, 19, "metrics"], [20, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 10, 12, "usage", "", false, false], [10, 12, 15, 19, "related-to", "", true, false], [15, 19, 20, 22, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Baum", "-", "Welch", "algorithm", "uses", "the", "well", "-", "known", "EM", "algorithm", "to", "find", "the", "maximum", "likelihood", "estimate", "of", "the", "hidden", "Markov", "model", "parameters", "given", "a", "set", "of", "observable", "feature", "vectors", "."], "sentence-detokenized": "The Baum-Welch algorithm uses the well-known EM algorithm to find the maximum likelihood estimate of the hidden Markov model parameters given a set of observable feature vectors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [15, 24], [25, 29], [30, 33], [34, 38], [38, 39], [39, 44], [45, 47], [48, 57], [58, 60], [61, 65], [66, 69], [70, 77], [78, 88], [89, 97], [98, 100], [101, 104], [105, 111], [112, 118], [119, 124], [125, 135], [136, 141], [142, 143], [144, 147], [148, 150], [151, 161], [162, 169], [170, 177], [177, 178]]}
{"doc_key": "ai-dev-114", "ner": [[9, 9, "product"], [11, 11, "product"], [29, 31, "misc"], [36, 44, "product"], [50, 55, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[9, 9, 11, 11, "compare", "", false, false], [29, 31, 11, 11, "part-of", "", false, false], [36, 44, 11, 11, "part-of", "", false, false], [50, 55, 11, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": [")", "In", "addition", "to", "the", "taxonomic", "information", "contained", "in", "OpenCyc", ",", "ResearchCyc", "contains", "considerably", "more", "semantic", "knowledge", "(", "i.e.", "additional", "facts", "and", "patterns", ")", "about", "the", "concepts", "included", "in", "the", "knowledge", "base", ";", "it", "also", "includes", "an", "extensive", "lexicon", ",", "English", "parsing", "and", "generation", "tools", ",", "and", "Java", "-", "based", "interfaces", "for", "knowledge", "editing", "and", "querying", "."], "sentence-detokenized": ") In addition to the taxonomic information contained in OpenCyc, ResearchCyc contains considerably more semantic knowledge (i.e. additional facts and patterns) about the concepts included in the knowledge base; it also includes an extensive lexicon, English parsing and generation tools, and Java-based interfaces for knowledge editing and querying.", "token2charspan": [[0, 1], [2, 4], [5, 13], [14, 16], [17, 20], [21, 30], [31, 42], [43, 52], [53, 55], [56, 63], [63, 64], [65, 76], [77, 85], [86, 98], [99, 103], [104, 112], [113, 122], [123, 124], [124, 128], [129, 139], [140, 145], [146, 149], [150, 158], [158, 159], [160, 165], [166, 169], [170, 178], [179, 187], [188, 190], [191, 194], [195, 204], [205, 209], [209, 210], [211, 213], [214, 218], [219, 227], [228, 230], [231, 240], [241, 248], [248, 249], [250, 257], [258, 265], [266, 269], [270, 280], [281, 286], [286, 287], [288, 291], [292, 296], [296, 297], [297, 302], [303, 313], [314, 317], [318, 327], [328, 335], [336, 339], [340, 348], [348, 349]]}
{"doc_key": "ai-dev-115", "ner": [[0, 2, "algorithm"], [5, 6, "task"], [10, 11, "field"], [13, 14, "field"], [16, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 6, "type-of", "", false, false], [5, 6, 10, 11, "part-of", "task_part_of_field", false, false], [5, 6, 13, 14, "part-of", "task_part_of_field", false, false], [5, 6, 16, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Hough", "transform", "is", "a", "feature", "extraction", "method", "used", "in", "image", "analysis", ",", "computer", "vision", "and", "digital", "image", "processing", "."], "sentence-detokenized": "The Hough transform is a feature extraction method used in image analysis, computer vision and digital image processing.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 22], [23, 24], [25, 32], [33, 43], [44, 50], [51, 55], [56, 58], [59, 64], [65, 73], [73, 74], [75, 83], [84, 90], [91, 94], [95, 102], [103, 108], [109, 119], [119, 120]]}
{"doc_key": "ai-dev-116", "ner": [[6, 6, "product"], [8, 12, "product"], [3, 3, "organisation"], [19, 19, "product"], [21, 22, "researcher"], [25, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 8, 12, "named", "", false, false], [6, 6, 3, 3, "artifact", "", false, false], [6, 6, 19, 19, "origin", "developed_from", false, false], [19, 19, 21, 22, "artifact", "", false, false], [25, 26, 3, 3, "role", "supported", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1978", ",", "Unimation", "developed", "the", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "robot", "with", "the", "support", "of", "Vicarm", "(", "Victor", "Scheinman", ")", "and", "General", "Motors", "."], "sentence-detokenized": "In 1978, Unimation developed the PUMA (Programmable Universal Machine for Assembly) robot with the support of Vicarm (Victor Scheinman) and General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 28], [29, 32], [33, 37], [38, 39], [39, 51], [52, 61], [62, 69], [70, 73], [74, 82], [82, 83], [84, 89], [90, 94], [95, 98], [99, 106], [107, 109], [110, 116], [117, 118], [118, 124], [125, 134], [134, 135], [136, 139], [140, 147], [148, 154], [154, 155]]}
{"doc_key": "ai-dev-117", "ner": [[0, 1, "algorithm"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 7, 8, "origin", "", false, false], [0, 1, 10, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "LSTM", "was", "initiated", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "The LSTM was initiated in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 22], [23, 25], [26, 30], [31, 33], [34, 38], [39, 49], [50, 53], [54, 60], [61, 72], [72, 73]]}
{"doc_key": "ai-dev-118", "ner": [[11, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "mixing", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated in a 2 \u00d7 2 contingency table or mixing matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 73], [74, 80], [81, 83], [84, 91], [91, 92]]}
{"doc_key": "ai-dev-119", "ner": [[11, 11, "conference"], [13, 14, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "also", "made", "a", "major", "contribution", "to", "the", "establishment", "of", "the", "ELRA", "and", "LREC", "conferences", "."], "sentence-detokenized": "He also made a major contribution to the establishment of the ELRA and LREC conferences.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 14], [15, 20], [21, 33], [34, 36], [37, 40], [41, 54], [55, 57], [58, 61], [62, 66], [67, 70], [71, 75], [76, 87], [87, 88]]}
{"doc_key": "ai-dev-120", "ner": [[12, 13, "misc"], [16, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 19, 12, 13, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "popular", "application", "for", "serial", "robots", "in", "today", "'s", "industry", "is", "an", "assembly", "robot", "called", "a", "SCARA", "robot", ",", "which", "has", "four", "degrees", "of", "freedom", "."], "sentence-detokenized": "A popular application for serial robots in today's industry is an assembly robot called a SCARA robot, which has four degrees of freedom.", "token2charspan": [[0, 1], [2, 9], [10, 21], [22, 25], [26, 32], [33, 39], [40, 42], [43, 48], [48, 50], [51, 59], [60, 62], [63, 65], [66, 74], [75, 80], [81, 87], [88, 89], [90, 95], [96, 101], [101, 102], [103, 108], [109, 112], [113, 117], [118, 125], [126, 128], [129, 136], [136, 137]]}
{"doc_key": "ai-dev-121", "ner": [[18, 28, "conference"], [22, 22, "conference"], [13, 16, "conference"], [32, 32, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 18, 28, "named", "", false, false], [32, 32, 13, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "a", "founding", "member", "and", "former", "chair", "(", "2006-2008", ")", "of", "the", "Association", "for", "Computational", "Linguistics", "'", "Web", "as", "Corpus", "(", "SIGWAC", ")", "Special", "Interest", "Group", "and", "a", "founding", "member", "of", "SENSEVAL", "."], "sentence-detokenized": "He was a founding member and former chair (2006-2008) of the Association for Computational Linguistics' Web as Corpus (SIGWAC) Special Interest Group and a founding member of SENSEVAL.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 17], [18, 24], [25, 28], [29, 35], [36, 41], [42, 43], [43, 52], [52, 53], [54, 56], [57, 60], [61, 72], [73, 76], [77, 90], [91, 102], [102, 103], [104, 107], [108, 110], [111, 117], [118, 119], [119, 125], [125, 126], [127, 134], [135, 143], [144, 149], [150, 153], [154, 155], [156, 164], [165, 171], [172, 174], [175, 183], [183, 184]]}
{"doc_key": "ai-dev-122", "ner": [[0, 0, "product"], [7, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["LinguaStream", "as", "a", "platform", "provides", "a", "comprehensive", "Java", "API", "."], "sentence-detokenized": "LinguaStream as a platform provides a comprehensive Java API.", "token2charspan": [[0, 12], [13, 15], [16, 17], [18, 26], [27, 35], [36, 37], [38, 51], [52, 56], [57, 60], [60, 61]]}
{"doc_key": "ai-dev-123", "ner": [[12, 12, "programlang"], [15, 17, "misc"], [20, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 20, 22, "type-of", "", false, false], [15, 17, 20, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "robot", "kit", "is", "based", "on", "Android", "and", "can", "be", "programmed", "using", "Java", ",", "the", "Blocks", "programming", "interface", "or", "other", "Android", "programming", "systems", "."], "sentence-detokenized": "The robot kit is based on Android and can be programmed using Java, the Blocks programming interface or other Android programming systems.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 16], [17, 22], [23, 25], [26, 33], [34, 37], [38, 41], [42, 44], [45, 55], [56, 61], [62, 66], [66, 67], [68, 71], [72, 78], [79, 90], [91, 100], [101, 103], [104, 109], [110, 117], [118, 129], [130, 137], [137, 138]]}
{"doc_key": "ai-dev-124", "ner": [[10, 11, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "method", "for", "defining", "the", "linked", "list", "determines", "whether", "a", "depth", "search", "or", "a", "breadth", "search", "is", "used", "."], "sentence-detokenized": "The method for defining the linked list determines whether a depth search or a breadth search is used.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 27], [28, 34], [35, 39], [40, 50], [51, 58], [59, 60], [61, 66], [67, 73], [74, 76], [77, 78], [79, 86], [87, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-dev-125", "ner": [[22, 23, "task"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "regions", "could", "signal", "the", "presence", "of", "objects", "or", "parts", "of", "objects", "in", "the", "image", "area", ",", "which", "can", "be", "used", "for", "object", "recognition", "and", "/", "or", "object", "video", "tracking", "."], "sentence-detokenized": "These regions could signal the presence of objects or parts of objects in the image area, which can be used for object recognition and/or object video tracking.", "token2charspan": [[0, 5], [6, 13], [14, 19], [20, 26], [27, 30], [31, 39], [40, 42], [43, 50], [51, 53], [54, 59], [60, 62], [63, 70], [71, 73], [74, 77], [78, 83], [84, 88], [88, 89], [90, 95], [96, 99], [100, 102], [103, 107], [108, 111], [112, 118], [119, 130], [131, 134], [134, 135], [135, 137], [138, 144], [145, 150], [151, 159], [159, 160]]}
{"doc_key": "ai-dev-126", "ner": [[4, 5, "algorithm"], [8, 9, "product"], [12, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "type-of", "", false, false], [8, 9, 12, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "semantic", "network", "is", "the", "Word", "Net", "database", "of", "English", "vocabulary", "."], "sentence-detokenized": "An example of a semantic network is the WordNet database of English vocabulary.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 32], [33, 35], [36, 39], [40, 44], [44, 47], [48, 56], [57, 59], [60, 67], [68, 78], [78, 79]]}
{"doc_key": "ai-dev-127", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 11, "field"], [20, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 7, 8, "part-of", "", false, false], [0, 1, 10, 11, "named", "same", false, false], [0, 1, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Speech", "recognition", "is", "an", "interdisciplinary", "subfield", "of", "computer", "science", "and", "computational", "linguistics", "that", "develops", "methodologies", "and", "technologies", "that", "enable", "computers", "to", "recognise", "and", "translate", "spoken", "language", "into", "text", "."], "sentence-detokenized": "Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that enable computers to recognise and translate spoken language into text.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 24], [25, 42], [43, 51], [52, 54], [55, 63], [64, 71], [72, 75], [76, 89], [90, 101], [102, 106], [107, 115], [116, 129], [130, 133], [134, 146], [147, 151], [152, 158], [159, 168], [169, 171], [172, 181], [182, 185], [186, 195], [196, 202], [203, 211], [212, 216], [217, 221], [221, 222]]}
{"doc_key": "ai-dev-128", "ner": [[0, 1, "field"], [9, 10, "misc"], [15, 17, "field"], [18, 19, "task"], [21, 22, "task"], [43, 43, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 43, 43, "named", "same", false, false], [15, 17, 0, 1, "part-of", "subfield", false, false], [18, 19, 0, 1, "part-of", "", false, false], [18, 19, 15, 17, "part-of", "", false, false], [21, 22, 15, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Artificial", "Intelligence", "has", "focused", "most", "of", "its", "attention", "on", "applied", "ontology", "in", "sub-fields", "such", "as", "natural", "language", "processing", "in", "machines", "and", "knowledge", "representation", ",", "but", "ontology", "editors", "are", "often", "used", "in", "various", "fields", "such", "as", "education", ",", "without", "the", "intention", "of", "contributing", "to", "AI", "."], "sentence-detokenized": "Artificial Intelligence has focused most of its attention on applied ontology in sub-fields such as natural language processing in machines and knowledge representation, but ontology editors are often used in various fields such as education, without the intention of contributing to AI.", "token2charspan": [[0, 10], [11, 23], [24, 27], [28, 35], [36, 40], [41, 43], [44, 47], [48, 57], [58, 60], [61, 68], [69, 77], [78, 80], [81, 91], [92, 96], [97, 99], [100, 107], [108, 116], [117, 127], [128, 130], [131, 139], [140, 143], [144, 153], [154, 168], [168, 169], [170, 173], [174, 182], [183, 190], [191, 194], [195, 200], [201, 205], [206, 208], [209, 216], [217, 223], [224, 228], [229, 231], [232, 241], [241, 242], [243, 250], [251, 254], [255, 264], [265, 267], [268, 280], [281, 283], [284, 286], [286, 287]]}
{"doc_key": "ai-dev-129", "ner": [[9, 12, "algorithm"], [13, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 12, 13, 15, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "update", "rule", "is", "in", "fact", "an", "update", "of", "the", "stochastic", "gradient", "descent", "for", "linear", "regression", "."], "sentence-detokenized": "This update rule is in fact an update of the stochastic gradient descent for linear regression.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 22], [23, 27], [28, 30], [31, 37], [38, 40], [41, 44], [45, 55], [56, 64], [65, 72], [73, 76], [77, 83], [84, 94], [94, 95]]}
{"doc_key": "ai-dev-130", "ner": [[5, 11, "organisation"], [14, 20, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "been", "elected", "to", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "the", "National", "Academy", "of", "Sciences", ",", "and", "has", "received", "several", "awards", ":"], "sentence-detokenized": "He has been elected to the American Academy of Arts and Sciences and the National Academy of Sciences, and has received several awards:", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 22], [23, 26], [27, 35], [36, 43], [44, 46], [47, 51], [52, 55], [56, 64], [65, 68], [69, 72], [73, 81], [82, 89], [90, 92], [93, 101], [101, 102], [103, 106], [107, 110], [111, 119], [120, 127], [128, 134], [134, 135]]}
{"doc_key": "ai-dev-131", "ner": [[5, 6, "organisation"], [12, 13, "person"], [15, 19, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 12, 13, "related-to", "written_about_by", false, false], [5, 6, 15, 19, "related-to", "written_about_by", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "recent", "view", "on", "Honda", "'s", "strategy", "was", "put", "forward", "by", "Gary", "Hamel", "and", "C.K", ".", "Prahalad", "in", "1989", "."], "sentence-detokenized": "The most recent view on Honda's strategy was put forward by Gary Hamel and C.K. Prahalad in 1989.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 20], [21, 23], [24, 29], [29, 31], [32, 40], [41, 44], [45, 48], [49, 56], [57, 59], [60, 64], [65, 70], [71, 74], [75, 78], [78, 79], [80, 88], [89, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-dev-132", "ner": [[1, 1, "metrics"], [5, 10, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 5, 10, "related-to", "calculates", true, false], [1, 1, 19, 19, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "BLEU", "simply", "calculates", "the", "accuracy", "of", "the", "n-", "grams", "by", "giving", "each", "of", "them", "an", "equal", "weight", ",", "NIST", "also", "calculates", "how", "informative", "a", "given", "n-", "gram", "is", "."], "sentence-detokenized": "While BLEU simply calculates the accuracy of the n-grams by giving each of them an equal weight, NIST also calculates how informative a given n-gram is.", "token2charspan": [[0, 5], [6, 10], [11, 17], [18, 28], [29, 32], [33, 41], [42, 44], [45, 48], [49, 51], [51, 56], [57, 59], [60, 66], [67, 71], [72, 74], [75, 79], [80, 82], [83, 88], [89, 95], [95, 96], [97, 101], [102, 106], [107, 117], [118, 121], [122, 133], [134, 135], [136, 141], [142, 144], [144, 148], [149, 151], [151, 152]]}
{"doc_key": "ai-dev-133", "ner": [[4, 14, "misc"], [5, 8, "conference"], [10, 10, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 14, 5, 8, "temporal", "", false, false], [10, 10, 5, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "awarded", "the", "2019", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "Lifetime", "Achievement", "Award", "."], "sentence-detokenized": "He was awarded the 2019 Association for Computational Linguistics (ACL) Lifetime Achievement Award.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 18], [19, 23], [24, 35], [36, 39], [40, 53], [54, 65], [66, 67], [67, 70], [70, 71], [72, 80], [81, 92], [93, 98], [98, 99]]}
{"doc_key": "ai-dev-134", "ner": [[0, 0, "researcher"], [6, 11, "organisation"], [13, 13, "organisation"], [17, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 11, "role", "", false, false], [0, 0, 17, 21, "role", "", false, false], [13, 13, 6, 11, "named", "", false, false], [23, 23, 17, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "is", "a", "member", "of", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "and", "the", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara is a member of the Institute of Electrical and Electronics Engineers (IEEE) and the American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 18], [19, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 65], [66, 75], [76, 77], [77, 81], [81, 82], [83, 86], [87, 90], [91, 99], [100, 111], [112, 115], [116, 126], [127, 139], [140, 141], [141, 145], [145, 146], [146, 147]]}
{"doc_key": "ai-dev-135", "ner": [[0, 1, "product"], [10, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 10, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "MATLAB", "code", "below", "shows", "a", "concrete", "solution", "to", "the", "nonlinear", "system", "of", "equations", "described", "in", "the", "previous", "section", "."], "sentence-detokenized": "The MATLAB code below shows a concrete solution to the nonlinear system of equations described in the previous section.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 21], [22, 27], [28, 29], [30, 38], [39, 47], [48, 50], [51, 54], [55, 64], [65, 71], [72, 74], [75, 84], [85, 94], [95, 97], [98, 101], [102, 110], [111, 118], [118, 119]]}
{"doc_key": "ai-dev-136", "ner": [[0, 2, "product"], [13, 17, "field"], [36, 37, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 13, 17, "related-to", "trained_by", true, false], [0, 2, 36, 37, "related-to", "trained_by", true, false], [13, 17, 36, 37, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Pattern", "recognition", "systems", "are", "in", "many", "cases", "trained", "on", "labelled", "training", "data", "(", "supervised", "learning", ")", ",", "but", "if", "labelled", "data", "is", "not", "available", ",", "other", "algorithms", "can", "be", "used", "to", "detect", "previously", "unknown", "patterns", "(", "unsupervised", "learning", ")", "."], "sentence-detokenized": "Pattern recognition systems are in many cases trained on labelled training data (supervised learning), but if labelled data is not available, other algorithms can be used to detect previously unknown patterns (unsupervised learning).", "token2charspan": [[0, 7], [8, 19], [20, 27], [28, 31], [32, 34], [35, 39], [40, 45], [46, 53], [54, 56], [57, 65], [66, 74], [75, 79], [80, 81], [81, 91], [92, 100], [100, 101], [101, 102], [103, 106], [107, 109], [110, 118], [119, 123], [124, 126], [127, 130], [131, 140], [140, 141], [142, 147], [148, 158], [159, 162], [163, 165], [166, 170], [171, 173], [174, 180], [181, 191], [192, 199], [200, 208], [209, 210], [210, 222], [223, 231], [231, 232], [232, 233]]}
{"doc_key": "ai-dev-137", "ner": [[5, 8, "researcher"], [9, 13, "country"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 8, 9, 13, "physical", "", false, false], [5, 8, 24, 25, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "was", "first", "used", "by", "Lawrence", "J.", "Fogel", "in", "the", "USA", "in", "1960", "to", "use", "simulated", "evolution", "as", "a", "learning", "process", "aimed", "at", "creating", "artificial", "intelligence", "."], "sentence-detokenized": "It was first used by Lawrence J. Fogel in the USA in 1960 to use simulated evolution as a learning process aimed at creating artificial intelligence.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 17], [18, 20], [21, 29], [30, 32], [33, 38], [39, 41], [42, 45], [46, 49], [50, 52], [53, 57], [58, 60], [61, 64], [65, 74], [75, 84], [85, 87], [88, 89], [90, 98], [99, 106], [107, 112], [113, 115], [116, 124], [125, 135], [136, 148], [148, 149]]}
{"doc_key": "ai-dev-138", "ner": [[0, 1, "field"], [10, 11, "field"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 10, 11, "part-of", "", false, false], [15, 16, 10, 11, "part-of", "", false, false], [18, 19, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Reinforcement", "learning", "is", "one", "of", "the", "three", "basic", "paradigms", "of", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "unsupervised", "learning", "."], "sentence-detokenized": "Reinforcement learning is one of the three basic paradigms of machine learning, along with supervised learning and unsupervised learning.", "token2charspan": [[0, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 42], [43, 48], [49, 58], [59, 61], [62, 69], [70, 78], [78, 79], [80, 85], [86, 90], [91, 101], [102, 110], [111, 114], [115, 127], [128, 136], [136, 137]]}
{"doc_key": "ai-dev-139", "ner": [[4, 5, "field"], [12, 12, "programlang"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 28, 29, "usage", "applies", false, false], [12, 12, 28, 29, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "such", "cases", ",", "cloud", "computing", "and", "the", "open", "source", "programming", "language", "R", "can", "help", "smaller", "banks", "to", "implement", "risk", "analytics", "and", "support", "branch", "-", "level", "monitoring", "through", "predictive", "analytics", "."], "sentence-detokenized": "In such cases, cloud computing and the open source programming language R can help smaller banks to implement risk analytics and support branch-level monitoring through predictive analytics.", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 20], [21, 30], [31, 34], [35, 38], [39, 43], [44, 50], [51, 62], [63, 71], [72, 73], [74, 77], [78, 82], [83, 90], [91, 96], [97, 99], [100, 109], [110, 114], [115, 124], [125, 128], [129, 136], [137, 143], [143, 144], [144, 149], [150, 160], [161, 168], [169, 179], [180, 189], [189, 190]]}
{"doc_key": "ai-dev-140", "ner": [[13, 14, "researcher"], [16, 16, "algorithm"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 14, 20, 21, "named", "same", false, false], [16, 16, 13, 14, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["One", "of", "the", "first", "versions", "of", "the", "theorem", "was", "proved", "in", "1989", "by", "George", "Cibenko", "for", "sigmoidal", "activation", "functions", ".", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "One of the first versions of the theorem was proved in 1989 by George Cibenko for sigmoidal activation functions. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 25], [26, 28], [29, 32], [33, 40], [41, 44], [45, 51], [52, 54], [55, 59], [60, 62], [63, 69], [70, 77], [78, 81], [82, 91], [92, 102], [103, 112], [112, 113], [114, 121], [122, 124], [125, 126], [126, 130], [130, 131], [131, 132], [133, 134], [135, 136], [136, 137], [137, 138], [138, 139], [140, 147], [147, 148]]}
{"doc_key": "ai-dev-141", "ner": [[5, 8, "algorithm"], [9, 9, "metrics"], [14, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 5, 8, "part-of", "", false, false], [14, 19, 9, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "process", ",", "called", "cross", "-checking", ",", "the", "MSE", "is", "often", "called", "the", "mean", "square", "prediction", "error", "and", "is", "calculated", "as", "follows", "."], "sentence-detokenized": "In this process, called cross-checking, the MSE is often called the mean square prediction error and is calculated as follows.", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 23], [24, 29], [29, 38], [38, 39], [40, 43], [44, 47], [48, 50], [51, 56], [57, 63], [64, 67], [68, 72], [73, 79], [80, 90], [91, 96], [97, 100], [101, 103], [104, 114], [115, 117], [118, 125], [125, 126]]}
{"doc_key": "ai-dev-142", "ner": [[0, 0, "task"], [4, 6, "task"], [8, 12, "task"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "compare", "", false, false], [4, 6, 18, 19, "part-of", "", false, false], [8, 12, 4, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OMR", "generally", "differs", "from", "optical", "character", "recognition", "(", "OCR", ")", "in", "that", "it", "does", "not", "require", "a", "sophisticated", "character", "recognition", "engine", "."], "sentence-detokenized": "OMR generally differs from optical character recognition (OCR) in that it does not require a sophisticated character recognition engine.", "token2charspan": [[0, 3], [4, 13], [14, 21], [22, 26], [27, 34], [35, 44], [45, 56], [57, 58], [58, 61], [61, 62], [63, 65], [66, 70], [71, 73], [74, 78], [79, 82], [83, 90], [91, 92], [93, 106], [107, 116], [117, 128], [129, 135], [135, 136]]}
{"doc_key": "ai-dev-143", "ner": [[10, 11, "location"], [13, 13, "location"], [15, 15, "location"], [19, 20, "location"], [22, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 15, 15, "physical", "", false, false], [19, 20, 13, 13, "physical", "", false, false], [22, 23, 13, 13, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2018", "and", "2019", ",", "the", "Championships", "will", "be", "held", "in", "Houston", "and", "Detroit", ",", "Michigan", ",", "at", "the", "TCF", "Center", "and", "Ford", "Field", "."], "sentence-detokenized": "In 2018 and 2019, the Championships will be held in Houston and Detroit, Michigan, at the TCF Center and Ford Field.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 16], [16, 17], [18, 21], [22, 35], [36, 40], [41, 43], [44, 48], [49, 51], [52, 59], [60, 63], [64, 71], [71, 72], [73, 81], [81, 82], [83, 85], [86, 89], [90, 93], [94, 100], [101, 104], [105, 109], [110, 115], [115, 116]]}
{"doc_key": "ai-dev-144", "ner": [[0, 0, "task"], [9, 10, "task"], [13, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [13, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "seen", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multi-class", "classification", "."], "sentence-detokenized": "Classification can be seen as two separate problems - binary classification and multi-class classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 26], [27, 29], [30, 33], [34, 42], [43, 51], [52, 53], [54, 60], [61, 75], [76, 79], [80, 91], [92, 106], [106, 107]]}
{"doc_key": "ai-dev-145", "ner": [[4, 5, "product"], [8, 9, "product"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "type-of", "", false, false], [12, 13, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "popular", "examples", "of", "parallel", "robots", "are", "the", "Stewart", "platform", "and", "the", "Delta", "robot", "."], "sentence-detokenized": "Two popular examples of parallel robots are the Stewart platform and the Delta robot.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 23], [24, 32], [33, 39], [40, 43], [44, 47], [48, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-146", "ner": [[4, 9, "algorithm"], [22, 23, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 9, 22, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "However", ",", "the", "ReLU", "activation", "function", ",", "which", "is", "not", "differentiable", "at", "0", ",", "has", "become", "quite", "popular", ",", "e.g.", "on", "Alex", "Net", ".", ")"], "sentence-detokenized": "(However, the ReLU activation function, which is not differentiable at 0, has become quite popular, e.g. on AlexNet. )", "token2charspan": [[0, 1], [1, 8], [8, 9], [10, 13], [14, 18], [19, 29], [30, 38], [38, 39], [40, 45], [46, 48], [49, 52], [53, 67], [68, 70], [71, 72], [72, 73], [74, 77], [78, 84], [85, 90], [91, 98], [98, 99], [100, 104], [105, 107], [108, 112], [112, 115], [115, 116], [117, 118]]}
{"doc_key": "ai-dev-147", "ner": [[0, 2, "metrics"], [7, 8, "task"], [14, 14, "task"], [16, 17, "task"], [19, 20, "task"], [23, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 23, 23, "named", "", true, false], [7, 8, 0, 2, "usage", "", true, false], [14, 14, 7, 8, "part-of", "", false, false], [16, 17, 7, 8, "part-of", "", false, false], [19, 20, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["F", "-", "scores", "are", "often", "used", "in", "information", "retrieval", "to", "evaluate", "the", "performance", "of", "search", ",", "document", "classification", "and", "query", "classification", ",", "so", "F_beta", "is", "widely", "applicable", "."], "sentence-detokenized": "F-scores are often used in information retrieval to evaluate the performance of search, document classification and query classification, so F_beta is widely applicable.", "token2charspan": [[0, 1], [1, 2], [2, 8], [9, 12], [13, 18], [19, 23], [24, 26], [27, 38], [39, 48], [49, 51], [52, 60], [61, 64], [65, 76], [77, 79], [80, 86], [86, 87], [88, 96], [97, 111], [112, 115], [116, 121], [122, 136], [136, 137], [138, 140], [141, 147], [148, 150], [151, 157], [158, 168], [168, 169]]}
{"doc_key": "ai-dev-148", "ner": [[17, 18, "algorithm"], [20, 20, "algorithm"], [23, 24, "algorithm"], [26, 26, "algorithm"], [29, 31, "algorithm"], [33, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 20, 17, 18, "named", "", false, false], [26, 26, 23, 24, "named", "", false, false], [33, 37, 29, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "is", "done", "by", "modelling", "the", "received", "signal", "and", "then", "using", "a", "statistical", "evaluation", "method", "such", "as", "Maximum", "Likelihood", "(", "ML", ")", ",", "Majority", "Vote", "(", "MV", ")", "or", "Maximum", "A", "posteriori", "(", "MAP", ")", "to", "decide", "which", "target", "in", "the", "library", "best", "fits", "the", "model", "created", "using", "the", "received", "signal", "."], "sentence-detokenized": "This is done by modelling the received signal and then using a statistical evaluation method such as Maximum Likelihood (ML), Majority Vote (MV) or Maximum A posteriori (MAP) to decide which target in the library best fits the model created using the received signal.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 25], [26, 29], [30, 38], [39, 45], [46, 49], [50, 54], [55, 60], [61, 62], [63, 74], [75, 85], [86, 92], [93, 97], [98, 100], [101, 108], [109, 119], [120, 121], [121, 123], [123, 124], [124, 125], [126, 134], [135, 139], [140, 141], [141, 143], [143, 144], [145, 147], [148, 155], [156, 157], [158, 168], [169, 170], [170, 173], [173, 174], [175, 177], [178, 184], [185, 190], [191, 197], [198, 200], [201, 204], [205, 212], [213, 217], [218, 222], [223, 226], [227, 232], [233, 240], [241, 246], [247, 250], [251, 259], [260, 266], [266, 267]]}
{"doc_key": "ai-dev-149", "ner": [[0, 0, "researcher"], [3, 3, "misc"], [4, 5, "field"], [6, 12, "university"], [16, 17, "misc"], [18, 18, "field"], [20, 24, "university"], [27, 27, "misc"], [28, 30, "field"], [31, 36, "university"], [44, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 0, 6, 12, "physical", "", false, false], [0, 0, 6, 12, "role", "", false, false], [0, 0, 20, 24, "physical", "", false, false], [0, 0, 20, 24, "role", "", false, false], [0, 0, 31, 36, "physical", "", false, false], [0, 0, 31, 36, "role", "", false, false], [3, 3, 0, 0, "origin", "", false, false], [3, 3, 4, 5, "topic", "", false, false], [16, 17, 0, 0, "origin", "", false, false], [16, 17, 18, 18, "topic", "", false, false], [27, 27, 0, 0, "origin", "", false, false], [27, 27, 28, 30, "topic", "", false, false], [44, 54, 27, 27, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Sova", "received", "a", "BSc", "in", "Mathematics", "from", "the", "Massachusetts", "Institute", "of", "Technology", "in", "1962", ",", "an", "MSc", "in", "Applied", "Mathematics", "from", "Harvard", "University", "in", "1966", "and", "a", "PhD", "in", "Computer", "Science", "from", "the", "Vrije", "Universiteit", "Brussel", "in", "1999", ",", "with", "a", "thesis", "entitled", "\"", "Knowledge", "Representation", ":", "Logical", ",", "Philosophical", "and", "Computational", "Foundations", "of", "Knowledge", "\"", "."], "sentence-detokenized": "Sova received a BSc in Mathematics from the Massachusetts Institute of Technology in 1962, an MSc in Applied Mathematics from Harvard University in 1966 and a PhD in Computer Science from the Vrije Universiteit Brussel in 1999, with a thesis entitled \"Knowledge Representation: Logical, Philosophical and Computational Foundations of Knowledge\".", "token2charspan": [[0, 4], [5, 13], [14, 15], [16, 19], [20, 22], [23, 34], [35, 39], [40, 43], [44, 57], [58, 67], [68, 70], [71, 81], [82, 84], [85, 89], [89, 90], [91, 93], [94, 97], [98, 100], [101, 108], [109, 120], [121, 125], [126, 133], [134, 144], [145, 147], [148, 152], [153, 156], [157, 158], [159, 162], [163, 165], [166, 174], [175, 182], [183, 187], [188, 191], [192, 197], [198, 210], [211, 218], [219, 221], [222, 226], [226, 227], [228, 232], [233, 234], [235, 241], [242, 250], [251, 252], [252, 261], [262, 276], [276, 277], [278, 285], [285, 286], [287, 300], [301, 304], [305, 318], [319, 330], [331, 333], [334, 343], [343, 344], [344, 345]]}
{"doc_key": "ai-dev-150", "ner": [[1, 2, "task"], [8, 8, "task"], [17, 17, "metrics"], [19, 20, "metrics"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 8, 8, "general-affiliation", "", false, false], [17, 17, 1, 2, "part-of", "", true, false], [19, 20, 1, 2, "part-of", "", true, false], [22, 23, 1, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "paraphrase", "recognition", "can", "be", "posed", "as", "a", "classification", "problem", ",", "most", "standard", "evaluation", "metrics", "such", "as", "accuracy", ",", "f1", "score", "or", "ROC", "curve", "perform", "relatively", "well", "."], "sentence-detokenized": "Since paraphrase recognition can be posed as a classification problem, most standard evaluation metrics such as accuracy, f1 score or ROC curve perform relatively well.", "token2charspan": [[0, 5], [6, 16], [17, 28], [29, 32], [33, 35], [36, 41], [42, 44], [45, 46], [47, 61], [62, 69], [69, 70], [71, 75], [76, 84], [85, 95], [96, 103], [104, 108], [109, 111], [112, 120], [120, 121], [122, 124], [125, 130], [131, 133], [134, 137], [138, 143], [144, 151], [152, 162], [163, 167], [167, 168]]}
{"doc_key": "ai-dev-151", "ner": [[16, 17, "algorithm"], [26, 27, "algorithm"], [29, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 17, 26, 27, "opposite", "not_suited_for", false, false], [16, 17, 29, 30, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "makes", "it", "practical", "for", "analysing", "large", "datasets", "(", "hundreds", "or", "thousands", "of", "taxa", ")", "and", "extracting", "data", ",", "as", "other", "types", "of", "analysis", "(", "e.g.", "maximum", "parsimony", ",", "maximum", "likelihood", ")", "may", "be", "too", "complex", "to", "calculate", "."], "sentence-detokenized": "This makes it practical for analysing large datasets (hundreds or thousands of taxa) and extracting data, as other types of analysis (e.g. maximum parsimony, maximum likelihood) may be too complex to calculate.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 37], [38, 43], [44, 52], [53, 54], [54, 62], [63, 65], [66, 75], [76, 78], [79, 83], [83, 84], [85, 88], [89, 99], [100, 104], [104, 105], [106, 108], [109, 114], [115, 120], [121, 123], [124, 132], [133, 134], [134, 138], [139, 146], [147, 156], [156, 157], [158, 165], [166, 176], [176, 177], [178, 181], [182, 184], [185, 188], [189, 196], [197, 199], [200, 209], [209, 210]]}
{"doc_key": "ai-dev-152", "ner": [[3, 5, "programlang"], [8, 12, "organisation"], [14, 18, "organisation"], [22, 22, "programlang"], [26, 36, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[14, 18, 8, 12, "named", "", false, false], [26, 36, 3, 5, "role", "submits", true, false], [26, 36, 8, 12, "role", "submits_to", true, false]], "relations_mapping_to_source": [1, 3, 4], "sentence": ["Submission", "of", "the", "DAML", "+", "OIL", "language", "to", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", "in", "2002", "Work", "carried", "out", "by", "DAML", "contractors", "and", "the", "European", "Union", "/", "US", "Ad", "Hoc", "Joint", "Committee", "on", "Markup", "Languages", "."], "sentence-detokenized": "Submission of the DAML+OIL language to the World Wide Web Consortium (W3C) in 2002 Work carried out by DAML contractors and the European Union/US Ad Hoc Joint Committee on Markup Languages.", "token2charspan": [[0, 10], [11, 13], [14, 17], [18, 22], [22, 23], [23, 26], [27, 35], [36, 38], [39, 42], [43, 48], [49, 53], [54, 57], [58, 68], [69, 70], [70, 73], [73, 74], [75, 77], [78, 82], [83, 87], [88, 95], [96, 99], [100, 102], [103, 107], [108, 119], [120, 123], [124, 127], [128, 136], [137, 142], [142, 143], [143, 145], [146, 148], [149, 152], [153, 158], [159, 168], [169, 171], [172, 178], [179, 188], [188, 189]]}
{"doc_key": "ai-dev-153", "ner": [[3, 4, "misc"], [8, 8, "misc"], [12, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 3, 4, "part-of", "", true, false], [12, 18, 3, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "non-linear", "normalisation", "is", "when", "the", "normalisation", "is", "by", "a", "sigmoidal", "function", ",", "in", "which", "case", "the", "normalised", "image", "is", "calculated", "by", "the", "formula", "."], "sentence-detokenized": "An example of non-linear normalisation is when the normalisation is by a sigmoidal function, in which case the normalised image is calculated by the formula.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 38], [39, 41], [42, 46], [47, 50], [51, 64], [65, 67], [68, 70], [71, 72], [73, 82], [83, 91], [91, 92], [93, 95], [96, 101], [102, 106], [107, 110], [111, 121], [122, 127], [128, 130], [131, 141], [142, 144], [145, 148], [149, 156], [156, 157]]}
{"doc_key": "ai-dev-154", "ner": [[6, 8, "metrics"], [11, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 11, 13, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "pointed", "out", "that", "accuracy", "is", "usually", "linked", "to", "recall", "to", "avoid", "this", "problem", "."], "sentence-detokenized": "It has been pointed out that accuracy is usually linked to recall to avoid this problem.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 23], [24, 28], [29, 37], [38, 40], [41, 48], [49, 55], [56, 58], [59, 65], [66, 68], [69, 74], [75, 79], [80, 87], [87, 88]]}
{"doc_key": "ai-dev-155", "ner": [[5, 7, "metrics"], [9, 15, "metrics"], [20, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 23, 9, 15, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "metrics", "commonly", "used", "are", "mean", "square", "error", "and", "root", "mean", "square", "error", ",", "the", "latter", "of", "which", "was", "used", "for", "the", "Netflix", "award", "."], "sentence-detokenized": "The metrics commonly used are mean square error and root mean square error, the latter of which was used for the Netflix award.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 25], [26, 29], [30, 34], [35, 41], [42, 47], [48, 51], [52, 56], [57, 61], [62, 68], [69, 74], [74, 75], [76, 79], [80, 86], [87, 89], [90, 95], [96, 99], [100, 104], [105, 108], [109, 112], [113, 120], [121, 126], [126, 127]]}
{"doc_key": "ai-dev-156", "ner": [[10, 13, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "August", "2016", ",", "a", "research", "programme", "was", "announced", "with", "University", "College", "Hospital", "to", "develop", "an", "algorithm", "to", "automatically", "distinguish", "between", "healthy", "and", "cancerous", "tissue", "in", "the", "head", "and", "neck", "."], "sentence-detokenized": "In August 2016, a research programme was announced with University College Hospital to develop an algorithm to automatically distinguish between healthy and cancerous tissue in the head and neck.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 17], [18, 26], [27, 36], [37, 40], [41, 50], [51, 55], [56, 66], [67, 74], [75, 83], [84, 86], [87, 94], [95, 97], [98, 107], [108, 110], [111, 124], [125, 136], [137, 144], [145, 152], [153, 156], [157, 166], [167, 173], [174, 176], [177, 180], [181, 185], [186, 189], [190, 194], [194, 195]]}
{"doc_key": "ai-dev-157", "ner": [[0, 1, "researcher"], [13, 15, "organisation"], [18, 23, "organisation"], [24, 27, "organisation"], [30, 35, "organisation"], [38, 44, "organisation"], [48, 51, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 13, 15, "role", "", false, false], [0, 1, 18, 23, "role", "", false, false], [0, 1, 24, 27, "role", "", false, false], [0, 1, 30, 35, "role", "", false, false], [0, 1, 38, 44, "role", "", false, false], [0, 1, 48, 51, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Posner", "'s", "theoretical", "and", "empirical", "contributions", "have", "been", "evaluated", "by", "members", "of", "the", "American", "Psychological", "Association", ",", "the", "Association", "for", "Psychological", "Science", ",", "the", "Society", "of", "Experimental", "Psychologists", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Posner's theoretical and empirical contributions have been evaluated by members of the American Psychological Association, the Association for Psychological Science, the Society of Experimental Psychologists, the American Academy of Arts and Sciences, the American Association for the Advancement of Science, and the National Academy of Sciences.", "token2charspan": [[0, 6], [6, 8], [9, 20], [21, 24], [25, 34], [35, 48], [49, 53], [54, 58], [59, 68], [69, 71], [72, 79], [80, 82], [83, 86], [87, 95], [96, 109], [110, 121], [121, 122], [123, 126], [127, 138], [139, 142], [143, 156], [157, 164], [164, 165], [166, 169], [170, 177], [178, 180], [181, 193], [194, 207], [207, 208], [209, 212], [213, 221], [222, 229], [230, 232], [233, 237], [238, 241], [242, 250], [250, 251], [252, 255], [256, 264], [265, 276], [277, 280], [281, 284], [285, 296], [297, 299], [300, 307], [307, 308], [309, 312], [313, 316], [317, 325], [326, 333], [334, 336], [337, 345], [345, 346]]}
{"doc_key": "ai-dev-158", "ner": [[2, 3, "product"], [7, 8, "field"], [12, 13, "task"], [15, 17, "task"], [19, 19, "task"], [22, 24, "task"], [26, 26, "task"], [29, 30, "field"], [32, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 3, 7, 8, "usage", "", false, false], [12, 13, 7, 8, "part-of", "", false, false], [15, 17, 7, 8, "part-of", "", false, false], [19, 19, 15, 17, "named", "", false, false], [22, 24, 7, 8, "part-of", "", false, false], [26, 26, 22, 24, "named", "", false, false], [29, 30, 7, 8, "part-of", "", false, false], [32, 33, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["These", "intelligent", "chatbots", "use", "various", "forms", "of", "artificial", "intelligence", ",", "such", "as", "image", "moderation", "and", "natural", "language", "understanding", "(", "NLU", ")", ",", "natural", "language", "generation", "(", "NLG", ")", ",", "machine", "learning", "and", "deep", "learning", "."], "sentence-detokenized": "These intelligent chatbots use various forms of artificial intelligence, such as image moderation and natural language understanding (NLU), natural language generation (NLG), machine learning and deep learning.", "token2charspan": [[0, 5], [6, 17], [18, 26], [27, 30], [31, 38], [39, 44], [45, 47], [48, 58], [59, 71], [71, 72], [73, 77], [78, 80], [81, 86], [87, 97], [98, 101], [102, 109], [110, 118], [119, 132], [133, 134], [134, 137], [137, 138], [138, 139], [140, 147], [148, 156], [157, 167], [168, 169], [169, 172], [172, 173], [173, 174], [175, 182], [183, 191], [192, 195], [196, 200], [201, 209], [209, 210]]}
{"doc_key": "ai-dev-159", "ner": [[5, 7, "metrics"], [9, 9, "metrics"], [12, 12, "metrics"], [15, 24, "metrics"], [26, 28, "metrics"], [30, 30, "metrics"], [33, 40, "metrics"], [44, 46, "metrics"], [48, 48, "metrics"], [51, 60, "metrics"], [62, 64, "metrics"], [66, 66, "metrics"], [69, 76, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[9, 9, 5, 7, "named", "", false, false], [12, 12, 5, 7, "named", "", false, false], [15, 24, 5, 7, "named", "", false, false], [30, 30, 26, 28, "named", "", false, false], [33, 40, 26, 28, "named", "", false, false], [48, 48, 44, 46, "named", "", false, false], [51, 60, 44, 46, "named", "", false, false], [66, 66, 62, 64, "named", "", false, false], [69, 76, 62, 64, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "series", "coefficients", "are", "the", "positive", "predictive", "value", "(", "PPV", ",", "or", "precision", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "plus", "the", "false", "discovery", "rate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "and", "the", "negative", "predictive", "value", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "plus", "the", "false", "release", "rate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "The series coefficients are the positive predictive value (PPV, or precision) (TP / (TP + FP)), plus the false discovery rate (FDR) (FP / (TP + FP)); and the negative predictive value (NPV) (TN / (TN + FN)), plus the false release rate (FOR) (FN / (TN + FN)).", "token2charspan": [[0, 3], [4, 10], [11, 23], [24, 27], [28, 31], [32, 40], [41, 51], [52, 57], [58, 59], [59, 62], [62, 63], [64, 66], [67, 76], [76, 77], [78, 79], [79, 81], [82, 83], [84, 85], [85, 87], [88, 89], [90, 92], [92, 93], [93, 94], [94, 95], [96, 100], [101, 104], [105, 110], [111, 120], [121, 125], [126, 127], [127, 130], [130, 131], [132, 133], [133, 135], [136, 137], [138, 139], [139, 141], [142, 143], [144, 146], [146, 147], [147, 148], [148, 149], [150, 153], [154, 157], [158, 166], [167, 177], [178, 183], [184, 185], [185, 188], [188, 189], [190, 191], [191, 193], [194, 195], [196, 197], [197, 199], [200, 201], [202, 204], [204, 205], [205, 206], [206, 207], [208, 212], [213, 216], [217, 222], [223, 230], [231, 235], [236, 237], [237, 240], [240, 241], [242, 243], [243, 245], [246, 247], [248, 249], [249, 251], [252, 253], [254, 256], [256, 257], [257, 258], [258, 259]]}
{"doc_key": "ai-dev-160", "ner": [[8, 9, "misc"], [15, 16, "algorithm"], [18, 18, "algorithm"], [22, 24, "algorithm"], [26, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[18, 18, 15, 16, "named", "", false, false], [26, 26, 22, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "information", "is", "a", "combination", "of", "sitemaps", "and", "RSS", "feeds", "and", "is", "built", "using", "an", "Information", "Model", "(", "IM", ")", "and", "a", "Biomedical", "Resource", "Ontology", "(", "BRO", ")", "."], "sentence-detokenized": "The information is a combination of sitemaps and RSS feeds and is built using an Information Model (IM) and a Biomedical Resource Ontology (BRO).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 20], [21, 32], [33, 35], [36, 44], [45, 48], [49, 52], [53, 58], [59, 62], [63, 65], [66, 71], [72, 77], [78, 80], [81, 92], [93, 98], [99, 100], [100, 102], [102, 103], [104, 107], [108, 109], [110, 120], [121, 129], [130, 138], [139, 140], [140, 143], [143, 144], [144, 145]]}
{"doc_key": "ai-dev-161", "ner": [[1, 2, "task"], [7, 9, "algorithm"], [11, 19, "algorithm"], [24, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 11, 19, "origin", "based_on", false, false], [11, 19, 7, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Recent", "text", "recognition", "is", "based", "on", "a", "recurrent", "neural", "network", "(", "long", "-", "term", "short", "-", "term", "memory", ")", "and", "does", "not", "require", "a", "language", "model", "."], "sentence-detokenized": "Recent text recognition is based on a recurrent neural network (long-term short-term memory) and does not require a language model.", "token2charspan": [[0, 6], [7, 11], [12, 23], [24, 26], [27, 32], [33, 35], [36, 37], [38, 47], [48, 54], [55, 62], [63, 64], [64, 68], [68, 69], [69, 73], [74, 79], [79, 80], [80, 84], [85, 91], [91, 92], [93, 96], [97, 101], [102, 105], [106, 113], [114, 115], [116, 124], [125, 130], [130, 131]]}
{"doc_key": "ai-dev-162", "ner": [[3, 4, "misc"], [6, 7, "metrics"], [10, 11, "algorithm"], [14, 15, "metrics"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 7, 3, 4, "type-of", "", false, false], [10, 11, 6, 7, "related-to", "", true, false], [14, 15, 3, 4, "type-of", "", false, false], [18, 19, 14, 15, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "most", "popular", "loss", "functions", "are", "hinge", "loss", "(", "for", "linear", "SVMs", ")", "and", "logarithmic", "loss", "(", "for", "logistic", "regression", ")", "."], "sentence-detokenized": "The most popular loss functions are hinge loss (for linear SVMs) and logarithmic loss (for logistic regression).", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 21], [22, 31], [32, 35], [36, 41], [42, 46], [47, 48], [48, 51], [52, 58], [59, 63], [63, 64], [65, 68], [69, 80], [81, 85], [86, 87], [87, 90], [91, 99], [100, 110], [110, 111], [111, 112]]}
{"doc_key": "ai-dev-163", "ner": [[0, 0, "metrics"], [9, 15, "metrics"], [17, 17, "metrics"], [20, 22, "metrics"], [24, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 9, 15, "compare", "", false, false], [0, 0, 20, 22, "compare", "", false, false], [17, 17, 9, 15, "named", "", false, false], [24, 24, 20, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "is", "designed", "to", "improve", "traditional", "methods", "such", "as", "peak", "signal", "-", "to", "-", "noise", "ratio", "(", "PSNR", ")", "and", "mean", "square", "error", "(", "MSE", ")", "."], "sentence-detokenized": "SSIM is designed to improve traditional methods such as peak signal-to-noise ratio (PSNR) and mean square error (MSE).", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 27], [28, 39], [40, 47], [48, 52], [53, 55], [56, 60], [61, 67], [67, 68], [68, 70], [70, 71], [71, 76], [77, 82], [83, 84], [84, 88], [88, 89], [90, 93], [94, 98], [99, 105], [106, 111], [112, 113], [113, 116], [116, 117], [117, 118]]}
{"doc_key": "ai-dev-164", "ner": [[10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "inspired", "future", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Morawetz", "and", "Mark", "Tilden", "."], "sentence-detokenized": "His work inspired future generations of robotics researchers such as Rodney Brooks, Hans Morawetz and Mark Tilden.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 24], [25, 36], [37, 39], [40, 48], [49, 60], [61, 65], [66, 68], [69, 75], [76, 82], [82, 83], [84, 88], [89, 97], [98, 101], [102, 106], [107, 113], [113, 114]]}
{"doc_key": "ai-dev-165", "ner": [[19, 20, "algorithm"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", ",", "pulse", "teaching", "is", "not", "differentiated", ",", "thus", "ruling", "out", "backflow", "-", "based", "training", "methods", "such", "as", "gradient", "descent", "."], "sentence-detokenized": "In addition, pulse teaching is not differentiated, thus ruling out backflow-based training methods such as gradient descent.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 18], [19, 27], [28, 30], [31, 34], [35, 49], [49, 50], [51, 55], [56, 62], [63, 66], [67, 75], [75, 76], [76, 81], [82, 90], [91, 98], [99, 103], [104, 106], [107, 115], [116, 123], [123, 124]]}
{"doc_key": "ai-dev-166", "ner": [[8, 9, "metrics"], [15, 19, "metrics"], [18, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 15, 19, "related-to", "describes", false, false], [15, 19, 18, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "relationship", "can", "be", "easily", "represented", "by", "a", "hash", "matrix", ",", "a", "table", "describing", "the", "accuracy", "of", "the", "classification", "model", "."], "sentence-detokenized": "This relationship can be easily represented by a hash matrix, a table describing the accuracy of the classification model.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 24], [25, 31], [32, 43], [44, 46], [47, 48], [49, 53], [54, 60], [60, 61], [62, 63], [64, 69], [70, 80], [81, 84], [85, 93], [94, 96], [97, 100], [101, 115], [116, 121], [121, 122]]}
{"doc_key": "ai-dev-167", "ner": [[5, 12, "conference"], [14, 14, "conference"], [0, 0, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 5, 12, "named", "", false, false], [0, 0, 5, 12, "physical", "", false, false], [0, 0, 5, 12, "role", "", false, false], [0, 0, 5, 12, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "researchers", "presented", "work", "at", "the", "2018", "Conference", "on", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "."], "sentence-detokenized": "Google researchers presented work at the 2018 Conference on Neural Information Processing Systems (NeurIPS).", "token2charspan": [[0, 6], [7, 18], [19, 28], [29, 33], [34, 36], [37, 40], [41, 45], [46, 56], [57, 59], [60, 66], [67, 78], [79, 89], [90, 97], [98, 99], [99, 106], [106, 107], [107, 108]]}
{"doc_key": "ai-dev-168", "ner": [[2, 4, "university"], [6, 6, "product"], [17, 19, "misc"], [16, 16, "conference"], [24, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 17, 19, "win-defeat", "", false, false], [17, 19, 16, 16, "temporal", "", false, false], [24, 27, 16, 16, "part-of", "", false, false], [24, 27, 16, 16, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "at", "Duke", ",", "he", "developed", "PROVERB", ",", "an", "automated", "crossword", "solver", "that", "won", "the", "1999", "AAAI", "Outstanding", "Paper", "Award", "and", "competed", "in", "the", "American", "Crossword", "Puzzle", "Tournament", "."], "sentence-detokenized": "While at Duke, he developed PROVERB, an automated crossword solver that won the 1999 AAAI Outstanding Paper Award and competed in the American Crossword Puzzle Tournament.", "token2charspan": [[0, 5], [6, 8], [9, 13], [13, 14], [15, 17], [18, 27], [28, 35], [35, 36], [37, 39], [40, 49], [50, 59], [60, 66], [67, 71], [72, 75], [76, 79], [80, 84], [85, 89], [90, 101], [102, 107], [108, 113], [114, 117], [118, 126], [127, 129], [130, 133], [134, 142], [143, 152], [153, 159], [160, 170], [170, 171]]}
{"doc_key": "ai-dev-169", "ner": [[2, 3, "location"], [5, 5, "location"], [14, 15, "country"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 5, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Headquartered", "in", "Rochester", "Hills", ",", "Michigan", ",", "the", "company", "had", "10", "regional", "offices", "in", "the", "US", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "sentence-detokenized": "Headquartered in Rochester Hills, Michigan, the company had 10 regional offices in the US, Canada, Mexico and Brazil.", "token2charspan": [[0, 13], [14, 16], [17, 26], [27, 32], [32, 33], [34, 42], [42, 43], [44, 47], [48, 55], [56, 59], [60, 62], [63, 71], [72, 79], [80, 82], [83, 86], [87, 89], [89, 90], [91, 97], [97, 98], [99, 105], [106, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-dev-170", "ner": [[11, 11, "product"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "joins", "a", "collection", "of", "historically", "significant", "robots", "including", "the", "early", "Unimate", "and", "the", "Odetics", "Odex", "1", "."], "sentence-detokenized": "It joins a collection of historically significant robots including the early Unimate and the Odetics Odex 1.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 21], [22, 24], [25, 37], [38, 49], [50, 56], [57, 66], [67, 70], [71, 76], [77, 84], [85, 88], [89, 92], [93, 100], [101, 105], [106, 107], [107, 108]]}
{"doc_key": "ai-dev-171", "ner": [[7, 8, "researcher"], [12, 12, "organisation"], [13, 15, "researcher"], [25, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 12, 12, "physical", "", false, false], [7, 8, 12, 12, "role", "", false, false], [13, 15, 12, 12, "physical", "", false, false], [13, 15, 12, 12, "role", "", false, false], [13, 15, 25, 30, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["This", "issue", "will", "be", "guest", "edited", "by", "David", "'s", "former", "colleague", "from", "NIST", ",", "Judah", "Levin", ",", "who", "is", "the", "most", "recent", "recipient", "of", "the", "I", ".", "I", ".", "Rabi", "Award", "."], "sentence-detokenized": "This issue will be guest edited by David's former colleague from NIST, Judah Levin, who is the most recent recipient of the I. I. Rabi Award.", "token2charspan": [[0, 4], [5, 10], [11, 15], [16, 18], [19, 24], [25, 31], [32, 34], [35, 40], [40, 42], [43, 49], [50, 59], [60, 64], [65, 69], [69, 70], [71, 76], [77, 82], [82, 83], [84, 87], [88, 90], [91, 94], [95, 99], [100, 106], [107, 116], [117, 119], [120, 123], [124, 125], [125, 126], [127, 128], [128, 129], [130, 134], [135, 140], [140, 141]]}
{"doc_key": "ai-dev-172", "ner": [[12, 17, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "can", "be", "arranged", "in", "a", "2", "\u00d7", "2", "contingency", "table", "(", "confusion", "matrix", ")", ",", "with", "the", "test", "result", "usually", "on", "the", "vertical", "axis", "and", "the", "actual", "situation", "on", "the", "horizontal", "axis", "."], "sentence-detokenized": "These can be arranged in a 2 \u00d7 2 contingency table (confusion matrix), with the test result usually on the vertical axis and the actual situation on the horizontal axis.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 21], [22, 24], [25, 26], [27, 28], [29, 30], [31, 32], [33, 44], [45, 50], [51, 52], [52, 61], [62, 68], [68, 69], [69, 70], [71, 75], [76, 79], [80, 84], [85, 91], [92, 99], [100, 102], [103, 106], [107, 115], [116, 120], [121, 124], [125, 128], [129, 135], [136, 145], [146, 148], [149, 152], [153, 163], [164, 168], [168, 169]]}
{"doc_key": "ai-dev-173", "ner": [[0, 4, "product"], [8, 8, "product"], [10, 10, "product"], [12, 13, "product"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 8, 8, "part-of", "", false, false], [0, 4, 10, 10, "part-of", "", false, false], [0, 4, 12, 13, "part-of", "", false, false], [0, 4, 16, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Apple", "'s", "iOS", "operating", "system", ",", "used", "on", "iPhone", ",", "iPad", "and", "iPod", "Touch", ",", "uses", "VoiceOver", "speech", "synthesis", "accessibility", "."], "sentence-detokenized": "Apple's iOS operating system, used on iPhone, iPad and iPod Touch, uses VoiceOver speech synthesis accessibility.", "token2charspan": [[0, 5], [5, 7], [8, 11], [12, 21], [22, 28], [28, 29], [30, 34], [35, 37], [38, 44], [44, 45], [46, 50], [51, 54], [55, 59], [60, 65], [65, 66], [67, 71], [72, 81], [82, 88], [89, 98], [99, 112], [112, 113]]}
{"doc_key": "ai-dev-174", "ner": [[8, 10, "conference"], [14, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "the", "best", "system", "that", "injected", "MUC", "-", "7", "got", "93.39", "%", "F", "-", "measure", ",", "while", "human", "annotators", "got", "97.6", "%", "and", "96.95", "%", "."], "sentence-detokenized": "For example, the best system that injected MUC-7 got 93.39% F-measure, while human annotators got 97.6% and 96.95%.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 33], [34, 42], [43, 46], [46, 47], [47, 48], [49, 52], [53, 58], [58, 59], [60, 61], [61, 62], [62, 69], [69, 70], [71, 76], [77, 82], [83, 93], [94, 97], [98, 102], [102, 103], [104, 107], [108, 113], [113, 114], [114, 115]]}
{"doc_key": "ai-dev-175", "ner": [[11, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 11, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "done", "using", "standard", "neural", "network", "training", "algorithms", "such", "as", "stochastic", "gradient", "descent", "with", "backpropagation", "."], "sentence-detokenized": "This is done using standard neural network training algorithms such as stochastic gradient descent with backpropagation.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 18], [19, 27], [28, 34], [35, 42], [43, 51], [52, 62], [63, 67], [68, 70], [71, 81], [82, 90], [91, 98], [99, 103], [104, 119], [119, 120]]}
{"doc_key": "ai-dev-176", "ner": [[0, 1, "organisation"], [16, 16, "country"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 16, 16, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "is", "a", "top", "1000", "site", ",", "ranking", "around", "400th", "globally", "and", "150th", "in", "the", "US", "alone", ",", "according", "to", "website", "ranking", "search", "engine", "Alexa", "."], "sentence-detokenized": "Rotten Tomatoes is a top 1000 site, ranking around 400th globally and 150th in the US alone, according to website ranking search engine Alexa.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 20], [21, 24], [25, 29], [30, 34], [34, 35], [36, 43], [44, 50], [51, 56], [57, 65], [66, 69], [70, 75], [76, 78], [79, 82], [83, 85], [86, 91], [91, 92], [93, 102], [103, 105], [106, 113], [114, 121], [122, 128], [129, 135], [136, 141], [141, 142]]}
{"doc_key": "ai-dev-177", "ner": [[17, 20, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Generally", "speaking", ",", "all", "learning", "takes", "the", "form", "of", "gradual", "changes", "over", "time", ",", "but", "describes", "a", "Sigmoid", "function", "that", "has", "a", "different", "appearance", "depending", "on", "the", "time", "scale", "of", "the", "observations", "."], "sentence-detokenized": "Generally speaking, all learning takes the form of gradual changes over time, but describes a Sigmoid function that has a different appearance depending on the time scale of the observations.", "token2charspan": [[0, 9], [10, 18], [18, 19], [20, 23], [24, 32], [33, 38], [39, 42], [43, 47], [48, 50], [51, 58], [59, 66], [67, 71], [72, 76], [76, 77], [78, 81], [82, 91], [92, 93], [94, 101], [102, 110], [111, 115], [116, 119], [120, 121], [122, 131], [132, 142], [143, 152], [153, 155], [156, 159], [160, 164], [165, 170], [171, 173], [174, 177], [178, 190], [190, 191]]}
{"doc_key": "ai-dev-178", "ner": [[0, 3, "metrics"], [4, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 4, 6, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["SSD", "is", "also", "called", "mean", "square", "error", "."], "sentence-detokenized": "SSD is also called mean square error.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 18], [19, 23], [24, 30], [31, 36], [36, 37]]}
{"doc_key": "ai-dev-179", "ner": [[0, 2, "algorithm"], [4, 5, "algorithm"], [7, 9, "algorithm"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 20, 21, "related-to", "can_be_related_to", true, false], [4, 5, 20, 21, "related-to", "can_be_related_to", true, false], [7, 9, 20, 21, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", ",", "neural", "networks", "or", "naive", "Bayes", "classifiers", "can", "be", "used", "together", "with", "model", "quality", "indicators", "such", "as", "balanced", "accuracy", "."], "sentence-detokenized": "Decision tree learning, neural networks or naive Bayes classifiers can be used together with model quality indicators such as balanced accuracy.", "token2charspan": [[0, 8], [9, 13], [14, 22], [22, 23], [24, 30], [31, 39], [40, 42], [43, 48], [49, 54], [55, 66], [67, 70], [71, 73], [74, 78], [79, 87], [88, 92], [93, 98], [99, 106], [107, 117], [118, 122], [123, 125], [126, 134], [135, 143], [143, 144]]}
{"doc_key": "ai-dev-180", "ner": [[6, 14, "conference"], [24, 28, "conference"], [29, 31, "misc"], [37, 39, "product"], [45, 49, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[29, 31, 24, 28, "origin", "", false, false], [29, 31, 24, 28, "temporal", "", false, false], [37, 39, 29, 31, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "is", "a", "past", "president", "of", "the", "ACL", "(", "1979", ")", "and", "the", "first", "ACL", "Fellow", "(", "2011", ")", ",", "a", "co-recipient", "of", "the", "1992", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "for", "his", "contributions", "to", "the", "Interlisp", "programming", "system", ",", "and", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "He is a past president of the ACL (1979) and the first ACL Fellow (2011), a co-recipient of the 1992 Association for Computing Machinery Software Systems Award for his contributions to the Interlisp programming system, and a Fellow of the Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 22], [23, 25], [26, 29], [30, 33], [34, 35], [35, 39], [39, 40], [41, 44], [45, 48], [49, 54], [55, 58], [59, 65], [66, 67], [67, 71], [71, 72], [72, 73], [74, 75], [76, 88], [89, 91], [92, 95], [96, 100], [101, 112], [113, 116], [117, 126], [127, 136], [137, 145], [146, 153], [154, 159], [160, 163], [164, 167], [168, 181], [182, 184], [185, 188], [189, 198], [199, 210], [211, 217], [217, 218], [219, 222], [223, 224], [225, 231], [232, 234], [235, 238], [239, 250], [251, 254], [255, 264], [265, 274], [274, 275]]}
{"doc_key": "ai-dev-181", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [11, 15, "researcher"], [8, 9, "researcher"], [24, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 24, 27, "related-to", "", false, false], [5, 6, 24, 27, "related-to", "", false, false], [11, 15, 24, 27, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Cade", "Metz", "considers", "Bengio", "as", "one", "of", "the", "three", "people", "who", "contributed", "most", "to", "the", "development", "of", "deep", "learning", "in", "the", "1990s", "and", "2000s", "."], "sentence-detokenized": "Along with Geoffrey Hinton and Yann LeCun, Cade Metz considers Bengio as one of the three people who contributed most to the development of deep learning in the 1990s and 2000s.", "token2charspan": [[0, 5], [6, 10], [11, 19], [20, 26], [27, 30], [31, 35], [36, 41], [41, 42], [43, 47], [48, 52], [53, 62], [63, 69], [70, 72], [73, 76], [77, 79], [80, 83], [84, 89], [90, 96], [97, 100], [101, 112], [113, 117], [118, 120], [121, 124], [125, 136], [137, 139], [140, 144], [145, 153], [154, 156], [157, 160], [161, 166], [167, 170], [171, 176], [176, 177]]}
{"doc_key": "ai-dev-182", "ner": [[0, 2, "field"], [4, 5, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "information", "theory", "and", "computer", "science", ",", "a", "code", "is", "usually", "thought", "of", "as", "an", "algorithm", "that", "uniquely", "represents", "symbols", "from", "a", "source", "alphabet", "with", "encoded", "strings", "that", "may", "be", "in", "some", "other", "target", "alphabet", "."], "sentence-detokenized": "In information theory and computer science, a code is usually thought of as an algorithm that uniquely represents symbols from a source alphabet with encoded strings that may be in some other target alphabet.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 45], [46, 50], [51, 53], [54, 61], [62, 69], [70, 72], [73, 75], [76, 78], [79, 88], [89, 93], [94, 102], [103, 113], [114, 121], [122, 126], [127, 128], [129, 135], [136, 144], [145, 149], [150, 157], [158, 165], [166, 170], [171, 174], [175, 177], [178, 180], [181, 185], [186, 191], [192, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-dev-183", "ner": [[10, 12, "algorithm"], [14, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 17, 10, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "fairly", "simple", "non", "-linear", "function", ",", "such", "as", "a", "sigmoidal", "function", "like", "the", "logistic", "function", ",", "also", "has", "an", "easy", "-", "to", "-", "compute", "derivative", "that", "can", "be", "important", "when", "calculating", "weight", "updates", "in", "a", "network", "."], "sentence-detokenized": "A fairly simple non-linear function, such as a sigmoidal function like the logistic function, also has an easy-to-compute derivative that can be important when calculating weight updates in a network.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 19], [19, 26], [27, 35], [35, 36], [37, 41], [42, 44], [45, 46], [47, 56], [57, 65], [66, 70], [71, 74], [75, 83], [84, 92], [92, 93], [94, 98], [99, 102], [103, 105], [106, 110], [110, 111], [111, 113], [113, 114], [114, 121], [122, 132], [133, 137], [138, 141], [142, 144], [145, 154], [155, 159], [160, 171], [172, 178], [179, 186], [187, 189], [190, 191], [192, 199], [199, 200]]}
{"doc_key": "ai-dev-184", "ner": [[0, 0, "person"], [5, 6, "location"], [8, 8, "location"], [10, 12, "country"], [15, 15, "country"], [18, 20, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 5, 6, "physical", "", false, false], [5, 6, 8, 8, "physical", "", false, false], [8, 8, 10, 12, "physical", "", false, false], [8, 8, 15, 15, "physical", "", false, false], [8, 8, 18, 20, "physical", "", false, false], [15, 15, 10, 12, "origin", "", false, false], [18, 20, 15, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "was", "born", "in", "1887", "in", "Hronov", ",", "Bohemia", "(", "Austria", "-", "Hungary", ",", "later", "Czechoslovakia", ",", "now", "the", "Czech", "Republic", ")", "."], "sentence-detokenized": "\u010capek was born in 1887 in Hronov, Bohemia (Austria-Hungary, later Czechoslovakia, now the Czech Republic).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 41], [42, 43], [43, 50], [50, 51], [51, 58], [58, 59], [60, 65], [66, 80], [80, 81], [82, 85], [86, 89], [90, 95], [96, 104], [104, 105], [105, 106]]}
{"doc_key": "ai-dev-185", "ner": [[5, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "specialised", "software", "can", "broadcast", "RSS", "feeds", "."], "sentence-detokenized": "Some specialised software can broadcast RSS feeds.", "token2charspan": [[0, 4], [5, 16], [17, 25], [26, 29], [30, 39], [40, 43], [44, 49], [49, 50]]}
{"doc_key": "ai-dev-186", "ner": [[6, 7, "task"], [9, 12, "task"], [14, 14, "task"], [17, 17, "task"], [19, 20, "task"], [27, 28, "task"], [30, 32, "task"], [36, 37, "task"], [39, 41, "product"], [43, 44, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[6, 7, 9, 12, "related-to", "", true, false], [6, 7, 14, 14, "related-to", "", true, false], [6, 7, 17, 17, "related-to", "", true, false], [30, 32, 27, 28, "usage", "", true, false], [39, 41, 36, 37, "type-of", "", false, false], [43, 44, 36, 37, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Aspects", "of", "ontology", "editors", "include", ":", "visual", "navigation", "capabilities", "in", "the", "knowledge", "model", ",", "inference", "engines", "and", "extraction", ";", "module", "support", ";", "import", "and", "export", "of", "foreign", "knowledge", "representation", "languages", "for", "ontology", "alignment", ";", "support", "for", "metontologies", "such", "as", "OWL", "-", "S", ",", "Dublin", "Core", ",", "etc", "."], "sentence-detokenized": "Aspects of ontology editors include: visual navigation capabilities in the knowledge model, inference engines and extraction; module support; import and export of foreign knowledge representation languages for ontology alignment; support for metontologies such as OWL-S, Dublin Core, etc.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 27], [28, 35], [35, 36], [37, 43], [44, 54], [55, 67], [68, 70], [71, 74], [75, 84], [85, 90], [90, 91], [92, 101], [102, 109], [110, 113], [114, 124], [124, 125], [126, 132], [133, 140], [140, 141], [142, 148], [149, 152], [153, 159], [160, 162], [163, 170], [171, 180], [181, 195], [196, 205], [206, 209], [210, 218], [219, 228], [228, 229], [230, 237], [238, 241], [242, 255], [256, 260], [261, 263], [264, 267], [267, 268], [268, 269], [269, 270], [271, 277], [278, 282], [282, 283], [284, 287], [287, 288]]}
{"doc_key": "ai-dev-187", "ner": [[0, 1, "organisation"], [6, 11, "misc"], [13, 17, "task"], [20, 21, "field"], [23, 23, "misc"], [26, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 11, 0, 1, "origin", "", false, false], [13, 17, 6, 11, "part-of", "", false, false], [20, 21, 6, 11, "part-of", "", false, false], [23, 23, 20, 21, "type-of", "", false, false], [26, 29, 20, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "FBI", "has", "also", "introduced", "a", "Next", "Generation", "Identification", "programme", ",", "which", "includes", "facial", "recognition", "as", "well", "as", "more", "traditional", "biometrics", "such", "as", "fingerprints", "and", "iris", "scans", "that", "can", "be", "extracted", "from", "both", "criminal", "and", "civil", "databases", "."], "sentence-detokenized": "The FBI has also introduced a Next Generation Identification programme, which includes facial recognition as well as more traditional biometrics such as fingerprints and iris scans that can be extracted from both criminal and civil databases.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 27], [28, 29], [30, 34], [35, 45], [46, 60], [61, 70], [70, 71], [72, 77], [78, 86], [87, 93], [94, 105], [106, 108], [109, 113], [114, 116], [117, 121], [122, 133], [134, 144], [145, 149], [150, 152], [153, 165], [166, 169], [170, 174], [175, 180], [181, 185], [186, 189], [190, 192], [193, 202], [203, 207], [208, 212], [213, 221], [222, 225], [226, 231], [232, 241], [241, 242]]}
{"doc_key": "ai-dev-188", "ner": [[5, 10, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "2016", "season", ",", "Samantha", "Ponder", "was", "added", "as", "host", ",", "replacing", "Molly", "McGrath", "."], "sentence-detokenized": "In the 2016 season, Samantha Ponder was added as host, replacing Molly McGrath.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [18, 19], [20, 28], [29, 35], [36, 39], [40, 45], [46, 48], [49, 53], [53, 54], [55, 64], [65, 70], [71, 78], [78, 79]]}
{"doc_key": "ai-dev-189", "ner": [[3, 8, "algorithm"], [12, 16, "misc"], [18, 18, "misc"], [20, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "opponent-", "finding", "algorithm", "commonly", "used", "for", "machine", "games", "(", "tic", "-", "tac", "-", "toe", ",", "chess", ",", "Go", ",", "etc.", ")", "."], "sentence-detokenized": "This is an opponent-finding algorithm commonly used for machine games (tic-tac-toe, chess, Go, etc.).", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 20], [20, 27], [28, 37], [38, 46], [47, 51], [52, 55], [56, 63], [64, 69], [70, 71], [71, 74], [74, 75], [75, 78], [78, 79], [79, 82], [82, 83], [84, 89], [89, 90], [91, 93], [93, 94], [95, 99], [99, 100], [100, 101]]}
{"doc_key": "ai-dev-190", "ner": [[2, 3, "field"], [5, 6, "field"], [8, 9, "field"], [16, 17, "field"], [19, 20, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "includes", "computer", "vision", "or", "machine", "vision", "and", "medical", "imaging", ",", "and", "makes", "extensive", "use", "of", "pattern", "recognition", ",", "digital", "geometry", "and", "signal", "processing", "."], "sentence-detokenized": "It includes computer vision or machine vision and medical imaging, and makes extensive use of pattern recognition, digital geometry and signal processing.", "token2charspan": [[0, 2], [3, 11], [12, 20], [21, 27], [28, 30], [31, 38], [39, 45], [46, 49], [50, 57], [58, 65], [65, 66], [67, 70], [71, 76], [77, 86], [87, 90], [91, 93], [94, 101], [102, 113], [113, 114], [115, 122], [123, 131], [132, 135], [136, 142], [143, 153], [153, 154]]}
{"doc_key": "ai-dev-191", "ner": [[0, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "in", "a", "facial", "recognition", "system", ",", "the", "input", "is", "taken", "from", "an", "image", "of", "a", "person", "'s", "face", "and", "the", "output", "is", "the", "name", "of", "that", "person", "."], "sentence-detokenized": "For example, in a facial recognition system, the input is taken from an image of a person's face and the output is the name of that person.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 17], [18, 24], [25, 36], [37, 43], [43, 44], [45, 48], [49, 54], [55, 57], [58, 63], [64, 68], [69, 71], [72, 77], [78, 80], [81, 82], [83, 89], [89, 91], [92, 96], [97, 100], [101, 104], [105, 111], [112, 114], [115, 118], [119, 123], [124, 126], [127, 131], [132, 138], [138, 139]]}
{"doc_key": "ai-dev-192", "ner": [[0, 1, "organisation"], [3, 4, "product"], [13, 15, "product"], [22, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 3, 4, "artifact", "", false, false], [3, 4, 13, 15, "part-of", "", false, false], [13, 15, 3, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc", "introduces", "Face", "ID", "as", "a", "biometric", "authentication", "system", "on", "its", "flagship", "i", "Phone", "X", ",", "replacing", "the", "fingerprint", "-", "based", "Touch", "ID", "system", "."], "sentence-detokenized": "Apple Inc introduces Face ID as a biometric authentication system on its flagship iPhone X, replacing the fingerprint-based Touch ID system.", "token2charspan": [[0, 5], [6, 9], [10, 20], [21, 25], [26, 28], [29, 31], [32, 33], [34, 43], [44, 58], [59, 65], [66, 68], [69, 72], [73, 81], [82, 83], [83, 88], [89, 90], [90, 91], [92, 101], [102, 105], [106, 117], [117, 118], [118, 123], [124, 129], [130, 132], [133, 139], [139, 140]]}
{"doc_key": "ai-dev-193", "ner": [[2, 5, "metrics"], [8, 11, "metrics"], [21, 24, "metrics"], [27, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Or", "combine", "the", "F", "-", "measure", "with", "the", "R-", "squared", "estimated", "for", "the", "raw", "model", "output", "and", "target", ";", "or", "the", "cost", "/", "benefit", "matrix", "with", "the", "correlation", "coefficient", ",", "and", "so", "on", "."], "sentence-detokenized": "Or combine the F-measure with the R-squared estimated for the raw model output and target; or the cost/benefit matrix with the correlation coefficient, and so on.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 16], [16, 17], [17, 24], [25, 29], [30, 33], [34, 36], [36, 43], [44, 53], [54, 57], [58, 61], [62, 65], [66, 71], [72, 78], [79, 82], [83, 89], [89, 90], [91, 93], [94, 97], [98, 102], [102, 103], [103, 110], [111, 117], [118, 122], [123, 126], [127, 138], [139, 150], [150, 151], [152, 155], [156, 158], [159, 161], [161, 162]]}
{"doc_key": "ai-dev-194", "ner": [[6, 9, "conference"], [15, 17, "location"], [19, 19, "location"], [21, 24, "location"], [25, 26, "location"], [28, 28, "country"], [34, 37, "location"], [41, 45, "location"], [40, 40, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 9, 15, 17, "physical", "", false, false], [6, 9, 21, 24, "physical", "", false, false], [6, 9, 34, 37, "physical", "", false, false], [6, 9, 41, 45, "physical", "", false, false], [15, 17, 19, 19, "physical", "", false, false], [21, 24, 25, 26, "physical", "", false, false], [25, 26, 28, 28, "physical", "", false, false], [34, 37, 40, 40, "physical", "", false, false], [41, 45, 40, 40, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Over", "the", "last", "15", "years", ",", "Campus", "Parties", "in", "Spain", "have", "been", "held", "at", "the", "Colegio", "Miguel", "Hern\u00e1ndez", ",", "Ceulaj", "and", "Benalm\u00e1dena", "municipal", "sports", "arenas", "in", "Malaga", ",", "Spain", ",", "as", "well", "as", "at", "the", "Valencia", "County", "Fair", "and", "the", "Valencia", "City", "of", "Arts", "and", "Sciences", "."], "sentence-detokenized": "Over the last 15 years, Campus Parties in Spain have been held at the Colegio Miguel Hern\u00e1ndez, Ceulaj and Benalm\u00e1dena municipal sports arenas in Malaga, Spain, as well as at the Valencia County Fair and the Valencia City of Arts and Sciences.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 22], [22, 23], [24, 30], [31, 38], [39, 41], [42, 47], [48, 52], [53, 57], [58, 62], [63, 65], [66, 69], [70, 77], [78, 84], [85, 94], [94, 95], [96, 102], [103, 106], [107, 118], [119, 128], [129, 135], [136, 142], [143, 145], [146, 152], [152, 153], [154, 159], [159, 160], [161, 163], [164, 168], [169, 171], [172, 174], [175, 178], [179, 187], [188, 194], [195, 199], [200, 203], [204, 207], [208, 216], [217, 221], [222, 224], [225, 229], [230, 233], [234, 242], [242, 243]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [15, 15, "programlang"], [18, 18, "product"], [20, 20, "product"], [24, 24, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 15, 0, 0, "general-affiliation", "", false, false], [18, 18, 15, 15, "part-of", "", false, false], [20, 20, 15, 15, "part-of", "", false, false], [24, 24, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["gnuplot", "can", "be", "used", "in", "a", "variety", "of", "programming", "languages", "to", "display", "data", ",", "including", "Perl", "(", "using", "PDL", "and", "CPAN", "packages", ")", ",", "Python", "(", "using", ")", "."], "sentence-detokenized": "gnuplot can be used in a variety of programming languages to display data, including Perl (using PDL and CPAN packages), Python (using).", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 19], [20, 22], [23, 24], [25, 32], [33, 35], [36, 47], [48, 57], [58, 60], [61, 68], [69, 73], [73, 74], [75, 84], [85, 89], [90, 91], [91, 96], [97, 100], [101, 104], [105, 109], [110, 118], [118, 119], [119, 120], [121, 127], [128, 129], [129, 134], [134, 135], [135, 136]]}
{"doc_key": "ai-dev-196", "ner": [[3, 5, "product"], [21, 21, "conference"], [23, 25, "conference"], [35, 35, "conference"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 21, 3, 5, "topic", "", false, false], [23, 25, 3, 5, "topic", "", false, false], [35, 35, 3, 5, "topic", "", false, false], [37, 37, 3, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "scope", "of", "spoken", "dialogue", "systems", "is", "quite", "broad", ",", "ranging", "from", "research", "(", "as", "reflected", "in", "scientific", "conferences", "such", "as", "SIGdial", "and", "Interspeech", ")", "to", "industry", "at", "large", "(", "with", "its", "meetings", "such", "as", "SpeechTek", "and", "AVIOS", ")", "."], "sentence-detokenized": "The scope of spoken dialogue systems is quite broad, ranging from research (as reflected in scientific conferences such as SIGdial and Interspeech) to industry at large (with its meetings such as SpeechTek and AVIOS).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 28], [29, 36], [37, 39], [40, 45], [46, 51], [51, 52], [53, 60], [61, 65], [66, 74], [75, 76], [76, 78], [79, 88], [89, 91], [92, 102], [103, 114], [115, 119], [120, 122], [123, 130], [131, 134], [135, 146], [146, 147], [148, 150], [151, 159], [160, 162], [163, 168], [169, 170], [170, 174], [175, 178], [179, 187], [188, 192], [193, 195], [196, 205], [206, 209], [210, 215], [215, 216], [216, 217]]}
{"doc_key": "ai-dev-197", "ner": [[0, 2, "field"], [6, 7, "task"], [9, 11, "task"], [13, 15, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 0, 2, "part-of", "task_part_of_field", false, false], [9, 11, 0, 2, "part-of", "task_part_of_field", false, false], [13, 15, 0, 2, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Natural", "language", "processing", "tasks", "often", "involve", "speech", "recognition", ",", "natural", "language", "understanding", "and", "natural", "language", "generation", "."], "sentence-detokenized": "Natural language processing tasks often involve speech recognition, natural language understanding and natural language generation.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 33], [34, 39], [40, 47], [48, 54], [55, 66], [66, 67], [68, 75], [76, 84], [85, 98], [99, 102], [103, 110], [111, 119], [120, 130], [130, 131]]}
{"doc_key": "ai-dev-198", "ner": [[5, 5, "product"], [6, 7, "product"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 6, 7, "part-of", "", false, false], [5, 5, 33, 34, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "such", "as", "Siri", "for", "iOS", ",", "work", "using", "a", "similar", "pattern", "recognition", "method", "as", "text", "-", "based", "systems", ",", "but", "in", "the", "former", "case", ",", "user", "input", "is", "provided", "via", "speech", "recognition", "."], "sentence-detokenized": "These systems, such as Siri for iOS, work using a similar pattern recognition method as text-based systems, but in the former case, user input is provided via speech recognition.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 27], [28, 31], [32, 35], [35, 36], [37, 41], [42, 47], [48, 49], [50, 57], [58, 65], [66, 77], [78, 84], [85, 87], [88, 92], [92, 93], [93, 98], [99, 106], [106, 107], [108, 111], [112, 114], [115, 118], [119, 125], [126, 130], [130, 131], [132, 136], [137, 142], [143, 145], [146, 154], [155, 158], [159, 165], [166, 177], [177, 178]]}
{"doc_key": "ai-dev-199", "ner": [[0, 4, "algorithm"], [16, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 16, 17, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["More", "exotic", "fit", "functions", "that", "explore", "the", "granularity", "of", "the", "model", "include", "the", "area", "under", "the", "ROC", "curve", "and", "the", "rank", "measure", "."], "sentence-detokenized": "More exotic fit functions that explore the granularity of the model include the area under the ROC curve and the rank measure.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 25], [26, 30], [31, 38], [39, 42], [43, 54], [55, 57], [58, 61], [62, 67], [68, 75], [76, 79], [80, 84], [85, 90], [91, 94], [95, 98], [99, 104], [105, 108], [109, 112], [113, 117], [118, 125], [125, 126]]}
{"doc_key": "ai-dev-200", "ner": [[3, 4, "product"], [9, 12, "researcher"], [16, 19, "product"], [27, 27, "organisation"], [29, 29, "organisation"], [38, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 9, 12, "origin", "", false, false], [9, 12, 27, 27, "role", "", false, false], [16, 19, 9, 12, "origin", "", false, false], [29, 29, 27, 27, "named", "", false, false], [38, 40, 27, 27, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "term", "\"", "Semantic", "Web", "\"", "was", "coined", "by", "Tim", "Berners", "-", "Lee", ",", "inventor", "of", "the", "World", "Wide", "Web", "and", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "oversees", "the", "development", "of", "proposed", "Semantic", "Web", "standards", "."], "sentence-detokenized": "The term \"Semantic Web\" was coined by Tim Berners-Lee, inventor of the World Wide Web and director of the World Wide Web Consortium (W3C), which oversees the development of proposed Semantic Web standards.", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 18], [19, 22], [22, 23], [24, 27], [28, 34], [35, 37], [38, 41], [42, 49], [49, 50], [50, 53], [53, 54], [55, 63], [64, 66], [67, 70], [71, 76], [77, 81], [82, 85], [86, 89], [90, 98], [99, 101], [102, 105], [106, 111], [112, 116], [117, 120], [121, 131], [132, 133], [133, 136], [136, 137], [137, 138], [139, 144], [145, 153], [154, 157], [158, 169], [170, 172], [173, 181], [182, 190], [191, 194], [195, 204], [204, 205]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [5, 5, "task"], [12, 13, "product"], [15, 19, "product"], [21, 21, "product"], [24, 29, "product"], [32, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 12, 13, "opposite", "", false, false], [0, 1, 15, 19, "opposite", "", false, false], [0, 1, 24, 29, "opposite", "", false, false], [0, 1, 32, 33, "part-of", "", false, false], [5, 5, 0, 1, "named", "", false, false], [21, 21, 15, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Machine", "translation", ",", "sometimes", "abbreviated", "MT", "(", "not", "to", "be", "confused", "with", "computer-assisted", "translation", ",", "machine", "-", "assisted", "human", "translation", "(", "MAHT", ")", "or", "interactive", "translation", ")", ",", "is", "a", "subfield", "of", "computer", "linguistics", "that", "studies", "the", "use", "of", "software", "to", "translate", "text", "or", "speech", "from", "one", "language", "into", "another", "."], "sentence-detokenized": "Machine translation, sometimes abbreviated MT (not to be confused with computer-assisted translation, machine-assisted human translation (MAHT) or interactive translation), is a subfield of computer linguistics that studies the use of software to translate text or speech from one language into another.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 30], [31, 42], [43, 45], [46, 47], [47, 50], [51, 53], [54, 56], [57, 65], [66, 70], [71, 88], [89, 100], [100, 101], [102, 109], [109, 110], [110, 118], [119, 124], [125, 136], [137, 138], [138, 142], [142, 143], [144, 146], [147, 158], [159, 170], [170, 171], [171, 172], [173, 175], [176, 177], [178, 186], [187, 189], [190, 198], [199, 210], [211, 215], [216, 223], [224, 227], [228, 231], [232, 234], [235, 243], [244, 246], [247, 256], [257, 261], [262, 264], [265, 271], [272, 276], [277, 280], [281, 289], [290, 294], [295, 302], [302, 303]]}
{"doc_key": "ai-dev-202", "ner": [[1, 3, "product"], [7, 10, "university"], [13, 14, "researcher"], [16, 17, "researcher"], [40, 43, "location"], [44, 45, "location"], [49, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 3, 13, 14, "artifact", "", false, false], [1, 3, 16, 17, "artifact", "", false, false], [13, 14, 7, 10, "physical", "", false, false], [13, 14, 7, 10, "role", "", false, false], [16, 17, 7, 10, "physical", "", false, false], [16, 17, 7, 10, "role", "", false, false], [40, 43, 44, 45, "physical", "", false, false], [49, 52, 40, 43, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Early", "cross-lingual", "MT", "systems", "were", "also", "developed", "at", "Stanford", "in", "the", "1970s", "by", "Roger", "Shanks", "and", "Yorick", "Wilkes", ";", "the", "former", "became", "the", "basis", "for", "a", "commercial", "system", "for", "transferring", "funds", ",", "and", "the", "code", "for", "the", "latter", "is", "preserved", "at", "the", "Computer", "Museum", "in", "Boston", "as", "the", "first", "cross-lingual", "machine", "translation", "system", "."], "sentence-detokenized": "Early cross-lingual MT systems were also developed at Stanford in the 1970s by Roger Shanks and Yorick Wilkes; the former became the basis for a commercial system for transferring funds, and the code for the latter is preserved at the Computer Museum in Boston as the first cross-lingual machine translation system.", "token2charspan": [[0, 5], [6, 19], [20, 22], [23, 30], [31, 35], [36, 40], [41, 50], [51, 53], [54, 62], [63, 65], [66, 69], [70, 75], [76, 78], [79, 84], [85, 91], [92, 95], [96, 102], [103, 109], [109, 110], [111, 114], [115, 121], [122, 128], [129, 132], [133, 138], [139, 142], [143, 144], [145, 155], [156, 162], [163, 166], [167, 179], [180, 185], [185, 186], [187, 190], [191, 194], [195, 199], [200, 203], [204, 207], [208, 214], [215, 217], [218, 227], [228, 230], [231, 234], [235, 243], [244, 250], [251, 253], [254, 260], [261, 263], [264, 267], [268, 273], [274, 287], [288, 295], [296, 307], [308, 314], [314, 315]]}
{"doc_key": "ai-dev-203", "ner": [[0, 0, "researcher"], [5, 10, "conference"], [12, 13, "conference"], [20, 25, "conference"], [27, 28, "conference"], [34, 40, "organisation"], [45, 45, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 10, "role", "", false, false], [0, 0, 20, 25, "role", "", false, false], [0, 0, 34, 40, "role", "", false, false], [0, 0, 45, 45, "role", "", false, false], [12, 13, 5, 10, "named", "", false, false], [27, 28, 20, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sycara", "was", "Program", "Chair", "of", "the", "Second", "International", "Semantic", "Web", "Conference", "(", "ISWC", "2003", ")", ",", "General", "Chair", "of", "the", "Second", "International", "Conference", "on", "Autonomous", "Agents", "(", "Agents", "98", ")", ",", "Chair", "of", "the", "Steering", "Committee", "of", "the", "Conference", "on", "Agents", "(", "1999-2001", ")", ",", "AAAI", "Fellowship", "Chair", "(", "1993-1999", ")", ";"], "sentence-detokenized": "Sycara was Program Chair of the Second International Semantic Web Conference (ISWC 2003), General Chair of the Second International Conference on Autonomous Agents (Agents 98), Chair of the Steering Committee of the Conference on Agents (1999-2001), AAAI Fellowship Chair (1993-1999);", "token2charspan": [[0, 6], [7, 10], [11, 18], [19, 24], [25, 27], [28, 31], [32, 38], [39, 52], [53, 61], [62, 65], [66, 76], [77, 78], [78, 82], [83, 87], [87, 88], [88, 89], [90, 97], [98, 103], [104, 106], [107, 110], [111, 117], [118, 131], [132, 142], [143, 145], [146, 156], [157, 163], [164, 165], [165, 171], [172, 174], [174, 175], [175, 176], [177, 182], [183, 185], [186, 189], [190, 198], [199, 208], [209, 211], [212, 215], [216, 226], [227, 229], [230, 236], [237, 238], [238, 247], [247, 248], [248, 249], [250, 254], [255, 265], [266, 271], [272, 273], [273, 282], [282, 283], [283, 284]]}
{"doc_key": "ai-dev-204", "ner": [[11, 11, "conference"], [13, 16, "conference"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 11, 11, "named", "", false, false], [18, 20, 11, 11, "part-of", "", false, false], [18, 20, 11, 11, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2016", ",", "she", "was", "selected", "as", "the", "winner", "of", "the", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "Lifetime", "Achievement", "Award", "."], "sentence-detokenized": "In 2016, she was selected as the winner of the ACL (Association for Computational Linguistics) Lifetime Achievement Award.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 25], [26, 28], [29, 32], [33, 39], [40, 42], [43, 46], [47, 50], [51, 52], [52, 63], [64, 67], [68, 81], [82, 93], [93, 94], [95, 103], [104, 115], [116, 121], [121, 122]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P.", "Frasconi", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 30], [31, 39], [40, 43], [44, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-206", "ner": [[3, 3, "product"], [8, 9, "misc"], [5, 7, "programlang"], [16, 17, "product"], [32, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 5, 7, "usage", "", false, false], [5, 7, 8, 9, "type-of", "", false, false], [5, 7, 16, 17, "related-to", "", false, false], [32, 32, 3, 3, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["For", "example", ",", "A.L.I.C.E.", "uses", "AIML", ",", "a", "markup", "language", "specific", "to", "its", "function", "as", "a", "dialogue", "system", ",", "which", "has", "since", "been", "adopted", "by", "various", "other", "developers", "of", "so", "-", "called", "Alicebots", "."], "sentence-detokenized": "For example, A.L.I.C.E. uses AIML, a markup language specific to its function as a dialogue system, which has since been adopted by various other developers of so-called Alicebots.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 23], [24, 28], [29, 33], [33, 34], [35, 36], [37, 43], [44, 52], [53, 61], [62, 64], [65, 68], [69, 77], [78, 80], [81, 82], [83, 91], [92, 98], [98, 99], [100, 105], [106, 109], [110, 115], [116, 120], [121, 128], [129, 131], [132, 139], [140, 145], [146, 156], [157, 159], [160, 162], [162, 163], [163, 169], [170, 179], [179, 180]]}
{"doc_key": "ai-dev-207", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2000", ",", "she", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2000, she was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 24], [25, 26], [27, 33], [34, 36], [37, 40], [41, 52], [53, 56], [57, 60], [61, 72], [73, 75], [76, 86], [87, 99], [99, 100]]}
{"doc_key": "ai-dev-208", "ner": [[0, 2, "misc"], [4, 4, "misc"], [10, 16, "misc"], [23, 25, "algorithm"], [34, 35, "field"], [37, 38, "field"], [40, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 10, 16, "type-of", "", false, false], [0, 2, 34, 35, "related-to", "performs", true, false], [0, 2, 37, 38, "related-to", "performs", true, false], [0, 2, 40, 41, "related-to", "performs", true, false], [4, 4, 0, 2, "named", "", false, false], [23, 25, 10, 16, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Learning", "Classifier", "Systems", "(", "LCS", ")", "are", "a", "family", "of", "rule", "-", "based", "machine", "learning", "algorithms", "that", "combine", "a", "detection", "component", ",", "usually", "a", "genetic", "algorithm", ",", "with", "a", "learning", "component", ",", "performing", "either", "supervised", "learning", ",", "reinforcement", "learning", "or", "unsupervised", "learning", "."], "sentence-detokenized": "Learning Classifier Systems (LCS) are a family of rule-based machine learning algorithms that combine a detection component, usually a genetic algorithm, with a learning component, performing either supervised learning, reinforcement learning or unsupervised learning.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 29], [29, 32], [32, 33], [34, 37], [38, 39], [40, 46], [47, 49], [50, 54], [54, 55], [55, 60], [61, 68], [69, 77], [78, 88], [89, 93], [94, 101], [102, 103], [104, 113], [114, 123], [123, 124], [125, 132], [133, 134], [135, 142], [143, 152], [152, 153], [154, 158], [159, 160], [161, 169], [170, 179], [179, 180], [181, 191], [192, 198], [199, 209], [210, 218], [218, 219], [220, 233], [234, 242], [243, 245], [246, 258], [259, 267], [267, 268]]}
{"doc_key": "ai-dev-209", "ner": [[15, 17, "algorithm"], [19, 19, "algorithm"], [28, 30, "algorithm"], [34, 35, "misc"], [44, 48, "algorithm"], [51, 62, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 17, 28, 30, "origin", "", false, false], [15, 17, 34, 35, "usage", "", false, false], [19, 19, 15, 17, "named", "", false, false], [44, 48, 34, 35, "type-of", "", false, false], [44, 48, 51, 62, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "unknown", "parameters", "of", "each", "vector", "\u03b2subk", "/", "sub", "are", "usually", "jointly", "estimated", "using", "a", "maximum", "a", "posteriori", "(", "MAP", ")", "estimator", ",", "which", "is", "an", "extension", "of", "the", "maximum", "likelihood", ",", "using", "a", "regularisation", "of", "the", "weights", "to", "prevent", "pathological", "solutions", "(", "usually", "a", "quadratic", "regularisation", "function", "equivalent", "to", "a", "Gaussian", "prior", "distribution", "of", "the", "mean", "of", "the", "null", "distribution", "of", "the", "weights", ",", "but", "other", "distributions", "are", "also", "possible", ")", "."], "sentence-detokenized": "The unknown parameters of each vector \u03b2subk/sub are usually jointly estimated using a maximum a posteriori (MAP) estimator, which is an extension of the maximum likelihood, using a regularisation of the weights to prevent pathological solutions (usually a quadratic regularisation function equivalent to a Gaussian prior distribution of the mean of the null distribution of the weights, but other distributions are also possible).", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 30], [31, 37], [38, 43], [43, 44], [44, 47], [48, 51], [52, 59], [60, 67], [68, 77], [78, 83], [84, 85], [86, 93], [94, 95], [96, 106], [107, 108], [108, 111], [111, 112], [113, 122], [122, 123], [124, 129], [130, 132], [133, 135], [136, 145], [146, 148], [149, 152], [153, 160], [161, 171], [171, 172], [173, 178], [179, 180], [181, 195], [196, 198], [199, 202], [203, 210], [211, 213], [214, 221], [222, 234], [235, 244], [245, 246], [246, 253], [254, 255], [256, 265], [266, 280], [281, 289], [290, 300], [301, 303], [304, 305], [306, 314], [315, 320], [321, 333], [334, 336], [337, 340], [341, 345], [346, 348], [349, 352], [353, 357], [358, 370], [371, 373], [374, 377], [378, 385], [385, 386], [387, 390], [391, 396], [397, 410], [411, 414], [415, 419], [420, 428], [428, 429], [429, 430]]}
{"doc_key": "ai-dev-210", "ner": [[9, 11, "researcher"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 9, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "hierarchical", "structure", "of", "words", "is", "clearly", "outlined", "in", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "The hierarchical structure of words is clearly outlined in George Miller's Wordnet.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 29], [30, 35], [36, 38], [39, 46], [47, 55], [56, 58], [59, 65], [66, 72], [72, 74], [75, 82], [82, 83]]}
{"doc_key": "ai-dev-211", "ner": [[6, 12, "conference"], [17, 20, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 20, 6, 12, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Their", "capabilities", "are", "illustrated", "by", "the", "ImageNet", "large", "-", "scale", "visual", "recognition", "challenge", ",", "a", "benchmark", "for", "object", "classification", "and", "detection", "that", "contains", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "Their capabilities are illustrated by the ImageNet large-scale visual recognition challenge, a benchmark for object classification and detection that contains millions of images and hundreds of object classes.", "token2charspan": [[0, 5], [6, 18], [19, 22], [23, 34], [35, 37], [38, 41], [42, 50], [51, 56], [56, 57], [57, 62], [63, 69], [70, 81], [82, 91], [91, 92], [93, 94], [95, 104], [105, 108], [109, 115], [116, 130], [131, 134], [135, 144], [145, 149], [150, 158], [159, 167], [168, 170], [171, 177], [178, 181], [182, 190], [191, 193], [194, 200], [201, 208], [208, 209]]}
{"doc_key": "ai-dev-212", "ner": [[0, 2, "misc"], [26, 26, "misc"], [29, 32, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[26, 26, 0, 2, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "science", "fiction", ",", "robots", "that", "look", "like", "women", "are", "often", "created", "to", "be", "used", "as", "domestic", "servants", "and", "sex", "slaves", ",", "as", "seen", "in", "\"", "Westworld", "\"", ",", "Paul", "J.", "Sometimes", "as", "warriors", ",", "assassins", "or", "workers", "."], "sentence-detokenized": "In science fiction, robots that look like women are often created to be used as domestic servants and sex slaves, as seen in \"Westworld\", Paul J. Sometimes as warriors, assassins or workers.", "token2charspan": [[0, 2], [3, 10], [11, 18], [18, 19], [20, 26], [27, 31], [32, 36], [37, 41], [42, 47], [48, 51], [52, 57], [58, 65], [66, 68], [69, 71], [72, 76], [77, 79], [80, 88], [89, 97], [98, 101], [102, 105], [106, 112], [112, 113], [114, 116], [117, 121], [122, 124], [125, 126], [126, 135], [135, 136], [136, 137], [138, 142], [143, 145], [146, 155], [156, 158], [159, 167], [167, 168], [169, 178], [179, 181], [182, 189], [189, 190]]}
{"doc_key": "ai-dev-213", "ner": [[0, 1, "task"], [3, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["question", "answering", ",", "speech", "recognition", "and", "machine", "translation", "."], "sentence-detokenized": "question answering, speech recognition and machine translation.", "token2charspan": [[0, 8], [9, 18], [18, 19], [20, 26], [27, 38], [39, 42], [43, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-214", "ner": [[5, 6, "researcher"], [9, 13, "organisation"], [14, 18, "location"], [19, 20, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 9, 13, "role", "", false, false], [9, 13, 14, 18, "physical", "", false, false], [14, 18, 19, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "his", "fundamental", "work", ",", "Harry", "Blum", "of", "the", "Air", "Force", "Cambridge", "Research", "Laboratory", "at", "Hanscom", "Air", "Force", "Base", "in", "Bedford", ",", "Massachusetts", ",", "defined", "a", "medial", "axis", "to", "calculate", "the", "skeleton", "of", "a", "figure", "using", "an", "intuitive", "model", "of", "fire", "propagation", "on", "a", "grass", "field", ",", "where", "the", "field", "has", "the", "shape", "of", "a", "given", "figure", "."], "sentence-detokenized": "In his fundamental work, Harry Blum of the Air Force Cambridge Research Laboratory at Hanscom Air Force Base in Bedford, Massachusetts, defined a medial axis to calculate the skeleton of a figure using an intuitive model of fire propagation on a grass field, where the field has the shape of a given figure.", "token2charspan": [[0, 2], [3, 6], [7, 18], [19, 23], [23, 24], [25, 30], [31, 35], [36, 38], [39, 42], [43, 46], [47, 52], [53, 62], [63, 71], [72, 82], [83, 85], [86, 93], [94, 97], [98, 103], [104, 108], [109, 111], [112, 119], [119, 120], [121, 134], [134, 135], [136, 143], [144, 145], [146, 152], [153, 157], [158, 160], [161, 170], [171, 174], [175, 183], [184, 186], [187, 188], [189, 195], [196, 201], [202, 204], [205, 214], [215, 220], [221, 223], [224, 228], [229, 240], [241, 243], [244, 245], [246, 251], [252, 257], [257, 258], [259, 264], [265, 268], [269, 274], [275, 278], [279, 282], [283, 288], [289, 291], [292, 293], [294, 299], [300, 306], [306, 307]]}
{"doc_key": "ai-dev-215", "ner": [[15, 15, "algorithm"], [17, 17, "algorithm"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 20, 21, "compare", "", false, false], [17, 17, 20, 21, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "unlike", "boosting", "algorithms", "that", "analytically", "minimise", "a", "convex", "loss", "function", "(", "such", "as", "AdaBoost", "and", "LogitBoost", ")", ",", "Brown", "Boost", "solves", "a", "system", "of", "two", "equations", "and", "two", "unknowns", "using", "standard", "numerical", "methods", "."], "sentence-detokenized": "However, unlike boosting algorithms that analytically minimise a convex loss function (such as AdaBoost and LogitBoost), BrownBoost solves a system of two equations and two unknowns using standard numerical methods.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 24], [25, 35], [36, 40], [41, 53], [54, 62], [63, 64], [65, 71], [72, 76], [77, 85], [86, 87], [87, 91], [92, 94], [95, 103], [104, 107], [108, 118], [118, 119], [119, 120], [121, 126], [126, 131], [132, 138], [139, 140], [141, 147], [148, 150], [151, 154], [155, 164], [165, 168], [169, 172], [173, 181], [182, 187], [188, 196], [197, 206], [207, 214], [214, 215]]}
{"doc_key": "ai-dev-216", "ner": [[0, 1, "researcher"], [9, 13, "misc"], [18, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 9, 13, "win-defeat", "", false, false], [0, 1, 18, 24, "role", "", false, false], [26, 26, 18, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getoor", "has", "received", "several", "best", "paper", "awards", ",", "an", "NSF", "Career", "Award", "and", "is", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Getoor has received several best paper awards, an NSF Career Award and is a member of the Association for the Advancement of Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 27], [28, 32], [33, 38], [39, 45], [45, 46], [47, 49], [50, 53], [54, 60], [61, 66], [67, 70], [71, 73], [74, 75], [76, 82], [83, 85], [86, 89], [90, 101], [102, 105], [106, 109], [110, 121], [122, 124], [125, 135], [136, 148], [149, 150], [150, 154], [154, 155], [155, 156]]}
{"doc_key": "ai-dev-217", "ner": [[0, 1, "misc"], [6, 12, "misc"], [17, 19, "misc"], [24, 30, "misc"], [35, 37, "misc"], [38, 42, "university"], [47, 54, "misc"], [59, 67, "misc"], [72, 76, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACM", "Fellow", "(", "2015", ")", "br", "Fellow", "of", "the", "Association", "for", "Computational", "Linguistics", "(", "2011", ")", "br", "Fellow", "of", "AAAI", "(", "1994", ")", "br", "Fellow", "of", "the", "International", "Speech", "Communication", "Association", "(", "2011", ")", "br", "Honorary", "Doctorate", "from", "KTH", "Royal", "Institute", "of", "Technology", "(", "2007", ")", "br", "Columbia", "Engineering", "School", "Alumni", "Association", "Distinguished", "Teaching", "Award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Speech", "and", "Sound", "Processing", "Award", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")"], "sentence-detokenized": "ACM Fellow (2015) br Fellow of the Association for Computational Linguistics (2011) br Fellow of AAAI (1994) br Fellow of the International Speech Communication Association (2011) br Honorary Doctorate from KTH Royal Institute of Technology (2007) br Columbia Engineering School Alumni Association Distinguished Teaching Award (2009) br IEEE James L. Flanagan Speech and Sound Processing Award (2011) br ISCA Medal for Scientific Achievement (2011)", "token2charspan": [[0, 3], [4, 10], [11, 12], [12, 16], [16, 17], [18, 20], [21, 27], [28, 30], [31, 34], [35, 46], [47, 50], [51, 64], [65, 76], [77, 78], [78, 82], [82, 83], [84, 86], [87, 93], [94, 96], [97, 101], [102, 103], [103, 107], [107, 108], [109, 111], [112, 118], [119, 121], [122, 125], [126, 139], [140, 146], [147, 160], [161, 172], [173, 174], [174, 178], [178, 179], [180, 182], [183, 191], [192, 201], [202, 206], [207, 210], [211, 216], [217, 226], [227, 229], [230, 240], [241, 242], [242, 246], [246, 247], [248, 250], [251, 259], [260, 271], [272, 278], [279, 285], [286, 297], [298, 311], [312, 320], [321, 326], [327, 328], [328, 332], [332, 333], [334, 336], [337, 341], [342, 347], [348, 350], [351, 359], [360, 366], [367, 370], [371, 376], [377, 387], [388, 393], [394, 395], [395, 399], [399, 400], [401, 403], [404, 408], [409, 414], [415, 418], [419, 429], [430, 441], [442, 443], [443, 447], [447, 448]]}
{"doc_key": "ai-dev-218", "ner": [[6, 6, "university"], [14, 16, "task"], [25, 27, "metrics"], [39, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 27, 39, 41, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["A", "disappointing", "result", "of", "the", "same", "Stanford", "study", "(", "and", "other", "attempts", "to", "improve", "name", "recognition", "translation", ")", "is", "that", "many", "of", "the", "reductions", "in", "bilingual", "assessment", "underperformance", "in", "translation", "are", "due", "to", "the", "inclusion", "of", "methods", "designed", "to", "translate", "named", "entities", "."], "sentence-detokenized": "A disappointing result of the same Stanford study (and other attempts to improve name recognition translation) is that many of the reductions in bilingual assessment underperformance in translation are due to the inclusion of methods designed to translate named entities.", "token2charspan": [[0, 1], [2, 15], [16, 22], [23, 25], [26, 29], [30, 34], [35, 43], [44, 49], [50, 51], [51, 54], [55, 60], [61, 69], [70, 72], [73, 80], [81, 85], [86, 97], [98, 109], [109, 110], [111, 113], [114, 118], [119, 123], [124, 126], [127, 130], [131, 141], [142, 144], [145, 154], [155, 165], [166, 182], [183, 185], [186, 197], [198, 201], [202, 205], [206, 208], [209, 212], [213, 222], [223, 225], [226, 233], [234, 242], [243, 245], [246, 255], [256, 261], [262, 270], [270, 271]]}
{"doc_key": "ai-dev-219", "ner": [[0, 0, "organisation"], [11, 13, "organisation"], [15, 20, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "role", "works_with", false, false], [0, 0, 15, 20, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "is", "using", "the", "PM", "data", "and", "working", "with", "researchers", "at", "Johns", "Hopkins", "Hospital", "and", "Washington", "University", "School", "of", "Medicine", "to", "help", "answer", "specific", "questions", "about", "heart", "disease", ",", "such", "as", "whether", "a", "weak", "heart", "causes", "arrhythmias", "or", "vice", "versa", "."], "sentence-detokenized": "Medtronic is using the PM data and working with researchers at Johns Hopkins Hospital and Washington University School of Medicine to help answer specific questions about heart disease, such as whether a weak heart causes arrhythmias or vice versa.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 22], [23, 25], [26, 30], [31, 34], [35, 42], [43, 47], [48, 59], [60, 62], [63, 68], [69, 76], [77, 85], [86, 89], [90, 100], [101, 111], [112, 118], [119, 121], [122, 130], [131, 133], [134, 138], [139, 145], [146, 154], [155, 164], [165, 170], [171, 176], [177, 184], [184, 185], [186, 190], [191, 193], [194, 201], [202, 203], [204, 208], [209, 214], [215, 221], [222, 233], [234, 236], [237, 241], [242, 247], [247, 248]]}
{"doc_key": "ai-dev-220", "ner": [[4, 5, "organisation"], [9, 10, "misc"], [13, 14, "person"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 4, 5, "artifact", "made_by_studio", false, false], [13, 14, 9, 10, "role", "", false, false], [16, 17, 9, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "was", "followed", "by", "Paramount", "'s", "first", "feature", "film", ",", "Sangaree", ",", "with", "Fernando", "Lamas", "and", "Arlene", "Dahl", "."], "sentence-detokenized": "This was followed by Paramount's first feature film, Sangaree, with Fernando Lamas and Arlene Dahl.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 30], [30, 32], [33, 38], [39, 46], [47, 51], [51, 52], [53, 61], [61, 62], [63, 67], [68, 76], [77, 82], [83, 86], [87, 93], [94, 98], [98, 99]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [8, 10, "researcher"], [12, 13, "researcher"], [17, 18, "organisation"], [20, 22, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 10, "origin", "", false, false], [0, 0, 12, 13, "origin", "", false, false], [8, 10, 17, 18, "physical", "", false, false], [8, 10, 17, 18, "role", "", false, false], [12, 13, 20, 22, "physical", "", false, false], [12, 13, 20, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "is", "a", "knowledge", "representation", "language", "developed", "by", "Daniel", "G.", "Bobrow", "and", "Terry", "Winograd", ",", "working", "at", "Xerox", "PARC", "and", "Stanford", "University", "respectively", "."], "sentence-detokenized": "KRL is a knowledge representation language developed by Daniel G. Bobrow and Terry Winograd, working at Xerox PARC and Stanford University respectively.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 18], [19, 33], [34, 42], [43, 52], [53, 55], [56, 62], [63, 65], [66, 72], [73, 76], [77, 82], [83, 91], [91, 92], [93, 100], [101, 103], [104, 109], [110, 114], [115, 118], [119, 127], [128, 138], [139, 151], [151, 152]]}
{"doc_key": "ai-dev-222", "ner": [[0, 10, "conference"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 24, "researcher"], [32, 33, "task"], [35, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 10, 32, 33, "topic", "", true, false], [12, 13, 0, 10, "physical", "", false, false], [12, 13, 0, 10, "role", "", false, false], [12, 13, 0, 10, "temporal", "", false, false], [15, 16, 0, 10, "physical", "", false, false], [15, 16, 0, 10, "role", "", false, false], [15, 16, 0, 10, "temporal", "", false, false], [18, 19, 0, 10, "physical", "", false, false], [18, 19, 0, 10, "role", "", false, false], [18, 19, 0, 10, "temporal", "", false, false], [21, 24, 0, 10, "physical", "", false, false], [21, 24, 0, 10, "role", "", false, false], [21, 24, 0, 10, "temporal", "", false, false], [32, 33, 35, 37, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["At", "the", "2006", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", "and", "Kwang", "-", "Ting", "Cheng", "presented", "an", "algorithm", "to", "significantly", "speed", "up", "human", "detection", "using", "HOG", "descriptor", "methods", "."], "sentence-detokenized": "At the 2006 IEEE Conference on Computer Vision and Pattern Recognition, Qiang Zhu, Shai Avidan, Mei-Chen Yeh and Kwang-Ting Cheng presented an algorithm to significantly speed up human detection using HOG descriptor methods.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 27], [28, 30], [31, 39], [40, 46], [47, 50], [51, 58], [59, 70], [70, 71], [72, 77], [78, 81], [81, 82], [83, 87], [88, 94], [94, 95], [96, 104], [105, 108], [109, 112], [113, 118], [118, 119], [119, 123], [124, 129], [130, 139], [140, 142], [143, 152], [153, 155], [156, 169], [170, 175], [176, 178], [179, 184], [185, 194], [195, 200], [201, 204], [205, 215], [216, 223], [223, 224]]}
{"doc_key": "ai-dev-223", "ner": [[0, 0, "researcher"], [6, 7, "conference"], [3, 12, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 7, "role", "", false, false], [0, 0, 3, 12, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "is", "a", "full", "member", "of", "the", "AAAI", "and", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Hayes is a full member of the AAAI and the Cognitive Science Society.", "token2charspan": [[0, 5], [6, 8], [9, 10], [11, 15], [16, 22], [23, 25], [26, 29], [30, 34], [35, 38], [39, 42], [43, 52], [53, 60], [61, 68], [68, 69]]}
{"doc_key": "ai-dev-224", "ner": [[0, 1, "misc"], [4, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 32, "field"], [39, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 1, 4, 5, "part-of", "", false, false], [0, 1, 4, 5, "usage", "", false, false], [0, 1, 7, 8, "part-of", "", false, false], [0, 1, 7, 8, "usage", "", false, false], [0, 1, 10, 11, "part-of", "", false, false], [0, 1, 10, 11, "usage", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [0, 1, 13, 13, "usage", "", false, false], [0, 1, 15, 16, "part-of", "", false, false], [0, 1, 15, 16, "usage", "", false, false], [0, 1, 18, 19, "part-of", "", false, false], [0, 1, 18, 19, "usage", "", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 21, 22, "usage", "", false, false], [0, 1, 24, 24, "part-of", "", false, false], [0, 1, 24, 24, "usage", "", false, false], [0, 1, 26, 27, "part-of", "", false, false], [0, 1, 26, 27, "usage", "", false, false], [0, 1, 29, 29, "part-of", "", false, false], [0, 1, 29, 29, "usage", "", false, false], [0, 1, 31, 32, "part-of", "", false, false], [0, 1, 31, 32, "usage", "", false, false], [0, 1, 39, 40, "part-of", "", false, false], [0, 1, 39, 40, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "image", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", "and", "pretty", "much", "any", "field", "of", "applied", "science", "and", "engineering", "that", "involves", "time", "measurements", "."], "sentence-detokenized": "Time series are used in statistics, signal processing, image recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering and pretty much any field of applied science and engineering that involves time measurements.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 23], [24, 34], [34, 35], [36, 42], [43, 53], [53, 54], [55, 60], [61, 72], [72, 73], [74, 86], [86, 87], [88, 100], [101, 108], [108, 109], [110, 117], [118, 129], [129, 130], [131, 141], [142, 152], [152, 153], [154, 176], [176, 177], [178, 185], [186, 197], [197, 198], [199, 208], [208, 209], [210, 224], [225, 236], [237, 240], [241, 247], [248, 252], [253, 256], [257, 262], [263, 265], [266, 273], [274, 281], [282, 285], [286, 297], [298, 302], [303, 311], [312, 316], [317, 329], [329, 330]]}
{"doc_key": "ai-dev-225", "ner": [[13, 16, "metrics"], [37, 39, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "principle", ",", "exact", "recovery", "over", "its", "feasible", "range", "can", "be", "solved", "using", "maximum", "likelihood", ",", "but", "this", "means", "solving", "a", "restricted", "or", "regular", "cut", "problem", ",", "such", "as", "the", "minimum", "bisecting", "cut", ",", "which", "is", "usually", "NP", "-", "complete", "."], "sentence-detokenized": "In principle, exact recovery over its feasible range can be solved using maximum likelihood, but this means solving a restricted or regular cut problem, such as the minimum bisecting cut, which is usually NP-complete.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 19], [20, 28], [29, 33], [34, 37], [38, 46], [47, 52], [53, 56], [57, 59], [60, 66], [67, 72], [73, 80], [81, 91], [91, 92], [93, 96], [97, 101], [102, 107], [108, 115], [116, 117], [118, 128], [129, 131], [132, 139], [140, 143], [144, 151], [151, 152], [153, 157], [158, 160], [161, 164], [165, 172], [173, 182], [183, 186], [186, 187], [188, 193], [194, 196], [197, 204], [205, 207], [207, 208], [208, 216], [216, 217]]}
{"doc_key": "ai-dev-226", "ner": [[4, 7, "task"], [10, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 12, 4, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["in", "his", "work", "on", "pedestrian", "detection", ",", "first", "described", "in", "the", "BMVC", "in", "2009", "."], "sentence-detokenized": "in his work on pedestrian detection, first described in the BMVC in 2009.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 25], [26, 35], [35, 36], [37, 42], [43, 52], [53, 55], [56, 59], [60, 64], [65, 67], [68, 72], [72, 73]]}
{"doc_key": "ai-dev-227", "ner": [[11, 16, "conference"], [3, 3, "researcher"], [6, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 11, 16, "physical", "", false, false], [3, 3, 11, 16, "role", "", false, false], [3, 3, 6, 18, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2007", ",", "Terzopoulos", "received", "the", "IEEE", "PAMI", "Computer", "Vision", "Award", "at", "the", "International", "Computer", "Vision", "Conference", "for", "his", "innovative", "and", "sustained", "research", "in", "the", "field", "of", "deformable", "models", "and", "their", "applications", "."], "sentence-detokenized": "In 2007, Terzopoulos received the IEEE PAMI Computer Vision Award at the International Computer Vision Conference for his innovative and sustained research in the field of deformable models and their applications.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 29], [30, 33], [34, 38], [39, 43], [44, 52], [53, 59], [60, 65], [66, 68], [69, 72], [73, 86], [87, 95], [96, 102], [103, 113], [114, 117], [118, 121], [122, 132], [133, 136], [137, 146], [147, 155], [156, 158], [159, 162], [163, 168], [169, 171], [172, 182], [183, 189], [190, 193], [194, 199], [200, 212], [212, 213]]}
{"doc_key": "ai-dev-228", "ner": [[0, 1, "task"], [3, 4, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 3, 4, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cluster", "analysis", "or", "cluster", "analysis", "involves", "dividing", "data", "points", "into", "clusters", "so", "that", "elements", "in", "one", "cluster", "are", "as", "similar", "as", "possible", "and", "elements", "in", "different", "clusters", "are", "as", "different", "as", "possible", "."], "sentence-detokenized": "Cluster analysis or cluster analysis involves dividing data points into clusters so that elements in one cluster are as similar as possible and elements in different clusters are as different as possible.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 36], [37, 45], [46, 54], [55, 59], [60, 66], [67, 71], [72, 80], [81, 83], [84, 88], [89, 97], [98, 100], [101, 104], [105, 112], [113, 116], [117, 119], [120, 127], [128, 130], [131, 139], [140, 143], [144, 152], [153, 155], [156, 165], [166, 174], [175, 178], [179, 181], [182, 191], [192, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-dev-229", "ner": [[8, 9, "field"], [15, 16, "field"], [18, 19, "task"], [21, 22, "field"], [25, 26, "field"], [28, 29, "field"], [31, 32, "field"], [34, 35, "task"], [36, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 9, 15, 16, "named", "", false, false], [8, 9, 21, 22, "named", "", false, false], [8, 9, 28, 29, "named", "", false, false], [18, 19, 15, 16, "part-of", "task_part_of_field", false, false], [25, 26, 21, 22, "part-of", "", false, false], [31, 32, 28, 29, "part-of", "", false, false], [34, 35, 31, 32, "part-of", "", false, false], [36, 37, 31, 32, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["(", "2005", ")", ",", "three", "different", "perspectives", "of", "text", "mining", "can", "be", "distinguished", ",", "namely", "text", "mining", "as", "information", "mining", ",", "text", "mining", "as", "text", "data", "mining", "and", "text", "mining", "as", "data", "mining", "(", "knowledge", "discovery", "in", "databases", ")", ".", "Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005), three different perspectives of text mining can be distinguished, namely text mining as information mining, text mining as text data mining and text mining as data mining (knowledge discovery in databases).Hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [6, 7], [8, 13], [14, 23], [24, 36], [37, 39], [40, 44], [45, 51], [52, 55], [56, 58], [59, 72], [72, 73], [74, 80], [81, 85], [86, 92], [93, 95], [96, 107], [108, 114], [114, 115], [116, 120], [121, 127], [128, 130], [131, 135], [136, 140], [141, 147], [148, 151], [152, 156], [157, 163], [164, 166], [167, 171], [172, 178], [179, 180], [180, 189], [190, 199], [200, 202], [203, 212], [212, 213], [213, 214], [214, 219], [219, 220], [221, 223], [223, 224], [225, 235], [235, 236], [237, 239], [240, 243], [244, 248], [248, 249], [250, 252], [253, 254], [254, 258], [258, 259], [259, 260]]}
{"doc_key": "ai-dev-230", "ner": [[0, 2, "product"], [13, 19, "location"], [20, 21, "location"], [23, 26, "location"], [29, 32, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 13, 19, "related-to", "developed_for", false, false], [13, 19, 20, 21, "physical", "", false, false], [20, 21, 23, 26, "physical", "", false, false], [29, 32, 0, 2, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Rancho", "Arm", "was", "developed", "as", "a", "robotic", "arm", "to", "assist", "disabled", "patients", "at", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Centre", "in", "Downey", ",", "California", ";", "it", "was", "acquired", "by", "Stanford", "University", "in", "1963", "."], "sentence-detokenized": "The Rancho Arm was developed as a robotic arm to assist disabled patients at Rancho Los Amigos National Rehabilitation Centre in Downey, California; it was acquired by Stanford University in 1963.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 18], [19, 28], [29, 31], [32, 33], [34, 41], [42, 45], [46, 48], [49, 55], [56, 64], [65, 73], [74, 76], [77, 83], [84, 87], [88, 94], [95, 103], [104, 118], [119, 125], [126, 128], [129, 135], [135, 136], [137, 147], [147, 148], [149, 151], [152, 155], [156, 164], [165, 167], [168, 176], [177, 187], [188, 190], [191, 195], [195, 196]]}
{"doc_key": "ai-dev-231", "ner": [[0, 1, "university"], [3, 3, "researcher"], [10, 13, "organisation"], [33, 35, "organisation"], [22, 23, "researcher"], [25, 27, "researcher"], [42, 42, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 0, 1, "physical", "", false, false], [3, 3, 0, 1, "role", "", false, false], [3, 3, 10, 13, "role", "founder", false, false], [3, 3, 33, 35, "role", "founder", false, false], [33, 35, 42, 42, "physical", "", false, false], [22, 23, 33, 35, "role", "founder", false, false], [25, 27, 33, 35, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["At", "UCSD", ",", "Norman", "was", "one", "of", "the", "founders", "of", "the", "Cognitive", "Science", "Institute", "and", "one", "of", "the", "organisers", "(", "along", "with", "Roger", "Shanks", ",", "Alan", "M.", "Collins", "and", "others", ")", "of", "the", "Cognitive", "Science", "Society", ",", "which", "first", "met", "on", "the", "UCSD", "campus", "in", "1979", "."], "sentence-detokenized": "At UCSD, Norman was one of the founders of the Cognitive Science Institute and one of the organisers (along with Roger Shanks, Alan M. Collins and others) of the Cognitive Science Society, which first met on the UCSD campus in 1979.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 23], [24, 26], [27, 30], [31, 39], [40, 42], [43, 46], [47, 56], [57, 64], [65, 74], [75, 78], [79, 82], [83, 85], [86, 89], [90, 100], [101, 102], [102, 107], [108, 112], [113, 118], [119, 125], [125, 126], [127, 131], [132, 134], [135, 142], [143, 146], [147, 153], [153, 154], [155, 157], [158, 161], [162, 171], [172, 179], [180, 187], [187, 188], [189, 194], [195, 200], [201, 204], [205, 207], [208, 211], [212, 216], [217, 223], [224, 226], [227, 231], [231, 232]]}
{"doc_key": "ai-dev-232", "ner": [[6, 7, "product"], [9, 10, "product"], [12, 13, "product"], [15, 17, "product"], [19, 19, "product"], [21, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[19, 19, 15, 17, "type-of", "", false, false], [21, 26, 15, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "common", "robot", "configurations", "are", "articulated", "robots", ",", "SCARA", "robots", ",", "delta", "robots", "and", "Cartesian", "coordinate", "robots", "(", "gantry", "or", "x", "-", "y", "-", "z", "robots", ")", "."], "sentence-detokenized": "The most common robot configurations are articulated robots, SCARA robots, delta robots and Cartesian coordinate robots (gantry or x-y-z robots).", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 21], [22, 36], [37, 40], [41, 52], [53, 59], [59, 60], [61, 66], [67, 73], [73, 74], [75, 80], [81, 87], [88, 91], [92, 101], [102, 112], [113, 119], [120, 121], [121, 127], [128, 130], [131, 132], [132, 133], [133, 134], [134, 135], [135, 136], [137, 143], [143, 144], [144, 145]]}
{"doc_key": "ai-dev-233", "ner": [[8, 8, "programlang"], [9, 10, "misc"], [15, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 8, 8, "part-of", "", false, false], [15, 15, 9, 10, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "can", "also", "be", "used", "directly", "with", "the", "Perl", "module", "TM", "(", "which", "also", "supports", "LTM", ")", "."], "sentence-detokenized": "It can also be used directly with the Perl module TM (which also supports LTM).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 19], [20, 28], [29, 33], [34, 37], [38, 42], [43, 49], [50, 52], [53, 54], [54, 59], [60, 64], [65, 73], [74, 77], [77, 78], [78, 79]]}
{"doc_key": "ai-dev-234", "ner": [[0, 2, "country"], [5, 6, "organisation"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 0, 2, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "United", "States", "team", "from", "Newton", "Labs", "won", "the", "competition", ",", "which", "was", "broadcast", "on", "CNN", "."], "sentence-detokenized": "The United States team from Newton Labs won the competition, which was broadcast on CNN.", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 22], [23, 27], [28, 34], [35, 39], [40, 43], [44, 47], [48, 59], [59, 60], [61, 66], [67, 70], [71, 80], [81, 83], [84, 87], [87, 88]]}
{"doc_key": "ai-dev-235", "ner": [[6, 18, "misc"], [15, 17, "person"], [20, 21, "person"], [23, 27, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 17, 6, 18, "role", "directs", false, false], [20, 21, 6, 18, "role", "acts_in", false, false], [23, 27, 6, 18, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["On", "23", "June", "2008", ",", "The", "Butler", "'s", "in", "Love", ",", "a", "short", "film", "directed", "by", "David", "Arquette", "and", "starring", "Elizabeth", "Berkeley", "and", "Thomas", "Jane", ",", "was", "released", "."], "sentence-detokenized": "On 23 June 2008, The Butler's in Love, a short film directed by David Arquette and starring Elizabeth Berkeley and Thomas Jane, was released.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 15], [15, 16], [17, 20], [21, 27], [27, 29], [30, 32], [33, 37], [37, 38], [39, 40], [41, 46], [47, 51], [52, 60], [61, 63], [64, 69], [70, 78], [79, 82], [83, 91], [92, 101], [102, 110], [111, 114], [115, 121], [122, 126], [126, 127], [128, 131], [132, 140], [140, 141]]}
{"doc_key": "ai-dev-236", "ner": [[3, 4, "product"], [10, 12, "field"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 13, 13, "general-affiliation", "", false, false], [10, 12, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "Word", "Net", "is", "a", "resource", "that", "includes", "a", "taxonomy", "of", "English", "word", "meanings", "."], "sentence-detokenized": "For example, WordNet is a resource that includes a taxonomy of English word meanings.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [17, 20], [21, 23], [24, 25], [26, 34], [35, 39], [40, 48], [49, 50], [51, 59], [60, 62], [63, 70], [71, 75], [76, 84], [84, 85]]}
{"doc_key": "ai-dev-237", "ner": [[1, 5, "product"], [7, 7, "product"], [9, 9, "product"], [16, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 1, 5, "type-of", "", false, false], [7, 7, 16, 16, "related-to", "ability_to", false, false], [9, 9, 1, 5, "type-of", "", false, false], [9, 9, 16, 16, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Existing", "humanoid", "robot", "systems", ",", "such", "as", "ASIMO", "and", "QRIO", ",", "use", "multiple", "motors", "to", "achieve", "movement", "."], "sentence-detokenized": "Existing humanoid robot systems, such as ASIMO and QRIO, use multiple motors to achieve movement.", "token2charspan": [[0, 8], [9, 17], [18, 23], [24, 31], [31, 32], [33, 37], [38, 40], [41, 46], [47, 50], [51, 55], [55, 56], [57, 60], [61, 69], [70, 76], [77, 79], [80, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-dev-238", "ner": [[0, 0, "metrics"], [6, 7, "metrics"], [9, 9, "metrics"], [11, 15, "misc"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 7, 0, 0, "part-of", "", false, false], [9, 9, 0, 0, "part-of", "", false, false], [11, 15, 0, 0, "part-of", "", false, false], [17, 17, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "has", "been", "developed", "using", "improved", "length", "penalty", ",", "precision", ",", "n-", "gram", "word", "order", "penalty", "and", "recall", "factors", "."], "sentence-detokenized": "LEPOR has been developed using improved length penalty, precision, n-gram word order penalty and recall factors.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 24], [25, 30], [31, 39], [40, 46], [47, 54], [54, 55], [56, 65], [65, 66], [67, 69], [69, 73], [74, 78], [79, 84], [85, 92], [93, 96], [97, 103], [104, 111], [111, 112]]}
{"doc_key": "ai-dev-239", "ner": [[5, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "based", "on", "the", "metrics", "of", "the", "bilingual", "assessment", "doubles", ",", "but", "with", "some", "changes", "."], "sentence-detokenized": "It is based on the metrics of the bilingual assessment doubles, but with some changes.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 14], [15, 18], [19, 26], [27, 29], [30, 33], [34, 43], [44, 54], [55, 62], [62, 63], [64, 67], [68, 72], [73, 77], [78, 85], [85, 86]]}
{"doc_key": "ai-dev-240", "ner": [[6, 6, "product"], [8, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "implementation", "in", "MATLAB", "/", "Octave", ":"], "sentence-detokenized": "This is an example implementation in MATLAB / Octave:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 33], [34, 36], [37, 43], [44, 45], [46, 52], [52, 53]]}
{"doc_key": "ai-dev-241", "ner": [[11, 11, "programlang"], [13, 13, "programlang"], [15, 15, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "designed", "for", "use", "in", "several", "computer", "languages", ",", "including", "Python", ",", "Ruby", "and", "Scheme", "."], "sentence-detokenized": "It is designed for use in several computer languages, including Python, Ruby and Scheme.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 18], [19, 22], [23, 25], [26, 33], [34, 42], [43, 52], [52, 53], [54, 63], [64, 70], [70, 71], [72, 76], [77, 80], [81, 87], [87, 88]]}
{"doc_key": "ai-dev-242", "ner": [[0, 3, "researcher"], [6, 7, "organisation"], [12, 14, "conference"], [18, 19, "academicjournal"], [23, 26, "organisation"], [32, 36, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 6, 7, "role", "", false, false], [0, 3, 12, 14, "role", "", false, false], [0, 3, 18, 19, "role", "", false, false], [0, 3, 23, 26, "role", "", false, false], [0, 3, 32, 36, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "has", "served", "as", "Secretary", "of", "the", "AISB", ",", "Chair", "and", "Trustee", "of", "the", "IJCAI", ",", "Editor", "of", "Artificial", "Intelligence", ",", "President", "of", "the", "Cognitive", "Science", "Society", ",", "and", "President", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes has served as Secretary of the AISB, Chair and Trustee of the IJCAI, Editor of Artificial Intelligence, President of the Cognitive Science Society, and President of the American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 32], [33, 36], [37, 41], [41, 42], [43, 48], [49, 52], [53, 60], [61, 63], [64, 67], [68, 73], [73, 74], [75, 81], [82, 84], [85, 95], [96, 108], [108, 109], [110, 119], [120, 122], [123, 126], [127, 136], [137, 144], [145, 152], [152, 153], [154, 157], [158, 167], [168, 170], [171, 174], [175, 183], [184, 195], [196, 199], [200, 210], [211, 223], [223, 224]]}
{"doc_key": "ai-dev-243", "ner": [[4, 12, "misc"], [14, 16, "misc"], [21, 22, "person"], [25, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 22, 4, 12, "role", "directed_by", false, false], [21, 22, 14, 16, "role", "directed_by", false, false], [21, 22, 25, 29, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "of", "them", ",", "Now", "It", "'s", "Time", "to", "Put", "On", "Your", "Glasses", "and", "Around", "Is", "Around", ",", "were", "directed", "by", "Norman", "McLaren", "for", "the", "National", "Film", "Board", "of", "Canada", "in", "1951", "."], "sentence-detokenized": "Two of them, Now It's Time to Put On Your Glasses and Around Is Around, were directed by Norman McLaren for the National Film Board of Canada in 1951.", "token2charspan": [[0, 3], [4, 6], [7, 11], [11, 12], [13, 16], [17, 19], [19, 21], [22, 26], [27, 29], [30, 33], [34, 36], [37, 41], [42, 49], [50, 53], [54, 60], [61, 63], [64, 70], [70, 71], [72, 76], [77, 85], [86, 88], [89, 95], [96, 103], [104, 107], [108, 111], [112, 120], [121, 125], [126, 131], [132, 134], [135, 141], [142, 144], [145, 149], [149, 150]]}
{"doc_key": "ai-dev-244", "ner": [[0, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "purpose", "of", "a", "recommender", "system", "is", "to", "predict", "the", "target", "user", "'s", "preference", "for", "a", "product", "."], "sentence-detokenized": "The purpose of a recommender system is to predict the target user's preference for a product.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 16], [17, 28], [29, 35], [36, 38], [39, 41], [42, 49], [50, 53], [54, 60], [61, 65], [65, 67], [68, 78], [79, 82], [83, 84], [85, 92], [92, 93]]}
{"doc_key": "ai-dev-245", "ner": [[0, 0, "algorithm"], [4, 4, "field"], [6, 6, "field"], [8, 9, "field"], [11, 13, "field"], [15, 15, "field"], [17, 18, "field"], [20, 20, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 4, "part-of", "", true, false], [0, 0, 6, 6, "part-of", "", true, false], [0, 0, 8, 9, "part-of", "", true, false], [0, 0, 11, 13, "part-of", "", true, false], [0, 0, 15, 15, "part-of", "", true, false], [0, 0, 17, 18, "part-of", "", true, false], [0, 0, 20, 20, "part-of", "", true, false], [0, 0, 22, 23, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Convolution", "is", "used", "in", "probability", ",", "statistics", ",", "computer", "vision", ",", "natural", "language", "processing", ",", "image", "and", "signal", "processing", ",", "engineering", "and", "differential", "equations", "."], "sentence-detokenized": "Convolution is used in probability, statistics, computer vision, natural language processing, image and signal processing, engineering and differential equations.", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 22], [23, 34], [34, 35], [36, 46], [46, 47], [48, 56], [57, 63], [63, 64], [65, 72], [73, 81], [82, 92], [92, 93], [94, 99], [100, 103], [104, 110], [111, 121], [121, 122], [123, 134], [135, 138], [139, 151], [152, 161], [161, 162]]}
{"doc_key": "ai-dev-246", "ner": [[0, 0, "field"], [3, 5, "task"], [7, 8, "task"], [10, 10, "task"], [11, 11, "task"], [12, 12, "task"], [14, 15, "task"], [17, 18, "task"], [20, 21, "task"], [23, 23, "task"], [26, 27, "task"], [29, 29, "field"], [31, 31, "field"], [33, 35, "field"], [37, 37, "field"], [39, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[0, 0, 3, 5, "part-of", "", true, false], [0, 0, 7, 8, "part-of", "", true, false], [0, 0, 10, 10, "part-of", "", true, false], [0, 0, 11, 11, "part-of", "", true, false], [0, 0, 12, 12, "part-of", "", true, false], [0, 0, 14, 15, "part-of", "", true, false], [0, 0, 17, 18, "part-of", "", true, false], [0, 0, 20, 21, "part-of", "", true, false], [0, 0, 23, 23, "part-of", "", true, false], [0, 0, 26, 27, "part-of", "", true, false], [0, 0, 29, 29, "part-of", "", true, false], [0, 0, 31, 31, "part-of", "", true, false], [0, 0, 33, 35, "part-of", "", true, false], [0, 0, 37, 37, "part-of", "", true, false], [0, 0, 39, 39, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["DSP", "applications", "include", "audio", "signal", "processing", ",", "audio", "compression", ",", "digital", "image", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communication", ",", "digital", "synthesizers", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", "and", "biomedicine", "."], "sentence-detokenized": "DSP applications include audio signal processing, audio compression, digital image processing, video compression, speech processing, speech recognition, digital communication, digital synthesizers, radar, sonar, financial signal processing, seismology and biomedicine.", "token2charspan": [[0, 3], [4, 16], [17, 24], [25, 30], [31, 37], [38, 48], [48, 49], [50, 55], [56, 67], [67, 68], [69, 76], [77, 82], [83, 93], [93, 94], [95, 100], [101, 112], [112, 113], [114, 120], [121, 131], [131, 132], [133, 139], [140, 151], [151, 152], [153, 160], [161, 174], [174, 175], [176, 183], [184, 196], [196, 197], [198, 203], [203, 204], [205, 210], [210, 211], [212, 221], [222, 228], [229, 239], [239, 240], [241, 251], [252, 255], [256, 267], [267, 268]]}
{"doc_key": "ai-dev-247", "ner": [[11, 12, "misc"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "20", "February", "1912", "-", "11", "August", "2011", ")", "was", "an", "American", "inventor", ",", "best", "known", "for", "creating", "the", "first", "industrial", "robot", ",", "Unimate", "."], "sentence-detokenized": "(20 February 1912 - 11 August 2011) was an American inventor, best known for creating the first industrial robot, Unimate.", "token2charspan": [[0, 1], [1, 3], [4, 12], [13, 17], [18, 19], [20, 22], [23, 29], [30, 34], [34, 35], [36, 39], [40, 42], [43, 51], [52, 60], [60, 61], [62, 66], [67, 72], [73, 76], [77, 85], [86, 89], [90, 95], [96, 106], [107, 112], [112, 113], [114, 121], [121, 122]]}
{"doc_key": "ai-dev-248", "ner": [[1, 3, "researcher"], [5, 7, "researcher"], [9, 9, "researcher"], [21, 23, "algorithm"], [25, 27, "algorithm"], [37, 38, "task"], [40, 40, "algorithm"], [32, 33, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 3, 21, 23, "related-to", "writes_about", true, false], [5, 7, 21, 23, "related-to", "writes_about", true, false], [9, 9, 21, 23, "related-to", "writes_about", true, false], [21, 23, 25, 27, "related-to", "", true, false], [37, 38, 40, 40, "related-to", "", true, false], [32, 33, 40, 40, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["With", "David", "E.", "Rumelhart", "and", "Ronald", "J.", "Williams", ",", "Hinton", "co-authored", "a", "widely", "cited", "paper", "published", "in", "1986", "that", "popularized", "the", "backpropagation", "algorithm", "for", "training", "multilayer", "neural", "networks", ",", "his", "student", "Alex", "Krizhevsky", "'s", "dramatic", "breakthrough", "in", "image", "recognition", ",", "AlexNet", "{", "{{", "cite", "web"], "sentence-detokenized": "With David E. Rumelhart and Ronald J. Williams, Hinton co-authored a widely cited paper published in 1986 that popularized the backpropagation algorithm for training multilayer neural networks, his student Alex Krizhevsky's dramatic breakthrough in image recognition, AlexNet {{{cite web", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 34], [35, 37], [38, 46], [46, 47], [48, 54], [55, 66], [67, 68], [69, 75], [76, 81], [82, 87], [88, 97], [98, 100], [101, 105], [106, 110], [111, 122], [123, 126], [127, 142], [143, 152], [153, 156], [157, 165], [166, 176], [177, 183], [184, 192], [192, 193], [194, 197], [198, 205], [206, 210], [211, 221], [221, 223], [224, 232], [233, 245], [246, 248], [249, 254], [255, 266], [266, 267], [268, 275], [276, 277], [277, 279], [279, 283], [284, 287]]}
{"doc_key": "ai-dev-249", "ner": [[10, 12, "metrics"], [14, 17, "metrics"], [19, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "predicted", "value", "is", "uniformly", "distributed", ",", "the", "root", "mean", "square", "error", ",", "root", "mean", "square", "error", "or", "median", "absolute", "deviation", "can", "be", "used", "to", "summarise", "the", "errors", "."], "sentence-detokenized": "If the predicted value is uniformly distributed, the root mean square error, root mean square error or median absolute deviation can be used to summarise the errors.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 22], [23, 25], [26, 35], [36, 47], [47, 48], [49, 52], [53, 57], [58, 62], [63, 69], [70, 75], [75, 76], [77, 81], [82, 86], [87, 93], [94, 99], [100, 102], [103, 109], [110, 118], [119, 128], [129, 132], [133, 135], [136, 140], [141, 143], [144, 153], [154, 157], [158, 164], [164, 165]]}
{"doc_key": "ai-dev-250", "ner": [[0, 1, "algorithm"], [9, 10, "field"], [12, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 9, 10, "part-of", "", true, false], [0, 1, 12, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Conceptual", "clustering", "developed", "mainly", "in", "the", "1980s", "as", "a", "machine", "learning", "paradigm", "for", "unsupervised", "learning", "."], "sentence-detokenized": "Conceptual clustering developed mainly in the 1980s as a machine learning paradigm for unsupervised learning.", "token2charspan": [[0, 10], [11, 21], [22, 31], [32, 38], [39, 41], [42, 45], [46, 51], [52, 54], [55, 56], [57, 64], [65, 73], [74, 82], [83, 86], [87, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-dev-251", "ner": [[9, 11, "product"], [27, 27, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "named", "entities", "can", "not", "be", "recognised", "by", "the", "machine", "translator", ",", "they", "may", "be", "mistranslated", "as", "common", "nouns", ",", "which", "is", "unlikely", "to", "affect", "the", "bilingual", "assessment", "of", "the", "translation", ",", "but", "will", "change", "the", "readability", "of", "the", "text", "."], "sentence-detokenized": "If the named entities cannot be recognised by the machine translator, they may be mistranslated as common nouns, which is unlikely to affect the bilingual assessment of the translation, but will change the readability of the text.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 21], [22, 25], [25, 28], [29, 31], [32, 42], [43, 45], [46, 49], [50, 57], [58, 68], [68, 69], [70, 74], [75, 78], [79, 81], [82, 95], [96, 98], [99, 105], [106, 111], [111, 112], [113, 118], [119, 121], [122, 130], [131, 133], [134, 140], [141, 144], [145, 154], [155, 165], [166, 168], [169, 172], [173, 184], [184, 185], [186, 189], [190, 194], [195, 201], [202, 205], [206, 217], [218, 220], [221, 224], [225, 229], [229, 230]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 22, "location"], [24, 24, "country"], [33, 37, "researcher"], [40, 41, "researcher"], [43, 46, "university"], [48, 49, "researcher"], [51, 52, "researcher"], [54, 55, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 22, "physical", "", false, false], [20, 22, 24, 24, "physical", "", false, false], [40, 41, 43, 46, "physical", "", false, false], [40, 41, 43, 46, "role", "", false, false], [48, 49, 43, 46, "physical", "", false, false], [48, 49, 43, 46, "role", "", false, false], [51, 52, 43, 46, "physical", "", false, false], [51, 52, 43, 46, "role", "", false, false], [54, 55, 43, 46, "physical", "", false, false], [54, 55, 43, 46, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng", "-", "S\u00e4by", ",", "Sweden", ",", "pp.", "1-3.This", "model", ",", "partly", "influenced", "by", "Sydney", "Lamb", ",", "was", "widely", "used", "by", "Schank", "'s", "students", "at", "Yale", ",", "such", "as", "Robert", "Wilensky", ",", "Wendy", "Lehnert", "and", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, pp. 1-3.This model, partly influenced by Sydney Lamb, was widely used by Schank's students at Yale, such as Robert Wilensky, Wendy Lehnert and Janet Kolodner.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 130], [130, 131], [131, 135], [135, 136], [137, 143], [143, 144], [145, 148], [149, 157], [158, 163], [163, 164], [165, 171], [172, 182], [183, 185], [186, 192], [193, 197], [197, 198], [199, 202], [203, 209], [210, 214], [215, 217], [218, 224], [224, 226], [227, 235], [236, 238], [239, 243], [243, 244], [245, 249], [250, 252], [253, 259], [260, 268], [268, 269], [270, 275], [276, 283], [284, 287], [288, 293], [294, 302], [302, 303]]}
{"doc_key": "ai-dev-253", "ner": [[2, 4, "algorithm"], [6, 6, "algorithm"], [13, 13, "algorithm"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 2, 4, "named", "", false, false], [13, 13, 2, 4, "named", "", false, false], [15, 16, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Improved", "Maximum", "Likelihood", "Method", "(", "IMLM", ")", "is", "a", "combination", "of", "two", "MLM", "(", "Maximum", "Likelihood", ")", "estimators", "."], "sentence-detokenized": "The Improved Maximum Likelihood Method (IMLM) is a combination of two MLM (Maximum Likelihood) estimators.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 38], [39, 40], [40, 44], [44, 45], [46, 48], [49, 50], [51, 62], [63, 65], [66, 69], [70, 73], [74, 75], [75, 82], [83, 93], [93, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-254", "ner": [[16, 17, "metrics"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 21, 16, 17, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "methods", "can", "also", "analyse", "the", "output", "of", "a", "programme", "and", "its", "efficiency", ",", "so", "its", "mixing", "matrix", "(", "or", "mixing", "table", ")", "can", "be", "analysed", "."], "sentence-detokenized": "These methods can also analyse the output of a programme and its efficiency, so its mixing matrix (or mixing table) can be analysed.", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 22], [23, 30], [31, 34], [35, 41], [42, 44], [45, 46], [47, 56], [57, 60], [61, 64], [65, 75], [75, 76], [77, 79], [80, 83], [84, 90], [91, 97], [98, 99], [99, 101], [102, 108], [109, 114], [114, 115], [116, 119], [120, 122], [123, 131], [131, 132]]}
{"doc_key": "ai-dev-255", "ner": [[0, 0, "product"], [5, 6, "researcher"], [8, 9, "researcher"], [11, 14, "researcher"], [19, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 6, "origin", "", false, false], [0, 0, 8, 9, "origin", "", false, false], [0, 0, 11, 14, "origin", "", false, false], [0, 0, 19, 22, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "was", "first", "published", "by", "Herbert", "Bey", ",", "Tinne", "Tuytelaars", "and", "Luc", "Van", "Gool", "and", "presented", "at", "the", "2006", "European", "Computer", "Vision", "Conference", "."], "sentence-detokenized": "SURF was first published by Herbert Bey, Tinne Tuytelaars and Luc Van Gool and presented at the 2006 European Computer Vision Conference.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 39], [39, 40], [41, 46], [47, 57], [58, 61], [62, 65], [66, 69], [70, 74], [75, 78], [79, 88], [89, 91], [92, 95], [96, 100], [101, 109], [110, 118], [119, 125], [126, 136], [136, 137]]}
{"doc_key": "ai-dev-256", "ner": [[0, 0, "task"], [6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 7, "part-of", "", false, false], [0, 0, 9, 10, "part-of", "", false, false], [0, 0, 12, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "is", "a", "research", "area", "in", "pattern", "recognition", ",", "artificial", "intelligence", "and", "computer", "vision", "."], "sentence-detokenized": "OCR is a research area in pattern recognition, artificial intelligence and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 17], [18, 22], [23, 25], [26, 33], [34, 45], [45, 46], [47, 57], [58, 70], [71, 74], [75, 83], [84, 90], [90, 91]]}
{"doc_key": "ai-dev-257", "ner": [[4, 6, "metrics"], [10, 12, "algorithm"], [14, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 16, 10, 12, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Continuing", "the", "example", "using", "maximum", "likelihood", "estimation", ",", "the", "noise", "probability", "density", "function", "(", "pdf", ")", "for", "one", "sample", "mathwn", "/", "math", "is", "."], "sentence-detokenized": "Continuing the example using maximum likelihood estimation, the noise probability density function (pdf) for one sample mathwn/math is.", "token2charspan": [[0, 10], [11, 14], [15, 22], [23, 28], [29, 36], [37, 47], [48, 58], [58, 59], [60, 63], [64, 69], [70, 81], [82, 89], [90, 98], [99, 100], [100, 103], [103, 104], [105, 108], [109, 112], [113, 119], [120, 126], [126, 127], [127, 131], [132, 134], [134, 135]]}
{"doc_key": "ai-dev-258", "ner": [[2, 3, "field"], [5, 6, "task"], [8, 9, "task"], [11, 12, "task"], [14, 15, "task"], [17, 19, "task"], [21, 21, "task"], [23, 23, "task"], [25, 26, "task"], [28, 30, "task"], [32, 34, "task"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 6, 2, 3, "part-of", "", false, false], [8, 9, 2, 3, "part-of", "", false, false], [11, 12, 2, 3, "part-of", "", false, false], [14, 15, 2, 3, "part-of", "", false, false], [17, 19, 2, 3, "part-of", "", false, false], [21, 21, 2, 3, "part-of", "", false, false], [23, 23, 2, 3, "part-of", "", false, false], [25, 26, 2, 3, "part-of", "", false, false], [28, 30, 2, 3, "part-of", "", false, false], [32, 34, 2, 3, "part-of", "", false, false], [36, 37, 2, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Sub-areas", "of", "computer", "vision", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "3D", "pose", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "servo", "control", ",", "3D", "scene", "modelling", "and", "image", "restoration", "."], "sentence-detokenized": "Sub-areas of computer vision include scene reconstruction, event detection, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual servo control, 3D scene modelling and image restoration.", "token2charspan": [[0, 9], [10, 12], [13, 21], [22, 28], [29, 36], [37, 42], [43, 57], [57, 58], [59, 64], [65, 74], [74, 75], [76, 81], [82, 90], [90, 91], [92, 98], [99, 110], [110, 111], [112, 114], [115, 119], [120, 130], [130, 131], [132, 140], [140, 141], [142, 150], [150, 151], [152, 158], [159, 169], [169, 170], [171, 177], [178, 183], [184, 191], [191, 192], [193, 195], [196, 201], [202, 211], [212, 215], [216, 221], [222, 233], [233, 234]]}
{"doc_key": "ai-dev-259", "ner": [[10, 15, "conference"], [3, 3, "researcher"], [7, 9, "misc"], [17, 18, "conference"], [21, 21, "researcher"], [23, 23, "researcher"], [25, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 15, 17, 18, "named", "", false, false], [3, 3, 7, 9, "win-defeat", "", false, false], [3, 3, 25, 26, "related-to", "writes_about", true, false], [7, 9, 10, 15, "temporal", "", false, false], [21, 21, 7, 9, "win-defeat", "", false, true], [21, 21, 25, 26, "related-to", "writes_about", true, false], [23, 23, 7, 9, "win-defeat", "", false, true], [23, 23, 25, 26, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["In", "2013", ",", "Terzopoulos", "was", "awarded", "the", "Helmholtz", "Prize", "at", "the", "International", "Computer", "Vision", "Conference", "for", "his", "1987", "ICCV", "work", "with", "Kass", "and", "Witkin", "on", "active", "contour", "models", "."], "sentence-detokenized": "In 2013, Terzopoulos was awarded the Helmholtz Prize at the International Computer Vision Conference for his 1987 ICCV work with Kass and Witkin on active contour models.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 24], [25, 32], [33, 36], [37, 46], [47, 52], [53, 55], [56, 59], [60, 73], [74, 82], [83, 89], [90, 100], [101, 104], [105, 108], [109, 113], [114, 118], [119, 123], [124, 128], [129, 133], [134, 137], [138, 144], [145, 147], [148, 154], [155, 162], [163, 169], [169, 170]]}
{"doc_key": "ai-dev-260", "ner": [[15, 17, "task"], [19, 21, "algorithm"], [23, 24, "algorithm"], [26, 28, "algorithm"], [30, 31, "algorithm"], [33, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 17, 19, 21, "usage", "", true, false], [15, 17, 23, 24, "usage", "", true, false], [15, 17, 26, 28, "usage", "", true, false], [15, 17, 30, 31, "usage", "", true, false], [15, 17, 33, 33, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["If", "the", "regularisation", "function", "There", "are", "many", "algorithms", "to", "solve", "such", "problems", ";", "popular", "algorithms", "for", "linear", "classification", "are", "stochastic", "gradient", "descent", ",", "gradient", "descent", ",", "L", "-", "BFGS", ",", "coordinate", "descent", "and", "Newton", "methods", "."], "sentence-detokenized": "If the regularisation function There are many algorithms to solve such problems; popular algorithms for linear classification are stochastic gradient descent, gradient descent, L-BFGS, coordinate descent and Newton methods.", "token2charspan": [[0, 2], [3, 6], [7, 21], [22, 30], [31, 36], [37, 40], [41, 45], [46, 56], [57, 59], [60, 65], [66, 70], [71, 79], [79, 80], [81, 88], [89, 99], [100, 103], [104, 110], [111, 125], [126, 129], [130, 140], [141, 149], [150, 157], [157, 158], [159, 167], [168, 175], [175, 176], [177, 178], [178, 179], [179, 183], [183, 184], [185, 195], [196, 203], [204, 207], [208, 214], [215, 222], [222, 223]]}
{"doc_key": "ai-dev-261", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [13, 14, "researcher"], [16, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 13, 14, "origin", "", false, false], [5, 5, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "Short", "Term", "Memory", "(", "LSTM", ")", "networks", "were", "invented", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "and", "have", "achieved", "record", "accuracy", "in", "several", "application", "areas", "."], "sentence-detokenized": "Long Short Term Memory (LSTM) networks were invented in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber and have achieved record accuracy in several application areas.", "token2charspan": [[0, 4], [5, 10], [11, 15], [16, 22], [23, 24], [24, 28], [28, 29], [30, 38], [39, 43], [44, 52], [53, 55], [56, 60], [61, 63], [64, 68], [69, 79], [80, 83], [84, 90], [91, 102], [103, 106], [107, 111], [112, 120], [121, 127], [128, 136], [137, 139], [140, 147], [148, 159], [160, 165], [165, 166]]}
{"doc_key": "ai-dev-262", "ner": [[0, 0, "product"], [4, 9, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 9, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["TN", "was", "developed", "at", "Massachusetts", "General", "Hospital", "and", "tested", "in", "several", "scenarios", "including", "smoking", "status", ",", "family", "history", "of", "coronary", "artery", "disease", ",", "identifying", "patients", "with", "sleep", "disorders", ","], "sentence-detokenized": "TN was developed at Massachusetts General Hospital and tested in several scenarios including smoking status, family history of coronary artery disease, identifying patients with sleep disorders,", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 33], [34, 41], [42, 50], [51, 54], [55, 61], [62, 64], [65, 72], [73, 82], [83, 92], [93, 100], [101, 107], [107, 108], [109, 115], [116, 123], [124, 126], [127, 135], [136, 142], [143, 150], [150, 151], [152, 163], [164, 172], [173, 177], [178, 183], [184, 193], [193, 194]]}
{"doc_key": "ai-dev-263", "ner": [[3, 3, "researcher"], [8, 8, "product"], [15, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 8, "role", "sells", false, false], [8, 8, 15, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 86], [87, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-dev-264", "ner": [[0, 2, "conference"], [12, 15, "location"], [16, 16, "location"], [18, 18, "country"], [32, 34, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 12, 15, "physical", "", false, false], [12, 15, 16, 16, "physical", "", false, false], [16, 16, 18, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Campus", "Party", "Europe", "took", "place", "from", "14", "-", "18", "April", "2010", "at", "the", "Caja", "M\u00e1gica", "in", "Madrid", ",", "Spain", ",", "and", "was", "attended", "by", "800", "participants", "from", "all", "27", "Member", "States", "of", "the", "European", "Union", "."], "sentence-detokenized": "Campus Party Europe took place from 14-18 April 2010 at the Caja M\u00e1gica in Madrid, Spain, and was attended by 800 participants from all 27 Member States of the European Union.", "token2charspan": [[0, 6], [7, 12], [13, 19], [20, 24], [25, 30], [31, 35], [36, 38], [38, 39], [39, 41], [42, 47], [48, 52], [53, 55], [56, 59], [60, 64], [65, 71], [72, 74], [75, 81], [81, 82], [83, 88], [88, 89], [90, 93], [94, 97], [98, 106], [107, 109], [110, 113], [114, 126], [127, 131], [132, 135], [136, 138], [139, 145], [146, 152], [153, 155], [156, 159], [160, 168], [169, 174], [174, 175]]}
{"doc_key": "ai-dev-265", "ner": [[7, 7, "organisation"], [9, 12, "organisation"], [14, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 17, 7, 7, "origin", "", false, false], [14, 17, 9, 12, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2016", ",", "a", "collaboration", "between", "DeepMind", "and", "Moorfields", "Eye", "Hospital", "to", "develop", "AI", "applications", "for", "healthcare", "was", "announced", "."], "sentence-detokenized": "In July 2016, a collaboration between DeepMind and Moorfields Eye Hospital to develop AI applications for healthcare was announced.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 15], [16, 29], [30, 37], [38, 46], [47, 50], [51, 61], [62, 65], [66, 74], [75, 77], [78, 85], [86, 88], [89, 101], [102, 105], [106, 116], [117, 120], [121, 130], [130, 131]]}
{"doc_key": "ai-dev-266", "ner": [[5, 5, "misc"], [13, 14, "university"], [16, 16, "university"], [18, 19, "university"], [21, 22, "university"], [24, 24, "university"], [26, 26, "university"], [27, 32, "university"], [34, 39, "university"], [40, 40, "university"], [42, 42, "university"], [45, 47, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 5, 13, 14, "physical", "", false, false], [5, 5, 16, 16, "physical", "", false, false], [5, 5, 18, 19, "physical", "", false, false], [5, 5, 21, 22, "physical", "", false, false], [5, 5, 24, 24, "physical", "", false, false], [5, 5, 26, 26, "physical", "", false, false], [5, 5, 27, 32, "physical", "", false, false], [5, 5, 34, 39, "physical", "", false, false], [5, 5, 40, 40, "physical", "", false, false], [5, 5, 42, 42, "physical", "", false, false], [5, 5, 45, 47, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["As", "a", "result", ",", "eleven", "PR2s", "were", "awarded", "to", "different", "institutions", ",", "including", "Freiburg", "University", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", "University", ",", "Technical", "University", "of", "Munich", ",", "University", "of", "Berkeley", ",", "University", "of", "Pennsylvania", ",", "USC", "and", "the", "University", "of", "Tokyo", "."], "sentence-detokenized": "As a result, eleven PR2s were awarded to different institutions, including Freiburg University, Bosch, Georgia Tech, KU Leuven, MIT, Stanford University, Technical University of Munich, University of Berkeley, University of Pennsylvania, USC and the University of Tokyo.", "token2charspan": [[0, 2], [3, 4], [5, 11], [11, 12], [13, 19], [20, 24], [25, 29], [30, 37], [38, 40], [41, 50], [51, 63], [63, 64], [65, 74], [75, 83], [84, 94], [94, 95], [96, 101], [101, 102], [103, 110], [111, 115], [115, 116], [117, 119], [120, 126], [126, 127], [128, 131], [131, 132], [133, 141], [142, 152], [152, 153], [154, 163], [164, 174], [175, 177], [178, 184], [184, 185], [186, 196], [197, 199], [200, 208], [208, 209], [210, 220], [221, 223], [224, 236], [236, 237], [238, 241], [242, 245], [246, 249], [250, 260], [261, 263], [264, 269], [269, 270]]}
{"doc_key": "ai-dev-267", "ner": [[0, 1, "metrics"], [3, 3, "metrics"], [5, 5, "metrics"], [7, 7, "metrics"], [17, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 17, 18, "part-of", "", false, false], [3, 3, 17, 18, "part-of", "", false, false], [5, 5, 17, 18, "part-of", "", false, false], [7, 7, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "TP", ",", "TN", ",", "FP", "and", "FN", "numbers", "are", "usually", "stored", "in", "a", "table", "called", "a", "mixing", "matrix", "."], "sentence-detokenized": "The TP, TN, FP and FN numbers are usually stored in a table called a mixing matrix.", "token2charspan": [[0, 3], [4, 6], [6, 7], [8, 10], [10, 11], [12, 14], [15, 18], [19, 21], [22, 29], [30, 33], [34, 41], [42, 48], [49, 51], [52, 53], [54, 59], [60, 66], [67, 68], [69, 75], [76, 82], [82, 83]]}
{"doc_key": "ai-dev-268", "ner": [[8, 9, "metrics"], [13, 13, "metrics"], [12, 17, "metrics"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "set", "of", "features", "usually", "used", "is", "the", "information", "gain", ",", "the", "mutual", "entropy", ",", "the", "mutual", "information", "and", "the", "odds", "ratio", "."], "sentence-detokenized": "The set of features usually used is the information gain, the mutual entropy, the mutual information and the odds ratio.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 19], [20, 27], [28, 32], [33, 35], [36, 39], [40, 51], [52, 56], [56, 57], [58, 61], [62, 68], [69, 76], [76, 77], [78, 81], [82, 88], [89, 100], [101, 104], [105, 108], [109, 113], [114, 119], [119, 120]]}
{"doc_key": "ai-dev-269", "ner": [[11, 12, "task"], [14, 15, "task"], [17, 17, "task"], [19, 19, "task"], [21, 21, "task"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[23, 23, 21, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "successfully", "applied", "to", "a", "variety", "of", "problems", "including", "robot", "control", ",", "lift", "planning", ",", "telecommunications", ",", "checkers", "and", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "It has been successfully applied to a variety of problems including robot control, lift planning, telecommunications, checkers and Go (AlphaGo).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 32], [33, 35], [36, 37], [38, 45], [46, 48], [49, 57], [58, 67], [68, 73], [74, 81], [81, 82], [83, 87], [88, 96], [96, 97], [98, 116], [116, 117], [118, 126], [127, 130], [131, 133], [134, 135], [135, 142], [142, 143], [143, 144]]}
{"doc_key": "ai-dev-270", "ner": [[12, 15, "misc"], [16, 19, "university"], [21, 22, "location"], [24, 24, "location"], [28, 31, "location"], [34, 36, "location"], [37, 38, "location"], [40, 40, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[12, 15, 16, 19, "physical", "", false, false], [16, 19, 21, 22, "physical", "", false, false], [21, 22, 24, 24, "physical", "", false, false], [28, 31, 34, 36, "physical", "", false, false], [34, 36, 37, 38, "physical", "", false, false], [37, 38, 40, 40, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "the", "inaugural", "year", "of", "the", "8th", "Mission", ",", "the", "Americas", "venue", "was", "the", "Georgia", "Institute", "of", "Technology", "campus", "in", "Atlanta", ",", "Georgia", ",", "and", "the", "Asia", "/", "Pacific", "venue", "was", "the", "Beihang", "University", "Gymnasium", "in", "Beijing", ",", "China", "."], "sentence-detokenized": "In 2018, the inaugural year of the 8th Mission, the Americas venue was the Georgia Institute of Technology campus in Atlanta, Georgia, and the Asia/Pacific venue was the Beihang University Gymnasium in Beijing, China.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 34], [35, 38], [39, 46], [46, 47], [48, 51], [52, 60], [61, 66], [67, 70], [71, 74], [75, 82], [83, 92], [93, 95], [96, 106], [107, 113], [114, 116], [117, 124], [124, 125], [126, 133], [133, 134], [135, 138], [139, 142], [143, 147], [147, 148], [148, 155], [156, 161], [162, 165], [166, 169], [170, 177], [178, 188], [189, 198], [199, 201], [202, 209], [209, 210], [211, 216], [216, 217]]}
{"doc_key": "ai-dev-271", "ner": [[0, 1, "field"], [6, 7, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "origin", "", false, false], [0, 1, 6, 7, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "is", "closely", "linked", "to", "pattern", "recognition", "and", "is", "based", "on", "artificial", "intelligence", "."], "sentence-detokenized": "Machine learning is closely linked to pattern recognition and is based on artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 34], [35, 37], [38, 45], [46, 57], [58, 61], [62, 64], [65, 70], [71, 73], [74, 84], [85, 97], [97, 98]]}
{"doc_key": "ai-dev-272", "ner": [[3, 3, "programlang"], [11, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "includes", "3", "Java", "games", "controlled", "by", "remote", "control", "and", "displayed", "on", "the", "LCD", "screen", "."], "sentence-detokenized": "It includes 3 Java games controlled by remote control and displayed on the LCD screen.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 18], [19, 24], [25, 35], [36, 38], [39, 45], [46, 53], [54, 57], [58, 67], [68, 70], [71, 74], [75, 78], [79, 85], [85, 86]]}
{"doc_key": "ai-dev-273", "ner": [[14, 18, "task"], [0, 2, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 14, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Optical", "motion", "sensing", "is", "a", "commercially", "successful", "but", "specialised", "computer", "vision", "-", "based", "method", "for", "assessing", "joi", "nt", "posture", "."], "sentence-detokenized": "Optical motion sensing is a commercially successful but specialised computer vision-based method for assessing joint posture.", "token2charspan": [[0, 7], [8, 14], [15, 22], [23, 25], [26, 27], [28, 40], [41, 51], [52, 55], [56, 67], [68, 76], [77, 83], [83, 84], [84, 89], [90, 96], [97, 100], [101, 110], [111, 114], [114, 116], [117, 124], [124, 125]]}
{"doc_key": "ai-dev-274", "ner": [[0, 1, "organisation"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SMC", "is", "very", "similar", "to", "the", "most", "popular", "Jaccard", "index", "."], "sentence-detokenized": "The SMC is very similar to the most popular Jaccard index.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 23], [24, 26], [27, 30], [31, 35], [36, 43], [44, 51], [52, 57], [57, 58]]}
{"doc_key": "ai-dev-275", "ner": [[0, 0, "product"], [2, 6, "product"], [8, 11, "product"], [20, 23, "researcher"], [28, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 11, "named", "", false, false], [0, 0, 20, 23, "artifact", "", false, false], [0, 0, 28, 28, "artifact", "", false, false], [2, 6, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", "or", "Programmable", "Universal", "Manipulation", "Arm", ")", "is", "an", "industrial", "robotic", "arm", "developed", "by", "Victor", "Scheinman", ",", "a", "pioneer", "in", "robotics", "at", "Unimation", "."], "sentence-detokenized": "PUMA (Programmable Universal Machine for Assembly or Programmable Universal Manipulation Arm) is an industrial robotic arm developed by Victor Scheinman, a pioneer in robotics at Unimation.", "token2charspan": [[0, 4], [5, 6], [6, 18], [19, 28], [29, 36], [37, 40], [41, 49], [50, 52], [53, 65], [66, 75], [76, 88], [89, 92], [92, 93], [94, 96], [97, 99], [100, 110], [111, 118], [119, 122], [123, 132], [133, 135], [136, 142], [143, 152], [152, 153], [154, 155], [156, 163], [164, 166], [167, 175], [176, 178], [179, 188], [188, 189]]}
{"doc_key": "ai-dev-276", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "written", "in", "Python", "."], "sentence-detokenized": "It is written in Python.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 23], [23, 24]]}
{"doc_key": "ai-dev-277", "ner": [[0, 0, "misc"], [1, 2, "misc"], [12, 12, "field"], [14, 15, "field"], [17, 17, "field"], [23, 24, "field"], [26, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7], "relations": [[0, 0, 1, 2, "related-to", "metric_for", true, false], [0, 0, 12, 12, "part-of", "", false, false], [0, 0, 14, 15, "part-of", "", false, false], [0, 0, 17, 17, "part-of", "", false, false], [0, 0, 23, 24, "part-of", "", false, false], [0, 0, 26, 31, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6], "sentence": ["Bandwidth", "in", "hertz", "is", "a", "key", "concept", "in", "many", "fields", ",", "including", "electronics", ",", "information", "theory", ",", "digital", "communications", ",", "radio", "communications", ",", "signal", "processing", "and", "spectroscopy", ",", "and", "is", "one", "of", "the", "factors", "that", "determine", "the", "capacity", "of", "a", "particular", "communication", "channel", "."], "sentence-detokenized": "Bandwidth in hertz is a key concept in many fields, including electronics, information theory, digital communications, radio communications, signal processing and spectroscopy, and is one of the factors that determine the capacity of a particular communication channel.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 21], [22, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 50], [50, 51], [52, 61], [62, 73], [73, 74], [75, 86], [87, 93], [93, 94], [95, 102], [103, 117], [117, 118], [119, 124], [125, 139], [139, 140], [141, 147], [148, 158], [159, 162], [163, 175], [175, 176], [177, 180], [181, 183], [184, 187], [188, 190], [191, 194], [195, 202], [203, 207], [208, 217], [218, 221], [222, 230], [231, 233], [234, 235], [236, 246], [247, 260], [261, 268], [268, 269]]}
{"doc_key": "ai-dev-278", "ner": [[8, 8, "algorithm"], [10, 10, "algorithm"], [16, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 16, 19, "part-of", "", false, false], [10, 10, 16, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "convex", "losses", "are", "used", "(", "as", "in", "AdaBoost", ",", "LogitBoost", "and", "all", "members", "of", "the", "AnyBoost", "family", "of", "algorithms", ")", ",", "then", "the", "example", "with", "the", "larger", "margin", "will", "receive", "less", "(", "or", "equal", ")", "weight", "than", "the", "example", "with", "the", "smaller", "margin", "."], "sentence-detokenized": "If convex losses are used (as in AdaBoost, LogitBoost and all members of the AnyBoost family of algorithms), then the example with the larger margin will receive less (or equal) weight than the example with the smaller margin.", "token2charspan": [[0, 2], [3, 9], [10, 16], [17, 20], [21, 25], [26, 27], [27, 29], [30, 32], [33, 41], [41, 42], [43, 53], [54, 57], [58, 61], [62, 69], [70, 72], [73, 76], [77, 85], [86, 92], [93, 95], [96, 106], [106, 107], [107, 108], [109, 113], [114, 117], [118, 125], [126, 130], [131, 134], [135, 141], [142, 148], [149, 153], [154, 161], [162, 166], [167, 168], [168, 170], [171, 176], [176, 177], [178, 184], [185, 189], [190, 193], [194, 201], [202, 206], [207, 210], [211, 218], [219, 225], [225, 226]]}
{"doc_key": "ai-dev-279", "ner": [[0, 6, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 6, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sepp", "Hochreiter", "'s", "1991", "diploma", "thesis", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Sepp Hochreiter's 1991 diploma thesis Sepp Hochreiter.", "token2charspan": [[0, 4], [5, 15], [15, 17], [18, 22], [23, 30], [31, 37], [38, 42], [43, 53], [53, 54]]}
{"doc_key": "ai-dev-280", "ner": [[4, 5, "algorithm"], [7, 7, "algorithm"], [10, 11, "algorithm"], [14, 14, "algorithm"], [17, 19, "algorithm"], [21, 24, "algorithm"], [26, 28, "algorithm"], [31, 32, "algorithm"], [34, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 7, 4, 5, "named", "", false, false], [14, 14, 10, 11, "named", "", false, false], [17, 19, 26, 28, "related-to", "", true, false], [21, 24, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Typical", "discriminative", "models", "include", "logistic", "regression", "(", "LR", ")", ",", "support", "vector", "machines", "(", "SVM", ")", ",", "conditional", "random", "fields", "(", "CRF", ")", "(", "specified", "over", "an", "undirected", "graph", ")", ",", "decision", "trees", ",", "neural", "networks", "and", "many", "others", "."], "sentence-detokenized": "Typical discriminative models include logistic regression (LR), support vector machines (SVM), conditional random fields (CRF) (specified over an undirected graph), decision trees, neural networks and many others.", "token2charspan": [[0, 7], [8, 22], [23, 29], [30, 37], [38, 46], [47, 57], [58, 59], [59, 61], [61, 62], [62, 63], [64, 71], [72, 78], [79, 87], [88, 89], [89, 92], [92, 93], [93, 94], [95, 106], [107, 113], [114, 120], [121, 122], [122, 125], [125, 126], [127, 128], [128, 137], [138, 142], [143, 145], [146, 156], [157, 162], [162, 163], [163, 164], [165, 173], [174, 179], [179, 180], [181, 187], [188, 196], [197, 200], [201, 205], [206, 212], [212, 213]]}
{"doc_key": "ai-dev-281", "ner": [[12, 14, "metrics"], [35, 37, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "then", "also", "possible", "to", "use", "these", "probabilities", "and", "estimate", "the", "mean", "squared", "error", "(", "or", "some", "other", "similar", "measure", ")", "between", "the", "probabilities", "and", "the", "actual", "values", ",", "then", "combine", "this", "with", "a", "mixing", "matrix", "to", "produce", "very", "efficient", "matching", "functions", "for", "logistic", "regression", "."], "sentence-detokenized": "It is then also possible to use these probabilities and estimate the mean squared error (or some other similar measure) between the probabilities and the actual values, then combine this with a mixing matrix to produce very efficient matching functions for logistic regression.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 15], [16, 24], [25, 27], [28, 31], [32, 37], [38, 51], [52, 55], [56, 64], [65, 68], [69, 73], [74, 81], [82, 87], [88, 89], [89, 91], [92, 96], [97, 102], [103, 110], [111, 118], [118, 119], [120, 127], [128, 131], [132, 145], [146, 149], [150, 153], [154, 160], [161, 167], [167, 168], [169, 173], [174, 181], [182, 186], [187, 191], [192, 193], [194, 200], [201, 207], [208, 210], [211, 218], [219, 223], [224, 233], [234, 242], [243, 252], [253, 256], [257, 265], [266, 276], [276, 277]]}
{"doc_key": "ai-dev-282", "ner": [[0, 1, "product"], [7, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 7, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "was", "first", "introduced", "in", "2005", "on", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "."], "sentence-detokenized": "VoiceOver was first introduced in 2005 on Mac OS X Tiger (10.4).", "token2charspan": [[0, 9], [10, 13], [14, 19], [20, 30], [31, 33], [34, 38], [39, 41], [42, 45], [46, 48], [49, 50], [51, 56], [57, 58], [58, 62], [62, 63], [63, 64]]}
{"doc_key": "ai-dev-283", "ner": [[13, 16, "algorithm"], [20, 21, "misc"], [27, 30, "metrics"], [24, 26, "algorithm"], [57, 62, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 16, 20, 21, "related-to", "applied_to", false, false], [27, 30, 20, 21, "type-of", "", false, false], [27, 30, 24, 26, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "practice", ",", "machine", "learning", "algorithms", "deal", "with", "this", "either", "by", "using", "a", "convex", "approximation", "of", "the", "0", "-", "1", "loss", "function", "(", "e.g.", "support", "vector", "machine", "loss", ")", ",", "which", "is", "easier", "to", "optimise", ",", "or", "by", "imposing", "assumptions", "on", "the", "distribution", "mathP", "(", "x", ",", "y", ")", "/", "math", "(", "and", "thus", "ceasing", "to", "be", "agnostic", "learning", "algorithms", "subject", "to", "the", "above", "result", ")", "."], "sentence-detokenized": "In practice, machine learning algorithms deal with this either by using a convex approximation of the 0-1 loss function (e.g. support vector machine loss), which is easier to optimise, or by imposing assumptions on the distribution mathP (x, y) / math (and thus ceasing to be agnostic learning algorithms subject to the above result).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 29], [30, 40], [41, 45], [46, 50], [51, 55], [56, 62], [63, 65], [66, 71], [72, 73], [74, 80], [81, 94], [95, 97], [98, 101], [102, 103], [103, 104], [104, 105], [106, 110], [111, 119], [120, 121], [121, 125], [126, 133], [134, 140], [141, 148], [149, 153], [153, 154], [154, 155], [156, 161], [162, 164], [165, 171], [172, 174], [175, 183], [183, 184], [185, 187], [188, 190], [191, 199], [200, 211], [212, 214], [215, 218], [219, 231], [232, 237], [238, 239], [239, 240], [240, 241], [242, 243], [243, 244], [245, 246], [247, 251], [252, 253], [253, 256], [257, 261], [262, 269], [270, 272], [273, 275], [276, 284], [285, 293], [294, 304], [305, 312], [313, 315], [316, 319], [320, 325], [326, 332], [332, 333], [333, 334]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [13, 15, "field"], [20, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 13, 15, "usage", "", false, false], [0, 0, 20, 21, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Westworld", "(", "1973", ")", "was", "the", "first", "feature", "-", "length", "film", "to", "use", "digital", "image", "processing", "in", "photography", "to", "simulate", "an", "android", "point", "of", "view", "."], "sentence-detokenized": "Westworld (1973) was the first feature-length film to use digital image processing in photography to simulate an android point of view.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 20], [21, 24], [25, 30], [31, 38], [38, 39], [39, 45], [46, 50], [51, 53], [54, 57], [58, 65], [66, 71], [72, 82], [83, 85], [86, 97], [98, 100], [101, 109], [110, 112], [113, 120], [121, 126], [127, 129], [130, 134], [134, 135]]}
{"doc_key": "ai-dev-285", "ner": [[7, 8, "task"], [10, 11, "task"], [13, 13, "task"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "now", "also", "widely", "used", "in", "speech", "recognition", ",", "speech", "synthesis", ",", "diarisation", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "It is now also widely used in speech recognition, speech synthesis, diarisation, Xavier Anguera et al.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 14], [15, 21], [22, 26], [27, 29], [30, 36], [37, 48], [48, 49], [50, 56], [57, 66], [66, 67], [68, 79], [79, 80], [81, 87], [88, 95], [96, 98], [99, 101], [101, 102]]}
{"doc_key": "ai-dev-286", "ner": [[11, 13, "algorithm"], [16, 17, "algorithm"], [20, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 17, 11, 13, "type-of", "", false, false], [20, 22, 11, 13, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "case", ",", "math", "/", "sigma", "/", "math", "is", "an", "activation", "function", "such", "as", "a", "sigmoidal", "function", "or", "a", "rectified", "linear", "unit", "."], "sentence-detokenized": "In this case, math/sigma/math is an activation function such as a sigmoidal function or a rectified linear unit.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 18], [18, 19], [19, 24], [24, 25], [25, 29], [30, 32], [33, 35], [36, 46], [47, 55], [56, 60], [61, 63], [64, 65], [66, 75], [76, 84], [85, 87], [88, 89], [90, 99], [100, 106], [107, 111], [111, 112]]}
{"doc_key": "ai-dev-287", "ner": [[6, 10, "algorithm"], [19, 19, "misc"], [21, 21, "misc"], [23, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "phonetic", "-", "based", "(", "i.e.", "Hidden", "Markov", "Model", "-", "based", ")", "approaches", "require", "separate", "components", "and", "training", "for", "pronunciation", ",", "acoustic", "and", "language", "models", "."], "sentence-detokenized": "Traditional phonetic-based (i.e. Hidden Markov Model-based) approaches require separate components and training for pronunciation, acoustic and language models.", "token2charspan": [[0, 11], [12, 20], [20, 21], [21, 26], [27, 28], [28, 32], [33, 39], [40, 46], [47, 52], [52, 53], [53, 58], [58, 59], [60, 70], [71, 78], [79, 87], [88, 98], [99, 102], [103, 111], [112, 115], [116, 129], [129, 130], [131, 139], [140, 143], [144, 152], [153, 159], [159, 160]]}
{"doc_key": "ai-dev-288", "ner": [[0, 3, "algorithm"], [7, 8, "field"], [10, 11, "field"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 13, 14, "related-to", "used_for", false, false], [7, 8, 0, 3, "usage", "", false, false], [10, 11, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Roberts", "cross", "operator", "is", "used", "in", "image", "processing", "and", "computer", "vision", "to", "define", "edges", "."], "sentence-detokenized": "The Roberts cross operator is used in image processing and computer vision to define edges.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 37], [38, 43], [44, 54], [55, 58], [59, 67], [68, 74], [75, 77], [78, 84], [85, 90], [90, 91]]}
{"doc_key": "ai-dev-289", "ner": [[0, 0, "metrics"], [2, 2, "metrics"], [23, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 23, 23, "opposite", "", false, false], [2, 2, 23, 23, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Sensitivity", "and", "specificity", "values", "depend", "on", "the", "percentage", "of", "positive", "cases", "in", "the", "study", "population", "(", "as", "opposed", "to", ",", "for", "example", ",", "accuracy", ")", "."], "sentence-detokenized": "Sensitivity and specificity values depend on the percentage of positive cases in the study population (as opposed to, for example, accuracy).", "token2charspan": [[0, 11], [12, 15], [16, 27], [28, 34], [35, 41], [42, 44], [45, 48], [49, 59], [60, 62], [63, 71], [72, 77], [78, 80], [81, 84], [85, 90], [91, 101], [102, 103], [103, 105], [106, 113], [114, 116], [116, 117], [118, 121], [122, 129], [129, 130], [131, 139], [139, 140], [140, 141]]}
{"doc_key": "ai-dev-290", "ner": [[1, 2, "algorithm"], [17, 17, "misc"], [8, 9, "researcher"], [11, 13, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 17, 1, 2, "topic", "", false, false], [17, 17, 8, 9, "artifact", "", false, false], [17, 17, 11, 13, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["But", "perceptron", "models", "were", "made", "very", "unpopular", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "'s", "1969", "book", "\"", "Perceptrons", "\"", "."], "sentence-detokenized": "But perceptron models were made very unpopular by Marvin Minsky and Seymour Papert's 1969 book \"Perceptrons\".", "token2charspan": [[0, 3], [4, 14], [15, 21], [22, 26], [27, 31], [32, 36], [37, 46], [47, 49], [50, 56], [57, 63], [64, 67], [68, 75], [76, 82], [82, 84], [85, 89], [90, 94], [95, 96], [96, 107], [107, 108], [108, 109]]}
{"doc_key": "ai-dev-291", "ner": [[0, 7, "conference"], [8, 8, "organisation"], [23, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 7, 23, 25, "topic", "", false, false], [8, 8, 0, 7, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Document", "Understanding", "Conferences", ",", "held", "annually", "by", "NIST", ",", "have", "developed", "sophisticated", "evaluation", "criteria", "for", "methods", "that", "take", "on", "the", "task", "of", "aggregating", "many", "documents", "."], "sentence-detokenized": "The Document Understanding Conferences, held annually by NIST, have developed sophisticated evaluation criteria for methods that take on the task of aggregating many documents.", "token2charspan": [[0, 3], [4, 12], [13, 26], [27, 38], [38, 39], [40, 44], [45, 53], [54, 56], [57, 61], [61, 62], [63, 67], [68, 77], [78, 91], [92, 102], [103, 111], [112, 115], [116, 123], [124, 128], [129, 133], [134, 136], [137, 140], [141, 145], [146, 148], [149, 160], [161, 165], [166, 175], [175, 176]]}
{"doc_key": "ai-dev-292", "ner": [[0, 2, "product"], [24, 26, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 24, 26, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "parallel", "manipulator", "is", "designed", "so", "that", "each", "circuit", "is", "usually", "short", ",", "simple", "and", "can", "therefore", "be", "robust", "against", "unwanted", "movement", "compared", "to", "a", "serial", "manipulator", "."], "sentence-detokenized": "The parallel manipulator is designed so that each circuit is usually short, simple and can therefore be robust against unwanted movement compared to a serial manipulator.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 27], [28, 36], [37, 39], [40, 44], [45, 49], [50, 57], [58, 60], [61, 68], [69, 74], [74, 75], [76, 82], [83, 86], [87, 90], [91, 100], [101, 103], [104, 110], [111, 118], [119, 127], [128, 136], [137, 145], [146, 148], [149, 150], [151, 157], [158, 169], [169, 170]]}
{"doc_key": "ai-dev-293", "ner": [[25, 25, "misc"], [27, 31, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "manipulator", "is", "what", "makes", "the", "robot", "move", ",", "and", "the", "design", "of", "these", "systems", "can", "be", "divided", "into", "several", "common", "types", ",", "such", "as", "SCARA", "and", "Cartesian", "coordinate", "robots", ",", "which", "use", "different", "coordinate", "systems", "to", "control", "the", "machine", "'s", "arms", "."], "sentence-detokenized": "The manipulator is what makes the robot move, and the design of these systems can be divided into several common types, such as SCARA and Cartesian coordinate robots, which use different coordinate systems to control the machine's arms.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 23], [24, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 49], [50, 53], [54, 60], [61, 63], [64, 69], [70, 77], [78, 81], [82, 84], [85, 92], [93, 97], [98, 105], [106, 112], [113, 118], [118, 119], [120, 124], [125, 127], [128, 133], [134, 137], [138, 147], [148, 158], [159, 165], [165, 166], [167, 172], [173, 176], [177, 186], [187, 197], [198, 205], [206, 208], [209, 216], [217, 220], [221, 228], [228, 230], [231, 235], [235, 236]]}
{"doc_key": "ai-dev-294", "ner": [[0, 3, "country"], [11, 14, "organisation"], [17, 24, "organisation"], [25, 28, "organisation"], [31, 33, "organisation"], [36, 42, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 14, 0, 3, "physical", "", false, false], [17, 24, 0, 3, "physical", "", false, false], [25, 28, 0, 3, "physical", "", false, false], [31, 33, 0, 3, "physical", "", false, false], [36, 42, 0, 3, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "United", "States", ",", "he", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "Linguistic", "Society", "of", "America", ",", "the", "American", "Philosophical", "Association", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In the United States, he is a member of the National Academy of Sciences, the American Academy of Arts and Sciences, the Linguistic Society of America, the American Philosophical Association and the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 20], [20, 21], [22, 24], [25, 27], [28, 29], [30, 36], [37, 39], [40, 43], [44, 52], [53, 60], [61, 63], [64, 72], [72, 73], [74, 77], [78, 86], [87, 94], [95, 97], [98, 102], [103, 106], [107, 115], [115, 116], [117, 120], [121, 131], [132, 139], [140, 142], [143, 150], [150, 151], [152, 155], [156, 164], [165, 178], [179, 190], [191, 194], [195, 198], [199, 207], [208, 219], [220, 223], [224, 227], [228, 239], [240, 242], [243, 250], [250, 251]]}
{"doc_key": "ai-dev-295", "ner": [[8, 10, "algorithm"], [12, 12, "algorithm"], [19, 19, "algorithm"], [26, 27, "algorithm"], [32, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 10, 19, 19, "named", "", false, false], [12, 12, 8, 10, "named", "", false, false], [19, 19, 26, 27, "compare", "", false, false], [19, 19, 32, 33, "related-to", "performs", false, false], [26, 27, 32, 33, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["They", "gained", "popularity", "with", "the", "rise", "of", "the", "support", "vector", "machine", "(", "SVM", ")", "in", "the", "1990s", ",", "when", "SVMs", "were", "found", "to", "be", "competitive", "with", "neural", "networks", "in", "tasks", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "They gained popularity with the rise of the support vector machine (SVM) in the 1990s, when SVMs were found to be competitive with neural networks in tasks such as handwriting recognition.", "token2charspan": [[0, 4], [5, 11], [12, 22], [23, 27], [28, 31], [32, 36], [37, 39], [40, 43], [44, 51], [52, 58], [59, 66], [67, 68], [68, 71], [71, 72], [73, 75], [76, 79], [80, 85], [85, 86], [87, 91], [92, 96], [97, 101], [102, 107], [108, 110], [111, 113], [114, 125], [126, 130], [131, 137], [138, 146], [147, 149], [150, 155], [156, 160], [161, 163], [164, 175], [176, 187], [187, 188]]}
{"doc_key": "ai-dev-296", "ner": [[2, 3, "misc"], [9, 11, "misc"], [13, 14, "algorithm"], [22, 25, "misc"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 11, "usage", "", false, false], [2, 3, 22, 25, "usage", "", false, false], [9, 11, 13, 14, "origin", "result_of_algorithm", false, false], [22, 25, 27, 28, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "empirical", "whitening", "transformation", "is", "obtained", "by", "estimating", "the", "covariance", "(", "e.g.", "by", "maximum", "likelihood", ")", "and", "then", "constructing", "an", "appropriate", "estimated", "whitening", "matrix", "(", "e.g.", "by", "Cholesky", "decomposition", ")", "."], "sentence-detokenized": "The empirical whitening transformation is obtained by estimating the covariance (e.g. by maximum likelihood) and then constructing an appropriate estimated whitening matrix (e.g. by Cholesky decomposition).", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 38], [39, 41], [42, 50], [51, 53], [54, 64], [65, 68], [69, 79], [80, 81], [81, 85], [86, 88], [89, 96], [97, 107], [107, 108], [109, 112], [113, 117], [118, 130], [131, 133], [134, 145], [146, 155], [156, 165], [166, 172], [173, 174], [174, 178], [179, 181], [182, 190], [191, 204], [204, 205], [205, 206]]}
{"doc_key": "ai-dev-297", "ner": [[0, 0, "organisation"], [8, 10, "product"], [23, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 0, 0, "artifact", "", false, false], [23, 24, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "is", "the", "world", "'s", "largest", "manufacturer", "of", "Cartesian", "coordinate", "robots", "and", "a", "recognised", "leader", "in", "low", "-", "cost", ",", "high", "-", "performance", "SCARA", "robots", "."], "sentence-detokenized": "IAI is the world's largest manufacturer of Cartesian coordinate robots and a recognised leader in low-cost, high-performance SCARA robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [16, 18], [19, 26], [27, 39], [40, 42], [43, 52], [53, 63], [64, 70], [71, 74], [75, 76], [77, 87], [88, 94], [95, 97], [98, 101], [101, 102], [102, 106], [106, 107], [108, 112], [112, 113], [113, 124], [125, 130], [131, 137], [137, 138]]}
{"doc_key": "ai-dev-298", "ner": [[10, 11, "field"], [13, 14, "field"], [16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formal", "concept", "analysis", "has", "practical", "applications", "in", "areas", "such", "as", "data", "mining", ",", "text", "mining", ",", "machine", "learning", ",", "knowledge", "management", ",", "semantic", "web", ",", "software", "development", ",", "chemistry", "and", "biology", "."], "sentence-detokenized": "Formal concept analysis has practical applications in areas such as data mining, text mining, machine learning, knowledge management, semantic web, software development, chemistry and biology.", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 27], [28, 37], [38, 50], [51, 53], [54, 59], [60, 64], [65, 67], [68, 72], [73, 79], [79, 80], [81, 85], [86, 92], [92, 93], [94, 101], [102, 110], [110, 111], [112, 121], [122, 132], [132, 133], [134, 142], [143, 146], [146, 147], [148, 156], [157, 168], [168, 169], [170, 179], [180, 183], [184, 191], [191, 192]]}
{"doc_key": "ai-dev-299", "ner": [[0, 2, "field"], [4, 6, "field"], [10, 11, "field"], [17, 19, "field"], [29, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 17, 19, "part-of", "", false, false], [4, 6, 29, 30, "topic", "", false, false], [10, 11, 4, 6, "named", "", false, false], [17, 19, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", ",", "computational", "learning", "theory", "(", "or", "simply", "learning", "theory", ")", "is", "a", "subfield", "of", "artificial", "intelligence", "devoted", "to", "the", "study", "of", "the", "design", "and", "analysis", "of", "machine", "learning", "algorithms", "."], "sentence-detokenized": "In computer science, computational learning theory (or simply learning theory) is a subfield of artificial intelligence devoted to the study of the design and analysis of machine learning algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 34], [35, 43], [44, 50], [51, 52], [52, 54], [55, 61], [62, 70], [71, 77], [77, 78], [79, 81], [82, 83], [84, 92], [93, 95], [96, 106], [107, 119], [120, 127], [128, 130], [131, 134], [135, 140], [141, 143], [144, 147], [148, 154], [155, 158], [159, 167], [168, 170], [171, 178], [179, 187], [188, 198], [198, 199]]}
{"doc_key": "ai-dev-300", "ner": [[0, 1, "algorithm"], [3, 3, "algorithm"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 1, "named", "", false, false], [10, 10, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Collaborative", "filtering", "(", "CF", ")", "is", "a", "technique", "used", "in", "recommender", "systems", "."], "sentence-detokenized": "Collaborative filtering (CF) is a technique used in recommender systems.", "token2charspan": [[0, 13], [14, 23], [24, 25], [25, 27], [27, 28], [29, 31], [32, 33], [34, 43], [44, 48], [49, 51], [52, 63], [64, 71], [71, 72]]}
{"doc_key": "ai-dev-301", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "FALSE", "positive", "rate", "is", "the", "fraction", "of", "all", "negative", "results", "that", "still", "give", "a", "positive", "test", "result", ",", "i.e.", "the", "conditional", "probability", "of", "a", "positive", "test", "result", "if", "the", "event", "did", "not", "occur", "."], "sentence-detokenized": "A FALSE positive rate is the fraction of all negative results that still give a positive test result, i.e. the conditional probability of a positive test result if the event did not occur.", "token2charspan": [[0, 1], [2, 7], [8, 16], [17, 21], [22, 24], [25, 28], [29, 37], [38, 40], [41, 44], [45, 53], [54, 61], [62, 66], [67, 72], [73, 77], [78, 79], [80, 88], [89, 93], [94, 100], [100, 101], [102, 106], [107, 110], [111, 122], [123, 134], [135, 137], [138, 139], [140, 148], [149, 153], [154, 160], [161, 163], [164, 167], [168, 173], [174, 177], [178, 181], [182, 187], [187, 188]]}
{"doc_key": "ai-dev-302", "ner": [[1, 15, "misc"], [39, 45, "metrics"], [44, 44, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 15, 39, 45, "topic", "", false, false], [1, 15, 44, 44, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "VLDB", "'", "8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pages", "422-433", ",", "it", "was", "shown", "that", "the", "given", "mathC", "/", "math", "and", "mathK", "/", "math", "values", "usually", "imply", "a", "relatively", "low", "accuracy", "of", "the", "iteratively", "computed", "SimRank", "results", "."], "sentence-detokenized": "In VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, pages 422-433, it was shown that the given mathC/math and mathK/math values usually imply a relatively low accuracy of the iteratively computed SimRank results.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [10, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 79], [80, 85], [85, 86], [87, 92], [93, 100], [100, 101], [102, 104], [105, 108], [109, 114], [115, 119], [120, 123], [124, 129], [130, 135], [135, 136], [136, 140], [141, 144], [145, 150], [150, 151], [151, 155], [156, 162], [163, 170], [171, 176], [177, 178], [179, 189], [190, 193], [194, 202], [203, 205], [206, 209], [210, 221], [222, 230], [231, 238], [239, 246], [246, 247]]}
{"doc_key": "ai-dev-303", "ner": [[0, 8, "misc"], [9, 9, "misc"], [15, 15, "person"], [17, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 0, 8, "general-affiliation", "", false, false], [9, 9, 15, 15, "artifact", "", false, false], [9, 9, 17, 19, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "June", "2015", ",", "the", "sci", "-", "fi", "drama", "Sense8", ",", "written", "and", "produced", "by", "Wachowski", "and", "J.", "Michael", "Straczynski", ",", "debuted", "."], "sentence-detokenized": "In June 2015, the sci-fi drama Sense8, written and produced by Wachowski and J. Michael Straczynski, debuted.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 21], [21, 22], [22, 24], [25, 30], [31, 37], [37, 38], [39, 46], [47, 50], [51, 59], [60, 62], [63, 72], [73, 76], [77, 79], [80, 87], [88, 99], [99, 100], [101, 108], [108, 109]]}
{"doc_key": "ai-dev-304", "ner": [[1, 1, "misc"], [6, 9, "product"], [25, 32, "misc"], [33, 33, "country"], [35, 35, "country"], [37, 37, "country"], [39, 39, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 1, 6, 9, "topic", "", false, false], [33, 33, 25, 32, "type-of", "", false, false], [35, 35, 25, 32, "type-of", "", false, false], [37, 37, 25, 32, "type-of", "", false, false], [39, 39, 25, 32, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Although", "Eurotra", "never", "provided", "a", "functioning", "MT", "system", ",", "the", "project", "had", "a", "far", "-", "reaching", "long", "-", "term", "impact", "on", "the", "emerging", "language", "sectors", "in", "the", "European", "Member", "States", ",", "especially", "in", "Greece", ",", "Italy", ",", "Spain", ",", "Portugal", "and", "the", "southern", "countries", "."], "sentence-detokenized": "Although Eurotra never provided a functioning MT system, the project had a far-reaching long-term impact on the emerging language sectors in the European Member States, especially in Greece, Italy, Spain, Portugal and the southern countries.", "token2charspan": [[0, 8], [9, 16], [17, 22], [23, 31], [32, 33], [34, 45], [46, 48], [49, 55], [55, 56], [57, 60], [61, 68], [69, 72], [73, 74], [75, 78], [78, 79], [79, 87], [88, 92], [92, 93], [93, 97], [98, 104], [105, 107], [108, 111], [112, 120], [121, 129], [130, 137], [138, 140], [141, 144], [145, 153], [154, 160], [161, 167], [167, 168], [169, 179], [180, 182], [183, 189], [189, 190], [191, 196], [196, 197], [198, 203], [203, 204], [205, 213], [214, 217], [218, 221], [222, 230], [231, 240], [240, 241]]}
{"doc_key": "ai-dev-305", "ner": [[0, 2, "algorithm"], [8, 12, "task"], [17, 19, "task"], [21, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 12, 0, 2, "usage", "", true, false], [17, 19, 8, 12, "named", "", false, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "automatic", "encoder", "has", "been", "successfully", "used", "in", "machine", "translation", "of", "human", "languages", ",", "commonly", "known", "as", "neural", "machine", "translation", "(", "NMT", ")", "."], "sentence-detokenized": "The automatic encoder has been successfully used in machine translation of human languages, commonly known as neural machine translation (NMT).", "token2charspan": [[0, 3], [4, 13], [14, 21], [22, 25], [26, 30], [31, 43], [44, 48], [49, 51], [52, 59], [60, 71], [72, 74], [75, 80], [81, 90], [90, 91], [92, 100], [101, 106], [107, 109], [110, 116], [117, 124], [125, 136], [137, 138], [138, 141], [141, 142], [142, 143]]}
{"doc_key": "ai-dev-306", "ner": [[9, 11, "metrics"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "examples", "of", "probability", "-", "based", "fitness", "functions", "include", "maximum", "likelihood", "estimation", "and", "hinge", "loss", "."], "sentence-detokenized": "Popular examples of probability-based fitness functions include maximum likelihood estimation and hinge loss.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 31], [31, 32], [32, 37], [38, 45], [46, 55], [56, 63], [64, 71], [72, 82], [83, 93], [94, 97], [98, 103], [104, 108], [108, 109]]}
{"doc_key": "ai-dev-307", "ner": [[0, 1, "field"], [12, 15, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 15, 0, 1, "part-of", "", false, false], [17, 18, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "mining", "is", "a", "related", "field", "of", "study", "that", "focuses", "on", "the", "analysis", "of", "research", "data", "through", "unsupervised", "learning", "."], "sentence-detokenized": "Data mining is a related field of study that focuses on the analysis of research data through unsupervised learning.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 33], [34, 39], [40, 44], [45, 52], [53, 55], [56, 59], [60, 68], [69, 71], [72, 80], [81, 85], [86, 93], [94, 106], [107, 115], [115, 116]]}
{"doc_key": "ai-dev-308", "ner": [[0, 1, "algorithm"], [13, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "includes", "methods", "to", "select", "people", "with", "similar", "interests", "and", "build", "a", "recommendation", "system", "based", "on", "this", "."], "sentence-detokenized": "Collaborative filtering includes methods to select people with similar interests and build a recommendation system based on this.", "token2charspan": [[0, 13], [14, 23], [24, 32], [33, 40], [41, 43], [44, 50], [51, 57], [58, 62], [63, 70], [71, 80], [81, 84], [85, 90], [91, 92], [93, 107], [108, 114], [115, 120], [121, 123], [124, 128], [128, 129]]}
{"doc_key": "ai-dev-309", "ner": [[1, 6, "algorithm"], [12, 12, "programlang"], [14, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 17, 1, 6, "type-of", "", false, false], [14, 17, 12, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Several", "WordNet", "-", "based", "word", "similarity", "algorithms", "have", "been", "implemented", "in", "the", "Perl", "package", "WordNet", ":", ":", "Similarity", "."], "sentence-detokenized": "Several WordNet-based word similarity algorithms have been implemented in the Perl package WordNet:: Similarity.", "token2charspan": [[0, 7], [8, 15], [15, 16], [16, 21], [22, 26], [27, 37], [38, 48], [49, 53], [54, 58], [59, 70], [71, 73], [74, 77], [78, 82], [83, 90], [91, 98], [98, 99], [99, 100], [101, 111], [111, 112]]}
{"doc_key": "ai-dev-310", "ner": [[4, 4, "conference"], [7, 9, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 4, 4, "named", "", false, false], [10, 11, 4, 4, "temporal", "", false, false], [13, 14, 4, 4, "temporal", "", false, false], [16, 21, 4, 4, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Another", "paper", "presented", "at", "CVPR", "2000", "(", "CVPR", ")", "by", "Eric", "Miller", ",", "Nicolas", "Matsakis", "and", "Paul", "Viola", "will", "also", "be", "discussed", "."], "sentence-detokenized": "Another paper presented at CVPR 2000 (CVPR) by Eric Miller, Nicolas Matsakis and Paul Viola will also be discussed.", "token2charspan": [[0, 7], [8, 13], [14, 23], [24, 26], [27, 31], [32, 36], [37, 38], [38, 42], [42, 43], [44, 46], [47, 51], [52, 58], [58, 59], [60, 67], [68, 76], [77, 80], [81, 85], [86, 91], [92, 96], [97, 101], [102, 104], [105, 114], [114, 115]]}
{"doc_key": "ai-dev-311", "ner": [[0, 0, "algorithm"], [13, 14, "misc"], [19, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 19, 20, "compare", "", false, false], [19, 20, 13, 14, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["QC", "is", "not", "evaluated", "against", "traditional", "state", "-", "of", "-", "the", "-", "art", "clustering", "algorithms", ",", "except", "for", "the", "Jaccard", "index", "."], "sentence-detokenized": "QC is not evaluated against traditional state-of-the-art clustering algorithms, except for the Jaccard index.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 19], [20, 27], [28, 39], [40, 45], [45, 46], [46, 48], [48, 49], [49, 52], [52, 53], [53, 56], [57, 67], [68, 78], [78, 79], [80, 86], [87, 90], [91, 94], [95, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-dev-312", "ner": [[2, 7, "misc"], [8, 10, "misc"], [13, 16, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 2, 7, "physical", "", false, false], [8, 10, 13, 16, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "the", "VEX", "Robotics", "World", "Championships", ",", "the", "Parade", "of", "Nations", "takes", "place", "in", "the", "Freedom", "Hall", ",", "with", "hundreds", "of", "students", "from", "more", "than", "30", "countries", "taking", "part", "."], "sentence-detokenized": "During the VEX Robotics World Championships, the Parade of Nations takes place in the Freedom Hall, with hundreds of students from more than 30 countries taking part.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 23], [24, 29], [30, 43], [43, 44], [45, 48], [49, 55], [56, 58], [59, 66], [67, 72], [73, 78], [79, 81], [82, 85], [86, 93], [94, 98], [98, 99], [100, 104], [105, 113], [114, 116], [117, 125], [126, 130], [131, 135], [136, 140], [141, 143], [144, 153], [154, 160], [161, 165], [165, 166]]}
{"doc_key": "ai-dev-313", "ner": [[5, 8, "metrics"], [10, 10, "metrics"], [14, 16, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 5, 8, "named", "", false, false], [18, 18, 14, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Other", "accuracy", "indicators", "are", "the", "Single", "Word", "Error", "Rate", "(", "SWER", ")", "and", "the", "Command", "Success", "Rate", "(", "CSR", ")", "."], "sentence-detokenized": "Other accuracy indicators are the Single Word Error Rate (SWER) and the Command Success Rate (CSR).", "token2charspan": [[0, 5], [6, 14], [15, 25], [26, 29], [30, 33], [34, 40], [41, 45], [46, 51], [52, 56], [57, 58], [58, 62], [62, 63], [64, 67], [68, 71], [72, 79], [80, 87], [88, 92], [93, 94], [94, 97], [97, 98], [98, 99]]}
{"doc_key": "ai-dev-314", "ner": [[7, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "presented", "their", "method", "and", "results", "at", "SIGGRAPH", "2000", "."], "sentence-detokenized": "They presented their method and results at SIGGRAPH 2000.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 27], [28, 31], [32, 39], [40, 42], [43, 51], [52, 56], [56, 57]]}
{"doc_key": "ai-dev-315", "ner": [[0, 2, "conference"], [7, 7, "misc"], [9, 13, "misc"], [16, 18, "conference"], [21, 34, "researcher"], [35, 38, "researcher"], [40, 42, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 7, 7, "origin", "", false, false], [7, 7, 16, 18, "physical", "", false, false], [7, 7, 16, 18, "temporal", "", false, false], [7, 7, 21, 34, "origin", "", false, false], [7, 7, 35, 38, "origin", "", false, false], [9, 13, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "KDD", "Conference", "grew", "out", "of", "the", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "workshops", "at", "AAAI", "conferences", "initiated", "by", "Gregory", "I", ".", "Piatetsky", "-", "Shapiro", "in", "1989", ",", "1991", "and", "1993", "and", "by", "Usama", "Fayyad", "in", "1994", ".", "Machines", "|", "ACM", "."], "sentence-detokenized": "The KDD Conference grew out of the KDD (Knowledge Discovery and Data Mining) workshops at AAAI conferences initiated by Gregory I. Piatetsky-Shapiro in 1989, 1991 and 1993 and by Usama Fayyad in 1994. Machines | ACM.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 23], [24, 27], [28, 30], [31, 34], [35, 38], [39, 40], [40, 49], [50, 59], [60, 63], [64, 68], [69, 75], [75, 76], [77, 86], [87, 89], [90, 94], [95, 106], [107, 116], [117, 119], [120, 127], [128, 129], [129, 130], [131, 140], [140, 141], [141, 148], [149, 151], [152, 156], [156, 157], [158, 162], [163, 166], [167, 171], [172, 175], [176, 178], [179, 184], [185, 191], [192, 194], [195, 199], [199, 200], [201, 209], [210, 211], [212, 215], [215, 216]]}
{"doc_key": "ai-dev-316", "ner": [[7, 10, "conference"], [12, 12, "conference"], [16, 21, "organisation"], [23, 26, "organisation"], [27, 31, "conference"], [33, 33, "conference"], [37, 43, "conference"], [45, 45, "conference"], [49, 55, "conference"], [57, 57, "conference"], [61, 66, "conference"], [68, 68, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[12, 12, 7, 10, "named", "", false, false], [23, 26, 16, 21, "named", "", false, false], [33, 33, 27, 31, "named", "", false, false], [45, 45, 37, 43, "named", "", false, false], [57, 57, 49, 55, "named", "", false, false], [68, 68, 61, 66, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "is", "an", "elected", "member", "of", "the", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "(", "AAAS", ")", "and", "the", "Society", "for", "Optics", "and", "Photonics", "Technology", "(", "SPIE", ")", "."], "sentence-detokenized": "He is an elected member of the Association for Computing Machinery (ACM), the Institute of Electrical and Electronics Engineers (IEEE), the International Association for Pattern Recognition (IAPR), the Association for the Advancement of Artificial Intelligence (AAAI), the American Association for the Advancement of Science (AAAS) and the Society for Optics and Photonics Technology (SPIE).", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 16], [17, 23], [24, 26], [27, 30], [31, 42], [43, 46], [47, 56], [57, 66], [67, 68], [68, 71], [71, 72], [72, 73], [74, 77], [78, 87], [88, 90], [91, 101], [102, 105], [106, 117], [118, 127], [128, 129], [129, 133], [133, 134], [134, 135], [136, 139], [140, 153], [154, 165], [166, 169], [170, 177], [178, 189], [190, 191], [191, 195], [195, 196], [196, 197], [198, 201], [202, 213], [214, 217], [218, 221], [222, 233], [234, 236], [237, 247], [248, 260], [261, 262], [262, 266], [266, 267], [267, 268], [269, 272], [273, 281], [282, 293], [294, 297], [298, 301], [302, 313], [314, 316], [317, 324], [325, 326], [326, 330], [330, 331], [332, 335], [336, 339], [340, 347], [348, 351], [352, 358], [359, 362], [363, 372], [373, 383], [384, 385], [385, 389], [389, 390], [390, 391]]}
{"doc_key": "ai-dev-317", "ner": [[0, 1, "field"], [3, 4, "field"], [15, 17, "field"], [30, 31, "field"], [47, 52, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 15, 17, "named", "", false, false], [3, 4, 30, 31, "named", "", false, false], [30, 31, 47, 52, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "and", "data", "mining", "often", "use", "the", "same", "techniques", "and", "overlap", "considerably", ",", "but", "machine", "learning", "focuses", "on", "prediction", "based", "on", "known", "features", "extracted", "from", "training", "data", ",", "while", "data", "mining", "focuses", "on", "discovering", "(", "previously", ")", "unknown", "features", "in", "the", "data", "(", "this", "is", "the", "knowledge", "discovery", "analysis", "stage", "in", "databases", ")", "."], "sentence-detokenized": "Machine learning and data mining often use the same techniques and overlap considerably, but machine learning focuses on prediction based on known features extracted from training data, while data mining focuses on discovering (previously) unknown features in the data (this is the knowledge discovery analysis stage in databases).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 62], [63, 66], [67, 74], [75, 87], [87, 88], [89, 92], [93, 100], [101, 109], [110, 117], [118, 120], [121, 131], [132, 137], [138, 140], [141, 146], [147, 155], [156, 165], [166, 170], [171, 179], [180, 184], [184, 185], [186, 191], [192, 196], [197, 203], [204, 211], [212, 214], [215, 226], [227, 228], [228, 238], [238, 239], [240, 247], [248, 256], [257, 259], [260, 263], [264, 268], [269, 270], [270, 274], [275, 277], [278, 281], [282, 291], [292, 301], [302, 310], [311, 316], [317, 319], [320, 329], [329, 330], [330, 331]]}
{"doc_key": "ai-dev-318", "ner": [[0, 2, "product"], [4, 4, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 4, 4, "general-affiliation", "", false, false], [0, 2, 4, 4, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "is", "written", "in", "Java", ",", "so", "it", "works", "on", "most", "modern", "operating", "systems", "."], "sentence-detokenized": "Indy is written in Java, so it works on most modern operating systems.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 23], [23, 24], [25, 27], [28, 30], [31, 36], [37, 39], [40, 44], [45, 51], [52, 61], [62, 69], [69, 70]]}
{"doc_key": "ai-dev-319", "ner": [[0, 0, "algorithm"], [5, 7, "algorithm"], [9, 9, "algorithm"], [15, 17, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 7, "type-of", "", true, false], [9, 9, 5, 7, "named", "", false, false], [15, 17, 5, 7, "type-of", "", true, false], [19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["NMF", "is", "a", "case", "of", "non-negative", "quadratic", "programming", "(", "NQP", ")", ",", "as", "is", "the", "support", "vector", "machine", "(", "SVM", ")", "."], "sentence-detokenized": "NMF is a case of non-negative quadratic programming (NQP), as is the support vector machine (SVM).", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 13], [14, 16], [17, 29], [30, 39], [40, 51], [52, 53], [53, 56], [56, 57], [57, 58], [59, 61], [62, 64], [65, 68], [69, 76], [77, 83], [84, 91], [92, 93], [93, 96], [96, 97], [97, 98]]}
{"doc_key": "ai-dev-320", "ner": [[8, 9, "misc"], [12, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 12, 14, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "method", "is", "based", "on", "the", "estimation", "of", "conditional", "probabilities", "using", "a", "non-parametric", "maximum", "likelihood", "method", "that", "allows"], "sentence-detokenized": "The method is based on the estimation of conditional probabilities using a non-parametric maximum likelihood method that allows", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 26], [27, 37], [38, 40], [41, 52], [53, 66], [67, 72], [73, 74], [75, 89], [90, 97], [98, 108], [109, 115], [116, 120], [121, 127]]}
{"doc_key": "ai-dev-321", "ner": [[6, 6, "algorithm"], [8, 10, "algorithm"], [12, 15, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Basic", "concepts", "of", "spectral", "estimation", "include", "autocorrelation", ",", "multivariate", "Fourier", "transform", ",", "root", "mean", "square", "error", "and", "entropy", "."], "sentence-detokenized": "Basic concepts of spectral estimation include autocorrelation, multivariate Fourier transform, root mean square error and entropy.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [27, 37], [38, 45], [46, 61], [61, 62], [63, 75], [76, 83], [84, 93], [93, 94], [95, 99], [100, 104], [105, 111], [112, 117], [118, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-dev-322", "ner": [[3, 4, "algorithm"], [9, 9, "field"], [11, 11, "algorithm"], [13, 15, "algorithm"], [17, 18, "task"], [20, 20, "field"], [22, 23, "field"], [25, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 4, 9, 9, "part-of", "", false, false], [3, 4, 11, 11, "part-of", "", false, false], [3, 4, 13, 15, "part-of", "", false, false], [3, 4, 17, 18, "part-of", "", false, false], [3, 4, 20, 20, "part-of", "", false, false], [3, 4, 22, 23, "part-of", "", false, false], [3, 4, 25, 26, "part-of", "", false, false], [3, 4, 28, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "applications", "of", "kernel", "methods", "are", "diverse", "and", "include", "geostatistics", ",", "kriging", ",", "inverse", "distance", "weighting", ",", "3D", "reconstruction", ",", "bioinformatics", ",", "chemical", "informatics", ",", "information", "extraction", "and", "handwriting", "recognition", "."], "sentence-detokenized": "The applications of kernel methods are diverse and include geostatistics, kriging, inverse distance weighting, 3D reconstruction, bioinformatics, chemical informatics, information extraction and handwriting recognition.", "token2charspan": [[0, 3], [4, 16], [17, 19], [20, 26], [27, 34], [35, 38], [39, 46], [47, 50], [51, 58], [59, 72], [72, 73], [74, 81], [81, 82], [83, 90], [91, 99], [100, 109], [109, 110], [111, 113], [114, 128], [128, 129], [130, 144], [144, 145], [146, 154], [155, 166], [166, 167], [168, 179], [180, 190], [191, 194], [195, 206], [207, 218], [218, 219]]}
{"doc_key": "ai-dev-323", "ner": [[12, 13, "organisation"], [14, 18, "product"], [20, 20, "product"], [23, 23, "organisation"], [24, 29, "product"], [31, 31, "product"], [34, 35, "product"], [37, 39, "product"], [41, 43, "product"], [45, 47, "product"], [51, 52, "product"], [54, 55, "product"], [57, 62, "product"], [65, 67, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[14, 18, 12, 13, "artifact", "", false, false], [14, 18, 34, 35, "compare", "", false, false], [14, 18, 37, 39, "compare", "", false, false], [14, 18, 41, 43, "compare", "", false, false], [14, 18, 45, 47, "compare", "", false, false], [14, 18, 51, 52, "compare", "", false, false], [14, 18, 54, 55, "compare", "", false, false], [14, 18, 57, 62, "compare", "", false, false], [14, 18, 65, 67, "compare", "", false, false], [20, 20, 14, 18, "named", "", false, false], [24, 29, 23, 23, "artifact", "", false, false], [24, 29, 34, 35, "compare", "", false, false], [24, 29, 37, 39, "compare", "", false, false], [24, 29, 41, 43, "compare", "", false, false], [24, 29, 45, 47, "compare", "", false, false], [24, 29, 51, 52, "compare", "", false, false], [24, 29, 54, 55, "compare", "", false, false], [24, 29, 57, 62, "compare", "", false, false], [24, 29, 65, 67, "compare", "", false, false], [31, 31, 24, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Robots", "can", "be", "autonomous", "or", "semi-autonomous", "and", "range", "from", "humanoids", "such", "as", "Honda", "'s", "Advanced", "Step", "in", "Innovative", "Mobility", "(", "ASIMO", ")", "and", "TOSY", "'s", "TOSY", "Ping", "Pong", "Playing", "Robot", "(", "TOPIO", ")", "to", "industrial", "robots", ",", "medical", "operative", "robots", ",", "patient", "assistant", "robots", ",", "therapy", "dog", "robots", ",", "collectively", "programmed", "family", "robots", ",", "drones", "such", "as", "General", "Atomics", "MQ", "-", "1", "Predator", "and", "even", "microscopic", "nano", "robots", "."], "sentence-detokenized": "Robots can be autonomous or semi-autonomous and range from humanoids such as Honda's Advanced Step in Innovative Mobility (ASIMO) and TOSY's TOSY Ping Pong Playing Robot (TOPIO) to industrial robots, medical operative robots, patient assistant robots, therapy dog robots, collectively programmed family robots, drones such as General Atomics MQ-1 Predator and even microscopic nano robots.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 24], [25, 27], [28, 43], [44, 47], [48, 53], [54, 58], [59, 68], [69, 73], [74, 76], [77, 82], [82, 84], [85, 93], [94, 98], [99, 101], [102, 112], [113, 121], [122, 123], [123, 128], [128, 129], [130, 133], [134, 138], [138, 140], [141, 145], [146, 150], [151, 155], [156, 163], [164, 169], [170, 171], [171, 176], [176, 177], [178, 180], [181, 191], [192, 198], [198, 199], [200, 207], [208, 217], [218, 224], [224, 225], [226, 233], [234, 243], [244, 250], [250, 251], [252, 259], [260, 263], [264, 270], [270, 271], [272, 284], [285, 295], [296, 302], [303, 309], [309, 310], [311, 317], [318, 322], [323, 325], [326, 333], [334, 341], [342, 344], [344, 345], [345, 346], [347, 355], [356, 359], [360, 364], [365, 376], [377, 381], [382, 388], [388, 389]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 3, "product"], [8, 14, "university"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [24, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 15, 16, "artifact", "", false, false], [0, 0, 18, 19, "artifact", "", false, false], [0, 0, 21, 22, "artifact", "", false, false], [0, 0, 24, 26, "artifact", "", false, false], [2, 3, 15, 16, "artifact", "", false, false], [2, 3, 18, 19, "artifact", "", false, false], [2, 3, 21, 22, "artifact", "", false, false], [2, 3, 24, 26, "artifact", "", false, false], [15, 16, 8, 14, "physical", "", false, false], [18, 19, 8, 14, "physical", "", false, false], [21, 22, 8, 14, "physical", "", false, false], [24, 26, 8, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "and", "Freddy", "II", "were", "robots", "built", "at", "Edinburgh", "University", "'s", "School", "of", "Informatics", "by", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "and", "Donald", "Michie", "that", "could", "assemble", "wooden", "blocks", "in", "several", "hours", "."], "sentence-detokenized": "Freddy and Freddy II were robots built at Edinburgh University's School of Informatics by Pat Ambler, Robin Popplestone, Austin Tate and Donald Michie that could assemble wooden blocks in several hours.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 25], [26, 32], [33, 38], [39, 41], [42, 51], [52, 62], [62, 64], [65, 71], [72, 74], [75, 86], [87, 89], [90, 93], [94, 100], [100, 101], [102, 107], [108, 119], [119, 120], [121, 127], [128, 132], [133, 136], [137, 143], [144, 150], [151, 155], [156, 161], [162, 170], [171, 177], [178, 184], [185, 187], [188, 195], [196, 201], [201, 202]]}
{"doc_key": "ai-dev-325", "ner": [[6, 6, "location"], [8, 10, "country"], [16, 16, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 8, 10, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "spent", "his", "childhood", "years", "in", "Paris", ",", "France", ",", "where", "his", "parents", "had", "emigrated", "from", "Lithuania", "in", "the", "early", "1920s", "."], "sentence-detokenized": "He spent his childhood years in Paris, France, where his parents had emigrated from Lithuania in the early 1920s.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 22], [23, 28], [29, 31], [32, 37], [37, 38], [39, 45], [45, 46], [47, 52], [53, 56], [57, 64], [65, 68], [69, 78], [79, 83], [84, 93], [94, 96], [97, 100], [101, 106], [107, 112], [112, 113]]}
{"doc_key": "ai-dev-326", "ner": [[2, 3, "researcher"], [5, 9, "misc"], [13, 17, "organisation"], [10, 12, "university"], [26, 31, "university"], [37, 40, "university"], [44, 45, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 3, 5, 9, "role", "", false, false], [2, 3, 10, 12, "physical", "", false, false], [2, 3, 26, 31, "role", "", false, false], [2, 3, 37, 40, "role", "", false, false], [2, 3, 44, 45, "role", "", false, false], [5, 9, 13, 17, "part-of", "", false, false], [13, 17, 10, 12, "part-of", "", false, false], [37, 40, 26, 31, "part-of", "", false, false], [44, 45, 26, 31, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Previously", ",", "Dr", "Paulos", "was", "Cooper-", "Siegel", "Associate", "Professor", "at", "Carnegie", "Mellon", "University", "'s", "School", "of", "Computer", "Science", ",", "where", "he", "was", "a", "faculty", "member", "of", "the", "Human", "-", "Computer", "Interaction", "Institute", ",", "and", "a", "faculty", "member", "at", "the", "Robotics", "Institute", "and", "the", "Entertainment", "Technology", "Centre", "."], "sentence-detokenized": "Previously, Dr Paulos was Cooper-Siegel Associate Professor at Carnegie Mellon University's School of Computer Science, where he was a faculty member of the Human-Computer Interaction Institute, and a faculty member at the Robotics Institute and the Entertainment Technology Centre.", "token2charspan": [[0, 10], [10, 11], [12, 14], [15, 21], [22, 25], [26, 33], [33, 39], [40, 49], [50, 59], [60, 62], [63, 71], [72, 78], [79, 89], [89, 91], [92, 98], [99, 101], [102, 110], [111, 118], [118, 119], [120, 125], [126, 128], [129, 132], [133, 134], [135, 142], [143, 149], [150, 152], [153, 156], [157, 162], [162, 163], [163, 171], [172, 183], [184, 193], [193, 194], [195, 198], [199, 200], [201, 208], [209, 215], [216, 218], [219, 222], [223, 231], [232, 241], [242, 245], [246, 249], [250, 263], [264, 274], [275, 281], [281, 282]]}
{"doc_key": "ai-dev-327", "ner": [[3, 4, "researcher"], [5, 7, "university"], [10, 11, "product"], [17, 21, "product"], [23, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 5, 7, "physical", "", false, false], [3, 4, 5, 7, "role", "", false, false], [10, 11, 3, 4, "artifact", "", false, false], [10, 11, 17, 21, "type-of", "", false, false], [10, 11, 23, 27, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1969", ",", "Victor", "Scheinman", "at", "Stanford", "University", "invented", "the", "Stanford", "Arm", "-", "a", "fully", "electric", ",", "6", "-", "axis", "articulated", "robot", "designed", "to", "be", "hand", "-", "held", "."], "sentence-detokenized": "In 1969, Victor Scheinman at Stanford University invented the Stanford Arm - a fully electric, 6-axis articulated robot designed to be hand-held.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 25], [26, 28], [29, 37], [38, 48], [49, 57], [58, 61], [62, 70], [71, 74], [75, 76], [77, 78], [79, 84], [85, 93], [93, 94], [95, 96], [96, 97], [97, 101], [102, 113], [114, 119], [120, 128], [129, 131], [132, 134], [135, 139], [139, 140], [140, 144], [144, 145]]}
{"doc_key": "ai-dev-328", "ner": [[5, 5, "product"], [15, 16, "field"], [18, 21, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 15, 16, "related-to", "", false, false], [5, 5, 18, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "development", "and", "deployment", "of", "chatbots", "is", "still", "an", "evolving", "field", ",", "closely", "linked", "to", "artificial", "intelligence", "and", "machine", "learning", ",", "so", "the", "proposed", "solutions", ",", "while", "having", "obvious", "advantages", ",", "have", "some", "significant", "limitations", "in", "terms", "of", "functionality", "and", "use", "cases", "."], "sentence-detokenized": "The development and deployment of chatbots is still an evolving field, closely linked to artificial intelligence and machine learning, so the proposed solutions, while having obvious advantages, have some significant limitations in terms of functionality and use cases.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 30], [31, 33], [34, 42], [43, 45], [46, 51], [52, 54], [55, 63], [64, 69], [69, 70], [71, 78], [79, 85], [86, 88], [89, 99], [100, 112], [113, 116], [117, 124], [125, 133], [133, 134], [135, 137], [138, 141], [142, 150], [151, 160], [160, 161], [162, 167], [168, 174], [175, 182], [183, 193], [193, 194], [195, 199], [200, 204], [205, 216], [217, 228], [229, 231], [232, 237], [238, 240], [241, 254], [255, 258], [259, 262], [263, 268], [268, 269]]}
{"doc_key": "ai-dev-329", "ner": [[7, 10, "university"], [11, 12, "product"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 7, 10, "part-of", "", true, false], [20, 21, 11, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "terms", "of", "freely", "available", "resources", ",", "Carnegie", "Mellon", "University", "'s", "Sphinx", "toolkit", "is", "one", "place", "to", "start", "learning", "about", "speech", "recognition", "and", "to", "start", "experimenting", "."], "sentence-detokenized": "In terms of freely available resources, Carnegie Mellon University's Sphinx toolkit is one place to start learning about speech recognition and to start experimenting.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 18], [19, 28], [29, 38], [38, 39], [40, 48], [49, 55], [56, 66], [66, 68], [69, 75], [76, 83], [84, 86], [87, 90], [91, 96], [97, 99], [100, 105], [106, 114], [115, 120], [121, 127], [128, 139], [140, 143], [144, 146], [147, 152], [153, 166], [166, 167]]}
{"doc_key": "ai-dev-330", "ner": [[2, 7, "misc"], [13, 23, "misc"], [19, 19, "misc"], [25, 25, "university"], [26, 27, "location"], [29, 32, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 7, 13, 23, "temporal", "", false, false], [19, 19, 13, 23, "named", "", false, false], [19, 19, 26, 27, "physical", "", false, false], [25, 25, 19, 19, "role", "", false, false], [26, 27, 29, 32, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "official", "RoboCup", "competition", "was", "preceded", "by", "the", "(", "often", "unrecognised", ")", "first", "International", "Microrobot", "World", "Cup", "Soccer", "(", "MIROSOT", ")", "tournament", ",", "hosted", "by", "KAIST", "in", "Taejon", ",", "Korea", "in", "November", "1996", "."], "sentence-detokenized": "The official RoboCup competition was preceded by the (often unrecognised) first International Microrobot World Cup Soccer (MIROSOT) tournament, hosted by KAIST in Taejon, Korea in November 1996.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 32], [33, 36], [37, 45], [46, 48], [49, 52], [53, 54], [54, 59], [60, 72], [72, 73], [74, 79], [80, 93], [94, 104], [105, 110], [111, 114], [115, 121], [122, 123], [123, 130], [130, 131], [132, 142], [142, 143], [144, 150], [151, 153], [154, 159], [160, 162], [163, 169], [169, 170], [171, 176], [177, 179], [180, 188], [189, 193], [193, 194]]}
{"doc_key": "ai-dev-331", "ner": [[8, 9, "metrics"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "standard", "math", "value", "for", "pivot", "loss", "(", "1-", "yf", "(", "x", ")", ")", "_", "+", "/", "math", "for", "labelled", "data", ",", "a", "loss", "function", "math", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "math", "is", "introduced", "for", "unlabelled", "data", ",", "allowing", "mathy", "=\\", "operator", "name", "{", "sign", "}", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "In addition to the standard math value for pivot loss (1-yf (x)) _ + / math for labelled data, a loss function math (-1 | f (x) |) _ + / math is introduced for unlabelled data, allowing mathy =\\ operator name {sign} {f (x)} /math.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 27], [28, 32], [33, 38], [39, 42], [43, 48], [49, 53], [54, 55], [55, 57], [57, 59], [60, 61], [61, 62], [62, 63], [63, 64], [65, 66], [67, 68], [69, 70], [71, 75], [76, 79], [80, 88], [89, 93], [93, 94], [95, 96], [97, 101], [102, 110], [111, 115], [116, 117], [117, 118], [118, 119], [120, 121], [122, 123], [124, 125], [125, 126], [126, 127], [128, 129], [129, 130], [131, 132], [133, 134], [135, 136], [137, 141], [142, 144], [145, 155], [156, 159], [160, 170], [171, 175], [175, 176], [177, 185], [186, 191], [192, 194], [195, 203], [204, 208], [209, 210], [210, 214], [214, 215], [216, 217], [217, 218], [219, 220], [220, 221], [221, 222], [222, 223], [224, 225], [225, 229], [229, 230]]}
{"doc_key": "ai-dev-332", "ner": [[0, 4, "misc"], [10, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 10, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "particular", ",", "the", "RLS", "is", "designed", "to", "reduce", "the", "mean", "squared", "error", "between", "the", "predicted", "values", "and", "the", "true", "labels", "after", "tuning", "."], "sentence-detokenized": "In particular, the RLS is designed to reduce the mean squared error between the predicted values and the true labels after tuning.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 22], [23, 25], [26, 34], [35, 37], [38, 44], [45, 48], [49, 53], [54, 61], [62, 67], [68, 75], [76, 79], [80, 89], [90, 96], [97, 100], [101, 104], [105, 109], [110, 116], [117, 122], [123, 129], [129, 130]]}
{"doc_key": "ai-dev-333", "ner": [[5, 7, "algorithm"], [10, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 10, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Essentially", ",", "it", "combines", "a", "maximum", "likelihood", "assessment", "with", "a", "tuning", "procedure", "that", "favours", "simpler", "models", "over", "more", "complex", "ones", "."], "sentence-detokenized": "Essentially, it combines a maximum likelihood assessment with a tuning procedure that favours simpler models over more complex ones.", "token2charspan": [[0, 11], [11, 12], [13, 15], [16, 24], [25, 26], [27, 34], [35, 45], [46, 56], [57, 61], [62, 63], [64, 70], [71, 80], [81, 85], [86, 93], [94, 101], [102, 108], [109, 113], [114, 118], [119, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-dev-334", "ner": [[0, 3, "metrics"], [9, 9, "metrics"], [11, 11, "metrics"], [13, 15, "misc"], [19, 20, "misc"], [33, 36, "algorithm"], [37, 41, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 9, 0, 3, "named", "", false, false], [11, 11, 0, 3, "named", "", false, false], [13, 15, 19, 20, "related-to", "", false, false], [13, 15, 33, 36, "related-to", "ratio", false, false], [33, 36, 37, 41, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "true", "positive", "rate", "is", "also", "known", "as", "the", "sensitivity", ",", "recall", "or", "probability", "of", "detection", "matted", "to", "the", "discrimination", "threshold", ")", "of", "the", "probability", "of", "detection", "on", "the", "y", "-axis", "versus", "the", "cumulative", "distribution", "function", "of", "the", "probability", "of", "false", "alarm", "on", "the", "x-", "axis", "."], "sentence-detokenized": "The true positive rate is also known as the sensitivity, recall or probability of detection matted to the discrimination threshold) of the probability of detection on the y-axis versus the cumulative distribution function of the probability of false alarm on the x-axis.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 25], [26, 30], [31, 36], [37, 39], [40, 43], [44, 55], [55, 56], [57, 63], [64, 66], [67, 78], [79, 81], [82, 91], [92, 98], [99, 101], [102, 105], [106, 120], [121, 130], [130, 131], [132, 134], [135, 138], [139, 150], [151, 153], [154, 163], [164, 166], [167, 170], [171, 172], [172, 177], [178, 184], [185, 188], [189, 199], [200, 212], [213, 221], [222, 224], [225, 228], [229, 240], [241, 243], [244, 249], [250, 255], [256, 258], [259, 262], [263, 265], [265, 269], [269, 270]]}
{"doc_key": "ai-dev-335", "ner": [[0, 1, "misc"], [3, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 0, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "English", ",", "Word", "Net", "is", "an", "example", "of", "a", "semantic", "network", "."], "sentence-detokenized": "In English, WordNet is an example of a semantic network.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [16, 19], [20, 22], [23, 25], [26, 33], [34, 36], [37, 38], [39, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-dev-336", "ner": [[5, 7, "product"], [12, 13, "product"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[24, 25, 5, 7, "usage", "", false, false], [24, 25, 12, 13, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "-", "term", "use", "of", "speech", "recognition", "software", "in", "combination", "with", "a", "word", "processor", "has", "shown", "benefits", "in", "short", "-", "term", "memory", "recovery", "in", "brain", "AVM", "patients", "treated", "with", "resection", "."], "sentence-detokenized": "Long-term use of speech recognition software in combination with a word processor has shown benefits in short-term memory recovery in brain AVM patients treated with resection.", "token2charspan": [[0, 4], [4, 5], [5, 9], [10, 13], [14, 16], [17, 23], [24, 35], [36, 44], [45, 47], [48, 59], [60, 64], [65, 66], [67, 71], [72, 81], [82, 85], [86, 91], [92, 100], [101, 103], [104, 109], [109, 110], [110, 114], [115, 121], [122, 130], [131, 133], [134, 139], [140, 143], [144, 152], [153, 160], [161, 165], [166, 175], [175, 176]]}
{"doc_key": "ai-dev-337", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "was", "edited", "by", "Ron", "Sun", ",", "Vasant", "Honavar", "and", "Greg", "Oden", "(", "from", "1999", "to", "2014", ")", "."], "sentence-detokenized": "It was edited by Ron Sun, Vasant Honavar and Greg Oden (from 1999 to 2014).", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 20], [21, 24], [24, 25], [26, 32], [33, 40], [41, 44], [45, 49], [50, 54], [55, 56], [56, 60], [61, 65], [66, 68], [69, 73], [73, 74], [74, 75]]}
{"doc_key": "ai-dev-338", "ner": [[6, 9, "product"], [12, 24, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 9, 12, 24, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Their", "\"", "parallel", "\"", "difference", "from", "a", "serial", "manipulator", "is", "that", "the", "effective", "end", "-effector", "(", "or", "\"", "arm", "\"", ")", "of", "the", "linkage", "is", "directly", "connected", "to", "its", "base", "via", "a", "number", "(", "typically", "three", "or", "six", ")", "of", "separate", "and", "independent", "links", "operating", "simultaneously", "."], "sentence-detokenized": "Their \"parallel\" difference from a serial manipulator is that the effective end-effector (or \"arm\") of the linkage is directly connected to its base via a number (typically three or six) of separate and independent links operating simultaneously.", "token2charspan": [[0, 5], [6, 7], [7, 15], [15, 16], [17, 27], [28, 32], [33, 34], [35, 41], [42, 53], [54, 56], [57, 61], [62, 65], [66, 75], [76, 79], [79, 88], [89, 90], [90, 92], [93, 94], [94, 97], [97, 98], [98, 99], [100, 102], [103, 106], [107, 114], [115, 117], [118, 126], [127, 136], [137, 139], [140, 143], [144, 148], [149, 152], [153, 154], [155, 161], [162, 163], [163, 172], [173, 178], [179, 181], [182, 185], [185, 186], [187, 189], [190, 198], [199, 202], [203, 214], [215, 220], [221, 230], [231, 245], [245, 246]]}
{"doc_key": "ai-dev-339", "ner": [[5, 8, "researcher"], [16, 17, "researcher"], [18, 20, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"], [28, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "thesis", "supervisor", "was", "Professor", "Cordell", "Green", ",", "and", "his", "thesis", "/", "oral", "committee", "included", "Professors", "Edward", "Feigenbaum", ",", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", ",", "Herbert", "Simon", ",", "."], "sentence-detokenized": "His thesis supervisor was Professor Cordell Green, and his thesis/oral committee included Professors Edward Feigenbaum, Joshua Lederberg, Paul Cohen, Allen Newell, Herbert Simon,.", "token2charspan": [[0, 3], [4, 10], [11, 21], [22, 25], [26, 35], [36, 43], [44, 49], [49, 50], [51, 54], [55, 58], [59, 65], [65, 66], [66, 70], [71, 80], [81, 89], [90, 100], [101, 107], [108, 118], [118, 119], [120, 126], [127, 136], [136, 137], [138, 142], [143, 148], [148, 149], [150, 155], [156, 162], [162, 163], [164, 171], [172, 177], [177, 178], [178, 179]]}
{"doc_key": "ai-dev-340", "ner": [[3, 5, "metrics"], [7, 10, "metrics"], [12, 14, "metrics"], [16, 18, "metrics"], [20, 23, "metrics"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "functions", "include", "mean", "squared", "error", ",", "root", "mean", "squared", "error", ",", "mean", "absolute", "error", ",", "relative", "squared", "error", ",", "relative", "relative", "squared", "error", ",", "relative", "absolute", "error", "and", "others", "."], "sentence-detokenized": "Such functions include mean squared error, root mean squared error, mean absolute error, relative squared error, relative relative squared error, relative absolute error and others.", "token2charspan": [[0, 4], [5, 14], [15, 22], [23, 27], [28, 35], [36, 41], [41, 42], [43, 47], [48, 52], [53, 60], [61, 66], [66, 67], [68, 72], [73, 81], [82, 87], [87, 88], [89, 97], [98, 105], [106, 111], [111, 112], [113, 121], [122, 130], [131, 138], [139, 144], [144, 145], [146, 154], [155, 163], [164, 169], [170, 173], [174, 180], [180, 181]]}
{"doc_key": "ai-dev-341", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [8, 10, "programlang"]], "ner_mapping_to_source": [0, 1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "bindings", "in", "Python", ",", "Java", "and", "MATLAB", "/", "OCTAVE", "."], "sentence-detokenized": "There are bindings in Python, Java and MATLAB/OCTAVE.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 21], [22, 28], [28, 29], [30, 34], [35, 38], [39, 45], [45, 46], [46, 52], [52, 53]]}
{"doc_key": "ai-dev-342", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "MATLAB", "implementation", "can", "be", "found", "at", "."], "sentence-detokenized": "The MATLAB implementation can be found at.", "token2charspan": [[0, 3], [4, 10], [11, 25], [26, 29], [30, 32], [33, 38], [39, 41], [41, 42]]}
{"doc_key": "ai-dev-343", "ner": [[0, 1, "researcher"], [9, 10, "field"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 10, 0, 1, "origin", "", false, false], [9, 10, 14, 15, "origin", "", false, false], [9, 10, 17, 18, "origin", "", false, false], [9, 10, 20, 21, "origin", "", false, false], [9, 10, 23, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "is", "one", "of", "the", "founding", "fathers", "of", "artificial", "intelligence", ",", "along", "with", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", "and", "Herbert", "A", ".", "Simon", "."], "sentence-detokenized": "John McCarthy is one of the founding fathers of artificial intelligence, along with Alan Turing, Marvin Minsky, Allen Newell and Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 36], [37, 44], [45, 47], [48, 58], [59, 71], [71, 72], [73, 78], [79, 83], [84, 88], [89, 95], [95, 96], [97, 103], [104, 110], [110, 111], [112, 117], [118, 124], [125, 128], [129, 136], [137, 138], [138, 139], [140, 145], [145, 146]]}
{"doc_key": "ai-dev-344", "ner": [[10, 13, "product"], [19, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "parallel", "manipulator", "is", "a", "mechanical", "system", "that", "uses", "multiple", "manipulators", "in", "series", "to", "support", "a", "single", "platform", "or", "end-effector", "."], "sentence-detokenized": "A parallel manipulator is a mechanical system that uses multiple manipulators in series to support a single platform or end-effector.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 27], [28, 38], [39, 45], [46, 50], [51, 55], [56, 64], [65, 77], [78, 80], [81, 87], [88, 90], [91, 98], [99, 100], [101, 107], [108, 116], [117, 119], [120, 132], [132, 133]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [3, 4, "task"], [7, 7, "product"], [9, 18, "product"], [26, 26, "misc"], [29, 29, "misc"], [32, 33, "misc"], [36, 41, "task"], [44, 46, "product"], [49, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 7, 0, 0, "part-of", "", false, false], [7, 7, 3, 4, "type-of", "", false, false], [9, 18, 7, 7, "named", "", false, false], [26, 26, 7, 7, "part-of", "", false, false], [29, 29, 7, 7, "part-of", "", false, false], [32, 33, 7, 7, "part-of", "", false, false], [36, 41, 7, 7, "part-of", "", false, false], [44, 46, 7, 7, "part-of", "", false, false], [49, 50, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "includes", "an", "information", "extraction", "system", "called", "ANNIE", "(", "A", "Nearly", "-", "New", "Information", "Extraction", "System", ")", ",", "which", "is", "a", "set", "of", "modules", "including", "a", "tokeniser", ",", "a", "gazetteer", ",", "a", "sentence", "splitter", ",", "a", "part", "-", "of", "-", "speech", "tagger", ",", "a", "named", "entity", "recogniser", "and", "a", "correlation", "tagger", "."], "sentence-detokenized": "GATE includes an information extraction system called ANNIE (A Nearly-New Information Extraction System), which is a set of modules including a tokeniser, a gazetteer, a sentence splitter, a part-of-speech tagger, a named entity recogniser and a correlation tagger.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 28], [29, 39], [40, 46], [47, 53], [54, 59], [60, 61], [61, 62], [63, 69], [69, 70], [70, 73], [74, 85], [86, 96], [97, 103], [103, 104], [104, 105], [106, 111], [112, 114], [115, 116], [117, 120], [121, 123], [124, 131], [132, 141], [142, 143], [144, 153], [153, 154], [155, 156], [157, 166], [166, 167], [168, 169], [170, 178], [179, 187], [187, 188], [189, 190], [191, 195], [195, 196], [196, 198], [198, 199], [199, 205], [206, 212], [212, 213], [214, 215], [216, 221], [222, 228], [229, 239], [240, 243], [244, 245], [246, 257], [258, 264], [264, 265]]}
{"doc_key": "ai-dev-346", "ner": [[3, 5, "university"], [26, 26, "country"], [17, 22, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "graduated", "from", "Moscow", "State", "University", "and", "in", "November", "1978", ",", "thanks", "to", "the", "personal", "intervention", "of", "Senator", "Edward", "M.", "Kennedy", ",", "he", "went", "to", "the", "USA", "."], "sentence-detokenized": "He graduated from Moscow State University and in November 1978, thanks to the personal intervention of Senator Edward M. Kennedy, he went to the USA.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 24], [25, 30], [31, 41], [42, 45], [46, 48], [49, 57], [58, 62], [62, 63], [64, 70], [71, 73], [74, 77], [78, 86], [87, 99], [100, 102], [103, 110], [111, 117], [118, 120], [121, 128], [128, 129], [130, 132], [133, 137], [138, 140], [141, 144], [145, 148], [148, 149]]}
{"doc_key": "ai-dev-347", "ner": [[4, 6, "organisation"], [9, 14, "misc"], [18, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 9, 14, "win-defeat", "", false, false], [9, 14, 18, 18, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "the", "DeepMind", "AlphaGo", "team", "received", "the", "first", "IJCAI", "Marvin", "Minsky", "Medal", "for", "outstanding", "achievements", "in", "artificial", "intelligence", "."], "sentence-detokenized": "In 2017, the DeepMind AlphaGo team received the first IJCAI Marvin Minsky Medal for outstanding achievements in artificial intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 21], [22, 29], [30, 34], [35, 43], [44, 47], [48, 53], [54, 59], [60, 66], [67, 73], [74, 79], [80, 83], [84, 95], [96, 108], [109, 111], [112, 122], [123, 135], [135, 136]]}
{"doc_key": "ai-dev-348", "ner": [[4, 6, "misc"], [9, 12, "misc"], [16, 17, "misc"], [25, 25, "misc"], [23, 30, "misc"], [36, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 6, 9, 12, "related-to", "is_recorded_by", false, false], [9, 12, 16, 17, "cause-effect", "", false, false], [9, 12, 16, 17, "physical", "", false, false], [9, 12, 25, 25, "physical", "", false, false], [9, 12, 36, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "ways", "in", "which", "anomalous", "propagation", "is", "recorded", "include", "tropospheric", "scattering", ",", "which", "causes", "irregularities", "in", "the", "troposphere", ",", "meteor", "scattering", ",", "refraction", "in", "ionised", "regions", "and", "layers", "of", "the", "ionosphere", ",", "and", "reflection", "from", "the", "ionosphere", "."], "sentence-detokenized": "Other ways in which anomalous propagation is recorded include tropospheric scattering, which causes irregularities in the troposphere, meteor scattering, refraction in ionised regions and layers of the ionosphere, and reflection from the ionosphere.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 19], [20, 29], [30, 41], [42, 44], [45, 53], [54, 61], [62, 74], [75, 85], [85, 86], [87, 92], [93, 99], [100, 114], [115, 117], [118, 121], [122, 133], [133, 134], [135, 141], [142, 152], [152, 153], [154, 164], [165, 167], [168, 175], [176, 183], [184, 187], [188, 194], [195, 197], [198, 201], [202, 212], [212, 213], [214, 217], [218, 228], [229, 233], [234, 237], [238, 248], [248, 249]]}
{"doc_key": "ai-dev-349", "ner": [[0, 2, "field"], [4, 4, "field"], [10, 10, "field"], [12, 13, "field"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 10, 10, "part-of", "", false, false], [0, 2, 12, 13, "part-of", "", false, false], [0, 2, 15, 16, "part-of", "", false, false], [0, 2, 18, 19, "part-of", "", false, false], [4, 4, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Natural", "Language", "Processing", "(", "NLP", ")", "is", "a", "sub-discipline", "of", "linguistics", ",", "computer", "science", ",", "information", "engineering", "and", "artificial", "intelligence", "that", "deals", "with", "the", "interaction", "between", "computers", "and", "human", "(", "natural", ")", "language", ",", "in", "particular", "how", "to", "program", "computers", "to", "process", "and", "analyse", "large", "amounts", "of", "natural", "language", "data", "."], "sentence-detokenized": "Natural Language Processing (NLP) is a sub-discipline of linguistics, computer science, information engineering and artificial intelligence that deals with the interaction between computers and human (natural) language, in particular how to program computers to process and analyse large amounts of natural language data.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [29, 32], [32, 33], [34, 36], [37, 38], [39, 53], [54, 56], [57, 68], [68, 69], [70, 78], [79, 86], [86, 87], [88, 99], [100, 111], [112, 115], [116, 126], [127, 139], [140, 144], [145, 150], [151, 155], [156, 159], [160, 171], [172, 179], [180, 189], [190, 193], [194, 199], [200, 201], [201, 208], [208, 209], [210, 218], [218, 219], [220, 222], [223, 233], [234, 237], [238, 240], [241, 248], [249, 258], [259, 261], [262, 269], [270, 273], [274, 281], [282, 287], [288, 295], [296, 298], [299, 306], [307, 315], [316, 320], [320, 321]]}
{"doc_key": "ai-dev-350", "ner": [[8, 9, "organisation"], [11, 12, "organisation"], [14, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "active", "youth", "-", "led", "climate", "groups", "include", "Extinction", "Rebellion", ",", "Sunrise", "Movement", ",", "SustainUS", "and", "others", ",", "working", "both", "internationally", "and", "locally", "."], "sentence-detokenized": "Other active youth-led climate groups include Extinction Rebellion, Sunrise Movement, SustainUS and others, working both internationally and locally.", "token2charspan": [[0, 5], [6, 12], [13, 18], [18, 19], [19, 22], [23, 30], [31, 37], [38, 45], [46, 56], [57, 66], [66, 67], [68, 75], [76, 84], [84, 85], [86, 95], [96, 99], [100, 106], [106, 107], [108, 115], [116, 120], [121, 136], [137, 140], [141, 148], [148, 149]]}
