{"doc_key": "ai-train-1", "ner": [[1, 5, "product"], [14, 15, "field"], [17, 18, "task"], [20, 21, "task"], [25, 27, "task"], [30, 31, "field"], [32, 34, "researcher"], [36, 38, "researcher"], [40, 41, "researcher"], [43, 44, "researcher"], [46, 48, "researcher"], [50, 51, "researcher"], [53, 54, "researcher"], [56, 57, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[1, 5, 14, 15, "part-of", "", false, false], [1, 5, 14, 15, "usage", "", false, false], [1, 5, 17, 18, "part-of", "", false, false], [1, 5, 17, 18, "usage", "", false, false], [1, 5, 20, 21, "part-of", "", false, false], [1, 5, 20, 21, "usage", "", false, false], [1, 5, 30, 31, "part-of", "", false, false], [1, 5, 30, 31, "usage", "", false, false], [25, 27, 20, 21, "part-of", "", false, false], [25, 27, 20, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Popular", "opinion", "-", "based", "recommender", "system", "approaches", "use", "a", "variety", "of", "methods", ",", "including", "text", "mining", ",", "information", "retrieval", ",", "sentiment", "analysis", "(", "see", "also", "multimodal", "sentiment", "analysis", ")", "and", "deep", "learning", "X.Y", ".", "Feng", ",", "H", ".", "Zhang", ",", "Y.J.", "Ren", ",", "P.H.", "Shang", ",", "Y", ".", "Zhu", ",", "Y.C.", "Liang", ",", "R.C.", "Guan", ",", "D.", "Xu", ",", "(", "2019", ")", ",", ",", "21", "(", "5", ")", ":", "e12957", "."], "sentence-detokenized": "Popular opinion-based recommender system approaches use a variety of methods, including text mining, information retrieval, sentiment analysis (see also multimodal sentiment analysis) and deep learning X.Y. Feng, H. Zhang, Y.J. Ren, P.H. Shang, Y. Zhu, Y.C. Liang, R.C. Guan, D. Xu, (2019),, 21 (5): e12957.", "token2charspan": [[0, 7], [8, 15], [15, 16], [16, 21], [22, 33], [34, 40], [41, 51], [52, 55], [56, 57], [58, 65], [66, 68], [69, 76], [76, 77], [78, 87], [88, 92], [93, 99], [99, 100], [101, 112], [113, 122], [122, 123], [124, 133], [134, 142], [143, 144], [144, 147], [148, 152], [153, 163], [164, 173], [174, 182], [182, 183], [184, 187], [188, 192], [193, 201], [202, 205], [205, 206], [207, 211], [211, 212], [213, 214], [214, 215], [216, 221], [221, 222], [223, 227], [228, 231], [231, 232], [233, 237], [238, 243], [243, 244], [245, 246], [246, 247], [248, 251], [251, 252], [253, 257], [258, 263], [263, 264], [265, 269], [270, 274], [274, 275], [276, 278], [279, 281], [281, 282], [283, 284], [284, 288], [288, 289], [289, 290], [290, 291], [292, 294], [295, 296], [296, 297], [297, 298], [298, 299], [300, 306], [306, 307]]}
{"doc_key": "ai-train-2", "ner": [[8, 8, "university"], [12, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 8, 8, "physical", "", false, false], [12, 13, 8, 8, "role", "", false, false], [15, 16, 8, 8, "physical", "", false, false], [15, 16, 8, 8, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "advocates", "of", "procedural", "representations", "focused", "mainly", "on", "MIT", ",", "led", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "."], "sentence-detokenized": "The advocates of procedural representations focused mainly on MIT, led by Marvin Minsky and Seymour Papert.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 27], [28, 43], [44, 51], [52, 58], [59, 61], [62, 65], [65, 66], [67, 70], [71, 73], [74, 80], [81, 87], [88, 91], [92, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-train-3", "ner": [[10, 10, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "standard", "interface", "and", "the", "calculator", "interface", "are", "written", "in", "Java", "."], "sentence-detokenized": "The standard interface and the calculator interface are written in Java.", "token2charspan": [[0, 3], [4, 12], [13, 22], [23, 26], [27, 30], [31, 41], [42, 51], [52, 55], [56, 63], [64, 66], [67, 71], [71, 72]]}
{"doc_key": "ai-train-4", "ner": [[0, 0, "product"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 21, 21, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["Octave", "helps", "you", "solve", "linear", "and", "non-linear", "numerical", "problems", "and", "perform", "other", "numerical", "experiments", "using", "software", "that", "is", "mostly", "compatible", "with", "MATLAB", "."], "sentence-detokenized": "Octave helps you solve linear and non-linear numerical problems and perform other numerical experiments using software that is mostly compatible with MATLAB.", "token2charspan": [[0, 6], [7, 12], [13, 16], [17, 22], [23, 29], [30, 33], [34, 44], [45, 54], [55, 63], [64, 67], [68, 75], [76, 81], [82, 91], [92, 103], [104, 109], [110, 118], [119, 123], [124, 126], [127, 133], [134, 144], [145, 149], [150, 156], [156, 157]]}
{"doc_key": "ai-train-5", "ner": [[2, 4, "algorithm"], [20, 21, "misc"], [24, 25, "researcher"], [31, 33, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 4, 24, 25, "origin", "", false, false], [20, 21, 24, 25, "origin", "", false, false], [24, 25, 31, 33, "physical", "", false, false], [24, 25, 31, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Variants", "of", "the", "backpropagation", "algorithm", "can", "be", "used", "to", "train", "deep", ",", "highly", "non-linear", "neural", "architectures", ",", "as", "well", "as", "unsupervised", "methods", "developed", "by", "Jeff", "Hinton", "and", "his", "colleagues", "at", "the", "University", "of", "Toronto", ",", "{{", "cite", "journal"], "sentence-detokenized": "Variants of the backpropagation algorithm can be used to train deep, highly non-linear neural architectures, as well as unsupervised methods developed by Jeff Hinton and his colleagues at the University of Toronto, {{cite journal", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 31], [32, 41], [42, 45], [46, 48], [49, 53], [54, 56], [57, 62], [63, 67], [67, 68], [69, 75], [76, 86], [87, 93], [94, 107], [107, 108], [109, 111], [112, 116], [117, 119], [120, 132], [133, 140], [141, 150], [151, 153], [154, 158], [159, 165], [166, 169], [170, 173], [174, 184], [185, 187], [188, 191], [192, 202], [203, 205], [206, 213], [213, 214], [215, 217], [217, 221], [222, 229]]}
{"doc_key": "ai-train-6", "ner": [[3, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "equivalent", "using", "DCG", "notation", ":"], "sentence-detokenized": "or equivalent using DCG notation:", "token2charspan": [[0, 2], [3, 13], [14, 19], [20, 23], [24, 32], [32, 33]]}
{"doc_key": "ai-train-7", "ner": [[0, 3, "algorithm"], [7, 12, "algorithm"], [14, 16, "algorithm"], [18, 21, "algorithm"], [23, 25, "algorithm"], [27, 35, "algorithm"], [41, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 7, 12, "type-of", "", false, false], [0, 3, 14, 16, "usage", "part-of?", true, false], [14, 16, 18, 21, "compare", "", false, false], [23, 25, 18, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Self", "-", "organising", "maps", "differ", "from", "other", "artificial", "neural", "networks", "in", "that", "they", "use", "competitive", "learning", "rather", "than", "error", "-correction", "learning", "such", "as", "back", "-", "propagation", "with", "gradient", "descent", ",", "and", "in", "that", "they", "use", "a", "neighbourhood", "function", "to", "preserve", "the", "topological", "properties", "of", "the", "input", "space", "."], "sentence-detokenized": "Self-organising maps differ from other artificial neural networks in that they use competitive learning rather than error-correction learning such as back-propagation with gradient descent, and in that they use a neighbourhood function to preserve the topological properties of the input space.", "token2charspan": [[0, 4], [4, 5], [5, 15], [16, 20], [21, 27], [28, 32], [33, 38], [39, 49], [50, 56], [57, 65], [66, 68], [69, 73], [74, 78], [79, 82], [83, 94], [95, 103], [104, 110], [111, 115], [116, 121], [121, 132], [133, 141], [142, 146], [147, 149], [150, 154], [154, 155], [155, 166], [167, 171], [172, 180], [181, 188], [188, 189], [190, 193], [194, 196], [197, 201], [202, 206], [207, 210], [211, 212], [213, 226], [227, 235], [236, 238], [239, 247], [248, 251], [252, 263], [264, 274], [275, 277], [278, 281], [282, 287], [288, 293], [293, 294]]}
{"doc_key": "ai-train-8", "ner": [[10, 13, "organisation"], [26, 30, "misc"], [33, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "the", "early", "1990s", ",", "several", "bodies", ",", "including", "the", "Society", "of", "Audio", "Engineers", ",", "have", "recommended", "that", "dynamic", "range", "measurements", "should", "be", "made", "using", "a", "sound", "signal", "which", "is", "then", "filtered", "into", "a", "noise", "floor", "measurement", "used", "to", "determine", "dynamic", "range", ".", "This", "avoids", "questionable", "measurements", "based", "on", "the", "use", "of", "blank", "media", "or", "exclusion", "schemes", "."], "sentence-detokenized": "Since the early 1990s, several bodies, including the Society of Audio Engineers, have recommended that dynamic range measurements should be made using a sound signal which is then filtered into a noise floor measurement used to determine dynamic range. This avoids questionable measurements based on the use of blank media or exclusion schemes.", "token2charspan": [[0, 5], [6, 9], [10, 15], [16, 21], [21, 22], [23, 30], [31, 37], [37, 38], [39, 48], [49, 52], [53, 60], [61, 63], [64, 69], [70, 79], [79, 80], [81, 85], [86, 97], [98, 102], [103, 110], [111, 116], [117, 129], [130, 136], [137, 139], [140, 144], [145, 150], [151, 152], [153, 158], [159, 165], [166, 171], [172, 174], [175, 179], [180, 188], [189, 193], [194, 195], [196, 201], [202, 207], [208, 219], [220, 224], [225, 227], [228, 237], [238, 245], [246, 251], [251, 252], [253, 257], [258, 264], [265, 277], [278, 290], [291, 296], [297, 299], [300, 303], [304, 307], [308, 310], [311, 316], [317, 322], [323, 325], [326, 335], [336, 343], [343, 344]]}
{"doc_key": "ai-train-9", "ner": [[7, 9, "misc"], [12, 13, "task"], [15, 16, "task"], [18, 19, "task"], [21, 22, "task"], [24, 24, "task"], [25, 29, "task"], [31, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[7, 9, 12, 13, "part-of", "concept_used_in", true, false], [7, 9, 15, 16, "part-of", "concept_used_in", false, false], [7, 9, 18, 19, "part-of", "concept_used_in", false, false], [7, 9, 21, 22, "part-of", "concept_used_in", false, false], [7, 9, 24, 24, "part-of", "concept_used_in", false, false], [7, 9, 25, 29, "part-of", "concept_used_in", false, false], [7, 9, 31, 33, "part-of", "concept_used_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "techniques", "used", "to", "create", "and", "recognise", "faces", "are", "also", "used", "beyond", "face", "recognition", ":", "handwriting", "recognition", ",", "lip", "reading", ",", "voice", "recognition", ",", "sign", "language", "/", "hand", "gesture", "interpretation", "and", "medical", "image", "analysis", "."], "sentence-detokenized": "The techniques used to create and recognise faces are also used beyond face recognition: handwriting recognition, lip reading, voice recognition, sign language/hand gesture interpretation and medical image analysis.", "token2charspan": [[0, 3], [4, 14], [15, 19], [20, 22], [23, 29], [30, 33], [34, 43], [44, 49], [50, 53], [54, 58], [59, 63], [64, 70], [71, 75], [76, 87], [87, 88], [89, 100], [101, 112], [112, 113], [114, 117], [118, 125], [125, 126], [127, 132], [133, 144], [144, 145], [146, 150], [151, 159], [159, 160], [160, 164], [165, 172], [173, 187], [188, 191], [192, 199], [200, 205], [206, 214], [214, 215]]}
{"doc_key": "ai-train-10", "ner": [[0, 3, "organisation"], [9, 14, "organisation"], [16, 16, "organisation"], [20, 23, "organisation"], [26, 30, "organisation"], [33, 36, "organisation"], [39, 43, "organisation"], [45, 45, "organisation"], [49, 54, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[9, 14, 0, 3, "part-of", "", false, false], [16, 16, 9, 14, "named", "", false, false], [20, 23, 0, 3, "part-of", "", false, false], [26, 30, 0, 3, "part-of", "", false, false], [33, 36, 0, 3, "part-of", "", false, false], [39, 43, 0, 3, "part-of", "", false, false], [45, 45, 39, 43, "named", "", false, false], [49, 54, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "National", "Science", "Foundation", "was", "the", "umbrella", "organisation", "for", "the", "National", "Aeronautics", "and", "Space", "Administration", "(", "NASA", ")", ",", "the", "US", "Department", "of", "Energy", ",", "the", "US", "Department", "of", "Commerce", "NIST", ",", "the", "US", "Department", "of", "Defense", ",", "the", "Defense", "Advanced", "Research", "Projects", "Agency", "(", "DARPA", ")", "and", "the", "Office", "of", "Naval", "Research", ",", "which", "coordinated", "research", "to", "inform", "strategic", "planners", "in", "their", "considerations", "."], "sentence-detokenized": "The National Science Foundation was the umbrella organisation for the National Aeronautics and Space Administration (NASA), the US Department of Energy, the US Department of Commerce NIST, the US Department of Defense, the Defense Advanced Research Projects Agency (DARPA) and the Office of Naval Research, which coordinated research to inform strategic planners in their considerations.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 35], [36, 39], [40, 48], [49, 61], [62, 65], [66, 69], [70, 78], [79, 90], [91, 94], [95, 100], [101, 115], [116, 117], [117, 121], [121, 122], [122, 123], [124, 127], [128, 130], [131, 141], [142, 144], [145, 151], [151, 152], [153, 156], [157, 159], [160, 170], [171, 173], [174, 182], [183, 187], [187, 188], [189, 192], [193, 195], [196, 206], [207, 209], [210, 217], [217, 218], [219, 222], [223, 230], [231, 239], [240, 248], [249, 257], [258, 264], [265, 266], [266, 271], [271, 272], [273, 276], [277, 280], [281, 287], [288, 290], [291, 296], [297, 305], [305, 306], [307, 312], [313, 324], [325, 333], [334, 336], [337, 343], [344, 353], [354, 362], [363, 365], [366, 371], [372, 386], [386, 387]]}
{"doc_key": "ai-train-11", "ner": [[18, 19, "metrics"], [21, 24, "algorithm"], [0, 4, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[18, 19, 21, 24, "part-of", "", false, false], [0, 4, 10, 11, "related-to", "added_appendix_to_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1935", ",", "Ronald", "Fisher", "proposed", "in", "an", "appendix", "to", "Bliss", "'s", "paper", "a", "fast", "method", "for", "calculating", "maximum", "likelihood", "estimates", "for", "the", "probit", "model", "."], "sentence-detokenized": "In 1935, Ronald Fisher proposed in an appendix to Bliss's paper a fast method for calculating maximum likelihood estimates for the probit model.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 22], [23, 31], [32, 34], [35, 37], [38, 46], [47, 49], [50, 55], [55, 57], [58, 63], [64, 65], [66, 70], [71, 77], [78, 81], [82, 93], [94, 101], [102, 112], [113, 122], [123, 126], [127, 130], [131, 137], [138, 143], [143, 144]]}
{"doc_key": "ai-train-12", "ner": [[10, 11, "product"], [14, 17, "product"], [19, 19, "organisation"], [20, 20, "product"], [23, 23, "organisation"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 20, 14, 17, "usage", "uses_software", false, false], [20, 20, 19, 19, "artifact", "", false, false], [20, 20, 24, 24, "named", "", false, false], [24, 24, 23, 23, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Several", "of", "these", "programmes", "are", "available", "online", ",", "such", "as", "Google", "Translate", "and", "the", "SYSTRAN", "system", ",", "which", "provides", "AltaVista", "BabelFish", "(", "now", "Yahoo", "Babelfish", "since", "9", "May", "2008", ")", "."], "sentence-detokenized": "Several of these programmes are available online, such as Google Translate and the SYSTRAN system, which provides AltaVista BabelFish (now Yahoo Babelfish since 9 May 2008).", "token2charspan": [[0, 7], [8, 10], [11, 16], [17, 27], [28, 31], [32, 41], [42, 48], [48, 49], [50, 54], [55, 57], [58, 64], [65, 74], [75, 78], [79, 82], [83, 90], [91, 97], [97, 98], [99, 104], [105, 113], [114, 123], [124, 133], [134, 135], [135, 138], [139, 144], [145, 154], [155, 160], [161, 162], [163, 166], [167, 171], [171, 172], [172, 173]]}
{"doc_key": "ai-train-13", "ner": [[0, 3, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [20, 24, "field"], [26, 27, "misc"], [31, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 20, 24, "related-to", "", true, false], [0, 3, 26, 27, "related-to", "", true, false], [0, 3, 31, 32, "related-to", "", true, false], [7, 8, 20, 24, "related-to", "", true, false], [7, 8, 26, 27, "related-to", "", true, false], [7, 8, 31, 32, "related-to", "", true, false], [10, 11, 20, 24, "related-to", "", true, false], [10, 11, 26, 27, "related-to", "", true, false], [10, 11, 31, 32, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "2002", ",", "H\u00fctter", ",", "together", "with", "J\u00fcrgen", "Schmidhuber", "and", "Shane", "Legg", ",", "developed", "and", "published", "a", "mathematical", "theory", "of", "artificial", "general", "intelligence", "based", "on", "idealised", "intelligent", "agents", "and", "reward", "-driven", "reinforcement", "learning", "."], "sentence-detokenized": "In 2002, H\u00fctter, together with J\u00fcrgen Schmidhuber and Shane Legg, developed and published a mathematical theory of artificial general intelligence based on idealised intelligent agents and reward-driven reinforcement learning.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [15, 16], [17, 25], [26, 30], [31, 37], [38, 49], [50, 53], [54, 59], [60, 64], [64, 65], [66, 75], [76, 79], [80, 89], [90, 91], [92, 104], [105, 111], [112, 114], [115, 125], [126, 133], [134, 146], [147, 152], [153, 155], [156, 165], [166, 177], [178, 184], [185, 188], [189, 195], [195, 202], [203, 216], [217, 225], [225, 226]]}
{"doc_key": "ai-train-14", "ner": [[11, 11, "metrics"], [13, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 11, 13, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "most", "common", "way", "is", "to", "use", "the", "so", "-", "called", "ROUGE", "(", "Recall", "-", "Oriented", "Understudy", "for", "Gisting", "Evaluation", ")", "measure", "."], "sentence-detokenized": "The most common way is to use the so-called ROUGE (Recall-Oriented Understudy for Gisting Evaluation) measure.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 19], [20, 22], [23, 25], [26, 29], [30, 33], [34, 36], [36, 37], [37, 43], [44, 49], [50, 51], [51, 57], [57, 58], [58, 66], [67, 77], [78, 81], [82, 89], [90, 100], [100, 101], [102, 109], [109, 110]]}
{"doc_key": "ai-train-15", "ner": [[0, 0, "product"], [14, 14, "programlang"], [16, 16, "programlang"], [19, 20, "researcher"], [22, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 14, 14, "related-to", "", false, false], [0, 0, 16, 16, "related-to", "", false, false], [19, 20, 22, 25, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["RapidMiner", "provides", "training", "schemes", ",", "models", "and", "algorithms", ",", "and", "can", "be", "extended", "using", "R", "and", "Python", "scripts", ".", "David", "Norris", ",", "Bloor", "Research", ",", "13", "November", "2013", "."], "sentence-detokenized": "RapidMiner provides training schemes, models and algorithms, and can be extended using R and Python scripts. David Norris, Bloor Research, 13 November 2013.", "token2charspan": [[0, 10], [11, 19], [20, 28], [29, 36], [36, 37], [38, 44], [45, 48], [49, 59], [59, 60], [61, 64], [65, 68], [69, 71], [72, 80], [81, 86], [87, 88], [89, 92], [93, 99], [100, 107], [107, 108], [109, 114], [115, 121], [121, 122], [123, 128], [129, 137], [137, 138], [139, 141], [142, 150], [151, 155], [155, 156]]}
{"doc_key": "ai-train-16", "ner": [[32, 32, "product"], [5, 7, "programlang"], [10, 21, "product"]], "ner_mapping_to_source": [0, 4, 5], "relations": [[32, 32, 10, 21, "related-to", "", true, false], [10, 21, 5, 7, "general-affiliation", "", true, false]], "relations_mapping_to_source": [2, 4], "sentence": ["However", ",", "the", "latest", "fully", "Java", "-", "based", "version", "(", "Weka", "3", ")", ",", "launched", "in", "1997", ",", "is", "now", "used", "in", "many", "different", "application", "areas", ",", "especially", "for", "education", "and", "research", "."], "sentence-detokenized": "However, the latest fully Java-based version (Weka 3), launched in 1997, is now used in many different application areas, especially for education and research.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 19], [20, 25], [26, 30], [30, 31], [31, 36], [37, 44], [45, 46], [46, 50], [51, 52], [52, 53], [53, 54], [55, 63], [64, 66], [67, 71], [71, 72], [73, 75], [76, 79], [80, 84], [85, 87], [88, 92], [93, 102], [103, 114], [115, 120], [120, 121], [122, 132], [133, 136], [137, 146], [147, 150], [151, 159], [159, 160]]}
{"doc_key": "ai-train-17", "ner": [[0, 0, "product"], [12, 21, "misc"], [24, 26, "misc"], [27, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 21, 0, 0, "topic", "", false, false], [12, 21, 24, 26, "win-defeat", "", false, false], [24, 26, 27, 37, "temporal", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Eurisko", "made", "many", "interesting", "discoveries", "and", "was", "highly", "acclaimed", "for", "his", "work", "Heuretics", ":", "Theoretical", "and", "Research", "on", "Heuristic", "Rules", ",", "which", "won", "the", "best", "paper", "award", "at", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "in", "1982", "."], "sentence-detokenized": "Eurisko made many interesting discoveries and was highly acclaimed for his work Heuretics: Theoretical and Research on Heuristic Rules, which won the best paper award at the Association for the Advancement of Artificial Intelligence in 1982.", "token2charspan": [[0, 7], [8, 12], [13, 17], [18, 29], [30, 41], [42, 45], [46, 49], [50, 56], [57, 66], [67, 70], [71, 74], [75, 79], [80, 89], [89, 90], [91, 102], [103, 106], [107, 115], [116, 118], [119, 128], [129, 134], [134, 135], [136, 141], [142, 145], [146, 149], [150, 154], [155, 160], [161, 166], [167, 169], [170, 173], [174, 185], [186, 189], [190, 193], [194, 205], [206, 208], [209, 219], [220, 232], [233, 235], [236, 240], [240, 241]]}
{"doc_key": "ai-train-18", "ner": [[8, 14, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["To", "account", "for", "multiple", "units", ",", "a", "separate", "pivot", "loss", "is", "calculated", "for", "each", "capsule", "."], "sentence-detokenized": "To account for multiple units, a separate pivot loss is calculated for each capsule.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 23], [24, 29], [29, 30], [31, 32], [33, 41], [42, 47], [48, 52], [53, 55], [56, 66], [67, 70], [71, 75], [76, 83], [83, 84]]}
{"doc_key": "ai-train-19", "ner": [[8, 9, "product"], [11, 12, "product"], [14, 15, "product"], [17, 18, "product"], [20, 21, "product"], [23, 24, "product"], [33, 38, "product"], [40, 41, "product"], [43, 44, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 9, 23, 24, "type-of", "", false, false], [11, 12, 23, 24, "type-of", "", false, false], [14, 15, 23, 24, "type-of", "", false, false], [17, 18, 23, 24, "type-of", "", false, false], [20, 21, 23, 24, "type-of", "", false, false], [40, 41, 33, 38, "type-of", "", false, false], [43, 44, 33, 38, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["With", "the", "advent", "of", "conversational", "assistants", "such", "as", "Apple", "Siri", ",", "Amazon", "Alexa", ",", "Google", "Assistant", ",", "Microsoft", "Cortana", "and", "Samsung", "Bixby", ",", "voice", "portals", "can", "now", "be", "accessed", "via", "mobile", "devices", "and", "Far", "Field", "voice", "smart", "speakers", "such", "as", "Amazon", "Echo", "and", "Google", "Home", "."], "sentence-detokenized": "With the advent of conversational assistants such as Apple Siri, Amazon Alexa, Google Assistant, Microsoft Cortana and Samsung Bixby, voice portals can now be accessed via mobile devices and Far Field voice smart speakers such as Amazon Echo and Google Home.", "token2charspan": [[0, 4], [5, 8], [9, 15], [16, 18], [19, 33], [34, 44], [45, 49], [50, 52], [53, 58], [59, 63], [63, 64], [65, 71], [72, 77], [77, 78], [79, 85], [86, 95], [95, 96], [97, 106], [107, 114], [115, 118], [119, 126], [127, 132], [132, 133], [134, 139], [140, 147], [148, 151], [152, 155], [156, 158], [159, 167], [168, 171], [172, 178], [179, 186], [187, 190], [191, 194], [195, 200], [201, 206], [207, 212], [213, 221], [222, 226], [227, 229], [230, 236], [237, 241], [242, 245], [246, 252], [253, 257], [257, 258]]}
{"doc_key": "ai-train-20", "ner": [[2, 3, "field"], [6, 8, "algorithm"], [10, 12, "algorithm"], [14, 15, "algorithm"], [18, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 2, 3, "type-of", "", false, false], [10, 12, 2, 3, "type-of", "", false, false], [14, 15, 2, 3, "type-of", "", false, false], [18, 18, 2, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Examples", "of", "supervised", "learning", "are", "the", "Naive", "Bayes", "classifier", ",", "support", "vector", "machine", ",", "Gaussian", "mixtures", "and", "the", "network", "."], "sentence-detokenized": "Examples of supervised learning are the Naive Bayes classifier, support vector machine, Gaussian mixtures and the network.", "token2charspan": [[0, 8], [9, 11], [12, 22], [23, 31], [32, 35], [36, 39], [40, 45], [46, 51], [52, 62], [62, 63], [64, 71], [72, 78], [79, 86], [86, 87], [88, 96], [97, 105], [106, 109], [110, 113], [114, 121], [121, 122]]}
{"doc_key": "ai-train-21", "ner": [[0, 2, "algorithm"], [25, 27, "algorithm"], [28, 28, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 25, 27, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "OSD", "algorithm", "can", "be", "used", "to", "derive", "mathematical", "O", "(", "\\", "sqrt", "{", "T", "})", "/mathematical", "regret", "bounds", "for", "the", "online", "version", "of", "the", "support", "vector", "machine", "classification", ",", "which", "uses", "mathematical", "v", "_t", "(", "w", ")", "=\\", "max", "\\", "{", "0", ",", "1", "-", "y", "_t", "(", "w", "\\", "cdot", "x", "_t", ")", "\\}.", "/", "math"], "sentence-detokenized": "The OSD algorithm can be used to derive mathematical O(\\ sqrt {T})/mathematical regret bounds for the online version of the support vector machine classification, which uses mathematical v _t (w) =\\ max\\ {0, 1 - y _t (w\\ cdot x _t)\\}. / math", "token2charspan": [[0, 3], [4, 7], [8, 17], [18, 21], [22, 24], [25, 29], [30, 32], [33, 39], [40, 52], [53, 54], [54, 55], [55, 56], [57, 61], [62, 63], [63, 64], [64, 66], [66, 79], [80, 86], [87, 93], [94, 97], [98, 101], [102, 108], [109, 116], [117, 119], [120, 123], [124, 131], [132, 138], [139, 146], [147, 161], [161, 162], [163, 168], [169, 173], [174, 186], [187, 188], [189, 191], [192, 193], [193, 194], [194, 195], [196, 198], [199, 202], [202, 203], [204, 205], [205, 206], [206, 207], [208, 209], [210, 211], [212, 213], [214, 216], [217, 218], [218, 219], [219, 220], [221, 225], [226, 227], [228, 230], [230, 231], [231, 234], [235, 236], [237, 241]]}
{"doc_key": "ai-train-22", "ner": [[2, 3, "task"], [5, 6, "task"], [8, 8, "task"], [10, 11, "task"], [13, 14, "task"], [16, 17, "task"], [19, 20, "task"], [22, 24, "task"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Applications", "include", "object", "recognition", ",", "robotic", "mapping", "and", "navigation", ",", "image", "stitching", ",", "3D", "modelling", ",", "gesture", "recognition", ",", "video", "tracking", ",", "individual", "wildlife", "identification", "and", "coordinated", "movement", "."], "sentence-detokenized": "Applications include object recognition, robotic mapping and navigation, image stitching, 3D modelling, gesture recognition, video tracking, individual wildlife identification and coordinated movement.", "token2charspan": [[0, 12], [13, 20], [21, 27], [28, 39], [39, 40], [41, 48], [49, 56], [57, 60], [61, 71], [71, 72], [73, 78], [79, 88], [88, 89], [90, 92], [93, 102], [102, 103], [104, 111], [112, 123], [123, 124], [125, 130], [131, 139], [139, 140], [141, 151], [152, 160], [161, 175], [176, 179], [180, 191], [192, 200], [200, 201]]}
{"doc_key": "ai-train-23", "ner": [[2, 3, "task"], [15, 17, "university"], [19, 21, "university"], [23, 24, "university"], [26, 27, "university"], [29, 33, "university"], [35, 37, "university"], [39, 41, "university"], [43, 44, "university"], [46, 51, "university"], [53, 53, "university"], [56, 59, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[2, 3, 15, 17, "related-to", "", true, false], [2, 3, 19, 21, "related-to", "", true, false], [2, 3, 23, 24, "related-to", "", true, false], [2, 3, 26, 27, "related-to", "", true, false], [2, 3, 29, 33, "related-to", "", true, false], [2, 3, 35, 37, "related-to", "", true, false], [2, 3, 39, 41, "related-to", "", true, false], [2, 3, 43, 44, "related-to", "", true, false], [2, 3, 46, 51, "related-to", "", true, false], [2, 3, 53, 53, "related-to", "", true, false], [2, 3, 56, 59, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Research", "on", "pose", "estimation", "is", "carried", "out", "by", "several", "groups", "and", "companies", ",", "including", "groups", "at", "Brown", "University", ",", "Carnegie", "Mellon", "University", ",", "MPI", "Saarbruecken", ",", "Stanford", "University", ",", "University", "of", "California", "San", "Diego", ",", "University", "of", "Toronto", ",", "Paris", "Central", "School", ",", "ETH", "Zurich", ",", "National", "University", "of", "Science", "and", "Technology", "(", "NUST", ")", "and", "University", "of", "California", "Irvine", "."], "sentence-detokenized": "Research on pose estimation is carried out by several groups and companies, including groups at Brown University, Carnegie Mellon University, MPI Saarbruecken, Stanford University, University of California San Diego, University of Toronto, Paris Central School, ETH Zurich, National University of Science and Technology (NUST) and University of California Irvine.", "token2charspan": [[0, 8], [9, 11], [12, 16], [17, 27], [28, 30], [31, 38], [39, 42], [43, 45], [46, 53], [54, 60], [61, 64], [65, 74], [74, 75], [76, 85], [86, 92], [93, 95], [96, 101], [102, 112], [112, 113], [114, 122], [123, 129], [130, 140], [140, 141], [142, 145], [146, 158], [158, 159], [160, 168], [169, 179], [179, 180], [181, 191], [192, 194], [195, 205], [206, 209], [210, 215], [215, 216], [217, 227], [228, 230], [231, 238], [238, 239], [240, 245], [246, 253], [254, 260], [260, 261], [262, 265], [266, 272], [272, 273], [274, 282], [283, 293], [294, 296], [297, 304], [305, 308], [309, 319], [320, 321], [321, 325], [325, 326], [327, 330], [331, 341], [342, 344], [345, 355], [356, 362], [362, 363]]}
{"doc_key": "ai-train-24", "ner": [[0, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sigmoid", "function", "of", "Cross", "entropy", "loss", "used", "to", "predict", "K", "independent", "probability", "values", "in", "maths", "0,1", "/", "maths", "."], "sentence-detokenized": "Sigmoid function of Cross entropy loss used to predict K independent probability values in maths 0,1 / maths.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 25], [26, 33], [34, 38], [39, 43], [44, 46], [47, 54], [55, 56], [57, 68], [69, 80], [81, 87], [88, 90], [91, 96], [97, 100], [101, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-train-25", "ner": [[10, 11, "misc"], [13, 14, "field"], [16, 17, "field"], [18, 21, "university"], [24, 25, "country"], [28, 31, "misc"], [32, 37, "university"], [38, 38, "country"], [4, 5, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[10, 11, 13, 14, "topic", "", false, false], [10, 11, 16, 17, "topic", "", false, false], [10, 11, 18, 21, "physical", "", true, false], [18, 21, 24, 25, "physical", "", false, false], [28, 31, 32, 37, "physical", "", true, false], [32, 37, 38, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Before", "becoming", "a", "Professor", "at", "Cambridge", ",", "he", "held", "the", "Johann", "Bernoulli", "Chair", "in", "Mathematics", "and", "Computer", "Science", "at", "the", "University", "of", "Groningen", "in", "the", "Netherlands", "and", "the", "Toshiba", "Endowed", "Chair", "at", "the", "Tokyo", "Institute", "of", "Technology", "in", "Japan", "."], "sentence-detokenized": "Before becoming a Professor at Cambridge, he held the Johann Bernoulli Chair in Mathematics and Computer Science at the University of Groningen in the Netherlands and the Toshiba Endowed Chair at the Tokyo Institute of Technology in Japan.", "token2charspan": [[0, 6], [7, 15], [16, 17], [18, 27], [28, 30], [31, 40], [40, 41], [42, 44], [45, 49], [50, 53], [54, 60], [61, 70], [71, 76], [77, 79], [80, 91], [92, 95], [96, 104], [105, 112], [113, 115], [116, 119], [120, 130], [131, 133], [134, 143], [144, 146], [147, 150], [151, 162], [163, 166], [167, 170], [171, 178], [179, 186], [187, 192], [193, 195], [196, 199], [200, 205], [206, 215], [216, 218], [219, 229], [230, 232], [233, 238], [238, 239]]}
{"doc_key": "ai-train-26", "ner": [[5, 6, "algorithm"], [10, 14, "algorithm"], [16, 16, "algorithm"], [20, 22, "researcher"], [24, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 10, 14, "usage", "", true, false], [10, 14, 20, 22, "origin", "", false, false], [10, 14, 24, 27, "origin", "", false, false], [16, 16, 10, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Another", "method", "used", "specifically", "in", "recurrent", "neural", "networks", "is", "the", "Long", "Short", "-", "Term", "Memory", "(", "LSTM", ")", "network", "developed", "by", "Sepp", "Hochreiter", "&", "J\u00fcrgen", "Schmidhuber", "in", "1997", "."], "sentence-detokenized": "Another method used specifically in recurrent neural networks is the Long Short-Term Memory (LSTM) network developed by Sepp Hochreiter & J\u00fcrgen Schmidhuber in 1997.", "token2charspan": [[0, 7], [8, 14], [15, 19], [20, 32], [33, 35], [36, 45], [46, 52], [53, 61], [62, 64], [65, 68], [69, 73], [74, 79], [79, 80], [80, 84], [85, 91], [92, 93], [93, 97], [97, 98], [99, 106], [107, 116], [117, 119], [120, 124], [125, 135], [136, 137], [138, 144], [145, 156], [157, 159], [160, 164], [164, 165]]}
{"doc_key": "ai-train-27", "ner": [[4, 5, "programlang"], [8, 9, "product"], [15, 15, "product"], [44, 44, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 4, 5, "general-affiliation", "", false, false], [8, 9, 15, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "inclusion", "of", "a", "C", "++", "interpreter", "(", "CI", "NT", "up", "to", "version", "5.34", ",", "Cling", "from", "version", "6", ")", "makes", "this", "package", "very", "versatile", "as", "it", "can", "be", "used", "in", "interactive", ",", "scripted", "and", "compiled", "modes", ",", "similar", "to", "commercial", "products", "such", "as", "MATLAB", "."], "sentence-detokenized": "The inclusion of a C++ interpreter (CINT up to version 5.34, Cling from version 6) makes this package very versatile as it can be used in interactive, scripted and compiled modes, similar to commercial products such as MATLAB.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 18], [19, 20], [20, 22], [23, 34], [35, 36], [36, 38], [38, 40], [41, 43], [44, 46], [47, 54], [55, 59], [59, 60], [61, 66], [67, 71], [72, 79], [80, 81], [81, 82], [83, 88], [89, 93], [94, 101], [102, 106], [107, 116], [117, 119], [120, 122], [123, 126], [127, 129], [130, 134], [135, 137], [138, 149], [149, 150], [151, 159], [160, 163], [164, 172], [173, 178], [178, 179], [180, 187], [188, 190], [191, 201], [202, 210], [211, 215], [216, 218], [219, 225], [225, 226]]}
{"doc_key": "ai-train-28", "ner": [[0, 2, "product"], [23, 25, "field"], [29, 30, "task"], [32, 34, "task"], [36, 37, "task"], [39, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 23, 25, "related-to", "", false, false], [29, 30, 23, 25, "part-of", "", false, false], [32, 34, 23, 25, "part-of", "", false, false], [36, 37, 23, 25, "part-of", "", false, false], [39, 40, 23, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Voice", "user", "interfaces", "that", "interpret", "and", "manage", "the", "state", "of", "a", "conversation", "are", "difficult", "to", "design", "because", "of", "the", "difficulty", "of", "integrating", "complex", "natural", "language", "processing", "tasks", "such", "as", "correlation", "resolution", ",", "named", "entity", "recognition", ",", "information", "retrieval", "and", "dialogue", "management", "."], "sentence-detokenized": "Voice user interfaces that interpret and manage the state of a conversation are difficult to design because of the difficulty of integrating complex natural language processing tasks such as correlation resolution, named entity recognition, information retrieval and dialogue management.", "token2charspan": [[0, 5], [6, 10], [11, 21], [22, 26], [27, 36], [37, 40], [41, 47], [48, 51], [52, 57], [58, 60], [61, 62], [63, 75], [76, 79], [80, 89], [90, 92], [93, 99], [100, 107], [108, 110], [111, 114], [115, 125], [126, 128], [129, 140], [141, 148], [149, 156], [157, 165], [166, 176], [177, 182], [183, 187], [188, 190], [191, 202], [203, 213], [213, 214], [215, 220], [221, 227], [228, 239], [239, 240], [241, 252], [253, 262], [263, 266], [267, 275], [276, 286], [286, 287]]}
{"doc_key": "ai-train-29", "ner": [[5, 6, "algorithm"], [9, 11, "algorithm"], [15, 17, "researcher"], [20, 26, "organisation"], [36, 37, "field"], [39, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 15, 17, "origin", "", false, false], [5, 6, 36, 37, "part-of", "", false, false], [5, 6, 39, 40, "part-of", "", false, false], [9, 11, 15, 17, "origin", "", false, false], [9, 11, 36, 37, "part-of", "", false, false], [9, 11, 39, 40, "part-of", "", false, false], [15, 17, 20, 26, "physical", "", false, false], [15, 17, 20, 26, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Between", "2009", "and", "2012", ",", "recurrent", "neural", "networks", "and", "deep", "feedforward", "neural", "networks", "developed", "by", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "Swiss", "artificial", "intelligence", "laboratory", "IDSIA", "have", "won", "eight", "international", "competitions", "in", "the", "field", "of", "pattern", "recognition", "and", "machine", "learning", "."], "sentence-detokenized": "Between 2009 and 2012, recurrent neural networks and deep feedforward neural networks developed by J\u00fcrgen Schmidhuber's research group at the Swiss artificial intelligence laboratory IDSIA have won eight international competitions in the field of pattern recognition and machine learning.", "token2charspan": [[0, 7], [8, 12], [13, 16], [17, 21], [21, 22], [23, 32], [33, 39], [40, 48], [49, 52], [53, 57], [58, 69], [70, 76], [77, 85], [86, 95], [96, 98], [99, 105], [106, 117], [117, 119], [120, 128], [129, 134], [135, 137], [138, 141], [142, 147], [148, 158], [159, 171], [172, 182], [183, 188], [189, 193], [194, 197], [198, 203], [204, 217], [218, 230], [231, 233], [234, 237], [238, 243], [244, 246], [247, 254], [255, 266], [267, 270], [271, 278], [279, 287], [287, 288]]}
{"doc_key": "ai-train-30", "ner": [[1, 3, "product"], [6, 7, "product"], [9, 10, "product"], [14, 15, "task"], [17, 17, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 6, 7, "usage", "", false, false], [1, 3, 9, 10, "usage", "", false, false], [1, 3, 14, 15, "usage", "", true, false], [1, 3, 17, 17, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Modern", "Windows", "computer", "systems", "can", "use", "SAPI", "4", "and", "SAPI", "5", "components", "to", "support", "speech", "synthesis", "and", "speech", "."], "sentence-detokenized": "Modern Windows computer systems can use SAPI 4 and SAPI 5 components to support speech synthesis and speech.", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 31], [32, 35], [36, 39], [40, 44], [45, 46], [47, 50], [51, 55], [56, 57], [58, 68], [69, 71], [72, 79], [80, 86], [87, 96], [97, 100], [101, 107], [107, 108]]}
{"doc_key": "ai-train-31", "ner": [[8, 12, "misc"], [13, 14, "field"], [16, 20, "university"], [26, 29, "field"], [31, 35, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 12, 13, 14, "topic", "topic_of_award", false, false], [8, 12, 16, 20, "origin", "", true, false], [26, 29, 31, 35, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "has", "received", "two", "honorary", "degrees", ",", "one", "S.V.", "della", "laurea", "ad", "honorem", "in", "psychology", "from", "the", "University", "of", "Padua", "in", "1995", "and", "one", "doctorate", "in", "industrial", "design", "and", "engineering", "from", "Delft", "University", "of", "Technology", "in", "1995", "."], "sentence-detokenized": "He has received two honorary degrees, one S.V. della laurea ad honorem in psychology from the University of Padua in 1995 and one doctorate in industrial design and engineering from Delft University of Technology in 1995.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 19], [20, 28], [29, 36], [36, 37], [38, 41], [42, 46], [47, 52], [53, 59], [60, 62], [63, 70], [71, 73], [74, 84], [85, 89], [90, 93], [94, 104], [105, 107], [108, 113], [114, 116], [117, 121], [122, 125], [126, 129], [130, 139], [140, 142], [143, 153], [154, 160], [161, 164], [165, 176], [177, 181], [182, 187], [188, 198], [199, 201], [202, 212], [213, 215], [216, 220], [220, 221]]}
{"doc_key": "ai-train-32", "ner": [[7, 8, "researcher"], [13, 17, "organisation"], [18, 19, "location"], [21, 22, "researcher"], [31, 33, "misc"], [44, 46, "misc"], [61, 62, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 8, 13, 17, "physical", "", false, false], [7, 8, 13, 17, "role", "", false, false], [13, 17, 18, 19, "physical", "", false, false], [21, 22, 31, 33, "related-to", "works_with", true, false], [21, 22, 44, 46, "related-to", "works_with", true, false], [21, 22, 61, 62, "related-to", "works_with", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Together", "with", "his", "long", "-", "time", "colleague", "Laurent", "Cohen", ",", "a", "neurologist", "at", "the", "Piti\u00e9", "-", "Salp\u00eatri\u00e8re", "Hospital", "in", "Paris", ",", "Dehen", "also", "identified", "patients", "with", "lesions", "in", "different", "regions", "of", "the", "parietal", "lobe", "who", "had", "impaired", "multiplication", "but", "preserved", "subtraction", "(", "related", "to", "lower", "parietal", "lobe", "lesions", ")", "and", "other", "patients", "with", "impaired", "subtraction", "but", "preserved", "multiplication", "(", "related", "to", "intraparietal", "sulcus", "lesions", ")", "."], "sentence-detokenized": "Together with his long-time colleague Laurent Cohen, a neurologist at the Piti\u00e9-Salp\u00eatri\u00e8re Hospital in Paris, Dehen also identified patients with lesions in different regions of the parietal lobe who had impaired multiplication but preserved subtraction (related to lower parietal lobe lesions) and other patients with impaired subtraction but preserved multiplication (related to intraparietal sulcus lesions).", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 22], [22, 23], [23, 27], [28, 37], [38, 45], [46, 51], [51, 52], [53, 54], [55, 66], [67, 69], [70, 73], [74, 79], [79, 80], [80, 91], [92, 100], [101, 103], [104, 109], [109, 110], [111, 116], [117, 121], [122, 132], [133, 141], [142, 146], [147, 154], [155, 157], [158, 167], [168, 175], [176, 178], [179, 182], [183, 191], [192, 196], [197, 200], [201, 204], [205, 213], [214, 228], [229, 232], [233, 242], [243, 254], [255, 256], [256, 263], [264, 266], [267, 272], [273, 281], [282, 286], [287, 294], [294, 295], [296, 299], [300, 305], [306, 314], [315, 319], [320, 328], [329, 340], [341, 344], [345, 354], [355, 369], [370, 371], [371, 378], [379, 381], [382, 395], [396, 402], [403, 410], [410, 411], [411, 412]]}
{"doc_key": "ai-train-33", "ner": [[2, 4, "product"], [10, 13, "misc"], [15, 21, "misc"], [25, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 13, 2, 4, "topic", "", false, false], [15, 21, 2, 4, "topic", "", false, false], [25, 28, 2, 4, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Recently", "invented", "artificially", "intelligent", "robot", "characters", "in", "films", "such", "as", "A.I", ".", "Artificial", "Intelligence", "and", "Ex", "Machina", ",", "as", "well", "as", "the", "2016", "TV", "adaptation", "Westworld", ",", "have", "made", "audiences", "more", "sympathetic", "to", "the", "robots", "themselves", "."], "sentence-detokenized": "Recently invented artificially intelligent robot characters in films such as A.I. Artificial Intelligence and Ex Machina, as well as the 2016 TV adaptation Westworld, have made audiences more sympathetic to the robots themselves.", "token2charspan": [[0, 8], [9, 17], [18, 30], [31, 42], [43, 48], [49, 59], [60, 62], [63, 68], [69, 73], [74, 76], [77, 80], [80, 81], [82, 92], [93, 105], [106, 109], [110, 112], [113, 120], [120, 121], [122, 124], [125, 129], [130, 132], [133, 136], [137, 141], [142, 144], [145, 155], [156, 165], [165, 166], [167, 171], [172, 176], [177, 186], [187, 191], [192, 203], [204, 206], [207, 210], [211, 217], [218, 228], [228, 229]]}
{"doc_key": "ai-train-34", "ner": [[7, 8, "field"], [10, 12, "algorithm"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 12, 7, 8, "part-of", "", false, false], [14, 15, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "of", "the", "main", "methods", "used", "in", "unsupervised", "learning", "are", "principal", "component", "analysis", "and", "cluster", "analysis", "."], "sentence-detokenized": "Two of the main methods used in unsupervised learning are principal component analysis and cluster analysis.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 15], [16, 23], [24, 28], [29, 31], [32, 44], [45, 53], [54, 57], [58, 67], [68, 77], [78, 86], [87, 90], [91, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-train-35", "ner": [[0, 3, "organisation"], [21, 24, "misc"], [29, 30, "misc"], [32, 34, "person"], [39, 40, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 24, 0, 3, "artifact", "", false, false], [29, 30, 0, 3, "artifact", "", false, false], [29, 30, 32, 34, "role", "director_of", false, false], [29, 30, 39, 40, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Walt", "Disney", "'s", "company", "also", "started", "to", "use", "3D", "films", "more", "in", "special", "locations", "to", "surprise", "audiences", ",", "such", "as", "The", "Voyages", "of", "the", "Magician", "(", "1982", ")", "and", "Captain", "EO", "(", "Francis", "Ford", "Coppola", ",", "1986", ",", "starring", "Michael", "Jackson", ")", "being", "prime", "examples", "."], "sentence-detokenized": "Walt Disney's company also started to use 3D films more in special locations to surprise audiences, such as The Voyages of the Magician (1982) and Captain EO (Francis Ford Coppola, 1986, starring Michael Jackson) being prime examples.", "token2charspan": [[0, 4], [5, 11], [11, 13], [14, 21], [22, 26], [27, 34], [35, 37], [38, 41], [42, 44], [45, 50], [51, 55], [56, 58], [59, 66], [67, 76], [77, 79], [80, 88], [89, 98], [98, 99], [100, 104], [105, 107], [108, 111], [112, 119], [120, 122], [123, 126], [127, 135], [136, 137], [137, 141], [141, 142], [143, 146], [147, 154], [155, 157], [158, 159], [159, 166], [167, 171], [172, 179], [179, 180], [181, 185], [185, 186], [187, 195], [196, 203], [204, 211], [211, 212], [213, 218], [219, 224], [225, 233], [233, 234]]}
{"doc_key": "ai-train-36", "ner": [[12, 14, "field"], [19, 24, "task"], [26, 27, "task"], [29, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 24, 12, 14, "part-of", "", false, false], [26, 27, 12, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Since", "2002", ",", "perceptron", "training", "has", "become", "popular", "in", "the", "field", "of", "natural", "language", "processing", "for", "tasks", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "syntactic", "analysis", "(", "Collins", ",", "2002", ")", "."], "sentence-detokenized": "Since 2002, perceptron training has become popular in the field of natural language processing for tasks such as part-of-speech tagging and syntactic analysis (Collins, 2002).", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 22], [23, 31], [32, 35], [36, 42], [43, 50], [51, 53], [54, 57], [58, 63], [64, 66], [67, 74], [75, 83], [84, 94], [95, 98], [99, 104], [105, 109], [110, 112], [113, 117], [117, 118], [118, 120], [120, 121], [121, 127], [128, 135], [136, 139], [140, 149], [150, 158], [159, 160], [160, 167], [167, 168], [169, 173], [173, 174], [174, 175]]}
{"doc_key": "ai-train-37", "ner": [[2, 4, "product"], [10, 15, "organisation"], [16, 17, "organisation"], [18, 19, "country"], [23, 26, "product"], [30, 32, "researcher"], [37, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 15, 2, 4, "role", "introduces_to_market", true, false], [16, 17, 2, 4, "role", "introduces_to_market", true, false], [16, 17, 18, 19, "physical", "", false, false], [23, 26, 37, 37, "related-to", "sold_to", true, false], [30, 32, 23, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "first", "pallet", "stacking", "robot", "was", "introduced", "in", "1963", "by", "the", "Fuji", "Yusoki", "Kogyo", "Company", ".", "KUKA", "robotics", "in", "Germany", ",", "and", "the", "programmable", "universal", "assembly", "machine", "was", "invented", "by", "Victor", "Scheinman", "in", "1976", "and", "sold", "to", "Unimation", "."], "sentence-detokenized": "The first pallet stacking robot was introduced in 1963 by the Fuji Yusoki Kogyo Company. KUKA robotics in Germany, and the programmable universal assembly machine was invented by Victor Scheinman in 1976 and sold to Unimation.", "token2charspan": [[0, 3], [4, 9], [10, 16], [17, 25], [26, 31], [32, 35], [36, 46], [47, 49], [50, 54], [55, 57], [58, 61], [62, 66], [67, 73], [74, 79], [80, 87], [87, 88], [89, 93], [94, 102], [103, 105], [106, 113], [113, 114], [115, 118], [119, 122], [123, 135], [136, 145], [146, 154], [155, 162], [163, 166], [167, 175], [176, 178], [179, 185], [186, 195], [196, 198], [199, 203], [204, 207], [208, 212], [213, 215], [216, 225], [225, 226]]}
{"doc_key": "ai-train-38", "ner": [[7, 7, "conference"], [9, 9, "researcher"], [17, 18, "field"], [30, 31, "researcher"], [35, 36, "researcher"], [49, 49, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 9, 7, 7, "role", "president_of", false, false], [9, 9, 30, 31, "role", "colleagues", false, false], [17, 18, 49, 49, "named", "same", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "mid-1990s", ",", "as", "President", "of", "AAAI", ",", "Hayes", "launched", "a", "series", "of", "attacks", "on", "critics", "of", "AI", ",", "mostly", "couched", "in", "ironic", "terms", ",", "and", "(", "with", "colleague", "Kenneth", "Ford", ")", "invented", "the", "Simon", "Newcombe", "Prize", ",", "awarded", "for", "the", "most", "ridiculous", "argument", "against", "the", "possibility", "of", "AI", "."], "sentence-detokenized": "In the mid-1990s, as President of AAAI, Hayes launched a series of attacks on critics of AI, mostly couched in ironic terms, and (with colleague Kenneth Ford) invented the Simon Newcombe Prize, awarded for the most ridiculous argument against the possibility of AI.", "token2charspan": [[0, 2], [3, 6], [7, 16], [16, 17], [18, 20], [21, 30], [31, 33], [34, 38], [38, 39], [40, 45], [46, 54], [55, 56], [57, 63], [64, 66], [67, 74], [75, 77], [78, 85], [86, 88], [89, 91], [91, 92], [93, 99], [100, 107], [108, 110], [111, 117], [118, 123], [123, 124], [125, 128], [129, 130], [130, 134], [135, 144], [145, 152], [153, 157], [157, 158], [159, 167], [168, 171], [172, 177], [178, 186], [187, 192], [192, 193], [194, 201], [202, 205], [206, 209], [210, 214], [215, 225], [226, 234], [235, 242], [243, 246], [247, 258], [259, 261], [262, 264], [264, 265]]}
{"doc_key": "ai-train-39", "ner": [[14, 21, "algorithm"], [42, 43, "algorithm"], [55, 58, "algorithm"], [61, 64, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 21, 42, 43, "named", "same", false, false], [55, 58, 14, 21, "type-of", "", false, false], [61, 64, 14, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "optimal", "value", "of", "math", "/", "alpha", "/", "math", "can", "be", "found", "using", "a", "line", "search", "algorithm", ",", "that", "is", ",", "the", "value", "of", "math", "/", "alpha", "/", "math", "is", "determined", "by", "finding", "the", "value", "that", "minimises", "S", ",", "usually", "using", "a", "line", "search", "over", "the", "interval", "math0", "/", "alpha", "1", "/", "math", "or", "a", "backward", "line", "search", "such", "as", "the", "Armijo", "-", "line", "search", "."], "sentence-detokenized": "The optimal value of math/alpha/math can be found using a line search algorithm, that is, the value of math/alpha/math is determined by finding the value that minimises S, usually using a line search over the interval math0/alpha 1/math or a backward line search such as the Armijo-line search.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 20], [21, 25], [25, 26], [26, 31], [31, 32], [32, 36], [37, 40], [41, 43], [44, 49], [50, 55], [56, 57], [58, 62], [63, 69], [70, 79], [79, 80], [81, 85], [86, 88], [88, 89], [90, 93], [94, 99], [100, 102], [103, 107], [107, 108], [108, 113], [113, 114], [114, 118], [119, 121], [122, 132], [133, 135], [136, 143], [144, 147], [148, 153], [154, 158], [159, 168], [169, 170], [170, 171], [172, 179], [180, 185], [186, 187], [188, 192], [193, 199], [200, 204], [205, 208], [209, 217], [218, 223], [223, 224], [224, 229], [230, 231], [231, 232], [232, 236], [237, 239], [240, 241], [242, 250], [251, 255], [256, 262], [263, 267], [268, 270], [271, 274], [275, 281], [281, 282], [282, 286], [287, 293], [293, 294]]}
{"doc_key": "ai-train-40", "ner": [[3, 5, "algorithm"], [7, 8, "algorithm"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "looks", "at", "the", "extensive", "search", "and", "advanced", "search", "methods", ",", "but", "ultimately", "concludes", "that", "the", "results", "reflect", "expert", "systems", "that", "embody", "a", "lot", "of", "technical", "knowledge", ",", "but", "do", "not", "shed", "much", "light", "on", "the", "mental", "processes", "that", "people", "use", "to", "solve", "such", "puzzles", "."], "sentence-detokenized": "He looks at the extensive search and advanced search methods, but ultimately concludes that the results reflect expert systems that embody a lot of technical knowledge, but do not shed much light on the mental processes that people use to solve such puzzles.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 15], [16, 25], [26, 32], [33, 36], [37, 45], [46, 52], [53, 60], [60, 61], [62, 65], [66, 76], [77, 86], [87, 91], [92, 95], [96, 103], [104, 111], [112, 118], [119, 126], [127, 131], [132, 138], [139, 140], [141, 144], [145, 147], [148, 157], [158, 167], [167, 168], [169, 172], [173, 175], [176, 179], [180, 184], [185, 189], [190, 195], [196, 198], [199, 202], [203, 209], [210, 219], [220, 224], [225, 231], [232, 235], [236, 238], [239, 244], [245, 249], [250, 257], [257, 258]]}
{"doc_key": "ai-train-41", "ner": [[0, 1, "task"], [3, 4, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Speech", "recognition", "and", "speech", "synthesis", "deal", "with", "how", "spoken", "language", "can", "be", "understood", "or", "created", "using", "computers", "."], "sentence-detokenized": "Speech recognition and speech synthesis deal with how spoken language can be understood or created using computers.", "token2charspan": [[0, 6], [7, 18], [19, 22], [23, 29], [30, 39], [40, 44], [45, 49], [50, 53], [54, 60], [61, 69], [70, 73], [74, 76], [77, 87], [88, 90], [91, 98], [99, 104], [105, 114], [114, 115]]}
{"doc_key": "ai-train-42", "ner": [[13, 14, "algorithm"], [26, 28, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "math", "theta", "^", "{", "*}", "/", "math", "is", "usually", "estimated", "using", "the", "maximum", "likelihood", "(", "math^theta", "^{", "*}", "=\\", "theta^{", "ML}", "/", "math", ")", "or", "maximum", "a", "posteriori", "(", "math^theta", "^{", "*}", "=\\", "theta", "^{", "MAP", "}", "/", "math", ")", "procedure", "."], "sentence-detokenized": "This math theta ^ {*} / math is usually estimated using the maximum likelihood (math^theta^{*} =\\ theta^{ML} / math) or maximum a posteriori (math^theta^{*} =\\ theta^{MAP} / math) procedure.", "token2charspan": [[0, 4], [5, 9], [10, 15], [16, 17], [18, 19], [19, 21], [22, 23], [24, 28], [29, 31], [32, 39], [40, 49], [50, 55], [56, 59], [60, 67], [68, 78], [79, 80], [80, 90], [90, 92], [92, 94], [95, 97], [98, 105], [105, 108], [109, 110], [111, 115], [115, 116], [117, 119], [120, 127], [128, 129], [130, 140], [141, 142], [142, 152], [152, 154], [154, 156], [157, 159], [160, 165], [165, 167], [167, 170], [170, 171], [172, 173], [174, 178], [178, 179], [180, 189], [189, 190]]}
{"doc_key": "ai-train-43", "ner": [[9, 10, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "less", "common", "languages", "use", "the", "open", "-", "source", "synthesiser", "eSpeak", "to", "produce", "speech", "that", "is", "robotic", ",", "awkward", "and", "difficult", "to", "understand", "."], "sentence-detokenized": "Some less common languages use the open-source synthesiser eSpeak to produce speech that is robotic, awkward and difficult to understand.", "token2charspan": [[0, 4], [5, 9], [10, 16], [17, 26], [27, 30], [31, 34], [35, 39], [39, 40], [40, 46], [47, 58], [59, 65], [66, 68], [69, 76], [77, 83], [84, 88], [89, 91], [92, 99], [99, 100], [101, 108], [109, 112], [113, 122], [123, 125], [126, 136], [136, 137]]}
{"doc_key": "ai-train-44", "ner": [[1, 1, "programlang"], [36, 37, "programlang"], [39, 39, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 36, 37, "compare", "", false, false], [1, 1, 39, 39, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Although", "R", "is", "used", "mainly", "by", "statisticians", "and", "other", "practitioners", "who", "need", "an", "environment", "for", "statistical", "computation", "and", "software", "development", ",", "it", "can", "also", "be", "used", "as", "a", "general", "matrix", "computation", "toolbox", "with", "performance", "comparable", "to", "GNU", "Octave", "or", "MATLAB", "."], "sentence-detokenized": "Although R is used mainly by statisticians and other practitioners who need an environment for statistical computation and software development, it can also be used as a general matrix computation toolbox with performance comparable to GNU Octave or MATLAB.", "token2charspan": [[0, 8], [9, 10], [11, 13], [14, 18], [19, 25], [26, 28], [29, 42], [43, 46], [47, 52], [53, 66], [67, 70], [71, 75], [76, 78], [79, 90], [91, 94], [95, 106], [107, 118], [119, 122], [123, 131], [132, 143], [143, 144], [145, 147], [148, 151], [152, 156], [157, 159], [160, 164], [165, 167], [168, 169], [170, 177], [178, 184], [185, 196], [197, 204], [205, 209], [210, 221], [222, 232], [233, 235], [236, 239], [240, 246], [247, 249], [250, 256], [256, 257]]}
{"doc_key": "ai-train-45", "ner": [[0, 0, "algorithm"], [3, 4, "field"], [8, 11, "misc"], [12, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 4, "part-of", "", false, false], [0, 0, 12, 14, "origin", "", false, false], [8, 11, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Heterodyning", "is", "a", "signal", "processing", "technique", "invented", "by", "Canadian", "inventor", "and", "engineer", "Reginald", "Fessenden", "that", "creates", "new", "frequencies", "by", "mixing", "two", "frequencies", "."], "sentence-detokenized": "Heterodyning is a signal processing technique invented by Canadian inventor and engineer Reginald Fessenden that creates new frequencies by mixing two frequencies.", "token2charspan": [[0, 12], [13, 15], [16, 17], [18, 24], [25, 35], [36, 45], [46, 54], [55, 57], [58, 66], [67, 75], [76, 79], [80, 88], [89, 97], [98, 107], [108, 112], [113, 120], [121, 124], [125, 136], [137, 139], [140, 146], [147, 150], [151, 162], [162, 163]]}
{"doc_key": "ai-train-46", "ner": [[18, 20, "person"], [21, 23, "misc"], [25, 27, "organisation"], [30, 30, "organisation"], [32, 34, "misc"], [36, 37, "person"], [39, 39, "organisation"], [41, 43, "misc"], [45, 46, "person"], [48, 49, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[18, 20, 21, 23, "role", "actor_in", false, false], [21, 23, 25, 27, "artifact", "", false, false], [32, 34, 30, 30, "artifact", "", false, false], [36, 37, 32, 34, "role", "actor_in", false, false], [41, 43, 39, 39, "artifact", "", false, false], [45, 46, 41, 43, "role", "actor_in", false, false], [48, 49, 41, 43, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Several", "other", "films", "were", "also", "released", "in", "3D", "that", "month", ",", "helping", "to", "bring", "back", "to", "the", "screen", "John", "Wayne", "'s", "Hondo", "(", "distributed", "by", "Warner", "Bros", ".", ")", ",", "Columbia", "'s", "Miss", "Sadie", "Thompson", "with", "Rita", "Hayworth", "and", "Paramount", "'s", "Money", "From", "Home", "with", "Dean", "Martin", "and", "Jerry", "Lewis", "."], "sentence-detokenized": "Several other films were also released in 3D that month, helping to bring back to the screen John Wayne's Hondo (distributed by Warner Bros. ), Columbia's Miss Sadie Thompson with Rita Hayworth and Paramount's Money From Home with Dean Martin and Jerry Lewis.", "token2charspan": [[0, 7], [8, 13], [14, 19], [20, 24], [25, 29], [30, 38], [39, 41], [42, 44], [45, 49], [50, 55], [55, 56], [57, 64], [65, 67], [68, 73], [74, 78], [79, 81], [82, 85], [86, 92], [93, 97], [98, 103], [103, 105], [106, 111], [112, 113], [113, 124], [125, 127], [128, 134], [135, 139], [139, 140], [141, 142], [142, 143], [144, 152], [152, 154], [155, 159], [160, 165], [166, 174], [175, 179], [180, 184], [185, 193], [194, 197], [198, 207], [207, 209], [210, 215], [216, 220], [221, 225], [226, 230], [231, 235], [236, 242], [243, 246], [247, 252], [253, 258], [258, 259]]}
{"doc_key": "ai-train-47", "ner": [[0, 0, "product"], [3, 4, "field"], [5, 6, "task"], [11, 11, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "general-affiliation", "", false, false], [0, 0, 11, 11, "artifact", "", false, false], [5, 6, 3, 4, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["DeepFace", "is", "a", "deep", "learning", "facial", "recognition", "system", "developed", "by", "the", "Facebook", "Research", "Group", "."], "sentence-detokenized": "DeepFace is a deep learning facial recognition system developed by the Facebook Research Group.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 18], [19, 27], [28, 34], [35, 46], [47, 53], [54, 63], [64, 66], [67, 70], [71, 79], [80, 88], [89, 94], [94, 95]]}
{"doc_key": "ai-train-48", "ner": [[0, 1, "field"], [8, 10, "conference"], [14, 16, "field"], [27, 28, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 14, 16, "part-of", "subfield", false, false], [8, 10, 0, 1, "topic", "", false, false], [27, 28, 0, 1, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Geometry", "processing", "is", "a", "frequent", "research", "topic", "at", "SIGGRAPH", ",", "the", "premier", "academic", "conference", "on", "computer", "graphics", ",", "and", "is", "also", "the", "focus", "of", "the", "annual", "Geometry", "Processing", "Symposium", "."], "sentence-detokenized": "Geometry processing is a frequent research topic at SIGGRAPH, the premier academic conference on computer graphics, and is also the focus of the annual Geometry Processing Symposium.", "token2charspan": [[0, 8], [9, 19], [20, 22], [23, 24], [25, 33], [34, 42], [43, 48], [49, 51], [52, 60], [60, 61], [62, 65], [66, 73], [74, 82], [83, 93], [94, 96], [97, 105], [106, 114], [114, 115], [116, 119], [120, 122], [123, 127], [128, 131], [132, 137], [138, 140], [141, 144], [145, 151], [152, 160], [161, 171], [172, 181], [181, 182]]}
{"doc_key": "ai-train-49", "ner": [[0, 1, "task"], [3, 4, "task"], [13, 15, "algorithm"], [17, 17, "algorithm"], [20, 22, "algorithm"], [24, 24, "algorithm"], [27, 29, "algorithm"], [31, 31, "algorithm"], [34, 34, "misc"], [41, 44, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[13, 15, 34, 34, "general-affiliation", "", false, false], [17, 17, 13, 15, "named", "", false, false], [20, 22, 34, 34, "general-affiliation", "", false, false], [24, 24, 20, 22, "named", "", false, false], [27, 29, 34, 34, "general-affiliation", "", false, false], [31, 31, 27, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Feature", "extraction", "and", "dimension", "reduction", "can", "be", "combined", "in", "a", "single", "step", "using", "principal", "component", "analysis", "(", "PCA", ")", ",", "linear", "discriminant", "analysis", "(", "LDA", ")", "or", "canonical", "correlation", "analysis", "(", "CCA", ")", "as", "preprocessing", "step", ",", "followed", "by", "clustering", "with", "k", "-", "NN", "over", "feature", "vectors", "in", "the", "dimension", "-", "reduced", "space", "."], "sentence-detokenized": "Feature extraction and dimension reduction can be combined in a single step using principal component analysis (PCA), linear discriminant analysis (LDA) or canonical correlation analysis (CCA) as preprocessing step, followed by clustering with k -NN over feature vectors in the dimension-reduced space.", "token2charspan": [[0, 7], [8, 18], [19, 22], [23, 32], [33, 42], [43, 46], [47, 49], [50, 58], [59, 61], [62, 63], [64, 70], [71, 75], [76, 81], [82, 91], [92, 101], [102, 110], [111, 112], [112, 115], [115, 116], [116, 117], [118, 124], [125, 137], [138, 146], [147, 148], [148, 151], [151, 152], [153, 155], [156, 165], [166, 177], [178, 186], [187, 188], [188, 191], [191, 192], [193, 195], [196, 209], [210, 214], [214, 215], [216, 224], [225, 227], [228, 238], [239, 243], [244, 245], [246, 247], [247, 249], [250, 254], [255, 262], [263, 270], [271, 273], [274, 277], [278, 287], [287, 288], [288, 295], [296, 301], [301, 302]]}
{"doc_key": "ai-train-50", "ner": [[0, 2, "algorithm"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 10, "related-to", "good_at", true, false], [0, 2, 12, 13, "related-to", "good_at", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Artificial", "neural", "networks", "are", "computational", "models", "that", "excel", "in", "machine", "learning", "and", "pattern", "recognition", "."], "sentence-detokenized": "Artificial neural networks are computational models that excel in machine learning and pattern recognition.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 30], [31, 44], [45, 51], [52, 56], [57, 62], [63, 65], [66, 73], [74, 82], [83, 86], [87, 94], [95, 106], [106, 107]]}
{"doc_key": "ai-train-51", "ner": [[1, 2, "researcher"], [4, 5, "researcher"], [7, 11, "misc"], [13, 17, "conference"], [19, 19, "conference"], [36, 39, "algorithm"], [40, 41, "researcher"], [43, 45, "researcher"], [47, 53, "misc"], [55, 64, "conference"], [66, 66, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[7, 11, 1, 2, "artifact", "", false, false], [7, 11, 4, 5, "artifact", "", false, false], [7, 11, 13, 17, "temporal", "", false, false], [19, 19, 13, 17, "named", "", false, false], [47, 53, 36, 39, "topic", "", false, false], [47, 53, 40, 41, "artifact", "", false, false], [47, 53, 43, 45, "artifact", "", false, false], [47, 53, 55, 64, "temporal", "", false, false], [66, 66, 55, 64, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": [",", "C.", "Papageorgiou", "and", "T.", "Poggio", ",", "A", "Trainable", "Pedestrian", "Detection", "system", ",", "International", "Journal", "of", "Computer", "Vision", "(", "IJCV", ")", ",", "pages", "1", ":", "15", "-", "33", ",", "2000", "others", "use", "local", "features", "such", "as", "histograms", "of", "oriented", "gradients", "N.", "Dalal", ",", "B", ".", "Triggs", ",", "Histograms", "of", "oriented", "gradients", "for", "human", "detection", ",", "IEEE", "Computer", "Society", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", ",", "pages", "1", ":", "886-893", ",", "2005", "descriptors", "."], "sentence-detokenized": ", C. Papageorgiou and T. Poggio, A Trainable Pedestrian Detection system, International Journal of Computer Vision (IJCV), pages 1: 15-33, 2000 others use local features such as histograms of oriented gradients N. Dalal, B. Triggs, Histograms of oriented gradients for human detection, IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), pages 1: 886-893, 2005 descriptors.", "token2charspan": [[0, 1], [2, 4], [5, 17], [18, 21], [22, 24], [25, 31], [31, 32], [33, 34], [35, 44], [45, 55], [56, 65], [66, 72], [72, 73], [74, 87], [88, 95], [96, 98], [99, 107], [108, 114], [115, 116], [116, 120], [120, 121], [121, 122], [123, 128], [129, 130], [130, 131], [132, 134], [134, 135], [135, 137], [137, 138], [139, 143], [144, 150], [151, 154], [155, 160], [161, 169], [170, 174], [175, 177], [178, 188], [189, 191], [192, 200], [201, 210], [211, 213], [214, 219], [219, 220], [221, 222], [222, 223], [224, 230], [230, 231], [232, 242], [243, 245], [246, 254], [255, 264], [265, 268], [269, 274], [275, 284], [284, 285], [286, 290], [291, 299], [300, 307], [308, 318], [319, 321], [322, 330], [331, 337], [338, 341], [342, 349], [350, 361], [362, 363], [363, 367], [367, 368], [368, 369], [370, 375], [376, 377], [377, 378], [379, 386], [386, 387], [388, 392], [393, 404], [404, 405]]}
{"doc_key": "ai-train-52", "ner": [[0, 1, "algorithm"], [6, 8, "algorithm"], [12, 13, "task"], [14, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 8, "type-of", "", false, false], [12, 13, 0, 1, "usage", "", true, false], [12, 13, 14, 16, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["An", "autoencoder", "is", "a", "type", "of", "artificial", "neural", "network", "used", "to", "learn", "functions", "in", "an", "unsupervised", "learning", "manner", "."], "sentence-detokenized": "An autoencoder is a type of artificial neural network used to learn functions in an unsupervised learning manner.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 19], [20, 24], [25, 27], [28, 38], [39, 45], [46, 53], [54, 58], [59, 61], [62, 67], [68, 77], [78, 80], [81, 83], [84, 96], [97, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-train-53", "ner": [[0, 0, "researcher"], [4, 6, "organisation"], [10, 11, "field"], [13, 14, "field"], [19, 23, "organisation"], [26, 26, "organisation"], [32, 32, "field"], [34, 35, "field"], [41, 41, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 6, "role", "fellow_of", false, false], [0, 0, 10, 11, "related-to", "contributes_to", false, false], [0, 0, 13, 14, "related-to", "contributes_to", false, false], [0, 0, 19, 23, "role", "fellow_of", false, false], [0, 0, 32, 32, "related-to", "contributes_to", false, false], [0, 0, 34, 35, "related-to", "contributes_to", false, false], [26, 26, 19, 23, "named", "", false, false], [41, 41, 19, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Haralik", "is", "a", "Fellow", "of", "the", "IEEE", "for", "contributions", "to", "computer", "vision", "and", "image", "processing", "and", "a", "Fellow", "of", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", "for", "contributions", "to", "pattern", "recognition", ",", "image", "processing", "and", "for", "his", "work", "with", "IAPR", "."], "sentence-detokenized": "Haralik is a Fellow of the IEEE for contributions to computer vision and image processing and a Fellow of the International Association for Pattern Recognition (IAPR) for contributions to pattern recognition, image processing and for his work with IAPR.", "token2charspan": [[0, 7], [8, 10], [11, 12], [13, 19], [20, 22], [23, 26], [27, 31], [32, 35], [36, 49], [50, 52], [53, 61], [62, 68], [69, 72], [73, 78], [79, 89], [90, 93], [94, 95], [96, 102], [103, 105], [106, 109], [110, 123], [124, 135], [136, 139], [140, 147], [148, 159], [160, 161], [161, 165], [165, 166], [167, 170], [171, 184], [185, 187], [188, 195], [196, 207], [207, 208], [209, 214], [215, 225], [226, 229], [230, 233], [234, 237], [238, 242], [243, 247], [248, 252], [252, 253]]}
{"doc_key": "ai-train-54", "ner": [[5, 7, "task"], [13, 15, "algorithm"], [17, 17, "algorithm"], [24, 25, "researcher"], [27, 28, "organisation"], [30, 31, "researcher"], [34, 36, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 7, 13, 15, "usage", "", false, false], [13, 15, 24, 25, "origin", "", true, false], [13, 15, 30, 31, "origin", "", true, false], [17, 17, 13, 15, "named", "", false, false], [24, 25, 27, 28, "physical", "", false, false], [24, 25, 27, 28, "role", "", false, false], [30, 31, 34, 36, "physical", "", false, false], [30, 31, 34, 36, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "first", "attempt", "to", "build", "a", "comprehensive", "ASR", "was", "a", "system", "based", "on", "connectionist", "temporal", "classification", "(", "CTC", ")", ",", "introduced", "in", "2014", "by", "Alex", "Graves", "of", "Google", "DeepMind", "and", "Navdeep", "Jaitly", "of", "the", "University", "of", "Toronto", "."], "sentence-detokenized": "The first attempt to build a comprehensive ASR was a system based on connectionist temporal classification (CTC), introduced in 2014 by Alex Graves of Google DeepMind and Navdeep Jaitly of the University of Toronto.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 20], [21, 26], [27, 28], [29, 42], [43, 46], [47, 50], [51, 52], [53, 59], [60, 65], [66, 68], [69, 82], [83, 91], [92, 106], [107, 108], [108, 111], [111, 112], [112, 113], [114, 124], [125, 127], [128, 132], [133, 135], [136, 140], [141, 147], [148, 150], [151, 157], [158, 166], [167, 170], [171, 178], [179, 185], [186, 188], [189, 192], [193, 203], [204, 206], [207, 214], [214, 215]]}
{"doc_key": "ai-train-55", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "algorithm"], [13, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 0, 2, "named", "", false, false], [10, 11, 0, 2, "type-of", "", false, false], [13, 13, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Linear", "Fractional", "Programming", "(", "LFP", ")", "is", "a", "generalisation", "of", "Linear", "Programming", "(", "LP", ")", "."], "sentence-detokenized": "Linear Fractional Programming (LFP) is a generalisation of Linear Programming (LP).", "token2charspan": [[0, 6], [7, 17], [18, 29], [30, 31], [31, 34], [34, 35], [36, 38], [39, 40], [41, 55], [56, 58], [59, 65], [66, 77], [78, 79], [79, 81], [81, 82], [82, 83]]}
{"doc_key": "ai-train-56", "ner": [[0, 1, "researcher"], [8, 15, "misc"], [16, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 8, 15, "win-defeat", "", false, false], [8, 15, 16, 24, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lafferty", "has", "received", "several", "awards", ",", "including", "two", "Test", "-", "of", "-", "Time", "awards", "at", "the", "International", "Conference", "on", "Machine", "Learning", "in", "2011", "and", "2012", ","], "sentence-detokenized": "Lafferty has received several awards, including two Test-of-Time awards at the International Conference on Machine Learning in 2011 and 2012,", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 29], [30, 36], [36, 37], [38, 47], [48, 51], [52, 56], [56, 57], [57, 59], [59, 60], [60, 64], [65, 71], [72, 74], [75, 78], [79, 92], [93, 103], [104, 106], [107, 114], [115, 123], [124, 126], [127, 131], [132, 135], [136, 140], [140, 141]]}
{"doc_key": "ai-train-57", "ner": [[10, 10, "product"], [12, 12, "programlang"], [25, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["With", "the", "advent", "of", "component", "-", "based", "frameworks", "such", "as", ".NET", "and", "Java", ",", "component", "-", "based", "development", "environments", "are", "able", "to", "deploy", "the", "developed", "neural", "network", "within", "these", "frameworks", "as", "inheritable", "components", "."], "sentence-detokenized": "With the advent of component-based frameworks such as .NET and Java, component-based development environments are able to deploy the developed neural network within these frameworks as inheritable components.", "token2charspan": [[0, 4], [5, 8], [9, 15], [16, 18], [19, 28], [28, 29], [29, 34], [35, 45], [46, 50], [51, 53], [54, 58], [59, 62], [63, 67], [67, 68], [69, 78], [78, 79], [79, 84], [85, 96], [97, 109], [110, 113], [114, 118], [119, 121], [122, 128], [129, 132], [133, 142], [143, 149], [150, 157], [158, 164], [165, 170], [171, 181], [182, 184], [185, 196], [197, 207], [207, 208]]}
{"doc_key": "ai-train-58", "ner": [[5, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "in", "the", "case", "of", "BLEU", ",", "the", "basic", "unit", "of", "evaluation", "is", "the", "sentence", ",", "the", "algorithm", "first", "creates", "an", "alignment", "(", "see", "illustrations", ")", "between", "two", "sentences", ",", "a", "candidate", "translation", "string", "and", "a", "reference", "translation", "string", "."], "sentence-detokenized": "As in the case of BLEU, the basic unit of evaluation is the sentence, the algorithm first creates an alignment (see illustrations) between two sentences, a candidate translation string and a reference translation string.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 14], [15, 17], [18, 22], [22, 23], [24, 27], [28, 33], [34, 38], [39, 41], [42, 52], [53, 55], [56, 59], [60, 68], [68, 69], [70, 73], [74, 83], [84, 89], [90, 97], [98, 100], [101, 110], [111, 112], [112, 115], [116, 129], [129, 130], [131, 138], [139, 142], [143, 152], [152, 153], [154, 155], [156, 165], [166, 177], [178, 184], [185, 188], [189, 190], [191, 200], [201, 212], [213, 219], [219, 220]]}
{"doc_key": "ai-train-59", "ner": [[6, 13, "conference"], [21, 21, "task"], [23, 24, "task"], [28, 29, "metrics"], [31, 37, "metrics"], [42, 45, "conference"], [47, 47, "conference"], [50, 50, "location"], [52, 52, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 13, 21, 21, "related-to", "subject_at", false, false], [6, 13, 23, 24, "related-to", "subject_at", false, false], [28, 29, 6, 13, "temporal", "", false, false], [31, 37, 28, 29, "named", "", true, false], [47, 47, 42, 45, "named", "", false, false], [50, 50, 52, 52, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["One", "of", "the", "metrics", "used", "at", "NIST", "'s", "annual", "document", "understanding", "conferences", ",", "where", "research", "groups", "submit", "their", "systems", "for", "both", "summarization", "and", "translation", "tasks", ",", "is", "the", "ROUGE", "metric", "(", "Recall", "-", "Oriented", "Understudy", "for", "Gisting", "Evaluation", ",", "In", "Advances", "of", "Neural", "Information", "Processing", "Systems", "(", "NIPS", ")", ",", "Montreal", ",", "Canada", ",", "December", "-", "2014", "."], "sentence-detokenized": "One of the metrics used at NIST's annual document understanding conferences, where research groups submit their systems for both summarization and translation tasks, is the ROUGE metric (Recall-Oriented Understudy for Gisting Evaluation, In Advances of Neural Information Processing Systems (NIPS), Montreal, Canada, December - 2014.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 18], [19, 23], [24, 26], [27, 31], [31, 33], [34, 40], [41, 49], [50, 63], [64, 75], [75, 76], [77, 82], [83, 91], [92, 98], [99, 105], [106, 111], [112, 119], [120, 123], [124, 128], [129, 142], [143, 146], [147, 158], [159, 164], [164, 165], [166, 168], [169, 172], [173, 178], [179, 185], [186, 187], [187, 193], [193, 194], [194, 202], [203, 213], [214, 217], [218, 225], [226, 236], [236, 237], [238, 240], [241, 249], [250, 252], [253, 259], [260, 271], [272, 282], [283, 290], [291, 292], [292, 296], [296, 297], [297, 298], [299, 307], [307, 308], [309, 315], [315, 316], [317, 325], [326, 327], [328, 332], [332, 333]]}
{"doc_key": "ai-train-60", "ner": [[4, 4, "programlang"], [6, 6, "product"], [8, 9, "programlang"], [13, 13, "product"], [19, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 8, 9, "type-of", "", false, false], [4, 4, 19, 19, "named", "", false, false], [6, 6, 8, 9, "part-of", "", false, false], [6, 6, 13, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Same", "implementation", "to", "run", "Java", "with", "JShell", "(", "Java", "9", "minimum", ")", ":", "codejshell", "scriptfile", "/", "codesyntaxhighlight", "lang", "=", "java"], "sentence-detokenized": "Same implementation to run Java with JShell (Java 9 minimum): codejshell scriptfile / codesyntaxhighlight lang = java", "token2charspan": [[0, 4], [5, 19], [20, 22], [23, 26], [27, 31], [32, 36], [37, 43], [44, 45], [45, 49], [50, 51], [52, 59], [59, 60], [60, 61], [62, 72], [73, 83], [84, 85], [86, 105], [106, 110], [111, 112], [113, 117]]}
{"doc_key": "ai-train-61", "ner": [[0, 3, "metrics"], [7, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 7, 10, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "NIST", "metrics", "are", "based", "on", "the", "BLEU", "metrics", ",", "but", "with", "some", "changes", "."], "sentence-detokenized": "The NIST metrics are based on the BLEU metrics, but with some changes.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 26], [27, 29], [30, 33], [34, 38], [39, 46], [46, 47], [48, 51], [52, 56], [57, 61], [62, 69], [69, 70]]}
{"doc_key": "ai-train-62", "ner": [[6, 6, "country"], [10, 12, "university"], [15, 17, "university"], [23, 24, "product"], [30, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 6, 6, "physical", "", false, false], [15, 17, 6, 6, "physical", "", false, false], [23, 24, 10, 12, "origin", "", false, false], [23, 24, 15, 17, "origin", "", false, false], [23, 24, 30, 33, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "late", "1980s", ",", "two", "Dutch", "universities", ",", "the", "University", "of", "Groningen", "and", "the", "University", "of", "Twente", ",", "jointly", "launched", "the", "\"", "Knowledge", "Graphs", "\"", "project", ",", "which", "are", "semantic", "networks", ",", "but", "with", "the", "additional", "restriction", "that", "the", "edges", "are", "restricted", "to", "be", "from", "a", "limited", "set", "of", "possible", "relations", "to", "facilitate", "algebra", "in", "the", "graph", "."], "sentence-detokenized": "In the late 1980s, two Dutch universities, the University of Groningen and the University of Twente, jointly launched the \"Knowledge Graphs\" project, which are semantic networks, but with the additional restriction that the edges are restricted to be from a limited set of possible relations to facilitate algebra in the graph.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 17], [17, 18], [19, 22], [23, 28], [29, 41], [41, 42], [43, 46], [47, 57], [58, 60], [61, 70], [71, 74], [75, 78], [79, 89], [90, 92], [93, 99], [99, 100], [101, 108], [109, 117], [118, 121], [122, 123], [123, 132], [133, 139], [139, 140], [141, 148], [148, 149], [150, 155], [156, 159], [160, 168], [169, 177], [177, 178], [179, 182], [183, 187], [188, 191], [192, 202], [203, 214], [215, 219], [220, 223], [224, 229], [230, 233], [234, 244], [245, 247], [248, 250], [251, 255], [256, 257], [258, 265], [266, 269], [270, 272], [273, 281], [282, 291], [292, 294], [295, 305], [306, 313], [314, 316], [317, 320], [321, 326], [326, 327]]}
{"doc_key": "ai-train-63", "ner": [[0, 1, "product"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Grammar", "checkers", "are", "most", "often", "implemented", "as", "a", "feature", "of", "a", "larger", "application", "such", "as", "a", "word", "processor", ",", "but", "they", "are", "also", "available", "as", "stand", "-", "alone", "applications", "that", "can", "be", "activated", "from", "programs", "that", "work", "with", "editable", "text", "."], "sentence-detokenized": "Grammar checkers are most often implemented as a feature of a larger application such as a word processor, but they are also available as stand-alone applications that can be activated from programs that work with editable text.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 31], [32, 43], [44, 46], [47, 48], [49, 56], [57, 59], [60, 61], [62, 68], [69, 80], [81, 85], [86, 88], [89, 90], [91, 95], [96, 105], [105, 106], [107, 110], [111, 115], [116, 119], [120, 124], [125, 134], [135, 137], [138, 143], [143, 144], [144, 149], [150, 162], [163, 167], [168, 171], [172, 174], [175, 184], [185, 189], [190, 198], [199, 203], [204, 208], [209, 213], [214, 222], [223, 227], [227, 228]]}
{"doc_key": "ai-train-64", "ner": [[6, 12, "organisation"], [15, 21, "conference"], [25, 27, "organisation"], [34, 36, "conference"], [39, 40, "conference"], [43, 45, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ",", "and", "the", "Cognitive", "Science", "Society", ",", "and", "is", "an", "editor", "of", "J.", "Automated", "Reasoning", ",", "J.", "Learning", "Sciences", ",", "and", "J.", "Applied", "Ontology", "."], "sentence-detokenized": "He is a member of the American Association for the Advancement of Science, the Association for the Advancement of Artificial Intelligence, and the Cognitive Science Society, and is an editor of J. Automated Reasoning, J. Learning Sciences, and J. Applied Ontology.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 42], [43, 46], [47, 50], [51, 62], [63, 65], [66, 73], [73, 74], [75, 78], [79, 90], [91, 94], [95, 98], [99, 110], [111, 113], [114, 124], [125, 137], [137, 138], [139, 142], [143, 146], [147, 156], [157, 164], [165, 172], [172, 173], [174, 177], [178, 180], [181, 183], [184, 190], [191, 193], [194, 196], [197, 206], [207, 216], [216, 217], [218, 220], [221, 229], [230, 238], [238, 239], [240, 243], [244, 246], [247, 254], [255, 263], [263, 264]]}
{"doc_key": "ai-train-65", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 13, "task"], [19, 20, "researcher"], [22, 23, "university"], [25, 26, "researcher"], [28, 31, "organisation"], [33, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 10, 13, "type-of", "", false, false], [0, 2, 19, 20, "origin", "", false, false], [0, 2, 25, 26, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [19, 20, 22, 23, "physical", "", false, false], [19, 20, 22, 23, "role", "", false, false], [25, 26, 28, 31, "role", "", false, false], [33, 33, 28, 31, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", ",", "a", "type", "of", "speech", "coding", ",", "was", "first", "developed", "in", "1966", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "."], "sentence-detokenized": "Linear predictive coding (LPC), a type of speech coding, was first developed in 1966 by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT).", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 38], [39, 41], [42, 48], [49, 55], [55, 56], [57, 60], [61, 66], [67, 76], [77, 79], [80, 84], [85, 87], [88, 96], [97, 104], [105, 107], [108, 114], [115, 125], [126, 129], [130, 135], [136, 141], [142, 144], [145, 151], [152, 161], [162, 165], [166, 175], [176, 177], [177, 180], [180, 181], [181, 182]]}
{"doc_key": "ai-train-66", "ner": [[55, 57, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "signal", "is", "ergodic", ",", "then", "all", "sample", "paths", "have", "the", "same", "time", "average", "and", "thus", "mathR", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "\\", "tau", ")", "=", "widehat", "{", "R", "}", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "\\", "tau", ")", "/", "math", "in", "the", "mean", "square", "error", "sense", "."], "sentence-detokenized": "If the signal is ergodic, then all sample paths have the same time average and thus mathR _ x^ {n / T _ 0} (\\ tau) = widehat {R} _ x^ {n / T _ 0} (\\ tau) / math in the mean square error sense.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 24], [24, 25], [26, 30], [31, 34], [35, 41], [42, 47], [48, 52], [53, 56], [57, 61], [62, 66], [67, 74], [75, 78], [79, 83], [84, 89], [90, 91], [92, 93], [93, 94], [95, 96], [96, 97], [98, 99], [100, 101], [102, 103], [104, 105], [105, 106], [107, 108], [108, 109], [110, 113], [113, 114], [115, 116], [117, 124], [125, 126], [126, 127], [127, 128], [129, 130], [131, 132], [132, 133], [134, 135], [135, 136], [137, 138], [139, 140], [141, 142], [143, 144], [144, 145], [146, 147], [147, 148], [149, 152], [152, 153], [154, 155], [156, 160], [161, 163], [164, 167], [168, 172], [173, 179], [180, 185], [186, 191], [191, 192]]}
{"doc_key": "ai-train-67", "ner": [[0, 1, "task"], [3, 4, "task"], [13, 15, "algorithm"], [17, 17, "algorithm"], [20, 22, "algorithm"], [24, 24, "algorithm"], [27, 29, "algorithm"], [31, 31, "algorithm"], [34, 36, "algorithm"], [38, 38, "algorithm"], [43, 47, "misc"], [48, 50, "algorithm"], [53, 56, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[13, 15, 43, 47, "related-to", "", false, false], [17, 17, 13, 15, "named", "", false, false], [20, 22, 43, 47, "related-to", "", false, false], [24, 24, 20, 22, "named", "", false, false], [27, 29, 43, 47, "related-to", "", false, false], [31, 31, 27, 29, "named", "", false, false], [34, 36, 43, 47, "related-to", "", false, false], [38, 38, 34, 36, "named", "", false, false], [48, 50, 53, 56, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Feature", "extraction", "and", "dimension", "reduction", "can", "be", "combined", "in", "a", "single", "step", "using", "principal", "component", "analysis", "(", "PCA", ")", ",", "linear", "discriminant", "analysis", "(", "LDA", ")", ",", "canonical", "correlation", "analysis", "(", "CCA", ")", "or", "non-negative", "matrix", "factorisation", "(", "NMF", ")", "methods", "as", "a", "preprocessing", "step", ",", "followed", "by", "K", "-", "NN", "clustering", "over", "feature", "vectors", "in", "the", "dimension", "-", "reduced", "space", "."], "sentence-detokenized": "Feature extraction and dimension reduction can be combined in a single step using principal component analysis (PCA), linear discriminant analysis (LDA), canonical correlation analysis (CCA) or non-negative matrix factorisation (NMF) methods as a preprocessing step, followed by K-NN clustering over feature vectors in the dimension-reduced space.", "token2charspan": [[0, 7], [8, 18], [19, 22], [23, 32], [33, 42], [43, 46], [47, 49], [50, 58], [59, 61], [62, 63], [64, 70], [71, 75], [76, 81], [82, 91], [92, 101], [102, 110], [111, 112], [112, 115], [115, 116], [116, 117], [118, 124], [125, 137], [138, 146], [147, 148], [148, 151], [151, 152], [152, 153], [154, 163], [164, 175], [176, 184], [185, 186], [186, 189], [189, 190], [191, 193], [194, 206], [207, 213], [214, 227], [228, 229], [229, 232], [232, 233], [234, 241], [242, 244], [245, 246], [247, 260], [261, 265], [265, 266], [267, 275], [276, 278], [279, 280], [280, 281], [281, 283], [284, 294], [295, 299], [300, 307], [308, 315], [316, 318], [319, 322], [323, 332], [332, 333], [333, 340], [341, 346], [346, 347]]}
{"doc_key": "ai-train-68", "ner": [[3, 3, "programlang"], [5, 5, "programlang"], [7, 7, "programlang"], [9, 9, "programlang"], [14, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 15, 3, 3, "related-to", "program_type_compatible_with", false, false], [14, 15, 5, 5, "related-to", "program_type_compatible_with", false, false], [14, 15, 7, 7, "related-to", "program_type_compatible_with", false, false], [14, 15, 9, 9, "related-to", "program_type_compatible_with", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Libraries", "written", "in", "Perl", ",", "Java", ",", "ActiveX", "or", ".NET", "can", "be", "called", "directly", "from", "MATLAB", ","], "sentence-detokenized": "Libraries written in Perl, Java, ActiveX or .NET can be called directly from MATLAB,", "token2charspan": [[0, 9], [10, 17], [18, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 40], [41, 43], [44, 48], [49, 52], [53, 55], [56, 62], [63, 71], [72, 76], [77, 83], [83, 84]]}
{"doc_key": "ai-train-69", "ner": [[0, 13, "task"], [7, 16, "task"], [30, 31, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 13, 7, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "named", "entity", "recognition", "task", "is", "the", "recognition", "of", "named", "entities", "in", "the", "text", ",", "while", "the", "task", "of", "determining", "the", "identity", "of", "named", "entities", "in", "the", "text", "is", "called", "entity", "linkage", "."], "sentence-detokenized": "The named entity recognition task is the recognition of named entities in the text, while the task of determining the identity of named entities in the text is called entity linkage.", "token2charspan": [[0, 3], [4, 9], [10, 16], [17, 28], [29, 33], [34, 36], [37, 40], [41, 52], [53, 55], [56, 61], [62, 70], [71, 73], [74, 77], [78, 82], [82, 83], [84, 89], [90, 93], [94, 98], [99, 101], [102, 113], [114, 117], [118, 126], [127, 129], [130, 135], [136, 144], [145, 147], [148, 151], [152, 156], [157, 159], [160, 166], [167, 173], [174, 181], [181, 182]]}
{"doc_key": "ai-train-70", "ner": [[0, 1, "algorithm"], [28, 28, "programlang"], [30, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 30, 31, "part-of", "", true, false], [30, 31, 28, 28, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "sigmoid", "functions", "and", "derivatives", "used", "in", "the", "package", "were", "originally", "included", "in", "the", "package", ",", "but", "as", "of", "version", "0.8.0", "they", "have", "been", "published", "in", "a", "separate", "R", "package", "sigmoid", "to", "allow", "wider", "use", "."], "sentence-detokenized": "The sigmoid functions and derivatives used in the package were originally included in the package, but as of version 0.8.0 they have been published in a separate R package sigmoid to allow wider use.", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 25], [26, 37], [38, 42], [43, 45], [46, 49], [50, 57], [58, 62], [63, 73], [74, 82], [83, 85], [86, 89], [90, 97], [97, 98], [99, 102], [103, 105], [106, 108], [109, 116], [117, 122], [123, 127], [128, 132], [133, 137], [138, 147], [148, 150], [151, 152], [153, 161], [162, 163], [164, 171], [172, 179], [180, 182], [183, 188], [189, 194], [195, 198], [198, 199]]}
{"doc_key": "ai-train-71", "ner": [[0, 1, "programlang"], [16, 20, "organisation"], [22, 25, "organisation"], [28, 29, "location"], [31, 33, "location"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 7, 8, "artifact", "", true, false], [0, 1, 10, 11, "artifact", "", true, false], [0, 1, 13, 15, "artifact", "", true, false], [22, 25, 16, 20, "named", "", false, false], [22, 25, 28, 29, "physical", "", false, false], [28, 29, 31, 33, "physical", "", false, false], [7, 8, 16, 20, "role", "", false, false], [10, 11, 16, 20, "role", "", false, false], [13, 15, 16, 20, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "logo", "was", "created", "in", "1967", "by", "Vally", "Feurzeigs", ",", "Cynthia", "Solomon", "and", "Seymour", "Papert", "at", "Bolt", ",", "Beranek", "and", "Newman", "(", "BBN", ")", ",", "a", "research", "company", "in", "Cambridge", ",", "Massachusetts", ",", "USA", "."], "sentence-detokenized": "The logo was created in 1967 by Vally Feurzeigs, Cynthia Solomon and Seymour Papert at Bolt, Beranek and Newman (BBN), a research company in Cambridge, Massachusetts, USA.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 20], [21, 23], [24, 28], [29, 31], [32, 37], [38, 47], [47, 48], [49, 56], [57, 64], [65, 68], [69, 76], [77, 83], [84, 86], [87, 91], [91, 92], [93, 100], [101, 104], [105, 111], [112, 113], [113, 116], [116, 117], [117, 118], [119, 120], [121, 129], [130, 137], [138, 140], [141, 150], [150, 151], [152, 165], [165, 166], [167, 170], [170, 171]]}
{"doc_key": "ai-train-72", "ner": [[0, 0, "misc"], [8, 9, "field"], [17, 18, "field"], [22, 23, "algorithm"], [24, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 9, "part-of", "", false, false], [0, 0, 17, 18, "compare", "", false, false], [22, 23, 17, 18, "part-of", "", false, false], [24, 27, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Neuroevolution", "is", "commonly", "used", "as", "part", "of", "a", "reinforcement", "learning", "paradigm", "and", "can", "be", "contrasted", "with", "conventional", "deep", "learning", "methods", "that", "use", "gradient", "descent", "in", "a", "neural", "network", "with", "a", "fixed", "topology", "."], "sentence-detokenized": "Neuroevolution is commonly used as part of a reinforcement learning paradigm and can be contrasted with conventional deep learning methods that use gradient descent in a neural network with a fixed topology.", "token2charspan": [[0, 14], [15, 17], [18, 26], [27, 31], [32, 34], [35, 39], [40, 42], [43, 44], [45, 58], [59, 67], [68, 76], [77, 80], [81, 84], [85, 87], [88, 98], [99, 103], [104, 116], [117, 121], [122, 130], [131, 138], [139, 143], [144, 147], [148, 156], [157, 164], [165, 167], [168, 169], [170, 176], [177, 184], [185, 189], [190, 191], [192, 197], [198, 206], [206, 207]]}
{"doc_key": "ai-train-73", "ner": [[4, 5, "algorithm"], [56, 58, "metrics"], [60, 60, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[60, 60, 56, 58, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["If", "we", "use", "the", "least", "squares", "method", "to", "fit", "a", "function", "to", "the", "data", "(", "x", "sub", "i", "/", "sub", ",", "y", "sub", "i", "/", "sub", ")", "sub", "1", "\u2264", "i", "\u2264", "n/", "sub", "in", "the", "hyperplane", "form", "\u0177", "=", "a", "+", "\u03b2", "supT", "/", "sup", "x", ",", "then", "we", "could", "assess", "the", "fit", "using", "the", "mean", "squared", "error", "(", "MSE", ")", "."], "sentence-detokenized": "If we use the least squares method to fit a function to the data (x sub i/sub, y sub i/sub) sub 1 \u2264 i \u2264 n/sub in the hyperplane form \u0177 = a + \u03b2 supT/sup x, then we could assess the fit using the mean squared error (MSE).", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 13], [14, 19], [20, 27], [28, 34], [35, 37], [38, 41], [42, 43], [44, 52], [53, 55], [56, 59], [60, 64], [65, 66], [66, 67], [68, 71], [72, 73], [73, 74], [74, 77], [77, 78], [79, 80], [81, 84], [85, 86], [86, 87], [87, 90], [90, 91], [92, 95], [96, 97], [98, 99], [100, 101], [102, 103], [104, 106], [106, 109], [110, 112], [113, 116], [117, 127], [128, 132], [133, 134], [135, 136], [137, 138], [139, 140], [141, 142], [143, 147], [147, 148], [148, 151], [152, 153], [153, 154], [155, 159], [160, 162], [163, 168], [169, 175], [176, 179], [180, 183], [184, 189], [190, 193], [194, 198], [199, 206], [207, 212], [213, 214], [214, 217], [217, 218], [218, 219]]}
{"doc_key": "ai-train-74", "ner": [[6, 6, "country"], [8, 8, "country"], [10, 10, "country"], [12, 12, "country"], [14, 14, "country"], [16, 16, "country"], [18, 18, "country"], [20, 20, "country"], [22, 22, "country"], [24, 24, "country"], [26, 26, "country"], [28, 28, "country"], [30, 30, "country"], [32, 32, "country"], [34, 34, "country"], [36, 50, "country"], [39, 39, "country"], [41, 41, "country"], [43, 43, "country"], [45, 45, "country"], [52, 54, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "company", "has", "international", "offices", "in", "Australia", ",", "Brazil", ",", "Canada", ",", "China", ",", "Germany", ",", "India", ",", "Italy", ",", "Japan", ",", "Korea", ",", "Lithuania", ",", "Poland", ",", "Malaysia", ",", "Philippines", ",", "Russia", ",", "Singapore", ",", "South", "Africa", ",", "Spain", ",", "Taiwan", ",", "Thailand", ",", "Turkey", ",", "Spain", ",", "South", "Africa", "and", "the", "United", "Kingdom", "."], "sentence-detokenized": "The company has international offices in Australia, Brazil, Canada, China, Germany, India, Italy, Japan, Korea, Lithuania, Poland, Malaysia, Philippines, Russia, Singapore, South Africa, Spain, Taiwan, Thailand, Turkey, Spain, South Africa and the United Kingdom.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 29], [30, 37], [38, 40], [41, 50], [50, 51], [52, 58], [58, 59], [60, 66], [66, 67], [68, 73], [73, 74], [75, 82], [82, 83], [84, 89], [89, 90], [91, 96], [96, 97], [98, 103], [103, 104], [105, 110], [110, 111], [112, 121], [121, 122], [123, 129], [129, 130], [131, 139], [139, 140], [141, 152], [152, 153], [154, 160], [160, 161], [162, 171], [171, 172], [173, 178], [179, 185], [185, 186], [187, 192], [192, 193], [194, 200], [200, 201], [202, 210], [210, 211], [212, 218], [218, 219], [220, 225], [225, 226], [227, 232], [233, 239], [240, 243], [244, 247], [248, 254], [255, 262], [262, 263]]}
{"doc_key": "ai-train-75", "ner": [[0, 3, "misc"], [4, 8, "field"], [16, 16, "organisation"], [12, 24, "university"], [29, 31, "organisation"], [33, 38, "university"], [41, 43, "university"], [45, 46, "university"], [49, 51, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 3, 4, 8, "topic", "", false, false], [0, 3, 16, 16, "origin", "", false, false], [0, 3, 12, 24, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "holds", "a", "PhD", "in", "Electrical", "and", "Computer", "Engineering", "(", "2000", ")", "from", "the", "Universities", "of", "Inria", "and", "Nice", "-", "Sophia", "Antipolis", ",", "and", "has", "held", "permanent", "positions", "at", "Siemens", "Corporate", "Technology", ",", "\u00c9cole", "des", "ponts", "ParisTech", ",", "and", "guest", "lectureships", "at", "Rutgers", "University", ",", "Yale", "University", "and", "the", "University", "of", "Houston", "."], "sentence-detokenized": "He holds a PhD in Electrical and Computer Engineering (2000) from the Universities of Inria and Nice-Sophia Antipolis, and has held permanent positions at Siemens Corporate Technology, \u00c9cole des ponts ParisTech, and guest lectureships at Rutgers University, Yale University and the University of Houston.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 14], [15, 17], [18, 28], [29, 32], [33, 41], [42, 53], [54, 55], [55, 59], [59, 60], [61, 65], [66, 69], [70, 82], [83, 85], [86, 91], [92, 95], [96, 100], [100, 101], [101, 107], [108, 117], [117, 118], [119, 122], [123, 126], [127, 131], [132, 141], [142, 151], [152, 154], [155, 162], [163, 172], [173, 183], [183, 184], [185, 190], [191, 194], [195, 200], [201, 210], [210, 211], [212, 215], [216, 221], [222, 234], [235, 237], [238, 245], [246, 256], [256, 257], [258, 262], [263, 273], [274, 277], [278, 281], [282, 292], [293, 295], [296, 303], [303, 304]]}
{"doc_key": "ai-train-76", "ner": [[7, 8, "researcher"], [10, 10, "researcher"], [14, 15, "product"], [16, 18, "country"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 10, 7, 8, "role", "licensing_patent_to", false, false], [10, 10, 16, 18, "physical", "", false, false], [20, 20, 10, 10, "artifact", "", false, false], [20, 20, 14, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Using", "the", "original", "patent", "granted", "to", "inventor", "George", "Devol", ",", "Engelberger", "developed", "the", "first", "industrial", "robot", "in", "the", "US", "-", "Unimate", "-", "in", "the", "1950s", "."], "sentence-detokenized": "Using the original patent granted to inventor George Devol, Engelberger developed the first industrial robot in the US - Unimate - in the 1950s.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 25], [26, 33], [34, 36], [37, 45], [46, 52], [53, 58], [58, 59], [60, 71], [72, 81], [82, 85], [86, 91], [92, 102], [103, 108], [109, 111], [112, 115], [116, 118], [119, 120], [121, 128], [129, 130], [131, 133], [134, 137], [138, 143], [143, 144]]}
{"doc_key": "ai-train-77", "ner": [[5, 7, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "input", "data", "is", "called", "speech", "recognition", "and", "the", "output", "data", "is", "called", "speech", "synthesis", "."], "sentence-detokenized": "The input data is called speech recognition and the output data is called speech synthesis.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 17], [18, 24], [25, 31], [32, 43], [44, 47], [48, 51], [52, 58], [59, 63], [64, 66], [67, 73], [74, 80], [81, 90], [90, 91]]}
{"doc_key": "ai-train-78", "ner": [[0, 0, "programlang"], [4, 4, "programlang"], [12, 12, "programlang"], [15, 15, "programlang"], [25, 25, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 12, 12, "named", "", false, false], [4, 4, 0, 0, "origin", "descendant_of", false, false], [4, 4, 15, 15, "general-affiliation", "", false, false], [4, 4, 25, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["CLIPS", "language", "descendants", "are", "Jess", "(", "the", "rules", "-", "based", "part", "of", "CLIPS", "rewritten", "in", "Java", ",", "later", "evolved", "in", "a", "different", "direction", ")", ",", "JESS", "was", "originally", "inspired", "by"], "sentence-detokenized": "CLIPS language descendants are Jess (the rules-based part of CLIPS rewritten in Java, later evolved in a different direction), JESS was originally inspired by", "token2charspan": [[0, 5], [6, 14], [15, 26], [27, 30], [31, 35], [36, 37], [37, 40], [41, 46], [46, 47], [47, 52], [53, 57], [58, 60], [61, 66], [67, 76], [77, 79], [80, 84], [84, 85], [86, 91], [92, 99], [100, 102], [103, 104], [105, 114], [115, 124], [124, 125], [125, 126], [127, 131], [132, 135], [136, 146], [147, 155], [156, 158]]}
{"doc_key": "ai-train-79", "ner": [[7, 7, "product"], [12, 15, "product"], [17, 18, "organisation"], [22, 23, "product"], [40, 41, "product"], [43, 47, "product"], [60, 63, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 15, 7, 7, "type-of", "", false, false], [17, 18, 12, 15, "usage", "", false, false], [22, 23, 17, 18, "artifact", "", false, false], [40, 41, 17, 18, "origin", "", true, false], [40, 41, 60, 63, "related-to", "", true, false], [43, 47, 17, 18, "origin", "", true, false], [43, 47, 60, 63, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "company", "has", "also", "created", "flexible", "intelligent", "AGV", "applications", "by", "developing", "the", "Motivity", "control", "system", "used", "by", "RMT", "Robotics", "to", "develop", "the", "ADAM", "iAGV", "(", "self", "-", "driving", "vehicle", ")", "used", "for", "complex", "picking", "and", "stacking", "operations", ",", "together", "with", "gantry", "systems", "and", "industrial", "robotic", "arms", "used", "in", "tier", "one", "automotive", "supply", "factories", "to", "move", "products", "from", "process", "to", "process", "in", "a", "non-linear", "layout", "."], "sentence-detokenized": "The company has also created flexible intelligent AGV applications by developing the Motivity control system used by RMT Robotics to develop the ADAM iAGV (self-driving vehicle) used for complex picking and stacking operations, together with gantry systems and industrial robotic arms used in tier one automotive supply factories to move products from process to process in a non-linear layout.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 20], [21, 28], [29, 37], [38, 49], [50, 53], [54, 66], [67, 69], [70, 80], [81, 84], [85, 93], [94, 101], [102, 108], [109, 113], [114, 116], [117, 120], [121, 129], [130, 132], [133, 140], [141, 144], [145, 149], [150, 154], [155, 156], [156, 160], [160, 161], [161, 168], [169, 176], [176, 177], [178, 182], [183, 186], [187, 194], [195, 202], [203, 206], [207, 215], [216, 226], [226, 227], [228, 236], [237, 241], [242, 248], [249, 256], [257, 260], [261, 271], [272, 279], [280, 284], [285, 289], [290, 292], [293, 297], [298, 301], [302, 312], [313, 319], [320, 329], [330, 332], [333, 337], [338, 346], [347, 351], [352, 359], [360, 362], [363, 370], [371, 373], [374, 375], [376, 386], [387, 393], [393, 394]]}
{"doc_key": "ai-train-80", "ner": [[8, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "parameters", "\u03b2", "are", "usually", "estimated", "by", "the", "maximum", "likelihood", "method", "."], "sentence-detokenized": "The parameters \u03b2 are usually estimated by the maximum likelihood method.", "token2charspan": [[0, 3], [4, 14], [15, 16], [17, 20], [21, 28], [29, 38], [39, 41], [42, 45], [46, 53], [54, 64], [65, 71], [71, 72]]}
{"doc_key": "ai-train-81", "ner": [[0, 1, "task"], [5, 5, "metrics"], [7, 7, "metrics"], [9, 9, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 0, 1, "part-of", "", false, false], [7, 7, 0, 1, "part-of", "", false, false], [9, 9, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Information", "retrieval", "metrics", "such", "as", "precision", "and", "recall", "or", "DCG", "are", "useful", "for", "assessing", "the", "quality", "of", "a", "recommendation", "method", "."], "sentence-detokenized": "Information retrieval metrics such as precision and recall or DCG are useful for assessing the quality of a recommendation method.", "token2charspan": [[0, 11], [12, 21], [22, 29], [30, 34], [35, 37], [38, 47], [48, 51], [52, 58], [59, 61], [62, 65], [66, 69], [70, 76], [77, 80], [81, 90], [91, 94], [95, 102], [103, 105], [106, 107], [108, 122], [123, 129], [129, 130]]}
{"doc_key": "ai-train-82", "ner": [[9, 12, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "a", "typical", "factory", ",", "there", "are", "hundreds", "of", "industrial", "robots", "working", "in", "fully", "automated", "production", "lines", ",", "with", "one", "robot", "for", "every", "ten", "people", "working", "."], "sentence-detokenized": "In a typical factory, there are hundreds of industrial robots working in fully automated production lines, with one robot for every ten people working.", "token2charspan": [[0, 2], [3, 4], [5, 12], [13, 20], [20, 21], [22, 27], [28, 31], [32, 40], [41, 43], [44, 54], [55, 61], [62, 69], [70, 72], [73, 78], [79, 88], [89, 99], [100, 105], [105, 106], [107, 111], [112, 115], [116, 121], [122, 125], [126, 131], [132, 135], [136, 142], [143, 150], [150, 151]]}
{"doc_key": "ai-train-83", "ner": [[5, 5, "product"], [13, 14, "field"], [18, 19, "task"], [21, 22, "task"], [24, 25, "task"], [27, 28, "task"], [30, 31, "task"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[13, 14, 5, 5, "usage", "", false, true], [18, 19, 13, 14, "part-of", "", false, false], [21, 22, 13, 14, "part-of", "", false, false], [24, 25, 13, 14, "part-of", "", false, false], [27, 28, 13, 14, "part-of", "", false, false], [30, 31, 13, 14, "part-of", "", false, false], [33, 34, 13, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Over", "the", "past", "decade", ",", "PCNNs", "have", "been", "used", "in", "a", "variety", "of", "image", "processing", "applications", ",", "including", "image", "segmentation", ",", "feature", "generation", ",", "face", "extraction", ",", "motion", "detection", ",", "region", "growing", "and", "noise", "reduction", "."], "sentence-detokenized": "Over the past decade, PCNNs have been used in a variety of image processing applications, including image segmentation, feature generation, face extraction, motion detection, region growing and noise reduction.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 20], [20, 21], [22, 27], [28, 32], [33, 37], [38, 42], [43, 45], [46, 47], [48, 55], [56, 58], [59, 64], [65, 75], [76, 88], [88, 89], [90, 99], [100, 105], [106, 118], [118, 119], [120, 127], [128, 138], [138, 139], [140, 144], [145, 155], [155, 156], [157, 163], [164, 173], [173, 174], [175, 181], [182, 189], [190, 193], [194, 199], [200, 209], [209, 210]]}
{"doc_key": "ai-train-84", "ner": [[0, 0, "researcher"], [16, 17, "field"], [21, 23, "misc"], [24, 32, "conference"], [34, 34, "conference"], [39, 40, "misc"], [43, 50, "conference"], [51, 52, "conference"], [54, 58, "conference"], [60, 60, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 0, 16, 17, "related-to", "contributes_to", false, false], [0, 0, 21, 23, "win-defeat", "", false, false], [0, 0, 39, 40, "win-defeat", "", false, false], [21, 23, 24, 32, "temporal", "", false, false], [34, 34, 24, 32, "named", "", false, false], [39, 40, 43, 50, "temporal", "", false, false], [39, 40, 54, 58, "temporal", "", false, false], [51, 52, 43, 50, "named", "", false, false], [60, 60, 54, 58, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Xu", "has", "published", "more", "than", "50", "papers", "in", "international", "conferences", "and", "journals", "in", "the", "field", "of", "computer", "vision", "and", "won", "the", "Best", "Paper", "Award", "at", "the", "International", "Conference", "on", "Non-Photorealistic", "Rendering", "and", "Animation", "(", "NPAR", ")", "2012", "and", "the", "Best", "Reviewer", "Award", "at", "the", "International", "Conferences", "Asian", "Conference", "on", "Computer", "Vision", "ACCV", "2012", "and", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "2015", "."], "sentence-detokenized": "Xu has published more than 50 papers in international conferences and journals in the field of computer vision and won the Best Paper Award at the International Conference on Non-Photorealistic Rendering and Animation (NPAR) 2012 and the Best Reviewer Award at the International Conferences Asian Conference on Computer Vision ACCV 2012 and International Conference on Computer Vision (ICCV) 2015.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 21], [22, 26], [27, 29], [30, 36], [37, 39], [40, 53], [54, 65], [66, 69], [70, 78], [79, 81], [82, 85], [86, 91], [92, 94], [95, 103], [104, 110], [111, 114], [115, 118], [119, 122], [123, 127], [128, 133], [134, 139], [140, 142], [143, 146], [147, 160], [161, 171], [172, 174], [175, 193], [194, 203], [204, 207], [208, 217], [218, 219], [219, 223], [223, 224], [225, 229], [230, 233], [234, 237], [238, 242], [243, 251], [252, 257], [258, 260], [261, 264], [265, 278], [279, 290], [291, 296], [297, 307], [308, 310], [311, 319], [320, 326], [327, 331], [332, 336], [337, 340], [341, 354], [355, 365], [366, 368], [369, 377], [378, 384], [385, 386], [386, 390], [390, 391], [392, 396], [396, 397]]}
{"doc_key": "ai-train-85", "ner": [[0, 0, "programlang"], [1, 3, "field"], [5, 6, "field"], [9, 11, "misc"], [13, 15, "researcher"], [16, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 1, 3, "part-of", "", false, false], [0, 0, 5, 6, "part-of", "", false, false], [0, 0, 9, 11, "type-of", "", false, false], [16, 18, 0, 0, "usage", "", false, false], [16, 18, 13, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["CycL", "in", "computer", "science", "and", "artificial", "intelligence", "is", "the", "ontology", "language", "used", "in", "Doug", "Lenat", "'s", "Cyc", "artificial", "project", "."], "sentence-detokenized": "CycL in computer science and artificial intelligence is the ontology language used in Doug Lenat's Cyc artificial project.", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 24], [25, 28], [29, 39], [40, 52], [53, 55], [56, 59], [60, 68], [69, 77], [78, 82], [83, 85], [86, 90], [91, 96], [96, 98], [99, 102], [103, 113], [114, 121], [121, 122]]}
{"doc_key": "ai-train-86", "ner": [[1, 3, "task"], [5, 8, "metrics"], [15, 18, "metrics"], [21, 28, "metrics"], [37, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 8, 1, 3, "part-of", "", false, false], [15, 18, 5, 8, "named", "", false, false], [21, 28, 5, 8, "named", "", false, false], [37, 39, 5, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Also", "in", "regression", "analysis", ",", "the", "mean", "squared", "error", ",", "often", "referred", "to", "as", "the", "mean", "squared", "prediction", "error", "or", "the", "out", "-", "of", "-", "sample", "mean", "squared", "error", ",", "can", "refer", "to", "the", "average", "of", "the", "squared", "deviations", "of", "the", "predictions", "from", "the", "true", "values", "in", "the", "out", "-", "of", "-", "sample", "test", "space", "generated", "by", "the", "model", "estimated", "in", "a", "given", "sample", "space", "."], "sentence-detokenized": "Also in regression analysis, the mean squared error, often referred to as the mean squared prediction error or the out-of-sample mean squared error, can refer to the average of the squared deviations of the predictions from the true values in the out-of-sample test space generated by the model estimated in a given sample space.", "token2charspan": [[0, 4], [5, 7], [8, 18], [19, 27], [27, 28], [29, 32], [33, 37], [38, 45], [46, 51], [51, 52], [53, 58], [59, 67], [68, 70], [71, 73], [74, 77], [78, 82], [83, 90], [91, 101], [102, 107], [108, 110], [111, 114], [115, 118], [118, 119], [119, 121], [121, 122], [122, 128], [129, 133], [134, 141], [142, 147], [147, 148], [149, 152], [153, 158], [159, 161], [162, 165], [166, 173], [174, 176], [177, 180], [181, 188], [189, 199], [200, 202], [203, 206], [207, 218], [219, 223], [224, 227], [228, 232], [233, 239], [240, 242], [243, 246], [247, 250], [250, 251], [251, 253], [253, 254], [254, 260], [261, 265], [266, 271], [272, 281], [282, 284], [285, 288], [289, 294], [295, 304], [305, 307], [308, 309], [310, 315], [316, 322], [323, 328], [328, 329]]}
{"doc_key": "ai-train-87", "ner": [[5, 7, "algorithm"], [9, 10, "algorithm"], [18, 24, "algorithm"], [35, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 9, 10, "compare", "", false, false], [5, 7, 18, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "results", "show", "that", "the", "C", "-", "HOG", "and", "R-", "HOG", "block", "descriptors", "perform", "comparably", ",", "and", "that", "the", "C", "-", "HOG", "descriptors", "have", "a", "slight", "advantage", "in", "terms", "of", "detection", "error", "rate", "for", "fixed", "FALSE", "positives", "in", "both", "datasets", "."], "sentence-detokenized": "The results show that the C-HOG and R-HOG block descriptors perform comparably, and that the C-HOG descriptors have a slight advantage in terms of detection error rate for fixed FALSE positives in both datasets.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 21], [22, 25], [26, 27], [27, 28], [28, 31], [32, 35], [36, 38], [38, 41], [42, 47], [48, 59], [60, 67], [68, 78], [78, 79], [80, 83], [84, 88], [89, 92], [93, 94], [94, 95], [95, 98], [99, 110], [111, 115], [116, 117], [118, 124], [125, 134], [135, 137], [138, 143], [144, 146], [147, 156], [157, 162], [163, 167], [168, 171], [172, 177], [178, 183], [184, 193], [194, 196], [197, 201], [202, 210], [210, 211]]}
{"doc_key": "ai-train-88", "ner": [[6, 8, "algorithm"], [10, 10, "misc"], [12, 14, "algorithm"], [16, 17, "algorithm"], [20, 22, "algorithm"], [24, 26, "algorithm"], [28, 30, "algorithm"], [32, 33, "misc"], [38, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 8, 10, 10, "usage", "", false, false], [12, 14, 32, 33, "usage", "", false, false], [16, 17, 32, 33, "usage", "", false, false], [20, 22, 32, 33, "usage", "", false, false], [24, 26, 32, 33, "usage", "", false, false], [28, 30, 32, 33, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "most", "popular", "recognition", "algorithms", "are", "principal", "component", "analysis", "using", "eigenfaces", ",", "linear", "discriminant", "analysis", ",", "flexible", "matching", "using", "the", "Fisher", "surface", "algorithm", ",", "hidden", "Markov", "model", ",", "multilinear", "subspace", "learning", "using", "tensor", "representation", ",", "and", "neurally", "motivated", "dynamic", "link", "matching", "."], "sentence-detokenized": "The most popular recognition algorithms are principal component analysis using eigenfaces, linear discriminant analysis, flexible matching using the Fisher surface algorithm, hidden Markov model, multilinear subspace learning using tensor representation, and neurally motivated dynamic link matching.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 28], [29, 39], [40, 43], [44, 53], [54, 63], [64, 72], [73, 78], [79, 89], [89, 90], [91, 97], [98, 110], [111, 119], [119, 120], [121, 129], [130, 138], [139, 144], [145, 148], [149, 155], [156, 163], [164, 173], [173, 174], [175, 181], [182, 188], [189, 194], [194, 195], [196, 207], [208, 216], [217, 225], [226, 231], [232, 238], [239, 253], [253, 254], [255, 258], [259, 267], [268, 277], [278, 285], [286, 290], [291, 299], [299, 300]]}
{"doc_key": "ai-train-89", "ner": [[3, 7, "misc"], [16, 19, "location"], [37, 39, "location"], [51, 52, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 19, 3, 7, "temporal", "", false, false], [37, 39, 3, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Starting", "with", "the", "2019", "Toronto", "International", "Film", "Festival", ",", "films", "can", "now", "be", "banned", "from", "the", "Scotiabank", "Theatre", "in", "Toronto", "-", "one", "of", "the", "festival", "'s", "main", "venues", "-", "and", "from", "screening", "elsewhere", "(", "such", "as", "the", "TIFF", "Bell", "Lightbox", "and", "other", "local", "cinemas", ")", "if", "they", "are", "distributed", "by", "a", "Netflix", "service", "."], "sentence-detokenized": "Starting with the 2019 Toronto International Film Festival, films can now be banned from the Scotiabank Theatre in Toronto - one of the festival's main venues - and from screening elsewhere (such as the TIFF Bell Lightbox and other local cinemas) if they are distributed by a Netflix service.", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 22], [23, 30], [31, 44], [45, 49], [50, 58], [58, 59], [60, 65], [66, 69], [70, 73], [74, 76], [77, 83], [84, 88], [89, 92], [93, 103], [104, 111], [112, 114], [115, 122], [123, 124], [125, 128], [129, 131], [132, 135], [136, 144], [144, 146], [147, 151], [152, 158], [159, 160], [161, 164], [165, 169], [170, 179], [180, 189], [190, 191], [191, 195], [196, 198], [199, 202], [203, 207], [208, 212], [213, 221], [222, 225], [226, 231], [232, 237], [238, 245], [245, 246], [247, 249], [250, 254], [255, 258], [259, 270], [271, 273], [274, 275], [276, 283], [284, 291], [291, 292]]}
{"doc_key": "ai-train-90", "ner": [[3, 3, "organisation"], [5, 7, "researcher"], [9, 11, "organisation"], [14, 15, "researcher"], [25, 28, "product"], [37, 38, "researcher"], [40, 42, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 9, 11, "related-to", "purchases", false, false], [5, 7, 14, 15, "named", "same", false, false], [5, 7, 37, 38, "named", "same", false, false], [9, 11, 5, 7, "origin", "founded_by", false, false], [25, 28, 3, 3, "artifact", "", false, false], [40, 42, 37, 38, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "1977", ",", "Unimation", "acquired", "Victor", "Sheinman", "'s", "company", "Vicarm", "Inc.", "and", ",", "with", "Sheinman", "'s", "help", ",", "the", "company", "developed", "and", "began", "manufacturing", "the", "Programmable", "Universal", "Assembly", "Machine", ",", "a", "new", "model", "of", "robotic", "arm", "using", "Sheinman", "'s", "advanced", "VAL", "programming", "language", "."], "sentence-detokenized": "In 1977, Unimation acquired Victor Sheinman's company Vicarm Inc. and, with Sheinman's help, the company developed and began manufacturing the Programmable Universal Assembly Machine, a new model of robotic arm using Sheinman's advanced VAL programming language.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 27], [28, 34], [35, 43], [43, 45], [46, 53], [54, 60], [61, 65], [66, 69], [69, 70], [71, 75], [76, 84], [84, 86], [87, 91], [91, 92], [93, 96], [97, 104], [105, 114], [115, 118], [119, 124], [125, 138], [139, 142], [143, 155], [156, 165], [166, 174], [175, 182], [182, 183], [184, 185], [186, 189], [190, 195], [196, 198], [199, 206], [207, 210], [211, 216], [217, 225], [225, 227], [228, 236], [237, 240], [241, 252], [253, 261], [261, 262]]}
{"doc_key": "ai-train-91", "ner": [[0, 1, "product"], [6, 6, "programlang"], [9, 11, "algorithm"], [12, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 6, "general-affiliation", "", false, false], [0, 1, 9, 11, "origin", "implementation_of", false, false], [0, 1, 12, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["J", "48", "is", "an", "open", "source", "Java", "implementation", "of", "the", "C4.5", "algorithm", "in", "the", "Weka", "data", "mining", "tool", "."], "sentence-detokenized": "J48 is an open source Java implementation of the C4.5 algorithm in the Weka data mining tool.", "token2charspan": [[0, 1], [1, 3], [4, 6], [7, 9], [10, 14], [15, 21], [22, 26], [27, 41], [42, 44], [45, 48], [49, 53], [54, 63], [64, 66], [67, 70], [71, 75], [76, 80], [81, 87], [88, 92], [92, 93]]}
{"doc_key": "ai-train-92", "ner": [[7, 7, "metrics"], [2, 5, "product"], [22, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 2, 5, "win-defeat", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["According", "to", "Google", "Scholar", ",", "the", "2004", "SSIM", "document", "has", "been", "cited", "more", "than", "20", "000", "times", ".", "It", "also", "received", "the", "IEEE", "Signal", "Processing", "Society", "'s", "Sustained", "Impact", "Award", "for", "2016", ",", "indicating", "an", "unusually", "high", "impact", "at", "least", "10", "years", "after", "its", "publication", "."], "sentence-detokenized": "According to Google Scholar, the 2004 SSIM document has been cited more than 20 000 times. It also received the IEEE Signal Processing Society's Sustained Impact Award for 2016, indicating an unusually high impact at least 10 years after its publication.", "token2charspan": [[0, 9], [10, 12], [13, 19], [20, 27], [27, 28], [29, 32], [33, 37], [38, 42], [43, 51], [52, 55], [56, 60], [61, 66], [67, 71], [72, 76], [77, 79], [80, 83], [84, 89], [89, 90], [91, 93], [94, 98], [99, 107], [108, 111], [112, 116], [117, 123], [124, 134], [135, 142], [142, 144], [145, 154], [155, 161], [162, 167], [168, 171], [172, 176], [176, 177], [178, 188], [189, 191], [192, 201], [202, 206], [207, 213], [214, 216], [217, 222], [223, 225], [226, 231], [232, 237], [238, 241], [242, 253], [253, 254]]}
{"doc_key": "ai-train-93", "ner": [[0, 1, "task"], [23, 24, "product"], [33, 35, "product"], [38, 38, "organisation"], [39, 39, "product"], [44, 44, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 38, 38, "artifact", "", false, false], [23, 24, 0, 1, "related-to", "performs", false, false], [23, 24, 33, 35, "part-of", "", false, false], [38, 38, 44, 44, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Speech", "synthesis", "is", "approaching", "complete", "indistinguishability", "from", "the", "real", "human", "voice", ",", "with", "the", "introduction", "in", "2016", "of", "voice", "editing", "and", "generation", "software", "Adobe", "Voco", ",", "a", "prototype", "to", "be", "part", "of", "the", "Adobe", "Creative", "Suite", ",", "and", "DeepMind", "WaveNet", ",", "a", "prototype", "from", "Google", "."], "sentence-detokenized": "Speech synthesis is approaching complete indistinguishability from the real human voice, with the introduction in 2016 of voice editing and generation software Adobe Voco, a prototype to be part of the Adobe Creative Suite, and DeepMind WaveNet, a prototype from Google.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 31], [32, 40], [41, 61], [62, 66], [67, 70], [71, 75], [76, 81], [82, 87], [87, 88], [89, 93], [94, 97], [98, 110], [111, 113], [114, 118], [119, 121], [122, 127], [128, 135], [136, 139], [140, 150], [151, 159], [160, 165], [166, 170], [170, 171], [172, 173], [174, 183], [184, 186], [187, 189], [190, 194], [195, 197], [198, 201], [202, 207], [208, 216], [217, 222], [222, 223], [224, 227], [228, 236], [237, 244], [244, 245], [246, 247], [248, 257], [258, 262], [263, 269], [269, 270]]}
{"doc_key": "ai-train-94", "ner": [[0, 0, "researcher"], [6, 9, "organisation"], [15, 20, "organisation"], [26, 26, "conference"], [33, 38, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 9, "role", "", false, false], [0, 0, 15, 20, "role", "", false, false], [0, 0, 26, 26, "role", "", false, false], [0, 0, 33, 38, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Poggio", "is", "an", "Honorary", "Fellow", "of", "the", "Neuroscience", "Research", "Program", ",", "a", "Fellow", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "a", "founding", "member", "of", "AAAI", ",", "and", "a", "founding", "member", "of", "the", "McGovern", "Institute", "for", "Brain", "Research", "."], "sentence-detokenized": "Poggio is an Honorary Fellow of the Neuroscience Research Program, a Fellow of the American Academy of Arts and Sciences, a founding member of AAAI, and a founding member of the McGovern Institute for Brain Research.", "token2charspan": [[0, 6], [7, 9], [10, 12], [13, 21], [22, 28], [29, 31], [32, 35], [36, 48], [49, 57], [58, 65], [65, 66], [67, 68], [69, 75], [76, 78], [79, 82], [83, 91], [92, 99], [100, 102], [103, 107], [108, 111], [112, 120], [120, 121], [122, 123], [124, 132], [133, 139], [140, 142], [143, 147], [147, 148], [149, 152], [153, 154], [155, 163], [164, 170], [171, 173], [174, 177], [178, 186], [187, 196], [197, 200], [201, 206], [207, 215], [215, 216]]}
{"doc_key": "ai-train-95", "ner": [[6, 7, "task"], [9, 9, "task"], [16, 18, "task"], [21, 21, "misc"], [22, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 7, 16, 18, "cause-effect", "", false, false], [9, 9, 16, 18, "cause-effect", "", false, false], [22, 23, 16, 18, "topic", "", false, false], [22, 23, 21, 21, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "1990s", ",", "advances", "in", "speech", "recognition", "and", "synthesis", "led", "to", "research", "in", "the", "field", "of", "speech", "translation", "with", "the", "German", "Verbmobil", "project", "."], "sentence-detokenized": "In the 1990s, advances in speech recognition and synthesis led to research in the field of speech translation with the German Verbmobil project.", "token2charspan": [[0, 2], [3, 6], [7, 12], [12, 13], [14, 22], [23, 25], [26, 32], [33, 44], [45, 48], [49, 58], [59, 62], [63, 65], [66, 74], [75, 77], [78, 81], [82, 87], [88, 90], [91, 97], [98, 109], [110, 114], [115, 118], [119, 125], [126, 135], [136, 143], [143, 144]]}
{"doc_key": "ai-train-96", "ner": [[3, 4, "researcher"], [8, 9, "researcher"], [11, 12, "researcher"], [15, 17, "algorithm"], [23, 32, "algorithm"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 8, 9, "role", "", false, false], [15, 17, 3, 4, "origin", "", false, false], [15, 17, 8, 9, "origin", "", false, false], [15, 17, 11, 12, "origin", "", false, false], [15, 17, 31, 32, "part-of", "", false, false], [23, 32, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "1999", ",", "Felix", "Gerss", "and", "his", "advisors", "J\u00fcrgen", "Schmidhuber", "and", "Fred", "Cummins", "introduced", "the", "Gate", "of", "Forgetting", "(", "also", "known", "as", "the", "Gate", "of", "Preservation", ")", "into", "the", "architecture", "of", "the", "LSTM", ","], "sentence-detokenized": "In 1999, Felix Gerss and his advisors J\u00fcrgen Schmidhuber and Fred Cummins introduced the Gate of Forgetting (also known as the Gate of Preservation) into the architecture of the LSTM,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 20], [21, 24], [25, 28], [29, 37], [38, 44], [45, 56], [57, 60], [61, 65], [66, 73], [74, 84], [85, 88], [89, 93], [94, 96], [97, 107], [108, 109], [109, 113], [114, 119], [120, 122], [123, 126], [127, 131], [132, 134], [135, 147], [147, 148], [149, 153], [154, 157], [158, 170], [171, 173], [174, 177], [178, 182], [182, 183]]}
{"doc_key": "ai-train-97", "ner": [[0, 3, "field"], [5, 8, "field"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 11, 0, 3, "part-of", "", false, false], [9, 11, 5, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "digital", "signal", "processing", "and", "information", "theory", ",", "the", "normalised", "sinc", "function", "is", "usually", "defined", "as", "follows", "."], "sentence-detokenized": "In digital signal processing and information theory, the normalised sinc function is usually defined as follows.", "token2charspan": [[0, 2], [3, 10], [11, 17], [18, 28], [29, 32], [33, 44], [45, 51], [51, 52], [53, 56], [57, 67], [68, 72], [73, 81], [82, 84], [85, 92], [93, 100], [101, 103], [104, 111], [111, 112]]}
{"doc_key": "ai-train-98", "ner": [[3, 4, "field"], [10, 14, "researcher"], [19, 23, "conference"], [25, 29, "organisation"], [31, 31, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 10, 14, "origin", "coined_term", false, false], [10, 14, 19, 23, "role", "", false, false], [10, 14, 25, 29, "role", "", false, false], [31, 31, 25, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "\"", "computational", "linguistics", "\"", "was", "first", "used", "by", "David", "Hays", ",", "a", "founding", "member", "of", "both", "the", "Association", "for", "Computational", "Linguistics", "and", "the", "International", "Committee", "for", "Computational", "Linguistics", "(", "ICCL", ")", "."], "sentence-detokenized": "The term \"computational linguistics\" was first used by David Hays, a founding member of both the Association for Computational Linguistics and the International Committee for Computational Linguistics (ICCL).", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 23], [24, 35], [35, 36], [37, 40], [41, 46], [47, 51], [52, 54], [55, 60], [61, 65], [65, 66], [67, 68], [69, 77], [78, 84], [85, 87], [88, 92], [93, 96], [97, 108], [109, 112], [113, 126], [127, 138], [139, 142], [143, 146], [147, 160], [161, 170], [171, 174], [175, 188], [189, 200], [201, 202], [202, 206], [206, 207], [207, 208]]}
{"doc_key": "ai-train-99", "ner": [[8, 13, "misc"], [18, 20, "misc"], [34, 37, "metrics"], [39, 42, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[39, 42, 34, 37, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["59", ",", "pp.", "2547-2553", ",", "October", "2011", "In", "one", "-", "dimensional", "memory", "-", "based", "(", "or", "memoryless", ")", "DPDs", ",", "in", "order", "to", "solve", "the", "coefficients", "of", "the", "digital", "predistorter", "polynomials", "and", "minimize", "the", "mean", "-", "squared", "error", "(", "MSE", ")", ",", "the", "distorted", "output", "of", "the", "nonlinear", "system", "must", "be", "read", "at", "a", "rate", "that", "allows", "the", "nonlinear", "products", "of", "order", "of", "the", "digital", "predistorter", "to", "be", "captured", "."], "sentence-detokenized": "59, pp. 2547-2553, October 2011 In one-dimensional memory-based (or memoryless) DPDs, in order to solve the coefficients of the digital predistorter polynomials and minimize the mean-squared error (MSE), the distorted output of the nonlinear system must be read at a rate that allows the nonlinear products of order of the digital predistorter to be captured.", "token2charspan": [[0, 2], [2, 3], [4, 7], [8, 17], [17, 18], [19, 26], [27, 31], [32, 34], [35, 38], [38, 39], [39, 50], [51, 57], [57, 58], [58, 63], [64, 65], [65, 67], [68, 78], [78, 79], [80, 84], [84, 85], [86, 88], [89, 94], [95, 97], [98, 103], [104, 107], [108, 120], [121, 123], [124, 127], [128, 135], [136, 148], [149, 160], [161, 164], [165, 173], [174, 177], [178, 182], [182, 183], [183, 190], [191, 196], [197, 198], [198, 201], [201, 202], [202, 203], [204, 207], [208, 217], [218, 224], [225, 227], [228, 231], [232, 241], [242, 248], [249, 253], [254, 256], [257, 261], [262, 264], [265, 266], [267, 271], [272, 276], [277, 283], [284, 287], [288, 297], [298, 306], [307, 309], [310, 315], [316, 318], [319, 322], [323, 330], [331, 343], [344, 346], [347, 349], [350, 358], [358, 359]]}
{"doc_key": "ai-train-100", "ner": [[0, 1, "researcher"], [8, 8, "location"], [10, 11, "location"], [13, 14, "country"], [17, 17, "location"], [19, 19, "country"], [32, 41, "organisation"], [42, 45, "organisation"], [46, 47, "location"], [53, 54, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 1, 8, 8, "physical", "", false, false], [0, 1, 42, 45, "physical", "", false, false], [0, 1, 53, 54, "role", "", false, false], [8, 8, 10, 11, "physical", "", false, false], [10, 11, 13, 14, "physical", "", false, false], [32, 41, 42, 45, "part-of", "", false, false], [42, 45, 46, 47, "physical", "", false, false], [53, 54, 32, 41, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Boris", "Katz", "(", "born", "5", "October", "1947", ",", "Chisinau", ",", "Moldavian", "SSR", ",", "Soviet", "Union", "(", "now", "Chisinau", ",", "Moldova", ")", ")", "is", "a", "leading", "American", "researcher", "(", "computer", "scientist", ")", "at", "the", "MIT", "Computer", "Science", "and", "Artificial", "Intelligence", "Laboratory", "at", "the", "Massachusetts", "Institute", "of", "Technology", "in", "Cambridge", ",", "and", "head", "of", "the", "InfoLab", "group", "."], "sentence-detokenized": "Boris Katz (born 5 October 1947, Chisinau, Moldavian SSR, Soviet Union (now Chisinau, Moldova)) is a leading American researcher (computer scientist) at the MIT Computer Science and Artificial Intelligence Laboratory at the Massachusetts Institute of Technology in Cambridge, and head of the InfoLab group.", "token2charspan": [[0, 5], [6, 10], [11, 12], [12, 16], [17, 18], [19, 26], [27, 31], [31, 32], [33, 41], [41, 42], [43, 52], [53, 56], [56, 57], [58, 64], [65, 70], [71, 72], [72, 75], [76, 84], [84, 85], [86, 93], [93, 94], [94, 95], [96, 98], [99, 100], [101, 108], [109, 117], [118, 128], [129, 130], [130, 138], [139, 148], [148, 149], [150, 152], [153, 156], [157, 160], [161, 169], [170, 177], [178, 181], [182, 192], [193, 205], [206, 216], [217, 219], [220, 223], [224, 237], [238, 247], [248, 250], [251, 261], [262, 264], [265, 274], [274, 275], [276, 279], [280, 284], [285, 287], [288, 291], [292, 299], [300, 305], [305, 306]]}
