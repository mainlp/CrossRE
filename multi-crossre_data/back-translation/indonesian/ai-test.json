{"doc_key": "ai-test-1", "ner": [[5, 7, "algorithm"], [9, 10, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Common", "generative", "modelling", "approaches", "include", "naive", "Bayes", "classifiers", ",", "Gaussian", "mixture", "models", ",", "variational", "autoencoders", "and", "others", "."], "sentence-detokenized": "Common generative modelling approaches include naive Bayes classifiers, Gaussian mixture models, variational autoencoders and others.", "token2charspan": [[0, 6], [7, 17], [18, 27], [28, 38], [39, 46], [47, 52], [53, 58], [59, 70], [70, 71], [72, 80], [81, 88], [89, 95], [95, 96], [97, 108], [109, 121], [122, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-test-2", "ner": [[6, 6, "organisation"], [8, 9, "conference"], [14, 19, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 8, 9, "role", "", false, false], [14, 19, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Finally", ",", "every", "two", "years", ",", "ELRA", "organises", "LREC", "'s", "major", "conference", ",", "the", "International", "Language", "Resources", "and", "Evaluation", "Conference", "."], "sentence-detokenized": "Finally, every two years, ELRA organises LREC's major conference, the International Language Resources and Evaluation Conference.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 18], [19, 24], [24, 25], [26, 30], [31, 40], [41, 45], [45, 47], [48, 53], [54, 64], [64, 65], [66, 69], [70, 83], [84, 92], [93, 102], [103, 106], [107, 117], [118, 128], [128, 129]]}
{"doc_key": "ai-test-3", "ner": [[6, 9, "algorithm"], [11, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "task", "is", "usually", "to", "obtain", "maximum", "likelihood", "estimates", "of", "the", "HMM", "parameters", "given", "the", "output", "sequence", "."], "sentence-detokenized": "The task is usually to obtain maximum likelihood estimates of the HMM parameters given the output sequence.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 22], [23, 29], [30, 37], [38, 48], [49, 58], [59, 61], [62, 65], [66, 69], [70, 80], [81, 86], [87, 90], [91, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-4", "ner": [[1, 1, "algorithm"], [4, 6, "algorithm"], [9, 9, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 9, 9, "compare", "", false, false], [4, 6, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Unlike", "neural", "networks", "and", "support", "vector", "machines", ",", "the", "AdaBoost", "training", "process", "only", "selects", "features", "that", "are", "known", "to", "improve", "the", "predictive", "power", "of", "the", "model", ",", "reducing", "dimensionality", "and", "potentially", "improving", "execution", "time", "as", "irrelevant", "features", "do", "not", "need", "to", "be", "calculated", "."], "sentence-detokenized": "Unlike neural networks and support vector machines, the AdaBoost training process only selects features that are known to improve the predictive power of the model, reducing dimensionality and potentially improving execution time as irrelevant features do not need to be calculated.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 26], [27, 34], [35, 41], [42, 50], [50, 51], [52, 55], [56, 64], [65, 73], [74, 81], [82, 86], [87, 94], [95, 103], [104, 108], [109, 112], [113, 118], [119, 121], [122, 129], [130, 133], [134, 144], [145, 150], [151, 153], [154, 157], [158, 163], [163, 164], [165, 173], [174, 188], [189, 192], [193, 204], [205, 214], [215, 224], [225, 229], [230, 232], [233, 243], [244, 252], [253, 255], [256, 259], [260, 264], [265, 267], [268, 270], [271, 281], [281, 282]]}
{"doc_key": "ai-test-5", "ner": [[0, 0, "misc"], [11, 14, "misc"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 14, "part-of", "", false, false], [11, 14, 15, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponymy", "is", "one", "of", "the", "possible", "relations", "between", "verbs", "in", "the", "semantic", "network", "of", "the", "Word", "Net", "database", "."], "sentence-detokenized": "Troponymy is one of the possible relations between verbs in the semantic network of the WordNet database.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 19], [20, 23], [24, 32], [33, 42], [43, 50], [51, 56], [57, 59], [60, 63], [64, 72], [73, 80], [81, 83], [84, 87], [88, 92], [92, 95], [96, 104], [104, 105]]}
{"doc_key": "ai-test-6", "ner": [[7, 8, "task"], [10, 11, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Frame", "language", "is", "a", "technology", "used", "for", "knowledge", "representation", "in", "artificial", "intelligence", "."], "sentence-detokenized": "Frame language is a technology used for knowledge representation in artificial intelligence.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 19], [20, 30], [31, 35], [36, 39], [40, 49], [50, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-7", "ner": [[0, 0, "metrics"], [5, 6, "metrics"], [12, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 5, 6, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "the", "Bilingual", "evaluation", "in", "the", "calculation", "of", "the", "conciseness", "penalty", "to", "the", "extent", "that", "small", "variations", "in", "translation", "length", "do", "not", "greatly", "impact", "the", "overall", "score", "."], "sentence-detokenized": "NIST also differs from the Bilingual evaluation in the calculation of the conciseness penalty to the extent that small variations in translation length do not greatly impact the overall score.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 26], [27, 36], [37, 47], [48, 50], [51, 54], [55, 66], [67, 69], [70, 73], [74, 85], [86, 93], [94, 96], [97, 100], [101, 107], [108, 112], [113, 118], [119, 129], [130, 132], [133, 144], [145, 151], [152, 154], [155, 158], [159, 166], [167, 173], [174, 177], [178, 185], [186, 191], [191, 192]]}
{"doc_key": "ai-test-8", "ner": [[4, 5, "algorithm"], [7, 9, "algorithm"], [18, 19, "field"], [28, 29, "algorithm"], [31, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 18, 19, "usage", "", false, false], [7, 9, 18, 19, "usage", "", false, false], [28, 29, 18, 19, "type-of", "", false, false], [31, 33, 18, 19, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "model", "(", "e.g.", "neural", "net", "or", "naive", "Bayes", "classifier", ")", "is", "trained", "on", "the", "training", "dataset", "using", "supervised", "learning", "methods", ",", "e.g.", "using", "optimisation", "methods", "such", "as", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The model (e.g. neural net or naive Bayes classifier) is trained on the training dataset using supervised learning methods, e.g. using optimisation methods such as gradient descent or stochastic gradient descent.", "token2charspan": [[0, 3], [4, 9], [10, 11], [11, 15], [16, 22], [23, 26], [27, 29], [30, 35], [36, 41], [42, 52], [52, 53], [54, 56], [57, 64], [65, 67], [68, 71], [72, 80], [81, 88], [89, 94], [95, 105], [106, 114], [115, 122], [122, 123], [124, 128], [129, 134], [135, 147], [148, 155], [156, 160], [161, 163], [164, 172], [173, 180], [181, 183], [184, 194], [195, 203], [204, 211], [211, 212]]}
{"doc_key": "ai-test-9", "ner": [[0, 0, "product"], [8, 9, "task"], [11, 11, "task"], [13, 15, "task"], [18, 19, "task"], [25, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 0, "usage", "", true, false], [11, 11, 0, 0, "usage", "", true, false], [13, 15, 0, 0, "usage", "", true, false], [18, 19, 0, 0, "usage", "", true, false], [25, 28, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "has", "been", "used", "in", "applications", "such", "as", "question", "answering", ",", "paraphrasing", ",", "recognising", "textual", "entailment", ",", "and", "information", "extraction", ",", "either", "directly", "or", "through", "Semantic", "Role", "Labelling", "tools", "."], "sentence-detokenized": "FrameNet has been used in applications such as question answering, paraphrasing, recognising textual entailment, and information extraction, either directly or through Semantic Role Labelling tools.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 25], [26, 38], [39, 43], [44, 46], [47, 55], [56, 65], [65, 66], [67, 79], [79, 80], [81, 92], [93, 100], [101, 111], [111, 112], [113, 116], [117, 128], [129, 139], [139, 140], [141, 147], [148, 156], [157, 159], [160, 167], [168, 176], [177, 181], [182, 191], [192, 197], [197, 198]]}
{"doc_key": "ai-test-10", "ner": [[6, 7, "field"], [12, 12, "misc"], [15, 15, "product"], [18, 20, "misc"], [21, 21, "product"], [24, 25, "field"], [28, 28, "product"], [31, 35, "misc"], [36, 36, "product"], [38, 38, "product"], [40, 40, "product"], [43, 44, "misc"], [47, 48, "product"], [50, 51, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[15, 15, 12, 12, "general-affiliation", "", false, false], [21, 21, 18, 20, "general-affiliation", "", false, false], [28, 28, 24, 25, "general-affiliation", "", false, false], [36, 36, 31, 35, "type-of", "", false, false], [38, 38, 31, 35, "type-of", "", false, false], [40, 40, 31, 35, "type-of", "", false, false], [47, 48, 43, 44, "general-affiliation", "", false, false], [50, 51, 43, 44, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["This", "would", "include", "programmes", "such", "as", "data", "analysis", "and", "extraction", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "general", "audit", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "e.g.", "Crystal", "Reports", "and", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "This would include programmes such as data analysis and extraction tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), general audit software (e.g. ACL, Arbutus, EAS), business intelligence (e.g. Crystal Reports and Business Objects), etc.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 29], [30, 34], [35, 37], [38, 42], [43, 51], [52, 55], [56, 66], [67, 72], [72, 73], [74, 86], [87, 88], [88, 92], [93, 98], [98, 99], [99, 100], [101, 110], [111, 112], [112, 116], [117, 123], [123, 124], [124, 125], [126, 137], [138, 146], [147, 148], [148, 152], [153, 156], [156, 157], [157, 158], [159, 166], [167, 172], [173, 181], [182, 183], [183, 187], [188, 191], [191, 192], [193, 200], [200, 201], [202, 205], [205, 206], [206, 207], [208, 216], [217, 229], [230, 231], [231, 235], [236, 243], [244, 251], [252, 255], [256, 264], [265, 272], [272, 273], [273, 274], [275, 278], [278, 279]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 6, "researcher"], [12, 12, "organisation"], [15, 15, "product"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "origin", "", false, false], [5, 6, 12, 12, "role", "", false, false], [15, 15, 22, 23, "type-of", "", false, false], [22, 23, 5, 6, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", "-", "founded", "by", "Rodney", "Brooks", ",", "who", "previously", "worked", "at", "iRobot", "-", "introduced", "Baxter", "in", "September", "2012", ";", "as", "an", "industrial", "robot", "designed", "to", "interact", "safely", "with", "human", "workers", "around", "it", ",", "and", "can", "be", "programmed", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "Rethink Robotics - founded by Rodney Brooks, who previously worked at iRobot - introduced Baxter in September 2012; as an industrial robot designed to interact safely with human workers around it, and can be programmed to perform simple tasks.", "token2charspan": [[0, 7], [8, 16], [17, 18], [19, 26], [27, 29], [30, 36], [37, 43], [43, 44], [45, 48], [49, 59], [60, 66], [67, 69], [70, 76], [77, 78], [79, 89], [90, 96], [97, 99], [100, 109], [110, 114], [114, 115], [116, 118], [119, 121], [122, 132], [133, 138], [139, 147], [148, 150], [151, 159], [160, 166], [167, 171], [172, 177], [178, 185], [186, 192], [193, 195], [195, 196], [197, 200], [201, 204], [205, 207], [208, 218], [219, 221], [222, 229], [230, 236], [237, 242], [242, 243]]}
{"doc_key": "ai-test-12", "ner": [[2, 2, "field"], [6, 6, "task"], [5, 9, "task"], [11, 14, "task"], [16, 18, "task"], [20, 21, "task"], [23, 24, "task"], [27, 39, "task"], [38, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 6, 2, 2, "part-of", "task_part_of_field", false, false], [5, 9, 2, 2, "part-of", "task_part_of_field", false, false], [11, 14, 2, 2, "part-of", "task_part_of_field", false, false], [16, 18, 2, 2, "part-of", "task_part_of_field", false, false], [20, 21, 2, 2, "part-of", "task_part_of_field", false, false], [23, 24, 2, 2, "part-of", "task_part_of_field", false, false], [27, 39, 2, 2, "part-of", "task_part_of_field", false, false], [38, 40, 2, 2, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Common", "text", "mining", "tasks", "include", "text", "categorisation", ",", "text", "clustering", ",", "concept", "/", "entity", "extraction", ",", "granular", "taxonomy", "production", ",", "sentiment", "analysis", ",", "document", "summarisation", ",", "and", "entity", "-", "relationship", "modelling", "(", "i.e.", ",", "learning", "the", "relationships", "between", "named", "entity", "recognition", ")", "."], "sentence-detokenized": "Common text mining tasks include text categorisation, text clustering, concept/entity extraction, granular taxonomy production, sentiment analysis, document summarisation, and entity-relationship modelling (i.e., learning the relationships between named entity recognition).", "token2charspan": [[0, 6], [7, 11], [12, 18], [19, 24], [25, 32], [33, 37], [38, 52], [52, 53], [54, 58], [59, 69], [69, 70], [71, 78], [78, 79], [79, 85], [86, 96], [96, 97], [98, 106], [107, 115], [116, 126], [126, 127], [128, 137], [138, 146], [146, 147], [148, 156], [157, 170], [170, 171], [172, 175], [176, 182], [182, 183], [183, 195], [196, 205], [206, 207], [207, 211], [211, 212], [213, 221], [222, 225], [226, 239], [240, 247], [248, 253], [254, 260], [261, 272], [272, 273], [273, 274]]}
{"doc_key": "ai-test-13", "ner": [[5, 5, "metrics"], [8, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "stemming", "reduces", "the", "precision", ",", "or", "correct", "negative", "rate", ",", "for", "such", "systems", "."], "sentence-detokenized": "However, stemming reduces the precision, or correct negative rate, for such systems.", "token2charspan": [[0, 7], [7, 8], [9, 17], [18, 25], [26, 29], [30, 39], [39, 40], [41, 43], [44, 51], [52, 60], [61, 65], [65, 66], [67, 70], [71, 75], [76, 83], [83, 84]]}
{"doc_key": "ai-test-14", "ner": [[4, 5, "task"], [7, 8, "misc"], [12, 13, "misc"], [23, 23, "product"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 4, 5, "temporal", "", false, false], [12, 13, 7, 8, "named", "", false, false], [23, 23, 7, 8, "usage", "", false, false], [25, 25, 7, 8, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "special", "case", "of", "keyword", "spotting", "is", "wake", "word", "(", "also", "called", "hot", "word", ")", "detection", "used", "by", "personal", "digital", "assistants", "such", "as", "Alexa", "or", "Siri", "to", "wake", "up", "when", "their", "name", "is", "spoken", "."], "sentence-detokenized": "A special case of keyword spotting is wake word (also called hot word) detection used by personal digital assistants such as Alexa or Siri to wake up when their name is spoken.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 17], [18, 25], [26, 34], [35, 37], [38, 42], [43, 47], [48, 49], [49, 53], [54, 60], [61, 64], [65, 69], [69, 70], [71, 80], [81, 85], [86, 88], [89, 97], [98, 105], [106, 116], [117, 121], [122, 124], [125, 130], [131, 133], [134, 138], [139, 141], [142, 146], [147, 149], [150, 154], [155, 160], [161, 165], [166, 168], [169, 175], [175, 176]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [9, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "with", "Java", "."], "sentence-detokenized": "Prova is an open source programming language that combines Prolog with Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 16], [17, 23], [24, 35], [36, 44], [45, 49], [50, 58], [59, 65], [66, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-test-16", "ner": [[3, 4, "organisation"], [9, 9, "organisation"], [16, 17, "product"], [26, 29, "country"], [33, 33, "organisation"], [43, 44, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 9, 9, "part-of", "", false, false], [3, 4, 9, 9, "role", "sells", false, false], [3, 4, 26, 29, "role", "sells_to", false, false], [33, 33, 43, 44, "opposite", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "1987", ",", "Tocibai", "Machine", ",", "a", "subsidiary", "of", "Toshiba", ",", "was", "accused", "of", "illegally", "selling", "CNC", "mills", "used", "to", "manufacture", "ultra-silent", "submarine", "propellers", "to", "the", "Soviet", "Union", ",", "in", "violation", "of", "the", "CoCom", "agreement", ",", "an", "international", "embargo", "against", "certain", "countries", "to", "COMECON", "countries", "."], "sentence-detokenized": "In 1987, Tocibai Machine, a subsidiary of Toshiba, was accused of illegally selling CNC mills used to manufacture ultra-silent submarine propellers to the Soviet Union, in violation of the CoCom agreement, an international embargo against certain countries to COMECON countries.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 24], [24, 25], [26, 27], [28, 38], [39, 41], [42, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 75], [76, 83], [84, 87], [88, 93], [94, 98], [99, 101], [102, 113], [114, 126], [127, 136], [137, 147], [148, 150], [151, 154], [155, 161], [162, 167], [167, 168], [169, 171], [172, 181], [182, 184], [185, 188], [189, 194], [195, 204], [204, 205], [206, 208], [209, 222], [223, 230], [231, 238], [239, 246], [247, 256], [257, 259], [260, 267], [268, 277], [277, 278]]}
{"doc_key": "ai-test-17", "ner": [[0, 1, "researcher"], [7, 10, "product"], [21, 24, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 0, 1, "artifact", "", false, false], [7, 10, 21, 24, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Engelberger", "'s", "most", "famous", "co-invention", ",", "the", "Unimate", "industrial", "robot", "arm", ",", "was", "among", "the", "first", "to", "be", "inducted", "into", "the", "Robot", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberger's most famous co-invention, the Unimate industrial robot arm, was among the first to be inducted into the Robot Hall of Fame in 2003.", "token2charspan": [[0, 11], [11, 13], [14, 18], [19, 25], [26, 38], [38, 39], [40, 43], [44, 51], [52, 62], [63, 68], [69, 72], [72, 73], [74, 77], [78, 83], [84, 87], [88, 93], [94, 96], [97, 99], [100, 108], [109, 113], [114, 117], [118, 123], [124, 128], [129, 131], [132, 136], [137, 139], [140, 144], [144, 145]]}
{"doc_key": "ai-test-18", "ner": [[3, 4, "misc"], [8, 8, "misc"], [10, 10, "person"], [18, 19, "field"], [15, 17, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 8, 8, "usage", "", false, false], [10, 10, 18, 19, "role", "", false, false], [18, 19, 15, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Initially", "controlled", "through", "static", "html", "web", "pages", "using", "CGI", ",", "Dalton", "'s", "work", "introduced", "a", "Java", "-", "based", "augmented", "reality", "interface", "that", "met", "with", "limited", "success", "."], "sentence-detokenized": "Initially controlled through static html web pages using CGI, Dalton's work introduced a Java-based augmented reality interface that met with limited success.", "token2charspan": [[0, 9], [10, 20], [21, 28], [29, 35], [36, 40], [41, 44], [45, 50], [51, 56], [57, 60], [60, 61], [62, 68], [68, 70], [71, 75], [76, 86], [87, 88], [89, 93], [93, 94], [94, 99], [100, 109], [110, 117], [118, 127], [128, 132], [133, 136], [137, 141], [142, 149], [150, 157], [157, 158]]}
{"doc_key": "ai-test-19", "ner": [[5, 6, "task"], [12, 12, "organisation"], [27, 27, "conference"], [31, 31, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 12, 12, "origin", "", false, false], [27, 27, 31, 31, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "publication", "on", "the", "LMF", "specification", "since", "it", "was", "ratified", "by", "ISO", "(", "this", "paper", "became", "(", "in", "2015", ")", "the", "9th", "most", "cited", "paper", "in", "LREC", "conferences", "out", "of", "LREC", "papers", ")", ":"], "sentence-detokenized": "The first publication on the LMF specification since it was ratified by ISO (this paper became (in 2015) the 9th most cited paper in LREC conferences out of LREC papers):", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 24], [25, 28], [29, 32], [33, 46], [47, 52], [53, 55], [56, 59], [60, 68], [69, 71], [72, 75], [76, 77], [77, 81], [82, 87], [88, 94], [95, 96], [96, 98], [99, 103], [103, 104], [105, 108], [109, 112], [113, 117], [118, 123], [124, 129], [130, 132], [133, 137], [138, 149], [150, 153], [154, 156], [157, 161], [162, 168], [168, 169], [169, 170]]}
{"doc_key": "ai-test-20", "ner": [[0, 1, "metrics"], [14, 15, "metrics"], [16, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 0, 1, "usage", "", false, false], [14, 15, 16, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Confusion", "matrix", "or", "matching", "matrix", "is", "often", "used", "as", "a", "tool", "to", "validate", "the", "accuracy", "of", "k", "-", "NN", "classification", "."], "sentence-detokenized": "Confusion matrix or matching matrix is often used as a tool to validate the accuracy of k-NN classification.", "token2charspan": [[0, 9], [10, 16], [17, 19], [20, 28], [29, 35], [36, 38], [39, 44], [45, 49], [50, 52], [53, 54], [55, 59], [60, 62], [63, 71], [72, 75], [76, 84], [85, 87], [88, 89], [89, 90], [90, 92], [93, 107], [107, 108]]}
{"doc_key": "ai-test-21", "ner": [[0, 1, "algorithm"], [12, 12, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 15, "part-of", "", false, false], [0, 1, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", "is", "one", "of", "the", "predictive", "modelling", "approaches", "used", "in", "statistics", ",", "data", "mining", "and", "machine", "learning", "."], "sentence-detokenized": "Decision tree learning is one of the predictive modelling approaches used in statistics, data mining and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 47], [48, 57], [58, 68], [69, 73], [74, 76], [77, 87], [87, 88], [89, 93], [94, 100], [101, 104], [105, 112], [113, 121], [121, 122]]}
{"doc_key": "ai-test-22", "ner": [[5, 5, "misc"], [17, 18, "field"], [22, 24, "algorithm"], [26, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 17, 18, "related-to", "", true, false], [22, 24, 17, 18, "type-of", "", false, false], [26, 26, 17, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["At", "runtime", ",", "the", "target", "prosody", "of", "a", "sentence", "is", "superimposed", "on", "these", "minimal", "units", "by", "using", "signal", "processing", "techniques", "such", "as", "linear", "predictive", "coding", ",", "PSOLA"], "sentence-detokenized": "At runtime, the target prosody of a sentence is superimposed on these minimal units by using signal processing techniques such as linear predictive coding, PSOLA", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 22], [23, 30], [31, 33], [34, 35], [36, 44], [45, 47], [48, 60], [61, 63], [64, 69], [70, 77], [78, 83], [84, 86], [87, 92], [93, 99], [100, 110], [111, 121], [122, 126], [127, 129], [130, 136], [137, 147], [148, 154], [154, 155], [156, 161]]}
{"doc_key": "ai-test-23", "ner": [[3, 4, "field"], [6, 7, "field"], [16, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 17, 3, 4, "usage", "", true, false], [16, 17, 6, 7, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "approach", "utilises", "artificial", "intelligence", "and", "machine", "learning", "to", "enable", "researchers", "to", "compare", "conventional", "and", "thermal", "facial", "images", "in", "real", "time", "."], "sentence-detokenized": "This approach utilises artificial intelligence and machine learning to enable researchers to compare conventional and thermal facial images in real time.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 33], [34, 46], [47, 50], [51, 58], [59, 67], [68, 70], [71, 77], [78, 89], [90, 92], [93, 100], [101, 113], [114, 117], [118, 125], [126, 132], [133, 139], [140, 142], [143, 147], [148, 152], [152, 153]]}
{"doc_key": "ai-test-24", "ner": [[1, 2, "field"], [4, 5, "algorithm"], [12, 13, "task"], [16, 17, "misc"], [23, 24, "field"], [26, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 1, 2, "part-of", "", false, false], [4, 5, 12, 13, "topic", "", false, false], [12, 13, 16, 17, "origin", "", false, false], [23, 24, 1, 2, "part-of", "", false, false], [23, 24, 4, 5, "topic", "", false, false], [26, 28, 1, 2, "part-of", "", false, false], [26, 28, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "computer", "science", ",", "evolutionary", "computing", "is", "a", "family", "of", "algorithms", "for", "global", "optimisation", "inspired", "by", "biological", "evolution", ",", "and", "the", "subfields", "of", "artificial", "intelligence", "and", "soft", "computing", "that", "study", "these", "algorithms", "."], "sentence-detokenized": "In computer science, evolutionary computing is a family of algorithms for global optimisation inspired by biological evolution, and the subfields of artificial intelligence and soft computing that study these algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 33], [34, 43], [44, 46], [47, 48], [49, 55], [56, 58], [59, 69], [70, 73], [74, 80], [81, 93], [94, 102], [103, 105], [106, 116], [117, 126], [126, 127], [128, 131], [132, 135], [136, 145], [146, 148], [149, 159], [160, 172], [173, 176], [177, 181], [182, 191], [192, 196], [197, 202], [203, 208], [209, 219], [219, 220]]}
{"doc_key": "ai-test-25", "ner": [[11, 12, "metrics"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "one", "can", "combine", "several", "measures", "based", "on", "the", "confusion", "matrix", "with", "the", "evaluated", "mean", "square", "error", "between", "the", "raw", "model", "output", "and", "the", "actual", "value", "."], "sentence-detokenized": "For example, one can combine several measures based on the confusion matrix with the evaluated mean square error between the raw model output and the actual value.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 20], [21, 28], [29, 36], [37, 45], [46, 51], [52, 54], [55, 58], [59, 68], [69, 75], [76, 80], [81, 84], [85, 94], [95, 99], [100, 106], [107, 112], [113, 120], [121, 124], [125, 128], [129, 134], [135, 141], [142, 145], [146, 149], [150, 156], [157, 162], [162, 163]]}
{"doc_key": "ai-test-26", "ner": [[7, 8, "product"], [11, 11, "researcher"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 11, 11, "origin", "", false, false], [7, 8, 18, 18, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "majority", "are", "the", "result", "of", "the", "word2vec", "model", "developed", "by", "Mikolov", "et", "al", "or", "a", "variant", "of", "word2vec", "."], "sentence-detokenized": "The majority are the result of the word2vec model developed by Mikolov et al or a variant of word2vec.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 20], [21, 27], [28, 30], [31, 34], [35, 43], [44, 49], [50, 59], [60, 62], [63, 70], [71, 73], [74, 76], [77, 79], [80, 81], [82, 89], [90, 92], [93, 101], [101, 102]]}
{"doc_key": "ai-test-27", "ner": [[12, 12, "conference"], [15, 19, "conference"], [21, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 21, 15, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["During", "this", "time", ",", "a", "total", "of", "43", "publications", "were", "recognised", "by", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "During this time, a total of 43 publications were recognised by CVPR and the International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 6], [7, 11], [12, 16], [16, 17], [18, 19], [20, 25], [26, 28], [29, 31], [32, 44], [45, 49], [50, 60], [61, 63], [64, 68], [69, 72], [73, 76], [77, 90], [91, 101], [102, 104], [105, 113], [114, 120], [121, 122], [122, 126], [126, 127], [127, 128]]}
{"doc_key": "ai-test-28", "ner": [[0, 0, "product"], [10, 11, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 11, "general-affiliation", "platform_for_education_about", false, false], [22, 23, 0, 0, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["AIBO", "has", "been", "widely", "used", "as", "an", "inexpensive", "platform", "for", "artificial", "intelligence", "education", "and", "research", ",", "as", "it", "integrates", "a", "computer", ",", "Computer", "vision", ",", "and", "articulators", "in", "a", "much", "cheaper", "package", "than", "conventional", "research", "robots", "."], "sentence-detokenized": "AIBO has been widely used as an inexpensive platform for artificial intelligence education and research, as it integrates a computer, Computer vision, and articulators in a much cheaper package than conventional research robots.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 20], [21, 25], [26, 28], [29, 31], [32, 43], [44, 52], [53, 56], [57, 67], [68, 80], [81, 90], [91, 94], [95, 103], [103, 104], [105, 107], [108, 110], [111, 121], [122, 123], [124, 132], [132, 133], [134, 142], [143, 149], [149, 150], [151, 154], [155, 167], [168, 170], [171, 172], [173, 177], [178, 185], [186, 193], [194, 198], [199, 211], [212, 220], [221, 227], [227, 228]]}
{"doc_key": "ai-test-29", "ner": [[8, 13, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "serves", "as", "the", "Programme", "Chair", "of", "the", "International", "Conference", "on", "Computer", "Vision", "2021", "."], "sentence-detokenized": "He serves as the Programme Chair of the International Conference on Computer Vision 2021.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 16], [17, 26], [27, 32], [33, 35], [36, 39], [40, 53], [54, 64], [65, 67], [68, 76], [77, 83], [84, 88], [88, 89]]}
{"doc_key": "ai-test-30", "ner": [[0, 0, "researcher"], [7, 7, "organisation"], [17, 17, "organisation"], [25, 26, "organisation"], [33, 37, "product"], [39, 39, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 7, 7, "role", "", false, false], [0, 0, 17, 17, "role", "", true, false], [17, 17, 25, 26, "role", "develops_with", false, false], [33, 37, 17, 17, "artifact", "", false, false], [39, 39, 33, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Scheinman", ",", "after", "receiving", "a", "scholarship", "from", "Unimation", "to", "develop", "his", "design", ",", "sold", "the", "design", "to", "Unimation", "who", "further", "developed", "it", "with", "support", "from", "General", "Motors", "and", "later", "marketed", "it", "as", "the", "Programmable", "Universal", "Machine", "for", "Assembly", "(", "PUMA", ")", "."], "sentence-detokenized": "Scheinman, after receiving a scholarship from Unimation to develop his design, sold the design to Unimation who further developed it with support from General Motors and later marketed it as the Programmable Universal Machine for Assembly (PUMA).", "token2charspan": [[0, 9], [9, 10], [11, 16], [17, 26], [27, 28], [29, 40], [41, 45], [46, 55], [56, 58], [59, 66], [67, 70], [71, 77], [77, 78], [79, 83], [84, 87], [88, 94], [95, 97], [98, 107], [108, 111], [112, 119], [120, 129], [130, 132], [133, 137], [138, 145], [146, 150], [151, 158], [159, 165], [166, 169], [170, 175], [176, 184], [185, 187], [188, 190], [191, 194], [195, 207], [208, 217], [218, 225], [226, 229], [230, 238], [239, 240], [240, 244], [244, 245], [245, 246]]}
{"doc_key": "ai-test-31", "ner": [[6, 7, "task"], [9, 11, "task"], [15, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 6, 7, "general-affiliation", "works_with", false, false], [15, 15, 9, 11, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "overview", "of", "calibration", "methods", "for", "binary", "classification", "and", "multiclass", "classification", "tasks", "is", "given", "by", "Gebel", "(", "2009", ")", "."], "sentence-detokenized": "An overview of calibration methods for binary classification and multiclass classification tasks is given by Gebel (2009).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 34], [35, 38], [39, 45], [46, 60], [61, 64], [65, 75], [76, 90], [91, 96], [97, 99], [100, 105], [106, 108], [109, 114], [115, 116], [116, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-test-32", "ner": [[7, 9, "task"], [11, 11, "task"], [14, 15, "task"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "involved", "in", "fields", "such", "as", "optical", "character", "recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "speech", "recognition", "technology", ",", "and", "electronic", "keyboard", "instruments", "."], "sentence-detokenized": "He is involved in fields such as optical character recognition (OCR), speech synthesis, speech recognition technology, and electronic keyboard instruments.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 24], [25, 29], [30, 32], [33, 40], [41, 50], [51, 62], [63, 64], [64, 67], [67, 68], [68, 69], [70, 76], [77, 86], [86, 87], [88, 94], [95, 106], [107, 117], [117, 118], [119, 122], [123, 133], [134, 142], [143, 154], [154, 155]]}
{"doc_key": "ai-test-33", "ner": [[8, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "newer", "and", "more", "advanced", "techniques", ",", "the", "Kaldi", "toolkit", "can", "be", "used", "."], "sentence-detokenized": "For newer and more advanced techniques, the Kaldi toolkit can be used.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 18], [19, 27], [28, 38], [38, 39], [40, 43], [44, 49], [50, 57], [58, 61], [62, 64], [65, 69], [69, 70]]}
{"doc_key": "ai-test-34", "ner": [[0, 2, "researcher"], [8, 10, "organisation"], [15, 16, "organisation"], [21, 22, "organisation"], [24, 25, "researcher"], [29, 32, "organisation"], [38, 40, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 8, 10, "role", "", false, false], [0, 2, 15, 16, "role", "", false, false], [0, 2, 21, 22, "role", "", false, false], [0, 2, 29, 32, "role", "", false, false], [0, 2, 38, 40, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson", "-", "Laird", "is", "a", "Fellow", "of", "the", "American", "Philosophical", "Society", ",", "Fellow", "of", "the", "Royal", "Society", ",", "Fellow", "of", "the", "British", "Academy", ",", "William", "James", "Fellow", "of", "the", "Association", "for", "Psychological", "Science", ",", "and", "Fellow", "of", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Johnson-Laird is a Fellow of the American Philosophical Society, Fellow of the Royal Society, Fellow of the British Academy, William James Fellow of the Association for Psychological Science, and Fellow of the Cognitive Science Society.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 71], [72, 74], [75, 78], [79, 84], [85, 92], [92, 93], [94, 100], [101, 103], [104, 107], [108, 115], [116, 123], [123, 124], [125, 132], [133, 138], [139, 145], [146, 148], [149, 152], [153, 164], [165, 168], [169, 182], [183, 190], [190, 191], [192, 195], [196, 202], [203, 205], [206, 209], [210, 219], [220, 227], [228, 235], [235, 236]]}
{"doc_key": "ai-test-35", "ner": [[2, 7, "conference"], [11, 12, "researcher"], [14, 15, "researcher"], [18, 19, "researcher"], [22, 23, "algorithm"], [27, 31, "task"], [33, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 12, 2, 7, "physical", "", false, false], [11, 12, 2, 7, "temporal", "", false, false], [14, 15, 2, 7, "physical", "", false, false], [14, 15, 2, 7, "temporal", "", false, false], [18, 19, 2, 7, "physical", "", false, false], [18, 19, 2, 7, "temporal", "", false, false], [22, 23, 18, 19, "role", "extends", false, false], [27, 31, 18, 19, "role", "extends", false, false], [33, 33, 27, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["At", "the", "IEEE", "International", "Conference", "on", "Image", "Processing", "in", "2010", ",", "Rui", "Hu", ",", "Mark", "Banard", ",", "and", "John", "Collomosse", "extended", "the", "HOG", "descriptor", "for", "use", "in", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the IEEE International Conference on Image Processing in 2010, Rui Hu, Mark Banard, and John Collomosse extended the HOG descriptor for use in sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 25], [26, 36], [37, 39], [40, 45], [46, 56], [57, 59], [60, 64], [64, 65], [66, 69], [70, 72], [72, 73], [74, 78], [79, 85], [85, 86], [87, 90], [91, 95], [96, 106], [107, 115], [116, 119], [120, 123], [124, 134], [135, 138], [139, 142], [143, 145], [146, 152], [152, 153], [153, 158], [159, 164], [165, 174], [175, 176], [176, 180], [180, 181], [181, 182]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "uses", "a", "modified", "form", "of", "precision", "to", "compare", "candidate", "translations", "with", "multiple", "reference", "translations", "."], "sentence-detokenized": "BLEU uses a modified form of precision to compare candidate translations with multiple reference translations.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 20], [21, 25], [26, 28], [29, 38], [39, 41], [42, 49], [50, 59], [60, 72], [73, 77], [78, 86], [87, 96], [97, 109], [109, 110]]}
{"doc_key": "ai-test-37", "ner": [[31, 32, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "case", "of", "the", "generalised", "basis", "space", "math", "(", "Y", ",\\", "mathcal", "{", "B", "},\\", "nu", ")", "/", "math", "(", "i.e.", "uncountable", "basis", "space", ")", ",", "one", "usually", "considers", "the", "relative", "entropy", "."], "sentence-detokenized": "For the case of the generalised basis space math(Y,\\ mathcal {B},\\ nu)/ math (i.e. uncountable basis space), one usually considers the relative entropy.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 15], [16, 19], [20, 31], [32, 37], [38, 43], [44, 48], [48, 49], [49, 50], [50, 52], [53, 60], [61, 62], [62, 63], [63, 66], [67, 69], [69, 70], [70, 71], [72, 76], [77, 78], [78, 82], [83, 94], [95, 100], [101, 106], [106, 107], [107, 108], [109, 112], [113, 120], [121, 130], [131, 134], [135, 143], [144, 151], [151, 152]]}
{"doc_key": "ai-test-38", "ner": [[8, 8, "country"], [9, 11, "organisation"], [13, 13, "organisation"], [21, 21, "country"], [16, 17, "organisation"], [19, 19, "organisation"], [23, 25, "organisation"], [28, 29, "country"], [30, 35, "organisation"], [37, 37, "organisation"], [44, 45, "misc"], [46, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[9, 11, 8, 8, "physical", "", false, false], [13, 13, 9, 11, "named", "", false, false], [16, 17, 21, 21, "physical", "", false, false], [19, 19, 16, 17, "named", "", false, false], [30, 35, 28, 29, "physical", "", false, false], [37, 37, 30, 35, "named", "", false, false], [44, 45, 46, 46, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["By", "October", "2011", ",", "existing", "partnerships", "with", "the", "US", "National", "Park", "Service", "(", "NPS", ")", ",", "Historic", "Scotland", "(", "HS", ")", "UK", ",", "World", "Monuments", "Fund", ",", "and", "Mexico", "'s", "Instituto", "Nacional", "de", "Antropolog\u00eda", "y", "Historia", "(", "INAH", ")", "had", "been", "significantly", "expanded", ",", "CyArk", "'s", "website"], "sentence-detokenized": "By October 2011, existing partnerships with the US National Park Service (NPS), Historic Scotland (HS) UK, World Monuments Fund, and Mexico's Instituto Nacional de Antropolog\u00eda y Historia (INAH) had been significantly expanded, CyArk's website", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [17, 25], [26, 38], [39, 43], [44, 47], [48, 50], [51, 59], [60, 64], [65, 72], [73, 74], [74, 77], [77, 78], [78, 79], [80, 88], [89, 97], [98, 99], [99, 101], [101, 102], [103, 105], [105, 106], [107, 112], [113, 122], [123, 127], [127, 128], [129, 132], [133, 139], [139, 141], [142, 151], [152, 160], [161, 163], [164, 176], [177, 178], [179, 187], [188, 189], [189, 193], [193, 194], [195, 198], [199, 203], [204, 217], [218, 226], [226, 227], [228, 233], [233, 235], [236, 243]]}
{"doc_key": "ai-test-39", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [11, 11, "product"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 11, 11, "part-of", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [11, 11, 6, 7, "general-affiliation", "", false, false], [13, 13, 6, 7, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SVM", "kernels", "are", "available", "in", "many", "machine", "learning", "toolkits", ",", "including", "LIBSVM", ",", "MATLAB", ",", "and", "others", "."], "sentence-detokenized": "SVM kernels are available in many machine learning toolkits, including LIBSVM, MATLAB, and others.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 25], [26, 28], [29, 33], [34, 41], [42, 50], [51, 59], [59, 60], [61, 70], [71, 77], [77, 78], [79, 85], [85, 86], [87, 90], [91, 97], [97, 98]]}
{"doc_key": "ai-test-40", "ner": [[2, 4, "misc"], [13, 14, "location"], [16, 16, "location"], [17, 18, "country"], [22, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 13, 14, "physical", "", false, false], [2, 4, 22, 24, "temporal", "", false, false], [13, 14, 16, 16, "physical", "", false, false], [16, 16, 17, 18, "physical", "", false, false], [22, 24, 13, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2009", "Loebner", "Prize", "competition", "was", "held", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", ",", "Brighton", "UK", "in", "conjunction", "with", "the", "Interspeech", "2009", "conference", "."], "sentence-detokenized": "The 2009 Loebner Prize competition was held on 6 September 2009 at the Brighton Centre, Brighton UK in conjunction with the Interspeech 2009 conference.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 34], [35, 38], [39, 43], [44, 46], [47, 48], [49, 58], [59, 63], [64, 66], [67, 70], [71, 79], [80, 86], [86, 87], [88, 96], [97, 99], [100, 102], [103, 114], [115, 119], [120, 123], [124, 135], [136, 140], [141, 151], [151, 152]]}
{"doc_key": "ai-test-41", "ner": [[2, 4, "product"], [10, 10, "product"], [17, 19, "product"], [20, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[20, 22, 2, 4, "part-of", "", false, false], [20, 22, 10, 10, "part-of", "", false, false], [20, 22, 17, 19, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "humanoid", "QRIO", "robot", "is", "designed", "as", "the", "successor", "to", "AIBO", ",", "and", "runs", "the", "same", "basic", "R", "-", "CODE", "Aperios", "operating", "system", "."], "sentence-detokenized": "The humanoid QRIO robot is designed as the successor to AIBO, and runs the same basic R-CODE Aperios operating system.", "token2charspan": [[0, 3], [4, 12], [13, 17], [18, 23], [24, 26], [27, 35], [36, 38], [39, 42], [43, 52], [53, 55], [56, 60], [60, 61], [62, 65], [66, 70], [71, 74], [75, 79], [80, 85], [86, 87], [87, 88], [88, 92], [93, 100], [101, 110], [111, 117], [117, 118]]}
{"doc_key": "ai-test-42", "ner": [[0, 3, "misc"], [7, 7, "algorithm"], [12, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 0, 3, "cause-effect", "", true, false], [12, 14, 0, 3, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "speech", "waveforms", "are", "generated", "from", "the", "HMMs", "themselves", "based", "on", "the", "maximum", "likelihood", "criterion", "."], "sentence-detokenized": "The speech waveforms are generated from the HMMs themselves based on the maximum likelihood criterion.", "token2charspan": [[0, 3], [4, 10], [11, 20], [21, 24], [25, 34], [35, 39], [40, 43], [44, 48], [49, 59], [60, 65], [66, 68], [69, 72], [73, 80], [81, 91], [92, 101], [101, 102]]}
{"doc_key": "ai-test-43", "ner": [[0, 1, "product"], [5, 7, "task"], [10, 12, "task"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 5, 7, "type-of", "", false, false], [0, 1, 10, 12, "type-of", "", false, false], [0, 1, 16, 16, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "is", "a", "free", "multilingual", "statistical", "machine", "translation", "and", "neural", "machine", "translation", "service", "developed", "by", "Google", ",", "for", "translating", "texts", "and", "websites", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Google Translate is a free multilingual statistical machine translation and neural machine translation service developed by Google, for translating texts and websites from one language to another.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 39], [40, 51], [52, 59], [60, 71], [72, 75], [76, 82], [83, 90], [91, 102], [103, 110], [111, 120], [121, 123], [124, 130], [130, 131], [132, 135], [136, 147], [148, 153], [154, 157], [158, 166], [167, 171], [172, 175], [176, 184], [185, 187], [188, 195], [195, 196]]}
{"doc_key": "ai-test-44", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [14, 16, "field"], [21, 23, "task"], [25, 26, "task"], [28, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[21, 23, 5, 6, "part-of", "", false, true], [21, 23, 8, 9, "part-of", "", false, true], [21, 23, 11, 12, "part-of", "", false, true], [25, 26, 5, 6, "part-of", "", false, true], [25, 26, 8, 9, "part-of", "", false, true], [25, 26, 11, 12, "part-of", "", false, true], [28, 31, 5, 6, "part-of", "", false, true], [28, 31, 8, 9, "part-of", "", false, true], [28, 31, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Frameworks", "are", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", "and", "digital", "image", "processing", "for", "purposes", "such", "as", "optical", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", "or", "compression", "."], "sentence-detokenized": "Frameworks are widely used in computer vision, image analysis, pattern recognition and digital image processing for purposes such as optical character recognition, fingerprint recognition, visual inspection or compression.", "token2charspan": [[0, 10], [11, 14], [15, 21], [22, 26], [27, 29], [30, 38], [39, 45], [45, 46], [47, 52], [53, 61], [61, 62], [63, 70], [71, 82], [83, 86], [87, 94], [95, 100], [101, 111], [112, 115], [116, 124], [125, 129], [130, 132], [133, 140], [141, 150], [151, 162], [162, 163], [164, 175], [176, 187], [187, 188], [189, 195], [196, 206], [207, 209], [210, 221], [221, 222]]}
{"doc_key": "ai-test-45", "ner": [[0, 6, "conference"], [11, 14, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 6, 11, 14, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "is", "a", "benchmark", "in", "object", "classification", "and", "detection", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object classification and detection, with millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 58], [59, 68], [69, 71], [72, 78], [79, 93], [94, 97], [98, 107], [107, 108], [109, 113], [114, 122], [123, 125], [126, 132], [133, 136], [137, 145], [146, 148], [149, 155], [156, 163], [163, 164]]}
{"doc_key": "ai-test-46", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [17, 19, "misc"], [22, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 17, 19, "part-of", "", false, false], [0, 0, 22, 25, "part-of", "", false, false], [4, 5, 17, 19, "part-of", "", false, false], [4, 5, 22, 25, "part-of", "", false, false], [7, 8, 17, 19, "part-of", "", false, false], [7, 8, 22, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "is", "referred", "to", "by", "some", "as", "the", "Godfather", "of", "AI", "and", "the", "Godfather", "of", "Deep", "Learning", "."], "sentence-detokenized": "Bengio, along with Geoffrey Hinton and Yann LeCun, is referred to by some as the Godfather of AI and the Godfather of Deep Learning.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 27], [28, 34], [35, 38], [39, 43], [44, 49], [49, 50], [51, 53], [54, 62], [63, 65], [66, 68], [69, 73], [74, 76], [77, 80], [81, 90], [91, 93], [94, 96], [97, 100], [101, 104], [105, 114], [115, 117], [118, 122], [123, 131], [131, 132]]}
{"doc_key": "ai-test-47", "ner": [[6, 6, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "Life", "Fellow", "of", "IEEE", "."], "sentence-detokenized": "He is a Life Fellow of IEEE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 19], [20, 22], [23, 27], [27, 28]]}
{"doc_key": "ai-test-48", "ner": [[0, 1, "organisation"], [13, 18, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 18, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NSA", "Bethesda", "is", "responsible", "for", "base", "operational", "support", "for", "its", "primary", "tenant", ",", "Walter", "Reed", "National", "Military", "Medical", "Centre", "."], "sentence-detokenized": "NSA Bethesda is responsible for base operational support for its primary tenant, Walter Reed National Military Medical Centre.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 31], [32, 36], [37, 48], [49, 56], [57, 60], [61, 64], [65, 72], [73, 79], [79, 80], [81, 87], [88, 92], [93, 101], [102, 110], [111, 118], [119, 125], [125, 126]]}
{"doc_key": "ai-test-49", "ner": [[6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "three", "main", "learning", "paradigms", "are", "supervised", "learning", ",", "unsupervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "The three main learning paradigms are supervised learning, unsupervised learning and reinforcement learning.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 23], [24, 33], [34, 37], [38, 48], [49, 57], [57, 58], [59, 71], [72, 80], [81, 84], [85, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-50", "ner": [[2, 2, "task"], [4, 8, "task"], [11, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Examples", "include", "control", ",", "planning", "and", "scheduling", ",", "the", "ability", "to", "answer", "diagnostic", "and", "consumer", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", "and", "facial", "recognition", "."], "sentence-detokenized": "Examples include control, planning and scheduling, the ability to answer diagnostic and consumer questions, handwriting recognition, natural language understanding, speech recognition and facial recognition.", "token2charspan": [[0, 8], [9, 16], [17, 24], [24, 25], [26, 34], [35, 38], [39, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 72], [73, 83], [84, 87], [88, 96], [97, 106], [106, 107], [108, 119], [120, 131], [131, 132], [133, 140], [141, 149], [150, 163], [163, 164], [165, 171], [172, 183], [184, 187], [188, 194], [195, 206], [206, 207]]}
{"doc_key": "ai-test-51", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", ",", "he", "was", "elected", "a", "fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "founding", "fellow", ")", "."], "sentence-detokenized": "In 1991, he was elected a fellow of the Association for the Advancement of Artificial Intelligence (1990, founding fellow).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [99, 100], [100, 104], [104, 105], [106, 114], [115, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-test-52", "ner": [[11, 12, "misc"], [15, 16, "algorithm"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "by", "formulating", "the", "problem", "as", "a", "solution", "of", "the", "Toeplitz", "matrix", "and", "using", "Levinson", "recursion", ",", "we", "can", "relatively", "quickly", "estimate", "the", "filter", "with", "the", "smallest", "possible", "mean", "square", "error", "."], "sentence-detokenized": "However, by formulating the problem as a solution of the Toeplitz matrix and using Levinson recursion, we can relatively quickly estimate the filter with the smallest possible mean square error.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 23], [24, 27], [28, 35], [36, 38], [39, 40], [41, 49], [50, 52], [53, 56], [57, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 101], [101, 102], [103, 105], [106, 109], [110, 120], [121, 128], [129, 137], [138, 141], [142, 148], [149, 153], [154, 157], [158, 166], [167, 175], [176, 180], [181, 187], [188, 193], [193, 194]]}
{"doc_key": "ai-test-53", "ner": [[5, 10, "conference"], [16, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 10, 16, 20, "physical", "", false, false], [16, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2011", ",", "the", "15th", "edition", "of", "Campus", "Party", "Spain", "will", "be", "held", "at", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "In July 2011, the 15th edition of Campus Party Spain will be held at the City of Arts and Sciences in Valencia.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 22], [23, 30], [31, 33], [34, 40], [41, 46], [47, 52], [53, 57], [58, 60], [61, 65], [66, 68], [69, 72], [73, 77], [78, 80], [81, 85], [86, 89], [90, 98], [99, 101], [102, 110], [110, 111]]}
{"doc_key": "ai-test-54", "ner": [[14, 14, "product"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Often", "this", "is", "generally", "only", "possible", "at", "the", "end", "of", "complex", "games", "such", "as", "chess", "or", "go", ",", "as", "it", "is", "computationally", "impossible", "to", "look", "ahead", "as", "far", "as", "the", "completion", "of", "the", "game", ",", "except", "towards", "the", "end", ",", "and", "instead", ",", "positions", "are", "given", "a", "finite", "value", "as", "an", "estimate", "of", "the", "degree", "of", "confidence", "that", "they", "will", "lead", "to", "a", "win", "for", "one", "player", "or", "another", "."], "sentence-detokenized": "Often this is generally only possible at the end of complex games such as chess or go, as it is computationally impossible to look ahead as far as the completion of the game, except towards the end, and instead, positions are given a finite value as an estimate of the degree of confidence that they will lead to a win for one player or another.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 23], [24, 28], [29, 37], [38, 40], [41, 44], [45, 48], [49, 51], [52, 59], [60, 65], [66, 70], [71, 73], [74, 79], [80, 82], [83, 85], [85, 86], [87, 89], [90, 92], [93, 95], [96, 111], [112, 122], [123, 125], [126, 130], [131, 136], [137, 139], [140, 143], [144, 146], [147, 150], [151, 161], [162, 164], [165, 168], [169, 173], [173, 174], [175, 181], [182, 189], [190, 193], [194, 197], [197, 198], [199, 202], [203, 210], [210, 211], [212, 221], [222, 225], [226, 231], [232, 233], [234, 240], [241, 246], [247, 249], [250, 252], [253, 261], [262, 264], [265, 268], [269, 275], [276, 278], [279, 289], [290, 294], [295, 299], [300, 304], [305, 309], [310, 312], [313, 314], [315, 318], [319, 322], [323, 326], [327, 333], [334, 336], [337, 344], [344, 345]]}
{"doc_key": "ai-test-55", "ner": [[3, 5, "algorithm"], [22, 23, "algorithm"], [25, 26, "algorithm"], [29, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 22, 23, "compare", "", false, false], [3, 5, 25, 26, "compare", "", false, false], [3, 5, 29, 31, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Differences", "between", "the", "multinomial", "logit", "model", "and", "various", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "with", "the", "same", "basic", "setup", "(", "perceptron", "algorithm", ",", "support", "vector", "machine", ",", "linear", "discriminant", "analysis", ",", "etc.", ")", "."], "sentence-detokenized": "Differences between the multinomial logit model and various other methods, models, algorithms, etc. with the same basic setup (perceptron algorithm, support vector machine, linear discriminant analysis, etc.).", "token2charspan": [[0, 11], [12, 19], [20, 23], [24, 35], [36, 41], [42, 47], [48, 51], [52, 59], [60, 65], [66, 73], [73, 74], [75, 81], [81, 82], [83, 93], [93, 94], [95, 99], [100, 104], [105, 108], [109, 113], [114, 119], [120, 125], [126, 127], [127, 137], [138, 147], [147, 148], [149, 156], [157, 163], [164, 171], [171, 172], [173, 179], [180, 192], [193, 201], [201, 202], [203, 207], [207, 208], [208, 209]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "published", "by"], "sentence-detokenized": "Association for Computational Linguistics, published by", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 52], [53, 55]]}
{"doc_key": "ai-test-57", "ner": [[3, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "a", "computerised", "face", "recognition", "system", ",", "each", "face", "is", "represented", "by", "a", "large", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In a computerised face recognition system, each face is represented by a large number of pixel values.", "token2charspan": [[0, 2], [3, 4], [5, 17], [18, 22], [23, 34], [35, 41], [41, 42], [43, 47], [48, 52], [53, 55], [56, 67], [68, 70], [71, 72], [73, 78], [79, 85], [86, 88], [89, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-58", "ner": [[6, 7, "person"], [14, 17, "organisation"], [22, 22, "country"], [26, 26, "person"], [36, 38, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 7, 14, 17, "role", "", false, false], [6, 7, 22, 22, "physical", "", false, false], [26, 26, 36, 38, "origin", "", false, false], [26, 26, 36, 38, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2002", ",", "his", "son", ",", "Daniel", "Pearl", ",", "a", "journalist", "working", "for", "the", "Wall", "Street", "Journal", "was", "kidnapped", "and", "murdered", "in", "Pakistan", ",", "which", "led", "Judea", "and", "other", "family", "members", "and", "friends", "to", "establish", "the", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "In 2002, his son, Daniel Pearl, a journalist working for the Wall Street Journal was kidnapped and murdered in Pakistan, which led Judea and other family members and friends to establish the Daniel Pearl Foundation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [16, 17], [18, 24], [25, 30], [30, 31], [32, 33], [34, 44], [45, 52], [53, 56], [57, 60], [61, 65], [66, 72], [73, 80], [81, 84], [85, 94], [95, 98], [99, 107], [108, 110], [111, 119], [119, 120], [121, 126], [127, 130], [131, 136], [137, 140], [141, 146], [147, 153], [154, 161], [162, 165], [166, 173], [174, 176], [177, 186], [187, 190], [191, 197], [198, 203], [204, 214], [214, 215]]}
{"doc_key": "ai-test-59", "ner": [[4, 6, "organisation"], [17, 18, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 17, 18, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "late", "2006", ",", "Red", "Envelope", "Entertainment", "also", "expanded", "into", "producing", "original", "content", "with", "filmmakers", "such", "as", "John", "Waters", "."], "sentence-detokenized": "In late 2006, Red Envelope Entertainment also expanded into producing original content with filmmakers such as John Waters.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 26], [27, 40], [41, 45], [46, 54], [55, 59], [60, 69], [70, 78], [79, 86], [87, 91], [92, 102], [103, 107], [108, 110], [111, 115], [116, 122], [122, 123]]}
{"doc_key": "ai-test-60", "ner": [[7, 11, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "building", "is", "now", "part", "of", "the", "Beth", "Israel", "Deaconess", "Medical", "Centre", "."], "sentence-detokenized": "This building is now part of the Beth Israel Deaconess Medical Centre.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 25], [26, 28], [29, 32], [33, 37], [38, 44], [45, 54], [55, 62], [63, 69], [69, 70]]}
{"doc_key": "ai-test-61", "ner": [[16, 17, "field"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "common", "theme", "of", "this", "work", "is", "the", "adoption", "of", "sign", "theory", "perspectives", "on", "issues", "of", "artificial", "intelligence", "and", "knowledge", "representation", "."], "sentence-detokenized": "The common theme of this work is the adoption of sign theory perspectives on issues of artificial intelligence and knowledge representation.", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 19], [20, 24], [25, 29], [30, 32], [33, 36], [37, 45], [46, 48], [49, 53], [54, 60], [61, 73], [74, 76], [77, 83], [84, 86], [87, 97], [98, 110], [111, 114], [115, 124], [125, 139], [139, 140]]}
{"doc_key": "ai-test-62", "ner": [[5, 7, "task"], [9, 9, "task"], [21, 22, "task"], [41, 42, "task"], [44, 45, "task"], [48, 50, "task"], [52, 52, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 7, 21, 22, "type-of", "", false, false], [5, 7, 48, 50, "compare", "", false, false], [5, 7, 48, 50, "opposite", "", false, false], [9, 9, 5, 7, "named", "", false, false], [41, 42, 48, 50, "part-of", "", false, false], [44, 45, 48, 50, "part-of", "", false, false], [48, 50, 21, 22, "type-of", "", false, false], [52, 52, 48, 50, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["For", "example", ",", "the", "term", "neural", "machine", "translation", "(", "NMT", ")", "emphasises", "the", "fact", "that", "deep", "learning", "-", "based", "approaches", "to", "machine", "translation", "directly", "learn", "sequence", "-", "to", "-", "sequence", "transformations", ",", "thus", "obviating", "the", "need", "for", "intermediate", "steps", "such", "as", "word", "alignment", "and", "language", "modelling", "used", "in", "statistical", "machine", "translation", "(", "SMT", ")", "."], "sentence-detokenized": "For example, the term neural machine translation (NMT) emphasises the fact that deep learning-based approaches to machine translation directly learn sequence-to-sequence transformations, thus obviating the need for intermediate steps such as word alignment and language modelling used in statistical machine translation (SMT).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 36], [37, 48], [49, 50], [50, 53], [53, 54], [55, 65], [66, 69], [70, 74], [75, 79], [80, 84], [85, 93], [93, 94], [94, 99], [100, 110], [111, 113], [114, 121], [122, 133], [134, 142], [143, 148], [149, 157], [157, 158], [158, 160], [160, 161], [161, 169], [170, 185], [185, 186], [187, 191], [192, 201], [202, 205], [206, 210], [211, 214], [215, 227], [228, 233], [234, 238], [239, 241], [242, 246], [247, 256], [257, 260], [261, 269], [270, 279], [280, 284], [285, 287], [288, 299], [300, 307], [308, 319], [320, 321], [321, 324], [324, 325], [325, 326]]}
{"doc_key": "ai-test-63", "ner": [[8, 9, "field"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 12, 13, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "of", "the", "research", "in", "the", "field", "of", "WSD", "is", "done", "using", "Word", "Net", "as", "a", "reference", "sense", "inventory", "."], "sentence-detokenized": "Most of the research in the field of WSD is done using WordNet as a reference sense inventory.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 20], [21, 23], [24, 27], [28, 33], [34, 36], [37, 40], [41, 43], [44, 48], [49, 54], [55, 59], [59, 62], [63, 65], [66, 67], [68, 77], [78, 83], [84, 93], [93, 94]]}
{"doc_key": "ai-test-64", "ner": [[2, 2, "misc"], [11, 12, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 2, 2, "general-affiliation", "", false, true], [15, 16, 2, 2, "general-affiliation", "", false, true]], "relations_mapping_to_source": [0, 1], "sentence": ["Notable", "former", "PhD", "students", "and", "postdoctoral", "researchers", "from", "his", "group", "include", "Richard", "Zemel", ",", "and", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Notable former PhD students and postdoctoral researchers from his group include Richard Zemel, and Zoubin Ghahramani.", "token2charspan": [[0, 7], [8, 14], [15, 18], [19, 27], [28, 31], [32, 44], [45, 56], [57, 61], [62, 65], [66, 71], [72, 79], [80, 87], [88, 93], [93, 94], [95, 98], [99, 105], [106, 116], [116, 117]]}
{"doc_key": "ai-test-65", "ner": [[7, 8, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 14, 15, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Each", "prediction", "result", "or", "instance", "of", "the", "confusion", "matrix", "represents", "one", "point", "in", "the", "ROC", "space", "."], "sentence-detokenized": "Each prediction result or instance of the confusion matrix represents one point in the ROC space.", "token2charspan": [[0, 4], [5, 15], [16, 22], [23, 25], [26, 34], [35, 37], [38, 41], [42, 51], [52, 58], [59, 69], [70, 73], [74, 79], [80, 82], [83, 86], [87, 90], [91, 96], [96, 97]]}
{"doc_key": "ai-test-66", "ner": [[2, 2, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [16, 18, "product"], [21, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 21, 23, "physical", "", false, false], [6, 7, 21, 23, "physical", "", false, false], [9, 10, 21, 23, "physical", "", false, false], [16, 18, 2, 2, "artifact", "", false, false], [16, 18, 6, 7, "artifact", "", false, false], [16, 18, 9, 10, "artifact", "", false, false], [16, 18, 21, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1997", "Thrun", "and", "his", "colleagues", "Wolfram", "Burgard", "and", "Dieter", "Fox", "developed", "the", "world", "'s", "first", "robot", "tour", "guide", "at", "the", "Deutsches", "Museum", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "In 1997 Thrun and his colleagues Wolfram Burgard and Dieter Fox developed the world's first robot tour guide at the Deutsches Museum Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 17], [18, 21], [22, 32], [33, 40], [41, 48], [49, 52], [53, 59], [60, 63], [64, 73], [74, 77], [78, 83], [83, 85], [86, 91], [92, 97], [98, 102], [103, 108], [109, 111], [112, 115], [116, 125], [126, 132], [133, 137], [138, 139], [139, 143], [143, 144], [144, 145]]}
{"doc_key": "ai-test-67", "ner": [[0, 1, "product"], [7, 7, "misc"], [24, 26, "field"], [28, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 1, "part-of", "", false, false], [24, 26, 0, 1, "usage", "", false, false], [28, 30, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "of", "semantic", "relationships", "between", "words", "in", "more", "than", "200", "languages", ".", "It", "s", "primary", "use", "is", "in", "automated", "natural", "language", "processing", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database of semantic relationships between words in more than 200 languages. Its primary use is in automated natural language processing and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 32], [33, 41], [42, 55], [56, 63], [64, 69], [70, 72], [73, 77], [78, 82], [83, 86], [87, 96], [96, 97], [98, 100], [100, 101], [102, 109], [110, 113], [114, 116], [117, 119], [120, 129], [130, 137], [138, 146], [147, 157], [158, 161], [162, 172], [173, 185], [186, 198], [198, 199]]}
{"doc_key": "ai-test-68", "ner": [[5, 7, "field"], [12, 15, "conference"], [17, 25, "conference"], [27, 27, "conference"], [30, 30, "conference"], [37, 38, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 15, 5, 7, "topic", "", false, false], [12, 15, 37, 38, "topic", "", false, false], [17, 25, 5, 7, "topic", "", false, false], [17, 25, 37, 38, "topic", "", false, false], [27, 27, 5, 7, "topic", "", false, false], [27, 27, 37, 38, "topic", "", false, false], [30, 30, 5, 7, "topic", "", false, false], [30, 30, 37, 38, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Conferences", "in", "the", "field", "of", "natural", "language", "processing", ",", "such", "as", "the", "Association", "for", "Computational", "Linguistics", ",", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", ",", "and", "HLT", ",", "began", "to", "include", "papers", "on", "speech", "processing", "."], "sentence-detokenized": "Conferences in the field of natural language processing, such as the Association for Computational Linguistics, North American Chapter of the Association for Computational Linguistics, EMNLP, and HLT, began to include papers on speech processing.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 24], [25, 27], [28, 35], [36, 44], [45, 55], [55, 56], [57, 61], [62, 64], [65, 68], [69, 80], [81, 84], [85, 98], [99, 110], [110, 111], [112, 117], [118, 126], [127, 134], [135, 137], [138, 141], [142, 153], [154, 157], [158, 171], [172, 183], [183, 184], [185, 190], [190, 191], [192, 195], [196, 199], [199, 200], [201, 206], [207, 209], [210, 217], [218, 224], [225, 227], [228, 234], [235, 245], [245, 246]]}
{"doc_key": "ai-test-69", "ner": [[3, 3, "programlang"], [19, 22, "misc"], [33, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "set", "of", "Java", "programmes", "use", "lexicons", "to", "work", "through", "variations", "in", "biomedical", "text", "by", "associating", "words", "based", "on", "their", "parts", "of", "speech", ",", "which", "can", "help", "in", "web", "searches", "or", "searching", "through", "electronic", "medical", "records", "."], "sentence-detokenized": "A set of Java programmes use lexicons to work through variations in biomedical text by associating words based on their parts of speech, which can help in web searches or searching through electronic medical records.", "token2charspan": [[0, 1], [2, 5], [6, 8], [9, 13], [14, 24], [25, 28], [29, 37], [38, 40], [41, 45], [46, 53], [54, 64], [65, 67], [68, 78], [79, 83], [84, 86], [87, 98], [99, 104], [105, 110], [111, 113], [114, 119], [120, 125], [126, 128], [129, 135], [135, 136], [137, 142], [143, 146], [147, 151], [152, 154], [155, 158], [159, 167], [168, 170], [171, 180], [181, 188], [189, 199], [200, 207], [208, 215], [215, 216]]}
{"doc_key": "ai-test-70", "ner": [[7, 7, "algorithm"], [9, 9, "algorithm"], [11, 11, "algorithm"], [13, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "many", "newer", "algorithms", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", ",", ",", ",", "and", "others", "."], "sentence-detokenized": "There are many newer algorithms such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost,,, and others.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 20], [21, 31], [32, 36], [37, 39], [40, 47], [47, 48], [49, 59], [59, 60], [61, 71], [71, 72], [73, 80], [80, 81], [82, 91], [91, 92], [92, 93], [93, 94], [95, 98], [99, 105], [105, 106]]}
{"doc_key": "ai-test-71", "ner": [[7, 7, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "of", "implementation", "in", "Python", ":"], "sentence-detokenized": "This is an example of implementation in Python:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 36], [37, 39], [40, 46], [46, 47]]}
{"doc_key": "ai-test-72", "ner": [[0, 0, "organisation"], [1, 1, "product"], [6, 8, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 0, 0, "artifact", "made_by_company", false, false], [6, 8, 1, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mattel", "Intellivision", "game", "consoles", "offered", "the", "Intellivoice", "Voice", "Synthesis", "module", "in", "1982", "."], "sentence-detokenized": "Mattel Intellivision game consoles offered the Intellivoice Voice Synthesis module in 1982.", "token2charspan": [[0, 6], [7, 20], [21, 25], [26, 34], [35, 42], [43, 46], [47, 59], [60, 65], [66, 75], [76, 82], [83, 85], [86, 90], [90, 91]]}
{"doc_key": "ai-test-73", "ner": [[4, 5, "task"], [8, 14, "task"], [16, 17, "field"], [19, 21, "task"], [25, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 14, 4, 5, "part-of", "", false, false], [16, 17, 4, 5, "part-of", "", false, false], [19, 21, 4, 5, "part-of", "", false, false], [25, 29, 19, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "also", "works", "on", "machine", "translation", ",", "both", "high", "-", "accuracy", "knowledge", "-", "based", "MT", "and", "machine", "learning", "for", "statistical", "machine", "translation", "(", "such", "as", "generalised", "example", "-", "based", "MT", ")", "."], "sentence-detokenized": "He also works on machine translation, both high-accuracy knowledge-based MT and machine learning for statistical machine translation (such as generalised example-based MT).", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 16], [17, 24], [25, 36], [36, 37], [38, 42], [43, 47], [47, 48], [48, 56], [57, 66], [66, 67], [67, 72], [73, 75], [76, 79], [80, 87], [88, 96], [97, 100], [101, 112], [113, 120], [121, 132], [133, 134], [134, 138], [139, 141], [142, 153], [154, 161], [161, 162], [162, 167], [168, 170], [170, 171], [171, 172]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [7, 7, "misc"], [22, 23, "algorithm"], [25, 26, "field"], [28, 29, "field"], [31, 31, "field"], [33, 34, "field"], [36, 36, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 22, 23, "general-affiliation", "", false, false], [0, 1, 25, 26, "general-affiliation", "", false, false], [0, 1, 28, 29, "general-affiliation", "", false, false], [0, 1, 31, 31, "general-affiliation", "", false, false], [0, 1, 33, 34, "general-affiliation", "", false, false], [0, 1, 36, 36, "general-affiliation", "", false, false], [7, 7, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "commonly", "referred", "to", "as", "Mathematica", ")", "is", "a", "modern", "technical", "computing", "system", "that", "covers", "most", "technical", "fields", "-", "including", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "data", "science", ",", "visualisation", ",", "and", "others", "."], "sentence-detokenized": "Wolfram Mathematica (commonly referred to as Mathematica) is a modern technical computing system that covers most technical fields - including neural networks, machine learning, image processing, geometry, data science, visualisation, and others.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 29], [30, 38], [39, 41], [42, 44], [45, 56], [56, 57], [58, 60], [61, 62], [63, 69], [70, 79], [80, 89], [90, 96], [97, 101], [102, 108], [109, 113], [114, 123], [124, 130], [131, 132], [133, 142], [143, 149], [150, 158], [158, 159], [160, 167], [168, 176], [176, 177], [178, 183], [184, 194], [194, 195], [196, 204], [204, 205], [206, 210], [211, 218], [218, 219], [220, 233], [233, 234], [235, 238], [239, 245], [245, 246]]}
{"doc_key": "ai-test-75", "ner": [[2, 7, "product"], [10, 11, "researcher"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 2, 7, "type-of", "", false, false], [17, 17, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "digitally", "operated", ",", "programmable", "robot", "was", "invented", "by", "George", "Devol", "in", "1954", "and", "eventually", "called", "Unimate", "."], "sentence-detokenized": "The first digitally operated, programmable robot was invented by George Devol in 1954 and eventually called Unimate.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 28], [28, 29], [30, 42], [43, 48], [49, 52], [53, 61], [62, 64], [65, 71], [72, 77], [78, 80], [81, 85], [86, 89], [90, 100], [101, 107], [108, 115], [115, 116]]}
{"doc_key": "ai-test-76", "ner": [[1, 1, "algorithm"], [3, 3, "algorithm"], [17, 18, "task"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 3, 3, "compare", "", false, false], [3, 3, 17, 18, "general-affiliation", "", false, false], [3, 3, 20, 21, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Like", "DBNs", ",", "DBMs", "can", "learn", "complex", "and", "abstract", "internal", "representations", "of", "inputs", "in", "tasks", "such", "as", "object", "recognition", "or", "speech", "recognition", ",", "using", "limited", "labelled", "data", "to", "refine", "representations", "built", "using", "a", "large", "set", "of", "unlabelled", "sensory", "input", "data", "."], "sentence-detokenized": "Like DBNs, DBMs can learn complex and abstract internal representations of inputs in tasks such as object recognition or speech recognition, using limited labelled data to refine representations built using a large set of unlabelled sensory input data.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 15], [16, 19], [20, 25], [26, 33], [34, 37], [38, 46], [47, 55], [56, 71], [72, 74], [75, 81], [82, 84], [85, 90], [91, 95], [96, 98], [99, 105], [106, 117], [118, 120], [121, 127], [128, 139], [139, 140], [141, 146], [147, 154], [155, 163], [164, 168], [169, 171], [172, 178], [179, 194], [195, 200], [201, 206], [207, 208], [209, 214], [215, 218], [219, 221], [222, 232], [233, 240], [241, 246], [247, 251], [251, 252]]}
{"doc_key": "ai-test-77", "ner": [[4, 8, "task"], [13, 13, "conference"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 4, 8, "topic", "", false, false], [15, 15, 4, 8, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "scientific", "conferences", "where", "vision", "-", "based", "activity", "recognition", "works", "often", "appear", "are", "ICCV", "and", "CVPR", "."], "sentence-detokenized": "The scientific conferences where vision-based activity recognition works often appear are ICCV and CVPR.", "token2charspan": [[0, 3], [4, 14], [15, 26], [27, 32], [33, 39], [39, 40], [40, 45], [46, 54], [55, 66], [67, 72], [73, 78], [79, 85], [86, 89], [90, 94], [95, 98], [99, 103], [103, 104]]}
{"doc_key": "ai-test-78", "ner": [[1, 1, "field"], [4, 5, "algorithm"], [7, 7, "algorithm"], [16, 17, "metrics"], [19, 21, "metrics"], [23, 23, "metrics"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 5, 1, 1, "part-of", "", false, false], [4, 5, 16, 17, "related-to", "finds", false, false], [4, 5, 19, 21, "related-to", "finds", false, false], [4, 5, 38, 38, "related-to", "", false, false], [7, 7, 4, 5, "named", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "statistics", ",", "the", "expectation", "-maximisation", "(", "EM", ")", "algorithm", "is", "an", "iterative", "method", "for", "finding", "maximum", "likelihood", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "estimates", "of", "parameters", "in", "statistical", "models", ",", "where", "the", "model", "depends", "on", "unobserved", "latent", "variables", "."], "sentence-detokenized": "In statistics, the expectation-maximisation (EM) algorithm is an iterative method for finding maximum likelihood or maximum a posteriori (MAP) estimates of parameters in statistical models, where the model depends on unobserved latent variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 30], [30, 43], [44, 45], [45, 47], [47, 48], [49, 58], [59, 61], [62, 64], [65, 74], [75, 81], [82, 85], [86, 93], [94, 101], [102, 112], [113, 115], [116, 123], [124, 125], [126, 136], [137, 138], [138, 141], [141, 142], [143, 152], [153, 155], [156, 166], [167, 169], [170, 181], [182, 188], [188, 189], [190, 195], [196, 199], [200, 205], [206, 213], [214, 216], [217, 227], [228, 234], [235, 244], [244, 245]]}
{"doc_key": "ai-test-79", "ner": [[5, 7, "metrics"], [5, 9, "metrics"], [14, 16, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 9, 5, 7, "named", "", false, false], [18, 18, 14, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Similarly", ",", "investigators", "sometimes", "report", "False", "Positive", "Rate", "(", "FPR", ")", "as", "well", "as", "False", "Negative", "Rate", "(", "FNR", ")", "."], "sentence-detokenized": "Similarly, investigators sometimes report False Positive Rate (FPR) as well as False Negative Rate (FNR).", "token2charspan": [[0, 9], [9, 10], [11, 24], [25, 34], [35, 41], [42, 47], [48, 56], [57, 61], [62, 63], [63, 66], [66, 67], [68, 70], [71, 75], [76, 78], [79, 84], [85, 93], [94, 98], [99, 100], [100, 103], [103, 104], [104, 105]]}
{"doc_key": "ai-test-80", "ner": [[6, 9, "metrics"], [12, 12, "field"], [15, 16, "metrics"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 12, 6, 9, "usage", "", false, false], [19, 20, 15, 16, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "concept", "is", "similar", "to", "the", "signal", "to", "noise", "ratio", "used", "in", "science", "and", "the", "confusion", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "This concept is similar to the signal to noise ratio used in science and the confusion matrix used in artificial intelligence.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 23], [24, 26], [27, 30], [31, 37], [38, 40], [41, 46], [47, 52], [53, 57], [58, 60], [61, 68], [69, 72], [73, 76], [77, 86], [87, 93], [94, 98], [99, 101], [102, 112], [113, 125], [125, 126]]}
{"doc_key": "ai-test-81", "ner": [[0, 2, "field"], [10, 11, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [30, 33, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 10, 11, "general-affiliation", "", false, false], [0, 2, 17, 18, "general-affiliation", "", false, false], [0, 2, 20, 21, "general-affiliation", "", false, false], [30, 33, 0, 2, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Human", "Augmentation", "Code", "of", "Ethics", ",", "originally", "introduced", "by", "Steve", "Mann", "in", "2004", "and", "refined", "by", "Ray", "Kurzweil", "and", "Marvin", "Minsky", "in", "2013", ",", "was", "finally", "ratified", "at", "the", "Toronto", "Virtual", "Reality", "conference", "on", "25", "June", "2017", "."], "sentence-detokenized": "The Human Augmentation Code of Ethics, originally introduced by Steve Mann in 2004 and refined by Ray Kurzweil and Marvin Minsky in 2013, was finally ratified at the Toronto Virtual Reality conference on 25 June 2017.", "token2charspan": [[0, 3], [4, 9], [10, 22], [23, 27], [28, 30], [31, 37], [37, 38], [39, 49], [50, 60], [61, 63], [64, 69], [70, 74], [75, 77], [78, 82], [83, 86], [87, 94], [95, 97], [98, 101], [102, 110], [111, 114], [115, 121], [122, 128], [129, 131], [132, 136], [136, 137], [138, 141], [142, 149], [150, 158], [159, 161], [162, 165], [166, 173], [174, 181], [182, 189], [190, 200], [201, 203], [204, 206], [207, 211], [212, 216], [216, 217]]}
{"doc_key": "ai-test-82", "ner": [[3, 5, "person"], [11, 12, "organisation"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 11, 12, "role", "directed_for", false, false], [3, 5, 18, 19, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", ",", "Walter", "R.", "Booth", "directed", "10", "films", "for", "the", "British", "Kinoplastikon", ",", "probably", "in", "collaboration", "with", "Cecil", "Hepworth", "."], "sentence-detokenized": "In 1913, Walter R. Booth directed 10 films for the British Kinoplastikon, probably in collaboration with Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 18], [19, 24], [25, 33], [34, 36], [37, 42], [43, 46], [47, 50], [51, 58], [59, 72], [72, 73], [74, 82], [83, 85], [86, 99], [100, 104], [105, 110], [111, 119], [119, 120]]}
{"doc_key": "ai-test-83", "ner": [[12, 12, "location"], [14, 15, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 15, 12, 12, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "introduced", "their", "new", "robot", "in", "1961", "at", "a", "trade", "show", "in", "Chicago", "'s", "Cow", "Palace", "."], "sentence-detokenized": "They introduced their new robot in 1961 at a trade show in Chicago's Cow Palace.", "token2charspan": [[0, 4], [5, 15], [16, 21], [22, 25], [26, 31], [32, 34], [35, 39], [40, 42], [43, 44], [45, 50], [51, 55], [56, 58], [59, 66], [66, 68], [69, 72], [73, 79], [79, 80]]}
{"doc_key": "ai-test-84", "ner": [[2, 2, "product"], [6, 7, "task"], [10, 12, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 6, 7, "usage", "", false, false], [2, 2, 10, 12, "usage", "", false, false], [2, 2, 17, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["While", "some", "chatbot", "applications", "use", "extensive", "word", "classification", "processes", ",", "natural", "language", "processing", "processors", ",", "and", "sophisticated", "artificial", "intelligence", ",", "others", "simply", "scan", "for", "common", "keywords", "and", "generate", "responses", "using", "common", "phrases", "obtained", "from", "related", "libraries", "or", "databases", "."], "sentence-detokenized": "While some chatbot applications use extensive word classification processes, natural language processing processors, and sophisticated artificial intelligence, others simply scan for common keywords and generate responses using common phrases obtained from related libraries or databases.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 31], [32, 35], [36, 45], [46, 50], [51, 65], [66, 75], [75, 76], [77, 84], [85, 93], [94, 104], [105, 115], [115, 116], [117, 120], [121, 134], [135, 145], [146, 158], [158, 159], [160, 166], [167, 173], [174, 178], [179, 182], [183, 189], [190, 198], [199, 202], [203, 211], [212, 221], [222, 227], [228, 234], [235, 242], [243, 251], [252, 256], [257, 264], [265, 274], [275, 277], [278, 287], [287, 288]]}
{"doc_key": "ai-test-85", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "WaveNet", "model", "proposed", "in", "2016", "achieved", "good", "performance", "on", "speech", "quality", "."], "sentence-detokenized": "The WaveNet model proposed in 2016 achieved good performance on speech quality.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 43], [44, 48], [49, 60], [61, 63], [64, 70], [71, 78], [78, 79]]}
{"doc_key": "ai-test-86", "ner": [[4, 4, "product"], [6, 7, "misc"], [9, 10, "misc"], [12, 13, "misc"], [15, 17, "misc"], [19, 21, "organisation"], [23, 23, "organisation"], [25, 28, "organisation"], [30, 30, "organisation"], [32, 35, "organisation"], [37, 38, "organisation"], [40, 40, "organisation"], [42, 44, "organisation"], [47, 47, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 4, 6, 7, "general-affiliation", "", false, false], [4, 4, 9, 10, "general-affiliation", "", false, false], [4, 4, 12, 13, "general-affiliation", "", false, false], [4, 4, 15, 17, "general-affiliation", "", false, false], [19, 21, 4, 4, "usage", "", false, false], [23, 23, 4, 4, "usage", "", false, false], [25, 28, 4, 4, "usage", "", false, false], [30, 30, 4, 4, "usage", "", false, false], [32, 35, 4, 4, "usage", "", false, false], [37, 38, 4, 4, "usage", "", false, false], [40, 40, 4, 4, "usage", "", false, false], [42, 44, 4, 4, "usage", "", false, false], [47, 47, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organisations", "known", "to", "use", "ALE", "for", "Emergency", "management", ",", "disaster", "relief", ",", "ordinary", "communications", "or", "extraordinary", "situation", "response", ":", "American", "Red", "Cross", ",", "FEMA", ",", "Disaster", "Medical", "Assistance", "Teams", ",", "NATO", ",", "Federal", "Bureau", "of", "Investigation", ",", "United", "Nations", ",", "AT&T", ",", "Civil", "Air", "Patrol", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organisations known to use ALE for Emergency management, disaster relief, ordinary communications or extraordinary situation response: American Red Cross, FEMA, Disaster Medical Assistance Teams, NATO, Federal Bureau of Investigation, United Nations, AT&T, Civil Air Patrol, (ARES).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 30], [31, 34], [35, 44], [45, 55], [55, 56], [57, 65], [66, 72], [72, 73], [74, 82], [83, 97], [98, 100], [101, 114], [115, 124], [125, 133], [133, 134], [135, 143], [144, 147], [148, 153], [153, 154], [155, 159], [159, 160], [161, 169], [170, 177], [178, 188], [189, 194], [194, 195], [196, 200], [200, 201], [202, 209], [210, 216], [217, 219], [220, 233], [233, 234], [235, 241], [242, 249], [249, 250], [251, 255], [255, 256], [257, 262], [263, 266], [267, 273], [273, 274], [275, 276], [276, 280], [280, 281], [281, 282]]}
{"doc_key": "ai-test-87", "ner": [[3, 4, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", ",", "the", "Kronecker", "delta", "is", "used", "for", "simplicity", "(", "cf", ".", "the", "derivative", "of", "the", "sigmoid", "function", ",", "which", "is", "expressed", "through", "the", "function", "itself", ")", "."], "sentence-detokenized": "Here, the Kronecker delta is used for simplicity (cf. the derivative of the sigmoid function, which is expressed through the function itself).", "token2charspan": [[0, 4], [4, 5], [6, 9], [10, 19], [20, 25], [26, 28], [29, 33], [34, 37], [38, 48], [49, 50], [50, 52], [52, 53], [54, 57], [58, 68], [69, 71], [72, 75], [76, 83], [84, 92], [92, 93], [94, 99], [100, 102], [103, 112], [113, 120], [121, 124], [125, 133], [134, 140], [140, 141], [141, 142]]}
{"doc_key": "ai-test-88", "ner": [[12, 13, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "theory", "is", "based", "on", "philosophical", "foundations", ",", "and", "was", "founded", "by", "Ray", "Solomonoff", "around", "1960", ".", "Samuel", "Rathmanner", "and", "Marcus", "Hutter", "."], "sentence-detokenized": "This theory is based on philosophical foundations, and was founded by Ray Solomonoff around 1960. Samuel Rathmanner and Marcus Hutter.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 20], [21, 23], [24, 37], [38, 49], [49, 50], [51, 54], [55, 58], [59, 66], [67, 69], [70, 73], [74, 84], [85, 91], [92, 96], [96, 97], [98, 104], [105, 115], [116, 119], [120, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [10, 11, "misc"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 11, "type-of", "", false, false], [0, 0, 14, 15, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "a", "freely", "available", "database", "originally", "designed", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "was", "expanded", "with", "the", "addition", "of", "definitions", "and", "is", "now", "also", "viewed", "as", "a", "dictionary", "."], "sentence-detokenized": "WordNet, a freely available database originally designed as a semantic network based on psycholinguistic principles, was expanded with the addition of definitions and is now also viewed as a dictionary.", "token2charspan": [[0, 7], [7, 8], [9, 10], [11, 17], [18, 27], [28, 36], [37, 47], [48, 56], [57, 59], [60, 61], [62, 70], [71, 78], [79, 84], [85, 87], [88, 104], [105, 115], [115, 116], [117, 120], [121, 129], [130, 134], [135, 138], [139, 147], [148, 150], [151, 162], [163, 166], [167, 169], [170, 173], [174, 178], [179, 185], [186, 188], [189, 190], [191, 201], [201, 202]]}
{"doc_key": "ai-test-90", "ner": [[5, 6, "field"], [14, 14, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 14, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Advances", "in", "the", "field", "of", "computational", "imaging", "research", "are", "presented", "in", "several", "places", "including", "SIGGRAPH", "and", "publications", "."], "sentence-detokenized": "Advances in the field of computational imaging research are presented in several places including SIGGRAPH and publications.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 21], [22, 24], [25, 38], [39, 46], [47, 55], [56, 59], [60, 69], [70, 72], [73, 80], [81, 87], [88, 97], [98, 106], [107, 110], [111, 123], [123, 124]]}
{"doc_key": "ai-test-91", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "considered", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multiclass", "classification", "."], "sentence-detokenized": "Classification can be considered as two separate problems - binary classification and multiclass classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 96], [97, 111], [111, 112]]}
{"doc_key": "ai-test-92", "ner": [[11, 11, "algorithm"], [16, 17, "algorithm"], [20, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 17, 11, 11, "type-of", "", false, false], [20, 20, 16, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Advanced", "gene", "finders", "for", "prokaryotic", "and", "eukaryotic", "genomes", "typically", "use", "complex", "probabilistic", "models", ",", "such", "as", "hidden", "Markov", "models", "(", "HMMs", ")", "to", "combine", "information", "from", "different", "signal", "and", "content", "measurements", "."], "sentence-detokenized": "Advanced gene finders for prokaryotic and eukaryotic genomes typically use complex probabilistic models, such as hidden Markov models (HMMs) to combine information from different signal and content measurements.", "token2charspan": [[0, 8], [9, 13], [14, 21], [22, 25], [26, 37], [38, 41], [42, 52], [53, 60], [61, 70], [71, 74], [75, 82], [83, 96], [97, 103], [103, 104], [105, 109], [110, 112], [113, 119], [120, 126], [127, 133], [134, 135], [135, 139], [139, 140], [141, 143], [144, 151], [152, 163], [164, 168], [169, 178], [179, 185], [186, 189], [190, 197], [198, 210], [210, 211]]}
{"doc_key": "ai-test-93", "ner": [[0, 0, "misc"], [3, 3, "misc"], [9, 10, "field"], [13, 14, "algorithm"], [17, 18, "algorithm"], [21, 21, "algorithm"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 9, 10, "part-of", "", false, false], [0, 0, 13, 14, "usage", "", false, false], [3, 3, 0, 0, "named", "", false, false], [17, 18, 0, 0, "origin", "", true, false], [21, 21, 17, 18, "named", "", false, false], [31, 32, 0, 0, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Neuroevolution", ",", "or", "neuro-evolution", ",", "is", "a", "form", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "generate", "artificial", "neural", "networks", "(", "ANNs", ")", ",", "parameters", ",", "topologies", "and", "rules", ".", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuroevolution, or neuro-evolution, is a form of artificial intelligence that uses evolutionary algorithms to generate artificial neural networks (ANNs), parameters, topologies and rules. and evolutionary robotics.", "token2charspan": [[0, 14], [14, 15], [16, 18], [19, 34], [34, 35], [36, 38], [39, 40], [41, 45], [46, 48], [49, 59], [60, 72], [73, 77], [78, 82], [83, 95], [96, 106], [107, 109], [110, 118], [119, 129], [130, 136], [137, 145], [146, 147], [147, 151], [151, 152], [152, 153], [154, 164], [164, 165], [166, 176], [177, 180], [181, 186], [186, 187], [188, 191], [192, 204], [205, 213], [213, 214]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [6, 6, "metrics"], [8, 8, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "IBM", "proposed", "and", "realised", "the", "BLEU", "system", "Papineni", "et", "al", "."], "sentence-detokenized": "Since IBM proposed and realised the BLEU system Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 31], [32, 35], [36, 40], [41, 47], [48, 56], [57, 59], [60, 62], [62, 63]]}
{"doc_key": "ai-test-95", "ner": [[10, 16, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 18, 10, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "experts", "attended", "a", "conference", "organised", "by", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "to", "discuss", "whether", "computers", "and", "robots", "might", "be", "able", "to", "gain", "any", "autonomy", ",", "and", "how", "much", "this", "ability", "could", "pose", "a", "threat", "or", "danger", "."], "sentence-detokenized": "In 2009, experts attended a conference organised by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether computers and robots might be able to gain any autonomy, and how much this ability could pose a threat or danger.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 25], [26, 27], [28, 38], [39, 48], [49, 51], [52, 55], [56, 67], [68, 71], [72, 75], [76, 87], [88, 90], [91, 101], [102, 114], [115, 116], [116, 120], [120, 121], [122, 124], [125, 132], [133, 140], [141, 150], [151, 154], [155, 161], [162, 167], [168, 170], [171, 175], [176, 178], [179, 183], [184, 187], [188, 196], [196, 197], [198, 201], [202, 205], [206, 210], [211, 215], [216, 223], [224, 229], [230, 234], [235, 236], [237, 243], [244, 246], [247, 253], [253, 254]]}
{"doc_key": "ai-test-96", "ner": [[19, 21, "researcher"], [23, 24, "researcher"], [26, 31, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[26, 31, 19, 21, "artifact", "", false, false], [26, 31, 23, 24, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["After", "boosting", ",", "a", "classifier", "built", "from", "200", "features", "can", "yield", "a", "95", "%", "detection", "rate", "under", "^{-5", "}.", "P", ".", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "After boosting, a classifier built from 200 features can yield a 95% detection rate under ^{-5}. P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 17], [18, 28], [29, 34], [35, 39], [40, 43], [44, 52], [53, 56], [57, 62], [63, 64], [65, 67], [67, 68], [69, 78], [79, 83], [84, 89], [90, 94], [94, 96], [97, 98], [98, 99], [100, 105], [105, 106], [107, 109], [110, 115], [115, 116], [117, 123], [124, 128], [128, 129], [129, 133], [134, 140], [141, 150], [150, 151], [152, 156], [156, 157]]}
{"doc_key": "ai-test-97", "ner": [[4, 6, "programlang"], [9, 9, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "website", "was", "originally", "Perl", "-", "based", ",", "but", "IMDb", "no", "longer", "reveals", "what", "software", "it", "uses", "for", "security", "reasons", "."], "sentence-detokenized": "The website was originally Perl-based, but IMDb no longer reveals what software it uses for security reasons.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 26], [27, 31], [31, 32], [32, 37], [37, 38], [39, 42], [43, 47], [48, 50], [51, 57], [58, 65], [66, 70], [71, 79], [80, 82], [83, 87], [88, 91], [92, 100], [101, 108], [108, 109]]}
{"doc_key": "ai-test-98", "ner": [[7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "start", "-", "up", "was", "founded", "by", "Demis", "Hassabis", ",", "Shane", "Legg", "and", "Mustafa", "Suleyman", "in", "2010", "."], "sentence-detokenized": "The start-up was founded by Demis Hassabis, Shane Legg and Mustafa Suleyman in 2010.", "token2charspan": [[0, 3], [4, 9], [9, 10], [10, 12], [13, 16], [17, 24], [25, 27], [28, 33], [34, 42], [42, 43], [44, 49], [50, 54], [55, 58], [59, 66], [67, 75], [76, 78], [79, 83], [83, 84]]}
{"doc_key": "ai-test-99", "ner": [[4, 5, "misc"], [8, 10, "metrics"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 4, 5, "type-of", "", false, false], [22, 23, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "very", "commonly", "used", "loss", "functions", "are", "the", "mean", "square", "error", ",", "mathL", "(", "a", ")", "=", "a^2", "/math", ",", "and", "the", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/math", "."], "sentence-detokenized": "Two very commonly used loss functions are the mean square error, mathL(a) = a^2/math, and the absolute loss, mathL(a) = |a |/math.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 27], [28, 37], [38, 41], [42, 45], [46, 50], [51, 57], [58, 63], [63, 64], [65, 70], [70, 71], [71, 72], [72, 73], [74, 75], [76, 79], [79, 84], [84, 85], [86, 89], [90, 93], [94, 102], [103, 107], [107, 108], [109, 114], [114, 115], [115, 116], [116, 117], [118, 119], [120, 121], [121, 122], [123, 124], [124, 129], [129, 130]]}
{"doc_key": "ai-test-100", "ner": [[3, 5, "algorithm"], [12, 14, "algorithm"], [16, 16, "algorithm"], [19, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 12, 14, "type-of", "example_of", false, false], [12, 14, 19, 20, "related-to", "", false, false], [16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "soft", "-margin", "support", "vector", "machine", "described", "above", "is", "an", "example", "of", "empirical", "risk", "minimisation", "(", "ERM", ")", "for", "hinge", "losses", "."], "sentence-detokenized": "The soft-margin support vector machine described above is an example of empirical risk minimisation (ERM) for hinge losses.", "token2charspan": [[0, 3], [4, 8], [8, 15], [16, 23], [24, 30], [31, 38], [39, 48], [49, 54], [55, 57], [58, 60], [61, 68], [69, 71], [72, 81], [82, 86], [87, 99], [100, 101], [101, 104], [104, 105], [106, 109], [110, 115], [116, 122], [122, 123]]}
{"doc_key": "ai-test-101", "ner": [[0, 4, "field"], [7, 7, "task"], [9, 11, "task"], [21, 21, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 11, 0, 4, "origin", "", false, false], [9, 11, 7, 7, "type-of", "", false, false], [21, 21, 9, 11, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "deep", "learning", "-", "based", "approach", "to", "MT", ",", "neural", "machine", "translation", "has", "made", "rapid", "progress", "in", "recent", "years", ",", "and", "Google", "has", "announced", "its", "translation", "service", "now", "uses", "this", "technology", "in", "preference", "to", "previous", "statistical", "methods", "."], "sentence-detokenized": "A deep learning-based approach to MT, neural machine translation has made rapid progress in recent years, and Google has announced its translation service now uses this technology in preference to previous statistical methods.", "token2charspan": [[0, 1], [2, 6], [7, 15], [15, 16], [16, 21], [22, 30], [31, 33], [34, 36], [36, 37], [38, 44], [45, 52], [53, 64], [65, 68], [69, 73], [74, 79], [80, 88], [89, 91], [92, 98], [99, 104], [104, 105], [106, 109], [110, 116], [117, 120], [121, 130], [131, 134], [135, 146], [147, 154], [155, 158], [159, 163], [164, 168], [169, 179], [180, 182], [183, 193], [194, 196], [197, 205], [206, 217], [218, 225], [225, 226]]}
{"doc_key": "ai-test-102", "ner": [[15, 15, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "tends", "to", "result", "in", "huge", "performance", "improvements", "when", "working", "with", "large", "corpora", "such", "as", "WordNet", "."], "sentence-detokenized": "This tends to result in huge performance improvements when working with large corpora such as WordNet.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 20], [21, 23], [24, 28], [29, 40], [41, 53], [54, 58], [59, 66], [67, 71], [72, 77], [78, 85], [86, 90], [91, 93], [94, 101], [101, 102]]}
{"doc_key": "ai-test-103", "ner": [[0, 1, "task"], [5, 5, "field"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 16, 18, "part-of", "", false, false], [16, 18, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Face", "detection", "is", "used", "in", "biometrics", ",", "often", "as", "part", "of", "(", "or", "together", "with", ")", "facial", "recognition", "systems", "."], "sentence-detokenized": "Face detection is used in biometrics, often as part of (or together with) facial recognition systems.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 22], [23, 25], [26, 36], [36, 37], [38, 43], [44, 46], [47, 51], [52, 54], [55, 56], [56, 58], [59, 67], [68, 72], [72, 73], [74, 80], [81, 92], [93, 100], [100, 101]]}
{"doc_key": "ai-test-104", "ner": [[2, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["trained", "with", "maximum", "likelihood", "estimation", "."], "sentence-detokenized": "trained with maximum likelihood estimation.", "token2charspan": [[0, 7], [8, 12], [13, 20], [21, 31], [32, 42], [42, 43]]}
{"doc_key": "ai-test-105", "ner": [[3, 3, "country"], [5, 10, "organisation"], [13, 13, "location"], [15, 15, "country"], [17, 20, "organisation"], [22, 22, "country"], [28, 28, "organisation"], [33, 35, "organisation"], [37, 37, "country"], [48, 51, "organisation"], [53, 54, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 10, 13, 13, "physical", "", false, false], [13, 13, 15, 15, "physical", "", false, false], [17, 20, 22, 22, "physical", "", false, false], [33, 35, 37, 37, "physical", "", false, false], [48, 51, 53, 54, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd", ".", "in", "Thailand", ";", "Komatsu", "(", "Shanghai", ")", "Ltd.", "in", "1996", "in", "Shanghai", ",", "China", ";", "Industrial", "Power", "Alliance", "Ltd.", "in", "Japan", ",", "a", "joint", "venture", "with", "Cummins", ",", "in", "1998", ";", "L&T-", "Komatsu", "Limited", "in", "India", "in", "1998", "(", "shares", "sold", "in", "2013", ")", ";", "and", "Komatsu", "Brasil", "International", "Ltda.", "in", "Brazil", "in", "1998", "."], "sentence-detokenized": "Ltd. in Thailand; Komatsu (Shanghai) Ltd. in 1996 in Shanghai, China; Industrial Power Alliance Ltd. in Japan, a joint venture with Cummins, in 1998; L&T-Komatsu Limited in India in 1998 (shares sold in 2013); and Komatsu Brasil International Ltda. in Brazil in 1998.", "token2charspan": [[0, 3], [3, 4], [5, 7], [8, 16], [16, 17], [18, 25], [26, 27], [27, 35], [35, 36], [37, 41], [42, 44], [45, 49], [50, 52], [53, 61], [61, 62], [63, 68], [68, 69], [70, 80], [81, 86], [87, 95], [96, 100], [101, 103], [104, 109], [109, 110], [111, 112], [113, 118], [119, 126], [127, 131], [132, 139], [139, 140], [141, 143], [144, 148], [148, 149], [150, 154], [154, 161], [162, 169], [170, 172], [173, 178], [179, 181], [182, 186], [187, 188], [188, 194], [195, 199], [200, 202], [203, 207], [207, 208], [208, 209], [210, 213], [214, 221], [222, 228], [229, 242], [243, 248], [249, 251], [252, 258], [259, 261], [262, 266], [266, 267]]}
{"doc_key": "ai-test-106", "ner": [[0, 0, "organisation"], [4, 6, "misc"], [11, 11, "misc"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 14, 0, 0, "physical", "", false, false], [13, 14, 4, 6, "general-affiliation", "", false, false], [13, 14, 11, 11, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["dgp", "also", "occasionally", "hosts", "artists", "in", "residence", "(", "for", "example", ",", "Oscar", "winner", "Chris", "Landreth", "."], "sentence-detokenized": "dgp also occasionally hosts artists in residence (for example, Oscar winner Chris Landreth.", "token2charspan": [[0, 3], [4, 8], [9, 21], [22, 27], [28, 35], [36, 38], [39, 48], [49, 50], [50, 53], [54, 61], [61, 62], [63, 68], [69, 75], [76, 81], [82, 90], [90, 91]]}
{"doc_key": "ai-test-107", "ner": [[7, 9, "misc"], [11, 13, "misc"], [15, 18, "misc"], [23, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "currently", "includes", "four", "sub-competitions", "-", "the", "RoboMaster", "Robotics", "Competition", ",", "RoboMaster", "Technical", "Challenge", ",", "ICRA", "RoboMaster", "AI", "Challenge", ",", "and", "the", "new", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "It currently includes four sub-competitions - the RoboMaster Robotics Competition, RoboMaster Technical Challenge, ICRA RoboMaster AI Challenge, and the new RoboMaster Youth Tournament.", "token2charspan": [[0, 2], [3, 12], [13, 21], [22, 26], [27, 43], [44, 45], [46, 49], [50, 60], [61, 69], [70, 81], [81, 82], [83, 93], [94, 103], [104, 113], [113, 114], [115, 119], [120, 130], [131, 133], [134, 143], [143, 144], [145, 148], [149, 152], [153, 156], [157, 167], [168, 173], [174, 184], [184, 185]]}
{"doc_key": "ai-test-108", "ner": [[7, 8, "field"], [14, 16, "algorithm"], [20, 21, "algorithm"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 20, 21, "usage", "", false, false], [7, 8, 23, 24, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "the", "early", "2000s", ",", "the", "dominant", "speech", "processing", "strategy", "began", "to", "shift", "from", "Hidden", "Markov", "models", "towards", "more", "modern", "neural", "networks", "and", "deep", "learning", "."], "sentence-detokenized": "In the early 2000s, the dominant speech processing strategy began to shift from Hidden Markov models towards more modern neural networks and deep learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 18], [18, 19], [20, 23], [24, 32], [33, 39], [40, 50], [51, 59], [60, 65], [66, 68], [69, 74], [75, 79], [80, 86], [87, 93], [94, 100], [101, 108], [109, 113], [114, 120], [121, 127], [128, 136], [137, 140], [141, 145], [146, 154], [154, 155]]}
{"doc_key": "ai-test-109", "ner": [[9, 11, "misc"], [16, 18, "metrics"], [20, 22, "metrics"], [29, 30, "metrics"], [31, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 18, 20, 22, "related-to", "equal", false, false], [29, 30, 31, 35, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "equivalent", "expression", ",", "in", "the", "case", "of", "a", "binary", "target", "rate", ",", "is", "that", "the", "TRUE", "positive", "rate", "and", "FALSE", "positive", "rate", "are", "equal", "(", "and", "therefore", "the", "FALSE", "negative", "rate", "and", "TRUE", "negative", "rate", "are", "equal", ")", "for", "each", "value", "of", "the", "sensitive", "characteristic", ":"], "sentence-detokenized": "Another equivalent expression, in the case of a binary target rate, is that the TRUE positive rate and FALSE positive rate are equal (and therefore the FALSE negative rate and TRUE negative rate are equal) for each value of the sensitive characteristic:", "token2charspan": [[0, 7], [8, 18], [19, 29], [29, 30], [31, 33], [34, 37], [38, 42], [43, 45], [46, 47], [48, 54], [55, 61], [62, 66], [66, 67], [68, 70], [71, 75], [76, 79], [80, 84], [85, 93], [94, 98], [99, 102], [103, 108], [109, 117], [118, 122], [123, 126], [127, 132], [133, 134], [134, 137], [138, 147], [148, 151], [152, 157], [158, 166], [167, 171], [172, 175], [176, 180], [181, 189], [190, 194], [195, 198], [199, 204], [204, 205], [206, 209], [210, 214], [215, 220], [221, 223], [224, 227], [228, 237], [238, 252], [252, 253]]}
{"doc_key": "ai-test-110", "ner": [[0, 0, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["MATLAB", "functions", ","], "sentence-detokenized": "MATLAB functions,", "token2charspan": [[0, 6], [7, 16], [16, 17]]}
{"doc_key": "ai-test-111", "ner": [[0, 1, "product"], [5, 5, "misc"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 1, "part-of", "", false, false], [13, 14, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Articulated", "robots", "are", "robots", "with", "rotary", "joints", "(", "e.g.", ",", "legged", "robots", "or", "industrial", "robots", ")", "."], "sentence-detokenized": "Articulated robots are robots with rotary joints (e.g., legged robots or industrial robots).", "token2charspan": [[0, 11], [12, 18], [19, 22], [23, 29], [30, 34], [35, 41], [42, 48], [49, 50], [50, 54], [54, 55], [56, 62], [63, 69], [70, 72], [73, 83], [84, 90], [90, 91], [91, 92]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [6, 6, "product"], [8, 9, "product"], [13, 13, "misc"], [20, 22, "product"], [26, 28, "misc"], [32, 32, "location"], [34, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 13, 13, "general-affiliation", "nationality", false, false], [0, 0, 26, 28, "usage", "", false, false], [0, 0, 32, 32, "physical", "", false, false], [6, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [32, 32, 34, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "also", "known", "as", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "an", "American", "music", "streaming", "internet", "radio", "service", "and", "automated", "Recommendation", "system", "powered", "by", "the", "Music", "Genome", "Project", "and", "headquartered", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (also known as Pandora Media or Pandora Radio) is an American music streaming internet radio service and automated Recommendation system powered by the Music Genome Project and headquartered in Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 30], [31, 36], [37, 39], [40, 47], [48, 53], [53, 54], [55, 57], [58, 60], [61, 69], [70, 75], [76, 85], [86, 94], [95, 100], [101, 108], [109, 112], [113, 122], [123, 137], [138, 144], [145, 152], [153, 155], [156, 159], [160, 165], [166, 172], [173, 180], [181, 184], [185, 198], [199, 201], [202, 209], [209, 210], [211, 221], [221, 222]]}
{"doc_key": "ai-test-113", "ner": [[7, 10, "organisation"], [18, 20, "organisation"], [24, 25, "conference"], [40, 40, "conference"], [42, 42, "conference"], [44, 44, "conference"], [46, 46, "conference"], [48, 48, "conference"], [50, 50, "conference"], [52, 52, "conference"], [54, 54, "conference"], [56, 56, "conference"], [58, 58, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "board", "member", "of", "the", "International", "Machine", "Learning", "Society", ",", "has", "been", "a", "member", "of", "the", "AAAI", "Executive", "board", ",", "was", "the", "2011", "ICML", "PC", "co-chair", ",", "and", "has", "served", "as", "a", "senior", "PC", "member", "for", "conferences", "including", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", "and", "WWW", "."], "sentence-detokenized": "He is a board member of the International Machine Learning Society, has been a member of the AAAI Executive board, was the 2011 ICML PC co-chair, and has served as a senior PC member for conferences including AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM and WWW.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 13], [14, 20], [21, 23], [24, 27], [28, 41], [42, 49], [50, 58], [59, 66], [66, 67], [68, 71], [72, 76], [77, 78], [79, 85], [86, 88], [89, 92], [93, 97], [98, 107], [108, 113], [113, 114], [115, 118], [119, 122], [123, 127], [128, 132], [133, 135], [136, 144], [144, 145], [146, 149], [150, 153], [154, 160], [161, 163], [164, 165], [166, 172], [173, 175], [176, 182], [183, 186], [187, 198], [199, 208], [209, 213], [213, 214], [215, 219], [219, 220], [221, 226], [226, 227], [228, 232], [232, 233], [234, 237], [237, 238], [239, 245], [245, 246], [247, 250], [250, 251], [252, 256], [256, 257], [258, 262], [263, 266], [267, 270], [270, 271]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [5, 10, "organisation"], [12, 12, "organisation"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 10, "role", "", false, false], [12, 12, 5, 10, "named", "", false, false], [16, 16, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "developed", "the", "Robocrane", ",", "in", "which", "the", "platform", "hangs", "from", "six", "cables", "instead", "of", "being", "supported", "by", "six", "jacks", "."], "sentence-detokenized": "James S. Albus of the National Institute of Standards and Technology (NIST) developed the Robocrane, in which the platform hangs from six cables instead of being supported by six jacks.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [74, 75], [76, 85], [86, 89], [90, 99], [99, 100], [101, 103], [104, 109], [110, 113], [114, 122], [123, 128], [129, 133], [134, 137], [138, 144], [145, 152], [153, 155], [156, 161], [162, 171], [172, 174], [175, 178], [179, 184], [184, 185]]}
{"doc_key": "ai-test-115", "ner": [[3, 5, "algorithm"], [8, 14, "algorithm"], [13, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 14, 3, 5, "type-of", "", false, false], [13, 13, 8, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "class", "of", "direct", "search", "algorithms", "are", "various", "evolutionary", "algorithms", ",", "such", "as", "genetic", "algorithms", "."], "sentence-detokenized": "Another class of direct search algorithms are various evolutionary algorithms, such as genetic algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 23], [24, 30], [31, 41], [42, 45], [46, 53], [54, 66], [67, 77], [77, 78], [79, 83], [84, 86], [87, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-test-116", "ner": [[0, 0, "organisation"], [3, 5, "misc"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 0, 0, "named", "", false, false], [6, 7, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "industrial", "robots", "and", "solutions", "for", "factory", "automation", "."], "sentence-detokenized": "KUKA is a German manufacturer of industrial robots and solutions for factory automation.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 43], [44, 50], [51, 54], [55, 64], [65, 68], [69, 76], [77, 87], [87, 88]]}
{"doc_key": "ai-test-117", "ner": [[8, 8, "misc"], [11, 12, "person"], [14, 20, "misc"], [22, 23, "person"], [25, 25, "misc"], [27, 29, "person"], [30, 31, "misc"], [33, 34, "person"], [36, 38, "misc"], [40, 42, "person"], [43, 47, "misc"], [49, 50, "person"], [52, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[11, 12, 8, 8, "usage", "", false, false], [14, 20, 11, 12, "artifact", "", false, false], [22, 23, 8, 8, "usage", "", false, false], [25, 25, 22, 23, "artifact", "", false, false], [27, 29, 8, 8, "usage", "", false, false], [30, 31, 27, 29, "artifact", "", false, false], [33, 34, 8, 8, "usage", "", false, false], [36, 38, 33, 34, "artifact", "", false, false], [40, 42, 8, 8, "usage", "", false, false], [43, 47, 40, 42, "artifact", "", false, false], [49, 50, 8, 8, "usage", "", false, false], [52, 55, 49, 50, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Other", "films", "between", "2016", "and", "2020", "shot", "with", "IMAX", "cameras", "are", "Zack", "Snyder", "'s", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", ",", "Clint", "Eastwood", "'s", "Sully", ",", "Damien", "Chazelle", "'s", "First", "Man", ",", "Patty", "Jenkins", "'", "Wonder", "Woman", "1984", ",", "Cary", "Joji", "Fukunaga", "'s", "No", "Time", "to", "Die", "and", "Joseph", "Kosinski", "'s", "Top", "Gun", ":", "Maverick", "."], "sentence-detokenized": "Other films between 2016 and 2020 shot with IMAX cameras are Zack Snyder's Batman v Superman: Dawn of Justice, Clint Eastwood's Sully, Damien Chazelle's First Man, Patty Jenkins' Wonder Woman 1984, Cary Joji Fukunaga's No Time to Die and Joseph Kosinski's Top Gun: Maverick.", "token2charspan": [[0, 5], [6, 11], [12, 19], [20, 24], [25, 28], [29, 33], [34, 38], [39, 43], [44, 48], [49, 56], [57, 60], [61, 65], [66, 72], [72, 74], [75, 81], [82, 83], [84, 92], [92, 93], [94, 98], [99, 101], [102, 109], [109, 110], [111, 116], [117, 125], [125, 127], [128, 133], [133, 134], [135, 141], [142, 150], [150, 152], [153, 158], [159, 162], [162, 163], [164, 169], [170, 177], [177, 178], [179, 185], [186, 191], [192, 196], [196, 197], [198, 202], [203, 207], [208, 216], [216, 218], [219, 221], [222, 226], [227, 229], [230, 233], [234, 237], [238, 244], [245, 253], [253, 255], [256, 259], [260, 263], [263, 264], [265, 273], [273, 274]]}
{"doc_key": "ai-test-118", "ner": [[4, 5, "misc"], [12, 14, "organisation"], [16, 16, "organisation"], [29, 29, "misc"], [36, 37, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 29, 29, "named", "", false, false], [12, 14, 4, 5, "usage", "", false, false], [12, 14, 36, 37, "physical", "", false, false], [16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "trial", "of", "the", "E13B", "MICR", "fo", "nt", "was", "shown", "to", "the", "American", "Bankers", "Association", "(", "ABA", ")", "in", "July", "1956", ",", "which", "adopted", "it", "in", "1958", "as", "the", "MICR", "standard", "for", "negotiable", "documents", "in", "the", "United", "States", "."], "sentence-detokenized": "A trial of the E13B MICR font was shown to the American Bankers Association (ABA) in July 1956, which adopted it in 1958 as the MICR standard for negotiable documents in the United States.", "token2charspan": [[0, 1], [2, 7], [8, 10], [11, 14], [15, 19], [20, 24], [25, 27], [27, 29], [30, 33], [34, 39], [40, 42], [43, 46], [47, 55], [56, 63], [64, 75], [76, 77], [77, 80], [80, 81], [82, 84], [85, 89], [90, 94], [94, 95], [96, 101], [102, 109], [110, 112], [113, 115], [116, 120], [121, 123], [124, 127], [128, 132], [133, 141], [142, 145], [146, 156], [157, 166], [167, 169], [170, 173], [174, 180], [181, 187], [187, 188]]}
{"doc_key": "ai-test-119", "ner": [[0, 2, "misc"], [15, 16, "field"], [19, 20, "field"], [23, 23, "field"], [25, 26, "field"], [28, 28, "field"], [31, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 16, 0, 2, "usage", "", false, false], [19, 20, 15, 16, "part-of", "", false, false], [23, 23, 0, 2, "usage", "", false, false], [25, 26, 0, 2, "usage", "", false, false], [28, 28, 0, 2, "usage", "", false, false], [31, 31, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "are", "widely", "applied", "to", "various", "difficult", "computational", "problems", ",", "including", "problems", "from", "computer", "science", "(", "especially", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", ",", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms are widely applied to various difficult computational problems, including problems from computer science (especially artificial intelligence), mathematics, operations research, engineering, and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 27], [28, 34], [35, 42], [43, 45], [46, 53], [54, 63], [64, 77], [78, 86], [86, 87], [88, 97], [98, 106], [107, 111], [112, 120], [121, 128], [129, 130], [130, 140], [141, 151], [152, 164], [164, 165], [165, 166], [167, 178], [178, 179], [180, 190], [191, 199], [199, 200], [201, 212], [212, 213], [214, 217], [218, 232], [232, 233]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [8, 8, "location"], [10, 10, "country"], [14, 14, "country"], [22, 23, "algorithm"], [25, 25, "algorithm"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 8, 8, "physical", "", false, false], [0, 1, 14, 14, "general-affiliation", "nationality", false, false], [0, 1, 22, 23, "general-affiliation", "topic_of_study", false, false], [0, 1, 25, 25, "general-affiliation", "topic_of_study", false, false], [8, 8, 10, 10, "physical", "", false, false], [25, 25, 27, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "born", "3", "September", "1947", ",", "Wallersdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "has", "studied", "the", "use", "of", "bounded", "rationality", "and", "heuristics", "in", "decision", "-", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (born 3 September 1947, Wallersdorf, Germany) is a German psychologist who has studied the use of bounded rationality and heuristics in decision-making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 21], [22, 23], [24, 33], [34, 38], [38, 39], [40, 51], [51, 52], [53, 60], [60, 61], [62, 64], [65, 66], [67, 73], [74, 86], [87, 90], [91, 94], [95, 102], [103, 106], [107, 110], [111, 113], [114, 121], [122, 133], [134, 137], [138, 148], [149, 151], [152, 160], [160, 161], [161, 167], [167, 168]]}
{"doc_key": "ai-test-121", "ner": [[3, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["to", "minimise", "the", "mean", "square", "error", "."], "sentence-detokenized": "to minimise the mean square error.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [21, 27], [28, 33], [33, 34]]}
{"doc_key": "ai-test-122", "ner": [[12, 13, "misc"], [16, 17, "organisation"], [33, 35, "field"], [53, 54, "misc"], [63, 65, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 16, 17, "origin", "", false, false], [53, 54, 63, 65, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["But", "even", "an", "official", "language", "with", "a", "governing", "academy", ",", "such", "as", "Standard", "French", "with", "the", "Acad\u00e9mie", "fran\u00e7aise", ",", "is", "classified", "as", "a", "natural", "language", "(", "for", "example", ",", "in", "the", "field", "of", "natural", "language", "processing", ")", ",", "because", "its", "prescriptive", "points", "do", "not", "make", "it", "constructed", "enough", "to", "be", "classified", "as", "a", "constructed", "language", "or", "controlled", "enough", "to", "be", "classified", "as", "a", "controlled", "natural", "language", "."], "sentence-detokenized": "But even an official language with a governing academy, such as Standard French with the Acad\u00e9mie fran\u00e7aise, is classified as a natural language (for example, in the field of natural language processing), because its prescriptive points do not make it constructed enough to be classified as a constructed language or controlled enough to be classified as a controlled natural language.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 20], [21, 29], [30, 34], [35, 36], [37, 46], [47, 54], [54, 55], [56, 60], [61, 63], [64, 72], [73, 79], [80, 84], [85, 88], [89, 97], [98, 107], [107, 108], [109, 111], [112, 122], [123, 125], [126, 127], [128, 135], [136, 144], [145, 146], [146, 149], [150, 157], [157, 158], [159, 161], [162, 165], [166, 171], [172, 174], [175, 182], [183, 191], [192, 202], [202, 203], [203, 204], [205, 212], [213, 216], [217, 229], [230, 236], [237, 239], [240, 243], [244, 248], [249, 251], [252, 263], [264, 270], [271, 273], [274, 276], [277, 287], [288, 290], [291, 292], [293, 304], [305, 313], [314, 316], [317, 327], [328, 334], [335, 337], [338, 340], [341, 351], [352, 354], [355, 356], [357, 367], [368, 375], [376, 384], [384, 385]]}
{"doc_key": "ai-test-123", "ner": [[13, 13, "metrics"], [15, 16, "metrics"], [18, 18, "metrics"], [36, 37, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[18, 18, 15, 16, "named", "", false, false], [39, 39, 36, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "a", "number", "of", "other", "metrics", ",", "the", "simplest", "of", "which", "is", "accuracy", "or", "Fraction", "Correct", "(", "FC", ")", ",", "which", "measures", "the", "fraction", "of", "all", "examples", "that", "are", "correctly", "categorised", ";", "its", "complement", "is", "Fraction", "Incorrect", "(", "FiC", ")", "."], "sentence-detokenized": "There are a number of other metrics, the simplest of which is accuracy or Fraction Correct (FC), which measures the fraction of all examples that are correctly categorised; its complement is Fraction Incorrect (FiC).", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 18], [19, 21], [22, 27], [28, 35], [35, 36], [37, 40], [41, 49], [50, 52], [53, 58], [59, 61], [62, 70], [71, 73], [74, 82], [83, 90], [91, 92], [92, 94], [94, 95], [95, 96], [97, 102], [103, 111], [112, 115], [116, 124], [125, 127], [128, 131], [132, 140], [141, 145], [146, 149], [150, 159], [160, 171], [171, 172], [173, 176], [177, 187], [188, 190], [191, 199], [200, 209], [210, 211], [211, 214], [214, 215], [215, 216]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [6, 9, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 9, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "became", "a", "Fellow", "of", "the", "Association", "for", "Computational", "Linguistics", "in", "2016", "."], "sentence-detokenized": "Cardie became a Fellow of the Association for Computational Linguistics in 2016.", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 59], [60, 71], [72, 74], [75, 79], [79, 80]]}
{"doc_key": "ai-test-125", "ner": [[12, 14, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Learning", "the", "parameters", "of", "math\\", "theta", "/", "mathematics", "is", "usually", "done", "with", "maximum", "likelihood", "learning", "for", "mathp", "(", "Y_i", "|", "X_i;\\theta", ")", "/", "math", "."], "sentence-detokenized": "Learning the parameters of math\\theta/mathematics is usually done with maximum likelihood learning for mathp(Y_i | X_i;\\theta)/math.", "token2charspan": [[0, 8], [9, 12], [13, 23], [24, 26], [27, 32], [32, 37], [37, 38], [38, 49], [50, 52], [53, 60], [61, 65], [66, 70], [71, 78], [79, 89], [90, 98], [99, 102], [103, 108], [108, 109], [109, 112], [113, 114], [115, 125], [125, 126], [126, 127], [127, 131], [131, 132]]}
{"doc_key": "ai-test-126", "ner": [[0, 1, "task"], [4, 6, "algorithm"], [8, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 0, 1, "usage", "", true, false], [8, 9, 4, 6, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cluster", "analysis", ",", "and", "non-negative", "matrix", "factorisation", "for", "descriptive", "mining", "."], "sentence-detokenized": "Cluster analysis, and non-negative matrix factorisation for descriptive mining.", "token2charspan": [[0, 7], [8, 16], [16, 17], [18, 21], [22, 34], [35, 41], [42, 55], [56, 59], [60, 71], [72, 78], [78, 79]]}
{"doc_key": "ai-test-127", "ner": [[1, 2, "field"], [5, 6, "field"], [26, 28, "field"], [30, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[26, 28, 1, 2, "part-of", "", false, false], [26, 28, 5, 6, "part-of", "", false, false], [30, 31, 1, 2, "part-of", "", false, false], [30, 31, 5, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", "and", "the", "information", "technology", "that", "enables", "it", ",", "there", "has", "been", "a", "long", "-", "term", "challenge", "to", "the", "ability", "of", "computers", "to", "perform", "natural", "language", "processing", "and", "machine", "learning", "."], "sentence-detokenized": "In computer science and the information technology that enables it, there has been a long-term challenge to the ability of computers to perform natural language processing and machine learning.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 23], [24, 27], [28, 39], [40, 50], [51, 55], [56, 63], [64, 66], [66, 67], [68, 73], [74, 77], [78, 82], [83, 84], [85, 89], [89, 90], [90, 94], [95, 104], [105, 107], [108, 111], [112, 119], [120, 122], [123, 132], [133, 135], [136, 143], [144, 151], [152, 160], [161, 171], [172, 175], [176, 183], [184, 192], [192, 193]]}
{"doc_key": "ai-test-128", "ner": [[3, 5, "algorithm"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 5, 9, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "Code", "for", "Gabor", "feature", "extraction", "from", "images", "in", "MATLAB", "can", "be", "found", "at"], "sentence-detokenized": "(Code for Gabor feature extraction from images in MATLAB can be found at", "token2charspan": [[0, 1], [1, 5], [6, 9], [10, 15], [16, 23], [24, 34], [35, 39], [40, 46], [47, 49], [50, 56], [57, 60], [61, 63], [64, 69], [70, 72]]}
{"doc_key": "ai-test-129", "ner": [[0, 0, "misc"], [14, 15, "algorithm"], [19, 19, "task"], [21, 21, "task"], [23, 24, "task"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 14, 15, "general-affiliation", "", false, false], [0, 0, 19, 19, "related-to", "solves_problem_of_type", false, false], [0, 0, 21, 21, "related-to", "solves_problem_of_type", false, false], [0, 0, 23, 24, "related-to", "solves_problem_of_type", false, false], [0, 0, 26, 27, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["NeuralExpert", "centres", "the", "design", "specification", "around", "the", "type", "of", "problem", "the", "user", "wants", "the", "neural", "network", "to", "solve", "(", "Classification", ",", "Prediction", ",", "Function", "approximation", "or", "Cluster", "analysis", ")", "."], "sentence-detokenized": "NeuralExpert centres the design specification around the type of problem the user wants the neural network to solve (Classification, Prediction, Function approximation or Cluster analysis).", "token2charspan": [[0, 12], [13, 20], [21, 24], [25, 31], [32, 45], [46, 52], [53, 56], [57, 61], [62, 64], [65, 72], [73, 76], [77, 81], [82, 87], [88, 91], [92, 98], [99, 106], [107, 109], [110, 115], [116, 117], [117, 131], [131, 132], [133, 143], [143, 144], [145, 153], [154, 167], [168, 170], [171, 178], [179, 187], [187, 188], [188, 189]]}
{"doc_key": "ai-test-130", "ner": [[2, 6, "misc"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "size", "of", "the", "quantisation", "step", "(", "\u0394", ")", "is", "small", "relative", "to", "the", "variation", "in", "the", "quantised", "signal", ",", "it", "is", "relatively", "easy", "to", "show", "that", "the", "mean", "square", "error", "produced", "by", "such", "a", "rounding", "operation", "will", "be", "about", "math\\", "Delta^2/12", "/", "math.math"], "sentence-detokenized": "When the size of the quantisation step (\u0394) is small relative to the variation in the quantised signal, it is relatively easy to show that the mean square error produced by such a rounding operation will be about math\\Delta^2/12/ math.math", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 20], [21, 33], [34, 38], [39, 40], [40, 41], [41, 42], [43, 45], [46, 51], [52, 60], [61, 63], [64, 67], [68, 77], [78, 80], [81, 84], [85, 94], [95, 101], [101, 102], [103, 105], [106, 108], [109, 119], [120, 124], [125, 127], [128, 132], [133, 137], [138, 141], [142, 146], [147, 153], [154, 159], [160, 168], [169, 171], [172, 176], [177, 178], [179, 187], [188, 197], [198, 202], [203, 205], [206, 211], [212, 217], [217, 227], [227, 228], [229, 238]]}
{"doc_key": "ai-test-131", "ner": [[16, 16, "product"], [23, 26, "researcher"], [28, 29, "researcher"], [31, 33, "researcher"], [35, 36, "researcher"], [38, 40, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "construction", "of", "rich", "lexicons", "with", "appropriate", "ontologies", "requires", "significant", "effort", ",", "for", "example", ",", "the", "Wordnet", "lexicon", "required", "years", "of", "effort", ".", "G.", "A", ".", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "The construction of rich lexicons with appropriate ontologies requires significant effort, for example, the Wordnet lexicon required years of effort. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 3], [4, 16], [17, 19], [20, 24], [25, 33], [34, 38], [39, 50], [51, 61], [62, 70], [71, 82], [83, 89], [89, 90], [91, 94], [95, 102], [102, 103], [104, 107], [108, 115], [116, 123], [124, 132], [133, 138], [139, 141], [142, 148], [148, 149], [150, 152], [153, 154], [154, 155], [156, 162], [162, 163], [164, 166], [167, 175], [175, 176], [177, 179], [180, 182], [183, 191], [191, 192], [193, 195], [196, 201], [201, 202], [203, 204], [204, 205], [206, 212], [212, 213]]}
{"doc_key": "ai-test-132", "ner": [[0, 1, "organisation"], [21, 22, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 22, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kawasaki", "'s", "portfolio", "also", "includes", "retractable", "roofs", ",", "floors", ",", "and", "other", "giant", "structures", ",", "one", "example", "of", "which", "is", "the", "Sapporo", "Dome", "'", "retractable", "surface", "'", "."], "sentence-detokenized": "Kawasaki's portfolio also includes retractable roofs, floors, and other giant structures, one example of which is the Sapporo Dome 'retractable surface'.", "token2charspan": [[0, 8], [8, 10], [11, 20], [21, 25], [26, 34], [35, 46], [47, 52], [52, 53], [54, 60], [60, 61], [62, 65], [66, 71], [72, 77], [78, 88], [88, 89], [90, 93], [94, 101], [102, 104], [105, 110], [111, 113], [114, 117], [118, 125], [126, 130], [131, 132], [132, 143], [144, 151], [151, 152], [152, 153]]}
{"doc_key": "ai-test-133", "ner": [[0, 1, "metrics"], [4, 6, "metrics"], [8, 10, "metrics"], [15, 16, "metrics"], [38, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 15, 16, "related-to", "", false, false], [0, 1, 38, 38, "opposite", "alternative_to", false, false], [4, 6, 0, 1, "type-of", "", false, false], [8, 10, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa", "statistics", "such", "as", "Fleiss", "'", "kappa", "and", "Cohen", "'s", "kappa", "are", "methods", "for", "calculating", "inter-rater", "reliability", "based", "on", "different", "assumptions", "about", "marginal", "distributions", "or", "prior", "distributions", ",", "and", "are", "increasingly", "used", "as", "chance", "-", "corrected", "alternatives", "to", "accuracy", "in", "other", "contexts", "."], "sentence-detokenized": "Kappa statistics such as Fleiss' kappa and Cohen's kappa are methods for calculating inter-rater reliability based on different assumptions about marginal distributions or prior distributions, and are increasingly used as chance-corrected alternatives to accuracy in other contexts.", "token2charspan": [[0, 5], [6, 16], [17, 21], [22, 24], [25, 31], [31, 32], [33, 38], [39, 42], [43, 48], [48, 50], [51, 56], [57, 60], [61, 68], [69, 72], [73, 84], [85, 96], [97, 108], [109, 114], [115, 117], [118, 127], [128, 139], [140, 145], [146, 154], [155, 168], [169, 171], [172, 177], [178, 191], [191, 192], [193, 196], [197, 200], [201, 213], [214, 218], [219, 221], [222, 228], [228, 229], [229, 238], [239, 251], [252, 254], [255, 263], [264, 266], [267, 272], [273, 281], [281, 282]]}
{"doc_key": "ai-test-134", "ner": [[3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 13, "researcher"], [18, 18, "researcher"], [27, 29, "algorithm"], [31, 35, "algorithm"], [37, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 4, 18, 18, "role", "student_of", false, false], [6, 7, 18, 18, "role", "student_of", false, false], [9, 10, 18, 18, "role", "student_of", false, false], [12, 13, 18, 18, "role", "student_of", false, false], [31, 35, 3, 4, "origin", "", false, false], [31, 35, 6, 7, "origin", "", false, false], [31, 35, 9, 10, "origin", "", false, false], [31, 35, 12, 13, "origin", "", false, false], [31, 35, 18, 18, "origin", "", false, false], [31, 35, 27, 29, "type-of", "", false, false], [37, 37, 31, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["With", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", ",", "and", "others", ",", "Schmidhuber", "published", "increasingly", "sophisticated", "versions", "of", "a", "type", "of", "recurrent", "neural", "network", "called", "long", "short", "-", "term", "memory", "(", "LSTM", ")", "."], "sentence-detokenized": "With his students Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves, and others, Schmidhuber published increasingly sophisticated versions of a type of recurrent neural network called long short-term memory (LSTM).", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 22], [23, 33], [33, 34], [35, 40], [41, 45], [45, 46], [47, 51], [52, 59], [59, 60], [61, 65], [66, 72], [72, 73], [74, 77], [78, 84], [84, 85], [86, 97], [98, 107], [108, 120], [121, 134], [135, 143], [144, 146], [147, 148], [149, 153], [154, 156], [157, 166], [167, 173], [174, 181], [182, 188], [189, 193], [194, 199], [199, 200], [200, 204], [205, 211], [212, 213], [213, 217], [217, 218], [218, 219]]}
{"doc_key": "ai-test-135", "ner": [[4, 8, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "The", "first", "KUKA", "LBR", "3", "cobot", "was", "released", "."], "sentence-detokenized": "2004 - The first KUKA LBR 3 cobot was released.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 21], [22, 25], [26, 27], [28, 33], [34, 37], [38, 46], [46, 47]]}
{"doc_key": "ai-test-136", "ner": [[11, 13, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "superficial", "approaches", "used", "to", "train", "and", "then", "disambiguate", "are", "the", "Naive", "Bayes", "classifier", "and", "decision", "trees", "."], "sentence-detokenized": "Two superficial approaches used to train and then disambiguate are the Naive Bayes classifier and decision trees.", "token2charspan": [[0, 3], [4, 15], [16, 26], [27, 31], [32, 34], [35, 40], [41, 44], [45, 49], [50, 62], [63, 66], [67, 70], [71, 76], [77, 82], [83, 93], [94, 97], [98, 106], [107, 112], [112, 113]]}
{"doc_key": "ai-test-137", "ner": [[5, 6, "misc"], [12, 13, "person"], [15, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 12, 13, "origin", "", false, false], [5, 6, 15, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "practical", "form", "of", "photography", "was", "introduced", "in", "January", "1839", "by", "Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "The first practical form of photography was introduced in January 1839 by Louis Daguerre and Henry Fox Talbot.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 24], [25, 27], [28, 39], [40, 43], [44, 54], [55, 57], [58, 65], [66, 70], [71, 73], [74, 79], [80, 88], [89, 92], [93, 98], [99, 102], [103, 109], [109, 110]]}
{"doc_key": "ai-test-138", "ner": [[3, 4, "task"], [8, 9, "task"], [18, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 18, 20, "part-of", "task_part_of_field", false, false], [8, 9, 18, 20, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "speech", "synthesis", ",", "combined", "with", "speech", "recognition", ",", "enables", "interaction", "with", "mobile", "devices", "via", "a", "language", "processing", "interface", "."], "sentence-detokenized": "For example, speech synthesis, combined with speech recognition, enables interaction with mobile devices via a language processing interface.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [29, 30], [31, 39], [40, 44], [45, 51], [52, 63], [63, 64], [65, 72], [73, 84], [85, 89], [90, 96], [97, 104], [105, 108], [109, 110], [111, 119], [120, 130], [131, 140], [140, 141]]}
{"doc_key": "ai-test-139", "ner": [[0, 0, "product"], [15, 15, "programlang"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 15, 15, "general-affiliation", "", false, false], [0, 0, 17, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Phidgets", "can", "be", "programmed", "using", "a", "variety", "of", "software", "and", "programming", "languages", ",", "ranging", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "Phidgets can be programmed using a variety of software and programming languages, ranging from Java to Microsoft Excel.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 26], [27, 32], [33, 34], [35, 42], [43, 45], [46, 54], [55, 58], [59, 70], [71, 80], [80, 81], [82, 89], [90, 94], [95, 99], [100, 102], [103, 112], [113, 118], [118, 119]]}
{"doc_key": "ai-test-140", "ner": [[2, 3, "field"], [9, 10, "researcher"], [13, 14, "misc"], [21, 22, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 10, "origin", "", false, false], [9, 10, 21, 22, "general-affiliation", "topic_of_study", false, false], [9, 10, 24, 25, "general-affiliation", "topic_of_study", false, false], [13, 14, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "machine", "learning", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "an", "American", "IBMer", "and", "pioneer", "in", "the", "field", "of", "computer", "games", "and", "artificial", "intelligence", "."], "sentence-detokenized": "The term machine learning was coined in 1959 by Arthur Samuel, an American IBMer and pioneer in the field of computer games and artificial intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 25], [26, 29], [30, 36], [37, 39], [40, 44], [45, 47], [48, 54], [55, 61], [61, 62], [63, 65], [66, 74], [75, 80], [81, 84], [85, 92], [93, 95], [96, 99], [100, 105], [106, 108], [109, 117], [118, 123], [124, 127], [128, 138], [139, 151], [151, 152]]}
{"doc_key": "ai-test-141", "ner": [[0, 1, "misc"], [2, 3, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Israeli", "poet", "David", "Avidan", ",", "who", "is", "fascinated", "by", "future", "technology", "and", "its", "relationship", "with", "art", ",", "wanted", "to", "explore", "the", "use", "of", "computers", "to", "write", "literature", "."], "sentence-detokenized": "Israeli poet David Avidan, who is fascinated by future technology and its relationship with art, wanted to explore the use of computers to write literature.", "token2charspan": [[0, 7], [8, 12], [13, 18], [19, 25], [25, 26], [27, 30], [31, 33], [34, 44], [45, 47], [48, 54], [55, 65], [66, 69], [70, 73], [74, 86], [87, 91], [92, 95], [95, 96], [97, 103], [104, 106], [107, 114], [115, 118], [119, 122], [123, 125], [126, 135], [136, 138], [139, 144], [145, 155], [155, 156]]}
{"doc_key": "ai-test-142", "ner": [[4, 5, "misc"], [9, 9, "organisation"], [16, 16, "location"], [26, 27, "location"], [28, 29, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 4, 5, "part-of", "", false, false], [28, 29, 26, 27, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "part", "of", "the", "GATEway", "Project", "in", "2017", ",", "Oxbotica", "trialled", "seven", "autonomous", "shuttle", "buses", "in", "Greenwich", ",", "navigating", "a", "two", "-", "mile", "riverside", "path", "near", "London", "'s", "O2", "Arena", "on", "a", "route", "also", "used", "by", "pedestrians", "and", "cyclists", "."], "sentence-detokenized": "As part of the GATEway Project in 2017, Oxbotica trialled seven autonomous shuttle buses in Greenwich, navigating a two-mile riverside path near London's O2 Arena on a route also used by pedestrians and cyclists.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 30], [31, 33], [34, 38], [38, 39], [40, 48], [49, 57], [58, 63], [64, 74], [75, 82], [83, 88], [89, 91], [92, 101], [101, 102], [103, 113], [114, 115], [116, 119], [119, 120], [120, 124], [125, 134], [135, 139], [140, 144], [145, 151], [151, 153], [154, 156], [157, 162], [163, 165], [166, 167], [168, 173], [174, 178], [179, 183], [184, 186], [187, 198], [199, 202], [203, 211], [211, 212]]}
{"doc_key": "ai-test-143", "ner": [[9, 10, "task"], [13, 15, "metrics"], [24, 25, "misc"], [27, 27, "metrics"], [29, 29, "metrics"], [31, 31, "metrics"], [33, 33, "metrics"], [35, 37, "metrics"], [40, 40, "metrics"], [42, 42, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[13, 15, 24, 25, "related-to", "is_a", false, false], [13, 15, 27, 27, "usage", "", false, false], [13, 15, 29, 29, "usage", "", false, false], [27, 27, 31, 31, "named", "same", false, false], [29, 29, 42, 42, "named", "same", false, false], [31, 31, 40, 40, "opposite", "", false, false], [31, 31, 42, 42, "opposite", "", false, false], [33, 33, 31, 31, "named", "", false, false], [35, 37, 31, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["An", "unrelated", "but", "commonly", "used", "basic", "statistical", "combination", "of", "information", "retrieval", "is", "the", "F", "-", "score", ",", "which", "is", "a", "(", "possibly", "weighted", ")", "harmonic", "average", "of", "recall", "and", "precision", "where", "recall", "=", "sensitivity", "=", "correct", "positive", "rate", ",", "but", "specificity", "and", "precision", "are", "entirely", "different", "measures", "."], "sentence-detokenized": "An unrelated but commonly used basic statistical combination of information retrieval is the F-score, which is a (possibly weighted) harmonic average of recall and precision where recall = sensitivity = correct positive rate, but specificity and precision are entirely different measures.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 25], [26, 30], [31, 36], [37, 48], [49, 60], [61, 63], [64, 75], [76, 85], [86, 88], [89, 92], [93, 94], [94, 95], [95, 100], [100, 101], [102, 107], [108, 110], [111, 112], [113, 114], [114, 122], [123, 131], [131, 132], [133, 141], [142, 149], [150, 152], [153, 159], [160, 163], [164, 173], [174, 179], [180, 186], [187, 188], [189, 200], [201, 202], [203, 210], [211, 219], [220, 224], [224, 225], [226, 229], [230, 241], [242, 245], [246, 255], [256, 259], [260, 268], [269, 278], [279, 287], [287, 288]]}
{"doc_key": "ai-test-144", "ner": [[0, 1, "field"], [10, 10, "field"], [12, 12, "field"], [14, 14, "field"], [16, 17, "field"], [20, 21, "field"], [30, 31, "product"], [33, 36, "product"], [38, 39, "product"], [42, 43, "product"], [54, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 10, "origin", "takes_inspiration_from", false, false], [0, 1, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 1, 14, 14, "origin", "takes_inspiration_from", false, false], [0, 1, 16, 17, "origin", "takes_inspiration_from", false, false], [0, 1, 20, 21, "origin", "takes_inspiration_from", false, false], [30, 31, 0, 1, "origin", "", false, false], [33, 36, 0, 1, "origin", "", false, false], [38, 39, 0, 1, "origin", "", false, false], [42, 43, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "is", "an", "interdisciplinary", "subject", "that", "draws", "inspiration", "from", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", ",", "and", "electronic", "engineering", "to", "design", "artificial", "neural", "systems", ",", "such", "as", "vision", "systems", ",", "eye", "-", "head", "systems", ",", "auditory", "processors", ",", "and", "autonomous", "robots", ",", "whose", "physical", "architecture", "and", "design", "principles", "are", "based", "on", "biological", "nervous", "systems", "."], "sentence-detokenized": "Neuromorphic engineering is an interdisciplinary subject that draws inspiration from biology, physics, mathematics, computer science, and electronic engineering to design artificial neural systems, such as vision systems, eye-head systems, auditory processors, and autonomous robots, whose physical architecture and design principles are based on biological nervous systems.", "token2charspan": [[0, 12], [13, 24], [25, 27], [28, 30], [31, 48], [49, 56], [57, 61], [62, 67], [68, 79], [80, 84], [85, 92], [92, 93], [94, 101], [101, 102], [103, 114], [114, 115], [116, 124], [125, 132], [132, 133], [134, 137], [138, 148], [149, 160], [161, 163], [164, 170], [171, 181], [182, 188], [189, 196], [196, 197], [198, 202], [203, 205], [206, 212], [213, 220], [220, 221], [222, 225], [225, 226], [226, 230], [231, 238], [238, 239], [240, 248], [249, 259], [259, 260], [261, 264], [265, 275], [276, 282], [282, 283], [284, 289], [290, 298], [299, 311], [312, 315], [316, 322], [323, 333], [334, 337], [338, 343], [344, 346], [347, 357], [358, 365], [366, 373], [373, 374]]}
{"doc_key": "ai-test-145", "ner": [[6, 8, "metrics"], [12, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 6, 8, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "be", "more", "specific", ",", "the", "BIBO", "stability", "criterion", "requires", "that", "the", "ROC", "of", "the", "system", "covers", "the", "unit", "circle", "."], "sentence-detokenized": "To be more specific, the BIBO stability criterion requires that the ROC of the system covers the unit circle.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 19], [19, 20], [21, 24], [25, 29], [30, 39], [40, 49], [50, 58], [59, 63], [64, 67], [68, 71], [72, 74], [75, 78], [79, 85], [86, 92], [93, 96], [97, 101], [102, 108], [108, 109]]}
{"doc_key": "ai-test-146", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "The", "programme", "was", "rewritten", "in", "Java", "starting", "in", "1998", "."], "sentence-detokenized": "2 The programme was rewritten in Java starting in 1998.", "token2charspan": [[0, 1], [2, 5], [6, 15], [16, 19], [20, 29], [30, 32], [33, 37], [38, 46], [47, 49], [50, 54], [54, 55]]}
{"doc_key": "ai-test-147", "ner": [[0, 0, "metrics"], [7, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 8, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MCC", "can", "be", "calculated", "directly", "from", "the", "confusion", "matrix", "using", "the", "formula", ":"], "sentence-detokenized": "MCC can be calculated directly from the confusion matrix using the formula:", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 21], [22, 30], [31, 35], [36, 39], [40, 49], [50, 56], [57, 62], [63, 66], [67, 74], [74, 75]]}
{"doc_key": "ai-test-148", "ner": [[8, 13, "organisation"], [19, 24, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 13, 19, 24, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "developed", "by", "a", "team", "at", "the", "MIT", "-", "IBM", "Watson", "AI", "Lab", "and", "first", "presented", "at", "the", "2018", "International", "Conference", "on", "Learning", "Representations", "."], "sentence-detokenized": "It was developed by a team at the MIT-IBM Watson AI Lab and first presented at the 2018 International Conference on Learning Representations.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 29], [30, 33], [34, 37], [37, 38], [38, 41], [42, 48], [49, 51], [52, 55], [56, 59], [60, 65], [66, 75], [76, 78], [79, 82], [83, 87], [88, 101], [102, 112], [113, 115], [116, 124], [125, 140], [140, 141]]}
{"doc_key": "ai-test-149", "ner": [[2, 4, "metrics"], [15, 17, "metrics"], [19, 21, "metrics"], [47, 47, "metrics"], [49, 49, "metrics"], [55, 57, "metrics"], [60, 60, "metrics"], [62, 62, "metrics"], [64, 67, "metrics"], [71, 71, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[15, 17, 47, 47, "type-of", "", false, false], [15, 17, 55, 57, "related-to", "collapses_to_identity", false, false], [19, 21, 49, 49, "type-of", "", false, false], [19, 21, 55, 57, "related-to", "collapses_to_identity", false, false], [19, 21, 64, 67, "named", "same", false, false], [60, 60, 71, 71, "related-to", "collapses_to_identity", false, false], [62, 62, 71, 71, "related-to", "collapses_to_identity", false, false], [64, 67, 71, 71, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["When", "the", "prevalence", "of", "TRUE", "for", "two", "positive", "variables", "is", "the", "same", "as", "assumed", "in", "Fleiss", "'", "kappa", "and", "F", "-", "score", ",", "i.e.", "the", "number", "of", "positive", "predictions", "corresponds", "to", "the", "number", "of", "positive", "classes", "in", "the", "dichotomous", "case", "(", "two", "classes", ")", ",", "the", "different", "kappa", "and", "correlation", "measures", "collapse", "into", "identity", "with", "Youden", "'s", "J", ",", "and", "recall", ",", "precision", "and", "F", "-", "score", "are", "also", "identical", "to", "accuracy", "."], "sentence-detokenized": "When the prevalence of TRUE for two positive variables is the same as assumed in Fleiss' kappa and F-score, i.e. the number of positive predictions corresponds to the number of positive classes in the dichotomous case (two classes), the different kappa and correlation measures collapse into identity with Youden's J, and recall, precision and F-score are also identical to accuracy.", "token2charspan": [[0, 4], [5, 8], [9, 19], [20, 22], [23, 27], [28, 31], [32, 35], [36, 44], [45, 54], [55, 57], [58, 61], [62, 66], [67, 69], [70, 77], [78, 80], [81, 87], [87, 88], [89, 94], [95, 98], [99, 100], [100, 101], [101, 106], [106, 107], [108, 112], [113, 116], [117, 123], [124, 126], [127, 135], [136, 147], [148, 159], [160, 162], [163, 166], [167, 173], [174, 176], [177, 185], [186, 193], [194, 196], [197, 200], [201, 212], [213, 217], [218, 219], [219, 222], [223, 230], [230, 231], [231, 232], [233, 236], [237, 246], [247, 252], [253, 256], [257, 268], [269, 277], [278, 286], [287, 291], [292, 300], [301, 305], [306, 312], [312, 314], [315, 316], [316, 317], [318, 321], [322, 328], [328, 329], [330, 339], [340, 343], [344, 345], [345, 346], [346, 351], [352, 355], [356, 360], [361, 370], [371, 373], [374, 382], [382, 383]]}
{"doc_key": "ai-test-150", "ner": [[0, 7, "misc"], [5, 5, "misc"], [9, 9, "conference"], [14, 15, "task"], [17, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 7, 9, 9, "part-of", "", false, false], [0, 7, 9, 9, "physical", "", false, false], [0, 7, 9, 9, "temporal", "", false, false], [5, 5, 0, 7, "named", "", false, false], [14, 15, 0, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Building", "Educational", "Applications", "(", "BEA", ")", "workshop", "at", "NAACL", "2013", "hosted", "the", "inaugural", "NLI", "co-task", ".", "Tetreault", "et", "al", ",", "2013", "The", "competition", "generated", "29", "entries", "from", "teams", "around", "the", "world", ",", "24", "of", "which", "also", "published", "papers", "describing", "their", "systems", "and", "approaches", "."], "sentence-detokenized": "The Building Educational Applications (BEA) workshop at NAACL 2013 hosted the inaugural NLI co-task. Tetreault et al, 2013 The competition generated 29 entries from teams around the world, 24 of which also published papers describing their systems and approaches.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 37], [38, 39], [39, 42], [42, 43], [44, 52], [53, 55], [56, 61], [62, 66], [67, 73], [74, 77], [78, 87], [88, 91], [92, 99], [99, 100], [101, 110], [111, 113], [114, 116], [116, 117], [118, 122], [123, 126], [127, 138], [139, 148], [149, 151], [152, 159], [160, 164], [165, 170], [171, 177], [178, 181], [182, 187], [187, 188], [189, 191], [192, 194], [195, 200], [201, 205], [206, 215], [216, 222], [223, 233], [234, 239], [240, 247], [248, 251], [252, 262], [262, 263]]}
{"doc_key": "ai-test-151", "ner": [[0, 2, "algorithm"], [5, 7, "algorithm"], [15, 16, "misc"], [18, 19, "misc"], [34, 35, "misc"], [38, 39, "algorithm"], [42, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 5, 7, "type-of", "", false, false], [0, 2, 15, 16, "related-to", "finds", false, false], [18, 19, 15, 16, "type-of", "", false, false], [42, 42, 38, 39, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Viterbi", "algorithm", "is", "a", "dynamic", "programming", "algorithm", "for", "finding", "the", "most", "probable", "sequence", "of", "hidden", "states", "called", "Viterbi", "paths", "that", "result", "in", "a", "sequence", "of", "observed", "events", ",", "especially", "in", "the", "context", "of", "Markov", "information", "sources", "and", "hidden", "Markov", "models", "(", "HMMs", ")", "."], "sentence-detokenized": "The Viterbi algorithm is a dynamic programming algorithm for finding the most probable sequence of hidden states called Viterbi paths that result in a sequence of observed events, especially in the context of Markov information sources and hidden Markov models (HMMs).", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 24], [25, 26], [27, 34], [35, 46], [47, 56], [57, 60], [61, 68], [69, 72], [73, 77], [78, 86], [87, 95], [96, 98], [99, 105], [106, 112], [113, 119], [120, 127], [128, 133], [134, 138], [139, 145], [146, 148], [149, 150], [151, 159], [160, 162], [163, 171], [172, 178], [178, 179], [180, 190], [191, 193], [194, 197], [198, 205], [206, 208], [209, 215], [216, 227], [228, 235], [236, 239], [240, 246], [247, 253], [254, 260], [261, 262], [262, 266], [266, 267], [267, 268]]}
{"doc_key": "ai-test-152", "ner": [[1, 1, "field"], [3, 5, "algorithm"], [8, 9, "misc"], [12, 13, "algorithm"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 1, 1, "part-of", "", false, false], [3, 5, 8, 9, "general-affiliation", "", false, false], [3, 5, 12, 13, "related-to", "generalizes_from", false, false], [3, 5, 15, 16, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "multinomial", "logistic", "regression", "is", "a", "classification", "method", "that", "generalises", "logistic", "regression", "for", "multiclass", "classification", ",", "i.e.", "with", "more", "than", "two", "possible", "discrete", "outcomes", "."], "sentence-detokenized": "In statistics, multinomial logistic regression is a classification method that generalises logistic regression for multiclass classification, i.e. with more than two possible discrete outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 26], [27, 35], [36, 46], [47, 49], [50, 51], [52, 66], [67, 73], [74, 78], [79, 90], [91, 99], [100, 110], [111, 114], [115, 125], [126, 140], [140, 141], [142, 146], [147, 151], [152, 156], [157, 161], [162, 165], [166, 174], [175, 183], [184, 192], [192, 193]]}
{"doc_key": "ai-test-153", "ner": [[0, 3, "algorithm"], [9, 10, "field"], [12, 15, "field"], [18, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 9, 10, "part-of", "", false, false], [0, 3, 12, 15, "part-of", "", false, false], [18, 18, 0, 3, "usage", "", true, false], [20, 21, 0, 3, "usage", "", true, false], [23, 24, 0, 3, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden", "Markov", "models", "are", "known", "for", "their", "application", "to", "reinforcement", "learning", "and", "recognition", "of", "temporal", "patterns", "such", "as", "speech", ",", "handwriting", "recognition", ",", "gesture", "recognition", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov models are known for their application to reinforcement learning and recognition of temporal patterns such as speech, handwriting recognition, gesture recognition, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 30], [31, 34], [35, 40], [41, 52], [53, 55], [56, 69], [70, 78], [79, 82], [83, 94], [95, 97], [98, 106], [107, 115], [116, 120], [121, 123], [124, 130], [130, 131], [132, 143], [144, 155], [155, 156], [157, 164], [165, 176], [176, 177], [178, 182], [183, 190], [190, 191], [192, 196], [197, 205], [205, 206]]}
{"doc_key": "ai-test-154", "ner": [[7, 9, "misc"], [34, 37, "metrics"], [39, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 39, 39, "named", "", false, false], [34, 37, 39, 39, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Basically", ",", "this", "means", "that", "if", "a", "later", "-", "gram", "has", "been", "seen", "more", "than", "k", "times", "in", "training", ",", "the", "conditional", "probability", "of", "a", "word", "given", "it", "s", "history", "is", "proportional", "to", "the", "maximum", "likelihood", "estimate", "of", "that", "programme", "."], "sentence-detokenized": "Basically, this means that if a later-gram has been seen more than k times in training, the conditional probability of a word given its history is proportional to the maximum likelihood estimate of that programme.", "token2charspan": [[0, 9], [9, 10], [11, 15], [16, 21], [22, 26], [27, 29], [30, 31], [32, 37], [37, 38], [38, 42], [43, 46], [47, 51], [52, 56], [57, 61], [62, 66], [67, 68], [69, 74], [75, 77], [78, 86], [86, 87], [88, 91], [92, 103], [104, 115], [116, 118], [119, 120], [121, 125], [126, 131], [132, 134], [134, 135], [136, 143], [144, 146], [147, 159], [160, 162], [163, 166], [167, 174], [175, 185], [186, 194], [195, 197], [198, 202], [203, 212], [212, 213]]}
{"doc_key": "ai-test-155", "ner": [[4, 5, "task"], [7, 9, "task"], [12, 14, "task"], [18, 20, "task"], [28, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[28, 30, 18, 20, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "knowledge", "representation", ",", "common", "sense", "reasoning", ",", "and", "natural", "language", "understanding", ",", "believing", "that", "deep", "language", "understanding", "can", "currently", "only", "be", "achieved", "by", "significant", "hand", "-", "engineering", "of", "semantically", "rich", "formalisms", "coupled", "with", "statistical", "preferences", "."], "sentence-detokenized": "He is interested in knowledge representation, common sense reasoning, and natural language understanding, believing that deep language understanding can currently only be achieved by significant hand-engineering of semantically rich formalisms coupled with statistical preferences.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 29], [30, 44], [44, 45], [46, 52], [53, 58], [59, 68], [68, 69], [70, 73], [74, 81], [82, 90], [91, 104], [104, 105], [106, 115], [116, 120], [121, 125], [126, 134], [135, 148], [149, 152], [153, 162], [163, 167], [168, 170], [171, 179], [180, 182], [183, 194], [195, 199], [199, 200], [200, 211], [212, 214], [215, 227], [228, 232], [233, 243], [244, 251], [252, 256], [257, 268], [269, 280], [280, 281]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "JavaScript", ",", "Python", "or"], "sentence-detokenized": "In JavaScript, Python or", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 24]]}
{"doc_key": "ai-test-157", "ner": [[0, 3, "misc"], [6, 7, "misc"], [10, 10, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 6, 7, "part-of", "", false, false], [6, 7, 10, 10, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "Award", "was", "announced", "in", "AI", "Magazine", "published", "by", "AAAI", "."], "sentence-detokenized": "The Newcomb Award was announced in AI Magazine published by AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 21], [22, 31], [32, 34], [35, 37], [38, 46], [47, 56], [57, 59], [60, 64], [64, 65]]}
{"doc_key": "ai-test-158", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "square", "error", "on", "the", "100", "-", "exemplar", "test", "set", "is", "0.084", ",", "which", "is", "smaller", "than", "the", "non-normalised", "error", "."], "sentence-detokenized": "The mean square error on the 100-exemplar test set is 0.084, which is smaller than the non-normalised error.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 21], [22, 24], [25, 28], [29, 32], [32, 33], [33, 41], [42, 46], [47, 50], [51, 53], [54, 59], [59, 60], [61, 66], [67, 69], [70, 77], [78, 82], [83, 86], [87, 101], [102, 107], [107, 108]]}
{"doc_key": "ai-test-159", "ner": [[0, 2, "metrics"], [8, 10, "field"], [15, 17, "task"], [19, 19, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 10, 0, 2, "usage", "", false, false], [15, 17, 8, 10, "part-of", "task_part_of_field", false, false], [19, 19, 15, 17, "named", "", false, false], [23, 24, 8, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["F", "-", "score", "has", "been", "widely", "used", "in", "natural", "language", "processing", "literature", ",", "such", "as", "named", "entity", "recognition", "(", "NER", ")", "evaluation", "and", "word", "segmentation", "."], "sentence-detokenized": "F-score has been widely used in natural language processing literature, such as named entity recognition (NER) evaluation and word segmentation.", "token2charspan": [[0, 1], [1, 2], [2, 7], [8, 11], [12, 16], [17, 23], [24, 28], [29, 31], [32, 39], [40, 48], [49, 59], [60, 70], [70, 71], [72, 76], [77, 79], [80, 85], [86, 92], [93, 104], [105, 106], [106, 109], [109, 110], [111, 121], [122, 125], [126, 130], [131, 143], [143, 144]]}
{"doc_key": "ai-test-160", "ner": [[0, 0, "product"], [5, 6, "product"], [14, 15, "misc"], [19, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 14, 15, "related-to", "performs_task", false, false], [0, 0, 19, 20, "related-to", "performs_task", false, false], [5, 6, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "commonly", "used", "in", "dialogue", "systems", "for", "various", "purposes", "including", "customer", "service", ",", "request", "routing", ",", "or", "for", "information", "gathering", "."], "sentence-detokenized": "Chatbots are commonly used in dialogue systems for various purposes including customer service, request routing, or for information gathering.", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 26], [27, 29], [30, 38], [39, 46], [47, 50], [51, 58], [59, 67], [68, 77], [78, 86], [87, 94], [94, 95], [96, 103], [104, 111], [111, 112], [113, 115], [116, 119], [120, 131], [132, 141], [141, 142]]}
{"doc_key": "ai-test-161", "ner": [[3, 9, "conference"], [13, 21, "conference"], [27, 37, "conference"], [42, 42, "conference"], [46, 49, "conference"], [52, 53, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 21, 3, 9, "named", "", false, false], [27, 37, 3, 9, "named", "", false, false], [42, 42, 27, 37, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Notable", "journals", "include", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "later", "renamed", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "and", "since", "September", "2014", "renamed", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "after", "merging", "with", "ACM", "publications", ")", ",", "Computer", "Speech", "and", "Language", ",", "and", "Speech", "Communication", "."], "sentence-detokenized": "Notable journals include IEEE Transactions on Speech and Audio Processing (later renamed IEEE Transactions on Audio, Speech and Language Processing and since September 2014 renamed IEEE/ACM Transactions on Audio, Speech and Language Processing - after merging with ACM publications), Computer Speech and Language, and Speech Communication.", "token2charspan": [[0, 7], [8, 16], [17, 24], [25, 29], [30, 42], [43, 45], [46, 52], [53, 56], [57, 62], [63, 73], [74, 75], [75, 80], [81, 88], [89, 93], [94, 106], [107, 109], [110, 115], [115, 116], [117, 123], [124, 127], [128, 136], [137, 147], [148, 151], [152, 157], [158, 167], [168, 172], [173, 180], [181, 185], [185, 186], [186, 189], [190, 202], [203, 205], [206, 211], [211, 212], [213, 219], [220, 223], [224, 232], [233, 243], [244, 245], [246, 251], [252, 259], [260, 264], [265, 268], [269, 281], [281, 282], [282, 283], [284, 292], [293, 299], [300, 303], [304, 312], [312, 313], [314, 317], [318, 324], [325, 338], [338, 339]]}
{"doc_key": "ai-test-162", "ner": [[0, 1, "algorithm"], [5, 6, "task"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 0, 1, "usage", "", false, false], [5, 6, 8, 9, "part-of", "task_part_of_field", false, false], [5, 6, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "is", "often", "used", "for", "data", "clustering", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "EM is often used for data clustering in machine learning and computer vision.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 20], [21, 25], [26, 36], [37, 39], [40, 47], [48, 56], [57, 60], [61, 69], [70, 76], [76, 77]]}
{"doc_key": "ai-test-163", "ner": [[9, 10, "metrics"], [15, 26, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 15, 26, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["While", "there", "is", "no", "perfect", "way", "to", "describe", "the", "confusion", "matrix", "of", "positive", "and", "negative", "TRUEs", "and", "FALSEs", "with", "a", "single", "number", ",", "the", "Matthews", "correlation", "coefficient", "is", "generally", "considered", "to", "be", "one", "of", "the", "best", "measures", "."], "sentence-detokenized": "While there is no perfect way to describe the confusion matrix of positive and negative TRUEs and FALSEs with a single number, the Matthews correlation coefficient is generally considered to be one of the best measures.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 17], [18, 25], [26, 29], [30, 32], [33, 41], [42, 45], [46, 55], [56, 62], [63, 65], [66, 74], [75, 78], [79, 87], [88, 93], [94, 97], [98, 104], [105, 109], [110, 111], [112, 118], [119, 125], [125, 126], [127, 130], [131, 139], [140, 151], [152, 163], [164, 166], [167, 176], [177, 187], [188, 190], [191, 193], [194, 197], [198, 200], [201, 204], [205, 209], [210, 218], [218, 219]]}
{"doc_key": "ai-test-164", "ner": [[11, 13, "field"], [29, 30, "field"], [37, 38, "field"], [42, 43, "algorithm"], [45, 46, "task"], [48, 49, "algorithm"], [54, 56, "algorithm"], [58, 59, "algorithm"], [65, 67, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[37, 38, 29, 30, "part-of", "subfield", false, false], [42, 43, 37, 38, "part-of", "", false, true], [45, 46, 37, 38, "part-of", "", false, true], [48, 49, 37, 38, "part-of", "", false, true], [54, 56, 37, 38, "part-of", "", false, true], [58, 59, 37, 38, "part-of", "", false, true], [65, 67, 37, 38, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "data", "sets", "have", "grown", "in", "size", "and", "complexity", ",", "straightforward", "direct", "data", "analysis", "has", "been", "augmented", "by", "indirect", "and", "automated", "data", "processing", ",", "aided", "by", "other", "discoveries", "in", "computer", "science", ",", "particularly", "in", "the", "field", "of", "machine", "learning", ",", "such", "as", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "decision", "tree", "learning", "and", "decision", "rules", "(", "1960s", ")", ",", "and", "support", "vector", "machines", "(", "1990", "s", ")", "."], "sentence-detokenized": "As data sets have grown in size and complexity, straightforward direct data analysis has been augmented by indirect and automated data processing, aided by other discoveries in computer science, particularly in the field of machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision tree learning and decision rules (1960s), and support vector machines (1990s).", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 17], [18, 23], [24, 26], [27, 31], [32, 35], [36, 46], [46, 47], [48, 63], [64, 70], [71, 75], [76, 84], [85, 88], [89, 93], [94, 103], [104, 106], [107, 115], [116, 119], [120, 129], [130, 134], [135, 145], [145, 146], [147, 152], [153, 155], [156, 161], [162, 173], [174, 176], [177, 185], [186, 193], [193, 194], [195, 207], [208, 210], [211, 214], [215, 220], [221, 223], [224, 231], [232, 240], [240, 241], [242, 246], [247, 249], [250, 256], [257, 265], [265, 266], [267, 274], [275, 283], [283, 284], [285, 292], [293, 303], [304, 305], [305, 310], [310, 311], [311, 312], [313, 321], [322, 326], [327, 335], [336, 339], [340, 348], [349, 354], [355, 356], [356, 361], [361, 362], [362, 363], [364, 367], [368, 375], [376, 382], [383, 391], [392, 393], [393, 397], [397, 398], [398, 399], [399, 400]]}
{"doc_key": "ai-test-165", "ner": [[6, 6, "researcher"], [11, 12, "misc"], [21, 22, "researcher"], [24, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 6, 6, "artifact", "", false, false], [11, 12, 21, 22, "artifact", "", false, false], [11, 12, 24, 25, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "autumn", "of", "2005", ",", "Thrun", "published", "a", "textbook", "entitled", "Probabilistic", "Robotics", "together", "with", "his", "long", "-", "term", "colleagues", ",", "Dieter", "Fox", "and", "Wolfram", "Burgard", "."], "sentence-detokenized": "In the autumn of 2005, Thrun published a textbook entitled Probabilistic Robotics together with his long-term colleagues, Dieter Fox and Wolfram Burgard.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 21], [21, 22], [23, 28], [29, 38], [39, 40], [41, 49], [50, 58], [59, 72], [73, 81], [82, 90], [91, 95], [96, 99], [100, 104], [104, 105], [105, 109], [110, 120], [120, 121], [122, 128], [129, 132], [133, 136], [137, 144], [145, 152], [152, 153]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereiramath", "as", "follows", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereiramath as follows:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 49], [50, 52], [53, 60], [60, 61]]}
{"doc_key": "ai-test-167", "ner": [[0, 1, "task"], [3, 3, "task"], [7, 8, "field"], [14, 15, "field"], [17, 19, "field"], [21, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 17, 19, "part-of", "task_part_of_field", false, false], [3, 3, 0, 1, "named", "", false, false], [14, 15, 7, 8, "part-of", "subfield", false, false], [17, 19, 7, 8, "part-of", "subfield", false, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Question", "answering", "(", "QA", ")", "is", "a", "computer", "science", "discipline", "within", "the", "field", "of", "information", "retrieval", "and", "natural", "language", "processing", "(", "NLP", ")", ",", "which", "is", "concerned", "with", "building", "systems", "that", "automatically", "answer", "questions", "posed", "by", "humans", "in", "natural", "language", "."], "sentence-detokenized": "Question answering (QA) is a computer science discipline within the field of information retrieval and natural language processing (NLP), which is concerned with building systems that automatically answer questions posed by humans in natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 37], [38, 45], [46, 56], [57, 63], [64, 67], [68, 73], [74, 76], [77, 88], [89, 98], [99, 102], [103, 110], [111, 119], [120, 130], [131, 132], [132, 135], [135, 136], [136, 137], [138, 143], [144, 146], [147, 156], [157, 161], [162, 170], [171, 178], [179, 183], [184, 197], [198, 204], [205, 214], [215, 220], [221, 223], [224, 230], [231, 233], [234, 241], [242, 250], [250, 251]]}
{"doc_key": "ai-test-168", "ner": [[9, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "in", "versions", "of", "the", "metric", "used", "by", "NIST", "evaluations", "before", "2009", ",", "the", "shortest", "reference", "sentence", "has", "been", "used", "instead", "."], "sentence-detokenized": "However, in versions of the metric used by NIST evaluations before 2009, the shortest reference sentence has been used instead.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 20], [21, 23], [24, 27], [28, 34], [35, 39], [40, 42], [43, 47], [48, 59], [60, 66], [67, 71], [71, 72], [73, 76], [77, 85], [86, 95], [96, 104], [105, 108], [109, 113], [114, 118], [119, 126], [126, 127]]}
{"doc_key": "ai-test-169", "ner": [[5, 5, "person"], [13, 14, "organisation"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 15, 15, "related-to", "invests_in", false, false], [15, 15, 13, 14, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["On", "27", "August", "2018", ",", "Toyota", "announced", "a", "$", "500", "Million", "investment", "in", "Uber", "'s", "autonomous", "cars", "."], "sentence-detokenized": "On 27 August 2018, Toyota announced a $500 Million investment in Uber's autonomous cars.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 17], [17, 18], [19, 25], [26, 35], [36, 37], [38, 39], [39, 42], [43, 50], [51, 61], [62, 64], [65, 69], [69, 71], [72, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-test-170", "ner": [[6, 20, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sample", "maximum", "is", "the", "maximum", "likelihood", "estimator", "for", "the", "population", "maximum", ",", "but", ",", "as", "discussed", "above", ",", "this", "estimator", "is", "biased", "."], "sentence-detokenized": "The sample maximum is the maximum likelihood estimator for the population maximum, but, as discussed above, this estimator is biased.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 25], [26, 33], [34, 44], [45, 54], [55, 58], [59, 62], [63, 73], [74, 81], [81, 82], [83, 86], [86, 87], [88, 90], [91, 100], [101, 106], [106, 107], [108, 112], [113, 122], [123, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [3, 3, "misc"], [6, 6, "metrics"], [15, 17, "algorithm"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 3, "related-to", "overcomes", false, false], [0, 0, 6, 6, "related-to", "increases", false, false], [3, 3, 15, 17, "opposite", "", false, false], [3, 3, 19, 21, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "helps", "overcome", "synonymy", "by", "improving", "recall", ",", "one", "of", "the", "most", "problematic", "constraints", "of", "Boolean", "keyword", "queries", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI helps overcome synonymy by improving recall, one of the most problematic constraints of Boolean keyword queries and vector space models.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 27], [28, 30], [31, 40], [41, 47], [47, 48], [49, 52], [53, 55], [56, 59], [60, 64], [65, 76], [77, 88], [89, 91], [92, 99], [100, 107], [108, 115], [116, 119], [120, 126], [127, 132], [133, 139], [139, 140]]}
{"doc_key": "ai-test-172", "ner": [[0, 1, "task"], [21, 21, "programlang"], [23, 23, "programlang"], [25, 25, "programlang"], [27, 28, "programlang"], [30, 30, "programlang"], [32, 32, "programlang"], [34, 34, "programlang"], [36, 36, "programlang"], [38, 38, "programlang"], [40, 40, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 21, 21, "general-affiliation", "", false, false], [0, 1, 23, 23, "general-affiliation", "", false, false], [0, 1, 25, 25, "general-affiliation", "", false, false], [0, 1, 27, 28, "general-affiliation", "", false, false], [0, 1, 30, 30, "general-affiliation", "", false, false], [0, 1, 32, 32, "general-affiliation", "", false, false], [0, 1, 34, 34, "general-affiliation", "", false, false], [0, 1, 36, 36, "general-affiliation", "", false, false], [0, 1, 38, 38, "general-affiliation", "", false, false], [0, 1, 40, 40, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Data", "acquisition", "applications", "are", "usually", "controlled", "by", "software", "programmes", "developed", "using", "a", "variety", "of", "general", "-", "purpose", "programming", "languages", "such", "as", "Assembly", ",", "BASIC", ",", "C", ",", "C", "++", ",", "C#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "Data acquisition applications are usually controlled by software programmes developed using a variety of general-purpose programming languages such as Assembly, BASIC, C, C++, C#, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 4], [5, 16], [17, 29], [30, 33], [34, 41], [42, 52], [53, 55], [56, 64], [65, 75], [76, 85], [86, 91], [92, 93], [94, 101], [102, 104], [105, 112], [112, 113], [113, 120], [121, 132], [133, 142], [143, 147], [148, 150], [151, 159], [159, 160], [161, 166], [166, 167], [168, 169], [169, 170], [171, 172], [172, 174], [174, 175], [176, 178], [178, 179], [180, 187], [187, 188], [189, 193], [193, 194], [195, 202], [202, 203], [204, 208], [208, 209], [210, 216], [216, 217], [218, 222]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [6, 6, "product"], [10, 10, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 3, 3, "artifact", "", false, false], [6, 6, 10, 10, "physical", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2003", ",", "Honda", "released", "the", "Cog", "advert", "in", "the", "UK", "and", "on", "the", "Internet", "."], "sentence-detokenized": "In 2003, Honda released the Cog advert in the UK and on the Internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 27], [28, 31], [32, 38], [39, 41], [42, 45], [46, 48], [49, 52], [53, 55], [56, 59], [60, 68], [68, 69]]}
{"doc_key": "ai-test-174", "ner": [[0, 4, "conference"], [6, 7, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 6, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Association", "for", "Computational", "Linguistics", "defines", "computational", "linguistics", "as", ":"], "sentence-detokenized": "The Association for Computational Linguistics defines computational linguistics as:", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 45], [46, 53], [54, 67], [68, 79], [80, 82], [82, 83]]}
{"doc_key": "ai-test-175", "ner": [[0, 3, "algorithm"], [11, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 11, 13, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "expectation", "-maximisation", "algorithm", "can", "be", "used", "to", "calculate", "an", "approximate", "maximum", "likelihood", "estimate", "of", "the", "unknown", "state", "space", "parameters", "in", "minimum", "variance", "filters", "and", "smoothing", "."], "sentence-detokenized": "The expectation-maximisation algorithm can be used to calculate an approximate maximum likelihood estimate of the unknown state space parameters in minimum variance filters and smoothing.", "token2charspan": [[0, 3], [4, 15], [15, 28], [29, 38], [39, 42], [43, 45], [46, 50], [51, 53], [54, 63], [64, 66], [67, 78], [79, 86], [87, 97], [98, 106], [107, 109], [110, 113], [114, 121], [122, 127], [128, 133], [134, 144], [145, 147], [148, 155], [156, 164], [165, 172], [173, 176], [177, 186], [186, 187]]}
{"doc_key": "ai-test-176", "ner": [[3, 3, "misc"], [5, 7, "person"], [9, 10, "person"], [13, 14, "person"], [17, 18, "misc"], [19, 20, "person"], [23, 24, "person"], [28, 28, "person"], [30, 31, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 7, 3, 3, "role", "actor_in", false, false], [9, 10, 3, 3, "role", "actor_in", false, false], [13, 14, 3, 3, "role", "actor_in", false, false], [19, 20, 17, 18, "role", "model_for", false, false], [28, 28, 30, 31, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Correspondents", "include", "former", "Baywatch", "actresses", "Donna", "D'", "Errico", ",", "Carmen", "Electra", ",", "and", "Traci", "Bingham", ",", "former", "Playboy", "Playmate", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", "and", "identical", "twins", "Randy", "and", "Jason", "Sklar", "."], "sentence-detokenized": "Correspondents include former Baywatch actresses Donna D'Errico, Carmen Electra, and Traci Bingham, former Playboy Playmate Heidi Mark, comedian Arj Barker and identical twins Randy and Jason Sklar.", "token2charspan": [[0, 14], [15, 22], [23, 29], [30, 38], [39, 48], [49, 54], [55, 57], [57, 63], [63, 64], [65, 71], [72, 79], [79, 80], [81, 84], [85, 90], [91, 98], [98, 99], [100, 106], [107, 114], [115, 123], [124, 129], [130, 134], [134, 135], [136, 144], [145, 148], [149, 155], [156, 159], [160, 169], [170, 175], [176, 181], [182, 185], [186, 191], [192, 197], [197, 198]]}
{"doc_key": "ai-test-177", "ner": [[9, 9, "task"], [11, 11, "task"], [15, 17, "product"], [8, 21, "task"], [23, 23, "task"], [27, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 9, 9, "named", "", false, false], [15, 17, 9, 9, "general-affiliation", "", false, false], [23, 23, 8, 21, "named", "", false, false], [27, 28, 8, 21, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "is", "commonly", "used", "to", "generate", "representations", "for", "speech", "recognition", "(", "ASR", ")", ",", "e.g.", "CMU", "Sphinx", "system", ",", "and", "speech", "synthesis", "(", "TTS", ")", ",", "e.g.", "Festival", "system", "."], "sentence-detokenized": "It is commonly used to generate representations for speech recognition (ASR), e.g. CMU Sphinx system, and speech synthesis (TTS), e.g. Festival system.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 19], [20, 22], [23, 31], [32, 47], [48, 51], [52, 58], [59, 70], [71, 72], [72, 75], [75, 76], [76, 77], [78, 82], [83, 86], [87, 93], [94, 100], [100, 101], [102, 105], [106, 112], [113, 122], [123, 124], [124, 127], [127, 128], [128, 129], [130, 134], [135, 143], [144, 150], [150, 151]]}
{"doc_key": "ai-test-178", "ner": [[0, 0, "metrics"], [2, 4, "metrics"], [6, 6, "metrics"], [12, 12, "metrics"], [26, 27, "metrics"], [29, 29, "metrics"], [40, 41, "metrics"], [43, 43, "metrics"], [45, 47, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 4, 0, 0, "named", "", false, false], [6, 6, 2, 4, "named", "", false, false], [12, 12, 0, 0, "named", "", false, false], [29, 29, 26, 27, "named", "", false, false], [43, 43, 40, 41, "named", "", false, false], [45, 47, 40, 41, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sensitivity", "or", "TRUE", "Positive", "Rate", "(", "TPR", ")", ",", "also", "known", "as", "recall", ",", "is", "the", "proportion", "of", "people", "who", "test", "positive", "and", "are", "positive", "(", "TRUE", "Positive", ",", "TP", ")", "out", "of", "all", "people", "who", "are", "truly", "positive", "(", "Condition", "Positive", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "Sensitivity or TRUE Positive Rate (TPR), also known as recall, is the proportion of people who test positive and are positive (TRUE Positive, TP) out of all people who are truly positive (Condition Positive, CP = TP + FN).", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 28], [29, 33], [34, 35], [35, 38], [38, 39], [39, 40], [41, 45], [46, 51], [52, 54], [55, 61], [61, 62], [63, 65], [66, 69], [70, 80], [81, 83], [84, 90], [91, 94], [95, 99], [100, 108], [109, 112], [113, 116], [117, 125], [126, 127], [127, 131], [132, 140], [140, 141], [142, 144], [144, 145], [146, 149], [150, 152], [153, 156], [157, 163], [164, 167], [168, 171], [172, 177], [178, 186], [187, 188], [188, 197], [198, 206], [206, 207], [208, 210], [211, 212], [213, 215], [216, 217], [218, 220], [220, 221], [221, 222]]}
{"doc_key": "ai-test-179", "ner": [[1, 2, "task"], [9, 9, "conference"], [11, 12, "conference"], [14, 14, "conference"], [16, 18, "conference"], [21, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6], "relations": [[9, 9, 1, 2, "topic", "", false, false], [11, 12, 1, 2, "topic", "", false, false], [14, 14, 1, 2, "topic", "", false, false], [16, 18, 1, 2, "topic", "", false, false], [21, 22, 1, 2, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5], "sentence": ["Popular", "speech", "recognition", "conferences", "held", "annually", "or", "biannually", "include", "SpeechTEK", "and", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", ",", "and", "IEEE", "ASRU", "."], "sentence-detokenized": "Popular speech recognition conferences held annually or biannually include SpeechTEK and SpeechTEK Europe, ICASSP, Interspeech/Eurospeech, and IEEE ASRU.", "token2charspan": [[0, 7], [8, 14], [15, 26], [27, 38], [39, 43], [44, 52], [53, 55], [56, 66], [67, 74], [75, 84], [85, 88], [89, 98], [99, 105], [105, 106], [107, 113], [113, 114], [115, 126], [126, 127], [127, 137], [137, 138], [139, 142], [143, 147], [148, 152], [152, 153]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [3, 3, "researcher"], [17, 18, "product"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 0, 0, "artifact", "", false, false], [21, 21, 3, 3, "artifact", "", false, false], [21, 21, 17, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "collaborated", "with", "Engelberger", ",", "who", "served", "as", "the", "company", "'s", "president", ",", "to", "engineer", "and", "manufacture", "industrial", "robots", "under", "the", "Unimate", "brand", "name", "."], "sentence-detokenized": "Devol collaborated with Engelberger, who served as the company's president, to engineer and manufacture industrial robots under the Unimate brand name.", "token2charspan": [[0, 5], [6, 18], [19, 23], [24, 35], [35, 36], [37, 40], [41, 47], [48, 50], [51, 54], [55, 62], [62, 64], [65, 74], [74, 75], [76, 78], [79, 87], [88, 91], [92, 103], [104, 114], [115, 121], [122, 127], [128, 131], [132, 139], [140, 145], [146, 150], [150, 151]]}
{"doc_key": "ai-test-181", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [9, 11, "algorithm"], [23, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 9, 11, "general-affiliation", "", false, false], [5, 5, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "Hidden", "Markov", "Model", "(", "HMM", ")", "is", "a", "statistical", "Markov", "model", "in", "which", "the", "system", "being", "modelled", "is", "assumed", "to", "be", "a", "Markov", "process", "with", "an", "unobserved", "(", "hidden", ")", "state", "."], "sentence-detokenized": "A Hidden Markov Model (HMM) is a statistical Markov model in which the system being modelled is assumed to be a Markov process with an unobserved (hidden) state.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [22, 23], [23, 26], [26, 27], [28, 30], [31, 32], [33, 44], [45, 51], [52, 57], [58, 60], [61, 66], [67, 70], [71, 77], [78, 83], [84, 92], [93, 95], [96, 103], [104, 106], [107, 109], [110, 111], [112, 118], [119, 126], [127, 131], [132, 134], [135, 145], [146, 147], [147, 153], [153, 154], [155, 160], [160, 161]]}
{"doc_key": "ai-test-182", "ner": [[18, 20, "metrics"], [27, 27, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "property", ",", "which", "is", "undesirable", "in", "many", "applications", ",", "has", "led", "researchers", "to", "use", "alternatives", "such", "as", "mean", "absolute", "error", ",", "or", "those", "based", "on", "the", "median", "."], "sentence-detokenized": "This property, which is undesirable in many applications, has led researchers to use alternatives such as mean absolute error, or those based on the median.", "token2charspan": [[0, 4], [5, 13], [13, 14], [15, 20], [21, 23], [24, 35], [36, 38], [39, 43], [44, 56], [56, 57], [58, 61], [62, 65], [66, 77], [78, 80], [81, 84], [85, 97], [98, 102], [103, 105], [106, 110], [111, 119], [120, 125], [125, 126], [127, 129], [130, 135], [136, 141], [142, 144], [145, 148], [149, 155], [155, 156]]}
{"doc_key": "ai-test-183", "ner": [[20, 21, "algorithm"], [29, 30, "field"], [33, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 21, 29, 30, "part-of", "", false, false], [20, 21, 33, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Such", "a", "sequence", "(", "which", "depends", "on", "the", "results", "of", "previous", "attribute", "investigations", "at", "each", "stage", ")", "is", "called", "a", "decision", "tree", "and", "is", "applied", "in", "the", "field", "of", "machine", "learning", "known", "as", "decision", "tree", "learning", "."], "sentence-detokenized": "Such a sequence (which depends on the results of previous attribute investigations at each stage) is called a decision tree and is applied in the field of machine learning known as decision tree learning.", "token2charspan": [[0, 4], [5, 6], [7, 15], [16, 17], [17, 22], [23, 30], [31, 33], [34, 37], [38, 45], [46, 48], [49, 57], [58, 67], [68, 82], [83, 85], [86, 90], [91, 96], [96, 97], [98, 100], [101, 107], [108, 109], [110, 118], [119, 123], [124, 127], [128, 130], [131, 138], [139, 141], [142, 145], [146, 151], [152, 154], [155, 162], [163, 171], [172, 177], [178, 180], [181, 189], [190, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-test-184", "ner": [[2, 3, "task"], [5, 5, "algorithm"], [15, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 5, 5, "compare", "", false, false], [15, 19, 5, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "in", "factor", "analysis", ",", "LCA", "can", "also", "be", "used", "to", "classify", "cases", "according", "to", "their", "maximum", "likelihood", "class", "membership", "."], "sentence-detokenized": "As in factor analysis, LCA can also be used to classify cases according to their maximum likelihood class membership.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 21], [21, 22], [23, 26], [27, 30], [31, 35], [36, 38], [39, 43], [44, 46], [47, 55], [56, 61], [62, 71], [72, 74], [75, 80], [81, 88], [89, 99], [100, 105], [106, 116], [116, 117]]}
{"doc_key": "ai-test-185", "ner": [[0, 2, "algorithm"], [6, 8, "metrics"], [10, 10, "metrics"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 6, 8, "usage", "", false, false], [6, 8, 12, 13, "related-to", "", false, false], [10, 10, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Supervised", "neural", "networks", "that", "use", "the", "mean", "squared", "error", "(", "MSE", ")", "cost", "function", "can", "use", "formal", "statistical", "methods", "to", "determine", "the", "confidence", "of", "the", "trained", "model", "."], "sentence-detokenized": "Supervised neural networks that use the mean squared error (MSE) cost function can use formal statistical methods to determine the confidence of the trained model.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 35], [36, 39], [40, 44], [45, 52], [53, 58], [59, 60], [60, 63], [63, 64], [65, 69], [70, 78], [79, 82], [83, 86], [87, 93], [94, 105], [106, 113], [114, 116], [117, 126], [127, 130], [131, 141], [142, 144], [145, 148], [149, 156], [157, 162], [162, 163]]}
{"doc_key": "ai-test-186", "ner": [[15, 16, "algorithm"], [19, 21, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 19, 21, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "directly", "expressed", "as", "a", "linear", "program", ",", "but", "is", "also", "equivalent", "to", "Tikhonov", "regularization", "with", "a", "hinge", "loss", "function", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=\\", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "This can be directly expressed as a linear program, but is also equivalent to Tikhonov regularization with a hinge loss function, mathV(f(x), y) =\\ max(0, 1 - yf(x)) / math:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 20], [21, 30], [31, 33], [34, 35], [36, 42], [43, 50], [50, 51], [52, 55], [56, 58], [59, 63], [64, 74], [75, 77], [78, 86], [87, 101], [102, 106], [107, 108], [109, 114], [115, 119], [120, 128], [128, 129], [130, 135], [135, 136], [136, 137], [137, 138], [138, 139], [139, 140], [140, 141], [142, 143], [143, 144], [145, 147], [148, 151], [151, 152], [152, 153], [153, 154], [155, 156], [157, 158], [159, 161], [161, 162], [162, 163], [163, 164], [164, 165], [166, 167], [168, 172], [172, 173]]}
{"doc_key": "ai-test-187", "ner": [[6, 7, "researcher"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "technique", "is", "described", "in", "Breiman", "'s", "original", "paper", "and", "implemented", "in", "the", "R", "package", "randomForest", "."], "sentence-detokenized": "The following technique is described in Breiman's original paper and implemented in the R package randomForest.", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 26], [27, 36], [37, 39], [40, 47], [47, 49], [50, 58], [59, 64], [65, 68], [69, 80], [81, 83], [84, 87], [88, 89], [90, 97], [98, 110], [110, 111]]}
{"doc_key": "ai-test-188", "ner": [[7, 7, "metrics"], [40, 40, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "image", "quality", "measures", ",", "such", "as", "PSNR", ",", "are", "usually", "performed", "on", "images", "with", "a", "fixed", "resolution", "and", "do", "not", "take", "into", "account", "some", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "changes", "in", "spatial", "resolution", "across", "the", "retina", "."], "sentence-detokenized": "Traditional image quality measures, such as PSNR, are usually performed on images with a fixed resolution and do not take into account some aspects of the human visual system, such as changes in spatial resolution across the retina.", "token2charspan": [[0, 11], [12, 17], [18, 25], [26, 34], [34, 35], [36, 40], [41, 43], [44, 48], [48, 49], [50, 53], [54, 61], [62, 71], [72, 74], [75, 81], [82, 86], [87, 88], [89, 94], [95, 105], [106, 109], [110, 112], [113, 116], [117, 121], [122, 126], [127, 134], [135, 139], [140, 147], [148, 150], [151, 154], [155, 160], [161, 167], [168, 174], [174, 175], [176, 180], [181, 183], [184, 191], [192, 194], [195, 202], [203, 213], [214, 220], [221, 224], [225, 231], [231, 232]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [10, 12, "person"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 15, 16, "role", "", false, false], [3, 4, 15, 16, "role", "", false, false], [6, 7, 15, 16, "role", "", false, false], [15, 16, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "and", "Macdonald", "Carey", "starred", "in", "Jack", "Broder", "'s", "colourful", "production", "Hannah", "Lee", ",", "which", "premiered", "on", "19", "June", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru and Macdonald Carey starred in Jack Broder's colourful production Hannah Lee, which premiered on 19 June 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 55], [56, 60], [61, 67], [67, 69], [70, 79], [80, 90], [91, 97], [98, 101], [101, 102], [103, 108], [109, 118], [119, 121], [122, 124], [125, 129], [130, 134], [134, 135]]}
{"doc_key": "ai-test-190", "ner": [[4, 5, "task"], [10, 11, "field"], [17, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 10, 11, "usage", "", false, false], [17, 17, 10, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "process", "is", "called", "image", "registration", ",", "and", "utilises", "different", "computer", "vision", "methods", ",", "mostly", "related", "to", "tracking", "."], "sentence-detokenized": "The process is called image registration, and utilises different computer vision methods, mostly related to tracking.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 21], [22, 27], [28, 40], [40, 41], [42, 45], [46, 54], [55, 64], [65, 73], [74, 80], [81, 88], [88, 89], [90, 96], [97, 104], [105, 107], [108, 116], [116, 117]]}
{"doc_key": "ai-test-191", "ner": [[16, 17, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Now", "let", "'s", "start", "explaining", "the", "different", "possible", "relationships", "between", "the", "predicted", "and", "actual", "results", ":", "Confusion", "matrix"], "sentence-detokenized": "Now let's start explaining the different possible relationships between the predicted and actual results: Confusion matrix", "token2charspan": [[0, 3], [4, 7], [7, 9], [10, 15], [16, 26], [27, 30], [31, 40], [41, 49], [50, 63], [64, 71], [72, 75], [76, 85], [86, 89], [90, 96], [97, 104], [104, 105], [106, 115], [116, 122]]}
{"doc_key": "ai-test-192", "ner": [[0, 0, "product"], [1, 3, "misc"], [5, 5, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 1, 3, "part-of", "", false, false], [0, 0, 1, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["VOICEBOX", "speech", "processing", "toolbox", "for", "MATLAB", "implements", "both", "conversion", "and", "inverse", ":"], "sentence-detokenized": "VOICEBOX speech processing toolbox for MATLAB implements both conversion and inverse:", "token2charspan": [[0, 8], [9, 15], [16, 26], [27, 34], [35, 38], [39, 45], [46, 56], [57, 61], [62, 72], [73, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "general-affiliation", "", false, false], [0, 0, 11, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logic", "programming", "language", "related", "to", "artificial", "intelligence", "and", "computational", "linguistics", "."], "sentence-detokenized": "Prolog is a logic programming language related to artificial intelligence and computational linguistics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 17], [18, 29], [30, 38], [39, 46], [47, 49], [50, 60], [61, 73], [74, 77], [78, 91], [92, 103], [103, 104]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [9, 9, "field"], [11, 11, "field"], [17, 20, "organisation"], [23, 26, "organisation"], [29, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 9, 9, "related-to", "works_with_topic", false, false], [0, 0, 11, 11, "related-to", "works_with_topic", false, false], [0, 0, 17, 20, "role", "", false, false], [0, 0, 23, 26, "role", "", false, false], [0, 0, 29, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "numerous", "awards", "for", "his", "contributions", "to", "neuroscience", "and", "psychology", ",", "including", "membership", "in", "the", "Royal", "Society", "of", "London", ",", "the", "Royal", "Society", "of", "Canada", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received numerous awards for his contributions to neuroscience and psychology, including membership in the Royal Society of London, the Royal Society of Canada and the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 35], [36, 39], [40, 43], [44, 57], [58, 60], [61, 73], [74, 77], [78, 88], [88, 89], [90, 99], [100, 110], [111, 113], [114, 117], [118, 123], [124, 131], [132, 134], [135, 141], [141, 142], [143, 146], [147, 152], [153, 160], [161, 163], [164, 170], [171, 174], [175, 178], [179, 187], [188, 195], [196, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-195", "ner": [[11, 12, "field"], [17, 18, "task"], [21, 21, "task"], [24, 26, "task"], [27, 27, "task"], [30, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 18, 11, 12, "part-of", "task_part_of_field", false, false], [21, 21, 11, 12, "part-of", "task_part_of_field", false, false], [24, 26, 11, 12, "part-of", "task_part_of_field", false, false], [27, 27, 11, 12, "part-of", "task_part_of_field", false, false], [30, 30, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["By", "combining", "these", "operators", ",", "one", "can", "obtain", "algorithms", "for", "many", "image", "processing", "tasks", ",", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "sharpening", ",", "image", "filtering", ",", "and", "classification", "."], "sentence-detokenized": "By combining these operators, one can obtain algorithms for many image processing tasks, such as feature extraction, image segmentation, image sharpening, image filtering, and classification.", "token2charspan": [[0, 2], [3, 12], [13, 18], [19, 28], [28, 29], [30, 33], [34, 37], [38, 44], [45, 55], [56, 59], [60, 64], [65, 70], [71, 81], [82, 87], [87, 88], [89, 93], [94, 96], [97, 104], [105, 115], [115, 116], [117, 122], [123, 135], [135, 136], [137, 142], [143, 153], [153, 154], [155, 160], [161, 170], [170, 171], [172, 175], [176, 190], [190, 191]]}
{"doc_key": "ai-test-196", "ner": [[9, 11, "university"], [19, 21, "organisation"], [23, 24, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "of", "2017", ",", "he", "is", "a", "professor", "at", "Coll\u00e8ge", "de", "France", "and", ",", "since", "1989", ",", "director", "of", "INSERM", "Unit", "562", ",", "Cognitive", "Neuroimaging", "."], "sentence-detokenized": "As of 2017, he is a professor at Coll\u00e8ge de France and, since 1989, director of INSERM Unit 562, Cognitive Neuroimaging.", "token2charspan": [[0, 2], [3, 5], [6, 10], [10, 11], [12, 14], [15, 17], [18, 19], [20, 29], [30, 32], [33, 40], [41, 43], [44, 50], [51, 54], [54, 55], [56, 61], [62, 66], [66, 67], [68, 76], [77, 79], [80, 86], [87, 91], [92, 95], [95, 96], [97, 106], [107, 119], [119, 120]]}
{"doc_key": "ai-test-197", "ner": [[11, 13, "algorithm"], [15, 18, "algorithm"], [24, 24, "algorithm"], [26, 31, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[24, 24, 26, 31, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "many", "approaches", "to", "study", "these", "embeddings", ",", "mainly", "using", "Bayesian", "clustering", "frameworks", "or", "energy", "-", "based", "frameworks", ",", "and", "more", "recently", ",", "TransE", "(", "Neural", "Information", "Processing", "Systems", "Conference", "2013", ")", "."], "sentence-detokenized": "There are many approaches to study these embeddings, mainly using Bayesian clustering frameworks or energy-based frameworks, and more recently, TransE (Neural Information Processing Systems Conference 2013).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 25], [26, 28], [29, 34], [35, 40], [41, 51], [51, 52], [53, 59], [60, 65], [66, 74], [75, 85], [86, 96], [97, 99], [100, 106], [106, 107], [107, 112], [113, 123], [123, 124], [125, 128], [129, 133], [134, 142], [142, 143], [144, 150], [151, 152], [152, 158], [159, 170], [171, 181], [182, 189], [190, 200], [201, 205], [205, 206], [206, 207]]}
{"doc_key": "ai-test-198", "ner": [[6, 8, "metrics"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "an", "alternative", "to", "the", "Word", "Error", "Rate", "used", "in", "some", "countries", "."], "sentence-detokenized": "It is an alternative to the Word Error Rate used in some countries.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 23], [24, 27], [28, 32], [33, 38], [39, 43], [44, 48], [49, 51], [52, 56], [57, 66], [66, 67]]}
{"doc_key": "ai-test-199", "ner": [[0, 0, "algorithm"], [11, 12, "task"], [14, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 28, "task"], [30, 31, "task"], [47, 47, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 0, 0, "usage", "", false, false], [14, 15, 0, 0, "usage", "", false, false], [17, 18, 0, 0, "usage", "", false, false], [20, 22, 0, 0, "usage", "", false, false], [24, 28, 0, 0, "usage", "", false, false], [30, 31, 0, 0, "usage", "", false, false], [47, 47, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "have", "been", "used", "in", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "board", "and", "video", "game", "playing", ",", "medical", "diagnosis", ",", "and", "even", "in", "activities", "traditionally", "thought", "to", "be", "reserved", "for", "humans", ",", "such", "as", "painting", "."], "sentence-detokenized": "ANNs have been used in a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, board and video game playing, medical diagnosis, and even in activities traditionally thought to be reserved for humans, such as painting.", "token2charspan": [[0, 4], [5, 9], [10, 14], [15, 19], [20, 22], [23, 24], [25, 32], [33, 35], [36, 41], [41, 42], [43, 52], [53, 61], [62, 68], [68, 69], [70, 76], [77, 88], [88, 89], [90, 97], [98, 109], [109, 110], [111, 117], [118, 125], [126, 135], [135, 136], [137, 142], [143, 146], [147, 152], [153, 157], [158, 165], [165, 166], [167, 174], [175, 184], [184, 185], [186, 189], [190, 194], [195, 197], [198, 208], [209, 222], [223, 230], [231, 233], [234, 236], [237, 245], [246, 249], [250, 256], [256, 257], [258, 262], [263, 265], [266, 274], [274, 275]]}
{"doc_key": "ai-test-200", "ner": [[0, 3, "product"], [5, 5, "product"], [26, 28, "field"], [30, 30, "field"], [35, 35, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 26, 28, "related-to", "", false, false], [0, 3, 35, 35, "general-affiliation", "", false, false], [5, 5, 0, 3, "named", "", false, false], [30, 30, 26, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "is", "an", "open", "-", "source", "research", "platform", "and", "collection", "of", "voice", ",", "sound", ",", "speech", ",", "text", ",", "and", "natural", "language", "processing", "(", "NLP", ")", "algorithms", "written", "in", "Java", "and", "structured", "into", "a", "modular", "and", "extensible", "framework", "that", "attempts", "to", "facilitate", "the", "addition", "of", "new", "algorithms", "."], "sentence-detokenized": "Modular Audio Recognition Framework (MARF) is an open-source research platform and collection of voice, sound, speech, text, and natural language processing (NLP) algorithms written in Java and structured into a modular and extensible framework that attempts to facilitate the addition of new algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 25], [26, 35], [36, 37], [37, 41], [41, 42], [43, 45], [46, 48], [49, 53], [53, 54], [54, 60], [61, 69], [70, 78], [79, 82], [83, 93], [94, 96], [97, 102], [102, 103], [104, 109], [109, 110], [111, 117], [117, 118], [119, 123], [123, 124], [125, 128], [129, 136], [137, 145], [146, 156], [157, 158], [158, 161], [161, 162], [163, 173], [174, 181], [182, 184], [185, 189], [190, 193], [194, 204], [205, 209], [210, 211], [212, 219], [220, 223], [224, 234], [235, 244], [245, 249], [250, 258], [259, 261], [262, 272], [273, 276], [277, 285], [286, 288], [289, 292], [293, 303], [303, 304]]}
{"doc_key": "ai-test-201", "ner": [[13, 15, "organisation"], [19, 19, "country"], [23, 25, "organisation"], [28, 29, "organisation"], [34, 35, "task"], [48, 51, "organisation"], [54, 55, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[23, 25, 19, 19, "physical", "", false, false], [23, 25, 34, 35, "usage", "", false, false], [23, 25, 48, 51, "named", "", false, false], [28, 29, 19, 19, "physical", "", false, false], [28, 29, 34, 35, "usage", "", false, false], [48, 51, 54, 55, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "a", "report", "by", "civil", "liberties", "and", "human", "rights", "campaign", "organisation", "Big", "Brother", "Watch", "revealed", "that", "two", "UK", "police", "forces", ",", "South", "Wales", "Police", "and", "the", "Metropolitan", "Police", ",", "were", "using", "live", "facial", "recognition", "at", "public", "events", "and", "in", "public", "spaces", ",", "in", "September", "2019", ",", "South", "Wales", "Police", "'s", "use", "of", "facial", "recognition", "was", "ruled", "lawful", "."], "sentence-detokenized": "In 2018, a report by civil liberties and human rights campaign organisation Big Brother Watch revealed that two UK police forces, South Wales Police and the Metropolitan Police, were using live facial recognition at public events and in public spaces, in September 2019, South Wales Police's use of facial recognition was ruled lawful.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 20], [21, 26], [27, 36], [37, 40], [41, 46], [47, 53], [54, 62], [63, 75], [76, 79], [80, 87], [88, 93], [94, 102], [103, 107], [108, 111], [112, 114], [115, 121], [122, 128], [128, 129], [130, 135], [136, 141], [142, 148], [149, 152], [153, 156], [157, 169], [170, 176], [176, 177], [178, 182], [183, 188], [189, 193], [194, 200], [201, 212], [213, 215], [216, 222], [223, 229], [230, 233], [234, 236], [237, 243], [244, 250], [250, 251], [252, 254], [255, 264], [265, 269], [269, 270], [271, 276], [277, 282], [283, 289], [289, 291], [292, 295], [296, 298], [299, 305], [306, 317], [318, 321], [322, 327], [328, 334], [334, 335]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [5, 5, "programlang"], [14, 15, "field"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 5, "general-affiliation", "", false, false], [0, 0, 14, 15, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "has", "been", "ported", "to", "R", ",", "a", "freely", "available", "language", "and", "environment", "for", "statistical", "computing", "and", "graphics", "."], "sentence-detokenized": "ANIMAL has been ported to R, a freely available language and environment for statistical computing and graphics.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [23, 25], [26, 27], [27, 28], [29, 30], [31, 37], [38, 47], [48, 56], [57, 60], [61, 72], [73, 76], [77, 88], [89, 98], [99, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-test-203", "ner": [[0, 5, "algorithm"], [7, 9, "algorithm"], [15, 17, "algorithm"], [19, 19, "algorithm"], [22, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 15, 17, "opposite", "alternative to", false, false], [7, 9, 0, 5, "named", "", false, false], [19, 19, 15, 17, "named", "", false, false], [22, 24, 0, 5, "usage", "", false, false], [22, 24, 15, 17, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Time", "-", "inhomogeneous", "hidden", "Bernoulli", "model", "(", "TI", "-", "HBM", ")", "is", "an", "alternative", "to", "hidden", "Markov", "model", "(", "HMM", ")", "for", "automatic", "speech", "recognition", "."], "sentence-detokenized": "Time-inhomogeneous hidden Bernoulli model (TI-HBM) is an alternative to hidden Markov model (HMM) for automatic speech recognition.", "token2charspan": [[0, 4], [4, 5], [5, 18], [19, 25], [26, 35], [36, 41], [42, 43], [43, 45], [45, 46], [46, 49], [49, 50], [51, 53], [54, 56], [57, 68], [69, 71], [72, 78], [79, 85], [86, 91], [92, 93], [93, 96], [96, 97], [98, 101], [102, 111], [112, 118], [119, 130], [130, 131]]}
{"doc_key": "ai-test-204", "ner": [[4, 4, "organisation"], [7, 8, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 7, 8, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "Nvidia", "demonstrated", "during", "SIGGRAPH", "a", "new", "method", "of", "foveated", "rendering", "that", "is", "claimed", "to", "be", "invisible", "to", "users", "."], "sentence-detokenized": "In July 2016, Nvidia demonstrated during SIGGRAPH a new method of foveated rendering that is claimed to be invisible to users.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 33], [34, 40], [41, 49], [50, 51], [52, 55], [56, 62], [63, 65], [66, 74], [75, 84], [85, 89], [90, 92], [93, 100], [101, 103], [104, 106], [107, 116], [117, 119], [120, 125], [125, 126]]}
{"doc_key": "ai-test-205", "ner": [[4, 6, "misc"], [9, 10, "researcher"], [17, 18, "researcher"], [20, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 9, 10, "origin", "", false, false], [4, 6, 17, 18, "origin", "", false, false], [4, 6, 20, 20, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Both", "rely", "on", "the", "speech", "act", "theory", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "refined", "by", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both rely on the speech act theory developed by John Searle in the 1960s and refined by Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 16], [17, 23], [24, 27], [28, 34], [35, 44], [45, 47], [48, 52], [53, 59], [60, 62], [63, 66], [67, 72], [73, 76], [77, 84], [85, 87], [88, 93], [94, 102], [103, 106], [107, 113], [114, 116], [117, 120], [121, 126], [126, 127]]}
{"doc_key": "ai-test-206", "ner": [[0, 3, "algorithm"], [19, 20, "researcher"], [21, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 19, 20, "related-to", "", false, false], [21, 22, 19, 20, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "knowledge", "structure", "have", "unlocked", "powerful", "hierarchical", "models", "of", "knowledge", "organisation", "such", "as", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "Neural network models of concept formation and knowledge structure have unlocked powerful hierarchical models of knowledge organisation such as George Miller's Wordnet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 56], [57, 66], [67, 71], [72, 80], [81, 89], [90, 102], [103, 109], [110, 112], [113, 122], [123, 135], [136, 140], [141, 143], [144, 150], [151, 157], [157, 159], [160, 167], [167, 168]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [15, 16, "field"], [19, 21, "product"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 15, 16, "part-of", "", false, false], [0, 1, 24, 26, "part-of", "", false, false], [19, 21, 15, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Template", "matching", "has", "a", "wide", "range", "of", "applications", "and", "is", "used", "in", "fields", "such", "as", "face", "recognition", "(", "see", "face", "recognition", "systems", ")", "and", "medical", "image", "processing", "."], "sentence-detokenized": "Template matching has a wide range of applications and is used in fields such as face recognition (see face recognition systems) and medical image processing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 23], [24, 28], [29, 34], [35, 37], [38, 50], [51, 54], [55, 57], [58, 62], [63, 65], [66, 72], [73, 77], [78, 80], [81, 85], [86, 97], [98, 99], [99, 102], [103, 107], [108, 119], [120, 127], [127, 128], [129, 132], [133, 140], [141, 146], [147, 157], [157, 158]]}
{"doc_key": "ai-test-208", "ner": [[9, 10, "researcher"], [12, 13, "researcher"], [18, 27, "organisation"], [29, 29, "organisation"], [38, 39, "algorithm"], [42, 48, "conference"], [50, 50, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 10, 18, 27, "role", "", false, false], [9, 10, 42, 48, "physical", "", false, false], [9, 10, 42, 48, "temporal", "", false, false], [9, 10, 50, 50, "physical", "", false, false], [12, 13, 18, 27, "role", "", false, false], [12, 13, 42, 48, "temporal", "", false, false], [29, 29, 18, 27, "named", "", false, false], [42, 48, 38, 39, "topic", "", false, false], [50, 50, 42, 48, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "usage", "only", "became", "widespread", "in", "2005", "when", "Navneet", "Dalal", "and", "Bill", "Triggs", ",", "researchers", "for", "the", "French", "National", "Institute", "for", "Research", "in", "Computer", "Science", "and", "Automation", "(", "INRIA", ")", ",", "presented", "their", "extended", "work", "on", "the", "HOG", "descriptor", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "However, usage only became widespread in 2005 when Navneet Dalal and Bill Triggs, researchers for the French National Institute for Research in Computer Science and Automation (INRIA), presented their extended work on the HOG descriptor at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 19], [20, 26], [27, 37], [38, 40], [41, 45], [46, 50], [51, 58], [59, 64], [65, 68], [69, 73], [74, 80], [80, 81], [82, 93], [94, 97], [98, 101], [102, 108], [109, 117], [118, 127], [128, 131], [132, 140], [141, 143], [144, 152], [153, 160], [161, 164], [165, 175], [176, 177], [177, 182], [182, 183], [183, 184], [185, 194], [195, 200], [201, 209], [210, 214], [215, 217], [218, 221], [222, 225], [226, 236], [237, 239], [240, 243], [244, 254], [255, 257], [258, 266], [267, 273], [274, 277], [278, 285], [286, 297], [298, 299], [299, 303], [303, 304], [304, 305]]}
{"doc_key": "ai-test-209", "ner": [[3, 3, "university"], [16, 18, "organisation"], [20, 21, "organisation"], [28, 28, "field"], [33, 35, "researcher"], [37, 40, "researcher"], [43, 45, "researcher"], [48, 51, "organisation"], [55, 57, "organisation"], [62, 63, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[20, 21, 28, 28, "related-to", "", false, false], [33, 35, 20, 21, "physical", "", false, false], [33, 35, 20, 21, "role", "", false, false], [37, 40, 20, 21, "physical", "", false, false], [37, 40, 20, 21, "role", "", false, false], [43, 45, 20, 21, "physical", "", false, false], [43, 45, 20, 21, "role", "", false, false], [62, 63, 55, 57, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Before", "joining", "the", "Penn", "faculty", "in", "2002", ",", "he", "spent", "a", "decade", "(", "1991-2001", ")", "at", "AT", "&T", "Labs", "and", "Bell", "Labs", ",", "including", "as", "head", "of", "the", "AI", "department", "with", "colleagues", "including", "Michael", "L.", "Littman", ",", "David", "A", ".", "McAllester", ",", "and", "Richard", "S.", "Sutton", ";", "the", "Secure", "Systems", "Research", "department", ";", "and", "the", "Machine", "Learning", "department", "with", "members", "such", "as", "Michael", "Collins", "and", "leaders", ")", "."], "sentence-detokenized": "Before joining the Penn faculty in 2002, he spent a decade (1991-2001) at AT&T Labs and Bell Labs, including as head of the AI department with colleagues including Michael L. Littman, David A. McAllester, and Richard S. Sutton; the Secure Systems Research department; and the Machine Learning department with members such as Michael Collins and leaders).", "token2charspan": [[0, 6], [7, 14], [15, 18], [19, 23], [24, 31], [32, 34], [35, 39], [39, 40], [41, 43], [44, 49], [50, 51], [52, 58], [59, 60], [60, 69], [69, 70], [71, 73], [74, 76], [76, 78], [79, 83], [84, 87], [88, 92], [93, 97], [97, 98], [99, 108], [109, 111], [112, 116], [117, 119], [120, 123], [124, 126], [127, 137], [138, 142], [143, 153], [154, 163], [164, 171], [172, 174], [175, 182], [182, 183], [184, 189], [190, 191], [191, 192], [193, 203], [203, 204], [205, 208], [209, 216], [217, 219], [220, 226], [226, 227], [228, 231], [232, 238], [239, 246], [247, 255], [256, 266], [266, 267], [268, 271], [272, 275], [276, 283], [284, 292], [293, 303], [304, 308], [309, 316], [317, 321], [322, 324], [325, 332], [333, 340], [341, 344], [345, 352], [352, 353], [353, 354]]}
{"doc_key": "ai-test-210", "ner": [[6, 8, "field"], [14, 15, "field"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 8, 14, 15, "compare", "", false, false], [25, 26, 14, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["When", "the", "data", "is", "unlabelled", ",", "supervised", "learning", "is", "not", "possible", ",", "and", "an", "unsupervised", "learning", "approach", "is", "required", "that", "attempts", "to", "find", "a", "natural", "Cluster", "analysis", "for", "the", "groups", ",", "and", "then", "map", "new", "data", "to", "these", "formed", "groups", "."], "sentence-detokenized": "When the data is unlabelled, supervised learning is not possible, and an unsupervised learning approach is required that attempts to find a natural Cluster analysis for the groups, and then map new data to these formed groups.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 27], [27, 28], [29, 39], [40, 48], [49, 51], [52, 55], [56, 64], [64, 65], [66, 69], [70, 72], [73, 85], [86, 94], [95, 103], [104, 106], [107, 115], [116, 120], [121, 129], [130, 132], [133, 137], [138, 139], [140, 147], [148, 155], [156, 164], [165, 168], [169, 172], [173, 179], [179, 180], [181, 184], [185, 189], [190, 193], [194, 197], [198, 202], [203, 205], [206, 211], [212, 218], [219, 225], [225, 226]]}
{"doc_key": "ai-test-211", "ner": [[3, 4, "field"], [15, 18, "organisation"], [25, 26, "field"], [28, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 15, 18, "origin", "", false, false], [3, 4, 25, 26, "part-of", "", false, false], [3, 4, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "field", "of", "computer", "science", "developed", "in", "the", "1950s", "at", "academic", "institutions", "such", "as", "the", "MIT", "A.I", ".", "Lab", ",", "initially", "as", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "This field of computer science developed in the 1950s at academic institutions such as the MIT A.I. Lab, initially as a branch of artificial intelligence and robotics.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 30], [31, 40], [41, 43], [44, 47], [48, 53], [54, 56], [57, 65], [66, 78], [79, 83], [84, 86], [87, 90], [91, 94], [95, 98], [98, 99], [100, 103], [103, 104], [105, 114], [115, 117], [118, 119], [120, 126], [127, 129], [130, 140], [141, 153], [154, 157], [158, 166], [166, 167]]}
{"doc_key": "ai-test-212", "ner": [[7, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "can", "also", "be", "replaced", "by", "the", "Log", "loss", "equation", "below", ":"], "sentence-detokenized": "This can also be replaced by the Log loss equation below:", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 25], [26, 28], [29, 32], [33, 36], [37, 41], [42, 50], [51, 56], [56, 57]]}
{"doc_key": "ai-test-213", "ner": [[0, 2, "organisation"], [5, 8, "organisation"], [11, 15, "university"], [17, 17, "university"], [19, 20, "university"], [23, 25, "university"], [28, 28, "country"], [33, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 33, 33, "related-to", "research_leader_in_field", false, false], [5, 8, 0, 2, "named", "", false, false], [5, 8, 33, 33, "related-to", "research_leader_in_field", false, false], [11, 15, 33, 33, "related-to", "research_leader_in_field", false, false], [17, 17, 33, 33, "related-to", "research_leader_in_field", false, false], [19, 20, 33, 33, "related-to", "research_leader_in_field", false, false], [23, 25, 28, 28, "physical", "", false, false], [23, 25, 33, 33, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Shirley", "Ryan", "AbilityLab", "(", "formerly", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "University", "of", "California", "at", "Berkeley", ",", "MIT", ",", "Stanford", "University", ",", "and", "University", "of", "Twente", "in", "the", "Netherlands", "are", "research", "leaders", "in", "biomechatronics", "."], "sentence-detokenized": "Shirley Ryan AbilityLab (formerly Rehabilitation Institute of Chicago), University of California at Berkeley, MIT, Stanford University, and University of Twente in the Netherlands are research leaders in biomechatronics.", "token2charspan": [[0, 7], [8, 12], [13, 23], [24, 25], [25, 33], [34, 48], [49, 58], [59, 61], [62, 69], [69, 70], [70, 71], [72, 82], [83, 85], [86, 96], [97, 99], [100, 108], [108, 109], [110, 113], [113, 114], [115, 123], [124, 134], [134, 135], [136, 139], [140, 150], [151, 153], [154, 160], [161, 163], [164, 167], [168, 179], [180, 183], [184, 192], [193, 200], [201, 203], [204, 219], [219, 220]]}
{"doc_key": "ai-test-214", "ner": [[28, 31, "metrics"], [42, 43, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Given", "a", "set", "of", "predicted", "values", "and", "a", "corresponding", "set", "of", "actual", "values", "for", "X", "for", "various", "time", "periods", ",", "a", "common", "evaluation", "technique", "is", "to", "use", "the", "mean", "squared", "prediction", "error", ";", "other", "measures", "are", "also", "available", "(", "see", "forecasting", "#", "forecasting", "accuracy", ")", "."], "sentence-detokenized": "Given a set of predicted values and a corresponding set of actual values for X for various time periods, a common evaluation technique is to use the mean squared prediction error; other measures are also available (see forecasting # forecasting accuracy).", "token2charspan": [[0, 5], [6, 7], [8, 11], [12, 14], [15, 24], [25, 31], [32, 35], [36, 37], [38, 51], [52, 55], [56, 58], [59, 65], [66, 72], [73, 76], [77, 78], [79, 82], [83, 90], [91, 95], [96, 103], [103, 104], [105, 106], [107, 113], [114, 124], [125, 134], [135, 137], [138, 140], [141, 144], [145, 148], [149, 153], [154, 161], [162, 172], [173, 178], [178, 179], [180, 185], [186, 194], [195, 198], [199, 203], [204, 213], [214, 215], [215, 218], [219, 230], [231, 232], [233, 244], [245, 253], [253, 254], [254, 255]]}
{"doc_key": "ai-test-215", "ner": [[13, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "measures", ",", "such", "as", "the", "proportion", "of", "correct", "predictions", "(", "also", "called", "accuracy", ")", ",", "are", "not", "useful", "when", "the", "two", "classes", "have", "very", "different", "sizes", "."], "sentence-detokenized": "Other measures, such as the proportion of correct predictions (also called accuracy), are not useful when the two classes have very different sizes.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 20], [21, 23], [24, 27], [28, 38], [39, 41], [42, 49], [50, 61], [62, 63], [63, 67], [68, 74], [75, 83], [83, 84], [84, 85], [86, 89], [90, 93], [94, 100], [101, 105], [106, 109], [110, 113], [114, 121], [122, 126], [127, 131], [132, 141], [142, 147], [147, 148]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [15, 19, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 15, 19, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "released", "to", "the", "public", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "in", "2000", ",", "and", "five", "betas", "were", "released", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was released to the public at the Conference on Computer Vision and Pattern Recognition in 2000, and five betas were released between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 46], [47, 49], [50, 53], [54, 60], [61, 63], [64, 67], [68, 78], [79, 81], [82, 90], [91, 97], [98, 101], [102, 109], [110, 121], [122, 124], [125, 129], [129, 130], [131, 134], [135, 139], [140, 145], [146, 150], [151, 159], [160, 167], [168, 172], [173, 176], [177, 181], [181, 182]]}
{"doc_key": "ai-test-217", "ner": [[23, 23, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Results", "have", "been", "presented", "that", "provide", "a", "correlation", "of", "up", "to", "0.964", "with", "human", "judgement", "at", "the", "corpus", "level", ",", "compared", "to", "the", "BLEU", "achievement", "of", "0.817", "on", "the", "same", "dataset", "."], "sentence-detokenized": "Results have been presented that provide a correlation of up to 0.964 with human judgement at the corpus level, compared to the BLEU achievement of 0.817 on the same dataset.", "token2charspan": [[0, 7], [8, 12], [13, 17], [18, 27], [28, 32], [33, 40], [41, 42], [43, 54], [55, 57], [58, 60], [61, 63], [64, 69], [70, 74], [75, 80], [81, 90], [91, 93], [94, 97], [98, 104], [105, 110], [110, 111], [112, 120], [121, 123], [124, 127], [128, 132], [133, 144], [145, 147], [148, 153], [154, 156], [157, 160], [161, 165], [166, 173], [173, 174]]}
{"doc_key": "ai-test-218", "ner": [[4, 4, "metrics"], [18, 18, "metrics"], [20, 22, "metrics"], [25, 27, "metrics"], [38, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 18, 18, "compare", "", false, false], [4, 4, 20, 22, "compare", "", false, false], [4, 4, 25, 27, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "initial", "version", "of", "VMAF", "has", "been", "shown", "to", "outperform", "other", "image", "and", "video", "quality", "metrics", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", ",", "and", "VQM", "-", "VFD", "on", "three", "out", "of", "four", "datasets", "in", "terms", "of", "prediction", "accuracy", ",", "when", "compared", "to", "subjective", "judgement", "."], "sentence-detokenized": "The initial version of VMAF has been shown to outperform other image and video quality metrics such as SSIM, PSNR -HVS, and VQM-VFD on three out of four datasets in terms of prediction accuracy, when compared to subjective judgement.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 22], [23, 27], [28, 31], [32, 36], [37, 42], [43, 45], [46, 56], [57, 62], [63, 68], [69, 72], [73, 78], [79, 86], [87, 94], [95, 99], [100, 102], [103, 107], [107, 108], [109, 113], [114, 115], [115, 118], [118, 119], [120, 123], [124, 127], [127, 128], [128, 131], [132, 134], [135, 140], [141, 144], [145, 147], [148, 152], [153, 161], [162, 164], [165, 170], [171, 173], [174, 184], [185, 193], [193, 194], [195, 199], [200, 208], [209, 211], [212, 222], [223, 232], [232, 233]]}
{"doc_key": "ai-test-219", "ner": [[17, 18, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 18, 23, 24, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "of", "'", "mouse", "'", "(", "animal", "or", "device", ")", "is", "irrelevant", "in", "machine", "translation", ",", "but", "relevant", "in", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity of 'mouse' (animal or device) is irrelevant in machine translation, but relevant in information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 31], [31, 36], [36, 37], [38, 39], [39, 45], [46, 48], [49, 55], [55, 56], [57, 59], [60, 70], [71, 73], [74, 81], [82, 93], [93, 94], [95, 98], [99, 107], [108, 110], [111, 122], [123, 132], [132, 133]]}
{"doc_key": "ai-test-220", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 1, "usage", "", false, false], [9, 10, 6, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "hashing", "was", "originally", "suggested", "in", "computer", "vision", "for", "object", "recognition", "in", "2D", "and", "3D", ","], "sentence-detokenized": "Geometric hashing was originally suggested in computer vision for object recognition in 2D and 3D,", "token2charspan": [[0, 9], [10, 17], [18, 21], [22, 32], [33, 42], [43, 45], [46, 54], [55, 61], [62, 65], [66, 72], [73, 84], [85, 87], [88, 90], [91, 94], [95, 97], [97, 98]]}
{"doc_key": "ai-test-221", "ner": [[9, 10, "field"], [14, 14, "field"], [15, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 9, 10, "part-of", "subfield", false, false], [15, 18, 9, 10, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "forms", "one", "of", "the", "three", "main", "categories", "of", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "It forms one of the three main categories of machine learning, along with supervised learning and reinforcement learning.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 15], [16, 19], [20, 25], [26, 30], [31, 41], [42, 44], [45, 52], [53, 61], [61, 62], [63, 68], [69, 73], [74, 84], [85, 93], [94, 97], [98, 111], [112, 120], [120, 121]]}
{"doc_key": "ai-test-222", "ner": [[0, 1, "field"], [17, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 31, "field"], [33, 34, "field"], [36, 37, "field"], [39, 39, "field"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 1, 17, 17, "part-of", "subfield", false, false], [0, 1, 19, 20, "part-of", "subfield", false, false], [0, 1, 22, 23, "part-of", "subfield", false, false], [0, 1, 25, 26, "part-of", "subfield", false, false], [0, 1, 28, 31, "part-of", "subfield", false, false], [0, 1, 33, 34, "part-of", "subfield", false, false], [0, 1, 36, 37, "part-of", "subfield", false, false], [0, 1, 39, 39, "part-of", "subfield", false, false], [0, 1, 41, 42, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Reinforcement", "learning", ",", "due", "to", "its", "generality", ",", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "games", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Reinforcement learning, due to its generality, is studied in many other disciplines, such as games, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 13], [14, 22], [22, 23], [24, 27], [28, 30], [31, 34], [35, 45], [45, 46], [47, 49], [50, 57], [58, 60], [61, 65], [66, 71], [72, 83], [83, 84], [85, 89], [90, 92], [93, 98], [98, 99], [100, 107], [108, 114], [114, 115], [116, 126], [127, 135], [135, 136], [137, 148], [149, 155], [155, 156], [157, 167], [167, 168], [168, 173], [174, 186], [186, 187], [188, 199], [200, 207], [207, 208], [209, 214], [215, 227], [227, 228], [229, 239], [240, 243], [244, 251], [252, 262], [262, 263]]}
{"doc_key": "ai-test-223", "ner": [[0, 2, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 7, "related-to", "", false, false], [0, 2, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pattern", "recognition", "is", "closely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ","], "sentence-detokenized": "Pattern recognition is closely related to artificial intelligence and machine learning,", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 38], [39, 41], [42, 52], [53, 65], [66, 69], [70, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-224", "ner": [[11, 12, "algorithm"], [15, 16, "field"], [18, 19, "field"], [30, 31, "task"], [33, 33, "task"], [35, 36, "task"], [38, 39, "algorithm"], [42, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 15, 16, "related-to", "", false, false], [11, 12, 18, 19, "related-to", "", false, false], [30, 31, 11, 12, "usage", "", true, false], [33, 33, 11, 12, "usage", "", true, false], [35, 36, 11, 12, "usage", "", true, false], [38, 39, 11, 12, "usage", "", true, false], [42, 44, 11, 12, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "software", "is", "used", "to", "design", ",", "train", ",", "and", "apply", "neural", "network", "models", "(", "supervised", "learning", "and", "unsupervised", "learning", ")", "to", "perform", "a", "wide", "variety", "of", "tasks", "such", "as", "data", "mining", ",", "classification", ",", "function", "estimation", ",", "multivariate", "regression", ",", "and", "time", "series", "prediction", "."], "sentence-detokenized": "The software is used to design, train, and apply neural network models (supervised learning and unsupervised learning) to perform a wide variety of tasks such as data mining, classification, function estimation, multivariate regression, and time series prediction.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [21, 23], [24, 30], [30, 31], [32, 37], [37, 38], [39, 42], [43, 48], [49, 55], [56, 63], [64, 70], [71, 72], [72, 82], [83, 91], [92, 95], [96, 108], [109, 117], [117, 118], [119, 121], [122, 129], [130, 131], [132, 136], [137, 144], [145, 147], [148, 153], [154, 158], [159, 161], [162, 166], [167, 173], [173, 174], [175, 189], [189, 190], [191, 199], [200, 210], [210, 211], [212, 224], [225, 235], [235, 236], [237, 240], [241, 245], [246, 252], [253, 263], [263, 264]]}
{"doc_key": "ai-test-225", "ner": [[11, 17, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", ",", "he", "was", "elected", "as", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016, he was elected as a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 28], [29, 35], [36, 38], [39, 42], [43, 54], [55, 58], [59, 62], [63, 74], [75, 77], [78, 88], [89, 101], [101, 102]]}
{"doc_key": "ai-test-226", "ner": [[6, 9, "organisation"], [15, 20, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", ",", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", ","], "sentence-detokenized": "He is a member of the National Academy of Sciences (since 2005), American Academy of Arts and Sciences (since 2009),", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 50], [51, 52], [52, 57], [58, 62], [62, 63], [63, 64], [65, 73], [74, 81], [82, 84], [85, 89], [90, 93], [94, 102], [103, 104], [104, 109], [110, 114], [114, 115], [115, 116]]}
{"doc_key": "ai-test-227", "ner": [[3, 5, "misc"], [9, 14, "product"], [17, 17, "country"], [19, 19, "country"], [24, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 14, 3, 5, "temporal", "", false, false], [9, 14, 17, 17, "physical", "", false, false], [9, 14, 19, 19, "physical", "", false, false], [9, 14, 24, 26, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "the", "1973", "Yom", "Kippur", "War", ",", "Soviet", "-supplied", "surface", "-", "to", "-", "air", "missile", "batteries", "in", "Egypt", "and", "Syria", "caused", "heavy", "damage", "to", "Israeli", "fighter", "jets", "."], "sentence-detokenized": "During the 1973 Yom Kippur War, Soviet-supplied surface-to-air missile batteries in Egypt and Syria caused heavy damage to Israeli fighter jets.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 26], [27, 30], [30, 31], [32, 38], [38, 47], [48, 55], [55, 56], [56, 58], [58, 59], [59, 62], [63, 70], [71, 80], [81, 83], [84, 89], [90, 93], [94, 99], [100, 106], [107, 112], [113, 119], [120, 122], [123, 130], [131, 138], [139, 143], [143, 144]]}
{"doc_key": "ai-test-228", "ner": [[9, 10, "product"], [14, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 15, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "resource", "(", "free", "but", "copyrighted", ")", "is", "the", "HTK", "book", "(", "and", "accompanying", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another resource (free but copyrighted) is the HTK book (and accompanying HTK toolkit).", "token2charspan": [[0, 7], [8, 16], [17, 18], [18, 22], [23, 26], [27, 38], [38, 39], [40, 42], [43, 46], [47, 50], [51, 55], [56, 57], [57, 60], [61, 73], [74, 77], [78, 85], [85, 86], [86, 87]]}
{"doc_key": "ai-test-229", "ner": [[4, 5, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "taken", "at", "the", "2004", "AAAI", "Spring", "Symposium", "where", "linguists", ",", "computer", "scientists", ",", "and", "other", "interested", "researchers", "first", "aligned", "interests", "and", "proposed", "a", "common", "task", "and", "benchmark", "dataset", "for", "systematic", "computational", "research", "on", "influence", ",", "attractiveness", ",", "subjectivity", ",", "and", "sentiment", "in", "text", "."], "sentence-detokenized": "- taken at the 2004 AAAI Spring Symposium where linguists, computer scientists, and other interested researchers first aligned interests and proposed a common task and benchmark dataset for systematic computational research on influence, attractiveness, subjectivity, and sentiment in text.", "token2charspan": [[0, 1], [2, 7], [8, 10], [11, 14], [15, 19], [20, 24], [25, 31], [32, 41], [42, 47], [48, 57], [57, 58], [59, 67], [68, 78], [78, 79], [80, 83], [84, 89], [90, 100], [101, 112], [113, 118], [119, 126], [127, 136], [137, 140], [141, 149], [150, 151], [152, 158], [159, 163], [164, 167], [168, 177], [178, 185], [186, 189], [190, 200], [201, 214], [215, 223], [224, 226], [227, 236], [236, 237], [238, 252], [252, 253], [254, 266], [266, 267], [268, 271], [272, 281], [282, 284], [285, 289], [289, 290]]}
{"doc_key": "ai-test-230", "ner": [[9, 10, "task"], [15, 16, "task"], [18, 20, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "single", "grid", "can", "be", "analysed", "for", "content", "(", "eyeball", "inspection", ")", "and", "structure", "(", "cluster", "analysis", ",", "principal", "component", "analysis", ",", "and", "various", "structural", "indices", "relating", "to", "complexity", "and", "range", "of", "ratings", "being", "the", "main", "techniques", "used", ")", "."], "sentence-detokenized": "A single grid can be analysed for content (eyeball inspection) and structure (cluster analysis, principal component analysis, and various structural indices relating to complexity and range of ratings being the main techniques used).", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 17], [18, 20], [21, 29], [30, 33], [34, 41], [42, 43], [43, 50], [51, 61], [61, 62], [63, 66], [67, 76], [77, 78], [78, 85], [86, 94], [94, 95], [96, 105], [106, 115], [116, 124], [124, 125], [126, 129], [130, 137], [138, 148], [149, 156], [157, 165], [166, 168], [169, 179], [180, 183], [184, 189], [190, 192], [193, 200], [201, 206], [207, 210], [211, 215], [216, 226], [227, 231], [231, 232], [232, 233]]}
{"doc_key": "ai-test-231", "ner": [[3, 3, "organisation"], [11, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", ",", "Toyota", "was", "considered", "to", "be", "lagging", "behind", "in", "self", "-", "driving", "cars", "and", "in", "need", "of", "innovation", "."], "sentence-detokenized": "In 2018, Toyota was considered to be lagging behind in self-driving cars and in need of innovation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 30], [31, 33], [34, 36], [37, 44], [45, 51], [52, 54], [55, 59], [59, 60], [60, 67], [68, 72], [73, 76], [77, 79], [80, 84], [85, 87], [88, 98], [98, 99]]}
{"doc_key": "ai-test-232", "ner": [[40, 41, "misc"], [43, 44, "misc"], [47, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "targets", "include", "natural", "objects", "such", "as", "land", ",", "sea", ",", "precipitation", "(", "such", "as", "rain", ",", "snow", "or", "hail", ")", ",", "sandstorms", ",", "animals", "(", "especially", "birds", ")", ",", "atmospheric", "turbulence", ",", "and", "other", "atmospheric", "effects", ",", "such", "as", "ionospheric", "reflections", ",", "meteor", "trails", ",", "and", "three", "-", "body", "scattering", "spikes", "."], "sentence-detokenized": "Such targets include natural objects such as land, sea, precipitation (such as rain, snow or hail), sandstorms, animals (especially birds), atmospheric turbulence, and other atmospheric effects, such as ionospheric reflections, meteor trails, and three-body scattering spikes.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 28], [29, 36], [37, 41], [42, 44], [45, 49], [49, 50], [51, 54], [54, 55], [56, 69], [70, 71], [71, 75], [76, 78], [79, 83], [83, 84], [85, 89], [90, 92], [93, 97], [97, 98], [98, 99], [100, 110], [110, 111], [112, 119], [120, 121], [121, 131], [132, 137], [137, 138], [138, 139], [140, 151], [152, 162], [162, 163], [164, 167], [168, 173], [174, 185], [186, 193], [193, 194], [195, 199], [200, 202], [203, 214], [215, 226], [226, 227], [228, 234], [235, 241], [241, 242], [243, 246], [247, 252], [252, 253], [253, 257], [258, 268], [269, 275], [275, 276]]}
{"doc_key": "ai-test-233", "ner": [[18, 19, "product"], [40, 41, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "planning", "and", "control", ",", "the", "essential", "difference", "between", "humanoids", "and", "other", "types", "of", "robots", "(", "such", "as", "industrial", "robots", ")", "is", "that", "the", "movement", "of", "the", "robot", "should", "be", "human", "-", "like", ",", "using", "legged", "locomotion", ",", "specifically", "a", "biped", "gait", "."], "sentence-detokenized": "In planning and control, the essential difference between humanoids and other types of robots (such as industrial robots) is that the movement of the robot should be human-like, using legged locomotion, specifically a biped gait.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 23], [23, 24], [25, 28], [29, 38], [39, 49], [50, 57], [58, 67], [68, 71], [72, 77], [78, 83], [84, 86], [87, 93], [94, 95], [95, 99], [100, 102], [103, 113], [114, 120], [120, 121], [122, 124], [125, 129], [130, 133], [134, 142], [143, 145], [146, 149], [150, 155], [156, 162], [163, 165], [166, 171], [171, 172], [172, 176], [176, 177], [178, 183], [184, 190], [191, 201], [201, 202], [203, 215], [216, 217], [218, 223], [224, 228], [228, 229]]}
{"doc_key": "ai-test-234", "ner": [[0, 1, "algorithm"], [9, 10, "misc"], [14, 14, "metrics"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Gradient", "descent", "can", "take", "many", "iterations", "to", "calculate", "the", "local", "minimum", "with", "the", "required", "accuracy", ",", "if", "the", "curvature", "in", "different", "directions", "is", "very", "different", "for", "a", "given", "function", "."], "sentence-detokenized": "Gradient descent can take many iterations to calculate the local minimum with the required accuracy, if the curvature in different directions is very different for a given function.", "token2charspan": [[0, 8], [9, 16], [17, 20], [21, 25], [26, 30], [31, 41], [42, 44], [45, 54], [55, 58], [59, 64], [65, 72], [73, 77], [78, 81], [82, 90], [91, 99], [99, 100], [101, 103], [104, 107], [108, 117], [118, 120], [121, 130], [131, 141], [142, 144], [145, 149], [150, 159], [160, 163], [164, 165], [166, 171], [172, 180], [180, 181]]}
{"doc_key": "ai-test-235", "ner": [[1, 6, "misc"], [10, 10, "misc"], [17, 22, "conference"], [25, 25, "location"], [27, 27, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 6, 10, 10, "part-of", "", true, false], [17, 22, 25, 25, "physical", "", false, true], [25, 25, 27, 27, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "1997", "RoboCup", "2D", "Football", "Simulation", "League", "was", "the", "first", "RoboCup", "competition", "promoted", "in", "conjunction", "with", "the", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", "held", "in", "Nagoya", ",", "Japan", ",", "from", "23", "to", "29", "August", "1997", "."], "sentence-detokenized": "The 1997 RoboCup 2D Football Simulation League was the first RoboCup competition promoted in conjunction with the International Joint Conference on Artificial Intelligence held in Nagoya, Japan, from 23 to 29 August 1997.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 19], [20, 28], [29, 39], [40, 46], [47, 50], [51, 54], [55, 60], [61, 68], [69, 80], [81, 89], [90, 92], [93, 104], [105, 109], [110, 113], [114, 127], [128, 133], [134, 144], [145, 147], [148, 158], [159, 171], [172, 176], [177, 179], [180, 186], [186, 187], [188, 193], [193, 194], [195, 199], [200, 202], [203, 205], [206, 208], [209, 215], [216, 220], [220, 221]]}
{"doc_key": "ai-test-236", "ner": [[6, 6, "programlang"], [10, 10, "programlang"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "options", "include", "an", "embedded", "Python", "environment", ",", "and", "R", "Console", "plus", "support", "for", "Rserve", "."], "sentence-detokenized": "Other programming options include an embedded Python environment, and R Console plus support for Rserve.", "token2charspan": [[0, 5], [6, 17], [18, 25], [26, 33], [34, 36], [37, 45], [46, 52], [53, 64], [64, 65], [66, 69], [70, 71], [72, 79], [80, 84], [85, 92], [93, 96], [97, 103], [103, 104]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [9, 10, "field"], [12, 12, "field"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [33, 34, "field"], [38, 39, "field"], [42, 43, "field"], [47, 48, "field"], [51, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[15, 16, 12, 12, "related-to", "contributes_to_field", true, false], [18, 19, 12, 12, "related-to", "contributes_to_field", true, false], [21, 22, 12, 12, "related-to", "contributes_to_field", true, false], [42, 43, 38, 39, "part-of", "", false, false], [47, 48, 42, 43, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["From", "Bonn", ",", "he", "has", "made", "fundamental", "contributions", "to", "artificial", "intelligence", "and", "robotics", "(", "with", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Thrun", "among", "his", "students", ")", ",", "and", "to", "the", "development", "of", "software", "engineering", ",", "particularly", "in", "civil", "engineering", ",", "and", "information", "systems", ",", "particularly", "in", "geosciences", ".", "won", "the", "AAAI", "Classic", "Paper", "award", "in", "2016.2014", "."], "sentence-detokenized": "From Bonn, he has made fundamental contributions to artificial intelligence and robotics (with Wolfram Burgard, Dieter Fox, Sebastian Thrun among his students), and to the development of software engineering, particularly in civil engineering, and information systems, particularly in geosciences. won the AAAI Classic Paper award in 2016.2014.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 13], [14, 17], [18, 22], [23, 34], [35, 48], [49, 51], [52, 62], [63, 75], [76, 79], [80, 88], [89, 90], [90, 94], [95, 102], [103, 110], [110, 111], [112, 118], [119, 122], [122, 123], [124, 133], [134, 139], [140, 145], [146, 149], [150, 158], [158, 159], [159, 160], [161, 164], [165, 167], [168, 171], [172, 183], [184, 186], [187, 195], [196, 207], [207, 208], [209, 221], [222, 224], [225, 230], [231, 242], [242, 243], [244, 247], [248, 259], [260, 267], [267, 268], [269, 281], [282, 284], [285, 296], [296, 297], [298, 301], [302, 305], [306, 310], [311, 318], [319, 324], [325, 330], [331, 333], [334, 343], [343, 344]]}
{"doc_key": "ai-test-238", "ner": [[2, 6, "conference"], [17, 18, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 6, 17, 18, "physical", "", false, false], [17, 18, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "US", "edition", "of", "Campus", "Party", "will", "take", "place", "from", "20", "to", "22", "August", "at", "the", "TCF", "Center", "in", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "The first US edition of Campus Party will take place from 20 to 22 August at the TCF Center in Detroit, Michigan.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 20], [21, 23], [24, 30], [31, 36], [37, 41], [42, 46], [47, 52], [53, 57], [58, 60], [61, 63], [64, 66], [67, 73], [74, 76], [77, 80], [81, 84], [85, 91], [92, 94], [95, 102], [102, 103], [104, 112], [112, 113]]}
{"doc_key": "ai-test-239", "ner": [[2, 3, "researcher"], [6, 7, "researcher"], [9, 9, "researcher"], [13, 14, "misc"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 13, 14, "win-defeat", "", false, false], [6, 7, 13, 14, "win-defeat", "", false, false], [9, 9, 13, 14, "win-defeat", "", false, false], [13, 14, 23, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Along", "with", "Yann", "LeCun", ",", "and", "Yoshua", "Bengio", ",", "Hinton", "won", "the", "2018", "Turing", "Award", "for", "conceptual", "and", "engineering", "breakthroughs", "that", "have", "made", "deep", "neural", "networks", "an", "essential", "component", "in", "computing", "."], "sentence-detokenized": "Along with Yann LeCun, and Yoshua Bengio, Hinton won the 2018 Turing Award for conceptual and engineering breakthroughs that have made deep neural networks an essential component in computing.", "token2charspan": [[0, 5], [6, 10], [11, 15], [16, 21], [21, 22], [23, 26], [27, 33], [34, 40], [40, 41], [42, 48], [49, 52], [53, 56], [57, 61], [62, 68], [69, 74], [75, 78], [79, 89], [90, 93], [94, 105], [106, 119], [120, 124], [125, 129], [130, 134], [135, 139], [140, 146], [147, 155], [156, 158], [159, 168], [169, 178], [179, 181], [182, 191], [191, 192]]}
{"doc_key": "ai-test-240", "ner": [[0, 2, "product"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Euler", "Math", "Toolbox", "uses", "a", "matrix", "language", "similar", "to", "MATLAB", ",", "a", "system", "that", "has", "been", "developed", "since", "the", "1970s", "."], "sentence-detokenized": "Euler Math Toolbox uses a matrix language similar to MATLAB, a system that has been developed since the 1970s.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 23], [24, 25], [26, 32], [33, 41], [42, 49], [50, 52], [53, 59], [59, 60], [61, 62], [63, 69], [70, 74], [75, 78], [79, 83], [84, 93], [94, 99], [100, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-test-241", "ner": [[10, 10, "programlang"], [12, 13, "programlang"], [15, 15, "programlang"], [17, 17, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "languages", "allow", "it", "in", "a", "portable", "way", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "or", "D", ")", "."], "sentence-detokenized": "Some languages allow it in a portable way (e.g. Scheme, Common Lisp, Perl or D).", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 23], [24, 26], [27, 28], [29, 37], [38, 41], [42, 43], [43, 47], [48, 54], [54, 55], [56, 62], [63, 67], [67, 68], [69, 73], [74, 76], [77, 78], [78, 79], [79, 80]]}
{"doc_key": "ai-test-242", "ner": [[7, 7, "misc"], [9, 10, "researcher"], [12, 13, "researcher"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 9, 10, "artifact", "", false, false], [7, 7, 12, 13, "artifact", "", false, false], [7, 7, 27, 28, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1969", ",", "a", "famous", "book", "titled", "Perceptrons", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "showed", "that", "it", "was", "impossible", "for", "these", "classes", "of", "networks", "to", "learn", "the", "XOR", "function", "."], "sentence-detokenized": "In 1969, a famous book titled Perceptrons by Marvin Minsky and Seymour Papert showed that it was impossible for these classes of networks to learn the XOR function.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 22], [23, 29], [30, 41], [42, 44], [45, 51], [52, 58], [59, 62], [63, 70], [71, 77], [78, 84], [85, 89], [90, 92], [93, 96], [97, 107], [108, 111], [112, 117], [118, 125], [126, 128], [129, 137], [138, 140], [141, 146], [147, 150], [151, 154], [155, 163], [163, 164]]}
{"doc_key": "ai-test-243", "ner": [[4, 9, "misc"], [12, 12, "product"], [18, 21, "organisation"], [25, 30, "organisation"], [33, 38, "location"], [40, 40, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 21, 12, 12, "usage", "", false, false], [18, 21, 33, 38, "physical", "", false, false], [25, 30, 18, 21, "named", "", false, false], [33, 38, 40, 40, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "large", "number", "of", "Russian", "scientific", "and", "technical", "documents", "were", "translated", "using", "SYSTRAN", "under", "the", "auspices", "of", "the", "USAF", "Overseas", "Technology", "Division", "(", "later", "the", "National", "Air", "and", "Space", "Intelligence", "Centre", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", ",", "Ohio", "."], "sentence-detokenized": "A large number of Russian scientific and technical documents were translated using SYSTRAN under the auspices of the USAF Overseas Technology Division (later the National Air and Space Intelligence Centre) at Wright-Patterson Air Force Base, Ohio.", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 17], [18, 25], [26, 36], [37, 40], [41, 50], [51, 60], [61, 65], [66, 76], [77, 82], [83, 90], [91, 96], [97, 100], [101, 109], [110, 112], [113, 116], [117, 121], [122, 130], [131, 141], [142, 150], [151, 152], [152, 157], [158, 161], [162, 170], [171, 174], [175, 178], [179, 184], [185, 197], [198, 204], [204, 205], [206, 208], [209, 215], [215, 216], [216, 225], [226, 229], [230, 235], [236, 240], [240, 241], [242, 246], [246, 247]]}
{"doc_key": "ai-test-244", "ner": [[0, 1, "field"], [4, 5, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-supervised", "learning", "falls", "between", "unsupervised", "learning", "(", "without", "labelled", "training", "data", ")", "and", "supervised", "learning", "(", "with", "fully", "labelled", "training", "data", ")", "."], "sentence-detokenized": "Semi-supervised learning falls between unsupervised learning (without labelled training data) and supervised learning (with fully labelled training data).", "token2charspan": [[0, 15], [16, 24], [25, 30], [31, 38], [39, 51], [52, 60], [61, 62], [62, 69], [70, 78], [79, 87], [88, 92], [92, 93], [94, 97], [98, 108], [109, 117], [118, 119], [119, 123], [124, 129], [130, 138], [139, 147], [148, 152], [152, 153], [153, 154]]}
{"doc_key": "ai-test-245", "ner": [[0, 2, "algorithm"], [7, 9, "algorithm"], [30, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 7, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ann", "-gram", "model", "is", "a", "type", "of", "probabilistic", "language", "model", "to", "predict", "the", "next", "item", "in", "such", "a", "sequence", "in", "the", "form", "of", "an", "(", "n", "-", "1", ")", "order", "Markov", "model", "."], "sentence-detokenized": "Ann-gram model is a type of probabilistic language model to predict the next item in such a sequence in the form of an (n - 1) order Markov model.", "token2charspan": [[0, 3], [3, 8], [9, 14], [15, 17], [18, 19], [20, 24], [25, 27], [28, 41], [42, 50], [51, 56], [57, 59], [60, 67], [68, 71], [72, 76], [77, 81], [82, 84], [85, 89], [90, 91], [92, 100], [101, 103], [104, 107], [108, 112], [113, 115], [116, 118], [119, 120], [120, 121], [122, 123], [124, 125], [125, 126], [127, 132], [133, 139], [140, 145], [145, 146]]}
{"doc_key": "ai-test-246", "ner": [[0, 2, "organisation"], [5, 5, "product"], [9, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 5, 5, "usage", "", false, false], [9, 15, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "has", "used", "Cyc", "to", "develop", "a", "natural", "language", "query", "interface", "of", "biomedical", "information", ",", "covering", "decades", "of", "information", "on", "cardiothoracic", "surgery", "."], "sentence-detokenized": "The Cleveland Clinic has used Cyc to develop a natural language query interface of biomedical information, covering decades of information on cardiothoracic surgery.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 24], [25, 29], [30, 33], [34, 36], [37, 44], [45, 46], [47, 54], [55, 63], [64, 69], [70, 79], [80, 82], [83, 93], [94, 105], [105, 106], [107, 115], [116, 123], [124, 126], [127, 138], [139, 141], [142, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-test-247", "ner": [[6, 7, "country"], [9, 9, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 9, 9, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "incident", "strained", "relations", "between", "the", "United", "States", "and", "Japan", ",", "and", "resulted", "in", "the", "arrest", "and", "prosecution", "of", "two", "senior", "executives", ",", "as", "well", "as", "the", "imposition", "of", "sanctions", "on", "the", "company", "by", "both", "countries", "."], "sentence-detokenized": "The incident strained relations between the United States and Japan, and resulted in the arrest and prosecution of two senior executives, as well as the imposition of sanctions on the company by both countries.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 31], [32, 39], [40, 43], [44, 50], [51, 57], [58, 61], [62, 67], [67, 68], [69, 72], [73, 81], [82, 84], [85, 88], [89, 95], [96, 99], [100, 111], [112, 114], [115, 118], [119, 125], [126, 136], [136, 137], [138, 140], [141, 145], [146, 148], [149, 152], [153, 163], [164, 166], [167, 176], [177, 179], [180, 183], [184, 191], [192, 194], [195, 199], [200, 209], [209, 210]]}
{"doc_key": "ai-test-248", "ner": [[5, 7, "algorithm"], [10, 11, "field"], [18, 18, "misc"], [26, 26, "misc"], [30, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 7, 10, 11, "type-of", "", false, false], [18, 18, 10, 11, "part-of", "", true, false], [26, 26, 10, 11, "part-of", "", true, false], [30, 30, 10, 11, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["If", "modelling", "is", "done", "by", "artificial", "neural", "networks", "or", "other", "machine", "learning", ",", "then", "parameter", "optimisation", "is", "called", "training", ",", "while", "model", "hyperparameter", "optimisation", "is", "called", "tuning", "and", "often", "uses", "cross-validation", "."], "sentence-detokenized": "If modelling is done by artificial neural networks or other machine learning, then parameter optimisation is called training, while model hyperparameter optimisation is called tuning and often uses cross-validation.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 20], [21, 23], [24, 34], [35, 41], [42, 50], [51, 53], [54, 59], [60, 67], [68, 76], [76, 77], [78, 82], [83, 92], [93, 105], [106, 108], [109, 115], [116, 124], [124, 125], [126, 131], [132, 137], [138, 152], [153, 165], [166, 168], [169, 175], [176, 182], [183, 186], [187, 192], [193, 197], [198, 214], [214, 215]]}
{"doc_key": "ai-test-249", "ner": [[8, 8, "country"], [10, 10, "country"], [12, 13, "country"], [19, 20, "organisation"], [22, 22, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 20, 22, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Localised", "versions", "of", "the", "site", "available", "in", "the", "UK", ",", "India", "and", "Australia", "were", "discontinued", "following", "the", "acquisition", "of", "Rotten", "Tomatoes", "by", "Fandango", "."], "sentence-detokenized": "Localised versions of the site available in the UK, India and Australia were discontinued following the acquisition of Rotten Tomatoes by Fandango.", "token2charspan": [[0, 9], [10, 18], [19, 21], [22, 25], [26, 30], [31, 40], [41, 43], [44, 47], [48, 50], [50, 51], [52, 57], [58, 61], [62, 71], [72, 76], [77, 89], [90, 99], [100, 103], [104, 115], [116, 118], [119, 125], [126, 134], [135, 137], [138, 146], [146, 147]]}
{"doc_key": "ai-test-250", "ner": [[0, 1, "task"], [13, 14, "metrics"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 13, 14, "related-to", "", false, false], [13, 14, 24, 25, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "NER", "model", "is", "one", "of", "a", "number", "of", "methods", "for", "determining", "the", "accuracy", "of", "live", "subtitles", "in", "television", "broadcasts", "and", "events", "produced", "using", "speech", "recognition", "."], "sentence-detokenized": "The NER model is one of a number of methods for determining the accuracy of live subtitles in television broadcasts and events produced using speech recognition.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 25], [26, 32], [33, 35], [36, 43], [44, 47], [48, 59], [60, 63], [64, 72], [73, 75], [76, 80], [81, 90], [91, 93], [94, 104], [105, 115], [116, 119], [120, 126], [127, 135], [136, 141], [142, 148], [149, 160], [160, 161]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [5, 7, "university"], [9, 10, "university"], [12, 12, "location"], [14, 18, "university"], [20, 21, "university"], [23, 23, "location"], [26, 31, "university"], [33, 35, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 5, 7, "physical", "", false, false], [0, 0, 5, 7, "role", "", false, false], [0, 0, 9, 10, "physical", "", false, false], [0, 0, 9, 10, "role", "", false, false], [0, 0, 14, 18, "physical", "", false, false], [0, 0, 14, 18, "role", "", false, false], [0, 0, 20, 21, "physical", "", false, false], [0, 0, 20, 21, "role", "", false, false], [0, 0, 26, 31, "physical", "", false, false], [0, 0, 26, 31, "role", "", false, false], [9, 10, 12, 12, "physical", "", false, false], [14, 18, 23, 23, "physical", "", false, false], [20, 21, 23, 23, "physical", "", false, false], [26, 31, 33, 35, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "has", "taught", "at", "the", "University", "of", "Cambridge", ",", "Hebrew", "University", "in", "Jerusalem", ",", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "and", "\u00c9cole", "Polytechnique", "in", "Paris", ",", "and", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "City", "."], "sentence-detokenized": "Atran has taught at the University of Cambridge, Hebrew University in Jerusalem, \u00c9cole pratique des hautes \u00e9tudes and \u00c9cole Polytechnique in Paris, and John Jay College of Criminal Justice in New York City.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 47], [47, 48], [49, 55], [56, 66], [67, 69], [70, 79], [79, 80], [81, 86], [87, 95], [96, 99], [100, 106], [107, 113], [114, 117], [118, 123], [124, 137], [138, 140], [141, 146], [146, 147], [148, 151], [152, 156], [157, 160], [161, 168], [169, 171], [172, 180], [181, 188], [189, 191], [192, 195], [196, 200], [201, 205], [205, 206]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [4, 6, "task"], [12, 13, "researcher"], [15, 15, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "origin", "", false, false], [0, 0, 4, 6, "related-to", "", false, false], [4, 6, 15, 15, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "was", "an", "early", "natural", "language", "understanding", "computer", "programme", ",", "developed", "by", "Terry", "Winograd", "at", "MIT", "in", "1968", "-", "1970", "."], "sentence-detokenized": "SHRDLU was an early natural language understanding computer programme, developed by Terry Winograd at MIT in 1968-1970.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 19], [20, 27], [28, 36], [37, 50], [51, 59], [60, 69], [69, 70], [71, 80], [81, 83], [84, 89], [90, 98], [99, 101], [102, 105], [106, 108], [109, 113], [113, 114], [114, 118], [118, 119]]}
{"doc_key": "ai-test-253", "ner": [[3, 3, "misc"], [6, 7, "field"], [9, 13, "university"], [15, 15, "location"], [17, 17, "country"], [24, 25, "university"], [28, 28, "misc"], [31, 34, "field"], [38, 39, "university"], [43, 43, "misc"], [45, 47, "field"], [52, 52, "misc"], [61, 65, "university"], [70, 72, "field"], [75, 76, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[3, 3, 6, 7, "topic", "", false, false], [3, 3, 9, 13, "origin", "", false, false], [9, 13, 15, 15, "physical", "", false, false], [9, 13, 24, 25, "role", "affiliated_with", false, false], [15, 15, 17, 17, "physical", "", false, false], [28, 28, 31, 34, "topic", "", false, false], [28, 28, 38, 39, "origin", "", false, false], [43, 43, 45, 47, "topic", "", false, false], [52, 52, 61, 65, "origin", "", false, false], [52, 52, 70, 72, "topic", "", false, false], [75, 76, 61, 65, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["He", "received", "his", "B.E.", "degree", "in", "electrical", "engineering", "from", "B.M.S", ".", "College", "of", "Engineering", "in", "Bangalore", ",", "India", "in", "1982", ",", "while", "affiliated", "with", "Bangalore", "University", ",", "his", "M.S.", "degree", "in", "electrical", "and", "computer", "engineering", "in", "1984", "from", "Drexel", "University", ",", "and", "his", "M.S.", "in", "computer", "science", "in", "1989", ",", "and", "his", "Ph.D.", "degree", "in", "1990", ",", "respectively", ",", "from", "the", "University", "of", "Wisconsin", "-", "Madison", ",", "where", "he", "studied", "Artificial", "Intelligence", "and", "worked", "with", "Leonard", "Uhr", "."], "sentence-detokenized": "He received his B.E. degree in electrical engineering from B.M.S. College of Engineering in Bangalore, India in 1982, while affiliated with Bangalore University, his M.S. degree in electrical and computer engineering in 1984 from Drexel University, and his M.S. in computer science in 1989, and his Ph.D. degree in 1990, respectively, from the University of Wisconsin-Madison, where he studied Artificial Intelligence and worked with Leonard Uhr.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [21, 27], [28, 30], [31, 41], [42, 53], [54, 58], [59, 64], [64, 65], [66, 73], [74, 76], [77, 88], [89, 91], [92, 101], [101, 102], [103, 108], [109, 111], [112, 116], [116, 117], [118, 123], [124, 134], [135, 139], [140, 149], [150, 160], [160, 161], [162, 165], [166, 170], [171, 177], [178, 180], [181, 191], [192, 195], [196, 204], [205, 216], [217, 219], [220, 224], [225, 229], [230, 236], [237, 247], [247, 248], [249, 252], [253, 256], [257, 261], [262, 264], [265, 273], [274, 281], [282, 284], [285, 289], [289, 290], [291, 294], [295, 298], [299, 304], [305, 311], [312, 314], [315, 319], [319, 320], [321, 333], [333, 334], [335, 339], [340, 343], [344, 354], [355, 357], [358, 367], [367, 368], [368, 375], [375, 376], [377, 382], [383, 385], [386, 393], [394, 404], [405, 417], [418, 421], [422, 428], [429, 433], [434, 441], [442, 445], [445, 446]]}
{"doc_key": "ai-test-254", "ner": [[5, 7, "metrics"], [9, 9, "metrics"], [18, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "usually", "assessed", "by", "word", "error", "rate", "(", "WER", ")", ",", "while", "speed", "is", "measured", "by", "the", "real", "-", "time", "factor", "."], "sentence-detokenized": "Accuracy is usually assessed by word error rate (WER), while speed is measured by the real-time factor.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 28], [29, 31], [32, 36], [37, 42], [43, 47], [48, 49], [49, 52], [52, 53], [53, 54], [55, 60], [61, 66], [67, 69], [70, 78], [79, 81], [82, 85], [86, 90], [90, 91], [91, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-test-255", "ner": [[2, 3, "researcher"], [7, 9, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 7, 9, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", "Terry", "Winograd", "developed", "an", "early", "natural", "language", "processing", "engine", "capable", "of", "interpreting", "naturally", "written", "commands", "in", "an", "environment", "governed", "by", "simple", "rules", "."], "sentence-detokenized": "In 1971 Terry Winograd developed an early natural language processing engine capable of interpreting naturally written commands in an environment governed by simple rules.", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 22], [23, 32], [33, 35], [36, 41], [42, 49], [50, 58], [59, 69], [70, 76], [77, 84], [85, 87], [88, 100], [101, 110], [111, 118], [119, 127], [128, 130], [131, 133], [134, 145], [146, 154], [155, 157], [158, 164], [165, 170], [170, 171]]}
{"doc_key": "ai-test-256", "ner": [[1, 2, "field"], [4, 5, "researcher"], [7, 10, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 4, 5, "related-to", "", false, false], [1, 2, 7, 10, "related-to", "", false, false], [1, 2, 13, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "artificial", "intelligence", ",", "Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", ",", "and", "Allen", "Newell", "stand", "out", "."], "sentence-detokenized": "In artificial intelligence, Marvin Minsky, Herbert A. Simon, and Allen Newell stand out.", "token2charspan": [[0, 2], [3, 13], [14, 26], [26, 27], [28, 34], [35, 41], [41, 42], [43, 50], [51, 52], [52, 53], [54, 59], [59, 60], [61, 64], [65, 70], [71, 77], [78, 83], [84, 87], [87, 88]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [30, 31, "field"], [33, 34, "field"], [39, 41, "field"], [49, 52, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[30, 31, 9, 10, "origin", "", true, false], [30, 31, 9, 10, "part-of", "", false, false], [30, 31, 39, 41, "compare", "", false, false], [33, 34, 9, 10, "origin", "", true, false], [33, 34, 9, 10, "part-of", "", false, false], [33, 34, 39, 41, "compare", "", false, false], [39, 41, 9, 10, "origin", "", true, false], [39, 41, 9, 10, "part-of", "", false, false], [39, 41, 49, 52, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "the", "second", "half", "of", "the", "20th", "century", ",", "electrical", "engineering", "itself", "separated", "into", "several", "disciplines", ",", "specialising", "in", "the", "design", "and", "analysis", "of", "systems", "that", "manipulate", "physical", "signals", ";", "electronic", "engineering", "and", "computer", "engineering", "being", "examples", ";", "while", "design", "engineering", "was", "developed", "to", "handle", "the", "functional", "design", "of", "user", "-", "machine", "interfaces", "."], "sentence-detokenized": "In the second half of the 20th century, electrical engineering itself separated into several disciplines, specialising in the design and analysis of systems that manipulate physical signals; electronic engineering and computer engineering being examples; while design engineering was developed to handle the functional design of user-machine interfaces.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 30], [31, 38], [38, 39], [40, 50], [51, 62], [63, 69], [70, 79], [80, 84], [85, 92], [93, 104], [104, 105], [106, 118], [119, 121], [122, 125], [126, 132], [133, 136], [137, 145], [146, 148], [149, 156], [157, 161], [162, 172], [173, 181], [182, 189], [189, 190], [191, 201], [202, 213], [214, 217], [218, 226], [227, 238], [239, 244], [245, 253], [253, 254], [255, 260], [261, 267], [268, 279], [280, 283], [284, 293], [294, 296], [297, 303], [304, 307], [308, 318], [319, 325], [326, 328], [329, 333], [333, 334], [334, 341], [342, 352], [352, 353]]}
{"doc_key": "ai-test-258", "ner": [[5, 5, "metrics"], [7, 8, "metrics"], [10, 10, "metrics"], [46, 48, "metrics"], [55, 56, "metrics"], [57, 67, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 10, 7, 8, "named", "", false, false], [46, 48, 55, 56, "named", "", false, false], [55, 56, 57, 67, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Perhaps", "the", "simplest", "statistic", "is", "accuracy", "or", "Fraction", "Correct", "(", "FC", ")", ",", "which", "measures", "the", "fraction", "of", "all", "examples", "that", "are", "correctly", "categorised", ";", "it", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "Total", "Population", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Perhaps the simplest statistic is accuracy or Fraction Correct (FC), which measures the fraction of all examples that are correctly categorised; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN) / Total Population = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 30], [31, 33], [34, 42], [43, 45], [46, 54], [55, 62], [63, 64], [64, 66], [66, 67], [67, 68], [69, 74], [75, 83], [84, 87], [88, 96], [97, 99], [100, 103], [104, 112], [113, 117], [118, 121], [122, 131], [132, 143], [143, 144], [145, 147], [148, 150], [151, 154], [155, 160], [161, 163], [164, 167], [168, 174], [175, 177], [178, 185], [186, 201], [202, 204], [205, 208], [209, 214], [215, 221], [222, 224], [225, 232], [233, 235], [236, 245], [246, 261], [261, 262], [263, 264], [264, 266], [267, 268], [269, 271], [271, 272], [273, 274], [275, 280], [281, 291], [292, 293], [294, 295], [295, 297], [298, 299], [300, 302], [302, 303], [304, 305], [306, 307], [307, 309], [310, 311], [312, 314], [315, 316], [317, 319], [320, 321], [322, 324], [324, 325], [325, 326]]}
{"doc_key": "ai-test-259", "ner": [[15, 23, "conference"], [25, 27, "conference"], [31, 31, "location"], [36, 36, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 23, 31, 31, "physical", "", false, false], [25, 27, 15, 23, "named", "", false, false], [36, 36, 15, 23, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "academic", "community", ",", "the", "main", "forum", "for", "research", "began", "in", "1995", "when", "the", "First", "International", "Conference", "on", "Data", "Mining", "and", "Knowledge", "Discovery", "(", "KDD", "-", "95", ")", "started", "in", "Montreal", "under", "the", "sponsorship", "of", "AAAI", "."], "sentence-detokenized": "In the academic community, the main forum for research began in 1995 when the First International Conference on Data Mining and Knowledge Discovery (KDD-95) started in Montreal under the sponsorship of AAAI.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 25], [25, 26], [27, 30], [31, 35], [36, 41], [42, 45], [46, 54], [55, 60], [61, 63], [64, 68], [69, 73], [74, 77], [78, 83], [84, 97], [98, 108], [109, 111], [112, 116], [117, 123], [124, 127], [128, 137], [138, 147], [148, 149], [149, 152], [152, 153], [153, 155], [155, 156], [157, 164], [165, 167], [168, 176], [177, 182], [183, 186], [187, 198], [199, 201], [202, 206], [206, 207]]}
{"doc_key": "ai-test-260", "ner": [[9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "approach", ",", "models", "are", "developed", "using", "different", "data", "mining", ",", "machine", "learning", "algorithms", "to", "predict", "user", "ratings", "from", "unrated", "items", "."], "sentence-detokenized": "In this approach, models are developed using different data mining, machine learning algorithms to predict user ratings from unrated items.", "token2charspan": [[0, 2], [3, 7], [8, 16], [16, 17], [18, 24], [25, 28], [29, 38], [39, 44], [45, 54], [55, 59], [60, 66], [66, 67], [68, 75], [76, 84], [85, 95], [96, 98], [99, 106], [107, 111], [112, 119], [120, 124], [125, 132], [133, 138], [138, 139]]}
{"doc_key": "ai-test-261", "ner": [[10, 10, "algorithm"], [15, 16, "algorithm"], [18, 19, "algorithm"], [26, 27, "misc"], [30, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 10, 15, 16, "related-to", "equivalent", false, false], [15, 16, 18, 19, "usage", "", false, false], [18, 19, 30, 31, "usage", "", false, false], [30, 31, 26, 27, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Based", "on", "the", "above", "discussion", ",", "we", "see", "that", "the", "SVM", "technique", "is", "equivalent", "to", "empirical", "risk", "with", "Tikhonov", "regularization", ",", "where", "in", "this", "case", "the", "loss", "function", "is", "the", "hinge", "loss", "."], "sentence-detokenized": "Based on the above discussion, we see that the SVM technique is equivalent to empirical risk with Tikhonov regularization, where in this case the loss function is the hinge loss.", "token2charspan": [[0, 5], [6, 8], [9, 12], [13, 18], [19, 29], [29, 30], [31, 33], [34, 37], [38, 42], [43, 46], [47, 50], [51, 60], [61, 63], [64, 74], [75, 77], [78, 87], [88, 92], [93, 97], [98, 106], [107, 121], [121, 122], [123, 128], [129, 131], [132, 136], [137, 141], [142, 145], [146, 150], [151, 159], [160, 162], [163, 166], [167, 172], [173, 177], [177, 178]]}
{"doc_key": "ai-test-262", "ner": [[6, 7, "person"], [10, 11, "person"], [14, 14, "organisation"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 17, 14, 14, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "2015", "edition", "was", "hosted", "by", "Molly", "McGrath", ",", "with", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "as", "commentators", "."], "sentence-detokenized": "The 2015 edition was hosted by Molly McGrath, with Chris Rose and former UFC fighter Kenny Florian as commentators.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 27], [28, 30], [31, 36], [37, 44], [44, 45], [46, 50], [51, 56], [57, 61], [62, 65], [66, 72], [73, 76], [77, 84], [85, 90], [91, 98], [99, 101], [102, 114], [114, 115]]}
{"doc_key": "ai-test-263", "ner": [[3, 5, "product"], [9, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [18, 18, "researcher"], [23, 23, "researcher"], [28, 29, "researcher"], [30, 32, "task"], [34, 34, "product"], [36, 37, "researcher"], [39, 40, "task"], [43, 44, "researcher"], [48, 49, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[3, 5, 9, 11, "origin", "", false, false], [3, 5, 13, 14, "origin", "", false, false], [3, 5, 16, 17, "origin", "", false, false], [3, 5, 18, 18, "origin", "", false, false], [13, 14, 36, 37, "named", "same", false, false], [16, 17, 23, 23, "named", "same", false, false], [16, 17, 28, 29, "named", "same", false, false], [30, 32, 34, 34, "related-to", "", false, false], [34, 34, 28, 29, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["A", "subset", "called", "Micro", "-", "Planner", "was", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "Sussman", ",", ",", ",", "and", "Winograd", "1971", "and", "used", "in", "Winograd", "'s", "natural", "language", "understanding", "programme", "SHRDLU", ",", "Eugene", "Charniak", "'s", "story", "understanding", "work", ",", "Thorne", "McCarty", "'s", "work", "on", "legal", "reasoning", ",", "and", "several", "other", "projects", "."], "sentence-detokenized": "A subset called Micro-Planner was implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd Sussman,,, and Winograd 1971 and used in Winograd's natural language understanding programme SHRDLU, Eugene Charniak's story understanding work, Thorne McCarty's work on legal reasoning, and several other projects.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [21, 22], [22, 29], [30, 33], [34, 45], [46, 48], [49, 55], [56, 59], [60, 67], [67, 68], [69, 75], [76, 84], [85, 88], [89, 94], [95, 103], [104, 111], [111, 112], [112, 113], [113, 114], [115, 118], [119, 127], [128, 132], [133, 136], [137, 141], [142, 144], [145, 153], [153, 155], [156, 163], [164, 172], [173, 186], [187, 196], [197, 203], [203, 204], [205, 211], [212, 220], [220, 222], [223, 228], [229, 242], [243, 247], [247, 248], [249, 255], [256, 263], [263, 265], [266, 270], [271, 273], [274, 279], [280, 289], [289, 290], [291, 294], [295, 302], [303, 308], [309, 317], [317, 318]]}
{"doc_key": "ai-test-264", "ner": [[0, 1, "product"], [11, 12, "product"], [15, 17, "task"], [19, 20, "task"], [22, 24, "task"], [26, 27, "task"], [29, 30, "task"], [33, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 0, 1, "usage", "", true, false], [15, 17, 11, 12, "part-of", "", true, false], [19, 20, 11, 12, "part-of", "", true, false], [22, 24, 11, 12, "part-of", "", true, false], [26, 27, 11, 12, "part-of", "", true, false], [29, 30, 11, 12, "part-of", "", true, false], [33, 36, 11, 12, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "has", "been", "used", "for", "a", "number", "of", "purposes", "in", "information", "systems", ",", "including", "word", "meaning", "disambiguation", ",", "information", "retrieval", ",", "automatic", "text", "classification", ",", "automatic", "summarisation", ",", "machine", "translation", "and", "even", "automatic", "crossword", "puzzle", "generation", "."], "sentence-detokenized": "WordNet has been used for a number of purposes in information systems, including word meaning disambiguation, information retrieval, automatic text classification, automatic summarisation, machine translation and even automatic crossword puzzle generation.", "token2charspan": [[0, 4], [4, 7], [8, 11], [12, 16], [17, 21], [22, 25], [26, 27], [28, 34], [35, 37], [38, 46], [47, 49], [50, 61], [62, 69], [69, 70], [71, 80], [81, 85], [86, 93], [94, 108], [108, 109], [110, 121], [122, 131], [131, 132], [133, 142], [143, 147], [148, 162], [162, 163], [164, 173], [174, 187], [187, 188], [189, 196], [197, 208], [209, 212], [213, 217], [218, 227], [228, 237], [238, 244], [245, 255], [255, 256]]}
{"doc_key": "ai-test-265", "ner": [[0, 0, "researcher"], [7, 7, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 7, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "was", "named", "a", "Fellow", "of", "the", "IEEE", "in", "1996", "."], "sentence-detokenized": "Keutzer was named a Fellow of the IEEE in 1996.", "token2charspan": [[0, 7], [8, 11], [12, 17], [18, 19], [20, 26], [27, 29], [30, 33], [34, 38], [39, 41], [42, 46], [46, 47]]}
{"doc_key": "ai-test-266", "ner": [[7, 9, "algorithm"], [55, 56, "misc"], [65, 66, "algorithm"], [68, 69, "algorithm"], [71, 72, "algorithm"], [75, 76, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[65, 66, 55, 56, "type-of", "", false, false], [68, 69, 55, 56, "type-of", "", false, false], [71, 72, 55, 56, "type-of", "", false, false], [75, 76, 55, 56, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "widely", "used", "type", "of", "composition", "is", "nonlinear", "weighted", "summation", ",", "where", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "left", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "right", ")", "/", "math", ",", "where", "math", "\\", "textstyle", "K", "/", "math", "(", "commonly", "referred", "to", "as", "activation", "function", ")", "is", "some", "predefined", "function", ",", "such", "as", "hyperbolic", "tangent", ",", "sigmoid", "function", ",", "softmax", "function", ",", "or", "rectifier", "function", "."], "sentence-detokenized": "A widely used type of composition is nonlinear weighted summation, where math\\ textstyle f (x) = K\\ left (\\ sum _ i w _ i g _ i (x) \\ right) / math, where math\\ textstyle K / math (commonly referred to as activation function) is some predefined function, such as hyperbolic tangent, sigmoid function, softmax function, or rectifier function.", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 18], [19, 21], [22, 33], [34, 36], [37, 46], [47, 55], [56, 65], [65, 66], [67, 72], [73, 77], [77, 78], [79, 88], [89, 90], [91, 92], [92, 93], [93, 94], [95, 96], [97, 98], [98, 99], [100, 104], [105, 106], [106, 107], [108, 111], [112, 113], [114, 115], [116, 117], [118, 119], [120, 121], [122, 123], [124, 125], [126, 127], [128, 129], [129, 130], [130, 131], [132, 133], [134, 139], [139, 140], [141, 142], [143, 147], [147, 148], [149, 154], [155, 159], [159, 160], [161, 170], [171, 172], [173, 174], [175, 179], [180, 181], [181, 189], [190, 198], [199, 201], [202, 204], [205, 215], [216, 224], [224, 225], [226, 228], [229, 233], [234, 244], [245, 253], [253, 254], [255, 259], [260, 262], [263, 273], [274, 281], [281, 282], [283, 290], [291, 299], [299, 300], [301, 308], [309, 317], [317, 318], [319, 321], [322, 331], [332, 340], [340, 341]]}
{"doc_key": "ai-test-267", "ner": [[3, 3, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "film", "Westworld", ",", "female", "robots", "actually", "engage", "in", "sexual", "relations", "with", "human", "men", "as", "part", "of", "a", "made", "-", "up", "holiday", "world", ",", "which", "human", "customers", "pay", "to", "attend", "."], "sentence-detokenized": "In the film Westworld, female robots actually engage in sexual relations with human men as part of a made-up holiday world, which human customers pay to attend.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 21], [21, 22], [23, 29], [30, 36], [37, 45], [46, 52], [53, 55], [56, 62], [63, 72], [73, 77], [78, 83], [84, 87], [88, 90], [91, 95], [96, 98], [99, 100], [101, 105], [105, 106], [106, 108], [109, 116], [117, 122], [122, 123], [124, 129], [130, 135], [136, 145], [146, 149], [150, 152], [153, 159], [159, 160]]}
{"doc_key": "ai-test-268", "ner": [[7, 9, "task"], [23, 28, "task"], [30, 31, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 23, 28, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Typically", ",", "the", "process", "starts", "with", "the", "extraction", "of", "terminology", "and", "concepts", "or", "noun", "phrases", "from", "plain", "text", "using", "linguistic", "processors", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "phrase", "chunking", "."], "sentence-detokenized": "Typically, the process starts with the extraction of terminology and concepts or noun phrases from plain text using linguistic processors such as part-of-speech tagging and phrase chunking.", "token2charspan": [[0, 9], [9, 10], [11, 14], [15, 22], [23, 29], [30, 34], [35, 38], [39, 49], [50, 52], [53, 64], [65, 68], [69, 77], [78, 80], [81, 85], [86, 93], [94, 98], [99, 104], [105, 109], [110, 115], [116, 126], [127, 137], [138, 142], [143, 145], [146, 150], [150, 151], [151, 153], [153, 154], [154, 160], [161, 168], [169, 172], [173, 179], [180, 188], [188, 189]]}
{"doc_key": "ai-test-269", "ner": [[13, 14, "field"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "demonstrated", "their", "performance", "on", "a", "number", "of", "problems", "of", "interest", "to", "the", "machine", "learning", "community", ",", "including", "handwriting", "recognition", "."], "sentence-detokenized": "They demonstrated their performance on a number of problems of interest to the machine learning community, including handwriting recognition.", "token2charspan": [[0, 4], [5, 17], [18, 23], [24, 35], [36, 38], [39, 40], [41, 47], [48, 50], [51, 59], [60, 62], [63, 71], [72, 74], [75, 78], [79, 86], [87, 95], [96, 105], [105, 106], [107, 116], [117, 128], [129, 140], [140, 141]]}
{"doc_key": "ai-test-270", "ner": [[3, 3, "university"], [5, 6, "researcher"], [12, 15, "researcher"], [18, 18, "product"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 3, 3, "physical", "", false, false], [5, 6, 3, 3, "role", "", false, false], [18, 18, 12, 15, "origin", "", false, false], [18, 18, 22, 23, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "studying", "at", "Stanford", ",", "Scheinman", "was", "awarded", "a", "scholarship", "sponsored", "by", "George", "Devol", ",", "the", "inventor", "of", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "While studying at Stanford, Scheinman was awarded a scholarship sponsored by George Devol, the inventor of Unimate, the first industrial robot.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [26, 27], [28, 37], [38, 41], [42, 49], [50, 51], [52, 63], [64, 73], [74, 76], [77, 83], [84, 89], [89, 90], [91, 94], [95, 103], [104, 106], [107, 114], [114, 115], [116, 119], [120, 125], [126, 136], [137, 142], [142, 143]]}
{"doc_key": "ai-test-271", "ner": [[5, 6, "task"], [9, 11, "metrics"], [13, 13, "metrics"], [21, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 9, 11, "usage", "", true, false], [13, 13, 9, 11, "named", "", false, false], [21, 22, 9, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Although", "originally", "used", "to", "evaluate", "machine", "translation", ",", "the", "bilingual", "understudy", "evaluation", "(", "BLEU", ")", "has", "been", "successfully", "used", "to", "evaluate", "paraphrasing", "models", "as", "well", "."], "sentence-detokenized": "Although originally used to evaluate machine translation, the bilingual understudy evaluation (BLEU) has been successfully used to evaluate paraphrasing models as well.", "token2charspan": [[0, 8], [9, 19], [20, 24], [25, 27], [28, 36], [37, 44], [45, 56], [56, 57], [58, 61], [62, 71], [72, 82], [83, 93], [94, 95], [95, 99], [99, 100], [101, 104], [105, 109], [110, 122], [123, 127], [128, 130], [131, 139], [140, 152], [153, 159], [160, 162], [163, 167], [167, 168]]}
{"doc_key": "ai-test-272", "ner": [[0, 0, "organisation"], [6, 8, "organisation"], [10, 10, "organisation"], [13, 13, "product"], [15, 15, "country"], [18, 19, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 8, "role", "licenses_to", false, false], [0, 0, 10, 10, "role", "licenses_to", false, false], [6, 8, 15, 15, "physical", "", false, false], [10, 10, 18, 19, "physical", "", false, false], [13, 13, 6, 8, "artifact", "produces", false, false], [13, 13, 10, 10, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "then", "licensed", "the", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "producing", "Unimates", "in", "Japan", "and", "the", "UK", "respectively", "."], "sentence-detokenized": "Unimation then licensed the technology to Kawasaki Heavy Industries and GKN, producing Unimates in Japan and the UK respectively.", "token2charspan": [[0, 9], [10, 14], [15, 23], [24, 27], [28, 38], [39, 41], [42, 50], [51, 56], [57, 67], [68, 71], [72, 75], [75, 76], [77, 86], [87, 95], [96, 98], [99, 104], [105, 108], [109, 112], [113, 115], [116, 128], [128, 129]]}
{"doc_key": "ai-test-273", "ner": [[19, 20, "conference"], [37, 38, "field"], [56, 60, "field"], [62, 62, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[37, 38, 56, 60, "compare", "", false, false], [62, 62, 56, 60, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "confusion", "between", "these", "two", "research", "communities", "(", "which", "often", "have", "separate", "conferences", "and", "separate", "journals", ",", "ECML", "PKDD", "being", "a", "major", "exception", ")", "stems", "from", "the", "basic", "assumptions", "on", "which", "they", "work", ":", "in", "machine", "learning", ",", "performance", "is", "usually", "evaluated", "with", "respect", "to", "the", "ability", "to", "reproduce", "known", "knowledge", ",", "while", "in", "knowledge", "discovery", "and", "data", "mining", "(", "KDD", ")", "the", "main", "task", "is", "the", "discovery", "of", "previously", "unknown", "knowledge", "."], "sentence-detokenized": "Much of the confusion between these two research communities (which often have separate conferences and separate journals, ECML PKDD being a major exception) stems from the basic assumptions on which they work: in machine learning, performance is usually evaluated with respect to the ability to reproduce known knowledge, while in knowledge discovery and data mining (KDD) the main task is the discovery of previously unknown knowledge.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 29], [30, 35], [36, 39], [40, 48], [49, 60], [61, 62], [62, 67], [68, 73], [74, 78], [79, 87], [88, 99], [100, 103], [104, 112], [113, 121], [121, 122], [123, 127], [128, 132], [133, 138], [139, 140], [141, 146], [147, 156], [156, 157], [158, 163], [164, 168], [169, 172], [173, 178], [179, 190], [191, 193], [194, 199], [200, 204], [205, 209], [209, 210], [211, 213], [214, 221], [222, 230], [230, 231], [232, 243], [244, 246], [247, 254], [255, 264], [265, 269], [270, 277], [278, 280], [281, 284], [285, 292], [293, 295], [296, 305], [306, 311], [312, 321], [321, 322], [323, 328], [329, 331], [332, 341], [342, 351], [352, 355], [356, 360], [361, 367], [368, 369], [369, 372], [372, 373], [374, 377], [378, 382], [383, 387], [388, 390], [391, 394], [395, 404], [405, 407], [408, 418], [419, 426], [427, 436], [436, 437]]}
{"doc_key": "ai-test-274", "ner": [[0, 1, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hidden", "Markov", "models", "are", "the", "basis", "for", "most", "modern", "automatic", "speech", "recognition", "systems", "."], "sentence-detokenized": "Hidden Markov models are the basis for most modern automatic speech recognition systems.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 28], [29, 34], [35, 38], [39, 43], [44, 50], [51, 60], [61, 67], [68, 79], [80, 87], [87, 88]]}
{"doc_key": "ai-test-275", "ner": [[3, 3, "location"], [5, 5, "country"], [10, 11, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 5, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["a", "company", "in", "Bangalore", ",", "India", "that", "specialises", "in", "online", "handwriting", "recognition", "software", "."], "sentence-detokenized": "a company in Bangalore, India that specialises in online handwriting recognition software.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 22], [22, 23], [24, 29], [30, 34], [35, 46], [47, 49], [50, 56], [57, 68], [69, 80], [81, 89], [89, 90]]}
{"doc_key": "ai-test-276", "ner": [[24, 25, "misc"], [48, 48, "metrics"], [50, 52, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[48, 48, 50, 52, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Do", "repeated", "translations", "converge", "on", "a", "single", "expression", "in", "both", "languages", "?", "That", "is", ",", "does", "the", "translation", "method", "show", "stationarity", "or", "produce", "a", "canonical", "form", "?", "Does", "the", "translation", "become", "stationary", "without", "losing", "the", "original", "meaning", "?", "This", "metric", "has", "been", "criticised", "for", "not", "correlating", "well", "with", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "scores", "."], "sentence-detokenized": "Do repeated translations converge on a single expression in both languages? That is, does the translation method show stationarity or produce a canonical form? Does the translation become stationary without losing the original meaning? This metric has been criticised for not correlating well with BLEU (BiLingual Evaluation Understudy) scores.", "token2charspan": [[0, 2], [3, 11], [12, 24], [25, 33], [34, 36], [37, 38], [39, 45], [46, 56], [57, 59], [60, 64], [65, 74], [74, 75], [76, 80], [81, 83], [83, 84], [85, 89], [90, 93], [94, 105], [106, 112], [113, 117], [118, 130], [131, 133], [134, 141], [142, 143], [144, 153], [154, 158], [158, 159], [160, 164], [165, 168], [169, 180], [181, 187], [188, 198], [199, 206], [207, 213], [214, 217], [218, 226], [227, 234], [234, 235], [236, 240], [241, 247], [248, 251], [252, 256], [257, 267], [268, 271], [272, 275], [276, 287], [288, 292], [293, 297], [298, 302], [303, 304], [304, 313], [314, 324], [325, 335], [335, 336], [337, 343], [343, 344]]}
{"doc_key": "ai-test-277", "ner": [[5, 9, "organisation"], [11, 18, "organisation"], [20, 21, "university"], [23, 23, "university"], [26, 27, "field"], [29, 33, "organisation"], [35, 37, "organisation"], [46, 49, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 18, 20, 21, "part-of", "", false, false], [23, 23, 26, 27, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "holds", "fellowships", "at", "the", "American", "Association", "for", "Artificial", "Intelligence", ",", "Center", "for", "Advanced", "Study", "in", "the", "Behavioural", "Sciences", "at", "Stanford", "University", ",", "MIT", "Center", "for", "Cognitive", "Science", ",", "Canadian", "Institute", "for", "Advanced", "Research", ",", "Canadian", "Psychological", "Association", ",", "and", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "in", "1998", "."], "sentence-detokenized": "He holds fellowships at the American Association for Artificial Intelligence, Center for Advanced Study in the Behavioural Sciences at Stanford University, MIT Center for Cognitive Science, Canadian Institute for Advanced Research, Canadian Psychological Association, and was elected a Fellow of the Royal Society of Canada in 1998.", "token2charspan": [[0, 2], [3, 8], [9, 20], [21, 23], [24, 27], [28, 36], [37, 48], [49, 52], [53, 63], [64, 76], [76, 77], [78, 84], [85, 88], [89, 97], [98, 103], [104, 106], [107, 110], [111, 122], [123, 131], [132, 134], [135, 143], [144, 154], [154, 155], [156, 159], [160, 166], [167, 170], [171, 180], [181, 188], [188, 189], [190, 198], [199, 208], [209, 212], [213, 221], [222, 230], [230, 231], [232, 240], [241, 254], [255, 266], [266, 267], [268, 271], [272, 275], [276, 283], [284, 285], [286, 292], [293, 295], [296, 299], [300, 305], [306, 313], [314, 316], [317, 323], [324, 326], [327, 331], [331, 332]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [17, 19, "misc"], [22, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 17, 19, "part-of", "", false, false], [0, 0, 22, 25, "part-of", "", false, false], [4, 5, 17, 19, "part-of", "", false, false], [4, 5, 22, 25, "part-of", "", false, false], [7, 8, 17, 19, "part-of", "", false, false], [7, 8, 22, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "-", "along", "with", "Yoshua", "Bengio", "and", "Yann", "LeCun", "-", "is", "referred", "to", "by", "some", "as", "the", "Godfather", "of", "AI", "and", "the", "Godfather", "of", "Deep", "Learning", "."], "sentence-detokenized": "Hinton - along with Yoshua Bengio and Yann LeCun - is referred to by some as the Godfather of AI and the Godfather of Deep Learning.", "token2charspan": [[0, 6], [7, 8], [9, 14], [15, 19], [20, 26], [27, 33], [34, 37], [38, 42], [43, 48], [49, 50], [51, 53], [54, 62], [63, 65], [66, 68], [69, 73], [74, 76], [77, 80], [81, 90], [91, 93], [94, 96], [97, 100], [101, 104], [105, 114], [115, 117], [118, 122], [123, 131], [131, 132]]}
{"doc_key": "ai-test-279", "ner": [[7, 7, "product"], [20, 20, "misc"], [22, 23, "misc"], [24, 24, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 7, 20, 20, "related-to", "", false, false], [7, 7, 22, 23, "related-to", "", false, false], [20, 20, 24, 24, "named", "same", false, false], [28, 29, 24, 24, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "lightweight", "open", "-", "source", "speech", "project", "eSpeak", ",", "which", "has", "its", "own", "approach", "to", "synthesis", ",", "has", "experimented", "with", "Mandarin", "and", "Cantonese", ".", "eSpeak", "was", "used", "by", "Google", "Translate", "from", "May", "20102010", "."], "sentence-detokenized": "The lightweight open-source speech project eSpeak, which has its own approach to synthesis, has experimented with Mandarin and Cantonese. eSpeak was used by Google Translate from May 20102010.", "token2charspan": [[0, 3], [4, 15], [16, 20], [20, 21], [21, 27], [28, 34], [35, 42], [43, 49], [49, 50], [51, 56], [57, 60], [61, 64], [65, 68], [69, 77], [78, 80], [81, 90], [90, 91], [92, 95], [96, 108], [109, 113], [114, 122], [123, 126], [127, 136], [136, 137], [138, 144], [145, 148], [149, 153], [154, 156], [157, 163], [164, 173], [174, 178], [179, 182], [183, 191], [191, 192]]}
{"doc_key": "ai-test-280", "ner": [[5, 7, "product"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Also", "released", "in", "1982", ",", "Software", "Automatic", "Mouth", "was", "the", "first", "commercial", "all", "-", "software", "voice", "synthesis", "programme", "."], "sentence-detokenized": "Also released in 1982, Software Automatic Mouth was the first commercial all-software voice synthesis programme.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 21], [21, 22], [23, 31], [32, 41], [42, 47], [48, 51], [52, 55], [56, 61], [62, 72], [73, 76], [76, 77], [77, 85], [86, 91], [92, 101], [102, 111], [111, 112]]}
{"doc_key": "ai-test-281", "ner": [[4, 6, "metrics"], [8, 8, "metrics"], [11, 11, "metrics"], [13, 13, "metrics"], [16, 23, "metrics"], [28, 30, "metrics"], [32, 32, "metrics"], [36, 41, "metrics"], [45, 47, "metrics"], [49, 49, "metrics"], [52, 52, "metrics"], [54, 54, "metrics"], [58, 64, "metrics"], [69, 71, "metrics"], [73, 73, "metrics"], [76, 83, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[8, 8, 4, 6, "named", "", false, false], [11, 11, 4, 6, "named", "", false, false], [13, 13, 4, 6, "named", "", false, false], [16, 23, 4, 6, "named", "", false, false], [32, 32, 28, 30, "named", "", false, false], [36, 41, 28, 30, "named", "", false, false], [49, 49, 45, 47, "named", "", false, false], [52, 52, 45, 47, "named", "", false, false], [54, 54, 45, 47, "named", "", false, false], [58, 64, 45, 47, "named", "", false, false], [73, 73, 69, 71, "named", "", false, false], [76, 83, 69, 71, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["The", "ratio", "columns", "are", "TRUE", "Positive", "Rate", "(", "TPR", ",", "aka", "Sensitivity", "or", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "with", "the", "complement", "FALSE", "Negative", "Rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "and", "TRUE", "Negative", "Rate", "(", "TNR", ",", "aka", "Specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "with", "the", "complement", "FALSE", "Positive", "Rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "The ratio columns are TRUE Positive Rate (TPR, aka Sensitivity or recall) (TP / (TP + FN)), with the complement FALSE Negative Rate (FNR) (FN / (TP + FN)); and TRUE Negative Rate (TNR, aka Specificity, SPC) (TN / (TN + FP)), with the complement FALSE Positive Rate (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 21], [22, 26], [27, 35], [36, 40], [41, 42], [42, 45], [45, 46], [47, 50], [51, 62], [63, 65], [66, 72], [72, 73], [74, 75], [75, 77], [78, 79], [80, 81], [81, 83], [84, 85], [86, 88], [88, 89], [89, 90], [90, 91], [92, 96], [97, 100], [101, 111], [112, 117], [118, 126], [127, 131], [132, 133], [133, 136], [136, 137], [138, 139], [139, 141], [142, 143], [144, 145], [145, 147], [148, 149], [150, 152], [152, 153], [153, 154], [154, 155], [156, 159], [160, 164], [165, 173], [174, 178], [179, 180], [180, 183], [183, 184], [185, 188], [189, 200], [200, 201], [202, 205], [205, 206], [207, 208], [208, 210], [211, 212], [213, 214], [214, 216], [217, 218], [219, 221], [221, 222], [222, 223], [223, 224], [225, 229], [230, 233], [234, 244], [245, 250], [251, 259], [260, 264], [265, 266], [266, 269], [269, 270], [271, 272], [272, 274], [275, 276], [277, 278], [278, 280], [281, 282], [283, 285], [285, 286], [286, 287], [287, 288]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 15, 15, "role", "working_with", false, false], [2, 2, 15, 15, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "and", "Weber", "also", "collaborated", "on", "many", "other", "robots", ",", "and", "their", "experience", "working", "with", "Kismet"], "sentence-detokenized": "Edsinger and Weber also collaborated on many other robots, and their experience working with Kismet", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 36], [37, 39], [40, 44], [45, 50], [51, 57], [57, 58], [59, 62], [63, 68], [69, 79], [80, 87], [88, 92], [93, 99]]}
{"doc_key": "ai-test-283", "ner": [[0, 0, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 11, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["R", "functionality", "can", "be", "accessed", "from", "several", "scripting", "languages", "such", "as", "Python", ",", "as", "well", "."], "sentence-detokenized": "R functionality can be accessed from several scripting languages such as Python, as well.", "token2charspan": [[0, 1], [2, 15], [16, 19], [20, 22], [23, 31], [32, 36], [37, 44], [45, 54], [55, 64], [65, 69], [70, 72], [73, 79], [79, 80], [81, 83], [84, 88], [88, 89]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "is", "one", "of", "the", "first", "robot", "languages", "and", "is", "used", "in", "Unimate", "robots", "."], "sentence-detokenized": "VAL is one of the first robot languages and is used in Unimate robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 13], [14, 17], [18, 23], [24, 29], [30, 39], [40, 43], [44, 46], [47, 51], [52, 54], [55, 62], [63, 69], [69, 70]]}
{"doc_key": "ai-test-285", "ner": [[13, 22, "conference"], [20, 20, "conference"], [24, 24, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 22, 24, 24, "physical", "", false, false], [20, 20, 13, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["They", "presented", "their", "database", "for", "the", "first", "time", "as", "a", "poster", "at", "the", "2009", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "Conference", "in", "Florida", "."], "sentence-detokenized": "They presented their database for the first time as a poster at the 2009 Computer Vision and Pattern Recognition (CVPR) Conference in Florida.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 29], [30, 33], [34, 37], [38, 43], [44, 48], [49, 51], [52, 53], [54, 60], [61, 63], [64, 67], [68, 72], [73, 81], [82, 88], [89, 92], [93, 100], [101, 112], [113, 114], [114, 118], [118, 119], [120, 130], [131, 133], [134, 141], [141, 142]]}
{"doc_key": "ai-test-286", "ner": [[0, 1, "misc"], [11, 12, "task"], [14, 15, "field"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 0, 1, "type-of", "", false, false], [14, 15, 0, 1, "type-of", "", false, false], [17, 18, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Categorisation", "tasks", "where", "no", "labels", "are", "provided", "are", "referred", "to", "as", "unsupervised", "classification", ",", "unsupervised", "learning", ",", "Cluster", "analysis", "."], "sentence-detokenized": "Categorisation tasks where no labels are provided are referred to as unsupervised classification, unsupervised learning, Cluster analysis.", "token2charspan": [[0, 14], [15, 20], [21, 26], [27, 29], [30, 36], [37, 40], [41, 49], [50, 53], [54, 62], [63, 65], [66, 68], [69, 81], [82, 96], [96, 97], [98, 110], [111, 119], [119, 120], [121, 128], [129, 137], [137, 138]]}
{"doc_key": "ai-test-287", "ner": [[1, 2, "task"], [10, 11, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Need", "object", "recognition", ",", "recognising", "and", "locating", "humans", "and", "further", "emotion", "recognition", "."], "sentence-detokenized": "Need object recognition, recognising and locating humans and further emotion recognition.", "token2charspan": [[0, 4], [5, 11], [12, 23], [23, 24], [25, 36], [37, 40], [41, 49], [50, 56], [57, 60], [61, 68], [69, 76], [77, 88], [88, 89]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [8, 8, "misc"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "process", "is", "complex", "and", "contains", "encoding", "and", "recall", "or", "retrieval", "."], "sentence-detokenized": "The process is complex and contains encoding and recall or retrieval.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 26], [27, 35], [36, 44], [45, 48], [49, 55], [56, 58], [59, 68], [68, 69]]}
{"doc_key": "ai-test-289", "ner": [[8, 9, "product"], [12, 13, "product"], [29, 30, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 12, 13, "named", "", false, false], [8, 9, 29, 30, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Also", "known", "as", "parallel", "robots", ",", "or", "generalised", "Stewart", "platforms", "(", "in", "Stewart", "platforms", ",", "actuators", "are", "paired", "together", "on", "the", "base", "and", "platform", ")", ",", "these", "systems", "are", "articulated", "robots", "that", "use", "similar", "mechanisms", "for", "movement", "of", "the", "robot", "at", "its", "base", ",", "or", "one", "or", "more", "manipulator", "arms", "."], "sentence-detokenized": "Also known as parallel robots, or generalised Stewart platforms (in Stewart platforms, actuators are paired together on the base and platform), these systems are articulated robots that use similar mechanisms for movement of the robot at its base, or one or more manipulator arms.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 29], [29, 30], [31, 33], [34, 45], [46, 53], [54, 63], [64, 65], [65, 67], [68, 75], [76, 85], [85, 86], [87, 96], [97, 100], [101, 107], [108, 116], [117, 119], [120, 123], [124, 128], [129, 132], [133, 141], [141, 142], [142, 143], [144, 149], [150, 157], [158, 161], [162, 173], [174, 180], [181, 185], [186, 189], [190, 197], [198, 208], [209, 212], [213, 221], [222, 224], [225, 228], [229, 234], [235, 237], [238, 241], [242, 246], [246, 247], [248, 250], [251, 254], [255, 257], [258, 262], [263, 274], [275, 279], [279, 280]]}
{"doc_key": "ai-test-290", "ner": [[0, 1, "field"], [4, 5, "field"], [12, 13, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 5, "part-of", "subfield", false, false], [0, 1, 12, 13, "compare", "", false, false], [12, 13, 18, 19, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "vision", "as", "a", "systems", "engineering", "discipline", "can", "be", "considered", "distinct", "from", "computer", "vision", ",", "a", "form", "of", "computer", "science", "."], "sentence-detokenized": "Machine vision as a systems engineering discipline can be considered distinct from computer vision, a form of computer science.", "token2charspan": [[0, 7], [8, 14], [15, 17], [18, 19], [20, 27], [28, 39], [40, 50], [51, 54], [55, 57], [58, 68], [69, 77], [78, 82], [83, 91], [92, 98], [98, 99], [100, 101], [102, 106], [107, 109], [110, 118], [119, 126], [126, 127]]}
{"doc_key": "ai-test-291", "ner": [[5, 6, "algorithm"], [10, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 10, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "activation", "function", "of", "the", "LSTM", "gate", "is", "often", "a", "logistic", "sigmoid", "function", "."], "sentence-detokenized": "The activation function of the LSTM gate is often a logistic sigmoid function.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 26], [27, 30], [31, 35], [36, 40], [41, 43], [44, 49], [50, 51], [52, 60], [61, 68], [69, 77], [77, 78]]}
{"doc_key": "ai-test-292", "ner": [[5, 6, "metrics"], [24, 26, "metrics"], [28, 28, "metrics"], [37, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 24, 26, "named", "", false, false], [5, 6, 37, 39, "named", "", false, false], [28, 28, 24, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "an", "efficient", "estimator", "(", "it", "must", "be", "unique", ")", ",", "and", "thus", "it", "is", "also", "a", "minimum", "variance", "unbiased", "(", "MVUE", ")", "estimator", ",", "in", "addition", "to", "being", "a", "maximum", "likelihood", "estimator", "."], "sentence-detokenized": "In other words, the sample mean is an efficient estimator (it must be unique), and thus it is also a minimum variance unbiased (MVUE) estimator, in addition to being a maximum likelihood estimator.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 37], [38, 47], [48, 57], [58, 59], [59, 61], [62, 66], [67, 69], [70, 76], [76, 77], [77, 78], [79, 82], [83, 87], [88, 90], [91, 93], [94, 98], [99, 100], [101, 108], [109, 117], [118, 126], [127, 128], [128, 132], [132, 133], [134, 143], [143, 144], [145, 147], [148, 156], [157, 159], [160, 165], [166, 167], [168, 175], [176, 186], [187, 196], [196, 197]]}
{"doc_key": "ai-test-293", "ner": [[2, 3, "academicjournal"], [6, 8, "researcher"], [10, 11, "researcher"], [14, 15, "researcher"], [23, 23, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 23, 23, "topic", "", false, false], [2, 3, 26, 27, "topic", "", false, false], [6, 8, 2, 3, "role", "", false, false], [10, 11, 2, 3, "role", "", false, false], [14, 15, 2, 3, "role", "", false, false], [23, 23, 26, 27, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["A", "2001", "Scientific", "American", "article", "by", "Berners", "-", "Lee", ",", "James", "Hendler", ",", "and", "Ora", "Lassila", "described", "the", "expected", "evolution", "from", "the", "current", "Web", "to", "the", "Semantic", "Web", "."], "sentence-detokenized": "A 2001 Scientific American article by Berners-Lee, James Hendler, and Ora Lassila described the expected evolution from the current Web to the Semantic Web.", "token2charspan": [[0, 1], [2, 6], [7, 17], [18, 26], [27, 34], [35, 37], [38, 45], [45, 46], [46, 49], [49, 50], [51, 56], [57, 64], [64, 65], [66, 69], [70, 73], [74, 81], [82, 91], [92, 95], [96, 104], [105, 114], [115, 119], [120, 123], [124, 131], [132, 135], [136, 138], [139, 142], [143, 151], [152, 155], [155, 156]]}
{"doc_key": "ai-test-294", "ner": [[0, 1, "misc"], [15, 16, "person"], [18, 18, "person"], [28, 28, "person"], [40, 40, "person"], [46, 47, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 16, 0, 1, "role", "actor_in_work", false, false], [18, 18, 15, 16, "named", "", false, false], [18, 18, 15, 16, "origin", "", false, false], [28, 28, 18, 18, "part-of", "", false, false], [46, 47, 18, 18, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Blade", "Runner", "used", "a", "number", "of", "actors", "who", "were", "lesser", "known", "at", "the", "time", ":", "Sean", "Young", "played", "Rachael", ",", "an", "experimental", "replicant", "implanted", "with", "the", "memories", "of", "Tyrell", "'s", "niece", ",", "causing", "her", "to", "believe", "she", "is", "human", ";", "Sammon", ",", "pp.", "92", "-", "93", "Nina", "Axelrod", "auditioned", "for", "the", "role", "."], "sentence-detokenized": "Blade Runner used a number of actors who were lesser known at the time: Sean Young played Rachael, an experimental replicant implanted with the memories of Tyrell's niece, causing her to believe she is human; Sammon, pp. 92-93 Nina Axelrod auditioned for the role.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 19], [20, 26], [27, 29], [30, 36], [37, 40], [41, 45], [46, 52], [53, 58], [59, 61], [62, 65], [66, 70], [70, 71], [72, 76], [77, 82], [83, 89], [90, 97], [97, 98], [99, 101], [102, 114], [115, 124], [125, 134], [135, 139], [140, 143], [144, 152], [153, 155], [156, 162], [162, 164], [165, 170], [170, 171], [172, 179], [180, 183], [184, 186], [187, 194], [195, 198], [199, 201], [202, 207], [207, 208], [209, 215], [215, 216], [217, 220], [221, 223], [223, 224], [224, 226], [227, 231], [232, 239], [240, 250], [251, 254], [255, 258], [259, 263], [263, 264]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 13, "university"], [20, 22, "product"], [24, 26, "product"], [42, 43, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 12, 13, "physical", "", false, false], [3, 4, 12, 13, "physical", "", false, false], [6, 7, 12, 13, "physical", "", false, false], [9, 10, 12, 13, "physical", "", false, false], [12, 13, 42, 43, "physical", "", true, false], [20, 22, 12, 13, "temporal", "", false, false], [24, 26, 12, 13, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "and", "Terry", "Winograd", "visited", "Edinburgh", "University", "in", "1971", "spreading", "the", "word", "about", "Micro", "-", "Planner", "and", "SHRDLU", "and", "casting", "doubt", "on", "the", "uniform", "resolution", "proof", "procedure", "approach", "that", "had", "been", "the", "mainstay", "of", "the", "Edinburgh", "Logicians", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited Edinburgh University in 1971 spreading the word about Micro-Planner and SHRDLU and casting doubt on the uniform resolution proof procedure approach that had been the mainstay of the Edinburgh Logicians.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 56], [57, 65], [66, 73], [74, 83], [84, 94], [95, 97], [98, 102], [103, 112], [113, 116], [117, 121], [122, 127], [128, 133], [133, 134], [134, 141], [142, 145], [146, 152], [153, 156], [157, 164], [165, 170], [171, 173], [174, 177], [178, 185], [186, 196], [197, 202], [203, 212], [213, 221], [222, 226], [227, 230], [231, 235], [236, 239], [240, 248], [249, 251], [252, 255], [256, 265], [266, 275], [275, 276]]}
{"doc_key": "ai-test-296", "ner": [[0, 0, "researcher"], [8, 8, "field"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 12, 13, "role", "inspires", false, false], [0, 0, 15, 16, "role", "inspires", false, false], [0, 0, 18, 19, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Walter", "'s", "work", "inspired", "the", "next", "generation", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work inspired the next generation of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 22], [23, 26], [27, 31], [32, 42], [43, 45], [46, 54], [55, 66], [67, 71], [72, 74], [75, 81], [82, 88], [88, 89], [90, 94], [95, 102], [103, 106], [107, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-test-297", "ner": [[7, 7, "algorithm"], [9, 10, "researcher"], [16, 22, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 9, 10, "origin", "", false, false], [7, 7, 16, 22, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Furthermore", ",", "a", "similar", "GPU", "-", "based", "CNN", "by", "Alex", "Krizhevsky", "et", "al", ".", "won", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "2012", "."], "sentence-detokenized": "Furthermore, a similar GPU-based CNN by Alex Krizhevsky et al. won the ImageNet Large Scale Visual Recognition Challenge 2012.", "token2charspan": [[0, 11], [11, 12], [13, 14], [15, 22], [23, 26], [26, 27], [27, 32], [33, 36], [37, 39], [40, 44], [45, 55], [56, 58], [59, 61], [61, 62], [63, 66], [67, 70], [71, 79], [80, 85], [86, 91], [92, 98], [99, 110], [111, 120], [121, 125], [125, 126]]}
{"doc_key": "ai-test-298", "ner": [[2, 3, "misc"], [8, 9, "metrics"], [11, 12, "metrics"], [16, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 2, 3, "type-of", "", false, false], [11, 12, 2, 3, "type-of", "", false, false], [11, 12, 16, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Commonly", "used", "loss", "functions", "for", "probabilistic", "classification", "include", "log", "loss", "and", "Brier", "score", "between", "the", "predicted", "probability", "distribution", "and", "TRUE", "."], "sentence-detokenized": "Commonly used loss functions for probabilistic classification include log loss and Brier score between the predicted probability distribution and TRUE.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 28], [29, 32], [33, 46], [47, 61], [62, 69], [70, 73], [74, 78], [79, 82], [83, 88], [89, 94], [95, 102], [103, 106], [107, 116], [117, 128], [129, 141], [142, 145], [146, 150], [150, 151]]}
{"doc_key": "ai-test-299", "ner": [[4, 5, "organisation"], [12, 12, "field"], [15, 15, "organisation"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 12, 12, "general-affiliation", "field_of_study", false, false], [4, 5, 18, 19, "part-of", "", false, false], [15, 15, 4, 5, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "May", "2016", ",", "NtechLab", "was", "accepted", "into", "the", "official", "testing", "of", "biometric", "technologies", "by", "NIST", "among", "three", "Russian", "companies", "."], "sentence-detokenized": "In May 2016, NtechLab was accepted into the official testing of biometric technologies by NIST among three Russian companies.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [22, 25], [26, 34], [35, 39], [40, 43], [44, 52], [53, 60], [61, 63], [64, 73], [74, 86], [87, 89], [90, 94], [95, 100], [101, 106], [107, 114], [115, 124], [124, 125]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "floating", "-", "point", "numbers", "only", "have", "a", "certain", "amount", "of", "mathematical", "precision", "."], "sentence-detokenized": "However, floating-point numbers only have a certain amount of mathematical precision.", "token2charspan": [[0, 7], [7, 8], [9, 17], [17, 18], [18, 23], [24, 31], [32, 36], [37, 41], [42, 43], [44, 51], [52, 58], [59, 61], [62, 74], [75, 84], [84, 85]]}
{"doc_key": "ai-test-301", "ner": [[4, 4, "organisation"], [10, 16, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 10, 16, "role", "contributes_to", false, false], [18, 18, 10, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "2015", ",", "many", "SenseTime", "papers", "were", "accepted", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "During 2015, many SenseTime papers were accepted at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 6], [7, 11], [11, 12], [13, 17], [18, 27], [28, 34], [35, 39], [40, 48], [49, 51], [52, 55], [56, 66], [67, 69], [70, 78], [79, 85], [86, 89], [90, 97], [98, 109], [110, 111], [111, 115], [115, 116], [116, 117]]}
{"doc_key": "ai-test-302", "ner": [[7, 9, "task"], [11, 11, "task"], [14, 15, "task"], [17, 20, "task"], [23, 23, "field"], [25, 27, "misc"], [29, 35, "conference"], [43, 45, "misc"], [47, 48, "conference"], [64, 66, "misc"], [68, 68, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[7, 9, 23, 23, "part-of", "task_part_of_field", false, false], [11, 11, 7, 9, "named", "", false, false], [14, 15, 23, 23, "part-of", "task_part_of_field", false, false], [17, 20, 14, 15, "named", "", false, false], [25, 27, 29, 35, "temporal", "", false, false], [43, 45, 47, 48, "temporal", "", false, false], [64, 66, 68, 68, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["He", "co", "-developed", "the", "optimal", "algorithm", "for", "Structure", "From", "Motion", "(", "SFM", ",", "or", "Visual", "SLAM", ",", "simultaneous", "localisation", "and", "mapping", ",", "in", "Robotics", ";", "Best", "Paper", "Award", "at", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "1998", ")", ",", "characterised", "its", "ambiguity", "(", "David", "Marr", "Prize", "at", "ICCV", "1999", ")", ",", "also", "characterised", "the", "identifiability", "and", "observability", "of", "visual", "-", "inertial", "sensor", "fusion", "(", "Best", "Paper", "Award", "at", "Robotics", "2015", ")", "."], "sentence-detokenized": "He co-developed the optimal algorithm for Structure From Motion (SFM, or Visual SLAM, simultaneous localisation and mapping, in Robotics; Best Paper Award at Conference on Computer Vision and Pattern Recognition 1998), characterised its ambiguity (David Marr Prize at ICCV 1999), also characterised the identifiability and observability of visual-inertial sensor fusion (Best Paper Award at Robotics 2015).", "token2charspan": [[0, 2], [3, 5], [5, 15], [16, 19], [20, 27], [28, 37], [38, 41], [42, 51], [52, 56], [57, 63], [64, 65], [65, 68], [68, 69], [70, 72], [73, 79], [80, 84], [84, 85], [86, 98], [99, 111], [112, 115], [116, 123], [123, 124], [125, 127], [128, 136], [136, 137], [138, 142], [143, 148], [149, 154], [155, 157], [158, 168], [169, 171], [172, 180], [181, 187], [188, 191], [192, 199], [200, 211], [212, 216], [216, 217], [217, 218], [219, 232], [233, 236], [237, 246], [247, 248], [248, 253], [254, 258], [259, 264], [265, 267], [268, 272], [273, 277], [277, 278], [278, 279], [280, 284], [285, 298], [299, 302], [303, 318], [319, 322], [323, 336], [337, 339], [340, 346], [346, 347], [347, 355], [356, 362], [363, 369], [370, 371], [371, 375], [376, 381], [382, 387], [388, 390], [391, 399], [400, 404], [404, 405], [405, 406]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 11, "field"], [14, 15, "field"], [22, 23, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 7, 8, "part-of", "task_part_of_field", false, false], [0, 1, 10, 11, "part-of", "task_part_of_field", false, false], [0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 22, 23, "part-of", "", false, false], [0, 1, 25, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "a", "fundamental", "tool", "in", "image", "processing", ",", "machine", "vision", ",", "and", "computer", "vision", ",", "particularly", "in", "the", "areas", "of", "feature", "detection", "and", "feature", "extraction", "."], "sentence-detokenized": "Edge detection is a fundamental tool in image processing, machine vision, and computer vision, particularly in the areas of feature detection and feature extraction.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 19], [20, 31], [32, 36], [37, 39], [40, 45], [46, 56], [56, 57], [58, 65], [66, 72], [72, 73], [74, 77], [78, 86], [87, 93], [93, 94], [95, 107], [108, 110], [111, 114], [115, 120], [121, 123], [124, 131], [132, 141], [142, 145], [146, 153], [154, 164], [164, 165]]}
{"doc_key": "ai-test-305", "ner": [[10, 11, "misc"], [27, 30, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "example", "of", "this", "is", "a", "variable", "such", "as", "the", "outside", "temperature", "(", "mathtemp", "/", "math", ")", ",", "which", "in", "certain", "applications", "may", "be", "recorded", "to", "several", "decimal", "places", "of", "precision", "(", "depending", "on", "the", "sensing", "tool", ")", "."], "sentence-detokenized": "An example of this is a variable such as the outside temperature (mathtemp/math), which in certain applications may be recorded to several decimal places of precision (depending on the sensing tool).", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 18], [19, 21], [22, 23], [24, 32], [33, 37], [38, 40], [41, 44], [45, 52], [53, 64], [65, 66], [66, 74], [74, 75], [75, 79], [79, 80], [80, 81], [82, 87], [88, 90], [91, 98], [99, 111], [112, 115], [116, 118], [119, 127], [128, 130], [131, 138], [139, 146], [147, 153], [154, 156], [157, 166], [167, 168], [168, 177], [178, 180], [181, 184], [185, 192], [193, 197], [197, 198], [198, 199]]}
{"doc_key": "ai-test-306", "ner": [[3, 4, "person"], [6, 7, "person"], [10, 11, "person"], [21, 22, "person"], [24, 24, "misc"], [28, 28, "misc"], [30, 31, "person"], [33, 33, "organisation"], [35, 36, "person"], [39, 39, "organisation"], [41, 42, "person"], [45, 45, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[30, 31, 24, 24, "part-of", "", false, false], [30, 31, 28, 28, "role", "", false, false], [35, 36, 33, 33, "role", "", false, false], [41, 42, 39, 39, "role", "youtuber", false, false], [45, 45, 41, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Returning", "judges", "are", "Fon", "Davis", ",", "Jessica", "Chobot", ",", "and", "Leland", "Melvin", ",", "as", "well", "as", "celebrity", "guest", "judges", ",", "actor", "Clark", "Gregg", ",", "MythBusters", "host", "and", "former", "Battlebots", "builder", "Adam", "Savage", ",", "NFL", "player", "Vernon", "Davis", ",", "and", "YouTube", "star", "Michael", "Stevens", "a.k.a", ".", "Vsauce", "."], "sentence-detokenized": "Returning judges are Fon Davis, Jessica Chobot, and Leland Melvin, as well as celebrity guest judges, actor Clark Gregg, MythBusters host and former Battlebots builder Adam Savage, NFL player Vernon Davis, and YouTube star Michael Stevens a.k.a. Vsauce.", "token2charspan": [[0, 9], [10, 16], [17, 20], [21, 24], [25, 30], [30, 31], [32, 39], [40, 46], [46, 47], [48, 51], [52, 58], [59, 65], [65, 66], [67, 69], [70, 74], [75, 77], [78, 87], [88, 93], [94, 100], [100, 101], [102, 107], [108, 113], [114, 119], [119, 120], [121, 132], [133, 137], [138, 141], [142, 148], [149, 159], [160, 167], [168, 172], [173, 179], [179, 180], [181, 184], [185, 191], [192, 198], [199, 204], [204, 205], [206, 209], [210, 217], [218, 222], [223, 230], [231, 238], [239, 244], [244, 245], [246, 252], [252, 253]]}
{"doc_key": "ai-test-307", "ner": [[9, 10, "algorithm"], [11, 15, "algorithm"], [17, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 17, 19, "part-of", "", false, false], [11, 15, 17, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["But", "these", "methods", "never", "win", "over", "the", "internal", "non-uniform", "Gaussian", "mixture", "model", "/", "Hidden", "Markov", "model", "(", "GMM", "-", "HMM", ")", "technology", "based", "on", "discriminatively", "trained", "generative", "models", "of", "speech", "."], "sentence-detokenized": "But these methods never win over the internal non-uniform Gaussian mixture model/Hidden Markov model (GMM-HMM) technology based on discriminatively trained generative models of speech.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 23], [24, 27], [28, 32], [33, 36], [37, 45], [46, 57], [58, 66], [67, 74], [75, 80], [80, 81], [81, 87], [88, 94], [95, 100], [101, 102], [102, 105], [105, 106], [106, 109], [109, 110], [111, 121], [122, 127], [128, 130], [131, 147], [148, 155], [156, 166], [167, 173], [174, 176], [177, 183], [183, 184]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", ",", "and", "SciPy", "provide", "an", "easy", "way", "to", "implement", "these", "different", "methods", "."], "sentence-detokenized": "Software packages such as MATLAB, GNU Octave, Scilab, and SciPy provide an easy way to implement these different methods.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [52, 53], [54, 57], [58, 63], [64, 71], [72, 74], [75, 79], [80, 83], [84, 86], [87, 96], [97, 102], [103, 112], [113, 120], [120, 121]]}
{"doc_key": "ai-test-309", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [8, 9, "task"], [16, 17, "researcher"], [19, 20, "university"], [22, 23, "researcher"], [25, 28, "organisation"], [30, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 8, 9, "related-to", "", false, false], [0, 2, 16, 17, "origin", "", false, false], [0, 2, 22, 23, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [16, 17, 19, 20, "physical", "", false, false], [16, 17, 19, 20, "role", "", false, false], [22, 23, 25, 28, "physical", "", false, false], [22, 23, 25, 28, "role", "", false, false], [30, 30, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", ",", "a", "speech", "processing", "algorithm", ",", "was", "first", "proposed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", "."], "sentence-detokenized": "Linear predictive coding (LPC), a speech processing algorithm, was first proposed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 72], [73, 81], [82, 84], [85, 93], [94, 101], [102, 104], [105, 111], [112, 122], [123, 126], [127, 132], [133, 138], [139, 141], [142, 148], [149, 158], [159, 162], [163, 172], [173, 174], [174, 177], [177, 178], [179, 181], [182, 186], [186, 187]]}
{"doc_key": "ai-test-310", "ner": [[17, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[26, 26, 17, 24, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2006", ",", "for", "the", "25th", "anniversary", "of", "this", "algorithm", ",", "a", "workshop", "was", "organised", "at", "the", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "to", "summarise", "recent", "contributions", "and", "variations", "on", "the", "original", "algorithm", ",", "mostly", "intended", "to", "improve", "the", "algorithm", "'s", "speed", ",", "robustness", "and", "accuracy", "of", "the", "estimated", "solution", "and", "to", "reduce", "the", "dependency", "of", "user", "-", "defined", "constants", "."], "sentence-detokenized": "In 2006, for the 25th anniversary of this algorithm, a workshop was organised at the International Conference on Computer Vision and Pattern Recognition (CVPR) to summarise recent contributions and variations on the original algorithm, mostly intended to improve the algorithm's speed, robustness and accuracy of the estimated solution and to reduce the dependency of user-defined constants.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 21], [22, 33], [34, 36], [37, 41], [42, 51], [51, 52], [53, 54], [55, 63], [64, 67], [68, 77], [78, 80], [81, 84], [85, 98], [99, 109], [110, 112], [113, 121], [122, 128], [129, 132], [133, 140], [141, 152], [153, 154], [154, 158], [158, 159], [160, 162], [163, 172], [173, 179], [180, 193], [194, 197], [198, 208], [209, 211], [212, 215], [216, 224], [225, 234], [234, 235], [236, 242], [243, 251], [252, 254], [255, 262], [263, 266], [267, 276], [276, 278], [279, 284], [284, 285], [286, 296], [297, 300], [301, 309], [310, 312], [313, 316], [317, 326], [327, 335], [336, 339], [340, 342], [343, 349], [350, 353], [354, 364], [365, 367], [368, 372], [372, 373], [373, 380], [381, 390], [390, 391]]}
{"doc_key": "ai-test-311", "ner": [[4, 6, "university"], [9, 12, "organisation"], [14, 16, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Members", "went", "to", "the", "University", "of", "Debrecen", ",", "the", "Hungarian", "Academy", "of", "Sciences", ",", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "University", ",", "etc", "."], "sentence-detokenized": "Members went to the University of Debrecen, the Hungarian Academy of Sciences, E\u00f6tv\u00f6s Lor\u00e1nd University, etc.", "token2charspan": [[0, 7], [8, 12], [13, 15], [16, 19], [20, 30], [31, 33], [34, 42], [42, 43], [44, 47], [48, 57], [58, 65], [66, 68], [69, 77], [77, 78], [79, 85], [86, 92], [93, 103], [103, 104], [105, 108], [108, 109]]}
{"doc_key": "ai-test-312", "ner": [[2, 3, "algorithm"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 16, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "extend", "SVM", "to", "cases", "where", "data", "can", "not", "be", "linearly", "separated", ",", "we", "introduce", "a", "loss", "function", ","], "sentence-detokenized": "To extend SVM to cases where data cannot be linearly separated, we introduce a loss function,", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 16], [17, 22], [23, 28], [29, 33], [34, 37], [37, 40], [41, 43], [44, 52], [53, 62], [62, 63], [64, 66], [67, 76], [77, 78], [79, 83], [84, 92], [92, 93]]}
{"doc_key": "ai-test-313", "ner": [[0, 0, "programlang"], [11, 12, "researcher"], [14, 15, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 11, 12, "origin", "", false, false], [0, 0, 14, 15, "origin", "", false, false], [0, 0, 18, 19, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "is", "an", "educational", "programming", "language", ",", "designed", "in", "1967", "by", "Wally", "Feurzeig", ",", "Seymour", "Papert", ",", "and", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo is an educational programming language, designed in 1967 by Wally Feurzeig, Seymour Papert, and Cynthia Solomon.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 34], [35, 43], [43, 44], [45, 53], [54, 56], [57, 61], [62, 64], [65, 70], [71, 79], [79, 80], [81, 88], [89, 95], [95, 96], [97, 100], [101, 108], [109, 116], [116, 117]]}
{"doc_key": "ai-test-314", "ner": [[0, 4, "organisation"], [8, 12, "organisation"], [14, 17, "location"], [19, 19, "location"], [21, 21, "location"], [29, 32, "product"], [42, 45, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 4, 8, 12, "role", "works_for", false, false], [8, 12, 14, 17, "physical", "", false, false], [14, 17, 19, 19, "physical", "", false, false], [19, 19, 21, 21, "physical", "", false, false], [29, 32, 0, 4, "origin", "", false, false], [42, 45, 29, 32, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "Eyring", "Research", "Institute", "was", "instrumental", "for", "the", "U.S.", "Air", "Force", "Missile", "Directorate", "at", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", "to", "produce", "in", "top", "military", "secrecy", "the", "Intelligent", "Systems", "Technology", "Software", "that", "became", "the", "basis", "for", "the", "later", "-", "named", "Reagan", "Star", "Wars", "programme", "."], "sentence-detokenized": "The Eyring Research Institute was instrumental for the U.S. Air Force Missile Directorate at Hill Air Force Base near Ogden, Utah to produce in top military secrecy the Intelligent Systems Technology Software that became the basis for the later-named Reagan Star Wars programme.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 29], [30, 33], [34, 46], [47, 50], [51, 54], [55, 59], [60, 63], [64, 69], [70, 77], [78, 89], [90, 92], [93, 97], [98, 101], [102, 107], [108, 112], [113, 117], [118, 123], [123, 124], [125, 129], [130, 132], [133, 140], [141, 143], [144, 147], [148, 156], [157, 164], [165, 168], [169, 180], [181, 188], [189, 199], [200, 208], [209, 213], [214, 220], [221, 224], [225, 230], [231, 234], [235, 238], [239, 244], [244, 245], [245, 250], [251, 257], [258, 262], [263, 267], [268, 277], [277, 278]]}
{"doc_key": "ai-test-315", "ner": [[11, 12, "field"], [21, 24, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "decades", "he", "has", "been", "researching", "and", "developing", "emerging", "areas", "of", "computer", "science", "from", "compilers", ",", "programming", "languages", "and", "system", "architectures", "John", "F", ".", "Sowa", "and", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "For decades he has been researching and developing emerging areas of computer science from compilers, programming languages and system architectures John F. Sowa and John Zachman (1992).", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 18], [19, 23], [24, 35], [36, 39], [40, 50], [51, 59], [60, 65], [66, 68], [69, 77], [78, 85], [86, 90], [91, 100], [100, 101], [102, 113], [114, 123], [124, 127], [128, 134], [135, 148], [149, 153], [154, 155], [155, 156], [157, 161], [162, 165], [166, 170], [171, 178], [179, 180], [180, 184], [184, 185], [185, 186]]}
{"doc_key": "ai-test-316", "ner": [[0, 2, "algorithm"], [9, 10, "algorithm"], [7, 13, "algorithm"], [18, 19, "field"], [21, 22, "field"], [26, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 10, 0, 2, "named", "", false, false], [7, 13, 0, 2, "named", "", false, false], [18, 19, 0, 2, "usage", "", false, false], [21, 22, 0, 2, "usage", "", false, false], [26, 28, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Sobel", "operator", ",", "sometimes", "called", "the", "Sobel", "-", "Feldman", "operator", "or", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "particularly", "in", "edge", "detection", "algorithms", "where", "it", "creates", "images", "that", "emphasise", "edges", "."], "sentence-detokenized": "The Sobel operator, sometimes called the Sobel-Feldman operator or Sobel filter, is used in image processing and computer vision, particularly in edge detection algorithms where it creates images that emphasise edges.", "token2charspan": [[0, 3], [4, 9], [10, 18], [18, 19], [20, 29], [30, 36], [37, 40], [41, 46], [46, 47], [47, 54], [55, 63], [64, 66], [67, 72], [73, 79], [79, 80], [81, 83], [84, 88], [89, 91], [92, 97], [98, 108], [109, 112], [113, 121], [122, 128], [128, 129], [130, 142], [143, 145], [146, 150], [151, 160], [161, 171], [172, 177], [178, 180], [181, 188], [189, 195], [196, 200], [201, 210], [211, 216], [216, 217]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [3, 4, "field"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 4, "compare", "", false, false], [0, 0, 3, 4, "type-of", "", false, false], [0, 0, 12, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "is", "a", "supervised", "learning", "algorithm", "that", "utilises", "data", "labels", ",", "while", "PCA", "is", "a", "learning", "algorithm", "that", "ignores", "labels", "."], "sentence-detokenized": "LDA is a supervised learning algorithm that utilises data labels, while PCA is a learning algorithm that ignores labels.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 19], [20, 28], [29, 38], [39, 43], [44, 52], [53, 57], [58, 64], [64, 65], [66, 71], [72, 75], [76, 78], [79, 80], [81, 89], [90, 99], [100, 104], [105, 112], [113, 119], [119, 120]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "linear", "classification", "algorithms", "include", "Winnow", ",", "support", "vector", "machines", "and", "logistic", "regression", "."], "sentence-detokenized": "Other linear classification algorithms include Winnow, support vector machines and logistic regression.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 38], [39, 46], [47, 53], [53, 54], [55, 62], [63, 69], [70, 78], [79, 82], [83, 91], [92, 102], [102, 103]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [4, 5, "programlang"], [14, 15, "product"], [17, 17, "programlang"], [20, 20, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 4, 5, "general-affiliation", "", true, false], [0, 0, 14, 15, "general-affiliation", "", true, false], [0, 0, 17, 17, "general-affiliation", "", true, false], [0, 0, 20, 20, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "consists", "of", "a", "C", "++", "class", "library", "and", "several", "interpreted", "interface", "layers", "including", "Tcl/", "Tk", ",", "Java", ",", "and", "Python", "."], "sentence-detokenized": "VTK consists of a C++ class library and several interpreted interface layers including Tcl/Tk, Java, and Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 17], [18, 19], [19, 21], [22, 27], [28, 35], [36, 39], [40, 47], [48, 59], [60, 69], [70, 76], [77, 86], [87, 91], [91, 93], [93, 94], [95, 99], [99, 100], [101, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-320", "ner": [[10, 12, "task"], [19, 21, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", ",", "text", "generated", "by", "processing", "spontaneous", "speech", "using", "automatic", "speech", "recognition", "and", "text", "printed", "or", "handwritten", "using", "optical", "character", "recognition", "contain", "processing", "noise", "."], "sentence-detokenized": "In addition, text generated by processing spontaneous speech using automatic speech recognition and text printed or handwritten using optical character recognition contain processing noise.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 17], [18, 27], [28, 30], [31, 41], [42, 53], [54, 60], [61, 66], [67, 76], [77, 83], [84, 95], [96, 99], [100, 104], [105, 112], [113, 115], [116, 127], [128, 133], [134, 141], [142, 151], [152, 163], [164, 171], [172, 182], [183, 188], [188, 189]]}
{"doc_key": "ai-test-321", "ner": [[0, 0, "researcher"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 9, 9, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "wrote", "several", "books", "and", "directed", "the", "development", "of", "WordNet", ",", "an", "online", "word", "link", "database", "that", "can", "be", "used", "by", "computer", "programmes", "."], "sentence-detokenized": "Miller wrote several books and directed the development of WordNet, an online word link database that can be used by computer programmes.", "token2charspan": [[0, 6], [7, 12], [13, 20], [21, 26], [27, 30], [31, 39], [40, 43], [44, 55], [56, 58], [59, 66], [66, 67], [68, 70], [71, 77], [78, 82], [83, 87], [88, 96], [97, 101], [102, 105], [106, 108], [109, 113], [114, 116], [117, 125], [126, 136], [136, 137]]}
{"doc_key": "ai-test-322", "ner": [[1, 1, "field"], [7, 9, "organisation"], [12, 12, "country"], [14, 15, "person"], [17, 19, "person"], [21, 22, "person"], [24, 25, "person"], [28, 28, "country"], [30, 33, "location"], [35, 36, "misc"], [37, 38, "person"], [41, 42, "person"], [44, 44, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[7, 9, 12, 12, "physical", "", false, false], [14, 15, 28, 28, "physical", "", false, false], [17, 19, 28, 28, "physical", "", false, false], [21, 22, 28, 28, "physical", "", false, false], [24, 25, 28, 28, "physical", "", false, false], [30, 33, 1, 1, "general-affiliation", "", false, false], [30, 33, 37, 38, "artifact", "", false, false], [35, 36, 37, 38, "named", "", false, false], [41, 42, 44, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Contemporary", "automata", "are", "represented", "by", "works", "by", "Cabaret", "Mechanical", "Theatre", "in", "the", "UK", ",", "Dug", "North", "and", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "in", "the", "USA", ",", "Le", "D\u00e9fenseur", "du", "Temps", "by", "French", "artist", "Jacques", "Monestier", ",", "and", "Fran\u00e7ois", "Junod", "in", "Switzerland", "."], "sentence-detokenized": "Contemporary automata are represented by works by Cabaret Mechanical Theatre in the UK, Dug North and Chomick + Meder, Arthur Ganson, Joe Jones in the USA, Le D\u00e9fenseur du Temps by French artist Jacques Monestier, and Fran\u00e7ois Junod in Switzerland.", "token2charspan": [[0, 12], [13, 21], [22, 25], [26, 37], [38, 40], [41, 46], [47, 49], [50, 57], [58, 68], [69, 76], [77, 79], [80, 83], [84, 86], [86, 87], [88, 91], [92, 97], [98, 101], [102, 109], [110, 111], [112, 117], [117, 118], [119, 125], [126, 132], [132, 133], [134, 137], [138, 143], [144, 146], [147, 150], [151, 154], [154, 155], [156, 158], [159, 168], [169, 171], [172, 177], [178, 180], [181, 187], [188, 194], [195, 202], [203, 212], [212, 213], [214, 217], [218, 226], [227, 232], [233, 235], [236, 247], [247, 248]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 22, 22, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "does", "include", "standard", "codefor", "/", "code", "and", "codewhile", "/", "code", "loops", ",", "but", "(", "as", "in", "other", "similar", "applications", "such", "as", "R", ")", ",", "using", "vector", "notation", "is", "recommended", "and", "often", "faster", "to", "execute", "."], "sentence-detokenized": "MATLAB does include standard codefor/code and codewhile/code loops, but (as in other similar applications such as R), using vector notation is recommended and often faster to execute.", "token2charspan": [[0, 6], [7, 11], [12, 19], [20, 28], [29, 36], [36, 37], [37, 41], [42, 45], [46, 55], [55, 56], [56, 60], [61, 66], [66, 67], [68, 71], [72, 73], [73, 75], [76, 78], [79, 84], [85, 92], [93, 105], [106, 110], [111, 113], [114, 115], [115, 116], [116, 117], [118, 123], [124, 130], [131, 139], [140, 142], [143, 154], [155, 158], [159, 164], [165, 171], [172, 174], [175, 182], [182, 183]]}
{"doc_key": "ai-test-324", "ner": [[0, 0, "researcher"], [6, 9, "conference"], [16, 17, "field"], [19, 25, "misc"], [28, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 19, 25, "win-defeat", "", false, false], [0, 0, 28, 37, "win-defeat", "", false, false], [19, 25, 6, 9, "temporal", "", false, false], [19, 25, 16, 17, "topic", "", false, false], [28, 37, 6, 9, "temporal", "", false, false], [28, 37, 16, 17, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "in", "2007", "for", "his", "achievements", "in", "computing", "education", ":", "Karl", "V", ".", "Karlstrom", "Outstanding", "Educator", "Award", "and", "the", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contributions", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "Pausch received two awards from the Association for Computing Machinery in 2007 for his achievements in computing education: Karl V. Karlstrom Outstanding Educator Award and the ACM SIGCSE Award for Outstanding Contributions to Computer Science Education.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 26], [27, 31], [32, 35], [36, 47], [48, 51], [52, 61], [62, 71], [72, 74], [75, 79], [80, 83], [84, 87], [88, 100], [101, 103], [104, 113], [114, 123], [123, 124], [125, 129], [130, 131], [131, 132], [133, 142], [143, 154], [155, 163], [164, 169], [170, 173], [174, 177], [178, 181], [182, 188], [189, 194], [195, 198], [199, 210], [211, 224], [225, 227], [228, 236], [237, 244], [245, 254], [254, 255]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [8, 8, "product"], [9, 9, "product"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 8, "role", "sells", false, false], [8, 8, 9, 9, "general-affiliation", "", false, false], [8, 8, 17, 18, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "in", "1961", "to", "General", "Motors", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered in 1961 to General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 83], [84, 86], [87, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-326", "ner": [[0, 1, "algorithm"], [5, 7, "field"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 1, "usage", "", false, false], [11, 12, 5, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantic", "networks", "are", "used", "in", "natural", "language", "processing", "applications", "such", "as", "semantic", "parsing", "."], "sentence-detokenized": "Semantic networks are used in natural language processing applications such as semantic parsing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 26], [27, 29], [30, 37], [38, 46], [47, 57], [58, 70], [71, 75], [76, 78], [79, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-327", "ner": [[4, 5, "field"], [7, 8, "field"], [10, 11, "task"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 8, 4, 5, "usage", "", false, false], [10, 11, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Some", "successful", "applications", "of", "deep", "learning", "are", "computer", "vision", "and", "speech", "recognition", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Some successful applications of deep learning are computer vision and speech recognition. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 31], [32, 36], [37, 45], [46, 49], [50, 58], [59, 65], [66, 69], [70, 76], [77, 88], [88, 89], [90, 97], [98, 101], [101, 102], [103, 108], [109, 115], [115, 116], [117, 123], [124, 133], [133, 134], [135, 141], [142, 143], [143, 144], [145, 147], [147, 148]]}
{"doc_key": "ai-test-328", "ner": [[4, 8, "product"], [14, 14, "misc"], [17, 17, "misc"], [23, 24, "product"], [27, 28, "task"], [30, 31, "task"], [33, 34, "task"], [36, 38, "field"], [40, 41, "task"], [43, 44, "field"], [46, 47, "task"], [49, 50, "task"], [52, 53, "task"], [56, 57, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 8, 14, 14, "physical", "travels_to", false, false], [4, 8, 17, 17, "physical", "travels_to", false, false], [23, 24, 4, 8, "part-of", "", false, false], [23, 24, 4, 8, "role", "maintains", false, false], [23, 24, 27, 28, "related-to", "has_ability_to", false, false], [23, 24, 30, 31, "related-to", "has_ability_to", false, false], [23, 24, 33, 34, "related-to", "has_ability_to", false, false], [23, 24, 36, 38, "related-to", "has_ability_to", false, false], [23, 24, 40, 41, "related-to", "has_ability_to", false, false], [23, 24, 43, 44, "related-to", "has_ability_to", false, false], [23, 24, 46, 47, "related-to", "has_ability_to", false, false], [23, 24, 49, 50, "related-to", "has_ability_to", false, false], [23, 24, 52, 53, "related-to", "has_ability_to", false, false], [23, 24, 56, 57, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "addition", "to", "maintaining", "Discovery", "One", "'s", "spacecraft", "systems", "during", "the", "interplanetary", "mission", "to", "Jupiter", "(", "or", "Saturn", "in", "the", "novel", ")", ",", "HAL", "is", "capable", "of", "speech", "synthesis", ",", "speech", "recognition", ",", "facial", "recognition", ",", "natural", "language", "processing", ",", "lip", "reading", ",", "art", "appreciation", ",", "affective", "computing", ",", "automated", "reasoning", ",", "spacecraft", "piloting", ",", "and", "playing", "chess", "."], "sentence-detokenized": "In addition to maintaining Discovery One's spacecraft systems during the interplanetary mission to Jupiter (or Saturn in the novel), HAL is capable of speech synthesis, speech recognition, facial recognition, natural language processing, lip reading, art appreciation, affective computing, automated reasoning, spacecraft piloting, and playing chess.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 36], [37, 40], [40, 42], [43, 53], [54, 61], [62, 68], [69, 72], [73, 87], [88, 95], [96, 98], [99, 106], [107, 108], [108, 110], [111, 117], [118, 120], [121, 124], [125, 130], [130, 131], [131, 132], [133, 136], [137, 139], [140, 147], [148, 150], [151, 157], [158, 167], [167, 168], [169, 175], [176, 187], [187, 188], [189, 195], [196, 207], [207, 208], [209, 216], [217, 225], [226, 236], [236, 237], [238, 241], [242, 249], [249, 250], [251, 254], [255, 267], [267, 268], [269, 278], [279, 288], [288, 289], [290, 299], [300, 309], [309, 310], [311, 321], [322, 330], [330, 331], [332, 335], [336, 343], [344, 349], [349, 350]]}
{"doc_key": "ai-test-329", "ner": [[0, 0, "researcher"], [3, 3, "country"], [6, 7, "country"], [11, 11, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 3, "physical", "", false, false], [0, 0, 6, 7, "physical", "", false, false], [0, 0, 11, 11, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Julesz", "emigrated", "from", "Hungary", "to", "the", "United", "States", "after", "the", "1956", "Soviet", "invasion", "."], "sentence-detokenized": "Julesz emigrated from Hungary to the United States after the 1956 Soviet invasion.", "token2charspan": [[0, 6], [7, 16], [17, 21], [22, 29], [30, 32], [33, 36], [37, 43], [44, 50], [51, 56], [57, 60], [61, 65], [66, 72], [73, 81], [81, 82]]}
{"doc_key": "ai-test-330", "ner": [[0, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sigmoid", "function", "activation", "function", "uses", "the", "second", "non-linearity", "for", "large", "inputs", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+\\", "exp", "(", "-", "v", "_", "i", ")", ")", "^{", "-1", "}", "/", "math", "."], "sentence-detokenized": "The sigmoid function activation function uses the second non-linearity for large inputs: math\\ phi(v _ i) = (1 +\\ exp(-v _ i)) ^{-1} / math.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 31], [32, 40], [41, 45], [46, 49], [50, 56], [57, 70], [71, 74], [75, 80], [81, 87], [87, 88], [89, 93], [93, 94], [95, 98], [98, 99], [99, 100], [101, 102], [103, 104], [104, 105], [106, 107], [108, 109], [109, 110], [111, 113], [114, 117], [117, 118], [118, 119], [119, 120], [121, 122], [123, 124], [124, 125], [125, 126], [127, 129], [129, 131], [131, 132], [133, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-test-331", "ner": [[12, 14, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "probability", "is", "used", "to", "determine", "what", "the", "target", "is", "by", "using", "maximum", "likelihood", "decisions", "."], "sentence-detokenized": "This probability is used to determine what the target is by using maximum likelihood decisions.", "token2charspan": [[0, 4], [5, 16], [17, 19], [20, 24], [25, 27], [28, 37], [38, 42], [43, 46], [47, 53], [54, 56], [57, 59], [60, 65], [66, 73], [74, 84], [85, 94], [94, 95]]}
{"doc_key": "ai-test-332", "ner": [[6, 8, "university"], [14, 16, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1984", "he", "moved", "to", "the", "University", "of", "Konstanz", "and", "in", "1990", "to", "the", "University", "of", "Salzburg", "."], "sentence-detokenized": "In 1984 he moved to the University of Konstanz and in 1990 to the University of Salzburg.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 46], [47, 50], [51, 53], [54, 58], [59, 61], [62, 65], [66, 76], [77, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-333", "ner": [[6, 7, "metrics"], [9, 11, "metrics"], [13, 15, "metrics"], [17, 17, "metrics"], [19, 20, "metrics"], [22, 24, "metrics"], [28, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 11, 6, 7, "origin", "based_on", false, false], [13, 15, 6, 7, "origin", "based_on", false, false], [17, 17, 6, 7, "origin", "based_on", false, false], [19, 20, 6, 7, "origin", "based_on", false, false], [22, 24, 6, 7, "origin", "based_on", false, false], [28, 31, 6, 7, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Some", "popular", "fitness", "functions", "based", "on", "confusion", "matrices", "include", "sensitivity", "/", "specificity", ",", "recall", "/", "precision", ",", "F-measure", ",", "Jaccard", "similarity", ",", "Matthews", "correlation", "coefficient", ",", "and", "a", "cost", "/", "gain", "matrix", "that", "combines", "the", "costs", "and", "benefits", "assigned", "to", "4", "different", "classification", "types", "."], "sentence-detokenized": "Some popular fitness functions based on confusion matrices include sensitivity/specificity, recall/precision, F-measure, Jaccard similarity, Matthews correlation coefficient, and a cost/gain matrix that combines the costs and benefits assigned to 4 different classification types.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 30], [31, 36], [37, 39], [40, 49], [50, 58], [59, 66], [67, 78], [78, 79], [79, 90], [90, 91], [92, 98], [98, 99], [99, 108], [108, 109], [110, 119], [119, 120], [121, 128], [129, 139], [139, 140], [141, 149], [150, 161], [162, 173], [173, 174], [175, 178], [179, 180], [181, 185], [185, 186], [186, 190], [191, 197], [198, 202], [203, 211], [212, 215], [216, 221], [222, 225], [226, 234], [235, 243], [244, 246], [247, 248], [249, 258], [259, 273], [274, 279], [279, 280]]}
{"doc_key": "ai-test-334", "ner": [[6, 6, "product"], [8, 8, "product"], [10, 10, "product"], [12, 12, "product"], [14, 14, "programlang"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[23, 25, 6, 6, "part-of", "", false, false], [23, 25, 8, 8, "part-of", "", false, false], [23, 25, 10, 10, "part-of", "", false, false], [23, 25, 12, 12, "part-of", "", false, false], [23, 25, 14, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Common", "numerical", "programming", "environments", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "and", "R", "provide", "some", "simpler", "feature", "extraction", "techniques", "(", "e.g.", "principal", "component", "analysis", ")", "through", "inbuilt", "commands", "."], "sentence-detokenized": "Common numerical programming environments such as MATLAB, SciLab, NumPy, Sklearn and R provide some simpler feature extraction techniques (e.g. principal component analysis) through inbuilt commands.", "token2charspan": [[0, 6], [7, 16], [17, 28], [29, 41], [42, 46], [47, 49], [50, 56], [56, 57], [58, 64], [64, 65], [66, 71], [71, 72], [73, 80], [81, 84], [85, 86], [87, 94], [95, 99], [100, 107], [108, 115], [116, 126], [127, 137], [138, 139], [139, 143], [144, 153], [154, 163], [164, 172], [172, 173], [174, 181], [182, 189], [190, 198], [198, 199]]}
{"doc_key": "ai-test-335", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "have", "been", "implemented", "to", "collaborate", "with", "humans", "to", "perform", "industrial", "manufacturing", "tasks", "."], "sentence-detokenized": "Industrial robots have been implemented to collaborate with humans to perform industrial manufacturing tasks.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 27], [28, 39], [40, 42], [43, 54], [55, 59], [60, 66], [67, 69], [70, 77], [78, 88], [89, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-test-336", "ner": [[6, 6, "field"], [8, 11, "researcher"], [18, 19, "field"], [21, 22, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 18, 19, "related-to", "", false, false], [6, 6, 21, 22, "related-to", "", false, false], [6, 6, 25, 26, "related-to", "", false, false], [8, 11, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "first", "published", "paper", "on", "CG", ",", "John", "F", ".", "Sowa", "applied", "it", "to", "various", "topics", "in", "artificial", "intelligence", ",", "computer", "science", ",", "and", "cognitive", "science", "."], "sentence-detokenized": "In the first published paper on CG, John F. Sowa applied it to various topics in artificial intelligence, computer science, and cognitive science.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [23, 28], [29, 31], [32, 34], [34, 35], [36, 40], [41, 42], [42, 43], [44, 48], [49, 56], [57, 59], [60, 62], [63, 70], [71, 77], [78, 80], [81, 91], [92, 104], [104, 105], [106, 114], [115, 122], [122, 123], [124, 127], [128, 137], [138, 145], [145, 146]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [4, 4, "metrics"], [6, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "in", "its", "calculation", "of", "brevity", "penalties", ",", "to", "the", "extent", "that", "small", "variations", "in", "translation", "length", "do", "not", "greatly", "impact", "the", "overall", "score", "."], "sentence-detokenized": "NIST also differs from BLEU in its calculation of brevity penalties, to the extent that small variations in translation length do not greatly impact the overall score.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 46], [47, 49], [50, 57], [58, 67], [67, 68], [69, 71], [72, 75], [76, 82], [83, 87], [88, 93], [94, 104], [105, 107], [108, 119], [120, 126], [127, 129], [130, 133], [134, 141], [142, 148], [149, 152], [153, 160], [161, 166], [166, 167]]}
{"doc_key": "ai-test-338", "ner": [[0, 5, "misc"], [13, 13, "conference"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 5, 13, 13, "temporal", "", false, false], [0, 5, 21, 22, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "IJCAI", "Award", "for", "Research", "Excellence", "is", "a", "biennial", "award", "given", "at", "the", "IJCAI", "conference", "to", "researchers", "in", "the", "field", "of", "artificial", "intelligence", "in", "recognition", "of", "their", "career", "excellence", "."], "sentence-detokenized": "The IJCAI Award for Research Excellence is a biennial award given at the IJCAI conference to researchers in the field of artificial intelligence in recognition of their career excellence.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 28], [29, 39], [40, 42], [43, 44], [45, 53], [54, 59], [60, 65], [66, 68], [69, 72], [73, 78], [79, 89], [90, 92], [93, 104], [105, 107], [108, 111], [112, 117], [118, 120], [121, 131], [132, 144], [145, 147], [148, 159], [160, 162], [163, 168], [169, 175], [176, 186], [186, 187]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [9, 9, "conference"], [20, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 9, 9, "role", "", false, false], [0, 0, 20, 27, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "is", "one", "of", "the", "original", "Fellows", "of", "the", "AAAI", ",", "and", "is", "the", "only", "individual", "to", "be", "on", "the", "Scientific", "Advisory", "Boards", "of", "both", "Microsoft", "and", "Apple", "."], "sentence-detokenized": "Lenat is one of the original Fellows of the AAAI, and is the only individual to be on the Scientific Advisory Boards of both Microsoft and Apple.", "token2charspan": [[0, 5], [6, 8], [9, 12], [13, 15], [16, 19], [20, 28], [29, 36], [37, 39], [40, 43], [44, 48], [48, 49], [50, 53], [54, 56], [57, 60], [61, 65], [66, 76], [77, 79], [80, 82], [83, 85], [86, 89], [90, 100], [101, 109], [110, 116], [117, 119], [120, 124], [125, 134], [135, 138], [139, 144], [144, 145]]}
{"doc_key": "ai-test-340", "ner": [[0, 2, "algorithm"], [7, 8, "misc"], [12, 14, "metrics"], [23, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 7, 8, "related-to", "minimise", false, false], [12, 14, 7, 8, "type-of", "", false, false], [23, 23, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "autoencoder", "is", "trained", "to", "minimise", "the", "reconstruction", "error", "(", "such", "as", "mean", "square", "error", ")", ",", "which", "is", "often", "referred", "to", "as", "loss", ":"], "sentence-detokenized": "The autoencoder is trained to minimise the reconstruction error (such as mean square error), which is often referred to as loss:", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 26], [27, 29], [30, 38], [39, 42], [43, 57], [58, 63], [64, 65], [65, 69], [70, 72], [73, 77], [78, 84], [85, 90], [90, 91], [91, 92], [93, 98], [99, 101], [102, 107], [108, 116], [117, 119], [120, 122], [123, 127], [127, 128]]}
{"doc_key": "ai-test-341", "ner": [[28, 30, "misc"], [33, 33, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[33, 33, 28, 30, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "to", "the", "use", "of", "definitions", "is", "to", "consider", "word", "-", "sense", "relatedness", "in", "general", "and", "calculate", "the", "similarity", "of", "each", "word", "pair", "based", "on", "a", "given", "lexical", "knowledge", "base", "such", "as", "WordNet", "."], "sentence-detokenized": "An alternative to the use of definitions is to consider word-sense relatedness in general and calculate the similarity of each word pair based on a given lexical knowledge base such as WordNet.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 21], [22, 25], [26, 28], [29, 40], [41, 43], [44, 46], [47, 55], [56, 60], [60, 61], [61, 66], [67, 78], [79, 81], [82, 89], [90, 93], [94, 103], [104, 107], [108, 118], [119, 121], [122, 126], [127, 131], [132, 136], [137, 142], [143, 145], [146, 147], [148, 153], [154, 161], [162, 171], [172, 176], [177, 181], [182, 184], [185, 192], [192, 193]]}
{"doc_key": "ai-test-342", "ner": [[0, 2, "algorithm"], [9, 11, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 11, "origin", "", false, false], [9, 11, 21, 22, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "invented", "by", "Richard", "S.", "Sutton", "based", "on", "previous", "work", "on", "temporal", "difference", "learning", "by", "Arthur", "Samuel", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm invented by Richard S. Sutton based on previous work on temporal difference learning by Arthur Samuel.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 42], [43, 45], [46, 53], [54, 56], [57, 63], [64, 69], [70, 72], [73, 81], [82, 86], [87, 89], [90, 98], [99, 109], [110, 118], [119, 121], [122, 128], [129, 135], [135, 136]]}
{"doc_key": "ai-test-343", "ner": [[1, 2, "field"], [4, 4, "field"], [6, 6, "task"], [7, 13, "task"], [15, 15, "task"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 1, 2, "part-of", "task_part_of_field", false, false], [6, 6, 4, 4, "part-of", "task_part_of_field", false, false], [7, 13, 6, 6, "named", "", false, false], [15, 15, 6, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "data", "mining", "and", "statistics", ",", "hierarchical", "clustering", "(", "also", "called", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "method", "of", "cluster", "analysis", "that", "seeks", "to", "build", "a", "hierarchy", "of", "clusters", "."], "sentence-detokenized": "In data mining and statistics, hierarchical clustering (also called hierarchical cluster analysis or HCA) is a method of cluster analysis that seeks to build a hierarchy of clusters.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 29], [29, 30], [31, 43], [44, 54], [55, 56], [56, 60], [61, 67], [68, 80], [81, 88], [89, 97], [98, 100], [101, 104], [104, 105], [106, 108], [109, 110], [111, 117], [118, 120], [121, 128], [129, 137], [138, 142], [143, 148], [149, 151], [152, 157], [158, 159], [160, 169], [170, 172], [173, 181], [181, 182]]}
{"doc_key": "ai-test-344", "ner": [[3, 3, "algorithm"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "concept", "of", "deconvolution", "is", "widely", "used", "in", "signal", "processing", "and", "image", "processing", "techniques", "."], "sentence-detokenized": "The concept of deconvolution is widely used in signal processing and image processing techniques.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 53], [54, 64], [65, 68], [69, 74], [75, 85], [86, 96], [96, 97]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [21, 22, "misc"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 21, 22, "related-to", "enhances", false, false], [0, 1, 21, 22, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "serve", "the", "construction", "and", "accumulation", "of", "spatial", "knowledge", ",", "allowing", "the", "mind", "'s", "eye", "to", "visualise", "images", "to", "reduce", "cognitive", "load", ",", "improve", "memory", "and", "information", "learning", "."], "sentence-detokenized": "Cognitive maps serve the construction and accumulation of spatial knowledge, allowing the mind's eye to visualise images to reduce cognitive load, improve memory and information learning.", "token2charspan": [[0, 9], [10, 14], [15, 20], [21, 24], [25, 37], [38, 41], [42, 54], [55, 57], [58, 65], [66, 75], [75, 76], [77, 85], [86, 89], [90, 94], [94, 96], [97, 100], [101, 103], [104, 113], [114, 120], [121, 123], [124, 130], [131, 140], [141, 145], [145, 146], [147, 154], [155, 161], [162, 165], [166, 177], [178, 186], [186, 187]]}
{"doc_key": "ai-test-346", "ner": [[8, 8, "programlang"], [10, 11, "programlang"], [13, 13, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "usually", "provides", "bindings", "to", "languages", "such", "as", "Python", ",", "C", "++", ",", "Java", ")", "."], "sentence-detokenized": "It usually provides bindings to languages such as Python, C++, Java).", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 28], [29, 31], [32, 41], [42, 46], [47, 49], [50, 56], [56, 57], [58, 59], [59, 61], [61, 62], [63, 67], [67, 68], [68, 69]]}
{"doc_key": "ai-test-347", "ner": [[0, 2, "product"], [4, 4, "product"], [14, 15, "task"], [21, 22, "task"], [26, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 14, 15, "usage", "", false, false], [0, 2, 21, 22, "usage", "", false, false], [0, 2, 26, 29, "usage", "", false, false], [4, 4, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Voice", "-user", "interfaces", "(", "VUIs", ")", "enable", "spoken", "human", "interaction", "with", "computers", ",", "using", "speech", "recognition", "to", "understand", "spoken", "commands", "and", "answer", "questions", ",", "and", "usually", "text", "to", "voice", "to", "play", "answers", "."], "sentence-detokenized": "Voice-user interfaces (VUIs) enable spoken human interaction with computers, using speech recognition to understand spoken commands and answer questions, and usually text to voice to play answers.", "token2charspan": [[0, 5], [5, 10], [11, 21], [22, 23], [23, 27], [27, 28], [29, 35], [36, 42], [43, 48], [49, 60], [61, 65], [66, 75], [75, 76], [77, 82], [83, 89], [90, 101], [102, 104], [105, 115], [116, 122], [123, 131], [132, 135], [136, 142], [143, 152], [152, 153], [154, 157], [158, 165], [166, 170], [171, 173], [174, 179], [180, 182], [183, 187], [188, 195], [195, 196]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 4, "misc"], [7, 7, "programlang"], [11, 14, "researcher"], [16, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 4, "general-affiliation", "is_a", false, false], [0, 0, 7, 7, "general-affiliation", "made_with", false, false], [0, 0, 11, 14, "origin", "", false, false], [11, 14, 16, 17, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Jess", "is", "a", "rule", "engine", "for", "the", "Java", "platform", "developed", "by", "Ernest", "Friedman", "-", "Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "Jess is a rule engine for the Java platform developed by Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 14], [15, 21], [22, 25], [26, 29], [30, 34], [35, 43], [44, 53], [54, 56], [57, 63], [64, 72], [72, 73], [73, 77], [78, 80], [81, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-349", "ner": [[1, 2, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 15, 15, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "multilayer", "perceptrons", ",", "where", "there", "are", "hidden", "layers", ",", "more", "advanced", "algorithms", "such", "as", "backpropagation", "should", "be", "used", "."], "sentence-detokenized": "For multilayer perceptrons, where there are hidden layers, more advanced algorithms such as backpropagation should be used.", "token2charspan": [[0, 3], [4, 14], [15, 26], [26, 27], [28, 33], [34, 39], [40, 43], [44, 50], [51, 57], [57, 58], [59, 63], [64, 72], [73, 83], [84, 88], [89, 91], [92, 107], [108, 114], [115, 117], [118, 122], [122, 123]]}
{"doc_key": "ai-test-350", "ner": [[0, 1, "product"], [3, 6, "product"], [10, 17, "algorithm"], [22, 23, "field"], [28, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 0, 1, "part-of", "", false, false], [3, 6, 10, 17, "usage", "", false, true], [10, 17, 22, 23, "related-to", "performs", false, false], [28, 33, 22, 23, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "Translate", "'s", "neural", "machine", "translation", "system", "uses", "a", "large", "end", "-", "to", "-", "end", "artificial", "neural", "network", "that", "attempts", "to", "perform", "deep", "learning", ",", "specifically", ",", "a", "long", "short", "-", "term", "memory", "network", "."], "sentence-detokenized": "Google Translate's neural machine translation system uses a large end-to-end artificial neural network that attempts to perform deep learning, specifically, a long short-term memory network.", "token2charspan": [[0, 6], [7, 16], [16, 18], [19, 25], [26, 33], [34, 45], [46, 52], [53, 57], [58, 59], [60, 65], [66, 69], [69, 70], [70, 72], [72, 73], [73, 76], [77, 87], [88, 94], [95, 102], [103, 107], [108, 116], [117, 119], [120, 127], [128, 132], [133, 141], [141, 142], [143, 155], [155, 156], [157, 158], [159, 163], [164, 169], [169, 170], [170, 174], [175, 181], [182, 189], [189, 190]]}
{"doc_key": "ai-test-351", "ner": [[14, 14, "researcher"], [16, 16, "researcher"], [18, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Various", "methods", "to", "do", "so", "were", "developed", "in", "the", "1980s", "and", "early", "1990s", "by", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "and", "others", "."], "sentence-detokenized": "Various methods to do so were developed in the 1980s and early 1990s by Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter and others.", "token2charspan": [[0, 7], [8, 15], [16, 18], [19, 21], [22, 24], [25, 29], [30, 39], [40, 42], [43, 46], [47, 52], [53, 56], [57, 62], [63, 68], [69, 71], [72, 78], [78, 79], [80, 88], [88, 89], [90, 98], [98, 99], [100, 106], [107, 118], [118, 119], [120, 124], [125, 135], [135, 136], [137, 148], [149, 152], [153, 159], [159, 160]]}
{"doc_key": "ai-test-352", "ner": [[0, 1, "organisation"], [2, 3, "organisation"], [8, 8, "organisation"], [11, 12, "task"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 8, 8, "role", "licenses_from", false, false], [2, 3, 0, 1, "named", "", false, false], [19, 19, 0, 1, "origin", "", false, false], [19, 19, 11, 12, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc", "originally", "licensed", "software", "from", "Nuance", "to", "provide", "voice", "recognition", "capabilities", "to", "its", "digital", "assistant", ",", "Siri", "."], "sentence-detokenized": "| Apple Apple Inc originally licensed software from Nuance to provide voice recognition capabilities to its digital assistant, Siri.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 17], [18, 28], [29, 37], [38, 46], [47, 51], [52, 58], [59, 61], [62, 69], [70, 75], [76, 87], [88, 100], [101, 103], [104, 107], [108, 115], [116, 125], [125, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [3, 5, "misc"], [8, 9, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 5, "role", "releases_movies_in_genre", false, false], [8, 9, 0, 0, "role", "directs_for", false, false], [13, 14, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "released", "several", "3D", "western", "films", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia released several 3D western films produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 28], [29, 36], [37, 42], [43, 51], [52, 54], [55, 58], [59, 66], [67, 70], [71, 79], [80, 82], [83, 90], [91, 97], [97, 98]]}
{"doc_key": "ai-test-354", "ner": [[9, 10, "field"], [12, 12, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "combines", "knowledge", "and", "research", "in", "the", "fields", "of", "computer", "science", ",", "linguistics", "and", "computer", "engineering", "."], "sentence-detokenized": "It combines knowledge and research in the fields of computer science, linguistics and computer engineering.", "token2charspan": [[0, 2], [3, 11], [12, 21], [22, 25], [26, 34], [35, 37], [38, 41], [42, 48], [49, 51], [52, 60], [61, 68], [68, 69], [70, 81], [82, 85], [86, 94], [95, 106], [106, 107]]}
{"doc_key": "ai-test-355", "ner": [[6, 7, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "is", "an", "example", "of", "R", "code", ":"], "sentence-detokenized": "The following is an example of R code:", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 19], [20, 27], [28, 30], [31, 32], [33, 37], [37, 38]]}
{"doc_key": "ai-test-356", "ner": [[0, 3, "metrics"], [8, 10, "metrics"], [12, 12, "metrics"], [16, 18, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 8, 10, "part-of", "plotted_into", false, false], [0, 3, 16, 18, "part-of", "plotted_into", false, false], [12, 12, 8, 10, "named", "", false, false], [20, 20, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "ROC", "curve", "is", "created", "by", "plotting", "the", "TRUE", "positive", "rate", "(", "TPR", ")", "against", "the", "FALSE", "positive", "rate", "(", "FPR", ")", "at", "various", "threshold", "settings", "."], "sentence-detokenized": "The ROC curve is created by plotting the TRUE positive rate (TPR) against the FALSE positive rate (FPR) at various threshold settings.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 24], [25, 27], [28, 36], [37, 40], [41, 45], [46, 54], [55, 59], [60, 61], [61, 64], [64, 65], [66, 73], [74, 77], [78, 83], [84, 92], [93, 97], [98, 99], [99, 102], [102, 103], [104, 106], [107, 114], [115, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-test-357", "ner": [[3, 4, "field"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 3, 4, "related-to", "researches_field", false, false], [10, 11, 3, 4, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Research", "stagnated", "after", "machine", "learning", "research", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", ","], "sentence-detokenized": "Research stagnated after machine learning research by Marvin Minsky and Seymour Papert (1969),", "token2charspan": [[0, 8], [9, 18], [19, 24], [25, 32], [33, 41], [42, 50], [51, 53], [54, 60], [61, 67], [68, 71], [72, 79], [80, 86], [87, 88], [88, 92], [92, 93], [93, 94]]}
{"doc_key": "ai-test-358", "ner": [[6, 6, "task"], [9, 10, "programlang"], [12, 14, "product"], [16, 17, "programlang"], [19, 19, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 9, 10, "related-to", "used_to_build", false, false], [6, 6, 12, 14, "related-to", "used_to_build", false, false], [6, 6, 16, 17, "related-to", "used_to_build", false, false], [6, 6, 19, 19, "related-to", "used_to_build", false, false], [6, 6, 22, 22, "related-to", "used_to_build", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "programming", "environments", "used", "to", "build", "DAQ", "applications", "include", "ladder", "logic", ",", "Visual", "C", "++", ",", "Visual", "Basic", ",", "LabVIEW", ",", "and", "MATLAB", "."], "sentence-detokenized": "Other programming environments used to build DAQ applications include ladder logic, Visual C++, Visual Basic, LabVIEW, and MATLAB.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 38], [39, 44], [45, 48], [49, 61], [62, 69], [70, 76], [77, 82], [82, 83], [84, 90], [91, 92], [92, 94], [94, 95], [96, 102], [103, 108], [108, 109], [110, 117], [117, 118], [119, 122], [123, 129], [129, 130]]}
{"doc_key": "ai-test-359", "ner": [[14, 15, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "designed", "to", "fix", "some", "of", "the", "issues", "found", "in", "the", "more", "popular", "BLEU", "metric", ",", "and", "also", "produces", "a", "good", "correlation", "with", "human", "judgement", "at", "the", "sentence", "or", "segment", "level", "."], "sentence-detokenized": "It is designed to fix some of the issues found in the more popular BLEU metric, and also produces a good correlation with human judgement at the sentence or segment level.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 21], [22, 26], [27, 29], [30, 33], [34, 40], [41, 46], [47, 49], [50, 53], [54, 58], [59, 66], [67, 71], [72, 78], [78, 79], [80, 83], [84, 88], [89, 97], [98, 99], [100, 104], [105, 116], [117, 121], [122, 127], [128, 137], [138, 140], [141, 144], [145, 153], [154, 156], [157, 164], [165, 170], [170, 171]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "Networks", ",", "Convolutional", "neural", "networks", "and", "long", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "semantic", "correlations", "between", "consecutive", "video", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov Networks, Convolutional neural networks and long short-term memory are often used to exploit semantic correlations between consecutive video frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [83, 88], [88, 89], [89, 93], [94, 100], [101, 104], [105, 110], [111, 115], [116, 118], [119, 126], [127, 135], [136, 148], [149, 156], [157, 168], [169, 174], [175, 181], [181, 182]]}
{"doc_key": "ai-test-361", "ner": [[3, 4, "product"], [7, 7, "product"], [14, 19, "product"], [23, 23, "product"], [40, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 14, 19, "artifact", "", false, false], [3, 4, 40, 40, "named", "", false, false], [7, 7, 3, 4, "named", "", false, false], [23, 23, 14, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Mass", "-", "produced", "printed", "circuit", "boards", "(", "PCBs", ")", "are", "almost", "exclusively", "manufactured", "by", "pick", "-", "and", "-", "place", "robots", ",", "usually", "with", "SCARA", "manipulators", ",", "which", "remove", "small", "electronic", "components", "from", "strips", "or", "trays", ",", "and", "place", "them", "onto", "PCBs", "with", "great", "accuracy", "."], "sentence-detokenized": "Mass-produced printed circuit boards (PCBs) are almost exclusively manufactured by pick-and-place robots, usually with SCARA manipulators, which remove small electronic components from strips or trays, and place them onto PCBs with great accuracy.", "token2charspan": [[0, 4], [4, 5], [5, 13], [14, 21], [22, 29], [30, 36], [37, 38], [38, 42], [42, 43], [44, 47], [48, 54], [55, 66], [67, 79], [80, 82], [83, 87], [87, 88], [88, 91], [91, 92], [92, 97], [98, 104], [104, 105], [106, 113], [114, 118], [119, 124], [125, 137], [137, 138], [139, 144], [145, 151], [152, 157], [158, 168], [169, 179], [180, 184], [185, 191], [192, 194], [195, 200], [200, 201], [202, 205], [206, 211], [212, 216], [217, 221], [222, 226], [227, 231], [232, 237], [238, 246], [246, 247]]}
{"doc_key": "ai-test-362", "ner": [[4, 5, "field"], [8, 16, "algorithm"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 29, "researcher"], [37, 38, "algorithm"], [40, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[8, 16, 4, 5, "part-of", "", false, false], [8, 16, 20, 21, "origin", "", false, false], [8, 16, 23, 24, "origin", "", false, false], [8, 16, 26, 29, "origin", "", false, false], [8, 16, 37, 38, "type-of", "", false, false], [37, 38, 40, 41, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "context", "of", "machine", "learning", ",", "where", "LDA", "is", "most", "widely", "applied", "today", ",", "LDA", "was", "independently", "reinvented", "by", "David", "Blei", ",", "Andrew", "Ng", "and", "Michael", "I", ".", "Jordan", "in", "2003", ",", "and", "presented", "as", "a", "graphical", "model", "for", "topic", "discovery", "."], "sentence-detokenized": "In the context of machine learning, where LDA is most widely applied today, LDA was independently reinvented by David Blei, Andrew Ng and Michael I. Jordan in 2003, and presented as a graphical model for topic discovery.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 25], [26, 34], [34, 35], [36, 41], [42, 45], [46, 48], [49, 53], [54, 60], [61, 68], [69, 74], [74, 75], [76, 79], [80, 83], [84, 97], [98, 108], [109, 111], [112, 117], [118, 122], [122, 123], [124, 130], [131, 133], [134, 137], [138, 145], [146, 147], [147, 148], [149, 155], [156, 158], [159, 163], [163, 164], [165, 168], [169, 178], [179, 181], [182, 183], [184, 193], [194, 199], [200, 203], [204, 209], [210, 219], [219, 220]]}
{"doc_key": "ai-test-363", "ner": [[10, 10, "task"], [13, 13, "misc"], [16, 16, "metrics"], [18, 18, "metrics"], [21, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 10, 13, 13, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "performance", "measured", "on", "the", "test", "data", "of", "eight", "naive", "WSIs", "across", "different", "tauopathies", "resulted", "in", "recall", ",", "precision", ",", "and", "F1", "scores", "of", "0.92", ",", "0.72", ",", "and", "0.81", ",", "respectively", "."], "sentence-detokenized": "The performance measured on the test data of eight naive WSIs across different tauopathies resulted in recall, precision, and F1 scores of 0.92, 0.72, and 0.81, respectively.", "token2charspan": [[0, 3], [4, 15], [16, 24], [25, 27], [28, 31], [32, 36], [37, 41], [42, 44], [45, 50], [51, 56], [57, 61], [62, 68], [69, 78], [79, 90], [91, 99], [100, 102], [103, 109], [109, 110], [111, 120], [120, 121], [122, 125], [126, 128], [129, 135], [136, 138], [139, 143], [143, 144], [145, 149], [149, 150], [151, 154], [155, 159], [159, 160], [161, 173], [173, 174]]}
{"doc_key": "ai-test-364", "ner": [[5, 5, "field"], [11, 12, "field"], [15, 15, "field"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 15, 15, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["With", "the", "help", "of", "advanced", "AR", "technologies", "(", "e.g.", ",", "adding", "computer", "vision", ",", "incorporating", "AR", "cameras", "into", "smartphones", "and", "object", "recognition", ")", ",", "information", "about", "the", "real", "world", "around", "the", "user", "becomes", "interactive", "and", "digitally", "manipulated", "."], "sentence-detokenized": "With the help of advanced AR technologies (e.g., adding computer vision, incorporating AR cameras into smartphones and object recognition), information about the real world around the user becomes interactive and digitally manipulated.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 25], [26, 28], [29, 41], [42, 43], [43, 47], [47, 48], [49, 55], [56, 64], [65, 71], [71, 72], [73, 86], [87, 89], [90, 97], [98, 102], [103, 114], [115, 118], [119, 125], [126, 137], [137, 138], [138, 139], [140, 151], [152, 157], [158, 161], [162, 166], [167, 172], [173, 179], [180, 183], [184, 188], [189, 196], [197, 208], [209, 212], [213, 222], [223, 234], [234, 235]]}
{"doc_key": "ai-test-365", "ner": [[3, 3, "researcher"], [8, 8, "organisation"], [16, 17, "field"], [27, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 8, "role", "forms_company", false, false], [8, 8, 16, 17, "related-to", "works_with", false, false], [8, 8, 27, 30, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2014", ",", "Schmidhuber", "formed", "a", "company", ",", "Nnaisense", ",", "to", "work", "on", "commercial", "applications", "of", "artificial", "intelligence", "in", "areas", "such", "as", "finance", ",", "heavy", "industry", "and", "self", "-", "driving", "cars", "."], "sentence-detokenized": "In 2014, Schmidhuber formed a company, Nnaisense, to work on commercial applications of artificial intelligence in areas such as finance, heavy industry and self-driving cars.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 27], [28, 29], [30, 37], [37, 38], [39, 48], [48, 49], [50, 52], [53, 57], [58, 60], [61, 71], [72, 84], [85, 87], [88, 98], [99, 111], [112, 114], [115, 120], [121, 125], [126, 128], [129, 136], [136, 137], [138, 143], [144, 152], [153, 156], [157, 161], [161, 162], [162, 169], [170, 174], [174, 175]]}
{"doc_key": "ai-test-366", "ner": [[26, 28, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Not", "only", "does", "this", "change", "the", "performance", "of", "all", "subsequent", "tests", "on", "the", "retained", "explanatory", "model", ",", "but", "it", "can", "also", "introduce", "bias", "and", "change", "the", "mean", "square", "error", "in", "the", "estimates", "."], "sentence-detokenized": "Not only does this change the performance of all subsequent tests on the retained explanatory model, but it can also introduce bias and change the mean square error in the estimates.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 18], [19, 25], [26, 29], [30, 41], [42, 44], [45, 48], [49, 59], [60, 65], [66, 68], [69, 72], [73, 81], [82, 93], [94, 99], [99, 100], [101, 104], [105, 107], [108, 111], [112, 116], [117, 126], [127, 131], [132, 135], [136, 142], [143, 146], [147, 151], [152, 158], [159, 164], [165, 167], [168, 171], [172, 181], [181, 182]]}
{"doc_key": "ai-test-367", "ner": [[0, 0, "misc"], [7, 7, "algorithm"], [10, 11, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 0, 0, "usage", "", false, false], [7, 7, 10, 11, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Bigrams", "are", "used", "in", "the", "most", "successful", "language", "models", "for", "speech", "recognition", "."], "sentence-detokenized": "Bigrams are used in the most successful language models for speech recognition.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 23], [24, 28], [29, 39], [40, 48], [49, 55], [56, 59], [60, 66], [67, 78], [78, 79]]}
{"doc_key": "ai-test-368", "ner": [[3, 4, "field"], [8, 10, "misc"], [15, 17, "misc"], [22, 24, "organisation"], [27, 29, "misc"], [35, 38, "organisation"], [41, 43, "misc"], [49, 53, "organisation"], [57, 59, "misc"], [65, 67, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[8, 10, 3, 4, "topic", "", false, false], [15, 17, 22, 24, "origin", "", false, false], [27, 29, 35, 38, "origin", "", false, false], [41, 43, 49, 53, "origin", "", false, false], [57, 59, 65, 67, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["His", "research", "in", "cognitive", "psychology", "has", "won", "the", "Early", "Career", "Award", "(", "1984", ")", "and", "Boyd", "McCandless", "Award", "1986", ")", "from", "the", "American", "Psychological", "Association", ",", "the", "Troland", "Research", "Award", "(", "1993", ")", "from", "the", "National", "Academy", "of", "Sciences", ",", "the", "Henry", "Dale", "Prize", "(", "2004", ")", "from", "the", "Royal", "Institution", "of", "Great", "Britain", ",", "and", "the", "George", "Miller", "Prize", "(", "2010", ")", "from", "the", "Cognitive", "Neuroscience", "Society", "."], "sentence-detokenized": "His research in cognitive psychology has won the Early Career Award (1984) and Boyd McCandless Award 1986) from the American Psychological Association, the Troland Research Award (1993) from the National Academy of Sciences, the Henry Dale Prize (2004) from the Royal Institution of Great Britain, and the George Miller Prize (2010) from the Cognitive Neuroscience Society.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 25], [26, 36], [37, 40], [41, 44], [45, 48], [49, 54], [55, 61], [62, 67], [68, 69], [69, 73], [73, 74], [75, 78], [79, 83], [84, 94], [95, 100], [101, 105], [105, 106], [107, 111], [112, 115], [116, 124], [125, 138], [139, 150], [150, 151], [152, 155], [156, 163], [164, 172], [173, 178], [179, 180], [180, 184], [184, 185], [186, 190], [191, 194], [195, 203], [204, 211], [212, 214], [215, 223], [223, 224], [225, 228], [229, 234], [235, 239], [240, 245], [246, 247], [247, 251], [251, 252], [253, 257], [258, 261], [262, 267], [268, 279], [280, 282], [283, 288], [289, 296], [296, 297], [298, 301], [302, 305], [306, 312], [313, 319], [320, 325], [326, 327], [327, 331], [331, 332], [333, 337], [338, 341], [342, 351], [352, 364], [365, 372], [372, 373]]}
{"doc_key": "ai-test-369", "ner": [[1, 1, "misc"], [7, 7, "misc"], [9, 12, "product"], [15, 15, "researcher"], [17, 17, "researcher"], [24, 25, "researcher"], [27, 28, "researcher"], [30, 31, "task"], [33, 36, "researcher"], [38, 42, "researcher"], [43, 44, "task"], [46, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[1, 1, 7, 7, "named", "", false, false], [1, 1, 46, 46, "named", "", false, false], [7, 7, 15, 15, "origin", "", false, false], [7, 7, 17, 17, "origin", "", false, false], [7, 7, 30, 31, "related-to", "used_for", false, false], [9, 12, 7, 7, "usage", "", false, false], [9, 12, 43, 44, "named", "", false, false], [24, 25, 7, 7, "usage", "", false, false], [24, 25, 33, 36, "named", "same", false, false], [27, 28, 7, 7, "usage", "", false, false], [27, 28, 38, 42, "named", "same", false, false], [43, 44, 46, 46, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["An", "eigenface", "(", "The", "approach", "of", "using", "eigenfaces", "for", "face", "recognition", "systems", "was", "developed", "by", "Sirovich", "and", "Kirby", "(", "1987", ")", "and", "used", "by", "Matthew", "Turk", "and", "Alex", "Pentland", "in", "face", "classification", ".", "Turk", ",", "Matthew", "A", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "An eigenface (The approach of using eigenfaces for face recognition systems was developed by Sirovich and Kirby (1987) and used by Matthew Turk and Alex Pentland in face classification. Turk, Matthew A and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 2], [3, 12], [13, 14], [14, 17], [18, 26], [27, 29], [30, 35], [36, 46], [47, 50], [51, 55], [56, 67], [68, 75], [76, 79], [80, 89], [90, 92], [93, 101], [102, 105], [106, 111], [112, 113], [113, 117], [117, 118], [119, 122], [123, 127], [128, 130], [131, 138], [139, 143], [144, 147], [148, 152], [153, 161], [162, 164], [165, 169], [170, 184], [184, 185], [186, 190], [190, 191], [192, 199], [200, 201], [202, 205], [206, 214], [214, 215], [216, 220], [221, 222], [222, 223], [224, 228], [229, 240], [241, 246], [247, 257], [257, 258]]}
{"doc_key": "ai-test-370", "ner": [[4, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Lexical", "dictionaries", "such", "as", "Word", "Net", "can", "then", "be", "used", "to", "understand", "the", "context", "."], "sentence-detokenized": "Lexical dictionaries such as WordNet can then be used to understand the context.", "token2charspan": [[0, 7], [8, 20], [21, 25], [26, 28], [29, 33], [33, 36], [37, 40], [41, 45], [46, 48], [49, 53], [54, 56], [57, 67], [68, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-test-371", "ner": [[0, 0, "misc"], [8, 8, "misc"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 8, "part-of", "", false, false], [8, 8, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hyponymy", "is", "the", "most", "frequently", "encoded", "relation", "among", "synsets", "used", "in", "lexical", "databases", "such", "as", "WordNet", "."], "sentence-detokenized": "Hyponymy is the most frequently encoded relation among synsets used in lexical databases such as WordNet.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 20], [21, 31], [32, 39], [40, 48], [49, 54], [55, 62], [63, 67], [68, 70], [71, 78], [79, 88], [89, 93], [94, 96], [97, 104], [104, 105]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [6, 7, "programlang"], [9, 9, "programlang"], [35, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 7, "general-affiliation", "", false, false], [0, 0, 9, 9, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "offers", "open", "source", "libraries", "in", "C", "++", "and", "Java", ",", "but", "many", "clients", "rely", "on", "community", "-", "developed", "libraries", "such", "as", "libraries", "that", "include", "embedded", "capabilities", "to", "retrieve", "data", "(", "array", "style", ")", "from", "DAP", "servers", "."], "sentence-detokenized": "OPeNDAP offers open source libraries in C++ and Java, but many clients rely on community-developed libraries such as libraries that include embedded capabilities to retrieve data (array style) from DAP servers.", "token2charspan": [[0, 7], [8, 14], [15, 19], [20, 26], [27, 36], [37, 39], [40, 41], [41, 43], [44, 47], [48, 52], [52, 53], [54, 57], [58, 62], [63, 70], [71, 75], [76, 78], [79, 88], [88, 89], [89, 98], [99, 108], [109, 113], [114, 116], [117, 126], [127, 131], [132, 139], [140, 148], [149, 161], [162, 164], [165, 173], [174, 178], [179, 180], [180, 185], [186, 191], [191, 192], [193, 197], [198, 201], [202, 209], [209, 210]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [8, 8, "product"], [17, 17, "country"], [31, 32, "misc"], [46, 47, "organisation"], [48, 48, "product"], [50, 51, "organisation"], [52, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 17, 17, "opposite", "", false, false], [8, 8, 17, 17, "artifact", "", false, false], [31, 32, 8, 8, "part-of", "", false, false], [48, 48, 46, 47, "artifact", "", false, false], [52, 56, 50, 51, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "that", "page", ",", "Samurai", "Damashii", "exaggerated", "the", "Senkousha", "as", "the", "crystallisation", "of", "four", "thousand", "years", "of", "Chinese", "scientific", "knowledge", ",", "commented", "on", "its", "crude", "design", "(", "for", "example", ",", "the", "Chinese", "Cannon", "on", "its", "crotch", ")", ",", "and", "placed", "it", "s", "image", "between", "those", "of", "Honda", "'s", "ASIMO", "and", "Sony", "'s", "QRIO", "SDR", "-", "3", "X", "for", "juxtaposition", "."], "sentence-detokenized": "In that page, Samurai Damashii exaggerated the Senkousha as the crystallisation of four thousand years of Chinese scientific knowledge, commented on its crude design (for example, the Chinese Cannon on its crotch), and placed its image between those of Honda's ASIMO and Sony's QRIO SDR-3X for juxtaposition.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 21], [22, 30], [31, 42], [43, 46], [47, 56], [57, 59], [60, 63], [64, 79], [80, 82], [83, 87], [88, 96], [97, 102], [103, 105], [106, 113], [114, 124], [125, 134], [134, 135], [136, 145], [146, 148], [149, 152], [153, 158], [159, 165], [166, 167], [167, 170], [171, 178], [178, 179], [180, 183], [184, 191], [192, 198], [199, 201], [202, 205], [206, 212], [212, 213], [213, 214], [215, 218], [219, 225], [226, 228], [228, 229], [230, 235], [236, 243], [244, 249], [250, 252], [253, 258], [258, 260], [261, 266], [267, 270], [271, 275], [275, 277], [278, 282], [283, 286], [286, 287], [287, 288], [288, 289], [290, 293], [294, 307], [307, 308]]}
{"doc_key": "ai-test-374", "ner": [[8, 9, "algorithm"], [22, 22, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 22, 22, "part-of", "includes_functionality_of", false, false], [8, 9, 24, 24, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "also", "many", "programming", "libraries", "that", "contain", "neural", "network", "functionality", "and", "that", "can", "be", "used", "in", "custom", "implementations", "(", "such", "as", "TensorFlow", ",", "Theano", ",", "etc.", ")", "."], "sentence-detokenized": "There are also many programming libraries that contain neural network functionality and that can be used in custom implementations (such as TensorFlow, Theano, etc.).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 31], [32, 41], [42, 46], [47, 54], [55, 61], [62, 69], [70, 83], [84, 87], [88, 92], [93, 96], [97, 99], [100, 104], [105, 107], [108, 114], [115, 130], [131, 132], [132, 136], [137, 139], [140, 150], [150, 151], [152, 158], [158, 159], [160, 164], [164, 165], [165, 166]]}
{"doc_key": "ai-test-375", "ner": [[6, 9, "conference"], [11, 11, "organisation"], [13, 19, "conference"], [21, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", "and", "SPIE", "."], "sentence-detokenized": "He is a Fellow of the Association for Computing Machinery, IEEE, American Association for the Advancement of Science, IAPR and SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 33], [34, 37], [38, 47], [48, 57], [57, 58], [59, 63], [63, 64], [65, 73], [74, 85], [86, 89], [90, 93], [94, 105], [106, 108], [109, 116], [116, 117], [118, 122], [123, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-376", "ner": [[3, 3, "organisation"], [7, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 7, 9, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["Trials", "by", "the", "RET", "in", "2011", "with", "facial", "recognition", "system", "cameras", "installed", "on", "trams", "ensured", "that", "people", "banned", "from", "trams", "did", "not", "sneak", "in", "."], "sentence-detokenized": "Trials by the RET in 2011 with facial recognition system cameras installed on trams ensured that people banned from trams did not sneak in.", "token2charspan": [[0, 6], [7, 9], [10, 13], [14, 17], [18, 20], [21, 25], [26, 30], [31, 37], [38, 49], [50, 56], [57, 64], [65, 74], [75, 77], [78, 83], [84, 91], [92, 96], [97, 103], [104, 110], [111, 115], [116, 121], [122, 125], [126, 129], [130, 135], [136, 138], [138, 139]]}
{"doc_key": "ai-test-377", "ner": [[5, 7, "person"], [9, 9, "organisation"], [18, 19, "person"], [21, 22, "person"], [30, 31, "person"], [33, 34, "person"], [36, 37, "person"], [39, 40, "person"], [42, 43, "person"], [45, 46, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[5, 7, 9, 9, "role", "works_for", false, false], [18, 19, 9, 9, "role", "works_for", false, false], [21, 22, 9, 9, "role", "works_for", false, false], [30, 31, 9, 9, "role", "works_for", false, false], [33, 34, 9, 9, "role", "works_for", false, false], [36, 37, 9, 9, "role", "works_for", false, false], [39, 40, 9, 9, "role", "works_for", false, false], [42, 43, 9, 9, "role", "works_for", false, false], [45, 46, 9, 9, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "film", ",", "adapted", "from", "Cole", "Porter", "'s", "popular", "Broadway", "musical", ",", "stars", "the", "MGM", "singing", "team", "of", "Howard", "Keel", "and", "Kathryn", "Grayson", "in", "the", "lead", "roles", ",", "supported", "by", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "and", "Tommy", "Rall", "."], "sentence-detokenized": "The film, adapted from Cole Porter's popular Broadway musical, stars the MGM singing team of Howard Keel and Kathryn Grayson in the lead roles, supported by Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar and Tommy Rall.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 17], [18, 22], [23, 27], [28, 34], [34, 36], [37, 44], [45, 53], [54, 61], [61, 62], [63, 68], [69, 72], [73, 76], [77, 84], [85, 89], [90, 92], [93, 99], [100, 104], [105, 108], [109, 116], [117, 124], [125, 127], [128, 131], [132, 136], [137, 142], [142, 143], [144, 153], [154, 156], [157, 160], [161, 167], [167, 168], [169, 175], [176, 180], [180, 181], [182, 187], [188, 191], [191, 192], [193, 198], [199, 207], [207, 208], [209, 213], [214, 221], [222, 225], [226, 231], [232, 236], [236, 237]]}
{"doc_key": "ai-test-378", "ner": [[17, 19, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "applications", "should", "streamline", "call", "flows", ",", "minimise", "requests", ",", "eliminate", "unnecessary", "iterations", "and", "enable", "complex", "mixed", "-initiative", "dialogue", "systems", ",", "allowing", "callers", "to", "enter", "multiple", "pieces", "of", "information", "in", "a", "single", "utterance", "and", "in", "any", "order", "or", "combination", "."], "sentence-detokenized": "Such applications should streamline call flows, minimise requests, eliminate unnecessary iterations and enable complex mixed-initiative dialogue systems, allowing callers to enter multiple pieces of information in a single utterance and in any order or combination.", "token2charspan": [[0, 4], [5, 17], [18, 24], [25, 35], [36, 40], [41, 46], [46, 47], [48, 56], [57, 65], [65, 66], [67, 76], [77, 88], [89, 99], [100, 103], [104, 110], [111, 118], [119, 124], [124, 135], [136, 144], [145, 152], [152, 153], [154, 162], [163, 170], [171, 173], [174, 179], [180, 188], [189, 195], [196, 198], [199, 210], [211, 213], [214, 215], [216, 222], [223, 232], [233, 236], [237, 239], [240, 243], [244, 249], [250, 252], [253, 264], [264, 265]]}
{"doc_key": "ai-test-379", "ner": [[4, 5, "algorithm"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 4, 5, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Thus", ",", "the", "traditional", "gradient", "descent", "method", "(", "or", "Stochastic", "gradient", "descent", ")", "can", "be", "adapted", ",", "where", "instead", "of", "taking", "steps", "in", "the", "direction", "of", "the", "function", "gradient", ",", "steps", "are", "taken", "in", "the", "direction", "of", "a", "selected", "vector", "of", "function", "sub-gradients", "."], "sentence-detokenized": "Thus, the traditional gradient descent method (or Stochastic gradient descent) can be adapted, where instead of taking steps in the direction of the function gradient, steps are taken in the direction of a selected vector of function sub-gradients.", "token2charspan": [[0, 4], [4, 5], [6, 9], [10, 21], [22, 30], [31, 38], [39, 45], [46, 47], [47, 49], [50, 60], [61, 69], [70, 77], [77, 78], [79, 82], [83, 85], [86, 93], [93, 94], [95, 100], [101, 108], [109, 111], [112, 118], [119, 124], [125, 127], [128, 131], [132, 141], [142, 144], [145, 148], [149, 157], [158, 166], [166, 167], [168, 173], [174, 177], [178, 183], [184, 186], [187, 190], [191, 200], [201, 203], [204, 205], [206, 214], [215, 221], [222, 224], [225, 233], [234, 247], [247, 248]]}
{"doc_key": "ai-test-380", "ner": [[11, 13, "metrics"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "it", "is", "assumed", "that", "the", "distortion", "is", "measured", "by", "the", "mean", "square", "error", ",", "the", "distortion", "D", ",", "is", "given", "by", ":"], "sentence-detokenized": "If it is assumed that the distortion is measured by the mean square error, the distortion D, is given by:", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 16], [17, 21], [22, 25], [26, 36], [37, 39], [40, 48], [49, 51], [52, 55], [56, 60], [61, 67], [68, 73], [73, 74], [75, 78], [79, 89], [90, 91], [91, 92], [93, 95], [96, 101], [102, 104], [104, 105]]}
{"doc_key": "ai-test-381", "ner": [[0, 0, "algorithm"], [4, 5, "field"], [17, 18, "task"], [20, 21, "task"], [24, 25, "task"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 5, "part-of", "", false, false], [17, 18, 0, 0, "part-of", "", false, false], [20, 21, 0, 0, "part-of", "", false, false], [24, 25, 0, 0, "part-of", "", false, false], [28, 29, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["MLPs", "were", "a", "popular", "machine", "learning", "solution", "in", "the", "1980s", ",", "finding", "applications", "in", "areas", "such", "as", "speech", "recognition", ",", "image", "recognition", ",", "and", "machine", "translation", "software", ",", "Neural", "networks", "."], "sentence-detokenized": "MLPs were a popular machine learning solution in the 1980s, finding applications in areas such as speech recognition, image recognition, and machine translation software, Neural networks.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 19], [20, 27], [28, 36], [37, 45], [46, 48], [49, 52], [53, 58], [58, 59], [60, 67], [68, 80], [81, 83], [84, 89], [90, 94], [95, 97], [98, 104], [105, 116], [116, 117], [118, 123], [124, 135], [135, 136], [137, 140], [141, 148], [149, 160], [161, 169], [169, 170], [171, 177], [178, 186], [186, 187]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [3, 3, "misc"], [6, 8, "university"], [16, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 8, "physical", "", false, false], [0, 0, 6, 8, "role", "", false, false], [3, 3, 0, 0, "origin", "", false, false], [16, 18, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "received", "his", "Ph.D.", "from", "the", "University", "of", "Toronto", "in", "1979", ",", "under", "the", "supervision", "of", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen received his Ph.D. from the University of Toronto in 1979, under the supervision of C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 24], [25, 29], [30, 33], [34, 44], [45, 47], [48, 55], [56, 58], [59, 63], [63, 64], [65, 70], [71, 74], [75, 86], [87, 89], [90, 92], [93, 100], [101, 109], [109, 110]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [5, 7, "field"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [19, 19, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 7, "related-to", "supports", false, false], [10, 10, 5, 7, "type-of", "", true, false], [12, 12, 5, 7, "type-of", "", true, false], [14, 14, 5, 7, "type-of", "", true, false], [14, 14, 19, 19, "related-to", "converting_to", true, false], [23, 23, 5, 7, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["OpenCV", "supports", "several", "models", "from", "deep", "learning", "frameworks", "such", "as", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "after", "converting", "to", "ONNX", "model", ")", "and", "Caffe", "according", "to", "the", "list", "of", "supported", "layers", "."], "sentence-detokenized": "OpenCV supports several models from deep learning frameworks such as TensorFlow, Torch, PyTorch (after converting to ONNX model) and Caffe according to the list of supported layers.", "token2charspan": [[0, 6], [7, 15], [16, 23], [24, 30], [31, 35], [36, 40], [41, 49], [50, 60], [61, 65], [66, 68], [69, 79], [79, 80], [81, 86], [86, 87], [88, 95], [96, 97], [97, 102], [103, 113], [114, 116], [117, 121], [122, 127], [127, 128], [129, 132], [133, 138], [139, 148], [149, 151], [152, 155], [156, 160], [161, 163], [164, 173], [174, 180], [180, 181]]}
{"doc_key": "ai-test-384", "ner": [[2, 2, "researcher"], [9, 12, "organisation"], [14, 14, "organisation"], [18, 22, "organisation"], [26, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 9, 12, "role", "", false, false], [2, 2, 18, 22, "role", "", false, false], [2, 2, 26, 26, "related-to", "lectures_in", false, false], [14, 14, 9, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Previously", ",", "Christensen", "was", "the", "Founding", "Chair", "of", "the", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "and", "an", "IEEE", "Robotics", "and", "Automation", "Society", "Distinguished", "Lecturer", "in", "Robotics", "."], "sentence-detokenized": "Previously, Christensen was the Founding Chair of the European Robotics Research Network (EURON) and an IEEE Robotics and Automation Society Distinguished Lecturer in Robotics.", "token2charspan": [[0, 10], [10, 11], [12, 23], [24, 27], [28, 31], [32, 40], [41, 46], [47, 49], [50, 53], [54, 62], [63, 71], [72, 80], [81, 88], [89, 90], [90, 95], [95, 96], [97, 100], [101, 103], [104, 108], [109, 117], [118, 121], [122, 132], [133, 140], [141, 154], [155, 163], [164, 166], [167, 175], [175, 176]]}
{"doc_key": "ai-test-385", "ner": [[7, 7, "field"], [9, 11, "university"], [13, 13, "location"], [15, 20, "country"], [24, 24, "misc"], [26, 26, "field"], [29, 32, "organisation"], [34, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 11, 13, 13, "physical", "", false, false], [13, 13, 15, 20, "physical", "", false, false], [24, 24, 26, 26, "topic", "", false, false], [29, 32, 34, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "received", "a", "master", "'s", "degree", "in", "mathematics", "from", "Samarkand", "State", "University", ",", "Samarkand", ",", "Soviet", "Socialist", "Republic", "of", "Uzbekistan", "in", "1958", "and", "a", "Ph.D", "in", "statistics", "at", "the", "Institute", "of", "Control", "Sciences", ",", "Moscow", "in", "1964", "."], "sentence-detokenized": "He received a master's degree in mathematics from Samarkand State University, Samarkand, Soviet Socialist Republic of Uzbekistan in 1958 and a Ph.D in statistics at the Institute of Control Sciences, Moscow in 1964.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 20], [20, 22], [23, 29], [30, 32], [33, 44], [45, 49], [50, 59], [60, 65], [66, 76], [76, 77], [78, 87], [87, 88], [89, 95], [96, 105], [106, 114], [115, 117], [118, 128], [129, 131], [132, 136], [137, 140], [141, 142], [143, 147], [148, 150], [151, 161], [162, 164], [165, 168], [169, 178], [179, 181], [182, 189], [190, 198], [198, 199], [200, 206], [207, 209], [210, 214], [214, 215]]}
{"doc_key": "ai-test-386", "ner": [[8, 8, "organisation"], [11, 13, "product"], [35, 36, "field"], [38, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 35, 36, "usage", "", false, false], [8, 8, 38, 40, "usage", "", false, false], [11, 13, 8, 8, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "an", "increasing", "amount", "of", "work", "at", "Cycorp", "involves", "giving", "Cyc", "systems", "the", "ability", "to", "communicate", "with", "end", "users", "in", "natural", "language", ",", "and", "to", "assist", "in", "the", "ongoing", "process", "of", "knowledge", "formation", "through", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "However, an increasing amount of work at Cycorp involves giving Cyc systems the ability to communicate with end users in natural language, and to assist in the ongoing process of knowledge formation through machine learning and natural language understanding.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 22], [23, 29], [30, 32], [33, 37], [38, 40], [41, 47], [48, 56], [57, 63], [64, 67], [68, 75], [76, 79], [80, 87], [88, 90], [91, 102], [103, 107], [108, 111], [112, 117], [118, 120], [121, 128], [129, 137], [137, 138], [139, 142], [143, 145], [146, 152], [153, 155], [156, 159], [160, 167], [168, 175], [176, 178], [179, 188], [189, 198], [199, 206], [207, 214], [215, 223], [224, 227], [228, 235], [236, 244], [245, 258], [258, 259]]}
{"doc_key": "ai-test-387", "ner": [[55, 55, "metrics"], [57, 57, "metrics"], [59, 59, "metrics"], [61, 62, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "if", "the", "most", "suitable", "classifier", "for", "the", "problem", "is", "sought", ",", "the", "training", "dataset", "is", "used", "to", "train", "the", "candidate", "algorithms", ",", "the", "validation", "dataset", "is", "used", "to", "compare", "their", "performance", "and", "decide", "which", "one", "to", "take", "and", ",", "finally", ",", "the", "testing", "dataset", "is", "used", "to", "obtain", "performance", "characteristics", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", ",", "F-", "measure", ",", "and", "so", "on", "."], "sentence-detokenized": "For example, if the most suitable classifier for the problem is sought, the training dataset is used to train the candidate algorithms, the validation dataset is used to compare their performance and decide which one to take and, finally, the testing dataset is used to obtain performance characteristics such as accuracy, sensitivity, specificity, F-measure, and so on.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 19], [20, 24], [25, 33], [34, 44], [45, 48], [49, 52], [53, 60], [61, 63], [64, 70], [70, 71], [72, 75], [76, 84], [85, 92], [93, 95], [96, 100], [101, 103], [104, 109], [110, 113], [114, 123], [124, 134], [134, 135], [136, 139], [140, 150], [151, 158], [159, 161], [162, 166], [167, 169], [170, 177], [178, 183], [184, 195], [196, 199], [200, 206], [207, 212], [213, 216], [217, 219], [220, 224], [225, 228], [228, 229], [230, 237], [237, 238], [239, 242], [243, 250], [251, 258], [259, 261], [262, 266], [267, 269], [270, 276], [277, 288], [289, 304], [305, 309], [310, 312], [313, 321], [321, 322], [323, 334], [334, 335], [336, 347], [347, 348], [349, 351], [351, 358], [358, 359], [360, 363], [364, 366], [367, 369], [369, 370]]}
{"doc_key": "ai-test-388", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "square", "error", "is", "0.15", "."], "sentence-detokenized": "The mean square error is 0.15.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 21], [22, 24], [25, 29], [29, 30]]}
{"doc_key": "ai-test-389", "ner": [[4, 5, "misc"], [9, 9, "organisation"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 4, 5, "role", "", false, false], [13, 14, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1979", ",", "the", "Micromouse", "competition", "was", "organised", "by", "IEEE", "as", "featured", "in", "Spectrum", "magazine", "."], "sentence-detokenized": "In 1979, the Micromouse competition was organised by IEEE as featured in Spectrum magazine.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 23], [24, 35], [36, 39], [40, 49], [50, 52], [53, 57], [58, 60], [61, 69], [70, 72], [73, 81], [82, 90], [90, 91]]}
{"doc_key": "ai-test-390", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [11, 13, "task"], [15, 16, "task"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 7, "part-of", "", false, false], [11, 13, 6, 7, "part-of", "task_part_of_field", false, false], [15, 16, 6, 7, "part-of", "task_part_of_field", false, false], [18, 19, 6, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Gabor", "spaces", "are", "very", "useful", "in", "image", "processing", "applications", "such", "as", "optical", "character", "recognition", ",", "iris", "recognition", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "Gabor spaces are very useful in image processing applications such as optical character recognition, iris recognition and fingerprint recognition.", "token2charspan": [[0, 5], [6, 12], [13, 16], [17, 21], [22, 28], [29, 31], [32, 37], [38, 48], [49, 61], [62, 66], [67, 69], [70, 77], [78, 87], [88, 99], [99, 100], [101, 105], [106, 117], [118, 121], [122, 133], [134, 145], [145, 146]]}
{"doc_key": "ai-test-391", "ner": [[7, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "through", "high", "-", "level", "interfaces", "to", "Java", "and", "Tcl", "."], "sentence-detokenized": "or through high-level interfaces to Java and Tcl.", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [16, 21], [22, 32], [33, 35], [36, 40], [41, 44], [45, 48], [48, 49]]}
{"doc_key": "ai-test-392", "ner": [[10, 11, "algorithm"], [18, 18, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 18, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "recent", "research", ",", "kernel", "-", "based", "methods", "such", "as", "support", "vector", "machines", "have", "shown", "superior", "performance", "in", "surveillance", "."], "sentence-detokenized": "In recent research, kernel-based methods such as support vector machines have shown superior performance in surveillance.", "token2charspan": [[0, 2], [3, 9], [10, 18], [18, 19], [20, 26], [26, 27], [27, 32], [33, 40], [41, 45], [46, 48], [49, 56], [57, 63], [64, 72], [73, 77], [78, 83], [84, 92], [93, 104], [105, 107], [108, 120], [120, 121]]}
{"doc_key": "ai-test-393", "ner": [[16, 16, "misc"], [22, 22, "researcher"], [24, 24, "researcher"], [32, 32, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 32, 32, "usage", "", false, false], [24, 24, 32, 32, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "illustrate", "the", "basic", "principles", "of", "bagging", ",", "below", "is", "an", "analysis", "of", "the", "relationship", "between", "ozone", "and", "temperature", "(", "data", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "analysis", "done", "in", "R", ")", "."], "sentence-detokenized": "To illustrate the basic principles of bagging, below is an analysis of the relationship between ozone and temperature (data from Rousseeuw and Leroy (1986), analysis done in R).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 34], [35, 37], [38, 45], [45, 46], [47, 52], [53, 55], [56, 58], [59, 67], [68, 70], [71, 74], [75, 87], [88, 95], [96, 101], [102, 105], [106, 117], [118, 119], [119, 123], [124, 128], [129, 138], [139, 142], [143, 148], [149, 150], [150, 154], [154, 155], [155, 156], [157, 165], [166, 170], [171, 173], [174, 175], [175, 176], [176, 177]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [11, 11, "product"], [18, 19, "product"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 0, 1, "artifact", "", false, false], [18, 19, 0, 1, "artifact", "", false, false], [21, 23, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Denso", "Wave", "is", "a", "subsidiary", "that", "manufactures", "automatic", "identification", "products", "(", "barcode", "readers", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "Denso Wave is a subsidiary that manufactures automatic identification products (barcode readers and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 15], [16, 26], [27, 31], [32, 44], [45, 54], [55, 69], [70, 78], [79, 80], [80, 87], [88, 95], [96, 99], [100, 107], [108, 116], [116, 117], [117, 118], [119, 129], [130, 136], [137, 140], [141, 153], [154, 159], [160, 171], [171, 172]]}
{"doc_key": "ai-test-395", "ner": [[2, 3, "metrics"], [7, 8, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 19, 19, "compare", "", false, false], [7, 8, 2, 3, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "the", "Bilingual", "evaluation", "only", "calculates", "the", "precision", "of", "n", "-", "grams", "by", "adding", "equal", "weights", "to", "each", ",", "NIST", "also", "calculates", "how", "informative", "a", "particular", "n-", "gram", "is", "."], "sentence-detokenized": "While the Bilingual evaluation only calculates the precision of n-grams by adding equal weights to each, NIST also calculates how informative a particular n-gram is.", "token2charspan": [[0, 5], [6, 9], [10, 19], [20, 30], [31, 35], [36, 46], [47, 50], [51, 60], [61, 63], [64, 65], [65, 66], [66, 71], [72, 74], [75, 81], [82, 87], [88, 95], [96, 98], [99, 103], [103, 104], [105, 109], [110, 114], [115, 125], [126, 129], [130, 141], [142, 143], [144, 154], [155, 157], [157, 161], [162, 164], [164, 165]]}
{"doc_key": "ai-test-396", "ner": [[13, 13, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Specifically", ",", "they", "are", "used", "during", "the", "calculation", "of", "likelihood", "trees", "(", "in", "Bayesian", "and", "maximum", "likelihood", "approaches", "to", "tree", "estimation", ")", "and", "they", "are", "used", "to", "estimate", "evolutionary", "distances", "between", "sequences", "from", "observed", "differences", "between", "sequences", "."], "sentence-detokenized": "Specifically, they are used during the calculation of likelihood trees (in Bayesian and maximum likelihood approaches to tree estimation) and they are used to estimate evolutionary distances between sequences from observed differences between sequences.", "token2charspan": [[0, 12], [12, 13], [14, 18], [19, 22], [23, 27], [28, 34], [35, 38], [39, 50], [51, 53], [54, 64], [65, 70], [71, 72], [72, 74], [75, 83], [84, 87], [88, 95], [96, 106], [107, 117], [118, 120], [121, 125], [126, 136], [136, 137], [138, 141], [142, 146], [147, 150], [151, 155], [156, 158], [159, 167], [168, 180], [181, 190], [191, 198], [199, 208], [209, 213], [214, 222], [223, 234], [235, 242], [243, 252], [252, 253]]}
{"doc_key": "ai-test-397", "ner": [[0, 3, "conference"], [20, 21, "misc"], [23, 23, "misc"], [46, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Audio", "Engineering", "Society", "recommends", "a", "sampling", "rate", "of", "48", "kHz", "for", "most", "applications", ",", "but", "recognises", "44.1", "kHz", "for", "Compact", "Disc", "(", "CD", ")", "and", "other", "consumer", "uses", ",", "32", "kHz", "for", "transmission", "-", "related", "applications", ",", "and", "96", "kHz", "for", "higher", "bandwidth", "or", "relaxed", "anti-aliasing", "filters", "."], "sentence-detokenized": "The Audio Engineering Society recommends a sampling rate of 48 kHz for most applications, but recognises 44.1 kHz for Compact Disc (CD) and other consumer uses, 32 kHz for transmission-related applications, and 96 kHz for higher bandwidth or relaxed anti-aliasing filters.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 40], [41, 42], [43, 51], [52, 56], [57, 59], [60, 62], [63, 66], [67, 70], [71, 75], [76, 88], [88, 89], [90, 93], [94, 104], [105, 109], [110, 113], [114, 117], [118, 125], [126, 130], [131, 132], [132, 134], [134, 135], [136, 139], [140, 145], [146, 154], [155, 159], [159, 160], [161, 163], [164, 167], [168, 171], [172, 184], [184, 185], [185, 192], [193, 205], [205, 206], [207, 210], [211, 213], [214, 217], [218, 221], [222, 228], [229, 238], [239, 241], [242, 249], [250, 263], [264, 271], [271, 272]]}
{"doc_key": "ai-test-398", "ner": [[10, 10, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Resources", "for", "word", "and", "concept", "affectivity", "have", "been", "created", "for", "WordNet", "{", "{", "cite", "journal"], "sentence-detokenized": "Resources for word and concept affectivity have been created for WordNet {{cite journal", "token2charspan": [[0, 9], [10, 13], [14, 18], [19, 22], [23, 30], [31, 42], [43, 47], [48, 52], [53, 60], [61, 64], [65, 72], [73, 74], [74, 75], [75, 79], [80, 87]]}
{"doc_key": "ai-test-399", "ner": [[1, 3, "misc"], [24, 25, "person"], [30, 33, "person"], [40, 42, "person"], [48, 51, "organisation"], [68, 70, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[30, 33, 40, 42, "role", "acts_in", false, false], [48, 51, 40, 42, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "red", "-green", "anaglyph", ",", "the", "audience", "was", "presented", "with", "three", "test", "reels", ",", "which", "included", "a", "rural", "scene", ",", "a", "test", "image", "of", "Marie", "Doro", ",", "a", "segment", "of", "John", "B", ".", "Mason", "playing", "a", "number", "of", "parts", "from", "Jim", "the", "Penman", "(", "a", "film", "released", "by", "Famous", "Players", "-", "Lasky", "that", "year", ",", "but", "not", "in", "3D", ")", ",", "Oriental", "dancers", ",", "and", "a", "reel", "of", "Niagara", "Falls", "footage", "."], "sentence-detokenized": "In red-green anaglyph, the audience was presented with three test reels, which included a rural scene, a test image of Marie Doro, a segment of John B. Mason playing a number of parts from Jim the Penman (a film released by Famous Players-Lasky that year, but not in 3D), Oriental dancers, and a reel of Niagara Falls footage.", "token2charspan": [[0, 2], [3, 6], [6, 12], [13, 21], [21, 22], [23, 26], [27, 35], [36, 39], [40, 49], [50, 54], [55, 60], [61, 65], [66, 71], [71, 72], [73, 78], [79, 87], [88, 89], [90, 95], [96, 101], [101, 102], [103, 104], [105, 109], [110, 115], [116, 118], [119, 124], [125, 129], [129, 130], [131, 132], [133, 140], [141, 143], [144, 148], [149, 150], [150, 151], [152, 157], [158, 165], [166, 167], [168, 174], [175, 177], [178, 183], [184, 188], [189, 192], [193, 196], [197, 203], [204, 205], [205, 206], [207, 211], [212, 220], [221, 223], [224, 230], [231, 238], [238, 239], [239, 244], [245, 249], [250, 254], [254, 255], [256, 259], [260, 263], [264, 266], [267, 269], [269, 270], [270, 271], [272, 280], [281, 288], [288, 289], [290, 293], [294, 295], [296, 300], [301, 303], [304, 311], [312, 317], [318, 325], [325, 326]]}
{"doc_key": "ai-test-400", "ner": [[7, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "specialised", "way", "to", "implement", "maximum", "likelihood", "estimation", "for", "this", "problem", "."], "sentence-detokenized": "This is a specialised way to implement maximum likelihood estimation for this problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 21], [22, 25], [26, 28], [29, 38], [39, 46], [47, 57], [58, 68], [69, 72], [73, 77], [78, 85], [85, 86]]}
{"doc_key": "ai-test-401", "ner": [[0, 4, "product"], [11, 11, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Crawler", "-", "friendly", "Web", "Servers", ",", "and", "integrating", "sitemap", "features", "and", "RSS", "feeds", "into", "a", "decentralised", "mechanism", "for", "computational", "biologists", "and", "bio-informaticians", "to", "openly", "broadcast", "and", "retrieve", "meta", "-", "data", "about", "biomedical", "resources", "."], "sentence-detokenized": "Crawler-friendly Web Servers, and integrating sitemap features and RSS feeds into a decentralised mechanism for computational biologists and bio-informaticians to openly broadcast and retrieve meta-data about biomedical resources.", "token2charspan": [[0, 7], [7, 8], [8, 16], [17, 20], [21, 28], [28, 29], [30, 33], [34, 45], [46, 53], [54, 62], [63, 66], [67, 70], [71, 76], [77, 81], [82, 83], [84, 97], [98, 107], [108, 111], [112, 125], [126, 136], [137, 140], [141, 159], [160, 162], [163, 169], [170, 179], [180, 183], [184, 192], [193, 197], [197, 198], [198, 202], [203, 208], [209, 219], [220, 229], [229, 230]]}
{"doc_key": "ai-test-402", "ner": [[5, 12, "misc"], [16, 21, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "covered", "in", "the", "American", "National", "Standards", "Institute", "/", "NISO", "Z39.50", "standard", ",", "and", "the", "International", "Organisation", "for", "Standardisation", "23950", "standard", "."], "sentence-detokenized": "This is covered in the American National Standards Institute/NISO Z39.50 standard, and the International Organisation for Standardisation 23950 standard.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 22], [23, 31], [32, 40], [41, 50], [51, 60], [60, 61], [61, 65], [66, 72], [73, 81], [81, 82], [83, 86], [87, 90], [91, 104], [105, 117], [118, 121], [122, 137], [138, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-test-403", "ner": [[12, 16, "misc"], [22, 22, "metrics"], [25, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "encoder", "and", "decoder", "are", "trained", "to", "retrieve", "phrases", "and", "reproduce", "the", "one", "-", "hot", "distribution", "of", "the", "corresponding", "paraphrases", "by", "minimising", "perplexity", "using", "simple", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The encoder and decoder are trained to retrieve phrases and reproduce the one-hot distribution of the corresponding paraphrases by minimising perplexity using simple stochastic gradient descent.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 47], [48, 55], [56, 59], [60, 69], [70, 73], [74, 77], [77, 78], [78, 81], [82, 94], [95, 97], [98, 101], [102, 115], [116, 127], [128, 130], [131, 141], [142, 152], [153, 158], [159, 165], [166, 176], [177, 185], [186, 193], [193, 194]]}
{"doc_key": "ai-test-404", "ner": [[4, 5, "field"], [8, 10, "task"], [12, 16, "task"], [28, 33, "task"], [35, 40, "task"], [43, 49, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 10, 4, 5, "part-of", "task_part_of_field", false, false], [12, 16, 4, 5, "part-of", "task_part_of_field", false, false], [28, 33, 4, 5, "part-of", "task_part_of_field", false, false], [35, 40, 4, 5, "part-of", "task_part_of_field", false, false], [43, 49, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "typical", "applications", "of", "pattern", "recognition", "techniques", "are", "automatic", "speech", "recognition", ",", "classification", "of", "text", "into", "categories", "(", "e.g.", ",", "spam", "/", "non", "-spam", "email", "messages", ")", ",", "recognition", "of", "handwriting", "on", "postal", "envelopes", ",", "automatic", "recognition", "of", "human", "face", "images", ",", "or", "extraction", "of", "handwritten", "images", "from", "medical", "forms", "."], "sentence-detokenized": "Other typical applications of pattern recognition techniques are automatic speech recognition, classification of text into categories (e.g., spam/non-spam email messages), recognition of handwriting on postal envelopes, automatic recognition of human face images, or extraction of handwritten images from medical forms.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 29], [30, 37], [38, 49], [50, 60], [61, 64], [65, 74], [75, 81], [82, 93], [93, 94], [95, 109], [110, 112], [113, 117], [118, 122], [123, 133], [134, 135], [135, 139], [139, 140], [141, 145], [145, 146], [146, 149], [149, 154], [155, 160], [161, 169], [169, 170], [170, 171], [172, 183], [184, 186], [187, 198], [199, 201], [202, 208], [209, 218], [218, 219], [220, 229], [230, 241], [242, 244], [245, 250], [251, 255], [256, 262], [262, 263], [264, 266], [267, 277], [278, 280], [281, 292], [293, 299], [300, 304], [305, 312], [313, 318], [318, 319]]}
{"doc_key": "ai-test-405", "ner": [[0, 2, "algorithm"], [13, 14, "field"], [16, 17, "task"], [19, 20, "task"], [22, 24, "task"], [26, 30, "task"], [32, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 14, 0, 2, "usage", "", false, false], [16, 17, 0, 2, "usage", "", false, false], [19, 20, 0, 2, "usage", "", false, false], [22, 24, 0, 2, "usage", "", false, false], [26, 30, 0, 2, "usage", "", false, false], [32, 33, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Artificial", "neural", "networks", "have", "been", "used", "on", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "playing", "board", "and", "video", "games", "and", "medical", "diagnosis", "."], "sentence-detokenized": "Artificial neural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 36], [37, 41], [42, 44], [45, 46], [47, 54], [55, 57], [58, 63], [63, 64], [65, 74], [75, 83], [84, 90], [90, 91], [92, 98], [99, 110], [110, 111], [112, 119], [120, 131], [131, 132], [133, 139], [140, 147], [148, 157], [157, 158], [159, 166], [167, 172], [173, 176], [177, 182], [183, 188], [189, 192], [193, 200], [201, 210], [210, 211]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [14, 14, "product"], [18, 18, "organisation"], [19, 20, "product"], [22, 22, "product"], [24, 26, "product"], [28, 28, "product"], [30, 30, "programlang"], [39, 40, "field"], [45, 45, "product"], [50, 50, "algorithm"], [52, 52, "algorithm"], [54, 54, "algorithm"], [58, 58, "product"], [66, 67, "task"], [72, 73, "algorithm"], [77, 77, "product"], [79, 79, "product"], [81, 83, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [4, 4, 14, 14, "named", "same", false, false], [4, 4, 45, 45, "named", "same", false, false], [30, 30, 39, 40, "related-to", "used_for", false, false], [50, 50, 30, 30, "part-of", "", true, false], [50, 50, 45, 45, "origin", "", true, false], [52, 52, 30, 30, "part-of", "", true, false], [52, 52, 45, 45, "origin", "", true, false], [54, 54, 30, 30, "part-of", "", true, false], [54, 54, 45, 45, "origin", "", true, false], [58, 58, 66, 67, "related-to", "used_for", false, false], [72, 73, 58, 58, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Examples", "include", "Salford", "Systems", "CART", "(", "which", "licences", "the", "proprietary", "code", "of", "the", "original", "CART", "authors", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "-", "source", "software", "environment", "for", "statistical", "computing", ",", "which", "includes", "several", "CART", "implementations", "such", "as", "the", "rpart", ",", "party", "and", "randomForest", "packages", ")", ",", "Weka", "(", "a", "free", "and", "open", "-", "source", "data", "-mining", "suite", ",", "containing", "many", "decision", "tree", "algorithms", ")", ",", "Orange", ",", "KNIME", ",", "Microsoft", "SQL", "Server", "programming", "language", ")", "."], "sentence-detokenized": "Examples include Salford Systems CART (which licences the proprietary code of the original CART authors), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open-source software environment for statistical computing, which includes several CART implementations such as the rpart, party and randomForest packages), Weka (a free and open-source data-mining suite, containing many decision tree algorithms), Orange, KNIME, Microsoft SQL Server programming language).", "token2charspan": [[0, 8], [9, 16], [17, 24], [25, 32], [33, 37], [38, 39], [39, 44], [45, 53], [54, 57], [58, 69], [70, 74], [75, 77], [78, 81], [82, 90], [91, 95], [96, 103], [103, 104], [104, 105], [106, 109], [110, 114], [115, 122], [122, 123], [124, 134], [134, 135], [136, 139], [140, 150], [151, 156], [156, 157], [158, 164], [164, 165], [166, 167], [168, 169], [169, 171], [172, 176], [176, 177], [177, 183], [184, 192], [193, 204], [205, 208], [209, 220], [221, 230], [230, 231], [232, 237], [238, 246], [247, 254], [255, 259], [260, 275], [276, 280], [281, 283], [284, 287], [288, 293], [293, 294], [295, 300], [301, 304], [305, 317], [318, 326], [326, 327], [327, 328], [329, 333], [334, 335], [335, 336], [337, 341], [342, 345], [346, 350], [350, 351], [351, 357], [358, 362], [362, 369], [370, 375], [375, 376], [377, 387], [388, 392], [393, 401], [402, 406], [407, 417], [417, 418], [418, 419], [420, 426], [426, 427], [428, 433], [433, 434], [435, 444], [445, 448], [449, 455], [456, 467], [468, 476], [476, 477], [477, 478]]}
{"doc_key": "ai-test-407", "ner": [[0, 2, "algorithm"], [4, 6, "algorithm"], [10, 11, "researcher"], [13, 14, "university"], [16, 17, "researcher"], [19, 22, "organisation"], [24, 24, "organisation"], [34, 36, "researcher"], [38, 40, "researcher"], [42, 43, "organisation"], [57, 60, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 10, 11, "origin", "", false, false], [0, 2, 16, 17, "origin", "", false, false], [0, 2, 34, 36, "origin", "", false, false], [0, 2, 38, 40, "origin", "", false, false], [4, 6, 0, 2, "named", "", false, false], [10, 11, 13, 14, "physical", "", false, false], [10, 11, 13, 14, "role", "", false, false], [16, 17, 19, 22, "physical", "", false, false], [16, 17, 19, 22, "role", "", false, false], [24, 24, 19, 22, "named", "", false, false], [34, 36, 42, 43, "physical", "", false, false], [34, 36, 42, 43, "role", "", false, false], [38, 40, 42, 43, "physical", "", false, false], [38, 40, 42, 43, "role", "", false, false], [57, 60, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", "was", "first", "developed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", ",", "and", "then", "further", "developed", "by", "Bishnu", "S.", "Atal", "and", "Manfred", "R.", "Schroeder", "at", "Bell", "Labs", "during", "the", "early", "to", "mid", "1970s", ",", "becoming", "the", "basis", "for", "the", "first", "speech", "synthesizer", "DSP", "chip", "in", "the", "late", "1970s", "."], "sentence-detokenized": "Linear predictive coding (LPC) was first developed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966, and then further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs during the early to mid 1970s, becoming the basis for the first speech synthesizer DSP chip in the late 1970s.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 40], [41, 50], [51, 53], [54, 62], [63, 70], [71, 73], [74, 80], [81, 91], [92, 95], [96, 101], [102, 107], [108, 110], [111, 117], [118, 127], [128, 131], [132, 141], [142, 143], [143, 146], [146, 147], [148, 150], [151, 155], [155, 156], [157, 160], [161, 165], [166, 173], [174, 183], [184, 186], [187, 193], [194, 196], [197, 201], [202, 205], [206, 213], [214, 216], [217, 226], [227, 229], [230, 234], [235, 239], [240, 246], [247, 250], [251, 256], [257, 259], [260, 263], [264, 269], [269, 270], [271, 279], [280, 283], [284, 289], [290, 293], [294, 297], [298, 303], [304, 310], [311, 322], [323, 326], [327, 331], [332, 334], [335, 338], [339, 343], [344, 349], [349, 350]]}
{"doc_key": "ai-test-408", "ner": [[0, 2, "metrics"], [7, 7, "metrics"], [9, 9, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 0, 2, "part-of", "", false, false], [9, 9, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["F", "-", "score", "is", "a", "combination", "of", "precision", "and", "recall", ",", "giving", "a", "single", "score", "."], "sentence-detokenized": "F-score is a combination of precision and recall, giving a single score.", "token2charspan": [[0, 1], [1, 2], [2, 7], [8, 10], [11, 12], [13, 24], [25, 27], [28, 37], [38, 41], [42, 48], [48, 49], [50, 56], [57, 58], [59, 65], [66, 71], [71, 72]]}
{"doc_key": "ai-test-409", "ner": [[0, 1, "field"], [8, 11, "task"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 0, 1, "part-of", "task_part_of_field", false, false], [17, 19, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Image", "analysis", "tasks", "can", "be", "as", "simple", "as", "reading", "a", "barcode", "tag", "or", "as", "sophisticated", "as", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Image analysis tasks can be as simple as reading a barcode tag or as sophisticated as a facial recognition system.", "token2charspan": [[0, 5], [6, 14], [15, 20], [21, 24], [25, 27], [28, 30], [31, 37], [38, 40], [41, 48], [49, 50], [51, 58], [59, 62], [63, 65], [66, 68], [69, 82], [83, 85], [86, 87], [88, 94], [95, 106], [107, 113], [113, 114]]}
{"doc_key": "ai-test-410", "ner": [[5, 8, "algorithm"], [26, 27, "algorithm"], [34, 36, "algorithm"], [40, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[34, 36, 26, 27, "type-of", "", false, false], [40, 40, 34, 36, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "special", "case", "of", "linear", "support", "-", "vector", "machines", "can", "be", "solved", "more", "efficiently", "with", "the", "same", "type", "of", "algorithms", "for", "optimising", "its", "close", "cousin", ",", "logistic", "regression", ";", "this", "class", "of", "algorithms", "includes", "stochastic", "gradient", "descent", "(", "e.g.", ",", "PEGASOS", ")", "."], "sentence-detokenized": "A special case of linear support-vector machines can be solved more efficiently with the same type of algorithms for optimising its close cousin, logistic regression; this class of algorithms includes stochastic gradient descent (e.g., PEGASOS).", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 17], [18, 24], [25, 32], [32, 33], [33, 39], [40, 48], [49, 52], [53, 55], [56, 62], [63, 67], [68, 79], [80, 84], [85, 88], [89, 93], [94, 98], [99, 101], [102, 112], [113, 116], [117, 127], [128, 131], [132, 137], [138, 144], [144, 145], [146, 154], [155, 165], [165, 166], [167, 171], [172, 177], [178, 180], [181, 191], [192, 200], [201, 211], [212, 220], [221, 228], [229, 230], [230, 234], [234, 235], [236, 243], [243, 244], [244, 245]]}
{"doc_key": "ai-test-411", "ner": [[1, 1, "product"], [4, 4, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 4, 4, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["When", "Siri", "on", "an", "iOS", "device", "is", "asked", "if", "you", "have", "a", "pet", ",", "one", "of", "the", "answers", "is", "I", "used", "to", "have", "an", "AIBO", "."], "sentence-detokenized": "When Siri on an iOS device is asked if you have a pet, one of the answers is I used to have an AIBO.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 15], [16, 19], [20, 26], [27, 29], [30, 35], [36, 38], [39, 42], [43, 47], [48, 49], [50, 53], [53, 54], [55, 58], [59, 61], [62, 65], [66, 73], [74, 76], [77, 78], [79, 83], [84, 86], [87, 91], [92, 94], [95, 99], [99, 100]]}
{"doc_key": "ai-test-412", "ner": [[1, 2, "task"], [4, 6, "metrics"], [9, 9, "metrics"], [12, 12, "metrics"], [15, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 1, 2, "part-of", "", false, false], [9, 9, 4, 6, "named", "", false, false], [12, 12, 1, 2, "part-of", "", false, false], [15, 15, 12, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "information", "retrieval", ",", "positive", "predictive", "value", "is", "called", "precision", ",", "and", "sensitivity", "is", "called", "recall", "."], "sentence-detokenized": "In information retrieval, positive predictive value is called precision, and sensitivity is called recall.", "token2charspan": [[0, 2], [3, 14], [15, 24], [24, 25], [26, 34], [35, 45], [46, 51], [52, 54], [55, 61], [62, 71], [71, 72], [73, 76], [77, 88], [89, 91], [92, 98], [99, 105], [105, 106]]}
{"doc_key": "ai-test-413", "ner": [[11, 12, "field"], [14, 14, "task"], [16, 16, "task"], [18, 19, "task"], [35, 36, "task"], [38, 39, "task"], [41, 45, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 14, 11, 12, "part-of", "task_part_of_field", false, false], [16, 16, 11, 12, "part-of", "task_part_of_field", false, false], [18, 19, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "particular", ",", "his", "research", "is", "focused", "on", "areas", "such", "as", "text", "mining", "(", "extraction", ",", "categorisation", ",", "novelty", "detection", ")", "and", "in", "novel", "theoretical", "frameworks", "such", "as", "unified", "utility", "-", "based", "theories", "that", "bridge", "information", "retrieval", ",", "automatic", "summarisation", ",", "free", "-", "text", "question", "answering", "and", "related", "tasks", "."], "sentence-detokenized": "In particular, his research is focused on areas such as text mining (extraction, categorisation, novelty detection) and in novel theoretical frameworks such as unified utility-based theories that bridge information retrieval, automatic summarisation, free-text question answering and related tasks.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 27], [28, 30], [31, 38], [39, 41], [42, 47], [48, 52], [53, 55], [56, 60], [61, 67], [68, 69], [69, 79], [79, 80], [81, 95], [95, 96], [97, 104], [105, 114], [114, 115], [116, 119], [120, 122], [123, 128], [129, 140], [141, 151], [152, 156], [157, 159], [160, 167], [168, 175], [175, 176], [176, 181], [182, 190], [191, 195], [196, 202], [203, 214], [215, 224], [224, 225], [226, 235], [236, 249], [249, 250], [251, 255], [255, 256], [256, 260], [261, 269], [270, 279], [280, 283], [284, 291], [292, 297], [297, 298]]}
{"doc_key": "ai-test-414", "ner": [[0, 2, "product"], [8, 9, "product"], [17, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 0, 2, "part-of", "", false, false], [17, 17, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Delta", "robot", "has", "a", "base", "-", "mounted", "rotary", "actuator", "that", "drives", "a", "lightweight", "and", "rigid", "parallelogram", "arm", "."], "sentence-detokenized": "The Delta robot has a base-mounted rotary actuator that drives a lightweight and rigid parallelogram arm.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 21], [22, 26], [26, 27], [27, 34], [35, 41], [42, 50], [51, 55], [56, 62], [63, 64], [65, 76], [77, 80], [81, 86], [87, 100], [101, 104], [104, 105]]}
{"doc_key": "ai-test-415", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", ",", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated in a 2 \u00d7 2 contingency table or confusion matrix, as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 76], [77, 83], [83, 84], [85, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-416", "ner": [[4, 5, "field"], [30, 31, "task"], [37, 38, "task"], [44, 46, "task"], [48, 50, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[30, 31, 4, 5, "part-of", "task_part_of_field", false, false], [37, 38, 4, 5, "part-of", "task_part_of_field", false, false], [44, 46, 4, 5, "part-of", "task_part_of_field", false, false], [48, 50, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "actual", "task", "of", "data", "mining", "is", "the", "semi-automated", "or", "automated", "analysis", "of", "large", "amounts", "of", "data", "to", "extract", "unknown", "and", "interesting", "patterns", "such", "as", "groups", "of", "data", "records", "(", "cluster", "analysis", ")", ",", "unusual", "records", "(", "anomaly", "detection", ")", ",", "and", "dependencies", "(", "association", "rule", "mining", ",", "sequential", "pattern", "mining", ")", "."], "sentence-detokenized": "The actual task of data mining is the semi-automated or automated analysis of large amounts of data to extract unknown and interesting patterns such as groups of data records (cluster analysis), unusual records (anomaly detection), and dependencies (association rule mining, sequential pattern mining).", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 18], [19, 23], [24, 30], [31, 33], [34, 37], [38, 52], [53, 55], [56, 65], [66, 74], [75, 77], [78, 83], [84, 91], [92, 94], [95, 99], [100, 102], [103, 110], [111, 118], [119, 122], [123, 134], [135, 143], [144, 148], [149, 151], [152, 158], [159, 161], [162, 166], [167, 174], [175, 176], [176, 183], [184, 192], [192, 193], [193, 194], [195, 202], [203, 210], [211, 212], [212, 219], [220, 229], [229, 230], [230, 231], [232, 235], [236, 248], [249, 250], [250, 261], [262, 266], [267, 273], [273, 274], [275, 285], [286, 293], [294, 300], [300, 301], [301, 302]]}
{"doc_key": "ai-test-417", "ner": [[1, 2, "product"], [4, 5, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "recommendation", "systems", ",", "sentiment", "analysis", "has", "proven", "to", "be", "a", "valuable", "technique", "."], "sentence-detokenized": "For recommendation systems, sentiment analysis has proven to be a valuable technique.", "token2charspan": [[0, 3], [4, 18], [19, 26], [26, 27], [28, 37], [38, 46], [47, 50], [51, 57], [58, 60], [61, 63], [64, 65], [66, 74], [75, 84], [84, 85]]}
{"doc_key": "ai-test-418", "ner": [[3, 3, "misc"], [11, 11, "product"], [33, 33, "organisation"], [37, 38, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 11, 11, "usage", "", false, false], [33, 33, 37, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Coincidentally", ",", "the", "Germans", "had", "chosen", "the", "operating", "frequency", "of", "the", "Wotan", "system", "very", "badly", ";", "it", "operates", "on", "45", "MHz", ",", "which", "happens", "to", "be", "the", "frequency", "of", "the", "powerful", "but", "inactive", "BBC", "television", "transmitter", "at", "Alexandra", "Palace", "."], "sentence-detokenized": "Coincidentally, the Germans had chosen the operating frequency of the Wotan system very badly; it operates on 45 MHz, which happens to be the frequency of the powerful but inactive BBC television transmitter at Alexandra Palace.", "token2charspan": [[0, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 52], [53, 62], [63, 65], [66, 69], [70, 75], [76, 82], [83, 87], [88, 93], [93, 94], [95, 97], [98, 106], [107, 109], [110, 112], [113, 116], [116, 117], [118, 123], [124, 131], [132, 134], [135, 137], [138, 141], [142, 151], [152, 154], [155, 158], [159, 167], [168, 171], [172, 180], [181, 184], [185, 195], [196, 207], [208, 210], [211, 220], [221, 227], [227, 228]]}
{"doc_key": "ai-test-419", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", ",", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated in a 2 \u00d7 2 contingency table or confusion matrix, as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 76], [77, 83], [83, 84], [85, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-420", "ner": [[1, 3, "misc"], [9, 9, "misc"], [13, 13, "product"], [15, 15, "product"], [17, 19, "product"], [28, 28, "misc"], [44, 46, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 13, 9, 9, "usage", "", false, false], [15, 15, 9, 9, "usage", "", false, false], [17, 19, 15, 15, "named", "", false, false], [28, 28, 9, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "Semantic", "Web", "applications", ",", "and", "in", "relatively", "popular", "RDF", "applications", "such", "as", "RSS", "and", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "resources", "tend", "to", "be", "represented", "by", "URIs", "that", "deliberately", "indicate", ",", "and", "can", "be", "used", "to", "access", ",", "actual", "data", "on", "the", "World", "Wide", "Web", "."], "sentence-detokenized": "In Semantic Web applications, and in relatively popular RDF applications such as RSS and FOAF (Friend a Friend), resources tend to be represented by URIs that deliberately indicate, and can be used to access, actual data on the World Wide Web.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 28], [28, 29], [30, 33], [34, 36], [37, 47], [48, 55], [56, 59], [60, 72], [73, 77], [78, 80], [81, 84], [85, 88], [89, 93], [94, 95], [95, 101], [102, 103], [104, 110], [110, 111], [111, 112], [113, 122], [123, 127], [128, 130], [131, 133], [134, 145], [146, 148], [149, 153], [154, 158], [159, 171], [172, 180], [180, 181], [182, 185], [186, 189], [190, 192], [193, 197], [198, 200], [201, 207], [207, 208], [209, 215], [216, 220], [221, 223], [224, 227], [228, 233], [234, 238], [239, 242], [242, 243]]}
{"doc_key": "ai-test-421", "ner": [[0, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "has", "studied", "this", "topic", "in", "depth"], "sentence-detokenized": "The Association for the Advancement of Artificial Intelligence has studied this topic in depth", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 74], [75, 79], [80, 85], [86, 88], [89, 94]]}
{"doc_key": "ai-test-422", "ner": [[6, 9, "product"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 18, 6, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Started", "as", "a", "curiosity", ",", "the", "Apple", "Macintosh", "speech", "system", "has", "evolved", "into", "a", "fully", "supported", "programme", "called", "PlainTalk", ",", "for", "people", "with", "vision", "problems", "."], "sentence-detokenized": "Started as a curiosity, the Apple Macintosh speech system has evolved into a fully supported programme called PlainTalk, for people with vision problems.", "token2charspan": [[0, 7], [8, 10], [11, 12], [13, 22], [22, 23], [24, 27], [28, 33], [34, 43], [44, 50], [51, 57], [58, 61], [62, 69], [70, 74], [75, 76], [77, 82], [83, 92], [93, 102], [103, 109], [110, 119], [119, 120], [121, 124], [125, 131], [132, 136], [137, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-test-423", "ner": [[7, 7, "field"], [9, 10, "task"], [12, 13, "task"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 7, 7, "part-of", "task_part_of_field", false, false], [12, 13, 7, 7, "part-of", "task_part_of_field", false, false], [15, 16, 7, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "areas", "of", "use", "for", "ontologies", "in", "NLP", "include", "information", "retrieval", ",", "information", "extraction", "and", "automatic", "summarisation", "."], "sentence-detokenized": "Other areas of use for ontologies in NLP include information retrieval, information extraction and automatic summarisation.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 18], [19, 22], [23, 33], [34, 36], [37, 40], [41, 48], [49, 60], [61, 70], [70, 71], [72, 83], [84, 94], [95, 98], [99, 108], [109, 122], [122, 123]]}
{"doc_key": "ai-test-424", "ner": [[8, 15, "organisation"], [18, 22, "organisation"], [25, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Institute", "has", "been", "collaborating", "closely", "with", "the", "Janelia", "Farm", "Campus", "of", "Howard", "Hughes", "Medical", "Institute", ",", "the", "Allen", "Institute", "for", "Brain", "Science", "and", "the", "National", "Institutes", "of", "Health", "to", "develop", "better", "methods", "of", "reconstructing", "neuronal", "architecture", "."], "sentence-detokenized": "The Institute has been collaborating closely with the Janelia Farm Campus of Howard Hughes Medical Institute, the Allen Institute for Brain Science and the National Institutes of Health to develop better methods of reconstructing neuronal architecture.", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 22], [23, 36], [37, 44], [45, 49], [50, 53], [54, 61], [62, 66], [67, 73], [74, 76], [77, 83], [84, 90], [91, 98], [99, 108], [108, 109], [110, 113], [114, 119], [120, 129], [130, 133], [134, 139], [140, 147], [148, 151], [152, 155], [156, 164], [165, 175], [176, 178], [179, 185], [186, 188], [189, 196], [197, 203], [204, 211], [212, 214], [215, 229], [230, 238], [239, 251], [251, 252]]}
{"doc_key": "ai-test-425", "ner": [[2, 2, "organisation"], [5, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 2, 2, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Recently", ",", "Google", "announced", "that", "Google", "Translate", "translated", "approximately", "enough", "text", "to", "fill", "1", "million", "books", "in", "one", "day", "(", "2012", ")", "."], "sentence-detokenized": "Recently, Google announced that Google Translate translated approximately enough text to fill 1 million books in one day (2012).", "token2charspan": [[0, 8], [8, 9], [10, 16], [17, 26], [27, 31], [32, 38], [39, 48], [49, 59], [60, 73], [74, 80], [81, 85], [86, 88], [89, 93], [94, 95], [96, 103], [104, 109], [110, 112], [113, 116], [117, 120], [121, 122], [122, 126], [126, 127], [127, 128]]}
{"doc_key": "ai-test-426", "ner": [[14, 14, "country"], [16, 16, "country"], [18, 18, "country"], [20, 20, "country"], [22, 22, "country"], [24, 25, "country"], [35, 36, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Events", "are", "held", "all", "over", "the", "world", ",", "and", "are", "most", "popular", "in", "the", "UK", ",", "USA", ",", "Japan", ",", "Singapore", ",", "India", ",", "South", "Korea", "and", "are", "becoming", "popular", "in", "subcontinental", "countries", "such", "as", "Sri", "Lanka", "."], "sentence-detokenized": "Events are held all over the world, and are most popular in the UK, USA, Japan, Singapore, India, South Korea and are becoming popular in subcontinental countries such as Sri Lanka.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 24], [25, 28], [29, 34], [34, 35], [36, 39], [40, 43], [44, 48], [49, 56], [57, 59], [60, 63], [64, 66], [66, 67], [68, 71], [71, 72], [73, 78], [78, 79], [80, 89], [89, 90], [91, 96], [96, 97], [98, 103], [104, 109], [110, 113], [114, 117], [118, 126], [127, 134], [135, 137], [138, 152], [153, 162], [163, 167], [168, 170], [171, 174], [175, 180], [180, 181]]}
{"doc_key": "ai-test-427", "ner": [[6, 6, "programlang"], [11, 11, "programlang"], [13, 13, "programlang"], [15, 16, "programlang"], [19, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "developed", "primarily", "in", "R", ",", "and", "occasionally", "in", "Java", ",", "C", ",", "C", "++", ",", "and", "Fortran", "."], "sentence-detokenized": "These packages are developed primarily in R, and occasionally in Java, C, C++, and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 28], [29, 38], [39, 41], [42, 43], [43, 44], [45, 48], [49, 61], [62, 64], [65, 69], [69, 70], [71, 72], [72, 73], [74, 75], [75, 77], [77, 78], [79, 82], [83, 90], [90, 91]]}
{"doc_key": "ai-test-428", "ner": [[4, 12, "conference"], [10, 10, "conference"], [14, 14, "researcher"], [16, 16, "researcher"], [19, 20, "researcher"], [24, 26, "algorithm"], [30, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 10, 4, 12, "named", "", false, false], [14, 14, 4, 12, "physical", "", false, false], [14, 14, 4, 12, "role", "", false, false], [14, 14, 19, 20, "role", "teams_up_with", false, false], [14, 14, 24, 26, "usage", "", false, false], [16, 16, 4, 12, "physical", "", false, false], [16, 16, 4, 12, "role", "", false, false], [16, 16, 19, 20, "role", "teams_up_with", false, false], [16, 16, 24, 26, "usage", "", false, false], [19, 20, 4, 12, "physical", "", false, false], [19, 20, 4, 12, "role", "", false, false], [19, 20, 24, 26, "usage", "", false, false], [24, 26, 30, 35, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["As", "part", "of", "the", "European", "Conference", "on", "Computer", "Vision", "(", "ECCV", ")", "2006", ",", "Dalal", "and", "Triggs", "collaborated", "with", "Cordelia", "Schmid", "to", "apply", "the", "HOG", "detector", "to", "the", "problem", "of", "human", "detection", "in", "film", "and", "video", "."], "sentence-detokenized": "As part of the European Conference on Computer Vision (ECCV) 2006, Dalal and Triggs collaborated with Cordelia Schmid to apply the HOG detector to the problem of human detection in film and video.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 23], [24, 34], [35, 37], [38, 46], [47, 53], [54, 55], [55, 59], [59, 60], [61, 65], [65, 66], [67, 72], [73, 76], [77, 83], [84, 96], [97, 101], [102, 110], [111, 117], [118, 120], [121, 126], [127, 130], [131, 134], [135, 143], [144, 146], [147, 150], [151, 158], [159, 161], [162, 167], [168, 177], [178, 180], [181, 185], [186, 189], [190, 195], [195, 196]]}
{"doc_key": "ai-test-429", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [10, 11, "task"], [17, 19, "metrics"], [21, 21, "metrics"], [27, 27, "metrics"], [30, 32, "metrics"], [34, 34, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 3, 10, 11, "related-to", "measured_with", false, false], [5, 5, 10, 11, "related-to", "measured_with", false, false], [17, 19, 10, 11, "related-to", "measured_with", false, false], [21, 21, 17, 19, "named", "", false, false], [27, 27, 17, 19, "named", "", false, false], [34, 34, 30, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "addition", "to", "sensitivity", "and", "specificity", ",", "the", "performance", "of", "binary", "classification", "tests", "can", "be", "measured", "by", "positive", "predictive", "value", "(", "PPV", ")", ",", "also", "known", "as", "precision", ",", "and", "negative", "predictive", "value", "(", "NPV", ")", "."], "sentence-detokenized": "In addition to sensitivity and specificity, the performance of binary classification tests can be measured by positive predictive value (PPV), also known as precision, and negative predictive value (NPV).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 42], [42, 43], [44, 47], [48, 59], [60, 62], [63, 69], [70, 84], [85, 90], [91, 94], [95, 97], [98, 106], [107, 109], [110, 118], [119, 129], [130, 135], [136, 137], [137, 140], [140, 141], [141, 142], [143, 147], [148, 153], [154, 156], [157, 166], [166, 167], [168, 171], [172, 180], [181, 191], [192, 197], [198, 199], [199, 202], [202, 203], [203, 204]]}
{"doc_key": "ai-test-430", "ner": [[14, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "models", "can", "give", "partial", "credit", "for", "overlapping", "matches", "(", "such", "as", "using", "the", "Jaccard", "index", "criterion", "."], "sentence-detokenized": "The models can give partial credit for overlapping matches (such as using the Jaccard index criterion.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 19], [20, 27], [28, 34], [35, 38], [39, 50], [51, 58], [59, 60], [60, 64], [65, 67], [68, 73], [74, 77], [78, 85], [86, 91], [92, 101], [101, 102]]}
{"doc_key": "ai-test-431", "ner": [[25, 30, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Furthermore", ",", "in", "the", "case", "of", "estimation", "based", "on", "a", "single", "sample", ",", "this", "points", "to", "philosophical", "issues", "and", "possible", "misunderstandings", "in", "the", "use", "of", "maximum", "likelihood", "estimators", "and", "likelihood", "functions", "."], "sentence-detokenized": "Furthermore, in the case of estimation based on a single sample, this points to philosophical issues and possible misunderstandings in the use of maximum likelihood estimators and likelihood functions.", "token2charspan": [[0, 11], [11, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 38], [39, 44], [45, 47], [48, 49], [50, 56], [57, 63], [63, 64], [65, 69], [70, 76], [77, 79], [80, 93], [94, 100], [101, 104], [105, 113], [114, 131], [132, 134], [135, 138], [139, 142], [143, 145], [146, 153], [154, 164], [165, 175], [176, 179], [180, 190], [191, 200], [200, 201]]}
