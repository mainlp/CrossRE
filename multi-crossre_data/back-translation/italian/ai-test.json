{"doc_key": "ai-test-1", "ner": [[6, 8, "algorithm"], [10, 11, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "approaches", "to", "generative", "models", "include", "naive", "Bayes", "classifiers", ",", "Gaussian", "mixture", "models", ",", "variational", "autoencoders", "and", "others", "."], "sentence-detokenized": "Typical approaches to generative models include naive Bayes classifiers, Gaussian mixture models, variational autoencoders and others.", "token2charspan": [[0, 7], [8, 18], [19, 21], [22, 32], [33, 39], [40, 47], [48, 53], [54, 59], [60, 71], [71, 72], [73, 81], [82, 89], [90, 96], [96, 97], [98, 109], [110, 122], [123, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-test-2", "ner": [[6, 6, "organisation"], [10, 10, "conference"], [11, 20, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 10, 10, "role", "", false, false], [11, 20, 10, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Finally", ",", "every", "two", "years", ",", "ELRA", "organises", "a", "major", "LREC", "conference", ",", "the", "International", "Conference", "on", "Language", "Resources", "and", "Evaluation", "."], "sentence-detokenized": "Finally, every two years, ELRA organises a major LREC conference, the International Conference on Language Resources and Evaluation.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 18], [19, 24], [24, 25], [26, 30], [31, 40], [41, 42], [43, 48], [49, 53], [54, 64], [64, 65], [66, 69], [70, 83], [84, 94], [95, 97], [98, 106], [107, 116], [117, 120], [121, 131], [131, 132]]}
{"doc_key": "ai-test-3", "ner": [[7, 11, "algorithm"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "task", "is", "usually", "to", "derive", "the", "maximum", "likelihood", "estimate", "of", "the", "HMM", "parameters", "given", "the", "output", "sequences", "."], "sentence-detokenized": "The task is usually to derive the maximum likelihood estimate of the HMM parameters given the output sequences.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 22], [23, 29], [30, 33], [34, 41], [42, 52], [53, 61], [62, 64], [65, 68], [69, 72], [73, 83], [84, 89], [90, 93], [94, 100], [101, 110], [110, 111]]}
{"doc_key": "ai-test-4", "ner": [[1, 1, "algorithm"], [4, 6, "algorithm"], [8, 8, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 8, 8, "compare", "", false, false], [4, 6, 8, 8, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Unlike", "neural", "networks", "and", "support", "vector", "machines", ",", "AdaBoost", "'s", "training", "process", "only", "selects", "known", "features", "to", "improve", "the", "predictive", "power", "of", "the", "model", ",", "reducing", "dimensionality", "and", "potentially", "improving", "runtime", ",", "as", "irrelevant", "features", "do", "not", "need", "to", "be", "calculated", "."], "sentence-detokenized": "Unlike neural networks and support vector machines, AdaBoost's training process only selects known features to improve the predictive power of the model, reducing dimensionality and potentially improving runtime, as irrelevant features do not need to be calculated.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 26], [27, 34], [35, 41], [42, 50], [50, 51], [52, 60], [60, 62], [63, 71], [72, 79], [80, 84], [85, 92], [93, 98], [99, 107], [108, 110], [111, 118], [119, 122], [123, 133], [134, 139], [140, 142], [143, 146], [147, 152], [152, 153], [154, 162], [163, 177], [178, 181], [182, 193], [194, 203], [204, 211], [211, 212], [213, 215], [216, 226], [227, 235], [236, 238], [239, 242], [243, 247], [248, 250], [251, 253], [254, 264], [264, 265]]}
{"doc_key": "ai-test-5", "ner": [[0, 0, "misc"], [11, 13, "misc"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "part-of", "", false, false], [11, 13, 15, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponymy", "is", "one", "of", "the", "possible", "relations", "between", "verbs", "in", "the", "semantic", "network", "of", "the", "Word", "Net", "database", "."], "sentence-detokenized": "Troponymy is one of the possible relations between verbs in the semantic network of the WordNet database.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 19], [20, 23], [24, 32], [33, 42], [43, 50], [51, 56], [57, 59], [60, 63], [64, 72], [73, 80], [81, 83], [84, 87], [88, 92], [92, 95], [96, 104], [104, 105]]}
{"doc_key": "ai-test-6", "ner": [[9, 11, "task"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 13, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "frame", "language", "is", "a", "technology", "used", "for", "the", "representation", "of", "knowledge", "in", "artificial", "intelligence", "."], "sentence-detokenized": "A frame language is a technology used for the representation of knowledge in artificial intelligence.", "token2charspan": [[0, 1], [2, 7], [8, 16], [17, 19], [20, 21], [22, 32], [33, 37], [38, 41], [42, 45], [46, 60], [61, 63], [64, 73], [74, 76], [77, 87], [88, 100], [100, 101]]}
{"doc_key": "ai-test-7", "ner": [[0, 0, "metrics"], [4, 7, "metrics"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 7, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "Bilingual", "evaluation", "understudy", "in", "the", "calculation", "of", "the", "brevity", "penalty", ",", "as", "small", "variations", "in", "the", "length", "of", "the", "translation", "do", "not", "affect", "the", "overall", "score", "that", "much", "."], "sentence-detokenized": "NIST also differs from Bilingual evaluation understudy in the calculation of the brevity penalty, as small variations in the length of the translation do not affect the overall score that much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 32], [33, 43], [44, 54], [55, 57], [58, 61], [62, 73], [74, 76], [77, 80], [81, 88], [89, 96], [96, 97], [98, 100], [101, 106], [107, 117], [118, 120], [121, 124], [125, 131], [132, 134], [135, 138], [139, 150], [151, 153], [154, 157], [158, 164], [165, 168], [169, 176], [177, 182], [183, 187], [188, 192], [192, 193]]}
{"doc_key": "ai-test-8", "ner": [[5, 6, "algorithm"], [8, 10, "algorithm"], [20, 21, "field"], [33, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[5, 6, 20, 21, "usage", "", false, false], [8, 10, 20, 21, "usage", "", false, false], [33, 35, 20, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 3], "sentence": ["The", "model", "(", "e.g.", "a", "neural", "network", "or", "naive", "Bayes", "classifier", ")", "is", "trained", "on", "the", "training", "dataset", "using", "a", "supervised", "learning", "method", ",", "e.g.", "using", "optimisation", "methods", "such", "as", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The model (e.g. a neural network or naive Bayes classifier) is trained on the training dataset using a supervised learning method, e.g. using optimisation methods such as gradient descent or stochastic gradient descent.", "token2charspan": [[0, 3], [4, 9], [10, 11], [11, 15], [16, 17], [18, 24], [25, 32], [33, 35], [36, 41], [42, 47], [48, 58], [58, 59], [60, 62], [63, 70], [71, 73], [74, 77], [78, 86], [87, 94], [95, 100], [101, 102], [103, 113], [114, 122], [123, 129], [129, 130], [131, 135], [136, 141], [142, 154], [155, 162], [163, 167], [168, 170], [171, 179], [180, 187], [188, 190], [191, 201], [202, 210], [211, 218], [218, 219]]}
{"doc_key": "ai-test-9", "ner": [[0, 0, "product"], [8, 9, "task"], [11, 11, "task"], [13, 15, "task"], [17, 18, "task"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 0, "usage", "", true, false], [11, 11, 0, 0, "usage", "", true, false], [13, 15, 0, 0, "usage", "", true, false], [17, 18, 0, 0, "usage", "", true, false], [24, 26, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "has", "been", "used", "in", "applications", "such", "as", "question", "answering", ",", "paraphrasing", ",", "textual", "implication", "recognition", "and", "information", "extraction", ",", "either", "directly", "or", "via", "semantic", "role", "labelling", "tools", "."], "sentence-detokenized": "FrameNet has been used in applications such as question answering, paraphrasing, textual implication recognition and information extraction, either directly or via semantic role labelling tools.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 25], [26, 38], [39, 43], [44, 46], [47, 55], [56, 65], [65, 66], [67, 79], [79, 80], [81, 88], [89, 100], [101, 112], [113, 116], [117, 128], [129, 139], [139, 140], [141, 147], [148, 156], [157, 159], [160, 163], [164, 172], [173, 177], [178, 187], [188, 193], [193, 194]]}
{"doc_key": "ai-test-10", "ner": [[5, 6, "field"], [11, 11, "misc"], [14, 14, "product"], [17, 17, "misc"], [20, 20, "product"], [23, 24, "field"], [27, 27, "product"], [30, 32, "misc"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [42, 43, "misc"], [46, 47, "product"], [49, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[14, 14, 11, 11, "general-affiliation", "", false, false], [20, 20, 17, 17, "general-affiliation", "", false, false], [27, 27, 23, 24, "general-affiliation", "", false, false], [35, 35, 30, 32, "type-of", "", false, false], [37, 37, 30, 32, "type-of", "", false, false], [39, 39, 30, 32, "type-of", "", false, false], [46, 47, 42, 43, "general-affiliation", "", false, false], [49, 50, 42, 43, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["This", "includes", "programmes", "such", "as", "data", "analysis", "and", "extraction", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "generalised", "audit", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "e.g.", "Crystal", "Reports", "and", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "This includes programmes such as data analysis and extraction tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), generalised audit software (e.g. ACL, Arbutus, EAS), business intelligence (e.g. Crystal Reports and Business Objects), etc.", "token2charspan": [[0, 4], [5, 13], [14, 24], [25, 29], [30, 32], [33, 37], [38, 46], [47, 50], [51, 61], [62, 67], [67, 68], [69, 81], [82, 83], [83, 87], [88, 93], [93, 94], [94, 95], [96, 105], [106, 107], [107, 111], [112, 118], [118, 119], [119, 120], [121, 132], [133, 141], [142, 143], [143, 147], [148, 151], [151, 152], [152, 153], [154, 165], [166, 171], [172, 180], [181, 182], [182, 186], [187, 190], [190, 191], [192, 199], [199, 200], [201, 204], [204, 205], [205, 206], [207, 215], [216, 228], [229, 230], [230, 234], [235, 242], [243, 250], [251, 254], [255, 263], [264, 271], [271, 272], [272, 273], [274, 277], [277, 278]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 6, "researcher"], [10, 10, "organisation"], [13, 13, "product"], [21, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "origin", "", false, false], [5, 6, 10, 10, "role", "", false, false], [13, 13, 21, 22, "type-of", "", false, false], [21, 22, 5, 6, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", "-", "founded", "by", "Rodney", "Brooks", ",", "formerly", "at", "iRobot", "-", "introduced", "Baxter", "in", "September", "2012", ";", "it", "is", "an", "industrial", "robot", "designed", "to", "interact", "safely", "with", "nearby", "human", "workers", "and", "programmable", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "Rethink Robotics - founded by Rodney Brooks, formerly at iRobot - introduced Baxter in September 2012; it is an industrial robot designed to interact safely with nearby human workers and programmable to perform simple tasks.", "token2charspan": [[0, 7], [8, 16], [17, 18], [19, 26], [27, 29], [30, 36], [37, 43], [43, 44], [45, 53], [54, 56], [57, 63], [64, 65], [66, 76], [77, 83], [84, 86], [87, 96], [97, 101], [101, 102], [103, 105], [106, 108], [109, 111], [112, 122], [123, 128], [129, 137], [138, 140], [141, 149], [150, 156], [157, 161], [162, 168], [169, 174], [175, 182], [183, 186], [187, 199], [200, 202], [203, 210], [211, 217], [218, 223], [223, 224]]}
{"doc_key": "ai-test-12", "ner": [[1, 2, "field"], [6, 6, "task"], [8, 9, "task"], [11, 14, "task"], [17, 20, "task"], [22, 23, "task"], [25, 26, "task"], [28, 30, "task"], [37, 39, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 6, 1, 2, "part-of", "task_part_of_field", false, false], [8, 9, 1, 2, "part-of", "task_part_of_field", false, false], [11, 14, 1, 2, "part-of", "task_part_of_field", false, false], [17, 20, 1, 2, "part-of", "task_part_of_field", false, false], [22, 23, 1, 2, "part-of", "task_part_of_field", false, false], [25, 26, 1, 2, "part-of", "task_part_of_field", false, false], [28, 30, 1, 2, "part-of", "task_part_of_field", false, false], [37, 39, 1, 2, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Typical", "text", "mining", "tasks", "include", "text", "categorisation", ",", "text", "clustering", ",", "concept", "/", "entity", "extraction", ",", "the", "production", "of", "granular", "taxonomies", ",", "sentiment", "analysis", ",", "document", "synthesis", "and", "entity", "relationship", "modelling", "(", "i.e.", "learning", "the", "relationships", "between", "recognised", "named", "entities", ")", "."], "sentence-detokenized": "Typical text mining tasks include text categorisation, text clustering, concept/entity extraction, the production of granular taxonomies, sentiment analysis, document synthesis and entity relationship modelling (i.e. learning the relationships between recognised named entities).", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 25], [26, 33], [34, 38], [39, 53], [53, 54], [55, 59], [60, 70], [70, 71], [72, 79], [79, 80], [80, 86], [87, 97], [97, 98], [99, 102], [103, 113], [114, 116], [117, 125], [126, 136], [136, 137], [138, 147], [148, 156], [156, 157], [158, 166], [167, 176], [177, 180], [181, 187], [188, 200], [201, 210], [211, 212], [212, 216], [217, 225], [226, 229], [230, 243], [244, 251], [252, 262], [263, 268], [269, 277], [277, 278], [278, 279]]}
{"doc_key": "ai-test-13", "ner": [[5, 5, "metrics"], [8, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "stemming", "reduces", "the", "accuracy", ",", "or", "true", "negative", "rate", ",", "for", "these", "systems", "."], "sentence-detokenized": "However, stemming reduces the accuracy, or true negative rate, for these systems.", "token2charspan": [[0, 7], [7, 8], [9, 17], [18, 25], [26, 29], [30, 38], [38, 39], [40, 42], [43, 47], [48, 56], [57, 61], [61, 62], [63, 66], [67, 72], [73, 80], [80, 81]]}
{"doc_key": "ai-test-14", "ner": [[4, 5, "task"], [10, 10, "misc"], [14, 15, "misc"], [25, 25, "product"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 10, 4, 5, "temporal", "", false, false], [14, 15, 10, 10, "named", "", false, false], [25, 25, 10, 10, "usage", "", false, false], [27, 27, 10, 10, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "special", "case", "of", "keyword", "detection", "is", "the", "detection", "of", "passwords", "(", "also", "called", "hot", "words", ")", ",", "used", "by", "personal", "digital", "assistants", "such", "as", "Alexa", "or", "Siri", "to", "wake", "up", "when", "their", "name", "is", "spoken", "."], "sentence-detokenized": "A special case of keyword detection is the detection of passwords (also called hot words), used by personal digital assistants such as Alexa or Siri to wake up when their name is spoken.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 17], [18, 25], [26, 35], [36, 38], [39, 42], [43, 52], [53, 55], [56, 65], [66, 67], [67, 71], [72, 78], [79, 82], [83, 88], [88, 89], [89, 90], [91, 95], [96, 98], [99, 107], [108, 115], [116, 126], [127, 131], [132, 134], [135, 140], [141, 143], [144, 148], [149, 151], [152, 156], [157, 159], [160, 164], [165, 170], [171, 175], [176, 178], [179, 185], [185, 186]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [9, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "and", "Java", "."], "sentence-detokenized": "Prova is an open source programming language that combines Prolog and Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 16], [17, 23], [24, 35], [36, 44], [45, 49], [50, 58], [59, 65], [66, 69], [70, 74], [74, 75]]}
{"doc_key": "ai-test-16", "ner": [[3, 4, "organisation"], [9, 9, "organisation"], [16, 18, "product"], [28, 29, "country"], [35, 35, "organisation"], [43, 43, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 9, 9, "part-of", "", false, false], [3, 4, 9, 9, "role", "sells", false, false], [3, 4, 28, 29, "role", "sells_to", false, false], [35, 35, 43, 43, "opposite", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "1987", ",", "Tocibai", "Machine", ",", "a", "subsidiary", "of", "Toshiba", ",", "was", "accused", "of", "illegally", "selling", "CNC", "milling", "cutters", "used", "to", "produce", "very", "quiet", "submarine", "propellers", "to", "the", "Soviet", "Union", ",", "in", "violation", "of", "the", "CoCom", "Agreement", ",", "an", "international", "embargo", "against", "certain", "COMECON", "countries", "."], "sentence-detokenized": "In 1987, Tocibai Machine, a subsidiary of Toshiba, was accused of illegally selling CNC milling cutters used to produce very quiet submarine propellers to the Soviet Union, in violation of the CoCom Agreement, an international embargo against certain COMECON countries.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 24], [24, 25], [26, 27], [28, 38], [39, 41], [42, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 75], [76, 83], [84, 87], [88, 95], [96, 103], [104, 108], [109, 111], [112, 119], [120, 124], [125, 130], [131, 140], [141, 151], [152, 154], [155, 158], [159, 165], [166, 171], [171, 172], [173, 175], [176, 185], [186, 188], [189, 192], [193, 198], [199, 208], [208, 209], [210, 212], [213, 226], [227, 234], [235, 242], [243, 250], [251, 258], [259, 268], [268, 269]]}
{"doc_key": "ai-test-17", "ner": [[0, 0, "researcher"], [7, 10, "product"], [21, 25, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 0, 0, "artifact", "", false, false], [7, 10, 21, 25, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Engelberger", "'s", "most", "famous", "co-invention", ",", "the", "Unimate", "industrial", "robotic", "arm", ",", "was", "among", "the", "first", "to", "be", "inducted", "into", "the", "Robot", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberger's most famous co-invention, the Unimate industrial robotic arm, was among the first to be inducted into the Robot Hall of Fame in 2003.", "token2charspan": [[0, 11], [11, 13], [14, 18], [19, 25], [26, 38], [38, 39], [40, 43], [44, 51], [52, 62], [63, 70], [71, 74], [74, 75], [76, 79], [80, 85], [86, 89], [90, 95], [96, 98], [99, 101], [102, 110], [111, 115], [116, 119], [120, 125], [126, 130], [131, 133], [134, 138], [139, 141], [142, 146], [146, 147]]}
{"doc_key": "ai-test-18", "ner": [[3, 4, "misc"], [8, 8, "misc"], [10, 10, "person"], [21, 22, "field"], [18, 20, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 8, 8, "usage", "", false, false], [10, 10, 21, 22, "role", "", false, false], [21, 22, 18, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Initially", "controlled", "through", "static", "html", "web", "pages", "using", "CGI", ",", "Dalton", "'s", "work", "saw", "the", "introduction", "of", "a", "Java", "-", "based", "augmented", "reality", "interface", ",", "which", "met", "with", "limited", "success", "."], "sentence-detokenized": "Initially controlled through static html web pages using CGI, Dalton's work saw the introduction of a Java-based augmented reality interface, which met with limited success.", "token2charspan": [[0, 9], [10, 20], [21, 28], [29, 35], [36, 40], [41, 44], [45, 50], [51, 56], [57, 60], [60, 61], [62, 68], [68, 70], [71, 75], [76, 79], [80, 83], [84, 96], [97, 99], [100, 101], [102, 106], [106, 107], [107, 112], [113, 122], [123, 130], [131, 140], [140, 141], [142, 147], [148, 151], [152, 156], [157, 164], [165, 172], [172, 173]]}
{"doc_key": "ai-test-19", "ner": [[5, 7, "task"], [10, 10, "organisation"], [25, 25, "conference"], [28, 28, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 10, 10, "origin", "", false, false], [25, 25, 28, 28, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "publication", "on", "the", "LMF", "specification", "as", "ratified", "by", "ISO", "(", "this", "document", "became", "(", "in", "2015", ")", "the", "9th", "most", "cited", "document", "within", "LREC", "conferences", "among", "LREC", "documents", ")", ":"], "sentence-detokenized": "The first publication on the LMF specification as ratified by ISO (this document became (in 2015) the 9th most cited document within LREC conferences among LREC documents):", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 24], [25, 28], [29, 32], [33, 46], [47, 49], [50, 58], [59, 61], [62, 65], [66, 67], [67, 71], [72, 80], [81, 87], [88, 89], [89, 91], [92, 96], [96, 97], [98, 101], [102, 105], [106, 110], [111, 116], [117, 125], [126, 132], [133, 137], [138, 149], [150, 155], [156, 160], [161, 170], [170, 171], [171, 172]]}
{"doc_key": "ai-test-20", "ner": [[1, 2, "metrics"], [15, 16, "metrics"], [18, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 1, 2, "usage", "", false, false], [15, 16, 18, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "confusion", "matrix", "or", "matching", "matrix", "is", "often", "used", "as", "a", "tool", "to", "validate", "the", "accuracy", "of", "the", "k", "-", "NN", "classification", "."], "sentence-detokenized": "A confusion matrix or matching matrix is often used as a tool to validate the accuracy of the k -NN classification.", "token2charspan": [[0, 1], [2, 11], [12, 18], [19, 21], [22, 30], [31, 37], [38, 40], [41, 46], [47, 51], [52, 54], [55, 56], [57, 61], [62, 64], [65, 73], [74, 77], [78, 86], [87, 89], [90, 93], [94, 95], [96, 97], [97, 99], [100, 114], [114, 115]]}
{"doc_key": "ai-test-21", "ner": [[0, 1, "algorithm"], [12, 12, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 15, "part-of", "", false, false], [0, 1, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", "is", "one", "of", "the", "predictive", "modelling", "approaches", "used", "in", "statistics", ",", "data", "mining", "and", "machine", "learning", "."], "sentence-detokenized": "Decision tree learning is one of the predictive modelling approaches used in statistics, data mining and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 47], [48, 57], [58, 68], [69, 73], [74, 76], [77, 87], [87, 88], [89, 93], [94, 100], [101, 104], [105, 112], [113, 121], [121, 122]]}
{"doc_key": "ai-test-22", "ner": [[5, 5, "misc"], [18, 22, "field"], [23, 25, "algorithm"], [27, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 18, 22, "related-to", "", true, false], [23, 25, 18, 22, "type-of", "", false, false], [27, 27, 18, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["During", "execution", ",", "the", "target", "prosody", "of", "a", "phrase", "is", "superimposed", "on", "these", "minimal", "units", "by", "means", "of", "signal", "processing", "techniques", "such", "as", "linear", "predictive", "coding", ",", "PSOLA"], "sentence-detokenized": "During execution, the target prosody of a phrase is superimposed on these minimal units by means of signal processing techniques such as linear predictive coding, PSOLA", "token2charspan": [[0, 6], [7, 16], [16, 17], [18, 21], [22, 28], [29, 36], [37, 39], [40, 41], [42, 48], [49, 51], [52, 64], [65, 67], [68, 73], [74, 81], [82, 87], [88, 90], [91, 96], [97, 99], [100, 106], [107, 117], [118, 128], [129, 133], [134, 136], [137, 143], [144, 154], [155, 161], [161, 162], [163, 168]]}
{"doc_key": "ai-test-23", "ner": [[3, 4, "field"], [6, 7, "field"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 3, 4, "usage", "", true, false], [17, 18, 6, 7, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "approach", "used", "artificial", "intelligence", "and", "machine", "learning", "to", "enable", "researchers", "to", "visually", "compare", "conventional", "and", "thermal", "facial", "images", "."], "sentence-detokenized": "This approach used artificial intelligence and machine learning to enable researchers to visually compare conventional and thermal facial images.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 29], [30, 42], [43, 46], [47, 54], [55, 63], [64, 66], [67, 73], [74, 85], [86, 88], [89, 97], [98, 105], [106, 118], [119, 122], [123, 130], [131, 137], [138, 144], [144, 145]]}
{"doc_key": "ai-test-24", "ner": [[1, 2, "field"], [4, 5, "algorithm"], [12, 13, "task"], [16, 17, "misc"], [22, 23, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 1, 2, "part-of", "", false, false], [4, 5, 12, 13, "topic", "", false, false], [12, 13, 16, 17, "origin", "", false, false], [22, 23, 1, 2, "part-of", "", false, false], [22, 23, 4, 5, "topic", "", false, false], [25, 26, 1, 2, "part-of", "", false, false], [25, 26, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "computer", "science", ",", "evolutionary", "computing", "is", "a", "family", "of", "algorithms", "for", "global", "optimisation", "inspired", "by", "biological", "evolution", "and", "the", "subfield", "of", "artificial", "intelligence", "and", "soft", "computing", "that", "studies", "these", "algorithms", "."], "sentence-detokenized": "In computer science, evolutionary computing is a family of algorithms for global optimisation inspired by biological evolution and the subfield of artificial intelligence and soft computing that studies these algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 33], [34, 43], [44, 46], [47, 48], [49, 55], [56, 58], [59, 69], [70, 73], [74, 80], [81, 93], [94, 102], [103, 105], [106, 116], [117, 126], [127, 130], [131, 134], [135, 143], [144, 146], [147, 157], [158, 170], [171, 174], [175, 179], [180, 189], [190, 194], [195, 202], [203, 208], [209, 219], [219, 220]]}
{"doc_key": "ai-test-25", "ner": [[11, 12, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "one", "can", "combine", "a", "measure", "based", "on", "the", "confusion", "matrix", "with", "the", "mean", "square", "error", "evaluated", "between", "the", "raw", "results", "of", "the", "model", "and", "the", "actual", "values", "."], "sentence-detokenized": "For example, one can combine a measure based on the confusion matrix with the mean square error evaluated between the raw results of the model and the actual values.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 20], [21, 28], [29, 30], [31, 38], [39, 44], [45, 47], [48, 51], [52, 61], [62, 68], [69, 73], [74, 77], [78, 82], [83, 89], [90, 95], [96, 105], [106, 113], [114, 117], [118, 121], [122, 129], [130, 132], [133, 136], [137, 142], [143, 146], [147, 150], [151, 157], [158, 164], [164, 165]]}
{"doc_key": "ai-test-26", "ner": [[5, 6, "product"], [9, 9, "researcher"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 9, 9, "origin", "", false, false], [5, 6, 16, 16, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Most", "are", "results", "of", "the", "word2vec", "model", "developed", "by", "Mikolov", "et", "al", ".", "or", "variants", "of", "word2vec", "."], "sentence-detokenized": "Most are results of the word2vec model developed by Mikolov et al. or variants of word2vec.", "token2charspan": [[0, 4], [5, 8], [9, 16], [17, 19], [20, 23], [24, 32], [33, 38], [39, 48], [49, 51], [52, 59], [60, 62], [63, 65], [65, 66], [67, 69], [70, 78], [79, 81], [82, 90], [90, 91]]}
{"doc_key": "ai-test-27", "ner": [[12, 12, "conference"], [15, 19, "conference"], [21, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 21, 15, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["During", "this", "period", ",", "a", "total", "of", "43", "publications", "were", "recognised", "by", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "During this period, a total of 43 publications were recognised by CVPR and the International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 6], [7, 11], [12, 18], [18, 19], [20, 21], [22, 27], [28, 30], [31, 33], [34, 46], [47, 51], [52, 62], [63, 65], [66, 70], [71, 74], [75, 78], [79, 92], [93, 103], [104, 106], [107, 115], [116, 122], [123, 124], [124, 128], [128, 129], [129, 130]]}
{"doc_key": "ai-test-28", "ner": [[1, 1, "product"], [11, 12, "field"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 11, 12, "general-affiliation", "platform_for_education_about", false, false], [23, 24, 1, 1, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "AIBO", "has", "been", "widely", "used", "as", "an", "economical", "platform", "for", "artificial", "intelligence", "education", "and", "research", ",", "because", "it", "integrates", "a", "computer", ",", "computer", "vision", "and", "articulators", "in", "a", "much", "cheaper", "package", "than", "conventional", "research", "robots", "."], "sentence-detokenized": "The AIBO has been widely used as an economical platform for artificial intelligence education and research, because it integrates a computer, computer vision and articulators in a much cheaper package than conventional research robots.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 17], [18, 24], [25, 29], [30, 32], [33, 35], [36, 46], [47, 55], [56, 59], [60, 70], [71, 83], [84, 93], [94, 97], [98, 106], [106, 107], [108, 115], [116, 118], [119, 129], [130, 131], [132, 140], [140, 141], [142, 150], [151, 157], [158, 161], [162, 174], [175, 177], [178, 179], [180, 184], [185, 192], [193, 200], [201, 205], [206, 218], [219, 227], [228, 234], [234, 235]]}
{"doc_key": "ai-test-29", "ner": [[6, 10, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "was", "programme", "chair", "of", "the", "International", "Computer", "Vision", "Conference", "2021", "."], "sentence-detokenized": "She was programme chair of the International Computer Vision Conference 2021.", "token2charspan": [[0, 3], [4, 7], [8, 17], [18, 23], [24, 26], [27, 30], [31, 44], [45, 53], [54, 60], [61, 71], [72, 76], [76, 77]]}
{"doc_key": "ai-test-30", "ner": [[0, 0, "researcher"], [7, 7, "organisation"], [16, 16, "organisation"], [26, 27, "organisation"], [33, 36, "product"], [38, 38, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 7, 7, "role", "", false, false], [0, 0, 16, 16, "role", "", true, false], [16, 16, 26, 27, "role", "develops_with", false, false], [33, 36, 16, 16, "artifact", "", false, false], [38, 38, 33, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Scheinman", ",", "after", "receiving", "a", "grant", "from", "Unimation", "to", "develop", "his", "designs", ",", "sold", "them", "to", "Unimation", ",", "which", "developed", "them", "further", "with", "the", "support", "of", "General", "Motors", "and", "later", "marketed", "them", "as", "Universal", "Programmable", "Assembly", "Machine", "(", "PUMA", ")", "."], "sentence-detokenized": "Scheinman, after receiving a grant from Unimation to develop his designs, sold them to Unimation, which developed them further with the support of General Motors and later marketed them as Universal Programmable Assembly Machine (PUMA).", "token2charspan": [[0, 9], [9, 10], [11, 16], [17, 26], [27, 28], [29, 34], [35, 39], [40, 49], [50, 52], [53, 60], [61, 64], [65, 72], [72, 73], [74, 78], [79, 83], [84, 86], [87, 96], [96, 97], [98, 103], [104, 113], [114, 118], [119, 126], [127, 131], [132, 135], [136, 143], [144, 146], [147, 154], [155, 161], [162, 165], [166, 171], [172, 180], [181, 185], [186, 188], [189, 198], [199, 211], [212, 220], [221, 228], [229, 230], [230, 234], [234, 235], [235, 236]]}
{"doc_key": "ai-test-31", "ner": [[6, 9, "task"], [8, 10, "task"], [14, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 6, 9, "general-affiliation", "works_with", false, false], [14, 14, 8, 10, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "overview", "of", "calibration", "methods", "for", "binary", "and", "multiclass", "classification", "tasks", "is", "provided", "by", "Gebel", "(", "2009", ")"], "sentence-detokenized": "An overview of calibration methods for binary and multiclass classification tasks is provided by Gebel (2009)", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 34], [35, 38], [39, 45], [46, 49], [50, 60], [61, 75], [76, 81], [82, 84], [85, 93], [94, 96], [97, 102], [103, 104], [104, 108], [108, 109]]}
{"doc_key": "ai-test-32", "ner": [[7, 9, "task"], [11, 11, "task"], [15, 15, "task"], [14, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "is", "involved", "in", "fields", "such", "as", "optical", "character", "recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "voice", "recognition", "technology", "and", "keyboard", "-", "based", "electronic", "instruments", "."], "sentence-detokenized": "It is involved in fields such as optical character recognition (OCR), speech synthesis, voice recognition technology and keyboard-based electronic instruments.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 24], [25, 29], [30, 32], [33, 40], [41, 50], [51, 62], [63, 64], [64, 67], [67, 68], [68, 69], [70, 76], [77, 86], [86, 87], [88, 93], [94, 105], [106, 116], [117, 120], [121, 129], [129, 130], [130, 135], [136, 146], [147, 158], [158, 159]]}
{"doc_key": "ai-test-33", "ner": [[13, 14, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "latest", "state", "-", "of", "-", "the", "-", "art", "techniques", ",", "the", "Kaldi", "toolkit", "can", "be", "used", "."], "sentence-detokenized": "For the latest state-of-the-art techniques, the Kaldi toolkit can be used.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 20], [20, 21], [21, 23], [23, 24], [24, 27], [27, 28], [28, 31], [32, 42], [42, 43], [44, 47], [48, 53], [54, 61], [62, 65], [66, 68], [69, 73], [73, 74]]}
{"doc_key": "ai-test-34", "ner": [[0, 2, "researcher"], [8, 10, "organisation"], [16, 17, "organisation"], [23, 24, "organisation"], [27, 28, "researcher"], [32, 35, "organisation"], [41, 43, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 8, 10, "role", "", false, false], [0, 2, 16, 17, "role", "", false, false], [0, 2, 23, 24, "role", "", false, false], [0, 2, 32, 35, "role", "", false, false], [0, 2, 41, 43, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson", "-", "Laird", "is", "a", "Fellow", "of", "the", "American", "Philosophical", "Society", ",", "a", "Fellow", "of", "the", "Royal", "Society", ",", "a", "Fellow", "of", "the", "British", "Academy", ",", "a", "William", "James", "Fellow", "of", "the", "Association", "for", "Psychological", "Science", "and", "a", "Fellow", "of", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Johnson-Laird is a Fellow of the American Philosophical Society, a Fellow of the Royal Society, a Fellow of the British Academy, a William James Fellow of the Association for Psychological Science and a Fellow of the Cognitive Science Society.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 66], [67, 73], [74, 76], [77, 80], [81, 86], [87, 94], [94, 95], [96, 97], [98, 104], [105, 107], [108, 111], [112, 119], [120, 127], [127, 128], [129, 130], [131, 138], [139, 144], [145, 151], [152, 154], [155, 158], [159, 170], [171, 174], [175, 188], [189, 196], [197, 200], [201, 202], [203, 209], [210, 212], [213, 216], [217, 226], [227, 234], [235, 242], [242, 243]]}
{"doc_key": "ai-test-35", "ner": [[2, 7, "conference"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"], [21, 22, "algorithm"], [26, 30, "task"], [32, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 12, 2, 7, "physical", "", false, false], [11, 12, 2, 7, "temporal", "", false, false], [14, 15, 2, 7, "physical", "", false, false], [14, 15, 2, 7, "temporal", "", false, false], [17, 18, 2, 7, "physical", "", false, false], [17, 18, 2, 7, "temporal", "", false, false], [21, 22, 17, 18, "role", "extends", false, false], [26, 30, 17, 18, "role", "extends", false, false], [32, 32, 26, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["At", "the", "IEEE", "International", "Conference", "on", "Image", "Processing", "in", "2010", ",", "Rui", "Hu", ",", "Mark", "Banard", "and", "John", "Collomosse", "extended", "the", "HOG", "descriptor", "for", "use", "in", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the IEEE International Conference on Image Processing in 2010, Rui Hu, Mark Banard and John Collomosse extended the HOG descriptor for use in sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 25], [26, 36], [37, 39], [40, 45], [46, 56], [57, 59], [60, 64], [64, 65], [66, 69], [70, 72], [72, 73], [74, 78], [79, 85], [86, 89], [90, 94], [95, 105], [106, 114], [115, 118], [119, 122], [123, 133], [134, 137], [138, 141], [142, 144], [145, 151], [151, 152], [152, 157], [158, 163], [164, 173], [174, 175], [175, 179], [179, 180], [180, 181]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "uses", "a", "modified", "form", "of", "precision", "to", "compare", "a", "candidate", "translation", "with", "several", "reference", "translations", "."], "sentence-detokenized": "BLEU uses a modified form of precision to compare a candidate translation with several reference translations.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 20], [21, 25], [26, 28], [29, 38], [39, 41], [42, 49], [50, 51], [52, 61], [62, 73], [74, 78], [79, 86], [87, 96], [97, 109], [109, 110]]}
{"doc_key": "ai-test-37", "ner": [[35, 36, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "case", "of", "a", "general", "basis", "space", "math", "(", "Y", ",\\", "mathcal", "{", "B", "},\\", "nu", ")", "/", "math", "(", "i.e.", "a", "basis", "space", "that", "can", "not", "be", "counted", ")", ",", "one", "typically", "considers", "relative", "entropy", "."], "sentence-detokenized": "For the case of a general basis space math (Y,\\ mathcal {B},\\ nu) / math (i.e. a basis space that cannot be counted), one typically considers relative entropy.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 15], [16, 17], [18, 25], [26, 31], [32, 37], [38, 42], [43, 44], [44, 45], [45, 47], [48, 55], [56, 57], [57, 58], [58, 61], [62, 64], [64, 65], [66, 67], [68, 72], [73, 74], [74, 78], [79, 80], [81, 86], [87, 92], [93, 97], [98, 101], [101, 104], [105, 107], [108, 115], [115, 116], [116, 117], [118, 121], [122, 131], [132, 141], [142, 150], [151, 158], [158, 159]]}
{"doc_key": "ai-test-38", "ner": [[17, 17, "country"], [9, 10, "organisation"], [12, 12, "organisation"], [26, 27, "country"], [19, 20, "organisation"], [22, 22, "organisation"], [30, 32, "organisation"], [45, 46, "country"], [35, 40, "organisation"], [42, 42, "organisation"], [50, 50, "misc"], [51, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[9, 10, 17, 17, "physical", "", false, false], [12, 12, 9, 10, "named", "", false, false], [19, 20, 26, 27, "physical", "", false, false], [22, 22, 19, 20, "named", "", false, false], [35, 40, 45, 46, "physical", "", false, false], [42, 42, 35, 40, "named", "", false, false], [50, 50, 51, 53, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "October", "2011", ",", "existing", "partnerships", "with", "the", "National", "Park", "Service", "(", "NPS", ")", "of", "the", "United", "States", ",", "Historic", "Scotland", "(", "HS", ")", "of", "the", "United", "Kingdom", ",", "the", "World", "Monuments", "Fund", "and", "the", "Instituto", "Nacional", "de", "Antropolog\u00eda", "y", "Historia", "(", "INAH", ")", "of", "Mexico", "were", "significantly", "expanded", ",", "CyArk", "'s", "website", "states", "."], "sentence-detokenized": "In October 2011, existing partnerships with the National Park Service (NPS) of the United States, Historic Scotland (HS) of the United Kingdom, the World Monuments Fund and the Instituto Nacional de Antropolog\u00eda y Historia (INAH) of Mexico were significantly expanded, CyArk's website states.", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [17, 25], [26, 38], [39, 43], [44, 47], [48, 56], [57, 61], [62, 69], [70, 71], [71, 74], [74, 75], [76, 78], [79, 82], [83, 89], [90, 96], [96, 97], [98, 106], [107, 115], [116, 117], [117, 119], [119, 120], [121, 123], [124, 127], [128, 134], [135, 142], [142, 143], [144, 147], [148, 153], [154, 163], [164, 168], [169, 172], [173, 176], [177, 186], [187, 195], [196, 198], [199, 211], [212, 213], [214, 222], [223, 224], [224, 228], [228, 229], [230, 232], [233, 239], [240, 244], [245, 258], [259, 267], [267, 268], [269, 274], [274, 276], [277, 284], [285, 291], [291, 292]]}
{"doc_key": "ai-test-39", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [11, 11, "product"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 11, 11, "part-of", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [11, 11, 6, 7, "general-affiliation", "", false, false], [13, 13, 6, 7, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kernel", "SVMs", "are", "available", "in", "many", "machine", "learning", "toolkits", ",", "including", "LIBSVM", ",", "MATLAB", "and", "others", "."], "sentence-detokenized": "Kernel SVMs are available in many machine learning toolkits, including LIBSVM, MATLAB and others.", "token2charspan": [[0, 6], [7, 11], [12, 15], [16, 25], [26, 28], [29, 33], [34, 41], [42, 50], [51, 59], [59, 60], [61, 70], [71, 77], [77, 78], [79, 85], [86, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-test-40", "ner": [[2, 6, "misc"], [14, 14, "location"], [16, 16, "location"], [17, 17, "country"], [23, 25, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 6, 14, 14, "physical", "", false, false], [2, 6, 23, 25, "temporal", "", false, false], [14, 14, 16, 16, "physical", "", false, false], [16, 16, 17, 17, "physical", "", false, false], [23, 25, 14, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2009", "Loebner", "Prize", "competition", "was", "held", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", ",", "Brighton", "UK", ",", "in", "conjunction", "with", "the", "Interspeech", "2009", "conference", "."], "sentence-detokenized": "The 2009 Loebner Prize competition was held on 6 September 2009 at the Brighton Centre, Brighton UK, in conjunction with the Interspeech 2009 conference.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 34], [35, 38], [39, 43], [44, 46], [47, 48], [49, 58], [59, 63], [64, 66], [67, 70], [71, 79], [80, 86], [86, 87], [88, 96], [97, 99], [99, 100], [101, 103], [104, 115], [116, 120], [121, 124], [125, 136], [137, 141], [142, 152], [152, 153]]}
{"doc_key": "ai-test-41", "ner": [[0, 4, "product"], [10, 10, "product"], [16, 18, "product"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 21, 0, 4, "part-of", "", false, false], [19, 21, 10, 10, "part-of", "", false, false], [19, 21, 16, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "QRIO", "humanoid", "robot", "was", "designed", "as", "a", "successor", "to", "AIBO", "and", "uses", "the", "same", "basic", "R", "-", "CODE", "Aperios", "operating", "system", "."], "sentence-detokenized": "The QRIO humanoid robot was designed as a successor to AIBO and uses the same basic R-CODE Aperios operating system.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 23], [24, 27], [28, 36], [37, 39], [40, 41], [42, 51], [52, 54], [55, 59], [60, 63], [64, 68], [69, 72], [73, 77], [78, 83], [84, 85], [85, 86], [86, 90], [91, 98], [99, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-42", "ner": [[0, 2, "misc"], [7, 7, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 0, 2, "cause-effect", "", true, false], [14, 15, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "speech", "waveforms", "are", "generated", "by", "the", "HMMs", "themselves", "according", "to", "the", "criterion", "of", "maximum", "likelihood", "."], "sentence-detokenized": "The speech waveforms are generated by the HMMs themselves according to the criterion of maximum likelihood.", "token2charspan": [[0, 3], [4, 10], [11, 20], [21, 24], [25, 34], [35, 37], [38, 41], [42, 46], [47, 57], [58, 67], [68, 70], [71, 74], [75, 84], [85, 87], [88, 95], [96, 106], [106, 107]]}
{"doc_key": "ai-test-43", "ner": [[0, 1, "product"], [5, 10, "task"], [8, 8, "task"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 5, 10, "type-of", "", false, false], [0, 1, 8, 8, "type-of", "", false, false], [0, 1, 14, 14, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "is", "a", "free", "multilingual", "statistical", "and", "neural", "machine", "translation", "service", "developed", "by", "Google", "to", "translate", "texts", "and", "websites", "from", "one", "language", "into", "another", "."], "sentence-detokenized": "Google Translate is a free multilingual statistical and neural machine translation service developed by Google to translate texts and websites from one language into another.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 39], [40, 51], [52, 55], [56, 62], [63, 70], [71, 82], [83, 90], [91, 100], [101, 103], [104, 110], [111, 113], [114, 123], [124, 129], [130, 133], [134, 142], [143, 147], [148, 151], [152, 160], [161, 165], [166, 173], [173, 174]]}
{"doc_key": "ai-test-44", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [14, 16, "field"], [21, 23, "task"], [25, 26, "task"], [28, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[21, 23, 5, 6, "part-of", "", false, true], [21, 23, 8, 9, "part-of", "", false, true], [21, 23, 11, 12, "part-of", "", false, true], [25, 26, 5, 6, "part-of", "", false, true], [25, 26, 8, 9, "part-of", "", false, true], [25, 26, 11, 12, "part-of", "", false, true], [28, 31, 5, 6, "part-of", "", false, true], [28, 31, 8, 9, "part-of", "", false, true], [28, 31, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Skeletons", "are", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", "and", "digital", "image", "processing", "for", "purposes", "such", "as", "optical", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", "or", "compression", "."], "sentence-detokenized": "Skeletons are widely used in computer vision, image analysis, pattern recognition and digital image processing for purposes such as optical character recognition, fingerprint recognition, visual inspection or compression.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 25], [26, 28], [29, 37], [38, 44], [44, 45], [46, 51], [52, 60], [60, 61], [62, 69], [70, 81], [82, 85], [86, 93], [94, 99], [100, 110], [111, 114], [115, 123], [124, 128], [129, 131], [132, 139], [140, 149], [150, 161], [161, 162], [163, 174], [175, 186], [186, 187], [188, 194], [195, 205], [206, 208], [209, 220], [220, 221]]}
{"doc_key": "ai-test-45", "ner": [[1, 8, "conference"], [11, 14, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 8, 11, 14, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "is", "a", "benchmark", "for", "object", "classification", "and", "detection", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark for object classification and detection, with millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 58], [59, 68], [69, 72], [73, 79], [80, 94], [95, 98], [99, 108], [108, 109], [110, 114], [115, 123], [124, 126], [127, 133], [134, 137], [138, 146], [147, 149], [150, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-test-46", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [18, 18, "misc"], [21, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 18, 18, "part-of", "", false, false], [0, 0, 21, 24, "part-of", "", false, false], [4, 5, 18, 18, "part-of", "", false, false], [4, 5, 21, 24, "part-of", "", false, false], [7, 8, 18, 18, "part-of", "", false, false], [7, 8, 21, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "together", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "is", "defined", "by", "some", "as", "the", "godfathers", "of", "AI", "and", "the", "godfathers", "of", "Deep", "Learning", "."], "sentence-detokenized": "Bengio, together with Geoffrey Hinton and Yann LeCun, is defined by some as the godfathers of AI and the godfathers of Deep Learning.", "token2charspan": [[0, 6], [6, 7], [8, 16], [17, 21], [22, 30], [31, 37], [38, 41], [42, 46], [47, 52], [52, 53], [54, 56], [57, 64], [65, 67], [68, 72], [73, 75], [76, 79], [80, 90], [91, 93], [94, 96], [97, 100], [101, 104], [105, 115], [116, 118], [119, 123], [124, 132], [132, 133]]}
{"doc_key": "ai-test-47", "ner": [[7, 7, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "life", "member", "of", "the", "IEEE", "."], "sentence-detokenized": "He is a life member of the IEEE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 19], [20, 22], [23, 26], [27, 31], [31, 32]]}
{"doc_key": "ai-test-48", "ner": [[0, 1, "organisation"], [14, 19, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 14, 19, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NSA", "Bethesda", "is", "responsible", "for", "base", "operational", "support", "for", "its", "main", "tenant", ",", "the", "Walter", "Reed", "National", "Military", "Medical", "Center", "."], "sentence-detokenized": "NSA Bethesda is responsible for base operational support for its main tenant, the Walter Reed National Military Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 31], [32, 36], [37, 48], [49, 56], [57, 60], [61, 64], [65, 69], [70, 76], [76, 77], [78, 81], [82, 88], [89, 93], [94, 102], [103, 111], [112, 119], [120, 126], [126, 127]]}
{"doc_key": "ai-test-49", "ner": [[6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "three", "main", "learning", "paradigms", "are", "supervised", "learning", ",", "unsupervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "The three main learning paradigms are supervised learning, unsupervised learning and reinforcement learning.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 23], [24, 33], [34, 37], [38, 48], [49, 57], [57, 58], [59, 71], [72, 80], [81, 84], [85, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-50", "ner": [[2, 2, "task"], [4, 6, "task"], [11, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Examples", "include", "control", ",", "planning", "and", "scheduling", ",", "the", "ability", "to", "answer", "diagnostic", "and", "consumer", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", "and", "facial", "recognition", "."], "sentence-detokenized": "Examples include control, planning and scheduling, the ability to answer diagnostic and consumer questions, handwriting recognition, natural language understanding, speech recognition and facial recognition.", "token2charspan": [[0, 8], [9, 16], [17, 24], [24, 25], [26, 34], [35, 38], [39, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 72], [73, 83], [84, 87], [88, 96], [97, 106], [106, 107], [108, 119], [120, 131], [131, 132], [133, 140], [141, 149], [150, 163], [163, 164], [165, 171], [172, 183], [184, 187], [188, 194], [195, 206], [206, 207]]}
{"doc_key": "ai-test-51", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", ",", "he", "was", "elected", "a", "fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "founding", "fellow", ")", "."], "sentence-detokenized": "In 1991, he was elected a fellow of the Association for the Advancement of Artificial Intelligence (1990, founding fellow).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [99, 100], [100, 104], [104, 105], [106, 114], [115, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-test-52", "ner": [[11, 12, "misc"], [15, 16, "algorithm"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "by", "formulating", "the", "problem", "as", "a", "solution", "of", "a", "Toeplitz", "matrix", "and", "using", "Levinson", "recursion", ",", "we", "can", "relatively", "quickly", "estimate", "a", "filter", "with", "the", "smallest", "possible", "mean", "square", "error", "."], "sentence-detokenized": "However, by formulating the problem as a solution of a Toeplitz matrix and using Levinson recursion, we can relatively quickly estimate a filter with the smallest possible mean square error.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 23], [24, 27], [28, 35], [36, 38], [39, 40], [41, 49], [50, 52], [53, 54], [55, 63], [64, 70], [71, 74], [75, 80], [81, 89], [90, 99], [99, 100], [101, 103], [104, 107], [108, 118], [119, 126], [127, 135], [136, 137], [138, 144], [145, 149], [150, 153], [154, 162], [163, 171], [172, 176], [177, 183], [184, 189], [189, 190]]}
{"doc_key": "ai-test-53", "ner": [[5, 13, "conference"], [16, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 13, 16, 20, "physical", "", false, false], [16, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2011", ",", "the", "15th", "edition", "of", "Campus", "Party", "Spain", "will", "be", "held", "at", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "In July 2011, the 15th edition of Campus Party Spain will be held at the City of Arts and Sciences in Valencia.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 22], [23, 30], [31, 33], [34, 40], [41, 46], [47, 52], [53, 57], [58, 60], [61, 65], [66, 68], [69, 72], [73, 77], [78, 80], [81, 85], [86, 89], [90, 98], [99, 101], [102, 110], [110, 111]]}
{"doc_key": "ai-test-54", "ner": [[13, 13, "product"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Often", "this", "is", "only", "possible", "at", "the", "end", "of", "complicated", "games", "such", "as", "chess", "or", "go", ",", "as", "it", "is", "not", "computationally", "feasible", "to", "look", "forward", "to", "the", "completion", "of", "the", "game", ",", "except", "towards", "the", "end", ",", "and", "instead", "positions", "are", "given", "finite", "values", "as", "estimates", "of", "the", "degree", "of", "conviction", "that", "will", "lead", "to", "a", "victory", "for", "one", "player", "or", "another", "."], "sentence-detokenized": "Often this is only possible at the end of complicated games such as chess or go, as it is not computationally feasible to look forward to the completion of the game, except towards the end, and instead positions are given finite values as estimates of the degree of conviction that will lead to a victory for one player or another.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 18], [19, 27], [28, 30], [31, 34], [35, 38], [39, 41], [42, 53], [54, 59], [60, 64], [65, 67], [68, 73], [74, 76], [77, 79], [79, 80], [81, 83], [84, 86], [87, 89], [90, 93], [94, 109], [110, 118], [119, 121], [122, 126], [127, 134], [135, 137], [138, 141], [142, 152], [153, 155], [156, 159], [160, 164], [164, 165], [166, 172], [173, 180], [181, 184], [185, 188], [188, 189], [190, 193], [194, 201], [202, 211], [212, 215], [216, 221], [222, 228], [229, 235], [236, 238], [239, 248], [249, 251], [252, 255], [256, 262], [263, 265], [266, 276], [277, 281], [282, 286], [287, 291], [292, 294], [295, 296], [297, 304], [305, 308], [309, 312], [313, 319], [320, 322], [323, 330], [330, 331]]}
{"doc_key": "ai-test-55", "ner": [[4, 6, "algorithm"], [24, 25, "algorithm"], [27, 28, "algorithm"], [31, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 24, 25, "compare", "", false, false], [4, 6, 27, 28, "compare", "", false, false], [4, 6, 31, 33, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "difference", "between", "the", "multinomial", "logit", "model", "and", "numerous", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "with", "the", "same", "basic", "approach", "(", "the", "perceptron", "algorithm", ",", "support", "vector", "machines", ",", "linear", "discriminant", "analysis", ",", "etc.", ")", "is", "not", "clear", "."], "sentence-detokenized": "The difference between the multinomial logit model and numerous other methods, models, algorithms, etc. with the same basic approach (the perceptron algorithm, support vector machines, linear discriminant analysis, etc.) is not clear.", "token2charspan": [[0, 3], [4, 14], [15, 22], [23, 26], [27, 38], [39, 44], [45, 50], [51, 54], [55, 63], [64, 69], [70, 77], [77, 78], [79, 85], [85, 86], [87, 97], [97, 98], [99, 103], [104, 108], [109, 112], [113, 117], [118, 123], [124, 132], [133, 134], [134, 137], [138, 148], [149, 158], [158, 159], [160, 167], [168, 174], [175, 183], [183, 184], [185, 191], [192, 204], [205, 213], [213, 214], [215, 219], [219, 220], [221, 223], [224, 227], [228, 233], [233, 234]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "published", "by"], "sentence-detokenized": "Association for Computational Linguistics, published by", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 52], [53, 55]]}
{"doc_key": "ai-test-57", "ner": [[3, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "computerised", "facial", "recognition", "system", ",", "each", "face", "is", "represented", "by", "a", "large", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In the computerised facial recognition system, each face is represented by a large number of pixel values.", "token2charspan": [[0, 2], [3, 6], [7, 19], [20, 26], [27, 38], [39, 45], [45, 46], [47, 51], [52, 56], [57, 59], [60, 71], [72, 74], [75, 76], [77, 82], [83, 89], [90, 92], [93, 98], [99, 105], [105, 106]]}
{"doc_key": "ai-test-58", "ner": [[5, 6, "person"], [13, 17, "organisation"], [22, 22, "country"], [25, 25, "person"], [36, 38, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 13, 17, "role", "", false, false], [5, 6, 22, 22, "physical", "", false, false], [25, 25, 36, 38, "origin", "", false, false], [25, 25, 36, 38, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2002", ",", "her", "son", "Daniel", "Pearl", ",", "a", "journalist", "working", "for", "the", "Wall", "Street", "Journal", ",", "was", "kidnapped", "and", "murdered", "in", "Pakistan", ",", "leading", "Judea", "and", "other", "family", "members", "and", "friends", "to", "set", "up", "the", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "In 2002, her son Daniel Pearl, a journalist working for the Wall Street Journal, was kidnapped and murdered in Pakistan, leading Judea and other family members and friends to set up the Daniel Pearl Foundation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 23], [24, 29], [29, 30], [31, 32], [33, 43], [44, 51], [52, 55], [56, 59], [60, 64], [65, 71], [72, 79], [79, 80], [81, 84], [85, 94], [95, 98], [99, 107], [108, 110], [111, 119], [119, 120], [121, 128], [129, 134], [135, 138], [139, 144], [145, 151], [152, 159], [160, 163], [164, 171], [172, 174], [175, 178], [179, 181], [182, 185], [186, 192], [193, 198], [199, 209], [209, 210]]}
{"doc_key": "ai-test-59", "ner": [[4, 6, "organisation"], [20, 21, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 20, 21, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "late", "2006", ",", "Red", "Envelope", "Entertainment", "has", "also", "expanded", "into", "the", "production", "of", "original", "content", "with", "directors", "such", "as", "John", "Waters", "."], "sentence-detokenized": "Since late 2006, Red Envelope Entertainment has also expanded into the production of original content with directors such as John Waters.", "token2charspan": [[0, 5], [6, 10], [11, 15], [15, 16], [17, 20], [21, 29], [30, 43], [44, 47], [48, 52], [53, 61], [62, 66], [67, 70], [71, 81], [82, 84], [85, 93], [94, 101], [102, 106], [107, 116], [117, 121], [122, 124], [125, 129], [130, 136], [136, 137]]}
{"doc_key": "ai-test-60", "ner": [[7, 11, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "building", "is", "now", "part", "of", "the", "Beth", "Israel", "Deaconess", "Medical", "Center", "."], "sentence-detokenized": "The building is now part of the Beth Israel Deaconess Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 31], [32, 36], [37, 43], [44, 53], [54, 61], [62, 68], [68, 69]]}
{"doc_key": "ai-test-61", "ner": [[18, 19, "field"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "common", "theme", "of", "this", "work", "is", "the", "adoption", "of", "a", "sign", "-", "theoretic", "perspective", "on", "issues", "of", "artificial", "intelligence", "and", "knowledge", "representation", "."], "sentence-detokenized": "A common theme of this work is the adoption of a sign-theoretic perspective on issues of artificial intelligence and knowledge representation.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 43], [44, 46], [47, 48], [49, 53], [53, 54], [54, 63], [64, 75], [76, 78], [79, 85], [86, 88], [89, 99], [100, 112], [113, 116], [117, 126], [127, 141], [141, 142]]}
{"doc_key": "ai-test-62", "ner": [[5, 7, "task"], [9, 9, "task"], [21, 22, "task"], [40, 41, "task"], [43, 44, "task"], [50, 52, "task"], [54, 54, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 7, 21, 22, "type-of", "", false, false], [5, 7, 50, 52, "compare", "", false, false], [5, 7, 50, 52, "opposite", "", false, false], [9, 9, 5, 7, "named", "", false, false], [40, 41, 50, 52, "part-of", "", false, false], [43, 44, 50, 52, "part-of", "", false, false], [50, 52, 21, 22, "type-of", "", false, false], [54, 54, 50, 52, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["For", "instance", ",", "the", "term", "neural", "machine", "translation", "(", "NMT", ")", "emphasises", "the", "fact", "that", "deep", "learning", "-", "based", "approaches", "to", "machine", "translation", "directly", "learn", "sequence", "-", "to", "-", "sequence", "transformations", ",", "eliminating", "the", "need", "for", "intermediate", "steps", "such", "as", "word", "alignment", "and", "language", "modelling", ",", "which", "are", "used", "in", "statistical", "machine", "translation", "(", "SMT", ")", "."], "sentence-detokenized": "For instance, the term neural machine translation (NMT) emphasises the fact that deep learning-based approaches to machine translation directly learn sequence-to-sequence transformations, eliminating the need for intermediate steps such as word alignment and language modelling, which are used in statistical machine translation (SMT).", "token2charspan": [[0, 3], [4, 12], [12, 13], [14, 17], [18, 22], [23, 29], [30, 37], [38, 49], [50, 51], [51, 54], [54, 55], [56, 66], [67, 70], [71, 75], [76, 80], [81, 85], [86, 94], [94, 95], [95, 100], [101, 111], [112, 114], [115, 122], [123, 134], [135, 143], [144, 149], [150, 158], [158, 159], [159, 161], [161, 162], [162, 170], [171, 186], [186, 187], [188, 199], [200, 203], [204, 208], [209, 212], [213, 225], [226, 231], [232, 236], [237, 239], [240, 244], [245, 254], [255, 258], [259, 267], [268, 277], [277, 278], [279, 284], [285, 288], [289, 293], [294, 296], [297, 308], [309, 316], [317, 328], [329, 330], [330, 333], [333, 334], [334, 335]]}
{"doc_key": "ai-test-63", "ner": [[8, 10, "field"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 13, 14, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "of", "the", "research", "in", "the", "field", "of", "WSD", "has", "been", "conducted", "using", "Word", "Net", "as", "a", "reference", "sense", "inventory", "."], "sentence-detokenized": "Most of the research in the field of WSD has been conducted using WordNet as a reference sense inventory.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 20], [21, 23], [24, 27], [28, 33], [34, 36], [37, 40], [41, 44], [45, 49], [50, 59], [60, 65], [66, 70], [70, 73], [74, 76], [77, 78], [79, 88], [89, 94], [95, 104], [104, 105]]}
{"doc_key": "ai-test-64", "ner": [[10, 11, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Former", "PhD", "students", "and", "postdoctoral", "researchers", "in", "his", "group", "include", "Richard", "Zemel", "and", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Former PhD students and postdoctoral researchers in his group include Richard Zemel and Zoubin Ghahramani.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 23], [24, 36], [37, 48], [49, 51], [52, 55], [56, 61], [62, 69], [70, 77], [78, 83], [84, 87], [88, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-test-65", "ner": [[7, 8, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 13, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Each", "prediction", "result", "or", "instance", "of", "a", "confusion", "matrix", "represents", "a", "point", "in", "ROC", "space", "."], "sentence-detokenized": "Each prediction result or instance of a confusion matrix represents a point in ROC space.", "token2charspan": [[0, 4], [5, 15], [16, 22], [23, 25], [26, 34], [35, 37], [38, 39], [40, 49], [50, 56], [57, 67], [68, 69], [70, 75], [76, 78], [79, 82], [83, 88], [88, 89]]}
{"doc_key": "ai-test-66", "ner": [[3, 3, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [17, 19, "product"], [22, 25, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 22, 25, "physical", "", false, false], [7, 8, 22, 25, "physical", "", false, false], [10, 11, 22, 25, "physical", "", false, false], [17, 19, 3, 3, "artifact", "", false, false], [17, 19, 7, 8, "artifact", "", false, false], [17, 19, 10, 11, "artifact", "", false, false], [17, 19, 22, 25, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1997", ",", "Thrun", "and", "his", "colleagues", "Wolfram", "Burgard", "and", "Dieter", "Fox", "developed", "the", "world", "'s", "first", "robotic", "tour", "guide", "in", "the", "Deutsches", "Museum", "in", "Bonn", "."], "sentence-detokenized": "In 1997, Thrun and his colleagues Wolfram Burgard and Dieter Fox developed the world's first robotic tour guide in the Deutsches Museum in Bonn.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 18], [19, 22], [23, 33], [34, 41], [42, 49], [50, 53], [54, 60], [61, 64], [65, 74], [75, 78], [79, 84], [84, 86], [87, 92], [93, 100], [101, 105], [106, 111], [112, 114], [115, 118], [119, 128], [129, 135], [136, 138], [139, 143], [143, 144]]}
{"doc_key": "ai-test-67", "ner": [[0, 3, "product"], [7, 7, "misc"], [24, 26, "field"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 3, "part-of", "", false, false], [24, 26, 0, 3, "usage", "", false, false], [28, 29, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "of", "semantic", "relationships", "between", "words", "in", "more", "than", "200", "languages", ".", "It", "s", "main", "use", "is", "for", "automatic", "natural", "language", "processing", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database of semantic relationships between words in more than 200 languages. Its main use is for automatic natural language processing and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 32], [33, 41], [42, 55], [56, 63], [64, 69], [70, 72], [73, 77], [78, 82], [83, 86], [87, 96], [96, 97], [98, 100], [100, 101], [102, 106], [107, 110], [111, 113], [114, 117], [118, 127], [128, 135], [136, 144], [145, 155], [156, 159], [160, 170], [171, 183], [184, 196], [196, 197]]}
{"doc_key": "ai-test-68", "ner": [[5, 7, "field"], [12, 26, "conference"], [28, 28, "conference"], [30, 30, "conference"], [38, 39, "field"]], "ner_mapping_to_source": [0, 2, 3, 4, 5], "relations": [[12, 26, 5, 7, "topic", "", false, false], [12, 26, 38, 39, "topic", "", false, false], [28, 28, 5, 7, "topic", "", false, false], [28, 28, 38, 39, "topic", "", false, false], [30, 30, 5, 7, "topic", "", false, false], [30, 30, 38, 39, "topic", "", false, false]], "relations_mapping_to_source": [2, 3, 4, 5, 6, 7], "sentence": ["Conferences", "in", "the", "field", "of", "natural", "language", "processing", ",", "such", "as", "the", "Association", "for", "Computational", "Linguistics", ",", "the", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", "and", "HLT", ",", "are", "beginning", "to", "include", "articles", "on", "speech", "processing", "."], "sentence-detokenized": "Conferences in the field of natural language processing, such as the Association for Computational Linguistics, the North American Chapter of the Association for Computational Linguistics, EMNLP and HLT, are beginning to include articles on speech processing.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 24], [25, 27], [28, 35], [36, 44], [45, 55], [55, 56], [57, 61], [62, 64], [65, 68], [69, 80], [81, 84], [85, 98], [99, 110], [110, 111], [112, 115], [116, 121], [122, 130], [131, 138], [139, 141], [142, 145], [146, 157], [158, 161], [162, 175], [176, 187], [187, 188], [189, 194], [195, 198], [199, 202], [202, 203], [204, 207], [208, 217], [218, 220], [221, 228], [229, 237], [238, 240], [241, 247], [248, 258], [258, 259]]}
{"doc_key": "ai-test-69", "ner": [[3, 3, "programlang"], [20, 22, "misc"], [34, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "number", "of", "Java", "programmes", "use", "the", "lexicon", "to", "analyse", "variations", "in", "biomedical", "texts", "by", "relating", "words", "according", "to", "their", "parts", "of", "speech", ",", "which", "can", "be", "useful", "in", "web", "searches", "or", "in", "an", "electronic", "medical", "record", "."], "sentence-detokenized": "A number of Java programmes use the lexicon to analyse variations in biomedical texts by relating words according to their parts of speech, which can be useful in web searches or in an electronic medical record.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 16], [17, 27], [28, 31], [32, 35], [36, 43], [44, 46], [47, 54], [55, 65], [66, 68], [69, 79], [80, 85], [86, 88], [89, 97], [98, 103], [104, 113], [114, 116], [117, 122], [123, 128], [129, 131], [132, 138], [138, 139], [140, 145], [146, 149], [150, 152], [153, 159], [160, 162], [163, 166], [167, 175], [176, 178], [179, 181], [182, 184], [185, 195], [196, 203], [204, 210], [210, 211]]}
{"doc_key": "ai-test-70", "ner": [[8, 8, "algorithm"], [10, 10, "algorithm"], [12, 12, "algorithm"], [14, 14, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "many", "newer", "algorithms", ",", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", "and", "others", "."], "sentence-detokenized": "There are many newer algorithms, such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost and others.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 20], [21, 31], [31, 32], [33, 37], [38, 40], [41, 48], [48, 49], [50, 60], [60, 61], [62, 72], [72, 73], [74, 81], [81, 82], [83, 92], [93, 96], [97, 103], [103, 104]]}
{"doc_key": "ai-test-71", "ner": [[8, 8, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "of", "an", "implementation", "in", "Python", ":"], "sentence-detokenized": "This is an example of an implementation in Python:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 24], [25, 39], [40, 42], [43, 49], [49, 50]]}
{"doc_key": "ai-test-72", "ner": [[1, 1, "organisation"], [2, 2, "product"], [7, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 1, 1, "artifact", "made_by_company", false, false], [7, 9, 2, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Mattel", "Intellivision", "game", "console", "offered", "the", "Intellivoice", "speech", "synthesis", "module", "in", "1982", "."], "sentence-detokenized": "The Mattel Intellivision game console offered the Intellivoice speech synthesis module in 1982.", "token2charspan": [[0, 3], [4, 10], [11, 24], [25, 29], [30, 37], [38, 45], [46, 49], [50, 62], [63, 69], [70, 79], [80, 86], [87, 89], [90, 94], [94, 95]]}
{"doc_key": "ai-test-73", "ner": [[4, 5, "task"], [8, 15, "task"], [17, 18, "field"], [20, 22, "task"], [26, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 15, 4, 5, "part-of", "", false, false], [17, 18, 4, 5, "part-of", "", false, false], [20, 22, 4, 5, "part-of", "", false, false], [26, 31, 20, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "also", "worked", "on", "machine", "translation", ",", "both", "knowledge", "-", "based", "high", "-", "precision", "machine", "translation", "and", "machine", "learning", "for", "statistical", "machine", "translation", "(", "such", "as", "machine", "translation", "based", "on", "generalised", "examples", ")", "."], "sentence-detokenized": "He also worked on machine translation, both knowledge-based high-precision machine translation and machine learning for statistical machine translation (such as machine translation based on generalised examples).", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 17], [18, 25], [26, 37], [37, 38], [39, 43], [44, 53], [53, 54], [54, 59], [60, 64], [64, 65], [65, 74], [75, 82], [83, 94], [95, 98], [99, 106], [107, 115], [116, 119], [120, 131], [132, 139], [140, 151], [152, 153], [153, 157], [158, 160], [161, 168], [169, 180], [181, 186], [187, 189], [190, 201], [202, 210], [210, 211], [211, 212]]}
{"doc_key": "ai-test-74", "ner": [[0, 0, "misc"], [1, 7, "misc"], [21, 22, "algorithm"], [24, 25, "field"], [27, 28, "field"], [30, 30, "field"], [32, 33, "field"], [35, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 21, 22, "general-affiliation", "", false, false], [0, 0, 24, 25, "general-affiliation", "", false, false], [0, 0, 27, 28, "general-affiliation", "", false, false], [0, 0, 30, 30, "general-affiliation", "", false, false], [0, 0, 32, 33, "general-affiliation", "", false, false], [0, 0, 35, 35, "general-affiliation", "", false, false], [1, 7, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "usually", "referred", "to", "as", "Mathematica", ")", "is", "a", "modern", "technical", "computing", "system", "spanning", "most", "technical", "areas", ",", "including", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "data", "science", ",", "visualisations", "and", "others", "."], "sentence-detokenized": "Wolfram Mathematica (usually referred to as Mathematica) is a modern technical computing system spanning most technical areas, including neural networks, machine learning, image processing, geometry, data science, visualisations and others.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 28], [29, 37], [38, 40], [41, 43], [44, 55], [55, 56], [57, 59], [60, 61], [62, 68], [69, 78], [79, 88], [89, 95], [96, 104], [105, 109], [110, 119], [120, 125], [125, 126], [127, 136], [137, 143], [144, 152], [152, 153], [154, 161], [162, 170], [170, 171], [172, 177], [178, 188], [188, 189], [190, 198], [198, 199], [200, 204], [205, 212], [212, 213], [214, 228], [229, 232], [233, 239], [239, 240]]}
{"doc_key": "ai-test-75", "ner": [[2, 6, "product"], [10, 11, "researcher"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 2, 6, "type-of", "", false, false], [17, 17, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "programmable", "and", "digitally", "operated", "robot", "was", "invented", "by", "George", "Devol", "in", "1954", "and", "was", "called", "Unimate", "."], "sentence-detokenized": "The first programmable and digitally operated robot was invented by George Devol in 1954 and was called Unimate.", "token2charspan": [[0, 3], [4, 9], [10, 22], [23, 26], [27, 36], [37, 45], [46, 51], [52, 55], [56, 64], [65, 67], [68, 74], [75, 80], [81, 83], [84, 88], [89, 92], [93, 96], [97, 103], [104, 111], [111, 112]]}
{"doc_key": "ai-test-76", "ner": [[1, 1, "algorithm"], [3, 3, "algorithm"], [17, 18, "task"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 3, 3, "compare", "", false, false], [3, 3, 17, 18, "general-affiliation", "", false, false], [3, 3, 20, 21, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Like", "DBNs", ",", "DBMs", "can", "learn", "complex", "and", "abstract", "internal", "representations", "of", "input", "in", "tasks", "such", "as", "object", "recognition", "or", "speech", "recognition", ",", "using", "limited", "labelled", "data", "to", "fine", "-", "tune", "the", "representations", "constructed", "using", "a", "large", "set", "of", "unlabelled", "input", "sensory", "data", "."], "sentence-detokenized": "Like DBNs, DBMs can learn complex and abstract internal representations of input in tasks such as object recognition or speech recognition, using limited labelled data to fine-tune the representations constructed using a large set of unlabelled input sensory data.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 15], [16, 19], [20, 25], [26, 33], [34, 37], [38, 46], [47, 55], [56, 71], [72, 74], [75, 80], [81, 83], [84, 89], [90, 94], [95, 97], [98, 104], [105, 116], [117, 119], [120, 126], [127, 138], [138, 139], [140, 145], [146, 153], [154, 162], [163, 167], [168, 170], [171, 175], [175, 176], [176, 180], [181, 184], [185, 200], [201, 212], [213, 218], [219, 220], [221, 226], [227, 230], [231, 233], [234, 244], [245, 250], [251, 258], [259, 263], [263, 264]]}
{"doc_key": "ai-test-77", "ner": [[3, 7, "task"], [13, 13, "conference"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 3, 7, "topic", "", false, false], [15, 15, 3, 7, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Scientific", "conferences", "where", "vision", "-", "based", "activity", "recognition", "papers", "are", "often", "presented", "are", "ICCV", "and", "CVPR", "."], "sentence-detokenized": "Scientific conferences where vision-based activity recognition papers are often presented are ICCV and CVPR.", "token2charspan": [[0, 10], [11, 22], [23, 28], [29, 35], [35, 36], [36, 41], [42, 50], [51, 62], [63, 69], [70, 73], [74, 79], [80, 89], [90, 93], [94, 98], [99, 102], [103, 107], [107, 108]]}
{"doc_key": "ai-test-78", "ner": [[1, 1, "field"], [4, 5, "algorithm"], [7, 7, "algorithm"], [17, 17, "metrics"], [19, 21, "metrics"], [23, 23, "metrics"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 5, 1, 1, "part-of", "", false, false], [4, 5, 17, 17, "related-to", "finds", false, false], [4, 5, 19, 21, "related-to", "finds", false, false], [4, 5, 38, 39, "related-to", "", false, false], [7, 7, 4, 5, "named", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "statistics", ",", "the", "expectation", "-maximisation", "(", "EM", ")", "algorithm", "is", "an", "iterative", "method", "for", "finding", "maximum", "likelihood", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "estimates", "of", "parameters", "in", "statistical", "models", ",", "where", "the", "model", "depends", "on", "unobserved", "latent", "variables", "."], "sentence-detokenized": "In statistics, the expectation-maximisation (EM) algorithm is an iterative method for finding maximum likelihood or maximum a posteriori (MAP) estimates of parameters in statistical models, where the model depends on unobserved latent variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 30], [30, 43], [44, 45], [45, 47], [47, 48], [49, 58], [59, 61], [62, 64], [65, 74], [75, 81], [82, 85], [86, 93], [94, 101], [102, 112], [113, 115], [116, 123], [124, 125], [126, 136], [137, 138], [138, 141], [141, 142], [143, 152], [153, 155], [156, 166], [167, 169], [170, 181], [182, 188], [188, 189], [190, 195], [196, 199], [200, 205], [206, 213], [214, 216], [217, 227], [228, 234], [235, 244], [244, 245]]}
{"doc_key": "ai-test-79", "ner": [[7, 8, "metrics"], [10, 10, "metrics"], [14, 16, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 7, 8, "named", "", false, false], [18, 18, 14, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Similarly", ",", "experimenters", "sometimes", "report", "the", "FALSE", "positivity", "rate", "(", "FPR", ")", "and", "the", "FALSE", "negativity", "rate", "(", "FNR", ")", "."], "sentence-detokenized": "Similarly, experimenters sometimes report the FALSE positivity rate (FPR) and the FALSE negativity rate (FNR).", "token2charspan": [[0, 9], [9, 10], [11, 24], [25, 34], [35, 41], [42, 45], [46, 51], [52, 62], [63, 67], [68, 69], [69, 72], [72, 73], [74, 77], [78, 81], [82, 87], [88, 98], [99, 103], [104, 105], [105, 108], [108, 109], [109, 110]]}
{"doc_key": "ai-test-80", "ner": [[6, 11, "metrics"], [14, 14, "field"], [17, 18, "metrics"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 14, 6, 11, "usage", "", false, false], [21, 22, 17, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "concept", "is", "similar", "to", "the", "signal", "-", "to", "-", "noise", "ratio", "used", "in", "science", "and", "the", "confusion", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "The concept is similar to the signal-to-noise ratio used in science and the confusion matrix used in artificial intelligence.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 25], [26, 29], [30, 36], [36, 37], [37, 39], [39, 40], [40, 45], [46, 51], [52, 56], [57, 59], [60, 67], [68, 71], [72, 75], [76, 85], [86, 92], [93, 97], [98, 100], [101, 111], [112, 124], [124, 125]]}
{"doc_key": "ai-test-81", "ner": [[5, 6, "field"], [11, 12, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [31, 34, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 11, 12, "general-affiliation", "", false, false], [5, 6, 18, 19, "general-affiliation", "", false, false], [5, 6, 21, 22, "general-affiliation", "", false, false], [31, 34, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Code", "of", "Ethics", "on", "Human", "Augmentation", ",", "originally", "introduced", "by", "Steve", "Mann", "in", "2004", "and", "refined", "with", "Ray", "Kurzweil", "and", "Marvin", "Minsky", "in", "2013", ",", "was", "finally", "ratified", "at", "the", "Virtual", "Reality", "Toronto", "conference", "on", "25", "June", "2017", "."], "sentence-detokenized": "The Code of Ethics on Human Augmentation, originally introduced by Steve Mann in 2004 and refined with Ray Kurzweil and Marvin Minsky in 2013, was finally ratified at the Virtual Reality Toronto conference on 25 June 2017.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 18], [19, 21], [22, 27], [28, 40], [40, 41], [42, 52], [53, 63], [64, 66], [67, 72], [73, 77], [78, 80], [81, 85], [86, 89], [90, 97], [98, 102], [103, 106], [107, 115], [116, 119], [120, 126], [127, 133], [134, 136], [137, 141], [141, 142], [143, 146], [147, 154], [155, 163], [164, 166], [167, 170], [171, 178], [179, 186], [187, 194], [195, 205], [206, 208], [209, 211], [212, 216], [217, 221], [221, 222]]}
{"doc_key": "ai-test-82", "ner": [[3, 5, "person"], [11, 13, "organisation"], [19, 20, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 11, 13, "role", "directed_for", false, false], [3, 5, 19, 20, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", ",", "Walter", "R.", "Booth", "directed", "10", "films", "for", "the", "U.K", ".", "Kinoplastikon", ",", "presumably", "in", "collaboration", "with", "Cecil", "Hepworth", "."], "sentence-detokenized": "In 1913, Walter R. Booth directed 10 films for the U.K. Kinoplastikon, presumably in collaboration with Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 18], [19, 24], [25, 33], [34, 36], [37, 42], [43, 46], [47, 50], [51, 54], [54, 55], [56, 69], [69, 70], [71, 81], [82, 84], [85, 98], [99, 103], [104, 109], [110, 118], [118, 119]]}
{"doc_key": "ai-test-83", "ner": [[16, 16, "location"], [13, 14, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 16, 16, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "new", "robot", "was", "presented", "in", "1961", "at", "a", "trade", "fair", "at", "the", "Cow", "Palace", "in", "Chicago", "."], "sentence-detokenized": "The new robot was presented in 1961 at a trade fair at the Cow Palace in Chicago.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 17], [18, 27], [28, 30], [31, 35], [36, 38], [39, 40], [41, 46], [47, 51], [52, 54], [55, 58], [59, 62], [63, 69], [70, 72], [73, 80], [80, 81]]}
{"doc_key": "ai-test-84", "ner": [[2, 2, "product"], [6, 7, "task"], [10, 12, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 6, 7, "usage", "", false, false], [2, 2, 10, 12, "usage", "", false, false], [2, 2, 15, 16, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["While", "some", "chatbot", "applications", "use", "extensive", "word", "classification", "processes", ",", "natural", "language", "processing", "and", "sophisticated", "artificial", "intelligence", ",", "others", "merely", "scan", "generic", "keywords", "and", "generate", "responses", "using", "common", "phrases", "obtained", "from", "an", "associated", "library", "or", "database", "."], "sentence-detokenized": "While some chatbot applications use extensive word classification processes, natural language processing and sophisticated artificial intelligence, others merely scan generic keywords and generate responses using common phrases obtained from an associated library or database.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 31], [32, 35], [36, 45], [46, 50], [51, 65], [66, 75], [75, 76], [77, 84], [85, 93], [94, 104], [105, 108], [109, 122], [123, 133], [134, 146], [146, 147], [148, 154], [155, 161], [162, 166], [167, 174], [175, 183], [184, 187], [188, 196], [197, 206], [207, 212], [213, 219], [220, 227], [228, 236], [237, 241], [242, 244], [245, 255], [256, 263], [264, 266], [267, 275], [275, 276]]}
{"doc_key": "ai-test-85", "ner": [[1, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "WaveNet", "model", "proposed", "in", "2016", "performs", "very", "well", "on", "speech", "quality", "."], "sentence-detokenized": "The WaveNet model proposed in 2016 performs very well on speech quality.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 43], [44, 48], [49, 53], [54, 56], [57, 63], [64, 71], [71, 72]]}
{"doc_key": "ai-test-86", "ner": [[4, 4, "product"], [6, 7, "misc"], [9, 10, "misc"], [12, 13, "misc"], [15, 18, "misc"], [20, 22, "organisation"], [24, 24, "organisation"], [26, 29, "organisation"], [31, 31, "organisation"], [33, 36, "organisation"], [38, 39, "organisation"], [41, 43, "organisation"], [45, 47, "organisation"], [50, 50, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 4, 6, 7, "general-affiliation", "", false, false], [4, 4, 9, 10, "general-affiliation", "", false, false], [4, 4, 12, 13, "general-affiliation", "", false, false], [4, 4, 15, 18, "general-affiliation", "", false, false], [20, 22, 4, 4, "usage", "", false, false], [24, 24, 4, 4, "usage", "", false, false], [26, 29, 4, 4, "usage", "", false, false], [31, 31, 4, 4, "usage", "", false, false], [33, 36, 4, 4, "usage", "", false, false], [38, 39, 4, 4, "usage", "", false, false], [41, 43, 4, 4, "usage", "", false, false], [45, 47, 4, 4, "usage", "", false, false], [50, 50, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organisations", "known", "to", "use", "ALE", "for", "emergency", "management", ",", "disaster", "relief", ",", "routine", "communication", "or", "response", "to", "extraordinary", "situations", ":", "American", "Red", "Cross", ",", "FEMA", ",", "Disaster", "Medical", "Assistance", "Teams", ",", "NATO", ",", "Federal", "Bureau", "of", "Investigation", ",", "United", "Nations", ",", "AT", "&", "T", ",", "Civil", "Air", "Patrol", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organisations known to use ALE for emergency management, disaster relief, routine communication or response to extraordinary situations: American Red Cross, FEMA, Disaster Medical Assistance Teams, NATO, Federal Bureau of Investigation, United Nations, AT & T, Civil Air Patrol, (ARES).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 30], [31, 34], [35, 44], [45, 55], [55, 56], [57, 65], [66, 72], [72, 73], [74, 81], [82, 95], [96, 98], [99, 107], [108, 110], [111, 124], [125, 135], [135, 136], [137, 145], [146, 149], [150, 155], [155, 156], [157, 161], [161, 162], [163, 171], [172, 179], [180, 190], [191, 196], [196, 197], [198, 202], [202, 203], [204, 211], [212, 218], [219, 221], [222, 235], [235, 236], [237, 243], [244, 251], [251, 252], [253, 255], [256, 257], [258, 259], [259, 260], [261, 266], [267, 270], [271, 277], [277, 278], [279, 280], [280, 284], [284, 285], [285, 286]]}
{"doc_key": "ai-test-87", "ner": [[4, 7, "algorithm"], [18, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "case", ",", "Kronecker", "'s", "delta", "is", "used", "for", "simplicity", "(", "cf", ".", "the", "derivative", "of", "a", "sigmoid", "function", ",", "expressed", "via", "the", "function", "itself", ")", "."], "sentence-detokenized": "In this case, Kronecker's delta is used for simplicity (cf. the derivative of a sigmoid function, expressed via the function itself).", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 23], [23, 25], [26, 31], [32, 34], [35, 39], [40, 43], [44, 54], [55, 56], [56, 58], [58, 59], [60, 63], [64, 74], [75, 77], [78, 79], [80, 87], [88, 96], [96, 97], [98, 107], [108, 111], [112, 115], [116, 124], [125, 131], [131, 132], [132, 133]]}
{"doc_key": "ai-test-88", "ner": [[11, 12, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "theory", "is", "based", "on", "philosophical", "foundations", "and", "was", "founded", "by", "Ray", "Solomonoff", "around", "1960", ".", "Samuel", "Rathmanner", "and", "Marcus", "Hutter", "."], "sentence-detokenized": "The theory is based on philosophical foundations and was founded by Ray Solomonoff around 1960. Samuel Rathmanner and Marcus Hutter.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 36], [37, 48], [49, 52], [53, 56], [57, 64], [65, 67], [68, 71], [72, 82], [83, 89], [90, 94], [94, 95], [96, 102], [103, 113], [114, 117], [118, 124], [125, 131], [131, 132]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [11, 12, "misc"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 12, "type-of", "", false, false], [0, 0, 15, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "a", "freely", "available", "database", ",", "originally", "conceived", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "has", "been", "expanded", "by", "adding", "definitions", "and", "is", "now", "also", "seen", "as", "a", "dictionary", "."], "sentence-detokenized": "WordNet, a freely available database, originally conceived as a semantic network based on psycholinguistic principles, has been expanded by adding definitions and is now also seen as a dictionary.", "token2charspan": [[0, 7], [7, 8], [9, 10], [11, 17], [18, 27], [28, 36], [36, 37], [38, 48], [49, 58], [59, 61], [62, 63], [64, 72], [73, 80], [81, 86], [87, 89], [90, 106], [107, 117], [117, 118], [119, 122], [123, 127], [128, 136], [137, 139], [140, 146], [147, 158], [159, 162], [163, 165], [166, 169], [170, 174], [175, 179], [180, 182], [183, 184], [185, 195], [195, 196]]}
{"doc_key": "ai-test-90", "ner": [[5, 6, "field"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Advances", "in", "the", "field", "of", "computational", "imaging", "research", "are", "presented", "in", "various", "venues", ",", "including", "SIGGRAPH", "and", "Congress", "publications", "."], "sentence-detokenized": "Advances in the field of computational imaging research are presented in various venues, including SIGGRAPH and Congress publications.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 21], [22, 24], [25, 38], [39, 46], [47, 55], [56, 59], [60, 69], [70, 72], [73, 80], [81, 87], [87, 88], [89, 98], [99, 107], [108, 111], [112, 120], [121, 133], [133, 134]]}
{"doc_key": "ai-test-91", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "considered", "as", "two", "distinct", "problems", ":", "binary", "classification", "and", "multiclass", "classification", "."], "sentence-detokenized": "Classification can be considered as two distinct problems: binary classification and multiclass classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 57], [57, 58], [59, 65], [66, 80], [81, 84], [85, 95], [96, 110], [110, 111]]}
{"doc_key": "ai-test-92", "ner": [[11, 11, "algorithm"], [16, 17, "algorithm"], [20, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 17, 11, 11, "type-of", "", false, false], [20, 20, 16, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Advanced", "gene", "finders", "for", "prokaryotic", "and", "eukaryotic", "genomes", "typically", "use", "complex", "probabilistic", "models", ",", "such", "as", "hidden", "Markov", "models", "(", "HMMs", ")", ",", "to", "combine", "information", "from", "a", "number", "of", "different", "signal", "and", "content", "measures", "."], "sentence-detokenized": "Advanced gene finders for prokaryotic and eukaryotic genomes typically use complex probabilistic models, such as hidden Markov models (HMMs), to combine information from a number of different signal and content measures.", "token2charspan": [[0, 8], [9, 13], [14, 21], [22, 25], [26, 37], [38, 41], [42, 52], [53, 60], [61, 70], [71, 74], [75, 82], [83, 96], [97, 103], [103, 104], [105, 109], [110, 112], [113, 119], [120, 126], [127, 133], [134, 135], [135, 139], [139, 140], [140, 141], [142, 144], [145, 152], [153, 164], [165, 169], [170, 171], [172, 178], [179, 181], [182, 191], [192, 198], [199, 202], [203, 210], [211, 219], [219, 220]]}
{"doc_key": "ai-test-93", "ner": [[0, 0, "misc"], [3, 3, "misc"], [9, 10, "field"], [13, 14, "algorithm"], [17, 18, "algorithm"], [21, 21, "algorithm"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 9, 10, "part-of", "", false, false], [0, 0, 13, 14, "usage", "", false, false], [3, 3, 0, 0, "named", "", false, false], [17, 18, 0, 0, "origin", "", true, false], [21, 21, 17, 18, "named", "", false, false], [31, 32, 0, 0, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Neuroevolution", ",", "or", "neuroevolution", ",", "is", "a", "form", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "generate", "artificial", "neural", "networks", "(", "ANNs", ")", ",", "parameters", ",", "topology", "and", "rules", ".", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuroevolution, or neuroevolution, is a form of artificial intelligence that uses evolutionary algorithms to generate artificial neural networks (ANNs), parameters, topology and rules. and evolutionary robotics.", "token2charspan": [[0, 14], [14, 15], [16, 18], [19, 33], [33, 34], [35, 37], [38, 39], [40, 44], [45, 47], [48, 58], [59, 71], [72, 76], [77, 81], [82, 94], [95, 105], [106, 108], [109, 117], [118, 128], [129, 135], [136, 144], [145, 146], [146, 150], [150, 151], [151, 152], [153, 163], [163, 164], [165, 173], [174, 177], [178, 183], [183, 184], [185, 188], [189, 201], [202, 210], [210, 211]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [6, 6, "metrics"], [8, 8, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "IBM", "proposed", "and", "implemented", "the", "BLEU", "system", "Papineni", "et", "al", "."], "sentence-detokenized": "Since IBM proposed and implemented the BLEU system Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 34], [35, 38], [39, 43], [44, 50], [51, 59], [60, 62], [63, 65], [65, 66]]}
{"doc_key": "ai-test-95", "ner": [[10, 16, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 18, 10, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "experts", "attended", "a", "conference", "organised", "by", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "to", "discuss", "whether", "computers", "and", "robots", "might", "be", "able", "to", "acquire", "autonomy", "and", "how", "much", "of", "a", "threat", "or", "danger", "these", "capabilities", "might", "pose", "."], "sentence-detokenized": "In 2009, experts attended a conference organised by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether computers and robots might be able to acquire autonomy and how much of a threat or danger these capabilities might pose.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 25], [26, 27], [28, 38], [39, 48], [49, 51], [52, 55], [56, 67], [68, 71], [72, 75], [76, 87], [88, 90], [91, 101], [102, 114], [115, 116], [116, 120], [120, 121], [122, 124], [125, 132], [133, 140], [141, 150], [151, 154], [155, 161], [162, 167], [168, 170], [171, 175], [176, 178], [179, 186], [187, 195], [196, 199], [200, 203], [204, 208], [209, 211], [212, 213], [214, 220], [221, 223], [224, 230], [231, 236], [237, 249], [250, 255], [256, 260], [260, 261]]}
{"doc_key": "ai-test-96", "ner": [[27, 28, "researcher"], [30, 31, "researcher"], [33, 38, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[33, 38, 27, 28, "artifact", "", false, false], [33, 38, 30, 31, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["After", "boosting", ",", "a", "classifier", "built", "from", "200", "features", "could", "produce", "a", "detection", "rate", "of", "95", "%", "with", "a", "positivity", "rate", "^", "{", "-", "5", "}", "/", "P.", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "After boosting, a classifier built from 200 features could produce a detection rate of 95% with a positivity rate ^ {-5} / P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 17], [18, 28], [29, 34], [35, 39], [40, 43], [44, 52], [53, 58], [59, 66], [67, 68], [69, 78], [79, 83], [84, 86], [87, 89], [89, 90], [91, 95], [96, 97], [98, 108], [109, 113], [114, 115], [116, 117], [117, 118], [118, 119], [119, 120], [121, 122], [123, 125], [126, 131], [131, 132], [133, 135], [136, 141], [141, 142], [143, 149], [150, 154], [154, 155], [155, 159], [160, 166], [167, 176], [176, 177], [178, 182], [182, 183]]}
{"doc_key": "ai-test-97", "ner": [[6, 6, "programlang"], [9, 9, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "site", "was", "originally", "based", "on", "Perl", ",", "but", "IMDb", "no", "longer", "discloses", "which", "software", "it", "uses", "for", "security", "reasons", "."], "sentence-detokenized": "The site was originally based on Perl, but IMDb no longer discloses which software it uses for security reasons.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 23], [24, 29], [30, 32], [33, 37], [37, 38], [39, 42], [43, 47], [48, 50], [51, 57], [58, 67], [68, 73], [74, 82], [83, 85], [86, 90], [91, 94], [95, 103], [104, 111], [111, 112]]}
{"doc_key": "ai-test-98", "ner": [[7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "start", "-", "up", "was", "founded", "by", "Demis", "Hassabis", ",", "Shane", "Legg", "and", "Mustafa", "Suleyman", "in", "2010", "."], "sentence-detokenized": "The start-up was founded by Demis Hassabis, Shane Legg and Mustafa Suleyman in 2010.", "token2charspan": [[0, 3], [4, 9], [9, 10], [10, 12], [13, 16], [17, 24], [25, 27], [28, 33], [34, 42], [42, 43], [44, 49], [50, 54], [55, 58], [59, 66], [67, 75], [76, 78], [79, 83], [83, 84]]}
{"doc_key": "ai-test-99", "ner": [[3, 4, "misc"], [7, 9, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 3, 4, "type-of", "", false, false], [24, 25, 3, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "widely", "used", "loss", "functions", "are", "the", "mean", "square", "error", ",", "mathL", "(", "a", ")", "=", "a", "^", "2", "/", "math", ",", "and", "the", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Two widely used loss functions are the mean square error, mathL (a) = a ^ 2 / math, and the absolute loss, mathL (a) = | a | / math.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 20], [21, 30], [31, 34], [35, 38], [39, 43], [44, 50], [51, 56], [56, 57], [58, 63], [64, 65], [65, 66], [66, 67], [68, 69], [70, 71], [72, 73], [74, 75], [76, 77], [78, 82], [82, 83], [84, 87], [88, 91], [92, 100], [101, 105], [105, 106], [107, 112], [113, 114], [114, 115], [115, 116], [117, 118], [119, 120], [121, 122], [123, 124], [125, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-100", "ner": [[0, 5, "algorithm"], [12, 14, "algorithm"], [16, 16, "algorithm"], [19, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 5, 12, 14, "type-of", "example_of", false, false], [12, 14, 19, 20, "related-to", "", false, false], [16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "soft", "-margin", "support", "vector", "machine", "described", "above", "is", "an", "example", "of", "empirical", "risk", "minimisation", "(", "ERM", ")", "for", "hinge", "loss", "."], "sentence-detokenized": "The soft-margin support vector machine described above is an example of empirical risk minimisation (ERM) for hinge loss.", "token2charspan": [[0, 3], [4, 8], [8, 15], [16, 23], [24, 30], [31, 38], [39, 48], [49, 54], [55, 57], [58, 60], [61, 68], [69, 71], [72, 81], [82, 86], [87, 99], [100, 101], [101, 104], [104, 105], [106, 109], [110, 115], [116, 120], [120, 121]]}
{"doc_key": "ai-test-101", "ner": [[1, 4, "field"], [7, 8, "task"], [10, 12, "task"], [21, 21, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 12, 1, 4, "origin", "", false, false], [10, 12, 7, 8, "type-of", "", false, false], [21, 21, 10, 12, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "deep", "learning", "-", "based", "approach", "to", "machine", "translation", ",", "neural", "machine", "translation", "has", "made", "rapid", "progress", "in", "recent", "years", "and", "Google", "has", "announced", "that", "its", "translation", "services", "now", "use", "this", "technology", "to", "replace", "previous", "statistical", "methods", "."], "sentence-detokenized": "A deep learning-based approach to machine translation, neural machine translation has made rapid progress in recent years and Google has announced that its translation services now use this technology to replace previous statistical methods.", "token2charspan": [[0, 1], [2, 6], [7, 15], [15, 16], [16, 21], [22, 30], [31, 33], [34, 41], [42, 53], [53, 54], [55, 61], [62, 69], [70, 81], [82, 85], [86, 90], [91, 96], [97, 105], [106, 108], [109, 115], [116, 121], [122, 125], [126, 132], [133, 136], [137, 146], [147, 151], [152, 155], [156, 167], [168, 176], [177, 180], [181, 184], [185, 189], [190, 200], [201, 203], [204, 211], [212, 220], [221, 232], [233, 240], [240, 241]]}
{"doc_key": "ai-test-102", "ner": [[14, 14, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "tends", "to", "produce", "large", "performance", "gains", "when", "working", "with", "large", "corpora", "such", "as", "WordNet", "."], "sentence-detokenized": "This tends to produce large performance gains when working with large corpora such as WordNet.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 21], [22, 27], [28, 39], [40, 45], [46, 50], [51, 58], [59, 63], [64, 69], [70, 77], [78, 82], [83, 85], [86, 93], [93, 94]]}
{"doc_key": "ai-test-103", "ner": [[0, 1, "task"], [5, 5, "field"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 17, 19, "part-of", "", false, false], [17, 19, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Face", "detection", "is", "used", "in", "biometrics", ",", "often", "as", "part", "of", "(", "or", "together", "with", ")", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Face detection is used in biometrics, often as part of (or together with) a facial recognition system.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 22], [23, 25], [26, 36], [36, 37], [38, 43], [44, 46], [47, 51], [52, 54], [55, 56], [56, 58], [59, 67], [68, 72], [72, 73], [74, 75], [76, 82], [83, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-104", "ner": [[2, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["trained", "by", "maximum", "likelihood", "estimation", "."], "sentence-detokenized": "trained by maximum likelihood estimation.", "token2charspan": [[0, 7], [8, 10], [11, 18], [19, 29], [30, 40], [40, 41]]}
{"doc_key": "ai-test-105", "ner": [[0, 3, "country"], [5, 9, "organisation"], [13, 13, "location"], [15, 15, "country"], [17, 20, "organisation"], [22, 22, "country"], [28, 28, "organisation"], [33, 37, "organisation"], [39, 39, "country"], [50, 53, "organisation"], [55, 55, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 9, 13, 13, "physical", "", false, false], [13, 13, 15, 15, "physical", "", false, false], [17, 20, 22, 22, "physical", "", false, false], [33, 37, 39, 39, "physical", "", false, false], [50, 53, 55, 55, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd", ".", "in", "Thailand", ";", "Komatsu", "(", "Shanghai", ")", "Ltd.", "in", "1996", "in", "Shanghai", ",", "China", ";", "Industrial", "Power", "Alliance", "Ltd.", "in", "Japan", ",", "a", "joint", "venture", "with", "Cummins", ",", "in", "1998", ";", "L", "&", "T-", "Komatsu", "Limited", "in", "India", "in", "1998", "(", "shares", "sold", "in", "2013", ")", ";", "and", "Komatsu", "Brasil", "International", "Ltda.", "in", "Brazil", "in", "1998", "."], "sentence-detokenized": "Ltd. in Thailand; Komatsu (Shanghai) Ltd. in 1996 in Shanghai, China; Industrial Power Alliance Ltd. in Japan, a joint venture with Cummins, in 1998; L & T-Komatsu Limited in India in 1998 (shares sold in 2013); and Komatsu Brasil International Ltda. in Brazil in 1998.", "token2charspan": [[0, 3], [3, 4], [5, 7], [8, 16], [16, 17], [18, 25], [26, 27], [27, 35], [35, 36], [37, 41], [42, 44], [45, 49], [50, 52], [53, 61], [61, 62], [63, 68], [68, 69], [70, 80], [81, 86], [87, 95], [96, 100], [101, 103], [104, 109], [109, 110], [111, 112], [113, 118], [119, 126], [127, 131], [132, 139], [139, 140], [141, 143], [144, 148], [148, 149], [150, 151], [152, 153], [154, 156], [156, 163], [164, 171], [172, 174], [175, 180], [181, 183], [184, 188], [189, 190], [190, 196], [197, 201], [202, 204], [205, 209], [209, 210], [210, 211], [212, 215], [216, 223], [224, 230], [231, 244], [245, 250], [251, 253], [254, 260], [261, 263], [264, 268], [268, 269]]}
{"doc_key": "ai-test-106", "ner": [[0, 1, "organisation"], [5, 9, "misc"], [12, 12, "misc"], [14, 15, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 15, 0, 1, "physical", "", false, false], [14, 15, 5, 9, "general-affiliation", "", false, false], [14, 15, 12, 12, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "dgp", "also", "occasionally", "hosts", "artists", "-", "in", "-", "residence", "(", "e.g.", "Oscar", "winner", "Chris", "Landreth", ")", "."], "sentence-detokenized": "The dgp also occasionally hosts artists-in-residence (e.g. Oscar winner Chris Landreth).", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 25], [26, 31], [32, 39], [39, 40], [40, 42], [42, 43], [43, 52], [53, 54], [54, 58], [59, 64], [65, 71], [72, 77], [78, 86], [86, 87], [87, 88]]}
{"doc_key": "ai-test-107", "ner": [[7, 9, "misc"], [13, 14, "misc"], [17, 20, "misc"], [24, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "currently", "comprises", "four", "sub-competitions", ":", "the", "RoboMaster", "Robotics", "Competition", ",", "the", "RoboMaster", "Technical", "Challenge", ",", "the", "ICRA", "RoboMaster", "AI", "Challenge", "and", "the", "new", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "It currently comprises four sub-competitions: the RoboMaster Robotics Competition, the RoboMaster Technical Challenge, the ICRA RoboMaster AI Challenge and the new RoboMaster Youth Tournament.", "token2charspan": [[0, 2], [3, 12], [13, 22], [23, 27], [28, 44], [44, 45], [46, 49], [50, 60], [61, 69], [70, 81], [81, 82], [83, 86], [87, 97], [98, 107], [108, 117], [117, 118], [119, 122], [123, 127], [128, 138], [139, 141], [142, 151], [152, 155], [156, 159], [160, 163], [164, 174], [175, 180], [181, 191], [191, 192]]}
{"doc_key": "ai-test-108", "ner": [[7, 8, "field"], [16, 18, "algorithm"], [22, 23, "algorithm"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 22, 23, "usage", "", false, false], [7, 8, 25, 26, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "the", "early", "2000s", ",", "the", "dominant", "speech", "processing", "strategy", "started", "to", "shift", "away", "from", "the", "hidden", "Markov", "model", "towards", "more", "modern", "neural", "networks", "and", "deep", "learning", "."], "sentence-detokenized": "In the early 2000s, the dominant speech processing strategy started to shift away from the hidden Markov model towards more modern neural networks and deep learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 18], [18, 19], [20, 23], [24, 32], [33, 39], [40, 50], [51, 59], [60, 67], [68, 70], [71, 76], [77, 81], [82, 86], [87, 90], [91, 97], [98, 104], [105, 110], [111, 118], [119, 123], [124, 130], [131, 137], [138, 146], [147, 150], [151, 155], [156, 164], [164, 165]]}
{"doc_key": "ai-test-109", "ner": [[9, 11, "misc"], [21, 25, "metrics"], [31, 32, "metrics"], [35, 37, "metrics"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[31, 32, 35, 37, "related-to", "equal", false, false]], "relations_mapping_to_source": [1], "sentence": ["Another", "equivalent", "expression", ",", "in", "the", "case", "of", "a", "binary", "target", "rate", ",", "is", "that", "the", "positive", "rate", "TRUE", "and", "the", "positive", "rate", "FALSE", "are", "equal", "(", "and", "thus", "the", "negative", "rate", "FALSE", "and", "the", "negative", "rate", "TRUE", "are", "equal", ")", "for", "each", "value", "of", "the", "sensitive", "characteristics", ":"], "sentence-detokenized": "Another equivalent expression, in the case of a binary target rate, is that the positive rate TRUE and the positive rate FALSE are equal (and thus the negative rate FALSE and the negative rate TRUE are equal) for each value of the sensitive characteristics:", "token2charspan": [[0, 7], [8, 18], [19, 29], [29, 30], [31, 33], [34, 37], [38, 42], [43, 45], [46, 47], [48, 54], [55, 61], [62, 66], [66, 67], [68, 70], [71, 75], [76, 79], [80, 88], [89, 93], [94, 98], [99, 102], [103, 106], [107, 115], [116, 120], [121, 126], [127, 130], [131, 136], [137, 138], [138, 141], [142, 146], [147, 150], [151, 159], [160, 164], [165, 170], [171, 174], [175, 178], [179, 187], [188, 192], [193, 197], [198, 201], [202, 207], [207, 208], [209, 212], [213, 217], [218, 223], [224, 226], [227, 230], [231, 240], [241, 256], [256, 257]]}
{"doc_key": "ai-test-110", "ner": [[1, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "MATLAB", "function", ","], "sentence-detokenized": "The MATLAB function,", "token2charspan": [[0, 3], [4, 10], [11, 19], [19, 20]]}
{"doc_key": "ai-test-111", "ner": [[1, 1, "product"], [7, 7, "misc"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 1, 1, "part-of", "", false, false], [16, 17, 1, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "articulated", "robot", "is", "a", "robot", "with", "rotating", "joints", "(", "e.g.", "a", "legged", "robot", "or", "an", "industrial", "robot", ")", "."], "sentence-detokenized": "An articulated robot is a robot with rotating joints (e.g. a legged robot or an industrial robot).", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 23], [24, 25], [26, 31], [32, 36], [37, 45], [46, 52], [53, 54], [54, 58], [59, 60], [61, 67], [68, 73], [74, 76], [77, 79], [80, 90], [91, 96], [96, 97], [97, 98]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [6, 6, "product"], [8, 9, "product"], [13, 13, "misc"], [22, 24, "product"], [29, 31, "misc"], [35, 35, "location"], [37, 37, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 13, 13, "general-affiliation", "nationality", false, false], [0, 0, 29, 31, "usage", "", false, false], [0, 0, 35, 35, "physical", "", false, false], [6, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [35, 35, 37, 37, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "also", "known", "as", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "an", "American", "music", "streaming", "and", "internet", "radio", "service", "with", "an", "automated", "recommendation", "system", ",", "operated", "by", "the", "Music", "Genome", "Project", "and", "based", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (also known as Pandora Media or Pandora Radio) is an American music streaming and internet radio service with an automated recommendation system, operated by the Music Genome Project and based in Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 30], [31, 36], [37, 39], [40, 47], [48, 53], [53, 54], [55, 57], [58, 60], [61, 69], [70, 75], [76, 85], [86, 89], [90, 98], [99, 104], [105, 112], [113, 117], [118, 120], [121, 130], [131, 145], [146, 152], [152, 153], [154, 162], [163, 165], [166, 169], [170, 175], [176, 182], [183, 190], [191, 194], [195, 200], [201, 203], [204, 211], [211, 212], [213, 223], [223, 224]]}
{"doc_key": "ai-test-113", "ner": [[11, 17, "organisation"], [19, 22, "organisation"], [27, 28, "conference"], [41, 41, "conference"], [43, 43, "conference"], [45, 45, "conference"], [47, 47, "conference"], [49, 49, "conference"], [51, 51, "conference"], [53, 53, "conference"], [55, 55, "conference"], [57, 57, "conference"], [59, 59, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "member", "of", "the", "board", "of", "directors", "of", "the", "International", "Machine", "Learning", "Society", ",", "served", "on", "the", "executive", "board", "of", "AAAI", ",", "was", "co-chair", "of", "ICML", "2011", "and", "has", "served", "as", "a", "senior", "board", "member", "for", "conferences", "such", "as", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", "and", "WWW", "."], "sentence-detokenized": "She is a member of the board of directors of the International Machine Learning Society, served on the executive board of AAAI, was co-chair of ICML 2011 and has served as a senior board member for conferences such as AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM and WWW.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 15], [16, 18], [19, 22], [23, 28], [29, 31], [32, 41], [42, 44], [45, 48], [49, 62], [63, 70], [71, 79], [80, 87], [87, 88], [89, 95], [96, 98], [99, 102], [103, 112], [113, 118], [119, 121], [122, 126], [126, 127], [128, 131], [132, 140], [141, 143], [144, 148], [149, 153], [154, 157], [158, 161], [162, 168], [169, 171], [172, 173], [174, 180], [181, 186], [187, 193], [194, 197], [198, 209], [210, 214], [215, 217], [218, 222], [222, 223], [224, 228], [228, 229], [230, 235], [235, 236], [237, 241], [241, 242], [243, 246], [246, 247], [248, 254], [254, 255], [256, 259], [259, 260], [261, 265], [265, 266], [267, 271], [272, 275], [276, 279], [279, 280]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [5, 10, "organisation"], [12, 12, "organisation"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 10, "role", "", false, false], [12, 12, 5, 10, "named", "", false, false], [16, 16, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "developed", "the", "Robocrane", ",", "in", "which", "the", "platform", "hangs", "from", "six", "cables", "instead", "of", "being", "supported", "by", "six", "jacks", "."], "sentence-detokenized": "James S. Albus of the National Institute of Standards and Technology (NIST) developed the Robocrane, in which the platform hangs from six cables instead of being supported by six jacks.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [74, 75], [76, 85], [86, 89], [90, 99], [99, 100], [101, 103], [104, 109], [110, 113], [114, 122], [123, 128], [129, 133], [134, 137], [138, 144], [145, 152], [153, 155], [156, 161], [162, 171], [172, 174], [175, 178], [179, 184], [184, 185]]}
{"doc_key": "ai-test-115", "ner": [[3, 6, "algorithm"], [9, 10, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 3, 6, "type-of", "", false, false], [13, 14, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "class", "of", "direct", "search", "algorithms", "are", "the", "various", "evolutionary", "algorithms", ",", "e.g.", "genetic", "algorithms", "."], "sentence-detokenized": "Another class of direct search algorithms are the various evolutionary algorithms, e.g. genetic algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 23], [24, 30], [31, 41], [42, 45], [46, 49], [50, 57], [58, 70], [71, 81], [81, 82], [83, 87], [88, 95], [96, 106], [106, 107]]}
{"doc_key": "ai-test-116", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 0, 0, "named", "", false, false], [6, 7, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "industrial", "robots", "and", "factory", "automation", "solutions", "."], "sentence-detokenized": "KUKA is a German manufacturer of industrial robots and factory automation solutions.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-117", "ner": [[4, 4, "misc"], [11, 12, "person"], [14, 20, "misc"], [22, 23, "person"], [25, 25, "misc"], [27, 28, "person"], [30, 31, "misc"], [33, 34, "person"], [36, 38, "misc"], [40, 43, "person"], [44, 47, "misc"], [49, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12], "relations": [[11, 12, 4, 4, "usage", "", false, false], [14, 20, 11, 12, "artifact", "", false, false], [22, 23, 4, 4, "usage", "", false, false], [25, 25, 22, 23, "artifact", "", false, false], [27, 28, 4, 4, "usage", "", false, false], [30, 31, 27, 28, "artifact", "", false, false], [33, 34, 4, 4, "usage", "", false, false], [36, 38, 33, 34, "artifact", "", false, false], [40, 43, 4, 4, "usage", "", false, false], [44, 47, 40, 43, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Other", "films", "shot", "with", "IMAX", "cameras", "between", "2016", "and", "2020", "were", "Zack", "Snyder", "'s", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", ",", "Clint", "Eastwood", "'s", "Sully", ",", "Damien", "Chazelle", "'s", "First", "Man", ",", "Patty", "Jenkins", "'", "Wonder", "Woman", "1984", ",", "Cary", "Joji", "Fukunaga", "'s", "No", "Time", "to", "Die", "and", "Joseph", "Kosinski", "'s", "Top", "Gun", ":", "Maverick", "."], "sentence-detokenized": "Other films shot with IMAX cameras between 2016 and 2020 were Zack Snyder's Batman v Superman: Dawn of Justice, Clint Eastwood's Sully, Damien Chazelle's First Man, Patty Jenkins' Wonder Woman 1984, Cary Joji Fukunaga's No Time to Die and Joseph Kosinski's Top Gun: Maverick.", "token2charspan": [[0, 5], [6, 11], [12, 16], [17, 21], [22, 26], [27, 34], [35, 42], [43, 47], [48, 51], [52, 56], [57, 61], [62, 66], [67, 73], [73, 75], [76, 82], [83, 84], [85, 93], [93, 94], [95, 99], [100, 102], [103, 110], [110, 111], [112, 117], [118, 126], [126, 128], [129, 134], [134, 135], [136, 142], [143, 151], [151, 153], [154, 159], [160, 163], [163, 164], [165, 170], [171, 178], [178, 179], [180, 186], [187, 192], [193, 197], [197, 198], [199, 203], [204, 208], [209, 217], [217, 219], [220, 222], [223, 227], [228, 230], [231, 234], [235, 238], [239, 245], [246, 254], [254, 256], [257, 260], [261, 264], [264, 265], [266, 274], [274, 275]]}
{"doc_key": "ai-test-118", "ner": [[0, 2, "misc"], [9, 11, "organisation"], [13, 13, "organisation"], [26, 26, "misc"], [33, 34, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 26, 26, "named", "", false, false], [9, 11, 0, 2, "usage", "", false, false], [9, 11, 33, 34, "physical", "", false, false], [13, 13, 9, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "MICR", "E13B", "character", "test", "was", "shown", "to", "the", "American", "Bankers", "Association", "(", "ABA", ")", "in", "July", "1956", ",", "which", "adopted", "it", "in", "1958", "as", "the", "MICR", "standard", "for", "negotiable", "documents", "in", "the", "United", "States", "."], "sentence-detokenized": "The MICR E13B character test was shown to the American Bankers Association (ABA) in July 1956, which adopted it in 1958 as the MICR standard for negotiable documents in the United States.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 23], [24, 28], [29, 32], [33, 38], [39, 41], [42, 45], [46, 54], [55, 62], [63, 74], [75, 76], [76, 79], [79, 80], [81, 83], [84, 88], [89, 93], [93, 94], [95, 100], [101, 108], [109, 111], [112, 114], [115, 119], [120, 122], [123, 126], [127, 131], [132, 140], [141, 144], [145, 155], [156, 165], [166, 168], [169, 172], [173, 179], [180, 186], [186, 187]]}
{"doc_key": "ai-test-119", "ner": [[0, 2, "misc"], [15, 16, "field"], [19, 20, "field"], [23, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 16, 0, 2, "usage", "", false, false], [19, 20, 15, 16, "part-of", "", false, false], [23, 23, 0, 2, "usage", "", false, false], [25, 26, 0, 2, "usage", "", false, false], [28, 28, 0, 2, "usage", "", false, false], [30, 30, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "are", "widely", "applied", "to", "numerous", "difficult", "computational", "problems", ",", "including", "problems", "in", "computer", "science", "(", "especially", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms are widely applied to numerous difficult computational problems, including problems in computer science (especially artificial intelligence), mathematics, operations research, engineering and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 27], [28, 34], [35, 42], [43, 45], [46, 54], [55, 64], [65, 78], [79, 87], [87, 88], [89, 98], [99, 107], [108, 110], [111, 119], [120, 127], [128, 129], [129, 139], [140, 150], [151, 163], [163, 164], [164, 165], [166, 177], [177, 178], [179, 189], [190, 198], [198, 199], [200, 211], [212, 215], [216, 230], [230, 231]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [8, 8, "location"], [10, 10, "country"], [14, 14, "country"], [22, 23, "algorithm"], [25, 25, "algorithm"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 8, 8, "physical", "", false, false], [0, 1, 14, 14, "general-affiliation", "nationality", false, false], [0, 1, 22, 23, "general-affiliation", "topic_of_study", false, false], [0, 1, 25, 25, "general-affiliation", "topic_of_study", false, false], [8, 8, 10, 10, "physical", "", false, false], [25, 25, 27, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "born", "3", "September", "1947", "in", "Wallersdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "has", "studied", "the", "use", "of", "bounded", "rationality", "and", "heuristics", "in", "decision", "-", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (born 3 September 1947 in Wallersdorf, Germany) is a German psychologist who has studied the use of bounded rationality and heuristics in decision-making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 21], [22, 23], [24, 33], [34, 38], [39, 41], [42, 53], [53, 54], [55, 62], [62, 63], [64, 66], [67, 68], [69, 75], [76, 88], [89, 92], [93, 96], [97, 104], [105, 108], [109, 112], [113, 115], [116, 123], [124, 135], [136, 139], [140, 150], [151, 153], [154, 162], [162, 163], [163, 169], [169, 170]]}
{"doc_key": "ai-test-121", "ner": [[3, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["to", "minimise", "the", "mean", "square", "error", "."], "sentence-detokenized": "to minimise the mean square error.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [21, 27], [28, 33], [33, 34]]}
{"doc_key": "ai-test-122", "ner": [[12, 13, "misc"], [16, 17, "organisation"], [31, 33, "field"], [50, 51, "misc"], [60, 62, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 16, 17, "origin", "", false, false], [50, 51, 60, 62, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["But", "even", "an", "official", "language", "with", "a", "regulating", "academy", ",", "such", "as", "standard", "French", "with", "the", "Acad\u00e9mie", "fran\u00e7aise", ",", "is", "classified", "as", "a", "natural", "language", "(", "e.g.", "in", "the", "field", "of", "natural", "language", "processing", ")", ",", "because", "its", "prescriptive", "points", "make", "it", "neither", "constructed", "enough", "to", "be", "classified", "as", "a", "constructed", "language", "nor", "controlled", "enough", "to", "be", "classified", "as", "a", "controlled", "natural", "language", "."], "sentence-detokenized": "But even an official language with a regulating academy, such as standard French with the Acad\u00e9mie fran\u00e7aise, is classified as a natural language (e.g. in the field of natural language processing), because its prescriptive points make it neither constructed enough to be classified as a constructed language nor controlled enough to be classified as a controlled natural language.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 20], [21, 29], [30, 34], [35, 36], [37, 47], [48, 55], [55, 56], [57, 61], [62, 64], [65, 73], [74, 80], [81, 85], [86, 89], [90, 98], [99, 108], [108, 109], [110, 112], [113, 123], [124, 126], [127, 128], [129, 136], [137, 145], [146, 147], [147, 151], [152, 154], [155, 158], [159, 164], [165, 167], [168, 175], [176, 184], [185, 195], [195, 196], [196, 197], [198, 205], [206, 209], [210, 222], [223, 229], [230, 234], [235, 237], [238, 245], [246, 257], [258, 264], [265, 267], [268, 270], [271, 281], [282, 284], [285, 286], [287, 298], [299, 307], [308, 311], [312, 322], [323, 329], [330, 332], [333, 335], [336, 346], [347, 349], [350, 351], [352, 362], [363, 370], [371, 379], [379, 380]]}
{"doc_key": "ai-test-123", "ner": [[14, 14, "metrics"], [16, 17, "metrics"], [19, 19, "metrics"], [38, 39, "metrics"], [41, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 16, 17, "named", "", false, false], [41, 41, 38, 39, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "a", "number", "of", "other", "metrics", ",", "the", "simplest", "of", "which", "is", "the", "accuracy", "or", "corrected", "fraction", "(", "FC", ")", ",", "which", "measures", "the", "fraction", "of", "all", "instances", "that", "are", "correctly", "categorised", ";", "the", "complement", "is", "the", "incorrect", "fraction", "(", "FiC", ")", "."], "sentence-detokenized": "There are a number of other metrics, the simplest of which is the accuracy or corrected fraction (FC), which measures the fraction of all instances that are correctly categorised; the complement is the incorrect fraction (FiC).", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 18], [19, 21], [22, 27], [28, 35], [35, 36], [37, 40], [41, 49], [50, 52], [53, 58], [59, 61], [62, 65], [66, 74], [75, 77], [78, 87], [88, 96], [97, 98], [98, 100], [100, 101], [101, 102], [103, 108], [109, 117], [118, 121], [122, 130], [131, 133], [134, 137], [138, 147], [148, 152], [153, 156], [157, 166], [167, 178], [178, 179], [180, 183], [184, 194], [195, 197], [198, 201], [202, 211], [212, 220], [221, 222], [222, 225], [225, 226], [226, 227]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [6, 9, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 9, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "became", "a", "Fellow", "of", "the", "Association", "for", "Computational", "Linguistics", "in", "2016", "."], "sentence-detokenized": "Cardie became a Fellow of the Association for Computational Linguistics in 2016.", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 59], [60, 71], [72, 74], [75, 79], [79, 80]]}
{"doc_key": "ai-test-125", "ner": [[12, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Learning", "the", "parameters", "math", "\\", "theta", "/", "math", "is", "usually", "done", "by", "learning", "the", "maximum", "likelihood", "for", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";\\", "theta", ")", "/", "math", "."], "sentence-detokenized": "Learning the parameters math\\ theta / math is usually done by learning the maximum likelihood for mathp (Y _ i | X _ i;\\ theta) / math.", "token2charspan": [[0, 8], [9, 12], [13, 23], [24, 28], [28, 29], [30, 35], [36, 37], [38, 42], [43, 45], [46, 53], [54, 58], [59, 61], [62, 70], [71, 74], [75, 82], [83, 93], [94, 97], [98, 103], [104, 105], [105, 106], [107, 108], [109, 110], [111, 112], [113, 114], [115, 116], [117, 118], [118, 120], [121, 126], [126, 127], [128, 129], [130, 134], [134, 135]]}
{"doc_key": "ai-test-126", "ner": [[0, 1, "task"], [3, 7, "algorithm"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 1, "usage", "", true, false], [9, 10, 3, 7, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cluster", "analysis", "and", "factoring", "of", "the", "non-negative", "matrix", "for", "descriptive", "extraction", "."], "sentence-detokenized": "Cluster analysis and factoring of the non-negative matrix for descriptive extraction.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 30], [31, 33], [34, 37], [38, 50], [51, 57], [58, 61], [62, 73], [74, 84], [84, 85]]}
{"doc_key": "ai-test-127", "ner": [[8, 9, "field"], [18, 20, "field"], [22, 23, "field"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[18, 20, 8, 9, "part-of", "", false, false], [22, 23, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [1, 3], "sentence": ["In", "the", "field", "of", "computer", "science", "and", "the", "information", "technologies", "it", "enables", ",", "the", "ability", "of", "computers", "to", "process", "natural", "language", "and", "machine", "learning", "has", "been", "a", "long", "-", "term", "challenge", "."], "sentence-detokenized": "In the field of computer science and the information technologies it enables, the ability of computers to process natural language and machine learning has been a long-term challenge.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 24], [25, 32], [33, 36], [37, 40], [41, 52], [53, 65], [66, 68], [69, 76], [76, 77], [78, 81], [82, 89], [90, 92], [93, 102], [103, 105], [106, 113], [114, 121], [122, 130], [131, 134], [135, 142], [143, 151], [152, 155], [156, 160], [161, 162], [163, 167], [167, 168], [168, 172], [173, 182], [182, 183]]}
{"doc_key": "ai-test-128", "ner": [[4, 6, "algorithm"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 10, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "The", "code", "for", "extracting", "Gabor", "features", "from", "images", "in", "MATLAB", "is", "available", "at"], "sentence-detokenized": "(The code for extracting Gabor features from images in MATLAB is available at", "token2charspan": [[0, 1], [1, 4], [5, 9], [10, 13], [14, 24], [25, 30], [31, 39], [40, 44], [45, 51], [52, 54], [55, 61], [62, 64], [65, 74], [75, 77]]}
{"doc_key": "ai-test-129", "ner": [[0, 0, "misc"], [17, 18, "algorithm"], [20, 20, "task"], [22, 22, "task"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 17, 18, "general-affiliation", "", false, false], [0, 0, 20, 20, "related-to", "solves_problem_of_type", false, false], [0, 0, 22, 22, "related-to", "solves_problem_of_type", false, false], [0, 0, 24, 25, "related-to", "solves_problem_of_type", false, false], [0, 0, 27, 28, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["NeuralExpert", "focuses", "the", "design", "specification", "on", "the", "type", "of", "problem", "the", "user", "wishes", "to", "solve", "with", "the", "neural", "network", "(", "classification", ",", "prediction", ",", "function", "approximation", "or", "cluster", "analysis", ")", "."], "sentence-detokenized": "NeuralExpert focuses the design specification on the type of problem the user wishes to solve with the neural network (classification, prediction, function approximation or cluster analysis).", "token2charspan": [[0, 12], [13, 20], [21, 24], [25, 31], [32, 45], [46, 48], [49, 52], [53, 57], [58, 60], [61, 68], [69, 72], [73, 77], [78, 84], [85, 87], [88, 93], [94, 98], [99, 102], [103, 109], [110, 117], [118, 119], [119, 133], [133, 134], [135, 145], [145, 146], [147, 155], [156, 169], [170, 172], [173, 180], [181, 189], [189, 190], [190, 191]]}
{"doc_key": "ai-test-130", "ner": [[2, 6, "misc"], [31, 33, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "size", "of", "the", "quantisation", "step", "(", "\u0394", ")", "is", "small", "compared", "to", "the", "variation", "of", "the", "signal", "to", "be", "quantised", ",", "it", "is", "relatively", "easy", "to", "demonstrate", "that", "the", "mean", "square", "error", "produced", "by", "this", "rounding", "operation", "will", "be", "approximately", "math", "\\", "Delta", "^", "2", "/", "12", "/", "math.math"], "sentence-detokenized": "When the size of the quantisation step (\u0394) is small compared to the variation of the signal to be quantised, it is relatively easy to demonstrate that the mean square error produced by this rounding operation will be approximately math\\ Delta ^ 2 / 12 / math.math", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 20], [21, 33], [34, 38], [39, 40], [40, 41], [41, 42], [43, 45], [46, 51], [52, 60], [61, 63], [64, 67], [68, 77], [78, 80], [81, 84], [85, 91], [92, 94], [95, 97], [98, 107], [107, 108], [109, 111], [112, 114], [115, 125], [126, 130], [131, 133], [134, 145], [146, 150], [151, 154], [155, 159], [160, 166], [167, 172], [173, 181], [182, 184], [185, 189], [190, 198], [199, 208], [209, 213], [214, 216], [217, 230], [231, 235], [235, 236], [237, 242], [243, 244], [245, 246], [247, 248], [249, 251], [252, 253], [254, 263]]}
{"doc_key": "ai-test-131", "ner": [[15, 15, "product"], [22, 25, "researcher"], [27, 28, "researcher"], [30, 32, "researcher"], [34, 35, "researcher"], [37, 39, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "construction", "of", "a", "rich", "lexicon", "with", "an", "adequate", "ontology", "requires", "significant", "effort", ",", "e.g.", "Wordnet", "'s", "lexicon", "took", "many", "years", ".", "G.", "A", ".", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "The construction of a rich lexicon with an adequate ontology requires significant effort, e.g. Wordnet's lexicon took many years. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 3], [4, 16], [17, 19], [20, 21], [22, 26], [27, 34], [35, 39], [40, 42], [43, 51], [52, 60], [61, 69], [70, 81], [82, 88], [88, 89], [90, 94], [95, 102], [102, 104], [105, 112], [113, 117], [118, 122], [123, 128], [128, 129], [130, 132], [133, 134], [134, 135], [136, 142], [142, 143], [144, 146], [147, 155], [155, 156], [157, 159], [160, 162], [163, 171], [171, 172], [173, 175], [176, 181], [181, 182], [183, 184], [184, 185], [186, 192], [192, 193]]}
{"doc_key": "ai-test-132", "ner": [[0, 0, "organisation"], [19, 21, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 21, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kawasaki", "'s", "portfolio", "also", "includes", "roofs", ",", "floors", "and", "other", "giant", "retractable", "structures", ";", "the", "retractable", "surface", "of", "the", "Sapporo", "Dome", "is", "one", "example", "."], "sentence-detokenized": "Kawasaki's portfolio also includes roofs, floors and other giant retractable structures; the retractable surface of the Sapporo Dome is one example.", "token2charspan": [[0, 8], [8, 10], [11, 20], [21, 25], [26, 34], [35, 40], [40, 41], [42, 48], [49, 52], [53, 58], [59, 64], [65, 76], [77, 87], [87, 88], [89, 92], [93, 104], [105, 112], [113, 115], [116, 119], [120, 127], [128, 132], [133, 135], [136, 139], [140, 147], [147, 148]]}
{"doc_key": "ai-test-133", "ner": [[0, 1, "metrics"], [5, 7, "metrics"], [9, 11, "metrics"], [17, 18, "metrics"], [40, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 17, 18, "related-to", "", false, false], [0, 1, 40, 40, "opposite", "alternative_to", false, false], [5, 7, 0, 1, "type-of", "", false, false], [9, 11, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa", "statistics", ",", "such", "as", "Fleiss", "'s", "kappa", "and", "Cohen", "'s", "kappa", ",", "are", "methods", "for", "calculating", "inter-rater", "reliability", "based", "on", "various", "assumptions", "about", "the", "marginal", "or", "prior", "distributions", ",", "and", "are", "increasingly", "used", "as", "chance", "-", "corrected", "alternatives", "to", "accuracy", "in", "other", "contexts", "."], "sentence-detokenized": "Kappa statistics, such as Fleiss's kappa and Cohen's kappa, are methods for calculating inter-rater reliability based on various assumptions about the marginal or prior distributions, and are increasingly used as chance-corrected alternatives to accuracy in other contexts.", "token2charspan": [[0, 5], [6, 16], [16, 17], [18, 22], [23, 25], [26, 32], [32, 34], [35, 40], [41, 44], [45, 50], [50, 52], [53, 58], [58, 59], [60, 63], [64, 71], [72, 75], [76, 87], [88, 99], [100, 111], [112, 117], [118, 120], [121, 128], [129, 140], [141, 146], [147, 150], [151, 159], [160, 162], [163, 168], [169, 182], [182, 183], [184, 187], [188, 191], [192, 204], [205, 209], [210, 212], [213, 219], [219, 220], [220, 229], [230, 242], [243, 245], [246, 254], [255, 257], [258, 263], [264, 272], [272, 273]]}
{"doc_key": "ai-test-134", "ner": [[3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 13, "researcher"], [17, 17, "researcher"], [27, 29, "algorithm"], [31, 34, "algorithm"], [36, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 4, 17, 17, "role", "student_of", false, false], [6, 7, 17, 17, "role", "student_of", false, false], [9, 10, 17, 17, "role", "student_of", false, false], [12, 13, 17, 17, "role", "student_of", false, false], [31, 34, 3, 4, "origin", "", false, false], [31, 34, 6, 7, "origin", "", false, false], [31, 34, 9, 10, "origin", "", false, false], [31, 34, 12, 13, "origin", "", false, false], [31, 34, 17, 17, "origin", "", false, false], [31, 34, 27, 29, "type-of", "", false, false], [36, 36, 31, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["With", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "and", "others", ",", "Schmidhuber", "has", "published", "increasingly", "sophisticated", "versions", "of", "a", "type", "of", "recurrent", "neural", "network", "called", "short", "-", "term", "memory", "(", "LSTM", ")", "."], "sentence-detokenized": "With his students Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves and others, Schmidhuber has published increasingly sophisticated versions of a type of recurrent neural network called short-term memory (LSTM).", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 22], [23, 33], [33, 34], [35, 40], [41, 45], [45, 46], [47, 51], [52, 59], [59, 60], [61, 65], [66, 72], [73, 76], [77, 83], [83, 84], [85, 96], [97, 100], [101, 110], [111, 123], [124, 137], [138, 146], [147, 149], [150, 151], [152, 156], [157, 159], [160, 169], [170, 176], [177, 184], [185, 191], [192, 197], [197, 198], [198, 202], [203, 209], [210, 211], [211, 215], [215, 216], [216, 217]]}
{"doc_key": "ai-test-135", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "The", "first", "KUKA", "LBR", "3", "Cobot", "is", "presented", "."], "sentence-detokenized": "2004 - The first KUKA LBR 3 Cobot is presented.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 21], [22, 25], [26, 27], [28, 33], [34, 36], [37, 46], [46, 47]]}
{"doc_key": "ai-test-136", "ner": [[11, 13, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "shallow", "approaches", "used", "to", "train", "and", "then", "disambiguate", "are", "the", "Naive", "Bayes", "classifier", "and", "decision", "trees", "."], "sentence-detokenized": "Two shallow approaches used to train and then disambiguate are the Naive Bayes classifier and decision trees.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 27], [28, 30], [31, 36], [37, 40], [41, 45], [46, 58], [59, 62], [63, 66], [67, 72], [73, 78], [79, 89], [90, 93], [94, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-test-137", "ner": [[5, 5, "misc"], [12, 13, "person"], [15, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 12, 13, "origin", "", false, false], [5, 5, 15, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "practical", "forms", "of", "photography", "were", "introduced", "in", "January", "1839", "by", "Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "The first practical forms of photography were introduced in January 1839 by Louis Daguerre and Henry Fox Talbot.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 25], [26, 28], [29, 40], [41, 45], [46, 56], [57, 59], [60, 67], [68, 72], [73, 75], [76, 81], [82, 90], [91, 94], [95, 100], [101, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-138", "ner": [[4, 4, "task"], [8, 9, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 17, 18, "part-of", "task_part_of_field", false, false], [8, 9, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "speech", "synthesis", ",", "combined", "with", "speech", "recognition", ",", "enables", "interaction", "with", "mobile", "devices", "via", "language", "processing", "interfaces", "."], "sentence-detokenized": "For example, speech synthesis, combined with speech recognition, enables interaction with mobile devices via language processing interfaces.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [29, 30], [31, 39], [40, 44], [45, 51], [52, 63], [63, 64], [65, 72], [73, 84], [85, 89], [90, 96], [97, 104], [105, 108], [109, 117], [118, 128], [129, 139], [139, 140]]}
{"doc_key": "ai-test-139", "ner": [[0, 0, "product"], [12, 12, "programlang"], [14, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 12, "general-affiliation", "", false, false], [0, 0, 14, 15, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Phidgets", "can", "be", "programmed", "using", "various", "software", "and", "programming", "languages", ",", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "Phidgets can be programmed using various software and programming languages, from Java to Microsoft Excel.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 26], [27, 32], [33, 40], [41, 49], [50, 53], [54, 65], [66, 75], [75, 76], [77, 81], [82, 86], [87, 89], [90, 99], [100, 105], [105, 106]]}
{"doc_key": "ai-test-140", "ner": [[2, 4, "field"], [9, 10, "researcher"], [13, 16, "misc"], [24, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 9, 10, "origin", "", false, false], [9, 10, 24, 25, "general-affiliation", "topic_of_study", false, false], [9, 10, 27, 28, "general-affiliation", "topic_of_study", false, false], [13, 16, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "machine", "learning", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "an", "American", "employee", "of", "IBM", "and", "a", "pioneer", "in", "the", "field", "of", "computer", "games", "and", "artificial", "intelligence", "."], "sentence-detokenized": "The term machine learning was coined in 1959 by Arthur Samuel, an American employee of IBM and a pioneer in the field of computer games and artificial intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 25], [26, 29], [30, 36], [37, 39], [40, 44], [45, 47], [48, 54], [55, 61], [61, 62], [63, 65], [66, 74], [75, 83], [84, 86], [87, 90], [91, 94], [95, 96], [97, 104], [105, 107], [108, 111], [112, 117], [118, 120], [121, 129], [130, 135], [136, 139], [140, 150], [151, 163], [163, 164]]}
{"doc_key": "ai-test-141", "ner": [[0, 1, "misc"], [2, 3, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Israeli", "poet", "David", "Avidan", ",", "fascinated", "by", "future", "technologies", "and", "their", "relationship", "to", "art", ",", "wanted", "to", "explore", "the", "use", "of", "computers", "for", "literary", "writing", "."], "sentence-detokenized": "Israeli poet David Avidan, fascinated by future technologies and their relationship to art, wanted to explore the use of computers for literary writing.", "token2charspan": [[0, 7], [8, 12], [13, 18], [19, 25], [25, 26], [27, 37], [38, 40], [41, 47], [48, 60], [61, 64], [65, 70], [71, 83], [84, 86], [87, 90], [90, 91], [92, 98], [99, 101], [102, 109], [110, 113], [114, 117], [118, 120], [121, 130], [131, 134], [135, 143], [144, 151], [151, 152]]}
{"doc_key": "ai-test-142", "ner": [[7, 8, "misc"], [10, 10, "organisation"], [17, 17, "location"], [29, 29, "location"], [31, 32, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 10, 7, 8, "part-of", "", false, false], [31, 32, 29, 29, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "as", "part", "of", "the", "GATEway", "project", ",", "Oxbotica", "trialled", "seven", "autonomous", "shuttle", "buses", "in", "Greenwich", ",", "navigating", "a", "two", "-", "mile", "route", "along", "the", "river", "near", "London", "'s", "O2", "Arena", ",", "on", "a", "route", "also", "used", "by", "pedestrians", "and", "cyclists", "."], "sentence-detokenized": "In 2017, as part of the GATEway project, Oxbotica trialled seven autonomous shuttle buses in Greenwich, navigating a two-mile route along the river near London's O2 Arena, on a route also used by pedestrians and cyclists.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 16], [17, 19], [20, 23], [24, 31], [32, 39], [39, 40], [41, 49], [50, 58], [59, 64], [65, 75], [76, 83], [84, 89], [90, 92], [93, 102], [102, 103], [104, 114], [115, 116], [117, 120], [120, 121], [121, 125], [126, 131], [132, 137], [138, 141], [142, 147], [148, 152], [153, 159], [159, 161], [162, 164], [165, 170], [170, 171], [172, 174], [175, 176], [177, 182], [183, 187], [188, 192], [193, 195], [196, 207], [208, 211], [212, 220], [220, 221]]}
{"doc_key": "ai-test-143", "ner": [[8, 9, "task"], [13, 14, "metrics"], [19, 20, "misc"], [26, 26, "metrics"], [28, 28, "metrics"], [31, 31, "metrics"], [32, 33, "metrics"], [35, 37, "metrics"], [40, 40, "metrics"], [42, 42, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[13, 14, 19, 20, "related-to", "is_a", false, false], [13, 14, 26, 26, "usage", "", false, false], [13, 14, 28, 28, "usage", "", false, false], [26, 26, 31, 31, "named", "same", false, false], [28, 28, 42, 42, "named", "same", false, false], [31, 31, 40, 40, "opposite", "", false, false], [31, 31, 42, 42, "opposite", "", false, false], [32, 33, 31, 31, "named", "", false, false], [35, 37, 31, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["An", "unrelated", "but", "commonly", "used", "combination", "of", "basic", "information", "retrieval", "statistics", "is", "the", "F", "score", ",", "which", "is", "a", "harmonic", "average", "(", "possibly", "weighted", ")", "of", "recall", "and", "precision", ",", "where", "recall", "=", "sensitivity", "=", "true", "positive", "rate", ",", "but", "specificity", "and", "precision", "are", "completely", "different", "measures", "."], "sentence-detokenized": "An unrelated but commonly used combination of basic information retrieval statistics is the F score, which is a harmonic average (possibly weighted) of recall and precision, where recall = sensitivity = true positive rate, but specificity and precision are completely different measures.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 25], [26, 30], [31, 42], [43, 45], [46, 51], [52, 63], [64, 73], [74, 84], [85, 87], [88, 91], [92, 93], [94, 99], [99, 100], [101, 106], [107, 109], [110, 111], [112, 120], [121, 128], [129, 130], [130, 138], [139, 147], [147, 148], [149, 151], [152, 158], [159, 162], [163, 172], [172, 173], [174, 179], [180, 186], [187, 188], [189, 200], [201, 202], [203, 207], [208, 216], [217, 221], [221, 222], [223, 226], [227, 238], [239, 242], [243, 252], [253, 256], [257, 267], [268, 277], [278, 286], [286, 287]]}
{"doc_key": "ai-test-144", "ner": [[0, 1, "field"], [10, 10, "field"], [12, 12, "field"], [14, 14, "field"], [16, 17, "field"], [19, 20, "field"], [29, 30, "product"], [32, 35, "product"], [37, 38, "product"], [40, 41, "product"], [54, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 10, "origin", "takes_inspiration_from", false, false], [0, 1, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 1, 14, 14, "origin", "takes_inspiration_from", false, false], [0, 1, 16, 17, "origin", "takes_inspiration_from", false, false], [0, 1, 19, 20, "origin", "takes_inspiration_from", false, false], [29, 30, 0, 1, "origin", "", false, false], [32, 35, 0, 1, "origin", "", false, false], [37, 38, 0, 1, "origin", "", false, false], [40, 41, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "is", "an", "interdisciplinary", "subject", "that", "draws", "inspiration", "from", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", "and", "electronic", "engineering", "to", "design", "artificial", "neural", "systems", ",", "such", "as", "vision", "systems", ",", "head", "-", "eye", "systems", ",", "auditory", "processors", "and", "autonomous", "robots", ",", "whose", "physical", "architecture", "and", "design", "principles", "are", "based", "on", "those", "of", "biological", "nervous", "systems", "."], "sentence-detokenized": "Neuromorphic engineering is an interdisciplinary subject that draws inspiration from biology, physics, mathematics, computer science and electronic engineering to design artificial neural systems, such as vision systems, head-eye systems, auditory processors and autonomous robots, whose physical architecture and design principles are based on those of biological nervous systems.", "token2charspan": [[0, 12], [13, 24], [25, 27], [28, 30], [31, 48], [49, 56], [57, 61], [62, 67], [68, 79], [80, 84], [85, 92], [92, 93], [94, 101], [101, 102], [103, 114], [114, 115], [116, 124], [125, 132], [133, 136], [137, 147], [148, 159], [160, 162], [163, 169], [170, 180], [181, 187], [188, 195], [195, 196], [197, 201], [202, 204], [205, 211], [212, 219], [219, 220], [221, 225], [225, 226], [226, 229], [230, 237], [237, 238], [239, 247], [248, 258], [259, 262], [263, 273], [274, 280], [280, 281], [282, 287], [288, 296], [297, 309], [310, 313], [314, 320], [321, 331], [332, 335], [336, 341], [342, 344], [345, 350], [351, 353], [354, 364], [365, 372], [373, 380], [380, 381]]}
{"doc_key": "ai-test-145", "ner": [[4, 6, "metrics"], [9, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 9, 4, 6, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "particular", ",", "the", "BIBO", "stability", "criterion", "requires", "the", "ROC", "of", "the", "system", "to", "include", "the", "unit", "circle", "."], "sentence-detokenized": "In particular, the BIBO stability criterion requires the ROC of the system to include the unit circle.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 23], [24, 33], [34, 43], [44, 52], [53, 56], [57, 60], [61, 63], [64, 67], [68, 74], [75, 77], [78, 85], [86, 89], [90, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-146", "ner": [[7, 8, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "The", "programme", "has", "been", "rewritten", "in", "Java", "since", "1998", "."], "sentence-detokenized": "2 The programme has been rewritten in Java since 1998.", "token2charspan": [[0, 1], [2, 5], [6, 15], [16, 19], [20, 24], [25, 34], [35, 37], [38, 42], [43, 48], [49, 53], [53, 54]]}
{"doc_key": "ai-test-147", "ner": [[0, 1, "metrics"], [8, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 8, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "MCC", "can", "be", "calculated", "directly", "from", "the", "confusion", "matrix", "using", "the", "formula", ":"], "sentence-detokenized": "The MCC can be calculated directly from the confusion matrix using the formula:", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 25], [26, 34], [35, 39], [40, 43], [44, 53], [54, 60], [61, 66], [67, 70], [71, 78], [78, 79]]}
{"doc_key": "ai-test-148", "ner": [[8, 13, "organisation"], [22, 27, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 13, 22, 27, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "developed", "by", "a", "team", "from", "the", "MIT", "-", "IBM", "Watson", "AI", "Lab", "and", "presented", "for", "the", "first", "time", "at", "the", "2018", "International", "Conference", "on", "Learning", "Representations", "."], "sentence-detokenized": "It was developed by a team from the MIT-IBM Watson AI Lab and presented for the first time at the 2018 International Conference on Learning Representations.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 31], [32, 35], [36, 39], [39, 40], [40, 43], [44, 50], [51, 53], [54, 57], [58, 61], [62, 71], [72, 75], [76, 79], [80, 85], [86, 90], [91, 93], [94, 97], [98, 102], [103, 116], [117, 127], [128, 130], [131, 139], [140, 155], [155, 156]]}
{"doc_key": "ai-test-149", "ner": [[2, 3, "metrics"], [15, 17, "metrics"], [19, 21, "metrics"], [49, 49, "metrics"], [51, 51, "metrics"], [57, 59, "metrics"], [62, 62, "metrics"], [64, 64, "metrics"], [66, 68, "metrics"], [73, 73, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[15, 17, 49, 49, "type-of", "", false, false], [15, 17, 57, 59, "related-to", "collapses_to_identity", false, false], [19, 21, 51, 51, "type-of", "", false, false], [19, 21, 57, 59, "related-to", "collapses_to_identity", false, false], [19, 21, 66, 68, "named", "same", false, false], [62, 62, 73, 73, "related-to", "collapses_to_identity", false, false], [64, 64, 73, 73, "related-to", "collapses_to_identity", false, false], [66, 68, 73, 73, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["When", "the", "TRUE", "prevalences", "for", "the", "two", "positive", "variables", "are", "equal", ",", "as", "assumed", "in", "Fleiss", "'", "kappa", "and", "F", "-", "score", ",", "i.e.", "the", "number", "of", "positive", "predictions", "corresponds", "to", "the", "number", "of", "positive", "classes", "in", "the", "dichotomous", "case", "(", "two", "classes", ")", ",", "the", "different", "measures", "of", "kappa", "and", "correlation", "collapse", "to", "become", "identical", "to", "Youden", "'s", "J", ",", "and", "recall", ",", "precision", "and", "F", "-", "score", "are", "similarly", "identical", "to", "accuracy", "."], "sentence-detokenized": "When the TRUE prevalences for the two positive variables are equal, as assumed in Fleiss' kappa and F-score, i.e. the number of positive predictions corresponds to the number of positive classes in the dichotomous case (two classes), the different measures of kappa and correlation collapse to become identical to Youden's J, and recall, precision and F-score are similarly identical to accuracy.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 25], [26, 29], [30, 33], [34, 37], [38, 46], [47, 56], [57, 60], [61, 66], [66, 67], [68, 70], [71, 78], [79, 81], [82, 88], [88, 89], [90, 95], [96, 99], [100, 101], [101, 102], [102, 107], [107, 108], [109, 113], [114, 117], [118, 124], [125, 127], [128, 136], [137, 148], [149, 160], [161, 163], [164, 167], [168, 174], [175, 177], [178, 186], [187, 194], [195, 197], [198, 201], [202, 213], [214, 218], [219, 220], [220, 223], [224, 231], [231, 232], [232, 233], [234, 237], [238, 247], [248, 256], [257, 259], [260, 265], [266, 269], [270, 281], [282, 290], [291, 293], [294, 300], [301, 310], [311, 313], [314, 320], [320, 322], [323, 324], [324, 325], [326, 329], [330, 336], [336, 337], [338, 347], [348, 351], [352, 353], [353, 354], [354, 359], [360, 363], [364, 373], [374, 383], [384, 386], [387, 395], [395, 396]]}
{"doc_key": "ai-test-150", "ner": [[3, 9, "misc"], [7, 7, "misc"], [2, 2, "conference"], [13, 16, "task"], [17, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 9, 2, 2, "part-of", "", false, false], [3, 9, 2, 2, "physical", "", false, false], [3, 9, 2, 2, "temporal", "", false, false], [7, 7, 3, 9, "named", "", false, false], [13, 16, 3, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2013", "NAACL", "Building", "Educational", "Applications", "(", "BEA", ")", "workshop", "hosted", "the", "first", "NLI", "shared", "task", ".", "Tetreault", "et", "al", ",", "2013", "The", "competition", "was", "attended", "by", "29", "teams", "from", "around", "the", "world", ",", "24", "of", "which", "also", "published", "a", "paper", "describing", "their", "systems", "and", "approaches", "."], "sentence-detokenized": "The 2013 NAACL Building Educational Applications (BEA) workshop hosted the first NLI shared task. Tetreault et al, 2013 The competition was attended by 29 teams from around the world, 24 of which also published a paper describing their systems and approaches.", "token2charspan": [[0, 3], [4, 8], [9, 14], [15, 23], [24, 35], [36, 48], [49, 50], [50, 53], [53, 54], [55, 63], [64, 70], [71, 74], [75, 80], [81, 84], [85, 91], [92, 96], [96, 97], [98, 107], [108, 110], [111, 113], [113, 114], [115, 119], [120, 123], [124, 135], [136, 139], [140, 148], [149, 151], [152, 154], [155, 160], [161, 165], [166, 172], [173, 176], [177, 182], [182, 183], [184, 186], [187, 189], [190, 195], [196, 200], [201, 210], [211, 212], [213, 218], [219, 229], [230, 235], [236, 243], [244, 247], [248, 258], [258, 259]]}
{"doc_key": "ai-test-151", "ner": [[0, 1, "algorithm"], [2, 7, "algorithm"], [15, 16, "misc"], [20, 21, "misc"], [37, 38, "misc"], [41, 42, "algorithm"], [45, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 2, 7, "type-of", "", false, false], [0, 1, 15, 16, "related-to", "finds", false, false], [20, 21, 15, 16, "type-of", "", false, false], [45, 45, 41, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Viterbi", "algorithm", "is", "a", "dynamic", "programming", "algorithm", "for", "finding", "the", "most", "probable", "sequence", "of", "hidden", "states", ",", "called", "the", "Viterbi", "path", ",", "which", "results", "in", "a", "sequence", "of", "observed", "events", ",", "especially", "in", "the", "context", "of", "Markov", "information", "sources", "and", "Hidden", "Markov", "Models", "(", "HMMs", ")", "."], "sentence-detokenized": "The Viterbi algorithm is a dynamic programming algorithm for finding the most probable sequence of hidden states, called the Viterbi path, which results in a sequence of observed events, especially in the context of Markov information sources and Hidden Markov Models (HMMs).", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 24], [25, 26], [27, 34], [35, 46], [47, 56], [57, 60], [61, 68], [69, 72], [73, 77], [78, 86], [87, 95], [96, 98], [99, 105], [106, 112], [112, 113], [114, 120], [121, 124], [125, 132], [133, 137], [137, 138], [139, 144], [145, 152], [153, 155], [156, 157], [158, 166], [167, 169], [170, 178], [179, 185], [185, 186], [187, 197], [198, 200], [201, 204], [205, 212], [213, 215], [216, 222], [223, 234], [235, 242], [243, 246], [247, 253], [254, 260], [261, 267], [268, 269], [269, 273], [273, 274], [274, 275]]}
{"doc_key": "ai-test-152", "ner": [[1, 1, "field"], [3, 5, "algorithm"], [8, 9, "misc"], [12, 13, "algorithm"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 1, 1, "part-of", "", false, false], [3, 5, 8, 9, "general-affiliation", "", false, false], [3, 5, 12, 13, "related-to", "generalizes_from", false, false], [3, 5, 15, 16, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "multinomial", "logistic", "regression", "is", "a", "classification", "method", "that", "generalises", "logistic", "regression", "to", "multiclass", "classification", ",", "i.e.", "with", "more", "than", "two", "possible", "discrete", "outcomes", "."], "sentence-detokenized": "In statistics, multinomial logistic regression is a classification method that generalises logistic regression to multiclass classification, i.e. with more than two possible discrete outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 26], [27, 35], [36, 46], [47, 49], [50, 51], [52, 66], [67, 73], [74, 78], [79, 90], [91, 99], [100, 110], [111, 113], [114, 124], [125, 139], [139, 140], [141, 145], [146, 150], [151, 155], [156, 160], [161, 164], [165, 173], [174, 182], [183, 191], [191, 192]]}
{"doc_key": "ai-test-153", "ner": [[0, 2, "algorithm"], [9, 10, "field"], [12, 15, "field"], [18, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 9, 10, "part-of", "", false, false], [0, 2, 12, 15, "part-of", "", false, false], [18, 18, 0, 2, "usage", "", true, false], [20, 21, 0, 2, "usage", "", true, false], [23, 24, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden", "Markov", "models", "are", "known", "for", "their", "applications", "to", "reinforcement", "learning", "and", "recognition", "of", "temporal", "patterns", "such", "as", "speech", ",", "handwriting", "recognition", ",", "gesture", "recognition", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov models are known for their applications to reinforcement learning and recognition of temporal patterns such as speech, handwriting recognition, gesture recognition, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 30], [31, 34], [35, 40], [41, 53], [54, 56], [57, 70], [71, 79], [80, 83], [84, 95], [96, 98], [99, 107], [108, 116], [117, 121], [122, 124], [125, 131], [131, 132], [133, 144], [145, 156], [156, 157], [158, 165], [166, 177], [177, 178], [179, 183], [184, 191], [191, 192], [193, 197], [198, 206], [206, 207]]}
{"doc_key": "ai-test-154", "ner": [[7, 9, "misc"], [34, 37, "metrics"], [39, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 39, 39, "named", "", false, false], [34, 37, 39, 39, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "essence", ",", "this", "means", "that", "if", "a", "gram", "has", "been", "seen", "more", "than", "k", "times", "during", "training", ",", "the", "conditional", "probability", "of", "a", "word", ",", "given", "its", "history", ",", "is", "proportional", "to", "the", "maximum", "likelihood", "estimate", "of", "that", "gram", "."], "sentence-detokenized": "In essence, this means that if a gram has been seen more than k times during training, the conditional probability of a word, given its history, is proportional to the maximum likelihood estimate of that gram.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [17, 22], [23, 27], [28, 30], [31, 32], [33, 37], [38, 41], [42, 46], [47, 51], [52, 56], [57, 61], [62, 63], [64, 69], [70, 76], [77, 85], [85, 86], [87, 90], [91, 102], [103, 114], [115, 117], [118, 119], [120, 124], [124, 125], [126, 131], [132, 135], [136, 143], [143, 144], [145, 147], [148, 160], [161, 163], [164, 167], [168, 175], [176, 186], [187, 195], [196, 198], [199, 203], [204, 208], [208, 209]]}
{"doc_key": "ai-test-155", "ner": [[4, 5, "task"], [7, 8, "task"], [10, 12, "task"], [16, 18, "task"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[26, 27, 16, 18, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "knowledge", "representation", ",", "meaningful", "reasoning", "and", "natural", "language", "understanding", ",", "believing", "that", "deep", "language", "understanding", "can", "currently", "only", "be", "achieved", "through", "significant", "manual", "engineering", "of", "semantics", "-", "rich", "formalisms", ",", "combined", "with", "statistical", "preferences", "."], "sentence-detokenized": "He is interested in knowledge representation, meaningful reasoning and natural language understanding, believing that deep language understanding can currently only be achieved through significant manual engineering of semantics-rich formalisms, combined with statistical preferences.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 29], [30, 44], [44, 45], [46, 56], [57, 66], [67, 70], [71, 78], [79, 87], [88, 101], [101, 102], [103, 112], [113, 117], [118, 122], [123, 131], [132, 145], [146, 149], [150, 159], [160, 164], [165, 167], [168, 176], [177, 184], [185, 196], [197, 203], [204, 215], [216, 218], [219, 228], [228, 229], [229, 233], [234, 244], [244, 245], [246, 254], [255, 259], [260, 271], [272, 283], [283, 284]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "JavaScript", ",", "Python", "or"], "sentence-detokenized": "In JavaScript, Python or", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 24]]}
{"doc_key": "ai-test-157", "ner": [[1, 2, "misc"], [7, 8, "misc"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 7, 8, "part-of", "", false, false], [7, 8, 12, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "awards", "are", "announced", "in", "the", "AI", "magazine", "published", "by", "the", "AAAI", "."], "sentence-detokenized": "The Newcomb awards are announced in the AI magazine published by the AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 32], [33, 35], [36, 39], [40, 42], [43, 51], [52, 61], [62, 64], [65, 68], [69, 73], [73, 74]]}
{"doc_key": "ai-test-158", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "square", "error", "on", "a", "test", "set", "of", "100", "specimens", "is", "0.084", ",", "which", "is", "lower", "than", "the", "un", "-", "normalised", "error", "."], "sentence-detokenized": "The mean square error on a test set of 100 specimens is 0.084, which is lower than the un-normalised error.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 21], [22, 24], [25, 26], [27, 31], [32, 35], [36, 38], [39, 42], [43, 52], [53, 55], [56, 61], [61, 62], [63, 68], [69, 71], [72, 77], [78, 82], [83, 86], [87, 89], [89, 90], [90, 100], [101, 106], [106, 107]]}
{"doc_key": "ai-test-159", "ner": [[0, 3, "metrics"], [9, 11, "field"], [19, 21, "task"], [23, 23, "task"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 11, 0, 3, "usage", "", false, false], [19, 21, 9, 11, "part-of", "task_part_of_field", false, false], [23, 23, 19, 21, "named", "", false, false], [26, 27, 9, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "F", "score", "has", "been", "widely", "used", "in", "the", "natural", "language", "processing", "literature", ",", "e.g.", "for", "the", "evaluation", "of", "named", "entity", "recognition", "(", "NER", ")", "and", "word", "segmentation", "."], "sentence-detokenized": "The F score has been widely used in the natural language processing literature, e.g. for the evaluation of named entity recognition (NER) and word segmentation.", "token2charspan": [[0, 3], [4, 5], [6, 11], [12, 15], [16, 20], [21, 27], [28, 32], [33, 35], [36, 39], [40, 47], [48, 56], [57, 67], [68, 78], [78, 79], [80, 84], [85, 88], [89, 92], [93, 103], [104, 106], [107, 112], [113, 119], [120, 131], [132, 133], [133, 136], [136, 137], [138, 141], [142, 146], [147, 159], [159, 160]]}
{"doc_key": "ai-test-160", "ner": [[0, 0, "product"], [5, 6, "product"], [15, 16, "misc"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 15, 16, "related-to", "performs_task", false, false], [0, 0, 18, 19, "related-to", "performs_task", false, false], [5, 6, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "typically", "used", "in", "dialogue", "systems", "for", "various", "purposes", ",", "including", "customer", "service", ",", "request", "routing", "or", "information", "gathering", "."], "sentence-detokenized": "Chatbots are typically used in dialogue systems for various purposes, including customer service, request routing or information gathering.", "token2charspan": [[0, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 39], [40, 47], [48, 51], [52, 59], [60, 68], [68, 69], [70, 79], [80, 88], [89, 96], [96, 97], [98, 105], [106, 113], [114, 116], [117, 128], [129, 138], [138, 139]]}
{"doc_key": "ai-test-161", "ner": [[4, 10, "conference"], [14, 22, "conference"], [28, 38, "conference"], [44, 44, "conference"], [48, 51, "conference"], [53, 54, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 22, 4, 10, "named", "", false, false], [28, 38, 4, 10, "named", "", false, false], [44, 44, 28, 38, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Major", "journals", "include", "the", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "later", "renamed", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "and", "since", "September", "2014", "renamed", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "after", "merging", "with", "an", "ACM", "publication", ")", ",", "Computer", "Speech", "and", "Language", "and", "Speech", "Communication", "."], "sentence-detokenized": "Major journals include the IEEE Transactions on Speech and Audio Processing (later renamed IEEE Transactions on Audio, Speech and Language Processing and since September 2014 renamed IEEE / ACM Transactions on Audio, Speech and Language Processing - after merging with an ACM publication), Computer Speech and Language and Speech Communication.", "token2charspan": [[0, 5], [6, 14], [15, 22], [23, 26], [27, 31], [32, 44], [45, 47], [48, 54], [55, 58], [59, 64], [65, 75], [76, 77], [77, 82], [83, 90], [91, 95], [96, 108], [109, 111], [112, 117], [117, 118], [119, 125], [126, 129], [130, 138], [139, 149], [150, 153], [154, 159], [160, 169], [170, 174], [175, 182], [183, 187], [188, 189], [190, 193], [194, 206], [207, 209], [210, 215], [215, 216], [217, 223], [224, 227], [228, 236], [237, 247], [248, 249], [250, 255], [256, 263], [264, 268], [269, 271], [272, 275], [276, 287], [287, 288], [288, 289], [290, 298], [299, 305], [306, 309], [310, 318], [319, 322], [323, 329], [330, 343], [343, 344]]}
{"doc_key": "ai-test-162", "ner": [[0, 0, "algorithm"], [5, 6, "task"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 0, 0, "usage", "", false, false], [5, 6, 8, 9, "part-of", "task_part_of_field", false, false], [5, 6, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "is", "often", "used", "for", "data", "clustering", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "EM is often used for data clustering in machine learning and computer vision.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 20], [21, 25], [26, 36], [37, 39], [40, 47], [48, 56], [57, 60], [61, 69], [70, 76], [76, 77]]}
{"doc_key": "ai-test-163", "ner": [[9, 11, "metrics"], [24, 26, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 24, 26, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["Although", "there", "is", "no", "perfect", "way", "to", "describe", "the", "confusion", "matrix", "of", "TRUE", "and", "FALSE", "positives", "and", "negatives", "with", "a", "single", "number", ",", "the", "Matthews", "correlation", "coefficient", "is", "generally", "considered", "one", "of", "the", "best", "measures", "of", "this", "type", "."], "sentence-detokenized": "Although there is no perfect way to describe the confusion matrix of TRUE and FALSE positives and negatives with a single number, the Matthews correlation coefficient is generally considered one of the best measures of this type.", "token2charspan": [[0, 8], [9, 14], [15, 17], [18, 20], [21, 28], [29, 32], [33, 35], [36, 44], [45, 48], [49, 58], [59, 65], [66, 68], [69, 73], [74, 77], [78, 83], [84, 93], [94, 97], [98, 107], [108, 112], [113, 114], [115, 121], [122, 128], [128, 129], [130, 133], [134, 142], [143, 154], [155, 166], [167, 169], [170, 179], [180, 190], [191, 194], [195, 197], [198, 201], [202, 206], [207, 215], [216, 218], [219, 223], [224, 228], [228, 229]]}
{"doc_key": "ai-test-164", "ner": [[10, 11, "field"], [26, 27, "field"], [34, 35, "field"], [39, 40, "algorithm"], [42, 43, "task"], [45, 46, "algorithm"], [52, 53, "algorithm"], [55, 56, "algorithm"], [62, 64, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[34, 35, 26, 27, "part-of", "subfield", false, false], [39, 40, 34, 35, "part-of", "", false, true], [42, 43, 34, 35, "part-of", "", false, true], [45, 46, 34, 35, "part-of", "", false, true], [52, 53, 34, 35, "part-of", "", false, true], [55, 56, 34, 35, "part-of", "", false, true], [62, 64, 34, 35, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "the", "size", "and", "complexity", "of", "datasets", "increased", ",", "direct", "data", "analysis", "was", "joined", "by", "indirect", "and", "automated", "data", "processing", ",", "aided", "by", "other", "discoveries", "in", "computer", "science", ",", "particularly", "in", "the", "field", "of", "machine", "learning", ",", "such", "as", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "decision", "tree", "learning", "and", "decision", "rules", "(", "1960", "s", ")", "and", "support", "vector", "machines", "(", "1990", "s", ")", "."], "sentence-detokenized": "As the size and complexity of datasets increased, direct data analysis was joined by indirect and automated data processing, aided by other discoveries in computer science, particularly in the field of machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision tree learning and decision rules (1960s) and support vector machines (1990s).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 15], [16, 26], [27, 29], [30, 38], [39, 48], [48, 49], [50, 56], [57, 61], [62, 70], [71, 74], [75, 81], [82, 84], [85, 93], [94, 97], [98, 107], [108, 112], [113, 123], [123, 124], [125, 130], [131, 133], [134, 139], [140, 151], [152, 154], [155, 163], [164, 171], [171, 172], [173, 185], [186, 188], [189, 192], [193, 198], [199, 201], [202, 209], [210, 218], [218, 219], [220, 224], [225, 227], [228, 234], [235, 243], [243, 244], [245, 252], [253, 261], [261, 262], [263, 270], [271, 281], [282, 283], [283, 288], [288, 289], [289, 290], [291, 299], [300, 304], [305, 313], [314, 317], [318, 326], [327, 332], [333, 334], [334, 338], [338, 339], [339, 340], [341, 344], [345, 352], [353, 359], [360, 368], [369, 370], [370, 374], [374, 375], [375, 376], [376, 377]]}
{"doc_key": "ai-test-165", "ner": [[4, 4, "researcher"], [9, 12, "misc"], [18, 19, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 12, 4, 4, "artifact", "", false, false], [9, 12, 18, 19, "artifact", "", false, false], [9, 12, 21, 22, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "autumn", "2005", ",", "Thrun", "published", "a", "textbook", "entitled", "Probabilistic", "Robotics", "together", "with", "his", "long", "-", "time", "collaborators", "Dieter", "Fox", "and", "Wolfram", "Burgard", "."], "sentence-detokenized": "In autumn 2005, Thrun published a textbook entitled Probabilistic Robotics together with his long-time collaborators Dieter Fox and Wolfram Burgard.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 21], [22, 31], [32, 33], [34, 42], [43, 51], [52, 65], [66, 74], [75, 83], [84, 88], [89, 92], [93, 97], [97, 98], [98, 102], [103, 116], [117, 123], [124, 127], [128, 131], [132, 139], [140, 147], [147, 148]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereiramath", "as", "follows", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereiramath as follows:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 49], [50, 52], [53, 60], [60, 61]]}
{"doc_key": "ai-test-167", "ner": [[0, 1, "task"], [3, 3, "task"], [7, 8, "field"], [16, 17, "field"], [19, 21, "field"], [23, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 16, 17, "part-of", "task_part_of_field", false, false], [0, 1, 19, 21, "part-of", "task_part_of_field", false, false], [3, 3, 0, 1, "named", "", false, false], [16, 17, 7, 8, "part-of", "subfield", false, false], [19, 21, 7, 8, "part-of", "subfield", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Question", "answering", "(", "QA", ")", "is", "a", "computer", "science", "discipline", "that", "falls", "within", "the", "fields", "of", "information", "retrieval", "and", "natural", "language", "processing", "(", "NLP", ")", "and", "is", "concerned", "with", "building", "systems", "that", "automatically", "answer", "questions", "posed", "by", "humans", "in", "a", "natural", "language", "."], "sentence-detokenized": "Question answering (QA) is a computer science discipline that falls within the fields of information retrieval and natural language processing (NLP) and is concerned with building systems that automatically answer questions posed by humans in a natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 37], [38, 45], [46, 56], [57, 61], [62, 67], [68, 74], [75, 78], [79, 85], [86, 88], [89, 100], [101, 110], [111, 114], [115, 122], [123, 131], [132, 142], [143, 144], [144, 147], [147, 148], [149, 152], [153, 155], [156, 165], [166, 170], [171, 179], [180, 187], [188, 192], [193, 206], [207, 213], [214, 223], [224, 229], [230, 232], [233, 239], [240, 242], [243, 244], [245, 252], [253, 261], [261, 262]]}
{"doc_key": "ai-test-168", "ner": [[10, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "in", "the", "version", "of", "the", "metrics", "used", "by", "NIST", "assessments", "prior", "to", "2009", ",", "the", "shorter", "reference", "sentence", "was", "used", "."], "sentence-detokenized": "However, in the version of the metrics used by NIST assessments prior to 2009, the shorter reference sentence was used.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 38], [39, 43], [44, 46], [47, 51], [52, 63], [64, 69], [70, 72], [73, 77], [77, 78], [79, 82], [83, 90], [91, 100], [101, 109], [110, 113], [114, 118], [118, 119]]}
{"doc_key": "ai-test-169", "ner": [[5, 5, "person"], [13, 13, "organisation"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 15, 15, "related-to", "invests_in", false, false], [15, 15, 13, 13, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["On", "27", "August", "2018", ",", "Toyota", "announced", "a", "$", "500", "million", "investment", "in", "Uber", "'s", "autonomous", "cars", "."], "sentence-detokenized": "On 27 August 2018, Toyota announced a $500 million investment in Uber's autonomous cars.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 17], [17, 18], [19, 25], [26, 35], [36, 37], [38, 39], [39, 42], [43, 50], [51, 61], [62, 64], [65, 69], [69, 71], [72, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-test-170", "ner": [[6, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sample", "maximum", "is", "the", "maximum", "likelihood", "estimator", "of", "the", "population", "maximum", ",", "but", ",", "as", "discussed", "above", ",", "it", "is", "biased", "."], "sentence-detokenized": "The sample maximum is the maximum likelihood estimator of the population maximum, but, as discussed above, it is biased.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 25], [26, 33], [34, 44], [45, 54], [55, 57], [58, 61], [62, 72], [73, 80], [80, 81], [82, 85], [85, 86], [87, 89], [90, 99], [100, 105], [105, 106], [107, 109], [110, 112], [113, 119], [119, 120]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [3, 3, "misc"], [6, 6, "metrics"], [15, 17, "algorithm"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 3, "related-to", "overcomes", false, false], [0, 0, 6, 6, "related-to", "increases", false, false], [3, 3, 15, 17, "opposite", "", false, false], [3, 3, 19, 21, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "helps", "overcome", "synonymy", "by", "increasing", "recall", ",", "one", "of", "the", "most", "problematic", "constraints", "of", "Boolean", "keyword", "queries", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI helps overcome synonymy by increasing recall, one of the most problematic constraints of Boolean keyword queries and vector space models.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 27], [28, 30], [31, 41], [42, 48], [48, 49], [50, 53], [54, 56], [57, 60], [61, 65], [66, 77], [78, 89], [90, 92], [93, 100], [101, 108], [109, 116], [117, 120], [121, 127], [128, 133], [134, 140], [140, 141]]}
{"doc_key": "ai-test-172", "ner": [[0, 1, "task"], [17, 17, "programlang"], [19, 19, "programlang"], [23, 24, "programlang"], [25, 26, "programlang"], [28, 28, "programlang"], [30, 30, "programlang"], [32, 32, "programlang"], [34, 34, "programlang"], [36, 36, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 17, 17, "general-affiliation", "", false, false], [0, 1, 19, 19, "general-affiliation", "", false, false], [0, 1, 23, 24, "general-affiliation", "", false, false], [0, 1, 25, 26, "general-affiliation", "", false, false], [0, 1, 28, 28, "general-affiliation", "", false, false], [0, 1, 30, 30, "general-affiliation", "", false, false], [0, 1, 32, 32, "general-affiliation", "", false, false], [0, 1, 34, 34, "general-affiliation", "", false, false], [0, 1, 36, 36, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Data", "acquisition", "applications", "are", "usually", "controlled", "by", "software", "programmes", "developed", "using", "various", "generic", "programming", "languages", "such", "as", "Assembly", ",", "BASIC", ",", "C", ",", "C", "++,", "C", "#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "Data acquisition applications are usually controlled by software programmes developed using various generic programming languages such as Assembly, BASIC, C, C++, C #, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 4], [5, 16], [17, 29], [30, 33], [34, 41], [42, 52], [53, 55], [56, 64], [65, 75], [76, 85], [86, 91], [92, 99], [100, 107], [108, 119], [120, 129], [130, 134], [135, 137], [138, 146], [146, 147], [148, 153], [153, 154], [155, 156], [156, 157], [158, 159], [159, 162], [163, 164], [165, 166], [166, 167], [168, 175], [175, 176], [177, 181], [181, 182], [183, 190], [190, 191], [192, 196], [196, 197], [198, 204], [204, 205], [206, 210]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [6, 6, "product"], [9, 9, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 3, 3, "artifact", "", false, false], [6, 6, 9, 9, "physical", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2003", ",", "Honda", "advertised", "the", "Cog", "in", "the", "UK", "and", "on", "the", "Internet", "."], "sentence-detokenized": "In 2003, Honda advertised the Cog in the UK and on the Internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 29], [30, 33], [34, 36], [37, 40], [41, 43], [44, 47], [48, 50], [51, 54], [55, 63], [63, 64]]}
{"doc_key": "ai-test-174", "ner": [[1, 2, "conference"], [3, 7, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 3, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Association", "for", "Computational", "Linguistics", "defines", "computational", "linguistics", "as", ":"], "sentence-detokenized": "The Association for Computational Linguistics defines computational linguistics as:", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 45], [46, 53], [54, 67], [68, 79], [80, 82], [82, 83]]}
{"doc_key": "ai-test-175", "ner": [[0, 2, "algorithm"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 11, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Expectation", "maximisation", "algorithms", "can", "be", "used", "to", "compute", "approximate", "maximum", "likelihood", "estimates", "of", "unknown", "parameters", "of", "the", "state", "space", "within", "minimum", "-variance", "filters", "and", "smoothers", "."], "sentence-detokenized": "Expectation maximisation algorithms can be used to compute approximate maximum likelihood estimates of unknown parameters of the state space within minimum-variance filters and smoothers.", "token2charspan": [[0, 11], [12, 24], [25, 35], [36, 39], [40, 42], [43, 47], [48, 50], [51, 58], [59, 70], [71, 78], [79, 89], [90, 99], [100, 102], [103, 110], [111, 121], [122, 124], [125, 128], [129, 134], [135, 140], [141, 147], [148, 155], [155, 164], [165, 172], [173, 176], [177, 186], [186, 187]]}
{"doc_key": "ai-test-176", "ner": [[5, 5, "misc"], [7, 9, "person"], [11, 12, "person"], [14, 15, "person"], [18, 19, "misc"], [20, 21, "person"], [24, 25, "person"], [29, 29, "person"], [31, 32, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 9, 5, 5, "role", "actor_in", false, false], [11, 12, 5, 5, "role", "actor_in", false, false], [14, 15, 5, 5, "role", "actor_in", false, false], [20, 21, 18, 19, "role", "model_for", false, false], [29, 29, 31, 32, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Among", "the", "correspondents", "were", "former", "Baywatch", "actresses", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "and", "Traci", "Bingham", ",", "former", "Playboy", "Playmate", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", "and", "identical", "twins", "Randy", "and", "Jason", "Sklar", "."], "sentence-detokenized": "Among the correspondents were former Baywatch actresses Donna D'Errico, Carmen Electra and Traci Bingham, former Playboy Playmate Heidi Mark, comedian Arj Barker and identical twins Randy and Jason Sklar.", "token2charspan": [[0, 5], [6, 9], [10, 24], [25, 29], [30, 36], [37, 45], [46, 55], [56, 61], [62, 64], [64, 70], [70, 71], [72, 78], [79, 86], [87, 90], [91, 96], [97, 104], [104, 105], [106, 112], [113, 120], [121, 129], [130, 135], [136, 140], [140, 141], [142, 150], [151, 154], [155, 161], [162, 165], [166, 175], [176, 181], [182, 187], [188, 191], [192, 197], [198, 203], [203, 204]]}
{"doc_key": "ai-test-177", "ner": [[8, 9, "task"], [11, 11, "task"], [15, 18, "product"], [22, 23, "task"], [25, 25, "task"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [15, 18, 8, 9, "general-affiliation", "", false, false], [25, 25, 22, 23, "named", "", false, false], [30, 31, 22, 23, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "is", "commonly", "used", "to", "generate", "representations", "for", "speech", "recognition", "(", "ASR", ")", ",", "e.g.", "CMU", "'s", "Sphinx", "system", ",", "and", "for", "speech", "synthesis", "(", "TTS", ")", ",", "e.g.", "the", "Festival", "system", "."], "sentence-detokenized": "It is commonly used to generate representations for speech recognition (ASR), e.g. CMU's Sphinx system, and for speech synthesis (TTS), e.g. the Festival system.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 19], [20, 22], [23, 31], [32, 47], [48, 51], [52, 58], [59, 70], [71, 72], [72, 75], [75, 76], [76, 77], [78, 82], [83, 86], [86, 88], [89, 95], [96, 102], [102, 103], [104, 107], [108, 111], [112, 118], [119, 128], [129, 130], [130, 133], [133, 134], [134, 135], [136, 140], [141, 144], [145, 153], [154, 160], [160, 161]]}
{"doc_key": "ai-test-178", "ner": [[0, 1, "metrics"], [3, 5, "metrics"], [7, 7, "metrics"], [13, 13, "metrics"], [27, 28, "metrics"], [30, 30, "metrics"], [41, 42, "metrics"], [44, 44, "metrics"], [46, 48, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 5, 0, 1, "named", "", false, false], [7, 7, 3, 5, "named", "", false, false], [13, 13, 0, 1, "named", "", false, false], [30, 30, 27, 28, "named", "", false, false], [44, 44, 41, 42, "named", "", false, false], [46, 48, 41, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "sensitivity", "or", "true", "positivity", "rate", "(", "TPR", ")", ",", "also", "known", "as", "recall", ",", "is", "the", "proportion", "of", "people", "who", "tested", "positive", "and", "are", "positive", "(", "true", "positivity", ",", "TP", ")", "compared", "to", "all", "people", "who", "are", "actually", "positive", "(", "positive", "status", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "The sensitivity or true positivity rate (TPR), also known as recall, is the proportion of people who tested positive and are positive (true positivity, TP) compared to all people who are actually positive (positive status, CP = TP + FN).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 23], [24, 34], [35, 39], [40, 41], [41, 44], [44, 45], [45, 46], [47, 51], [52, 57], [58, 60], [61, 67], [67, 68], [69, 71], [72, 75], [76, 86], [87, 89], [90, 96], [97, 100], [101, 107], [108, 116], [117, 120], [121, 124], [125, 133], [134, 135], [135, 139], [140, 150], [150, 151], [152, 154], [154, 155], [156, 164], [165, 167], [168, 171], [172, 178], [179, 182], [183, 186], [187, 195], [196, 204], [205, 206], [206, 214], [215, 221], [221, 222], [223, 225], [226, 227], [228, 230], [231, 232], [233, 235], [235, 236], [236, 237]]}
{"doc_key": "ai-test-179", "ner": [[0, 1, "task"], [9, 12, "conference"], [14, 14, "conference"], [16, 16, "conference"], [16, 18, "conference"], [20, 21, "conference"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6], "relations": [[9, 12, 0, 1, "topic", "", false, false], [14, 14, 0, 1, "topic", "", false, false], [16, 16, 0, 1, "topic", "", false, false], [16, 18, 0, 1, "topic", "", false, false], [20, 21, 0, 1, "topic", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5], "sentence": ["Speech", "recognition", "conferences", "held", "every", "year", "or", "two", "include", "SpeechTEK", "and", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "and", "IEEE", "ASRU", "."], "sentence-detokenized": "Speech recognition conferences held every year or two include SpeechTEK and SpeechTEK Europe, ICASSP, Interspeech / Eurospeech and IEEE ASRU.", "token2charspan": [[0, 6], [7, 18], [19, 30], [31, 35], [36, 41], [42, 46], [47, 49], [50, 53], [54, 61], [62, 71], [72, 75], [76, 85], [86, 92], [92, 93], [94, 100], [100, 101], [102, 113], [114, 115], [116, 126], [127, 130], [131, 135], [136, 140], [140, 141]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [3, 3, "researcher"], [17, 18, "product"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 0, 0, "artifact", "", false, false], [21, 21, 3, 3, "artifact", "", false, false], [21, 21, 17, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "collaborated", "with", "Engelberger", ",", "who", "was", "president", "of", "the", "company", ",", "to", "design", "and", "produce", "an", "industrial", "robot", "under", "the", "Unimate", "brand", "."], "sentence-detokenized": "Devol collaborated with Engelberger, who was president of the company, to design and produce an industrial robot under the Unimate brand.", "token2charspan": [[0, 5], [6, 18], [19, 23], [24, 35], [35, 36], [37, 40], [41, 44], [45, 54], [55, 57], [58, 61], [62, 69], [69, 70], [71, 73], [74, 80], [81, 84], [85, 92], [93, 95], [96, 106], [107, 112], [113, 118], [119, 122], [123, 130], [131, 136], [136, 137]]}
{"doc_key": "ai-test-181", "ner": [[1, 3, "algorithm"], [5, 5, "algorithm"], [9, 11, "algorithm"], [24, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 9, 11, "general-affiliation", "", false, false], [5, 5, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "Hidden", "Markov", "Model", "(", "HMM", ")", "is", "a", "statistical", "Markov", "model", "in", "which", "the", "system", "to", "be", "modelled", "is", "assumed", "to", "be", "a", "Markov", "process", "with", "unobserved", "(", "hidden", ")", "states", "."], "sentence-detokenized": "A Hidden Markov Model (HMM) is a statistical Markov model in which the system to be modelled is assumed to be a Markov process with unobserved (hidden) states.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [22, 23], [23, 26], [26, 27], [28, 30], [31, 32], [33, 44], [45, 51], [52, 57], [58, 60], [61, 66], [67, 70], [71, 77], [78, 80], [81, 83], [84, 92], [93, 95], [96, 103], [104, 106], [107, 109], [110, 111], [112, 118], [119, 126], [127, 131], [132, 142], [143, 144], [144, 150], [150, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-test-182", "ner": [[16, 18, "metrics"], [24, 24, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "property", ",", "undesirable", "in", "many", "applications", ",", "has", "led", "researchers", "to", "use", "alternatives", "such", "as", "mean", "absolute", "error", "or", "those", "based", "on", "the", "median", "."], "sentence-detokenized": "This property, undesirable in many applications, has led researchers to use alternatives such as mean absolute error or those based on the median.", "token2charspan": [[0, 4], [5, 13], [13, 14], [15, 26], [27, 29], [30, 34], [35, 47], [47, 48], [49, 52], [53, 56], [57, 68], [69, 71], [72, 75], [76, 88], [89, 93], [94, 96], [97, 101], [102, 110], [111, 116], [117, 119], [120, 125], [126, 131], [132, 134], [135, 138], [139, 145], [145, 146]]}
{"doc_key": "ai-test-183", "ner": [[22, 23, "algorithm"], [31, 32, "field"], [35, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 23, 31, 32, "part-of", "", false, false], [22, 23, 35, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Such", "a", "sequence", "(", "which", "depends", "on", "the", "outcome", "of", "the", "investigation", "of", "previous", "attributes", "at", "each", "stage", ")", "is", "called", "a", "decision", "tree", "and", "finds", "application", "in", "the", "area", "of", "machine", "learning", "known", "as", "decision", "tree", "learning", "."], "sentence-detokenized": "Such a sequence (which depends on the outcome of the investigation of previous attributes at each stage) is called a decision tree and finds application in the area of machine learning known as decision tree learning.", "token2charspan": [[0, 4], [5, 6], [7, 15], [16, 17], [17, 22], [23, 30], [31, 33], [34, 37], [38, 45], [46, 48], [49, 52], [53, 66], [67, 69], [70, 78], [79, 89], [90, 92], [93, 97], [98, 103], [103, 104], [105, 107], [108, 114], [115, 116], [117, 125], [126, 130], [131, 134], [135, 140], [141, 152], [153, 155], [156, 159], [160, 164], [165, 167], [168, 175], [176, 184], [185, 190], [191, 193], [194, 202], [203, 207], [208, 216], [216, 217]]}
{"doc_key": "ai-test-184", "ner": [[2, 3, "task"], [5, 5, "algorithm"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 5, 5, "compare", "", false, false], [20, 21, 5, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "in", "factor", "analysis", ",", "LCA", "can", "also", "be", "used", "to", "classify", "cases", "according", "to", "whether", "they", "belong", "to", "the", "highest", "likelihood", "class", "."], "sentence-detokenized": "As in factor analysis, LCA can also be used to classify cases according to whether they belong to the highest likelihood class.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 21], [21, 22], [23, 26], [27, 30], [31, 35], [36, 38], [39, 43], [44, 46], [47, 55], [56, 61], [62, 71], [72, 74], [75, 82], [83, 87], [88, 94], [95, 97], [98, 101], [102, 109], [110, 120], [121, 126], [126, 127]]}
{"doc_key": "ai-test-185", "ner": [[0, 2, "algorithm"], [5, 7, "metrics"], [9, 9, "metrics"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 7, "usage", "", false, false], [5, 7, 11, 12, "related-to", "", false, false], [9, 9, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Supervised", "neural", "networks", "using", "a", "mean", "square", "error", "(", "MSE", ")", "cost", "function", "can", "use", "formal", "statistical", "methods", "to", "determine", "the", "confidence", "of", "the", "trained", "model", "."], "sentence-detokenized": "Supervised neural networks using a mean square error (MSE) cost function can use formal statistical methods to determine the confidence of the trained model.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 32], [33, 34], [35, 39], [40, 46], [47, 52], [53, 54], [54, 57], [57, 58], [59, 63], [64, 72], [73, 76], [77, 80], [81, 87], [88, 99], [100, 107], [108, 110], [111, 120], [121, 124], [125, 135], [136, 138], [139, 142], [143, 150], [151, 156], [156, 157]]}
{"doc_key": "ai-test-186", "ner": [[16, 17, "algorithm"], [20, 22, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 20, 22, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "expressed", "directly", "as", "a", "linear", "programme", ",", "but", "is", "also", "equivalent", "to", "the", "Tikhonov", "regularisation", "with", "the", "hinge", "loss", "function", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=\\", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "This can be expressed directly as a linear programme, but is also equivalent to the Tikhonov regularisation with the hinge loss function, mathV (f (x), y) =\\ max (0, 1 - yf (x)) / math:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 21], [22, 30], [31, 33], [34, 35], [36, 42], [43, 52], [52, 53], [54, 57], [58, 60], [61, 65], [66, 76], [77, 79], [80, 83], [84, 92], [93, 107], [108, 112], [113, 116], [117, 122], [123, 127], [128, 136], [136, 137], [138, 143], [144, 145], [145, 146], [147, 148], [148, 149], [149, 150], [150, 151], [152, 153], [153, 154], [155, 157], [158, 161], [162, 163], [163, 164], [164, 165], [166, 167], [168, 169], [170, 172], [173, 174], [174, 175], [175, 176], [176, 177], [178, 179], [180, 184], [184, 185]]}
{"doc_key": "ai-test-187", "ner": [[6, 6, "researcher"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "technique", "was", "described", "in", "Breiman", "'s", "original", "article", "and", "is", "implemented", "in", "the", "R", "package", "RandomForest", "."], "sentence-detokenized": "The following technique was described in Breiman's original article and is implemented in the R package RandomForest.", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 27], [28, 37], [38, 40], [41, 48], [48, 50], [51, 59], [60, 67], [68, 71], [72, 74], [75, 86], [87, 89], [90, 93], [94, 95], [96, 103], [104, 116], [116, 117]]}
{"doc_key": "ai-test-188", "ner": [[8, 8, "metrics"], [41, 41, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "measures", "of", "image", "quality", ",", "such", "as", "PSNR", ",", "are", "typically", "performed", "on", "fixed", "-", "resolution", "images", "and", "do", "not", "take", "into", "account", "certain", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "the", "variation", "of", "spatial", "resolution", "on", "the", "retina", "."], "sentence-detokenized": "Traditional measures of image quality, such as PSNR, are typically performed on fixed-resolution images and do not take into account certain aspects of the human visual system, such as the variation of spatial resolution on the retina.", "token2charspan": [[0, 11], [12, 20], [21, 23], [24, 29], [30, 37], [37, 38], [39, 43], [44, 46], [47, 51], [51, 52], [53, 56], [57, 66], [67, 76], [77, 79], [80, 85], [85, 86], [86, 96], [97, 103], [104, 107], [108, 110], [111, 114], [115, 119], [120, 124], [125, 132], [133, 140], [141, 148], [149, 151], [152, 155], [156, 161], [162, 168], [169, 175], [175, 176], [177, 181], [182, 184], [185, 188], [189, 198], [199, 201], [202, 209], [210, 220], [221, 223], [224, 227], [228, 234], [234, 235]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [10, 11, "person"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 15, 16, "role", "", false, false], [3, 4, 15, 16, "role", "", false, false], [6, 7, 15, 16, "role", "", false, false], [15, 16, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "and", "Macdonald", "Carey", "starred", "in", "Jack", "Broder", "'s", "colour", "production", "Hannah", "Lee", ",", "which", "premiered", "on", "19", "June", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru and Macdonald Carey starred in Jack Broder's colour production Hannah Lee, which premiered on 19 June 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 55], [56, 60], [61, 67], [67, 69], [70, 76], [77, 87], [88, 94], [95, 98], [98, 99], [100, 105], [106, 115], [116, 118], [119, 121], [122, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-190", "ner": [[4, 5, "task"], [9, 10, "field"], [16, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 9, 10, "usage", "", false, false], [16, 16, 9, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "process", "is", "called", "image", "registration", "and", "uses", "various", "computer", "vision", "methods", ",", "mostly", "related", "to", "tracking", "."], "sentence-detokenized": "This process is called image registration and uses various computer vision methods, mostly related to tracking.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 22], [23, 28], [29, 41], [42, 45], [46, 50], [51, 58], [59, 67], [68, 74], [75, 82], [82, 83], [84, 90], [91, 98], [99, 101], [102, 110], [110, 111]]}
{"doc_key": "ai-test-191", "ner": [[17, 18, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["We", "now", "begin", "to", "explain", "the", "different", "possible", "relationships", "between", "the", "predicted", "and", "the", "actual", "result", ":", "Confusion", "matrix"], "sentence-detokenized": "We now begin to explain the different possible relationships between the predicted and the actual result: Confusion matrix", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 23], [24, 27], [28, 37], [38, 46], [47, 60], [61, 68], [69, 72], [73, 82], [83, 86], [87, 90], [91, 97], [98, 104], [104, 105], [106, 115], [116, 122]]}
{"doc_key": "ai-test-192", "ner": [[1, 1, "product"], [1, 4, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 1, 4, "part-of", "", false, false], [1, 1, 1, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "VOICEBOX", "speech", "processing", "toolbox", "for", "MATLAB", "implements", "conversion", "and", "inversion", "as", ":"], "sentence-detokenized": "The VOICEBOX speech processing toolbox for MATLAB implements conversion and inversion as:", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 30], [31, 38], [39, 42], [43, 49], [50, 60], [61, 71], [72, 75], [76, 85], [86, 88], [88, 89]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "general-affiliation", "", false, false], [0, 0, 11, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logic", "programming", "language", "associated", "with", "artificial", "intelligence", "and", "computational", "linguistics", "."], "sentence-detokenized": "Prolog is a logic programming language associated with artificial intelligence and computational linguistics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 17], [18, 29], [30, 38], [39, 49], [50, 54], [55, 65], [66, 78], [79, 82], [83, 96], [97, 108], [108, 109]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [9, 9, "field"], [11, 13, "field"], [17, 20, "organisation"], [23, 26, "organisation"], [29, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 9, 9, "related-to", "works_with_topic", false, false], [0, 0, 11, 13, "related-to", "works_with_topic", false, false], [0, 0, 17, 20, "role", "", false, false], [0, 0, 23, 26, "role", "", false, false], [0, 0, 29, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "numerous", "awards", "for", "his", "contributions", "to", "neuroscience", "and", "psychology", ",", "including", "membership", "in", "the", "Royal", "Society", "of", "London", ",", "the", "Royal", "Society", "of", "Canada", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received numerous awards for his contributions to neuroscience and psychology, including membership in the Royal Society of London, the Royal Society of Canada and the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 35], [36, 39], [40, 43], [44, 57], [58, 60], [61, 73], [74, 77], [78, 88], [88, 89], [90, 99], [100, 110], [111, 113], [114, 117], [118, 123], [124, 131], [132, 134], [135, 141], [141, 142], [143, 146], [147, 152], [153, 160], [161, 163], [164, 170], [171, 174], [175, 178], [179, 187], [188, 195], [196, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-195", "ner": [[8, 9, "field"], [14, 15, "task"], [18, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 15, 8, 9, "part-of", "task_part_of_field", false, false], [18, 18, 8, 9, "part-of", "task_part_of_field", false, false], [20, 21, 8, 9, "part-of", "task_part_of_field", false, false], [23, 24, 8, 9, "part-of", "task_part_of_field", false, false], [26, 26, 8, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Combining", "these", "operators", "results", "in", "algorithms", "for", "many", "image", "processing", "tasks", ",", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "sharpening", ",", "image", "filtering", "and", "classification", "."], "sentence-detokenized": "Combining these operators results in algorithms for many image processing tasks, such as feature extraction, image segmentation, image sharpening, image filtering and classification.", "token2charspan": [[0, 9], [10, 15], [16, 25], [26, 33], [34, 36], [37, 47], [48, 51], [52, 56], [57, 62], [63, 73], [74, 79], [79, 80], [81, 85], [86, 88], [89, 96], [97, 107], [107, 108], [109, 114], [115, 127], [127, 128], [129, 134], [135, 145], [145, 146], [147, 152], [153, 162], [163, 166], [167, 181], [181, 182]]}
{"doc_key": "ai-test-196", "ner": [[9, 11, "university"], [19, 21, "organisation"], [23, 24, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "2017", ",", "he", "has", "been", "professor", "at", "the", "Coll\u00e8ge", "de", "France", "and", ",", "since", "1989", ",", "director", "of", "INSERM", "Unit", "562", ",", "Cognitive", "Neuroimaging", "."], "sentence-detokenized": "Since 2017, he has been professor at the Coll\u00e8ge de France and, since 1989, director of INSERM Unit 562, Cognitive Neuroimaging.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 14], [15, 18], [19, 23], [24, 33], [34, 36], [37, 40], [41, 48], [49, 51], [52, 58], [59, 62], [62, 63], [64, 69], [70, 74], [74, 75], [76, 84], [85, 87], [88, 94], [95, 99], [100, 103], [103, 104], [105, 114], [115, 127], [127, 128]]}
{"doc_key": "ai-test-197", "ner": [[11, 17, "algorithm"], [13, 18, "algorithm"], [23, 23, "algorithm"], [25, 31, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 25, 31, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "many", "approaches", "to", "learning", "these", "embeddings", ",", "notably", "using", "Bayesian", "or", "energy", "-", "based", "clustering", "frameworks", "and", ",", "more", "recently", ",", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", "2013", ")", "."], "sentence-detokenized": "There are many approaches to learning these embeddings, notably using Bayesian or energy-based clustering frameworks and, more recently, TransE (Conference on Neural Information Processing Systems 2013).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 25], [26, 28], [29, 37], [38, 43], [44, 54], [54, 55], [56, 63], [64, 69], [70, 78], [79, 81], [82, 88], [88, 89], [89, 94], [95, 105], [106, 116], [117, 120], [120, 121], [122, 126], [127, 135], [135, 136], [137, 143], [144, 145], [145, 155], [156, 158], [159, 165], [166, 177], [178, 188], [189, 196], [197, 201], [201, 202], [202, 203]]}
{"doc_key": "ai-test-198", "ner": [[6, 7, "metrics"], [8, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 8, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "is", "an", "alternative", "to", "the", "Word", "Error", "Rate", "used", "in", "several", "countries", "."], "sentence-detokenized": "It is an alternative to the Word Error Rate used in several countries.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 23], [24, 27], [28, 32], [33, 38], [39, 43], [44, 48], [49, 51], [52, 59], [60, 69], [69, 70]]}
{"doc_key": "ai-test-199", "ner": [[0, 0, "algorithm"], [11, 12, "task"], [14, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 28, "task"], [30, 31, "task"], [44, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 0, 0, "usage", "", false, false], [14, 15, 0, 0, "usage", "", false, false], [17, 18, 0, 0, "usage", "", false, false], [20, 22, 0, 0, "usage", "", false, false], [24, 28, 0, 0, "usage", "", false, false], [30, 31, 0, 0, "usage", "", false, false], [44, 44, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "have", "been", "used", "for", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "playing", "board", "and", "video", "games", ",", "medical", "diagnosis", "and", "even", "in", "activities", "traditionally", "considered", "reserved", "for", "humans", ",", "such", "as", "painting", "."], "sentence-detokenized": "ANNs have been used for a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games, medical diagnosis and even in activities traditionally considered reserved for humans, such as painting.", "token2charspan": [[0, 4], [5, 9], [10, 14], [15, 19], [20, 23], [24, 25], [26, 33], [34, 36], [37, 42], [42, 43], [44, 53], [54, 62], [63, 69], [69, 70], [71, 77], [78, 89], [89, 90], [91, 98], [99, 110], [110, 111], [112, 118], [119, 126], [127, 136], [136, 137], [138, 145], [146, 151], [152, 155], [156, 161], [162, 167], [167, 168], [169, 176], [177, 186], [187, 190], [191, 195], [196, 198], [199, 209], [210, 223], [224, 234], [235, 243], [244, 247], [248, 254], [254, 255], [256, 260], [261, 263], [264, 272], [272, 273]]}
{"doc_key": "ai-test-200", "ner": [[0, 3, "product"], [5, 8, "product"], [27, 29, "field"], [31, 31, "field"], [35, 35, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 27, 29, "related-to", "", false, false], [0, 3, 35, 35, "general-affiliation", "", false, false], [5, 8, 0, 3, "named", "", false, false], [31, 31, 27, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "is", "an", "open", "-", "source", "research", "platform", "and", "collection", "of", "algorithms", "for", "voice", ",", "sound", ",", "speech", ",", "text", "and", "natural", "language", "processing", "(", "NLP", ")", "written", "in", "Java", "and", "organised", "in", "a", "modular", "and", "extensible", "framework", "that", "seeks", "to", "facilitate", "the", "addition", "of", "new", "algorithms", "."], "sentence-detokenized": "Modular Audio Recognition Framework (MARF) is an open-source research platform and collection of algorithms for voice, sound, speech, text and natural language processing (NLP) written in Java and organised in a modular and extensible framework that seeks to facilitate the addition of new algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 25], [26, 35], [36, 37], [37, 41], [41, 42], [43, 45], [46, 48], [49, 53], [53, 54], [54, 60], [61, 69], [70, 78], [79, 82], [83, 93], [94, 96], [97, 107], [108, 111], [112, 117], [117, 118], [119, 124], [124, 125], [126, 132], [132, 133], [134, 138], [139, 142], [143, 150], [151, 159], [160, 170], [171, 172], [172, 175], [175, 176], [177, 184], [185, 187], [188, 192], [193, 196], [197, 206], [207, 209], [210, 211], [212, 219], [220, 223], [224, 234], [235, 244], [245, 249], [250, 255], [256, 258], [259, 269], [270, 273], [274, 282], [283, 285], [286, 289], [290, 300], [300, 301]]}
{"doc_key": "ai-test-201", "ner": [[11, 13, "organisation"], [17, 17, "country"], [22, 24, "organisation"], [27, 28, "organisation"], [33, 36, "task"], [53, 57, "organisation"], [50, 51, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[22, 24, 17, 17, "physical", "", false, false], [22, 24, 33, 36, "usage", "", false, false], [22, 24, 53, 57, "named", "", false, false], [27, 28, 17, 17, "physical", "", false, false], [27, 28, 33, 36, "usage", "", false, false], [53, 57, 50, 51, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "a", "report", "by", "civil", "liberties", "and", "rights", "organisation", "Big", "Brother", "Watch", "revealed", "that", "two", "UK", "police", "forces", ",", "the", "South", "Wales", "Police", "and", "the", "Metropolitan", "Police", ",", "were", "using", "live", "facial", "recognition", "at", "public", "events", "and", "in", "public", "spaces", ";", "in", "September", "2019", ",", "the", "use", "of", "facial", "recognition", "by", "the", "South", "Wales", "Police", "was", "declared", "legal", "."], "sentence-detokenized": "In 2018, a report by civil liberties and rights organisation Big Brother Watch revealed that two UK police forces, the South Wales Police and the Metropolitan Police, were using live facial recognition at public events and in public spaces; in September 2019, the use of facial recognition by the South Wales Police was declared legal.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 20], [21, 26], [27, 36], [37, 40], [41, 47], [48, 60], [61, 64], [65, 72], [73, 78], [79, 87], [88, 92], [93, 96], [97, 99], [100, 106], [107, 113], [113, 114], [115, 118], [119, 124], [125, 130], [131, 137], [138, 141], [142, 145], [146, 158], [159, 165], [165, 166], [167, 171], [172, 177], [178, 182], [183, 189], [190, 201], [202, 204], [205, 211], [212, 218], [219, 222], [223, 225], [226, 232], [233, 239], [239, 240], [241, 243], [244, 253], [254, 258], [258, 259], [260, 263], [264, 267], [268, 270], [271, 277], [278, 289], [290, 292], [293, 296], [297, 302], [303, 308], [309, 315], [316, 319], [320, 328], [329, 334], [334, 335]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [4, 6, "programlang"], [13, 14, "field"], [16, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "general-affiliation", "", false, false], [0, 0, 13, 14, "related-to", "", false, false], [0, 0, 16, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "was", "ported", "to", "R", ",", "a", "freely", "available", "language", "and", "environment", "for", "statistical", "computing", "and", "graphics", "."], "sentence-detokenized": "ANIMAL was ported to R, a freely available language and environment for statistical computing and graphics.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 22], [22, 23], [24, 25], [26, 32], [33, 42], [43, 51], [52, 55], [56, 67], [68, 71], [72, 83], [84, 93], [94, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-203", "ner": [[0, 5, "algorithm"], [7, 9, "algorithm"], [16, 18, "algorithm"], [20, 20, "algorithm"], [23, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 16, 18, "opposite", "alternative to", false, false], [7, 9, 0, 5, "named", "", false, false], [20, 20, 16, 18, "named", "", false, false], [23, 25, 0, 5, "usage", "", false, false], [23, 25, 16, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "temporally", "homogeneous", "hidden", "Bernoulli", "model", "(", "TI", "-", "HBM", ")", "is", "an", "alternative", "to", "the", "hidden", "Markov", "model", "(", "HMM", ")", "for", "automatic", "speech", "recognition", "."], "sentence-detokenized": "The temporally homogeneous hidden Bernoulli model (TI-HBM) is an alternative to the hidden Markov model (HMM) for automatic speech recognition.", "token2charspan": [[0, 3], [4, 14], [15, 26], [27, 33], [34, 43], [44, 49], [50, 51], [51, 53], [53, 54], [54, 57], [57, 58], [59, 61], [62, 64], [65, 76], [77, 79], [80, 83], [84, 90], [91, 97], [98, 103], [104, 105], [105, 108], [108, 109], [110, 113], [114, 123], [124, 130], [131, 142], [142, 143]]}
{"doc_key": "ai-test-204", "ner": [[4, 4, "organisation"], [7, 7, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 7, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "Nvidia", "demonstrated", "during", "SIGGRAPH", "a", "new", "foveated", "rendering", "method", "that", "is", "claimed", "to", "be", "invisible", "to", "users", "."], "sentence-detokenized": "In July 2016, Nvidia demonstrated during SIGGRAPH a new foveated rendering method that is claimed to be invisible to users.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 33], [34, 40], [41, 49], [50, 51], [52, 55], [56, 64], [65, 74], [75, 81], [82, 86], [87, 89], [90, 97], [98, 100], [101, 103], [104, 113], [114, 116], [117, 122], [122, 123]]}
{"doc_key": "ai-test-205", "ner": [[5, 7, "misc"], [10, 11, "researcher"], [18, 19, "researcher"], [21, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 10, 11, "origin", "", false, false], [5, 7, 18, 19, "origin", "", false, false], [5, 7, 21, 21, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Both", "are", "based", "on", "the", "speech", "act", "theory", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "improved", "by", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both are based on the speech act theory developed by John Searle in the 1960s and improved by Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 17], [18, 21], [22, 28], [29, 32], [33, 39], [40, 49], [50, 52], [53, 57], [58, 64], [65, 67], [68, 71], [72, 77], [78, 81], [82, 90], [91, 93], [94, 99], [100, 108], [109, 112], [113, 119], [120, 122], [123, 126], [127, 132], [132, 133]]}
{"doc_key": "ai-test-206", "ner": [[0, 2, "algorithm"], [21, 22, "researcher"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 21, 22, "related-to", "", false, false], [24, 24, 21, 22, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "knowledge", "structure", "have", "opened", "up", "powerful", "hierarchical", "models", "of", "knowledge", "organisation", ",", "such", "as", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "Neural network models of concept formation and knowledge structure have opened up powerful hierarchical models of knowledge organisation, such as George Miller's Wordnet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 56], [57, 66], [67, 71], [72, 78], [79, 81], [82, 90], [91, 103], [104, 110], [111, 113], [114, 123], [124, 136], [136, 137], [138, 142], [143, 145], [146, 152], [153, 159], [159, 161], [162, 169], [169, 170]]}
{"doc_key": "ai-test-207", "ner": [[0, 2, "algorithm"], [12, 12, "field"], [13, 18, "product"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 12, 12, "part-of", "", false, false], [0, 2, 21, 23, "part-of", "", false, false], [13, 18, 12, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Pattern", "matching", "has", "several", "applications", "and", "is", "used", "in", "fields", "such", "as", "face", "recognition", "(", "see", "facial", "recognition", "system", ")", "and", "medical", "image", "processing", "."], "sentence-detokenized": "Pattern matching has several applications and is used in fields such as face recognition (see facial recognition system) and medical image processing.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 28], [29, 41], [42, 45], [46, 48], [49, 53], [54, 56], [57, 63], [64, 68], [69, 71], [72, 76], [77, 88], [89, 90], [90, 93], [94, 100], [101, 112], [113, 119], [119, 120], [121, 124], [125, 132], [133, 138], [139, 149], [149, 150]]}
{"doc_key": "ai-test-208", "ner": [[12, 13, "researcher"], [15, 16, "researcher"], [21, 30, "organisation"], [32, 32, "organisation"], [40, 41, "algorithm"], [44, 50, "conference"], [52, 52, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 13, 21, 30, "role", "", false, false], [12, 13, 44, 50, "physical", "", false, false], [12, 13, 44, 50, "temporal", "", false, false], [12, 13, 52, 52, "physical", "", false, false], [15, 16, 21, 30, "role", "", false, false], [15, 16, 44, 50, "temporal", "", false, false], [32, 32, 21, 30, "named", "", false, false], [44, 50, 40, 41, "topic", "", false, false], [52, 52, 44, 50, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "it", "s", "use", "only", "became", "widespread", "in", "2005", ",", "when", "Navneet", "Dalal", "and", "Bill", "Triggs", ",", "researchers", "at", "the", "French", "National", "Institute", "for", "Research", "in", "Computer", "Science", "and", "Automation", "(", "INRIA", ")", ",", "presented", "their", "additional", "work", "on", "HOG", "descriptors", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "However, its use only became widespread in 2005, when Navneet Dalal and Bill Triggs, researchers at the French National Institute for Research in Computer Science and Automation (INRIA), presented their additional work on HOG descriptors at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 7], [7, 8], [9, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 39], [40, 42], [43, 47], [47, 48], [49, 53], [54, 61], [62, 67], [68, 71], [72, 76], [77, 83], [83, 84], [85, 96], [97, 99], [100, 103], [104, 110], [111, 119], [120, 129], [130, 133], [134, 142], [143, 145], [146, 154], [155, 162], [163, 166], [167, 177], [178, 179], [179, 184], [184, 185], [185, 186], [187, 196], [197, 202], [203, 213], [214, 218], [219, 221], [222, 225], [226, 237], [238, 240], [241, 244], [245, 255], [256, 258], [259, 267], [268, 274], [275, 278], [279, 286], [287, 298], [299, 300], [300, 304], [304, 305], [305, 306]]}
{"doc_key": "ai-test-209", "ner": [[4, 4, "university"], [17, 20, "organisation"], [22, 23, "organisation"], [30, 30, "field"], [36, 38, "researcher"], [40, 43, "researcher"], [45, 47, "researcher"], [51, 54, "organisation"], [59, 61, "organisation"], [66, 67, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[22, 23, 30, 30, "related-to", "", false, false], [36, 38, 22, 23, "physical", "", false, false], [36, 38, 22, 23, "role", "", false, false], [40, 43, 22, 23, "physical", "", false, false], [40, 43, 22, 23, "role", "", false, false], [45, 47, 22, 23, "physical", "", false, false], [45, 47, 22, 23, "role", "", false, false], [66, 67, 59, 61, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Prior", "to", "joining", "the", "Penn", "faculty", "in", "2002", ",", "he", "spent", "a", "decade", "(", "1991-2001", ")", "at", "AT", "&", "T", "Labs", "and", "Bell", "Labs", ",", "including", "as", "head", "of", "the", "AI", "department", "with", "colleagues", "such", "as", "Michael", "L.", "Littman", ",", "David", "A", ".", "McAllester", "and", "Richard", "S.", "Sutton", ";", "of", "the", "secure", "systems", "research", "department", ";", "and", "of", "the", "machine", "learning", "department", "with", "members", "such", "as", "Michael", "Collins", "and", "the", "leader", ")", "."], "sentence-detokenized": "Prior to joining the Penn faculty in 2002, he spent a decade (1991-2001) at AT & T Labs and Bell Labs, including as head of the AI department with colleagues such as Michael L. Littman, David A. McAllester and Richard S. Sutton; of the secure systems research department; and of the machine learning department with members such as Michael Collins and the leader).", "token2charspan": [[0, 5], [6, 8], [9, 16], [17, 20], [21, 25], [26, 33], [34, 36], [37, 41], [41, 42], [43, 45], [46, 51], [52, 53], [54, 60], [61, 62], [62, 71], [71, 72], [73, 75], [76, 78], [79, 80], [81, 82], [83, 87], [88, 91], [92, 96], [97, 101], [101, 102], [103, 112], [113, 115], [116, 120], [121, 123], [124, 127], [128, 130], [131, 141], [142, 146], [147, 157], [158, 162], [163, 165], [166, 173], [174, 176], [177, 184], [184, 185], [186, 191], [192, 193], [193, 194], [195, 205], [206, 209], [210, 217], [218, 220], [221, 227], [227, 228], [229, 231], [232, 235], [236, 242], [243, 250], [251, 259], [260, 270], [270, 271], [272, 275], [276, 278], [279, 282], [283, 290], [291, 299], [300, 310], [311, 315], [316, 323], [324, 328], [329, 331], [332, 339], [340, 347], [348, 351], [352, 355], [356, 362], [362, 363], [363, 364]]}
{"doc_key": "ai-test-210", "ner": [[6, 8, "field"], [13, 14, "field"], [23, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 8, 13, 14, "compare", "", false, false], [23, 23, 13, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["When", "data", "are", "not", "labelled", ",", "supervised", "learning", "is", "not", "possible", "and", "an", "unsupervised", "learning", "approach", "is", "required", "to", "find", "a", "natural", "cluster", "analysis", "and", "then", "map", "new", "data", "into", "these", "formed", "clusters", "."], "sentence-detokenized": "When data are not labelled, supervised learning is not possible and an unsupervised learning approach is required to find a natural cluster analysis and then map new data into these formed clusters.", "token2charspan": [[0, 4], [5, 9], [10, 13], [14, 17], [18, 26], [26, 27], [28, 38], [39, 47], [48, 50], [51, 54], [55, 63], [64, 67], [68, 70], [71, 83], [84, 92], [93, 101], [102, 104], [105, 113], [114, 116], [117, 121], [122, 123], [124, 131], [132, 139], [140, 148], [149, 152], [153, 157], [158, 161], [162, 165], [166, 170], [171, 175], [176, 181], [182, 188], [189, 197], [197, 198]]}
{"doc_key": "ai-test-211", "ner": [[3, 4, "field"], [15, 18, "organisation"], [25, 26, "field"], [28, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 15, 18, "origin", "", false, false], [3, 4, 25, 26, "part-of", "", false, false], [3, 4, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "field", "of", "computer", "science", "developed", "in", "the", "1950s", "at", "academic", "institutions", "such", "as", "the", "MIT", "A.I", ".", "Lab", ",", "originally", "as", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "This field of computer science developed in the 1950s at academic institutions such as the MIT A.I. Lab, originally as a branch of artificial intelligence and robotics.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 30], [31, 40], [41, 43], [44, 47], [48, 53], [54, 56], [57, 65], [66, 78], [79, 83], [84, 86], [87, 90], [91, 94], [95, 98], [98, 99], [100, 103], [103, 104], [105, 115], [116, 118], [119, 120], [121, 127], [128, 130], [131, 141], [142, 154], [155, 158], [159, 167], [167, 168]]}
{"doc_key": "ai-test-212", "ner": [[7, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["One", "could", "also", "replace", "it", "with", "the", "logical", "loss", "equation", "below", ":"], "sentence-detokenized": "One could also replace it with the logical loss equation below:", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 22], [23, 25], [26, 30], [31, 34], [35, 42], [43, 47], [48, 56], [57, 62], [62, 63]]}
{"doc_key": "ai-test-213", "ner": [[1, 3, "organisation"], [7, 10, "organisation"], [14, 18, "university"], [20, 20, "university"], [22, 23, "university"], [26, 28, "university"], [31, 31, "country"], [36, 36, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 3, 36, 36, "related-to", "research_leader_in_field", false, false], [7, 10, 1, 3, "named", "", false, false], [7, 10, 36, 36, "related-to", "research_leader_in_field", false, false], [14, 18, 36, 36, "related-to", "research_leader_in_field", false, false], [20, 20, 36, 36, "related-to", "research_leader_in_field", false, false], [22, 23, 36, 36, "related-to", "research_leader_in_field", false, false], [26, 28, 31, 31, "physical", "", false, false], [26, 28, 36, 36, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "Shirley", "Ryan", "AbilityLab", "(", "formerly", "the", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "the", "University", "of", "California", "at", "Berkeley", ",", "MIT", ",", "Stanford", "University", "and", "the", "University", "of", "Twente", "in", "the", "Netherlands", "are", "the", "leaders", "in", "biomechatronics", "research", "."], "sentence-detokenized": "The Shirley Ryan AbilityLab (formerly the Rehabilitation Institute of Chicago), the University of California at Berkeley, MIT, Stanford University and the University of Twente in the Netherlands are the leaders in biomechatronics research.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 27], [28, 29], [29, 37], [38, 41], [42, 56], [57, 66], [67, 69], [70, 77], [77, 78], [78, 79], [80, 83], [84, 94], [95, 97], [98, 108], [109, 111], [112, 120], [120, 121], [122, 125], [125, 126], [127, 135], [136, 146], [147, 150], [151, 154], [155, 165], [166, 168], [169, 175], [176, 178], [179, 182], [183, 194], [195, 198], [199, 202], [203, 210], [211, 213], [214, 229], [230, 238], [238, 239]]}
{"doc_key": "ai-test-214", "ner": [[28, 32, "metrics"], [42, 43, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Given", "a", "set", "of", "predicted", "values", "and", "a", "corresponding", "set", "of", "actual", "values", "for", "X", "for", "various", "time", "periods", ",", "a", "common", "evaluation", "technique", "is", "to", "use", "the", "mean", "square", "error", "of", "prediction", ";", "other", "measures", "are", "also", "available", "(", "see", "prediction", "#prediction", "accuracy", ")", "."], "sentence-detokenized": "Given a set of predicted values and a corresponding set of actual values for X for various time periods, a common evaluation technique is to use the mean square error of prediction; other measures are also available (see prediction #prediction accuracy).", "token2charspan": [[0, 5], [6, 7], [8, 11], [12, 14], [15, 24], [25, 31], [32, 35], [36, 37], [38, 51], [52, 55], [56, 58], [59, 65], [66, 72], [73, 76], [77, 78], [79, 82], [83, 90], [91, 95], [96, 103], [103, 104], [105, 106], [107, 113], [114, 124], [125, 134], [135, 137], [138, 140], [141, 144], [145, 148], [149, 153], [154, 160], [161, 166], [167, 169], [170, 180], [180, 181], [182, 187], [188, 196], [197, 200], [201, 205], [206, 215], [216, 217], [217, 220], [221, 231], [232, 243], [244, 252], [252, 253], [253, 254]]}
{"doc_key": "ai-test-215", "ner": [[15, 15, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "measures", ",", "such", "as", "the", "percentage", "of", "correct", "predictions", "(", "also", "referred", "to", "as", "accuracy", ")", ",", "are", "not", "useful", "when", "the", "two", "classes", "are", "of", "very", "different", "sizes", "."], "sentence-detokenized": "Other measures, such as the percentage of correct predictions (also referred to as accuracy), are not useful when the two classes are of very different sizes.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 20], [21, 23], [24, 27], [28, 38], [39, 41], [42, 49], [50, 61], [62, 63], [63, 67], [68, 76], [77, 79], [80, 82], [83, 91], [91, 92], [92, 93], [94, 97], [98, 101], [102, 108], [109, 113], [114, 117], [118, 121], [122, 129], [130, 133], [134, 136], [137, 141], [142, 151], [152, 157], [157, 158]]}
{"doc_key": "ai-test-216", "ner": [[5, 9, "product"], [15, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 9, 15, 20, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "released", "to", "the", "public", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "in", "2000", ",", "while", "five", "beta", "versions", "were", "released", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was released to the public at the Conference on Computer Vision and Pattern Recognition in 2000, while five beta versions were released between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 46], [47, 49], [50, 53], [54, 60], [61, 63], [64, 67], [68, 78], [79, 81], [82, 90], [91, 97], [98, 101], [102, 109], [110, 121], [122, 124], [125, 129], [129, 130], [131, 136], [137, 141], [142, 146], [147, 155], [156, 160], [161, 169], [170, 177], [178, 182], [183, 186], [187, 191], [191, 192]]}
{"doc_key": "ai-test-217", "ner": [[19, 19, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Results", "were", "presented", "giving", "a", "correlation", "of", "up", "to", "0.964", "with", "human", "judgement", "at", "corpus", "level", ",", "compared", "to", "BLEU", "'s", "result", "of", "0.817", "on", "the", "same", "dataset", "."], "sentence-detokenized": "Results were presented giving a correlation of up to 0.964 with human judgement at corpus level, compared to BLEU's result of 0.817 on the same dataset.", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 29], [30, 31], [32, 43], [44, 46], [47, 49], [50, 52], [53, 58], [59, 63], [64, 69], [70, 79], [80, 82], [83, 89], [90, 95], [95, 96], [97, 105], [106, 108], [109, 113], [113, 115], [116, 122], [123, 125], [126, 131], [132, 134], [135, 138], [139, 143], [144, 151], [151, 152]]}
{"doc_key": "ai-test-218", "ner": [[4, 8, "metrics"], [18, 18, "metrics"], [20, 22, "metrics"], [24, 27, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 8, 18, 18, "compare", "", false, false], [4, 8, 20, 22, "compare", "", false, false], [4, 8, 24, 27, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["An", "early", "version", "of", "VMAF", "has", "been", "shown", "to", "outperform", "other", "image", "and", "video", "quality", "metrics", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", "and", "VQM", "-", "VFD", "on", "three", "of", "the", "four", "datasets", "in", "terms", "of", "prediction", "accuracy", ",", "when", "compared", "to", "subjective", "evaluations", "."], "sentence-detokenized": "An early version of VMAF has been shown to outperform other image and video quality metrics such as SSIM, PSNR -HVS and VQM-VFD on three of the four datasets in terms of prediction accuracy, when compared to subjective evaluations.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 19], [20, 24], [25, 28], [29, 33], [34, 39], [40, 42], [43, 53], [54, 59], [60, 65], [66, 69], [70, 75], [76, 83], [84, 91], [92, 96], [97, 99], [100, 104], [104, 105], [106, 110], [111, 112], [112, 115], [116, 119], [120, 123], [123, 124], [124, 127], [128, 130], [131, 136], [137, 139], [140, 143], [144, 148], [149, 157], [158, 160], [161, 166], [167, 169], [170, 180], [181, 189], [189, 190], [191, 195], [196, 204], [205, 207], [208, 218], [219, 230], [230, 231]]}
{"doc_key": "ai-test-219", "ner": [[18, 19, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 25, 26, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "of", "'", "mouse", "'", "(", "animal", "or", "device", ")", "is", "not", "relevant", "in", "machine", "translation", ",", "but", "is", "relevant", "in", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity of 'mouse' (animal or device) is not relevant in machine translation, but is relevant in information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 31], [31, 36], [36, 37], [38, 39], [39, 45], [46, 48], [49, 55], [55, 56], [57, 59], [60, 63], [64, 72], [73, 75], [76, 83], [84, 95], [95, 96], [97, 100], [101, 103], [104, 112], [113, 115], [116, 127], [128, 137], [137, 138]]}
{"doc_key": "ai-test-220", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [10, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 1, "usage", "", false, false], [10, 15, 6, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "hashing", "was", "originally", "proposed", "in", "computer", "vision", "for", "the", "recognition", "of", "2D", "and", "3D", "objects", ","], "sentence-detokenized": "Geometric hashing was originally proposed in computer vision for the recognition of 2D and 3D objects,", "token2charspan": [[0, 9], [10, 17], [18, 21], [22, 32], [33, 41], [42, 44], [45, 53], [54, 60], [61, 64], [65, 68], [69, 80], [81, 83], [84, 86], [87, 90], [91, 93], [94, 101], [101, 102]]}
{"doc_key": "ai-test-221", "ner": [[9, 10, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 9, 10, "part-of", "subfield", false, false], [17, 18, 9, 10, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "constitutes", "one", "of", "the", "three", "main", "categories", "of", "machine", "learning", ",", "together", "with", "supervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "It constitutes one of the three main categories of machine learning, together with supervised learning and reinforcement learning.", "token2charspan": [[0, 2], [3, 14], [15, 18], [19, 21], [22, 25], [26, 31], [32, 36], [37, 47], [48, 50], [51, 58], [59, 67], [67, 68], [69, 77], [78, 82], [83, 93], [94, 102], [103, 106], [107, 120], [121, 129], [129, 130]]}
{"doc_key": "ai-test-222", "ner": [[0, 1, "field"], [17, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 31, "field"], [33, 34, "field"], [36, 37, "field"], [39, 39, "field"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 1, 17, 17, "part-of", "subfield", false, false], [0, 1, 19, 20, "part-of", "subfield", false, false], [0, 1, 22, 23, "part-of", "subfield", false, false], [0, 1, 25, 26, "part-of", "subfield", false, false], [0, 1, 28, 31, "part-of", "subfield", false, false], [0, 1, 33, 34, "part-of", "subfield", false, false], [0, 1, 36, 37, "part-of", "subfield", false, false], [0, 1, 39, 39, "part-of", "subfield", false, false], [0, 1, 41, 42, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Reinforcement", "learning", ",", "due", "to", "its", "generality", ",", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "games", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Reinforcement learning, due to its generality, is studied in many other disciplines, such as games, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 13], [14, 22], [22, 23], [24, 27], [28, 30], [31, 34], [35, 45], [45, 46], [47, 49], [50, 57], [58, 60], [61, 65], [66, 71], [72, 83], [83, 84], [85, 89], [90, 92], [93, 98], [98, 99], [100, 107], [108, 114], [114, 115], [116, 126], [127, 135], [135, 136], [137, 148], [149, 155], [155, 156], [157, 167], [167, 168], [168, 173], [174, 186], [186, 187], [188, 199], [200, 207], [207, 208], [209, 214], [215, 227], [227, 228], [229, 239], [240, 243], [244, 251], [252, 262], [262, 263]]}
{"doc_key": "ai-test-223", "ner": [[0, 1, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "related-to", "", false, false], [0, 1, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pattern", "recognition", "is", "closely", "linked", "to", "artificial", "intelligence", "and", "machine", "learning", ","], "sentence-detokenized": "Pattern recognition is closely linked to artificial intelligence and machine learning,", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 37], [38, 40], [41, 51], [52, 64], [65, 68], [69, 76], [77, 85], [85, 86]]}
{"doc_key": "ai-test-224", "ner": [[10, 11, "algorithm"], [14, 17, "field"], [16, 16, "field"], [29, 30, "task"], [32, 32, "task"], [34, 35, "task"], [37, 38, "algorithm"], [40, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 14, 17, "related-to", "", false, false], [10, 11, 16, 16, "related-to", "", false, false], [29, 30, 10, 11, "usage", "", true, false], [32, 32, 10, 11, "usage", "", true, false], [34, 35, 10, 11, "usage", "", true, false], [37, 38, 10, 11, "usage", "", true, false], [40, 42, 10, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "software", "is", "used", "to", "design", ",", "train", "and", "deploy", "neural", "network", "models", "(", "supervised", "and", "unsupervised", "learning", ")", "to", "perform", "a", "wide", "range", "of", "tasks", ",", "such", "as", "data", "mining", ",", "classification", ",", "function", "approximation", ",", "multivariate", "regression", "and", "time", "series", "prediction", "."], "sentence-detokenized": "The software is used to design, train and deploy neural network models (supervised and unsupervised learning) to perform a wide range of tasks, such as data mining, classification, function approximation, multivariate regression and time series prediction.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [21, 23], [24, 30], [30, 31], [32, 37], [38, 41], [42, 48], [49, 55], [56, 63], [64, 70], [71, 72], [72, 82], [83, 86], [87, 99], [100, 108], [108, 109], [110, 112], [113, 120], [121, 122], [123, 127], [128, 133], [134, 136], [137, 142], [142, 143], [144, 148], [149, 151], [152, 156], [157, 163], [163, 164], [165, 179], [179, 180], [181, 189], [190, 203], [203, 204], [205, 217], [218, 228], [229, 232], [233, 237], [238, 244], [245, 255], [255, 256]]}
{"doc_key": "ai-test-225", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016, he was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-test-226", "ner": [[6, 9, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", "and", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", ","], "sentence-detokenized": "He is a member of the National Academy of Sciences (since 2005) and the American Academy of Arts and Sciences (since 2009),", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 50], [51, 52], [52, 57], [58, 62], [62, 63], [64, 67], [68, 71], [72, 80], [81, 88], [89, 91], [92, 96], [97, 100], [101, 109], [110, 111], [111, 116], [117, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-test-227", "ner": [[3, 5, "misc"], [9, 14, "product"], [17, 17, "country"], [19, 19, "country"], [22, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 14, 3, 5, "temporal", "", false, false], [9, 14, 17, 17, "physical", "", false, false], [9, 14, 19, 19, "physical", "", false, false], [9, 14, 22, 24, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "the", "1973", "Yom", "Kippur", "war", ",", "Soviet", "-supplied", "surface", "-", "to", "-", "air", "missile", "batteries", "in", "Egypt", "and", "Syria", "heavily", "damaged", "Israeli", "fighter", "jets", "."], "sentence-detokenized": "During the 1973 Yom Kippur war, Soviet-supplied surface-to-air missile batteries in Egypt and Syria heavily damaged Israeli fighter jets.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 26], [27, 30], [30, 31], [32, 38], [38, 47], [48, 55], [55, 56], [56, 58], [58, 59], [59, 62], [63, 70], [71, 80], [81, 83], [84, 89], [90, 93], [94, 99], [100, 107], [108, 115], [116, 123], [124, 131], [132, 136], [136, 137]]}
{"doc_key": "ai-test-228", "ner": [[9, 10, "product"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "(", "free", "but", "copyrighted", ")", "resource", "is", "the", "HTK", "book", "(", "and", "the", "accompanying", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another (free but copyrighted) resource is the HTK book (and the accompanying HTK toolkit).", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 17], [18, 29], [29, 30], [31, 39], [40, 42], [43, 46], [47, 50], [51, 55], [56, 57], [57, 60], [61, 64], [65, 77], [78, 81], [82, 89], [89, 90], [90, 91]]}
{"doc_key": "ai-test-229", "ner": [[5, 9, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "were", "taken", "at", "the", "AAAI", "spring", "symposium", "in", "2004", ",", "where", "linguists", ",", "computer", "scientists", "and", "other", "interested", "researchers", "aligned", "interests", "for", "the", "first", "time", "and", "proposed", "shared", "tasks", "and", "reference", "datasets", "for", "systematic", "computational", "research", "on", "affect", ",", "attractiveness", ",", "subjectivity", "and", "sentiment", "in", "texts", "."], "sentence-detokenized": "- were taken at the AAAI spring symposium in 2004, where linguists, computer scientists and other interested researchers aligned interests for the first time and proposed shared tasks and reference datasets for systematic computational research on affect, attractiveness, subjectivity and sentiment in texts.", "token2charspan": [[0, 1], [2, 6], [7, 12], [13, 15], [16, 19], [20, 24], [25, 31], [32, 41], [42, 44], [45, 49], [49, 50], [51, 56], [57, 66], [66, 67], [68, 76], [77, 87], [88, 91], [92, 97], [98, 108], [109, 120], [121, 128], [129, 138], [139, 142], [143, 146], [147, 152], [153, 157], [158, 161], [162, 170], [171, 177], [178, 183], [184, 187], [188, 197], [198, 206], [207, 210], [211, 221], [222, 235], [236, 244], [245, 247], [248, 254], [254, 255], [256, 270], [270, 271], [272, 284], [285, 288], [289, 298], [299, 301], [302, 307], [307, 308]]}
{"doc_key": "ai-test-230", "ner": [[10, 12, "task"], [22, 22, "task"], [23, 27, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "single", "grid", "can", "be", "analysed", "for", "both", "content", "(", "inspection", "by", "eye", ")", "and", "structure", "(", "the", "main", "techniques", "used", "are", "cluster", "analysis", ",", "principal", "component", "analysis", "and", "a", "series", "of", "structural", "indices", "relating", "to", "the", "complexity", "and", "range", "of", "ratings", ")", "."], "sentence-detokenized": "A single grid can be analysed for both content (inspection by eye) and structure (the main techniques used are cluster analysis, principal component analysis and a series of structural indices relating to the complexity and range of ratings).", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 17], [18, 20], [21, 29], [30, 33], [34, 38], [39, 46], [47, 48], [48, 58], [59, 61], [62, 65], [65, 66], [67, 70], [71, 80], [81, 82], [82, 85], [86, 90], [91, 101], [102, 106], [107, 110], [111, 118], [119, 127], [127, 128], [129, 138], [139, 148], [149, 157], [158, 161], [162, 163], [164, 170], [171, 173], [174, 184], [185, 192], [193, 201], [202, 204], [205, 208], [209, 219], [220, 223], [224, 229], [230, 232], [233, 240], [240, 241], [241, 242]]}
{"doc_key": "ai-test-231", "ner": [[3, 4, "organisation"], [11, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", ",", "Toyota", "was", "considered", "to", "be", "lagging", "behind", "in", "autonomous", "driving", "and", "in", "need", "of", "innovation", "."], "sentence-detokenized": "In 2018, Toyota was considered to be lagging behind in autonomous driving and in need of innovation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 30], [31, 33], [34, 36], [37, 44], [45, 51], [52, 54], [55, 65], [66, 73], [74, 77], [78, 80], [81, 85], [86, 88], [89, 99], [99, 100]]}
{"doc_key": "ai-test-232", "ner": [[41, 44, "misc"], [46, 47, "misc"], [49, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "targets", "include", "natural", "objects", "such", "as", "the", "ground", ",", "the", "sea", ",", "precipitation", "(", "such", "as", "rain", ",", "snow", "or", "hail", ")", ",", "sandstorms", ",", "animals", "(", "especially", "birds", ")", ",", "atmospheric", "turbulence", "and", "other", "atmospheric", "effects", ",", "such", "as", "reflections", "from", "the", "ionosphere", ",", "meteor", "trails", "and", "three", "-", "body", "scatter", "peaks", "."], "sentence-detokenized": "Such targets include natural objects such as the ground, the sea, precipitation (such as rain, snow or hail), sandstorms, animals (especially birds), atmospheric turbulence and other atmospheric effects, such as reflections from the ionosphere, meteor trails and three-body scatter peaks.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 28], [29, 36], [37, 41], [42, 44], [45, 48], [49, 55], [55, 56], [57, 60], [61, 64], [64, 65], [66, 79], [80, 81], [81, 85], [86, 88], [89, 93], [93, 94], [95, 99], [100, 102], [103, 107], [107, 108], [108, 109], [110, 120], [120, 121], [122, 129], [130, 131], [131, 141], [142, 147], [147, 148], [148, 149], [150, 161], [162, 172], [173, 176], [177, 182], [183, 194], [195, 202], [202, 203], [204, 208], [209, 211], [212, 223], [224, 228], [229, 232], [233, 243], [243, 244], [245, 251], [252, 258], [259, 262], [263, 268], [268, 269], [269, 273], [274, 281], [282, 287], [287, 288]]}
{"doc_key": "ai-test-233", "ner": [[18, 18, "product"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "planning", "and", "control", ",", "the", "essential", "difference", "between", "humanoids", "and", "other", "types", "of", "robots", "(", "such", "as", "industrial", "robots", ")", "is", "that", "the", "robot", "'s", "movement", "must", "be", "human", "-", "like", ",", "using", "leg", "locomotion", ",", "particularly", "bipedal", "gait", "."], "sentence-detokenized": "In planning and control, the essential difference between humanoids and other types of robots (such as industrial robots) is that the robot's movement must be human-like, using leg locomotion, particularly bipedal gait.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 23], [23, 24], [25, 28], [29, 38], [39, 49], [50, 57], [58, 67], [68, 71], [72, 77], [78, 83], [84, 86], [87, 93], [94, 95], [95, 99], [100, 102], [103, 113], [114, 120], [120, 121], [122, 124], [125, 129], [130, 133], [134, 139], [139, 141], [142, 150], [151, 155], [156, 158], [159, 164], [164, 165], [165, 169], [169, 170], [171, 176], [177, 180], [181, 191], [191, 192], [193, 205], [206, 213], [214, 218], [218, 219]]}
{"doc_key": "ai-test-234", "ner": [[0, 1, "algorithm"], [9, 10, "misc"], [14, 14, "metrics"], [17, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Gradient", "descent", "may", "require", "many", "iterations", "to", "calculate", "a", "local", "minimum", "with", "the", "required", "precision", "if", "the", "curvature", "in", "different", "directions", "is", "very", "different", "for", "the", "given", "function", "."], "sentence-detokenized": "Gradient descent may require many iterations to calculate a local minimum with the required precision if the curvature in different directions is very different for the given function.", "token2charspan": [[0, 8], [9, 16], [17, 20], [21, 28], [29, 33], [34, 44], [45, 47], [48, 57], [58, 59], [60, 65], [66, 73], [74, 78], [79, 82], [83, 91], [92, 101], [102, 104], [105, 108], [109, 118], [119, 121], [122, 131], [132, 142], [143, 145], [146, 150], [151, 160], [161, 164], [165, 168], [169, 174], [175, 183], [183, 184]]}
{"doc_key": "ai-test-235", "ner": [[1, 7, "misc"], [10, 10, "misc"], [17, 22, "conference"], [25, 25, "location"], [27, 27, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 7, 10, 10, "part-of", "", true, false], [17, 22, 25, 25, "physical", "", false, true], [25, 25, 27, 27, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "1997", "RoboCup", "2D", "Soccer", "Simulation", "League", "was", "the", "first", "RoboCup", "competition", "held", "in", "conjunction", "with", "the", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", "held", "in", "Nagoya", ",", "Japan", ",", "from", "23", "-", "29", "August", "1997", "."], "sentence-detokenized": "The 1997 RoboCup 2D Soccer Simulation League was the first RoboCup competition held in conjunction with the International Joint Conference on Artificial Intelligence held in Nagoya, Japan, from 23-29 August 1997.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 19], [20, 26], [27, 37], [38, 44], [45, 48], [49, 52], [53, 58], [59, 66], [67, 78], [79, 83], [84, 86], [87, 98], [99, 103], [104, 107], [108, 121], [122, 127], [128, 138], [139, 141], [142, 152], [153, 165], [166, 170], [171, 173], [174, 180], [180, 181], [182, 187], [187, 188], [189, 193], [194, 196], [196, 197], [197, 199], [200, 206], [207, 211], [211, 212]]}
{"doc_key": "ai-test-236", "ner": [[6, 6, "programlang"], [10, 10, "programlang"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "options", "include", "an", "integrated", "Python", "environment", "and", "an", "R", "console", "with", "support", "for", "Rserve", "."], "sentence-detokenized": "Other programming options include an integrated Python environment and an R console with support for Rserve.", "token2charspan": [[0, 5], [6, 17], [18, 25], [26, 33], [34, 36], [37, 47], [48, 54], [55, 66], [67, 70], [71, 73], [74, 75], [76, 83], [84, 88], [89, 96], [97, 100], [101, 107], [107, 108]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [10, 11, "field"], [13, 13, "field"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 23, "researcher"], [34, 35, "field"], [39, 40, "field"], [43, 44, "field"], [48, 49, "field"], [53, 56, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[16, 17, 13, 13, "related-to", "contributes_to_field", true, false], [19, 20, 13, 13, "related-to", "contributes_to_field", true, false], [22, 23, 13, 13, "related-to", "contributes_to_field", true, false], [43, 44, 39, 40, "part-of", "", false, false], [48, 49, 43, 44, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["From", "Bonn", ",", "he", "has", "been", "a", "key", "contributor", "to", "artificial", "intelligence", "and", "robotics", "(", "with", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Thrun", "among", "his", "students", ")", ",", "and", "to", "the", "development", "of", "software", "engineering", ",", "particularly", "in", "civil", "engineering", ",", "and", "information", "systems", ",", "particularly", "in", "geosciences", ".", "won", "the", "2016.2014", "AAAI", "Classic", "Paper", "award", "."], "sentence-detokenized": "From Bonn, he has been a key contributor to artificial intelligence and robotics (with Wolfram Burgard, Dieter Fox, Sebastian Thrun among his students), and to the development of software engineering, particularly in civil engineering, and information systems, particularly in geosciences. won the 2016.2014 AAAI Classic Paper award.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 13], [14, 17], [18, 22], [23, 24], [25, 28], [29, 40], [41, 43], [44, 54], [55, 67], [68, 71], [72, 80], [81, 82], [82, 86], [87, 94], [95, 102], [102, 103], [104, 110], [111, 114], [114, 115], [116, 125], [126, 131], [132, 137], [138, 141], [142, 150], [150, 151], [151, 152], [153, 156], [157, 159], [160, 163], [164, 175], [176, 178], [179, 187], [188, 199], [199, 200], [201, 213], [214, 216], [217, 222], [223, 234], [234, 235], [236, 239], [240, 251], [252, 259], [259, 260], [261, 273], [274, 276], [277, 288], [288, 289], [290, 293], [294, 297], [298, 307], [308, 312], [313, 320], [321, 326], [327, 332], [332, 333]]}
{"doc_key": "ai-test-238", "ner": [[2, 10, "conference"], [18, 19, "location"], [21, 21, "location"], [23, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 10, 18, 19, "physical", "", false, false], [18, 19, 21, 21, "physical", "", false, false], [21, 21, 23, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "US", "edition", "of", "the", "Campus", "Party", "will", "be", "held", "from", "20", "to", "22", "August", "at", "the", "TCF", "Center", "in", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "The first US edition of the Campus Party will be held from 20 to 22 August at the TCF Center in Detroit, Michigan.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 20], [21, 23], [24, 27], [28, 34], [35, 40], [41, 45], [46, 48], [49, 53], [54, 58], [59, 61], [62, 64], [65, 67], [68, 74], [75, 77], [78, 81], [82, 85], [86, 92], [93, 95], [96, 103], [103, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-239", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 13, "misc"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 12, 13, "win-defeat", "", false, false], [5, 6, 12, 13, "win-defeat", "", false, false], [8, 8, 12, 13, "win-defeat", "", false, false], [12, 13, 22, 24, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Together", "with", "Yann", "LeCun", "and", "Yoshua", "Bengio", ",", "Hinton", "won", "the", "2018", "Turing", "Prize", "for", "conceptual", "and", "engineering", "breakthroughs", "that", "have", "made", "deep", "neural", "networks", "a", "fundamental", "component", "of", "computer", "science", "."], "sentence-detokenized": "Together with Yann LeCun and Yoshua Bengio, Hinton won the 2018 Turing Prize for conceptual and engineering breakthroughs that have made deep neural networks a fundamental component of computer science.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 24], [25, 28], [29, 35], [36, 42], [42, 43], [44, 50], [51, 54], [55, 58], [59, 63], [64, 70], [71, 76], [77, 80], [81, 91], [92, 95], [96, 107], [108, 121], [122, 126], [127, 131], [132, 136], [137, 141], [142, 148], [149, 157], [158, 159], [160, 171], [172, 181], [182, 184], [185, 193], [194, 201], [201, 202]]}
{"doc_key": "ai-test-240", "ner": [[0, 2, "product"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Euler", "Math", "Toolbox", "uses", "a", "matrix", "language", "similar", "to", "MATLAB", ",", "a", "system", "that", "has", "been", "under", "development", "since", "the", "1970s", "."], "sentence-detokenized": "Euler Math Toolbox uses a matrix language similar to MATLAB, a system that has been under development since the 1970s.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 23], [24, 25], [26, 32], [33, 41], [42, 49], [50, 52], [53, 59], [59, 60], [61, 62], [63, 69], [70, 74], [75, 78], [79, 83], [84, 89], [90, 101], [102, 107], [108, 111], [112, 117], [117, 118]]}
{"doc_key": "ai-test-241", "ner": [[11, 11, "programlang"], [13, 14, "programlang"], [16, 16, "programlang"], [18, 18, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "languages", "make", "this", "possible", "in", "a", "portable", "manner", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "or", "D", ")", "."], "sentence-detokenized": "Some languages make this possible in a portable manner (e.g. Scheme, Common Lisp, Perl or D).", "token2charspan": [[0, 4], [5, 14], [15, 19], [20, 24], [25, 33], [34, 36], [37, 38], [39, 47], [48, 54], [55, 56], [56, 60], [61, 67], [67, 68], [69, 75], [76, 80], [80, 81], [82, 86], [87, 89], [90, 91], [91, 92], [92, 93]]}
{"doc_key": "ai-test-242", "ner": [[7, 7, "misc"], [9, 10, "researcher"], [12, 13, "researcher"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 9, 10, "artifact", "", false, false], [7, 7, 12, 13, "artifact", "", false, false], [7, 7, 27, 28, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1969", ",", "a", "famous", "book", "entitled", "Perceptrons", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "demonstrated", "that", "it", "was", "impossible", "for", "these", "classes", "of", "networks", "to", "learn", "an", "XOR", "function", "."], "sentence-detokenized": "In 1969, a famous book entitled Perceptrons by Marvin Minsky and Seymour Papert demonstrated that it was impossible for these classes of networks to learn an XOR function.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 22], [23, 31], [32, 43], [44, 46], [47, 53], [54, 60], [61, 64], [65, 72], [73, 79], [80, 92], [93, 97], [98, 100], [101, 104], [105, 115], [116, 119], [120, 125], [126, 133], [134, 136], [137, 145], [146, 148], [149, 154], [155, 157], [158, 161], [162, 170], [170, 171]]}
{"doc_key": "ai-test-243", "ner": [[4, 9, "misc"], [12, 12, "product"], [18, 21, "organisation"], [24, 29, "organisation"], [32, 37, "location"], [39, 39, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 21, 12, 12, "usage", "", false, false], [18, 21, 32, 37, "physical", "", false, false], [24, 29, 18, 21, "named", "", false, false], [32, 37, 39, 39, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "large", "number", "of", "Russian", "scientific", "and", "technical", "documents", "were", "translated", "with", "SYSTRAN", "under", "the", "auspices", "of", "the", "USAF", "Foreign", "Technology", "Division", "(", "later", "National", "Air", "and", "Space", "Intelligence", "Center", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", ",", "Ohio", "."], "sentence-detokenized": "A large number of Russian scientific and technical documents were translated with SYSTRAN under the auspices of the USAF Foreign Technology Division (later National Air and Space Intelligence Center) at Wright-Patterson Air Force Base, Ohio.", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 17], [18, 25], [26, 36], [37, 40], [41, 50], [51, 60], [61, 65], [66, 76], [77, 81], [82, 89], [90, 95], [96, 99], [100, 108], [109, 111], [112, 115], [116, 120], [121, 128], [129, 139], [140, 148], [149, 150], [150, 155], [156, 164], [165, 168], [169, 172], [173, 178], [179, 191], [192, 198], [198, 199], [200, 202], [203, 209], [209, 210], [210, 219], [220, 223], [224, 229], [230, 234], [234, 235], [236, 240], [240, 241]]}
{"doc_key": "ai-test-244", "ner": [[0, 1, "field"], [4, 5, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-supervised", "learning", "lies", "between", "unsupervised", "learning", "(", "without", "labelled", "training", "data", ")", "and", "supervised", "learning", "(", "with", "fully", "labelled", "training", "data", ")", "."], "sentence-detokenized": "Semi-supervised learning lies between unsupervised learning (without labelled training data) and supervised learning (with fully labelled training data).", "token2charspan": [[0, 15], [16, 24], [25, 29], [30, 37], [38, 50], [51, 59], [60, 61], [61, 68], [69, 77], [78, 86], [87, 91], [91, 92], [93, 96], [97, 107], [108, 116], [117, 118], [118, 122], [123, 128], [129, 137], [138, 146], [147, 151], [151, 152], [152, 153]]}
{"doc_key": "ai-test-245", "ner": [[0, 4, "algorithm"], [9, 13, "algorithm"], [33, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 9, 13, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Ann", "-", "gram", "model", "is", "a", "type", "of", "probabilistic", "language", "model", "for", "the", "prediction", "of", "the", "next", "element", "in", "that", "sequence", "in", "the", "form", "of", "an", "(", "n", "-", "1", ")", "-order", "Markov", "model", "."], "sentence-detokenized": "The Ann -gram model is a type of probabilistic language model for the prediction of the next element in that sequence in the form of an (n - 1)-order Markov model.", "token2charspan": [[0, 3], [4, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 24], [25, 29], [30, 32], [33, 46], [47, 55], [56, 61], [62, 65], [66, 69], [70, 80], [81, 83], [84, 87], [88, 92], [93, 100], [101, 103], [104, 108], [109, 117], [118, 120], [121, 124], [125, 129], [130, 132], [133, 135], [136, 137], [137, 138], [139, 140], [141, 142], [142, 143], [143, 149], [150, 156], [157, 162], [162, 163]]}
{"doc_key": "ai-test-246", "ner": [[1, 2, "organisation"], [4, 4, "product"], [8, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 4, 4, "usage", "", false, false], [8, 13, 1, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "used", "Cyc", "to", "develop", "a", "natural", "language", "query", "interface", "of", "biomedical", "information", ",", "covering", "decades", "of", "information", "on", "cardiothoracic", "surgery", "."], "sentence-detokenized": "The Cleveland Clinic used Cyc to develop a natural language query interface of biomedical information, covering decades of information on cardiothoracic surgery.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 29], [30, 32], [33, 40], [41, 42], [43, 50], [51, 59], [60, 65], [66, 75], [76, 78], [79, 89], [90, 101], [101, 102], [103, 111], [112, 119], [120, 122], [123, 134], [135, 137], [138, 152], [153, 160], [160, 161]]}
{"doc_key": "ai-test-247", "ner": [[6, 6, "country"], [8, 9, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 6, 8, 9, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "incident", "strained", "relations", "between", "the", "US", "and", "Japan", "and", "led", "to", "the", "arrest", "and", "indictment", "of", "two", "executives", "and", "the", "imposition", "of", "sanctions", "on", "the", "company", "by", "both", "countries", "."], "sentence-detokenized": "The incident strained relations between the US and Japan and led to the arrest and indictment of two executives and the imposition of sanctions on the company by both countries.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 31], [32, 39], [40, 43], [44, 46], [47, 50], [51, 56], [57, 60], [61, 64], [65, 67], [68, 71], [72, 78], [79, 82], [83, 93], [94, 96], [97, 100], [101, 111], [112, 115], [116, 119], [120, 130], [131, 133], [134, 143], [144, 146], [147, 150], [151, 158], [159, 161], [162, 166], [167, 176], [176, 177]]}
{"doc_key": "ai-test-248", "ner": [[7, 9, "algorithm"], [14, 15, "field"], [21, 21, "misc"], [30, 30, "misc"], [34, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 14, 15, "type-of", "", false, false], [21, 21, 14, 15, "part-of", "", true, false], [30, 30, 14, 15, "part-of", "", true, false], [34, 34, 14, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["If", "modelling", "is", "carried", "out", "by", "an", "artificial", "neural", "network", "or", "another", "type", "of", "machine", "learning", ",", "parameter", "optimisation", "is", "called", "training", ",", "while", "optimisation", "of", "model", "hyper-parameters", "is", "called", "tuning", "and", "often", "uses", "cross-validation", "."], "sentence-detokenized": "If modelling is carried out by an artificial neural network or another type of machine learning, parameter optimisation is called training, while optimisation of model hyper-parameters is called tuning and often uses cross-validation.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 23], [24, 27], [28, 30], [31, 33], [34, 44], [45, 51], [52, 59], [60, 62], [63, 70], [71, 75], [76, 78], [79, 86], [87, 95], [95, 96], [97, 106], [107, 119], [120, 122], [123, 129], [130, 138], [138, 139], [140, 145], [146, 158], [159, 161], [162, 167], [168, 184], [185, 187], [188, 194], [195, 201], [202, 205], [206, 211], [212, 216], [217, 233], [233, 234]]}
{"doc_key": "ai-test-249", "ner": [[9, 9, "country"], [11, 11, "country"], [13, 14, "country"], [20, 22, "organisation"], [23, 23, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 22, 23, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "localised", "versions", "of", "the", "site", "available", "in", "the", "UK", ",", "India", "and", "Australia", "were", "discontinued", "following", "the", "acquisition", "of", "Rotten", "Tomatoes", "by", "Fandango", "."], "sentence-detokenized": "The localised versions of the site available in the UK, India and Australia were discontinued following the acquisition of Rotten Tomatoes by Fandango.", "token2charspan": [[0, 3], [4, 13], [14, 22], [23, 25], [26, 29], [30, 34], [35, 44], [45, 47], [48, 51], [52, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 80], [81, 93], [94, 103], [104, 107], [108, 119], [120, 122], [123, 129], [130, 138], [139, 141], [142, 150], [150, 151]]}
{"doc_key": "ai-test-250", "ner": [[1, 1, "task"], [11, 12, "metrics"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 11, 12, "related-to", "", false, false], [11, 12, 24, 25, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "NER", "model", "is", "one", "of", "the", "methods", "for", "determining", "the", "accuracy", "of", "live", "subtitles", "in", "television", "broadcasts", "and", "events", "that", "are", "produced", "using", "speech", "recognition", "."], "sentence-detokenized": "The NER model is one of the methods for determining the accuracy of live subtitles in television broadcasts and events that are produced using speech recognition.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 35], [36, 39], [40, 51], [52, 55], [56, 64], [65, 67], [68, 72], [73, 82], [83, 85], [86, 96], [97, 107], [108, 111], [112, 118], [119, 123], [124, 127], [128, 136], [137, 142], [143, 149], [150, 161], [161, 162]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [4, 5, "university"], [7, 8, "university"], [10, 10, "location"], [12, 16, "university"], [18, 19, "university"], [21, 21, "location"], [24, 29, "university"], [31, 32, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 5, "physical", "", false, false], [0, 0, 4, 5, "role", "", false, false], [0, 0, 7, 8, "physical", "", false, false], [0, 0, 7, 8, "role", "", false, false], [0, 0, 12, 16, "physical", "", false, false], [0, 0, 12, 16, "role", "", false, false], [0, 0, 18, 19, "physical", "", false, false], [0, 0, 18, 19, "role", "", false, false], [0, 0, 24, 29, "physical", "", false, false], [0, 0, 24, 29, "role", "", false, false], [7, 8, 10, 10, "physical", "", false, false], [12, 16, 21, 21, "physical", "", false, false], [18, 19, 21, 21, "physical", "", false, false], [24, 29, 31, 32, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "has", "taught", "at", "Cambridge", "University", ",", "Hebrew", "University", "in", "Jerusalem", ",", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "and", "\u00c9cole", "Polytechnique", "in", "Paris", ",", "and", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "."], "sentence-detokenized": "Atran has taught at Cambridge University, Hebrew University in Jerusalem, \u00c9cole pratique des hautes \u00e9tudes and \u00c9cole Polytechnique in Paris, and John Jay College of Criminal Justice in New York.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 40], [40, 41], [42, 48], [49, 59], [60, 62], [63, 72], [72, 73], [74, 79], [80, 88], [89, 92], [93, 99], [100, 106], [107, 110], [111, 116], [117, 130], [131, 133], [134, 139], [139, 140], [141, 144], [145, 149], [150, 153], [154, 161], [162, 164], [165, 173], [174, 181], [182, 184], [185, 188], [189, 193], [193, 194]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [4, 6, "task"], [10, 11, "researcher"], [13, 13, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "origin", "", false, false], [0, 0, 4, 6, "related-to", "", false, false], [4, 6, 13, 13, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "was", "an", "early", "natural", "language", "understanding", "programme", "developed", "by", "Terry", "Winograd", "at", "MIT", "in", "1968", "-", "1970", "."], "sentence-detokenized": "SHRDLU was an early natural language understanding programme developed by Terry Winograd at MIT in 1968-1970.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 19], [20, 27], [28, 36], [37, 50], [51, 60], [61, 70], [71, 73], [74, 79], [80, 88], [89, 91], [92, 95], [96, 98], [99, 103], [103, 104], [104, 108], [108, 109]]}
{"doc_key": "ai-test-253", "ner": [[3, 3, "misc"], [5, 7, "field"], [9, 13, "university"], [15, 15, "location"], [17, 19, "country"], [27, 28, "university"], [31, 31, "misc"], [33, 38, "field"], [41, 42, "university"], [46, 46, "misc"], [48, 49, "field"], [54, 55, "misc"], [62, 66, "university"], [71, 72, "field"], [76, 77, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[3, 3, 5, 7, "topic", "", false, false], [3, 3, 9, 13, "origin", "", false, false], [9, 13, 15, 15, "physical", "", false, false], [9, 13, 27, 28, "role", "affiliated_with", false, false], [15, 15, 17, 19, "physical", "", false, false], [31, 31, 33, 38, "topic", "", false, false], [31, 31, 41, 42, "origin", "", false, false], [46, 46, 48, 49, "topic", "", false, false], [54, 55, 62, 66, "origin", "", false, false], [54, 55, 71, 72, "topic", "", false, false], [76, 77, 62, 66, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["He", "received", "a", "B.E.", "in", "electrical", "engineering", "from", "the", "B.M.S", ".", "College", "of", "Engineering", "in", "Bangalore", ",", "India", ",", "in", "1982", ",", "when", "he", "was", "affiliated", "with", "Bangalore", "University", ",", "an", "M.S.", "in", "electrical", "engineering", "and", "computer", "science", "in", "1984", "from", "Drexel", "University", ",", "and", "an", "M.S.", "in", "computer", "science", "in", "1989", "and", "a", "Ph.D.", "in", "1990", ",", "respectively", ",", "from", "the", "University", "of", "Wisconsin", "-", "Madison", ",", "where", "he", "studied", "artificial", "intelligence", "and", "worked", "with", "Leonard", "Uhr", "."], "sentence-detokenized": "He received a B.E. in electrical engineering from the B.M.S. College of Engineering in Bangalore, India, in 1982, when he was affiliated with Bangalore University, an M.S. in electrical engineering and computer science in 1984 from Drexel University, and an M.S. in computer science in 1989 and a Ph.D. in 1990, respectively, from the University of Wisconsin-Madison, where he studied artificial intelligence and worked with Leonard Uhr.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 18], [19, 21], [22, 32], [33, 44], [45, 49], [50, 53], [54, 59], [59, 60], [61, 68], [69, 71], [72, 83], [84, 86], [87, 96], [96, 97], [98, 103], [103, 104], [105, 107], [108, 112], [112, 113], [114, 118], [119, 121], [122, 125], [126, 136], [137, 141], [142, 151], [152, 162], [162, 163], [164, 166], [167, 171], [172, 174], [175, 185], [186, 197], [198, 201], [202, 210], [211, 218], [219, 221], [222, 226], [227, 231], [232, 238], [239, 249], [249, 250], [251, 254], [255, 257], [258, 262], [263, 265], [266, 274], [275, 282], [283, 285], [286, 290], [291, 294], [295, 296], [297, 302], [303, 305], [306, 310], [310, 311], [312, 324], [324, 325], [326, 330], [331, 334], [335, 345], [346, 348], [349, 358], [358, 359], [359, 366], [366, 367], [368, 373], [374, 376], [377, 384], [385, 395], [396, 408], [409, 412], [413, 419], [420, 424], [425, 432], [433, 436], [436, 437]]}
{"doc_key": "ai-test-254", "ner": [[6, 8, "metrics"], [10, 10, "metrics"], [19, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "usually", "assessed", "with", "the", "word", "error", "rate", "(", "WER", ")", ",", "while", "speed", "is", "measured", "with", "the", "real", "time", "factor", "."], "sentence-detokenized": "Accuracy is usually assessed with the word error rate (WER), while speed is measured with the real time factor.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 28], [29, 33], [34, 37], [38, 42], [43, 48], [49, 53], [54, 55], [55, 58], [58, 59], [59, 60], [61, 66], [67, 72], [73, 75], [76, 84], [85, 89], [90, 93], [94, 98], [99, 103], [104, 110], [110, 111]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [8, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", ",", "Terry", "Winograd", "developed", "a", "first", "natural", "language", "processing", "engine", "capable", "of", "interpreting", "naturally", "written", "commands", "within", "a", "simple", "rule", "-", "governed", "environment", "."], "sentence-detokenized": "In 1971, Terry Winograd developed a first natural language processing engine capable of interpreting naturally written commands within a simple rule-governed environment.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 33], [34, 35], [36, 41], [42, 49], [50, 58], [59, 69], [70, 76], [77, 84], [85, 87], [88, 100], [101, 110], [111, 118], [119, 127], [128, 134], [135, 136], [137, 143], [144, 148], [148, 149], [149, 157], [158, 169], [169, 170]]}
{"doc_key": "ai-test-256", "ner": [[4, 5, "field"], [7, 8, "researcher"], [10, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 7, 8, "related-to", "", false, false], [4, 5, 10, 13, "related-to", "", false, false], [4, 5, 15, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "field", "of", "artificial", "intelligence", ",", "Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "and", "Allen", "Newell", "are", "the", "main", "protagonists", "."], "sentence-detokenized": "In the field of artificial intelligence, Marvin Minsky, Herbert A. Simon and Allen Newell are the main protagonists.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 26], [27, 39], [39, 40], [41, 47], [48, 54], [54, 55], [56, 63], [64, 65], [65, 66], [67, 72], [73, 76], [77, 82], [83, 89], [90, 93], [94, 97], [98, 102], [103, 115], [115, 116]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [34, 35, "field"], [37, 38, "field"], [41, 42, "field"], [51, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[34, 35, 9, 10, "origin", "", true, false], [34, 35, 9, 10, "part-of", "", false, false], [34, 35, 41, 42, "compare", "", false, false], [37, 38, 9, 10, "origin", "", true, false], [37, 38, 9, 10, "part-of", "", false, false], [37, 38, 41, 42, "compare", "", false, false], [41, 42, 9, 10, "origin", "", true, false], [41, 42, 9, 10, "part-of", "", false, false], [41, 42, 51, 54, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "the", "second", "half", "of", "the", "20th", "century", ",", "electrical", "engineering", "itself", "separated", "into", "several", "disciplines", ",", "specialising", "in", "the", "design", "and", "analysis", "of", "systems", "that", "manipulate", "physical", "signals", ";", "examples", "of", "this", "are", "electrical", "engineering", "and", "computer", "engineering", ",", "while", "design", "engineering", "developed", "to", "deal", "with", "the", "functional", "design", "of", "user", "-", "machine", "interfaces", "."], "sentence-detokenized": "In the second half of the 20th century, electrical engineering itself separated into several disciplines, specialising in the design and analysis of systems that manipulate physical signals; examples of this are electrical engineering and computer engineering, while design engineering developed to deal with the functional design of user-machine interfaces.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 30], [31, 38], [38, 39], [40, 50], [51, 62], [63, 69], [70, 79], [80, 84], [85, 92], [93, 104], [104, 105], [106, 118], [119, 121], [122, 125], [126, 132], [133, 136], [137, 145], [146, 148], [149, 156], [157, 161], [162, 172], [173, 181], [182, 189], [189, 190], [191, 199], [200, 202], [203, 207], [208, 211], [212, 222], [223, 234], [235, 238], [239, 247], [248, 259], [259, 260], [261, 266], [267, 273], [274, 285], [286, 295], [296, 298], [299, 303], [304, 308], [309, 312], [313, 323], [324, 330], [331, 333], [334, 338], [338, 339], [339, 346], [347, 357], [357, 358]]}
{"doc_key": "ai-test-258", "ner": [[5, 5, "metrics"], [7, 8, "metrics"], [10, 10, "metrics"], [44, 46, "metrics"], [53, 65, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[10, 10, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Perhaps", "the", "simplest", "statistic", "is", "accuracy", "or", "Correct", "Fraction", "(", "FC", ")", ",", "which", "measures", "the", "fraction", "of", "all", "instances", "classified", "correctly", ";", "it", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "Total", "Population", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Perhaps the simplest statistic is accuracy or Correct Fraction (FC), which measures the fraction of all instances classified correctly; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN) / Total Population = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 30], [31, 33], [34, 42], [43, 45], [46, 53], [54, 62], [63, 64], [64, 66], [66, 67], [67, 68], [69, 74], [75, 83], [84, 87], [88, 96], [97, 99], [100, 103], [104, 113], [114, 124], [125, 134], [134, 135], [136, 138], [139, 141], [142, 145], [146, 151], [152, 154], [155, 158], [159, 165], [166, 168], [169, 176], [177, 192], [193, 195], [196, 199], [200, 205], [206, 212], [213, 215], [216, 223], [224, 226], [227, 236], [237, 252], [252, 253], [254, 255], [255, 257], [258, 259], [260, 262], [262, 263], [264, 265], [266, 271], [272, 282], [283, 284], [285, 286], [286, 288], [289, 290], [291, 293], [293, 294], [295, 296], [297, 298], [298, 300], [301, 302], [303, 305], [306, 307], [308, 310], [311, 312], [313, 315], [315, 316], [316, 317]]}
{"doc_key": "ai-test-259", "ner": [[14, 21, "conference"], [23, 25, "conference"], [30, 31, "location"], [35, 35, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 21, 30, 31, "physical", "", false, false], [23, 25, 14, 21, "named", "", false, false], [35, 35, 14, 21, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "academic", "community", ",", "major", "research", "forums", "began", "in", "1995", ",", "when", "the", "first", "international", "conference", "Data", "Mining", "and", "Knowledge", "Discovery", "(", "KDD", "-", "95", ")", "was", "launched", "in", "Montreal", "under", "the", "auspices", "of", "AAAI", "."], "sentence-detokenized": "In the academic community, major research forums began in 1995, when the first international conference Data Mining and Knowledge Discovery (KDD-95) was launched in Montreal under the auspices of AAAI.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 25], [25, 26], [27, 32], [33, 41], [42, 48], [49, 54], [55, 57], [58, 62], [62, 63], [64, 68], [69, 72], [73, 78], [79, 92], [93, 103], [104, 108], [109, 115], [116, 119], [120, 129], [130, 139], [140, 141], [141, 144], [144, 145], [145, 147], [147, 148], [149, 152], [153, 161], [162, 164], [165, 173], [174, 179], [180, 183], [184, 192], [193, 195], [196, 200], [200, 201]]}
{"doc_key": "ai-test-260", "ner": [[9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "approach", ",", "models", "are", "developed", "using", "various", "data", "mining", "and", "machine", "learning", "algorithms", "to", "predict", "user", "evaluations", "of", "unrated", "articles", "."], "sentence-detokenized": "In this approach, models are developed using various data mining and machine learning algorithms to predict user evaluations of unrated articles.", "token2charspan": [[0, 2], [3, 7], [8, 16], [16, 17], [18, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 57], [58, 64], [65, 68], [69, 76], [77, 85], [86, 96], [97, 99], [100, 107], [108, 112], [113, 124], [125, 127], [128, 135], [136, 144], [144, 145]]}
{"doc_key": "ai-test-261", "ner": [[12, 12, "algorithm"], [18, 19, "algorithm"], [21, 22, "algorithm"], [29, 30, "misc"], [33, 34, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 18, 19, "related-to", "equivalent", false, false], [18, 19, 21, 22, "usage", "", false, false], [21, 22, 33, 34, "usage", "", false, false], [33, 34, 29, 30, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "light", "of", "the", "previous", "discussion", ",", "we", "see", "that", "the", "SVM", "technique", "is", "equivalent", "to", "the", "empirical", "risk", "with", "Tikhonov", "regularisation", ",", "where", "in", "this", "case", "the", "loss", "function", "is", "the", "hinge", "loss"], "sentence-detokenized": "In the light of the previous discussion, we see that the SVM technique is equivalent to the empirical risk with Tikhonov regularisation, where in this case the loss function is the hinge loss", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 19], [20, 28], [29, 39], [39, 40], [41, 43], [44, 47], [48, 52], [53, 56], [57, 60], [61, 70], [71, 73], [74, 84], [85, 87], [88, 91], [92, 101], [102, 106], [107, 111], [112, 120], [121, 135], [135, 136], [137, 142], [143, 145], [146, 150], [151, 155], [156, 159], [160, 164], [165, 173], [174, 176], [177, 180], [181, 186], [187, 191]]}
{"doc_key": "ai-test-262", "ner": [[6, 7, "person"], [10, 11, "person"], [14, 14, "organisation"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 17, 14, 14, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "2015", "edition", "was", "hosted", "by", "Molly", "McGrath", ",", "with", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "as", "commentators", "."], "sentence-detokenized": "The 2015 edition was hosted by Molly McGrath, with Chris Rose and former UFC fighter Kenny Florian as commentators.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 27], [28, 30], [31, 36], [37, 44], [44, 45], [46, 50], [51, 56], [57, 61], [62, 65], [66, 72], [73, 76], [77, 84], [85, 90], [91, 98], [99, 101], [102, 114], [114, 115]]}
{"doc_key": "ai-test-263", "ner": [[4, 7, "product"], [10, 11, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"], [12, 19, "researcher"], [21, 21, "researcher"], [28, 28, "researcher"], [30, 32, "task"], [34, 34, "product"], [36, 40, "researcher"], [41, 42, "task"], [44, 45, "researcher"], [49, 50, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[4, 7, 10, 11, "origin", "", false, false], [4, 7, 14, 15, "origin", "", false, false], [4, 7, 17, 18, "origin", "", false, false], [4, 7, 12, 19, "origin", "", false, false], [14, 15, 36, 40, "named", "same", false, false], [17, 18, 21, 21, "named", "same", false, false], [17, 18, 28, 28, "named", "same", false, false], [30, 32, 34, 34, "related-to", "", false, false], [34, 34, 28, 28, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["A", "subset", "called", "the", "Micro", "-", "Planner", "was", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "Sussman", "and", "Winograd", "in", "1971", "and", "was", "used", "in", "Winograd", "'s", "natural", "language", "understanding", "programme", "SHRDLU", ",", "Eugene", "Charniak", "'s", "work", "on", "story", "comprehension", ",", "Thorne", "McCarty", "'s", "work", "on", "legal", "reasoning", "and", "a", "number", "of", "other", "projects", "."], "sentence-detokenized": "A subset called the Micro-Planner was implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd Sussman and Winograd in 1971 and was used in Winograd's natural language understanding programme SHRDLU, Eugene Charniak's work on story comprehension, Thorne McCarty's work on legal reasoning and a number of other projects.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 19], [20, 25], [25, 26], [26, 33], [34, 37], [38, 49], [50, 52], [53, 59], [60, 63], [64, 71], [71, 72], [73, 79], [80, 88], [89, 92], [93, 98], [99, 107], [108, 115], [116, 119], [120, 128], [129, 131], [132, 136], [137, 140], [141, 144], [145, 149], [150, 152], [153, 161], [161, 163], [164, 171], [172, 180], [181, 194], [195, 204], [205, 211], [211, 212], [213, 219], [220, 228], [228, 230], [231, 235], [236, 238], [239, 244], [245, 258], [258, 259], [260, 266], [267, 274], [274, 276], [277, 281], [282, 284], [285, 290], [291, 300], [301, 304], [305, 306], [307, 313], [314, 316], [317, 322], [323, 331], [331, 332]]}
{"doc_key": "ai-test-264", "ner": [[0, 1, "product"], [11, 12, "product"], [15, 17, "task"], [19, 20, "task"], [22, 24, "task"], [27, 27, "task"], [29, 30, "task"], [33, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 0, 1, "usage", "", true, false], [15, 17, 11, 12, "part-of", "", true, false], [19, 20, 11, 12, "part-of", "", true, false], [22, 24, 11, 12, "part-of", "", true, false], [27, 27, 11, 12, "part-of", "", true, false], [29, 30, 11, 12, "part-of", "", true, false], [33, 36, 11, 12, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "has", "been", "used", "for", "a", "variety", "of", "purposes", "in", "information", "systems", ",", "including", "word", "sense", "disambiguation", ",", "information", "retrieval", ",", "automatic", "text", "classification", ",", "machine", "summarisation", ",", "machine", "translation", "and", "even", "automatic", "crossword", "puzzle", "generation", "."], "sentence-detokenized": "WordNet has been used for a variety of purposes in information systems, including word sense disambiguation, information retrieval, automatic text classification, machine summarisation, machine translation and even automatic crossword puzzle generation.", "token2charspan": [[0, 4], [4, 7], [8, 11], [12, 16], [17, 21], [22, 25], [26, 27], [28, 35], [36, 38], [39, 47], [48, 50], [51, 62], [63, 70], [70, 71], [72, 81], [82, 86], [87, 92], [93, 107], [107, 108], [109, 120], [121, 130], [130, 131], [132, 141], [142, 146], [147, 161], [161, 162], [163, 170], [171, 184], [184, 185], [186, 193], [194, 205], [206, 209], [210, 214], [215, 224], [225, 234], [235, 241], [242, 252], [252, 253]]}
{"doc_key": "ai-test-265", "ner": [[0, 1, "researcher"], [7, 7, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 7, 7, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "was", "appointed", "a", "Fellow", "of", "the", "IEEE", "in", "1996", "."], "sentence-detokenized": "Keutzer was appointed a Fellow of the IEEE in 1996.", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 23], [24, 30], [31, 33], [34, 37], [38, 42], [43, 45], [46, 50], [50, 51]]}
{"doc_key": "ai-test-266", "ner": [[8, 13, "algorithm"], [57, 58, "misc"], [68, 69, "algorithm"], [71, 72, "algorithm"], [74, 75, "algorithm"], [77, 78, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[68, 69, 57, 58, "type-of", "", false, false], [71, 72, 57, 58, "type-of", "", false, false], [74, 75, 57, 58, "type-of", "", false, false], [77, 78, 57, 58, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "widely", "used", "type", "of", "composition", "is", "the", "non-linear", "weighted", "sum", ",", "where", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "left", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "right", ")", "/", "math", ",", "where", "math", "\\", "textstyle", "K", "/", "math", "(", "commonly", "referred", "to", "as", "the", "activation", "function", ")", "is", "a", "predefined", "function", ",", "such", "as", "the", "hyperbolic", "tangent", ",", "sigmoid", "function", ",", "softmax", "function", "or", "straightening", "function", "."], "sentence-detokenized": "A widely used type of composition is the non-linear weighted sum, where math\\ textstyle f (x) = K\\ left (\\ sum _ i w _ i g _ i (x)\\ right) / math, where math\\ textstyle K / math (commonly referred to as the activation function) is a predefined function, such as the hyperbolic tangent, sigmoid function, softmax function or straightening function.", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 18], [19, 21], [22, 33], [34, 36], [37, 40], [41, 51], [52, 60], [61, 64], [64, 65], [66, 71], [72, 76], [76, 77], [78, 87], [88, 89], [90, 91], [91, 92], [92, 93], [94, 95], [96, 97], [97, 98], [99, 103], [104, 105], [105, 106], [107, 110], [111, 112], [113, 114], [115, 116], [117, 118], [119, 120], [121, 122], [123, 124], [125, 126], [127, 128], [128, 129], [129, 130], [130, 131], [132, 137], [137, 138], [139, 140], [141, 145], [145, 146], [147, 152], [153, 157], [157, 158], [159, 168], [169, 170], [171, 172], [173, 177], [178, 179], [179, 187], [188, 196], [197, 199], [200, 202], [203, 206], [207, 217], [218, 226], [226, 227], [228, 230], [231, 232], [233, 243], [244, 252], [252, 253], [254, 258], [259, 261], [262, 265], [266, 276], [277, 284], [284, 285], [286, 293], [294, 302], [302, 303], [304, 311], [312, 320], [321, 323], [324, 337], [338, 346], [346, 347]]}
{"doc_key": "ai-test-267", "ner": [[3, 3, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "film", "Westworld", ",", "robot", "women", "actually", "had", "sex", "with", "human", "men", "as", "part", "of", "the", "fictional", "holiday", "world", "in", "which", "human", "customers", "paid", "to", "participate", "."], "sentence-detokenized": "In the film Westworld, robot women actually had sex with human men as part of the fictional holiday world in which human customers paid to participate.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 21], [21, 22], [23, 28], [29, 34], [35, 43], [44, 47], [48, 51], [52, 56], [57, 62], [63, 66], [67, 69], [70, 74], [75, 77], [78, 81], [82, 91], [92, 99], [100, 105], [106, 108], [109, 114], [115, 120], [121, 130], [131, 135], [136, 138], [139, 150], [150, 151]]}
{"doc_key": "ai-test-268", "ner": [[7, 9, "task"], [25, 30, "task"], [32, 33, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 25, 30, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Typically", ",", "the", "process", "begins", "with", "the", "extraction", "of", "terminology", "and", "concepts", "or", "noun", "phrases", "from", "the", "plain", "text", ",", "using", "linguistic", "processors", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "phrase", "chunking", "."], "sentence-detokenized": "Typically, the process begins with the extraction of terminology and concepts or noun phrases from the plain text, using linguistic processors such as part-of-speech tagging and phrase chunking.", "token2charspan": [[0, 9], [9, 10], [11, 14], [15, 22], [23, 29], [30, 34], [35, 38], [39, 49], [50, 52], [53, 64], [65, 68], [69, 77], [78, 80], [81, 85], [86, 93], [94, 98], [99, 102], [103, 108], [109, 113], [113, 114], [115, 120], [121, 131], [132, 142], [143, 147], [148, 150], [151, 155], [155, 156], [156, 158], [158, 159], [159, 165], [166, 173], [174, 177], [178, 184], [185, 193], [193, 194]]}
{"doc_key": "ai-test-269", "ner": [[13, 14, "field"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "demonstrated", "its", "performance", "on", "a", "number", "of", "problems", "of", "interest", "to", "the", "machine", "learning", "community", ",", "including", "handwriting", "recognition", "."], "sentence-detokenized": "They demonstrated its performance on a number of problems of interest to the machine learning community, including handwriting recognition.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 33], [34, 36], [37, 38], [39, 45], [46, 48], [49, 57], [58, 60], [61, 69], [70, 72], [73, 76], [77, 84], [85, 93], [94, 103], [103, 104], [105, 114], [115, 126], [127, 138], [138, 139]]}
{"doc_key": "ai-test-270", "ner": [[3, 3, "university"], [5, 6, "researcher"], [11, 12, "researcher"], [18, 18, "product"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 3, 3, "physical", "", false, false], [5, 6, 3, 3, "role", "", false, false], [18, 18, 11, 12, "origin", "", false, false], [18, 18, 22, 23, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "studying", "at", "Stanford", ",", "Scheinman", "obtained", "a", "scholarship", "sponsored", "by", "George", "Devol", ",", "the", "inventor", "of", "the", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "While studying at Stanford, Scheinman obtained a scholarship sponsored by George Devol, the inventor of the Unimate, the first industrial robot.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [26, 27], [28, 37], [38, 46], [47, 48], [49, 60], [61, 70], [71, 73], [74, 80], [81, 86], [86, 87], [88, 91], [92, 100], [101, 103], [104, 107], [108, 115], [115, 116], [117, 120], [121, 126], [127, 137], [138, 143], [143, 144]]}
{"doc_key": "ai-test-271", "ner": [[5, 6, "task"], [9, 11, "metrics"], [13, 15, "metrics"], [22, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 9, 11, "usage", "", true, false], [13, 15, 9, 11, "named", "", false, false], [22, 24, 9, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Although", "originally", "used", "to", "evaluate", "machine", "translations", ",", "the", "bilingual", "evaluation", "understudy", "(", "BLEU", ")", "has", "also", "been", "successfully", "used", "to", "evaluate", "paraphrase", "generation", "models", "."], "sentence-detokenized": "Although originally used to evaluate machine translations, the bilingual evaluation understudy (BLEU) has also been successfully used to evaluate paraphrase generation models.", "token2charspan": [[0, 8], [9, 19], [20, 24], [25, 27], [28, 36], [37, 44], [45, 57], [57, 58], [59, 62], [63, 72], [73, 83], [84, 94], [95, 96], [96, 100], [100, 101], [102, 105], [106, 110], [111, 115], [116, 128], [129, 133], [134, 136], [137, 145], [146, 156], [157, 167], [168, 174], [174, 175]]}
{"doc_key": "ai-test-272", "ner": [[0, 0, "organisation"], [6, 8, "organisation"], [10, 10, "organisation"], [14, 14, "product"], [16, 16, "country"], [18, 18, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 8, "role", "licenses_to", false, false], [0, 0, 10, 10, "role", "licenses_to", false, false], [6, 8, 16, 16, "physical", "", false, false], [10, 10, 18, 18, "physical", "", false, false], [14, 14, 6, 8, "artifact", "produces", false, false], [14, 14, 10, 10, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "later", "licensed", "its", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "who", "manufacture", "Unimation", "in", "Japan", "and", "England", "respectively", "."], "sentence-detokenized": "Unimation later licensed its technology to Kawasaki Heavy Industries and GKN, who manufacture Unimation in Japan and England respectively.", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 57], [58, 68], [69, 72], [73, 76], [76, 77], [78, 81], [82, 93], [94, 103], [104, 106], [107, 112], [113, 116], [117, 124], [125, 137], [137, 138]]}
{"doc_key": "ai-test-273", "ner": [[19, 20, "conference"], [39, 40, "field"], [58, 62, "field"], [64, 64, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[39, 40, 58, 62, "compare", "", false, false], [64, 64, 58, 62, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "confusion", "between", "these", "two", "research", "communities", "(", "which", "often", "have", "separate", "conferences", "and", "journals", ",", "the", "ECML", "PKDD", "being", "one", "of", "the", "main", "exceptions", ")", "stems", "from", "the", "basic", "assumptions", "with", "which", "they", "work", ":", "in", "machine", "learning", ",", "performance", "is", "usually", "assessed", "with", "respect", "to", "the", "ability", "to", "reproduce", "known", "knowledge", ",", "whereas", "in", "knowledge", "discovery", "and", "data", "mining", "(", "KDD", ")", "the", "main", "task", "is", "the", "discovery", "of", "previously", "unknown", "knowledge", "."], "sentence-detokenized": "Much of the confusion between these two research communities (which often have separate conferences and journals, the ECML PKDD being one of the main exceptions) stems from the basic assumptions with which they work: in machine learning, performance is usually assessed with respect to the ability to reproduce known knowledge, whereas in knowledge discovery and data mining (KDD) the main task is the discovery of previously unknown knowledge.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 29], [30, 35], [36, 39], [40, 48], [49, 60], [61, 62], [62, 67], [68, 73], [74, 78], [79, 87], [88, 99], [100, 103], [104, 112], [112, 113], [114, 117], [118, 122], [123, 127], [128, 133], [134, 137], [138, 140], [141, 144], [145, 149], [150, 160], [160, 161], [162, 167], [168, 172], [173, 176], [177, 182], [183, 194], [195, 199], [200, 205], [206, 210], [211, 215], [215, 216], [217, 219], [220, 227], [228, 236], [236, 237], [238, 249], [250, 252], [253, 260], [261, 269], [270, 274], [275, 282], [283, 285], [286, 289], [290, 297], [298, 300], [301, 310], [311, 316], [317, 326], [326, 327], [328, 335], [336, 338], [339, 348], [349, 358], [359, 362], [363, 367], [368, 374], [375, 376], [376, 379], [379, 380], [381, 384], [385, 389], [390, 394], [395, 397], [398, 401], [402, 411], [412, 414], [415, 425], [426, 433], [434, 443], [443, 444]]}
{"doc_key": "ai-test-274", "ner": [[0, 1, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hidden", "Markov", "models", "form", "the", "basis", "of", "most", "modern", "automatic", "speech", "recognition", "systems", "."], "sentence-detokenized": "Hidden Markov models form the basis of most modern automatic speech recognition systems.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 25], [26, 29], [30, 35], [36, 38], [39, 43], [44, 50], [51, 60], [61, 67], [68, 79], [80, 87], [87, 88]]}
{"doc_key": "ai-test-275", "ner": [[3, 3, "location"], [5, 5, "country"], [10, 11, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 5, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["a", "company", "in", "Bangalore", ",", "India", ",", "specialising", "in", "online", "handwriting", "recognition", "software", "."], "sentence-detokenized": "a company in Bangalore, India, specialising in online handwriting recognition software.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 22], [22, 23], [24, 29], [29, 30], [31, 43], [44, 46], [47, 53], [54, 65], [66, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-276", "ner": [[24, 25, "misc"], [50, 54, "metrics"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Do", "repeated", "translations", "converge", "on", "a", "single", "expression", "in", "both", "languages", "?", "That", "is", ",", "does", "the", "translation", "method", "show", "stationarity", "or", "produce", "a", "canonical", "form", "?", "Does", "the", "translation", "become", "stationary", "without", "losing", "the", "original", "meaning", "?", "This", "metric", "has", "been", "criticised", "because", "it", "does", "not", "correlate", "well", "with", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "scores", "."], "sentence-detokenized": "Do repeated translations converge on a single expression in both languages? That is, does the translation method show stationarity or produce a canonical form? Does the translation become stationary without losing the original meaning? This metric has been criticised because it does not correlate well with BLEU (BiLingual Evaluation Understudy) scores.", "token2charspan": [[0, 2], [3, 11], [12, 24], [25, 33], [34, 36], [37, 38], [39, 45], [46, 56], [57, 59], [60, 64], [65, 74], [74, 75], [76, 80], [81, 83], [83, 84], [85, 89], [90, 93], [94, 105], [106, 112], [113, 117], [118, 130], [131, 133], [134, 141], [142, 143], [144, 153], [154, 158], [158, 159], [160, 164], [165, 168], [169, 180], [181, 187], [188, 198], [199, 206], [207, 213], [214, 217], [218, 226], [227, 234], [234, 235], [236, 240], [241, 247], [248, 251], [252, 256], [257, 267], [268, 275], [276, 278], [279, 283], [284, 287], [288, 297], [298, 302], [303, 307], [308, 312], [313, 314], [314, 323], [324, 334], [335, 345], [345, 346], [347, 353], [353, 354]]}
{"doc_key": "ai-test-277", "ner": [[6, 10, "organisation"], [13, 20, "organisation"], [22, 23, "university"], [26, 26, "university"], [29, 30, "field"], [33, 37, "organisation"], [40, 42, "organisation"], [50, 53, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[13, 20, 22, 23, "part-of", "", false, false], [26, 26, 29, 30, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "has", "received", "fellowships", "from", "the", "American", "Association", "for", "Artificial", "Intelligence", ",", "the", "Center", "for", "Advanced", "Study", "in", "the", "Behavioral", "Sciences", "at", "Stanford", "University", ",", "the", "MIT", "Center", "for", "Cognitive", "Science", ",", "the", "Canadian", "Institute", "for", "Advanced", "Research", ",", "the", "Canadian", "Psychological", "Association", "and", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "in", "1998", "."], "sentence-detokenized": "He has received fellowships from the American Association for Artificial Intelligence, the Center for Advanced Study in the Behavioral Sciences at Stanford University, the MIT Center for Cognitive Science, the Canadian Institute for Advanced Research, the Canadian Psychological Association and was elected a Fellow of the Royal Society of Canada in 1998.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 27], [28, 32], [33, 36], [37, 45], [46, 57], [58, 61], [62, 72], [73, 85], [85, 86], [87, 90], [91, 97], [98, 101], [102, 110], [111, 116], [117, 119], [120, 123], [124, 134], [135, 143], [144, 146], [147, 155], [156, 166], [166, 167], [168, 171], [172, 175], [176, 182], [183, 186], [187, 196], [197, 204], [204, 205], [206, 209], [210, 218], [219, 228], [229, 232], [233, 241], [242, 250], [250, 251], [252, 255], [256, 264], [265, 278], [279, 290], [291, 294], [295, 298], [299, 306], [307, 308], [309, 315], [316, 318], [319, 322], [323, 328], [329, 336], [337, 339], [340, 346], [347, 349], [350, 354], [354, 355]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [16, 19, "misc"], [21, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 16, 19, "part-of", "", false, false], [0, 0, 21, 22, "part-of", "", false, false], [4, 5, 16, 19, "part-of", "", false, false], [4, 5, 21, 22, "part-of", "", false, false], [7, 8, 16, 19, "part-of", "", false, false], [7, 8, 21, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", ",", "together", "with", "Yoshua", "Bengio", "and", "Yann", "LeCun", ",", "is", "described", "by", "some", "as", "the", "godfathers", "of", "artificial", "intelligence", "and", "deep", "learning", "."], "sentence-detokenized": "Hinton, together with Yoshua Bengio and Yann LeCun, is described by some as the godfathers of artificial intelligence and deep learning.", "token2charspan": [[0, 6], [6, 7], [8, 16], [17, 21], [22, 28], [29, 35], [36, 39], [40, 44], [45, 50], [50, 51], [52, 54], [55, 64], [65, 67], [68, 72], [73, 75], [76, 79], [80, 90], [91, 93], [94, 104], [105, 117], [118, 121], [122, 126], [127, 135], [135, 136]]}
{"doc_key": "ai-test-279", "ner": [[7, 10, "product"], [19, 19, "misc"], [21, 22, "misc"], [23, 23, "product"], [27, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 10, 19, 19, "related-to", "", false, false], [7, 10, 21, 22, "related-to", "", false, false], [19, 19, 23, 23, "named", "same", false, false], [27, 28, 23, 23, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "open", "-", "source", "lightweight", "voice", "project", "eSpeak", ",", "which", "has", "its", "own", "approach", "to", "synthesis", ",", "experimented", "with", "Mandarin", "and", "Cantonese", ".", "eSpeak", "was", "used", "by", "Google", "Translate", "from", "May", "2010-2010", "."], "sentence-detokenized": "The open-source lightweight voice project eSpeak, which has its own approach to synthesis, experimented with Mandarin and Cantonese. eSpeak was used by Google Translate from May 2010-2010.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 15], [16, 27], [28, 33], [34, 41], [42, 48], [48, 49], [50, 55], [56, 59], [60, 63], [64, 67], [68, 76], [77, 79], [80, 89], [89, 90], [91, 103], [104, 108], [109, 117], [118, 121], [122, 131], [131, 132], [133, 139], [140, 143], [144, 148], [149, 151], [152, 158], [159, 168], [169, 173], [174, 177], [178, 187], [187, 188]]}
{"doc_key": "ai-test-280", "ner": [[5, 7, "product"], [13, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 13, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Also", "released", "in", "1982", ",", "Software", "Automatic", "Mouth", "was", "the", "first", "commercial", "speech", "synthesis", "programme", "to", "be", "entirely", "software", "-", "based", "."], "sentence-detokenized": "Also released in 1982, Software Automatic Mouth was the first commercial speech synthesis programme to be entirely software-based.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 21], [21, 22], [23, 31], [32, 41], [42, 47], [48, 51], [52, 55], [56, 61], [62, 72], [73, 79], [80, 89], [90, 99], [100, 102], [103, 105], [106, 114], [115, 123], [123, 124], [124, 129], [129, 130]]}
{"doc_key": "ai-test-281", "ner": [[4, 6, "metrics"], [8, 8, "metrics"], [11, 11, "metrics"], [13, 13, "metrics"], [16, 27, "metrics"], [28, 30, "metrics"], [32, 32, "metrics"], [35, 42, "metrics"], [45, 47, "metrics"], [49, 49, "metrics"], [52, 52, "metrics"], [54, 54, "metrics"], [57, 64, "metrics"], [69, 71, "metrics"], [73, 73, "metrics"], [76, 82, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[8, 8, 4, 6, "named", "", false, false], [11, 11, 4, 6, "named", "", false, false], [13, 13, 4, 6, "named", "", false, false], [16, 27, 4, 6, "named", "", false, false], [32, 32, 28, 30, "named", "", false, false], [35, 42, 28, 30, "named", "", false, false], [49, 49, 45, 47, "named", "", false, false], [52, 52, 45, 47, "named", "", false, false], [54, 54, 45, 47, "named", "", false, false], [57, 64, 45, 47, "named", "", false, false], [73, 73, 69, 71, "named", "", false, false], [76, 82, 69, 71, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["The", "column", "ratios", "are", "True", "Positivity", "Rate", "(", "TPR", ",", "a.k.a.", "sensitivity", "or", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "with", "complement", "the", "FALSE", "Negativity", "Rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "and", "True", "Negativity", "Rate", "(", "TNR", ",", "a.k.a.", "specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "with", "complement", "the", "FALSE", "Positivity", "Rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "The column ratios are True Positivity Rate (TPR, a.k.a. sensitivity or recall) (TP / (TP + FN)), with complement the FALSE Negativity Rate (FNR) (FN / (TP + FN)); and True Negativity Rate (TNR, a.k.a. specificity, SPC) (TN / (TN + FP)), with complement the FALSE Positivity Rate (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 21], [22, 26], [27, 37], [38, 42], [43, 44], [44, 47], [47, 48], [49, 55], [56, 67], [68, 70], [71, 77], [77, 78], [79, 80], [80, 82], [83, 84], [85, 86], [86, 88], [89, 90], [91, 93], [93, 94], [94, 95], [95, 96], [97, 101], [102, 112], [113, 116], [117, 122], [123, 133], [134, 138], [139, 140], [140, 143], [143, 144], [145, 146], [146, 148], [149, 150], [151, 152], [152, 154], [155, 156], [157, 159], [159, 160], [160, 161], [161, 162], [163, 166], [167, 171], [172, 182], [183, 187], [188, 189], [189, 192], [192, 193], [194, 200], [201, 212], [212, 213], [214, 217], [217, 218], [219, 220], [220, 222], [223, 224], [225, 226], [226, 228], [229, 230], [231, 233], [233, 234], [234, 235], [235, 236], [237, 241], [242, 252], [253, 256], [257, 262], [263, 273], [274, 278], [279, 280], [280, 283], [283, 284], [285, 286], [286, 288], [289, 290], [291, 292], [292, 294], [295, 296], [297, 299], [299, 300], [300, 301], [301, 302]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 15, 15, "role", "working_with", false, false], [2, 2, 15, 15, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "and", "Weber", "also", "collaborated", "on", "many", "other", "robots", ",", "and", "their", "experience", "working", "with", "Kismet"], "sentence-detokenized": "Edsinger and Weber also collaborated on many other robots, and their experience working with Kismet", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 36], [37, 39], [40, 44], [45, 50], [51, 57], [57, 58], [59, 62], [63, 68], [69, 79], [80, 87], [88, 92], [93, 99]]}
{"doc_key": "ai-test-283", "ner": [[3, 4, "programlang"], [14, 14, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 14, 14, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "functionality", "of", "R", "is", "also", "accessible", "from", "various", "scripting", "languages", ",", "such", "as", "Python", "."], "sentence-detokenized": "The functionality of R is also accessible from various scripting languages, such as Python.", "token2charspan": [[0, 3], [4, 17], [18, 20], [21, 22], [23, 25], [26, 30], [31, 41], [42, 46], [47, 54], [55, 64], [65, 74], [74, 75], [76, 80], [81, 83], [84, 90], [90, 91]]}
{"doc_key": "ai-test-284", "ner": [[0, 1, "programlang"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 0, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "was", "one", "of", "the", "first", "robot", "languages", "and", "was", "used", "in", "Unimate", "robots", "."], "sentence-detokenized": "VAL was one of the first robot languages and was used in Unimate robots.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 24], [25, 30], [31, 40], [41, 44], [45, 48], [49, 53], [54, 56], [57, 64], [65, 71], [71, 72]]}
{"doc_key": "ai-test-285", "ner": [[13, 23, "conference"], [20, 20, "conference"], [24, 24, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 23, 24, 24, "physical", "", false, false], [20, 20, 13, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["They", "presented", "their", "database", "for", "the", "first", "time", "in", "poster", "form", "at", "the", "2009", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "Conference", "in", "Florida", "."], "sentence-detokenized": "They presented their database for the first time in poster form at the 2009 Computer Vision and Pattern Recognition (CVPR) Conference in Florida.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 29], [30, 33], [34, 37], [38, 43], [44, 48], [49, 51], [52, 58], [59, 63], [64, 66], [67, 70], [71, 75], [76, 84], [85, 91], [92, 95], [96, 103], [104, 115], [116, 117], [117, 121], [121, 122], [123, 133], [134, 136], [137, 144], [144, 145]]}
{"doc_key": "ai-test-286", "ner": [[0, 1, "misc"], [13, 13, "task"], [12, 16, "field"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 13, 0, 1, "type-of", "", false, false], [12, 16, 0, 1, "type-of", "", false, false], [18, 19, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Categorisation", "tasks", "in", "which", "no", "labels", "are", "provided", "are", "referred", "to", "as", "unsupervised", "classification", ",", "unsupervised", "learning", ",", "cluster", "analysis", "."], "sentence-detokenized": "Categorisation tasks in which no labels are provided are referred to as unsupervised classification, unsupervised learning, cluster analysis.", "token2charspan": [[0, 14], [15, 20], [21, 23], [24, 29], [30, 32], [33, 39], [40, 43], [44, 52], [53, 56], [57, 65], [66, 68], [69, 71], [72, 84], [85, 99], [99, 100], [101, 113], [114, 122], [122, 123], [124, 131], [132, 140], [140, 141]]}
{"doc_key": "ai-test-287", "ner": [[3, 5, "task"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "must", "recognise", "objects", ",", "recognise", "and", "locate", "humans", "and", "further", "recognise", "emotions", "."], "sentence-detokenized": "It must recognise objects, recognise and locate humans and further recognise emotions.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 25], [25, 26], [27, 36], [37, 40], [41, 47], [48, 54], [55, 58], [59, 66], [67, 76], [77, 85], [85, 86]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "process", "is", "complex", "and", "involves", "encoding", "and", "recall", "or", "retrieval", "."], "sentence-detokenized": "The process is complex and involves encoding and recall or retrieval.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 26], [27, 35], [36, 44], [45, 48], [49, 55], [56, 58], [59, 68], [68, 69]]}
{"doc_key": "ai-test-289", "ner": [[7, 8, "product"], [12, 13, "product"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 12, 13, "named", "", false, false], [7, 8, 30, 31, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Also", "known", "as", "parallel", "robots", "or", "generalised", "Stewart", "platforms", "(", "in", "the", "Stewart", "platform", ",", "actuators", "are", "coupled", "on", "both", "the", "base", "and", "the", "platform", ")", ",", "these", "systems", "are", "articulated", "robots", "that", "use", "similar", "mechanisms", "for", "the", "movement", "of", "the", "robot", "on", "the", "base", "or", "one", "or", "more", "manipulator", "arms", "."], "sentence-detokenized": "Also known as parallel robots or generalised Stewart platforms (in the Stewart platform, actuators are coupled on both the base and the platform), these systems are articulated robots that use similar mechanisms for the movement of the robot on the base or one or more manipulator arms.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 29], [30, 32], [33, 44], [45, 52], [53, 62], [63, 64], [64, 66], [67, 70], [71, 78], [79, 87], [87, 88], [89, 98], [99, 102], [103, 110], [111, 113], [114, 118], [119, 122], [123, 127], [128, 131], [132, 135], [136, 144], [144, 145], [145, 146], [147, 152], [153, 160], [161, 164], [165, 176], [177, 183], [184, 188], [189, 192], [193, 200], [201, 211], [212, 215], [216, 219], [220, 228], [229, 231], [232, 235], [236, 241], [242, 244], [245, 248], [249, 253], [254, 256], [257, 260], [261, 263], [264, 268], [269, 280], [281, 285], [285, 286]]}
{"doc_key": "ai-test-290", "ner": [[0, 1, "field"], [4, 5, "field"], [13, 13, "field"], [12, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 5, "part-of", "subfield", false, false], [0, 1, 13, 13, "compare", "", false, false], [13, 13, 12, 19, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Computer", "vision", "as", "a", "systems", "engineering", "discipline", "can", "be", "considered", "distinct", "from", "computer", "vision", ",", "a", "form", "of", "computer", "science", "."], "sentence-detokenized": "Computer vision as a systems engineering discipline can be considered distinct from computer vision, a form of computer science.", "token2charspan": [[0, 8], [9, 15], [16, 18], [19, 20], [21, 28], [29, 40], [41, 51], [52, 55], [56, 58], [59, 69], [70, 78], [79, 83], [84, 92], [93, 99], [99, 100], [101, 102], [103, 107], [108, 110], [111, 119], [120, 127], [127, 128]]}
{"doc_key": "ai-test-291", "ner": [[4, 5, "algorithm"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 9, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "activation", "function", "of", "LSTM", "ports", "is", "often", "the", "logistic", "sigmoid", "function", "."], "sentence-detokenized": "The activation function of LSTM ports is often the logistic sigmoid function.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 26], [27, 31], [32, 37], [38, 40], [41, 46], [47, 50], [51, 59], [60, 67], [68, 76], [76, 77]]}
{"doc_key": "ai-test-292", "ner": [[5, 6, "metrics"], [20, 24, "metrics"], [26, 26, "metrics"], [34, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 20, 24, "named", "", false, false], [5, 6, 34, 37, "named", "", false, false], [26, 26, 20, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "the", "(", "necessarily", "unique", ")", "efficient", "estimator", "and", "thus", "also", "the", "estimator", "not", "affected", "by", "minimum", "variance", "(", "MVUE", ")", ",", "as", "well", "as", "being", "the", "estimator", "of", "maximum", "likelihood", "."], "sentence-detokenized": "In other words, the sample mean is the (necessarily unique) efficient estimator and thus also the estimator not affected by minimum variance (MVUE), as well as being the estimator of maximum likelihood.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 38], [39, 40], [40, 51], [52, 58], [58, 59], [60, 69], [70, 79], [80, 83], [84, 88], [89, 93], [94, 97], [98, 107], [108, 111], [112, 120], [121, 123], [124, 131], [132, 140], [141, 142], [142, 146], [146, 147], [147, 148], [149, 151], [152, 156], [157, 159], [160, 165], [166, 169], [170, 179], [180, 182], [183, 190], [191, 201], [201, 202]]}
{"doc_key": "ai-test-293", "ner": [[2, 3, "academicjournal"], [6, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [22, 22, "product"], [25, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 22, 22, "topic", "", false, false], [2, 3, 25, 26, "topic", "", false, false], [6, 8, 2, 3, "role", "", false, false], [10, 11, 2, 3, "role", "", false, false], [13, 14, 2, 3, "role", "", false, false], [22, 22, 25, 26, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "2001", "Scientific", "American", "article", "by", "Berners", "-", "Lee", ",", "James", "Hendler", "and", "Ora", "Lassila", "described", "the", "expected", "evolution", "of", "the", "existing", "Web", "into", "a", "semantic", "Web", "."], "sentence-detokenized": "The 2001 Scientific American article by Berners-Lee, James Hendler and Ora Lassila described the expected evolution of the existing Web into a semantic Web.", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 28], [29, 36], [37, 39], [40, 47], [47, 48], [48, 51], [51, 52], [53, 58], [59, 66], [67, 70], [71, 74], [75, 82], [83, 92], [93, 96], [97, 105], [106, 115], [116, 118], [119, 122], [123, 131], [132, 135], [136, 140], [141, 142], [143, 151], [152, 155], [155, 156]]}
{"doc_key": "ai-test-294", "ner": [[0, 1, "misc"], [12, 13, "person"], [15, 15, "person"], [27, 27, "person"], [38, 38, "person"], [44, 45, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 13, 0, 1, "role", "actor_in_work", false, false], [15, 15, 12, 13, "named", "", false, false], [15, 15, 12, 13, "origin", "", false, false], [27, 27, 15, 15, "part-of", "", false, false], [44, 45, 15, 15, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Blade", "Runner", "used", "a", "number", "of", "then", "little", "-", "known", "actors", ":", "Sean", "Young", "plays", "Rachael", ",", "an", "experimental", "replicant", "who", "is", "implanted", "with", "the", "memories", "of", "Tyrell", "'s", "niece", ",", "making", "her", "believe", "she", "is", "human", ";", "Sammon", ",", "pp.", "92", "-", "93", "Nina", "Axelrod", "auditioned", "for", "the", "role", "."], "sentence-detokenized": "Blade Runner used a number of then little-known actors: Sean Young plays Rachael, an experimental replicant who is implanted with the memories of Tyrell's niece, making her believe she is human; Sammon, pp. 92-93 Nina Axelrod auditioned for the role.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 19], [20, 26], [27, 29], [30, 34], [35, 41], [41, 42], [42, 47], [48, 54], [54, 55], [56, 60], [61, 66], [67, 72], [73, 80], [80, 81], [82, 84], [85, 97], [98, 107], [108, 111], [112, 114], [115, 124], [125, 129], [130, 133], [134, 142], [143, 145], [146, 152], [152, 154], [155, 160], [160, 161], [162, 168], [169, 172], [173, 180], [181, 184], [185, 187], [188, 193], [193, 194], [195, 201], [201, 202], [203, 206], [207, 209], [209, 210], [210, 212], [213, 217], [218, 225], [226, 236], [237, 240], [241, 244], [245, 249], [249, 250]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [13, 15, "university"], [23, 25, "product"], [27, 27, "product"], [43, 43, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 13, 15, "physical", "", false, false], [3, 4, 13, 15, "physical", "", false, false], [6, 7, 13, 15, "physical", "", false, false], [9, 10, 13, 15, "physical", "", false, false], [13, 15, 43, 43, "physical", "", true, false], [23, 25, 13, 15, "temporal", "", false, false], [27, 27, 13, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "and", "Terry", "Winograd", "visited", "the", "University", "of", "Edinburgh", "in", "1971", ",", "spreading", "the", "news", "about", "Micro", "-", "Planner", "and", "SHRDLU", "and", "questioning", "the", "uniform", "resolution", "proof", "approach", ",", "which", "had", "been", "the", "mainstay", "of", "the", "Edinburgh", "logicians", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited the University of Edinburgh in 1971, spreading the news about Micro-Planner and SHRDLU and questioning the uniform resolution proof approach, which had been the mainstay of the Edinburgh logicians.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 56], [57, 65], [66, 73], [74, 77], [78, 88], [89, 91], [92, 101], [102, 104], [105, 109], [109, 110], [111, 120], [121, 124], [125, 129], [130, 135], [136, 141], [141, 142], [142, 149], [150, 153], [154, 160], [161, 164], [165, 176], [177, 180], [181, 188], [189, 199], [200, 205], [206, 214], [214, 215], [216, 221], [222, 225], [226, 230], [231, 234], [235, 243], [244, 246], [247, 250], [251, 260], [261, 270], [270, 271]]}
{"doc_key": "ai-test-296", "ner": [[0, 0, "researcher"], [7, 7, "field"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 12, 13, "role", "inspires", false, false], [0, 0, 15, 16, "role", "inspires", false, false], [0, 0, 18, 19, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Walter", "'s", "work", "inspired", "subsequent", "generations", "of", "robotics", "researchers", ",", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work inspired subsequent generations of robotics researchers, such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 22], [23, 33], [34, 45], [46, 48], [49, 57], [58, 69], [69, 70], [71, 75], [76, 78], [79, 85], [86, 92], [92, 93], [94, 98], [99, 106], [107, 110], [111, 115], [116, 122], [122, 123]]}
{"doc_key": "ai-test-297", "ner": [[7, 7, "algorithm"], [9, 10, "researcher"], [16, 22, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 9, 10, "origin", "", false, false], [7, 7, 16, 22, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Subsequently", ",", "a", "similar", "GPU", "-", "based", "CNN", "by", "Alex", "Krizhevsky", "et", "al", ".", "won", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "2012", "."], "sentence-detokenized": "Subsequently, a similar GPU-based CNN by Alex Krizhevsky et al. won the ImageNet Large Scale Visual Recognition Challenge 2012.", "token2charspan": [[0, 12], [12, 13], [14, 15], [16, 23], [24, 27], [27, 28], [28, 33], [34, 37], [38, 40], [41, 45], [46, 56], [57, 59], [60, 62], [62, 63], [64, 67], [68, 71], [72, 80], [81, 86], [87, 92], [93, 99], [100, 111], [112, 121], [122, 126], [126, 127]]}
{"doc_key": "ai-test-298", "ner": [[2, 3, "misc"], [9, 10, "metrics"], [13, 14, "metrics"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 2, 3, "type-of", "", false, false], [13, 14, 2, 3, "type-of", "", false, false], [13, 14, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Commonly", "used", "loss", "functions", "for", "probabilistic", "classification", "include", "the", "log", "loss", "and", "the", "Brier", "score", "between", "expected", "and", "TRUE", "probability", "distributions", "."], "sentence-detokenized": "Commonly used loss functions for probabilistic classification include the log loss and the Brier score between expected and TRUE probability distributions.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 28], [29, 32], [33, 46], [47, 61], [62, 69], [70, 73], [74, 77], [78, 82], [83, 86], [87, 90], [91, 96], [97, 102], [103, 110], [111, 119], [120, 123], [124, 128], [129, 140], [141, 154], [154, 155]]}
{"doc_key": "ai-test-299", "ner": [[4, 5, "organisation"], [12, 12, "field"], [15, 15, "organisation"], [19, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 12, 12, "general-affiliation", "field_of_study", false, false], [4, 5, 19, 20, "part-of", "", false, false], [15, 15, 4, 5, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "May", "2016", ",", "NtechLab", "was", "admitted", "to", "the", "official", "testing", "of", "biometric", "technology", "by", "NIST", "among", "the", "three", "Russian", "companies", "."], "sentence-detokenized": "In May 2016, NtechLab was admitted to the official testing of biometric technology by NIST among the three Russian companies.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [22, 25], [26, 34], [35, 37], [38, 41], [42, 50], [51, 58], [59, 61], [62, 71], [72, 82], [83, 85], [86, 90], [91, 96], [97, 100], [101, 106], [107, 114], [115, 124], [124, 125]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "floating", "-", "point", "numbers", "only", "have", "a", "certain", "mathematical", "precision", "."], "sentence-detokenized": "However, floating-point numbers only have a certain mathematical precision.", "token2charspan": [[0, 7], [7, 8], [9, 17], [17, 18], [18, 23], [24, 31], [32, 36], [37, 41], [42, 43], [44, 51], [52, 64], [65, 74], [74, 75]]}
{"doc_key": "ai-test-301", "ner": [[4, 4, "organisation"], [10, 16, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 10, 16, "role", "contributes_to", false, false], [18, 18, 10, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "2015", ",", "several", "SenseTime", "papers", "were", "accepted", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "During 2015, several SenseTime papers were accepted at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 6], [7, 11], [11, 12], [13, 20], [21, 30], [31, 37], [38, 42], [43, 51], [52, 54], [55, 58], [59, 69], [70, 72], [73, 81], [82, 88], [89, 92], [93, 100], [101, 112], [113, 114], [114, 118], [118, 119], [119, 120]]}
{"doc_key": "ai-test-302", "ner": [[5, 7, "task"], [9, 9, "task"], [12, 13, "task"], [15, 18, "task"], [21, 21, "field"], [23, 25, "misc"], [28, 34, "conference"], [41, 43, "misc"], [45, 46, "conference"], [63, 65, "misc"], [67, 67, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 7, 21, 21, "part-of", "task_part_of_field", false, false], [9, 9, 5, 7, "named", "", false, false], [12, 13, 21, 21, "part-of", "task_part_of_field", false, false], [15, 18, 12, 13, "named", "", false, false], [23, 25, 28, 34, "temporal", "", false, false], [41, 43, 45, 46, "temporal", "", false, false], [63, 65, 67, 67, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["He", "co-developed", "optimal", "algorithms", "for", "Structure", "From", "Motion", "(", "SFM", ",", "or", "Visual", "SLAM", ",", "simultaneous", "localisation", "and", "mapping", ",", "in", "Robotics", ";", "Best", "Paper", "award", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "1998", ")", ",", "characterised", "ambiguities", "(", "David", "Marr", "award", "at", "ICCV", "1999", ")", ",", "and", "also", "characterised", "the", "identifiability", "and", "observability", "of", "visual", "-", "inertial", "sensor", "fusion", "(", "Best", "Paper", "award", "at", "Robotics", "2015", ")", "."], "sentence-detokenized": "He co-developed optimal algorithms for Structure From Motion (SFM, or Visual SLAM, simultaneous localisation and mapping, in Robotics; Best Paper award at the Conference on Computer Vision and Pattern Recognition 1998), characterised ambiguities (David Marr award at ICCV 1999), and also characterised the identifiability and observability of visual-inertial sensor fusion (Best Paper award at Robotics 2015).", "token2charspan": [[0, 2], [3, 15], [16, 23], [24, 34], [35, 38], [39, 48], [49, 53], [54, 60], [61, 62], [62, 65], [65, 66], [67, 69], [70, 76], [77, 81], [81, 82], [83, 95], [96, 108], [109, 112], [113, 120], [120, 121], [122, 124], [125, 133], [133, 134], [135, 139], [140, 145], [146, 151], [152, 154], [155, 158], [159, 169], [170, 172], [173, 181], [182, 188], [189, 192], [193, 200], [201, 212], [213, 217], [217, 218], [218, 219], [220, 233], [234, 245], [246, 247], [247, 252], [253, 257], [258, 263], [264, 266], [267, 271], [272, 276], [276, 277], [277, 278], [279, 282], [283, 287], [288, 301], [302, 305], [306, 321], [322, 325], [326, 339], [340, 342], [343, 349], [349, 350], [350, 358], [359, 365], [366, 372], [373, 374], [374, 378], [379, 384], [385, 390], [391, 393], [394, 402], [403, 407], [407, 408], [408, 409]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 11, "field"], [13, 14, "field"], [21, 22, "task"], [24, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 7, 8, "part-of", "task_part_of_field", false, false], [0, 1, 10, 11, "part-of", "task_part_of_field", false, false], [0, 1, 13, 14, "part-of", "task_part_of_field", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 24, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "a", "key", "tool", "in", "image", "processing", ",", "machine", "vision", "and", "computer", "vision", ",", "particularly", "in", "the", "areas", "of", "feature", "detection", "and", "extraction", "."], "sentence-detokenized": "Edge detection is a key tool in image processing, machine vision and computer vision, particularly in the areas of feature detection and extraction.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 19], [20, 23], [24, 28], [29, 31], [32, 37], [38, 48], [48, 49], [50, 57], [58, 64], [65, 68], [69, 77], [78, 84], [84, 85], [86, 98], [99, 101], [102, 105], [106, 111], [112, 114], [115, 122], [123, 132], [133, 136], [137, 147], [147, 148]]}
{"doc_key": "ai-test-305", "ner": [[8, 9, "misc"], [26, 29, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "example", "is", "a", "variable", "such", "as", "the", "outside", "temperature", "(", "mathtemp", "/", "math", ")", ",", "which", "in", "a", "given", "application", "could", "be", "recorded", "to", "several", "decimal", "places", "of", "accuracy", "(", "depending", "on", "the", "sensing", "equipment", ")", "."], "sentence-detokenized": "An example is a variable such as the outside temperature (mathtemp / math), which in a given application could be recorded to several decimal places of accuracy (depending on the sensing equipment).", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 29], [30, 32], [33, 36], [37, 44], [45, 56], [57, 58], [58, 66], [67, 68], [69, 73], [73, 74], [74, 75], [76, 81], [82, 84], [85, 86], [87, 92], [93, 104], [105, 110], [111, 113], [114, 122], [123, 125], [126, 133], [134, 141], [142, 148], [149, 151], [152, 160], [161, 162], [162, 171], [172, 174], [175, 178], [179, 186], [187, 196], [196, 197], [197, 198]]}
{"doc_key": "ai-test-306", "ner": [[3, 4, "person"], [6, 7, "person"], [9, 10, "person"], [19, 20, "person"], [22, 22, "misc"], [26, 26, "misc"], [28, 29, "person"], [31, 31, "organisation"], [33, 34, "person"], [36, 36, "organisation"], [38, 39, "person"], [42, 42, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[28, 29, 22, 22, "part-of", "", false, false], [28, 29, 26, 26, "role", "", false, false], [33, 34, 31, 31, "role", "", false, false], [38, 39, 36, 36, "role", "youtuber", false, false], [42, 42, 38, 39, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Returning", "judges", "are", "Fon", "Davis", ",", "Jessica", "Chobot", "and", "Leland", "Melvin", ",", "plus", "celebrity", "guest", "judges", "such", "as", "actor", "Clark", "Gregg", ",", "MythBusters", "host", "and", "former", "Battlebots", "builder", "Adam", "Savage", ",", "NFL", "tightend", "Vernon", "Davis", "and", "YouTube", "star", "Michael", "Stevens", ",", "aka", "Vsauce", "."], "sentence-detokenized": "Returning judges are Fon Davis, Jessica Chobot and Leland Melvin, plus celebrity guest judges such as actor Clark Gregg, MythBusters host and former Battlebots builder Adam Savage, NFL tightend Vernon Davis and YouTube star Michael Stevens, aka Vsauce.", "token2charspan": [[0, 9], [10, 16], [17, 20], [21, 24], [25, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 57], [58, 64], [64, 65], [66, 70], [71, 80], [81, 86], [87, 93], [94, 98], [99, 101], [102, 107], [108, 113], [114, 119], [119, 120], [121, 132], [133, 137], [138, 141], [142, 148], [149, 159], [160, 167], [168, 172], [173, 179], [179, 180], [181, 184], [185, 193], [194, 200], [201, 206], [207, 210], [211, 218], [219, 223], [224, 231], [232, 239], [239, 240], [241, 244], [245, 251], [251, 252]]}
{"doc_key": "ai-test-307", "ner": [[14, 14, "algorithm"], [15, 19, "algorithm"], [21, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 21, 23, "part-of", "", false, false], [15, 19, 21, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "methods", ",", "however", ",", "have", "never", "trumped", "the", "technology", "of", "the", "internal", "non-uniform", "Gaussian", "mixture", "/", "hidden", "Markov", "model", "(", "GMM", "-", "HMM", ")", ",", "which", "is", "based", "on", "discriminatively", "trained", "generative", "speech", "models", "."], "sentence-detokenized": "These methods, however, have never trumped the technology of the internal non-uniform Gaussian mixture/hidden Markov model (GMM-HMM), which is based on discriminatively trained generative speech models.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 22], [22, 23], [24, 28], [29, 34], [35, 42], [43, 46], [47, 57], [58, 60], [61, 64], [65, 73], [74, 85], [86, 94], [95, 102], [102, 103], [103, 109], [110, 116], [117, 122], [123, 124], [124, 127], [127, 128], [128, 131], [131, 132], [132, 133], [134, 139], [140, 142], [143, 148], [149, 151], [152, 168], [169, 176], [177, 187], [188, 194], [195, 201], [201, 202]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "and", "SciPy", "offer", "practical", "ways", "to", "apply", "these", "different", "methods", "."], "sentence-detokenized": "Software packages such as MATLAB, GNU Octave, Scilab and SciPy offer practical ways to apply these different methods.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [53, 56], [57, 62], [63, 68], [69, 78], [79, 83], [84, 86], [87, 92], [93, 98], [99, 108], [109, 116], [116, 117]]}
{"doc_key": "ai-test-309", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [8, 9, "task"], [16, 17, "researcher"], [19, 20, "university"], [22, 23, "researcher"], [25, 28, "organisation"], [30, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 8, 9, "related-to", "", false, false], [0, 2, 16, 17, "origin", "", false, false], [0, 2, 22, 23, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [16, 17, 19, 20, "physical", "", false, false], [16, 17, 19, 20, "role", "", false, false], [22, 23, 25, 28, "physical", "", false, false], [22, 23, 25, 28, "role", "", false, false], [30, 30, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", ",", "a", "speech", "processing", "algorithm", ",", "was", "first", "proposed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", "."], "sentence-detokenized": "Linear predictive coding (LPC), a speech processing algorithm, was first proposed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 72], [73, 81], [82, 84], [85, 93], [94, 101], [102, 104], [105, 111], [112, 122], [123, 126], [127, 132], [133, 138], [139, 141], [142, 148], [149, 158], [159, 162], [163, 172], [173, 174], [174, 177], [177, 178], [179, 181], [182, 186], [186, 187]]}
{"doc_key": "ai-test-310", "ner": [[20, 27, "conference"], [29, 29, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[29, 29, 20, 27, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2006", ",", "on", "the", "occasion", "of", "the", "25th", "anniversary", "of", "the", "algorithm", ",", "a", "workshop", "was", "organised", "at", "the", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "to", "summarise", "the", "most", "recent", "contributions", "and", "variations", "made", "to", "the", "original", "algorithm", ",", "aimed", "mainly", "at", "improving", "the", "speed", "of", "the", "algorithm", ",", "the", "robustness", "and", "accuracy", "of", "the", "estimated", "solution", ",", "and", "decreasing", "the", "dependence", "on", "user", "-", "defined", "constants", "."], "sentence-detokenized": "In 2006, on the occasion of the 25th anniversary of the algorithm, a workshop was organised at the International Conference on Computer Vision and Pattern Recognition (CVPR) to summarise the most recent contributions and variations made to the original algorithm, aimed mainly at improving the speed of the algorithm, the robustness and accuracy of the estimated solution, and decreasing the dependence on user-defined constants.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 24], [25, 27], [28, 31], [32, 36], [37, 48], [49, 51], [52, 55], [56, 65], [65, 66], [67, 68], [69, 77], [78, 81], [82, 91], [92, 94], [95, 98], [99, 112], [113, 123], [124, 126], [127, 135], [136, 142], [143, 146], [147, 154], [155, 166], [167, 168], [168, 172], [172, 173], [174, 176], [177, 186], [187, 190], [191, 195], [196, 202], [203, 216], [217, 220], [221, 231], [232, 236], [237, 239], [240, 243], [244, 252], [253, 262], [262, 263], [264, 269], [270, 276], [277, 279], [280, 289], [290, 293], [294, 299], [300, 302], [303, 306], [307, 316], [316, 317], [318, 321], [322, 332], [333, 336], [337, 345], [346, 348], [349, 352], [353, 362], [363, 371], [371, 372], [373, 376], [377, 387], [388, 391], [392, 402], [403, 405], [406, 410], [410, 411], [411, 418], [419, 428], [428, 429]]}
{"doc_key": "ai-test-311", "ner": [[4, 6, "university"], [9, 12, "organisation"], [14, 16, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Members", "have", "attended", "the", "University", "of", "Debrecen", ",", "the", "Hungarian", "Academy", "of", "Sciences", ",", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "University", ",", "etc", "."], "sentence-detokenized": "Members have attended the University of Debrecen, the Hungarian Academy of Sciences, E\u00f6tv\u00f6s Lor\u00e1nd University, etc.", "token2charspan": [[0, 7], [8, 12], [13, 21], [22, 25], [26, 36], [37, 39], [40, 48], [48, 49], [50, 53], [54, 63], [64, 71], [72, 74], [75, 83], [83, 84], [85, 91], [92, 98], [99, 109], [109, 110], [111, 114], [114, 115]]}
{"doc_key": "ai-test-312", "ner": [[2, 2, "algorithm"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 16, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "extend", "SVM", "to", "cases", "where", "the", "data", "are", "not", "linearly", "separable", ",", "we", "introduce", "the", "loss", "function", ","], "sentence-detokenized": "To extend SVM to cases where the data are not linearly separable, we introduce the loss function,", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 16], [17, 22], [23, 28], [29, 32], [33, 37], [38, 41], [42, 45], [46, 54], [55, 64], [64, 65], [66, 68], [69, 78], [79, 82], [83, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-313", "ner": [[0, 0, "programlang"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 11, 12, "origin", "", false, false], [0, 0, 14, 15, "origin", "", false, false], [0, 0, 17, 18, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "is", "an", "educational", "programming", "language", ",", "designed", "in", "1967", "by", "Wally", "Feurzeig", ",", "Seymour", "Papert", "and", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo is an educational programming language, designed in 1967 by Wally Feurzeig, Seymour Papert and Cynthia Solomon.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 34], [35, 43], [43, 44], [45, 53], [54, 56], [57, 61], [62, 64], [65, 70], [71, 79], [79, 80], [81, 88], [89, 95], [96, 99], [100, 107], [108, 115], [115, 116]]}
{"doc_key": "ai-test-314", "ner": [[0, 4, "organisation"], [10, 12, "organisation"], [14, 17, "location"], [19, 19, "location"], [21, 21, "location"], [31, 34, "product"], [40, 43, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 4, 10, 12, "role", "works_for", false, false], [10, 12, 14, 17, "physical", "", false, false], [14, 17, 19, 19, "physical", "", false, false], [19, 19, 21, 21, "physical", "", false, false], [31, 34, 0, 4, "origin", "", false, false], [40, 43, 31, 34, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "Eyring", "Research", "Institute", "was", "instrumental", "to", "the", "US", "Air", "Force", "Missile", "Directorate", "at", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", ",", "in", "producing", ",", "in", "military", "secrecy", ",", "the", "intelligent", "systems", "technology", "software", "that", "was", "crucial", "to", "the", "Reagan", "Star", "Wars", "programme", "."], "sentence-detokenized": "The Eyring Research Institute was instrumental to the US Air Force Missile Directorate at Hill Air Force Base near Ogden, Utah, in producing, in military secrecy, the intelligent systems technology software that was crucial to the Reagan Star Wars programme.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 29], [30, 33], [34, 46], [47, 49], [50, 53], [54, 56], [57, 60], [61, 66], [67, 74], [75, 86], [87, 89], [90, 94], [95, 98], [99, 104], [105, 109], [110, 114], [115, 120], [120, 121], [122, 126], [126, 127], [128, 130], [131, 140], [140, 141], [142, 144], [145, 153], [154, 161], [161, 162], [163, 166], [167, 178], [179, 186], [187, 197], [198, 206], [207, 211], [212, 215], [216, 223], [224, 226], [227, 230], [231, 237], [238, 242], [243, 247], [248, 257], [257, 258]]}
{"doc_key": "ai-test-315", "ner": [[12, 13, "field"], [23, 26, "researcher"], [28, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Over", "the", "decades", ",", "he", "has", "researched", "and", "developed", "emerging", "fields", "of", "computer", "science", ",", "from", "compilers", "to", "programming", "languages", "and", "system", "architecture", "John", "F", ".", "Sowa", "and", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "Over the decades, he has researched and developed emerging fields of computer science, from compilers to programming languages and system architecture John F. Sowa and John Zachman (1992).", "token2charspan": [[0, 4], [5, 8], [9, 16], [16, 17], [18, 20], [21, 24], [25, 35], [36, 39], [40, 49], [50, 58], [59, 65], [66, 68], [69, 77], [78, 85], [85, 86], [87, 91], [92, 101], [102, 104], [105, 116], [117, 126], [127, 130], [131, 137], [138, 150], [151, 155], [156, 157], [157, 158], [159, 163], [164, 167], [168, 172], [173, 180], [181, 182], [182, 186], [186, 187], [187, 188]]}
{"doc_key": "ai-test-316", "ner": [[0, 1, "algorithm"], [2, 10, "algorithm"], [7, 13, "algorithm"], [18, 19, "field"], [21, 22, "field"], [26, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 10, 0, 1, "named", "", false, false], [7, 13, 0, 1, "named", "", false, false], [18, 19, 0, 1, "usage", "", false, false], [21, 22, 0, 1, "usage", "", false, false], [26, 28, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Sobel", "operator", ",", "sometimes", "called", "the", "Sobel", "-", "Feldman", "operator", "or", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "particularly", "in", "edge", "detection", "algorithms", ",", "where", "it", "creates", "an", "image", "that", "emphasises", "edges", "."], "sentence-detokenized": "The Sobel operator, sometimes called the Sobel-Feldman operator or Sobel filter, is used in image processing and computer vision, particularly in edge detection algorithms, where it creates an image that emphasises edges.", "token2charspan": [[0, 3], [4, 9], [10, 18], [18, 19], [20, 29], [30, 36], [37, 40], [41, 46], [46, 47], [47, 54], [55, 63], [64, 66], [67, 72], [73, 79], [79, 80], [81, 83], [84, 88], [89, 91], [92, 97], [98, 108], [109, 112], [113, 121], [122, 128], [128, 129], [130, 142], [143, 145], [146, 150], [151, 160], [161, 171], [171, 172], [173, 178], [179, 181], [182, 189], [190, 192], [193, 198], [199, 203], [204, 214], [215, 220], [220, 221]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [3, 4, "field"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 4, "compare", "", false, false], [0, 0, 3, 4, "type-of", "", false, false], [0, 0, 12, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "is", "a", "supervised", "learning", "algorithm", "that", "uses", "data", "labels", ",", "while", "PCA", "is", "a", "learning", "algorithm", "that", "ignores", "labels", "."], "sentence-detokenized": "LDA is a supervised learning algorithm that uses data labels, while PCA is a learning algorithm that ignores labels.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 19], [20, 28], [29, 38], [39, 43], [44, 48], [49, 53], [54, 60], [60, 61], [62, 67], [68, 71], [72, 74], [75, 76], [77, 85], [86, 95], [96, 100], [101, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "linear", "classification", "algorithms", "are", "Winnow", ",", "support", "vector", "machine", "and", "logistic", "regression", "."], "sentence-detokenized": "Other linear classification algorithms are Winnow, support vector machine and logistic regression.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 38], [39, 42], [43, 49], [49, 50], [51, 58], [59, 65], [66, 73], [74, 77], [78, 86], [87, 97], [97, 98]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [4, 5, "programlang"], [15, 17, "product"], [19, 19, "programlang"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 4, 5, "general-affiliation", "", true, false], [0, 0, 15, 17, "general-affiliation", "", true, false], [0, 0, 19, 19, "general-affiliation", "", true, false], [0, 0, 21, 21, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "consists", "of", "a", "C", "+", "class", "library", "and", "several", "interpreted", "interface", "layers", ",", "including", "Tcl", "/", "Tk", ",", "Java", "and", "Python", "."], "sentence-detokenized": "VTK consists of a C+ class library and several interpreted interface layers, including Tcl / Tk, Java and Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 17], [18, 19], [19, 20], [21, 26], [27, 34], [35, 38], [39, 46], [47, 58], [59, 68], [69, 75], [75, 76], [77, 86], [87, 90], [91, 92], [93, 95], [95, 96], [97, 101], [102, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-test-320", "ner": [[10, 12, "task"], [19, 21, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", ",", "text", "produced", "by", "processing", "spontaneous", "speech", "through", "automatic", "speech", "recognition", "and", "printed", "or", "handwritten", "text", "through", "optical", "character", "recognition", "contains", "processing", "noise", "."], "sentence-detokenized": "In addition, text produced by processing spontaneous speech through automatic speech recognition and printed or handwritten text through optical character recognition contains processing noise.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 17], [18, 26], [27, 29], [30, 40], [41, 52], [53, 59], [60, 67], [68, 77], [78, 84], [85, 96], [97, 100], [101, 108], [109, 111], [112, 123], [124, 128], [129, 136], [137, 144], [145, 154], [155, 166], [167, 175], [176, 186], [187, 192], [192, 193]]}
{"doc_key": "ai-test-321", "ner": [[0, 1, "researcher"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 10, 10, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "has", "written", "several", "books", "and", "directed", "the", "development", "of", "WordNet", ",", "an", "online", "database", "of", "word", "links", "that", "can", "be", "used", "by", "computer", "programmes", "."], "sentence-detokenized": "Miller has written several books and directed the development of WordNet, an online database of word links that can be used by computer programmes.", "token2charspan": [[0, 6], [7, 10], [11, 18], [19, 26], [27, 32], [33, 36], [37, 45], [46, 49], [50, 61], [62, 64], [65, 72], [72, 73], [74, 76], [77, 83], [84, 92], [93, 95], [96, 100], [101, 106], [107, 111], [112, 115], [116, 118], [119, 123], [124, 126], [127, 135], [136, 146], [146, 147]]}
{"doc_key": "ai-test-322", "ner": [[1, 1, "field"], [7, 9, "organisation"], [12, 12, "country"], [14, 15, "person"], [17, 19, "person"], [21, 22, "person"], [24, 25, "person"], [28, 28, "country"], [30, 33, "location"], [35, 36, "misc"], [37, 38, "person"], [40, 41, "person"], [43, 43, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[7, 9, 12, 12, "physical", "", false, false], [14, 15, 28, 28, "physical", "", false, false], [17, 19, 28, 28, "physical", "", false, false], [21, 22, 28, 28, "physical", "", false, false], [24, 25, 28, 28, "physical", "", false, false], [30, 33, 1, 1, "general-affiliation", "", false, false], [30, 33, 37, 38, "artifact", "", false, false], [35, 36, 37, 38, "named", "", false, false], [40, 41, 43, 43, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Contemporary", "automata", "are", "represented", "by", "works", "by", "Cabaret", "Mechanical", "Theatre", "in", "the", "UK", ",", "Dug", "North", "and", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "in", "the", "US", ",", "Le", "D\u00e9fenseur", "du", "Temps", "by", "French", "artist", "Jacques", "Monestier", "and", "Fran\u00e7ois", "Junod", "in", "Switzerland", "."], "sentence-detokenized": "Contemporary automata are represented by works by Cabaret Mechanical Theatre in the UK, Dug North and Chomick + Meder, Arthur Ganson, Joe Jones in the US, Le D\u00e9fenseur du Temps by French artist Jacques Monestier and Fran\u00e7ois Junod in Switzerland.", "token2charspan": [[0, 12], [13, 21], [22, 25], [26, 37], [38, 40], [41, 46], [47, 49], [50, 57], [58, 68], [69, 76], [77, 79], [80, 83], [84, 86], [86, 87], [88, 91], [92, 97], [98, 101], [102, 109], [110, 111], [112, 117], [117, 118], [119, 125], [126, 132], [132, 133], [134, 137], [138, 143], [144, 146], [147, 150], [151, 153], [153, 154], [155, 157], [158, 167], [168, 170], [171, 176], [177, 179], [180, 186], [187, 193], [194, 201], [202, 211], [212, 215], [216, 224], [225, 230], [231, 233], [234, 245], [245, 246]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 22, 22, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "includes", "the", "standard", "loops", "codefor", "/", "code", "and", "codewhile", "/", "code", ",", "but", "(", "as", "in", "other", "similar", "applications", "such", "as", "R", ")", ",", "the", "use", "of", "vector", "notation", "is", "encouraged", "and", "is", "often", "faster", "to", "execute", "."], "sentence-detokenized": "MATLAB includes the standard loops codefor / code and codewhile / code, but (as in other similar applications such as R), the use of vector notation is encouraged and is often faster to execute.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 28], [29, 34], [35, 42], [43, 44], [45, 49], [50, 53], [54, 63], [64, 65], [66, 70], [70, 71], [72, 75], [76, 77], [77, 79], [80, 82], [83, 88], [89, 96], [97, 109], [110, 114], [115, 117], [118, 119], [119, 120], [120, 121], [122, 125], [126, 129], [130, 132], [133, 139], [140, 148], [149, 151], [152, 162], [163, 166], [167, 169], [170, 175], [176, 182], [183, 185], [186, 193], [193, 194]]}
{"doc_key": "ai-test-324", "ner": [[3, 3, "researcher"], [9, 12, "conference"], [17, 19, "field"], [22, 28, "misc"], [31, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 22, 28, "win-defeat", "", false, false], [3, 3, 31, 40, "win-defeat", "", false, false], [22, 28, 9, 12, "temporal", "", false, false], [22, 28, 17, 19, "topic", "", false, false], [31, 40, 9, 12, "temporal", "", false, false], [31, 40, 17, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2007", ",", "Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "for", "his", "achievements", "in", "computer", "science", "education", ":", "the", "Karl", "V", ".", "Karlstrom", "Outstanding", "Educator", "Award", "and", "the", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contributions", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "In 2007, Pausch received two awards from the Association for Computing Machinery for his achievements in computer science education: the Karl V. Karlstrom Outstanding Educator Award and the ACM SIGCSE Award for Outstanding Contributions to Computer Science Education.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 24], [25, 28], [29, 35], [36, 40], [41, 44], [45, 56], [57, 60], [61, 70], [71, 80], [81, 84], [85, 88], [89, 101], [102, 104], [105, 113], [114, 121], [122, 131], [131, 132], [133, 136], [137, 141], [142, 143], [143, 144], [145, 154], [155, 166], [167, 175], [176, 181], [182, 185], [186, 189], [190, 193], [194, 200], [201, 206], [207, 210], [211, 222], [223, 236], [237, 239], [240, 248], [249, 256], [257, 266], [266, 267]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [8, 8, "product"], [9, 9, "product"], [15, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 8, "role", "sells", false, false], [8, 8, 9, 9, "general-affiliation", "", false, false], [8, 8, 15, 16, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "shipped", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was shipped to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 73], [74, 76], [77, 84], [85, 91], [92, 94], [95, 99], [99, 100]]}
{"doc_key": "ai-test-326", "ner": [[0, 1, "algorithm"], [5, 7, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 0, 1, "usage", "", false, false], [12, 13, 5, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantic", "networks", "are", "used", "in", "natural", "language", "processing", "applications", ",", "such", "as", "semantic", "parsing", "."], "sentence-detokenized": "Semantic networks are used in natural language processing applications, such as semantic parsing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 26], [27, 29], [30, 37], [38, 46], [47, 57], [58, 70], [70, 71], [72, 76], [77, 79], [80, 88], [89, 96], [96, 97]]}
{"doc_key": "ai-test-327", "ner": [[4, 5, "field"], [7, 8, "field"], [10, 11, "task"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 8, 4, 5, "usage", "", false, false], [10, 11, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Some", "successful", "applications", "of", "deep", "learning", "are", "computer", "vision", "and", "speech", "recognition", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Some successful applications of deep learning are computer vision and speech recognition. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 31], [32, 36], [37, 45], [46, 49], [50, 58], [59, 65], [66, 69], [70, 76], [77, 88], [88, 89], [90, 97], [98, 101], [101, 102], [103, 108], [109, 115], [115, 116], [117, 123], [124, 133], [133, 134], [135, 141], [142, 143], [143, 144], [145, 147], [147, 148]]}
{"doc_key": "ai-test-328", "ner": [[5, 10, "product"], [16, 16, "misc"], [19, 19, "misc"], [25, 25, "product"], [29, 30, "task"], [32, 33, "task"], [35, 36, "task"], [38, 40, "field"], [42, 43, "task"], [45, 46, "field"], [48, 49, "task"], [51, 52, "task"], [54, 55, "task"], [57, 58, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[5, 10, 16, 16, "physical", "travels_to", false, false], [5, 10, 19, 19, "physical", "travels_to", false, false], [25, 25, 5, 10, "part-of", "", false, false], [25, 25, 5, 10, "role", "maintains", false, false], [25, 25, 29, 30, "related-to", "has_ability_to", false, false], [25, 25, 32, 33, "related-to", "has_ability_to", false, false], [25, 25, 35, 36, "related-to", "has_ability_to", false, false], [25, 25, 38, 40, "related-to", "has_ability_to", false, false], [25, 25, 42, 43, "related-to", "has_ability_to", false, false], [25, 25, 45, 46, "related-to", "has_ability_to", false, false], [25, 25, 48, 49, "related-to", "has_ability_to", false, false], [25, 25, 51, 52, "related-to", "has_ability_to", false, false], [25, 25, 54, 55, "related-to", "has_ability_to", false, false], [25, 25, 57, 58, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "addition", "to", "maintaining", "the", "systems", "of", "the", "Discovery", "One", "spacecraft", "during", "the", "interplanetary", "mission", "to", "Jupiter", "(", "or", "Saturn", "in", "the", "novel", ")", ",", "HAL", "is", "capable", "of", "speech", "synthesis", ",", "voice", "recognition", ",", "facial", "recognition", ",", "natural", "language", "processing", ",", "lip", "reading", ",", "art", "appreciation", ",", "affective", "computing", ",", "automated", "reasoning", ",", "spacecraft", "piloting", "and", "chess", "playing", "."], "sentence-detokenized": "In addition to maintaining the systems of the Discovery One spacecraft during the interplanetary mission to Jupiter (or Saturn in the novel), HAL is capable of speech synthesis, voice recognition, facial recognition, natural language processing, lip reading, art appreciation, affective computing, automated reasoning, spacecraft piloting and chess playing.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 38], [39, 41], [42, 45], [46, 55], [56, 59], [60, 70], [71, 77], [78, 81], [82, 96], [97, 104], [105, 107], [108, 115], [116, 117], [117, 119], [120, 126], [127, 129], [130, 133], [134, 139], [139, 140], [140, 141], [142, 145], [146, 148], [149, 156], [157, 159], [160, 166], [167, 176], [176, 177], [178, 183], [184, 195], [195, 196], [197, 203], [204, 215], [215, 216], [217, 224], [225, 233], [234, 244], [244, 245], [246, 249], [250, 257], [257, 258], [259, 262], [263, 275], [275, 276], [277, 286], [287, 296], [296, 297], [298, 307], [308, 317], [317, 318], [319, 329], [330, 338], [339, 342], [343, 348], [349, 356], [356, 357]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [4, 4, "country"], [7, 8, "country"], [11, 11, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 4, "physical", "", false, false], [0, 1, 7, 8, "physical", "", false, false], [0, 1, 11, 11, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr", "Julesz", "emigrated", "from", "Hungary", "to", "the", "United", "States", "after", "the", "Soviet", "invasion", "in", "1956", "."], "sentence-detokenized": "Dr Julesz emigrated from Hungary to the United States after the Soviet invasion in 1956.", "token2charspan": [[0, 2], [3, 9], [10, 19], [20, 24], [25, 32], [33, 35], [36, 39], [40, 46], [47, 53], [54, 59], [60, 63], [64, 70], [71, 79], [80, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-test-330", "ner": [[0, 1, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sigmoid", "activation", "functions", "use", "a", "second", "non-linearity", "for", "large", "inputs", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+\\", "exp", "(", "-", "v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "The sigmoid activation functions use a second non-linearity for large inputs: math\\ phi (v _ i) = (1 +\\ exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 32], [33, 36], [37, 38], [39, 45], [46, 59], [60, 63], [64, 69], [70, 76], [76, 77], [78, 82], [82, 83], [84, 87], [88, 89], [89, 90], [91, 92], [93, 94], [94, 95], [96, 97], [98, 99], [99, 100], [101, 103], [104, 107], [108, 109], [109, 110], [110, 111], [112, 113], [114, 115], [115, 116], [116, 117], [118, 119], [120, 121], [121, 123], [123, 124], [125, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-331", "ner": [[12, 14, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "probabilities", "are", "used", "to", "determine", "what", "the", "target", "is", "using", "a", "maximum", "likelihood", "decision", "."], "sentence-detokenized": "These probabilities are used to determine what the target is using a maximum likelihood decision.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 46], [47, 50], [51, 57], [58, 60], [61, 66], [67, 68], [69, 76], [77, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-332", "ner": [[6, 8, "university"], [14, 16, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1984", "he", "moved", "to", "the", "University", "of", "Constance", "and", "in", "1990", "to", "the", "University", "of", "Salzburg", "."], "sentence-detokenized": "In 1984 he moved to the University of Constance and in 1990 to the University of Salzburg.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 47], [48, 51], [52, 54], [55, 59], [60, 62], [63, 66], [67, 77], [78, 80], [81, 89], [89, 90]]}
{"doc_key": "ai-test-333", "ner": [[7, 8, "metrics"], [10, 12, "metrics"], [14, 16, "metrics"], [18, 18, "metrics"], [20, 21, "metrics"], [23, 26, "metrics"], [31, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 12, 7, 8, "origin", "based_on", false, false], [14, 16, 7, 8, "origin", "based_on", false, false], [18, 18, 7, 8, "origin", "based_on", false, false], [20, 21, 7, 8, "origin", "based_on", false, false], [23, 26, 7, 8, "origin", "based_on", false, false], [31, 31, 7, 8, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Some", "popular", "fitness", "functions", "based", "on", "the", "confusion", "matrix", "include", "sensitivity", "/", "specificity", ",", "recall", "/", "precision", ",", "F-measure", ",", "Jaccard", "similarity", ",", "Matthews", "'", "correlation", "coefficient", "and", "cost", "/", "gain", "matrix", "combining", "the", "costs", "and", "gains", "assigned", "to", "the", "4", "different", "classification", "types", "."], "sentence-detokenized": "Some popular fitness functions based on the confusion matrix include sensitivity/specificity, recall/precision, F-measure, Jaccard similarity, Matthews' correlation coefficient and cost/gain matrix combining the costs and gains assigned to the 4 different classification types.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 30], [31, 36], [37, 39], [40, 43], [44, 53], [54, 60], [61, 68], [69, 80], [80, 81], [81, 92], [92, 93], [94, 100], [100, 101], [101, 110], [110, 111], [112, 121], [121, 122], [123, 130], [131, 141], [141, 142], [143, 151], [151, 152], [153, 164], [165, 176], [177, 180], [181, 185], [185, 186], [186, 190], [191, 197], [198, 207], [208, 211], [212, 217], [218, 221], [222, 227], [228, 236], [237, 239], [240, 243], [244, 245], [246, 255], [256, 270], [271, 276], [276, 277]]}
{"doc_key": "ai-test-334", "ner": [[7, 7, "product"], [9, 9, "product"], [11, 11, "product"], [13, 13, "product"], [16, 17, "programlang"], [29, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[29, 31, 7, 7, "part-of", "", false, false], [29, 31, 9, 9, "part-of", "", false, false], [29, 31, 11, 11, "part-of", "", false, false], [29, 31, 13, 13, "part-of", "", false, false], [29, 31, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Common", "numerical", "programming", "environments", ",", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "and", "the", "R", "language", ",", "provide", "some", "of", "the", "simplest", "feature", "extraction", "techniques", "(", "e.g.", "principal", "component", "analysis", ")", "via", "built", "-", "in", "commands", "."], "sentence-detokenized": "Common numerical programming environments, such as MATLAB, SciLab, NumPy, Sklearn and the R language, provide some of the simplest feature extraction techniques (e.g. principal component analysis) via built-in commands.", "token2charspan": [[0, 6], [7, 16], [17, 28], [29, 41], [41, 42], [43, 47], [48, 50], [51, 57], [57, 58], [59, 65], [65, 66], [67, 72], [72, 73], [74, 81], [82, 85], [86, 89], [90, 91], [92, 100], [100, 101], [102, 109], [110, 114], [115, 117], [118, 121], [122, 130], [131, 138], [139, 149], [150, 160], [161, 162], [162, 166], [167, 176], [177, 186], [187, 195], [195, 196], [197, 200], [201, 206], [206, 207], [207, 209], [210, 218], [218, 219]]}
{"doc_key": "ai-test-335", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "have", "been", "implemented", "to", "collaborate", "with", "humans", "in", "performing", "industrial", "production", "tasks", "."], "sentence-detokenized": "Industrial robots have been implemented to collaborate with humans in performing industrial production tasks.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 27], [28, 39], [40, 42], [43, 54], [55, 59], [60, 66], [67, 69], [70, 80], [81, 91], [92, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-test-336", "ner": [[6, 6, "field"], [8, 11, "researcher"], [21, 22, "field"], [24, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 21, 22, "related-to", "", false, false], [6, 6, 24, 25, "related-to", "", false, false], [6, 6, 27, 28, "related-to", "", false, false], [8, 11, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "first", "published", "article", "on", "CGs", ",", "John", "F", ".", "Sowa", "applied", "them", "to", "a", "wide", "range", "of", "topics", "in", "artificial", "intelligence", ",", "computer", "science", "and", "cognitive", "science", "."], "sentence-detokenized": "In the first published article on CGs, John F. Sowa applied them to a wide range of topics in artificial intelligence, computer science and cognitive science.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [23, 30], [31, 33], [34, 37], [37, 38], [39, 43], [44, 45], [45, 46], [47, 51], [52, 59], [60, 64], [65, 67], [68, 69], [70, 74], [75, 80], [81, 83], [84, 90], [91, 93], [94, 104], [105, 117], [117, 118], [119, 127], [128, 135], [136, 139], [140, 149], [150, 157], [157, 158]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [4, 4, "metrics"], [10, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "in", "the", "calculation", "of", "the", "brevity", "penalty", ",", "insofar", "as", "small", "variations", "in", "the", "length", "of", "the", "translation", "do", "not", "affect", "the", "overall", "score", "that", "much", "."], "sentence-detokenized": "NIST also differs from BLEU in the calculation of the brevity penalty, insofar as small variations in the length of the translation do not affect the overall score that much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 46], [47, 49], [50, 53], [54, 61], [62, 69], [69, 70], [71, 78], [79, 81], [82, 87], [88, 98], [99, 101], [102, 105], [106, 112], [113, 115], [116, 119], [120, 131], [132, 134], [135, 138], [139, 145], [146, 149], [150, 157], [158, 163], [164, 168], [169, 173], [173, 174]]}
{"doc_key": "ai-test-338", "ner": [[0, 5, "misc"], [13, 13, "conference"], [21, 23, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 5, 13, 13, "temporal", "", false, false], [0, 5, 21, 23, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "IJCAI", "Award", "for", "Research", "Excellence", "is", "a", "biennial", "award", "presented", "at", "the", "IJCAI", "conference", "to", "researchers", "in", "the", "field", "of", "artificial", "intelligence", "in", "recognition", "of", "their", "career", "excellence", "."], "sentence-detokenized": "The IJCAI Award for Research Excellence is a biennial award presented at the IJCAI conference to researchers in the field of artificial intelligence in recognition of their career excellence.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 28], [29, 39], [40, 42], [43, 44], [45, 53], [54, 59], [60, 69], [70, 72], [73, 76], [77, 82], [83, 93], [94, 96], [97, 108], [109, 111], [112, 115], [116, 121], [122, 124], [125, 135], [136, 148], [149, 151], [152, 163], [164, 166], [167, 172], [173, 179], [180, 190], [190, 191]]}
{"doc_key": "ai-test-339", "ner": [[0, 4, "researcher"], [6, 6, "conference"], [17, 22, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 6, 6, "role", "", false, false], [0, 4, 17, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "was", "one", "of", "the", "original", "AAAI", "Fellows", "and", "is", "the", "only", "individual", "to", "serve", "on", "the", "scientific", "boards", "of", "Microsoft", "and", "Apple", "."], "sentence-detokenized": "Lenat was one of the original AAAI Fellows and is the only individual to serve on the scientific boards of Microsoft and Apple.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 16], [17, 20], [21, 29], [30, 34], [35, 42], [43, 46], [47, 49], [50, 53], [54, 58], [59, 69], [70, 72], [73, 78], [79, 81], [82, 85], [86, 96], [97, 103], [104, 106], [107, 116], [117, 120], [121, 126], [126, 127]]}
{"doc_key": "ai-test-340", "ner": [[0, 0, "algorithm"], [5, 6, "misc"], [10, 12, "metrics"], [19, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "related-to", "minimise", false, false], [10, 12, 5, 6, "type-of", "", false, false], [19, 19, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoders", "are", "trained", "to", "minimise", "reconstruction", "errors", "(", "such", "as", "mean", "square", "error", ")", ",", "often", "referred", "to", "as", "loss", ":"], "sentence-detokenized": "Autoencoders are trained to minimise reconstruction errors (such as mean square error), often referred to as loss:", "token2charspan": [[0, 12], [13, 16], [17, 24], [25, 27], [28, 36], [37, 51], [52, 58], [59, 60], [60, 64], [65, 67], [68, 72], [73, 79], [80, 85], [85, 86], [86, 87], [88, 93], [94, 102], [103, 105], [106, 108], [109, 113], [113, 114]]}
{"doc_key": "ai-test-341", "ner": [[31, 33, "misc"], [37, 37, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[37, 37, 31, 33, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "to", "using", "definitions", "is", "to", "consider", "the", "general", "kinship", "between", "word", "senses", "and", "to", "calculate", "the", "similarity", "of", "each", "pair", "of", "word", "senses", "on", "the", "basis", "of", "a", "given", "lexical", "knowledge", "base", ",", "such", "as", "WordNet", "."], "sentence-detokenized": "An alternative to using definitions is to consider the general kinship between word senses and to calculate the similarity of each pair of word senses on the basis of a given lexical knowledge base, such as WordNet.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 23], [24, 35], [36, 38], [39, 41], [42, 50], [51, 54], [55, 62], [63, 70], [71, 78], [79, 83], [84, 90], [91, 94], [95, 97], [98, 107], [108, 111], [112, 122], [123, 125], [126, 130], [131, 135], [136, 138], [139, 143], [144, 150], [151, 153], [154, 157], [158, 163], [164, 166], [167, 168], [169, 174], [175, 182], [183, 192], [193, 197], [197, 198], [199, 203], [204, 206], [207, 214], [214, 215]]}
{"doc_key": "ai-test-342", "ner": [[0, 2, "algorithm"], [9, 11, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 11, "origin", "", false, false], [9, 11, 21, 22, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "invented", "by", "Richard", "S.", "Sutton", "based", "on", "earlier", "work", "on", "time", "difference", "learning", "by", "Arthur", "Samuel", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm invented by Richard S. Sutton based on earlier work on time difference learning by Arthur Samuel.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 42], [43, 45], [46, 53], [54, 56], [57, 63], [64, 69], [70, 72], [73, 80], [81, 85], [86, 88], [89, 93], [94, 104], [105, 113], [114, 116], [117, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-343", "ner": [[1, 2, "field"], [4, 4, "field"], [7, 7, "task"], [11, 13, "task"], [15, 15, "task"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 7, 1, 2, "part-of", "task_part_of_field", false, false], [7, 7, 4, 4, "part-of", "task_part_of_field", false, false], [11, 13, 7, 7, "named", "", false, false], [15, 15, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "data", "mining", "and", "statistics", ",", "hierarchical", "clustering", "(", "also", "called", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "cluster", "analysis", "method", "that", "attempts", "to", "construct", "a", "hierarchy", "of", "clusters", "."], "sentence-detokenized": "In data mining and statistics, hierarchical clustering (also called hierarchical cluster analysis or HCA) is a cluster analysis method that attempts to construct a hierarchy of clusters.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 29], [29, 30], [31, 43], [44, 54], [55, 56], [56, 60], [61, 67], [68, 80], [81, 88], [89, 97], [98, 100], [101, 104], [104, 105], [106, 108], [109, 110], [111, 118], [119, 127], [128, 134], [135, 139], [140, 148], [149, 151], [152, 161], [162, 163], [164, 173], [174, 176], [177, 185], [185, 186]]}
{"doc_key": "ai-test-344", "ner": [[3, 3, "algorithm"], [8, 11, "field"], [10, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "concept", "of", "deconvolution", "is", "widely", "used", "in", "signal", "and", "image", "processing", "techniques", "."], "sentence-detokenized": "The concept of deconvolution is widely used in signal and image processing techniques.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 53], [54, 57], [58, 63], [64, 74], [75, 85], [85, 86]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [21, 22, "misc"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 21, 22, "related-to", "enhances", false, false], [0, 1, 21, 22, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "serve", "the", "construction", "and", "accumulation", "of", "spatial", "knowledge", ",", "allowing", "the", "mind", "'s", "eye", "to", "visualise", "images", "to", "reduce", "cognitive", "load", ",", "improve", "recall", "and", "learning", "of", "information", "."], "sentence-detokenized": "Cognitive maps serve the construction and accumulation of spatial knowledge, allowing the mind's eye to visualise images to reduce cognitive load, improve recall and learning of information.", "token2charspan": [[0, 9], [10, 14], [15, 20], [21, 24], [25, 37], [38, 41], [42, 54], [55, 57], [58, 65], [66, 75], [75, 76], [77, 85], [86, 89], [90, 94], [94, 96], [97, 100], [101, 103], [104, 113], [114, 120], [121, 123], [124, 130], [131, 140], [141, 145], [145, 146], [147, 154], [155, 161], [162, 165], [166, 174], [175, 177], [178, 189], [189, 190]]}
{"doc_key": "ai-test-346", "ner": [[8, 8, "programlang"], [10, 11, "programlang"], [13, 13, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["which", "generally", "provides", "bindings", "to", "languages", "such", "as", "Python", ",", "C", "++", ",", "Java", ")", "."], "sentence-detokenized": "which generally provides bindings to languages such as Python, C++, Java).", "token2charspan": [[0, 5], [6, 15], [16, 24], [25, 33], [34, 36], [37, 46], [47, 51], [52, 54], [55, 61], [61, 62], [63, 64], [64, 66], [66, 67], [68, 72], [72, 73], [73, 74]]}
{"doc_key": "ai-test-347", "ner": [[1, 3, "product"], [5, 5, "product"], [16, 17, "task"], [23, 25, "task"], [29, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 16, 17, "usage", "", false, false], [1, 3, 23, 25, "usage", "", false, false], [1, 3, 29, 32, "usage", "", false, false], [5, 5, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "voice", "user", "interface", "(", "VUI", ")", "makes", "spoken", "human", "interaction", "with", "computers", "possible", ",", "using", "speech", "recognition", "to", "understand", "voice", "commands", "and", "answers", "to", "questions", ",", "and", "typically", "text", "to", "speech", "to", "reproduce", "an", "answer", "."], "sentence-detokenized": "A voice user interface (VUI) makes spoken human interaction with computers possible, using speech recognition to understand voice commands and answers to questions, and typically text to speech to reproduce an answer.", "token2charspan": [[0, 1], [2, 7], [8, 12], [13, 22], [23, 24], [24, 27], [27, 28], [29, 34], [35, 41], [42, 47], [48, 59], [60, 64], [65, 74], [75, 83], [83, 84], [85, 90], [91, 97], [98, 109], [110, 112], [113, 123], [124, 129], [130, 138], [139, 142], [143, 150], [151, 153], [154, 163], [163, 164], [165, 168], [169, 178], [179, 183], [184, 186], [187, 193], [194, 196], [197, 206], [207, 209], [210, 216], [216, 217]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 5, "misc"], [7, 7, "programlang"], [12, 15, "researcher"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 5, "general-affiliation", "is_a", false, false], [0, 0, 7, 7, "general-affiliation", "made_with", false, false], [0, 0, 12, 15, "origin", "", false, false], [12, 15, 17, 18, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Jess", "is", "a", "rules", "engine", "for", "the", "Java", "platform", ",", "developed", "by", "Ernest", "Friedman", "-", "Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "Jess is a rules engine for the Java platform, developed by Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 15], [16, 22], [23, 26], [27, 30], [31, 35], [36, 44], [44, 45], [46, 55], [56, 58], [59, 65], [66, 74], [74, 75], [75, 79], [80, 82], [83, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-349", "ner": [[1, 2, "algorithm"], [22, 22, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 22, 22, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "multilayer", "perceptrons", ",", "where", "there", "is", "a", "hidden", "layer", ",", "it", "is", "necessary", "to", "use", "more", "sophisticated", "algorithms", ",", "such", "as", "backpropagation", "."], "sentence-detokenized": "For multilayer perceptrons, where there is a hidden layer, it is necessary to use more sophisticated algorithms, such as backpropagation.", "token2charspan": [[0, 3], [4, 14], [15, 26], [26, 27], [28, 33], [34, 39], [40, 42], [43, 44], [45, 51], [52, 57], [57, 58], [59, 61], [62, 64], [65, 74], [75, 77], [78, 81], [82, 86], [87, 100], [101, 111], [111, 112], [113, 117], [118, 120], [121, 136], [136, 137]]}
{"doc_key": "ai-test-350", "ner": [[0, 0, "product"], [1, 6, "product"], [10, 17, "algorithm"], [22, 23, "field"], [27, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 6, 0, 0, "part-of", "", false, false], [1, 6, 10, 17, "usage", "", false, true], [10, 17, 22, 23, "related-to", "performs", false, false], [27, 31, 22, 23, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "Translate", "'s", "neural", "machine", "translation", "system", "uses", "a", "large", "end", "-", "to", "-", "end", "artificial", "neural", "network", "that", "attempts", "to", "perform", "deep", "learning", ",", "in", "particular", "short", "-", "term", "memory", "networks", "."], "sentence-detokenized": "Google Translate's neural machine translation system uses a large end-to-end artificial neural network that attempts to perform deep learning, in particular short-term memory networks.", "token2charspan": [[0, 6], [7, 16], [16, 18], [19, 25], [26, 33], [34, 45], [46, 52], [53, 57], [58, 59], [60, 65], [66, 69], [69, 70], [70, 72], [72, 73], [73, 76], [77, 87], [88, 94], [95, 102], [103, 107], [108, 116], [117, 119], [120, 127], [128, 132], [133, 141], [141, 142], [143, 145], [146, 156], [157, 162], [162, 163], [163, 167], [168, 174], [175, 183], [183, 184]]}
{"doc_key": "ai-test-351", "ner": [[7, 7, "researcher"], [9, 9, "researcher"], [11, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "1980s", "and", "early", "1990s", ",", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "and", "others", "developed", "various", "methods", "to", "do", "this", "."], "sentence-detokenized": "In the 1980s and early 1990s, Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter and others developed various methods to do this.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 16], [17, 22], [23, 28], [28, 29], [30, 36], [36, 37], [38, 46], [46, 47], [48, 56], [56, 57], [58, 64], [65, 76], [76, 77], [78, 82], [83, 93], [93, 94], [95, 106], [107, 110], [111, 117], [118, 127], [128, 135], [136, 143], [144, 146], [147, 149], [150, 154], [154, 155]]}
{"doc_key": "ai-test-352", "ner": [[0, 0, "organisation"], [1, 3, "organisation"], [6, 6, "organisation"], [11, 12, "task"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 6, "role", "licenses_from", false, false], [1, 3, 0, 0, "named", "", false, false], [18, 18, 0, 0, "origin", "", false, false], [18, 18, 11, 12, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc", "originally", "licensed", "Nuance", "'s", "software", "to", "provide", "voice", "recognition", "capabilities", "to", "its", "digital", "assistant", "Siri", "."], "sentence-detokenized": "| Apple Apple Inc originally licensed Nuance's software to provide voice recognition capabilities to its digital assistant Siri.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 17], [18, 28], [29, 37], [38, 44], [44, 46], [47, 55], [56, 58], [59, 66], [67, 72], [73, 84], [85, 97], [98, 100], [101, 104], [105, 112], [113, 122], [123, 127], [127, 128]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [7, 8, "person"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 4, "role", "releases_movies_in_genre", false, false], [7, 8, 0, 0, "role", "directs_for", false, false], [12, 13, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "released", "several", "3D", "westerns", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia released several 3D westerns produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 28], [29, 37], [38, 46], [47, 49], [50, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-test-354", "ner": [[10, 11, "field"], [13, 13, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "project", "incorporates", "knowledge", "and", "research", "in", "the", "fields", "of", "computer", "science", ",", "linguistics", "and", "computer", "engineering", "."], "sentence-detokenized": "The project incorporates knowledge and research in the fields of computer science, linguistics and computer engineering.", "token2charspan": [[0, 3], [4, 11], [12, 24], [25, 34], [35, 38], [39, 47], [48, 50], [51, 54], [55, 61], [62, 64], [65, 73], [74, 81], [81, 82], [83, 94], [95, 98], [99, 107], [108, 119], [119, 120]]}
{"doc_key": "ai-test-355", "ner": [[5, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", "is", "an", "example", "of", "R-", "code", ":"], "sentence-detokenized": "Here is an example of R-code:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 24], [24, 28], [28, 29]]}
{"doc_key": "ai-test-356", "ner": [[0, 2, "metrics"], [8, 11, "metrics"], [13, 13, "metrics"], [17, 20, "metrics"], [22, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 8, 11, "part-of", "plotted_into", false, false], [0, 2, 17, 20, "part-of", "plotted_into", false, false], [13, 13, 8, 11, "named", "", false, false], [22, 22, 17, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "ROC", "curve", "is", "created", "by", "plotting", "the", "rate", "of", "TRUE", "positives", "(", "TPR", ")", "against", "the", "rate", "of", "FALSE", "positives", "(", "FPR", ")", "at", "various", "threshold", "settings", "."], "sentence-detokenized": "The ROC curve is created by plotting the rate of TRUE positives (TPR) against the rate of FALSE positives (FPR) at various threshold settings.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 24], [25, 27], [28, 36], [37, 40], [41, 45], [46, 48], [49, 53], [54, 63], [64, 65], [65, 68], [68, 69], [70, 77], [78, 81], [82, 86], [87, 89], [90, 95], [96, 105], [106, 107], [107, 110], [110, 111], [112, 114], [115, 122], [123, 132], [133, 141], [141, 142]]}
{"doc_key": "ai-test-357", "ner": [[7, 8, "field"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 7, 8, "related-to", "researches_field", false, false], [14, 15, 7, 8, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Research", "came", "to", "a", "standstill", "after", "the", "machine", "learning", "research", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", ","], "sentence-detokenized": "Research came to a standstill after the machine learning research of Marvin Minsky and Seymour Papert (1969),", "token2charspan": [[0, 8], [9, 13], [14, 16], [17, 18], [19, 29], [30, 35], [36, 39], [40, 47], [48, 56], [57, 65], [66, 68], [69, 75], [76, 82], [83, 86], [87, 94], [95, 101], [102, 103], [103, 107], [107, 108], [108, 109]]}
{"doc_key": "ai-test-358", "ner": [[6, 6, "task"], [9, 10, "programlang"], [13, 14, "product"], [12, 17, "programlang"], [19, 19, "product"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 9, 10, "related-to", "used_to_build", false, false], [6, 6, 13, 14, "related-to", "used_to_build", false, false], [6, 6, 12, 17, "related-to", "used_to_build", false, false], [6, 6, 19, 19, "related-to", "used_to_build", false, false], [6, 6, 21, 21, "related-to", "used_to_build", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "programming", "environments", "used", "to", "build", "DAQ", "applications", "are", "ladder", "logic", ",", "Visual", "C", "+", ",", "Visual", "Basic", ",", "LabVIEW", "and", "MATLAB", "."], "sentence-detokenized": "Other programming environments used to build DAQ applications are ladder logic, Visual C+, Visual Basic, LabVIEW and MATLAB.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 38], [39, 44], [45, 48], [49, 61], [62, 65], [66, 72], [73, 78], [78, 79], [80, 86], [87, 88], [88, 89], [89, 90], [91, 97], [98, 103], [103, 104], [105, 112], [113, 116], [117, 123], [123, 124]]}
{"doc_key": "ai-test-359", "ner": [[15, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "metric", "was", "designed", "to", "solve", "some", "of", "the", "problems", "found", "in", "the", "more", "popular", "BLEU", "metric", "and", "to", "produce", "a", "good", "correlation", "with", "human", "judgement", "at", "the", "sentence", "or", "segment", "level", "."], "sentence-detokenized": "The metric was designed to solve some of the problems found in the more popular BLEU metric and to produce a good correlation with human judgement at the sentence or segment level.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 37], [38, 40], [41, 44], [45, 53], [54, 59], [60, 62], [63, 66], [67, 71], [72, 79], [80, 84], [85, 91], [92, 95], [96, 98], [99, 106], [107, 108], [109, 113], [114, 125], [126, 130], [131, 136], [137, 146], [147, 149], [150, 153], [154, 162], [163, 165], [166, 173], [174, 179], [179, 180]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "semantic", "correlations", "between", "consecutive", "video", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and short-term memory are often used to exploit semantic correlations between consecutive video frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 83], [83, 84], [84, 88], [89, 95], [96, 99], [100, 105], [106, 110], [111, 113], [114, 121], [122, 130], [131, 143], [144, 151], [152, 163], [164, 169], [170, 176], [176, 177]]}
{"doc_key": "ai-test-361", "ner": [[4, 5, "product"], [7, 7, "product"], [14, 19, "product"], [23, 23, "product"], [39, 39, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 14, 19, "artifact", "", false, false], [4, 5, 39, 39, "named", "", false, false], [7, 7, 4, 5, "named", "", false, false], [23, 23, 14, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Mass", "-", "produced", "printed", "circuit", "boards", "(", "PCBs", ")", "are", "almost", "exclusively", "produced", "by", "pick", "-", "and", "-", "place", "robots", ",", "usually", "with", "SCARA", "manipulators", ",", "which", "remove", "small", "electronic", "components", "from", "strips", "or", "trays", "and", "place", "them", "on", "PCBs", "with", "great", "precision", "."], "sentence-detokenized": "Mass-produced printed circuit boards (PCBs) are almost exclusively produced by pick-and-place robots, usually with SCARA manipulators, which remove small electronic components from strips or trays and place them on PCBs with great precision.", "token2charspan": [[0, 4], [4, 5], [5, 13], [14, 21], [22, 29], [30, 36], [37, 38], [38, 42], [42, 43], [44, 47], [48, 54], [55, 66], [67, 75], [76, 78], [79, 83], [83, 84], [84, 87], [87, 88], [88, 93], [94, 100], [100, 101], [102, 109], [110, 114], [115, 120], [121, 133], [133, 134], [135, 140], [141, 147], [148, 153], [154, 164], [165, 175], [176, 180], [181, 187], [188, 190], [191, 196], [197, 200], [201, 206], [207, 211], [212, 214], [215, 219], [220, 224], [225, 230], [231, 240], [240, 241]]}
{"doc_key": "ai-test-362", "ner": [[4, 5, "field"], [14, 15, "algorithm"], [19, 20, "researcher"], [22, 23, "researcher"], [25, 28, "researcher"], [35, 36, "algorithm"], [38, 39, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 15, 4, 5, "part-of", "", false, false], [14, 15, 19, 20, "origin", "", false, false], [14, 15, 22, 23, "origin", "", false, false], [14, 15, 25, 28, "origin", "", false, false], [14, 15, 35, 36, "type-of", "", false, false], [35, 36, 38, 39, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "field", "of", "machine", "learning", ",", "where", "it", "finds", "most", "application", "today", ",", "LDA", "was", "independently", "rediscovered", "by", "David", "Blei", ",", "Andrew", "Ng", "and", "Michael", "I", ".", "Jordan", "in", "2003", "and", "presented", "as", "a", "graphical", "model", "for", "topic", "discovery", "."], "sentence-detokenized": "In the field of machine learning, where it finds most application today, LDA was independently rediscovered by David Blei, Andrew Ng and Michael I. Jordan in 2003 and presented as a graphical model for topic discovery.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 23], [24, 32], [32, 33], [34, 39], [40, 42], [43, 48], [49, 53], [54, 65], [66, 71], [71, 72], [73, 76], [77, 80], [81, 94], [95, 107], [108, 110], [111, 116], [117, 121], [121, 122], [123, 129], [130, 132], [133, 136], [137, 144], [145, 146], [146, 147], [148, 154], [155, 157], [158, 162], [163, 166], [167, 176], [177, 179], [180, 181], [182, 191], [192, 197], [198, 201], [202, 207], [208, 217], [217, 218]]}
{"doc_key": "ai-test-363", "ner": [[9, 9, "task"], [13, 13, "misc"], [17, 17, "metrics"], [19, 19, "metrics"], [21, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 13, 13, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "performance", "measured", "on", "the", "test", "data", "of", "eight", "WSI", "naive", "of", "various", "tauopathies", "resulted", "in", "a", "recall", ",", "precision", "and", "F1", "score", "of", "0.92", ",", "0.72", "and", "0.81", "respectively", "."], "sentence-detokenized": "The performance measured on the test data of eight WSI naive of various tauopathies resulted in a recall, precision and F1 score of 0.92, 0.72 and 0.81 respectively.", "token2charspan": [[0, 3], [4, 15], [16, 24], [25, 27], [28, 31], [32, 36], [37, 41], [42, 44], [45, 50], [51, 54], [55, 60], [61, 63], [64, 71], [72, 83], [84, 92], [93, 95], [96, 97], [98, 104], [104, 105], [106, 115], [116, 119], [120, 122], [123, 128], [129, 131], [132, 136], [136, 137], [138, 142], [143, 146], [147, 151], [152, 164], [164, 165]]}
{"doc_key": "ai-test-364", "ner": [[5, 5, "field"], [12, 13, "field"], [18, 18, "field"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 18, 18, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["With", "the", "help", "of", "advanced", "AR", "technologies", "(", "e.g.", "the", "addition", "of", "computer", "vision", ",", "the", "incorporation", "of", "AR", "cameras", "into", "smartphones", "and", "object", "recognition", ")", ",", "information", "about", "the", "user", "'s", "surrounding", "real", "world", "becomes", "interactive", "and", "digitally", "manipulated", "."], "sentence-detokenized": "With the help of advanced AR technologies (e.g. the addition of computer vision, the incorporation of AR cameras into smartphones and object recognition), information about the user's surrounding real world becomes interactive and digitally manipulated.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 25], [26, 28], [29, 41], [42, 43], [43, 47], [48, 51], [52, 60], [61, 63], [64, 72], [73, 79], [79, 80], [81, 84], [85, 98], [99, 101], [102, 104], [105, 112], [113, 117], [118, 129], [130, 133], [134, 140], [141, 152], [152, 153], [153, 154], [155, 166], [167, 172], [173, 176], [177, 181], [181, 183], [184, 195], [196, 200], [201, 206], [207, 214], [215, 226], [227, 230], [231, 240], [241, 252], [252, 253]]}
{"doc_key": "ai-test-365", "ner": [[3, 3, "researcher"], [9, 9, "organisation"], [17, 18, "field"], [28, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 9, 9, "role", "forms_company", false, false], [9, 9, 17, 18, "related-to", "works_with", false, false], [9, 9, 28, 30, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2014", ",", "Schmidhuber", "set", "up", "a", "company", ",", "Nnaisense", ",", "to", "work", "on", "commercial", "applications", "of", "artificial", "intelligence", "in", "fields", "such", "as", "finance", ",", "heavy", "industry", "and", "self", "-", "driving", "cars", "."], "sentence-detokenized": "In 2014, Schmidhuber set up a company, Nnaisense, to work on commercial applications of artificial intelligence in fields such as finance, heavy industry and self-driving cars.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 24], [25, 27], [28, 29], [30, 37], [37, 38], [39, 48], [48, 49], [50, 52], [53, 57], [58, 60], [61, 71], [72, 84], [85, 87], [88, 98], [99, 111], [112, 114], [115, 121], [122, 126], [127, 129], [130, 137], [137, 138], [139, 144], [145, 153], [154, 157], [158, 162], [162, 163], [163, 170], [171, 175], [175, 176]]}
{"doc_key": "ai-test-366", "ner": [[23, 25, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "not", "only", "alters", "the", "performance", "of", "all", "subsequent", "tests", "on", "the", "retained", "explanatory", "model", ",", "but", "can", "introduce", "bias", "and", "alter", "the", "mean", "square", "error", "in", "the", "estimate", "."], "sentence-detokenized": "This not only alters the performance of all subsequent tests on the retained explanatory model, but can introduce bias and alter the mean square error in the estimate.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 20], [21, 24], [25, 36], [37, 39], [40, 43], [44, 54], [55, 60], [61, 63], [64, 67], [68, 76], [77, 88], [89, 94], [94, 95], [96, 99], [100, 103], [104, 113], [114, 118], [119, 122], [123, 128], [129, 132], [133, 137], [138, 144], [145, 150], [151, 153], [154, 157], [158, 166], [166, 167]]}
{"doc_key": "ai-test-367", "ner": [[0, 0, "misc"], [6, 6, "algorithm"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 0, 0, "usage", "", false, false], [6, 6, 9, 10, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Bigrams", "are", "used", "in", "most", "successful", "language", "models", "for", "speech", "recognition", "."], "sentence-detokenized": "Bigrams are used in most successful language models for speech recognition.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 24], [25, 35], [36, 44], [45, 51], [52, 55], [56, 62], [63, 74], [74, 75]]}
{"doc_key": "ai-test-368", "ner": [[3, 6, "field"], [10, 12, "misc"], [18, 20, "misc"], [26, 28, "organisation"], [31, 33, "misc"], [39, 42, "organisation"], [45, 47, "misc"], [53, 57, "organisation"], [60, 62, "misc"], [68, 70, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[10, 12, 3, 6, "topic", "", false, false], [18, 20, 26, 28, "origin", "", false, false], [31, 33, 39, 42, "origin", "", false, false], [45, 47, 53, 57, "origin", "", false, false], [60, 62, 68, 70, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["His", "research", "in", "cognitive", "psychology", "has", "been", "honoured", "with", "the", "Early", "Career", "Award", "(", "1984", ")", "and", "the", "Boyd", "McCandless", "Award", "(", "1986", ")", "from", "the", "American", "Psychological", "Association", ",", "the", "Troland", "Research", "Award", "(", "1993", ")", "from", "the", "National", "Academy", "of", "Sciences", ",", "the", "Henry", "Dale", "Prize", "(", "2004", ")", "from", "the", "Royal", "Institution", "of", "Great", "Britain", "and", "the", "George", "Miller", "Prize", "(", "2010", ")", "from", "the", "Cognitive", "Neuroscience", "Society", "."], "sentence-detokenized": "His research in cognitive psychology has been honoured with the Early Career Award (1984) and the Boyd McCandless Award (1986) from the American Psychological Association, the Troland Research Award (1993) from the National Academy of Sciences, the Henry Dale Prize (2004) from the Royal Institution of Great Britain and the George Miller Prize (2010) from the Cognitive Neuroscience Society.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 25], [26, 36], [37, 40], [41, 45], [46, 54], [55, 59], [60, 63], [64, 69], [70, 76], [77, 82], [83, 84], [84, 88], [88, 89], [90, 93], [94, 97], [98, 102], [103, 113], [114, 119], [120, 121], [121, 125], [125, 126], [127, 131], [132, 135], [136, 144], [145, 158], [159, 170], [170, 171], [172, 175], [176, 183], [184, 192], [193, 198], [199, 200], [200, 204], [204, 205], [206, 210], [211, 214], [215, 223], [224, 231], [232, 234], [235, 243], [243, 244], [245, 248], [249, 254], [255, 259], [260, 265], [266, 267], [267, 271], [271, 272], [273, 277], [278, 281], [282, 287], [288, 299], [300, 302], [303, 308], [309, 316], [317, 320], [321, 324], [325, 331], [332, 338], [339, 344], [345, 346], [346, 350], [350, 351], [352, 356], [357, 360], [361, 370], [371, 383], [384, 391], [391, 392]]}
{"doc_key": "ai-test-369", "ner": [[4, 4, "misc"], [6, 8, "product"], [11, 11, "researcher"], [13, 13, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 27, "task"], [29, 32, "researcher"], [34, 39, "researcher"], [40, 40, "task"], [42, 42, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[4, 4, 11, 11, "origin", "", false, false], [4, 4, 13, 13, "origin", "", false, false], [4, 4, 26, 27, "related-to", "used_for", false, false], [6, 8, 4, 4, "usage", "", false, false], [6, 8, 40, 40, "named", "", false, false], [20, 21, 4, 4, "usage", "", false, false], [20, 21, 29, 32, "named", "same", false, false], [23, 24, 4, 4, "usage", "", false, false], [23, 24, 34, 39, "named", "same", false, false], [40, 40, 42, 42, "usage", "", false, false]], "relations_mapping_to_source": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["The", "approach", "of", "using", "eigenfaces", "for", "face", "recognition", "was", "developed", "by", "Sirovich", "and", "Kirby", "(", "1987", ")", "and", "used", "by", "Matthew", "Turk", "and", "Alex", "Pentland", "in", "face", "classification", ".", "Turk", ",", "Matthew", "A", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "The approach of using eigenfaces for face recognition was developed by Sirovich and Kirby (1987) and used by Matthew Turk and Alex Pentland in face classification. Turk, Matthew A and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 21], [22, 32], [33, 36], [37, 41], [42, 53], [54, 57], [58, 67], [68, 70], [71, 79], [80, 83], [84, 89], [90, 91], [91, 95], [95, 96], [97, 100], [101, 105], [106, 108], [109, 116], [117, 121], [122, 125], [126, 130], [131, 139], [140, 142], [143, 147], [148, 162], [162, 163], [164, 168], [168, 169], [170, 177], [178, 179], [180, 183], [184, 192], [192, 193], [194, 198], [199, 200], [200, 201], [202, 206], [207, 218], [219, 224], [225, 235], [235, 236]]}
{"doc_key": "ai-test-370", "ner": [[5, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "lexical", "dictionary", "such", "as", "Word", "Net", "can", "therefore", "be", "used", "to", "understand", "the", "context", "."], "sentence-detokenized": "A lexical dictionary such as WordNet can therefore be used to understand the context.", "token2charspan": [[0, 1], [2, 9], [10, 20], [21, 25], [26, 28], [29, 33], [33, 36], [37, 40], [41, 50], [51, 53], [54, 58], [59, 61], [62, 72], [73, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-test-371", "ner": [[0, 0, "misc"], [8, 8, "misc"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 8, "part-of", "", false, false], [8, 8, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hyponymy", "is", "the", "most", "frequently", "encoded", "relation", "between", "syntagmas", "used", "in", "lexical", "databases", "such", "as", "WordNet", "."], "sentence-detokenized": "Hyponymy is the most frequently encoded relation between syntagmas used in lexical databases such as WordNet.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 20], [21, 31], [32, 39], [40, 48], [49, 56], [57, 66], [67, 71], [72, 74], [75, 82], [83, 92], [93, 97], [98, 100], [101, 108], [108, 109]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [7, 8, "programlang"], [10, 10, "programlang"], [40, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 8, "general-affiliation", "", false, false], [0, 0, 10, 10, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "offers", "open", "-", "source", "libraries", "in", "C", "+", "and", "Java", ",", "but", "many", "clients", "rely", "on", "community", "-", "developed", "libraries", ",", "such", "as", "libraries", "that", "include", "built", "-", "in", "functionality", "for", "retrieving", "(", "array", "-", "type", ")", "data", "from", "DAP", "servers", "."], "sentence-detokenized": "OPeNDAP offers open-source libraries in C+ and Java, but many clients rely on community-developed libraries, such as libraries that include built-in functionality for retrieving (array-type) data from DAP servers.", "token2charspan": [[0, 7], [8, 14], [15, 19], [19, 20], [20, 26], [27, 36], [37, 39], [40, 41], [41, 42], [43, 46], [47, 51], [51, 52], [53, 56], [57, 61], [62, 69], [70, 74], [75, 77], [78, 87], [87, 88], [88, 97], [98, 107], [107, 108], [109, 113], [114, 116], [117, 126], [127, 131], [132, 139], [140, 145], [145, 146], [146, 148], [149, 162], [163, 166], [167, 177], [178, 179], [179, 184], [184, 185], [185, 189], [189, 190], [191, 195], [196, 200], [201, 204], [205, 212], [212, 213]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [8, 8, "product"], [13, 13, "country"], [30, 31, "misc"], [44, 44, "organisation"], [46, 46, "product"], [48, 48, "organisation"], [50, 53, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 13, 13, "opposite", "", false, false], [8, 8, 13, 13, "artifact", "", false, false], [30, 31, 8, 8, "part-of", "", false, false], [46, 46, 44, 44, "artifact", "", false, false], [50, 53, 48, 48, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "that", "page", ",", "Samurai", "Damashii", "extolled", "the", "Senkousha", "as", "the", "crystallisation", "of", "China", "'s", "four", "thousand", "years", "of", "scientific", "knowledge", ",", "commented", "on", "the", "crude", "design", "(", "e.g.", "the", "Chinese", "cannon", "on", "the", "horse", ")", "and", "placed", "it", "s", "image", "between", "those", "of", "Honda", "'s", "ASIMO", "and", "Sony", "'s", "QRIO", "SDR", "-", "3X", "to", "juxtapose", "it", "."], "sentence-detokenized": "On that page, Samurai Damashii extolled the Senkousha as the crystallisation of China's four thousand years of scientific knowledge, commented on the crude design (e.g. the Chinese cannon on the horse) and placed its image between those of Honda's ASIMO and Sony's QRIO SDR-3X to juxtapose it.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 21], [22, 30], [31, 39], [40, 43], [44, 53], [54, 56], [57, 60], [61, 76], [77, 79], [80, 85], [85, 87], [88, 92], [93, 101], [102, 107], [108, 110], [111, 121], [122, 131], [131, 132], [133, 142], [143, 145], [146, 149], [150, 155], [156, 162], [163, 164], [164, 168], [169, 172], [173, 180], [181, 187], [188, 190], [191, 194], [195, 200], [200, 201], [202, 205], [206, 212], [213, 215], [215, 216], [217, 222], [223, 230], [231, 236], [237, 239], [240, 245], [245, 247], [248, 253], [254, 257], [258, 262], [262, 264], [265, 269], [270, 273], [273, 274], [274, 276], [277, 279], [280, 289], [290, 292], [292, 293]]}
{"doc_key": "ai-test-374", "ner": [[8, 9, "algorithm"], [21, 21, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 21, 21, "part-of", "includes_functionality_of", false, false], [8, 9, 23, 23, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "also", "many", "programming", "libraries", "that", "contain", "neural", "network", "functionality", "and", "can", "be", "used", "in", "customised", "implementations", "(", "such", "as", "TensorFlow", ",", "Theano", ",", "etc.", ")", "."], "sentence-detokenized": "There are also many programming libraries that contain neural network functionality and can be used in customised implementations (such as TensorFlow, Theano, etc.).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 31], [32, 41], [42, 46], [47, 54], [55, 61], [62, 69], [70, 83], [84, 87], [88, 91], [92, 94], [95, 99], [100, 102], [103, 113], [114, 129], [130, 131], [131, 135], [136, 138], [139, 149], [149, 150], [151, 157], [157, 158], [159, 163], [163, 164], [164, 165]]}
{"doc_key": "ai-test-375", "ner": [[6, 9, "conference"], [12, 12, "organisation"], [15, 21, "conference"], [24, 24, "conference"], [27, 27, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", ",", "the", "IEEE", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "the", "IAPR", "and", "the", "SPIE", "."], "sentence-detokenized": "He is a member of the Association for Computing Machinery, the IEEE, the American Association for the Advancement of Science, the IAPR and the SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 33], [34, 37], [38, 47], [48, 57], [57, 58], [59, 62], [63, 67], [67, 68], [69, 72], [73, 81], [82, 93], [94, 97], [98, 101], [102, 113], [114, 116], [117, 124], [124, 125], [126, 129], [130, 134], [135, 138], [139, 142], [143, 147], [147, 148]]}
{"doc_key": "ai-test-376", "ner": [[4, 4, "organisation"], [8, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 8, 10, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "experiment", "conducted", "by", "RET", "in", "2011", "with", "facial", "recognition", "system", "cameras", "mounted", "on", "trams", "meant", "that", "people", "who", "had", "been", "banned", "from", "the", "city", "'s", "trams", "still", "did", "not", "sneak", "on", "."], "sentence-detokenized": "An experiment conducted by RET in 2011 with facial recognition system cameras mounted on trams meant that people who had been banned from the city's trams still did not sneak on.", "token2charspan": [[0, 2], [3, 13], [14, 23], [24, 26], [27, 30], [31, 33], [34, 38], [39, 43], [44, 50], [51, 62], [63, 69], [70, 77], [78, 85], [86, 88], [89, 94], [95, 100], [101, 105], [106, 112], [113, 116], [117, 120], [121, 125], [126, 132], [133, 137], [138, 141], [142, 146], [146, 148], [149, 154], [155, 160], [161, 164], [165, 168], [169, 174], [175, 177], [177, 178]]}
{"doc_key": "ai-test-377", "ner": [[5, 6, "person"], [7, 9, "organisation"], [18, 19, "person"], [21, 22, "person"], [26, 27, "person"], [29, 30, "person"], [32, 33, "person"], [35, 36, "person"], [38, 39, "person"], [41, 42, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[5, 6, 7, 9, "role", "works_for", false, false], [18, 19, 7, 9, "role", "works_for", false, false], [21, 22, 7, 9, "role", "works_for", false, false], [26, 27, 7, 9, "role", "works_for", false, false], [29, 30, 7, 9, "role", "works_for", false, false], [32, 33, 7, 9, "role", "works_for", false, false], [35, 36, 7, 9, "role", "works_for", false, false], [38, 39, 7, 9, "role", "works_for", false, false], [41, 42, 7, 9, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "film", ",", "adapted", "from", "Cole", "Porter", "'s", "popular", "Broadway", "musical", ",", "stars", "the", "MGM", "singing", "duo", "of", "Howard", "Keel", "and", "Kathryn", "Grayson", ",", "joined", "by", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "and", "Tommy", "Rall", "."], "sentence-detokenized": "The film, adapted from Cole Porter's popular Broadway musical, stars the MGM singing duo of Howard Keel and Kathryn Grayson, joined by Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar and Tommy Rall.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 17], [18, 22], [23, 27], [28, 34], [34, 36], [37, 44], [45, 53], [54, 61], [61, 62], [63, 68], [69, 72], [73, 76], [77, 84], [85, 88], [89, 91], [92, 98], [99, 103], [104, 107], [108, 115], [116, 123], [123, 124], [125, 131], [132, 134], [135, 138], [139, 145], [145, 146], [147, 153], [154, 158], [158, 159], [160, 165], [166, 169], [169, 170], [171, 176], [177, 185], [185, 186], [187, 191], [192, 199], [200, 203], [204, 209], [210, 214], [214, 215]]}
{"doc_key": "ai-test-378", "ner": [[15, 17, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "applications", "should", "streamline", "call", "flows", ",", "minimise", "requests", ",", "eliminate", "unnecessary", "iterations", "and", "enable", "mixed-initiative", "dialogue", "systems", ",", "which", "allow", "callers", "to", "enter", "different", "information", "in", "a", "single", "utterance", "and", "in", "any", "order", "or", "combination", "."], "sentence-detokenized": "Such applications should streamline call flows, minimise requests, eliminate unnecessary iterations and enable mixed-initiative dialogue systems, which allow callers to enter different information in a single utterance and in any order or combination.", "token2charspan": [[0, 4], [5, 17], [18, 24], [25, 35], [36, 40], [41, 46], [46, 47], [48, 56], [57, 65], [65, 66], [67, 76], [77, 88], [89, 99], [100, 103], [104, 110], [111, 127], [128, 136], [137, 144], [144, 145], [146, 151], [152, 157], [158, 165], [166, 168], [169, 174], [175, 184], [185, 196], [197, 199], [200, 201], [202, 208], [209, 218], [219, 222], [223, 225], [226, 229], [230, 235], [236, 238], [239, 250], [250, 251]]}
{"doc_key": "ai-test-379", "ner": [[5, 6, "algorithm"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "this", "reason", ",", "traditional", "gradient", "descent", "(", "or", "stochastic", "gradient", "descent", ")", "methods", "can", "be", "adapted", ",", "in", "which", "instead", "of", "performing", "a", "step", "in", "the", "direction", "of", "the", "gradient", "of", "the", "function", ",", "a", "step", "is", "performed", "in", "the", "direction", "of", "a", "vector", "selected", "from", "the", "subgradient", "of", "the", "function", "."], "sentence-detokenized": "For this reason, traditional gradient descent (or stochastic gradient descent) methods can be adapted, in which instead of performing a step in the direction of the gradient of the function, a step is performed in the direction of a vector selected from the subgradient of the function.", "token2charspan": [[0, 3], [4, 8], [9, 15], [15, 16], [17, 28], [29, 37], [38, 45], [46, 47], [47, 49], [50, 60], [61, 69], [70, 77], [77, 78], [79, 86], [87, 90], [91, 93], [94, 101], [101, 102], [103, 105], [106, 111], [112, 119], [120, 122], [123, 133], [134, 135], [136, 140], [141, 143], [144, 147], [148, 157], [158, 160], [161, 164], [165, 173], [174, 176], [177, 180], [181, 189], [189, 190], [191, 192], [193, 197], [198, 200], [201, 210], [211, 213], [214, 217], [218, 227], [228, 230], [231, 232], [233, 239], [240, 248], [249, 253], [254, 257], [258, 269], [270, 272], [273, 276], [277, 285], [285, 286]]}
{"doc_key": "ai-test-380", "ner": [[9, 11, "metrics"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "distortion", "is", "assumed", "to", "be", "measured", "by", "the", "mean", "square", "error", ",", "distortion", "D", "is", "given", "by", ":"], "sentence-detokenized": "If distortion is assumed to be measured by the mean square error, distortion D is given by:", "token2charspan": [[0, 2], [3, 13], [14, 16], [17, 24], [25, 27], [28, 30], [31, 39], [40, 42], [43, 46], [47, 51], [52, 58], [59, 64], [64, 65], [66, 76], [77, 78], [79, 81], [82, 87], [88, 90], [90, 91]]}
{"doc_key": "ai-test-381", "ner": [[0, 0, "algorithm"], [4, 5, "field"], [18, 19, "task"], [21, 22, "task"], [24, 25, "task"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 5, "part-of", "", false, false], [18, 19, 0, 0, "part-of", "", false, false], [21, 22, 0, 0, "part-of", "", false, false], [24, 25, 0, 0, "part-of", "", false, false], [28, 29, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["MLPs", "were", "a", "popular", "machine", "learning", "solution", "in", "the", "1980s", ",", "finding", "application", "in", "various", "fields", "such", "as", "speech", "recognition", ",", "image", "recognition", "and", "machine", "translation", "software", ",", "neural", "networks", "."], "sentence-detokenized": "MLPs were a popular machine learning solution in the 1980s, finding application in various fields such as speech recognition, image recognition and machine translation software, neural networks.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 19], [20, 27], [28, 36], [37, 45], [46, 48], [49, 52], [53, 58], [58, 59], [60, 67], [68, 79], [80, 82], [83, 90], [91, 97], [98, 102], [103, 105], [106, 112], [113, 124], [124, 125], [126, 131], [132, 143], [144, 147], [148, 155], [156, 167], [168, 176], [176, 177], [178, 184], [185, 193], [193, 194]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [3, 3, "misc"], [6, 8, "university"], [16, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 8, "physical", "", false, false], [0, 0, 6, 8, "role", "", false, false], [3, 3, 0, 0, "origin", "", false, false], [16, 18, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "received", "his", "PhD", "from", "the", "University", "of", "Toronto", "in", "1979", ",", "under", "the", "supervision", "of", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen received his PhD from the University of Toronto in 1979, under the supervision of C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 22], [23, 27], [28, 31], [32, 42], [43, 45], [46, 53], [54, 56], [57, 61], [61, 62], [63, 68], [69, 72], [73, 84], [85, 87], [88, 90], [91, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [3, 5, "field"], [9, 9, "product"], [11, 11, "product"], [13, 13, "product"], [19, 19, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 3, 5, "related-to", "supports", false, false], [9, 9, 3, 5, "type-of", "", true, false], [11, 11, 3, 5, "type-of", "", true, false], [13, 13, 3, 5, "type-of", "", true, false], [13, 13, 19, 19, "related-to", "converting_to", true, false], [23, 23, 3, 5, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["OpenCV", "supports", "certain", "deep", "learning", "framework", "models", "such", "as", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "after", "conversion", "to", "an", "ONNX", "model", ")", "and", "Caffe", "according", "to", "a", "defined", "list", "of", "supported", "levels", "."], "sentence-detokenized": "OpenCV supports certain deep learning framework models such as TensorFlow, Torch, PyTorch (after conversion to an ONNX model) and Caffe according to a defined list of supported levels.", "token2charspan": [[0, 6], [7, 15], [16, 23], [24, 28], [29, 37], [38, 47], [48, 54], [55, 59], [60, 62], [63, 73], [73, 74], [75, 80], [80, 81], [82, 89], [90, 91], [91, 96], [97, 107], [108, 110], [111, 113], [114, 118], [119, 124], [124, 125], [126, 129], [130, 135], [136, 145], [146, 148], [149, 150], [151, 158], [159, 163], [164, 166], [167, 176], [177, 183], [183, 184]]}
{"doc_key": "ai-test-384", "ner": [[2, 4, "researcher"], [9, 13, "organisation"], [15, 15, "organisation"], [23, 27, "organisation"], [20, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 9, 13, "role", "", false, false], [2, 4, 23, 27, "role", "", false, false], [2, 4, 20, 22, "related-to", "lectures_in", false, false], [15, 15, 9, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Previously", ",", "Christensen", "was", "the", "founding", "president", "of", "the", "European", "Network", "for", "Robotics", "Research", "(", "EURON", ")", "and", "lecturer", "in", "robotics", "at", "the", "IEEE", "Robotics", "and", "Automation", "Society", "."], "sentence-detokenized": "Previously, Christensen was the founding president of the European Network for Robotics Research (EURON) and lecturer in robotics at the IEEE Robotics and Automation Society.", "token2charspan": [[0, 10], [10, 11], [12, 23], [24, 27], [28, 31], [32, 40], [41, 50], [51, 53], [54, 57], [58, 66], [67, 74], [75, 78], [79, 87], [88, 96], [97, 98], [98, 103], [103, 104], [105, 108], [109, 117], [118, 120], [121, 129], [130, 132], [133, 136], [137, 141], [142, 150], [151, 154], [155, 165], [166, 173], [173, 174]]}
{"doc_key": "ai-test-385", "ner": [[7, 7, "field"], [10, 11, "university"], [9, 13, "location"], [15, 18, "country"], [23, 23, "misc"], [25, 25, "field"], [29, 32, "organisation"], [28, 28, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 9, 13, "physical", "", false, false], [9, 13, 15, 18, "physical", "", false, false], [23, 23, 25, 25, "topic", "", false, false], [29, 32, 28, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "received", "his", "master", "'s", "degree", "in", "mathematics", "from", "Samarkand", "State", "University", ",", "Samarkand", ",", "Uzbek", "Soviet", "Socialist", "Republic", "in", "1958", "and", "his", "doctorate", "in", "statistics", "from", "the", "Moscow", "Institute", "of", "Control", "Sciences", "in", "1964", "."], "sentence-detokenized": "He received his master's degree in mathematics from Samarkand State University, Samarkand, Uzbek Soviet Socialist Republic in 1958 and his doctorate in statistics from the Moscow Institute of Control Sciences in 1964.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 22], [22, 24], [25, 31], [32, 34], [35, 46], [47, 51], [52, 61], [62, 67], [68, 78], [78, 79], [80, 89], [89, 90], [91, 96], [97, 103], [104, 113], [114, 122], [123, 125], [126, 130], [131, 134], [135, 138], [139, 148], [149, 151], [152, 162], [163, 167], [168, 171], [172, 178], [179, 188], [189, 191], [192, 199], [200, 208], [209, 211], [212, 216], [216, 217]]}
{"doc_key": "ai-test-386", "ner": [[4, 13, "product"], [31, 32, "field"], [34, 36, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Increasingly", ",", "however", ",", "Cycorp", "'s", "job", "is", "to", "give", "the", "Cyc", "system", "the", "ability", "to", "communicate", "with", "end", "users", "in", "natural", "language", "and", "to", "assist", "the", "knowledge", "formation", "process", "through", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "Increasingly, however, Cycorp's job is to give the Cyc system the ability to communicate with end users in natural language and to assist the knowledge formation process through machine learning and natural language understanding.", "token2charspan": [[0, 12], [12, 13], [14, 21], [21, 22], [23, 29], [29, 31], [32, 35], [36, 38], [39, 41], [42, 46], [47, 50], [51, 54], [55, 61], [62, 65], [66, 73], [74, 76], [77, 88], [89, 93], [94, 97], [98, 103], [104, 106], [107, 114], [115, 123], [124, 127], [128, 130], [131, 137], [138, 141], [142, 151], [152, 161], [162, 169], [170, 177], [178, 185], [186, 194], [195, 198], [199, 206], [207, 215], [216, 229], [229, 230]]}
{"doc_key": "ai-test-387", "ner": [[55, 55, "metrics"], [57, 57, "metrics"], [59, 59, "metrics"], [61, 62, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "when", "looking", "for", "the", "most", "suitable", "classifier", "for", "the", "problem", ",", "the", "training", "dataset", "is", "used", "to", "train", "the", "candidate", "algorithms", ",", "the", "validation", "dataset", "is", "used", "to", "compare", "their", "performance", "and", "decide", "which", "one", "to", "choose", ",", "and", "finally", ",", "the", "test", "dataset", "is", "used", "to", "obtain", "performance", "characteristics", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", ",", "F-", "measure", "and", "so", "on", "."], "sentence-detokenized": "For example, when looking for the most suitable classifier for the problem, the training dataset is used to train the candidate algorithms, the validation dataset is used to compare their performance and decide which one to choose, and finally, the test dataset is used to obtain performance characteristics such as accuracy, sensitivity, specificity, F-measure and so on.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [18, 25], [26, 29], [30, 33], [34, 38], [39, 47], [48, 58], [59, 62], [63, 66], [67, 74], [74, 75], [76, 79], [80, 88], [89, 96], [97, 99], [100, 104], [105, 107], [108, 113], [114, 117], [118, 127], [128, 138], [138, 139], [140, 143], [144, 154], [155, 162], [163, 165], [166, 170], [171, 173], [174, 181], [182, 187], [188, 199], [200, 203], [204, 210], [211, 216], [217, 220], [221, 223], [224, 230], [230, 231], [232, 235], [236, 243], [243, 244], [245, 248], [249, 253], [254, 261], [262, 264], [265, 269], [270, 272], [273, 279], [280, 291], [292, 307], [308, 312], [313, 315], [316, 324], [324, 325], [326, 337], [337, 338], [339, 350], [350, 351], [352, 354], [354, 361], [362, 365], [366, 368], [369, 371], [371, 372]]}
{"doc_key": "ai-test-388", "ner": [[1, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "square", "error", "is", "0.15", "."], "sentence-detokenized": "The mean square error is 0.15.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 21], [22, 24], [25, 29], [29, 30]]}
{"doc_key": "ai-test-389", "ner": [[7, 8, "misc"], [4, 4, "organisation"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 7, 8, "role", "", false, false], [13, 13, 7, 8, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1979", ",", "the", "IEEE", "organised", "a", "micromouse", "competition", ",", "as", "shown", "in", "Spectrum", "magazine", "."], "sentence-detokenized": "In 1979, the IEEE organised a micromouse competition, as shown in Spectrum magazine.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 27], [28, 29], [30, 40], [41, 52], [52, 53], [54, 56], [57, 62], [63, 65], [66, 74], [75, 83], [83, 84]]}
{"doc_key": "ai-test-390", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [11, 13, "task"], [15, 16, "task"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 7, "part-of", "", false, false], [11, 13, 6, 7, "part-of", "task_part_of_field", false, false], [15, 16, 6, 7, "part-of", "task_part_of_field", false, false], [18, 19, 6, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Gabor", "space", "is", "very", "useful", "in", "image", "processing", "applications", "such", "as", "optical", "character", "recognition", ",", "iris", "recognition", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "Gabor space is very useful in image processing applications such as optical character recognition, iris recognition and fingerprint recognition.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 19], [20, 26], [27, 29], [30, 35], [36, 46], [47, 59], [60, 64], [65, 67], [68, 75], [76, 85], [86, 97], [97, 98], [99, 103], [104, 115], [116, 119], [120, 131], [132, 143], [143, 144]]}
{"doc_key": "ai-test-391", "ner": [[7, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "via", "high", "-", "level", "interfaces", "for", "Java", "and", "Tcl", "."], "sentence-detokenized": "or via high-level interfaces for Java and Tcl.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [12, 17], [18, 28], [29, 32], [33, 37], [38, 41], [42, 45], [45, 46]]}
{"doc_key": "ai-test-392", "ner": [[11, 12, "algorithm"], [20, 20, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 20, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "recent", "research", ",", "kernel", "-", "based", "methods", ",", "such", "as", "support", "vector", "machines", ",", "have", "shown", "superior", "performance", "in", "supervision", "."], "sentence-detokenized": "In recent research, kernel-based methods, such as support vector machines, have shown superior performance in supervision.", "token2charspan": [[0, 2], [3, 9], [10, 18], [18, 19], [20, 26], [26, 27], [27, 32], [33, 40], [40, 41], [42, 46], [47, 49], [50, 57], [58, 64], [65, 73], [73, 74], [75, 79], [80, 85], [86, 94], [95, 106], [107, 109], [110, 121], [121, 122]]}
{"doc_key": "ai-test-393", "ner": [[17, 17, "misc"], [23, 23, "researcher"], [25, 25, "researcher"], [33, 33, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 33, 33, "usage", "", false, false], [25, 25, 33, 33, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "illustrate", "the", "basic", "principles", "of", "bagging", ",", "the", "following", "is", "an", "analysis", "of", "the", "relationship", "between", "ozone", "and", "temperature", "(", "data", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "analysis", "performed", "in", "R", ")", "."], "sentence-detokenized": "To illustrate the basic principles of bagging, the following is an analysis of the relationship between ozone and temperature (data from Rousseeuw and Leroy (1986), analysis performed in R).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 34], [35, 37], [38, 45], [45, 46], [47, 50], [51, 60], [61, 63], [64, 66], [67, 75], [76, 78], [79, 82], [83, 95], [96, 103], [104, 109], [110, 113], [114, 125], [126, 127], [127, 131], [132, 136], [137, 146], [147, 150], [151, 156], [157, 158], [158, 162], [162, 163], [163, 164], [165, 173], [174, 183], [184, 186], [187, 188], [188, 189], [189, 190]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [11, 11, "product"], [18, 19, "product"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 0, 1, "artifact", "", false, false], [18, 19, 0, 1, "artifact", "", false, false], [21, 23, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Denso", "Wave", "is", "a", "subsidiary", "that", "manufactures", "automatic", "identification", "products", "(", "barcode", "readers", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "Denso Wave is a subsidiary that manufactures automatic identification products (barcode readers and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 15], [16, 26], [27, 31], [32, 44], [45, 54], [55, 69], [70, 78], [79, 80], [80, 87], [88, 95], [96, 99], [100, 107], [108, 116], [116, 117], [117, 118], [119, 129], [130, 136], [137, 140], [141, 153], [154, 159], [160, 171], [171, 172]]}
{"doc_key": "ai-test-395", "ner": [[1, 3, "metrics"], [7, 8, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 3, 18, 18, "compare", "", false, false], [7, 8, 1, 3, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Whereas", "Bilingual", "evaluation", "understudy", "merely", "calculates", "the", "accuracy", "of", "graphemes", ",", "giving", "equal", "weight", "to", "each", "one", ",", "NIST", "also", "calculates", "the", "degree", "of", "information", "of", "a", "particular", "grapheme", "."], "sentence-detokenized": "Whereas Bilingual evaluation understudy merely calculates the accuracy of graphemes, giving equal weight to each one, NIST also calculates the degree of information of a particular grapheme.", "token2charspan": [[0, 7], [8, 17], [18, 28], [29, 39], [40, 46], [47, 57], [58, 61], [62, 70], [71, 73], [74, 83], [83, 84], [85, 91], [92, 97], [98, 104], [105, 107], [108, 112], [113, 116], [116, 117], [118, 122], [123, 127], [128, 138], [139, 142], [143, 149], [150, 152], [153, 164], [165, 167], [168, 169], [170, 180], [181, 189], [189, 190]]}
{"doc_key": "ai-test-396", "ner": [[15, 15, "algorithm"], [17, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "particular", ",", "they", "are", "used", "when", "calculating", "the", "likelihood", "of", "a", "tree", "(", "in", "Bayesian", "and", "maximum", "likelihood", "approaches", "to", "tree", "estimation", ")", "and", "are", "used", "to", "estimate", "the", "evolutionary", "distance", "between", "sequences", "from", "observed", "differences", "between", "sequences", "."], "sentence-detokenized": "In particular, they are used when calculating the likelihood of a tree (in Bayesian and maximum likelihood approaches to tree estimation) and are used to estimate the evolutionary distance between sequences from observed differences between sequences.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 19], [20, 23], [24, 28], [29, 33], [34, 45], [46, 49], [50, 60], [61, 63], [64, 65], [66, 70], [71, 72], [72, 74], [75, 83], [84, 87], [88, 95], [96, 106], [107, 117], [118, 120], [121, 125], [126, 136], [136, 137], [138, 141], [142, 145], [146, 150], [151, 153], [154, 162], [163, 166], [167, 179], [180, 188], [189, 196], [197, 206], [207, 211], [212, 220], [221, 232], [233, 240], [241, 250], [250, 251]]}
{"doc_key": "ai-test-397", "ner": [[1, 3, "conference"], [20, 21, "misc"], [23, 23, "misc"], [49, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Audio", "Engineering", "Society", "recommends", "a", "sampling", "frequency", "of", "48", "kHz", "for", "most", "applications", ",", "but", "recognises", "44.1", "kHz", "for", "Compact", "Discs", "(", "CDs", ")", "and", "other", "consumer", "uses", ",", "32", "kHz", "for", "broadcast", "-", "related", "applications", ",", "and", "96", "kHz", "for", "higher", "bandwidth", "or", "the", "use", "of", "relaxed", "anti-aliasing", "filters", "."], "sentence-detokenized": "The Audio Engineering Society recommends a sampling frequency of 48 kHz for most applications, but recognises 44.1 kHz for Compact Discs (CDs) and other consumer uses, 32 kHz for broadcast-related applications, and 96 kHz for higher bandwidth or the use of relaxed anti-aliasing filters.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 40], [41, 42], [43, 51], [52, 61], [62, 64], [65, 67], [68, 71], [72, 75], [76, 80], [81, 93], [93, 94], [95, 98], [99, 109], [110, 114], [115, 118], [119, 122], [123, 130], [131, 136], [137, 138], [138, 141], [141, 142], [143, 146], [147, 152], [153, 161], [162, 166], [166, 167], [168, 170], [171, 174], [175, 178], [179, 188], [188, 189], [189, 196], [197, 209], [209, 210], [211, 214], [215, 217], [218, 221], [222, 225], [226, 232], [233, 242], [243, 245], [246, 249], [250, 253], [254, 256], [257, 264], [265, 278], [279, 286], [286, 287]]}
{"doc_key": "ai-test-398", "ner": [[12, 12, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Resources", "for", "the", "affectivity", "of", "words", "and", "concepts", "have", "been", "created", "for", "WordNet", "{", "{", "cite", "journal"], "sentence-detokenized": "Resources for the affectivity of words and concepts have been created for WordNet {{cite journal", "token2charspan": [[0, 9], [10, 13], [14, 17], [18, 29], [30, 32], [33, 38], [39, 42], [43, 51], [52, 56], [57, 61], [62, 69], [70, 73], [74, 81], [82, 83], [83, 84], [84, 88], [89, 96]]}
{"doc_key": "ai-test-399", "ner": [[1, 3, "misc"], [22, 23, "person"], [28, 31, "person"], [36, 38, "person"], [44, 47, "organisation"], [65, 66, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[28, 31, 36, 38, "role", "acts_in", false, false], [44, 47, 36, 38, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "red", "-green", "anaglyph", ",", "the", "audience", "was", "presented", "with", "three", "test", "reels", ",", "which", "included", "rural", "scenes", ",", "rehearsal", "footage", "of", "Marie", "Doro", ",", "a", "segment", "of", "John", "B", ".", "Mason", "acting", "out", "passages", "from", "Jim", "the", "Penman", "(", "a", "film", "distributed", "by", "Famous", "Players", "-", "Lasky", "that", "year", ",", "but", "not", "in", "3D", ")", ",", "Oriental", "dancers", "and", "a", "reel", "of", "footage", "of", "Niagara", "Falls", "."], "sentence-detokenized": "In red-green anaglyph, the audience was presented with three test reels, which included rural scenes, rehearsal footage of Marie Doro, a segment of John B. Mason acting out passages from Jim the Penman (a film distributed by Famous Players-Lasky that year, but not in 3D), Oriental dancers and a reel of footage of Niagara Falls.", "token2charspan": [[0, 2], [3, 6], [6, 12], [13, 21], [21, 22], [23, 26], [27, 35], [36, 39], [40, 49], [50, 54], [55, 60], [61, 65], [66, 71], [71, 72], [73, 78], [79, 87], [88, 93], [94, 100], [100, 101], [102, 111], [112, 119], [120, 122], [123, 128], [129, 133], [133, 134], [135, 136], [137, 144], [145, 147], [148, 152], [153, 154], [154, 155], [156, 161], [162, 168], [169, 172], [173, 181], [182, 186], [187, 190], [191, 194], [195, 201], [202, 203], [203, 204], [205, 209], [210, 221], [222, 224], [225, 231], [232, 239], [239, 240], [240, 245], [246, 250], [251, 255], [255, 256], [257, 260], [261, 264], [265, 267], [268, 270], [270, 271], [271, 272], [273, 281], [282, 289], [290, 293], [294, 295], [296, 300], [301, 303], [304, 311], [312, 314], [315, 322], [323, 328], [328, 329]]}
{"doc_key": "ai-test-400", "ner": [[7, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "special", "way", "of", "implementing", "maximum", "likelihood", "estimation", "for", "this", "problem", "."], "sentence-detokenized": "This is a special way of implementing maximum likelihood estimation for this problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 17], [18, 21], [22, 24], [25, 37], [38, 45], [46, 56], [57, 67], [68, 71], [72, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-test-401", "ner": [[7, 7, "misc"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "integrates", "the", "features", "of", "sitemaps", "and", "RSS", "feeds", "into", "a", "decentralised", "mechanism", "that", "allows", "computational", "biologists", "and", "bioinformaticians", "to", "openly", "transmit", "and", "retrieve", "metadata", "on", "biomedical", "resources", "."], "sentence-detokenized": "It integrates the features of sitemaps and RSS feeds into a decentralised mechanism that allows computational biologists and bioinformaticians to openly transmit and retrieve metadata on biomedical resources.", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 26], [27, 29], [30, 38], [39, 42], [43, 46], [47, 52], [53, 57], [58, 59], [60, 73], [74, 83], [84, 88], [89, 95], [96, 109], [110, 120], [121, 124], [125, 142], [143, 145], [146, 152], [153, 161], [162, 165], [166, 174], [175, 183], [184, 186], [187, 197], [198, 207], [207, 208]]}
{"doc_key": "ai-test-402", "ner": [[5, 12, "misc"], [15, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "covered", "by", "the", "American", "National", "Standards", "Institute", "/", "NISO", "standard", "Z39.50", "and", "the", "International", "Organisation", "for", "Standardisation", "standard", "23950", "."], "sentence-detokenized": "It is covered by the American National Standards Institute / NISO standard Z39.50 and the International Organisation for Standardisation standard 23950.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 20], [21, 29], [30, 38], [39, 48], [49, 58], [59, 60], [61, 65], [66, 74], [75, 81], [82, 85], [86, 89], [90, 103], [104, 116], [117, 120], [121, 136], [137, 145], [146, 151], [151, 152]]}
{"doc_key": "ai-test-403", "ner": [[13, 17, "misc"], [23, 23, "metrics"], [26, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "encoder", "and", "decoder", "are", "trained", "to", "take", "a", "sentence", "and", "reproduce", "the", "one", "-", "hot", "distribution", "of", "a", "corresponding", "paraphrase", ",", "minimising", "perplexity", "through", "simple", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The encoder and decoder are trained to take a sentence and reproduce the one-hot distribution of a corresponding paraphrase, minimising perplexity through simple stochastic gradient descent.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 45], [46, 54], [55, 58], [59, 68], [69, 72], [73, 76], [76, 77], [77, 80], [81, 93], [94, 96], [97, 98], [99, 112], [113, 123], [123, 124], [125, 135], [136, 146], [147, 154], [155, 161], [162, 172], [173, 181], [182, 189], [189, 190]]}
{"doc_key": "ai-test-404", "ner": [[4, 5, "field"], [8, 10, "task"], [12, 17, "task"], [28, 33, "task"], [35, 41, "task"], [43, 49, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 10, 4, 5, "part-of", "task_part_of_field", false, false], [12, 17, 4, 5, "part-of", "task_part_of_field", false, false], [28, 33, 4, 5, "part-of", "task_part_of_field", false, false], [35, 41, 4, 5, "part-of", "task_part_of_field", false, false], [43, 49, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "typical", "applications", "of", "pattern", "recognition", "techniques", "are", "automatic", "speech", "recognition", ",", "classification", "of", "text", "into", "different", "categories", "(", "e.g.", "spam", "/", "non", "-spam", "e-mail", "messages", ")", ",", "recognition", "of", "handwriting", "on", "postal", "envelopes", ",", "automatic", "recognition", "of", "images", "of", "human", "faces", "or", "extraction", "of", "handwriting", "images", "from", "medical", "forms", "."], "sentence-detokenized": "Other typical applications of pattern recognition techniques are automatic speech recognition, classification of text into different categories (e.g. spam/non-spam e-mail messages), recognition of handwriting on postal envelopes, automatic recognition of images of human faces or extraction of handwriting images from medical forms.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 29], [30, 37], [38, 49], [50, 60], [61, 64], [65, 74], [75, 81], [82, 93], [93, 94], [95, 109], [110, 112], [113, 117], [118, 122], [123, 132], [133, 143], [144, 145], [145, 149], [150, 154], [154, 155], [155, 158], [158, 163], [164, 170], [171, 179], [179, 180], [180, 181], [182, 193], [194, 196], [197, 208], [209, 211], [212, 218], [219, 228], [228, 229], [230, 239], [240, 251], [252, 254], [255, 261], [262, 264], [265, 270], [271, 276], [277, 279], [280, 290], [291, 293], [294, 305], [306, 312], [313, 317], [318, 325], [326, 331], [331, 332]]}
{"doc_key": "ai-test-405", "ner": [[0, 2, "algorithm"], [13, 14, "field"], [16, 17, "task"], [19, 20, "task"], [22, 24, "task"], [26, 30, "task"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 14, 0, 2, "usage", "", false, false], [16, 17, 0, 2, "usage", "", false, false], [19, 20, 0, 2, "usage", "", false, false], [22, 24, 0, 2, "usage", "", false, false], [26, 30, 0, 2, "usage", "", false, false], [33, 34, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Artificial", "neural", "networks", "have", "been", "used", "for", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "playing", "board", "games", "and", "videos", ",", "and", "medical", "diagnosis", "."], "sentence-detokenized": "Artificial neural networks have been used for a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board games and videos, and medical diagnosis.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 36], [37, 41], [42, 45], [46, 47], [48, 55], [56, 58], [59, 64], [64, 65], [66, 75], [76, 84], [85, 91], [91, 92], [93, 99], [100, 111], [111, 112], [113, 120], [121, 132], [132, 133], [134, 140], [141, 148], [149, 158], [158, 159], [160, 167], [168, 173], [174, 179], [180, 183], [184, 190], [190, 191], [192, 195], [196, 203], [204, 213], [213, 214]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [15, 15, "product"], [19, 19, "organisation"], [20, 21, "product"], [23, 23, "product"], [25, 27, "product"], [29, 29, "product"], [31, 31, "programlang"], [40, 41, "field"], [48, 48, "product"], [52, 52, "algorithm"], [54, 54, "algorithm"], [56, 56, "algorithm"], [60, 60, "product"], [68, 70, "task"], [76, 77, "algorithm"], [81, 81, "product"], [83, 83, "product"], [86, 88, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [4, 4, 15, 15, "named", "same", false, false], [4, 4, 48, 48, "named", "same", false, false], [31, 31, 40, 41, "related-to", "used_for", false, false], [52, 52, 31, 31, "part-of", "", true, false], [52, 52, 48, 48, "origin", "", true, false], [54, 54, 31, 31, "part-of", "", true, false], [54, 54, 48, 48, "origin", "", true, false], [56, 56, 31, 31, "part-of", "", true, false], [56, 56, 48, 48, "origin", "", true, false], [60, 60, 68, 70, "related-to", "used_for", false, false], [76, 77, 60, 60, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Examples", "include", "Salford", "Systems", "CART", "(", "which", "has", "licensed", "the", "proprietary", "code", "of", "the", "original", "CART", "authors", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "-", "source", "software", "environment", "for", "statistical", "processing", ",", "which", "includes", "several", "implementations", "of", "CART", "such", "as", "the", "rpart", ",", "party", "and", "randomForest", "packages", ")", ",", "Weka", "(", "a", "free", "and", "open", "-", "source", "data", "-", "mining", "suite", ",", "which", "contains", "many", "decision", "tree", "algorithms", ")", ",", "Orange", ",", "KNIME", ",", "the", "Microsoft", "SQL", "Server", "programming", "language", ")", "."], "sentence-detokenized": "Examples include Salford Systems CART (which has licensed the proprietary code of the original CART authors), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open-source software environment for statistical processing, which includes several implementations of CART such as the rpart, party and randomForest packages), Weka (a free and open-source data-mining suite, which contains many decision tree algorithms), Orange, KNIME, the Microsoft SQL Server programming language).", "token2charspan": [[0, 8], [9, 16], [17, 24], [25, 32], [33, 37], [38, 39], [39, 44], [45, 48], [49, 57], [58, 61], [62, 73], [74, 78], [79, 81], [82, 85], [86, 94], [95, 99], [100, 107], [107, 108], [108, 109], [110, 113], [114, 118], [119, 126], [126, 127], [128, 138], [138, 139], [140, 143], [144, 154], [155, 160], [160, 161], [162, 168], [168, 169], [170, 171], [172, 173], [173, 175], [176, 180], [180, 181], [181, 187], [188, 196], [197, 208], [209, 212], [213, 224], [225, 235], [235, 236], [237, 242], [243, 251], [252, 259], [260, 275], [276, 278], [279, 283], [284, 288], [289, 291], [292, 295], [296, 301], [301, 302], [303, 308], [309, 312], [313, 325], [326, 334], [334, 335], [335, 336], [337, 341], [342, 343], [343, 344], [345, 349], [350, 353], [354, 358], [358, 359], [359, 365], [366, 370], [370, 371], [371, 377], [378, 383], [383, 384], [385, 390], [391, 399], [400, 404], [405, 413], [414, 418], [419, 429], [429, 430], [430, 431], [432, 438], [438, 439], [440, 445], [445, 446], [447, 450], [451, 460], [461, 464], [465, 471], [472, 483], [484, 492], [492, 493], [493, 494]]}
{"doc_key": "ai-test-407", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "researcher"], [13, 14, "university"], [16, 17, "researcher"], [19, 22, "organisation"], [24, 24, "organisation"], [35, 37, "researcher"], [39, 41, "researcher"], [43, 46, "organisation"], [57, 60, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 10, 11, "origin", "", false, false], [0, 2, 16, 17, "origin", "", false, false], [0, 2, 35, 37, "origin", "", false, false], [0, 2, 39, 41, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [10, 11, 13, 14, "physical", "", false, false], [10, 11, 13, 14, "role", "", false, false], [16, 17, 19, 22, "physical", "", false, false], [16, 17, 19, 22, "role", "", false, false], [24, 24, 19, 22, "named", "", false, false], [35, 37, 43, 46, "physical", "", false, false], [35, 37, 43, 46, "role", "", false, false], [39, 41, 43, 46, "physical", "", false, false], [39, 41, 43, 46, "role", "", false, false], [57, 60, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", "was", "first", "developed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", ",", "and", "was", "then", "further", "developed", "by", "Bishnu", "S.", "Atal", "and", "Manfred", "R.", "Schroeder", "at", "Bell", "Labs", "in", "the", "early", "and", "mid-1970s", ",", "becoming", "the", "basis", "for", "the", "first", "speech", "synthesis", "DSP", "chips", "in", "the", "late", "1970s", "."], "sentence-detokenized": "Linear predictive coding (LPC) was first developed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966, and was then further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs in the early and mid-1970s, becoming the basis for the first speech synthesis DSP chips in the late 1970s.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 40], [41, 50], [51, 53], [54, 62], [63, 70], [71, 73], [74, 80], [81, 91], [92, 95], [96, 101], [102, 107], [108, 110], [111, 117], [118, 127], [128, 131], [132, 141], [142, 143], [143, 146], [146, 147], [148, 150], [151, 155], [155, 156], [157, 160], [161, 164], [165, 169], [170, 177], [178, 187], [188, 190], [191, 197], [198, 200], [201, 205], [206, 209], [210, 217], [218, 220], [221, 230], [231, 233], [234, 238], [239, 243], [244, 246], [247, 250], [251, 256], [257, 260], [261, 270], [270, 271], [272, 280], [281, 284], [285, 290], [291, 294], [295, 298], [299, 304], [305, 311], [312, 321], [322, 325], [326, 331], [332, 334], [335, 338], [339, 343], [344, 349], [349, 350]]}
{"doc_key": "ai-test-408", "ner": [[0, 2, "metrics"], [7, 7, "metrics"], [9, 9, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 0, 2, "part-of", "", false, false], [9, 9, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "F", "score", "is", "a", "combination", "of", "accuracy", "and", "recall", ",", "which", "provides", "a", "single", "score", "."], "sentence-detokenized": "The F score is a combination of accuracy and recall, which provides a single score.", "token2charspan": [[0, 3], [4, 5], [6, 11], [12, 14], [15, 16], [17, 28], [29, 31], [32, 40], [41, 44], [45, 51], [51, 52], [53, 58], [59, 67], [68, 69], [70, 76], [77, 82], [82, 83]]}
{"doc_key": "ai-test-409", "ner": [[0, 1, "field"], [7, 9, "task"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 0, 1, "part-of", "task_part_of_field", false, false], [14, 16, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Image", "analysis", "can", "be", "as", "simple", "as", "reading", "barcodes", "or", "as", "sophisticated", "as", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Image analysis can be as simple as reading barcodes or as sophisticated as a facial recognition system.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 21], [22, 24], [25, 31], [32, 34], [35, 42], [43, 51], [52, 54], [55, 57], [58, 71], [72, 74], [75, 76], [77, 83], [84, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-test-410", "ner": [[5, 7, "algorithm"], [25, 26, "algorithm"], [33, 35, "algorithm"], [38, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[33, 35, 25, 26, "type-of", "", false, false], [38, 38, 33, 35, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "special", "case", "of", "linear", "support", "vector", "machines", "can", "be", "solved", "more", "efficiently", "with", "the", "same", "type", "of", "algorithms", "that", "optimise", "its", "close", "cousin", ",", "logistic", "regression", ";", "this", "class", "of", "algorithms", "includes", "stochastic", "gradient", "descent", "(", "e.g.", "PEGASOS", ")", "."], "sentence-detokenized": "The special case of linear support vector machines can be solved more efficiently with the same type of algorithms that optimise its close cousin, logistic regression; this class of algorithms includes stochastic gradient descent (e.g. PEGASOS).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 34], [35, 41], [42, 50], [51, 54], [55, 57], [58, 64], [65, 69], [70, 81], [82, 86], [87, 90], [91, 95], [96, 100], [101, 103], [104, 114], [115, 119], [120, 128], [129, 132], [133, 138], [139, 145], [145, 146], [147, 155], [156, 166], [166, 167], [168, 172], [173, 178], [179, 181], [182, 192], [193, 201], [202, 212], [213, 221], [222, 229], [230, 231], [231, 235], [236, 243], [243, 244], [244, 245]]}
{"doc_key": "ai-test-411", "ner": [[1, 1, "product"], [4, 4, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 4, 4, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["When", "Siri", "on", "an", "iOS", "device", "is", "asked", "Do", "you", "have", "a", "pet", "?", ",", "one", "of", "the", "answers", "is", "I", "had", "an", "AIBO", "."], "sentence-detokenized": "When Siri on an iOS device is asked Do you have a pet?, one of the answers is I had an AIBO.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 15], [16, 19], [20, 26], [27, 29], [30, 35], [36, 38], [39, 42], [43, 47], [48, 49], [50, 53], [53, 54], [54, 55], [56, 59], [60, 62], [63, 66], [67, 74], [75, 77], [78, 79], [80, 83], [84, 86], [87, 91], [91, 92]]}
{"doc_key": "ai-test-412", "ner": [[1, 2, "task"], [5, 7, "metrics"], [10, 10, "metrics"], [13, 13, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 7, 1, 2, "part-of", "", false, false], [10, 10, 5, 7, "named", "", false, false], [13, 13, 1, 2, "part-of", "", false, false], [16, 16, 13, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "information", "retrieval", ",", "the", "positive", "predictive", "value", "is", "called", "precision", ",", "while", "sensitivity", "is", "called", "recall", "."], "sentence-detokenized": "In information retrieval, the positive predictive value is called precision, while sensitivity is called recall.", "token2charspan": [[0, 2], [3, 14], [15, 24], [24, 25], [26, 29], [30, 38], [39, 49], [50, 55], [56, 58], [59, 65], [66, 75], [75, 76], [77, 82], [83, 94], [95, 97], [98, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-413", "ner": [[11, 12, "field"], [14, 14, "task"], [16, 16, "task"], [18, 19, "task"], [34, 35, "task"], [37, 38, "task"], [40, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 14, 11, 12, "part-of", "task_part_of_field", false, false], [16, 16, 11, 12, "part-of", "task_part_of_field", false, false], [18, 19, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "particular", ",", "his", "research", "has", "focused", "on", "areas", "such", "as", "text", "mining", "(", "extraction", ",", "categorisation", ",", "novelty", "detection", ")", "and", "new", "theoretical", "frameworks", "such", "as", "a", "unified", "utility", "-", "based", "theory", "linking", "information", "retrieval", ",", "automatic", "synthesis", ",", "free", "-", "text", "question", "answering", "and", "related", "tasks", "."], "sentence-detokenized": "In particular, his research has focused on areas such as text mining (extraction, categorisation, novelty detection) and new theoretical frameworks such as a unified utility-based theory linking information retrieval, automatic synthesis, free-text question answering and related tasks.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 27], [28, 31], [32, 39], [40, 42], [43, 48], [49, 53], [54, 56], [57, 61], [62, 68], [69, 70], [70, 80], [80, 81], [82, 96], [96, 97], [98, 105], [106, 115], [115, 116], [117, 120], [121, 124], [125, 136], [137, 147], [148, 152], [153, 155], [156, 157], [158, 165], [166, 173], [173, 174], [174, 179], [180, 186], [187, 194], [195, 206], [207, 216], [216, 217], [218, 227], [228, 237], [237, 238], [239, 243], [243, 244], [244, 248], [249, 257], [258, 267], [268, 271], [272, 279], [280, 285], [285, 286]]}
{"doc_key": "ai-test-414", "ner": [[0, 1, "product"], [8, 9, "product"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 0, 1, "part-of", "", false, false], [17, 18, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Delta", "robots", "are", "equipped", "with", "base", "-", "mounted", "rotary", "actuators", "that", "move", "a", "light", ",", "rigid", ",", "parallelogram", "arm", "."], "sentence-detokenized": "Delta robots are equipped with base-mounted rotary actuators that move a light, rigid, parallelogram arm.", "token2charspan": [[0, 5], [6, 12], [13, 16], [17, 25], [26, 30], [31, 35], [35, 36], [36, 43], [44, 50], [51, 60], [61, 65], [66, 70], [71, 72], [73, 78], [78, 79], [80, 85], [85, 86], [87, 100], [101, 104], [104, 105]]}
{"doc_key": "ai-test-415", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", ",", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated in a 2 \u00d7 2 contingency table or confusion matrix, as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 76], [77, 83], [83, 84], [85, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-416", "ner": [[0, 1, "field"], [29, 30, "task"], [36, 37, "task"], [42, 44, "task"], [46, 48, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[29, 30, 0, 1, "part-of", "task_part_of_field", false, false], [36, 37, 0, 1, "part-of", "task_part_of_field", false, false], [42, 44, 0, 1, "part-of", "task_part_of_field", false, false], [46, 48, 0, 1, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Data", "mining", "proper", "consists", "of", "the", "semi-automatic", "or", "automatic", "analysis", "of", "large", "amounts", "of", "data", "to", "extract", "unknown", "and", "interesting", "patterns", ",", "such", "as", "groups", "of", "data", "records", "(", "cluster", "analysis", ")", ",", "unusual", "records", "(", "anomaly", "detection", ")", "and", "dependencies", "(", "association", "rule", "mining", ",", "sequential", "pattern", "mining", ")", "."], "sentence-detokenized": "Data mining proper consists of the semi-automatic or automatic analysis of large amounts of data to extract unknown and interesting patterns, such as groups of data records (cluster analysis), unusual records (anomaly detection) and dependencies (association rule mining, sequential pattern mining).", "token2charspan": [[0, 4], [5, 11], [12, 18], [19, 27], [28, 30], [31, 34], [35, 49], [50, 52], [53, 62], [63, 71], [72, 74], [75, 80], [81, 88], [89, 91], [92, 96], [97, 99], [100, 107], [108, 115], [116, 119], [120, 131], [132, 140], [140, 141], [142, 146], [147, 149], [150, 156], [157, 159], [160, 164], [165, 172], [173, 174], [174, 181], [182, 190], [190, 191], [191, 192], [193, 200], [201, 208], [209, 210], [210, 217], [218, 227], [227, 228], [229, 232], [233, 245], [246, 247], [247, 258], [259, 263], [264, 270], [270, 271], [272, 282], [283, 290], [291, 297], [297, 298], [298, 299]]}
{"doc_key": "ai-test-417", "ner": [[2, 3, "product"], [5, 6, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 5, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "a", "recommendation", "system", ",", "sentiment", "analysis", "has", "proven", "to", "be", "a", "valuable", "technique", "."], "sentence-detokenized": "For a recommendation system, sentiment analysis has proven to be a valuable technique.", "token2charspan": [[0, 3], [4, 5], [6, 20], [21, 27], [27, 28], [29, 38], [39, 47], [48, 51], [52, 58], [59, 61], [62, 64], [65, 66], [67, 75], [76, 85], [85, 86]]}
{"doc_key": "ai-test-418", "ner": [[4, 4, "misc"], [14, 14, "product"], [27, 28, "organisation"], [35, 36, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 14, 14, "usage", "", false, false], [27, 28, 35, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["By", "chance", ",", "the", "Germans", "had", "very", "poorly", "chosen", "the", "operating", "frequency", "of", "the", "Wotan", "system", ",", "which", "operated", "at", "45", "MHz", ",", "the", "frequency", "of", "the", "BBC", "'s", "powerful", "but", "inactive", "television", "transmitter", "at", "Alexandra", "Palace", "."], "sentence-detokenized": "By chance, the Germans had very poorly chosen the operating frequency of the Wotan system, which operated at 45 MHz, the frequency of the BBC's powerful but inactive television transmitter at Alexandra Palace.", "token2charspan": [[0, 2], [3, 9], [9, 10], [11, 14], [15, 22], [23, 26], [27, 31], [32, 38], [39, 45], [46, 49], [50, 59], [60, 69], [70, 72], [73, 76], [77, 82], [83, 89], [89, 90], [91, 96], [97, 105], [106, 108], [109, 111], [112, 115], [115, 116], [117, 120], [121, 130], [131, 133], [134, 137], [138, 141], [141, 143], [144, 152], [153, 156], [157, 165], [166, 176], [177, 188], [189, 191], [192, 201], [202, 208], [208, 209]]}
{"doc_key": "ai-test-419", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", ",", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated in a 2 \u00d7 2 contingency table or confusion matrix, as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 76], [77, 83], [83, 84], [85, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-420", "ner": [[1, 8, "misc"], [7, 7, "misc"], [11, 11, "product"], [13, 13, "product"], [15, 17, "product"], [26, 26, "misc"], [42, 44, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 11, 7, 7, "usage", "", false, false], [13, 13, 7, 7, "usage", "", false, false], [15, 17, 13, 13, "named", "", false, false], [26, 26, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "Semantic", "Web", "applications", "and", "relatively", "popular", "RDF", "applications", "such", "as", "RSS", "and", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "resources", "tend", "to", "be", "represented", "by", "URIs", "that", "intentionally", "denote", ",", "and", "can", "be", "used", "to", "access", ",", "real", "data", "on", "the", "World", "Wide", "Web", "."], "sentence-detokenized": "In Semantic Web applications and relatively popular RDF applications such as RSS and FOAF (Friend a Friend), resources tend to be represented by URIs that intentionally denote, and can be used to access, real data on the World Wide Web.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 28], [29, 32], [33, 43], [44, 51], [52, 55], [56, 68], [69, 73], [74, 76], [77, 80], [81, 84], [85, 89], [90, 91], [91, 97], [98, 99], [100, 106], [106, 107], [107, 108], [109, 118], [119, 123], [124, 126], [127, 129], [130, 141], [142, 144], [145, 149], [150, 154], [155, 168], [169, 175], [175, 176], [177, 180], [181, 184], [185, 187], [188, 192], [193, 195], [196, 202], [202, 203], [204, 208], [209, 213], [214, 216], [217, 220], [221, 226], [227, 231], [232, 235], [235, 236]]}
{"doc_key": "ai-test-421", "ner": [[1, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "has", "studied", "this", "topic", "in", "depth", "."], "sentence-detokenized": "The Association for the Advancement of Artificial Intelligence has studied this topic in depth.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 74], [75, 79], [80, 85], [86, 88], [89, 94], [94, 95]]}
{"doc_key": "ai-test-422", "ner": [[6, 10, "product"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 19, 6, 10, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starting", "out", "as", "a", "curiosity", ",", "Apple", "'s", "Macintosh", "voice", "system", "has", "evolved", "into", "a", "fully", "supported", "programme", ",", "PlainTalk", ",", "for", "the", "visually", "impaired", "."], "sentence-detokenized": "Starting out as a curiosity, Apple's Macintosh voice system has evolved into a fully supported programme, PlainTalk, for the visually impaired.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 17], [18, 27], [27, 28], [29, 34], [34, 36], [37, 46], [47, 52], [53, 59], [60, 63], [64, 71], [72, 76], [77, 78], [79, 84], [85, 94], [95, 104], [104, 105], [106, 115], [115, 116], [117, 120], [121, 124], [125, 133], [134, 142], [142, 143]]}
{"doc_key": "ai-test-423", "ner": [[7, 7, "field"], [9, 9, "task"], [10, 13, "task"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 7, 7, "part-of", "task_part_of_field", false, false], [10, 13, 7, 7, "part-of", "task_part_of_field", false, false], [15, 16, 7, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "areas", "of", "use", "of", "ontologies", "in", "NLP", "are", "information", "retrieval", ",", "information", "extraction", "and", "automatic", "synthesis", "."], "sentence-detokenized": "Other areas of use of ontologies in NLP are information retrieval, information extraction and automatic synthesis.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 43], [44, 55], [56, 65], [65, 66], [67, 78], [79, 89], [90, 93], [94, 103], [104, 113], [113, 114]]}
{"doc_key": "ai-test-424", "ner": [[7, 15, "organisation"], [18, 22, "organisation"], [25, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Institute", "has", "worked", "closely", "with", "the", "Janelia", "Farm", "Campus", "of", "the", "Howard", "Hughes", "Medical", "Institute", ",", "the", "Allen", "Institute", "for", "Brain", "Science", "and", "the", "National", "Institutes", "of", "Health", "to", "develop", "better", "methods", "of", "reconstructing", "neuronal", "architectures", "."], "sentence-detokenized": "The Institute has worked closely with the Janelia Farm Campus of the Howard Hughes Medical Institute, the Allen Institute for Brain Science and the National Institutes of Health to develop better methods of reconstructing neuronal architectures.", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 24], [25, 32], [33, 37], [38, 41], [42, 49], [50, 54], [55, 61], [62, 64], [65, 68], [69, 75], [76, 82], [83, 90], [91, 100], [100, 101], [102, 105], [106, 111], [112, 121], [122, 125], [126, 131], [132, 139], [140, 143], [144, 147], [148, 156], [157, 167], [168, 170], [171, 177], [178, 180], [181, 188], [189, 195], [196, 203], [204, 206], [207, 221], [222, 230], [231, 244], [244, 245]]}
{"doc_key": "ai-test-425", "ner": [[2, 2, "organisation"], [5, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 2, 2, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Recently", ",", "Google", "announced", "that", "Google", "Translate", "translates", "enough", "text", "to", "fill", "1", "million", "books", "in", "one", "day", "(", "2012", ")", "."], "sentence-detokenized": "Recently, Google announced that Google Translate translates enough text to fill 1 million books in one day (2012).", "token2charspan": [[0, 8], [8, 9], [10, 16], [17, 26], [27, 31], [32, 38], [39, 48], [49, 59], [60, 66], [67, 71], [72, 74], [75, 79], [80, 81], [82, 89], [90, 95], [96, 98], [99, 102], [103, 106], [107, 108], [108, 112], [112, 113], [113, 114]]}
{"doc_key": "ai-test-426", "ner": [[15, 15, "country"], [18, 19, "country"], [21, 21, "country"], [23, 23, "country"], [25, 25, "country"], [27, 28, "country"], [39, 40, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "events", "are", "held", "all", "over", "the", "world", "and", "are", "most", "popular", "in", "the", "United", "Kingdom", ",", "the", "United", "States", ",", "Japan", ",", "Singapore", ",", "India", ",", "South", "Korea", "and", "are", "also", "becoming", "popular", "in", "subcontinental", "countries", "such", "as", "Sri", "Lanka", "."], "sentence-detokenized": "The events are held all over the world and are most popular in the United Kingdom, the United States, Japan, Singapore, India, South Korea and are also becoming popular in subcontinental countries such as Sri Lanka.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 19], [20, 23], [24, 28], [29, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 59], [60, 62], [63, 66], [67, 73], [74, 81], [81, 82], [83, 86], [87, 93], [94, 100], [100, 101], [102, 107], [107, 108], [109, 118], [118, 119], [120, 125], [125, 126], [127, 132], [133, 138], [139, 142], [143, 146], [147, 151], [152, 160], [161, 168], [169, 171], [172, 186], [187, 196], [197, 201], [202, 204], [205, 208], [209, 214], [214, 215]]}
{"doc_key": "ai-test-427", "ner": [[6, 6, "programlang"], [10, 10, "programlang"], [12, 15, "programlang"], [17, 17, "programlang"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "mainly", "developed", "in", "R", "and", "sometimes", "in", "Java", ",", "C", ",", "C", "+", "and", "Fortran", "."], "sentence-detokenized": "These packages are mainly developed in R and sometimes in Java, C, C+ and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 25], [26, 35], [36, 38], [39, 40], [41, 44], [45, 54], [55, 57], [58, 62], [62, 63], [64, 65], [65, 66], [67, 68], [68, 69], [70, 73], [74, 81], [81, 82]]}
{"doc_key": "ai-test-428", "ner": [[4, 9, "conference"], [11, 11, "conference"], [14, 14, "researcher"], [16, 16, "researcher"], [19, 20, "researcher"], [23, 24, "algorithm"], [29, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 11, 4, 9, "named", "", false, false], [14, 14, 4, 9, "physical", "", false, false], [14, 14, 4, 9, "role", "", false, false], [14, 14, 19, 20, "role", "teams_up_with", false, false], [14, 14, 23, 24, "usage", "", false, false], [16, 16, 4, 9, "physical", "", false, false], [16, 16, 4, 9, "role", "", false, false], [16, 16, 19, 20, "role", "teams_up_with", false, false], [16, 16, 23, 24, "usage", "", false, false], [19, 20, 4, 9, "physical", "", false, false], [19, 20, 4, 9, "role", "", false, false], [19, 20, 23, 24, "usage", "", false, false], [23, 24, 29, 34, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["As", "part", "of", "the", "2006", "European", "Conference", "on", "Computer", "Vision", "(", "ECCV", ")", ",", "Dalal", "and", "Triggs", "collaborated", "with", "Cordelia", "Schmid", "to", "apply", "HOG", "detectors", "to", "the", "problem", "of", "human", "detection", "in", "film", "and", "video", "."], "sentence-detokenized": "As part of the 2006 European Conference on Computer Vision (ECCV), Dalal and Triggs collaborated with Cordelia Schmid to apply HOG detectors to the problem of human detection in film and video.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 19], [20, 28], [29, 39], [40, 42], [43, 51], [52, 58], [59, 60], [60, 64], [64, 65], [65, 66], [67, 72], [73, 76], [77, 83], [84, 96], [97, 101], [102, 110], [111, 117], [118, 120], [121, 126], [127, 130], [131, 140], [141, 143], [144, 147], [148, 155], [156, 158], [159, 164], [165, 174], [175, 177], [178, 182], [183, 186], [187, 192], [192, 193]]}
{"doc_key": "ai-test-429", "ner": [[3, 3, "metrics"], [5, 7, "metrics"], [11, 12, "task"], [19, 21, "metrics"], [23, 23, "metrics"], [29, 29, "metrics"], [33, 35, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 3, 11, 12, "related-to", "measured_with", false, false], [5, 7, 11, 12, "related-to", "measured_with", false, false], [19, 21, 11, 12, "related-to", "measured_with", false, false], [23, 23, 19, 21, "named", "", false, false], [29, 29, 19, 21, "named", "", false, false], [37, 37, 33, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "addition", "to", "sensitivity", "and", "specificity", ",", "the", "performance", "of", "a", "binary", "classification", "test", "can", "be", "measured", "by", "the", "positive", "predictive", "value", "(", "PPV", ")", ",", "also", "known", "as", "accuracy", ",", "and", "the", "negative", "predictive", "value", "(", "NPV", ")", "."], "sentence-detokenized": "In addition to sensitivity and specificity, the performance of a binary classification test can be measured by the positive predictive value (PPV), also known as accuracy, and the negative predictive value (NPV).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 42], [42, 43], [44, 47], [48, 59], [60, 62], [63, 64], [65, 71], [72, 86], [87, 91], [92, 95], [96, 98], [99, 107], [108, 110], [111, 114], [115, 123], [124, 134], [135, 140], [141, 142], [142, 145], [145, 146], [146, 147], [148, 152], [153, 158], [159, 161], [162, 170], [170, 171], [172, 175], [176, 179], [180, 188], [189, 199], [200, 205], [206, 207], [207, 210], [210, 211], [211, 212]]}
{"doc_key": "ai-test-430", "ner": [[13, 15, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "models", "can", "give", "partial", "credit", "to", "overlapping", "matches", "(", "e.g.", "using", "the", "Jaccard", "index", "criterion", ")", "."], "sentence-detokenized": "Such models can give partial credit to overlapping matches (e.g. using the Jaccard index criterion).", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 28], [29, 35], [36, 38], [39, 50], [51, 58], [59, 60], [60, 64], [65, 70], [71, 74], [75, 82], [83, 88], [89, 98], [98, 99], [99, 100]]}
{"doc_key": "ai-test-431", "ner": [[23, 28, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Furthermore", ",", "in", "the", "case", "of", "single", "-", "sample", "estimates", ",", "it", "demonstrates", "the", "philosophical", "issues", "and", "possible", "misunderstandings", "in", "the", "use", "of", "maximum", "likelihood", "estimators", "and", "likelihood", "functions", "."], "sentence-detokenized": "Furthermore, in the case of single-sample estimates, it demonstrates the philosophical issues and possible misunderstandings in the use of maximum likelihood estimators and likelihood functions.", "token2charspan": [[0, 11], [11, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 34], [34, 35], [35, 41], [42, 51], [51, 52], [53, 55], [56, 68], [69, 72], [73, 86], [87, 93], [94, 97], [98, 106], [107, 124], [125, 127], [128, 131], [132, 135], [136, 138], [139, 146], [147, 157], [158, 168], [169, 172], [173, 183], [184, 193], [193, 194]]}
