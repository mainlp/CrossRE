{"doc_key": "ai-train-1", "ner": [[3, 7, "product"], [13, 14, "field"], [16, 17, "task"], [19, 20, "task"], [24, 26, "task"], [29, 30, "field"], [31, 33, "researcher"], [35, 37, "researcher"], [39, 40, "researcher"], [42, 43, "researcher"], [47, 47, "researcher"], [49, 50, "researcher"], [52, 53, "researcher"], [55, 56, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[3, 7, 13, 14, "part-of", "", false, false], [3, 7, 13, 14, "usage", "", false, false], [3, 7, 16, 17, "part-of", "", false, false], [3, 7, 16, 17, "usage", "", false, false], [3, 7, 19, 20, "part-of", "", false, false], [3, 7, 19, 20, "usage", "", false, false], [3, 7, 29, 30, "part-of", "", false, false], [3, 7, 29, 30, "usage", "", false, false], [24, 26, 19, 20, "part-of", "", false, false], [24, 26, 19, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Popular", "approaches", "to", "opinion", "-", "based", "recommendation", "systems", "use", "various", "techniques", ",", "including", "text", "mining", ",", "information", "retrieval", ",", "sentiment", "analysis", "(", "see", "also", "Multimodal", "sentiment", "analysis", ")", "and", "deep", "learning", "X.Y", ".", "Feng", ",", "H", ".", "Zhang", ",", "Y.J.", "Ren", ",", "P.H.", "Shang", ",", "Y", ".", "Zhu", ",", "Y.C.", "Liang", ",", "R.C.", "Guan", ",", "D.", "Xu", ",", "(", "2019", ")", ",", "21", "(", "5", ")", ":", "e12957", "."], "sentence-detokenized": "Popular approaches to opinion-based recommendation systems use various techniques, including text mining, information retrieval, sentiment analysis (see also Multimodal sentiment analysis) and deep learning X.Y. Feng, H. Zhang, Y.J. Ren, P.H. Shang, Y. Zhu, Y.C. Liang, R.C. Guan, D. Xu, (2019), 21(5): e12957.", "token2charspan": [[0, 7], [8, 18], [19, 21], [22, 29], [29, 30], [30, 35], [36, 50], [51, 58], [59, 62], [63, 70], [71, 81], [81, 82], [83, 92], [93, 97], [98, 104], [104, 105], [106, 117], [118, 127], [127, 128], [129, 138], [139, 147], [148, 149], [149, 152], [153, 157], [158, 168], [169, 178], [179, 187], [187, 188], [189, 192], [193, 197], [198, 206], [207, 210], [210, 211], [212, 216], [216, 217], [218, 219], [219, 220], [221, 226], [226, 227], [228, 232], [233, 236], [236, 237], [238, 242], [243, 248], [248, 249], [250, 251], [251, 252], [253, 256], [256, 257], [258, 262], [263, 268], [268, 269], [270, 274], [275, 279], [279, 280], [281, 283], [284, 286], [286, 287], [288, 289], [289, 293], [293, 294], [294, 295], [296, 298], [298, 299], [299, 300], [300, 301], [301, 302], [303, 309], [309, 310]]}
{"doc_key": "ai-train-2", "ner": [[8, 8, "university"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 8, 8, "physical", "", false, false], [14, 15, 8, 8, "role", "", false, false], [17, 18, 8, 8, "physical", "", false, false], [17, 18, 8, 8, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Advocates", "of", "procedural", "representations", "were", "mainly", "concentrated", "at", "MIT", ",", "under", "the", "leadership", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "."], "sentence-detokenized": "Advocates of procedural representations were mainly concentrated at MIT, under the leadership of Marvin Minsky and Seymour Papert.", "token2charspan": [[0, 9], [10, 12], [13, 23], [24, 39], [40, 44], [45, 51], [52, 64], [65, 67], [68, 71], [71, 72], [73, 78], [79, 82], [83, 93], [94, 96], [97, 103], [104, 110], [111, 114], [115, 122], [123, 129], [129, 130]]}
{"doc_key": "ai-train-3", "ner": [[10, 10, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "standard", "interface", "and", "the", "calculator", "interface", "are", "written", "in", "Java", "."], "sentence-detokenized": "The standard interface and the calculator interface are written in Java.", "token2charspan": [[0, 3], [4, 12], [13, 22], [23, 26], [27, 30], [31, 41], [42, 51], [52, 55], [56, 63], [64, 66], [67, 71], [71, 72]]}
{"doc_key": "ai-train-4", "ner": [[0, 0, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 22, 22, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["Octave", "helps", "to", "numerically", "solve", "linear", "and", "non-linear", "problems", "and", "perform", "other", "numerical", "experiments", "using", "a", "programme", "that", "is", "mostly", "compatible", "with", "MATLAB", "."], "sentence-detokenized": "Octave helps to numerically solve linear and non-linear problems and perform other numerical experiments using a programme that is mostly compatible with MATLAB.", "token2charspan": [[0, 6], [7, 12], [13, 15], [16, 27], [28, 33], [34, 40], [41, 44], [45, 55], [56, 64], [65, 68], [69, 76], [77, 82], [83, 92], [93, 104], [105, 110], [111, 112], [113, 122], [123, 127], [128, 130], [131, 137], [138, 148], [149, 153], [154, 160], [160, 161]]}
{"doc_key": "ai-train-5", "ner": [[3, 6, "algorithm"], [9, 10, "misc"], [12, 13, "researcher"], [18, 20, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 6, 12, 13, "origin", "", false, false], [9, 10, 12, 13, "origin", "", false, false], [12, 13, 18, 20, "physical", "", false, false], [12, 13, 18, 20, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Variants", "of", "the", "back", "-", "propagation", "algorithm", "and", "the", "unsupervised", "methods", "of", "Geoff", "Hinton", "and", "colleagues", "at", "the", "University", "of", "Toronto", "can", "be", "used", "to", "train", "deep", ",", "highly", "non-linear", "neural", "architectures", ",", "{", "{", "cite", "journal"], "sentence-detokenized": "Variants of the back-propagation algorithm and the unsupervised methods of Geoff Hinton and colleagues at the University of Toronto can be used to train deep, highly non-linear neural architectures, {{cite journal", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 20], [20, 21], [21, 32], [33, 42], [43, 46], [47, 50], [51, 63], [64, 71], [72, 74], [75, 80], [81, 87], [88, 91], [92, 102], [103, 105], [106, 109], [110, 120], [121, 123], [124, 131], [132, 135], [136, 138], [139, 143], [144, 146], [147, 152], [153, 157], [157, 158], [159, 165], [166, 176], [177, 183], [184, 197], [197, 198], [199, 200], [200, 201], [201, 205], [206, 213]]}
{"doc_key": "ai-train-6", "ner": [[4, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "equivalently", "using", "the", "DCG", "notation", ":"], "sentence-detokenized": "or equivalently using the DCG notation:", "token2charspan": [[0, 2], [3, 15], [16, 21], [22, 25], [26, 29], [30, 38], [38, 39]]}
{"doc_key": "ai-train-7", "ner": [[0, 3, "algorithm"], [7, 10, "algorithm"], [14, 15, "algorithm"], [19, 22, "algorithm"], [25, 27, "algorithm"], [29, 30, "algorithm"], [43, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 7, 10, "type-of", "", false, false], [0, 3, 14, 15, "usage", "part-of?", true, false], [14, 15, 19, 22, "compare", "", false, false], [25, 27, 19, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Self", "-", "organising", "maps", "differ", "from", "other", "artificial", "neural", "networks", "in", "that", "they", "apply", "competitive", "learning", "as", "opposed", "to", "error", "-", "corrected", "learning", "such", "as", "back", "-", "propagation", "with", "gradient", "descent", ")", "and", "in", "that", "they", "use", "a", "neighbourhood", "function", "to", "preserve", "the", "topological", "properties", "of", "the", "input", "space", "."], "sentence-detokenized": "Self-organising maps differ from other artificial neural networks in that they apply competitive learning as opposed to error-corrected learning such as back-propagation with gradient descent) and in that they use a neighbourhood function to preserve the topological properties of the input space.", "token2charspan": [[0, 4], [4, 5], [5, 15], [16, 20], [21, 27], [28, 32], [33, 38], [39, 49], [50, 56], [57, 65], [66, 68], [69, 73], [74, 78], [79, 84], [85, 96], [97, 105], [106, 108], [109, 116], [117, 119], [120, 125], [125, 126], [126, 135], [136, 144], [145, 149], [150, 152], [153, 157], [157, 158], [158, 169], [170, 174], [175, 183], [184, 191], [191, 192], [193, 196], [197, 199], [200, 204], [205, 209], [210, 213], [214, 215], [216, 229], [230, 238], [239, 241], [242, 250], [251, 254], [255, 266], [267, 277], [278, 280], [281, 284], [285, 290], [291, 296], [296, 297]]}
{"doc_key": "ai-train-8", "ner": [[10, 14, "organisation"], [24, 25, "misc"], [35, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "the", "early", "1990s", ",", "various", "authorities", ",", "including", "the", "Audio", "Engineering", "Society", ",", "have", "recommended", "that", "dynamic", "range", "measurements", "be", "performed", "with", "an", "audio", "signal", "present", ",", "which", "is", "then", "filtered", "out", "in", "the", "noise", "floor", "measurement", "used", "to", "determine", "dynamic", "range", ".", "This", "avoids", "questionable", "measurements", "based", "on", "the", "use", "of", "empty", "media", "or", "muting", "circuits", "."], "sentence-detokenized": "Since the early 1990s, various authorities, including the Audio Engineering Society, have recommended that dynamic range measurements be performed with an audio signal present, which is then filtered out in the noise floor measurement used to determine dynamic range. This avoids questionable measurements based on the use of empty media or muting circuits.", "token2charspan": [[0, 5], [6, 9], [10, 15], [16, 21], [21, 22], [23, 30], [31, 42], [42, 43], [44, 53], [54, 57], [58, 63], [64, 75], [76, 83], [83, 84], [85, 89], [90, 101], [102, 106], [107, 114], [115, 120], [121, 133], [134, 136], [137, 146], [147, 151], [152, 154], [155, 160], [161, 167], [168, 175], [175, 176], [177, 182], [183, 185], [186, 190], [191, 199], [200, 203], [204, 206], [207, 210], [211, 216], [217, 222], [223, 234], [235, 239], [240, 242], [243, 252], [253, 260], [261, 266], [266, 267], [268, 272], [273, 279], [280, 292], [293, 305], [306, 311], [312, 314], [315, 318], [319, 322], [323, 325], [326, 331], [332, 337], [338, 340], [341, 347], [348, 356], [356, 357]]}
{"doc_key": "ai-train-9", "ner": [[5, 7, "misc"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 30, "task"], [32, 34, "task"], [36, 38, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[5, 7, 17, 18, "part-of", "concept_used_in", true, false], [5, 7, 20, 21, "part-of", "concept_used_in", false, false], [5, 7, 23, 24, "part-of", "concept_used_in", false, false], [5, 7, 26, 27, "part-of", "concept_used_in", false, false], [5, 7, 29, 30, "part-of", "concept_used_in", false, false], [5, 7, 32, 34, "part-of", "concept_used_in", false, false], [5, 7, 36, 38, "part-of", "concept_used_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "technique", "used", "to", "create", "self", "-", "facts", "and", "use", "them", "for", "recognition", "is", "also", "used", "outside", "facial", "recognition", ":", "handwriting", "recognition", ",", "lip", "reading", ",", "voice", "recognition", ",", "sign", "language", "and", "hand", "gesture", "interpretation", "and", "medical", "image", "analysis", "."], "sentence-detokenized": "The technique used to create self-facts and use them for recognition is also used outside facial recognition: handwriting recognition, lip reading, voice recognition, sign language and hand gesture interpretation and medical image analysis.", "token2charspan": [[0, 3], [4, 13], [14, 18], [19, 21], [22, 28], [29, 33], [33, 34], [34, 39], [40, 43], [44, 47], [48, 52], [53, 56], [57, 68], [69, 71], [72, 76], [77, 81], [82, 89], [90, 96], [97, 108], [108, 109], [110, 121], [122, 133], [133, 134], [135, 138], [139, 146], [146, 147], [148, 153], [154, 165], [165, 166], [167, 171], [172, 180], [181, 184], [185, 189], [190, 197], [198, 212], [213, 216], [217, 224], [225, 230], [231, 239], [239, 240]]}
{"doc_key": "ai-train-10", "ner": [[1, 3, "organisation"], [10, 14, "organisation"], [16, 16, "organisation"], [23, 23, "organisation"], [28, 30, "organisation"], [33, 36, "organisation"], [39, 43, "organisation"], [45, 45, "organisation"], [49, 52, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[10, 14, 1, 3, "part-of", "", false, false], [16, 16, 10, 14, "named", "", false, false], [23, 23, 1, 3, "part-of", "", false, false], [28, 30, 1, 3, "part-of", "", false, false], [33, 36, 1, 3, "part-of", "", false, false], [39, 43, 1, 3, "part-of", "", false, false], [45, 45, 39, 43, "named", "", false, false], [49, 52, 1, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "National", "Science", "Foundation", "served", "as", "an", "umbrella", "for", "the", "National", "Aeronautics", "and", "Space", "Administration", "(", "NASA", ")", ",", "the", "US", "Department", "of", "Energy", ",", "the", "US", "Department", "of", "Commerce", "NIST", ",", "the", "US", "Department", "of", "Defence", ",", "the", "Defense", "Advanced", "Research", "Projects", "Agency", "(", "DARPA", ")", "and", "the", "Office", "of", "Naval", "Research", "coordinated", "studies", "to", "inform", "strategic", "planners", "in", "their", "deliberations", "."], "sentence-detokenized": "The National Science Foundation served as an umbrella for the National Aeronautics and Space Administration (NASA), the US Department of Energy, the US Department of Commerce NIST, the US Department of Defence, the Defense Advanced Research Projects Agency (DARPA) and the Office of Naval Research coordinated studies to inform strategic planners in their deliberations.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 38], [39, 41], [42, 44], [45, 53], [54, 57], [58, 61], [62, 70], [71, 82], [83, 86], [87, 92], [93, 107], [108, 109], [109, 113], [113, 114], [114, 115], [116, 119], [120, 122], [123, 133], [134, 136], [137, 143], [143, 144], [145, 148], [149, 151], [152, 162], [163, 165], [166, 174], [175, 179], [179, 180], [181, 184], [185, 187], [188, 198], [199, 201], [202, 209], [209, 210], [211, 214], [215, 222], [223, 231], [232, 240], [241, 249], [250, 256], [257, 258], [258, 263], [263, 264], [265, 268], [269, 272], [273, 279], [280, 282], [283, 288], [289, 297], [298, 309], [310, 317], [318, 320], [321, 327], [328, 337], [338, 346], [347, 349], [350, 355], [356, 369], [369, 370]]}
{"doc_key": "ai-train-11", "ner": [[5, 6, "metrics"], [10, 12, "algorithm"], [15, 16, "researcher"], [21, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 10, 12, "part-of", "", false, false], [15, 16, 21, 21, "related-to", "added_appendix_to_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "quick", "method", "to", "calculate", "maximum", "likelihood", "estimates", "for", "the", "probit", "model", "was", "proposed", "by", "Ronald", "Fisher", "as", "an", "appendix", "to", "Bliss", "'", "work", "in", "1935", "."], "sentence-detokenized": "A quick method to calculate maximum likelihood estimates for the probit model was proposed by Ronald Fisher as an appendix to Bliss' work in 1935.", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 17], [18, 27], [28, 35], [36, 46], [47, 56], [57, 60], [61, 64], [65, 71], [72, 77], [78, 81], [82, 90], [91, 93], [94, 100], [101, 107], [108, 110], [111, 113], [114, 122], [123, 125], [126, 131], [131, 132], [133, 137], [138, 140], [141, 145], [145, 146]]}
{"doc_key": "ai-train-12", "ner": [[10, 11, "product"], [14, 15, "product"], [18, 18, "organisation"], [20, 20, "product"], [23, 23, "organisation"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 20, 14, 15, "usage", "uses_software", false, false], [20, 20, 18, 18, "artifact", "", false, false], [20, 20, 25, 25, "named", "", false, false], [25, 25, 23, 23, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Many", "of", "these", "programmes", "are", "available", "online", ",", "such", "as", "Google", "Translate", "and", "the", "SYSTRAN", "system", "that", "powers", "AltaVista", "'s", "BabelFish", "(", "now", "Yahoo", "'s", "Babelfish", "as", "of", "9", "May", "2008", ")", "."], "sentence-detokenized": "Many of these programmes are available online, such as Google Translate and the SYSTRAN system that powers AltaVista's BabelFish (now Yahoo's Babelfish as of 9 May 2008).", "token2charspan": [[0, 4], [5, 7], [8, 13], [14, 24], [25, 28], [29, 38], [39, 45], [45, 46], [47, 51], [52, 54], [55, 61], [62, 71], [72, 75], [76, 79], [80, 87], [88, 94], [95, 99], [100, 106], [107, 116], [116, 118], [119, 128], [129, 130], [130, 133], [134, 139], [139, 141], [142, 151], [152, 154], [155, 157], [158, 159], [160, 163], [164, 168], [168, 169], [169, 170]]}
{"doc_key": "ai-train-13", "ner": [[3, 3, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [20, 22, "field"], [26, 27, "misc"], [31, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 20, 22, "related-to", "", true, false], [3, 3, 26, 27, "related-to", "", true, false], [3, 3, 31, 32, "related-to", "", true, false], [7, 8, 20, 22, "related-to", "", true, false], [7, 8, 26, 27, "related-to", "", true, false], [7, 8, 31, 32, "related-to", "", true, false], [10, 11, 20, 22, "related-to", "", true, false], [10, 11, 26, 27, "related-to", "", true, false], [10, 11, 31, 32, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "2002", ",", "Hutter", ",", "together", "with", "J\u00fcrgen", "Schmidhuber", "and", "Shane", "Legg", ",", "developed", "and", "published", "a", "mathematical", "theory", "of", "general", "artificial", "intelligence", "based", "on", "idealised", "intelligent", "agents", "and", "reward", "-motivated", "reinforcement", "learning", "."], "sentence-detokenized": "In 2002, Hutter, together with J\u00fcrgen Schmidhuber and Shane Legg, developed and published a mathematical theory of general artificial intelligence based on idealised intelligent agents and reward-motivated reinforcement learning.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [15, 16], [17, 25], [26, 30], [31, 37], [38, 49], [50, 53], [54, 59], [60, 64], [64, 65], [66, 75], [76, 79], [80, 89], [90, 91], [92, 104], [105, 111], [112, 114], [115, 122], [123, 133], [134, 146], [147, 152], [153, 155], [156, 165], [166, 177], [178, 184], [185, 188], [189, 195], [195, 205], [206, 219], [220, 228], [228, 229]]}
{"doc_key": "ai-train-14", "ner": [[11, 11, "metrics"], [13, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 11, 13, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "most", "common", "way", "is", "to", "use", "the", "so", "-", "called", "ROUGE", "(", "Recall", "-", "Oriented", "Understudy", "for", "Gisting", "Evaluation", ")", "measure", "."], "sentence-detokenized": "The most common way is to use the so-called ROUGE (Recall-Oriented Understudy for Gisting Evaluation) measure.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 19], [20, 22], [23, 25], [26, 29], [30, 33], [34, 36], [36, 37], [37, 43], [44, 49], [50, 51], [51, 57], [57, 58], [58, 66], [67, 77], [78, 81], [82, 89], [90, 100], [100, 101], [102, 109], [109, 110]]}
{"doc_key": "ai-train-15", "ner": [[0, 0, "product"], [13, 13, "programlang"], [16, 16, "programlang"], [18, 19, "researcher"], [21, 22, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 13, 13, "related-to", "", false, false], [0, 0, 16, 16, "related-to", "", false, false], [18, 19, 21, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["RapidMiner", "provides", "learning", "schemes", ",", "models", "and", "algorithms", "and", "can", "be", "extended", "using", "R", "scripts", "and", "Python", ".", "David", "Norris", ",", "Bloor", "Research", ",", "13", "November", "2013", "."], "sentence-detokenized": "RapidMiner provides learning schemes, models and algorithms and can be extended using R scripts and Python. David Norris, Bloor Research, 13 November 2013.", "token2charspan": [[0, 10], [11, 19], [20, 28], [29, 36], [36, 37], [38, 44], [45, 48], [49, 59], [60, 63], [64, 67], [68, 70], [71, 79], [80, 85], [86, 87], [88, 95], [96, 99], [100, 106], [106, 107], [108, 113], [114, 120], [120, 121], [122, 127], [128, 136], [136, 137], [138, 140], [141, 149], [150, 154], [154, 155]]}
{"doc_key": "ai-train-16", "ner": [[5, 7, "programlang"], [10, 14, "product"]], "ner_mapping_to_source": [4, 5], "relations": [[10, 14, 5, 7, "general-affiliation", "", true, false]], "relations_mapping_to_source": [4], "sentence": ["The", "most", "recent", ",", "fully", "Java", "-", "based", "version", "(", "Weka", "3", ")", ",", "the", "development", "of", "which", "started", "in", "1997", ",", "is", "now", "used", "in", "many", "different", "application", "areas", ",", "particularly", "for", "teaching", "and", "research", "purposes", "."], "sentence-detokenized": "The most recent, fully Java-based version (Weka 3), the development of which started in 1997, is now used in many different application areas, particularly for teaching and research purposes.", "token2charspan": [[0, 3], [4, 8], [9, 15], [15, 16], [17, 22], [23, 27], [27, 28], [28, 33], [34, 41], [42, 43], [43, 47], [48, 49], [49, 50], [50, 51], [52, 55], [56, 67], [68, 70], [71, 76], [77, 84], [85, 87], [88, 92], [92, 93], [94, 96], [97, 100], [101, 105], [106, 108], [109, 113], [114, 123], [124, 135], [136, 141], [141, 142], [143, 155], [156, 159], [160, 168], [169, 172], [173, 181], [182, 190], [190, 191]]}
{"doc_key": "ai-train-17", "ner": [[0, 0, "product"], [12, 19, "misc"], [22, 24, "misc"], [27, 34, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 19, 0, 0, "topic", "", false, false], [12, 19, 22, 24, "win-defeat", "", false, false], [22, 24, 27, 34, "temporal", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Eurisko", "made", "many", "interesting", "discoveries", "and", "enjoyed", "considerable", "success", ":", "his", "article", "Heuretics", ":", "Theoretical", "and", "Study", "of", "Heuristic", "Rules", "won", "the", "Best", "Paper", "award", "at", "the", "1982", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "Eurisko made many interesting discoveries and enjoyed considerable success: his article Heuretics: Theoretical and Study of Heuristic Rules won the Best Paper award at the 1982 Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 7], [8, 12], [13, 17], [18, 29], [30, 41], [42, 45], [46, 53], [54, 66], [67, 74], [74, 75], [76, 79], [80, 87], [88, 97], [97, 98], [99, 110], [111, 114], [115, 120], [121, 123], [124, 133], [134, 139], [140, 143], [144, 147], [148, 152], [153, 158], [159, 164], [165, 167], [168, 171], [172, 176], [177, 188], [189, 192], [193, 196], [197, 208], [209, 211], [212, 222], [223, 235], [235, 236]]}
{"doc_key": "ai-train-18", "ner": [[9, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["To", "take", "several", "entities", "into", "account", ",", "a", "separate", "hinge", "loss", "is", "calculated", "for", "each", "capsule", "."], "sentence-detokenized": "To take several entities into account, a separate hinge loss is calculated for each capsule.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 24], [25, 29], [30, 37], [37, 38], [39, 40], [41, 49], [50, 55], [56, 60], [61, 63], [64, 74], [75, 78], [79, 83], [84, 91], [91, 92]]}
{"doc_key": "ai-train-19", "ner": [[8, 10, "product"], [12, 14, "product"], [16, 17, "product"], [19, 21, "product"], [23, 25, "product"], [27, 28, "product"], [36, 40, "product"], [43, 44, "product"], [46, 47, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 10, 27, 28, "type-of", "", false, false], [12, 14, 27, 28, "type-of", "", false, false], [16, 17, 27, 28, "type-of", "", false, false], [19, 21, 27, 28, "type-of", "", false, false], [23, 25, 27, 28, "type-of", "", false, false], [43, 44, 36, 40, "type-of", "", false, false], [46, 47, 36, 40, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["With", "the", "emergence", "of", "conversational", "assistants", "such", "as", "Apple", "'s", "Siri", ",", "Amazon", "'s", "Alexa", ",", "Google", "Assistant", ",", "Microsoft", "'s", "Cortana", "and", "Samsung", "'s", "Bixby", ",", "voice", "portals", "are", "now", "accessible", "through", "mobile", "devices", "and", "Far", "Field", "voice", "smart", "speakers", "such", "as", "Amazon", "Echo", "and", "Google", "Home", "."], "sentence-detokenized": "With the emergence of conversational assistants such as Apple's Siri, Amazon's Alexa, Google Assistant, Microsoft's Cortana and Samsung's Bixby, voice portals are now accessible through mobile devices and Far Field voice smart speakers such as Amazon Echo and Google Home.", "token2charspan": [[0, 4], [5, 8], [9, 18], [19, 21], [22, 36], [37, 47], [48, 52], [53, 55], [56, 61], [61, 63], [64, 68], [68, 69], [70, 76], [76, 78], [79, 84], [84, 85], [86, 92], [93, 102], [102, 103], [104, 113], [113, 115], [116, 123], [124, 127], [128, 135], [135, 137], [138, 143], [143, 144], [145, 150], [151, 158], [159, 162], [163, 166], [167, 177], [178, 185], [186, 192], [193, 200], [201, 204], [205, 208], [209, 214], [215, 220], [221, 226], [227, 235], [236, 240], [241, 243], [244, 250], [251, 255], [256, 259], [260, 266], [267, 271], [271, 272]]}
{"doc_key": "ai-train-20", "ner": [[2, 3, "field"], [6, 8, "algorithm"], [11, 13, "algorithm"], [15, 16, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 2, 3, "type-of", "", false, false], [11, 13, 2, 3, "type-of", "", false, false], [15, 16, 2, 3, "type-of", "", false, false], [19, 19, 2, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Examples", "of", "supervised", "learning", "are", "the", "Naive", "Bayes", "classifier", ",", "the", "Support", "vector", "machine", ",", "Gaussian", "mixtures", "and", "the", "network", "."], "sentence-detokenized": "Examples of supervised learning are the Naive Bayes classifier, the Support vector machine, Gaussian mixtures and the network.", "token2charspan": [[0, 8], [9, 11], [12, 22], [23, 31], [32, 35], [36, 39], [40, 45], [46, 51], [52, 62], [62, 63], [64, 67], [68, 75], [76, 82], [83, 90], [90, 91], [92, 100], [101, 109], [110, 113], [114, 117], [118, 125], [125, 126]]}
{"doc_key": "ai-train-21", "ner": [[4, 5, "algorithm"], [26, 28, "algorithm"], [30, 30, "task"], [36, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 26, 28, "part-of", "", true, false], [36, 37, 30, 30, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["One", "can", "use", "the", "OSD", "algorithm", "to", "derive", "mathematical", "O", "(", "sqrt", "{", "T", "}", ")", "/", "mathematical", "regret", "limits", "for", "the", "online", "version", "of", "the", "support", "vector", "machine", "for", "classification", ",", "which", "uses", "the", "mathematical", "hinge", "loss", "v", "_t", "(", "w", ")", "=", "max", "\\", "{", "0", ",", "1", "-", "y", "_t", "(", "w", "cdot", "x", "_t", ")", "\\}", "/", "mathematical"], "sentence-detokenized": "One can use the OSD algorithm to derive mathematical O (sqrt {T}) / mathematical regret limits for the online version of the support vector machine for classification, which uses the mathematical hinge loss v _t (w) = max\\ {0, 1 - y _t (w cdot x _t)\\} / mathematical", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 15], [16, 19], [20, 29], [30, 32], [33, 39], [40, 52], [53, 54], [55, 56], [56, 60], [61, 62], [62, 63], [63, 64], [64, 65], [66, 67], [68, 80], [81, 87], [88, 94], [95, 98], [99, 102], [103, 109], [110, 117], [118, 120], [121, 124], [125, 132], [133, 139], [140, 147], [148, 151], [152, 166], [166, 167], [168, 173], [174, 178], [179, 182], [183, 195], [196, 201], [202, 206], [207, 208], [209, 211], [212, 213], [213, 214], [214, 215], [216, 217], [218, 221], [221, 222], [223, 224], [224, 225], [225, 226], [227, 228], [229, 230], [231, 232], [233, 235], [236, 237], [237, 238], [239, 243], [244, 245], [246, 248], [248, 249], [249, 251], [252, 253], [254, 266]]}
{"doc_key": "ai-train-22", "ner": [[2, 3, "task"], [5, 6, "task"], [8, 8, "task"], [10, 11, "task"], [13, 14, "task"], [16, 17, "task"], [19, 20, "task"], [22, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Applications", "include", "object", "recognition", ",", "robotic", "mapping", "and", "navigation", ",", "image", "stitching", ",", "3D", "modelling", ",", "gesture", "recognition", ",", "video", "tracking", ",", "individual", "identification", "of", "wild", "animals", "and", "moving", "matches", "."], "sentence-detokenized": "Applications include object recognition, robotic mapping and navigation, image stitching, 3D modelling, gesture recognition, video tracking, individual identification of wild animals and moving matches.", "token2charspan": [[0, 12], [13, 20], [21, 27], [28, 39], [39, 40], [41, 48], [49, 56], [57, 60], [61, 71], [71, 72], [73, 78], [79, 88], [88, 89], [90, 92], [93, 102], [102, 103], [104, 111], [112, 123], [123, 124], [125, 130], [131, 139], [139, 140], [141, 151], [152, 166], [167, 169], [170, 174], [175, 182], [183, 186], [187, 193], [194, 201], [201, 202]]}
{"doc_key": "ai-train-23", "ner": [[8, 9, "task"], [14, 15, "university"], [17, 19, "university"], [21, 22, "university"], [24, 25, "university"], [27, 32, "university"], [34, 36, "university"], [38, 40, "university"], [42, 43, "university"], [45, 50, "university"], [52, 52, "university"], [55, 59, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[8, 9, 14, 15, "related-to", "", true, false], [8, 9, 17, 19, "related-to", "", true, false], [8, 9, 21, 22, "related-to", "", true, false], [8, 9, 24, 25, "related-to", "", true, false], [8, 9, 27, 32, "related-to", "", true, false], [8, 9, 34, 36, "related-to", "", true, false], [8, 9, 38, 40, "related-to", "", true, false], [8, 9, 42, 43, "related-to", "", true, false], [8, 9, 45, 50, "related-to", "", true, false], [8, 9, 52, 52, "related-to", "", true, false], [8, 9, 55, 59, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Numerous", "groups", "and", "companies", "are", "conducting", "research", "on", "pose", "estimation", ",", "including", "groups", "from", "Brown", "University", ",", "Carnegie", "Mellon", "University", ",", "MPI", "Saarbruecken", ",", "Stanford", "University", ",", "University", "of", "California", ",", "San", "Diego", ",", "University", "of", "Toronto", ",", "Ecole", "Centrale", "Paris", ",", "ETH", "Zurich", ",", "National", "University", "of", "Science", "and", "Technology", "(", "NUST", ")", "and", "University", "of", "California", ",", "Irvine", "."], "sentence-detokenized": "Numerous groups and companies are conducting research on pose estimation, including groups from Brown University, Carnegie Mellon University, MPI Saarbruecken, Stanford University, University of California, San Diego, University of Toronto, Ecole Centrale Paris, ETH Zurich, National University of Science and Technology (NUST) and University of California, Irvine.", "token2charspan": [[0, 8], [9, 15], [16, 19], [20, 29], [30, 33], [34, 44], [45, 53], [54, 56], [57, 61], [62, 72], [72, 73], [74, 83], [84, 90], [91, 95], [96, 101], [102, 112], [112, 113], [114, 122], [123, 129], [130, 140], [140, 141], [142, 145], [146, 158], [158, 159], [160, 168], [169, 179], [179, 180], [181, 191], [192, 194], [195, 205], [205, 206], [207, 210], [211, 216], [216, 217], [218, 228], [229, 231], [232, 239], [239, 240], [241, 246], [247, 255], [256, 261], [261, 262], [263, 266], [267, 273], [273, 274], [275, 283], [284, 294], [295, 297], [298, 305], [306, 309], [310, 320], [321, 322], [322, 326], [326, 327], [328, 331], [332, 342], [343, 345], [346, 356], [356, 357], [358, 364], [364, 365]]}
{"doc_key": "ai-train-24", "ner": [[0, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "cross", "entropy", "loss", "sigmoid", "function", "is", "used", "to", "predict", "K", "independent", "probability", "values", "in", "0.1", "/", "mathematics", "."], "sentence-detokenized": "The cross entropy loss sigmoid function is used to predict K independent probability values in 0.1 / mathematics.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 22], [23, 30], [31, 39], [40, 42], [43, 47], [48, 50], [51, 58], [59, 60], [61, 72], [73, 84], [85, 91], [92, 94], [95, 98], [99, 100], [101, 112], [112, 113]]}
{"doc_key": "ai-train-25", "ner": [[10, 12, "misc"], [14, 14, "field"], [16, 18, "field"], [20, 22, "university"], [25, 25, "country"], [28, 30, "misc"], [33, 36, "university"], [38, 38, "country"], [5, 5, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[10, 12, 14, 14, "topic", "", false, false], [10, 12, 16, 18, "topic", "", false, false], [10, 12, 20, 22, "physical", "", true, false], [20, 22, 25, 25, "physical", "", false, false], [28, 30, 33, 36, "physical", "", true, false], [33, 36, 38, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Before", "becoming", "a", "professor", "at", "Cambridge", ",", "he", "held", "the", "Johann", "Bernoulli", "Chair", "of", "Mathematics", "and", "Computer", "Science", "at", "the", "University", "of", "Groningen", "in", "the", "Netherlands", "and", "the", "Toshiba", "Endowed", "Chair", "at", "the", "Tokyo", "Institute", "of", "Technology", "in", "Japan", "."], "sentence-detokenized": "Before becoming a professor at Cambridge, he held the Johann Bernoulli Chair of Mathematics and Computer Science at the University of Groningen in the Netherlands and the Toshiba Endowed Chair at the Tokyo Institute of Technology in Japan.", "token2charspan": [[0, 6], [7, 15], [16, 17], [18, 27], [28, 30], [31, 40], [40, 41], [42, 44], [45, 49], [50, 53], [54, 60], [61, 70], [71, 76], [77, 79], [80, 91], [92, 95], [96, 104], [105, 112], [113, 115], [116, 119], [120, 130], [131, 133], [134, 143], [144, 146], [147, 150], [151, 162], [163, 166], [167, 170], [171, 178], [179, 186], [187, 192], [193, 195], [196, 199], [200, 205], [206, 215], [216, 218], [219, 229], [230, 232], [233, 238], [238, 239]]}
{"doc_key": "ai-train-26", "ner": [[7, 8, "algorithm"], [18, 21, "algorithm"], [24, 24, "algorithm"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 18, 21, "usage", "", true, false], [18, 21, 11, 12, "origin", "", false, false], [18, 21, 14, 15, "origin", "", false, false], [24, 24, 18, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Another", "technique", "that", "is", "particularly", "used", "for", "recurrent", "neural", "networks", "is", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "'s", "1997", "short", "-", "term", "memory", "network", "(", "LSTM", ")", "."], "sentence-detokenized": "Another technique that is particularly used for recurrent neural networks is Sepp Hochreiter and J\u00fcrgen Schmidhuber's 1997 short-term memory network (LSTM).", "token2charspan": [[0, 7], [8, 17], [18, 22], [23, 25], [26, 38], [39, 43], [44, 47], [48, 57], [58, 64], [65, 73], [74, 76], [77, 81], [82, 92], [93, 96], [97, 103], [104, 115], [115, 117], [118, 122], [123, 128], [128, 129], [129, 133], [134, 140], [141, 148], [149, 150], [150, 154], [154, 155], [155, 156]]}
{"doc_key": "ai-train-27", "ner": [[4, 5, "programlang"], [8, 9, "product"], [15, 15, "product"], [44, 44, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 4, 5, "general-affiliation", "", false, false], [8, 9, 15, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "inclusion", "of", "a", "C", "+", "interpreter", "(", "CI", "NT", "up", "to", "version", "5.34", ",", "Cling", "from", "version", "6", ")", "makes", "this", "package", "very", "versatile", ",", "as", "it", "can", "be", "used", "in", "interactive", ",", "scripted", "and", "compiled", "mode", "similar", "to", "commercial", "products", "such", "as", "MATLAB", "."], "sentence-detokenized": "The inclusion of a C+ interpreter (CINT up to version 5.34, Cling from version 6) makes this package very versatile, as it can be used in interactive, scripted and compiled mode similar to commercial products such as MATLAB.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 18], [19, 20], [20, 21], [22, 33], [34, 35], [35, 37], [37, 39], [40, 42], [43, 45], [46, 53], [54, 58], [58, 59], [60, 65], [66, 70], [71, 78], [79, 80], [80, 81], [82, 87], [88, 92], [93, 100], [101, 105], [106, 115], [115, 116], [117, 119], [120, 122], [123, 126], [127, 129], [130, 134], [135, 137], [138, 149], [149, 150], [151, 159], [160, 163], [164, 172], [173, 177], [178, 185], [186, 188], [189, 199], [200, 208], [209, 213], [214, 216], [217, 223], [223, 224]]}
{"doc_key": "ai-train-28", "ner": [[0, 1, "product"], [20, 22, "field"], [26, 27, "task"], [29, 31, "task"], [33, 34, "task"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 20, 22, "related-to", "", false, false], [26, 27, 20, 22, "part-of", "", false, false], [29, 31, 20, 22, "part-of", "", false, false], [33, 34, 20, 22, "part-of", "", false, false], [36, 37, 20, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Voice", "interfaces", "that", "interpret", "and", "manage", "conversation", "state", "are", "difficult", "to", "design", "due", "to", "the", "inherent", "difficulty", "of", "integrating", "complex", "natural", "language", "processing", "tasks", "such", "as", "coreference", "resolution", ",", "named", "entity", "recognition", ",", "information", "retrieval", "and", "dialogue", "management", "."], "sentence-detokenized": "Voice interfaces that interpret and manage conversation state are difficult to design due to the inherent difficulty of integrating complex natural language processing tasks such as coreference resolution, named entity recognition, information retrieval and dialogue management.", "token2charspan": [[0, 5], [6, 16], [17, 21], [22, 31], [32, 35], [36, 42], [43, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 85], [86, 89], [90, 92], [93, 96], [97, 105], [106, 116], [117, 119], [120, 131], [132, 139], [140, 147], [148, 156], [157, 167], [168, 173], [174, 178], [179, 181], [182, 193], [194, 204], [204, 205], [206, 211], [212, 218], [219, 230], [230, 231], [232, 243], [244, 253], [254, 257], [258, 266], [267, 277], [277, 278]]}
{"doc_key": "ai-train-29", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [13, 15, "researcher"], [20, 24, "organisation"], [33, 34, "field"], [36, 37, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 13, 15, "origin", "", false, false], [5, 5, 33, 34, "part-of", "", false, false], [5, 5, 36, 37, "part-of", "", false, false], [7, 9, 13, 15, "origin", "", false, false], [7, 9, 33, 34, "part-of", "", false, false], [7, 9, 36, 37, "part-of", "", false, false], [13, 15, 20, 24, "physical", "", false, false], [13, 15, 20, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Between", "2009", "and", "2012", ",", "recurrent", "and", "feedforward", "deep", "neural", "networks", "developed", "by", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "Swiss", "artificial", "intelligence", "laboratory", "IDSIA", "won", "eight", "international", "competitions", "in", "the", "field", "of", "pattern", "recognition", "and", "machine", "learning", "."], "sentence-detokenized": "Between 2009 and 2012, recurrent and feedforward deep neural networks developed by J\u00fcrgen Schmidhuber's research group at the Swiss artificial intelligence laboratory IDSIA won eight international competitions in the field of pattern recognition and machine learning.", "token2charspan": [[0, 7], [8, 12], [13, 16], [17, 21], [21, 22], [23, 32], [33, 36], [37, 48], [49, 53], [54, 60], [61, 69], [70, 79], [80, 82], [83, 89], [90, 101], [101, 103], [104, 112], [113, 118], [119, 121], [122, 125], [126, 131], [132, 142], [143, 155], [156, 166], [167, 172], [173, 176], [177, 182], [183, 196], [197, 209], [210, 212], [213, 216], [217, 222], [223, 225], [226, 233], [234, 245], [246, 249], [250, 257], [258, 266], [266, 267]]}
{"doc_key": "ai-train-30", "ner": [[1, 3, "product"], [6, 7, "product"], [9, 10, "product"], [15, 15, "task"], [14, 17, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 6, 7, "usage", "", false, false], [1, 3, 9, 10, "usage", "", false, false], [1, 3, 15, 15, "usage", "", true, false], [1, 3, 14, 17, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Modern", "Windows", "desktop", "systems", "can", "use", "SAPI", "4", "and", "SAPI", "5", "components", "to", "support", "speech", "synthesis", "and", "speech", "."], "sentence-detokenized": "Modern Windows desktop systems can use SAPI 4 and SAPI 5 components to support speech synthesis and speech.", "token2charspan": [[0, 6], [7, 14], [15, 22], [23, 30], [31, 34], [35, 38], [39, 43], [44, 45], [46, 49], [50, 54], [55, 56], [57, 67], [68, 70], [71, 78], [79, 85], [86, 95], [96, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-train-31", "ner": [[3, 8, "misc"], [10, 10, "field"], [13, 15, "university"], [22, 25, "field"], [28, 31, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 8, 10, 10, "topic", "topic_of_award", false, false], [3, 8, 13, 15, "origin", "", true, false], [22, 25, 28, 31, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "received", "two", "honorary", "degrees", ",", "an", "honorary", "degree", "in", "Psychology", "from", "the", "University", "of", "Padua", "in", "1995", "and", "a", "doctorate", "in", "Industrial", "Design", "and", "Engineering", "from", "the", "Delft", "University", "of", "Technology", "."], "sentence-detokenized": "He received two honorary degrees, an honorary degree in Psychology from the University of Padua in 1995 and a doctorate in Industrial Design and Engineering from the Delft University of Technology.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 24], [25, 32], [32, 33], [34, 36], [37, 45], [46, 52], [53, 55], [56, 66], [67, 71], [72, 75], [76, 86], [87, 89], [90, 95], [96, 98], [99, 103], [104, 107], [108, 109], [110, 119], [120, 122], [123, 133], [134, 140], [141, 144], [145, 156], [157, 161], [162, 165], [166, 171], [172, 182], [183, 185], [186, 196], [196, 197]]}
{"doc_key": "ai-train-32", "ner": [[5, 6, "researcher"], [12, 15, "organisation"], [17, 17, "location"], [19, 19, "researcher"], [30, 31, "misc"], [44, 46, "misc"], [62, 63, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 6, 12, 15, "physical", "", false, false], [5, 6, 12, 15, "role", "", false, false], [12, 15, 17, 17, "physical", "", false, false], [19, 19, 30, 31, "related-to", "works_with", true, false], [19, 19, 44, 46, "related-to", "works_with", true, false], [19, 19, 62, 63, "related-to", "works_with", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["With", "long", "-", "time", "collaborator", "Laurent", "Cohen", ",", "a", "neurologist", "at", "the", "Hospital", "Piti\u00e9", "-", "Salp\u00eatri\u00e8re", "in", "Paris", ",", "Dehaene", "also", "identified", "patients", "with", "lesions", "in", "different", "regions", "of", "the", "parietal", "lobe", "with", "altered", "multiplication", "but", "preserved", "subtraction", "(", "associated", "with", "lesions", "of", "the", "inferior", "parietal", "lobule", ")", "and", "others", "with", "altered", "subtraction", "but", "preserved", "multiplication", "(", "associated", "with", "lesions", "of", "the", "intraparietal", "sulcus", ")", "."], "sentence-detokenized": "With long-time collaborator Laurent Cohen, a neurologist at the Hospital Piti\u00e9-Salp\u00eatri\u00e8re in Paris, Dehaene also identified patients with lesions in different regions of the parietal lobe with altered multiplication but preserved subtraction (associated with lesions of the inferior parietal lobule) and others with altered subtraction but preserved multiplication (associated with lesions of the intraparietal sulcus).", "token2charspan": [[0, 4], [5, 9], [9, 10], [10, 14], [15, 27], [28, 35], [36, 41], [41, 42], [43, 44], [45, 56], [57, 59], [60, 63], [64, 72], [73, 78], [78, 79], [79, 90], [91, 93], [94, 99], [99, 100], [101, 108], [109, 113], [114, 124], [125, 133], [134, 138], [139, 146], [147, 149], [150, 159], [160, 167], [168, 170], [171, 174], [175, 183], [184, 188], [189, 193], [194, 201], [202, 216], [217, 220], [221, 230], [231, 242], [243, 244], [244, 254], [255, 259], [260, 267], [268, 270], [271, 274], [275, 283], [284, 292], [293, 299], [299, 300], [301, 304], [305, 311], [312, 316], [317, 324], [325, 336], [337, 340], [341, 350], [351, 365], [366, 367], [367, 377], [378, 382], [383, 390], [391, 393], [394, 397], [398, 411], [412, 418], [418, 419], [419, 420]]}
{"doc_key": "ai-train-33", "ner": [[7, 9, "product"], [14, 17, "misc"], [19, 20, "misc"], [27, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 17, 7, 9, "topic", "", false, false], [19, 20, 7, 9, "topic", "", false, false], [27, 27, 7, 9, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["More", "recently", ",", "the", "fictional", "representations", "of", "artificially", "intelligent", "robots", "in", "films", "such", "as", "A.I", ".", "Artificial", "Intelligence", "and", "Ex", "Machina", "and", "the", "2016", "television", "adaptation", "of", "Westworld", "have", "aroused", "public", "sympathy", "for", "the", "robots", "themselves", "."], "sentence-detokenized": "More recently, the fictional representations of artificially intelligent robots in films such as A.I. Artificial Intelligence and Ex Machina and the 2016 television adaptation of Westworld have aroused public sympathy for the robots themselves.", "token2charspan": [[0, 4], [5, 13], [13, 14], [15, 18], [19, 28], [29, 44], [45, 47], [48, 60], [61, 72], [73, 79], [80, 82], [83, 88], [89, 93], [94, 96], [97, 100], [100, 101], [102, 112], [113, 125], [126, 129], [130, 132], [133, 140], [141, 144], [145, 148], [149, 153], [154, 164], [165, 175], [176, 178], [179, 188], [189, 193], [194, 201], [202, 208], [209, 217], [218, 221], [222, 225], [226, 232], [233, 243], [243, 244]]}
{"doc_key": "ai-train-34", "ner": [[7, 8, "field"], [10, 12, "algorithm"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 12, 7, 8, "part-of", "", false, false], [14, 15, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "of", "the", "main", "methods", "used", "in", "unsupervised", "learning", "are", "principal", "component", "analysis", "and", "cluster", "analysis", "."], "sentence-detokenized": "Two of the main methods used in unsupervised learning are principal component analysis and cluster analysis.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 15], [16, 23], [24, 28], [29, 31], [32, 44], [45, 53], [54, 57], [58, 67], [68, 77], [78, 86], [87, 90], [91, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-train-35", "ner": [[0, 3, "organisation"], [20, 21, "misc"], [26, 27, "misc"], [29, 31, "person"], [36, 37, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 21, 0, 3, "artifact", "", false, false], [26, 27, 0, 3, "artifact", "", false, false], [26, 27, 29, 31, "role", "director_of", false, false], [26, 27, 36, 37, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Walt", "Disney", "Company", "also", "started", "to", "make", "more", "use", "of", "3D", "films", "in", "special", "locations", "to", "impress", "audiences", ":", "Magical", "Journeys", "(", "1982", ")", "and", "Captain", "EO", "(", "Francis", "Ford", "Coppola", ",", "1986", ",", "with", "Michael", "Jackson", ")", "are", "notable", "examples", "."], "sentence-detokenized": "The Walt Disney Company also started to make more use of 3D films in special locations to impress audiences: Magical Journeys (1982) and Captain EO (Francis Ford Coppola, 1986, with Michael Jackson) are notable examples.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 23], [24, 28], [29, 36], [37, 39], [40, 44], [45, 49], [50, 53], [54, 56], [57, 59], [60, 65], [66, 68], [69, 76], [77, 86], [87, 89], [90, 97], [98, 107], [107, 108], [109, 116], [117, 125], [126, 127], [127, 131], [131, 132], [133, 136], [137, 144], [145, 147], [148, 149], [149, 156], [157, 161], [162, 169], [169, 170], [171, 175], [175, 176], [177, 181], [182, 189], [190, 197], [197, 198], [199, 202], [203, 210], [211, 219], [219, 220]]}
{"doc_key": "ai-train-36", "ner": [[12, 14, "field"], [19, 24, "task"], [26, 27, "task"], [29, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 24, 12, 14, "part-of", "", false, false], [26, 27, 12, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Since", "2002", ",", "perceptron", "training", "has", "become", "popular", "in", "the", "field", "of", "natural", "language", "processing", "for", "tasks", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "syntactic", "parsing", "(", "Collins", ",", "2002", ")", "."], "sentence-detokenized": "Since 2002, perceptron training has become popular in the field of natural language processing for tasks such as part-of-speech tagging and syntactic parsing (Collins, 2002).", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 22], [23, 31], [32, 35], [36, 42], [43, 50], [51, 53], [54, 57], [58, 63], [64, 66], [67, 74], [75, 83], [84, 94], [95, 98], [99, 104], [105, 109], [110, 112], [113, 117], [117, 118], [118, 120], [120, 121], [121, 127], [128, 135], [136, 139], [140, 149], [150, 157], [158, 159], [159, 166], [166, 167], [168, 172], [172, 173], [173, 174]]}
{"doc_key": "ai-train-37", "ner": [[2, 4, "product"], [9, 13, "organisation"], [15, 16, "organisation"], [18, 18, "country"], [22, 26, "product"], [29, 30, "researcher"], [39, 39, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 13, 2, 4, "role", "introduces_to_market", true, false], [15, 16, 2, 4, "role", "introduces_to_market", true, false], [15, 16, 18, 18, "physical", "", false, false], [22, 26, 39, 39, "related-to", "sold_to", true, false], [29, 30, 22, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "first", "palletising", "robot", "was", "introduced", "in", "1963", "by", "Fuji", "Yusoki", "Kogyo", "Company", ".", "by", "KUKA", "robotics", "in", "Germany", ",", "while", "the", "universal", "programmable", "assembly", "machine", "was", "invented", "by", "Victor", "Scheinman", "in", "1976", "and", "the", "project", "was", "sold", "to", "Unimation", "."], "sentence-detokenized": "The first palletising robot was introduced in 1963 by Fuji Yusoki Kogyo Company. by KUKA robotics in Germany, while the universal programmable assembly machine was invented by Victor Scheinman in 1976 and the project was sold to Unimation.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 27], [28, 31], [32, 42], [43, 45], [46, 50], [51, 53], [54, 58], [59, 65], [66, 71], [72, 79], [79, 80], [81, 83], [84, 88], [89, 97], [98, 100], [101, 108], [108, 109], [110, 115], [116, 119], [120, 129], [130, 142], [143, 151], [152, 159], [160, 163], [164, 172], [173, 175], [176, 182], [183, 192], [193, 195], [196, 200], [201, 204], [205, 208], [209, 216], [217, 220], [221, 225], [226, 228], [229, 238], [238, 239]]}
{"doc_key": "ai-train-38", "ner": [[8, 8, "conference"], [10, 10, "researcher"], [17, 17, "field"], [32, 33, "researcher"], [40, 41, "researcher"], [54, 54, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 10, 8, 8, "role", "president_of", false, false], [10, 10, 32, 33, "role", "colleagues", false, false], [17, 17, 54, 54, "named", "same", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "mid-1990s", ",", "while", "president", "of", "the", "AAAI", ",", "Hayes", "began", "a", "series", "of", "attacks", "on", "AI", "critics", ",", "mostly", "couched", "in", "ironic", "terms", ",", "and", "(", "together", "with", "his", "colleague", "Kenneth", "Ford", ")", "invented", "a", "prize", "named", "after", "Simon", "Newcomb", "to", "be", "awarded", "to", "the", "most", "ridiculous", "argument", "refuting", "the", "possibility", "of", "AI", "."], "sentence-detokenized": "In the mid-1990s, while president of the AAAI, Hayes began a series of attacks on AI critics, mostly couched in ironic terms, and (together with his colleague Kenneth Ford) invented a prize named after Simon Newcomb to be awarded to the most ridiculous argument refuting the possibility of AI.", "token2charspan": [[0, 2], [3, 6], [7, 16], [16, 17], [18, 23], [24, 33], [34, 36], [37, 40], [41, 45], [45, 46], [47, 52], [53, 58], [59, 60], [61, 67], [68, 70], [71, 78], [79, 81], [82, 84], [85, 92], [92, 93], [94, 100], [101, 108], [109, 111], [112, 118], [119, 124], [124, 125], [126, 129], [130, 131], [131, 139], [140, 144], [145, 148], [149, 158], [159, 166], [167, 171], [171, 172], [173, 181], [182, 183], [184, 189], [190, 195], [196, 201], [202, 207], [208, 215], [216, 218], [219, 221], [222, 229], [230, 232], [233, 236], [237, 241], [242, 252], [253, 261], [262, 270], [271, 274], [275, 286], [287, 289], [290, 292], [292, 293]]}
{"doc_key": "ai-train-39", "ner": [[14, 16, "algorithm"], [40, 41, "algorithm"], [53, 57, "algorithm"], [59, 61, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 16, 40, 41, "named", "same", false, false], [53, 57, 14, 16, "type-of", "", false, false], [59, 61, 14, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["An", "optimal", "value", "for", "math", "\\", "alpha", "/", "math", "can", "be", "found", "using", "a", "linear", "search", "algorithm", ",", "i.e.", "the", "magnitude", "of", "math", "\\", "alpha", "/", "math", "is", "determined", "by", "finding", "the", "value", "that", "minimises", "S", ",", "usually", "using", "a", "linear", "search", "in", "the", "range", "math0", "\\", "alpha", "1", "/", "math", "or", "a", "backward", "linear", "search", "such", "as", "the", "Armijo", "linear", "search", "."], "sentence-detokenized": "An optimal value for math\\ alpha / math can be found using a linear search algorithm, i.e. the magnitude of math\\ alpha / math is determined by finding the value that minimises S, usually using a linear search in the range math0\\ alpha 1 / math or a backward linear search such as the Armijo linear search.", "token2charspan": [[0, 2], [3, 10], [11, 16], [17, 20], [21, 25], [25, 26], [27, 32], [33, 34], [35, 39], [40, 43], [44, 46], [47, 52], [53, 58], [59, 60], [61, 67], [68, 74], [75, 84], [84, 85], [86, 90], [91, 94], [95, 104], [105, 107], [108, 112], [112, 113], [114, 119], [120, 121], [122, 126], [127, 129], [130, 140], [141, 143], [144, 151], [152, 155], [156, 161], [162, 166], [167, 176], [177, 178], [178, 179], [180, 187], [188, 193], [194, 195], [196, 202], [203, 209], [210, 212], [213, 216], [217, 222], [223, 228], [228, 229], [230, 235], [236, 237], [238, 239], [240, 244], [245, 247], [248, 249], [250, 258], [259, 265], [266, 272], [273, 277], [278, 280], [281, 284], [285, 291], [292, 298], [299, 305], [305, 306]]}
{"doc_key": "ai-train-40", "ner": [[2, 9, "algorithm"], [6, 8, "algorithm"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "discusses", "Breadth", "-", "first", "and", "Depth", "-", "first", "search", "techniques", ",", "but", "ultimately", "concludes", "that", "the", "results", "represent", "expert", "systems", "that", "embody", "a", "lot", "of", "technical", "knowledge", ",", "but", "do", "not", "shed", "much", "light", "on", "the", "mental", "processes", "humans", "use", "to", "solve", "such", "puzzles", "."], "sentence-detokenized": "He discusses Breadth-first and Depth-first search techniques, but ultimately concludes that the results represent expert systems that embody a lot of technical knowledge, but do not shed much light on the mental processes humans use to solve such puzzles.", "token2charspan": [[0, 2], [3, 12], [13, 20], [20, 21], [21, 26], [27, 30], [31, 36], [36, 37], [37, 42], [43, 49], [50, 60], [60, 61], [62, 65], [66, 76], [77, 86], [87, 91], [92, 95], [96, 103], [104, 113], [114, 120], [121, 128], [129, 133], [134, 140], [141, 142], [143, 146], [147, 149], [150, 159], [160, 169], [169, 170], [171, 174], [175, 177], [178, 181], [182, 186], [187, 191], [192, 197], [198, 200], [201, 204], [205, 211], [212, 221], [222, 228], [229, 232], [233, 235], [236, 241], [242, 246], [247, 254], [254, 255]]}
{"doc_key": "ai-train-41", "ner": [[0, 3, "task"], [4, 4, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Speech", "recognition", "and", "speech", "synthesis", "deal", "with", "how", "spoken", "language", "can", "be", "understood", "or", "created", "with", "computers", "."], "sentence-detokenized": "Speech recognition and speech synthesis deal with how spoken language can be understood or created with computers.", "token2charspan": [[0, 6], [7, 18], [19, 22], [23, 29], [30, 39], [40, 44], [45, 49], [50, 53], [54, 60], [61, 69], [70, 73], [74, 76], [77, 87], [88, 90], [91, 98], [99, 103], [104, 113], [113, 114]]}
{"doc_key": "ai-train-42", "ner": [[15, 16, "algorithm"], [36, 37, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "math", "\\", "theta", "^", "{", "*}", "/", "mathematics", "is", "normally", "estimated", "using", "either", "a", "maximum", "likelihood", "procedure", "(", "math", "\\", "theta", "^", "{", "*}", "=\\", "theta", "^", "{", "ML", "}", "/", "mathematics", ")", "or", "a", "maximum", "positivity", "procedure", "(", "math", "\\", "theta", "^", "{", "*}", "=\\", "theta", "^", "{", "MAP", "}", "/", "mathematics", ")", "."], "sentence-detokenized": "This math\\ theta ^ {*} / mathematics is normally estimated using either a maximum likelihood procedure (math\\ theta ^ {*} =\\ theta ^ {ML} / mathematics) or a maximum positivity procedure (math\\ theta ^ {*} =\\ theta ^ {MAP} / mathematics).", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 16], [17, 18], [19, 20], [20, 22], [23, 24], [25, 36], [37, 39], [40, 48], [49, 58], [59, 64], [65, 71], [72, 73], [74, 81], [82, 92], [93, 102], [103, 104], [104, 108], [108, 109], [110, 115], [116, 117], [118, 119], [119, 121], [122, 124], [125, 130], [131, 132], [133, 134], [134, 136], [136, 137], [138, 139], [140, 151], [151, 152], [153, 155], [156, 157], [158, 165], [166, 176], [177, 186], [187, 188], [188, 192], [192, 193], [194, 199], [200, 201], [202, 203], [203, 205], [206, 208], [209, 214], [215, 216], [217, 218], [218, 221], [221, 222], [223, 224], [225, 236], [236, 237], [237, 238]]}
{"doc_key": "ai-train-43", "ner": [[10, 11, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "less", "widely", "spoken", "languages", "use", "the", "open", "-", "source", "eSpeak", "synthesiser", "for", "speech", ",", "producing", "an", "ungainly", ",", "robotic", "voice", "that", "can", "be", "difficult", "to", "understand", "."], "sentence-detokenized": "Some less widely spoken languages use the open-source eSpeak synthesiser for speech, producing an ungainly, robotic voice that can be difficult to understand.", "token2charspan": [[0, 4], [5, 9], [10, 16], [17, 23], [24, 33], [34, 37], [38, 41], [42, 46], [46, 47], [47, 53], [54, 60], [61, 72], [73, 76], [77, 83], [83, 84], [85, 94], [95, 97], [98, 106], [106, 107], [108, 115], [116, 121], [122, 126], [127, 130], [131, 133], [134, 143], [144, 146], [147, 157], [157, 158]]}
{"doc_key": "ai-train-44", "ner": [[19, 19, "programlang"], [35, 36, "programlang"], [38, 38, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 19, 35, 36, "compare", "", false, false], [19, 19, 38, 38, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Although", "mainly", "used", "by", "statisticians", "and", "other", "professionals", "who", "need", "an", "environment", "for", "statistical", "calculation", "and", "software", "development", ",", "R", "can", "also", "function", "as", "a", "general", "toolbox", "for", "matrix", "calculation", ",", "with", "performance", "comparable", "to", "GNU", "Octave", "or", "MATLAB", "."], "sentence-detokenized": "Although mainly used by statisticians and other professionals who need an environment for statistical calculation and software development, R can also function as a general toolbox for matrix calculation, with performance comparable to GNU Octave or MATLAB.", "token2charspan": [[0, 8], [9, 15], [16, 20], [21, 23], [24, 37], [38, 41], [42, 47], [48, 61], [62, 65], [66, 70], [71, 73], [74, 85], [86, 89], [90, 101], [102, 113], [114, 117], [118, 126], [127, 138], [138, 139], [140, 141], [142, 145], [146, 150], [151, 159], [160, 162], [163, 164], [165, 172], [173, 180], [181, 184], [185, 191], [192, 203], [203, 204], [205, 209], [210, 221], [222, 232], [233, 235], [236, 239], [240, 246], [247, 249], [250, 256], [256, 257]]}
{"doc_key": "ai-train-45", "ner": [[0, 0, "algorithm"], [3, 4, "field"], [8, 11, "misc"], [12, 13, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 4, "part-of", "", false, false], [0, 0, 12, 13, "origin", "", false, false], [8, 11, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Heterodirection", "is", "a", "signal", "processing", "technique", "invented", "by", "Canadian", "inventor", "-", "engineer", "Reginald", "Fessenden", "that", "creates", "new", "frequencies", "by", "combining", "two", "frequencies", "."], "sentence-detokenized": "Heterodirection is a signal processing technique invented by Canadian inventor-engineer Reginald Fessenden that creates new frequencies by combining two frequencies.", "token2charspan": [[0, 15], [16, 18], [19, 20], [21, 27], [28, 38], [39, 48], [49, 57], [58, 60], [61, 69], [70, 78], [78, 79], [79, 87], [88, 96], [97, 106], [107, 111], [112, 119], [120, 123], [124, 135], [136, 138], [139, 148], [149, 152], [153, 164], [164, 165]]}
{"doc_key": "ai-train-46", "ner": [[14, 16, "person"], [18, 18, "misc"], [22, 24, "organisation"], [27, 27, "organisation"], [29, 31, "misc"], [33, 34, "person"], [36, 36, "organisation"], [38, 40, "misc"], [42, 43, "person"], [45, 46, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[14, 16, 18, 18, "role", "actor_in", false, false], [18, 18, 22, 24, "artifact", "", false, false], [29, 31, 27, 27, "artifact", "", false, false], [33, 34, 29, 31, "role", "actor_in", false, false], [38, 40, 36, 36, "artifact", "", false, false], [42, 43, 38, 40, "role", "actor_in", false, false], [45, 46, 38, 40, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Several", "other", "films", "that", "helped", "put", "3D", "back", "on", "the", "map", "that", "month", "were", "John", "Wayne", "'s", "film", "Hondo", "(", "distributed", "by", "Warner", "Bros", ".", ")", ",", "Columbia", "'s", "Miss", "Sadie", "Thompson", "with", "Rita", "Hayworth", "and", "Paramount", "'s", "Money", "From", "Home", "with", "Dean", "Martin", "and", "Jerry", "Lewis", "."], "sentence-detokenized": "Several other films that helped put 3D back on the map that month were John Wayne's film Hondo (distributed by Warner Bros. ), Columbia's Miss Sadie Thompson with Rita Hayworth and Paramount's Money From Home with Dean Martin and Jerry Lewis.", "token2charspan": [[0, 7], [8, 13], [14, 19], [20, 24], [25, 31], [32, 35], [36, 38], [39, 43], [44, 46], [47, 50], [51, 54], [55, 59], [60, 65], [66, 70], [71, 75], [76, 81], [81, 83], [84, 88], [89, 94], [95, 96], [96, 107], [108, 110], [111, 117], [118, 122], [122, 123], [124, 125], [125, 126], [127, 135], [135, 137], [138, 142], [143, 148], [149, 157], [158, 162], [163, 167], [168, 176], [177, 180], [181, 190], [190, 192], [193, 198], [199, 203], [204, 208], [209, 213], [214, 218], [219, 225], [226, 229], [230, 235], [236, 241], [241, 242]]}
{"doc_key": "ai-train-47", "ner": [[0, 0, "product"], [3, 4, "field"], [5, 6, "task"], [11, 11, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "general-affiliation", "", false, false], [0, 0, 11, 11, "artifact", "", false, false], [5, 6, 3, 4, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["DeepFace", "is", "a", "deep", "learning", "facial", "recognition", "system", "created", "by", "a", "Facebook", "research", "group", "."], "sentence-detokenized": "DeepFace is a deep learning facial recognition system created by a Facebook research group.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 18], [19, 27], [28, 34], [35, 46], [47, 53], [54, 61], [62, 64], [65, 66], [67, 75], [76, 84], [85, 90], [90, 91]]}
{"doc_key": "ai-train-48", "ner": [[0, 3, "field"], [8, 8, "conference"], [13, 14, "field"], [24, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 13, 14, "part-of", "subfield", false, false], [8, 8, 0, 3, "topic", "", false, false], [24, 26, 0, 3, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Geometry", "processing", "is", "a", "common", "research", "topic", "at", "SIGGRAPH", ",", "the", "leading", "academic", "computer", "graphics", "conference", ",", "and", "the", "main", "topic", "of", "the", "annual", "Geometry", "Processing", "Symposium", "."], "sentence-detokenized": "Geometry processing is a common research topic at SIGGRAPH, the leading academic computer graphics conference, and the main topic of the annual Geometry Processing Symposium.", "token2charspan": [[0, 8], [9, 19], [20, 22], [23, 24], [25, 31], [32, 40], [41, 46], [47, 49], [50, 58], [58, 59], [60, 63], [64, 71], [72, 80], [81, 89], [90, 98], [99, 109], [109, 110], [111, 114], [115, 118], [119, 123], [124, 129], [130, 132], [133, 136], [137, 143], [144, 152], [153, 163], [164, 173], [173, 174]]}
{"doc_key": "ai-train-49", "ner": [[0, 1, "task"], [3, 4, "task"], [13, 15, "algorithm"], [17, 17, "algorithm"], [20, 22, "algorithm"], [24, 24, "algorithm"], [27, 29, "algorithm"], [31, 31, "algorithm"], [35, 35, "misc"], [42, 44, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[13, 15, 35, 35, "general-affiliation", "", false, false], [17, 17, 13, 15, "named", "", false, false], [20, 22, 35, 35, "general-affiliation", "", false, false], [24, 24, 20, 22, "named", "", false, false], [27, 29, 35, 35, "general-affiliation", "", false, false], [31, 31, 27, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Feature", "extraction", "and", "dimension", "reduction", "can", "be", "combined", "in", "a", "single", "step", "using", "principal", "component", "analysis", "(", "PCA", ")", ",", "linear", "discriminant", "analysis", "(", "LDA", ")", "or", "canonical", "correlation", "analysis", "(", "CCA", ")", "as", "a", "pre-processing", "step", ",", "followed", "by", "clustering", "using", "k", "-", "NN", "on", "the", "feature", "vectors", "in", "dimension", "-", "reduced", "space", "."], "sentence-detokenized": "Feature extraction and dimension reduction can be combined in a single step using principal component analysis (PCA), linear discriminant analysis (LDA) or canonical correlation analysis (CCA) as a pre-processing step, followed by clustering using k-NN on the feature vectors in dimension-reduced space.", "token2charspan": [[0, 7], [8, 18], [19, 22], [23, 32], [33, 42], [43, 46], [47, 49], [50, 58], [59, 61], [62, 63], [64, 70], [71, 75], [76, 81], [82, 91], [92, 101], [102, 110], [111, 112], [112, 115], [115, 116], [116, 117], [118, 124], [125, 137], [138, 146], [147, 148], [148, 151], [151, 152], [153, 155], [156, 165], [166, 177], [178, 186], [187, 188], [188, 191], [191, 192], [193, 195], [196, 197], [198, 212], [213, 217], [217, 218], [219, 227], [228, 230], [231, 241], [242, 247], [248, 249], [249, 250], [250, 252], [253, 255], [256, 259], [260, 267], [268, 275], [276, 278], [279, 288], [288, 289], [289, 296], [297, 302], [302, 303]]}
{"doc_key": "ai-train-50", "ner": [[0, 2, "algorithm"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 10, "related-to", "good_at", true, false], [0, 2, 12, 13, "related-to", "good_at", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Artificial", "neural", "networks", "are", "computational", "models", "that", "excel", "in", "machine", "learning", "and", "pattern", "recognition", "."], "sentence-detokenized": "Artificial neural networks are computational models that excel in machine learning and pattern recognition.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 30], [31, 44], [45, 51], [52, 56], [57, 62], [63, 65], [66, 73], [74, 82], [83, 86], [87, 94], [95, 106], [106, 107]]}
{"doc_key": "ai-train-51", "ner": [[1, 2, "researcher"], [4, 5, "researcher"], [7, 11, "misc"], [13, 17, "conference"], [19, 19, "conference"], [37, 40, "algorithm"], [41, 42, "researcher"], [44, 46, "researcher"], [48, 54, "misc"], [56, 65, "conference"], [67, 67, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[7, 11, 1, 2, "artifact", "", false, false], [7, 11, 4, 5, "artifact", "", false, false], [7, 11, 13, 17, "temporal", "", false, false], [19, 19, 13, 17, "named", "", false, false], [48, 54, 37, 40, "topic", "", false, false], [48, 54, 41, 42, "artifact", "", false, false], [48, 54, 44, 46, "artifact", "", false, false], [48, 54, 56, 65, "temporal", "", false, false], [67, 67, 56, 65, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": [",", "C.", "Papageorgiou", "and", "T.", "Poggio", ",", "A", "Trainable", "Pedestrian", "Detection", "system", ",", "International", "Journal", "of", "Computer", "Vision", "(", "IJCV", ")", ",", "pages", "1", ":", "15", "-", "33", ",", "2000", "others", "use", "local", "features", "such", "as", "the", "histogram", "of", "oriented", "gradients", "N.", "Dalal", ",", "B", ".", "Triggs", ",", "Histograms", "of", "oriented", "gradients", "for", "human", "detection", ",", "IEEE", "Computer", "Society", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", ",", "pages", "1", ":", "886-893", ",", "2005", "descriptors", "."], "sentence-detokenized": ", C. Papageorgiou and T. Poggio, A Trainable Pedestrian Detection system, International Journal of Computer Vision (IJCV), pages 1: 15-33, 2000 others use local features such as the histogram of oriented gradients N. Dalal, B. Triggs, Histograms of oriented gradients for human detection, IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), pages 1: 886-893, 2005 descriptors.", "token2charspan": [[0, 1], [2, 4], [5, 17], [18, 21], [22, 24], [25, 31], [31, 32], [33, 34], [35, 44], [45, 55], [56, 65], [66, 72], [72, 73], [74, 87], [88, 95], [96, 98], [99, 107], [108, 114], [115, 116], [116, 120], [120, 121], [121, 122], [123, 128], [129, 130], [130, 131], [132, 134], [134, 135], [135, 137], [137, 138], [139, 143], [144, 150], [151, 154], [155, 160], [161, 169], [170, 174], [175, 177], [178, 181], [182, 191], [192, 194], [195, 203], [204, 213], [214, 216], [217, 222], [222, 223], [224, 225], [225, 226], [227, 233], [233, 234], [235, 245], [246, 248], [249, 257], [258, 267], [268, 271], [272, 277], [278, 287], [287, 288], [289, 293], [294, 302], [303, 310], [311, 321], [322, 324], [325, 333], [334, 340], [341, 344], [345, 352], [353, 364], [365, 366], [366, 370], [370, 371], [371, 372], [373, 378], [379, 380], [380, 381], [382, 389], [389, 390], [391, 395], [396, 407], [407, 408]]}
{"doc_key": "ai-train-52", "ner": [[1, 1, "algorithm"], [6, 8, "algorithm"], [12, 14, "task"], [15, 15, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 6, 8, "type-of", "", false, false], [12, 14, 1, 1, "usage", "", true, false], [12, 14, 15, 15, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["An", "autoencoder", "is", "a", "type", "of", "artificial", "neural", "network", "used", "for", "learning", "functions", "in", "an", "unsupervised", "manner", "."], "sentence-detokenized": "An autoencoder is a type of artificial neural network used for learning functions in an unsupervised manner.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 19], [20, 24], [25, 27], [28, 38], [39, 45], [46, 53], [54, 58], [59, 62], [63, 71], [72, 81], [82, 84], [85, 87], [88, 100], [101, 107], [107, 108]]}
{"doc_key": "ai-train-53", "ner": [[0, 0, "researcher"], [6, 7, "organisation"], [11, 12, "field"], [14, 17, "field"], [21, 23, "organisation"], [27, 27, "organisation"], [24, 34, "field"], [36, 37, "field"], [44, 44, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 6, 7, "role", "fellow_of", false, false], [0, 0, 11, 12, "related-to", "contributes_to", false, false], [0, 0, 14, 17, "related-to", "contributes_to", false, false], [0, 0, 21, 23, "role", "fellow_of", false, false], [0, 0, 24, 34, "related-to", "contributes_to", false, false], [0, 0, 36, 37, "related-to", "contributes_to", false, false], [27, 27, 21, 23, "named", "", false, false], [44, 44, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Haralick", "is", "a", "Fellow", "of", "the", "IEEE", "for", "his", "contributions", "in", "computer", "vision", "and", "image", "processing", "and", "a", "Fellow", "of", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", "for", "his", "contributions", "in", "pattern", "recognition", ",", "image", "processing", "and", "for", "his", "service", "to", "the", "IAPR", "."], "sentence-detokenized": "Haralick is a Fellow of the IEEE for his contributions in computer vision and image processing and a Fellow of the International Association for Pattern Recognition (IAPR) for his contributions in pattern recognition, image processing and for his service to the IAPR.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 20], [21, 23], [24, 27], [28, 32], [33, 36], [37, 40], [41, 54], [55, 57], [58, 66], [67, 73], [74, 77], [78, 83], [84, 94], [95, 98], [99, 100], [101, 107], [108, 110], [111, 114], [115, 128], [129, 140], [141, 144], [145, 152], [153, 164], [165, 166], [166, 170], [170, 171], [172, 175], [176, 179], [180, 193], [194, 196], [197, 204], [205, 216], [216, 217], [218, 223], [224, 234], [235, 238], [239, 242], [243, 246], [247, 254], [255, 257], [258, 261], [262, 266], [266, 267]]}
{"doc_key": "ai-train-54", "ner": [[4, 10, "task"], [16, 18, "algorithm"], [20, 20, "algorithm"], [25, 26, "researcher"], [28, 29, "organisation"], [31, 32, "researcher"], [35, 37, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 10, 16, 18, "usage", "", false, false], [16, 18, 25, 26, "origin", "", true, false], [16, 18, 31, 32, "origin", "", true, false], [20, 20, 16, 18, "named", "", false, false], [25, 26, 28, 29, "physical", "", false, false], [25, 26, 28, 29, "role", "", false, false], [31, 32, 35, 37, "physical", "", false, false], [31, 32, 35, 37, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "first", "attempt", "at", "end", "-", "to", "-", "end", "ASR", "was", "that", "of", "systems", "based", "on", "Connectionist", "Temporal", "Classification", "(", "CTC", ")", ",", "introduced", "by", "Alex", "Graves", "of", "Google", "DeepMind", "and", "Navdeep", "Jaitly", "of", "the", "University", "of", "Toronto", "in", "2014", "."], "sentence-detokenized": "The first attempt at end-to-end ASR was that of systems based on Connectionist Temporal Classification (CTC), introduced by Alex Graves of Google DeepMind and Navdeep Jaitly of the University of Toronto in 2014.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 20], [21, 24], [24, 25], [25, 27], [27, 28], [28, 31], [32, 35], [36, 39], [40, 44], [45, 47], [48, 55], [56, 61], [62, 64], [65, 78], [79, 87], [88, 102], [103, 104], [104, 107], [107, 108], [108, 109], [110, 120], [121, 123], [124, 128], [129, 135], [136, 138], [139, 145], [146, 154], [155, 158], [159, 166], [167, 173], [174, 176], [177, 180], [181, 191], [192, 194], [195, 202], [203, 205], [206, 210], [210, 211]]}
{"doc_key": "ai-train-55", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "algorithm"], [13, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 0, 2, "named", "", false, false], [10, 11, 0, 2, "type-of", "", false, false], [13, 13, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Linear-", "fractional", "programming", "(", "LFP", ")", "is", "a", "generalisation", "of", "linear", "programming", "(", "LP", ")", "."], "sentence-detokenized": "Linear-fractional programming (LFP) is a generalisation of linear programming (LP).", "token2charspan": [[0, 7], [7, 17], [18, 29], [30, 31], [31, 34], [34, 35], [36, 38], [39, 40], [41, 55], [56, 58], [59, 65], [66, 77], [78, 79], [79, 81], [81, 82], [82, 83]]}
{"doc_key": "ai-train-56", "ner": [[0, 0, "researcher"], [8, 13, "misc"], [16, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 13, "win-defeat", "", false, false], [8, 13, 16, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lafferty", "has", "received", "numerous", "awards", ",", "including", "two", "Test", "-", "of", "-", "Time", "awards", "at", "the", "2011", "and", "2012", "International", "Conference", "on", "Machine", "Learning", ","], "sentence-detokenized": "Lafferty has received numerous awards, including two Test-of-Time awards at the 2011 and 2012 International Conference on Machine Learning,", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 30], [31, 37], [37, 38], [39, 48], [49, 52], [53, 57], [57, 58], [58, 60], [60, 61], [61, 65], [66, 72], [73, 75], [76, 79], [80, 84], [85, 88], [89, 93], [94, 107], [108, 118], [119, 121], [122, 129], [130, 138], [138, 139]]}
{"doc_key": "ai-train-57", "ner": [[10, 10, "product"], [12, 12, "programlang"], [24, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["With", "the", "advent", "of", "component", "-", "based", "frameworks", "such", "as", ".NET", "and", "Java", ",", "component", "-", "based", "development", "environments", "are", "able", "to", "distribute", "the", "neural", "network", "developed", "in", "these", "frameworks", "as", "inheritable", "components", "."], "sentence-detokenized": "With the advent of component-based frameworks such as .NET and Java, component-based development environments are able to distribute the neural network developed in these frameworks as inheritable components.", "token2charspan": [[0, 4], [5, 8], [9, 15], [16, 18], [19, 28], [28, 29], [29, 34], [35, 45], [46, 50], [51, 53], [54, 58], [59, 62], [63, 67], [67, 68], [69, 78], [78, 79], [79, 84], [85, 96], [97, 109], [110, 113], [114, 118], [119, 121], [122, 132], [133, 136], [137, 143], [144, 151], [152, 161], [162, 164], [165, 170], [171, 181], [182, 184], [185, 196], [197, 207], [207, 208]]}
{"doc_key": "ai-train-58", "ner": [[5, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "in", "the", "case", "of", "BLEU", ",", "the", "basic", "unit", "of", "evaluation", "is", "the", "sentence", ";", "the", "algorithm", "first", "creates", "an", "alignment", "(", "see", "illustrations", ")", "between", "two", "sentences", ",", "the", "candidate", "translation", "string", "and", "the", "reference", "translation", "string", "."], "sentence-detokenized": "As in the case of BLEU, the basic unit of evaluation is the sentence; the algorithm first creates an alignment (see illustrations) between two sentences, the candidate translation string and the reference translation string.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 14], [15, 17], [18, 22], [22, 23], [24, 27], [28, 33], [34, 38], [39, 41], [42, 52], [53, 55], [56, 59], [60, 68], [68, 69], [70, 73], [74, 83], [84, 89], [90, 97], [98, 100], [101, 110], [111, 112], [112, 115], [116, 129], [129, 130], [131, 138], [139, 142], [143, 152], [152, 153], [154, 157], [158, 167], [168, 179], [180, 186], [187, 190], [191, 194], [195, 204], [205, 216], [217, 223], [223, 224]]}
{"doc_key": "ai-train-59", "ner": [[6, 12, "conference"], [21, 21, "task"], [23, 24, "task"], [28, 29, "metrics"], [31, 37, "metrics"], [42, 45, "conference"], [47, 47, "conference"], [50, 50, "location"], [52, 52, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 12, 21, 21, "related-to", "subject_at", false, false], [6, 12, 23, 24, "related-to", "subject_at", false, false], [28, 29, 6, 12, "temporal", "", false, false], [31, 37, 28, 29, "named", "", true, false], [47, 47, 42, 45, "named", "", false, false], [50, 50, 52, 52, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["One", "of", "the", "metrics", "used", "at", "NIST", "'s", "annual", "conferences", "on", "document", "understanding", ",", "where", "research", "groups", "present", "their", "systems", "for", "summarisation", "and", "translation", "tasks", ",", "is", "the", "ROUGE", "metric", "(", "Recall", "-", "Oriented", "Understudy", "for", "Gisting", "Evaluation", ",", "In", "Advances", "of", "Neural", "Information", "Processing", "Systems", "(", "NIPS", ")", ",", "Montreal", ",", "Canada", ",", "December", "-", "2014", "."], "sentence-detokenized": "One of the metrics used at NIST's annual conferences on document understanding, where research groups present their systems for summarisation and translation tasks, is the ROUGE metric (Recall-Oriented Understudy for Gisting Evaluation, In Advances of Neural Information Processing Systems (NIPS), Montreal, Canada, December - 2014.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 18], [19, 23], [24, 26], [27, 31], [31, 33], [34, 40], [41, 52], [53, 55], [56, 64], [65, 78], [78, 79], [80, 85], [86, 94], [95, 101], [102, 109], [110, 115], [116, 123], [124, 127], [128, 141], [142, 145], [146, 157], [158, 163], [163, 164], [165, 167], [168, 171], [172, 177], [178, 184], [185, 186], [186, 192], [192, 193], [193, 201], [202, 212], [213, 216], [217, 224], [225, 235], [235, 236], [237, 239], [240, 248], [249, 251], [252, 258], [259, 270], [271, 281], [282, 289], [290, 291], [291, 295], [295, 296], [296, 297], [298, 306], [306, 307], [308, 314], [314, 315], [316, 324], [325, 326], [327, 331], [331, 332]]}
{"doc_key": "ai-train-60", "ner": [[7, 7, "programlang"], [9, 9, "product"], [11, 12, "programlang"], [16, 16, "product"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 7, 11, 12, "type-of", "", false, false], [7, 7, 22, 22, "named", "", false, false], [9, 9, 11, 12, "part-of", "", false, false], [9, 9, 16, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Same", "implementation", ",", "to", "be", "executed", "in", "Java", "with", "JShell", "(", "Java", "9", "minimum", ")", ":", "codejshell", "scriptfile", "/", "codesyntaxhighlight", "lang", "=", "java"], "sentence-detokenized": "Same implementation, to be executed in Java with JShell (Java 9 minimum): codejshell scriptfile / codesyntaxhighlight lang = java", "token2charspan": [[0, 4], [5, 19], [19, 20], [21, 23], [24, 26], [27, 35], [36, 38], [39, 43], [44, 48], [49, 55], [56, 57], [57, 61], [62, 63], [64, 71], [71, 72], [72, 73], [74, 84], [85, 95], [96, 97], [98, 117], [118, 122], [123, 124], [125, 129]]}
{"doc_key": "ai-train-61", "ner": [[0, 3, "metrics"], [7, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 7, 8, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "NIST", "metric", "is", "based", "on", "the", "BLEU", "metric", ",", "but", "with", "some", "modifications", "."], "sentence-detokenized": "The NIST metric is based on the BLEU metric, but with some modifications.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 18], [19, 24], [25, 27], [28, 31], [32, 36], [37, 43], [43, 44], [45, 48], [49, 53], [54, 58], [59, 72], [72, 73]]}
{"doc_key": "ai-train-62", "ner": [[8, 8, "country"], [14, 14, "university"], [17, 19, "university"], [26, 27, "product"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 14, 8, 8, "physical", "", false, false], [17, 19, 8, 8, "physical", "", false, false], [26, 27, 14, 14, "origin", "", false, false], [26, 27, 17, 19, "origin", "", false, false], [26, 27, 31, 32, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["At", "the", "end", "of", "the", "1980s", ",", "two", "Dutch", "universities", ",", "the", "University", "of", "Groningen", "and", "the", "University", "of", "Twente", ",", "started", "a", "joint", "project", "called", "Knowledge", "Graphs", ",", "which", "are", "semantic", "networks", ",", "but", "with", "the", "additional", "constraint", "that", "the", "edges", "must", "belong", "to", "a", "limited", "set", "of", "possible", "relations", ",", "to", "facilitate", "algebras", "on", "the", "graph", "."], "sentence-detokenized": "At the end of the 1980s, two Dutch universities, the University of Groningen and the University of Twente, started a joint project called Knowledge Graphs, which are semantic networks, but with the additional constraint that the edges must belong to a limited set of possible relations, to facilitate algebras on the graph.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 17], [18, 23], [23, 24], [25, 28], [29, 34], [35, 47], [47, 48], [49, 52], [53, 63], [64, 66], [67, 76], [77, 80], [81, 84], [85, 95], [96, 98], [99, 105], [105, 106], [107, 114], [115, 116], [117, 122], [123, 130], [131, 137], [138, 147], [148, 154], [154, 155], [156, 161], [162, 165], [166, 174], [175, 183], [183, 184], [185, 188], [189, 193], [194, 197], [198, 208], [209, 219], [220, 224], [225, 228], [229, 234], [235, 239], [240, 246], [247, 249], [250, 251], [252, 259], [260, 263], [264, 266], [267, 275], [276, 285], [285, 286], [287, 289], [290, 300], [301, 309], [310, 312], [313, 316], [317, 322], [322, 323]]}
{"doc_key": "ai-train-63", "ner": [[0, 2, "product"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Grammar", "correctors", "are", "often", "implemented", "as", "a", "feature", "of", "a", "larger", "programme", ",", "such", "as", "a", "word", "processor", ",", "but", "are", "also", "available", "as", "a", "stand", "-", "alone", "application", "that", "can", "be", "activated", "within", "programmes", "that", "work", "with", "editable", "text", "."], "sentence-detokenized": "Grammar correctors are often implemented as a feature of a larger programme, such as a word processor, but are also available as a stand-alone application that can be activated within programmes that work with editable text.", "token2charspan": [[0, 7], [8, 18], [19, 22], [23, 28], [29, 40], [41, 43], [44, 45], [46, 53], [54, 56], [57, 58], [59, 65], [66, 75], [75, 76], [77, 81], [82, 84], [85, 86], [87, 91], [92, 101], [101, 102], [103, 106], [107, 110], [111, 115], [116, 125], [126, 128], [129, 130], [131, 136], [136, 137], [137, 142], [143, 154], [155, 159], [160, 163], [164, 166], [167, 176], [177, 183], [184, 194], [195, 199], [200, 204], [205, 209], [210, 218], [219, 223], [223, 224]]}
{"doc_key": "ai-train-64", "ner": [[6, 12, "organisation"], [8, 20, "conference"], [23, 25, "organisation"], [33, 35, "conference"], [38, 39, "conference"], [41, 43, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "the", "Association", "for", "the", "Advancement", "Artificial", "Intelligence", "and", "the", "Cognitive", "Science", "Society", ",", "as", "well", "as", "an", "editor", "of", "J.", "Automated", "Reasoning", ",", "J.", "Learning", "Sciences", "and", "J.", "Applied", "Ontology", "."], "sentence-detokenized": "He is a member of the American Association for the Advancement of Science, the Association for the Advancement Artificial Intelligence and the Cognitive Science Society, as well as an editor of J. Automated Reasoning, J. Learning Sciences and J. Applied Ontology.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 42], [43, 46], [47, 50], [51, 62], [63, 65], [66, 73], [73, 74], [75, 78], [79, 90], [91, 94], [95, 98], [99, 110], [111, 121], [122, 134], [135, 138], [139, 142], [143, 152], [153, 160], [161, 168], [168, 169], [170, 172], [173, 177], [178, 180], [181, 183], [184, 190], [191, 193], [194, 196], [197, 206], [207, 216], [216, 217], [218, 220], [221, 229], [230, 238], [239, 242], [243, 245], [246, 253], [254, 262], [262, 263]]}
{"doc_key": "ai-train-65", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "task"], [20, 21, "researcher"], [23, 24, "university"], [26, 27, "researcher"], [29, 32, "organisation"], [34, 34, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 10, 11, "type-of", "", false, false], [0, 2, 20, 21, "origin", "", false, false], [0, 2, 26, 27, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [20, 21, 23, 24, "physical", "", false, false], [20, 21, 23, 24, "role", "", false, false], [26, 27, 29, 32, "role", "", false, false], [34, 34, 29, 32, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", ",", "a", "form", "of", "speech", "coding", ",", "began", "to", "develop", "with", "the", "work", "of", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", "."], "sentence-detokenized": "Linear predictive coding (LPC), a form of speech coding, began to develop with the work of Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 38], [39, 41], [42, 48], [49, 55], [55, 56], [57, 62], [63, 65], [66, 73], [74, 78], [79, 82], [83, 87], [88, 90], [91, 99], [100, 107], [108, 110], [111, 117], [118, 128], [129, 132], [133, 138], [139, 144], [145, 147], [148, 154], [155, 164], [165, 168], [169, 178], [179, 180], [180, 183], [183, 184], [185, 187], [188, 192], [192, 193]]}
{"doc_key": "ai-train-66", "ner": [[55, 57, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "signal", "is", "further", "ergodic", ",", "all", "sampling", "paths", "have", "the", "same", "time", "average", "and", "thus", "mathR", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "\\", "tau", ")", "=\\", "widehat", "{", "R", "}", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "\\", "tau", ")", "/", "math", "in", "the", "mean", "square", "error", "sense", "."], "sentence-detokenized": "If the signal is further ergodic, all sampling paths have the same time average and thus mathR _ x ^ {n / T _ 0} (\\ tau) =\\ widehat {R} _ x ^ {n / T _ 0} (\\ tau) / math in the mean square error sense.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 24], [25, 32], [32, 33], [34, 37], [38, 46], [47, 52], [53, 57], [58, 61], [62, 66], [67, 71], [72, 79], [80, 83], [84, 88], [89, 94], [95, 96], [97, 98], [99, 100], [101, 102], [102, 103], [104, 105], [106, 107], [108, 109], [110, 111], [111, 112], [113, 114], [114, 115], [116, 119], [119, 120], [121, 123], [124, 131], [132, 133], [133, 134], [134, 135], [136, 137], [138, 139], [140, 141], [142, 143], [143, 144], [145, 146], [147, 148], [149, 150], [151, 152], [152, 153], [154, 155], [155, 156], [157, 160], [160, 161], [162, 163], [164, 168], [169, 171], [172, 175], [176, 180], [181, 187], [188, 193], [194, 199], [199, 200]]}
{"doc_key": "ai-train-67", "ner": [[0, 1, "task"], [3, 4, "task"], [13, 15, "algorithm"], [17, 17, "algorithm"], [20, 22, "algorithm"], [24, 24, "algorithm"], [27, 29, "algorithm"], [31, 31, "algorithm"], [34, 36, "algorithm"], [38, 38, "algorithm"], [43, 44, "misc"], [48, 50, "algorithm"], [54, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[13, 15, 43, 44, "related-to", "", false, false], [17, 17, 13, 15, "named", "", false, false], [20, 22, 43, 44, "related-to", "", false, false], [24, 24, 20, 22, "named", "", false, false], [27, 29, 43, 44, "related-to", "", false, false], [31, 31, 27, 29, "named", "", false, false], [34, 36, 43, 44, "related-to", "", false, false], [38, 38, 34, 36, "named", "", false, false], [48, 50, 54, 55, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Feature", "extraction", "and", "dimensionality", "reduction", "can", "be", "combined", "in", "a", "single", "step", "using", "principal", "component", "analysis", "(", "PCA", ")", ",", "linear", "discriminant", "analysis", "(", "LDA", ")", ",", "canonical", "correlation", "analysis", "(", "CCA", ")", "or", "non-negative", "matrix", "factorisation", "(", "NMF", ")", "techniques", "as", "a", "pre-processing", "step", ",", "followed", "by", "K", "-", "NN", "clustering", "on", "the", "feature", "vectors", "in", "the", "reduced-dimensional", "space", "."], "sentence-detokenized": "Feature extraction and dimensionality reduction can be combined in a single step using principal component analysis (PCA), linear discriminant analysis (LDA), canonical correlation analysis (CCA) or non-negative matrix factorisation (NMF) techniques as a pre-processing step, followed by K-NN clustering on the feature vectors in the reduced-dimensional space.", "token2charspan": [[0, 7], [8, 18], [19, 22], [23, 37], [38, 47], [48, 51], [52, 54], [55, 63], [64, 66], [67, 68], [69, 75], [76, 80], [81, 86], [87, 96], [97, 106], [107, 115], [116, 117], [117, 120], [120, 121], [121, 122], [123, 129], [130, 142], [143, 151], [152, 153], [153, 156], [156, 157], [157, 158], [159, 168], [169, 180], [181, 189], [190, 191], [191, 194], [194, 195], [196, 198], [199, 211], [212, 218], [219, 232], [233, 234], [234, 237], [237, 238], [239, 249], [250, 252], [253, 254], [255, 269], [270, 274], [274, 275], [276, 284], [285, 287], [288, 289], [289, 290], [290, 292], [293, 303], [304, 306], [307, 310], [311, 318], [319, 326], [327, 329], [330, 333], [334, 353], [354, 359], [359, 360]]}
{"doc_key": "ai-train-68", "ner": [[3, 3, "programlang"], [5, 5, "programlang"], [7, 7, "programlang"], [9, 9, "programlang"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 16, 3, 3, "related-to", "program_type_compatible_with", false, false], [16, 16, 5, 5, "related-to", "program_type_compatible_with", false, false], [16, 16, 7, 7, "related-to", "program_type_compatible_with", false, false], [16, 16, 9, 9, "related-to", "program_type_compatible_with", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Libraries", "written", "in", "Perl", ",", "Java", ",", "ActiveX", "or", ".NET", "can", "be", "called", "up", "directly", "from", "MATLAB", ","], "sentence-detokenized": "Libraries written in Perl, Java, ActiveX or .NET can be called up directly from MATLAB,", "token2charspan": [[0, 9], [10, 17], [18, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 40], [41, 43], [44, 48], [49, 52], [53, 55], [56, 62], [63, 65], [66, 74], [75, 79], [80, 86], [86, 87]]}
{"doc_key": "ai-train-69", "ner": [[3, 9, "task"], [13, 13, "task"], [32, 33, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 9, 13, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "task", "of", "recognising", "the", "named", "entities", "in", "the", "text", "is", "Named", "Entity", "Recognition", ",", "while", "the", "task", "of", "determining", "the", "identity", "of", "the", "named", "entities", "mentioned", "in", "the", "text", "is", "called", "Entity", "Linking", "."], "sentence-detokenized": "The task of recognising the named entities in the text is Named Entity Recognition, while the task of determining the identity of the named entities mentioned in the text is called Entity Linking.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 23], [24, 27], [28, 33], [34, 42], [43, 45], [46, 49], [50, 54], [55, 57], [58, 63], [64, 70], [71, 82], [82, 83], [84, 89], [90, 93], [94, 98], [99, 101], [102, 113], [114, 117], [118, 126], [127, 129], [130, 133], [134, 139], [140, 148], [149, 158], [159, 161], [162, 165], [166, 170], [171, 173], [174, 180], [181, 187], [188, 195], [195, 196]]}
{"doc_key": "ai-train-70", "ner": [[1, 1, "algorithm"], [26, 26, "programlang"], [29, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 29, 32, "part-of", "", true, false], [29, 32, 26, 26, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "sigmoid", "functions", "and", "derivatives", "used", "in", "the", "package", "were", "originally", "included", "in", "the", "package", ",", "but", "since", "version", "0.8.0", "have", "been", "released", "in", "a", "separate", "R", "package", ",", "sigmoid", ",", "with", "the", "intention", "of", "enabling", "more", "general", "use", "."], "sentence-detokenized": "The sigmoid functions and derivatives used in the package were originally included in the package, but since version 0.8.0 have been released in a separate R package, sigmoid, with the intention of enabling more general use.", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 25], [26, 37], [38, 42], [43, 45], [46, 49], [50, 57], [58, 62], [63, 73], [74, 82], [83, 85], [86, 89], [90, 97], [97, 98], [99, 102], [103, 108], [109, 116], [117, 122], [123, 127], [128, 132], [133, 141], [142, 144], [145, 146], [147, 155], [156, 157], [158, 165], [165, 166], [167, 174], [174, 175], [176, 180], [181, 184], [185, 194], [195, 197], [198, 206], [207, 211], [212, 219], [220, 223], [223, 224]]}
{"doc_key": "ai-train-71", "ner": [[0, 2, "programlang"], [7, 11, "organisation"], [13, 13, "organisation"], [20, 20, "location"], [22, 22, "location"], [25, 26, "researcher"], [28, 29, "researcher"], [31, 32, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 25, 26, "artifact", "", true, false], [0, 2, 28, 29, "artifact", "", true, false], [0, 2, 31, 32, "artifact", "", true, false], [13, 13, 7, 11, "named", "", false, false], [13, 13, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false], [25, 26, 7, 11, "role", "", false, false], [28, 29, 7, 11, "role", "", false, false], [31, 32, 7, 11, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "logo", "was", "created", "in", "1967", "at", "Bolt", ",", "Beranek", "and", "Newman", "(", "BBN", ")", ",", "a", "research", "company", "in", "Cambridge", ",", "Massachusetts", ",", "by", "Wally", "Feurzeig", ",", "Cynthia", "Solomon", "and", "Seymour", "Papert", "."], "sentence-detokenized": "The logo was created in 1967 at Bolt, Beranek and Newman (BBN), a research company in Cambridge, Massachusetts, by Wally Feurzeig, Cynthia Solomon and Seymour Papert.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 20], [21, 23], [24, 28], [29, 31], [32, 36], [36, 37], [38, 45], [46, 49], [50, 56], [57, 58], [58, 61], [61, 62], [62, 63], [64, 65], [66, 74], [75, 82], [83, 85], [86, 95], [95, 96], [97, 110], [110, 111], [112, 114], [115, 120], [121, 129], [129, 130], [131, 138], [139, 146], [147, 150], [151, 158], [159, 165], [165, 166]]}
{"doc_key": "ai-train-72", "ner": [[0, 0, "misc"], [8, 9, "field"], [17, 18, "field"], [22, 23, "algorithm"], [26, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 9, "part-of", "", false, false], [0, 0, 17, 18, "compare", "", false, false], [22, 23, 17, 18, "part-of", "", false, false], [26, 27, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Neuroevolution", "is", "commonly", "used", "as", "part", "of", "the", "reinforcement", "learning", "paradigm", "and", "can", "be", "contrasted", "with", "conventional", "deep", "learning", "techniques", "that", "use", "gradient", "descent", "on", "a", "neural", "network", "with", "a", "fixed", "topology", "."], "sentence-detokenized": "Neuroevolution is commonly used as part of the reinforcement learning paradigm and can be contrasted with conventional deep learning techniques that use gradient descent on a neural network with a fixed topology.", "token2charspan": [[0, 14], [15, 17], [18, 26], [27, 31], [32, 34], [35, 39], [40, 42], [43, 46], [47, 60], [61, 69], [70, 78], [79, 82], [83, 86], [87, 89], [90, 100], [101, 105], [106, 118], [119, 123], [124, 132], [133, 143], [144, 148], [149, 152], [153, 161], [162, 169], [170, 172], [173, 174], [175, 181], [182, 189], [190, 194], [195, 196], [197, 202], [203, 211], [211, 212]]}
{"doc_key": "ai-train-73", "ner": [[3, 4, "algorithm"], [55, 57, "metrics"], [59, 59, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[59, 59, 55, 57, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["If", "we", "use", "least", "squares", "to", "fit", "a", "function", "in", "the", "form", "of", "a", "hyperplane", "\u0177", "=", "a", "+", "\u03b2", "supT", "/", "sup", "x", "to", "the", "data", "(", "x", "sub", "i", "/", "sub", ",", "y", "sub", "i", "/", "sub", ")", "sub", "1", "\u2264", "i", "\u2264n", "/", "sub", ",", "we", "could", "evaluate", "the", "fit", "using", "the", "mean", "square", "error", "(", "MSE", ")", "."], "sentence-detokenized": "If we use least squares to fit a function in the form of a hyperplane \u0177 = a + \u03b2 supT / sup x to the data (x sub i / sub, y sub i / sub) sub 1 \u2264 i \u2264n / sub, we could evaluate the fit using the mean square error (MSE).", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 15], [16, 23], [24, 26], [27, 30], [31, 32], [33, 41], [42, 44], [45, 48], [49, 53], [54, 56], [57, 58], [59, 69], [70, 71], [72, 73], [74, 75], [76, 77], [78, 79], [80, 84], [85, 86], [87, 90], [91, 92], [93, 95], [96, 99], [100, 104], [105, 106], [106, 107], [108, 111], [112, 113], [114, 115], [116, 119], [119, 120], [121, 122], [123, 126], [127, 128], [129, 130], [131, 134], [134, 135], [136, 139], [140, 141], [142, 143], [144, 145], [146, 148], [149, 150], [151, 154], [154, 155], [156, 158], [159, 164], [165, 173], [174, 177], [178, 181], [182, 187], [188, 191], [192, 196], [197, 203], [204, 209], [210, 211], [211, 214], [214, 215], [215, 216]]}
{"doc_key": "ai-train-74", "ner": [[6, 6, "country"], [8, 8, "country"], [10, 10, "country"], [12, 12, "country"], [14, 14, "country"], [16, 16, "country"], [18, 18, "country"], [20, 20, "country"], [22, 22, "country"], [24, 24, "country"], [26, 26, "country"], [28, 28, "country"], [31, 31, "country"], [33, 33, "country"], [35, 35, "country"], [37, 38, "country"], [40, 40, "country"], [42, 42, "country"], [44, 44, "country"], [46, 46, "country"], [49, 49, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "company", "has", "international", "operations", "in", "Australia", ",", "Brazil", ",", "Canada", ",", "China", ",", "Germany", ",", "India", ",", "Italy", ",", "Japan", ",", "Korea", ",", "Lithuania", ",", "Poland", ",", "Malaysia", ",", "the", "Philippines", ",", "Russia", ",", "Singapore", ",", "South", "Africa", ",", "Spain", ",", "Taiwan", ",", "Thailand", ",", "Turkey", "and", "the", "UK", "."], "sentence-detokenized": "The company has international operations in Australia, Brazil, Canada, China, Germany, India, Italy, Japan, Korea, Lithuania, Poland, Malaysia, the Philippines, Russia, Singapore, South Africa, Spain, Taiwan, Thailand, Turkey and the UK.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 29], [30, 40], [41, 43], [44, 53], [53, 54], [55, 61], [61, 62], [63, 69], [69, 70], [71, 76], [76, 77], [78, 85], [85, 86], [87, 92], [92, 93], [94, 99], [99, 100], [101, 106], [106, 107], [108, 113], [113, 114], [115, 124], [124, 125], [126, 132], [132, 133], [134, 142], [142, 143], [144, 147], [148, 159], [159, 160], [161, 167], [167, 168], [169, 178], [178, 179], [180, 185], [186, 192], [192, 193], [194, 199], [199, 200], [201, 207], [207, 208], [209, 217], [217, 218], [219, 225], [226, 229], [230, 233], [234, 236], [236, 237]]}
{"doc_key": "ai-train-75", "ner": [[3, 3, "misc"], [5, 8, "field"], [13, 13, "organisation"], [16, 23, "university"], [28, 30, "organisation"], [32, 35, "university"], [40, 41, "university"], [43, 44, "university"], [47, 49, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 3, 5, 8, "topic", "", false, false], [3, 3, 13, 13, "origin", "", false, false], [3, 3, 16, 23, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "holds", "a", "PhD", "in", "electrical", "and", "computer", "engineering", "(", "2000", ")", "from", "Inria", "and", "the", "University", "of", "Nice", "Sophia", "Antipolis", ",", "and", "has", "held", "permanent", "positions", "at", "Siemens", "Corporate", "Technology", ",", "\u00c9cole", "des", "ponts", "ParisTech", "and", "visiting", "positions", "at", "Rutgers", "University", ",", "Yale", "University", "and", "the", "University", "of", "Houston", "."], "sentence-detokenized": "He holds a PhD in electrical and computer engineering (2000) from Inria and the University of Nice Sophia Antipolis, and has held permanent positions at Siemens Corporate Technology, \u00c9cole des ponts ParisTech and visiting positions at Rutgers University, Yale University and the University of Houston.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 14], [15, 17], [18, 28], [29, 32], [33, 41], [42, 53], [54, 55], [55, 59], [59, 60], [61, 65], [66, 71], [72, 75], [76, 79], [80, 90], [91, 93], [94, 98], [99, 105], [106, 115], [115, 116], [117, 120], [121, 124], [125, 129], [130, 139], [140, 149], [150, 152], [153, 160], [161, 170], [171, 181], [181, 182], [183, 188], [189, 192], [193, 198], [199, 208], [209, 212], [213, 221], [222, 231], [232, 234], [235, 242], [243, 253], [253, 254], [255, 259], [260, 270], [271, 274], [275, 278], [279, 289], [290, 292], [293, 300], [300, 301]]}
{"doc_key": "ai-train-76", "ner": [[7, 8, "researcher"], [10, 10, "researcher"], [14, 16, "product"], [18, 19, "country"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 10, 7, 8, "role", "licensing_patent_to", false, false], [10, 10, 18, 19, "physical", "", false, false], [22, 22, 10, 10, "artifact", "", false, false], [22, 22, 14, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Licensing", "the", "original", "patent", "awarded", "to", "inventor", "George", "Devol", ",", "Engelberger", "developed", "the", "first", "industrial", "robot", "in", "the", "United", "States", ",", "the", "Unimate", ",", "in", "the", "1950s", "."], "sentence-detokenized": "Licensing the original patent awarded to inventor George Devol, Engelberger developed the first industrial robot in the United States, the Unimate, in the 1950s.", "token2charspan": [[0, 9], [10, 13], [14, 22], [23, 29], [30, 37], [38, 40], [41, 49], [50, 56], [57, 62], [62, 63], [64, 75], [76, 85], [86, 89], [90, 95], [96, 106], [107, 112], [113, 115], [116, 119], [120, 126], [127, 133], [133, 134], [135, 138], [139, 146], [146, 147], [148, 150], [151, 154], [155, 160], [160, 161]]}
{"doc_key": "ai-train-77", "ner": [[4, 5, "task"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "input", "is", "called", "speech", "recognition", "and", "the", "output", "is", "called", "speech", "synthesis", "."], "sentence-detokenized": "The input is called speech recognition and the output is called speech synthesis.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 26], [27, 38], [39, 42], [43, 46], [47, 53], [54, 56], [57, 63], [64, 70], [71, 80], [80, 81]]}
{"doc_key": "ai-train-78", "ner": [[3, 3, "programlang"], [6, 6, "programlang"], [13, 13, "programlang"], [16, 16, "programlang"], [26, 26, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 13, 13, "named", "", false, false], [6, 6, 3, 3, "origin", "descendant_of", false, false], [6, 6, 16, 16, "general-affiliation", "", false, false], [6, 6, 26, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Descendants", "of", "the", "CLIPS", "language", "include", "Jess", "(", "rule", "-", "based", "portion", "of", "CLIPS", "rewritten", "in", "Java", ",", "later", "grown", "in", "a", "different", "direction", ")", ",", "JESS", "was", "originally", "inspired"], "sentence-detokenized": "Descendants of the CLIPS language include Jess (rule-based portion of CLIPS rewritten in Java, later grown in a different direction), JESS was originally inspired", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 24], [25, 33], [34, 41], [42, 46], [47, 48], [48, 52], [52, 53], [53, 58], [59, 66], [67, 69], [70, 75], [76, 85], [86, 88], [89, 93], [93, 94], [95, 100], [101, 106], [107, 109], [110, 111], [112, 121], [122, 131], [131, 132], [132, 133], [134, 138], [139, 142], [143, 153], [154, 162]]}
{"doc_key": "ai-train-79", "ner": [[7, 7, "product"], [12, 14, "product"], [17, 18, "organisation"], [22, 23, "product"], [43, 44, "product"], [46, 48, "product"], [66, 67, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 14, 7, 7, "type-of", "", false, false], [17, 18, 12, 14, "usage", "", false, false], [22, 23, 17, 18, "artifact", "", false, false], [43, 44, 17, 18, "origin", "", true, false], [43, 44, 66, 67, "related-to", "", true, false], [46, 48, 17, 18, "origin", "", true, false], [46, 48, 66, 67, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["It", "has", "also", "created", "intelligent", "and", "flexible", "AGV", "applications", ",", "designing", "the", "Motivity", "control", "system", "used", "by", "RMT", "Robotics", "to", "develop", "its", "ADAM", "iAGV", "(", "Self", "-", "Guided", "Vehicle", ")", ",", "used", "for", "complex", "pick", "-", "and", "-", "place", "operations", "in", "combination", "with", "gantry", "systems", "and", "industrial", "robotic", "arms", ",", "used", "in", "Tier", "1", "automotive", "supply", "factories", "to", "move", "products", "from", "one", "process", "to", "another", "in", "non-linear", "layouts", "."], "sentence-detokenized": "It has also created intelligent and flexible AGV applications, designing the Motivity control system used by RMT Robotics to develop its ADAM iAGV (Self-Guided Vehicle), used for complex pick-and-place operations in combination with gantry systems and industrial robotic arms, used in Tier 1 automotive supply factories to move products from one process to another in non-linear layouts.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 31], [32, 35], [36, 44], [45, 48], [49, 61], [61, 62], [63, 72], [73, 76], [77, 85], [86, 93], [94, 100], [101, 105], [106, 108], [109, 112], [113, 121], [122, 124], [125, 132], [133, 136], [137, 141], [142, 146], [147, 148], [148, 152], [152, 153], [153, 159], [160, 167], [167, 168], [168, 169], [170, 174], [175, 178], [179, 186], [187, 191], [191, 192], [192, 195], [195, 196], [196, 201], [202, 212], [213, 215], [216, 227], [228, 232], [233, 239], [240, 247], [248, 251], [252, 262], [263, 270], [271, 275], [275, 276], [277, 281], [282, 284], [285, 289], [290, 291], [292, 302], [303, 309], [310, 319], [320, 322], [323, 327], [328, 336], [337, 341], [342, 345], [346, 353], [354, 356], [357, 364], [365, 367], [368, 378], [379, 386], [386, 387]]}
{"doc_key": "ai-train-80", "ner": [[7, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "\u03b2", "parameters", "are", "typically", "estimated", "with", "maximum", "likelihood", "."], "sentence-detokenized": "The \u03b2 parameters are typically estimated with maximum likelihood.", "token2charspan": [[0, 3], [4, 5], [6, 16], [17, 20], [21, 30], [31, 40], [41, 45], [46, 53], [54, 64], [64, 65]]}
{"doc_key": "ai-train-81", "ner": [[0, 1, "task"], [5, 5, "metrics"], [7, 7, "metrics"], [9, 9, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 0, 1, "part-of", "", false, false], [7, 7, 0, 1, "part-of", "", false, false], [9, 9, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Information", "retrieval", "metrics", "such", "as", "precision", "and", "recall", "or", "DCG", "are", "useful", "for", "assessing", "the", "quality", "of", "a", "recommendation", "method", "."], "sentence-detokenized": "Information retrieval metrics such as precision and recall or DCG are useful for assessing the quality of a recommendation method.", "token2charspan": [[0, 11], [12, 21], [22, 29], [30, 34], [35, 37], [38, 47], [48, 51], [52, 58], [59, 61], [62, 65], [66, 69], [70, 76], [77, 80], [81, 90], [91, 94], [95, 102], [103, 105], [106, 107], [108, 122], [123, 129], [129, 130]]}
{"doc_key": "ai-train-82", "ner": [[6, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "typical", "factory", "contains", "hundreds", "of", "industrial", "robots", "working", "on", "fully", "automated", "production", "lines", ",", "with", "one", "robot", "for", "every", "ten", "human", "workers", "."], "sentence-detokenized": "A typical factory contains hundreds of industrial robots working on fully automated production lines, with one robot for every ten human workers.", "token2charspan": [[0, 1], [2, 9], [10, 17], [18, 26], [27, 35], [36, 38], [39, 49], [50, 56], [57, 64], [65, 67], [68, 73], [74, 83], [84, 94], [95, 100], [100, 101], [102, 106], [107, 110], [111, 116], [117, 120], [121, 126], [127, 130], [131, 136], [137, 144], [144, 145]]}
{"doc_key": "ai-train-83", "ner": [[5, 5, "product"], [13, 14, "field"], [18, 19, "task"], [21, 22, "task"], [24, 25, "task"], [27, 28, "task"], [30, 31, "task"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[13, 14, 5, 5, "usage", "", false, true], [18, 19, 13, 14, "part-of", "", false, false], [21, 22, 13, 14, "part-of", "", false, false], [24, 25, 13, 14, "part-of", "", false, false], [27, 28, 13, 14, "part-of", "", false, false], [30, 31, 13, 14, "part-of", "", false, false], [33, 34, 13, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Over", "the", "past", "decade", ",", "NCPs", "have", "been", "used", "in", "a", "variety", "of", "image", "processing", "applications", ",", "including", "image", "segmentation", ",", "feature", "generation", ",", "face", "extraction", ",", "motion", "detection", ",", "region", "growing", "and", "noise", "reduction", "."], "sentence-detokenized": "Over the past decade, NCPs have been used in a variety of image processing applications, including image segmentation, feature generation, face extraction, motion detection, region growing and noise reduction.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 20], [20, 21], [22, 26], [27, 31], [32, 36], [37, 41], [42, 44], [45, 46], [47, 54], [55, 57], [58, 63], [64, 74], [75, 87], [87, 88], [89, 98], [99, 104], [105, 117], [117, 118], [119, 126], [127, 137], [137, 138], [139, 143], [144, 154], [154, 155], [156, 162], [163, 172], [172, 173], [174, 180], [181, 188], [189, 192], [193, 198], [199, 208], [208, 209]]}
{"doc_key": "ai-train-84", "ner": [[0, 1, "researcher"], [16, 17, "field"], [21, 24, "misc"], [26, 31, "conference"], [33, 33, "conference"], [38, 40, "misc"], [43, 49, "conference"], [50, 51, "conference"], [53, 57, "conference"], [59, 59, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 1, 16, 17, "related-to", "contributes_to", false, false], [0, 1, 21, 24, "win-defeat", "", false, false], [0, 1, 38, 40, "win-defeat", "", false, false], [21, 24, 26, 31, "temporal", "", false, false], [33, 33, 26, 31, "named", "", false, false], [38, 40, 43, 49, "temporal", "", false, false], [38, 40, 53, 57, "temporal", "", false, false], [50, 51, 43, 49, "named", "", false, false], [59, 59, 53, 57, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Xu", "has", "published", "more", "than", "50", "papers", "in", "international", "conferences", "and", "journals", "in", "the", "field", "of", "computer", "vision", "and", "won", "the", "Best", "Paper", "Award", "at", "the", "international", "conference", "Non-Photorealistic", "Rendering", "and", "Animation", "(", "NPAR", ")", "2012", "and", "the", "Best", "Reviewer", "Award", "at", "the", "international", "conferences", "Asian", "Conference", "on", "Computer", "Vision", "ACCV", "2012", "and", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "2015", "."], "sentence-detokenized": "Xu has published more than 50 papers in international conferences and journals in the field of computer vision and won the Best Paper Award at the international conference Non-Photorealistic Rendering and Animation (NPAR) 2012 and the Best Reviewer Award at the international conferences Asian Conference on Computer Vision ACCV 2012 and International Conference on Computer Vision (ICCV) 2015.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 21], [22, 26], [27, 29], [30, 36], [37, 39], [40, 53], [54, 65], [66, 69], [70, 78], [79, 81], [82, 85], [86, 91], [92, 94], [95, 103], [104, 110], [111, 114], [115, 118], [119, 122], [123, 127], [128, 133], [134, 139], [140, 142], [143, 146], [147, 160], [161, 171], [172, 190], [191, 200], [201, 204], [205, 214], [215, 216], [216, 220], [220, 221], [222, 226], [227, 230], [231, 234], [235, 239], [240, 248], [249, 254], [255, 257], [258, 261], [262, 275], [276, 287], [288, 293], [294, 304], [305, 307], [308, 316], [317, 323], [324, 328], [329, 333], [334, 337], [338, 351], [352, 362], [363, 365], [366, 374], [375, 381], [382, 383], [383, 387], [387, 388], [389, 393], [393, 394]]}
{"doc_key": "ai-train-85", "ner": [[0, 0, "programlang"], [2, 3, "field"], [5, 6, "field"], [9, 10, "misc"], [13, 14, "researcher"], [16, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 2, 3, "part-of", "", false, false], [0, 0, 5, 6, "part-of", "", false, false], [0, 0, 9, 10, "type-of", "", false, false], [16, 18, 0, 0, "usage", "", false, false], [16, 18, 13, 14, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["CycL", "in", "computer", "science", "and", "artificial", "intelligence", "is", "an", "ontology", "language", "used", "by", "Doug", "Lenat", "'s", "artificial", "Cyc", "project", "."], "sentence-detokenized": "CycL in computer science and artificial intelligence is an ontology language used by Doug Lenat's artificial Cyc project.", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 24], [25, 28], [29, 39], [40, 52], [53, 55], [56, 58], [59, 67], [68, 76], [77, 81], [82, 84], [85, 89], [90, 95], [95, 97], [98, 108], [109, 112], [113, 120], [120, 121]]}
{"doc_key": "ai-train-86", "ner": [[2, 3, "task"], [6, 8, "metrics"], [15, 18, "metrics"], [20, 27, "metrics"], [37, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 2, 3, "part-of", "", false, false], [15, 18, 6, 8, "named", "", false, false], [20, 27, 6, 8, "named", "", false, false], [37, 40, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Also", "in", "regression", "analysis", ",", "the", "mean", "square", "error", ",", "often", "referred", "to", "as", "the", "mean", "square", "prediction", "error", "or", "out", "-", "of", "-", "sample", "mean", "square", "error", ",", "may", "refer", "to", "the", "mean", "value", "of", "the", "quadratic", "deviations", "of", "the", "predictions", "from", "the", "TRUE", "values", ",", "on", "an", "out", "-", "of", "-", "sample", "test", "space", ",", "generated", "by", "a", "model", "estimated", "on", "a", "particular", "sample", "space", "."], "sentence-detokenized": "Also in regression analysis, the mean square error, often referred to as the mean square prediction error or out-of-sample mean square error, may refer to the mean value of the quadratic deviations of the predictions from the TRUE values, on an out-of-sample test space, generated by a model estimated on a particular sample space.", "token2charspan": [[0, 4], [5, 7], [8, 18], [19, 27], [27, 28], [29, 32], [33, 37], [38, 44], [45, 50], [50, 51], [52, 57], [58, 66], [67, 69], [70, 72], [73, 76], [77, 81], [82, 88], [89, 99], [100, 105], [106, 108], [109, 112], [112, 113], [113, 115], [115, 116], [116, 122], [123, 127], [128, 134], [135, 140], [140, 141], [142, 145], [146, 151], [152, 154], [155, 158], [159, 163], [164, 169], [170, 172], [173, 176], [177, 186], [187, 197], [198, 200], [201, 204], [205, 216], [217, 221], [222, 225], [226, 230], [231, 237], [237, 238], [239, 241], [242, 244], [245, 248], [248, 249], [249, 251], [251, 252], [252, 258], [259, 263], [264, 269], [269, 270], [271, 280], [281, 283], [284, 285], [286, 291], [292, 301], [302, 304], [305, 306], [307, 317], [318, 324], [325, 330], [330, 331]]}
{"doc_key": "ai-train-87", "ner": [[6, 8, "algorithm"], [10, 11, "algorithm"], [19, 22, "algorithm"], [33, 34, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 8, 10, 11, "compare", "", false, false], [6, 8, 19, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "terms", "of", "results", ",", "the", "C", "-", "HOG", "and", "R-", "HOG", "block", "descriptors", "perform", "comparably", ",", "with", "the", "C", "-", "HOG", "descriptors", "maintaining", "a", "slight", "advantage", "in", "the", "non-detection", "rate", "at", "fixed", "FALSE", "positive", "rates", "on", "both", "datasets", "."], "sentence-detokenized": "In terms of results, the C-HOG and R-HOG block descriptors perform comparably, with the C-HOG descriptors maintaining a slight advantage in the non-detection rate at fixed FALSE positive rates on both datasets.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 19], [19, 20], [21, 24], [25, 26], [26, 27], [27, 30], [31, 34], [35, 37], [37, 40], [41, 46], [47, 58], [59, 66], [67, 77], [77, 78], [79, 83], [84, 87], [88, 89], [89, 90], [90, 93], [94, 105], [106, 117], [118, 119], [120, 126], [127, 136], [137, 139], [140, 143], [144, 157], [158, 162], [163, 165], [166, 171], [172, 177], [178, 186], [187, 192], [193, 195], [196, 200], [201, 209], [209, 210]]}
{"doc_key": "ai-train-88", "ner": [[4, 6, "algorithm"], [8, 8, "misc"], [10, 12, "algorithm"], [14, 15, "algorithm"], [18, 19, "algorithm"], [21, 23, "algorithm"], [25, 27, "algorithm"], [29, 30, "misc"], [32, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[4, 6, 8, 8, "usage", "", false, false], [10, 12, 29, 30, "usage", "", false, false], [14, 15, 29, 30, "usage", "", false, false], [18, 19, 29, 30, "usage", "", false, false], [21, 23, 29, 30, "usage", "", false, false], [25, 27, 29, 30, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Popular", "recognition", "algorithms", "include", "principal", "component", "analysis", "using", "eigenfaces", ",", "linear", "discriminant", "analysis", ",", "elastic", "matching", "using", "the", "Fisherface", "algorithm", ",", "hidden", "Markov", "model", ",", "multilinear", "subspace", "learning", "using", "tensor", "representation", "and", "dynamic", "linkage", "matching", "motivated", "by", "neurons", "."], "sentence-detokenized": "Popular recognition algorithms include principal component analysis using eigenfaces, linear discriminant analysis, elastic matching using the Fisherface algorithm, hidden Markov model, multilinear subspace learning using tensor representation and dynamic linkage matching motivated by neurons.", "token2charspan": [[0, 7], [8, 19], [20, 30], [31, 38], [39, 48], [49, 58], [59, 67], [68, 73], [74, 84], [84, 85], [86, 92], [93, 105], [106, 114], [114, 115], [116, 123], [124, 132], [133, 138], [139, 142], [143, 153], [154, 163], [163, 164], [165, 171], [172, 178], [179, 184], [184, 185], [186, 197], [198, 206], [207, 215], [216, 221], [222, 228], [229, 243], [244, 247], [248, 255], [256, 263], [264, 272], [273, 282], [283, 285], [286, 293], [293, 294]]}
{"doc_key": "ai-train-89", "ner": [[3, 10, "misc"], [20, 23, "location"], [40, 42, "location"], [55, 55, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[20, 23, 3, 10, "temporal", "", false, false], [40, 42, 3, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Starting", "with", "the", "2019", "edition", "of", "the", "Toronto", "International", "Film", "Festival", ",", "films", "may", "be", "excluded", "from", "screening", "at", "the", "Scotiabank", "Theatre", "in", "Toronto", "-", "one", "of", "the", "festival", "'s", "main", "venues", "-", "and", "screened", "elsewhere", "(", "such", "as", "the", "TIFF", "Bell", "Lightbox", "and", "other", "local", "cinemas", ")", "if", "distributed", "by", "a", "service", "such", "as", "Netflix", "."], "sentence-detokenized": "Starting with the 2019 edition of the Toronto International Film Festival, films may be excluded from screening at the Scotiabank Theatre in Toronto - one of the festival's main venues - and screened elsewhere (such as the TIFF Bell Lightbox and other local cinemas) if distributed by a service such as Netflix.", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 22], [23, 30], [31, 33], [34, 37], [38, 45], [46, 59], [60, 64], [65, 73], [73, 74], [75, 80], [81, 84], [85, 87], [88, 96], [97, 101], [102, 111], [112, 114], [115, 118], [119, 129], [130, 137], [138, 140], [141, 148], [149, 150], [151, 154], [155, 157], [158, 161], [162, 170], [170, 172], [173, 177], [178, 184], [185, 186], [187, 190], [191, 199], [200, 209], [210, 211], [211, 215], [216, 218], [219, 222], [223, 227], [228, 232], [233, 241], [242, 245], [246, 251], [252, 257], [258, 265], [265, 266], [267, 269], [270, 281], [282, 284], [285, 286], [287, 294], [295, 299], [300, 302], [303, 310], [310, 311]]}
{"doc_key": "ai-train-90", "ner": [[0, 0, "organisation"], [2, 3, "researcher"], [5, 6, "organisation"], [12, 12, "researcher"], [23, 26, "product"], [36, 36, "researcher"], [45, 47, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 6, "related-to", "purchases", false, false], [2, 3, 12, 12, "named", "same", false, false], [2, 3, 36, 36, "named", "same", false, false], [5, 6, 2, 3, "origin", "founded_by", false, false], [23, 26, 0, 0, "artifact", "", false, false], [45, 47, 36, 36, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "bought", "Victor", "Scheinman", "'s", "Vicarm", "Inc.", "in", "1977", "and", ",", "with", "Scheinman", "'s", "help", ",", "the", "company", "created", "and", "began", "producing", "the", "Universal", "Programmable", "Assembly", "Machine", ",", "a", "new", "model", "of", "robotic", "arm", ",", "using", "Scheinman", "'s", "state", "-", "of", "-", "the", "-", "art", "VAL", "programming", "language", "."], "sentence-detokenized": "Unimation bought Victor Scheinman's Vicarm Inc. in 1977 and, with Scheinman's help, the company created and began producing the Universal Programmable Assembly Machine, a new model of robotic arm, using Scheinman's state-of-the-art VAL programming language.", "token2charspan": [[0, 9], [10, 16], [17, 23], [24, 33], [33, 35], [36, 42], [43, 47], [48, 50], [51, 55], [56, 59], [59, 60], [61, 65], [66, 75], [75, 77], [78, 82], [82, 83], [84, 87], [88, 95], [96, 103], [104, 107], [108, 113], [114, 123], [124, 127], [128, 137], [138, 150], [151, 159], [160, 167], [167, 168], [169, 170], [171, 174], [175, 180], [181, 183], [184, 191], [192, 195], [195, 196], [197, 202], [203, 212], [212, 214], [215, 220], [220, 221], [221, 223], [223, 224], [224, 227], [227, 228], [228, 231], [232, 235], [236, 247], [248, 256], [256, 257]]}
{"doc_key": "ai-train-91", "ner": [[0, 1, "product"], [6, 6, "programlang"], [10, 11, "algorithm"], [14, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 6, "general-affiliation", "", false, false], [0, 1, 10, 11, "origin", "implementation_of", false, false], [0, 1, 14, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["J", "48", "is", "an", "open", "source", "Java", "implementation", "of", "the", "C4.5", "algorithm", "in", "the", "data", "mining", "tool", "Weka", "."], "sentence-detokenized": "J48 is an open source Java implementation of the C4.5 algorithm in the data mining tool Weka.", "token2charspan": [[0, 1], [1, 3], [4, 6], [7, 9], [10, 14], [15, 21], [22, 26], [27, 41], [42, 44], [45, 48], [49, 53], [54, 63], [64, 66], [67, 70], [71, 75], [76, 82], [83, 87], [88, 92], [92, 93]]}
{"doc_key": "ai-train-92", "ner": [[2, 2, "metrics"], [12, 13, "product"], [17, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 12, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "2004", "SSIM", "paper", "has", "been", "cited", "over", "20,000", "times", "according", "to", "Google", "Scholar", "and", "received", "the", "IEEE", "Signal", "Processing", "Society", "'s", "2016", "Sustained", "Impact", "Award", ",", "which", "indicates", "a", "paper", "with", "an", "unusually", "high", "impact", "for", "at", "least", "10", "years", "after", "its", "publication", "."], "sentence-detokenized": "The 2004 SSIM paper has been cited over 20,000 times according to Google Scholar and received the IEEE Signal Processing Society's 2016 Sustained Impact Award, which indicates a paper with an unusually high impact for at least 10 years after its publication.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 19], [20, 23], [24, 28], [29, 34], [35, 39], [40, 46], [47, 52], [53, 62], [63, 65], [66, 72], [73, 80], [81, 84], [85, 93], [94, 97], [98, 102], [103, 109], [110, 120], [121, 128], [128, 130], [131, 135], [136, 145], [146, 152], [153, 158], [158, 159], [160, 165], [166, 175], [176, 177], [178, 183], [184, 188], [189, 191], [192, 201], [202, 206], [207, 213], [214, 217], [218, 220], [221, 226], [227, 229], [230, 235], [236, 241], [242, 245], [246, 257], [257, 258]]}
{"doc_key": "ai-train-93", "ner": [[0, 1, "task"], [22, 23, "product"], [38, 40, "product"], [43, 43, "organisation"], [44, 44, "product"], [49, 49, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 43, 43, "artifact", "", false, false], [22, 23, 0, 1, "related-to", "performs", false, false], [22, 23, 38, 40, "part-of", "", false, false], [43, 43, 49, 49, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Speech", "synthesis", "is", "about", "to", "become", "completely", "indistinguishable", "from", "the", "voice", "of", "a", "real", "human", "being", "with", "the", "introduction", "in", "2016", "of", "Adobe", "Voco", "speech", "editing", "and", "generation", "software", ",", "a", "prototype", "intended", "to", "be", "part", "of", "the", "Adobe", "Creative", "Suite", ",", "and", "DeepMind", "WaveNet", ",", "a", "prototype", "from", "Google", "."], "sentence-detokenized": "Speech synthesis is about to become completely indistinguishable from the voice of a real human being with the introduction in 2016 of Adobe Voco speech editing and generation software, a prototype intended to be part of the Adobe Creative Suite, and DeepMind WaveNet, a prototype from Google.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 25], [26, 28], [29, 35], [36, 46], [47, 64], [65, 69], [70, 73], [74, 79], [80, 82], [83, 84], [85, 89], [90, 95], [96, 101], [102, 106], [107, 110], [111, 123], [124, 126], [127, 131], [132, 134], [135, 140], [141, 145], [146, 152], [153, 160], [161, 164], [165, 175], [176, 184], [184, 185], [186, 187], [188, 197], [198, 206], [207, 209], [210, 212], [213, 217], [218, 220], [221, 224], [225, 230], [231, 239], [240, 245], [245, 246], [247, 250], [251, 259], [260, 267], [267, 268], [269, 270], [271, 280], [281, 285], [286, 292], [292, 293]]}
{"doc_key": "ai-train-94", "ner": [[0, 0, "researcher"], [7, 11, "organisation"], [15, 20, "organisation"], [26, 26, "conference"], [33, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 7, 11, "role", "", false, false], [0, 0, 15, 20, "role", "", false, false], [0, 0, 26, 26, "role", "", false, false], [0, 0, 33, 37, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Poggio", "is", "an", "honorary", "member", "of", "the", "Neuroscience", "Research", "Program", ",", "a", "member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "a", "founding", "member", "of", "AAAI", "and", "a", "founding", "member", "of", "the", "McGovern", "Institute", "for", "Brain", "Research", "."], "sentence-detokenized": "Poggio is an honorary member of the Neuroscience Research Program, a member of the American Academy of Arts and Sciences, a founding member of AAAI and a founding member of the McGovern Institute for Brain Research.", "token2charspan": [[0, 6], [7, 9], [10, 12], [13, 21], [22, 28], [29, 31], [32, 35], [36, 48], [49, 57], [58, 65], [65, 66], [67, 68], [69, 75], [76, 78], [79, 82], [83, 91], [92, 99], [100, 102], [103, 107], [108, 111], [112, 120], [120, 121], [122, 123], [124, 132], [133, 139], [140, 142], [143, 147], [148, 151], [152, 153], [154, 162], [163, 169], [170, 172], [173, 176], [177, 185], [186, 195], [196, 199], [200, 205], [206, 214], [214, 215]]}
{"doc_key": "ai-train-95", "ner": [[9, 9, "task"], [8, 12, "task"], [16, 17, "task"], [24, 24, "misc"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 16, 17, "cause-effect", "", false, false], [8, 12, 16, 17, "cause-effect", "", false, false], [25, 26, 16, 17, "topic", "", false, false], [25, 26, 24, 24, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "1990s", ",", "encouraged", "by", "successes", "in", "speech", "recognition", "and", "speech", "synthesis", ",", "research", "into", "speech", "translation", "began", "with", "the", "development", "of", "the", "German", "Verbmobil", "project", "."], "sentence-detokenized": "In the 1990s, encouraged by successes in speech recognition and speech synthesis, research into speech translation began with the development of the German Verbmobil project.", "token2charspan": [[0, 2], [3, 6], [7, 12], [12, 13], [14, 24], [25, 27], [28, 37], [38, 40], [41, 47], [48, 59], [60, 63], [64, 70], [71, 80], [80, 81], [82, 90], [91, 95], [96, 102], [103, 114], [115, 120], [121, 125], [126, 129], [130, 141], [142, 144], [145, 148], [149, 155], [156, 165], [166, 173], [173, 174]]}
{"doc_key": "ai-train-96", "ner": [[3, 4, "researcher"], [8, 9, "researcher"], [11, 12, "researcher"], [15, 16, "algorithm"], [21, 22, "algorithm"], [26, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 8, 9, "role", "", false, false], [15, 16, 3, 4, "origin", "", false, false], [15, 16, 8, 9, "origin", "", false, false], [15, 16, 11, 12, "origin", "", false, false], [15, 16, 26, 26, "part-of", "", false, false], [21, 22, 15, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "1999", ",", "Felix", "Gers", "and", "his", "advisor", "J\u00fcrgen", "Schmidhuber", "and", "Fred", "Cummins", "introduced", "the", "forgetting", "door", "(", "also", "called", "the", "retention", "door", ")", "into", "the", "LSTM", "architecture", ","], "sentence-detokenized": "In 1999, Felix Gers and his advisor J\u00fcrgen Schmidhuber and Fred Cummins introduced the forgetting door (also called the retention door) into the LSTM architecture,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 19], [20, 23], [24, 27], [28, 35], [36, 42], [43, 54], [55, 58], [59, 63], [64, 71], [72, 82], [83, 86], [87, 97], [98, 102], [103, 104], [104, 108], [109, 115], [116, 119], [120, 129], [130, 134], [134, 135], [136, 140], [141, 144], [145, 149], [150, 162], [162, 163]]}
{"doc_key": "ai-train-97", "ner": [[1, 3, "field"], [5, 6, "field"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 11, 1, 3, "part-of", "", false, false], [9, 11, 5, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "digital", "signal", "processing", "and", "information", "theory", ",", "the", "normalised", "sinc", "function", "is", "commonly", "defined", "by"], "sentence-detokenized": "In digital signal processing and information theory, the normalised sinc function is commonly defined by", "token2charspan": [[0, 2], [3, 10], [11, 17], [18, 28], [29, 32], [33, 44], [45, 51], [51, 52], [53, 56], [57, 67], [68, 72], [73, 81], [82, 84], [85, 93], [94, 101], [102, 104]]}
{"doc_key": "ai-train-98", "ner": [[2, 3, "field"], [9, 10, "researcher"], [17, 20, "conference"], [23, 27, "organisation"], [29, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 10, "origin", "coined_term", false, false], [9, 10, 17, 20, "role", "", false, false], [9, 10, 23, 27, "role", "", false, false], [29, 29, 23, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "computational", "linguistics", "itself", "was", "first", "coined", "by", "David", "Hays", ",", "a", "founding", "member", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "the", "International", "Committee", "on", "Computational", "Linguistics", "(", "ICCL", ")", "."], "sentence-detokenized": "The term computational linguistics itself was first coined by David Hays, a founding member of the Association for Computational Linguistics and the International Committee on Computational Linguistics (ICCL).", "token2charspan": [[0, 3], [4, 8], [9, 22], [23, 34], [35, 41], [42, 45], [46, 51], [52, 58], [59, 61], [62, 67], [68, 72], [72, 73], [74, 75], [76, 84], [85, 91], [92, 94], [95, 98], [99, 110], [111, 114], [115, 128], [129, 140], [141, 144], [145, 148], [149, 162], [163, 172], [173, 175], [176, 189], [190, 201], [202, 203], [203, 207], [207, 208], [208, 209]]}
{"doc_key": "ai-train-99", "ner": [[9, 16, "misc"], [14, 14, "misc"], [37, 39, "metrics"], [41, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[41, 41, 37, 39, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["59", ",", "pp.", "2547-2553", ",", "October", "2011", "In", "the", "one", "-dimensional", "polynomial", "-", "based", "DPD", "with", "memory", "(", "or", "without", "memory", ")", ",", "in", "order", "to", "resolve", "the", "coefficients", "of", "the", "digital", "pre-distorter", "polynomials", "and", "minimise", "the", "mean", "square", "error", "(", "MSE", ")", ",", "the", "distorted", "output", "of", "the", "nonlinear", "system", "must", "be", "oversampled", "at", "a", "rate", "that", "allows", "the", "acquisition", "of", "the", "nonlinear", "products", "of", "the", "order", "of", "the", "digital", "pre-distorter", "."], "sentence-detokenized": "59, pp. 2547-2553, October 2011 In the one-dimensional polynomial-based DPD with memory (or without memory), in order to resolve the coefficients of the digital pre-distorter polynomials and minimise the mean square error (MSE), the distorted output of the nonlinear system must be oversampled at a rate that allows the acquisition of the nonlinear products of the order of the digital pre-distorter.", "token2charspan": [[0, 2], [2, 3], [4, 7], [8, 17], [17, 18], [19, 26], [27, 31], [32, 34], [35, 38], [39, 42], [42, 54], [55, 65], [65, 66], [66, 71], [72, 75], [76, 80], [81, 87], [88, 89], [89, 91], [92, 99], [100, 106], [106, 107], [107, 108], [109, 111], [112, 117], [118, 120], [121, 128], [129, 132], [133, 145], [146, 148], [149, 152], [153, 160], [161, 174], [175, 186], [187, 190], [191, 199], [200, 203], [204, 208], [209, 215], [216, 221], [222, 223], [223, 226], [226, 227], [227, 228], [229, 232], [233, 242], [243, 249], [250, 252], [253, 256], [257, 266], [267, 273], [274, 278], [279, 281], [282, 293], [294, 296], [297, 298], [299, 303], [304, 308], [309, 315], [316, 319], [320, 331], [332, 334], [335, 338], [339, 348], [349, 357], [358, 360], [361, 364], [365, 370], [371, 373], [374, 377], [378, 385], [386, 399], [399, 400]]}
{"doc_key": "ai-train-100", "ner": [[0, 1, "researcher"], [9, 9, "location"], [11, 12, "location"], [14, 15, "country"], [19, 19, "location"], [21, 21, "country"], [30, 40, "organisation"], [43, 46, "organisation"], [48, 48, "location"], [55, 56, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 1, 9, 9, "physical", "", false, false], [0, 1, 43, 46, "physical", "", false, false], [0, 1, 55, 56, "role", "", false, false], [9, 9, 11, 12, "physical", "", false, false], [11, 12, 14, 15, "physical", "", false, false], [30, 40, 43, 46, "part-of", "", false, false], [43, 46, 48, 48, "physical", "", false, false], [55, 56, 30, 40, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Boris", "Katz", ",", "(", "born", "5", "October", "1947", "in", "Chi\u0219in\u0103u", ",", "Moldavian", "SSR", ",", "Soviet", "Union", ",", "(", "now", "Chi\u0219in\u0103u", ",", "Moldova", ")", ")", "is", "an", "American", "researcher", "(", "computer", "scientist", ")", "at", "the", "MIT", "Computer", "Science", "and", "Artificial", "Intelligence", "Laboratory", "at", "the", "Massachusetts", "Institute", "of", "Technology", "in", "Cambridge", "and", "head", "of", "the", "lab", "'s", "InfoLab", "group", "."], "sentence-detokenized": "Boris Katz, (born 5 October 1947 in Chi\u0219in\u0103u, Moldavian SSR, Soviet Union, (now Chi\u0219in\u0103u, Moldova)) is an American researcher (computer scientist) at the MIT Computer Science and Artificial Intelligence Laboratory at the Massachusetts Institute of Technology in Cambridge and head of the lab's InfoLab group.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 13], [13, 17], [18, 19], [20, 27], [28, 32], [33, 35], [36, 44], [44, 45], [46, 55], [56, 59], [59, 60], [61, 67], [68, 73], [73, 74], [75, 76], [76, 79], [80, 88], [88, 89], [90, 97], [97, 98], [98, 99], [100, 102], [103, 105], [106, 114], [115, 125], [126, 127], [127, 135], [136, 145], [145, 146], [147, 149], [150, 153], [154, 157], [158, 166], [167, 174], [175, 178], [179, 189], [190, 202], [203, 213], [214, 216], [217, 220], [221, 234], [235, 244], [245, 247], [248, 258], [259, 261], [262, 271], [272, 275], [276, 280], [281, 283], [284, 287], [288, 291], [291, 293], [294, 301], [302, 307], [307, 308]]}
