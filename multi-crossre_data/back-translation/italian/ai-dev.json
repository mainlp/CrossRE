{"doc_key": "ai-dev-1", "ner": [[4, 4, "metrics"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 4, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["In", "this", "case", ",", "accuracy", "is", "measured", "by", "the", "error", "rate", ",", "defined", "as", ":"], "sentence-detokenized": "In this case, accuracy is measured by the error rate, defined as:", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 22], [23, 25], [26, 34], [35, 37], [38, 41], [42, 47], [48, 52], [52, 53], [54, 61], [62, 64], [64, 65]]}
{"doc_key": "ai-dev-2", "ner": [[4, 4, "algorithm"], [11, 12, "misc"], [16, 18, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 11, 12, "type-of", "", false, false], [4, 4, 16, 18, "related-to", "", false, false], [4, 4, 19, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "this", "respect", ",", "SVM", "is", "closely", "related", "to", "other", "fundamental", "classification", "algorithms", ",", "such", "as", "regularised", "least", "squares", "logistic", "regression", "."], "sentence-detokenized": "In this respect, SVM is closely related to other fundamental classification algorithms, such as regularised least squares logistic regression.", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 20], [21, 23], [24, 31], [32, 39], [40, 42], [43, 48], [49, 60], [61, 75], [76, 86], [86, 87], [88, 92], [93, 95], [96, 107], [108, 113], [114, 121], [122, 130], [131, 141], [141, 142]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [3, 4, "person"], [14, 15, "person"], [17, 17, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 0, 1, "named", "actor_plays_character", false, false], [3, 4, 0, 1, "origin", "actor_plays_character", false, false], [17, 17, 14, 15, "named", "actor_plays_character", false, false], [17, 17, 14, 15, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "plays", "Leon", "Kowalski", ",", "a", "replicant", "who", "fights", "and", "works", ",", "and", "Joanna", "Cassidy", "plays", "Zhora", ",", "an", "assassin", "replicant", "."], "sentence-detokenized": "Brion James plays Leon Kowalski, a replicant who fights and works, and Joanna Cassidy plays Zhora, an assassin replicant.", "token2charspan": [[0, 5], [6, 11], [12, 17], [18, 22], [23, 31], [31, 32], [33, 34], [35, 44], [45, 48], [49, 55], [56, 59], [60, 65], [65, 66], [67, 70], [71, 77], [78, 85], [86, 91], [92, 97], [97, 98], [99, 101], [102, 110], [111, 120], [120, 121]]}
{"doc_key": "ai-dev-4", "ner": [[18, 21, "product"], [23, 23, "product"], [16, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 21, 16, 16, "physical", "", false, false], [23, 23, 18, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "image", "to", "be", "scanned", ",", "stored", "and", "recreated", "in", "digital", "pixels", "was", "displayed", "on", "NIST", "'s", "Standards", "Eastern", "Automatic", "Computer", "(", "SEAC", ")", "."], "sentence-detokenized": "The first image to be scanned, stored and recreated in digital pixels was displayed on NIST's Standards Eastern Automatic Computer (SEAC).", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 18], [19, 21], [22, 29], [29, 30], [31, 37], [38, 41], [42, 51], [52, 54], [55, 62], [63, 69], [70, 73], [74, 83], [84, 86], [87, 91], [91, 93], [94, 103], [104, 111], [112, 121], [122, 130], [131, 132], [132, 136], [136, 137], [137, 138]]}
{"doc_key": "ai-dev-5", "ner": [[0, 9, "task"], [21, 22, "task"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 9, 21, 22, "part-of", "", false, false], [0, 9, 24, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Text", "segmentation", "into", "topics", "or", "turns", "of", "speech", "can", "be", "useful", "in", "some", "natural", "processing", "tasks", ":", "it", "can", "significantly", "improve", "information", "retrieval", "or", "speech", "recognition", "(", "by", "indexing", "/", "recognising", "documents", "more", "precisely", "or", "providing", "the", "specific", "part", "of", "a", "document", "corresponding", "to", "the", "query", "as", "a", "result", ")", "."], "sentence-detokenized": "Text segmentation into topics or turns of speech can be useful in some natural processing tasks: it can significantly improve information retrieval or speech recognition (by indexing/recognising documents more precisely or providing the specific part of a document corresponding to the query as a result).", "token2charspan": [[0, 4], [5, 17], [18, 22], [23, 29], [30, 32], [33, 38], [39, 41], [42, 48], [49, 52], [53, 55], [56, 62], [63, 65], [66, 70], [71, 78], [79, 89], [90, 95], [95, 96], [97, 99], [100, 103], [104, 117], [118, 125], [126, 137], [138, 147], [148, 150], [151, 157], [158, 169], [170, 171], [171, 173], [174, 182], [182, 183], [183, 194], [195, 204], [205, 209], [210, 219], [220, 222], [223, 232], [233, 236], [237, 245], [246, 250], [251, 253], [254, 255], [256, 264], [265, 278], [279, 281], [282, 285], [286, 291], [292, 294], [295, 296], [297, 303], [303, 304], [304, 305]]}
{"doc_key": "ai-dev-6", "ner": [[8, 9, "university"], [20, 21, "conference"], [23, 24, "university"], [33, 34, "researcher"], [36, 37, "researcher"], [39, 40, "researcher"], [42, 43, "researcher"], [45, 46, "researcher"], [48, 49, "researcher"], [51, 53, "researcher"], [55, 56, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[20, 21, 23, 24, "physical", "", false, false], [33, 34, 20, 21, "physical", "", false, false], [33, 34, 20, 21, "role", "", false, false], [33, 34, 20, 21, "temporal", "", false, false], [36, 37, 20, 21, "physical", "", false, false], [36, 37, 20, 21, "role", "", false, false], [36, 37, 20, 21, "temporal", "", false, false], [39, 40, 20, 21, "physical", "", false, false], [39, 40, 20, 21, "role", "", false, false], [39, 40, 20, 21, "temporal", "", false, false], [42, 43, 20, 21, "physical", "", false, false], [42, 43, 20, 21, "role", "", false, false], [42, 43, 20, 21, "temporal", "", false, false], [45, 46, 20, 21, "physical", "", false, false], [45, 46, 20, 21, "role", "", false, false], [45, 46, 20, 21, "temporal", "", false, false], [48, 49, 20, 21, "physical", "", false, false], [48, 49, 20, 21, "role", "", false, false], [48, 49, 20, 21, "temporal", "", false, false], [51, 53, 20, 21, "physical", "", false, false], [51, 53, 20, 21, "role", "", false, false], [51, 53, 20, 21, "temporal", "", false, false], [55, 56, 20, 21, "physical", "", false, false], [55, 56, 20, 21, "role", "", false, false], [55, 56, 20, 21, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["In", "1999", "he", "organised", "such", "a", "symposium", "at", "Indiana", "University", "and", "in", "April", "2000", "he", "organised", "a", "larger", "symposium", "entitled", "Spiritual", "Robots", "at", "Stanford", "University", ",", "where", "he", "moderated", "a", "panel", "consisting", "of", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", "and", "John", "Koza", "."], "sentence-detokenized": "In 1999 he organised such a symposium at Indiana University and in April 2000 he organised a larger symposium entitled Spiritual Robots at Stanford University, where he moderated a panel consisting of Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland and John Koza.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 20], [21, 25], [26, 27], [28, 37], [38, 40], [41, 48], [49, 59], [60, 63], [64, 66], [67, 72], [73, 77], [78, 80], [81, 90], [91, 92], [93, 99], [100, 109], [110, 118], [119, 128], [129, 135], [136, 138], [139, 147], [148, 158], [158, 159], [160, 165], [166, 168], [169, 178], [179, 180], [181, 186], [187, 197], [198, 200], [201, 204], [205, 213], [213, 214], [215, 219], [220, 227], [227, 228], [229, 234], [235, 240], [240, 241], [242, 247], [248, 254], [254, 255], [256, 260], [261, 264], [264, 265], [266, 271], [272, 277], [277, 278], [279, 283], [284, 289], [290, 297], [298, 301], [302, 306], [307, 311], [311, 312]]}
{"doc_key": "ai-dev-7", "ner": [[8, 8, "metrics"], [9, 9, "metrics"], [12, 12, "metrics"], [13, 14, "metrics"], [18, 18, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 8, 18, 18, "named", "", false, false], [9, 9, 8, 8, "named", "", false, false], [12, 12, 39, 39, "named", "", false, false], [13, 14, 12, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["To", "calculate", "the", "score", "we", "consider", "both", "the", "precision", "p", "and", "the", "recall", "r", "of", "the", "test", ":", "p", "is", "the", "number", "of", "corrected", "positive", "results", "divided", "by", "the", "number", "of", "all", "positive", "results", "returned", "by", "the", "classifier", "and", "r", "is", "the", "number", "of", "corrected", "positive", "results", "divided", "by", "the", "number", "of", "all", "relevant", "samples", "(", "all", "samples", "that", "should", "have", "been", "identified", "as", "positive", ")", "."], "sentence-detokenized": "To calculate the score we consider both the precision p and the recall r of the test: p is the number of corrected positive results divided by the number of all positive results returned by the classifier and r is the number of corrected positive results divided by the number of all relevant samples (all samples that should have been identified as positive).", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 22], [23, 25], [26, 34], [35, 39], [40, 43], [44, 53], [54, 55], [56, 59], [60, 63], [64, 70], [71, 72], [73, 75], [76, 79], [80, 84], [84, 85], [86, 87], [88, 90], [91, 94], [95, 101], [102, 104], [105, 114], [115, 123], [124, 131], [132, 139], [140, 142], [143, 146], [147, 153], [154, 156], [157, 160], [161, 169], [170, 177], [178, 186], [187, 189], [190, 193], [194, 204], [205, 208], [209, 210], [211, 213], [214, 217], [218, 224], [225, 227], [228, 237], [238, 246], [247, 254], [255, 262], [263, 265], [266, 269], [270, 276], [277, 279], [280, 283], [284, 292], [293, 300], [301, 302], [302, 305], [306, 313], [314, 318], [319, 325], [326, 330], [331, 335], [336, 346], [347, 349], [350, 358], [358, 359], [359, 360]]}
{"doc_key": "ai-dev-8", "ner": [[4, 4, "organisation"], [23, 23, "product"], [31, 32, "person"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 23, 23, "artifact", "", false, false], [23, 23, 31, 32, "win-defeat", "", false, false], [23, 23, 38, 38, "win-defeat", "", true, false], [31, 32, 38, 38, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "its", "acquisition", "by", "Google", ",", "the", "company", "has", "made", "a", "number", "of", "significant", "achievements", ",", "the", "most", "important", "being", "the", "creation", "of", "AlphaGo", ",", "a", "programme", "that", "defeated", "world", "champion", "Lee", "Sedol", "in", "the", "complex", "game", "of", "Go", "."], "sentence-detokenized": "Since its acquisition by Google, the company has made a number of significant achievements, the most important being the creation of AlphaGo, a programme that defeated world champion Lee Sedol in the complex game of Go.", "token2charspan": [[0, 5], [6, 9], [10, 21], [22, 24], [25, 31], [31, 32], [33, 36], [37, 44], [45, 48], [49, 53], [54, 55], [56, 62], [63, 65], [66, 77], [78, 90], [90, 91], [92, 95], [96, 100], [101, 110], [111, 116], [117, 120], [121, 129], [130, 132], [133, 140], [140, 141], [142, 143], [144, 153], [154, 158], [159, 167], [168, 173], [174, 182], [183, 186], [187, 192], [193, 195], [196, 199], [200, 207], [208, 212], [213, 215], [216, 218], [218, 219]]}
{"doc_key": "ai-dev-9", "ner": [[14, 15, "misc"], [27, 27, "field"], [31, 35, "product"], [52, 53, "misc"], [58, 58, "misc"], [61, 61, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 15, 27, 27, "part-of", "", false, false], [14, 15, 58, 58, "named", "same", false, false], [31, 35, 52, 53, "related-to", "", false, false], [31, 35, 58, 58, "usage", "", false, false], [31, 35, 61, 61, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Representing", "words", "taking", "their", "context", "into", "account", "through", "dense", "vectors", "of", "fixed", "size", "(", "word", "embeddings", ")", "has", "become", "one", "of", "the", "fundamental", "building", "blocks", "in", "several", "NLP", "systems", ".", "An", "unsupervised", "disambiguation", "system", "uses", "the", "similarity", "between", "the", "senses", "of", "words", "in", "a", "fixed", "context", "window", "to", "select", "the", "most", "suitable", "word", "sense", "using", "a", "pre-trained", "word", "embedding", "model", "and", "WordNet", "."], "sentence-detokenized": "Representing words taking their context into account through dense vectors of fixed size (word embeddings) has become one of the fundamental building blocks in several NLP systems. An unsupervised disambiguation system uses the similarity between the senses of words in a fixed context window to select the most suitable word sense using a pre-trained word embedding model and WordNet.", "token2charspan": [[0, 12], [13, 18], [19, 25], [26, 31], [32, 39], [40, 44], [45, 52], [53, 60], [61, 66], [67, 74], [75, 77], [78, 83], [84, 88], [89, 90], [90, 94], [95, 105], [105, 106], [107, 110], [111, 117], [118, 121], [122, 124], [125, 128], [129, 140], [141, 149], [150, 156], [157, 159], [160, 167], [168, 171], [172, 179], [179, 180], [181, 183], [184, 196], [197, 211], [212, 218], [219, 223], [224, 227], [228, 238], [239, 246], [247, 250], [251, 257], [258, 260], [261, 266], [267, 269], [270, 271], [272, 277], [278, 285], [286, 292], [293, 295], [296, 302], [303, 306], [307, 311], [312, 320], [321, 325], [326, 331], [332, 337], [338, 339], [340, 351], [352, 356], [357, 366], [367, 372], [373, 376], [377, 384], [384, 385]]}
{"doc_key": "ai-dev-10", "ner": [[0, 1, "field"], [5, 5, "field"], [7, 8, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 1, "part-of", "", false, false], [7, 8, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "techniques", ",", "both", "supervised", "and", "unsupervised", "learning", ",", "have", "been", "used", "to", "induce", "such", "rules", "automatically", "."], "sentence-detokenized": "Machine learning techniques, both supervised and unsupervised learning, have been used to induce such rules automatically.", "token2charspan": [[0, 7], [8, 16], [17, 27], [27, 28], [29, 33], [34, 44], [45, 48], [49, 61], [62, 70], [70, 71], [72, 76], [77, 81], [82, 86], [87, 89], [90, 96], [97, 101], [102, 107], [108, 121], [121, 122]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1969", ",", "Scheinman", "invented", "the", "Stanford", "arm", ","], "sentence-detokenized": "In 1969, Scheinman invented the Stanford arm,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 27], [28, 31], [32, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-dev-12", "ner": [[2, 3, "metrics"], [8, 11, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "the", "log", "loss", "is", "differentiable", ",", "a", "gradient", "-", "based", "method", "can", "be", "used", "to", "optimise", "the", "model", "."], "sentence-detokenized": "Since the log loss is differentiable, a gradient-based method can be used to optimise the model.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 18], [19, 21], [22, 36], [36, 37], [38, 39], [40, 48], [48, 49], [49, 54], [55, 61], [62, 65], [66, 68], [69, 73], [74, 76], [77, 85], [86, 89], [90, 95], [95, 96]]}
{"doc_key": "ai-dev-13", "ner": [[1, 2, "field"], [6, 6, "algorithm"], [8, 8, "algorithm"], [11, 13, "algorithm"], [16, 17, "field"], [27, 27, "task"], [29, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[6, 6, 16, 17, "part-of", "", false, false], [8, 8, 6, 6, "named", "", false, false], [11, 13, 6, 6, "named", "", false, false], [16, 17, 1, 2, "part-of", "subfield", false, false], [27, 27, 16, 17, "part-of", "", false, false], [29, 30, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "machine", "learning", ",", "support", "vector", "machines", "(", "SVMs", ",", "also", "support", "vector", "networks", ")", "are", "supervised", "learning", "models", "with", "learning", "algorithms", "that", "analyse", "data", "used", "for", "classification", "and", "regression", "analysis", "."], "sentence-detokenized": "In machine learning, support vector machines (SVMs, also support vector networks) are supervised learning models with learning algorithms that analyse data used for classification and regression analysis.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 28], [29, 35], [36, 44], [45, 46], [46, 50], [50, 51], [52, 56], [57, 64], [65, 71], [72, 80], [80, 81], [82, 85], [86, 96], [97, 105], [106, 112], [113, 117], [118, 126], [127, 137], [138, 142], [143, 150], [151, 155], [156, 160], [161, 164], [165, 179], [180, 183], [184, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-dev-14", "ner": [[9, 10, "task"], [12, 12, "task"], [29, 29, "metrics"], [31, 31, "metrics"], [33, 33, "researcher"], [35, 35, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 12, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "2002", ")", "as", "an", "automatic", "metric", "for", "evaluating", "machine", "translation", "(", "MT", ")", ",", "many", "other", "methods", "have", "been", "proposed", "to", "revise", "or", "improve", "it", ",", "such", "as", "TER", ",", "METEOR", ",", "Banerjee", "and", "Lavie", "(", "2005", ")", "etc", "."], "sentence-detokenized": "(2002) as an automatic metric for evaluating machine translation (MT), many other methods have been proposed to revise or improve it, such as TER, METEOR, Banerjee and Lavie (2005) etc.", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 9], [10, 12], [13, 22], [23, 29], [30, 33], [34, 44], [45, 52], [53, 64], [65, 66], [66, 68], [68, 69], [69, 70], [71, 75], [76, 81], [82, 89], [90, 94], [95, 99], [100, 108], [109, 111], [112, 118], [119, 121], [122, 129], [130, 132], [132, 133], [134, 138], [139, 141], [142, 145], [145, 146], [147, 153], [153, 154], [155, 163], [164, 167], [168, 173], [174, 175], [175, 179], [179, 180], [181, 184], [184, 185]]}
{"doc_key": "ai-dev-15", "ner": [[3, 4, "misc"], [9, 9, "organisation"], [10, 10, "organisation"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 10, 10, "origin", "", false, false], [10, 10, 9, 9, "part-of", "", false, false], [16, 17, 10, 10, "role", "", false, false], [19, 20, 10, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "includes", "a", "superior", "ontology", ",", "created", "by", "the", "IEEE", "P1600.1", "working", "group", "(", "originally", "by", "Ian", "Niles", "and", "Adam", "Pease", ")", "."], "sentence-detokenized": "It includes a superior ontology, created by the IEEE P1600.1 working group (originally by Ian Niles and Adam Pease).", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 22], [23, 31], [31, 32], [33, 40], [41, 43], [44, 47], [48, 52], [53, 60], [61, 68], [69, 74], [75, 76], [76, 86], [87, 89], [90, 93], [94, 99], [100, 103], [104, 108], [109, 114], [114, 115], [115, 116]]}
{"doc_key": "ai-dev-16", "ner": [[1, 3, "misc"], [33, 35, "algorithm"], [37, 38, "algorithm"], [41, 42, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[33, 35, 1, 3, "part-of", "", true, false], [37, 38, 1, 3, "part-of", "", true, false], [41, 42, 37, 38, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "cryogenic", "electron", "tomography", ",", "where", "a", "limited", "number", "of", "projections", "are", "acquired", "due", "to", "hardware", "limitations", "and", "to", "avoid", "damage", "to", "the", "biological", "sample", ",", "it", "can", "be", "used", "in", "conjunction", "with", "compressive", "sensing", "techniques", "or", "regularisation", "functions", "(", "e.g.", "Huber", "loss", ")", "to", "improve", "reconstruction", "for", "better", "interpretation", "."], "sentence-detokenized": "In cryogenic electron tomography, where a limited number of projections are acquired due to hardware limitations and to avoid damage to the biological sample, it can be used in conjunction with compressive sensing techniques or regularisation functions (e.g. Huber loss) to improve reconstruction for better interpretation.", "token2charspan": [[0, 2], [3, 12], [13, 21], [22, 32], [32, 33], [34, 39], [40, 41], [42, 49], [50, 56], [57, 59], [60, 71], [72, 75], [76, 84], [85, 88], [89, 91], [92, 100], [101, 112], [113, 116], [117, 119], [120, 125], [126, 132], [133, 135], [136, 139], [140, 150], [151, 157], [157, 158], [159, 161], [162, 165], [166, 168], [169, 173], [174, 176], [177, 188], [189, 193], [194, 205], [206, 213], [214, 224], [225, 227], [228, 242], [243, 252], [253, 254], [254, 258], [259, 264], [265, 269], [269, 270], [271, 273], [274, 281], [282, 296], [297, 300], [301, 307], [308, 322], [322, 323]]}
{"doc_key": "ai-dev-17", "ner": [[4, 4, "misc"], [7, 7, "programlang"], [10, 10, "algorithm"], [11, 14, "algorithm"], [18, 19, "algorithm"], [25, 27, "product"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 4, 7, 7, "part-of", "", false, false], [10, 10, 4, 4, "type-of", "", false, false], [11, 14, 4, 4, "type-of", "", false, false], [18, 19, 4, 4, "type-of", "", false, false], [25, 27, 7, 7, "general-affiliation", "", true, false], [25, 27, 7, 7, "part-of", "", true, false], [30, 30, 25, 27, "role", "publishes", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["An", "implementation", "of", "several", "bleaching", "procedures", "in", "R", ",", "including", "ZCA", "bleaching", "and", "PCA", "bleaching", ",", "but", "also", "CCA", "bleaching", ",", "is", "available", "in", "the", "R", "whitening", "package", "published", "in", "CRAN", "."], "sentence-detokenized": "An implementation of several bleaching procedures in R, including ZCA bleaching and PCA bleaching, but also CCA bleaching, is available in the R whitening package published in CRAN.", "token2charspan": [[0, 2], [3, 17], [18, 20], [21, 28], [29, 38], [39, 49], [50, 52], [53, 54], [54, 55], [56, 65], [66, 69], [70, 79], [80, 83], [84, 87], [88, 97], [97, 98], [99, 102], [103, 107], [108, 111], [112, 121], [121, 122], [123, 125], [126, 135], [136, 138], [139, 142], [143, 144], [145, 154], [155, 162], [163, 172], [173, 175], [176, 180], [180, 181]]}
{"doc_key": "ai-dev-18", "ner": [[31, 31, "product"], [33, 33, "product"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [41, 41, "product"], [45, 46, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[31, 31, 35, 35, "compare", "", false, false], [31, 31, 37, 37, "compare", "", false, false], [31, 31, 39, 39, "compare", "", false, false], [31, 31, 41, 41, "compare", "", false, false], [31, 31, 45, 46, "compare", "", false, false], [33, 33, 35, 35, "compare", "", false, false], [33, 33, 37, 37, "compare", "", false, false], [33, 33, 39, 39, "compare", "", false, false], [33, 33, 41, 41, "compare", "", false, false], [33, 33, 45, 46, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Today", ",", "the", "field", "has", "become", "even", "more", "daunting", "and", "complex", "with", "the", "addition", "of", "languages", "and", "software", "for", "the", "analysis", "and", "design", "of", "circuits", ",", "systems", "and", "signals", ",", "from", "MATLAB", "and", "Simulink", "to", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "and", "even", "the", "Assembly", "language", "."], "sentence-detokenized": "Today, the field has become even more daunting and complex with the addition of languages and software for the analysis and design of circuits, systems and signals, from MATLAB and Simulink to NumPy, VHDL, PSpice, Verilog and even the Assembly language.", "token2charspan": [[0, 5], [5, 6], [7, 10], [11, 16], [17, 20], [21, 27], [28, 32], [33, 37], [38, 46], [47, 50], [51, 58], [59, 63], [64, 67], [68, 76], [77, 79], [80, 89], [90, 93], [94, 102], [103, 106], [107, 110], [111, 119], [120, 123], [124, 130], [131, 133], [134, 142], [142, 143], [144, 151], [152, 155], [156, 163], [163, 164], [165, 169], [170, 176], [177, 180], [181, 189], [190, 192], [193, 198], [198, 199], [200, 204], [204, 205], [206, 212], [212, 213], [214, 221], [222, 225], [226, 230], [231, 234], [235, 243], [244, 252], [252, 253]]}
{"doc_key": "ai-dev-19", "ner": [[5, 6, "person"], [13, 14, "person"], [15, 17, "organisation"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 17, 13, 14, "origin", "", false, false], [21, 21, 15, 17, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "company", "was", "founded", "by", "Kiichiro", "Toyoda", "in", "1937", "as", "a", "spinoff", "of", "Sakichi", "Toyoda", "'s", "Toyota", "Industries", "company", "to", "create", "automobiles", "."], "sentence-detokenized": "The company was founded by Kiichiro Toyoda in 1937 as a spinoff of Sakichi Toyoda's Toyota Industries company to create automobiles.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 35], [36, 42], [43, 45], [46, 50], [51, 53], [54, 55], [56, 63], [64, 66], [67, 74], [75, 81], [81, 83], [84, 90], [91, 101], [102, 109], [110, 112], [113, 119], [120, 131], [131, 132]]}
{"doc_key": "ai-dev-20", "ner": [[0, 1, "field"], [54, 55, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[54, 55, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Unsupervised", "learning", ",", "on", "the", "other", "hand", ",", "takes", "training", "data", "that", "has", "not", "been", "labelled", "by", "hand", "and", "tries", "to", "find", "intrinsic", "patterns", "in", "the", "data", "that", "can", "be", "used", "to", "determine", "the", "correct", "output", "value", "for", "new", "data", "instances", ".", "A", "combination", "of", "these", "two", "methods", "that", "has", "recently", "been", "explored", "is", "semi-supervised", "learning", ",", "which", "uses", "a", "combination", "of", "labelled", "and", "unlabelled", "data", "(", "typically", "a", "small", "set", "of", "labelled", "data", "combined", "with", "a", "large", "amount", "of", "unlabelled", "data", ")", "."], "sentence-detokenized": "Unsupervised learning, on the other hand, takes training data that has not been labelled by hand and tries to find intrinsic patterns in the data that can be used to determine the correct output value for new data instances. A combination of these two methods that has recently been explored is semi-supervised learning, which uses a combination of labelled and unlabelled data (typically a small set of labelled data combined with a large amount of unlabelled data).", "token2charspan": [[0, 12], [13, 21], [21, 22], [23, 25], [26, 29], [30, 35], [36, 40], [40, 41], [42, 47], [48, 56], [57, 61], [62, 66], [67, 70], [71, 74], [75, 79], [80, 88], [89, 91], [92, 96], [97, 100], [101, 106], [107, 109], [110, 114], [115, 124], [125, 133], [134, 136], [137, 140], [141, 145], [146, 150], [151, 154], [155, 157], [158, 162], [163, 165], [166, 175], [176, 179], [180, 187], [188, 194], [195, 200], [201, 204], [205, 208], [209, 213], [214, 223], [223, 224], [225, 226], [227, 238], [239, 241], [242, 247], [248, 251], [252, 259], [260, 264], [265, 268], [269, 277], [278, 282], [283, 291], [292, 294], [295, 310], [311, 319], [319, 320], [321, 326], [327, 331], [332, 333], [334, 345], [346, 348], [349, 357], [358, 361], [362, 372], [373, 377], [378, 379], [379, 388], [389, 390], [391, 396], [397, 400], [401, 403], [404, 412], [413, 417], [418, 426], [427, 431], [432, 433], [434, 439], [440, 446], [447, 449], [450, 460], [461, 465], [465, 466], [466, 467]]}
{"doc_key": "ai-dev-21", "ner": [[20, 20, "organisation"], [22, 22, "product"], [24, 25, "organisation"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 20, 20, "artifact", "", false, false], [24, 25, 27, 27, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Although", "these", "humanoid", "robots", "are", "intended", "for", "utilitarian", "uses", ",", "there", "are", "some", "that", "aim", "at", "entertainment", ",", "such", "as", "Sony", "'s", "QRIO", "and", "Wow", "Wee", "'s", "RoboSapien", "."], "sentence-detokenized": "Although these humanoid robots are intended for utilitarian uses, there are some that aim at entertainment, such as Sony's QRIO and Wow Wee's RoboSapien.", "token2charspan": [[0, 8], [9, 14], [15, 23], [24, 30], [31, 34], [35, 43], [44, 47], [48, 59], [60, 64], [64, 65], [66, 71], [72, 75], [76, 80], [81, 85], [86, 89], [90, 92], [93, 106], [106, 107], [108, 112], [113, 115], [116, 120], [120, 122], [123, 127], [128, 131], [132, 135], [136, 139], [139, 141], [142, 152], [152, 153]]}
{"doc_key": "ai-dev-22", "ner": [[0, 0, "researcher"], [6, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 12, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Webber", "became", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "in", "1991", ","], "sentence-detokenized": "Webber became a Fellow of the Association for the Advancement of Artificial Intelligence in 1991,", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 49], [50, 61], [62, 64], [65, 75], [76, 88], [89, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-dev-23", "ner": [[6, 6, "field"], [8, 8, "field"], [20, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 23, 6, 6, "part-of", "task_part_of_field", false, false], [20, 23, 8, 8, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["With", "this", "company", ",", "he", "developed", "data-mining", "and", "database", "technologies", ",", "in", "particular", "high", "-", "level", "ontologies", "for", "intelligence", "and", "automatic", "natural", "language", "understanding", "."], "sentence-detokenized": "With this company, he developed data-mining and database technologies, in particular high-level ontologies for intelligence and automatic natural language understanding.", "token2charspan": [[0, 4], [5, 9], [10, 17], [17, 18], [19, 21], [22, 31], [32, 43], [44, 47], [48, 56], [57, 69], [69, 70], [71, 73], [74, 84], [85, 89], [89, 90], [90, 95], [96, 106], [107, 110], [111, 123], [124, 127], [128, 137], [138, 145], [146, 154], [155, 168], [168, 169]]}
{"doc_key": "ai-dev-24", "ner": [[24, 24, "misc"], [26, 29, "misc"], [32, 33, "misc"], [35, 35, "country"], [38, 40, "organisation"], [42, 42, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[24, 24, 35, 35, "physical", "", false, false], [26, 29, 35, 35, "physical", "", false, false], [32, 33, 35, 35, "physical", "", false, false], [38, 40, 42, 42, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["However", ",", "in", "recent", "years", ",", "one", "can", "observe", "the", "emergence", "of", "various", "e-services", "and", "related", "initiatives", "in", "developing", "countries", ",", "such", "as", "Project", "Nemmadi", ",", "Project", "MCA21", "Mission", "Mode", "or", "even", "Digital", "India", "in", "India", ";", "the", "Electronic", "Government", "Directorate", "in", "Pakistan", ",", "etc."], "sentence-detokenized": "However, in recent years, one can observe the emergence of various e-services and related initiatives in developing countries, such as Project Nemmadi, Project MCA21 Mission Mode or even Digital India in India; the Electronic Government Directorate in Pakistan, etc.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 18], [19, 24], [24, 25], [26, 29], [30, 33], [34, 41], [42, 45], [46, 55], [56, 58], [59, 66], [67, 77], [78, 81], [82, 89], [90, 101], [102, 104], [105, 115], [116, 125], [125, 126], [127, 131], [132, 134], [135, 142], [143, 150], [150, 151], [152, 159], [160, 165], [166, 173], [174, 178], [179, 181], [182, 186], [187, 194], [195, 200], [201, 203], [204, 209], [209, 210], [211, 214], [215, 225], [226, 236], [237, 248], [249, 251], [252, 260], [260, 261], [262, 266]]}
{"doc_key": "ai-dev-25", "ner": [[3, 3, "misc"], [5, 5, "field"], [7, 8, "field"], [10, 12, "university"], [16, 18, "university"], [26, 28, "university"], [32, 32, "misc"], [34, 35, "field"], [39, 39, "misc"], [41, 43, "university"], [45, 47, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 3, 5, 5, "topic", "", false, false], [3, 3, 7, 8, "topic", "", false, false], [3, 3, 10, 12, "origin", "", false, false], [10, 12, 16, 18, "part-of", "", false, false], [26, 28, 10, 12, "part-of", "", false, false], [32, 32, 34, 35, "topic", "", false, false], [32, 32, 41, 43, "origin", "", false, false], [39, 39, 41, 43, "origin", "", false, false], [41, 43, 45, 47, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["He", "received", "a", "PhD", "in", "Radiophysics", "and", "Electronics", "from", "the", "Rajabazar", "Science", "College", "campus", "of", "the", "University", "of", "Calcutta", "in", "1979", "as", "a", "student", "of", "the", "Indian", "Statistical", "Institute", ",", "and", "another", "PhD", "in", "Electrical", "Engineering", "along", "with", "a", "Diploma", "from", "Imperial", "College", "at", "the", "University", "of", "London", "in", "1982", "."], "sentence-detokenized": "He received a PhD in Radiophysics and Electronics from the Rajabazar Science College campus of the University of Calcutta in 1979 as a student of the Indian Statistical Institute, and another PhD in Electrical Engineering along with a Diploma from Imperial College at the University of London in 1982.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 17], [18, 20], [21, 33], [34, 37], [38, 49], [50, 54], [55, 58], [59, 68], [69, 76], [77, 84], [85, 91], [92, 94], [95, 98], [99, 109], [110, 112], [113, 121], [122, 124], [125, 129], [130, 132], [133, 134], [135, 142], [143, 145], [146, 149], [150, 156], [157, 168], [169, 178], [178, 179], [180, 183], [184, 191], [192, 195], [196, 198], [199, 209], [210, 221], [222, 227], [228, 232], [233, 234], [235, 242], [243, 247], [248, 256], [257, 264], [265, 267], [268, 271], [272, 282], [283, 285], [286, 292], [293, 295], [296, 300], [300, 301]]}
{"doc_key": "ai-dev-26", "ner": [[14, 18, "location"], [19, 21, "misc"], [28, 29, "misc"], [31, 33, "person"], [35, 36, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 21, 14, 18, "temporal", "", false, false], [28, 29, 14, 18, "temporal", "", false, false], [31, 33, 28, 29, "role", "actor_in", false, false], [35, 36, 28, 29, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["World", "premieres", "of", "several", "never", "-", "before", "-", "seen", "films", "in", "3D", "were", "announced", "at", "Expo", "II", ",", "including", "The", "Diamond", "Wizard", "and", "Universal", "'s", "short", "film", ",", "Hawaiian", "Nights", "starring", "Mamie", "Van", "Doren", "and", "Pinky", "Lee", "."], "sentence-detokenized": "World premieres of several never-before-seen films in 3D were announced at Expo II, including The Diamond Wizard and Universal's short film, Hawaiian Nights starring Mamie Van Doren and Pinky Lee.", "token2charspan": [[0, 5], [6, 15], [16, 18], [19, 26], [27, 32], [32, 33], [33, 39], [39, 40], [40, 44], [45, 50], [51, 53], [54, 56], [57, 61], [62, 71], [72, 74], [75, 79], [80, 82], [82, 83], [84, 93], [94, 97], [98, 105], [106, 112], [113, 116], [117, 126], [126, 128], [129, 134], [135, 139], [139, 140], [141, 149], [150, 156], [157, 165], [166, 171], [172, 175], [176, 181], [182, 185], [186, 191], [192, 195], [195, 196]]}
{"doc_key": "ai-dev-27", "ner": [[7, 8, "researcher"], [16, 20, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 16, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "maximum", "subarray", "problem", "was", "proposed", "by", "Ulf", "Grenander", "in", "1977", "as", "a", "simplified", "model", "for", "estimating", "the", "maximum", "likelihood", "of", "patterns", "in", "digitised", "images", "."], "sentence-detokenized": "The maximum subarray problem was proposed by Ulf Grenander in 1977 as a simplified model for estimating the maximum likelihood of patterns in digitised images.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 28], [29, 32], [33, 41], [42, 44], [45, 48], [49, 58], [59, 61], [62, 66], [67, 69], [70, 71], [72, 82], [83, 88], [89, 92], [93, 103], [104, 107], [108, 115], [116, 126], [127, 129], [130, 138], [139, 141], [142, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-dev-28", "ner": [[1, 2, "product"], [4, 5, "product"], [8, 9, "product"], [12, 12, "product"], [14, 16, "product"], [18, 21, "product"], [34, 34, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[34, 34, 1, 2, "part-of", "", false, false], [34, 34, 4, 5, "part-of", "", false, false], [34, 34, 8, 9, "part-of", "", false, false], [34, 34, 12, 12, "part-of", "", false, false], [34, 34, 14, 16, "part-of", "", false, false], [34, 34, 18, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "iPhone", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", ",", "iPod", "Touch", "5", "G", "and", "later", "are", "all", "equipped", "with", "a", "more", "advanced", "voice", "assistant", "called", "Siri", "."], "sentence-detokenized": "The iPhone 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G, iPod Touch 5G and later are all equipped with a more advanced voice assistant called Siri.", "token2charspan": [[0, 3], [4, 10], [11, 13], [13, 14], [15, 19], [20, 21], [21, 22], [23, 27], [28, 32], [33, 35], [35, 36], [37, 41], [42, 45], [45, 46], [47, 51], [52, 55], [56, 58], [58, 59], [60, 64], [65, 70], [71, 72], [72, 73], [74, 77], [78, 83], [84, 87], [88, 91], [92, 100], [101, 105], [106, 107], [108, 112], [113, 121], [122, 127], [128, 137], [138, 144], [145, 149], [149, 150]]}
{"doc_key": "ai-dev-29", "ner": [[7, 8, "metrics"], [11, 14, "metrics"], [16, 20, "metrics"], [37, 39, "metrics"], [45, 48, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 14, 37, 39, "named", "", false, false], [16, 20, 11, 14, "named", "", false, false], [37, 39, 45, 48, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["It", "is", "easy", "to", "verify", "that", "the", "logistic", "loss", "and", "the", "binary", "cross", "-entropy", "loss", "(", "log", "loss", ")", "are", "in", "fact", "equal", "(", "up", "to", "a", "multiplicative", "constant", "math", "\\", "frac", "{", "1", "}", "{", "The", "cross", "-entropy", "loss", "is", "closely", "related", "to", "the", "Kullback", "-", "Leibler", "divergence", "between", "the", "empirical", "and", "the", "predicted", "distribution", "."], "sentence-detokenized": "It is easy to verify that the logistic loss and the binary cross-entropy loss (log loss) are in fact equal (up to a multiplicative constant math\\ frac {1} {The cross-entropy loss is closely related to the Kullback-Leibler divergence between the empirical and the predicted distribution.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 20], [21, 25], [26, 29], [30, 38], [39, 43], [44, 47], [48, 51], [52, 58], [59, 64], [64, 72], [73, 77], [78, 79], [79, 82], [83, 87], [87, 88], [89, 92], [93, 95], [96, 100], [101, 106], [107, 108], [108, 110], [111, 113], [114, 115], [116, 130], [131, 139], [140, 144], [144, 145], [146, 150], [151, 152], [152, 153], [153, 154], [155, 156], [156, 159], [160, 165], [165, 173], [174, 178], [179, 181], [182, 189], [190, 197], [198, 200], [201, 204], [205, 213], [213, 214], [214, 221], [222, 232], [233, 240], [241, 244], [245, 254], [255, 258], [259, 262], [263, 272], [273, 285], [285, 286]]}
{"doc_key": "ai-dev-30", "ner": [[1, 2, "algorithm"], [8, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 1, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "EM", "algorithm", "is", "used", "to", "find", "the", "maximum", "likelihood", "(", "local", ")", "parameters", "of", "a", "statistical", "model", "in", "cases", "where", "the", "equations", "can", "not", "be", "solved", "directly", "."], "sentence-detokenized": "The EM algorithm is used to find the maximum likelihood (local) parameters of a statistical model in cases where the equations cannot be solved directly.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 32], [33, 36], [37, 44], [45, 55], [56, 57], [57, 62], [62, 63], [64, 74], [75, 77], [78, 79], [80, 91], [92, 97], [98, 100], [101, 106], [107, 112], [113, 116], [117, 126], [127, 130], [130, 133], [134, 136], [137, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-dev-31", "ner": [[9, 10, "task"], [13, 17, "task"], [23, 23, "task"], [22, 25, "task"], [32, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "research", "was", "fundamental", "to", "the", "development", "of", "modern", "speech", "synthesis", "techniques", ",", "reading", "machines", "for", "the", "blind", ",", "the", "study", "of", "speech", "perception", "and", "recognition", ",", "and", "the", "development", "of", "the", "motor", "theory", "of", "speech", "perception", "."], "sentence-detokenized": "This research was fundamental to the development of modern speech synthesis techniques, reading machines for the blind, the study of speech perception and recognition, and the development of the motor theory of speech perception.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 29], [30, 32], [33, 36], [37, 48], [49, 51], [52, 58], [59, 65], [66, 75], [76, 86], [86, 87], [88, 95], [96, 104], [105, 108], [109, 112], [113, 118], [118, 119], [120, 123], [124, 129], [130, 132], [133, 139], [140, 150], [151, 154], [155, 166], [166, 167], [168, 171], [172, 175], [176, 187], [188, 190], [191, 194], [195, 200], [201, 207], [208, 210], [211, 217], [218, 228], [228, 229]]}
{"doc_key": "ai-dev-32", "ner": [[1, 1, "product"], [2, 4, "misc"], [6, 6, "misc"], [10, 12, "misc"], [15, 15, "product"], [17, 17, "product"], [19, 19, "product"], [24, 24, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 1, 1, "origin", "", false, false], [2, 4, 10, 12, "type-of", "", false, false], [2, 4, 15, 15, "related-to", "program_for", false, false], [2, 4, 17, 17, "related-to", "program_for", false, false], [2, 4, 19, 19, "related-to", "program_for", false, false], [2, 4, 24, 24, "related-to", "program_for", false, false], [6, 6, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "Arduino", "integrated", "development", "environment", "(", "IDE", ")", "is", "a", "cross", "-platform", "application", "(", "for", "Windows", ",", "macOS", "and", "Linux", ")", "written", "in", "the", "Java", "programming", "language", "."], "sentence-detokenized": "The Arduino integrated development environment (IDE) is a cross-platform application (for Windows, macOS and Linux) written in the Java programming language.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 57], [58, 63], [63, 72], [73, 84], [85, 86], [86, 89], [90, 97], [97, 98], [99, 104], [105, 108], [109, 114], [114, 115], [116, 123], [124, 126], [127, 130], [131, 135], [136, 147], [148, 156], [156, 157]]}
{"doc_key": "ai-dev-33", "ner": [[0, 1, "algorithm"], [9, 10, "field"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 9, 10, "opposite", "", false, false], [13, 14, 9, 10, "related-to", "works_with", false, false], [16, 17, 9, 10, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Neural", "network", "research", "stagnated", "after", "the", "publication", "of", "the", "machine", "learning", "research", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", "."], "sentence-detokenized": "Neural network research stagnated after the publication of the machine learning research of Marvin Minsky and Seymour Papert (1969).", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 33], [34, 39], [40, 43], [44, 55], [56, 58], [59, 62], [63, 70], [71, 79], [80, 88], [89, 91], [92, 98], [99, 105], [106, 109], [110, 117], [118, 124], [125, 126], [126, 130], [130, 131], [131, 132]]}
{"doc_key": "ai-dev-34", "ner": [[18, 19, "organisation"], [21, 21, "organisation"], [24, 26, "country"], [28, 31, "organisation"], [34, 34, "country"], [36, 37, "organisation"], [40, 40, "country"], [42, 42, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[28, 31, 24, 26, "general-affiliation", "", false, false], [36, 37, 34, 34, "general-affiliation", "", false, false], [42, 42, 40, 40, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Only", "a", "few", "non-Japanese", "companies", "have", "managed", "to", "survive", "in", "this", "market", ",", "the", "main", "ones", "being", ":", "Adept", "Technology", ",", "St\u00e4ubli", ",", "the", "Swedish", "-", "Swiss", "company", "ABB", "Asea", "Brown", "Boveri", ",", "the", "German", "company", "KUKA", "Robotics", "and", "the", "Italian", "company", "Comau", "."], "sentence-detokenized": "Only a few non-Japanese companies have managed to survive in this market, the main ones being: Adept Technology, St\u00e4ubli, the Swedish-Swiss company ABB Asea Brown Boveri, the German company KUKA Robotics and the Italian company Comau.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 23], [24, 33], [34, 38], [39, 46], [47, 49], [50, 57], [58, 60], [61, 65], [66, 72], [72, 73], [74, 77], [78, 82], [83, 87], [88, 93], [93, 94], [95, 100], [101, 111], [111, 112], [113, 120], [120, 121], [122, 125], [126, 133], [133, 134], [134, 139], [140, 147], [148, 151], [152, 156], [157, 162], [163, 169], [169, 170], [171, 174], [175, 181], [182, 189], [190, 194], [195, 203], [204, 207], [208, 211], [212, 219], [220, 227], [228, 233], [233, 234]]}
{"doc_key": "ai-dev-35", "ner": [[8, 9, "conference"], [14, 14, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 14, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Research", "activities", "include", "an", "annual", "conference", ",", "the", "RuleML", "Symposium", ",", "also", "known", "as", "RuleML", "."], "sentence-detokenized": "Research activities include an annual conference, the RuleML Symposium, also known as RuleML.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 30], [31, 37], [38, 48], [48, 49], [50, 53], [54, 60], [61, 70], [70, 71], [72, 76], [77, 82], [83, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-dev-36", "ner": [[9, 9, "field"], [11, 12, "field"], [14, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Concepts", "are", "used", "as", "tools", "or", "formal", "models", "in", "mathematics", ",", "computer", "science", ",", "databases", "and", "artificial", "intelligence", ",", "where", "they", "are", "sometimes", "called", "classes", ",", "schemes", "or", "categories", "."], "sentence-detokenized": "Concepts are used as tools or formal models in mathematics, computer science, databases and artificial intelligence, where they are sometimes called classes, schemes or categories.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 26], [27, 29], [30, 36], [37, 43], [44, 46], [47, 58], [58, 59], [60, 68], [69, 76], [76, 77], [78, 87], [88, 91], [92, 102], [103, 115], [115, 116], [117, 122], [123, 127], [128, 131], [132, 141], [142, 148], [149, 156], [156, 157], [158, 165], [166, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-dev-37", "ner": [[6, 8, "organisation"], [11, 14, "organisation"], [17, 17, "organisation"], [19, 21, "organisation"], [24, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "been", "honoured", "by", "the", "American", "Psychological", "Association", ",", "the", "National", "Academy", "of", "Sciences", ",", "the", "Royal", ",", "Cognitive", "Neuroscience", "Society", "and", "the", "American", "Humanist", "Association", "."], "sentence-detokenized": "He has been honoured by the American Psychological Association, the National Academy of Sciences, the Royal, Cognitive Neuroscience Society and the American Humanist Association.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 23], [24, 27], [28, 36], [37, 50], [51, 62], [62, 63], [64, 67], [68, 76], [77, 84], [85, 87], [88, 96], [96, 97], [98, 101], [102, 107], [107, 108], [109, 118], [119, 131], [132, 139], [140, 143], [144, 147], [148, 156], [157, 165], [166, 177], [177, 178]]}
{"doc_key": "ai-dev-38", "ner": [[1, 2, "person"], [4, 5, "person"], [7, 8, "person"], [15, 18, "person"], [21, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 27, 15, 18, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starring", "Harrison", "Ford", ",", "Rutger", "Hauer", "and", "Sean", "Young", ",", "it", "is", "loosely", "based", "on", "Philip", "K", ".", "Dick", "'s", "novel", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "?", "(", "1968", ")", "."], "sentence-detokenized": "Starring Harrison Ford, Rutger Hauer and Sean Young, it is loosely based on Philip K. Dick's novel Do Androids Dream of Electric Sheep? (1968).", "token2charspan": [[0, 8], [9, 17], [18, 22], [22, 23], [24, 30], [31, 36], [37, 40], [41, 45], [46, 51], [51, 52], [53, 55], [56, 58], [59, 66], [67, 72], [73, 75], [76, 82], [83, 84], [84, 85], [86, 90], [90, 92], [93, 98], [99, 101], [102, 110], [111, 116], [117, 119], [120, 128], [129, 134], [134, 135], [136, 137], [137, 141], [141, 142], [142, 143]]}
{"doc_key": "ai-dev-39", "ner": [[0, 1, "task"], [3, 5, "algorithm"], [11, 12, "field"], [14, 15, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 3, 5, "usage", "", false, false], [0, 1, 11, 12, "part-of", "task_part_of_field", false, false], [0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Image", "segmentation", "using", "k-means", "clustering", "algorithms", "has", "long", "been", "used", "for", "pattern", "recognition", ",", "object", "detection", "and", "medical", "imaging", "."], "sentence-detokenized": "Image segmentation using k-means clustering algorithms has long been used for pattern recognition, object detection and medical imaging.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 32], [33, 43], [44, 54], [55, 58], [59, 63], [64, 68], [69, 73], [74, 77], [78, 85], [86, 97], [97, 98], [99, 105], [106, 115], [116, 119], [120, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-dev-40", "ner": [[12, 12, "algorithm"], [16, 17, "algorithm"], [20, 20, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["General", "sampling", "from", "truncated", "normals", "can", "be", "achieved", "using", "approximations", "to", "the", "CDF", "normal", "and", "the", "probit", "function", ",", "and", "R", "has", "a", "codertnorm", "(", ")", "/", "code", "function", "to", "generate", "samples", "of", "truncated", "normals", "."], "sentence-detokenized": "General sampling from truncated normals can be achieved using approximations to the CDF normal and the probit function, and R has a codertnorm () / code function to generate samples of truncated normals.", "token2charspan": [[0, 7], [8, 16], [17, 21], [22, 31], [32, 39], [40, 43], [44, 46], [47, 55], [56, 61], [62, 76], [77, 79], [80, 83], [84, 87], [88, 94], [95, 98], [99, 102], [103, 109], [110, 118], [118, 119], [120, 123], [124, 125], [126, 129], [130, 131], [132, 142], [143, 144], [144, 145], [146, 147], [148, 152], [153, 161], [162, 164], [165, 173], [174, 181], [182, 184], [185, 194], [195, 202], [202, 203]]}
{"doc_key": "ai-dev-41", "ner": [[7, 8, "university"], [10, 11, "university"], [13, 15, "university"], [17, 19, "university"], [21, 22, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "also", "received", "honorary", "doctorates", "from", "Newcastle", "University", ",", "Surrey", "University", ",", "Tel", "Aviv", "University", ",", "Simon", "Fraser", "University", "and", "Troms\u00f8", "University", "."], "sentence-detokenized": "He has also received honorary doctorates from Newcastle University, Surrey University, Tel Aviv University, Simon Fraser University and Troms\u00f8 University.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 29], [30, 40], [41, 45], [46, 55], [56, 66], [66, 67], [68, 74], [75, 85], [85, 86], [87, 90], [91, 95], [96, 106], [106, 107], [108, 113], [114, 120], [121, 131], [132, 135], [136, 142], [143, 153], [153, 154]]}
{"doc_key": "ai-dev-42", "ner": [[1, 1, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "Java", "implementation", "using", "zero", "-", "based", "array", "indices", "and", "a", "practical", "method", "for", "printing", "the", "resolved", "order", "of", "operations", ":"], "sentence-detokenized": "A Java implementation using zero-based array indices and a practical method for printing the resolved order of operations:", "token2charspan": [[0, 1], [2, 6], [7, 21], [22, 27], [28, 32], [32, 33], [33, 38], [39, 44], [45, 52], [53, 56], [57, 58], [59, 68], [69, 75], [76, 79], [80, 88], [89, 92], [93, 101], [102, 107], [108, 110], [111, 121], [121, 122]]}
{"doc_key": "ai-dev-43", "ner": [[9, 10, "metrics"], [13, 14, "metrics"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 14, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Such", "networks", "are", "commonly", "trained", "in", "a", "regime", "of", "cross", "-entropy", "(", "or", "cross", "-entropy", ")", ",", "providing", "a", "non-linear", "variant", "of", "multinomial", "logistic", "regression", "."], "sentence-detokenized": "Such networks are commonly trained in a regime of cross-entropy (or cross-entropy), providing a non-linear variant of multinomial logistic regression.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 26], [27, 34], [35, 37], [38, 39], [40, 46], [47, 49], [50, 55], [55, 63], [64, 65], [65, 67], [68, 73], [73, 81], [81, 82], [82, 83], [84, 93], [94, 95], [96, 106], [107, 114], [115, 117], [118, 129], [130, 138], [139, 149], [149, 150]]}
{"doc_key": "ai-dev-44", "ner": [[1, 1, "conference"], [4, 11, "conference"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "ACL", "has", "a", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", "."], "sentence-detokenized": "The ACL has a European Chapter of the Association for Computational Linguistics.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 13], [14, 22], [23, 30], [31, 33], [34, 37], [38, 49], [50, 53], [54, 67], [68, 79], [79, 80]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 8, "researcher"], [25, 25, "misc"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 25, 25, "role", "", false, false], [6, 8, 25, 25, "role", "", false, false], [25, 25, 27, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "professors", ",", "Hal", "Abelson", "and", "Gerald", "Jay", "Sussman", ",", "chose", "to", "remain", "neutral", ":", "for", "the", "next", "30", "years", "their", "group", "was", "variously", "called", "Switzerland", "and", "Project", "MAC", "."], "sentence-detokenized": "Two professors, Hal Abelson and Gerald Jay Sussman, chose to remain neutral: for the next 30 years their group was variously called Switzerland and Project MAC.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 50], [50, 51], [52, 57], [58, 60], [61, 67], [68, 75], [75, 76], [77, 80], [81, 84], [85, 89], [90, 92], [93, 98], [99, 104], [105, 110], [111, 114], [115, 124], [125, 131], [132, 143], [144, 147], [148, 155], [156, 159], [159, 160]]}
{"doc_key": "ai-dev-46", "ner": [[2, 2, "misc"], [4, 4, "researcher"], [8, 11, "university"], [15, 19, "organisation"], [20, 22, "organisation"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 4, 4, "temporal", "", false, false], [4, 4, 15, 19, "physical", "", false, false], [4, 4, 15, 19, "role", "", false, false], [4, 4, 20, 22, "role", "", false, false], [20, 22, 8, 11, "part-of", "", false, false], [26, 27, 20, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["After", "his", "PhD", ",", "Ghahramani", "moved", "to", "the", "University", "of", "Toronto", "in", "1995", "as", "an", "ITRC", "Postdoctoral", "Fellow", "in", "the", "Artificial", "Intelligence", "Laboratory", ",", "working", "with", "Geoffrey", "Hinton", "."], "sentence-detokenized": "After his PhD, Ghahramani moved to the University of Toronto in 1995 as an ITRC Postdoctoral Fellow in the Artificial Intelligence Laboratory, working with Geoffrey Hinton.", "token2charspan": [[0, 5], [6, 9], [10, 13], [13, 14], [15, 25], [26, 31], [32, 34], [35, 38], [39, 49], [50, 52], [53, 60], [61, 63], [64, 68], [69, 71], [72, 74], [75, 79], [80, 92], [93, 99], [100, 102], [103, 106], [107, 117], [118, 130], [131, 141], [141, 142], [143, 150], [151, 155], [156, 164], [165, 171], [171, 172]]}
{"doc_key": "ai-dev-47", "ner": [[23, 24, "metrics"], [27, 27, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[27, 27, 23, 24, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Subsequent", "work", "focused", "on", "solving", "these", "problems", ",", "but", "it", "was", "only", "with", "the", "advent", "of", "the", "modern", "computer", "and", "the", "spread", "of", "maximum", "likelihood", "parameterisation", "(", "MLE", ")", "techniques", "that", "research", "really", "took", "off", "."], "sentence-detokenized": "Subsequent work focused on solving these problems, but it was only with the advent of the modern computer and the spread of maximum likelihood parameterisation (MLE) techniques that research really took off.", "token2charspan": [[0, 10], [11, 15], [16, 23], [24, 26], [27, 34], [35, 40], [41, 49], [49, 50], [51, 54], [55, 57], [58, 61], [62, 66], [67, 71], [72, 75], [76, 82], [83, 85], [86, 89], [90, 96], [97, 105], [106, 109], [110, 113], [114, 120], [121, 123], [124, 131], [132, 142], [143, 159], [160, 161], [161, 164], [164, 165], [166, 176], [177, 181], [182, 190], [191, 197], [198, 202], [203, 206], [206, 207]]}
{"doc_key": "ai-dev-48", "ner": [[5, 6, "person"], [9, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "series", "was", "produced", "by", "David", "Fincher", "and", "starred", "Kevin", "Spacey", "."], "sentence-detokenized": "The series was produced by David Fincher and starred Kevin Spacey.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 40], [41, 44], [45, 52], [53, 58], [59, 65], [65, 66]]}
{"doc_key": "ai-dev-49", "ner": [[17, 17, "metrics"], [24, 25, "algorithm"], [31, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[24, 25, 31, 33, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Due", "to", "limitations", "in", "computing", "power", ",", "current", "in", "silico", "methods", "usually", "have", "to", "trade", "speed", "for", "accuracy", ";", "for", "example", ",", "using", "fast", "protein", "docking", "methods", "instead", "of", "computationally", "expensive", "free", "energy", "calculations", "."], "sentence-detokenized": "Due to limitations in computing power, current in silico methods usually have to trade speed for accuracy; for example, using fast protein docking methods instead of computationally expensive free energy calculations.", "token2charspan": [[0, 3], [4, 6], [7, 18], [19, 21], [22, 31], [32, 37], [37, 38], [39, 46], [47, 49], [50, 56], [57, 64], [65, 72], [73, 77], [78, 80], [81, 86], [87, 92], [93, 96], [97, 105], [105, 106], [107, 110], [111, 118], [118, 119], [120, 125], [126, 130], [131, 138], [139, 146], [147, 154], [155, 162], [163, 165], [166, 181], [182, 191], [192, 196], [197, 203], [204, 216], [216, 217]]}
{"doc_key": "ai-dev-50", "ner": [[7, 8, "country"], [10, 10, "country"], [12, 12, "country"], [14, 14, "country"], [16, 16, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "had", "over", "30", "locations", "in", "the", "United", "States", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "sentence-detokenized": "It had over 30 locations in the United States, Canada, Mexico, Brazil and Argentina.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 24], [25, 27], [28, 31], [32, 38], [39, 45], [45, 46], [47, 53], [53, 54], [55, 61], [61, 62], [63, 69], [70, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-dev-51", "ner": [[5, 6, "field"], [11, 13, "product"], [15, 17, "algorithm"], [22, 24, "task"], [26, 27, "task"], [32, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 13, 5, 6, "part-of", "", false, false], [11, 13, 15, 17, "usage", "", false, false], [22, 24, 5, 6, "part-of", "task_part_of_field", false, false], [22, 24, 32, 32, "related-to", "performs", false, false], [26, 27, 5, 6, "part-of", "task_part_of_field", false, false], [26, 27, 32, 32, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["An", "example", "of", "a", "typical", "computer", "vision", "calculation", "pipeline", "for", "a", "facial", "recognition", "system", "using", "k", "-", "NN", ",", "including", "pre-processing", "steps", "for", "feature", "extraction", "and", "size", "reduction", "(", "usually", "implemented", "with", "OpenCV", ")", ":"], "sentence-detokenized": "An example of a typical computer vision calculation pipeline for a facial recognition system using k -NN, including pre-processing steps for feature extraction and size reduction (usually implemented with OpenCV):", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 23], [24, 32], [33, 39], [40, 51], [52, 60], [61, 64], [65, 66], [67, 73], [74, 85], [86, 92], [93, 98], [99, 100], [101, 102], [102, 104], [104, 105], [106, 115], [116, 130], [131, 136], [137, 140], [141, 148], [149, 159], [160, 163], [164, 168], [169, 178], [179, 180], [180, 187], [188, 199], [200, 204], [205, 211], [211, 212], [212, 213]]}
{"doc_key": "ai-dev-52", "ner": [[10, 12, "algorithm"], [14, 14, "misc"], [16, 17, "misc"], [21, 21, "programlang"], [23, 23, "product"], [27, 28, "algorithm"], [31, 32, "misc"], [34, 34, "misc"], [36, 38, "misc"], [45, 45, "misc"], [47, 49, "misc"], [50, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "a", "rich", "set", "of", "features", ",", "libraries", "for", "constraint", "logic", "programming", ",", "multithreading", ",", "unit", "tests", ",", "interfacing", "with", "Java", ",", "ODBC", "and", "others", ",", "literal", "programming", ",", "a", "web", "server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "developer", "tools", "(", "including", "an", "IDE", "with", "debugger", "and", "GUI", "profiler", ")", "and", "extensive", "documentation", "."], "sentence-detokenized": "It has a rich set of features, libraries for constraint logic programming, multithreading, unit tests, interfacing with Java, ODBC and others, literal programming, a web server, SGML, RDF, RDFS, developer tools (including an IDE with debugger and GUI profiler) and extensive documentation.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 13], [14, 17], [18, 20], [21, 29], [29, 30], [31, 40], [41, 44], [45, 55], [56, 61], [62, 73], [73, 74], [75, 89], [89, 90], [91, 95], [96, 101], [101, 102], [103, 114], [115, 119], [120, 124], [124, 125], [126, 130], [131, 134], [135, 141], [141, 142], [143, 150], [151, 162], [162, 163], [164, 165], [166, 169], [170, 176], [176, 177], [178, 182], [182, 183], [184, 187], [187, 188], [189, 193], [193, 194], [195, 204], [205, 210], [211, 212], [212, 221], [222, 224], [225, 228], [229, 233], [234, 242], [243, 246], [247, 250], [251, 259], [259, 260], [261, 264], [265, 274], [275, 288], [288, 289]]}
{"doc_key": "ai-dev-53", "ner": [[1, 2, "field"], [4, 5, "field"], [10, 12, "misc"], [14, 16, "misc"], [19, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 1, 2, "part-of", "", true, false], [10, 12, 4, 5, "part-of", "", false, false], [10, 12, 19, 21, "type-of", "", false, false], [14, 16, 1, 2, "part-of", "", false, false], [14, 16, 4, 5, "part-of", "", false, false], [14, 16, 19, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "computer", "vision", "and", "image", "processing", ",", "the", "notion", "of", "scale", "space", "representation", "and", "Gaussian", "derivation", "operators", "are", "a", "canonical", "multiscale", "representation", "."], "sentence-detokenized": "In computer vision and image processing, the notion of scale space representation and Gaussian derivation operators are a canonical multiscale representation.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 22], [23, 28], [29, 39], [39, 40], [41, 44], [45, 51], [52, 54], [55, 60], [61, 66], [67, 81], [82, 85], [86, 94], [95, 105], [106, 115], [116, 119], [120, 121], [122, 131], [132, 142], [143, 157], [157, 158]]}
{"doc_key": "ai-dev-54", "ner": [[10, 10, "organisation"], [6, 24, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 10, 6, 24, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "also", "chairman", "of", "the", "Neural", "Information", "Processing", "Systems", "Foundation", ",", "a", "non-profit", "organisation", "that", "oversees", "the", "annual", "conference", "on", "Neural", "Information", "Processing", "Systems", "."], "sentence-detokenized": "He is also chairman of the Neural Information Processing Systems Foundation, a non-profit organisation that oversees the annual conference on Neural Information Processing Systems.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 19], [20, 22], [23, 26], [27, 33], [34, 45], [46, 56], [57, 64], [65, 75], [75, 76], [77, 78], [79, 89], [90, 102], [103, 107], [108, 116], [117, 120], [121, 127], [128, 138], [139, 141], [142, 148], [149, 160], [161, 171], [172, 179], [179, 180]]}
{"doc_key": "ai-dev-55", "ner": [[1, 2, "task"], [6, 10, "metrics"], [13, 14, "misc"], [23, 23, "task"], [17, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 6, 10, "usage", "", false, false], [6, 10, 13, 14, "type-of", "", false, false], [23, 23, 17, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["For", "regression", "analysis", "problems", ",", "the", "quadratic", "error", "can", "be", "used", "as", "a", "loss", "function", ",", "while", "cross", "entropy", "can", "be", "used", "for", "classification", "."], "sentence-detokenized": "For regression analysis problems, the quadratic error can be used as a loss function, while cross entropy can be used for classification.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 32], [32, 33], [34, 37], [38, 47], [48, 53], [54, 57], [58, 60], [61, 65], [66, 68], [69, 70], [71, 75], [76, 84], [84, 85], [86, 91], [92, 97], [98, 105], [106, 109], [110, 112], [113, 117], [118, 121], [122, 136], [136, 137]]}
{"doc_key": "ai-dev-56", "ner": [[0, 1, "researcher"], [19, 22, "conference"], [30, 30, "university"], [36, 37, "field"], [45, 49, "conference"]], "ner_mapping_to_source": [0, 2, 3, 4, 5], "relations": [[0, 1, 30, 30, "physical", "", false, false], [0, 1, 30, 30, "role", "", false, false], [0, 1, 45, 49, "role", "", false, false], [30, 30, 36, 37, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [1, 2, 3, 5], "sentence": ["Lafferty", "has", "held", "many", "prestigious", "positions", ",", "including", ":", "1", ")", "programme", "co-chair", "and", "general", "conference", "co-chair", "of", "the", "Neural", "Information", "Processing", "Systems", "Foundation", "conferences", ";", "2", ")", "co-director", "of", "CMU", "'s", "new", "PhD", "programme", "in", "Machine", "Learning", ";", "3", ")", "associate", "editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research", "."], "sentence-detokenized": "Lafferty has held many prestigious positions, including: 1) programme co-chair and general conference co-chair of the Neural Information Processing Systems Foundation conferences; 2) co-director of CMU's new PhD programme in Machine Learning; 3) associate editor of the Journal of Machine Learning Research.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 34], [35, 44], [44, 45], [46, 55], [55, 56], [57, 58], [58, 59], [60, 69], [70, 78], [79, 82], [83, 90], [91, 101], [102, 110], [111, 113], [114, 117], [118, 124], [125, 136], [137, 147], [148, 155], [156, 166], [167, 178], [178, 179], [180, 181], [181, 182], [183, 194], [195, 197], [198, 201], [201, 203], [204, 207], [208, 211], [212, 221], [222, 224], [225, 232], [233, 241], [241, 242], [243, 244], [244, 245], [246, 255], [256, 262], [263, 265], [266, 269], [270, 277], [278, 280], [281, 288], [289, 297], [298, 306], [306, 307]]}
{"doc_key": "ai-dev-57", "ner": [[0, 1, "misc"], [5, 5, "algorithm"], [7, 9, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 1, "type-of", "", false, false], [7, 9, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Convex", "algorithms", ",", "such", "as", "AdaBoost", "and", "LogitBoost", ",", "can", "be", "defeated", "by", "random", "noise", ",", "so", "they", "are", "unable", "to", "learn", "fundamental", ",", "learnable", "combinations", "of", "weak", "hypotheses", "."], "sentence-detokenized": "Convex algorithms, such as AdaBoost and LogitBoost, can be defeated by random noise, so they are unable to learn fundamental, learnable combinations of weak hypotheses.", "token2charspan": [[0, 6], [7, 17], [17, 18], [19, 23], [24, 26], [27, 35], [36, 39], [40, 50], [50, 51], [52, 55], [56, 58], [59, 67], [68, 70], [71, 77], [78, 83], [83, 84], [85, 87], [88, 92], [93, 96], [97, 103], [104, 106], [107, 112], [113, 124], [124, 125], [126, 135], [136, 148], [149, 151], [152, 156], [157, 167], [167, 168]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [3, 8, "product"], [11, 14, "algorithm"], [20, 21, "algorithm"], [24, 29, "task"], [31, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 8, "type-of", "", false, false], [0, 0, 11, 14, "usage", "", false, false], [0, 0, 20, 21, "usage", "", false, false], [20, 21, 24, 29, "related-to", "used_for", true, false], [20, 21, 31, 34, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "is", "a", "surface", "-", "transfer", "machine", "translation", "system", "that", "uses", "finite", "-", "state", "transducers", "for", "all", "lexical", "transformations", "and", "hidden", "Markov", "models", "for", "part", "-", "of", "-", "speech", "tagging", "or", "disambiguation", "of", "word", "categories", "."], "sentence-detokenized": "Apertium is a surface-transfer machine translation system that uses finite-state transducers for all lexical transformations and hidden Markov models for part-of-speech tagging or disambiguation of word categories.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 21], [21, 22], [22, 30], [31, 38], [39, 50], [51, 57], [58, 62], [63, 67], [68, 74], [74, 75], [75, 80], [81, 92], [93, 96], [97, 100], [101, 108], [109, 124], [125, 128], [129, 135], [136, 142], [143, 149], [150, 153], [154, 158], [158, 159], [159, 161], [161, 162], [162, 168], [169, 176], [177, 179], [180, 194], [195, 197], [198, 202], [203, 213], [213, 214]]}
{"doc_key": "ai-dev-59", "ner": [[1, 3, "misc"], [14, 17, "metrics"], [31, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 3, 14, 17, "related-to", "", true, false], [14, 17, 31, 32, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "natural", "gradient", "of", "mathE", "f", "(", "x", ")", "/", "math", ",", "conforming", "to", "Fisher", "'s", "information", "metric", "(", "a", "measure", "of", "information", "distance", "between", "probability", "distributions", "and", "the", "curvature", "of", "relative", "entropy", ")", ",", "now", "reads"], "sentence-detokenized": "The natural gradient of mathE f (x) / math, conforming to Fisher's information metric (a measure of information distance between probability distributions and the curvature of relative entropy), now reads", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 23], [24, 29], [30, 31], [32, 33], [33, 34], [34, 35], [36, 37], [38, 42], [42, 43], [44, 54], [55, 57], [58, 64], [64, 66], [67, 78], [79, 85], [86, 87], [87, 88], [89, 96], [97, 99], [100, 111], [112, 120], [121, 128], [129, 140], [141, 154], [155, 158], [159, 162], [163, 172], [173, 175], [176, 184], [185, 192], [192, 193], [193, 194], [195, 198], [199, 204]]}
{"doc_key": "ai-dev-60", "ner": [[1, 3, "programlang"], [6, 9, "product"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 1, 3, "origin", "", false, false], [11, 11, 1, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "S", "programming", "language", "inspired", "the", "S", "'", "-", "PLUS", "and", "R", "systems", "."], "sentence-detokenized": "The S programming language inspired the S '-PLUS and R systems.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 26], [27, 35], [36, 39], [40, 41], [42, 43], [43, 44], [44, 48], [49, 52], [53, 54], [55, 62], [62, 63]]}
{"doc_key": "ai-dev-61", "ner": [[5, 6, "product"], [10, 10, "product"], [13, 15, "product"], [19, 21, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 10, 10, "named", "same", false, false], [13, 15, 10, 10, "origin", "derived_from", false, false], [13, 15, 19, 21, "origin", "", false, false], [13, 15, 23, 24, "origin", "", false, false], [13, 15, 26, 27, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "most", "influential", "implementation", "of", "Planner", "was", "the", "subset", "of", "Planner", ",", "called", "Micro", "-", "Planner", ",", "created", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "."], "sentence-detokenized": "The most influential implementation of Planner was the subset of Planner, called Micro-Planner, created by Gerald Jay Sussman, Eugene Charniak and Terry Winograd.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 35], [36, 38], [39, 46], [47, 50], [51, 54], [55, 61], [62, 64], [65, 72], [72, 73], [74, 80], [81, 86], [86, 87], [87, 94], [94, 95], [96, 103], [104, 106], [107, 113], [114, 117], [118, 125], [125, 126], [127, 133], [134, 142], [143, 146], [147, 152], [153, 161], [161, 162]]}
{"doc_key": "ai-dev-62", "ner": [[4, 6, "country"], [8, 11, "researcher"], [20, 20, "misc"], [21, 26, "university"], [34, 35, "misc"], [42, 43, "misc"], [46, 48, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[8, 11, 4, 6, "general-affiliation", "from_country", false, false], [21, 26, 20, 20, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1779", ",", "the", "German", "-", "Danish", "scientist", "Christian", "Gottlieb", "Kratzenstein", "won", "first", "prize", "in", "a", "competition", "organised", "by", "the", "Russian", "Imperial", "Academy", "of", "Sciences", "and", "Arts", "for", "his", "constructed", "models", "of", "the", "human", "vocal", "tract", "capable", "of", "producing", "the", "five", "long", "vowel", "sounds", "(", "in", "International", "Phonetic", "Alphabet", "notation", ":"], "sentence-detokenized": "In 1779, the German-Danish scientist Christian Gottlieb Kratzenstein won first prize in a competition organised by the Russian Imperial Academy of Sciences and Arts for his constructed models of the human vocal tract capable of producing the five long vowel sounds (in International Phonetic Alphabet notation:", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [19, 20], [20, 26], [27, 36], [37, 46], [47, 55], [56, 68], [69, 72], [73, 78], [79, 84], [85, 87], [88, 89], [90, 101], [102, 111], [112, 114], [115, 118], [119, 126], [127, 135], [136, 143], [144, 146], [147, 155], [156, 159], [160, 164], [165, 168], [169, 172], [173, 184], [185, 191], [192, 194], [195, 198], [199, 204], [205, 210], [211, 216], [217, 224], [225, 227], [228, 237], [238, 241], [242, 246], [247, 251], [252, 257], [258, 264], [265, 266], [266, 268], [269, 282], [283, 291], [292, 300], [301, 309], [309, 310]]}
{"doc_key": "ai-dev-63", "ner": [[3, 4, "product"], [6, 7, "misc"], [10, 14, "misc"], [33, 35, "misc"], [57, 58, "task"], [63, 64, "product"], [66, 66, "product"], [72, 75, "task"], [74, 74, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 4, 63, 64, "related-to", "supports_program", false, false], [3, 4, 66, 66, "related-to", "supports_program", false, false], [6, 7, 3, 4, "part-of", "", false, false], [10, 14, 3, 4, "part-of", "", false, false], [33, 35, 3, 4, "part-of", "", false, false], [57, 58, 3, 4, "part-of", "", false, false], [72, 75, 3, 4, "part-of", "", false, false], [74, 74, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["New", "features", "in", "Office", "XP", "include", "smart", "tags", ",", "a", "selection", "-", "based", "search", "function", "that", "recognises", "different", "types", "of", "text", "in", "a", "document", "so", "that", "users", "can", "perform", "additional", "actions", ";", "a", "task", "pane", "interface", "that", "consolidates", "popular", "menu", "bar", "commands", "on", "the", "right", "-", "hand", "side", "of", "the", "screen", "for", "easy", "quick", "access", ";", "new", "document", "collaboration", "capabilities", ";", "support", "for", "MSN", "Groups", "and", "SharePoint", ";", "and", "built", "-", "in", "handwriting", "and", "speech", "recognition", "capabilities", "."], "sentence-detokenized": "New features in Office XP include smart tags, a selection-based search function that recognises different types of text in a document so that users can perform additional actions; a task pane interface that consolidates popular menu bar commands on the right-hand side of the screen for easy quick access; new document collaboration capabilities; support for MSN Groups and SharePoint; and built-in handwriting and speech recognition capabilities.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 25], [26, 33], [34, 39], [40, 44], [44, 45], [46, 47], [48, 57], [57, 58], [58, 63], [64, 70], [71, 79], [80, 84], [85, 95], [96, 105], [106, 111], [112, 114], [115, 119], [120, 122], [123, 124], [125, 133], [134, 136], [137, 141], [142, 147], [148, 151], [152, 159], [160, 170], [171, 178], [178, 179], [180, 181], [182, 186], [187, 191], [192, 201], [202, 206], [207, 219], [220, 227], [228, 232], [233, 236], [237, 245], [246, 248], [249, 252], [253, 258], [258, 259], [259, 263], [264, 268], [269, 271], [272, 275], [276, 282], [283, 286], [287, 291], [292, 297], [298, 304], [304, 305], [306, 309], [310, 318], [319, 332], [333, 345], [345, 346], [347, 354], [355, 358], [359, 362], [363, 369], [370, 373], [374, 384], [384, 385], [386, 389], [390, 395], [395, 396], [396, 398], [399, 410], [411, 414], [415, 421], [422, 433], [434, 446], [446, 447]]}
{"doc_key": "ai-dev-64", "ner": [[11, 11, "algorithm"], [12, 16, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 11, 12, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "many", "applications", ",", "the", "units", "of", "these", "networks", "apply", "a", "sigmoid", "function", "as", "a", "trigger", "function", "."], "sentence-detokenized": "In many applications, the units of these networks apply a sigmoid function as a trigger function.", "token2charspan": [[0, 2], [3, 7], [8, 20], [20, 21], [22, 25], [26, 31], [32, 34], [35, 40], [41, 49], [50, 55], [56, 57], [58, 65], [66, 74], [75, 77], [78, 79], [80, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-dev-65", "ner": [[3, 6, "researcher"], [12, 17, "organisation"], [28, 34, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 6, 12, 17, "role", "", false, false], [3, 6, 28, 34, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2001", ",", "Mehler", "was", "elected", "an", "honorary", "foreign", "member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "in", "2003", "he", "was", "elected", "a", "Fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In 2001, Mehler was elected an honorary foreign member of the American Academy of Arts and Sciences and in 2003 he was elected a Fellow of the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 27], [28, 30], [31, 39], [40, 47], [48, 54], [55, 57], [58, 61], [62, 70], [71, 78], [79, 81], [82, 86], [87, 90], [91, 99], [100, 103], [104, 106], [107, 111], [112, 114], [115, 118], [119, 126], [127, 128], [129, 135], [136, 138], [139, 142], [143, 151], [152, 163], [164, 167], [168, 171], [172, 183], [184, 186], [187, 194], [194, 195]]}
{"doc_key": "ai-dev-66", "ner": [[4, 6, "task"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 9, 10, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Extending", "this", "concept", "to", "non", "-binary", "classifications", "produces", "the", "confusion", "matrix", "."], "sentence-detokenized": "Extending this concept to non-binary classifications produces the confusion matrix.", "token2charspan": [[0, 9], [10, 14], [15, 22], [23, 25], [26, 29], [29, 36], [37, 52], [53, 61], [62, 65], [66, 75], [76, 82], [82, 83]]}
{"doc_key": "ai-dev-67", "ner": [[14, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "updated", "estimate", "of", "the", "variance", "of", "measurement", "noise", "can", "be", "obtained", "from", "the", "maximum", "likelihood", "calculation"], "sentence-detokenized": "An updated estimate of the variance of measurement noise can be obtained from the maximum likelihood calculation", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 22], [23, 26], [27, 35], [36, 38], [39, 50], [51, 56], [57, 60], [61, 63], [64, 72], [73, 77], [78, 81], [82, 89], [90, 100], [101, 112]]}
{"doc_key": "ai-dev-68", "ner": [[1, 2, "field"], [4, 4, "algorithm"], [9, 10, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 9, 10, "usage", "", true, false], [4, 4, 12, 13, "related-to", "", true, false], [9, 10, 1, 2, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "machine", "learning", ",", "perceptron", "is", "an", "algorithm", "for", "supervised", "learning", "of", "binary", "classification", "."], "sentence-detokenized": "In machine learning, perceptron is an algorithm for supervised learning of binary classification.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 31], [32, 34], [35, 37], [38, 47], [48, 51], [52, 62], [63, 71], [72, 74], [75, 81], [82, 96], [96, 97]]}
{"doc_key": "ai-dev-69", "ner": [[10, 11, "field"], [13, 13, "field"], [17, 22, "conference"], [25, 29, "conference"], [32, 38, "conference"], [41, 45, "conference"], [48, 52, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[17, 22, 10, 11, "topic", "", false, false], [17, 22, 13, 13, "topic", "", false, false], [25, 29, 10, 11, "topic", "", false, false], [25, 29, 13, 13, "topic", "", false, false], [32, 38, 10, 11, "topic", "", false, false], [32, 38, 13, 13, "topic", "", false, false], [41, 45, 10, 11, "topic", "", false, false], [41, 45, 13, 13, "topic", "", false, false], [48, 52, 10, 11, "topic", "", false, false], [48, 52, 13, 13, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["She", "has", "also", "been", "area", "chair", "of", "several", "conferences", "on", "machine", "learning", "and", "vision", ",", "including", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "the", "International", "Conference", "on", "Learning", "Representations", ",", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "the", "International", "Conference", "on", "Computer", "Vision", "and", "the", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "She has also been area chair of several conferences on machine learning and vision, including the Conference on Neural Information Processing Systems, the International Conference on Learning Representations, the Conference on Computer Vision and Pattern Recognition, the International Conference on Computer Vision and the European Conference on Computer Vision.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 17], [18, 22], [23, 28], [29, 31], [32, 39], [40, 51], [52, 54], [55, 62], [63, 71], [72, 75], [76, 82], [82, 83], [84, 93], [94, 97], [98, 108], [109, 111], [112, 118], [119, 130], [131, 141], [142, 149], [149, 150], [151, 154], [155, 168], [169, 179], [180, 182], [183, 191], [192, 207], [207, 208], [209, 212], [213, 223], [224, 226], [227, 235], [236, 242], [243, 246], [247, 254], [255, 266], [266, 267], [268, 271], [272, 285], [286, 296], [297, 299], [300, 308], [309, 315], [316, 319], [320, 323], [324, 332], [333, 343], [344, 346], [347, 355], [356, 362], [362, 363]]}
{"doc_key": "ai-dev-70", "ner": [[1, 2, "algorithm"], [8, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 1, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "condensation", "algorithm", "was", "also", "used", "for", "the", "facial", "recognition", "system", "in", "a", "video", "sequence", "."], "sentence-detokenized": "The condensation algorithm was also used for the facial recognition system in a video sequence.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 30], [31, 35], [36, 40], [41, 44], [45, 48], [49, 55], [56, 67], [68, 74], [75, 77], [78, 79], [80, 85], [86, 94], [94, 95]]}
{"doc_key": "ai-dev-71", "ner": [[0, 4, "task"], [8, 8, "organisation"], [19, 19, "conference"], [23, 27, "academicjournal"], [30, 30, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 0, 4, "topic", "", false, false], [19, 19, 8, 8, "origin", "", false, false], [23, 27, 0, 4, "topic", "", false, false], [23, 27, 8, 8, "origin", "", true, false], [30, 30, 23, 27, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "dissemination", "of", "information", "is", "also", "part", "of", "ELRA", "'s", "mission", ",", "which", "takes", "the", "form", "of", "organising", "the", "LREC", "conference", "and", "the", "Language", "Resources", "and", "Evaluation", "Journal", "published", "by", "Springer", "."], "sentence-detokenized": "The dissemination of information is also part of ELRA's mission, which takes the form of organising the LREC conference and the Language Resources and Evaluation Journal published by Springer.", "token2charspan": [[0, 3], [4, 17], [18, 20], [21, 32], [33, 35], [36, 40], [41, 45], [46, 48], [49, 53], [53, 55], [56, 63], [63, 64], [65, 70], [71, 76], [77, 80], [81, 85], [86, 88], [89, 99], [100, 103], [104, 108], [109, 119], [120, 123], [124, 127], [128, 136], [137, 146], [147, 150], [151, 161], [162, 169], [170, 179], [180, 182], [183, 191], [191, 192]]}
{"doc_key": "ai-dev-72", "ner": [[1, 7, "field"], [9, 10, "field"], [12, 14, "field"], [16, 17, "field"], [53, 54, "field"], [59, 59, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 7, 53, 54, "named", "", false, false], [12, 14, 1, 7, "named", "", false, false], [59, 59, 9, 10, "part-of", "", true, false], [59, 59, 12, 14, "part-of", "", true, false], [59, 59, 53, 54, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "linear", "time", "-", "invariant", "systems", "(", "LTI", ")", "control", "theory", "and", "digital", "signal", "processing", "or", "signal", "processing", ",", "the", "relationship", "between", "the", "input", "signal", ",", "math", "\\", "displaystyle", "x", "(", "t", ")", "/", "math", ",", "and", "the", "output", "signal", ",", "math", "\\", "displaystyle", "y", "(", "t", ")", "/", "math", ",", "of", "an", "LTI", "system", "is", "governed", "by", "a", "convolution", "operation", ":"], "sentence-detokenized": "In linear time-invariant systems (LTI) control theory and digital signal processing or signal processing, the relationship between the input signal, math\\ displaystyle x (t) / math, and the output signal, math\\ displaystyle y (t) / math, of an LTI system is governed by a convolution operation:", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [15, 24], [25, 32], [33, 34], [34, 37], [37, 38], [39, 46], [47, 53], [54, 57], [58, 65], [66, 72], [73, 83], [84, 86], [87, 93], [94, 104], [104, 105], [106, 109], [110, 122], [123, 130], [131, 134], [135, 140], [141, 147], [147, 148], [149, 153], [153, 154], [155, 167], [168, 169], [170, 171], [171, 172], [172, 173], [174, 175], [176, 180], [180, 181], [182, 185], [186, 189], [190, 196], [197, 203], [203, 204], [205, 209], [209, 210], [211, 223], [224, 225], [226, 227], [227, 228], [228, 229], [230, 231], [232, 236], [236, 237], [238, 240], [241, 243], [244, 247], [248, 254], [255, 257], [258, 266], [267, 269], [270, 271], [272, 283], [284, 293], [293, 294]]}
{"doc_key": "ai-dev-73", "ner": [[16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 31, "field"], [33, 34, "product"], [36, 37, "field"], [39, 39, "field"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Due", "to", "its", "generality", ",", "this", "field", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Due to its generality, this field is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 21], [21, 22], [23, 27], [28, 33], [34, 36], [37, 44], [45, 47], [48, 52], [53, 58], [59, 70], [70, 71], [72, 76], [77, 79], [80, 84], [85, 91], [91, 92], [93, 100], [101, 107], [107, 108], [109, 119], [120, 128], [128, 129], [130, 141], [142, 148], [148, 149], [150, 160], [160, 161], [161, 166], [167, 179], [179, 180], [181, 192], [193, 200], [200, 201], [202, 207], [208, 220], [220, 221], [222, 232], [233, 236], [237, 244], [245, 255], [255, 256]]}
{"doc_key": "ai-dev-74", "ner": [[0, 2, "algorithm"], [15, 16, "field"], [19, 20, "algorithm"], [26, 27, "algorithm"], [33, 34, "algorithm"], [37, 37, "algorithm"], [38, 40, "researcher"], [42, 43, "researcher"], [45, 47, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[15, 16, 0, 2, "usage", "", true, false], [19, 20, 15, 16, "part-of", "", true, false], [26, 27, 15, 16, "part-of", "", true, false], [33, 34, 15, 16, "part-of", "", true, false], [37, 37, 15, 16, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Stochastic", "gradient", "descent", "is", "a", "popular", "algorithm", "for", "training", "a", "wide", "range", "of", "models", "in", "machine", "learning", ",", "including", "support", "vector", "(", "linear", ")", "machines", ",", "logistic", "regression", "(", "see", ",", "e.g.", ",", "Vowpal", "Wabbit", ")", "and", "graphical", "models.Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastic gradient descent is a popular algorithm for training a wide range of models in machine learning, including support vector (linear) machines, logistic regression (see, e.g., Vowpal Wabbit) and graphical models.Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 30], [31, 32], [33, 40], [41, 50], [51, 54], [55, 63], [64, 65], [66, 70], [71, 76], [77, 79], [80, 86], [87, 89], [90, 97], [98, 106], [106, 107], [108, 117], [118, 125], [126, 132], [133, 134], [134, 140], [140, 141], [142, 150], [150, 151], [152, 160], [161, 171], [172, 173], [173, 176], [176, 177], [178, 182], [182, 183], [184, 190], [191, 197], [197, 198], [199, 202], [203, 212], [213, 225], [226, 230], [231, 237], [237, 238], [239, 243], [244, 251], [251, 252], [253, 264], [265, 267], [268, 275], [276, 277], [277, 281], [281, 282], [282, 283]]}
{"doc_key": "ai-dev-75", "ner": [[8, 8, "organisation"], [12, 13, "product"], [18, 18, "country"], [21, 23, "university"], [25, 25, "location"], [27, 29, "university"], [31, 31, "location"], [33, 34, "university"], [36, 36, "location"], [38, 40, "university"], [42, 42, "location"], [44, 45, "university"], [47, 47, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 21, 23, "role", "donates_to", false, false], [8, 8, 27, 29, "role", "donates_to", false, false], [8, 8, 33, 34, "role", "donates_to", false, false], [8, 8, 38, 40, "role", "donates_to", false, false], [8, 8, 44, 45, "role", "donates_to", false, false], [12, 13, 8, 8, "origin", "donates", true, false], [21, 23, 25, 25, "physical", "", false, false], [25, 25, 18, 18, "physical", "", false, false], [27, 29, 31, 31, "physical", "", false, false], [31, 31, 18, 18, "physical", "", false, false], [33, 34, 36, 36, "physical", "", false, false], [36, 36, 18, 18, "physical", "", false, false], [38, 40, 42, 42, "physical", "", false, false], [42, 42, 18, 18, "physical", "", false, false], [44, 45, 47, 47, "physical", "", false, false], [47, 47, 18, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["In", "August", "2011", ",", "it", "was", "announced", "that", "Hitachi", "would", "donate", "an", "electron", "microscope", "to", "each", "of", "five", "Indonesian", "universities", "(", "North", "Sumatra", "University", "in", "Medan", ",", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Padjadjaran", "University", "in", "Bandung", ",", "Jenderal", "Soedirman", "University", "in", "Purwokerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "sentence-detokenized": "In August 2011, it was announced that Hitachi would donate an electron microscope to each of five Indonesian universities (North Sumatra University in Medan, Indonesian Christian University in Jakarta, Padjadjaran University in Bandung, Jenderal Soedirman University in Purwokerto and Muhammadiyah University in Malang).", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 32], [33, 37], [38, 45], [46, 51], [52, 58], [59, 61], [62, 70], [71, 81], [82, 84], [85, 89], [90, 92], [93, 97], [98, 108], [109, 121], [122, 123], [123, 128], [129, 136], [137, 147], [148, 150], [151, 156], [156, 157], [158, 168], [169, 178], [179, 189], [190, 192], [193, 200], [200, 201], [202, 213], [214, 224], [225, 227], [228, 235], [235, 236], [237, 245], [246, 255], [256, 266], [267, 269], [270, 280], [281, 284], [285, 297], [298, 308], [309, 311], [312, 318], [318, 319], [319, 320]]}
{"doc_key": "ai-dev-76", "ner": [[2, 2, "field"], [0, 1, "field"], [7, 8, "algorithm"], [10, 11, "algorithm"], [20, 21, "field"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 0, 1, "part-of", "", false, false], [2, 2, 20, 21, "related-to", "", true, false], [2, 2, 26, 27, "related-to", "", true, false], [7, 8, 2, 2, "type-of", "", false, false], [10, 11, 2, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Operations", "research", "optimisation", "techniques", ",", "such", "as", "linear", "programming", "or", "dynamic", "programming", ",", "are", "often", "impractical", "for", "large", "-", "scale", "software", "engineering", "problems", "due", "to", "their", "computational", "complexity", "."], "sentence-detokenized": "Operations research optimisation techniques, such as linear programming or dynamic programming, are often impractical for large-scale software engineering problems due to their computational complexity.", "token2charspan": [[0, 10], [11, 19], [20, 32], [33, 43], [43, 44], [45, 49], [50, 52], [53, 59], [60, 71], [72, 74], [75, 82], [83, 94], [94, 95], [96, 99], [100, 105], [106, 117], [118, 121], [122, 127], [127, 128], [128, 133], [134, 142], [143, 154], [155, 163], [164, 167], [168, 170], [171, 176], [177, 190], [191, 201], [201, 202]]}
{"doc_key": "ai-dev-77", "ner": [[0, 0, "metrics"], [6, 6, "metrics"], [8, 10, "metrics"], [15, 15, "metrics"], [20, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 6, "compare", "", false, false], [0, 0, 8, 10, "compare", "", false, false], [15, 15, 8, 10, "part-of", "", false, false], [20, 23, 8, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sensitivity", "is", "not", "the", "same", "as", "accuracy", "or", "positive", "predictive", "value", "(", "ratio", "of", "TRUE", "positives", "to", "the", "combination", "of", "TRUE", "and", "FALSE", "positives", ")", ",", "which", "is", "a", "statement", "about", "the", "proportion", "of", "actual", "positives", "in", "the", "population", "tested", ",", "as", "well", "as", "about", "the", "test", "."], "sentence-detokenized": "Sensitivity is not the same as accuracy or positive predictive value (ratio of TRUE positives to the combination of TRUE and FALSE positives), which is a statement about the proportion of actual positives in the population tested, as well as about the test.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 22], [23, 27], [28, 30], [31, 39], [40, 42], [43, 51], [52, 62], [63, 68], [69, 70], [70, 75], [76, 78], [79, 83], [84, 93], [94, 96], [97, 100], [101, 112], [113, 115], [116, 120], [121, 124], [125, 130], [131, 140], [140, 141], [141, 142], [143, 148], [149, 151], [152, 153], [154, 163], [164, 169], [170, 173], [174, 184], [185, 187], [188, 194], [195, 204], [205, 207], [208, 211], [212, 222], [223, 229], [229, 230], [231, 233], [234, 238], [239, 241], [242, 247], [248, 251], [252, 256], [256, 257]]}
{"doc_key": "ai-dev-78", "ner": [[3, 4, "person"], [10, 10, "product"], [15, 15, "person"], [27, 27, "person"], [34, 36, "person"], [39, 39, "person"], [45, 46, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 4, 39, 39, "named", "same", false, false], [10, 10, 3, 4, "artifact", "", false, false], [34, 36, 45, 46, "role", "convinces", false, false], [45, 46, 10, 10, "role", "producer", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "screenplay", "by", "Hampton", "Fancher", "!", "--", "initially", "not", "titled", "Android", "-", "for", "explanation", "see", "Sammon", ",", "pp.", "32", "and", "38", "-", "was", "optioned", "in", "1977", ".", "Sammon", ",", "pp.", "23", "-", "30", "Producer", "Michael", "Deeley", "became", "interested", "in", "Fancher", "'s", "draft", "and", "convinced", "director", "Ridley", "Scott", "to", "shoot", "it", "."], "sentence-detokenized": "The screenplay by Hampton Fancher! -- initially not titled Android - for explanation see Sammon, pp. 32 and 38 - was optioned in 1977. Sammon, pp. 23-30 Producer Michael Deeley became interested in Fancher's draft and convinced director Ridley Scott to shoot it.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 25], [26, 33], [33, 34], [35, 37], [38, 47], [48, 51], [52, 58], [59, 66], [67, 68], [69, 72], [73, 84], [85, 88], [89, 95], [95, 96], [97, 100], [101, 103], [104, 107], [108, 110], [111, 112], [113, 116], [117, 125], [126, 128], [129, 133], [133, 134], [135, 141], [141, 142], [143, 146], [147, 149], [149, 150], [150, 152], [153, 161], [162, 169], [170, 176], [177, 183], [184, 194], [195, 197], [198, 205], [205, 207], [208, 213], [214, 217], [218, 227], [228, 236], [237, 243], [244, 249], [250, 252], [253, 258], [259, 261], [261, 262]]}
{"doc_key": "ai-dev-79", "ner": [[0, 1, "field"], [3, 4, "task"], [6, 7, "task"], [10, 12, "misc"], [14, 15, "field"], [17, 19, "task"], [21, 22, "task"], [24, 25, "field"], [29, 32, "task"], [34, 34, "task"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [6, 7, 0, 1, "part-of", "", false, false], [10, 12, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false], [17, 19, 0, 1, "part-of", "", false, false], [21, 22, 0, 1, "part-of", "", false, false], [24, 25, 0, 1, "part-of", "", false, false], [29, 32, 0, 1, "part-of", "", false, false], [34, 34, 0, 1, "part-of", "", false, false], [36, 37, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Text", "analysis", "includes", "information", "retrieval", ",", "lexical", "analysis", "to", "study", "word", "frequency", "distributions", ",", "pattern", "recognition", ",", "labelling", "/", "annotation", ",", "information", "extraction", ",", "data", "mining", "techniques", ",", "including", "link", "and", "association", "analysis", ",", "visualisation", "and", "predictive", "analysis", "."], "sentence-detokenized": "Text analysis includes information retrieval, lexical analysis to study word frequency distributions, pattern recognition, labelling/annotation, information extraction, data mining techniques, including link and association analysis, visualisation and predictive analysis.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 34], [35, 44], [44, 45], [46, 53], [54, 62], [63, 65], [66, 71], [72, 76], [77, 86], [87, 100], [100, 101], [102, 109], [110, 121], [121, 122], [123, 132], [132, 133], [133, 143], [143, 144], [145, 156], [157, 167], [167, 168], [169, 173], [174, 180], [181, 191], [191, 192], [193, 202], [203, 207], [208, 211], [212, 223], [224, 232], [232, 233], [234, 247], [248, 251], [252, 262], [263, 271], [271, 272]]}
{"doc_key": "ai-dev-80", "ner": [[3, 3, "product"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Several", "metrics", "use", "WordNet", ",", "a", "manually", "constructed", "lexical", "database", "of", "English", "words", "."], "sentence-detokenized": "Several metrics use WordNet, a manually constructed lexical database of English words.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 27], [27, 28], [29, 30], [31, 39], [40, 51], [52, 59], [60, 68], [69, 71], [72, 79], [80, 85], [85, 86]]}
{"doc_key": "ai-dev-81", "ner": [[6, 7, "field"], [9, 10, "task"], [12, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "system", "uses", "a", "combination", "of", "computational", "linguistics", ",", "information", "retrieval", "and", "knowledge", "representation", "techniques", "to", "find", "answers", "."], "sentence-detokenized": "The system uses a combination of computational linguistics, information retrieval and knowledge representation techniques to find answers.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 17], [18, 29], [30, 32], [33, 46], [47, 58], [58, 59], [60, 71], [72, 81], [82, 85], [86, 95], [96, 110], [111, 121], [122, 124], [125, 129], [130, 137], [137, 138]]}
{"doc_key": "ai-dev-82", "ner": [[6, 9, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 9, 13, 13, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "performance", "metric", ",", "the", "uncertainty", "coefficient", "has", "the", "advantage", "over", "simple", "accuracy", "that", "it", "is", "not", "affected", "by", "the", "relative", "size", "of", "the", "different", "classes", "."], "sentence-detokenized": "As a performance metric, the uncertainty coefficient has the advantage over simple accuracy that it is not affected by the relative size of the different classes.", "token2charspan": [[0, 2], [3, 4], [5, 16], [17, 23], [23, 24], [25, 28], [29, 40], [41, 52], [53, 56], [57, 60], [61, 70], [71, 75], [76, 82], [83, 91], [92, 96], [97, 99], [100, 102], [103, 106], [107, 115], [116, 118], [119, 122], [123, 131], [132, 136], [137, 139], [140, 143], [144, 153], [154, 161], [161, 162]]}
{"doc_key": "ai-dev-83", "ner": [[9, 10, "algorithm"], [12, 13, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Researchers", "have", "tried", "a", "number", "of", "methods", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "Hidden", "Markov", "models", ",", "etc", "."], "sentence-detokenized": "Researchers have tried a number of methods such as optical flow, Kalman filtering, Hidden Markov models, etc.", "token2charspan": [[0, 11], [12, 16], [17, 22], [23, 24], [25, 31], [32, 34], [35, 42], [43, 47], [48, 50], [51, 58], [59, 63], [63, 64], [65, 71], [72, 81], [81, 82], [83, 89], [90, 96], [97, 103], [103, 104], [105, 108], [108, 109]]}
{"doc_key": "ai-dev-84", "ner": [[12, 15, "conference"], [34, 36, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "served", "as", "president", ",", "vice-president", "and", "secretary", "-", "treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "was", "a", "member", "of", "the", "board", "of", "directors", "and", "secretary", "of", "the", "board", "of", "directors", "of", "the", "Computing", "Research", "Association", "."], "sentence-detokenized": "She served as president, vice-president and secretary-treasurer of the Association for Computational Linguistics and was a member of the board of directors and secretary of the board of directors of the Computing Research Association.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 23], [23, 24], [25, 39], [40, 43], [44, 53], [53, 54], [54, 63], [64, 66], [67, 70], [71, 82], [83, 86], [87, 100], [101, 112], [113, 116], [117, 120], [121, 122], [123, 129], [130, 132], [133, 136], [137, 142], [143, 145], [146, 155], [156, 159], [160, 169], [170, 172], [173, 176], [177, 182], [183, 185], [186, 195], [196, 198], [199, 202], [203, 212], [213, 221], [222, 233], [233, 234]]}
{"doc_key": "ai-dev-85", "ner": [[7, 7, "programlang"], [9, 9, "product"], [11, 11, "programlang"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 11, 11, "compare", "", false, false], [7, 7, 13, 14, "related-to", "supports", false, false], [9, 9, 11, 11, "compare", "", false, false], [9, 9, 13, 14, "related-to", "supports", false, false], [11, 11, 13, 14, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Like", "other", "similar", "languages", ",", "such", "as", "APL", "and", "MATLAB", ",", "R", "supports", "matrix", "arithmetic", "."], "sentence-detokenized": "Like other similar languages, such as APL and MATLAB, R supports matrix arithmetic.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 28], [28, 29], [30, 34], [35, 37], [38, 41], [42, 45], [46, 52], [52, 53], [54, 55], [56, 64], [65, 71], [72, 82], [82, 83]]}
{"doc_key": "ai-dev-86", "ner": [[7, 8, "misc"], [12, 13, "organisation"], [17, 18, "researcher"], [21, 24, "university"], [27, 32, "misc"], [34, 34, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 8, 12, 13, "physical", "", false, false], [7, 8, 27, 32, "temporal", "", false, false], [17, 18, 7, 8, "role", "arranges", false, false], [17, 18, 21, 24, "role", "works_for", false, false], [34, 34, 7, 8, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "7", "June", "2014", ",", "in", "a", "Turing", "test", "competition", "at", "the", "Royal", "Society", ",", "organised", "by", "Kevin", "Warwick", "of", "the", "University", "of", "Reading", "to", "mark", "the", "60th", "anniversary", "of", "Turing", "'s", "death", ",", "Goostman", "won", "after", "33", "%", "of", "the", "judges", "were", "convinced", "that", "the", "bot", "was", "human", "."], "sentence-detokenized": "On 7 June 2014, in a Turing test competition at the Royal Society, organised by Kevin Warwick of the University of Reading to mark the 60th anniversary of Turing's death, Goostman won after 33% of the judges were convinced that the bot was human.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 14], [14, 15], [16, 18], [19, 20], [21, 27], [28, 32], [33, 44], [45, 47], [48, 51], [52, 57], [58, 65], [65, 66], [67, 76], [77, 79], [80, 85], [86, 93], [94, 96], [97, 100], [101, 111], [112, 114], [115, 122], [123, 125], [126, 130], [131, 134], [135, 139], [140, 151], [152, 154], [155, 161], [161, 163], [164, 169], [169, 170], [171, 179], [180, 183], [184, 189], [190, 192], [192, 193], [194, 196], [197, 200], [201, 207], [208, 212], [213, 222], [223, 227], [228, 231], [232, 235], [236, 239], [240, 245], [245, 246]]}
{"doc_key": "ai-dev-87", "ner": [[1, 2, "product"], [4, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "collaborative", "robot", "or", "cobot", "is", "a", "robot", "that", "can", "safely", "and", "effectively", "interact", "with", "human", "workers", "while", "performing", "simple", "industrial", "tasks", "."], "sentence-detokenized": "A collaborative robot or cobot is a robot that can safely and effectively interact with human workers while performing simple industrial tasks.", "token2charspan": [[0, 1], [2, 15], [16, 21], [22, 24], [25, 30], [31, 33], [34, 35], [36, 41], [42, 46], [47, 50], [51, 57], [58, 61], [62, 73], [74, 82], [83, 87], [88, 93], [94, 101], [102, 107], [108, 118], [119, 125], [126, 136], [137, 142], [142, 143]]}
{"doc_key": "ai-dev-88", "ner": [[11, 12, "field"], [17, 17, "task"], [19, 20, "task"], [23, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[17, 17, 11, 12, "part-of", "task_part_of_field", false, false], [19, 20, 11, 12, "part-of", "task_part_of_field", false, false], [23, 23, 11, 12, "part-of", "task_part_of_field", false, false], [25, 26, 11, 12, "part-of", "task_part_of_field", false, false], [28, 29, 11, 12, "part-of", "task_part_of_field", false, false], [31, 33, 11, 12, "part-of", "task_part_of_field", false, false], [35, 36, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "general", "framework", "has", "been", "applied", "to", "a", "wide", "variety", "of", "computer", "vision", "problems", ",", "including", "feature", "detection", ",", "feature", "classification", ",", "image", "segmentation", ",", "image", "matching", ",", "motion", "estimation", ",", "shape", "cue", "calculation", "and", "object", "recognition", "."], "sentence-detokenized": "This general framework has been applied to a wide variety of computer vision problems, including feature detection, feature classification, image segmentation, image matching, motion estimation, shape cue calculation and object recognition.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 26], [27, 31], [32, 39], [40, 42], [43, 44], [45, 49], [50, 57], [58, 60], [61, 69], [70, 76], [77, 85], [85, 86], [87, 96], [97, 104], [105, 114], [114, 115], [116, 123], [124, 138], [138, 139], [140, 145], [146, 158], [158, 159], [160, 165], [166, 174], [174, 175], [176, 182], [183, 193], [193, 194], [195, 200], [201, 204], [205, 216], [217, 220], [221, 227], [228, 239], [239, 240]]}
{"doc_key": "ai-dev-89", "ner": [[5, 6, "task"], [8, 10, "algorithm"], [13, 14, "algorithm"], [26, 27, "algorithm"], [32, 32, "algorithm"], [35, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 8, 10, "part-of", "", false, false], [5, 6, 13, 14, "usage", "", false, false], [8, 10, 26, 27, "named", "same", false, false], [26, 27, 32, 32, "related-to", "", false, false], [26, 27, 35, 36, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "many", "practical", "applications", ",", "parameter", "estimation", "for", "naive", "Bayes", "models", "uses", "the", "maximum", "likelihood", "method", ";", "in", "other", "words", ",", "one", "can", "work", "with", "the", "naive", "Bayes", "model", "without", "accepting", "Bayesian", "probability", "or", "using", "Bayesian", "methods", "."], "sentence-detokenized": "In many practical applications, parameter estimation for naive Bayes models uses the maximum likelihood method; in other words, one can work with the naive Bayes model without accepting Bayesian probability or using Bayesian methods.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 30], [30, 31], [32, 41], [42, 52], [53, 56], [57, 62], [63, 68], [69, 75], [76, 80], [81, 84], [85, 92], [93, 103], [104, 110], [110, 111], [112, 114], [115, 120], [121, 126], [126, 127], [128, 131], [132, 135], [136, 140], [141, 145], [146, 149], [150, 155], [156, 161], [162, 167], [168, 175], [176, 185], [186, 194], [195, 206], [207, 209], [210, 215], [216, 224], [225, 232], [232, 233]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [12, 15, "university"], [17, 19, "researcher"], [21, 22, "misc"], [26, 26, "university"], [28, 28, "university"], [31, 31, "misc"], [38, 40, "university"], [46, 49, "misc"], [51, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 4, 12, 15, "physical", "", false, false], [2, 4, 12, 15, "role", "", false, false], [2, 4, 17, 19, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [17, 19, 26, 26, "physical", "", false, false], [17, 19, 26, 26, "role", "", false, false], [17, 19, 28, 28, "physical", "", false, false], [17, 19, 28, 28, "role", "", false, false], [17, 19, 38, 40, "physical", "", false, false], [17, 19, 38, 40, "role", "", false, false], [21, 22, 17, 19, "named", "", false, false], [31, 31, 17, 19, "origin", "", false, false], [46, 49, 17, 19, "artifact", "", false, false], [46, 49, 51, 54, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Brothers", "-", "Victor", "Gershevich", "Katz", ",", "American", "mathematician", ",", "professor", "at", "the", "Massachusetts", "Institute", "of", "Technology", ";", "Mikhail", "Gershevich", "Katz", ",", "Israeli", "mathematician", ",", "graduate", "of", "Harvard", "and", "Columbia", "universities", "(", "Ph.D.", ",", "1984", ")", ",", "professor", "at", "Bar-", "Ilan", "University", ",", "author", "of", "the", "monograph", "Systolic", "Geometry", "and", "Topology", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", "."], "sentence-detokenized": "Brothers - Victor Gershevich Katz, American mathematician, professor at the Massachusetts Institute of Technology; Mikhail Gershevich Katz, Israeli mathematician, graduate of Harvard and Columbia universities (Ph.D. , 1984), professor at Bar-Ilan University, author of the monograph Systolic Geometry and Topology (Mathematical Surveys and Monographs, vol.", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 28], [29, 33], [33, 34], [35, 43], [44, 57], [57, 58], [59, 68], [69, 71], [72, 75], [76, 89], [90, 99], [100, 102], [103, 113], [113, 114], [115, 122], [123, 133], [134, 138], [138, 139], [140, 147], [148, 161], [161, 162], [163, 171], [172, 174], [175, 182], [183, 186], [187, 195], [196, 208], [209, 210], [210, 215], [216, 217], [218, 222], [222, 223], [223, 224], [225, 234], [235, 237], [238, 242], [242, 246], [247, 257], [257, 258], [259, 265], [266, 268], [269, 272], [273, 282], [283, 291], [292, 300], [301, 304], [305, 313], [314, 315], [315, 327], [328, 335], [336, 339], [340, 350], [350, 351], [352, 355], [355, 356]]}
{"doc_key": "ai-dev-91", "ner": [[3, 4, "person"], [9, 10, "conference"], [15, 18, "organisation"], [20, 26, "location"], [30, 30, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 9, 10, "physical", "", false, false], [3, 4, 9, 10, "role", "", false, false], [3, 4, 15, 18, "role", "", false, false], [15, 18, 20, 26, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2000", ",", "Manuel", "Toharia", ",", "speaker", "of", "previous", "Campus", "Parties", "and", "director", "of", "the", "Prince", "Felipe", "Science", "Museum", "in", "Valencia", "'s", "City", "of", "Arts", "and", "Sciences", ",", "suggested", "to", "Ragageles", "that", "the", "event", "be", "expanded", "and", "made", "more", "international", "by", "moving", "it", "to", "the", "famous", "museum", "."], "sentence-detokenized": "In 2000, Manuel Toharia, speaker of previous Campus Parties and director of the Prince Felipe Science Museum in Valencia's City of Arts and Sciences, suggested to Ragageles that the event be expanded and made more international by moving it to the famous museum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 23], [23, 24], [25, 32], [33, 35], [36, 44], [45, 51], [52, 59], [60, 63], [64, 72], [73, 75], [76, 79], [80, 86], [87, 93], [94, 101], [102, 108], [109, 111], [112, 120], [120, 122], [123, 127], [128, 130], [131, 135], [136, 139], [140, 148], [148, 149], [150, 159], [160, 162], [163, 172], [173, 177], [178, 181], [182, 187], [188, 190], [191, 199], [200, 203], [204, 208], [209, 213], [214, 227], [228, 230], [231, 237], [238, 240], [241, 243], [244, 247], [248, 254], [255, 261], [261, 262]]}
{"doc_key": "ai-dev-92", "ner": [[5, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Within", "20", "minutes", ",", "a", "facial", "recognition", "system", "identifies", "personal", "information", ",", "including", "family", "name", ",", "identity", "card", "number", "and", "address", ",", "which", "is", "displayed", "in", "the", "street", "on", "an", "advertising", "screen", "."], "sentence-detokenized": "Within 20 minutes, a facial recognition system identifies personal information, including family name, identity card number and address, which is displayed in the street on an advertising screen.", "token2charspan": [[0, 6], [7, 9], [10, 17], [17, 18], [19, 20], [21, 27], [28, 39], [40, 46], [47, 57], [58, 66], [67, 78], [78, 79], [80, 89], [90, 96], [97, 101], [101, 102], [103, 111], [112, 116], [117, 123], [124, 127], [128, 135], [135, 136], [137, 142], [143, 145], [146, 155], [156, 158], [159, 162], [163, 169], [170, 172], [173, 175], [176, 187], [188, 194], [194, 195]]}
{"doc_key": "ai-dev-93", "ner": [[6, 9, "field"], [6, 8, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "research", "has", "increasingly", "focused", "on", "unsupervised", "and", "semi-supervised", "learning", "algorithms", "."], "sentence-detokenized": "Recent research has increasingly focused on unsupervised and semi-supervised learning algorithms.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 32], [33, 40], [41, 43], [44, 56], [57, 60], [61, 76], [77, 85], [86, 96], [96, 97]]}
{"doc_key": "ai-dev-94", "ner": [[5, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Calculation", "of", "this", "example", "using", "Python", "code", ":"], "sentence-detokenized": "Calculation of this example using Python code:", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 27], [28, 33], [34, 40], [41, 45], [45, 46]]}
{"doc_key": "ai-dev-95", "ner": [[7, 10, "task"], [16, 17, "field"], [20, 24, "algorithm"], [26, 26, "algorithm"], [30, 32, "algorithm"], [35, 36, "researcher"], [38, 39, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[20, 24, 16, 17, "part-of", "", false, false], [20, 24, 30, 32, "type-of", "", false, false], [20, 24, 35, 36, "origin", "", false, false], [20, 24, 38, 39, "origin", "", false, false], [26, 26, 20, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Today", ",", "however", ",", "many", "aspects", "of", "speech", "recognition", "have", "been", "taken", "into", "account", "by", "a", "deep", "learning", "method", "called", "Long", "short", "-", "term", "memory", "(", "LSTM", ")", ",", "a", "recurrent", "neural", "network", "published", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "."], "sentence-detokenized": "Today, however, many aspects of speech recognition have been taken into account by a deep learning method called Long short-term memory (LSTM), a recurrent neural network published by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997.", "token2charspan": [[0, 5], [5, 6], [7, 14], [14, 15], [16, 20], [21, 28], [29, 31], [32, 38], [39, 50], [51, 55], [56, 60], [61, 66], [67, 71], [72, 79], [80, 82], [83, 84], [85, 89], [90, 98], [99, 105], [106, 112], [113, 117], [118, 123], [123, 124], [124, 128], [129, 135], [136, 137], [137, 141], [141, 142], [142, 143], [144, 145], [146, 155], [156, 162], [163, 170], [171, 180], [181, 183], [184, 188], [189, 199], [200, 203], [204, 210], [211, 222], [223, 225], [226, 230], [230, 231]]}
{"doc_key": "ai-dev-96", "ner": [[8, 8, "algorithm"], [14, 14, "algorithm"], [18, 18, "algorithm"], [23, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 14, 14, "compare", "", false, false], [8, 8, 23, 23, "named", "same", false, false], [18, 18, 23, 23, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "preliminary", "experimental", "results", "with", "noisy", "datasets", ",", "BrownBoost", "outperformed", "the", "generalisation", "error", "of", "AdaBoost", ";", "however", ",", "LogitBoost", "performed", "as", "well", "as", "BrownBoost", "."], "sentence-detokenized": "In preliminary experimental results with noisy datasets, BrownBoost outperformed the generalisation error of AdaBoost; however, LogitBoost performed as well as BrownBoost.", "token2charspan": [[0, 2], [3, 14], [15, 27], [28, 35], [36, 40], [41, 46], [47, 55], [55, 56], [57, 67], [68, 80], [81, 84], [85, 99], [100, 105], [106, 108], [109, 117], [117, 118], [119, 126], [126, 127], [128, 138], [139, 148], [149, 151], [152, 156], [157, 159], [160, 170], [170, 171]]}
{"doc_key": "ai-dev-97", "ner": [[0, 2, "algorithm"], [5, 7, "researcher"], [10, 10, "country"], [13, 15, "researcher"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 7, "part-of", "", false, false], [5, 7, 10, 10, "physical", "", false, false], [19, 20, 13, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evolutionary", "programming", "was", "introduced", "by", "Lawrence", "J.", "Fogel", "in", "the", "US", ",", "while", "John", "Henry", "Holland", "called", "his", "method", "genetic", "algorithm", "."], "sentence-detokenized": "Evolutionary programming was introduced by Lawrence J. Fogel in the US, while John Henry Holland called his method genetic algorithm.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 54], [55, 60], [61, 63], [64, 67], [68, 70], [70, 71], [72, 77], [78, 82], [83, 88], [89, 96], [97, 103], [104, 107], [108, 114], [115, 122], [123, 132], [132, 133]]}
{"doc_key": "ai-dev-98", "ner": [[3, 3, "researcher"], [5, 5, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 11, 12, "role", "", false, false], [3, 3, 14, 15, "role", "", false, false], [3, 3, 17, 18, "role", "", false, false], [3, 3, 20, 21, "role", "", false, false], [5, 5, 11, 12, "role", "", false, false], [5, 5, 14, 15, "role", "", false, false], [5, 5, 17, 18, "role", "", false, false], [5, 5, 20, 21, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Calculations", "made", "by", "Doug", ",", "Alan", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", "and", "John", "McCarthy", ")", "indicated", "that", "this", "effort", "would", "take", "between", "1,000", "and", "3,000", "years", "to", "complete", ",", "far", "beyond", "the", "standard", "academic", "project", "model", "."], "sentence-detokenized": "Calculations made by Doug, Alan and their colleagues (including Marvin Minsky, Allen Newell, Edward Feigenbaum and John McCarthy) indicated that this effort would take between 1,000 and 3,000 years to complete, far beyond the standard academic project model.", "token2charspan": [[0, 12], [13, 17], [18, 20], [21, 25], [25, 26], [27, 31], [32, 35], [36, 41], [42, 52], [53, 54], [54, 63], [64, 70], [71, 77], [77, 78], [79, 84], [85, 91], [91, 92], [93, 99], [100, 110], [111, 114], [115, 119], [120, 128], [128, 129], [130, 139], [140, 144], [145, 149], [150, 156], [157, 162], [163, 167], [168, 175], [176, 181], [182, 185], [186, 191], [192, 197], [198, 200], [201, 209], [209, 210], [211, 214], [215, 221], [222, 225], [226, 234], [235, 243], [244, 251], [252, 257], [257, 258]]}
{"doc_key": "ai-dev-99", "ner": [[5, 7, "metrics"], [11, 11, "metrics"], [14, 16, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 11, 11, "part-of", "implemented_in", false, false], [14, 16, 19, 19, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "common", "criteria", "are", "the", "mean", "square", "error", "criterion", "implemented", "in", "MSECriterion", "and", "the", "cross", "-entropy", "criterion", "implemented", "in", "NLLCriterion", "."], "sentence-detokenized": "The common criteria are the mean square error criterion implemented in MSECriterion and the cross-entropy criterion implemented in NLLCriterion.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 23], [24, 27], [28, 32], [33, 39], [40, 45], [46, 55], [56, 67], [68, 70], [71, 83], [84, 87], [88, 91], [92, 97], [97, 105], [106, 115], [116, 127], [128, 130], [131, 143], [143, 144]]}
{"doc_key": "ai-dev-100", "ner": [[0, 3, "researcher"], [11, 11, "organisation"], [15, 23, "misc"], [38, 41, "conference"], [47, 47, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 11, 11, "role", "", false, false], [0, 3, 38, 41, "role", "", false, false], [0, 3, 47, 47, "role", "", false, false], [15, 23, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zurada", "has", "served", "the", "engineering", "profession", "as", "a", "long", "-", "standing", "IEEE", "volunteer", ":", "in", "2014", "he", "was", "IEEE", "Vice", "President", "for", "Technical", "Activities", "(", "TAB", "Chair", ")", ",", "in", "2004", "-", "05", "he", "was", "President", "of", "the", "IEEE", "Computational", "Intelligence", "Society", ",", "and", "a", "member", "of", "ADCOM", "in", "2009", "-", "14", ",", "2016", "-", "18", "and", "previous", "years", "."], "sentence-detokenized": "Zurada has served the engineering profession as a long-standing IEEE volunteer: in 2014 he was IEEE Vice President for Technical Activities (TAB Chair), in 2004-05 he was President of the IEEE Computational Intelligence Society, and a member of ADCOM in 2009-14, 2016-18 and previous years.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 21], [22, 33], [34, 44], [45, 47], [48, 49], [50, 54], [54, 55], [55, 63], [64, 68], [69, 78], [78, 79], [80, 82], [83, 87], [88, 90], [91, 94], [95, 99], [100, 104], [105, 114], [115, 118], [119, 128], [129, 139], [140, 141], [141, 144], [145, 150], [150, 151], [151, 152], [153, 155], [156, 160], [160, 161], [161, 163], [164, 166], [167, 170], [171, 180], [181, 183], [184, 187], [188, 192], [193, 206], [207, 219], [220, 227], [227, 228], [229, 232], [233, 234], [235, 241], [242, 244], [245, 250], [251, 253], [254, 258], [258, 259], [259, 261], [261, 262], [263, 267], [267, 268], [268, 270], [271, 274], [275, 283], [284, 289], [289, 290]]}
{"doc_key": "ai-dev-101", "ner": [[3, 4, "field"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 4, "part-of", "", false, false], [11, 12, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "general", ",", "computational", "linguistics", "involves", "linguists", ",", "computer", "scientists", ",", "artificial", "intelligence", "experts", ",", "mathematicians", ",", "logicians", ",", "philosophers", ",", "cognitive", "scientists", ",", "cognitive", "psychologists", ",", "psycholinguists", ",", "anthropologists", "and", "neuroscientists", ",", "among", "others", "."], "sentence-detokenized": "In general, computational linguistics involves linguists, computer scientists, artificial intelligence experts, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists and neuroscientists, among others.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 25], [26, 37], [38, 46], [47, 56], [56, 57], [58, 66], [67, 77], [77, 78], [79, 89], [90, 102], [103, 110], [110, 111], [112, 126], [126, 127], [128, 137], [137, 138], [139, 151], [151, 152], [153, 162], [163, 173], [173, 174], [175, 184], [185, 198], [198, 199], [200, 215], [215, 216], [217, 232], [233, 236], [237, 252], [252, 253], [254, 259], [260, 266], [266, 267]]}
{"doc_key": "ai-dev-102", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "correlations", "between", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and short-term memory are often used to exploit correlations between frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 83], [83, 84], [84, 88], [89, 95], [96, 99], [100, 105], [106, 110], [111, 113], [114, 121], [122, 134], [135, 142], [143, 149], [149, 150]]}
{"doc_key": "ai-dev-103", "ner": [[0, 0, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "was", "the", "first", "industrial", "robot", ","], "sentence-detokenized": "Unimate was the first industrial robot,", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 21], [22, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-dev-104", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 11, 13, "win-defeat", "", false, false], [5, 6, 11, 13, "win-defeat", "", false, false], [8, 8, 11, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Together", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "won", "the", "2018", "Turing", "Prize", "."], "sentence-detokenized": "Together with Geoffrey Hinton and Yann LeCun, Bengio won the 2018 Turing Prize.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 29], [30, 33], [34, 38], [39, 44], [44, 45], [46, 52], [53, 56], [57, 60], [61, 65], [66, 72], [73, 78], [78, 79]]}
{"doc_key": "ai-dev-105", "ner": [[6, 6, "country"], [20, 23, "misc"], [25, 25, "country"], [29, 30, "organisation"], [34, 35, "person"], [37, 38, "person"], [46, 48, "misc"], [53, 53, "country"], [59, 59, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[20, 23, 6, 6, "physical", "filmed_in", false, false], [34, 35, 29, 30, "role", "host", false, false], [37, 38, 29, 30, "role", "reporter", false, false], [46, 48, 6, 6, "physical", "filmed_in", false, false], [46, 48, 53, 53, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "series", "were", "filmed", "in", "the", "UK", "office", "for", "specific", "sectors", "of", "the", "global", "market", ",", "including", "two", "series", "of", "Robot", "Wars", "Extreme", "Warriors", "with", "US", "competitors", "for", "the", "TNN", "network", "(", "led", "by", "Mick", "Foley", "and", "Rebecca", "Grant", "as", "pit", "reporters", ")", ",", "two", "of", "Dutch", "Robot", "Wars", "for", "distribution", "in", "the", "Netherlands", "and", "a", "single", "series", "for", "Germany", "."], "sentence-detokenized": "Other series were filmed in the UK office for specific sectors of the global market, including two series of Robot Wars Extreme Warriors with US competitors for the TNN network (led by Mick Foley and Rebecca Grant as pit reporters), two of Dutch Robot Wars for distribution in the Netherlands and a single series for Germany.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 24], [25, 27], [28, 31], [32, 34], [35, 41], [42, 45], [46, 54], [55, 62], [63, 65], [66, 69], [70, 76], [77, 83], [83, 84], [85, 94], [95, 98], [99, 105], [106, 108], [109, 114], [115, 119], [120, 127], [128, 136], [137, 141], [142, 144], [145, 156], [157, 160], [161, 164], [165, 168], [169, 176], [177, 178], [178, 181], [182, 184], [185, 189], [190, 195], [196, 199], [200, 207], [208, 213], [214, 216], [217, 220], [221, 230], [230, 231], [231, 232], [233, 236], [237, 239], [240, 245], [246, 251], [252, 256], [257, 260], [261, 273], [274, 276], [277, 280], [281, 292], [293, 296], [297, 298], [299, 305], [306, 312], [313, 316], [317, 324], [324, 325]]}
{"doc_key": "ai-dev-106", "ner": [[8, 8, "researcher"], [13, 13, "product"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 13, 13, "role", "", false, false], [30, 31, 13, 13, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "many", "years", ",", "starting", "in", "1986", ",", "Miller", "directed", "the", "development", "of", "WordNet", ",", "a", "large", "computer", "-", "readable", "electronic", "reference", "that", "can", "be", "used", "in", "applications", "such", "as", "search", "engines", "."], "sentence-detokenized": "For many years, starting in 1986, Miller directed the development of WordNet, a large computer-readable electronic reference that can be used in applications such as search engines.", "token2charspan": [[0, 3], [4, 8], [9, 14], [14, 15], [16, 24], [25, 27], [28, 32], [32, 33], [34, 40], [41, 49], [50, 53], [54, 65], [66, 68], [69, 76], [76, 77], [78, 79], [80, 85], [86, 94], [94, 95], [95, 103], [104, 114], [115, 124], [125, 129], [130, 133], [134, 136], [137, 141], [142, 144], [145, 157], [158, 162], [163, 165], [166, 172], [173, 180], [180, 181]]}
{"doc_key": "ai-dev-107", "ner": [[3, 3, "algorithm"], [5, 8, "algorithm"], [11, 13, "researcher"], [18, 22, "organisation"], [26, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 11, 13, "origin", "", false, false], [3, 3, 26, 28, "win-defeat", "", false, false], [5, 8, 11, 13, "origin", "", false, false], [5, 8, 26, 28, "win-defeat", "", false, false], [11, 13, 18, 22, "physical", "", false, false], [11, 13, 18, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Since", "2009", ",", "recurrent", "and", "feedforward", "deep", "neural", "networks", "developed", "by", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "Swiss", "artificial", "intelligence", "laboratory", "IDSIA", "have", "won", "several", "international", "writing", "competitions", "..."], "sentence-detokenized": "Since 2009, recurrent and feedforward deep neural networks developed by J\u00fcrgen Schmidhuber's research group at the Swiss artificial intelligence laboratory IDSIA have won several international writing competitions...", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 21], [22, 25], [26, 37], [38, 42], [43, 49], [50, 58], [59, 68], [69, 71], [72, 78], [79, 90], [90, 92], [93, 101], [102, 107], [108, 110], [111, 114], [115, 120], [121, 131], [132, 144], [145, 155], [156, 161], [162, 166], [167, 170], [171, 178], [179, 192], [193, 200], [201, 213], [213, 216]]}
{"doc_key": "ai-dev-108", "ner": [[5, 6, "programlang"], [12, 12, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "is", "implemented", "in", "C", "++", "and", "has", "been", "packaged", "for", "Python", "."], "sentence-detokenized": "The software is implemented in C++ and has been packaged for Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 30], [31, 32], [32, 34], [35, 38], [39, 42], [43, 47], [48, 56], [57, 60], [61, 67], [67, 68]]}
{"doc_key": "ai-dev-109", "ner": [[8, 9, "country"], [14, 15, "misc"], [20, 21, "misc"], [33, 34, "misc"], [36, 36, "misc"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 8, 9, "temporal", "", false, false], [20, 21, 14, 15, "artifact", "", false, false], [20, 21, 38, 38, "physical", "", false, false], [36, 36, 33, 34, "named", "", false, false], [36, 36, 38, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1857", ",", "at", "the", "request", "of", "the", "Tokugawa", "shogunate", ",", "a", "group", "of", "Dutch", "engineers", "began", "work", "on", "the", "Nagasaki", "Yotetsusho", ",", "a", "modern", "western", "-", "style", "foundry", "and", "shipyard", "near", "the", "Dutch", "settlement", "of", "Dejima", "in", "Nagasaki", "."], "sentence-detokenized": "In 1857, at the request of the Tokugawa shogunate, a group of Dutch engineers began work on the Nagasaki Yotetsusho, a modern western-style foundry and shipyard near the Dutch settlement of Dejima in Nagasaki.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 39], [40, 49], [49, 50], [51, 52], [53, 58], [59, 61], [62, 67], [68, 77], [78, 83], [84, 88], [89, 91], [92, 95], [96, 104], [105, 115], [115, 116], [117, 118], [119, 125], [126, 133], [133, 134], [134, 139], [140, 147], [148, 151], [152, 160], [161, 165], [166, 169], [170, 175], [176, 186], [187, 189], [190, 196], [197, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-dev-110", "ner": [[10, 12, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["To", "be", "as", "precise", "as", "possible", ",", "we", "measure", "the", "mean", "square", "error", "between", "math", "/", "math", "and", "math", "\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "we", "want", "math", "(", "y", "-\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", "^", "2", "/", "math", "is", "minimum", ",", "both", "for", "mathx", "_", "1", ",\\", "points", ",", "x", "_n", "/", "math", "and", "for", "points", "outside", "our", "sample", "."], "sentence-detokenized": "To be as precise as possible, we measure the mean square error between math / math and math\\ hat {f} (x; D) / math: we want math (y -\\ hat {f} (x; D)) ^ 2 / math is minimum, both for mathx _ 1,\\ points, x _n / math and for points outside our sample.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 16], [17, 19], [20, 28], [28, 29], [30, 32], [33, 40], [41, 44], [45, 49], [50, 56], [57, 62], [63, 70], [71, 75], [76, 77], [78, 82], [83, 86], [87, 91], [91, 92], [93, 96], [97, 98], [98, 99], [99, 100], [101, 102], [102, 103], [103, 104], [105, 106], [106, 107], [108, 109], [110, 114], [114, 115], [116, 118], [119, 123], [124, 128], [129, 130], [130, 131], [132, 134], [135, 138], [139, 140], [140, 141], [141, 142], [143, 144], [144, 145], [145, 146], [147, 148], [148, 149], [149, 150], [151, 152], [153, 154], [155, 156], [157, 161], [162, 164], [165, 172], [172, 173], [174, 178], [179, 182], [183, 188], [189, 190], [191, 192], [192, 194], [195, 201], [201, 202], [203, 204], [205, 207], [208, 209], [210, 214], [215, 218], [219, 222], [223, 229], [230, 237], [238, 241], [242, 248], [248, 249]]}
{"doc_key": "ai-dev-111", "ner": [[4, 7, "researcher"], [14, 16, "organisation"], [19, 23, "product"], [31, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 7, 14, 16, "role", "", false, false], [19, 23, 14, 16, "temporal", "", false, false], [19, 23, 31, 32, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Later", "that", "October", ",", "Wydner", "was", "invited", "to", "attend", "the", "annual", "meeting", "of", "the", "American", "Translators", "Association", ",", "where", "Weidner", "'s", "machine", "translation", "system", "was", "hailed", "as", "a", "welcome", "breakthrough", "in", "machine", "translation", "."], "sentence-detokenized": "Later that October, Wydner was invited to attend the annual meeting of the American Translators Association, where Weidner's machine translation system was hailed as a welcome breakthrough in machine translation.", "token2charspan": [[0, 5], [6, 10], [11, 18], [18, 19], [20, 26], [27, 30], [31, 38], [39, 41], [42, 48], [49, 52], [53, 59], [60, 67], [68, 70], [71, 74], [75, 83], [84, 95], [96, 107], [107, 108], [109, 114], [115, 122], [122, 124], [125, 132], [133, 144], [145, 151], [152, 155], [156, 162], [163, 165], [166, 167], [168, 175], [176, 188], [189, 191], [192, 199], [200, 211], [211, 212]]}
{"doc_key": "ai-dev-112", "ner": [[2, 8, "conference"], [10, 10, "conference"], [13, 13, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 2, 8, "named", "", false, false], [10, 10, 2, 8, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["At", "the", "2018", "Conference", "on", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", ",", "Google", "researchers", "presented", "the", "work", "."], "sentence-detokenized": "At the 2018 Conference on Neural Information Processing Systems (NeurIPS), Google researchers presented the work.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 22], [23, 25], [26, 32], [33, 44], [45, 55], [56, 63], [64, 65], [65, 72], [72, 73], [73, 74], [75, 81], [82, 93], [94, 103], [104, 107], [108, 112], [112, 113]]}
{"doc_key": "ai-dev-113", "ner": [[1, 3, "algorithm"], [4, 11, "algorithm"], [15, 18, "metrics"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 4, 11, "usage", "", false, false], [4, 11, 15, 18, "related-to", "", true, false], [15, 18, 23, 25, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Baum", "-", "Welch", "algorithm", "uses", "the", "well", "-", "known", "EM", "algorithm", "to", "find", "the", "maximum", "likelihood", "estimate", "of", "the", "parameters", "of", "a", "hidden", "Markov", "model", "given", "a", "set", "of", "observed", "feature", "vectors", "."], "sentence-detokenized": "The Baum-Welch algorithm uses the well-known EM algorithm to find the maximum likelihood estimate of the parameters of a hidden Markov model given a set of observed feature vectors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [15, 24], [25, 29], [30, 33], [34, 38], [38, 39], [39, 44], [45, 47], [48, 57], [58, 60], [61, 65], [66, 69], [70, 77], [78, 88], [89, 97], [98, 100], [101, 104], [105, 115], [116, 118], [119, 120], [121, 127], [128, 134], [135, 140], [141, 146], [147, 148], [149, 152], [153, 155], [156, 164], [165, 172], [173, 180], [180, 181]]}
{"doc_key": "ai-dev-114", "ner": [[8, 8, "product"], [10, 10, "product"], [33, 34, "misc"], [40, 47, "product"], [50, 52, "programlang"], [53, 58, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 8, 10, 10, "compare", "", false, false], [33, 34, 10, 10, "part-of", "", false, false], [40, 47, 10, 10, "part-of", "", false, false], [53, 58, 10, 10, "part-of", "", false, false], [53, 58, 50, 52, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "addition", "to", "the", "taxonomic", "information", "contained", "in", "OpenCyc", ",", "ResearchCyc", "includes", "significantly", "more", "semantic", "knowledge", "(", "i.e.", ",", "additional", "facts", "and", "rules", "of", "thumb", ")", "related", "to", "the", "concepts", "of", "it", "s", "knowledge", "base", ";", "it", "also", "includes", "an", "extensive", "lexicon", ",", "English", "parsing", "and", "generation", "tools", ",", "and", "Java", "-", "based", "interfaces", "for", "editing", "and", "querying", "knowledge", "."], "sentence-detokenized": "In addition to the taxonomic information contained in OpenCyc, ResearchCyc includes significantly more semantic knowledge (i.e., additional facts and rules of thumb) related to the concepts of its knowledge base; it also includes an extensive lexicon, English parsing and generation tools, and Java-based interfaces for editing and querying knowledge.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 28], [29, 40], [41, 50], [51, 53], [54, 61], [61, 62], [63, 74], [75, 83], [84, 97], [98, 102], [103, 111], [112, 121], [122, 123], [123, 127], [127, 128], [129, 139], [140, 145], [146, 149], [150, 155], [156, 158], [159, 164], [164, 165], [166, 173], [174, 176], [177, 180], [181, 189], [190, 192], [193, 195], [195, 196], [197, 206], [207, 211], [211, 212], [213, 215], [216, 220], [221, 229], [230, 232], [233, 242], [243, 250], [250, 251], [252, 259], [260, 267], [268, 271], [272, 282], [283, 288], [288, 289], [290, 293], [294, 298], [298, 299], [299, 304], [305, 315], [316, 319], [320, 327], [328, 331], [332, 340], [341, 350], [350, 351]]}
{"doc_key": "ai-dev-115", "ner": [[0, 2, "algorithm"], [5, 6, "task"], [10, 11, "field"], [13, 14, "field"], [16, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 6, "type-of", "", false, false], [5, 6, 10, 11, "part-of", "task_part_of_field", false, false], [5, 6, 13, 14, "part-of", "task_part_of_field", false, false], [5, 6, 16, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Hough", "transform", "is", "a", "feature", "extraction", "technique", "used", "in", "image", "analysis", ",", "computer", "vision", "and", "digital", "image", "processing", "."], "sentence-detokenized": "The Hough transform is a feature extraction technique used in image analysis, computer vision and digital image processing.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 22], [23, 24], [25, 32], [33, 43], [44, 53], [54, 58], [59, 61], [62, 67], [68, 76], [76, 77], [78, 86], [87, 93], [94, 97], [98, 105], [106, 111], [112, 122], [122, 123]]}
{"doc_key": "ai-dev-116", "ner": [[4, 4, "product"], [6, 10, "product"], [16, 16, "organisation"], [18, 18, "product"], [20, 21, "researcher"], [28, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 6, 10, "named", "", false, false], [4, 4, 16, 16, "artifact", "", false, false], [4, 4, 18, 18, "origin", "developed_from", false, false], [18, 18, 20, 21, "artifact", "", false, false], [28, 29, 16, 16, "role", "supported", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1978", ",", "the", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "robot", "was", "developed", "by", "Unimation", "from", "Vicarm", "(", "Victor", "Scheinman", ")", "and", "with", "the", "support", "of", "General", "Motors", "."], "sentence-detokenized": "In 1978, the PUMA (Programmable Universal Machine for Assembly) robot was developed by Unimation from Vicarm (Victor Scheinman) and with the support of General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 19], [19, 31], [32, 41], [42, 49], [50, 53], [54, 62], [62, 63], [64, 69], [70, 73], [74, 83], [84, 86], [87, 96], [97, 101], [102, 108], [109, 110], [110, 116], [117, 126], [126, 127], [128, 131], [132, 136], [137, 140], [141, 148], [149, 151], [152, 159], [160, 166], [166, 167]]}
{"doc_key": "ai-dev-117", "ner": [[0, 1, "algorithm"], [6, 7, "researcher"], [9, 10, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "origin", "", false, false], [0, 1, 9, 10, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["LSTM", "was", "proposed", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "LSTM was proposed in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 25], [26, 28], [29, 33], [34, 44], [45, 48], [49, 55], [56, 67], [67, 68]]}
{"doc_key": "ai-dev-118", "ner": [[11, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", ",", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated in a 2 \u00d7 2 contingency table or confusion matrix, as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 76], [77, 83], [83, 84], [85, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-dev-119", "ner": [[9, 9, "conference"], [12, 13, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "also", "contributed", "a", "lot", "to", "the", "creation", "of", "ELRA", "and", "the", "LREC", "conference", "."], "sentence-detokenized": "He also contributed a lot to the creation of ELRA and the LREC conference.", "token2charspan": [[0, 2], [3, 7], [8, 19], [20, 21], [22, 25], [26, 28], [29, 32], [33, 41], [42, 44], [45, 49], [50, 53], [54, 57], [58, 62], [63, 73], [73, 74]]}
{"doc_key": "ai-dev-120", "ner": [[16, 17, "misc"], [21, 22, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 22, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "popular", "application", "for", "serial", "robots", "in", "industry", "today", "is", "the", "pick", "-", "and", "-", "place", "assembly", "robot", ",", "called", "the", "SCARA", "robot", ",", "which", "has", "four", "degrees", "of", "freedom", "."], "sentence-detokenized": "A popular application for serial robots in industry today is the pick-and-place assembly robot, called the SCARA robot, which has four degrees of freedom.", "token2charspan": [[0, 1], [2, 9], [10, 21], [22, 25], [26, 32], [33, 39], [40, 42], [43, 51], [52, 57], [58, 60], [61, 64], [65, 69], [69, 70], [70, 73], [73, 74], [74, 79], [80, 88], [89, 94], [94, 95], [96, 102], [103, 106], [107, 112], [113, 118], [118, 119], [120, 125], [126, 129], [130, 134], [135, 142], [143, 145], [146, 153], [153, 154]]}
{"doc_key": "ai-dev-121", "ner": [[15, 21, "conference"], [23, 23, "conference"], [27, 30, "conference"], [39, 39, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 15, 21, "named", "", false, false], [39, 39, 27, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "one", "of", "the", "founding", "members", "and", "former", "chairman", "(", "2006-2008", ")", "of", "the", "Special", "Interest", "Group", "on", "Web", "as", "Corpus", "(", "SIGWAC", ")", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "also", "one", "of", "the", "founding", "organisers", "of", "SENSEVAL", "."], "sentence-detokenized": "He was one of the founding members and former chairman (2006-2008) of the Special Interest Group on Web as Corpus (SIGWAC) of the Association for Computational Linguistics and also one of the founding organisers of SENSEVAL.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 17], [18, 26], [27, 34], [35, 38], [39, 45], [46, 54], [55, 56], [56, 65], [65, 66], [67, 69], [70, 73], [74, 81], [82, 90], [91, 96], [97, 99], [100, 103], [104, 106], [107, 113], [114, 115], [115, 121], [121, 122], [123, 125], [126, 129], [130, 141], [142, 145], [146, 159], [160, 171], [172, 175], [176, 180], [181, 184], [185, 187], [188, 191], [192, 200], [201, 211], [212, 214], [215, 223], [223, 224]]}
{"doc_key": "ai-dev-122", "ner": [[4, 4, "product"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 4, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "platform", ",", "LinguaStream", "offers", "an", "extensive", "Java", "API", "."], "sentence-detokenized": "As a platform, LinguaStream offers an extensive Java API.", "token2charspan": [[0, 2], [3, 4], [5, 13], [13, 14], [15, 27], [28, 34], [35, 37], [38, 47], [48, 52], [53, 56], [56, 57]]}
{"doc_key": "ai-dev-123", "ner": [[11, 11, "programlang"], [14, 16, "misc"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 19, 21, "type-of", "", false, false], [14, 16, 19, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "robot", "kit", "is", "Android", "-", "based", "and", "is", "programmed", "using", "Java", ",", "the", "Blocks", "programming", "interface", "or", "other", "Android", "programming", "systems", "."], "sentence-detokenized": "The robot kit is Android-based and is programmed using Java, the Blocks programming interface or other Android programming systems.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 16], [17, 24], [24, 25], [25, 30], [31, 34], [35, 37], [38, 48], [49, 54], [55, 59], [59, 60], [61, 64], [65, 71], [72, 83], [84, 93], [94, 96], [97, 102], [103, 110], [111, 122], [123, 130], [130, 131]]}
{"doc_key": "ai-dev-124", "ner": [[10, 17, "algorithm"], [14, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "linked", "list", "definition", "method", "specifies", "the", "use", "of", "a", "depth", "-", "first", "or", "breadth", "-", "first", "search", "."], "sentence-detokenized": "The linked list definition method specifies the use of a depth-first or breadth-first search.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 26], [27, 33], [34, 43], [44, 47], [48, 51], [52, 54], [55, 56], [57, 62], [62, 63], [63, 68], [69, 71], [72, 79], [79, 80], [80, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-dev-125", "ner": [[21, 21, "task"], [25, 28, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "regions", "could", "signal", "the", "presence", "of", "objects", "or", "parts", "of", "objects", "in", "the", "image", "domain", ",", "with", "applications", "to", "object", "recognition", "and", "/", "or", "video", "tracking", "of", "objects", "."], "sentence-detokenized": "These regions could signal the presence of objects or parts of objects in the image domain, with applications to object recognition and/or video tracking of objects.", "token2charspan": [[0, 5], [6, 13], [14, 19], [20, 26], [27, 30], [31, 39], [40, 42], [43, 50], [51, 53], [54, 59], [60, 62], [63, 70], [71, 73], [74, 77], [78, 83], [84, 90], [90, 91], [92, 96], [97, 109], [110, 112], [113, 119], [120, 131], [132, 135], [135, 136], [136, 138], [139, 144], [145, 153], [154, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-dev-126", "ner": [[4, 5, "algorithm"], [7, 7, "product"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 4, 5, "type-of", "", false, false], [7, 7, 14, 15, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "semantic", "network", "is", "WordNet", ",", "a", "lexical", "database", "of", "the", "English", "language", "."], "sentence-detokenized": "An example of a semantic network is WordNet, a lexical database of the English language.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 32], [33, 35], [36, 43], [43, 44], [45, 46], [47, 54], [55, 63], [64, 66], [67, 70], [71, 78], [79, 87], [87, 88]]}
{"doc_key": "ai-dev-127", "ner": [[0, 3, "task"], [7, 8, "field"], [10, 11, "field"], [20, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 7, 8, "part-of", "", false, false], [0, 3, 10, 11, "named", "same", false, false], [0, 3, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Speech", "recognition", "is", "an", "interdisciplinary", "subfield", "of", "computer", "science", "and", "computational", "linguistics", "that", "develops", "methodologies", "and", "technologies", "that", "enable", "the", "recognition", "and", "translation", "of", "spoken", "language", "into", "text", "by", "computers", "."], "sentence-detokenized": "Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that enable the recognition and translation of spoken language into text by computers.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 24], [25, 42], [43, 51], [52, 54], [55, 63], [64, 71], [72, 75], [76, 89], [90, 101], [102, 106], [107, 115], [116, 129], [130, 133], [134, 146], [147, 151], [152, 158], [159, 162], [163, 174], [175, 178], [179, 190], [191, 193], [194, 200], [201, 209], [210, 214], [215, 219], [220, 222], [223, 232], [232, 233]]}
{"doc_key": "ai-dev-128", "ner": [[0, 1, "field"], [8, 9, "misc"], [14, 16, "field"], [18, 18, "task"], [20, 21, "task"], [43, 43, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 43, 43, "named", "same", false, false], [14, 16, 0, 1, "part-of", "subfield", false, false], [18, 18, 0, 1, "part-of", "", false, false], [18, 18, 14, 16, "part-of", "", false, false], [20, 21, 14, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Artificial", "intelligence", "has", "maintained", "the", "greatest", "focus", "on", "applied", "ontology", "in", "sub-fields", "such", "as", "natural", "language", "processing", "within", "machines", "and", "knowledge", "representation", ",", "but", "ontology", "writers", "are", "often", "used", "in", "a", "variety", "of", "fields", "such", "as", "education", "without", "the", "intention", "of", "contributing", "to", "AI", "."], "sentence-detokenized": "Artificial intelligence has maintained the greatest focus on applied ontology in sub-fields such as natural language processing within machines and knowledge representation, but ontology writers are often used in a variety of fields such as education without the intention of contributing to AI.", "token2charspan": [[0, 10], [11, 23], [24, 27], [28, 38], [39, 42], [43, 51], [52, 57], [58, 60], [61, 68], [69, 77], [78, 80], [81, 91], [92, 96], [97, 99], [100, 107], [108, 116], [117, 127], [128, 134], [135, 143], [144, 147], [148, 157], [158, 172], [172, 173], [174, 177], [178, 186], [187, 194], [195, 198], [199, 204], [205, 209], [210, 212], [213, 214], [215, 222], [223, 225], [226, 232], [233, 237], [238, 240], [241, 250], [251, 258], [259, 262], [263, 272], [273, 275], [276, 288], [289, 291], [292, 294], [294, 295]]}
{"doc_key": "ai-dev-129", "ner": [[7, 12, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 12, 14, 15, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "update", "rule", "is", "in", "fact", "the", "stochastic", "update", "of", "the", "gradient", "descent", "for", "linear", "regression", "."], "sentence-detokenized": "This update rule is in fact the stochastic update of the gradient descent for linear regression.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 22], [23, 27], [28, 31], [32, 42], [43, 49], [50, 52], [53, 56], [57, 65], [66, 73], [74, 77], [78, 84], [85, 95], [95, 96]]}
{"doc_key": "ai-dev-130", "ner": [[5, 8, "organisation"], [10, 16, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "elected", "to", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "the", "National", "Academy", "of", "Sciences", "and", "received", "a", "number", "of", "awards", ":"], "sentence-detokenized": "He was elected to the American Academy of Arts and Sciences and the National Academy of Sciences and received a number of awards:", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 46], [47, 50], [51, 59], [60, 63], [64, 67], [68, 76], [77, 84], [85, 87], [88, 96], [97, 100], [101, 109], [110, 111], [112, 118], [119, 121], [122, 128], [128, 129]]}
{"doc_key": "ai-dev-131", "ner": [[7, 7, "organisation"], [13, 14, "person"], [16, 19, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 13, 14, "related-to", "written_about_by", false, false], [7, 7, 16, 19, "related-to", "written_about_by", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "recent", "school", "of", "thought", "on", "Honda", "'s", "strategy", "was", "proposed", "by", "Gary", "Hamel", "and", "C.", "K", ".", "Prahalad", "in", "1989", "."], "sentence-detokenized": "The most recent school of thought on Honda's strategy was proposed by Gary Hamel and C. K. Prahalad in 1989.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 22], [23, 25], [26, 33], [34, 36], [37, 42], [42, 44], [45, 53], [54, 57], [58, 66], [67, 69], [70, 74], [75, 80], [81, 84], [85, 87], [88, 89], [89, 90], [91, 99], [100, 102], [103, 107], [107, 108]]}
{"doc_key": "ai-dev-132", "ner": [[1, 1, "metrics"], [5, 6, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 5, 6, "related-to", "calculates", true, false], [1, 1, 17, 17, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "BLEU", "simply", "calculates", "the", "accuracy", "of", "graphemes", "by", "adding", "an", "equal", "weight", "to", "each", "one", ",", "NIST", "also", "calculates", "how", "informative", "a", "particular", "grapheme", "is", "."], "sentence-detokenized": "While BLEU simply calculates the accuracy of graphemes by adding an equal weight to each one, NIST also calculates how informative a particular grapheme is.", "token2charspan": [[0, 5], [6, 10], [11, 17], [18, 28], [29, 32], [33, 41], [42, 44], [45, 54], [55, 57], [58, 64], [65, 67], [68, 73], [74, 80], [81, 83], [84, 88], [89, 92], [92, 93], [94, 98], [99, 103], [104, 114], [115, 118], [119, 130], [131, 132], [133, 143], [144, 152], [153, 155], [155, 156]]}
{"doc_key": "ai-dev-133", "ner": [[4, 9, "misc"], [10, 13, "conference"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 9, 10, 13, "temporal", "", false, false], [15, 15, 10, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "awarded", "the", "2019", "Lifetime", "Achievement", "Award", "of", "the", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "He was awarded the 2019 Lifetime Achievement Award of the Association for Computational Linguistics (ACL).", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 18], [19, 23], [24, 32], [33, 44], [45, 50], [51, 53], [54, 57], [58, 69], [70, 73], [74, 87], [88, 99], [100, 101], [101, 104], [104, 105], [105, 106]]}
{"doc_key": "ai-dev-134", "ner": [[0, 0, "researcher"], [6, 11, "organisation"], [13, 13, "organisation"], [20, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 11, "role", "", false, false], [0, 0, 20, 24, "role", "", false, false], [13, 13, 6, 11, "named", "", false, false], [26, 26, 20, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "is", "a", "Fellow", "of", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "and", "a", "Fellow", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara is a Fellow of the Institute of Electrical and Electronics Engineers (IEEE) and a Fellow of the American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 18], [19, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 65], [66, 75], [76, 77], [77, 81], [81, 82], [83, 86], [87, 88], [89, 95], [96, 98], [99, 102], [103, 111], [112, 123], [124, 127], [128, 138], [139, 151], [152, 153], [153, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-dev-135", "ner": [[2, 2, "product"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 11, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "following", "MATLAB", "code", "shows", "a", "concrete", "solution", "for", "solving", "the", "system", "of", "non-linear", "equations", "presented", "in", "the", "previous", "section", ":", "See", "also"], "sentence-detokenized": "The following MATLAB code shows a concrete solution for solving the system of non-linear equations presented in the previous section: See also", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 31], [32, 33], [34, 42], [43, 51], [52, 55], [56, 63], [64, 67], [68, 74], [75, 77], [78, 88], [89, 98], [99, 108], [109, 111], [112, 115], [116, 124], [125, 132], [132, 133], [134, 137], [138, 142]]}
{"doc_key": "ai-dev-136", "ner": [[4, 6, "product"], [14, 15, "field"], [37, 38, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 14, 15, "related-to", "trained_by", true, false], [4, 6, 37, 38, "related-to", "trained_by", true, false], [14, 15, 37, 38, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "many", "cases", ",", "pattern", "recognition", "systems", "are", "trained", "from", "labelled", "training", "data", "(", "supervised", "learning", ")", ",", "but", "when", "labelled", "data", "are", "not", "available", ",", "other", "algorithms", "can", "be", "used", "to", "discover", "previously", "unknown", "patterns", "(", "unsupervised", "learning", ")", "."], "sentence-detokenized": "In many cases, pattern recognition systems are trained from labelled training data (supervised learning), but when labelled data are not available, other algorithms can be used to discover previously unknown patterns (unsupervised learning).", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 22], [23, 34], [35, 42], [43, 46], [47, 54], [55, 59], [60, 68], [69, 77], [78, 82], [83, 84], [84, 94], [95, 103], [103, 104], [104, 105], [106, 109], [110, 114], [115, 123], [124, 128], [129, 132], [133, 136], [137, 146], [146, 147], [148, 153], [154, 164], [165, 168], [169, 171], [172, 176], [177, 179], [180, 188], [189, 199], [200, 207], [208, 216], [217, 218], [218, 230], [231, 239], [239, 240], [240, 241]]}
{"doc_key": "ai-dev-137", "ner": [[5, 7, "researcher"], [10, 10, "country"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 10, 10, "physical", "", false, false], [5, 7, 23, 24, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "was", "first", "used", "by", "Lawrence", "J.", "Fogel", "in", "the", "US", "in", "1960", "to", "use", "simulated", "evolution", "as", "a", "learning", "process", "to", "generate", "artificial", "intelligence", "."], "sentence-detokenized": "It was first used by Lawrence J. Fogel in the US in 1960 to use simulated evolution as a learning process to generate artificial intelligence.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 17], [18, 20], [21, 29], [30, 32], [33, 38], [39, 41], [42, 45], [46, 48], [49, 51], [52, 56], [57, 59], [60, 63], [64, 73], [74, 83], [84, 86], [87, 88], [89, 97], [98, 105], [106, 108], [109, 117], [118, 128], [129, 141], [141, 142]]}
{"doc_key": "ai-dev-138", "ner": [[0, 1, "field"], [10, 11, "field"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 10, 11, "part-of", "", false, false], [15, 16, 10, 11, "part-of", "", false, false], [18, 19, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Reinforcement", "learning", "is", "one", "of", "the", "three", "fundamental", "paradigms", "of", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "unsupervised", "learning", "."], "sentence-detokenized": "Reinforcement learning is one of the three fundamental paradigms of machine learning, along with supervised learning and unsupervised learning.", "token2charspan": [[0, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 42], [43, 54], [55, 64], [65, 67], [68, 75], [76, 84], [84, 85], [86, 91], [92, 96], [97, 107], [108, 116], [117, 120], [121, 133], [134, 142], [142, 143]]}
{"doc_key": "ai-dev-139", "ner": [[4, 5, "field"], [12, 12, "programlang"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 28, 29, "usage", "applies", false, false], [12, 12, 28, 29, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "these", "cases", ",", "cloud", "computing", "and", "the", "open", "source", "programming", "language", "R", "can", "help", "smaller", "banks", "adopt", "risk", "analysis", "and", "support", "branch", "-", "level", "monitoring", "by", "applying", "predictive", "analytics", "."], "sentence-detokenized": "In these cases, cloud computing and the open source programming language R can help smaller banks adopt risk analysis and support branch-level monitoring by applying predictive analytics.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 21], [22, 31], [32, 35], [36, 39], [40, 44], [45, 51], [52, 63], [64, 72], [73, 74], [75, 78], [79, 83], [84, 91], [92, 97], [98, 103], [104, 108], [109, 117], [118, 121], [122, 129], [130, 136], [136, 137], [137, 142], [143, 153], [154, 156], [157, 165], [166, 176], [177, 186], [186, 187]]}
{"doc_key": "ai-dev-140", "ner": [[9, 10, "researcher"], [14, 16, "algorithm"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 18, 19, "named", "same", false, false], [14, 16, 9, 10, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "early", "version", "of", "the", "theorem", "was", "proved", "by", "George", "Cybenko", "in", "1989", "for", "sigmoid", "activation", "functions", ".", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "An early version of the theorem was proved by George Cybenko in 1989 for sigmoid activation functions. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 19], [20, 23], [24, 31], [32, 35], [36, 42], [43, 45], [46, 52], [53, 60], [61, 63], [64, 68], [69, 72], [73, 80], [81, 91], [92, 101], [101, 102], [103, 110], [111, 113], [114, 115], [115, 119], [119, 120], [120, 121], [122, 123], [124, 125], [125, 126], [126, 127], [127, 128], [129, 136], [136, 137]]}
{"doc_key": "ai-dev-141", "ner": [[6, 6, "algorithm"], [9, 9, "metrics"], [13, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 6, 6, "part-of", "", false, false], [13, 18, 9, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "process", ",", "known", "as", "cross-validation", ",", "the", "MSE", "is", "often", "called", "mean", "squared", "prediction", "error", "and", "is", "calculated", "as"], "sentence-detokenized": "In this process, known as cross-validation, the MSE is often called mean squared prediction error and is calculated as", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 22], [23, 25], [26, 42], [42, 43], [44, 47], [48, 51], [52, 54], [55, 60], [61, 67], [68, 72], [73, 80], [81, 91], [92, 97], [98, 101], [102, 104], [105, 115], [116, 118]]}
{"doc_key": "ai-dev-142", "ner": [[0, 0, "task"], [4, 6, "task"], [8, 8, "task"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "compare", "", false, false], [4, 6, 14, 15, "part-of", "", false, false], [8, 8, 4, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OMR", "generally", "differs", "from", "optical", "character", "recognition", "(", "OCR", ")", "in", "that", "no", "complicated", "pattern", "recognition", "engine", "is", "required", "."], "sentence-detokenized": "OMR generally differs from optical character recognition (OCR) in that no complicated pattern recognition engine is required.", "token2charspan": [[0, 3], [4, 13], [14, 21], [22, 26], [27, 34], [35, 44], [45, 56], [57, 58], [58, 61], [61, 62], [63, 65], [66, 70], [71, 73], [74, 85], [86, 93], [94, 105], [106, 112], [113, 115], [116, 124], [124, 125]]}
{"doc_key": "ai-dev-143", "ner": [[11, 11, "location"], [13, 13, "location"], [15, 15, "location"], [19, 20, "location"], [22, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 15, 15, "physical", "", false, false], [19, 20, 13, 13, "physical", "", false, false], [22, 23, 13, 13, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2018", "and", "2019", ",", "the", "championship", "will", "be", "held", "in", "Houston", "and", "Detroit", ",", "Michigan", ",", "at", "the", "TCF", "Center", "and", "Ford", "Field", "."], "sentence-detokenized": "In 2018 and 2019, the championship will be held in Houston and Detroit, Michigan, at the TCF Center and Ford Field.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 16], [16, 17], [18, 21], [22, 34], [35, 39], [40, 42], [43, 47], [48, 50], [51, 58], [59, 62], [63, 70], [70, 71], [72, 80], [80, 81], [82, 84], [85, 88], [89, 92], [93, 99], [100, 103], [104, 108], [109, 114], [114, 115]]}
{"doc_key": "ai-dev-144", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "considered", "as", "two", "distinct", "problems", ":", "binary", "classification", "and", "multiclass", "classification", "."], "sentence-detokenized": "Classification can be considered as two distinct problems: binary classification and multiclass classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 57], [57, 58], [59, 65], [66, 80], [81, 84], [85, 95], [96, 110], [110, 111]]}
{"doc_key": "ai-dev-145", "ner": [[4, 5, "product"], [8, 9, "product"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "type-of", "", false, false], [12, 13, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "examples", "of", "popular", "parallel", "robots", "are", "the", "Stewart", "platform", "and", "the", "Delta", "robot", "."], "sentence-detokenized": "Two examples of popular parallel robots are the Stewart platform and the Delta robot.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 23], [24, 32], [33, 39], [40, 43], [44, 47], [48, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-146", "ner": [[4, 6, "algorithm"], [23, 23, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 23, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "However", ",", "the", "ReLU", "activation", "function", ",", "which", "can", "not", "be", "differentiated", "to", "0", ",", "has", "become", "very", "popular", ",", "e.g.", "in", "AlexNet", ")", "."], "sentence-detokenized": "(However, the ReLU activation function, which cannot be differentiated to 0, has become very popular, e.g. in AlexNet).", "token2charspan": [[0, 1], [1, 8], [8, 9], [10, 13], [14, 18], [19, 29], [30, 38], [38, 39], [40, 45], [46, 49], [49, 52], [53, 55], [56, 70], [71, 73], [74, 75], [75, 76], [77, 80], [81, 87], [88, 92], [93, 100], [100, 101], [102, 106], [107, 109], [110, 117], [117, 118], [118, 119]]}
{"doc_key": "ai-dev-147", "ner": [[1, 2, "metrics"], [10, 11, "task"], [14, 14, "task"], [17, 18, "task"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 11, 1, 2, "usage", "", true, false], [14, 14, 10, 11, "part-of", "", false, false], [17, 18, 10, 11, "part-of", "", false, false], [20, 21, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4], "sentence": ["The", "F", "score", "is", "often", "used", "in", "the", "field", "of", "information", "retrieval", "to", "measure", "search", "performance", ",", "document", "classification", "and", "query", "classification", "."], "sentence-detokenized": "The F score is often used in the field of information retrieval to measure search performance, document classification and query classification.", "token2charspan": [[0, 3], [4, 5], [6, 11], [12, 14], [15, 20], [21, 25], [26, 28], [29, 32], [33, 38], [39, 41], [42, 53], [54, 63], [64, 66], [67, 74], [75, 81], [82, 93], [93, 94], [95, 103], [104, 118], [119, 122], [123, 128], [129, 143], [143, 144]]}
{"doc_key": "ai-dev-148", "ner": [[16, 17, "algorithm"], [19, 19, "algorithm"], [22, 23, "algorithm"], [25, 25, "algorithm"], [28, 30, "algorithm"], [32, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[19, 19, 16, 17, "named", "", false, false], [25, 25, 22, 23, "named", "", false, false], [32, 32, 28, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "is", "done", "by", "modelling", "the", "received", "signal", "and", "using", "a", "statistical", "estimation", "method", "such", "as", "maximum", "likelihood", "(", "ML", ")", ",", "majority", "vote", "(", "MV", ")", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "to", "decide", "which", "library", "target", "best", "fits", "the", "model", "constructed", "from", "the", "received", "signal", "."], "sentence-detokenized": "This is done by modelling the received signal and using a statistical estimation method such as maximum likelihood (ML), majority vote (MV) or maximum a posteriori (MAP) to decide which library target best fits the model constructed from the received signal.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 25], [26, 29], [30, 38], [39, 45], [46, 49], [50, 55], [56, 57], [58, 69], [70, 80], [81, 87], [88, 92], [93, 95], [96, 103], [104, 114], [115, 116], [116, 118], [118, 119], [119, 120], [121, 129], [130, 134], [135, 136], [136, 138], [138, 139], [140, 142], [143, 150], [151, 152], [153, 163], [164, 165], [165, 168], [168, 169], [170, 172], [173, 179], [180, 185], [186, 193], [194, 200], [201, 205], [206, 210], [211, 214], [215, 220], [221, 232], [233, 237], [238, 241], [242, 250], [251, 257], [257, 258]]}
{"doc_key": "ai-dev-149", "ner": [[0, 1, "researcher"], [3, 5, "misc"], [7, 7, "field"], [10, 13, "university"], [18, 20, "misc"], [22, 22, "field"], [25, 26, "university"], [32, 32, "misc"], [34, 35, "field"], [38, 40, "university"], [47, 56, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 13, "physical", "", false, false], [0, 1, 10, 13, "role", "", false, false], [0, 1, 25, 26, "physical", "", false, false], [0, 1, 25, 26, "role", "", false, false], [0, 1, 38, 40, "physical", "", false, false], [0, 1, 38, 40, "role", "", false, false], [3, 5, 0, 1, "origin", "", false, false], [3, 5, 7, 7, "topic", "", false, false], [18, 20, 0, 1, "origin", "", false, false], [18, 20, 22, 22, "topic", "", false, false], [32, 32, 0, 1, "origin", "", false, false], [32, 32, 34, 35, "topic", "", false, false], [47, 56, 32, 32, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Sowa", "received", "a", "bachelor", "'s", "degree", "in", "mathematics", "from", "the", "Massachusetts", "Institute", "of", "Technology", "in", "1962", ",", "a", "master", "'s", "degree", "in", "applied", "sciences", "from", "Harvard", "University", "in", "1966", ",", "and", "a", "PhD", "in", "computer", "science", "from", "the", "Vrije", "Universiteit", "Brussel", "in", "1999", "with", "a", "thesis", "entitled", "Knowledge", "Representation", ":", "Logical", ",", "Philosophical", ",", "and", "Computational", "Foundations", "."], "sentence-detokenized": "Sowa received a bachelor's degree in mathematics from the Massachusetts Institute of Technology in 1962, a master's degree in applied sciences from Harvard University in 1966, and a PhD in computer science from the Vrije Universiteit Brussel in 1999 with a thesis entitled Knowledge Representation: Logical, Philosophical, and Computational Foundations.", "token2charspan": [[0, 4], [5, 13], [14, 15], [16, 24], [24, 26], [27, 33], [34, 36], [37, 48], [49, 53], [54, 57], [58, 71], [72, 81], [82, 84], [85, 95], [96, 98], [99, 103], [103, 104], [105, 106], [107, 113], [113, 115], [116, 122], [123, 125], [126, 133], [134, 142], [143, 147], [148, 155], [156, 166], [167, 169], [170, 174], [174, 175], [176, 179], [180, 181], [182, 185], [186, 188], [189, 197], [198, 205], [206, 210], [211, 214], [215, 220], [221, 233], [234, 241], [242, 244], [245, 249], [250, 254], [255, 256], [257, 263], [264, 272], [273, 282], [283, 297], [297, 298], [299, 306], [306, 307], [308, 321], [321, 322], [323, 326], [327, 340], [341, 352], [352, 353]]}
{"doc_key": "ai-dev-150", "ner": [[1, 2, "task"], [8, 8, "task"], [18, 18, "metrics"], [20, 21, "metrics"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 8, 8, "general-affiliation", "", false, false], [18, 18, 1, 2, "part-of", "", true, false], [20, 21, 1, 2, "part-of", "", true, false], [23, 24, 1, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "paraphrase", "recognition", "can", "be", "posed", "as", "a", "classification", "problem", ",", "most", "standard", "evaluation", "metrics", ",", "such", "as", "accuracy", ",", "f1", "score", "or", "ROC", "curve", ",", "perform", "relatively", "well", "."], "sentence-detokenized": "Since paraphrase recognition can be posed as a classification problem, most standard evaluation metrics, such as accuracy, f1 score or ROC curve, perform relatively well.", "token2charspan": [[0, 5], [6, 16], [17, 28], [29, 32], [33, 35], [36, 41], [42, 44], [45, 46], [47, 61], [62, 69], [69, 70], [71, 75], [76, 84], [85, 95], [96, 103], [103, 104], [105, 109], [110, 112], [113, 121], [121, 122], [123, 125], [126, 131], [132, 134], [135, 138], [139, 144], [144, 145], [146, 153], [154, 164], [165, 169], [169, 170]]}
{"doc_key": "ai-dev-151", "ner": [[19, 19, "algorithm"], [30, 33, "algorithm"]], "ner_mapping_to_source": [0, 2], "relations": [[19, 19, 30, 33, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [1], "sentence": ["This", "makes", "it", "practical", "for", "the", "analysis", "of", "large", "datasets", "(", "hundreds", "or", "thousands", "of", "taxa", ")", "and", "for", "bootstrapping", ",", "for", "which", "other", "means", "of", "analysis", "(", "e.g.", "maximum", "parsimony", ",", "maximum", "likelihood", ")", "might", "be", "computationally", "prohibitive", "."], "sentence-detokenized": "This makes it practical for the analysis of large datasets (hundreds or thousands of taxa) and for bootstrapping, for which other means of analysis (e.g. maximum parsimony, maximum likelihood) might be computationally prohibitive.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 31], [32, 40], [41, 43], [44, 49], [50, 58], [59, 60], [60, 68], [69, 71], [72, 81], [82, 84], [85, 89], [89, 90], [91, 94], [95, 98], [99, 112], [112, 113], [114, 117], [118, 123], [124, 129], [130, 135], [136, 138], [139, 147], [148, 149], [149, 153], [154, 161], [162, 171], [171, 172], [173, 180], [181, 191], [191, 192], [193, 198], [199, 201], [202, 217], [218, 229], [229, 230]]}
{"doc_key": "ai-dev-152", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [10, 13, "organisation"], [15, 15, "organisation"], [27, 27, "programlang"], [31, 45, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 27, 27, "named", "same", false, false], [15, 15, 10, 13, "named", "", false, false], [31, 45, 4, 4, "role", "submits", true, false], [31, 45, 6, 6, "role", "submits", true, false], [31, 45, 10, 13, "role", "submits_to", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "submission", "of", "the", "DAML", "+", "OIL", "language", "to", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", "in", "2002", "was", "the", "result", "of", "the", "work", "of", "the", "DAML", "contractors", "and", "the", "Joint", "Ad", "Hoc", "Committee", "on", "Markup", "Languages", "of", "the", "European", "Union", "and", "the", "United", "States", "."], "sentence-detokenized": "The submission of the DAML + OIL language to the World Wide Web Consortium (W3C) in 2002 was the result of the work of the DAML contractors and the Joint Ad Hoc Committee on Markup Languages of the European Union and the United States.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 21], [22, 26], [27, 28], [29, 32], [33, 41], [42, 44], [45, 48], [49, 54], [55, 59], [60, 63], [64, 74], [75, 76], [76, 79], [79, 80], [81, 83], [84, 88], [89, 92], [93, 96], [97, 103], [104, 106], [107, 110], [111, 115], [116, 118], [119, 122], [123, 127], [128, 139], [140, 143], [144, 147], [148, 153], [154, 156], [157, 160], [161, 170], [171, 173], [174, 180], [181, 190], [191, 193], [194, 197], [198, 206], [207, 212], [213, 216], [217, 220], [221, 227], [228, 234], [234, 235]]}
{"doc_key": "ai-dev-153", "ner": [[3, 4, "misc"], [7, 7, "misc"], [10, 11, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 3, 4, "part-of", "", true, false], [10, 11, 3, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "non-linear", "normalisation", "is", "when", "normalisation", "follows", "a", "sigmoid", "function", ";", "in", "this", "case", ",", "the", "normalised", "image", "is", "calculated", "according", "to", "the", "formula"], "sentence-detokenized": "An example of non-linear normalisation is when normalisation follows a sigmoid function; in this case, the normalised image is calculated according to the formula", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 38], [39, 41], [42, 46], [47, 60], [61, 68], [69, 70], [71, 78], [79, 87], [87, 88], [89, 91], [92, 96], [97, 101], [101, 102], [103, 106], [107, 117], [118, 123], [124, 126], [127, 137], [138, 147], [148, 150], [151, 154], [155, 162]]}
{"doc_key": "ai-dev-154", "ner": [[10, 10, "metrics"], [15, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 10, 15, 15, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "remedy", "this", "problem", ",", "it", "was", "pointed", "out", "that", "precision", "is", "usually", "associated", "with", "recall", "."], "sentence-detokenized": "To remedy this problem, it was pointed out that precision is usually associated with recall.", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 22], [22, 23], [24, 26], [27, 30], [31, 38], [39, 42], [43, 47], [48, 57], [58, 60], [61, 68], [69, 79], [80, 84], [85, 91], [91, 92]]}
{"doc_key": "ai-dev-155", "ner": [[9, 11, "metrics"], [18, 19, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [[18, 19, 9, 11, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Commonly", "used", "metrics", "are", "mean", "square", "error", "and", "root", "mean", "square", "error", ",", "the", "latter", "used", "in", "the", "Netflix", "Prize", "."], "sentence-detokenized": "Commonly used metrics are mean square error and root mean square error, the latter used in the Netflix Prize.", "token2charspan": [[0, 8], [9, 13], [14, 21], [22, 25], [26, 30], [31, 37], [38, 43], [44, 47], [48, 52], [53, 57], [58, 64], [65, 70], [70, 71], [72, 75], [76, 82], [83, 87], [88, 90], [91, 94], [95, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-dev-156", "ner": [[11, 15, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "August", "2016", ",", "a", "research", "programme", "was", "announced", "with", "the", "University", "College", "Hospital", "with", "the", "aim", "of", "developing", "an", "algorithm", "that", "can", "automatically", "differentiate", "healthy", "from", "cancerous", "tissue", "in", "the", "head", "and", "neck", "areas", "."], "sentence-detokenized": "In August 2016, a research programme was announced with the University College Hospital with the aim of developing an algorithm that can automatically differentiate healthy from cancerous tissue in the head and neck areas.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 17], [18, 26], [27, 36], [37, 40], [41, 50], [51, 55], [56, 59], [60, 70], [71, 78], [79, 87], [88, 92], [93, 96], [97, 100], [101, 103], [104, 114], [115, 117], [118, 127], [128, 132], [133, 136], [137, 150], [151, 164], [165, 172], [173, 177], [178, 187], [188, 194], [195, 197], [198, 201], [202, 206], [207, 210], [211, 215], [216, 221], [221, 222]]}
{"doc_key": "ai-dev-157", "ner": [[3, 3, "researcher"], [16, 18, "organisation"], [21, 24, "organisation"], [27, 30, "organisation"], [34, 38, "organisation"], [41, 47, "organisation"], [50, 53, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 16, 18, "role", "", false, false], [3, 3, 21, 24, "role", "", false, false], [3, 3, 27, 30, "role", "", false, false], [3, 3, 34, 38, "role", "", false, false], [3, 3, 41, 47, "role", "", false, false], [3, 3, 50, 53, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "impact", "of", "Posner", "'s", "theoretical", "and", "empirical", "contributions", "has", "been", "recognised", "through", "membership", "in", "the", "American", "Psychological", "Association", ",", "the", "Association", "for", "Psychological", "Science", ",", "the", "Society", "of", "Experimental", "Psychologists", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "The impact of Posner's theoretical and empirical contributions has been recognised through membership in the American Psychological Association, the Association for Psychological Science, the Society of Experimental Psychologists, the American Academy of Arts and Sciences, the American Association for the Advancement of Science and the National Academy of Sciences.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 20], [20, 22], [23, 34], [35, 38], [39, 48], [49, 62], [63, 66], [67, 71], [72, 82], [83, 90], [91, 101], [102, 104], [105, 108], [109, 117], [118, 131], [132, 143], [143, 144], [145, 148], [149, 160], [161, 164], [165, 178], [179, 186], [186, 187], [188, 191], [192, 199], [200, 202], [203, 215], [216, 229], [229, 230], [231, 234], [235, 243], [244, 251], [252, 254], [255, 259], [260, 263], [264, 272], [272, 273], [274, 277], [278, 286], [287, 298], [299, 302], [303, 306], [307, 318], [319, 321], [322, 329], [330, 333], [334, 337], [338, 346], [347, 354], [355, 357], [358, 366], [366, 367]]}
{"doc_key": "ai-dev-158", "ner": [[2, 2, "product"], [7, 8, "field"], [12, 13, "task"], [17, 17, "task"], [19, 19, "task"], [22, 24, "task"], [26, 26, "task"], [29, 30, "field"], [32, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 2, 7, 8, "usage", "", false, false], [12, 13, 7, 8, "part-of", "", false, false], [17, 17, 7, 8, "part-of", "", false, false], [19, 19, 17, 17, "named", "", false, false], [22, 24, 7, 8, "part-of", "", false, false], [26, 26, 22, 24, "named", "", false, false], [29, 30, 7, 8, "part-of", "", false, false], [32, 33, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["These", "intelligent", "chatbots", "use", "all", "kinds", "of", "artificial", "intelligence", ",", "such", "as", "image", "moderation", "and", "natural", "language", "understanding", "(", "NLU", ")", ",", "natural", "language", "generation", "(", "NLG", ")", ",", "machine", "learning", "and", "deep", "learning", "."], "sentence-detokenized": "These intelligent chatbots use all kinds of artificial intelligence, such as image moderation and natural language understanding (NLU), natural language generation (NLG), machine learning and deep learning.", "token2charspan": [[0, 5], [6, 17], [18, 26], [27, 30], [31, 34], [35, 40], [41, 43], [44, 54], [55, 67], [67, 68], [69, 73], [74, 76], [77, 82], [83, 93], [94, 97], [98, 105], [106, 114], [115, 128], [129, 130], [130, 133], [133, 134], [134, 135], [136, 143], [144, 152], [153, 163], [164, 165], [165, 168], [168, 169], [169, 170], [171, 178], [179, 187], [188, 191], [192, 196], [197, 205], [205, 206]]}
{"doc_key": "ai-dev-159", "ner": [[4, 6, "metrics"], [8, 8, "metrics"], [11, 11, "metrics"], [14, 20, "metrics"], [27, 29, "metrics"], [31, 31, "metrics"], [34, 40, "metrics"], [44, 46, "metrics"], [48, 48, "metrics"], [51, 58, "metrics"], [64, 66, "metrics"], [68, 68, "metrics"], [71, 76, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 4, 6, "named", "", false, false], [11, 11, 4, 6, "named", "", false, false], [14, 20, 4, 6, "named", "", false, false], [31, 31, 27, 29, "named", "", false, false], [34, 40, 27, 29, "named", "", false, false], [48, 48, 44, 46, "named", "", false, false], [51, 58, 44, 46, "named", "", false, false], [68, 68, 64, 66, "named", "", false, false], [71, 76, 64, 66, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "line", "ratios", "are", "Positive", "Predictive", "Value", "(", "PPV", ",", "a.k.a.", "accuracy", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "with", "the", "complement", "of", "FALSE", "Discovery", "Rate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "and", "Negative", "Predictive", "Value", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "with", "the", "complement", "of", "FALSE", "Omission", "Rate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "The line ratios are Positive Predictive Value (PPV, a.k.a. accuracy) (TP / (TP + FP)), with the complement of FALSE Discovery Rate (FDR) (FP / (TP + FP)); and Negative Predictive Value (NPV) (TN / (TN + FN)), with the complement of FALSE Omission Rate (FOR) (FN / (TN + FN)).", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 19], [20, 28], [29, 39], [40, 45], [46, 47], [47, 50], [50, 51], [52, 58], [59, 67], [67, 68], [69, 70], [70, 72], [73, 74], [75, 76], [76, 78], [79, 80], [81, 83], [83, 84], [84, 85], [85, 86], [87, 91], [92, 95], [96, 106], [107, 109], [110, 115], [116, 125], [126, 130], [131, 132], [132, 135], [135, 136], [137, 138], [138, 140], [141, 142], [143, 144], [144, 146], [147, 148], [149, 151], [151, 152], [152, 153], [153, 154], [155, 158], [159, 167], [168, 178], [179, 184], [185, 186], [186, 189], [189, 190], [191, 192], [192, 194], [195, 196], [197, 198], [198, 200], [201, 202], [203, 205], [205, 206], [206, 207], [207, 208], [209, 213], [214, 217], [218, 228], [229, 231], [232, 237], [238, 246], [247, 251], [252, 253], [253, 256], [256, 257], [258, 259], [259, 261], [262, 263], [264, 265], [265, 267], [268, 269], [270, 272], [272, 273], [273, 274], [274, 275]]}
{"doc_key": "ai-dev-160", "ner": [[8, 8, "misc"], [14, 15, "algorithm"], [17, 17, "algorithm"], [21, 23, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 17, 14, 15, "named", "", false, false], [25, 25, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "information", "is", "a", "mixture", "of", "sitemap", "and", "RSS", "and", "is", "created", "using", "the", "Information", "Model", "(", "IM", ")", "and", "the", "Biomedical", "Resource", "Ontology", "(", "BRO", ")", "."], "sentence-detokenized": "The information is a mixture of sitemap and RSS and is created using the Information Model (IM) and the Biomedical Resource Ontology (BRO).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 20], [21, 28], [29, 31], [32, 39], [40, 43], [44, 47], [48, 51], [52, 54], [55, 62], [63, 68], [69, 72], [73, 84], [85, 90], [91, 92], [92, 94], [94, 95], [96, 99], [100, 103], [104, 114], [115, 123], [124, 132], [133, 134], [134, 137], [137, 138], [138, 139]]}
{"doc_key": "ai-dev-161", "ner": [[1, 3, "task"], [7, 9, "algorithm"], [11, 14, "algorithm"], [21, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 11, 14, "origin", "based_on", false, false], [11, 14, 7, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Recent", "text", "recognition", "is", "based", "on", "a", "recurrent", "neural", "network", "(", "short", "-", "term", "memory", ")", "and", "does", "not", "require", "a", "language", "model", "."], "sentence-detokenized": "Recent text recognition is based on a recurrent neural network (short-term memory) and does not require a language model.", "token2charspan": [[0, 6], [7, 11], [12, 23], [24, 26], [27, 32], [33, 35], [36, 37], [38, 47], [48, 54], [55, 62], [63, 64], [64, 69], [69, 70], [70, 74], [75, 81], [81, 82], [83, 86], [87, 91], [92, 95], [96, 103], [104, 105], [106, 114], [115, 120], [120, 121]]}
{"doc_key": "ai-dev-162", "ner": [[1, 2, "misc"], [4, 5, "metrics"], [8, 9, "algorithm"], [13, 13, "metrics"], [12, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 1, 2, "type-of", "", false, false], [8, 9, 4, 5, "related-to", "", true, false], [13, 13, 1, 2, "type-of", "", false, false], [12, 17, 13, 13, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Popular", "loss", "functions", "include", "hinge", "loss", "(", "for", "linear", "SVMs", ")", "and", "log", "loss", "(", "for", "logistic", "regression", ")", "."], "sentence-detokenized": "Popular loss functions include hinge loss (for linear SVMs) and log loss (for logistic regression).", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 30], [31, 36], [37, 41], [42, 43], [43, 46], [47, 53], [54, 58], [58, 59], [60, 63], [64, 67], [68, 72], [73, 74], [74, 77], [78, 86], [87, 97], [97, 98], [98, 99]]}
{"doc_key": "ai-dev-163", "ner": [[0, 1, "metrics"], [10, 16, "metrics"], [18, 18, "metrics"], [21, 23, "metrics"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 10, 16, "compare", "", false, false], [0, 1, 21, 23, "compare", "", false, false], [18, 18, 10, 16, "named", "", false, false], [25, 25, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "was", "designed", "to", "improve", "on", "traditional", "methods", "such", "as", "peak", "signal", "-", "to", "-", "noise", "ratio", "(", "PSNR", ")", "and", "mean", "square", "error", "(", "MSE", ")", "."], "sentence-detokenized": "SSIM was designed to improve on traditional methods such as peak signal-to-noise ratio (PSNR) and mean square error (MSE).", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 28], [29, 31], [32, 43], [44, 51], [52, 56], [57, 59], [60, 64], [65, 71], [71, 72], [72, 74], [74, 75], [75, 80], [81, 86], [87, 88], [88, 92], [92, 93], [94, 97], [98, 102], [103, 109], [110, 115], [116, 117], [117, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-dev-164", "ner": [[10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "inspired", "subsequent", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "His work inspired subsequent generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 28], [29, 40], [41, 43], [44, 52], [53, 64], [65, 69], [70, 72], [73, 79], [80, 86], [86, 87], [88, 92], [93, 100], [101, 104], [105, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-dev-165", "ner": [[10, 14, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 20, 10, 14, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "addition", ",", "pulse", "training", "is", "non-differentiable", ",", "which", "eliminates", "back", "-", "propagation", "-", "based", "training", "methods", "such", "as", "gradient", "descent", "."], "sentence-detokenized": "In addition, pulse training is non-differentiable, which eliminates back-propagation-based training methods such as gradient descent.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 18], [19, 27], [28, 30], [31, 49], [49, 50], [51, 56], [57, 67], [68, 72], [72, 73], [73, 84], [84, 85], [85, 90], [91, 99], [100, 107], [108, 112], [113, 115], [116, 124], [125, 132], [132, 133]]}
{"doc_key": "ai-dev-166", "ner": [[8, 9, "metrics"], [15, 16, "metrics"], [18, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 15, 16, "related-to", "describes", false, false], [15, 16, 18, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "relationships", "can", "easily", "be", "represented", "with", "a", "confusion", "matrix", ",", "a", "table", "describing", "the", "accuracy", "of", "a", "classification", "model", "."], "sentence-detokenized": "These relationships can easily be represented with a confusion matrix, a table describing the accuracy of a classification model.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 30], [31, 33], [34, 45], [46, 50], [51, 52], [53, 62], [63, 69], [69, 70], [71, 72], [73, 78], [79, 89], [90, 93], [94, 102], [103, 105], [106, 107], [108, 122], [123, 128], [128, 129]]}
{"doc_key": "ai-dev-167", "ner": [[2, 10, "conference"], [8, 8, "conference"], [12, 13, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 2, 10, "named", "", false, false], [12, 13, 2, 10, "physical", "", false, false], [12, 13, 2, 10, "role", "", false, false], [12, 13, 2, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["At", "the", "2018", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "Conference", ",", "Google", "researchers", "presented", "work"], "sentence-detokenized": "At the 2018 Neural Information Processing Systems (NeurIPS) Conference, Google researchers presented work", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 30], [31, 41], [42, 49], [50, 51], [51, 58], [58, 59], [60, 70], [70, 71], [72, 78], [79, 90], [91, 100], [101, 105]]}
{"doc_key": "ai-dev-168", "ner": [[4, 4, "university"], [13, 13, "product"], [18, 20, "misc"], [24, 24, "conference"], [29, 32, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 18, 20, "win-defeat", "", false, false], [18, 20, 24, 24, "temporal", "", false, false], [29, 32, 24, 24, "part-of", "", false, false], [29, 32, 24, 24, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "his", "time", "at", "Duke", ",", "he", "worked", "on", "the", "automatic", "crossword", "solver", "PROVERB", ",", "which", "won", "an", "Outstanding", "Paper", "Award", "in", "1999", "from", "AAAI", "and", "participated", "in", "the", "American", "Crossword", "Puzzle", "Tournament", "."], "sentence-detokenized": "During his time at Duke, he worked on the automatic crossword solver PROVERB, which won an Outstanding Paper Award in 1999 from AAAI and participated in the American Crossword Puzzle Tournament.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 18], [19, 23], [23, 24], [25, 27], [28, 34], [35, 37], [38, 41], [42, 51], [52, 61], [62, 68], [69, 76], [76, 77], [78, 83], [84, 87], [88, 90], [91, 102], [103, 108], [109, 114], [115, 117], [118, 122], [123, 127], [128, 132], [133, 136], [137, 149], [150, 152], [153, 156], [157, 165], [166, 175], [176, 182], [183, 193], [193, 194]]}
{"doc_key": "ai-dev-169", "ner": [[2, 3, "location"], [5, 5, "location"], [15, 15, "country"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 5, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Headquartered", "in", "Rochester", "Hills", ",", "Michigan", ",", "the", "company", "had", "10", "regional", "offices", "in", "the", "US", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "sentence-detokenized": "Headquartered in Rochester Hills, Michigan, the company had 10 regional offices in the US, Canada, Mexico and Brazil.", "token2charspan": [[0, 13], [14, 16], [17, 26], [27, 32], [32, 33], [34, 42], [42, 43], [44, 47], [48, 55], [56, 59], [60, 62], [63, 71], [72, 79], [80, 82], [83, 86], [87, 89], [89, 90], [91, 97], [97, 98], [99, 105], [106, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-dev-170", "ner": [[12, 12, "product"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "joins", "a", "collection", "of", "historically", "important", "robots", "that", "includes", "an", "early", "Unimate", "and", "the", "Odetics", "Odex", "1", "."], "sentence-detokenized": "It joins a collection of historically important robots that includes an early Unimate and the Odetics Odex 1.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 21], [22, 24], [25, 37], [38, 47], [48, 54], [55, 59], [60, 68], [69, 71], [72, 77], [78, 85], [86, 89], [90, 93], [94, 101], [102, 106], [107, 108], [108, 109]]}
{"doc_key": "ai-dev-171", "ner": [[8, 9, "researcher"], [13, 13, "organisation"], [15, 16, "researcher"], [26, 34, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 13, 13, "physical", "", false, false], [8, 9, 13, 13, "role", "", false, false], [15, 16, 13, 13, "physical", "", false, false], [15, 16, 13, 13, "role", "", false, false], [15, 16, 26, 34, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "guest", "editor", "for", "that", "issue", "will", "be", "David", "'s", "former", "colleague", "at", "NIST", ",", "Judah", "Levine", ",", "who", "is", "the", "most", "recent", "recipient", "of", "the", "I", ".", "I", ".", "Award", ".", "I", ".", "Rabi", "."], "sentence-detokenized": "The guest editor for that issue will be David's former colleague at NIST, Judah Levine, who is the most recent recipient of the I. I. Award. I. Rabi.", "token2charspan": [[0, 3], [4, 9], [10, 16], [17, 20], [21, 25], [26, 31], [32, 36], [37, 39], [40, 45], [45, 47], [48, 54], [55, 64], [65, 67], [68, 72], [72, 73], [74, 79], [80, 86], [86, 87], [88, 91], [92, 94], [95, 98], [99, 103], [104, 110], [111, 120], [121, 123], [124, 127], [128, 129], [129, 130], [131, 132], [132, 133], [134, 139], [139, 140], [141, 142], [142, 143], [144, 148], [148, 149]]}
{"doc_key": "ai-dev-172", "ner": [[12, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "can", "be", "organised", "in", "a", "2", "\u00d7", "2", "contingency", "table", "(", "confusion", "matrix", ")", ",", "conventionally", "with", "the", "test", "result", "on", "the", "vertical", "axis", "and", "the", "actual", "condition", "on", "the", "horizontal", "axis", "."], "sentence-detokenized": "These can be organised in a 2 \u00d7 2 contingency table (confusion matrix), conventionally with the test result on the vertical axis and the actual condition on the horizontal axis.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 22], [23, 25], [26, 27], [28, 29], [30, 31], [32, 33], [34, 45], [46, 51], [52, 53], [53, 62], [63, 69], [69, 70], [70, 71], [72, 86], [87, 91], [92, 95], [96, 100], [101, 107], [108, 110], [111, 114], [115, 123], [124, 128], [129, 132], [133, 136], [137, 143], [144, 153], [154, 156], [157, 160], [161, 171], [172, 176], [176, 177]]}
{"doc_key": "ai-dev-173", "ner": [[1, 4, "product"], [8, 8, "product"], [10, 10, "product"], [12, 13, "product"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 4, 8, 8, "part-of", "", false, false], [1, 4, 10, 10, "part-of", "", false, false], [1, 4, 12, 13, "part-of", "", false, false], [1, 4, 15, 17, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Apple", "iOS", "operating", "system", "used", "on", "the", "iPhone", ",", "iPad", "and", "iPod", "Touch", "uses", "VoiceOver", "speech", "synthesis", "accessibility", "."], "sentence-detokenized": "The Apple iOS operating system used on the iPhone, iPad and iPod Touch uses VoiceOver speech synthesis accessibility.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 23], [24, 30], [31, 35], [36, 38], [39, 42], [43, 49], [49, 50], [51, 55], [56, 59], [60, 64], [65, 70], [71, 75], [76, 85], [86, 92], [93, 102], [103, 116], [116, 117]]}
{"doc_key": "ai-dev-174", "ner": [[7, 10, "conference"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "the", "best", "system", "with", "MUC", "-", "7", "scored", "93.39", "%", "of", "the", "F", "-", "measure", ",", "while", "human", "annotators", "scored", "97.6", "%", "and", "96.95", "%", "."], "sentence-detokenized": "For example, the best system with MUC-7 scored 93.39% of the F-measure, while human annotators scored 97.6% and 96.95%.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 33], [34, 37], [37, 38], [38, 39], [40, 46], [47, 52], [52, 53], [54, 56], [57, 60], [61, 62], [62, 63], [63, 70], [70, 71], [72, 77], [78, 83], [84, 94], [95, 101], [102, 106], [106, 107], [108, 111], [112, 117], [117, 118], [118, 119]]}
{"doc_key": "ai-dev-175", "ner": [[12, 14, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 16, 12, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "done", "using", "standard", "neural", "network", "training", "algorithms", ",", "such", "as", "stochastic", "gradient", "descent", "with", "backpropagation", "."], "sentence-detokenized": "This is done using standard neural network training algorithms, such as stochastic gradient descent with backpropagation.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 18], [19, 27], [28, 34], [35, 42], [43, 51], [52, 62], [62, 63], [64, 68], [69, 71], [72, 82], [83, 91], [92, 99], [100, 104], [105, 120], [120, 121]]}
{"doc_key": "ai-dev-176", "ner": [[0, 2, "organisation"], [18, 18, "country"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 18, 18, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "is", "a", "top", "1000", "site", ",", "ranking", "around", "No.", "400", "globally", "and", "No.", "150", "in", "the", "US", "alone", ",", "according", "to", "the", "website", "ranker", "Alexa", "."], "sentence-detokenized": "Rotten Tomatoes is a top 1000 site, ranking around No. 400 globally and No. 150 in the US alone, according to the website ranker Alexa.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 20], [21, 24], [25, 29], [30, 34], [34, 35], [36, 43], [44, 50], [51, 54], [55, 58], [59, 67], [68, 71], [72, 75], [76, 79], [80, 82], [83, 86], [87, 89], [90, 95], [95, 96], [97, 106], [107, 109], [110, 113], [114, 121], [122, 128], [129, 134], [134, 135]]}
{"doc_key": "ai-dev-177", "ner": [[14, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "general", ",", "all", "learning", "shows", "incremental", "change", "over", "time", ",", "but", "describes", "a", "sigmoid", "function", "that", "has", "different", "aspects", "depending", "on", "the", "time", "scale", "of", "observation", "."], "sentence-detokenized": "In general, all learning shows incremental change over time, but describes a sigmoid function that has different aspects depending on the time scale of observation.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 24], [25, 30], [31, 42], [43, 49], [50, 54], [55, 59], [59, 60], [61, 64], [65, 74], [75, 76], [77, 84], [85, 93], [94, 98], [99, 102], [103, 112], [113, 120], [121, 130], [131, 133], [134, 137], [138, 142], [143, 148], [149, 151], [152, 163], [163, 164]]}
{"doc_key": "ai-dev-178", "ner": [[0, 0, "metrics"], [5, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["SSD", "is", "also", "known", "as", "mean", "square", "error", "."], "sentence-detokenized": "SSD is also known as mean square error.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 17], [18, 20], [21, 25], [26, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-dev-179", "ner": [[0, 2, "algorithm"], [4, 5, "algorithm"], [8, 10, "algorithm"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 22, 23, "related-to", "can_be_related_to", true, false], [4, 5, 22, 23, "related-to", "can_be_related_to", true, false], [8, 10, 22, 23, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", ",", "neural", "networks", "or", "a", "naive", "Bayes", "classifier", "can", "be", "used", "in", "combination", "with", "model", "quality", "measures", "such", "as", "balanced", "accuracy", "."], "sentence-detokenized": "Decision tree learning, neural networks or a naive Bayes classifier can be used in combination with model quality measures such as balanced accuracy.", "token2charspan": [[0, 8], [9, 13], [14, 22], [22, 23], [24, 30], [31, 39], [40, 42], [43, 44], [45, 50], [51, 56], [57, 67], [68, 71], [72, 74], [75, 79], [80, 82], [83, 94], [95, 99], [100, 105], [106, 113], [114, 122], [123, 127], [128, 130], [131, 139], [140, 148], [148, 149]]}
{"doc_key": "ai-dev-180", "ner": [[17, 17, "conference"], [23, 27, "conference"], [28, 30, "misc"], [36, 38, "product"], [45, 48, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[28, 30, 23, 27, "origin", "", false, false], [28, 30, 23, 27, "temporal", "", false, false], [36, 38, 28, 30, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "is", "a", "past", "president", "(", "1979", ")", "and", "an", "inaugural", "Fellow", "(", "2011", ")", "of", "the", "ACL", ",", "a", "co-recipient", "of", "the", "1992", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "for", "his", "contribution", "to", "the", "Interlisp", "programming", "system", ",", "and", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "He is a past president (1979) and an inaugural Fellow (2011) of the ACL, a co-recipient of the 1992 Association for Computing Machinery Software Systems Award for his contribution to the Interlisp programming system, and a Fellow of the Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 22], [23, 24], [24, 28], [28, 29], [30, 33], [34, 36], [37, 46], [47, 53], [54, 55], [55, 59], [59, 60], [61, 63], [64, 67], [68, 71], [71, 72], [73, 74], [75, 87], [88, 90], [91, 94], [95, 99], [100, 111], [112, 115], [116, 125], [126, 135], [136, 144], [145, 152], [153, 158], [159, 162], [163, 166], [167, 179], [180, 182], [183, 186], [187, 196], [197, 208], [209, 215], [215, 216], [217, 220], [221, 222], [223, 229], [230, 232], [233, 236], [237, 248], [249, 252], [253, 262], [263, 272], [272, 273]]}
{"doc_key": "ai-dev-181", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 15, "researcher"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 27, 28, "related-to", "", false, false], [5, 6, 27, 28, "related-to", "", false, false], [8, 8, 27, 28, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Together", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "is", "considered", "by", "Cade", "Metz", "to", "be", "one", "of", "the", "three", "people", "most", "responsible", "for", "the", "advancement", "of", "deep", "learning", "in", "the", "1990s", "and", "2000s", "."], "sentence-detokenized": "Together with Geoffrey Hinton and Yann LeCun, Bengio is considered by Cade Metz to be one of the three people most responsible for the advancement of deep learning in the 1990s and 2000s.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 29], [30, 33], [34, 38], [39, 44], [44, 45], [46, 52], [53, 55], [56, 66], [67, 69], [70, 74], [75, 79], [80, 82], [83, 85], [86, 89], [90, 92], [93, 96], [97, 102], [103, 109], [110, 114], [115, 126], [127, 130], [131, 134], [135, 146], [147, 149], [150, 154], [155, 163], [164, 166], [167, 170], [171, 176], [177, 180], [181, 186], [186, 187]]}
{"doc_key": "ai-dev-182", "ner": [[1, 2, "field"], [4, 5, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "information", "theory", "and", "computer", "science", ",", "a", "code", "is", "usually", "regarded", "as", "an", "algorithm", "that", "uniquely", "represents", "symbols", "in", "a", "source", "alphabet", "with", "encoded", "strings", ",", "which", "may", "be", "in", "another", "target", "alphabet", "."], "sentence-detokenized": "In information theory and computer science, a code is usually regarded as an algorithm that uniquely represents symbols in a source alphabet with encoded strings, which may be in another target alphabet.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 45], [46, 50], [51, 53], [54, 61], [62, 70], [71, 73], [74, 76], [77, 86], [87, 91], [92, 100], [101, 111], [112, 119], [120, 122], [123, 124], [125, 131], [132, 140], [141, 145], [146, 153], [154, 161], [161, 162], [163, 168], [169, 172], [173, 175], [176, 178], [179, 186], [187, 193], [194, 202], [202, 203]]}
{"doc_key": "ai-dev-183", "ner": [[8, 9, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 8, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "fairly", "simple", "non", "-linear", "function", ",", "the", "sigmoid", "function", ",", "like", "the", "logistic", "function", ",", "also", "has", "an", "easily", "calculable", "derivative", ",", "which", "can", "be", "important", "for", "calculating", "updates", "of", "weights", "in", "the", "network", "."], "sentence-detokenized": "A fairly simple non-linear function, the sigmoid function, like the logistic function, also has an easily calculable derivative, which can be important for calculating updates of weights in the network.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 19], [19, 26], [27, 35], [35, 36], [37, 40], [41, 48], [49, 57], [57, 58], [59, 63], [64, 67], [68, 76], [77, 85], [85, 86], [87, 91], [92, 95], [96, 98], [99, 105], [106, 116], [117, 127], [127, 128], [129, 134], [135, 138], [139, 141], [142, 151], [152, 155], [156, 167], [168, 175], [176, 178], [179, 186], [187, 189], [190, 193], [194, 201], [201, 202]]}
{"doc_key": "ai-dev-184", "ner": [[0, 0, "person"], [4, 4, "location"], [6, 6, "location"], [8, 10, "country"], [13, 13, "country"], [17, 18, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 4, "physical", "", false, false], [4, 4, 6, 6, "physical", "", false, false], [6, 6, 8, 10, "physical", "", false, false], [6, 6, 13, 13, "physical", "", false, false], [6, 6, 17, 18, "physical", "", false, false], [13, 13, 8, 10, "origin", "", false, false], [17, 18, 13, 13, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "was", "born", "in", "Hronov", ",", "Bohemia", "(", "Austria", "-", "Hungary", ",", "later", "Czechoslovakia", ",", "now", "the", "Czech", "Republic", ")", "in", "1887", "."], "sentence-detokenized": "\u010capek was born in Hronov, Bohemia (Austria-Hungary, later Czechoslovakia, now the Czech Republic) in 1887.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 24], [24, 25], [26, 33], [34, 35], [35, 42], [42, 43], [43, 50], [50, 51], [52, 57], [58, 72], [72, 73], [74, 77], [78, 81], [82, 87], [88, 96], [96, 97], [98, 100], [101, 105], [105, 106]]}
{"doc_key": "ai-dev-185", "ner": [[5, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "specialised", "software", "can", "narrate", "RSS", "."], "sentence-detokenized": "Some specialised software can narrate RSS.", "token2charspan": [[0, 4], [5, 16], [17, 25], [26, 29], [30, 37], [38, 41], [41, 42]]}
{"doc_key": "ai-dev-186", "ner": [[6, 7, "task"], [11, 12, "task"], [14, 14, "task"], [16, 16, "task"], [19, 21, "task"], [28, 29, "task"], [32, 33, "task"], [37, 38, "task"], [41, 43, "product"], [45, 46, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[6, 7, 11, 12, "related-to", "", true, false], [6, 7, 14, 14, "related-to", "", true, false], [6, 7, 16, 16, "related-to", "", true, false], [32, 33, 28, 29, "usage", "", true, false], [41, 43, 37, 38, "type-of", "", false, false], [45, 46, 37, 38, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Aspects", "of", "ontology", "editors", "include", ":", "visual", "navigation", "possibilities", "within", "the", "knowledge", "model", ",", "inference", "and", "extraction", "engines", ";", "support", "for", "modules", ";", "import", "and", "export", "of", "foreign", "knowledge", "representation", "languages", "for", "ontology", "matching", ";", "support", "for", "meta", "-ontologies", "such", "as", "OWL", "-", "S", ",", "Dublin", "Core", ",", "etc", "."], "sentence-detokenized": "Aspects of ontology editors include: visual navigation possibilities within the knowledge model, inference and extraction engines; support for modules; import and export of foreign knowledge representation languages for ontology matching; support for meta-ontologies such as OWL-S, Dublin Core, etc.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 27], [28, 35], [35, 36], [37, 43], [44, 54], [55, 68], [69, 75], [76, 79], [80, 89], [90, 95], [95, 96], [97, 106], [107, 110], [111, 121], [122, 129], [129, 130], [131, 138], [139, 142], [143, 150], [150, 151], [152, 158], [159, 162], [163, 169], [170, 172], [173, 180], [181, 190], [191, 205], [206, 215], [216, 219], [220, 228], [229, 237], [237, 238], [239, 246], [247, 250], [251, 255], [255, 266], [267, 271], [272, 274], [275, 278], [278, 279], [279, 280], [280, 281], [282, 288], [289, 293], [293, 294], [295, 298], [298, 299]]}
{"doc_key": "ai-dev-187", "ner": [[1, 1, "organisation"], [6, 10, "misc"], [13, 14, "task"], [21, 22, "field"], [25, 25, "misc"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 10, 1, 1, "origin", "", false, false], [13, 14, 6, 10, "part-of", "", false, false], [21, 22, 6, 10, "part-of", "", false, false], [25, 25, 21, 22, "type-of", "", false, false], [27, 28, 21, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "FBI", "has", "also", "established", "its", "next", "-", "generation", "identification", "programme", "to", "include", "facial", "recognition", ",", "in", "addition", "to", "more", "traditional", "biometric", "data", "such", "as", "fingerprints", "and", "iris", "scans", ",", "which", "can", "be", "extracted", "from", "both", "criminal", "and", "civil", "databases", "."], "sentence-detokenized": "The FBI has also established its next-generation identification programme to include facial recognition, in addition to more traditional biometric data such as fingerprints and iris scans, which can be extracted from both criminal and civil databases.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 28], [29, 32], [33, 37], [37, 38], [38, 48], [49, 63], [64, 73], [74, 76], [77, 84], [85, 91], [92, 103], [103, 104], [105, 107], [108, 116], [117, 119], [120, 124], [125, 136], [137, 146], [147, 151], [152, 156], [157, 159], [160, 172], [173, 176], [177, 181], [182, 187], [187, 188], [189, 194], [195, 198], [199, 201], [202, 211], [212, 216], [217, 221], [222, 230], [231, 234], [235, 240], [241, 250], [250, 251]]}
{"doc_key": "ai-dev-188", "ner": [[5, 6, "person"], [14, 15, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "2016", "season", ",", "Samantha", "Ponder", "was", "added", "as", "a", "presenter", ",", "replacing", "Molly", "McGrath", "."], "sentence-detokenized": "For the 2016 season, Samantha Ponder was added as a presenter, replacing Molly McGrath.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 19], [19, 20], [21, 29], [30, 36], [37, 40], [41, 46], [47, 49], [50, 51], [52, 61], [61, 62], [63, 72], [73, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-dev-189", "ner": [[3, 5, "algorithm"], [18, 22, "misc"], [24, 24, "misc"], [26, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "adversarial", "search", "algorithm", "commonly", "used", "for", "the", "automatic", "play", "of", "two", "-", "player", "games", "(", "Tic", "-", "tac", "-", "toe", ",", "Chess", ",", "Go", ",", "etc.", ")", "."], "sentence-detokenized": "This is an adversarial search algorithm commonly used for the automatic play of two-player games (Tic-tac-toe, Chess, Go, etc.).", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 29], [30, 39], [40, 48], [49, 53], [54, 57], [58, 61], [62, 71], [72, 76], [77, 79], [80, 83], [83, 84], [84, 90], [91, 96], [97, 98], [98, 101], [101, 102], [102, 105], [105, 106], [106, 109], [109, 110], [111, 116], [116, 117], [118, 120], [120, 121], [122, 126], [126, 127], [127, 128]]}
{"doc_key": "ai-dev-190", "ner": [[6, 9, "field"], [11, 12, "field"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "involves", "the", "fields", "of", "computer", "vision", "or", "computer", "vision", "and", "medical", "imaging", "and", "makes", "intensive", "use", "of", "pattern", "recognition", ",", "digital", "geometry", "and", "signal", "processing", "."], "sentence-detokenized": "It involves the fields of computer vision or computer vision and medical imaging and makes intensive use of pattern recognition, digital geometry and signal processing.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 22], [23, 25], [26, 34], [35, 41], [42, 44], [45, 53], [54, 60], [61, 64], [65, 72], [73, 80], [81, 84], [85, 90], [91, 100], [101, 104], [105, 107], [108, 115], [116, 127], [127, 128], [129, 136], [137, 145], [146, 149], [150, 156], [157, 167], [167, 168]]}
{"doc_key": "ai-dev-191", "ner": [[2, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "facial", "recognition", "system", ",", "for", "example", ",", "the", "input", "is", "an", "image", "of", "a", "person", "'s", "face", "and", "the", "output", "label", "is", "the", "name", "of", "that", "person", "."], "sentence-detokenized": "In the facial recognition system, for example, the input is an image of a person's face and the output label is the name of that person.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 25], [26, 32], [32, 33], [34, 37], [38, 45], [45, 46], [47, 50], [51, 56], [57, 59], [60, 62], [63, 68], [69, 71], [72, 73], [74, 80], [80, 82], [83, 87], [88, 91], [92, 95], [96, 102], [103, 108], [109, 111], [112, 115], [116, 120], [121, 123], [124, 128], [129, 135], [135, 136]]}
{"doc_key": "ai-dev-192", "ner": [[0, 1, "organisation"], [3, 4, "product"], [8, 10, "product"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 3, 4, "artifact", "", false, false], [3, 4, 8, 10, "part-of", "", false, false], [8, 10, 3, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc.", "introduced", "Face", "ID", "on", "the", "flagship", "i", "Phone", "X", "as", "the", "successor", "to", "Touch", "ID", "'s", "biometric", "authentication", ",", "a", "fingerprint", "-", "based", "system", "."], "sentence-detokenized": "Apple Inc. introduced Face ID on the flagship iPhone X as the successor to Touch ID's biometric authentication, a fingerprint-based system.", "token2charspan": [[0, 5], [6, 10], [11, 21], [22, 26], [27, 29], [30, 32], [33, 36], [37, 45], [46, 47], [47, 52], [53, 54], [55, 57], [58, 61], [62, 71], [72, 74], [75, 80], [81, 83], [83, 85], [86, 95], [96, 110], [110, 111], [112, 113], [114, 125], [125, 126], [126, 131], [132, 138], [138, 139]]}
{"doc_key": "ai-dev-193", "ner": [[3, 5, "metrics"], [8, 9, "metrics"], [22, 25, "metrics"], [28, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Or", "combine", "the", "F", "-", "measure", "with", "the", "R-", "square", "evaluated", "for", "the", "raw", "model", "output", "and", "the", "target", ";", "or", "the", "cost", "/", "gain", "matrix", "with", "the", "correlation", "coefficient", ",", "and", "so", "on", "."], "sentence-detokenized": "Or combine the F-measure with the R-square evaluated for the raw model output and the target; or the cost/gain matrix with the correlation coefficient, and so on.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 16], [16, 17], [17, 24], [25, 29], [30, 33], [34, 36], [36, 42], [43, 52], [53, 56], [57, 60], [61, 64], [65, 70], [71, 77], [78, 81], [82, 85], [86, 92], [92, 93], [94, 96], [97, 100], [101, 105], [105, 106], [106, 110], [111, 117], [118, 122], [123, 126], [127, 138], [139, 150], [150, 151], [152, 155], [156, 158], [159, 161], [161, 162]]}
{"doc_key": "ai-dev-194", "ner": [[1, 5, "conference"], [11, 13, "location"], [16, 16, "location"], [20, 24, "location"], [26, 26, "location"], [28, 28, "country"], [39, 41, "location"], [44, 48, "location"], [50, 50, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[1, 5, 11, 13, "physical", "", false, false], [1, 5, 20, 24, "physical", "", false, false], [1, 5, 39, 41, "physical", "", false, false], [1, 5, 44, 48, "physical", "", false, false], [11, 13, 16, 16, "physical", "", false, false], [20, 24, 26, 26, "physical", "", false, false], [26, 26, 28, 28, "physical", "", false, false], [39, 41, 50, 50, "physical", "", false, false], [44, 48, 50, 50, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "Spanish", "edition", "of", "Campus", "Party", "has", "been", "held", "at", "the", "Colegio", "Miguel", "Hern\u00e1ndez", ",", "in", "Ceulaj", ",", "and", "the", "Municipal", "Sport", "Arena", "of", "Benalm\u00e1dena", "in", "Malaga", ",", "Spain", ",", "and", "for", "the", "past", "15", "years", "at", "both", "the", "Valencia", "County", "Fair", "and", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "The Spanish edition of Campus Party has been held at the Colegio Miguel Hern\u00e1ndez, in Ceulaj, and the Municipal Sport Arena of Benalm\u00e1dena in Malaga, Spain, and for the past 15 years at both the Valencia County Fair and the City of Arts and Sciences in Valencia.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 22], [23, 29], [30, 35], [36, 39], [40, 44], [45, 49], [50, 52], [53, 56], [57, 64], [65, 71], [72, 81], [81, 82], [83, 85], [86, 92], [92, 93], [94, 97], [98, 101], [102, 111], [112, 117], [118, 123], [124, 126], [127, 138], [139, 141], [142, 148], [148, 149], [150, 155], [155, 156], [157, 160], [161, 164], [165, 168], [169, 173], [174, 176], [177, 182], [183, 185], [186, 190], [191, 194], [195, 203], [204, 210], [211, 215], [216, 219], [220, 223], [224, 228], [229, 231], [232, 236], [237, 240], [241, 249], [250, 252], [253, 261], [261, 262]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [14, 14, "programlang"], [18, 18, "product"], [20, 20, "product"], [24, 24, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 14, 0, 0, "general-affiliation", "", false, false], [18, 18, 14, 14, "part-of", "", false, false], [20, 20, 14, 14, "part-of", "", false, false], [24, 24, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["gnuplot", "can", "be", "used", "by", "several", "programming", "languages", "to", "create", "data", "graphs", ",", "including", "Perl", "(", "via", "the", "PDL", "and", "CPAN", "packages", ")", ",", "Python", "(", "via", ")", "."], "sentence-detokenized": "gnuplot can be used by several programming languages to create data graphs, including Perl (via the PDL and CPAN packages), Python (via).", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 19], [20, 22], [23, 30], [31, 42], [43, 52], [53, 55], [56, 62], [63, 67], [68, 74], [74, 75], [76, 85], [86, 90], [91, 92], [92, 95], [96, 99], [100, 103], [104, 107], [108, 112], [113, 121], [121, 122], [122, 123], [124, 130], [131, 132], [132, 135], [135, 136], [136, 137]]}
{"doc_key": "ai-dev-196", "ner": [[3, 6, "product"], [19, 19, "conference"], [21, 21, "conference"], [35, 35, "conference"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 3, 6, "topic", "", false, false], [21, 21, 3, 6, "topic", "", false, false], [35, 35, 3, 6, "topic", "", false, false], [37, 37, 3, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "field", "of", "speech", "dialogue", "systems", "is", "quite", "broad", "and", "encompasses", "research", "(", "presented", "at", "scientific", "conferences", "such", "as", "SIGdial", "and", "Interspeech", ")", "and", "a", "large", "industrial", "sector", "(", "with", "its", "own", "meetings", "such", "as", "SpeechTek", "and", "AVIOS", ")", "."], "sentence-detokenized": "The field of speech dialogue systems is quite broad and encompasses research (presented at scientific conferences such as SIGdial and Interspeech) and a large industrial sector (with its own meetings such as SpeechTek and AVIOS).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 28], [29, 36], [37, 39], [40, 45], [46, 51], [52, 55], [56, 67], [68, 76], [77, 78], [78, 87], [88, 90], [91, 101], [102, 113], [114, 118], [119, 121], [122, 129], [130, 133], [134, 145], [145, 146], [147, 150], [151, 152], [153, 158], [159, 169], [170, 176], [177, 178], [178, 182], [183, 186], [187, 190], [191, 199], [200, 204], [205, 207], [208, 217], [218, 221], [222, 227], [227, 228], [228, 229]]}
{"doc_key": "ai-dev-197", "ner": [[3, 5, "field"], [8, 9, "task"], [11, 13, "task"], [15, 17, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 3, 5, "part-of", "task_part_of_field", false, false], [11, 13, 3, 5, "part-of", "task_part_of_field", false, false], [15, 17, 3, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "challenges", "in", "natural", "language", "processing", "often", "concern", "speech", "recognition", ",", "natural", "language", "understanding", "and", "natural", "language", "generation", "."], "sentence-detokenized": "The challenges in natural language processing often concern speech recognition, natural language understanding and natural language generation.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 25], [26, 34], [35, 45], [46, 51], [52, 59], [60, 66], [67, 78], [78, 79], [80, 87], [88, 96], [97, 110], [111, 114], [115, 122], [123, 131], [132, 142], [142, 143]]}
{"doc_key": "ai-dev-198", "ner": [[4, 4, "product"], [7, 9, "product"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 7, 9, "part-of", "", false, false], [4, 4, 35, 36, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "like", "Siri", "of", "the", "iOS", "operating", "system", ",", "work", "with", "a", "pattern", "recognition", "technique", "similar", "to", "that", "of", "text", "-", "based", "systems", ",", "but", "in", "the", "former", "case", "user", "input", "is", "through", "voice", "recognition", "."], "sentence-detokenized": "These systems, like Siri of the iOS operating system, work with a pattern recognition technique similar to that of text-based systems, but in the former case user input is through voice recognition.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 24], [25, 27], [28, 31], [32, 35], [36, 45], [46, 52], [52, 53], [54, 58], [59, 63], [64, 65], [66, 73], [74, 85], [86, 95], [96, 103], [104, 106], [107, 111], [112, 114], [115, 119], [119, 120], [120, 125], [126, 133], [133, 134], [135, 138], [139, 141], [142, 145], [146, 152], [153, 157], [158, 162], [163, 168], [169, 171], [172, 179], [180, 185], [186, 197], [197, 198]]}
{"doc_key": "ai-dev-199", "ner": [[1, 3, "algorithm"], [16, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 3, 16, 17, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["More", "exotic", "fitness", "functions", "that", "explore", "the", "granularity", "of", "the", "model", "include", "the", "area", "under", "the", "ROC", "curve", "and", "the", "rank", "measure", "."], "sentence-detokenized": "More exotic fitness functions that explore the granularity of the model include the area under the ROC curve and the rank measure.", "token2charspan": [[0, 4], [5, 11], [12, 19], [20, 29], [30, 34], [35, 42], [43, 46], [47, 58], [59, 61], [62, 65], [66, 71], [72, 79], [80, 83], [84, 88], [89, 94], [95, 98], [99, 102], [103, 108], [109, 112], [113, 116], [117, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-dev-200", "ner": [[3, 3, "product"], [7, 10, "researcher"], [15, 17, "product"], [22, 25, "organisation"], [27, 27, "organisation"], [37, 41, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 7, 10, "origin", "", false, false], [7, 10, 22, 25, "role", "", false, false], [15, 17, 7, 10, "origin", "", false, false], [27, 27, 22, 25, "named", "", false, false], [37, 41, 22, 25, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "term", "Semantic", "Web", "was", "coined", "by", "Tim", "Berners", "-", "Lee", ",", "inventor", "of", "the", "World", "Wide", "Web", "and", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "oversees", "the", "development", "of", "the", "proposed", "standards", "for", "the", "Semantic", "Web", "."], "sentence-detokenized": "The term Semantic Web was coined by Tim Berners-Lee, inventor of the World Wide Web and director of the World Wide Web Consortium (W3C), which oversees the development of the proposed standards for the Semantic Web.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 25], [26, 32], [33, 35], [36, 39], [40, 47], [47, 48], [48, 51], [51, 52], [53, 61], [62, 64], [65, 68], [69, 74], [75, 79], [80, 83], [84, 87], [88, 96], [97, 99], [100, 103], [104, 109], [110, 114], [115, 118], [119, 129], [130, 131], [131, 134], [134, 135], [135, 136], [137, 142], [143, 151], [152, 155], [156, 167], [168, 170], [171, 174], [175, 183], [184, 193], [194, 197], [198, 201], [202, 210], [211, 214], [214, 215]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [9, 9, "task"], [16, 19, "product"], [21, 25, "product"], [27, 27, "product"], [30, 31, "product"], [38, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 16, 19, "opposite", "", false, false], [0, 1, 21, 25, "opposite", "", false, false], [0, 1, 30, 31, "opposite", "", false, false], [0, 1, 38, 39, "part-of", "", false, false], [9, 9, 0, 1, "named", "", false, false], [27, 27, 21, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Machine", "translation", ",", "sometimes", "referred", "to", "by", "the", "abbreviation", "MT", "(", "not", "to", "be", "confused", "with", "computer", "-", "aided", "translation", ",", "machine", "-", "aided", "human", "translation", "(", "MAHT", ")", "or", "interactive", "translation", ")", ",", "is", "a", "subfield", "of", "computational", "linguistics", "that", "studies", "the", "use", "of", "software", "to", "translate", "text", "or", "speech", "from", "one", "language", "into", "another", "."], "sentence-detokenized": "Machine translation, sometimes referred to by the abbreviation MT (not to be confused with computer-aided translation, machine-aided human translation (MAHT) or interactive translation), is a subfield of computational linguistics that studies the use of software to translate text or speech from one language into another.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 30], [31, 39], [40, 42], [43, 45], [46, 49], [50, 62], [63, 65], [66, 67], [67, 70], [71, 73], [74, 76], [77, 85], [86, 90], [91, 99], [99, 100], [100, 105], [106, 117], [117, 118], [119, 126], [126, 127], [127, 132], [133, 138], [139, 150], [151, 152], [152, 156], [156, 157], [158, 160], [161, 172], [173, 184], [184, 185], [185, 186], [187, 189], [190, 191], [192, 200], [201, 203], [204, 217], [218, 229], [230, 234], [235, 242], [243, 246], [247, 250], [251, 253], [254, 262], [263, 265], [266, 275], [276, 280], [281, 283], [284, 290], [291, 295], [296, 299], [300, 308], [309, 313], [314, 321], [321, 322]]}
{"doc_key": "ai-dev-202", "ner": [[3, 6, "product"], [10, 10, "university"], [15, 16, "researcher"], [18, 19, "researcher"], [43, 44, "location"], [46, 46, "location"], [50, 53, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 6, 15, 16, "artifact", "", false, false], [3, 6, 18, 19, "artifact", "", false, false], [15, 16, 10, 10, "physical", "", false, false], [15, 16, 10, 10, "role", "", false, false], [18, 19, 10, 10, "physical", "", false, false], [18, 19, 10, 10, "role", "", false, false], [43, 44, 46, 46, "physical", "", false, false], [50, 53, 43, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "first", "interlingual", "machine", "translation", "systems", "were", "also", "realised", "at", "Stanford", "in", "the", "1970s", "by", "Roger", "Schank", "and", "Yorick", "Wilks", ";", "the", "former", "became", "the", "basis", "of", "a", "commercial", "fund", "transfer", "system", ",", "while", "the", "code", "of", "the", "latter", "is", "preserved", "at", "the", "Computer", "Museum", "in", "Boston", "as", "the", "first", "interlingual", "machine", "translation", "system", "."], "sentence-detokenized": "The first interlingual machine translation systems were also realised at Stanford in the 1970s by Roger Schank and Yorick Wilks; the former became the basis of a commercial fund transfer system, while the code of the latter is preserved at the Computer Museum in Boston as the first interlingual machine translation system.", "token2charspan": [[0, 3], [4, 9], [10, 22], [23, 30], [31, 42], [43, 50], [51, 55], [56, 60], [61, 69], [70, 72], [73, 81], [82, 84], [85, 88], [89, 94], [95, 97], [98, 103], [104, 110], [111, 114], [115, 121], [122, 127], [127, 128], [129, 132], [133, 139], [140, 146], [147, 150], [151, 156], [157, 159], [160, 161], [162, 172], [173, 177], [178, 186], [187, 193], [193, 194], [195, 200], [201, 204], [205, 209], [210, 212], [213, 216], [217, 223], [224, 226], [227, 236], [237, 239], [240, 243], [244, 252], [253, 259], [260, 262], [263, 269], [270, 272], [273, 276], [277, 282], [283, 295], [296, 303], [304, 315], [316, 322], [322, 323]]}
{"doc_key": "ai-dev-203", "ner": [[0, 0, "researcher"], [6, 12, "conference"], [14, 15, "conference"], [22, 27, "conference"], [30, 30, "conference"], [36, 41, "organisation"], [49, 50, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 6, 12, "role", "", false, false], [0, 0, 22, 27, "role", "", false, false], [0, 0, 36, 41, "role", "", false, false], [0, 0, 49, 50, "role", "", false, false], [14, 15, 6, 12, "named", "", false, false], [30, 30, 22, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sycara", "was", "programme", "chair", "of", "the", "Second", "International", "Conference", "on", "the", "Semantic", "Web", "(", "ISWC", "2003", ")", ";", "general", "chair", "of", "the", "Second", "International", "Conference", "on", "Autonomous", "Agents", "(", "Agents", "98", ")", ";", "chair", "of", "the", "Steering", "Committee", "of", "the", "Agents", "Conference", "(", "1999-2001", ")", ";", "chair", "of", "the", "AAAI", "fellowship", "(", "1993-1999", ")", ";"], "sentence-detokenized": "Sycara was programme chair of the Second International Conference on the Semantic Web (ISWC 2003); general chair of the Second International Conference on Autonomous Agents (Agents 98); chair of the Steering Committee of the Agents Conference (1999-2001); chair of the AAAI fellowship (1993-1999);", "token2charspan": [[0, 6], [7, 10], [11, 20], [21, 26], [27, 29], [30, 33], [34, 40], [41, 54], [55, 65], [66, 68], [69, 72], [73, 81], [82, 85], [86, 87], [87, 91], [92, 96], [96, 97], [97, 98], [99, 106], [107, 112], [113, 115], [116, 119], [120, 126], [127, 140], [141, 151], [152, 154], [155, 165], [166, 172], [173, 174], [174, 180], [181, 183], [183, 184], [184, 185], [186, 191], [192, 194], [195, 198], [199, 207], [208, 217], [218, 220], [221, 224], [225, 231], [232, 242], [243, 244], [244, 253], [253, 254], [254, 255], [256, 261], [262, 264], [265, 268], [269, 273], [274, 284], [285, 286], [286, 295], [295, 296], [296, 297]]}
{"doc_key": "ai-dev-204", "ner": [[11, 11, "conference"], [13, 16, "conference"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 11, 11, "named", "", false, false], [18, 20, 11, 11, "part-of", "", false, false], [18, 20, 11, 11, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2016", ",", "she", "was", "selected", "as", "the", "winner", "of", "the", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "Lifetime", "Achievement", "Award", "."], "sentence-detokenized": "In 2016, she was selected as the winner of the ACL (Association for Computational Linguistics) Lifetime Achievement Award.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 25], [26, 28], [29, 32], [33, 39], [40, 42], [43, 46], [47, 50], [51, 52], [52, 63], [64, 67], [68, 81], [82, 93], [93, 94], [95, 103], [104, 115], [116, 121], [121, 122]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P.", "Frasconi", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 30], [31, 39], [40, 43], [44, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-206", "ner": [[3, 3, "product"], [6, 7, "misc"], [9, 9, "programlang"], [17, 18, "product"], [33, 33, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 9, 9, "usage", "", false, false], [9, 9, 6, 7, "type-of", "", false, false], [9, 9, 17, 18, "related-to", "", false, false], [33, 33, 3, 3, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["For", "example", ",", "A.L.I.C.E.", "uses", "a", "markup", "language", "called", "AIML", ",", "specifically", "for", "its", "function", "as", "a", "dialogue", "system", ",", "which", "has", "since", "been", "adopted", "by", "various", "other", "developers", "of", "so", "-", "called", "Alicebots", "."], "sentence-detokenized": "For example, A.L.I.C.E. uses a markup language called AIML, specifically for its function as a dialogue system, which has since been adopted by various other developers of so-called Alicebots.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 23], [24, 28], [29, 30], [31, 37], [38, 46], [47, 53], [54, 58], [58, 59], [60, 72], [73, 76], [77, 80], [81, 89], [90, 92], [93, 94], [95, 103], [104, 110], [110, 111], [112, 117], [118, 121], [122, 127], [128, 132], [133, 140], [141, 143], [144, 151], [152, 157], [158, 168], [169, 171], [172, 174], [174, 175], [175, 181], [182, 191], [191, 192]]}
{"doc_key": "ai-dev-207", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2000", ",", "she", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2000, she was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 24], [25, 26], [27, 33], [34, 36], [37, 40], [41, 52], [53, 56], [57, 60], [61, 72], [73, 75], [76, 86], [87, 99], [99, 100]]}
{"doc_key": "ai-dev-208", "ner": [[0, 2, "misc"], [4, 4, "misc"], [10, 15, "misc"], [24, 25, "algorithm"], [33, 34, "field"], [36, 37, "field"], [39, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 10, 15, "type-of", "", false, false], [0, 2, 33, 34, "related-to", "performs", true, false], [0, 2, 36, 37, "related-to", "performs", true, false], [0, 2, 39, 40, "related-to", "performs", true, false], [4, 4, 0, 2, "named", "", false, false], [24, 25, 10, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Classifier", "learning", "systems", "(", "LCS", ")", "are", "a", "family", "of", "rule", "-", "based", "machine", "learning", "algorithms", "that", "combine", "a", "discovery", "component", ",", "usually", "a", "genetic", "algorithm", ",", "with", "a", "learning", "component", ",", "performing", "supervised", "learning", ",", "reinforcement", "learning", "or", "unsupervised", "learning", "."], "sentence-detokenized": "Classifier learning systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, usually a genetic algorithm, with a learning component, performing supervised learning, reinforcement learning or unsupervised learning.", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 29], [29, 32], [32, 33], [34, 37], [38, 39], [40, 46], [47, 49], [50, 54], [54, 55], [55, 60], [61, 68], [69, 77], [78, 88], [89, 93], [94, 101], [102, 103], [104, 113], [114, 123], [123, 124], [125, 132], [133, 134], [135, 142], [143, 152], [152, 153], [154, 158], [159, 160], [161, 169], [170, 179], [179, 180], [181, 191], [192, 202], [203, 211], [211, 212], [213, 226], [227, 235], [236, 238], [239, 251], [252, 260], [260, 261]]}
{"doc_key": "ai-dev-209", "ner": [[14, 16, "algorithm"], [19, 19, "algorithm"], [27, 28, "algorithm"], [32, 34, "misc"], [43, 45, "algorithm"], [53, 56, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 16, 27, 28, "origin", "", false, false], [14, 16, 32, 34, "usage", "", false, false], [19, 19, 14, 16, "named", "", false, false], [43, 45, 32, 34, "type-of", "", false, false], [43, 45, 53, 56, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "unknown", "parameters", "in", "each", "\u03b2subk", "/", "sub", "vector", "are", "typically", "jointly", "estimated", "by", "maximum", "a", "posteriori", "estimation", "(", "MAP", ")", ",", "which", "is", "an", "extension", "of", "maximum", "likelihood", "that", "uses", "a", "regularisation", "of", "the", "weights", "to", "avoid", "pathological", "solutions", "(", "usually", "a", "squared", "regularisation", "function", ",", "which", "is", "equivalent", "to", "placing", "a", "zero", "mean", "Gaussian", "distribution", "on", "the", "weights", ",", "but", "other", "distributions", "are", "also", "possible", ")", "."], "sentence-detokenized": "The unknown parameters in each \u03b2subk/sub vector are typically jointly estimated by maximum a posteriori estimation (MAP), which is an extension of maximum likelihood that uses a regularisation of the weights to avoid pathological solutions (usually a squared regularisation function, which is equivalent to placing a zero mean Gaussian distribution on the weights, but other distributions are also possible).", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 30], [31, 36], [36, 37], [37, 40], [41, 47], [48, 51], [52, 61], [62, 69], [70, 79], [80, 82], [83, 90], [91, 92], [93, 103], [104, 114], [115, 116], [116, 119], [119, 120], [120, 121], [122, 127], [128, 130], [131, 133], [134, 143], [144, 146], [147, 154], [155, 165], [166, 170], [171, 175], [176, 177], [178, 192], [193, 195], [196, 199], [200, 207], [208, 210], [211, 216], [217, 229], [230, 239], [240, 241], [241, 248], [249, 250], [251, 258], [259, 273], [274, 282], [282, 283], [284, 289], [290, 292], [293, 303], [304, 306], [307, 314], [315, 316], [317, 321], [322, 326], [327, 335], [336, 348], [349, 351], [352, 355], [356, 363], [363, 364], [365, 368], [369, 374], [375, 388], [389, 392], [393, 397], [398, 406], [406, 407], [407, 408]]}
{"doc_key": "ai-dev-210", "ner": [[9, 10, "researcher"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 9, 10, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "hierarchical", "structure", "of", "words", "was", "explicitly", "mapped", "in", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "The hierarchical structure of words was explicitly mapped in George Miller's Wordnet.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 29], [30, 35], [36, 39], [40, 50], [51, 57], [58, 60], [61, 67], [68, 74], [74, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-dev-211", "ner": [[9, 18, "conference"], [21, 24, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 24, 9, 18, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "illustration", "of", "their", "capabilities", "is", "provided", "by", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", ";", "this", "is", "a", "benchmark", "in", "object", "classification", "and", "detection", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "An illustration of their capabilities is provided by the ImageNet Large Scale Visual Recognition Challenge; this is a benchmark in object classification and detection, with millions of images and hundreds of object classes.", "token2charspan": [[0, 2], [3, 15], [16, 18], [19, 24], [25, 37], [38, 40], [41, 49], [50, 52], [53, 56], [57, 65], [66, 71], [72, 77], [78, 84], [85, 96], [97, 106], [106, 107], [108, 112], [113, 115], [116, 117], [118, 127], [128, 130], [131, 137], [138, 152], [153, 156], [157, 166], [166, 167], [168, 172], [173, 181], [182, 184], [185, 191], [192, 195], [196, 204], [205, 207], [208, 214], [215, 222], [222, 223]]}
{"doc_key": "ai-dev-212", "ner": [[1, 2, "misc"], [25, 25, "misc"], [35, 37, "person"], [30, 30, "misc"], [50, 52, "person"], [43, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[25, 25, 1, 2, "general-affiliation", "", false, false], [30, 30, 1, 2, "general-affiliation", "", false, false], [30, 30, 35, 37, "artifact", "", false, false], [43, 45, 1, 2, "general-affiliation", "", false, false], [43, 45, 50, 52, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "science", "fiction", ",", "female", "-", "looking", "robots", "are", "often", "produced", "to", "be", "used", "as", "servants", "and", "sex", "slaves", ",", "as", "seen", "in", "the", "film", "Westworld", ",", "in", "the", "novel", "Fairyland", "(", "1995", ")", "by", "Paul", "J.", "McAuley", "and", "in", "the", "short", "story", "Helen", "O'", "Loy", "(", "1938", ")", "by", "Lester", "del", "Rey", ",", "and", "sometimes", "as", "warriors", ",", "assassins", "or", "workers", "."], "sentence-detokenized": "In science fiction, female-looking robots are often produced to be used as servants and sex slaves, as seen in the film Westworld, in the novel Fairyland (1995) by Paul J. McAuley and in the short story Helen O'Loy (1938) by Lester del Rey, and sometimes as warriors, assassins or workers.", "token2charspan": [[0, 2], [3, 10], [11, 18], [18, 19], [20, 26], [26, 27], [27, 34], [35, 41], [42, 45], [46, 51], [52, 60], [61, 63], [64, 66], [67, 71], [72, 74], [75, 83], [84, 87], [88, 91], [92, 98], [98, 99], [100, 102], [103, 107], [108, 110], [111, 114], [115, 119], [120, 129], [129, 130], [131, 133], [134, 137], [138, 143], [144, 153], [154, 155], [155, 159], [159, 160], [161, 163], [164, 168], [169, 171], [172, 179], [180, 183], [184, 186], [187, 190], [191, 196], [197, 202], [203, 208], [209, 211], [211, 214], [215, 216], [216, 220], [220, 221], [222, 224], [225, 231], [232, 235], [236, 239], [239, 240], [241, 244], [245, 254], [255, 257], [258, 266], [266, 267], [268, 277], [278, 280], [281, 288], [288, 289]]}
{"doc_key": "ai-dev-213", "ner": [[0, 1, "task"], [3, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["question", "answering", ",", "voice", "recognition", "and", "automatic", "translation", "."], "sentence-detokenized": "question answering, voice recognition and automatic translation.", "token2charspan": [[0, 8], [9, 18], [18, 19], [20, 25], [26, 37], [38, 41], [42, 51], [52, 63], [63, 64]]}
{"doc_key": "ai-dev-214", "ner": [[5, 6, "researcher"], [10, 13, "organisation"], [9, 18, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 10, 13, "role", "", false, false], [10, 13, 9, 18, "physical", "", false, false], [9, 18, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "seminal", "work", ",", "Harry", "Blum", "of", "the", "Air", "Force", "Cambridge", "Research", "Laboratories", "at", "Hanscom", "Air", "Force", "Base", ",", "Bedford", ",", "Massachusetts", ",", "defined", "a", "median", "axis", "for", "calculating", "the", "skeleton", "of", "a", "shape", ",", "using", "an", "intuitive", "model", "of", "fire", "propagation", "over", "a", "field", "of", "grass", ",", "where", "the", "field", "has", "the", "shape", "of", "the", "given", "shape", "."], "sentence-detokenized": "In his seminal work, Harry Blum of the Air Force Cambridge Research Laboratories at Hanscom Air Force Base, Bedford, Massachusetts, defined a median axis for calculating the skeleton of a shape, using an intuitive model of fire propagation over a field of grass, where the field has the shape of the given shape.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 19], [19, 20], [21, 26], [27, 31], [32, 34], [35, 38], [39, 42], [43, 48], [49, 58], [59, 67], [68, 80], [81, 83], [84, 91], [92, 95], [96, 101], [102, 106], [106, 107], [108, 115], [115, 116], [117, 130], [130, 131], [132, 139], [140, 141], [142, 148], [149, 153], [154, 157], [158, 169], [170, 173], [174, 182], [183, 185], [186, 187], [188, 193], [193, 194], [195, 200], [201, 203], [204, 213], [214, 219], [220, 222], [223, 227], [228, 239], [240, 244], [245, 246], [247, 252], [253, 255], [256, 261], [261, 262], [263, 268], [269, 272], [273, 278], [279, 282], [283, 286], [287, 292], [293, 295], [296, 299], [300, 305], [306, 311], [311, 312]]}
{"doc_key": "ai-dev-215", "ner": [[14, 14, "algorithm"], [16, 16, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 19, 20, "compare", "", false, false], [16, 16, 19, 20, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "unlike", "boosting", "algorithms", "that", "minimise", "a", "convex", "loss", "function", "analytically", "(", "e.g.", "AdaBoost", "and", "LogitBoost", ")", ",", "Brown", "Boost", "solves", "a", "system", "of", "two", "equations", "and", "two", "unknowns", "using", "standard", "numerical", "methods", "."], "sentence-detokenized": "However, unlike boosting algorithms that minimise a convex loss function analytically (e.g. AdaBoost and LogitBoost), BrownBoost solves a system of two equations and two unknowns using standard numerical methods.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 24], [25, 35], [36, 40], [41, 49], [50, 51], [52, 58], [59, 63], [64, 72], [73, 85], [86, 87], [87, 91], [92, 100], [101, 104], [105, 115], [115, 116], [116, 117], [118, 123], [123, 128], [129, 135], [136, 137], [138, 144], [145, 147], [148, 151], [152, 161], [162, 165], [166, 169], [170, 178], [179, 184], [185, 193], [194, 203], [204, 211], [211, 212]]}
{"doc_key": "ai-dev-216", "ner": [[0, 0, "researcher"], [9, 11, "misc"], [15, 20, "conference"], [22, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 9, 11, "win-defeat", "", false, false], [0, 0, 15, 20, "role", "", false, false], [22, 22, 15, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getoor", "has", "received", "several", "best", "work", "awards", ",", "an", "NSF", "Career", "Award", "and", "is", "an", "Association", "for", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "Fellow", "."], "sentence-detokenized": "Getoor has received several best work awards, an NSF Career Award and is an Association for Advancement of Artificial Intelligence (AAAI) Fellow.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 27], [28, 32], [33, 37], [38, 44], [44, 45], [46, 48], [49, 52], [53, 59], [60, 65], [66, 69], [70, 72], [73, 75], [76, 87], [88, 91], [92, 103], [104, 106], [107, 117], [118, 130], [131, 132], [132, 136], [136, 137], [138, 144], [144, 145]]}
{"doc_key": "ai-dev-217", "ner": [[0, 1, "misc"], [6, 10, "misc"], [15, 16, "misc"], [21, 25, "misc"], [30, 31, "misc"], [35, 39, "university"], [44, 52, "misc"], [57, 65, "misc"], [70, 74, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACM", "Fellow", "(", "2015", ")", "br", "Association", "for", "Computational", "Linguistics", "Fellow", "(", "2011", ")", "br", "AAAI", "Fellow", "(", "1994", ")", "br", "International", "Speech", "Communication", "Association", "Fellow", "(", "2011", ")", "br", "Honorary", "Doctorate", "(", "Hedersdoktor", ")", "KTH", "Royal", "Institute", "of", "Technology", "(", "2007", ")", "br", "Columbia", "Engineering", "School", "Alumni", "Association", "Distinguished", "Faculty", "Teaching", "award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Speech", "and", "Audio", "Processing", "Award", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")"], "sentence-detokenized": "ACM Fellow (2015) br Association for Computational Linguistics Fellow (2011) br AAAI Fellow (1994) br International Speech Communication Association Fellow (2011) br Honorary Doctorate (Hedersdoktor) KTH Royal Institute of Technology (2007) br Columbia Engineering School Alumni Association Distinguished Faculty Teaching award (2009) br IEEE James L. Flanagan Speech and Audio Processing Award (2011) br ISCA Medal for Scientific Achievement (2011)", "token2charspan": [[0, 3], [4, 10], [11, 12], [12, 16], [16, 17], [18, 20], [21, 32], [33, 36], [37, 50], [51, 62], [63, 69], [70, 71], [71, 75], [75, 76], [77, 79], [80, 84], [85, 91], [92, 93], [93, 97], [97, 98], [99, 101], [102, 115], [116, 122], [123, 136], [137, 148], [149, 155], [156, 157], [157, 161], [161, 162], [163, 165], [166, 174], [175, 184], [185, 186], [186, 198], [198, 199], [200, 203], [204, 209], [210, 219], [220, 222], [223, 233], [234, 235], [235, 239], [239, 240], [241, 243], [244, 252], [253, 264], [265, 271], [272, 278], [279, 290], [291, 304], [305, 312], [313, 321], [322, 327], [328, 329], [329, 333], [333, 334], [335, 337], [338, 342], [343, 348], [349, 351], [352, 360], [361, 367], [368, 371], [372, 377], [378, 388], [389, 394], [395, 396], [396, 400], [400, 401], [402, 404], [405, 409], [410, 415], [416, 419], [420, 430], [431, 442], [443, 444], [444, 448], [448, 449]]}
{"doc_key": "ai-dev-218", "ner": [[5, 5, "university"], [15, 18, "task"], [36, 37, "metrics"], [28, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[36, 37, 28, 32, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["A", "frustrating", "result", "of", "the", "Stanford", "study", "itself", "(", "and", "other", "attempts", "to", "improve", "the", "translation", "of", "name", "recognition", ")", "is", "that", "the", "inclusion", "of", "methods", "for", "translating", "named", "entities", "often", "results", "in", "a", "decrease", "in", "bilingual", "assessment", "scores", "."], "sentence-detokenized": "A frustrating result of the Stanford study itself (and other attempts to improve the translation of name recognition) is that the inclusion of methods for translating named entities often results in a decrease in bilingual assessment scores.", "token2charspan": [[0, 1], [2, 13], [14, 20], [21, 23], [24, 27], [28, 36], [37, 42], [43, 49], [50, 51], [51, 54], [55, 60], [61, 69], [70, 72], [73, 80], [81, 84], [85, 96], [97, 99], [100, 104], [105, 116], [116, 117], [118, 120], [121, 125], [126, 129], [130, 139], [140, 142], [143, 150], [151, 154], [155, 166], [167, 172], [173, 181], [182, 187], [188, 195], [196, 198], [199, 200], [201, 209], [210, 212], [213, 222], [223, 233], [234, 240], [240, 241]]}
{"doc_key": "ai-dev-219", "ner": [[0, 0, "organisation"], [11, 13, "organisation"], [15, 19, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "role", "works_with", false, false], [0, 0, 15, 19, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "uses", "the", "collected", "PM", "data", "and", "collaborates", "with", "researchers", "at", "Johns", "Hopkins", "Hospital", "and", "Washington", "University", "School", "of", "Medicine", "to", "help", "answer", "specific", "questions", "about", "heart", "disease", ",", "such", "as", "whether", "weak", "hearts", "cause", "arrhythmias", "or", "vice", "versa", "."], "sentence-detokenized": "Medtronic uses the collected PM data and collaborates with researchers at Johns Hopkins Hospital and Washington University School of Medicine to help answer specific questions about heart disease, such as whether weak hearts cause arrhythmias or vice versa.", "token2charspan": [[0, 9], [10, 14], [15, 18], [19, 28], [29, 31], [32, 36], [37, 40], [41, 53], [54, 58], [59, 70], [71, 73], [74, 79], [80, 87], [88, 96], [97, 100], [101, 111], [112, 122], [123, 129], [130, 132], [133, 141], [142, 144], [145, 149], [150, 156], [157, 165], [166, 175], [176, 181], [182, 187], [188, 195], [195, 196], [197, 201], [202, 204], [205, 212], [213, 217], [218, 224], [225, 230], [231, 242], [243, 245], [246, 250], [251, 256], [256, 257]]}
{"doc_key": "ai-dev-220", "ner": [[4, 4, "organisation"], [9, 9, "misc"], [11, 12, "person"], [14, 15, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 4, 4, "artifact", "made_by_studio", false, false], [11, 12, 9, 9, "role", "", false, false], [14, 15, 9, 9, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "was", "followed", "by", "Paramount", "'s", "first", "film", ",", "Sangaree", "starring", "Fernando", "Lamas", "and", "Arlene", "Dahl", "."], "sentence-detokenized": "This was followed by Paramount's first film, Sangaree starring Fernando Lamas and Arlene Dahl.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 30], [30, 32], [33, 38], [39, 43], [43, 44], [45, 53], [54, 62], [63, 71], [72, 77], [78, 81], [82, 88], [89, 93], [93, 94]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [9, 11, "researcher"], [13, 14, "researcher"], [16, 17, "organisation"], [19, 20, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 9, 11, "origin", "", false, false], [0, 0, 13, 14, "origin", "", false, false], [9, 11, 16, 17, "physical", "", false, false], [9, 11, 16, 17, "role", "", false, false], [13, 14, 19, 20, "physical", "", false, false], [13, 14, 19, 20, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "is", "a", "knowledge", "representation", "language", ",", "developed", "by", "Daniel", "G.", "Bobrow", "and", "Terry", "Winograd", "at", "Xerox", "PARC", "and", "Stanford", "University", ",", "respectively", "."], "sentence-detokenized": "KRL is a knowledge representation language, developed by Daniel G. Bobrow and Terry Winograd at Xerox PARC and Stanford University, respectively.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 18], [19, 33], [34, 42], [42, 43], [44, 53], [54, 56], [57, 63], [64, 66], [67, 73], [74, 77], [78, 83], [84, 92], [93, 95], [96, 101], [102, 106], [107, 110], [111, 119], [120, 130], [130, 131], [132, 144], [144, 145]]}
{"doc_key": "ai-dev-222", "ner": [[5, 12, "conference"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 26, "researcher"], [33, 34, "task"], [36, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 12, 33, 34, "topic", "", true, false], [14, 15, 5, 12, "physical", "", false, false], [14, 15, 5, 12, "role", "", false, false], [14, 15, 5, 12, "temporal", "", false, false], [17, 18, 5, 12, "physical", "", false, false], [17, 18, 5, 12, "role", "", false, false], [17, 18, 5, 12, "temporal", "", false, false], [20, 21, 5, 12, "physical", "", false, false], [20, 21, 5, 12, "role", "", false, false], [20, 21, 5, 12, "temporal", "", false, false], [23, 26, 5, 12, "physical", "", false, false], [23, 26, 5, 12, "role", "", false, false], [23, 26, 5, 12, "temporal", "", false, false], [33, 34, 36, 38, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "2006", ",", "at", "the", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", "and", "Kwang", "-", "Ting", "Cheng", "presented", "an", "algorithm", "to", "significantly", "accelerate", "human", "detection", "using", "HOG", "descriptor", "methods", "."], "sentence-detokenized": "In 2006, at the IEEE Conference on Computer Vision and Pattern Recognition, Qiang Zhu, Shai Avidan, Mei-Chen Yeh and Kwang-Ting Cheng presented an algorithm to significantly accelerate human detection using HOG descriptor methods.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 20], [21, 31], [32, 34], [35, 43], [44, 50], [51, 54], [55, 62], [63, 74], [74, 75], [76, 81], [82, 85], [85, 86], [87, 91], [92, 98], [98, 99], [100, 108], [109, 112], [113, 116], [117, 122], [122, 123], [123, 127], [128, 133], [134, 143], [144, 146], [147, 156], [157, 159], [160, 173], [174, 184], [185, 190], [191, 200], [201, 206], [207, 210], [211, 221], [222, 229], [229, 230]]}
{"doc_key": "ai-dev-223", "ner": [[0, 0, "researcher"], [6, 6, "conference"], [9, 11, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 6, "role", "", false, false], [0, 0, 9, 11, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "is", "a", "founding", "member", "of", "AAAI", "and", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Hayes is a founding member of AAAI and the Cognitive Science Society.", "token2charspan": [[0, 5], [6, 8], [9, 10], [11, 19], [20, 26], [27, 29], [30, 34], [35, 38], [39, 42], [43, 52], [53, 60], [61, 68], [68, 69]]}
{"doc_key": "ai-dev-224", "ner": [[0, 1, "misc"], [5, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 32, "field"], [42, 43, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 1, 5, 5, "part-of", "", false, false], [0, 1, 5, 5, "usage", "", false, false], [0, 1, 7, 8, "part-of", "", false, false], [0, 1, 7, 8, "usage", "", false, false], [0, 1, 10, 11, "part-of", "", false, false], [0, 1, 10, 11, "usage", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [0, 1, 13, 13, "usage", "", false, false], [0, 1, 15, 16, "part-of", "", false, false], [0, 1, 15, 16, "usage", "", false, false], [0, 1, 18, 19, "part-of", "", false, false], [0, 1, 18, 19, "usage", "", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 21, 22, "usage", "", false, false], [0, 1, 24, 24, "part-of", "", false, false], [0, 1, 24, 24, "usage", "", false, false], [0, 1, 26, 27, "part-of", "", false, false], [0, 1, 26, 27, "usage", "", false, false], [0, 1, 29, 29, "part-of", "", false, false], [0, 1, 29, 29, "usage", "", false, false], [0, 1, 31, 32, "part-of", "", false, false], [0, 1, 31, 32, "usage", "", false, false], [0, 1, 42, 43, "part-of", "", false, false], [0, 1, 42, 43, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "forecasting", ",", "electroencephalography", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", "and", ",", "in", "general", ",", "in", "all", "areas", "of", "applied", "science", "and", "engineering", "involving", "time", "measurements", "."], "sentence-detokenized": "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake forecasting, electroencephalography, control engineering, astronomy, communications engineering and, in general, in all areas of applied science and engineering involving time measurements.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 23], [24, 34], [34, 35], [36, 42], [43, 53], [53, 54], [55, 62], [63, 74], [74, 75], [76, 88], [88, 89], [90, 102], [103, 110], [110, 111], [112, 119], [120, 131], [131, 132], [133, 143], [144, 155], [155, 156], [157, 179], [179, 180], [181, 188], [189, 200], [200, 201], [202, 211], [211, 212], [213, 227], [228, 239], [240, 243], [243, 244], [245, 247], [248, 255], [255, 256], [257, 259], [260, 263], [264, 269], [270, 272], [273, 280], [281, 288], [289, 292], [293, 304], [305, 314], [315, 319], [320, 332], [332, 333]]}
{"doc_key": "ai-dev-225", "ner": [[13, 14, "metrics"], [37, 39, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "principle", ",", "exact", "recovery", "can", "be", "solved", "in", "its", "feasibility", "range", "using", "maximum", "likelihood", ",", "but", "this", "is", "equivalent", "to", "solving", "a", "constrained", "or", "regularised", "shear", "problem", ",", "such", "as", "minimum", "bisection", ",", "which", "is", "typically", "NP", "-", "complete", "."], "sentence-detokenized": "In principle, exact recovery can be solved in its feasibility range using maximum likelihood, but this is equivalent to solving a constrained or regularised shear problem, such as minimum bisection, which is typically NP-complete.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 19], [20, 28], [29, 32], [33, 35], [36, 42], [43, 45], [46, 49], [50, 61], [62, 67], [68, 73], [74, 81], [82, 92], [92, 93], [94, 97], [98, 102], [103, 105], [106, 116], [117, 119], [120, 127], [128, 129], [130, 141], [142, 144], [145, 156], [157, 162], [163, 170], [170, 171], [172, 176], [177, 179], [180, 187], [188, 197], [197, 198], [199, 204], [205, 207], [208, 217], [218, 220], [220, 221], [221, 229], [229, 230]]}
{"doc_key": "ai-dev-226", "ner": [[4, 5, "task"], [11, 11, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 11, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["in", "their", "work", "on", "pedestrian", "detection", ",", "first", "described", "at", "the", "BMVC", "in", "2009", "."], "sentence-detokenized": "in their work on pedestrian detection, first described at the BMVC in 2009.", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 16], [17, 27], [28, 37], [37, 38], [39, 44], [45, 54], [55, 57], [58, 61], [62, 66], [67, 69], [70, 74], [74, 75]]}
{"doc_key": "ai-dev-227", "ner": [[5, 8, "conference"], [10, 10, "researcher"], [13, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 5, 8, "physical", "", false, false], [10, 10, 5, 8, "role", "", false, false], [10, 10, 13, 20, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2007", ",", "at", "the", "International", "Computer", "Vision", "Conference", ",", "Terzopoulos", "received", "the", "inaugural", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "for", "pioneering", "and", "sustained", "research", "on", "deformable", "models", "and", "their", "applications", "."], "sentence-detokenized": "In 2007, at the International Computer Vision Conference, Terzopoulos received the inaugural IEEE PAMI Computer Vision Distinguished Researcher Award for pioneering and sustained research on deformable models and their applications.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 38], [39, 45], [46, 56], [56, 57], [58, 69], [70, 78], [79, 82], [83, 92], [93, 97], [98, 102], [103, 111], [112, 118], [119, 132], [133, 143], [144, 149], [150, 153], [154, 164], [165, 168], [169, 178], [179, 187], [188, 190], [191, 201], [202, 208], [209, 212], [213, 218], [219, 231], [231, 232]]}
{"doc_key": "ai-dev-228", "ner": [[0, 1, "task"], [3, 4, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 3, 4, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cluster", "analysis", "or", "cluster", "analysis", "consists", "of", "assigning", "data", "points", "to", "clusters", "in", "such", "a", "way", "that", "elements", "of", "the", "same", "cluster", "are", "as", "similar", "as", "possible", ",", "while", "elements", "belonging", "to", "different", "clusters", "are", "as", "dissimilar", "as", "possible", "."], "sentence-detokenized": "Cluster analysis or cluster analysis consists of assigning data points to clusters in such a way that elements of the same cluster are as similar as possible, while elements belonging to different clusters are as dissimilar as possible.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 36], [37, 45], [46, 48], [49, 58], [59, 63], [64, 70], [71, 73], [74, 82], [83, 85], [86, 90], [91, 92], [93, 96], [97, 101], [102, 110], [111, 113], [114, 117], [118, 122], [123, 130], [131, 134], [135, 137], [138, 145], [146, 148], [149, 157], [157, 158], [159, 164], [165, 173], [174, 183], [184, 186], [187, 196], [197, 205], [206, 209], [210, 212], [213, 223], [224, 226], [227, 235], [235, 236]]}
{"doc_key": "ai-dev-229", "ner": [[10, 11, "field"], [10, 10, "field"], [17, 18, "task"], [15, 15, "field"], [27, 28, "field"], [30, 31, "field"], [34, 35, "task"], [37, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6, 7, 8], "relations": [[10, 11, 10, 10, "named", "", false, false], [10, 11, 15, 15, "named", "", false, false], [10, 11, 27, 28, "named", "", false, false], [17, 18, 10, 10, "part-of", "task_part_of_field", false, false], [30, 31, 27, 28, "part-of", "", false, false], [34, 35, 30, 31, "part-of", "", false, false], [37, 37, 30, 31, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6, 7], "sentence": ["(", "2005", ")", "we", "can", "distinguish", "three", "different", "perspectives", "of", "text", "mining", ",", "namely", "text", "mining", "as", "information", "extraction", ",", "text", "mining", "as", "text", "data", "mining", "and", "text", "mining", "as", "data", "mining", "process", "(", "Knowledge", "Discovery", "in", "Databases", ")", ".", "Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005) we can distinguish three different perspectives of text mining, namely text mining as information extraction, text mining as text data mining and text mining as data mining process (Knowledge Discovery in Databases).Hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 9], [10, 13], [14, 25], [26, 31], [32, 41], [42, 54], [55, 57], [58, 62], [63, 69], [69, 70], [71, 77], [78, 82], [83, 89], [90, 92], [93, 104], [105, 115], [115, 116], [117, 121], [122, 128], [129, 131], [132, 136], [137, 141], [142, 148], [149, 152], [153, 157], [158, 164], [165, 167], [168, 172], [173, 179], [180, 187], [188, 189], [189, 198], [199, 208], [209, 211], [212, 221], [221, 222], [222, 223], [223, 228], [228, 229], [230, 232], [232, 233], [234, 244], [244, 245], [246, 248], [249, 252], [253, 257], [257, 258], [259, 261], [262, 263], [263, 267], [267, 268], [268, 269]]}
{"doc_key": "ai-dev-230", "ner": [[1, 3, "product"], [15, 20, "location"], [22, 22, "location"], [24, 24, "location"], [34, 35, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 15, 20, "related-to", "developed_for", false, false], [15, 20, 22, 22, "physical", "", false, false], [22, 22, 24, 24, "physical", "", false, false], [34, 35, 1, 3, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Rancho", "Arm", "was", "developed", "as", "a", "robotic", "arm", "to", "help", "disabled", "patients", "at", "the", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Center", "in", "Downey", ",", "California", ";", "this", "computer", "-", "controlled", "arm", "was", "purchased", "from", "Stanford", "University", "in", "1963", "."], "sentence-detokenized": "The Rancho Arm was developed as a robotic arm to help disabled patients at the Rancho Los Amigos National Rehabilitation Center in Downey, California; this computer-controlled arm was purchased from Stanford University in 1963.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 18], [19, 28], [29, 31], [32, 33], [34, 41], [42, 45], [46, 48], [49, 53], [54, 62], [63, 71], [72, 74], [75, 78], [79, 85], [86, 89], [90, 96], [97, 105], [106, 120], [121, 127], [128, 130], [131, 137], [137, 138], [139, 149], [149, 150], [151, 155], [156, 164], [164, 165], [165, 175], [176, 179], [180, 183], [184, 193], [194, 198], [199, 207], [208, 218], [219, 221], [222, 226], [226, 227]]}
{"doc_key": "ai-dev-231", "ner": [[1, 1, "university"], [3, 7, "researcher"], [11, 14, "organisation"], [22, 24, "organisation"], [28, 29, "researcher"], [31, 33, "researcher"], [46, 46, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 7, 1, 1, "physical", "", false, false], [3, 7, 1, 1, "role", "", false, false], [3, 7, 11, 14, "role", "founder", false, false], [3, 7, 22, 24, "role", "founder", false, false], [22, 24, 46, 46, "physical", "", false, false], [28, 29, 22, 24, "role", "founder", false, false], [31, 33, 22, 24, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["At", "UCSD", ",", "Norman", "was", "one", "of", "the", "founders", "of", "the", "Institute", "for", "Cognitive", "Science", "and", "one", "of", "the", "organisers", "of", "the", "Cognitive", "Science", "Society", "(", "together", "with", "Roger", "Schank", ",", "Allan", "M.", "Collins", "and", "others", ")", ",", "which", "held", "it", "s", "first", "meeting", "on", "the", "UCSD", "campus", "in", "1979", "."], "sentence-detokenized": "At UCSD, Norman was one of the founders of the Institute for Cognitive Science and one of the organisers of the Cognitive Science Society (together with Roger Schank, Allan M. Collins and others), which held its first meeting on the UCSD campus in 1979.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 23], [24, 26], [27, 30], [31, 39], [40, 42], [43, 46], [47, 56], [57, 60], [61, 70], [71, 78], [79, 82], [83, 86], [87, 89], [90, 93], [94, 104], [105, 107], [108, 111], [112, 121], [122, 129], [130, 137], [138, 139], [139, 147], [148, 152], [153, 158], [159, 165], [165, 166], [167, 172], [173, 175], [176, 183], [184, 187], [188, 194], [194, 195], [195, 196], [197, 202], [203, 207], [208, 210], [210, 211], [212, 217], [218, 225], [226, 228], [229, 232], [233, 237], [238, 244], [245, 247], [248, 252], [252, 253]]}
{"doc_key": "ai-dev-232", "ner": [[7, 8, "product"], [10, 11, "product"], [13, 14, "product"], [16, 18, "product"], [20, 21, "product"], [23, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 16, 18, "type-of", "", false, false], [23, 28, 16, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "commonly", "used", "robot", "configurations", "are", "articulated", "robots", ",", "SCARA", "robots", ",", "delta", "robots", "and", "Cartesian", "co-ordinate", "robots", "(", "gantry", "robots", "or", "x", "-", "y", "-", "z", "robots", ")", "."], "sentence-detokenized": "The most commonly used robot configurations are articulated robots, SCARA robots, delta robots and Cartesian co-ordinate robots (gantry robots or x-y-z robots).", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 28], [29, 43], [44, 47], [48, 59], [60, 66], [66, 67], [68, 73], [74, 80], [80, 81], [82, 87], [88, 94], [95, 98], [99, 108], [109, 120], [121, 127], [128, 129], [129, 135], [136, 142], [143, 145], [146, 147], [147, 148], [148, 149], [149, 150], [150, 151], [152, 158], [158, 159], [159, 160]]}
{"doc_key": "ai-dev-233", "ner": [[9, 9, "programlang"], [10, 11, "misc"], [16, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 9, 9, "part-of", "", false, false], [16, 16, 10, 11, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Alternatively", ",", "it", "can", "be", "used", "directly", "with", "the", "Perl", "TM", "module", "(", "which", "also", "supports", "LTM", ")", "."], "sentence-detokenized": "Alternatively, it can be used directly with the Perl TM module (which also supports LTM).", "token2charspan": [[0, 13], [13, 14], [15, 17], [18, 21], [22, 24], [25, 29], [30, 38], [39, 43], [44, 47], [48, 52], [53, 55], [56, 62], [63, 64], [64, 69], [70, 74], [75, 83], [84, 87], [87, 88], [88, 89]]}
{"doc_key": "ai-dev-234", "ner": [[6, 6, "country"], [9, 10, "organisation"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 6, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "competition", "was", "won", "by", "a", "US", "team", "from", "Newton", "Laboratories", "and", "was", "broadcast", "by", "CNN", "."], "sentence-detokenized": "The competition was won by a US team from Newton Laboratories and was broadcast by CNN.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 26], [27, 28], [29, 31], [32, 36], [37, 41], [42, 48], [49, 61], [62, 65], [66, 69], [70, 79], [80, 82], [83, 86], [86, 87]]}
{"doc_key": "ai-dev-235", "ner": [[0, 4, "misc"], [11, 12, "person"], [15, 16, "person"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 0, 4, "role", "directs", false, false], [15, 16, 0, 4, "role", "acts_in", false, false], [18, 19, 0, 4, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Butler", "'s", "in", "Love", ",", "a", "short", "film", "directed", "by", "David", "Arquette", "and", "starring", "Elizabeth", "Berkley", "and", "Thomas", "Jane", ",", "was", "released", "on", "23", "June", "2008", "."], "sentence-detokenized": "The Butler's in Love, a short film directed by David Arquette and starring Elizabeth Berkley and Thomas Jane, was released on 23 June 2008.", "token2charspan": [[0, 3], [4, 10], [10, 12], [13, 15], [16, 20], [20, 21], [22, 23], [24, 29], [30, 34], [35, 43], [44, 46], [47, 52], [53, 61], [62, 65], [66, 74], [75, 84], [85, 92], [93, 96], [97, 103], [104, 108], [108, 109], [110, 113], [114, 122], [123, 125], [126, 128], [129, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-dev-236", "ner": [[3, 6, "product"], [11, 11, "field"], [21, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 6, 21, 21, "general-affiliation", "", false, false], [11, 11, 3, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "Word", "Net", "is", "a", "resource", "that", "includes", "a", "taxonomy", ",", "the", "elements", "of", "which", "are", "the", "meanings", "of", "English", "words", "."], "sentence-detokenized": "For example, WordNet is a resource that includes a taxonomy, the elements of which are the meanings of English words.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [17, 20], [21, 23], [24, 25], [26, 34], [35, 39], [40, 48], [49, 50], [51, 59], [59, 60], [61, 64], [65, 73], [74, 76], [77, 82], [83, 86], [87, 90], [91, 99], [100, 102], [103, 110], [111, 116], [116, 117]]}
{"doc_key": "ai-dev-237", "ner": [[1, 3, "product"], [7, 7, "product"], [9, 9, "product"], [16, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 1, 3, "type-of", "", false, false], [7, 7, 16, 16, "related-to", "ability_to", false, false], [9, 9, 1, 3, "type-of", "", false, false], [9, 9, 16, 16, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Existing", "humanoid", "robotic", "systems", ",", "such", "as", "ASIMO", "and", "QRIO", ",", "use", "many", "motors", "to", "achieve", "locomotion", "."], "sentence-detokenized": "Existing humanoid robotic systems, such as ASIMO and QRIO, use many motors to achieve locomotion.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 33], [33, 34], [35, 39], [40, 42], [43, 48], [49, 52], [53, 57], [57, 58], [59, 62], [63, 67], [68, 74], [75, 77], [78, 85], [86, 96], [96, 97]]}
{"doc_key": "ai-dev-238", "ner": [[0, 1, "metrics"], [5, 8, "metrics"], [10, 10, "metrics"], [12, 16, "misc"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 8, 0, 1, "part-of", "", false, false], [10, 10, 0, 1, "part-of", "", false, false], [12, 16, 0, 1, "part-of", "", false, false], [18, 18, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "was", "designed", "with", "the", "penalisation", "factors", "of", "length", ",", "precision", ",", "n-", "gram", "word", "order", "penalisation", "and", "recall", "."], "sentence-detokenized": "LEPOR was designed with the penalisation factors of length, precision, n-gram word order penalisation and recall.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 23], [24, 27], [28, 40], [41, 48], [49, 51], [52, 58], [58, 59], [60, 69], [69, 70], [71, 73], [73, 77], [78, 82], [83, 88], [89, 101], [102, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-dev-239", "ner": [[5, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "based", "on", "the", "bilingual", "evaluation", "metric", ",", "but", "with", "some", "modifications", "."], "sentence-detokenized": "It is based on the bilingual evaluation metric, but with some modifications.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 14], [15, 18], [19, 28], [29, 39], [40, 46], [46, 47], [48, 51], [52, 56], [57, 61], [62, 75], [75, 76]]}
{"doc_key": "ai-dev-240", "ner": [[7, 7, "product"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "of", "implementation", "in", "MATLAB", "/", "Octave", ":"], "sentence-detokenized": "This is an example of implementation in MATLAB / Octave:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 36], [37, 39], [40, 46], [47, 48], [49, 55], [55, 56]]}
{"doc_key": "ai-dev-241", "ner": [[12, 12, "programlang"], [14, 14, "programlang"], [16, 16, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "designed", "to", "be", "used", "with", "various", "computer", "languages", ",", "including", "Python", ",", "Ruby", "and", "Scheme", "."], "sentence-detokenized": "It is designed to be used with various computer languages, including Python, Ruby and Scheme.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 20], [21, 25], [26, 30], [31, 38], [39, 47], [48, 57], [57, 58], [59, 68], [69, 75], [75, 76], [77, 81], [82, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-dev-242", "ner": [[0, 0, "researcher"], [5, 5, "organisation"], [11, 11, "conference"], [16, 17, "academicjournal"], [22, 24, "organisation"], [29, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 5, 5, "role", "", false, false], [0, 0, 11, 11, "role", "", false, false], [0, 0, 16, 17, "role", "", false, false], [0, 0, 22, 24, "role", "", false, false], [0, 0, 29, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "has", "been", "secretary", "of", "AISB", ",", "president", "and", "trustee", "of", "IJCAI", ",", "associate", "editor", "of", "Artificial", "Intelligence", ",", "governor", "of", "the", "Cognitive", "Science", "Society", "and", "president", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes has been secretary of AISB, president and trustee of IJCAI, associate editor of Artificial Intelligence, governor of the Cognitive Science Society and president of the American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 24], [25, 27], [28, 32], [32, 33], [34, 43], [44, 47], [48, 55], [56, 58], [59, 64], [64, 65], [66, 75], [76, 82], [83, 85], [86, 96], [97, 109], [109, 110], [111, 119], [120, 122], [123, 126], [127, 136], [137, 144], [145, 152], [153, 156], [157, 166], [167, 169], [170, 173], [174, 182], [183, 194], [195, 198], [199, 209], [210, 222], [222, 223]]}
{"doc_key": "ai-dev-243", "ner": [[4, 14, "misc"], [16, 18, "misc"], [23, 24, "person"], [29, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 24, 4, 14, "role", "directed_by", false, false], [23, 24, 16, 18, "role", "directed_by", false, false], [23, 24, 29, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "of", "these", ",", "Now", "is", "the", "Time", "(", "to", "Put", "On", "Your", "Glasses", ")", "and", "Around", "is", "Around", ",", "were", "directed", "by", "Norman", "McLaren", "in", "1951", "for", "the", "National", "Film", "Board", "of", "Canada", "."], "sentence-detokenized": "Two of these, Now is the Time (to Put On Your Glasses) and Around is Around, were directed by Norman McLaren in 1951 for the National Film Board of Canada.", "token2charspan": [[0, 3], [4, 6], [7, 12], [12, 13], [14, 17], [18, 20], [21, 24], [25, 29], [30, 31], [31, 33], [34, 37], [38, 40], [41, 45], [46, 53], [53, 54], [55, 58], [59, 65], [66, 68], [69, 75], [75, 76], [77, 81], [82, 90], [91, 93], [94, 100], [101, 108], [109, 111], [112, 116], [117, 120], [121, 124], [125, 133], [134, 138], [139, 144], [145, 147], [148, 154], [154, 155]]}
{"doc_key": "ai-dev-244", "ner": [[1, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "recommendation", "system", "aims", "to", "predict", "the", "preference", "for", "an", "article", "of", "a", "target", "user", "."], "sentence-detokenized": "A recommendation system aims to predict the preference for an article of a target user.", "token2charspan": [[0, 1], [2, 16], [17, 23], [24, 28], [29, 31], [32, 39], [40, 43], [44, 54], [55, 58], [59, 61], [62, 69], [70, 72], [73, 74], [75, 81], [82, 86], [86, 87]]}
{"doc_key": "ai-dev-245", "ner": [[0, 0, "algorithm"], [4, 4, "field"], [6, 6, "field"], [8, 9, "field"], [11, 13, "field"], [15, 18, "field"], [17, 17, "field"], [20, 20, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 4, "part-of", "", true, false], [0, 0, 6, 6, "part-of", "", true, false], [0, 0, 8, 9, "part-of", "", true, false], [0, 0, 11, 13, "part-of", "", true, false], [0, 0, 15, 18, "part-of", "", true, false], [0, 0, 17, 17, "part-of", "", true, false], [0, 0, 20, 20, "part-of", "", true, false], [0, 0, 22, 23, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Convolution", "has", "applications", "including", "probability", ",", "statistics", ",", "computer", "vision", ",", "natural", "language", "processing", ",", "image", "and", "signal", "processing", ",", "engineering", "and", "differential", "equations", "."], "sentence-detokenized": "Convolution has applications including probability, statistics, computer vision, natural language processing, image and signal processing, engineering and differential equations.", "token2charspan": [[0, 11], [12, 15], [16, 28], [29, 38], [39, 50], [50, 51], [52, 62], [62, 63], [64, 72], [73, 79], [79, 80], [81, 88], [89, 97], [98, 108], [108, 109], [110, 115], [116, 119], [120, 126], [127, 137], [137, 138], [139, 150], [151, 154], [155, 167], [168, 177], [177, 178]]}
{"doc_key": "ai-dev-246", "ner": [[0, 0, "field"], [4, 5, "task"], [3, 8, "task"], [10, 10, "task"], [11, 11, "task"], [12, 12, "task"], [14, 15, "task"], [18, 18, "task"], [17, 21, "task"], [23, 23, "task"], [26, 27, "task"], [29, 29, "field"], [31, 31, "field"], [33, 35, "field"], [37, 37, "field"], [39, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[0, 0, 4, 5, "part-of", "", true, false], [0, 0, 3, 8, "part-of", "", true, false], [0, 0, 10, 10, "part-of", "", true, false], [0, 0, 11, 11, "part-of", "", true, false], [0, 0, 12, 12, "part-of", "", true, false], [0, 0, 14, 15, "part-of", "", true, false], [0, 0, 18, 18, "part-of", "", true, false], [0, 0, 17, 21, "part-of", "", true, false], [0, 0, 23, 23, "part-of", "", true, false], [0, 0, 26, 27, "part-of", "", true, false], [0, 0, 29, 29, "part-of", "", true, false], [0, 0, 31, 31, "part-of", "", true, false], [0, 0, 33, 35, "part-of", "", true, false], [0, 0, 37, 37, "part-of", "", true, false], [0, 0, 39, 39, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["DSP", "applications", "include", "audio", "signal", "processing", ",", "audio", "compression", ",", "digital", "image", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communications", ",", "digital", "synthesisers", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", "and", "biomedicine", "."], "sentence-detokenized": "DSP applications include audio signal processing, audio compression, digital image processing, video compression, speech processing, speech recognition, digital communications, digital synthesisers, radar, sonar, financial signal processing, seismology and biomedicine.", "token2charspan": [[0, 3], [4, 16], [17, 24], [25, 30], [31, 37], [38, 48], [48, 49], [50, 55], [56, 67], [67, 68], [69, 76], [77, 82], [83, 93], [93, 94], [95, 100], [101, 112], [112, 113], [114, 120], [121, 131], [131, 132], [133, 139], [140, 151], [151, 152], [153, 160], [161, 175], [175, 176], [177, 184], [185, 197], [197, 198], [199, 204], [204, 205], [206, 211], [211, 212], [213, 222], [223, 229], [230, 240], [240, 241], [242, 252], [253, 256], [257, 268], [268, 269]]}
{"doc_key": "ai-dev-247", "ner": [[11, 12, "misc"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "20", "February", "1912", "-", "11", "August", "2011", ")", "was", "an", "American", "inventor", ",", "best", "known", "for", "creating", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "(20 February 1912 - 11 August 2011) was an American inventor, best known for creating Unimate, the first industrial robot.", "token2charspan": [[0, 1], [1, 3], [4, 12], [13, 17], [18, 19], [20, 22], [23, 29], [30, 34], [34, 35], [36, 39], [40, 42], [43, 51], [52, 60], [60, 61], [62, 66], [67, 72], [73, 76], [77, 85], [86, 93], [93, 94], [95, 98], [99, 104], [105, 115], [116, 121], [121, 122]]}
{"doc_key": "ai-dev-248", "ner": [[2, 4, "researcher"], [6, 8, "researcher"], [10, 10, "researcher"], [23, 25, "algorithm"], [27, 29, "algorithm"], [35, 37, "task"], [39, 40, "algorithm"], [45, 46, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 23, 25, "related-to", "writes_about", true, false], [6, 8, 23, 25, "related-to", "writes_about", true, false], [10, 10, 23, 25, "related-to", "writes_about", true, false], [23, 25, 27, 29, "related-to", "", true, false], [35, 37, 39, 40, "related-to", "", true, false], [45, 46, 39, 40, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Together", "with", "David", "E.", "Rumelhart", "and", "Ronald", "J.", "Williams", ",", "Hinton", "co-authored", "a", "much", "-", "cited", "paper", "published", "in", "1986", "that", "popularised", "the", "backpropagation", "algorithm", "for", "training", "multilayer", "neural", "networks", ",", "the", "extraordinary", "milestone", "in", "image", "recognition", "of", "the", "Alex", "Net", "designed", "by", "his", "student", "Alex", "Krizhevsky", "{{", "cite", "web"], "sentence-detokenized": "Together with David E. Rumelhart and Ronald J. Williams, Hinton co-authored a much-cited paper published in 1986 that popularised the backpropagation algorithm for training multilayer neural networks, the extraordinary milestone in image recognition of the AlexNet designed by his student Alex Krizhevsky {{cite web", "token2charspan": [[0, 8], [9, 13], [14, 19], [20, 22], [23, 32], [33, 36], [37, 43], [44, 46], [47, 55], [55, 56], [57, 63], [64, 75], [76, 77], [78, 82], [82, 83], [83, 88], [89, 94], [95, 104], [105, 107], [108, 112], [113, 117], [118, 129], [130, 133], [134, 149], [150, 159], [160, 163], [164, 172], [173, 183], [184, 190], [191, 199], [199, 200], [201, 204], [205, 218], [219, 228], [229, 231], [232, 237], [238, 249], [250, 252], [253, 256], [257, 261], [261, 264], [265, 273], [274, 276], [277, 280], [281, 288], [289, 293], [294, 304], [305, 307], [307, 311], [312, 315]]}
{"doc_key": "ai-dev-249", "ner": [[11, 18, "metrics"], [20, 22, "metrics"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "value", "to", "be", "predicted", "is", "continuously", "distributed", ",", "the", "mean", "square", "error", ",", "root", "mean", "square", "error", "or", "median", "absolute", "deviation", "can", "be", "used", "to", "summarise", "the", "errors", "."], "sentence-detokenized": "When the value to be predicted is continuously distributed, the mean square error, root mean square error or median absolute deviation can be used to summarise the errors.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 17], [18, 20], [21, 30], [31, 33], [34, 46], [47, 58], [58, 59], [60, 63], [64, 68], [69, 75], [76, 81], [81, 82], [83, 87], [88, 92], [93, 99], [100, 105], [106, 108], [109, 115], [116, 124], [125, 134], [135, 138], [139, 141], [142, 146], [147, 149], [150, 159], [160, 163], [164, 170], [170, 171]]}
{"doc_key": "ai-dev-250", "ner": [[0, 1, "algorithm"], [9, 10, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 9, 10, "part-of", "", true, false], [0, 1, 13, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Conceptual", "clustering", "developed", "mainly", "in", "the", "1980s", "as", "a", "machine", "learning", "paradigm", "for", "unsupervised", "learning", "."], "sentence-detokenized": "Conceptual clustering developed mainly in the 1980s as a machine learning paradigm for unsupervised learning.", "token2charspan": [[0, 10], [11, 21], [22, 31], [32, 38], [39, 41], [42, 45], [46, 51], [52, 54], [55, 56], [57, 64], [65, 73], [74, 82], [83, 86], [87, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-dev-251", "ner": [[9, 10, "product"], [27, 29, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "named", "entities", "can", "not", "be", "recognised", "by", "the", "machine", "translator", ",", "they", "could", "be", "mistranslated", "as", "common", "nouns", ",", "which", "would", "most", "likely", "not", "affect", "the", "bilingual", "evaluation", "of", "the", "translation", ",", "but", "would", "change", "the", "human", "readability", "of", "the", "text", "."], "sentence-detokenized": "If named entities cannot be recognised by the machine translator, they could be mistranslated as common nouns, which would most likely not affect the bilingual evaluation of the translation, but would change the human readability of the text.", "token2charspan": [[0, 2], [3, 8], [9, 17], [18, 21], [21, 24], [25, 27], [28, 38], [39, 41], [42, 45], [46, 53], [54, 64], [64, 65], [66, 70], [71, 76], [77, 79], [80, 93], [94, 96], [97, 103], [104, 109], [109, 110], [111, 116], [117, 122], [123, 127], [128, 134], [135, 138], [139, 145], [146, 149], [150, 159], [160, 170], [171, 173], [174, 177], [178, 189], [189, 190], [191, 194], [195, 200], [201, 207], [208, 211], [212, 217], [218, 229], [230, 232], [233, 236], [237, 241], [241, 242]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 22, "location"], [24, 24, "country"], [38, 39, "researcher"], [45, 45, "researcher"], [49, 50, "university"], [54, 55, "researcher"], [57, 58, "researcher"], [60, 61, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 22, "physical", "", false, false], [20, 22, 24, 24, "physical", "", false, false], [45, 45, 49, 50, "physical", "", false, false], [45, 45, 49, 50, "role", "", false, false], [54, 55, 49, 50, "physical", "", false, false], [54, 55, 49, 50, "role", "", false, false], [57, 58, 49, 50, "physical", "", false, false], [57, 58, 49, 50, "role", "", false, false], [60, 61, 49, 50, "physical", "", false, false], [60, 61, 49, 50, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng", "-", "S\u00e4by", ",", "Sweden", ",", "pp.", "1-", "3", "This", "model", ",", "partially", "influenced", "by", "the", "work", "of", "Sydney", "Lamb", ",", "was", "widely", "used", "by", "Schank", "'s", "students", "at", "Yale", "University", ",", "such", "as", "Robert", "Wilensky", ",", "Wendy", "Lehnert", "and", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, pp. 1-3 This model, partially influenced by the work of Sydney Lamb, was widely used by Schank's students at Yale University, such as Robert Wilensky, Wendy Lehnert and Janet Kolodner.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 130], [130, 131], [131, 135], [135, 136], [137, 143], [143, 144], [145, 148], [149, 151], [151, 152], [153, 157], [158, 163], [163, 164], [165, 174], [175, 185], [186, 188], [189, 192], [193, 197], [198, 200], [201, 207], [208, 212], [212, 213], [214, 217], [218, 224], [225, 229], [230, 232], [233, 239], [239, 241], [242, 250], [251, 253], [254, 258], [259, 269], [269, 270], [271, 275], [276, 278], [279, 285], [286, 294], [294, 295], [296, 301], [302, 309], [310, 313], [314, 319], [320, 328], [328, 329]]}
{"doc_key": "ai-dev-253", "ner": [[0, 4, "algorithm"], [6, 6, "algorithm"], [13, 13, "algorithm"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 0, 4, "named", "", false, false], [13, 13, 0, 4, "named", "", false, false], [15, 16, 0, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "improved", "maximum", "likelihood", "method", "(", "IMLM", ")", "is", "a", "combination", "of", "two", "MLM", "(", "maximum", "likelihood", ")", "estimators", "."], "sentence-detokenized": "The improved maximum likelihood method (IMLM) is a combination of two MLM (maximum likelihood) estimators.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 38], [39, 40], [40, 44], [44, 45], [46, 48], [49, 50], [51, 62], [63, 65], [66, 69], [70, 73], [74, 75], [75, 82], [83, 93], [93, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-254", "ner": [[19, 20, "metrics"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[23, 24, 19, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "methods", "can", "also", "analyse", "the", "output", "of", "a", "programme", "and", "its", "usefulness", "and", "thus", "may", "involve", "analysing", "its", "confusion", "matrix", "(", "or", "confusion", "table", ")", "."], "sentence-detokenized": "These methods can also analyse the output of a programme and its usefulness and thus may involve analysing its confusion matrix (or confusion table).", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 22], [23, 30], [31, 34], [35, 41], [42, 44], [45, 46], [47, 56], [57, 60], [61, 64], [65, 75], [76, 79], [80, 84], [85, 88], [89, 96], [97, 106], [107, 110], [111, 120], [121, 127], [128, 129], [129, 131], [132, 141], [142, 147], [147, 148], [148, 149]]}
{"doc_key": "ai-dev-255", "ner": [[0, 1, "product"], [5, 6, "researcher"], [8, 9, "researcher"], [11, 13, "researcher"], [18, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "origin", "", false, false], [0, 1, 8, 9, "origin", "", false, false], [0, 1, 11, 13, "origin", "", false, false], [0, 1, 18, 24, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "was", "first", "published", "by", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", "and", "Luc", "Van", "Gool", "and", "presented", "at", "the", "European", "Conference", "on", "Computer", "Vision", "in", "2006", "."], "sentence-detokenized": "SURF was first published by Herbert Bay, Tinne Tuytelaars and Luc Van Gool and presented at the European Conference on Computer Vision in 2006.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 39], [39, 40], [41, 46], [47, 57], [58, 61], [62, 65], [66, 69], [70, 74], [75, 78], [79, 88], [89, 91], [92, 95], [96, 104], [105, 115], [116, 118], [119, 127], [128, 134], [135, 137], [138, 142], [142, 143]]}
{"doc_key": "ai-dev-256", "ner": [[0, 4, "task"], [7, 8, "field"], [10, 11, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 7, 8, "part-of", "", false, false], [0, 4, 10, 11, "part-of", "", false, false], [0, 4, 13, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "is", "a", "field", "of", "research", "in", "pattern", "recognition", ",", "artificial", "intelligence", "and", "computer", "vision", "."], "sentence-detokenized": "OCR is a field of research in pattern recognition, artificial intelligence and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 14], [15, 17], [18, 26], [27, 29], [30, 37], [38, 49], [49, 50], [51, 61], [62, 74], [75, 78], [79, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-dev-257", "ner": [[5, 7, "metrics"], [10, 12, "algorithm"], [14, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 10, 12, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Continuing", "the", "example", "using", "the", "maximum", "likelihood", "estimator", ",", "the", "probability", "density", "function", "(", "pdf", ")", "of", "the", "noise", "for", "a", "mathwn", "/", "math", "sample", "is"], "sentence-detokenized": "Continuing the example using the maximum likelihood estimator, the probability density function (pdf) of the noise for a mathwn / math sample is", "token2charspan": [[0, 10], [11, 14], [15, 22], [23, 28], [29, 32], [33, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 78], [79, 86], [87, 95], [96, 97], [97, 100], [100, 101], [102, 104], [105, 108], [109, 114], [115, 118], [119, 120], [121, 127], [128, 129], [130, 134], [135, 141], [142, 144]]}
{"doc_key": "ai-dev-258", "ner": [[3, 4, "field"], [6, 7, "task"], [9, 10, "task"], [12, 13, "task"], [15, 16, "task"], [18, 20, "task"], [22, 22, "task"], [24, 24, "task"], [26, 27, "task"], [29, 30, "task"], [32, 34, "task"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[6, 7, 3, 4, "part-of", "", false, false], [9, 10, 3, 4, "part-of", "", false, false], [12, 13, 3, 4, "part-of", "", false, false], [15, 16, 3, 4, "part-of", "", false, false], [18, 20, 3, 4, "part-of", "", false, false], [22, 22, 3, 4, "part-of", "", false, false], [24, 24, 3, 4, "part-of", "", false, false], [26, 27, 3, 4, "part-of", "", false, false], [29, 30, 3, 4, "part-of", "", false, false], [32, 34, 3, 4, "part-of", "", false, false], [36, 37, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["The", "sub-domains", "of", "computer", "vision", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "3D", "pose", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "aid", ",", "3D", "scene", "modelling", "and", "image", "restoration", "."], "sentence-detokenized": "The sub-domains of computer vision include scene reconstruction, event detection, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual aid, 3D scene modelling and image restoration.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 27], [28, 34], [35, 42], [43, 48], [49, 63], [63, 64], [65, 70], [71, 80], [80, 81], [82, 87], [88, 96], [96, 97], [98, 104], [105, 116], [116, 117], [118, 120], [121, 125], [126, 136], [136, 137], [138, 146], [146, 147], [148, 156], [156, 157], [158, 164], [165, 175], [175, 176], [177, 183], [184, 187], [187, 188], [189, 191], [192, 197], [198, 207], [208, 211], [212, 217], [218, 229], [229, 230]]}
{"doc_key": "ai-dev-259", "ner": [[5, 9, "conference"], [11, 13, "researcher"], [15, 16, "misc"], [19, 20, "conference"], [23, 23, "researcher"], [25, 25, "researcher"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 9, 19, 20, "named", "", false, false], [11, 13, 15, 16, "win-defeat", "", false, false], [11, 13, 27, 28, "related-to", "writes_about", true, false], [15, 16, 5, 9, "temporal", "", false, false], [23, 23, 15, 16, "win-defeat", "", false, true], [23, 23, 27, 28, "related-to", "writes_about", true, false], [25, 25, 15, 16, "win-defeat", "", false, true], [25, 25, 27, 28, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["In", "2013", ",", "at", "the", "International", "Conference", "on", "Computer", "Vision", ",", "Terzopoulos", "was", "awarded", "the", "Helmholtz", "Prize", "for", "his", "1987", "ICCV", "paper", "with", "Kass", "and", "Witkin", "on", "active", "contour", "models", "."], "sentence-detokenized": "In 2013, at the International Conference on Computer Vision, Terzopoulos was awarded the Helmholtz Prize for his 1987 ICCV paper with Kass and Witkin on active contour models.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 40], [41, 43], [44, 52], [53, 59], [59, 60], [61, 72], [73, 76], [77, 84], [85, 88], [89, 98], [99, 104], [105, 108], [109, 112], [113, 117], [118, 122], [123, 128], [129, 133], [134, 138], [139, 142], [143, 149], [150, 152], [153, 159], [160, 167], [168, 174], [174, 175]]}
{"doc_key": "ai-dev-260", "ner": [[14, 15, "task"], [17, 17, "algorithm"], [18, 25, "algorithm"], [21, 23, "algorithm"], [27, 28, "algorithm"], [30, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 15, 17, 17, "usage", "", true, false], [14, 15, 18, 25, "usage", "", true, false], [14, 15, 21, 23, "usage", "", true, false], [14, 15, 27, 28, "usage", "", true, false], [14, 15, 30, 30, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["There", "are", "many", "algorithms", "for", "solving", "such", "problems", ";", "the", "most", "popular", "ones", "for", "linear", "classification", "include", "stochastic", "gradient", "descent", ",", "L", "-", "BFGS", "gradient", "descent", ",", "coordinate", "descent", "and", "Newton", "'s", "methods", "."], "sentence-detokenized": "There are many algorithms for solving such problems; the most popular ones for linear classification include stochastic gradient descent, L-BFGS gradient descent, coordinate descent and Newton's methods.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 25], [26, 29], [30, 37], [38, 42], [43, 51], [51, 52], [53, 56], [57, 61], [62, 69], [70, 74], [75, 78], [79, 85], [86, 100], [101, 108], [109, 119], [120, 128], [129, 136], [136, 137], [138, 139], [139, 140], [140, 144], [145, 153], [154, 161], [161, 162], [163, 173], [174, 181], [182, 185], [186, 192], [192, 194], [195, 202], [202, 203]]}
{"doc_key": "ai-dev-261", "ner": [[0, 3, "algorithm"], [6, 8, "algorithm"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 11, 12, "origin", "", false, false], [6, 8, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Short", "-", "term", "memory", "networks", "(", "LSTM", ")", "were", "invented", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "and", "have", "set", "accuracy", "records", "in", "various", "fields", "of", "application", "."], "sentence-detokenized": "Short-term memory networks (LSTM) were invented by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997 and have set accuracy records in various fields of application.", "token2charspan": [[0, 5], [5, 6], [6, 10], [11, 17], [18, 26], [27, 28], [28, 32], [32, 33], [34, 38], [39, 47], [48, 50], [51, 55], [56, 66], [67, 70], [71, 77], [78, 89], [90, 92], [93, 97], [98, 101], [102, 106], [107, 110], [111, 119], [120, 127], [128, 130], [131, 138], [139, 145], [146, 148], [149, 160], [160, 161]]}
{"doc_key": "ai-dev-262", "ner": [[0, 1, "product"], [5, 9, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 5, 9, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["TN", "was", "developed", "at", "the", "Massachusetts", "General", "Hospital", "and", "was", "tested", "in", "several", "scenarios", ",", "including", "extraction", "of", "smoking", "status", ",", "family", "history", "of", "coronary", "artery", "disease", ",", "and", "identification", "of", "patients", "with", "sleep", "disorders", ","], "sentence-detokenized": "TN was developed at the Massachusetts General Hospital and was tested in several scenarios, including extraction of smoking status, family history of coronary artery disease, and identification of patients with sleep disorders,", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 23], [24, 37], [38, 45], [46, 54], [55, 58], [59, 62], [63, 69], [70, 72], [73, 80], [81, 90], [90, 91], [92, 101], [102, 112], [113, 115], [116, 123], [124, 130], [130, 131], [132, 138], [139, 146], [147, 149], [150, 158], [159, 165], [166, 173], [173, 174], [175, 178], [179, 193], [194, 196], [197, 205], [206, 210], [211, 216], [217, 226], [226, 227]]}
{"doc_key": "ai-dev-263", "ner": [[3, 3, "researcher"], [8, 8, "product"], [15, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 8, "role", "sells", false, false], [8, 8, 15, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "shipped", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was shipped to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 73], [74, 76], [77, 84], [85, 91], [92, 94], [95, 99], [99, 100]]}
{"doc_key": "ai-dev-264", "ner": [[1, 5, "conference"], [14, 15, "location"], [17, 17, "location"], [19, 19, "country"], [29, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 5, 14, 15, "physical", "", false, false], [14, 15, 17, 17, "physical", "", false, false], [17, 17, 19, 19, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Campus", "Party", "Europe", "was", "held", "from", "14", "to", "18", "April", "2010", "at", "the", "Caja", "M\u00e1gica", "in", "Madrid", ",", "Spain", ",", "with", "800", "participants", "from", "each", "of", "the", "27", "EU", "Member", "States", "."], "sentence-detokenized": "The Campus Party Europe was held from 14 to 18 April 2010 at the Caja M\u00e1gica in Madrid, Spain, with 800 participants from each of the 27 EU Member States.", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 23], [24, 27], [28, 32], [33, 37], [38, 40], [41, 43], [44, 46], [47, 52], [53, 57], [58, 60], [61, 64], [65, 69], [70, 76], [77, 79], [80, 86], [86, 87], [88, 93], [93, 94], [95, 99], [100, 103], [104, 116], [117, 121], [122, 126], [127, 129], [130, 133], [134, 136], [137, 139], [140, 146], [147, 153], [153, 154]]}
{"doc_key": "ai-dev-265", "ner": [[9, 9, "organisation"], [11, 13, "organisation"], [16, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 19, 9, 9, "origin", "", false, false], [16, 19, 11, 13, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2016", ",", "a", "collaboration", "was", "announced", "between", "DeepMind", "and", "Moorfields", "Eye", "Hospital", "to", "develop", "AI", "applications", "for", "healthcare", "."], "sentence-detokenized": "In July 2016, a collaboration was announced between DeepMind and Moorfields Eye Hospital to develop AI applications for healthcare.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 15], [16, 29], [30, 33], [34, 43], [44, 51], [52, 60], [61, 64], [65, 75], [76, 79], [80, 88], [89, 91], [92, 99], [100, 102], [103, 115], [116, 119], [120, 130], [130, 131]]}
{"doc_key": "ai-dev-266", "ner": [[5, 6, "misc"], [14, 16, "university"], [18, 18, "university"], [20, 21, "university"], [23, 24, "university"], [26, 26, "university"], [28, 28, "university"], [30, 33, "university"], [35, 36, "university"], [38, 39, "university"], [41, 41, "university"], [43, 45, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 6, 14, 16, "physical", "", false, false], [5, 6, 18, 18, "physical", "", false, false], [5, 6, 20, 21, "physical", "", false, false], [5, 6, 23, 24, "physical", "", false, false], [5, 6, 26, 26, "physical", "", false, false], [5, 6, 28, 28, "physical", "", false, false], [5, 6, 30, 33, "physical", "", false, false], [5, 6, 35, 36, "physical", "", false, false], [5, 6, 38, 39, "physical", "", false, false], [5, 6, 41, 41, "physical", "", false, false], [5, 6, 43, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["In", "the", "end", ",", "eleven", "PR2s", "were", "awarded", "to", "different", "institutions", ",", "including", "the", "University", "of", "Freiburg", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "Technical", "University", "of", "Munich", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", "and", "University", "of", "Tokyo", "."], "sentence-detokenized": "In the end, eleven PR2s were awarded to different institutions, including the University of Freiburg, Bosch, Georgia Tech, KU Leuven, MIT, Stanford, Technical University of Munich, UC Berkeley, U Penn, USC and University of Tokyo.", "token2charspan": [[0, 2], [3, 6], [7, 10], [10, 11], [12, 18], [19, 23], [24, 28], [29, 36], [37, 39], [40, 49], [50, 62], [62, 63], [64, 73], [74, 77], [78, 88], [89, 91], [92, 100], [100, 101], [102, 107], [107, 108], [109, 116], [117, 121], [121, 122], [123, 125], [126, 132], [132, 133], [134, 137], [137, 138], [139, 147], [147, 148], [149, 158], [159, 169], [170, 172], [173, 179], [179, 180], [181, 183], [184, 192], [192, 193], [194, 195], [196, 200], [200, 201], [202, 205], [206, 209], [210, 220], [221, 223], [224, 229], [229, 230]]}
{"doc_key": "ai-dev-267", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [7, 7, "metrics"], [9, 9, "metrics"], [19, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 19, 20, "part-of", "", false, false], [5, 5, 19, 20, "part-of", "", false, false], [7, 7, 19, 20, "part-of", "", false, false], [9, 9, 19, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "counts", "of", "TP", ",", "TN", ",", "FP", "and", "FN", "are", "usually", "reported", "in", "a", "table", "known", "as", "a", "confusion", "matrix", "."], "sentence-detokenized": "The counts of TP, TN, FP and FN are usually reported in a table known as a confusion matrix.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 16], [16, 17], [18, 20], [20, 21], [22, 24], [25, 28], [29, 31], [32, 35], [36, 43], [44, 52], [53, 55], [56, 57], [58, 63], [64, 69], [70, 72], [73, 74], [75, 84], [85, 91], [91, 92]]}
{"doc_key": "ai-dev-268", "ner": [[4, 5, "metrics"], [7, 8, "metrics"], [10, 11, "metrics"], [13, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "feature", "sets", ",", "information", "gain", ",", "cross", "entropy", ",", "mutual", "information", "and", "odds", "ratio", "are", "usually", "used", "."], "sentence-detokenized": "As feature sets, information gain, cross entropy, mutual information and odds ratio are usually used.", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [17, 28], [29, 33], [33, 34], [35, 40], [41, 48], [48, 49], [50, 56], [57, 68], [69, 72], [73, 77], [78, 83], [84, 87], [88, 95], [96, 100], [100, 101]]}
{"doc_key": "ai-dev-269", "ner": [[10, 11, "task"], [13, 14, "task"], [16, 16, "task"], [18, 18, "task"], [20, 20, "task"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[22, 22, 20, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "successfully", "applied", "to", "various", "problems", ",", "including", "robot", "control", ",", "lift", "programming", ",", "telecommunications", ",", "checkers", "and", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "It has been successfully applied to various problems, including robot control, lift programming, telecommunications, checkers and Go (AlphaGo).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 32], [33, 35], [36, 43], [44, 52], [52, 53], [54, 63], [64, 69], [70, 77], [77, 78], [79, 83], [84, 95], [95, 96], [97, 115], [115, 116], [117, 125], [126, 129], [130, 132], [133, 134], [134, 141], [141, 142], [142, 143]]}
{"doc_key": "ai-dev-270", "ner": [[11, 14, "misc"], [21, 23, "university"], [25, 25, "location"], [20, 27, "location"], [31, 36, "location"], [39, 42, "location"], [43, 43, "location"], [45, 45, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 14, 21, 23, "physical", "", false, false], [21, 23, 25, 25, "physical", "", false, false], [25, 25, 20, 27, "physical", "", false, false], [31, 36, 39, 42, "physical", "", false, false], [39, 42, 43, 43, "physical", "", false, false], [43, 43, 45, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "the", "inaugural", "year", "of", "Mission", "8", ",", "the", "American", "venue", "was", "held", "on", "the", "campus", "of", "the", "Georgia", "Institute", "of", "Technology", "in", "Atlanta", ",", "Georgia", ",", "while", "the", "Asia", "/", "Pacific", "venue", "was", "held", "at", "the", "Beihang", "University", "Gymnasium", "in", "Beijing", ",", "China", "."], "sentence-detokenized": "In 2018, the inaugural year of Mission 8, the American venue was held on the campus of the Georgia Institute of Technology in Atlanta, Georgia, while the Asia/Pacific venue was held at the Beihang University Gymnasium in Beijing, China.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 38], [39, 40], [40, 41], [42, 45], [46, 54], [55, 60], [61, 64], [65, 69], [70, 72], [73, 76], [77, 83], [84, 86], [87, 90], [91, 98], [99, 108], [109, 111], [112, 122], [123, 125], [126, 133], [133, 134], [135, 142], [142, 143], [144, 149], [150, 153], [154, 158], [158, 159], [159, 166], [167, 172], [173, 176], [177, 181], [182, 184], [185, 188], [189, 196], [197, 207], [208, 217], [218, 220], [221, 228], [228, 229], [230, 235], [235, 236]]}
{"doc_key": "ai-dev-271", "ner": [[0, 1, "field"], [6, 7, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "origin", "", false, false], [0, 1, 6, 7, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "is", "strongly", "linked", "to", "pattern", "recognition", "and", "originates", "from", "artificial", "intelligence", "."], "sentence-detokenized": "Machine learning is strongly linked to pattern recognition and originates from artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 28], [29, 35], [36, 38], [39, 46], [47, 58], [59, 62], [63, 73], [74, 78], [79, 89], [90, 102], [102, 103]]}
{"doc_key": "ai-dev-272", "ner": [[3, 3, "programlang"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "features", "3", "Java", "games", "that", "are", "controlled", "with", "the", "remote", "control", "and", "displayed", "on", "the", "LCD", "screen", "."], "sentence-detokenized": "It features 3 Java games that are controlled with the remote control and displayed on the LCD screen.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 18], [19, 24], [25, 29], [30, 33], [34, 44], [45, 49], [50, 53], [54, 60], [61, 68], [69, 72], [73, 82], [83, 85], [86, 89], [90, 93], [94, 100], [100, 101]]}
{"doc_key": "ai-dev-273", "ner": [[3, 15, "task"], [17, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 19, 3, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "commercially", "successful", "computer", "vision", "-", "based", "technique", "for", "estimating", "the", "pose", "of", "an", "articulated", "body", "is", "optical", "motion", "capture", "."], "sentence-detokenized": "A commercially successful computer vision-based technique for estimating the pose of an articulated body is optical motion capture.", "token2charspan": [[0, 1], [2, 14], [15, 25], [26, 34], [35, 41], [41, 42], [42, 47], [48, 57], [58, 61], [62, 72], [73, 76], [77, 81], [82, 84], [85, 87], [88, 99], [100, 104], [105, 107], [108, 115], [116, 122], [123, 130], [130, 131]]}
{"doc_key": "ai-dev-274", "ner": [[1, 1, "organisation"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 9, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SMC", "is", "very", "similar", "to", "the", "better", "known", "Jaccard", "index", "."], "sentence-detokenized": "The SMC is very similar to the better known Jaccard index.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 23], [24, 26], [27, 30], [31, 37], [38, 43], [44, 51], [52, 57], [57, 58]]}
{"doc_key": "ai-dev-275", "ner": [[1, 1, "product"], [5, 7, "product"], [10, 12, "product"], [22, 23, "researcher"], [29, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 10, 12, "named", "", false, false], [1, 1, 22, 23, "artifact", "", false, false], [1, 1, 29, 29, "artifact", "", false, false], [5, 7, 1, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ",", "or", "Programmable", "Universal", "Manipulation", "Arm", ")", "is", "an", "industrial", "robotic", "arm", "developed", "by", "Victor", "Scheinman", "at", "the", "pioneering", "robotics", "company", "Unimation", "."], "sentence-detokenized": "The PUMA (Programmable Universal Machine for Assembly, or Programmable Universal Manipulation Arm) is an industrial robotic arm developed by Victor Scheinman at the pioneering robotics company Unimation.", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 22], [23, 32], [33, 40], [41, 44], [45, 53], [53, 54], [55, 57], [58, 70], [71, 80], [81, 93], [94, 97], [97, 98], [99, 101], [102, 104], [105, 115], [116, 123], [124, 127], [128, 137], [138, 140], [141, 147], [148, 157], [158, 160], [161, 164], [165, 175], [176, 184], [185, 192], [193, 202], [202, 203]]}
{"doc_key": "ai-dev-276", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "written", "in", "Python", "."], "sentence-detokenized": "It is written in Python.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 23], [23, 24]]}
{"doc_key": "ai-dev-277", "ner": [[0, 0, "misc"], [2, 4, "misc"], [12, 12, "field"], [14, 15, "field"], [17, 17, "field"], [20, 20, "field"], [23, 24, "field"], [26, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 2, 4, "related-to", "metric_for", true, false], [0, 0, 12, 12, "part-of", "", false, false], [0, 0, 14, 15, "part-of", "", false, false], [0, 0, 17, 17, "part-of", "", false, false], [0, 0, 20, 20, "part-of", "", false, false], [0, 0, 23, 24, "part-of", "", false, false], [0, 0, 26, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Bandwidth", "in", "hertz", "is", "a", "central", "concept", "in", "many", "fields", ",", "including", "electronics", ",", "information", "theory", ",", "digital", "communications", ",", "radio", "communications", ",", "signal", "processing", "and", "spectroscopy", ",", "and", "is", "one", "of", "the", "determining", "factors", "of", "the", "capacity", "of", "a", "given", "communication", "channel", "."], "sentence-detokenized": "Bandwidth in hertz is a central concept in many fields, including electronics, information theory, digital communications, radio communications, signal processing and spectroscopy, and is one of the determining factors of the capacity of a given communication channel.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 21], [22, 23], [24, 31], [32, 39], [40, 42], [43, 47], [48, 54], [54, 55], [56, 65], [66, 77], [77, 78], [79, 90], [91, 97], [97, 98], [99, 106], [107, 121], [121, 122], [123, 128], [129, 143], [143, 144], [145, 151], [152, 162], [163, 166], [167, 179], [179, 180], [181, 184], [185, 187], [188, 191], [192, 194], [195, 198], [199, 210], [211, 218], [219, 221], [222, 225], [226, 234], [235, 237], [238, 239], [240, 245], [246, 259], [260, 267], [267, 268]]}
{"doc_key": "ai-dev-278", "ner": [[9, 9, "algorithm"], [11, 11, "algorithm"], [17, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 17, 20, "part-of", "", false, false], [11, 11, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "a", "convex", "loss", "is", "used", "(", "as", "in", "AdaBoost", ",", "LogitBoost", "and", "all", "members", "of", "the", "AnyBoost", "family", "of", "algorithms", ")", ",", "an", "example", "with", "a", "larger", "margin", "will", "receive", "a", "lower", "(", "or", "equal", ")", "weight", "than", "an", "example", "with", "a", "smaller", "margin", "."], "sentence-detokenized": "If a convex loss is used (as in AdaBoost, LogitBoost and all members of the AnyBoost family of algorithms), an example with a larger margin will receive a lower (or equal) weight than an example with a smaller margin.", "token2charspan": [[0, 2], [3, 4], [5, 11], [12, 16], [17, 19], [20, 24], [25, 26], [26, 28], [29, 31], [32, 40], [40, 41], [42, 52], [53, 56], [57, 60], [61, 68], [69, 71], [72, 75], [76, 84], [85, 91], [92, 94], [95, 105], [105, 106], [106, 107], [108, 110], [111, 118], [119, 123], [124, 125], [126, 132], [133, 139], [140, 144], [145, 152], [153, 154], [155, 160], [161, 162], [162, 164], [165, 170], [170, 171], [172, 178], [179, 183], [184, 186], [187, 194], [195, 199], [200, 201], [202, 209], [210, 216], [216, 217]]}
{"doc_key": "ai-dev-279", "ner": [[0, 7, "researcher"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", "'s", "1991", "diploma", "thesis", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Sepp Hochreiter's 1991 diploma thesis Sepp Hochreiter.", "token2charspan": [[0, 4], [5, 15], [15, 17], [18, 22], [23, 30], [31, 37], [38, 42], [43, 53], [53, 54]]}
{"doc_key": "ai-dev-280", "ner": [[4, 5, "algorithm"], [7, 7, "algorithm"], [10, 11, "algorithm"], [14, 14, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [27, 28, "algorithm"], [31, 32, "algorithm"], [34, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 7, 4, 5, "named", "", false, false], [14, 14, 10, 11, "named", "", false, false], [17, 19, 27, 28, "related-to", "", true, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Typical", "discriminative", "models", "include", "logistic", "regression", "(", "LR", ")", ",", "support", "vector", "machines", "(", "SVM", ")", ",", "conditional", "random", "fields", "(", "CRF", ")", "(", "specified", "on", "an", "undirected", "graph", ")", ",", "decision", "trees", ",", "neural", "networks", "and", "many", "others", "."], "sentence-detokenized": "Typical discriminative models include logistic regression (LR), support vector machines (SVM), conditional random fields (CRF) (specified on an undirected graph), decision trees, neural networks and many others.", "token2charspan": [[0, 7], [8, 22], [23, 29], [30, 37], [38, 46], [47, 57], [58, 59], [59, 61], [61, 62], [62, 63], [64, 71], [72, 78], [79, 87], [88, 89], [89, 92], [92, 93], [93, 94], [95, 106], [107, 113], [114, 120], [121, 122], [122, 125], [125, 126], [127, 128], [128, 137], [138, 140], [141, 143], [144, 154], [155, 160], [160, 161], [161, 162], [163, 171], [172, 177], [177, 178], [179, 185], [186, 194], [195, 198], [199, 203], [204, 210], [210, 211]]}
{"doc_key": "ai-dev-281", "ner": [[9, 11, "metrics"], [32, 33, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["You", "can", "also", "use", "these", "probabilities", "and", "estimate", "the", "mean", "square", "error", "(", "or", "some", "other", "similar", "measure", ")", "between", "the", "probabilities", "and", "the", "actual", "values", ",", "then", "combine", "this", "with", "the", "confusion", "matrix", "to", "create", "very", "efficient", "fitness", "functions", "for", "logistic", "regression", "."], "sentence-detokenized": "You can also use these probabilities and estimate the mean square error (or some other similar measure) between the probabilities and the actual values, then combine this with the confusion matrix to create very efficient fitness functions for logistic regression.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 16], [17, 22], [23, 36], [37, 40], [41, 49], [50, 53], [54, 58], [59, 65], [66, 71], [72, 73], [73, 75], [76, 80], [81, 86], [87, 94], [95, 102], [102, 103], [104, 111], [112, 115], [116, 129], [130, 133], [134, 137], [138, 144], [145, 151], [151, 152], [153, 157], [158, 165], [166, 170], [171, 175], [176, 179], [180, 189], [190, 196], [197, 199], [200, 206], [207, 211], [212, 221], [222, 229], [230, 239], [240, 243], [244, 252], [253, 263], [263, 264]]}
{"doc_key": "ai-dev-282", "ner": [[0, 1, "product"], [7, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 7, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "was", "first", "introduced", "in", "2005", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "."], "sentence-detokenized": "VoiceOver was first introduced in 2005 in Mac OS X Tiger (10.4).", "token2charspan": [[0, 9], [10, 13], [14, 19], [20, 30], [31, 33], [34, 38], [39, 41], [42, 45], [46, 48], [49, 50], [51, 56], [57, 58], [58, 62], [62, 63], [63, 64]]}
{"doc_key": "ai-dev-283", "ner": [[12, 13, "algorithm"], [18, 20, "misc"], [25, 26, "metrics"], [29, 31, "algorithm"], [62, 64, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 18, 20, "related-to", "applied_to", false, false], [25, 26, 18, 20, "type-of", "", false, false], [25, 26, 29, 31, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "practice", ",", "machine", "learning", "algorithms", "address", "this", "problem", "by", "employing", "a", "convex", "approximation", "to", "the", "0", "-", "1", "loss", "function", "(", "such", "as", "the", "hinge", "loss", "for", "the", "support", "vector", "machine", ")", ",", "which", "is", "easier", "to", "optimise", ",", "or", "by", "imposing", "assumptions", "on", "the", "mathP", "(", "x", ",", "y", ")", "/", "math", "distribution", "(", "and", "thus", "cease", "to", "be", "result", "agnostic", "learning", "algorithms", ")", "."], "sentence-detokenized": "In practice, machine learning algorithms address this problem by employing a convex approximation to the 0-1 loss function (such as the hinge loss for the support vector machine), which is easier to optimise, or by imposing assumptions on the mathP (x, y) / math distribution (and thus cease to be result agnostic learning algorithms).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 29], [30, 40], [41, 48], [49, 53], [54, 61], [62, 64], [65, 74], [75, 76], [77, 83], [84, 97], [98, 100], [101, 104], [105, 106], [106, 107], [107, 108], [109, 113], [114, 122], [123, 124], [124, 128], [129, 131], [132, 135], [136, 141], [142, 146], [147, 150], [151, 154], [155, 162], [163, 169], [170, 177], [177, 178], [178, 179], [180, 185], [186, 188], [189, 195], [196, 198], [199, 207], [207, 208], [209, 211], [212, 214], [215, 223], [224, 235], [236, 238], [239, 242], [243, 248], [249, 250], [250, 251], [251, 252], [253, 254], [254, 255], [256, 257], [258, 262], [263, 275], [276, 277], [277, 280], [281, 285], [286, 291], [292, 294], [295, 297], [298, 304], [305, 313], [314, 322], [323, 333], [333, 334], [334, 335]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [11, 13, "field"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "usage", "", false, false], [0, 0, 17, 17, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Westworld", "(", "1973", ")", "was", "the", "first", "feature", "film", "to", "use", "digital", "image", "processing", "to", "simulate", "an", "android", "'s", "point", "of", "view", "."], "sentence-detokenized": "Westworld (1973) was the first feature film to use digital image processing to simulate an android's point of view.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 20], [21, 24], [25, 30], [31, 38], [39, 43], [44, 46], [47, 50], [51, 58], [59, 64], [65, 75], [76, 78], [79, 87], [88, 90], [91, 98], [98, 100], [101, 106], [107, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-dev-285", "ner": [[8, 8, "task"], [11, 11, "task"], [13, 13, "task"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "now", "also", "commonly", "used", "in", "speech", "recognition", ",", "speech", "synthesis", ",", "diarising", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "It is now also commonly used in speech recognition, speech synthesis, diarising, Xavier Anguera et al.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 14], [15, 23], [24, 28], [29, 31], [32, 38], [39, 50], [50, 51], [52, 58], [59, 68], [68, 69], [70, 79], [79, 80], [81, 87], [88, 95], [96, 98], [99, 101], [101, 102]]}
{"doc_key": "ai-dev-286", "ner": [[9, 11, "algorithm"], [16, 17, "algorithm"], [20, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 17, 9, 11, "type-of", "", false, false], [20, 22, 9, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Here", ",", "math", "\\", "sigma", "/", "math", "is", "an", "elementary", "activation", "function", ",", "such", "as", "a", "sigmoid", "function", "or", "a", "rectified", "linear", "unit", "."], "sentence-detokenized": "Here, math\\ sigma / math is an elementary activation function, such as a sigmoid function or a rectified linear unit.", "token2charspan": [[0, 4], [4, 5], [6, 10], [10, 11], [12, 17], [18, 19], [20, 24], [25, 27], [28, 30], [31, 41], [42, 52], [53, 61], [61, 62], [63, 67], [68, 70], [71, 72], [73, 80], [81, 89], [90, 92], [93, 94], [95, 104], [105, 111], [112, 116], [116, 117]]}
{"doc_key": "ai-dev-287", "ner": [[8, 14, "algorithm"], [23, 23, "misc"], [25, 25, "misc"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "phonetic", "-", "based", "approaches", "(", "i.e.", "all", "models", "based", "on", "the", "Hidden", "Markov", "model", ")", "require", "separate", "components", "and", "training", "for", "the", "pronunciation", ",", "acoustic", "and", "language", "model", "."], "sentence-detokenized": "Traditional phonetic-based approaches (i.e. all models based on the Hidden Markov model) require separate components and training for the pronunciation, acoustic and language model.", "token2charspan": [[0, 11], [12, 20], [20, 21], [21, 26], [27, 37], [38, 39], [39, 43], [44, 47], [48, 54], [55, 60], [61, 63], [64, 67], [68, 74], [75, 81], [82, 87], [87, 88], [89, 96], [97, 105], [106, 116], [117, 120], [121, 129], [130, 133], [134, 137], [138, 151], [151, 152], [153, 161], [162, 165], [166, 174], [175, 180], [180, 181]]}
{"doc_key": "ai-dev-288", "ner": [[1, 3, "algorithm"], [7, 8, "field"], [10, 11, "field"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 13, 14, "related-to", "used_for", false, false], [7, 8, 1, 3, "usage", "", false, false], [10, 11, 1, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Roberts", "cross", "operator", "is", "used", "in", "image", "processing", "and", "computer", "vision", "for", "edge", "detection", "."], "sentence-detokenized": "The Roberts cross operator is used in image processing and computer vision for edge detection.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 37], [38, 43], [44, 54], [55, 58], [59, 67], [68, 74], [75, 78], [79, 83], [84, 93], [93, 94]]}
{"doc_key": "ai-dev-289", "ner": [[0, 0, "metrics"], [2, 2, "metrics"], [24, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 24, 24, "opposite", "", false, false], [2, 2, 24, 24, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Sensitivity", "and", "specificity", "values", "do", "not", "depend", "on", "the", "percentage", "of", "positive", "cases", "in", "the", "population", "of", "interest", "(", "unlike", ",", "for", "example", ",", "precision", ")", "."], "sentence-detokenized": "Sensitivity and specificity values do not depend on the percentage of positive cases in the population of interest (unlike, for example, precision).", "token2charspan": [[0, 11], [12, 15], [16, 27], [28, 34], [35, 37], [38, 41], [42, 48], [49, 51], [52, 55], [56, 66], [67, 69], [70, 78], [79, 84], [85, 87], [88, 91], [92, 102], [103, 105], [106, 114], [115, 116], [116, 122], [122, 123], [124, 127], [128, 135], [135, 136], [137, 146], [146, 147], [147, 148]]}
{"doc_key": "ai-dev-290", "ner": [[1, 2, "algorithm"], [10, 10, "misc"], [12, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 1, 2, "topic", "", false, false], [10, 10, 12, 13, "artifact", "", false, false], [10, 10, 15, 16, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["But", "perceptron", "models", "were", "made", "very", "unpopular", "by", "the", "book", "Perceptrons", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", ",", "published", "in", "1969", "."], "sentence-detokenized": "But perceptron models were made very unpopular by the book Perceptrons by Marvin Minsky and Seymour Papert, published in 1969.", "token2charspan": [[0, 3], [4, 14], [15, 21], [22, 26], [27, 31], [32, 36], [37, 46], [47, 49], [50, 53], [54, 58], [59, 70], [71, 73], [74, 80], [81, 87], [88, 91], [92, 99], [100, 106], [106, 107], [108, 117], [118, 120], [121, 125], [125, 126]]}
{"doc_key": "ai-dev-291", "ner": [[1, 3, "conference"], [8, 8, "organisation"], [22, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 3, 22, 24, "topic", "", false, false], [8, 8, 1, 3, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Document", "Understanding", "Conferences", ",", "conducted", "annually", "by", "NIST", ",", "have", "developed", "sophisticated", "evaluation", "criteria", "for", "techniques", "that", "accept", "the", "challenge", "of", "synthesising", "multiple", "documents", "."], "sentence-detokenized": "The Document Understanding Conferences, conducted annually by NIST, have developed sophisticated evaluation criteria for techniques that accept the challenge of synthesising multiple documents.", "token2charspan": [[0, 3], [4, 12], [13, 26], [27, 38], [38, 39], [40, 49], [50, 58], [59, 61], [62, 66], [66, 67], [68, 72], [73, 82], [83, 96], [97, 107], [108, 116], [117, 120], [121, 131], [132, 136], [137, 143], [144, 147], [148, 157], [158, 160], [161, 173], [174, 182], [183, 192], [192, 193]]}
{"doc_key": "ai-dev-292", "ner": [[1, 2, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 26, 27, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "parallel", "manipulator", "is", "designed", "so", "that", "each", "chain", "is", "usually", "short", ",", "simple", "and", "can", "therefore", "be", "rigid", "against", "unwanted", "movements", ",", "compared", "to", "a", "serial", "manipulator", "."], "sentence-detokenized": "A parallel manipulator is designed so that each chain is usually short, simple and can therefore be rigid against unwanted movements, compared to a serial manipulator.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 34], [35, 37], [38, 42], [43, 47], [48, 53], [54, 56], [57, 64], [65, 70], [70, 71], [72, 78], [79, 82], [83, 86], [87, 96], [97, 99], [100, 105], [106, 113], [114, 122], [123, 132], [132, 133], [134, 142], [143, 145], [146, 147], [148, 154], [155, 166], [166, 167]]}
{"doc_key": "ai-dev-293", "ner": [[24, 24, "misc"], [26, 28, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "manipulator", "is", "what", "makes", "the", "robot", "move", "and", "the", "design", "of", "these", "systems", "can", "be", "divided", "into", "several", "common", "types", ",", "such", "as", "SCARA", "and", "Cartesian", "co-ordinate", "robots", ",", "which", "use", "different", "co-ordinate", "systems", "to", "direct", "the", "arms", "of", "the", "machine", "."], "sentence-detokenized": "The manipulator is what makes the robot move and the design of these systems can be divided into several common types, such as SCARA and Cartesian co-ordinate robots, which use different co-ordinate systems to direct the arms of the machine.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 23], [24, 29], [30, 33], [34, 39], [40, 44], [45, 48], [49, 52], [53, 59], [60, 62], [63, 68], [69, 76], [77, 80], [81, 83], [84, 91], [92, 96], [97, 104], [105, 111], [112, 117], [117, 118], [119, 123], [124, 126], [127, 132], [133, 136], [137, 146], [147, 158], [159, 165], [165, 166], [167, 172], [173, 176], [177, 186], [187, 198], [199, 206], [207, 209], [210, 216], [217, 220], [221, 225], [226, 228], [229, 232], [233, 240], [240, 241]]}
{"doc_key": "ai-dev-294", "ner": [[2, 3, "country"], [11, 12, "organisation"], [13, 24, "organisation"], [25, 28, "organisation"], [31, 33, "organisation"], [36, 42, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 12, 2, 3, "physical", "", false, false], [13, 24, 2, 3, "physical", "", false, false], [25, 28, 2, 3, "physical", "", false, false], [31, 33, 2, 3, "physical", "", false, false], [36, 42, 2, 3, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "United", "States", ",", "he", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "Linguistic", "Society", "of", "America", ",", "the", "American", "Philosophical", "Association", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In the United States, he is a member of the National Academy of Sciences, the American Academy of Arts and Sciences, the Linguistic Society of America, the American Philosophical Association and the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 20], [20, 21], [22, 24], [25, 27], [28, 29], [30, 36], [37, 39], [40, 43], [44, 52], [53, 60], [61, 63], [64, 72], [72, 73], [74, 77], [78, 86], [87, 94], [95, 97], [98, 102], [103, 106], [107, 115], [115, 116], [117, 120], [121, 131], [132, 139], [140, 142], [143, 150], [150, 151], [152, 155], [156, 164], [165, 178], [179, 190], [191, 194], [195, 198], [199, 207], [208, 219], [220, 223], [224, 227], [228, 239], [240, 242], [243, 250], [250, 251]]}
{"doc_key": "ai-dev-295", "ner": [[9, 11, "algorithm"], [13, 13, "algorithm"], [24, 25, "algorithm"], [28, 29, "algorithm"], [34, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 11, 24, 25, "named", "", false, false], [13, 13, 9, 11, "named", "", false, false], [24, 25, 28, 29, "compare", "", false, false], [24, 25, 34, 35, "related-to", "performs", false, false], [28, 29, 34, 35, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["They", "rose", "to", "prominence", "with", "the", "popularity", "of", "the", "support", "vector", "machine", "(", "SVM", ")", "in", "the", "1990s", ",", "when", "it", "was", "discovered", "that", "SVM", "was", "competitive", "with", "neural", "networks", "in", "tasks", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "They rose to prominence with the popularity of the support vector machine (SVM) in the 1990s, when it was discovered that SVM was competitive with neural networks in tasks such as handwriting recognition.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 23], [24, 28], [29, 32], [33, 43], [44, 46], [47, 50], [51, 58], [59, 65], [66, 73], [74, 75], [75, 78], [78, 79], [80, 82], [83, 86], [87, 92], [92, 93], [94, 98], [99, 101], [102, 105], [106, 116], [117, 121], [122, 125], [126, 129], [130, 141], [142, 146], [147, 153], [154, 162], [163, 165], [166, 171], [172, 176], [177, 179], [180, 191], [192, 203], [203, 204]]}
{"doc_key": "ai-dev-296", "ner": [[3, 3, "misc"], [9, 9, "misc"], [15, 16, "algorithm"], [24, 25, "misc"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 9, 9, "usage", "", false, false], [3, 3, 24, 25, "usage", "", false, false], [9, 9, 15, 16, "origin", "result_of_algorithm", false, false], [24, 25, 31, 32, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["An", "empirical", "whitening", "transform", "is", "obtained", "by", "estimating", "the", "covariance", "(", "e.g.", "by", "means", "of", "maximum", "likelihood", ")", "and", "then", "constructing", "a", "corresponding", "estimated", "whitening", "matrix", "(", "e.g.", "by", "means", "of", "Cholesky", "decomposition", ")", "."], "sentence-detokenized": "An empirical whitening transform is obtained by estimating the covariance (e.g. by means of maximum likelihood) and then constructing a corresponding estimated whitening matrix (e.g. by means of Cholesky decomposition).", "token2charspan": [[0, 2], [3, 12], [13, 22], [23, 32], [33, 35], [36, 44], [45, 47], [48, 58], [59, 62], [63, 73], [74, 75], [75, 79], [80, 82], [83, 88], [89, 91], [92, 99], [100, 110], [110, 111], [112, 115], [116, 120], [121, 133], [134, 135], [136, 149], [150, 159], [160, 169], [170, 176], [177, 178], [178, 182], [183, 185], [186, 191], [192, 194], [195, 203], [204, 217], [217, 218], [218, 219]]}
{"doc_key": "ai-dev-297", "ner": [[0, 2, "organisation"], [8, 10, "product"], [23, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 0, 2, "artifact", "", false, false], [23, 24, 0, 2, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "is", "the", "world", "'s", "largest", "manufacturer", "of", "Cartesian", "coordinate", "robots", "and", "an", "established", "leader", "in", "low", "-", "cost", ",", "high", "-", "performance", "SCARA", "robots", "."], "sentence-detokenized": "IAI is the world's largest manufacturer of Cartesian coordinate robots and an established leader in low-cost, high-performance SCARA robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [16, 18], [19, 26], [27, 39], [40, 42], [43, 52], [53, 63], [64, 70], [71, 74], [75, 77], [78, 89], [90, 96], [97, 99], [100, 103], [103, 104], [104, 108], [108, 109], [110, 114], [114, 115], [115, 126], [127, 132], [133, 139], [139, 140]]}
{"doc_key": "ai-dev-298", "ner": [[10, 11, "field"], [13, 14, "field"], [16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formal", "concept", "analysis", "finds", "practical", "application", "in", "fields", "such", "as", "data", "mining", ",", "text", "mining", ",", "machine", "learning", ",", "knowledge", "management", ",", "semantic", "web", ",", "software", "development", ",", "chemistry", "and", "biology", "."], "sentence-detokenized": "Formal concept analysis finds practical application in fields such as data mining, text mining, machine learning, knowledge management, semantic web, software development, chemistry and biology.", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 29], [30, 39], [40, 51], [52, 54], [55, 61], [62, 66], [67, 69], [70, 74], [75, 81], [81, 82], [83, 87], [88, 94], [94, 95], [96, 103], [104, 112], [112, 113], [114, 123], [124, 134], [134, 135], [136, 144], [145, 148], [148, 149], [150, 158], [159, 170], [170, 171], [172, 181], [182, 185], [186, 193], [193, 194]]}
{"doc_key": "ai-dev-299", "ner": [[1, 2, "field"], [4, 6, "field"], [10, 11, "field"], [17, 18, "field"], [29, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 17, 18, "part-of", "", false, false], [4, 6, 29, 30, "topic", "", false, false], [10, 11, 4, 6, "named", "", false, false], [17, 18, 1, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", ",", "computational", "learning", "theory", "(", "or", "simply", "learning", "theory", ")", "is", "a", "subfield", "of", "artificial", "intelligence", "dedicated", "to", "the", "study", "of", "the", "design", "and", "analysis", "of", "machine", "learning", "algorithms", "."], "sentence-detokenized": "In computer science, computational learning theory (or simply learning theory) is a subfield of artificial intelligence dedicated to the study of the design and analysis of machine learning algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 34], [35, 43], [44, 50], [51, 52], [52, 54], [55, 61], [62, 70], [71, 77], [77, 78], [79, 81], [82, 83], [84, 92], [93, 95], [96, 106], [107, 119], [120, 129], [130, 132], [133, 136], [137, 142], [143, 145], [146, 149], [150, 156], [157, 160], [161, 169], [170, 172], [173, 180], [181, 189], [190, 200], [200, 201]]}
{"doc_key": "ai-dev-300", "ner": [[0, 1, "algorithm"], [3, 3, "algorithm"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 1, "named", "", false, false], [10, 10, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Collaborative", "filtering", "(", "CF", ")", "is", "a", "technique", "used", "by", "recommendation", "systems", "."], "sentence-detokenized": "Collaborative filtering (CF) is a technique used by recommendation systems.", "token2charspan": [[0, 13], [14, 23], [24, 25], [25, 27], [27, 28], [29, 31], [32, 33], [34, 43], [44, 48], [49, 51], [52, 66], [67, 74], [74, 75]]}
{"doc_key": "ai-dev-301", "ner": [[1, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "FALSE", "positive", "rate", "is", "the", "proportion", "of", "all", "negatives", "that", "still", "produce", "positive", "test", "results", ",", "i.e.", "the", "conditional", "probability", "of", "a", "positive", "test", "result", "given", "an", "event", "that", "was", "not", "present", "."], "sentence-detokenized": "The FALSE positive rate is the proportion of all negatives that still produce positive test results, i.e. the conditional probability of a positive test result given an event that was not present.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 23], [24, 26], [27, 30], [31, 41], [42, 44], [45, 48], [49, 58], [59, 63], [64, 69], [70, 77], [78, 86], [87, 91], [92, 99], [99, 100], [101, 105], [106, 109], [110, 121], [122, 133], [134, 136], [137, 138], [139, 147], [148, 152], [153, 159], [160, 165], [166, 168], [169, 174], [175, 179], [180, 183], [184, 187], [188, 195], [195, 196]]}
{"doc_key": "ai-dev-302", "ner": [[1, 14, "misc"], [37, 37, "metrics"], [42, 42, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 14, 37, 37, "topic", "", false, false], [1, 14, 42, 42, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "VLDB", "'", "8", ":", "Proceedings", "of", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pp.", "422--433", ".", "showed", "that", "the", "values", "given", "for", "mathC", "/", "math", "and", "mathK", "/", "math", "generally", "imply", "a", "relatively", "low", "accuracy", "of", "the", "iteratively", "calculated", "SimRank", "scores", "."], "sentence-detokenized": "In VLDB '8: Proceedings of 34th International Conference on Very Large Data Bases, pp. 422--433. showed that the values given for mathC / math and mathK / math generally imply a relatively low accuracy of the iteratively calculated SimRank scores.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [10, 11], [12, 23], [24, 26], [27, 31], [32, 45], [46, 56], [57, 59], [60, 64], [65, 70], [71, 75], [76, 81], [81, 82], [83, 86], [87, 95], [95, 96], [97, 103], [104, 108], [109, 112], [113, 119], [120, 125], [126, 129], [130, 135], [136, 137], [138, 142], [143, 146], [147, 152], [153, 154], [155, 159], [160, 169], [170, 175], [176, 177], [178, 188], [189, 192], [193, 201], [202, 204], [205, 208], [209, 220], [221, 231], [232, 239], [240, 246], [246, 247]]}
{"doc_key": "ai-dev-303", "ner": [[7, 10, "misc"], [11, 11, "misc"], [18, 18, "person"], [20, 22, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 7, 10, "general-affiliation", "", false, false], [11, 11, 18, 18, "artifact", "", false, false], [11, 11, 20, 22, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["June", "2015", "saw", "the", "debut", "of", "the", "sci", "-", "fi", "drama", "Sense8", ",", "written", "and", "produced", "by", "the", "Wachowskis", "and", "J.", "Michael", "Straczynski", "."], "sentence-detokenized": "June 2015 saw the debut of the sci-fi drama Sense8, written and produced by the Wachowskis and J. Michael Straczynski.", "token2charspan": [[0, 4], [5, 9], [10, 13], [14, 17], [18, 23], [24, 26], [27, 30], [31, 34], [34, 35], [35, 37], [38, 43], [44, 50], [50, 51], [52, 59], [60, 63], [64, 72], [73, 75], [76, 79], [80, 90], [91, 94], [95, 97], [98, 105], [106, 117], [117, 118]]}
{"doc_key": "ai-dev-304", "ner": [[1, 1, "misc"], [6, 8, "product"], [27, 29, "misc"], [37, 37, "country"], [39, 39, "country"], [41, 41, "country"], [43, 43, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 1, 6, 8, "topic", "", false, false], [37, 37, 27, 29, "type-of", "", false, false], [39, 39, 27, 29, "type-of", "", false, false], [41, 41, 27, 29, "type-of", "", false, false], [43, 43, 27, 29, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Although", "Eurotra", "never", "provided", "a", "functioning", "machine", "translation", "system", ",", "the", "project", "had", "a", "far", "-", "reaching", "long", "-", "term", "impact", "on", "the", "nascent", "language", "industries", "in", "European", "Member", "States", ",", "particularly", "in", "the", "southern", "countries", "of", "Greece", ",", "Italy", ",", "Spain", "and", "Portugal", "."], "sentence-detokenized": "Although Eurotra never provided a functioning machine translation system, the project had a far-reaching long-term impact on the nascent language industries in European Member States, particularly in the southern countries of Greece, Italy, Spain and Portugal.", "token2charspan": [[0, 8], [9, 16], [17, 22], [23, 31], [32, 33], [34, 45], [46, 53], [54, 65], [66, 72], [72, 73], [74, 77], [78, 85], [86, 89], [90, 91], [92, 95], [95, 96], [96, 104], [105, 109], [109, 110], [110, 114], [115, 121], [122, 124], [125, 128], [129, 136], [137, 145], [146, 156], [157, 159], [160, 168], [169, 175], [176, 182], [182, 183], [184, 196], [197, 199], [200, 203], [204, 212], [213, 222], [223, 225], [226, 232], [232, 233], [234, 239], [239, 240], [241, 246], [247, 250], [251, 259], [259, 260]]}
{"doc_key": "ai-dev-305", "ner": [[0, 1, "algorithm"], [8, 10, "task"], [18, 20, "task"], [22, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 10, 0, 1, "usage", "", true, false], [18, 20, 8, 10, "named", "", false, false], [22, 22, 18, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "autoencoder", "has", "been", "successfully", "applied", "to", "the", "automatic", "translation", "of", "human", "languages", ",", "usually", "referred", "to", "as", "neural", "machine", "translation", "(", "NMT", ")", "."], "sentence-detokenized": "The autoencoder has been successfully applied to the automatic translation of human languages, usually referred to as neural machine translation (NMT).", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 24], [25, 37], [38, 45], [46, 48], [49, 52], [53, 62], [63, 74], [75, 77], [78, 83], [84, 93], [93, 94], [95, 102], [103, 111], [112, 114], [115, 117], [118, 124], [125, 132], [133, 144], [145, 146], [146, 149], [149, 150], [150, 151]]}
{"doc_key": "ai-dev-306", "ner": [[9, 11, "metrics"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "examples", "of", "probability", "-", "based", "fitness", "functions", "are", "maximum", "likelihood", "estimation", "and", "hinge", "loss", "."], "sentence-detokenized": "Popular examples of probability-based fitness functions are maximum likelihood estimation and hinge loss.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 31], [31, 32], [32, 37], [38, 45], [46, 55], [56, 59], [60, 67], [68, 78], [79, 89], [90, 93], [94, 99], [100, 104], [104, 105]]}
{"doc_key": "ai-dev-307", "ner": [[0, 3, "field"], [12, 15, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 15, 0, 3, "part-of", "", false, false], [17, 18, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "mining", "is", "a", "related", "field", "of", "study", "that", "focuses", "on", "the", "exploratory", "analysis", "of", "data", "through", "unsupervised", "learning", "."], "sentence-detokenized": "Data mining is a related field of study that focuses on the exploratory analysis of data through unsupervised learning.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 33], [34, 39], [40, 44], [45, 52], [53, 55], [56, 59], [60, 71], [72, 80], [81, 83], [84, 88], [89, 96], [97, 109], [110, 118], [118, 119]]}
{"doc_key": "ai-dev-308", "ner": [[0, 1, "algorithm"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 12, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "includes", "techniques", "to", "match", "people", "with", "similar", "interests", "and", "create", "recommendation", "systems", "on", "this", "basis", "."], "sentence-detokenized": "Collaborative filtering includes techniques to match people with similar interests and create recommendation systems on this basis.", "token2charspan": [[0, 13], [14, 23], [24, 32], [33, 43], [44, 46], [47, 52], [53, 59], [60, 64], [65, 72], [73, 82], [83, 86], [87, 93], [94, 108], [109, 116], [117, 119], [120, 124], [125, 130], [130, 131]]}
{"doc_key": "ai-dev-309", "ner": [[3, 8, "algorithm"], [13, 13, "programlang"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 18, 3, 8, "type-of", "", false, false], [16, 18, 13, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "number", "of", "WordNet", "-", "based", "word", "similarity", "algorithms", "are", "implemented", "in", "a", "Perl", "package", "called", "WordNet", ":", "Similarity", "."], "sentence-detokenized": "A number of WordNet-based word similarity algorithms are implemented in a Perl package called WordNet: Similarity.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 19], [19, 20], [20, 25], [26, 30], [31, 41], [42, 52], [53, 56], [57, 68], [69, 71], [72, 73], [74, 78], [79, 86], [87, 93], [94, 101], [101, 102], [103, 113], [113, 114]]}
{"doc_key": "ai-dev-310", "ner": [[5, 5, "conference"], [8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Another", "paper", ",", "presented", "at", "CVPR", "2000", "by", "Erik", "Miller", ",", "Nicholas", "Matsakis", "and", "Paul", "Viola", ",", "will", "also", "be", "discussed", "."], "sentence-detokenized": "Another paper, presented at CVPR 2000 by Erik Miller, Nicholas Matsakis and Paul Viola, will also be discussed.", "token2charspan": [[0, 7], [8, 13], [13, 14], [15, 24], [25, 27], [28, 32], [33, 37], [38, 40], [41, 45], [46, 52], [52, 53], [54, 62], [63, 71], [72, 75], [76, 80], [81, 86], [86, 87], [88, 92], [93, 97], [98, 100], [101, 110], [110, 111]]}
{"doc_key": "ai-dev-311", "ner": [[0, 0, "algorithm"], [7, 8, "misc"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 13, 14, "compare", "", false, false], [13, 14, 7, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["QC", "was", "not", "evaluated", "against", "traditional", "modern", "clustering", "algorithms", ",", "apart", "from", "the", "Jaccard", "index", "."], "sentence-detokenized": "QC was not evaluated against traditional modern clustering algorithms, apart from the Jaccard index.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 20], [21, 28], [29, 40], [41, 47], [48, 58], [59, 69], [69, 70], [71, 76], [77, 81], [82, 85], [86, 93], [94, 99], [99, 100]]}
{"doc_key": "ai-dev-312", "ner": [[2, 5, "misc"], [8, 10, "misc"], [15, 16, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 2, 5, "physical", "", false, false], [8, 10, 15, 16, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "the", "VEX", "World", "Robotics", "Championship", ",", "the", "Parade", "of", "Nations", "is", "held", "in", "the", "Freedom", "Hall", ",", "attended", "by", "hundreds", "of", "students", "from", "over", "30", "countries", "."], "sentence-detokenized": "During the VEX World Robotics Championship, the Parade of Nations is held in the Freedom Hall, attended by hundreds of students from over 30 countries.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 20], [21, 29], [30, 42], [42, 43], [44, 47], [48, 54], [55, 57], [58, 65], [66, 68], [69, 73], [74, 76], [77, 80], [81, 88], [89, 93], [93, 94], [95, 103], [104, 106], [107, 115], [116, 118], [119, 127], [128, 132], [133, 137], [138, 140], [141, 150], [150, 151]]}
{"doc_key": "ai-dev-313", "ner": [[6, 9, "metrics"], [11, 11, "metrics"], [15, 17, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 6, 9, "named", "", false, false], [19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Other", "measures", "of", "accuracy", "are", "the", "Single", "Word", "Error", "Rate", "(", "SWER", ")", "and", "the", "Command", "Success", "Rate", "(", "CSR", ")", "."], "sentence-detokenized": "Other measures of accuracy are the Single Word Error Rate (SWER) and the Command Success Rate (CSR).", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [27, 30], [31, 34], [35, 41], [42, 46], [47, 52], [53, 57], [58, 59], [59, 63], [63, 64], [65, 68], [69, 72], [73, 80], [81, 88], [89, 93], [94, 95], [95, 98], [98, 99], [99, 100]]}
{"doc_key": "ai-dev-314", "ner": [[7, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "presented", "their", "method", "and", "results", "at", "SIGGRAPH", "2000", "."], "sentence-detokenized": "They presented their method and results at SIGGRAPH 2000.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 27], [28, 31], [32, 39], [40, 42], [43, 51], [52, 56], [56, 57]]}
{"doc_key": "ai-dev-315", "ner": [[0, 4, "conference"], [7, 7, "misc"], [9, 13, "misc"], [18, 19, "conference"], [23, 28, "researcher"], [37, 38, "researcher"], [42, 44, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 4, 7, 7, "origin", "", false, false], [7, 7, 18, 19, "physical", "", false, false], [7, 7, 18, 19, "temporal", "", false, false], [7, 7, 23, 28, "origin", "", false, false], [7, 7, 37, 38, "origin", "", false, false], [9, 13, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "KDD", "conference", "grew", "out", "of", "the", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "workshops", "of", "the", "AAAI", "conferences", ",", "initiated", "by", "Gregory", "I", ".", "Piatetsky", "-", "Shapiro", "in", "1989", ",", "1991", "and", "1993", "and", "by", "Usama", "Fayyad", "in", "1994", ".", "Machinery", "|", "ACM", "."], "sentence-detokenized": "The KDD conference grew out of the KDD (Knowledge Discovery and Data Mining) workshops of the AAAI conferences, initiated by Gregory I. Piatetsky-Shapiro in 1989, 1991 and 1993 and by Usama Fayyad in 1994. Machinery | ACM.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 23], [24, 27], [28, 30], [31, 34], [35, 38], [39, 40], [40, 49], [50, 59], [60, 63], [64, 68], [69, 75], [75, 76], [77, 86], [87, 89], [90, 93], [94, 98], [99, 110], [110, 111], [112, 121], [122, 124], [125, 132], [133, 134], [134, 135], [136, 145], [145, 146], [146, 153], [154, 156], [157, 161], [161, 162], [163, 167], [168, 171], [172, 176], [177, 180], [181, 183], [184, 189], [190, 196], [197, 199], [200, 204], [204, 205], [206, 215], [216, 217], [218, 221], [221, 222]]}
{"doc_key": "ai-dev-316", "ner": [[7, 10, "conference"], [12, 12, "conference"], [16, 21, "organisation"], [23, 23, "organisation"], [27, 31, "conference"], [33, 33, "conference"], [37, 43, "conference"], [45, 45, "conference"], [49, 54, "conference"], [56, 56, "conference"], [60, 65, "conference"], [67, 67, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[12, 12, 7, 10, "named", "", false, false], [23, 23, 16, 21, "named", "", false, false], [33, 33, 27, 31, "named", "", false, false], [45, 45, 37, 43, "named", "", false, false], [56, 56, 49, 54, "named", "", false, false], [67, 67, 60, 65, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "is", "an", "elected", "member", "of", "the", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "the", "American", "Association", "for", "Advancement", "of", "Science", "(", "AAAS", ")", "and", "the", "Society", "for", "Optics", "and", "Photonics", "Technology", "(", "SPIE", ")", "."], "sentence-detokenized": "He is an elected member of the Association for Computing Machinery (ACM), the Institute of Electrical and Electronics Engineers (IEEE), the International Association for Pattern Recognition (IAPR), the Association for the Advancement of Artificial Intelligence (AAAI), the American Association for Advancement of Science (AAAS) and the Society for Optics and Photonics Technology (SPIE).", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 16], [17, 23], [24, 26], [27, 30], [31, 42], [43, 46], [47, 56], [57, 66], [67, 68], [68, 71], [71, 72], [72, 73], [74, 77], [78, 87], [88, 90], [91, 101], [102, 105], [106, 117], [118, 127], [128, 129], [129, 133], [133, 134], [134, 135], [136, 139], [140, 153], [154, 165], [166, 169], [170, 177], [178, 189], [190, 191], [191, 195], [195, 196], [196, 197], [198, 201], [202, 213], [214, 217], [218, 221], [222, 233], [234, 236], [237, 247], [248, 260], [261, 262], [262, 266], [266, 267], [267, 268], [269, 272], [273, 281], [282, 293], [294, 297], [298, 309], [310, 312], [313, 320], [321, 322], [322, 326], [326, 327], [328, 331], [332, 335], [336, 343], [344, 347], [348, 354], [355, 358], [359, 368], [369, 379], [380, 381], [381, 385], [385, 386], [386, 387]]}
{"doc_key": "ai-dev-317", "ner": [[0, 1, "field"], [3, 4, "field"], [16, 17, "field"], [31, 32, "field"], [53, 56, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 17, "named", "", false, false], [3, 4, 31, 32, "named", "", false, false], [31, 32, 53, 56, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "and", "data", "mining", "often", "use", "the", "same", "methods", "and", "overlap", "significantly", ",", "but", "whereas", "machine", "learning", "focuses", "on", "prediction", ",", "based", "on", "known", "properties", "learned", "from", "training", "data", ",", "data", "mining", "focuses", "on", "the", "discovery", "of", "(", "previously", ")", "unknown", "properties", "in", "the", "data", "(", "this", "is", "the", "analysis", "phase", "of", "knowledge", "discovery", "in", "databases", ")", "."], "sentence-detokenized": "Machine learning and data mining often use the same methods and overlap significantly, but whereas machine learning focuses on prediction, based on known properties learned from training data, data mining focuses on the discovery of (previously) unknown properties in the data (this is the analysis phase of knowledge discovery in databases).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 59], [60, 63], [64, 71], [72, 85], [85, 86], [87, 90], [91, 98], [99, 106], [107, 115], [116, 123], [124, 126], [127, 137], [137, 138], [139, 144], [145, 147], [148, 153], [154, 164], [165, 172], [173, 177], [178, 186], [187, 191], [191, 192], [193, 197], [198, 204], [205, 212], [213, 215], [216, 219], [220, 229], [230, 232], [233, 234], [234, 244], [244, 245], [246, 253], [254, 264], [265, 267], [268, 271], [272, 276], [277, 278], [278, 282], [283, 285], [286, 289], [290, 298], [299, 304], [305, 307], [308, 317], [318, 327], [328, 330], [331, 340], [340, 341], [341, 342]]}
{"doc_key": "ai-dev-318", "ner": [[0, 1, "product"], [4, 4, "programlang"], [11, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 4, 4, "general-affiliation", "", false, false], [0, 1, 4, 4, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "is", "written", "in", "Java", "and", "thus", "runs", "on", "most", "modern", "operating", "systems", "."], "sentence-detokenized": "Indy is written in Java and thus runs on most modern operating systems.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 23], [24, 27], [28, 32], [33, 37], [38, 40], [41, 45], [46, 52], [53, 62], [63, 70], [70, 71]]}
{"doc_key": "ai-dev-319", "ner": [[0, 3, "algorithm"], [6, 8, "algorithm"], [10, 10, "algorithm"], [16, 18, "algorithm"], [20, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 6, 8, "type-of", "", true, false], [10, 10, 6, 8, "named", "", false, false], [16, 18, 6, 8, "type-of", "", true, false], [20, 20, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "NMF", "is", "an", "instance", "of", "non-negative", "quadratic", "programming", "(", "NQP", ")", ",", "just", "like", "the", "support", "vector", "machine", "(", "SVM", ")", "."], "sentence-detokenized": "The NMF is an instance of non-negative quadratic programming (NQP), just like the support vector machine (SVM).", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 13], [14, 22], [23, 25], [26, 38], [39, 48], [49, 60], [61, 62], [62, 65], [65, 66], [66, 67], [68, 72], [73, 77], [78, 81], [82, 89], [90, 96], [97, 104], [105, 106], [106, 109], [109, 110], [110, 111]]}
{"doc_key": "ai-dev-320", "ner": [[8, 9, "misc"], [12, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 12, 14, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "method", "is", "based", "on", "the", "estimation", "of", "conditional", "probabilities", "using", "the", "non-parametric", "maximum", "likelihood", "method", "leading", "to"], "sentence-detokenized": "The method is based on the estimation of conditional probabilities using the non-parametric maximum likelihood method leading to", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 26], [27, 37], [38, 40], [41, 52], [53, 66], [67, 72], [73, 76], [77, 91], [92, 99], [100, 110], [111, 117], [118, 125], [126, 128]]}
{"doc_key": "ai-dev-321", "ner": [[7, 7, "algorithm"], [9, 12, "algorithm"], [14, 16, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "basic", "concepts", "of", "spectral", "estimation", "include", "autocorrelation", ",", "multi", "-D", "Fourier", "transform", ",", "mean", "square", "error", "and", "entropy", "."], "sentence-detokenized": "The basic concepts of spectral estimation include autocorrelation, multi-D Fourier transform, mean square error and entropy.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 21], [22, 30], [31, 41], [42, 49], [50, 65], [65, 66], [67, 72], [72, 74], [75, 82], [83, 92], [92, 93], [94, 98], [99, 105], [106, 111], [112, 115], [116, 123], [123, 124]]}
{"doc_key": "ai-dev-322", "ner": [[4, 6, "algorithm"], [10, 10, "field"], [12, 12, "algorithm"], [14, 16, "algorithm"], [18, 19, "task"], [21, 23, "field"], [25, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7, 8], "relations": [[4, 6, 10, 10, "part-of", "", false, false], [4, 6, 12, 12, "part-of", "", false, false], [4, 6, 14, 16, "part-of", "", false, false], [4, 6, 18, 19, "part-of", "", false, false], [4, 6, 21, 23, "part-of", "", false, false], [4, 6, 25, 26, "part-of", "", false, false], [4, 6, 28, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6, 7], "sentence": ["The", "application", "areas", "of", "kernel", "methods", "are", "diverse", "and", "include", "geostatistics", ",", "kriging", ",", "inverse", "distance", "weighting", ",", "3D", "reconstruction", ",", "bioinformatics", ",", "chemoinformatics", ",", "information", "extraction", "and", "handwriting", "recognition", "."], "sentence-detokenized": "The application areas of kernel methods are diverse and include geostatistics, kriging, inverse distance weighting, 3D reconstruction, bioinformatics, chemoinformatics, information extraction and handwriting recognition.", "token2charspan": [[0, 3], [4, 15], [16, 21], [22, 24], [25, 31], [32, 39], [40, 43], [44, 51], [52, 55], [56, 63], [64, 77], [77, 78], [79, 86], [86, 87], [88, 95], [96, 104], [105, 114], [114, 115], [116, 118], [119, 133], [133, 134], [135, 149], [149, 150], [151, 167], [167, 168], [169, 180], [181, 191], [192, 195], [196, 207], [208, 219], [219, 220]]}
{"doc_key": "ai-dev-323", "ner": [[12, 12, "organisation"], [16, 20, "product"], [14, 14, "product"], [27, 27, "organisation"], [28, 31, "product"], [25, 25, "product"], [34, 35, "product"], [37, 39, "product"], [41, 43, "product"], [45, 47, "product"], [51, 52, "product"], [54, 55, "product"], [58, 64, "product"], [67, 69, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[16, 20, 12, 12, "artifact", "", false, false], [16, 20, 34, 35, "compare", "", false, false], [16, 20, 37, 39, "compare", "", false, false], [16, 20, 41, 43, "compare", "", false, false], [16, 20, 45, 47, "compare", "", false, false], [16, 20, 51, 52, "compare", "", false, false], [16, 20, 54, 55, "compare", "", false, false], [16, 20, 58, 64, "compare", "", false, false], [16, 20, 67, 69, "compare", "", false, false], [14, 14, 16, 20, "named", "", false, false], [28, 31, 27, 27, "artifact", "", false, false], [28, 31, 34, 35, "compare", "", false, false], [28, 31, 37, 39, "compare", "", false, false], [28, 31, 41, 43, "compare", "", false, false], [28, 31, 45, 47, "compare", "", false, false], [28, 31, 51, 52, "compare", "", false, false], [28, 31, 54, 55, "compare", "", false, false], [28, 31, 58, 64, "compare", "", false, false], [28, 31, 67, 69, "compare", "", false, false], [25, 25, 28, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Robots", "can", "be", "autonomous", "or", "semi-autonomous", "and", "range", "from", "humanoids", "such", "as", "Honda", "'s", "ASIMO", "(", "Advanced", "Step", "in", "Innovative", "Mobility", ")", "and", "TOSY", "'s", "TOPIO", "(", "TOSY", "Ping", "Pong", "Playing", "Robot", ")", "to", "industrial", "robots", ",", "medical", "robot", "operators", ",", "patient", "care", "robots", ",", "dog", "therapy", "robots", ",", "collectively", "programmed", "robot", "swarms", ",", "UAV", "drones", "such", "as", "General", "Atomics", "'", "MQ", "-", "1", "Predator", "and", "even", "microscopic", "nano", "robots", "."], "sentence-detokenized": "Robots can be autonomous or semi-autonomous and range from humanoids such as Honda's ASIMO (Advanced Step in Innovative Mobility) and TOSY's TOPIO (TOSY Ping Pong Playing Robot) to industrial robots, medical robot operators, patient care robots, dog therapy robots, collectively programmed robot swarms, UAV drones such as General Atomics' MQ-1 Predator and even microscopic nano robots.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 24], [25, 27], [28, 43], [44, 47], [48, 53], [54, 58], [59, 68], [69, 73], [74, 76], [77, 82], [82, 84], [85, 90], [91, 92], [92, 100], [101, 105], [106, 108], [109, 119], [120, 128], [128, 129], [130, 133], [134, 138], [138, 140], [141, 146], [147, 148], [148, 152], [153, 157], [158, 162], [163, 170], [171, 176], [176, 177], [178, 180], [181, 191], [192, 198], [198, 199], [200, 207], [208, 213], [214, 223], [223, 224], [225, 232], [233, 237], [238, 244], [244, 245], [246, 249], [250, 257], [258, 264], [264, 265], [266, 278], [279, 289], [290, 295], [296, 302], [302, 303], [304, 307], [308, 314], [315, 319], [320, 322], [323, 330], [331, 338], [338, 339], [340, 342], [342, 343], [343, 344], [345, 353], [354, 357], [358, 362], [363, 374], [375, 379], [380, 386], [386, 387]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 3, "product"], [9, 16, "university"], [18, 19, "researcher"], [21, 22, "researcher"], [24, 25, "researcher"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 18, 19, "artifact", "", false, false], [0, 0, 21, 22, "artifact", "", false, false], [0, 0, 24, 25, "artifact", "", false, false], [0, 0, 27, 28, "artifact", "", false, false], [2, 3, 18, 19, "artifact", "", false, false], [2, 3, 21, 22, "artifact", "", false, false], [2, 3, 24, 25, "artifact", "", false, false], [2, 3, 27, 28, "artifact", "", false, false], [18, 19, 9, 16, "physical", "", false, false], [21, 22, 9, 16, "physical", "", false, false], [24, 25, 9, 16, "physical", "", false, false], [27, 28, 9, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "and", "Freddy", "II", "were", "robots", "built", "at", "the", "University", "of", "Edinburgh", "'s", "School", "of", "Computer", "Science", "by", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "and", "Donald", "Mitchie", ",", "and", "were", "able", "to", "assemble", "wooden", "blocks", "in", "a", "period", "of", "several", "hours", "."], "sentence-detokenized": "Freddy and Freddy II were robots built at the University of Edinburgh's School of Computer Science by Pat Ambler, Robin Popplestone, Austin Tate and Donald Mitchie, and were able to assemble wooden blocks in a period of several hours.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 25], [26, 32], [33, 38], [39, 41], [42, 45], [46, 56], [57, 59], [60, 69], [69, 71], [72, 78], [79, 81], [82, 90], [91, 98], [99, 101], [102, 105], [106, 112], [112, 113], [114, 119], [120, 131], [131, 132], [133, 139], [140, 144], [145, 148], [149, 155], [156, 163], [163, 164], [165, 168], [169, 173], [174, 178], [179, 181], [182, 190], [191, 197], [198, 204], [205, 207], [208, 209], [210, 216], [217, 219], [220, 227], [228, 233], [233, 234]]}
{"doc_key": "ai-dev-325", "ner": [[6, 6, "location"], [8, 8, "country"], [16, 16, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 8, 8, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "spent", "his", "childhood", "years", "in", "Paris", ",", "France", ",", "where", "his", "parents", "had", "emigrated", "from", "Lithuania", "in", "the", "early", "1920s", "."], "sentence-detokenized": "He spent his childhood years in Paris, France, where his parents had emigrated from Lithuania in the early 1920s.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 22], [23, 28], [29, 31], [32, 37], [37, 38], [39, 45], [45, 46], [47, 52], [53, 56], [57, 64], [65, 68], [69, 78], [79, 83], [84, 93], [94, 96], [97, 100], [101, 106], [107, 112], [112, 113]]}
{"doc_key": "ai-dev-326", "ner": [[2, 3, "researcher"], [6, 9, "misc"], [15, 18, "organisation"], [11, 13, "university"], [27, 31, "university"], [37, 38, "university"], [41, 43, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 3, 6, 9, "role", "", false, false], [2, 3, 11, 13, "physical", "", false, false], [2, 3, 27, 31, "role", "", false, false], [2, 3, 37, 38, "role", "", false, false], [2, 3, 41, 43, "role", "", false, false], [6, 9, 15, 18, "part-of", "", false, false], [15, 18, 11, 13, "part-of", "", false, false], [37, 38, 27, 31, "part-of", "", false, false], [41, 43, 27, 31, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Previously", ",", "Dr.", "Paulos", "held", "the", "Cooper-", "Siegel", "associate", "professorship", "at", "Carnegie", "Mellon", "University", "'s", "School", "of", "Computer", "Science", ",", "where", "he", "was", "a", "lecturer", "in", "the", "Human", "-", "Computer", "Interaction", "Institute", "with", "courtesy", "appointments", "at", "the", "Robotics", "Institute", "and", "the", "Entertainment", "Technology", "Center", "."], "sentence-detokenized": "Previously, Dr. Paulos held the Cooper-Siegel associate professorship at Carnegie Mellon University's School of Computer Science, where he was a lecturer in the Human-Computer Interaction Institute with courtesy appointments at the Robotics Institute and the Entertainment Technology Center.", "token2charspan": [[0, 10], [10, 11], [12, 15], [16, 22], [23, 27], [28, 31], [32, 39], [39, 45], [46, 55], [56, 69], [70, 72], [73, 81], [82, 88], [89, 99], [99, 101], [102, 108], [109, 111], [112, 120], [121, 128], [128, 129], [130, 135], [136, 138], [139, 142], [143, 144], [145, 153], [154, 156], [157, 160], [161, 166], [166, 167], [167, 175], [176, 187], [188, 197], [198, 202], [203, 211], [212, 224], [225, 227], [228, 231], [232, 240], [241, 250], [251, 254], [255, 258], [259, 272], [273, 283], [284, 290], [290, 291]]}
{"doc_key": "ai-dev-327", "ner": [[3, 4, "researcher"], [7, 7, "university"], [6, 11, "product"], [14, 22, "product"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 7, 7, "physical", "", false, false], [3, 4, 7, 7, "role", "", false, false], [6, 11, 3, 4, "artifact", "", false, false], [6, 11, 14, 22, "type-of", "", false, false], [6, 11, 27, 28, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1969", ",", "Victor", "Scheinman", "of", "Stanford", "University", "invented", "the", "Stanford", "Arm", ",", "a", "6", "-", "axis", ",", "fully", "electric", ",", "articulated", "robot", "designed", "to", "enable", "an", "arm", "solution", "."], "sentence-detokenized": "In 1969, Victor Scheinman of Stanford University invented the Stanford Arm, a 6-axis, fully electric, articulated robot designed to enable an arm solution.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 25], [26, 28], [29, 37], [38, 48], [49, 57], [58, 61], [62, 70], [71, 74], [74, 75], [76, 77], [78, 79], [79, 80], [80, 84], [84, 85], [86, 91], [92, 100], [100, 101], [102, 113], [114, 119], [120, 128], [129, 131], [132, 138], [139, 141], [142, 145], [146, 154], [154, 155]]}
{"doc_key": "ai-dev-328", "ner": [[5, 5, "product"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 15, 16, "related-to", "", false, false], [5, 5, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "creation", "and", "implementation", "of", "chatbots", "is", "still", "a", "developing", "area", ",", "strongly", "linked", "to", "artificial", "intelligence", "and", "machine", "learning", ",", "so", "that", "the", "solutions", "provided", ",", "while", "having", "clear", "advantages", ",", "have", "some", "important", "limitations", "in", "terms", "of", "functionality", "and", "use", "cases", "."], "sentence-detokenized": "The creation and implementation of chatbots is still a developing area, strongly linked to artificial intelligence and machine learning, so that the solutions provided, while having clear advantages, have some important limitations in terms of functionality and use cases.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 31], [32, 34], [35, 43], [44, 46], [47, 52], [53, 54], [55, 65], [66, 70], [70, 71], [72, 80], [81, 87], [88, 90], [91, 101], [102, 114], [115, 118], [119, 126], [127, 135], [135, 136], [137, 139], [140, 144], [145, 148], [149, 158], [159, 167], [167, 168], [169, 174], [175, 181], [182, 187], [188, 198], [198, 199], [200, 204], [205, 209], [210, 219], [220, 231], [232, 234], [235, 240], [241, 243], [244, 257], [258, 261], [262, 265], [266, 271], [271, 272]]}
{"doc_key": "ai-dev-329", "ner": [[7, 9, "university"], [11, 12, "product"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 7, 9, "part-of", "", true, false], [20, 21, 11, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "terms", "of", "freely", "available", "resources", ",", "Carnegie", "Mellon", "University", "'s", "Sphinx", "toolkit", "is", "a", "starting", "point", "for", "learning", "about", "speech", "recognition", "and", "beginning", "to", "experiment", "."], "sentence-detokenized": "In terms of freely available resources, Carnegie Mellon University's Sphinx toolkit is a starting point for learning about speech recognition and beginning to experiment.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 18], [19, 28], [29, 38], [38, 39], [40, 48], [49, 55], [56, 66], [66, 68], [69, 75], [76, 83], [84, 86], [87, 88], [89, 97], [98, 103], [104, 107], [108, 116], [117, 122], [123, 129], [130, 141], [142, 145], [146, 155], [156, 158], [159, 169], [169, 170]]}
{"doc_key": "ai-dev-330", "ner": [[2, 4, "misc"], [13, 22, "misc"], [19, 19, "misc"], [25, 25, "university"], [27, 27, "location"], [29, 29, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 4, 13, 22, "temporal", "", false, false], [19, 19, 13, 22, "named", "", false, false], [19, 19, 27, 27, "physical", "", false, false], [25, 25, 19, 19, "role", "", false, false], [27, 27, 29, 29, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "formal", "RoboCup", "competition", "was", "preceded", "by", "the", "(", "often", "misunderstood", ")", "first", "international", "Micro", "Robot", "World", "Cup", "(", "MIROSOT", ")", "football", "tournament", "held", "by", "KAIST", "in", "Taejon", ",", "Korea", ",", "in", "November", "1996", "."], "sentence-detokenized": "The formal RoboCup competition was preceded by the (often misunderstood) first international Micro Robot World Cup (MIROSOT) football tournament held by KAIST in Taejon, Korea, in November 1996.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 30], [31, 34], [35, 43], [44, 46], [47, 50], [51, 52], [52, 57], [58, 71], [71, 72], [73, 78], [79, 92], [93, 98], [99, 104], [105, 110], [111, 114], [115, 116], [116, 123], [123, 124], [125, 133], [134, 144], [145, 149], [150, 152], [153, 158], [159, 161], [162, 168], [168, 169], [170, 175], [175, 176], [177, 179], [180, 188], [189, 193], [193, 194]]}
{"doc_key": "ai-dev-331", "ner": [[6, 7, "metrics"], [24, 27, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "standard", "maths", "hinge", "loss", "(", "1-", "yf", "(", "x", ")", ")", "_", "+", "/", "for", "labelled", "data", ",", "a", "math", "loss", "function", "is", "introduced", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "maths", "is", "introduced", "for", "unlabelled", "data", "by", "letting", "mathy", "=", "operator", "name", "{", "sign", "}", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "In addition to the standard maths hinge loss (1-yf (x)) _ + / for labelled data, a math loss function is introduced (-1 | f (x) |) _ + / maths is introduced for unlabelled data by letting mathy = operator name {sign} {f (x)} / math.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 27], [28, 33], [34, 39], [40, 44], [45, 46], [46, 48], [48, 50], [51, 52], [52, 53], [53, 54], [54, 55], [56, 57], [58, 59], [60, 61], [62, 65], [66, 74], [75, 79], [79, 80], [81, 82], [83, 87], [88, 92], [93, 101], [102, 104], [105, 115], [116, 117], [117, 118], [118, 119], [120, 121], [122, 123], [124, 125], [125, 126], [126, 127], [128, 129], [129, 130], [131, 132], [133, 134], [135, 136], [137, 142], [143, 145], [146, 156], [157, 160], [161, 171], [172, 176], [177, 179], [180, 187], [188, 193], [194, 195], [196, 204], [205, 209], [210, 211], [211, 215], [215, 216], [217, 218], [218, 219], [220, 221], [221, 222], [222, 223], [223, 224], [225, 226], [227, 231], [231, 232]]}
{"doc_key": "ai-dev-332", "ner": [[3, 3, "misc"], [9, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 9, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "particular", ",", "RLS", "is", "designed", "to", "minimise", "the", "mean", "square", "error", "between", "predicted", "values", "and", "TRUE", "labels", ",", "subject", "to", "regularisation", "."], "sentence-detokenized": "In particular, RLS is designed to minimise the mean square error between predicted values and TRUE labels, subject to regularisation.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 21], [22, 30], [31, 33], [34, 42], [43, 46], [47, 51], [52, 58], [59, 64], [65, 72], [73, 82], [83, 89], [90, 93], [94, 98], [99, 105], [105, 106], [107, 114], [115, 117], [118, 132], [132, 133]]}
{"doc_key": "ai-dev-333", "ner": [[5, 7, "algorithm"], [10, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 10, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "essence", ",", "it", "combines", "maximum", "likelihood", "estimation", "with", "a", "regularisation", "procedure", "that", "favours", "simpler", "models", "over", "more", "complex", "ones", "."], "sentence-detokenized": "In essence, it combines maximum likelihood estimation with a regularisation procedure that favours simpler models over more complex ones.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 14], [15, 23], [24, 31], [32, 42], [43, 53], [54, 58], [59, 60], [61, 75], [76, 85], [86, 90], [91, 98], [99, 106], [107, 113], [114, 118], [119, 123], [124, 131], [132, 136], [136, 137]]}
{"doc_key": "ai-dev-334", "ner": [[1, 3, "metrics"], [9, 9, "metrics"], [11, 11, "metrics"], [13, 15, "misc"], [17, 18, "misc"], [31, 34, "algorithm"], [36, 41, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 9, 1, 3, "named", "", false, false], [11, 11, 1, 3, "named", "", false, false], [13, 15, 17, 18, "related-to", "", false, false], [13, 15, 31, 34, "related-to", "ratio", false, false], [31, 34, 36, 41, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "true", "positive", "rate", "is", "also", "known", "as", "the", "sensitivity", ",", "recall", "or", "probability", "of", "detection", "versus", "discrimination", "threshold", ")", "of", "the", "probability", "of", "detection", "on", "the", "y", "-axis", "versus", "the", "cumulative", "distribution", "function", "of", "the", "probability", "of", "false", "alarm", "on", "the", "x-", "axis", "."], "sentence-detokenized": "The true positive rate is also known as the sensitivity, recall or probability of detection versus discrimination threshold) of the probability of detection on the y-axis versus the cumulative distribution function of the probability of false alarm on the x-axis.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 25], [26, 30], [31, 36], [37, 39], [40, 43], [44, 55], [55, 56], [57, 63], [64, 66], [67, 78], [79, 81], [82, 91], [92, 98], [99, 113], [114, 123], [123, 124], [125, 127], [128, 131], [132, 143], [144, 146], [147, 156], [157, 159], [160, 163], [164, 165], [165, 170], [171, 177], [178, 181], [182, 192], [193, 205], [206, 214], [215, 217], [218, 221], [222, 233], [234, 236], [237, 242], [243, 248], [249, 251], [252, 255], [256, 258], [258, 262], [262, 263]]}
{"doc_key": "ai-dev-335", "ner": [[1, 1, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "English", ",", "Word", "Net", "is", "an", "example", "of", "a", "semantic", "network", "."], "sentence-detokenized": "In English, WordNet is an example of a semantic network.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [16, 19], [20, 22], [23, 25], [26, 33], [34, 36], [37, 38], [39, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-dev-336", "ner": [[3, 5, "product"], [9, 10, "product"], [23, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 3, 5, "usage", "", false, false], [23, 24, 9, 10, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolonged", "use", "of", "speech", "recognition", "software", "in", "combination", "with", "word", "processors", "has", "shown", "benefits", "for", "short", "-", "term", "memory", "enhancement", "in", "patients", "with", "cerebral", "AVM", "treated", "with", "resection", "."], "sentence-detokenized": "Prolonged use of speech recognition software in combination with word processors has shown benefits for short-term memory enhancement in patients with cerebral AVM treated with resection.", "token2charspan": [[0, 9], [10, 13], [14, 16], [17, 23], [24, 35], [36, 44], [45, 47], [48, 59], [60, 64], [65, 69], [70, 80], [81, 84], [85, 90], [91, 99], [100, 103], [104, 109], [109, 110], [110, 114], [115, 121], [122, 133], [134, 136], [137, 145], [146, 150], [151, 159], [160, 163], [164, 171], [172, 176], [177, 186], [186, 187]]}
{"doc_key": "ai-dev-337", "ner": [[8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Its", "founding", "editors", "-", "in", "-", "chief", "were", "Ron", "Sun", ",", "Vasant", "Honavar", "and", "Gregg", "Oden", "(", "1999", "to", "2014", ")", "."], "sentence-detokenized": "Its founding editors-in-chief were Ron Sun, Vasant Honavar and Gregg Oden (1999 to 2014).", "token2charspan": [[0, 3], [4, 12], [13, 20], [20, 21], [21, 23], [23, 24], [24, 29], [30, 34], [35, 38], [39, 42], [42, 43], [44, 50], [51, 58], [59, 62], [63, 68], [69, 73], [74, 75], [75, 79], [80, 82], [83, 87], [87, 88], [88, 89]]}
{"doc_key": "ai-dev-338", "ner": [[7, 8, "product"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 12, 13, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Their", "'", "parallel", "'", "distinction", "from", "a", "serial", "manipulator", "is", "that", "the", "end", "effector", "(", "or", "'", "hand", "'", ")", "of", "this", "link", "(", "or", "'", "arm", "'", ")", "is", "directly", "connected", "to", "its", "base", "by", "a", "series", "of", "separate", "and", "independent", "links", "(", "usually", "three", "or", "six", ")", "working", "simultaneously", "."], "sentence-detokenized": "Their 'parallel' distinction from a serial manipulator is that the end effector (or 'hand') of this link (or 'arm') is directly connected to its base by a series of separate and independent links (usually three or six) working simultaneously.", "token2charspan": [[0, 5], [6, 7], [7, 15], [15, 16], [17, 28], [29, 33], [34, 35], [36, 42], [43, 54], [55, 57], [58, 62], [63, 66], [67, 70], [71, 79], [80, 81], [81, 83], [84, 85], [85, 89], [89, 90], [90, 91], [92, 94], [95, 99], [100, 104], [105, 106], [106, 108], [109, 110], [110, 113], [113, 114], [114, 115], [116, 118], [119, 127], [128, 137], [138, 140], [141, 144], [145, 149], [150, 152], [153, 154], [155, 161], [162, 164], [165, 173], [174, 177], [178, 189], [190, 195], [196, 197], [197, 204], [205, 210], [211, 213], [214, 217], [217, 218], [219, 226], [227, 241], [241, 242]]}
{"doc_key": "ai-dev-339", "ner": [[4, 5, "researcher"], [15, 16, "researcher"], [17, 19, "researcher"], [21, 22, "researcher"], [24, 25, "researcher"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "advisor", "was", "Professor", "Cordell", "Green", ",", "and", "his", "thesis", "and", "oral", "committee", "included", "Professors", "Edward", "Feigenbaum", ",", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", "and", "Herbert", "Simon", "."], "sentence-detokenized": "His advisor was Professor Cordell Green, and his thesis and oral committee included Professors Edward Feigenbaum, Joshua Lederberg, Paul Cohen, Allen Newell and Herbert Simon.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 25], [26, 33], [34, 39], [39, 40], [41, 44], [45, 48], [49, 55], [56, 59], [60, 64], [65, 74], [75, 83], [84, 94], [95, 101], [102, 112], [112, 113], [114, 120], [121, 130], [130, 131], [132, 136], [137, 142], [142, 143], [144, 149], [150, 156], [157, 160], [161, 168], [169, 174], [174, 175]]}
{"doc_key": "ai-dev-340", "ner": [[4, 5, "metrics"], [3, 3, "metrics"], [11, 13, "metrics"], [15, 15, "metrics"], [16, 17, "metrics"], [19, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "functions", "include", "mean", "square", "error", ",", "mean", "square", "error", ",", "mean", "absolute", "error", ",", "relative", "square", "error", ",", "relative", "absolute", "error", "and", "others", "."], "sentence-detokenized": "These functions include mean square error, mean square error, mean absolute error, relative square error, relative absolute error and others.", "token2charspan": [[0, 5], [6, 15], [16, 23], [24, 28], [29, 35], [36, 41], [41, 42], [43, 47], [48, 54], [55, 60], [60, 61], [62, 66], [67, 75], [76, 81], [81, 82], [83, 91], [92, 98], [99, 104], [104, 105], [106, 114], [115, 123], [124, 129], [130, 133], [134, 140], [140, 141]]}
{"doc_key": "ai-dev-341", "ner": [[3, 3, "programlang"], [5, 5, "programlang"], [7, 7, "product"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Bindings", "exist", "in", "Python", ",", "Java", "and", "MATLAB", "/", "OCTAVE", "."], "sentence-detokenized": "Bindings exist in Python, Java and MATLAB / OCTAVE.", "token2charspan": [[0, 8], [9, 14], [15, 17], [18, 24], [24, 25], [26, 30], [31, 34], [35, 41], [42, 43], [44, 50], [50, 51]]}
{"doc_key": "ai-dev-342", "ner": [[3, 8, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "implementation", "in", "MATLAB", "is", "available", "on", "the", "site", "."], "sentence-detokenized": "An implementation in MATLAB is available on the site.", "token2charspan": [[0, 2], [3, 17], [18, 20], [21, 27], [28, 30], [31, 40], [41, 43], [44, 47], [48, 52], [52, 53]]}
{"doc_key": "ai-dev-343", "ner": [[0, 1, "researcher"], [9, 10, "field"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 10, 0, 1, "origin", "", false, false], [9, 10, 14, 15, "origin", "", false, false], [9, 10, 17, 18, "origin", "", false, false], [9, 10, 20, 21, "origin", "", false, false], [9, 10, 23, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "is", "one", "of", "the", "founding", "fathers", "of", "artificial", "intelligence", ",", "along", "with", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", "and", "Herbert", "A", ".", "Simon", "."], "sentence-detokenized": "John McCarthy is one of the founding fathers of artificial intelligence, along with Alan Turing, Marvin Minsky, Allen Newell and Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 36], [37, 44], [45, 47], [48, 58], [59, 71], [71, 72], [73, 78], [79, 83], [84, 88], [89, 95], [95, 96], [97, 103], [104, 110], [110, 111], [112, 117], [118, 124], [125, 128], [129, 136], [137, 138], [138, 139], [140, 145], [145, 146]]}
{"doc_key": "ai-dev-344", "ner": [[10, 11, "product"], [21, 22, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "parallel", "manipulator", "is", "a", "mechanical", "system", "that", "uses", "several", "serial", "manipulators", "to", "support", "a", "single", "platform", ",", "or", "a", "single", "end", "device", "."], "sentence-detokenized": "A parallel manipulator is a mechanical system that uses several serial manipulators to support a single platform, or a single end device.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 27], [28, 38], [39, 45], [46, 50], [51, 55], [56, 63], [64, 70], [71, 83], [84, 86], [87, 94], [95, 96], [97, 103], [104, 112], [112, 113], [114, 116], [117, 118], [119, 125], [126, 129], [130, 136], [136, 137]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [3, 4, "task"], [7, 7, "product"], [9, 15, "product"], [25, 25, "misc"], [28, 28, "misc"], [31, 32, "misc"], [35, 40, "task"], [43, 46, "product"], [49, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 7, 0, 0, "part-of", "", false, false], [7, 7, 3, 4, "type-of", "", false, false], [9, 15, 7, 7, "named", "", false, false], [25, 25, 7, 7, "part-of", "", false, false], [28, 28, 7, 7, "part-of", "", false, false], [31, 32, 7, 7, "part-of", "", false, false], [35, 40, 7, 7, "part-of", "", false, false], [43, 46, 7, 7, "part-of", "", false, false], [49, 50, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "includes", "an", "information", "extraction", "system", "called", "ANNIE", "(", "A", "Nearly", "-", "New", "Information", "Extraction", "System", ")", ",", "a", "set", "of", "modules", "that", "includes", "a", "tokenizer", ",", "a", "gazetteer", ",", "a", "sentence", "splitter", ",", "a", "part", "-", "of", "-", "speech", "tagging", ",", "a", "named", "entity", "recognition", "transducer", "and", "a", "coreference", "tagger", "."], "sentence-detokenized": "GATE includes an information extraction system called ANNIE (A Nearly-New Information Extraction System), a set of modules that includes a tokenizer, a gazetteer, a sentence splitter, a part-of-speech tagging, a named entity recognition transducer and a coreference tagger.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 28], [29, 39], [40, 46], [47, 53], [54, 59], [60, 61], [61, 62], [63, 69], [69, 70], [70, 73], [74, 85], [86, 96], [97, 103], [103, 104], [104, 105], [106, 107], [108, 111], [112, 114], [115, 122], [123, 127], [128, 136], [137, 138], [139, 148], [148, 149], [150, 151], [152, 161], [161, 162], [163, 164], [165, 173], [174, 182], [182, 183], [184, 185], [186, 190], [190, 191], [191, 193], [193, 194], [194, 200], [201, 208], [208, 209], [210, 211], [212, 217], [218, 224], [225, 236], [237, 247], [248, 251], [252, 253], [254, 265], [266, 272], [272, 273]]}
{"doc_key": "ai-dev-346", "ner": [[3, 5, "university"], [15, 16, "country"], [23, 26, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "graduated", "from", "Moscow", "State", "University", "and", ",", "in", "November", "1978", ",", "left", "for", "the", "United", "States", "thanks", "to", "the", "personal", "intervention", "of", "Senator", "Edward", "M.", "Kennedy", "."], "sentence-detokenized": "He graduated from Moscow State University and, in November 1978, left for the United States thanks to the personal intervention of Senator Edward M. Kennedy.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 24], [25, 30], [31, 41], [42, 45], [45, 46], [47, 49], [50, 58], [59, 63], [63, 64], [65, 69], [70, 73], [74, 77], [78, 84], [85, 91], [92, 98], [99, 101], [102, 105], [106, 114], [115, 127], [128, 130], [131, 138], [139, 145], [146, 148], [149, 156], [156, 157]]}
{"doc_key": "ai-dev-347", "ner": [[4, 6, "organisation"], [9, 13, "misc"], [18, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 9, 13, "win-defeat", "", false, false], [9, 13, 18, 18, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "the", "DeepMind", "AlphaGo", "team", "received", "the", "inaugural", "IJCAI", "Marvin", "Minsky", "Medal", "for", "Outstanding", "Achievements", "in", "AI", "."], "sentence-detokenized": "In 2017, the DeepMind AlphaGo team received the inaugural IJCAI Marvin Minsky Medal for Outstanding Achievements in AI.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 21], [22, 29], [30, 34], [35, 43], [44, 47], [48, 57], [58, 63], [64, 70], [71, 77], [78, 83], [84, 87], [88, 99], [100, 112], [113, 115], [116, 118], [118, 119]]}
{"doc_key": "ai-dev-348", "ner": [[4, 5, "misc"], [9, 9, "misc"], [14, 14, "misc"], [27, 27, "misc"], [35, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[4, 5, 9, 9, "related-to", "is_recorded_by", false, false], [9, 9, 14, 14, "cause-effect", "", false, false], [9, 9, 14, 14, "physical", "", false, false], [9, 9, 27, 27, "physical", "", false, false], [9, 9, 35, 35, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "ways", "in", "which", "anomalous", "propagations", "are", "recorded", "are", "troposcatter", "causing", "irregularities", "in", "the", "troposphere", ",", "scattering", "due", "to", "meteors", ",", "refraction", "in", "the", "ionosphere", "'s", "ionised", "regions", "and", "layers", ",", "and", "reflection", "from", "the", "ionosphere", "."], "sentence-detokenized": "Other ways in which anomalous propagations are recorded are troposcatter causing irregularities in the troposphere, scattering due to meteors, refraction in the ionosphere's ionised regions and layers, and reflection from the ionosphere.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 19], [20, 29], [30, 42], [43, 46], [47, 55], [56, 59], [60, 72], [73, 80], [81, 95], [96, 98], [99, 102], [103, 114], [114, 115], [116, 126], [127, 130], [131, 133], [134, 141], [141, 142], [143, 153], [154, 156], [157, 160], [161, 171], [171, 173], [174, 181], [182, 189], [190, 193], [194, 200], [200, 201], [202, 205], [206, 216], [217, 221], [222, 225], [226, 236], [236, 237]]}
{"doc_key": "ai-dev-349", "ner": [[0, 2, "field"], [4, 4, "field"], [10, 10, "field"], [12, 13, "field"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 10, 10, "part-of", "", false, false], [0, 2, 12, 13, "part-of", "", false, false], [0, 2, 15, 16, "part-of", "", false, false], [0, 2, 18, 19, "part-of", "", false, false], [4, 4, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Natural", "language", "processing", "(", "NLP", ")", "is", "a", "sub-field", "of", "linguistics", ",", "computer", "science", ",", "information", "engineering", "and", "artificial", "intelligence", "that", "deals", "with", "the", "interactions", "between", "computers", "and", "human", "(", "natural", ")", "languages", ",", "specifically", "how", "to", "programme", "computers", "to", "process", "and", "analyse", "large", "amounts", "of", "natural", "language", "data", "."], "sentence-detokenized": "Natural language processing (NLP) is a sub-field of linguistics, computer science, information engineering and artificial intelligence that deals with the interactions between computers and human (natural) languages, specifically how to programme computers to process and analyse large amounts of natural language data.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [29, 32], [32, 33], [34, 36], [37, 38], [39, 48], [49, 51], [52, 63], [63, 64], [65, 73], [74, 81], [81, 82], [83, 94], [95, 106], [107, 110], [111, 121], [122, 134], [135, 139], [140, 145], [146, 150], [151, 154], [155, 167], [168, 175], [176, 185], [186, 189], [190, 195], [196, 197], [197, 204], [204, 205], [206, 215], [215, 216], [217, 229], [230, 233], [234, 236], [237, 246], [247, 256], [257, 259], [260, 267], [268, 271], [272, 279], [280, 285], [286, 293], [294, 296], [297, 304], [305, 313], [314, 318], [318, 319]]}
{"doc_key": "ai-dev-350", "ner": [[8, 9, "organisation"], [12, 13, "organisation"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "active", "youth", "-", "led", "climate", "groups", "are", "Extinction", "Rebellion", ",", "the", "Sunrise", "Movement", ",", "SustainUS", "and", "others", "working", "at", "transnational", "and", "local", "level", "."], "sentence-detokenized": "Other active youth-led climate groups are Extinction Rebellion, the Sunrise Movement, SustainUS and others working at transnational and local level.", "token2charspan": [[0, 5], [6, 12], [13, 18], [18, 19], [19, 22], [23, 30], [31, 37], [38, 41], [42, 52], [53, 62], [62, 63], [64, 67], [68, 75], [76, 84], [84, 85], [86, 95], [96, 99], [100, 106], [107, 114], [115, 117], [118, 131], [132, 135], [136, 141], [142, 147], [147, 148]]}
