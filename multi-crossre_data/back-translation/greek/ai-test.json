{"doc_key": "ai-test-1", "ner": [[5, 7, "algorithm"], [9, 11, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "generative", "model", "approaches", "include", "naive", "Bayes", "classifiers", ",", "Gaussian", "mixture", "models", ",", "variable", "autocoders", "and", "others", "."], "sentence-detokenized": "Typical generative model approaches include naive Bayes classifiers, Gaussian mixture models, variable autocoders and others.", "token2charspan": [[0, 7], [8, 18], [19, 24], [25, 35], [36, 43], [44, 49], [50, 55], [56, 67], [67, 68], [69, 77], [78, 85], [86, 92], [92, 93], [94, 102], [103, 113], [114, 117], [118, 124], [124, 125]]}
{"doc_key": "ai-test-2", "ner": [[6, 6, "organisation"], [12, 12, "conference"], [15, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 12, 12, "role", "", false, false], [15, 21, 12, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Finally", ",", "every", "two", "years", ",", "ELRA", "organises", "a", "major", "conference", ",", "LREC", ",", "the", "International", "Conference", "on", "Language", "Resources", "and", "Evaluation", "."], "sentence-detokenized": "Finally, every two years, ELRA organises a major conference, LREC, the International Conference on Language Resources and Evaluation.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 18], [19, 24], [24, 25], [26, 30], [31, 40], [41, 42], [43, 48], [49, 59], [59, 60], [61, 65], [65, 66], [67, 70], [71, 84], [85, 95], [96, 98], [99, 107], [108, 117], [118, 121], [122, 132], [132, 133]]}
{"doc_key": "ai-test-3", "ner": [[7, 11, "algorithm"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "goal", "is", "usually", "to", "derive", "the", "maximum", "likelihood", "estimate", "for", "the", "HMM", "parameters", "given", "the", "output", "sequences", "."], "sentence-detokenized": "The goal is usually to derive the maximum likelihood estimate for the HMM parameters given the output sequences.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 22], [23, 29], [30, 33], [34, 41], [42, 52], [53, 61], [62, 65], [66, 69], [70, 73], [74, 84], [85, 90], [91, 94], [95, 101], [102, 111], [111, 112]]}
{"doc_key": "ai-test-4", "ner": [[1, 1, "algorithm"], [5, 7, "algorithm"], [10, 10, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 10, 10, "compare", "", false, false], [5, 7, 10, 10, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Unlike", "neural", "networks", "and", "the", "support", "vector", "machine", ",", "the", "AdaBoost", "training", "process", "selects", "only", "those", "features", "known", "to", "improve", "the", "predictive", "ability", "of", "the", "model", ",", "reducing", "dimensionality", "and", "potentially", "improving", "runtime", ",", "as", "there", "is", "no", "need", "to", "compute", "irrelevant", "features", "."], "sentence-detokenized": "Unlike neural networks and the support vector machine, the AdaBoost training process selects only those features known to improve the predictive ability of the model, reducing dimensionality and potentially improving runtime, as there is no need to compute irrelevant features.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 26], [27, 30], [31, 38], [39, 45], [46, 53], [53, 54], [55, 58], [59, 67], [68, 76], [77, 84], [85, 92], [93, 97], [98, 103], [104, 112], [113, 118], [119, 121], [122, 129], [130, 133], [134, 144], [145, 152], [153, 155], [156, 159], [160, 165], [165, 166], [167, 175], [176, 190], [191, 194], [195, 206], [207, 216], [217, 224], [224, 225], [226, 228], [229, 234], [235, 237], [238, 240], [241, 245], [246, 248], [249, 256], [257, 267], [268, 276], [276, 277]]}
{"doc_key": "ai-test-5", "ner": [[0, 1, "misc"], [12, 14, "misc"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 12, 14, "part-of", "", false, false], [12, 14, 16, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "troponym", "is", "one", "of", "the", "possible", "relations", "between", "verbs", "in", "the", "semantic", "network", "of", "the", "Word", "Net", "database", "."], "sentence-detokenized": "The troponym is one of the possible relations between verbs in the semantic network of the WordNet database.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 22], [23, 26], [27, 35], [36, 45], [46, 53], [54, 59], [60, 62], [63, 66], [67, 75], [76, 83], [84, 86], [87, 90], [91, 95], [95, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-6", "ner": [[7, 8, "task"], [10, 11, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Context", "language", "is", "a", "technology", "used", "to", "represent", "knowledge", "in", "artificial", "intelligence", "."], "sentence-detokenized": "Context language is a technology used to represent knowledge in artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 21], [22, 32], [33, 37], [38, 40], [41, 50], [51, 60], [61, 63], [64, 74], [75, 87], [87, 88]]}
{"doc_key": "ai-test-7", "ner": [[0, 1, "metrics"], [6, 10, "metrics"], [14, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "NIST", "also", "differs", "from", "the", "Bilingual", "understudy", "assessment", "in", "its", "calculation", "of", "the", "brevity", "penalty", ",", "since", "small", "variations", "in", "translation", "length", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "The NIST also differs from the Bilingual understudy assessment in its calculation of the brevity penalty, since small variations in translation length do not affect the overall score as much.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 21], [22, 26], [27, 30], [31, 40], [41, 51], [52, 62], [63, 65], [66, 69], [70, 81], [82, 84], [85, 88], [89, 96], [97, 104], [104, 105], [106, 111], [112, 117], [118, 128], [129, 131], [132, 143], [144, 150], [151, 153], [154, 157], [158, 164], [165, 168], [169, 176], [177, 182], [183, 185], [186, 190], [190, 191]]}
{"doc_key": "ai-test-8", "ner": [[15, 16, "algorithm"], [19, 21, "algorithm"], [31, 32, "field"], [42, 43, "algorithm"], [45, 47, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 16, 31, 32, "usage", "", false, false], [19, 21, 31, 32, "usage", "", false, false], [42, 43, 31, 32, "type-of", "", false, false], [45, 47, 31, 32, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "model", "is", "first", "fitted", "to", "a", "training", "dataset", ",", "The", "model", "(", "e.g.", "a", "neural", "network", "or", "a", "naive", "Bayes", "classifier", ")", "is", "trained", "on", "the", "training", "dataset", "using", "a", "supervised", "learning", "method", ",", "for", "example", "using", "optimisation", "methods", "such", "as", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The model is first fitted to a training dataset, The model (e.g. a neural network or a naive Bayes classifier) is trained on the training dataset using a supervised learning method, for example using optimisation methods such as gradient descent or stochastic gradient descent.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 18], [19, 25], [26, 28], [29, 30], [31, 39], [40, 47], [47, 48], [49, 52], [53, 58], [59, 60], [60, 64], [65, 66], [67, 73], [74, 81], [82, 84], [85, 86], [87, 92], [93, 98], [99, 109], [109, 110], [111, 113], [114, 121], [122, 124], [125, 128], [129, 137], [138, 145], [146, 151], [152, 153], [154, 164], [165, 173], [174, 180], [180, 181], [182, 185], [186, 193], [194, 199], [200, 212], [213, 220], [221, 225], [226, 228], [229, 237], [238, 245], [246, 248], [249, 259], [260, 268], [269, 276], [276, 277]]}
{"doc_key": "ai-test-9", "ner": [[0, 0, "product"], [8, 9, "task"], [11, 11, "task"], [13, 15, "task"], [17, 18, "task"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 0, "usage", "", true, false], [11, 11, 0, 0, "usage", "", true, false], [13, 15, 0, 0, "usage", "", true, false], [17, 18, 0, 0, "usage", "", true, false], [24, 26, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "has", "been", "used", "in", "applications", "such", "as", "question", "answering", ",", "paraphrasing", ",", "text", "implication", "recognition", "and", "information", "extraction", ",", "either", "directly", "or", "through", "Semantic", "Role", "Labeling", "tools", "."], "sentence-detokenized": "FrameNet has been used in applications such as question answering, paraphrasing, text implication recognition and information extraction, either directly or through Semantic Role Labeling tools.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 25], [26, 38], [39, 43], [44, 46], [47, 55], [56, 65], [65, 66], [67, 79], [79, 80], [81, 85], [86, 97], [98, 109], [110, 113], [114, 125], [126, 136], [136, 137], [138, 144], [145, 153], [154, 156], [157, 164], [165, 173], [174, 178], [179, 187], [188, 193], [193, 194]]}
{"doc_key": "ai-test-10", "ner": [[6, 7, "field"], [12, 12, "misc"], [15, 15, "product"], [18, 18, "misc"], [21, 21, "product"], [24, 25, "field"], [28, 28, "product"], [31, 33, "misc"], [36, 36, "product"], [38, 38, "product"], [40, 40, "product"], [43, 44, "misc"], [47, 48, "product"], [50, 51, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[15, 15, 12, 12, "general-affiliation", "", false, false], [21, 21, 18, 18, "general-affiliation", "", false, false], [28, 28, 24, 25, "general-affiliation", "", false, false], [36, 36, 31, 33, "type-of", "", false, false], [38, 38, 31, 33, "type-of", "", false, false], [40, 40, 31, 33, "type-of", "", false, false], [47, 48, 43, 44, "general-affiliation", "", false, false], [50, 51, 43, 44, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["This", "could", "include", "programs", "such", "as", "data", "analysis", "and", "extraction", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "generalized", "control", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "e.g.", "Crystal", "Reports", "and", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "This could include programs such as data analysis and extraction tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), generalized control software (e.g. ACL, Arbutus, EAS), business intelligence (e.g. Crystal Reports and Business Objects), etc.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 27], [28, 32], [33, 35], [36, 40], [41, 49], [50, 53], [54, 64], [65, 70], [70, 71], [72, 84], [85, 86], [86, 90], [91, 96], [96, 97], [97, 98], [99, 108], [109, 110], [110, 114], [115, 121], [121, 122], [122, 123], [124, 135], [136, 144], [145, 146], [146, 150], [151, 154], [154, 155], [155, 156], [157, 168], [169, 176], [177, 185], [186, 187], [187, 191], [192, 195], [195, 196], [197, 204], [204, 205], [206, 209], [209, 210], [210, 211], [212, 220], [221, 233], [234, 235], [235, 239], [240, 247], [248, 255], [256, 259], [260, 268], [269, 276], [276, 277], [277, 278], [279, 282], [282, 283]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 6, "researcher"], [12, 12, "organisation"], [15, 15, "product"], [21, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "origin", "", false, false], [5, 6, 12, 12, "role", "", false, false], [15, 15, 21, 22, "type-of", "", false, false], [21, 22, 5, 6, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", "-", "founded", "by", "Rodney", "Brooks", ",", "who", "previously", "worked", "at", "iRobot", "-", "introduced", "Baxter", "in", "September", "2012", "as", "an", "industrial", "robot", "designed", "to", "safely", "interact", "with", "nearby", "workers", "and", "can", "be", "programmed", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "Rethink Robotics - founded by Rodney Brooks, who previously worked at iRobot - introduced Baxter in September 2012 as an industrial robot designed to safely interact with nearby workers and can be programmed to perform simple tasks.", "token2charspan": [[0, 7], [8, 16], [17, 18], [19, 26], [27, 29], [30, 36], [37, 43], [43, 44], [45, 48], [49, 59], [60, 66], [67, 69], [70, 76], [77, 78], [79, 89], [90, 96], [97, 99], [100, 109], [110, 114], [115, 117], [118, 120], [121, 131], [132, 137], [138, 146], [147, 149], [150, 156], [157, 165], [166, 170], [171, 177], [178, 185], [186, 189], [190, 193], [194, 196], [197, 207], [208, 210], [211, 218], [219, 225], [226, 231], [231, 232]]}
{"doc_key": "ai-test-12", "ner": [[1, 2, "field"], [5, 6, "task"], [8, 9, "task"], [11, 14, "task"], [16, 18, "task"], [20, 21, "task"], [23, 24, "task"], [27, 29, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 6, 1, 2, "part-of", "task_part_of_field", false, false], [8, 9, 1, 2, "part-of", "task_part_of_field", false, false], [11, 14, 1, 2, "part-of", "task_part_of_field", false, false], [16, 18, 1, 2, "part-of", "task_part_of_field", false, false], [20, 21, 1, 2, "part-of", "task_part_of_field", false, false], [23, 24, 1, 2, "part-of", "task_part_of_field", false, false], [27, 29, 1, 2, "part-of", "task_part_of_field", false, false], [35, 36, 1, 2, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Typical", "text", "mining", "tasks", "include", "text", "categorization", ",", "text", "clustering", ",", "concept", "/", "entity", "extraction", ",", "generating", "detailed", "taxonomies", ",", "sentiment", "analysis", ",", "document", "summarization", ",", "and", "entity", "relationship", "modeling", "(", "i.e.", "learning", "relationships", "between", "recognized", "entities", ")", "."], "sentence-detokenized": "Typical text mining tasks include text categorization, text clustering, concept/entity extraction, generating detailed taxonomies, sentiment analysis, document summarization, and entity relationship modeling (i.e. learning relationships between recognized entities).", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 25], [26, 33], [34, 38], [39, 53], [53, 54], [55, 59], [60, 70], [70, 71], [72, 79], [79, 80], [80, 86], [87, 97], [97, 98], [99, 109], [110, 118], [119, 129], [129, 130], [131, 140], [141, 149], [149, 150], [151, 159], [160, 173], [173, 174], [175, 178], [179, 185], [186, 198], [199, 207], [208, 209], [209, 213], [214, 222], [223, 236], [237, 244], [245, 255], [256, 264], [264, 265], [265, 266]]}
{"doc_key": "ai-test-13", "ner": [[4, 5, "metrics"], [9, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "stemming", "reduces", "the", "accuracy", ",", "or", "the", "percentage", "of", "TRUE", "negatives", ",", "for", "such", "systems", "."], "sentence-detokenized": "However, stemming reduces the accuracy, or the percentage of TRUE negatives, for such systems.", "token2charspan": [[0, 7], [7, 8], [9, 17], [18, 25], [26, 29], [30, 38], [38, 39], [40, 42], [43, 46], [47, 57], [58, 60], [61, 65], [66, 75], [75, 76], [77, 80], [81, 85], [86, 93], [93, 94]]}
{"doc_key": "ai-test-14", "ner": [[4, 5, "task"], [7, 10, "misc"], [15, 17, "misc"], [26, 26, "product"], [28, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 10, 4, 5, "temporal", "", false, false], [15, 17, 7, 10, "named", "", false, false], [26, 26, 7, 10, "usage", "", false, false], [28, 28, 7, 10, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "special", "case", "of", "keyword", "detection", "is", "wake", "-", "up", "word", "detection", "(", "also", "called", "\"", "hot", "word", "\"", ")", "used", "by", "personal", "digital", "assistants", "like", "Alexa", "or", "Siri", "to", "wake", "up", "when", "their", "name", "is", "spoken", "."], "sentence-detokenized": "A special case of keyword detection is wake-up word detection (also called \"hot word\") used by personal digital assistants like Alexa or Siri to wake up when their name is spoken.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 17], [18, 25], [26, 35], [36, 38], [39, 43], [43, 44], [44, 46], [47, 51], [52, 61], [62, 63], [63, 67], [68, 74], [75, 76], [76, 79], [80, 84], [84, 85], [85, 86], [87, 91], [92, 94], [95, 103], [104, 111], [112, 122], [123, 127], [128, 133], [134, 136], [137, 141], [142, 144], [145, 149], [150, 152], [153, 157], [158, 163], [164, 168], [169, 171], [172, 178], [178, 179]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [9, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "with", "Java", "."], "sentence-detokenized": "Prova is an open source programming language that combines Prolog with Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 16], [17, 23], [24, 35], [36, 44], [45, 49], [50, 58], [59, 65], [66, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-test-16", "ner": [[3, 4, "organisation"], [9, 9, "organisation"], [16, 18, "product"], [28, 29, "country"], [34, 34, "organisation"], [44, 44, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 9, 9, "part-of", "", false, false], [3, 4, 9, 9, "role", "sells", false, false], [3, 4, 28, 29, "role", "sells_to", false, false], [34, 34, 44, 44, "opposite", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "1987", ",", "Tocibai", "Machine", ",", "a", "subsidiary", "of", "Toshiba", ",", "was", "accused", "of", "illegally", "selling", "CNC", "milling", "cutters", "used", "to", "produce", "very", "quiet", "submarine", "propellers", "to", "the", "Soviet", "Union", "in", "violation", "of", "the", "CoCom", "agreement", ",", "an", "international", "embargo", "by", "certain", "countries", "on", "COMECON", "countries", "."], "sentence-detokenized": "In 1987, Tocibai Machine, a subsidiary of Toshiba, was accused of illegally selling CNC milling cutters used to produce very quiet submarine propellers to the Soviet Union in violation of the CoCom agreement, an international embargo by certain countries on COMECON countries.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 24], [24, 25], [26, 27], [28, 38], [39, 41], [42, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 75], [76, 83], [84, 87], [88, 95], [96, 103], [104, 108], [109, 111], [112, 119], [120, 124], [125, 130], [131, 140], [141, 151], [152, 154], [155, 158], [159, 165], [166, 171], [172, 174], [175, 184], [185, 187], [188, 191], [192, 197], [198, 207], [207, 208], [209, 211], [212, 225], [226, 233], [234, 236], [237, 244], [245, 254], [255, 257], [258, 265], [266, 275], [275, 276]]}
{"doc_key": "ai-test-17", "ner": [[7, 10, "product"], [21, 24, "location"]], "ner_mapping_to_source": [1, 2], "relations": [[7, 10, 21, 24, "physical", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Engelberger", "'s", "most", "famous", "invention", ",", "the", "Unimate", "industrial", "robotic", "arm", ",", "was", "among", "the", "first", "to", "be", "inducted", "into", "the", "Robot", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberger's most famous invention, the Unimate industrial robotic arm, was among the first to be inducted into the Robot Hall of Fame in 2003.", "token2charspan": [[0, 11], [11, 13], [14, 18], [19, 25], [26, 35], [35, 36], [37, 40], [41, 48], [49, 59], [60, 67], [68, 71], [71, 72], [73, 76], [77, 82], [83, 86], [87, 92], [93, 95], [96, 98], [99, 107], [108, 112], [113, 116], [117, 122], [123, 127], [128, 130], [131, 135], [136, 138], [139, 143], [143, 144]]}
{"doc_key": "ai-test-18", "ner": [[3, 4, "misc"], [8, 8, "misc"], [10, 10, "person"], [21, 22, "field"], [18, 25, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 8, 8, "usage", "", false, false], [10, 10, 21, 22, "role", "", false, false], [21, 22, 18, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Originally", "controlled", "via", "static", "html", "web", "pages", "using", "CGI", ",", "Dalton", "'s", "work", "saw", "the", "introduction", "of", "a", "Java", "-", "based", "augmented", "reality", "interface", ",", "which", "has", "had", "limited", "success", "."], "sentence-detokenized": "Originally controlled via static html web pages using CGI, Dalton's work saw the introduction of a Java-based augmented reality interface, which has had limited success.", "token2charspan": [[0, 10], [11, 21], [22, 25], [26, 32], [33, 37], [38, 41], [42, 47], [48, 53], [54, 57], [57, 58], [59, 65], [65, 67], [68, 72], [73, 76], [77, 80], [81, 93], [94, 96], [97, 98], [99, 103], [103, 104], [104, 109], [110, 119], [120, 127], [128, 137], [137, 138], [139, 144], [145, 148], [149, 152], [153, 160], [161, 168], [168, 169]]}
{"doc_key": "ai-test-19", "ner": [[5, 6, "task"], [10, 10, "organisation"], [26, 26, "conference"], [30, 30, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 10, 10, "origin", "", false, false], [26, 26, 30, 30, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "publication", "on", "the", "LMF", "specification", "as", "validated", "by", "ISO", "(", "this", "paper", "became", "(", "in", "2015", ")", "the", "9th", "most", "cited", "paper", "in", "the", "LREC", "conference", "proceedings", "by", "LREC", "papers", ")", ":"], "sentence-detokenized": "The first publication on the LMF specification as validated by ISO (this paper became (in 2015) the 9th most cited paper in the LREC conference proceedings by LREC papers):", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 24], [25, 28], [29, 32], [33, 46], [47, 49], [50, 59], [60, 62], [63, 66], [67, 68], [68, 72], [73, 78], [79, 85], [86, 87], [87, 89], [90, 94], [94, 95], [96, 99], [100, 103], [104, 108], [109, 114], [115, 120], [121, 123], [124, 127], [128, 132], [133, 143], [144, 155], [156, 158], [159, 163], [164, 170], [170, 171], [171, 172]]}
{"doc_key": "ai-test-20", "ner": [[1, 2, "metrics"], [15, 16, "metrics"], [18, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 1, 2, "usage", "", false, false], [15, 16, 18, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "confusion", "matrix", "or", "matching", "matrix", "is", "often", "used", "as", "a", "tool", "to", "validate", "the", "accuracy", "of", "the", "k", "-", "NN", "classification", "."], "sentence-detokenized": "A confusion matrix or matching matrix is often used as a tool to validate the accuracy of the k -NN classification.", "token2charspan": [[0, 1], [2, 11], [12, 18], [19, 21], [22, 30], [31, 37], [38, 40], [41, 46], [47, 51], [52, 54], [55, 56], [57, 61], [62, 64], [65, 73], [74, 77], [78, 86], [87, 89], [90, 93], [94, 95], [96, 97], [97, 99], [100, 114], [114, 115]]}
{"doc_key": "ai-test-21", "ner": [[0, 1, "algorithm"], [12, 12, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 15, "part-of", "", false, false], [0, 1, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", "is", "one", "of", "the", "prediction", "modelling", "approaches", "used", "in", "statistics", ",", "data", "mining", "and", "machine", "learning", "."], "sentence-detokenized": "Decision tree learning is one of the prediction modelling approaches used in statistics, data mining and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 47], [48, 57], [58, 68], [69, 73], [74, 76], [77, 87], [87, 88], [89, 93], [94, 100], [101, 104], [105, 112], [113, 121], [121, 122]]}
{"doc_key": "ai-test-22", "ner": [[5, 7, "misc"], [17, 21, "field"], [22, 24, "algorithm"], [26, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 17, 21, "related-to", "", true, false], [22, 24, 17, 21, "type-of", "", false, false], [26, 26, 17, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["At", "run", "-time", ",", "the", "target", "prosody", "of", "a", "sentence", "is", "placed", "in", "these", "minimum", "units", "through", "signal", "processing", "techniques", "such", "as", "linear", "predictive", "coding", ",", "PSOLA"], "sentence-detokenized": "At run-time, the target prosody of a sentence is placed in these minimum units through signal processing techniques such as linear predictive coding, PSOLA", "token2charspan": [[0, 2], [3, 6], [6, 11], [11, 12], [13, 16], [17, 23], [24, 31], [32, 34], [35, 36], [37, 45], [46, 48], [49, 55], [56, 58], [59, 64], [65, 72], [73, 78], [79, 86], [87, 93], [94, 104], [105, 115], [116, 120], [121, 123], [124, 130], [131, 141], [142, 148], [148, 149], [150, 155]]}
{"doc_key": "ai-test-23", "ner": [[3, 4, "field"], [6, 7, "field"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 3, 4, "usage", "", true, false], [17, 18, 6, 7, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "approach", "used", "artificial", "intelligence", "and", "machine", "learning", "to", "allow", "researchers", "to", "visibly", "compare", "conventional", "and", "thermal", "facial", "images", "."], "sentence-detokenized": "This approach used artificial intelligence and machine learning to allow researchers to visibly compare conventional and thermal facial images.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 29], [30, 42], [43, 46], [47, 54], [55, 63], [64, 66], [67, 72], [73, 84], [85, 87], [88, 95], [96, 103], [104, 116], [117, 120], [121, 128], [129, 135], [136, 142], [142, 143]]}
{"doc_key": "ai-test-24", "ner": [[1, 2, "field"], [4, 5, "algorithm"], [12, 13, "task"], [16, 17, "misc"], [23, 24, "field"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 1, 2, "part-of", "", false, false], [4, 5, 12, 13, "topic", "", false, false], [12, 13, 16, 17, "origin", "", false, false], [23, 24, 1, 2, "part-of", "", false, false], [23, 24, 4, 5, "topic", "", false, false], [26, 27, 1, 2, "part-of", "", false, false], [26, 27, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "computer", "science", ",", "evolutionary", "computation", "is", "a", "family", "of", "algorithms", "for", "global", "optimization", "inspired", "by", "biological", "evolution", ",", "and", "the", "subfield", "of", "artificial", "intelligence", "and", "soft", "computing", "that", "studies", "these", "algorithms", "."], "sentence-detokenized": "In computer science, evolutionary computation is a family of algorithms for global optimization inspired by biological evolution, and the subfield of artificial intelligence and soft computing that studies these algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 33], [34, 45], [46, 48], [49, 50], [51, 57], [58, 60], [61, 71], [72, 75], [76, 82], [83, 95], [96, 104], [105, 107], [108, 118], [119, 128], [128, 129], [130, 133], [134, 137], [138, 146], [147, 149], [150, 160], [161, 173], [174, 177], [178, 182], [183, 192], [193, 197], [198, 205], [206, 211], [212, 222], [222, 223]]}
{"doc_key": "ai-test-25", "ner": [[11, 12, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "one", "can", "combine", "some", "measure", "based", "on", "the", "confusion", "matrix", "with", "the", "mean", "squared", "error", "evaluated", "between", "the", "raw", "model", "results", "and", "the", "actual", "values", "."], "sentence-detokenized": "For example, one can combine some measure based on the confusion matrix with the mean squared error evaluated between the raw model results and the actual values.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 20], [21, 28], [29, 33], [34, 41], [42, 47], [48, 50], [51, 54], [55, 64], [65, 71], [72, 76], [77, 80], [81, 85], [86, 93], [94, 99], [100, 109], [110, 117], [118, 121], [122, 125], [126, 131], [132, 139], [140, 143], [144, 147], [148, 154], [155, 161], [161, 162]]}
{"doc_key": "ai-test-26", "ner": [[6, 7, "product"], [10, 10, "researcher"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 10, 10, "origin", "", false, false], [6, 7, 17, 17, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "majority", "are", "results", "of", "the", "word2vec", "model", "developed", "by", "Mikolov", "et", "al", ".", "or", "variants", "of", "word2vec", "."], "sentence-detokenized": "The majority are results of the word2vec model developed by Mikolov et al. or variants of word2vec.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 24], [25, 27], [28, 31], [32, 40], [41, 46], [47, 56], [57, 59], [60, 67], [68, 70], [71, 73], [73, 74], [75, 77], [78, 86], [87, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-27", "ner": [[11, 11, "conference"], [15, 18, "conference"], [14, 20, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 20, 15, 18, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["During", "this", "period", "a", "total", "of", "43", "publications", "were", "recognized", "by", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "During this period a total of 43 publications were recognized by CVPR and the International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 6], [7, 11], [12, 18], [19, 20], [21, 26], [27, 29], [30, 32], [33, 45], [46, 50], [51, 61], [62, 64], [65, 69], [70, 73], [74, 77], [78, 91], [92, 102], [103, 105], [106, 114], [115, 121], [122, 123], [123, 127], [127, 128], [128, 129]]}
{"doc_key": "ai-test-28", "ner": [[0, 0, "product"], [14, 15, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 15, "general-affiliation", "platform_for_education_about", false, false], [22, 23, 0, 0, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["AIBO", "has", "been", "much", "used", "as", "an", "inexpensive", "platform", "for", "education", "and", "research", "in", "artificial", "intelligence", "because", "it", "integrates", "a", "computer", ",", "computer", "vision", "and", "modularity", "in", "a", "package", "much", "cheaper", "than", "conventional", "research", "robots", "."], "sentence-detokenized": "AIBO has been much used as an inexpensive platform for education and research in artificial intelligence because it integrates a computer, computer vision and modularity in a package much cheaper than conventional research robots.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 18], [19, 23], [24, 26], [27, 29], [30, 41], [42, 50], [51, 54], [55, 64], [65, 68], [69, 77], [78, 80], [81, 91], [92, 104], [105, 112], [113, 115], [116, 126], [127, 128], [129, 137], [137, 138], [139, 147], [148, 154], [155, 158], [159, 169], [170, 172], [173, 174], [175, 182], [183, 187], [188, 195], [196, 200], [201, 213], [214, 222], [223, 229], [229, 230]]}
{"doc_key": "ai-test-29", "ner": [[6, 11, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "chaired", "the", "programme", "of", "the", "International", "Conference", "on", "Computer", "Vision", "2021", "."], "sentence-detokenized": "He chaired the programme of the International Conference on Computer Vision 2021.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 24], [25, 27], [28, 31], [32, 45], [46, 56], [57, 59], [60, 68], [69, 75], [76, 80], [80, 81]]}
{"doc_key": "ai-test-30", "ner": [[0, 0, "researcher"], [7, 7, "organisation"], [17, 17, "organisation"], [27, 28, "organisation"], [38, 39, "product"], [35, 41, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 7, 7, "role", "", false, false], [0, 0, 17, 17, "role", "", true, false], [17, 17, 27, 28, "role", "develops_with", false, false], [38, 39, 17, 17, "artifact", "", false, false], [35, 41, 38, 39, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Scheinman", ",", "after", "receiving", "a", "grant", "from", "Unimation", "to", "develop", "his", "designs", ",", "sold", "these", "designs", "to", "Unimation", ",", "which", "further", "developed", "them", "with", "the", "support", "of", "General", "Motors", "and", "later", "marketed", "them", "as", "the", "Programmable", "Universal", "Machine", "for", "Assembly", "(", "PUMA", ")", "."], "sentence-detokenized": "Scheinman, after receiving a grant from Unimation to develop his designs, sold these designs to Unimation, which further developed them with the support of General Motors and later marketed them as the Programmable Universal Machine for Assembly (PUMA).", "token2charspan": [[0, 9], [9, 10], [11, 16], [17, 26], [27, 28], [29, 34], [35, 39], [40, 49], [50, 52], [53, 60], [61, 64], [65, 72], [72, 73], [74, 78], [79, 84], [85, 92], [93, 95], [96, 105], [105, 106], [107, 112], [113, 120], [121, 130], [131, 135], [136, 140], [141, 144], [145, 152], [153, 155], [156, 163], [164, 170], [171, 174], [175, 180], [181, 189], [190, 194], [195, 197], [198, 201], [202, 214], [215, 224], [225, 232], [233, 236], [237, 245], [246, 247], [247, 251], [251, 252], [252, 253]]}
{"doc_key": "ai-test-31", "ner": [[6, 6, "task"], [7, 11, "task"], [15, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 6, 6, "general-affiliation", "works_with", false, false], [15, 15, 7, 11, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "overview", "of", "calibration", "methods", "for", "binary", "classification", "and", "multicategory", "classification", "tasks", "is", "given", "by", "Gebel", "(", "2009", ")", "."], "sentence-detokenized": "An overview of calibration methods for binary classification and multicategory classification tasks is given by Gebel (2009).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 34], [35, 38], [39, 45], [46, 60], [61, 64], [65, 78], [79, 93], [94, 99], [100, 102], [103, 108], [109, 111], [112, 117], [118, 119], [119, 123], [123, 124], [124, 125]]}
{"doc_key": "ai-test-32", "ner": [[6, 10, "task"], [13, 14, "task"], [16, 17, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "deals", "with", "areas", "such", "as", "optical", "character", "recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "speech", "recognition", "technology", "and", "electronic", "keyboards", "."], "sentence-detokenized": "It deals with areas such as optical character recognition (OCR), speech synthesis, speech recognition technology and electronic keyboards.", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 19], [20, 24], [25, 27], [28, 35], [36, 45], [46, 57], [58, 59], [59, 62], [62, 63], [63, 64], [65, 71], [72, 81], [81, 82], [83, 89], [90, 101], [102, 112], [113, 116], [117, 127], [128, 137], [137, 138]]}
{"doc_key": "ai-test-33", "ner": [[8, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "more", "recent", "and", "modern", "techniques", ",", "the", "Kaldi", "toolbox", "can", "be", "used", "."], "sentence-detokenized": "For more recent and modern techniques, the Kaldi toolbox can be used.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 19], [20, 26], [27, 37], [37, 38], [39, 42], [43, 48], [49, 56], [57, 60], [61, 63], [64, 68], [68, 69]]}
{"doc_key": "ai-test-34", "ner": [[0, 4, "researcher"], [8, 10, "organisation"], [16, 17, "organisation"], [23, 24, "organisation"], [27, 28, "researcher"], [32, 35, "organisation"], [42, 44, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 4, 8, 10, "role", "", false, false], [0, 4, 16, 17, "role", "", false, false], [0, 4, 23, 24, "role", "", false, false], [0, 4, 32, 35, "role", "", false, false], [0, 4, 42, 44, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson", "-", "Laird", "is", "a", "Fellow", "of", "the", "American", "Philosophical", "Society", ",", "a", "Fellow", "of", "the", "Royal", "Society", ",", "a", "Fellow", "of", "the", "British", "Academy", ",", "a", "William", "James", "Fellow", "of", "the", "Association", "for", "Psychological", "Science", ",", "and", "a", "Fellow", "of", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Johnson-Laird is a Fellow of the American Philosophical Society, a Fellow of the Royal Society, a Fellow of the British Academy, a William James Fellow of the Association for Psychological Science, and a Fellow of the Cognitive Science Society.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 66], [67, 73], [74, 76], [77, 80], [81, 86], [87, 94], [94, 95], [96, 97], [98, 104], [105, 107], [108, 111], [112, 119], [120, 127], [127, 128], [129, 130], [131, 138], [139, 144], [145, 151], [152, 154], [155, 158], [159, 170], [171, 174], [175, 188], [189, 196], [196, 197], [198, 201], [202, 203], [204, 210], [211, 213], [214, 217], [218, 227], [228, 235], [236, 243], [243, 244]]}
{"doc_key": "ai-test-35", "ner": [[0, 8, "conference"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"], [21, 22, "algorithm"], [30, 30, "task"], [26, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 12, 0, 8, "physical", "", false, false], [11, 12, 0, 8, "temporal", "", false, false], [14, 15, 0, 8, "physical", "", false, false], [14, 15, 0, 8, "temporal", "", false, false], [17, 18, 0, 8, "physical", "", false, false], [17, 18, 0, 8, "temporal", "", false, false], [21, 22, 17, 18, "role", "extends", false, false], [30, 30, 17, 18, "role", "extends", false, false], [26, 32, 30, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["At", "the", "IEEE", "International", "Conference", "on", "Image", "Processing", "in", "2010", ",", "Rui", "Hu", ",", "Mark", "Banard", "and", "John", "Collomosse", "extended", "the", "HOG", "descriptor", "for", "use", "in", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the IEEE International Conference on Image Processing in 2010, Rui Hu, Mark Banard and John Collomosse extended the HOG descriptor for use in sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 25], [26, 36], [37, 39], [40, 45], [46, 56], [57, 59], [60, 64], [64, 65], [66, 69], [70, 72], [72, 73], [74, 78], [79, 85], [86, 89], [90, 94], [95, 105], [106, 114], [115, 118], [119, 122], [123, 133], [134, 137], [138, 141], [142, 144], [145, 151], [151, 152], [152, 157], [158, 163], [164, 173], [174, 175], [175, 179], [179, 180], [180, 181]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "uses", "a", "modified", "form", "of", "precision", "to", "compare", "a", "candidate", "translation", "with", "multiple", "reference", "translations", "."], "sentence-detokenized": "BLEU uses a modified form of precision to compare a candidate translation with multiple reference translations.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 20], [21, 25], [26, 28], [29, 38], [39, 41], [42, 49], [50, 51], [52, 61], [62, 73], [74, 78], [79, 87], [88, 97], [98, 110], [110, 111]]}
{"doc_key": "ai-test-37", "ner": [[32, 33, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "case", "of", "a", "general", "base", "space", "math", "(", "Y", ",\\", "mathcal", "{", "B", "},\\", "nu", ")", "/", "math", "(", "i.e.", "a", "base", "space", "that", "is", "not", "measurable", ")", ",", "the", "relative", "entropy", "is", "usually", "considered", "."], "sentence-detokenized": "For the case of a general base space math (Y,\\ mathcal {B},\\ nu) / math (i.e. a base space that is not measurable), the relative entropy is usually considered.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 15], [16, 17], [18, 25], [26, 30], [31, 36], [37, 41], [42, 43], [43, 44], [44, 46], [47, 54], [55, 56], [56, 57], [57, 60], [61, 63], [63, 64], [65, 66], [67, 71], [72, 73], [73, 77], [78, 79], [80, 84], [85, 90], [91, 95], [96, 98], [99, 102], [103, 113], [113, 114], [114, 115], [116, 119], [120, 128], [129, 136], [137, 139], [140, 147], [148, 158], [158, 159]]}
{"doc_key": "ai-test-38", "ner": [[17, 18, "country"], [11, 11, "organisation"], [9, 13, "organisation"], [27, 28, "country"], [21, 21, "organisation"], [23, 23, "organisation"], [31, 33, "organisation"], [46, 46, "country"], [36, 41, "organisation"], [38, 45, "organisation"], [52, 52, "misc"], [53, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[11, 11, 17, 18, "physical", "", false, false], [9, 13, 11, 11, "named", "", false, false], [21, 21, 27, 28, "physical", "", false, false], [23, 23, 21, 21, "named", "", false, false], [36, 41, 46, 46, "physical", "", false, false], [38, 45, 36, 41, "named", "", false, false], [52, 52, 53, 53, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "of", "October", "2011", ",", "existing", "partnerships", "with", "the", "National", "Park", "Service", "(", "NPS", ")", "of", "the", "United", "States", ",", "Historic", "Scotland", "(", "HS", ")", "of", "the", "United", "Kingdom", ",", "the", "World", "Monuments", "Fund", "and", "the", "National", "Institute", "of", "Anthropology", "and", "History", "(", "INAH", ")", "of", "Mexico", "had", "been", "significantly", "expanded", ",", "CyArk", "website"], "sentence-detokenized": "As of October 2011, existing partnerships with the National Park Service (NPS) of the United States, Historic Scotland (HS) of the United Kingdom, the World Monuments Fund and the National Institute of Anthropology and History (INAH) of Mexico had been significantly expanded, CyArk website", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 18], [18, 19], [20, 28], [29, 41], [42, 46], [47, 50], [51, 59], [60, 64], [65, 72], [73, 74], [74, 77], [77, 78], [79, 81], [82, 85], [86, 92], [93, 99], [99, 100], [101, 109], [110, 118], [119, 120], [120, 122], [122, 123], [124, 126], [127, 130], [131, 137], [138, 145], [145, 146], [147, 150], [151, 156], [157, 166], [167, 171], [172, 175], [176, 179], [180, 188], [189, 198], [199, 201], [202, 214], [215, 218], [219, 226], [227, 228], [228, 232], [232, 233], [234, 236], [237, 243], [244, 247], [248, 252], [253, 266], [267, 275], [275, 276], [277, 282], [283, 290]]}
{"doc_key": "ai-test-39", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [11, 11, "product"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 11, 11, "part-of", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [11, 11, 6, 7, "general-affiliation", "", false, false], [13, 13, 6, 7, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Core", "SVMs", "are", "available", "in", "many", "machine", "learning", "toolkits", ",", "including", "LIBSVM", ",", "MATLAB", "and", "others", "."], "sentence-detokenized": "Core SVMs are available in many machine learning toolkits, including LIBSVM, MATLAB and others.", "token2charspan": [[0, 4], [5, 9], [10, 13], [14, 23], [24, 26], [27, 31], [32, 39], [40, 48], [49, 57], [57, 58], [59, 68], [69, 75], [75, 76], [77, 83], [84, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-test-40", "ner": [[0, 4, "misc"], [13, 14, "location"], [16, 16, "location"], [17, 22, "country"], [24, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 13, 14, "physical", "", false, false], [0, 4, 24, 26, "temporal", "", false, false], [13, 14, 16, 16, "physical", "", false, false], [16, 16, 17, 22, "physical", "", false, false], [24, 26, 13, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2009", "Loebner", "Prize", "Competition", "took", "place", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", ",", "Brighton", ",", "UK", ",", "in", "conjunction", "with", "the", "Interspeech", "2009", "conference", "."], "sentence-detokenized": "The 2009 Loebner Prize Competition took place on 6 September 2009 at the Brighton Centre, Brighton, UK, in conjunction with the Interspeech 2009 conference.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 34], [35, 39], [40, 45], [46, 48], [49, 50], [51, 60], [61, 65], [66, 68], [69, 72], [73, 81], [82, 88], [88, 89], [90, 98], [98, 99], [100, 102], [102, 103], [104, 106], [107, 118], [119, 123], [124, 127], [128, 139], [140, 144], [145, 155], [155, 156]]}
{"doc_key": "ai-test-41", "ner": [[2, 3, "product"], [10, 10, "product"], [16, 18, "product"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 21, 2, 3, "part-of", "", false, false], [19, 21, 10, 10, "part-of", "", false, false], [19, 21, 16, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "humanoid", "robot", "QRIO", "was", "designed", "as", "the", "successor", "to", "AIBO", "and", "runs", "the", "same", "basic", "R", "-", "CODE", "Aperios", "operating", "system", "."], "sentence-detokenized": "The humanoid robot QRIO was designed as the successor to AIBO and runs the same basic R-CODE Aperios operating system.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 23], [24, 27], [28, 36], [37, 39], [40, 43], [44, 53], [54, 56], [57, 61], [62, 65], [66, 70], [71, 74], [75, 79], [80, 85], [86, 87], [87, 88], [88, 92], [93, 100], [101, 110], [111, 117], [117, 118]]}
{"doc_key": "ai-test-42", "ner": [[0, 3, "misc"], [6, 7, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 3, "cause-effect", "", true, false], [12, 13, 0, 3, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "speech", "waveforms", "are", "generated", "by", "the", "HMMs", "themselves", "based", "on", "the", "maximum", "likelihood", "criterion", "."], "sentence-detokenized": "The speech waveforms are generated by the HMMs themselves based on the maximum likelihood criterion.", "token2charspan": [[0, 3], [4, 10], [11, 20], [21, 24], [25, 34], [35, 37], [38, 41], [42, 46], [47, 57], [58, 63], [64, 66], [67, 70], [71, 78], [79, 89], [90, 99], [99, 100]]}
{"doc_key": "ai-test-43", "ner": [[0, 1, "product"], [5, 8, "task"], [10, 12, "task"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 5, 8, "type-of", "", false, false], [0, 1, 10, 12, "type-of", "", false, false], [0, 1, 16, 16, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "is", "a", "free", "multilingual", "statistical", "machine", "translation", "and", "neural", "machine", "translation", "service", "developed", "by", "Google", "for", "translating", "texts", "and", "websites", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Google Translate is a free multilingual statistical machine translation and neural machine translation service developed by Google for translating texts and websites from one language to another.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 39], [40, 51], [52, 59], [60, 71], [72, 75], [76, 82], [83, 90], [91, 102], [103, 110], [111, 120], [121, 123], [124, 130], [131, 134], [135, 146], [147, 152], [153, 156], [157, 165], [166, 170], [171, 174], [175, 183], [184, 186], [187, 194], [194, 195]]}
{"doc_key": "ai-test-44", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [14, 16, "field"], [21, 23, "task"], [25, 26, "task"], [28, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[21, 23, 5, 6, "part-of", "", false, true], [21, 23, 8, 9, "part-of", "", false, true], [21, 23, 11, 12, "part-of", "", false, true], [25, 26, 5, 6, "part-of", "", false, true], [25, 26, 8, 9, "part-of", "", false, true], [25, 26, 11, 12, "part-of", "", false, true], [28, 31, 5, 6, "part-of", "", false, true], [28, 31, 8, 9, "part-of", "", false, true], [28, 31, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Skeletons", "are", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", "and", "digital", "image", "processing", "for", "purposes", "such", "as", "visual", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", "or", "compression", "."], "sentence-detokenized": "Skeletons are widely used in computer vision, image analysis, pattern recognition and digital image processing for purposes such as visual character recognition, fingerprint recognition, visual inspection or compression.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 25], [26, 28], [29, 37], [38, 44], [44, 45], [46, 51], [52, 60], [60, 61], [62, 69], [70, 81], [82, 85], [86, 93], [94, 99], [100, 110], [111, 114], [115, 123], [124, 128], [129, 131], [132, 138], [139, 148], [149, 160], [160, 161], [162, 173], [174, 185], [185, 186], [187, 193], [194, 204], [205, 207], [208, 219], [219, 220]]}
{"doc_key": "ai-test-45", "ner": [[1, 8, "conference"], [11, 14, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 8, 11, 14, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "is", "a", "benchmark", "in", "object", "classification", "and", "detection", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object classification and detection, with millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 58], [59, 68], [69, 71], [72, 78], [79, 93], [94, 97], [98, 107], [107, 108], [109, 113], [114, 122], [123, 125], [126, 132], [133, 136], [137, 145], [146, 148], [149, 155], [156, 163], [163, 164]]}
{"doc_key": "ai-test-46", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [17, 20, "misc"], [23, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 17, 20, "part-of", "", false, false], [0, 0, 23, 26, "part-of", "", false, false], [4, 5, 17, 20, "part-of", "", false, false], [4, 5, 23, 26, "part-of", "", false, false], [7, 8, 17, 20, "part-of", "", false, false], [7, 8, 23, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "are", "referred", "to", "by", "some", "as", "the", "godfathers", "of", "artificial", "intelligence", "and", "the", "godfathers", "of", "deep", "learning", "."], "sentence-detokenized": "Bengio, along with Geoffrey Hinton and Yann LeCun, are referred to by some as the godfathers of artificial intelligence and the godfathers of deep learning.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 27], [28, 34], [35, 38], [39, 43], [44, 49], [49, 50], [51, 54], [55, 63], [64, 66], [67, 69], [70, 74], [75, 77], [78, 81], [82, 92], [93, 95], [96, 106], [107, 119], [120, 123], [124, 127], [128, 138], [139, 141], [142, 146], [147, 155], [155, 156]]}
{"doc_key": "ai-test-47", "ner": [[7, 7, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "life", "member", "of", "the", "IEEE", "."], "sentence-detokenized": "He is a life member of the IEEE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 19], [20, 22], [23, 26], [27, 31], [31, 32]]}
{"doc_key": "ai-test-48", "ner": [[0, 1, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 16, 21, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NSA", "Bethesda", "is", "responsible", "for", "the", "operational", "support", "of", "the", "base", "of", "its", "primary", "tenant", ",", "Walter", "Reed", "National", "Military", "Medical", "Center", "."], "sentence-detokenized": "NSA Bethesda is responsible for the operational support of the base of its primary tenant, Walter Reed National Military Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 31], [32, 35], [36, 47], [48, 55], [56, 58], [59, 62], [63, 67], [68, 70], [71, 74], [75, 82], [83, 89], [89, 90], [91, 97], [98, 102], [103, 111], [112, 120], [121, 128], [129, 135], [135, 136]]}
{"doc_key": "ai-test-49", "ner": [[7, 8, "field"], [10, 11, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "three", "main", "examples", "of", "learning", "are", "supervised", "learning", ",", "unsupervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "The three main examples of learning are supervised learning, unsupervised learning and reinforcement learning.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 23], [24, 26], [27, 35], [36, 39], [40, 50], [51, 59], [59, 60], [61, 73], [74, 82], [83, 86], [87, 100], [101, 109], [109, 110]]}
{"doc_key": "ai-test-50", "ner": [[2, 2, "task"], [4, 6, "task"], [11, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Examples", "include", "control", ",", "programming", "and", "scheduling", ",", "the", "ability", "to", "answer", "diagnostic", "and", "consumer", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", "and", "facial", "recognition", "."], "sentence-detokenized": "Examples include control, programming and scheduling, the ability to answer diagnostic and consumer questions, handwriting recognition, natural language understanding, speech recognition and facial recognition.", "token2charspan": [[0, 8], [9, 16], [17, 24], [24, 25], [26, 37], [38, 41], [42, 52], [52, 53], [54, 57], [58, 65], [66, 68], [69, 75], [76, 86], [87, 90], [91, 99], [100, 109], [109, 110], [111, 122], [123, 134], [134, 135], [136, 143], [144, 152], [153, 166], [166, 167], [168, 174], [175, 186], [187, 190], [191, 197], [198, 209], [209, 210]]}
{"doc_key": "ai-test-51", "ner": [[9, 15, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", "he", "was", "elected", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "founding", "member", ")", "."], "sentence-detokenized": "In 1991 he was elected a member of the Association for the Advancement of Artificial Intelligence (1990, founding member).", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 24], [25, 31], [32, 34], [35, 38], [39, 50], [51, 54], [55, 58], [59, 70], [71, 73], [74, 84], [85, 97], [98, 99], [99, 103], [103, 104], [105, 113], [114, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-test-52", "ner": [[11, 12, "misc"], [15, 16, "algorithm"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "by", "formulating", "the", "problem", "as", "a", "solution", "of", "a", "Toeplitz", "matrix", "and", "using", "Levinson", "recursion", ",", "we", "can", "relatively", "quickly", "estimate", "a", "filter", "with", "the", "smallest", "possible", "mean", "square", "error", "."], "sentence-detokenized": "However, by formulating the problem as a solution of a Toeplitz matrix and using Levinson recursion, we can relatively quickly estimate a filter with the smallest possible mean square error.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 23], [24, 27], [28, 35], [36, 38], [39, 40], [41, 49], [50, 52], [53, 54], [55, 63], [64, 70], [71, 74], [75, 80], [81, 89], [90, 99], [99, 100], [101, 103], [104, 107], [108, 118], [119, 126], [127, 135], [136, 137], [138, 144], [145, 149], [150, 153], [154, 162], [163, 171], [172, 176], [177, 183], [184, 189], [189, 190]]}
{"doc_key": "ai-test-53", "ner": [[4, 9, "conference"], [15, 19, "location"], [21, 21, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 9, 15, 19, "physical", "", false, false], [15, 19, 21, 21, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2011", "the", "15th", "edition", "of", "Campus", "Party", "Spain", "will", "take", "place", "in", "the", "City", "of", "Arts", "and", "Sciences", "of", "Valencia", "."], "sentence-detokenized": "In July 2011 the 15th edition of Campus Party Spain will take place in the City of Arts and Sciences of Valencia.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 16], [17, 21], [22, 29], [30, 32], [33, 39], [40, 45], [46, 51], [52, 56], [57, 61], [62, 67], [68, 70], [71, 74], [75, 79], [80, 82], [83, 87], [88, 91], [92, 100], [101, 103], [104, 112], [112, 113]]}
{"doc_key": "ai-test-54", "ner": [[14, 14, "product"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Often", "this", "is", "generally", "only", "possible", "at", "the", "end", "of", "complex", "games", "such", "as", "chess", "or", "go", ",", "as", "it", "is", "not", "computationally", "feasible", "to", "look", "ahead", "to", "the", "end", "of", "the", "game", ",", "but", "only", "towards", "the", "end", ",", "and", "instead", ",", "positions", "are", "given", "finite", "values", "as", "estimates", "of", "the", "degree", "of", "confidence", "that", "they", "will", "result", "in", "a", "win", "for", "one", "player", "or", "the", "other", "."], "sentence-detokenized": "Often this is generally only possible at the end of complex games such as chess or go, as it is not computationally feasible to look ahead to the end of the game, but only towards the end, and instead, positions are given finite values as estimates of the degree of confidence that they will result in a win for one player or the other.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 23], [24, 28], [29, 37], [38, 40], [41, 44], [45, 48], [49, 51], [52, 59], [60, 65], [66, 70], [71, 73], [74, 79], [80, 82], [83, 85], [85, 86], [87, 89], [90, 92], [93, 95], [96, 99], [100, 115], [116, 124], [125, 127], [128, 132], [133, 138], [139, 141], [142, 145], [146, 149], [150, 152], [153, 156], [157, 161], [161, 162], [163, 166], [167, 171], [172, 179], [180, 183], [184, 187], [187, 188], [189, 192], [193, 200], [200, 201], [202, 211], [212, 215], [216, 221], [222, 228], [229, 235], [236, 238], [239, 248], [249, 251], [252, 255], [256, 262], [263, 265], [266, 276], [277, 281], [282, 286], [287, 291], [292, 298], [299, 301], [302, 303], [304, 307], [308, 311], [312, 315], [316, 322], [323, 325], [326, 329], [330, 335], [335, 336]]}
{"doc_key": "ai-test-55", "ner": [[4, 6, "algorithm"], [23, 24, "algorithm"], [26, 28, "algorithm"], [30, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 23, 24, "compare", "", false, false], [4, 6, 26, 28, "compare", "", false, false], [4, 6, 30, 32, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "difference", "between", "the", "polynomial", "logarithmic", "model", "and", "many", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "with", "the", "same", "basic", "setup", "(", "perceptron", "algorithm", ",", "support", "vector", "machines", ",", "linear", "discriminant", "analysis", ",", "etc", "."], "sentence-detokenized": "The difference between the polynomial logarithmic model and many other methods, models, algorithms, etc. with the same basic setup (perceptron algorithm, support vector machines, linear discriminant analysis, etc.", "token2charspan": [[0, 3], [4, 14], [15, 22], [23, 26], [27, 37], [38, 49], [50, 55], [56, 59], [60, 64], [65, 70], [71, 78], [78, 79], [80, 86], [86, 87], [88, 98], [98, 99], [100, 104], [105, 109], [110, 113], [114, 118], [119, 124], [125, 130], [131, 132], [132, 142], [143, 152], [152, 153], [154, 161], [162, 168], [169, 177], [177, 178], [179, 185], [186, 198], [199, 207], [207, 208], [209, 212], [212, 213]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "published", "by", "the"], "sentence-detokenized": "Association for Computational Linguistics, published by the", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 52], [53, 55], [56, 59]]}
{"doc_key": "ai-test-57", "ner": [[3, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "electronic", "facial", "recognition", "system", ",", "each", "face", "is", "represented", "by", "a", "large", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In the electronic facial recognition system, each face is represented by a large number of pixel values.", "token2charspan": [[0, 2], [3, 6], [7, 17], [18, 24], [25, 36], [37, 43], [43, 44], [45, 49], [50, 54], [55, 57], [58, 69], [70, 72], [73, 74], [75, 80], [81, 87], [88, 90], [91, 96], [97, 103], [103, 104]]}
{"doc_key": "ai-test-58", "ner": [[6, 7, "person"], [14, 16, "organisation"], [23, 23, "country"], [26, 26, "person"], [36, 38, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 7, 14, 16, "role", "", false, false], [6, 7, 23, 23, "physical", "", false, false], [26, 26, 36, 38, "origin", "", false, false], [26, 26, 36, 38, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2002", ",", "his", "son", ",", "Daniel", "Pearl", ",", "a", "journalist", "working", "for", "the", "Wall", "Street", "Journal", ",", "was", "kidnapped", "and", "murdered", "in", "Pakistan", ",", "leading", "Judea", "and", "other", "family", "members", "and", "friends", "to", "create", "the", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "In 2002, his son, Daniel Pearl, a journalist working for the Wall Street Journal, was kidnapped and murdered in Pakistan, leading Judea and other family members and friends to create the Daniel Pearl Foundation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [16, 17], [18, 24], [25, 30], [30, 31], [32, 33], [34, 44], [45, 52], [53, 56], [57, 60], [61, 65], [66, 72], [73, 80], [80, 81], [82, 85], [86, 95], [96, 99], [100, 108], [109, 111], [112, 120], [120, 121], [122, 129], [130, 135], [136, 139], [140, 145], [146, 152], [153, 160], [161, 164], [165, 172], [173, 175], [176, 182], [183, 186], [187, 193], [194, 199], [200, 210], [210, 211]]}
{"doc_key": "ai-test-59", "ner": [[4, 6, "organisation"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 18, 19, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "late", "2006", ",", "Red", "Envelope", "Entertainment", "has", "also", "expanded", "into", "producing", "original", "content", "with", "directors", "such", "as", "John", "Waters", "."], "sentence-detokenized": "Since late 2006, Red Envelope Entertainment has also expanded into producing original content with directors such as John Waters.", "token2charspan": [[0, 5], [6, 10], [11, 15], [15, 16], [17, 20], [21, 29], [30, 43], [44, 47], [48, 52], [53, 61], [62, 66], [67, 76], [77, 85], [86, 93], [94, 98], [99, 108], [109, 113], [114, 116], [117, 121], [122, 128], [128, 129]]}
{"doc_key": "ai-test-60", "ner": [[7, 11, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "building", "is", "now", "part", "of", "the", "Beth", "Israel", "Deaconess", "Medical", "Center", "."], "sentence-detokenized": "The building is now part of the Beth Israel Deaconess Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 31], [32, 36], [37, 43], [44, 53], [54, 61], [62, 68], [68, 69]]}
{"doc_key": "ai-test-61", "ner": [[15, 16, "field"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "common", "theme", "of", "this", "paper", "is", "the", "adoption", "of", "a", "theoretical", "points", "perspective", "on", "artificial", "intelligence", "and", "knowledge", "representation", "."], "sentence-detokenized": "A common theme of this paper is the adoption of a theoretical points perspective on artificial intelligence and knowledge representation.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 17], [18, 22], [23, 28], [29, 31], [32, 35], [36, 44], [45, 47], [48, 49], [50, 61], [62, 68], [69, 80], [81, 83], [84, 94], [95, 107], [108, 111], [112, 121], [122, 136], [136, 137]]}
{"doc_key": "ai-test-62", "ner": [[5, 7, "task"], [9, 9, "task"], [19, 20, "task"], [39, 40, "task"], [42, 43, "task"], [46, 48, "task"], [50, 50, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 7, 19, 20, "type-of", "", false, false], [5, 7, 46, 48, "compare", "", false, false], [5, 7, 46, 48, "opposite", "", false, false], [9, 9, 5, 7, "named", "", false, false], [39, 40, 46, 48, "part-of", "", false, false], [42, 43, 46, 48, "part-of", "", false, false], [46, 48, 19, 20, "type-of", "", false, false], [50, 50, 46, 48, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["For", "example", ",", "the", "term", "neural", "machine", "translation", "(", "NMT", ")", "emphasises", "the", "fact", "that", "deep", "learning", "-", "based", "machine", "translation", "approaches", "learn", "sequence", "-", "to", "-", "sequence", "transformations", "directly", ",", "avoiding", "the", "need", "for", "intermediate", "steps", "such", "as", "word", "alignment", "and", "language", "modelling", "used", "in", "statistical", "machine", "translation", "(", "STT", ")", "."], "sentence-detokenized": "For example, the term neural machine translation (NMT) emphasises the fact that deep learning-based machine translation approaches learn sequence-to-sequence transformations directly, avoiding the need for intermediate steps such as word alignment and language modelling used in statistical machine translation (STT).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 36], [37, 48], [49, 50], [50, 53], [53, 54], [55, 65], [66, 69], [70, 74], [75, 79], [80, 84], [85, 93], [93, 94], [94, 99], [100, 107], [108, 119], [120, 130], [131, 136], [137, 145], [145, 146], [146, 148], [148, 149], [149, 157], [158, 173], [174, 182], [182, 183], [184, 192], [193, 196], [197, 201], [202, 205], [206, 218], [219, 224], [225, 229], [230, 232], [233, 237], [238, 247], [248, 251], [252, 260], [261, 270], [271, 275], [276, 278], [279, 290], [291, 298], [299, 310], [311, 312], [312, 315], [315, 316], [316, 317]]}
{"doc_key": "ai-test-63", "ner": [[6, 6, "field"], [10, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 6, 10, 11, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "research", "in", "the", "field", "of", "WSD", "is", "conducted", "using", "Word", "Net", "as", "a", "reference", "meaning", "inventory", "for", "."], "sentence-detokenized": "Most research in the field of WSD is conducted using WordNet as a reference meaning inventory for.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 26], [27, 29], [30, 33], [34, 36], [37, 46], [47, 52], [53, 57], [57, 60], [61, 63], [64, 65], [66, 75], [76, 83], [84, 93], [94, 97], [97, 98]]}
{"doc_key": "ai-test-64", "ner": [[2, 2, "misc"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 2, 2, "general-affiliation", "", false, true], [14, 15, 2, 2, "general-affiliation", "", false, true]], "relations_mapping_to_source": [0, 1], "sentence": ["Notable", "former", "PhD", "students", "and", "postdoctoral", "researchers", "in", "his", "group", "include", "Richard", "Zemel", "and", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Notable former PhD students and postdoctoral researchers in his group include Richard Zemel and Zoubin Ghahramani.", "token2charspan": [[0, 7], [8, 14], [15, 18], [19, 27], [28, 31], [32, 44], [45, 56], [57, 59], [60, 63], [64, 69], [70, 77], [78, 85], [86, 91], [92, 95], [96, 102], [103, 113], [113, 114]]}
{"doc_key": "ai-test-65", "ner": [[7, 8, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 13, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Each", "prediction", "result", "or", "instance", "of", "a", "confusion", "matrix", "represents", "a", "point", "in", "ROC", "space", "."], "sentence-detokenized": "Each prediction result or instance of a confusion matrix represents a point in ROC space.", "token2charspan": [[0, 4], [5, 15], [16, 22], [23, 25], [26, 34], [35, 37], [38, 39], [40, 49], [50, 56], [57, 67], [68, 69], [70, 75], [76, 78], [79, 82], [83, 88], [88, 89]]}
{"doc_key": "ai-test-66", "ner": [[2, 2, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [13, 20, "product"], [21, 24, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 21, 24, "physical", "", false, false], [6, 7, 21, 24, "physical", "", false, false], [9, 10, 21, 24, "physical", "", false, false], [13, 20, 2, 2, "artifact", "", false, false], [13, 20, 6, 7, "artifact", "", false, false], [13, 20, 9, 10, "artifact", "", false, false], [13, 20, 21, 24, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1997", "Thrun", "and", "his", "colleagues", "Wolfram", "Burgard", "and", "Dieter", "Fox", "developed", "the", "world", "'s", "first", "robotic", "tour", "guide", "at", "the", "German", "Museum", "in", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "In 1997 Thrun and his colleagues Wolfram Burgard and Dieter Fox developed the world's first robotic tour guide at the German Museum in Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 17], [18, 21], [22, 32], [33, 40], [41, 48], [49, 52], [53, 59], [60, 63], [64, 73], [74, 77], [78, 83], [83, 85], [86, 91], [92, 99], [100, 104], [105, 110], [111, 113], [114, 117], [118, 124], [125, 131], [132, 134], [135, 139], [140, 141], [141, 145], [145, 146], [146, 147]]}
{"doc_key": "ai-test-67", "ner": [[0, 1, "product"], [7, 7, "misc"], [21, 23, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 1, "part-of", "", false, false], [21, 23, 0, 1, "usage", "", false, false], [25, 26, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "of", "semantic", "relationships", "between", "words", "in", "more", "than", "200", "languages.Its", "main", "use", "is", "in", "automatic", "natural", "language", "processing", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database of semantic relationships between words in more than 200 languages.Its main use is in automatic natural language processing and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 32], [33, 41], [42, 55], [56, 63], [64, 69], [70, 72], [73, 77], [78, 82], [83, 86], [87, 100], [101, 105], [106, 109], [110, 112], [113, 115], [116, 125], [126, 133], [134, 142], [143, 153], [154, 157], [158, 168], [169, 181], [182, 194], [194, 195]]}
{"doc_key": "ai-test-68", "ner": [[5, 7, "field"], [12, 15, "conference"], [18, 26, "conference"], [28, 28, "conference"], [30, 30, "conference"], [38, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 15, 5, 7, "topic", "", false, false], [12, 15, 38, 39, "topic", "", false, false], [18, 26, 5, 7, "topic", "", false, false], [18, 26, 38, 39, "topic", "", false, false], [28, 28, 5, 7, "topic", "", false, false], [28, 28, 38, 39, "topic", "", false, false], [30, 30, 5, 7, "topic", "", false, false], [30, 30, 38, 39, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Conferences", "in", "the", "field", "of", "natural", "language", "processing", ",", "such", "as", "the", "Association", "for", "Computational", "Linguistics", ",", "the", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", "and", "HLT", ",", "are", "beginning", "to", "include", "papers", "on", "speech", "processing", "."], "sentence-detokenized": "Conferences in the field of natural language processing, such as the Association for Computational Linguistics, the North American Chapter of the Association for Computational Linguistics, EMNLP and HLT, are beginning to include papers on speech processing.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 24], [25, 27], [28, 35], [36, 44], [45, 55], [55, 56], [57, 61], [62, 64], [65, 68], [69, 80], [81, 84], [85, 98], [99, 110], [110, 111], [112, 115], [116, 121], [122, 130], [131, 138], [139, 141], [142, 145], [146, 157], [158, 161], [162, 175], [176, 187], [187, 188], [189, 194], [195, 198], [199, 202], [202, 203], [204, 207], [208, 217], [218, 220], [221, 228], [229, 235], [236, 238], [239, 245], [246, 256], [256, 257]]}
{"doc_key": "ai-test-69", "ner": [[3, 3, "programlang"], [19, 24, "misc"], [35, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "set", "of", "Java", "programs", "uses", "the", "dictionary", "to", "process", "variations", "in", "biomedical", "texts", "by", "associating", "words", "based", "on", "their", "parts", "of", "speech", ",", "which", "can", "be", "useful", "in", "web", "searches", "or", "searches", "through", "an", "electronic", "medical", "record", "."], "sentence-detokenized": "A set of Java programs uses the dictionary to process variations in biomedical texts by associating words based on their parts of speech, which can be useful in web searches or searches through an electronic medical record.", "token2charspan": [[0, 1], [2, 5], [6, 8], [9, 13], [14, 22], [23, 27], [28, 31], [32, 42], [43, 45], [46, 53], [54, 64], [65, 67], [68, 78], [79, 84], [85, 87], [88, 99], [100, 105], [106, 111], [112, 114], [115, 120], [121, 126], [127, 129], [130, 136], [136, 137], [138, 143], [144, 147], [148, 150], [151, 157], [158, 160], [161, 164], [165, 173], [174, 176], [177, 185], [186, 193], [194, 196], [197, 207], [208, 215], [216, 222], [222, 223]]}
{"doc_key": "ai-test-70", "ner": [[9, 9, "algorithm"], [11, 11, "algorithm"], [13, 13, "algorithm"], [15, 15, "algorithm"], [17, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "many", "more", "recent", "algorithms", ",", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", "and", "others", "."], "sentence-detokenized": "There are many more recent algorithms, such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost and others.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 26], [27, 37], [37, 38], [39, 43], [44, 46], [47, 54], [54, 55], [56, 66], [66, 67], [68, 78], [78, 79], [80, 87], [87, 88], [89, 98], [99, 102], [103, 109], [109, 110]]}
{"doc_key": "ai-test-71", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "of", "a", "Python", "implementation", ":"], "sentence-detokenized": "This is an example of a Python implementation:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 23], [24, 30], [31, 45], [45, 46]]}
{"doc_key": "ai-test-72", "ner": [[0, 0, "organisation"], [2, 2, "product"], [7, 11, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 0, 0, "artifact", "made_by_company", false, false], [7, 11, 2, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mattel", "'s", "Intellivision", "game", "console", "offered", "the", "Intellivoice", "Voice", "Synthesis", "unit", "in", "1982", "."], "sentence-detokenized": "Mattel's Intellivision game console offered the Intellivoice Voice Synthesis unit in 1982.", "token2charspan": [[0, 6], [6, 8], [9, 22], [23, 27], [28, 35], [36, 43], [44, 47], [48, 60], [61, 66], [67, 76], [77, 81], [82, 84], [85, 89], [89, 90]]}
{"doc_key": "ai-test-73", "ner": [[4, 5, "task"], [9, 15, "task"], [17, 18, "field"], [20, 22, "task"], [26, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 15, 4, 5, "part-of", "", false, false], [17, 18, 4, 5, "part-of", "", false, false], [20, 22, 4, 5, "part-of", "", false, false], [26, 30, 20, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "also", "worked", "on", "machine", "translation", ",", "both", "in", "high", "-", "precision", "knowledge", "-", "based", "MT", "and", "machine", "learning", "for", "statistical", "machine", "translation", "(", "such", "as", "generalised", "paradigm", "-", "based", "MT", ")", "."], "sentence-detokenized": "He also worked on machine translation, both in high-precision knowledge-based MT and machine learning for statistical machine translation (such as generalised paradigm-based MT).", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 17], [18, 25], [26, 37], [37, 38], [39, 43], [44, 46], [47, 51], [51, 52], [52, 61], [62, 71], [71, 72], [72, 77], [78, 80], [81, 84], [85, 92], [93, 101], [102, 105], [106, 117], [118, 125], [126, 137], [138, 139], [139, 143], [144, 146], [147, 158], [159, 167], [167, 168], [168, 173], [174, 176], [176, 177], [177, 178]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [5, 5, "misc"], [21, 22, "algorithm"], [24, 25, "field"], [27, 28, "field"], [30, 30, "field"], [32, 33, "field"], [35, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 21, 22, "general-affiliation", "", false, false], [0, 1, 24, 25, "general-affiliation", "", false, false], [0, 1, 27, 28, "general-affiliation", "", false, false], [0, 1, 30, 30, "general-affiliation", "", false, false], [0, 1, 32, 33, "general-affiliation", "", false, false], [0, 1, 35, 35, "general-affiliation", "", false, false], [5, 5, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "commonly", "called", "Mathematica", ")", "is", "a", "modern", "technical", "computing", "system", "that", "covers", "most", "areas", "of", "engineering", "-", "including", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "data", "science", ",", "visualizations", "and", "more", "."], "sentence-detokenized": "Wolfram Mathematica (commonly called Mathematica) is a modern technical computing system that covers most areas of engineering - including neural networks, machine learning, image processing, geometry, data science, visualizations and more.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 29], [30, 36], [37, 48], [48, 49], [50, 52], [53, 54], [55, 61], [62, 71], [72, 81], [82, 88], [89, 93], [94, 100], [101, 105], [106, 111], [112, 114], [115, 126], [127, 128], [129, 138], [139, 145], [146, 154], [154, 155], [156, 163], [164, 172], [172, 173], [174, 179], [180, 190], [190, 191], [192, 200], [200, 201], [202, 206], [207, 214], [214, 215], [216, 230], [231, 234], [235, 239], [239, 240]]}
{"doc_key": "ai-test-75", "ner": [[2, 6, "product"], [10, 11, "researcher"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 2, 6, "type-of", "", false, false], [17, 17, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "digitally", "operated", "and", "programmable", "robot", "was", "invented", "by", "George", "Devol", "in", "1954", "and", "eventually", "named", "Unimate", "."], "sentence-detokenized": "The first digitally operated and programmable robot was invented by George Devol in 1954 and eventually named Unimate.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 28], [29, 32], [33, 45], [46, 51], [52, 55], [56, 64], [65, 67], [68, 74], [75, 80], [81, 83], [84, 88], [89, 92], [93, 103], [104, 109], [110, 117], [117, 118]]}
{"doc_key": "ai-test-76", "ner": [[1, 1, "algorithm"], [3, 3, "algorithm"], [17, 18, "task"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 3, 3, "compare", "", false, false], [3, 3, 17, 18, "general-affiliation", "", false, false], [3, 3, 20, 21, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Like", "DBNs", ",", "DBMs", "can", "learn", "complex", "and", "abstract", "internal", "representations", "of", "input", "in", "tasks", "such", "as", "object", "recognition", "or", "speech", "recognition", ",", "using", "limited", ",", "labeled", "data", "to", "refine", "representations", "constructed", "using", "a", "large", "set", "of", "unlabeled", "sensory", "input", "data", "."], "sentence-detokenized": "Like DBNs, DBMs can learn complex and abstract internal representations of input in tasks such as object recognition or speech recognition, using limited, labeled data to refine representations constructed using a large set of unlabeled sensory input data.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 15], [16, 19], [20, 25], [26, 33], [34, 37], [38, 46], [47, 55], [56, 71], [72, 74], [75, 80], [81, 83], [84, 89], [90, 94], [95, 97], [98, 104], [105, 116], [117, 119], [120, 126], [127, 138], [138, 139], [140, 145], [146, 153], [153, 154], [155, 162], [163, 167], [168, 170], [171, 177], [178, 193], [194, 205], [206, 211], [212, 213], [214, 219], [220, 223], [224, 226], [227, 236], [237, 244], [245, 250], [251, 255], [255, 256]]}
{"doc_key": "ai-test-77", "ner": [[4, 8, "task"], [13, 13, "conference"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 4, 8, "topic", "", false, false], [15, 15, 4, 8, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Scientific", "conferences", "in", "which", "vision", "-", "based", "activity", "recognition", "tasks", "frequently", "appear", "are", "ICCV", "and", "CVPR", "."], "sentence-detokenized": "Scientific conferences in which vision-based activity recognition tasks frequently appear are ICCV and CVPR.", "token2charspan": [[0, 10], [11, 22], [23, 25], [26, 31], [32, 38], [38, 39], [39, 44], [45, 53], [54, 65], [66, 71], [72, 82], [83, 89], [90, 93], [94, 98], [99, 102], [103, 107], [107, 108]]}
{"doc_key": "ai-test-78", "ner": [[1, 1, "field"], [4, 5, "algorithm"], [7, 7, "algorithm"], [17, 21, "metrics"], [20, 20, "metrics"], [19, 23, "metrics"], [37, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 5, 1, 1, "part-of", "", false, false], [4, 5, 17, 21, "related-to", "finds", false, false], [4, 5, 20, 20, "related-to", "finds", false, false], [4, 5, 37, 38, "related-to", "", false, false], [7, 7, 4, 5, "named", "", false, false], [19, 23, 20, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "statistics", ",", "the", "expectation", "maximization", "(", "EM", ")", "algorithm", "is", "an", "iterative", "method", "for", "finding", "maximum", "likelihood", "or", "maximum", "posterior", "probability", "(", "MAP", ")", "estimates", "of", "parameters", "in", "statistical", "models", "where", "the", "model", "depends", "on", "unobserved", "latent", "variables", "."], "sentence-detokenized": "In statistics, the expectation maximization (EM) algorithm is an iterative method for finding maximum likelihood or maximum posterior probability (MAP) estimates of parameters in statistical models where the model depends on unobserved latent variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 30], [31, 43], [44, 45], [45, 47], [47, 48], [49, 58], [59, 61], [62, 64], [65, 74], [75, 81], [82, 85], [86, 93], [94, 101], [102, 112], [113, 115], [116, 123], [124, 133], [134, 145], [146, 147], [147, 150], [150, 151], [152, 161], [162, 164], [165, 175], [176, 178], [179, 190], [191, 197], [198, 203], [204, 207], [208, 213], [214, 221], [222, 224], [225, 235], [236, 242], [243, 252], [252, 253]]}
{"doc_key": "ai-test-79", "ner": [[6, 10, "metrics"], [18, 18, "metrics"], [16, 20, "metrics"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[16, 20, 18, 18, "named", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Similarly", ",", "researchers", "sometimes", "report", "the", "false", "positive", "rate", "(", "FPR", ")", "as", "well", "as", "the", "false", "negative", "rate", "(", "FNR", ")", "."], "sentence-detokenized": "Similarly, researchers sometimes report the false positive rate (FPR) as well as the false negative rate (FNR).", "token2charspan": [[0, 9], [9, 10], [11, 22], [23, 32], [33, 39], [40, 43], [44, 49], [50, 58], [59, 63], [64, 65], [65, 68], [68, 69], [70, 72], [73, 77], [78, 80], [81, 84], [85, 90], [91, 99], [100, 104], [105, 106], [106, 109], [109, 110], [110, 111]]}
{"doc_key": "ai-test-80", "ner": [[6, 11, "metrics"], [15, 15, "field"], [18, 19, "metrics"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 15, 6, 11, "usage", "", false, false], [22, 23, 18, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "concept", "is", "similar", "to", "the", "signal", "-", "to", "-", "noise", "ratio", "used", "in", "the", "sciences", "and", "the", "confusion", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "The concept is similar to the signal-to-noise ratio used in the sciences and the confusion matrix used in artificial intelligence.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 25], [26, 29], [30, 36], [36, 37], [37, 39], [39, 40], [40, 45], [46, 51], [52, 56], [57, 59], [60, 63], [64, 72], [73, 76], [77, 80], [81, 90], [91, 97], [98, 102], [103, 105], [106, 116], [117, 129], [129, 130]]}
{"doc_key": "ai-test-81", "ner": [[5, 6, "field"], [11, 13, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [31, 35, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 11, 13, "general-affiliation", "", false, false], [5, 6, 18, 19, "general-affiliation", "", false, false], [5, 6, 21, 22, "general-affiliation", "", false, false], [31, 35, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Code", "of", "Conduct", "for", "Human", "Augmentation", ",", "originally", "presented", "by", "Steve", "Mann", "in", "2004", "and", "refined", "by", "Ray", "Kurzweil", "and", "Marvin", "Minsky", "in", "2013", ",", "was", "finally", "ratified", "at", "the", "Toronto", "Virtual", "Reality", "Conference", "on", "25", "June", "2017", "."], "sentence-detokenized": "The Code of Conduct for Human Augmentation, originally presented by Steve Mann in 2004 and refined by Ray Kurzweil and Marvin Minsky in 2013, was finally ratified at the Toronto Virtual Reality Conference on 25 June 2017.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 23], [24, 29], [30, 42], [42, 43], [44, 54], [55, 64], [65, 67], [68, 73], [74, 78], [79, 81], [82, 86], [87, 90], [91, 98], [99, 101], [102, 105], [106, 114], [115, 118], [119, 125], [126, 132], [133, 135], [136, 140], [140, 141], [142, 145], [146, 153], [154, 162], [163, 165], [166, 169], [170, 177], [178, 185], [186, 193], [194, 204], [205, 207], [208, 210], [211, 215], [216, 220], [220, 221]]}
{"doc_key": "ai-test-82", "ner": [[3, 5, "person"], [12, 12, "organisation"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 12, 12, "role", "directed_for", false, false], [3, 5, 18, 19, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", ",", "Walter", "R.", "Booth", "directed", "10", "films", "for", "the", "British", "Kinoplastikon", ",", "probably", "in", "collaboration", "with", "Cecil", "Hepworth", "."], "sentence-detokenized": "In 1913, Walter R. Booth directed 10 films for the British Kinoplastikon, probably in collaboration with Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 18], [19, 24], [25, 33], [34, 36], [37, 42], [43, 46], [47, 50], [51, 58], [59, 72], [72, 73], [74, 82], [83, 85], [86, 99], [100, 104], [105, 110], [111, 119], [119, 120]]}
{"doc_key": "ai-test-83", "ner": [[16, 16, "location"], [13, 14, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 16, 16, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "unveiled", "their", "new", "robot", "in", "1961", "at", "a", "trade", "show", "at", "the", "Cow", "Palace", "in", "Chicago", "."], "sentence-detokenized": "They unveiled their new robot in 1961 at a trade show at the Cow Palace in Chicago.", "token2charspan": [[0, 4], [5, 13], [14, 19], [20, 23], [24, 29], [30, 32], [33, 37], [38, 40], [41, 42], [43, 48], [49, 53], [54, 56], [57, 60], [61, 64], [65, 71], [72, 74], [75, 82], [82, 83]]}
{"doc_key": "ai-test-84", "ner": [[2, 2, "product"], [6, 7, "task"], [9, 11, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 6, 7, "usage", "", false, false], [2, 2, 9, 11, "usage", "", false, false], [2, 2, 14, 15, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["While", "some", "chatbot", "applications", "use", "extensive", "word", "sorting", ",", "natural", "language", "processors", "and", "sophisticated", "artificial", "intelligence", ",", "others", "simply", "scan", "for", "generic", "keywords", "and", "generate", "answers", "using", "common", "phrases", "taken", "from", "a", "relevant", "library", "or", "database", "."], "sentence-detokenized": "While some chatbot applications use extensive word sorting, natural language processors and sophisticated artificial intelligence, others simply scan for generic keywords and generate answers using common phrases taken from a relevant library or database.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 31], [32, 35], [36, 45], [46, 50], [51, 58], [58, 59], [60, 67], [68, 76], [77, 87], [88, 91], [92, 105], [106, 116], [117, 129], [129, 130], [131, 137], [138, 144], [145, 149], [150, 153], [154, 161], [162, 170], [171, 174], [175, 183], [184, 191], [192, 197], [198, 204], [205, 212], [213, 218], [219, 223], [224, 225], [226, 234], [235, 242], [243, 245], [246, 254], [254, 255]]}
{"doc_key": "ai-test-85", "ner": [[1, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "WaveNet", "model", "proposed", "in", "2016", "achieves", "great", "performance", "in", "speech", "quality", "."], "sentence-detokenized": "The WaveNet model proposed in 2016 achieves great performance in speech quality.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 43], [44, 49], [50, 61], [62, 64], [65, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-test-86", "ner": [[4, 4, "product"], [6, 7, "misc"], [9, 10, "misc"], [12, 13, "misc"], [15, 16, "misc"], [18, 18, "organisation"], [21, 24, "organisation"], [27, 53, "organisation"], [30, 55, "organisation"], [57, 58, "organisation"], [61, 61, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 8, 9, 10, 11, 12, 13], "relations": [[4, 4, 6, 7, "general-affiliation", "", false, false], [4, 4, 9, 10, "general-affiliation", "", false, false], [4, 4, 12, 13, "general-affiliation", "", false, false], [4, 4, 15, 16, "general-affiliation", "", false, false], [18, 18, 4, 4, "usage", "", false, false], [21, 24, 4, 4, "usage", "", false, false], [27, 53, 4, 4, "usage", "", false, false], [30, 55, 4, 4, "usage", "", false, false], [57, 58, 4, 4, "usage", "", false, false], [61, 61, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 7, 8, 9, 10, 11, 12], "sentence": ["Organizations", "known", "to", "use", "ALE", "for", "emergency", "management", ",", "disaster", "relief", ",", "routine", "communication", "or", "emergency", "response", ":", "NATO", ",", "the", "Federal", "Bureau", "of", "Investigation", ",", "the", "United", "Nations", ",", "AT&E", ",", "the", "United", "Nations", ",", "the", "United", "Nations", ",", "the", "United", "States", ",", "and", "the", "United", "States", ".", "The", "United", "Nations", ",", "UN", ",", "AT&T", ",", "Civil", "Aviation", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organizations known to use ALE for emergency management, disaster relief, routine communication or emergency response: NATO, the Federal Bureau of Investigation, the United Nations, AT&E, the United Nations, the United Nations, the United States, and the United States. The United Nations, UN, AT&T, Civil Aviation, (ARES).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 30], [31, 34], [35, 44], [45, 55], [55, 56], [57, 65], [66, 72], [72, 73], [74, 81], [82, 95], [96, 98], [99, 108], [109, 117], [117, 118], [119, 123], [123, 124], [125, 128], [129, 136], [137, 143], [144, 146], [147, 160], [160, 161], [162, 165], [166, 172], [173, 180], [180, 181], [182, 186], [186, 187], [188, 191], [192, 198], [199, 206], [206, 207], [208, 211], [212, 218], [219, 226], [226, 227], [228, 231], [232, 238], [239, 245], [245, 246], [247, 250], [251, 254], [255, 261], [262, 268], [268, 269], [270, 273], [274, 280], [281, 288], [288, 289], [290, 292], [292, 293], [294, 298], [298, 299], [300, 305], [306, 314], [314, 315], [316, 317], [317, 321], [321, 322], [322, 323]]}
{"doc_key": "ai-test-87", "ner": [[3, 4, "algorithm"], [15, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", ",", "the", "Kronecker", "delta", "is", "used", "for", "simplicity", "(", "see", "the", "derivative", "of", "a", "sigmoid", "function", ",", "which", "is", "expressed", "via", "the", "function", "itself", ")", "."], "sentence-detokenized": "Here, the Kronecker delta is used for simplicity (see the derivative of a sigmoid function, which is expressed via the function itself).", "token2charspan": [[0, 4], [4, 5], [6, 9], [10, 19], [20, 25], [26, 28], [29, 33], [34, 37], [38, 48], [49, 50], [50, 53], [54, 57], [58, 68], [69, 71], [72, 73], [74, 81], [82, 90], [90, 91], [92, 97], [98, 100], [101, 110], [111, 114], [115, 118], [119, 127], [128, 134], [134, 135], [135, 136]]}
{"doc_key": "ai-test-88", "ner": [[11, 12, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "theory", "is", "based", "on", "philosophical", "foundations", "and", "was", "founded", "by", "Ray", "Solomonoff", "around", "1960", ".", "Samuel", "Rathmanner", "and", "Marcus", "Hutter", "."], "sentence-detokenized": "The theory is based on philosophical foundations and was founded by Ray Solomonoff around 1960. Samuel Rathmanner and Marcus Hutter.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 36], [37, 48], [49, 52], [53, 56], [57, 64], [65, 67], [68, 71], [72, 82], [83, 89], [90, 94], [94, 95], [96, 102], [103, 113], [114, 117], [118, 124], [125, 131], [131, 132]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [10, 11, "misc"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 11, "type-of", "", false, false], [0, 0, 14, 15, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "a", "freely", "available", "database", "originally", "designed", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "has", "been", "expanded", "to", "include", "definitions", "and", "is", "now", "also", "considered", "a", "dictionary", "."], "sentence-detokenized": "WordNet, a freely available database originally designed as a semantic network based on psycholinguistic principles, has been expanded to include definitions and is now also considered a dictionary.", "token2charspan": [[0, 7], [7, 8], [9, 10], [11, 17], [18, 27], [28, 36], [37, 47], [48, 56], [57, 59], [60, 61], [62, 70], [71, 78], [79, 84], [85, 87], [88, 104], [105, 115], [115, 116], [117, 120], [121, 125], [126, 134], [135, 137], [138, 145], [146, 157], [158, 161], [162, 164], [165, 168], [169, 173], [174, 184], [185, 186], [187, 197], [197, 198]]}
{"doc_key": "ai-test-90", "ner": [[2, 3, "field"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 2, 3, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Developments", "in", "computational", "imaging", "research", "are", "presented", "in", "various", "venues", ",", "including", "SIGGRAPH", "and", "."], "sentence-detokenized": "Developments in computational imaging research are presented in various venues, including SIGGRAPH and.", "token2charspan": [[0, 12], [13, 15], [16, 29], [30, 37], [38, 46], [47, 50], [51, 60], [61, 63], [64, 71], [72, 78], [78, 79], [80, 89], [90, 98], [99, 102], [102, 103]]}
{"doc_key": "ai-test-91", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "viewed", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multi-category", "classification", "."], "sentence-detokenized": "Classification can be viewed as two separate problems - binary classification and multi-category classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 28], [29, 31], [32, 35], [36, 44], [45, 53], [54, 55], [56, 62], [63, 77], [78, 81], [82, 96], [97, 111], [111, 112]]}
{"doc_key": "ai-test-92", "ner": [[12, 12, "algorithm"], [17, 18, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 12, 12, "type-of", "", false, false], [21, 21, 17, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Advanced", "gene", "probes", "for", "both", "prokaryotic", "and", "eukaryotic", "genomes", "typically", "use", "complex", "probabilistic", "models", ",", "such", "as", "hidden", "Markov", "models", "(", "HMMs", ")", ",", "to", "combine", "information", "from", "a", "variety", "of", "different", "signal", "and", "content", "measurements", "."], "sentence-detokenized": "Advanced gene probes for both prokaryotic and eukaryotic genomes typically use complex probabilistic models, such as hidden Markov models (HMMs), to combine information from a variety of different signal and content measurements.", "token2charspan": [[0, 8], [9, 13], [14, 20], [21, 24], [25, 29], [30, 41], [42, 45], [46, 56], [57, 64], [65, 74], [75, 78], [79, 86], [87, 100], [101, 107], [107, 108], [109, 113], [114, 116], [117, 123], [124, 130], [131, 137], [138, 139], [139, 143], [143, 144], [144, 145], [146, 148], [149, 156], [157, 168], [169, 173], [174, 175], [176, 183], [184, 186], [187, 196], [197, 203], [204, 207], [208, 215], [216, 228], [228, 229]]}
{"doc_key": "ai-test-93", "ner": [[0, 0, "misc"], [2, 2, "misc"], [7, 8, "field"], [11, 12, "algorithm"], [15, 16, "algorithm"], [19, 19, "algorithm"], [29, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 7, 8, "part-of", "", false, false], [0, 0, 11, 12, "usage", "", false, false], [2, 2, 0, 0, "named", "", false, false], [15, 16, 0, 0, "origin", "", true, false], [19, 19, 15, 16, "named", "", false, false], [29, 30, 0, 0, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Neuroevolution", "or", "neuroevolution", "is", "a", "form", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "create", "artificial", "neural", "networks", "(", "ANNs", ")", ",", "parameters", ",", "topology", "and", "rules", ".", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuroevolution or neuroevolution is a form of artificial intelligence that uses evolutionary algorithms to create artificial neural networks (ANNs), parameters, topology and rules. and evolutionary robotics.", "token2charspan": [[0, 14], [15, 17], [18, 32], [33, 35], [36, 37], [38, 42], [43, 45], [46, 56], [57, 69], [70, 74], [75, 79], [80, 92], [93, 103], [104, 106], [107, 113], [114, 124], [125, 131], [132, 140], [141, 142], [142, 146], [146, 147], [147, 148], [149, 159], [159, 160], [161, 169], [170, 173], [174, 179], [179, 180], [181, 184], [185, 197], [198, 206], [206, 207]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [6, 6, "metrics"], [8, 8, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "IBM", "proposed", "and", "implemented", "the", "BLEU", "system", "Papineni", "et", "al", "."], "sentence-detokenized": "Since IBM proposed and implemented the BLEU system Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 34], [35, 38], [39, 43], [44, 50], [51, 59], [60, 62], [63, 65], [65, 66]]}
{"doc_key": "ai-test-95", "ner": [[13, 16, "conference"], [10, 18, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 18, 13, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "experts", "attended", "a", "conference", "organised", "by", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "to", "discuss", "whether", "computers", "and", "robots", "could", "gain", "autonomy", "and", "whether", "these", "capabilities", "could", "pose", "a", "threat", "or", "danger", "."], "sentence-detokenized": "In 2009, experts attended a conference organised by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether computers and robots could gain autonomy and whether these capabilities could pose a threat or danger.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 25], [26, 27], [28, 38], [39, 48], [49, 51], [52, 55], [56, 67], [68, 71], [72, 75], [76, 87], [88, 90], [91, 101], [102, 114], [115, 116], [116, 120], [120, 121], [122, 124], [125, 132], [133, 140], [141, 150], [151, 154], [155, 161], [162, 167], [168, 172], [173, 181], [182, 185], [186, 193], [194, 199], [200, 212], [213, 218], [219, 223], [224, 225], [226, 232], [233, 235], [236, 242], [242, 243]]}
{"doc_key": "ai-test-96", "ner": [[24, 25, "researcher"], [27, 28, "researcher"], [30, 35, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[30, 35, 24, 25, "artifact", "", false, false], [30, 35, 27, 28, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["After", "boosting", ",", "a", "classifier", "constructed", "from", "200", "features", "can", "yield", "a", "95", "%", "detection", "rate", "under", "a", "^", "{", "-", "5", "}", "/", "P.", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "After boosting, a classifier constructed from 200 features can yield a 95% detection rate under a ^ {-5} / P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 17], [18, 28], [29, 40], [41, 45], [46, 49], [50, 58], [59, 62], [63, 68], [69, 70], [71, 73], [73, 74], [75, 84], [85, 89], [90, 95], [96, 97], [98, 99], [100, 101], [101, 102], [102, 103], [103, 104], [105, 106], [107, 109], [110, 115], [115, 116], [117, 119], [120, 125], [125, 126], [127, 133], [134, 138], [138, 139], [139, 143], [144, 150], [151, 160], [160, 161], [162, 166], [166, 167]]}
{"doc_key": "ai-test-97", "ner": [[6, 6, "programlang"], [9, 9, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "site", "was", "originally", "based", "on", "Perl", ",", "but", "IMDb", "no", "longer", "discloses", "what", "software", "it", "uses", "for", "security", "reasons", "."], "sentence-detokenized": "The site was originally based on Perl, but IMDb no longer discloses what software it uses for security reasons.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 23], [24, 29], [30, 32], [33, 37], [37, 38], [39, 42], [43, 47], [48, 50], [51, 57], [58, 67], [68, 72], [73, 81], [82, 84], [85, 89], [90, 93], [94, 102], [103, 110], [110, 111]]}
{"doc_key": "ai-test-98", "ner": [[7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "start", "-", "up", "was", "founded", "by", "Demis", "Hassabis", ",", "Shane", "Legg", "and", "Mustafa", "Suleyman", "in", "2010", "."], "sentence-detokenized": "The start-up was founded by Demis Hassabis, Shane Legg and Mustafa Suleyman in 2010.", "token2charspan": [[0, 3], [4, 9], [9, 10], [10, 12], [13, 16], [17, 24], [25, 27], [28, 33], [34, 42], [42, 43], [44, 49], [50, 54], [55, 58], [59, 66], [67, 75], [76, 78], [79, 83], [83, 84]]}
{"doc_key": "ai-test-99", "ner": [[4, 5, "misc"], [8, 10, "metrics"], [25, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 4, 5, "type-of", "", false, false], [25, 26, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "very", "commonly", "used", "loss", "functions", "are", "the", "mean", "squared", "error", ",", "mathL", "(", "a", ")", "=", "a", "^", "2", "/", "math", ",", "and", "the", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "|", "/", "math", "."], "sentence-detokenized": "Two very commonly used loss functions are the mean squared error, mathL (a) = a ^ 2 / math, and the absolute loss, mathL (a) = | a | | / math.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 27], [28, 37], [38, 41], [42, 45], [46, 50], [51, 58], [59, 64], [64, 65], [66, 71], [72, 73], [73, 74], [74, 75], [76, 77], [78, 79], [80, 81], [82, 83], [84, 85], [86, 90], [90, 91], [92, 95], [96, 99], [100, 108], [109, 113], [113, 114], [115, 120], [121, 122], [122, 123], [123, 124], [125, 126], [127, 128], [129, 130], [131, 132], [133, 134], [135, 136], [137, 141], [141, 142]]}
{"doc_key": "ai-test-100", "ner": [[3, 5, "algorithm"], [13, 14, "algorithm"], [12, 16, "algorithm"], [19, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 13, 14, "type-of", "example_of", false, false], [13, 14, 19, 21, "related-to", "", false, false], [12, 16, 13, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "soft", "-margin", "support", "vector", "machine", "described", "above", "is", "an", "example", "of", "empirical", "risk", "minimization", "(", "ERM", ")", "for", "joi", "nt", "loss", "."], "sentence-detokenized": "The soft-margin support vector machine described above is an example of empirical risk minimization (ERM) for joint loss.", "token2charspan": [[0, 3], [4, 8], [8, 15], [16, 23], [24, 30], [31, 38], [39, 48], [49, 54], [55, 57], [58, 60], [61, 68], [69, 71], [72, 81], [82, 86], [87, 99], [100, 101], [101, 104], [104, 105], [106, 109], [110, 113], [113, 115], [116, 120], [120, 121]]}
{"doc_key": "ai-test-101", "ner": [[8, 10, "field"], [11, 11, "task"], [0, 2, "task"], [21, 21, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 8, 10, "origin", "", false, false], [0, 2, 11, 11, "type-of", "", false, false], [21, 21, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Neural", "machine", "translation", ",", "an", "approach", "based", "on", "deep", "learning", "in", "MT", ",", "has", "made", "rapid", "progress", "in", "recent", "years", "and", "Google", "has", "announced", "that", "its", "translation", "services", "now", "use", "this", "technology", "instead", "of", "the", "previous", "statistical", "methods", "."], "sentence-detokenized": "Neural machine translation, an approach based on deep learning in MT, has made rapid progress in recent years and Google has announced that its translation services now use this technology instead of the previous statistical methods.", "token2charspan": [[0, 6], [7, 14], [15, 26], [26, 27], [28, 30], [31, 39], [40, 45], [46, 48], [49, 53], [54, 62], [63, 65], [66, 68], [68, 69], [70, 73], [74, 78], [79, 84], [85, 93], [94, 96], [97, 103], [104, 109], [110, 113], [114, 120], [121, 124], [125, 134], [135, 139], [140, 143], [144, 155], [156, 164], [165, 168], [169, 172], [173, 177], [178, 188], [189, 196], [197, 199], [200, 203], [204, 212], [213, 224], [225, 232], [232, 233]]}
{"doc_key": "ai-test-102", "ner": [[18, 18, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "tends", "to", "yield", "very", "large", "performance", "gains", "when", "working", "with", "large", "bodies", "of", "text", ",", "such", "as", "WordNet", "."], "sentence-detokenized": "This tends to yield very large performance gains when working with large bodies of text, such as WordNet.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 19], [20, 24], [25, 30], [31, 42], [43, 48], [49, 53], [54, 61], [62, 66], [67, 72], [73, 79], [80, 82], [83, 87], [87, 88], [89, 93], [94, 96], [97, 104], [104, 105]]}
{"doc_key": "ai-test-103", "ner": [[0, 1, "task"], [5, 5, "field"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 17, 19, "part-of", "", false, false], [17, 19, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Face", "detection", "is", "used", "in", "biometrics", ",", "often", "as", "part", "of", "(", "or", "together", "with", ")", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Face detection is used in biometrics, often as part of (or together with) a facial recognition system.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 22], [23, 25], [26, 36], [36, 37], [38, 43], [44, 46], [47, 51], [52, 54], [55, 56], [56, 58], [59, 67], [68, 72], [72, 73], [74, 75], [76, 82], [83, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-104", "ner": [[2, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["trained", "with", "maximum", "likelihood", "estimation", "."], "sentence-detokenized": "trained with maximum likelihood estimation.", "token2charspan": [[0, 7], [8, 12], [13, 20], [21, 31], [32, 42], [42, 43]]}
{"doc_key": "ai-test-105", "ner": [[5, 10, "organisation"], [13, 13, "location"], [17, 20, "organisation"], [22, 22, "country"], [28, 28, "organisation"], [33, 37, "organisation"], [39, 39, "country"], [50, 53, "organisation"], [55, 55, "country"]], "ner_mapping_to_source": [1, 2, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 10, 13, 13, "physical", "", false, false], [17, 20, 22, 22, "physical", "", false, false], [33, 37, 39, 39, "physical", "", false, false], [50, 53, 55, 55, "physical", "", false, false]], "relations_mapping_to_source": [0, 2, 3, 4], "sentence": ["Ltd", ".", "in", "Thailand", ";", "Komatsu", "(", "Shanghai", ")", "Ltd.", "in", "1996", "in", "Shanghai", ",", "China", ";", "Industrial", "Power", "Alliance", "Ltd.", "in", "Japan", ",", "a", "joint", "venture", "with", "Cummins", ",", "in", "1998", ";", "L", "&", "T-", "Komatsu", "Limited", "in", "India", "in", "1998", "(", "shares", "sold", "in", "2013", ")", ";", "and", "Komatsu", "Brasil", "International", "Ltda.", "in", "Brazil", "in", "1998", "."], "sentence-detokenized": "Ltd. in Thailand; Komatsu (Shanghai) Ltd. in 1996 in Shanghai, China; Industrial Power Alliance Ltd. in Japan, a joint venture with Cummins, in 1998; L & T-Komatsu Limited in India in 1998 (shares sold in 2013); and Komatsu Brasil International Ltda. in Brazil in 1998.", "token2charspan": [[0, 3], [3, 4], [5, 7], [8, 16], [16, 17], [18, 25], [26, 27], [27, 35], [35, 36], [37, 41], [42, 44], [45, 49], [50, 52], [53, 61], [61, 62], [63, 68], [68, 69], [70, 80], [81, 86], [87, 95], [96, 100], [101, 103], [104, 109], [109, 110], [111, 112], [113, 118], [119, 126], [127, 131], [132, 139], [139, 140], [141, 143], [144, 148], [148, 149], [150, 151], [152, 153], [154, 156], [156, 163], [164, 171], [172, 174], [175, 180], [181, 183], [184, 188], [189, 190], [190, 196], [197, 201], [202, 204], [205, 209], [209, 210], [210, 211], [212, 215], [216, 223], [224, 230], [231, 244], [245, 250], [251, 253], [254, 260], [261, 263], [264, 268], [268, 269]]}
{"doc_key": "ai-test-106", "ner": [[0, 1, "organisation"], [5, 7, "misc"], [10, 10, "misc"], [11, 12, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 0, 1, "physical", "", false, false], [11, 12, 5, 7, "general-affiliation", "", false, false], [11, 12, 10, 10, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "dgp", "also", "occasionally", "hosts", "artists", "in", "residence", "(", "e.g.", "Oscar-winning", "Chris", "Landreth", "."], "sentence-detokenized": "The dgp also occasionally hosts artists in residence (e.g. Oscar-winning Chris Landreth.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 25], [26, 31], [32, 39], [40, 42], [43, 52], [53, 54], [54, 58], [59, 72], [73, 78], [79, 87], [87, 88]]}
{"doc_key": "ai-test-107", "ner": [[7, 9, "misc"], [12, 14, "misc"], [17, 21, "misc"], [25, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "currently", "includes", "four", "sub-competitions", "-", "the", "RoboMaster", "robotics", "competition", ",", "the", "RoboMaster", "technical", "competition", ",", "the", "ICRA", "RoboMaster", "artificial", "intelligence", "competition", "and", "the", "new", "RoboMaster", "youth", "tournament", "."], "sentence-detokenized": "It currently includes four sub-competitions - the RoboMaster robotics competition, the RoboMaster technical competition, the ICRA RoboMaster artificial intelligence competition and the new RoboMaster youth tournament.", "token2charspan": [[0, 2], [3, 12], [13, 21], [22, 26], [27, 43], [44, 45], [46, 49], [50, 60], [61, 69], [70, 81], [81, 82], [83, 86], [87, 97], [98, 107], [108, 119], [119, 120], [121, 124], [125, 129], [130, 140], [141, 151], [152, 164], [165, 176], [177, 180], [181, 184], [185, 188], [189, 199], [200, 205], [206, 216], [216, 217]]}
{"doc_key": "ai-test-108", "ner": [[7, 8, "field"], [15, 17, "algorithm"], [21, 22, "algorithm"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 21, 22, "usage", "", false, false], [7, 8, 24, 25, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["By", "the", "early", "2000s", ",", "the", "dominant", "speech", "processing", "strategy", "began", "to", "shift", "from", "the", "Hidden", "Markov", "model", "to", "more", "modern", "neural", "networks", "and", "deep", "learning", "."], "sentence-detokenized": "By the early 2000s, the dominant speech processing strategy began to shift from the Hidden Markov model to more modern neural networks and deep learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 18], [18, 19], [20, 23], [24, 32], [33, 39], [40, 50], [51, 59], [60, 65], [66, 68], [69, 74], [75, 79], [80, 83], [84, 90], [91, 97], [98, 103], [104, 106], [107, 111], [112, 118], [119, 125], [126, 134], [135, 138], [139, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-test-109", "ner": [[9, 11, "misc"], [16, 18, "metrics"], [21, 23, "metrics"], [30, 32, "metrics"], [35, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 18, 21, 23, "related-to", "equal", false, false], [30, 32, 35, 37, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "equivalent", "expression", ",", "in", "the", "case", "of", "a", "binary", "target", "rate", ",", "is", "that", "the", "TRUE", "positive", "rate", "and", "the", "FALSE", "positive", "rate", "are", "equal", "(", "and", "therefore", "the", "FALSE", "negative", "rate", "and", "the", "TRUE", "negative", "rate", "are", "equal", ")", "for", "each", "value", "of", "the", "sensitive", "features", ":"], "sentence-detokenized": "Another equivalent expression, in the case of a binary target rate, is that the TRUE positive rate and the FALSE positive rate are equal (and therefore the FALSE negative rate and the TRUE negative rate are equal) for each value of the sensitive features:", "token2charspan": [[0, 7], [8, 18], [19, 29], [29, 30], [31, 33], [34, 37], [38, 42], [43, 45], [46, 47], [48, 54], [55, 61], [62, 66], [66, 67], [68, 70], [71, 75], [76, 79], [80, 84], [85, 93], [94, 98], [99, 102], [103, 106], [107, 112], [113, 121], [122, 126], [127, 130], [131, 136], [137, 138], [138, 141], [142, 151], [152, 155], [156, 161], [162, 170], [171, 175], [176, 179], [180, 183], [184, 188], [189, 197], [198, 202], [203, 206], [207, 212], [212, 213], [214, 217], [218, 222], [223, 228], [229, 231], [232, 235], [236, 245], [246, 254], [254, 255]]}
{"doc_key": "ai-test-110", "ner": [[1, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "MATLAB", "function", ","], "sentence-detokenized": "The MATLAB function,", "token2charspan": [[0, 3], [4, 10], [11, 19], [19, 20]]}
{"doc_key": "ai-test-111", "ner": [[1, 2, "product"], [7, 7, "misc"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 1, 2, "part-of", "", false, false], [16, 17, 1, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "articulated", "robot", "is", "a", "robot", "with", "rotating", "joints", "(", "e.g.", "a", "walking", "robot", "or", "an", "industrial", "robot", ")", "."], "sentence-detokenized": "An articulated robot is a robot with rotating joints (e.g. a walking robot or an industrial robot).", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 23], [24, 25], [26, 31], [32, 36], [37, 45], [46, 52], [53, 54], [54, 58], [59, 60], [61, 68], [69, 74], [75, 77], [78, 80], [81, 91], [92, 97], [97, 98], [98, 99]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [5, 6, "product"], [8, 9, "product"], [13, 13, "misc"], [21, 25, "product"], [27, 29, "misc"], [33, 33, "location"], [35, 35, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 13, 13, "general-affiliation", "nationality", false, false], [0, 0, 27, 29, "usage", "", false, false], [0, 0, 33, 33, "physical", "", false, false], [5, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [33, 33, 35, 35, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "also", "known", "as", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "an", "American", "music", "streaming", "internet", "radio", "service", "with", "an", "automated", "recommendation", "system", "powered", "by", "the", "Music", "Genome", "Project", "and", "based", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (also known as Pandora Media or Pandora Radio) is an American music streaming internet radio service with an automated recommendation system powered by the Music Genome Project and based in Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 30], [31, 36], [37, 39], [40, 47], [48, 53], [53, 54], [55, 57], [58, 60], [61, 69], [70, 75], [76, 85], [86, 94], [95, 100], [101, 108], [109, 113], [114, 116], [117, 126], [127, 141], [142, 148], [149, 156], [157, 159], [160, 163], [164, 169], [170, 176], [177, 184], [185, 188], [189, 194], [195, 197], [198, 205], [205, 206], [207, 217], [217, 218]]}
{"doc_key": "ai-test-113", "ner": [[7, 10, "organisation"], [18, 20, "organisation"], [26, 27, "conference"], [41, 41, "conference"], [43, 43, "conference"], [45, 45, "conference"], [47, 47, "conference"], [49, 49, "conference"], [51, 51, "conference"], [53, 53, "conference"], [55, 55, "conference"], [57, 57, "conference"], [60, 60, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "board", "member", "of", "the", "International", "Machine", "Learning", "Society", ",", "has", "been", "a", "member", "of", "the", "AAAI", "executive", "board", ",", "was", "PC", "co-chair", "at", "ICML", "2011", ",", "and", "has", "served", "as", "a", "senior", "PC", "member", "at", "conferences", "such", "as", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", ",", "and", "WWW", "."], "sentence-detokenized": "He is a board member of the International Machine Learning Society, has been a member of the AAAI executive board, was PC co-chair at ICML 2011, and has served as a senior PC member at conferences such as AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM, and WWW.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 13], [14, 20], [21, 23], [24, 27], [28, 41], [42, 49], [50, 58], [59, 66], [66, 67], [68, 71], [72, 76], [77, 78], [79, 85], [86, 88], [89, 92], [93, 97], [98, 107], [108, 113], [113, 114], [115, 118], [119, 121], [122, 130], [131, 133], [134, 138], [139, 143], [143, 144], [145, 148], [149, 152], [153, 159], [160, 162], [163, 164], [165, 171], [172, 174], [175, 181], [182, 184], [185, 196], [197, 201], [202, 204], [205, 209], [209, 210], [211, 215], [215, 216], [217, 222], [222, 223], [224, 228], [228, 229], [230, 233], [233, 234], [235, 241], [241, 242], [243, 246], [246, 247], [248, 252], [252, 253], [254, 258], [258, 259], [260, 263], [264, 267], [267, 268]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [8, 10, "organisation"], [5, 12, "organisation"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 8, 10, "role", "", false, false], [5, 12, 8, 10, "named", "", false, false], [16, 16, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "developed", "the", "Robocrane", ",", "where", "the", "platform", "hangs", "from", "six", "cables", "instead", "of", "being", "supported", "by", "six", "jacks", "."], "sentence-detokenized": "James S. Albus of the National Institute of Standards and Technology (NIST) developed the Robocrane, where the platform hangs from six cables instead of being supported by six jacks.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [74, 75], [76, 85], [86, 89], [90, 99], [99, 100], [101, 106], [107, 110], [111, 119], [120, 125], [126, 130], [131, 134], [135, 141], [142, 149], [150, 152], [153, 158], [159, 168], [169, 171], [172, 175], [176, 181], [181, 182]]}
{"doc_key": "ai-test-115", "ner": [[3, 5, "algorithm"], [8, 9, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 5, "type-of", "", false, false], [12, 13, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "category", "of", "direct", "search", "algorithms", "are", "various", "evolutionary", "algorithms", ",", "e.g.", "genetic", "algorithms", "."], "sentence-detokenized": "Another category of direct search algorithms are various evolutionary algorithms, e.g. genetic algorithms.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 26], [27, 33], [34, 44], [45, 48], [49, 56], [57, 69], [70, 80], [80, 81], [82, 86], [87, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-test-116", "ner": [[0, 0, "organisation"], [3, 3, "misc"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 0, "named", "", false, false], [6, 7, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "industrial", "robots", "and", "factory", "automation", "solutions", "."], "sentence-detokenized": "KUKA is a German manufacturer of industrial robots and factory automation solutions.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-117", "ner": [[8, 8, "misc"], [11, 11, "person"], [14, 20, "misc"], [22, 23, "person"], [25, 25, "misc"], [27, 28, "person"], [30, 31, "misc"], [33, 34, "person"], [36, 38, "misc"], [40, 41, "person"], [43, 47, "misc"], [49, 49, "person"], [51, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[11, 11, 8, 8, "usage", "", false, false], [14, 20, 11, 11, "artifact", "", false, false], [22, 23, 8, 8, "usage", "", false, false], [25, 25, 22, 23, "artifact", "", false, false], [27, 28, 8, 8, "usage", "", false, false], [30, 31, 27, 28, "artifact", "", false, false], [33, 34, 8, 8, "usage", "", false, false], [36, 38, 33, 34, "artifact", "", false, false], [40, 41, 8, 8, "usage", "", false, false], [43, 47, 40, 41, "artifact", "", false, false], [49, 49, 8, 8, "usage", "", false, false], [51, 55, 49, 49, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Other", "films", "between", "2016", "and", "2020", "shot", "with", "IMAX", "cameras", "included", "Zack", "Snyder", "'s", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", ",", "Clint", "Eastwood", "'s", "Sully", ",", "Damien", "Chazelle", "'s", "First", "Man", ",", "Patty", "Jenkins", "'", "Wonder", "Woman", "1984", ",", "Cary", "Joji", "Fukunaga", "'s", "No", "Time", "to", "Die", "and", "Joseph", "Kosinski", "'s", "Top", "Gun", ":", "Maverick", "."], "sentence-detokenized": "Other films between 2016 and 2020 shot with IMAX cameras included Zack Snyder's Batman v Superman: Dawn of Justice, Clint Eastwood's Sully, Damien Chazelle's First Man, Patty Jenkins' Wonder Woman 1984, Cary Joji Fukunaga's No Time to Die and Joseph Kosinski's Top Gun: Maverick.", "token2charspan": [[0, 5], [6, 11], [12, 19], [20, 24], [25, 28], [29, 33], [34, 38], [39, 43], [44, 48], [49, 56], [57, 65], [66, 70], [71, 77], [77, 79], [80, 86], [87, 88], [89, 97], [97, 98], [99, 103], [104, 106], [107, 114], [114, 115], [116, 121], [122, 130], [130, 132], [133, 138], [138, 139], [140, 146], [147, 155], [155, 157], [158, 163], [164, 167], [167, 168], [169, 174], [175, 182], [182, 183], [184, 190], [191, 196], [197, 201], [201, 202], [203, 207], [208, 212], [213, 221], [221, 223], [224, 226], [227, 231], [232, 234], [235, 238], [239, 242], [243, 249], [250, 258], [258, 260], [261, 264], [265, 268], [268, 269], [270, 278], [278, 279]]}
{"doc_key": "ai-test-118", "ner": [[0, 2, "misc"], [9, 13, "organisation"], [26, 26, "misc"], [33, 34, "country"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[0, 2, 26, 26, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "MICR", "E13B", "test", "typeface", "was", "presented", "to", "the", "American", "Bankers", "Association", "(", "ABA", ")", "in", "July", "1956", ",", "which", "adopted", "it", "in", "1958", "as", "the", "MICR", "standard", "for", "negotiable", "documents", "in", "the", "United", "States", "."], "sentence-detokenized": "The MICR E13B test typeface was presented to the American Bankers Association (ABA) in July 1956, which adopted it in 1958 as the MICR standard for negotiable documents in the United States.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 18], [19, 27], [28, 31], [32, 41], [42, 44], [45, 48], [49, 57], [58, 65], [66, 77], [78, 79], [79, 82], [82, 83], [84, 86], [87, 91], [92, 96], [96, 97], [98, 103], [104, 111], [112, 114], [115, 117], [118, 122], [123, 125], [126, 129], [130, 134], [135, 143], [144, 147], [148, 158], [159, 168], [169, 171], [172, 175], [176, 182], [183, 189], [189, 190]]}
{"doc_key": "ai-test-119", "ner": [[0, 3, "misc"], [15, 16, "field"], [20, 21, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 16, 0, 3, "usage", "", false, false], [20, 21, 15, 16, "part-of", "", false, false], [24, 24, 0, 3, "usage", "", false, false], [26, 27, 0, 3, "usage", "", false, false], [29, 29, 0, 3, "usage", "", false, false], [31, 31, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "are", "widely", "applied", "to", "numerous", "difficult", "computational", "problems", ",", "including", "problems", "from", "computer", "science", "(", "in", "particular", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms are widely applied to numerous difficult computational problems, including problems from computer science (in particular artificial intelligence), mathematics, operations research, engineering and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 27], [28, 34], [35, 42], [43, 45], [46, 54], [55, 64], [65, 78], [79, 87], [87, 88], [89, 98], [99, 107], [108, 112], [113, 121], [122, 129], [130, 131], [131, 133], [134, 144], [145, 155], [156, 168], [168, 169], [169, 170], [171, 182], [182, 183], [184, 194], [195, 203], [203, 204], [205, 216], [217, 220], [221, 235], [235, 236]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [8, 8, "location"], [10, 10, "country"], [14, 14, "country"], [22, 23, "algorithm"], [25, 25, "algorithm"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 8, 8, "physical", "", false, false], [0, 1, 14, 14, "general-affiliation", "nationality", false, false], [0, 1, 22, 23, "general-affiliation", "topic_of_study", false, false], [0, 1, 25, 25, "general-affiliation", "topic_of_study", false, false], [8, 8, 10, 10, "physical", "", false, false], [25, 25, 27, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "born", "3", "September", "1947", "in", "Wallersdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "has", "studied", "the", "use", "of", "bounded", "rationality", "and", "heuristics", "in", "decision", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (born 3 September 1947 in Wallersdorf, Germany) is a German psychologist who has studied the use of bounded rationality and heuristics in decision making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 21], [22, 23], [24, 33], [34, 38], [39, 41], [42, 53], [53, 54], [55, 62], [62, 63], [64, 66], [67, 68], [69, 75], [76, 88], [89, 92], [93, 96], [97, 104], [105, 108], [109, 112], [113, 115], [116, 123], [124, 135], [136, 139], [140, 150], [151, 153], [154, 162], [163, 169], [169, 170]]}
{"doc_key": "ai-test-121", "ner": [[3, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["to", "minimise", "the", "mean", "square", "error", "."], "sentence-detokenized": "to minimise the mean square error.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [21, 27], [28, 33], [33, 34]]}
{"doc_key": "ai-test-122", "ner": [[12, 13, "misc"], [16, 17, "organisation"], [33, 35, "field"], [52, 53, "misc"], [62, 64, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 16, 17, "origin", "", false, false], [52, 53, 62, 64, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["But", "even", "a", "formal", "language", "with", "a", "regulatory", "academy", ",", "such", "as", "standard", "French", "with", "the", "Acad\u00e9mie", "fran\u00e7aise", ",", "is", "classified", "as", "a", "natural", "language", "(", "for", "example", ",", "in", "the", "field", "of", "natural", "language", "processing", ")", ",", "since", "its", "normative", "points", "make", "it", "neither", "constructed", "enough", "to", "be", "classified", "as", "a", "constructed", "language", "nor", "controlled", "enough", "to", "be", "classified", "as", "a", "controlled", "natural", "language", "."], "sentence-detokenized": "But even a formal language with a regulatory academy, such as standard French with the Acad\u00e9mie fran\u00e7aise, is classified as a natural language (for example, in the field of natural language processing), since its normative points make it neither constructed enough to be classified as a constructed language nor controlled enough to be classified as a controlled natural language.", "token2charspan": [[0, 3], [4, 8], [9, 10], [11, 17], [18, 26], [27, 31], [32, 33], [34, 44], [45, 52], [52, 53], [54, 58], [59, 61], [62, 70], [71, 77], [78, 82], [83, 86], [87, 95], [96, 105], [105, 106], [107, 109], [110, 120], [121, 123], [124, 125], [126, 133], [134, 142], [143, 144], [144, 147], [148, 155], [155, 156], [157, 159], [160, 163], [164, 169], [170, 172], [173, 180], [181, 189], [190, 200], [200, 201], [201, 202], [203, 208], [209, 212], [213, 222], [223, 229], [230, 234], [235, 237], [238, 245], [246, 257], [258, 264], [265, 267], [268, 270], [271, 281], [282, 284], [285, 286], [287, 298], [299, 307], [308, 311], [312, 322], [323, 329], [330, 332], [333, 335], [336, 346], [347, 349], [350, 351], [352, 362], [363, 370], [371, 379], [379, 380]]}
{"doc_key": "ai-test-123", "ner": [[11, 11, "metrics"], [14, 15, "metrics"], [17, 17, "metrics"], [36, 37, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 17, 14, 15, "named", "", false, false], [39, 39, 36, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "a", "number", "of", "other", "metrics", ",", "the", "simplest", "being", "precision", "or", "the", "fraction", "correct", "(", "FC", ")", ",", "which", "measures", "the", "fraction", "of", "all", "cases", "that", "are", "correctly", "categorised", ";", "the", "complement", "is", "the", "fraction", "incorrect", "(", "FiC", ")", "."], "sentence-detokenized": "There are a number of other metrics, the simplest being precision or the fraction correct (FC), which measures the fraction of all cases that are correctly categorised; the complement is the fraction incorrect (FiC).", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 18], [19, 21], [22, 27], [28, 35], [35, 36], [37, 40], [41, 49], [50, 55], [56, 65], [66, 68], [69, 72], [73, 81], [82, 89], [90, 91], [91, 93], [93, 94], [94, 95], [96, 101], [102, 110], [111, 114], [115, 123], [124, 126], [127, 130], [131, 136], [137, 141], [142, 145], [146, 155], [156, 167], [167, 168], [169, 172], [173, 183], [184, 186], [187, 190], [191, 199], [200, 209], [210, 211], [211, 214], [214, 215], [215, 216]]}
{"doc_key": "ai-test-124", "ner": [[0, 1, "researcher"], [3, 7, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 3, 7, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "joined", "the", "Association", "for", "Computational", "Linguistics", "in", "2016", "."], "sentence-detokenized": "Cardie joined the Association for Computational Linguistics in 2016.", "token2charspan": [[0, 6], [7, 13], [14, 17], [18, 29], [30, 33], [34, 47], [48, 59], [60, 62], [63, 67], [67, 68]]}
{"doc_key": "ai-test-125", "ner": [[12, 14, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Learning", "the", "parameters", "math", "\\", "theta", "/", "math", "is", "usually", "done", "by", "learning", "maximum", "likelihood", "for", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";\\", "theta", ")", "/", "math", "."], "sentence-detokenized": "Learning the parameters math\\ theta / math is usually done by learning maximum likelihood for mathp (Y _ i | X _ i;\\ theta) / math.", "token2charspan": [[0, 8], [9, 12], [13, 23], [24, 28], [28, 29], [30, 35], [36, 37], [38, 42], [43, 45], [46, 53], [54, 58], [59, 61], [62, 70], [71, 78], [79, 89], [90, 93], [94, 99], [100, 101], [101, 102], [103, 104], [105, 106], [107, 108], [109, 110], [111, 112], [113, 114], [114, 116], [117, 122], [122, 123], [124, 125], [126, 130], [130, 131]]}
{"doc_key": "ai-test-126", "ner": [[0, 1, "task"], [3, 6, "algorithm"], [8, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 0, 1, "usage", "", true, false], [8, 9, 3, 6, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cluster", "analysis", "and", "factorization", "of", "nonnegative", "matrices", "for", "descriptive", "mining", "."], "sentence-detokenized": "Cluster analysis and factorization of nonnegative matrices for descriptive mining.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 34], [35, 37], [38, 49], [50, 58], [59, 62], [63, 74], [75, 81], [81, 82]]}
{"doc_key": "ai-test-127", "ner": [[1, 2, "field"], [5, 7, "field"], [16, 18, "field"], [20, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 18, 1, 2, "part-of", "", false, false], [16, 18, 5, 7, "part-of", "", false, false], [20, 23, 1, 2, "part-of", "", false, false], [20, 23, 5, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", "and", "the", "information", "technology", "it", "enables", ",", "the", "ability", "of", "computers", "to", "do", "natural", "language", "processing", "and", "machine", "learning", "is", "a", "long", "-", "standing", "challenge", "."], "sentence-detokenized": "In computer science and the information technology it enables, the ability of computers to do natural language processing and machine learning is a long-standing challenge.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 23], [24, 27], [28, 39], [40, 50], [51, 53], [54, 61], [61, 62], [63, 66], [67, 74], [75, 77], [78, 87], [88, 90], [91, 93], [94, 101], [102, 110], [111, 121], [122, 125], [126, 133], [134, 142], [143, 145], [146, 147], [148, 152], [152, 153], [153, 161], [162, 171], [171, 172]]}
{"doc_key": "ai-test-128", "ner": [[4, 6, "algorithm"], [10, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 10, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "The", "code", "for", "extracting", "Gabor", "features", "from", "images", "in", "MATLAB", "can", "be", "found", "at"], "sentence-detokenized": "(The code for extracting Gabor features from images in MATLAB can be found at", "token2charspan": [[0, 1], [1, 4], [5, 9], [10, 13], [14, 24], [25, 30], [31, 39], [40, 44], [45, 51], [52, 54], [55, 61], [62, 65], [66, 68], [69, 74], [75, 77]]}
{"doc_key": "ai-test-129", "ner": [[0, 0, "misc"], [14, 15, "algorithm"], [19, 19, "task"], [21, 21, "task"], [23, 24, "task"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 14, 15, "general-affiliation", "", false, false], [0, 0, 19, 19, "related-to", "solves_problem_of_type", false, false], [0, 0, 21, 21, "related-to", "solves_problem_of_type", false, false], [0, 0, 23, 24, "related-to", "solves_problem_of_type", false, false], [0, 0, 26, 27, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["NeuralExpert", "centers", "the", "design", "specification", "around", "the", "type", "of", "problem", "the", "user", "wants", "the", "neural", "network", "to", "solve", "(", "classification", ",", "prediction", ",", "function", "approximation", "or", "cluster", "analysis", ")", "."], "sentence-detokenized": "NeuralExpert centers the design specification around the type of problem the user wants the neural network to solve (classification, prediction, function approximation or cluster analysis).", "token2charspan": [[0, 12], [13, 20], [21, 24], [25, 31], [32, 45], [46, 52], [53, 56], [57, 61], [62, 64], [65, 72], [73, 76], [77, 81], [82, 87], [88, 91], [92, 98], [99, 106], [107, 109], [110, 115], [116, 117], [117, 131], [131, 132], [133, 143], [143, 144], [145, 153], [154, 167], [168, 170], [171, 178], [179, 187], [187, 188], [188, 189]]}
{"doc_key": "ai-test-130", "ner": [[2, 6, "misc"], [30, 32, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "size", "of", "the", "quantization", "step", "(", "D", ")", "is", "small", "relative", "to", "the", "variance", "of", "the", "signal", "being", "quantized", ",", "it", "is", "relatively", "simple", "to", "show", "that", "the", "mean", "square", "error", "produced", "by", "such", "a", "rounding", "operation", "will", "be", "about", "math", "\\", "Delta", "^", "2", "/", "12", "/", "math.math"], "sentence-detokenized": "When the size of the quantization step (D) is small relative to the variance of the signal being quantized, it is relatively simple to show that the mean square error produced by such a rounding operation will be about math\\ Delta ^ 2 / 12 / math.math", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 20], [21, 33], [34, 38], [39, 40], [40, 41], [41, 42], [43, 45], [46, 51], [52, 60], [61, 63], [64, 67], [68, 76], [77, 79], [80, 83], [84, 90], [91, 96], [97, 106], [106, 107], [108, 110], [111, 113], [114, 124], [125, 131], [132, 134], [135, 139], [140, 144], [145, 148], [149, 153], [154, 160], [161, 166], [167, 175], [176, 178], [179, 183], [184, 185], [186, 194], [195, 204], [205, 209], [210, 212], [213, 218], [219, 223], [223, 224], [225, 230], [231, 232], [233, 234], [235, 236], [237, 239], [240, 241], [242, 251]]}
{"doc_key": "ai-test-131", "ner": [[14, 14, "product"], [24, 27, "researcher"], [29, 30, "researcher"], [32, 34, "researcher"], [36, 37, "researcher"], [39, 41, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Building", "a", "rich", "dictionary", "with", "an", "appropriate", "ontology", "requires", "considerable", "effort", ",", "e.g.", "the", "Wordnet", "dictionary", "required", "many", "man", "-", "years", "of", "effort", ".", "G.", "A", ".", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "Building a rich dictionary with an appropriate ontology requires considerable effort, e.g. the Wordnet dictionary required many man-years of effort. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 8], [9, 10], [11, 15], [16, 26], [27, 31], [32, 34], [35, 46], [47, 55], [56, 64], [65, 77], [78, 84], [84, 85], [86, 90], [91, 94], [95, 102], [103, 113], [114, 122], [123, 127], [128, 131], [131, 132], [132, 137], [138, 140], [141, 147], [147, 148], [149, 151], [152, 153], [153, 154], [155, 161], [161, 162], [163, 165], [166, 174], [174, 175], [176, 178], [179, 181], [182, 190], [190, 191], [192, 194], [195, 200], [200, 201], [202, 203], [203, 204], [205, 211], [211, 212]]}
{"doc_key": "ai-test-132", "ner": [[0, 1, "organisation"], [16, 17, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kawasaki", "'s", "portfolio", "also", "includes", "retractable", "roofs", ",", "floors", "and", "other", "giant", "structures", ",", "with", "the", "Sapporo", "Dome", "retractable", "surface", "being", "one", "example", "."], "sentence-detokenized": "Kawasaki's portfolio also includes retractable roofs, floors and other giant structures, with the Sapporo Dome retractable surface being one example.", "token2charspan": [[0, 8], [8, 10], [11, 20], [21, 25], [26, 34], [35, 46], [47, 52], [52, 53], [54, 60], [61, 64], [65, 70], [71, 76], [77, 87], [87, 88], [89, 93], [94, 97], [98, 105], [106, 110], [111, 122], [123, 130], [131, 136], [137, 140], [141, 148], [148, 149]]}
{"doc_key": "ai-test-133", "ner": [[0, 1, "metrics"], [5, 7, "metrics"], [9, 11, "metrics"], [17, 18, "metrics"], [38, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 17, 18, "related-to", "", false, false], [0, 1, 38, 38, "opposite", "alternative_to", false, false], [5, 7, 0, 1, "type-of", "", false, false], [9, 11, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa", "statistics", ",", "such", "as", "Fleiss", "'s", "kappa", "and", "Cohen", "'s", "kappa", ",", "are", "methods", "of", "calculating", "inter-rater", "reliability", "based", "on", "different", "assumptions", "about", "marginal", "or", "prior", "distributions", "and", "are", "increasingly", "used", "as", "chance", "-", "corrected", "alternatives", "for", "accuracy", "in", "other", "contexts", "."], "sentence-detokenized": "Kappa statistics, such as Fleiss's kappa and Cohen's kappa, are methods of calculating inter-rater reliability based on different assumptions about marginal or prior distributions and are increasingly used as chance-corrected alternatives for accuracy in other contexts.", "token2charspan": [[0, 5], [6, 16], [16, 17], [18, 22], [23, 25], [26, 32], [32, 34], [35, 40], [41, 44], [45, 50], [50, 52], [53, 58], [58, 59], [60, 63], [64, 71], [72, 74], [75, 86], [87, 98], [99, 110], [111, 116], [117, 119], [120, 129], [130, 141], [142, 147], [148, 156], [157, 159], [160, 165], [166, 179], [180, 183], [184, 187], [188, 200], [201, 205], [206, 208], [209, 215], [215, 216], [216, 225], [226, 238], [239, 242], [243, 251], [252, 254], [255, 260], [261, 269], [269, 270]]}
{"doc_key": "ai-test-134", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [18, 18, "researcher"], [27, 29, "algorithm"], [37, 37, "algorithm"], [31, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 18, 18, "role", "student_of", false, false], [7, 8, 18, 18, "role", "student_of", false, false], [10, 11, 18, 18, "role", "student_of", false, false], [13, 14, 18, 18, "role", "student_of", false, false], [37, 37, 4, 5, "origin", "", false, false], [37, 37, 7, 8, "origin", "", false, false], [37, 37, 10, 11, "origin", "", false, false], [37, 37, 13, 14, "origin", "", false, false], [37, 37, 18, 18, "origin", "", false, false], [37, 37, 27, 29, "type-of", "", false, false], [31, 39, 37, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Together", "with", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "and", "others", ",", "Schmidhuber", "published", "increasingly", "sophisticated", "versions", "of", "a", "type", "of", "recurrent", "neural", "network", "called", "long", "-", "term", "short", "-", "term", "memory", "(", "LSTM", ")", "."], "sentence-detokenized": "Together with his students Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves and others, Schmidhuber published increasingly sophisticated versions of a type of recurrent neural network called long-term short-term memory (LSTM).", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 26], [27, 31], [32, 42], [42, 43], [44, 49], [50, 54], [54, 55], [56, 60], [61, 68], [68, 69], [70, 74], [75, 81], [82, 85], [86, 92], [92, 93], [94, 105], [106, 115], [116, 128], [129, 142], [143, 151], [152, 154], [155, 156], [157, 161], [162, 164], [165, 174], [175, 181], [182, 189], [190, 196], [197, 201], [201, 202], [202, 206], [207, 212], [212, 213], [213, 217], [218, 224], [225, 226], [226, 230], [230, 231], [231, 232]]}
{"doc_key": "ai-test-135", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "The", "first", "Cobot", "KUKA", "LBR", "3", "is", "launched", "."], "sentence-detokenized": "2004 - The first Cobot KUKA LBR 3 is launched.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 22], [23, 27], [28, 31], [32, 33], [34, 36], [37, 45], [45, 46]]}
{"doc_key": "ai-test-136", "ner": [[11, 13, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "shallow", "approaches", "used", "for", "training", "and", "then", "disambiguation", "are", "the", "Naive", "Bayes", "classifier", "and", "decision", "trees", "."], "sentence-detokenized": "Two shallow approaches used for training and then disambiguation are the Naive Bayes classifier and decision trees.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 27], [28, 31], [32, 40], [41, 44], [45, 49], [50, 64], [65, 68], [69, 72], [73, 78], [79, 84], [85, 95], [96, 99], [100, 108], [109, 114], [114, 115]]}
{"doc_key": "ai-test-137", "ner": [[5, 5, "misc"], [12, 13, "person"], [15, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 12, 13, "origin", "", false, false], [5, 5, 15, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "practical", "forms", "of", "photography", "were", "presented", "in", "January", "1839", "by", "Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "The first practical forms of photography were presented in January 1839 by Louis Daguerre and Henry Fox Talbot.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 25], [26, 28], [29, 40], [41, 45], [46, 55], [56, 58], [59, 66], [67, 71], [72, 74], [75, 80], [81, 89], [90, 93], [94, 99], [100, 103], [104, 110], [110, 111]]}
{"doc_key": "ai-test-138", "ner": [[3, 4, "task"], [8, 9, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 17, 18, "part-of", "task_part_of_field", false, false], [8, 9, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "speech", "synthesis", ",", "combined", "with", "speech", "recognition", ",", "allows", "interaction", "with", "mobile", "devices", "through", "language", "processing", "interfaces", "."], "sentence-detokenized": "For example, speech synthesis, combined with speech recognition, allows interaction with mobile devices through language processing interfaces.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [29, 30], [31, 39], [40, 44], [45, 51], [52, 63], [63, 64], [65, 71], [72, 83], [84, 88], [89, 95], [96, 103], [104, 111], [112, 120], [121, 131], [132, 142], [142, 143]]}
{"doc_key": "ai-test-139", "ner": [[0, 0, "product"], [14, 14, "programlang"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 14, "general-affiliation", "", false, false], [0, 0, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Phidgets", "can", "be", "programmed", "using", "a", "variety", "of", "software", "and", "programming", "languages", ",", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "Phidgets can be programmed using a variety of software and programming languages, from Java to Microsoft Excel.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 26], [27, 32], [33, 34], [35, 42], [43, 45], [46, 54], [55, 58], [59, 70], [71, 80], [80, 81], [82, 86], [87, 91], [92, 94], [95, 104], [105, 110], [110, 111]]}
{"doc_key": "ai-test-140", "ner": [[2, 3, "field"], [9, 10, "researcher"], [13, 15, "misc"], [22, 23, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 10, "origin", "", false, false], [9, 10, 22, 23, "general-affiliation", "topic_of_study", false, false], [9, 10, 25, 26, "general-affiliation", "topic_of_study", false, false], [13, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "machine", "learning", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "an", "American", "IBM", "employee", "and", "pioneer", "in", "the", "field", "of", "computer", "games", "and", "artificial", "intelligence", "."], "sentence-detokenized": "The term machine learning was coined in 1959 by Arthur Samuel, an American IBM employee and pioneer in the field of computer games and artificial intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 25], [26, 29], [30, 36], [37, 39], [40, 44], [45, 47], [48, 54], [55, 61], [61, 62], [63, 65], [66, 74], [75, 78], [79, 87], [88, 91], [92, 99], [100, 102], [103, 106], [107, 112], [113, 115], [116, 124], [125, 130], [131, 134], [135, 145], [146, 158], [158, 159]]}
{"doc_key": "ai-test-141", "ner": [[1, 2, "misc"], [3, 4, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Israeli", "poet", "David", "Avidan", ",", "who", "was", "fascinated", "by", "future", "technologies", "and", "their", "relation", "to", "art", ",", "wanted", "to", "explore", "the", "use", "of", "computers", "for", "writing", "literature", "."], "sentence-detokenized": "The Israeli poet David Avidan, who was fascinated by future technologies and their relation to art, wanted to explore the use of computers for writing literature.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 22], [23, 29], [29, 30], [31, 34], [35, 38], [39, 49], [50, 52], [53, 59], [60, 72], [73, 76], [77, 82], [83, 91], [92, 94], [95, 98], [98, 99], [100, 106], [107, 109], [110, 117], [118, 121], [122, 125], [126, 128], [129, 138], [139, 142], [143, 150], [151, 161], [161, 162]]}
{"doc_key": "ai-test-142", "ner": [[4, 6, "misc"], [9, 9, "organisation"], [15, 15, "location"], [30, 30, "location"], [26, 29, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 4, 6, "part-of", "", false, false], [26, 29, 30, 30, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "part", "of", "the", "GATEway", "Project", "in", "2017", ",", "Oxbotica", "tested", "seven", "autonomous", "buses", "in", "Greenwich", ",", "which", "toured", "a", "two", "-", "mile", "riverside", "path", "near", "The", "O2", "Arena", "in", "London", ",", "on", "a", "route", "also", "used", "by", "pedestrians", "and", "cyclists", "."], "sentence-detokenized": "As part of the GATEway Project in 2017, Oxbotica tested seven autonomous buses in Greenwich, which toured a two-mile riverside path near The O2 Arena in London, on a route also used by pedestrians and cyclists.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 30], [31, 33], [34, 38], [38, 39], [40, 48], [49, 55], [56, 61], [62, 72], [73, 78], [79, 81], [82, 91], [91, 92], [93, 98], [99, 105], [106, 107], [108, 111], [111, 112], [112, 116], [117, 126], [127, 131], [132, 136], [137, 140], [141, 143], [144, 149], [150, 152], [153, 159], [159, 160], [161, 163], [164, 165], [166, 171], [172, 176], [177, 181], [182, 184], [185, 196], [197, 200], [201, 209], [209, 210]]}
{"doc_key": "ai-test-143", "ner": [[10, 11, "task"], [14, 16, "metrics"], [25, 26, "misc"], [28, 28, "metrics"], [30, 30, "metrics"], [33, 33, "metrics"], [35, 35, "metrics"], [37, 39, "metrics"], [42, 42, "metrics"], [44, 44, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[14, 16, 25, 26, "related-to", "is_a", false, false], [14, 16, 28, 28, "usage", "", false, false], [14, 16, 30, 30, "usage", "", false, false], [28, 28, 33, 33, "named", "same", false, false], [30, 30, 44, 44, "named", "same", false, false], [33, 33, 42, 42, "opposite", "", false, false], [33, 33, 44, 44, "opposite", "", false, false], [35, 35, 33, 33, "named", "", false, false], [37, 39, 33, 33, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["An", "unrelated", "but", "often", "used", "combination", "of", "key", "statistics", "from", "information", "retrieval", "is", "the", "F", "-", "score", ",", "which", "is", "a", "(", "possibly", "weighted", ")", "harmonic", "average", "of", "recall", "and", "precision", ",", "where", "recall", "=", "sensitivity", "=", "TRUE", "positive", "rate", ",", "but", "specificity", "and", "precision", "are", "completely", "different", "measures", "."], "sentence-detokenized": "An unrelated but often used combination of key statistics from information retrieval is the F-score, which is a (possibly weighted) harmonic average of recall and precision, where recall = sensitivity = TRUE positive rate, but specificity and precision are completely different measures.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 22], [23, 27], [28, 39], [40, 42], [43, 46], [47, 57], [58, 62], [63, 74], [75, 84], [85, 87], [88, 91], [92, 93], [93, 94], [94, 99], [99, 100], [101, 106], [107, 109], [110, 111], [112, 113], [113, 121], [122, 130], [130, 131], [132, 140], [141, 148], [149, 151], [152, 158], [159, 162], [163, 172], [172, 173], [174, 179], [180, 186], [187, 188], [189, 200], [201, 202], [203, 207], [208, 216], [217, 221], [221, 222], [223, 226], [227, 238], [239, 242], [243, 252], [253, 256], [257, 267], [268, 277], [278, 286], [286, 287]]}
{"doc_key": "ai-test-144", "ner": [[0, 1, "field"], [10, 10, "field"], [12, 12, "field"], [14, 14, "field"], [16, 17, "field"], [19, 20, "field"], [29, 30, "product"], [32, 35, "product"], [37, 38, "product"], [40, 41, "product"], [54, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 10, "origin", "takes_inspiration_from", false, false], [0, 1, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 1, 14, 14, "origin", "takes_inspiration_from", false, false], [0, 1, 16, 17, "origin", "takes_inspiration_from", false, false], [0, 1, 19, 20, "origin", "takes_inspiration_from", false, false], [29, 30, 0, 1, "origin", "", false, false], [32, 35, 0, 1, "origin", "", false, false], [37, 38, 0, 1, "origin", "", false, false], [40, 41, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "is", "an", "interdisciplinary", "subject", "that", "draws", "inspiration", "from", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", "and", "electronic", "engineering", "to", "design", "artificial", "neural", "systems", ",", "such", "as", "vision", "systems", ",", "head", "-", "eye", "systems", ",", "auditory", "processors", "and", "autonomous", "robots", ",", "whose", "physical", "architecture", "and", "design", "principles", "are", "based", "on", "those", "of", "biological", "neural", "systems", "."], "sentence-detokenized": "Neuromorphic engineering is an interdisciplinary subject that draws inspiration from biology, physics, mathematics, computer science and electronic engineering to design artificial neural systems, such as vision systems, head-eye systems, auditory processors and autonomous robots, whose physical architecture and design principles are based on those of biological neural systems.", "token2charspan": [[0, 12], [13, 24], [25, 27], [28, 30], [31, 48], [49, 56], [57, 61], [62, 67], [68, 79], [80, 84], [85, 92], [92, 93], [94, 101], [101, 102], [103, 114], [114, 115], [116, 124], [125, 132], [133, 136], [137, 147], [148, 159], [160, 162], [163, 169], [170, 180], [181, 187], [188, 195], [195, 196], [197, 201], [202, 204], [205, 211], [212, 219], [219, 220], [221, 225], [225, 226], [226, 229], [230, 237], [237, 238], [239, 247], [248, 258], [259, 262], [263, 273], [274, 280], [280, 281], [282, 287], [288, 296], [297, 309], [310, 313], [314, 320], [321, 331], [332, 335], [336, 341], [342, 344], [345, 350], [351, 353], [354, 364], [365, 371], [372, 379], [379, 380]]}
{"doc_key": "ai-test-145", "ner": [[4, 6, "metrics"], [10, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 13, 4, 6, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "particular", ",", "the", "BIBO", "stability", "criterion", "requires", "that", "the", "ROC", "of", "the", "system", "includes", "the", "unit", "cycle", "."], "sentence-detokenized": "In particular, the BIBO stability criterion requires that the ROC of the system includes the unit cycle.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 23], [24, 33], [34, 43], [44, 52], [53, 57], [58, 61], [62, 65], [66, 68], [69, 72], [73, 79], [80, 88], [89, 92], [93, 97], [98, 103], [103, 104]]}
{"doc_key": "ai-test-146", "ner": [[7, 7, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "The", "program", "has", "been", "rewritten", "in", "Java", "since", "1998", "."], "sentence-detokenized": "2 The program has been rewritten in Java since 1998.", "token2charspan": [[0, 1], [2, 5], [6, 13], [14, 17], [18, 22], [23, 32], [33, 35], [36, 40], [41, 46], [47, 51], [51, 52]]}
{"doc_key": "ai-test-147", "ner": [[1, 1, "metrics"], [8, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 8, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "MCC", "can", "be", "calculated", "directly", "from", "the", "confusion", "table", "using", "the", "formula", ":"], "sentence-detokenized": "The MCC can be calculated directly from the confusion table using the formula:", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 25], [26, 34], [35, 39], [40, 43], [44, 53], [54, 59], [60, 65], [66, 69], [70, 77], [77, 78]]}
{"doc_key": "ai-test-148", "ner": [[6, 11, "organisation"], [17, 22, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 11, 17, 22, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Developed", "by", "a", "team", "at", "the", "MIT", "-", "IBM", "Watson", "AI", "Lab", "and", "first", "presented", "at", "the", "2018", "International", "Conference", "on", "Representation", "Learning", "."], "sentence-detokenized": "Developed by a team at the MIT-IBM Watson AI Lab and first presented at the 2018 International Conference on Representation Learning.", "token2charspan": [[0, 9], [10, 12], [13, 14], [15, 19], [20, 22], [23, 26], [27, 30], [30, 31], [31, 34], [35, 41], [42, 44], [45, 48], [49, 52], [53, 58], [59, 68], [69, 71], [72, 75], [76, 80], [81, 94], [95, 105], [106, 108], [109, 123], [124, 132], [132, 133]]}
{"doc_key": "ai-test-149", "ner": [[2, 3, "metrics"], [15, 17, "metrics"], [19, 21, "metrics"], [49, 49, "metrics"], [51, 51, "metrics"], [57, 59, "metrics"], [62, 62, "metrics"], [64, 64, "metrics"], [67, 69, "metrics"], [74, 74, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[15, 17, 49, 49, "type-of", "", false, false], [15, 17, 57, 59, "related-to", "collapses_to_identity", false, false], [19, 21, 51, 51, "type-of", "", false, false], [19, 21, 57, 59, "related-to", "collapses_to_identity", false, false], [19, 21, 67, 69, "named", "same", false, false], [62, 62, 74, 74, "related-to", "collapses_to_identity", false, false], [64, 64, 74, 74, "related-to", "collapses_to_identity", false, false], [67, 69, 74, 74, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["When", "the", "TRUE", "prevalences", "for", "the", "two", "positive", "variables", "are", "equal", ",", "as", "assumed", "in", "Fleiss", "'s", "kappa", "and", "F", "-", "score", ",", "i.e.", ",", "the", "number", "of", "positive", "predictions", "corresponds", "to", "the", "number", "of", "positive", "classes", "in", "the", "dichotomous", "(", "two", "-", "class", ")", "case", ",", "the", "different", "kappa", "and", "correlation", "measures", "collapse", "to", "identity", "with", "Youden", "'s", "J", ",", "and", "recall", ",", "precision", ",", "and", "F", "-", "score", "are", "similarly", "identical", "to", "precision", "."], "sentence-detokenized": "When the TRUE prevalences for the two positive variables are equal, as assumed in Fleiss's kappa and F-score, i.e., the number of positive predictions corresponds to the number of positive classes in the dichotomous (two-class) case, the different kappa and correlation measures collapse to identity with Youden's J, and recall, precision, and F-score are similarly identical to precision.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 25], [26, 29], [30, 33], [34, 37], [38, 46], [47, 56], [57, 60], [61, 66], [66, 67], [68, 70], [71, 78], [79, 81], [82, 88], [88, 90], [91, 96], [97, 100], [101, 102], [102, 103], [103, 108], [108, 109], [110, 114], [114, 115], [116, 119], [120, 126], [127, 129], [130, 138], [139, 150], [151, 162], [163, 165], [166, 169], [170, 176], [177, 179], [180, 188], [189, 196], [197, 199], [200, 203], [204, 215], [216, 217], [217, 220], [220, 221], [221, 226], [226, 227], [228, 232], [232, 233], [234, 237], [238, 247], [248, 253], [254, 257], [258, 269], [270, 278], [279, 287], [288, 290], [291, 299], [300, 304], [305, 311], [311, 313], [314, 315], [315, 316], [317, 320], [321, 327], [327, 328], [329, 338], [338, 339], [340, 343], [344, 345], [345, 346], [346, 351], [352, 355], [356, 365], [366, 375], [376, 378], [379, 388], [388, 389]]}
{"doc_key": "ai-test-150", "ner": [[7, 7, "misc"], [1, 5, "misc"], [9, 9, "conference"], [14, 17, "task"], [18, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 7, 9, 9, "part-of", "", false, false], [7, 7, 9, 9, "physical", "", false, false], [7, 7, 9, 9, "temporal", "", false, false], [1, 5, 7, 7, "named", "", false, false], [14, 17, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Building", "Educational", "Applications", "(", "BEA", ")", "workshop", "at", "NAACL", "2013", "hosted", "the", "inaugural", "joint", "NLI", "paper", ".", "Tetreault", "et", "al", ",", "2013", "The", "competition", "resulted", "in", "29", "entries", "from", "teams", "from", "around", "the", "world", ",", "24", "of", "which", "also", "published", "a", "paper", "describing", "their", "systems", "and", "approaches", "."], "sentence-detokenized": "The Building Educational Applications (BEA) workshop at NAACL 2013 hosted the inaugural joint NLI paper. Tetreault et al, 2013 The competition resulted in 29 entries from teams from around the world, 24 of which also published a paper describing their systems and approaches.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 37], [38, 39], [39, 42], [42, 43], [44, 52], [53, 55], [56, 61], [62, 66], [67, 73], [74, 77], [78, 87], [88, 93], [94, 97], [98, 103], [103, 104], [105, 114], [115, 117], [118, 120], [120, 121], [122, 126], [127, 130], [131, 142], [143, 151], [152, 154], [155, 157], [158, 165], [166, 170], [171, 176], [177, 181], [182, 188], [189, 192], [193, 198], [198, 199], [200, 202], [203, 205], [206, 211], [212, 216], [217, 226], [227, 228], [229, 234], [235, 245], [246, 251], [252, 259], [260, 263], [264, 274], [274, 275]]}
{"doc_key": "ai-test-151", "ner": [[1, 2, "algorithm"], [5, 7, "algorithm"], [15, 16, "misc"], [19, 20, "misc"], [34, 35, "misc"], [38, 40, "algorithm"], [42, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 2, 5, 7, "type-of", "", false, false], [1, 2, 15, 16, "related-to", "finds", false, false], [19, 20, 15, 16, "type-of", "", false, false], [42, 42, 38, 40, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Viterbi", "algorithm", "is", "a", "dynamic", "programming", "algorithm", "for", "finding", "the", "most", "likely", "sequence", "of", "hidden", "states", "called", "a", "Viterbi", "path", "leading", "to", "a", "sequence", "of", "observed", "events", ",", "particularly", "in", "the", "context", "of", "Markov", "information", "sources", "and", "hidden", "Markov", "models", "(", "HMMs", ")", "."], "sentence-detokenized": "The Viterbi algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states called a Viterbi path leading to a sequence of observed events, particularly in the context of Markov information sources and hidden Markov models (HMMs).", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 24], [25, 26], [27, 34], [35, 46], [47, 56], [57, 60], [61, 68], [69, 72], [73, 77], [78, 84], [85, 93], [94, 96], [97, 103], [104, 110], [111, 117], [118, 119], [120, 127], [128, 132], [133, 140], [141, 143], [144, 145], [146, 154], [155, 157], [158, 166], [167, 173], [173, 174], [175, 187], [188, 190], [191, 194], [195, 202], [203, 205], [206, 212], [213, 224], [225, 232], [233, 236], [237, 243], [244, 250], [251, 257], [258, 259], [259, 263], [263, 264], [264, 265]]}
{"doc_key": "ai-test-152", "ner": [[1, 1, "field"], [3, 5, "algorithm"], [8, 9, "misc"], [12, 13, "algorithm"], [15, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 1, 1, "part-of", "", false, false], [3, 5, 8, 9, "general-affiliation", "", false, false], [3, 5, 12, 13, "related-to", "generalizes_from", false, false], [3, 5, 15, 18, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "multinomial", "logistic", "regression", "is", "a", "classification", "method", "that", "generalises", "logistic", "regression", "to", "multicategory", "classification", ",", "i.e.", "with", "more", "than", "two", "possible", "distinct", "outcomes", "."], "sentence-detokenized": "In statistics, multinomial logistic regression is a classification method that generalises logistic regression to multicategory classification, i.e. with more than two possible distinct outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 26], [27, 35], [36, 46], [47, 49], [50, 51], [52, 66], [67, 73], [74, 78], [79, 90], [91, 99], [100, 110], [111, 113], [114, 127], [128, 142], [142, 143], [144, 148], [149, 153], [154, 158], [159, 163], [164, 167], [168, 176], [177, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-test-153", "ner": [[0, 2, "algorithm"], [9, 10, "field"], [12, 14, "field"], [18, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 9, 10, "part-of", "", false, false], [0, 2, 12, 14, "part-of", "", false, false], [18, 18, 0, 2, "usage", "", true, false], [20, 21, 0, 2, "usage", "", true, false], [23, 24, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden", "Markov", "models", "are", "known", "for", "their", "applications", "in", "reinforcement", "learning", "and", "longitudinal", "pattern", "recognition", ",", "such", "as", "speech", ",", "handwriting", "recognition", ",", "gesture", "recognition", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov models are known for their applications in reinforcement learning and longitudinal pattern recognition, such as speech, handwriting recognition, gesture recognition, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 30], [31, 34], [35, 40], [41, 53], [54, 56], [57, 70], [71, 79], [80, 83], [84, 96], [97, 104], [105, 116], [116, 117], [118, 122], [123, 125], [126, 132], [132, 133], [134, 145], [146, 157], [157, 158], [159, 166], [167, 178], [178, 179], [180, 184], [185, 192], [192, 193], [194, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-154", "ner": [[6, 9, "misc"], [33, 36, "metrics"], [39, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 39, 40, "named", "", false, false], [33, 36, 39, 40, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Essentially", ",", "this", "means", "that", "if", "the", "then", "-", "gram", "has", "occurred", "more", "than", "k", "times", "during", "training", ",", "the", "conditional", "probability", "of", "a", "word", "given", "it", "s", "history", "is", "proportional", "to", "the", "maximum", "likelihood", "estimate", "of", "that", "n", "-", "gram", "."], "sentence-detokenized": "Essentially, this means that if the then-gram has occurred more than k times during training, the conditional probability of a word given its history is proportional to the maximum likelihood estimate of that n -gram.", "token2charspan": [[0, 11], [11, 12], [13, 17], [18, 23], [24, 28], [29, 31], [32, 35], [36, 40], [40, 41], [41, 45], [46, 49], [50, 58], [59, 63], [64, 68], [69, 70], [71, 76], [77, 83], [84, 92], [92, 93], [94, 97], [98, 109], [110, 121], [122, 124], [125, 126], [127, 131], [132, 137], [138, 140], [140, 141], [142, 149], [150, 152], [153, 165], [166, 168], [169, 172], [173, 180], [181, 191], [192, 200], [201, 203], [204, 208], [209, 210], [211, 212], [212, 216], [216, 217]]}
{"doc_key": "ai-test-155", "ner": [[4, 5, "task"], [7, 8, "task"], [10, 12, "task"], [16, 19, "task"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[26, 27, 16, 19, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "knowledge", "representation", ",", "common", "sense", "and", "natural", "language", "understanding", ",", "believing", "that", "deep", "understanding", "of", "language", "can", "only", "be", "achieved", "by", "significant", "handcrafting", "of", "semantically", "rich", "formalisms", "combined", "with", "statistical", "preferences", "."], "sentence-detokenized": "He is interested in knowledge representation, common sense and natural language understanding, believing that deep understanding of language can only be achieved by significant handcrafting of semantically rich formalisms combined with statistical preferences.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 29], [30, 44], [44, 45], [46, 52], [53, 58], [59, 62], [63, 70], [71, 79], [80, 93], [93, 94], [95, 104], [105, 109], [110, 114], [115, 128], [129, 131], [132, 140], [141, 144], [145, 149], [150, 152], [153, 161], [162, 164], [165, 176], [177, 189], [190, 192], [193, 205], [206, 210], [211, 221], [222, 230], [231, 235], [236, 247], [248, 259], [259, 260]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "JavaScript", ",", "Python", "or"], "sentence-detokenized": "In JavaScript, Python or", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 24]]}
{"doc_key": "ai-test-157", "ner": [[1, 2, "misc"], [6, 7, "misc"], [10, 10, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 6, 7, "part-of", "", false, false], [6, 7, 10, 10, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "Awards", "are", "announced", "in", "AI", "Magazine", "published", "by", "AAAI", "."], "sentence-detokenized": "The Newcomb Awards are announced in AI Magazine published by AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 32], [33, 35], [36, 38], [39, 47], [48, 57], [58, 60], [61, 65], [65, 66]]}
{"doc_key": "ai-test-158", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "squared", "error", "in", "a", "test", "set", "of", "100", "subsamples", "is", "0.084", ",", "smaller", "than", "the", "unnormalized", "error", "."], "sentence-detokenized": "The mean squared error in a test set of 100 subsamples is 0.084, smaller than the unnormalized error.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 25], [26, 27], [28, 32], [33, 36], [37, 39], [40, 43], [44, 54], [55, 57], [58, 63], [63, 64], [65, 72], [73, 77], [78, 81], [82, 94], [95, 100], [100, 101]]}
{"doc_key": "ai-test-159", "ner": [[0, 2, "metrics"], [9, 11, "field"], [18, 18, "task"], [17, 21, "task"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 11, 0, 2, "usage", "", false, false], [18, 18, 9, 11, "part-of", "task_part_of_field", false, false], [17, 21, 18, 18, "named", "", false, false], [24, 25, 9, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["F", "-", "score", "has", "been", "widely", "used", "in", "the", "natural", "language", "processing", "literature", ",", "such", "as", "evaluating", "named", "entity", "recognition", "(", "NER", ")", "and", "word", "segmentation", "."], "sentence-detokenized": "F-score has been widely used in the natural language processing literature, such as evaluating named entity recognition (NER) and word segmentation.", "token2charspan": [[0, 1], [1, 2], [2, 7], [8, 11], [12, 16], [17, 23], [24, 28], [29, 31], [32, 35], [36, 43], [44, 52], [53, 63], [64, 74], [74, 75], [76, 80], [81, 83], [84, 94], [95, 100], [101, 107], [108, 119], [120, 121], [121, 124], [124, 125], [126, 129], [130, 134], [135, 147], [147, 148]]}
{"doc_key": "ai-test-160", "ner": [[0, 1, "product"], [5, 6, "product"], [15, 16, "misc"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 15, 16, "related-to", "performs_task", false, false], [0, 1, 18, 19, "related-to", "performs_task", false, false], [5, 6, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "commonly", "used", "in", "dialogue", "systems", "for", "various", "purposes", ",", "including", "customer", "service", ",", "routing", "requests", "or", "collecting", "information", "."], "sentence-detokenized": "Chatbots are commonly used in dialogue systems for various purposes, including customer service, routing requests or collecting information.", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 26], [27, 29], [30, 38], [39, 46], [47, 50], [51, 58], [59, 67], [67, 68], [69, 78], [79, 87], [88, 95], [95, 96], [97, 104], [105, 113], [114, 116], [117, 127], [128, 139], [139, 140]]}
{"doc_key": "ai-test-161", "ner": [[3, 9, "conference"], [13, 21, "conference"], [28, 38, "conference"], [45, 45, "conference"], [49, 52, "conference"], [54, 55, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 21, 3, 9, "named", "", false, false], [28, 38, 3, 9, "named", "", false, false], [45, 45, 28, 38, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Major", "journals", "include", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "later", "renamed", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "and", "as", "of", "September", "2014", "renamed", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "following", "a", "merger", "with", "an", "ACM", "publication", ")", ",", "Computer", "Speech", "and", "Language", "and", "Speech", "Communication", "."], "sentence-detokenized": "Major journals include IEEE Transactions on Speech and Audio Processing (later renamed IEEE Transactions on Audio, Speech and Language Processing and as of September 2014 renamed IEEE/ACM Transactions on Audio, Speech and Language Processing - following a merger with an ACM publication), Computer Speech and Language and Speech Communication.", "token2charspan": [[0, 5], [6, 14], [15, 22], [23, 27], [28, 40], [41, 43], [44, 50], [51, 54], [55, 60], [61, 71], [72, 73], [73, 78], [79, 86], [87, 91], [92, 104], [105, 107], [108, 113], [113, 114], [115, 121], [122, 125], [126, 134], [135, 145], [146, 149], [150, 152], [153, 155], [156, 165], [166, 170], [171, 178], [179, 183], [183, 184], [184, 187], [188, 200], [201, 203], [204, 209], [209, 210], [211, 217], [218, 221], [222, 230], [231, 241], [242, 243], [244, 253], [254, 255], [256, 262], [263, 267], [268, 270], [271, 274], [275, 286], [286, 287], [287, 288], [289, 297], [298, 304], [305, 308], [309, 317], [318, 321], [322, 328], [329, 342], [342, 343]]}
{"doc_key": "ai-test-162", "ner": [[0, 0, "algorithm"], [5, 6, "task"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 0, 0, "usage", "", false, false], [5, 6, 8, 9, "part-of", "task_part_of_field", false, false], [5, 6, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "is", "often", "used", "for", "data", "clustering", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "EM is often used for data clustering in machine learning and computer vision.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 20], [21, 25], [26, 36], [37, 39], [40, 47], [48, 56], [57, 60], [61, 69], [70, 76], [76, 77]]}
{"doc_key": "ai-test-163", "ner": [[9, 11, "metrics"], [24, 26, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 24, 26, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["Although", "there", "is", "no", "perfect", "way", "to", "describe", "the", "confusion", "matrix", "of", "TRUE", "and", "FALSE", "positives", "and", "negatives", "with", "a", "single", "number", ",", "the", "Matthews", "correlation", "coefficient", "is", "generally", "regarded", "as", "one", "of", "the", "best", "such", "measures", "."], "sentence-detokenized": "Although there is no perfect way to describe the confusion matrix of TRUE and FALSE positives and negatives with a single number, the Matthews correlation coefficient is generally regarded as one of the best such measures.", "token2charspan": [[0, 8], [9, 14], [15, 17], [18, 20], [21, 28], [29, 32], [33, 35], [36, 44], [45, 48], [49, 58], [59, 65], [66, 68], [69, 73], [74, 77], [78, 83], [84, 93], [94, 97], [98, 107], [108, 112], [113, 114], [115, 121], [122, 128], [128, 129], [130, 133], [134, 142], [143, 154], [155, 166], [167, 169], [170, 179], [180, 188], [189, 191], [192, 195], [196, 198], [199, 202], [203, 207], [208, 212], [213, 221], [221, 222]]}
{"doc_key": "ai-test-164", "ner": [[10, 11, "field"], [26, 27, "field"], [31, 32, "field"], [36, 37, "algorithm"], [39, 40, "task"], [42, 43, "algorithm"], [48, 53, "algorithm"], [51, 52, "algorithm"], [59, 61, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[31, 32, 26, 27, "part-of", "subfield", false, false], [36, 37, 31, 32, "part-of", "", false, true], [39, 40, 31, 32, "part-of", "", false, true], [42, 43, 31, 32, "part-of", "", false, true], [48, 53, 31, 32, "part-of", "", false, true], [51, 52, 31, 32, "part-of", "", false, true], [59, 61, 31, 32, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "datasets", "grew", "in", "size", "and", "complexity", ",", "direct", "manual", "data", "analysis", "was", "augmented", "by", "indirect", ",", "automated", "data", "processing", ",", "aided", "by", "other", "breakthroughs", "in", "computer", "science", ",", "especially", "in", "machine", "learning", ",", "such", "as", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "decision", "tree", "and", "decision", "rule", "learning", "(", "1960", "s", ")", "and", "support", "vector", "machines", "(", "1990", "s", ")", "."], "sentence-detokenized": "As datasets grew in size and complexity, direct manual data analysis was augmented by indirect, automated data processing, aided by other breakthroughs in computer science, especially in machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision tree and decision rule learning (1960s) and support vector machines (1990s).", "token2charspan": [[0, 2], [3, 11], [12, 16], [17, 19], [20, 24], [25, 28], [29, 39], [39, 40], [41, 47], [48, 54], [55, 59], [60, 68], [69, 72], [73, 82], [83, 85], [86, 94], [94, 95], [96, 105], [106, 110], [111, 121], [121, 122], [123, 128], [129, 131], [132, 137], [138, 151], [152, 154], [155, 163], [164, 171], [171, 172], [173, 183], [184, 186], [187, 194], [195, 203], [203, 204], [205, 209], [210, 212], [213, 219], [220, 228], [228, 229], [230, 237], [238, 246], [246, 247], [248, 255], [256, 266], [267, 268], [268, 273], [273, 274], [274, 275], [276, 284], [285, 289], [290, 293], [294, 302], [303, 307], [308, 316], [317, 318], [318, 322], [322, 323], [323, 324], [325, 328], [329, 336], [337, 343], [344, 352], [353, 354], [354, 358], [358, 359], [359, 360], [360, 361]]}
{"doc_key": "ai-test-165", "ner": [[6, 6, "researcher"], [11, 13, "misc"], [19, 20, "researcher"], [22, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 13, 6, 6, "artifact", "", false, false], [11, 13, 19, 20, "artifact", "", false, false], [11, 13, 22, 23, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "fall", "of", "2005", ",", "Thrun", "published", "a", "textbook", "entitled", "Probabilistic", "Robotics", "with", "his", "long", "-", "time", "collaborators", "Dieter", "Fox", "and", "Wolfram", "Burgard", "."], "sentence-detokenized": "In the fall of 2005, Thrun published a textbook entitled Probabilistic Robotics with his long-time collaborators Dieter Fox and Wolfram Burgard.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 19], [19, 20], [21, 26], [27, 36], [37, 38], [39, 47], [48, 56], [57, 70], [71, 79], [80, 84], [85, 88], [89, 93], [93, 94], [94, 98], [99, 112], [113, 119], [120, 123], [124, 127], [128, 135], [136, 143], [143, 144]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereiramath", "as", "follows", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereiramath as follows:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 49], [50, 52], [53, 60], [60, 61]]}
{"doc_key": "ai-test-167", "ner": [[0, 1, "task"], [3, 3, "task"], [9, 12, "field"], [15, 16, "field"], [20, 20, "field"], [18, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 15, 16, "part-of", "task_part_of_field", false, false], [0, 1, 20, 20, "part-of", "task_part_of_field", false, false], [3, 3, 0, 1, "named", "", false, false], [15, 16, 9, 12, "part-of", "subfield", false, false], [20, 20, 9, 12, "part-of", "subfield", false, false], [18, 24, 20, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Question", "Answering", "(", "QA", ")", "is", "a", "branch", "of", "computer", "science", "in", "the", "fields", "of", "information", "retrieval", "and", "natural", "language", "processing", "(", "NLP", ")", "that", "deals", "with", "the", "creation", "of", "systems", "that", "automatically", "answer", "questions", "posed", "by", "humans", "in", "natural", "language", "."], "sentence-detokenized": "Question Answering (QA) is a branch of computer science in the fields of information retrieval and natural language processing (NLP) that deals with the creation of systems that automatically answer questions posed by humans in natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 35], [36, 38], [39, 47], [48, 55], [56, 58], [59, 62], [63, 69], [70, 72], [73, 84], [85, 94], [95, 98], [99, 106], [107, 115], [116, 126], [127, 128], [128, 131], [131, 132], [133, 137], [138, 143], [144, 148], [149, 152], [153, 161], [162, 164], [165, 172], [173, 177], [178, 191], [192, 198], [199, 208], [209, 214], [215, 217], [218, 224], [225, 227], [228, 235], [236, 244], [244, 245]]}
{"doc_key": "ai-test-168", "ner": [[10, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "in", "the", "version", "of", "the", "metric", "used", "by", "NIST", "assessments", "prior", "to", "2009", ",", "the", "shorter", "benchmark", "proposal", "was", "used", "."], "sentence-detokenized": "However, in the version of the metric used by NIST assessments prior to 2009, the shorter benchmark proposal was used.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 37], [38, 42], [43, 45], [46, 50], [51, 62], [63, 68], [69, 71], [72, 76], [76, 77], [78, 81], [82, 89], [90, 99], [100, 108], [109, 112], [113, 117], [117, 118]]}
{"doc_key": "ai-test-169", "ner": [[5, 5, "person"], [13, 13, "organisation"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 15, 15, "related-to", "invests_in", false, false], [15, 15, 13, 13, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["On", "27", "August", "2018", ",", "Toyota", "announced", "a", "$", "500", "million", "investment", "in", "Uber", "'s", "autonomous", "cars", "."], "sentence-detokenized": "On 27 August 2018, Toyota announced a $500 million investment in Uber's autonomous cars.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 17], [17, 18], [19, 25], [26, 35], [36, 37], [38, 39], [39, 42], [43, 50], [51, 61], [62, 64], [65, 69], [69, 71], [72, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-test-170", "ner": [[5, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sample", "maximum", "is", "the", "maximum", "likelihood", "estimator", "for", "the", "population", "maximum", ",", "but", ",", "as", "discussed", "above", ",", "it", "is", "biased", "."], "sentence-detokenized": "The sample maximum is the maximum likelihood estimator for the population maximum, but, as discussed above, it is biased.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 25], [26, 33], [34, 44], [45, 54], [55, 58], [59, 62], [63, 73], [74, 81], [81, 82], [83, 86], [86, 87], [88, 90], [91, 100], [101, 106], [106, 107], [108, 110], [111, 113], [114, 120], [120, 121]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [3, 3, "misc"], [6, 6, "metrics"], [15, 17, "algorithm"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 3, "related-to", "overcomes", false, false], [0, 0, 6, 6, "related-to", "increases", false, false], [3, 3, 15, 17, "opposite", "", false, false], [3, 3, 19, 21, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "helps", "address", "synonymity", "by", "increasing", "recall", ",", "one", "of", "the", "most", "problematic", "limitations", "of", "Boolean", "keyword", "queries", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI helps address synonymity by increasing recall, one of the most problematic limitations of Boolean keyword queries and vector space models.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 28], [29, 31], [32, 42], [43, 49], [49, 50], [51, 54], [55, 57], [58, 61], [62, 66], [67, 78], [79, 90], [91, 93], [94, 101], [102, 109], [110, 117], [118, 121], [122, 128], [129, 134], [135, 141], [141, 142]]}
{"doc_key": "ai-test-172", "ner": [[0, 1, "task"], [19, 19, "programlang"], [21, 21, "programlang"], [23, 23, "programlang"], [25, 26, "programlang"], [28, 28, "programlang"], [30, 30, "programlang"], [32, 32, "programlang"], [34, 34, "programlang"], [36, 36, "programlang"], [38, 38, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 19, 19, "general-affiliation", "", false, false], [0, 1, 21, 21, "general-affiliation", "", false, false], [0, 1, 23, 23, "general-affiliation", "", false, false], [0, 1, 25, 26, "general-affiliation", "", false, false], [0, 1, 28, 28, "general-affiliation", "", false, false], [0, 1, 30, 30, "general-affiliation", "", false, false], [0, 1, 32, 32, "general-affiliation", "", false, false], [0, 1, 34, 34, "general-affiliation", "", false, false], [0, 1, 36, 36, "general-affiliation", "", false, false], [0, 1, 38, 38, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Data", "collection", "applications", "are", "usually", "controlled", "by", "software", "programs", "developed", "with", "various", "general", "-", "purpose", "programming", "languages", "such", "as", "Assembly", ",", "BASIC", ",", "C", ",", "C", "++", ",", "C#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "Data collection applications are usually controlled by software programs developed with various general-purpose programming languages such as Assembly, BASIC, C, C++, C#, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 32], [33, 40], [41, 51], [52, 54], [55, 63], [64, 72], [73, 82], [83, 87], [88, 95], [96, 103], [103, 104], [104, 111], [112, 123], [124, 133], [134, 138], [139, 141], [142, 150], [150, 151], [152, 157], [157, 158], [159, 160], [160, 161], [162, 163], [163, 165], [165, 166], [167, 169], [169, 170], [171, 178], [178, 179], [180, 184], [184, 185], [186, 193], [193, 194], [195, 199], [199, 200], [201, 207], [207, 208], [209, 213]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [6, 9, "product"], [10, 10, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 3, 3, "artifact", "", false, false], [6, 9, 10, 10, "physical", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2003", ",", "Honda", "launched", "its", "Cog", "advertisement", "in", "the", "UK", "and", "on", "the", "Internet", "."], "sentence-detokenized": "In 2003, Honda launched its Cog advertisement in the UK and on the Internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 27], [28, 31], [32, 45], [46, 48], [49, 52], [53, 55], [56, 59], [60, 62], [63, 66], [67, 75], [75, 76]]}
{"doc_key": "ai-test-174", "ner": [[1, 4, "conference"], [6, 7, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 4, 6, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Association", "for", "Computational", "Linguistics", "defines", "computational", "linguistics", "as", ":"], "sentence-detokenized": "The Association for Computational Linguistics defines computational linguistics as:", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 45], [46, 53], [54, 67], [68, 79], [80, 82], [82, 83]]}
{"doc_key": "ai-test-175", "ner": [[0, 2, "algorithm"], [9, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 12, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Expectation", "maximization", "algorithms", "can", "be", "used", "to", "compute", "approximate", "maximum", "likelihood", "estimates", "of", "unknown", "state", "space", "parameters", "in", "the", "context", "of", "filters", "and", "minimum", "variance", "smoothers", "."], "sentence-detokenized": "Expectation maximization algorithms can be used to compute approximate maximum likelihood estimates of unknown state space parameters in the context of filters and minimum variance smoothers.", "token2charspan": [[0, 11], [12, 24], [25, 35], [36, 39], [40, 42], [43, 47], [48, 50], [51, 58], [59, 70], [71, 78], [79, 89], [90, 99], [100, 102], [103, 110], [111, 116], [117, 122], [123, 133], [134, 136], [137, 140], [141, 148], [149, 151], [152, 159], [160, 163], [164, 171], [172, 180], [181, 190], [190, 191]]}
{"doc_key": "ai-test-176", "ner": [[3, 3, "misc"], [5, 7, "person"], [9, 10, "person"], [12, 13, "person"], [16, 17, "misc"], [18, 19, "person"], [22, 23, "person"], [27, 27, "person"], [29, 30, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 7, 3, 3, "role", "actor_in", false, false], [9, 10, 3, 3, "role", "actor_in", false, false], [12, 13, 3, 3, "role", "actor_in", false, false], [18, 19, 16, 17, "role", "model_for", false, false], [27, 27, 29, 30, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Correspondents", "included", "former", "Baywatch", "actresses", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "and", "Traci", "Bingham", ",", "former", "Playboy", "Playmate", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", "and", "monogamous", "twins", "Randy", "and", "Jason", "Sklar", "."], "sentence-detokenized": "Correspondents included former Baywatch actresses Donna D'Errico, Carmen Electra and Traci Bingham, former Playboy Playmate Heidi Mark, comedian Arj Barker and monogamous twins Randy and Jason Sklar.", "token2charspan": [[0, 14], [15, 23], [24, 30], [31, 39], [40, 49], [50, 55], [56, 58], [58, 64], [64, 65], [66, 72], [73, 80], [81, 84], [85, 90], [91, 98], [98, 99], [100, 106], [107, 114], [115, 123], [124, 129], [130, 134], [134, 135], [136, 144], [145, 148], [149, 155], [156, 159], [160, 170], [171, 176], [177, 182], [183, 186], [187, 192], [193, 198], [198, 199]]}
{"doc_key": "ai-test-177", "ner": [[8, 9, "task"], [11, 11, "task"], [16, 18, "product"], [21, 22, "task"], [24, 27, "task"], [29, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [16, 18, 8, 9, "general-affiliation", "", false, false], [24, 27, 21, 22, "named", "", false, false], [29, 30, 21, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "is", "commonly", "used", "to", "create", "representations", "for", "speech", "recognition", "(", "ASR", ")", ",", "e.g.", "the", "CMU", "Sphinx", "system", ",", "and", "speech", "synthesis", "(", "TTS", ")", ",", "e.g.", "the", "Festival", "system", "."], "sentence-detokenized": "It is commonly used to create representations for speech recognition (ASR), e.g. the CMU Sphinx system, and speech synthesis (TTS), e.g. the Festival system.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 19], [20, 22], [23, 29], [30, 45], [46, 49], [50, 56], [57, 68], [69, 70], [70, 73], [73, 74], [74, 75], [76, 80], [81, 84], [85, 88], [89, 95], [96, 102], [102, 103], [104, 107], [108, 114], [115, 124], [125, 126], [126, 129], [129, 130], [130, 131], [132, 136], [137, 140], [141, 149], [150, 156], [156, 157]]}
{"doc_key": "ai-test-178", "ner": [[0, 1, "metrics"], [4, 5, "metrics"], [7, 7, "metrics"], [13, 13, "metrics"], [27, 28, "metrics"], [30, 30, "metrics"], [41, 41, "metrics"], [43, 43, "metrics"], [45, 47, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[4, 5, 0, 1, "named", "", false, false], [7, 7, 4, 5, "named", "", false, false], [13, 13, 0, 1, "named", "", false, false], [30, 30, 27, 28, "named", "", false, false], [43, 43, 41, 41, "named", "", false, false], [45, 47, 41, 41, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "sensitivity", "or", "TRUE", "Positive", "Rate", "(", "TPR", ")", ",", "also", "known", "as", "recall", ",", "is", "the", "proportion", "of", "individuals", "who", "tested", "positive", "and", "are", "positive", "(", "TRUE", "Positive", ",", "TP", ")", "to", "all", "individuals", "who", "are", "actually", "positive", "(", "Condition", "Positive", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "The sensitivity or TRUE Positive Rate (TPR), also known as recall, is the proportion of individuals who tested positive and are positive (TRUE Positive, TP) to all individuals who are actually positive (Condition Positive, CP = TP + FN).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 23], [24, 32], [33, 37], [38, 39], [39, 42], [42, 43], [43, 44], [45, 49], [50, 55], [56, 58], [59, 65], [65, 66], [67, 69], [70, 73], [74, 84], [85, 87], [88, 99], [100, 103], [104, 110], [111, 119], [120, 123], [124, 127], [128, 136], [137, 138], [138, 142], [143, 151], [151, 152], [153, 155], [155, 156], [157, 159], [160, 163], [164, 175], [176, 179], [180, 183], [184, 192], [193, 201], [202, 203], [203, 212], [213, 221], [221, 222], [223, 225], [226, 227], [228, 230], [231, 232], [233, 235], [235, 236], [236, 237]]}
{"doc_key": "ai-test-179", "ner": [[1, 2, "task"], [10, 10, "conference"], [12, 13, "conference"], [15, 15, "conference"], [17, 19, "conference"], [21, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6], "relations": [[10, 10, 1, 2, "topic", "", false, false], [12, 13, 1, 2, "topic", "", false, false], [15, 15, 1, 2, "topic", "", false, false], [17, 19, 1, 2, "topic", "", false, false], [21, 22, 1, 2, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5], "sentence": ["Popular", "speech", "recognition", "conferences", "held", "every", "year", "or", "two", "include", "SpeechTEK", "and", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "and", "IEEE", "ASRU", "."], "sentence-detokenized": "Popular speech recognition conferences held every year or two include SpeechTEK and SpeechTEK Europe, ICASSP, Interspeech/Eurospeech and IEEE ASRU.", "token2charspan": [[0, 7], [8, 14], [15, 26], [27, 38], [39, 43], [44, 49], [50, 54], [55, 57], [58, 61], [62, 69], [70, 79], [80, 83], [84, 93], [94, 100], [100, 101], [102, 108], [108, 109], [110, 121], [121, 122], [122, 132], [133, 136], [137, 141], [142, 146], [146, 147]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [3, 3, "researcher"], [18, 19, "product"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 0, 0, "artifact", "", false, false], [21, 21, 3, 3, "artifact", "", false, false], [21, 21, 18, 19, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "collaborated", "with", "Engelberger", ",", "who", "served", "as", "the", "company", "'s", "president", ",", "to", "design", "and", "produce", "an", "industrial", "robot", "branded", "Unimate", "."], "sentence-detokenized": "Devol collaborated with Engelberger, who served as the company's president, to design and produce an industrial robot branded Unimate.", "token2charspan": [[0, 5], [6, 18], [19, 23], [24, 35], [35, 36], [37, 40], [41, 47], [48, 50], [51, 54], [55, 62], [62, 64], [65, 74], [74, 75], [76, 78], [79, 85], [86, 89], [90, 97], [98, 100], [101, 111], [112, 117], [118, 125], [126, 133], [133, 134]]}
{"doc_key": "ai-test-181", "ner": [[2, 2, "algorithm"], [5, 5, "algorithm"], [9, 11, "algorithm"], [23, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 9, 11, "general-affiliation", "", false, false], [5, 5, 2, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "hidden", "Markov", "model", "(", "HMM", ")", "is", "a", "statistical", "Markov", "model", "in", "which", "the", "system", "being", "modelled", "is", "assumed", "to", "be", "a", "Markov", "process", "with", "unobserved", "(", "hidden", ")", "states", "."], "sentence-detokenized": "A hidden Markov model (HMM) is a statistical Markov model in which the system being modelled is assumed to be a Markov process with unobserved (hidden) states.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [22, 23], [23, 26], [26, 27], [28, 30], [31, 32], [33, 44], [45, 51], [52, 57], [58, 60], [61, 66], [67, 70], [71, 77], [78, 83], [84, 92], [93, 95], [96, 103], [104, 106], [107, 109], [110, 111], [112, 118], [119, 126], [127, 131], [132, 142], [143, 144], [144, 150], [150, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-test-182", "ner": [[17, 19, "metrics"], [25, 25, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "property", ",", "undesirable", "in", "many", "applications", ",", "has", "led", "researchers", "to", "use", "alternatives", "such", "as", "the", "mean", "absolute", "error", "or", "those", "based", "on", "the", "median", "."], "sentence-detokenized": "This property, undesirable in many applications, has led researchers to use alternatives such as the mean absolute error or those based on the median.", "token2charspan": [[0, 4], [5, 13], [13, 14], [15, 26], [27, 29], [30, 34], [35, 47], [47, 48], [49, 52], [53, 56], [57, 68], [69, 71], [72, 75], [76, 88], [89, 93], [94, 96], [97, 100], [101, 105], [106, 114], [115, 120], [121, 123], [124, 129], [130, 135], [136, 138], [139, 142], [143, 149], [149, 150]]}
{"doc_key": "ai-test-183", "ner": [[23, 24, "algorithm"], [32, 33, "field"], [36, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 32, 33, "part-of", "", false, false], [23, 24, 36, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Such", "a", "sequence", "(", "which", "depends", "on", "the", "result", "of", "the", "exploration", "of", "the", "previous", "features", "at", "each", "stage", ")", "is", "called", "a", "decision", "tree", "and", "is", "applied", "in", "the", "field", "of", "machine", "learning", "known", "as", "decision", "tree", "learning", "."], "sentence-detokenized": "Such a sequence (which depends on the result of the exploration of the previous features at each stage) is called a decision tree and is applied in the field of machine learning known as decision tree learning.", "token2charspan": [[0, 4], [5, 6], [7, 15], [16, 17], [17, 22], [23, 30], [31, 33], [34, 37], [38, 44], [45, 47], [48, 51], [52, 63], [64, 66], [67, 70], [71, 79], [80, 88], [89, 91], [92, 96], [97, 102], [102, 103], [104, 106], [107, 113], [114, 115], [116, 124], [125, 129], [130, 133], [134, 136], [137, 144], [145, 147], [148, 151], [152, 157], [158, 160], [161, 168], [169, 177], [178, 183], [184, 186], [187, 195], [196, 200], [201, 209], [209, 210]]}
{"doc_key": "ai-test-184", "ner": [[2, 3, "task"], [6, 6, "algorithm"], [18, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 6, 6, "compare", "", false, false], [18, 20, 6, 6, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "in", "factor", "analysis", ",", "the", "LCA", "can", "also", "be", "used", "to", "classify", "the", "case", "according", "to", "its", "maximum", "probability", "of", "inclusion", "in", "a", "class", "."], "sentence-detokenized": "As in factor analysis, the LCA can also be used to classify the case according to its maximum probability of inclusion in a class.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 21], [21, 22], [23, 26], [27, 30], [31, 34], [35, 39], [40, 42], [43, 47], [48, 50], [51, 59], [60, 63], [64, 68], [69, 78], [79, 81], [82, 85], [86, 93], [94, 105], [106, 108], [109, 118], [119, 121], [122, 123], [124, 129], [129, 130]]}
{"doc_key": "ai-test-185", "ner": [[0, 2, "algorithm"], [9, 10, "metrics"], [8, 12, "metrics"], [5, 7, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 9, 10, "usage", "", false, false], [9, 10, 5, 7, "related-to", "", false, false], [8, 12, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Supervised", "neural", "networks", "using", "a", "cost", "function", "of", "mean", "square", "error", "(", "MSE", ")", "can", "use", "formal", "statistical", "methods", "to", "determine", "the", "confidence", "of", "the", "trained", "model", "."], "sentence-detokenized": "Supervised neural networks using a cost function of mean square error (MSE) can use formal statistical methods to determine the confidence of the trained model.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 32], [33, 34], [35, 39], [40, 48], [49, 51], [52, 56], [57, 63], [64, 69], [70, 71], [71, 74], [74, 75], [76, 79], [80, 83], [84, 90], [91, 102], [103, 110], [111, 113], [114, 123], [124, 127], [128, 138], [139, 141], [142, 145], [146, 153], [154, 159], [159, 160]]}
{"doc_key": "ai-test-186", "ner": [[15, 16, "algorithm"], [19, 21, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 19, 21, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "expressed", "directly", "as", "a", "linear", "program", ",", "but", "is", "also", "equivalent", "to", "Tikhonov", "normalization", "with", "the", "joint", "loss", "function", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=\\", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "This can be expressed directly as a linear program, but is also equivalent to Tikhonov normalization with the joint loss function, mathV(f(x), y) =\\ max (0, 1 - yf(x))/math:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 21], [22, 30], [31, 33], [34, 35], [36, 42], [43, 50], [50, 51], [52, 55], [56, 58], [59, 63], [64, 74], [75, 77], [78, 86], [87, 100], [101, 105], [106, 109], [110, 115], [116, 120], [121, 129], [129, 130], [131, 136], [136, 137], [137, 138], [138, 139], [139, 140], [140, 141], [141, 142], [143, 144], [144, 145], [146, 148], [149, 152], [153, 154], [154, 155], [155, 156], [157, 158], [159, 160], [161, 163], [163, 164], [164, 165], [165, 166], [166, 167], [167, 168], [168, 172], [172, 173]]}
{"doc_key": "ai-test-187", "ner": [[14, 16, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "technique", "is", "described", "in", "Breiman", "'s", "original", "paper", "and", "implemented", "in", "the", "R", "package", "randomForest", "."], "sentence-detokenized": "The following technique is described in Breiman's original paper and implemented in the R package randomForest.", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 26], [27, 36], [37, 39], [40, 47], [47, 49], [50, 58], [59, 64], [65, 68], [69, 80], [81, 83], [84, 87], [88, 89], [90, 97], [98, 110], [110, 111]]}
{"doc_key": "ai-test-188", "ner": [[8, 8, "metrics"], [40, 40, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "measures", "of", "image", "quality", ",", "such", "as", "PSNR", ",", "are", "usually", "performed", "on", "fixed", "resolution", "images", "and", "do", "not", "take", "into", "account", "certain", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "the", "change", "in", "spatial", "resolution", "in", "the", "retina", "."], "sentence-detokenized": "Traditional measures of image quality, such as PSNR, are usually performed on fixed resolution images and do not take into account certain aspects of the human visual system, such as the change in spatial resolution in the retina.", "token2charspan": [[0, 11], [12, 20], [21, 23], [24, 29], [30, 37], [37, 38], [39, 43], [44, 46], [47, 51], [51, 52], [53, 56], [57, 64], [65, 74], [75, 77], [78, 83], [84, 94], [95, 101], [102, 105], [106, 108], [109, 112], [113, 117], [118, 122], [123, 130], [131, 138], [139, 146], [147, 149], [150, 153], [154, 159], [160, 166], [167, 173], [173, 174], [175, 179], [180, 182], [183, 186], [187, 193], [194, 196], [197, 204], [205, 215], [216, 218], [219, 222], [223, 229], [229, 230]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [10, 11, "person"], [16, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 19, "role", "", false, false], [3, 4, 16, 19, "role", "", false, false], [6, 7, 16, 19, "role", "", false, false], [16, 19, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "and", "Macdonald", "Carey", "starred", "in", "Jack", "Broder", "'s", "colour", "production", "of", "Hannah", "Lee", ",", "which", "premiered", "on", "19", "June", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru and Macdonald Carey starred in Jack Broder's colour production of Hannah Lee, which premiered on 19 June 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 55], [56, 60], [61, 67], [67, 69], [70, 76], [77, 87], [88, 90], [91, 97], [98, 101], [101, 102], [103, 108], [109, 118], [119, 121], [122, 124], [125, 129], [130, 134], [134, 135]]}
{"doc_key": "ai-test-190", "ner": [[4, 5, "task"], [11, 12, "field"], [17, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 11, 12, "usage", "", false, false], [17, 17, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "process", "is", "called", "image", "capture", "and", "uses", "various", "methods", "of", "computer", "vision", ",", "mainly", "related", "to", "tracking", "."], "sentence-detokenized": "This process is called image capture and uses various methods of computer vision, mainly related to tracking.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 22], [23, 28], [29, 36], [37, 40], [41, 45], [46, 53], [54, 61], [62, 64], [65, 73], [74, 80], [80, 81], [82, 88], [89, 96], [97, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-test-191", "ner": [[17, 18, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Now", "let", "'s", "start", "explaining", "the", "various", "possible", "relationships", "between", "the", "predicted", "and", "the", "actual", "outcome", ":", "Confusion", "table"], "sentence-detokenized": "Now let's start explaining the various possible relationships between the predicted and the actual outcome: Confusion table", "token2charspan": [[0, 3], [4, 7], [7, 9], [10, 15], [16, 26], [27, 30], [31, 38], [39, 47], [48, 61], [62, 69], [70, 73], [74, 83], [84, 87], [88, 91], [92, 98], [99, 106], [106, 107], [108, 117], [118, 123]]}
{"doc_key": "ai-test-192", "ner": [[1, 1, "product"], [2, 4, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 2, 4, "part-of", "", false, false], [1, 1, 2, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "VOICEBOX", "speech", "processing", "toolkit", "for", "MATLAB", "implements", "the", "conversion", "and", "inversion", "as", "follows", ":"], "sentence-detokenized": "The VOICEBOX speech processing toolkit for MATLAB implements the conversion and inversion as follows:", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 30], [31, 38], [39, 42], [43, 49], [50, 60], [61, 64], [65, 75], [76, 79], [80, 89], [90, 92], [93, 100], [100, 101]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "general-affiliation", "", false, false], [0, 0, 11, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logic", "programming", "language", "related", "to", "artificial", "intelligence", "and", "computational", "linguistics", "."], "sentence-detokenized": "Prolog is a logic programming language related to artificial intelligence and computational linguistics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 17], [18, 29], [30, 38], [39, 46], [47, 49], [50, 60], [61, 73], [74, 77], [78, 91], [92, 103], [103, 104]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [9, 9, "field"], [11, 11, "field"], [17, 20, "organisation"], [23, 26, "organisation"], [29, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 9, 9, "related-to", "works_with_topic", false, false], [0, 0, 11, 11, "related-to", "works_with_topic", false, false], [0, 0, 17, 20, "role", "", false, false], [0, 0, 23, 26, "role", "", false, false], [0, 0, 29, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "numerous", "awards", "for", "her", "contributions", "to", "neuroscience", "and", "psychology", ",", "including", "membership", "of", "the", "Royal", "Society", "of", "London", ",", "the", "Royal", "Society", "of", "Canada", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received numerous awards for her contributions to neuroscience and psychology, including membership of the Royal Society of London, the Royal Society of Canada and the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 35], [36, 39], [40, 43], [44, 57], [58, 60], [61, 73], [74, 77], [78, 88], [88, 89], [90, 99], [100, 110], [111, 113], [114, 117], [118, 123], [124, 131], [132, 134], [135, 141], [141, 142], [143, 146], [147, 152], [153, 160], [161, 163], [164, 170], [171, 174], [175, 178], [179, 187], [188, 195], [196, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-195", "ner": [[10, 11, "field"], [16, 17, "task"], [19, 20, "task"], [22, 23, "task"], [25, 26, "task"], [28, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[16, 17, 10, 11, "part-of", "task_part_of_field", false, false], [19, 20, 10, 11, "part-of", "task_part_of_field", false, false], [22, 23, 10, 11, "part-of", "task_part_of_field", false, false], [25, 26, 10, 11, "part-of", "task_part_of_field", false, false], [28, 28, 10, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["By", "combining", "these", "operators", "one", "can", "obtain", "algorithms", "for", "many", "image", "processing", "tasks", ",", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "sharpening", ",", "image", "filtering", "and", "classification", "."], "sentence-detokenized": "By combining these operators one can obtain algorithms for many image processing tasks, such as feature extraction, image segmentation, image sharpening, image filtering and classification.", "token2charspan": [[0, 2], [3, 12], [13, 18], [19, 28], [29, 32], [33, 36], [37, 43], [44, 54], [55, 58], [59, 63], [64, 69], [70, 80], [81, 86], [86, 87], [88, 92], [93, 95], [96, 103], [104, 114], [114, 115], [116, 121], [122, 134], [134, 135], [136, 141], [142, 152], [152, 153], [154, 159], [160, 169], [170, 173], [174, 188], [188, 189]]}
{"doc_key": "ai-test-196", "ner": [[9, 11, "university"], [19, 21, "organisation"], [23, 24, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "2017", "he", "has", "been", "a", "professor", "at", "the", "Coll\u00e8ge", "de", "France", "and", ",", "since", "1989", ",", "director", "of", "INSERM", "Unit", "562", ",", "Cognitive", "Neuroimaging", "."], "sentence-detokenized": "Since 2017 he has been a professor at the Coll\u00e8ge de France and, since 1989, director of INSERM Unit 562, Cognitive Neuroimaging.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 17], [18, 22], [23, 24], [25, 34], [35, 37], [38, 41], [42, 49], [50, 52], [53, 59], [60, 63], [63, 64], [65, 70], [71, 75], [75, 76], [77, 85], [86, 88], [89, 95], [96, 100], [101, 104], [104, 105], [106, 115], [116, 128], [128, 129]]}
{"doc_key": "ai-test-197", "ner": [[12, 14, "algorithm"], [16, 19, "algorithm"], [24, 24, "algorithm"], [26, 32, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[24, 24, 26, 32, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "many", "approaches", "to", "learning", "these", "embeddings", ",", "in", "particular", "using", "Bayesian", "clustering", "frameworks", "or", "energy", "-", "based", "frameworks", ",", "and", "more", "recently", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", "2013", ")", "."], "sentence-detokenized": "There are many approaches to learning these embeddings, in particular using Bayesian clustering frameworks or energy-based frameworks, and more recently TransE (Conference on Neural Information Processing Systems 2013).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 25], [26, 28], [29, 37], [38, 43], [44, 54], [54, 55], [56, 58], [59, 69], [70, 75], [76, 84], [85, 95], [96, 106], [107, 109], [110, 116], [116, 117], [117, 122], [123, 133], [133, 134], [135, 138], [139, 143], [144, 152], [153, 159], [160, 161], [161, 171], [172, 174], [175, 181], [182, 193], [194, 204], [205, 212], [213, 217], [217, 218], [218, 219]]}
{"doc_key": "ai-test-198", "ner": [[6, 7, "metrics"], [8, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 8, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "is", "an", "alternative", "to", "the", "Word", "Error", "Rate", "used", "in", "many", "countries", "."], "sentence-detokenized": "It is an alternative to the Word Error Rate used in many countries.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 23], [24, 27], [28, 32], [33, 38], [39, 43], [44, 48], [49, 51], [52, 56], [57, 66], [66, 67]]}
{"doc_key": "ai-test-199", "ner": [[0, 0, "algorithm"], [12, 13, "task"], [15, 16, "task"], [18, 19, "task"], [21, 23, "task"], [25, 29, "task"], [31, 32, "task"], [45, 45, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[12, 13, 0, 0, "usage", "", false, false], [15, 16, 0, 0, "usage", "", false, false], [18, 19, 0, 0, "usage", "", false, false], [21, 23, 0, 0, "usage", "", false, false], [25, 29, 0, 0, "usage", "", false, false], [31, 32, 0, 0, "usage", "", false, false], [45, 45, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "have", "been", "used", "in", "a", "variety", "of", "tasks", ",", "such", "as", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "desktop", "and", "video", "game", "playback", ",", "medical", "diagnostics", ",", "and", "even", "in", "activities", "traditionally", "considered", "exclusively", "human", ",", "such", "as", "painting", "."], "sentence-detokenized": "ANNs have been used in a variety of tasks, such as computer vision, speech recognition, machine translation, social network filtering, desktop and video game playback, medical diagnostics, and even in activities traditionally considered exclusively human, such as painting.", "token2charspan": [[0, 4], [5, 9], [10, 14], [15, 19], [20, 22], [23, 24], [25, 32], [33, 35], [36, 41], [41, 42], [43, 47], [48, 50], [51, 59], [60, 66], [66, 67], [68, 74], [75, 86], [86, 87], [88, 95], [96, 107], [107, 108], [109, 115], [116, 123], [124, 133], [133, 134], [135, 142], [143, 146], [147, 152], [153, 157], [158, 166], [166, 167], [168, 175], [176, 187], [187, 188], [189, 192], [193, 197], [198, 200], [201, 211], [212, 225], [226, 236], [237, 248], [249, 254], [254, 255], [256, 260], [261, 263], [264, 272], [272, 273]]}
{"doc_key": "ai-test-200", "ner": [[0, 4, "product"], [1, 6, "product"], [26, 28, "field"], [30, 30, "field"], [35, 35, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 26, 28, "related-to", "", false, false], [0, 4, 35, 35, "general-affiliation", "", false, false], [1, 6, 0, 4, "named", "", false, false], [30, 30, 26, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "is", "an", "open", "source", "research", "platform", "and", "a", "collection", "of", "voice", ",", "audio", ",", "speech", ",", "text", "and", "natural", "language", "processing", "(", "NLP", ")", "algorithms", "written", "in", "Java", "and", "arranged", "in", "a", "modular", "and", "extensible", "framework", "that", "seeks", "to", "facilitate", "the", "addition", "of", "new", "algorithms", "."], "sentence-detokenized": "The Modular Audio Recognition Framework (MARF) is an open source research platform and a collection of voice, audio, speech, text and natural language processing (NLP) algorithms written in Java and arranged in a modular and extensible framework that seeks to facilitate the addition of new algorithms.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 29], [30, 39], [40, 41], [41, 45], [45, 46], [47, 49], [50, 52], [53, 57], [58, 64], [65, 73], [74, 82], [83, 86], [87, 88], [89, 99], [100, 102], [103, 108], [108, 109], [110, 115], [115, 116], [117, 123], [123, 124], [125, 129], [130, 133], [134, 141], [142, 150], [151, 161], [162, 163], [163, 166], [166, 167], [168, 178], [179, 186], [187, 189], [190, 194], [195, 198], [199, 207], [208, 210], [211, 212], [213, 220], [221, 224], [225, 235], [236, 245], [246, 250], [251, 256], [257, 259], [260, 270], [271, 274], [275, 283], [284, 286], [287, 290], [291, 301], [301, 302]]}
{"doc_key": "ai-test-201", "ner": [[12, 14, "organisation"], [19, 19, "country"], [23, 25, "organisation"], [28, 29, "organisation"], [34, 35, "task"], [48, 51, "organisation"], [54, 55, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[23, 25, 19, 19, "physical", "", false, false], [23, 25, 34, 35, "usage", "", false, false], [23, 25, 48, 51, "named", "", false, false], [28, 29, 19, 19, "physical", "", false, false], [28, 29, 34, 35, "usage", "", false, false], [48, 51, 54, 55, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "a", "report", "by", "civil", "liberties", "and", "rights", "organisation", ",", "Big", "Brother", "Watch", ",", "revealed", "that", "two", "UK", "police", "forces", ",", "South", "Wales", "Police", "and", "the", "Metropolitan", "Police", ",", "were", "using", "live", "facial", "recognition", "at", "public", "events", "and", "in", "public", "places", ",", "in", "September", "2019", ",", "South", "Wales", "Police", "'s", "use", "of", "facial", "recognition", "was", "found", "to", "be", "legal", "."], "sentence-detokenized": "In 2018, a report by civil liberties and rights organisation, Big Brother Watch, revealed that two UK police forces, South Wales Police and the Metropolitan Police, were using live facial recognition at public events and in public places, in September 2019, South Wales Police's use of facial recognition was found to be legal.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 20], [21, 26], [27, 36], [37, 40], [41, 47], [48, 60], [60, 61], [62, 65], [66, 73], [74, 79], [79, 80], [81, 89], [90, 94], [95, 98], [99, 101], [102, 108], [109, 115], [115, 116], [117, 122], [123, 128], [129, 135], [136, 139], [140, 143], [144, 156], [157, 163], [163, 164], [165, 169], [170, 175], [176, 180], [181, 187], [188, 199], [200, 202], [203, 209], [210, 216], [217, 220], [221, 223], [224, 230], [231, 237], [237, 238], [239, 241], [242, 251], [252, 256], [256, 257], [258, 263], [264, 269], [270, 276], [276, 278], [279, 282], [283, 285], [286, 292], [293, 304], [305, 308], [309, 314], [315, 317], [318, 320], [321, 326], [326, 327]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [5, 5, "programlang"], [14, 15, "field"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 5, "general-affiliation", "", false, false], [0, 0, 14, 15, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "has", "been", "ported", "to", "R", ",", "a", "freely", "available", "language", "and", "environment", "for", "statistical", "computing", "and", "graphics", "."], "sentence-detokenized": "ANIMAL has been ported to R, a freely available language and environment for statistical computing and graphics.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [23, 25], [26, 27], [27, 28], [29, 30], [31, 37], [38, 47], [48, 56], [57, 60], [61, 72], [73, 76], [77, 88], [89, 98], [99, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-test-203", "ner": [[0, 5, "algorithm"], [7, 9, "algorithm"], [16, 17, "algorithm"], [18, 20, "algorithm"], [23, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 16, 17, "opposite", "alternative to", false, false], [7, 9, 0, 5, "named", "", false, false], [18, 20, 16, 17, "named", "", false, false], [23, 25, 0, 5, "usage", "", false, false], [23, 25, 16, 17, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "temporally", "inhomogeneous", "hidden", "Bernoulli", "model", "(", "TI", "-", "HBM", ")", "is", "an", "alternative", "to", "the", "hidden", "Markov", "model", "(", "HMM", ")", "for", "automatic", "speech", "recognition", "."], "sentence-detokenized": "The temporally inhomogeneous hidden Bernoulli model (TI-HBM) is an alternative to the hidden Markov model (HMM) for automatic speech recognition.", "token2charspan": [[0, 3], [4, 14], [15, 28], [29, 35], [36, 45], [46, 51], [52, 53], [53, 55], [55, 56], [56, 59], [59, 60], [61, 63], [64, 66], [67, 78], [79, 81], [82, 85], [86, 92], [93, 99], [100, 105], [106, 107], [107, 110], [110, 111], [112, 115], [116, 125], [126, 132], [133, 144], [144, 145]]}
{"doc_key": "ai-test-204", "ner": [[4, 4, "organisation"], [7, 7, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 7, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "Nvidia", "unveiled", "during", "SIGGRAPH", "a", "new", "foveated", "rendering", "method", "that", "claimed", "to", "be", "invisible", "to", "users", "."], "sentence-detokenized": "In July 2016, Nvidia unveiled during SIGGRAPH a new foveated rendering method that claimed to be invisible to users.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 29], [30, 36], [37, 45], [46, 47], [48, 51], [52, 60], [61, 70], [71, 77], [78, 82], [83, 90], [91, 93], [94, 96], [97, 106], [107, 109], [110, 115], [115, 116]]}
{"doc_key": "ai-test-205", "ner": [[5, 8, "misc"], [11, 14, "researcher"], [19, 20, "researcher"], [22, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 8, 11, 14, "origin", "", false, false], [5, 8, 19, 20, "origin", "", false, false], [5, 8, 22, 24, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Both", "are", "based", "on", "the", "theory", "of", "speech", "acts", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "reinforced", "by", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both are based on the theory of speech acts developed by John Searle in the 1960s and reinforced by Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 17], [18, 21], [22, 28], [29, 31], [32, 38], [39, 43], [44, 53], [54, 56], [57, 61], [62, 68], [69, 71], [72, 75], [76, 81], [82, 85], [86, 96], [97, 99], [100, 105], [106, 114], [115, 118], [119, 125], [126, 128], [129, 132], [133, 138], [138, 139]]}
{"doc_key": "ai-test-206", "ner": [[0, 3, "algorithm"], [21, 21, "researcher"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 21, 21, "related-to", "", false, false], [24, 24, 21, 21, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "knowledge", "structure", "have", "opened", "up", "powerful", "hierarchical", "models", "of", "knowledge", "organization", ",", "such", "as", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "Neural network models of concept formation and knowledge structure have opened up powerful hierarchical models of knowledge organization, such as George Miller's Wordnet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 56], [57, 66], [67, 71], [72, 78], [79, 81], [82, 90], [91, 103], [104, 110], [111, 113], [114, 123], [124, 136], [136, 137], [138, 142], [143, 145], [146, 152], [153, 159], [159, 161], [162, 169], [169, 170]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [12, 13, "field"], [16, 18, "product"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 13, "part-of", "", false, false], [0, 1, 21, 23, "part-of", "", false, false], [16, 18, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Pattern", "matching", "has", "various", "applications", "and", "is", "used", "in", "areas", "such", "as", "face", "recognition", "(", "see", "face", "recognition", "system", ")", "and", "medical", "image", "processing", "."], "sentence-detokenized": "Pattern matching has various applications and is used in areas such as face recognition (see face recognition system) and medical image processing.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 28], [29, 41], [42, 45], [46, 48], [49, 53], [54, 56], [57, 62], [63, 67], [68, 70], [71, 75], [76, 87], [88, 89], [89, 92], [93, 97], [98, 109], [110, 116], [116, 117], [118, 121], [122, 129], [130, 135], [136, 146], [146, 147]]}
{"doc_key": "ai-test-208", "ner": [[11, 12, "researcher"], [14, 15, "researcher"], [20, 29, "organisation"], [31, 31, "organisation"], [39, 40, "algorithm"], [43, 49, "conference"], [45, 51, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 12, 20, 29, "role", "", false, false], [11, 12, 43, 49, "physical", "", false, false], [11, 12, 43, 49, "temporal", "", false, false], [11, 12, 45, 51, "physical", "", false, false], [14, 15, 20, 29, "role", "", false, false], [14, 15, 43, 49, "temporal", "", false, false], [31, 31, 20, 29, "named", "", false, false], [43, 49, 39, 40, "topic", "", false, false], [45, 51, 43, 49, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "their", "use", "only", "became", "widespread", "in", "2005", ",", "when", "Navneet", "Dalal", "and", "Bill", "Triggs", ",", "researchers", "at", "the", "French", "National", "Institute", "for", "Research", "in", "Computer", "Science", "and", "Automation", "(", "INRIA", ")", ",", "presented", "their", "complementary", "work", "on", "HOG", "descriptors", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "However, their use only became widespread in 2005, when Navneet Dalal and Bill Triggs, researchers at the French National Institute for Research in Computer Science and Automation (INRIA), presented their complementary work on HOG descriptors at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 18], [19, 23], [24, 30], [31, 41], [42, 44], [45, 49], [49, 50], [51, 55], [56, 63], [64, 69], [70, 73], [74, 78], [79, 85], [85, 86], [87, 98], [99, 101], [102, 105], [106, 112], [113, 121], [122, 131], [132, 135], [136, 144], [145, 147], [148, 156], [157, 164], [165, 168], [169, 179], [180, 181], [181, 186], [186, 187], [187, 188], [189, 198], [199, 204], [205, 218], [219, 223], [224, 226], [227, 230], [231, 242], [243, 245], [246, 249], [250, 260], [261, 263], [264, 272], [273, 279], [280, 283], [284, 291], [292, 303], [304, 305], [305, 309], [309, 310], [310, 311]]}
{"doc_key": "ai-test-209", "ner": [[4, 4, "university"], [17, 20, "organisation"], [22, 23, "organisation"], [30, 30, "field"], [36, 38, "researcher"], [40, 43, "researcher"], [46, 48, "researcher"], [51, 54, "organisation"], [58, 60, "organisation"], [65, 66, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[22, 23, 30, 30, "related-to", "", false, false], [36, 38, 22, 23, "physical", "", false, false], [36, 38, 22, 23, "role", "", false, false], [40, 43, 22, 23, "physical", "", false, false], [40, 43, 22, 23, "role", "", false, false], [46, 48, 22, 23, "physical", "", false, false], [46, 48, 22, 23, "role", "", false, false], [65, 66, 58, 60, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Prior", "to", "joining", "the", "Penn", "faculty", "in", "2002", ",", "he", "spent", "a", "decade", "(", "1991-2001", ")", "at", "AT", "&", "T", "Labs", "and", "Bell", "Labs", ",", "including", "as", "head", "of", "the", "AI", "Division", "with", "colleagues", "such", "as", "Michael", "L.", "Littman", ",", "David", "A", ".", "McAllester", ",", "and", "Richard", "S.", "Sutton", ",", "the", "Secure", "Systems", "Research", "Division", ",", "and", "the", "Machine", "Learning", "Division", "with", "members", "such", "as", "Michael", "Collins", "and", "the", "Chief", ")", "."], "sentence-detokenized": "Prior to joining the Penn faculty in 2002, he spent a decade (1991-2001) at AT & T Labs and Bell Labs, including as head of the AI Division with colleagues such as Michael L. Littman, David A. McAllester, and Richard S. Sutton, the Secure Systems Research Division, and the Machine Learning Division with members such as Michael Collins and the Chief).", "token2charspan": [[0, 5], [6, 8], [9, 16], [17, 20], [21, 25], [26, 33], [34, 36], [37, 41], [41, 42], [43, 45], [46, 51], [52, 53], [54, 60], [61, 62], [62, 71], [71, 72], [73, 75], [76, 78], [79, 80], [81, 82], [83, 87], [88, 91], [92, 96], [97, 101], [101, 102], [103, 112], [113, 115], [116, 120], [121, 123], [124, 127], [128, 130], [131, 139], [140, 144], [145, 155], [156, 160], [161, 163], [164, 171], [172, 174], [175, 182], [182, 183], [184, 189], [190, 191], [191, 192], [193, 203], [203, 204], [205, 208], [209, 216], [217, 219], [220, 226], [226, 227], [228, 231], [232, 238], [239, 246], [247, 255], [256, 264], [264, 265], [266, 269], [270, 273], [274, 281], [282, 290], [291, 299], [300, 304], [305, 312], [313, 317], [318, 320], [321, 328], [329, 336], [337, 340], [341, 344], [345, 350], [350, 351], [351, 352]]}
{"doc_key": "ai-test-210", "ner": [[5, 7, "field"], [12, 13, "field"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 12, 13, "compare", "", false, false], [23, 24, 12, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["When", "data", "is", "unlabeled", ",", "supervised", "learning", "is", "not", "possible", "and", "an", "unsupervised", "learning", "approach", "is", "required", ",", "which", "tries", "to", "find", "natural", "cluster", "analysis", "in", "clusters", "and", "then", "assign", "new", "data", "to", "these", "clusters", "formed", "."], "sentence-detokenized": "When data is unlabeled, supervised learning is not possible and an unsupervised learning approach is required, which tries to find natural cluster analysis in clusters and then assign new data to these clusters formed.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 22], [22, 23], [24, 34], [35, 43], [44, 46], [47, 50], [51, 59], [60, 63], [64, 66], [67, 79], [80, 88], [89, 97], [98, 100], [101, 109], [109, 110], [111, 116], [117, 122], [123, 125], [126, 130], [131, 138], [139, 146], [147, 155], [156, 158], [159, 167], [168, 171], [172, 176], [177, 183], [184, 187], [188, 192], [193, 195], [196, 201], [202, 210], [211, 217], [217, 218]]}
{"doc_key": "ai-test-211", "ner": [[3, 4, "field"], [16, 19, "organisation"], [26, 27, "field"], [29, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 16, 19, "origin", "", false, false], [3, 4, 26, 27, "part-of", "", false, false], [3, 4, 29, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "field", "of", "computer", "science", "was", "developed", "in", "the", "1950s", "at", "academic", "institutions", "such", "as", "the", "MIT", "A.I", ".", "Lab", ",", "initially", "as", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "This field of computer science was developed in the 1950s at academic institutions such as the MIT A.I. Lab, initially as a branch of artificial intelligence and robotics.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 30], [31, 34], [35, 44], [45, 47], [48, 51], [52, 57], [58, 60], [61, 69], [70, 82], [83, 87], [88, 90], [91, 94], [95, 98], [99, 102], [102, 103], [104, 107], [107, 108], [109, 118], [119, 121], [122, 123], [124, 130], [131, 133], [134, 144], [145, 157], [158, 161], [162, 170], [170, 171]]}
{"doc_key": "ai-test-212", "ner": [[8, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "could", "also", "be", "replaced", "by", "the", "following", "Log", "loss", "equation", ":"], "sentence-detokenized": "It could also be replaced by the following Log loss equation:", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 16], [17, 25], [26, 28], [29, 32], [33, 42], [43, 46], [47, 51], [52, 60], [60, 61]]}
{"doc_key": "ai-test-213", "ner": [[1, 3, "organisation"], [6, 10, "organisation"], [14, 18, "university"], [20, 20, "university"], [22, 23, "university"], [26, 28, "university"], [31, 31, "country"], [35, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 3, 35, 35, "related-to", "research_leader_in_field", false, false], [6, 10, 1, 3, "named", "", false, false], [6, 10, 35, 35, "related-to", "research_leader_in_field", false, false], [14, 18, 35, 35, "related-to", "research_leader_in_field", false, false], [20, 20, 35, 35, "related-to", "research_leader_in_field", false, false], [22, 23, 35, 35, "related-to", "research_leader_in_field", false, false], [26, 28, 31, 31, "physical", "", false, false], [26, 28, 35, 35, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "Shirley", "Ryan", "AbilityLab", "(", "formerly", "the", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "the", "University", "of", "California", "at", "Berkeley", ",", "MIT", ",", "Stanford", "University", "and", "the", "University", "of", "Twente", "in", "the", "Netherlands", "are", "leaders", "in", "biomechatronics", "research", "."], "sentence-detokenized": "The Shirley Ryan AbilityLab (formerly the Rehabilitation Institute of Chicago), the University of California at Berkeley, MIT, Stanford University and the University of Twente in the Netherlands are leaders in biomechatronics research.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 27], [28, 29], [29, 37], [38, 41], [42, 56], [57, 66], [67, 69], [70, 77], [77, 78], [78, 79], [80, 83], [84, 94], [95, 97], [98, 108], [109, 111], [112, 120], [120, 121], [122, 125], [125, 126], [127, 135], [136, 146], [147, 150], [151, 154], [155, 165], [166, 168], [169, 175], [176, 178], [179, 182], [183, 194], [195, 198], [199, 206], [207, 209], [210, 225], [226, 234], [234, 235]]}
{"doc_key": "ai-test-214", "ner": [[28, 31, "metrics"], [42, 42, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Given", "a", "set", "of", "predicted", "values", "and", "a", "corresponding", "set", "of", "actual", "values", "for", "X", "for", "various", "time", "periods", ",", "a", "common", "evaluation", "technique", "is", "to", "use", "the", "mean", "squared", "forecast", "error", ";", "other", "measures", "also", "exist", "(", "see", "forecast", "#", "forecast", "accuracy", ")", "."], "sentence-detokenized": "Given a set of predicted values and a corresponding set of actual values for X for various time periods, a common evaluation technique is to use the mean squared forecast error; other measures also exist (see forecast # forecast accuracy).", "token2charspan": [[0, 5], [6, 7], [8, 11], [12, 14], [15, 24], [25, 31], [32, 35], [36, 37], [38, 51], [52, 55], [56, 58], [59, 65], [66, 72], [73, 76], [77, 78], [79, 82], [83, 90], [91, 95], [96, 103], [103, 104], [105, 106], [107, 113], [114, 124], [125, 134], [135, 137], [138, 140], [141, 144], [145, 148], [149, 153], [154, 161], [162, 170], [171, 176], [176, 177], [178, 183], [184, 192], [193, 197], [198, 203], [204, 205], [205, 208], [209, 217], [218, 219], [220, 228], [229, 237], [237, 238], [238, 239]]}
{"doc_key": "ai-test-215", "ner": [[13, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "measures", ",", "such", "as", "the", "percentage", "of", "correct", "predictions", "(", "also", "called", "accuracy", ")", ",", "are", "not", "useful", "when", "the", "two", "classes", "have", "very", "different", "sizes", "."], "sentence-detokenized": "Other measures, such as the percentage of correct predictions (also called accuracy), are not useful when the two classes have very different sizes.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 20], [21, 23], [24, 27], [28, 38], [39, 41], [42, 49], [50, 61], [62, 63], [63, 67], [68, 74], [75, 83], [83, 84], [84, 85], [86, 89], [90, 93], [94, 100], [101, 105], [106, 109], [110, 113], [114, 121], [122, 126], [127, 131], [132, 141], [142, 147], [147, 148]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [13, 17, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 13, 17, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "released", "to", "the", "public", "at", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "conference", "in", "2000", ",", "and", "five", "betas", "were", "released", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was released to the public at the Computer Vision and Pattern Recognition conference in 2000, and five betas were released between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 46], [47, 49], [50, 53], [54, 60], [61, 63], [64, 67], [68, 76], [77, 83], [84, 87], [88, 95], [96, 107], [108, 118], [119, 121], [122, 126], [126, 127], [128, 131], [132, 136], [137, 142], [143, 147], [148, 156], [157, 164], [165, 169], [170, 173], [174, 178], [178, 179]]}
{"doc_key": "ai-test-217", "ner": [[23, 23, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Results", "were", "presented", "that", "give", "a", "correlation", "of", "up", "to", "0.964", "with", "human", "judgment", "at", "the", "data", "corpus", "level", ",", "compared", "to", "the", "BLEU", "result", "of", "0.817", "on", "the", "same", "data", "set", "."], "sentence-detokenized": "Results were presented that give a correlation of up to 0.964 with human judgment at the data corpus level, compared to the BLEU result of 0.817 on the same data set.", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 27], [28, 32], [33, 34], [35, 46], [47, 49], [50, 52], [53, 55], [56, 61], [62, 66], [67, 72], [73, 81], [82, 84], [85, 88], [89, 93], [94, 100], [101, 106], [106, 107], [108, 116], [117, 119], [120, 123], [124, 128], [129, 135], [136, 138], [139, 144], [145, 147], [148, 151], [152, 156], [157, 161], [162, 165], [165, 166]]}
{"doc_key": "ai-test-218", "ner": [[4, 4, "metrics"], [19, 19, "metrics"], [21, 23, "metrics"], [25, 27, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 19, 19, "compare", "", false, false], [4, 4, 21, 23, "compare", "", false, false], [4, 4, 25, 27, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["An", "early", "version", "of", "VMAF", "has", "been", "shown", "to", "outperform", "other", "image", "and", "video", "quality", "metrics", ",", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", "and", "VQM", "-", "VFD", ",", "on", "three", "of", "the", "four", "datasets", "in", "terms", "of", "prediction", "accuracy", ",", "compared", "to", "subjective", "ratings", "."], "sentence-detokenized": "An early version of VMAF has been shown to outperform other image and video quality metrics, such as SSIM, PSNR -HVS and VQM-VFD, on three of the four datasets in terms of prediction accuracy, compared to subjective ratings.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 19], [20, 24], [25, 28], [29, 33], [34, 39], [40, 42], [43, 53], [54, 59], [60, 65], [66, 69], [70, 75], [76, 83], [84, 91], [91, 92], [93, 97], [98, 100], [101, 105], [105, 106], [107, 111], [112, 113], [113, 116], [117, 120], [121, 124], [124, 125], [125, 128], [128, 129], [130, 132], [133, 138], [139, 141], [142, 145], [146, 150], [151, 159], [160, 162], [163, 168], [169, 171], [172, 182], [183, 191], [191, 192], [193, 201], [202, 204], [205, 215], [216, 223], [223, 224]]}
{"doc_key": "ai-test-219", "ner": [[20, 24, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 24, 28, 29, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "of", "the", "term", "\"", "mouse", "\"", "(", "animal", "or", "device", ")", "is", "not", "relevant", "for", "machine", "translation", ",", "but", "it", "is", "relevant", "for", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity of the term \"mouse\" (animal or device) is not relevant for machine translation, but it is relevant for information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 33], [34, 38], [39, 40], [40, 45], [45, 46], [47, 48], [48, 54], [55, 57], [58, 64], [64, 65], [66, 68], [69, 72], [73, 81], [82, 85], [86, 93], [94, 105], [105, 106], [107, 110], [111, 113], [114, 116], [117, 125], [126, 129], [130, 141], [142, 151], [151, 152]]}
{"doc_key": "ai-test-220", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 1, "usage", "", false, false], [9, 10, 6, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "segmentation", "was", "originally", "proposed", "in", "computer", "vision", "for", "object", "recognition", "in", "2D", "and", "3D", ","], "sentence-detokenized": "Geometric segmentation was originally proposed in computer vision for object recognition in 2D and 3D,", "token2charspan": [[0, 9], [10, 22], [23, 26], [27, 37], [38, 46], [47, 49], [50, 58], [59, 65], [66, 69], [70, 76], [77, 88], [89, 91], [92, 94], [95, 98], [99, 101], [101, 102]]}
{"doc_key": "ai-test-221", "ner": [[9, 10, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 9, 10, "part-of", "subfield", false, false], [17, 18, 9, 10, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "is", "one", "of", "the", "three", "main", "categories", "of", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "It is one of the three main categories of machine learning, along with supervised learning and reinforcement learning.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 12], [13, 16], [17, 22], [23, 27], [28, 38], [39, 41], [42, 49], [50, 58], [58, 59], [60, 65], [66, 70], [71, 81], [82, 90], [91, 94], [95, 108], [109, 117], [117, 118]]}
{"doc_key": "ai-test-222", "ner": [[5, 6, "field"], [16, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"], [27, 30, "field"], [32, 33, "field"], [35, 36, "field"], [38, 38, "field"], [40, 41, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[5, 6, 16, 16, "part-of", "subfield", false, false], [5, 6, 18, 19, "part-of", "subfield", false, false], [5, 6, 21, 22, "part-of", "subfield", false, false], [5, 6, 24, 25, "part-of", "subfield", false, false], [5, 6, 27, 30, "part-of", "subfield", false, false], [5, 6, 32, 33, "part-of", "subfield", false, false], [5, 6, 35, 36, "part-of", "subfield", false, false], [5, 6, 38, 38, "part-of", "subfield", false, false], [5, 6, 40, 41, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Because", "of", "its", "generality", ",", "reinforcement", "learning", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "games", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimization", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Because of its generality, reinforcement learning is studied in many other disciplines, such as games, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [25, 26], [27, 40], [41, 49], [50, 52], [53, 60], [61, 63], [64, 68], [69, 74], [75, 86], [86, 87], [88, 92], [93, 95], [96, 101], [101, 102], [103, 110], [111, 117], [117, 118], [119, 129], [130, 138], [138, 139], [140, 151], [152, 158], [158, 159], [160, 170], [170, 171], [171, 176], [177, 189], [189, 190], [191, 202], [203, 210], [210, 211], [212, 217], [218, 230], [230, 231], [232, 242], [243, 246], [247, 254], [255, 265], [265, 266]]}
{"doc_key": "ai-test-223", "ner": [[0, 2, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 7, "related-to", "", false, false], [0, 2, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pattern", "recognition", "is", "closely", "linked", "to", "artificial", "intelligence", "and", "machine", "learning", ","], "sentence-detokenized": "Pattern recognition is closely linked to artificial intelligence and machine learning,", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 37], [38, 40], [41, 51], [52, 64], [65, 68], [69, 76], [77, 85], [85, 86]]}
{"doc_key": "ai-test-224", "ner": [[10, 11, "algorithm"], [14, 15, "field"], [17, 18, "field"], [30, 31, "task"], [33, 33, "task"], [35, 36, "task"], [38, 39, "algorithm"], [41, 43, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 14, 15, "related-to", "", false, false], [10, 11, 17, 18, "related-to", "", false, false], [30, 31, 10, 11, "usage", "", true, false], [33, 33, 10, 11, "usage", "", true, false], [35, 36, 10, 11, "usage", "", true, false], [38, 39, 10, 11, "usage", "", true, false], [41, 43, 10, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "software", "is", "used", "to", "design", ",", "train", "and", "develop", "neural", "network", "models", "(", "supervised", "learning", "and", "unsupervised", "learning", ")", "to", "perform", "a", "wide", "variety", "of", "tasks", ",", "such", "as", "data", "mining", ",", "classification", ",", "function", "approximation", ",", "multivariate", "regression", "and", "time", "series", "prediction", "."], "sentence-detokenized": "The software is used to design, train and develop neural network models (supervised learning and unsupervised learning) to perform a wide variety of tasks, such as data mining, classification, function approximation, multivariate regression and time series prediction.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [21, 23], [24, 30], [30, 31], [32, 37], [38, 41], [42, 49], [50, 56], [57, 64], [65, 71], [72, 73], [73, 83], [84, 92], [93, 96], [97, 109], [110, 118], [118, 119], [120, 122], [123, 130], [131, 132], [133, 137], [138, 145], [146, 148], [149, 154], [154, 155], [156, 160], [161, 163], [164, 168], [169, 175], [175, 176], [177, 191], [191, 192], [193, 201], [202, 215], [215, 216], [217, 229], [230, 240], [241, 244], [245, 249], [250, 256], [257, 267], [267, 268]]}
{"doc_key": "ai-test-225", "ner": [[9, 15, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", "he", "was", "elected", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016 he was elected a member of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 24], [25, 31], [32, 34], [35, 38], [39, 50], [51, 54], [55, 58], [59, 70], [71, 73], [74, 84], [85, 97], [97, 98]]}
{"doc_key": "ai-test-226", "ner": [[6, 9, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", "and", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", ","], "sentence-detokenized": "He is a member of the National Academy of Sciences (since 2005) and the American Academy of Arts and Sciences (since 2009),", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 50], [51, 52], [52, 57], [58, 62], [62, 63], [64, 67], [68, 71], [72, 80], [81, 88], [89, 91], [92, 96], [97, 100], [101, 109], [110, 111], [111, 116], [117, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-test-227", "ner": [[3, 5, "misc"], [8, 13, "product"], [16, 16, "country"], [18, 18, "country"], [23, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 13, 3, 5, "temporal", "", false, false], [8, 13, 16, 16, "physical", "", false, false], [8, 13, 18, 18, "physical", "", false, false], [8, 13, 23, 25, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "the", "1973", "Yom", "Kippur", "War", ",", "Soviet", "surface", "-", "to", "-", "air", "missile", "batteries", "in", "Egypt", "and", "Syria", "caused", "serious", "damage", "to", "Israeli", "fighter", "aircraft", "."], "sentence-detokenized": "During the 1973 Yom Kippur War, Soviet surface-to-air missile batteries in Egypt and Syria caused serious damage to Israeli fighter aircraft.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 26], [27, 30], [30, 31], [32, 38], [39, 46], [46, 47], [47, 49], [49, 50], [50, 53], [54, 61], [62, 71], [72, 74], [75, 80], [81, 84], [85, 90], [91, 97], [98, 105], [106, 112], [113, 115], [116, 123], [124, 131], [132, 140], [140, 141]]}
{"doc_key": "ai-test-228", "ner": [[9, 10, "product"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "resource", "(", "free", "but", "copyrighted", ")", "is", "the", "HTK", "book", "(", "and", "the", "accompanying", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another resource (free but copyrighted) is the HTK book (and the accompanying HTK toolkit).", "token2charspan": [[0, 7], [8, 16], [17, 18], [18, 22], [23, 26], [27, 38], [38, 39], [40, 42], [43, 46], [47, 50], [51, 55], [56, 57], [57, 60], [61, 64], [65, 77], [78, 81], [82, 89], [89, 90], [90, 91]]}
{"doc_key": "ai-test-229", "ner": [[5, 6, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "were", "taken", "at", "the", "2004", "AAAI", "Spring", "Symposium", ",", "where", "linguists", ",", "computer", "scientists", "and", "other", "interested", "researchers", "aligned", "their", "interests", "for", "the", "first", "time", "and", "proposed", "common", "tasks", "and", "reference", "datasets", "for", "systematic", "computational", "research", "on", "emotion", ",", "appeal", ",", "subjectivity", "and", "sentiment", "in", "texts", "."], "sentence-detokenized": "- were taken at the 2004 AAAI Spring Symposium, where linguists, computer scientists and other interested researchers aligned their interests for the first time and proposed common tasks and reference datasets for systematic computational research on emotion, appeal, subjectivity and sentiment in texts.", "token2charspan": [[0, 1], [2, 6], [7, 12], [13, 15], [16, 19], [20, 24], [25, 29], [30, 36], [37, 46], [46, 47], [48, 53], [54, 63], [63, 64], [65, 73], [74, 84], [85, 88], [89, 94], [95, 105], [106, 117], [118, 125], [126, 131], [132, 141], [142, 145], [146, 149], [150, 155], [156, 160], [161, 164], [165, 173], [174, 180], [181, 186], [187, 190], [191, 200], [201, 209], [210, 213], [214, 224], [225, 238], [239, 247], [248, 250], [251, 258], [258, 259], [260, 266], [266, 267], [268, 280], [281, 284], [285, 294], [295, 297], [298, 303], [303, 304]]}
{"doc_key": "ai-test-230", "ner": [[12, 14, "task"], [19, 20, "task"], [22, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "single", "grid", "can", "be", "analysed", "both", "in", "terms", "of", "content", "(", "inspection", "by", "eye", ")", "and", "structure", "(", "cluster", "analysis", ",", "principal", "component", "analysis", "and", "various", "structural", "indicators", "related", "to", "the", "complexity", "and", "breadth", "of", "evaluations", "are", "the", "main", "techniques", "used", ")", "."], "sentence-detokenized": "A single grid can be analysed both in terms of content (inspection by eye) and structure (cluster analysis, principal component analysis and various structural indicators related to the complexity and breadth of evaluations are the main techniques used).", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 17], [18, 20], [21, 29], [30, 34], [35, 37], [38, 43], [44, 46], [47, 54], [55, 56], [56, 66], [67, 69], [70, 73], [73, 74], [75, 78], [79, 88], [89, 90], [90, 97], [98, 106], [106, 107], [108, 117], [118, 127], [128, 136], [137, 140], [141, 148], [149, 159], [160, 170], [171, 178], [179, 181], [182, 185], [186, 196], [197, 200], [201, 208], [209, 211], [212, 223], [224, 227], [228, 231], [232, 236], [237, 247], [248, 252], [252, 253], [253, 254]]}
{"doc_key": "ai-test-231", "ner": [[2, 2, "organisation"], [10, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", "Toyota", "was", "seen", "as", "being", "behind", "in", "the", "self", "-", "driving", "car", "and", "in", "need", "of", "innovation", "."], "sentence-detokenized": "In 2018 Toyota was seen as being behind in the self-driving car and in need of innovation.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 23], [24, 26], [27, 32], [33, 39], [40, 42], [43, 46], [47, 51], [51, 52], [52, 59], [60, 63], [64, 67], [68, 70], [71, 75], [76, 78], [79, 89], [89, 90]]}
{"doc_key": "ai-test-232", "ner": [[40, 41, "misc"], [43, 44, "misc"], [46, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "targets", "include", "natural", "objects", "such", "as", "the", "ground", ",", "the", "sea", ",", "precipitation", "(", "such", "as", "rain", ",", "snow", "or", "hail", ")", ",", "sandstorms", ",", "animals", "(", "especially", "birds", ")", ",", "atmospheric", "turbulence", "and", "other", "atmospheric", "phenomena", "such", "as", "ionospheric", "reflections", ",", "meteor", "trails", "and", "three", "-", "body", "scattering", "peaks", "."], "sentence-detokenized": "Such targets include natural objects such as the ground, the sea, precipitation (such as rain, snow or hail), sandstorms, animals (especially birds), atmospheric turbulence and other atmospheric phenomena such as ionospheric reflections, meteor trails and three-body scattering peaks.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 28], [29, 36], [37, 41], [42, 44], [45, 48], [49, 55], [55, 56], [57, 60], [61, 64], [64, 65], [66, 79], [80, 81], [81, 85], [86, 88], [89, 93], [93, 94], [95, 99], [100, 102], [103, 107], [107, 108], [108, 109], [110, 120], [120, 121], [122, 129], [130, 131], [131, 141], [142, 147], [147, 148], [148, 149], [150, 161], [162, 172], [173, 176], [177, 182], [183, 194], [195, 204], [205, 209], [210, 212], [213, 224], [225, 236], [236, 237], [238, 244], [245, 251], [252, 255], [256, 261], [261, 262], [262, 266], [267, 277], [278, 283], [283, 284]]}
{"doc_key": "ai-test-233", "ner": [[19, 20, "product"], [39, 40, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "design", "and", "control", ",", "the", "essential", "difference", "between", "humanoid", "robots", "and", "other", "types", "of", "robots", "(", "such", "as", "industrial", "robots", ")", "is", "that", "the", "robot", "'s", "movement", "must", "resemble", "human", "movement", ",", "using", "leg", "movement", ",", "in", "particular", "bipedal", "walking", "."], "sentence-detokenized": "In design and control, the essential difference between humanoid robots and other types of robots (such as industrial robots) is that the robot's movement must resemble human movement, using leg movement, in particular bipedal walking.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 21], [21, 22], [23, 26], [27, 36], [37, 47], [48, 55], [56, 64], [65, 71], [72, 75], [76, 81], [82, 87], [88, 90], [91, 97], [98, 99], [99, 103], [104, 106], [107, 117], [118, 124], [124, 125], [126, 128], [129, 133], [134, 137], [138, 143], [143, 145], [146, 154], [155, 159], [160, 168], [169, 174], [175, 183], [183, 184], [185, 190], [191, 194], [195, 203], [203, 204], [205, 207], [208, 218], [219, 226], [227, 234], [234, 235]]}
{"doc_key": "ai-test-234", "ner": [[1, 2, "algorithm"], [10, 11, "misc"], [15, 15, "metrics"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "gradient", "descent", "may", "need", "many", "iterations", "to", "calculate", "a", "local", "minimum", "with", "the", "required", "accuracy", "if", "the", "curvature", "in", "different", "directions", "is", "very", "different", "for", "the", "particular", "function", "."], "sentence-detokenized": "The gradient descent may need many iterations to calculate a local minimum with the required accuracy if the curvature in different directions is very different for the particular function.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 24], [25, 29], [30, 34], [35, 45], [46, 48], [49, 58], [59, 60], [61, 66], [67, 74], [75, 79], [80, 83], [84, 92], [93, 101], [102, 104], [105, 108], [109, 118], [119, 121], [122, 131], [132, 142], [143, 145], [146, 150], [151, 160], [161, 164], [165, 168], [169, 179], [180, 188], [188, 189]]}
{"doc_key": "ai-test-235", "ner": [[1, 6, "misc"], [10, 10, "misc"], [19, 23, "conference"], [26, 26, "location"], [28, 29, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 6, 10, 10, "part-of", "", true, false], [19, 23, 26, 26, "physical", "", false, true], [26, 26, 28, 29, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "1997", "RoboCup", "2D", "Soccer", "Simulation", "League", "was", "the", "first", "RoboCup", "competition", "to", "be", "promoted", "in", "conjunction", "with", "the", "International", "Joint", "Artificial", "Intelligence", "Conference", "held", "in", "Nagoya", ",", "Japan", "from", "23", "to", "29", "August", "1997", "."], "sentence-detokenized": "The 1997 RoboCup 2D Soccer Simulation League was the first RoboCup competition to be promoted in conjunction with the International Joint Artificial Intelligence Conference held in Nagoya, Japan from 23 to 29 August 1997.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 19], [20, 26], [27, 37], [38, 44], [45, 48], [49, 52], [53, 58], [59, 66], [67, 78], [79, 81], [82, 84], [85, 93], [94, 96], [97, 108], [109, 113], [114, 117], [118, 131], [132, 137], [138, 148], [149, 161], [162, 172], [173, 177], [178, 180], [181, 187], [187, 188], [189, 194], [195, 199], [200, 202], [203, 205], [206, 208], [209, 215], [216, 220], [220, 221]]}
{"doc_key": "ai-test-236", "ner": [[8, 8, "programlang"], [12, 12, "programlang"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "options", "include", "a", "built", "-", "in", "Python", "environment", "and", "an", "R", "console", "as", "well", "as", "support", "for", "Rserve", "."], "sentence-detokenized": "Other programming options include a built-in Python environment and an R console as well as support for Rserve.", "token2charspan": [[0, 5], [6, 17], [18, 25], [26, 33], [34, 35], [36, 41], [41, 42], [42, 44], [45, 51], [52, 63], [64, 67], [68, 70], [71, 72], [73, 80], [81, 83], [84, 88], [89, 91], [92, 99], [100, 103], [104, 110], [110, 111]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [6, 7, "field"], [9, 9, "field"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [32, 33, "field"], [37, 38, "field"], [41, 42, "field"], [46, 47, "field"], [52, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[12, 13, 9, 9, "related-to", "contributes_to_field", true, false], [15, 16, 9, 9, "related-to", "contributes_to_field", true, false], [18, 19, 9, 9, "related-to", "contributes_to_field", true, false], [41, 42, 37, 38, "part-of", "", false, false], [46, 47, 41, 42, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["From", "Bonn", "he", "contributed", "substantially", "to", "artificial", "intelligence", "and", "robotics", "(", "with", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Thrun", "among", "his", "students", ")", ",", "as", "well", "as", "to", "the", "development", "of", "software", "engineering", ",", "especially", "in", "civil", "engineering", ",", "and", "information", "systems", ",", "especially", "in", "geosciences", ".", "He", "won", "the", "2016.2014", "AAAI", "Classic", "Paper", "Award", "."], "sentence-detokenized": "From Bonn he contributed substantially to artificial intelligence and robotics (with Wolfram Burgard, Dieter Fox, Sebastian Thrun among his students), as well as to the development of software engineering, especially in civil engineering, and information systems, especially in geosciences. He won the 2016.2014 AAAI Classic Paper Award.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 24], [25, 38], [39, 41], [42, 52], [53, 65], [66, 69], [70, 78], [79, 80], [80, 84], [85, 92], [93, 100], [100, 101], [102, 108], [109, 112], [112, 113], [114, 123], [124, 129], [130, 135], [136, 139], [140, 148], [148, 149], [149, 150], [151, 153], [154, 158], [159, 161], [162, 164], [165, 168], [169, 180], [181, 183], [184, 192], [193, 204], [204, 205], [206, 216], [217, 219], [220, 225], [226, 237], [237, 238], [239, 242], [243, 254], [255, 262], [262, 263], [264, 274], [275, 277], [278, 289], [289, 290], [291, 293], [294, 297], [298, 301], [302, 311], [312, 316], [317, 324], [325, 330], [331, 336], [336, 337]]}
{"doc_key": "ai-test-238", "ner": [[2, 13, "conference"], [20, 21, "location"], [23, 23, "location"], [25, 25, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 13, 20, 21, "physical", "", false, false], [20, 21, 23, 23, "physical", "", false, false], [23, 23, 25, 25, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "edition", "of", "the", "Campus", "Party", "in", "the", "US", "will", "take", "place", "from", "20", "to", "22", "August", "at", "the", "TCF", "Center", "in", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "The first edition of the Campus Party in the US will take place from 20 to 22 August at the TCF Center in Detroit, Michigan.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 20], [21, 24], [25, 31], [32, 37], [38, 40], [41, 44], [45, 47], [48, 52], [53, 57], [58, 63], [64, 68], [69, 71], [72, 74], [75, 77], [78, 84], [85, 87], [88, 91], [92, 95], [96, 102], [103, 105], [106, 113], [113, 114], [115, 123], [123, 124]]}
{"doc_key": "ai-test-239", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 13, "misc"], [21, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 12, 13, "win-defeat", "", false, false], [5, 6, 12, 13, "win-defeat", "", false, false], [8, 8, 12, 13, "win-defeat", "", false, false], [12, 13, 21, 23, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Along", "with", "Yann", "LeCun", "and", "Yoshua", "Bengio", ",", "Hinton", "won", "the", "2018", "Turing", "Prize", "for", "conceptual", "and", "engineering", "breakthroughs", "that", "made", "deep", "neural", "networks", "a", "critical", "component", "of", "computing", "."], "sentence-detokenized": "Along with Yann LeCun and Yoshua Bengio, Hinton won the 2018 Turing Prize for conceptual and engineering breakthroughs that made deep neural networks a critical component of computing.", "token2charspan": [[0, 5], [6, 10], [11, 15], [16, 21], [22, 25], [26, 32], [33, 39], [39, 40], [41, 47], [48, 51], [52, 55], [56, 60], [61, 67], [68, 73], [74, 77], [78, 88], [89, 92], [93, 104], [105, 118], [119, 123], [124, 128], [129, 133], [134, 140], [141, 149], [150, 151], [152, 160], [161, 170], [171, 173], [174, 183], [183, 184]]}
{"doc_key": "ai-test-240", "ner": [[0, 3, "product"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 10, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Euler", "Math", "Toolbox", "uses", "a", "table", "language", "similar", "to", "MATLAB", ",", "a", "system", "that", "has", "been", "under", "development", "since", "the", "1970s", "."], "sentence-detokenized": "The Euler Math Toolbox uses a table language similar to MATLAB, a system that has been under development since the 1970s.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 22], [23, 27], [28, 29], [30, 35], [36, 44], [45, 52], [53, 55], [56, 62], [62, 63], [64, 65], [66, 72], [73, 77], [78, 81], [82, 86], [87, 92], [93, 104], [105, 110], [111, 114], [115, 120], [120, 121]]}
{"doc_key": "ai-test-241", "ner": [[7, 7, "programlang"], [9, 10, "programlang"], [12, 12, "programlang"], [14, 14, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "languages", "allow", "it", "portably", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "or", "D", ")", "."], "sentence-detokenized": "Some languages allow it portably (e.g. Scheme, Common Lisp, Perl or D).", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 23], [24, 32], [33, 34], [34, 38], [39, 45], [45, 46], [47, 53], [54, 58], [58, 59], [60, 64], [65, 67], [68, 69], [69, 70], [70, 71]]}
{"doc_key": "ai-test-242", "ner": [[6, 7, "misc"], [8, 9, "researcher"], [11, 12, "researcher"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 8, 9, "artifact", "", false, false], [6, 7, 11, 12, "artifact", "", false, false], [6, 7, 26, 27, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1969", "a", "famous", "book", "called", "Perceptrons", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "showed", "that", "it", "was", "impossible", "for", "these", "classes", "of", "networks", "to", "learn", "an", "XOR", "function", "."], "sentence-detokenized": "In 1969 a famous book called Perceptrons by Marvin Minsky and Seymour Papert showed that it was impossible for these classes of networks to learn an XOR function.", "token2charspan": [[0, 2], [3, 7], [8, 9], [10, 16], [17, 21], [22, 28], [29, 40], [41, 43], [44, 50], [51, 57], [58, 61], [62, 69], [70, 76], [77, 83], [84, 88], [89, 91], [92, 95], [96, 106], [107, 110], [111, 116], [117, 124], [125, 127], [128, 136], [137, 139], [140, 145], [146, 148], [149, 152], [153, 161], [161, 162]]}
{"doc_key": "ai-test-243", "ner": [[4, 8, "misc"], [12, 14, "product"], [18, 21, "organisation"], [24, 30, "organisation"], [33, 35, "location"], [40, 40, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 21, 12, 14, "usage", "", false, false], [18, 21, 33, 35, "physical", "", false, false], [24, 30, 18, 21, "named", "", false, false], [33, 35, 40, 40, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "large", "number", "of", "Russian", "scientific", "and", "technical", "documents", "were", "translated", "using", "SYSTRAN", "under", "the", "auspices", "of", "the", "USAF", "Foreign", "Technology", "Division", "(", "later", "the", "National", "Air", "and", "Space", "Intelligence", "Center", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", ",", "Ohio", "."], "sentence-detokenized": "A large number of Russian scientific and technical documents were translated using SYSTRAN under the auspices of the USAF Foreign Technology Division (later the National Air and Space Intelligence Center) at Wright-Patterson Air Force Base, Ohio.", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 17], [18, 25], [26, 36], [37, 40], [41, 50], [51, 60], [61, 65], [66, 76], [77, 82], [83, 90], [91, 96], [97, 100], [101, 109], [110, 112], [113, 116], [117, 121], [122, 129], [130, 140], [141, 149], [150, 151], [151, 156], [157, 160], [161, 169], [170, 173], [174, 177], [178, 183], [184, 196], [197, 203], [203, 204], [205, 207], [208, 214], [214, 215], [215, 224], [225, 228], [229, 234], [235, 239], [239, 240], [241, 245], [245, 246]]}
{"doc_key": "ai-test-244", "ner": [[0, 1, "field"], [4, 5, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-supervised", "learning", "lies", "between", "unsupervised", "learning", "(", "without", "any", "labelled", "training", "data", ")", "and", "supervised", "learning", "(", "with", "fully", "labelled", "training", "data", ")", "."], "sentence-detokenized": "Semi-supervised learning lies between unsupervised learning (without any labelled training data) and supervised learning (with fully labelled training data).", "token2charspan": [[0, 15], [16, 24], [25, 29], [30, 37], [38, 50], [51, 59], [60, 61], [61, 68], [69, 72], [73, 81], [82, 90], [91, 95], [95, 96], [97, 100], [101, 111], [112, 120], [121, 122], [122, 126], [127, 132], [133, 141], [142, 150], [151, 155], [155, 156], [156, 157]]}
{"doc_key": "ai-test-245", "ner": [[0, 4, "algorithm"], [9, 11, "algorithm"], [26, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 9, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Ann", "-", "gram", "model", "is", "a", "type", "of", "probabilistic", "language", "model", "for", "predicting", "the", "next", "element", "in", "such", "a", "sequence", "in", "the", "form", "of", "a", "Markov", "(", "n", "-", "1", ")", "-order", "model", ".effectively", "."], "sentence-detokenized": "The Ann -gram model is a type of probabilistic language model for predicting the next element in such a sequence in the form of a Markov (n - 1)-order model .effectively.", "token2charspan": [[0, 3], [4, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 24], [25, 29], [30, 32], [33, 46], [47, 55], [56, 61], [62, 65], [66, 76], [77, 80], [81, 85], [86, 93], [94, 96], [97, 101], [102, 103], [104, 112], [113, 115], [116, 119], [120, 124], [125, 127], [128, 129], [130, 136], [137, 138], [138, 139], [140, 141], [142, 143], [143, 144], [144, 150], [151, 156], [157, 169], [169, 170]]}
{"doc_key": "ai-test-246", "ner": [[1, 2, "organisation"], [4, 4, "product"], [8, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 4, 4, "usage", "", false, false], [8, 14, 1, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "used", "Cyc", "to", "develop", "a", "natural", "language", "biomedical", "information", "query", "interface", "that", "covers", "decades", "of", "information", "about", "cardiothoracic", "procedures", "."], "sentence-detokenized": "The Cleveland Clinic used Cyc to develop a natural language biomedical information query interface that covers decades of information about cardiothoracic procedures.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 29], [30, 32], [33, 40], [41, 42], [43, 50], [51, 59], [60, 70], [71, 82], [83, 88], [89, 98], [99, 103], [104, 110], [111, 118], [119, 121], [122, 133], [134, 139], [140, 154], [155, 165], [165, 166]]}
{"doc_key": "ai-test-247", "ner": [[6, 7, "country"], [9, 9, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 9, 9, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "incident", "strained", "relations", "between", "the", "United", "States", "and", "Japan", "and", "resulted", "in", "the", "arrest", "and", "prosecution", "of", "two", "senior", "executives", "and", "the", "imposition", "of", "sanctions", "on", "the", "company", "by", "both", "countries", "."], "sentence-detokenized": "The incident strained relations between the United States and Japan and resulted in the arrest and prosecution of two senior executives and the imposition of sanctions on the company by both countries.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 31], [32, 39], [40, 43], [44, 50], [51, 57], [58, 61], [62, 67], [68, 71], [72, 80], [81, 83], [84, 87], [88, 94], [95, 98], [99, 110], [111, 113], [114, 117], [118, 124], [125, 135], [136, 139], [140, 143], [144, 154], [155, 157], [158, 167], [168, 170], [171, 174], [175, 182], [183, 185], [186, 190], [191, 200], [200, 201]]}
{"doc_key": "ai-test-248", "ner": [[7, 9, "algorithm"], [12, 13, "field"], [22, 22, "misc"], [35, 35, "misc"], [38, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 12, 13, "type-of", "", false, false], [22, 22, 12, 13, "part-of", "", true, false], [35, 35, 12, 13, "part-of", "", true, false], [38, 38, 12, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["If", "the", "modelling", "is", "done", "with", "an", "artificial", "neural", "network", "or", "other", "machine", "learning", ",", "the", "optimisation", "of", "the", "parameters", "is", "called", "training", ",", "while", "the", "optimisation", "of", "the", "hyperparameters", "of", "the", "model", "is", "called", "tuning", ",", "and", "cross-validation", "is", "often", "used", "."], "sentence-detokenized": "If the modelling is done with an artificial neural network or other machine learning, the optimisation of the parameters is called training, while the optimisation of the hyperparameters of the model is called tuning, and cross-validation is often used.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 24], [25, 29], [30, 32], [33, 43], [44, 50], [51, 58], [59, 61], [62, 67], [68, 75], [76, 84], [84, 85], [86, 89], [90, 102], [103, 105], [106, 109], [110, 120], [121, 123], [124, 130], [131, 139], [139, 140], [141, 146], [147, 150], [151, 163], [164, 166], [167, 170], [171, 186], [187, 189], [190, 193], [194, 199], [200, 202], [203, 209], [210, 216], [216, 217], [218, 221], [222, 238], [239, 241], [242, 247], [248, 252], [252, 253]]}
{"doc_key": "ai-test-249", "ner": [[11, 11, "country"], [13, 13, "country"], [15, 15, "country"], [22, 23, "organisation"], [25, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[22, 23, 25, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "local", "versions", "of", "the", "site", "that", "were", "available", "in", "the", "UK", ",", "India", "and", "Australia", "were", "discontinued", "following", "the", "acquisition", "of", "Rotten", "Tomatoes", "by", "Fandango", "."], "sentence-detokenized": "The local versions of the site that were available in the UK, India and Australia were discontinued following the acquisition of Rotten Tomatoes by Fandango.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 21], [22, 25], [26, 30], [31, 35], [36, 40], [41, 50], [51, 53], [54, 57], [58, 60], [60, 61], [62, 67], [68, 71], [72, 81], [82, 86], [87, 99], [100, 109], [110, 113], [114, 125], [126, 128], [129, 135], [136, 144], [145, 147], [148, 156], [156, 157]]}
{"doc_key": "ai-test-250", "ner": [[1, 1, "task"], [11, 12, "metrics"], [22, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 11, 12, "related-to", "", false, false], [11, 12, 22, 23, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "NER", "model", "is", "one", "of", "several", "methods", "for", "determining", "the", "accuracy", "of", "subtitles", "in", "live", "television", "broadcasts", "and", "events", "produced", "using", "speech", "recognition", "."], "sentence-detokenized": "The NER model is one of several methods for determining the accuracy of subtitles in live television broadcasts and events produced using speech recognition.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 31], [32, 39], [40, 43], [44, 55], [56, 59], [60, 68], [69, 71], [72, 81], [82, 84], [85, 89], [90, 100], [101, 111], [112, 115], [116, 122], [123, 131], [132, 137], [138, 144], [145, 156], [156, 157]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [5, 7, "university"], [10, 11, "university"], [13, 13, "location"], [16, 20, "university"], [23, 24, "university"], [26, 26, "location"], [29, 34, "university"], [36, 37, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 5, 7, "physical", "", false, false], [0, 0, 5, 7, "role", "", false, false], [0, 0, 10, 11, "physical", "", false, false], [0, 0, 10, 11, "role", "", false, false], [0, 0, 16, 20, "physical", "", false, false], [0, 0, 16, 20, "role", "", false, false], [0, 0, 23, 24, "physical", "", false, false], [0, 0, 23, 24, "role", "", false, false], [0, 0, 29, 34, "physical", "", false, false], [0, 0, 29, 34, "role", "", false, false], [10, 11, 13, 13, "physical", "", false, false], [16, 20, 26, 26, "physical", "", false, false], [23, 24, 26, 26, "physical", "", false, false], [29, 34, 36, 37, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "has", "taught", "at", "the", "University", "of", "Cambridge", ",", "the", "Hebrew", "University", "of", "Jerusalem", ",", "the", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "and", "the", "\u00c9cole", "Polytechnique", "in", "Paris", "and", "the", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "."], "sentence-detokenized": "Atran has taught at the University of Cambridge, the Hebrew University of Jerusalem, the \u00c9cole pratique des hautes \u00e9tudes and the \u00c9cole Polytechnique in Paris and the John Jay College of Criminal Justice in New York.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 47], [47, 48], [49, 52], [53, 59], [60, 70], [71, 73], [74, 83], [83, 84], [85, 88], [89, 94], [95, 103], [104, 107], [108, 114], [115, 121], [122, 125], [126, 129], [130, 135], [136, 149], [150, 152], [153, 158], [159, 162], [163, 166], [167, 171], [172, 175], [176, 183], [184, 186], [187, 195], [196, 203], [204, 206], [207, 210], [211, 215], [215, 216]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [7, 9, "task"], [13, 14, "researcher"], [16, 16, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 9, "origin", "", false, false], [0, 0, 7, 9, "related-to", "", false, false], [7, 9, 16, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "was", "an", "early", "computer", "program", "for", "natural", "language", "understanding", ",", "developed", "by", "Terry", "Winograd", "at", "MIT", "in", "1968", "-", "1970", "."], "sentence-detokenized": "SHRDLU was an early computer program for natural language understanding, developed by Terry Winograd at MIT in 1968-1970.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 19], [20, 28], [29, 36], [37, 40], [41, 48], [49, 57], [58, 71], [71, 72], [73, 82], [83, 85], [86, 91], [92, 100], [101, 103], [104, 107], [108, 110], [111, 115], [115, 116], [116, 120], [120, 121]]}
{"doc_key": "ai-test-253", "ner": [[2, 4, "misc"], [5, 7, "field"], [8, 12, "university"], [14, 14, "location"], [16, 17, "country"], [26, 28, "university"], [30, 33, "misc"], [35, 38, "field"], [42, 43, "university"], [47, 47, "misc"], [51, 52, "field"], [56, 58, "misc"], [65, 69, "university"], [74, 75, "field"], [79, 80, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[2, 4, 5, 7, "topic", "", false, false], [2, 4, 8, 12, "origin", "", false, false], [8, 12, 14, 14, "physical", "", false, false], [8, 12, 26, 28, "role", "affiliated_with", false, false], [14, 14, 16, 17, "physical", "", false, false], [30, 33, 35, 38, "topic", "", false, false], [30, 33, 42, 43, "origin", "", false, false], [47, 47, 51, 52, "topic", "", false, false], [56, 58, 65, 69, "origin", "", false, false], [56, 58, 74, 75, "topic", "", false, false], [79, 80, 65, 69, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["He", "received", "a", "degree", "in", "electronic", "engineering", "from", "B.M.S", ".", "College", "of", "Engineering", "in", "Bangalore", ",", "India", "in", "1982", ",", "when", "it", "was", "affiliated", "with", "the", "University", "of", "Bangalore", ",", "a", "master", "'s", "degree", "in", "electrical", "and", "computer", "engineering", "in", "1984", "from", "Drexel", "University", ",", "and", "a", "master", "'s", "degree", "in", "computer", "science", "in", "1989", "and", "a", "Ph.D.", "in", "1990", ",", "respectively", ",", "from", "the", "University", "of", "Wisconsin", "-", "Madison", ",", "where", "he", "studied", "Artificial", "Intelligence", "and", "worked", "with", "Leonard", "Uhr", "."], "sentence-detokenized": "He received a degree in electronic engineering from B.M.S. College of Engineering in Bangalore, India in 1982, when it was affiliated with the University of Bangalore, a master's degree in electrical and computer engineering in 1984 from Drexel University, and a master's degree in computer science in 1989 and a Ph.D. in 1990, respectively, from the University of Wisconsin-Madison, where he studied Artificial Intelligence and worked with Leonard Uhr.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 20], [21, 23], [24, 34], [35, 46], [47, 51], [52, 57], [57, 58], [59, 66], [67, 69], [70, 81], [82, 84], [85, 94], [94, 95], [96, 101], [102, 104], [105, 109], [109, 110], [111, 115], [116, 118], [119, 122], [123, 133], [134, 138], [139, 142], [143, 153], [154, 156], [157, 166], [166, 167], [168, 169], [170, 176], [176, 178], [179, 185], [186, 188], [189, 199], [200, 203], [204, 212], [213, 224], [225, 227], [228, 232], [233, 237], [238, 244], [245, 255], [255, 256], [257, 260], [261, 262], [263, 269], [269, 271], [272, 278], [279, 281], [282, 290], [291, 298], [299, 301], [302, 306], [307, 310], [311, 312], [313, 318], [319, 321], [322, 326], [326, 327], [328, 340], [340, 341], [342, 346], [347, 350], [351, 361], [362, 364], [365, 374], [374, 375], [375, 382], [382, 383], [384, 389], [390, 392], [393, 400], [401, 411], [412, 424], [425, 428], [429, 435], [436, 440], [441, 448], [449, 452], [452, 453]]}
{"doc_key": "ai-test-254", "ner": [[8, 8, "metrics"], [6, 10, "metrics"], [19, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 10, 8, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "usually", "assessed", "by", "the", "word", "error", "rate", "(", "WER", ")", ",", "while", "speed", "is", "measured", "by", "the", "real", "-", "time", "factor", "."], "sentence-detokenized": "Accuracy is usually assessed by the word error rate (WER), while speed is measured by the real-time factor.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 28], [29, 31], [32, 35], [36, 40], [41, 46], [47, 51], [52, 53], [53, 56], [56, 57], [57, 58], [59, 64], [65, 70], [71, 73], [74, 82], [83, 85], [86, 89], [90, 94], [94, 95], [95, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-255", "ner": [[2, 3, "researcher"], [7, 9, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 7, 9, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", "Terry", "Winograd", "developed", "an", "early", "natural", "language", "processing", "engine", "capable", "of", "interpreting", "physically", "written", "commands", "within", "a", "simple", "rule", "-", "governed", "environment", "."], "sentence-detokenized": "In 1971 Terry Winograd developed an early natural language processing engine capable of interpreting physically written commands within a simple rule-governed environment.", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 22], [23, 32], [33, 35], [36, 41], [42, 49], [50, 58], [59, 69], [70, 76], [77, 84], [85, 87], [88, 100], [101, 111], [112, 119], [120, 128], [129, 135], [136, 137], [138, 144], [145, 149], [149, 150], [150, 158], [159, 170], [170, 171]]}
{"doc_key": "ai-test-256", "ner": [[1, 2, "field"], [4, 5, "researcher"], [7, 10, "researcher"], [12, 13, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 4, 5, "related-to", "", false, false], [1, 2, 7, 10, "related-to", "", false, false], [1, 2, 12, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "artificial", "intelligence", ",", "Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "and", "Allen", "Newell", "are", "prominent", "."], "sentence-detokenized": "In artificial intelligence, Marvin Minsky, Herbert A. Simon and Allen Newell are prominent.", "token2charspan": [[0, 2], [3, 13], [14, 26], [26, 27], [28, 34], [35, 41], [41, 42], [43, 50], [51, 52], [52, 53], [54, 59], [60, 63], [64, 69], [70, 76], [77, 80], [81, 90], [90, 91]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [33, 33, "field"], [36, 36, "field"], [39, 40, "field"], [49, 52, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[33, 33, 9, 10, "origin", "", true, false], [33, 33, 9, 10, "part-of", "", false, false], [33, 33, 39, 40, "compare", "", false, false], [36, 36, 9, 10, "origin", "", true, false], [36, 36, 9, 10, "part-of", "", false, false], [36, 36, 39, 40, "compare", "", false, false], [39, 40, 9, 10, "origin", "", true, false], [39, 40, 9, 10, "part-of", "", false, false], [39, 40, 49, 52, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "the", "second", "half", "of", "the", "20th", "century", ",", "electrical", "engineering", "itself", "was", "split", "into", "several", "disciplines", ",", "specialising", "in", "the", "design", "and", "analysis", "of", "systems", "that", "manipulate", "physical", "signals", "-", "examples", "include", "electronic", "and", "computer", "engineering", "-", "while", "design", "engineering", "developed", "to", "deal", "with", "the", "functional", "design", "of", "user", "-", "machine", "interfaces", "."], "sentence-detokenized": "In the second half of the 20th century, electrical engineering itself was split into several disciplines, specialising in the design and analysis of systems that manipulate physical signals - examples include electronic and computer engineering - while design engineering developed to deal with the functional design of user-machine interfaces.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 30], [31, 38], [38, 39], [40, 50], [51, 62], [63, 69], [70, 73], [74, 79], [80, 84], [85, 92], [93, 104], [104, 105], [106, 118], [119, 121], [122, 125], [126, 132], [133, 136], [137, 145], [146, 148], [149, 156], [157, 161], [162, 172], [173, 181], [182, 189], [190, 191], [192, 200], [201, 208], [209, 219], [220, 223], [224, 232], [233, 244], [245, 246], [247, 252], [253, 259], [260, 271], [272, 281], [282, 284], [285, 289], [290, 294], [295, 298], [299, 309], [310, 316], [317, 319], [320, 324], [324, 325], [325, 332], [333, 343], [343, 344]]}
{"doc_key": "ai-test-258", "ner": [[6, 6, "metrics"], [8, 10, "metrics"], [12, 12, "metrics"], [48, 50, "metrics"], [57, 59, "metrics"], [63, 69, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 12, 8, 10, "named", "", false, false], [48, 50, 57, 59, "named", "", false, false], [57, 59, 63, 69, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Perhaps", "the", "simplest", "statistic", "is", "the", "accuracy", "or", "correct", "classification", "fraction", "(", "FC", ")", ",", "which", "measures", "the", "fraction", "of", "all", "cases", "that", "are", "correctly", "categorized", ";", "it", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "Total", "population", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Perhaps the simplest statistic is the accuracy or correct classification fraction (FC), which measures the fraction of all cases that are correctly categorized; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN) / Total population = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 30], [31, 33], [34, 37], [38, 46], [47, 49], [50, 57], [58, 72], [73, 81], [82, 83], [83, 85], [85, 86], [86, 87], [88, 93], [94, 102], [103, 106], [107, 115], [116, 118], [119, 122], [123, 128], [129, 133], [134, 137], [138, 147], [148, 159], [159, 160], [161, 163], [164, 166], [167, 170], [171, 176], [177, 179], [180, 183], [184, 190], [191, 193], [194, 201], [202, 217], [218, 220], [221, 224], [225, 230], [231, 237], [238, 240], [241, 248], [249, 251], [252, 261], [262, 277], [277, 278], [279, 280], [280, 282], [283, 284], [285, 287], [287, 288], [289, 290], [291, 296], [297, 307], [308, 309], [310, 311], [311, 313], [314, 315], [316, 318], [318, 319], [320, 321], [322, 323], [323, 325], [326, 327], [328, 330], [331, 332], [333, 335], [336, 337], [338, 340], [340, 341], [341, 342]]}
{"doc_key": "ai-test-259", "ner": [[15, 23, "conference"], [25, 27, "conference"], [32, 33, "location"], [37, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 23, 32, 33, "physical", "", false, false], [25, 27, 15, 23, "named", "", false, false], [37, 38, 15, 23, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "academia", ",", "the", "most", "important", "forums", "for", "research", "started", "in", "1995", ",", "when", "the", "first", "international", "conference", "on", "Data", "Mining", "and", "Knowledge", "Discovery", "(", "KDD", "-", "95", ")", "was", "launched", "in", "Montreal", "under", "the", "auspices", "of", "the", "AAAI", "."], "sentence-detokenized": "In academia, the most important forums for research started in 1995, when the first international conference on Data Mining and Knowledge Discovery (KDD-95) was launched in Montreal under the auspices of the AAAI.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 16], [17, 21], [22, 31], [32, 38], [39, 42], [43, 51], [52, 59], [60, 62], [63, 67], [67, 68], [69, 73], [74, 77], [78, 83], [84, 97], [98, 108], [109, 111], [112, 116], [117, 123], [124, 127], [128, 137], [138, 147], [148, 149], [149, 152], [152, 153], [153, 155], [155, 156], [157, 160], [161, 169], [170, 172], [173, 181], [182, 187], [188, 191], [192, 200], [201, 203], [204, 207], [208, 212], [212, 213]]}
{"doc_key": "ai-test-260", "ner": [[9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "approach", ",", "models", "are", "developed", "using", "various", "data", "mining", "and", "machine", "learning", "algorithms", "to", "predict", "user", "ratings", "on", "unrated", "items", "."], "sentence-detokenized": "In this approach, models are developed using various data mining and machine learning algorithms to predict user ratings on unrated items.", "token2charspan": [[0, 2], [3, 7], [8, 16], [16, 17], [18, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 57], [58, 64], [65, 68], [69, 76], [77, 85], [86, 96], [97, 99], [100, 107], [108, 112], [113, 120], [121, 123], [124, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-test-261", "ner": [[11, 11, "algorithm"], [16, 17, "algorithm"], [19, 20, "algorithm"], [27, 28, "misc"], [31, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 11, 16, 17, "related-to", "equivalent", false, false], [16, 17, 19, 20, "usage", "", false, false], [19, 20, 31, 32, "usage", "", false, false], [31, 32, 27, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "light", "of", "the", "above", "discussion", ",", "we", "see", "that", "the", "SVM", "technique", "is", "equivalent", "to", "empirical", "risk", "with", "Tikhonov", "normalization", ",", "where", "in", "this", "case", "the", "loss", "function", "is", "the", "joint", "loss"], "sentence-detokenized": "In light of the above discussion, we see that the SVM technique is equivalent to empirical risk with Tikhonov normalization, where in this case the loss function is the joint loss", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 15], [16, 21], [22, 32], [32, 33], [34, 36], [37, 40], [41, 45], [46, 49], [50, 53], [54, 63], [64, 66], [67, 77], [78, 80], [81, 90], [91, 95], [96, 100], [101, 109], [110, 123], [123, 124], [125, 130], [131, 133], [134, 138], [139, 143], [144, 147], [148, 152], [153, 161], [162, 164], [165, 168], [169, 174], [175, 179]]}
{"doc_key": "ai-test-262", "ner": [[6, 7, "person"], [12, 13, "person"], [16, 16, "organisation"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[18, 19, 16, 16, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "2015", "edition", "was", "presented", "by", "Molly", "McGrath", ",", "with", "commentary", "by", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "."], "sentence-detokenized": "The 2015 edition was presented by Molly McGrath, with commentary by Chris Rose and former UFC fighter Kenny Florian.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 30], [31, 33], [34, 39], [40, 47], [47, 48], [49, 53], [54, 64], [65, 67], [68, 73], [74, 78], [79, 82], [83, 89], [90, 93], [94, 101], [102, 107], [108, 115], [115, 116]]}
{"doc_key": "ai-test-263", "ner": [[3, 5, "product"], [9, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [18, 18, "researcher"], [22, 22, "researcher"], [29, 29, "researcher"], [31, 33, "task"], [35, 35, "product"], [37, 37, "researcher"], [42, 43, "task"], [45, 46, "researcher"], [50, 51, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[3, 5, 9, 11, "origin", "", false, false], [3, 5, 13, 14, "origin", "", false, false], [3, 5, 16, 17, "origin", "", false, false], [3, 5, 18, 18, "origin", "", false, false], [13, 14, 37, 37, "named", "same", false, false], [16, 17, 22, 22, "named", "same", false, false], [16, 17, 29, 29, "named", "same", false, false], [31, 33, 35, 35, "related-to", "", false, false], [35, 35, 29, 29, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["A", "subset", "called", "Micro", "-", "Planner", "was", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "Sussman", ",", ",", "and", "Winograd", "in", "1971", "and", "was", "used", "in", "Winograd", "'s", "natural", "language", "understanding", "program", "SHRDLU", ",", "Eugene", "Charniak", "'s", "work", "on", "story", "comprehension", ",", "Thorne", "McCarty", "'s", "work", "on", "legal", "reasoning", ",", "and", "a", "number", "of", "other", "projects", "."], "sentence-detokenized": "A subset called Micro-Planner was implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd Sussman,, and Winograd in 1971 and was used in Winograd's natural language understanding program SHRDLU, Eugene Charniak's work on story comprehension, Thorne McCarty's work on legal reasoning, and a number of other projects.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [21, 22], [22, 29], [30, 33], [34, 45], [46, 48], [49, 55], [56, 59], [60, 67], [67, 68], [69, 75], [76, 84], [85, 88], [89, 94], [95, 103], [104, 111], [111, 112], [112, 113], [114, 117], [118, 126], [127, 129], [130, 134], [135, 138], [139, 142], [143, 147], [148, 150], [151, 159], [159, 161], [162, 169], [170, 178], [179, 192], [193, 200], [201, 207], [207, 208], [209, 215], [216, 224], [224, 226], [227, 231], [232, 234], [235, 240], [241, 254], [254, 255], [256, 262], [263, 270], [270, 272], [273, 277], [278, 280], [281, 286], [287, 296], [296, 297], [298, 301], [302, 303], [304, 310], [311, 313], [314, 319], [320, 328], [328, 329]]}
{"doc_key": "ai-test-264", "ner": [[0, 1, "product"], [11, 12, "product"], [15, 17, "task"], [19, 20, "task"], [22, 24, "task"], [26, 27, "task"], [29, 30, "task"], [33, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 0, 1, "usage", "", true, false], [15, 17, 11, 12, "part-of", "", true, false], [19, 20, 11, 12, "part-of", "", true, false], [22, 24, 11, 12, "part-of", "", true, false], [26, 27, 11, 12, "part-of", "", true, false], [29, 30, 11, 12, "part-of", "", true, false], [33, 36, 11, 12, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "has", "been", "used", "for", "a", "variety", "of", "purposes", "in", "information", "systems", ",", "including", "word", "sense", "clarification", ",", "information", "retrieval", ",", "automatic", "text", "classification", ",", "automatic", "summarization", ",", "automatic", "translation", "and", "even", "automatic", "crossword", "puzzle", "generation", "."], "sentence-detokenized": "WordNet has been used for a variety of purposes in information systems, including word sense clarification, information retrieval, automatic text classification, automatic summarization, automatic translation and even automatic crossword puzzle generation.", "token2charspan": [[0, 4], [4, 7], [8, 11], [12, 16], [17, 21], [22, 25], [26, 27], [28, 35], [36, 38], [39, 47], [48, 50], [51, 62], [63, 70], [70, 71], [72, 81], [82, 86], [87, 92], [93, 106], [106, 107], [108, 119], [120, 129], [129, 130], [131, 140], [141, 145], [146, 160], [160, 161], [162, 171], [172, 185], [185, 186], [187, 196], [197, 208], [209, 212], [213, 217], [218, 227], [228, 237], [238, 244], [245, 255], [255, 256]]}
{"doc_key": "ai-test-265", "ner": [[0, 0, "researcher"], [5, 6, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 6, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "was", "inducted", "into", "the", "IEEE", "in", "1996", "."], "sentence-detokenized": "Keutzer was inducted into the IEEE in 1996.", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 25], [26, 29], [30, 34], [35, 37], [38, 42], [42, 43]]}
{"doc_key": "ai-test-266", "ner": [[8, 10, "algorithm"], [57, 58, "misc"], [68, 69, "algorithm"], [71, 72, "algorithm"], [74, 75, "algorithm"], [77, 78, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[68, 69, 57, 58, "type-of", "", false, false], [71, 72, 57, 58, "type-of", "", false, false], [74, 75, 57, 58, "type-of", "", false, false], [77, 78, 57, 58, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "commonly", "used", "type", "of", "synthesis", "is", "the", "nonlinear", "weighted", "sum", ",", "where", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "left", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "right", ")", "/", "math", ",", "where", "math", "\\", "textstyle", "K", "/", "math", "(", "usually", "referred", "to", "as", "the", "activation", "function", ")", "is", "some", "predefined", "function", ",", "such", "as", "the", "hyperbolic", "tangent", ",", "sigmoid", "function", ",", "softmax", "function", "or", "correction", "function", "."], "sentence-detokenized": "A commonly used type of synthesis is the nonlinear weighted sum, where math\\ textstyle f (x) = K\\ left (\\ sum _ i w _ i g _ i (x)\\ right) / math, where math\\ textstyle K / math (usually referred to as the activation function) is some predefined function, such as the hyperbolic tangent, sigmoid function, softmax function or correction function.", "token2charspan": [[0, 1], [2, 10], [11, 15], [16, 20], [21, 23], [24, 33], [34, 36], [37, 40], [41, 50], [51, 59], [60, 63], [63, 64], [65, 70], [71, 75], [75, 76], [77, 86], [87, 88], [89, 90], [90, 91], [91, 92], [93, 94], [95, 96], [96, 97], [98, 102], [103, 104], [104, 105], [106, 109], [110, 111], [112, 113], [114, 115], [116, 117], [118, 119], [120, 121], [122, 123], [124, 125], [126, 127], [127, 128], [128, 129], [129, 130], [131, 136], [136, 137], [138, 139], [140, 144], [144, 145], [146, 151], [152, 156], [156, 157], [158, 167], [168, 169], [170, 171], [172, 176], [177, 178], [178, 185], [186, 194], [195, 197], [198, 200], [201, 204], [205, 215], [216, 224], [224, 225], [226, 228], [229, 233], [234, 244], [245, 253], [253, 254], [255, 259], [260, 262], [263, 266], [267, 277], [278, 285], [285, 286], [287, 294], [295, 303], [303, 304], [305, 312], [313, 321], [322, 324], [325, 335], [336, 344], [344, 345]]}
{"doc_key": "ai-test-267", "ner": [[3, 3, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "movie", "Westworld", ",", "female", "robots", "actually", "mated", "with", "humans", "as", "part", "of", "the", "fictional", "holiday", "world", "that", "humans", "paid", "to", "watch", "."], "sentence-detokenized": "In the movie Westworld, female robots actually mated with humans as part of the fictional holiday world that humans paid to watch.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [22, 23], [24, 30], [31, 37], [38, 46], [47, 52], [53, 57], [58, 64], [65, 67], [68, 72], [73, 75], [76, 79], [80, 89], [90, 97], [98, 103], [104, 108], [109, 115], [116, 120], [121, 123], [124, 129], [129, 130]]}
{"doc_key": "ai-test-268", "ner": [[7, 9, "task"], [23, 28, "task"], [30, 31, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 23, 28, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Usually", ",", "the", "process", "starts", "with", "the", "extraction", "of", "terminology", "and", "concepts", "or", "noun", "phrases", "from", "plain", "text", "using", "language", "editors", "such", "as", "part", "-", "of", "-", "speech", "highlighting", "and", "sentence", "fragmentation", "."], "sentence-detokenized": "Usually, the process starts with the extraction of terminology and concepts or noun phrases from plain text using language editors such as part-of-speech highlighting and sentence fragmentation.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 20], [21, 27], [28, 32], [33, 36], [37, 47], [48, 50], [51, 62], [63, 66], [67, 75], [76, 78], [79, 83], [84, 91], [92, 96], [97, 102], [103, 107], [108, 113], [114, 122], [123, 130], [131, 135], [136, 138], [139, 143], [143, 144], [144, 146], [146, 147], [147, 153], [154, 166], [167, 170], [171, 179], [180, 193], [193, 194]]}
{"doc_key": "ai-test-269", "ner": [[13, 14, "field"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "demonstrated", "its", "performance", "on", "a", "number", "of", "problems", "of", "interest", "to", "the", "machine", "learning", "community", ",", "including", "handwriting", "recognition", "."], "sentence-detokenized": "They demonstrated its performance on a number of problems of interest to the machine learning community, including handwriting recognition.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 33], [34, 36], [37, 38], [39, 45], [46, 48], [49, 57], [58, 60], [61, 69], [70, 72], [73, 76], [77, 84], [85, 93], [94, 103], [103, 104], [105, 114], [115, 126], [127, 138], [138, 139]]}
{"doc_key": "ai-test-270", "ner": [[3, 3, "university"], [5, 5, "researcher"], [10, 13, "researcher"], [16, 16, "product"], [20, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 3, 3, "physical", "", false, false], [5, 5, 3, 3, "role", "", false, false], [16, 16, 10, 13, "origin", "", false, false], [16, 16, 20, 21, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "studying", "at", "Stanford", ",", "Scheinman", "received", "a", "scholarship", "from", "George", "Devol", ",", "the", "inventor", "of", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "While studying at Stanford, Scheinman received a scholarship from George Devol, the inventor of Unimate, the first industrial robot.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [26, 27], [28, 37], [38, 46], [47, 48], [49, 60], [61, 65], [66, 72], [73, 78], [78, 79], [80, 83], [84, 92], [93, 95], [96, 103], [103, 104], [105, 108], [109, 114], [115, 125], [126, 131], [131, 132]]}
{"doc_key": "ai-test-271", "ner": [[5, 6, "task"], [9, 13, "metrics"], [9, 9, "metrics"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 9, 13, "usage", "", true, false], [9, 9, 9, 13, "named", "", false, false], [21, 23, 9, 13, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Although", "originally", "used", "to", "evaluate", "machine", "translations", ",", "the", "BLEU", "(", "bilingual", "evaluation", "understudy", ")", "has", "been", "successfully", "used", "to", "evaluate", "paraphrase", "generation", "models", "."], "sentence-detokenized": "Although originally used to evaluate machine translations, the BLEU (bilingual evaluation understudy) has been successfully used to evaluate paraphrase generation models.", "token2charspan": [[0, 8], [9, 19], [20, 24], [25, 27], [28, 36], [37, 44], [45, 57], [57, 58], [59, 62], [63, 67], [68, 69], [69, 78], [79, 89], [90, 100], [100, 101], [102, 105], [106, 110], [111, 123], [124, 128], [129, 131], [132, 140], [141, 151], [152, 162], [163, 169], [169, 170]]}
{"doc_key": "ai-test-272", "ner": [[0, 0, "organisation"], [6, 8, "organisation"], [10, 10, "organisation"], [13, 13, "product"], [15, 15, "country"], [17, 17, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 8, "role", "licenses_to", false, false], [0, 0, 10, 10, "role", "licenses_to", false, false], [6, 8, 15, 15, "physical", "", false, false], [10, 10, 17, 17, "physical", "", false, false], [13, 13, 6, 8, "artifact", "produces", false, false], [13, 13, 10, 10, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "later", "licensed", "its", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "manufacturing", "Unimates", "in", "Japan", "and", "England", "respectively", "."], "sentence-detokenized": "Unimation later licensed its technology to Kawasaki Heavy Industries and GKN, manufacturing Unimates in Japan and England respectively.", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 57], [58, 68], [69, 72], [73, 76], [76, 77], [78, 91], [92, 100], [101, 103], [104, 109], [110, 113], [114, 121], [122, 134], [134, 135]]}
{"doc_key": "ai-test-273", "ner": [[20, 22, "conference"], [37, 38, "field"], [56, 60, "field"], [62, 62, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[37, 38, 56, 60, "compare", "", false, false], [62, 62, 56, 60, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "confusion", "between", "these", "two", "research", "communities", "(", "which", "often", "have", "separate", "conferences", "and", "separate", "journals", ",", "with", "ECML", "PKDD", "being", "a", "notable", "exception", ")", "stems", "from", "the", "basic", "assumptions", "they", "work", "with", ":", "in", "machine", "learning", ",", "performance", "is", "usually", "evaluated", "in", "terms", "of", "the", "ability", "to", "reproduce", "known", "knowledge", ",", "whereas", "in", "knowledge", "discovery", "and", "data", "mining", "(", "KDD", ")", "the", "key", "task", "is", "the", "discovery", "of", "previously", "unknown", "knowledge", "."], "sentence-detokenized": "Much of the confusion between these two research communities (which often have separate conferences and separate journals, with ECML PKDD being a notable exception) stems from the basic assumptions they work with: in machine learning, performance is usually evaluated in terms of the ability to reproduce known knowledge, whereas in knowledge discovery and data mining (KDD) the key task is the discovery of previously unknown knowledge.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 29], [30, 35], [36, 39], [40, 48], [49, 60], [61, 62], [62, 67], [68, 73], [74, 78], [79, 87], [88, 99], [100, 103], [104, 112], [113, 121], [121, 122], [123, 127], [128, 132], [133, 137], [138, 143], [144, 145], [146, 153], [154, 163], [163, 164], [165, 170], [171, 175], [176, 179], [180, 185], [186, 197], [198, 202], [203, 207], [208, 212], [212, 213], [214, 216], [217, 224], [225, 233], [233, 234], [235, 246], [247, 249], [250, 257], [258, 267], [268, 270], [271, 276], [277, 279], [280, 283], [284, 291], [292, 294], [295, 304], [305, 310], [311, 320], [320, 321], [322, 329], [330, 332], [333, 342], [343, 352], [353, 356], [357, 361], [362, 368], [369, 370], [370, 373], [373, 374], [375, 378], [379, 382], [383, 387], [388, 390], [391, 394], [395, 404], [405, 407], [408, 418], [419, 426], [427, 436], [436, 437]]}
{"doc_key": "ai-test-274", "ner": [[0, 1, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hidden", "Markov", "models", "are", "the", "basis", "for", "most", "modern", "automatic", "speech", "recognition", "systems", "."], "sentence-detokenized": "Hidden Markov models are the basis for most modern automatic speech recognition systems.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 28], [29, 34], [35, 38], [39, 43], [44, 50], [51, 60], [61, 67], [68, 79], [80, 87], [87, 88]]}
{"doc_key": "ai-test-275", "ner": [[4, 4, "location"], [6, 6, "country"], [10, 11, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 6, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": [",", "a", "company", "in", "Bangalore", ",", "India", "specialising", "in", "online", "handwriting", "recognition", "software", "."], "sentence-detokenized": ", a company in Bangalore, India specialising in online handwriting recognition software.", "token2charspan": [[0, 1], [2, 3], [4, 11], [12, 14], [15, 24], [24, 25], [26, 31], [32, 44], [45, 47], [48, 54], [55, 66], [67, 78], [79, 87], [87, 88]]}
{"doc_key": "ai-test-276", "ner": [[27, 28, "misc"], [51, 51, "metrics"], [53, 55, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[51, 51, 53, 55, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Do", "the", "repeated", "translations", "converge", "into", "a", "single", "expression", "in", "both", "languages", "?", "That", "is", ",", "does", "the", "translation", "method", "exhibit", "stasis", "or", "does", "it", "produce", "a", "regular", "form", "?", "Does", "the", "translation", "become", "stagnant", "without", "losing", "the", "original", "meaning", "?", "This", "metric", "has", "been", "criticized", "as", "not", "correlating", "well", "with", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "scores", "."], "sentence-detokenized": "Do the repeated translations converge into a single expression in both languages? That is, does the translation method exhibit stasis or does it produce a regular form? Does the translation become stagnant without losing the original meaning? This metric has been criticized as not correlating well with BLEU (BiLingual Evaluation Understudy) scores.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 28], [29, 37], [38, 42], [43, 44], [45, 51], [52, 62], [63, 65], [66, 70], [71, 80], [80, 81], [82, 86], [87, 89], [89, 90], [91, 95], [96, 99], [100, 111], [112, 118], [119, 126], [127, 133], [134, 136], [137, 141], [142, 144], [145, 152], [153, 154], [155, 162], [163, 167], [167, 168], [169, 173], [174, 177], [178, 189], [190, 196], [197, 205], [206, 213], [214, 220], [221, 224], [225, 233], [234, 241], [241, 242], [243, 247], [248, 254], [255, 258], [259, 263], [264, 274], [275, 277], [278, 281], [282, 293], [294, 298], [299, 303], [304, 308], [309, 310], [310, 319], [320, 330], [331, 341], [341, 342], [343, 349], [349, 350]]}
{"doc_key": "ai-test-277", "ner": [[6, 10, "organisation"], [13, 19, "organisation"], [21, 22, "university"], [25, 25, "university"], [28, 29, "field"], [32, 36, "organisation"], [39, 41, "organisation"], [50, 53, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[13, 19, 21, 22, "part-of", "", false, false], [25, 25, 28, 29, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "is", "a", "fellow", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", ",", "the", "Center", "for", "Advanced", "Studies", "in", "Behavioral", "Sciences", "at", "Stanford", "University", ",", "the", "MIT", "Center", "for", "Cognitive", "Science", ",", "the", "Canadian", "Institute", "for", "Advanced", "Research", ",", "the", "Canadian", "Psychological", "Association", ",", "and", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "in", "1998", "."], "sentence-detokenized": "He is a fellow of the American Association for Artificial Intelligence, the Center for Advanced Studies in Behavioral Sciences at Stanford University, the MIT Center for Cognitive Science, the Canadian Institute for Advanced Research, the Canadian Psychological Association, and was elected a Fellow of the Royal Society of Canada in 1998.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 42], [43, 46], [47, 57], [58, 70], [70, 71], [72, 75], [76, 82], [83, 86], [87, 95], [96, 103], [104, 106], [107, 117], [118, 126], [127, 129], [130, 138], [139, 149], [149, 150], [151, 154], [155, 158], [159, 165], [166, 169], [170, 179], [180, 187], [187, 188], [189, 192], [193, 201], [202, 211], [212, 215], [216, 224], [225, 233], [233, 234], [235, 238], [239, 247], [248, 261], [262, 273], [273, 274], [275, 278], [279, 282], [283, 290], [291, 292], [293, 299], [300, 302], [303, 306], [307, 312], [313, 320], [321, 323], [324, 330], [331, 333], [334, 338], [338, 339]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [17, 20, "misc"], [23, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 17, 20, "part-of", "", false, false], [0, 0, 23, 26, "part-of", "", false, false], [4, 5, 17, 20, "part-of", "", false, false], [4, 5, 23, 26, "part-of", "", false, false], [7, 8, 17, 20, "part-of", "", false, false], [7, 8, 23, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "-", "along", "with", "Yoshua", "Bengio", "and", "Yann", "LeCun", "-", "are", "referred", "to", "by", "some", "as", "the", "godfathers", "of", "artificial", "intelligence", "and", "the", "godfathers", "of", "deep", "learning", "."], "sentence-detokenized": "Hinton - along with Yoshua Bengio and Yann LeCun - are referred to by some as the godfathers of artificial intelligence and the godfathers of deep learning.", "token2charspan": [[0, 6], [7, 8], [9, 14], [15, 19], [20, 26], [27, 33], [34, 37], [38, 42], [43, 48], [49, 50], [51, 54], [55, 63], [64, 66], [67, 69], [70, 74], [75, 77], [78, 81], [82, 92], [93, 95], [96, 106], [107, 119], [120, 123], [124, 127], [128, 138], [139, 141], [142, 146], [147, 155], [155, 156]]}
{"doc_key": "ai-test-279", "ner": [[6, 8, "product"], [18, 18, "misc"], [20, 21, "misc"], [22, 22, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 18, 18, "related-to", "", false, false], [6, 8, 20, 21, "related-to", "", false, false], [18, 18, 22, 22, "named", "same", false, false], [26, 27, 22, 22, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "lightweight", "open", "source", "speech", "program", "eSpeak", ",", "which", "has", "its", "own", "approach", "to", "synthesis", ",", "experimented", "with", "Mandarin", "and", "Cantonese", ".", "eSpeak", "was", "used", "by", "Google", "Translate", "from", "May", "20102010", "."], "sentence-detokenized": "The lightweight open source speech program eSpeak, which has its own approach to synthesis, experimented with Mandarin and Cantonese. eSpeak was used by Google Translate from May 20102010.", "token2charspan": [[0, 3], [4, 15], [16, 20], [21, 27], [28, 34], [35, 42], [43, 49], [49, 50], [51, 56], [57, 60], [61, 64], [65, 68], [69, 77], [78, 80], [81, 90], [90, 91], [92, 104], [105, 109], [110, 118], [119, 122], [123, 132], [132, 133], [134, 140], [141, 144], [145, 149], [150, 152], [153, 159], [160, 169], [170, 174], [175, 178], [179, 187], [187, 188]]}
{"doc_key": "ai-test-280", "ner": [[2, 4, "product"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 4, 15, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Also", ",", "Automatic", "Mouth", "software", "was", "released", "in", "1982", "and", "was", "the", "first", "commercial", "voice", "synthesis", "program", "that", "was", "software", "-", "only", "."], "sentence-detokenized": "Also, Automatic Mouth software was released in 1982 and was the first commercial voice synthesis program that was software-only.", "token2charspan": [[0, 4], [4, 5], [6, 15], [16, 21], [22, 30], [31, 34], [35, 43], [44, 46], [47, 51], [52, 55], [56, 59], [60, 63], [64, 69], [70, 80], [81, 86], [87, 96], [97, 104], [105, 109], [110, 113], [114, 122], [122, 123], [123, 127], [127, 128]]}
{"doc_key": "ai-test-281", "ner": [[7, 9, "metrics"], [11, 11, "metrics"], [14, 14, "metrics"], [16, 16, "metrics"], [19, 26, "metrics"], [33, 33, "metrics"], [31, 35, "metrics"], [38, 44, "metrics"], [49, 51, "metrics"], [53, 53, "metrics"], [56, 58, "metrics"], [61, 68, "metrics"], [72, 75, "metrics"], [73, 77, "metrics"], [80, 86, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15], "relations": [[11, 11, 7, 9, "named", "", false, false], [14, 14, 7, 9, "named", "", false, false], [16, 16, 7, 9, "named", "", false, false], [19, 26, 7, 9, "named", "", false, false], [31, 35, 33, 33, "named", "", false, false], [38, 44, 33, 33, "named", "", false, false], [53, 53, 49, 51, "named", "", false, false], [56, 58, 49, 51, "named", "", false, false], [61, 68, 49, 51, "named", "", false, false], [73, 77, 72, 75, "named", "", false, false], [80, 86, 72, 75, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11], "sentence": ["The", "ratios", "of", "the", "columns", "are", "the", "TRUE", "Positive", "Rate", "(", "TPR", ",", "or", "Sensitivity", "or", "Recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "supplemented", "by", "the", "False", "Negative", "Rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "and", "the", "True", "Negative", "Rate", "(", "TNR", ",", "or", "Specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "supplemented", "by", "the", "False", "Positive", "Rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "The ratios of the columns are the TRUE Positive Rate (TPR, or Sensitivity or Recall) (TP / (TP + FN)), supplemented by the False Negative Rate (FNR) (FN / (TP + FN)); and the True Negative Rate (TNR, or Specificity, SPC) (TN / (TN + FP)), supplemented by the False Positive Rate (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 17], [18, 25], [26, 29], [30, 33], [34, 38], [39, 47], [48, 52], [53, 54], [54, 57], [57, 58], [59, 61], [62, 73], [74, 76], [77, 83], [83, 84], [85, 86], [86, 88], [89, 90], [91, 92], [92, 94], [95, 96], [97, 99], [99, 100], [100, 101], [101, 102], [103, 115], [116, 118], [119, 122], [123, 128], [129, 137], [138, 142], [143, 144], [144, 147], [147, 148], [149, 150], [150, 152], [153, 154], [155, 156], [156, 158], [159, 160], [161, 163], [163, 164], [164, 165], [165, 166], [167, 170], [171, 174], [175, 179], [180, 188], [189, 193], [194, 195], [195, 198], [198, 199], [200, 202], [203, 214], [214, 215], [216, 219], [219, 220], [221, 222], [222, 224], [225, 226], [227, 228], [228, 230], [231, 232], [233, 235], [235, 236], [236, 237], [237, 238], [239, 251], [252, 254], [255, 258], [259, 264], [265, 273], [274, 278], [279, 280], [280, 283], [283, 284], [285, 286], [286, 288], [289, 290], [291, 292], [292, 294], [295, 296], [297, 299], [299, 300], [300, 301], [301, 302]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 15, 15, "role", "working_with", false, false], [2, 2, 15, 15, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "and", "Weber", "have", "collaborated", "on", "many", "other", "robots", "and", "their", "experience", "of", "working", "with", "Kismet"], "sentence-detokenized": "Edsinger and Weber have collaborated on many other robots and their experience of working with Kismet", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 36], [37, 39], [40, 44], [45, 50], [51, 57], [58, 61], [62, 67], [68, 78], [79, 81], [82, 89], [90, 94], [95, 101]]}
{"doc_key": "ai-test-283", "ner": [[3, 3, "programlang"], [13, 13, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 13, 13, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "functionality", "of", "R", "is", "accessible", "from", "various", "scripting", "languages", ",", "such", "as", "Python", ",", "is", "also", "available", "."], "sentence-detokenized": "The functionality of R is accessible from various scripting languages, such as Python, is also available.", "token2charspan": [[0, 3], [4, 17], [18, 20], [21, 22], [23, 25], [26, 36], [37, 41], [42, 49], [50, 59], [60, 69], [69, 70], [71, 75], [76, 78], [79, 85], [85, 86], [87, 89], [90, 94], [95, 104], [104, 105]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "was", "one", "of", "the", "first", "robot", "languages", "and", "was", "used", "in", "the", "Unimate", "robots", "."], "sentence-detokenized": "VAL was one of the first robot languages and was used in the Unimate robots.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 24], [25, 30], [31, 40], [41, 44], [45, 48], [49, 53], [54, 56], [57, 60], [61, 68], [69, 75], [75, 76]]}
{"doc_key": "ai-test-285", "ner": [[10, 16, "conference"], [11, 18, "conference"], [21, 21, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 16, 21, 21, "physical", "", false, false], [11, 18, 10, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["They", "first", "presented", "their", "database", "as", "a", "poster", "at", "the", "2009", "Computer", "Vision", "and", "Pattern", "Recognition", "Conference", "(", "CVPR", ")", "in", "Florida", "."], "sentence-detokenized": "They first presented their database as a poster at the 2009 Computer Vision and Pattern Recognition Conference (CVPR) in Florida.", "token2charspan": [[0, 4], [5, 10], [11, 20], [21, 26], [27, 35], [36, 38], [39, 40], [41, 47], [48, 50], [51, 54], [55, 59], [60, 68], [69, 75], [76, 79], [80, 87], [88, 99], [100, 110], [111, 112], [112, 116], [116, 117], [118, 120], [121, 128], [128, 129]]}
{"doc_key": "ai-test-286", "ner": [[0, 1, "misc"], [12, 13, "task"], [15, 16, "field"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 13, 0, 1, "type-of", "", false, false], [15, 16, 0, 1, "type-of", "", false, false], [18, 19, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Categorization", "tasks", "in", "which", "labels", "are", "not", "provided", "are", "referred", "to", "as", "unsupervised", "classification", ",", "unsupervised", "learning", ",", "cluster", "analysis", "."], "sentence-detokenized": "Categorization tasks in which labels are not provided are referred to as unsupervised classification, unsupervised learning, cluster analysis.", "token2charspan": [[0, 14], [15, 20], [21, 23], [24, 29], [30, 36], [37, 40], [41, 44], [45, 53], [54, 57], [58, 66], [67, 69], [70, 72], [73, 85], [86, 100], [100, 101], [102, 114], [115, 123], [123, 124], [125, 132], [133, 141], [141, 142]]}
{"doc_key": "ai-test-287", "ner": [[2, 3, "task"], [12, 14, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "needs", "object", "recognition", ",", "recognition", "and", "identification", "of", "people", "and", "further", "recognition", "of", "emotions", "."], "sentence-detokenized": "It needs object recognition, recognition and identification of people and further recognition of emotions.", "token2charspan": [[0, 2], [3, 8], [9, 15], [16, 27], [27, 28], [29, 40], [41, 44], [45, 59], [60, 62], [63, 69], [70, 73], [74, 81], [82, 93], [94, 96], [97, 105], [105, 106]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [8, 8, "misc"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "process", "is", "complex", "and", "involves", "coding", "and", "recall", "or", "recovery", "."], "sentence-detokenized": "The process is complex and involves coding and recall or recovery.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 26], [27, 35], [36, 42], [43, 46], [47, 53], [54, 56], [57, 65], [65, 66]]}
{"doc_key": "ai-test-289", "ner": [[8, 9, "product"], [13, 14, "product"], [31, 32, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 13, 14, "named", "", false, false], [8, 9, 31, 32, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Also", "known", "as", "parallel", "robots", ",", "or", "generalized", "Stewart", "platforms", "(", "in", "the", "Stewart", "platform", ",", "actuators", "are", "assigned", "to", "both", "the", "base", "and", "the", "platform", ")", ",", "these", "systems", "are", "modular", "robots", "that", "use", "similar", "mechanisms", "to", "move", "either", "the", "robot", "on", "its", "base", "or", "one", "or", "more", "manipulator", "arms", "."], "sentence-detokenized": "Also known as parallel robots, or generalized Stewart platforms (in the Stewart platform, actuators are assigned to both the base and the platform), these systems are modular robots that use similar mechanisms to move either the robot on its base or one or more manipulator arms.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 29], [29, 30], [31, 33], [34, 45], [46, 53], [54, 63], [64, 65], [65, 67], [68, 71], [72, 79], [80, 88], [88, 89], [90, 99], [100, 103], [104, 112], [113, 115], [116, 120], [121, 124], [125, 129], [130, 133], [134, 137], [138, 146], [146, 147], [147, 148], [149, 154], [155, 162], [163, 166], [167, 174], [175, 181], [182, 186], [187, 190], [191, 198], [199, 209], [210, 212], [213, 217], [218, 224], [225, 228], [229, 234], [235, 237], [238, 241], [242, 246], [247, 249], [250, 253], [254, 256], [257, 261], [262, 273], [274, 278], [278, 279]]}
{"doc_key": "ai-test-290", "ner": [[0, 1, "field"], [6, 7, "field"], [13, 14, "field"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 7, "part-of", "subfield", false, false], [0, 1, 13, 14, "compare", "", false, false], [13, 14, 19, 20, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "vision", "as", "a", "branch", "of", "systems", "engineering", "can", "be", "considered", "distinct", "from", "computer", "vision", ",", "a", "form", "of", "computer", "science", "."], "sentence-detokenized": "Machine vision as a branch of systems engineering can be considered distinct from computer vision, a form of computer science.", "token2charspan": [[0, 7], [8, 14], [15, 17], [18, 19], [20, 26], [27, 29], [30, 37], [38, 49], [50, 53], [54, 56], [57, 67], [68, 76], [77, 81], [82, 90], [91, 97], [97, 98], [99, 100], [101, 105], [106, 108], [109, 117], [118, 125], [125, 126]]}
{"doc_key": "ai-test-291", "ner": [[4, 5, "algorithm"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 9, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "activation", "function", "of", "LSTM", "gates", "is", "often", "the", "logistic", "sigmoid", "function", "."], "sentence-detokenized": "The activation function of LSTM gates is often the logistic sigmoid function.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 26], [27, 31], [32, 37], [38, 40], [41, 46], [47, 50], [51, 59], [60, 67], [68, 76], [76, 77]]}
{"doc_key": "ai-test-292", "ner": [[5, 6, "metrics"], [19, 21, "metrics"], [18, 28, "metrics"], [30, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 19, 21, "named", "", false, false], [5, 6, 30, 32, "named", "", false, false], [18, 28, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "the", "(", "necessarily", "unique", ")", "effective", "estimator", "and", "therefore", "the", "minimum", "unbiased", "variance", "estimator", "(", "MVUE", ")", ",", "in", "addition", "to", "the", "maximum", "likelihood", "estimator", "."], "sentence-detokenized": "In other words, the sample mean is the (necessarily unique) effective estimator and therefore the minimum unbiased variance estimator (MVUE), in addition to the maximum likelihood estimator.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 38], [39, 40], [40, 51], [52, 58], [58, 59], [60, 69], [70, 79], [80, 83], [84, 93], [94, 97], [98, 105], [106, 114], [115, 123], [124, 133], [134, 135], [135, 139], [139, 140], [140, 141], [142, 144], [145, 153], [154, 156], [157, 160], [161, 168], [169, 179], [180, 189], [189, 190]]}
{"doc_key": "ai-test-293", "ner": [[14, 15, "academicjournal"], [4, 6, "researcher"], [8, 9, "researcher"], [11, 13, "researcher"], [23, 23, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 15, 23, 23, "topic", "", false, false], [14, 15, 26, 27, "topic", "", false, false], [4, 6, 14, 15, "role", "", false, false], [8, 9, 14, 15, "role", "", false, false], [11, 13, 14, 15, "role", "", false, false], [23, 23, 26, 27, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "2001", "article", "by", "Berners", "-", "Lee", ",", "James", "Hendler", "and", "Ora", "Lassila", "in", "Scientific", "American", "described", "the", "expected", "evolution", "of", "the", "existing", "Web", "into", "a", "Semantic", "Web", "."], "sentence-detokenized": "The 2001 article by Berners-Lee, James Hendler and Ora Lassila in Scientific American described the expected evolution of the existing Web into a Semantic Web.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 19], [20, 27], [27, 28], [28, 31], [31, 32], [33, 38], [39, 46], [47, 50], [51, 54], [55, 62], [63, 65], [66, 76], [77, 85], [86, 95], [96, 99], [100, 108], [109, 118], [119, 121], [122, 125], [126, 134], [135, 138], [139, 143], [144, 145], [146, 154], [155, 158], [158, 159]]}
{"doc_key": "ai-test-294", "ner": [[0, 1, "misc"], [12, 12, "person"], [18, 19, "person"]], "ner_mapping_to_source": [0, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Blade", "Runner", "used", "several", "lesser", "-", "known", "actors", "of", "the", "time", ":", "Sammon", ",", "pp.", "92", "-", "93", "Nina", "Axelrod", "auditioned", "for", "the", "role", "."], "sentence-detokenized": "Blade Runner used several lesser-known actors of the time: Sammon, pp. 92-93 Nina Axelrod auditioned for the role.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 25], [26, 32], [32, 33], [33, 38], [39, 45], [46, 48], [49, 52], [53, 57], [57, 58], [59, 65], [65, 66], [67, 70], [71, 73], [73, 74], [74, 76], [77, 81], [82, 89], [90, 100], [101, 104], [105, 108], [109, 113], [113, 114]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [13, 17, "university"], [24, 26, "product"], [29, 29, "product"], [42, 42, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 13, 17, "physical", "", false, false], [3, 4, 13, 17, "physical", "", false, false], [6, 7, 13, 17, "physical", "", false, false], [9, 10, 13, 17, "physical", "", false, false], [13, 17, 42, 42, "physical", "", true, false], [24, 26, 13, 17, "temporal", "", false, false], [29, 29, 13, 17, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "and", "Terry", "Winograd", "visited", "the", "University", "of", "Edinburgh", "in", "1971", ",", "spreading", "the", "news", "about", "the", "Micro", "-", "Planner", "and", "the", "SHRDLU", "and", "questioning", "the", "uniform", "proof", "process", "approach", "that", "was", "the", "mainstay", "of", "Edinburgh", "Logic", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited the University of Edinburgh in 1971, spreading the news about the Micro-Planner and the SHRDLU and questioning the uniform proof process approach that was the mainstay of Edinburgh Logic.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 56], [57, 65], [66, 73], [74, 77], [78, 88], [89, 91], [92, 101], [102, 104], [105, 109], [109, 110], [111, 120], [121, 124], [125, 129], [130, 135], [136, 139], [140, 145], [145, 146], [146, 153], [154, 157], [158, 161], [162, 168], [169, 172], [173, 184], [185, 188], [189, 196], [197, 202], [203, 210], [211, 219], [220, 224], [225, 228], [229, 232], [233, 241], [242, 244], [245, 254], [255, 260], [260, 261]]}
{"doc_key": "ai-test-296", "ner": [[0, 0, "researcher"], [7, 10, "field"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 11, 12, "role", "inspires", false, false], [0, 0, 14, 15, "role", "inspires", false, false], [0, 0, 17, 18, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Walter", "'s", "work", "inspired", "subsequent", "generations", "of", "robotics", "researchers", ",", "including", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work inspired subsequent generations of robotics researchers, including Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 22], [23, 33], [34, 45], [46, 48], [49, 57], [58, 69], [69, 70], [71, 80], [81, 87], [88, 94], [94, 95], [96, 100], [101, 108], [109, 112], [113, 117], [118, 124], [124, 125]]}
{"doc_key": "ai-test-297", "ner": [[7, 7, "algorithm"], [9, 10, "researcher"], [16, 22, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 9, 10, "origin", "", false, false], [7, 7, 16, 22, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Subsequently", ",", "a", "similar", "GPU", "-", "based", "CNN", "by", "Alex", "Krizhevsky", "et", "al", ".", "won", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "2012", "."], "sentence-detokenized": "Subsequently, a similar GPU-based CNN by Alex Krizhevsky et al. won the ImageNet Large Scale Visual Recognition Challenge 2012.", "token2charspan": [[0, 12], [12, 13], [14, 15], [16, 23], [24, 27], [27, 28], [28, 33], [34, 37], [38, 40], [41, 45], [46, 56], [57, 59], [60, 62], [62, 63], [64, 67], [68, 71], [72, 80], [81, 86], [87, 92], [93, 99], [100, 111], [112, 121], [122, 126], [126, 127]]}
{"doc_key": "ai-test-298", "ner": [[2, 3, "misc"], [9, 10, "metrics"], [13, 14, "metrics"], [20, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 2, 3, "type-of", "", false, false], [13, 14, 2, 3, "type-of", "", false, false], [13, 14, 20, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Commonly", "used", "loss", "functions", "for", "probabilistic", "classification", "include", "the", "log", "loss", "and", "the", "Brier", "score", "between", "the", "predicted", "and", "the", "TRUE", "probability", "distribution", "."], "sentence-detokenized": "Commonly used loss functions for probabilistic classification include the log loss and the Brier score between the predicted and the TRUE probability distribution.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 28], [29, 32], [33, 46], [47, 61], [62, 69], [70, 73], [74, 77], [78, 82], [83, 86], [87, 90], [91, 96], [97, 102], [103, 110], [111, 114], [115, 124], [125, 128], [129, 132], [133, 137], [138, 149], [150, 162], [162, 163]]}
{"doc_key": "ai-test-299", "ner": [[4, 5, "organisation"], [10, 11, "field"], [14, 14, "organisation"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 10, 11, "general-affiliation", "field_of_study", false, false], [4, 5, 17, 18, "part-of", "", false, false], [14, 14, 4, 5, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "May", "2016", ",", "NtechLab", "was", "accepted", "into", "the", "official", "biometric", "technology", "testing", "by", "NIST", "among", "three", "Russian", "companies", "."], "sentence-detokenized": "In May 2016, NtechLab was accepted into the official biometric technology testing by NIST among three Russian companies.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [22, 25], [26, 34], [35, 39], [40, 43], [44, 52], [53, 62], [63, 73], [74, 81], [82, 84], [85, 89], [90, 95], [96, 101], [102, 109], [110, 119], [119, 120]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "floating", "-", "point", "numbers", "have", "only", "a", "certain", "amount", "of", "mathematical", "precision", "."], "sentence-detokenized": "However, floating-point numbers have only a certain amount of mathematical precision.", "token2charspan": [[0, 7], [7, 8], [9, 17], [17, 18], [18, 23], [24, 31], [32, 36], [37, 41], [42, 43], [44, 51], [52, 58], [59, 61], [62, 74], [75, 84], [84, 85]]}
{"doc_key": "ai-test-301", "ner": [[5, 5, "organisation"], [13, 20, "conference"], [12, 18, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 13, 20, "role", "contributes_to", false, false], [12, 18, 13, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "2015", ",", "many", "of", "SenseTime", "'s", "papers", "were", "accepted", "at", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "conference", "."], "sentence-detokenized": "During 2015, many of SenseTime's papers were accepted at the Computer Vision and Pattern Recognition (CVPR) conference.", "token2charspan": [[0, 6], [7, 11], [11, 12], [13, 17], [18, 20], [21, 30], [30, 32], [33, 39], [40, 44], [45, 53], [54, 56], [57, 60], [61, 69], [70, 76], [77, 80], [81, 88], [89, 100], [101, 102], [102, 106], [106, 107], [108, 118], [118, 119]]}
{"doc_key": "ai-test-302", "ner": [[5, 7, "task"], [9, 9, "task"], [12, 13, "task"], [15, 18, "task"], [23, 25, "misc"], [28, 33, "conference"], [41, 43, "misc"], [45, 46, "conference"], [64, 66, "misc"], [68, 68, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10], "relations": [[9, 9, 5, 7, "named", "", false, false], [15, 18, 12, 13, "named", "", false, false], [23, 25, 28, 33, "temporal", "", false, false], [41, 43, 45, 46, "temporal", "", false, false], [64, 66, 68, 68, "temporal", "", false, false]], "relations_mapping_to_source": [1, 3, 4, 5, 6], "sentence": ["He", "co-formulated", "optimal", "algorithms", "for", "structure", "from", "motion", "(", "SFM", ",", "or", "Visual", "SLAM", ",", "simultaneous", "localization", "and", "mapping", ",", "in", "Robotics", ";", "Best", "Paper", "Award", "at", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "conference", "1998", ")", ",", "characterized", "its", "ambiguities", "(", "David", "Marr", "Award", "at", "ICCV", "1999", ")", ",", "also", "characterized", "the", "recognizability", "and", "observability", "of", "the", "fusion", "of", "visual", "and", "inertial", "sensors", "(", "Best", "Paper", "Award", "at", "Robotics", "2015", ")", "."], "sentence-detokenized": "He co-formulated optimal algorithms for structure from motion (SFM, or Visual SLAM, simultaneous localization and mapping, in Robotics; Best Paper Award at the Computer Vision and Pattern Recognition conference 1998), characterized its ambiguities (David Marr Award at ICCV 1999), also characterized the recognizability and observability of the fusion of visual and inertial sensors (Best Paper Award at Robotics 2015).", "token2charspan": [[0, 2], [3, 16], [17, 24], [25, 35], [36, 39], [40, 49], [50, 54], [55, 61], [62, 63], [63, 66], [66, 67], [68, 70], [71, 77], [78, 82], [82, 83], [84, 96], [97, 109], [110, 113], [114, 121], [121, 122], [123, 125], [126, 134], [134, 135], [136, 140], [141, 146], [147, 152], [153, 155], [156, 159], [160, 168], [169, 175], [176, 179], [180, 187], [188, 199], [200, 210], [211, 215], [215, 216], [216, 217], [218, 231], [232, 235], [236, 247], [248, 249], [249, 254], [255, 259], [260, 265], [266, 268], [269, 273], [274, 278], [278, 279], [279, 280], [281, 285], [286, 299], [300, 303], [304, 319], [320, 323], [324, 337], [338, 340], [341, 344], [345, 351], [352, 354], [355, 361], [362, 365], [366, 374], [375, 382], [383, 384], [384, 388], [389, 394], [395, 400], [401, 403], [404, 412], [413, 417], [417, 418], [418, 419]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 11, "field"], [13, 14, "field"], [21, 22, "task"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 7, 8, "part-of", "task_part_of_field", false, false], [0, 1, 10, 11, "part-of", "task_part_of_field", false, false], [0, 1, 13, 14, "part-of", "task_part_of_field", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 24, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "a", "fundamental", "tool", "in", "image", "processing", ",", "machine", "vision", "and", "computer", "vision", ",", "particularly", "in", "the", "areas", "of", "feature", "detection", "and", "feature", "extraction", "."], "sentence-detokenized": "Edge detection is a fundamental tool in image processing, machine vision and computer vision, particularly in the areas of feature detection and feature extraction.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 19], [20, 31], [32, 36], [37, 39], [40, 45], [46, 56], [56, 57], [58, 65], [66, 72], [73, 76], [77, 85], [86, 92], [92, 93], [94, 106], [107, 109], [110, 113], [114, 119], [120, 122], [123, 130], [131, 140], [141, 144], [145, 152], [153, 163], [163, 164]]}
{"doc_key": "ai-test-305", "ner": [[8, 9, "misc"], [24, 27, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "example", "would", "be", "a", "variable", "such", "as", "outdoor", "temperature", "(", "mathtemp", "/", "math", ")", ",", "which", "in", "a", "given", "application", "can", "be", "recorded", "to", "several", "decimal", "places", "(", "depending", "on", "the", "sensing", "device", ")", "."], "sentence-detokenized": "An example would be a variable such as outdoor temperature (mathtemp/math), which in a given application can be recorded to several decimal places (depending on the sensing device).", "token2charspan": [[0, 2], [3, 10], [11, 16], [17, 19], [20, 21], [22, 30], [31, 35], [36, 38], [39, 46], [47, 58], [59, 60], [60, 68], [68, 69], [69, 73], [73, 74], [74, 75], [76, 81], [82, 84], [85, 86], [87, 92], [93, 104], [105, 108], [109, 111], [112, 120], [121, 123], [124, 131], [132, 139], [140, 146], [147, 148], [148, 157], [158, 160], [161, 164], [165, 172], [173, 179], [179, 180], [180, 181]]}
{"doc_key": "ai-test-306", "ner": [[3, 4, "person"], [6, 7, "person"], [9, 10, "person"], [20, 21, "person"], [23, 23, "misc"], [27, 27, "misc"], [29, 30, "person"], [32, 32, "organisation"], [34, 35, "person"], [37, 37, "organisation"], [39, 40, "person"], [42, 42, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[29, 30, 23, 23, "part-of", "", false, false], [29, 30, 27, 27, "role", "", false, false], [34, 35, 32, 32, "role", "", false, false], [39, 40, 37, 37, "role", "youtuber", false, false], [42, 42, 39, 40, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Returning", "judges", "include", "Fon", "Davis", ",", "Jessica", "Chobot", "and", "Leland", "Melvin", ",", "as", "well", "as", "celebrity", "guest", "judges", ",", "actor", "Clark", "Gregg", ",", "MythBusters", "host", "and", "former", "Battlebots", "builder", "Adam", "Savage", ",", "NFL", "tightend", "Vernon", "Davis", "and", "YouTube", "star", "Michael", "Stevens", "aka", "Vsauce", "."], "sentence-detokenized": "Returning judges include Fon Davis, Jessica Chobot and Leland Melvin, as well as celebrity guest judges, actor Clark Gregg, MythBusters host and former Battlebots builder Adam Savage, NFL tightend Vernon Davis and YouTube star Michael Stevens aka Vsauce.", "token2charspan": [[0, 9], [10, 16], [17, 24], [25, 28], [29, 34], [34, 35], [36, 43], [44, 50], [51, 54], [55, 61], [62, 68], [68, 69], [70, 72], [73, 77], [78, 80], [81, 90], [91, 96], [97, 103], [103, 104], [105, 110], [111, 116], [117, 122], [122, 123], [124, 135], [136, 140], [141, 144], [145, 151], [152, 162], [163, 170], [171, 175], [176, 182], [182, 183], [184, 187], [188, 196], [197, 203], [204, 209], [210, 213], [214, 221], [222, 226], [227, 234], [235, 242], [243, 246], [247, 253], [253, 254]]}
{"doc_key": "ai-test-307", "ner": [[15, 16, "algorithm"], [11, 14, "algorithm"], [18, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 18, 20, "part-of", "", false, false], [11, 14, 18, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "these", "methods", "never", "beat", "the", "non-uniform", "internal", "-", "manual", "Gaussian", "/", "shadow", "Markov", "mixture", "model", "(", "GMM", "-", "HMM", ")", "technology", "based", "on", "generative", "speech", "models", "trained", "discretely", "."], "sentence-detokenized": "However, these methods never beat the non-uniform internal-manual Gaussian/shadow Markov mixture model (GMM-HMM) technology based on generative speech models trained discretely.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 22], [23, 28], [29, 33], [34, 37], [38, 49], [50, 58], [58, 59], [59, 65], [66, 74], [74, 75], [75, 81], [82, 88], [89, 96], [97, 102], [103, 104], [104, 107], [107, 108], [108, 111], [111, 112], [113, 123], [124, 129], [130, 132], [133, 143], [144, 150], [151, 157], [158, 165], [166, 176], [176, 177]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "and", "SciPy", "provide", "convenient", "ways", "to", "apply", "these", "different", "methods", "."], "sentence-detokenized": "Software packages such as MATLAB, GNU Octave, Scilab and SciPy provide convenient ways to apply these different methods.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [53, 56], [57, 62], [63, 70], [71, 81], [82, 86], [87, 89], [90, 95], [96, 101], [102, 111], [112, 119], [119, 120]]}
{"doc_key": "ai-test-309", "ner": [[1, 2, "algorithm"], [0, 4, "algorithm"], [8, 9, "task"], [16, 17, "researcher"], [19, 20, "university"], [22, 23, "researcher"], [25, 28, "organisation"], [30, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 2, 8, 9, "related-to", "", false, false], [1, 2, 16, 17, "origin", "", false, false], [1, 2, 22, 23, "origin", "", false, false], [0, 4, 1, 2, "named", "", false, false], [16, 17, 19, 20, "physical", "", false, false], [16, 17, 19, 20, "role", "", false, false], [22, 23, 25, 28, "physical", "", false, false], [22, 23, 25, 28, "role", "", false, false], [30, 32, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", ",", "a", "speech", "processing", "algorithm", ",", "was", "first", "proposed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", "."], "sentence-detokenized": "Linear predictive coding (LPC), a speech processing algorithm, was first proposed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 72], [73, 81], [82, 84], [85, 93], [94, 101], [102, 104], [105, 111], [112, 122], [123, 126], [127, 132], [133, 138], [139, 141], [142, 148], [149, 158], [159, 162], [163, 172], [173, 174], [174, 177], [177, 178], [179, 181], [182, 186], [186, 187]]}
{"doc_key": "ai-test-310", "ner": [[17, 24, "conference"], [20, 26, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 26, 17, 24, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2006", ",", "on", "the", "25th", "anniversary", "of", "the", "algorithm", ",", "a", "workshop", "was", "organized", "at", "the", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "to", "summarize", "the", "most", "recent", "contributions", "and", "variations", "of", "the", "original", "algorithm", ",", "mainly", "to", "improve", "the", "speed", "of", "the", "algorithm", ",", "the", "robustness", "and", "accuracy", "of", "the", "estimated", "solution", ",", "and", "to", "reduce", "the", "dependence", "on", "user", "-", "defined", "constants", "."], "sentence-detokenized": "In 2006, on the 25th anniversary of the algorithm, a workshop was organized at the International Conference on Computer Vision and Pattern Recognition (CVPR) to summarize the most recent contributions and variations of the original algorithm, mainly to improve the speed of the algorithm, the robustness and accuracy of the estimated solution, and to reduce the dependence on user-defined constants.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 20], [21, 32], [33, 35], [36, 39], [40, 49], [49, 50], [51, 52], [53, 61], [62, 65], [66, 75], [76, 78], [79, 82], [83, 96], [97, 107], [108, 110], [111, 119], [120, 126], [127, 130], [131, 138], [139, 150], [151, 152], [152, 156], [156, 157], [158, 160], [161, 170], [171, 174], [175, 179], [180, 186], [187, 200], [201, 204], [205, 215], [216, 218], [219, 222], [223, 231], [232, 241], [241, 242], [243, 249], [250, 252], [253, 260], [261, 264], [265, 270], [271, 273], [274, 277], [278, 287], [287, 288], [289, 292], [293, 303], [304, 307], [308, 316], [317, 319], [320, 323], [324, 333], [334, 342], [342, 343], [344, 347], [348, 350], [351, 357], [358, 361], [362, 372], [373, 375], [376, 380], [380, 381], [381, 388], [389, 398], [398, 399]]}
{"doc_key": "ai-test-311", "ner": [[4, 6, "university"], [9, 12, "organisation"], [14, 16, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Members", "went", "to", "the", "University", "of", "Debrecen", ",", "the", "Hungarian", "Academy", "of", "Sciences", ",", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "University", ",", "etc", "."], "sentence-detokenized": "Members went to the University of Debrecen, the Hungarian Academy of Sciences, E\u00f6tv\u00f6s Lor\u00e1nd University, etc.", "token2charspan": [[0, 7], [8, 12], [13, 15], [16, 19], [20, 30], [31, 33], [34, 42], [42, 43], [44, 47], [48, 57], [58, 65], [66, 68], [69, 77], [77, 78], [79, 85], [86, 92], [93, 103], [103, 104], [105, 108], [108, 109]]}
{"doc_key": "ai-test-312", "ner": [[2, 3, "algorithm"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "extend", "the", "SVM", "to", "cases", "in", "which", "the", "data", "is", "not", "linearly", "separable", ",", "we", "introduce", "the", "loss", "function", ","], "sentence-detokenized": "To extend the SVM to cases in which the data is not linearly separable, we introduce the loss function,", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 17], [18, 20], [21, 26], [27, 29], [30, 35], [36, 39], [40, 44], [45, 47], [48, 51], [52, 60], [61, 70], [70, 71], [72, 74], [75, 84], [85, 88], [89, 93], [94, 102], [102, 103]]}
{"doc_key": "ai-test-313", "ner": [[0, 0, "programlang"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 11, 12, "origin", "", false, false], [0, 0, 14, 15, "origin", "", false, false], [0, 0, 17, 18, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "is", "an", "educational", "programming", "language", ",", "designed", "in", "1967", "by", "Wally", "Feurzeig", ",", "Seymour", "Papert", "and", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo is an educational programming language, designed in 1967 by Wally Feurzeig, Seymour Papert and Cynthia Solomon.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 34], [35, 43], [43, 44], [45, 53], [54, 56], [57, 61], [62, 64], [65, 70], [71, 79], [79, 80], [81, 88], [89, 95], [96, 99], [100, 107], [108, 115], [115, 116]]}
{"doc_key": "ai-test-314", "ner": [[0, 3, "organisation"], [9, 13, "organisation"], [15, 18, "location"], [20, 20, "location"], [22, 22, "location"], [33, 38, "product"], [42, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 9, 13, "role", "works_for", false, false], [9, 13, 15, 18, "physical", "", false, false], [15, 18, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false], [33, 38, 0, 3, "origin", "", false, false], [42, 50, 33, 38, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "Eyring", "Research", "Institute", "was", "instrumental", "in", "helping", "the", "US", "Air", "Force", "Missile", "Directorate", "at", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", ",", "to", "produce", ",", "in", "top", "military", "secrecy", ",", "the", "Intelligent", "Systems", "Technology", "Software", ",", "which", "was", "fundamental", "to", "Reagan", "'s", "Star", "Wars", "program", "later", "called", "Star", "Wars", "."], "sentence-detokenized": "The Eyring Research Institute was instrumental in helping the US Air Force Missile Directorate at Hill Air Force Base near Ogden, Utah, to produce, in top military secrecy, the Intelligent Systems Technology Software, which was fundamental to Reagan's Star Wars program later called Star Wars.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 29], [30, 33], [34, 46], [47, 49], [50, 57], [58, 61], [62, 64], [65, 68], [69, 74], [75, 82], [83, 94], [95, 97], [98, 102], [103, 106], [107, 112], [113, 117], [118, 122], [123, 128], [128, 129], [130, 134], [134, 135], [136, 138], [139, 146], [146, 147], [148, 150], [151, 154], [155, 163], [164, 171], [171, 172], [173, 176], [177, 188], [189, 196], [197, 207], [208, 216], [216, 217], [218, 223], [224, 227], [228, 239], [240, 242], [243, 249], [249, 251], [252, 256], [257, 261], [262, 269], [270, 275], [276, 282], [283, 287], [288, 292], [292, 293]]}
{"doc_key": "ai-test-315", "ner": [[11, 12, "field"], [21, 24, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Over", "the", "decades", "he", "has", "researched", "and", "developed", "emerging", "areas", "of", "computer", "science", "from", "compilers", ",", "programming", "languages", "and", "systems", "architecture", "John", "F", ".", "Sowa", "and", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "Over the decades he has researched and developed emerging areas of computer science from compilers, programming languages and systems architecture John F. Sowa and John Zachman (1992).", "token2charspan": [[0, 4], [5, 8], [9, 16], [17, 19], [20, 23], [24, 34], [35, 38], [39, 48], [49, 57], [58, 63], [64, 66], [67, 75], [76, 83], [84, 88], [89, 98], [98, 99], [100, 111], [112, 121], [122, 125], [126, 133], [134, 146], [147, 151], [152, 153], [153, 154], [155, 159], [160, 163], [164, 168], [169, 176], [177, 178], [178, 182], [182, 183], [183, 184]]}
{"doc_key": "ai-test-316", "ner": [[1, 2, "algorithm"], [7, 10, "algorithm"], [12, 13, "algorithm"], [18, 19, "field"], [21, 22, "field"], [26, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 10, 1, 2, "named", "", false, false], [12, 13, 1, 2, "named", "", false, false], [18, 19, 1, 2, "usage", "", false, false], [21, 22, 1, 2, "usage", "", false, false], [26, 28, 1, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Sobel", "operator", ",", "sometimes", "called", "the", "Sobel", "-", "Feldman", "operator", "or", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "particularly", "in", "edge", "detection", "algorithms", ",", "where", "it", "creates", "an", "image", "that", "emphasizes", "edges", "."], "sentence-detokenized": "The Sobel operator, sometimes called the Sobel-Feldman operator or Sobel filter, is used in image processing and computer vision, particularly in edge detection algorithms, where it creates an image that emphasizes edges.", "token2charspan": [[0, 3], [4, 9], [10, 18], [18, 19], [20, 29], [30, 36], [37, 40], [41, 46], [46, 47], [47, 54], [55, 63], [64, 66], [67, 72], [73, 79], [79, 80], [81, 83], [84, 88], [89, 91], [92, 97], [98, 108], [109, 112], [113, 121], [122, 128], [128, 129], [130, 142], [143, 145], [146, 150], [151, 160], [161, 171], [171, 172], [173, 178], [179, 181], [182, 189], [190, 192], [193, 198], [199, 203], [204, 214], [215, 220], [220, 221]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [3, 4, "field"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 4, "compare", "", false, false], [0, 0, 3, 4, "type-of", "", false, false], [0, 0, 15, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "is", "a", "supervised", "learning", "algorithm", "that", "uses", "the", "labels", "of", "the", "data", ",", "while", "PCA", "is", "a", "label", "-", "ignoring", "learning", "algorithm", "."], "sentence-detokenized": "LDA is a supervised learning algorithm that uses the labels of the data, while PCA is a label-ignoring learning algorithm.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 19], [20, 28], [29, 38], [39, 43], [44, 48], [49, 52], [53, 59], [60, 62], [63, 66], [67, 71], [71, 72], [73, 78], [79, 82], [83, 85], [86, 87], [88, 93], [93, 94], [94, 102], [103, 111], [112, 121], [121, 122]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "linear", "classification", "algorithms", "include", "Winnow", ",", "support", "vector", "machine", "and", "logistic", "regression", "."], "sentence-detokenized": "Other linear classification algorithms include Winnow, support vector machine and logistic regression.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 38], [39, 46], [47, 53], [53, 54], [55, 62], [63, 69], [70, 77], [78, 81], [82, 90], [91, 101], [101, 102]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [6, 7, "programlang"], [17, 19, "product"], [21, 21, "programlang"], [23, 23, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 7, "general-affiliation", "", true, false], [0, 0, 17, 19, "general-affiliation", "", true, false], [0, 0, 21, 21, "general-affiliation", "", true, false], [0, 0, 23, 23, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "consists", "of", "a", "library", "of", "C", "++", "classes", "and", "several", "layers", "of", "interpreted", "interfaces", ",", "including", "Tcl", "/", "Tk", ",", "Java", "and", "Python", "."], "sentence-detokenized": "VTK consists of a library of C++ classes and several layers of interpreted interfaces, including Tcl/Tk, Java and Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 17], [18, 25], [26, 28], [29, 30], [30, 32], [33, 40], [41, 44], [45, 52], [53, 59], [60, 62], [63, 74], [75, 85], [85, 86], [87, 96], [97, 100], [100, 101], [101, 103], [103, 104], [105, 109], [110, 113], [114, 120], [120, 121]]}
{"doc_key": "ai-test-320", "ner": [[9, 11, "task"], [18, 20, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Also", ",", "text", "produced", "by", "spontaneous", "speech", "processing", "using", "automatic", "speech", "recognition", "and", "printed", "or", "handwritten", "text", "using", "visual", "character", "recognition", "contains", "processing", "noise", "."], "sentence-detokenized": "Also, text produced by spontaneous speech processing using automatic speech recognition and printed or handwritten text using visual character recognition contains processing noise.", "token2charspan": [[0, 4], [4, 5], [6, 10], [11, 19], [20, 22], [23, 34], [35, 41], [42, 52], [53, 58], [59, 68], [69, 75], [76, 87], [88, 91], [92, 99], [100, 102], [103, 114], [115, 119], [120, 125], [126, 132], [133, 142], [143, 154], [155, 163], [164, 174], [175, 180], [180, 181]]}
{"doc_key": "ai-test-321", "ner": [[0, 0, "researcher"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 9, 9, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "wrote", "several", "books", "and", "directed", "the", "development", "of", "WordNet", ",", "an", "online", "database", "of", "linking", "words", "that", "can", "be", "used", "by", "computer", "programs", "."], "sentence-detokenized": "Miller wrote several books and directed the development of WordNet, an online database of linking words that can be used by computer programs.", "token2charspan": [[0, 6], [7, 12], [13, 20], [21, 26], [27, 30], [31, 39], [40, 43], [44, 55], [56, 58], [59, 66], [66, 67], [68, 70], [71, 77], [78, 86], [87, 89], [90, 97], [98, 103], [104, 108], [109, 112], [113, 115], [116, 120], [121, 123], [124, 132], [133, 141], [141, 142]]}
{"doc_key": "ai-test-322", "ner": [[1, 1, "field"], [8, 10, "organisation"], [13, 14, "country"], [16, 17, "person"], [19, 21, "person"], [23, 24, "person"], [26, 27, "person"], [30, 31, "country"], [33, 36, "location"], [38, 39, "misc"], [40, 41, "person"], [43, 44, "person"], [46, 46, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 10, 13, 14, "physical", "", false, false], [16, 17, 30, 31, "physical", "", false, false], [19, 21, 30, 31, "physical", "", false, false], [23, 24, 30, 31, "physical", "", false, false], [26, 27, 30, 31, "physical", "", false, false], [33, 36, 1, 1, "general-affiliation", "", false, false], [33, 36, 40, 41, "artifact", "", false, false], [38, 39, 40, 41, "named", "", false, false], [43, 44, 46, 46, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Contemporary", "automatons", "are", "represented", "by", "the", "works", "of", "Cabaret", "Mechanical", "Theatre", "in", "the", "United", "Kingdom", ",", "Dug", "North", "and", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "in", "the", "United", "States", ",", "Le", "D\u00e9fenseur", "du", "Temps", "by", "French", "artist", "Jacques", "Monestier", "and", "Fran\u00e7ois", "Junod", "in", "Switzerland", "."], "sentence-detokenized": "Contemporary automatons are represented by the works of Cabaret Mechanical Theatre in the United Kingdom, Dug North and Chomick + Meder, Arthur Ganson, Joe Jones in the United States, Le D\u00e9fenseur du Temps by French artist Jacques Monestier and Fran\u00e7ois Junod in Switzerland.", "token2charspan": [[0, 12], [13, 23], [24, 27], [28, 39], [40, 42], [43, 46], [47, 52], [53, 55], [56, 63], [64, 74], [75, 82], [83, 85], [86, 89], [90, 96], [97, 104], [104, 105], [106, 109], [110, 115], [116, 119], [120, 127], [128, 129], [130, 135], [135, 136], [137, 143], [144, 150], [150, 151], [152, 155], [156, 161], [162, 164], [165, 168], [169, 175], [176, 182], [182, 183], [184, 186], [187, 196], [197, 199], [200, 205], [206, 208], [209, 215], [216, 222], [223, 230], [231, 240], [241, 244], [245, 253], [254, 259], [260, 262], [263, 274], [274, 275]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 22, 22, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "includes", "the", "standard", "codefor", "/", "code", "and", "codewhile", "/", "code", "loops", ",", "but", "(", "as", "in", "other", "similar", "applications", "such", "as", "R", ")", ",", "the", "use", "of", "vector", "notation", "is", "encouraged", "and", "is", "often", "faster", "to", "execute", "."], "sentence-detokenized": "MATLAB includes the standard codefor/code and codewhile/code loops, but (as in other similar applications such as R), the use of vector notation is encouraged and is often faster to execute.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 28], [29, 36], [36, 37], [37, 41], [42, 45], [46, 55], [55, 56], [56, 60], [61, 66], [66, 67], [68, 71], [72, 73], [73, 75], [76, 78], [79, 84], [85, 92], [93, 105], [106, 110], [111, 113], [114, 115], [115, 116], [116, 117], [118, 121], [122, 125], [126, 128], [129, 135], [136, 144], [145, 147], [148, 158], [159, 162], [163, 165], [166, 171], [172, 178], [179, 181], [182, 189], [189, 190]]}
{"doc_key": "ai-test-324", "ner": [[0, 0, "researcher"], [6, 9, "conference"], [16, 18, "field"], [21, 27, "misc"], [30, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 21, 27, "win-defeat", "", false, false], [0, 0, 30, 39, "win-defeat", "", false, false], [21, 27, 6, 9, "temporal", "", false, false], [21, 27, 16, 18, "topic", "", false, false], [30, 39, 6, 9, "temporal", "", false, false], [30, 39, 16, 18, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "in", "2007", "for", "his", "achievements", "in", "computer", "science", "education", ":", "the", "Karl", "V", ".", "Karlstrom", "Outstanding", "Educator", "Award", "and", "the", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contributions", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "Pausch received two awards from the Association for Computing Machinery in 2007 for his achievements in computer science education: the Karl V. Karlstrom Outstanding Educator Award and the ACM SIGCSE Award for Outstanding Contributions to Computer Science Education.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 26], [27, 31], [32, 35], [36, 47], [48, 51], [52, 61], [62, 71], [72, 74], [75, 79], [80, 83], [84, 87], [88, 100], [101, 103], [104, 112], [113, 120], [121, 130], [130, 131], [132, 135], [136, 140], [141, 142], [142, 143], [144, 153], [154, 165], [166, 174], [175, 180], [181, 184], [185, 188], [189, 192], [193, 199], [200, 205], [206, 209], [210, 221], [222, 235], [236, 238], [239, 247], [248, 255], [256, 265], [265, 266]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [8, 12, "product"], [9, 9, "product"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 12, "role", "sells", false, false], [8, 12, 9, 9, "general-affiliation", "", false, false], [8, 12, 17, 18, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "shipped", "in", "1961", "to", "General", "Motors", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was shipped in 1961 to General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 73], [74, 76], [77, 81], [82, 84], [85, 92], [93, 99], [99, 100]]}
{"doc_key": "ai-test-326", "ner": [[0, 1, "algorithm"], [5, 10, "field"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 1, "usage", "", false, false], [11, 12, 5, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantic", "networks", "are", "used", "in", "natural", "language", "processing", "applications", "such", "as", "semantic", "analysis", "."], "sentence-detokenized": "Semantic networks are used in natural language processing applications such as semantic analysis.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 26], [27, 29], [30, 37], [38, 46], [47, 57], [58, 70], [71, 75], [76, 78], [79, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-327", "ner": [[4, 5, "field"], [7, 8, "field"], [10, 11, "task"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 8, 4, 5, "usage", "", false, false], [10, 11, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Some", "successful", "applications", "of", "deep", "learning", "are", "computer", "vision", "and", "speech", "recognition", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Some successful applications of deep learning are computer vision and speech recognition. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 31], [32, 36], [37, 45], [46, 49], [50, 58], [59, 65], [66, 69], [70, 76], [77, 88], [88, 89], [90, 97], [98, 101], [101, 102], [103, 108], [109, 115], [115, 116], [117, 123], [124, 133], [133, 134], [135, 141], [142, 143], [143, 144], [145, 147], [147, 148]]}
{"doc_key": "ai-test-328", "ner": [[5, 10, "product"], [16, 16, "misc"], [19, 21, "misc"], [25, 27, "product"], [29, 30, "task"], [32, 33, "task"], [35, 36, "task"], [38, 40, "field"], [42, 43, "task"], [45, 46, "field"], [48, 49, "task"], [51, 52, "task"], [54, 55, "task"], [58, 59, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[5, 10, 16, 16, "physical", "travels_to", false, false], [5, 10, 19, 21, "physical", "travels_to", false, false], [25, 27, 5, 10, "part-of", "", false, false], [25, 27, 5, 10, "role", "maintains", false, false], [25, 27, 29, 30, "related-to", "has_ability_to", false, false], [25, 27, 32, 33, "related-to", "has_ability_to", false, false], [25, 27, 35, 36, "related-to", "has_ability_to", false, false], [25, 27, 38, 40, "related-to", "has_ability_to", false, false], [25, 27, 42, 43, "related-to", "has_ability_to", false, false], [25, 27, 45, 46, "related-to", "has_ability_to", false, false], [25, 27, 48, 49, "related-to", "has_ability_to", false, false], [25, 27, 51, 52, "related-to", "has_ability_to", false, false], [25, 27, 54, 55, "related-to", "has_ability_to", false, false], [25, 27, 58, 59, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "addition", "to", "maintaining", "the", "systems", "of", "the", "spacecraft", "Discovery", "One", "during", "the", "interplanetary", "mission", "to", "Jupiter", "(", "or", "Saturn", "in", "the", "novel", ")", ",", "HAL", "is", "capable", "of", "speech", "synthesis", ",", "speech", "recognition", ",", "face", "recognition", ",", "natural", "language", "processing", ",", "lip", "reading", ",", "art", "appreciation", ",", "emotional", "computing", ",", "logic", "automation", ",", "piloting", "spacecraft", ",", "and", "playing", "chess", "."], "sentence-detokenized": "In addition to maintaining the systems of the spacecraft Discovery One during the interplanetary mission to Jupiter (or Saturn in the novel), HAL is capable of speech synthesis, speech recognition, face recognition, natural language processing, lip reading, art appreciation, emotional computing, logic automation, piloting spacecraft, and playing chess.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 38], [39, 41], [42, 45], [46, 56], [57, 66], [67, 70], [71, 77], [78, 81], [82, 96], [97, 104], [105, 107], [108, 115], [116, 117], [117, 119], [120, 126], [127, 129], [130, 133], [134, 139], [139, 140], [140, 141], [142, 145], [146, 148], [149, 156], [157, 159], [160, 166], [167, 176], [176, 177], [178, 184], [185, 196], [196, 197], [198, 202], [203, 214], [214, 215], [216, 223], [224, 232], [233, 243], [243, 244], [245, 248], [249, 256], [256, 257], [258, 261], [262, 274], [274, 275], [276, 285], [286, 295], [295, 296], [297, 302], [303, 313], [313, 314], [315, 323], [324, 334], [334, 335], [336, 339], [340, 347], [348, 353], [353, 354]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [4, 4, "country"], [7, 8, "country"], [11, 11, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 4, "physical", "", false, false], [0, 1, 7, 8, "physical", "", false, false], [0, 1, 11, 11, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr.", "Julesz", "emigrated", "from", "Hungary", "to", "the", "United", "States", "after", "the", "Soviet", "invasion", "of", "1956", "."], "sentence-detokenized": "Dr. Julesz emigrated from Hungary to the United States after the Soviet invasion of 1956.", "token2charspan": [[0, 3], [4, 10], [11, 20], [21, 25], [26, 33], [34, 36], [37, 40], [41, 47], [48, 54], [55, 60], [61, 64], [65, 71], [72, 80], [81, 83], [84, 88], [88, 89]]}
{"doc_key": "ai-test-330", "ner": [[1, 2, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sigmoid", "function", "activation", "functions", "use", "a", "second", "nonlinearity", "for", "large", "inputs", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+\\", "exp", "(", "-", "v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "The sigmoid function activation functions use a second nonlinearity for large inputs: math\\ phi (v _ i) = (1 +\\ exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 31], [32, 41], [42, 45], [46, 47], [48, 54], [55, 67], [68, 71], [72, 77], [78, 84], [84, 85], [86, 90], [90, 91], [92, 95], [96, 97], [97, 98], [99, 100], [101, 102], [102, 103], [104, 105], [106, 107], [107, 108], [109, 111], [112, 115], [116, 117], [117, 118], [118, 119], [120, 121], [122, 123], [123, 124], [124, 125], [126, 127], [128, 129], [129, 131], [131, 132], [133, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-test-331", "ner": [[12, 14, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "probabilities", "are", "used", "to", "determine", "which", "is", "the", "target", "using", "a", "maximum", "likelihood", "decision", "."], "sentence-detokenized": "These probabilities are used to determine which is the target using a maximum likelihood decision.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 47], [48, 50], [51, 54], [55, 61], [62, 67], [68, 69], [70, 77], [78, 88], [89, 97], [97, 98]]}
{"doc_key": "ai-test-332", "ner": [[6, 8, "university"], [14, 16, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1984", "he", "moved", "to", "the", "University", "of", "Konstanz", "and", "in", "1990", "to", "the", "University", "of", "Salzburg", "."], "sentence-detokenized": "In 1984 he moved to the University of Konstanz and in 1990 to the University of Salzburg.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 46], [47, 50], [51, 53], [54, 58], [59, 61], [62, 65], [66, 76], [77, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-333", "ner": [[7, 8, "metrics"], [10, 12, "metrics"], [14, 16, "metrics"], [18, 18, "metrics"], [20, 21, "metrics"], [23, 25, "metrics"], [29, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 12, 7, 8, "origin", "based_on", false, false], [14, 16, 7, 8, "origin", "based_on", false, false], [18, 18, 7, 8, "origin", "based_on", false, false], [20, 21, 7, 8, "origin", "based_on", false, false], [23, 25, 7, 8, "origin", "based_on", false, false], [29, 32, 7, 8, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Some", "popular", "fitness", "functions", "based", "on", "the", "confusion", "matrix", "include", "sensitivity", "/", "specificity", ",", "recall", "/", "accuracy", ",", "F-measure", ",", "Jaccard", "similarity", ",", "Matthews", "correlation", "coefficient", ",", "and", "the", "cost", "/", "gain", "matrix", "that", "combines", "the", "costs", "and", "gains", "corresponding", "to", "the", "4", "different", "types", "of", "classifications", "."], "sentence-detokenized": "Some popular fitness functions based on the confusion matrix include sensitivity/specificity, recall/accuracy, F-measure, Jaccard similarity, Matthews correlation coefficient, and the cost/gain matrix that combines the costs and gains corresponding to the 4 different types of classifications.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 30], [31, 36], [37, 39], [40, 43], [44, 53], [54, 60], [61, 68], [69, 80], [80, 81], [81, 92], [92, 93], [94, 100], [100, 101], [101, 109], [109, 110], [111, 120], [120, 121], [122, 129], [130, 140], [140, 141], [142, 150], [151, 162], [163, 174], [174, 175], [176, 179], [180, 183], [184, 188], [188, 189], [189, 193], [194, 200], [201, 205], [206, 214], [215, 218], [219, 224], [225, 228], [229, 234], [235, 248], [249, 251], [252, 255], [256, 257], [258, 267], [268, 273], [274, 276], [277, 292], [292, 293]]}
{"doc_key": "ai-test-334", "ner": [[7, 7, "product"], [9, 9, "product"], [11, 11, "product"], [13, 13, "product"], [16, 17, "programlang"], [29, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[29, 31, 7, 7, "part-of", "", false, false], [29, 31, 9, 9, "part-of", "", false, false], [29, 31, 11, 11, "part-of", "", false, false], [29, 31, 13, 13, "part-of", "", false, false], [29, 31, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Common", "numerical", "programming", "environments", ",", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "and", "the", "R", "language", ",", "provide", "some", "of", "the", "simplest", "feature", "extraction", "techniques", "(", "e.g.", "principal", "component", "analysis", ")", "via", "built", "-", "in", "commands", "."], "sentence-detokenized": "Common numerical programming environments, such as MATLAB, SciLab, NumPy, Sklearn and the R language, provide some of the simplest feature extraction techniques (e.g. principal component analysis) via built-in commands.", "token2charspan": [[0, 6], [7, 16], [17, 28], [29, 41], [41, 42], [43, 47], [48, 50], [51, 57], [57, 58], [59, 65], [65, 66], [67, 72], [72, 73], [74, 81], [82, 85], [86, 89], [90, 91], [92, 100], [100, 101], [102, 109], [110, 114], [115, 117], [118, 121], [122, 130], [131, 138], [139, 149], [150, 160], [161, 162], [162, 166], [167, 176], [177, 186], [187, 195], [195, 196], [197, 200], [201, 206], [206, 207], [207, 209], [210, 218], [218, 219]]}
{"doc_key": "ai-test-335", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "have", "been", "applied", "to", "work", "together", "with", "humans", "to", "perform", "industrial", "production", "tasks", "."], "sentence-detokenized": "Industrial robots have been applied to work together with humans to perform industrial production tasks.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 27], [28, 35], [36, 38], [39, 43], [44, 52], [53, 57], [58, 64], [65, 67], [68, 75], [76, 86], [87, 97], [98, 103], [103, 104]]}
{"doc_key": "ai-test-336", "ner": [[6, 6, "field"], [8, 11, "researcher"], [21, 22, "field"], [24, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 21, 22, "related-to", "", false, false], [6, 6, 24, 25, "related-to", "", false, false], [6, 6, 27, 28, "related-to", "", false, false], [8, 11, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "first", "published", "work", "on", "CGs", ",", "John", "F", ".", "Sowa", "applied", "them", "to", "a", "wide", "range", "of", "topics", "in", "artificial", "intelligence", ",", "computer", "science", "and", "cognitive", "science", "."], "sentence-detokenized": "In the first published work on CGs, John F. Sowa applied them to a wide range of topics in artificial intelligence, computer science and cognitive science.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [23, 27], [28, 30], [31, 34], [34, 35], [36, 40], [41, 42], [42, 43], [44, 48], [49, 56], [57, 61], [62, 64], [65, 66], [67, 71], [72, 77], [78, 80], [81, 87], [88, 90], [91, 101], [102, 114], [114, 115], [116, 124], [125, 132], [133, 136], [137, 146], [147, 154], [154, 155]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [4, 6, "metrics"], [10, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 6, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "in", "the", "calculation", "of", "the", "brevity", "penalty", ",", "since", "small", "variations", "in", "translation", "length", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from BLEU in the calculation of the brevity penalty, since small variations in translation length do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 46], [47, 49], [50, 53], [54, 61], [62, 69], [69, 70], [71, 76], [77, 82], [83, 93], [94, 96], [97, 108], [109, 115], [116, 118], [119, 122], [123, 129], [130, 133], [134, 141], [142, 147], [148, 150], [151, 155], [155, 156]]}
{"doc_key": "ai-test-338", "ner": [[0, 5, "misc"], [13, 13, "conference"], [21, 23, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 5, 13, 13, "temporal", "", false, false], [0, 5, 21, 23, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "IJCAI", "Award", "for", "Research", "Excellence", "is", "a", "biennial", "award", "presented", "at", "the", "IJCAI", "conference", "to", "researchers", "in", "the", "field", "of", "artificial", "intelligence", "in", "recognition", "of", "their", "career", "excellence", "."], "sentence-detokenized": "The IJCAI Award for Research Excellence is a biennial award presented at the IJCAI conference to researchers in the field of artificial intelligence in recognition of their career excellence.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 28], [29, 39], [40, 42], [43, 44], [45, 53], [54, 59], [60, 69], [70, 72], [73, 76], [77, 82], [83, 93], [94, 96], [97, 108], [109, 111], [112, 115], [116, 121], [122, 124], [125, 135], [136, 148], [149, 151], [152, 163], [164, 166], [167, 172], [173, 179], [180, 190], [190, 191]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [4, 4, "conference"], [16, 23, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "role", "", false, false], [0, 0, 16, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "was", "an", "original", "AAAI", "Fellow", "and", "is", "the", "only", "person", "to", "have", "served", "on", "the", "Scientific", "Advisory", "Boards", "of", "both", "Microsoft", "and", "Apple", "."], "sentence-detokenized": "Lenat was an original AAAI Fellow and is the only person to have served on the Scientific Advisory Boards of both Microsoft and Apple.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 21], [22, 26], [27, 33], [34, 37], [38, 40], [41, 44], [45, 49], [50, 56], [57, 59], [60, 64], [65, 71], [72, 74], [75, 78], [79, 89], [90, 98], [99, 105], [106, 108], [109, 113], [114, 123], [124, 127], [128, 133], [133, 134]]}
{"doc_key": "ai-test-340", "ner": [[0, 0, "algorithm"], [5, 6, "misc"], [10, 12, "metrics"], [19, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "related-to", "minimise", false, false], [10, 12, 5, 6, "type-of", "", false, false], [19, 19, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autocoders", "are", "trained", "to", "minimize", "reconstruction", "errors", "(", "such", "as", "mean", "square", "error", ")", ",", "often", "referred", "to", "as", "loss", ":"], "sentence-detokenized": "Autocoders are trained to minimize reconstruction errors (such as mean square error), often referred to as loss:", "token2charspan": [[0, 10], [11, 14], [15, 22], [23, 25], [26, 34], [35, 49], [50, 56], [57, 58], [58, 62], [63, 65], [66, 70], [71, 77], [78, 83], [83, 84], [84, 85], [86, 91], [92, 100], [101, 103], [104, 106], [107, 111], [111, 112]]}
{"doc_key": "ai-test-341", "ner": [[31, 33, "misc"], [37, 37, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[37, 37, 31, 33, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "to", "using", "definitions", "is", "to", "take", "into", "account", "the", "general", "relatedness", "between", "word", "-", "verbs", "and", "calculate", "the", "similarity", "of", "each", "word", "-", "verb", "pair", "based", "on", "a", "given", "lexical", "knowledge", "base", ",", "such", "as", "WordNet", "."], "sentence-detokenized": "An alternative to using definitions is to take into account the general relatedness between word-verbs and calculate the similarity of each word-verb pair based on a given lexical knowledge base, such as WordNet.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 23], [24, 35], [36, 38], [39, 41], [42, 46], [47, 51], [52, 59], [60, 63], [64, 71], [72, 83], [84, 91], [92, 96], [96, 97], [97, 102], [103, 106], [107, 116], [117, 120], [121, 131], [132, 134], [135, 139], [140, 144], [144, 145], [145, 149], [150, 154], [155, 160], [161, 163], [164, 165], [166, 171], [172, 179], [180, 189], [190, 194], [194, 195], [196, 200], [201, 203], [204, 211], [211, 212]]}
{"doc_key": "ai-test-342", "ner": [[0, 2, "algorithm"], [9, 12, "researcher"], [15, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 12, "origin", "", false, false], [9, 12, 15, 15, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "devised", "by", "Richard", "S.", "Sutton", "and", "based", "on", "Arthur", "Samuel", "'s", "earlier", "work", "on", "learning", "the", "time", "difference", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm devised by Richard S. Sutton and based on Arthur Samuel's earlier work on learning the time difference.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 41], [42, 44], [45, 52], [53, 55], [56, 62], [63, 66], [67, 72], [73, 75], [76, 82], [83, 89], [89, 91], [92, 99], [100, 104], [105, 107], [108, 116], [117, 120], [121, 125], [126, 136], [136, 137]]}
{"doc_key": "ai-test-343", "ner": [[1, 2, "field"], [4, 4, "field"], [6, 7, "task"], [12, 13, "task"], [15, 15, "task"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 1, 2, "part-of", "task_part_of_field", false, false], [6, 7, 4, 4, "part-of", "task_part_of_field", false, false], [12, 13, 6, 7, "named", "", false, false], [15, 15, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "data", "mining", "and", "statistics", ",", "hierarchical", "clustering", "(", "also", "called", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "cluster", "analysis", "method", "that", "seeks", "to", "create", "a", "hierarchy", "of", "clusters", "."], "sentence-detokenized": "In data mining and statistics, hierarchical clustering (also called hierarchical cluster analysis or HCA) is a cluster analysis method that seeks to create a hierarchy of clusters.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 29], [29, 30], [31, 43], [44, 54], [55, 56], [56, 60], [61, 67], [68, 80], [81, 88], [89, 97], [98, 100], [101, 104], [104, 105], [106, 108], [109, 110], [111, 118], [119, 127], [128, 134], [135, 139], [140, 145], [146, 148], [149, 155], [156, 157], [158, 167], [168, 170], [171, 179], [179, 180]]}
{"doc_key": "ai-test-344", "ner": [[3, 3, "algorithm"], [8, 11, "field"], [10, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "concept", "of", "decomposition", "is", "widely", "used", "in", "signal", "and", "image", "processing", "techniques", "."], "sentence-detokenized": "The concept of decomposition is widely used in signal and image processing techniques.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 53], [54, 57], [58, 63], [64, 74], [75, 85], [85, 86]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [22, 23, "misc"], [26, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 22, 23, "related-to", "enhances", false, false], [0, 1, 22, 23, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "serve", "to", "construct", "and", "accumulate", "spatial", "knowledge", "by", "allowing", "the", "mind", "'s", "eye", "to", "visualise", "images", "in", "order", "to", "reduce", "cognitive", "load", ",", "enhance", "recall", "and", "learning", "of", "information", "."], "sentence-detokenized": "Cognitive maps serve to construct and accumulate spatial knowledge by allowing the mind's eye to visualise images in order to reduce cognitive load, enhance recall and learning of information.", "token2charspan": [[0, 9], [10, 14], [15, 20], [21, 23], [24, 33], [34, 37], [38, 48], [49, 56], [57, 66], [67, 69], [70, 78], [79, 82], [83, 87], [87, 89], [90, 93], [94, 96], [97, 106], [107, 113], [114, 116], [117, 122], [123, 125], [126, 132], [133, 142], [143, 147], [147, 148], [149, 156], [157, 163], [164, 167], [168, 176], [177, 179], [180, 191], [191, 192]]}
{"doc_key": "ai-test-346", "ner": [[8, 8, "programlang"], [10, 11, "programlang"], [13, 13, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "usually", "providing", "bindings", "in", "languages", "such", "as", "Python", ",", "C", "++", ",", "Java", ")", "."], "sentence-detokenized": ", usually providing bindings in languages such as Python, C++, Java).", "token2charspan": [[0, 1], [2, 9], [10, 19], [20, 28], [29, 31], [32, 41], [42, 46], [47, 49], [50, 56], [56, 57], [58, 59], [59, 61], [61, 62], [63, 67], [67, 68], [68, 69]]}
{"doc_key": "ai-test-347", "ner": [[1, 5, "product"], [19, 20, "task"], [26, 27, "task"], [31, 35, "task"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "voice", "-user", "interface", "(", "VUI", ")", "makes", "it", "possible", "for", "humans", "to", "interact", "verbally", "with", "computers", ",", "using", "speech", "recognition", "to", "understand", "spoken", "commands", "and", "answer", "questions", ",", "and", "usually", "converting", "text", "to", "speech", "to", "play", "back", "a", "response", "."], "sentence-detokenized": "A voice-user interface (VUI) makes it possible for humans to interact verbally with computers, using speech recognition to understand spoken commands and answer questions, and usually converting text to speech to play back a response.", "token2charspan": [[0, 1], [2, 7], [7, 12], [13, 22], [23, 24], [24, 27], [27, 28], [29, 34], [35, 37], [38, 46], [47, 50], [51, 57], [58, 60], [61, 69], [70, 78], [79, 83], [84, 93], [93, 94], [95, 100], [101, 107], [108, 119], [120, 122], [123, 133], [134, 140], [141, 149], [150, 153], [154, 160], [161, 170], [170, 171], [172, 175], [176, 183], [184, 194], [195, 199], [200, 202], [203, 209], [210, 212], [213, 217], [218, 222], [223, 224], [225, 233], [233, 234]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 4, "misc"], [7, 7, "programlang"], [11, 14, "researcher"], [16, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 4, "general-affiliation", "is_a", false, false], [0, 0, 7, 7, "general-affiliation", "made_with", false, false], [0, 0, 11, 14, "origin", "", false, false], [11, 14, 16, 17, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Jess", "is", "a", "rules", "engine", "for", "the", "Java", "platform", "developed", "by", "Ernest", "Friedman", "-", "Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "Jess is a rules engine for the Java platform developed by Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 15], [16, 22], [23, 26], [27, 30], [31, 35], [36, 44], [45, 54], [55, 57], [58, 64], [65, 73], [73, 74], [74, 78], [79, 81], [82, 88], [89, 97], [97, 98]]}
{"doc_key": "ai-test-349", "ner": [[1, 2, "algorithm"], [18, 22, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 18, 22, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "layered", "perceptrons", ",", "where", "there", "is", "a", "hidden", "layer", ",", "more", "sophisticated", "algorithms", ",", "such", "as", "the", "backpropagation", "algorithm", ",", "should", "be", "used", "."], "sentence-detokenized": "For layered perceptrons, where there is a hidden layer, more sophisticated algorithms, such as the backpropagation algorithm, should be used.", "token2charspan": [[0, 3], [4, 11], [12, 23], [23, 24], [25, 30], [31, 36], [37, 39], [40, 41], [42, 48], [49, 54], [54, 55], [56, 60], [61, 74], [75, 85], [85, 86], [87, 91], [92, 94], [95, 98], [99, 114], [115, 124], [124, 125], [126, 132], [133, 135], [136, 140], [140, 141]]}
{"doc_key": "ai-test-350", "ner": [[0, 1, "product"], [2, 6, "product"], [10, 19, "algorithm"], [23, 24, "field"], [28, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 6, 0, 1, "part-of", "", false, false], [2, 6, 10, 19, "usage", "", false, true], [10, 19, 23, 24, "related-to", "performs", false, false], [28, 33, 23, 24, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "Translate", "'s", "neural", "machine", "translation", "system", "uses", "a", "large", "end", "-", "to", "-", "end", "artificial", "neural", "network", ",", "which", "tries", "to", "perform", "deep", "learning", ",", "in", "particular", "long", "short", "-", "term", "memory", "networks", "."], "sentence-detokenized": "Google Translate's neural machine translation system uses a large end-to-end artificial neural network, which tries to perform deep learning, in particular long short-term memory networks.", "token2charspan": [[0, 6], [7, 16], [16, 18], [19, 25], [26, 33], [34, 45], [46, 52], [53, 57], [58, 59], [60, 65], [66, 69], [69, 70], [70, 72], [72, 73], [73, 76], [77, 87], [88, 94], [95, 102], [102, 103], [104, 109], [110, 115], [116, 118], [119, 126], [127, 131], [132, 140], [140, 141], [142, 144], [145, 155], [156, 160], [161, 166], [166, 167], [167, 171], [172, 178], [179, 187], [187, 188]]}
{"doc_key": "ai-test-351", "ner": [[14, 14, "researcher"], [16, 16, "researcher"], [18, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Various", "methods", "for", "this", "purpose", "were", "developed", "in", "the", "1980s", "and", "early", "1990s", "by", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "and", "others", "."], "sentence-detokenized": "Various methods for this purpose were developed in the 1980s and early 1990s by Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter and others.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 24], [25, 32], [33, 37], [38, 47], [48, 50], [51, 54], [55, 60], [61, 64], [65, 70], [71, 76], [77, 79], [80, 86], [86, 87], [88, 96], [96, 97], [98, 106], [106, 107], [108, 114], [115, 126], [126, 127], [128, 132], [133, 143], [143, 144], [145, 156], [157, 160], [161, 167], [167, 168]]}
{"doc_key": "ai-test-352", "ner": [[1, 1, "organisation"], [2, 4, "organisation"], [9, 10, "organisation"], [12, 15, "task"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 9, 10, "role", "licenses_from", false, false], [2, 4, 1, 1, "named", "", false, false], [19, 19, 1, 1, "origin", "", false, false], [19, 19, 12, 15, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc.", "had", "originally", "licensed", "software", "from", "Nuance", "to", "provide", "speech", "recognition", "capabilities", "to", "its", "digital", "assistant", "Siri", "."], "sentence-detokenized": "| Apple Apple Inc. had originally licensed software from Nuance to provide speech recognition capabilities to its digital assistant Siri.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 18], [19, 22], [23, 33], [34, 42], [43, 51], [52, 56], [57, 63], [64, 66], [67, 74], [75, 81], [82, 93], [94, 106], [107, 109], [110, 113], [114, 121], [122, 131], [132, 136], [136, 137]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [7, 8, "person"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 4, "role", "releases_movies_in_genre", false, false], [7, 8, 0, 0, "role", "directs_for", false, false], [12, 13, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "released", "several", "3D", "westerns", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia released several 3D westerns produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 28], [29, 37], [38, 46], [47, 49], [50, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-test-354", "ner": [[9, 10, "field"], [12, 12, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "integrates", "knowledge", "and", "research", "in", "the", "fields", "of", "computer", "science", ",", "linguistics", "and", "computer", "engineering", "."], "sentence-detokenized": "It integrates knowledge and research in the fields of computer science, linguistics and computer engineering.", "token2charspan": [[0, 2], [3, 13], [14, 23], [24, 27], [28, 36], [37, 39], [40, 43], [44, 50], [51, 53], [54, 62], [63, 70], [70, 71], [72, 83], [84, 87], [88, 96], [97, 108], [108, 109]]}
{"doc_key": "ai-test-355", "ner": [[5, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", "is", "an", "example", "of", "R", "code", ":"], "sentence-detokenized": "Here is an example of R code:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 23], [24, 28], [28, 29]]}
{"doc_key": "ai-test-356", "ner": [[0, 2, "metrics"], [8, 11, "metrics"], [10, 13, "metrics"], [17, 20, "metrics"], [19, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 8, 11, "part-of", "plotted_into", false, false], [0, 2, 17, 20, "part-of", "plotted_into", false, false], [10, 13, 8, 11, "named", "", false, false], [19, 22, 17, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "ROC", "curve", "is", "generated", "by", "plotting", "the", "percentage", "of", "TRUE", "positives", "(", "TPR", ")", "against", "the", "percentage", "of", "False", "Positives", "(", "FPR", ")", "at", "various", "threshold", "settings", "."], "sentence-detokenized": "The ROC curve is generated by plotting the percentage of TRUE positives (TPR) against the percentage of False Positives (FPR) at various threshold settings.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 26], [27, 29], [30, 38], [39, 42], [43, 53], [54, 56], [57, 61], [62, 71], [72, 73], [73, 76], [76, 77], [78, 85], [86, 89], [90, 100], [101, 103], [104, 109], [110, 119], [120, 121], [121, 124], [124, 125], [126, 128], [129, 136], [137, 146], [147, 155], [155, 156]]}
{"doc_key": "ai-test-357", "ner": [[4, 5, "field"], [8, 9, "researcher"], [11, 12, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "related-to", "researches_field", false, false], [11, 12, 4, 5, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Research", "stalled", "after", "the", "machine", "learning", "research", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", ","], "sentence-detokenized": "Research stalled after the machine learning research of Marvin Minsky and Seymour Papert (1969),", "token2charspan": [[0, 8], [9, 16], [17, 22], [23, 26], [27, 34], [35, 43], [44, 52], [53, 55], [56, 62], [63, 69], [70, 73], [74, 81], [82, 88], [89, 90], [90, 94], [94, 95], [95, 96]]}
{"doc_key": "ai-test-358", "ner": [[6, 6, "task"], [9, 10, "programlang"], [12, 14, "product"], [16, 17, "programlang"], [19, 19, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 9, 10, "related-to", "used_to_build", false, false], [6, 6, 12, 14, "related-to", "used_to_build", false, false], [6, 6, 16, 17, "related-to", "used_to_build", false, false], [6, 6, 19, 19, "related-to", "used_to_build", false, false], [6, 6, 22, 22, "related-to", "used_to_build", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "programming", "environments", "used", "to", "build", "DAQ", "applications", "include", "Ladder", "Logic", ",", "Visual", "C", "++", ",", "Visual", "Basic", ",", "LabVIEW", ",", "and", "MATLAB", "."], "sentence-detokenized": "Other programming environments used to build DAQ applications include Ladder Logic, Visual C++, Visual Basic, LabVIEW, and MATLAB.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 38], [39, 44], [45, 48], [49, 61], [62, 69], [70, 76], [77, 82], [82, 83], [84, 90], [91, 92], [92, 94], [94, 95], [96, 102], [103, 108], [108, 109], [110, 117], [117, 118], [119, 122], [123, 129], [129, 130]]}
{"doc_key": "ai-test-359", "ner": [[15, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "metric", "was", "designed", "to", "correct", "some", "of", "the", "problems", "identified", "in", "the", "more", "popular", "BLEU", "metric", "and", "also", "produce", "good", "correlation", "with", "human", "judgment", "at", "the", "sentence", "or", "department", "level", "."], "sentence-detokenized": "The metric was designed to correct some of the problems identified in the more popular BLEU metric and also produce good correlation with human judgment at the sentence or department level.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 34], [35, 39], [40, 42], [43, 46], [47, 55], [56, 66], [67, 69], [70, 73], [74, 78], [79, 86], [87, 91], [92, 98], [99, 102], [103, 107], [108, 115], [116, 120], [121, 132], [133, 137], [138, 143], [144, 152], [153, 155], [156, 159], [160, 168], [169, 171], [172, 182], [183, 188], [188, 189]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "-", "term", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "semantic", "associations", "between", "successive", "video", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long-term short-term memory are often used to exploit semantic associations between successive video frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [82, 83], [83, 87], [88, 93], [93, 94], [94, 98], [99, 105], [106, 109], [110, 115], [116, 120], [121, 123], [124, 131], [132, 140], [141, 153], [154, 161], [162, 172], [173, 178], [179, 185], [185, 186]]}
{"doc_key": "ai-test-361", "ner": [[3, 7, "product"], [14, 19, "product"], [23, 23, "product"], [39, 39, "product"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[23, 23, 14, 19, "part-of", "", false, false]], "relations_mapping_to_source": [3], "sentence": ["Mass", "-", "produced", "printed", "circuit", "boards", "(", "PCBs", ")", "are", "made", "almost", "exclusively", "by", "pick", "-", "and", "-", "place", "robots", ",", "usually", "with", "SCARA", "operators", ",", "which", "remove", "tiny", "electronic", "components", "from", "tapes", "or", "trays", "and", "mount", "them", "on", "PCBs", "with", "great", "precision", "."], "sentence-detokenized": "Mass-produced printed circuit boards (PCBs) are made almost exclusively by pick-and-place robots, usually with SCARA operators, which remove tiny electronic components from tapes or trays and mount them on PCBs with great precision.", "token2charspan": [[0, 4], [4, 5], [5, 13], [14, 21], [22, 29], [30, 36], [37, 38], [38, 42], [42, 43], [44, 47], [48, 52], [53, 59], [60, 71], [72, 74], [75, 79], [79, 80], [80, 83], [83, 84], [84, 89], [90, 96], [96, 97], [98, 105], [106, 110], [111, 116], [117, 126], [126, 127], [128, 133], [134, 140], [141, 145], [146, 156], [157, 167], [168, 172], [173, 178], [179, 181], [182, 187], [188, 191], [192, 197], [198, 202], [203, 205], [206, 210], [211, 215], [216, 221], [222, 231], [231, 232]]}
{"doc_key": "ai-test-362", "ner": [[4, 5, "field"], [15, 15, "algorithm"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 29, "researcher"], [36, 37, "algorithm"], [39, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 4, 5, "part-of", "", false, false], [15, 15, 20, 21, "origin", "", false, false], [15, 15, 23, 24, "origin", "", false, false], [15, 15, 26, 29, "origin", "", false, false], [15, 15, 36, 37, "type-of", "", false, false], [36, 37, 39, 40, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "context", "of", "machine", "learning", ",", "where", "it", "is", "more", "widely", "applied", "today", ",", "LDA", "was", "independently", "rediscovered", "by", "David", "Blei", ",", "Andrew", "Ng", "and", "Michael", "I", ".", "Jordan", "in", "2003", "and", "presented", "as", "a", "graphical", "model", "for", "topic", "discovery", "."], "sentence-detokenized": "In the context of machine learning, where it is more widely applied today, LDA was independently rediscovered by David Blei, Andrew Ng and Michael I. Jordan in 2003 and presented as a graphical model for topic discovery.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 25], [26, 34], [34, 35], [36, 41], [42, 44], [45, 47], [48, 52], [53, 59], [60, 67], [68, 73], [73, 74], [75, 78], [79, 82], [83, 96], [97, 109], [110, 112], [113, 118], [119, 123], [123, 124], [125, 131], [132, 134], [135, 138], [139, 146], [147, 148], [148, 149], [150, 156], [157, 159], [160, 164], [165, 168], [169, 178], [179, 181], [182, 183], [184, 193], [194, 199], [200, 203], [204, 209], [210, 219], [219, 220]]}
{"doc_key": "ai-test-363", "ner": [[5, 5, "task"], [10, 10, "misc"], [13, 13, "metrics"], [15, 15, "metrics"], [17, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 10, 10, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["Measured", "performance", "on", "eight", "naive", "WSI", "test", "data", "in", "various", "tauopathies", "resulted", "in", "recall", ",", "accuracy", "and", "F1", "scores", "of", "0.92", ",", "0.72", "and", "0.81", ",", "respectively", "."], "sentence-detokenized": "Measured performance on eight naive WSI test data in various tauopathies resulted in recall, accuracy and F1 scores of 0.92, 0.72 and 0.81, respectively.", "token2charspan": [[0, 8], [9, 20], [21, 23], [24, 29], [30, 35], [36, 39], [40, 44], [45, 49], [50, 52], [53, 60], [61, 72], [73, 81], [82, 84], [85, 91], [91, 92], [93, 101], [102, 105], [106, 108], [109, 115], [116, 118], [119, 123], [123, 124], [125, 129], [130, 133], [134, 138], [138, 139], [140, 152], [152, 153]]}
{"doc_key": "ai-test-364", "ner": [[5, 5, "field"], [10, 11, "field"], [14, 14, "field"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 14, 14, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["With", "the", "help", "of", "advanced", "AR", "technologies", "(", "e.g.", "adding", "computer", "vision", ",", "integrating", "AR", "cameras", "into", "smartphones", "and", "object", "recognition", ")", ",", "information", "about", "the", "real", "world", "around", "the", "user", "becomes", "interactive", "and", "digitally", "manipulated", "."], "sentence-detokenized": "With the help of advanced AR technologies (e.g. adding computer vision, integrating AR cameras into smartphones and object recognition), information about the real world around the user becomes interactive and digitally manipulated.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 25], [26, 28], [29, 41], [42, 43], [43, 47], [48, 54], [55, 63], [64, 70], [70, 71], [72, 83], [84, 86], [87, 94], [95, 99], [100, 111], [112, 115], [116, 122], [123, 134], [134, 135], [135, 136], [137, 148], [149, 154], [155, 158], [159, 163], [164, 169], [170, 176], [177, 180], [181, 185], [186, 193], [194, 205], [206, 209], [210, 219], [220, 231], [231, 232]]}
{"doc_key": "ai-test-365", "ner": [[3, 3, "researcher"], [9, 9, "organisation"], [17, 18, "field"], [27, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 9, 9, "role", "forms_company", false, false], [9, 9, 17, 18, "related-to", "works_with", false, false], [9, 9, 27, 29, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2014", ",", "Schmidhuber", "set", "up", "a", "company", ",", "Nnaisense", ",", "to", "deal", "with", "commercial", "applications", "of", "AI", "in", "areas", "such", "as", "finance", ",", "heavy", "industry", "and", "self", "-", "driving", "cars", "."], "sentence-detokenized": "In 2014, Schmidhuber set up a company, Nnaisense, to deal with commercial applications of AI in areas such as finance, heavy industry and self-driving cars.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 24], [25, 27], [28, 29], [30, 37], [37, 38], [39, 48], [48, 49], [50, 52], [53, 57], [58, 62], [63, 73], [74, 86], [87, 89], [90, 92], [93, 95], [96, 101], [102, 106], [107, 109], [110, 117], [117, 118], [119, 124], [125, 133], [134, 137], [138, 142], [142, 143], [143, 150], [151, 155], [155, 156]]}
{"doc_key": "ai-test-366", "ner": [[23, 25, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "not", "only", "alters", "the", "performance", "of", "all", "subsequent", "tests", "on", "the", "retained", "explanatory", "model", ",", "but", "can", "introduce", "bias", "and", "alter", "the", "mean", "squared", "error", "in", "the", "estimate", "."], "sentence-detokenized": "This not only alters the performance of all subsequent tests on the retained explanatory model, but can introduce bias and alter the mean squared error in the estimate.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 20], [21, 24], [25, 36], [37, 39], [40, 43], [44, 54], [55, 60], [61, 63], [64, 67], [68, 76], [77, 88], [89, 94], [94, 95], [96, 99], [100, 103], [104, 113], [114, 118], [119, 122], [123, 128], [129, 132], [133, 137], [138, 145], [146, 151], [152, 154], [155, 158], [159, 167], [167, 168]]}
{"doc_key": "ai-test-367", "ner": [[0, 0, "misc"], [7, 7, "algorithm"], [10, 11, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 0, 0, "usage", "", false, false], [7, 7, 10, 11, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Bigrams", "are", "used", "in", "the", "most", "successful", "language", "models", "for", "speech", "recognition", "."], "sentence-detokenized": "Bigrams are used in the most successful language models for speech recognition.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 23], [24, 28], [29, 39], [40, 48], [49, 55], [56, 59], [60, 66], [67, 78], [78, 79]]}
{"doc_key": "ai-test-368", "ner": [[3, 4, "field"], [10, 12, "misc"], [18, 20, "misc"], [26, 28, "organisation"], [31, 33, "misc"], [39, 42, "organisation"], [45, 47, "misc"], [53, 57, "organisation"], [61, 63, "misc"], [69, 72, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[10, 12, 3, 4, "topic", "", false, false], [18, 20, 26, 28, "origin", "", false, false], [31, 33, 39, 42, "origin", "", false, false], [45, 47, 53, 57, "origin", "", false, false], [61, 63, 69, 72, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["His", "research", "in", "cognitive", "psychology", "has", "been", "honored", "with", "the", "Early", "Career", "Award", "(", "1984", ")", "and", "the", "Boyd", "McCandless", "Award", "(", "1986", ")", "from", "the", "American", "Psychological", "Association", ",", "the", "Troland", "Research", "Award", "(", "1993", ")", "from", "the", "National", "Academy", "of", "Sciences", ",", "the", "Henry", "Dale", "Prize", "(", "2004", ")", "from", "the", "Royal", "Foundation", "of", "Great", "Britain", ",", "and", "the", "George", "Miller", "Prize", "(", "2010", ")", "from", "the", "Society", "for", "Cognitive", "Neuroscience", "."], "sentence-detokenized": "His research in cognitive psychology has been honored with the Early Career Award (1984) and the Boyd McCandless Award (1986) from the American Psychological Association, the Troland Research Award (1993) from the National Academy of Sciences, the Henry Dale Prize (2004) from the Royal Foundation of Great Britain, and the George Miller Prize (2010) from the Society for Cognitive Neuroscience.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 25], [26, 36], [37, 40], [41, 45], [46, 53], [54, 58], [59, 62], [63, 68], [69, 75], [76, 81], [82, 83], [83, 87], [87, 88], [89, 92], [93, 96], [97, 101], [102, 112], [113, 118], [119, 120], [120, 124], [124, 125], [126, 130], [131, 134], [135, 143], [144, 157], [158, 169], [169, 170], [171, 174], [175, 182], [183, 191], [192, 197], [198, 199], [199, 203], [203, 204], [205, 209], [210, 213], [214, 222], [223, 230], [231, 233], [234, 242], [242, 243], [244, 247], [248, 253], [254, 258], [259, 264], [265, 266], [266, 270], [270, 271], [272, 276], [277, 280], [281, 286], [287, 297], [298, 300], [301, 306], [307, 314], [314, 315], [316, 319], [320, 323], [324, 330], [331, 337], [338, 343], [344, 345], [345, 349], [349, 350], [351, 355], [356, 359], [360, 367], [368, 371], [372, 381], [382, 394], [394, 395]]}
{"doc_key": "ai-test-369", "ner": [[1, 1, "misc"], [7, 7, "misc"], [10, 12, "product"], [16, 16, "researcher"], [18, 18, "researcher"], [25, 26, "researcher"], [28, 29, "researcher"], [31, 32, "task"], [34, 37, "researcher"], [39, 43, "researcher"], [44, 45, "task"], [47, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[1, 1, 7, 7, "named", "", false, false], [1, 1, 47, 47, "named", "", false, false], [7, 7, 16, 16, "origin", "", false, false], [7, 7, 18, 18, "origin", "", false, false], [7, 7, 31, 32, "related-to", "used_for", false, false], [10, 12, 7, 7, "usage", "", false, false], [10, 12, 44, 45, "named", "", false, false], [25, 26, 7, 7, "usage", "", false, false], [25, 26, 34, 37, "named", "same", false, false], [28, 29, 7, 7, "usage", "", false, false], [28, 29, 39, 43, "named", "same", false, false], [44, 45, 47, 47, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["An", "eigenface", "(", "The", "approach", "of", "using", "eigenfaces", "for", "the", "face", "recognition", "system", "was", "developed", "by", "Sirovich", "and", "Kirby", "(", "1987", ")", "and", "used", "by", "Matthew", "Turk", "and", "Alex", "Pentland", "in", "face", "classification", ".", "Turk", ",", "Matthew", "A", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "An eigenface (The approach of using eigenfaces for the face recognition system was developed by Sirovich and Kirby (1987) and used by Matthew Turk and Alex Pentland in face classification. Turk, Matthew A and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 2], [3, 12], [13, 14], [14, 17], [18, 26], [27, 29], [30, 35], [36, 46], [47, 50], [51, 54], [55, 59], [60, 71], [72, 78], [79, 82], [83, 92], [93, 95], [96, 104], [105, 108], [109, 114], [115, 116], [116, 120], [120, 121], [122, 125], [126, 130], [131, 133], [134, 141], [142, 146], [147, 150], [151, 155], [156, 164], [165, 167], [168, 172], [173, 187], [187, 188], [189, 193], [193, 194], [195, 202], [203, 204], [205, 208], [209, 217], [217, 218], [219, 223], [224, 225], [225, 226], [227, 231], [232, 243], [244, 249], [250, 260], [260, 261]]}
{"doc_key": "ai-test-370", "ner": [[5, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "lexical", "dictionary", "such", "as", "Word", "Net", "can", "then", "be", "used", "to", "understand", "the", "context", "."], "sentence-detokenized": "A lexical dictionary such as WordNet can then be used to understand the context.", "token2charspan": [[0, 1], [2, 9], [10, 20], [21, 25], [26, 28], [29, 33], [33, 36], [37, 40], [41, 45], [46, 48], [49, 53], [54, 56], [57, 67], [68, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-test-371", "ner": [[8, 8, "misc"], [15, 15, "product"]], "ner_mapping_to_source": [1, 2], "relations": [[8, 8, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Hyponymy", "is", "the", "most", "commonly", "encoded", "relationship", "between", "sets", "used", "in", "lexical", "databases", "such", "as", "WordNet", "."], "sentence-detokenized": "Hyponymy is the most commonly encoded relationship between sets used in lexical databases such as WordNet.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 20], [21, 29], [30, 37], [38, 50], [51, 58], [59, 63], [64, 68], [69, 71], [72, 79], [80, 89], [90, 94], [95, 97], [98, 105], [105, 106]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [6, 7, "programlang"], [9, 9, "programlang"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 7, "general-affiliation", "", false, false], [0, 0, 9, 9, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "offers", "open", "source", "libraries", "in", "C", "++", "and", "Java", ",", "but", "many", "customers", "rely", "on", "community", "-", "developed", "libraries", ",", "as", "the", "libraries", "include", "built", "-", "in", "capabilities", "for", "retrieving", "(", "table", "-", "type", ")", "data", "from", "DAP", "servers", "."], "sentence-detokenized": "OPeNDAP offers open source libraries in C++ and Java, but many customers rely on community-developed libraries, as the libraries include built-in capabilities for retrieving (table-type) data from DAP servers.", "token2charspan": [[0, 7], [8, 14], [15, 19], [20, 26], [27, 36], [37, 39], [40, 41], [41, 43], [44, 47], [48, 52], [52, 53], [54, 57], [58, 62], [63, 72], [73, 77], [78, 80], [81, 90], [90, 91], [91, 100], [101, 110], [110, 111], [112, 114], [115, 118], [119, 128], [129, 136], [137, 142], [142, 143], [143, 145], [146, 158], [159, 162], [163, 173], [174, 175], [175, 180], [180, 181], [181, 185], [185, 186], [187, 191], [192, 196], [197, 200], [201, 208], [208, 209]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [8, 8, "product"], [17, 17, "country"], [30, 32, "misc"], [45, 45, "organisation"], [47, 47, "product"], [51, 55, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7], "relations": [[4, 5, 17, 17, "opposite", "", false, false], [8, 8, 17, 17, "artifact", "", false, false], [30, 32, 8, 8, "part-of", "", false, false], [47, 47, 45, 45, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["On", "that", "page", ",", "Samurai", "Damashii", "overpraised", "the", "Senkousha", "as", "the", "crystallization", "of", "four", "thousand", "years", "of", "Chinese", "scientific", "knowledge", ",", "commented", "on", "its", "crude", "design", "(", "e.g.", ",", "the", "Chinese", "cannon", "in", "its", "crotch", ")", ",", "and", "placed", "it", "s", "image", "between", "images", "of", "Honda", "'s", "ASIMO", "and", "Sony", "'s", "QRIO", "SDR", "-", "3", "X", "for", "contrast", "."], "sentence-detokenized": "On that page, Samurai Damashii overpraised the Senkousha as the crystallization of four thousand years of Chinese scientific knowledge, commented on its crude design (e.g., the Chinese cannon in its crotch), and placed its image between images of Honda's ASIMO and Sony's QRIO SDR-3X for contrast.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 21], [22, 30], [31, 42], [43, 46], [47, 56], [57, 59], [60, 63], [64, 79], [80, 82], [83, 87], [88, 96], [97, 102], [103, 105], [106, 113], [114, 124], [125, 134], [134, 135], [136, 145], [146, 148], [149, 152], [153, 158], [159, 165], [166, 167], [167, 171], [171, 172], [173, 176], [177, 184], [185, 191], [192, 194], [195, 198], [199, 205], [205, 206], [206, 207], [208, 211], [212, 218], [219, 221], [221, 222], [223, 228], [229, 236], [237, 243], [244, 246], [247, 252], [252, 254], [255, 260], [261, 264], [265, 269], [269, 271], [272, 276], [277, 280], [280, 281], [281, 282], [282, 283], [284, 287], [288, 296], [296, 297]]}
{"doc_key": "ai-test-374", "ner": [[8, 9, "algorithm"], [21, 21, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 21, 21, "part-of", "includes_functionality_of", false, false], [8, 9, 23, 23, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "also", "many", "programming", "libraries", "that", "contain", "neural", "network", "functionality", "and", "can", "be", "used", "in", "custom", "implementations", "(", "such", "as", "TensorFlow", ",", "Theano", ",", "etc", "."], "sentence-detokenized": "There are also many programming libraries that contain neural network functionality and can be used in custom implementations (such as TensorFlow, Theano, etc.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 31], [32, 41], [42, 46], [47, 54], [55, 61], [62, 69], [70, 83], [84, 87], [88, 91], [92, 94], [95, 99], [100, 102], [103, 109], [110, 125], [126, 127], [127, 131], [132, 134], [135, 145], [145, 146], [147, 153], [153, 154], [155, 158], [158, 159]]}
{"doc_key": "ai-test-375", "ner": [[6, 9, "conference"], [11, 11, "organisation"], [13, 19, "conference"], [21, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", "and", "SPIE", "."], "sentence-detokenized": "He is a member of the Association for Computing Machinery, IEEE, American Association for the Advancement of Science, IAPR and SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 33], [34, 37], [38, 47], [48, 57], [57, 58], [59, 63], [63, 64], [65, 73], [74, 85], [86, 89], [90, 93], [94, 105], [106, 108], [109, 116], [116, 117], [118, 122], [123, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-376", "ner": [[1, 1, "organisation"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 6, 7, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "RET", "trial", "in", "2011", "with", "facial", "recognition", "cameras", "mounted", "on", "trams", "ensured", "that", "people", "who", "were", "banned", "from", "entering", "the", "city", "'s", "trams", "were", "not", "sneaking", "in", "anyway", "."], "sentence-detokenized": "An RET trial in 2011 with facial recognition cameras mounted on trams ensured that people who were banned from entering the city's trams were not sneaking in anyway.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 20], [21, 25], [26, 32], [33, 44], [45, 52], [53, 60], [61, 63], [64, 69], [70, 77], [78, 82], [83, 89], [90, 93], [94, 98], [99, 105], [106, 110], [111, 119], [120, 123], [124, 128], [128, 130], [131, 136], [137, 141], [142, 145], [146, 154], [155, 157], [158, 164], [164, 165]]}
{"doc_key": "ai-test-377", "ner": [[7, 8, "person"], [11, 11, "organisation"], [20, 21, "person"], [23, 24, "person"], [27, 28, "person"], [30, 31, "person"], [33, 34, "person"], [36, 37, "person"], [39, 40, "person"], [42, 43, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 8, 11, 11, "role", "works_for", false, false], [20, 21, 11, 11, "role", "works_for", false, false], [23, 24, 11, 11, "role", "works_for", false, false], [27, 28, 11, 11, "role", "works_for", false, false], [30, 31, 11, 11, "role", "works_for", false, false], [33, 34, 11, 11, "role", "works_for", false, false], [36, 37, 11, 11, "role", "works_for", false, false], [39, 40, 11, 11, "role", "works_for", false, false], [42, 43, 11, 11, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "film", ",", "which", "was", "adapted", "from", "Cole", "Porter", "'s", "popular", "Broadway", "musical", ",", "starred", "the", "MGM", "singing", "team", "of", "Howard", "Keel", "and", "Kathryn", "Grayson", ",", "with", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "and", "Tommy", "Rall", "."], "sentence-detokenized": "The film, which was adapted from Cole Porter's popular Broadway musical, starred the MGM singing team of Howard Keel and Kathryn Grayson, with Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar and Tommy Rall.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 15], [16, 19], [20, 27], [28, 32], [33, 37], [38, 44], [44, 46], [47, 54], [55, 63], [64, 71], [71, 72], [73, 80], [81, 84], [85, 88], [89, 96], [97, 101], [102, 104], [105, 111], [112, 116], [117, 120], [121, 128], [129, 136], [136, 137], [138, 142], [143, 146], [147, 153], [153, 154], [155, 161], [162, 166], [166, 167], [168, 173], [174, 177], [177, 178], [179, 184], [185, 193], [193, 194], [195, 199], [200, 207], [208, 211], [212, 217], [218, 222], [222, 223]]}
{"doc_key": "ai-test-378", "ner": [[21, 25, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "applications", "should", "streamline", "call", "flows", ",", "minimize", "prompts", ",", "eliminate", "unnecessary", "repetition", ",", "and", "allow", "for", "the", "development", "of", "a", "mixed", "-initiative", "dialogue", "system", "that", "allows", "callers", "to", "enter", "various", "information", "in", "a", "single", "expression", "and", "in", "any", "order", "or", "combination", "."], "sentence-detokenized": "These applications should streamline call flows, minimize prompts, eliminate unnecessary repetition, and allow for the development of a mixed-initiative dialogue system that allows callers to enter various information in a single expression and in any order or combination.", "token2charspan": [[0, 5], [6, 18], [19, 25], [26, 36], [37, 41], [42, 47], [47, 48], [49, 57], [58, 65], [65, 66], [67, 76], [77, 88], [89, 99], [99, 100], [101, 104], [105, 110], [111, 114], [115, 118], [119, 130], [131, 133], [134, 135], [136, 141], [141, 152], [153, 161], [162, 168], [169, 173], [174, 180], [181, 188], [189, 191], [192, 197], [198, 205], [206, 217], [218, 220], [221, 222], [223, 229], [230, 240], [241, 244], [245, 247], [248, 251], [252, 257], [258, 260], [261, 272], [272, 273]]}
{"doc_key": "ai-test-379", "ner": [[3, 4, "algorithm"], [7, 9, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 3, 4, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Therefore", ",", "traditional", "gradient", "descent", "(", "or", "stochastic", "gradient", "descent", ")", "methods", "can", "be", "adapted", ",", "where", "instead", "of", "taking", "a", "step", "in", "the", "direction", "of", "the", "gradient", "of", "the", "function", ",", "a", "step", "is", "taken", "in", "the", "direction", "of", "a", "vector", "chosen", "from", "the", "sub-gradient", "of", "the", "function", "."], "sentence-detokenized": "Therefore, traditional gradient descent (or stochastic gradient descent) methods can be adapted, where instead of taking a step in the direction of the gradient of the function, a step is taken in the direction of a vector chosen from the sub-gradient of the function.", "token2charspan": [[0, 9], [9, 10], [11, 22], [23, 31], [32, 39], [40, 41], [41, 43], [44, 54], [55, 63], [64, 71], [71, 72], [73, 80], [81, 84], [85, 87], [88, 95], [95, 96], [97, 102], [103, 110], [111, 113], [114, 120], [121, 122], [123, 127], [128, 130], [131, 134], [135, 144], [145, 147], [148, 151], [152, 160], [161, 163], [164, 167], [168, 176], [176, 177], [178, 179], [180, 184], [185, 187], [188, 193], [194, 196], [197, 200], [201, 210], [211, 213], [214, 215], [216, 222], [223, 229], [230, 234], [235, 238], [239, 251], [252, 254], [255, 258], [259, 267], [267, 268]]}
{"doc_key": "ai-test-380", "ner": [[9, 11, "metrics"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Assuming", "that", "the", "deformation", "is", "measured", "by", "the", "root", "mean", "square", "error", ",", "the", "deformation", "D", ",", "is", "given", "by", ":"], "sentence-detokenized": "Assuming that the deformation is measured by the root mean square error, the deformation D, is given by:", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 29], [30, 32], [33, 41], [42, 44], [45, 48], [49, 53], [54, 58], [59, 65], [66, 71], [71, 72], [73, 76], [77, 88], [89, 90], [90, 91], [92, 94], [95, 100], [101, 103], [103, 104]]}
{"doc_key": "ai-test-381", "ner": [[0, 0, "algorithm"], [4, 5, "field"], [18, 19, "task"], [21, 22, "task"], [24, 25, "task"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 5, "part-of", "", false, false], [18, 19, 0, 0, "part-of", "", false, false], [21, 22, 0, 0, "part-of", "", false, false], [24, 25, 0, 0, "part-of", "", false, false], [28, 29, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["MLPs", "were", "a", "popular", "machine", "learning", "solution", "in", "the", "1980s", ",", "finding", "applications", "in", "various", "fields", "such", "as", "speech", "recognition", ",", "image", "recognition", "and", "machine", "translation", "software", ",", "neural", "networks", "."], "sentence-detokenized": "MLPs were a popular machine learning solution in the 1980s, finding applications in various fields such as speech recognition, image recognition and machine translation software, neural networks.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 19], [20, 27], [28, 36], [37, 45], [46, 48], [49, 52], [53, 58], [58, 59], [60, 67], [68, 80], [81, 83], [84, 91], [92, 98], [99, 103], [104, 106], [107, 113], [114, 125], [125, 126], [127, 132], [133, 144], [145, 148], [149, 156], [157, 168], [169, 177], [177, 178], [179, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [3, 3, "misc"], [6, 9, "university"], [16, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 9, "physical", "", false, false], [0, 0, 6, 9, "role", "", false, false], [3, 3, 0, 0, "origin", "", false, false], [16, 18, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "received", "his", "PhD", "from", "the", "University", "of", "Toronto", "in", "1979", ",", "under", "the", "supervision", "of", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen received his PhD from the University of Toronto in 1979, under the supervision of C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 22], [23, 27], [28, 31], [32, 42], [43, 45], [46, 53], [54, 56], [57, 61], [61, 62], [63, 68], [69, 72], [73, 84], [85, 87], [88, 90], [91, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [5, 7, "field"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [19, 19, "product"], [23, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 7, "related-to", "supports", false, false], [10, 10, 5, 7, "type-of", "", true, false], [12, 12, 5, 7, "type-of", "", true, false], [14, 14, 5, 7, "type-of", "", true, false], [14, 14, 19, 19, "related-to", "converting_to", true, false], [23, 25, 5, 7, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["OpenCV", "supports", "certain", "models", "from", "deep", "learning", "frameworks", "such", "as", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "after", "conversion", "to", "ONNX", "model", ")", "and", "Caffe", "according", "to", "a", "defined", "list", "of", "supported", "levels", "."], "sentence-detokenized": "OpenCV supports certain models from deep learning frameworks such as TensorFlow, Torch, PyTorch (after conversion to ONNX model) and Caffe according to a defined list of supported levels.", "token2charspan": [[0, 6], [7, 15], [16, 23], [24, 30], [31, 35], [36, 40], [41, 49], [50, 60], [61, 65], [66, 68], [69, 79], [79, 80], [81, 86], [86, 87], [88, 95], [96, 97], [97, 102], [103, 113], [114, 116], [117, 121], [122, 127], [127, 128], [129, 132], [133, 138], [139, 148], [149, 151], [152, 153], [154, 161], [162, 166], [167, 169], [170, 179], [180, 186], [186, 187]]}
{"doc_key": "ai-test-384", "ner": [[2, 2, "researcher"], [11, 12, "organisation"], [9, 14, "organisation"], [24, 28, "organisation"], [20, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 11, 12, "role", "", false, false], [2, 2, 24, 28, "role", "", false, false], [2, 2, 20, 23, "related-to", "lectures_in", false, false], [9, 14, 11, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Previously", ",", "Christensen", "was", "the", "founding", "president", "of", "the", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "and", "a", "distinguished", "lecturer", "in", "robotics", "at", "the", "IEEE", "Robotics", "and", "Automation", "Society", "."], "sentence-detokenized": "Previously, Christensen was the founding president of the European Robotics Research Network (EURON) and a distinguished lecturer in robotics at the IEEE Robotics and Automation Society.", "token2charspan": [[0, 10], [10, 11], [12, 23], [24, 27], [28, 31], [32, 40], [41, 50], [51, 53], [54, 57], [58, 66], [67, 75], [76, 84], [85, 92], [93, 94], [94, 99], [99, 100], [101, 104], [105, 106], [107, 120], [121, 129], [130, 132], [133, 141], [142, 144], [145, 148], [149, 153], [154, 162], [163, 166], [167, 177], [178, 185], [185, 186]]}
{"doc_key": "ai-test-385", "ner": [[7, 7, "field"], [9, 11, "university"], [13, 13, "location"], [15, 19, "country"], [24, 24, "misc"], [26, 26, "field"], [30, 34, "organisation"], [29, 29, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 11, 13, 13, "physical", "", false, false], [13, 13, 15, 19, "physical", "", false, false], [24, 24, 26, 26, "topic", "", false, false], [30, 34, 29, 29, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "received", "his", "master", "'s", "degree", "in", "mathematics", "from", "Samarkand", "State", "University", ",", "Samarkand", ",", "Soviet", "Socialist", "Republic", "of", "Uzbekistan", "in", "1958", "and", "his", "doctorate", "in", "statistics", "at", "the", "Moscow", "Institute", "of", "Control", "Sciences", "in", "1964", "."], "sentence-detokenized": "He received his master's degree in mathematics from Samarkand State University, Samarkand, Soviet Socialist Republic of Uzbekistan in 1958 and his doctorate in statistics at the Moscow Institute of Control Sciences in 1964.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 22], [22, 24], [25, 31], [32, 34], [35, 46], [47, 51], [52, 61], [62, 67], [68, 78], [78, 79], [80, 89], [89, 90], [91, 97], [98, 107], [108, 116], [117, 119], [120, 130], [131, 133], [134, 138], [139, 142], [143, 146], [147, 156], [157, 159], [160, 170], [171, 173], [174, 177], [178, 184], [185, 194], [195, 197], [198, 205], [206, 214], [215, 217], [218, 222], [222, 223]]}
{"doc_key": "ai-test-386", "ner": [[6, 6, "organisation"], [10, 11, "product"], [33, 34, "field"], [36, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 33, 34, "usage", "", false, false], [6, 6, 36, 38, "usage", "", false, false], [10, 11, 6, 6, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Increasingly", ",", "however", ",", "work", "at", "Cycorp", "involves", "providing", "the", "Cyc", "system", "with", "the", "ability", "to", "communicate", "with", "end-users", "in", "natural", "language", "and", "to", "assist", "in", "the", "ongoing", "process", "of", "knowledge", "formation", "through", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "Increasingly, however, work at Cycorp involves providing the Cyc system with the ability to communicate with end-users in natural language and to assist in the ongoing process of knowledge formation through machine learning and natural language understanding.", "token2charspan": [[0, 12], [12, 13], [14, 21], [21, 22], [23, 27], [28, 30], [31, 37], [38, 46], [47, 56], [57, 60], [61, 64], [65, 71], [72, 76], [77, 80], [81, 88], [89, 91], [92, 103], [104, 108], [109, 118], [119, 121], [122, 129], [130, 138], [139, 142], [143, 145], [146, 152], [153, 155], [156, 159], [160, 167], [168, 175], [176, 178], [179, 188], [189, 198], [199, 206], [207, 214], [215, 223], [224, 227], [228, 235], [236, 244], [245, 258], [258, 259]]}
{"doc_key": "ai-test-387", "ner": [[54, 54, "metrics"], [56, 56, "metrics"], [58, 58, "metrics"], [60, 63, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "if", "the", "most", "suitable", "classifier", "for", "the", "problem", "is", "sought", ",", "the", "training", "dataset", "is", "used", "to", "train", "the", "candidate", "algorithms", ",", "the", "validation", "dataset", "is", "used", "to", "compare", "their", "performance", "and", "decide", "which", "one", "to", "choose", ",", "and", "finally", "the", "testing", "dataset", "is", "used", "to", "obtain", "performance", "characteristics", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", ",", "F-", "measure", ",", "and", "so", "on", "."], "sentence-detokenized": "For example, if the most suitable classifier for the problem is sought, the training dataset is used to train the candidate algorithms, the validation dataset is used to compare their performance and decide which one to choose, and finally the testing dataset is used to obtain performance characteristics such as accuracy, sensitivity, specificity, F-measure, and so on.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 19], [20, 24], [25, 33], [34, 44], [45, 48], [49, 52], [53, 60], [61, 63], [64, 70], [70, 71], [72, 75], [76, 84], [85, 92], [93, 95], [96, 100], [101, 103], [104, 109], [110, 113], [114, 123], [124, 134], [134, 135], [136, 139], [140, 150], [151, 158], [159, 161], [162, 166], [167, 169], [170, 177], [178, 183], [184, 195], [196, 199], [200, 206], [207, 212], [213, 216], [217, 219], [220, 226], [226, 227], [228, 231], [232, 239], [240, 243], [244, 251], [252, 259], [260, 262], [263, 267], [268, 270], [271, 277], [278, 289], [290, 305], [306, 310], [311, 313], [314, 322], [322, 323], [324, 335], [335, 336], [337, 348], [348, 349], [350, 352], [352, 359], [359, 360], [361, 364], [365, 367], [368, 370], [370, 371]]}
{"doc_key": "ai-test-388", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "square", "error", "is", "0.15", "."], "sentence-detokenized": "The mean square error is 0.15.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 21], [22, 24], [25, 29], [29, 30]]}
{"doc_key": "ai-test-389", "ner": [[3, 4, "misc"], [9, 9, "organisation"], [14, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 3, 4, "role", "", false, false], [14, 14, 3, 4, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1979", "a", "Micromouse", "competition", "was", "organized", "by", "the", "IEEE", ",", "as", "featured", "in", "Spectrum", "magazine", "."], "sentence-detokenized": "In 1979 a Micromouse competition was organized by the IEEE, as featured in Spectrum magazine.", "token2charspan": [[0, 2], [3, 7], [8, 9], [10, 20], [21, 32], [33, 36], [37, 46], [47, 49], [50, 53], [54, 58], [58, 59], [60, 62], [63, 71], [72, 74], [75, 83], [84, 92], [92, 93]]}
{"doc_key": "ai-test-390", "ner": [[0, 2, "algorithm"], [7, 8, "field"], [12, 14, "task"], [16, 17, "task"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 7, 8, "part-of", "", false, false], [12, 14, 7, 8, "part-of", "task_part_of_field", false, false], [16, 17, 7, 8, "part-of", "task_part_of_field", false, false], [19, 20, 7, 8, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Gabor", "space", "is", "very", "useful", "in", "image", "processing", "applications", "such", "as", "visual", "character", "recognition", ",", "iris", "recognition", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "The Gabor space is very useful in image processing applications such as visual character recognition, iris recognition and fingerprint recognition.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 18], [19, 23], [24, 30], [31, 33], [34, 39], [40, 50], [51, 63], [64, 68], [69, 71], [72, 78], [79, 88], [89, 100], [100, 101], [102, 106], [107, 118], [119, 122], [123, 134], [135, 146], [146, 147]]}
{"doc_key": "ai-test-391", "ner": [[7, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "through", "high", "-", "level", "interfaces", "with", "Java", "and", "Tcl", "."], "sentence-detokenized": "or through high-level interfaces with Java and Tcl.", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [16, 21], [22, 32], [33, 37], [38, 42], [43, 46], [47, 50], [50, 51]]}
{"doc_key": "ai-test-392", "ner": [[11, 13, "algorithm"], [20, 21, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 13, 20, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "recent", "research", ",", "kernel", "-", "based", "methods", ",", "such", "as", "support", "vector", "machines", ",", "have", "shown", "superior", "performance", "to", "supervised", "methods", "."], "sentence-detokenized": "In recent research, kernel-based methods, such as support vector machines, have shown superior performance to supervised methods.", "token2charspan": [[0, 2], [3, 9], [10, 18], [18, 19], [20, 26], [26, 27], [27, 32], [33, 40], [40, 41], [42, 46], [47, 49], [50, 57], [58, 64], [65, 73], [73, 74], [75, 79], [80, 85], [86, 94], [95, 106], [107, 109], [110, 120], [121, 128], [128, 129]]}
{"doc_key": "ai-test-393", "ner": [[14, 14, "misc"], [21, 21, "researcher"], [23, 23, "researcher"], [31, 31, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 31, 31, "usage", "", false, false], [23, 23, 31, 31, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "illustrate", "the", "basic", "principles", "of", "bagging", ",", "an", "analysis", "of", "the", "relationship", "between", "ozone", "and", "temperature", "follows", "(", "data", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "analysis", "done", "in", "R", ")", "."], "sentence-detokenized": "To illustrate the basic principles of bagging, an analysis of the relationship between ozone and temperature follows (data from Rousseeuw and Leroy (1986), analysis done in R).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 34], [35, 37], [38, 45], [45, 46], [47, 49], [50, 58], [59, 61], [62, 65], [66, 78], [79, 86], [87, 92], [93, 96], [97, 108], [109, 116], [117, 118], [118, 122], [123, 127], [128, 137], [138, 141], [142, 147], [148, 149], [149, 153], [153, 154], [154, 155], [156, 164], [165, 169], [170, 172], [173, 174], [174, 175], [175, 176]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [11, 11, "product"], [18, 19, "product"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 0, 1, "artifact", "", false, false], [18, 19, 0, 1, "artifact", "", false, false], [21, 23, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Denso", "Wave", "is", "a", "subsidiary", "that", "produces", "automatic", "recognition", "products", "(", "barcode", "readers", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "Denso Wave is a subsidiary that produces automatic recognition products (barcode readers and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 15], [16, 26], [27, 31], [32, 40], [41, 50], [51, 62], [63, 71], [72, 73], [73, 80], [81, 88], [89, 92], [93, 100], [101, 109], [109, 110], [110, 111], [112, 122], [123, 129], [130, 133], [134, 146], [147, 152], [153, 164], [164, 165]]}
{"doc_key": "ai-test-395", "ner": [[1, 4, "metrics"], [8, 9, "metrics"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 4, 21, 21, "compare", "", false, false], [8, 9, 1, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Where", "the", "Bilingual", "evaluation", "understudy", "simply", "calculates", "the", "accuracy", "of", "n", "-", "grams", "by", "adding", "equal", "weight", "to", "each", "one", ",", "NIST", "also", "calculates", "how", "informative", "a", "particular", "n-", "gram", "is", "."], "sentence-detokenized": "Where the Bilingual evaluation understudy simply calculates the accuracy of n-grams by adding equal weight to each one, NIST also calculates how informative a particular n-gram is.", "token2charspan": [[0, 5], [6, 9], [10, 19], [20, 30], [31, 41], [42, 48], [49, 59], [60, 63], [64, 72], [73, 75], [76, 77], [77, 78], [78, 83], [84, 86], [87, 93], [94, 99], [100, 106], [107, 109], [110, 114], [115, 118], [118, 119], [120, 124], [125, 129], [130, 140], [141, 144], [145, 156], [157, 158], [159, 169], [170, 172], [172, 176], [177, 179], [179, 180]]}
{"doc_key": "ai-test-396", "ner": [[15, 15, "algorithm"], [17, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "particular", ",", "they", "are", "used", "when", "calculating", "the", "likelihood", "of", "a", "tree", "(", "in", "Bayesian", "and", "maximum", "likelihood", "approaches", "to", "tree", "estimation", ")", "and", "are", "used", "to", "estimate", "the", "evolutionary", "distance", "between", "sequences", "from", "the", "observed", "differences", "between", "sequences", "."], "sentence-detokenized": "In particular, they are used when calculating the likelihood of a tree (in Bayesian and maximum likelihood approaches to tree estimation) and are used to estimate the evolutionary distance between sequences from the observed differences between sequences.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 19], [20, 23], [24, 28], [29, 33], [34, 45], [46, 49], [50, 60], [61, 63], [64, 65], [66, 70], [71, 72], [72, 74], [75, 83], [84, 87], [88, 95], [96, 106], [107, 117], [118, 120], [121, 125], [126, 136], [136, 137], [138, 141], [142, 145], [146, 150], [151, 153], [154, 162], [163, 166], [167, 179], [180, 188], [189, 196], [197, 206], [207, 211], [212, 215], [216, 224], [225, 236], [237, 244], [245, 254], [254, 255]]}
{"doc_key": "ai-test-397", "ner": [[1, 3, "conference"], [20, 21, "misc"], [23, 23, "misc"], [46, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Audio", "Engineering", "Society", "recommends", "a", "sampling", "rate", "of", "48", "kHz", "for", "most", "applications", ",", "but", "recognizes", "44.1", "kHz", "for", "Compact", "Disc", "(", "CD", ")", "and", "other", "consumer", "uses", ",", "32", "kHz", "for", "broadcast", "-", "related", "applications", ",", "and", "96", "kHz", "for", "higher", "bandwidth", "or", "loose", "anti-aliasing", "filter", "ing", "."], "sentence-detokenized": "The Audio Engineering Society recommends a sampling rate of 48 kHz for most applications, but recognizes 44.1 kHz for Compact Disc (CD) and other consumer uses, 32 kHz for broadcast-related applications, and 96 kHz for higher bandwidth or loose anti-aliasing filter ing.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 40], [41, 42], [43, 51], [52, 56], [57, 59], [60, 62], [63, 66], [67, 70], [71, 75], [76, 88], [88, 89], [90, 93], [94, 104], [105, 109], [110, 113], [114, 117], [118, 125], [126, 130], [131, 132], [132, 134], [134, 135], [136, 139], [140, 145], [146, 154], [155, 159], [159, 160], [161, 163], [164, 167], [168, 171], [172, 181], [181, 182], [182, 189], [190, 202], [202, 203], [204, 207], [208, 210], [211, 214], [215, 218], [219, 225], [226, 235], [236, 238], [239, 244], [245, 258], [259, 265], [266, 269], [269, 270]]}
{"doc_key": "ai-test-398", "ner": [[12, 12, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Resources", "for", "the", "synaesthesia", "of", "words", "and", "concepts", "have", "been", "created", "for", "WordNet", "{", "{", "cite", "journal"], "sentence-detokenized": "Resources for the synaesthesia of words and concepts have been created for WordNet {{cite journal", "token2charspan": [[0, 9], [10, 13], [14, 17], [18, 30], [31, 33], [34, 39], [40, 43], [44, 52], [53, 57], [58, 62], [63, 70], [71, 74], [75, 82], [83, 84], [84, 85], [85, 89], [90, 97]]}
{"doc_key": "ai-test-399", "ner": [[2, 5, "misc"], [23, 24, "person"], [29, 32, "person"], [37, 39, "person"], [45, 48, "organisation"], [67, 68, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[29, 32, 37, 39, "role", "acts_in", false, false], [45, 48, 37, 39, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "a", "red", "and", "green", "light", ",", "the", "audience", "saw", "three", "reels", "of", "test", "reels", ",", "including", "rural", "scenes", ",", "test", "footage", "of", "Marie", "Doro", ",", "a", "segment", "of", "John", "B", ".", "Mason", "playing", "some", "clips", "from", "Jim", "the", "Penman", "(", "a", "film", "released", "by", "Famous", "Players", "-", "Lasky", "that", "year", ",", "but", "not", "in", "3D", ")", ",", "oriental", "dancers", ",", "and", "a", "reel", "of", "footage", "of", "Niagara", "Falls", "."], "sentence-detokenized": "In a red and green light, the audience saw three reels of test reels, including rural scenes, test footage of Marie Doro, a segment of John B. Mason playing some clips from Jim the Penman (a film released by Famous Players-Lasky that year, but not in 3D), oriental dancers, and a reel of footage of Niagara Falls.", "token2charspan": [[0, 2], [3, 4], [5, 8], [9, 12], [13, 18], [19, 24], [24, 25], [26, 29], [30, 38], [39, 42], [43, 48], [49, 54], [55, 57], [58, 62], [63, 68], [68, 69], [70, 79], [80, 85], [86, 92], [92, 93], [94, 98], [99, 106], [107, 109], [110, 115], [116, 120], [120, 121], [122, 123], [124, 131], [132, 134], [135, 139], [140, 141], [141, 142], [143, 148], [149, 156], [157, 161], [162, 167], [168, 172], [173, 176], [177, 180], [181, 187], [188, 189], [189, 190], [191, 195], [196, 204], [205, 207], [208, 214], [215, 222], [222, 223], [223, 228], [229, 233], [234, 238], [238, 239], [240, 243], [244, 247], [248, 250], [251, 253], [253, 254], [254, 255], [256, 264], [265, 272], [272, 273], [274, 277], [278, 279], [280, 284], [285, 287], [288, 295], [296, 298], [299, 306], [307, 312], [312, 313]]}
{"doc_key": "ai-test-400", "ner": [[7, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "particular", "way", "of", "applying", "maximum", "likelihood", "estimation", "to", "this", "problem", "."], "sentence-detokenized": "This is a particular way of applying maximum likelihood estimation to this problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 20], [21, 24], [25, 27], [28, 36], [37, 44], [45, 55], [56, 66], [67, 69], [70, 74], [75, 82], [82, 83]]}
{"doc_key": "ai-test-401", "ner": [[0, 4, "product"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Crawler", "-", "friendly", "Web", "Servers", ",", "and", "integrates", "the", "features", "of", "sitemaps", "and", "RSS", "feeds", "into", "a", "decentralized", "mechanism", "for", "computational", "biologists", "and", "bioinformaticians", "to", "openly", "transmit", "and", "retrieve", "metadata", "about", "biomedical", "resources", "."], "sentence-detokenized": "Crawler-friendly Web Servers, and integrates the features of sitemaps and RSS feeds into a decentralized mechanism for computational biologists and bioinformaticians to openly transmit and retrieve metadata about biomedical resources.", "token2charspan": [[0, 7], [7, 8], [8, 16], [17, 20], [21, 28], [28, 29], [30, 33], [34, 44], [45, 48], [49, 57], [58, 60], [61, 69], [70, 73], [74, 77], [78, 83], [84, 88], [89, 90], [91, 104], [105, 114], [115, 118], [119, 132], [133, 143], [144, 147], [148, 165], [166, 168], [169, 175], [176, 184], [185, 188], [189, 197], [198, 206], [207, 212], [213, 223], [224, 233], [233, 234]]}
{"doc_key": "ai-test-402", "ner": [[5, 12, "misc"], [15, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "covered", "by", "the", "American", "National", "Standards", "Institute", "/", "NISO", "standard", "Z39.50", "and", "the", "International", "Organization", "for", "Standardization", "standard", "23950", "."], "sentence-detokenized": "It is covered by the American National Standards Institute/NISO standard Z39.50 and the International Organization for Standardization standard 23950.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 20], [21, 29], [30, 38], [39, 48], [49, 58], [58, 59], [59, 63], [64, 72], [73, 79], [80, 83], [84, 87], [88, 101], [102, 114], [115, 118], [119, 134], [135, 143], [144, 149], [149, 150]]}
{"doc_key": "ai-test-403", "ner": [[13, 17, "misc"], [23, 23, "metrics"], [26, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "encoder", "and", "decoder", "are", "trained", "to", "receive", "a", "phrase", "and", "reproduce", "the", "distribution", "of", "a", "snapshot", "of", "a", "corresponding", "paraphrase", "by", "minimizing", "complexity", "using", "simple", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The encoder and decoder are trained to receive a phrase and reproduce the distribution of a snapshot of a corresponding paraphrase by minimizing complexity using simple stochastic gradient descent.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 46], [47, 48], [49, 55], [56, 59], [60, 69], [70, 73], [74, 86], [87, 89], [90, 91], [92, 100], [101, 103], [104, 105], [106, 119], [120, 130], [131, 133], [134, 144], [145, 155], [156, 161], [162, 168], [169, 179], [180, 188], [189, 196], [196, 197]]}
{"doc_key": "ai-test-404", "ner": [[4, 5, "field"], [8, 10, "task"], [12, 16, "task"], [26, 30, "task"], [32, 38, "task"], [40, 45, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 10, 4, 5, "part-of", "task_part_of_field", false, false], [12, 16, 4, 5, "part-of", "task_part_of_field", false, false], [26, 30, 4, 5, "part-of", "task_part_of_field", false, false], [32, 38, 4, 5, "part-of", "task_part_of_field", false, false], [40, 45, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "typical", "applications", "of", "pattern", "recognition", "techniques", "are", "automatic", "speech", "recognition", ",", "text", "classification", "into", "different", "categories", "(", "e.g.", "spam", "/", "not", "spam", "emails", ")", ",", "handwriting", "recognition", "in", "postal", "envelopes", ",", "automatic", "recognition", "of", "images", "of", "human", "faces", "or", "extraction", "of", "handwriting", "from", "medical", "forms", "."], "sentence-detokenized": "Other typical applications of pattern recognition techniques are automatic speech recognition, text classification into different categories (e.g. spam/not spam emails), handwriting recognition in postal envelopes, automatic recognition of images of human faces or extraction of handwriting from medical forms.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 29], [30, 37], [38, 49], [50, 60], [61, 64], [65, 74], [75, 81], [82, 93], [93, 94], [95, 99], [100, 114], [115, 119], [120, 129], [130, 140], [141, 142], [142, 146], [147, 151], [151, 152], [152, 155], [156, 160], [161, 167], [167, 168], [168, 169], [170, 181], [182, 193], [194, 196], [197, 203], [204, 213], [213, 214], [215, 224], [225, 236], [237, 239], [240, 246], [247, 249], [250, 255], [256, 261], [262, 264], [265, 275], [276, 278], [279, 290], [291, 295], [296, 303], [304, 309], [309, 310]]}
{"doc_key": "ai-test-405", "ner": [[0, 2, "algorithm"], [14, 15, "field"], [17, 18, "task"], [20, 21, "task"], [23, 25, "task"], [27, 31, "task"], [34, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 15, 0, 2, "usage", "", false, false], [17, 18, 0, 2, "usage", "", false, false], [20, 21, 0, 2, "usage", "", false, false], [23, 25, 0, 2, "usage", "", false, false], [27, 31, 0, 2, "usage", "", false, false], [34, 35, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Artificial", "neural", "networks", "have", "been", "used", "in", "a", "variety", "of", "tasks", ",", "such", "as", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "desktop", "and", "video", "game", "playback", ",", "and", "medical", "diagnostics", "."], "sentence-detokenized": "Artificial neural networks have been used in a variety of tasks, such as computer vision, speech recognition, machine translation, social network filtering, desktop and video game playback, and medical diagnostics.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 36], [37, 41], [42, 44], [45, 46], [47, 54], [55, 57], [58, 63], [63, 64], [65, 69], [70, 72], [73, 81], [82, 88], [88, 89], [90, 96], [97, 108], [108, 109], [110, 117], [118, 129], [129, 130], [131, 137], [138, 145], [146, 155], [155, 156], [157, 164], [165, 168], [169, 174], [175, 179], [180, 188], [188, 189], [190, 193], [194, 201], [202, 213], [213, 214]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [16, 16, "product"], [19, 19, "organisation"], [20, 21, "product"], [23, 23, "product"], [25, 27, "product"], [29, 29, "product"], [31, 31, "programlang"], [39, 40, "field"], [47, 47, "product"], [52, 52, "algorithm"], [54, 54, "algorithm"], [56, 56, "algorithm"], [60, 60, "product"], [68, 69, "task"], [74, 75, "algorithm"], [79, 79, "product"], [81, 81, "product"], [84, 86, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [4, 4, 16, 16, "named", "same", false, false], [4, 4, 47, 47, "named", "same", false, false], [31, 31, 39, 40, "related-to", "used_for", false, false], [52, 52, 31, 31, "part-of", "", true, false], [52, 52, 47, 47, "origin", "", true, false], [54, 54, 31, 31, "part-of", "", true, false], [54, 54, 47, 47, "origin", "", true, false], [56, 56, 31, 31, "part-of", "", true, false], [56, 56, 47, 47, "origin", "", true, false], [60, 60, 68, 69, "related-to", "used_for", false, false], [74, 75, 60, 60, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Examples", "include", "Salford", "Systems", "CART", "(", "which", "licensed", "the", "proprietary", "code", "of", "the", "original", "authors", "of", "CART", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "source", "software", "environment", "for", "statistical", "computing", ",", "which", "includes", "several", "implementations", "of", "CART", ",", "such", "as", "the", "rpart", ",", "party", "and", "randomForest", "packages", ")", ",", "Weka", "(", "a", "free", "and", "open", "-", "source", "data", "mining", "suite", ",", "containing", "many", "decision", "tree", "algorithms", ")", ",", "Orange", ",", "KNIME", ",", "the", "Microsoft", "SQL", "Server", "programming", "language", ")", "."], "sentence-detokenized": "Examples include Salford Systems CART (which licensed the proprietary code of the original authors of CART), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open source software environment for statistical computing, which includes several implementations of CART, such as the rpart, party and randomForest packages), Weka (a free and open-source data mining suite, containing many decision tree algorithms), Orange, KNIME, the Microsoft SQL Server programming language).", "token2charspan": [[0, 8], [9, 16], [17, 24], [25, 32], [33, 37], [38, 39], [39, 44], [45, 53], [54, 57], [58, 69], [70, 74], [75, 77], [78, 81], [82, 90], [91, 98], [99, 101], [102, 106], [106, 107], [107, 108], [109, 112], [113, 117], [118, 125], [125, 126], [127, 137], [137, 138], [139, 142], [143, 153], [154, 159], [159, 160], [161, 167], [167, 168], [169, 170], [171, 172], [172, 174], [175, 179], [180, 186], [187, 195], [196, 207], [208, 211], [212, 223], [224, 233], [233, 234], [235, 240], [241, 249], [250, 257], [258, 273], [274, 276], [277, 281], [281, 282], [283, 287], [288, 290], [291, 294], [295, 300], [300, 301], [302, 307], [308, 311], [312, 324], [325, 333], [333, 334], [334, 335], [336, 340], [341, 342], [342, 343], [344, 348], [349, 352], [353, 357], [357, 358], [358, 364], [365, 369], [370, 376], [377, 382], [382, 383], [384, 394], [395, 399], [400, 408], [409, 413], [414, 424], [424, 425], [425, 426], [427, 433], [433, 434], [435, 440], [440, 441], [442, 445], [446, 455], [456, 459], [460, 466], [467, 478], [479, 487], [487, 488], [488, 489]]}
{"doc_key": "ai-test-407", "ner": [[1, 2, "algorithm"], [0, 4, "algorithm"], [10, 11, "researcher"], [13, 14, "university"], [16, 17, "researcher"], [19, 22, "organisation"], [24, 24, "organisation"], [33, 35, "researcher"], [37, 39, "researcher"], [41, 44, "organisation"], [55, 58, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[1, 2, 10, 11, "origin", "", false, false], [1, 2, 16, 17, "origin", "", false, false], [1, 2, 33, 35, "origin", "", false, false], [1, 2, 37, 39, "origin", "", false, false], [0, 4, 1, 2, "named", "", false, false], [10, 11, 13, 14, "physical", "", false, false], [10, 11, 13, 14, "role", "", false, false], [16, 17, 19, 22, "physical", "", false, false], [16, 17, 19, 22, "role", "", false, false], [24, 24, 19, 22, "named", "", false, false], [33, 35, 41, 44, "physical", "", false, false], [33, 35, 41, 44, "role", "", false, false], [37, 39, 41, 44, "physical", "", false, false], [37, 39, 41, 44, "role", "", false, false], [55, 58, 1, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", "was", "first", "developed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", "and", "then", "further", "developed", "by", "Bishnu", "S.", "Atal", "and", "Manfred", "R.", "Schroeder", "at", "Bell", "Labs", "in", "the", "early", "and", "mid-1970s", ",", "forming", "the", "basis", "for", "the", "first", "DSP", "speech", "synthesizer", "chips", "in", "the", "late", "1970s", "."], "sentence-detokenized": "Linear predictive coding (LPC) was first developed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966 and then further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs in the early and mid-1970s, forming the basis for the first DSP speech synthesizer chips in the late 1970s.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 40], [41, 50], [51, 53], [54, 62], [63, 70], [71, 73], [74, 80], [81, 91], [92, 95], [96, 101], [102, 107], [108, 110], [111, 117], [118, 127], [128, 131], [132, 141], [142, 143], [143, 146], [146, 147], [148, 150], [151, 155], [156, 159], [160, 164], [165, 172], [173, 182], [183, 185], [186, 192], [193, 195], [196, 200], [201, 204], [205, 212], [213, 215], [216, 225], [226, 228], [229, 233], [234, 238], [239, 241], [242, 245], [246, 251], [252, 255], [256, 265], [265, 266], [267, 274], [275, 278], [279, 284], [285, 288], [289, 292], [293, 298], [299, 302], [303, 309], [310, 321], [322, 327], [328, 330], [331, 334], [335, 339], [340, 345], [345, 346]]}
{"doc_key": "ai-test-408", "ner": [[0, 3, "metrics"], [8, 8, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 0, 3, "part-of", "", false, false], [10, 10, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "F", "-", "score", "is", "a", "combination", "of", "accuracy", "and", "recall", ",", "providing", "a", "single", "score", "."], "sentence-detokenized": "The F-score is a combination of accuracy and recall, providing a single score.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 16], [17, 28], [29, 31], [32, 40], [41, 44], [45, 51], [51, 52], [53, 62], [63, 64], [65, 71], [72, 77], [77, 78]]}
{"doc_key": "ai-test-409", "ner": [[0, 1, "field"], [8, 11, "task"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 0, 1, "part-of", "task_part_of_field", false, false], [16, 17, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Image", "analysis", "tasks", "can", "be", "as", "simple", "as", "reading", "barcode", "labels", "d", "or", "as", "complex", "as", "facial", "recognition", "."], "sentence-detokenized": "Image analysis tasks can be as simple as reading barcode labels d or as complex as facial recognition.", "token2charspan": [[0, 5], [6, 14], [15, 20], [21, 24], [25, 27], [28, 30], [31, 37], [38, 40], [41, 48], [49, 56], [57, 63], [64, 65], [66, 68], [69, 71], [72, 79], [80, 82], [83, 89], [90, 101], [101, 102]]}
{"doc_key": "ai-test-410", "ner": [[5, 7, "algorithm"], [25, 25, "algorithm"], [34, 36, "algorithm"], [40, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[34, 36, 25, 25, "type-of", "", false, false], [40, 40, 34, 36, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "special", "case", "of", "linear", "support", "vector", "machines", "can", "be", "solved", "more", "efficiently", "with", "the", "same", "kind", "of", "algorithms", "for", "optimizing", "its", "close", "cousin", ",", "logistic", "regression", ";", "this", "class", "of", "algorithms", "includes", "the", "stochastic", "gradient", "descent", "(", "e.g.", ",", "PEGASOS", ")", "."], "sentence-detokenized": "The special case of linear support vector machines can be solved more efficiently with the same kind of algorithms for optimizing its close cousin, logistic regression; this class of algorithms includes the stochastic gradient descent (e.g., PEGASOS).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 34], [35, 41], [42, 50], [51, 54], [55, 57], [58, 64], [65, 69], [70, 81], [82, 86], [87, 90], [91, 95], [96, 100], [101, 103], [104, 114], [115, 118], [119, 129], [130, 133], [134, 139], [140, 146], [146, 147], [148, 156], [157, 167], [167, 168], [169, 173], [174, 179], [180, 182], [183, 193], [194, 202], [203, 206], [207, 217], [218, 226], [227, 234], [235, 236], [236, 240], [240, 241], [242, 249], [249, 250], [250, 251]]}
{"doc_key": "ai-test-411", "ner": [[0, 1, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "Siri", "on", "an", "iOS", "device", "asks", "Do", "you", "have", "a", "pet", "?", ",", "one", "of", "the", "answers", "is", "I", "had", "an", "AIBO", "."], "sentence-detokenized": "When Siri on an iOS device asks Do you have a pet?, one of the answers is I had an AIBO.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 38], [39, 43], [44, 45], [46, 49], [49, 50], [50, 51], [52, 55], [56, 58], [59, 62], [63, 70], [71, 73], [74, 75], [76, 79], [80, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-test-412", "ner": [[1, 2, "task"], [4, 6, "metrics"], [9, 9, "metrics"], [11, 11, "metrics"], [14, 14, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 1, 2, "part-of", "", false, false], [9, 9, 4, 6, "named", "", false, false], [11, 11, 1, 2, "part-of", "", false, false], [14, 14, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "information", "retrieval", ",", "positive", "predictive", "value", "is", "called", "accuracy", "and", "sensitivity", "is", "called", "recall", "."], "sentence-detokenized": "In information retrieval, positive predictive value is called accuracy and sensitivity is called recall.", "token2charspan": [[0, 2], [3, 14], [15, 24], [24, 25], [26, 34], [35, 45], [46, 51], [52, 54], [55, 61], [62, 70], [71, 74], [75, 86], [87, 89], [90, 96], [97, 103], [103, 104]]}
{"doc_key": "ai-test-413", "ner": [[10, 11, "field"], [13, 13, "task"], [15, 15, "task"], [17, 18, "task"], [33, 34, "task"], [36, 37, "task"], [39, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 13, 10, 11, "part-of", "task_part_of_field", false, false], [15, 15, 10, 11, "part-of", "task_part_of_field", false, false], [17, 18, 10, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "particular", ",", "his", "research", "focused", "on", "areas", "such", "as", "text", "mining", "(", "extraction", ",", "categorization", ",", "novelty", "detection", ")", "and", "new", "theoretical", "frameworks", "such", "as", "a", "unified", "utility", "-", "based", "theory", "bridging", "information", "retrieval", ",", "automatic", "summarization", ",", "free", "text", "question", "answering", "and", "related", "tasks", "."], "sentence-detokenized": "In particular, his research focused on areas such as text mining (extraction, categorization, novelty detection) and new theoretical frameworks such as a unified utility-based theory bridging information retrieval, automatic summarization, free text question answering and related tasks.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 27], [28, 35], [36, 38], [39, 44], [45, 49], [50, 52], [53, 57], [58, 64], [65, 66], [66, 76], [76, 77], [78, 92], [92, 93], [94, 101], [102, 111], [111, 112], [113, 116], [117, 120], [121, 132], [133, 143], [144, 148], [149, 151], [152, 153], [154, 161], [162, 169], [169, 170], [170, 175], [176, 182], [183, 191], [192, 203], [204, 213], [213, 214], [215, 224], [225, 238], [238, 239], [240, 244], [245, 249], [250, 258], [259, 268], [269, 272], [273, 280], [281, 286], [286, 287]]}
{"doc_key": "ai-test-414", "ner": [[0, 1, "product"], [3, 4, "product"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [17, 18, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Delta", "robots", "have", "rotary", "actuators", "mounted", "on", "the", "base", ",", "which", "drive", "a", "lightweight", ",", "rigid", ",", "parallelogram", "arm", "."], "sentence-detokenized": "Delta robots have rotary actuators mounted on the base, which drive a lightweight, rigid, parallelogram arm.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 24], [25, 34], [35, 42], [43, 45], [46, 49], [50, 54], [54, 55], [56, 61], [62, 67], [68, 69], [70, 81], [81, 82], [83, 88], [88, 89], [90, 103], [104, 107], [107, 108]]}
{"doc_key": "ai-test-415", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "expressed", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "table", ",", "as", "follows", ":"], "sentence-detokenized": "The four results can be expressed in a 2 \u00d7 2 contingency table or confusion table, as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 33], [34, 36], [37, 38], [39, 40], [41, 42], [43, 44], [45, 56], [57, 62], [63, 65], [66, 75], [76, 81], [81, 82], [83, 85], [86, 93], [93, 94]]}
{"doc_key": "ai-test-416", "ner": [[2, 3, "field"], [30, 31, "task"], [37, 38, "task"], [43, 45, "task"], [47, 49, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[30, 31, 2, 3, "part-of", "task_part_of_field", false, false], [37, 38, 2, 3, "part-of", "task_part_of_field", false, false], [43, 45, 2, 3, "part-of", "task_part_of_field", false, false], [47, 49, 2, 3, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "actual", "data", "mining", "task", "is", "the", "semi-automatic", "or", "automatic", "analysis", "of", "large", "amounts", "of", "data", "to", "extract", "unknown", ",", "interesting", "patterns", ",", "such", "as", "groups", "of", "data", "records", "(", "cluster", "analysis", ")", ",", "unusual", "records", "(", "anomaly", "detection", ")", "and", "dependencies", "(", "association", "rule", "mining", ",", "sequential", "pattern", "mining", ")", "."], "sentence-detokenized": "The actual data mining task is the semi-automatic or automatic analysis of large amounts of data to extract unknown, interesting patterns, such as groups of data records (cluster analysis), unusual records (anomaly detection) and dependencies (association rule mining, sequential pattern mining).", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 22], [23, 27], [28, 30], [31, 34], [35, 49], [50, 52], [53, 62], [63, 71], [72, 74], [75, 80], [81, 88], [89, 91], [92, 96], [97, 99], [100, 107], [108, 115], [115, 116], [117, 128], [129, 137], [137, 138], [139, 143], [144, 146], [147, 153], [154, 156], [157, 161], [162, 169], [170, 171], [171, 178], [179, 187], [187, 188], [188, 189], [190, 197], [198, 205], [206, 207], [207, 214], [215, 224], [224, 225], [226, 229], [230, 242], [243, 244], [244, 255], [256, 260], [261, 267], [267, 268], [269, 279], [280, 287], [288, 294], [294, 295], [295, 296]]}
{"doc_key": "ai-test-417", "ner": [[2, 3, "product"], [5, 6, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 5, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "a", "recommendation", "system", ",", "sentiment", "analysis", "has", "proven", "to", "be", "a", "valuable", "technique", "."], "sentence-detokenized": "For a recommendation system, sentiment analysis has proven to be a valuable technique.", "token2charspan": [[0, 3], [4, 5], [6, 20], [21, 27], [27, 28], [29, 38], [39, 47], [48, 51], [52, 58], [59, 61], [62, 64], [65, 66], [67, 75], [76, 85], [85, 86]]}
{"doc_key": "ai-test-418", "ner": [[7, 7, "misc"], [17, 17, "product"], [38, 38, "organisation"], [42, 43, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 17, 17, "usage", "", false, false], [38, 38, 42, 43, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "luck", "would", "have", "it", ",", "the", "Germans", "had", "very", "badly", "chosen", "the", "operating", "frequency", "of", "the", "Wotan", "system", ":", "it", "was", "operating", "on", "45", "MHz", ",", "which", "happens", "to", "be", "the", "frequency", "of", "the", "powerful", "but", "inactive", "BBC", "TV", "transmitter", "at", "Alexandra", "Palace", "."], "sentence-detokenized": "As luck would have it, the Germans had very badly chosen the operating frequency of the Wotan system: it was operating on 45 MHz, which happens to be the frequency of the powerful but inactive BBC TV transmitter at Alexandra Palace.", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 18], [19, 21], [21, 22], [23, 26], [27, 34], [35, 38], [39, 43], [44, 49], [50, 56], [57, 60], [61, 70], [71, 80], [81, 83], [84, 87], [88, 93], [94, 100], [100, 101], [102, 104], [105, 108], [109, 118], [119, 121], [122, 124], [125, 128], [128, 129], [130, 135], [136, 143], [144, 146], [147, 149], [150, 153], [154, 163], [164, 166], [167, 170], [171, 179], [180, 183], [184, 192], [193, 196], [197, 199], [200, 211], [212, 214], [215, 224], [225, 231], [231, 232]]}
{"doc_key": "ai-test-419", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "expressed", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "table", ",", "as", "follows", ":"], "sentence-detokenized": "The four results can be expressed in a 2 \u00d7 2 contingency table or confusion table, as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 33], [34, 36], [37, 38], [39, 40], [41, 42], [43, 44], [45, 56], [57, 62], [63, 65], [66, 75], [76, 81], [81, 82], [83, 85], [86, 93], [93, 94]]}
{"doc_key": "ai-test-420", "ner": [[1, 3, "misc"], [8, 8, "misc"], [12, 12, "product"], [14, 14, "product"], [16, 18, "product"], [27, 29, "misc"], [42, 42, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 12, 8, 8, "usage", "", false, false], [14, 14, 8, 8, "usage", "", false, false], [16, 18, 14, 14, "named", "", false, false], [27, 29, 8, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "Semantic", "Web", "applications", "and", "in", "relatively", "popular", "RDF", "applications", "such", "as", "RSS", "and", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "resources", "tend", "to", "be", "represented", "by", "URIs", "that", "are", "intentionally", "declared", "and", "can", "be", "used", "to", "access", "real", "data", "on", "the", "Web", "."], "sentence-detokenized": "In Semantic Web applications and in relatively popular RDF applications such as RSS and FOAF (Friend a Friend), resources tend to be represented by URIs that are intentionally declared and can be used to access real data on the Web.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 28], [29, 32], [33, 35], [36, 46], [47, 54], [55, 58], [59, 71], [72, 76], [77, 79], [80, 83], [84, 87], [88, 92], [93, 94], [94, 100], [101, 102], [103, 109], [109, 110], [110, 111], [112, 121], [122, 126], [127, 129], [130, 132], [133, 144], [145, 147], [148, 152], [153, 157], [158, 161], [162, 175], [176, 184], [185, 188], [189, 192], [193, 195], [196, 200], [201, 203], [204, 210], [211, 215], [216, 220], [221, 223], [224, 227], [228, 231], [231, 232]]}
{"doc_key": "ai-test-421", "ner": [[1, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "has", "studied", "this", "issue", "in", "depth"], "sentence-detokenized": "The Association for the Advancement of Artificial Intelligence has studied this issue in depth", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 74], [75, 79], [80, 85], [86, 88], [89, 94]]}
{"doc_key": "ai-test-422", "ner": [[6, 9, "product"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 6, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starting", "as", "a", "curiosity", ",", "the", "Apple", "Macintosh", "speech", "system", "evolved", "into", "a", "fully", "supported", "PlainTalk", "program", "for", "the", "visually", "impaired", "."], "sentence-detokenized": "Starting as a curiosity, the Apple Macintosh speech system evolved into a fully supported PlainTalk program for the visually impaired.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 23], [23, 24], [25, 28], [29, 34], [35, 44], [45, 51], [52, 58], [59, 66], [67, 71], [72, 73], [74, 79], [80, 89], [90, 99], [100, 107], [108, 111], [112, 115], [116, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-test-423", "ner": [[10, 10, "field"], [12, 13, "task"], [15, 16, "task"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 13, 10, 10, "part-of", "task_part_of_field", false, false], [15, 16, 10, 10, "part-of", "task_part_of_field", false, false], [18, 19, 10, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "areas", "of", "use", "of", "ontologies", "in", "the", "context", "of", "NLP", "include", "information", "retrieval", ",", "information", "extraction", "and", "automatic", "summarization", "."], "sentence-detokenized": "Other areas of use of ontologies in the context of NLP include information retrieval, information extraction and automatic summarization.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 47], [48, 50], [51, 54], [55, 62], [63, 74], [75, 84], [84, 85], [86, 97], [98, 108], [109, 112], [113, 122], [123, 136], [136, 137]]}
{"doc_key": "ai-test-424", "ner": [[7, 15, "organisation"], [18, 22, "organisation"], [25, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Institute", "has", "worked", "closely", "with", "the", "Janelia", "Farm", "Campus", "of", "the", "Howard", "Hughes", "Medical", "Institute", ",", "the", "Allen", "Institute", "for", "Brain", "Science", "and", "the", "National", "Institutes", "of", "Health", "to", "develop", "better", "methods", "for", "reconstructing", "neural", "architectures", "."], "sentence-detokenized": "The Institute has worked closely with the Janelia Farm Campus of the Howard Hughes Medical Institute, the Allen Institute for Brain Science and the National Institutes of Health to develop better methods for reconstructing neural architectures.", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 24], [25, 32], [33, 37], [38, 41], [42, 49], [50, 54], [55, 61], [62, 64], [65, 68], [69, 75], [76, 82], [83, 90], [91, 100], [100, 101], [102, 105], [106, 111], [112, 121], [122, 125], [126, 131], [132, 139], [140, 143], [144, 147], [148, 156], [157, 167], [168, 170], [171, 177], [178, 180], [181, 188], [189, 195], [196, 203], [204, 207], [208, 222], [223, 229], [230, 243], [243, 244]]}
{"doc_key": "ai-test-425", "ner": [[2, 2, "organisation"], [5, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 2, 2, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Recently", ",", "Google", "announced", "that", "Google", "Translate", "translates", "about", "enough", "text", "to", "fill", "1", "million", "books", "in", "one", "day", "(", "2012", ")", "."], "sentence-detokenized": "Recently, Google announced that Google Translate translates about enough text to fill 1 million books in one day (2012).", "token2charspan": [[0, 8], [8, 9], [10, 16], [17, 26], [27, 31], [32, 38], [39, 48], [49, 59], [60, 65], [66, 72], [73, 77], [78, 80], [81, 85], [86, 87], [88, 95], [96, 101], [102, 104], [105, 108], [109, 112], [113, 114], [114, 118], [118, 119], [119, 120]]}
{"doc_key": "ai-test-426", "ner": [[13, 14, "country"], [17, 18, "country"], [20, 20, "country"], [22, 22, "country"], [24, 24, "country"], [26, 27, "country"], [38, 39, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "events", "are", "held", "around", "the", "world", "and", "are", "most", "popular", "in", "the", "United", "Kingdom", ",", "the", "United", "States", ",", "Japan", ",", "Singapore", ",", "India", ",", "South", "Korea", "and", "are", "becoming", "increasingly", "popular", "in", "subcontinent", "countries", "such", "as", "Sri", "Lanka", "."], "sentence-detokenized": "The events are held around the world and are most popular in the United Kingdom, the United States, Japan, Singapore, India, South Korea and are becoming increasingly popular in subcontinent countries such as Sri Lanka.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 19], [20, 26], [27, 30], [31, 36], [37, 40], [41, 44], [45, 49], [50, 57], [58, 60], [61, 64], [65, 71], [72, 79], [79, 80], [81, 84], [85, 91], [92, 98], [98, 99], [100, 105], [105, 106], [107, 116], [116, 117], [118, 123], [123, 124], [125, 130], [131, 136], [137, 140], [141, 144], [145, 153], [154, 166], [167, 174], [175, 177], [178, 190], [191, 200], [201, 205], [206, 208], [209, 212], [213, 218], [218, 219]]}
{"doc_key": "ai-test-427", "ner": [[6, 6, "programlang"], [10, 10, "programlang"], [12, 12, "programlang"], [14, 15, "programlang"], [17, 17, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "mainly", "developed", "in", "R", "and", "sometimes", "in", "Java", ",", "C", ",", "C", "++", "and", "Fortran", "."], "sentence-detokenized": "These packages are mainly developed in R and sometimes in Java, C, C++ and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 25], [26, 35], [36, 38], [39, 40], [41, 44], [45, 54], [55, 57], [58, 62], [62, 63], [64, 65], [65, 66], [67, 68], [68, 70], [71, 74], [75, 82], [82, 83]]}
{"doc_key": "ai-test-428", "ner": [[2, 6, "conference"], [3, 8, "conference"], [11, 11, "researcher"], [13, 13, "researcher"], [16, 17, "researcher"], [20, 23, "algorithm"], [26, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 8, 2, 6, "named", "", false, false], [11, 11, 2, 6, "physical", "", false, false], [11, 11, 2, 6, "role", "", false, false], [11, 11, 16, 17, "role", "teams_up_with", false, false], [11, 11, 20, 23, "usage", "", false, false], [13, 13, 2, 6, "physical", "", false, false], [13, 13, 2, 6, "role", "", false, false], [13, 13, 16, 17, "role", "teams_up_with", false, false], [13, 13, 20, 23, "usage", "", false, false], [16, 17, 2, 6, "physical", "", false, false], [16, 17, 2, 6, "role", "", false, false], [16, 17, 20, 23, "usage", "", false, false], [20, 23, 26, 31, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["At", "the", "2006", "European", "Computer", "Vision", "Conference", "(", "ECCV", ")", ",", "Dalal", "and", "Triggs", "worked", "with", "Cordelia", "Schmid", "to", "apply", "HOG", "detectors", "to", "the", "problem", "of", "detecting", "people", "in", "movies", "and", "videos", "."], "sentence-detokenized": "At the 2006 European Computer Vision Conference (ECCV), Dalal and Triggs worked with Cordelia Schmid to apply HOG detectors to the problem of detecting people in movies and videos.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 29], [30, 36], [37, 47], [48, 49], [49, 53], [53, 54], [54, 55], [56, 61], [62, 65], [66, 72], [73, 79], [80, 84], [85, 93], [94, 100], [101, 103], [104, 109], [110, 113], [114, 123], [124, 126], [127, 130], [131, 138], [139, 141], [142, 151], [152, 158], [159, 161], [162, 168], [169, 172], [173, 179], [179, 180]]}
{"doc_key": "ai-test-429", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [11, 12, "task"], [19, 23, "metrics"], [29, 29, "metrics"], [34, 35, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7], "relations": [[3, 3, 11, 12, "related-to", "measured_with", false, false], [5, 5, 11, 12, "related-to", "measured_with", false, false], [37, 37, 34, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 5], "sentence": ["In", "addition", "to", "sensitivity", "and", "specificity", ",", "the", "performance", "of", "a", "binary", "classification", "test", "can", "be", "measured", "by", "the", "positive", "predictive", "value", "(", "PPV", ")", ",", "also", "known", "as", "accuracy", ",", "and", "the", "negative", "predictive", "value", "(", "NPV", ")", "."], "sentence-detokenized": "In addition to sensitivity and specificity, the performance of a binary classification test can be measured by the positive predictive value (PPV), also known as accuracy, and the negative predictive value (NPV).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 42], [42, 43], [44, 47], [48, 59], [60, 62], [63, 64], [65, 71], [72, 86], [87, 91], [92, 95], [96, 98], [99, 107], [108, 110], [111, 114], [115, 123], [124, 134], [135, 140], [141, 142], [142, 145], [145, 146], [146, 147], [148, 152], [153, 158], [159, 161], [162, 170], [170, 171], [172, 175], [176, 179], [180, 188], [189, 199], [200, 205], [206, 207], [207, 210], [210, 211], [211, 212]]}
{"doc_key": "ai-test-430", "ner": [[14, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "models", "can", "give", "partial", "credit", "for", "overlapping", "matches", "(", "such", "as", "using", "the", "Jaccard", "index", "criterion", "."], "sentence-detokenized": "Such models can give partial credit for overlapping matches (such as using the Jaccard index criterion.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 28], [29, 35], [36, 39], [40, 51], [52, 59], [60, 61], [61, 65], [66, 68], [69, 74], [75, 78], [79, 86], [87, 92], [93, 102], [102, 103]]}
{"doc_key": "ai-test-431", "ner": [[24, 29, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Moreover", ",", "in", "the", "case", "of", "estimation", "based", "on", "a", "single", "sample", ",", "it", "demonstrates", "philosophical", "issues", "and", "possible", "misconceptions", "in", "the", "use", "of", "maximum", "likelihood", "estimators", "and", "likelihood", "functions", "."], "sentence-detokenized": "Moreover, in the case of estimation based on a single sample, it demonstrates philosophical issues and possible misconceptions in the use of maximum likelihood estimators and likelihood functions.", "token2charspan": [[0, 8], [8, 9], [10, 12], [13, 16], [17, 21], [22, 24], [25, 35], [36, 41], [42, 44], [45, 46], [47, 53], [54, 60], [60, 61], [62, 64], [65, 77], [78, 91], [92, 98], [99, 102], [103, 111], [112, 126], [127, 129], [130, 133], [134, 137], [138, 140], [141, 148], [149, 159], [160, 170], [171, 174], [175, 185], [186, 195], [195, 196]]}
