{"doc_key": "ai-dev-1", "ner": [[2, 2, "metrics"], [7, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 2, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Here", ",", "accuracy", "is", "measured", "by", "the", "error", "rate", ",", "which", "is", "defined", "as", "follows", ":"], "sentence-detokenized": "Here, accuracy is measured by the error rate, which is defined as follows:", "token2charspan": [[0, 4], [4, 5], [6, 14], [15, 17], [18, 26], [27, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 51], [52, 54], [55, 62], [63, 65], [66, 73], [73, 74]]}
{"doc_key": "ai-dev-2", "ner": [[4, 4, "algorithm"], [11, 12, "misc"], [16, 18, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 11, 12, "type-of", "", false, false], [4, 4, 16, 18, "related-to", "", false, false], [4, 4, 19, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "this", "respect", ",", "SVM", "is", "closely", "related", "to", "other", "fundamental", "classification", "algorithms", ",", "such", "as", "normalized", "least", "squares", "logistic", "regression", "."], "sentence-detokenized": "In this respect, SVM is closely related to other fundamental classification algorithms, such as normalized least squares logistic regression.", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 20], [21, 23], [24, 31], [32, 39], [40, 42], [43, 48], [49, 60], [61, 75], [76, 86], [86, 87], [88, 92], [93, 95], [96, 106], [107, 112], [113, 120], [121, 129], [130, 140], [140, 141]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [3, 4, "person"], [13, 14, "person"], [16, 16, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 0, 1, "named", "actor_plays_character", false, false], [3, 4, 0, 1, "origin", "actor_plays_character", false, false], [16, 16, 13, 14, "named", "actor_plays_character", false, false], [16, 16, 13, 14, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "portrays", "Leon", "Kowalski", ",", "a", "combat", "and", "labor", "representative", ",", "and", "Joanna", "Cassidy", "portrays", "Zhora", ",", "a", "killer", "representative", "."], "sentence-detokenized": "Brion James portrays Leon Kowalski, a combat and labor representative, and Joanna Cassidy portrays Zhora, a killer representative.", "token2charspan": [[0, 5], [6, 11], [12, 20], [21, 25], [26, 34], [34, 35], [36, 37], [38, 44], [45, 48], [49, 54], [55, 69], [69, 70], [71, 74], [75, 81], [82, 89], [90, 98], [99, 104], [104, 105], [106, 107], [108, 114], [115, 129], [129, 130]]}
{"doc_key": "ai-dev-4", "ner": [[16, 18, "product"], [15, 20, "product"], [23, 23, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 18, 23, 23, "physical", "", false, false], [15, 20, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "image", "scanned", ",", "stored", "and", "reconstructed", "in", "digital", "pixels", "was", "displayed", "on", "the", "Standards", "Eastern", "Automatic", "Computer", "(", "SEAC", ")", "at", "NIST", "."], "sentence-detokenized": "The first image scanned, stored and reconstructed in digital pixels was displayed on the Standards Eastern Automatic Computer (SEAC) at NIST.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [23, 24], [25, 31], [32, 35], [36, 49], [50, 52], [53, 60], [61, 67], [68, 71], [72, 81], [82, 84], [85, 88], [89, 98], [99, 106], [107, 116], [117, 125], [126, 127], [127, 131], [131, 132], [133, 135], [136, 140], [140, 141]]}
{"doc_key": "ai-dev-5", "ner": [[0, 6, "task"], [20, 21, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 20, 21, "part-of", "", false, false], [0, 6, 23, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Segmenting", "text", "into", "topics", "or", "speech", "turns", "can", "be", "useful", "in", "certain", "natural", "processing", "tasks", ":", "it", "can", "greatly", "improve", "information", "retrieval", "or", "speech", "recognition", "(", "by", "indexing", "/", "recognizing", "documents", "more", "accurately", "or", "by", "resulting", "in", "the", "specific", "part", "of", "a", "document", "that", "corresponds", "to", "the", "query", ")", "."], "sentence-detokenized": "Segmenting text into topics or speech turns can be useful in certain natural processing tasks: it can greatly improve information retrieval or speech recognition (by indexing/recognizing documents more accurately or by resulting in the specific part of a document that corresponds to the query).", "token2charspan": [[0, 10], [11, 15], [16, 20], [21, 27], [28, 30], [31, 37], [38, 43], [44, 47], [48, 50], [51, 57], [58, 60], [61, 68], [69, 76], [77, 87], [88, 93], [93, 94], [95, 97], [98, 101], [102, 109], [110, 117], [118, 129], [130, 139], [140, 142], [143, 149], [150, 161], [162, 163], [163, 165], [166, 174], [174, 175], [175, 186], [187, 196], [197, 201], [202, 212], [213, 215], [216, 218], [219, 228], [229, 231], [232, 235], [236, 244], [245, 249], [250, 252], [253, 254], [255, 263], [264, 268], [269, 280], [281, 283], [284, 287], [288, 293], [293, 294], [294, 295]]}
{"doc_key": "ai-dev-6", "ner": [[1, 3, "university"], [22, 23, "conference"], [26, 29, "university"], [36, 37, "researcher"], [39, 40, "researcher"], [42, 43, "researcher"], [45, 46, "researcher"], [48, 49, "researcher"], [51, 52, "researcher"], [54, 56, "researcher"], [58, 59, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[22, 23, 26, 29, "physical", "", false, false], [36, 37, 22, 23, "physical", "", false, false], [36, 37, 22, 23, "role", "", false, false], [36, 37, 22, 23, "temporal", "", false, false], [39, 40, 22, 23, "physical", "", false, false], [39, 40, 22, 23, "role", "", false, false], [39, 40, 22, 23, "temporal", "", false, false], [42, 43, 22, 23, "physical", "", false, false], [42, 43, 22, 23, "role", "", false, false], [42, 43, 22, 23, "temporal", "", false, false], [45, 46, 22, 23, "physical", "", false, false], [45, 46, 22, 23, "role", "", false, false], [45, 46, 22, 23, "temporal", "", false, false], [48, 49, 22, 23, "physical", "", false, false], [48, 49, 22, 23, "role", "", false, false], [48, 49, 22, 23, "temporal", "", false, false], [51, 52, 22, 23, "physical", "", false, false], [51, 52, 22, 23, "role", "", false, false], [51, 52, 22, 23, "temporal", "", false, false], [54, 56, 22, 23, "physical", "", false, false], [54, 56, 22, 23, "role", "", false, false], [54, 56, 22, 23, "temporal", "", false, false], [58, 59, 22, 23, "physical", "", false, false], [58, 59, 22, 23, "role", "", false, false], [58, 59, 22, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["At", "Indiana", "University", "in", "1999", "he", "organized", "such", "a", "symposium", ",", "and", "in", "April", "2000", "he", "organized", "a", "larger", "symposium", "entitled", "\"", "Mental", "Robots", "\"", "at", "Stanford", "University", ",", "where", "he", "moderated", "a", "panel", "consisting", "of", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", "and", "John", "Koza", "."], "sentence-detokenized": "At Indiana University in 1999 he organized such a symposium, and in April 2000 he organized a larger symposium entitled \"Mental Robots\" at Stanford University, where he moderated a panel consisting of Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland and John Koza.", "token2charspan": [[0, 2], [3, 10], [11, 21], [22, 24], [25, 29], [30, 32], [33, 42], [43, 47], [48, 49], [50, 59], [59, 60], [61, 64], [65, 67], [68, 73], [74, 78], [79, 81], [82, 91], [92, 93], [94, 100], [101, 110], [111, 119], [120, 121], [121, 127], [128, 134], [134, 135], [136, 138], [139, 147], [148, 158], [158, 159], [160, 165], [166, 168], [169, 178], [179, 180], [181, 186], [187, 197], [198, 200], [201, 204], [205, 213], [213, 214], [215, 219], [220, 227], [227, 228], [229, 234], [235, 240], [240, 241], [242, 247], [248, 254], [254, 255], [256, 260], [261, 264], [264, 265], [266, 271], [272, 277], [277, 278], [279, 283], [284, 289], [290, 297], [298, 301], [302, 306], [307, 311], [311, 312]]}
{"doc_key": "ai-dev-7", "ner": [[9, 9, "metrics"], [10, 10, "metrics"], [13, 13, "metrics"], [14, 14, "metrics"], [23, 23, "metrics"], [44, 44, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 9, 23, 23, "named", "", false, false], [10, 10, 9, 9, "named", "", false, false], [13, 13, 44, 44, "named", "", false, false], [14, 14, 13, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["For", "the", "calculation", "of", "the", "score", ",", "both", "the", "precision", "p", "and", "the", "recall", "r", "of", "the", "test", "are", "taken", "into", "account", ":", "p", "is", "the", "number", "of", "correct", "positive", "results", "divided", "by", "the", "number", "of", "all", "positive", "results", "returned", "by", "the", "classifier", "and", "r", "is", "the", "number", "of", "correct", "positive", "results", "divided", "by", "the", "number", "of", "all", "relevant", "samples", "(", "all", "samples", "that", "should", "have", "been", "identified", "as", "positive", ")", "."], "sentence-detokenized": "For the calculation of the score, both the precision p and the recall r of the test are taken into account: p is the number of correct positive results divided by the number of all positive results returned by the classifier and r is the number of correct positive results divided by the number of all relevant samples (all samples that should have been identified as positive).", "token2charspan": [[0, 3], [4, 7], [8, 19], [20, 22], [23, 26], [27, 32], [32, 33], [34, 38], [39, 42], [43, 52], [53, 54], [55, 58], [59, 62], [63, 69], [70, 71], [72, 74], [75, 78], [79, 83], [84, 87], [88, 93], [94, 98], [99, 106], [106, 107], [108, 109], [110, 112], [113, 116], [117, 123], [124, 126], [127, 134], [135, 143], [144, 151], [152, 159], [160, 162], [163, 166], [167, 173], [174, 176], [177, 180], [181, 189], [190, 197], [198, 206], [207, 209], [210, 213], [214, 224], [225, 228], [229, 230], [231, 233], [234, 237], [238, 244], [245, 247], [248, 255], [256, 264], [265, 272], [273, 280], [281, 283], [284, 287], [288, 294], [295, 297], [298, 301], [302, 310], [311, 318], [319, 320], [320, 323], [324, 331], [332, 336], [337, 343], [344, 348], [349, 353], [354, 364], [365, 367], [368, 376], [376, 377], [377, 378]]}
{"doc_key": "ai-dev-8", "ner": [[2, 2, "organisation"], [21, 21, "product"], [29, 30, "person"], [36, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 21, 21, "artifact", "", false, false], [21, 21, 29, 30, "win-defeat", "", false, false], [21, 21, 36, 36, "win-defeat", "", true, false], [29, 30, 36, 36, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "the", "Google", "acquisition", ",", "the", "company", "has", "made", "a", "number", "of", "significant", "achievements", ",", "perhaps", "most", "notably", "the", "creation", "of", "AlphaGo", ",", "a", "program", "that", "beat", "world", "champion", "Lee", "Sedol", "at", "the", "complex", "game", "of", "Go", "."], "sentence-detokenized": "Since the Google acquisition, the company has made a number of significant achievements, perhaps most notably the creation of AlphaGo, a program that beat world champion Lee Sedol at the complex game of Go.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 28], [28, 29], [30, 33], [34, 41], [42, 45], [46, 50], [51, 52], [53, 59], [60, 62], [63, 74], [75, 87], [87, 88], [89, 96], [97, 101], [102, 109], [110, 113], [114, 122], [123, 125], [126, 133], [133, 134], [135, 136], [137, 144], [145, 149], [150, 154], [155, 160], [161, 169], [170, 173], [174, 179], [180, 182], [183, 186], [187, 194], [195, 199], [200, 202], [203, 205], [205, 206]]}
{"doc_key": "ai-dev-9", "ner": [[14, 15, "misc"], [26, 26, "field"], [28, 30, "product"], [47, 48, "misc"], [52, 53, "misc"], [56, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 15, 26, 26, "part-of", "", false, false], [14, 15, 52, 53, "named", "same", false, false], [28, 30, 47, 48, "related-to", "", false, false], [28, 30, 52, 53, "usage", "", false, false], [28, 30, 56, 56, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "representation", "of", "words", "by", "considering", "their", "contexts", "through", "dense", ",", "fixed", "-", "size", "word", "embeddings", "has", "become", "one", "of", "the", "most", "fundamental", "elements", "in", "many", "NLP", "systems.An", "unsupervised", "disambiguation", "system", "uses", "the", "similarity", "between", "word", "meanings", "in", "a", "fixed", "context", "window", "to", "select", "the", "most", "appropriate", "word", "meaning", "using", "a", "pre-trained", "word", "embedding", "model", "and", "WordNet", "."], "sentence-detokenized": "The representation of words by considering their contexts through dense, fixed-size word embeddings has become one of the most fundamental elements in many NLP systems.An unsupervised disambiguation system uses the similarity between word meanings in a fixed context window to select the most appropriate word meaning using a pre-trained word embedding model and WordNet.", "token2charspan": [[0, 3], [4, 18], [19, 21], [22, 27], [28, 30], [31, 42], [43, 48], [49, 57], [58, 65], [66, 71], [71, 72], [73, 78], [78, 79], [79, 83], [84, 88], [89, 99], [100, 103], [104, 110], [111, 114], [115, 117], [118, 121], [122, 126], [127, 138], [139, 147], [148, 150], [151, 155], [156, 159], [160, 170], [171, 183], [184, 198], [199, 205], [206, 210], [211, 214], [215, 225], [226, 233], [234, 238], [239, 247], [248, 250], [251, 252], [253, 258], [259, 266], [267, 273], [274, 276], [277, 283], [284, 287], [288, 292], [293, 304], [305, 309], [310, 317], [318, 323], [324, 325], [326, 337], [338, 342], [343, 352], [353, 358], [359, 362], [363, 370], [370, 371]]}
{"doc_key": "ai-dev-10", "ner": [[0, 1, "field"], [5, 5, "field"], [7, 8, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 1, "part-of", "", false, false], [7, 8, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "techniques", ",", "either", "supervised", "or", "unsupervised", "learning", ",", "have", "been", "used", "to", "automatically", "generate", "such", "rules", "."], "sentence-detokenized": "Machine learning techniques, either supervised or unsupervised learning, have been used to automatically generate such rules.", "token2charspan": [[0, 7], [8, 16], [17, 27], [27, 28], [29, 35], [36, 46], [47, 49], [50, 62], [63, 71], [71, 72], [73, 77], [78, 82], [83, 87], [88, 90], [91, 104], [105, 113], [114, 118], [119, 124], [124, 125]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1969", ",", "Scheinman", "invented", "the", "Stanford", "arm", ","], "sentence-detokenized": "In 1969, Scheinman invented the Stanford arm,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 27], [28, 31], [32, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-dev-12", "ner": [[2, 3, "metrics"], [8, 11, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "the", "Log", "loss", "is", "differentiable", ",", "a", "gradient", "-", "based", "method", "can", "be", "used", "to", "optimize", "the", "model", "."], "sentence-detokenized": "Since the Log loss is differentiable, a gradient-based method can be used to optimize the model.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 18], [19, 21], [22, 36], [36, 37], [38, 39], [40, 48], [48, 49], [49, 54], [55, 61], [62, 65], [66, 68], [69, 73], [74, 76], [77, 85], [86, 89], [90, 95], [95, 96]]}
{"doc_key": "ai-dev-13", "ner": [[1, 2, "field"], [4, 6, "algorithm"], [8, 8, "algorithm"], [13, 15, "algorithm"], [18, 19, "field"], [29, 29, "task"], [31, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 6, 18, 19, "part-of", "", false, false], [8, 8, 4, 6, "named", "", false, false], [13, 15, 4, 6, "named", "", false, false], [18, 19, 1, 2, "part-of", "subfield", false, false], [29, 29, 18, 19, "part-of", "", false, false], [31, 32, 18, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "machine", "learning", ",", "support", "vector", "machines", "(", "SVMs", ",", "also", "known", "as", "support", "vector", "networks", ")", "are", "supervised", "learning", "models", "and", "learning", "algorithms", "that", "analyse", "data", "used", "for", "classification", "and", "regression", "analysis", "."], "sentence-detokenized": "In machine learning, support vector machines (SVMs, also known as support vector networks) are supervised learning models and learning algorithms that analyse data used for classification and regression analysis.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 28], [29, 35], [36, 44], [45, 46], [46, 50], [50, 51], [52, 56], [57, 62], [63, 65], [66, 73], [74, 80], [81, 89], [89, 90], [91, 94], [95, 105], [106, 114], [115, 121], [122, 125], [126, 134], [135, 145], [146, 150], [151, 158], [159, 163], [164, 168], [169, 172], [173, 187], [188, 191], [192, 202], [203, 211], [211, 212]]}
{"doc_key": "ai-dev-14", "ner": [[11, 11, "task"], [13, 13, "task"], [30, 30, "metrics"], [32, 32, "metrics"], [34, 34, "researcher"], [36, 36, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 13, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": [",", "(", "2002", ")", "as", "an", "automatic", "metric", "for", "evaluating", "machine", "translation", "(", "MT", ")", ",", "many", "other", "methods", "have", "been", "proposed", "to", "revise", "or", "improve", "it", ",", "such", "as", "TER", ",", "METEOR", ",", "Banerjee", "and", "Lavie", ",", "(", "2005", ")", ",", "etc", "."], "sentence-detokenized": ", (2002) as an automatic metric for evaluating machine translation (MT), many other methods have been proposed to revise or improve it, such as TER, METEOR, Banerjee and Lavie, (2005), etc.", "token2charspan": [[0, 1], [2, 3], [3, 7], [7, 8], [9, 11], [12, 14], [15, 24], [25, 31], [32, 35], [36, 46], [47, 54], [55, 66], [67, 68], [68, 70], [70, 71], [71, 72], [73, 77], [78, 83], [84, 91], [92, 96], [97, 101], [102, 110], [111, 113], [114, 120], [121, 123], [124, 131], [132, 134], [134, 135], [136, 140], [141, 143], [144, 147], [147, 148], [149, 155], [155, 156], [157, 165], [166, 169], [170, 175], [175, 176], [177, 178], [178, 182], [182, 183], [183, 184], [185, 188], [188, 189]]}
{"doc_key": "ai-dev-15", "ner": [[3, 4, "misc"], [11, 11, "organisation"], [12, 12, "organisation"], [18, 19, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 12, 12, "origin", "", false, false], [12, 12, 11, 11, "part-of", "", false, false], [18, 19, 12, 12, "role", "", false, false], [21, 22, 12, 12, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "includes", "a", "higher", "ontology", ",", "which", "was", "created", "by", "the", "IEEE", "P1600.1", "working", "group", "(", "originally", "by", "Ian", "Niles", "and", "Adam", "Pease", ")", "."], "sentence-detokenized": "It includes a higher ontology, which was created by the IEEE P1600.1 working group (originally by Ian Niles and Adam Pease).", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 20], [21, 29], [29, 30], [31, 36], [37, 40], [41, 48], [49, 51], [52, 55], [56, 60], [61, 68], [69, 76], [77, 82], [83, 84], [84, 94], [95, 97], [98, 101], [102, 107], [108, 111], [112, 116], [117, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-dev-16", "ner": [[1, 2, "misc"], [31, 33, "algorithm"], [35, 36, "algorithm"], [39, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[31, 33, 1, 2, "part-of", "", true, false], [35, 36, 1, 2, "part-of", "", true, false], [39, 40, 35, 36, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "cryoelectron", "tomography", ",", "where", "a", "limited", "number", "of", "projections", "are", "obtained", "due", "to", "hardware", "limitations", "and", "to", "avoid", "damage", "to", "the", "biological", "sample", ",", "it", "can", "be", "used", "together", "with", "compressive", "sensing", "techniques", "or", "normalization", "functions", "(", "e.g.", "Huber", "loss", ")", "to", "improve", "reconstruction", "for", "better", "interpretation", "."], "sentence-detokenized": "In cryoelectron tomography, where a limited number of projections are obtained due to hardware limitations and to avoid damage to the biological sample, it can be used together with compressive sensing techniques or normalization functions (e.g. Huber loss) to improve reconstruction for better interpretation.", "token2charspan": [[0, 2], [3, 15], [16, 26], [26, 27], [28, 33], [34, 35], [36, 43], [44, 50], [51, 53], [54, 65], [66, 69], [70, 78], [79, 82], [83, 85], [86, 94], [95, 106], [107, 110], [111, 113], [114, 119], [120, 126], [127, 129], [130, 133], [134, 144], [145, 151], [151, 152], [153, 155], [156, 159], [160, 162], [163, 167], [168, 176], [177, 181], [182, 193], [194, 201], [202, 212], [213, 215], [216, 229], [230, 239], [240, 241], [241, 245], [246, 251], [252, 256], [256, 257], [258, 260], [261, 268], [269, 283], [284, 287], [288, 294], [295, 309], [309, 310]]}
{"doc_key": "ai-dev-17", "ner": [[4, 4, "misc"], [7, 7, "programlang"], [10, 10, "algorithm"], [12, 13, "algorithm"], [17, 18, "algorithm"], [24, 26, "product"], [29, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 4, 7, 7, "part-of", "", false, false], [10, 10, 4, 4, "type-of", "", false, false], [12, 13, 4, 4, "type-of", "", false, false], [17, 18, 4, 4, "type-of", "", false, false], [24, 26, 7, 7, "general-affiliation", "", true, false], [24, 26, 7, 7, "part-of", "", true, false], [29, 29, 24, 26, "role", "publishes", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["An", "implementation", "of", "various", "whitening", "procedures", "in", "R", ",", "including", "ZCA", "and", "PCA", "whitening", ",", "but", "also", "CCA", "whitening", ",", "is", "available", "in", "the", "R", "whitening", "package", "published", "in", "CRAN", "."], "sentence-detokenized": "An implementation of various whitening procedures in R, including ZCA and PCA whitening, but also CCA whitening, is available in the R whitening package published in CRAN.", "token2charspan": [[0, 2], [3, 17], [18, 20], [21, 28], [29, 38], [39, 49], [50, 52], [53, 54], [54, 55], [56, 65], [66, 69], [70, 73], [74, 77], [78, 87], [87, 88], [89, 92], [93, 97], [98, 101], [102, 111], [111, 112], [113, 115], [116, 125], [126, 128], [129, 132], [133, 134], [135, 144], [145, 152], [153, 162], [163, 165], [166, 170], [170, 171]]}
{"doc_key": "ai-dev-18", "ner": [[31, 31, "product"], [33, 33, "product"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [41, 41, "product"], [44, 44, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[31, 31, 35, 35, "compare", "", false, false], [31, 31, 37, 37, "compare", "", false, false], [31, 31, 39, 39, "compare", "", false, false], [31, 31, 41, 41, "compare", "", false, false], [31, 31, 44, 44, "compare", "", false, false], [33, 33, 35, 35, "compare", "", false, false], [33, 33, 37, 37, "compare", "", false, false], [33, 33, 39, 39, "compare", "", false, false], [33, 33, 41, 41, "compare", "", false, false], [33, 33, 44, 44, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Today", ",", "the", "field", "has", "become", "even", "more", "daunting", "and", "complex", "with", "the", "addition", "of", "languages", "and", "software", "for", "the", "analysis", "and", "design", "of", "circuits", ",", "systems", "and", "signals", ",", "from", "MATLAB", "and", "Simulink", "to", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "and", "even", "Assembly", "."], "sentence-detokenized": "Today, the field has become even more daunting and complex with the addition of languages and software for the analysis and design of circuits, systems and signals, from MATLAB and Simulink to NumPy, VHDL, PSpice, Verilog and even Assembly.", "token2charspan": [[0, 5], [5, 6], [7, 10], [11, 16], [17, 20], [21, 27], [28, 32], [33, 37], [38, 46], [47, 50], [51, 58], [59, 63], [64, 67], [68, 76], [77, 79], [80, 89], [90, 93], [94, 102], [103, 106], [107, 110], [111, 119], [120, 123], [124, 130], [131, 133], [134, 142], [142, 143], [144, 151], [152, 155], [156, 163], [163, 164], [165, 169], [170, 176], [177, 180], [181, 189], [190, 192], [193, 198], [198, 199], [200, 204], [204, 205], [206, 212], [212, 213], [214, 221], [222, 225], [226, 230], [231, 239], [239, 240]]}
{"doc_key": "ai-dev-19", "ner": [[5, 6, "person"], [16, 17, "person"], [18, 21, "organisation"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[18, 21, 16, 17, "origin", "", false, false], [23, 23, 18, 21, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "company", "was", "founded", "by", "Kiichiro", "Toyoda", "in", "1937", ",", "as", "a", "spin", "-", "off", "from", "Sakichi", "Toyoda", "'s", "Toyota", "Industries", "to", "create", "cars", "."], "sentence-detokenized": "The company was founded by Kiichiro Toyoda in 1937, as a spin-off from Sakichi Toyoda's Toyota Industries to create cars.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 35], [36, 42], [43, 45], [46, 50], [50, 51], [52, 54], [55, 56], [57, 61], [61, 62], [62, 65], [66, 70], [71, 78], [79, 85], [85, 87], [88, 94], [95, 105], [106, 108], [109, 115], [116, 120], [120, 121]]}
{"doc_key": "ai-dev-20", "ner": [[0, 4, "field"], [54, 55, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[54, 55, 0, 4, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Unsupervised", "learning", ",", "on", "the", "other", "hand", ",", "assumes", "training", "data", "that", "has", "not", "been", "manually", "labeled", "and", "tries", "to", "find", "intrinsic", "patterns", "in", "the", "data", ",", "which", "can", "then", "be", "used", "to", "determine", "the", "correct", "output", "value", "for", "new", "data", "instances", ".", "A", "combination", "of", "the", "two", "that", "has", "recently", "been", "explored", "is", "semi-supervised", "learning", ",", "which", "uses", "a", "combination", "of", "labeled", "and", "unlabeled", "data", "(", "typically", "a", "small", "set", "of", "labeled", "data", "combined", "with", "a", "large", "amount", "of", "unlabeled", "data", ")", "."], "sentence-detokenized": "Unsupervised learning, on the other hand, assumes training data that has not been manually labeled and tries to find intrinsic patterns in the data, which can then be used to determine the correct output value for new data instances. A combination of the two that has recently been explored is semi-supervised learning, which uses a combination of labeled and unlabeled data (typically a small set of labeled data combined with a large amount of unlabeled data).", "token2charspan": [[0, 12], [13, 21], [21, 22], [23, 25], [26, 29], [30, 35], [36, 40], [40, 41], [42, 49], [50, 58], [59, 63], [64, 68], [69, 72], [73, 76], [77, 81], [82, 90], [91, 98], [99, 102], [103, 108], [109, 111], [112, 116], [117, 126], [127, 135], [136, 138], [139, 142], [143, 147], [147, 148], [149, 154], [155, 158], [159, 163], [164, 166], [167, 171], [172, 174], [175, 184], [185, 188], [189, 196], [197, 203], [204, 209], [210, 213], [214, 217], [218, 222], [223, 232], [232, 233], [234, 235], [236, 247], [248, 250], [251, 254], [255, 258], [259, 263], [264, 267], [268, 276], [277, 281], [282, 290], [291, 293], [294, 309], [310, 318], [318, 319], [320, 325], [326, 330], [331, 332], [333, 344], [345, 347], [348, 355], [356, 359], [360, 369], [370, 374], [375, 376], [376, 385], [386, 387], [388, 393], [394, 397], [398, 400], [401, 408], [409, 413], [414, 422], [423, 427], [428, 429], [430, 435], [436, 442], [443, 445], [446, 455], [456, 460], [460, 461], [461, 462]]}
{"doc_key": "ai-dev-21", "ner": [[20, 20, "organisation"], [22, 22, "product"], [24, 25, "organisation"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 20, 20, "artifact", "", false, false], [24, 25, 27, 27, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Despite", "these", "humanoid", "robots", "for", "utilitarian", "uses", ",", "there", "are", "some", "humanoid", "robots", "aimed", "at", "recreational", "uses", ",", "such", "as", "Sony", "'s", "QRIO", "and", "Wow", "Wee", "'s", "RoboSapien", "."], "sentence-detokenized": "Despite these humanoid robots for utilitarian uses, there are some humanoid robots aimed at recreational uses, such as Sony's QRIO and Wow Wee's RoboSapien.", "token2charspan": [[0, 7], [8, 13], [14, 22], [23, 29], [30, 33], [34, 45], [46, 50], [50, 51], [52, 57], [58, 61], [62, 66], [67, 75], [76, 82], [83, 88], [89, 91], [92, 104], [105, 109], [109, 110], [111, 115], [116, 118], [119, 123], [123, 125], [126, 130], [131, 134], [135, 138], [139, 142], [142, 144], [145, 155], [155, 156]]}
{"doc_key": "ai-dev-22", "ner": [[0, 0, "researcher"], [3, 10, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 3, 10, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Webber", "joined", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "in", "1991", ","], "sentence-detokenized": "Webber joined the Association for the Advancement of Artificial Intelligence in 1991,", "token2charspan": [[0, 6], [7, 13], [14, 17], [18, 29], [30, 33], [34, 37], [38, 49], [50, 52], [53, 63], [64, 76], [77, 79], [80, 84], [84, 85]]}
{"doc_key": "ai-dev-23", "ner": [[5, 6, "field"], [8, 8, "field"], [20, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 23, 5, 6, "part-of", "task_part_of_field", false, false], [20, 23, 8, 8, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["With", "this", "company", "he", "developed", "data", "mining", "and", "database", "technology", ",", "in", "particular", "high", "-", "level", "ontologies", "for", "intelligence", "and", "automated", "natural", "language", "understanding", "."], "sentence-detokenized": "With this company he developed data mining and database technology, in particular high-level ontologies for intelligence and automated natural language understanding.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 20], [21, 30], [31, 35], [36, 42], [43, 46], [47, 55], [56, 66], [66, 67], [68, 70], [71, 81], [82, 86], [86, 87], [87, 92], [93, 103], [104, 107], [108, 120], [121, 124], [125, 134], [135, 142], [143, 151], [152, 165], [165, 166]]}
{"doc_key": "ai-dev-24", "ner": [[23, 24, "misc"], [26, 29, "misc"], [31, 32, "misc"], [38, 38, "country"], [40, 41, "organisation"], [43, 43, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[23, 24, 38, 38, "physical", "", false, false], [26, 29, 38, 38, "physical", "", false, false], [31, 32, 38, 38, "physical", "", false, false], [40, 41, 43, 43, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["However", ",", "in", "recent", "years", ",", "one", "can", "observe", "the", "emergence", "of", "various", "e-services", "and", "related", "initiatives", "in", "developing", "countries", ",", "such", "as", "Project", "Nemmadi", ",", "MCA21", "Mission", "Mode", "Project", "or", "Digital", "India", "even", "more", "so", ",", "in", "India", ",", "e-Governance", "Directorate", "in", "Pakistan", "etc", "."], "sentence-detokenized": "However, in recent years, one can observe the emergence of various e-services and related initiatives in developing countries, such as Project Nemmadi, MCA21 Mission Mode Project or Digital India even more so, in India, e-Governance Directorate in Pakistan etc.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 18], [19, 24], [24, 25], [26, 29], [30, 33], [34, 41], [42, 45], [46, 55], [56, 58], [59, 66], [67, 77], [78, 81], [82, 89], [90, 101], [102, 104], [105, 115], [116, 125], [125, 126], [127, 131], [132, 134], [135, 142], [143, 150], [150, 151], [152, 157], [158, 165], [166, 170], [171, 178], [179, 181], [182, 189], [190, 195], [196, 200], [201, 205], [206, 208], [208, 209], [210, 212], [213, 218], [218, 219], [220, 232], [233, 244], [245, 247], [248, 256], [257, 260], [260, 261]]}
{"doc_key": "ai-dev-25", "ner": [[3, 4, "misc"], [5, 6, "field"], [8, 9, "field"], [10, 12, "university"], [14, 16, "university"], [24, 26, "university"], [29, 29, "misc"], [31, 32, "field"], [36, 38, "misc"], [40, 41, "university"], [43, 45, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 4, 5, 6, "topic", "", false, false], [3, 4, 8, 9, "topic", "", false, false], [3, 4, 10, 12, "origin", "", false, false], [10, 12, 14, 16, "part-of", "", false, false], [24, 26, 10, 12, "part-of", "", false, false], [29, 29, 31, 32, "topic", "", false, false], [29, 29, 40, 41, "origin", "", false, false], [36, 38, 40, 41, "origin", "", false, false], [40, 41, 43, 45, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["He", "received", "a", "PhD", "in", "Radio", "Physics", "and", "Electronics", "from", "Rajabazar", "Science", "College", ",", "University", "of", "Calcutta", "in", "1979", "as", "a", "student", "of", "the", "Indian", "Statistical", "Institute", "and", "another", "PhD", "in", "Electrical", "Engineering", "along", "with", "an", "Imperial", "College", "Diploma", "from", "Imperial", "College", ",", "University", "of", "London", "in", "1982", "."], "sentence-detokenized": "He received a PhD in Radio Physics and Electronics from Rajabazar Science College, University of Calcutta in 1979 as a student of the Indian Statistical Institute and another PhD in Electrical Engineering along with an Imperial College Diploma from Imperial College, University of London in 1982.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 17], [18, 20], [21, 26], [27, 34], [35, 38], [39, 50], [51, 55], [56, 65], [66, 73], [74, 81], [81, 82], [83, 93], [94, 96], [97, 105], [106, 108], [109, 113], [114, 116], [117, 118], [119, 126], [127, 129], [130, 133], [134, 140], [141, 152], [153, 162], [163, 166], [167, 174], [175, 178], [179, 181], [182, 192], [193, 204], [205, 210], [211, 215], [216, 218], [219, 227], [228, 235], [236, 243], [244, 248], [249, 257], [258, 265], [265, 266], [267, 277], [278, 280], [281, 287], [288, 290], [291, 295], [295, 296]]}
{"doc_key": "ai-dev-26", "ner": [[0, 2, "location"], [24, 26, "misc"], [32, 33, "misc"], [35, 37, "person"], [39, 40, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[24, 26, 0, 2, "temporal", "", false, false], [32, 33, 0, 2, "temporal", "", false, false], [35, 37, 32, 33, "role", "actor_in", false, false], [39, 40, 32, 33, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Expo", "II", "was", "announced", "to", "be", "the", "venue", "for", "the", "world", "premiere", "of", "several", "never", "-", "before", "-", "seen", "films", "in", "3D", ",", "including", "The", "Diamond", "Wizard", "and", "Universal", "'s", "short", "film", "Hawaiian", "Nights", "starring", "Mamie", "Van", "Doren", "and", "Pinky", "Lee", "."], "sentence-detokenized": "Expo II was announced to be the venue for the world premiere of several never-before-seen films in 3D, including The Diamond Wizard and Universal's short film Hawaiian Nights starring Mamie Van Doren and Pinky Lee.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 24], [25, 27], [28, 31], [32, 37], [38, 41], [42, 45], [46, 51], [52, 60], [61, 63], [64, 71], [72, 77], [77, 78], [78, 84], [84, 85], [85, 89], [90, 95], [96, 98], [99, 101], [101, 102], [103, 112], [113, 116], [117, 124], [125, 131], [132, 135], [136, 145], [145, 147], [148, 153], [154, 158], [159, 167], [168, 174], [175, 183], [184, 189], [190, 193], [194, 199], [200, 203], [204, 209], [210, 213], [213, 214]]}
{"doc_key": "ai-dev-27", "ner": [[7, 8, "researcher"], [16, 20, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 16, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "maximum", "subarray", "problem", "was", "proposed", "by", "Ulf", "Grenander", "in", "1977", "as", "a", "simplified", "model", "for", "estimating", "the", "maximum", "likelihood", "of", "patterns", "in", "digitized", "images", "."], "sentence-detokenized": "The maximum subarray problem was proposed by Ulf Grenander in 1977 as a simplified model for estimating the maximum likelihood of patterns in digitized images.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 28], [29, 32], [33, 41], [42, 44], [45, 48], [49, 58], [59, 61], [62, 66], [67, 69], [70, 71], [72, 82], [83, 88], [89, 92], [93, 103], [104, 107], [108, 115], [116, 126], [127, 129], [130, 138], [139, 141], [142, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-dev-28", "ner": [[0, 1, "product"], [3, 4, "product"], [6, 8, "product"], [10, 11, "product"], [13, 19, "product"], [21, 24, "product"], [35, 35, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[35, 35, 0, 1, "part-of", "", false, false], [35, 35, 3, 4, "part-of", "", false, false], [35, 35, 6, 8, "part-of", "", false, false], [35, 35, 10, 11, "part-of", "", false, false], [35, 35, 13, 19, "part-of", "", false, false], [35, 35, 21, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["iPhone", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", ",", "iPad", "Pro", "1G", ",", "iPod", "Touch", "5", "G", "and", "later", ",", "have", "a", "more", "advanced", "voice", "assistant", "called", "Siri", "."], "sentence-detokenized": "iPhone 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G, iPad Pro 1G, iPod Touch 5G and later, have a more advanced voice assistant called Siri.", "token2charspan": [[0, 6], [7, 9], [9, 10], [11, 15], [16, 17], [17, 18], [19, 23], [24, 28], [29, 31], [31, 32], [33, 37], [38, 41], [41, 42], [43, 47], [48, 51], [52, 54], [54, 55], [56, 60], [61, 64], [65, 67], [67, 68], [69, 73], [74, 79], [80, 81], [81, 82], [83, 86], [87, 92], [92, 93], [94, 98], [99, 100], [101, 105], [106, 114], [115, 120], [121, 130], [131, 137], [138, 142], [142, 143]]}
{"doc_key": "ai-dev-29", "ner": [[7, 8, "metrics"], [11, 14, "metrics"], [16, 17, "metrics"], [46, 49, "metrics"], [54, 57, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 14, 46, 49, "named", "", false, false], [16, 17, 11, 14, "named", "", false, false], [46, 49, 54, 57, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["It", "is", "easy", "to", "check", "that", "the", "log", "loss", "and", "the", "binary", "cross", "-entropy", "loss", "(", "Log", "loss", ")", "are", "actually", "the", "same", "(", "up", "to", "a", "multiplicative", "constant", "math", "\\", "frac", "{", "1", "}", "{", "\\", "log", "(", "2", ")", "}", "/", "math", ")", "The", "cross", "-entropy", "loss", "is", "closely", "related", "to", "the", "Kullback", "-", "Leibler", "divergence", "between", "the", "empirical", "distribution", "and", "the", "predicted", "distribution", "."], "sentence-detokenized": "It is easy to check that the log loss and the binary cross-entropy loss (Log loss) are actually the same (up to a multiplicative constant math\\ frac {1} {\\ log (2)} / math) The cross-entropy loss is closely related to the Kullback-Leibler divergence between the empirical distribution and the predicted distribution.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 19], [20, 24], [25, 28], [29, 32], [33, 37], [38, 41], [42, 45], [46, 52], [53, 58], [58, 66], [67, 71], [72, 73], [73, 76], [77, 81], [81, 82], [83, 86], [87, 95], [96, 99], [100, 104], [105, 106], [106, 108], [109, 111], [112, 113], [114, 128], [129, 137], [138, 142], [142, 143], [144, 148], [149, 150], [150, 151], [151, 152], [153, 154], [154, 155], [156, 159], [160, 161], [161, 162], [162, 163], [163, 164], [165, 166], [167, 171], [171, 172], [173, 176], [177, 182], [182, 190], [191, 195], [196, 198], [199, 206], [207, 214], [215, 217], [218, 221], [222, 230], [230, 231], [231, 238], [239, 249], [250, 257], [258, 261], [262, 271], [272, 284], [285, 288], [289, 292], [293, 302], [303, 315], [315, 316]]}
{"doc_key": "ai-dev-30", "ner": [[1, 2, "algorithm"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 1, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "EM", "algorithm", "is", "used", "to", "find", "the", "(", "local", ")", "maximum", "likelihood", "parameters", "of", "a", "statistical", "model", "in", "cases", "where", "the", "equations", "can", "not", "be", "solved", "directly", "."], "sentence-detokenized": "The EM algorithm is used to find the (local) maximum likelihood parameters of a statistical model in cases where the equations cannot be solved directly.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 32], [33, 36], [37, 38], [38, 43], [43, 44], [45, 52], [53, 63], [64, 74], [75, 77], [78, 79], [80, 91], [92, 97], [98, 100], [101, 106], [107, 112], [113, 116], [117, 126], [127, 130], [130, 133], [134, 136], [137, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-dev-31", "ner": [[9, 10, "task"], [13, 17, "task"], [22, 23, "task"], [25, 26, "task"], [33, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "research", "was", "fundamental", "to", "the", "development", "of", "modern", "speech", "synthesis", "techniques", ",", "reading", "machines", "for", "the", "blind", ",", "the", "study", "of", "speech", "perception", "and", "speech", "recognition", ",", "and", "the", "development", "of", "the", "kinetic", "theory", "of", "speech", "perception", "."], "sentence-detokenized": "This research was fundamental to the development of modern speech synthesis techniques, reading machines for the blind, the study of speech perception and speech recognition, and the development of the kinetic theory of speech perception.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 29], [30, 32], [33, 36], [37, 48], [49, 51], [52, 58], [59, 65], [66, 75], [76, 86], [86, 87], [88, 95], [96, 104], [105, 108], [109, 112], [113, 118], [118, 119], [120, 123], [124, 129], [130, 132], [133, 139], [140, 150], [151, 154], [155, 161], [162, 173], [173, 174], [175, 178], [179, 182], [183, 194], [195, 197], [198, 201], [202, 209], [210, 216], [217, 219], [220, 226], [227, 237], [237, 238]]}
{"doc_key": "ai-dev-32", "ner": [[1, 3, "product"], [4, 4, "misc"], [6, 6, "misc"], [10, 11, "misc"], [14, 14, "product"], [16, 16, "product"], [18, 18, "product"], [23, 23, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 4, 1, 3, "origin", "", false, false], [4, 4, 10, 11, "type-of", "", false, false], [4, 4, 14, 14, "related-to", "program_for", false, false], [4, 4, 16, 16, "related-to", "program_for", false, false], [4, 4, 18, 18, "related-to", "program_for", false, false], [4, 4, 23, 23, "related-to", "program_for", false, false], [6, 6, 4, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "Arduino", "Integrated", "Development", "Environment", "(", "IDE", ")", "is", "a", "multi-platform", "application", "(", "for", "Windows", ",", "macOS", "and", "Linux", ")", "written", "in", "the", "Java", "programming", "language", "."], "sentence-detokenized": "The Arduino Integrated Development Environment (IDE) is a multi-platform application (for Windows, macOS and Linux) written in the Java programming language.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 57], [58, 72], [73, 84], [85, 86], [86, 89], [90, 97], [97, 98], [99, 104], [105, 108], [109, 114], [114, 115], [116, 123], [124, 126], [127, 130], [131, 135], [136, 147], [148, 156], [156, 157]]}
{"doc_key": "ai-dev-33", "ner": [[2, 3, "algorithm"], [11, 12, "field"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 11, 12, "opposite", "", false, false], [14, 15, 11, 12, "related-to", "works_with", false, false], [17, 18, 11, 12, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Research", "on", "neural", "networks", "stagnated", "after", "the", "publication", "of", "research", "on", "machine", "learning", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", "."], "sentence-detokenized": "Research on neural networks stagnated after the publication of research on machine learning by Marvin Minsky and Seymour Papert (1969).", "token2charspan": [[0, 8], [9, 11], [12, 18], [19, 27], [28, 37], [38, 43], [44, 47], [48, 59], [60, 62], [63, 71], [72, 74], [75, 82], [83, 91], [92, 94], [95, 101], [102, 108], [109, 112], [113, 120], [121, 127], [128, 129], [129, 133], [133, 134], [134, 135]]}
{"doc_key": "ai-dev-34", "ner": [[19, 20, "organisation"], [22, 22, "organisation"], [25, 27, "country"], [29, 32, "organisation"], [35, 35, "country"], [37, 38, "organisation"], [41, 41, "country"], [43, 43, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[29, 32, 25, 27, "general-affiliation", "", false, false], [37, 38, 35, 35, "general-affiliation", "", false, false], [43, 43, 41, 41, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Only", "a", "few", "non-Japanese", "companies", "have", "finally", "managed", "to", "survive", "in", "this", "market", ",", "the", "main", "ones", "being", ":", "Adept", "Technology", ",", "St\u00e4ubli", ",", "the", "Swedish", "-", "Swiss", "company", "ABB", "Asea", "Brown", "Boveri", ",", "the", "German", "company", "KUKA", "Robotics", "and", "the", "Italian", "company", "Comau", "."], "sentence-detokenized": "Only a few non-Japanese companies have finally managed to survive in this market, the main ones being: Adept Technology, St\u00e4ubli, the Swedish-Swiss company ABB Asea Brown Boveri, the German company KUKA Robotics and the Italian company Comau.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 23], [24, 33], [34, 38], [39, 46], [47, 54], [55, 57], [58, 65], [66, 68], [69, 73], [74, 80], [80, 81], [82, 85], [86, 90], [91, 95], [96, 101], [101, 102], [103, 108], [109, 119], [119, 120], [121, 128], [128, 129], [130, 133], [134, 141], [141, 142], [142, 147], [148, 155], [156, 159], [160, 164], [165, 170], [171, 177], [177, 178], [179, 182], [183, 189], [190, 197], [198, 202], [203, 211], [212, 215], [216, 219], [220, 227], [228, 235], [236, 241], [241, 242]]}
{"doc_key": "ai-dev-35", "ner": [[9, 10, "conference"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Research", "activities", "include", "an", "annual", "research", "conference", ",", "the", "RuleML", "Symposium", ",", "also", "known", "as", "RuleML", "for", "short", "."], "sentence-detokenized": "Research activities include an annual research conference, the RuleML Symposium, also known as RuleML for short.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 30], [31, 37], [38, 46], [47, 57], [57, 58], [59, 62], [63, 69], [70, 79], [79, 80], [81, 85], [86, 91], [92, 94], [95, 101], [102, 105], [106, 111], [111, 112]]}
{"doc_key": "ai-dev-36", "ner": [[9, 9, "field"], [11, 12, "field"], [14, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Concepts", "are", "used", "as", "formal", "tools", "or", "models", "in", "mathematics", ",", "computer", "science", ",", "databases", "and", "artificial", "intelligence", ",", "where", "they", "are", "sometimes", "called", "classes", ",", "schemas", "or", "categories", "."], "sentence-detokenized": "Concepts are used as formal tools or models in mathematics, computer science, databases and artificial intelligence, where they are sometimes called classes, schemas or categories.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 33], [34, 36], [37, 43], [44, 46], [47, 58], [58, 59], [60, 68], [69, 76], [76, 77], [78, 87], [88, 91], [92, 102], [103, 115], [115, 116], [117, 122], [123, 127], [128, 131], [132, 141], [142, 148], [149, 156], [156, 157], [158, 165], [166, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-dev-37", "ner": [[6, 8, "organisation"], [11, 14, "organisation"], [17, 17, "organisation"], [20, 23, "organisation"], [27, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "won", "awards", "from", "the", "American", "Psychological", "Association", ",", "the", "National", "Academy", "of", "Sciences", ",", "the", "Royal", ",", "the", "Society", "for", "Cognitive", "Neuroscience", ",", "and", "the", "American", "Humanist", "Association", "."], "sentence-detokenized": "He has won awards from the American Psychological Association, the National Academy of Sciences, the Royal, the Society for Cognitive Neuroscience, and the American Humanist Association.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 17], [18, 22], [23, 26], [27, 35], [36, 49], [50, 61], [61, 62], [63, 66], [67, 75], [76, 83], [84, 86], [87, 95], [95, 96], [97, 100], [101, 106], [106, 107], [108, 111], [112, 119], [120, 123], [124, 133], [134, 146], [146, 147], [148, 151], [152, 155], [156, 164], [165, 173], [174, 185], [185, 186]]}
{"doc_key": "ai-dev-38", "ner": [[1, 2, "person"], [4, 5, "person"], [7, 8, "person"], [15, 16, "person"], [21, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 27, 15, 16, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starring", "Harrison", "Ford", ",", "Rutger", "Hauer", "and", "Sean", "Young", ",", "it", "'s", "loosely", "based", "on", "Philip", "K", ".", "Dick", "'s", "novel", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "?", "(", "1968", ")", "."], "sentence-detokenized": "Starring Harrison Ford, Rutger Hauer and Sean Young, it's loosely based on Philip K. Dick's novel Do Androids Dream of Electric Sheep? (1968).", "token2charspan": [[0, 8], [9, 17], [18, 22], [22, 23], [24, 30], [31, 36], [37, 40], [41, 45], [46, 51], [51, 52], [53, 55], [55, 57], [58, 65], [66, 71], [72, 74], [75, 81], [82, 83], [83, 84], [85, 89], [89, 91], [92, 97], [98, 100], [101, 109], [110, 115], [116, 118], [119, 127], [128, 133], [133, 134], [135, 136], [136, 140], [140, 141], [141, 142]]}
{"doc_key": "ai-dev-39", "ner": [[0, 1, "task"], [3, 6, "algorithm"], [11, 12, "field"], [14, 15, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 3, 6, "usage", "", false, false], [0, 1, 11, 12, "part-of", "task_part_of_field", false, false], [0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Image", "segmentation", "using", "k-means", "clustering", "algorithms", "has", "long", "been", "used", "for", "pattern", "recognition", ",", "object", "detection", "and", "medical", "imaging", "."], "sentence-detokenized": "Image segmentation using k-means clustering algorithms has long been used for pattern recognition, object detection and medical imaging.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 32], [33, 43], [44, 54], [55, 58], [59, 63], [64, 68], [69, 73], [74, 77], [78, 85], [86, 97], [97, 98], [99, 105], [106, 115], [116, 119], [120, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-dev-40", "ner": [[13, 13, "algorithm"], [17, 18, "algorithm"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["General", "sampling", "from", "the", "truncated", "normal", "can", "be", "achieved", "using", "approximations", "of", "the", "CDF", "normal", "and", "the", "probit", "function", ",", "and", "R", "has", "a", "codertnorm", "(", ")", "/", "code", "function", "for", "generating", "truncated", "normal", "samples", "."], "sentence-detokenized": "General sampling from the truncated normal can be achieved using approximations of the CDF normal and the probit function, and R has a codertnorm() / code function for generating truncated normal samples.", "token2charspan": [[0, 7], [8, 16], [17, 21], [22, 25], [26, 35], [36, 42], [43, 46], [47, 49], [50, 58], [59, 64], [65, 79], [80, 82], [83, 86], [87, 90], [91, 97], [98, 101], [102, 105], [106, 112], [113, 121], [121, 122], [123, 126], [127, 128], [129, 132], [133, 134], [135, 145], [145, 146], [146, 147], [148, 149], [150, 154], [155, 163], [164, 167], [168, 178], [179, 188], [189, 195], [196, 203], [203, 204]]}
{"doc_key": "ai-dev-41", "ner": [[9, 11, "university"], [13, 13, "university"], [15, 17, "university"], [19, 21, "university"], [24, 26, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "also", "been", "awarded", "honorary", "doctorates", "by", "the", "Universities", "of", "Newcastle", ",", "Surrey", ",", "Tel", "Aviv", "University", ",", "Simon", "Fraser", "University", "and", "the", "University", "of", "Troms\u00f8", "."], "sentence-detokenized": "He has also been awarded honorary doctorates by the Universities of Newcastle, Surrey, Tel Aviv University, Simon Fraser University and the University of Troms\u00f8.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 24], [25, 33], [34, 44], [45, 47], [48, 51], [52, 64], [65, 67], [68, 77], [77, 78], [79, 85], [85, 86], [87, 90], [91, 95], [96, 106], [106, 107], [108, 113], [114, 120], [121, 131], [132, 135], [136, 139], [140, 150], [151, 153], [154, 160], [160, 161]]}
{"doc_key": "ai-dev-42", "ner": [[1, 1, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "Java", "implementation", "that", "uses", "zero", "-", "based", "array", "pointers", "along", "with", "a", "convenience", "method", "for", "printing", "the", "solved", "array", "of", "operations", ":"], "sentence-detokenized": "A Java implementation that uses zero-based array pointers along with a convenience method for printing the solved array of operations:", "token2charspan": [[0, 1], [2, 6], [7, 21], [22, 26], [27, 31], [32, 36], [36, 37], [37, 42], [43, 48], [49, 57], [58, 63], [64, 68], [69, 70], [71, 82], [83, 89], [90, 93], [94, 102], [103, 106], [107, 113], [114, 119], [120, 122], [123, 133], [133, 134]]}
{"doc_key": "ai-dev-43", "ner": [[6, 7, "metrics"], [10, 11, "metrics"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Such", "networks", "are", "usually", "trained", "under", "cross", "entropy", "(", "or", "cross", "-entropy", ")", ",", "giving", "a", "non-linear", "variant", "of", "polynomial", "logistic", "regression", "."], "sentence-detokenized": "Such networks are usually trained under cross entropy (or cross-entropy), giving a non-linear variant of polynomial logistic regression.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 25], [26, 33], [34, 39], [40, 45], [46, 53], [54, 55], [55, 57], [58, 63], [63, 71], [71, 72], [72, 73], [74, 80], [81, 82], [83, 93], [94, 101], [102, 104], [105, 115], [116, 124], [125, 135], [135, 136]]}
{"doc_key": "ai-dev-44", "ner": [[0, 0, "conference"], [3, 4, "misc"], [6, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["ACL", "has", "a", "European", "chapter", "(", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ")"], "sentence-detokenized": "ACL has a European chapter (European Chapter of the Association for Computational Linguistics)", "token2charspan": [[0, 3], [4, 7], [8, 9], [10, 18], [19, 26], [27, 28], [28, 36], [37, 44], [45, 47], [48, 51], [52, 63], [64, 67], [68, 81], [82, 93], [93, 94]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 8, "researcher"], [22, 22, "misc"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 22, 22, "role", "", false, false], [6, 8, 22, 22, "role", "", false, false], [22, 22, 25, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "professors", ",", "Hal", "Abelson", "and", "Gerald", "Jay", "Sussman", ",", "chose", "to", "remain", "neutral", "-", "their", "group", "was", "variously", "referred", "to", "as", "Switzerland", "and", "the", "MAC", "Project", "for", "the", "next", "30", "years", "."], "sentence-detokenized": "Two professors, Hal Abelson and Gerald Jay Sussman, chose to remain neutral - their group was variously referred to as Switzerland and the MAC Project for the next 30 years.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 50], [50, 51], [52, 57], [58, 60], [61, 67], [68, 75], [76, 77], [78, 83], [84, 89], [90, 93], [94, 103], [104, 112], [113, 115], [116, 118], [119, 130], [131, 134], [135, 138], [139, 142], [143, 150], [151, 154], [155, 158], [159, 163], [164, 166], [167, 172], [172, 173]]}
{"doc_key": "ai-dev-46", "ner": [[2, 2, "misc"], [4, 4, "researcher"], [8, 10, "university"], [15, 19, "organisation"], [20, 22, "organisation"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 4, 4, "temporal", "", false, false], [4, 4, 15, 19, "physical", "", false, false], [4, 4, 15, 19, "role", "", false, false], [4, 4, 20, 22, "role", "", false, false], [20, 22, 8, 10, "part-of", "", false, false], [26, 27, 20, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["After", "his", "PhD", ",", "Ghahramani", "moved", "to", "the", "University", "of", "Toronto", "in", "1995", "as", "an", "ITRC", "postdoctoral", "fellow", "in", "the", "Artificial", "Intelligence", "Laboratory", ",", "working", "with", "Geoffrey", "Hinton", "."], "sentence-detokenized": "After his PhD, Ghahramani moved to the University of Toronto in 1995 as an ITRC postdoctoral fellow in the Artificial Intelligence Laboratory, working with Geoffrey Hinton.", "token2charspan": [[0, 5], [6, 9], [10, 13], [13, 14], [15, 25], [26, 31], [32, 34], [35, 38], [39, 49], [50, 52], [53, 60], [61, 63], [64, 68], [69, 71], [72, 74], [75, 79], [80, 92], [93, 99], [100, 102], [103, 106], [107, 117], [118, 130], [131, 141], [141, 142], [143, 150], [151, 155], [156, 164], [165, 171], [171, 172]]}
{"doc_key": "ai-dev-47", "ner": [[24, 28, "metrics"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Subsequent", "work", "focused", "on", "addressing", "these", "problems", ",", "but", "research", "only", "really", "took", "off", "with", "the", "advent", "of", "modern", "computers", "and", "the", "spread", "of", "Maximum", "Likelihood", "Estimation", "(", "MLE", ")", "parameterization", "techniques", "."], "sentence-detokenized": "Subsequent work focused on addressing these problems, but research only really took off with the advent of modern computers and the spread of Maximum Likelihood Estimation (MLE) parameterization techniques.", "token2charspan": [[0, 10], [11, 15], [16, 23], [24, 26], [27, 37], [38, 43], [44, 52], [52, 53], [54, 57], [58, 66], [67, 71], [72, 78], [79, 83], [84, 87], [88, 92], [93, 96], [97, 103], [104, 106], [107, 113], [114, 123], [124, 127], [128, 131], [132, 138], [139, 141], [142, 149], [150, 160], [161, 171], [172, 173], [173, 176], [176, 177], [178, 194], [195, 205], [205, 206]]}
{"doc_key": "ai-dev-48", "ner": [[5, 6, "person"], [9, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "series", "was", "produced", "by", "David", "Fincher", "and", "starred", "Kevin", "Spacey", "."], "sentence-detokenized": "The series was produced by David Fincher and starred Kevin Spacey.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 40], [41, 44], [45, 52], [53, 58], [59, 65], [65, 66]]}
{"doc_key": "ai-dev-49", "ner": [[17, 17, "metrics"], [22, 23, "algorithm"], [29, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 23, 29, 31, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Due", "to", "limitations", "in", "computational", "power", ",", "current", "in", "silico", "methods", "usually", "have", "to", "trade", "speed", "for", "accuracy", ",", "e.g.", "using", "fast", "protein", "binding", "methods", "instead", "of", "computationally", "expensive", "free", "energy", "calculations", "."], "sentence-detokenized": "Due to limitations in computational power, current in silico methods usually have to trade speed for accuracy, e.g. using fast protein binding methods instead of computationally expensive free energy calculations.", "token2charspan": [[0, 3], [4, 6], [7, 18], [19, 21], [22, 35], [36, 41], [41, 42], [43, 50], [51, 53], [54, 60], [61, 68], [69, 76], [77, 81], [82, 84], [85, 90], [91, 96], [97, 100], [101, 109], [109, 110], [111, 115], [116, 121], [122, 126], [127, 134], [135, 142], [143, 150], [151, 158], [159, 161], [162, 177], [178, 187], [188, 192], [193, 199], [200, 212], [212, 213]]}
{"doc_key": "ai-dev-50", "ner": [[7, 7, "country"], [9, 9, "country"], [11, 11, "country"], [13, 13, "country"], [15, 15, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "had", "over", "30", "locations", "in", "the", "US", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "sentence-detokenized": "He had over 30 locations in the US, Canada, Mexico, Brazil and Argentina.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 24], [25, 27], [28, 31], [32, 34], [34, 35], [36, 42], [42, 43], [44, 50], [50, 51], [52, 58], [59, 62], [63, 72], [72, 73]]}
{"doc_key": "ai-dev-51", "ner": [[6, 6, "field"], [10, 12, "product"], [14, 16, "algorithm"], [20, 21, "task"], [23, 24, "task"], [31, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 12, 6, 6, "part-of", "", false, false], [10, 12, 14, 16, "usage", "", false, false], [20, 21, 6, 6, "part-of", "task_part_of_field", false, false], [20, 21, 31, 31, "related-to", "performs", false, false], [23, 24, 6, 6, "part-of", "task_part_of_field", false, false], [23, 24, 31, 31, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["An", "example", "of", "a", "typical", "computer", "vision", "pipeline", "for", "a", "face", "recognition", "system", "using", "k", "-", "NN", ",", "including", "the", "feature", "extraction", "and", "dimensionality", "reduction", "preprocessing", "steps", "(", "typically", "implemented", "with", "OpenCV", ")", ":"], "sentence-detokenized": "An example of a typical computer vision pipeline for a face recognition system using k -NN, including the feature extraction and dimensionality reduction preprocessing steps (typically implemented with OpenCV):", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 23], [24, 32], [33, 39], [40, 48], [49, 52], [53, 54], [55, 59], [60, 71], [72, 78], [79, 84], [85, 86], [87, 88], [88, 90], [90, 91], [92, 101], [102, 105], [106, 113], [114, 124], [125, 128], [129, 143], [144, 153], [154, 167], [168, 173], [174, 175], [175, 184], [185, 196], [197, 201], [202, 208], [208, 209], [209, 210]]}
{"doc_key": "ai-dev-52", "ner": [[9, 11, "algorithm"], [13, 13, "misc"], [15, 16, "misc"], [18, 18, "misc"], [22, 22, "programlang"], [24, 24, "product"], [28, 29, "algorithm"], [31, 32, "misc"], [34, 34, "misc"], [36, 36, "misc"], [38, 38, "misc"], [45, 45, "misc"], [47, 48, "misc"], [50, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "a", "rich", "feature", "set", ",", "libraries", "for", "constraint", "logic", "programming", ",", "multithreading", ",", "unit", "testing", ",", "GUI", ",", "interface", "with", "Java", ",", "ODBC", "and", "others", ",", "grammar", "programming", ",", "web", "server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "development", "tools", "(", "including", "an", "IDE", "with", "GUI", "debugger", "and", "GUI", "profiler", ")", "and", "extensive", "documentation", "."], "sentence-detokenized": "It has a rich feature set, libraries for constraint logic programming, multithreading, unit testing, GUI, interface with Java, ODBC and others, grammar programming, web server, SGML, RDF, RDFS, development tools (including an IDE with GUI debugger and GUI profiler) and extensive documentation.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 13], [14, 21], [22, 25], [25, 26], [27, 36], [37, 40], [41, 51], [52, 57], [58, 69], [69, 70], [71, 85], [85, 86], [87, 91], [92, 99], [99, 100], [101, 104], [104, 105], [106, 115], [116, 120], [121, 125], [125, 126], [127, 131], [132, 135], [136, 142], [142, 143], [144, 151], [152, 163], [163, 164], [165, 168], [169, 175], [175, 176], [177, 181], [181, 182], [183, 186], [186, 187], [188, 192], [192, 193], [194, 205], [206, 211], [212, 213], [213, 222], [223, 225], [226, 229], [230, 234], [235, 238], [239, 247], [248, 251], [252, 255], [256, 264], [264, 265], [266, 269], [270, 279], [280, 293], [293, 294]]}
{"doc_key": "ai-dev-53", "ner": [[1, 2, "field"], [4, 5, "field"], [10, 12, "misc"], [14, 16, "misc"], [19, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 1, 2, "part-of", "", true, false], [10, 12, 4, 5, "part-of", "", false, false], [10, 12, 19, 22, "type-of", "", false, false], [14, 16, 1, 2, "part-of", "", false, false], [14, 16, 4, 5, "part-of", "", false, false], [14, 16, 19, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "computer", "vision", "and", "image", "processing", ",", "the", "concept", "of", "scale", "space", "representation", "and", "Gaussian", "derivative", "operators", "is", "a", "regular", "multi", "-scale", "representation", "."], "sentence-detokenized": "In computer vision and image processing, the concept of scale space representation and Gaussian derivative operators is a regular multi-scale representation.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 22], [23, 28], [29, 39], [39, 40], [41, 44], [45, 52], [53, 55], [56, 61], [62, 67], [68, 82], [83, 86], [87, 95], [96, 106], [107, 116], [117, 119], [120, 121], [122, 129], [130, 135], [135, 141], [142, 156], [156, 157]]}
{"doc_key": "ai-dev-54", "ner": [[6, 10, "organisation"], [19, 23, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 10, 19, 23, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "also", "president", "of", "the", "Neural", "Information", "Processing", "Systems", "Foundation", ",", "a", "non-profit", "organization", "that", "oversees", "the", "annual", "Neural", "Information", "Processing", "Systems", "Conference", "."], "sentence-detokenized": "He is also president of the Neural Information Processing Systems Foundation, a non-profit organization that oversees the annual Neural Information Processing Systems Conference.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 20], [21, 23], [24, 27], [28, 34], [35, 46], [47, 57], [58, 65], [66, 76], [76, 77], [78, 79], [80, 90], [91, 103], [104, 108], [109, 117], [118, 121], [122, 128], [129, 135], [136, 147], [148, 158], [159, 166], [167, 177], [177, 178]]}
{"doc_key": "ai-dev-55", "ner": [[1, 2, "task"], [6, 12, "metrics"], [13, 14, "misc"], [18, 18, "task"], [20, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 6, 12, "usage", "", false, false], [6, 12, 13, 14, "type-of", "", false, false], [18, 18, 20, 23, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["For", "regression", "analysis", "problems", ",", "the", "squared", "error", "can", "be", "used", "as", "a", "loss", "function", ",", "while", "for", "classification", ",", "cross", "-entropy", "can", "be", "used", "."], "sentence-detokenized": "For regression analysis problems, the squared error can be used as a loss function, while for classification, cross-entropy can be used.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 32], [32, 33], [34, 37], [38, 45], [46, 51], [52, 55], [56, 58], [59, 63], [64, 66], [67, 68], [69, 73], [74, 82], [82, 83], [84, 89], [90, 93], [94, 108], [108, 109], [110, 115], [115, 123], [124, 127], [128, 130], [131, 135], [135, 136]]}
{"doc_key": "ai-dev-56", "ner": [[0, 0, "researcher"], [15, 15, "university"], [17, 19, "field"], [28, 32, "conference"]], "ner_mapping_to_source": [0, 3, 4, 5], "relations": [[0, 0, 15, 15, "physical", "", false, false], [0, 0, 15, 15, "role", "", false, false], [0, 0, 28, 32, "role", "", false, false], [15, 15, 17, 19, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [1, 2, 3, 5], "sentence": ["Lafferty", "has", "served", "in", "many", "prestigious", "positions", ",", "including", ":", "2", ")", "co-director", "of", "CMU", "'s", "new", "machine", "learning", "doctoral", "program", ";", "3", ")", "associate", "editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research"], "sentence-detokenized": "Lafferty has served in many prestigious positions, including: 2) co-director of CMU's new machine learning doctoral program; 3) associate editor of the Journal of Machine Learning Research", "token2charspan": [[0, 8], [9, 12], [13, 19], [20, 22], [23, 27], [28, 39], [40, 49], [49, 50], [51, 60], [60, 61], [62, 63], [63, 64], [65, 76], [77, 79], [80, 83], [83, 85], [86, 89], [90, 97], [98, 106], [107, 115], [116, 123], [123, 124], [125, 126], [126, 127], [128, 137], [138, 144], [145, 147], [148, 151], [152, 159], [160, 162], [163, 170], [171, 179], [180, 188]]}
{"doc_key": "ai-dev-57", "ner": [[0, 1, "misc"], [5, 5, "algorithm"], [7, 7, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 1, "type-of", "", false, false], [7, 7, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Convex", "algorithms", ",", "such", "as", "AdaBoost", "and", "LogitBoost", ",", "can", "be", "defeated", "by", "random", "noise", ",", "so", "they", "can", "not", "learn", "basic", "and", "learning", "combinations", "of", "weak", "hypotheses", "."], "sentence-detokenized": "Convex algorithms, such as AdaBoost and LogitBoost, can be defeated by random noise, so they cannot learn basic and learning combinations of weak hypotheses.", "token2charspan": [[0, 6], [7, 17], [17, 18], [19, 23], [24, 26], [27, 35], [36, 39], [40, 50], [50, 51], [52, 55], [56, 58], [59, 67], [68, 70], [71, 77], [78, 83], [83, 84], [85, 87], [88, 92], [93, 96], [96, 99], [100, 105], [106, 111], [112, 115], [116, 124], [125, 137], [138, 140], [141, 145], [146, 156], [156, 157]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [3, 8, "product"], [12, 15, "algorithm"], [22, 23, "algorithm"], [26, 31, "task"], [33, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 8, "type-of", "", false, false], [0, 0, 12, 15, "usage", "", false, false], [0, 0, 22, 23, "usage", "", false, false], [22, 23, 26, 31, "related-to", "used_for", true, false], [22, 23, 33, 35, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "is", "a", "machine", "translation", "system", "with", "shallow", "translation", ",", "which", "uses", "finite", "-", "state", "transducers", "for", "all", "its", "lexical", "transformations", "and", "hidden", "Markov", "models", "for", "part", "-", "of", "-", "speech", "highlighting", "or", "word", "class", "disambiguation", "."], "sentence-detokenized": "Apertium is a machine translation system with shallow translation, which uses finite-state transducers for all its lexical transformations and hidden Markov models for part-of-speech highlighting or word class disambiguation.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 21], [22, 33], [34, 40], [41, 45], [46, 53], [54, 65], [65, 66], [67, 72], [73, 77], [78, 84], [84, 85], [85, 90], [91, 102], [103, 106], [107, 110], [111, 114], [115, 122], [123, 138], [139, 142], [143, 149], [150, 156], [157, 163], [164, 167], [168, 172], [172, 173], [173, 175], [175, 176], [176, 182], [183, 195], [196, 198], [199, 203], [204, 209], [210, 224], [224, 225]]}
{"doc_key": "ai-dev-59", "ner": [[1, 3, "misc"], [16, 18, "metrics"], [32, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 3, 16, 18, "related-to", "", true, false], [16, 18, 32, 33, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "natural", "gradient", "of", "mathE", "f", "(", "x", ")", "/", "math", ",", "which", "conforms", "to", "the", "Fisher", "information", "metric", "(", "an", "informative", "measure", "of", "distance", "between", "probability", "distributions", "and", "the", "curvature", "of", "relative", "entropy", ")", ",", "is", "now", "as", "follows"], "sentence-detokenized": "The natural gradient of mathE f (x)/math, which conforms to the Fisher information metric (an informative measure of distance between probability distributions and the curvature of relative entropy), is now as follows", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 23], [24, 29], [30, 31], [32, 33], [33, 34], [34, 35], [35, 36], [36, 40], [40, 41], [42, 47], [48, 56], [57, 59], [60, 63], [64, 70], [71, 82], [83, 89], [90, 91], [91, 93], [94, 105], [106, 113], [114, 116], [117, 125], [126, 133], [134, 145], [146, 159], [160, 163], [164, 167], [168, 177], [178, 180], [181, 189], [190, 197], [197, 198], [198, 199], [200, 202], [203, 206], [207, 209], [210, 217]]}
{"doc_key": "ai-dev-60", "ner": [[0, 3, "programlang"], [6, 9, "product"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 0, 3, "origin", "", false, false], [11, 11, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "S", "programming", "language", "inspired", "the", "S", "'", "-", "PLUS", "and", "R", "systems", "."], "sentence-detokenized": "The S programming language inspired the S'-PLUS and R systems.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 26], [27, 35], [36, 39], [40, 41], [41, 42], [42, 43], [43, 47], [48, 51], [52, 53], [54, 61], [61, 62]]}
{"doc_key": "ai-dev-61", "ner": [[5, 5, "product"], [10, 10, "product"], [16, 18, "product"], [22, 24, "researcher"], [26, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 10, 10, "named", "same", false, false], [16, 18, 10, 10, "origin", "derived_from", false, false], [16, 18, 22, 24, "origin", "", false, false], [16, 18, 26, 27, "origin", "", false, false], [16, 18, 29, 30, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "most", "influential", "implementation", "of", "Planner", "was", "the", "subset", "of", "Planner", ",", "the", "so", "-", "called", "Micro", "-", "Planner", ",", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "."], "sentence-detokenized": "The most influential implementation of Planner was the subset of Planner, the so-called Micro-Planner, implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 35], [36, 38], [39, 46], [47, 50], [51, 54], [55, 61], [62, 64], [65, 72], [72, 73], [74, 77], [78, 80], [80, 81], [81, 87], [88, 93], [93, 94], [94, 101], [101, 102], [103, 114], [115, 117], [118, 124], [125, 128], [129, 136], [136, 137], [138, 144], [145, 153], [154, 157], [158, 163], [164, 172], [172, 173]]}
{"doc_key": "ai-dev-62", "ner": [[3, 5, "country"], [7, 9, "researcher"], [19, 19, "misc"], [20, 25, "university"], [32, 33, "misc"], [40, 40, "misc"], [47, 49, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[7, 9, 3, 5, "general-affiliation", "from_country", false, false], [20, 25, 19, 19, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1779", "the", "German", "-", "Danish", "scientist", "Christian", "Gottlieb", "Kratzenstein", "won", "first", "prize", "in", "a", "competition", "announced", "by", "the", "Russian", "Imperial", "Academy", "of", "Sciences", "and", "Arts", "for", "his", "models", "of", "the", "human", "vocal", "tract", "that", "could", "produce", "the", "five", "long", "phonemes", "(", "in", "the", "notation", "of", "the", "International", "Phonetic", "Alphabet", ":"], "sentence-detokenized": "In 1779 the German-Danish scientist Christian Gottlieb Kratzenstein won first prize in a competition announced by the Russian Imperial Academy of Sciences and Arts for his models of the human vocal tract that could produce the five long phonemes (in the notation of the International Phonetic Alphabet:", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 18], [18, 19], [19, 25], [26, 35], [36, 45], [46, 54], [55, 67], [68, 71], [72, 77], [78, 83], [84, 86], [87, 88], [89, 100], [101, 110], [111, 113], [114, 117], [118, 125], [126, 134], [135, 142], [143, 145], [146, 154], [155, 158], [159, 163], [164, 167], [168, 171], [172, 178], [179, 181], [182, 185], [186, 191], [192, 197], [198, 203], [204, 208], [209, 214], [215, 222], [223, 226], [227, 231], [232, 236], [237, 245], [246, 247], [247, 249], [250, 253], [254, 262], [263, 265], [266, 269], [270, 283], [284, 292], [293, 301], [301, 302]]}
{"doc_key": "ai-dev-63", "ner": [[3, 4, "product"], [6, 7, "misc"], [10, 14, "misc"], [32, 32, "misc"], [55, 56, "task"], [61, 62, "product"], [64, 64, "product"], [70, 73, "task"], [72, 72, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 4, 61, 62, "related-to", "supports_program", false, false], [3, 4, 64, 64, "related-to", "supports_program", false, false], [6, 7, 3, 4, "part-of", "", false, false], [10, 14, 3, 4, "part-of", "", false, false], [32, 32, 3, 4, "part-of", "", false, false], [55, 56, 3, 4, "part-of", "", false, false], [70, 73, 3, 4, "part-of", "", false, false], [72, 72, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["New", "features", "in", "Office", "XP", "include", "smart", "labels", ",", "a", "selection", "-", "based", "search", "function", "that", "recognizes", "different", "types", "of", "text", "in", "a", "document", "so", "users", "can", "perform", "additional", "actions", ",", "an", "interface", "that", "consolidates", "popular", "menu", "bar", "commands", "on", "the", "right", "side", "of", "the", "screen", "to", "make", "them", "easier", "to", "access", "quickly", ",", "new", "document", "collaboration", "features", ",", "support", "for", "MSN", "Groups", "and", "SharePoint", ",", "and", "built", "-", "in", "handwriting", "and", "speech", "recognition", "capabilities", "."], "sentence-detokenized": "New features in Office XP include smart labels, a selection-based search function that recognizes different types of text in a document so users can perform additional actions, an interface that consolidates popular menu bar commands on the right side of the screen to make them easier to access quickly, new document collaboration features, support for MSN Groups and SharePoint, and built-in handwriting and speech recognition capabilities.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 25], [26, 33], [34, 39], [40, 46], [46, 47], [48, 49], [50, 59], [59, 60], [60, 65], [66, 72], [73, 81], [82, 86], [87, 97], [98, 107], [108, 113], [114, 116], [117, 121], [122, 124], [125, 126], [127, 135], [136, 138], [139, 144], [145, 148], [149, 156], [157, 167], [168, 175], [175, 176], [177, 179], [180, 189], [190, 194], [195, 207], [208, 215], [216, 220], [221, 224], [225, 233], [234, 236], [237, 240], [241, 246], [247, 251], [252, 254], [255, 258], [259, 265], [266, 268], [269, 273], [274, 278], [279, 285], [286, 288], [289, 295], [296, 303], [303, 304], [305, 308], [309, 317], [318, 331], [332, 340], [340, 341], [342, 349], [350, 353], [354, 357], [358, 364], [365, 368], [369, 379], [379, 380], [381, 384], [385, 390], [390, 391], [391, 393], [394, 405], [406, 409], [410, 416], [417, 428], [429, 441], [441, 442]]}
{"doc_key": "ai-dev-64", "ner": [[11, 12, "algorithm"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 15, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "many", "embodiments", ",", "the", "units", "of", "these", "networks", "implement", "a", "sigmoid", "function", "as", "an", "activation", "function", "."], "sentence-detokenized": "In many embodiments, the units of these networks implement a sigmoid function as an activation function.", "token2charspan": [[0, 2], [3, 7], [8, 19], [19, 20], [21, 24], [25, 30], [31, 33], [34, 39], [40, 48], [49, 58], [59, 60], [61, 68], [69, 77], [78, 80], [81, 83], [84, 94], [95, 103], [103, 104]]}
{"doc_key": "ai-dev-65", "ner": [[3, 3, "researcher"], [12, 17, "organisation"], [28, 34, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 12, 17, "role", "", false, false], [3, 3, 28, 34, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2001", ",", "Mehler", "was", "elected", "an", "honorary", "foreign", "member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "in", "2003", "he", "was", "elected", "a", "fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In 2001, Mehler was elected an honorary foreign member of the American Academy of Arts and Sciences and in 2003 he was elected a fellow of the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 27], [28, 30], [31, 39], [40, 47], [48, 54], [55, 57], [58, 61], [62, 70], [71, 78], [79, 81], [82, 86], [87, 90], [91, 99], [100, 103], [104, 106], [107, 111], [112, 114], [115, 118], [119, 126], [127, 128], [129, 135], [136, 138], [139, 142], [143, 151], [152, 163], [164, 167], [168, 171], [172, 183], [184, 186], [187, 194], [194, 195]]}
{"doc_key": "ai-dev-66", "ner": [[4, 6, "task"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 9, 10, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Extending", "this", "concept", "to", "non", "-binary", "classifications", "gives", "the", "confusion", "matrix", "."], "sentence-detokenized": "Extending this concept to non-binary classifications gives the confusion matrix.", "token2charspan": [[0, 9], [10, 14], [15, 22], [23, 25], [26, 29], [29, 36], [37, 52], [53, 58], [59, 62], [63, 72], [73, 79], [79, 80]]}
{"doc_key": "ai-dev-67", "ner": [[14, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "updated", "estimate", "of", "the", "variation", "in", "measurement", "noise", "can", "be", "obtained", "from", "the", "maximum", "likelihood", "calculation"], "sentence-detokenized": "An updated estimate of the variation in measurement noise can be obtained from the maximum likelihood calculation", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 22], [23, 26], [27, 36], [37, 39], [40, 51], [52, 57], [58, 61], [62, 64], [65, 73], [74, 78], [79, 82], [83, 90], [91, 101], [102, 113]]}
{"doc_key": "ai-dev-68", "ner": [[1, 2, "field"], [4, 4, "algorithm"], [9, 10, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 9, 10, "usage", "", true, false], [4, 4, 12, 13, "related-to", "", true, false], [9, 10, 1, 2, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "machine", "learning", ",", "perceptron", "is", "an", "algorithm", "for", "supervised", "learning", "of", "binary", "classification", "."], "sentence-detokenized": "In machine learning, perceptron is an algorithm for supervised learning of binary classification.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 31], [32, 34], [35, 37], [38, 47], [48, 51], [52, 62], [63, 71], [72, 74], [75, 81], [82, 96], [96, 97]]}
{"doc_key": "ai-dev-69", "ner": [[5, 6, "field"], [8, 8, "field"], [13, 18, "conference"], [21, 25, "conference"], [28, 34, "conference"], [37, 41, "conference"], [45, 49, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 18, 5, 6, "topic", "", false, false], [13, 18, 8, 8, "topic", "", false, false], [21, 25, 5, 6, "topic", "", false, false], [21, 25, 8, 8, "topic", "", false, false], [28, 34, 5, 6, "topic", "", false, false], [28, 34, 8, 8, "topic", "", false, false], [37, 41, 5, 6, "topic", "", false, false], [37, 41, 8, 8, "topic", "", false, false], [45, 49, 5, 6, "topic", "", false, false], [45, 49, 8, 8, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["He", "has", "also", "chaired", "several", "machine", "learning", "and", "vision", "conferences", ",", "including", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "the", "International", "Conference", "on", "Learning", "Representations", ",", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "the", "International", "Conference", "on", "Computer", "Vision", ",", "and", "the", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "He has also chaired several machine learning and vision conferences, including the Conference on Neural Information Processing Systems, the International Conference on Learning Representations, the Conference on Computer Vision and Pattern Recognition, the International Conference on Computer Vision, and the European Conference on Computer Vision.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 27], [28, 35], [36, 44], [45, 48], [49, 55], [56, 67], [67, 68], [69, 78], [79, 82], [83, 93], [94, 96], [97, 103], [104, 115], [116, 126], [127, 134], [134, 135], [136, 139], [140, 153], [154, 164], [165, 167], [168, 176], [177, 192], [192, 193], [194, 197], [198, 208], [209, 211], [212, 220], [221, 227], [228, 231], [232, 239], [240, 251], [251, 252], [253, 256], [257, 270], [271, 281], [282, 284], [285, 293], [294, 300], [300, 301], [302, 305], [306, 309], [310, 318], [319, 329], [330, 332], [333, 341], [342, 348], [348, 349]]}
{"doc_key": "ai-dev-70", "ner": [[1, 2, "algorithm"], [9, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 1, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "condensation", "algorithm", "has", "also", "been", "used", "for", "the", "face", "recognition", "system", "in", "a", "video", "sequence", "."], "sentence-detokenized": "The condensation algorithm has also been used for the face recognition system in a video sequence.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 30], [31, 35], [36, 40], [41, 45], [46, 49], [50, 53], [54, 58], [59, 70], [71, 77], [78, 80], [81, 82], [83, 88], [89, 97], [97, 98]]}
{"doc_key": "ai-dev-71", "ner": [[0, 1, "task"], [6, 11, "organisation"], [20, 20, "conference"], [25, 29, "academicjournal"], [32, 32, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 20, 0, 1, "topic", "", false, false], [20, 20, 6, 11, "origin", "", false, false], [25, 29, 0, 1, "topic", "", false, false], [25, 29, 6, 11, "origin", "", true, false], [32, 32, 25, 29, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Information", "dissemination", "is", "also", "part", "of", "ELRA", "'s", "missions", ",", "which", "is", "carried", "out", "both", "through", "the", "organisation", "of", "the", "LREC", "conference", "and", "through", "the", "Language", "Resources", "and", "Evaluation", "Journal", "published", "by", "Springer", "."], "sentence-detokenized": "Information dissemination is also part of ELRA's missions, which is carried out both through the organisation of the LREC conference and through the Language Resources and Evaluation Journal published by Springer.", "token2charspan": [[0, 11], [12, 25], [26, 28], [29, 33], [34, 38], [39, 41], [42, 46], [46, 48], [49, 57], [57, 58], [59, 64], [65, 67], [68, 75], [76, 79], [80, 84], [85, 92], [93, 96], [97, 109], [110, 112], [113, 116], [117, 121], [122, 132], [133, 136], [137, 144], [145, 148], [149, 157], [158, 167], [168, 171], [172, 182], [183, 190], [191, 200], [201, 203], [204, 212], [212, 213]]}
{"doc_key": "ai-dev-72", "ner": [[1, 7, "field"], [9, 10, "field"], [12, 14, "field"], [16, 17, "field"], [53, 55, "field"], [59, 59, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 7, 53, 55, "named", "", false, false], [12, 14, 1, 7, "named", "", false, false], [59, 59, 9, 10, "part-of", "", true, false], [59, 59, 12, 14, "part-of", "", true, false], [59, 59, 53, 55, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "linear", "time", "invariant", "(", "LTI", ")", "theory", ",", "control", "theory", "and", "digital", "signal", "processing", "or", "signal", "processing", ",", "the", "relationship", "between", "the", "input", "signal", ",", "math", "\\", "displaystyle", "x", "(", "t", ")", "/", "math", ",", "and", "the", "output", "signal", ",", "math", "\\", "displaystyle", "y", "(", "t", ")", "/", "math", ",", "of", "an", "LTI", "system", "is", "governed", "by", "a", "convolution", "operation", ":"], "sentence-detokenized": "In linear time invariant (LTI) theory, control theory and digital signal processing or signal processing, the relationship between the input signal, math\\ displaystyle x(t)/math, and the output signal, math\\ displaystyle y(t)/math, of an LTI system is governed by a convolution operation:", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 24], [25, 26], [26, 29], [29, 30], [31, 37], [37, 38], [39, 46], [47, 53], [54, 57], [58, 65], [66, 72], [73, 83], [84, 86], [87, 93], [94, 104], [104, 105], [106, 109], [110, 122], [123, 130], [131, 134], [135, 140], [141, 147], [147, 148], [149, 153], [153, 154], [155, 167], [168, 169], [169, 170], [170, 171], [171, 172], [172, 173], [173, 177], [177, 178], [179, 182], [183, 186], [187, 193], [194, 200], [200, 201], [202, 206], [206, 207], [208, 220], [221, 222], [222, 223], [223, 224], [224, 225], [225, 226], [226, 230], [230, 231], [232, 234], [235, 237], [238, 241], [242, 248], [249, 251], [252, 260], [261, 263], [264, 265], [266, 277], [278, 287], [287, 288]]}
{"doc_key": "ai-dev-73", "ner": [[16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 31, "field"], [33, 34, "product"], [36, 37, "field"], [39, 39, "field"], [42, 43, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Because", "of", "its", "generality", ",", "the", "field", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimization", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", ",", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Because of its generality, the field is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics, and genetic algorithms.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [25, 26], [27, 30], [31, 36], [37, 39], [40, 47], [48, 50], [51, 55], [56, 61], [62, 73], [73, 74], [75, 79], [80, 82], [83, 87], [88, 94], [94, 95], [96, 103], [104, 110], [110, 111], [112, 122], [123, 131], [131, 132], [133, 144], [145, 151], [151, 152], [153, 163], [163, 164], [164, 169], [170, 182], [182, 183], [184, 195], [196, 203], [203, 204], [205, 210], [211, 223], [223, 224], [225, 235], [235, 236], [237, 240], [241, 248], [249, 259], [259, 260]]}
{"doc_key": "ai-dev-74", "ner": [[0, 2, "algorithm"], [15, 16, "field"], [22, 23, "algorithm"], [26, 27, "algorithm"], [33, 34, "algorithm"], [38, 38, "algorithm"], [39, 41, "researcher"], [43, 44, "researcher"], [46, 48, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[15, 16, 0, 2, "usage", "", true, false], [22, 23, 15, 16, "part-of", "", true, false], [26, 27, 15, 16, "part-of", "", true, false], [33, 34, 15, 16, "part-of", "", true, false], [38, 38, 15, 16, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Stochastic", "gradient", "descent", "is", "a", "popular", "algorithm", "for", "training", "a", "wide", "range", "of", "models", "in", "machine", "learning", ",", "including", "(", "linear", ")", "support", "vector", "machines", ",", "logistic", "regression", "(", "see", ",", "e.g.", ",", "Vowpal", "Wabbit", ")", ",", "and", "graphical", "models.Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastic gradient descent is a popular algorithm for training a wide range of models in machine learning, including (linear) support vector machines, logistic regression (see, e.g. , Vowpal Wabbit), and graphical models.Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 30], [31, 32], [33, 40], [41, 50], [51, 54], [55, 63], [64, 65], [66, 70], [71, 76], [77, 79], [80, 86], [87, 89], [90, 97], [98, 106], [106, 107], [108, 117], [118, 119], [119, 125], [125, 126], [127, 134], [135, 141], [142, 150], [150, 151], [152, 160], [161, 171], [172, 173], [173, 176], [176, 177], [178, 182], [183, 184], [185, 191], [192, 198], [198, 199], [199, 200], [201, 204], [205, 214], [215, 227], [228, 232], [233, 239], [239, 240], [241, 245], [246, 253], [253, 254], [255, 266], [267, 269], [270, 277], [278, 279], [279, 283], [283, 284], [284, 285]]}
{"doc_key": "ai-dev-75", "ner": [[7, 7, "organisation"], [11, 13, "product"], [16, 16, "country"], [22, 25, "university"], [27, 27, "location"], [30, 32, "university"], [34, 34, "location"], [36, 37, "university"], [39, 39, "location"], [41, 43, "university"], [45, 45, "location"], [47, 48, "university"], [50, 50, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[7, 7, 22, 25, "role", "donates_to", false, false], [7, 7, 30, 32, "role", "donates_to", false, false], [7, 7, 36, 37, "role", "donates_to", false, false], [7, 7, 41, 43, "role", "donates_to", false, false], [7, 7, 47, 48, "role", "donates_to", false, false], [11, 13, 7, 7, "origin", "donates", true, false], [22, 25, 27, 27, "physical", "", false, false], [27, 27, 16, 16, "physical", "", false, false], [30, 32, 34, 34, "physical", "", false, false], [34, 34, 16, 16, "physical", "", false, false], [36, 37, 39, 39, "physical", "", false, false], [39, 39, 16, 16, "physical", "", false, false], [41, 43, 45, 45, "physical", "", false, false], [45, 45, 16, 16, "physical", "", false, false], [47, 48, 50, 50, "physical", "", false, false], [50, 50, 16, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["In", "August", "2011", "it", "was", "announced", "that", "Hitachi", "would", "donate", "an", "electron", "microscope", "to", "each", "of", "Indonesia", "'s", "five", "universities", "(", "the", "University", "of", "North", "Sumatra", "in", "Medan", ",", "the", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Padjadjaran", "University", "in", "Bandung", ",", "Jenderal", "Soedirman", "University", "in", "Purvokerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "sentence-detokenized": "In August 2011 it was announced that Hitachi would donate an electron microscope to each of Indonesia's five universities (the University of North Sumatra in Medan, the Indonesian Christian University in Jakarta, Padjadjaran University in Bandung, Jenderal Soedirman University in Purvokerto and Muhammadiyah University in Malang).", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 17], [18, 21], [22, 31], [32, 36], [37, 44], [45, 50], [51, 57], [58, 60], [61, 69], [70, 80], [81, 83], [84, 88], [89, 91], [92, 101], [101, 103], [104, 108], [109, 121], [122, 123], [123, 126], [127, 137], [138, 140], [141, 146], [147, 154], [155, 157], [158, 163], [163, 164], [165, 168], [169, 179], [180, 189], [190, 200], [201, 203], [204, 211], [211, 212], [213, 224], [225, 235], [236, 238], [239, 246], [246, 247], [248, 256], [257, 266], [267, 277], [278, 280], [281, 291], [292, 295], [296, 308], [309, 319], [320, 322], [323, 329], [329, 330], [330, 331]]}
{"doc_key": "ai-dev-76", "ner": [[0, 0, "field"], [3, 4, "field"], [8, 9, "algorithm"], [11, 12, "algorithm"], [21, 22, "field"], [27, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 4, "part-of", "", false, false], [0, 0, 21, 22, "related-to", "", true, false], [0, 0, 27, 28, "related-to", "", true, false], [8, 9, 0, 0, "type-of", "", false, false], [11, 12, 0, 0, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Optimization", "techniques", "in", "operations", "research", ",", "such", "as", "linear", "programming", "or", "dynamic", "programming", ",", "are", "often", "inapplicable", "to", "large", "-", "scale", "software", "engineering", "problems", "because", "of", "their", "computational", "complexity", "."], "sentence-detokenized": "Optimization techniques in operations research, such as linear programming or dynamic programming, are often inapplicable to large-scale software engineering problems because of their computational complexity.", "token2charspan": [[0, 12], [13, 23], [24, 26], [27, 37], [38, 46], [46, 47], [48, 52], [53, 55], [56, 62], [63, 74], [75, 77], [78, 85], [86, 97], [97, 98], [99, 102], [103, 108], [109, 121], [122, 124], [125, 130], [130, 131], [131, 136], [137, 145], [146, 157], [158, 166], [167, 174], [175, 177], [178, 183], [184, 197], [198, 208], [208, 209]]}
{"doc_key": "ai-dev-77", "ner": [[0, 0, "metrics"], [6, 6, "metrics"], [8, 10, "metrics"], [14, 16, "metrics"], [20, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 6, "compare", "", false, false], [0, 0, 8, 10, "compare", "", false, false], [14, 16, 8, 10, "part-of", "", false, false], [20, 24, 8, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sensitivity", "is", "not", "the", "same", "as", "accuracy", "or", "positive", "predictive", "value", "(", "ratio", "of", "TRUE", "positive", "results", "to", "the", "combined", "TRUE", "and", "FALSE", "positive", "results", ")", ",", "which", "is", "both", "a", "statement", "about", "the", "proportion", "of", "true", "positive", "results", "in", "the", "population", "being", "tested", "and", "about", "the", "test", "."], "sentence-detokenized": "Sensitivity is not the same as accuracy or positive predictive value (ratio of TRUE positive results to the combined TRUE and FALSE positive results), which is both a statement about the proportion of true positive results in the population being tested and about the test.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 22], [23, 27], [28, 30], [31, 39], [40, 42], [43, 51], [52, 62], [63, 68], [69, 70], [70, 75], [76, 78], [79, 83], [84, 92], [93, 100], [101, 103], [104, 107], [108, 116], [117, 121], [122, 125], [126, 131], [132, 140], [141, 148], [148, 149], [149, 150], [151, 156], [157, 159], [160, 164], [165, 166], [167, 176], [177, 182], [183, 186], [187, 197], [198, 200], [201, 205], [206, 214], [215, 222], [223, 225], [226, 229], [230, 240], [241, 246], [247, 253], [254, 257], [258, 263], [264, 267], [268, 272], [272, 273]]}
{"doc_key": "ai-dev-78", "ner": [[0, 1, "person"], [11, 11, "product"], [14, 14, "person"], [29, 29, "person"], [37, 38, "person"], [49, 50, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[11, 11, 0, 1, "artifact", "", false, false], [37, 38, 49, 50, "role", "convinces", false, false], [49, 50, 11, 11, "role", "producer", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Hampton", "Fancher", "'s", "script", "!", "--", "It", "was", "not", "originally", "titled", "Android", "-", "See", "Sammon", ",", "p.", "32", "and", "38", "for", "explanation", "--", "it", "was", "chosen", "in", "1977", ".", "Sammon", ",", "pp.", "23", "-", "30", ".", "Producer", "Michael", "Deeley", "took", "an", "interest", "in", "Fancher", "'s", "draft", "and", "convinced", "director", "Ridley", "Scott", "to", "shoot", "it", "."], "sentence-detokenized": "Hampton Fancher's script! -- It was not originally titled Android - See Sammon, p. 32 and 38 for explanation -- it was chosen in 1977. Sammon, pp. 23-30. Producer Michael Deeley took an interest in Fancher's draft and convinced director Ridley Scott to shoot it.", "token2charspan": [[0, 7], [8, 15], [15, 17], [18, 24], [24, 25], [26, 28], [29, 31], [32, 35], [36, 39], [40, 50], [51, 57], [58, 65], [66, 67], [68, 71], [72, 78], [78, 79], [80, 82], [83, 85], [86, 89], [90, 92], [93, 96], [97, 108], [109, 111], [112, 114], [115, 118], [119, 125], [126, 128], [129, 133], [133, 134], [135, 141], [141, 142], [143, 146], [147, 149], [149, 150], [150, 152], [152, 153], [154, 162], [163, 170], [171, 177], [178, 182], [183, 185], [186, 194], [195, 197], [198, 205], [205, 207], [208, 213], [214, 217], [218, 227], [228, 236], [237, 243], [244, 249], [250, 252], [253, 258], [259, 261], [261, 262]]}
{"doc_key": "ai-dev-79", "ner": [[0, 1, "field"], [3, 4, "task"], [6, 7, "task"], [10, 12, "misc"], [14, 15, "field"], [17, 19, "task"], [21, 22, "task"], [24, 25, "field"], [28, 31, "task"], [33, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [6, 7, 0, 1, "part-of", "", false, false], [10, 12, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false], [17, 19, 0, 1, "part-of", "", false, false], [21, 22, 0, 1, "part-of", "", false, false], [24, 25, 0, 1, "part-of", "", false, false], [28, 31, 0, 1, "part-of", "", false, false], [33, 33, 0, 1, "part-of", "", false, false], [35, 36, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Text", "analysis", "includes", "information", "retrieval", ",", "lexical", "analysis", "to", "study", "word", "frequency", "distributions", ",", "pattern", "recognition", ",", "tagging", "/", "annotation", ",", "information", "extraction", ",", "data", "mining", "techniques", "including", "link", "and", "association", "analysis", ",", "visualisation", "and", "predictive", "analysis", "."], "sentence-detokenized": "Text analysis includes information retrieval, lexical analysis to study word frequency distributions, pattern recognition, tagging/annotation, information extraction, data mining techniques including link and association analysis, visualisation and predictive analysis.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 34], [35, 44], [44, 45], [46, 53], [54, 62], [63, 65], [66, 71], [72, 76], [77, 86], [87, 100], [100, 101], [102, 109], [110, 121], [121, 122], [123, 130], [130, 131], [131, 141], [141, 142], [143, 154], [155, 165], [165, 166], [167, 171], [172, 178], [179, 189], [190, 199], [200, 204], [205, 208], [209, 220], [221, 229], [229, 230], [231, 244], [245, 248], [249, 259], [260, 268], [268, 269]]}
{"doc_key": "ai-dev-80", "ner": [[3, 3, "product"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Many", "measurements", "use", "WordNet", ",", "a", "manually", "constructed", "dictionary", "database", "of", "English", "words", "."], "sentence-detokenized": "Many measurements use WordNet, a manually constructed dictionary database of English words.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 29], [29, 30], [31, 32], [33, 41], [42, 53], [54, 64], [65, 73], [74, 76], [77, 84], [85, 90], [90, 91]]}
{"doc_key": "ai-dev-81", "ner": [[8, 9, "field"], [11, 12, "task"], [14, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "system", "uses", "a", "combination", "of", "techniques", "from", "computational", "linguistics", ",", "information", "retrieval", "and", "knowledge", "representation", "to", "find", "answers", "."], "sentence-detokenized": "The system uses a combination of techniques from computational linguistics, information retrieval and knowledge representation to find answers.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 17], [18, 29], [30, 32], [33, 43], [44, 48], [49, 62], [63, 74], [74, 75], [76, 87], [88, 97], [98, 101], [102, 111], [112, 126], [127, 129], [130, 134], [135, 142], [142, 143]]}
{"doc_key": "ai-dev-82", "ner": [[6, 9, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 9, 13, 13, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "performance", "measure", ",", "the", "uncertainty", "factor", "has", "the", "advantage", "over", "simple", "precision", "that", "it", "is", "not", "affected", "by", "the", "relative", "sizes", "of", "the", "different", "classes", "."], "sentence-detokenized": "As a performance measure, the uncertainty factor has the advantage over simple precision that it is not affected by the relative sizes of the different classes.", "token2charspan": [[0, 2], [3, 4], [5, 16], [17, 24], [24, 25], [26, 29], [30, 41], [42, 48], [49, 52], [53, 56], [57, 66], [67, 71], [72, 78], [79, 88], [89, 93], [94, 96], [97, 99], [100, 103], [104, 112], [113, 115], [116, 119], [120, 128], [129, 134], [135, 137], [138, 141], [142, 151], [152, 159], [159, 160]]}
{"doc_key": "ai-dev-83", "ner": [[8, 9, "algorithm"], [11, 12, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Researchers", "have", "tried", "various", "methods", ",", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "Hidden", "Markov", "Models", ",", "etc", "."], "sentence-detokenized": "Researchers have tried various methods, such as optical flow, Kalman filtering, Hidden Markov Models, etc.", "token2charspan": [[0, 11], [12, 16], [17, 22], [23, 30], [31, 38], [38, 39], [40, 44], [45, 47], [48, 55], [56, 60], [60, 61], [62, 68], [69, 78], [78, 79], [80, 86], [87, 93], [94, 100], [100, 101], [102, 105], [105, 106]]}
{"doc_key": "ai-dev-84", "ner": [[14, 17, "conference"], [36, 38, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "served", "as", "President", ",", "Vice", "President", "and", "Secretary", "-", "Treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "has", "served", "on", "the", "board", "of", "directors", "and", "as", "secretary", "of", "the", "board", "of", "directors", "of", "the", "Computing", "Research", "Association", "."], "sentence-detokenized": "He has served as President, Vice President and Secretary-Treasurer of the Association for Computational Linguistics and has served on the board of directors and as secretary of the board of directors of the Computing Research Association.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 26], [26, 27], [28, 32], [33, 42], [43, 46], [47, 56], [56, 57], [57, 66], [67, 69], [70, 73], [74, 85], [86, 89], [90, 103], [104, 115], [116, 119], [120, 123], [124, 130], [131, 133], [134, 137], [138, 143], [144, 146], [147, 156], [157, 160], [161, 163], [164, 173], [174, 176], [177, 180], [181, 186], [187, 189], [190, 199], [200, 202], [203, 206], [207, 216], [217, 225], [226, 237], [237, 238]]}
{"doc_key": "ai-dev-85", "ner": [[7, 7, "programlang"], [9, 9, "product"], [11, 11, "programlang"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 11, 11, "compare", "", false, false], [7, 7, 13, 14, "related-to", "supports", false, false], [9, 9, 11, 11, "compare", "", false, false], [9, 9, 13, 14, "related-to", "supports", false, false], [11, 11, 13, 14, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Like", "other", "similar", "languages", ",", "such", "as", "APL", "and", "MATLAB", ",", "R", "supports", "matrix", "arithmetic", "."], "sentence-detokenized": "Like other similar languages, such as APL and MATLAB, R supports matrix arithmetic.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 28], [28, 29], [30, 34], [35, 37], [38, 41], [42, 45], [46, 52], [52, 53], [54, 55], [56, 64], [65, 71], [72, 82], [82, 83]]}
{"doc_key": "ai-dev-86", "ner": [[7, 8, "misc"], [12, 13, "organisation"], [17, 18, "researcher"], [21, 23, "university"], [27, 32, "misc"], [34, 34, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 8, 12, 13, "physical", "", false, false], [7, 8, 27, 32, "temporal", "", false, false], [17, 18, 7, 8, "role", "arranges", false, false], [17, 18, 21, 23, "role", "works_for", false, false], [34, 34, 7, 8, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "7", "June", "2014", ",", "in", "a", "Turing", "test", "competition", "at", "the", "Royal", "Society", ",", "organised", "by", "Kevin", "Warwick", "of", "the", "University", "of", "Reading", "to", "mark", "the", "60th", "anniversary", "of", "Turing", "'s", "death", ",", "Goostman", "won", "after", "33", "%", "of", "the", "judges", "were", "convinced", "that", "the", "robot", "was", "human", "."], "sentence-detokenized": "On 7 June 2014, in a Turing test competition at the Royal Society, organised by Kevin Warwick of the University of Reading to mark the 60th anniversary of Turing's death, Goostman won after 33% of the judges were convinced that the robot was human.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 14], [14, 15], [16, 18], [19, 20], [21, 27], [28, 32], [33, 44], [45, 47], [48, 51], [52, 57], [58, 65], [65, 66], [67, 76], [77, 79], [80, 85], [86, 93], [94, 96], [97, 100], [101, 111], [112, 114], [115, 122], [123, 125], [126, 130], [131, 134], [135, 139], [140, 151], [152, 154], [155, 161], [161, 163], [164, 169], [169, 170], [171, 179], [180, 183], [184, 189], [190, 192], [192, 193], [194, 196], [197, 200], [201, 207], [208, 212], [213, 222], [223, 227], [228, 231], [232, 237], [238, 241], [242, 247], [247, 248]]}
{"doc_key": "ai-dev-87", "ner": [[1, 2, "product"], [4, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "collaborative", "robot", "or", "cobot", "is", "a", "robot", "that", "can", "safely", "and", "efficiently", "interact", "with", "human", "workers", "while", "performing", "simple", "industrial", "tasks", "."], "sentence-detokenized": "A collaborative robot or cobot is a robot that can safely and efficiently interact with human workers while performing simple industrial tasks.", "token2charspan": [[0, 1], [2, 15], [16, 21], [22, 24], [25, 30], [31, 33], [34, 35], [36, 41], [42, 46], [47, 50], [51, 57], [58, 61], [62, 73], [74, 82], [83, 87], [88, 93], [94, 101], [102, 107], [108, 118], [119, 125], [126, 136], [137, 142], [142, 143]]}
{"doc_key": "ai-dev-88", "ner": [[13, 14, "field"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 30, "task"], [32, 34, "task"], [37, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[17, 18, 13, 14, "part-of", "task_part_of_field", false, false], [20, 21, 13, 14, "part-of", "task_part_of_field", false, false], [23, 24, 13, 14, "part-of", "task_part_of_field", false, false], [26, 27, 13, 14, "part-of", "task_part_of_field", false, false], [29, 30, 13, 14, "part-of", "task_part_of_field", false, false], [32, 34, 13, 14, "part-of", "task_part_of_field", false, false], [37, 38, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "overall", "framework", "has", "been", "applied", "to", "a", "wide", "variety", "of", "problems", "in", "computer", "vision", ",", "including", "feature", "detection", ",", "feature", "classification", ",", "image", "segmentation", ",", "image", "matching", ",", "motion", "estimation", ",", "shape", "cue", "computation", ",", "and", "object", "recognition", "."], "sentence-detokenized": "This overall framework has been applied to a wide variety of problems in computer vision, including feature detection, feature classification, image segmentation, image matching, motion estimation, shape cue computation, and object recognition.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 26], [27, 31], [32, 39], [40, 42], [43, 44], [45, 49], [50, 57], [58, 60], [61, 69], [70, 72], [73, 81], [82, 88], [88, 89], [90, 99], [100, 107], [108, 117], [117, 118], [119, 126], [127, 141], [141, 142], [143, 148], [149, 161], [161, 162], [163, 168], [169, 177], [177, 178], [179, 185], [186, 196], [196, 197], [198, 203], [204, 207], [208, 219], [219, 220], [221, 224], [225, 231], [232, 243], [243, 244]]}
{"doc_key": "ai-dev-89", "ner": [[5, 6, "task"], [8, 10, "algorithm"], [13, 13, "algorithm"], [26, 27, "algorithm"], [31, 32, "algorithm"], [35, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 8, 10, "part-of", "", false, false], [5, 6, 13, 13, "usage", "", false, false], [8, 10, 26, 27, "named", "same", false, false], [26, 27, 31, 32, "related-to", "", false, false], [26, 27, 35, 36, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "many", "practical", "applications", ",", "parameter", "estimation", "for", "naive", "Bayesian", "models", "uses", "the", "maximum", "likelihood", "method", ";", "in", "other", "words", ",", "one", "can", "work", "with", "the", "naive", "Bayesian", "model", "without", "accepting", "Bayesian", "probability", "or", "using", "Bayesian", "methods", "."], "sentence-detokenized": "In many practical applications, parameter estimation for naive Bayesian models uses the maximum likelihood method; in other words, one can work with the naive Bayesian model without accepting Bayesian probability or using Bayesian methods.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 30], [30, 31], [32, 41], [42, 52], [53, 56], [57, 62], [63, 71], [72, 78], [79, 83], [84, 87], [88, 95], [96, 106], [107, 113], [113, 114], [115, 117], [118, 123], [124, 129], [129, 130], [131, 134], [135, 138], [139, 143], [144, 148], [149, 152], [153, 158], [159, 167], [168, 173], [174, 181], [182, 191], [192, 200], [201, 212], [213, 215], [216, 221], [222, 230], [231, 238], [238, 239]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [12, 15, "university"], [17, 19, "researcher"], [21, 22, "misc"], [26, 26, "university"], [28, 28, "university"], [31, 31, "misc"], [38, 40, "university"], [46, 49, "misc"], [51, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 4, 12, 15, "physical", "", false, false], [2, 4, 12, 15, "role", "", false, false], [2, 4, 17, 19, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [17, 19, 26, 26, "physical", "", false, false], [17, 19, 26, 26, "role", "", false, false], [17, 19, 28, 28, "physical", "", false, false], [17, 19, 28, 28, "role", "", false, false], [17, 19, 38, 40, "physical", "", false, false], [17, 19, 38, 40, "role", "", false, false], [21, 22, 17, 19, "named", "", false, false], [31, 31, 17, 19, "origin", "", false, false], [46, 49, 17, 19, "artifact", "", false, false], [46, 49, 51, 54, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Brothers", "-", "Victor", "Gershevich", "Katz", ",", "American", "mathematician", ",", "professor", "at", "the", "Massachusetts", "Institute", "of", "Technology", ";", "Mikhail", "Gershevich", "Katz", ",", "Israeli", "mathematician", ",", "graduate", "of", "Harvard", "and", "Columbia", "Universities", "(", "Ph.D.", ",", "1984", ")", ",", "professor", "at", "Bar-", "Ilan", "University", ",", "author", "of", "the", "monograph", "Systolic", "Geometry", "and", "Topology", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", "."], "sentence-detokenized": "Brothers - Victor Gershevich Katz, American mathematician, professor at the Massachusetts Institute of Technology; Mikhail Gershevich Katz, Israeli mathematician, graduate of Harvard and Columbia Universities (Ph.D. , 1984), professor at Bar-Ilan University, author of the monograph Systolic Geometry and Topology (Mathematical Surveys and Monographs, vol.", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 28], [29, 33], [33, 34], [35, 43], [44, 57], [57, 58], [59, 68], [69, 71], [72, 75], [76, 89], [90, 99], [100, 102], [103, 113], [113, 114], [115, 122], [123, 133], [134, 138], [138, 139], [140, 147], [148, 161], [161, 162], [163, 171], [172, 174], [175, 182], [183, 186], [187, 195], [196, 208], [209, 210], [210, 215], [216, 217], [218, 222], [222, 223], [223, 224], [225, 234], [235, 237], [238, 242], [242, 246], [247, 257], [257, 258], [259, 265], [266, 268], [269, 272], [273, 282], [283, 291], [292, 300], [301, 304], [305, 313], [314, 315], [315, 327], [328, 335], [336, 339], [340, 350], [350, 351], [352, 355], [355, 356]]}
{"doc_key": "ai-dev-91", "ner": [[2, 3, "person"], [9, 10, "conference"], [16, 22, "organisation"], [24, 30, "location"], [34, 34, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 10, "physical", "", false, false], [2, 3, 9, 10, "role", "", false, false], [2, 3, 16, 22, "role", "", false, false], [16, 22, 24, 30, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2000", "Manuel", "Toharia", ",", "a", "speaker", "at", "previous", "Campus", "Parties", ",", "and", "director", "of", "the", "Museo", "de", "la", "Scienze", "de", "Pr\u00edncipe", "Felipe", "in", "Valencia", "'s", "City", "of", "Arts", "and", "Sciences", ",", "suggested", "to", "Ragageles", "to", "expand", "and", "make", "the", "event", "more", "international", "by", "moving", "it", "to", "the", "famous", "museum", "."], "sentence-detokenized": "In 2000 Manuel Toharia, a speaker at previous Campus Parties, and director of the Museo de la Scienze de Pr\u00edncipe Felipe in Valencia's City of Arts and Sciences, suggested to Ragageles to expand and make the event more international by moving it to the famous museum.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 22], [22, 23], [24, 25], [26, 33], [34, 36], [37, 45], [46, 52], [53, 60], [60, 61], [62, 65], [66, 74], [75, 77], [78, 81], [82, 87], [88, 90], [91, 93], [94, 101], [102, 104], [105, 113], [114, 120], [121, 123], [124, 132], [132, 134], [135, 139], [140, 142], [143, 147], [148, 151], [152, 160], [160, 161], [162, 171], [172, 174], [175, 184], [185, 187], [188, 194], [195, 198], [199, 203], [204, 207], [208, 213], [214, 218], [219, 232], [233, 235], [236, 242], [243, 245], [246, 248], [249, 252], [253, 259], [260, 266], [266, 267]]}
{"doc_key": "ai-dev-92", "ner": [[5, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Within", "20", "minutes", ",", "a", "facial", "recognition", "system", "recognises", "personal", "information", "such", "as", "family", "name", ",", "ID", "number", "and", "address", ",", "which", "is", "displayed", "on", "the", "street", "on", "a", "billboard", "."], "sentence-detokenized": "Within 20 minutes, a facial recognition system recognises personal information such as family name, ID number and address, which is displayed on the street on a billboard.", "token2charspan": [[0, 6], [7, 9], [10, 17], [17, 18], [19, 20], [21, 27], [28, 39], [40, 46], [47, 57], [58, 66], [67, 78], [79, 83], [84, 86], [87, 93], [94, 98], [98, 99], [100, 102], [103, 109], [110, 113], [114, 121], [121, 122], [123, 128], [129, 131], [132, 141], [142, 144], [145, 148], [149, 155], [156, 158], [159, 160], [161, 170], [170, 171]]}
{"doc_key": "ai-dev-93", "ner": [[6, 7, "field"], [10, 11, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "research", "has", "increasingly", "focused", "on", "unsupervised", "learning", "algorithms", "and", "semi-supervised", "learning", "algorithms", "."], "sentence-detokenized": "Recent research has increasingly focused on unsupervised learning algorithms and semi-supervised learning algorithms.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 32], [33, 40], [41, 43], [44, 56], [57, 65], [66, 76], [77, 80], [81, 96], [97, 105], [106, 116], [116, 117]]}
{"doc_key": "ai-dev-94", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Calculate", "this", "example", "using", "Python", "code", ":"], "sentence-detokenized": "Calculate this example using Python code:", "token2charspan": [[0, 9], [10, 14], [15, 22], [23, 28], [29, 35], [36, 40], [40, 41]]}
{"doc_key": "ai-dev-95", "ner": [[7, 8, "task"], [15, 16, "field"], [21, 25, "algorithm"], [19, 27, "algorithm"], [31, 33, "algorithm"], [36, 37, "researcher"], [39, 40, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[21, 25, 15, 16, "part-of", "", false, false], [21, 25, 31, 33, "type-of", "", false, false], [21, 25, 36, 37, "origin", "", false, false], [21, 25, 39, 40, "origin", "", false, false], [19, 27, 21, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Today", ",", "however", ",", "many", "aspects", "of", "speech", "recognition", "have", "been", "taken", "over", "by", "a", "deep", "learning", "method", "called", "Long", "-", "term", "short", "-", "term", "memory", "(", "LSTM", ")", ",", "a", "recurrent", "neural", "network", "published", "by", "Sepp", "Hochreiter", "&", "J\u00fcrgen", "Schmidhuber", "in", "1997", "."], "sentence-detokenized": "Today, however, many aspects of speech recognition have been taken over by a deep learning method called Long-term short-term memory (LSTM), a recurrent neural network published by Sepp Hochreiter & J\u00fcrgen Schmidhuber in 1997.", "token2charspan": [[0, 5], [5, 6], [7, 14], [14, 15], [16, 20], [21, 28], [29, 31], [32, 38], [39, 50], [51, 55], [56, 60], [61, 66], [67, 71], [72, 74], [75, 76], [77, 81], [82, 90], [91, 97], [98, 104], [105, 109], [109, 110], [110, 114], [115, 120], [120, 121], [121, 125], [126, 132], [133, 134], [134, 138], [138, 139], [139, 140], [141, 142], [143, 152], [153, 159], [160, 167], [168, 177], [178, 180], [181, 185], [186, 196], [197, 198], [199, 205], [206, 217], [218, 220], [221, 225], [225, 226]]}
{"doc_key": "ai-dev-96", "ner": [[8, 8, "algorithm"], [17, 17, "algorithm"], [22, 22, "algorithm"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[8, 8, 22, 22, "named", "same", false, false], [17, 17, 22, 22, "compare", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "preliminary", "experimental", "results", "with", "noisy", "datasets", ",", "BrownBoost", "outperformed", "AdaBoost", "'s", "generalization", "error", ";", "however", ",", "LogitBoost", "performed", "as", "well", "as", "BrownBoost", "."], "sentence-detokenized": "In preliminary experimental results with noisy datasets, BrownBoost outperformed AdaBoost's generalization error; however, LogitBoost performed as well as BrownBoost.", "token2charspan": [[0, 2], [3, 14], [15, 27], [28, 35], [36, 40], [41, 46], [47, 55], [55, 56], [57, 67], [68, 80], [81, 89], [89, 91], [92, 106], [107, 112], [112, 113], [114, 121], [121, 122], [123, 133], [134, 143], [144, 146], [147, 151], [152, 154], [155, 165], [165, 166]]}
{"doc_key": "ai-dev-97", "ner": [[0, 1, "algorithm"], [5, 7, "researcher"], [10, 10, "country"], [13, 15, "researcher"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 7, "part-of", "", false, false], [5, 7, 10, 10, "physical", "", false, false], [20, 21, 13, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evolutionary", "programming", "was", "introduced", "by", "Lawrence", "J.", "Fogel", "in", "the", "USA", ",", "while", "John", "Henry", "Holland", "called", "his", "method", "the", "genetic", "algorithm", "."], "sentence-detokenized": "Evolutionary programming was introduced by Lawrence J. Fogel in the USA, while John Henry Holland called his method the genetic algorithm.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 54], [55, 60], [61, 63], [64, 67], [68, 71], [71, 72], [73, 78], [79, 83], [84, 89], [90, 97], [98, 104], [105, 108], [109, 115], [116, 119], [120, 127], [128, 137], [137, 138]]}
{"doc_key": "ai-dev-98", "ner": [[3, 3, "researcher"], [5, 5, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 11, 12, "role", "", false, false], [3, 3, 14, 15, "role", "", false, false], [3, 3, 17, 18, "role", "", false, false], [3, 3, 20, 21, "role", "", false, false], [5, 5, 11, 12, "role", "", false, false], [5, 5, 14, 15, "role", "", false, false], [5, 5, 17, 18, "role", "", false, false], [5, 5, 20, 21, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "calculations", "of", "Doug", ",", "Alan", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", "and", "John", "McCarthy", ")", "showed", "that", "this", "effort", "would", "require", "between", "1000", "and", "3000", "man", "-", "years", "of", "effort", ",", "far", "beyond", "the", "typical", "academic", "project", "model", "."], "sentence-detokenized": "The calculations of Doug, Alan and their colleagues (including Marvin Minsky, Allen Newell, Edward Feigenbaum and John McCarthy) showed that this effort would require between 1000 and 3000 man-years of effort, far beyond the typical academic project model.", "token2charspan": [[0, 3], [4, 16], [17, 19], [20, 24], [24, 25], [26, 30], [31, 34], [35, 40], [41, 51], [52, 53], [53, 62], [63, 69], [70, 76], [76, 77], [78, 83], [84, 90], [90, 91], [92, 98], [99, 109], [110, 113], [114, 118], [119, 127], [127, 128], [129, 135], [136, 140], [141, 145], [146, 152], [153, 158], [159, 166], [167, 174], [175, 179], [180, 183], [184, 188], [189, 192], [192, 193], [193, 198], [199, 201], [202, 208], [208, 209], [210, 213], [214, 220], [221, 224], [225, 232], [233, 241], [242, 249], [250, 255], [255, 256]]}
{"doc_key": "ai-dev-99", "ner": [[4, 6, "metrics"], [11, 11, "metrics"], [14, 16, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 11, 11, "part-of", "implemented_in", false, false], [14, 16, 20, 20, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Common", "criteria", "are", "the", "mean", "square", "error", "criterion", "applied", "to", "the", "MSECriterion", "and", "the", "cross", "-entropy", "criterion", "applied", "to", "the", "NLLCriterion", "."], "sentence-detokenized": "Common criteria are the mean square error criterion applied to the MSECriterion and the cross-entropy criterion applied to the NLLCriterion.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 23], [24, 28], [29, 35], [36, 41], [42, 51], [52, 59], [60, 62], [63, 66], [67, 79], [80, 83], [84, 87], [88, 93], [93, 101], [102, 111], [112, 119], [120, 122], [123, 126], [127, 139], [139, 140]]}
{"doc_key": "ai-dev-100", "ner": [[0, 0, "researcher"], [11, 11, "organisation"], [15, 27, "misc"], [30, 33, "conference"], [45, 45, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 11, 11, "role", "", false, false], [0, 0, 30, 33, "role", "", false, false], [0, 0, 45, 45, "role", "", false, false], [15, 27, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zurada", "has", "served", "the", "engineering", "profession", "as", "a", "long", "-", "time", "IEEE", "volunteer", ":", "as", "IEEE", "Vice", "Chair", "of", "IEEE", "Technical", "Activities", "(", "TAB", "Chair", ")", "in", "2014", ",", "as", "IEEE", "Computational", "Intelligence", "Society", "President", "in", "2004", "-", "05", ",", "and", "as", "a", "member", "of", "ADCOM", "in", "2009", "-", "14", ",", "2016", "-", "18", ",", "and", "previous", "years", "."], "sentence-detokenized": "Zurada has served the engineering profession as a long-time IEEE volunteer: as IEEE Vice Chair of IEEE Technical Activities (TAB Chair) in 2014, as IEEE Computational Intelligence Society President in 2004-05, and as a member of ADCOM in 2009-14, 2016-18, and previous years.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 21], [22, 33], [34, 44], [45, 47], [48, 49], [50, 54], [54, 55], [55, 59], [60, 64], [65, 74], [74, 75], [76, 78], [79, 83], [84, 88], [89, 94], [95, 97], [98, 102], [103, 112], [113, 123], [124, 125], [125, 128], [129, 134], [134, 135], [136, 138], [139, 143], [143, 144], [145, 147], [148, 152], [153, 166], [167, 179], [180, 187], [188, 197], [198, 200], [201, 205], [205, 206], [206, 208], [208, 209], [210, 213], [214, 216], [217, 218], [219, 225], [226, 228], [229, 234], [235, 237], [238, 242], [242, 243], [243, 245], [245, 246], [247, 251], [251, 252], [252, 254], [254, 255], [256, 259], [260, 268], [269, 274], [274, 275]]}
{"doc_key": "ai-dev-101", "ner": [[3, 8, "field"], [13, 13, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 3, 8, "part-of", "", false, false], [16, 17, 3, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "general", ",", "computational", "linguistics", "is", "based", "on", "the", "involvement", "of", "linguists", ",", "computer", "scientists", ",", "artificial", "intelligence", "specialists", ",", "mathematicians", ",", "logicians", ",", "philosophers", ",", "cognitive", "scientists", ",", "cognitive", "psychologists", ",", "psycholinguists", ",", "anthropologists", "and", "neuroscientists", ",", "among", "others", "."], "sentence-detokenized": "In general, computational linguistics is based on the involvement of linguists, computer scientists, artificial intelligence specialists, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists and neuroscientists, among others.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 25], [26, 37], [38, 40], [41, 46], [47, 49], [50, 53], [54, 65], [66, 68], [69, 78], [78, 79], [80, 88], [89, 99], [99, 100], [101, 111], [112, 124], [125, 136], [136, 137], [138, 152], [152, 153], [154, 163], [163, 164], [165, 177], [177, 178], [179, 188], [189, 199], [199, 200], [201, 210], [211, 224], [224, 225], [226, 241], [241, 242], [243, 258], [259, 262], [263, 278], [278, 279], [280, 285], [286, 292], [292, 293]]}
{"doc_key": "ai-dev-102", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "-", "term", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "the", "correlations", "between", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long-term short-term memory are often used to exploit the correlations between frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [82, 83], [83, 87], [88, 93], [93, 94], [94, 98], [99, 105], [106, 109], [110, 115], [116, 120], [121, 123], [124, 131], [132, 135], [136, 148], [149, 156], [157, 163], [163, 164]]}
{"doc_key": "ai-dev-103", "ner": [[0, 0, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "was", "the", "first", "industrial", "robot", ","], "sentence-detokenized": "Unimate was the first industrial robot,", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 21], [22, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-dev-104", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 11, 13, "win-defeat", "", false, false], [5, 6, 11, 13, "win-defeat", "", false, false], [8, 8, 11, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Together", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "won", "the", "2018", "Turing", "Prize", "."], "sentence-detokenized": "Together with Geoffrey Hinton and Yann LeCun, Bengio won the 2018 Turing Prize.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 29], [30, 33], [34, 38], [39, 44], [44, 45], [46, 52], [53, 56], [57, 60], [61, 65], [66, 72], [73, 78], [78, 79]]}
{"doc_key": "ai-dev-105", "ner": [[6, 6, "country"], [17, 20, "misc"], [25, 26, "country"], [29, 30, "organisation"], [34, 35, "person"], [37, 38, "person"], [47, 49, "misc"], [54, 54, "country"], [59, 59, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[17, 20, 6, 6, "physical", "filmed_in", false, false], [34, 35, 29, 30, "role", "host", false, false], [37, 38, 29, 30, "role", "reporter", false, false], [47, 49, 6, 6, "physical", "filmed_in", false, false], [47, 49, 54, 54, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Additional", "series", "were", "filmed", "in", "the", "UK", "for", "specific", "global", "market", "sectors", ",", "including", "two", "series", "of", "Robot", "Wars", "Extreme", "Warriors", "with", "competitors", "from", "the", "United", "States", "for", "the", "TNN", "network", "(", "hosted", "by", "Mick", "Foley", "and", "Rebecca", "Grant", "as", "a", "reporter", ")", ",", "two", "series", "of", "Dutch", "Robot", "Wars", "for", "distribution", "in", "the", "Netherlands", "and", "one", "series", "for", "Germany", "."], "sentence-detokenized": "Additional series were filmed in the UK for specific global market sectors, including two series of Robot Wars Extreme Warriors with competitors from the United States for the TNN network (hosted by Mick Foley and Rebecca Grant as a reporter), two series of Dutch Robot Wars for distribution in the Netherlands and one series for Germany.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 29], [30, 32], [33, 36], [37, 39], [40, 43], [44, 52], [53, 59], [60, 66], [67, 74], [74, 75], [76, 85], [86, 89], [90, 96], [97, 99], [100, 105], [106, 110], [111, 118], [119, 127], [128, 132], [133, 144], [145, 149], [150, 153], [154, 160], [161, 167], [168, 171], [172, 175], [176, 179], [180, 187], [188, 189], [189, 195], [196, 198], [199, 203], [204, 209], [210, 213], [214, 221], [222, 227], [228, 230], [231, 232], [233, 241], [241, 242], [242, 243], [244, 247], [248, 254], [255, 257], [258, 263], [264, 269], [270, 274], [275, 278], [279, 291], [292, 294], [295, 298], [299, 310], [311, 314], [315, 318], [319, 325], [326, 329], [330, 337], [337, 338]]}
{"doc_key": "ai-dev-106", "ner": [[8, 8, "researcher"], [13, 13, "product"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 13, 13, "role", "", false, false], [30, 31, 13, 13, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "many", "years", ",", "beginning", "in", "1986", ",", "Miller", "directed", "the", "development", "of", "WordNet", ",", "a", "large", "computer", "-", "readable", "electronic", "reference", "that", "can", "be", "used", "in", "applications", "such", "as", "search", "engines", "."], "sentence-detokenized": "For many years, beginning in 1986, Miller directed the development of WordNet, a large computer-readable electronic reference that can be used in applications such as search engines.", "token2charspan": [[0, 3], [4, 8], [9, 14], [14, 15], [16, 25], [26, 28], [29, 33], [33, 34], [35, 41], [42, 50], [51, 54], [55, 66], [67, 69], [70, 77], [77, 78], [79, 80], [81, 86], [87, 95], [95, 96], [96, 104], [105, 115], [116, 125], [126, 130], [131, 134], [135, 137], [138, 142], [143, 145], [146, 158], [159, 163], [164, 166], [167, 173], [174, 181], [181, 182]]}
{"doc_key": "ai-dev-107", "ner": [[4, 5, "algorithm"], [8, 11, "algorithm"], [14, 16, "researcher"], [21, 25, "organisation"], [29, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 14, 16, "origin", "", false, false], [4, 5, 29, 31, "win-defeat", "", false, false], [8, 11, 14, 16, "origin", "", false, false], [8, 11, 29, 31, "win-defeat", "", false, false], [14, 16, 21, 25, "physical", "", false, false], [14, 16, 21, 25, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Since", "2009", ",", "the", "recurrent", "neural", "networks", "and", "deep", "feedforward", "neural", "networks", "developed", "in", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "Swiss", "artificial", "intelligence", "laboratory", "IDSIA", "have", "won", "several", "international", "writing", "competitions", "."], "sentence-detokenized": "Since 2009, the recurrent neural networks and deep feedforward neural networks developed in J\u00fcrgen Schmidhuber's research group at the Swiss artificial intelligence laboratory IDSIA have won several international writing competitions.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 15], [16, 25], [26, 32], [33, 41], [42, 45], [46, 50], [51, 62], [63, 69], [70, 78], [79, 88], [89, 91], [92, 98], [99, 110], [110, 112], [113, 121], [122, 127], [128, 130], [131, 134], [135, 140], [141, 151], [152, 164], [165, 175], [176, 181], [182, 186], [187, 190], [191, 198], [199, 212], [213, 220], [221, 233], [233, 234]]}
{"doc_key": "ai-dev-108", "ner": [[6, 7, "programlang"], [12, 12, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "has", "been", "implemented", "in", "C", "++", "and", "is", "wrapped", "for", "Python", "."], "sentence-detokenized": "The software has been implemented in C++ and is wrapped for Python.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 21], [22, 33], [34, 36], [37, 38], [38, 40], [41, 44], [45, 47], [48, 55], [56, 59], [60, 66], [66, 67]]}
{"doc_key": "ai-dev-109", "ner": [[7, 8, "country"], [13, 14, "misc"], [18, 19, "misc"], [32, 34, "misc"], [35, 35, "misc"], [37, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 19, 7, 8, "temporal", "", false, false], [18, 19, 13, 14, "artifact", "", false, false], [18, 19, 37, 37, "physical", "", false, false], [35, 35, 32, 34, "named", "", false, false], [35, 35, 37, 37, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1857", ",", "at", "the", "request", "of", "Shogunate", "Tokugawa", ",", "a", "team", "of", "Dutch", "engineers", "began", "work", "on", "Nagasaki", "Yotetsusho", ",", "a", "modern", ",", "Western", "-", "style", "foundry", "and", "shipyard", "near", "the", "Dutch", "settlement", "of", "Dejima", ",", "Nagasaki", "."], "sentence-detokenized": "In 1857, at the request of Shogunate Tokugawa, a team of Dutch engineers began work on Nagasaki Yotetsusho, a modern, Western-style foundry and shipyard near the Dutch settlement of Dejima, Nagasaki.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 36], [37, 45], [45, 46], [47, 48], [49, 53], [54, 56], [57, 62], [63, 72], [73, 78], [79, 83], [84, 86], [87, 95], [96, 106], [106, 107], [108, 109], [110, 116], [116, 117], [118, 125], [125, 126], [126, 131], [132, 139], [140, 143], [144, 152], [153, 157], [158, 161], [162, 167], [168, 178], [179, 181], [182, 188], [188, 189], [190, 198], [198, 199]]}
{"doc_key": "ai-dev-110", "ner": [[10, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["We", "make", "it", "as", "accurate", "as", "possible", "by", "measuring", "the", "mean", "-", "square", "error", "between", "mathy", "/", "math", "and", "math", "\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "we", "want", "math", "(", "y", "-\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", "^", "2", "/", "math", "to", "be", "minimal", ",", "both", "for", "mathx", "_", "1", ",\\", "dots", ",", "x", "_n", "/", "math", "and", "for", "points", "outside", "our", "sample", "."], "sentence-detokenized": "We make it as accurate as possible by measuring the mean-square error between mathy / math and math\\ hat {f} (x; D) / math: we want math (y -\\ hat {f} (x; D)) ^ 2 / math to be minimal, both for mathx _ 1,\\ dots, x _n / math and for points outside our sample.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 13], [14, 22], [23, 25], [26, 34], [35, 37], [38, 47], [48, 51], [52, 56], [56, 57], [57, 63], [64, 69], [70, 77], [78, 83], [84, 85], [86, 90], [91, 94], [95, 99], [99, 100], [101, 104], [105, 106], [106, 107], [107, 108], [109, 110], [110, 111], [111, 112], [113, 114], [114, 115], [116, 117], [118, 122], [122, 123], [124, 126], [127, 131], [132, 136], [137, 138], [138, 139], [140, 142], [143, 146], [147, 148], [148, 149], [149, 150], [151, 152], [152, 153], [153, 154], [155, 156], [156, 157], [157, 158], [159, 160], [161, 162], [163, 164], [165, 169], [170, 172], [173, 175], [176, 183], [183, 184], [185, 189], [190, 193], [194, 199], [200, 201], [202, 203], [203, 205], [206, 210], [210, 211], [212, 213], [214, 216], [217, 218], [219, 223], [224, 227], [228, 231], [232, 238], [239, 246], [247, 250], [251, 257], [257, 258]]}
{"doc_key": "ai-dev-111", "ner": [[6, 6, "researcher"], [14, 16, "organisation"], [25, 28, "product"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 14, 16, "role", "", false, false], [25, 28, 14, 16, "temporal", "", false, false], [25, 28, 36, 37, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "then", "extended", "an", "invitation", "to", "Wydner", "to", "attend", "the", "annual", "meeting", "of", "the", "American", "Translators", "Association", "in", "October", "the", "following", "year", ",", "where", "the", "Weidner", "machine", "translation", "system", "was", "hailed", "as", "an", "anticipated", "breakthrough", "in", "machine", "translation", "."], "sentence-detokenized": "He then extended an invitation to Wydner to attend the annual meeting of the American Translators Association in October the following year, where the Weidner machine translation system was hailed as an anticipated breakthrough in machine translation.", "token2charspan": [[0, 2], [3, 7], [8, 16], [17, 19], [20, 30], [31, 33], [34, 40], [41, 43], [44, 50], [51, 54], [55, 61], [62, 69], [70, 72], [73, 76], [77, 85], [86, 97], [98, 109], [110, 112], [113, 120], [121, 124], [125, 134], [135, 139], [139, 140], [141, 146], [147, 150], [151, 158], [159, 166], [167, 178], [179, 185], [186, 189], [190, 196], [197, 199], [200, 202], [203, 214], [215, 227], [228, 230], [231, 238], [239, 250], [250, 251]]}
{"doc_key": "ai-dev-112", "ner": [[2, 10, "conference"], [3, 8, "conference"], [12, 12, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 8, 2, 10, "named", "", false, false], [3, 8, 2, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["At", "the", "2018", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "conference", ",", "Google", "researchers", "presented", "the", "work", "."], "sentence-detokenized": "At the 2018 Neural Information Processing Systems (NeurIPS) conference, Google researchers presented the work.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 30], [31, 41], [42, 49], [50, 51], [51, 58], [58, 59], [60, 70], [70, 71], [72, 78], [79, 90], [91, 100], [101, 104], [105, 109], [109, 110]]}
{"doc_key": "ai-dev-113", "ner": [[1, 4, "algorithm"], [10, 11, "algorithm"], [15, 18, "metrics"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 4, 10, 11, "usage", "", false, false], [10, 11, 15, 18, "related-to", "", true, false], [15, 18, 23, 25, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Baum", "-", "Welch", "algorithm", "uses", "the", "well", "-", "known", "EM", "algorithm", "to", "find", "the", "maximum", "likelihood", "estimate", "of", "the", "parameters", "of", "a", "hidden", "Markov", "model", "given", "a", "set", "of", "observed", "feature", "vectors", "."], "sentence-detokenized": "The Baum-Welch algorithm uses the well-known EM algorithm to find the maximum likelihood estimate of the parameters of a hidden Markov model given a set of observed feature vectors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [15, 24], [25, 29], [30, 33], [34, 38], [38, 39], [39, 44], [45, 47], [48, 57], [58, 60], [61, 65], [66, 69], [70, 77], [78, 88], [89, 97], [98, 100], [101, 104], [105, 115], [116, 118], [119, 120], [121, 127], [128, 134], [135, 140], [141, 146], [147, 148], [149, 152], [153, 155], [156, 164], [165, 172], [173, 180], [180, 181]]}
{"doc_key": "ai-dev-114", "ner": [[9, 9, "product"], [11, 11, "product"], [30, 31, "misc"], [37, 44, "product"], [47, 49, "programlang"], [50, 55, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 9, 11, 11, "compare", "", false, false], [30, 31, 11, 11, "part-of", "", false, false], [37, 44, 11, 11, "part-of", "", false, false], [50, 55, 11, 11, "part-of", "", false, false], [50, 55, 47, 49, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": [")", "In", "addition", "to", "the", "taxonomic", "information", "contained", "in", "OpenCyc", ",", "ResearchCyc", "includes", "significantly", "more", "semantic", "knowledge", "(", "i.e.", ",", "additional", "facts", "and", "rules", ")", "about", "the", "concepts", "in", "its", "knowledge", "base", ";", "it", "also", "includes", "a", "large", "dictionary", ",", "parsing", "and", "English", "generation", "tools", ",", "and", "Java", "-", "based", "interfaces", "for", "knowledge", "processing", "and", "querying", "."], "sentence-detokenized": ") In addition to the taxonomic information contained in OpenCyc, ResearchCyc includes significantly more semantic knowledge (i.e., additional facts and rules) about the concepts in its knowledge base; it also includes a large dictionary, parsing and English generation tools, and Java-based interfaces for knowledge processing and querying.", "token2charspan": [[0, 1], [2, 4], [5, 13], [14, 16], [17, 20], [21, 30], [31, 42], [43, 52], [53, 55], [56, 63], [63, 64], [65, 76], [77, 85], [86, 99], [100, 104], [105, 113], [114, 123], [124, 125], [125, 129], [129, 130], [131, 141], [142, 147], [148, 151], [152, 157], [157, 158], [159, 164], [165, 168], [169, 177], [178, 180], [181, 184], [185, 194], [195, 199], [199, 200], [201, 203], [204, 208], [209, 217], [218, 219], [220, 225], [226, 236], [236, 237], [238, 245], [246, 249], [250, 257], [258, 268], [269, 274], [274, 275], [276, 279], [280, 284], [284, 285], [285, 290], [291, 301], [302, 305], [306, 315], [316, 326], [327, 330], [331, 339], [339, 340]]}
{"doc_key": "ai-dev-115", "ner": [[0, 2, "algorithm"], [5, 6, "task"], [10, 11, "field"], [13, 14, "field"], [16, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 6, "type-of", "", false, false], [5, 6, 10, 11, "part-of", "task_part_of_field", false, false], [5, 6, 13, 14, "part-of", "task_part_of_field", false, false], [5, 6, 16, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Hough", "transform", "is", "a", "feature", "extraction", "technique", "used", "in", "image", "analysis", ",", "computer", "vision", "and", "digital", "image", "processing", "."], "sentence-detokenized": "The Hough transform is a feature extraction technique used in image analysis, computer vision and digital image processing.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 22], [23, 24], [25, 32], [33, 43], [44, 53], [54, 58], [59, 61], [62, 67], [68, 76], [76, 77], [78, 86], [87, 93], [94, 97], [98, 105], [106, 111], [112, 122], [122, 123]]}
{"doc_key": "ai-dev-116", "ner": [[4, 4, "product"], [6, 10, "product"], [16, 16, "organisation"], [18, 18, "product"], [20, 21, "researcher"], [28, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 6, 10, "named", "", false, false], [4, 4, 16, 16, "artifact", "", false, false], [4, 4, 18, 18, "origin", "developed_from", false, false], [18, 18, 20, 21, "artifact", "", false, false], [28, 29, 16, 16, "role", "supported", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1978", ",", "the", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "robot", "was", "developed", "by", "Unimation", "from", "Vicarm", "(", "Victor", "Scheinman", ")", "and", "with", "the", "support", "of", "General", "Motors", "."], "sentence-detokenized": "In 1978, the PUMA (Programmable Universal Machine for Assembly) robot was developed by Unimation from Vicarm (Victor Scheinman) and with the support of General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 19], [19, 31], [32, 41], [42, 49], [50, 53], [54, 62], [62, 63], [64, 69], [70, 73], [74, 83], [84, 86], [87, 96], [97, 101], [102, 108], [109, 110], [110, 116], [117, 126], [126, 127], [128, 131], [132, 136], [137, 140], [141, 148], [149, 151], [152, 159], [160, 166], [166, 167]]}
{"doc_key": "ai-dev-117", "ner": [[0, 1, "algorithm"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 7, 8, "origin", "", false, false], [0, 1, 10, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "LSTM", "was", "proposed", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "The LSTM was proposed in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 21], [22, 24], [25, 29], [30, 32], [33, 37], [38, 48], [49, 52], [53, 59], [60, 71], [71, 72]]}
{"doc_key": "ai-dev-118", "ner": [[11, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "expressed", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "table", ",", "as", "follows", ":"], "sentence-detokenized": "The four results can be expressed in a 2 \u00d7 2 contingency table or confusion table, as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 33], [34, 36], [37, 38], [39, 40], [41, 42], [43, 44], [45, 56], [57, 62], [63, 65], [66, 75], [76, 81], [81, 82], [83, 85], [86, 93], [93, 94]]}
{"doc_key": "ai-dev-119", "ner": [[6, 6, "conference"], [9, 10, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "also", "instrumental", "in", "establishing", "ELRA", "and", "the", "LREC", "conference", "."], "sentence-detokenized": "He was also instrumental in establishing ELRA and the LREC conference.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 27], [28, 40], [41, 45], [46, 49], [50, 53], [54, 58], [59, 69], [69, 70]]}
{"doc_key": "ai-dev-120", "ner": [[17, 18, "misc"], [24, 27, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[24, 27, 17, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "popular", "application", "for", "serial", "robots", "in", "today", "'s", "industry", "is", "the", "pick", "-", "and", "-", "place", "assembly", "robot", ",", "the", "so", "-", "called", "SCARA", "robot", ",", "which", "has", "four", "degrees", "of", "freedom", "."], "sentence-detokenized": "A popular application for serial robots in today's industry is the pick-and-place assembly robot, the so-called SCARA robot, which has four degrees of freedom.", "token2charspan": [[0, 1], [2, 9], [10, 21], [22, 25], [26, 32], [33, 39], [40, 42], [43, 48], [48, 50], [51, 59], [60, 62], [63, 66], [67, 71], [71, 72], [72, 75], [75, 76], [76, 81], [82, 90], [91, 96], [96, 97], [98, 101], [102, 104], [104, 105], [105, 111], [112, 117], [118, 123], [123, 124], [125, 130], [131, 134], [135, 139], [140, 147], [148, 150], [151, 158], [158, 159]]}
{"doc_key": "ai-dev-121", "ner": [[16, 25, "conference"], [15, 27, "conference"], [31, 34, "conference"], [42, 42, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 27, 16, 25, "named", "", false, false], [42, 42, 31, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "one", "of", "the", "founding", "members", "and", "former", "chair", "(", "2006-2008", ")", "of", "the", "Special", "Interest", "Group", "on", "the", "Web", "as", "a", "Body", "of", "Data", "(", "SIGWAC", ")", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "also", "one", "of", "the", "founders", "of", "SENSEVAL", "."], "sentence-detokenized": "He was one of the founding members and former chair (2006-2008) of the Special Interest Group on the Web as a Body of Data (SIGWAC) of the Association for Computational Linguistics and also one of the founders of SENSEVAL.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 17], [18, 26], [27, 34], [35, 38], [39, 45], [46, 51], [52, 53], [53, 62], [62, 63], [64, 66], [67, 70], [71, 78], [79, 87], [88, 93], [94, 96], [97, 100], [101, 104], [105, 107], [108, 109], [110, 114], [115, 117], [118, 122], [123, 124], [124, 130], [130, 131], [132, 134], [135, 138], [139, 150], [151, 154], [155, 168], [169, 180], [181, 184], [185, 189], [190, 193], [194, 196], [197, 200], [201, 209], [210, 212], [213, 221], [221, 222]]}
{"doc_key": "ai-dev-122", "ner": [[4, 4, "product"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 4, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "platform", ",", "LinguaStream", "provides", "an", "extensive", "Java", "API", "."], "sentence-detokenized": "As a platform, LinguaStream provides an extensive Java API.", "token2charspan": [[0, 2], [3, 4], [5, 13], [13, 14], [15, 27], [28, 36], [37, 39], [40, 49], [50, 54], [55, 58], [58, 59]]}
{"doc_key": "ai-dev-123", "ner": [[11, 11, "programlang"], [14, 16, "misc"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 19, 21, "type-of", "", false, false], [14, 16, 19, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "robot", "kit", "is", "based", "on", "Android", "and", "is", "programmed", "using", "Java", ",", "the", "Blocks", "programming", "interface", "or", "other", "Android", "programming", "systems", "."], "sentence-detokenized": "The robot kit is based on Android and is programmed using Java, the Blocks programming interface or other Android programming systems.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 16], [17, 22], [23, 25], [26, 33], [34, 37], [38, 40], [41, 51], [52, 57], [58, 62], [62, 63], [64, 67], [68, 74], [75, 86], [87, 96], [97, 99], [100, 105], [106, 113], [114, 125], [126, 133], [133, 134]]}
{"doc_key": "ai-dev-124", "ner": [[10, 13, "algorithm"], [16, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "linked", "list", "definition", "method", "specifies", "the", "use", "of", "a", "depth", "-", "based", "search", "or", "a", "range", "-", "based", "search", "."], "sentence-detokenized": "The linked list definition method specifies the use of a depth-based search or a range-based search.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 26], [27, 33], [34, 43], [44, 47], [48, 51], [52, 54], [55, 56], [57, 62], [62, 63], [63, 68], [69, 75], [76, 78], [79, 80], [81, 86], [86, 87], [87, 92], [93, 99], [99, 100]]}
{"doc_key": "ai-dev-125", "ner": [[19, 20, "task"], [24, 27, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "areas", "could", "signal", "the", "presence", "of", "objects", "or", "parts", "of", "objects", "in", "the", "image", "field", "with", "application", "to", "object", "recognition", "and", "/", "or", "object", "tracking", "in", "video", "."], "sentence-detokenized": "These areas could signal the presence of objects or parts of objects in the image field with application to object recognition and/or object tracking in video.", "token2charspan": [[0, 5], [6, 11], [12, 17], [18, 24], [25, 28], [29, 37], [38, 40], [41, 48], [49, 51], [52, 57], [58, 60], [61, 68], [69, 71], [72, 75], [76, 81], [82, 87], [88, 92], [93, 104], [105, 107], [108, 114], [115, 126], [127, 130], [130, 131], [131, 133], [134, 140], [141, 149], [150, 152], [153, 158], [158, 159]]}
{"doc_key": "ai-dev-126", "ner": [[4, 5, "algorithm"], [7, 7, "product"], [14, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 4, 5, "type-of", "", false, false], [7, 7, 14, 14, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "semantic", "network", "is", "WordNet", ",", "a", "lexical", "database", "of", "the", "English", "language", "."], "sentence-detokenized": "An example of a semantic network is WordNet, a lexical database of the English language.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 32], [33, 35], [36, 43], [43, 44], [45, 46], [47, 54], [55, 63], [64, 66], [67, 70], [71, 78], [79, 87], [87, 88]]}
{"doc_key": "ai-dev-127", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 11, "field"], [20, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 7, 8, "part-of", "", false, false], [0, 1, 10, 11, "named", "same", false, false], [0, 1, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Speech", "recognition", "is", "an", "interdisciplinary", "subfield", "of", "computer", "science", "and", "computational", "linguistics", "that", "develops", "methodologies", "and", "technologies", "that", "enable", "the", "recognition", "and", "translation", "of", "spoken", "speech", "into", "text", "by", "computers", "."], "sentence-detokenized": "Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that enable the recognition and translation of spoken speech into text by computers.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 24], [25, 42], [43, 51], [52, 54], [55, 63], [64, 71], [72, 75], [76, 89], [90, 101], [102, 106], [107, 115], [116, 129], [130, 133], [134, 146], [147, 151], [152, 158], [159, 162], [163, 174], [175, 178], [179, 190], [191, 193], [194, 200], [201, 207], [208, 212], [213, 217], [218, 220], [221, 230], [230, 231]]}
{"doc_key": "ai-dev-128", "ner": [[0, 1, "field"], [10, 11, "misc"], [16, 20, "field"], [23, 23, "task"], [25, 26, "task"], [46, 47, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 46, 47, "named", "same", false, false], [16, 20, 0, 1, "part-of", "subfield", false, false], [23, 23, 0, 1, "part-of", "", false, false], [23, 23, 16, 20, "part-of", "", false, false], [25, 26, 16, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Artificial", "intelligence", "has", "retained", "the", "most", "attention", "in", "terms", "of", "applied", "ontology", "in", "subfields", "such", "as", "natural", "language", "processing", "in", "the", "context", "of", "engineering", "and", "knowledge", "representation", ",", "but", "ontology", "processors", "are", "often", "used", "in", "various", "domains", "such", "as", "education", "without", "the", "intention", "of", "contributing", "to", "artificial", "intelligence", "."], "sentence-detokenized": "Artificial intelligence has retained the most attention in terms of applied ontology in subfields such as natural language processing in the context of engineering and knowledge representation, but ontology processors are often used in various domains such as education without the intention of contributing to artificial intelligence.", "token2charspan": [[0, 10], [11, 23], [24, 27], [28, 36], [37, 40], [41, 45], [46, 55], [56, 58], [59, 64], [65, 67], [68, 75], [76, 84], [85, 87], [88, 97], [98, 102], [103, 105], [106, 113], [114, 122], [123, 133], [134, 136], [137, 140], [141, 148], [149, 151], [152, 163], [164, 167], [168, 177], [178, 192], [192, 193], [194, 197], [198, 206], [207, 217], [218, 221], [222, 227], [228, 232], [233, 235], [236, 243], [244, 251], [252, 256], [257, 259], [260, 269], [270, 277], [278, 281], [282, 291], [292, 294], [295, 307], [308, 310], [311, 321], [322, 334], [334, 335]]}
{"doc_key": "ai-dev-129", "ner": [[6, 8, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 11, 12, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "update", "rule", "is", "actually", "the", "stochastic", "gradient", "descent", "update", "for", "linear", "regression", "."], "sentence-detokenized": "This update rule is actually the stochastic gradient descent update for linear regression.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 28], [29, 32], [33, 43], [44, 52], [53, 60], [61, 67], [68, 71], [72, 78], [79, 89], [89, 90]]}
{"doc_key": "ai-dev-130", "ner": [[7, 12, "organisation"], [15, 18, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "elected", "a", "member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "the", "National", "Academy", "of", "Sciences", "and", "has", "received", "a", "number", "of", "awards", ":"], "sentence-detokenized": "He was elected a member of the American Academy of Arts and Sciences and the National Academy of Sciences and has received a number of awards:", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 16], [17, 23], [24, 26], [27, 30], [31, 39], [40, 47], [48, 50], [51, 55], [56, 59], [60, 68], [69, 72], [73, 76], [77, 85], [86, 93], [94, 96], [97, 105], [106, 109], [110, 113], [114, 122], [123, 124], [125, 131], [132, 134], [135, 141], [141, 142]]}
{"doc_key": "ai-dev-131", "ner": [[7, 12, "organisation"], [13, 14, "person"], [16, 19, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 12, 13, 14, "related-to", "written_about_by", false, false], [7, 12, 16, 19, "related-to", "written_about_by", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "recent", "school", "of", "thought", "on", "Honda", "'s", "strategy", "was", "formulated", "by", "Gary", "Hamel", "and", "C.", "K", ".", "Prahalad", "in", "1989", "."], "sentence-detokenized": "The most recent school of thought on Honda's strategy was formulated by Gary Hamel and C. K. Prahalad in 1989.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 22], [23, 25], [26, 33], [34, 36], [37, 42], [42, 44], [45, 53], [54, 57], [58, 68], [69, 71], [72, 76], [77, 82], [83, 86], [87, 89], [90, 91], [91, 92], [93, 101], [102, 104], [105, 109], [109, 110]]}
{"doc_key": "ai-dev-132", "ner": [[1, 1, "metrics"], [5, 6, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 5, 6, "related-to", "calculates", true, false], [1, 1, 18, 18, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "BLEU", "simply", "calculates", "the", "accuracy", "of", "n-", "grams", "by", "adding", "equal", "weight", "to", "each", "of", "them", ",", "NIST", "also", "calculates", "how", "informative", "a", "particular", "n-", "gram", "is", "."], "sentence-detokenized": "While BLEU simply calculates the accuracy of n-grams by adding equal weight to each of them, NIST also calculates how informative a particular n-gram is.", "token2charspan": [[0, 5], [6, 10], [11, 17], [18, 28], [29, 32], [33, 41], [42, 44], [45, 47], [47, 52], [53, 55], [56, 62], [63, 68], [69, 75], [76, 78], [79, 83], [84, 86], [87, 91], [91, 92], [93, 97], [98, 102], [103, 113], [114, 117], [118, 129], [130, 131], [132, 142], [143, 145], [145, 149], [150, 152], [152, 153]]}
{"doc_key": "ai-dev-133", "ner": [[4, 8, "misc"], [12, 13, "conference"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 8, 12, 13, "temporal", "", false, false], [15, 15, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "awarded", "the", "2019", "Lifetime", "Achievement", "Award", "by", "the", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "He was awarded the 2019 Lifetime Achievement Award by the Association for Computational Linguistics (ACL).", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 18], [19, 23], [24, 32], [33, 44], [45, 50], [51, 53], [54, 57], [58, 69], [70, 73], [74, 87], [88, 99], [100, 101], [101, 104], [104, 105], [105, 106]]}
{"doc_key": "ai-dev-134", "ner": [[0, 2, "researcher"], [8, 11, "organisation"], [6, 13, "organisation"], [23, 24, "conference"], [20, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 8, 11, "role", "", false, false], [0, 2, 23, 24, "role", "", false, false], [6, 13, 8, 11, "named", "", false, false], [20, 26, 23, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "is", "a", "member", "of", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "and", "a", "member", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara is a member of the Institute of Electrical and Electronics Engineers (IEEE) and a member of the American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 18], [19, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 65], [66, 75], [76, 77], [77, 81], [81, 82], [83, 86], [87, 88], [89, 95], [96, 98], [99, 102], [103, 111], [112, 123], [124, 127], [128, 138], [139, 151], [152, 153], [153, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-dev-135", "ner": [[2, 2, "product"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 11, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "following", "MATLAB", "code", "presents", "a", "concrete", "solution", "to", "solve", "the", "nonlinear", "system", "of", "equations", "presented", "in", "the", "previous", "section", ":", "See", "also"], "sentence-detokenized": "The following MATLAB code presents a concrete solution to solve the nonlinear system of equations presented in the previous section: See also", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 34], [35, 36], [37, 45], [46, 54], [55, 57], [58, 63], [64, 67], [68, 77], [78, 84], [85, 87], [88, 97], [98, 107], [108, 110], [111, 114], [115, 123], [124, 131], [131, 132], [133, 136], [137, 141]]}
{"doc_key": "ai-dev-136", "ner": [[0, 2, "product"], [13, 14, "field"], [36, 37, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 13, 14, "related-to", "trained_by", true, false], [0, 2, 36, 37, "related-to", "trained_by", true, false], [13, 14, 36, 37, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Pattern", "recognition", "systems", "are", "in", "many", "cases", "trained", "from", "tagged", "training", "data", "(", "supervised", "learning", ")", ",", "but", "when", "no", "tagged", "data", "are", "available", ",", "other", "algorithms", "can", "be", "used", "to", "discover", "previously", "unknown", "patterns", "(", "unsupervised", "learning", ")", "."], "sentence-detokenized": "Pattern recognition systems are in many cases trained from tagged training data (supervised learning), but when no tagged data are available, other algorithms can be used to discover previously unknown patterns (unsupervised learning).", "token2charspan": [[0, 7], [8, 19], [20, 27], [28, 31], [32, 34], [35, 39], [40, 45], [46, 53], [54, 58], [59, 65], [66, 74], [75, 79], [80, 81], [81, 91], [92, 100], [100, 101], [101, 102], [103, 106], [107, 111], [112, 114], [115, 121], [122, 126], [127, 130], [131, 140], [140, 141], [142, 147], [148, 158], [159, 162], [163, 165], [166, 170], [171, 173], [174, 182], [183, 193], [194, 201], [202, 210], [211, 212], [212, 224], [225, 233], [233, 234], [234, 235]]}
{"doc_key": "ai-dev-137", "ner": [[5, 7, "researcher"], [10, 11, "country"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 10, 11, "physical", "", false, false], [5, 7, 26, 27, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "was", "first", "used", "by", "Lawrence", "J.", "Fogel", "in", "the", "USA", "in", "1960", ",", "in", "order", "to", "use", "simulated", "evolution", "as", "a", "learning", "process", "to", "create", "artificial", "intelligence", "."], "sentence-detokenized": "It was first used by Lawrence J. Fogel in the USA in 1960, in order to use simulated evolution as a learning process to create artificial intelligence.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 17], [18, 20], [21, 29], [30, 32], [33, 38], [39, 41], [42, 45], [46, 49], [50, 52], [53, 57], [57, 58], [59, 61], [62, 67], [68, 70], [71, 74], [75, 84], [85, 94], [95, 97], [98, 99], [100, 108], [109, 116], [117, 119], [120, 126], [127, 137], [138, 150], [150, 151]]}
{"doc_key": "ai-dev-138", "ner": [[0, 1, "field"], [10, 11, "field"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 10, 11, "part-of", "", false, false], [15, 16, 10, 11, "part-of", "", false, false], [18, 19, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Reinforcement", "learning", "is", "one", "of", "the", "three", "main", "examples", "of", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "unsupervised", "learning", "."], "sentence-detokenized": "Reinforcement learning is one of the three main examples of machine learning, along with supervised learning and unsupervised learning.", "token2charspan": [[0, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 42], [43, 47], [48, 56], [57, 59], [60, 67], [68, 76], [76, 77], [78, 83], [84, 88], [89, 99], [100, 108], [109, 112], [113, 125], [126, 134], [134, 135]]}
{"doc_key": "ai-dev-139", "ner": [[4, 5, "field"], [12, 12, "programlang"], [29, 30, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 29, 30, "usage", "applies", false, false], [12, 12, 29, 30, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "such", "cases", ",", "cloud", "computing", "and", "the", "open", "source", "programming", "language", "R", "can", "help", "smaller", "banks", "to", "adopt", "risk", "analysis", "and", "support", "branch", "-", "level", "monitoring", "by", "applying", "predictive", "analytics", "."], "sentence-detokenized": "In such cases, cloud computing and the open source programming language R can help smaller banks to adopt risk analysis and support branch-level monitoring by applying predictive analytics.", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 20], [21, 30], [31, 34], [35, 38], [39, 43], [44, 50], [51, 62], [63, 71], [72, 73], [74, 77], [78, 82], [83, 90], [91, 96], [97, 99], [100, 105], [106, 110], [111, 119], [120, 123], [124, 131], [132, 138], [138, 139], [139, 144], [145, 155], [156, 158], [159, 167], [168, 178], [179, 188], [188, 189]]}
{"doc_key": "ai-dev-140", "ner": [[11, 12, "researcher"], [16, 16, "algorithm"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 20, 21, "named", "same", false, false], [16, 16, 11, 12, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["One", "of", "the", "first", "versions", "of", "the", "theorem", "was", "proved", "by", "George", "Cybenko", "in", "1989", "for", "sigmoid", "activation", "functions", ".", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "One of the first versions of the theorem was proved by George Cybenko in 1989 for sigmoid activation functions. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 25], [26, 28], [29, 32], [33, 40], [41, 44], [45, 51], [52, 54], [55, 61], [62, 69], [70, 72], [73, 77], [78, 81], [82, 89], [90, 100], [101, 110], [110, 111], [112, 119], [120, 122], [123, 124], [124, 128], [128, 129], [129, 130], [131, 132], [133, 134], [134, 135], [135, 136], [136, 137], [138, 145], [145, 146]]}
{"doc_key": "ai-dev-141", "ner": [[8, 8, "algorithm"], [11, 12, "metrics"], [17, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 8, 8, "part-of", "", false, false], [17, 20, 11, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "process", ",", "which", "is", "known", "as", "cross-validation", ",", "the", "MSE", "is", "often", "called", "the", "mean", "squared", "error", "of", "prediction", "and", "is", "calculated", "as", "follows"], "sentence-detokenized": "In this process, which is known as cross-validation, the MSE is often called the mean squared error of prediction and is calculated as follows", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 22], [23, 25], [26, 31], [32, 34], [35, 51], [51, 52], [53, 56], [57, 60], [61, 63], [64, 69], [70, 76], [77, 80], [81, 85], [86, 93], [94, 99], [100, 102], [103, 113], [114, 117], [118, 120], [121, 131], [132, 134], [135, 142]]}
{"doc_key": "ai-dev-142", "ner": [[0, 1, "task"], [6, 6, "task"], [5, 12, "task"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 6, "compare", "", false, false], [6, 6, 21, 22, "part-of", "", false, false], [5, 12, 6, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OMR", "is", "generally", "distinguished", "from", "optical", "character", "recognition", "(", "OCR", ")", "by", "the", "fact", "that", "it", "does", "not", "require", "a", "complex", "pattern", "recognition", "engine", "."], "sentence-detokenized": "OMR is generally distinguished from optical character recognition (OCR) by the fact that it does not require a complex pattern recognition engine.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 30], [31, 35], [36, 43], [44, 53], [54, 65], [66, 67], [67, 70], [70, 71], [72, 74], [75, 78], [79, 83], [84, 88], [89, 91], [92, 96], [97, 100], [101, 108], [109, 110], [111, 118], [119, 126], [127, 138], [139, 145], [145, 146]]}
{"doc_key": "ai-dev-143", "ner": [[10, 10, "location"], [12, 12, "location"], [14, 14, "location"], [17, 18, "location"], [20, 21, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 14, 14, "physical", "", false, false], [17, 18, 12, 12, "physical", "", false, false], [20, 21, 12, 12, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2018", "and", "2019", ",", "the", "championship", "was", "held", "in", "Houston", "and", "Detroit", ",", "Michigan", "at", "the", "TCF", "Center", "and", "Ford", "Field", "."], "sentence-detokenized": "In 2018 and 2019, the championship was held in Houston and Detroit, Michigan at the TCF Center and Ford Field.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 16], [16, 17], [18, 21], [22, 34], [35, 38], [39, 43], [44, 46], [47, 54], [55, 58], [59, 66], [66, 67], [68, 76], [77, 79], [80, 83], [84, 87], [88, 94], [95, 98], [99, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-dev-144", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "viewed", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multi-category", "classification", "."], "sentence-detokenized": "Classification can be viewed as two separate problems - binary classification and multi-category classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 28], [29, 31], [32, 35], [36, 44], [45, 53], [54, 55], [56, 62], [63, 77], [78, 81], [82, 96], [97, 111], [111, 112]]}
{"doc_key": "ai-dev-145", "ner": [[4, 5, "product"], [8, 9, "product"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "type-of", "", false, false], [12, 13, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "examples", "of", "popular", "parallel", "robots", "are", "the", "Stewart", "platform", "and", "the", "Delta", "robot", "."], "sentence-detokenized": "Two examples of popular parallel robots are the Stewart platform and the Delta robot.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 23], [24, 32], [33, 39], [40, 43], [44, 47], [48, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-146", "ner": [[4, 6, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 21, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "However", ",", "the", "ReLU", "activation", "function", ",", "which", "is", "non-differentiable", "at", "0", ",", "has", "become", "quite", "popular", ",", "e.g.", "on", "AlexNet", ")"], "sentence-detokenized": "(However, the ReLU activation function, which is non-differentiable at 0, has become quite popular, e.g. on AlexNet)", "token2charspan": [[0, 1], [1, 8], [8, 9], [10, 13], [14, 18], [19, 29], [30, 38], [38, 39], [40, 45], [46, 48], [49, 67], [68, 70], [71, 72], [72, 73], [74, 77], [78, 84], [85, 90], [91, 98], [98, 99], [100, 104], [105, 107], [108, 115], [115, 116]]}
{"doc_key": "ai-dev-147", "ner": [[0, 3, "metrics"], [10, 11, "task"], [17, 17, "task"], [19, 20, "task"], [22, 23, "task"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 26, 27, "named", "", true, false], [10, 11, 0, 3, "usage", "", true, false], [17, 17, 10, 11, "part-of", "", false, false], [19, 20, 10, 11, "part-of", "", false, false], [22, 23, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["F", "-", "score", "is", "often", "used", "in", "the", "field", "of", "information", "retrieval", "to", "measure", "the", "performance", "of", "search", ",", "document", "classification", "and", "query", "classification", "and", "thus", "F_beta", "is", "widely", "used", "."], "sentence-detokenized": "F-score is often used in the field of information retrieval to measure the performance of search, document classification and query classification and thus F_beta is widely used.", "token2charspan": [[0, 1], [1, 2], [2, 7], [8, 10], [11, 16], [17, 21], [22, 24], [25, 28], [29, 34], [35, 37], [38, 49], [50, 59], [60, 62], [63, 70], [71, 74], [75, 86], [87, 89], [90, 96], [96, 97], [98, 106], [107, 121], [122, 125], [126, 131], [132, 146], [147, 150], [151, 155], [156, 162], [163, 165], [166, 172], [173, 177], [177, 178]]}
{"doc_key": "ai-dev-148", "ner": [[19, 19, "algorithm"], [18, 21, "algorithm"], [24, 25, "algorithm"], [27, 27, "algorithm"], [31, 32, "algorithm"], [30, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 21, 19, 19, "named", "", false, false], [27, 27, 24, 25, "named", "", false, false], [30, 34, 31, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "is", "done", "by", "modelling", "the", "received", "signal", "and", "then", "using", "a", "statistical", "estimation", "method", ",", "such", "as", "maximum", "likelihood", "(", "ML", ")", ",", "majority", "voting", "(", "MV", ")", "or", "maximum", "posterior", "estimation", "(", "MAP", ")", ",", "to", "make", "a", "decision", "on", "which", "target", "in", "the", "library", "best", "fits", "the", "model", "built", "using", "the", "received", "signal", "."], "sentence-detokenized": "This is done by modelling the received signal and then using a statistical estimation method, such as maximum likelihood (ML), majority voting (MV) or maximum posterior estimation (MAP), to make a decision on which target in the library best fits the model built using the received signal.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 25], [26, 29], [30, 38], [39, 45], [46, 49], [50, 54], [55, 60], [61, 62], [63, 74], [75, 85], [86, 92], [92, 93], [94, 98], [99, 101], [102, 109], [110, 120], [121, 122], [122, 124], [124, 125], [125, 126], [127, 135], [136, 142], [143, 144], [144, 146], [146, 147], [148, 150], [151, 158], [159, 168], [169, 179], [180, 181], [181, 184], [184, 185], [185, 186], [187, 189], [190, 194], [195, 196], [197, 205], [206, 208], [209, 214], [215, 221], [222, 224], [225, 228], [229, 236], [237, 241], [242, 246], [247, 250], [251, 256], [257, 262], [263, 268], [269, 272], [273, 281], [282, 288], [288, 289]]}
{"doc_key": "ai-dev-149", "ner": [[0, 0, "researcher"], [3, 5, "misc"], [7, 7, "field"], [10, 14, "university"], [18, 21, "misc"], [22, 22, "field"], [25, 26, "university"], [31, 31, "misc"], [33, 34, "field"], [37, 39, "university"], [45, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 0, 10, 14, "physical", "", false, false], [0, 0, 10, 14, "role", "", false, false], [0, 0, 25, 26, "physical", "", false, false], [0, 0, 25, 26, "role", "", false, false], [0, 0, 37, 39, "physical", "", false, false], [0, 0, 37, 39, "role", "", false, false], [3, 5, 0, 0, "origin", "", false, false], [3, 5, 7, 7, "topic", "", false, false], [18, 21, 0, 0, "origin", "", false, false], [18, 21, 22, 22, "topic", "", false, false], [31, 31, 0, 0, "origin", "", false, false], [31, 31, 33, 34, "topic", "", false, false], [45, 53, 31, 31, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Sowa", "received", "a", "bachelor", "'s", "degree", "in", "mathematics", "from", "the", "Massachusetts", "Institute", "of", "Technology", "in", "1962", ",", "a", "master", "'s", "degree", "in", "applied", "science", "from", "Harvard", "University", "in", "1966", "and", "a", "doctorate", "in", "computer", "science", "from", "the", "Vrije", "Universiteit", "Brussel", "in", "1999", ",", "entitled", "\"", "Knowledge", "representation", ":", "logical", ",", "philosophical", "and", "computational", "foundations", "\"", "."], "sentence-detokenized": "Sowa received a bachelor's degree in mathematics from the Massachusetts Institute of Technology in 1962, a master's degree in applied science from Harvard University in 1966 and a doctorate in computer science from the Vrije Universiteit Brussel in 1999, entitled \"Knowledge representation: logical, philosophical and computational foundations\".", "token2charspan": [[0, 4], [5, 13], [14, 15], [16, 24], [24, 26], [27, 33], [34, 36], [37, 48], [49, 53], [54, 57], [58, 71], [72, 81], [82, 84], [85, 95], [96, 98], [99, 103], [103, 104], [105, 106], [107, 113], [113, 115], [116, 122], [123, 125], [126, 133], [134, 141], [142, 146], [147, 154], [155, 165], [166, 168], [169, 173], [174, 177], [178, 179], [180, 189], [190, 192], [193, 201], [202, 209], [210, 214], [215, 218], [219, 224], [225, 237], [238, 245], [246, 248], [249, 253], [253, 254], [255, 263], [264, 265], [265, 274], [275, 289], [289, 290], [291, 298], [298, 299], [300, 313], [314, 317], [318, 331], [332, 343], [343, 344], [344, 345]]}
{"doc_key": "ai-dev-150", "ner": [[1, 2, "task"], [8, 8, "task"], [18, 18, "metrics"], [20, 21, "metrics"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 8, 8, "general-affiliation", "", false, false], [18, 18, 1, 2, "part-of", "", true, false], [20, 21, 1, 2, "part-of", "", true, false], [23, 24, 1, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "paraphrase", "identification", "can", "be", "posed", "as", "a", "classification", "problem", ",", "most", "standard", "evaluation", "metrics", ",", "such", "as", "accuracy", ",", "f1", "score", "or", "ROC", "curve", ",", "work", "relatively", "well", "."], "sentence-detokenized": "Since paraphrase identification can be posed as a classification problem, most standard evaluation metrics, such as accuracy, f1 score or ROC curve, work relatively well.", "token2charspan": [[0, 5], [6, 16], [17, 31], [32, 35], [36, 38], [39, 44], [45, 47], [48, 49], [50, 64], [65, 72], [72, 73], [74, 78], [79, 87], [88, 98], [99, 106], [106, 107], [108, 112], [113, 115], [116, 124], [124, 125], [126, 128], [129, 134], [135, 137], [138, 141], [142, 147], [147, 148], [149, 153], [154, 164], [165, 169], [169, 170]]}
{"doc_key": "ai-dev-151", "ner": [[19, 19, "algorithm"], [32, 33, "algorithm"], [35, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 19, 32, 33, "opposite", "not_suited_for", false, false], [19, 19, 35, 36, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "makes", "it", "practical", "for", "the", "analysis", "of", "large", "datasets", "(", "hundreds", "or", "thousands", "of", "taxa", ")", "and", "for", "bootstrapping", ",", "for", "the", "purposes", "of", "which", "other", "means", "of", "analysis", "(", "e.g.", "maximum", "sparsity", ",", "maximum", "likelihood", ")", "may", "be", "computationally", "prohibitive", "."], "sentence-detokenized": "This makes it practical for the analysis of large datasets (hundreds or thousands of taxa) and for bootstrapping, for the purposes of which other means of analysis (e.g. maximum sparsity, maximum likelihood) may be computationally prohibitive.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 31], [32, 40], [41, 43], [44, 49], [50, 58], [59, 60], [60, 68], [69, 71], [72, 81], [82, 84], [85, 89], [89, 90], [91, 94], [95, 98], [99, 112], [112, 113], [114, 117], [118, 121], [122, 130], [131, 133], [134, 139], [140, 145], [146, 151], [152, 154], [155, 163], [164, 165], [165, 169], [170, 177], [178, 186], [186, 187], [188, 195], [196, 206], [206, 207], [208, 211], [212, 214], [215, 230], [231, 242], [242, 243]]}
{"doc_key": "ai-dev-152", "ner": [[5, 10, "programlang"], [12, 14, "organisation"], [11, 16, "organisation"], [25, 25, "programlang"], [29, 43, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[11, 16, 12, 14, "named", "", false, false], [29, 43, 5, 10, "role", "submits", true, false], [29, 43, 12, 14, "role", "submits_to", true, false]], "relations_mapping_to_source": [1, 3, 4], "sentence": ["The", "2002", "submission", "of", "the", "DAML", "+", "OIL", "language", "to", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "the", "work", "carried", "out", "by", "the", "DAML", "contractors", "and", "the", "ad", "hoc", "Joint", "Committee", "on", "Markup", "Languages", "of", "the", "European", "Union", "and", "the", "United", "States", "."], "sentence-detokenized": "The 2002 submission of the DAML+OIL language to the World Wide Web Consortium (W3C), the work carried out by the DAML contractors and the ad hoc Joint Committee on Markup Languages of the European Union and the United States.", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 22], [23, 26], [27, 31], [31, 32], [32, 35], [36, 44], [45, 47], [48, 51], [52, 57], [58, 62], [63, 66], [67, 77], [78, 79], [79, 82], [82, 83], [83, 84], [85, 88], [89, 93], [94, 101], [102, 105], [106, 108], [109, 112], [113, 117], [118, 129], [130, 133], [134, 137], [138, 140], [141, 144], [145, 150], [151, 160], [161, 163], [164, 170], [171, 180], [181, 183], [184, 187], [188, 196], [197, 202], [203, 206], [207, 210], [211, 217], [218, 224], [224, 225]]}
{"doc_key": "ai-dev-153", "ner": [[3, 4, "misc"], [8, 8, "misc"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 3, 4, "part-of", "", true, false], [11, 12, 3, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "non-linear", "normalization", "is", "when", "the", "normalization", "follows", "a", "sigmoid", "function", ",", "in", "which", "case", ",", "the", "normalized", "image", "is", "calculated", "according", "to", "the", "formula"], "sentence-detokenized": "An example of non-linear normalization is when the normalization follows a sigmoid function, in which case, the normalized image is calculated according to the formula", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 38], [39, 41], [42, 46], [47, 50], [51, 64], [65, 72], [73, 74], [75, 82], [83, 91], [91, 92], [93, 95], [96, 101], [102, 106], [106, 107], [108, 111], [112, 122], [123, 128], [129, 131], [132, 142], [143, 152], [153, 155], [156, 159], [160, 167]]}
{"doc_key": "ai-dev-154", "ner": [[6, 7, "metrics"], [11, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 11, 11, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "pointed", "out", "that", "accuracy", "is", "usually", "combined", "with", "recall", "to", "overcome", "this", "problem", "."], "sentence-detokenized": "It has been pointed out that accuracy is usually combined with recall to overcome this problem.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 23], [24, 28], [29, 37], [38, 40], [41, 48], [49, 57], [58, 62], [63, 69], [70, 72], [73, 81], [82, 86], [87, 94], [94, 95]]}
{"doc_key": "ai-dev-155", "ner": [[7, 9, "metrics"], [6, 17, "metrics"], [23, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 6, 17, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "metrics", "commonly", "used", "are", "the", "root", "mean", "square", "error", "and", "the", "root", "mean", "square", "error", ",", "the", "latter", "being", "used", "in", "the", "Netflix", "award", "."], "sentence-detokenized": "The metrics commonly used are the root mean square error and the root mean square error, the latter being used in the Netflix award.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 25], [26, 29], [30, 33], [34, 38], [39, 43], [44, 50], [51, 56], [57, 60], [61, 64], [65, 69], [70, 74], [75, 81], [82, 87], [87, 88], [89, 92], [93, 99], [100, 105], [106, 110], [111, 113], [114, 117], [118, 125], [126, 131], [131, 132]]}
{"doc_key": "ai-dev-156", "ner": [[8, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "August", "2016", ",", "a", "research", "project", "with", "University", "College", "Hospital", "was", "announced", "to", "develop", "an", "algorithm", "that", "can", "automatically", "distinguish", "between", "healthy", "and", "cancerous", "tissue", "in", "areas", "of", "the", "head", "and", "neck", "."], "sentence-detokenized": "In August 2016, a research project with University College Hospital was announced to develop an algorithm that can automatically distinguish between healthy and cancerous tissue in areas of the head and neck.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 17], [18, 26], [27, 34], [35, 39], [40, 50], [51, 58], [59, 67], [68, 71], [72, 81], [82, 84], [85, 92], [93, 95], [96, 105], [106, 110], [111, 114], [115, 128], [129, 140], [141, 148], [149, 156], [157, 160], [161, 170], [171, 177], [178, 180], [181, 186], [187, 189], [190, 193], [194, 198], [199, 202], [203, 207], [207, 208]]}
{"doc_key": "ai-dev-157", "ner": [[16, 18, "organisation"], [21, 24, "organisation"], [27, 30, "organisation"], [33, 38, "organisation"], [41, 47, "organisation"], [51, 54, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "impact", "of", "Posner", "'s", "theoretical", "and", "empirical", "contributions", "has", "been", "recognized", "through", "scholarship", "in", "the", "American", "Psychological", "Association", ",", "the", "Association", "for", "Psychological", "Science", ",", "the", "Society", "of", "Experimental", "Psychologists", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "The impact of Posner's theoretical and empirical contributions has been recognized through scholarship in the American Psychological Association, the Association for Psychological Science, the Society of Experimental Psychologists, the American Academy of Arts and Sciences, the American Association for the Advancement of Science, and the National Academy of Sciences.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 20], [20, 22], [23, 34], [35, 38], [39, 48], [49, 62], [63, 66], [67, 71], [72, 82], [83, 90], [91, 102], [103, 105], [106, 109], [110, 118], [119, 132], [133, 144], [144, 145], [146, 149], [150, 161], [162, 165], [166, 179], [180, 187], [187, 188], [189, 192], [193, 200], [201, 203], [204, 216], [217, 230], [230, 231], [232, 235], [236, 244], [245, 252], [253, 255], [256, 260], [261, 264], [265, 273], [273, 274], [275, 278], [279, 287], [288, 299], [300, 303], [304, 307], [308, 319], [320, 322], [323, 330], [330, 331], [332, 335], [336, 339], [340, 348], [349, 356], [357, 359], [360, 368], [368, 369]]}
{"doc_key": "ai-dev-158", "ner": [[2, 2, "product"], [7, 8, "field"], [12, 13, "task"], [17, 17, "task"], [19, 19, "task"], [23, 24, "task"], [26, 26, "task"], [29, 30, "field"], [32, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 2, 7, 8, "usage", "", false, false], [12, 13, 7, 8, "part-of", "", false, false], [17, 17, 7, 8, "part-of", "", false, false], [19, 19, 17, 17, "named", "", false, false], [23, 24, 7, 8, "part-of", "", false, false], [26, 26, 23, 24, "named", "", false, false], [29, 30, 7, 8, "part-of", "", false, false], [32, 33, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["These", "intelligent", "chatbots", "use", "all", "kinds", "of", "artificial", "intelligence", ",", "such", "as", "image", "retention", "and", "natural", "language", "understanding", "(", "NLU", ")", ",", "natural", "language", "generation", "(", "NLG", ")", ",", "machine", "learning", "and", "deep", "learning", "."], "sentence-detokenized": "These intelligent chatbots use all kinds of artificial intelligence, such as image retention and natural language understanding (NLU), natural language generation (NLG), machine learning and deep learning.", "token2charspan": [[0, 5], [6, 17], [18, 26], [27, 30], [31, 34], [35, 40], [41, 43], [44, 54], [55, 67], [67, 68], [69, 73], [74, 76], [77, 82], [83, 92], [93, 96], [97, 104], [105, 113], [114, 127], [128, 129], [129, 132], [132, 133], [133, 134], [135, 142], [143, 151], [152, 162], [163, 164], [164, 167], [167, 168], [168, 169], [170, 177], [178, 186], [187, 190], [191, 195], [196, 204], [204, 205]]}
{"doc_key": "ai-dev-159", "ner": [[8, 11, "metrics"], [14, 14, "metrics"], [17, 23, "metrics"], [31, 31, "metrics"], [29, 33, "metrics"], [36, 43, "metrics"], [48, 49, "metrics"], [51, 51, "metrics"], [54, 61, "metrics"], [67, 68, "metrics"], [66, 70, "metrics"], [73, 80, "metrics"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[29, 33, 31, 31, "named", "", false, false], [36, 43, 31, 31, "named", "", false, false], [51, 51, 48, 49, "named", "", false, false], [54, 61, 48, 49, "named", "", false, false], [66, 70, 67, 68, "named", "", false, false], [73, 80, 67, 68, "named", "", false, false]], "relations_mapping_to_source": [3, 4, 5, 6, 7, 8], "sentence": ["The", "ratios", "in", "the", "series", "are", "the", "Positive", "Predictive", "Value", "(", "PPV", ",", "or", "precision", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "supplemented", "by", "the", "False", "Discovery", "Rate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "and", "the", "Negative", "Predictive", "Value", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "supplemented", "by", "the", "False", "Failure", "Rate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "The ratios in the series are the Positive Predictive Value (PPV, or precision) (TP / (TP + FP)), supplemented by the False Discovery Rate (FDR) (FP / (TP + FP)); and the Negative Predictive Value (NPV) (TN / (TN + FN)), supplemented by the False Failure Rate (FOR) (FN / (TN + FN)).", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 17], [18, 24], [25, 28], [29, 32], [33, 41], [42, 52], [53, 58], [59, 60], [60, 63], [63, 64], [65, 67], [68, 77], [77, 78], [79, 80], [80, 82], [83, 84], [85, 86], [86, 88], [89, 90], [91, 93], [93, 94], [94, 95], [95, 96], [97, 109], [110, 112], [113, 116], [117, 122], [123, 132], [133, 137], [138, 139], [139, 142], [142, 143], [144, 145], [145, 147], [148, 149], [150, 151], [151, 153], [154, 155], [156, 158], [158, 159], [159, 160], [160, 161], [162, 165], [166, 169], [170, 178], [179, 189], [190, 195], [196, 197], [197, 200], [200, 201], [202, 203], [203, 205], [206, 207], [208, 209], [209, 211], [212, 213], [214, 216], [216, 217], [217, 218], [218, 219], [220, 232], [233, 235], [236, 239], [240, 245], [246, 253], [254, 258], [259, 260], [260, 263], [263, 264], [265, 266], [266, 268], [269, 270], [271, 272], [272, 274], [275, 276], [277, 279], [279, 280], [280, 281], [281, 282]]}
{"doc_key": "ai-dev-160", "ner": [[8, 8, "misc"], [13, 16, "algorithm"], [21, 21, "algorithm"], [19, 23, "algorithm"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[19, 23, 21, 21, "named", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["The", "information", "is", "a", "mixture", "of", "sitemaps", "and", "RSS", "and", "is", "generated", "using", "Information", "Model", "(", "IM", ")", "and", "Biomedical", "Resource", "Ontology", "(", "BRO", ")", "."], "sentence-detokenized": "The information is a mixture of sitemaps and RSS and is generated using Information Model (IM) and Biomedical Resource Ontology (BRO).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 20], [21, 28], [29, 31], [32, 40], [41, 44], [45, 48], [49, 52], [53, 55], [56, 65], [66, 71], [72, 83], [84, 89], [90, 91], [91, 93], [93, 94], [95, 98], [99, 109], [110, 118], [119, 127], [128, 129], [129, 132], [132, 133], [133, 134]]}
{"doc_key": "ai-dev-161", "ner": [[1, 2, "task"], [7, 9, "algorithm"], [11, 15, "algorithm"], [21, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 11, 15, "origin", "based_on", false, false], [11, 15, 7, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Recent", "text", "recognition", "is", "based", "on", "a", "recurrent", "neural", "network", "(", "long", "short", "-", "term", "memory", ")", "and", "does", "not", "require", "a", "language", "model", "."], "sentence-detokenized": "Recent text recognition is based on a recurrent neural network (long short-term memory) and does not require a language model.", "token2charspan": [[0, 6], [7, 11], [12, 23], [24, 26], [27, 32], [33, 35], [36, 37], [38, 47], [48, 54], [55, 62], [63, 64], [64, 68], [69, 74], [74, 75], [75, 79], [80, 86], [86, 87], [88, 91], [92, 96], [97, 100], [101, 108], [109, 110], [111, 119], [120, 125], [125, 126]]}
{"doc_key": "ai-dev-162", "ner": [[1, 2, "misc"], [4, 6, "metrics"], [9, 10, "algorithm"], [13, 14, "metrics"], [17, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 1, 2, "type-of", "", false, false], [9, 10, 4, 6, "related-to", "", true, false], [13, 14, 1, 2, "type-of", "", false, false], [17, 18, 13, 14, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Popular", "loss", "functions", "include", "joi", "nt", "loss", "(", "for", "linear", "SVMs", ")", "and", "log", "loss", "(", "for", "logistic", "regression", ")", "."], "sentence-detokenized": "Popular loss functions include joint loss (for linear SVMs) and log loss (for logistic regression).", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 30], [31, 34], [34, 36], [37, 41], [42, 43], [43, 46], [47, 53], [54, 58], [58, 59], [60, 63], [64, 67], [68, 72], [73, 74], [74, 77], [78, 86], [87, 97], [97, 98], [98, 99]]}
{"doc_key": "ai-dev-163", "ner": [[0, 0, "metrics"], [12, 17, "metrics"], [11, 19, "metrics"], [23, 24, "metrics"], [22, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 12, 17, "compare", "", false, false], [0, 0, 23, 24, "compare", "", false, false], [11, 19, 12, 17, "named", "", false, false], [22, 26, 23, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "is", "designed", "to", "improve", "on", "traditional", "methods", "such", "as", "the", "peak", "signal", "-", "to", "-", "noise", "ratio", "(", "PSNR", ")", "and", "mean", "square", "error", "(", "MSE", ")", "."], "sentence-detokenized": "SSIM is designed to improve on traditional methods such as the peak signal-to-noise ratio (PSNR) and mean square error (MSE).", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 27], [28, 30], [31, 42], [43, 50], [51, 55], [56, 58], [59, 62], [63, 67], [68, 74], [74, 75], [75, 77], [77, 78], [78, 83], [84, 89], [90, 91], [91, 95], [95, 96], [97, 100], [101, 105], [106, 112], [113, 118], [119, 120], [120, 123], [123, 124], [124, 125]]}
{"doc_key": "ai-dev-164", "ner": [[10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "inspired", "subsequent", "generations", "of", "robotics", "researchers", ",", "including", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "His work inspired subsequent generations of robotics researchers, including Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 28], [29, 40], [41, 43], [44, 52], [53, 64], [64, 65], [66, 75], [76, 82], [83, 89], [89, 90], [91, 95], [96, 103], [104, 107], [108, 112], [113, 119], [119, 120]]}
{"doc_key": "ai-dev-165", "ner": [[9, 11, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 9, 11, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["Further", ",", "pulse", "training", "is", "not", "differentiable", ",", "eliminating", "backpropagation", "-", "based", "training", "methods", "such", "as", "gradient", "descent", "."], "sentence-detokenized": "Further, pulse training is not differentiable, eliminating backpropagation-based training methods such as gradient descent.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 23], [24, 26], [27, 30], [31, 45], [45, 46], [47, 58], [59, 74], [74, 75], [75, 80], [81, 89], [90, 97], [98, 102], [103, 105], [106, 114], [115, 122], [122, 123]]}
{"doc_key": "ai-dev-166", "ner": [[8, 9, "metrics"], [16, 17, "metrics"], [19, 19, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 16, 17, "related-to", "describes", false, false], [16, 17, 19, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "relationships", "can", "be", "easily", "represented", "by", "a", "confusion", "matrix", ",", "a", "table", "that", "describes", "the", "accuracy", "of", "a", "classification", "model", "."], "sentence-detokenized": "These relationships can be easily represented by a confusion matrix, a table that describes the accuracy of a classification model.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 26], [27, 33], [34, 45], [46, 48], [49, 50], [51, 60], [61, 67], [67, 68], [69, 70], [71, 76], [77, 81], [82, 91], [92, 95], [96, 104], [105, 107], [108, 109], [110, 124], [125, 130], [130, 131]]}
{"doc_key": "ai-dev-167", "ner": [[2, 10, "conference"], [3, 8, "conference"], [12, 12, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 8, 2, 10, "named", "", false, false], [12, 12, 2, 10, "physical", "", false, false], [12, 12, 2, 10, "role", "", false, false], [12, 12, 2, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["At", "the", "2018", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "conference", ",", "Google", "researchers", "presented", "the", "work"], "sentence-detokenized": "At the 2018 Neural Information Processing Systems (NeurIPS) conference, Google researchers presented the work", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 30], [31, 41], [42, 49], [50, 51], [51, 58], [58, 59], [60, 70], [70, 71], [72, 78], [79, 90], [91, 100], [101, 104], [105, 109]]}
{"doc_key": "ai-dev-168", "ner": [[0, 4, "university"], [14, 14, "product"], [19, 21, "misc"], [25, 25, "conference"], [30, 33, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 14, 19, 21, "win-defeat", "", false, false], [19, 21, 25, 25, "temporal", "", false, false], [30, 33, 25, 25, "part-of", "", false, false], [30, 33, 25, 25, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "his", "time", "at", "Duke", ",", "he", "worked", "on", "an", "automated", "crossword", "puzzle", "solver", "PROVERB", ",", "which", "won", "the", "Outstanding", "Paper", "Award", "in", "1999", "from", "AAAI", "and", "participated", "in", "the", "American", "Crossword", "Puzzle", "Tournament", "."], "sentence-detokenized": "During his time at Duke, he worked on an automated crossword puzzle solver PROVERB, which won the Outstanding Paper Award in 1999 from AAAI and participated in the American Crossword Puzzle Tournament.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 18], [19, 23], [23, 24], [25, 27], [28, 34], [35, 37], [38, 40], [41, 50], [51, 60], [61, 67], [68, 74], [75, 82], [82, 83], [84, 89], [90, 93], [94, 97], [98, 109], [110, 115], [116, 121], [122, 124], [125, 129], [130, 134], [135, 139], [140, 143], [144, 156], [157, 159], [160, 163], [164, 172], [173, 182], [183, 189], [190, 200], [200, 201]]}
{"doc_key": "ai-dev-169", "ner": [[2, 3, "location"], [5, 5, "location"], [15, 15, "country"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 5, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Headquartered", "in", "Rochester", "Hills", ",", "Michigan", ",", "the", "company", "had", "10", "regional", "locations", "in", "the", "US", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "sentence-detokenized": "Headquartered in Rochester Hills, Michigan, the company had 10 regional locations in the US, Canada, Mexico and Brazil.", "token2charspan": [[0, 13], [14, 16], [17, 26], [27, 32], [32, 33], [34, 42], [42, 43], [44, 47], [48, 55], [56, 59], [60, 62], [63, 71], [72, 81], [82, 84], [85, 88], [89, 91], [91, 92], [93, 99], [99, 100], [101, 107], [108, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-dev-170", "ner": [[14, 14, "product"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "part", "of", "a", "collection", "of", "historically", "significant", "robots", "that", "includes", "an", "early", "Unimate", "and", "the", "Odetics", "Odex", "1", "."], "sentence-detokenized": "It is part of a collection of historically significant robots that includes an early Unimate and the Odetics Odex 1.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 15], [16, 26], [27, 29], [30, 42], [43, 54], [55, 61], [62, 66], [67, 75], [76, 78], [79, 84], [85, 92], [93, 96], [97, 100], [101, 108], [109, 113], [114, 115], [115, 116]]}
{"doc_key": "ai-dev-171", "ner": [[7, 7, "researcher"], [12, 12, "organisation"], [14, 15, "researcher"], [25, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 12, 12, "physical", "", false, false], [7, 7, 12, 12, "role", "", false, false], [14, 15, 12, 12, "physical", "", false, false], [14, 15, 12, 12, "role", "", false, false], [14, 15, 25, 28, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Guest", "editor", "of", "this", "issue", "will", "be", "David", "'s", "former", "colleague", "at", "NIST", ",", "Judah", "Levine", ",", "who", "is", "the", "most", "recent", "recipient", "of", "the", "I.I", ".", "Rabi", "Award", "."], "sentence-detokenized": "Guest editor of this issue will be David's former colleague at NIST, Judah Levine, who is the most recent recipient of the I.I. Rabi Award.", "token2charspan": [[0, 5], [6, 12], [13, 15], [16, 20], [21, 26], [27, 31], [32, 34], [35, 40], [40, 42], [43, 49], [50, 59], [60, 62], [63, 67], [67, 68], [69, 74], [75, 81], [81, 82], [83, 86], [87, 89], [90, 93], [94, 98], [99, 105], [106, 115], [116, 118], [119, 122], [123, 126], [126, 127], [128, 132], [133, 138], [138, 139]]}
{"doc_key": "ai-dev-172", "ner": [[12, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "can", "be", "placed", "in", "a", "2", "\u00d7", "2", "contingency", "table", "(", "confusion", "table", ")", ",", "with", "the", "test", "result", "on", "the", "vertical", "axis", "and", "the", "actual", "situation", "on", "the", "horizontal", "axis", "."], "sentence-detokenized": "These can be placed in a 2 \u00d7 2 contingency table (confusion table), with the test result on the vertical axis and the actual situation on the horizontal axis.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 19], [20, 22], [23, 24], [25, 26], [27, 28], [29, 30], [31, 42], [43, 48], [49, 50], [50, 59], [60, 65], [65, 66], [66, 67], [68, 72], [73, 76], [77, 81], [82, 88], [89, 91], [92, 95], [96, 104], [105, 109], [110, 113], [114, 117], [118, 124], [125, 134], [135, 137], [138, 141], [142, 152], [153, 157], [157, 158]]}
{"doc_key": "ai-dev-173", "ner": [[0, 4, "product"], [8, 8, "product"], [10, 10, "product"], [12, 13, "product"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 8, 8, "part-of", "", false, false], [0, 4, 10, 10, "part-of", "", false, false], [0, 4, 12, 13, "part-of", "", false, false], [0, 4, 15, 17, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Apple", "'s", "iOS", "operating", "system", "used", "on", "the", "iPhone", ",", "iPad", "and", "iPod", "Touch", "uses", "VoiceOver", "speech", "synthesis", "accessibility", "."], "sentence-detokenized": "Apple's iOS operating system used on the iPhone, iPad and iPod Touch uses VoiceOver speech synthesis accessibility.", "token2charspan": [[0, 5], [5, 7], [8, 11], [12, 21], [22, 28], [29, 33], [34, 36], [37, 40], [41, 47], [47, 48], [49, 53], [54, 57], [58, 62], [63, 68], [69, 73], [74, 83], [84, 90], [91, 100], [101, 114], [114, 115]]}
{"doc_key": "ai-dev-174", "ner": [[7, 9, "conference"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "the", "best", "system", "entering", "MUC", "-", "7", "scored", "93.39", "%", "of", "the", "F", "-", "measure", ",", "while", "the", "human", "annotators", "scored", "97.6", "%", "and", "96.95", "%", "."], "sentence-detokenized": "For example, the best system entering MUC-7 scored 93.39% of the F-measure, while the human annotators scored 97.6% and 96.95%.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 37], [38, 41], [41, 42], [42, 43], [44, 50], [51, 56], [56, 57], [58, 60], [61, 64], [65, 66], [66, 67], [67, 74], [74, 75], [76, 81], [82, 85], [86, 91], [92, 102], [103, 109], [110, 114], [114, 115], [116, 119], [120, 125], [125, 126], [126, 127]]}
{"doc_key": "ai-dev-175", "ner": [[12, 14, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 16, 12, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "done", "using", "standard", "neural", "network", "training", "algorithms", ",", "such", "as", "stochastic", "gradient", "descent", "with", "backpropagation", "."], "sentence-detokenized": "This is done using standard neural network training algorithms, such as stochastic gradient descent with backpropagation.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 18], [19, 27], [28, 34], [35, 42], [43, 51], [52, 62], [62, 63], [64, 68], [69, 71], [72, 82], [83, 91], [92, 99], [100, 104], [105, 120], [120, 121]]}
{"doc_key": "ai-dev-176", "ner": [[0, 1, "organisation"], [22, 22, "country"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "is", "one", "of", "the", "top", "1000", "sites", ",", "ranking", "around", "#", "400", "worldwide", "and", "in", "the", "top", "150", "for", "the", "US", "alone", ",", "according", "to", "Alexa", ",", "which", "ranks", "sites", "."], "sentence-detokenized": "Rotten Tomatoes is one of the top 1000 sites, ranking around #400 worldwide and in the top 150 for the US alone, according to Alexa, which ranks sites.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 22], [23, 25], [26, 29], [30, 33], [34, 38], [39, 44], [44, 45], [46, 53], [54, 60], [61, 62], [62, 65], [66, 75], [76, 79], [80, 82], [83, 86], [87, 90], [91, 94], [95, 98], [99, 102], [103, 105], [106, 111], [111, 112], [113, 122], [123, 125], [126, 131], [131, 132], [133, 138], [139, 144], [145, 150], [150, 151]]}
{"doc_key": "ai-dev-177", "ner": [[16, 17, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "general", ",", "all", "learning", "shows", "a", "gradual", "change", "over", "time", ",", "but", "it", "describes", "a", "sigmoidal", "function", "that", "has", "a", "different", "appearance", "depending", "on", "the", "time", "scale", "of", "observation", "."], "sentence-detokenized": "In general, all learning shows a gradual change over time, but it describes a sigmoidal function that has a different appearance depending on the time scale of observation.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 24], [25, 30], [31, 32], [33, 40], [41, 47], [48, 52], [53, 57], [57, 58], [59, 62], [63, 65], [66, 75], [76, 77], [78, 87], [88, 96], [97, 101], [102, 105], [106, 107], [108, 117], [118, 128], [129, 138], [139, 141], [142, 145], [146, 150], [151, 156], [157, 159], [160, 171], [171, 172]]}
{"doc_key": "ai-dev-178", "ner": [[0, 0, "metrics"], [5, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["SSD", "is", "also", "known", "as", "mean", "square", "error", "."], "sentence-detokenized": "SSD is also known as mean square error.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 17], [18, 20], [21, 25], [26, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-dev-179", "ner": [[0, 2, "algorithm"], [4, 5, "algorithm"], [8, 12, "algorithm"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 23, 24, "related-to", "can_be_related_to", true, false], [4, 5, 23, 24, "related-to", "can_be_related_to", true, false], [8, 12, 23, 24, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", ",", "neural", "networks", "or", "a", "naive", "Bayes", "classifier", "could", "be", "used", "in", "conjunction", "with", "measures", "of", "model", "quality", "such", "as", "balanced", "accuracy", "."], "sentence-detokenized": "Decision tree learning, neural networks or a naive Bayes classifier could be used in conjunction with measures of model quality such as balanced accuracy.", "token2charspan": [[0, 8], [9, 13], [14, 22], [22, 23], [24, 30], [31, 39], [40, 42], [43, 44], [45, 50], [51, 56], [57, 67], [68, 73], [74, 76], [77, 81], [82, 84], [85, 96], [97, 101], [102, 110], [111, 113], [114, 119], [120, 127], [128, 132], [133, 135], [136, 144], [145, 153], [153, 154]]}
{"doc_key": "ai-dev-180", "ner": [[15, 15, "conference"], [21, 25, "conference"], [26, 29, "misc"], [34, 36, "product"], [43, 46, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[26, 29, 21, 25, "origin", "", false, false], [26, 29, 21, 25, "temporal", "", false, false], [34, 36, 26, 29, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "is", "a", "past", "president", "(", "1979", ")", "and", "founding", "member", "(", "2011", ")", "of", "ACL", ",", "a", "co-recipient", "of", "the", "1992", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "for", "his", "contribution", "to", "the", "Interlisp", "programming", "system", ",", "and", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "He is a past president (1979) and founding member (2011) of ACL, a co-recipient of the 1992 Association for Computing Machinery Software Systems Award for his contribution to the Interlisp programming system, and a member of the Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 22], [23, 24], [24, 28], [28, 29], [30, 33], [34, 42], [43, 49], [50, 51], [51, 55], [55, 56], [57, 59], [60, 63], [63, 64], [65, 66], [67, 79], [80, 82], [83, 86], [87, 91], [92, 103], [104, 107], [108, 117], [118, 127], [128, 136], [137, 144], [145, 150], [151, 154], [155, 158], [159, 171], [172, 174], [175, 178], [179, 188], [189, 200], [201, 207], [207, 208], [209, 212], [213, 214], [215, 221], [222, 224], [225, 228], [229, 240], [241, 244], [245, 254], [255, 264], [264, 265]]}
{"doc_key": "ai-dev-181", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 13, "researcher"], [28, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 28, 31, "related-to", "", false, false], [5, 6, 28, 31, "related-to", "", false, false], [8, 8, 28, 31, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "is", "considered", "by", "Cade", "Metz", "as", "one", "of", "the", "three", "people", "who", "were", "most", "responsible", "for", "the", "progress", "of", "deep", "learning", "during", "the", "1990s", "and", "2000s", "."], "sentence-detokenized": "Along with Geoffrey Hinton and Yann LeCun, Bengio is considered by Cade Metz as one of the three people who were most responsible for the progress of deep learning during the 1990s and 2000s.", "token2charspan": [[0, 5], [6, 10], [11, 19], [20, 26], [27, 30], [31, 35], [36, 41], [41, 42], [43, 49], [50, 52], [53, 63], [64, 66], [67, 71], [72, 76], [77, 79], [80, 83], [84, 86], [87, 90], [91, 96], [97, 103], [104, 107], [108, 112], [113, 117], [118, 129], [130, 133], [134, 137], [138, 146], [147, 149], [150, 154], [155, 163], [164, 170], [171, 174], [175, 180], [181, 184], [185, 190], [190, 191]]}
{"doc_key": "ai-dev-182", "ner": [[0, 2, "field"], [4, 5, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "information", "theory", "and", "computer", "science", ",", "a", "code", "is", "usually", "thought", "of", "as", "an", "algorithm", "that", "represents", "unique", "symbols", "from", "a", "source", "alphabet", "with", "encoded", "strings", ",", "which", "may", "be", "in", "some", "other", "target", "alphabet", "."], "sentence-detokenized": "In information theory and computer science, a code is usually thought of as an algorithm that represents unique symbols from a source alphabet with encoded strings, which may be in some other target alphabet.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 45], [46, 50], [51, 53], [54, 61], [62, 69], [70, 72], [73, 75], [76, 78], [79, 88], [89, 93], [94, 104], [105, 111], [112, 119], [120, 124], [125, 126], [127, 133], [134, 142], [143, 147], [148, 155], [156, 163], [163, 164], [165, 170], [171, 174], [175, 177], [178, 180], [181, 185], [186, 191], [192, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-dev-183", "ner": [[7, 8, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 7, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "fairly", "simple", "nonlinear", "function", ",", "the", "sigmoid", "function", ",", "such", "as", "the", "logistic", "function", ",", "also", "has", "an", "easily", "computable", "derivative", ",", "which", "can", "be", "important", "when", "calculating", "updates", "of", "weights", "in", "the", "network", "."], "sentence-detokenized": "A fairly simple nonlinear function, the sigmoid function, such as the logistic function, also has an easily computable derivative, which can be important when calculating updates of weights in the network.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 25], [26, 34], [34, 35], [36, 39], [40, 47], [48, 56], [56, 57], [58, 62], [63, 65], [66, 69], [70, 78], [79, 87], [87, 88], [89, 93], [94, 97], [98, 100], [101, 107], [108, 118], [119, 129], [129, 130], [131, 136], [137, 140], [141, 143], [144, 153], [154, 158], [159, 170], [171, 178], [179, 181], [182, 189], [190, 192], [193, 196], [197, 204], [204, 205]]}
{"doc_key": "ai-dev-184", "ner": [[0, 0, "person"], [4, 4, "location"], [6, 6, "location"], [8, 10, "country"], [13, 13, "country"], [16, 18, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 4, "physical", "", false, false], [4, 4, 6, 6, "physical", "", false, false], [6, 6, 8, 10, "physical", "", false, false], [6, 6, 13, 13, "physical", "", false, false], [6, 6, 16, 18, "physical", "", false, false], [13, 13, 8, 10, "origin", "", false, false], [16, 18, 13, 13, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "was", "born", "in", "Hronov", ",", "Bohemia", "(", "Austria", "-", "Hungary", ",", "later", "Czechoslovakia", ",", "now", "the", "Czech", "Republic", ")", "in", "1887", "."], "sentence-detokenized": "\u010capek was born in Hronov, Bohemia (Austria-Hungary, later Czechoslovakia, now the Czech Republic) in 1887.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 24], [24, 25], [26, 33], [34, 35], [35, 42], [42, 43], [43, 50], [50, 51], [52, 57], [58, 72], [72, 73], [74, 77], [78, 81], [82, 87], [88, 96], [96, 97], [98, 100], [101, 105], [105, 106]]}
{"doc_key": "ai-dev-185", "ner": [[5, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "specialized", "software", "can", "narrate", "RSS", "."], "sentence-detokenized": "Some specialized software can narrate RSS.", "token2charspan": [[0, 4], [5, 16], [17, 25], [26, 29], [30, 37], [38, 41], [41, 42]]}
{"doc_key": "ai-dev-186", "ner": [[6, 7, "task"], [11, 12, "task"], [14, 14, "task"], [16, 16, "task"], [19, 20, "task"], [27, 28, "task"], [31, 32, "task"], [37, 38, "task"], [41, 43, "product"], [45, 46, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[6, 7, 11, 12, "related-to", "", true, false], [6, 7, 14, 14, "related-to", "", true, false], [6, 7, 16, 16, "related-to", "", true, false], [31, 32, 27, 28, "usage", "", true, false], [41, 43, 37, 38, "type-of", "", false, false], [45, 46, 37, 38, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Aspects", "of", "ontology", "processors", "include", ":", "visual", "navigation", "capabilities", "within", "the", "knowledge", "model", ",", "inference", "and", "extraction", "engines", ",", "module", "support", ",", "import", "and", "export", "of", "foreign", "knowledge", "representation", "languages", "for", "ontology", "mapping", ",", "and", "support", "for", "meta", "-ontologies", "such", "as", "OWL", "-", "S", ",", "Dublin", "Core", ",", "etc", "."], "sentence-detokenized": "Aspects of ontology processors include: visual navigation capabilities within the knowledge model, inference and extraction engines, module support, import and export of foreign knowledge representation languages for ontology mapping, and support for meta-ontologies such as OWL-S, Dublin Core, etc.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 30], [31, 38], [38, 39], [40, 46], [47, 57], [58, 70], [71, 77], [78, 81], [82, 91], [92, 97], [97, 98], [99, 108], [109, 112], [113, 123], [124, 131], [131, 132], [133, 139], [140, 147], [147, 148], [149, 155], [156, 159], [160, 166], [167, 169], [170, 177], [178, 187], [188, 202], [203, 212], [213, 216], [217, 225], [226, 233], [233, 234], [235, 238], [239, 246], [247, 250], [251, 255], [255, 266], [267, 271], [272, 274], [275, 278], [278, 279], [279, 280], [280, 281], [282, 288], [289, 293], [293, 294], [295, 298], [298, 299]]}
{"doc_key": "ai-dev-187", "ner": [[0, 1, "organisation"], [6, 9, "misc"], [12, 13, "task"], [20, 20, "field"], [23, 23, "misc"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 9, 0, 1, "origin", "", false, false], [12, 13, 6, 9, "part-of", "", false, false], [20, 20, 6, 9, "part-of", "", false, false], [23, 23, 20, 20, "type-of", "", false, false], [25, 26, 20, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "FBI", "has", "also", "established", "the", "Next", "Generation", "Identification", "Program", "that", "includes", "facial", "recognition", ",", "as", "well", "as", "more", "traditional", "biometrics", "such", "as", "fingerprints", "and", "iris", "scans", ",", "which", "can", "be", "drawn", "from", "both", "criminal", "and", "civilian", "databases", "."], "sentence-detokenized": "The FBI has also established the Next Generation Identification Program that includes facial recognition, as well as more traditional biometrics such as fingerprints and iris scans, which can be drawn from both criminal and civilian databases.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 28], [29, 32], [33, 37], [38, 48], [49, 63], [64, 71], [72, 76], [77, 85], [86, 92], [93, 104], [104, 105], [106, 108], [109, 113], [114, 116], [117, 121], [122, 133], [134, 144], [145, 149], [150, 152], [153, 165], [166, 169], [170, 174], [175, 180], [180, 181], [182, 187], [188, 191], [192, 194], [195, 200], [201, 205], [206, 210], [211, 219], [220, 223], [224, 232], [233, 242], [242, 243]]}
{"doc_key": "ai-dev-188", "ner": [[5, 6, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "2016", "season", ",", "Samantha", "Ponder", "was", "added", "as", "host", ",", "replacing", "Molly", "McGrath", "."], "sentence-detokenized": "For the 2016 season, Samantha Ponder was added as host, replacing Molly McGrath.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 19], [19, 20], [21, 29], [30, 36], [37, 40], [41, 46], [47, 49], [50, 54], [54, 55], [56, 65], [66, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-dev-189", "ner": [[3, 5, "algorithm"], [18, 22, "misc"], [24, 24, "misc"], [26, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "a", "contrastive", "search", "algorithm", "commonly", "used", "for", "the", "mechanical", "play", "of", "two", "-", "player", "games", "(", "Tic", "-", "tac", "-", "toe", ",", "chess", ",", "Go", ",", "etc", "."], "sentence-detokenized": "It is a contrastive search algorithm commonly used for the mechanical play of two-player games (Tic-tac-toe, chess, Go, etc.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 19], [20, 26], [27, 36], [37, 45], [46, 50], [51, 54], [55, 58], [59, 69], [70, 74], [75, 77], [78, 81], [81, 82], [82, 88], [89, 94], [95, 96], [96, 99], [99, 100], [100, 103], [103, 104], [104, 107], [107, 108], [109, 114], [114, 115], [116, 118], [118, 119], [120, 123], [123, 124]]}
{"doc_key": "ai-dev-190", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "encompasses", "the", "fields", "of", "computer", "vision", "or", "machine", "vision", "and", "medical", "imaging", "and", "makes", "extensive", "use", "of", "pattern", "recognition", ",", "digital", "geometry", "and", "signal", "processing", "."], "sentence-detokenized": "It encompasses the fields of computer vision or machine vision and medical imaging and makes extensive use of pattern recognition, digital geometry and signal processing.", "token2charspan": [[0, 2], [3, 14], [15, 18], [19, 25], [26, 28], [29, 37], [38, 44], [45, 47], [48, 55], [56, 62], [63, 66], [67, 74], [75, 82], [83, 86], [87, 92], [93, 102], [103, 106], [107, 109], [110, 117], [118, 129], [129, 130], [131, 138], [139, 147], [148, 151], [152, 158], [159, 169], [169, 170]]}
{"doc_key": "ai-dev-191", "ner": [[2, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "facial", "recognition", "system", ",", "for", "example", ",", "the", "image", "of", "a", "person", "'s", "face", "would", "be", "the", "input", "and", "the", "output", "tag", "would", "be", "the", "person", "'s", "name", "."], "sentence-detokenized": "In the facial recognition system, for example, the image of a person's face would be the input and the output tag would be the person's name.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 25], [26, 32], [32, 33], [34, 37], [38, 45], [45, 46], [47, 50], [51, 56], [57, 59], [60, 61], [62, 68], [68, 70], [71, 75], [76, 81], [82, 84], [85, 88], [89, 94], [95, 98], [99, 102], [103, 109], [110, 113], [114, 119], [120, 122], [123, 126], [127, 133], [133, 135], [136, 140], [140, 141]]}
{"doc_key": "ai-dev-192", "ner": [[0, 1, "organisation"], [4, 5, "product"], [9, 11, "product"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 5, "artifact", "", false, false], [4, 5, 9, 11, "part-of", "", false, false], [9, 11, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc", "has", "introduced", "Face", "ID", "on", "its", "flagship", "i", "Phone", "X", "as", "a", "successor", "to", "Touch", "ID", "'s", "biometric", "authentication", ",", "a", "fingerprint", "-", "based", "system", "."], "sentence-detokenized": "Apple Inc has introduced Face ID on its flagship iPhone X as a successor to Touch ID's biometric authentication, a fingerprint-based system.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 24], [25, 29], [30, 32], [33, 35], [36, 39], [40, 48], [49, 50], [50, 55], [56, 57], [58, 60], [61, 62], [63, 72], [73, 75], [76, 81], [82, 84], [84, 86], [87, 96], [97, 111], [111, 112], [113, 114], [115, 126], [126, 127], [127, 132], [133, 139], [139, 140]]}
{"doc_key": "ai-dev-193", "ner": [[3, 4, "metrics"], [7, 8, "metrics"], [22, 25, "metrics"], [28, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Or", "combine", "the", "F", "measure", "with", "the", "squared", "R", "evaluated", "for", "the", "model", "'s", "raw", "output", "and", "the", "target", ",", "or", "the", "cost", "/", "profit", "matrix", "with", "the", "correlation", "coefficient", ",", "and", "so", "on", "."], "sentence-detokenized": "Or combine the F measure with the squared R evaluated for the model's raw output and the target, or the cost/profit matrix with the correlation coefficient, and so on.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 16], [17, 24], [25, 29], [30, 33], [34, 41], [42, 43], [44, 53], [54, 57], [58, 61], [62, 67], [67, 69], [70, 73], [74, 80], [81, 84], [85, 88], [89, 95], [95, 96], [97, 99], [100, 103], [104, 108], [108, 109], [109, 115], [116, 122], [123, 127], [128, 131], [132, 143], [144, 155], [155, 156], [157, 160], [161, 163], [164, 166], [166, 167]]}
{"doc_key": "ai-dev-194", "ner": [[1, 6, "conference"], [12, 14, "location"], [16, 16, "location"], [20, 24, "location"], [26, 26, "location"], [28, 32, "country"], [35, 37, "location"], [40, 44, "location"], [46, 48, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[1, 6, 12, 14, "physical", "", false, false], [1, 6, 20, 24, "physical", "", false, false], [1, 6, 35, 37, "physical", "", false, false], [1, 6, 40, 44, "physical", "", false, false], [12, 14, 16, 16, "physical", "", false, false], [20, 24, 26, 26, "physical", "", false, false], [26, 26, 28, 32, "physical", "", false, false], [35, 37, 46, 48, "physical", "", false, false], [40, 44, 46, 48, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "Spanish", "version", "of", "the", "Campus", "Party", "has", "been", "held", "at", "the", "Colegio", "Miguel", "Hern\u00e1ndez", ",", "Ceulaj", ",", "and", "the", "Municipal", "Sports", "Arena", "of", "Benalm\u00e1dena", "in", "Malaga", ",", "Spain", ",", "as", "well", "as", "at", "the", "Valencia", "County", "Fair", "and", "the", "City", "of", "Arts", "and", "Sciences", "of", "Valencia", "for", "the", "last", "15", "years", "."], "sentence-detokenized": "The Spanish version of the Campus Party has been held at the Colegio Miguel Hern\u00e1ndez, Ceulaj, and the Municipal Sports Arena of Benalm\u00e1dena in Malaga, Spain, as well as at the Valencia County Fair and the City of Arts and Sciences of Valencia for the last 15 years.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 22], [23, 26], [27, 33], [34, 39], [40, 43], [44, 48], [49, 53], [54, 56], [57, 60], [61, 68], [69, 75], [76, 85], [85, 86], [87, 93], [93, 94], [95, 98], [99, 102], [103, 112], [113, 119], [120, 125], [126, 128], [129, 140], [141, 143], [144, 150], [150, 151], [152, 157], [157, 158], [159, 161], [162, 166], [167, 169], [170, 172], [173, 176], [177, 185], [186, 192], [193, 197], [198, 201], [202, 205], [206, 210], [211, 213], [214, 218], [219, 222], [223, 231], [232, 234], [235, 243], [244, 247], [248, 251], [252, 256], [257, 259], [260, 265], [265, 266]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [14, 14, "programlang"], [18, 18, "product"], [20, 20, "product"], [24, 24, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 14, 0, 0, "general-affiliation", "", false, false], [18, 18, 14, 14, "part-of", "", false, false], [20, 20, 14, 14, "part-of", "", false, false], [24, 24, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["gnuplot", "can", "be", "used", "by", "several", "programming", "languages", "to", "graphically", "represent", "data", ",", "including", "Perl", "(", "via", "the", "PDL", "and", "CPAN", "packages", ")", ",", "Python", "(", "via", ")", "."], "sentence-detokenized": "gnuplot can be used by several programming languages to graphically represent data, including Perl (via the PDL and CPAN packages), Python (via).", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 19], [20, 22], [23, 30], [31, 42], [43, 52], [53, 55], [56, 67], [68, 77], [78, 82], [82, 83], [84, 93], [94, 98], [99, 100], [100, 103], [104, 107], [108, 111], [112, 115], [116, 120], [121, 129], [129, 130], [130, 131], [132, 138], [139, 140], [140, 143], [143, 144], [144, 145]]}
{"doc_key": "ai-dev-196", "ner": [[3, 5, "product"], [19, 19, "conference"], [21, 21, "conference"], [35, 35, "conference"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 3, 5, "topic", "", false, false], [21, 21, 3, 5, "topic", "", false, false], [35, 35, 3, 5, "topic", "", false, false], [37, 37, 3, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "field", "of", "spoken", "dialogue", "systems", "is", "quite", "large", "and", "includes", "research", "(", "presented", "at", "scientific", "conferences", "such", "as", "SIGdial", "and", "Interspeech", ")", "and", "a", "large", "industrial", "sector", "(", "with", "its", "own", "meetings", "such", "as", "SpeechTek", "and", "AVIOS", ")", "."], "sentence-detokenized": "The field of spoken dialogue systems is quite large and includes research (presented at scientific conferences such as SIGdial and Interspeech) and a large industrial sector (with its own meetings such as SpeechTek and AVIOS).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 28], [29, 36], [37, 39], [40, 45], [46, 51], [52, 55], [56, 64], [65, 73], [74, 75], [75, 84], [85, 87], [88, 98], [99, 110], [111, 115], [116, 118], [119, 126], [127, 130], [131, 142], [142, 143], [144, 147], [148, 149], [150, 155], [156, 166], [167, 173], [174, 175], [175, 179], [180, 183], [184, 187], [188, 196], [197, 201], [202, 204], [205, 214], [215, 218], [219, 224], [224, 225], [225, 226]]}
{"doc_key": "ai-dev-197", "ner": [[2, 4, "field"], [7, 8, "task"], [10, 12, "task"], [14, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 2, 4, "part-of", "task_part_of_field", false, false], [10, 12, 2, 4, "part-of", "task_part_of_field", false, false], [14, 16, 2, 4, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Challenges", "in", "natural", "language", "processing", "often", "include", "speech", "recognition", ",", "natural", "language", "understanding", "and", "natural", "language", "generation", "."], "sentence-detokenized": "Challenges in natural language processing often include speech recognition, natural language understanding and natural language generation.", "token2charspan": [[0, 10], [11, 13], [14, 21], [22, 30], [31, 41], [42, 47], [48, 55], [56, 62], [63, 74], [74, 75], [76, 83], [84, 92], [93, 106], [107, 110], [111, 118], [119, 127], [128, 138], [138, 139]]}
{"doc_key": "ai-dev-198", "ner": [[5, 5, "product"], [8, 10, "product"], [39, 40, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 8, 10, "part-of", "", false, false], [5, 5, 39, 40, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "such", "as", "Siri", "in", "the", "iOS", "operating", "system", ",", "operate", "with", "a", "similar", "pattern", "recognition", "technique", "to", "that", "of", "text", "-", "based", "systems", ",", "but", "in", "the", "former", ",", "the", "user", "'s", "input", "is", "done", "through", "speech", "recognition", "."], "sentence-detokenized": "These systems, such as Siri in the iOS operating system, operate with a similar pattern recognition technique to that of text-based systems, but in the former, the user's input is done through speech recognition.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 27], [28, 30], [31, 34], [35, 38], [39, 48], [49, 55], [55, 56], [57, 64], [65, 69], [70, 71], [72, 79], [80, 87], [88, 99], [100, 109], [110, 112], [113, 117], [118, 120], [121, 125], [125, 126], [126, 131], [132, 139], [139, 140], [141, 144], [145, 147], [148, 151], [152, 158], [158, 159], [160, 163], [164, 168], [168, 170], [171, 176], [177, 179], [180, 184], [185, 192], [193, 199], [200, 211], [211, 212]]}
{"doc_key": "ai-dev-199", "ner": [[2, 4, "algorithm"], [17, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 4, 17, 18, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "more", "exotic", "fitness", "functions", "that", "explore", "the", "granularity", "of", "the", "model", "include", "the", "area", "under", "the", "ROC", "curve", "and", "the", "ranking", "measure", "."], "sentence-detokenized": "The more exotic fitness functions that explore the granularity of the model include the area under the ROC curve and the ranking measure.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 23], [24, 33], [34, 38], [39, 46], [47, 50], [51, 62], [63, 65], [66, 69], [70, 75], [76, 83], [84, 87], [88, 92], [93, 98], [99, 102], [103, 106], [107, 112], [113, 116], [117, 120], [121, 128], [129, 136], [136, 137]]}
{"doc_key": "ai-dev-200", "ner": [[2, 3, "product"], [7, 10, "researcher"], [16, 16, "product"], [17, 26, "organisation"], [23, 28, "organisation"], [38, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 7, 10, "origin", "", false, false], [7, 10, 17, 26, "role", "", false, false], [16, 16, 7, 10, "origin", "", false, false], [23, 28, 17, 26, "named", "", false, false], [38, 40, 17, 26, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "term", "Semantic", "Web", "was", "coined", "by", "Tim", "Berners", "-", "Lee", ",", "the", "inventor", "of", "the", "World", "Wide", "Web", "and", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "oversees", "the", "development", "of", "the", "proposed", "Semantic", "Web", "standards", "."], "sentence-detokenized": "The term Semantic Web was coined by Tim Berners-Lee, the inventor of the World Wide Web and director of the World Wide Web Consortium (W3C), which oversees the development of the proposed Semantic Web standards.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 25], [26, 32], [33, 35], [36, 39], [40, 47], [47, 48], [48, 51], [51, 52], [53, 56], [57, 65], [66, 68], [69, 72], [73, 78], [79, 83], [84, 87], [88, 91], [92, 100], [101, 103], [104, 107], [108, 113], [114, 118], [119, 122], [123, 133], [134, 135], [135, 138], [138, 139], [139, 140], [141, 146], [147, 155], [156, 159], [160, 171], [172, 174], [175, 178], [179, 187], [188, 196], [197, 200], [201, 210], [210, 211]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [9, 9, "task"], [16, 17, "product"], [19, 22, "product"], [24, 24, "product"], [27, 28, "product"], [35, 36, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 16, 17, "opposite", "", false, false], [0, 1, 19, 22, "opposite", "", false, false], [0, 1, 27, 28, "opposite", "", false, false], [0, 1, 35, 36, "part-of", "", false, false], [9, 9, 0, 1, "named", "", false, false], [24, 24, 19, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Machine", "translation", ",", "sometimes", "referred", "to", "by", "the", "abbreviation", "MT", "(", "not", "to", "be", "confused", "with", "computer-assisted", "translation", ",", "human", "-", "assisted", "translation", "(", "MAHT", ")", "or", "interactive", "translation", ")", ",", "is", "a", "subfield", "of", "computational", "linguistics", "that", "investigates", "the", "use", "of", "software", "to", "translate", "text", "or", "speech", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Machine translation, sometimes referred to by the abbreviation MT (not to be confused with computer-assisted translation, human-assisted translation (MAHT) or interactive translation), is a subfield of computational linguistics that investigates the use of software to translate text or speech from one language to another.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 30], [31, 39], [40, 42], [43, 45], [46, 49], [50, 62], [63, 65], [66, 67], [67, 70], [71, 73], [74, 76], [77, 85], [86, 90], [91, 108], [109, 120], [120, 121], [122, 127], [127, 128], [128, 136], [137, 148], [149, 150], [150, 154], [154, 155], [156, 158], [159, 170], [171, 182], [182, 183], [183, 184], [185, 187], [188, 189], [190, 198], [199, 201], [202, 215], [216, 227], [228, 232], [233, 245], [246, 249], [250, 253], [254, 256], [257, 265], [266, 268], [269, 278], [279, 283], [284, 286], [287, 293], [294, 298], [299, 302], [303, 311], [312, 314], [315, 322], [322, 323]]}
{"doc_key": "ai-dev-202", "ner": [[1, 4, "product"], [9, 11, "university"], [14, 15, "researcher"], [17, 17, "researcher"], [41, 45, "location"], [43, 43, "location"], [49, 54, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 4, 14, 15, "artifact", "", false, false], [1, 4, 17, 17, "artifact", "", false, false], [14, 15, 9, 11, "physical", "", false, false], [14, 15, 9, 11, "role", "", false, false], [17, 17, 9, 11, "physical", "", false, false], [17, 17, 9, 11, "role", "", false, false], [41, 45, 43, 43, "physical", "", false, false], [49, 54, 41, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Early", "cross", "-language", "MT", "systems", "were", "also", "built", "in", "Stanford", "in", "the", "1970s", "by", "Roger", "Schank", "and", "Yorick", "Wilks", ";", "the", "first", "formed", "the", "basis", "of", "a", "commercial", "system", "for", "transferring", "funds", ",", "while", "the", "code", "for", "the", "second", "is", "kept", "in", "the", "Boston", "Computer", "Museum", "as", "the", "first", "cross", "-", "language", "machine", "translation", "system", "."], "sentence-detokenized": "Early cross-language MT systems were also built in Stanford in the 1970s by Roger Schank and Yorick Wilks; the first formed the basis of a commercial system for transferring funds, while the code for the second is kept in the Boston Computer Museum as the first cross-language machine translation system.", "token2charspan": [[0, 5], [6, 11], [11, 20], [21, 23], [24, 31], [32, 36], [37, 41], [42, 47], [48, 50], [51, 59], [60, 62], [63, 66], [67, 72], [73, 75], [76, 81], [82, 88], [89, 92], [93, 99], [100, 105], [105, 106], [107, 110], [111, 116], [117, 123], [124, 127], [128, 133], [134, 136], [137, 138], [139, 149], [150, 156], [157, 160], [161, 173], [174, 179], [179, 180], [181, 186], [187, 190], [191, 195], [196, 199], [200, 203], [204, 210], [211, 213], [214, 218], [219, 221], [222, 225], [226, 232], [233, 241], [242, 248], [249, 251], [252, 255], [256, 261], [262, 267], [267, 268], [268, 276], [277, 284], [285, 296], [297, 303], [303, 304]]}
{"doc_key": "ai-dev-203", "ner": [[0, 2, "researcher"], [7, 11, "conference"], [8, 14, "conference"], [21, 26, "conference"], [28, 29, "conference"], [35, 38, "organisation"], [47, 47, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 7, 11, "role", "", false, false], [0, 2, 21, 26, "role", "", false, false], [0, 2, 35, 38, "role", "", false, false], [0, 2, 47, 47, "role", "", false, false], [8, 14, 7, 11, "named", "", false, false], [28, 29, 21, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sycara", "served", "as", "program", "chair", "of", "the", "Second", "International", "Semantic", "Web", "Conference", "(", "ISWC", "2003", ")", ",", "general", "chair", "of", "the", "Second", "International", "Conference", "on", "Autonomous", "Agents", "(", "Agents", "98", ")", ",", "chair", "of", "the", "Agents", "Conference", "Steering", "Committee", "(", "1999-2001", ")", ",", "and", "chair", "of", "the", "AAAI", "Fellowship", "Committee", "(", "1993-1999", ")", ","], "sentence-detokenized": "Sycara served as program chair of the Second International Semantic Web Conference (ISWC 2003), general chair of the Second International Conference on Autonomous Agents (Agents 98), chair of the Agents Conference Steering Committee (1999-2001), and chair of the AAAI Fellowship Committee (1993-1999),", "token2charspan": [[0, 6], [7, 13], [14, 16], [17, 24], [25, 30], [31, 33], [34, 37], [38, 44], [45, 58], [59, 67], [68, 71], [72, 82], [83, 84], [84, 88], [89, 93], [93, 94], [94, 95], [96, 103], [104, 109], [110, 112], [113, 116], [117, 123], [124, 137], [138, 148], [149, 151], [152, 162], [163, 169], [170, 171], [171, 177], [178, 180], [180, 181], [181, 182], [183, 188], [189, 191], [192, 195], [196, 202], [203, 213], [214, 222], [223, 232], [233, 234], [234, 243], [243, 244], [244, 245], [246, 249], [250, 255], [256, 258], [259, 262], [263, 267], [268, 278], [279, 288], [289, 290], [290, 299], [299, 300], [300, 301]]}
{"doc_key": "ai-dev-204", "ner": [[11, 11, "conference"], [13, 16, "conference"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 11, 11, "named", "", false, false], [18, 20, 11, 11, "part-of", "", false, false], [18, 20, 11, 11, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2016", ",", "she", "was", "selected", "as", "the", "winner", "of", "the", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "Lifetime", "Achievement", "Award", "."], "sentence-detokenized": "In 2016, she was selected as the winner of the ACL (Association for Computational Linguistics) Lifetime Achievement Award.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 25], [26, 28], [29, 32], [33, 39], [40, 42], [43, 46], [47, 50], [51, 52], [52, 63], [64, 67], [68, 81], [82, 93], [93, 94], [95, 103], [104, 115], [116, 121], [121, 122]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P.", "Frasconi", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 30], [31, 39], [40, 43], [44, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-206", "ner": [[3, 3, "product"], [6, 7, "misc"], [9, 9, "programlang"], [19, 20, "product"], [35, 35, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 9, 9, "usage", "", false, false], [9, 9, 6, 7, "type-of", "", false, false], [9, 9, 19, 20, "related-to", "", false, false], [35, 35, 3, 3, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["For", "example", ",", "A.L.I.C.E.", "uses", "a", "markup", "language", "called", "AIML", ",", "which", "is", "specific", "to", "its", "function", "as", "a", "dialogue", "system", ",", "and", "has", "since", "been", "adopted", "by", "several", "other", "developers", "of", "so", "-", "called", "Alicebots", "."], "sentence-detokenized": "For example, A.L.I.C.E. uses a markup language called AIML, which is specific to its function as a dialogue system, and has since been adopted by several other developers of so-called Alicebots.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 23], [24, 28], [29, 30], [31, 37], [38, 46], [47, 53], [54, 58], [58, 59], [60, 65], [66, 68], [69, 77], [78, 80], [81, 84], [85, 93], [94, 96], [97, 98], [99, 107], [108, 114], [114, 115], [116, 119], [120, 123], [124, 129], [130, 134], [135, 142], [143, 145], [146, 153], [154, 159], [160, 170], [171, 173], [174, 176], [176, 177], [177, 183], [184, 193], [193, 194]]}
{"doc_key": "ai-dev-207", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2000", ",", "he", "was", "elected", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2000, he was elected a member of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-dev-208", "ner": [[1, 2, "misc"], [0, 4, "misc"], [10, 15, "misc"], [24, 25, "algorithm"], [34, 35, "field"], [37, 38, "field"], [41, 42, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 2, 10, 15, "type-of", "", false, false], [1, 2, 34, 35, "related-to", "performs", true, false], [1, 2, 37, 38, "related-to", "performs", true, false], [1, 2, 41, 42, "related-to", "performs", true, false], [0, 4, 1, 2, "named", "", false, false], [24, 25, 10, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Learning", "Classifier", "Systems", "(", "LCS", ")", "are", "a", "family", "of", "rule", "-", "based", "machine", "learning", "algorithms", "that", "combine", "a", "discovery", "component", ",", "usually", "a", "genetic", "algorithm", ",", "with", "a", "learning", "component", "that", "performs", "either", "supervised", "learning", ",", "reinforcement", "learning", ",", "or", "unsupervised", "learning", "."], "sentence-detokenized": "Learning Classifier Systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, usually a genetic algorithm, with a learning component that performs either supervised learning, reinforcement learning, or unsupervised learning.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 29], [29, 32], [32, 33], [34, 37], [38, 39], [40, 46], [47, 49], [50, 54], [54, 55], [55, 60], [61, 68], [69, 77], [78, 88], [89, 93], [94, 101], [102, 103], [104, 113], [114, 123], [123, 124], [125, 132], [133, 134], [135, 142], [143, 152], [152, 153], [154, 158], [159, 160], [161, 169], [170, 179], [180, 184], [185, 193], [194, 200], [201, 211], [212, 220], [220, 221], [222, 235], [236, 244], [244, 245], [246, 248], [249, 261], [262, 270], [270, 271]]}
{"doc_key": "ai-dev-209", "ner": [[16, 16, "algorithm"], [14, 19, "algorithm"], [27, 29, "algorithm"], [31, 32, "misc"], [42, 44, "algorithm"], [52, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[16, 16, 27, 29, "origin", "", false, false], [16, 16, 31, 32, "usage", "", false, false], [14, 19, 16, 16, "named", "", false, false], [42, 44, 31, 32, "type-of", "", false, false], [42, 44, 52, 55, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "unknown", "parameters", "in", "each", "\u03b2subk", "/", "sub", "vector", "are", "usually", "jointly", "estimated", "by", "maximum", "a", "posteriori", "estimation", "(", "MAP", ")", ",", "which", "is", "an", "extension", "of", "maximum", "likelihood", "that", "uses", "normalization", "of", "the", "weights", "to", "avoid", "pathological", "solutions", "(", "usually", "a", "quadratic", "normalization", "function", ",", "which", "is", "equivalent", "to", "fitting", "a", "zero-mean", "prior", "Gaussian", "distribution", "to", "the", "weights", ",", "but", "other", "distributions", "are", "also", "possible", ")", "."], "sentence-detokenized": "The unknown parameters in each \u03b2subk/sub vector are usually jointly estimated by maximum a posteriori estimation (MAP), which is an extension of maximum likelihood that uses normalization of the weights to avoid pathological solutions (usually a quadratic normalization function, which is equivalent to fitting a zero-mean prior Gaussian distribution to the weights, but other distributions are also possible).", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 30], [31, 36], [36, 37], [37, 40], [41, 47], [48, 51], [52, 59], [60, 67], [68, 77], [78, 80], [81, 88], [89, 90], [91, 101], [102, 112], [113, 114], [114, 117], [117, 118], [118, 119], [120, 125], [126, 128], [129, 131], [132, 141], [142, 144], [145, 152], [153, 163], [164, 168], [169, 173], [174, 187], [188, 190], [191, 194], [195, 202], [203, 205], [206, 211], [212, 224], [225, 234], [235, 236], [236, 243], [244, 245], [246, 255], [256, 269], [270, 278], [278, 279], [280, 285], [286, 288], [289, 299], [300, 302], [303, 310], [311, 312], [313, 322], [323, 328], [329, 337], [338, 350], [351, 353], [354, 357], [358, 365], [365, 366], [367, 370], [371, 376], [377, 390], [391, 394], [395, 399], [400, 408], [408, 409], [409, 410]]}
{"doc_key": "ai-dev-210", "ner": [[9, 9, "researcher"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 9, 9, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "hierarchical", "structure", "of", "words", "is", "explicitly", "mapped", "in", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "The hierarchical structure of words is explicitly mapped in George Miller's Wordnet.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 29], [30, 35], [36, 38], [39, 49], [50, 56], [57, 59], [60, 66], [67, 73], [73, 75], [76, 83], [83, 84]]}
{"doc_key": "ai-dev-211", "ner": [[9, 14, "conference"], [21, 24, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 24, 9, 14, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "insight", "into", "their", "capabilities", "is", "given", "by", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", ":", "it", "is", "a", "benchmark", "in", "object", "classification", "and", "detection", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "An insight into their capabilities is given by the ImageNet Large Scale Visual Recognition Challenge: it is a benchmark in object classification and detection, with millions of images and hundreds of object classes.", "token2charspan": [[0, 2], [3, 10], [11, 15], [16, 21], [22, 34], [35, 37], [38, 43], [44, 46], [47, 50], [51, 59], [60, 65], [66, 71], [72, 78], [79, 90], [91, 100], [100, 101], [102, 104], [105, 107], [108, 109], [110, 119], [120, 122], [123, 129], [130, 144], [145, 148], [149, 158], [158, 159], [160, 164], [165, 173], [174, 176], [177, 183], [184, 187], [188, 196], [197, 199], [200, 206], [207, 214], [214, 215]]}
{"doc_key": "ai-dev-212", "ner": [[1, 2, "misc"], [25, 25, "misc"], [27, 29, "person"], [33, 33, "misc"], [36, 38, "person"], [43, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[25, 25, 1, 2, "general-affiliation", "", false, false], [33, 33, 1, 2, "general-affiliation", "", false, false], [33, 33, 27, 29, "artifact", "", false, false], [43, 46, 1, 2, "general-affiliation", "", false, false], [43, 46, 36, 38, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "science", "fiction", ",", "female", "-", "looking", "robots", "are", "often", "produced", "for", "use", "as", "domestic", "servants", "and", "sex", "slaves", ",", "as", "seen", "in", "the", "film", "Westworld", ",", "Paul", "J.", "McAuley", "'s", "1995", "novel", "Fairyland", ",", "and", "Lester", "del", "Rey", "'s", "1938", "short", "story", "Helen", "O'Loy", ",", "and", "sometimes", "as", "warriors", ",", "assassins", ",", "or", "laborers", "."], "sentence-detokenized": "In science fiction, female-looking robots are often produced for use as domestic servants and sex slaves, as seen in the film Westworld, Paul J. McAuley's 1995 novel Fairyland, and Lester del Rey's 1938 short story Helen O'Loy, and sometimes as warriors, assassins, or laborers.", "token2charspan": [[0, 2], [3, 10], [11, 18], [18, 19], [20, 26], [26, 27], [27, 34], [35, 41], [42, 45], [46, 51], [52, 60], [61, 64], [65, 68], [69, 71], [72, 80], [81, 89], [90, 93], [94, 97], [98, 104], [104, 105], [106, 108], [109, 113], [114, 116], [117, 120], [121, 125], [126, 135], [135, 136], [137, 141], [142, 144], [145, 152], [152, 154], [155, 159], [160, 165], [166, 175], [175, 176], [177, 180], [181, 187], [188, 191], [192, 195], [195, 197], [198, 202], [203, 208], [209, 214], [215, 220], [221, 226], [226, 227], [228, 231], [232, 241], [242, 244], [245, 253], [253, 254], [255, 264], [264, 265], [266, 268], [269, 277], [277, 278]]}
{"doc_key": "ai-dev-213", "ner": [[0, 1, "task"], [3, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["question", "answering", ",", "speech", "recognition", "and", "machine", "translation", "."], "sentence-detokenized": "question answering, speech recognition and machine translation.", "token2charspan": [[0, 8], [9, 18], [18, 19], [20, 26], [27, 38], [39, 42], [43, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-214", "ner": [[5, 6, "researcher"], [9, 13, "organisation"], [15, 15, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 9, 13, "role", "", false, false], [9, 13, 15, 15, "physical", "", false, false], [15, 15, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "pioneering", "work", ",", "Harry", "Blum", "of", "the", "Air", "Force", "Cambridge", "Research", "Laboratories", "at", "Hanscom", "Air", "Force", "Base", ",", "Bedford", ",", "Massachusetts", ",", "defined", "a", "mid-axis", "for", "calculating", "the", "skeleton", "of", "a", "shape", "using", "an", "intuitive", "model", "of", "fire", "spread", "in", "a", "grass", "field", ",", "where", "the", "field", "has", "the", "shape", "of", "the", "given", "shape", "."], "sentence-detokenized": "In his pioneering work, Harry Blum of the Air Force Cambridge Research Laboratories at Hanscom Air Force Base, Bedford, Massachusetts, defined a mid-axis for calculating the skeleton of a shape using an intuitive model of fire spread in a grass field, where the field has the shape of the given shape.", "token2charspan": [[0, 2], [3, 6], [7, 17], [18, 22], [22, 23], [24, 29], [30, 34], [35, 37], [38, 41], [42, 45], [46, 51], [52, 61], [62, 70], [71, 83], [84, 86], [87, 94], [95, 98], [99, 104], [105, 109], [109, 110], [111, 118], [118, 119], [120, 133], [133, 134], [135, 142], [143, 144], [145, 153], [154, 157], [158, 169], [170, 173], [174, 182], [183, 185], [186, 187], [188, 193], [194, 199], [200, 202], [203, 212], [213, 218], [219, 221], [222, 226], [227, 233], [234, 236], [237, 238], [239, 244], [245, 250], [250, 251], [252, 257], [258, 261], [262, 267], [268, 271], [272, 275], [276, 281], [282, 284], [285, 288], [289, 294], [295, 300], [300, 301]]}
{"doc_key": "ai-dev-215", "ner": [[15, 15, "algorithm"], [17, 17, "algorithm"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 20, 21, "compare", "", false, false], [17, 17, 20, 21, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "unlike", "boosting", "algorithms", "that", "analytically", "minimize", "a", "convex", "loss", "function", "(", "e.g.", ",", "AdaBoost", "and", "LogitBoost", ")", ",", "Brown", "Boost", "solves", "a", "system", "of", "two", "equations", "and", "two", "unknowns", "using", "standard", "numerical", "methods", "."], "sentence-detokenized": "However, unlike boosting algorithms that analytically minimize a convex loss function (e.g., AdaBoost and LogitBoost), BrownBoost solves a system of two equations and two unknowns using standard numerical methods.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 24], [25, 35], [36, 40], [41, 53], [54, 62], [63, 64], [65, 71], [72, 76], [77, 85], [86, 87], [87, 91], [91, 92], [93, 101], [102, 105], [106, 116], [116, 117], [117, 118], [119, 124], [124, 129], [130, 136], [137, 138], [139, 145], [146, 148], [149, 152], [153, 162], [163, 166], [167, 170], [171, 179], [180, 185], [186, 194], [195, 204], [205, 212], [212, 213]]}
{"doc_key": "ai-dev-216", "ner": [[0, 0, "researcher"], [9, 11, "misc"], [20, 24, "conference"], [18, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 9, 11, "win-defeat", "", false, false], [0, 0, 20, 24, "role", "", false, false], [18, 26, 20, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getoor", "has", "received", "multiple", "best", "paper", "awards", ",", "an", "NSF", "career", "award", "and", "is", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Getoor has received multiple best paper awards, an NSF career award and is a member of the Association for the Advancement of Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 33], [34, 39], [40, 46], [46, 47], [48, 50], [51, 54], [55, 61], [62, 67], [68, 71], [72, 74], [75, 76], [77, 83], [84, 86], [87, 90], [91, 102], [103, 106], [107, 110], [111, 122], [123, 125], [126, 136], [137, 149], [150, 151], [151, 155], [155, 156], [156, 157]]}
{"doc_key": "ai-dev-217", "ner": [[0, 1, "misc"], [6, 10, "misc"], [15, 16, "misc"], [21, 25, "misc"], [30, 31, "misc"], [35, 39, "university"], [44, 53, "misc"], [58, 61, "misc"], [66, 70, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACM", "Fellow", "(", "2015", ")", "br", "Association", "for", "Computational", "Linguistics", "Fellow", "(", "2011", ")", "br", "AAAI", "Fellow", "(", "1994", ")", "br", "International", "Speech", "Communication", "Association", "Fellow", "(", "2011", ")", "br", "Honorary", "Doctorate", "(", "Hedersdoktor", ")", "KTH", "Royal", "Institute", "of", "Technology", "(", "2007", ")", "br", "Distinguished", "Teaching", "Award", "from", "the", "Columbia", "Polytechnic", "Institute", "Alumni", "Association", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")"], "sentence-detokenized": "ACM Fellow (2015) br Association for Computational Linguistics Fellow (2011) br AAAI Fellow (1994) br International Speech Communication Association Fellow (2011) br Honorary Doctorate (Hedersdoktor) KTH Royal Institute of Technology (2007) br Distinguished Teaching Award from the Columbia Polytechnic Institute Alumni Association (2009) br IEEE James L. Flanagan (2011) br ISCA Medal for Scientific Achievement (2011)", "token2charspan": [[0, 3], [4, 10], [11, 12], [12, 16], [16, 17], [18, 20], [21, 32], [33, 36], [37, 50], [51, 62], [63, 69], [70, 71], [71, 75], [75, 76], [77, 79], [80, 84], [85, 91], [92, 93], [93, 97], [97, 98], [99, 101], [102, 115], [116, 122], [123, 136], [137, 148], [149, 155], [156, 157], [157, 161], [161, 162], [163, 165], [166, 174], [175, 184], [185, 186], [186, 198], [198, 199], [200, 203], [204, 209], [210, 219], [220, 222], [223, 233], [234, 235], [235, 239], [239, 240], [241, 243], [244, 257], [258, 266], [267, 272], [273, 277], [278, 281], [282, 290], [291, 302], [303, 312], [313, 319], [320, 331], [332, 333], [333, 337], [337, 338], [339, 341], [342, 346], [347, 352], [353, 355], [356, 364], [365, 366], [366, 370], [370, 371], [372, 374], [375, 379], [380, 385], [386, 389], [390, 400], [401, 412], [413, 414], [414, 418], [418, 419]]}
{"doc_key": "ai-dev-218", "ner": [[6, 6, "university"], [14, 17, "task"], [27, 32, "metrics"], [41, 43, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[27, 32, 41, 43, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["A", "disappointing", "result", "of", "the", "same", "Stanford", "study", "(", "and", "other", "efforts", "to", "improve", "translation", "with", "name", "recognition", ")", "is", "that", "many", "times", ",", "a", "reduction", "in", "bilingual", "assessment", "scores", "for", "translation", "candidates", "will", "result", "from", "the", "inclusion", "of", "methods", "for", "translating", "named", "entities", "."], "sentence-detokenized": "A disappointing result of the same Stanford study (and other efforts to improve translation with name recognition) is that many times, a reduction in bilingual assessment scores for translation candidates will result from the inclusion of methods for translating named entities.", "token2charspan": [[0, 1], [2, 15], [16, 22], [23, 25], [26, 29], [30, 34], [35, 43], [44, 49], [50, 51], [51, 54], [55, 60], [61, 68], [69, 71], [72, 79], [80, 91], [92, 96], [97, 101], [102, 113], [113, 114], [115, 117], [118, 122], [123, 127], [128, 133], [133, 134], [135, 136], [137, 146], [147, 149], [150, 159], [160, 170], [171, 177], [178, 181], [182, 193], [194, 204], [205, 209], [210, 216], [217, 221], [222, 225], [226, 235], [236, 238], [239, 246], [247, 250], [251, 262], [263, 268], [269, 277], [277, 278]]}
{"doc_key": "ai-dev-219", "ner": [[0, 0, "organisation"], [11, 13, "organisation"], [16, 22, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "role", "works_with", false, false], [0, 0, 16, 22, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "uses", "the", "PM", "data", "collected", "and", "collaborates", "with", "researchers", "at", "Johns", "Hopkins", "Hospital", "and", "the", "University", "of", "Washington", "School", "of", "Medicine", "to", "answer", "specific", "questions", "about", "heart", "disease", ",", "such", "as", "whether", "weak", "hearts", "cause", "arrhythmias", "or", "vice", "versa", "."], "sentence-detokenized": "Medtronic uses the PM data collected and collaborates with researchers at Johns Hopkins Hospital and the University of Washington School of Medicine to answer specific questions about heart disease, such as whether weak hearts cause arrhythmias or vice versa.", "token2charspan": [[0, 9], [10, 14], [15, 18], [19, 21], [22, 26], [27, 36], [37, 40], [41, 53], [54, 58], [59, 70], [71, 73], [74, 79], [80, 87], [88, 96], [97, 100], [101, 104], [105, 115], [116, 118], [119, 129], [130, 136], [137, 139], [140, 148], [149, 151], [152, 158], [159, 167], [168, 177], [178, 183], [184, 189], [190, 197], [197, 198], [199, 203], [204, 206], [207, 214], [215, 219], [220, 226], [227, 232], [233, 244], [245, 247], [248, 252], [253, 258], [258, 259]]}
{"doc_key": "ai-dev-220", "ner": [[10, 10, "misc"], [12, 13, "person"], [15, 16, "person"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[12, 13, 10, 10, "role", "", false, false], [15, 16, 10, 10, "role", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["This", "was", "followed", "by", "Paramount", "'s", "first", "feature", "film", ",", "Sangaree", "with", "Fernando", "Lamas", "and", "Arlene", "Dahl", "."], "sentence-detokenized": "This was followed by Paramount's first feature film, Sangaree with Fernando Lamas and Arlene Dahl.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 30], [30, 32], [33, 38], [39, 46], [47, 51], [51, 52], [53, 61], [62, 66], [67, 75], [76, 81], [82, 85], [86, 92], [93, 97], [97, 98]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [8, 10, "researcher"], [12, 14, "researcher"], [17, 18, "organisation"], [20, 21, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 10, "origin", "", false, false], [0, 0, 12, 14, "origin", "", false, false], [8, 10, 17, 18, "physical", "", false, false], [8, 10, 17, 18, "role", "", false, false], [12, 14, 20, 21, "physical", "", false, false], [12, 14, 20, 21, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "is", "a", "knowledge", "representation", "language", "developed", "by", "Daniel", "G.", "Bobrow", "and", "Terry", "Winograd", "while", "working", "at", "Xerox", "PARC", "and", "Stanford", "University", ",", "respectively", "."], "sentence-detokenized": "KRL is a knowledge representation language developed by Daniel G. Bobrow and Terry Winograd while working at Xerox PARC and Stanford University, respectively.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 18], [19, 33], [34, 42], [43, 52], [53, 55], [56, 62], [63, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 97], [98, 105], [106, 108], [109, 114], [115, 119], [120, 123], [124, 132], [133, 143], [143, 144], [145, 157], [157, 158]]}
{"doc_key": "ai-dev-222", "ner": [[0, 10, "conference"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"], [33, 34, "task"], [36, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 10, 33, 34, "topic", "", true, false], [13, 14, 0, 10, "physical", "", false, false], [13, 14, 0, 10, "role", "", false, false], [13, 14, 0, 10, "temporal", "", false, false], [16, 17, 0, 10, "physical", "", false, false], [16, 17, 0, 10, "role", "", false, false], [16, 17, 0, 10, "temporal", "", false, false], [19, 20, 0, 10, "physical", "", false, false], [19, 20, 0, 10, "role", "", false, false], [19, 20, 0, 10, "temporal", "", false, false], [22, 25, 0, 10, "physical", "", false, false], [22, 25, 0, 10, "role", "", false, false], [22, 25, 0, 10, "temporal", "", false, false], [33, 34, 36, 38, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["At", "the", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "in", "2006", ",", "Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", "and", "Kwang", "-", "Ting", "Cheng", "presented", "an", "algorithm", "to", "significantly", "speed", "up", "human", "detection", "using", "HOG", "description", "methods", "."], "sentence-detokenized": "At the IEEE Conference on Computer Vision and Pattern Recognition in 2006, Qiang Zhu, Shai Avidan, Mei-Chen Yeh and Kwang-Ting Cheng presented an algorithm to significantly speed up human detection using HOG description methods.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 22], [23, 25], [26, 34], [35, 41], [42, 45], [46, 53], [54, 65], [66, 68], [69, 73], [73, 74], [75, 80], [81, 84], [84, 85], [86, 90], [91, 97], [97, 98], [99, 107], [108, 111], [112, 115], [116, 121], [121, 122], [122, 126], [127, 132], [133, 142], [143, 145], [146, 155], [156, 158], [159, 172], [173, 178], [179, 181], [182, 187], [188, 197], [198, 203], [204, 207], [208, 219], [220, 227], [227, 228]]}
{"doc_key": "ai-dev-223", "ner": [[0, 2, "researcher"], [6, 6, "conference"], [9, 11, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 6, "role", "", false, false], [0, 2, 9, 11, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "is", "a", "member", "of", "the", "AAAI", "and", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Hayes is a member of the AAAI and the Cognitive Science Society.", "token2charspan": [[0, 5], [6, 8], [9, 10], [11, 17], [18, 20], [21, 24], [25, 29], [30, 33], [34, 37], [38, 47], [48, 55], [56, 63], [63, 64]]}
{"doc_key": "ai-dev-224", "ner": [[0, 1, "misc"], [5, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 32, "field"], [38, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 1, 5, 5, "part-of", "", false, false], [0, 1, 5, 5, "usage", "", false, false], [0, 1, 7, 8, "part-of", "", false, false], [0, 1, 7, 8, "usage", "", false, false], [0, 1, 10, 11, "part-of", "", false, false], [0, 1, 10, 11, "usage", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [0, 1, 13, 13, "usage", "", false, false], [0, 1, 15, 16, "part-of", "", false, false], [0, 1, 15, 16, "usage", "", false, false], [0, 1, 18, 19, "part-of", "", false, false], [0, 1, 18, 19, "usage", "", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 21, 22, "usage", "", false, false], [0, 1, 24, 24, "part-of", "", false, false], [0, 1, 24, 24, "usage", "", false, false], [0, 1, 26, 27, "part-of", "", false, false], [0, 1, 26, 27, "usage", "", false, false], [0, 1, 29, 29, "part-of", "", false, false], [0, 1, 29, 29, "usage", "", false, false], [0, 1, 31, 32, "part-of", "", false, false], [0, 1, 31, 32, "usage", "", false, false], [0, 1, 38, 39, "part-of", "", false, false], [0, 1, 38, 39, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", "and", "largely", "every", "field", "of", "applied", "science", "and", "engineering", "that", "involves", "time", "measurements", "."], "sentence-detokenized": "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering and largely every field of applied science and engineering that involves time measurements.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 23], [24, 34], [34, 35], [36, 42], [43, 53], [53, 54], [55, 62], [63, 74], [74, 75], [76, 88], [88, 89], [90, 102], [103, 110], [110, 111], [112, 119], [120, 131], [131, 132], [133, 143], [144, 154], [154, 155], [156, 178], [178, 179], [180, 187], [188, 199], [199, 200], [201, 210], [210, 211], [212, 226], [227, 238], [239, 242], [243, 250], [251, 256], [257, 262], [263, 265], [266, 273], [274, 281], [282, 285], [286, 297], [298, 302], [303, 311], [312, 316], [317, 329], [329, 330]]}
{"doc_key": "ai-dev-225", "ner": [[13, 14, "metrics"], [36, 38, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "principle", ",", "exact", "recovery", "can", "be", "solved", "in", "its", "feasible", "range", "using", "maximum", "likelihood", ",", "but", "this", "amounts", "to", "solving", "a", "bounded", "or", "normalized", "cutoff", "problem", ",", "such", "as", "minimum", "bisection", ",", "which", "is", "usually", "NP", "-", "complete", "."], "sentence-detokenized": "In principle, exact recovery can be solved in its feasible range using maximum likelihood, but this amounts to solving a bounded or normalized cutoff problem, such as minimum bisection, which is usually NP-complete.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 19], [20, 28], [29, 32], [33, 35], [36, 42], [43, 45], [46, 49], [50, 58], [59, 64], [65, 70], [71, 78], [79, 89], [89, 90], [91, 94], [95, 99], [100, 107], [108, 110], [111, 118], [119, 120], [121, 128], [129, 131], [132, 142], [143, 149], [150, 157], [157, 158], [159, 163], [164, 166], [167, 174], [175, 184], [184, 185], [186, 191], [192, 194], [195, 202], [203, 205], [205, 206], [206, 214], [214, 215]]}
{"doc_key": "ai-dev-226", "ner": [[2, 3, "task"], [12, 13, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 2, 3, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["in", "their", "pedestrian", "detection", "project", ",", "which", "was", "first", "described", "in", "the", "BMVC", "in", "2009", "."], "sentence-detokenized": "in their pedestrian detection project, which was first described in the BMVC in 2009.", "token2charspan": [[0, 2], [3, 8], [9, 19], [20, 29], [30, 37], [37, 38], [39, 44], [45, 48], [49, 54], [55, 64], [65, 67], [68, 71], [72, 76], [77, 79], [80, 84], [84, 85]]}
{"doc_key": "ai-dev-227", "ner": [[5, 9, "conference"], [11, 11, "researcher"], [15, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 5, 9, "physical", "", false, false], [11, 11, 5, 9, "role", "", false, false], [11, 11, 15, 22, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2007", ",", "at", "the", "International", "Conference", "on", "Computer", "Vision", ",", "Terzopoulos", "was", "awarded", "the", "first", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "for", "his", "pioneering", "and", "ongoing", "research", "on", "deformable", "models", "and", "their", "applications", "."], "sentence-detokenized": "In 2007, at the International Conference on Computer Vision, Terzopoulos was awarded the first IEEE PAMI Computer Vision Distinguished Researcher Award for his pioneering and ongoing research on deformable models and their applications.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 40], [41, 43], [44, 52], [53, 59], [59, 60], [61, 72], [73, 76], [77, 84], [85, 88], [89, 94], [95, 99], [100, 104], [105, 113], [114, 120], [121, 134], [135, 145], [146, 151], [152, 155], [156, 159], [160, 170], [171, 174], [175, 182], [183, 191], [192, 194], [195, 205], [206, 212], [213, 216], [217, 222], [223, 235], [235, 236]]}
{"doc_key": "ai-dev-228", "ner": [[0, 3, "task"], [4, 4, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 4, 4, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cluster", "analysis", "or", "cluster", "analysis", "involves", "assigning", "data", "points", "to", "clusters", "so", "that", "items", "belonging", "to", "the", "same", "cluster", "are", "as", "similar", "as", "possible", ",", "while", "items", "belonging", "to", "different", "clusters", "are", "as", "dissimilar", "as", "possible", "."], "sentence-detokenized": "Cluster analysis or cluster analysis involves assigning data points to clusters so that items belonging to the same cluster are as similar as possible, while items belonging to different clusters are as dissimilar as possible.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 36], [37, 45], [46, 55], [56, 60], [61, 67], [68, 70], [71, 79], [80, 82], [83, 87], [88, 93], [94, 103], [104, 106], [107, 110], [111, 115], [116, 123], [124, 127], [128, 130], [131, 138], [139, 141], [142, 150], [150, 151], [152, 157], [158, 163], [164, 173], [174, 176], [177, 186], [187, 195], [196, 199], [200, 202], [203, 213], [214, 216], [217, 225], [225, 226]]}
{"doc_key": "ai-dev-229", "ner": [[10, 11, "field"], [14, 15, "field"], [17, 18, "task"], [20, 21, "field"], [24, 25, "field"], [27, 28, "field"], [33, 34, "field"], [36, 37, "task"], [39, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[10, 11, 14, 15, "named", "", false, false], [10, 11, 20, 21, "named", "", false, false], [10, 11, 27, 28, "named", "", false, false], [17, 18, 14, 15, "part-of", "task_part_of_field", false, false], [24, 25, 20, 21, "part-of", "", false, false], [33, 34, 27, 28, "part-of", "", false, false], [36, 37, 33, 34, "part-of", "", false, false], [39, 39, 33, 34, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["(", "2005", ")", "we", "can", "distinguish", "three", "different", "perspectives", "of", "text", "mining", ",", "namely", "text", "mining", "as", "information", "mining", ",", "text", "mining", "as", "text", "data", "mining", "and", "text", "mining", "as", "a", "process", "of", "data", "mining", "(", "Knowledge", "Discovery", "in", "Databases", ")", ".", "Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005) we can distinguish three different perspectives of text mining, namely text mining as information mining, text mining as text data mining and text mining as a process of data mining (Knowledge Discovery in Databases).Hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 9], [10, 13], [14, 25], [26, 31], [32, 41], [42, 54], [55, 57], [58, 62], [63, 69], [69, 70], [71, 77], [78, 82], [83, 89], [90, 92], [93, 104], [105, 111], [111, 112], [113, 117], [118, 124], [125, 127], [128, 132], [133, 137], [138, 144], [145, 148], [149, 153], [154, 160], [161, 163], [164, 165], [166, 173], [174, 176], [177, 181], [182, 188], [189, 190], [190, 199], [200, 209], [210, 212], [213, 222], [222, 223], [223, 224], [224, 229], [229, 230], [231, 233], [233, 234], [235, 245], [245, 246], [247, 249], [250, 253], [254, 258], [258, 259], [260, 262], [263, 264], [264, 268], [268, 269], [269, 270]]}
{"doc_key": "ai-dev-230", "ner": [[1, 2, "product"], [16, 21, "location"], [23, 23, "location"], [25, 25, "location"], [35, 36, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 16, 21, "related-to", "developed_for", false, false], [16, 21, 23, 23, "physical", "", false, false], [23, 23, 25, 25, "physical", "", false, false], [35, 36, 1, 2, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Rancho", "arm", "was", "developed", "as", "a", "robotic", "arm", "to", "help", "the", "disabled", "patients", "at", "the", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Center", "in", "Downey", ",", "California", ".", "This", "computer", "-", "controlled", "arm", "was", "purchased", "by", "Stanford", "University", "in", "1963", "."], "sentence-detokenized": "The Rancho arm was developed as a robotic arm to help the disabled patients at the Rancho Los Amigos National Rehabilitation Center in Downey, California. This computer-controlled arm was purchased by Stanford University in 1963.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 18], [19, 28], [29, 31], [32, 33], [34, 41], [42, 45], [46, 48], [49, 53], [54, 57], [58, 66], [67, 75], [76, 78], [79, 82], [83, 89], [90, 93], [94, 100], [101, 109], [110, 124], [125, 131], [132, 134], [135, 141], [141, 142], [143, 153], [153, 154], [155, 159], [160, 168], [168, 169], [169, 179], [180, 183], [184, 187], [188, 197], [198, 200], [201, 209], [210, 220], [221, 223], [224, 228], [228, 229]]}
{"doc_key": "ai-dev-231", "ner": [[1, 1, "university"], [3, 3, "researcher"], [10, 13, "organisation"], [21, 23, "organisation"], [27, 28, "researcher"], [30, 32, "researcher"], [45, 45, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 1, 1, "physical", "", false, false], [3, 3, 1, 1, "role", "", false, false], [3, 3, 10, 13, "role", "founder", false, false], [3, 3, 21, 23, "role", "founder", false, false], [21, 23, 45, 45, "physical", "", false, false], [27, 28, 21, 23, "role", "founder", false, false], [30, 32, 21, 23, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["At", "UCSD", ",", "Norman", "was", "one", "of", "the", "founders", "of", "the", "Cognitive", "Science", "Institute", "and", "one", "of", "the", "organizers", "of", "the", "Cognitive", "Science", "Society", "(", "along", "with", "Roger", "Schank", ",", "Allan", "M.", "Collins", "and", "others", ")", ",", "which", "held", "it", "s", "first", "meeting", "on", "the", "UCSD", "campus", "in", "1979", "."], "sentence-detokenized": "At UCSD, Norman was one of the founders of the Cognitive Science Institute and one of the organizers of the Cognitive Science Society (along with Roger Schank, Allan M. Collins and others), which held its first meeting on the UCSD campus in 1979.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 23], [24, 26], [27, 30], [31, 39], [40, 42], [43, 46], [47, 56], [57, 64], [65, 74], [75, 78], [79, 82], [83, 85], [86, 89], [90, 100], [101, 103], [104, 107], [108, 117], [118, 125], [126, 133], [134, 135], [135, 140], [141, 145], [146, 151], [152, 158], [158, 159], [160, 165], [166, 168], [169, 176], [177, 180], [181, 187], [187, 188], [188, 189], [190, 195], [196, 200], [201, 203], [203, 204], [205, 210], [211, 218], [219, 221], [222, 225], [226, 230], [231, 237], [238, 240], [241, 245], [245, 246]]}
{"doc_key": "ai-dev-232", "ner": [[7, 8, "product"], [10, 11, "product"], [13, 14, "product"], [16, 18, "product"], [20, 20, "product"], [22, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 20, 16, 18, "type-of", "", false, false], [22, 27, 16, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "commonly", "used", "robot", "configurations", "are", "articulated", "robots", ",", "SCARA", "robots", ",", "delta", "robots", "and", "Cartesian", "coordinate", "robots", "(", "gantry", "or", "x", "-", "y", "-", "z", "robots", ")", "."], "sentence-detokenized": "The most commonly used robot configurations are articulated robots, SCARA robots, delta robots and Cartesian coordinate robots (gantry or x-y-z robots).", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 28], [29, 43], [44, 47], [48, 59], [60, 66], [66, 67], [68, 73], [74, 80], [80, 81], [82, 87], [88, 94], [95, 98], [99, 108], [109, 119], [120, 126], [127, 128], [128, 134], [135, 137], [138, 139], [139, 140], [140, 141], [141, 142], [142, 143], [144, 150], [150, 151], [151, 152]]}
{"doc_key": "ai-dev-233", "ner": [[9, 9, "programlang"], [10, 11, "misc"], [16, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 9, 9, "part-of", "", false, false], [16, 16, 10, 11, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Alternatively", ",", "it", "can", "be", "used", "directly", "with", "the", "Perl", "Module", "TM", "(", "which", "also", "supports", "LTM", ")", "."], "sentence-detokenized": "Alternatively, it can be used directly with the Perl Module TM (which also supports LTM).", "token2charspan": [[0, 13], [13, 14], [15, 17], [18, 21], [22, 24], [25, 29], [30, 38], [39, 43], [44, 47], [48, 52], [53, 59], [60, 62], [63, 64], [64, 69], [70, 74], [75, 83], [84, 87], [87, 88], [88, 89]]}
{"doc_key": "ai-dev-234", "ner": [[12, 13, "country"], [8, 11, "organisation"], [20, 20, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 12, 13, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "competition", "was", "won", "by", "a", "team", "from", "Newton", "Labs", "in", "the", "United", "States", "and", "the", "competition", "was", "aired", "on", "CNN", "."], "sentence-detokenized": "The competition was won by a team from Newton Labs in the United States and the competition was aired on CNN.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 26], [27, 28], [29, 33], [34, 38], [39, 45], [46, 50], [51, 53], [54, 57], [58, 64], [65, 71], [72, 75], [76, 79], [80, 91], [92, 95], [96, 101], [102, 104], [105, 108], [108, 109]]}
{"doc_key": "ai-dev-235", "ner": [[3, 7, "misc"], [11, 12, "person"], [15, 16, "person"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 3, 7, "role", "directs", false, false], [15, 16, 3, 7, "role", "acts_in", false, false], [18, 19, 3, 7, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "short", "film", "The", "Butler", "'s", "in", "Love", ",", "directed", "by", "David", "Arquette", "and", "starring", "Elizabeth", "Berkley", "and", "Thomas", "Jane", ",", "was", "released", "on", "June", "23", ",", "2008", "."], "sentence-detokenized": "The short film The Butler's in Love, directed by David Arquette and starring Elizabeth Berkley and Thomas Jane, was released on June 23, 2008.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 18], [19, 25], [25, 27], [28, 30], [31, 35], [35, 36], [37, 45], [46, 48], [49, 54], [55, 63], [64, 67], [68, 76], [77, 86], [87, 94], [95, 98], [99, 105], [106, 110], [110, 111], [112, 115], [116, 124], [125, 127], [128, 132], [133, 135], [135, 136], [137, 141], [141, 142]]}
{"doc_key": "ai-dev-236", "ner": [[3, 4, "product"], [11, 13, "field"], [21, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 21, 21, "general-affiliation", "", false, false], [11, 13, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "Word", "Net", "is", "a", "resource", "that", "includes", "a", "taxonomy", ",", "the", "elements", "of", "which", "are", "the", "meanings", "of", "English", "words", "."], "sentence-detokenized": "For example, WordNet is a resource that includes a taxonomy, the elements of which are the meanings of English words.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [17, 20], [21, 23], [24, 25], [26, 34], [35, 39], [40, 48], [49, 50], [51, 59], [59, 60], [61, 64], [65, 73], [74, 76], [77, 82], [83, 86], [87, 90], [91, 99], [100, 102], [103, 110], [111, 116], [116, 117]]}
{"doc_key": "ai-dev-237", "ner": [[1, 3, "product"], [7, 7, "product"], [9, 9, "product"], [16, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 1, 3, "type-of", "", false, false], [7, 7, 16, 16, "related-to", "ability_to", false, false], [9, 9, 1, 3, "type-of", "", false, false], [9, 9, 16, 16, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Existing", "humanoid", "robot", "systems", ",", "such", "as", "ASIMO", "and", "QRIO", ",", "use", "multiple", "motors", "to", "achieve", "locomotion", "."], "sentence-detokenized": "Existing humanoid robot systems, such as ASIMO and QRIO, use multiple motors to achieve locomotion.", "token2charspan": [[0, 8], [9, 17], [18, 23], [24, 31], [31, 32], [33, 37], [38, 40], [41, 46], [47, 50], [51, 55], [55, 56], [57, 60], [61, 69], [70, 76], [77, 79], [80, 87], [88, 98], [98, 99]]}
{"doc_key": "ai-dev-238", "ner": [[0, 1, "metrics"], [8, 9, "metrics"], [11, 11, "metrics"], [13, 17, "misc"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 9, 0, 1, "part-of", "", false, false], [11, 11, 0, 1, "part-of", "", false, false], [13, 17, 0, 1, "part-of", "", false, false], [19, 19, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "is", "designed", "with", "the", "factors", "of", "enhanced", "length", "penalty", ",", "precision", ",", "n-", "gram", "word", "order", "penalty", "and", "recall", "."], "sentence-detokenized": "LEPOR is designed with the factors of enhanced length penalty, precision, n-gram word order penalty and recall.", "token2charspan": [[0, 5], [6, 8], [9, 17], [18, 22], [23, 26], [27, 34], [35, 37], [38, 46], [47, 53], [54, 61], [61, 62], [63, 72], [72, 73], [74, 76], [76, 80], [81, 85], [86, 91], [92, 99], [100, 103], [104, 110], [110, 111]]}
{"doc_key": "ai-dev-239", "ner": [[5, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "based", "on", "the", "bilingual", "student", "assessment", "metric", ",", "but", "with", "some", "changes", "."], "sentence-detokenized": "It is based on the bilingual student assessment metric, but with some changes.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 14], [15, 18], [19, 28], [29, 36], [37, 47], [48, 54], [54, 55], [56, 59], [60, 64], [65, 69], [70, 77], [77, 78]]}
{"doc_key": "ai-dev-240", "ner": [[8, 8, "product"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "of", "an", "application", "in", "MATLAB", "/", "Octave", ":"], "sentence-detokenized": "This is an example of an application in MATLAB / Octave:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 24], [25, 36], [37, 39], [40, 46], [47, 48], [49, 55], [55, 56]]}
{"doc_key": "ai-dev-241", "ner": [[13, 13, "programlang"], [15, 15, "programlang"], [17, 17, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "designed", "to", "be", "used", "through", "many", "computer", "languages", ",", "such", "as", "Python", ",", "Ruby", "and", "Scheme", "."], "sentence-detokenized": "It is designed to be used through many computer languages, such as Python, Ruby and Scheme.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 20], [21, 25], [26, 33], [34, 38], [39, 47], [48, 57], [57, 58], [59, 63], [64, 66], [67, 73], [73, 74], [75, 79], [80, 83], [84, 90], [90, 91]]}
{"doc_key": "ai-dev-242", "ner": [[0, 0, "researcher"], [6, 6, "organisation"], [12, 12, "conference"], [17, 18, "academicjournal"], [23, 25, "organisation"], [31, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 6, "role", "", false, false], [0, 0, 12, 12, "role", "", false, false], [0, 0, 17, 18, "role", "", false, false], [0, 0, 23, 25, "role", "", false, false], [0, 0, 31, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "has", "served", "as", "secretary", "of", "AISB", ",", "president", "and", "trustee", "of", "IJCAI", ",", "associate", "editor", "of", "Artificial", "Intelligence", ",", "governor", "of", "the", "Cognitive", "Science", "Society", ",", "and", "president", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes has served as secretary of AISB, president and trustee of IJCAI, associate editor of Artificial Intelligence, governor of the Cognitive Science Society, and president of the American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 32], [33, 37], [37, 38], [39, 48], [49, 52], [53, 60], [61, 63], [64, 69], [69, 70], [71, 80], [81, 87], [88, 90], [91, 101], [102, 114], [114, 115], [116, 124], [125, 127], [128, 131], [132, 141], [142, 149], [150, 157], [157, 158], [159, 162], [163, 172], [173, 175], [176, 179], [180, 188], [189, 200], [201, 204], [205, 215], [216, 228], [228, 229]]}
{"doc_key": "ai-dev-243", "ner": [[4, 14, "misc"], [16, 18, "misc"], [23, 24, "person"], [29, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 24, 4, 14, "role", "directed_by", false, false], [23, 24, 16, 18, "role", "directed_by", false, false], [23, 24, 29, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "of", "them", ",", "Now", "is", "the", "Time", "(", "to", "Put", "On", "Your", "Glasses", ")", "and", "Around", "is", "Around", ",", "were", "directed", "by", "Norman", "McLaren", "in", "1951", "for", "the", "National", "Film", "Board", "of", "Canada", "."], "sentence-detokenized": "Two of them, Now is the Time (to Put On Your Glasses) and Around is Around, were directed by Norman McLaren in 1951 for the National Film Board of Canada.", "token2charspan": [[0, 3], [4, 6], [7, 11], [11, 12], [13, 16], [17, 19], [20, 23], [24, 28], [29, 30], [30, 32], [33, 36], [37, 39], [40, 44], [45, 52], [52, 53], [54, 57], [58, 64], [65, 67], [68, 74], [74, 75], [76, 80], [81, 89], [90, 92], [93, 99], [100, 107], [108, 110], [111, 115], [116, 119], [120, 123], [124, 132], [133, 137], [138, 143], [144, 146], [147, 153], [153, 154]]}
{"doc_key": "ai-dev-244", "ner": [[1, 4, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "recommendation", "system", "aims", "to", "predict", "a", "target", "user", "'s", "preference", "for", "an", "item", "."], "sentence-detokenized": "A recommendation system aims to predict a target user's preference for an item.", "token2charspan": [[0, 1], [2, 16], [17, 23], [24, 28], [29, 31], [32, 39], [40, 41], [42, 48], [49, 53], [53, 55], [56, 66], [67, 70], [71, 73], [74, 78], [78, 79]]}
{"doc_key": "ai-dev-245", "ner": [[0, 0, "algorithm"], [5, 5, "field"], [7, 7, "field"], [9, 10, "field"], [12, 14, "field"], [16, 19, "field"], [18, 18, "field"], [21, 21, "field"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 5, 5, "part-of", "", true, false], [0, 0, 7, 7, "part-of", "", true, false], [0, 0, 9, 10, "part-of", "", true, false], [0, 0, 12, 14, "part-of", "", true, false], [0, 0, 16, 19, "part-of", "", true, false], [0, 0, 18, 18, "part-of", "", true, false], [0, 0, 21, 21, "part-of", "", true, false], [0, 0, 23, 24, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Convolution", "has", "applications", "that", "include", "probability", ",", "statistics", ",", "computer", "vision", ",", "natural", "language", "processing", ",", "image", "and", "signal", "processing", ",", "engineering", "and", "differential", "equations", "."], "sentence-detokenized": "Convolution has applications that include probability, statistics, computer vision, natural language processing, image and signal processing, engineering and differential equations.", "token2charspan": [[0, 11], [12, 15], [16, 28], [29, 33], [34, 41], [42, 53], [53, 54], [55, 65], [65, 66], [67, 75], [76, 82], [82, 83], [84, 91], [92, 100], [101, 111], [111, 112], [113, 118], [119, 122], [123, 129], [130, 140], [140, 141], [142, 153], [154, 157], [158, 170], [171, 180], [180, 181]]}
{"doc_key": "ai-dev-246", "ner": [[0, 0, "field"], [3, 5, "task"], [7, 8, "task"], [10, 14, "task"], [11, 11, "task"], [12, 12, "task"], [15, 19, "task"], [21, 22, "task"], [24, 25, "task"], [27, 27, "task"], [30, 31, "task"], [33, 33, "field"], [35, 35, "field"], [37, 39, "field"], [41, 41, "field"], [43, 43, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[0, 0, 3, 5, "part-of", "", true, false], [0, 0, 7, 8, "part-of", "", true, false], [0, 0, 10, 14, "part-of", "", true, false], [0, 0, 11, 11, "part-of", "", true, false], [0, 0, 12, 12, "part-of", "", true, false], [0, 0, 15, 19, "part-of", "", true, false], [0, 0, 21, 22, "part-of", "", true, false], [0, 0, 24, 25, "part-of", "", true, false], [0, 0, 27, 27, "part-of", "", true, false], [0, 0, 30, 31, "part-of", "", true, false], [0, 0, 33, 33, "part-of", "", true, false], [0, 0, 35, 35, "part-of", "", true, false], [0, 0, 37, 39, "part-of", "", true, false], [0, 0, 41, 41, "part-of", "", true, false], [0, 0, 43, 43, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["DSP", "applications", "include", "audio", "signal", "processing", ",", "audio", "compression", ",", "digital", "image", "processing", ",", "digital", "video", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communications", ",", "digital", "synthesizers", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", "and", "biomedicine", "."], "sentence-detokenized": "DSP applications include audio signal processing, audio compression, digital image processing, digital video processing, video compression, speech processing, speech recognition, digital communications, digital synthesizers, radar, sonar, financial signal processing, seismology and biomedicine.", "token2charspan": [[0, 3], [4, 16], [17, 24], [25, 30], [31, 37], [38, 48], [48, 49], [50, 55], [56, 67], [67, 68], [69, 76], [77, 82], [83, 93], [93, 94], [95, 102], [103, 108], [109, 119], [119, 120], [121, 126], [127, 138], [138, 139], [140, 146], [147, 157], [157, 158], [159, 165], [166, 177], [177, 178], [179, 186], [187, 201], [201, 202], [203, 210], [211, 223], [223, 224], [225, 230], [230, 231], [232, 237], [237, 238], [239, 248], [249, 255], [256, 266], [266, 267], [268, 278], [279, 282], [283, 294], [294, 295]]}
{"doc_key": "ai-dev-247", "ner": [[13, 14, "misc"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "February", "20", ",", "1912", "-", "August", "11", ",", "2011", ")", "was", "an", "American", "inventor", "best", "known", "for", "creating", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "(February 20, 1912 - August 11, 2011) was an American inventor best known for creating Unimate, the first industrial robot.", "token2charspan": [[0, 1], [1, 9], [10, 12], [12, 13], [14, 18], [19, 20], [21, 27], [28, 30], [30, 31], [32, 36], [36, 37], [38, 41], [42, 44], [45, 53], [54, 62], [63, 67], [68, 73], [74, 77], [78, 86], [87, 94], [94, 95], [96, 99], [100, 105], [106, 116], [117, 122], [122, 123]]}
{"doc_key": "ai-dev-248", "ner": [[2, 4, "researcher"], [6, 8, "researcher"], [10, 10, "researcher"], [22, 23, "algorithm"], [26, 28, "algorithm"], [36, 37, "task"], [34, 35, "algorithm"], [42, 43, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 22, 23, "related-to", "writes_about", true, false], [6, 8, 22, 23, "related-to", "writes_about", true, false], [10, 10, 22, 23, "related-to", "writes_about", true, false], [22, 23, 26, 28, "related-to", "", true, false], [36, 37, 34, 35, "related-to", "", true, false], [42, 43, 34, 35, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Along", "with", "David", "E.", "Rumelhart", "and", "Ronald", "J.", "Williams", ",", "Hinton", "co-authored", "a", "highly", "cited", "paper", "published", "in", "1986", "that", "popularized", "the", "backpropagation", "algorithm", "for", "training", "multi-layer", "neural", "networks", ",", "The", "dramatic", "milestone", "of", "Alex", "Net", "image", "recognition", "designed", "by", "his", "student", "Alex", "Krizhevsky", "{{", "cite", "web"], "sentence-detokenized": "Along with David E. Rumelhart and Ronald J. Williams, Hinton co-authored a highly cited paper published in 1986 that popularized the backpropagation algorithm for training multi-layer neural networks, The dramatic milestone of AlexNet image recognition designed by his student Alex Krizhevsky {{cite web", "token2charspan": [[0, 5], [6, 10], [11, 16], [17, 19], [20, 29], [30, 33], [34, 40], [41, 43], [44, 52], [52, 53], [54, 60], [61, 72], [73, 74], [75, 81], [82, 87], [88, 93], [94, 103], [104, 106], [107, 111], [112, 116], [117, 128], [129, 132], [133, 148], [149, 158], [159, 162], [163, 171], [172, 183], [184, 190], [191, 199], [199, 200], [201, 204], [205, 213], [214, 223], [224, 226], [227, 231], [231, 234], [235, 240], [241, 252], [253, 261], [262, 264], [265, 268], [269, 276], [277, 281], [282, 292], [293, 295], [295, 299], [300, 303]]}
{"doc_key": "ai-dev-249", "ner": [[10, 12, "metrics"], [9, 18, "metrics"], [21, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "predicted", "value", "is", "continuously", "distributed", ",", "the", "root", "mean", "square", "error", ",", "the", "root", "mean", "square", "error", "or", "the", "median", "absolute", "deviation", "can", "be", "used", "to", "summarise", "the", "errors", "."], "sentence-detokenized": "When the predicted value is continuously distributed, the root mean square error, the root mean square error or the median absolute deviation can be used to summarise the errors.", "token2charspan": [[0, 4], [5, 8], [9, 18], [19, 24], [25, 27], [28, 40], [41, 52], [52, 53], [54, 57], [58, 62], [63, 67], [68, 74], [75, 80], [80, 81], [82, 85], [86, 90], [91, 95], [96, 102], [103, 108], [109, 111], [112, 115], [116, 122], [123, 131], [132, 141], [142, 145], [146, 148], [149, 153], [154, 156], [157, 166], [167, 170], [171, 177], [177, 178]]}
{"doc_key": "ai-dev-250", "ner": [[0, 1, "algorithm"], [10, 11, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 10, 11, "part-of", "", true, false], [0, 1, 14, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Conceptual", "clustering", "was", "developed", "mainly", "during", "the", "1980s", "as", "a", "machine", "learning", "paradigm", "for", "unsupervised", "learning", "."], "sentence-detokenized": "Conceptual clustering was developed mainly during the 1980s as a machine learning paradigm for unsupervised learning.", "token2charspan": [[0, 10], [11, 21], [22, 25], [26, 35], [36, 42], [43, 49], [50, 53], [54, 59], [60, 62], [63, 64], [65, 72], [73, 81], [82, 90], [91, 94], [95, 107], [108, 116], [116, 117]]}
{"doc_key": "ai-dev-251", "ner": [[10, 11, "product"], [31, 33, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "named", "entities", "can", "not", "be", "identified", "by", "the", "machine", "translator", ",", "they", "may", "be", "mistranslated", "as", "common", "nouns", ",", "which", "will", "probably", "not", "affect", "the", "translation", "score", "of", "the", "bilingual", "evaluation", "substitute", ",", "but", "will", "change", "the", "human", "readability", "of", "the", "text", "."], "sentence-detokenized": "If the named entities cannot be identified by the machine translator, they may be mistranslated as common nouns, which will probably not affect the translation score of the bilingual evaluation substitute, but will change the human readability of the text.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 21], [22, 25], [25, 28], [29, 31], [32, 42], [43, 45], [46, 49], [50, 57], [58, 68], [68, 69], [70, 74], [75, 78], [79, 81], [82, 95], [96, 98], [99, 105], [106, 111], [111, 112], [113, 118], [119, 123], [124, 132], [133, 136], [137, 143], [144, 147], [148, 159], [160, 165], [166, 168], [169, 172], [173, 182], [183, 193], [194, 204], [204, 205], [206, 209], [210, 214], [215, 221], [222, 225], [226, 231], [232, 243], [244, 246], [247, 250], [251, 255], [255, 256]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 10, "misc"], [12, 18, "conference"], [20, 22, "location"], [24, 24, "country"], [38, 39, "researcher"], [45, 45, "researcher"], [49, 50, "university"], [54, 55, "researcher"], [57, 58, "researcher"], [60, 61, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 10, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 22, "physical", "", false, false], [20, 22, 24, 24, "physical", "", false, false], [45, 45, 49, 50, "physical", "", false, false], [45, 45, 49, 50, "role", "", false, false], [54, 55, 49, 50, "physical", "", false, false], [54, 55, 49, 50, "role", "", false, false], [57, 58, 49, 50, "physical", "", false, false], [57, 58, 49, 50, "role", "", false, false], [60, 61, 49, 50, "physical", "", false, false], [60, 61, 49, 50, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng", "-", "S\u00e4by", ",", "Sweden", ",", "pages", "1-", "3", "This", "model", ",", "partly", "influenced", "by", "the", "work", "of", "Sydney", "Lamb", ",", "was", "used", "extensively", "by", "Schank", "'s", "students", "at", "Yale", "University", ",", "such", "as", "Robert", "Wilensky", ",", "Wendy", "Lehnert", "and", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, pages 1-3 This model, partly influenced by the work of Sydney Lamb, was used extensively by Schank's students at Yale University, such as Robert Wilensky, Wendy Lehnert and Janet Kolodner.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 130], [130, 131], [131, 135], [135, 136], [137, 143], [143, 144], [145, 150], [151, 153], [153, 154], [155, 159], [160, 165], [165, 166], [167, 173], [174, 184], [185, 187], [188, 191], [192, 196], [197, 199], [200, 206], [207, 211], [211, 212], [213, 216], [217, 221], [222, 233], [234, 236], [237, 243], [243, 245], [246, 254], [255, 257], [258, 262], [263, 273], [273, 274], [275, 279], [280, 282], [283, 289], [290, 298], [298, 299], [300, 305], [306, 313], [314, 317], [318, 323], [324, 332], [332, 333]]}
{"doc_key": "ai-dev-253", "ner": [[1, 6, "algorithm"], [13, 15, "algorithm"], [16, 16, "metrics"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Improved", "Maximum", "Likelihood", "Method", "(", "IMLM", ")", "is", "a", "combination", "of", "two", "MLM", "(", "maximum", "likelihood", ")", "estimators", "."], "sentence-detokenized": "The Improved Maximum Likelihood Method (IMLM) is a combination of two MLM (maximum likelihood) estimators.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 38], [39, 40], [40, 44], [44, 45], [46, 48], [49, 50], [51, 62], [63, 65], [66, 69], [70, 73], [74, 75], [75, 82], [83, 93], [93, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-254", "ner": [[19, 20, "metrics"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[23, 24, 19, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "methods", "can", "also", "analyze", "the", "output", "of", "a", "program", "and", "its", "utility", "and", ",", "therefore", ",", "may", "include", "confusion", "table", "(", "or", "confusion", "table", ")", "analysis", "."], "sentence-detokenized": "These methods can also analyze the output of a program and its utility and, therefore, may include confusion table (or confusion table) analysis.", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 22], [23, 30], [31, 34], [35, 41], [42, 44], [45, 46], [47, 54], [55, 58], [59, 62], [63, 70], [71, 74], [74, 75], [76, 85], [85, 86], [87, 90], [91, 98], [99, 108], [109, 114], [115, 116], [116, 118], [119, 128], [129, 134], [134, 135], [136, 144], [144, 145]]}
{"doc_key": "ai-dev-255", "ner": [[0, 0, "product"], [5, 6, "researcher"], [8, 9, "researcher"], [11, 13, "researcher"], [18, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 6, "origin", "", false, false], [0, 0, 8, 9, "origin", "", false, false], [0, 0, 11, 13, "origin", "", false, false], [0, 0, 18, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "was", "first", "published", "by", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", "and", "Luc", "Van", "Gool", "and", "presented", "at", "the", "European", "Computer", "Vision", "Conference", "in", "2006", "."], "sentence-detokenized": "SURF was first published by Herbert Bay, Tinne Tuytelaars and Luc Van Gool and presented at the European Computer Vision Conference in 2006.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 39], [39, 40], [41, 46], [47, 57], [58, 61], [62, 65], [66, 69], [70, 74], [75, 78], [79, 88], [89, 91], [92, 95], [96, 104], [105, 113], [114, 120], [121, 131], [132, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-dev-256", "ner": [[0, 0, "task"], [7, 8, "field"], [10, 11, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 8, "part-of", "", false, false], [0, 0, 10, 11, "part-of", "", false, false], [0, 0, 13, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "is", "a", "field", "of", "research", "in", "pattern", "recognition", ",", "artificial", "intelligence", "and", "computer", "vision", "."], "sentence-detokenized": "OCR is a field of research in pattern recognition, artificial intelligence and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 14], [15, 17], [18, 26], [27, 29], [30, 37], [38, 49], [49, 50], [51, 61], [62, 74], [75, 78], [79, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-dev-257", "ner": [[5, 7, "metrics"], [10, 12, "algorithm"], [14, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 10, 12, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Continuing", "the", "example", "using", "the", "maximum", "likelihood", "estimator", ",", "the", "probability", "density", "function", "(", "pdf", ")", "of", "the", "noise", "for", "a", "mathwn", "/", "math", "sample", "is"], "sentence-detokenized": "Continuing the example using the maximum likelihood estimator, the probability density function (pdf) of the noise for a mathwn/math sample is", "token2charspan": [[0, 10], [11, 14], [15, 22], [23, 28], [29, 32], [33, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 78], [79, 86], [87, 95], [96, 97], [97, 100], [100, 101], [102, 104], [105, 108], [109, 114], [115, 118], [119, 120], [121, 127], [127, 128], [128, 132], [133, 139], [140, 142]]}
{"doc_key": "ai-dev-258", "ner": [[3, 4, "field"], [6, 7, "task"], [9, 10, "task"], [12, 13, "task"], [15, 16, "task"], [18, 20, "task"], [22, 22, "task"], [24, 24, "task"], [26, 27, "task"], [29, 30, "task"], [32, 34, "task"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[6, 7, 3, 4, "part-of", "", false, false], [9, 10, 3, 4, "part-of", "", false, false], [12, 13, 3, 4, "part-of", "", false, false], [15, 16, 3, 4, "part-of", "", false, false], [18, 20, 3, 4, "part-of", "", false, false], [22, 22, 3, 4, "part-of", "", false, false], [24, 24, 3, 4, "part-of", "", false, false], [26, 27, 3, 4, "part-of", "", false, false], [29, 30, 3, 4, "part-of", "", false, false], [32, 34, 3, 4, "part-of", "", false, false], [36, 37, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["The", "subfields", "of", "computer", "vision", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "3D", "pose", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "adjustment", ",", "3D", "scene", "modelling", "and", "image", "restoration", "."], "sentence-detokenized": "The subfields of computer vision include scene reconstruction, event detection, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual adjustment, 3D scene modelling and image restoration.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 25], [26, 32], [33, 40], [41, 46], [47, 61], [61, 62], [63, 68], [69, 78], [78, 79], [80, 85], [86, 94], [94, 95], [96, 102], [103, 114], [114, 115], [116, 118], [119, 123], [124, 134], [134, 135], [136, 144], [144, 145], [146, 154], [154, 155], [156, 162], [163, 173], [173, 174], [175, 181], [182, 192], [192, 193], [194, 196], [197, 202], [203, 212], [213, 216], [217, 222], [223, 234], [234, 235]]}
{"doc_key": "ai-dev-259", "ner": [[5, 9, "conference"], [11, 11, "researcher"], [15, 16, "misc"], [19, 20, "conference"], [23, 23, "researcher"], [25, 25, "researcher"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 9, 19, 20, "named", "", false, false], [11, 11, 15, 16, "win-defeat", "", false, false], [11, 11, 27, 28, "related-to", "writes_about", true, false], [15, 16, 5, 9, "temporal", "", false, false], [23, 23, 15, 16, "win-defeat", "", false, true], [23, 23, 27, 28, "related-to", "writes_about", true, false], [25, 25, 15, 16, "win-defeat", "", false, true], [25, 25, 27, 28, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["In", "2013", ",", "at", "the", "International", "Conference", "on", "Computer", "Vision", ",", "Terzopoulos", "was", "awarded", "the", "Helmholtz", "Prize", "for", "his", "1987", "ICCV", "paper", "with", "Kass", "and", "Witkin", "on", "active", "contour", "models", "."], "sentence-detokenized": "In 2013, at the International Conference on Computer Vision, Terzopoulos was awarded the Helmholtz Prize for his 1987 ICCV paper with Kass and Witkin on active contour models.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 40], [41, 43], [44, 52], [53, 59], [59, 60], [61, 72], [73, 76], [77, 84], [85, 88], [89, 98], [99, 104], [105, 108], [109, 112], [113, 117], [118, 122], [123, 128], [129, 133], [134, 138], [139, 142], [143, 149], [150, 152], [153, 159], [160, 167], [168, 174], [174, 175]]}
{"doc_key": "ai-dev-260", "ner": [[17, 18, "task"], [20, 22, "algorithm"], [24, 25, "algorithm"], [27, 29, "algorithm"], [31, 32, "algorithm"], [34, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 18, 20, 22, "usage", "", true, false], [17, 18, 24, 25, "usage", "", true, false], [17, 18, 27, 29, "usage", "", true, false], [17, 18, 31, 32, "usage", "", true, false], [17, 18, 34, 34, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["If", "the", "normalization", "function", "There", "are", "many", "algorithms", "for", "solving", "such", "problems", ";", "the", "popular", "ones", "for", "linear", "classification", "include", "Stochastic", "gradient", "descent", ")", "gradient", "descent", ",", "L", "-", "BFGS", ",", "coordinate", "descent", "and", "Newton", "."], "sentence-detokenized": "If the normalization function There are many algorithms for solving such problems; the popular ones for linear classification include Stochastic gradient descent) gradient descent, L-BFGS, coordinate descent and Newton.", "token2charspan": [[0, 2], [3, 6], [7, 20], [21, 29], [30, 35], [36, 39], [40, 44], [45, 55], [56, 59], [60, 67], [68, 72], [73, 81], [81, 82], [83, 86], [87, 94], [95, 99], [100, 103], [104, 110], [111, 125], [126, 133], [134, 144], [145, 153], [154, 161], [161, 162], [163, 171], [172, 179], [179, 180], [181, 182], [182, 183], [183, 187], [187, 188], [189, 199], [200, 207], [208, 211], [212, 218], [218, 219]]}
{"doc_key": "ai-dev-261", "ner": [[0, 6, "algorithm"], [12, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Long", "short", "-", "term", "memory", "(", "LSTM", ")", "networks", "were", "invented", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "and", "set", "records", "for", "accuracy", "in", "many", "application", "areas", "."], "sentence-detokenized": "Long short-term memory (LSTM) networks were invented by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997 and set records for accuracy in many application areas.", "token2charspan": [[0, 4], [5, 10], [10, 11], [11, 15], [16, 22], [23, 24], [24, 28], [28, 29], [30, 38], [39, 43], [44, 52], [53, 55], [56, 60], [61, 71], [72, 75], [76, 82], [83, 94], [95, 97], [98, 102], [103, 106], [107, 110], [111, 118], [119, 122], [123, 131], [132, 134], [135, 139], [140, 151], [152, 157], [157, 158]]}
{"doc_key": "ai-dev-262", "ner": [[0, 0, "product"], [4, 6, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["TN", "was", "developed", "at", "Massachusetts", "General", "Hospital", "and", "tested", "in", "multiple", "scenarios", ",", "including", "extraction", "of", "smoking", "status", ",", "family", "history", "of", "coronary", "artery", "disease", ",", "identification", "of", "patients", "with", "sleep", "disorders", ","], "sentence-detokenized": "TN was developed at Massachusetts General Hospital and tested in multiple scenarios, including extraction of smoking status, family history of coronary artery disease, identification of patients with sleep disorders,", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 33], [34, 41], [42, 50], [51, 54], [55, 61], [62, 64], [65, 73], [74, 83], [83, 84], [85, 94], [95, 105], [106, 108], [109, 116], [117, 123], [123, 124], [125, 131], [132, 139], [140, 142], [143, 151], [152, 158], [159, 166], [166, 167], [168, 182], [183, 185], [186, 194], [195, 199], [200, 205], [206, 215], [215, 216]]}
{"doc_key": "ai-dev-263", "ner": [[3, 3, "researcher"], [8, 12, "product"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 12, "role", "sells", false, false], [8, 12, 17, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "shipped", "in", "1961", "to", "General", "Motors", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was shipped in 1961 to General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 73], [74, 76], [77, 81], [82, 84], [85, 92], [93, 99], [99, 100]]}
{"doc_key": "ai-dev-264", "ner": [[0, 5, "conference"], [12, 13, "location"], [15, 15, "location"], [17, 17, "country"], [30, 31, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 12, 13, "physical", "", false, false], [12, 13, 15, 15, "physical", "", false, false], [15, 15, 17, 17, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Campus", "Party", "Europe", "took", "place", "on", "14", "-", "18", "April", "2010", "at", "Caja", "M\u00e1gica", "in", "Madrid", ",", "Spain", "with", "800", "participants", "from", "each", "of", "the", "27", "Member", "States", "of", "the", "European", "Union", "."], "sentence-detokenized": "Campus Party Europe took place on 14-18 April 2010 at Caja M\u00e1gica in Madrid, Spain with 800 participants from each of the 27 Member States of the European Union.", "token2charspan": [[0, 6], [7, 12], [13, 19], [20, 24], [25, 30], [31, 33], [34, 36], [36, 37], [37, 39], [40, 45], [46, 50], [51, 53], [54, 58], [59, 65], [66, 68], [69, 75], [75, 76], [77, 82], [83, 87], [88, 91], [92, 104], [105, 109], [110, 114], [115, 117], [118, 121], [122, 124], [125, 131], [132, 138], [139, 141], [142, 145], [146, 154], [155, 160], [160, 161]]}
{"doc_key": "ai-dev-265", "ner": [[7, 7, "organisation"], [9, 11, "organisation"], [14, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 18, 7, 7, "origin", "", false, false], [14, 18, 9, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2016", ",", "a", "partnership", "between", "DeepMind", "and", "Moorfields", "Eye", "Hospital", "to", "develop", "AI", "applications", "for", "healthcare", "was", "announced", "."], "sentence-detokenized": "In July 2016, a partnership between DeepMind and Moorfields Eye Hospital to develop AI applications for healthcare was announced.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 15], [16, 27], [28, 35], [36, 44], [45, 48], [49, 59], [60, 63], [64, 72], [73, 75], [76, 83], [84, 86], [87, 99], [100, 103], [104, 114], [115, 118], [119, 128], [128, 129]]}
{"doc_key": "ai-dev-266", "ner": [[1, 1, "misc"], [11, 13, "university"], [15, 15, "university"], [17, 18, "university"], [20, 21, "university"], [23, 23, "university"], [25, 25, "university"], [27, 30, "university"], [32, 33, "university"], [35, 36, "university"], [38, 38, "university"], [41, 43, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[1, 1, 11, 13, "physical", "", false, false], [1, 1, 15, 15, "physical", "", false, false], [1, 1, 17, 18, "physical", "", false, false], [1, 1, 20, 21, "physical", "", false, false], [1, 1, 23, 23, "physical", "", false, false], [1, 1, 25, 25, "physical", "", false, false], [1, 1, 27, 30, "physical", "", false, false], [1, 1, 32, 33, "physical", "", false, false], [1, 1, 35, 36, "physical", "", false, false], [1, 1, 38, 38, "physical", "", false, false], [1, 1, 41, 43, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Eleven", "PR2s", "were", "eventually", "awarded", "to", "various", "institutions", ",", "including", "the", "University", "of", "Freiburg", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "Munich", "University", "of", "Technology", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", "and", "the", "University", "of", "Tokyo", "."], "sentence-detokenized": "Eleven PR2s were eventually awarded to various institutions, including the University of Freiburg, Bosch, Georgia Tech, KU Leuven, MIT, Stanford, Munich University of Technology, UC Berkeley, U Penn, USC and the University of Tokyo.", "token2charspan": [[0, 6], [7, 11], [12, 16], [17, 27], [28, 35], [36, 38], [39, 46], [47, 59], [59, 60], [61, 70], [71, 74], [75, 85], [86, 88], [89, 97], [97, 98], [99, 104], [104, 105], [106, 113], [114, 118], [118, 119], [120, 122], [123, 129], [129, 130], [131, 134], [134, 135], [136, 144], [144, 145], [146, 152], [153, 163], [164, 166], [167, 177], [177, 178], [179, 181], [182, 190], [190, 191], [192, 193], [194, 198], [198, 199], [200, 203], [204, 207], [208, 211], [212, 222], [223, 225], [226, 231], [231, 232]]}
{"doc_key": "ai-dev-267", "ner": [[0, 1, "metrics"], [3, 3, "metrics"], [5, 5, "metrics"], [7, 7, "metrics"], [18, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 18, 19, "part-of", "", false, false], [3, 3, 18, 19, "part-of", "", false, false], [5, 5, 18, 19, "part-of", "", false, false], [7, 7, 18, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "TP", ",", "TN", ",", "FP", "and", "FN", "measurements", "are", "usually", "kept", "in", "a", "table", "known", "as", "a", "confusion", "table", "."], "sentence-detokenized": "The TP, TN, FP and FN measurements are usually kept in a table known as a confusion table.", "token2charspan": [[0, 3], [4, 6], [6, 7], [8, 10], [10, 11], [12, 14], [15, 18], [19, 21], [22, 34], [35, 38], [39, 46], [47, 51], [52, 54], [55, 56], [57, 62], [63, 68], [69, 71], [72, 73], [74, 83], [84, 89], [89, 90]]}
{"doc_key": "ai-dev-268", "ner": [[0, 1, "metrics"], [3, 4, "metrics"], [6, 7, "metrics"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Information", "gain", ",", "cross", "-entropy", ",", "mutual", "information", "and", "likelihood", "ratio", "are", "commonly", "used", "as", "feature", "sets", "."], "sentence-detokenized": "Information gain, cross-entropy, mutual information and likelihood ratio are commonly used as feature sets.", "token2charspan": [[0, 11], [12, 16], [16, 17], [18, 23], [23, 31], [31, 32], [33, 39], [40, 51], [52, 55], [56, 66], [67, 72], [73, 76], [77, 85], [86, 90], [91, 93], [94, 101], [102, 106], [106, 107]]}
{"doc_key": "ai-dev-269", "ner": [[10, 11, "task"], [13, 14, "task"], [16, 16, "task"], [18, 18, "task"], [20, 20, "task"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[22, 22, 20, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "successfully", "applied", "to", "various", "problems", "such", "as", "robot", "control", ",", "elevator", "programming", ",", "telecommunications", ",", "checkers", "and", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "It has been successfully applied to various problems such as robot control, elevator programming, telecommunications, checkers and Go (AlphaGo).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 32], [33, 35], [36, 43], [44, 52], [53, 57], [58, 60], [61, 66], [67, 74], [74, 75], [76, 84], [85, 96], [96, 97], [98, 116], [116, 117], [118, 126], [127, 130], [131, 133], [134, 135], [135, 142], [142, 143], [143, 144]]}
{"doc_key": "ai-dev-270", "ner": [[11, 12, "misc"], [20, 23, "university"], [25, 25, "location"], [27, 27, "location"], [31, 36, "location"], [39, 41, "location"], [43, 43, "location"], [45, 45, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 20, 23, "physical", "", false, false], [20, 23, 25, 25, "physical", "", false, false], [25, 25, 27, 27, "physical", "", false, false], [31, 36, 39, 41, "physical", "", false, false], [39, 41, 43, 43, "physical", "", false, false], [43, 43, 45, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "the", "inaugural", "year", "of", "Mission", "8", ",", "the", "U.S.", "venue", "was", "held", "on", "the", "campus", "of", "the", "Georgia", "Institute", "of", "Technology", "in", "Atlanta", ",", "Georgia", ",", "while", "the", "Asia", "/", "Pacific", "venue", "was", "held", "at", "the", "Beihang", "University", "Gymnasium", "in", "Beijing", ",", "China", "."], "sentence-detokenized": "In 2018, the inaugural year of Mission 8, the U.S. venue was held on the campus of the Georgia Institute of Technology in Atlanta, Georgia, while the Asia/Pacific venue was held at the Beihang University Gymnasium in Beijing, China.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 38], [39, 40], [40, 41], [42, 45], [46, 50], [51, 56], [57, 60], [61, 65], [66, 68], [69, 72], [73, 79], [80, 82], [83, 86], [87, 94], [95, 104], [105, 107], [108, 118], [119, 121], [122, 129], [129, 130], [131, 138], [138, 139], [140, 145], [146, 149], [150, 154], [154, 155], [155, 162], [163, 168], [169, 172], [173, 177], [178, 180], [181, 184], [185, 192], [193, 203], [204, 213], [214, 216], [217, 224], [224, 225], [226, 231], [231, 232]]}
{"doc_key": "ai-dev-271", "ner": [[0, 2, "field"], [6, 7, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 7, "origin", "", false, false], [0, 2, 6, 7, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "is", "closely", "related", "to", "pattern", "recognition", "and", "comes", "from", "artificial", "intelligence", "."], "sentence-detokenized": "Machine learning is closely related to pattern recognition and comes from artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 35], [36, 38], [39, 46], [47, 58], [59, 62], [63, 68], [69, 73], [74, 84], [85, 97], [97, 98]]}
{"doc_key": "ai-dev-272", "ner": [[3, 3, "programlang"], [14, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "3", "Java", "games", "controlled", "by", "the", "remote", "control", "and", "displayed", "on", "the", "LCD", "screen", "."], "sentence-detokenized": "It has 3 Java games controlled by the remote control and displayed on the LCD screen.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 13], [14, 19], [20, 30], [31, 33], [34, 37], [38, 44], [45, 52], [53, 56], [57, 66], [67, 69], [70, 73], [74, 77], [78, 84], [84, 85]]}
{"doc_key": "ai-dev-273", "ner": [[6, 17, "task"], [18, 20, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 20, 6, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "commercially", "successful", "but", "specialized", "technique", "to", "estimate", "the", "posture", "of", "articulated", "bodies", "based", "on", "computer", "vision", "is", "visual", "motion", "capture", "."], "sentence-detokenized": "A commercially successful but specialized technique to estimate the posture of articulated bodies based on computer vision is visual motion capture.", "token2charspan": [[0, 1], [2, 14], [15, 25], [26, 29], [30, 41], [42, 51], [52, 54], [55, 63], [64, 67], [68, 75], [76, 78], [79, 90], [91, 97], [98, 103], [104, 106], [107, 115], [116, 122], [123, 125], [126, 132], [133, 139], [140, 147], [147, 148]]}
{"doc_key": "ai-dev-274", "ner": [[1, 1, "organisation"], [10, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 10, 11, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SMC", "index", "is", "very", "similar", "to", "the", "more", "popular", "Jaccard", "index", "."], "sentence-detokenized": "The SMC index is very similar to the more popular Jaccard index.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 21], [22, 29], [30, 32], [33, 36], [37, 41], [42, 49], [50, 57], [58, 63], [63, 64]]}
{"doc_key": "ai-dev-275", "ner": [[1, 1, "product"], [3, 7, "product"], [9, 12, "product"], [21, 22, "researcher"], [28, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 9, 12, "named", "", false, false], [1, 1, 21, 22, "artifact", "", false, false], [1, 1, 28, 28, "artifact", "", false, false], [3, 7, 1, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", "or", "Programmable", "Universal", "Manipulation", "Arm", ")", "is", "an", "industrial", "robotic", "arm", "developed", "by", "Victor", "Scheinman", "at", "the", "pioneering", "robot", "company", "Unimation", "."], "sentence-detokenized": "The PUMA (Programmable Universal Machine for Assembly or Programmable Universal Manipulation Arm) is an industrial robotic arm developed by Victor Scheinman at the pioneering robot company Unimation.", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 22], [23, 32], [33, 40], [41, 44], [45, 53], [54, 56], [57, 69], [70, 79], [80, 92], [93, 96], [96, 97], [98, 100], [101, 103], [104, 114], [115, 122], [123, 126], [127, 136], [137, 139], [140, 146], [147, 156], [157, 159], [160, 163], [164, 174], [175, 180], [181, 188], [189, 198], [198, 199]]}
{"doc_key": "ai-dev-276", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "written", "in", "Python", "."], "sentence-detokenized": "It is written in Python.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 23], [23, 24]]}
{"doc_key": "ai-dev-277", "ner": [[0, 0, "misc"], [2, 2, "misc"], [13, 13, "field"], [15, 16, "field"], [18, 18, "field"], [24, 25, "field"], [27, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7], "relations": [[0, 0, 2, 2, "related-to", "metric_for", true, false], [0, 0, 13, 13, "part-of", "", false, false], [0, 0, 15, 16, "part-of", "", false, false], [0, 0, 18, 18, "part-of", "", false, false], [0, 0, 24, 25, "part-of", "", false, false], [0, 0, 27, 27, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6], "sentence": ["Bandwidth", "in", "Hertz", "is", "a", "central", "concept", "in", "many", "fields", ",", "such", "as", "electronics", ",", "information", "theory", ",", "digital", "communications", ",", "radio", "communications", ",", "signal", "processing", "and", "spectroscopy", ",", "and", "is", "one", "of", "the", "determinants", "of", "the", "capacity", "of", "a", "particular", "communication", "channel", "."], "sentence-detokenized": "Bandwidth in Hertz is a central concept in many fields, such as electronics, information theory, digital communications, radio communications, signal processing and spectroscopy, and is one of the determinants of the capacity of a particular communication channel.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 21], [22, 23], [24, 31], [32, 39], [40, 42], [43, 47], [48, 54], [54, 55], [56, 60], [61, 63], [64, 75], [75, 76], [77, 88], [89, 95], [95, 96], [97, 104], [105, 119], [119, 120], [121, 126], [127, 141], [141, 142], [143, 149], [150, 160], [161, 164], [165, 177], [177, 178], [179, 182], [183, 185], [186, 189], [190, 192], [193, 196], [197, 209], [210, 212], [213, 216], [217, 225], [226, 228], [229, 230], [231, 241], [242, 255], [256, 263], [263, 264]]}
{"doc_key": "ai-dev-278", "ner": [[9, 9, "algorithm"], [11, 11, "algorithm"], [17, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 17, 20, "part-of", "", false, false], [11, 11, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "a", "convex", "loss", "is", "used", "(", "as", "in", "AdaBoost", ",", "LogitBoost", "and", "all", "members", "of", "the", "AnyBoost", "family", "of", "algorithms", ")", ",", "then", "an", "example", "with", "a", "higher", "margin", "will", "receive", "less", "(", "or", "equal", ")", "weight", "than", "an", "example", "with", "a", "lower", "margin", "."], "sentence-detokenized": "If a convex loss is used (as in AdaBoost, LogitBoost and all members of the AnyBoost family of algorithms), then an example with a higher margin will receive less (or equal) weight than an example with a lower margin.", "token2charspan": [[0, 2], [3, 4], [5, 11], [12, 16], [17, 19], [20, 24], [25, 26], [26, 28], [29, 31], [32, 40], [40, 41], [42, 52], [53, 56], [57, 60], [61, 68], [69, 71], [72, 75], [76, 84], [85, 91], [92, 94], [95, 105], [105, 106], [106, 107], [108, 112], [113, 115], [116, 123], [124, 128], [129, 130], [131, 137], [138, 144], [145, 149], [150, 157], [158, 162], [163, 164], [164, 166], [167, 172], [172, 173], [174, 180], [181, 185], [186, 188], [189, 196], [197, 201], [202, 203], [204, 209], [210, 216], [216, 217]]}
{"doc_key": "ai-dev-279", "ner": [[0, 0, "researcher"], [5, 6, "researcher"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sepp", "Hochreiter", "'s", "1991", "thesis", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Sepp Hochreiter's 1991 thesis Sepp Hochreiter.", "token2charspan": [[0, 4], [5, 15], [15, 17], [18, 22], [23, 29], [30, 34], [35, 45], [45, 46]]}
{"doc_key": "ai-dev-280", "ner": [[5, 5, "algorithm"], [4, 7, "algorithm"], [10, 11, "algorithm"], [14, 14, "algorithm"], [19, 19, "algorithm"], [18, 21, "algorithm"], [27, 28, "algorithm"], [31, 32, "algorithm"], [34, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[4, 7, 5, 5, "named", "", false, false], [14, 14, 10, 11, "named", "", false, false], [19, 19, 27, 28, "related-to", "", true, false], [18, 21, 19, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Typical", "discrimination", "models", "include", "logistic", "regression", "(", "LR", ")", ",", "support", "vector", "machines", "(", "SVM", ")", ",", "conditional", "random", "fields", "(", "CRF", ")", "(", "defined", "on", "an", "undirected", "graph", ")", ",", "decision", "trees", ",", "neural", "networks", "and", "many", "others", "."], "sentence-detokenized": "Typical discrimination models include logistic regression (LR), support vector machines (SVM), conditional random fields (CRF) (defined on an undirected graph), decision trees, neural networks and many others.", "token2charspan": [[0, 7], [8, 22], [23, 29], [30, 37], [38, 46], [47, 57], [58, 59], [59, 61], [61, 62], [62, 63], [64, 71], [72, 78], [79, 87], [88, 89], [89, 92], [92, 93], [93, 94], [95, 106], [107, 113], [114, 120], [121, 122], [122, 125], [125, 126], [127, 128], [128, 135], [136, 138], [139, 141], [142, 152], [153, 158], [158, 159], [159, 160], [161, 169], [170, 175], [175, 176], [177, 183], [184, 192], [193, 196], [197, 201], [202, 208], [208, 209]]}
{"doc_key": "ai-dev-281", "ner": [[12, 14, "metrics"], [36, 37, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Then", "it", "is", "also", "possible", "to", "use", "these", "probabilities", "and", "evaluate", "the", "mean", "squared", "error", "(", "or", "some", "other", "similar", "measure", ")", "between", "the", "probabilities", "and", "the", "true", "values", ",", "and", "then", "combine", "this", "with", "the", "confusion", "matrix", "to", "create", "very", "effective", "goodness", "-", "of", "-", "fit", "functions", "for", "logistic", "regression", "."], "sentence-detokenized": "Then it is also possible to use these probabilities and evaluate the mean squared error (or some other similar measure) between the probabilities and the true values, and then combine this with the confusion matrix to create very effective goodness-of-fit functions for logistic regression.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 15], [16, 24], [25, 27], [28, 31], [32, 37], [38, 51], [52, 55], [56, 64], [65, 68], [69, 73], [74, 81], [82, 87], [88, 89], [89, 91], [92, 96], [97, 102], [103, 110], [111, 118], [118, 119], [120, 127], [128, 131], [132, 145], [146, 149], [150, 153], [154, 158], [159, 165], [165, 166], [167, 170], [171, 175], [176, 183], [184, 188], [189, 193], [194, 197], [198, 207], [208, 214], [215, 217], [218, 224], [225, 229], [230, 239], [240, 248], [248, 249], [249, 251], [251, 252], [252, 255], [256, 265], [266, 269], [270, 278], [279, 289], [289, 290]]}
{"doc_key": "ai-dev-282", "ner": [[0, 0, "product"], [7, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "was", "first", "used", "in", "2005", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "."], "sentence-detokenized": "VoiceOver was first used in 2005 in Mac OS X Tiger (10.4).", "token2charspan": [[0, 9], [10, 13], [14, 19], [20, 24], [25, 27], [28, 32], [33, 35], [36, 39], [40, 42], [43, 44], [45, 50], [51, 52], [52, 56], [56, 57], [57, 58]]}
{"doc_key": "ai-dev-283", "ner": [[13, 15, "algorithm"], [19, 21, "misc"], [25, 27, "metrics"], [30, 32, "algorithm"], [62, 64, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 15, 19, 21, "related-to", "applied_to", false, false], [25, 27, 19, 21, "type-of", "", false, false], [25, 27, 30, 32, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "practice", ",", "machine", "learning", "algorithms", "deal", "with", "this", "by", "either", "using", "a", "convex", "approximation", "of", "the", "0", "-", "1", "loss", "function", "(", "such", "as", "the", "joint", "loss", "for", "the", "support", "vector", "machine", ")", ",", "which", "is", "easier", "to", "optimize", ",", "or", "by", "imposing", "assumptions", "on", "the", "mathP", "(", "x", ",", "y", ")", "/", "math", "distribution", "(", "and", "thus", "ceasing", "to", "be", "agnostic", "learning", "algorithms", "in", "which", "the", "above", "result", "holds", ")", "."], "sentence-detokenized": "In practice, machine learning algorithms deal with this by either using a convex approximation of the 0-1 loss function (such as the joint loss for the support vector machine), which is easier to optimize, or by imposing assumptions on the mathP(x, y)/math distribution (and thus ceasing to be agnostic learning algorithms in which the above result holds).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 29], [30, 40], [41, 45], [46, 50], [51, 55], [56, 58], [59, 65], [66, 71], [72, 73], [74, 80], [81, 94], [95, 97], [98, 101], [102, 103], [103, 104], [104, 105], [106, 110], [111, 119], [120, 121], [121, 125], [126, 128], [129, 132], [133, 138], [139, 143], [144, 147], [148, 151], [152, 159], [160, 166], [167, 174], [174, 175], [175, 176], [177, 182], [183, 185], [186, 192], [193, 195], [196, 204], [204, 205], [206, 208], [209, 211], [212, 220], [221, 232], [233, 235], [236, 239], [240, 245], [245, 246], [246, 247], [247, 248], [249, 250], [250, 251], [251, 252], [252, 256], [257, 269], [270, 271], [271, 274], [275, 279], [280, 287], [288, 290], [291, 293], [294, 302], [303, 311], [312, 322], [323, 325], [326, 331], [332, 335], [336, 341], [342, 348], [349, 354], [354, 355], [355, 356]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [11, 13, "field"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "usage", "", false, false], [0, 0, 22, 22, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Westworld", "(", "1973", ")", "was", "the", "first", "feature", "film", "to", "use", "digital", "image", "processing", "in", "photography", "to", "simulate", "the", "perspective", "of", "an", "android", "."], "sentence-detokenized": "Westworld (1973) was the first feature film to use digital image processing in photography to simulate the perspective of an android.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 20], [21, 24], [25, 30], [31, 38], [39, 43], [44, 46], [47, 50], [51, 58], [59, 64], [65, 75], [76, 78], [79, 90], [91, 93], [94, 102], [103, 106], [107, 118], [119, 121], [122, 124], [125, 132], [132, 133]]}
{"doc_key": "ai-dev-285", "ner": [[7, 8, "task"], [10, 11, "task"], [13, 13, "task"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "now", "also", "widely", "used", "in", "speech", "recognition", ",", "speech", "synthesis", ",", "diarisation", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "It is now also widely used in speech recognition, speech synthesis, diarisation, Xavier Anguera et al.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 14], [15, 21], [22, 26], [27, 29], [30, 36], [37, 48], [48, 49], [50, 56], [57, 66], [66, 67], [68, 79], [79, 80], [81, 87], [88, 95], [96, 98], [99, 101], [101, 102]]}
{"doc_key": "ai-dev-286", "ner": [[9, 14, "algorithm"], [16, 17, "algorithm"], [20, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 17, 9, 14, "type-of", "", false, false], [20, 22, 9, 14, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Here", ",", "math", "\\", "sigma", "/", "math", "is", "a", "per-element", "activation", "function", ",", "such", "as", "a", "sigmoid", "function", "or", "a", "corrected", "linear", "unit", "."], "sentence-detokenized": "Here, math\\ sigma/math is a per-element activation function, such as a sigmoid function or a corrected linear unit.", "token2charspan": [[0, 4], [4, 5], [6, 10], [10, 11], [12, 17], [17, 18], [18, 22], [23, 25], [26, 27], [28, 39], [40, 50], [51, 59], [59, 60], [61, 65], [66, 68], [69, 70], [71, 78], [79, 87], [88, 90], [91, 92], [93, 102], [103, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-dev-287", "ner": [[8, 9, "algorithm"], [22, 22, "misc"], [24, 24, "misc"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "phonetics", "-", "based", "approaches", "(", "i.e.", "all", "Hidden", "Markov", "model", "-", "based", "models", ")", "required", "separate", "components", "and", "training", "for", "the", "pronunciation", ",", "auditory", "and", "language", "models", "."], "sentence-detokenized": "Traditional phonetics-based approaches (i.e. all Hidden Markov model-based models) required separate components and training for the pronunciation, auditory and language models.", "token2charspan": [[0, 11], [12, 21], [21, 22], [22, 27], [28, 38], [39, 40], [40, 44], [45, 48], [49, 55], [56, 62], [63, 68], [68, 69], [69, 74], [75, 81], [81, 82], [83, 91], [92, 100], [101, 111], [112, 115], [116, 124], [125, 128], [129, 132], [133, 146], [146, 147], [148, 156], [157, 160], [161, 169], [170, 176], [176, 177]]}
{"doc_key": "ai-dev-288", "ner": [[1, 3, "algorithm"], [7, 8, "field"], [10, 11, "field"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 13, 14, "related-to", "used_for", false, false], [7, 8, 1, 3, "usage", "", false, false], [10, 11, 1, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Roberts", "cross", "operator", "is", "used", "in", "image", "processing", "and", "computer", "vision", "to", "detect", "edges", "."], "sentence-detokenized": "The Roberts cross operator is used in image processing and computer vision to detect edges.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 37], [38, 43], [44, 54], [55, 58], [59, 67], [68, 74], [75, 77], [78, 84], [85, 90], [90, 91]]}
{"doc_key": "ai-dev-289", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [26, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 26, 26, "opposite", "", false, false], [5, 5, 26, 26, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "values", "of", "sensitivity", "and", "specificity", "have", "no", "relation", "to", "the", "proportion", "of", "positive", "cases", "in", "the", "population", "of", "interest", "(", "unlike", ",", "for", "example", ",", "accuracy", ")", "."], "sentence-detokenized": "The values of sensitivity and specificity have no relation to the proportion of positive cases in the population of interest (unlike, for example, accuracy).", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 25], [26, 29], [30, 41], [42, 46], [47, 49], [50, 58], [59, 61], [62, 65], [66, 76], [77, 79], [80, 88], [89, 94], [95, 97], [98, 101], [102, 112], [113, 115], [116, 124], [125, 126], [126, 132], [132, 133], [134, 137], [138, 145], [145, 146], [147, 155], [155, 156], [156, 157]]}
{"doc_key": "ai-dev-290", "ner": [[2, 3, "algorithm"], [11, 12, "misc"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 2, 3, "topic", "", false, false], [11, 12, 13, 14, "artifact", "", false, false], [11, 12, 16, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "perceptron", "models", "have", "become", "very", "unpopular", "since", "the", "book", "Perceptrons", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", ",", "published", "in", "1969", "."], "sentence-detokenized": "However, perceptron models have become very unpopular since the book Perceptrons by Marvin Minsky and Seymour Papert, published in 1969.", "token2charspan": [[0, 7], [7, 8], [9, 19], [20, 26], [27, 31], [32, 38], [39, 43], [44, 53], [54, 59], [60, 63], [64, 68], [69, 80], [81, 83], [84, 90], [91, 97], [98, 101], [102, 109], [110, 116], [116, 117], [118, 127], [128, 130], [131, 135], [135, 136]]}
{"doc_key": "ai-dev-291", "ner": [[1, 3, "conference"], [8, 8, "organisation"], [22, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 3, 22, 24, "topic", "", false, false], [8, 8, 1, 3, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Document", "Understanding", "Conferences", ",", "held", "annually", "by", "NIST", ",", "have", "developed", "sophisticated", "evaluation", "criteria", "for", "techniques", "that", "accept", "the", "challenge", "of", "summarizing", "multiple", "documents", "."], "sentence-detokenized": "The Document Understanding Conferences, held annually by NIST, have developed sophisticated evaluation criteria for techniques that accept the challenge of summarizing multiple documents.", "token2charspan": [[0, 3], [4, 12], [13, 26], [27, 38], [38, 39], [40, 44], [45, 53], [54, 56], [57, 61], [61, 62], [63, 67], [68, 77], [78, 91], [92, 102], [103, 111], [112, 115], [116, 126], [127, 131], [132, 138], [139, 142], [143, 152], [153, 155], [156, 167], [168, 176], [177, 186], [186, 187]]}
{"doc_key": "ai-dev-292", "ner": [[1, 2, "product"], [24, 25, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 24, 25, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "parallel", "manipulator", "is", "designed", "so", "that", "each", "chain", "is", "usually", "short", ",", "simple", "and", "therefore", "rigid", "against", "unwanted", "movements", ",", "compared", "to", "a", "serial", "manipulator", "."], "sentence-detokenized": "A parallel manipulator is designed so that each chain is usually short, simple and therefore rigid against unwanted movements, compared to a serial manipulator.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 34], [35, 37], [38, 42], [43, 47], [48, 53], [54, 56], [57, 64], [65, 70], [70, 71], [72, 78], [79, 82], [83, 92], [93, 98], [99, 106], [107, 115], [116, 125], [125, 126], [127, 135], [136, 138], [139, 140], [141, 147], [148, 159], [159, 160]]}
{"doc_key": "ai-dev-293", "ner": [[26, 26, "misc"], [27, 32, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "operator", "is", "what", "makes", "the", "robot", "move", ",", "and", "the", "design", "of", "these", "systems", "can", "be", "categorized", "into", "several", "common", "types", ",", "such", "as", "the", "SCARA", "robot", "and", "the", "Cartesian", "coordinate", "robot", ",", "which", "use", "different", "coordinate", "systems", "to", "steer", "the", "arms", "of", "the", "machine", "."], "sentence-detokenized": "The operator is what makes the robot move, and the design of these systems can be categorized into several common types, such as the SCARA robot and the Cartesian coordinate robot, which use different coordinate systems to steer the arms of the machine.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [21, 26], [27, 30], [31, 36], [37, 41], [41, 42], [43, 46], [47, 50], [51, 57], [58, 60], [61, 66], [67, 74], [75, 78], [79, 81], [82, 93], [94, 98], [99, 106], [107, 113], [114, 119], [119, 120], [121, 125], [126, 128], [129, 132], [133, 138], [139, 144], [145, 148], [149, 152], [153, 162], [163, 173], [174, 179], [179, 180], [181, 186], [187, 190], [191, 200], [201, 211], [212, 219], [220, 222], [223, 228], [229, 232], [233, 237], [238, 240], [241, 244], [245, 252], [252, 253]]}
{"doc_key": "ai-dev-294", "ner": [[2, 3, "country"], [11, 14, "organisation"], [17, 22, "organisation"], [25, 28, "organisation"], [31, 33, "organisation"], [37, 43, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 14, 2, 3, "physical", "", false, false], [17, 22, 2, 3, "physical", "", false, false], [25, 28, 2, 3, "physical", "", false, false], [31, 33, 2, 3, "physical", "", false, false], [37, 43, 2, 3, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "United", "States", ",", "he", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "Linguistic", "Society", "of", "America", ",", "the", "American", "Philosophical", "Society", ",", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In the United States, he is a member of the National Academy of Sciences, the American Academy of Arts and Sciences, the Linguistic Society of America, the American Philosophical Society, and the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 20], [20, 21], [22, 24], [25, 27], [28, 29], [30, 36], [37, 39], [40, 43], [44, 52], [53, 60], [61, 63], [64, 72], [72, 73], [74, 77], [78, 86], [87, 94], [95, 97], [98, 102], [103, 106], [107, 115], [115, 116], [117, 120], [121, 131], [132, 139], [140, 142], [143, 150], [150, 151], [152, 155], [156, 164], [165, 178], [179, 186], [186, 187], [188, 191], [192, 195], [196, 204], [205, 216], [217, 220], [221, 224], [225, 236], [237, 239], [240, 247], [247, 248]]}
{"doc_key": "ai-dev-295", "ner": [[9, 10, "algorithm"], [11, 16, "algorithm"], [24, 24, "algorithm"], [28, 29, "algorithm"], [34, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 10, 24, 24, "named", "", false, false], [11, 16, 9, 10, "named", "", false, false], [24, 24, 28, 29, "compare", "", false, false], [24, 24, 34, 35, "related-to", "performs", false, false], [28, 29, 34, 35, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["They", "were", "greatly", "highlighted", "by", "the", "popularity", "of", "the", "support", "vector", "machine", "(", "SVM", ")", "in", "the", "1990s", ",", "when", "it", "was", "found", "that", "SVM", "was", "competitive", "with", "neural", "networks", "in", "tasks", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "They were greatly highlighted by the popularity of the support vector machine (SVM) in the 1990s, when it was found that SVM was competitive with neural networks in tasks such as handwriting recognition.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 29], [30, 32], [33, 36], [37, 47], [48, 50], [51, 54], [55, 62], [63, 69], [70, 77], [78, 79], [79, 82], [82, 83], [84, 86], [87, 90], [91, 96], [96, 97], [98, 102], [103, 105], [106, 109], [110, 115], [116, 120], [121, 124], [125, 128], [129, 140], [141, 145], [146, 152], [153, 161], [162, 164], [165, 170], [171, 175], [176, 178], [179, 190], [191, 202], [202, 203]]}
{"doc_key": "ai-dev-296", "ner": [[2, 3, "misc"], [9, 9, "misc"], [14, 15, "algorithm"], [23, 24, "misc"], [29, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 9, "usage", "", false, false], [2, 3, 23, 24, "usage", "", false, false], [9, 9, 14, 15, "origin", "result_of_algorithm", false, false], [23, 24, 29, 30, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["An", "empirical", "whitening", "transformation", "is", "obtained", "by", "estimating", "the", "covariance", "(", "e.g.", ",", "by", "maximum", "likelihood", ")", "and", "then", "constructing", "a", "corresponding", "estimated", "whitening", "matrix", "(", "e.g.", ",", "by", "Cholesky", "decomposition", ")", "."], "sentence-detokenized": "An empirical whitening transformation is obtained by estimating the covariance (e.g., by maximum likelihood) and then constructing a corresponding estimated whitening matrix (e.g., by Cholesky decomposition).", "token2charspan": [[0, 2], [3, 12], [13, 22], [23, 37], [38, 40], [41, 49], [50, 52], [53, 63], [64, 67], [68, 78], [79, 80], [80, 84], [84, 85], [86, 88], [89, 96], [97, 107], [107, 108], [109, 112], [113, 117], [118, 130], [131, 132], [133, 146], [147, 156], [157, 166], [167, 173], [174, 175], [175, 179], [179, 180], [181, 183], [184, 192], [193, 206], [206, 207], [207, 208]]}
{"doc_key": "ai-dev-297", "ner": [[0, 2, "organisation"], [8, 10, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 0, 2, "artifact", "", false, false], [26, 27, 0, 2, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "is", "the", "world", "'s", "largest", "manufacturer", "of", "Cartesian", "coordinate", "robots", "and", "has", "established", "itself", "as", "a", "leader", "in", "low", "-", "cost", ",", "high", "-", "performance", "SCARA", "robots", "."], "sentence-detokenized": "IAI is the world's largest manufacturer of Cartesian coordinate robots and has established itself as a leader in low-cost, high-performance SCARA robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [16, 18], [19, 26], [27, 39], [40, 42], [43, 52], [53, 63], [64, 70], [71, 74], [75, 78], [79, 90], [91, 97], [98, 100], [101, 102], [103, 109], [110, 112], [113, 116], [116, 117], [117, 121], [121, 122], [123, 127], [127, 128], [128, 139], [140, 145], [146, 152], [152, 153]]}
{"doc_key": "ai-dev-298", "ner": [[10, 11, "field"], [13, 14, "field"], [16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formal", "concept", "analysis", "has", "practical", "applications", "in", "areas", "such", "as", "data", "mining", ",", "text", "mining", ",", "machine", "learning", ",", "knowledge", "management", ",", "semantic", "web", ",", "software", "development", ",", "chemistry", "and", "biology", "."], "sentence-detokenized": "Formal concept analysis has practical applications in areas such as data mining, text mining, machine learning, knowledge management, semantic web, software development, chemistry and biology.", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 27], [28, 37], [38, 50], [51, 53], [54, 59], [60, 64], [65, 67], [68, 72], [73, 79], [79, 80], [81, 85], [86, 92], [92, 93], [94, 101], [102, 110], [110, 111], [112, 121], [122, 132], [132, 133], [134, 142], [143, 146], [146, 147], [148, 156], [157, 168], [168, 169], [170, 179], [180, 183], [184, 191], [191, 192]]}
{"doc_key": "ai-dev-299", "ner": [[1, 2, "field"], [4, 6, "field"], [10, 11, "field"], [17, 18, "field"], [30, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 17, 18, "part-of", "", false, false], [4, 6, 30, 31, "topic", "", false, false], [10, 11, 4, 6, "named", "", false, false], [17, 18, 1, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", ",", "computational", "learning", "theory", "(", "or", "simply", "learning", "theory", ")", "is", "a", "subfield", "of", "artificial", "intelligence", "that", "deals", "with", "the", "study", "of", "the", "design", "and", "analysis", "of", "machine", "learning", "algorithms", "."], "sentence-detokenized": "In computer science, computational learning theory (or simply learning theory) is a subfield of artificial intelligence that deals with the study of the design and analysis of machine learning algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 34], [35, 43], [44, 50], [51, 52], [52, 54], [55, 61], [62, 70], [71, 77], [77, 78], [79, 81], [82, 83], [84, 92], [93, 95], [96, 106], [107, 119], [120, 124], [125, 130], [131, 135], [136, 139], [140, 145], [146, 148], [149, 152], [153, 159], [160, 163], [164, 172], [173, 175], [176, 183], [184, 192], [193, 203], [203, 204]]}
{"doc_key": "ai-dev-300", "ner": [[1, 1, "algorithm"], [0, 3, "algorithm"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 1, 1, "named", "", false, false], [10, 10, 1, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cooperative", "filtering", "(", "CF", ")", "is", "a", "technique", "used", "by", "recommender", "systems", "."], "sentence-detokenized": "Cooperative filtering (CF) is a technique used by recommender systems.", "token2charspan": [[0, 11], [12, 21], [22, 23], [23, 25], [25, 26], [27, 29], [30, 31], [32, 41], [42, 46], [47, 49], [50, 61], [62, 69], [69, 70]]}
{"doc_key": "ai-dev-301", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "FALSE", "positive", "rate", "is", "the", "percentage", "of", "all", "negatives", "that", "still", "give", "positive", "test", "results", ",", "i.e.", "the", "conditional", "probability", "of", "a", "positive", "test", "result", "given", "an", "event", "that", "was", "not", "present", "."], "sentence-detokenized": "The FALSE positive rate is the percentage of all negatives that still give positive test results, i.e. the conditional probability of a positive test result given an event that was not present.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 23], [24, 26], [27, 30], [31, 41], [42, 44], [45, 48], [49, 58], [59, 63], [64, 69], [70, 74], [75, 83], [84, 88], [89, 96], [96, 97], [98, 102], [103, 106], [107, 118], [119, 130], [131, 133], [134, 135], [136, 144], [145, 149], [150, 156], [157, 162], [163, 165], [166, 171], [172, 176], [177, 180], [181, 184], [185, 192], [192, 193]]}
{"doc_key": "ai-dev-302", "ner": [[1, 15, "misc"], [37, 37, "metrics"], [41, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 15, 37, 37, "topic", "", false, false], [1, 15, 41, 41, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "VLDB", "'", "8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pages", "422--433", ".", "showed", "that", "the", "given", "values", "for", "mathC", "/", "math", "and", "mathK", "/", "math", "generally", "imply", "relatively", "low", "accuracy", "of", "iteratively", "computed", "SimRank", "results", "."], "sentence-detokenized": "In VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, pages 422--433. showed that the given values for mathC/math and mathK/math generally imply relatively low accuracy of iteratively computed SimRank results.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [10, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 79], [80, 85], [85, 86], [87, 92], [93, 101], [101, 102], [103, 109], [110, 114], [115, 118], [119, 124], [125, 131], [132, 135], [136, 141], [141, 142], [142, 146], [147, 150], [151, 156], [156, 157], [157, 161], [162, 171], [172, 177], [178, 188], [189, 192], [193, 201], [202, 204], [205, 216], [217, 225], [226, 233], [234, 241], [241, 242]]}
{"doc_key": "ai-dev-303", "ner": [[1, 4, "misc"], [5, 5, "misc"], [15, 16, "person"], [18, 20, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 1, 4, "general-affiliation", "", false, false], [5, 5, 15, 16, "artifact", "", false, false], [5, 5, 18, 20, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "sci", "-", "fi", "drama", "Sense8", "debuted", "in", "June", "2015", ",", "written", "and", "produced", "by", "the", "Wachowskis", "and", "J.", "Michael", "Straczynski", "."], "sentence-detokenized": "The sci-fi drama Sense8 debuted in June 2015, written and produced by the Wachowskis and J. Michael Straczynski.", "token2charspan": [[0, 3], [4, 7], [7, 8], [8, 10], [11, 16], [17, 23], [24, 31], [32, 34], [35, 39], [40, 44], [44, 45], [46, 53], [54, 57], [58, 66], [67, 69], [70, 73], [74, 84], [85, 88], [89, 91], [92, 99], [100, 111], [111, 112]]}
{"doc_key": "ai-dev-304", "ner": [[1, 1, "misc"], [6, 7, "product"], [28, 30, "misc"], [38, 38, "country"], [40, 40, "country"], [42, 42, "country"], [44, 44, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 1, 6, 7, "topic", "", false, false], [38, 38, 28, 30, "type-of", "", false, false], [40, 40, 28, 30, "type-of", "", false, false], [42, 42, 28, 30, "type-of", "", false, false], [44, 44, 28, 30, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Although", "Eurotra", "never", "delivered", "an", "operational", "MT", "system", ",", "the", "project", "had", "a", "far", "-", "reaching", "impact", "in", "the", "long", "term", "on", "the", "nascent", "language", "industries", "of", "the", "European", "Member", "States", ",", "particularly", "in", "the", "southern", "countries", "of", "Greece", ",", "Italy", ",", "Spain", "and", "Portugal", "."], "sentence-detokenized": "Although Eurotra never delivered an operational MT system, the project had a far-reaching impact in the long term on the nascent language industries of the European Member States, particularly in the southern countries of Greece, Italy, Spain and Portugal.", "token2charspan": [[0, 8], [9, 16], [17, 22], [23, 32], [33, 35], [36, 47], [48, 50], [51, 57], [57, 58], [59, 62], [63, 70], [71, 74], [75, 76], [77, 80], [80, 81], [81, 89], [90, 96], [97, 99], [100, 103], [104, 108], [109, 113], [114, 116], [117, 120], [121, 128], [129, 137], [138, 148], [149, 151], [152, 155], [156, 164], [165, 171], [172, 178], [178, 179], [180, 192], [193, 195], [196, 199], [200, 208], [209, 218], [219, 221], [222, 228], [228, 229], [230, 235], [235, 236], [237, 242], [243, 246], [247, 255], [255, 256]]}
{"doc_key": "ai-dev-305", "ner": [[0, 2, "algorithm"], [8, 10, "task"], [18, 20, "task"], [22, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 10, 0, 2, "usage", "", true, false], [18, 20, 8, 10, "named", "", false, false], [22, 22, 18, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "automatic", "coder", "has", "been", "successfully", "applied", "to", "machine", "translation", "of", "human", "languages", ",", "commonly", "referred", "to", "as", "neural", "machine", "translation", "(", "NMT", ")", "."], "sentence-detokenized": "The automatic coder has been successfully applied to machine translation of human languages, commonly referred to as neural machine translation (NMT).", "token2charspan": [[0, 3], [4, 13], [14, 19], [20, 23], [24, 28], [29, 41], [42, 49], [50, 52], [53, 60], [61, 72], [73, 75], [76, 81], [82, 91], [91, 92], [93, 101], [102, 110], [111, 113], [114, 116], [117, 123], [124, 131], [132, 143], [144, 145], [145, 148], [148, 149], [149, 150]]}
{"doc_key": "ai-dev-306", "ner": [[9, 11, "metrics"], [13, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "examples", "of", "probability", "-", "based", "fitness", "functions", "include", "maximum", "likelihood", "estimation", "and", "joi", "nt", "loss", "."], "sentence-detokenized": "Popular examples of probability-based fitness functions include maximum likelihood estimation and joint loss.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 31], [31, 32], [32, 37], [38, 45], [46, 55], [56, 63], [64, 71], [72, 82], [83, 93], [94, 97], [98, 101], [101, 103], [104, 108], [108, 109]]}
{"doc_key": "ai-dev-307", "ner": [[0, 1, "field"], [12, 14, "task"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 14, 0, 1, "part-of", "", false, false], [16, 17, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "mining", "is", "a", "related", "field", "of", "study", ",", "which", "focuses", "on", "exploratory", "data", "analysis", "through", "unsupervised", "learning", "."], "sentence-detokenized": "Data mining is a related field of study, which focuses on exploratory data analysis through unsupervised learning.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 33], [34, 39], [39, 40], [41, 46], [47, 54], [55, 57], [58, 69], [70, 74], [75, 83], [84, 91], [92, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-dev-308", "ner": [[0, 1, "algorithm"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "involves", "techniques", "for", "matching", "people", "with", "similar", "interests", "and", "creating", "a", "recommendation", "system", "based", "on", "this", "."], "sentence-detokenized": "Collaborative filtering involves techniques for matching people with similar interests and creating a recommendation system based on this.", "token2charspan": [[0, 13], [14, 23], [24, 32], [33, 43], [44, 47], [48, 56], [57, 63], [64, 68], [69, 76], [77, 86], [87, 90], [91, 99], [100, 101], [102, 116], [117, 123], [124, 129], [130, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-dev-309", "ner": [[1, 6, "algorithm"], [11, 11, "programlang"], [14, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 17, 1, 6, "type-of", "", false, false], [14, 17, 11, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Some", "WordNet", "-", "based", "word", "similarity", "algorithms", "are", "implemented", "in", "a", "Perl", "package", "called", "WordNet", ":", ":", "Similarity", "."], "sentence-detokenized": "Some WordNet-based word similarity algorithms are implemented in a Perl package called WordNet:: Similarity.", "token2charspan": [[0, 4], [5, 12], [12, 13], [13, 18], [19, 23], [24, 34], [35, 45], [46, 49], [50, 61], [62, 64], [65, 66], [67, 71], [72, 79], [80, 86], [87, 94], [94, 95], [95, 96], [97, 107], [107, 108]]}
{"doc_key": "ai-dev-310", "ner": [[4, 4, "conference"], [6, 6, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 4, 4, "named", "", false, false], [10, 11, 4, 4, "temporal", "", false, false], [13, 14, 4, 4, "temporal", "", false, false], [16, 17, 4, 4, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Another", "paper", "presented", "at", "CVPR", "(", "CVPR", ")", "2000", "by", "Erik", "Miller", ",", "Nicholas", "Matsakis", "and", "Paul", "Viola", "will", "also", "be", "discussed", "."], "sentence-detokenized": "Another paper presented at CVPR (CVPR) 2000 by Erik Miller, Nicholas Matsakis and Paul Viola will also be discussed.", "token2charspan": [[0, 7], [8, 13], [14, 23], [24, 26], [27, 31], [32, 33], [33, 37], [37, 38], [39, 43], [44, 46], [47, 51], [52, 58], [58, 59], [60, 68], [69, 77], [78, 81], [82, 86], [87, 92], [93, 97], [98, 102], [103, 105], [106, 115], [115, 116]]}
{"doc_key": "ai-dev-311", "ner": [[0, 0, "algorithm"], [8, 9, "misc"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 15, "compare", "", false, false], [14, 15, 8, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["QC", "has", "not", "been", "evaluated", "against", "traditional", "modern", "clustering", "algorithms", ",", "except", "for", "the", "Jaccard", "index", "."], "sentence-detokenized": "QC has not been evaluated against traditional modern clustering algorithms, except for the Jaccard index.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 15], [16, 25], [26, 33], [34, 45], [46, 52], [53, 63], [64, 74], [74, 75], [76, 82], [83, 86], [87, 90], [91, 98], [99, 104], [104, 105]]}
{"doc_key": "ai-dev-312", "ner": [[2, 5, "misc"], [8, 10, "misc"], [14, 14, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 2, 5, "physical", "", false, false], [8, 10, 14, 14, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "the", "VEX", "World", "Robotics", "Championships", ",", "the", "Parade", "of", "Nations", "takes", "place", "at", "Freedom", "Hall", ",", "with", "hundreds", "of", "students", "from", "more", "than", "30", "countries", "participating", "."], "sentence-detokenized": "During the VEX World Robotics Championships, the Parade of Nations takes place at Freedom Hall, with hundreds of students from more than 30 countries participating.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 20], [21, 29], [30, 43], [43, 44], [45, 48], [49, 55], [56, 58], [59, 66], [67, 72], [73, 78], [79, 81], [82, 89], [90, 94], [94, 95], [96, 100], [101, 109], [110, 112], [113, 121], [122, 126], [127, 131], [132, 136], [137, 139], [140, 149], [150, 163], [163, 164]]}
{"doc_key": "ai-dev-313", "ner": [[6, 8, "metrics"], [5, 10, "metrics"], [14, 15, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 10, 6, 8, "named", "", false, false], [17, 17, 14, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Other", "measures", "of", "accuracy", "include", "single", "word", "error", "rate", "(", "SWER", ")", "and", "command", "success", "rate", "(", "CSR", ")", "."], "sentence-detokenized": "Other measures of accuracy include single word error rate (SWER) and command success rate (CSR).", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [27, 34], [35, 41], [42, 46], [47, 52], [53, 57], [58, 59], [59, 63], [63, 64], [65, 68], [69, 76], [77, 84], [85, 89], [90, 91], [91, 94], [94, 95], [95, 96]]}
{"doc_key": "ai-dev-314", "ner": [[7, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "presented", "their", "method", "and", "results", "at", "SIGGRAPH", "2000", "."], "sentence-detokenized": "They presented their method and results at SIGGRAPH 2000.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 27], [28, 31], [32, 39], [40, 42], [43, 51], [52, 56], [56, 57]]}
{"doc_key": "ai-dev-315", "ner": [[0, 2, "conference"], [7, 7, "misc"], [9, 13, "misc"], [18, 19, "conference"], [25, 30, "researcher"], [38, 39, "researcher"], [43, 45, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 7, 7, "origin", "", false, false], [7, 7, 18, 19, "physical", "", false, false], [7, 7, 18, 19, "temporal", "", false, false], [7, 7, 25, 30, "origin", "", false, false], [7, 7, 38, 39, "origin", "", false, false], [9, 13, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "KDD", "conference", "grew", "out", "of", "the", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "workshops", "at", "the", "AAAI", "conferences", ",", "which", "were", "initiated", "by", "Gregory", "I", ".", "Piatetsky", "-", "Shapiro", "in", "1989", ",", "1991", "and", "1993", "and", "Usama", "Fayyad", "in", "1994", ".", "Machinery", "|", "ACM", "."], "sentence-detokenized": "The KDD conference grew out of the KDD (Knowledge Discovery and Data Mining) workshops at the AAAI conferences, which were initiated by Gregory I. Piatetsky-Shapiro in 1989, 1991 and 1993 and Usama Fayyad in 1994. Machinery | ACM.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 23], [24, 27], [28, 30], [31, 34], [35, 38], [39, 40], [40, 49], [50, 59], [60, 63], [64, 68], [69, 75], [75, 76], [77, 86], [87, 89], [90, 93], [94, 98], [99, 110], [110, 111], [112, 117], [118, 122], [123, 132], [133, 135], [136, 143], [144, 145], [145, 146], [147, 156], [156, 157], [157, 164], [165, 167], [168, 172], [172, 173], [174, 178], [179, 182], [183, 187], [188, 191], [192, 197], [198, 204], [205, 207], [208, 212], [212, 213], [214, 223], [224, 225], [226, 229], [229, 230]]}
{"doc_key": "ai-dev-316", "ner": [[10, 11, "conference"], [13, 13, "conference"], [19, 22, "organisation"], [24, 24, "organisation"], [29, 32, "conference"], [28, 34, "conference"], [38, 44, "conference"], [46, 46, "conference"], [53, 55, "conference"], [57, 57, "conference"], [61, 66, "conference"], [65, 68, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[13, 13, 10, 11, "named", "", false, false], [24, 24, 19, 22, "named", "", false, false], [28, 34, 29, 32, "named", "", false, false], [46, 46, 38, 44, "named", "", false, false], [57, 57, 53, 55, "named", "", false, false], [65, 68, 61, 66, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "has", "been", "elected", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "the", "American", "Association", "for", "Advancement", "of", "Science", "(", "AAAS", ")", "and", "the", "Society", "for", "Optics", "and", "Photonics", "Technology", "(", "SPIE", ")", "."], "sentence-detokenized": "He has been elected a member of the Association for Computing Machinery (ACM), the Institute of Electrical and Electronics Engineers (IEEE), the International Association for Pattern Recognition (IAPR), the Association for the Advancement of Artificial Intelligence (AAAI), the American Association for Advancement of Science (AAAS) and the Society for Optics and Photonics Technology (SPIE).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 21], [22, 28], [29, 31], [32, 35], [36, 47], [48, 51], [52, 61], [62, 71], [72, 73], [73, 76], [76, 77], [77, 78], [79, 82], [83, 92], [93, 95], [96, 106], [107, 110], [111, 122], [123, 132], [133, 134], [134, 138], [138, 139], [139, 140], [141, 144], [145, 158], [159, 170], [171, 174], [175, 182], [183, 194], [195, 196], [196, 200], [200, 201], [201, 202], [203, 206], [207, 218], [219, 222], [223, 226], [227, 238], [239, 241], [242, 252], [253, 265], [266, 267], [267, 271], [271, 272], [272, 273], [274, 277], [278, 286], [287, 298], [299, 302], [303, 314], [315, 317], [318, 325], [326, 327], [327, 331], [331, 332], [333, 336], [337, 340], [341, 348], [349, 352], [353, 359], [360, 363], [364, 373], [374, 384], [385, 386], [386, 390], [390, 391], [391, 392]]}
{"doc_key": "ai-dev-317", "ner": [[0, 1, "field"], [3, 4, "field"], [16, 17, "field"], [32, 33, "field"], [49, 57, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 17, "named", "", false, false], [3, 4, 32, 33, "named", "", false, false], [32, 33, 49, 57, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "and", "data", "mining", "often", "use", "the", "same", "methods", "and", "overlap", "significantly", ",", "but", "while", "machine", "learning", "focuses", "on", "prediction", ",", "based", "on", "known", "properties", "learned", "from", "the", "training", "data", ",", "data", "mining", "focuses", "on", "discovering", "(", "previously", ")", "unknown", "properties", "in", "the", "data", "(", "this", "is", "the", "knowledge", "discovery", "analysis", "stage", "of", "knowledge", "discovery", "in", "databases", ")", "."], "sentence-detokenized": "Machine learning and data mining often use the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on discovering (previously) unknown properties in the data (this is the knowledge discovery analysis stage of knowledge discovery in databases).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 59], [60, 63], [64, 71], [72, 85], [85, 86], [87, 90], [91, 96], [97, 104], [105, 113], [114, 121], [122, 124], [125, 135], [135, 136], [137, 142], [143, 145], [146, 151], [152, 162], [163, 170], [171, 175], [176, 179], [180, 188], [189, 193], [193, 194], [195, 199], [200, 206], [207, 214], [215, 217], [218, 229], [230, 231], [231, 241], [241, 242], [243, 250], [251, 261], [262, 264], [265, 268], [269, 273], [274, 275], [275, 279], [280, 282], [283, 286], [287, 296], [297, 306], [307, 315], [316, 321], [322, 324], [325, 334], [335, 344], [345, 347], [348, 357], [357, 358], [358, 359]]}
{"doc_key": "ai-dev-318", "ner": [[0, 1, "product"], [4, 4, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 4, 4, "general-affiliation", "", false, false], [0, 1, 4, 4, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "is", "written", "in", "Java", "and", "therefore", "runs", "on", "most", "modern", "operating", "systems", "."], "sentence-detokenized": "Indy is written in Java and therefore runs on most modern operating systems.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 23], [24, 27], [28, 37], [38, 42], [43, 45], [46, 50], [51, 57], [58, 67], [68, 75], [75, 76]]}
{"doc_key": "ai-dev-319", "ner": [[0, 0, "algorithm"], [5, 9, "algorithm"], [15, 17, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [3], "sentence": ["NMF", "is", "a", "case", "of", "non-negative", "quadratic", "programming", "(", "NQP", ")", ",", "just", "like", "the", "support", "vector", "machine", "(", "SVM", ")", "."], "sentence-detokenized": "NMF is a case of non-negative quadratic programming (NQP), just like the support vector machine (SVM).", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 13], [14, 16], [17, 29], [30, 39], [40, 51], [52, 53], [53, 56], [56, 57], [57, 58], [59, 63], [64, 68], [69, 72], [73, 80], [81, 87], [88, 95], [96, 97], [97, 100], [100, 101], [101, 102]]}
{"doc_key": "ai-dev-320", "ner": [[8, 9, "misc"], [12, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 12, 14, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "method", "is", "based", "on", "the", "estimation", "of", "conditional", "probabilities", "by", "the", "non-parametric", "maximum", "likelihood", "method", ",", "which", "leads", "to"], "sentence-detokenized": "The method is based on the estimation of conditional probabilities by the non-parametric maximum likelihood method, which leads to", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 26], [27, 37], [38, 40], [41, 52], [53, 66], [67, 69], [70, 73], [74, 88], [89, 96], [97, 107], [108, 114], [114, 115], [116, 121], [122, 127], [128, 130]]}
{"doc_key": "ai-dev-321", "ner": [[8, 8, "algorithm"], [10, 12, "algorithm"], [14, 16, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "key", "concepts", "involved", "in", "spectral", "estimation", "include", "autocorrelation", ",", "multivariate", "Fourier", "transform", ",", "mean", "square", "error", "and", "entropy", "."], "sentence-detokenized": "The key concepts involved in spectral estimation include autocorrelation, multivariate Fourier transform, mean square error and entropy.", "token2charspan": [[0, 3], [4, 7], [8, 16], [17, 25], [26, 28], [29, 37], [38, 48], [49, 56], [57, 72], [72, 73], [74, 86], [87, 94], [95, 104], [104, 105], [106, 110], [111, 117], [118, 123], [124, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-dev-322", "ner": [[4, 5, "algorithm"], [10, 10, "field"], [12, 12, "algorithm"], [14, 16, "algorithm"], [18, 19, "task"], [21, 21, "field"], [23, 23, "field"], [25, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[4, 5, 10, 10, "part-of", "", false, false], [4, 5, 12, 12, "part-of", "", false, false], [4, 5, 14, 16, "part-of", "", false, false], [4, 5, 18, 19, "part-of", "", false, false], [4, 5, 21, 21, "part-of", "", false, false], [4, 5, 23, 23, "part-of", "", false, false], [4, 5, 25, 26, "part-of", "", false, false], [4, 5, 28, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "application", "areas", "of", "kernel", "methods", "are", "diverse", "and", "include", "geostatistics", ",", "kriging", ",", "inverse", "distance", "weighting", ",", "3D", "reconstruction", ",", "bioinformatics", ",", "chemoinformatics", ",", "information", "extraction", "and", "handwriting", "recognition", "."], "sentence-detokenized": "The application areas of kernel methods are diverse and include geostatistics, kriging, inverse distance weighting, 3D reconstruction, bioinformatics, chemoinformatics, information extraction and handwriting recognition.", "token2charspan": [[0, 3], [4, 15], [16, 21], [22, 24], [25, 31], [32, 39], [40, 43], [44, 51], [52, 55], [56, 63], [64, 77], [77, 78], [79, 86], [86, 87], [88, 95], [96, 104], [105, 114], [114, 115], [116, 118], [119, 133], [133, 134], [135, 149], [149, 150], [151, 167], [167, 168], [169, 180], [181, 191], [192, 195], [196, 207], [208, 219], [219, 220]]}
{"doc_key": "ai-dev-323", "ner": [[13, 13, "organisation"], [16, 19, "product"], [15, 21, "product"], [26, 26, "organisation"], [27, 30, "product"], [32, 32, "product"], [35, 36, "product"], [38, 40, "product"], [42, 44, "product"], [46, 48, "product"], [52, 53, "product"], [55, 56, "product"], [59, 65, "product"], [69, 70, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[16, 19, 13, 13, "artifact", "", false, false], [16, 19, 35, 36, "compare", "", false, false], [16, 19, 38, 40, "compare", "", false, false], [16, 19, 42, 44, "compare", "", false, false], [16, 19, 46, 48, "compare", "", false, false], [16, 19, 52, 53, "compare", "", false, false], [16, 19, 55, 56, "compare", "", false, false], [16, 19, 59, 65, "compare", "", false, false], [16, 19, 69, 70, "compare", "", false, false], [15, 21, 16, 19, "named", "", false, false], [27, 30, 26, 26, "artifact", "", false, false], [27, 30, 35, 36, "compare", "", false, false], [27, 30, 38, 40, "compare", "", false, false], [27, 30, 42, 44, "compare", "", false, false], [27, 30, 46, 48, "compare", "", false, false], [27, 30, 52, 53, "compare", "", false, false], [27, 30, 55, 56, "compare", "", false, false], [27, 30, 59, 65, "compare", "", false, false], [27, 30, 69, 70, "compare", "", false, false], [32, 32, 27, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Robots", "can", "be", "autonomous", "or", "semi-autonomous", "and", "range", "from", "humanoid", "robots", "such", "as", "Honda", "'s", "Advanced", "Step", "in", "Innovative", "Mobility", "(", "ASIMO", ")", "and", "TOSY", "'s", "TOSY", "Ping", "Pong", "Playing", "Robot", "(", "TOPIO", ")", "to", "industrial", "robots", ",", "medical", "surgical", "robots", ",", "patient", "assistance", "robots", ",", "dog", "therapy", "robots", ",", "collectively", "programmed", "swarm", "robots", ",", "UAV", "drones", "such", "as", "General", "Atomics", "'", "MQ", "-", "1", "Predator", ",", "and", "even", "tiny", "nanobots", "."], "sentence-detokenized": "Robots can be autonomous or semi-autonomous and range from humanoid robots such as Honda's Advanced Step in Innovative Mobility (ASIMO) and TOSY's TOSY Ping Pong Playing Robot (TOPIO) to industrial robots, medical surgical robots, patient assistance robots, dog therapy robots, collectively programmed swarm robots, UAV drones such as General Atomics' MQ-1 Predator, and even tiny nanobots.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 24], [25, 27], [28, 43], [44, 47], [48, 53], [54, 58], [59, 67], [68, 74], [75, 79], [80, 82], [83, 88], [88, 90], [91, 99], [100, 104], [105, 107], [108, 118], [119, 127], [128, 129], [129, 134], [134, 135], [136, 139], [140, 144], [144, 146], [147, 151], [152, 156], [157, 161], [162, 169], [170, 175], [176, 177], [177, 182], [182, 183], [184, 186], [187, 197], [198, 204], [204, 205], [206, 213], [214, 222], [223, 229], [229, 230], [231, 238], [239, 249], [250, 256], [256, 257], [258, 261], [262, 269], [270, 276], [276, 277], [278, 290], [291, 301], [302, 307], [308, 314], [314, 315], [316, 319], [320, 326], [327, 331], [332, 334], [335, 342], [343, 350], [350, 351], [352, 354], [354, 355], [355, 356], [357, 365], [365, 366], [367, 370], [371, 375], [376, 380], [381, 389], [389, 390]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 3, "product"], [9, 15, "university"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 17, 18, "artifact", "", false, false], [0, 0, 20, 21, "artifact", "", false, false], [0, 0, 23, 24, "artifact", "", false, false], [0, 0, 26, 27, "artifact", "", false, false], [2, 3, 17, 18, "artifact", "", false, false], [2, 3, 20, 21, "artifact", "", false, false], [2, 3, 23, 24, "artifact", "", false, false], [2, 3, 26, 27, "artifact", "", false, false], [17, 18, 9, 15, "physical", "", false, false], [20, 21, 9, 15, "physical", "", false, false], [23, 24, 9, 15, "physical", "", false, false], [26, 27, 9, 15, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "and", "Freddy", "II", "were", "robots", "built", "at", "the", "University", "of", "Edinburgh", "'s", "School", "of", "Computing", "by", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "and", "Donald", "Mitchie", "and", "were", "capable", "of", "assembling", "wooden", "blocks", "in", "a", "matter", "of", "hours", "."], "sentence-detokenized": "Freddy and Freddy II were robots built at the University of Edinburgh's School of Computing by Pat Ambler, Robin Popplestone, Austin Tate and Donald Mitchie and were capable of assembling wooden blocks in a matter of hours.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 25], [26, 32], [33, 38], [39, 41], [42, 45], [46, 56], [57, 59], [60, 69], [69, 71], [72, 78], [79, 81], [82, 91], [92, 94], [95, 98], [99, 105], [105, 106], [107, 112], [113, 124], [124, 125], [126, 132], [133, 137], [138, 141], [142, 148], [149, 156], [157, 160], [161, 165], [166, 173], [174, 176], [177, 187], [188, 194], [195, 201], [202, 204], [205, 206], [207, 213], [214, 216], [217, 222], [222, 223]]}
{"doc_key": "ai-dev-325", "ner": [[5, 5, "location"], [7, 7, "country"], [15, 15, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 7, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "spent", "his", "childhood", "in", "Paris", ",", "France", ",", "where", "his", "parents", "had", "emigrated", "from", "Lithuania", "in", "the", "early", "1920s", "."], "sentence-detokenized": "He spent his childhood in Paris, France, where his parents had emigrated from Lithuania in the early 1920s.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 22], [23, 25], [26, 31], [31, 32], [33, 39], [39, 40], [41, 46], [47, 50], [51, 58], [59, 62], [63, 72], [73, 77], [78, 87], [88, 90], [91, 94], [95, 100], [101, 106], [106, 107]]}
{"doc_key": "ai-dev-326", "ner": [[2, 3, "researcher"], [6, 10, "misc"], [15, 18, "organisation"], [11, 13, "university"], [27, 34, "university"], [40, 41, "university"], [44, 47, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 3, 6, 10, "role", "", false, false], [2, 3, 11, 13, "physical", "", false, false], [2, 3, 27, 34, "role", "", false, false], [2, 3, 40, 41, "role", "", false, false], [2, 3, 44, 47, "role", "", false, false], [6, 10, 15, 18, "part-of", "", false, false], [15, 18, 11, 13, "part-of", "", false, false], [40, 41, 27, 34, "part-of", "", false, false], [44, 47, 27, 34, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Previously", ",", "Dr.", "Paul", "held", "the", "Cooper-", "Siegel", "Associate", "Professorship", "at", "Carnegie", "Mellon", "University", "'s", "School", "of", "Computer", "Science", ",", "where", "he", "was", "a", "professor", "at", "the", "Institute", "for", "Human", "-", "Computer", "Interaction", ",", "while", "also", "holding", "appointments", "at", "the", "Robotics", "Institute", "and", "the", "Center", "for", "Entertainment", "Technology", "."], "sentence-detokenized": "Previously, Dr. Paul held the Cooper-Siegel Associate Professorship at Carnegie Mellon University's School of Computer Science, where he was a professor at the Institute for Human-Computer Interaction, while also holding appointments at the Robotics Institute and the Center for Entertainment Technology.", "token2charspan": [[0, 10], [10, 11], [12, 15], [16, 20], [21, 25], [26, 29], [30, 37], [37, 43], [44, 53], [54, 67], [68, 70], [71, 79], [80, 86], [87, 97], [97, 99], [100, 106], [107, 109], [110, 118], [119, 126], [126, 127], [128, 133], [134, 136], [137, 140], [141, 142], [143, 152], [153, 155], [156, 159], [160, 169], [170, 173], [174, 179], [179, 180], [180, 188], [189, 200], [200, 201], [202, 207], [208, 212], [213, 220], [221, 233], [234, 236], [237, 240], [241, 249], [250, 259], [260, 263], [264, 267], [268, 274], [275, 278], [279, 292], [293, 303], [303, 304]]}
{"doc_key": "ai-dev-327", "ner": [[2, 3, "researcher"], [5, 6, "university"], [9, 10, "product"], [17, 21, "product"], [26, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 5, 6, "physical", "", false, false], [2, 3, 5, 6, "role", "", false, false], [9, 10, 2, 3, "artifact", "", false, false], [9, 10, 17, 21, "type-of", "", false, false], [9, 10, 26, 29, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1969", "Victor", "Scheinman", "at", "Stanford", "University", "invented", "the", "Stanford", "Arm", ",", "an", "all", "-", "electric", ",", "6", "-", "axis", "articulated", "robot", "designed", "to", "enable", "the", "solution", "of", "an", "arm", "."], "sentence-detokenized": "In 1969 Victor Scheinman at Stanford University invented the Stanford Arm, an all-electric, 6-axis articulated robot designed to enable the solution of an arm.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 24], [25, 27], [28, 36], [37, 47], [48, 56], [57, 60], [61, 69], [70, 73], [73, 74], [75, 77], [78, 81], [81, 82], [82, 90], [90, 91], [92, 93], [93, 94], [94, 98], [99, 110], [111, 116], [117, 125], [126, 128], [129, 135], [136, 139], [140, 148], [149, 151], [152, 154], [155, 158], [158, 159]]}
{"doc_key": "ai-dev-328", "ner": [[5, 5, "product"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 15, 16, "related-to", "", false, false], [5, 5, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "creation", "and", "implementation", "of", "chatbots", "is", "still", "a", "growing", "field", ",", "largely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ",", "so", "the", "solutions", "provided", ",", "while", "having", "obvious", "advantages", ",", "have", "some", "important", "limitations", "in", "terms", "of", "functionality", "and", "use", "cases", "."], "sentence-detokenized": "The creation and implementation of chatbots is still a growing field, largely related to artificial intelligence and machine learning, so the solutions provided, while having obvious advantages, have some important limitations in terms of functionality and use cases.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 31], [32, 34], [35, 43], [44, 46], [47, 52], [53, 54], [55, 62], [63, 68], [68, 69], [70, 77], [78, 85], [86, 88], [89, 99], [100, 112], [113, 116], [117, 124], [125, 133], [133, 134], [135, 137], [138, 141], [142, 151], [152, 160], [160, 161], [162, 167], [168, 174], [175, 182], [183, 193], [193, 194], [195, 199], [200, 204], [205, 214], [215, 226], [227, 229], [230, 235], [236, 238], [239, 252], [253, 256], [257, 260], [261, 266], [266, 267]]}
{"doc_key": "ai-dev-329", "ner": [[7, 9, "university"], [10, 12, "product"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 12, 7, 9, "part-of", "", true, false], [20, 21, 10, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "terms", "of", "freely", "available", "resources", ",", "Carnegie", "Mellon", "University", "'s", "Sphinx", "toolkit", "is", "a", "place", "to", "start", "learning", "about", "speech", "recognition", "and", "begin", "experimenting", "."], "sentence-detokenized": "In terms of freely available resources, Carnegie Mellon University's Sphinx toolkit is a place to start learning about speech recognition and begin experimenting.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 18], [19, 28], [29, 38], [38, 39], [40, 48], [49, 55], [56, 66], [66, 68], [69, 75], [76, 83], [84, 86], [87, 88], [89, 94], [95, 97], [98, 103], [104, 112], [113, 118], [119, 125], [126, 137], [138, 141], [142, 147], [148, 161], [161, 162]]}
{"doc_key": "ai-dev-330", "ner": [[2, 4, "misc"], [13, 22, "misc"], [14, 19, "misc"], [25, 25, "university"], [27, 27, "location"], [29, 30, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 4, 13, 22, "temporal", "", false, false], [14, 19, 13, 22, "named", "", false, false], [14, 19, 27, 27, "physical", "", false, false], [25, 25, 14, 19, "role", "", false, false], [27, 27, 29, 30, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "official", "RoboCup", "competition", "was", "preceded", "by", "the", "(", "often", "unrecognised", ")", "first", "international", "Micro", "Robot", "World", "Cup", "(", "MIROSOT", ")", "football", "tournament", "organised", "by", "KAIST", "in", "Taejon", ",", "Korea", "in", "November", "1996", "."], "sentence-detokenized": "The official RoboCup competition was preceded by the (often unrecognised) first international Micro Robot World Cup (MIROSOT) football tournament organised by KAIST in Taejon, Korea in November 1996.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 32], [33, 36], [37, 45], [46, 48], [49, 52], [53, 54], [54, 59], [60, 72], [72, 73], [74, 79], [80, 93], [94, 99], [100, 105], [106, 111], [112, 115], [116, 117], [117, 124], [124, 125], [126, 134], [135, 145], [146, 155], [156, 158], [159, 164], [165, 167], [168, 174], [174, 175], [176, 181], [182, 184], [185, 193], [194, 198], [198, 199]]}
{"doc_key": "ai-dev-331", "ner": [[5, 7, "metrics"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "standard", "loss", "math", "articulation", "(", "1-", "yf", "(", "x", ")", ")", "_", "+", "/", "math", "for", "labeled", "data", ",", "a", "loss", "function", "math", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "math", "is", "introduced", "for", "unlabeled", "data", "leaving", "mathy", "=\\", "operatorname", "{", "sign", "}", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "In addition to the standard loss math articulation (1-yf(x)) _ + / math for labeled data, a loss function math (-1 | f(x) |) _ + / math is introduced for unlabeled data leaving mathy =\\ operatorname {sign} {f (x)} / math.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 27], [28, 32], [33, 37], [38, 50], [51, 52], [52, 54], [54, 56], [56, 57], [57, 58], [58, 59], [59, 60], [61, 62], [63, 64], [65, 66], [67, 71], [72, 75], [76, 83], [84, 88], [88, 89], [90, 91], [92, 96], [97, 105], [106, 110], [111, 112], [112, 113], [113, 114], [115, 116], [117, 118], [118, 119], [119, 120], [120, 121], [122, 123], [123, 124], [125, 126], [127, 128], [129, 130], [131, 135], [136, 138], [139, 149], [150, 153], [154, 163], [164, 168], [169, 176], [177, 182], [183, 185], [186, 198], [199, 200], [200, 204], [204, 205], [206, 207], [207, 208], [209, 210], [210, 211], [211, 212], [212, 213], [214, 215], [216, 220], [220, 221]]}
{"doc_key": "ai-dev-332", "ner": [[2, 3, "misc"], [8, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Specifically", ",", "RLS", "is", "designed", "to", "minimize", "the", "mean", "square", "error", "between", "predicted", "values", "and", "TRUE", "labels", ",", "subject", "to", "normalization", "."], "sentence-detokenized": "Specifically, RLS is designed to minimize the mean square error between predicted values and TRUE labels, subject to normalization.", "token2charspan": [[0, 12], [12, 13], [14, 17], [18, 20], [21, 29], [30, 32], [33, 41], [42, 45], [46, 50], [51, 57], [58, 63], [64, 71], [72, 81], [82, 88], [89, 92], [93, 97], [98, 104], [104, 105], [106, 113], [114, 116], [117, 130], [130, 131]]}
{"doc_key": "ai-dev-333", "ner": [[4, 6, "algorithm"], [9, 10, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Essentially", ",", "this", "combines", "maximum", "likelihood", "estimation", "with", "a", "normalization", "procedure", "that", "favors", "simpler", "models", "over", "more", "complex", "models", "."], "sentence-detokenized": "Essentially, this combines maximum likelihood estimation with a normalization procedure that favors simpler models over more complex models.", "token2charspan": [[0, 11], [11, 12], [13, 17], [18, 26], [27, 34], [35, 45], [46, 56], [57, 61], [62, 63], [64, 77], [78, 87], [88, 92], [93, 99], [100, 107], [108, 114], [115, 119], [120, 124], [125, 132], [133, 139], [139, 140]]}
{"doc_key": "ai-dev-334", "ner": [[1, 3, "metrics"], [9, 9, "metrics"], [11, 11, "metrics"], [13, 15, "misc"], [19, 20, "misc"], [33, 36, "algorithm"], [38, 43, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 9, 1, 3, "named", "", false, false], [11, 11, 1, 3, "named", "", false, false], [13, 15, 19, 20, "related-to", "", false, false], [13, 15, 33, 36, "related-to", "ratio", false, false], [33, 36, 38, 43, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "true", "positive", "rate", "is", "also", "known", "as", "the", "sensitivity", ",", "recall", "or", "probability", "of", "detection", "mathematically", "at", "the", "discrimination", "threshold", ")", "of", "the", "probability", "of", "detection", "on", "the", "y", "-axis", "versus", "the", "cumulative", "distribution", "function", "of", "the", "probability", "of", "false", "alarm", "on", "the", "x-", "axis", "."], "sentence-detokenized": "The true positive rate is also known as the sensitivity, recall or probability of detection mathematically at the discrimination threshold) of the probability of detection on the y-axis versus the cumulative distribution function of the probability of false alarm on the x-axis.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 25], [26, 30], [31, 36], [37, 39], [40, 43], [44, 55], [55, 56], [57, 63], [64, 66], [67, 78], [79, 81], [82, 91], [92, 106], [107, 109], [110, 113], [114, 128], [129, 138], [138, 139], [140, 142], [143, 146], [147, 158], [159, 161], [162, 171], [172, 174], [175, 178], [179, 180], [180, 185], [186, 192], [193, 196], [197, 207], [208, 220], [221, 229], [230, 232], [233, 236], [237, 248], [249, 251], [252, 257], [258, 263], [264, 266], [267, 270], [271, 273], [273, 277], [277, 278]]}
{"doc_key": "ai-dev-335", "ner": [[1, 1, "misc"], [3, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 1, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "English", ",", "Word", "Net", "is", "an", "example", "of", "a", "semantic", "network", "."], "sentence-detokenized": "In English, WordNet is an example of a semantic network.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [16, 19], [20, 22], [23, 25], [26, 33], [34, 36], [37, 38], [39, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-dev-336", "ner": [[3, 6, "product"], [9, 10, "product"], [23, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 3, 6, "usage", "", false, false], [23, 24, 9, 10, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolonged", "use", "of", "speech", "recognition", "software", "in", "combination", "with", "word", "processors", "has", "shown", "benefits", "for", "enhancing", "short", "-", "term", "memory", "in", "patients", "with", "AVM", "brain", "ablation", "."], "sentence-detokenized": "Prolonged use of speech recognition software in combination with word processors has shown benefits for enhancing short-term memory in patients with AVM brain ablation.", "token2charspan": [[0, 9], [10, 13], [14, 16], [17, 23], [24, 35], [36, 44], [45, 47], [48, 59], [60, 64], [65, 69], [70, 80], [81, 84], [85, 90], [91, 99], [100, 103], [104, 113], [114, 119], [119, 120], [120, 124], [125, 131], [132, 134], [135, 143], [144, 148], [149, 152], [153, 158], [159, 167], [167, 168]]}
{"doc_key": "ai-dev-337", "ner": [[8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Its", "founding", "editors", "-", "in", "-", "chief", "were", "Ron", "Sun", ",", "Vasant", "Honavar", "and", "Gregg", "Oden", "(", "from", "1999", "to", "2014", ")", "."], "sentence-detokenized": "Its founding editors-in-chief were Ron Sun, Vasant Honavar and Gregg Oden (from 1999 to 2014).", "token2charspan": [[0, 3], [4, 12], [13, 20], [20, 21], [21, 23], [23, 24], [24, 29], [30, 34], [35, 38], [39, 42], [42, 43], [44, 50], [51, 58], [59, 62], [63, 68], [69, 73], [74, 75], [75, 79], [80, 84], [85, 87], [88, 92], [92, 93], [93, 94]]}
{"doc_key": "ai-dev-338", "ner": [[7, 8, "product"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 13, 14, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Their", "'", "parallel", "'", "distinction", ",", "unlike", "serial", "operators", ",", "is", "that", "the", "final", "actuator", "(", "or", "'", "hand", "'", ")", "of", "this", "link", "(", "or", "'", "arm", "'", ")", "is", "directly", "connected", "to", "it", "s", "base", "by", "a", "number", "(", "usually", "three", "or", "six", ")", "of", "separate", "and", "independent", "links", "operating", "simultaneously", "."], "sentence-detokenized": "Their 'parallel' distinction, unlike serial operators, is that the final actuator (or 'hand') of this link (or 'arm') is directly connected to its base by a number (usually three or six) of separate and independent links operating simultaneously.", "token2charspan": [[0, 5], [6, 7], [7, 15], [15, 16], [17, 28], [28, 29], [30, 36], [37, 43], [44, 53], [53, 54], [55, 57], [58, 62], [63, 66], [67, 72], [73, 81], [82, 83], [83, 85], [86, 87], [87, 91], [91, 92], [92, 93], [94, 96], [97, 101], [102, 106], [107, 108], [108, 110], [111, 112], [112, 115], [115, 116], [116, 117], [118, 120], [121, 129], [130, 139], [140, 142], [143, 145], [145, 146], [147, 151], [152, 154], [155, 156], [157, 163], [164, 165], [165, 172], [173, 178], [179, 181], [182, 185], [185, 186], [187, 189], [190, 198], [199, 202], [203, 214], [215, 220], [221, 230], [231, 245], [245, 246]]}
{"doc_key": "ai-dev-339", "ner": [[5, 6, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"], [28, 33, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "thesis", "advisor", "was", "Professor", "Cordell", "Green", ",", "and", "his", "thesis", "/", "proposal", "committee", "included", "Professors", "Edward", "Feigenbaum", ",", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", ",", "Herbert", "Simon", ",", "and", "Herbert", "Simon", "."], "sentence-detokenized": "His thesis advisor was Professor Cordell Green, and his thesis/proposal committee included Professors Edward Feigenbaum, Joshua Lederberg, Paul Cohen, Allen Newell, Herbert Simon, and Herbert Simon.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 22], [23, 32], [33, 40], [41, 46], [46, 47], [48, 51], [52, 55], [56, 62], [62, 63], [63, 71], [72, 81], [82, 90], [91, 101], [102, 108], [109, 119], [119, 120], [121, 127], [128, 137], [137, 138], [139, 143], [144, 149], [149, 150], [151, 156], [157, 163], [163, 164], [165, 172], [173, 178], [178, 179], [180, 183], [184, 191], [192, 197], [197, 198]]}
{"doc_key": "ai-dev-340", "ner": [[4, 6, "metrics"], [9, 14, "metrics"], [17, 19, "metrics"], [22, 24, "metrics"], [27, 32, "metrics"], [35, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "functions", "include", "the", "mean", "square", "error", ",", "the", "root", "of", "the", "mean", "square", "error", ",", "the", "mean", "absolute", "error", ",", "the", "relative", "square", "error", ",", "the", "root", "of", "the", "relative", "square", "error", ",", "the", "relative", "absolute", "error", "and", "others", "."], "sentence-detokenized": "Such functions include the mean square error, the root of the mean square error, the mean absolute error, the relative square error, the root of the relative square error, the relative absolute error and others.", "token2charspan": [[0, 4], [5, 14], [15, 22], [23, 26], [27, 31], [32, 38], [39, 44], [44, 45], [46, 49], [50, 54], [55, 57], [58, 61], [62, 66], [67, 73], [74, 79], [79, 80], [81, 84], [85, 89], [90, 98], [99, 104], [104, 105], [106, 109], [110, 118], [119, 125], [126, 131], [131, 132], [133, 136], [137, 141], [142, 144], [145, 148], [149, 157], [158, 164], [165, 170], [170, 171], [172, 175], [176, 184], [185, 193], [194, 199], [200, 203], [204, 210], [210, 211]]}
{"doc_key": "ai-dev-341", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "bindings", "in", "Python", ",", "Java", "and", "MATLAB", "/", "OCTAVE", "."], "sentence-detokenized": "There are bindings in Python, Java and MATLAB / OCTAVE.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 21], [22, 28], [28, 29], [30, 34], [35, 38], [39, 45], [46, 47], [48, 54], [54, 55]]}
{"doc_key": "ai-dev-342", "ner": [[3, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "application", "in", "MATLAB", "can", "be", "found", "on", "the", "website", "."], "sentence-detokenized": "An application in MATLAB can be found on the website.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 24], [25, 28], [29, 31], [32, 37], [38, 40], [41, 44], [45, 52], [52, 53]]}
{"doc_key": "ai-dev-343", "ner": [[0, 1, "researcher"], [8, 9, "field"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 1, "origin", "", false, false], [8, 9, 13, 14, "origin", "", false, false], [8, 9, 16, 17, "origin", "", false, false], [8, 9, 19, 20, "origin", "", false, false], [8, 9, 22, 25, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "is", "one", "of", "the", "founders", "of", "artificial", "intelligence", ",", "along", "with", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", "and", "Herbert", "A", ".", "Simon", "."], "sentence-detokenized": "John McCarthy is one of the founders of artificial intelligence, along with Alan Turing, Marvin Minsky, Allen Newell and Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 36], [37, 39], [40, 50], [51, 63], [63, 64], [65, 70], [71, 75], [76, 80], [81, 87], [87, 88], [89, 95], [96, 102], [102, 103], [104, 109], [110, 116], [117, 120], [121, 128], [129, 130], [130, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-dev-344", "ner": [[10, 11, "product"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "parallel", "operator", "is", "a", "mechanical", "system", "that", "uses", "multiple", "serial", "operators", "to", "support", "a", "single", "platform", "or", "end", "carrier", "."], "sentence-detokenized": "A parallel operator is a mechanical system that uses multiple serial operators to support a single platform or end carrier.", "token2charspan": [[0, 1], [2, 10], [11, 19], [20, 22], [23, 24], [25, 35], [36, 42], [43, 47], [48, 52], [53, 61], [62, 68], [69, 78], [79, 81], [82, 89], [90, 91], [92, 98], [99, 107], [108, 110], [111, 114], [115, 122], [122, 123]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [3, 4, "task"], [7, 7, "product"], [9, 15, "product"], [27, 27, "misc"], [30, 30, "misc"], [33, 34, "misc"], [37, 42, "task"], [45, 48, "product"], [52, 53, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 7, 0, 0, "part-of", "", false, false], [7, 7, 3, 4, "type-of", "", false, false], [9, 15, 7, 7, "named", "", false, false], [27, 27, 7, 7, "part-of", "", false, false], [30, 30, 7, 7, "part-of", "", false, false], [33, 34, 7, 7, "part-of", "", false, false], [37, 42, 7, 7, "part-of", "", false, false], [45, 48, 7, 7, "part-of", "", false, false], [52, 53, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "includes", "an", "information", "extraction", "system", "called", "ANNIE", "(", "A", "Nearly", "-", "New", "Information", "Extraction", "System", ")", ",", "which", "is", "a", "set", "of", "modules", "that", "includes", "a", "tokenizer", ",", "a", "gazetteer", ",", "a", "sentence", "separator", ",", "a", "part", "-", "of", "-", "speech", "tagger", ",", "a", "named", "entity", "recognition", "transducer", ",", "and", "a", "kernel", "tagger", "."], "sentence-detokenized": "GATE includes an information extraction system called ANNIE (A Nearly-New Information Extraction System), which is a set of modules that includes a tokenizer, a gazetteer, a sentence separator, a part-of-speech tagger, a named entity recognition transducer, and a kernel tagger.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 28], [29, 39], [40, 46], [47, 53], [54, 59], [60, 61], [61, 62], [63, 69], [69, 70], [70, 73], [74, 85], [86, 96], [97, 103], [103, 104], [104, 105], [106, 111], [112, 114], [115, 116], [117, 120], [121, 123], [124, 131], [132, 136], [137, 145], [146, 147], [148, 157], [157, 158], [159, 160], [161, 170], [170, 171], [172, 173], [174, 182], [183, 192], [192, 193], [194, 195], [196, 200], [200, 201], [201, 203], [203, 204], [204, 210], [211, 217], [217, 218], [219, 220], [221, 226], [227, 233], [234, 245], [246, 256], [256, 257], [258, 261], [262, 263], [264, 270], [271, 277], [277, 278]]}
{"doc_key": "ai-dev-346", "ner": [[3, 5, "university"], [13, 14, "country"], [21, 24, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "graduated", "from", "Moscow", "State", "University", "and", "in", "November", "1978", "left", "for", "the", "United", "States", "thanks", "to", "the", "personal", "intervention", "of", "Senator", "Edward", "M.", "Kennedy", "."], "sentence-detokenized": "He graduated from Moscow State University and in November 1978 left for the United States thanks to the personal intervention of Senator Edward M. Kennedy.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 24], [25, 30], [31, 41], [42, 45], [46, 48], [49, 57], [58, 62], [63, 67], [68, 71], [72, 75], [76, 82], [83, 89], [90, 96], [97, 99], [100, 103], [104, 112], [113, 125], [126, 128], [129, 136], [137, 143], [144, 146], [147, 154], [154, 155]]}
{"doc_key": "ai-dev-347", "ner": [[3, 6, "organisation"], [9, 13, "misc"], [18, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 6, 9, 13, "win-defeat", "", false, false], [9, 13, 18, 18, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "DeepMind", "'s", "AlphaGo", "team", "received", "the", "inaugural", "IJCAI", "Marvin", "Minsky", "Medal", "for", "Outstanding", "Achievement", "in", "AI", "."], "sentence-detokenized": "In 2017, DeepMind's AlphaGo team received the inaugural IJCAI Marvin Minsky Medal for Outstanding Achievement in AI.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 17], [17, 19], [20, 27], [28, 32], [33, 41], [42, 45], [46, 55], [56, 61], [62, 68], [69, 75], [76, 81], [82, 85], [86, 97], [98, 109], [110, 112], [113, 115], [115, 116]]}
{"doc_key": "ai-dev-348", "ner": [[4, 5, "misc"], [9, 9, "misc"], [21, 22, "misc"], [27, 27, "misc"], [33, 33, "misc"]], "ner_mapping_to_source": [0, 1, 3, 4, 5], "relations": [[4, 5, 9, 9, "related-to", "is_recorded_by", false, false], [9, 9, 21, 22, "physical", "", false, false], [9, 9, 33, 33, "physical", "", false, false]], "relations_mapping_to_source": [0, 3, 4], "sentence": ["Other", "ways", "in", "which", "anomalous", "propagation", "is", "recorded", "are", "tropospheric", "anomalies", "in", "the", "troposphere", ",", "meteor", "scattering", ",", "refraction", "in", "the", "ionized", "regions", "and", "layers", "of", "the", "ionosphere", ",", "and", "reflection", "from", "the", "ionosphere", "."], "sentence-detokenized": "Other ways in which anomalous propagation is recorded are tropospheric anomalies in the troposphere, meteor scattering, refraction in the ionized regions and layers of the ionosphere, and reflection from the ionosphere.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 19], [20, 29], [30, 41], [42, 44], [45, 53], [54, 57], [58, 70], [71, 80], [81, 83], [84, 87], [88, 99], [99, 100], [101, 107], [108, 118], [118, 119], [120, 130], [131, 133], [134, 137], [138, 145], [146, 153], [154, 157], [158, 164], [165, 167], [168, 171], [172, 182], [182, 183], [184, 187], [188, 198], [199, 203], [204, 207], [208, 218], [218, 219]]}
{"doc_key": "ai-dev-349", "ner": [[2, 2, "field"], [0, 4, "field"], [10, 10, "field"], [12, 13, "field"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 10, 10, "part-of", "", false, false], [2, 2, 12, 13, "part-of", "", false, false], [2, 2, 15, 16, "part-of", "", false, false], [2, 2, 18, 19, "part-of", "", false, false], [0, 4, 2, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Natural", "language", "processing", "(", "NLP", ")", "is", "a", "subfield", "of", "linguistics", ",", "computer", "science", ",", "computer", "engineering", "and", "artificial", "intelligence", "that", "deals", "with", "the", "interactions", "between", "computers", "and", "human", "(", "natural", ")", "languages", ",", "in", "particular", "how", "to", "program", "computers", "to", "process", "and", "analyse", "large", "amounts", "of", "natural", "language", "data", "."], "sentence-detokenized": "Natural language processing (NLP) is a subfield of linguistics, computer science, computer engineering and artificial intelligence that deals with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyse large amounts of natural language data.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [29, 32], [32, 33], [34, 36], [37, 38], [39, 47], [48, 50], [51, 62], [62, 63], [64, 72], [73, 80], [80, 81], [82, 90], [91, 102], [103, 106], [107, 117], [118, 130], [131, 135], [136, 141], [142, 146], [147, 150], [151, 163], [164, 171], [172, 181], [182, 185], [186, 191], [192, 193], [193, 200], [200, 201], [202, 211], [211, 212], [213, 215], [216, 226], [227, 230], [231, 233], [234, 241], [242, 251], [252, 254], [255, 262], [263, 266], [267, 274], [275, 280], [281, 288], [289, 291], [292, 299], [300, 308], [309, 313], [313, 314]]}
{"doc_key": "ai-dev-350", "ner": [[8, 9, "organisation"], [11, 12, "organisation"], [14, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "active", "youth", "-", "led", "climate", "groups", "include", "Extinction", "Rebellion", ",", "Sunrise", "Movement", ",", "SustainUS", ",", "SustainUS", ",", "and", "others", ",", "working", "both", "at", "the", "transnational", "and", "local", "level", "."], "sentence-detokenized": "Other active youth-led climate groups include Extinction Rebellion, Sunrise Movement, SustainUS, SustainUS, and others, working both at the transnational and local level.", "token2charspan": [[0, 5], [6, 12], [13, 18], [18, 19], [19, 22], [23, 30], [31, 37], [38, 45], [46, 56], [57, 66], [66, 67], [68, 75], [76, 84], [84, 85], [86, 95], [95, 96], [97, 106], [106, 107], [108, 111], [112, 118], [118, 119], [120, 127], [128, 132], [133, 135], [136, 139], [140, 153], [154, 157], [158, 163], [164, 169], [169, 170]]}
