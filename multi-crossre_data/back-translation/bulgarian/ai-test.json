{"doc_key": "ai-test-1", "ner": [[6, 8, "algorithm"], [10, 11, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "approaches", "for", "generative", "models", "include", "naive", "Bayes", "classifiers", ",", "Gaussian", "mixture", "models", ",", "variational", "autoencoders", ",", "and", "others", "."], "sentence-detokenized": "Typical approaches for generative models include naive Bayes classifiers, Gaussian mixture models, variational autoencoders, and others.", "token2charspan": [[0, 7], [8, 18], [19, 22], [23, 33], [34, 40], [41, 48], [49, 54], [55, 60], [61, 72], [72, 73], [74, 82], [83, 90], [91, 97], [97, 98], [99, 110], [111, 123], [123, 124], [125, 128], [129, 135], [135, 136]]}
{"doc_key": "ai-test-2", "ner": [[5, 5, "organisation"], [10, 11, "conference"], [14, 19, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 10, 11, "role", "", false, false], [14, 19, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Finally", ",", "every", "second", "year", "ELRA", "organises", "a", "major", "conference", ",", "LREC", "-", "the", "International", "Language", "Resources", "and", "Evaluation", "Conference", "."], "sentence-detokenized": "Finally, every second year ELRA organises a major conference, LREC - the International Language Resources and Evaluation Conference.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 21], [22, 26], [27, 31], [32, 41], [42, 43], [44, 49], [50, 60], [60, 61], [62, 66], [67, 68], [69, 72], [73, 86], [87, 95], [96, 105], [106, 109], [110, 120], [121, 131], [131, 132]]}
{"doc_key": "ai-test-3", "ner": [[7, 11, "algorithm"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "task", "is", "usually", "to", "obtain", "a", "maximum", "likelihood", "estimate", "of", "the", "HMM", "parameters", "given", "the", "output", "sequences", "."], "sentence-detokenized": "The task is usually to obtain a maximum likelihood estimate of the HMM parameters given the output sequences.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 22], [23, 29], [30, 31], [32, 39], [40, 50], [51, 59], [60, 62], [63, 66], [67, 70], [71, 81], [82, 87], [88, 91], [92, 98], [99, 108], [108, 109]]}
{"doc_key": "ai-test-4", "ner": [[1, 2, "algorithm"], [4, 6, "algorithm"], [9, 9, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 9, 9, "compare", "", false, false], [4, 6, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Unlike", "neural", "networks", "and", "support", "vector", "machines", ",", "the", "AdaBoost", "learning", "process", "selects", "only", "those", "features", "that", "are", "known", "to", "improve", "the", "predictive", "power", "of", "the", "model", ",", "reducing", "dimensionality", "and", "potentially", "improving", "runtime", ",", "as", "it", "does", "not", "need", "to", "compute", "non-essential", "features", "."], "sentence-detokenized": "Unlike neural networks and support vector machines, the AdaBoost learning process selects only those features that are known to improve the predictive power of the model, reducing dimensionality and potentially improving runtime, as it does not need to compute non-essential features.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 26], [27, 34], [35, 41], [42, 50], [50, 51], [52, 55], [56, 64], [65, 73], [74, 81], [82, 89], [90, 94], [95, 100], [101, 109], [110, 114], [115, 118], [119, 124], [125, 127], [128, 135], [136, 139], [140, 150], [151, 156], [157, 159], [160, 163], [164, 169], [169, 170], [171, 179], [180, 194], [195, 198], [199, 210], [211, 220], [221, 228], [228, 229], [230, 232], [233, 235], [236, 240], [241, 244], [245, 249], [250, 252], [253, 260], [261, 274], [275, 283], [283, 284]]}
{"doc_key": "ai-test-5", "ner": [[0, 0, "misc"], [11, 14, "misc"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 14, "part-of", "", false, false], [11, 14, 15, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponymy", "is", "one", "of", "the", "possible", "relationships", "between", "verbs", "in", "the", "semantic", "network", "of", "the", "Word", "Net", "database", "."], "sentence-detokenized": "Troponymy is one of the possible relationships between verbs in the semantic network of the WordNet database.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 19], [20, 23], [24, 32], [33, 46], [47, 54], [55, 60], [61, 63], [64, 67], [68, 76], [77, 84], [85, 87], [88, 91], [92, 96], [96, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-test-6", "ner": [[8, 9, "task"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "framework", "language", "is", "a", "technology", "used", "to", "represent", "knowledge", "in", "artificial", "intelligence", "."], "sentence-detokenized": "A framework language is a technology used to represent knowledge in artificial intelligence.", "token2charspan": [[0, 1], [2, 11], [12, 20], [21, 23], [24, 25], [26, 36], [37, 41], [42, 44], [45, 54], [55, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-7", "ner": [[0, 0, "metrics"], [5, 8, "metrics"], [12, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 5, 8, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "the", "bilingual", "score", "in", "the", "calculation", "of", "the", "brevity", "penalty", "because", "small", "differences", "in", "translation", "length", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from the bilingual score in the calculation of the brevity penalty because small differences in translation length do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 26], [27, 36], [37, 42], [43, 45], [46, 49], [50, 61], [62, 64], [65, 68], [69, 76], [77, 84], [85, 92], [93, 98], [99, 110], [111, 113], [114, 125], [126, 132], [133, 135], [136, 139], [140, 146], [147, 150], [151, 158], [159, 164], [165, 167], [168, 172], [172, 173]]}
{"doc_key": "ai-test-8", "ner": [[15, 17, "algorithm"], [19, 21, "algorithm"], [32, 35, "field"], [42, 43, "algorithm"], [45, 47, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 17, 32, 35, "usage", "", false, false], [19, 21, 32, 35, "usage", "", false, false], [42, 43, 32, 35, "type-of", "", false, false], [45, 47, 32, 35, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "model", "is", "initially", "tuned", "on", "a", "training", "dataset", ",", "The", "model", "(", "e.g.", ",", "a", "neural", "network", "or", "naive", "Bayes", "classifier", ")", "is", "trained", "on", "the", "training", "dataset", "using", "a", "supervised", "learning", "method", ",", "e.g.", ",", "using", "optimization", "methods", "such", "as", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The model is initially tuned on a training dataset, The model (e.g., a neural network or naive Bayes classifier) is trained on the training dataset using a supervised learning method, e.g., using optimization methods such as gradient descent or stochastic gradient descent.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 22], [23, 28], [29, 31], [32, 33], [34, 42], [43, 50], [50, 51], [52, 55], [56, 61], [62, 63], [63, 67], [67, 68], [69, 70], [71, 77], [78, 85], [86, 88], [89, 94], [95, 100], [101, 111], [111, 112], [113, 115], [116, 123], [124, 126], [127, 130], [131, 139], [140, 147], [148, 153], [154, 155], [156, 166], [167, 175], [176, 182], [182, 183], [184, 188], [188, 189], [190, 195], [196, 208], [209, 216], [217, 221], [222, 224], [225, 233], [234, 241], [242, 244], [245, 255], [256, 264], [265, 272], [272, 273]]}
{"doc_key": "ai-test-9", "ner": [[0, 2, "product"], [9, 9, "task"], [11, 11, "task"], [13, 15, "task"], [18, 19, "task"], [25, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 9, 0, 2, "usage", "", true, false], [11, 11, 0, 2, "usage", "", true, false], [13, 15, 0, 2, "usage", "", true, false], [18, 19, 0, 2, "usage", "", true, false], [25, 28, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Frame", "Net", "is", "used", "in", "applications", "such", "as", "question", "answering", ",", "paraphrasing", ",", "text", "correlation", "recognition", ",", "and", "information", "retrieval", ",", "either", "directly", "or", "through", "semantic", "role", "tagging", "tools", "."], "sentence-detokenized": "FrameNet is used in applications such as question answering, paraphrasing, text correlation recognition, and information retrieval, either directly or through semantic role tagging tools.", "token2charspan": [[0, 5], [5, 8], [9, 11], [12, 16], [17, 19], [20, 32], [33, 37], [38, 40], [41, 49], [50, 59], [59, 60], [61, 73], [73, 74], [75, 79], [80, 91], [92, 103], [103, 104], [105, 108], [109, 120], [121, 130], [130, 131], [132, 138], [139, 147], [148, 150], [151, 158], [159, 167], [168, 172], [173, 180], [181, 186], [186, 187]]}
{"doc_key": "ai-test-10", "ner": [[6, 9, "field"], [11, 11, "misc"], [14, 14, "product"], [17, 17, "misc"], [20, 20, "product"], [23, 24, "field"], [27, 27, "product"], [30, 34, "misc"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [42, 45, "misc"], [46, 47, "product"], [49, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[14, 14, 11, 11, "general-affiliation", "", false, false], [20, 20, 17, 17, "general-affiliation", "", false, false], [27, 27, 23, 24, "general-affiliation", "", false, false], [35, 35, 30, 34, "type-of", "", false, false], [37, 37, 30, 34, "type-of", "", false, false], [39, 39, 30, 34, "type-of", "", false, false], [46, 47, 42, 45, "general-affiliation", "", false, false], [49, 50, 42, 45, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["This", "includes", "programs", "such", "as", "data", "analysis", "and", "extraction", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "aggregated", "audit", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "e.g.", "Crystal", "Reports", "and", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "This includes programs such as data analysis and extraction tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), aggregated audit software (e.g. ACL, Arbutus, EAS), business intelligence (e.g. Crystal Reports and Business Objects), etc.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 27], [28, 30], [31, 35], [36, 44], [45, 48], [49, 59], [60, 65], [65, 66], [67, 79], [80, 81], [81, 85], [86, 91], [91, 92], [92, 93], [94, 103], [104, 105], [105, 109], [110, 116], [116, 117], [117, 118], [119, 130], [131, 139], [140, 141], [141, 145], [146, 149], [149, 150], [150, 151], [152, 162], [163, 168], [169, 177], [178, 179], [179, 183], [184, 187], [187, 188], [189, 196], [196, 197], [198, 201], [201, 202], [202, 203], [204, 212], [213, 225], [226, 227], [227, 231], [232, 239], [240, 247], [248, 251], [252, 260], [261, 268], [268, 269], [269, 270], [271, 274], [274, 275]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 8, "researcher"], [12, 12, "organisation"], [15, 15, "product"], [21, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 8, "origin", "", false, false], [5, 8, 12, 12, "role", "", false, false], [15, 15, 21, 22, "type-of", "", false, false], [21, 22, 5, 8, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", ",", "founded", "by", "Rodney", "Brooks", ",", "who", "previously", "worked", "at", "iRobot", ",", "introduced", "Baxter", "in", "September", "2012", "as", "an", "industrial", "robot", "designed", "to", "safely", "interact", "with", "neighboring", "human", "workers", "and", "programmable", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "Rethink Robotics, founded by Rodney Brooks, who previously worked at iRobot, introduced Baxter in September 2012 as an industrial robot designed to safely interact with neighboring human workers and programmable to perform simple tasks.", "token2charspan": [[0, 7], [8, 16], [16, 17], [18, 25], [26, 28], [29, 35], [36, 42], [42, 43], [44, 47], [48, 58], [59, 65], [66, 68], [69, 75], [75, 76], [77, 87], [88, 94], [95, 97], [98, 107], [108, 112], [113, 115], [116, 118], [119, 129], [130, 135], [136, 144], [145, 147], [148, 154], [155, 163], [164, 168], [169, 180], [181, 186], [187, 194], [195, 198], [199, 211], [212, 214], [215, 222], [223, 229], [230, 235], [235, 236]]}
{"doc_key": "ai-test-12", "ner": [[4, 6, "field"], [8, 9, "task"], [12, 12, "task"], [14, 17, "task"], [19, 21, "task"], [23, 24, "task"], [26, 27, "task"], [30, 34, "task"], [39, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 9, 4, 6, "part-of", "task_part_of_field", false, false], [12, 12, 4, 6, "part-of", "task_part_of_field", false, false], [14, 17, 4, 6, "part-of", "task_part_of_field", false, false], [19, 21, 4, 6, "part-of", "task_part_of_field", false, false], [23, 24, 4, 6, "part-of", "task_part_of_field", false, false], [26, 27, 4, 6, "part-of", "task_part_of_field", false, false], [30, 34, 4, 6, "part-of", "task_part_of_field", false, false], [39, 41, 4, 6, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Typical", "tasks", "for", "information", "extraction", "from", "text", "include", "text", "categorization", ",", "text", "clustering", ",", "concept", "/", "entity", "extraction", ",", "creating", "detailed", "taxonomies", ",", "sentiment", "analysis", ",", "document", "summarization", ",", "and", "entity", "relationship", "modeling", "(", "i.e.", ",", "learning", "relationships", "between", "named", "entity", "recognitions", ")", "."], "sentence-detokenized": "Typical tasks for information extraction from text include text categorization, text clustering, concept/entity extraction, creating detailed taxonomies, sentiment analysis, document summarization, and entity relationship modeling (i.e., learning relationships between named entity recognitions).", "token2charspan": [[0, 7], [8, 13], [14, 17], [18, 29], [30, 40], [41, 45], [46, 50], [51, 58], [59, 63], [64, 78], [78, 79], [80, 84], [85, 95], [95, 96], [97, 104], [104, 105], [105, 111], [112, 122], [122, 123], [124, 132], [133, 141], [142, 152], [152, 153], [154, 163], [164, 172], [172, 173], [174, 182], [183, 196], [196, 197], [198, 201], [202, 208], [209, 221], [222, 230], [231, 232], [232, 236], [236, 237], [238, 246], [247, 260], [261, 268], [269, 274], [275, 281], [282, 294], [294, 295], [295, 296]]}
{"doc_key": "ai-test-13", "ner": [[10, 10, "metrics"], [13, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nevertheless", ",", "in", "such", "systems", ",", "the", "stem", "reduces", "the", "precision", "or", "the", "percentage", "of", "true", "negatives", "."], "sentence-detokenized": "Nevertheless, in such systems, the stem reduces the precision or the percentage of true negatives.", "token2charspan": [[0, 12], [12, 13], [14, 16], [17, 21], [22, 29], [29, 30], [31, 34], [35, 39], [40, 47], [48, 51], [52, 61], [62, 64], [65, 68], [69, 79], [80, 82], [83, 87], [88, 97], [97, 98]]}
{"doc_key": "ai-test-14", "ner": [[4, 8, "task"], [10, 10, "misc"], [13, 18, "misc"], [25, 25, "product"], [27, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 10, 4, 8, "temporal", "", false, false], [13, 18, 10, 10, "named", "", false, false], [25, 25, 10, 10, "usage", "", false, false], [27, 28, 10, 10, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "special", "case", "of", "keyword", "detection", "is", "wake", "word", "detection", "(", "also", "called", "hot", "words", ")", ",", "which", "is", "used", "by", "personal", "digital", "assistants", "like", "Alexa", "or", "Siri", "to", "wake", "up", "when", "their", "name", "is", "spoken", "."], "sentence-detokenized": "A special case of keyword detection is wake word detection (also called hot words), which is used by personal digital assistants like Alexa or Siri to wake up when their name is spoken.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 17], [18, 25], [26, 35], [36, 38], [39, 43], [44, 48], [49, 58], [59, 60], [60, 64], [65, 71], [72, 75], [76, 81], [81, 82], [82, 83], [84, 89], [90, 92], [93, 97], [98, 100], [101, 109], [110, 117], [118, 128], [129, 133], [134, 139], [140, 142], [143, 147], [148, 150], [151, 155], [156, 158], [159, 163], [164, 169], [170, 174], [175, 177], [178, 184], [184, 185]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [9, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "with", "Java", "."], "sentence-detokenized": "Prova is an open source programming language that combines Prolog with Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 16], [17, 23], [24, 35], [36, 44], [45, 49], [50, 58], [59, 65], [66, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-test-16", "ner": [[3, 4, "organisation"], [9, 9, "organisation"], [16, 18, "product"], [30, 32, "country"], [36, 39, "organisation"], [46, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 9, 9, "part-of", "", false, false], [3, 4, 9, 9, "role", "sells", false, false], [3, 4, 30, 32, "role", "sells_to", false, false], [36, 39, 46, 47, "opposite", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "1987", ",", "Tocibai", "Machine", ",", "a", "subsidiary", "of", "Toshiba", ",", "was", "accused", "of", "illegally", "selling", "CNC", "milling", "cutters", ",", "used", "to", "produce", "very", "quiet", "submarine", "propellers", ",", "to", "the", "Soviet", "Union", "in", "violation", "of", "the", "CoCom", "Agreement", ",", "an", "international", "embargo", "on", "certain", "countries", "to", "COMECON", "countries", "."], "sentence-detokenized": "In 1987, Tocibai Machine, a subsidiary of Toshiba, was accused of illegally selling CNC milling cutters, used to produce very quiet submarine propellers, to the Soviet Union in violation of the CoCom Agreement, an international embargo on certain countries to COMECON countries.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 24], [24, 25], [26, 27], [28, 38], [39, 41], [42, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 75], [76, 83], [84, 87], [88, 95], [96, 103], [103, 104], [105, 109], [110, 112], [113, 120], [121, 125], [126, 131], [132, 141], [142, 152], [152, 153], [154, 156], [157, 160], [161, 167], [168, 173], [174, 176], [177, 186], [187, 189], [190, 193], [194, 199], [200, 209], [209, 210], [211, 213], [214, 227], [228, 235], [236, 238], [239, 246], [247, 256], [257, 259], [260, 267], [268, 277], [277, 278]]}
{"doc_key": "ai-test-17", "ner": [[0, 6, "researcher"], [7, 12, "product"], [19, 24, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 12, 0, 6, "artifact", "", false, false], [7, 12, 19, 24, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Engelberger", "'s", "most", "famous", "invention", ",", "the", "Unimate", "industrial", "robotic", "arm", ",", "was", "among", "the", "first", "inductees", "into", "the", "Robot", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberger's most famous invention, the Unimate industrial robotic arm, was among the first inductees into the Robot Hall of Fame in 2003.", "token2charspan": [[0, 11], [11, 13], [14, 18], [19, 25], [26, 35], [35, 36], [37, 40], [41, 48], [49, 59], [60, 67], [68, 71], [71, 72], [73, 76], [77, 82], [83, 86], [87, 92], [93, 102], [103, 107], [108, 111], [112, 117], [118, 122], [123, 125], [126, 130], [131, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-test-18", "ner": [[5, 8, "misc"], [9, 11, "misc"], [13, 13, "person"], [21, 22, "field"], [18, 27, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 8, 9, 11, "usage", "", false, false], [13, 13, 21, 22, "role", "", false, false], [21, 22, 18, 27, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Initially", ",", "control", "was", "through", "static", "html", "webpages", "using", "CGI", ",", "but", "after", "Dalton", "'s", "work", ",", "a", "Java", "-", "based", "augmented", "reality", "interface", "was", "introduced", "with", "limited", "success", "."], "sentence-detokenized": "Initially, control was through static html webpages using CGI, but after Dalton's work, a Java-based augmented reality interface was introduced with limited success.", "token2charspan": [[0, 9], [9, 10], [11, 18], [19, 22], [23, 30], [31, 37], [38, 42], [43, 51], [52, 57], [58, 61], [61, 62], [63, 66], [67, 72], [73, 79], [79, 81], [82, 86], [86, 87], [88, 89], [90, 94], [94, 95], [95, 100], [101, 110], [111, 118], [119, 128], [129, 132], [133, 143], [144, 148], [149, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-test-19", "ner": [[5, 6, "task"], [10, 10, "organisation"], [26, 26, "conference"], [29, 29, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 10, 10, "origin", "", false, false], [26, 26, 29, 29, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "publication", "for", "the", "LMF", "specification", "as", "ratified", "by", "ISO", "(", "this", "document", "became", "(", "in", "2015", ")", "the", "9th", "most", "cited", "document", "within", "the", "LREC", "conferences", "by", "LREC", "documents", ")", ":"], "sentence-detokenized": "The first publication for the LMF specification as ratified by ISO (this document became (in 2015) the 9th most cited document within the LREC conferences by LREC documents):", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 25], [26, 29], [30, 33], [34, 47], [48, 50], [51, 59], [60, 62], [63, 66], [67, 68], [68, 72], [73, 81], [82, 88], [89, 90], [90, 92], [93, 97], [97, 98], [99, 102], [103, 106], [107, 111], [112, 117], [118, 126], [127, 133], [134, 137], [138, 142], [143, 154], [155, 157], [158, 162], [163, 172], [172, 173], [173, 174]]}
{"doc_key": "ai-test-20", "ner": [[0, 2, "metrics"], [16, 17, "metrics"], [18, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 17, 0, 2, "usage", "", false, false], [16, 17, 18, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "confusion", "matrix", "or", "the", "correspondence", "matrix", "is", "often", "used", "as", "a", "tool", "to", "validate", "the", "accuracy", "of", "k", "-", "NN", "classification", "."], "sentence-detokenized": "The confusion matrix or the correspondence matrix is often used as a tool to validate the accuracy of k -NN classification.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 23], [24, 27], [28, 42], [43, 49], [50, 52], [53, 58], [59, 63], [64, 66], [67, 68], [69, 73], [74, 76], [77, 85], [86, 89], [90, 98], [99, 101], [102, 103], [104, 105], [105, 107], [108, 122], [122, 123]]}
{"doc_key": "ai-test-21", "ner": [[2, 3, "algorithm"], [13, 13, "field"], [15, 16, "field"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 13, 13, "part-of", "", false, false], [2, 3, 15, 16, "part-of", "", false, false], [2, 3, 19, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Learning", "with", "decision", "trees", "is", "one", "of", "the", "predictive", "modeling", "approaches", "used", "in", "statistics", ",", "data", "mining", ",", "and", "machine", "learning", "."], "sentence-detokenized": "Learning with decision trees is one of the predictive modeling approaches used in statistics, data mining, and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 28], [29, 31], [32, 35], [36, 38], [39, 42], [43, 53], [54, 62], [63, 73], [74, 78], [79, 81], [82, 92], [92, 93], [94, 98], [99, 105], [105, 106], [107, 110], [111, 118], [119, 127], [127, 128]]}
{"doc_key": "ai-test-22", "ner": [[6, 6, "misc"], [14, 14, "field"], [19, 21, "algorithm"], [23, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 14, 14, "related-to", "", true, false], [19, 21, 14, 14, "type-of", "", false, false], [23, 23, 14, 14, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["At", "runtime", ",", "the", "target", "sentence", "prosody", "is", "superimposed", "on", "these", "minimal", "units", "using", "signal", "processing", "techniques", "such", "as", "linear", "predictive", "coding", ",", "PSOLA"], "sentence-detokenized": "At runtime, the target sentence prosody is superimposed on these minimal units using signal processing techniques such as linear predictive coding, PSOLA", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 22], [23, 31], [32, 39], [40, 42], [43, 55], [56, 58], [59, 64], [65, 72], [73, 78], [79, 84], [85, 91], [92, 102], [103, 113], [114, 118], [119, 121], [122, 128], [129, 139], [140, 146], [146, 147], [148, 153]]}
{"doc_key": "ai-test-23", "ner": [[3, 4, "field"], [6, 8, "field"], [18, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 18, 3, 4, "usage", "", true, false], [18, 18, 6, 8, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "approach", "uses", "artificial", "intelligence", "and", "machine", "learning", "to", "allow", "researchers", "to", "visibly", "compare", "conventional", "and", "thermal", "facial", "images", "."], "sentence-detokenized": "This approach uses artificial intelligence and machine learning to allow researchers to visibly compare conventional and thermal facial images.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 29], [30, 42], [43, 46], [47, 54], [55, 63], [64, 66], [67, 72], [73, 84], [85, 87], [88, 95], [96, 103], [104, 116], [117, 120], [121, 128], [129, 135], [136, 142], [142, 143]]}
{"doc_key": "ai-test-24", "ner": [[1, 2, "field"], [4, 5, "algorithm"], [10, 11, "task"], [15, 16, "misc"], [22, 23, "field"], [25, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 1, 2, "part-of", "", false, false], [4, 5, 10, 11, "topic", "", false, false], [10, 11, 15, 16, "origin", "", false, false], [22, 23, 1, 2, "part-of", "", false, false], [22, 23, 4, 5, "topic", "", false, false], [25, 27, 1, 2, "part-of", "", false, false], [25, 27, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "computer", "science", ",", "evolutionary", "computation", "is", "a", "family", "of", "global", "optimization", "algorithms", "inspired", "by", "biological", "evolution", ",", "and", "a", "subfield", "of", "artificial", "intelligence", "and", "soft", "computing", "that", "studies", "these", "algorithms", "."], "sentence-detokenized": "In computer science, evolutionary computation is a family of global optimization algorithms inspired by biological evolution, and a subfield of artificial intelligence and soft computing that studies these algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 33], [34, 45], [46, 48], [49, 50], [51, 57], [58, 60], [61, 67], [68, 80], [81, 91], [92, 100], [101, 103], [104, 114], [115, 124], [124, 125], [126, 129], [130, 131], [132, 140], [141, 143], [144, 154], [155, 167], [168, 171], [172, 176], [177, 186], [187, 191], [192, 199], [200, 205], [206, 216], [216, 217]]}
{"doc_key": "ai-test-25", "ner": [[11, 12, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "one", "could", "combine", "some", "measure", "based", "on", "the", "confusion", "matrix", "with", "the", "mean", "squared", "error", "estimated", "between", "the", "raw", "model", "results", "and", "the", "actual", "values", "."], "sentence-detokenized": "For example, one could combine some measure based on the confusion matrix with the mean squared error estimated between the raw model results and the actual values.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 22], [23, 30], [31, 35], [36, 43], [44, 49], [50, 52], [53, 56], [57, 66], [67, 73], [74, 78], [79, 82], [83, 87], [88, 95], [96, 101], [102, 111], [112, 119], [120, 123], [124, 127], [128, 133], [134, 141], [142, 145], [146, 149], [150, 156], [157, 163], [163, 164]]}
{"doc_key": "ai-test-26", "ner": [[7, 8, "product"], [11, 11, "researcher"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 11, 11, "origin", "", false, false], [7, 8, 18, 18, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Most", "of", "them", "are", "results", "from", "the", "word2vec", "model", "developed", "by", "Mikolov", "et", "al", ",", "or", "variants", "of", "word2vec", "."], "sentence-detokenized": "Most of them are results from the word2vec model developed by Mikolov et al, or variants of word2vec.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 16], [17, 24], [25, 29], [30, 33], [34, 42], [43, 48], [49, 58], [59, 61], [62, 69], [70, 72], [73, 75], [75, 76], [77, 79], [80, 88], [89, 91], [92, 100], [100, 101]]}
{"doc_key": "ai-test-27", "ner": [[0, 4, "conference"], [7, 11, "conference"], [13, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 7, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["During", "this", "time", ",", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "recognized", "a", "total", "of", "43", "publications", "."], "sentence-detokenized": "During this time, CVPR and the International Conference on Computer Vision (ICCV) recognized a total of 43 publications.", "token2charspan": [[0, 6], [7, 11], [12, 16], [16, 17], [18, 22], [23, 26], [27, 30], [31, 44], [45, 55], [56, 58], [59, 67], [68, 74], [75, 76], [76, 80], [80, 81], [82, 92], [93, 94], [95, 100], [101, 103], [104, 106], [107, 119], [119, 120]]}
{"doc_key": "ai-test-28", "ner": [[0, 0, "product"], [15, 16, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 15, 16, "general-affiliation", "platform_for_education_about", false, false], [22, 23, 0, 0, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["AIBO", "is", "much", "used", "as", "a", "low", "-", "cost", "platform", "for", "AI", "training", "and", "research", ",", "as", "it", "integrates", "a", "computer", ",", "computer", "vision", ",", "and", "articulators", "into", "a", "package", "that", "is", "significantly", "cheaper", "than", "conventional", "research", "robots", "."], "sentence-detokenized": "AIBO is much used as a low-cost platform for AI training and research, as it integrates a computer, computer vision, and articulators into a package that is significantly cheaper than conventional research robots.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 17], [18, 20], [21, 22], [23, 26], [26, 27], [27, 31], [32, 40], [41, 44], [45, 47], [48, 56], [57, 60], [61, 69], [69, 70], [71, 73], [74, 76], [77, 87], [88, 89], [90, 98], [98, 99], [100, 108], [109, 115], [115, 116], [117, 120], [121, 133], [134, 138], [139, 140], [141, 148], [149, 153], [154, 156], [157, 170], [171, 178], [179, 183], [184, 196], [197, 205], [206, 212], [212, 213]]}
{"doc_key": "ai-test-29", "ner": [[6, 11, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "was", "program", "chair", "for", "the", "International", "Conference", "on", "Computer", "Vision", "2021", "."], "sentence-detokenized": "She was program chair for the International Conference on Computer Vision 2021.", "token2charspan": [[0, 3], [4, 7], [8, 15], [16, 21], [22, 25], [26, 29], [30, 43], [44, 54], [55, 57], [58, 66], [67, 73], [74, 78], [78, 79]]}
{"doc_key": "ai-test-30", "ner": [[11, 11, "researcher"], [5, 6, "organisation"], [16, 16, "organisation"], [25, 26, "organisation"], [33, 36, "product"], [38, 38, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 5, 6, "role", "", false, false], [11, 11, 16, 16, "role", "", true, false], [16, 16, 25, 26, "role", "develops_with", false, false], [33, 36, 16, 16, "artifact", "", false, false], [38, 38, 33, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["After", "receiving", "a", "grant", "from", "Unimation", "to", "develop", "his", "designs", ",", "Shainman", "sold", "these", "designs", "to", "Unimation", ",", "which", "further", "developed", "them", "with", "support", "from", "General", "Motors", "and", "later", "marketed", "them", "as", "the", "Programmable", "Universal", "Machine", "Assembly", "(", "PUMA", ")", "."], "sentence-detokenized": "After receiving a grant from Unimation to develop his designs, Shainman sold these designs to Unimation, which further developed them with support from General Motors and later marketed them as the Programmable Universal Machine Assembly (PUMA).", "token2charspan": [[0, 5], [6, 15], [16, 17], [18, 23], [24, 28], [29, 38], [39, 41], [42, 49], [50, 53], [54, 61], [61, 62], [63, 71], [72, 76], [77, 82], [83, 90], [91, 93], [94, 103], [103, 104], [105, 110], [111, 118], [119, 128], [129, 133], [134, 138], [139, 146], [147, 151], [152, 159], [160, 166], [167, 170], [171, 176], [177, 185], [186, 190], [191, 193], [194, 197], [198, 210], [211, 220], [221, 228], [229, 237], [238, 239], [239, 243], [243, 244], [244, 245]]}
{"doc_key": "ai-test-31", "ner": [[6, 12, "task"], [8, 10, "task"], [14, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 6, 12, "general-affiliation", "works_with", false, false], [14, 14, 8, 10, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "review", "of", "calibration", "methods", "for", "binary", "and", "multiclass", "classification", "tasks", "is", "given", "by", "Gebel", "(", "2009", ")", "."], "sentence-detokenized": "A review of calibration methods for binary and multiclass classification tasks is given by Gebel (2009).", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 23], [24, 31], [32, 35], [36, 42], [43, 46], [47, 57], [58, 72], [73, 78], [79, 81], [82, 87], [88, 90], [91, 96], [97, 98], [98, 102], [102, 103], [103, 104]]}
{"doc_key": "ai-test-32", "ner": [[7, 9, "task"], [11, 11, "task"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "involved", "in", "areas", "such", "as", "optical", "character", "recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "speech", "recognition", "technology", "and", "electronic", "keyboards", "."], "sentence-detokenized": "He is involved in areas such as optical character recognition (OCR), speech synthesis, speech recognition technology and electronic keyboards.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 23], [24, 28], [29, 31], [32, 39], [40, 49], [50, 61], [62, 63], [63, 66], [66, 67], [67, 68], [69, 75], [76, 85], [85, 86], [87, 93], [94, 105], [106, 116], [117, 120], [121, 131], [132, 141], [141, 142]]}
{"doc_key": "ai-test-33", "ner": [[8, 13, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "newer", "and", "more", "advanced", "techniques", ",", "the", "Kaldi", "tool", "kit", "can", "be", "used", "."], "sentence-detokenized": "For newer and more advanced techniques, the Kaldi tool kit can be used.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 18], [19, 27], [28, 38], [38, 39], [40, 43], [44, 49], [50, 54], [55, 58], [59, 62], [63, 65], [66, 70], [70, 71]]}
{"doc_key": "ai-test-34", "ner": [[0, 2, "researcher"], [8, 12, "organisation"], [16, 19, "organisation"], [23, 24, "organisation"], [30, 31, "researcher"], [32, 35, "organisation"], [42, 45, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 8, 12, "role", "", false, false], [0, 2, 16, 19, "role", "", false, false], [0, 2, 23, 24, "role", "", false, false], [0, 2, 32, 35, "role", "", false, false], [0, 2, 42, 45, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson", "-", "Laird", "is", "a", "Fellow", "of", "the", "American", "Philosophical", "Society", ",", "a", "Fellow", "of", "the", "Royal", "Society", ",", "a", "Fellow", "of", "the", "British", "Academy", ",", "a", "Fellow", "of", "the", "William", "James", "Association", "for", "Psychological", "Science", ",", "and", "a", "Fellow", "of", "the", "Society", "for", "Cognitive", "Science", "."], "sentence-detokenized": "Johnson-Laird is a Fellow of the American Philosophical Society, a Fellow of the Royal Society, a Fellow of the British Academy, a Fellow of the William James Association for Psychological Science, and a Fellow of the Society for Cognitive Science.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 66], [67, 73], [74, 76], [77, 80], [81, 86], [87, 94], [94, 95], [96, 97], [98, 104], [105, 107], [108, 111], [112, 119], [120, 127], [127, 128], [129, 130], [131, 137], [138, 140], [141, 144], [145, 152], [153, 158], [159, 170], [171, 174], [175, 188], [189, 196], [196, 197], [198, 201], [202, 203], [204, 210], [211, 213], [214, 217], [218, 225], [226, 229], [230, 239], [240, 247], [247, 248]]}
{"doc_key": "ai-test-35", "ner": [[3, 8, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [17, 18, "researcher"], [21, 23, "algorithm"], [26, 30, "task"], [32, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 3, 8, "physical", "", false, false], [10, 11, 3, 8, "temporal", "", false, false], [13, 14, 3, 8, "physical", "", false, false], [13, 14, 3, 8, "temporal", "", false, false], [17, 18, 3, 8, "physical", "", false, false], [17, 18, 3, 8, "temporal", "", false, false], [21, 23, 17, 18, "role", "extends", false, false], [26, 30, 17, 18, "role", "extends", false, false], [32, 32, 26, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["At", "the", "2010", "IEEE", "International", "Conference", "on", "Image", "Processing", ",", "Rui", "Hu", ",", "Mark", "Bannard", ",", "and", "John", "Colomus", "extended", "the", "HOG", "descriptor", "for", "use", "in", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the 2010 IEEE International Conference on Image Processing, Rui Hu, Mark Bannard, and John Colomus extended the HOG descriptor for use in sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 30], [31, 41], [42, 44], [45, 50], [51, 61], [61, 62], [63, 66], [67, 69], [69, 70], [71, 75], [76, 83], [83, 84], [85, 88], [89, 93], [94, 101], [102, 110], [111, 114], [115, 118], [119, 129], [130, 133], [134, 137], [138, 140], [141, 147], [147, 148], [148, 153], [154, 159], [160, 169], [170, 171], [171, 175], [175, 176], [176, 177]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 7, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "uses", "a", "modified", "form", "of", "precision", "to", "compare", "a", "candidate", "translation", "with", "multiple", "reference", "translations", "."], "sentence-detokenized": "BLEU uses a modified form of precision to compare a candidate translation with multiple reference translations.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 20], [21, 25], [26, 28], [29, 38], [39, 41], [42, 49], [50, 51], [52, 61], [62, 73], [74, 78], [79, 87], [88, 97], [98, 110], [110, 111]]}
{"doc_key": "ai-test-37", "ner": [[31, 32, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "case", "of", "a", "general", "basis", "space", "math", "(", "Y", ",\\", "mathcal", "{", "B", "},\\", "nu", ")", "/", "math", "(", "i.e.", "a", "basis", "space", "that", "is", "not", "enumerable", ")", ",", "relative", "entropy", "is", "usually", "considered", "."], "sentence-detokenized": "In the case of a general basis space math (Y,\\ mathcal {B},\\ nu) / math (i.e. a basis space that is not enumerable), relative entropy is usually considered.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 36], [37, 41], [42, 43], [43, 44], [44, 46], [47, 54], [55, 56], [56, 57], [57, 60], [61, 63], [63, 64], [65, 66], [67, 71], [72, 73], [73, 77], [78, 79], [80, 85], [86, 91], [92, 96], [97, 99], [100, 103], [104, 114], [114, 115], [115, 116], [117, 125], [126, 133], [134, 136], [137, 144], [145, 155], [155, 156]]}
{"doc_key": "ai-test-38", "ner": [[9, 9, "country"], [10, 12, "organisation"], [14, 14, "organisation"], [24, 25, "country"], [17, 18, "organisation"], [20, 20, "organisation"], [27, 30, "organisation"], [41, 41, "country"], [33, 40, "organisation"], [43, 46, "organisation"], [51, 51, "misc"], [52, 52, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[10, 12, 9, 9, "physical", "", false, false], [14, 14, 10, 12, "named", "", false, false], [17, 18, 24, 25, "physical", "", false, false], [20, 20, 17, 18, "named", "", false, false], [33, 40, 41, 41, "physical", "", false, false], [43, 46, 33, 40, "named", "", false, false], [51, 51, 52, 52, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "of", "October", "2011", ",", "existing", "partnerships", "with", "the", "U.S.", "National", "Park", "Service", "(", "NPS", ")", ",", "Historic", "Scotland", "(", "HS", ")", "of", "the", "United", "Kingdom", ",", "the", "World", "Monuments", "Fund", ",", "and", "the", "National", "Institute", "of", "Anthropology", "and", "History", "of", "Mexico", "(", "INAH", ")", "have", "been", "significantly", "expanded", ",", ",", "CyArk", "website"], "sentence-detokenized": "As of October 2011, existing partnerships with the U.S. National Park Service (NPS), Historic Scotland (HS) of the United Kingdom, the World Monuments Fund, and the National Institute of Anthropology and History of Mexico (INAH) have been significantly expanded,, CyArk website", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 18], [18, 19], [20, 28], [29, 41], [42, 46], [47, 50], [51, 55], [56, 64], [65, 69], [70, 77], [78, 79], [79, 82], [82, 83], [83, 84], [85, 93], [94, 102], [103, 104], [104, 106], [106, 107], [108, 110], [111, 114], [115, 121], [122, 129], [129, 130], [131, 134], [135, 140], [141, 150], [151, 155], [155, 156], [157, 160], [161, 164], [165, 173], [174, 183], [184, 186], [187, 199], [200, 203], [204, 211], [212, 214], [215, 221], [222, 223], [223, 227], [227, 228], [229, 233], [234, 238], [239, 252], [253, 261], [261, 262], [262, 263], [264, 269], [270, 277]]}
{"doc_key": "ai-test-39", "ner": [[0, 3, "algorithm"], [6, 8, "field"], [11, 11, "product"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 11, 11, "part-of", "", false, false], [0, 3, 13, 13, "part-of", "", false, false], [11, 11, 6, 8, "general-affiliation", "", false, false], [13, 13, 6, 8, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kernel", "SVMs", "are", "available", "in", "many", "machine", "learning", "toolkits", ",", "including", "LIBSVM", ",", "MATLAB", ",", "and", "others", "."], "sentence-detokenized": "Kernel SVMs are available in many machine learning toolkits, including LIBSVM, MATLAB, and others.", "token2charspan": [[0, 6], [7, 11], [12, 15], [16, 25], [26, 28], [29, 33], [34, 41], [42, 50], [51, 59], [59, 60], [61, 70], [71, 77], [77, 78], [79, 85], [85, 86], [87, 90], [91, 97], [97, 98]]}
{"doc_key": "ai-test-40", "ner": [[2, 4, "misc"], [13, 14, "location"], [16, 16, "location"], [18, 21, "country"], [23, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 13, 14, "physical", "", false, false], [2, 4, 23, 26, "temporal", "", false, false], [13, 14, 16, 16, "physical", "", false, false], [16, 16, 18, 21, "physical", "", false, false], [23, 26, 13, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2009", "Leebner", "Prize", "competition", "was", "held", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", ",", "Brighton", ",", "UK", ",", "in", "conjunction", "with", "the", "Interspeech", "2009", "conference", "."], "sentence-detokenized": "The 2009 Leebner Prize competition was held on 6 September 2009 at the Brighton Centre, Brighton, UK, in conjunction with the Interspeech 2009 conference.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 34], [35, 38], [39, 43], [44, 46], [47, 48], [49, 58], [59, 63], [64, 66], [67, 70], [71, 79], [80, 86], [86, 87], [88, 96], [96, 97], [98, 100], [100, 101], [102, 104], [105, 116], [117, 121], [122, 125], [126, 137], [138, 142], [143, 153], [153, 154]]}
{"doc_key": "ai-test-41", "ner": [[0, 3, "product"], [10, 10, "product"], [16, 18, "product"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 21, 0, 3, "part-of", "", false, false], [19, 21, 10, 10, "part-of", "", false, false], [19, 21, 16, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "QRIO", "humanoid", "robot", "is", "designed", "as", "a", "successor", "to", "AIBO", "and", "runs", "the", "same", "underlying", "R", "-", "CODE", "Aperios", "operating", "system", "."], "sentence-detokenized": "The QRIO humanoid robot is designed as a successor to AIBO and runs the same underlying R-CODE Aperios operating system.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 23], [24, 26], [27, 35], [36, 38], [39, 40], [41, 50], [51, 53], [54, 58], [59, 62], [63, 67], [68, 71], [72, 76], [77, 87], [88, 89], [89, 90], [90, 94], [95, 102], [103, 112], [113, 119], [119, 120]]}
{"doc_key": "ai-test-42", "ner": [[0, 2, "misc"], [7, 11, "algorithm"], [12, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 11, 0, 2, "cause-effect", "", true, false], [12, 14, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "speech", "forms", "are", "generated", "by", "the", "HMMs", "themselves", "based", "on", "the", "maximum", "likelihood", "criterion", "."], "sentence-detokenized": "The speech forms are generated by the HMMs themselves based on the maximum likelihood criterion.", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 20], [21, 30], [31, 33], [34, 37], [38, 42], [43, 53], [54, 59], [60, 62], [63, 66], [67, 74], [75, 85], [86, 95], [95, 96]]}
{"doc_key": "ai-test-43", "ner": [[0, 1, "product"], [5, 8, "task"], [10, 12, "task"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 5, 8, "type-of", "", false, false], [0, 1, 10, 12, "type-of", "", false, false], [0, 1, 16, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "is", "a", "free", "multilingual", "statistical", "machine", "translation", "and", "neural", "machine", "translation", "service", "developed", "by", "Google", "to", "translate", "text", "and", "websites", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Google Translate is a free multilingual statistical machine translation and neural machine translation service developed by Google to translate text and websites from one language to another.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 39], [40, 51], [52, 59], [60, 71], [72, 75], [76, 82], [83, 90], [91, 102], [103, 110], [111, 120], [121, 123], [124, 130], [131, 133], [134, 143], [144, 148], [149, 152], [153, 161], [162, 166], [167, 170], [171, 179], [180, 182], [183, 190], [190, 191]]}
{"doc_key": "ai-test-44", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [15, 18, "field"], [22, 24, "task"], [26, 27, "task"], [29, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[22, 24, 5, 6, "part-of", "", false, true], [22, 24, 8, 9, "part-of", "", false, true], [22, 24, 11, 12, "part-of", "", false, true], [26, 27, 5, 6, "part-of", "", false, true], [26, 27, 8, 9, "part-of", "", false, true], [26, 27, 11, 12, "part-of", "", false, true], [29, 33, 5, 6, "part-of", "", false, true], [29, 33, 8, 9, "part-of", "", false, true], [29, 33, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Skeletons", "are", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", ",", "and", "digital", "image", "processing", "for", "purposes", "such", "as", "optical", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", ",", "or", "compression", "."], "sentence-detokenized": "Skeletons are widely used in computer vision, image analysis, pattern recognition, and digital image processing for purposes such as optical character recognition, fingerprint recognition, visual inspection, or compression.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 25], [26, 28], [29, 37], [38, 44], [44, 45], [46, 51], [52, 60], [60, 61], [62, 69], [70, 81], [81, 82], [83, 86], [87, 94], [95, 100], [101, 111], [112, 115], [116, 124], [125, 129], [130, 132], [133, 140], [141, 150], [151, 162], [162, 163], [164, 175], [176, 187], [187, 188], [189, 195], [196, 206], [206, 207], [208, 210], [211, 222], [222, 223]]}
{"doc_key": "ai-test-45", "ner": [[0, 6, "conference"], [11, 15, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 6, 11, 15, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "is", "the", "benchmark", "for", "object", "classification", "and", "detection", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge is the benchmark for object classification and detection with millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 60], [61, 70], [71, 74], [75, 81], [82, 96], [97, 100], [101, 110], [111, 115], [116, 124], [125, 127], [128, 134], [135, 138], [139, 147], [148, 150], [151, 157], [158, 165], [165, 166]]}
{"doc_key": "ai-test-46", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 12, "researcher"], [15, 18, "misc"], [21, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 15, 18, "part-of", "", false, false], [0, 2, 21, 24, "part-of", "", false, false], [4, 5, 15, 18, "part-of", "", false, false], [4, 5, 21, 24, "part-of", "", false, false], [7, 12, 15, 18, "part-of", "", false, false], [7, 12, 21, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "along", "with", "Jeffrey", "Hinton", "and", "Ian", "LeCun", ",", "are", "called", "by", "some", "the", "godfathers", "of", "artificial", "intelligence", "and", "the", "godfathers", "of", "deep", "learning", "."], "sentence-detokenized": "Bengio, along with Jeffrey Hinton and Ian LeCun, are called by some the godfathers of artificial intelligence and the godfathers of deep learning.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 26], [27, 33], [34, 37], [38, 41], [42, 47], [47, 48], [49, 52], [53, 59], [60, 62], [63, 67], [68, 71], [72, 82], [83, 85], [86, 96], [97, 109], [110, 113], [114, 117], [118, 128], [129, 131], [132, 136], [137, 145], [145, 146]]}
{"doc_key": "ai-test-47", "ner": [[7, 7, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "life", "member", "of", "the", "IEEE", "."], "sentence-detokenized": "He is a life member of the IEEE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 19], [20, 22], [23, 26], [27, 31], [31, 32]]}
{"doc_key": "ai-test-48", "ner": [[0, 1, "organisation"], [15, 20, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 15, 20, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NSA", "Bethesda", "is", "responsible", "for", "operational", "support", "of", "the", "base", ",", "whose", "primary", "tenant", "is", "Walter", "Reed", "National", "Military", "Medical", "Center", "."], "sentence-detokenized": "NSA Bethesda is responsible for operational support of the base, whose primary tenant is Walter Reed National Military Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 31], [32, 43], [44, 51], [52, 54], [55, 58], [59, 63], [63, 64], [65, 70], [71, 78], [79, 85], [86, 88], [89, 95], [96, 100], [101, 109], [110, 118], [119, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-test-49", "ner": [[6, 7, "field"], [9, 10, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "three", "main", "training", "paradigms", "are", "supervised", "learning", ",", "unsupervised", "learning", ",", "and", "reinforcement", "learning", "."], "sentence-detokenized": "The three main training paradigms are supervised learning, unsupervised learning, and reinforcement learning.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 23], [24, 33], [34, 37], [38, 48], [49, 57], [57, 58], [59, 71], [72, 80], [80, 81], [82, 85], [86, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-test-50", "ner": [[2, 2, "task"], [4, 6, "task"], [11, 14, "task"], [16, 17, "task"], [19, 21, "task"], [23, 24, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Examples", "include", "control", ",", "planning", "and", "scheduling", ",", "ability", "to", "answer", "diagnostic", "and", "user", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", ",", "and", "facial", "recognition", "."], "sentence-detokenized": "Examples include control, planning and scheduling, ability to answer diagnostic and user questions, handwriting recognition, natural language understanding, speech recognition, and facial recognition.", "token2charspan": [[0, 8], [9, 16], [17, 24], [24, 25], [26, 34], [35, 38], [39, 49], [49, 50], [51, 58], [59, 61], [62, 68], [69, 79], [80, 83], [84, 88], [89, 98], [98, 99], [100, 111], [112, 123], [123, 124], [125, 132], [133, 141], [142, 155], [155, 156], [157, 163], [164, 175], [175, 176], [177, 180], [181, 187], [188, 199], [199, 200]]}
{"doc_key": "ai-test-51", "ner": [[8, 14, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", ",", "he", "was", "elected", "to", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "founding", "member", ")", "."], "sentence-detokenized": "In 1991, he was elected to the Association for the Advancement of Artificial Intelligence (1990, founding member).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 42], [43, 46], [47, 50], [51, 62], [63, 65], [66, 76], [77, 89], [90, 91], [91, 95], [95, 96], [97, 105], [106, 112], [112, 113], [113, 114]]}
{"doc_key": "ai-test-52", "ner": [[11, 12, "misc"], [15, 19, "algorithm"], [30, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "by", "formulating", "the", "problem", "as", "a", "solution", "of", "a", "Toeplitz", "matrix", "and", "using", "Levinson", "'s", "recursion", ",", "we", "can", "relatively", "quickly", "estimate", "a", "filter", "with", "the", "smallest", "possible", "mean", "squared", "error", "."], "sentence-detokenized": "However, by formulating the problem as a solution of a Toeplitz matrix and using Levinson's recursion, we can relatively quickly estimate a filter with the smallest possible mean squared error.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 23], [24, 27], [28, 35], [36, 38], [39, 40], [41, 49], [50, 52], [53, 54], [55, 63], [64, 70], [71, 74], [75, 80], [81, 89], [89, 91], [92, 101], [101, 102], [103, 105], [106, 109], [110, 120], [121, 128], [129, 137], [138, 139], [140, 146], [147, 151], [152, 155], [156, 164], [165, 173], [174, 178], [179, 186], [187, 192], [192, 193]]}
{"doc_key": "ai-test-53", "ner": [[5, 10, "conference"], [16, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 10, 16, 20, "physical", "", false, false], [16, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2011", ",", "the", "15th", "edition", "of", "Campus", "Party", "Spain", "will", "take", "place", "in", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "In July 2011, the 15th edition of Campus Party Spain will take place in the City of Arts and Sciences in Valencia.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 22], [23, 30], [31, 33], [34, 40], [41, 46], [47, 52], [53, 57], [58, 62], [63, 68], [69, 71], [72, 75], [76, 80], [81, 83], [84, 88], [89, 92], [93, 101], [102, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-54", "ner": [[14, 14, "product"], [16, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Often", "this", "is", "only", "possible", "at", "the", "very", "end", "of", "complex", "games", "such", "as", "chess", "or", "Go", ",", "as", "it", "is", "not", "computationally", "possible", "to", "look", "ahead", "to", "the", "completion", "of", "the", "game", "except", "towards", "the", "end", ",", "and", "instead", "the", "positions", "are", "given", "finite", "values", "as", "an", "estimate", "of", "the", "degree", "of", "certainty", "that", "they", "will", "result", "in", "a", "win", "for", "one", "player", "or", "another", "."], "sentence-detokenized": "Often this is only possible at the very end of complex games such as chess or Go, as it is not computationally possible to look ahead to the completion of the game except towards the end, and instead the positions are given finite values as an estimate of the degree of certainty that they will result in a win for one player or another.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 18], [19, 27], [28, 30], [31, 34], [35, 39], [40, 43], [44, 46], [47, 54], [55, 60], [61, 65], [66, 68], [69, 74], [75, 77], [78, 80], [80, 81], [82, 84], [85, 87], [88, 90], [91, 94], [95, 110], [111, 119], [120, 122], [123, 127], [128, 133], [134, 136], [137, 140], [141, 151], [152, 154], [155, 158], [159, 163], [164, 170], [171, 178], [179, 182], [183, 186], [186, 187], [188, 191], [192, 199], [200, 203], [204, 213], [214, 217], [218, 223], [224, 230], [231, 237], [238, 240], [241, 243], [244, 252], [253, 255], [256, 259], [260, 266], [267, 269], [270, 279], [280, 284], [285, 289], [290, 294], [295, 301], [302, 304], [305, 306], [307, 310], [311, 314], [315, 318], [319, 325], [326, 328], [329, 336], [336, 337]]}
{"doc_key": "ai-test-55", "ner": [[4, 6, "algorithm"], [23, 25, "algorithm"], [27, 28, "algorithm"], [31, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 23, 25, "compare", "", false, false], [4, 6, 27, 28, "compare", "", false, false], [4, 6, 31, 33, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "difference", "between", "the", "multi-component", "logarithmic", "model", "and", "many", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "with", "the", "same", "basic", "configuration", "(", "the", "perceptron", "algorithm", ",", "support", "vector", "machines", ",", "linear", "discriminant", "analysis", ",", "etc", "."], "sentence-detokenized": "The difference between the multi-component logarithmic model and many other methods, models, algorithms, etc. with the same basic configuration (the perceptron algorithm, support vector machines, linear discriminant analysis, etc.", "token2charspan": [[0, 3], [4, 14], [15, 22], [23, 26], [27, 42], [43, 54], [55, 60], [61, 64], [65, 69], [70, 75], [76, 83], [83, 84], [85, 91], [91, 92], [93, 103], [103, 104], [105, 109], [110, 114], [115, 118], [119, 123], [124, 129], [130, 143], [144, 145], [145, 148], [149, 159], [160, 169], [169, 170], [171, 178], [179, 185], [186, 194], [194, 195], [196, 202], [203, 215], [216, 224], [224, 225], [226, 229], [229, 230]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "published", "by"], "sentence-detokenized": "Association for Computational Linguistics, published by", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 52], [53, 55]]}
{"doc_key": "ai-test-57", "ner": [[3, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "a", "computerized", "face", "recognition", "system", ",", "each", "face", "is", "represented", "by", "a", "large", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In a computerized face recognition system, each face is represented by a large number of pixel values.", "token2charspan": [[0, 2], [3, 4], [5, 17], [18, 22], [23, 34], [35, 41], [41, 42], [43, 47], [48, 52], [53, 55], [56, 67], [68, 70], [71, 72], [73, 78], [79, 85], [86, 88], [89, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-58", "ner": [[5, 8, "person"], [13, 15, "organisation"], [23, 24, "country"], [25, 25, "person"], [35, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 8, 13, 15, "role", "", false, false], [5, 8, 23, 24, "physical", "", false, false], [25, 25, 35, 37, "origin", "", false, false], [25, 25, 35, 37, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2002", ",", "his", "son", "Daniel", "Pearl", ",", "a", "journalist", "working", "for", "the", "Wall", "Street", "Journal", ",", "was", "kidnapped", "and", "killed", "in", "Pakistan", ",", "prompting", "Judah", "and", "other", "family", "members", "and", "friends", "to", "create", "the", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "In 2002, his son Daniel Pearl, a journalist working for the Wall Street Journal, was kidnapped and killed in Pakistan, prompting Judah and other family members and friends to create the Daniel Pearl Foundation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 23], [24, 29], [29, 30], [31, 32], [33, 43], [44, 51], [52, 55], [56, 59], [60, 64], [65, 71], [72, 79], [79, 80], [81, 84], [85, 94], [95, 98], [99, 105], [106, 108], [109, 117], [117, 118], [119, 128], [129, 134], [135, 138], [139, 144], [145, 151], [152, 159], [160, 163], [164, 171], [172, 174], [175, 181], [182, 185], [186, 192], [193, 198], [199, 209], [209, 210]]}
{"doc_key": "ai-test-59", "ner": [[4, 6, "organisation"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 16, 17, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "late", "2006", ",", "Red", "Envelope", "Entertainment", "expanded", "into", "producing", "original", "content", "with", "directors", "such", "as", "John", "Waters", "."], "sentence-detokenized": "In late 2006, Red Envelope Entertainment expanded into producing original content with directors such as John Waters.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 26], [27, 40], [41, 49], [50, 54], [55, 64], [65, 73], [74, 81], [82, 86], [87, 96], [97, 101], [102, 104], [105, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-test-60", "ner": [[6, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "building", "is", "currently", "part", "of", "Beth", "Israel", "Deaconess", "Medical", "Center", "."], "sentence-detokenized": "The building is currently part of Beth Israel Deaconess Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 25], [26, 30], [31, 33], [34, 38], [39, 45], [46, 55], [56, 63], [64, 70], [70, 71]]}
{"doc_key": "ai-test-61", "ner": [[18, 19, "field"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "common", "theme", "of", "this", "work", "is", "the", "adoption", "of", "a", "sign", "-", "theoretic", "perspective", "on", "issues", "of", "artificial", "intelligence", "and", "knowledge", "representation", "."], "sentence-detokenized": "A common theme of this work is the adoption of a sign-theoretic perspective on issues of artificial intelligence and knowledge representation.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 43], [44, 46], [47, 48], [49, 53], [53, 54], [54, 63], [64, 75], [76, 78], [79, 85], [86, 88], [89, 99], [100, 112], [113, 116], [117, 126], [127, 141], [141, 142]]}
{"doc_key": "ai-test-62", "ner": [[6, 8, "task"], [11, 11, "task"], [17, 18, "task"], [41, 42, "task"], [44, 47, "task"], [50, 52, "task"], [54, 54, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[6, 8, 17, 18, "type-of", "", false, false], [6, 8, 50, 52, "compare", "", false, false], [6, 8, 50, 52, "opposite", "", false, false], [11, 11, 6, 8, "named", "", false, false], [41, 42, 50, 52, "part-of", "", false, false], [44, 47, 50, 52, "part-of", "", false, false], [50, 52, 17, 18, "type-of", "", false, false], [54, 54, 50, 52, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["For", "example", ",", "the", "term", "\"", "neural", "machine", "translation", "\"", "(", "NMT", ")", "highlights", "the", "fact", "that", "machine", "translation", "approaches", "based", "on", "deep", "learning", "directly", "learn", "sequence", "-", "to", "-", "sequence", "transformations", ",", "removing", "the", "need", "for", "intermediate", "steps", "such", "as", "word", "alignment", "and", "language", "modeling", "that", "are", "used", "in", "statistical", "machine", "translation", "(", "SMT", ")", "."], "sentence-detokenized": "For example, the term \"neural machine translation\" (NMT) highlights the fact that machine translation approaches based on deep learning directly learn sequence-to-sequence transformations, removing the need for intermediate steps such as word alignment and language modeling that are used in statistical machine translation (SMT).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 23], [23, 29], [30, 37], [38, 49], [49, 50], [51, 52], [52, 55], [55, 56], [57, 67], [68, 71], [72, 76], [77, 81], [82, 89], [90, 101], [102, 112], [113, 118], [119, 121], [122, 126], [127, 135], [136, 144], [145, 150], [151, 159], [159, 160], [160, 162], [162, 163], [163, 171], [172, 187], [187, 188], [189, 197], [198, 201], [202, 206], [207, 210], [211, 223], [224, 229], [230, 234], [235, 237], [238, 242], [243, 252], [253, 256], [257, 265], [266, 274], [275, 279], [280, 283], [284, 288], [289, 291], [292, 303], [304, 311], [312, 323], [324, 325], [325, 328], [328, 329], [329, 330]]}
{"doc_key": "ai-test-63", "ner": [[1, 4, "field"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 4, 6, 7, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "WSD", "research", "is", "conducted", "using", "Word", "Net", "as", "a", "reference", "list", "of", "meanings", "for", "."], "sentence-detokenized": "Most WSD research is conducted using WordNet as a reference list of meanings for.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 30], [31, 36], [37, 41], [41, 44], [45, 47], [48, 49], [50, 59], [60, 64], [65, 67], [68, 76], [77, 80], [80, 81]]}
{"doc_key": "ai-test-64", "ner": [[9, 10, "researcher"], [12, 13, "researcher"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Former", "PhD", "students", "and", "postdocs", "from", "his", "group", "include", "Richard", "Zemel", "and", "Zubin", "Gahramani", "."], "sentence-detokenized": "Former PhD students and postdocs from his group include Richard Zemel and Zubin Gahramani.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 23], [24, 32], [33, 37], [38, 41], [42, 47], [48, 55], [56, 63], [64, 69], [70, 73], [74, 79], [80, 89], [89, 90]]}
{"doc_key": "ai-test-65", "ner": [[7, 8, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 14, 15, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Each", "prediction", "score", "or", "instance", "of", "the", "confusion", "matrix", "represents", "a", "point", "in", "the", "ROC", "space", "."], "sentence-detokenized": "Each prediction score or instance of the confusion matrix represents a point in the ROC space.", "token2charspan": [[0, 4], [5, 15], [16, 21], [22, 24], [25, 33], [34, 36], [37, 40], [41, 50], [51, 57], [58, 68], [69, 70], [71, 76], [77, 79], [80, 83], [84, 87], [88, 93], [93, 94]]}
{"doc_key": "ai-test-66", "ner": [[3, 3, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [17, 20, "product"], [21, 24, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 21, 24, "physical", "", false, false], [7, 8, 21, 24, "physical", "", false, false], [10, 11, 21, 24, "physical", "", false, false], [17, 20, 3, 3, "artifact", "", false, false], [17, 20, 7, 8, "artifact", "", false, false], [17, 20, 10, 11, "artifact", "", false, false], [17, 20, 21, 24, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1997", ",", "Tran", "and", "his", "colleagues", "Wolfram", "Burgard", "and", "Dieter", "Fox", "developed", "the", "world", "'s", "first", "robot", "guide", "at", "the", "Deutsches", "Museum", "in", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "In 1997, Tran and his colleagues Wolfram Burgard and Dieter Fox developed the world's first robot guide at the Deutsches Museum in Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 13], [14, 17], [18, 21], [22, 32], [33, 40], [41, 48], [49, 52], [53, 59], [60, 63], [64, 73], [74, 77], [78, 83], [83, 85], [86, 91], [92, 97], [98, 103], [104, 106], [107, 110], [111, 120], [121, 127], [128, 130], [131, 135], [136, 137], [137, 141], [141, 142], [142, 143]]}
{"doc_key": "ai-test-67", "ner": [[0, 1, "product"], [7, 7, "misc"], [24, 26, "field"], [28, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 1, "part-of", "", false, false], [24, 26, 0, 1, "usage", "", false, false], [28, 30, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "of", "semantic", "relationships", "between", "words", "in", "more", "than", "200", "languages", ".", "it", "s", "main", "use", "is", "in", "automatic", "natural", "language", "processing", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database of semantic relationships between words in more than 200 languages. its main use is in automatic natural language processing and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 32], [33, 41], [42, 55], [56, 63], [64, 69], [70, 72], [73, 77], [78, 82], [83, 86], [87, 96], [96, 97], [98, 100], [100, 101], [102, 106], [107, 110], [111, 113], [114, 116], [117, 126], [127, 134], [135, 143], [144, 154], [155, 158], [159, 169], [170, 182], [183, 195], [195, 196]]}
{"doc_key": "ai-test-68", "ner": [[2, 4, "field"], [8, 12, "conference"], [15, 23, "conference"], [25, 25, "conference"], [28, 28, "conference"], [36, 37, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 12, 2, 4, "topic", "", false, false], [8, 12, 36, 37, "topic", "", false, false], [15, 23, 2, 4, "topic", "", false, false], [15, 23, 36, 37, "topic", "", false, false], [25, 25, 2, 4, "topic", "", false, false], [25, 25, 36, 37, "topic", "", false, false], [28, 28, 2, 4, "topic", "", false, false], [28, 28, 36, 37, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Conferences", "in", "natural", "language", "processing", ",", "such", "as", "the", "Association", "for", "Computational", "Linguistics", ",", "the", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", ",", "and", "HLT", ",", "are", "beginning", "to", "include", "papers", "on", "speech", "processing", "."], "sentence-detokenized": "Conferences in natural language processing, such as the Association for Computational Linguistics, the North American Chapter of the Association for Computational Linguistics, EMNLP, and HLT, are beginning to include papers on speech processing.", "token2charspan": [[0, 11], [12, 14], [15, 22], [23, 31], [32, 42], [42, 43], [44, 48], [49, 51], [52, 55], [56, 67], [68, 71], [72, 85], [86, 97], [97, 98], [99, 102], [103, 108], [109, 117], [118, 125], [126, 128], [129, 132], [133, 144], [145, 148], [149, 162], [163, 174], [174, 175], [176, 181], [181, 182], [183, 186], [187, 190], [190, 191], [192, 195], [196, 205], [206, 208], [209, 216], [217, 223], [224, 226], [227, 233], [234, 244], [244, 245]]}
{"doc_key": "ai-test-69", "ner": [[3, 3, "programlang"], [19, 26, "misc"], [33, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "set", "of", "Java", "programs", "uses", "the", "lexicon", "to", "process", "variations", "in", "biomedical", "texts", "by", "linking", "words", "by", "their", "parts", "of", "speech", ",", "which", "can", "be", "useful", "when", "searching", "the", "Web", "or", "an", "electronic", "medical", "record", "."], "sentence-detokenized": "A set of Java programs uses the lexicon to process variations in biomedical texts by linking words by their parts of speech, which can be useful when searching the Web or an electronic medical record.", "token2charspan": [[0, 1], [2, 5], [6, 8], [9, 13], [14, 22], [23, 27], [28, 31], [32, 39], [40, 42], [43, 50], [51, 61], [62, 64], [65, 75], [76, 81], [82, 84], [85, 92], [93, 98], [99, 101], [102, 107], [108, 113], [114, 116], [117, 123], [123, 124], [125, 130], [131, 134], [135, 137], [138, 144], [145, 149], [150, 159], [160, 163], [164, 167], [168, 170], [171, 173], [174, 184], [185, 192], [193, 199], [199, 200]]}
{"doc_key": "ai-test-70", "ner": [[8, 8, "algorithm"], [10, 10, "algorithm"], [12, 12, "algorithm"], [14, 14, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "many", "newer", "algorithms", ",", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", "and", "others", "."], "sentence-detokenized": "There are many newer algorithms, such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost and others.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 20], [21, 31], [31, 32], [33, 37], [38, 40], [41, 48], [48, 49], [50, 60], [60, 61], [62, 72], [72, 73], [74, 81], [81, 82], [83, 92], [93, 96], [97, 103], [103, 104]]}
{"doc_key": "ai-test-71", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "sample", "implementation", "in", "Python", ":"], "sentence-detokenized": "This is a sample implementation in Python:", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 31], [32, 34], [35, 41], [41, 42]]}
{"doc_key": "ai-test-72", "ner": [[3, 3, "organisation"], [5, 5, "product"], [10, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 3, 3, "artifact", "made_by_company", false, false], [10, 13, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1982", ",", "Mattel", "'s", "Intellivision", "game", "console", "offered", "the", "Intellivoice", "Voice", "Synthesis", "module", "."], "sentence-detokenized": "In 1982, Mattel's Intellivision game console offered the Intellivoice Voice Synthesis module.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [15, 17], [18, 31], [32, 36], [37, 44], [45, 52], [53, 56], [57, 69], [70, 75], [76, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-test-73", "ner": [[5, 8, "task"], [10, 17, "task"], [19, 20, "field"], [22, 24, "task"], [28, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 17, 5, 8, "part-of", "", false, false], [19, 20, 5, 8, "part-of", "", false, false], [22, 24, 5, 8, "part-of", "", false, false], [28, 32, 22, 24, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "has", "also", "worked", "on", "machine", "translation", ",", "both", "on", "high", "-", "precision", "knowledge", "-", "based", "MT", "and", "on", "machine", "learning", "for", "statistical", "machine", "translation", "(", "e.g.", ",", "MT", "based", "on", "generalized", "examples", ")", "."], "sentence-detokenized": "He has also worked on machine translation, both on high-precision knowledge-based MT and on machine learning for statistical machine translation (e.g., MT based on generalized examples).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 21], [22, 29], [30, 41], [41, 42], [43, 47], [48, 50], [51, 55], [55, 56], [56, 65], [66, 75], [75, 76], [76, 81], [82, 84], [85, 88], [89, 91], [92, 99], [100, 108], [109, 112], [113, 124], [125, 132], [133, 144], [145, 146], [146, 150], [150, 151], [152, 154], [155, 160], [161, 163], [164, 175], [176, 184], [184, 185], [185, 186]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [7, 7, "misc"], [21, 22, "algorithm"], [24, 25, "field"], [27, 28, "field"], [30, 30, "field"], [32, 33, "field"], [35, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 21, 22, "general-affiliation", "", false, false], [0, 1, 24, 25, "general-affiliation", "", false, false], [0, 1, 27, 28, "general-affiliation", "", false, false], [0, 1, 30, 30, "general-affiliation", "", false, false], [0, 1, 32, 33, "general-affiliation", "", false, false], [0, 1, 35, 35, "general-affiliation", "", false, false], [7, 7, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "commonly", "referred", "to", "as", "Mathematica", ")", "is", "an", "advanced", "technical", "computing", "system", "covering", "most", "technical", "areas", "-", "including", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "data", "science", ",", "visualizations", ",", "and", "more", "."], "sentence-detokenized": "Wolfram Mathematica (commonly referred to as Mathematica) is an advanced technical computing system covering most technical areas - including neural networks, machine learning, image processing, geometry, data science, visualizations, and more.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 29], [30, 38], [39, 41], [42, 44], [45, 56], [56, 57], [58, 60], [61, 63], [64, 72], [73, 82], [83, 92], [93, 99], [100, 108], [109, 113], [114, 123], [124, 129], [130, 131], [132, 141], [142, 148], [149, 157], [157, 158], [159, 166], [167, 175], [175, 176], [177, 182], [183, 193], [193, 194], [195, 203], [203, 204], [205, 209], [210, 217], [217, 218], [219, 233], [233, 234], [235, 238], [239, 243], [243, 244]]}
{"doc_key": "ai-test-75", "ner": [[2, 7, "product"], [10, 11, "researcher"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 2, 7, "type-of", "", false, false], [17, 17, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "digitally", "controlled", "and", "programmable", "robot", "was", "invented", "by", "George", "Devoll", "in", "1954", "and", "eventually", "named", "Unimate", "."], "sentence-detokenized": "The first digitally controlled and programmable robot was invented by George Devoll in 1954 and eventually named Unimate.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 30], [31, 34], [35, 47], [48, 53], [54, 57], [58, 66], [67, 69], [70, 76], [77, 83], [84, 86], [87, 91], [92, 95], [96, 106], [107, 112], [113, 120], [120, 121]]}
{"doc_key": "ai-test-76", "ner": [[1, 1, "algorithm"], [3, 3, "algorithm"], [18, 19, "task"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 3, 3, "compare", "", false, false], [3, 3, 18, 19, "general-affiliation", "", false, false], [3, 3, 21, 23, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Like", "DBNs", ",", "DBMs", "can", "learn", "complex", "and", "abstract", "internal", "representations", "of", "input", "data", "in", "tasks", "such", "as", "object", "recognition", "or", "speech", "recognition", "by", "using", "constrained", ",", "labeled", "data", "to", "refine", "representations", "built", "using", "a", "large", "set", "of", "unlabeled", "sensor", "input", "data", "."], "sentence-detokenized": "Like DBNs, DBMs can learn complex and abstract internal representations of input data in tasks such as object recognition or speech recognition by using constrained, labeled data to refine representations built using a large set of unlabeled sensor input data.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 15], [16, 19], [20, 25], [26, 33], [34, 37], [38, 46], [47, 55], [56, 71], [72, 74], [75, 80], [81, 85], [86, 88], [89, 94], [95, 99], [100, 102], [103, 109], [110, 121], [122, 124], [125, 131], [132, 143], [144, 146], [147, 152], [153, 164], [164, 165], [166, 173], [174, 178], [179, 181], [182, 188], [189, 204], [205, 210], [211, 216], [217, 218], [219, 224], [225, 228], [229, 231], [232, 241], [242, 248], [249, 254], [255, 259], [259, 260]]}
{"doc_key": "ai-test-77", "ner": [[7, 14, "task"], [15, 15, "conference"], [17, 17, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 7, 14, "topic", "", false, false], [17, 17, 7, 14, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "scientific", "conferences", "at", "which", "developments", "on", "vision", "-", "based", "activity", "recognition", "often", "appear", "are", "ICCV", "and", "CVPR", "."], "sentence-detokenized": "The scientific conferences at which developments on vision-based activity recognition often appear are ICCV and CVPR.", "token2charspan": [[0, 3], [4, 14], [15, 26], [27, 29], [30, 35], [36, 48], [49, 51], [52, 58], [58, 59], [59, 64], [65, 73], [74, 85], [86, 91], [92, 98], [99, 102], [103, 107], [108, 111], [112, 116], [116, 117]]}
{"doc_key": "ai-test-78", "ner": [[1, 1, "field"], [4, 5, "algorithm"], [7, 7, "algorithm"], [16, 17, "metrics"], [19, 21, "metrics"], [23, 23, "metrics"], [37, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 5, 1, 1, "part-of", "", false, false], [4, 5, 16, 17, "related-to", "finds", false, false], [4, 5, 19, 21, "related-to", "finds", false, false], [4, 5, 37, 38, "related-to", "", false, false], [7, 7, 4, 5, "named", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "statistics", ",", "the", "expectation", "maximization", "(", "EM", ")", "algorithm", "is", "an", "iterative", "method", "for", "finding", "maximum", "likelihood", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "estimates", "of", "parameters", "in", "statistical", "models", "where", "the", "model", "depends", "on", "unobserved", "hidden", "variables", "."], "sentence-detokenized": "In statistics, the expectation maximization (EM) algorithm is an iterative method for finding maximum likelihood or maximum a posteriori (MAP) estimates of parameters in statistical models where the model depends on unobserved hidden variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 30], [31, 43], [44, 45], [45, 47], [47, 48], [49, 58], [59, 61], [62, 64], [65, 74], [75, 81], [82, 85], [86, 93], [94, 101], [102, 112], [113, 115], [116, 123], [124, 125], [126, 136], [137, 138], [138, 141], [141, 142], [143, 152], [153, 155], [156, 166], [167, 169], [170, 181], [182, 188], [189, 194], [195, 198], [199, 204], [205, 212], [213, 215], [216, 226], [227, 233], [234, 243], [243, 244]]}
{"doc_key": "ai-test-79", "ner": [[5, 7, "metrics"], [9, 13, "metrics"], [14, 16, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 13, 5, 7, "named", "", false, false], [18, 18, 14, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Similarly", ",", "investigators", "sometimes", "report", "false", "positive", "rates", "(", "FPRs", ")", "as", "well", "as", "false", "negative", "rates", "(", "FNRs", ")", "."], "sentence-detokenized": "Similarly, investigators sometimes report false positive rates (FPRs) as well as false negative rates (FNRs).", "token2charspan": [[0, 9], [9, 10], [11, 24], [25, 34], [35, 41], [42, 47], [48, 56], [57, 62], [63, 64], [64, 68], [68, 69], [70, 72], [73, 77], [78, 80], [81, 86], [87, 95], [96, 101], [102, 103], [103, 107], [107, 108], [108, 109]]}
{"doc_key": "ai-test-80", "ner": [[6, 12, "metrics"], [15, 16, "field"], [19, 21, "metrics"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 16, 6, 12, "usage", "", false, false], [23, 24, 19, 21, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "concept", "is", "similar", "to", "the", "signal", "-", "to", "-", "noise", "ratio", "used", "in", "the", "natural", "sciences", "and", "the", "confusion", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "The concept is similar to the signal-to-noise ratio used in the natural sciences and the confusion matrix used in artificial intelligence.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 25], [26, 29], [30, 36], [36, 37], [37, 39], [39, 40], [40, 45], [46, 51], [52, 56], [57, 59], [60, 63], [64, 71], [72, 80], [81, 84], [85, 88], [89, 98], [99, 105], [106, 110], [111, 113], [114, 124], [125, 137], [137, 138]]}
{"doc_key": "ai-test-81", "ner": [[5, 8, "field"], [13, 14, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [33, 39, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 8, 13, 14, "general-affiliation", "", false, false], [5, 8, 20, 21, "general-affiliation", "", false, false], [5, 8, 23, 24, "general-affiliation", "", false, false], [33, 39, 5, 8, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Code", "of", "Ethics", "for", "Human", "Augmentations", ",", "which", "was", "originally", "introduced", "by", "Steve", "Mann", "in", "2004", "and", "refined", "by", "Ray", "Kurzweil", "and", "Marvin", "Minsky", "in", "2013", ",", "was", "finally", "ratified", "at", "the", "Virtual", "Reality", "Conference", "in", "Toronto", "on", "June", "25", ",", "2017", "."], "sentence-detokenized": "The Code of Ethics for Human Augmentations, which was originally introduced by Steve Mann in 2004 and refined by Ray Kurzweil and Marvin Minsky in 2013, was finally ratified at the Virtual Reality Conference in Toronto on June 25, 2017.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 18], [19, 22], [23, 28], [29, 42], [42, 43], [44, 49], [50, 53], [54, 64], [65, 75], [76, 78], [79, 84], [85, 89], [90, 92], [93, 97], [98, 101], [102, 109], [110, 112], [113, 116], [117, 125], [126, 129], [130, 136], [137, 143], [144, 146], [147, 151], [151, 152], [153, 156], [157, 164], [165, 173], [174, 176], [177, 180], [181, 188], [189, 196], [197, 207], [208, 210], [211, 218], [219, 221], [222, 226], [227, 229], [229, 230], [231, 235], [235, 236]]}
{"doc_key": "ai-test-82", "ner": [[3, 5, "person"], [12, 15, "organisation"], [19, 20, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 12, 15, "role", "directed_for", false, false], [3, 5, 19, 20, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", ".", "Walter", "R.", "Booth", "directed", "10", "films", "for", "the", "British", "company", "Kinoplastikon", ",", "probably", "in", "collaboration", "with", "Cecil", "Hepworth", "."], "sentence-detokenized": "In 1913. Walter R. Booth directed 10 films for the British company Kinoplastikon, probably in collaboration with Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 18], [19, 24], [25, 33], [34, 36], [37, 42], [43, 46], [47, 50], [51, 58], [59, 66], [67, 80], [80, 81], [82, 90], [91, 93], [94, 107], [108, 112], [113, 118], [119, 127], [127, 128]]}
{"doc_key": "ai-test-83", "ner": [[14, 15, "location"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "introduced", "their", "new", "robot", "in", "1961", "at", "a", "trade", "show", "at", "Chicago", "'s", "Cow", "Palace", "."], "sentence-detokenized": "They introduced their new robot in 1961 at a trade show at Chicago's Cow Palace.", "token2charspan": [[0, 4], [5, 15], [16, 21], [22, 25], [26, 31], [32, 34], [35, 39], [40, 42], [43, 44], [45, 50], [51, 55], [56, 58], [59, 66], [66, 68], [69, 72], [73, 79], [79, 80]]}
{"doc_key": "ai-test-84", "ner": [[2, 2, "product"], [6, 8, "task"], [10, 11, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 6, 8, "usage", "", false, false], [2, 2, 10, 11, "usage", "", false, false], [2, 2, 17, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["While", "some", "chatbot", "applications", "use", "extensive", "word", "classification", "processes", ",", "natural", "language", "processing", "engines", ",", "and", "advanced", "artificial", "intelligence", ",", "others", "simply", "scan", "for", "common", "keywords", "and", "generate", "responses", "using", "common", "phrases", "derived", "from", "a", "linked", "library", "or", "database", "."], "sentence-detokenized": "While some chatbot applications use extensive word classification processes, natural language processing engines, and advanced artificial intelligence, others simply scan for common keywords and generate responses using common phrases derived from a linked library or database.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 31], [32, 35], [36, 45], [46, 50], [51, 65], [66, 75], [75, 76], [77, 84], [85, 93], [94, 104], [105, 112], [112, 113], [114, 117], [118, 126], [127, 137], [138, 150], [150, 151], [152, 158], [159, 165], [166, 170], [171, 174], [175, 181], [182, 190], [191, 194], [195, 203], [204, 213], [214, 219], [220, 226], [227, 234], [235, 242], [243, 247], [248, 249], [250, 256], [257, 264], [265, 267], [268, 276], [276, 277]]}
{"doc_key": "ai-test-85", "ner": [[1, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "WaveNet", "model", "proposed", "in", "2016", "achieves", "excellent", "results", "in", "terms", "of", "speech", "quality", "."], "sentence-detokenized": "The WaveNet model proposed in 2016 achieves excellent results in terms of speech quality.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 43], [44, 53], [54, 61], [62, 64], [65, 70], [71, 73], [74, 80], [81, 88], [88, 89]]}
{"doc_key": "ai-test-86", "ner": [[4, 4, "product"], [6, 7, "misc"], [9, 10, "misc"], [12, 13, "misc"], [17, 17, "misc"], [19, 21, "organisation"], [23, 23, "organisation"], [25, 28, "organisation"], [30, 30, "organisation"], [32, 35, "organisation"], [37, 38, "organisation"], [40, 40, "organisation"], [42, 44, "organisation"], [47, 47, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 4, 6, 7, "general-affiliation", "", false, false], [4, 4, 9, 10, "general-affiliation", "", false, false], [4, 4, 12, 13, "general-affiliation", "", false, false], [4, 4, 17, 17, "general-affiliation", "", false, false], [19, 21, 4, 4, "usage", "", false, false], [23, 23, 4, 4, "usage", "", false, false], [25, 28, 4, 4, "usage", "", false, false], [30, 30, 4, 4, "usage", "", false, false], [32, 35, 4, 4, "usage", "", false, false], [37, 38, 4, 4, "usage", "", false, false], [40, 40, 4, 4, "usage", "", false, false], [42, 44, 4, 4, "usage", "", false, false], [47, 47, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organizations", "known", "to", "use", "ALE", "for", "emergency", "management", ",", "disaster", "relief", ",", "simple", "communication", ",", "or", "emergency", "response", ":", "American", "Red", "Cross", ",", "FEMA", ",", "Disaster", "Medical", "Assistance", "Teams", ",", "NATO", ",", "Federal", "Bureau", "of", "Investigation", ",", "United", "Nations", ",", "AT&T", ",", "Civil", "Air", "Patrol", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organizations known to use ALE for emergency management, disaster relief, simple communication, or emergency response: American Red Cross, FEMA, Disaster Medical Assistance Teams, NATO, Federal Bureau of Investigation, United Nations, AT&T, Civil Air Patrol, (ARES).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 30], [31, 34], [35, 44], [45, 55], [55, 56], [57, 65], [66, 72], [72, 73], [74, 80], [81, 94], [94, 95], [96, 98], [99, 108], [109, 117], [117, 118], [119, 127], [128, 131], [132, 137], [137, 138], [139, 143], [143, 144], [145, 153], [154, 161], [162, 172], [173, 178], [178, 179], [180, 184], [184, 185], [186, 193], [194, 200], [201, 203], [204, 217], [217, 218], [219, 225], [226, 233], [233, 234], [235, 239], [239, 240], [241, 246], [247, 250], [251, 257], [257, 258], [259, 260], [260, 264], [264, 265], [265, 266]]}
{"doc_key": "ai-test-87", "ner": [[0, 7, "algorithm"], [14, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Kronecker", "delta", "is", "used", "here", "for", "simplicity", "(", "see", "the", "derivative", "of", "a", "sigmoid", "function", ",", "which", "is", "expressed", "by", "the", "function", "itself", ")", "."], "sentence-detokenized": "The Kronecker delta is used here for simplicity (see the derivative of a sigmoid function, which is expressed by the function itself).", "token2charspan": [[0, 3], [4, 13], [14, 19], [20, 22], [23, 27], [28, 32], [33, 36], [37, 47], [48, 49], [49, 52], [53, 56], [57, 67], [68, 70], [71, 72], [73, 80], [81, 89], [89, 90], [91, 96], [97, 99], [100, 109], [110, 112], [113, 116], [117, 125], [126, 132], [132, 133], [133, 134]]}
{"doc_key": "ai-test-88", "ner": [[11, 12, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "theory", "is", "based", "on", "philosophical", "foundations", "and", "was", "created", "by", "Ray", "Solomonov", "around", "1960", ",", "Samuel", "Ratmaner", "and", "Markus", "Hutter", "."], "sentence-detokenized": "The theory is based on philosophical foundations and was created by Ray Solomonov around 1960, Samuel Ratmaner and Markus Hutter.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 36], [37, 48], [49, 52], [53, 56], [57, 64], [65, 67], [68, 71], [72, 81], [82, 88], [89, 93], [93, 94], [95, 101], [102, 110], [111, 114], [115, 121], [122, 128], [128, 129]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [10, 11, "misc"], [14, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 11, "type-of", "", false, false], [0, 0, 14, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "a", "freely", "accessible", "database", "originally", "conceived", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "has", "been", "extended", "by", "adding", "definitions", "and", "is", "now", "also", "considered", "as", "a", "dictionary", "."], "sentence-detokenized": "WordNet, a freely accessible database originally conceived as a semantic network based on psycholinguistic principles, has been extended by adding definitions and is now also considered as a dictionary.", "token2charspan": [[0, 7], [7, 8], [9, 10], [11, 17], [18, 28], [29, 37], [38, 48], [49, 58], [59, 61], [62, 63], [64, 72], [73, 80], [81, 86], [87, 89], [90, 106], [107, 117], [117, 118], [119, 122], [123, 127], [128, 136], [137, 139], [140, 146], [147, 158], [159, 162], [163, 165], [166, 169], [170, 174], [175, 185], [186, 188], [189, 190], [191, 201], [201, 202]]}
{"doc_key": "ai-test-90", "ner": [[5, 6, "field"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Advances", "in", "the", "field", "of", "computer", "imaging", "research", "are", "presented", "in", "several", "places", ",", "including", "SIGGRAPH", "publications", "and", "on", "."], "sentence-detokenized": "Advances in the field of computer imaging research are presented in several places, including SIGGRAPH publications and on.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 21], [22, 24], [25, 33], [34, 41], [42, 50], [51, 54], [55, 64], [65, 67], [68, 75], [76, 82], [82, 83], [84, 93], [94, 102], [103, 115], [116, 119], [120, 122], [122, 123]]}
{"doc_key": "ai-test-91", "ner": [[0, 1, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 1, "part-of", "", false, false], [12, 13, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "viewed", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multi-class", "classification", "."], "sentence-detokenized": "Classification can be viewed as two separate problems - binary classification and multi-class classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 28], [29, 31], [32, 35], [36, 44], [45, 53], [54, 55], [56, 62], [63, 77], [78, 81], [82, 93], [94, 108], [108, 109]]}
{"doc_key": "ai-test-92", "ner": [[14, 14, "algorithm"], [19, 20, "algorithm"], [23, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 20, 14, 14, "type-of", "", false, false], [23, 23, 19, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Advanced", "gene", "-", "finding", "devices", "for", "both", "prokaryotic", "and", "eukaryotic", "genomes", "typically", "use", "complex", "probabilistic", "models", ",", "such", "as", "hidden", "Markov", "models", "(", "HMMs", ")", ",", "to", "combine", "information", "from", "different", "signal", "and", "content", "measurements", "."], "sentence-detokenized": "Advanced gene-finding devices for both prokaryotic and eukaryotic genomes typically use complex probabilistic models, such as hidden Markov models (HMMs), to combine information from different signal and content measurements.", "token2charspan": [[0, 8], [9, 13], [13, 14], [14, 21], [22, 29], [30, 33], [34, 38], [39, 50], [51, 54], [55, 65], [66, 73], [74, 83], [84, 87], [88, 95], [96, 109], [110, 116], [116, 117], [118, 122], [123, 125], [126, 132], [133, 139], [140, 146], [147, 148], [148, 152], [152, 153], [153, 154], [155, 157], [158, 165], [166, 177], [178, 182], [183, 192], [193, 199], [200, 203], [204, 211], [212, 224], [224, 225]]}
{"doc_key": "ai-test-93", "ner": [[0, 0, "misc"], [2, 2, "misc"], [7, 9, "field"], [11, 13, "algorithm"], [15, 16, "algorithm"], [19, 19, "algorithm"], [30, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 7, 9, "part-of", "", false, false], [0, 0, 11, 13, "usage", "", false, false], [2, 2, 0, 0, "named", "", false, false], [15, 16, 0, 0, "origin", "", true, false], [19, 19, 15, 16, "named", "", false, false], [30, 31, 0, 0, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Neuroevolution", "or", "neuroevolution", "is", "a", "form", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "generate", "artificial", "neural", "networks", "(", "ANNs", ")", ".", "parameters", ".", "topology", ".", "and", "rules", ".", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuroevolution or neuroevolution is a form of artificial intelligence that uses evolutionary algorithms to generate artificial neural networks (ANNs). parameters. topology. and rules. and evolutionary robotics.", "token2charspan": [[0, 14], [15, 17], [18, 32], [33, 35], [36, 37], [38, 42], [43, 45], [46, 56], [57, 69], [70, 74], [75, 79], [80, 92], [93, 103], [104, 106], [107, 115], [116, 126], [127, 133], [134, 142], [143, 144], [144, 148], [148, 149], [149, 150], [151, 161], [161, 162], [163, 171], [171, 172], [173, 176], [177, 182], [182, 183], [184, 187], [188, 200], [201, 209], [209, 210]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [6, 7, "metrics"], [9, 9, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["After", "IBM", "proposed", "and", "implemented", "the", "BLEU", "system", ",", "Papineni", "et", "al", "."], "sentence-detokenized": "After IBM proposed and implemented the BLEU system, Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 34], [35, 38], [39, 43], [44, 50], [50, 51], [52, 60], [61, 63], [64, 66], [66, 67]]}
{"doc_key": "ai-test-95", "ner": [[10, 17, "conference"], [19, 21, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 21, 10, 17, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "experts", "participated", "in", "a", "conference", "organized", "by", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "to", "discuss", "whether", "computers", "and", "robots", "can", "gain", "some", "autonomy", "and", "to", "what", "extent", "these", "capabilities", "may", "pose", "a", "threat", "or", "danger", "."], "sentence-detokenized": "In 2009, experts participated in a conference organized by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether computers and robots can gain some autonomy and to what extent these capabilities may pose a threat or danger.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 29], [30, 32], [33, 34], [35, 45], [46, 55], [56, 58], [59, 62], [63, 74], [75, 78], [79, 82], [83, 94], [95, 97], [98, 108], [109, 121], [122, 123], [123, 127], [127, 128], [129, 131], [132, 139], [140, 147], [148, 157], [158, 161], [162, 168], [169, 172], [173, 177], [178, 182], [183, 191], [192, 195], [196, 198], [199, 203], [204, 210], [211, 216], [217, 229], [230, 233], [234, 238], [239, 240], [241, 247], [248, 250], [251, 257], [257, 258]]}
{"doc_key": "ai-test-96", "ner": [[23, 24, "researcher"], [26, 27, "researcher"], [29, 34, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[29, 34, 23, 24, "artifact", "", false, false], [29, 34, 26, 27, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["After", "boosting", ",", "a", "classifier", "built", "from", "200", "features", "can", "give", "a", "95", "%", "detection", "rate", "at", "^", "{", "-", "5", "}", "/", "P.", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "After boosting, a classifier built from 200 features can give a 95% detection rate at ^ {-5} / P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 17], [18, 28], [29, 34], [35, 39], [40, 43], [44, 52], [53, 56], [57, 61], [62, 63], [64, 66], [66, 67], [68, 77], [78, 82], [83, 85], [86, 87], [88, 89], [89, 90], [90, 91], [91, 92], [93, 94], [95, 97], [98, 103], [103, 104], [105, 107], [108, 113], [113, 114], [115, 121], [122, 126], [126, 127], [127, 131], [132, 138], [139, 148], [148, 149], [150, 154], [154, 155]]}
{"doc_key": "ai-test-97", "ner": [[4, 6, "programlang"], [12, 12, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "website", "was", "originally", "Perl", "-", "based", ",", "but", "for", "security", "reasons", "IMDb", "no", "longer", "discloses", "what", "software", "it", "uses", "."], "sentence-detokenized": "The website was originally Perl-based, but for security reasons IMDb no longer discloses what software it uses.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 26], [27, 31], [31, 32], [32, 37], [37, 38], [39, 42], [43, 46], [47, 55], [56, 63], [64, 68], [69, 71], [72, 78], [79, 88], [89, 93], [94, 102], [103, 105], [106, 110], [110, 111]]}
{"doc_key": "ai-test-98", "ner": [[5, 6, "researcher"], [8, 9, "researcher"], [11, 12, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "startup", "was", "founded", "by", "Demis", "Hasabis", ",", "Shane", "Legg", "and", "Mustafa", "Suleiman", "in", "2010", "."], "sentence-detokenized": "The startup was founded by Demis Hasabis, Shane Legg and Mustafa Suleiman in 2010.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 32], [33, 40], [40, 41], [42, 47], [48, 52], [53, 56], [57, 64], [65, 73], [74, 76], [77, 81], [81, 82]]}
{"doc_key": "ai-test-99", "ner": [[4, 5, "misc"], [8, 10, "metrics"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 4, 5, "type-of", "", false, false], [22, 23, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "very", "commonly", "used", "loss", "functions", "are", "the", "mean", "squared", "error", ",", "mathL", "(", "a", ")", "=", "a^2", "/math", ",", "and", "the", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/math", "."], "sentence-detokenized": "Two very commonly used loss functions are the mean squared error, mathL(a) = a^2/math, and the absolute loss, mathL(a) = |a |/math.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 27], [28, 37], [38, 41], [42, 45], [46, 50], [51, 58], [59, 64], [64, 65], [66, 71], [71, 72], [72, 73], [73, 74], [75, 76], [77, 80], [80, 85], [85, 86], [87, 90], [91, 94], [95, 103], [104, 108], [108, 109], [110, 115], [115, 116], [116, 117], [117, 118], [119, 120], [121, 122], [122, 123], [124, 125], [125, 130], [130, 131]]}
{"doc_key": "ai-test-100", "ner": [[2, 5, "algorithm"], [12, 14, "algorithm"], [16, 18, "algorithm"], [19, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 5, 12, 14, "type-of", "example_of", false, false], [12, 14, 19, 20, "related-to", "", false, false], [16, 18, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "soft", "-margin", "support", "vector", "machine", "described", "above", "is", "an", "example", "of", "empirical", "risk", "minimization", "(", "ERM", ")", "for", "hinge", "loss", "."], "sentence-detokenized": "The soft-margin support vector machine described above is an example of empirical risk minimization (ERM) for hinge loss.", "token2charspan": [[0, 3], [4, 8], [8, 15], [16, 23], [24, 30], [31, 38], [39, 48], [49, 54], [55, 57], [58, 60], [61, 68], [69, 71], [72, 81], [82, 86], [87, 99], [100, 101], [101, 104], [104, 105], [106, 109], [110, 115], [116, 120], [120, 121]]}
{"doc_key": "ai-test-101", "ner": [[5, 8, "field"], [11, 11, "task"], [0, 2, "task"], [22, 22, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 8, "origin", "", false, false], [0, 2, 11, 11, "type-of", "", false, false], [22, 22, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Neural", "machine", "translation", ",", "a", "deep", "learning", "-", "based", "approach", "to", "MT", ",", "has", "made", "rapid", "progress", "in", "recent", "years", ",", "and", "Google", "has", "announced", "that", "its", "translation", "services", "now", "use", "this", "technology", "instead", "of", "previous", "statistical", "methods", "."], "sentence-detokenized": "Neural machine translation, a deep learning-based approach to MT, has made rapid progress in recent years, and Google has announced that its translation services now use this technology instead of previous statistical methods.", "token2charspan": [[0, 6], [7, 14], [15, 26], [26, 27], [28, 29], [30, 34], [35, 43], [43, 44], [44, 49], [50, 58], [59, 61], [62, 64], [64, 65], [66, 69], [70, 74], [75, 80], [81, 89], [90, 92], [93, 99], [100, 105], [105, 106], [107, 110], [111, 117], [118, 121], [122, 131], [132, 136], [137, 140], [141, 152], [153, 161], [162, 165], [166, 169], [170, 174], [175, 185], [186, 193], [194, 196], [197, 205], [206, 217], [218, 225], [225, 226]]}
{"doc_key": "ai-test-102", "ner": [[15, 15, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "usually", "results", "in", "a", "very", "large", "performance", "gain", "when", "working", "with", "large", "corpora", "like", "WordNet", "."], "sentence-detokenized": "This usually results in a very large performance gain when working with large corpora like WordNet.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 23], [24, 25], [26, 30], [31, 36], [37, 48], [49, 53], [54, 58], [59, 66], [67, 71], [72, 77], [78, 85], [86, 90], [91, 98], [98, 99]]}
{"doc_key": "ai-test-103", "ner": [[0, 3, "task"], [5, 7, "field"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 16, 18, "part-of", "", false, false], [16, 18, 5, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Facial", "recognition", "is", "used", "in", "biometrics", ",", "often", "as", "part", "of", "(", "or", "alongside", ")", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Facial recognition is used in biometrics, often as part of (or alongside) a facial recognition system.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 26], [27, 29], [30, 40], [40, 41], [42, 47], [48, 50], [51, 55], [56, 58], [59, 60], [60, 62], [63, 72], [72, 73], [74, 75], [76, 82], [83, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-104", "ner": [[2, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["trained", "by", "maximum", "likelihood", "estimation", "."], "sentence-detokenized": "trained by maximum likelihood estimation.", "token2charspan": [[0, 7], [8, 10], [11, 18], [19, 29], [30, 40], [40, 41]]}
{"doc_key": "ai-test-105", "ner": [[3, 3, "country"], [5, 9, "organisation"], [13, 13, "location"], [15, 15, "country"], [17, 20, "organisation"], [22, 24, "country"], [28, 28, "organisation"], [33, 35, "organisation"], [37, 37, "country"], [49, 52, "organisation"], [54, 54, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 9, 13, 13, "physical", "", false, false], [13, 13, 15, 15, "physical", "", false, false], [17, 20, 22, 24, "physical", "", false, false], [33, 35, 37, 37, "physical", "", false, false], [49, 52, 54, 54, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd", ".", "in", "Thailand", ";", "Komatsu", "(", "Shanghai", ")", "Ltd.", "in", "1996", "in", "Shanghai", ",", "China", ";", "Industrial", "Power", "Alliance", "Ltd.", "in", "Japan", ",", "a", "joint", "venture", "with", "Cummins", ",", "in", "1998", ";", "L&T-", "Komatsu", "Limited", "in", "India", "in", "1998", "(", "shares", "were", "sold", "in", "2013", ")", ";", "and", "Komatsu", "Brasil", "International", "Ltda.", "in", "Brazil", "in", "1998", "."], "sentence-detokenized": "Ltd. in Thailand; Komatsu (Shanghai) Ltd. in 1996 in Shanghai, China; Industrial Power Alliance Ltd. in Japan, a joint venture with Cummins, in 1998; L&T-Komatsu Limited in India in 1998 (shares were sold in 2013); and Komatsu Brasil International Ltda. in Brazil in 1998.", "token2charspan": [[0, 3], [3, 4], [5, 7], [8, 16], [16, 17], [18, 25], [26, 27], [27, 35], [35, 36], [37, 41], [42, 44], [45, 49], [50, 52], [53, 61], [61, 62], [63, 68], [68, 69], [70, 80], [81, 86], [87, 95], [96, 100], [101, 103], [104, 109], [109, 110], [111, 112], [113, 118], [119, 126], [127, 131], [132, 139], [139, 140], [141, 143], [144, 148], [148, 149], [150, 154], [154, 161], [162, 169], [170, 172], [173, 178], [179, 181], [182, 186], [187, 188], [188, 194], [195, 199], [200, 204], [205, 207], [208, 212], [212, 213], [213, 214], [215, 218], [219, 226], [227, 233], [234, 247], [248, 253], [254, 256], [257, 263], [264, 266], [267, 271], [271, 272]]}
{"doc_key": "ai-test-106", "ner": [[0, 1, "organisation"], [4, 8, "misc"], [10, 10, "misc"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 13, 0, 1, "physical", "", false, false], [12, 13, 4, 8, "general-affiliation", "", false, false], [12, 13, 10, 10, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["dgp", "also", "occasionally", "hosts", "artists", "in", "residence", "(", "such", "as", "Oscar", "winner", "Chris", "Landreth", ")", "."], "sentence-detokenized": "dgp also occasionally hosts artists in residence (such as Oscar winner Chris Landreth).", "token2charspan": [[0, 3], [4, 8], [9, 21], [22, 27], [28, 35], [36, 38], [39, 48], [49, 50], [50, 54], [55, 57], [58, 63], [64, 70], [71, 76], [77, 85], [85, 86], [86, 87]]}
{"doc_key": "ai-test-107", "ner": [[7, 9, "misc"], [12, 14, "misc"], [17, 20, "misc"], [24, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "currently", "includes", "four", "sub-competitions", "-", "the", "RoboMaster", "Robotics", "Competition", ",", "the", "RoboMaster", "Technical", "Challenge", ",", "the", "ICRA", "RoboMaster", "AI", "Challenge", "and", "the", "new", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "It currently includes four sub-competitions - the RoboMaster Robotics Competition, the RoboMaster Technical Challenge, the ICRA RoboMaster AI Challenge and the new RoboMaster Youth Tournament.", "token2charspan": [[0, 2], [3, 12], [13, 21], [22, 26], [27, 43], [44, 45], [46, 49], [50, 60], [61, 69], [70, 81], [81, 82], [83, 86], [87, 97], [98, 107], [108, 117], [117, 118], [119, 122], [123, 127], [128, 138], [139, 141], [142, 151], [152, 155], [156, 159], [160, 163], [164, 174], [175, 180], [181, 191], [191, 192]]}
{"doc_key": "ai-test-108", "ner": [[7, 7, "field"], [16, 18, "algorithm"], [22, 23, "algorithm"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 22, 23, "usage", "", false, false], [7, 7, 25, 26, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "the", "early", "2000s", ",", "the", "dominant", "speech", "processing", "strategy", "began", "to", "shift", "away", "from", "the", "hidden", "Markov", "model", "to", "more", "advanced", "neural", "networks", "and", "deep", "learning", "."], "sentence-detokenized": "In the early 2000s, the dominant speech processing strategy began to shift away from the hidden Markov model to more advanced neural networks and deep learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 18], [18, 19], [20, 23], [24, 32], [33, 39], [40, 50], [51, 59], [60, 65], [66, 68], [69, 74], [75, 79], [80, 84], [85, 88], [89, 95], [96, 102], [103, 108], [109, 111], [112, 116], [117, 125], [126, 132], [133, 141], [142, 145], [146, 150], [151, 159], [159, 160]]}
{"doc_key": "ai-test-109", "ner": [[8, 10, "misc"], [14, 16, "metrics"], [19, 21, "metrics"], [27, 30, "metrics"], [33, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 16, 19, 21, "related-to", "equal", false, false], [27, 30, 33, 35, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "equivalent", "expression", "in", "the", "case", "of", "a", "binary", "target", "norm", "is", "that", "the", "true", "positive", "norm", "and", "the", "false", "positive", "norm", "are", "equal", "(", "and", "therefore", "the", "false", "negative", "norm", "and", "the", "true", "negative", "norm", "are", "equal", ")", "for", "each", "value", "of", "the", "sensitive", "features", ":"], "sentence-detokenized": "Another equivalent expression in the case of a binary target norm is that the true positive norm and the false positive norm are equal (and therefore the false negative norm and the true negative norm are equal) for each value of the sensitive features:", "token2charspan": [[0, 7], [8, 18], [19, 29], [30, 32], [33, 36], [37, 41], [42, 44], [45, 46], [47, 53], [54, 60], [61, 65], [66, 68], [69, 73], [74, 77], [78, 82], [83, 91], [92, 96], [97, 100], [101, 104], [105, 110], [111, 119], [120, 124], [125, 128], [129, 134], [135, 136], [136, 139], [140, 149], [150, 153], [154, 159], [160, 168], [169, 173], [174, 177], [178, 181], [182, 186], [187, 195], [196, 200], [201, 204], [205, 210], [210, 211], [212, 215], [216, 220], [221, 226], [227, 229], [230, 233], [234, 243], [244, 252], [252, 253]]}
{"doc_key": "ai-test-110", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "MATLAB", "function", ","], "sentence-detokenized": "The MATLAB function,", "token2charspan": [[0, 3], [4, 10], [11, 19], [19, 20]]}
{"doc_key": "ai-test-111", "ner": [[0, 2, "product"], [7, 10, "misc"], [14, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 0, 2, "part-of", "", false, false], [14, 15, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "articulated", "robot", "is", "a", "robot", "with", "rotating", "joints", "(", "e.g.", "a", "leg", "or", "industrial", "robot", ")", "."], "sentence-detokenized": "An articulated robot is a robot with rotating joints (e.g. a leg or industrial robot).", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 23], [24, 25], [26, 31], [32, 36], [37, 45], [46, 52], [53, 54], [54, 58], [59, 60], [61, 64], [65, 67], [68, 78], [79, 84], [84, 85], [85, 86]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [5, 6, "product"], [8, 9, "product"], [12, 13, "misc"], [20, 22, "product"], [25, 28, "misc"], [32, 32, "location"], [34, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 12, 13, "general-affiliation", "nationality", false, false], [0, 0, 25, 28, "usage", "", false, false], [0, 0, 32, 32, "physical", "", false, false], [5, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [32, 32, 34, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "also", "known", "as", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "an", "American", "Internet", "radio", "music", "streaming", "service", "and", "automated", "recommendation", "system", "powered", "by", "the", "Music", "Genome", "Project", ",", "based", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (also known as Pandora Media or Pandora Radio) is an American Internet radio music streaming service and automated recommendation system powered by the Music Genome Project, based in Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 30], [31, 36], [37, 39], [40, 47], [48, 53], [53, 54], [55, 57], [58, 60], [61, 69], [70, 78], [79, 84], [85, 90], [91, 100], [101, 108], [109, 112], [113, 122], [123, 137], [138, 144], [145, 152], [153, 155], [156, 159], [160, 165], [166, 172], [173, 180], [180, 181], [182, 187], [188, 190], [191, 198], [198, 199], [200, 210], [210, 211]]}
{"doc_key": "ai-test-113", "ner": [[11, 16, "organisation"], [20, 22, "organisation"], [28, 28, "conference"], [42, 42, "conference"], [44, 44, "conference"], [46, 46, "conference"], [48, 48, "conference"], [50, 50, "conference"], [52, 52, "conference"], [54, 54, "conference"], [56, 56, "conference"], [58, 58, "conference"], [61, 61, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "member", "of", "the", "Board", "of", "Directors", "of", "the", "International", "Machine", "Learning", "Society", ",", "a", "member", "of", "the", "AAAI", "Executive", "Board", ",", "co-chair", "of", "the", "2011", "ICML", "SC", ",", "and", "has", "served", "as", "a", "senior", "SC", "member", "of", "conferences", "including", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", ",", "and", "WWW", "."], "sentence-detokenized": "She is a member of the Board of Directors of the International Machine Learning Society, a member of the AAAI Executive Board, co-chair of the 2011 ICML SC, and has served as a senior SC member of conferences including AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM, and WWW.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 15], [16, 18], [19, 22], [23, 28], [29, 31], [32, 41], [42, 44], [45, 48], [49, 62], [63, 70], [71, 79], [80, 87], [87, 88], [89, 90], [91, 97], [98, 100], [101, 104], [105, 109], [110, 119], [120, 125], [125, 126], [127, 135], [136, 138], [139, 142], [143, 147], [148, 152], [153, 155], [155, 156], [157, 160], [161, 164], [165, 171], [172, 174], [175, 176], [177, 183], [184, 186], [187, 193], [194, 196], [197, 208], [209, 218], [219, 223], [223, 224], [225, 229], [229, 230], [231, 236], [236, 237], [238, 242], [242, 243], [244, 247], [247, 248], [249, 255], [255, 256], [257, 260], [260, 261], [262, 266], [266, 267], [268, 272], [272, 273], [274, 277], [278, 281], [281, 282]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [5, 10, "organisation"], [12, 12, "organisation"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 10, "role", "", false, false], [12, 12, 5, 10, "named", "", false, false], [15, 17, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "developed", "Robocrane", ",", "where", "the", "platform", "hangs", "from", "six", "cables", "instead", "of", "being", "supported", "by", "six", "sockets", "."], "sentence-detokenized": "James S. Albus of the National Institute of Standards and Technology (NIST) developed Robocrane, where the platform hangs from six cables instead of being supported by six sockets.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [74, 75], [76, 85], [86, 95], [95, 96], [97, 102], [103, 106], [107, 115], [116, 121], [122, 126], [127, 130], [131, 137], [138, 145], [146, 148], [149, 154], [155, 164], [165, 167], [168, 171], [172, 179], [179, 180]]}
{"doc_key": "ai-test-115", "ner": [[3, 5, "algorithm"], [9, 10, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 3, 5, "type-of", "", false, false], [13, 14, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "class", "of", "direct", "search", "algorithms", "are", "the", "various", "evolutionary", "algorithms", ",", "e.g.", "genetic", "algorithms", "."], "sentence-detokenized": "Another class of direct search algorithms are the various evolutionary algorithms, e.g. genetic algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 23], [24, 30], [31, 41], [42, 45], [46, 49], [50, 57], [58, 70], [71, 81], [81, 82], [83, 87], [88, 95], [96, 106], [106, 107]]}
{"doc_key": "ai-test-116", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 0, 0, "named", "", false, false], [6, 7, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "industrial", "robots", "and", "factory", "automation", "solutions", "."], "sentence-detokenized": "KUKA is a German manufacturer of industrial robots and factory automation solutions.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-117", "ner": [[9, 9, "misc"], [12, 13, "person"], [14, 21, "misc"], [23, 24, "person"], [25, 26, "misc"], [28, 29, "person"], [31, 32, "misc"], [34, 35, "person"], [36, 39, "misc"], [41, 43, "person"], [44, 48, "misc"], [50, 54, "person"], [53, 56, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[12, 13, 9, 9, "usage", "", false, false], [14, 21, 12, 13, "artifact", "", false, false], [23, 24, 9, 9, "usage", "", false, false], [25, 26, 23, 24, "artifact", "", false, false], [28, 29, 9, 9, "usage", "", false, false], [31, 32, 28, 29, "artifact", "", false, false], [34, 35, 9, 9, "usage", "", false, false], [36, 39, 34, 35, "artifact", "", false, false], [41, 43, 9, 9, "usage", "", false, false], [44, 48, 41, 43, "artifact", "", false, false], [50, 54, 9, 9, "usage", "", false, false], [53, 56, 50, 54, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Other", "films", "between", "2016", "and", "2020", "shot", "with", "the", "IMAX", "camera", "include", "Zack", "Snyder", "'s", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", ",", "Clint", "Eastwood", "'s", "Sully", ",", "Damien", "Chazelle", "'s", "First", "Man", ",", "Patty", "Jenkins", "'", "Wonder", "Woman", "1984", ",", "Carrie", "Joji", "Fukunaga", "'s", "No", "Time", "to", "Die", "and", "Joseph", "Kosinski", "'s", "Top", "Gun", ":", "Maverick", "."], "sentence-detokenized": "Other films between 2016 and 2020 shot with the IMAX camera include Zack Snyder's Batman v Superman: Dawn of Justice, Clint Eastwood's Sully, Damien Chazelle's First Man, Patty Jenkins' Wonder Woman 1984, Carrie Joji Fukunaga's No Time to Die and Joseph Kosinski's Top Gun: Maverick.", "token2charspan": [[0, 5], [6, 11], [12, 19], [20, 24], [25, 28], [29, 33], [34, 38], [39, 43], [44, 47], [48, 52], [53, 59], [60, 67], [68, 72], [73, 79], [79, 81], [82, 88], [89, 90], [91, 99], [99, 100], [101, 105], [106, 108], [109, 116], [116, 117], [118, 123], [124, 132], [132, 134], [135, 140], [140, 141], [142, 148], [149, 157], [157, 159], [160, 165], [166, 169], [169, 170], [171, 176], [177, 184], [184, 185], [186, 192], [193, 198], [199, 203], [203, 204], [205, 211], [212, 216], [217, 225], [225, 227], [228, 230], [231, 235], [236, 238], [239, 242], [243, 246], [247, 253], [254, 262], [262, 264], [265, 268], [269, 272], [272, 273], [274, 282], [282, 283]]}
{"doc_key": "ai-test-118", "ner": [[5, 6, "misc"], [12, 14, "organisation"], [16, 16, "organisation"], [29, 29, "misc"], [36, 37, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 29, 29, "named", "", false, false], [12, 14, 5, 6, "usage", "", false, false], [12, 14, 36, 37, "physical", "", false, false], [16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "trial", "version", "of", "the", "MICR", "E13B", "font", "was", "shown", "to", "the", "American", "Bankers", "Association", "(", "ABA", ")", "in", "July", "1956", ",", "which", "adopted", "it", "in", "1958", "as", "the", "MICR", "standard", "for", "negotiable", "documents", "in", "the", "United", "States", "."], "sentence-detokenized": "A trial version of the MICR E13B font was shown to the American Bankers Association (ABA) in July 1956, which adopted it in 1958 as the MICR standard for negotiable documents in the United States.", "token2charspan": [[0, 1], [2, 7], [8, 15], [16, 18], [19, 22], [23, 27], [28, 32], [33, 37], [38, 41], [42, 47], [48, 50], [51, 54], [55, 63], [64, 71], [72, 83], [84, 85], [85, 88], [88, 89], [90, 92], [93, 97], [98, 102], [102, 103], [104, 109], [110, 117], [118, 120], [121, 123], [124, 128], [129, 131], [132, 135], [136, 140], [141, 149], [150, 153], [154, 164], [165, 174], [175, 177], [178, 181], [182, 188], [189, 195], [195, 196]]}
{"doc_key": "ai-test-119", "ner": [[0, 2, "misc"], [16, 17, "field"], [20, 21, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [32, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[16, 17, 0, 2, "usage", "", false, false], [20, 21, 16, 17, "part-of", "", false, false], [24, 24, 0, 2, "usage", "", false, false], [26, 27, 0, 2, "usage", "", false, false], [29, 29, 0, 2, "usage", "", false, false], [32, 32, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "have", "been", "widely", "applied", "to", "many", "difficult", "computational", "problems", ",", "including", "problems", "in", "computer", "science", "(", "particularly", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", ",", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms have been widely applied to many difficult computational problems, including problems in computer science (particularly artificial intelligence), mathematics, operations research, engineering, and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 28], [29, 33], [34, 40], [41, 48], [49, 51], [52, 56], [57, 66], [67, 80], [81, 89], [89, 90], [91, 100], [101, 109], [110, 112], [113, 121], [122, 129], [130, 131], [131, 143], [144, 154], [155, 167], [167, 168], [168, 169], [170, 181], [181, 182], [183, 193], [194, 202], [202, 203], [204, 215], [215, 216], [217, 220], [221, 235], [235, 236]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [9, 9, "location"], [11, 11, "country"], [15, 15, "country"], [22, 23, "algorithm"], [25, 25, "algorithm"], [28, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 9, 9, "physical", "", false, false], [0, 1, 15, 15, "general-affiliation", "nationality", false, false], [0, 1, 22, 23, "general-affiliation", "topic_of_study", false, false], [0, 1, 25, 25, "general-affiliation", "topic_of_study", false, false], [9, 9, 11, 11, "physical", "", false, false], [25, 25, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "born", "September", "3", ",", "1947", "in", "Walersdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "studies", "the", "use", "of", "bounded", "rationality", "and", "heuristics", "in", "decision", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (born September 3, 1947 in Walersdorf, Germany) is a German psychologist who studies the use of bounded rationality and heuristics in decision making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 21], [22, 31], [32, 33], [33, 34], [35, 39], [40, 42], [43, 53], [53, 54], [55, 62], [62, 63], [64, 66], [67, 68], [69, 75], [76, 88], [89, 92], [93, 100], [101, 104], [105, 108], [109, 111], [112, 119], [120, 131], [132, 135], [136, 146], [147, 149], [150, 158], [159, 165], [165, 166]]}
{"doc_key": "ai-test-121", "ner": [[3, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["to", "minimize", "the", "mean", "squared", "error", "."], "sentence-detokenized": "to minimize the mean squared error.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [21, 28], [29, 34], [34, 35]]}
{"doc_key": "ai-test-122", "ner": [[12, 13, "misc"], [16, 17, "organisation"], [32, 36, "field"], [49, 50, "misc"], [59, 61, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 16, 17, "origin", "", false, false], [49, 50, 59, 61, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["But", "even", "an", "official", "language", "with", "a", "regulatory", "academy", ",", "such", "as", "standard", "French", "with", "the", "French", "Academy", ",", "qualifies", "as", "a", "natural", "language", "(", "for", "example", ",", "in", "the", "field", "of", "natural", "language", "processing", ")", "because", "its", "prescriptions", "make", "it", "neither", "sufficiently", "constructed", "to", "be", "classified", "as", "a", "constructed", "language", "nor", "sufficiently", "controlled", "to", "be", "classified", "as", "a", "controlled", "natural", "language", "."], "sentence-detokenized": "But even an official language with a regulatory academy, such as standard French with the French Academy, qualifies as a natural language (for example, in the field of natural language processing) because its prescriptions make it neither sufficiently constructed to be classified as a constructed language nor sufficiently controlled to be classified as a controlled natural language.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 20], [21, 29], [30, 34], [35, 36], [37, 47], [48, 55], [55, 56], [57, 61], [62, 64], [65, 73], [74, 80], [81, 85], [86, 89], [90, 96], [97, 104], [104, 105], [106, 115], [116, 118], [119, 120], [121, 128], [129, 137], [138, 139], [139, 142], [143, 150], [150, 151], [152, 154], [155, 158], [159, 164], [165, 167], [168, 175], [176, 184], [185, 195], [195, 196], [197, 204], [205, 208], [209, 222], [223, 227], [228, 230], [231, 238], [239, 251], [252, 263], [264, 266], [267, 269], [270, 280], [281, 283], [284, 285], [286, 297], [298, 306], [307, 310], [311, 323], [324, 334], [335, 337], [338, 340], [341, 351], [352, 354], [355, 356], [357, 367], [368, 375], [376, 384], [384, 385]]}
{"doc_key": "ai-test-123", "ner": [[14, 14, "metrics"], [16, 17, "metrics"], [19, 22, "metrics"], [38, 39, "metrics"], [41, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 22, 16, 17, "named", "", false, false], [41, 41, 38, 39, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "a", "number", "of", "other", "metrics", ",", "the", "simplest", "of", "which", "is", "the", "accuracy", "or", "Fraction", "Correct", "(", "FC", ")", ",", "which", "measures", "the", "fraction", "of", "all", "cases", "that", "are", "correctly", "categorized", ";", "the", "complement", "is", "the", "Fraction", "Incorrect", "(", "FiC", ")", "."], "sentence-detokenized": "There are a number of other metrics, the simplest of which is the accuracy or Fraction Correct (FC), which measures the fraction of all cases that are correctly categorized; the complement is the Fraction Incorrect (FiC).", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 18], [19, 21], [22, 27], [28, 35], [35, 36], [37, 40], [41, 49], [50, 52], [53, 58], [59, 61], [62, 65], [66, 74], [75, 77], [78, 86], [87, 94], [95, 96], [96, 98], [98, 99], [99, 100], [101, 106], [107, 115], [116, 119], [120, 128], [129, 131], [132, 135], [136, 141], [142, 146], [147, 150], [151, 160], [161, 172], [172, 173], [174, 177], [178, 188], [189, 191], [192, 195], [196, 204], [205, 214], [215, 216], [216, 219], [219, 220], [220, 221]]}
{"doc_key": "ai-test-124", "ner": [[3, 3, "researcher"], [9, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 9, 12, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2016", ",", "Cardi", "became", "a", "member", "of", "the", "Association", "for", "Computational", "Linguistics", "."], "sentence-detokenized": "In 2016, Cardi became a member of the Association for Computational Linguistics.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 21], [22, 23], [24, 30], [31, 33], [34, 37], [38, 49], [50, 53], [54, 67], [68, 79], [79, 80]]}
{"doc_key": "ai-test-125", "ner": [[12, 30, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Learning", "the", "math", "\\", "theta", "/", "math", "parameters", "is", "usually", "done", "by", "learning", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";\\", "theta", ")", "/", "math", "as", "plausibly", "as", "possible", "."], "sentence-detokenized": "Learning the math\\ theta / math parameters is usually done by learning mathp (Y _ i | X _ i;\\ theta) / math as plausibly as possible.", "token2charspan": [[0, 8], [9, 12], [13, 17], [17, 18], [19, 24], [25, 26], [27, 31], [32, 42], [43, 45], [46, 53], [54, 58], [59, 61], [62, 70], [71, 76], [77, 78], [78, 79], [80, 81], [82, 83], [84, 85], [86, 87], [88, 89], [90, 91], [91, 93], [94, 99], [99, 100], [101, 102], [103, 107], [108, 110], [111, 120], [121, 123], [124, 132], [132, 133]]}
{"doc_key": "ai-test-126", "ner": [[0, 1, "task"], [3, 6, "algorithm"], [8, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 0, 1, "usage", "", true, false], [8, 10, 3, 6, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cluster", "analysis", "and", "factorization", "of", "nonnegative", "matrices", "for", "descriptive", "information", "extraction", "."], "sentence-detokenized": "Cluster analysis and factorization of nonnegative matrices for descriptive information extraction.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 34], [35, 37], [38, 49], [50, 58], [59, 62], [63, 74], [75, 86], [87, 97], [97, 98]]}
{"doc_key": "ai-test-127", "ner": [[4, 5, "field"], [8, 12, "field"], [26, 28, "field"], [30, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[26, 28, 4, 5, "part-of", "", false, false], [26, 28, 8, 12, "part-of", "", false, false], [30, 31, 4, 5, "part-of", "", false, false], [30, 31, 8, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "field", "of", "computer", "science", "and", "the", "information", "technology", "that", "it", "enables", ",", "a", "long", "-", "term", "challenge", "is", "the", "ability", "of", "computers", "to", "perform", "natural", "language", "processing", "and", "machine", "learning", "."], "sentence-detokenized": "In the field of computer science and the information technology that it enables, a long-term challenge is the ability of computers to perform natural language processing and machine learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 24], [25, 32], [33, 36], [37, 40], [41, 52], [53, 63], [64, 68], [69, 71], [72, 79], [79, 80], [81, 82], [83, 87], [87, 88], [88, 92], [93, 102], [103, 105], [106, 109], [110, 117], [118, 120], [121, 130], [131, 133], [134, 141], [142, 149], [150, 158], [159, 169], [170, 173], [174, 181], [182, 190], [190, 191]]}
{"doc_key": "ai-test-128", "ner": [[3, 6, "algorithm"], [7, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 6, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "Code", "for", "extracting", "Gabor", "features", "from", "MATLAB", "images", "can", "be", "found", "at"], "sentence-detokenized": "(Code for extracting Gabor features from MATLAB images can be found at", "token2charspan": [[0, 1], [1, 5], [6, 9], [10, 20], [21, 26], [27, 35], [36, 40], [41, 47], [48, 54], [55, 58], [59, 61], [62, 67], [68, 70]]}
{"doc_key": "ai-test-129", "ner": [[0, 0, "misc"], [13, 14, "algorithm"], [18, 18, "task"], [20, 20, "task"], [22, 23, "task"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 13, 14, "general-affiliation", "", false, false], [0, 0, 18, 18, "related-to", "solves_problem_of_type", false, false], [0, 0, 20, 20, "related-to", "solves_problem_of_type", false, false], [0, 0, 22, 23, "related-to", "solves_problem_of_type", false, false], [0, 0, 26, 27, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["NeuralExpert", "focuses", "design", "specifications", "on", "the", "type", "of", "problem", "the", "user", "wants", "the", "neural", "network", "to", "solve", "(", "classification", ",", "prediction", ",", "feature", "approximation", ",", "or", "cluster", "analysis", ")", "."], "sentence-detokenized": "NeuralExpert focuses design specifications on the type of problem the user wants the neural network to solve (classification, prediction, feature approximation, or cluster analysis).", "token2charspan": [[0, 12], [13, 20], [21, 27], [28, 42], [43, 45], [46, 49], [50, 54], [55, 57], [58, 65], [66, 69], [70, 74], [75, 80], [81, 84], [85, 91], [92, 99], [100, 102], [103, 108], [109, 110], [110, 124], [124, 125], [126, 136], [136, 137], [138, 145], [146, 159], [159, 160], [161, 163], [164, 171], [172, 180], [180, 181], [181, 182]]}
{"doc_key": "ai-test-130", "ner": [[1, 6, "misc"], [29, 32, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "size", "of", "the", "quantization", "step", "(", "\u0394", ")", "is", "small", "compared", "to", "the", "variation", "of", "the", "quantized", "signal", ",", "it", "is", "relatively", "easy", "to", "show", "that", "the", "mean", "squared", "error", "obtained", "from", "such", "a", "rounding", "operation", "will", "be", "approximately", "math", "\\", "Delta^2/12", "/math.math"], "sentence-detokenized": "When the size of the quantization step (\u0394) is small compared to the variation of the quantized signal, it is relatively easy to show that the mean squared error obtained from such a rounding operation will be approximately math\\Delta^2/12/math.math", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 20], [21, 33], [34, 38], [39, 40], [40, 41], [41, 42], [43, 45], [46, 51], [52, 60], [61, 63], [64, 67], [68, 77], [78, 80], [81, 84], [85, 94], [95, 101], [101, 102], [103, 105], [106, 108], [109, 119], [120, 124], [125, 127], [128, 132], [133, 137], [138, 141], [142, 146], [147, 154], [155, 160], [161, 169], [170, 174], [175, 179], [180, 181], [182, 190], [191, 200], [201, 205], [206, 208], [209, 222], [223, 227], [227, 228], [228, 238], [238, 248]]}
{"doc_key": "ai-test-131", "ner": [[15, 15, "product"], [25, 29, "researcher"], [31, 32, "researcher"], [34, 38, "researcher"], [40, 41, "researcher"], [43, 45, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Building", "a", "rich", "lexicon", "with", "an", "appropriate", "ontology", "requires", "significant", "effort", ",", "e.g.", ",", "the", "Wordnet", "lexicon", "required", "many", "man", "-", "years", "of", "effort", ".", "\u0413", ".", "\u0410", ".", "Miller", ",", "R.", "Beckwith", ",", "K", ".", "\u0414", ".", "Felbaum", ",", "D.", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "Building a rich lexicon with an appropriate ontology requires significant effort, e.g., the Wordnet lexicon required many man-years of effort. \u0413. \u0410. Miller, R. Beckwith, K. \u0414. Felbaum, D. Gross, K. Miller.", "token2charspan": [[0, 8], [9, 10], [11, 15], [16, 23], [24, 28], [29, 31], [32, 43], [44, 52], [53, 61], [62, 73], [74, 80], [80, 81], [82, 86], [86, 87], [88, 91], [92, 99], [100, 107], [108, 116], [117, 121], [122, 125], [125, 126], [126, 131], [132, 134], [135, 141], [141, 142], [143, 144], [144, 145], [146, 147], [147, 148], [149, 155], [155, 156], [157, 159], [160, 168], [168, 169], [170, 171], [171, 172], [173, 174], [174, 175], [176, 183], [183, 184], [185, 187], [188, 193], [193, 194], [195, 196], [196, 197], [198, 204], [204, 205]]}
{"doc_key": "ai-test-132", "ner": [[0, 0, "organisation"], [22, 24, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[22, 24, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kawasaki", "'s", "portfolio", "also", "includes", "retractable", "roofs", ",", "floors", "and", "other", "giant", "structures", ",", "an", "example", "being", "the", "retractable", "surface", "of", "the", "dome", "at", "Sapporo", "."], "sentence-detokenized": "Kawasaki's portfolio also includes retractable roofs, floors and other giant structures, an example being the retractable surface of the dome at Sapporo.", "token2charspan": [[0, 8], [8, 10], [11, 20], [21, 25], [26, 34], [35, 46], [47, 52], [52, 53], [54, 60], [61, 64], [65, 70], [71, 76], [77, 87], [87, 88], [89, 91], [92, 99], [100, 105], [106, 109], [110, 121], [122, 129], [130, 132], [133, 136], [137, 141], [142, 144], [145, 152], [152, 153]]}
{"doc_key": "ai-test-133", "ner": [[0, 1, "metrics"], [5, 7, "metrics"], [9, 11, "metrics"], [17, 18, "metrics"], [38, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 17, 18, "related-to", "", false, false], [0, 1, 38, 40, "opposite", "alternative_to", false, false], [5, 7, 0, 1, "type-of", "", false, false], [9, 11, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa", "statistics", ",", "such", "as", "Fleiss", "'s", "Kappa", "and", "Cohen", "'s", "Kappa", ",", "are", "methods", "for", "calculating", "inter-rater", "reliability", "based", "on", "different", "assumptions", "about", "marginal", "or", "prior", "distributions", ",", "and", "are", "increasingly", "used", "as", "alternatives", "to", "chance", "-", "adjusted", "accuracy", "in", "other", "contexts", "."], "sentence-detokenized": "Kappa statistics, such as Fleiss's Kappa and Cohen's Kappa, are methods for calculating inter-rater reliability based on different assumptions about marginal or prior distributions, and are increasingly used as alternatives to chance-adjusted accuracy in other contexts.", "token2charspan": [[0, 5], [6, 16], [16, 17], [18, 22], [23, 25], [26, 32], [32, 34], [35, 40], [41, 44], [45, 50], [50, 52], [53, 58], [58, 59], [60, 63], [64, 71], [72, 75], [76, 87], [88, 99], [100, 111], [112, 117], [118, 120], [121, 130], [131, 142], [143, 148], [149, 157], [158, 160], [161, 166], [167, 180], [180, 181], [182, 185], [186, 189], [190, 202], [203, 207], [208, 210], [211, 223], [224, 226], [227, 233], [233, 234], [234, 242], [243, 251], [252, 254], [255, 260], [261, 269], [269, 270]]}
{"doc_key": "ai-test-134", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [18, 18, "researcher"], [27, 29, "algorithm"], [31, 35, "algorithm"], [37, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 18, 18, "role", "student_of", false, false], [7, 8, 18, 18, "role", "student_of", false, false], [10, 11, 18, 18, "role", "student_of", false, false], [13, 14, 18, 18, "role", "student_of", false, false], [31, 35, 4, 5, "origin", "", false, false], [31, 35, 7, 8, "origin", "", false, false], [31, 35, 10, 11, "origin", "", false, false], [31, 35, 13, 14, "origin", "", false, false], [31, 35, 18, 18, "origin", "", false, false], [31, 35, 27, 29, "type-of", "", false, false], [37, 37, 31, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Along", "with", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "and", "others", ",", "Schmidhuber", "published", "increasingly", "sophisticated", "versions", "of", "a", "type", "of", "recurrent", "neural", "network", "called", "long", "short", "-", "term", "memory", "(", "LSTM", ")", "."], "sentence-detokenized": "Along with his students Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves and others, Schmidhuber published increasingly sophisticated versions of a type of recurrent neural network called long short-term memory (LSTM).", "token2charspan": [[0, 5], [6, 10], [11, 14], [15, 23], [24, 28], [29, 39], [39, 40], [41, 46], [47, 51], [51, 52], [53, 57], [58, 65], [65, 66], [67, 71], [72, 78], [79, 82], [83, 89], [89, 90], [91, 102], [103, 112], [113, 125], [126, 139], [140, 148], [149, 151], [152, 153], [154, 158], [159, 161], [162, 171], [172, 178], [179, 186], [187, 193], [194, 198], [199, 204], [204, 205], [205, 209], [210, 216], [217, 218], [218, 222], [222, 223], [223, 224]]}
{"doc_key": "ai-test-135", "ner": [[4, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "The", "first", "Cobot", "KUKA", "LBR", "3", "is", "released", "."], "sentence-detokenized": "2004 - The first Cobot KUKA LBR 3 is released.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 22], [23, 27], [28, 31], [32, 33], [34, 36], [37, 45], [45, 46]]}
{"doc_key": "ai-test-136", "ner": [[11, 13, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "superficial", "approaches", "used", "for", "training", "and", "posterior", "differentiation", "are", "the", "Naive", "Bayes", "classifier", "and", "decision", "trees", "."], "sentence-detokenized": "Two superficial approaches used for training and posterior differentiation are the Naive Bayes classifier and decision trees.", "token2charspan": [[0, 3], [4, 15], [16, 26], [27, 31], [32, 35], [36, 44], [45, 48], [49, 58], [59, 74], [75, 78], [79, 82], [83, 88], [89, 94], [95, 105], [106, 109], [110, 118], [119, 124], [124, 125]]}
{"doc_key": "ai-test-137", "ner": [[5, 6, "misc"], [12, 13, "person"], [15, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 12, 13, "origin", "", false, false], [5, 6, 15, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "practical", "forms", "of", "photography", "were", "introduced", "in", "January", "1839", "by", "Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "The first practical forms of photography were introduced in January 1839 by Louis Daguerre and Henry Fox Talbot.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 25], [26, 28], [29, 40], [41, 45], [46, 56], [57, 59], [60, 67], [68, 72], [73, 75], [76, 81], [82, 90], [91, 94], [95, 100], [101, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-138", "ner": [[3, 4, "task"], [7, 8, "task"], [15, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 15, 17, "part-of", "task_part_of_field", false, false], [7, 8, 15, 17, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "speech", "synthesis", "coupled", "with", "speech", "recognition", "enables", "interaction", "with", "mobile", "devices", "through", "speech", "processing", "interfaces", "."], "sentence-detokenized": "For example, speech synthesis coupled with speech recognition enables interaction with mobile devices through speech processing interfaces.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [30, 37], [38, 42], [43, 49], [50, 61], [62, 69], [70, 81], [82, 86], [87, 93], [94, 101], [102, 109], [110, 116], [117, 127], [128, 138], [138, 139]]}
{"doc_key": "ai-test-139", "ner": [[0, 2, "product"], [13, 13, "programlang"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 13, 13, "general-affiliation", "", false, false], [0, 2, 15, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Phidgets", "can", "be", "programmed", "using", "a", "variety", "of", "software", "and", "programming", "languages", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "Phidgets can be programmed using a variety of software and programming languages from Java to Microsoft Excel.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 26], [27, 32], [33, 34], [35, 42], [43, 45], [46, 54], [55, 58], [59, 70], [71, 80], [81, 85], [86, 90], [91, 93], [94, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-test-140", "ner": [[3, 6, "field"], [11, 12, "researcher"], [14, 17, "misc"], [24, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 11, 12, "origin", "", false, false], [11, 12, 24, 25, "general-affiliation", "topic_of_study", false, false], [11, 12, 27, 28, "general-affiliation", "topic_of_study", false, false], [14, 17, 11, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "\"", "machine", "learning", "\"", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "an", "American", "IBM", "employee", "and", "pioneer", "in", "the", "field", "of", "computer", "games", "and", "artificial", "intelligence", "."], "sentence-detokenized": "The term \"machine learning\" was coined in 1959 by Arthur Samuel, an American IBM employee and pioneer in the field of computer games and artificial intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 17], [18, 26], [26, 27], [28, 31], [32, 38], [39, 41], [42, 46], [47, 49], [50, 56], [57, 63], [63, 64], [65, 67], [68, 76], [77, 80], [81, 89], [90, 93], [94, 101], [102, 104], [105, 108], [109, 114], [115, 117], [118, 126], [127, 132], [133, 136], [137, 147], [148, 160], [160, 161]]}
{"doc_key": "ai-test-141", "ner": [[0, 1, "misc"], [2, 3, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Israeli", "poet", "David", "Avidan", ",", "who", "is", "fascinated", "by", "future", "technology", "and", "its", "relationship", "to", "art", ",", "wants", "to", "explore", "the", "use", "of", "computers", "to", "write", "literature", "."], "sentence-detokenized": "Israeli poet David Avidan, who is fascinated by future technology and its relationship to art, wants to explore the use of computers to write literature.", "token2charspan": [[0, 7], [8, 12], [13, 18], [19, 25], [25, 26], [27, 30], [31, 33], [34, 44], [45, 47], [48, 54], [55, 65], [66, 69], [70, 73], [74, 86], [87, 89], [90, 93], [93, 94], [95, 100], [101, 103], [104, 111], [112, 115], [116, 119], [120, 122], [123, 132], [133, 135], [136, 141], [142, 152], [152, 153]]}
{"doc_key": "ai-test-142", "ner": [[4, 5, "misc"], [9, 9, "organisation"], [15, 17, "location"], [28, 31, "location"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[9, 9, 4, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "part", "of", "the", "GATEway", "project", "in", "2017", ",", "Oxbotica", "trialled", "seven", "autonomous", "buses", "in", "Greenwich", ",", "which", "run", "along", "the", "two", "-", "kilometre", "promenade", "near", "London", "'s", "O2", "Arena", "on", "a", "route", "also", "used", "by", "pedestrians", "and", "cyclists", "."], "sentence-detokenized": "As part of the GATEway project in 2017, Oxbotica trialled seven autonomous buses in Greenwich, which run along the two-kilometre promenade near London's O2 Arena on a route also used by pedestrians and cyclists.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 30], [31, 33], [34, 38], [38, 39], [40, 48], [49, 57], [58, 63], [64, 74], [75, 80], [81, 83], [84, 93], [93, 94], [95, 100], [101, 104], [105, 110], [111, 114], [115, 118], [118, 119], [119, 128], [129, 138], [139, 143], [144, 150], [150, 152], [153, 155], [156, 161], [162, 164], [165, 166], [167, 172], [173, 177], [178, 182], [183, 185], [186, 197], [198, 201], [202, 210], [210, 211]]}
{"doc_key": "ai-test-143", "ner": [[8, 9, "task"], [12, 16, "metrics"], [23, 24, "misc"], [26, 26, "metrics"], [28, 28, "metrics"], [31, 31, "metrics"], [33, 33, "metrics"], [35, 37, "metrics"], [40, 40, "metrics"], [42, 42, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[12, 16, 23, 24, "related-to", "is_a", false, false], [12, 16, 26, 26, "usage", "", false, false], [12, 16, 28, 28, "usage", "", false, false], [26, 26, 31, 31, "named", "same", false, false], [28, 28, 42, 42, "named", "same", false, false], [31, 31, 40, 40, "opposite", "", false, false], [31, 31, 42, 42, "opposite", "", false, false], [33, 33, 31, 31, "named", "", false, false], [35, 37, 31, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["An", "unrelated", "but", "commonly", "used", "combination", "of", "basic", "information", "retrieval", "statistics", "is", "F", "-", "score", ",", "which", "is", "a", "(", "possibly", "weighted", ")", "harmonic", "mean", "of", "recall", "and", "precision", ",", "where", "recall", "=", "sensitivity", "=", "TRUE", "positive", "rate", ",", "but", "specificity", "and", "precision", "are", "completely", "different", "measures", "."], "sentence-detokenized": "An unrelated but commonly used combination of basic information retrieval statistics is F-score, which is a (possibly weighted) harmonic mean of recall and precision, where recall = sensitivity = TRUE positive rate, but specificity and precision are completely different measures.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 25], [26, 30], [31, 42], [43, 45], [46, 51], [52, 63], [64, 73], [74, 84], [85, 87], [88, 89], [89, 90], [90, 95], [95, 96], [97, 102], [103, 105], [106, 107], [108, 109], [109, 117], [118, 126], [126, 127], [128, 136], [137, 141], [142, 144], [145, 151], [152, 155], [156, 165], [165, 166], [167, 172], [173, 179], [180, 181], [182, 193], [194, 195], [196, 200], [201, 209], [210, 214], [214, 215], [216, 219], [220, 231], [232, 235], [236, 245], [246, 249], [250, 260], [261, 270], [271, 279], [279, 280]]}
{"doc_key": "ai-test-144", "ner": [[0, 1, "field"], [10, 10, "field"], [12, 12, "field"], [14, 14, "field"], [16, 17, "field"], [20, 22, "field"], [30, 31, "product"], [33, 36, "product"], [38, 39, "product"], [42, 45, "product"], [56, 58, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 10, "origin", "takes_inspiration_from", false, false], [0, 1, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 1, 14, 14, "origin", "takes_inspiration_from", false, false], [0, 1, 16, 17, "origin", "takes_inspiration_from", false, false], [0, 1, 20, 22, "origin", "takes_inspiration_from", false, false], [30, 31, 0, 1, "origin", "", false, false], [33, 36, 0, 1, "origin", "", false, false], [38, 39, 0, 1, "origin", "", false, false], [42, 45, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "is", "an", "interdisciplinary", "discipline", "that", "draws", "inspiration", "from", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", ",", "and", "electronic", "engineering", "to", "design", "artificial", "neural", "systems", ",", "such", "as", "vision", "systems", ",", "head", "-", "eye", "systems", ",", "auditory", "processors", ",", "and", "autonomous", "robots", ",", "whose", "physical", "architecture", "and", "design", "principles", "are", "based", "on", "those", "of", "biological", "nervous", "systems", "."], "sentence-detokenized": "Neuromorphic engineering is an interdisciplinary discipline that draws inspiration from biology, physics, mathematics, computer science, and electronic engineering to design artificial neural systems, such as vision systems, head-eye systems, auditory processors, and autonomous robots, whose physical architecture and design principles are based on those of biological nervous systems.", "token2charspan": [[0, 12], [13, 24], [25, 27], [28, 30], [31, 48], [49, 59], [60, 64], [65, 70], [71, 82], [83, 87], [88, 95], [95, 96], [97, 104], [104, 105], [106, 117], [117, 118], [119, 127], [128, 135], [135, 136], [137, 140], [141, 151], [152, 163], [164, 166], [167, 173], [174, 184], [185, 191], [192, 199], [199, 200], [201, 205], [206, 208], [209, 215], [216, 223], [223, 224], [225, 229], [229, 230], [230, 233], [234, 241], [241, 242], [243, 251], [252, 262], [262, 263], [264, 267], [268, 278], [279, 285], [285, 286], [287, 292], [293, 301], [302, 314], [315, 318], [319, 325], [326, 336], [337, 340], [341, 346], [347, 349], [350, 355], [356, 358], [359, 369], [370, 377], [378, 385], [385, 386]]}
{"doc_key": "ai-test-145", "ner": [[3, 5, "metrics"], [8, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 8, 3, 5, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Specifically", ",", "the", "BIBO", "stability", "criterion", "requires", "the", "ROC", "of", "the", "system", "to", "include", "the", "unit", "circle", "."], "sentence-detokenized": "Specifically, the BIBO stability criterion requires the ROC of the system to include the unit circle.", "token2charspan": [[0, 12], [12, 13], [14, 17], [18, 22], [23, 32], [33, 42], [43, 51], [52, 55], [56, 59], [60, 62], [63, 66], [67, 73], [74, 76], [77, 84], [85, 88], [89, 93], [94, 100], [100, 101]]}
{"doc_key": "ai-test-146", "ner": [[7, 9, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "The", "program", "has", "been", "rewritten", "in", "Java", "since", "1998", "."], "sentence-detokenized": "2 The program has been rewritten in Java since 1998.", "token2charspan": [[0, 1], [2, 5], [6, 13], [14, 17], [18, 22], [23, 32], [33, 35], [36, 40], [41, 46], [47, 51], [51, 52]]}
{"doc_key": "ai-test-147", "ner": [[0, 1, "metrics"], [8, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 8, 11, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "MCC", "can", "be", "calculated", "directly", "from", "the", "confusion", "matrix", "using", "the", "formula", ":"], "sentence-detokenized": "The MCC can be calculated directly from the confusion matrix using the formula:", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 25], [26, 34], [35, 39], [40, 43], [44, 53], [54, 60], [61, 66], [67, 70], [71, 78], [78, 79]]}
{"doc_key": "ai-test-148", "ner": [[8, 14, "organisation"], [21, 26, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 14, 21, 26, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "developed", "by", "a", "team", "in", "the", "MIT", "-", "IBM", "Watson", "Artificial", "Intelligence", "Lab", "and", "was", "first", "presented", "at", "the", "2018", "International", "Conference", "on", "Learning", "Representations", "."], "sentence-detokenized": "It was developed by a team in the MIT-IBM Watson Artificial Intelligence Lab and was first presented at the 2018 International Conference on Learning Representations.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 29], [30, 33], [34, 37], [37, 38], [38, 41], [42, 48], [49, 59], [60, 72], [73, 76], [77, 80], [81, 84], [85, 90], [91, 100], [101, 103], [104, 107], [108, 112], [113, 126], [127, 137], [138, 140], [141, 149], [150, 165], [165, 166]]}
{"doc_key": "ai-test-149", "ner": [[2, 5, "metrics"], [15, 15, "metrics"], [17, 23, "metrics"], [48, 48, "metrics"], [50, 50, "metrics"], [55, 57, "metrics"], [60, 60, "metrics"], [62, 62, "metrics"], [65, 67, "metrics"], [72, 72, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[15, 15, 48, 48, "type-of", "", false, false], [15, 15, 55, 57, "related-to", "collapses_to_identity", false, false], [17, 23, 50, 50, "type-of", "", false, false], [17, 23, 55, 57, "related-to", "collapses_to_identity", false, false], [17, 23, 65, 67, "named", "same", false, false], [60, 60, 72, 72, "related-to", "collapses_to_identity", false, false], [62, 62, 72, 72, "related-to", "collapses_to_identity", false, false], [65, 67, 72, 72, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["When", "the", "TRUE", "distributions", "for", "the", "two", "positive", "variables", "are", "equal", ",", "as", "assumed", "in", "kappa", "and", "F", "-", "score", ",", "i.e.", ",", "the", "number", "of", "positive", "predictors", "matches", "the", "number", "of", "positive", "classes", "in", "the", "dichotomous", "(", "two", "-", "class", ")", "case", ",", "the", "various", "measures", "of", "kappa", "and", "correlation", "collapse", "to", "identity", "with", "Youden", "'s", "J", ",", "and", "recall", ",", "precision", ",", "and", "F", "-", "score", "are", "similarly", "identical", "to", "precision", "."], "sentence-detokenized": "When the TRUE distributions for the two positive variables are equal, as assumed in kappa and F-score, i.e., the number of positive predictors matches the number of positive classes in the dichotomous (two-class) case, the various measures of kappa and correlation collapse to identity with Youden's J, and recall, precision, and F-score are similarly identical to precision.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 27], [28, 31], [32, 35], [36, 39], [40, 48], [49, 58], [59, 62], [63, 68], [68, 69], [70, 72], [73, 80], [81, 83], [84, 89], [90, 93], [94, 95], [95, 96], [96, 101], [101, 102], [103, 107], [107, 108], [109, 112], [113, 119], [120, 122], [123, 131], [132, 142], [143, 150], [151, 154], [155, 161], [162, 164], [165, 173], [174, 181], [182, 184], [185, 188], [189, 200], [201, 202], [202, 205], [205, 206], [206, 211], [211, 212], [213, 217], [217, 218], [219, 222], [223, 230], [231, 239], [240, 242], [243, 248], [249, 252], [253, 264], [265, 273], [274, 276], [277, 285], [286, 290], [291, 297], [297, 299], [300, 301], [301, 302], [303, 306], [307, 313], [313, 314], [315, 324], [324, 325], [326, 329], [330, 331], [331, 332], [332, 337], [338, 341], [342, 351], [352, 361], [362, 364], [365, 374], [374, 375]]}
{"doc_key": "ai-test-150", "ner": [[0, 7, "misc"], [5, 5, "misc"], [9, 9, "conference"], [14, 17, "task"], [18, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 7, 9, 9, "part-of", "", false, false], [0, 7, 9, 9, "physical", "", false, false], [0, 7, 9, 9, "temporal", "", false, false], [5, 5, 0, 7, "named", "", false, false], [14, 17, 0, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Building", "Educational", "Applications", "(", "BEA", ")", "workshop", "at", "NAACL", "2013", "hosted", "the", "first", "NLI", "shared", "task", ".", "Tetreault", "et", "al", ",", "2013", "The", "competition", "resulted", "in", "29", "submissions", "from", "teams", "around", "the", "world", ",", "24", "of", "which", "also", "published", "a", "paper", "describing", "their", "systems", "and", "approaches", "."], "sentence-detokenized": "The Building Educational Applications (BEA) workshop at NAACL 2013 hosted the first NLI shared task. Tetreault et al, 2013 The competition resulted in 29 submissions from teams around the world, 24 of which also published a paper describing their systems and approaches.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 37], [38, 39], [39, 42], [42, 43], [44, 52], [53, 55], [56, 61], [62, 66], [67, 73], [74, 77], [78, 83], [84, 87], [88, 94], [95, 99], [99, 100], [101, 110], [111, 113], [114, 116], [116, 117], [118, 122], [123, 126], [127, 138], [139, 147], [148, 150], [151, 153], [154, 165], [166, 170], [171, 176], [177, 183], [184, 187], [188, 193], [193, 194], [195, 197], [198, 200], [201, 206], [207, 211], [212, 221], [222, 223], [224, 229], [230, 240], [241, 246], [247, 254], [255, 258], [259, 269], [269, 270]]}
{"doc_key": "ai-test-151", "ner": [[0, 2, "algorithm"], [5, 8, "algorithm"], [15, 16, "misc"], [20, 23, "misc"], [37, 38, "misc"], [41, 42, "algorithm"], [45, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 5, 8, "type-of", "", false, false], [0, 2, 15, 16, "related-to", "finds", false, false], [20, 23, 15, 16, "type-of", "", false, false], [45, 45, 41, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Viterbi", "algorithm", "is", "a", "dynamic", "programming", "algorithm", "for", "finding", "the", "most", "likely", "sequence", "of", "hidden", "states", ",", "called", "a", "Viterbi", "path", ",", "that", "leads", "to", "a", "sequence", "of", "observed", "events", ",", "especially", "in", "the", "context", "of", "Markovian", "information", "sources", "and", "hidden", "Markov", "models", "(", "HMMs", ")", "."], "sentence-detokenized": "The Viterbi algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states, called a Viterbi path, that leads to a sequence of observed events, especially in the context of Markovian information sources and hidden Markov models (HMMs).", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 24], [25, 26], [27, 34], [35, 46], [47, 56], [57, 60], [61, 68], [69, 72], [73, 77], [78, 84], [85, 93], [94, 96], [97, 103], [104, 110], [110, 111], [112, 118], [119, 120], [121, 128], [129, 133], [133, 134], [135, 139], [140, 145], [146, 148], [149, 150], [151, 159], [160, 162], [163, 171], [172, 178], [178, 179], [180, 190], [191, 193], [194, 197], [198, 205], [206, 208], [209, 218], [219, 230], [231, 238], [239, 242], [243, 249], [250, 256], [257, 263], [264, 265], [265, 269], [269, 270], [270, 271]]}
{"doc_key": "ai-test-152", "ner": [[1, 1, "field"], [3, 5, "algorithm"], [8, 10, "misc"], [12, 13, "algorithm"], [15, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 1, 1, "part-of", "", false, false], [3, 5, 8, 10, "general-affiliation", "", false, false], [3, 5, 12, 13, "related-to", "generalizes_from", false, false], [3, 5, 15, 22, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "multinomial", "logistic", "regression", "is", "a", "classification", "method", "that", "generalizes", "logistic", "regression", "to", "classification", "of", "multiple", "classes", ",", "i.e.", ",", "with", "more", "than", "two", "possible", "discrete", "outcomes", "."], "sentence-detokenized": "In statistics, multinomial logistic regression is a classification method that generalizes logistic regression to classification of multiple classes, i.e., with more than two possible discrete outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 26], [27, 35], [36, 46], [47, 49], [50, 51], [52, 66], [67, 73], [74, 78], [79, 90], [91, 99], [100, 110], [111, 113], [114, 128], [129, 131], [132, 140], [141, 148], [148, 149], [150, 154], [154, 155], [156, 160], [161, 165], [166, 170], [171, 174], [175, 183], [184, 192], [193, 201], [201, 202]]}
{"doc_key": "ai-test-153", "ner": [[0, 2, "algorithm"], [9, 10, "field"], [12, 14, "field"], [18, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 9, 10, "part-of", "", false, false], [0, 2, 12, 14, "part-of", "", false, false], [18, 18, 0, 2, "usage", "", true, false], [20, 21, 0, 2, "usage", "", true, false], [23, 24, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden", "Markov", "models", "are", "known", "for", "their", "applications", "to", "reinforcement", "learning", "and", "temporal", "pattern", "recognition", ",", "such", "as", "speech", ",", "handwriting", "recognition", ",", "gesture", "recognition", ",", "Tad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov models are known for their applications to reinforcement learning and temporal pattern recognition, such as speech, handwriting recognition, gesture recognition, Tad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 30], [31, 34], [35, 40], [41, 53], [54, 56], [57, 70], [71, 79], [80, 83], [84, 92], [93, 100], [101, 112], [112, 113], [114, 118], [119, 121], [122, 128], [128, 129], [130, 141], [142, 153], [153, 154], [155, 162], [163, 174], [174, 175], [176, 179], [180, 187], [187, 188], [189, 193], [194, 202], [202, 203]]}
{"doc_key": "ai-test-154", "ner": [[6, 8, "misc"], [32, 35, "metrics"], [37, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 8, 37, 38, "named", "", false, false], [32, 35, 37, 38, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Essentially", ",", "this", "means", "that", "if", "this", "gram", "was", "seen", "more", "than", "k", "times", "in", "training", ",", "the", "conditional", "probability", "of", "the", "word", ",", "given", "its", "history", ",", "is", "proportional", "to", "the", "maximum", "likelihood", "estimate", "of", "thisp", "-", "gram", "."], "sentence-detokenized": "Essentially, this means that if this gram was seen more than k times in training, the conditional probability of the word, given its history, is proportional to the maximum likelihood estimate of thisp -gram.", "token2charspan": [[0, 11], [11, 12], [13, 17], [18, 23], [24, 28], [29, 31], [32, 36], [37, 41], [42, 45], [46, 50], [51, 55], [56, 60], [61, 62], [63, 68], [69, 71], [72, 80], [80, 81], [82, 85], [86, 97], [98, 109], [110, 112], [113, 116], [117, 121], [121, 122], [123, 128], [129, 132], [133, 140], [140, 141], [142, 144], [145, 157], [158, 160], [161, 164], [165, 172], [173, 183], [184, 192], [193, 195], [196, 201], [202, 203], [203, 207], [207, 208]]}
{"doc_key": "ai-test-155", "ner": [[4, 5, "task"], [7, 7, "task"], [10, 12, "task"], [16, 19, "task"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[27, 29, 16, 19, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "knowledge", "representation", ",", "reasoning", ",", "and", "natural", "language", "understanding", ",", "believing", "that", "deep", "understanding", "of", "language", "can", "currently", "only", "be", "achieved", "through", "significant", "manual", "design", "of", "semantics", "-", "rich", "formalisms", "combined", "with", "statistical", "preferences", "."], "sentence-detokenized": "He is interested in knowledge representation, reasoning, and natural language understanding, believing that deep understanding of language can currently only be achieved through significant manual design of semantics-rich formalisms combined with statistical preferences.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 29], [30, 44], [44, 45], [46, 55], [55, 56], [57, 60], [61, 68], [69, 77], [78, 91], [91, 92], [93, 102], [103, 107], [108, 112], [113, 126], [127, 129], [130, 138], [139, 142], [143, 152], [153, 157], [158, 160], [161, 169], [170, 177], [178, 189], [190, 196], [197, 203], [204, 206], [207, 216], [216, 217], [217, 221], [222, 232], [233, 241], [242, 246], [247, 258], [259, 270], [270, 271]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "JavaScript", ",", "Python", "or"], "sentence-detokenized": "In JavaScript, Python or", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 24]]}
{"doc_key": "ai-test-157", "ner": [[0, 2, "misc"], [7, 10, "misc"], [14, 14, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 7, 10, "part-of", "", false, false], [7, 10, 14, 14, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "Awards", "are", "announced", "in", "the", "Journal", "of", "Artificial", "Intelligence", ",", "published", "by", "AAAI", "."], "sentence-detokenized": "The Newcomb Awards are announced in the Journal of Artificial Intelligence, published by AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 32], [33, 35], [36, 39], [40, 47], [48, 50], [51, 61], [62, 74], [74, 75], [76, 85], [86, 88], [89, 93], [93, 94]]}
{"doc_key": "ai-test-158", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "squared", "error", "for", "a", "test", "set", "of", "100", "instances", "is", "0.084", ",", "which", "is", "less", "than", "the", "unnormalized", "error", "."], "sentence-detokenized": "The mean squared error for a test set of 100 instances is 0.084, which is less than the unnormalized error.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 26], [27, 28], [29, 33], [34, 37], [38, 40], [41, 44], [45, 54], [55, 57], [58, 63], [63, 64], [65, 70], [71, 73], [74, 78], [79, 83], [84, 87], [88, 100], [101, 106], [106, 107]]}
{"doc_key": "ai-test-159", "ner": [[0, 5, "metrics"], [10, 15, "field"], [18, 20, "task"], [22, 22, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 15, 0, 5, "usage", "", false, false], [18, 20, 10, 15, "part-of", "task_part_of_field", false, false], [22, 22, 18, 20, "named", "", false, false], [25, 26, 10, 15, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["F", "-", "score", "estimation", "has", "been", "widely", "used", "in", "the", "natural", "language", "processing", "literature", ",", "e.g.", ",", "for", "named", "entity", "recognition", "(", "NER", ")", "and", "word", "segmentation", "estimation", "."], "sentence-detokenized": "F-score estimation has been widely used in the natural language processing literature, e.g., for named entity recognition (NER) and word segmentation estimation.", "token2charspan": [[0, 1], [1, 2], [2, 7], [8, 18], [19, 22], [23, 27], [28, 34], [35, 39], [40, 42], [43, 46], [47, 54], [55, 63], [64, 74], [75, 85], [85, 86], [87, 91], [91, 92], [93, 96], [97, 102], [103, 109], [110, 121], [122, 123], [123, 126], [126, 127], [128, 131], [132, 136], [137, 149], [150, 160], [160, 161]]}
{"doc_key": "ai-test-160", "ner": [[0, 3, "product"], [5, 8, "product"], [17, 18, "misc"], [22, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 17, 18, "related-to", "performs_task", false, false], [0, 3, 22, 22, "related-to", "performs_task", false, false], [5, 8, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "typically", "used", "in", "dialog", "systems", "for", "a", "variety", "of", "purposes", ",", "including", "customer", "service", ",", "routing", "requests", ",", "or", "collecting", "information", "."], "sentence-detokenized": "Chatbots are typically used in dialog systems for a variety of purposes, including customer service, routing requests, or collecting information.", "token2charspan": [[0, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 37], [38, 45], [46, 49], [50, 51], [52, 59], [60, 62], [63, 71], [71, 72], [73, 82], [83, 91], [92, 99], [99, 100], [101, 108], [109, 117], [117, 118], [119, 121], [122, 132], [133, 144], [144, 145]]}
{"doc_key": "ai-test-161", "ner": [[3, 9, "conference"], [13, 23, "conference"], [27, 37, "conference"], [42, 42, "conference"], [46, 49, "conference"], [52, 53, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 23, 3, 9, "named", "", false, false], [27, 37, 3, 9, "named", "", false, false], [42, 42, 27, 37, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Important", "journals", "include", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "later", "renamed", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", ",", "and", "since", "September", "2014", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "after", "merging", "with", "ACM", "publication", ")", ",", "Computer", "Speech", "and", "Language", ",", "and", "Speech", "Communication", "."], "sentence-detokenized": "Important journals include IEEE Transactions on Speech and Audio Processing (later renamed IEEE Transactions on Audio, Speech and Language Processing, and since September 2014 IEEE/ACM Transactions on Audio, Speech and Language Processing - after merging with ACM publication), Computer Speech and Language, and Speech Communication.", "token2charspan": [[0, 9], [10, 18], [19, 26], [27, 31], [32, 44], [45, 47], [48, 54], [55, 58], [59, 64], [65, 75], [76, 77], [77, 82], [83, 90], [91, 95], [96, 108], [109, 111], [112, 117], [117, 118], [119, 125], [126, 129], [130, 138], [139, 149], [149, 150], [151, 154], [155, 160], [161, 170], [171, 175], [176, 180], [180, 181], [181, 184], [185, 197], [198, 200], [201, 206], [206, 207], [208, 214], [215, 218], [219, 227], [228, 238], [239, 240], [241, 246], [247, 254], [255, 259], [260, 263], [264, 275], [275, 276], [276, 277], [278, 286], [287, 293], [294, 297], [298, 306], [306, 307], [308, 311], [312, 318], [319, 332], [332, 333]]}
{"doc_key": "ai-test-162", "ner": [[0, 0, "algorithm"], [5, 6, "task"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 0, 0, "usage", "", false, false], [5, 6, 8, 9, "part-of", "task_part_of_field", false, false], [5, 6, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "is", "often", "used", "for", "data", "clustering", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "EM is often used for data clustering in machine learning and computer vision.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 20], [21, 25], [26, 36], [37, 39], [40, 47], [48, 56], [57, 60], [61, 69], [70, 76], [76, 77]]}
{"doc_key": "ai-test-163", "ner": [[9, 11, "metrics"], [21, 24, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 21, 24, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["Although", "there", "is", "no", "perfect", "way", "to", "describe", "the", "confusion", "matrix", "of", "positive", "and", "negative", "scores", "with", "a", "single", "number", ",", "the", "Matthews", "correlation", "coefficient", "is", "generally", "considered", "one", "of", "the", "best", "such", "measures", "."], "sentence-detokenized": "Although there is no perfect way to describe the confusion matrix of positive and negative scores with a single number, the Matthews correlation coefficient is generally considered one of the best such measures.", "token2charspan": [[0, 8], [9, 14], [15, 17], [18, 20], [21, 28], [29, 32], [33, 35], [36, 44], [45, 48], [49, 58], [59, 65], [66, 68], [69, 77], [78, 81], [82, 90], [91, 97], [98, 102], [103, 104], [105, 111], [112, 118], [118, 119], [120, 123], [124, 132], [133, 144], [145, 156], [157, 159], [160, 169], [170, 180], [181, 184], [185, 187], [188, 191], [192, 196], [197, 201], [202, 210], [210, 211]]}
{"doc_key": "ai-test-164", "ner": [[12, 13, "field"], [28, 31, "field"], [33, 34, "field"], [38, 39, "algorithm"], [41, 42, "task"], [44, 45, "algorithm"], [50, 53, "algorithm"], [56, 56, "algorithm"], [62, 67, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[33, 34, 28, 31, "part-of", "subfield", false, false], [38, 39, 33, 34, "part-of", "", false, true], [41, 42, 33, 34, "part-of", "", false, true], [44, 45, 33, 34, "part-of", "", false, true], [50, 53, 33, 34, "part-of", "", false, true], [56, 56, 33, 34, "part-of", "", false, true], [62, 67, 33, 34, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "the", "size", "and", "complexity", "of", "datasets", "grew", ",", "direct", ",", "practical", "data", "analysis", "was", "complemented", "by", "indirect", ",", "automated", "data", "processing", ",", "aided", "by", "other", "developments", "in", "computer", "science", ",", "especially", "in", "machine", "learning", ",", "such", "as", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "learning", "by", "decision", "trees", "and", "decision", "rules", "(", "1960s", ")", ",", "and", "support", "vector", "machines", "(", "1990", "s", ")", "."], "sentence-detokenized": "As the size and complexity of datasets grew, direct, practical data analysis was complemented by indirect, automated data processing, aided by other developments in computer science, especially in machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), learning by decision trees and decision rules (1960s), and support vector machines (1990s).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 15], [16, 26], [27, 29], [30, 38], [39, 43], [43, 44], [45, 51], [51, 52], [53, 62], [63, 67], [68, 76], [77, 80], [81, 93], [94, 96], [97, 105], [105, 106], [107, 116], [117, 121], [122, 132], [132, 133], [134, 139], [140, 142], [143, 148], [149, 161], [162, 164], [165, 173], [174, 181], [181, 182], [183, 193], [194, 196], [197, 204], [205, 213], [213, 214], [215, 219], [220, 222], [223, 229], [230, 238], [238, 239], [240, 247], [248, 256], [256, 257], [258, 265], [266, 276], [277, 278], [278, 283], [283, 284], [284, 285], [286, 294], [295, 297], [298, 306], [307, 312], [313, 316], [317, 325], [326, 331], [332, 333], [333, 338], [338, 339], [339, 340], [341, 344], [345, 352], [353, 359], [360, 368], [369, 370], [370, 374], [374, 375], [375, 376], [376, 377]]}
{"doc_key": "ai-test-165", "ner": [[6, 6, "researcher"], [11, 14, "misc"], [19, 20, "researcher"], [22, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 14, 6, 6, "artifact", "", false, false], [11, 14, 19, 20, "artifact", "", false, false], [11, 14, 22, 23, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "fall", "of", "2005", ",", "Tran", "published", "a", "textbook", "entitled", "Probabilistic", "Robotics", "with", "his", "long", "-", "time", "collaborators", "Dieter", "Fox", "and", "Wolfram", "Burgard", "."], "sentence-detokenized": "In the fall of 2005, Tran published a textbook entitled Probabilistic Robotics with his long-time collaborators Dieter Fox and Wolfram Burgard.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 19], [19, 20], [21, 25], [26, 35], [36, 37], [38, 46], [47, 55], [56, 69], [70, 78], [79, 83], [84, 87], [88, 92], [92, 93], [93, 97], [98, 111], [112, 118], [119, 122], [123, 126], [127, 134], [135, 142], [142, 143]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereyramat", "as", "follows", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereyramat as follows:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 48], [49, 51], [52, 59], [59, 60]]}
{"doc_key": "ai-test-167", "ner": [[0, 1, "task"], [3, 3, "task"], [11, 13, "field"], [9, 10, "field"], [26, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[0, 1, 9, 10, "part-of", "task_part_of_field", false, false], [3, 3, 0, 1, "named", "", false, false], [9, 10, 11, 13, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["Question", "answering", "(", "QA", ")", "is", "a", "discipline", "in", "computer", "science", "that", "deals", "with", "building", "systems", "that", "automatically", "answer", "questions", "asked", "by", "humans", "in", "natural", "language", "."], "sentence-detokenized": "Question answering (QA) is a discipline in computer science that deals with building systems that automatically answer questions asked by humans in natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 39], [40, 42], [43, 51], [52, 59], [60, 64], [65, 70], [71, 75], [76, 84], [85, 92], [93, 97], [98, 111], [112, 118], [119, 128], [129, 134], [135, 137], [138, 144], [145, 147], [148, 155], [156, 164], [164, 165]]}
{"doc_key": "ai-test-168", "ner": [[9, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "the", "version", "of", "the", "metric", "used", "in", "NIST", "assessments", "prior", "to", "2009", "uses", "the", "shortest", "reference", "sentence", "instead", "."], "sentence-detokenized": "However, the version of the metric used in NIST assessments prior to 2009 uses the shortest reference sentence instead.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 20], [21, 23], [24, 27], [28, 34], [35, 39], [40, 42], [43, 47], [48, 59], [60, 65], [66, 68], [69, 73], [74, 78], [79, 82], [83, 91], [92, 101], [102, 110], [111, 118], [118, 119]]}
{"doc_key": "ai-test-169", "ner": [[6, 6, "person"], [14, 17, "organisation"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 16, 16, "related-to", "invests_in", false, false], [16, 16, 14, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["On", "August", "27", ",", "2018", ",", "Toyota", "announced", "a", "$", "500", "million", "investment", "in", "Uber", "'s", "autonomous", "cars", "."], "sentence-detokenized": "On August 27, 2018, Toyota announced a $500 million investment in Uber's autonomous cars.", "token2charspan": [[0, 2], [3, 9], [10, 12], [12, 13], [14, 18], [18, 19], [20, 26], [27, 36], [37, 38], [39, 40], [40, 43], [44, 51], [52, 62], [63, 65], [66, 70], [70, 72], [73, 83], [84, 88], [88, 89]]}
{"doc_key": "ai-test-170", "ner": [[6, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "maximum", "sample", "value", "is", "the", "maximum", "plausible", "estimate", "of", "the", "maximum", "population", "value", "but", ",", "as", "discussed", "above", ",", "it", "is", "biased", "."], "sentence-detokenized": "The maximum sample value is the maximum plausible estimate of the maximum population value but, as discussed above, it is biased.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 24], [25, 27], [28, 31], [32, 39], [40, 49], [50, 58], [59, 61], [62, 65], [66, 73], [74, 84], [85, 90], [91, 94], [94, 95], [96, 98], [99, 108], [109, 114], [114, 115], [116, 118], [119, 121], [122, 128], [128, 129]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [3, 4, "misc"], [15, 17, "algorithm"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[0, 0, 3, 4, "related-to", "overcomes", false, false], [3, 4, 15, 17, "opposite", "", false, false], [3, 4, 19, 21, "opposite", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["LSI", "helps", "overcome", "synonymy", "by", "increasing", "recall", ",", "one", "of", "the", "most", "problematic", "limitations", "of", "Boolean", "keyword", "queries", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI helps overcome synonymy by increasing recall, one of the most problematic limitations of Boolean keyword queries and vector space models.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 27], [28, 30], [31, 41], [42, 48], [48, 49], [50, 53], [54, 56], [57, 60], [61, 65], [66, 77], [78, 89], [90, 92], [93, 100], [101, 108], [109, 116], [117, 120], [121, 127], [128, 133], [134, 140], [140, 141]]}
{"doc_key": "ai-test-172", "ner": [[0, 0, "task"], [19, 19, "programlang"], [21, 21, "programlang"], [23, 23, "programlang"], [25, 26, "programlang"], [28, 28, "programlang"], [30, 30, "programlang"], [32, 32, "programlang"], [34, 34, "programlang"], [36, 36, "programlang"], [38, 38, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 0, 19, 19, "general-affiliation", "", false, false], [0, 0, 21, 21, "general-affiliation", "", false, false], [0, 0, 23, 23, "general-affiliation", "", false, false], [0, 0, 25, 26, "general-affiliation", "", false, false], [0, 0, 28, 28, "general-affiliation", "", false, false], [0, 0, 30, 30, "general-affiliation", "", false, false], [0, 0, 32, 32, "general-affiliation", "", false, false], [0, 0, 34, 34, "general-affiliation", "", false, false], [0, 0, 36, 36, "general-affiliation", "", false, false], [0, 0, 38, 38, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Data", "acquisition", "applications", "are", "typically", "driven", "by", "software", "programs", "developed", "using", "various", "general", "-", "purpose", "programming", "languages", "such", "as", "Assembler", ",", "BASIC", ",", "C", ",", "C", "++", ",", "C#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "Data acquisition applications are typically driven by software programs developed using various general-purpose programming languages such as Assembler, BASIC, C, C++, C#, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 4], [5, 16], [17, 29], [30, 33], [34, 43], [44, 50], [51, 53], [54, 62], [63, 71], [72, 81], [82, 87], [88, 95], [96, 103], [103, 104], [104, 111], [112, 123], [124, 133], [134, 138], [139, 141], [142, 151], [151, 152], [153, 158], [158, 159], [160, 161], [161, 162], [163, 164], [164, 166], [166, 167], [168, 170], [170, 171], [172, 179], [179, 180], [181, 185], [185, 186], [187, 194], [194, 195], [196, 200], [200, 201], [202, 208], [208, 209], [210, 214]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [6, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 10, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2003", ",", "Honda", "launched", "its", "Cog", "advertising", "in", "the", "UK", "and", "on", "the", "internet", "."], "sentence-detokenized": "In 2003, Honda launched its Cog advertising in the UK and on the internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 27], [28, 31], [32, 43], [44, 46], [47, 50], [51, 53], [54, 57], [58, 60], [61, 64], [65, 73], [73, 74]]}
{"doc_key": "ai-test-174", "ner": [[0, 4, "conference"], [6, 7, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 6, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Association", "for", "Computational", "Linguistics", "defines", "computational", "linguistics", "as", ":"], "sentence-detokenized": "The Association for Computational Linguistics defines computational linguistics as:", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 45], [46, 53], [54, 67], [68, 79], [80, 82], [82, 83]]}
{"doc_key": "ai-test-175", "ner": [[0, 2, "algorithm"], [8, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 8, 11, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Expectation", "-maximization", "algorithms", "can", "be", "used", "to", "compute", "maximum", "likelihood", "estimates", "of", "unknown", "state", "-", "space", "parameters", "within", "minimum", "-bias", "filters", "and", "smoothing", "devices", "."], "sentence-detokenized": "Expectation-maximization algorithms can be used to compute maximum likelihood estimates of unknown state-space parameters within minimum-bias filters and smoothing devices.", "token2charspan": [[0, 11], [11, 24], [25, 35], [36, 39], [40, 42], [43, 47], [48, 50], [51, 58], [59, 66], [67, 77], [78, 87], [88, 90], [91, 98], [99, 104], [104, 105], [105, 110], [111, 121], [122, 128], [129, 136], [136, 141], [142, 149], [150, 153], [154, 163], [164, 171], [171, 172]]}
{"doc_key": "ai-test-176", "ner": [[6, 9, "misc"], [12, 14, "person"], [16, 17, "person"], [19, 20, "person"], [23, 26, "misc"], [27, 28, "person"], [31, 32, "person"], [36, 36, "person"], [38, 39, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[12, 14, 6, 9, "role", "actor_in", false, false], [16, 17, 6, 9, "role", "actor_in", false, false], [19, 20, 6, 9, "role", "actor_in", false, false], [27, 28, 23, 26, "role", "model_for", false, false], [36, 36, 38, 39, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Among", "the", "correspondents", "were", "former", "\"", "Lifeguards", "on", "the", "Beach", "\"", "actresses", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "and", "Tracy", "Bingham", ",", "former", "\"", "Playboy", "\"", "playmate", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", "and", "identical", "twins", "Randy", "and", "Jason", "Sklar", "."], "sentence-detokenized": "Among the correspondents were former \"Lifeguards on the Beach\" actresses Donna D'Errico, Carmen Electra and Tracy Bingham, former \"Playboy\" playmate Heidi Mark, comedian Arj Barker and identical twins Randy and Jason Sklar.", "token2charspan": [[0, 5], [6, 9], [10, 24], [25, 29], [30, 36], [37, 38], [38, 48], [49, 51], [52, 55], [56, 61], [61, 62], [63, 72], [73, 78], [79, 81], [81, 87], [87, 88], [89, 95], [96, 103], [104, 107], [108, 113], [114, 121], [121, 122], [123, 129], [130, 131], [131, 138], [138, 139], [140, 148], [149, 154], [155, 159], [159, 160], [161, 169], [170, 173], [174, 180], [181, 184], [185, 194], [195, 200], [201, 206], [207, 210], [211, 216], [217, 222], [222, 223]]}
{"doc_key": "ai-test-177", "ner": [[8, 9, "task"], [11, 11, "task"], [15, 18, "product"], [22, 23, "task"], [25, 28, "task"], [29, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [15, 18, 8, 9, "general-affiliation", "", false, false], [25, 28, 22, 23, "named", "", false, false], [29, 31, 22, 23, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "is", "typically", "used", "to", "generate", "representations", "for", "speech", "recognition", "(", "ASR", ")", ",", "e.g.", "the", "CMU", "Sphinx", "system", ",", "and", "for", "speech", "synthesis", "(", "TTS", ")", ",", "e.g.", "the", "Festival", "system", "."], "sentence-detokenized": "It is typically used to generate representations for speech recognition (ASR), e.g. the CMU Sphinx system, and for speech synthesis (TTS), e.g. the Festival system.", "token2charspan": [[0, 2], [3, 5], [6, 15], [16, 20], [21, 23], [24, 32], [33, 48], [49, 52], [53, 59], [60, 71], [72, 73], [73, 76], [76, 77], [77, 78], [79, 83], [84, 87], [88, 91], [92, 98], [99, 105], [105, 106], [107, 110], [111, 114], [115, 121], [122, 131], [132, 133], [133, 136], [136, 137], [137, 138], [139, 143], [144, 147], [148, 156], [157, 163], [163, 164]]}
{"doc_key": "ai-test-178", "ner": [[0, 1, "metrics"], [3, 5, "metrics"], [7, 10, "metrics"], [15, 16, "metrics"], [31, 32, "metrics"], [34, 34, "metrics"], [45, 46, "metrics"], [48, 48, "metrics"], [50, 52, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 5, 0, 1, "named", "", false, false], [7, 10, 3, 5, "named", "", false, false], [15, 16, 0, 1, "named", "", false, false], [34, 34, 31, 32, "named", "", false, false], [48, 48, 45, 46, "named", "", false, false], [50, 52, 45, 46, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "sensitivity", "or", "true", "positive", "rate", "(", "TPR", ")", ",", "also", "known", "as", "the", "\"", "recall", "rate", ",", "\"", "is", "the", "proportion", "of", "people", "who", "test", "positive", "and", "are", "positive", "(", "TRUE", "Positive", ",", "TP", ")", "out", "of", "all", "people", "who", "are", "actually", "positive", "(", "Condition", "Positive", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "The sensitivity or true positive rate (TPR), also known as the \"recall rate,\" is the proportion of people who test positive and are positive (TRUE Positive, TP) out of all people who are actually positive (Condition Positive, CP = TP + FN).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 23], [24, 32], [33, 37], [38, 39], [39, 42], [42, 43], [43, 44], [45, 49], [50, 55], [56, 58], [59, 62], [63, 64], [64, 70], [71, 75], [75, 76], [76, 77], [78, 80], [81, 84], [85, 95], [96, 98], [99, 105], [106, 109], [110, 114], [115, 123], [124, 127], [128, 131], [132, 140], [141, 142], [142, 146], [147, 155], [155, 156], [157, 159], [159, 160], [161, 164], [165, 167], [168, 171], [172, 178], [179, 182], [183, 186], [187, 195], [196, 204], [205, 206], [206, 215], [216, 224], [224, 225], [226, 228], [229, 230], [231, 233], [234, 235], [236, 238], [238, 239], [239, 240]]}
{"doc_key": "ai-test-179", "ner": [[1, 2, "task"], [10, 10, "conference"], [12, 13, "conference"], [15, 15, "conference"], [17, 19, "conference"], [22, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6], "relations": [[10, 10, 1, 2, "topic", "", false, false], [12, 13, 1, 2, "topic", "", false, false], [15, 15, 1, 2, "topic", "", false, false], [17, 19, 1, 2, "topic", "", false, false], [22, 23, 1, 2, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5], "sentence": ["Popular", "speech", "recognition", "conferences", "held", "every", "year", "or", "two", "include", "SpeechTEK", "and", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", ",", "and", "IEEE", "ASRU", "."], "sentence-detokenized": "Popular speech recognition conferences held every year or two include SpeechTEK and SpeechTEK Europe, ICASSP, Interspeech/Eurospeech, and IEEE ASRU.", "token2charspan": [[0, 7], [8, 14], [15, 26], [27, 38], [39, 43], [44, 49], [50, 54], [55, 57], [58, 61], [62, 69], [70, 79], [80, 83], [84, 93], [94, 100], [100, 101], [102, 108], [108, 109], [110, 121], [121, 122], [122, 132], [132, 133], [134, 137], [138, 142], [143, 147], [147, 148]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [3, 7, "researcher"], [16, 18, "product"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[20, 20, 0, 0, "artifact", "", false, false], [20, 20, 3, 7, "artifact", "", false, false], [20, 20, 16, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "collaborated", "with", "Engelberger", ",", "who", "is", "the", "company", "'s", "president", ",", "to", "design", "and", "manufacture", "an", "industrial", "robot", "branded", "Unimate", "."], "sentence-detokenized": "Devol collaborated with Engelberger, who is the company's president, to design and manufacture an industrial robot branded Unimate.", "token2charspan": [[0, 5], [6, 18], [19, 23], [24, 35], [35, 36], [37, 40], [41, 43], [44, 47], [48, 55], [55, 57], [58, 67], [67, 68], [69, 71], [72, 78], [79, 82], [83, 94], [95, 97], [98, 108], [109, 114], [115, 122], [123, 130], [130, 131]]}
{"doc_key": "ai-test-181", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [9, 14, "algorithm"], [22, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 9, 14, "general-affiliation", "", false, false], [5, 5, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Hidden", "Markov", "Model", "(", "HMM", ")", "is", "a", "statistical", "Markov", "model", "in", "which", "the", "modeled", "system", "is", "assumed", "to", "be", "a", "Markov", "process", "with", "unobserved", "(", "hidden", ")", "states", "."], "sentence-detokenized": "The Hidden Markov Model (HMM) is a statistical Markov model in which the modeled system is assumed to be a Markov process with unobserved (hidden) states.", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 23], [24, 25], [25, 28], [28, 29], [30, 32], [33, 34], [35, 46], [47, 53], [54, 59], [60, 62], [63, 68], [69, 72], [73, 80], [81, 87], [88, 90], [91, 98], [99, 101], [102, 104], [105, 106], [107, 113], [114, 121], [122, 126], [127, 137], [138, 139], [139, 145], [145, 146], [147, 153], [153, 154]]}
{"doc_key": "ai-test-182", "ner": [[16, 18, "metrics"], [24, 24, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "property", ",", "undesirable", "in", "many", "applications", ",", "has", "led", "researchers", "to", "use", "alternatives", "such", "as", "mean", "absolute", "error", "or", "those", "based", "on", "the", "median", "."], "sentence-detokenized": "This property, undesirable in many applications, has led researchers to use alternatives such as mean absolute error or those based on the median.", "token2charspan": [[0, 4], [5, 13], [13, 14], [15, 26], [27, 29], [30, 34], [35, 47], [47, 48], [49, 52], [53, 56], [57, 68], [69, 71], [72, 75], [76, 88], [89, 93], [94, 96], [97, 101], [102, 110], [111, 116], [117, 119], [120, 125], [126, 131], [132, 134], [135, 138], [139, 145], [145, 146]]}
{"doc_key": "ai-test-183", "ner": [[21, 22, "algorithm"], [30, 31, "field"], [34, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 22, 30, 31, "part-of", "", false, false], [21, 22, 34, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Such", "a", "sequence", "(", "which", "depends", "on", "the", "result", "of", "exploring", "the", "previous", "attributes", "at", "each", "stage", ")", "is", "called", "a", "decision", "tree", "and", "is", "applied", "in", "the", "field", "of", "machine", "learning", "known", "as", "decision", "tree", "learning", "."], "sentence-detokenized": "Such a sequence (which depends on the result of exploring the previous attributes at each stage) is called a decision tree and is applied in the field of machine learning known as decision tree learning.", "token2charspan": [[0, 4], [5, 6], [7, 15], [16, 17], [17, 22], [23, 30], [31, 33], [34, 37], [38, 44], [45, 47], [48, 57], [58, 61], [62, 70], [71, 81], [82, 84], [85, 89], [90, 95], [95, 96], [97, 99], [100, 106], [107, 108], [109, 117], [118, 122], [123, 126], [127, 129], [130, 137], [138, 140], [141, 144], [145, 150], [151, 153], [154, 161], [162, 170], [171, 176], [177, 179], [180, 188], [189, 193], [194, 202], [202, 203]]}
{"doc_key": "ai-test-184", "ner": [[2, 3, "task"], [5, 5, "algorithm"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 5, 5, "compare", "", false, false], [19, 21, 5, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "with", "factor", "analysis", ",", "LCA", "can", "also", "be", "used", "to", "classify", "cases", "according", "to", "their", "membership", "in", "the", "maximum", "likelihood", "class", "."], "sentence-detokenized": "As with factor analysis, LCA can also be used to classify cases according to their membership in the maximum likelihood class.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 23], [23, 24], [25, 28], [29, 32], [33, 37], [38, 40], [41, 45], [46, 48], [49, 57], [58, 63], [64, 73], [74, 76], [77, 82], [83, 93], [94, 96], [97, 100], [101, 108], [109, 119], [120, 125], [125, 126]]}
{"doc_key": "ai-test-185", "ner": [[0, 3, "algorithm"], [6, 8, "metrics"], [10, 10, "metrics"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 6, 8, "usage", "", false, false], [6, 8, 12, 13, "related-to", "", false, false], [10, 10, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Supervised", "neural", "networks", "that", "use", "a", "mean", "squared", "error", "(", "MSE", ")", "cost", "function", "can", "use", "formal", "statistical", "methods", "to", "determine", "the", "confidence", "in", "the", "trained", "model", "."], "sentence-detokenized": "Supervised neural networks that use a mean squared error (MSE) cost function can use formal statistical methods to determine the confidence in the trained model.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 35], [36, 37], [38, 42], [43, 50], [51, 56], [57, 58], [58, 61], [61, 62], [63, 67], [68, 76], [77, 80], [81, 84], [85, 91], [92, 103], [104, 111], [112, 114], [115, 124], [125, 128], [129, 139], [140, 142], [143, 146], [147, 154], [155, 160], [160, 161]]}
{"doc_key": "ai-test-186", "ner": [[16, 19, "algorithm"], [20, 22, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 19, 20, 22, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "expressed", "directly", "as", "a", "linear", "program", ",", "but", "is", "also", "equivalent", "to", "a", "Tikhonov", "regularization", "with", "the", "pivot", "loss", "function", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "This can be expressed directly as a linear program, but is also equivalent to a Tikhonov regularization with the pivot loss function, mathV (f (x), y) = max (0, 1 - yf (x)) / math:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 21], [22, 30], [31, 33], [34, 35], [36, 42], [43, 50], [50, 51], [52, 55], [56, 58], [59, 63], [64, 74], [75, 77], [78, 79], [80, 88], [89, 103], [104, 108], [109, 112], [113, 118], [119, 123], [124, 132], [132, 133], [134, 139], [140, 141], [141, 142], [143, 144], [144, 145], [145, 146], [146, 147], [148, 149], [149, 150], [151, 152], [153, 156], [157, 158], [158, 159], [159, 160], [161, 162], [163, 164], [165, 167], [168, 169], [169, 170], [170, 171], [171, 172], [173, 174], [175, 179], [179, 180]]}
{"doc_key": "ai-test-187", "ner": [[6, 6, "researcher"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "technique", "is", "described", "in", "Breiman", "'s", "original", "paper", "and", "implemented", "in", "the", "R", "package", "randomForest", "."], "sentence-detokenized": "The following technique is described in Breiman's original paper and implemented in the R package randomForest.", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 26], [27, 36], [37, 39], [40, 47], [47, 49], [50, 58], [59, 64], [65, 68], [69, 80], [81, 83], [84, 87], [88, 89], [90, 97], [98, 110], [110, 111]]}
{"doc_key": "ai-test-188", "ner": [[7, 7, "metrics"], [39, 39, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "image", "quality", "measures", ",", "such", "as", "PSNR", ",", "are", "typically", "performed", "for", "fixed", "-", "resolution", "images", "and", "do", "not", "account", "for", "some", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "the", "change", "in", "spatial", "resolution", "of", "the", "retina", "."], "sentence-detokenized": "Traditional image quality measures, such as PSNR, are typically performed for fixed-resolution images and do not account for some aspects of the human visual system, such as the change in spatial resolution of the retina.", "token2charspan": [[0, 11], [12, 17], [18, 25], [26, 34], [34, 35], [36, 40], [41, 43], [44, 48], [48, 49], [50, 53], [54, 63], [64, 73], [74, 77], [78, 83], [83, 84], [84, 94], [95, 101], [102, 105], [106, 108], [109, 112], [113, 120], [121, 124], [125, 129], [130, 137], [138, 140], [141, 144], [145, 150], [151, 157], [158, 164], [164, 165], [166, 170], [171, 173], [174, 177], [178, 184], [185, 187], [188, 195], [196, 206], [207, 209], [210, 213], [214, 220], [220, 221]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [10, 11, "person"], [16, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 19, "role", "", false, false], [3, 4, 16, 19, "role", "", false, false], [6, 7, 16, 19, "role", "", false, false], [16, 19, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joan", "Drew", "and", "Macdonald", "Carey", "starred", "in", "Jack", "Browder", "'s", "color", "production", "of", "Hannah", "Lee", ",", "which", "premiered", "on", "June", "19", ",", "1953", "."], "sentence-detokenized": "John Ireland, Joan Drew and Macdonald Carey starred in Jack Browder's color production of Hannah Lee, which premiered on June 19, 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 18], [19, 23], [24, 27], [28, 37], [38, 43], [44, 51], [52, 54], [55, 59], [60, 67], [67, 69], [70, 75], [76, 86], [87, 89], [90, 96], [97, 100], [100, 101], [102, 107], [108, 117], [118, 120], [121, 125], [126, 128], [128, 129], [130, 134], [134, 135]]}
{"doc_key": "ai-test-190", "ner": [[4, 5, "task"], [11, 15, "field"], [18, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 11, 15, "usage", "", false, false], [18, 18, 11, 15, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "process", "is", "called", "image", "registration", "and", "uses", "a", "variety", "of", "computer", "vision", "methods", ",", "mostly", "related", "to", "tracking", "."], "sentence-detokenized": "This process is called image registration and uses a variety of computer vision methods, mostly related to tracking.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 22], [23, 28], [29, 41], [42, 45], [46, 50], [51, 52], [53, 60], [61, 63], [64, 72], [73, 79], [80, 87], [87, 88], [89, 95], [96, 103], [104, 106], [107, 115], [115, 116]]}
{"doc_key": "ai-test-191", "ner": [[18, 19, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Now", "let", "'s", "start", "explaining", "the", "different", "possible", "relationships", "between", "the", "predicted", "and", "the", "actual", "outcome", ":", "the", "confusion", "matrix"], "sentence-detokenized": "Now let's start explaining the different possible relationships between the predicted and the actual outcome: the confusion matrix", "token2charspan": [[0, 3], [4, 7], [7, 9], [10, 15], [16, 26], [27, 30], [31, 40], [41, 49], [50, 63], [64, 71], [72, 75], [76, 85], [86, 89], [90, 93], [94, 100], [101, 108], [108, 109], [110, 113], [114, 123], [124, 130]]}
{"doc_key": "ai-test-192", "ner": [[0, 1, "product"], [2, 4, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 2, 4, "part-of", "", false, false], [0, 1, 2, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "VOICEBOX", "speech", "processing", "toolkit", "for", "MATLAB", "implements", "the", "transformation", "and", "its", "inverse", "as", ":"], "sentence-detokenized": "The VOICEBOX speech processing toolkit for MATLAB implements the transformation and its inverse as:", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 30], [31, 38], [39, 42], [43, 49], [50, 60], [61, 64], [65, 79], [80, 83], [84, 87], [88, 95], [96, 98], [98, 99]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "general-affiliation", "", false, false], [0, 0, 11, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logic", "programming", "language", "related", "to", "artificial", "intelligence", "and", "computational", "linguistics", "."], "sentence-detokenized": "Prolog is a logic programming language related to artificial intelligence and computational linguistics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 17], [18, 29], [30, 38], [39, 46], [47, 49], [50, 60], [61, 73], [74, 77], [78, 91], [92, 103], [103, 104]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [9, 9, "field"], [11, 11, "field"], [17, 20, "organisation"], [23, 26, "organisation"], [30, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 9, 9, "related-to", "works_with_topic", false, false], [0, 0, 11, 11, "related-to", "works_with_topic", false, false], [0, 0, 17, 20, "role", "", false, false], [0, 0, 23, 26, "role", "", false, false], [0, 0, 30, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "numerous", "awards", "for", "her", "contributions", "to", "neuroscience", "and", "psychology", ",", "including", "membership", "in", "the", "Royal", "Society", "of", "London", ",", "the", "Royal", "Society", "of", "Canada", ",", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received numerous awards for her contributions to neuroscience and psychology, including membership in the Royal Society of London, the Royal Society of Canada, and the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 35], [36, 39], [40, 43], [44, 57], [58, 60], [61, 73], [74, 77], [78, 88], [88, 89], [90, 99], [100, 110], [111, 113], [114, 117], [118, 123], [124, 131], [132, 134], [135, 141], [141, 142], [143, 146], [147, 152], [153, 160], [161, 163], [164, 170], [170, 171], [172, 175], [176, 179], [180, 188], [189, 196], [197, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-test-195", "ner": [[11, 11, "field"], [13, 14, "task"], [16, 17, "task"], [19, 20, "task"], [23, 23, "task"], [25, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 14, 11, 11, "part-of", "task_part_of_field", false, false], [16, 17, 11, 11, "part-of", "task_part_of_field", false, false], [19, 20, 11, 11, "part-of", "task_part_of_field", false, false], [23, 23, 11, 11, "part-of", "task_part_of_field", false, false], [25, 28, 11, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["By", "combining", "these", "operators", ",", "algorithms", "for", "many", "image", "processing", "tasks", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "sharpening", ",", "image", "filtering", "and", "classification", "can", "be", "obtained", "."], "sentence-detokenized": "By combining these operators, algorithms for many image processing tasks such as feature extraction, image segmentation, image sharpening, image filtering and classification can be obtained.", "token2charspan": [[0, 2], [3, 12], [13, 18], [19, 28], [28, 29], [30, 40], [41, 44], [45, 49], [50, 55], [56, 66], [67, 72], [73, 77], [78, 80], [81, 88], [89, 99], [99, 100], [101, 106], [107, 119], [119, 120], [121, 126], [127, 137], [137, 138], [139, 144], [145, 154], [155, 158], [159, 173], [174, 177], [178, 180], [181, 189], [189, 190]]}
{"doc_key": "ai-test-196", "ner": [[7, 12, "university"], [15, 18, "organisation"], [20, 21, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 21, 15, 18, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "has", "been", "a", "professor", "at", "the", "Coll\u00e8ge", "de", "France", "since", "2017", "and", "Director", "of", "INSERM", "'s", "Department", "562", ",", "Cognitive", "Neuroimaging", ",", "since", "1989", "."], "sentence-detokenized": "He has been a professor at the Coll\u00e8ge de France since 2017 and Director of INSERM's Department 562, Cognitive Neuroimaging, since 1989.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 13], [14, 23], [24, 26], [27, 30], [31, 38], [39, 41], [42, 48], [49, 54], [55, 59], [60, 63], [64, 72], [73, 75], [76, 82], [82, 84], [85, 95], [96, 99], [99, 100], [101, 110], [111, 123], [123, 124], [125, 130], [131, 135], [135, 136]]}
{"doc_key": "ai-test-197", "ner": [[11, 17, "algorithm"], [14, 19, "algorithm"], [22, 22, "algorithm"], [24, 31, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 24, 31, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["Many", "approaches", "exist", "to", "study", "these", "embeddings", ",", "in", "particular", "using", "Bayesian", "clustering", "or", "energy", "-", "based", "frameworks", ",", "and", "more", "recently", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "2013", ")", "."], "sentence-detokenized": "Many approaches exist to study these embeddings, in particular using Bayesian clustering or energy-based frameworks, and more recently TransE (Conference on Neural Information Processing Systems, 2013).", "token2charspan": [[0, 4], [5, 15], [16, 21], [22, 24], [25, 30], [31, 36], [37, 47], [47, 48], [49, 51], [52, 62], [63, 68], [69, 77], [78, 88], [89, 91], [92, 98], [98, 99], [99, 104], [105, 115], [115, 116], [117, 120], [121, 125], [126, 134], [135, 141], [142, 143], [143, 153], [154, 156], [157, 163], [164, 175], [176, 186], [187, 194], [194, 195], [196, 200], [200, 201], [201, 202]]}
{"doc_key": "ai-test-198", "ner": [[6, 8, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 13, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "is", "an", "alternative", "to", "the", "Word", "Error", "Rate", "used", "in", "several", "countries", "."], "sentence-detokenized": "It is an alternative to the Word Error Rate used in several countries.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 23], [24, 27], [28, 32], [33, 38], [39, 43], [44, 48], [49, 51], [52, 59], [60, 69], [69, 70]]}
{"doc_key": "ai-test-199", "ner": [[0, 0, "algorithm"], [10, 11, "task"], [13, 14, "task"], [16, 17, "task"], [19, 21, "task"], [23, 26, "task"], [28, 29, "task"], [44, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 0, 0, "usage", "", false, false], [13, 14, 0, 0, "usage", "", false, false], [16, 17, 0, 0, "usage", "", false, false], [19, 21, 0, 0, "usage", "", false, false], [23, 26, 0, 0, "usage", "", false, false], [28, 29, 0, 0, "usage", "", false, false], [44, 44, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "are", "used", "for", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "desktop", "and", "video", "gaming", ",", "medical", "diagnostics", ",", "and", "even", "for", "activities", "traditionally", "considered", "the", "preserve", "of", "humans", ",", "such", "as", "drawing", "."], "sentence-detokenized": "ANNs are used for a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, desktop and video gaming, medical diagnostics, and even for activities traditionally considered the preserve of humans, such as drawing.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 17], [18, 19], [20, 27], [28, 30], [31, 36], [36, 37], [38, 47], [48, 56], [57, 63], [63, 64], [65, 71], [72, 83], [83, 84], [85, 92], [93, 104], [104, 105], [106, 112], [113, 120], [121, 130], [130, 131], [132, 139], [140, 143], [144, 149], [150, 156], [156, 157], [158, 165], [166, 177], [177, 178], [179, 182], [183, 187], [188, 191], [192, 202], [203, 216], [217, 227], [228, 231], [232, 240], [241, 243], [244, 250], [250, 251], [252, 256], [257, 259], [260, 267], [267, 268]]}
{"doc_key": "ai-test-200", "ner": [[0, 4, "product"], [6, 6, "product"], [25, 27, "field"], [29, 29, "field"], [34, 34, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 25, 27, "related-to", "", false, false], [0, 4, 34, 34, "general-affiliation", "", false, false], [6, 6, 0, 4, "named", "", false, false], [29, 29, 25, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "is", "an", "open", "source", "research", "platform", "and", "collection", "of", "voice", ",", "sound", ",", "speech", ",", "text", "and", "natural", "language", "processing", "(", "NLP", ")", "algorithms", "written", "in", "Java", "and", "arranged", "in", "a", "modular", "and", "extensible", "framework", "that", "attempts", "to", "facilitate", "the", "addition", "of", "new", "algorithms", "."], "sentence-detokenized": "The Modular Audio Recognition Framework (MARF) is an open source research platform and collection of voice, sound, speech, text and natural language processing (NLP) algorithms written in Java and arranged in a modular and extensible framework that attempts to facilitate the addition of new algorithms.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 29], [30, 39], [40, 41], [41, 45], [45, 46], [47, 49], [50, 52], [53, 57], [58, 64], [65, 73], [74, 82], [83, 86], [87, 97], [98, 100], [101, 106], [106, 107], [108, 113], [113, 114], [115, 121], [121, 122], [123, 127], [128, 131], [132, 139], [140, 148], [149, 159], [160, 161], [161, 164], [164, 165], [166, 176], [177, 184], [185, 187], [188, 192], [193, 196], [197, 205], [206, 208], [209, 210], [211, 218], [219, 222], [223, 233], [234, 243], [244, 248], [249, 257], [258, 260], [261, 271], [272, 275], [276, 284], [285, 287], [288, 291], [292, 302], [302, 303]]}
{"doc_key": "ai-test-201", "ner": [[13, 15, "organisation"], [22, 22, "country"], [23, 25, "organisation"], [28, 29, "organisation"], [36, 37, "task"], [48, 50, "organisation"], [56, 56, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[23, 25, 22, 22, "physical", "", false, false], [23, 25, 36, 37, "usage", "", false, false], [23, 25, 48, 50, "named", "", false, false], [28, 29, 22, 22, "physical", "", false, false], [28, 29, 36, 37, "usage", "", false, false], [48, 50, 56, 56, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "a", "report", "by", "civil", "liberties", "and", "civil", "rights", "campaigning", "organisation", "Big", "Brother", "Watch", "revealed", "that", "two", "UK", "police", "forces", "-", "South", "Wales", "Police", "and", "the", "Metropolitan", "Police", "-", "were", "using", "real", "-", "time", "facial", "recognition", "at", "public", "events", "and", "in", "public", "places.In", "September", "2019", ",", "South", "Wales", "Police", "declared", "the", "use", "of", "facial", "recognition", "legal", "."], "sentence-detokenized": "In 2018, a report by civil liberties and civil rights campaigning organisation Big Brother Watch revealed that two UK police forces - South Wales Police and the Metropolitan Police - were using real-time facial recognition at public events and in public places.In September 2019, South Wales Police declared the use of facial recognition legal.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 20], [21, 26], [27, 36], [37, 40], [41, 46], [47, 53], [54, 65], [66, 78], [79, 82], [83, 90], [91, 96], [97, 105], [106, 110], [111, 114], [115, 117], [118, 124], [125, 131], [132, 133], [134, 139], [140, 145], [146, 152], [153, 156], [157, 160], [161, 173], [174, 180], [181, 182], [183, 187], [188, 193], [194, 198], [198, 199], [199, 203], [204, 210], [211, 222], [223, 225], [226, 232], [233, 239], [240, 243], [244, 246], [247, 253], [254, 263], [264, 273], [274, 278], [278, 279], [280, 285], [286, 291], [292, 298], [299, 307], [308, 311], [312, 315], [316, 318], [319, 325], [326, 337], [338, 343], [343, 344]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [5, 5, "programlang"], [14, 15, "field"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 5, "general-affiliation", "", false, false], [0, 0, 14, 15, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "has", "been", "ported", "to", "R", ",", "a", "freely", "available", "language", "and", "environment", "for", "statistical", "computing", "and", "graphing", "."], "sentence-detokenized": "ANIMAL has been ported to R, a freely available language and environment for statistical computing and graphing.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [23, 25], [26, 27], [27, 28], [29, 30], [31, 37], [38, 47], [48, 56], [57, 60], [61, 72], [73, 76], [77, 88], [89, 98], [99, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-test-203", "ner": [[0, 6, "algorithm"], [8, 10, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 17, 19, "opposite", "alternative to", false, false], [8, 10, 0, 6, "named", "", false, false], [21, 21, 17, 19, "named", "", false, false], [24, 26, 0, 6, "usage", "", false, false], [24, 26, 17, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "time", "-", "inhomogeneous", "hidden", "Bernoulli", "model", "(", "TI", "-", "HBM", ")", "is", "an", "alternative", "to", "the", "hidden", "Markov", "model", "(", "HMM", ")", "for", "automatic", "speech", "recognition", "."], "sentence-detokenized": "The time-inhomogeneous hidden Bernoulli model (TI-HBM) is an alternative to the hidden Markov model (HMM) for automatic speech recognition.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 22], [23, 29], [30, 39], [40, 45], [46, 47], [47, 49], [49, 50], [50, 53], [53, 54], [55, 57], [58, 60], [61, 72], [73, 75], [76, 79], [80, 86], [87, 93], [94, 99], [100, 101], [101, 104], [104, 105], [106, 109], [110, 119], [120, 126], [127, 138], [138, 139]]}
{"doc_key": "ai-test-204", "ner": [[4, 4, "organisation"], [7, 7, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 7, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "Nvidia", "demonstrated", "at", "SIGGRAPH", "a", "new", "foveate", "rendering", "method", "that", "is", "claimed", "to", "be", "invisible", "to", "users", "."], "sentence-detokenized": "In July 2016, Nvidia demonstrated at SIGGRAPH a new foveate rendering method that is claimed to be invisible to users.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 33], [34, 36], [37, 45], [46, 47], [48, 51], [52, 59], [60, 69], [70, 76], [77, 81], [82, 84], [85, 92], [93, 95], [96, 98], [99, 108], [109, 111], [112, 117], [117, 118]]}
{"doc_key": "ai-test-205", "ner": [[4, 8, "misc"], [11, 12, "researcher"], [19, 20, "researcher"], [22, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 8, 11, 12, "origin", "", false, false], [4, 8, 19, 20, "origin", "", false, false], [4, 8, 22, 22, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Both", "are", "based", "on", "the", "theory", "of", "speech", "acts", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "refined", "by", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both are based on the theory of speech acts developed by John Searle in the 1960s and refined by Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 17], [18, 21], [22, 28], [29, 31], [32, 38], [39, 43], [44, 53], [54, 56], [57, 61], [62, 68], [69, 71], [72, 75], [76, 81], [82, 85], [86, 93], [94, 96], [97, 102], [103, 111], [112, 115], [116, 122], [123, 125], [126, 129], [130, 135], [135, 136]]}
{"doc_key": "ai-test-206", "ner": [[0, 3, "algorithm"], [20, 21, "researcher"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 20, 21, "related-to", "", false, false], [23, 23, 20, 21, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "knowledge", "structure", "have", "discovered", "powerful", "hierarchical", "models", "of", "knowledge", "organization", ",", "such", "as", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "Neural network models of concept formation and knowledge structure have discovered powerful hierarchical models of knowledge organization, such as George Miller's Wordnet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 56], [57, 66], [67, 71], [72, 82], [83, 91], [92, 104], [105, 111], [112, 114], [115, 124], [125, 137], [137, 138], [139, 143], [144, 146], [147, 153], [154, 160], [160, 162], [163, 170], [170, 171]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [12, 13, "field"], [16, 18, "product"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 13, "part-of", "", false, false], [0, 1, 21, 23, "part-of", "", false, false], [16, 18, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Pattern", "matching", "has", "various", "applications", "and", "is", "used", "in", "areas", "such", "as", "face", "recognition", "(", "see", "Face", "Recognition", "System", ")", "and", "medical", "image", "processing", "."], "sentence-detokenized": "Pattern matching has various applications and is used in areas such as face recognition (see Face Recognition System) and medical image processing.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 28], [29, 41], [42, 45], [46, 48], [49, 53], [54, 56], [57, 62], [63, 67], [68, 70], [71, 75], [76, 87], [88, 89], [89, 92], [93, 97], [98, 109], [110, 116], [116, 117], [118, 121], [122, 129], [130, 135], [136, 146], [146, 147]]}
{"doc_key": "ai-test-208", "ner": [[11, 12, "researcher"], [14, 15, "researcher"], [20, 29, "organisation"], [31, 31, "organisation"], [39, 40, "algorithm"], [43, 51, "conference"], [49, 49, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 12, 20, 29, "role", "", false, false], [11, 12, 43, 51, "physical", "", false, false], [11, 12, 43, 51, "temporal", "", false, false], [11, 12, 49, 49, "physical", "", false, false], [14, 15, 20, 29, "role", "", false, false], [14, 15, 43, 51, "temporal", "", false, false], [31, 31, 20, 29, "named", "", false, false], [43, 51, 39, 40, "topic", "", false, false], [49, 49, 43, 51, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "their", "use", "only", "became", "widespread", "in", "2005", ",", "when", "Navnet", "Dalal", "and", "Bill", "Triggs", ",", "researchers", "at", "the", "French", "National", "Institute", "for", "Research", "in", "Computer", "Science", "and", "Automation", "(", "INRIA", ")", ",", "presented", "their", "complementary", "work", "on", "HOG", "descriptors", "at", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "conference", "."], "sentence-detokenized": "However, their use only became widespread in 2005, when Navnet Dalal and Bill Triggs, researchers at the French National Institute for Research in Computer Science and Automation (INRIA), presented their complementary work on HOG descriptors at the Computer Vision and Pattern Recognition (CVPR) conference.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 18], [19, 23], [24, 30], [31, 41], [42, 44], [45, 49], [49, 50], [51, 55], [56, 62], [63, 68], [69, 72], [73, 77], [78, 84], [84, 85], [86, 97], [98, 100], [101, 104], [105, 111], [112, 120], [121, 130], [131, 134], [135, 143], [144, 146], [147, 155], [156, 163], [164, 167], [168, 178], [179, 180], [180, 185], [185, 186], [186, 187], [188, 197], [198, 203], [204, 217], [218, 222], [223, 225], [226, 229], [230, 241], [242, 244], [245, 248], [249, 257], [258, 264], [265, 268], [269, 276], [277, 288], [289, 290], [290, 294], [294, 295], [296, 306], [306, 307]]}
{"doc_key": "ai-test-209", "ner": [[4, 4, "university"], [17, 19, "organisation"], [21, 22, "organisation"], [29, 30, "field"], [36, 39, "researcher"], [41, 44, "researcher"], [46, 48, "researcher"], [50, 54, "organisation"], [58, 61, "organisation"], [65, 66, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[21, 22, 29, 30, "related-to", "", false, false], [36, 39, 21, 22, "physical", "", false, false], [36, 39, 21, 22, "role", "", false, false], [41, 44, 21, 22, "physical", "", false, false], [41, 44, 21, 22, "role", "", false, false], [46, 48, 21, 22, "physical", "", false, false], [46, 48, 21, 22, "role", "", false, false], [65, 66, 58, 61, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Prior", "to", "joining", "the", "Penn", "faculty", "in", "2002", ",", "he", "spent", "a", "decade", "(", "1991-2001", ")", "at", "AT", "&T", "Labs", "and", "Bell", "Labs", ",", "including", "as", "head", "of", "the", "Artificial", "Intelligence", "Division", "with", "colleagues", "such", "as", "Michael", "L", ".", "Littman", ",", "David", "A", ".", "Macalester", "and", "Richard", "S.", "Sutton", ";", "the", "Secure", "Systems", "Research", "Division", ";", "and", "the", "Machine", "Learning", "Division", "with", "members", "such", "as", "Michael", "Collins", "and", "the", "head", ")", "."], "sentence-detokenized": "Prior to joining the Penn faculty in 2002, he spent a decade (1991-2001) at AT&T Labs and Bell Labs, including as head of the Artificial Intelligence Division with colleagues such as Michael L. Littman, David A. Macalester and Richard S. Sutton; the Secure Systems Research Division; and the Machine Learning Division with members such as Michael Collins and the head).", "token2charspan": [[0, 5], [6, 8], [9, 16], [17, 20], [21, 25], [26, 33], [34, 36], [37, 41], [41, 42], [43, 45], [46, 51], [52, 53], [54, 60], [61, 62], [62, 71], [71, 72], [73, 75], [76, 78], [78, 80], [81, 85], [86, 89], [90, 94], [95, 99], [99, 100], [101, 110], [111, 113], [114, 118], [119, 121], [122, 125], [126, 136], [137, 149], [150, 158], [159, 163], [164, 174], [175, 179], [180, 182], [183, 190], [191, 192], [192, 193], [194, 201], [201, 202], [203, 208], [209, 210], [210, 211], [212, 222], [223, 226], [227, 234], [235, 237], [238, 244], [244, 245], [246, 249], [250, 256], [257, 264], [265, 273], [274, 282], [282, 283], [284, 287], [288, 291], [292, 299], [300, 308], [309, 317], [318, 322], [323, 330], [331, 335], [336, 338], [339, 346], [347, 354], [355, 358], [359, 362], [363, 367], [367, 368], [368, 369]]}
{"doc_key": "ai-test-210", "ner": [[6, 7, "field"], [13, 20, "field"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 13, 20, "compare", "", false, false], [24, 26, 13, 20, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["When", "the", "data", "is", "unlabeled", ",", "supervised", "learning", "is", "not", "possible", "and", "an", "unsupervised", "learning", "approach", "is", "needed", "that", "attempts", "to", "find", "a", "natural", "cluster", "analysis", "of", "groups", "and", "then", "match", "the", "new", "data", "to", "these", "formed", "groups", "."], "sentence-detokenized": "When the data is unlabeled, supervised learning is not possible and an unsupervised learning approach is needed that attempts to find a natural cluster analysis of groups and then match the new data to these formed groups.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 26], [26, 27], [28, 38], [39, 47], [48, 50], [51, 54], [55, 63], [64, 67], [68, 70], [71, 83], [84, 92], [93, 101], [102, 104], [105, 111], [112, 116], [117, 125], [126, 128], [129, 133], [134, 135], [136, 143], [144, 151], [152, 160], [161, 163], [164, 170], [171, 174], [175, 179], [180, 185], [186, 189], [190, 193], [194, 198], [199, 201], [202, 207], [208, 214], [215, 221], [221, 222]]}
{"doc_key": "ai-test-211", "ner": [[3, 4, "field"], [15, 25, "organisation"], [32, 33, "field"], [35, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 15, 25, "origin", "", false, false], [3, 4, 32, 33, "part-of", "", false, false], [3, 4, 35, 35, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "area", "of", "computer", "science", "developed", "in", "the", "1950s", "at", "academic", "institutions", "such", "as", "the", "Massachusetts", "Institute", "of", "Technology", "'s", "(", "MIT", ")", "Artificial", "Intelligence", "Laboratory", ",", "initially", "as", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "This area of computer science developed in the 1950s at academic institutions such as the Massachusetts Institute of Technology's (MIT) Artificial Intelligence Laboratory, initially as a branch of artificial intelligence and robotics.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 21], [22, 29], [30, 39], [40, 42], [43, 46], [47, 52], [53, 55], [56, 64], [65, 77], [78, 82], [83, 85], [86, 89], [90, 103], [104, 113], [114, 116], [117, 127], [127, 129], [130, 131], [131, 134], [134, 135], [136, 146], [147, 159], [160, 170], [170, 171], [172, 181], [182, 184], [185, 186], [187, 193], [194, 196], [197, 207], [208, 220], [221, 224], [225, 233], [233, 234]]}
{"doc_key": "ai-test-212", "ner": [[7, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "can", "also", "be", "replaced", "by", "the", "Log", "loss", "equation", "below", ":"], "sentence-detokenized": "It can also be replaced by the Log loss equation below:", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 23], [24, 26], [27, 30], [31, 34], [35, 39], [40, 48], [49, 54], [54, 55]]}
{"doc_key": "ai-test-213", "ner": [[0, 3, "organisation"], [6, 10, "organisation"], [14, 18, "university"], [21, 24, "university"], [26, 27, "university"], [30, 32, "university"], [34, 35, "country"], [39, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 39, 39, "related-to", "research_leader_in_field", false, false], [6, 10, 0, 3, "named", "", false, false], [6, 10, 39, 39, "related-to", "research_leader_in_field", false, false], [14, 18, 39, 39, "related-to", "research_leader_in_field", false, false], [21, 24, 39, 39, "related-to", "research_leader_in_field", false, false], [26, 27, 39, 39, "related-to", "research_leader_in_field", false, false], [30, 32, 34, 35, "physical", "", false, false], [30, 32, 39, 39, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "Shirley", "Ryan", "AbilityLab", "(", "formerly", "the", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "the", "University", "of", "California", "at", "Berkeley", ",", "the", "Massachusetts", "Institute", "of", "Technology", ",", "Stanford", "University", "and", "the", "University", "of", "Twente", "in", "the", "Netherlands", "are", "leaders", "in", "biomechatronics", "research", "."], "sentence-detokenized": "The Shirley Ryan AbilityLab (formerly the Rehabilitation Institute of Chicago), the University of California at Berkeley, the Massachusetts Institute of Technology, Stanford University and the University of Twente in the Netherlands are leaders in biomechatronics research.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 27], [28, 29], [29, 37], [38, 41], [42, 56], [57, 66], [67, 69], [70, 77], [77, 78], [78, 79], [80, 83], [84, 94], [95, 97], [98, 108], [109, 111], [112, 120], [120, 121], [122, 125], [126, 139], [140, 149], [150, 152], [153, 163], [163, 164], [165, 173], [174, 184], [185, 188], [189, 192], [193, 203], [204, 206], [207, 213], [214, 216], [217, 220], [221, 232], [233, 236], [237, 244], [245, 247], [248, 263], [264, 272], [272, 273]]}
{"doc_key": "ai-test-214", "ner": [[28, 31, "metrics"], [40, 41, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Given", "a", "set", "of", "forecast", "values", "and", "a", "corresponding", "set", "of", "actual", "values", "for", "X", "for", "different", "time", "periods", ",", "a", "common", "estimation", "technique", "is", "to", "use", "the", "mean", "squared", "forecast", "error", ";", "other", "measures", "exist", "(", "see", "forecasting", "#", "forecasting", "accuracy", ")", "."], "sentence-detokenized": "Given a set of forecast values and a corresponding set of actual values for X for different time periods, a common estimation technique is to use the mean squared forecast error; other measures exist (see forecasting # forecasting accuracy).", "token2charspan": [[0, 5], [6, 7], [8, 11], [12, 14], [15, 23], [24, 30], [31, 34], [35, 36], [37, 50], [51, 54], [55, 57], [58, 64], [65, 71], [72, 75], [76, 77], [78, 81], [82, 91], [92, 96], [97, 104], [104, 105], [106, 107], [108, 114], [115, 125], [126, 135], [136, 138], [139, 141], [142, 145], [146, 149], [150, 154], [155, 162], [163, 171], [172, 177], [177, 178], [179, 184], [185, 193], [194, 199], [200, 201], [201, 204], [205, 216], [217, 218], [219, 230], [231, 239], [239, 240], [240, 241]]}
{"doc_key": "ai-test-215", "ner": [[13, 20, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "metrics", ",", "such", "as", "the", "proportion", "of", "correct", "predictions", "(", "also", "called", "accuracy", ")", ",", "are", "not", "useful", "when", "the", "two", "classes", "are", "of", "very", "different", "sizes", "."], "sentence-detokenized": "Other metrics, such as the proportion of correct predictions (also called accuracy), are not useful when the two classes are of very different sizes.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 26], [27, 37], [38, 40], [41, 48], [49, 60], [61, 62], [62, 66], [67, 73], [74, 82], [82, 83], [83, 84], [85, 88], [89, 92], [93, 99], [100, 104], [105, 108], [109, 112], [113, 120], [121, 124], [125, 127], [128, 132], [133, 142], [143, 148], [148, 149]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [12, 18, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 12, 18, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "published", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "in", "2000", ",", "and", "five", "beta", "versions", "were", "published", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was published at the Conference on Computer Vision and Pattern Recognition in 2000, and five beta versions were published between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 47], [48, 50], [51, 54], [55, 65], [66, 68], [69, 77], [78, 84], [85, 88], [89, 96], [97, 108], [109, 111], [112, 116], [116, 117], [118, 121], [122, 126], [127, 131], [132, 140], [141, 145], [146, 155], [156, 163], [164, 168], [169, 172], [173, 177], [177, 178]]}
{"doc_key": "ai-test-217", "ner": [[22, 24, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Results", "are", "presented", "that", "show", "a", "correlation", "of", "up", "to", "0.964", "with", "human", "judgment", "at", "the", "corpus", "level", ",", "compared", "to", "the", "BLEU", "achievement", "of", "0.817", "for", "the", "same", "dataset", "."], "sentence-detokenized": "Results are presented that show a correlation of up to 0.964 with human judgment at the corpus level, compared to the BLEU achievement of 0.817 for the same dataset.", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 26], [27, 31], [32, 33], [34, 45], [46, 48], [49, 51], [52, 54], [55, 60], [61, 65], [66, 71], [72, 80], [81, 83], [84, 87], [88, 94], [95, 100], [100, 101], [102, 110], [111, 113], [114, 117], [118, 122], [123, 134], [135, 137], [138, 143], [144, 147], [148, 151], [152, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-test-218", "ner": [[4, 4, "metrics"], [19, 19, "metrics"], [21, 23, "metrics"], [26, 30, "metrics"], [40, 42, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 19, 19, "compare", "", false, false], [4, 4, 21, 23, "compare", "", false, false], [4, 4, 26, 30, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["An", "early", "version", "of", "VMAF", "has", "been", "shown", "to", "outperform", "other", "image", "and", "video", "quality", "metrics", ",", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", ",", "and", "VQM", "-", "VFD", ",", "on", "three", "out", "of", "four", "datasets", "in", "terms", "of", "prediction", "accuracy", "compared", "to", "subjective", "estimates", "."], "sentence-detokenized": "An early version of VMAF has been shown to outperform other image and video quality metrics, such as SSIM, PSNR -HVS, and VQM-VFD, on three out of four datasets in terms of prediction accuracy compared to subjective estimates.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 19], [20, 24], [25, 28], [29, 33], [34, 39], [40, 42], [43, 53], [54, 59], [60, 65], [66, 69], [70, 75], [76, 83], [84, 91], [91, 92], [93, 97], [98, 100], [101, 105], [105, 106], [107, 111], [112, 113], [113, 116], [116, 117], [118, 121], [122, 125], [125, 126], [126, 129], [129, 130], [131, 133], [134, 139], [140, 143], [144, 146], [147, 151], [152, 160], [161, 163], [164, 169], [170, 172], [173, 183], [184, 192], [193, 201], [202, 204], [205, 215], [216, 225], [225, 226]]}
{"doc_key": "ai-test-219", "ner": [[20, 23, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 23, 28, 29, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "of", "the", "word", "\"", "mouse", "\"", "(", "animal", "or", "device", ")", "is", "not", "relevant", "to", "machine", "translation", ",", "but", "it", "is", "relevant", "to", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity of the word \"mouse\" (animal or device) is not relevant to machine translation, but it is relevant to information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 33], [34, 38], [39, 40], [40, 45], [45, 46], [47, 48], [48, 54], [55, 57], [58, 64], [64, 65], [66, 68], [69, 72], [73, 81], [82, 84], [85, 92], [93, 104], [104, 105], [106, 109], [110, 112], [113, 115], [116, 124], [125, 127], [128, 139], [140, 149], [149, 150]]}
{"doc_key": "ai-test-220", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 1, "usage", "", false, false], [12, 13, 6, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "hashing", "was", "originally", "proposed", "in", "computer", "vision", "for", "2D", "and", "3D", "object", "recognition", ","], "sentence-detokenized": "Geometric hashing was originally proposed in computer vision for 2D and 3D object recognition,", "token2charspan": [[0, 9], [10, 17], [18, 21], [22, 32], [33, 41], [42, 44], [45, 53], [54, 60], [61, 64], [65, 67], [68, 71], [72, 74], [75, 81], [82, 93], [93, 94]]}
{"doc_key": "ai-test-221", "ner": [[9, 10, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 9, 10, "part-of", "subfield", false, false], [17, 18, 9, 10, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "is", "one", "of", "the", "three", "main", "categories", "of", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "It is one of the three main categories of machine learning, along with supervised learning and reinforcement learning.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 12], [13, 16], [17, 22], [23, 27], [28, 38], [39, 41], [42, 49], [50, 58], [58, 59], [60, 65], [66, 70], [71, 81], [82, 90], [91, 94], [95, 108], [109, 117], [117, 118]]}
{"doc_key": "ai-test-222", "ner": [[0, 1, "field"], [17, 18, "field"], [20, 21, "field"], [23, 24, "field"], [26, 27, "field"], [29, 32, "field"], [34, 35, "field"], [37, 38, "field"], [40, 40, "field"], [43, 44, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 1, 17, 18, "part-of", "subfield", false, false], [0, 1, 20, 21, "part-of", "subfield", false, false], [0, 1, 23, 24, "part-of", "subfield", false, false], [0, 1, 26, 27, "part-of", "subfield", false, false], [0, 1, 29, 32, "part-of", "subfield", false, false], [0, 1, 34, 35, "part-of", "subfield", false, false], [0, 1, 37, 38, "part-of", "subfield", false, false], [0, 1, 40, 40, "part-of", "subfield", false, false], [0, 1, 43, 44, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Reinforcement", "learning", ",", "because", "of", "its", "pervasiveness", ",", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimization", ",", "multiagent", "systems", ",", "swarm", "intelligence", ",", "statistics", ",", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Reinforcement learning, because of its pervasiveness, is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimization, multiagent systems, swarm intelligence, statistics, and genetic algorithms.", "token2charspan": [[0, 13], [14, 22], [22, 23], [24, 31], [32, 34], [35, 38], [39, 52], [52, 53], [54, 56], [57, 64], [65, 67], [68, 72], [73, 78], [79, 90], [90, 91], [92, 96], [97, 99], [100, 104], [105, 111], [111, 112], [113, 120], [121, 127], [127, 128], [129, 139], [140, 148], [148, 149], [150, 161], [162, 168], [168, 169], [170, 180], [180, 181], [181, 186], [187, 199], [199, 200], [201, 211], [212, 219], [219, 220], [221, 226], [227, 239], [239, 240], [241, 251], [251, 252], [253, 256], [257, 264], [265, 275], [275, 276]]}
{"doc_key": "ai-test-223", "ner": [[0, 1, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "related-to", "", false, false], [0, 1, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pattern", "recognition", "is", "closely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ","], "sentence-detokenized": "Pattern recognition is closely related to artificial intelligence and machine learning,", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 38], [39, 41], [42, 52], [53, 65], [66, 69], [70, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-224", "ner": [[11, 12, "algorithm"], [15, 16, "field"], [17, 20, "field"], [31, 31, "task"], [33, 33, "task"], [35, 36, "task"], [38, 39, "algorithm"], [42, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 15, 16, "related-to", "", false, false], [11, 12, 17, 20, "related-to", "", false, false], [31, 31, 11, 12, "usage", "", true, false], [33, 33, 11, 12, "usage", "", true, false], [35, 36, 11, 12, "usage", "", true, false], [38, 39, 11, 12, "usage", "", true, false], [42, 44, 11, 12, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "software", "is", "used", "to", "design", ",", "train", ",", "and", "deploy", "neural", "network", "models", "(", "supervised", "and", "unsupervised", "learning", ")", "to", "perform", "a", "wide", "variety", "of", "tasks", ",", "such", "as", "data", "mining", ",", "classification", ",", "feature", "approximation", ",", "multivariate", "regression", ",", "and", "time", "series", "forecasting", "."], "sentence-detokenized": "The software is used to design, train, and deploy neural network models (supervised and unsupervised learning) to perform a wide variety of tasks, such as data mining, classification, feature approximation, multivariate regression, and time series forecasting.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [21, 23], [24, 30], [30, 31], [32, 37], [37, 38], [39, 42], [43, 49], [50, 56], [57, 64], [65, 71], [72, 73], [73, 83], [84, 87], [88, 100], [101, 109], [109, 110], [111, 113], [114, 121], [122, 123], [124, 128], [129, 136], [137, 139], [140, 145], [145, 146], [147, 151], [152, 154], [155, 159], [160, 166], [166, 167], [168, 182], [182, 183], [184, 191], [192, 205], [205, 206], [207, 219], [220, 230], [230, 231], [232, 235], [236, 240], [241, 247], [248, 259], [259, 260]]}
{"doc_key": "ai-test-225", "ner": [[8, 14, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", ",", "he", "was", "elected", "to", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016, he was elected to the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 42], [43, 46], [47, 50], [51, 62], [63, 65], [66, 76], [77, 89], [89, 90]]}
{"doc_key": "ai-test-226", "ner": [[6, 9, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", "and", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", ","], "sentence-detokenized": "She is a member of the National Academy of Sciences (since 2005) and the American Academy of Arts and Sciences (since 2009),", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 15], [16, 18], [19, 22], [23, 31], [32, 39], [40, 42], [43, 51], [52, 53], [53, 58], [59, 63], [63, 64], [65, 68], [69, 72], [73, 81], [82, 89], [90, 92], [93, 97], [98, 101], [102, 110], [111, 112], [112, 117], [118, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-test-227", "ner": [[3, 5, "misc"], [9, 16, "product"], [17, 17, "country"], [19, 19, "country"], [24, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 16, 3, 5, "temporal", "", false, false], [9, 16, 17, 17, "physical", "", false, false], [9, 16, 19, 19, "physical", "", false, false], [9, 16, 24, 26, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "the", "1973", "Yom", "Kippur", "War", ",", "Soviet", "-supplied", "surface", "-", "to", "-", "air", "missile", "batteries", "in", "Egypt", "and", "Syria", "inflicted", "heavy", "damage", "on", "Israeli", "fighter", "jets", "."], "sentence-detokenized": "During the 1973 Yom Kippur War, Soviet-supplied surface-to-air missile batteries in Egypt and Syria inflicted heavy damage on Israeli fighter jets.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 26], [27, 30], [30, 31], [32, 38], [38, 47], [48, 55], [55, 56], [56, 58], [58, 59], [59, 62], [63, 70], [71, 80], [81, 83], [84, 89], [90, 93], [94, 99], [100, 109], [110, 115], [116, 122], [123, 125], [126, 133], [134, 141], [142, 146], [146, 147]]}
{"doc_key": "ai-test-228", "ner": [[10, 11, "product"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "resource", "(", "free", ",", "but", "copyrighted", ")", "is", "the", "HTK", "book", "(", "and", "the", "accompanying", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another resource (free, but copyrighted) is the HTK book (and the accompanying HTK toolkit).", "token2charspan": [[0, 7], [8, 16], [17, 18], [18, 22], [22, 23], [24, 27], [28, 39], [39, 40], [41, 43], [44, 47], [48, 51], [52, 56], [57, 58], [58, 61], [62, 65], [66, 78], [79, 82], [83, 90], [90, 91], [91, 92]]}
{"doc_key": "ai-test-229", "ner": [[6, 10, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "were", "made", "at", "the", "2004", "AAAI", "Spring", "Symposium", ",", "where", "linguists", ",", "computer", "scientists", ",", "and", "other", "interested", "researchers", "first", "aligned", "their", "interests", "and", "proposed", "common", "tasks", "and", "datasets", "for", "systematic", "computational", "studies", "of", "affect", ",", "attractiveness", ",", "subjectivity", ",", "and", "sentiment", "in", "text", "."], "sentence-detokenized": "- were made at the 2004 AAAI Spring Symposium, where linguists, computer scientists, and other interested researchers first aligned their interests and proposed common tasks and datasets for systematic computational studies of affect, attractiveness, subjectivity, and sentiment in text.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 14], [15, 18], [19, 23], [24, 28], [29, 35], [36, 45], [45, 46], [47, 52], [53, 62], [62, 63], [64, 72], [73, 83], [83, 84], [85, 88], [89, 94], [95, 105], [106, 117], [118, 123], [124, 131], [132, 137], [138, 147], [148, 151], [152, 160], [161, 167], [168, 173], [174, 177], [178, 186], [187, 190], [191, 201], [202, 215], [216, 223], [224, 226], [227, 233], [233, 234], [235, 249], [249, 250], [251, 263], [263, 264], [265, 268], [269, 278], [279, 281], [282, 286], [286, 287]]}
{"doc_key": "ai-test-230", "ner": [[12, 15, "task"], [18, 19, "task"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "single", "table", "can", "be", "analysed", "both", "in", "terms", "of", "content", "(", "finger", "checking", ")", "and", "structure", "(", "cluster", "analysis", ",", "principal", "component", "analysis", "and", "various", "structural", "indices", "related", "to", "the", "complexity", "and", "range", "of", "scores", "are", "the", "main", "techniques", "used", ")", "."], "sentence-detokenized": "A single table can be analysed both in terms of content (finger checking) and structure (cluster analysis, principal component analysis and various structural indices related to the complexity and range of scores are the main techniques used).", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 18], [19, 21], [22, 30], [31, 35], [36, 38], [39, 44], [45, 47], [48, 55], [56, 57], [57, 63], [64, 72], [72, 73], [74, 77], [78, 87], [88, 89], [89, 96], [97, 105], [105, 106], [107, 116], [117, 126], [127, 135], [136, 139], [140, 147], [148, 158], [159, 166], [167, 174], [175, 177], [178, 181], [182, 192], [193, 196], [197, 202], [203, 205], [206, 212], [213, 216], [217, 220], [221, 225], [226, 236], [237, 241], [241, 242], [242, 243]]}
{"doc_key": "ai-test-231", "ner": [[3, 3, "organisation"], [10, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", ",", "Toyota", "was", "considered", "a", "laggard", "in", "the", "self", "-", "driving", "car", "field", "and", "in", "need", "of", "innovation", "."], "sentence-detokenized": "In 2018, Toyota was considered a laggard in the self-driving car field and in need of innovation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 30], [31, 32], [33, 40], [41, 43], [44, 47], [48, 52], [52, 53], [53, 60], [61, 64], [65, 70], [71, 74], [75, 77], [78, 82], [83, 85], [86, 96], [96, 97]]}
{"doc_key": "ai-test-232", "ner": [[40, 43, "misc"], [45, 46, "misc"], [48, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "targets", "are", "natural", "objects", "such", "as", "the", "ground", ",", "the", "sea", ",", "precipitation", "(", "such", "as", "rain", ",", "snow", "or", "hail", ")", ",", "sandstorms", ",", "animals", "(", "especially", "birds", ")", ",", "atmospheric", "turbulence", "and", "other", "atmospheric", "effects", "such", "as", "reflections", "from", "the", "ionosphere", ",", "meteor", "trails", "and", "three", "-", "body", "scattering", "."], "sentence-detokenized": "Such targets are natural objects such as the ground, the sea, precipitation (such as rain, snow or hail), sandstorms, animals (especially birds), atmospheric turbulence and other atmospheric effects such as reflections from the ionosphere, meteor trails and three-body scattering.", "token2charspan": [[0, 4], [5, 12], [13, 16], [17, 24], [25, 32], [33, 37], [38, 40], [41, 44], [45, 51], [51, 52], [53, 56], [57, 60], [60, 61], [62, 75], [76, 77], [77, 81], [82, 84], [85, 89], [89, 90], [91, 95], [96, 98], [99, 103], [103, 104], [104, 105], [106, 116], [116, 117], [118, 125], [126, 127], [127, 137], [138, 143], [143, 144], [144, 145], [146, 157], [158, 168], [169, 172], [173, 178], [179, 190], [191, 198], [199, 203], [204, 206], [207, 218], [219, 223], [224, 227], [228, 238], [238, 239], [240, 246], [247, 253], [254, 257], [258, 263], [263, 264], [264, 268], [269, 279], [279, 280]]}
{"doc_key": "ai-test-233", "ner": [[18, 19, "product"], [40, 41, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "planning", "and", "control", ",", "the", "essential", "difference", "between", "humanoids", "and", "other", "types", "of", "robots", "(", "e.g.", ",", "industrial", "robots", ")", "is", "that", "the", "robot", "'s", "locomotion", "must", "be", "similar", "to", "a", "human", "'s", ",", "using", "leg", "movement", ",", "especially", "bipedal", "gait", "."], "sentence-detokenized": "In planning and control, the essential difference between humanoids and other types of robots (e.g., industrial robots) is that the robot's locomotion must be similar to a human's, using leg movement, especially bipedal gait.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 23], [23, 24], [25, 28], [29, 38], [39, 49], [50, 57], [58, 67], [68, 71], [72, 77], [78, 83], [84, 86], [87, 93], [94, 95], [95, 99], [99, 100], [101, 111], [112, 118], [118, 119], [120, 122], [123, 127], [128, 131], [132, 137], [137, 139], [140, 150], [151, 155], [156, 158], [159, 166], [167, 169], [170, 171], [172, 177], [177, 179], [179, 180], [181, 186], [187, 190], [191, 199], [199, 200], [201, 211], [212, 219], [220, 224], [224, 225]]}
{"doc_key": "ai-test-234", "ner": [[0, 2, "algorithm"], [9, 12, "misc"], [14, 14, "metrics"], [16, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Gradient", "descent", "can", "take", "many", "iterations", "to", "compute", "a", "local", "minimum", "with", "the", "required", "accuracy", "if", "the", "curvature", "in", "different", "directions", "is", "very", "different", "for", "a", "given", "function", "."], "sentence-detokenized": "Gradient descent can take many iterations to compute a local minimum with the required accuracy if the curvature in different directions is very different for a given function.", "token2charspan": [[0, 8], [9, 16], [17, 20], [21, 25], [26, 30], [31, 41], [42, 44], [45, 52], [53, 54], [55, 60], [61, 68], [69, 73], [74, 77], [78, 86], [87, 95], [96, 98], [99, 102], [103, 112], [113, 115], [116, 125], [126, 136], [137, 139], [140, 144], [145, 154], [155, 158], [159, 160], [161, 166], [167, 175], [175, 176]]}
{"doc_key": "ai-test-235", "ner": [[0, 6, "misc"], [10, 16, "misc"], [17, 24, "conference"], [26, 26, "location"], [28, 30, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 10, 16, "part-of", "", true, false], [17, 24, 26, 26, "physical", "", false, true], [26, 26, 28, 30, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "RoboCup", "2D", "Football", "Simulation", "League", "1997", "was", "the", "first", "RoboCup", "competition", "organized", "as", "part", "of", "the", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", ",", "held", "in", "Nagoya", ",", "Japan", ",", "from", "August", "23", "to", "29", ",", "1997", "."], "sentence-detokenized": "The RoboCup 2D Football Simulation League 1997 was the first RoboCup competition organized as part of the International Joint Conference on Artificial Intelligence, held in Nagoya, Japan, from August 23 to 29, 1997.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 23], [24, 34], [35, 41], [42, 46], [47, 50], [51, 54], [55, 60], [61, 68], [69, 80], [81, 90], [91, 93], [94, 98], [99, 101], [102, 105], [106, 119], [120, 125], [126, 136], [137, 139], [140, 150], [151, 163], [163, 164], [165, 169], [170, 172], [173, 179], [179, 180], [181, 186], [186, 187], [188, 192], [193, 199], [200, 202], [203, 205], [206, 208], [208, 209], [210, 214], [214, 215]]}
{"doc_key": "ai-test-236", "ner": [[8, 8, "programlang"], [12, 16, "programlang"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "options", "include", "a", "built", "-", "in", "Python", "environment", "and", "an", "R", "console", ",", "as", "well", "as", "Rserve", "support", "."], "sentence-detokenized": "Other programming options include a built-in Python environment and an R console, as well as Rserve support.", "token2charspan": [[0, 5], [6, 17], [18, 25], [26, 33], [34, 35], [36, 41], [41, 42], [42, 44], [45, 51], [52, 63], [64, 67], [68, 70], [71, 72], [73, 80], [80, 81], [82, 84], [85, 89], [90, 92], [93, 99], [100, 107], [107, 108]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [9, 10, "field"], [12, 12, "field"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [35, 36, "field"], [40, 41, "field"], [44, 47, "field"], [49, 50, "field"], [53, 57, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[15, 16, 12, 12, "related-to", "contributes_to_field", true, false], [18, 19, 12, 12, "related-to", "contributes_to_field", true, false], [21, 22, 12, 12, "related-to", "contributes_to_field", true, false], [44, 47, 40, 41, "part-of", "", false, false], [49, 50, 44, 47, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Since", "Bonn", ",", "he", "has", "made", "significant", "contributions", "to", "artificial", "intelligence", "and", "robotics", "(", "with", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Thrun", "among", "his", "students", ")", ",", "as", "well", "as", "to", "the", "development", "of", "software", "engineering", ",", "especially", "in", "civil", "engineering", ",", "and", "information", "systems", ",", "especially", "in", "geosciences", ".", "won", "the", "AAAI", "Classic", "Paper", "Award", "for", "2016.2014", "."], "sentence-detokenized": "Since Bonn, he has made significant contributions to artificial intelligence and robotics (with Wolfram Burgard, Dieter Fox, Sebastian Thrun among his students), as well as to the development of software engineering, especially in civil engineering, and information systems, especially in geosciences. won the AAAI Classic Paper Award for 2016.2014.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 14], [15, 18], [19, 23], [24, 35], [36, 49], [50, 52], [53, 63], [64, 76], [77, 80], [81, 89], [90, 91], [91, 95], [96, 103], [104, 111], [111, 112], [113, 119], [120, 123], [123, 124], [125, 134], [135, 140], [141, 146], [147, 150], [151, 159], [159, 160], [160, 161], [162, 164], [165, 169], [170, 172], [173, 175], [176, 179], [180, 191], [192, 194], [195, 203], [204, 215], [215, 216], [217, 227], [228, 230], [231, 236], [237, 248], [248, 249], [250, 253], [254, 265], [266, 273], [273, 274], [275, 285], [286, 288], [289, 300], [300, 301], [302, 305], [306, 309], [310, 314], [315, 322], [323, 328], [329, 334], [335, 338], [339, 348], [348, 349]]}
{"doc_key": "ai-test-238", "ner": [[2, 9, "conference"], [17, 18, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 9, 17, 18, "physical", "", false, false], [17, 18, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "edition", "of", "Campus", "Party", "USA", "will", "be", "held", "from", "August", "20", "to", "22", "at", "the", "TCF", "Center", "in", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "The first edition of Campus Party USA will be held from August 20 to 22 at the TCF Center in Detroit, Michigan.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 20], [21, 27], [28, 33], [34, 37], [38, 42], [43, 45], [46, 50], [51, 55], [56, 62], [63, 65], [66, 68], [69, 71], [72, 74], [75, 78], [79, 82], [83, 89], [90, 92], [93, 100], [100, 101], [102, 110], [110, 111]]}
{"doc_key": "ai-test-239", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 13, "misc"], [22, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 12, 13, "win-defeat", "", false, false], [5, 6, 12, 13, "win-defeat", "", false, false], [8, 8, 12, 13, "win-defeat", "", false, false], [12, 13, 22, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Together", "with", "Jan", "Lekun", "and", "Joshua", "Bengio", ",", "Hinton", "won", "the", "2018", "Turing", "Prize", "for", "conceptual", "and", "engineering", "breakthroughs", "that", "have", "made", "deep", "neural", "networks", "a", "critical", "component", "of", "computing", "."], "sentence-detokenized": "Together with Jan Lekun and Joshua Bengio, Hinton won the 2018 Turing Prize for conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing.", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 23], [24, 27], [28, 34], [35, 41], [41, 42], [43, 49], [50, 53], [54, 57], [58, 62], [63, 69], [70, 75], [76, 79], [80, 90], [91, 94], [95, 106], [107, 120], [121, 125], [126, 130], [131, 135], [136, 140], [141, 147], [148, 156], [157, 158], [159, 167], [168, 177], [178, 180], [181, 190], [190, 191]]}
{"doc_key": "ai-test-240", "ner": [[0, 2, "product"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Euler", "Math", "Toolbox", "uses", "a", "matrix", "language", "similar", "to", "MATLAB", ",", "a", "system", "that", "has", "been", "in", "development", "since", "the", "1970s", "."], "sentence-detokenized": "Euler Math Toolbox uses a matrix language similar to MATLAB, a system that has been in development since the 1970s.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 23], [24, 25], [26, 32], [33, 41], [42, 49], [50, 52], [53, 59], [59, 60], [61, 62], [63, 69], [70, 74], [75, 78], [79, 83], [84, 86], [87, 98], [99, 104], [105, 108], [109, 114], [114, 115]]}
{"doc_key": "ai-test-241", "ner": [[6, 6, "programlang"], [8, 9, "programlang"], [11, 11, "programlang"], [13, 13, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "languages", "allow", "portability", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "or", "D", ")", "."], "sentence-detokenized": "Some languages allow portability (e.g. Scheme, Common Lisp, Perl or D).", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 32], [33, 34], [34, 38], [39, 45], [45, 46], [47, 53], [54, 58], [58, 59], [60, 64], [65, 67], [68, 69], [69, 70], [70, 71]]}
{"doc_key": "ai-test-242", "ner": [[11, 11, "misc"], [3, 4, "researcher"], [6, 7, "researcher"], [24, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 3, 4, "artifact", "", false, false], [11, 11, 6, 7, "artifact", "", false, false], [11, 11, 24, 26, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1969", ",", "Marvin", "Minsky", "and", "Seymour", "Pappert", "'s", "famous", "book", "Perceptrons", "showed", "that", "it", "is", "impossible", "for", "these", "classes", "of", "networks", "to", "learn", "the", "XOR", "function", "."], "sentence-detokenized": "In 1969, Marvin Minsky and Seymour Pappert's famous book Perceptrons showed that it is impossible for these classes of networks to learn the XOR function.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 22], [23, 26], [27, 34], [35, 42], [42, 44], [45, 51], [52, 56], [57, 68], [69, 75], [76, 80], [81, 83], [84, 86], [87, 97], [98, 101], [102, 107], [108, 115], [116, 118], [119, 127], [128, 130], [131, 136], [137, 140], [141, 144], [145, 153], [153, 154]]}
{"doc_key": "ai-test-243", "ner": [[4, 8, "misc"], [12, 15, "product"], [20, 26, "organisation"], [29, 37, "organisation"], [38, 43, "location"], [45, 45, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 26, 12, 15, "usage", "", false, false], [20, 26, 38, 43, "physical", "", false, false], [29, 37, 20, 26, "named", "", false, false], [38, 43, 45, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "large", "number", "of", "Russian", "scientific", "and", "technical", "documents", "were", "translated", "with", "SYSTRAN", "'s", "assistance", "under", "the", "auspices", "of", "the", "U.S.", "Air", "Force", "'s", "Foreign", "Technology", "Division", "(", "later", "the", "National", "Air", "and", "Space", "Intelligence", "Center", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", ",", "Ohio", "."], "sentence-detokenized": "A large number of Russian scientific and technical documents were translated with SYSTRAN's assistance under the auspices of the U.S. Air Force's Foreign Technology Division (later the National Air and Space Intelligence Center) at Wright-Patterson Air Force Base, Ohio.", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 17], [18, 25], [26, 36], [37, 40], [41, 50], [51, 60], [61, 65], [66, 76], [77, 81], [82, 89], [89, 91], [92, 102], [103, 108], [109, 112], [113, 121], [122, 124], [125, 128], [129, 133], [134, 137], [138, 143], [143, 145], [146, 153], [154, 164], [165, 173], [174, 175], [175, 180], [181, 184], [185, 193], [194, 197], [198, 201], [202, 207], [208, 220], [221, 227], [227, 228], [229, 231], [232, 238], [238, 239], [239, 248], [249, 252], [253, 258], [259, 263], [263, 264], [265, 269], [269, 270]]}
{"doc_key": "ai-test-244", "ner": [[0, 1, "field"], [4, 5, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-supervised", "learning", "lies", "between", "unsupervised", "learning", "(", "without", "any", "labeled", "learning", "data", ")", "and", "supervised", "learning", "(", "with", "fully", "labeled", "learning", "data", ")", "."], "sentence-detokenized": "Semi-supervised learning lies between unsupervised learning (without any labeled learning data) and supervised learning (with fully labeled learning data).", "token2charspan": [[0, 15], [16, 24], [25, 29], [30, 37], [38, 50], [51, 59], [60, 61], [61, 68], [69, 72], [73, 80], [81, 89], [90, 94], [94, 95], [96, 99], [100, 110], [111, 119], [120, 121], [121, 125], [126, 131], [132, 139], [140, 148], [149, 153], [153, 154], [154, 155]]}
{"doc_key": "ai-test-245", "ner": [[0, 4, "algorithm"], [9, 12, "algorithm"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 9, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Ann", "-", "gram", "model", "is", "a", "type", "of", "probabilistic", "language", "model", "for", "predicting", "the", "next", "element", "in", "such", "a", "sequence", "in", "the", "form", "of", "an", "(", "n", "-", "1", ")", "Markov", "model", "."], "sentence-detokenized": "The Ann -gram model is a type of probabilistic language model for predicting the next element in such a sequence in the form of an (n - 1) Markov model.", "token2charspan": [[0, 3], [4, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 24], [25, 29], [30, 32], [33, 46], [47, 55], [56, 61], [62, 65], [66, 76], [77, 80], [81, 85], [86, 93], [94, 96], [97, 101], [102, 103], [104, 112], [113, 115], [116, 119], [120, 124], [125, 127], [128, 130], [131, 132], [132, 133], [134, 135], [136, 137], [137, 138], [139, 145], [146, 151], [151, 152]]}
{"doc_key": "ai-test-246", "ner": [[0, 2, "organisation"], [4, 5, "product"], [8, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 4, 5, "usage", "", false, false], [8, 14, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "used", "Cyc", "to", "develop", "a", "natural", "language", "query", "interface", "for", "biomedical", "information", "spanning", "decades", "of", "cardiothoracic", "surgery", "information", "."], "sentence-detokenized": "The Cleveland Clinic used Cyc to develop a natural language query interface for biomedical information spanning decades of cardiothoracic surgery information.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 29], [30, 32], [33, 40], [41, 42], [43, 50], [51, 59], [60, 65], [66, 75], [76, 79], [80, 90], [91, 102], [103, 111], [112, 119], [120, 122], [123, 137], [138, 145], [146, 157], [157, 158]]}
{"doc_key": "ai-test-247", "ner": [[6, 7, "country"], [9, 9, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 9, 9, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "incident", "strained", "relations", "between", "the", "United", "States", "and", "Japan", "and", "led", "to", "the", "arrest", "and", "prosecution", "of", "two", "senior", "executives", "and", "the", "imposition", "of", "sanctions", "on", "the", "company", "by", "both", "countries", "."], "sentence-detokenized": "The incident strained relations between the United States and Japan and led to the arrest and prosecution of two senior executives and the imposition of sanctions on the company by both countries.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 31], [32, 39], [40, 43], [44, 50], [51, 57], [58, 61], [62, 67], [68, 71], [72, 75], [76, 78], [79, 82], [83, 89], [90, 93], [94, 105], [106, 108], [109, 112], [113, 119], [120, 130], [131, 134], [135, 138], [139, 149], [150, 152], [153, 162], [163, 165], [166, 169], [170, 177], [178, 180], [181, 185], [186, 195], [195, 196]]}
{"doc_key": "ai-test-248", "ner": [[7, 9, "algorithm"], [12, 15, "field"], [22, 24, "misc"], [33, 33, "misc"], [37, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 12, 15, "type-of", "", false, false], [22, 24, 12, 15, "part-of", "", true, false], [33, 33, 12, 15, "part-of", "", true, false], [37, 37, 12, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["If", "the", "modeling", "is", "done", "by", "an", "artificial", "neural", "network", "or", "other", "machine", "learning", ",", "the", "optimization", "of", "the", "parameters", "is", "called", "training", ",", "and", "the", "optimization", "of", "the", "model", "hyperparameters", "is", "called", "tuning", "and", "often", "uses", "cross-validation", "."], "sentence-detokenized": "If the modeling is done by an artificial neural network or other machine learning, the optimization of the parameters is called training, and the optimization of the model hyperparameters is called tuning and often uses cross-validation.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 18], [19, 23], [24, 26], [27, 29], [30, 40], [41, 47], [48, 55], [56, 58], [59, 64], [65, 72], [73, 81], [81, 82], [83, 86], [87, 99], [100, 102], [103, 106], [107, 117], [118, 120], [121, 127], [128, 136], [136, 137], [138, 141], [142, 145], [146, 158], [159, 161], [162, 165], [166, 171], [172, 187], [188, 190], [191, 197], [198, 204], [205, 208], [209, 214], [215, 219], [220, 236], [236, 237]]}
{"doc_key": "ai-test-249", "ner": [[9, 9, "country"], [11, 11, "country"], [13, 13, "country"], [21, 23, "organisation"], [24, 24, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 23, 24, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Localised", "versions", "of", "the", "site", ",", "available", "in", "the", "UK", ",", "India", "and", "Australia", ",", "were", "discontinued", "following", "the", "acquisition", "of", "Rotten", "Tomatoes", "by", "Fandango", "."], "sentence-detokenized": "Localised versions of the site, available in the UK, India and Australia, were discontinued following the acquisition of Rotten Tomatoes by Fandango.", "token2charspan": [[0, 9], [10, 18], [19, 21], [22, 25], [26, 30], [30, 31], [32, 41], [42, 44], [45, 48], [49, 51], [51, 52], [53, 58], [59, 62], [63, 72], [72, 73], [74, 78], [79, 91], [92, 101], [102, 105], [106, 117], [118, 120], [121, 127], [128, 136], [137, 139], [140, 148], [148, 149]]}
{"doc_key": "ai-test-250", "ner": [[1, 1, "task"], [13, 14, "metrics"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 13, 14, "related-to", "", false, false], [13, 14, 26, 27, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "NER", "model", "is", "one", "of", "a", "number", "of", "methods", "for", "determining", "the", "accuracy", "of", "live", "captions", "in", "TV", "shows", "and", "events", "that", "are", "created", "using", "speech", "recognition", "."], "sentence-detokenized": "The NER model is one of a number of methods for determining the accuracy of live captions in TV shows and events that are created using speech recognition.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 25], [26, 32], [33, 35], [36, 43], [44, 47], [48, 59], [60, 63], [64, 72], [73, 75], [76, 80], [81, 89], [90, 92], [93, 95], [96, 101], [102, 105], [106, 112], [113, 117], [118, 121], [122, 129], [130, 135], [136, 142], [143, 154], [154, 155]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [5, 7, "university"], [10, 12, "university"], [13, 13, "location"], [15, 20, "university"], [23, 24, "university"], [26, 28, "location"], [30, 35, "university"], [37, 38, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 5, 7, "physical", "", false, false], [0, 0, 5, 7, "role", "", false, false], [0, 0, 10, 12, "physical", "", false, false], [0, 0, 10, 12, "role", "", false, false], [0, 0, 15, 20, "physical", "", false, false], [0, 0, 15, 20, "role", "", false, false], [0, 0, 23, 24, "physical", "", false, false], [0, 0, 23, 24, "role", "", false, false], [0, 0, 30, 35, "physical", "", false, false], [0, 0, 30, 35, "role", "", false, false], [10, 12, 13, 13, "physical", "", false, false], [15, 20, 26, 28, "physical", "", false, false], [23, 24, 26, 28, "physical", "", false, false], [30, 35, 37, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "has", "taught", "at", "the", "University", "of", "Cambridge", ",", "the", "Hebrew", "University", "of", "Jerusalem", ",", "the", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "and", "the", "\u00c9cole", "Polytechnique", "in", "Paris", ",", "and", "the", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "."], "sentence-detokenized": "Atran has taught at the University of Cambridge, the Hebrew University of Jerusalem, the \u00c9cole pratique des hautes \u00e9tudes and the \u00c9cole Polytechnique in Paris, and the John Jay College of Criminal Justice in New York.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 47], [47, 48], [49, 52], [53, 59], [60, 70], [71, 73], [74, 83], [83, 84], [85, 88], [89, 94], [95, 103], [104, 107], [108, 114], [115, 121], [122, 125], [126, 129], [130, 135], [136, 149], [150, 152], [153, 158], [158, 159], [160, 163], [164, 167], [168, 172], [173, 176], [177, 184], [185, 187], [188, 196], [197, 204], [205, 207], [208, 211], [212, 216], [216, 217]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [4, 6, "task"], [11, 12, "researcher"], [14, 14, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "origin", "", false, false], [0, 0, 4, 6, "related-to", "", false, false], [4, 6, 14, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "was", "an", "early", "natural", "language", "understanding", "computer", "program", "developed", "by", "Terry", "Winograd", "at", "MIT", "in", "1968", "-", "1970", "."], "sentence-detokenized": "SHRDLU was an early natural language understanding computer program developed by Terry Winograd at MIT in 1968-1970.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 19], [20, 27], [28, 36], [37, 50], [51, 59], [60, 67], [68, 77], [78, 80], [81, 86], [87, 95], [96, 98], [99, 102], [103, 105], [106, 110], [110, 111], [111, 115], [115, 116]]}
{"doc_key": "ai-test-253", "ner": [[3, 4, "misc"], [6, 9, "field"], [10, 14, "university"], [16, 16, "location"], [18, 18, "country"], [27, 30, "university"], [31, 31, "misc"], [34, 37, "field"], [41, 44, "university"], [45, 46, "misc"], [48, 49, "field"], [54, 55, "misc"], [60, 68, "university"], [71, 72, "field"], [76, 77, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[3, 4, 6, 9, "topic", "", false, false], [3, 4, 10, 14, "origin", "", false, false], [10, 14, 16, 16, "physical", "", false, false], [10, 14, 27, 30, "role", "affiliated_with", false, false], [16, 16, 18, 18, "physical", "", false, false], [31, 31, 34, 37, "topic", "", false, false], [31, 31, 41, 44, "origin", "", false, false], [45, 46, 48, 49, "topic", "", false, false], [54, 55, 60, 68, "origin", "", false, false], [54, 55, 71, 72, "topic", "", false, false], [76, 77, 60, 68, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["He", "received", "his", "B.S.", "degree", "in", "electronic", "engineering", "from", "the", "B.M.S", ".", "College", "of", "Engineering", "in", "Bangalore", ",", "India", ",", "in", "1982", "when", "he", "was", "affiliated", "with", "Bangalore", "University", ",", "his", "M.S.", "degree", "in", "electrical", "and", "computer", "engineering", "in", "1984", "from", "Drexel", "University", ",", "his", "M.S.", "degree", "in", "computer", "science", "in", "1989", "and", "his", "Ph.D.", "degree", "in", "1990", "from", "the", "University", "of", "Wisconsin", "-", "Madison", ",", "respectively", ",", "where", "he", "studied", "artificial", "intelligence", "and", "worked", "with", "Leonard", "Ur", "."], "sentence-detokenized": "He received his B.S. degree in electronic engineering from the B.M.S. College of Engineering in Bangalore, India, in 1982 when he was affiliated with Bangalore University, his M.S. degree in electrical and computer engineering in 1984 from Drexel University, his M.S. degree in computer science in 1989 and his Ph.D. degree in 1990 from the University of Wisconsin-Madison, respectively, where he studied artificial intelligence and worked with Leonard Ur.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [21, 27], [28, 30], [31, 41], [42, 53], [54, 58], [59, 62], [63, 68], [68, 69], [70, 77], [78, 80], [81, 92], [93, 95], [96, 105], [105, 106], [107, 112], [112, 113], [114, 116], [117, 121], [122, 126], [127, 129], [130, 133], [134, 144], [145, 149], [150, 159], [160, 170], [170, 171], [172, 175], [176, 180], [181, 187], [188, 190], [191, 201], [202, 205], [206, 214], [215, 226], [227, 229], [230, 234], [235, 239], [240, 246], [247, 257], [257, 258], [259, 262], [263, 267], [268, 274], [275, 277], [278, 286], [287, 294], [295, 297], [298, 302], [303, 306], [307, 310], [311, 316], [317, 323], [324, 326], [327, 331], [332, 336], [337, 340], [341, 351], [352, 354], [355, 364], [364, 365], [365, 372], [372, 373], [374, 386], [386, 387], [388, 393], [394, 396], [397, 404], [405, 415], [416, 428], [429, 432], [433, 439], [440, 444], [445, 452], [453, 455], [455, 456]]}
{"doc_key": "ai-test-254", "ner": [[6, 8, "metrics"], [10, 13, "metrics"], [19, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 13, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "usually", "evaluated", "by", "the", "word", "error", "rate", "(", "WER", ")", ",", "while", "speed", "is", "measured", "by", "the", "real", "-", "time", "rate", "."], "sentence-detokenized": "Accuracy is usually evaluated by the word error rate (WER), while speed is measured by the real-time rate.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 29], [30, 32], [33, 36], [37, 41], [42, 47], [48, 52], [53, 54], [54, 57], [57, 58], [58, 59], [60, 65], [66, 71], [72, 74], [75, 83], [84, 86], [87, 90], [91, 95], [95, 96], [96, 100], [101, 105], [105, 106]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [8, 12, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", ".", "Terry", "Winograd", "developed", "an", "early", "natural", "language", "processing", "engine", "that", "could", "interpret", "naturally", "written", "commands", "in", "a", "simple", "rule", "-", "driven", "environment", "."], "sentence-detokenized": "In 1971. Terry Winograd developed an early natural language processing engine that could interpret naturally written commands in a simple rule-driven environment.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 33], [34, 36], [37, 42], [43, 50], [51, 59], [60, 70], [71, 77], [78, 82], [83, 88], [89, 98], [99, 108], [109, 116], [117, 125], [126, 128], [129, 130], [131, 137], [138, 142], [142, 143], [143, 149], [150, 161], [161, 162]]}
{"doc_key": "ai-test-256", "ner": [[4, 5, "field"], [7, 8, "researcher"], [10, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 7, 8, "related-to", "", false, false], [4, 5, 10, 13, "related-to", "", false, false], [4, 5, 15, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "field", "of", "Artificial", "Intelligence", ",", "Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "and", "Alan", "Newell", "."], "sentence-detokenized": "In the field of Artificial Intelligence, Marvin Minsky, Herbert A. Simon and Alan Newell.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 26], [27, 39], [39, 40], [41, 47], [48, 54], [54, 55], [56, 63], [64, 65], [65, 66], [67, 72], [73, 76], [77, 81], [82, 88], [88, 89]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [31, 32, "field"], [34, 35, "field"], [38, 39, "field"], [48, 52, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[31, 32, 9, 10, "origin", "", true, false], [31, 32, 9, 10, "part-of", "", false, false], [31, 32, 38, 39, "compare", "", false, false], [34, 35, 9, 10, "origin", "", true, false], [34, 35, 9, 10, "part-of", "", false, false], [34, 35, 38, 39, "compare", "", false, false], [38, 39, 9, 10, "origin", "", true, false], [38, 39, 9, 10, "part-of", "", false, false], [38, 39, 48, 52, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "the", "second", "half", "of", "the", "20th", "century", ",", "electrical", "engineering", "itself", "split", "into", "several", "disciplines", "specializing", "in", "the", "design", "and", "analysis", "of", "systems", "that", "manipulate", "physical", "signals", ";", "examples", "include", "electronic", "engineering", "and", "computer", "engineering", ";", "while", "design", "engineering", "evolved", "to", "deal", "with", "the", "functional", "design", "of", "interfaces", "between", "users", "and", "machines", "."], "sentence-detokenized": "In the second half of the 20th century, electrical engineering itself split into several disciplines specializing in the design and analysis of systems that manipulate physical signals; examples include electronic engineering and computer engineering; while design engineering evolved to deal with the functional design of interfaces between users and machines.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 30], [31, 38], [38, 39], [40, 50], [51, 62], [63, 69], [70, 75], [76, 80], [81, 88], [89, 100], [101, 113], [114, 116], [117, 120], [121, 127], [128, 131], [132, 140], [141, 143], [144, 151], [152, 156], [157, 167], [168, 176], [177, 184], [184, 185], [186, 194], [195, 202], [203, 213], [214, 225], [226, 229], [230, 238], [239, 250], [250, 251], [252, 257], [258, 264], [265, 276], [277, 284], [285, 287], [288, 292], [293, 297], [298, 301], [302, 312], [313, 319], [320, 322], [323, 333], [334, 341], [342, 347], [348, 351], [352, 360], [360, 361]]}
{"doc_key": "ai-test-258", "ner": [[6, 6, "metrics"], [8, 9, "metrics"], [11, 14, "metrics"], [47, 49, "metrics"], [56, 57, "metrics"], [61, 62, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 14, 8, 9, "named", "", false, false], [47, 49, 56, 57, "named", "", false, false], [56, 57, 61, 62, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Perhaps", "the", "simplest", "statistic", "is", "the", "accuracy", "or", "fraction", "correct", "(", "FC", ")", ",", "which", "measures", "the", "fraction", "of", "all", "cases", "that", "are", "correctly", "categorized", ";", "it", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "total", "population", "=", "(", "TP", "+TN", ")", "/", "(", "TP+TN+", "FP+FN", ")", "."], "sentence-detokenized": "Perhaps the simplest statistic is the accuracy or fraction correct (FC), which measures the fraction of all cases that are correctly categorized; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP+TN)/total population = (TP+TN)/(TP+TN+FP+FN).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 30], [31, 33], [34, 37], [38, 46], [47, 49], [50, 58], [59, 66], [67, 68], [68, 70], [70, 71], [71, 72], [73, 78], [79, 87], [88, 91], [92, 100], [101, 103], [104, 107], [108, 113], [114, 118], [119, 122], [123, 132], [133, 144], [144, 145], [146, 148], [149, 151], [152, 155], [156, 161], [162, 164], [165, 168], [169, 175], [176, 178], [179, 186], [187, 202], [203, 205], [206, 209], [210, 215], [216, 222], [223, 225], [226, 233], [234, 236], [237, 246], [247, 262], [262, 263], [264, 265], [265, 267], [267, 268], [268, 270], [270, 271], [271, 272], [272, 277], [278, 288], [289, 290], [291, 292], [292, 294], [294, 297], [297, 298], [298, 299], [299, 300], [300, 306], [306, 311], [311, 312], [312, 313]]}
{"doc_key": "ai-test-259", "ner": [[12, 20, "conference"], [22, 34, "conference"], [29, 29, "location"], [34, 34, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 20, 29, 29, "physical", "", false, false], [22, 34, 12, 20, "named", "", false, false], [34, 34, 12, 20, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "academia", ",", "the", "major", "research", "forums", "began", "in", "1995", "when", "the", "First", "International", "Conference", "on", "Data", "Mining", "and", "Knowledge", "Discovery", "(", "KDD", "-", "95", ")", "was", "launched", "in", "Montreal", "under", "the", "sponsorship", "of", "AAAI", "."], "sentence-detokenized": "In academia, the major research forums began in 1995 when the First International Conference on Data Mining and Knowledge Discovery (KDD-95) was launched in Montreal under the sponsorship of AAAI.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 16], [17, 22], [23, 31], [32, 38], [39, 44], [45, 47], [48, 52], [53, 57], [58, 61], [62, 67], [68, 81], [82, 92], [93, 95], [96, 100], [101, 107], [108, 111], [112, 121], [122, 131], [132, 133], [133, 136], [136, 137], [137, 139], [139, 140], [141, 144], [145, 153], [154, 156], [157, 165], [166, 171], [172, 175], [176, 187], [188, 190], [191, 195], [195, 196]]}
{"doc_key": "ai-test-260", "ner": [[10, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "approach", ",", "models", "are", "developed", "using", "various", "data", "mining", "and", "machine", "learning", "algorithms", "to", "predict", "users", "'", "scores", "for", "unrated", "items", "."], "sentence-detokenized": "In this approach, models are developed using various data mining and machine learning algorithms to predict users' scores for unrated items.", "token2charspan": [[0, 2], [3, 7], [8, 16], [16, 17], [18, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 57], [58, 64], [65, 68], [69, 76], [77, 85], [86, 96], [97, 99], [100, 107], [108, 113], [113, 114], [115, 121], [122, 125], [126, 133], [134, 139], [139, 140]]}
{"doc_key": "ai-test-261", "ner": [[11, 11, "algorithm"], [17, 18, "algorithm"], [20, 23, "algorithm"], [27, 31, "misc"], [32, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 11, 17, 18, "related-to", "equivalent", false, false], [17, 18, 20, 23, "usage", "", false, false], [20, 23, 32, 33, "usage", "", false, false], [32, 33, 27, 31, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "light", "of", "the", "above", "discussion", ",", "we", "see", "that", "the", "SVM", "technique", "is", "equivalent", "to", "an", "empirical", "risk", "with", "Tikhonov", "regularization", ",", "where", "in", "this", "case", "the", "loss", "function", "is", "the", "hinge", "loss"], "sentence-detokenized": "In light of the above discussion, we see that the SVM technique is equivalent to an empirical risk with Tikhonov regularization, where in this case the loss function is the hinge loss", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 15], [16, 21], [22, 32], [32, 33], [34, 36], [37, 40], [41, 45], [46, 49], [50, 53], [54, 63], [64, 66], [67, 77], [78, 80], [81, 83], [84, 93], [94, 98], [99, 103], [104, 112], [113, 127], [127, 128], [129, 134], [135, 137], [138, 142], [143, 147], [148, 151], [152, 156], [157, 165], [166, 168], [169, 172], [173, 178], [179, 183]]}
{"doc_key": "ai-test-262", "ner": [[6, 7, "person"], [11, 12, "person"], [15, 15, "organisation"], [17, 18, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 18, 15, 15, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "2015", "edition", "was", "hosted", "by", "Molly", "McGrath", ",", "with", "commentators", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "."], "sentence-detokenized": "The 2015 edition was hosted by Molly McGrath, with commentators Chris Rose and former UFC fighter Kenny Florian.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 27], [28, 30], [31, 36], [37, 44], [44, 45], [46, 50], [51, 63], [64, 69], [70, 74], [75, 78], [79, 85], [86, 89], [90, 97], [98, 103], [104, 111], [111, 112]]}
{"doc_key": "ai-test-263", "ner": [[4, 6, "product"], [11, 13, "researcher"], [15, 16, "researcher"], [19, 20, "researcher"], [21, 21, "researcher"], [23, 23, "researcher"], [31, 31, "researcher"], [34, 36, "task"], [33, 33, "product"], [39, 41, "researcher"], [43, 44, "task"], [46, 47, "researcher"], [49, 50, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[4, 6, 11, 13, "origin", "", false, false], [4, 6, 15, 16, "origin", "", false, false], [4, 6, 19, 20, "origin", "", false, false], [4, 6, 21, 21, "origin", "", false, false], [15, 16, 39, 41, "named", "same", false, false], [19, 20, 23, 23, "named", "same", false, false], [19, 20, 31, 31, "named", "same", false, false], [34, 36, 33, 33, "related-to", "", false, false], [33, 33, 31, 31, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["A", "subset", ",", "called", "Micro", "-", "Planner", ",", "was", "implemented", "by", "Gerald", "J.", "Sussman", ",", "Eugene", "Charniak", ",", "and", "Terry", "Winograd", "Sussman", "and", "Winograd", "in", "1971", "and", "has", "been", "used", "in", "Winograd", "'s", "SHRDLU", "natural", "language", "understanding", "program", ",", "Eugene", "Charniak", "'s", "story", "understanding", "work", ",", "Thorne", "McCarthy", "'s", "legal", "reasoning", "work", ",", "and", "several", "other", "projects", "."], "sentence-detokenized": "A subset, called Micro-Planner, was implemented by Gerald J. Sussman, Eugene Charniak, and Terry Winograd Sussman and Winograd in 1971 and has been used in Winograd's SHRDLU natural language understanding program, Eugene Charniak's story understanding work, Thorne McCarthy's legal reasoning work, and several other projects.", "token2charspan": [[0, 1], [2, 8], [8, 9], [10, 16], [17, 22], [22, 23], [23, 30], [30, 31], [32, 35], [36, 47], [48, 50], [51, 57], [58, 60], [61, 68], [68, 69], [70, 76], [77, 85], [85, 86], [87, 90], [91, 96], [97, 105], [106, 113], [114, 117], [118, 126], [127, 129], [130, 134], [135, 138], [139, 142], [143, 147], [148, 152], [153, 155], [156, 164], [164, 166], [167, 173], [174, 181], [182, 190], [191, 204], [205, 212], [212, 213], [214, 220], [221, 229], [229, 231], [232, 237], [238, 251], [252, 256], [256, 257], [258, 264], [265, 273], [273, 275], [276, 281], [282, 291], [292, 296], [296, 297], [298, 301], [302, 309], [310, 315], [316, 324], [324, 325]]}
{"doc_key": "ai-test-264", "ner": [[0, 4, "product"], [10, 11, "product"], [14, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 25, "task"], [27, 28, "task"], [32, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 0, 4, "usage", "", true, false], [14, 15, 10, 11, "part-of", "", true, false], [17, 18, 10, 11, "part-of", "", true, false], [20, 22, 10, 11, "part-of", "", true, false], [24, 25, 10, 11, "part-of", "", true, false], [27, 28, 10, 11, "part-of", "", true, false], [32, 34, 10, 11, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "is", "used", "for", "a", "number", "of", "purposes", "in", "information", "systems", ",", "including", "word", "disambiguation", ",", "information", "extraction", ",", "automatic", "text", "classification", ",", "automatic", "summarization", ",", "machine", "translation", ",", "and", "even", "automatic", "crossword", "generation", "."], "sentence-detokenized": "WordNet is used for a number of purposes in information systems, including word disambiguation, information extraction, automatic text classification, automatic summarization, machine translation, and even automatic crossword generation.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 15], [16, 19], [20, 21], [22, 28], [29, 31], [32, 40], [41, 43], [44, 55], [56, 63], [63, 64], [65, 74], [75, 79], [80, 94], [94, 95], [96, 107], [108, 118], [118, 119], [120, 129], [130, 134], [135, 149], [149, 150], [151, 160], [161, 174], [174, 175], [176, 183], [184, 195], [195, 196], [197, 200], [201, 205], [206, 215], [216, 225], [226, 236], [236, 237]]}
{"doc_key": "ai-test-265", "ner": [[3, 3, "researcher"], [10, 10, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 10, 10, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1996", ",", "Keutzer", "was", "named", "a", "Fellow", "of", "the", "IEEE", "."], "sentence-detokenized": "In 1996, Keutzer was named a Fellow of the IEEE.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 20], [21, 26], [27, 28], [29, 35], [36, 38], [39, 42], [43, 47], [47, 48]]}
{"doc_key": "ai-test-266", "ner": [[8, 10, "algorithm"], [54, 56, "misc"], [66, 67, "algorithm"], [69, 70, "algorithm"], [72, 73, "algorithm"], [76, 77, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[66, 67, 54, 56, "type-of", "", false, false], [69, 70, 54, 56, "type-of", "", false, false], [72, 73, 54, 56, "type-of", "", false, false], [76, 77, 54, 56, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "widely", "used", "type", "of", "composition", "is", "the", "nonlinear", "weighted", "sum", ",", "where", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "left", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "right", ")", "/", "math", ",", "where", "math", "\\", "textstyle", "K", "/", "math", "(", "usually", "called", "the", "activation", "function", ")", "is", "some", "predefined", "function", ",", "such", "as", "a", "hyperbolic", "tangent", ",", "sigmoid", "function", ",", "softmax", "function", ",", "or", "rectifier", "function", "."], "sentence-detokenized": "A widely used type of composition is the nonlinear weighted sum, where math\\ textstyle f (x) = K\\ left (\\ sum _ i w _ i g _ i (x)\\ right) / math, where math\\ textstyle K / math (usually called the activation function) is some predefined function, such as a hyperbolic tangent, sigmoid function, softmax function, or rectifier function.", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 18], [19, 21], [22, 33], [34, 36], [37, 40], [41, 50], [51, 59], [60, 63], [63, 64], [65, 70], [71, 75], [75, 76], [77, 86], [87, 88], [89, 90], [90, 91], [91, 92], [93, 94], [95, 96], [96, 97], [98, 102], [103, 104], [104, 105], [106, 109], [110, 111], [112, 113], [114, 115], [116, 117], [118, 119], [120, 121], [122, 123], [124, 125], [126, 127], [127, 128], [128, 129], [129, 130], [131, 136], [136, 137], [138, 139], [140, 144], [144, 145], [146, 151], [152, 156], [156, 157], [158, 167], [168, 169], [170, 171], [172, 176], [177, 178], [178, 185], [186, 192], [193, 196], [197, 207], [208, 216], [216, 217], [218, 220], [221, 225], [226, 236], [237, 245], [245, 246], [247, 251], [252, 254], [255, 256], [257, 267], [268, 275], [275, 276], [277, 284], [285, 293], [293, 294], [295, 302], [303, 311], [311, 312], [313, 315], [316, 325], [326, 334], [334, 335]]}
{"doc_key": "ai-test-267", "ner": [[3, 3, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "movie", "Westworld", ",", "female", "robots", "actually", "have", "sex", "with", "humans", "as", "part", "of", "a", "fictional", "holiday", "world", "that", "customers", "pay", "for", "."], "sentence-detokenized": "In the movie Westworld, female robots actually have sex with humans as part of a fictional holiday world that customers pay for.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [22, 23], [24, 30], [31, 37], [38, 46], [47, 51], [52, 55], [56, 60], [61, 67], [68, 70], [71, 75], [76, 78], [79, 80], [81, 90], [91, 98], [99, 104], [105, 109], [110, 119], [120, 123], [124, 127], [127, 128]]}
{"doc_key": "ai-test-268", "ner": [[6, 7, "task"], [21, 26, "task"], [29, 29, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 21, 26, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Typically", ",", "the", "process", "starts", "with", "extracting", "terminology", "and", "concepts", "or", "noun", "phrases", "from", "plain", "text", "using", "linguistic", "processors", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "phrase", "splitting", "."], "sentence-detokenized": "Typically, the process starts with extracting terminology and concepts or noun phrases from plain text using linguistic processors such as part-of-speech tagging and phrase splitting.", "token2charspan": [[0, 9], [9, 10], [11, 14], [15, 22], [23, 29], [30, 34], [35, 45], [46, 57], [58, 61], [62, 70], [71, 73], [74, 78], [79, 86], [87, 91], [92, 97], [98, 102], [103, 108], [109, 119], [120, 130], [131, 135], [136, 138], [139, 143], [143, 144], [144, 146], [146, 147], [147, 153], [154, 161], [162, 165], [166, 172], [173, 182], [182, 183]]}
{"doc_key": "ai-test-269", "ner": [[14, 16, "field"], [19, 21, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 21, 14, 16, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "demonstrated", "its", "effectiveness", "in", "solving", "a", "number", "of", "problems", "of", "interest", "to", "the", "machine", "learning", "community", ",", "including", "handwritten", "text", "recognition", "."], "sentence-detokenized": "They demonstrated its effectiveness in solving a number of problems of interest to the machine learning community, including handwritten text recognition.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 35], [36, 38], [39, 46], [47, 48], [49, 55], [56, 58], [59, 67], [68, 70], [71, 79], [80, 82], [83, 86], [87, 94], [95, 103], [104, 113], [113, 114], [115, 124], [125, 136], [137, 141], [142, 153], [153, 154]]}
{"doc_key": "ai-test-270", "ner": [[3, 3, "university"], [5, 5, "researcher"], [11, 12, "researcher"], [16, 16, "product"], [20, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 3, 3, "physical", "", false, false], [5, 5, 3, 3, "role", "", false, false], [16, 16, 11, 12, "origin", "", false, false], [16, 16, 20, 21, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "studying", "at", "Stanford", ",", "Shainman", "received", "a", "scholarship", "sponsored", "by", "George", "Devoll", ",", "inventor", "of", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "While studying at Stanford, Shainman received a scholarship sponsored by George Devoll, inventor of Unimate, the first industrial robot.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [26, 27], [28, 36], [37, 45], [46, 47], [48, 59], [60, 69], [70, 72], [73, 79], [80, 86], [86, 87], [88, 96], [97, 99], [100, 107], [107, 108], [109, 112], [113, 118], [119, 129], [130, 135], [135, 136]]}
{"doc_key": "ai-test-271", "ner": [[5, 6, "task"], [8, 11, "metrics"], [13, 13, "metrics"], [22, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 8, 11, "usage", "", true, false], [13, 13, 8, 11, "named", "", false, false], [22, 24, 8, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Although", "originally", "used", "for", "evaluating", "machine", "translations", ",", "Bilingual", "Lack", "of", "Evaluability", "(", "BLEU", ")", "has", "also", "been", "successfully", "used", "for", "evaluating", "paraphrase", "generation", "models", "."], "sentence-detokenized": "Although originally used for evaluating machine translations, Bilingual Lack of Evaluability (BLEU) has also been successfully used for evaluating paraphrase generation models.", "token2charspan": [[0, 8], [9, 19], [20, 24], [25, 28], [29, 39], [40, 47], [48, 60], [60, 61], [62, 71], [72, 76], [77, 79], [80, 92], [93, 94], [94, 98], [98, 99], [100, 103], [104, 108], [109, 113], [114, 126], [127, 131], [132, 135], [136, 146], [147, 157], [158, 168], [169, 175], [175, 176]]}
{"doc_key": "ai-test-272", "ner": [[0, 0, "organisation"], [6, 8, "organisation"], [10, 10, "organisation"], [14, 14, "product"], [16, 16, "country"], [18, 20, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 8, "role", "licenses_to", false, false], [0, 0, 10, 10, "role", "licenses_to", false, false], [6, 8, 16, 16, "physical", "", false, false], [10, 10, 18, 20, "physical", "", false, false], [14, 14, 6, 8, "artifact", "produces", false, false], [14, 14, 10, 10, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "later", "licensed", "its", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "which", "manufactured", "Unimates", "in", "Japan", "and", "England", ",", "respectively", "."], "sentence-detokenized": "Unimation later licensed its technology to Kawasaki Heavy Industries and GKN, which manufactured Unimates in Japan and England, respectively.", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 57], [58, 68], [69, 72], [73, 76], [76, 77], [78, 83], [84, 96], [97, 105], [106, 108], [109, 114], [115, 118], [119, 126], [126, 127], [128, 140], [140, 141]]}
{"doc_key": "ai-test-273", "ner": [[19, 20, "conference"], [37, 38, "field"], [56, 60, "field"], [62, 62, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[37, 38, 56, 60, "compare", "", false, false], [62, 62, 56, 60, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "confusion", "between", "these", "two", "research", "communities", "(", "which", "often", "have", "separate", "conferences", "and", "separate", "journals", ",", "ECML", "PKDD", "being", "a", "major", "exception", ")", "comes", "from", "the", "underlying", "assumptions", "with", "which", "they", "work", ":", "in", "machine", "learning", ",", "performance", "is", "usually", "evaluated", "in", "terms", "of", "the", "ability", "to", "reproduce", "known", "knowledge", ",", "whereas", "in", "knowledge", "discovery", "and", "data", "mining", "(", "KDD", ")", "the", "main", "task", "is", "the", "discovery", "of", "previously", "unknown", "knowledge", "."], "sentence-detokenized": "Much of the confusion between these two research communities (which often have separate conferences and separate journals, ECML PKDD being a major exception) comes from the underlying assumptions with which they work: in machine learning, performance is usually evaluated in terms of the ability to reproduce known knowledge, whereas in knowledge discovery and data mining (KDD) the main task is the discovery of previously unknown knowledge.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 29], [30, 35], [36, 39], [40, 48], [49, 60], [61, 62], [62, 67], [68, 73], [74, 78], [79, 87], [88, 99], [100, 103], [104, 112], [113, 121], [121, 122], [123, 127], [128, 132], [133, 138], [139, 140], [141, 146], [147, 156], [156, 157], [158, 163], [164, 168], [169, 172], [173, 183], [184, 195], [196, 200], [201, 206], [207, 211], [212, 216], [216, 217], [218, 220], [221, 228], [229, 237], [237, 238], [239, 250], [251, 253], [254, 261], [262, 271], [272, 274], [275, 280], [281, 283], [284, 287], [288, 295], [296, 298], [299, 308], [309, 314], [315, 324], [324, 325], [326, 333], [334, 336], [337, 346], [347, 356], [357, 360], [361, 365], [366, 372], [373, 374], [374, 377], [377, 378], [379, 382], [383, 387], [388, 392], [393, 395], [396, 399], [400, 409], [410, 412], [413, 423], [424, 431], [432, 441], [441, 442]]}
{"doc_key": "ai-test-274", "ner": [[0, 1, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hidden", "Markov", "models", "are", "the", "basis", "of", "most", "modern", "automatic", "speech", "recognition", "systems", "."], "sentence-detokenized": "Hidden Markov models are the basis of most modern automatic speech recognition systems.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 28], [29, 34], [35, 37], [38, 42], [43, 49], [50, 59], [60, 66], [67, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-test-275", "ner": [[4, 4, "location"], [6, 6, "country"], [10, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 6, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": [",", "a", "company", "in", "Bangalore", ",", "India", "specializing", "in", "online", "handwritten", "text", "recognition", "software", "."], "sentence-detokenized": ", a company in Bangalore, India specializing in online handwritten text recognition software.", "token2charspan": [[0, 1], [2, 3], [4, 11], [12, 14], [15, 24], [24, 25], [26, 31], [32, 44], [45, 47], [48, 54], [55, 66], [67, 71], [72, 83], [84, 92], [92, 93]]}
{"doc_key": "ai-test-276", "ner": [[25, 26, "misc"], [49, 49, "metrics"], [51, 55, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[49, 49, 51, 55, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Do", "the", "repeated", "translations", "result", "in", "one", "expression", "in", "both", "languages", "?", "That", "is", ",", "does", "the", "method", "of", "translation", "indicate", "stationarity", "or", "create", "a", "canonical", "form", "?", "Does", "the", "translation", "become", "stationary", "without", "losing", "the", "original", "meaning", "?", "This", "metric", "has", "been", "criticized", "for", "not", "correlating", "well", "with", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "results", "."], "sentence-detokenized": "Do the repeated translations result in one expression in both languages? That is, does the method of translation indicate stationarity or create a canonical form? Does the translation become stationary without losing the original meaning? This metric has been criticized for not correlating well with BLEU (BiLingual Evaluation Understudy) results.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 28], [29, 35], [36, 38], [39, 42], [43, 53], [54, 56], [57, 61], [62, 71], [71, 72], [73, 77], [78, 80], [80, 81], [82, 86], [87, 90], [91, 97], [98, 100], [101, 112], [113, 121], [122, 134], [135, 137], [138, 144], [145, 146], [147, 156], [157, 161], [161, 162], [163, 167], [168, 171], [172, 183], [184, 190], [191, 201], [202, 209], [210, 216], [217, 220], [221, 229], [230, 237], [237, 238], [239, 243], [244, 250], [251, 254], [255, 259], [260, 270], [271, 274], [275, 278], [279, 290], [291, 295], [296, 300], [301, 305], [306, 307], [307, 316], [317, 327], [328, 338], [338, 339], [340, 347], [347, 348]]}
{"doc_key": "ai-test-277", "ner": [[6, 10, "organisation"], [13, 19, "organisation"], [21, 24, "university"], [31, 34, "university"], [27, 30, "field"], [36, 41, "organisation"], [44, 46, "organisation"], [55, 58, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[13, 19, 21, 24, "part-of", "", false, false], [31, 34, 27, 30, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "has", "held", "fellowships", "at", "the", "American", "Association", "for", "Artificial", "Intelligence", ",", "the", "Center", "for", "Advanced", "Studies", "in", "Behavioral", "Sciences", "at", "Stanford", "University", ",", "the", "Center", "for", "Cognitive", "Science", "at", "the", "Massachusetts", "Institute", "of", "Technology", ",", "the", "Canadian", "Institute", "for", "Advanced", "Studies", ",", "the", "Canadian", "Psychological", "Association", ",", "and", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "in", "1998", "."], "sentence-detokenized": "He has held fellowships at the American Association for Artificial Intelligence, the Center for Advanced Studies in Behavioral Sciences at Stanford University, the Center for Cognitive Science at the Massachusetts Institute of Technology, the Canadian Institute for Advanced Studies, the Canadian Psychological Association, and was elected a Fellow of the Royal Society of Canada in 1998.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 23], [24, 26], [27, 30], [31, 39], [40, 51], [52, 55], [56, 66], [67, 79], [79, 80], [81, 84], [85, 91], [92, 95], [96, 104], [105, 112], [113, 115], [116, 126], [127, 135], [136, 138], [139, 147], [148, 158], [158, 159], [160, 163], [164, 170], [171, 174], [175, 184], [185, 192], [193, 195], [196, 199], [200, 213], [214, 223], [224, 226], [227, 237], [237, 238], [239, 242], [243, 251], [252, 261], [262, 265], [266, 274], [275, 282], [282, 283], [284, 287], [288, 296], [297, 310], [311, 322], [322, 323], [324, 327], [328, 331], [332, 339], [340, 341], [342, 348], [349, 351], [352, 355], [356, 361], [362, 369], [370, 372], [373, 379], [380, 382], [383, 387], [387, 388]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 13, "researcher"], [15, 19, "misc"], [22, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 15, 19, "part-of", "", false, false], [0, 0, 22, 25, "part-of", "", false, false], [4, 5, 15, 19, "part-of", "", false, false], [4, 5, 22, 25, "part-of", "", false, false], [7, 13, 15, 19, "part-of", "", false, false], [7, 13, 22, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "-", "along", "with", "Joshua", "Bengio", "and", "Jan", "Lekun", "-", "have", "been", "called", "by", "some", "the", "godfathers", "of", "artificial", "intelligence", "and", "the", "godfathers", "of", "deep", "learning", "."], "sentence-detokenized": "Hinton - along with Joshua Bengio and Jan Lekun - have been called by some the godfathers of artificial intelligence and the godfathers of deep learning.", "token2charspan": [[0, 6], [7, 8], [9, 14], [15, 19], [20, 26], [27, 33], [34, 37], [38, 41], [42, 47], [48, 49], [50, 54], [55, 59], [60, 66], [67, 69], [70, 74], [75, 78], [79, 89], [90, 92], [93, 103], [104, 116], [117, 120], [121, 124], [125, 135], [136, 138], [139, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-test-279", "ner": [[6, 6, "product"], [19, 19, "misc"], [21, 22, "misc"], [23, 23, "product"], [28, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 19, 19, "related-to", "", false, false], [6, 6, 21, 22, "related-to", "", false, false], [19, 19, 23, 23, "named", "same", false, false], [28, 30, 23, 23, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "lightweight", "open", "source", "speech", "project", "eSpeak", ",", "which", "has", "its", "own", "approach", "to", "synthesis", ",", "is", "experimenting", "with", "Mandarin", "and", "Cantonese", ".", "eSpeak", "has", "been", "used", "by", "Google", "Translate", "since", "May", "2010", "."], "sentence-detokenized": "The lightweight open source speech project eSpeak, which has its own approach to synthesis, is experimenting with Mandarin and Cantonese. eSpeak has been used by Google Translate since May 2010.", "token2charspan": [[0, 3], [4, 15], [16, 20], [21, 27], [28, 34], [35, 42], [43, 49], [49, 50], [51, 56], [57, 60], [61, 64], [65, 68], [69, 77], [78, 80], [81, 90], [90, 91], [92, 94], [95, 108], [109, 113], [114, 122], [123, 126], [127, 136], [136, 137], [138, 144], [145, 148], [149, 153], [154, 158], [159, 161], [162, 168], [169, 178], [179, 184], [185, 188], [189, 193], [193, 194]]}
{"doc_key": "ai-test-280", "ner": [[13, 15, "product"], [10, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 15, 10, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1982", ",", "the", "first", "commercial", "all", "-", "software", "voice", "synthesis", "program", ",", "Software", "Automatic", "Mouth", ",", "was", "released", "."], "sentence-detokenized": "In 1982, the first commercial all-software voice synthesis program, Software Automatic Mouth, was released.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 18], [19, 29], [30, 33], [33, 34], [34, 42], [43, 48], [49, 58], [59, 66], [66, 67], [68, 76], [77, 86], [87, 92], [92, 93], [94, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-281", "ner": [[7, 9, "metrics"], [11, 11, "metrics"], [14, 14, "metrics"], [16, 16, "metrics"], [19, 26, "metrics"], [30, 32, "metrics"], [34, 34, "metrics"], [37, 43, "metrics"], [47, 49, "metrics"], [51, 51, "metrics"], [54, 54, "metrics"], [56, 56, "metrics"], [59, 66, "metrics"], [70, 72, "metrics"], [74, 74, "metrics"], [77, 83, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[11, 11, 7, 9, "named", "", false, false], [14, 14, 7, 9, "named", "", false, false], [16, 16, 7, 9, "named", "", false, false], [19, 26, 7, 9, "named", "", false, false], [34, 34, 30, 32, "named", "", false, false], [37, 43, 30, 32, "named", "", false, false], [51, 51, 47, 49, "named", "", false, false], [54, 54, 47, 49, "named", "", false, false], [56, 56, 47, 49, "named", "", false, false], [59, 66, 47, 49, "named", "", false, false], [74, 74, 70, 72, "named", "", false, false], [77, 83, 70, 72, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["The", "ratios", "in", "the", "column", "are", ":", "TRUE", "Positive", "Rate", "(", "TPR", ",", "aka", "Sensitivity", "or", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "with", "complement", "FALSE", "Negative", "Rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "and", "TRUE", "Negative", "Rate", "(", "TNR", ",", "aka", "Specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "with", "complement", "FALSE", "Positive", "Rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "The ratios in the column are: TRUE Positive Rate (TPR, aka Sensitivity or recall) (TP/(TP+FN)), with complement FALSE Negative Rate (FNR) (FN/(TP+FN)); and TRUE Negative Rate (TNR, aka Specificity, SPC) (TN/(TN+FP)), with complement FALSE Positive Rate (FPR) (FP/(TN+FP)).", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 17], [18, 24], [25, 28], [28, 29], [30, 34], [35, 43], [44, 48], [49, 50], [50, 53], [53, 54], [55, 58], [59, 70], [71, 73], [74, 80], [80, 81], [82, 83], [83, 85], [85, 86], [86, 87], [87, 89], [89, 90], [90, 92], [92, 93], [93, 94], [94, 95], [96, 100], [101, 111], [112, 117], [118, 126], [127, 131], [132, 133], [133, 136], [136, 137], [138, 139], [139, 141], [141, 142], [142, 143], [143, 145], [145, 146], [146, 148], [148, 149], [149, 150], [150, 151], [152, 155], [156, 160], [161, 169], [170, 174], [175, 176], [176, 179], [179, 180], [181, 184], [185, 196], [196, 197], [198, 201], [201, 202], [203, 204], [204, 206], [206, 207], [207, 208], [208, 210], [210, 211], [211, 213], [213, 214], [214, 215], [215, 216], [217, 221], [222, 232], [233, 238], [239, 247], [248, 252], [253, 254], [254, 257], [257, 258], [259, 260], [260, 262], [262, 263], [263, 264], [264, 266], [266, 267], [267, 269], [269, 270], [270, 271], [271, 272]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 15, 15, "role", "working_with", false, false], [2, 2, 15, 15, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "and", "Weber", "have", "collaborated", "on", "many", "other", "robots", ",", "and", "their", "experience", "working", "with", "Kismet"], "sentence-detokenized": "Edsinger and Weber have collaborated on many other robots, and their experience working with Kismet", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 36], [37, 39], [40, 44], [45, 50], [51, 57], [57, 58], [59, 62], [63, 68], [69, 79], [80, 87], [88, 92], [93, 99]]}
{"doc_key": "ai-test-283", "ner": [[0, 4, "programlang"], [12, 12, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 12, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["R", "functionality", "is", "also", "available", "from", "several", "scripting", "languages", ",", "such", "as", "Python", "."], "sentence-detokenized": "R functionality is also available from several scripting languages, such as Python.", "token2charspan": [[0, 1], [2, 15], [16, 18], [19, 23], [24, 33], [34, 38], [39, 46], [47, 56], [57, 66], [66, 67], [68, 72], [73, 75], [76, 82], [82, 83]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "was", "one", "of", "the", "first", "robot", "languages", "and", "was", "used", "in", "Unimate", "robots", "."], "sentence-detokenized": "VAL was one of the first robot languages and was used in Unimate robots.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 24], [25, 30], [31, 40], [41, 44], [45, 48], [49, 53], [54, 56], [57, 64], [65, 71], [71, 72]]}
{"doc_key": "ai-test-285", "ner": [[13, 22, "conference"], [20, 20, "conference"], [24, 24, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 22, 24, 24, "physical", "", false, false], [20, 20, 13, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["They", "presented", "their", "database", "for", "the", "first", "time", "as", "a", "poster", "at", "the", "2009", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "conference", "in", "Florida", "."], "sentence-detokenized": "They presented their database for the first time as a poster at the 2009 Computer Vision and Pattern Recognition (CVPR) conference in Florida.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 29], [30, 33], [34, 37], [38, 43], [44, 48], [49, 51], [52, 53], [54, 60], [61, 63], [64, 67], [68, 72], [73, 81], [82, 88], [89, 92], [93, 100], [101, 112], [113, 114], [114, 118], [118, 119], [120, 130], [131, 133], [134, 141], [141, 142]]}
{"doc_key": "ai-test-286", "ner": [[0, 2, "misc"], [9, 10, "task"], [12, 13, "field"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 0, 2, "type-of", "", false, false], [12, 13, 0, 2, "type-of", "", false, false], [15, 16, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Categorization", "tasks", "where", "no", "labels", "are", "provided", "are", "called", "unsupervised", "classification", ",", "unsupervised", "learning", ",", "cluster", "analysis", "."], "sentence-detokenized": "Categorization tasks where no labels are provided are called unsupervised classification, unsupervised learning, cluster analysis.", "token2charspan": [[0, 14], [15, 20], [21, 26], [27, 29], [30, 36], [37, 40], [41, 49], [50, 53], [54, 60], [61, 73], [74, 88], [88, 89], [90, 102], [103, 111], [111, 112], [113, 120], [121, 129], [129, 130]]}
{"doc_key": "ai-test-287", "ner": [[2, 3, "task"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "must", "recognize", "objects", ",", "recognize", "and", "detect", "people", ",", "and", "recognize", "emotions", "."], "sentence-detokenized": "It must recognize objects, recognize and detect people, and recognize emotions.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 25], [25, 26], [27, 36], [37, 40], [41, 47], [48, 54], [54, 55], [56, 59], [60, 69], [70, 78], [78, 79]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [8, 8, "misc"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "process", "is", "complex", "and", "involves", "encoding", "and", "recall", "or", "retrieval", "."], "sentence-detokenized": "The process is complex and involves encoding and recall or retrieval.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 26], [27, 35], [36, 44], [45, 48], [49, 55], [56, 58], [59, 68], [68, 69]]}
{"doc_key": "ai-test-289", "ner": [[7, 8, "product"], [12, 13, "product"], [30, 32, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 12, 13, "named", "", false, false], [7, 8, 30, 32, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Also", "known", "as", "parallel", "robots", "or", "generalized", "Stuart", "platforms", "(", "in", "the", "Stuart", "platform", ",", "actuators", "are", "paired", "on", "both", "the", "base", "and", "the", "platform", ")", ",", "these", "systems", "are", "articulated", "robots", "that", "use", "similar", "mechanisms", "to", "move", "the", "robot", "on", "the", "base", "or", "on", "one", "or", "more", "manipulator", "arms", "."], "sentence-detokenized": "Also known as parallel robots or generalized Stuart platforms (in the Stuart platform, actuators are paired on both the base and the platform), these systems are articulated robots that use similar mechanisms to move the robot on the base or on one or more manipulator arms.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 29], [30, 32], [33, 44], [45, 51], [52, 61], [62, 63], [63, 65], [66, 69], [70, 76], [77, 85], [85, 86], [87, 96], [97, 100], [101, 107], [108, 110], [111, 115], [116, 119], [120, 124], [125, 128], [129, 132], [133, 141], [141, 142], [142, 143], [144, 149], [150, 157], [158, 161], [162, 173], [174, 180], [181, 185], [186, 189], [190, 197], [198, 208], [209, 211], [212, 216], [217, 220], [221, 226], [227, 229], [230, 233], [234, 238], [239, 241], [242, 244], [245, 248], [249, 251], [252, 256], [257, 268], [269, 273], [273, 274]]}
{"doc_key": "ai-test-290", "ner": [[0, 1, "field"], [6, 7, "field"], [13, 16, "field"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 7, "part-of", "subfield", false, false], [0, 1, 13, 16, "compare", "", false, false], [13, 16, 21, 22, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "vision", "as", "a", "discipline", "of", "systems", "engineering", "can", "be", "considered", "distinct", "from", "computer", "vision", ",", "which", "is", "a", "type", "of", "computer", "science", "."], "sentence-detokenized": "Machine vision as a discipline of systems engineering can be considered distinct from computer vision, which is a type of computer science.", "token2charspan": [[0, 7], [8, 14], [15, 17], [18, 19], [20, 30], [31, 33], [34, 41], [42, 53], [54, 57], [58, 60], [61, 71], [72, 80], [81, 85], [86, 94], [95, 101], [101, 102], [103, 108], [109, 111], [112, 113], [114, 118], [119, 121], [122, 130], [131, 138], [138, 139]]}
{"doc_key": "ai-test-291", "ner": [[1, 2, "algorithm"], [8, 10, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "LSTM", "gate", "activation", "function", "is", "often", "the", "logistic", "sigmoid", "function", "."], "sentence-detokenized": "The LSTM gate activation function is often the logistic sigmoid function.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 24], [25, 33], [34, 36], [37, 42], [43, 46], [47, 55], [56, 63], [64, 72], [72, 73]]}
{"doc_key": "ai-test-292", "ner": [[5, 6, "metrics"], [19, 21, "metrics"], [23, 28, "metrics"], [31, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 19, 21, "named", "", false, false], [5, 6, 31, 33, "named", "", false, false], [23, 28, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "the", "(", "necessarily", "unique", ")", "efficient", "estimate", ",", "and", "therefore", "the", "minimum", "variance", "estimate", "(", "MVUE", ")", ",", "in", "addition", "to", "being", "a", "maximum", "likelihood", "estimate", "."], "sentence-detokenized": "In other words, the sample mean is the (necessarily unique) efficient estimate, and therefore the minimum variance estimate (MVUE), in addition to being a maximum likelihood estimate.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 38], [39, 40], [40, 51], [52, 58], [58, 59], [60, 69], [70, 78], [78, 79], [80, 83], [84, 93], [94, 97], [98, 105], [106, 114], [115, 123], [124, 125], [125, 129], [129, 130], [130, 131], [132, 134], [135, 143], [144, 146], [147, 152], [153, 154], [155, 162], [163, 173], [174, 182], [182, 183]]}
{"doc_key": "ai-test-293", "ner": [[1, 3, "academicjournal"], [6, 8, "researcher"], [10, 11, "researcher"], [14, 15, "researcher"], [23, 23, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 3, 23, 23, "topic", "", false, false], [1, 3, 26, 27, "topic", "", false, false], [6, 8, 1, 3, "role", "", false, false], [10, 11, 1, 3, "role", "", false, false], [14, 15, 1, 3, "role", "", false, false], [23, 23, 26, 27, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "2001", "Scientific", "American", "article", "by", "Berners", "-", "Lee", ",", "James", "Handler", ",", "and", "Ora", "Lascilla", "describes", "the", "expected", "evolution", "of", "the", "existing", "network", "to", "a", "semantic", "network", "."], "sentence-detokenized": "The 2001 Scientific American article by Berners-Lee, James Handler, and Ora Lascilla describes the expected evolution of the existing network to a semantic network.", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 28], [29, 36], [37, 39], [40, 47], [47, 48], [48, 51], [51, 52], [53, 58], [59, 66], [66, 67], [68, 71], [72, 75], [76, 84], [85, 94], [95, 98], [99, 107], [108, 117], [118, 120], [121, 124], [125, 133], [134, 141], [142, 144], [145, 146], [147, 155], [156, 163], [163, 164]]}
{"doc_key": "ai-test-294", "ner": [[0, 2, "misc"], [14, 15, "person"], [17, 17, "person"], [26, 30, "person"], [40, 40, "person"], [46, 48, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 15, 0, 2, "role", "actor_in_work", false, false], [17, 17, 14, 15, "named", "", false, false], [17, 17, 14, 15, "origin", "", false, false], [26, 30, 17, 17, "part-of", "", false, false], [46, 48, 17, 17, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Blade", "Runner", "used", "a", "number", "of", "lesser", "-", "known", "actors", "at", "the", "time", ":", "Sean", "Young", "plays", "Rachel", ",", "an", "experimental", "replicant", "who", "is", "implanted", "with", "Tyrell", "'s", "niece", "'s", "memories", ",", "leading", "her", "to", "believe", "she", "is", "human", ";", "Sammon", ",", "pp.", "92", "-", "93", "Nina", "Axelrod", "auditions", "for", "the", "role", "."], "sentence-detokenized": "Blade Runner used a number of lesser-known actors at the time: Sean Young plays Rachel, an experimental replicant who is implanted with Tyrell's niece's memories, leading her to believe she is human; Sammon, pp. 92-93 Nina Axelrod auditions for the role.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 19], [20, 26], [27, 29], [30, 36], [36, 37], [37, 42], [43, 49], [50, 52], [53, 56], [57, 61], [61, 62], [63, 67], [68, 73], [74, 79], [80, 86], [86, 87], [88, 90], [91, 103], [104, 113], [114, 117], [118, 120], [121, 130], [131, 135], [136, 142], [142, 144], [145, 150], [150, 152], [153, 161], [161, 162], [163, 170], [171, 174], [175, 177], [178, 185], [186, 189], [190, 192], [193, 198], [198, 199], [200, 206], [206, 207], [208, 211], [212, 214], [214, 215], [215, 217], [218, 222], [223, 230], [231, 240], [241, 244], [245, 248], [249, 253], [253, 254]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 13, "university"], [21, 23, "product"], [25, 25, "product"], [40, 40, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 12, 13, "physical", "", false, false], [3, 4, 12, 13, "physical", "", false, false], [6, 7, 12, 13, "physical", "", false, false], [9, 10, 12, 13, "physical", "", false, false], [12, 13, 40, 40, "physical", "", true, false], [21, 23, 12, 13, "temporal", "", false, false], [25, 25, 12, 13, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Jerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Pappert", "and", "Terry", "Winograd", "visited", "Edinburgh", "University", "in", "1971", ",", "spreading", "the", "news", "of", "Micro", "-", "Planner", "and", "SHRDLU", "and", "questioning", "the", "unified", "resolution", "proof", "procedure", "approach", "that", "had", "been", "a", "mainstay", "of", "Edinburgh", "logicians", "."], "sentence-detokenized": "Jerry Sussman, Eugene Charniak, Seymour Pappert and Terry Winograd visited Edinburgh University in 1971, spreading the news of Micro-Planner and SHRDLU and questioning the unified resolution proof procedure approach that had been a mainstay of Edinburgh logicians.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 47], [48, 51], [52, 57], [58, 66], [67, 74], [75, 84], [85, 95], [96, 98], [99, 103], [103, 104], [105, 114], [115, 118], [119, 123], [124, 126], [127, 132], [132, 133], [133, 140], [141, 144], [145, 151], [152, 155], [156, 167], [168, 171], [172, 179], [180, 190], [191, 196], [197, 206], [207, 215], [216, 220], [221, 224], [225, 229], [230, 231], [232, 240], [241, 243], [244, 253], [254, 263], [263, 264]]}
{"doc_key": "ai-test-296", "ner": [[0, 0, "researcher"], [8, 9, "field"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 13, 14, "role", "inspires", false, false], [0, 0, 16, 17, "role", "inspires", false, false], [0, 0, 19, 20, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Walter", "'s", "work", "inspired", "the", "next", "generation", "of", "robotics", "researchers", ",", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work inspired the next generation of robotics researchers, such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 22], [23, 26], [27, 31], [32, 42], [43, 45], [46, 54], [55, 66], [66, 67], [68, 72], [73, 75], [76, 82], [83, 89], [89, 90], [91, 95], [96, 103], [104, 107], [108, 112], [113, 119], [119, 120]]}
{"doc_key": "ai-test-297", "ner": [[7, 7, "algorithm"], [9, 10, "researcher"], [16, 22, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 9, 10, "origin", "", false, false], [7, 7, 16, 22, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Subsequently", ",", "a", "similar", "GPU", "-", "based", "CNN", "by", "Alex", "Krizhevsky", "et", "al", ".", "won", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "2012", "."], "sentence-detokenized": "Subsequently, a similar GPU-based CNN by Alex Krizhevsky et al. won the ImageNet Large Scale Visual Recognition Challenge 2012.", "token2charspan": [[0, 12], [12, 13], [14, 15], [16, 23], [24, 27], [27, 28], [28, 33], [34, 37], [38, 40], [41, 45], [46, 56], [57, 59], [60, 62], [62, 63], [64, 67], [68, 71], [72, 80], [81, 86], [87, 92], [93, 99], [100, 111], [112, 121], [122, 126], [126, 127]]}
{"doc_key": "ai-test-298", "ner": [[2, 3, "misc"], [8, 9, "metrics"], [11, 12, "metrics"], [17, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 2, 3, "type-of", "", false, false], [11, 12, 2, 3, "type-of", "", false, false], [11, 12, 17, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Commonly", "used", "loss", "functions", "in", "probabilistic", "classification", "include", "logarithmic", "loss", "and", "Brier", "score", "between", "the", "predicted", "and", "true", "probability", "distributions", "."], "sentence-detokenized": "Commonly used loss functions in probabilistic classification include logarithmic loss and Brier score between the predicted and true probability distributions.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 28], [29, 31], [32, 45], [46, 60], [61, 68], [69, 80], [81, 85], [86, 89], [90, 95], [96, 101], [102, 109], [110, 113], [114, 123], [124, 127], [128, 132], [133, 144], [145, 158], [158, 159]]}
{"doc_key": "ai-test-299", "ner": [[4, 4, "organisation"], [13, 13, "field"], [8, 8, "organisation"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 13, 13, "general-affiliation", "field_of_study", false, false], [4, 4, 17, 18, "part-of", "", false, false], [8, 8, 4, 4, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "May", "2016", ",", "NtechLab", "was", "admitted", "to", "NIST", "'s", "official", "testing", "of", "biometric", "technologies", "among", "three", "Russian", "companies", "."], "sentence-detokenized": "In May 2016, NtechLab was admitted to NIST's official testing of biometric technologies among three Russian companies.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [22, 25], [26, 34], [35, 37], [38, 42], [42, 44], [45, 53], [54, 61], [62, 64], [65, 74], [75, 87], [88, 93], [94, 99], [100, 107], [108, 117], [117, 118]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "floating", "point", "numbers", "only", "have", "a", "certain", "mathematical", "precision", "."], "sentence-detokenized": "However, floating point numbers only have a certain mathematical precision.", "token2charspan": [[0, 7], [7, 8], [9, 17], [18, 23], [24, 31], [32, 36], [37, 41], [42, 43], [44, 51], [52, 64], [65, 74], [74, 75]]}
{"doc_key": "ai-test-301", "ner": [[4, 4, "organisation"], [10, 18, "conference"], [16, 16, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 10, 18, "role", "contributes_to", false, false], [16, 16, 10, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2015", ",", "many", "SenseTime", "papers", "were", "accepted", "at", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "conference", "."], "sentence-detokenized": "In 2015, many SenseTime papers were accepted at the Computer Vision and Pattern Recognition (CVPR) conference.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 13], [14, 23], [24, 30], [31, 35], [36, 44], [45, 47], [48, 51], [52, 60], [61, 67], [68, 71], [72, 79], [80, 91], [92, 93], [93, 97], [97, 98], [99, 109], [109, 110]]}
{"doc_key": "ai-test-302", "ner": [[5, 7, "task"], [9, 9, "task"], [12, 13, "task"], [15, 18, "task"], [21, 21, "field"], [23, 25, "misc"], [28, 33, "conference"], [41, 43, "misc"], [45, 46, "conference"], [66, 67, "misc"], [69, 69, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 7, 21, 21, "part-of", "task_part_of_field", false, false], [9, 9, 5, 7, "named", "", false, false], [12, 13, 21, 21, "part-of", "task_part_of_field", false, false], [15, 18, 12, 13, "named", "", false, false], [23, 25, 28, 33, "temporal", "", false, false], [41, 43, 45, 46, "temporal", "", false, false], [66, 67, 69, 69, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["He", "co-authored", "optimal", "algorithms", "for", "Structure", "From", "Motion", "(", "SFM", ",", "or", "Visual", "SLAM", ",", "simultaneous", "localization", "and", "mapping", ",", "in", "robotics", ";", "best", "paper", "award", "at", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "Conference", "1998", ")", ",", "characterized", "its", "ambiguities", "(", "David", "Marr", "award", "at", "ICCV", "1999", ")", ",", "also", "characterized", "the", "ability", "to", "identify", "and", "monitor", "the", "fusion", "of", "visual", "and", "inertial", "sensors", "(", "best", "paper", "award", "at", "Robotics", "2015", ")", "."], "sentence-detokenized": "He co-authored optimal algorithms for Structure From Motion (SFM, or Visual SLAM, simultaneous localization and mapping, in robotics; best paper award at the Computer Vision and Pattern Recognition Conference 1998), characterized its ambiguities (David Marr award at ICCV 1999 ), also characterized the ability to identify and monitor the fusion of visual and inertial sensors (best paper award at Robotics 2015).", "token2charspan": [[0, 2], [3, 14], [15, 22], [23, 33], [34, 37], [38, 47], [48, 52], [53, 59], [60, 61], [61, 64], [64, 65], [66, 68], [69, 75], [76, 80], [80, 81], [82, 94], [95, 107], [108, 111], [112, 119], [119, 120], [121, 123], [124, 132], [132, 133], [134, 138], [139, 144], [145, 150], [151, 153], [154, 157], [158, 166], [167, 173], [174, 177], [178, 185], [186, 197], [198, 208], [209, 213], [213, 214], [214, 215], [216, 229], [230, 233], [234, 245], [246, 247], [247, 252], [253, 257], [258, 263], [264, 266], [267, 271], [272, 276], [277, 278], [278, 279], [280, 284], [285, 298], [299, 302], [303, 310], [311, 313], [314, 322], [323, 326], [327, 334], [335, 338], [339, 345], [346, 348], [349, 355], [356, 359], [360, 368], [369, 376], [377, 378], [378, 382], [383, 388], [389, 394], [395, 397], [398, 406], [407, 411], [411, 412], [412, 413]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 11, "field"], [13, 16, "field"], [21, 22, "task"], [25, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 7, 8, "part-of", "task_part_of_field", false, false], [0, 1, 10, 11, "part-of", "task_part_of_field", false, false], [0, 1, 13, 16, "part-of", "task_part_of_field", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 25, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "an", "essential", "tool", "in", "image", "processing", ",", "machine", "vision", "and", "computer", "vision", ",", "especially", "in", "the", "areas", "of", "feature", "detection", "and", "feature", "extraction", "."], "sentence-detokenized": "Edge detection is an essential tool in image processing, machine vision and computer vision, especially in the areas of feature detection and feature extraction.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 20], [21, 30], [31, 35], [36, 38], [39, 44], [45, 55], [55, 56], [57, 64], [65, 71], [72, 75], [76, 84], [85, 91], [91, 92], [93, 103], [104, 106], [107, 110], [111, 116], [117, 119], [120, 127], [128, 137], [138, 141], [142, 149], [150, 160], [160, 161]]}
{"doc_key": "ai-test-305", "ner": [[8, 9, "misc"], [28, 30, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "example", "is", "a", "variable", "such", "as", "the", "outdoor", "temperature", "(", "mathtemp", "/", "math", ")", ",", "which", "in", "a", "given", "application", "can", "be", "recorded", "to", "several", "decimal", "places", "(", "depending", "on", "the", "readout", "apparatus", ")", "."], "sentence-detokenized": "An example is a variable such as the outdoor temperature (mathtemp / math), which in a given application can be recorded to several decimal places (depending on the readout apparatus).", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 29], [30, 32], [33, 36], [37, 44], [45, 56], [57, 58], [58, 66], [67, 68], [69, 73], [73, 74], [74, 75], [76, 81], [82, 84], [85, 86], [87, 92], [93, 104], [105, 108], [109, 111], [112, 120], [121, 123], [124, 131], [132, 139], [140, 146], [147, 148], [148, 157], [158, 160], [161, 164], [165, 172], [173, 182], [182, 183], [183, 184]]}
{"doc_key": "ai-test-306", "ner": [[3, 4, "person"], [6, 7, "person"], [9, 14, "person"], [19, 20, "person"], [22, 22, "misc"], [26, 26, "misc"], [28, 29, "person"], [32, 32, "organisation"], [34, 35, "person"], [37, 37, "organisation"], [39, 42, "person"], [43, 43, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[28, 29, 22, 22, "part-of", "", false, false], [28, 29, 26, 26, "role", "", false, false], [34, 35, 32, 32, "role", "", false, false], [39, 42, 37, 37, "role", "youtuber", false, false], [43, 43, 39, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Returning", "judges", "include", "Von", "Davis", ",", "Jessica", "Chobot", "and", "Leland", "Melvin", ",", "as", "well", "as", "celebrity", "guest", "judges", "actor", "Clark", "Gregg", ",", "MythBusters", "host", "and", "former", "Battlebots", "builder", "Adam", "Savage", ",", "the", "NFL", "'s", "Vernon", "Davis", "and", "YouTube", "star", "Michael", "Stevens", ",", "aka", "Vsauce", "."], "sentence-detokenized": "Returning judges include Von Davis, Jessica Chobot and Leland Melvin, as well as celebrity guest judges actor Clark Gregg, MythBusters host and former Battlebots builder Adam Savage, the NFL's Vernon Davis and YouTube star Michael Stevens, aka Vsauce.", "token2charspan": [[0, 9], [10, 16], [17, 24], [25, 28], [29, 34], [34, 35], [36, 43], [44, 50], [51, 54], [55, 61], [62, 68], [68, 69], [70, 72], [73, 77], [78, 80], [81, 90], [91, 96], [97, 103], [104, 109], [110, 115], [116, 121], [121, 122], [123, 134], [135, 139], [140, 143], [144, 150], [151, 161], [162, 169], [170, 174], [175, 181], [181, 182], [183, 186], [187, 190], [190, 192], [193, 199], [200, 205], [206, 209], [210, 217], [218, 222], [223, 230], [231, 238], [238, 239], [240, 243], [244, 250], [250, 251]]}
{"doc_key": "ai-test-307", "ner": [[8, 9, "algorithm"], [10, 14, "algorithm"], [16, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 16, 18, "part-of", "", false, false], [10, 14, 16, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["But", "these", "methods", "never", "managed", "to", "outperform", "the", "Gaussian", "mixture", "model", "/", "hidden", "Markov", "model", "(", "GMM", "-", "HMM", ")", "nonuniform", "inner", "modeling", "technology", "based", "on", "generative", "speech", "models", "trained", "in", "a", "discriminative", "manner", "."], "sentence-detokenized": "But these methods never managed to outperform the Gaussian mixture model/hidden Markov model (GMM-HMM) nonuniform inner modeling technology based on generative speech models trained in a discriminative manner.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 23], [24, 31], [32, 34], [35, 45], [46, 49], [50, 58], [59, 66], [67, 72], [72, 73], [73, 79], [80, 86], [87, 92], [93, 94], [94, 97], [97, 98], [98, 101], [101, 102], [103, 113], [114, 119], [120, 128], [129, 139], [140, 145], [146, 148], [149, 159], [160, 166], [167, 173], [174, 181], [182, 184], [185, 186], [187, 201], [202, 208], [208, 209]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "and", "SciPy", "provide", "convenient", "ways", "to", "apply", "these", "different", "methods", "."], "sentence-detokenized": "Software packages such as MATLAB, GNU Octave, Scilab and SciPy provide convenient ways to apply these different methods.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [53, 56], [57, 62], [63, 70], [71, 81], [82, 86], [87, 89], [90, 95], [96, 101], [102, 111], [112, 119], [119, 120]]}
{"doc_key": "ai-test-309", "ner": [[5, 7, "algorithm"], [9, 13, "algorithm"], [16, 17, "researcher"], [19, 20, "university"], [22, 23, "researcher"], [25, 28, "organisation"], [30, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7], "relations": [[5, 7, 16, 17, "origin", "", false, false], [5, 7, 22, 23, "origin", "", false, false], [9, 13, 5, 7, "named", "", false, false], [16, 17, 19, 20, "physical", "", false, false], [16, 17, 19, 20, "role", "", false, false], [22, 23, 25, 28, "physical", "", false, false], [22, 23, 25, 28, "role", "", false, false], [30, 30, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "speech", "processing", "algorithm", ",", "Linear", "Predictive", "Coding", "(", "LPC", ")", ",", "was", "first", "proposed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", "."], "sentence-detokenized": "The speech processing algorithm, Linear Predictive Coding (LPC), was first proposed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966.", "token2charspan": [[0, 3], [4, 10], [11, 21], [22, 31], [31, 32], [33, 39], [40, 50], [51, 57], [58, 59], [59, 62], [62, 63], [63, 64], [65, 68], [69, 74], [75, 83], [84, 86], [87, 95], [96, 103], [104, 106], [107, 113], [114, 124], [125, 128], [129, 134], [135, 140], [141, 143], [144, 150], [151, 160], [161, 164], [165, 174], [175, 176], [176, 179], [179, 180], [181, 183], [184, 188], [188, 189]]}
{"doc_key": "ai-test-310", "ner": [[20, 27, "conference"], [29, 29, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[29, 29, 20, 27, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2006", ",", "on", "the", "occasion", "of", "the", "25th", "anniversary", "of", "the", "algorithm", ",", "a", "workshop", "was", "organized", "at", "the", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "to", "summarize", "the", "latest", "contributions", "and", "variations", "of", "the", "original", "algorithm", ",", "designed", "primarily", "to", "improve", "the", "speed", "of", "the", "algorithm", ",", "the", "reliability", "and", "accuracy", "of", "the", "estimated", "solution", ",", "and", "to", "reduce", "dependence", "on", "user", "-", "defined", "constants", "."], "sentence-detokenized": "In 2006, on the occasion of the 25th anniversary of the algorithm, a workshop was organized at the International Conference on Computer Vision and Pattern Recognition (CVPR) to summarize the latest contributions and variations of the original algorithm, designed primarily to improve the speed of the algorithm, the reliability and accuracy of the estimated solution, and to reduce dependence on user-defined constants.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 24], [25, 27], [28, 31], [32, 36], [37, 48], [49, 51], [52, 55], [56, 65], [65, 66], [67, 68], [69, 77], [78, 81], [82, 91], [92, 94], [95, 98], [99, 112], [113, 123], [124, 126], [127, 135], [136, 142], [143, 146], [147, 154], [155, 166], [167, 168], [168, 172], [172, 173], [174, 176], [177, 186], [187, 190], [191, 197], [198, 211], [212, 215], [216, 226], [227, 229], [230, 233], [234, 242], [243, 252], [252, 253], [254, 262], [263, 272], [273, 275], [276, 283], [284, 287], [288, 293], [294, 296], [297, 300], [301, 310], [310, 311], [312, 315], [316, 327], [328, 331], [332, 340], [341, 343], [344, 347], [348, 357], [358, 366], [366, 367], [368, 371], [372, 374], [375, 381], [382, 392], [393, 395], [396, 400], [400, 401], [401, 408], [409, 418], [418, 419]]}
{"doc_key": "ai-test-311", "ner": [[6, 8, "university"], [11, 16, "organisation"], [17, 19, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Members", "of", "the", "club", "visit", "the", "University", "of", "Debrecen", ",", "the", "Hungarian", "Academy", "of", "Sciences", ",", "the", "Etv\u00e1sz", "Lor\u00e1nd", "University", ",", "etc", "."], "sentence-detokenized": "Members of the club visit the University of Debrecen, the Hungarian Academy of Sciences, the Etv\u00e1sz Lor\u00e1nd University, etc.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 19], [20, 25], [26, 29], [30, 40], [41, 43], [44, 52], [52, 53], [54, 57], [58, 67], [68, 75], [76, 78], [79, 87], [87, 88], [89, 92], [93, 99], [100, 106], [107, 117], [117, 118], [119, 122], [122, 123]]}
{"doc_key": "ai-test-312", "ner": [[3, 4, "algorithm"], [16, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 16, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "extend", "the", "SVM", "for", "cases", "where", "the", "data", "are", "not", "linearly", "separated", ",", "we", "introduce", "the", "loss", "function", ","], "sentence-detokenized": "To extend the SVM for cases where the data are not linearly separated, we introduce the loss function,", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 17], [18, 21], [22, 27], [28, 33], [34, 37], [38, 42], [43, 46], [47, 50], [51, 59], [60, 69], [69, 70], [71, 73], [74, 83], [84, 87], [88, 92], [93, 101], [101, 102]]}
{"doc_key": "ai-test-313", "ner": [[0, 0, "programlang"], [10, 11, "researcher"], [13, 14, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 10, 11, "origin", "", false, false], [0, 0, 13, 14, "origin", "", false, false], [0, 0, 17, 18, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "is", "an", "educational", "programming", "language", "developed", "in", "1967", "by", "Wally", "Voerzig", ",", "Seymour", "Papert", ",", "and", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo is an educational programming language developed in 1967 by Wally Voerzig, Seymour Papert, and Cynthia Solomon.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 34], [35, 43], [44, 53], [54, 56], [57, 61], [62, 64], [65, 70], [71, 78], [78, 79], [80, 87], [88, 94], [94, 95], [96, 99], [100, 107], [108, 115], [115, 116]]}
{"doc_key": "ai-test-314", "ner": [[0, 3, "organisation"], [6, 10, "organisation"], [12, 15, "location"], [17, 17, "location"], [19, 19, "location"], [30, 41, "product"], [43, 49, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 6, 10, "role", "works_for", false, false], [6, 10, 12, 15, "physical", "", false, false], [12, 15, 17, 17, "physical", "", false, false], [17, 17, 19, 19, "physical", "", false, false], [30, 41, 0, 3, "origin", "", false, false], [43, 49, 30, 41, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "Eyring", "Research", "Institute", "helped", "the", "U.S.", "Air", "Force", "Missile", "Command", "at", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", ",", "create", ",", "under", "conditions", "of", "strict", "military", "secrecy", ",", "the", "software", "for", "the", "Intelligent", "Systems", "technology", "that", "was", "the", "basis", "of", "what", "Reagan", "later", "called", "the", "Star", "Wars", "program", "."], "sentence-detokenized": "The Eyring Research Institute helped the U.S. Air Force Missile Command at Hill Air Force Base near Ogden, Utah, create, under conditions of strict military secrecy, the software for the Intelligent Systems technology that was the basis of what Reagan later called the Star Wars program.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 29], [30, 36], [37, 40], [41, 45], [46, 49], [50, 55], [56, 63], [64, 71], [72, 74], [75, 79], [80, 83], [84, 89], [90, 94], [95, 99], [100, 105], [105, 106], [107, 111], [111, 112], [113, 119], [119, 120], [121, 126], [127, 137], [138, 140], [141, 147], [148, 156], [157, 164], [164, 165], [166, 169], [170, 178], [179, 182], [183, 186], [187, 198], [199, 206], [207, 217], [218, 222], [223, 226], [227, 230], [231, 236], [237, 239], [240, 244], [245, 251], [252, 257], [258, 264], [265, 268], [269, 273], [274, 278], [279, 286], [286, 287]]}
{"doc_key": "ai-test-315", "ner": [[11, 12, "field"], [22, 25, "researcher"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Over", "the", "decades", ",", "he", "explored", "and", "developed", "new", "areas", "of", "computer", "science", "from", "compiler", ",", "programming", "languages", ",", "and", "system", "architecture", "John", "F", ".", "Sowa", "and", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "Over the decades, he explored and developed new areas of computer science from compiler, programming languages, and system architecture John F. Sowa and John Zachman (1992).", "token2charspan": [[0, 4], [5, 8], [9, 16], [16, 17], [18, 20], [21, 29], [30, 33], [34, 43], [44, 47], [48, 53], [54, 56], [57, 65], [66, 73], [74, 78], [79, 87], [87, 88], [89, 100], [101, 110], [110, 111], [112, 115], [116, 122], [123, 135], [136, 140], [141, 142], [142, 143], [144, 148], [149, 152], [153, 157], [158, 165], [166, 167], [167, 171], [171, 172], [172, 173]]}
{"doc_key": "ai-test-316", "ner": [[0, 2, "algorithm"], [6, 10, "algorithm"], [12, 13, "algorithm"], [18, 19, "field"], [21, 24, "field"], [26, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 10, 0, 2, "named", "", false, false], [12, 13, 0, 2, "named", "", false, false], [18, 19, 0, 2, "usage", "", false, false], [21, 24, 0, 2, "usage", "", false, false], [26, 29, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Sobel", "operator", ",", "sometimes", "called", "the", "Sobel", "-", "Feldman", "operator", "or", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "especially", "in", "edge", "detection", "algorithms", "where", "it", "creates", "an", "image", "with", "highlighted", "edges", "."], "sentence-detokenized": "The Sobel operator, sometimes called the Sobel-Feldman operator or Sobel filter, is used in image processing and computer vision, especially in edge detection algorithms where it creates an image with highlighted edges.", "token2charspan": [[0, 3], [4, 9], [10, 18], [18, 19], [20, 29], [30, 36], [37, 40], [41, 46], [46, 47], [47, 54], [55, 63], [64, 66], [67, 72], [73, 79], [79, 80], [81, 83], [84, 88], [89, 91], [92, 97], [98, 108], [109, 112], [113, 121], [122, 128], [128, 129], [130, 140], [141, 143], [144, 148], [149, 158], [159, 169], [170, 175], [176, 178], [179, 186], [187, 189], [190, 195], [196, 200], [201, 212], [213, 218], [218, 219]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [3, 4, "field"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 4, "compare", "", false, false], [0, 0, 3, 4, "type-of", "", false, false], [0, 0, 15, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "is", "a", "supervised", "learning", "algorithm", "that", "uses", "the", "labels", "of", "the", "data", ",", "while", "PCA", "is", "a", "learning", "algorithm", "that", "ignores", "the", "labels", "."], "sentence-detokenized": "LDA is a supervised learning algorithm that uses the labels of the data, while PCA is a learning algorithm that ignores the labels.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 19], [20, 28], [29, 38], [39, 43], [44, 48], [49, 52], [53, 59], [60, 62], [63, 66], [67, 71], [71, 72], [73, 78], [79, 82], [83, 85], [86, 87], [88, 96], [97, 106], [107, 111], [112, 119], [120, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "linear", "classification", "algorithms", "include", "Winnow", ",", "support", "vector", "machine", "and", "logistic", "regression", "."], "sentence-detokenized": "Other linear classification algorithms include Winnow, support vector machine and logistic regression.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 38], [39, 46], [47, 53], [53, 54], [55, 62], [63, 69], [70, 77], [78, 81], [82, 90], [91, 101], [101, 102]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [6, 7, "programlang"], [16, 17, "product"], [19, 19, "programlang"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 7, "general-affiliation", "", true, false], [0, 0, 16, 17, "general-affiliation", "", true, false], [0, 0, 19, 19, "general-affiliation", "", true, false], [0, 0, 22, 22, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "consists", "of", "a", "library", "of", "C", "++", "classes", "and", "several", "interpreted", "interface", "layers", ",", "including", "Tcl/", "Tk", ",", "Java", ",", "and", "Python", "."], "sentence-detokenized": "VTK consists of a library of C++ classes and several interpreted interface layers, including Tcl/Tk, Java, and Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 17], [18, 25], [26, 28], [29, 30], [30, 32], [33, 40], [41, 44], [45, 52], [53, 64], [65, 74], [75, 81], [81, 82], [83, 92], [93, 97], [97, 99], [99, 100], [101, 105], [105, 106], [107, 110], [111, 117], [117, 118]]}
{"doc_key": "ai-test-320", "ner": [[9, 12, "task"], [18, 20, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Also", ",", "text", "created", "by", "processing", "spontaneous", "speech", "using", "automatic", "speech", "recognition", "and", "printed", "or", "handwritten", "text", "using", "optical", "character", "recognition", "contain", "processing", "noise", "."], "sentence-detokenized": "Also, text created by processing spontaneous speech using automatic speech recognition and printed or handwritten text using optical character recognition contain processing noise.", "token2charspan": [[0, 4], [4, 5], [6, 10], [11, 18], [19, 21], [22, 32], [33, 44], [45, 51], [52, 57], [58, 67], [68, 74], [75, 86], [87, 90], [91, 98], [99, 101], [102, 113], [114, 118], [119, 124], [125, 132], [133, 142], [143, 154], [155, 162], [163, 173], [174, 179], [179, 180]]}
{"doc_key": "ai-test-321", "ner": [[0, 2, "researcher"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 12, 12, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "is", "the", "author", "of", "several", "books", "and", "led", "the", "development", "of", "WordNet", ",", "an", "online", "database", "of", "word", "relationships", "that", "can", "be", "used", "by", "computer", "programs", "."], "sentence-detokenized": "Miller is the author of several books and led the development of WordNet, an online database of word relationships that can be used by computer programs.", "token2charspan": [[0, 6], [7, 9], [10, 13], [14, 20], [21, 23], [24, 31], [32, 37], [38, 41], [42, 45], [46, 49], [50, 61], [62, 64], [65, 72], [72, 73], [74, 76], [77, 83], [84, 92], [93, 95], [96, 100], [101, 114], [115, 119], [120, 123], [124, 126], [127, 131], [132, 134], [135, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-test-322", "ner": [[1, 5, "field"], [8, 10, "organisation"], [13, 14, "country"], [16, 17, "person"], [19, 21, "person"], [23, 24, "person"], [26, 27, "person"], [30, 31, "country"], [33, 36, "location"], [38, 39, "misc"], [40, 41, "person"], [43, 44, "person"], [46, 46, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 10, 13, 14, "physical", "", false, false], [16, 17, 30, 31, "physical", "", false, false], [19, 21, 30, 31, "physical", "", false, false], [23, 24, 30, 31, "physical", "", false, false], [26, 27, 30, 31, "physical", "", false, false], [33, 36, 1, 5, "general-affiliation", "", false, false], [33, 36, 40, 41, "artifact", "", false, false], [38, 39, 40, 41, "named", "", false, false], [43, 44, 46, 46, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Contemporary", "automata", "are", "represented", "by", "the", "works", "of", "Cabaret", "Mechanical", "Theatre", "in", "the", "United", "Kingdom", ",", "Dug", "North", "and", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "in", "the", "United", "States", ",", "Le", "D\u00e9fenseur", "du", "Temps", "by", "French", "artist", "Jacques", "Monestier", "and", "Fran\u00e7ois", "Junod", "in", "Switzerland", "."], "sentence-detokenized": "Contemporary automata are represented by the works of Cabaret Mechanical Theatre in the United Kingdom, Dug North and Chomick + Meder, Arthur Ganson, Joe Jones in the United States, Le D\u00e9fenseur du Temps by French artist Jacques Monestier and Fran\u00e7ois Junod in Switzerland.", "token2charspan": [[0, 12], [13, 21], [22, 25], [26, 37], [38, 40], [41, 44], [45, 50], [51, 53], [54, 61], [62, 72], [73, 80], [81, 83], [84, 87], [88, 94], [95, 102], [102, 103], [104, 107], [108, 113], [114, 117], [118, 125], [126, 127], [128, 133], [133, 134], [135, 141], [142, 148], [148, 149], [150, 153], [154, 159], [160, 162], [163, 166], [167, 173], [174, 180], [180, 181], [182, 184], [185, 194], [195, 197], [198, 203], [204, 206], [207, 213], [214, 220], [221, 228], [229, 238], [239, 242], [243, 251], [252, 257], [258, 260], [261, 272], [272, 273]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 22, 22, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "includes", "standard", "codefor", "/", "code", "and", "codewhile", "/", "code", "loops", ",", "but", "(", "as", "in", "other", "similar", "applications", ",", "e.g.", ",", "R", ")", "the", "use", "of", "vectorized", "notation", "is", "encouraged", "and", "is", "often", "faster", "to", "execute", "."], "sentence-detokenized": "MATLAB includes standard codefor/code and codewhile/code loops, but (as in other similar applications, e.g., R) the use of vectorized notation is encouraged and is often faster to execute.", "token2charspan": [[0, 6], [7, 15], [16, 24], [25, 32], [32, 33], [33, 37], [38, 41], [42, 51], [51, 52], [52, 56], [57, 62], [62, 63], [64, 67], [68, 69], [69, 71], [72, 74], [75, 80], [81, 88], [89, 101], [101, 102], [103, 107], [107, 108], [109, 110], [110, 111], [112, 115], [116, 119], [120, 122], [123, 133], [134, 142], [143, 145], [146, 156], [157, 160], [161, 163], [164, 169], [170, 176], [177, 179], [180, 187], [187, 188]]}
{"doc_key": "ai-test-324", "ner": [[3, 3, "researcher"], [9, 14, "conference"], [17, 19, "field"], [21, 28, "misc"], [31, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 21, 28, "win-defeat", "", false, false], [3, 3, 31, 40, "win-defeat", "", false, false], [21, 28, 9, 14, "temporal", "", false, false], [21, 28, 17, 19, "topic", "", false, false], [31, 40, 9, 14, "temporal", "", false, false], [31, 40, 17, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2007", ".", "Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "for", "his", "achievements", "in", "computer", "science", "education", ":", "the", "Karl", "V", ".", "Karlstrom", "Outstanding", "Educator", "Award", "and", "the", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contributions", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "In 2007. Pausch received two awards from the Association for Computing Machinery for his achievements in computer science education: the Karl V. Karlstrom Outstanding Educator Award and the ACM SIGCSE Award for Outstanding Contributions to Computer Science Education.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 24], [25, 28], [29, 35], [36, 40], [41, 44], [45, 56], [57, 60], [61, 70], [71, 80], [81, 84], [85, 88], [89, 101], [102, 104], [105, 113], [114, 121], [122, 131], [131, 132], [133, 136], [137, 141], [142, 143], [143, 144], [145, 154], [155, 166], [167, 175], [176, 181], [182, 185], [186, 189], [190, 193], [194, 200], [201, 206], [207, 210], [211, 222], [223, 236], [237, 239], [240, 248], [249, 256], [257, 266], [266, 267]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [8, 11, "product"], [9, 9, "product"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 11, "role", "sells", false, false], [8, 11, 9, 9, "general-affiliation", "", false, false], [8, 11, 17, 18, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "in", "1961", "to", "General", "Motors", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered in 1961 to General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 83], [84, 86], [87, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-326", "ner": [[0, 1, "algorithm"], [5, 7, "field"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 1, "usage", "", false, false], [11, 12, 5, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantic", "networks", "are", "used", "in", "natural", "language", "processing", "applications", "such", "as", "semantic", "parsing", "."], "sentence-detokenized": "Semantic networks are used in natural language processing applications such as semantic parsing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 26], [27, 29], [30, 37], [38, 46], [47, 57], [58, 70], [71, 75], [76, 78], [79, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-327", "ner": [[4, 5, "field"], [7, 8, "field"], [10, 11, "task"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 8, 4, 5, "usage", "", false, false], [10, 11, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Some", "successful", "applications", "of", "deep", "learning", "are", "computer", "vision", "and", "speech", "recognition", ".", "Honglak", "Lee", ",", "Roger", "Gross", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Some successful applications of deep learning are computer vision and speech recognition. Honglak Lee, Roger Gross, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 31], [32, 36], [37, 45], [46, 49], [50, 58], [59, 65], [66, 69], [70, 76], [77, 88], [88, 89], [90, 97], [98, 101], [101, 102], [103, 108], [109, 114], [114, 115], [116, 122], [123, 132], [132, 133], [134, 140], [141, 142], [142, 143], [144, 146], [146, 147]]}
{"doc_key": "ai-test-328", "ner": [[5, 11, "product"], [15, 15, "misc"], [18, 18, "misc"], [24, 24, "product"], [26, 27, "task"], [29, 30, "task"], [32, 33, "task"], [35, 37, "field"], [39, 41, "task"], [43, 44, "field"], [47, 48, "task"], [50, 51, "task"], [53, 54, "task"], [57, 58, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[5, 11, 15, 15, "physical", "travels_to", false, false], [5, 11, 18, 18, "physical", "travels_to", false, false], [24, 24, 5, 11, "part-of", "", false, false], [24, 24, 5, 11, "role", "maintains", false, false], [24, 24, 26, 27, "related-to", "has_ability_to", false, false], [24, 24, 29, 30, "related-to", "has_ability_to", false, false], [24, 24, 32, 33, "related-to", "has_ability_to", false, false], [24, 24, 35, 37, "related-to", "has_ability_to", false, false], [24, 24, 39, 41, "related-to", "has_ability_to", false, false], [24, 24, 43, 44, "related-to", "has_ability_to", false, false], [24, 24, 47, 48, "related-to", "has_ability_to", false, false], [24, 24, 50, 51, "related-to", "has_ability_to", false, false], [24, 24, 53, 54, "related-to", "has_ability_to", false, false], [24, 24, 57, 58, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "addition", "to", "supporting", "the", "Discovery", "One", "spacecraft", "'s", "systems", "during", "the", "interplanetary", "mission", "to", "Jupiter", "(", "or", "Saturn", "in", "the", "novel", ")", ",", "HAL", "can", "synthesize", "speech", ",", "recognize", "speech", ",", "recognize", "faces", ",", "process", "natural", "language", ",", "lip", "-", "read", ",", "evaluate", "art", ",", "use", "affective", "computing", ",", "reason", "automatically", ",", "pilot", "spacecraft", ",", "and", "play", "chess", "."], "sentence-detokenized": "In addition to supporting the Discovery One spacecraft's systems during the interplanetary mission to Jupiter (or Saturn in the novel), HAL can synthesize speech, recognize speech, recognize faces, process natural language, lip-read, evaluate art, use affective computing, reason automatically, pilot spacecraft, and play chess.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 25], [26, 29], [30, 39], [40, 43], [44, 54], [54, 56], [57, 64], [65, 71], [72, 75], [76, 90], [91, 98], [99, 101], [102, 109], [110, 111], [111, 113], [114, 120], [121, 123], [124, 127], [128, 133], [133, 134], [134, 135], [136, 139], [140, 143], [144, 154], [155, 161], [161, 162], [163, 172], [173, 179], [179, 180], [181, 190], [191, 196], [196, 197], [198, 205], [206, 213], [214, 222], [222, 223], [224, 227], [227, 228], [228, 232], [232, 233], [234, 242], [243, 246], [246, 247], [248, 251], [252, 261], [262, 271], [271, 272], [273, 279], [280, 293], [293, 294], [295, 300], [301, 311], [311, 312], [313, 316], [317, 321], [322, 327], [327, 328]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [4, 4, "country"], [7, 8, "country"], [11, 11, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 4, "physical", "", false, false], [0, 1, 7, 8, "physical", "", false, false], [0, 1, 11, 11, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr.", "Jules", "emigrated", "from", "Hungary", "to", "the", "United", "States", "after", "the", "Soviet", "invasion", "in", "1956", "."], "sentence-detokenized": "Dr. Jules emigrated from Hungary to the United States after the Soviet invasion in 1956.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 24], [25, 32], [33, 35], [36, 39], [40, 46], [47, 53], [54, 59], [60, 63], [64, 70], [71, 79], [80, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-test-330", "ner": [[0, 1, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sigmoid", "activation", "functions", "use", "a", "second", "nonlinearity", "for", "large", "inputs", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+\\", "exp", "(", "-", "v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "The sigmoid activation functions use a second nonlinearity for large inputs: math\\ phi (v _ i) = (1 +\\ exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 32], [33, 36], [37, 38], [39, 45], [46, 58], [59, 62], [63, 68], [69, 75], [75, 76], [77, 81], [81, 82], [83, 86], [87, 88], [88, 89], [90, 91], [92, 93], [93, 94], [95, 96], [97, 98], [98, 99], [100, 102], [103, 106], [107, 108], [108, 109], [109, 110], [111, 112], [113, 114], [114, 115], [115, 116], [117, 118], [119, 120], [120, 122], [122, 123], [124, 125], [126, 130], [130, 131]]}
{"doc_key": "ai-test-331", "ner": [[12, 14, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "probabilities", "are", "used", "to", "determine", "which", "is", "the", "target", "using", "the", "maximum", "likelihood", "solution", "."], "sentence-detokenized": "These probabilities are used to determine which is the target using the maximum likelihood solution.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 47], [48, 50], [51, 54], [55, 61], [62, 67], [68, 71], [72, 79], [80, 90], [91, 99], [99, 100]]}
{"doc_key": "ai-test-332", "ner": [[6, 10, "university"], [14, 16, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1984", "he", "moved", "to", "the", "University", "of", "Konstanz", "and", "in", "1990", "to", "the", "University", "of", "Salzburg", "."], "sentence-detokenized": "In 1984 he moved to the University of Konstanz and in 1990 to the University of Salzburg.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 46], [47, 50], [51, 53], [54, 58], [59, 61], [62, 65], [66, 76], [77, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-333", "ner": [[11, 12, "metrics"], [14, 16, "metrics"], [18, 20, "metrics"], [22, 22, "metrics"], [24, 25, "metrics"], [27, 29, "metrics"], [33, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 16, 11, 12, "origin", "based_on", false, false], [18, 20, 11, 12, "origin", "based_on", false, false], [22, 22, 11, 12, "origin", "based_on", false, false], [24, 25, 11, 12, "origin", "based_on", false, false], [27, 29, 11, 12, "origin", "based_on", false, false], [33, 37, 11, 12, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Some", "popular", "goodness", "-", "of", "-", "fit", "functions", "based", "on", "the", "confusion", "matrix", "include", "sensitivity", "/", "specificity", ",", "recall", "/", "precision", ",", "F-measure", ",", "Jaccard", "similarity", ",", "Matthews", "correlation", "coefficient", ",", "and", "a", "cost", "/", "benefit", "matrix", "that", "combines", "the", "costs", "and", "benefits", "determined", "for", "the", "4", "different", "classification", "types", "."], "sentence-detokenized": "Some popular goodness-of-fit functions based on the confusion matrix include sensitivity/specificity, recall/precision, F-measure, Jaccard similarity, Matthews correlation coefficient, and a cost/benefit matrix that combines the costs and benefits determined for the 4 different classification types.", "token2charspan": [[0, 4], [5, 12], [13, 21], [21, 22], [22, 24], [24, 25], [25, 28], [29, 38], [39, 44], [45, 47], [48, 51], [52, 61], [62, 68], [69, 76], [77, 88], [88, 89], [89, 100], [100, 101], [102, 108], [108, 109], [109, 118], [118, 119], [120, 129], [129, 130], [131, 138], [139, 149], [149, 150], [151, 159], [160, 171], [172, 183], [183, 184], [185, 188], [189, 190], [191, 195], [195, 196], [196, 203], [204, 210], [211, 215], [216, 224], [225, 228], [229, 234], [235, 238], [239, 247], [248, 258], [259, 262], [263, 266], [267, 268], [269, 278], [279, 293], [294, 299], [299, 300]]}
{"doc_key": "ai-test-334", "ner": [[7, 7, "product"], [9, 9, "product"], [11, 11, "product"], [13, 13, "product"], [16, 18, "programlang"], [31, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[31, 33, 7, 7, "part-of", "", false, false], [31, 33, 9, 9, "part-of", "", false, false], [31, 33, 11, 11, "part-of", "", false, false], [31, 33, 13, 13, "part-of", "", false, false], [31, 33, 16, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Common", "numerical", "programming", "environments", ",", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", ",", "and", "the", "R", "language", ",", "provide", "some", "of", "the", "simpler", "feature", "extraction", "techniques", "(", "e.g.", ",", "principal", "component", "analysis", ")", "via", "built", "-", "in", "commands", "."], "sentence-detokenized": "Common numerical programming environments, such as MATLAB, SciLab, NumPy, Sklearn, and the R language, provide some of the simpler feature extraction techniques (e.g., principal component analysis) via built-in commands.", "token2charspan": [[0, 6], [7, 16], [17, 28], [29, 41], [41, 42], [43, 47], [48, 50], [51, 57], [57, 58], [59, 65], [65, 66], [67, 72], [72, 73], [74, 81], [81, 82], [83, 86], [87, 90], [91, 92], [93, 101], [101, 102], [103, 110], [111, 115], [116, 118], [119, 122], [123, 130], [131, 138], [139, 149], [150, 160], [161, 162], [162, 166], [166, 167], [168, 177], [178, 187], [188, 196], [196, 197], [198, 201], [202, 207], [207, 208], [208, 210], [211, 219], [219, 220]]}
{"doc_key": "ai-test-335", "ner": [[0, 3, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "have", "been", "deployed", "to", "collaborate", "with", "humans", "to", "perform", "tasks", "in", "industrial", "production", "."], "sentence-detokenized": "Industrial robots have been deployed to collaborate with humans to perform tasks in industrial production.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 27], [28, 36], [37, 39], [40, 51], [52, 56], [57, 63], [64, 66], [67, 74], [75, 80], [81, 83], [84, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-test-336", "ner": [[6, 6, "field"], [7, 9, "researcher"], [19, 20, "field"], [22, 23, "field"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 19, 20, "related-to", "", false, false], [6, 6, 22, 23, "related-to", "", false, false], [6, 6, 26, 27, "related-to", "", false, false], [7, 9, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "first", "published", "article", "on", "KG", ",", "John", "Sova", "applies", "them", "to", "a", "wide", "range", "of", "topics", "in", "artificial", "intelligence", ",", "computer", "science", ",", "and", "cognitive", "science", "."], "sentence-detokenized": "In the first published article on KG, John Sova applies them to a wide range of topics in artificial intelligence, computer science, and cognitive science.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [23, 30], [31, 33], [34, 36], [36, 37], [38, 42], [43, 47], [48, 55], [56, 60], [61, 63], [64, 65], [66, 70], [71, 76], [77, 79], [80, 86], [87, 89], [90, 100], [101, 113], [113, 114], [115, 123], [124, 131], [131, 132], [133, 136], [137, 146], [147, 154], [154, 155]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [4, 4, "metrics"], [10, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "in", "the", "calculation", "of", "the", "brevity", "penalty", "because", "small", "differences", "in", "translation", "length", "do", "not", "affect", "the", "overall", "result", "as", "much", "."], "sentence-detokenized": "NIST also differs from BLEU in the calculation of the brevity penalty because small differences in translation length do not affect the overall result as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 46], [47, 49], [50, 53], [54, 61], [62, 69], [70, 77], [78, 83], [84, 95], [96, 98], [99, 110], [111, 117], [118, 120], [121, 124], [125, 131], [132, 135], [136, 143], [144, 150], [151, 153], [154, 158], [158, 159]]}
{"doc_key": "ai-test-338", "ner": [[0, 4, "misc"], [12, 12, "conference"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 12, 12, "temporal", "", false, false], [0, 4, 19, 20, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "IJCAI", "Research", "Excellence", "Award", "is", "a", "bi-annual", "award", "presented", "at", "the", "IJCAI", "conference", "to", "an", "AI", "researcher", "in", "recognition", "of", "excellence", "in", "their", "career", "."], "sentence-detokenized": "The IJCAI Research Excellence Award is a bi-annual award presented at the IJCAI conference to an AI researcher in recognition of excellence in their career.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 29], [30, 35], [36, 38], [39, 40], [41, 50], [51, 56], [57, 66], [67, 69], [70, 73], [74, 79], [80, 90], [91, 93], [94, 96], [97, 99], [100, 110], [111, 113], [114, 125], [126, 128], [129, 139], [140, 142], [143, 148], [149, 155], [155, 156]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [6, 6, "conference"], [17, 23, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 6, "role", "", false, false], [0, 0, 17, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "was", "one", "of", "the", "first", "AAAI", "Fellows", "and", "is", "the", "only", "person", "to", "serve", "on", "the", "scientific", "advisory", "boards", "of", "Microsoft", "and", "Apple", "."], "sentence-detokenized": "Lenat was one of the first AAAI Fellows and is the only person to serve on the scientific advisory boards of Microsoft and Apple.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 16], [17, 20], [21, 26], [27, 31], [32, 39], [40, 43], [44, 46], [47, 50], [51, 55], [56, 62], [63, 65], [66, 71], [72, 74], [75, 78], [79, 89], [90, 98], [99, 105], [106, 108], [109, 118], [119, 122], [123, 128], [128, 129]]}
{"doc_key": "ai-test-340", "ner": [[0, 0, "algorithm"], [5, 6, "misc"], [10, 15, "metrics"], [19, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "related-to", "minimise", false, false], [10, 15, 5, 6, "type-of", "", false, false], [19, 19, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoders", "are", "trained", "to", "minimize", "reconstruction", "errors", "(", "e.g.", ",", "mean", "squared", "error", ")", ",", "often", "referred", "to", "as", "loss", ":"], "sentence-detokenized": "Autoencoders are trained to minimize reconstruction errors (e.g., mean squared error), often referred to as loss:", "token2charspan": [[0, 12], [13, 16], [17, 24], [25, 27], [28, 36], [37, 51], [52, 58], [59, 60], [60, 64], [64, 65], [66, 70], [71, 78], [79, 84], [84, 85], [85, 86], [87, 92], [93, 101], [102, 104], [105, 107], [108, 112], [112, 113]]}
{"doc_key": "ai-test-341", "ner": [[28, 30, "misc"], [34, 34, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[34, 34, 28, 30, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "to", "using", "definitions", "is", "to", "consider", "the", "common", "relatedness", "between", "word", "meanings", "and", "compute", "the", "similarity", "of", "each", "pair", "of", "word", "meanings", "based", "on", "a", "given", "lexical", "knowledge", "base", ",", "such", "as", "WordNet", "."], "sentence-detokenized": "An alternative to using definitions is to consider the common relatedness between word meanings and compute the similarity of each pair of word meanings based on a given lexical knowledge base, such as WordNet.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 23], [24, 35], [36, 38], [39, 41], [42, 50], [51, 54], [55, 61], [62, 73], [74, 81], [82, 86], [87, 95], [96, 99], [100, 107], [108, 111], [112, 122], [123, 125], [126, 130], [131, 135], [136, 138], [139, 143], [144, 152], [153, 158], [159, 161], [162, 163], [164, 169], [170, 177], [178, 187], [188, 192], [192, 193], [194, 198], [199, 201], [202, 209], [209, 210]]}
{"doc_key": "ai-test-342", "ner": [[0, 2, "algorithm"], [9, 11, "researcher"], [17, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 11, "origin", "", false, false], [9, 11, 17, 19, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "invented", "by", "Richard", "S.", "Sutton", "based", "on", "earlier", "work", "by", "Arthur", "Samuel", "on", "learning", "through", "temporal", "differences", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm invented by Richard S. Sutton based on earlier work by Arthur Samuel on learning through temporal differences.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 42], [43, 45], [46, 53], [54, 56], [57, 63], [64, 69], [70, 72], [73, 80], [81, 85], [86, 88], [89, 95], [96, 102], [103, 105], [106, 114], [115, 122], [123, 131], [132, 143], [143, 144]]}
{"doc_key": "ai-test-343", "ner": [[2, 2, "field"], [4, 4, "field"], [6, 7, "task"], [11, 13, "task"], [15, 15, "task"], [19, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 2, 2, "part-of", "task_part_of_field", false, false], [6, 7, 4, 4, "part-of", "task_part_of_field", false, false], [11, 13, 6, 7, "named", "", false, false], [15, 15, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "data", "mining", "and", "statistics", ",", "hierarchical", "clustering", "(", "also", "called", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "cluster", "analysis", "method", "that", "aims", "to", "build", "a", "hierarchy", "of", "clusters", "."], "sentence-detokenized": "In data mining and statistics, hierarchical clustering (also called hierarchical cluster analysis or HCA) is a cluster analysis method that aims to build a hierarchy of clusters.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 29], [29, 30], [31, 43], [44, 54], [55, 56], [56, 60], [61, 67], [68, 80], [81, 88], [89, 97], [98, 100], [101, 104], [104, 105], [106, 108], [109, 110], [111, 118], [119, 127], [128, 134], [135, 139], [140, 144], [145, 147], [148, 153], [154, 155], [156, 165], [166, 168], [169, 177], [177, 178]]}
{"doc_key": "ai-test-344", "ner": [[3, 6, "algorithm"], [8, 8, "field"], [10, 11, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 6, 8, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "concept", "of", "deconvolution", "is", "widely", "used", "in", "signal", "and", "image", "processing", "techniques", "."], "sentence-detokenized": "The concept of deconvolution is widely used in signal and image processing techniques.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 53], [54, 57], [58, 63], [64, 74], [75, 85], [85, 86]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [22, 23, "misc"], [26, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 22, 23, "related-to", "enhances", false, false], [0, 1, 22, 23, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "serve", "to", "build", "and", "accumulate", "spatial", "knowledge", "by", "allowing", "the", "mind", "'s", "eye", "to", "visualize", "images", "in", "order", "to", "reduce", "cognitive", "load", ",", "improve", "recall", ",", "and", "information", "retention", "."], "sentence-detokenized": "Cognitive maps serve to build and accumulate spatial knowledge by allowing the mind's eye to visualize images in order to reduce cognitive load, improve recall, and information retention.", "token2charspan": [[0, 9], [10, 14], [15, 20], [21, 23], [24, 29], [30, 33], [34, 44], [45, 52], [53, 62], [63, 65], [66, 74], [75, 78], [79, 83], [83, 85], [86, 89], [90, 92], [93, 102], [103, 109], [110, 112], [113, 118], [119, 121], [122, 128], [129, 138], [139, 143], [143, 144], [145, 152], [153, 159], [159, 160], [161, 164], [165, 176], [177, 186], [186, 187]]}
{"doc_key": "ai-test-346", "ner": [[8, 8, "programlang"], [10, 11, "programlang"], [13, 13, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "usually", "providing", "connections", "to", "languages", "such", "as", "Python", ",", "C", "++", ",", "Java", ")", "."], "sentence-detokenized": ", usually providing connections to languages such as Python, C++, Java).", "token2charspan": [[0, 1], [2, 9], [10, 19], [20, 31], [32, 34], [35, 44], [45, 49], [50, 52], [53, 59], [59, 60], [61, 62], [62, 64], [64, 65], [66, 70], [70, 71], [71, 72]]}
{"doc_key": "ai-test-347", "ner": [[0, 2, "product"], [4, 4, "product"], [18, 20, "task"], [25, 28, "task"], [32, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 18, 20, "usage", "", false, false], [0, 2, 25, 28, "usage", "", false, false], [0, 2, 32, 36, "usage", "", false, false], [4, 4, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Voice", "User", "Interface", "(", "VUI", ")", "makes", "it", "possible", "for", "humans", "to", "interact", "vocally", "with", "computers", "by", "using", "speech", "recognition", "to", "understand", "voice", "commands", "and", "answer", "questions", ",", "and", "usually", "to", "reproduce", "text", "-", "to", "-", "speech", "."], "sentence-detokenized": "Voice User Interface (VUI) makes it possible for humans to interact vocally with computers by using speech recognition to understand voice commands and answer questions, and usually to reproduce text-to-speech.", "token2charspan": [[0, 5], [6, 10], [11, 20], [21, 22], [22, 25], [25, 26], [27, 32], [33, 35], [36, 44], [45, 48], [49, 55], [56, 58], [59, 67], [68, 75], [76, 80], [81, 90], [91, 93], [94, 99], [100, 106], [107, 118], [119, 121], [122, 132], [133, 138], [139, 147], [148, 151], [152, 158], [159, 168], [168, 169], [170, 173], [174, 181], [182, 184], [185, 194], [195, 199], [199, 200], [200, 202], [202, 203], [203, 209], [209, 210]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 4, "misc"], [7, 7, "programlang"], [11, 14, "researcher"], [16, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 4, "general-affiliation", "is_a", false, false], [0, 0, 7, 7, "general-affiliation", "made_with", false, false], [0, 0, 11, 14, "origin", "", false, false], [11, 14, 16, 17, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Jess", "is", "a", "rules", "engine", "for", "the", "Java", "platform", "developed", "by", "Ernest", "Friedman", "-", "Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "Jess is a rules engine for the Java platform developed by Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 15], [16, 22], [23, 26], [27, 30], [31, 35], [36, 44], [45, 54], [55, 57], [58, 64], [65, 73], [73, 74], [74, 78], [79, 81], [82, 88], [89, 97], [97, 98]]}
{"doc_key": "ai-test-349", "ner": [[1, 3, "algorithm"], [16, 22, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 3, 16, 22, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "multilayer", "perceptrons", "where", "there", "is", "a", "hidden", "layer", ",", "more", "sophisticated", "algorithms", ",", "such", "as", "back", "-", "propagation", ",", "must", "be", "used", "."], "sentence-detokenized": "For multilayer perceptrons where there is a hidden layer, more sophisticated algorithms, such as back-propagation, must be used.", "token2charspan": [[0, 3], [4, 14], [15, 26], [27, 32], [33, 38], [39, 41], [42, 43], [44, 50], [51, 56], [56, 57], [58, 62], [63, 76], [77, 87], [87, 88], [89, 93], [94, 96], [97, 101], [101, 102], [102, 113], [113, 114], [115, 119], [120, 122], [123, 127], [127, 128]]}
{"doc_key": "ai-test-350", "ner": [[0, 1, "product"], [2, 6, "product"], [10, 18, "algorithm"], [22, 23, "field"], [27, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 6, 0, 1, "part-of", "", false, false], [2, 6, 10, 18, "usage", "", false, true], [10, 18, 22, 23, "related-to", "performs", false, false], [27, 33, 22, 23, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "Translate", "'s", "neural", "machine", "translation", "system", "uses", "a", "large", "end", "-", "to", "-", "end", "artificial", "neural", "network", "that", "attempts", "to", "perform", "deep", "learning", ",", "in", "particular", "networks", "with", "long", "short", "-", "term", "memory", "."], "sentence-detokenized": "Google Translate's neural machine translation system uses a large end-to-end artificial neural network that attempts to perform deep learning, in particular networks with long short-term memory.", "token2charspan": [[0, 6], [7, 16], [16, 18], [19, 25], [26, 33], [34, 45], [46, 52], [53, 57], [58, 59], [60, 65], [66, 69], [69, 70], [70, 72], [72, 73], [73, 76], [77, 87], [88, 94], [95, 102], [103, 107], [108, 116], [117, 119], [120, 127], [128, 132], [133, 141], [141, 142], [143, 145], [146, 156], [157, 165], [166, 170], [171, 175], [176, 181], [181, 182], [182, 186], [187, 193], [193, 194]]}
{"doc_key": "ai-test-351", "ner": [[14, 14, "researcher"], [16, 16, "researcher"], [18, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Various", "methods", "for", "doing", "this", "were", "developed", "in", "the", "1980s", "and", "early", "1990s", "by", "Verbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Perlmutter", ",", "and", "others", "."], "sentence-detokenized": "Various methods for doing this were developed in the 1980s and early 1990s by Verbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Perlmutter, and others.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 25], [26, 30], [31, 35], [36, 45], [46, 48], [49, 52], [53, 58], [59, 62], [63, 68], [69, 74], [75, 77], [78, 84], [84, 85], [86, 94], [94, 95], [96, 104], [104, 105], [106, 112], [113, 124], [124, 125], [126, 130], [131, 141], [141, 142], [143, 153], [153, 154], [155, 158], [159, 165], [165, 166]]}
{"doc_key": "ai-test-352", "ner": [[1, 1, "organisation"], [2, 3, "organisation"], [8, 9, "organisation"], [11, 12, "task"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 8, 9, "role", "licenses_from", false, false], [2, 3, 1, 1, "named", "", false, false], [16, 16, 1, 1, "origin", "", false, false], [16, 16, 11, 12, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc.", "originally", "licensed", "software", "from", "Nuance", "to", "provide", "speech", "recognition", "capability", "to", "its", "Siri", "digital", "assistant", "."], "sentence-detokenized": "| Apple Apple Inc. originally licensed software from Nuance to provide speech recognition capability to its Siri digital assistant.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 18], [19, 29], [30, 38], [39, 47], [48, 52], [53, 59], [60, 62], [63, 70], [71, 77], [78, 89], [90, 100], [101, 103], [104, 107], [108, 112], [113, 120], [121, 130], [130, 131]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [4, 5, "misc"], [8, 9, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 5, "role", "releases_movies_in_genre", false, false], [8, 9, 0, 0, "role", "directs_for", false, false], [13, 14, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "is", "releasing", "several", "3D", "westerns", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia is releasing several 3D westerns produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 11], [12, 21], [22, 29], [30, 32], [33, 41], [42, 50], [51, 53], [54, 57], [58, 65], [66, 69], [70, 78], [79, 81], [82, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-test-354", "ner": [[6, 7, "field"], [9, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "includes", "knowledge", "and", "research", "in", "computer", "science", ",", "linguistics", "and", "computer", "engineering", "."], "sentence-detokenized": "It includes knowledge and research in computer science, linguistics and computer engineering.", "token2charspan": [[0, 2], [3, 11], [12, 21], [22, 25], [26, 34], [35, 37], [38, 46], [47, 54], [54, 55], [56, 67], [68, 71], [72, 80], [81, 92], [92, 93]]}
{"doc_key": "ai-test-355", "ner": [[5, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", "is", "an", "example", "of", "R", "code", ":"], "sentence-detokenized": "Here is an example of R code:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 23], [24, 28], [28, 29]]}
{"doc_key": "ai-test-356", "ner": [[0, 2, "metrics"], [8, 10, "metrics"], [12, 12, "metrics"], [16, 18, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 8, 10, "part-of", "plotted_into", false, false], [0, 2, 16, 18, "part-of", "plotted_into", false, false], [12, 12, 8, 10, "named", "", false, false], [20, 20, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "ROC", "curve", "is", "created", "by", "comparing", "the", "true", "positive", "rate", "(", "TPR", ")", "with", "the", "false", "positive", "rate", "(", "FPR", ")", "at", "different", "threshold", "settings", "."], "sentence-detokenized": "The ROC curve is created by comparing the true positive rate (TPR) with the false positive rate (FPR) at different threshold settings.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 24], [25, 27], [28, 37], [38, 41], [42, 46], [47, 55], [56, 60], [61, 62], [62, 65], [65, 66], [67, 71], [72, 75], [76, 81], [82, 90], [91, 95], [96, 97], [97, 100], [100, 101], [102, 104], [105, 114], [115, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-test-357", "ner": [[15, 16, "field"], [4, 5, "researcher"], [7, 8, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 15, 16, "related-to", "researches_field", false, false], [7, 8, 15, 16, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Research", "has", "stagnated", "since", "Marvin", "Minsky", "and", "Seymour", "Pappert", "'s", "(", "1969", ")", "research", "on", "machine", "learning", ","], "sentence-detokenized": "Research has stagnated since Marvin Minsky and Seymour Pappert's (1969) research on machine learning,", "token2charspan": [[0, 8], [9, 12], [13, 22], [23, 28], [29, 35], [36, 42], [43, 46], [47, 54], [55, 62], [62, 64], [65, 66], [66, 70], [70, 71], [72, 80], [81, 83], [84, 91], [92, 100], [100, 101]]}
{"doc_key": "ai-test-358", "ner": [[8, 8, "task"], [11, 12, "programlang"], [14, 16, "product"], [18, 19, "programlang"], [21, 21, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 8, 11, 12, "related-to", "used_to_build", false, false], [8, 8, 14, 16, "related-to", "used_to_build", false, false], [8, 8, 18, 19, "related-to", "used_to_build", false, false], [8, 8, 21, 21, "related-to", "used_to_build", false, false], [8, 8, 24, 24, "related-to", "used_to_build", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "programming", "environments", "that", "are", "used", "to", "create", "DAQ", "applications", "include", "Logic", "Ladder", ",", "Visual", "C", "++", ",", "Visual", "Basic", ",", "LabVIEW", ",", "and", "MATLAB", "."], "sentence-detokenized": "Other programming environments that are used to create DAQ applications include Logic Ladder, Visual C++, Visual Basic, LabVIEW, and MATLAB.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 39], [40, 44], [45, 47], [48, 54], [55, 58], [59, 71], [72, 79], [80, 85], [86, 92], [92, 93], [94, 100], [101, 102], [102, 104], [104, 105], [106, 112], [113, 118], [118, 119], [120, 127], [127, 128], [129, 132], [133, 139], [139, 140]]}
{"doc_key": "ai-test-359", "ner": [[15, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "metric", "is", "designed", "to", "fix", "some", "of", "the", "problems", "found", "in", "the", "more", "popular", "BLEU", "metric", ",", "and", "also", "to", "provide", "a", "good", "correlation", "with", "human", "judgment", "at", "the", "sentence", "or", "segment", "level", "."], "sentence-detokenized": "The metric is designed to fix some of the problems found in the more popular BLEU metric, and also to provide a good correlation with human judgment at the sentence or segment level.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 22], [23, 25], [26, 29], [30, 34], [35, 37], [38, 41], [42, 50], [51, 56], [57, 59], [60, 63], [64, 68], [69, 76], [77, 81], [82, 88], [88, 89], [90, 93], [94, 98], [99, 101], [102, 109], [110, 111], [112, 116], [117, 128], [129, 133], [134, 139], [140, 148], [149, 151], [152, 155], [156, 164], [165, 167], [168, 175], [176, 181], [181, 182]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [15, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", ",", "and", "long", "-", "term", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "semantic", "correlations", "between", "consecutive", "video", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks, and long-term short-term memory are often used to exploit semantic correlations between consecutive video frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [73, 74], [75, 78], [79, 83], [83, 84], [84, 88], [89, 94], [94, 95], [95, 99], [100, 106], [107, 110], [111, 116], [117, 121], [122, 124], [125, 132], [133, 141], [142, 154], [155, 162], [163, 174], [175, 180], [181, 187], [187, 188]]}
{"doc_key": "ai-test-361", "ner": [[3, 3, "product"], [7, 7, "product"], [14, 19, "product"], [23, 26, "product"], [40, 41, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 14, 19, "artifact", "", false, false], [3, 3, 40, 41, "named", "", false, false], [7, 7, 3, 3, "named", "", false, false], [23, 26, 14, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Mass", "-", "produced", "printed", "circuit", "boards", "(", "PCBs", ")", "are", "manufactured", "almost", "exclusively", "by", "pick", "-", "and", "-", "place", "robots", ",", "usually", "with", "SCARA", "handlers", ",", "which", "remove", "small", "electronic", "components", "from", "strips", "or", "trays", "and", "place", "them", "on", "the", "PCB", "with", "great", "precision", "."], "sentence-detokenized": "Mass-produced printed circuit boards (PCBs) are manufactured almost exclusively by pick-and-place robots, usually with SCARA handlers, which remove small electronic components from strips or trays and place them on the PCB with great precision.", "token2charspan": [[0, 4], [4, 5], [5, 13], [14, 21], [22, 29], [30, 36], [37, 38], [38, 42], [42, 43], [44, 47], [48, 60], [61, 67], [68, 79], [80, 82], [83, 87], [87, 88], [88, 91], [91, 92], [92, 97], [98, 104], [104, 105], [106, 113], [114, 118], [119, 124], [125, 133], [133, 134], [135, 140], [141, 147], [148, 153], [154, 164], [165, 175], [176, 180], [181, 187], [188, 190], [191, 196], [197, 200], [201, 206], [207, 211], [212, 214], [215, 218], [219, 222], [223, 227], [228, 233], [234, 243], [243, 244]]}
{"doc_key": "ai-test-362", "ner": [[4, 10, "field"], [17, 19, "algorithm"], [23, 24, "researcher"], [26, 27, "researcher"], [30, 32, "researcher"], [40, 41, "algorithm"], [44, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[17, 19, 4, 10, "part-of", "", false, false], [17, 19, 23, 24, "origin", "", false, false], [17, 19, 26, 27, "origin", "", false, false], [17, 19, 30, 32, "origin", "", false, false], [17, 19, 40, 41, "type-of", "", false, false], [40, 41, 44, 44, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "context", "of", "machine", "self", "-", "learning", ",", "where", "it", "is", "most", "widely", "applied", "today", ",", "LDA", "has", "been", "independently", "reinvented", "by", "David", "Bley", ",", "Andrew", "Ng", ",", "and", "Michael", "Y.", "Jordan", "in", "2003", "and", "was", "introduced", "as", "a", "graphical", "model", "for", "topic", "discovery", "."], "sentence-detokenized": "In the context of machine self-learning, where it is most widely applied today, LDA has been independently reinvented by David Bley, Andrew Ng, and Michael Y. Jordan in 2003 and was introduced as a graphical model for topic discovery.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 25], [26, 30], [30, 31], [31, 39], [39, 40], [41, 46], [47, 49], [50, 52], [53, 57], [58, 64], [65, 72], [73, 78], [78, 79], [80, 83], [84, 87], [88, 92], [93, 106], [107, 117], [118, 120], [121, 126], [127, 131], [131, 132], [133, 139], [140, 142], [142, 143], [144, 147], [148, 155], [156, 158], [159, 165], [166, 168], [169, 173], [174, 177], [178, 181], [182, 192], [193, 195], [196, 197], [198, 207], [208, 213], [214, 217], [218, 223], [224, 233], [233, 234]]}
{"doc_key": "ai-test-363", "ner": [[7, 8, "task"], [10, 10, "misc"], [13, 13, "metrics"], [15, 15, "metrics"], [18, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 10, 10, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["Measured", "test", "data", "performance", "of", "eight", "naive", "WSIs", "for", "different", "tauopathies", "resulted", "in", "recall", ",", "precision", ",", "and", "F1", "scores", "of", "0.92", ",", "0.72", ",", "and", "0.81", ",", "respectively", "."], "sentence-detokenized": "Measured test data performance of eight naive WSIs for different tauopathies resulted in recall, precision, and F1 scores of 0.92, 0.72, and 0.81, respectively.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 30], [31, 33], [34, 39], [40, 45], [46, 50], [51, 54], [55, 64], [65, 76], [77, 85], [86, 88], [89, 95], [95, 96], [97, 106], [106, 107], [108, 111], [112, 114], [115, 121], [122, 124], [125, 129], [129, 130], [131, 135], [135, 136], [137, 140], [141, 145], [145, 146], [147, 159], [159, 160]]}
{"doc_key": "ai-test-364", "ner": [[3, 6, "field"], [9, 10, "field"], [13, 16, "field"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 6, 13, 16, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["By", "using", "advanced", "AR", "technologies", "(", "e.g.", ",", "adding", "computer", "vision", ",", "incorporating", "AR", "cameras", "into", "a", "smartphone", ",", "and", "object", "recognition", ")", ",", "information", "about", "the", "user", "'s", "surrounding", "real", "world", "becomes", "interactive", "and", "is", "digitally", "manipulated", "."], "sentence-detokenized": "By using advanced AR technologies (e.g., adding computer vision, incorporating AR cameras into a smartphone, and object recognition), information about the user's surrounding real world becomes interactive and is digitally manipulated.", "token2charspan": [[0, 2], [3, 8], [9, 17], [18, 20], [21, 33], [34, 35], [35, 39], [39, 40], [41, 47], [48, 56], [57, 63], [63, 64], [65, 78], [79, 81], [82, 89], [90, 94], [95, 96], [97, 107], [107, 108], [109, 112], [113, 119], [120, 131], [131, 132], [132, 133], [134, 145], [146, 151], [152, 155], [156, 160], [160, 162], [163, 174], [175, 179], [180, 185], [186, 193], [194, 205], [206, 209], [210, 212], [213, 222], [223, 234], [234, 235]]}
{"doc_key": "ai-test-365", "ner": [[3, 3, "researcher"], [7, 10, "organisation"], [16, 18, "field"], [27, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 7, 10, "role", "forms_company", false, false], [7, 10, 16, 18, "related-to", "works_with", false, false], [7, 10, 27, 29, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2014", ",", "Schmidhuber", "founded", "the", "company", "Nnaisense", ",", "which", "is", "working", "on", "commercial", "applications", "of", "artificial", "intelligence", "in", "areas", "such", "as", "finance", ",", "heavy", "industry", "and", "self", "-", "driving", "cars", "."], "sentence-detokenized": "In 2014, Schmidhuber founded the company Nnaisense, which is working on commercial applications of artificial intelligence in areas such as finance, heavy industry and self-driving cars.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 28], [29, 32], [33, 40], [41, 50], [50, 51], [52, 57], [58, 60], [61, 68], [69, 71], [72, 82], [83, 95], [96, 98], [99, 109], [110, 122], [123, 125], [126, 131], [132, 136], [137, 139], [140, 147], [147, 148], [149, 154], [155, 163], [164, 167], [168, 172], [172, 173], [173, 180], [181, 185], [185, 186]]}
{"doc_key": "ai-test-366", "ner": [[26, 30, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Not", "only", "does", "this", "change", "the", "results", "of", "any", "subsequent", "tests", "of", "the", "retained", "explanatory", "model", ",", "but", "it", "can", "also", "introduce", "bias", "and", "change", "the", "mean", "squared", "error", "of", "the", "estimation", "."], "sentence-detokenized": "Not only does this change the results of any subsequent tests of the retained explanatory model, but it can also introduce bias and change the mean squared error of the estimation.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 18], [19, 25], [26, 29], [30, 37], [38, 40], [41, 44], [45, 55], [56, 61], [62, 64], [65, 68], [69, 77], [78, 89], [90, 95], [95, 96], [97, 100], [101, 103], [104, 107], [108, 112], [113, 122], [123, 127], [128, 131], [132, 138], [139, 142], [143, 147], [148, 155], [156, 161], [162, 164], [165, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-test-367", "ner": [[0, 3, "misc"], [6, 6, "algorithm"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 0, 3, "usage", "", false, false], [6, 6, 9, 10, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Digrams", "are", "used", "in", "most", "successful", "language", "models", "for", "speech", "recognition", "."], "sentence-detokenized": "Digrams are used in most successful language models for speech recognition.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 24], [25, 35], [36, 44], [45, 51], [52, 55], [56, 62], [63, 74], [74, 75]]}
{"doc_key": "ai-test-368", "ner": [[3, 4, "field"], [7, 8, "misc"], [15, 17, "misc"], [23, 25, "organisation"], [28, 30, "misc"], [36, 39, "organisation"], [42, 44, "misc"], [50, 54, "organisation"], [57, 60, "misc"], [66, 69, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 8, 3, 4, "topic", "", false, false], [15, 17, 23, 25, "origin", "", false, false], [28, 30, 36, 39, "origin", "", false, false], [42, 44, 50, 54, "origin", "", false, false], [57, 60, 66, 69, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["His", "research", "in", "cognitive", "psychology", "won", "the", "Early", "Career", "Award", "(", "1984", ")", "and", "the", "Boyd", "McCandless", "Award", "(", "1986", ")", "of", "the", "American", "Psychological", "Association", ",", "the", "Trolland", "Research", "Award", "(", "1993", ")", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "Henry", "Dale", "Award", "(", "2004", ")", "of", "the", "Royal", "Institute", "of", "Great", "Britain", ",", "and", "the", "George", "Miller", "Award", "(", "2010", ")", "of", "the", "Society", "for", "Cognitive", "Neuroscience", "."], "sentence-detokenized": "His research in cognitive psychology won the Early Career Award (1984) and the Boyd McCandless Award (1986) of the American Psychological Association, the Trolland Research Award (1993) of the National Academy of Sciences, the Henry Dale Award (2004) of the Royal Institute of Great Britain, and the George Miller Award (2010) of the Society for Cognitive Neuroscience.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 25], [26, 36], [37, 40], [41, 44], [45, 50], [51, 57], [58, 63], [64, 65], [65, 69], [69, 70], [71, 74], [75, 78], [79, 83], [84, 94], [95, 100], [101, 102], [102, 106], [106, 107], [108, 110], [111, 114], [115, 123], [124, 137], [138, 149], [149, 150], [151, 154], [155, 163], [164, 172], [173, 178], [179, 180], [180, 184], [184, 185], [186, 188], [189, 192], [193, 201], [202, 209], [210, 212], [213, 221], [221, 222], [223, 226], [227, 232], [233, 237], [238, 243], [244, 245], [245, 249], [249, 250], [251, 253], [254, 257], [258, 263], [264, 273], [274, 276], [277, 282], [283, 290], [290, 291], [292, 295], [296, 299], [300, 306], [307, 313], [314, 319], [320, 321], [321, 325], [325, 326], [327, 329], [330, 333], [334, 341], [342, 345], [346, 355], [356, 368], [368, 369]]}
{"doc_key": "ai-test-369", "ner": [[0, 0, "misc"], [6, 6, "misc"], [9, 11, "product"], [15, 15, "researcher"], [17, 17, "researcher"], [25, 26, "researcher"], [28, 29, "researcher"], [31, 32, "task"], [34, 37, "researcher"], [39, 43, "researcher"], [44, 46, "task"], [47, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[0, 0, 6, 6, "named", "", false, false], [0, 0, 47, 47, "named", "", false, false], [6, 6, 15, 15, "origin", "", false, false], [6, 6, 17, 17, "origin", "", false, false], [6, 6, 31, 32, "related-to", "used_for", false, false], [9, 11, 6, 6, "usage", "", false, false], [9, 11, 44, 46, "named", "", false, false], [25, 26, 6, 6, "usage", "", false, false], [25, 26, 34, 37, "named", "same", false, false], [28, 29, 6, 6, "usage", "", false, false], [28, 29, 39, 43, "named", "same", false, false], [44, 46, 47, 47, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Eigenface", "(", "The", "approach", "of", "using", "eigenfaces", "for", "a", "face", "recognition", "system", "was", "developed", "by", "Sirovich", "and", "Kirby", "(", "1987", ")", "and", "was", "used", "by", "Matthew", "Turk", "and", "Alex", "Pentland", "in", "face", "classification", ".", "Turk", ",", "Matthew", "A", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "Eigenface (The approach of using eigenfaces for a face recognition system was developed by Sirovich and Kirby (1987) and was used by Matthew Turk and Alex Pentland in face classification. Turk, Matthew A and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 9], [10, 11], [11, 14], [15, 23], [24, 26], [27, 32], [33, 43], [44, 47], [48, 49], [50, 54], [55, 66], [67, 73], [74, 77], [78, 87], [88, 90], [91, 99], [100, 103], [104, 109], [110, 111], [111, 115], [115, 116], [117, 120], [121, 124], [125, 129], [130, 132], [133, 140], [141, 145], [146, 149], [150, 154], [155, 163], [164, 166], [167, 171], [172, 186], [186, 187], [188, 192], [192, 193], [194, 201], [202, 203], [204, 207], [208, 216], [216, 217], [218, 222], [223, 224], [224, 225], [226, 230], [231, 242], [243, 248], [249, 259], [259, 260]]}
{"doc_key": "ai-test-370", "ner": [[5, 14, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "vocabulary", "dictionary", "such", "as", "Word", "Net", "can", "then", "be", "used", "to", "understand", "the", "context", "."], "sentence-detokenized": "A vocabulary dictionary such as WordNet can then be used to understand the context.", "token2charspan": [[0, 1], [2, 12], [13, 23], [24, 28], [29, 31], [32, 36], [36, 39], [40, 43], [44, 48], [49, 51], [52, 56], [57, 59], [60, 70], [71, 74], [75, 82], [82, 83]]}
{"doc_key": "ai-test-371", "ner": [[0, 0, "misc"], [8, 10, "misc"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 10, "part-of", "", false, false], [8, 10, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hyponymy", "is", "the", "most", "commonly", "encoded", "relationship", "between", "synonyms", "used", "in", "lexical", "databases", "such", "as", "WordNet", "."], "sentence-detokenized": "Hyponymy is the most commonly encoded relationship between synonyms used in lexical databases such as WordNet.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 20], [21, 29], [30, 37], [38, 50], [51, 58], [59, 67], [68, 72], [73, 75], [76, 83], [84, 93], [94, 98], [99, 101], [102, 109], [109, 110]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [6, 7, "programlang"], [9, 11, "programlang"], [39, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 7, "general-affiliation", "", false, false], [0, 0, 9, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "offers", "open", "source", "libraries", "in", "C", "++", "and", "Java", ",", "but", "many", "customers", "rely", "on", "community", "-", "developed", "libraries", ",", "such", "as", "libraries", "that", "include", "built", "-", "in", "capabilities", "for", "extracting", "data", "(", "array", "-", "style", ")", "from", "DAP", "servers", "."], "sentence-detokenized": "OPeNDAP offers open source libraries in C++ and Java, but many customers rely on community-developed libraries, such as libraries that include built-in capabilities for extracting data (array-style) from DAP servers.", "token2charspan": [[0, 7], [8, 14], [15, 19], [20, 26], [27, 36], [37, 39], [40, 41], [41, 43], [44, 47], [48, 52], [52, 53], [54, 57], [58, 62], [63, 72], [73, 77], [78, 80], [81, 90], [90, 91], [91, 100], [101, 110], [110, 111], [112, 116], [117, 119], [120, 129], [130, 134], [135, 142], [143, 148], [148, 149], [149, 151], [152, 164], [165, 168], [169, 179], [180, 184], [185, 186], [186, 191], [191, 192], [192, 197], [197, 198], [199, 203], [204, 207], [208, 215], [215, 216]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [7, 8, "product"], [13, 21, "country"], [30, 34, "misc"], [46, 46, "organisation"], [48, 48, "product"], [50, 50, "organisation"], [51, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 13, 21, "opposite", "", false, false], [7, 8, 13, 21, "artifact", "", false, false], [30, 34, 7, 8, "part-of", "", false, false], [48, 48, 46, 46, "artifact", "", false, false], [51, 56, 50, 50, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "this", "page", ",", "Samurai", "Damashii", "exaggerates", "the", "Senkousha", "as", "a", "crystallization", "of", "China", "'s", "four-thousand", "-", "year", "-", "old", "scientific", "knowledge", ",", "comments", "on", "the", "crude", "design", "(", "e.g.", "the", "Chinese", "cannon", "on", "the", "bosom", ")", ",", "and", "places", "it", "s", "image", "among", "images", "of", "Honda", "'s", "ASIMO", "and", "Sony", "'s", "QRIO", "SDR", "-", "3", "X", "for", "comparison", "."], "sentence-detokenized": "In this page, Samurai Damashii exaggerates the Senkousha as a crystallization of China's four-thousand-year-old scientific knowledge, comments on the crude design (e.g. the Chinese cannon on the bosom), and places its image among images of Honda's ASIMO and Sony's QRIO SDR-3X for comparison.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 21], [22, 30], [31, 42], [43, 46], [47, 56], [57, 59], [60, 61], [62, 77], [78, 80], [81, 86], [86, 88], [89, 102], [102, 103], [103, 107], [107, 108], [108, 111], [112, 122], [123, 132], [132, 133], [134, 142], [143, 145], [146, 149], [150, 155], [156, 162], [163, 164], [164, 168], [169, 172], [173, 180], [181, 187], [188, 190], [191, 194], [195, 200], [200, 201], [201, 202], [203, 206], [207, 213], [214, 216], [216, 217], [218, 223], [224, 229], [230, 236], [237, 239], [240, 245], [245, 247], [248, 253], [254, 257], [258, 262], [262, 264], [265, 269], [270, 273], [273, 274], [274, 275], [275, 276], [277, 280], [281, 291], [291, 292]]}
{"doc_key": "ai-test-374", "ner": [[8, 9, "algorithm"], [22, 22, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 22, 22, "part-of", "includes_functionality_of", false, false], [8, 9, 24, 24, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "also", "many", "programming", "libraries", "that", "contain", "neural", "network", "functionality", "and", "that", "can", "be", "used", "in", "custom", "implementations", "(", "such", "as", "TensorFlow", ",", "Theano", ",", "etc", "."], "sentence-detokenized": "There are also many programming libraries that contain neural network functionality and that can be used in custom implementations (such as TensorFlow, Theano, etc.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 31], [32, 41], [42, 46], [47, 54], [55, 61], [62, 69], [70, 83], [84, 87], [88, 92], [93, 96], [97, 99], [100, 104], [105, 107], [108, 114], [115, 130], [131, 132], [132, 136], [137, 139], [140, 150], [150, 151], [152, 158], [158, 159], [160, 163], [163, 164]]}
{"doc_key": "ai-test-375", "ner": [[6, 9, "conference"], [11, 11, "organisation"], [13, 19, "conference"], [21, 21, "conference"], [24, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", ",", "and", "SPIE", "."], "sentence-detokenized": "He is a member of the Association for Computing Machinery, IEEE, American Association for the Advancement of Science, IAPR, and SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 33], [34, 37], [38, 47], [48, 57], [57, 58], [59, 63], [63, 64], [65, 73], [74, 85], [86, 89], [90, 93], [94, 105], [106, 108], [109, 116], [116, 117], [118, 122], [122, 123], [124, 127], [128, 132], [132, 133]]}
{"doc_key": "ai-test-376", "ner": [[4, 5, "organisation"], [7, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 7, 9, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2011", ",", "the", "RET", "experimented", "with", "face", "-", "recognition", "cameras", "installed", "in", "trams", "to", "make", "sure", "that", "people", "banned", "from", "entering", "city", "trams", "did", "n't", "sneak", "on", "anyway", "."], "sentence-detokenized": "In 2011, the RET experimented with face-recognition cameras installed in trams to make sure that people banned from entering city trams didn't sneak on anyway.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 29], [30, 34], [35, 39], [39, 40], [40, 51], [52, 59], [60, 69], [70, 72], [73, 78], [79, 81], [82, 86], [87, 91], [92, 96], [97, 103], [104, 110], [111, 115], [116, 124], [125, 129], [130, 135], [136, 139], [139, 142], [143, 148], [149, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-test-377", "ner": [[5, 12, "person"], [9, 9, "organisation"], [15, 16, "person"], [18, 21, "person"], [26, 27, "person"], [29, 30, "person"], [32, 33, "person"], [35, 36, "person"], [38, 39, "person"], [41, 42, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[5, 12, 9, 9, "role", "works_for", false, false], [15, 16, 9, 9, "role", "works_for", false, false], [18, 21, 9, 9, "role", "works_for", false, false], [26, 27, 9, 9, "role", "works_for", false, false], [29, 30, 9, 9, "role", "works_for", false, false], [32, 33, 9, 9, "role", "works_for", false, false], [35, 36, 9, 9, "role", "works_for", false, false], [38, 39, 9, 9, "role", "works_for", false, false], [41, 42, 9, 9, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "film", ",", "adapted", "from", "Cole", "Porter", "'s", "popular", "Broadway", "musical", ",", "stars", "MGM", "singers", "Howard", "Keel", "and", "Kathryn", "Grayson", "in", "the", "lead", "roles", ",", "with", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Vann", ",", "James", "Whitmore", ",", "Kurt", "Kashnar", "and", "Tommy", "Rall", "."], "sentence-detokenized": "The film, adapted from Cole Porter's popular Broadway musical, stars MGM singers Howard Keel and Kathryn Grayson in the lead roles, with Ann Miller, Keenan Wynn, Bobby Vann, James Whitmore, Kurt Kashnar and Tommy Rall.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 17], [18, 22], [23, 27], [28, 34], [34, 36], [37, 44], [45, 53], [54, 61], [61, 62], [63, 68], [69, 72], [73, 80], [81, 87], [88, 92], [93, 96], [97, 104], [105, 112], [113, 115], [116, 119], [120, 124], [125, 130], [130, 131], [132, 136], [137, 140], [141, 147], [147, 148], [149, 155], [156, 160], [160, 161], [162, 167], [168, 172], [172, 173], [174, 179], [180, 188], [188, 189], [190, 194], [195, 202], [203, 206], [207, 212], [213, 217], [217, 218]]}
{"doc_key": "ai-test-378", "ner": [[20, 25, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "applications", "should", "streamline", "call", "flows", ",", "minimize", "prompts", ",", "eliminate", "unnecessary", "repetition", ",", "and", "allow", "the", "development", "of", "a", "mixed", "-", "initiative", "dialog", "system", "that", "allows", "callers", "to", "enter", "multiple", "pieces", "of", "information", "in", "a", "single", "utterance", "and", "in", "any", "order", "or", "combination", "."], "sentence-detokenized": "Such applications should streamline call flows, minimize prompts, eliminate unnecessary repetition, and allow the development of a mixed-initiative dialog system that allows callers to enter multiple pieces of information in a single utterance and in any order or combination.", "token2charspan": [[0, 4], [5, 17], [18, 24], [25, 35], [36, 40], [41, 46], [46, 47], [48, 56], [57, 64], [64, 65], [66, 75], [76, 87], [88, 98], [98, 99], [100, 103], [104, 109], [110, 113], [114, 125], [126, 128], [129, 130], [131, 136], [136, 137], [137, 147], [148, 154], [155, 161], [162, 166], [167, 173], [174, 181], [182, 184], [185, 190], [191, 199], [200, 206], [207, 209], [210, 221], [222, 224], [225, 226], [227, 233], [234, 243], [244, 247], [248, 250], [251, 254], [255, 260], [261, 263], [264, 275], [275, 276]]}
{"doc_key": "ai-test-379", "ner": [[5, 6, "algorithm"], [9, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 18, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "this", "way", ",", "traditional", "gradient", "descent", "(", "or", "stochastic", "gradient", "descent", ")", "methods", "can", "be", "adapted", ",", "where", "instead", "of", "a", "step", "in", "the", "direction", "of", "the", "gradient", "of", "the", "function", ",", "a", "step", "in", "the", "direction", "of", "a", "vector", "chosen", "from", "the", "subgradient", "of", "the", "function", "is", "taken", "."], "sentence-detokenized": "In this way, traditional gradient descent (or stochastic gradient descent) methods can be adapted, where instead of a step in the direction of the gradient of the function, a step in the direction of a vector chosen from the subgradient of the function is taken.", "token2charspan": [[0, 2], [3, 7], [8, 11], [11, 12], [13, 24], [25, 33], [34, 41], [42, 43], [43, 45], [46, 56], [57, 65], [66, 73], [73, 74], [75, 82], [83, 86], [87, 89], [90, 97], [97, 98], [99, 104], [105, 112], [113, 115], [116, 117], [118, 122], [123, 125], [126, 129], [130, 139], [140, 142], [143, 146], [147, 155], [156, 158], [159, 162], [163, 171], [171, 172], [173, 174], [175, 179], [180, 182], [183, 186], [187, 196], [197, 199], [200, 201], [202, 208], [209, 215], [216, 220], [221, 224], [225, 236], [237, 239], [240, 243], [244, 252], [253, 255], [256, 261], [261, 262]]}
{"doc_key": "ai-test-380", "ner": [[8, 10, "metrics"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Assuming", "that", "the", "distortion", "is", "measured", "by", "the", "mean", "squared", "error", ",", "the", "distortion", "D", "is", "defined", "by", ":"], "sentence-detokenized": "Assuming that the distortion is measured by the mean squared error, the distortion D is defined by:", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 28], [29, 31], [32, 40], [41, 43], [44, 47], [48, 52], [53, 60], [61, 66], [66, 67], [68, 71], [72, 82], [83, 84], [85, 87], [88, 95], [96, 98], [98, 99]]}
{"doc_key": "ai-test-381", "ner": [[4, 4, "algorithm"], [11, 11, "field"], [19, 20, "task"], [22, 23, "task"], [25, 27, "task"], [29, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 11, 11, "part-of", "", false, false], [19, 20, 4, 4, "part-of", "", false, false], [22, 23, 4, 4, "part-of", "", false, false], [25, 27, 4, 4, "part-of", "", false, false], [29, 30, 4, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "1980s", ",", "MLPs", "were", "a", "popular", "machine", "learning", "solution", "that", "found", "application", "in", "various", "fields", "such", "as", "speech", "recognition", ",", "image", "recognition", "and", "machine", "translation", "software", ",", "Neural", "Networks", "."], "sentence-detokenized": "In the 1980s, MLPs were a popular machine learning solution that found application in various fields such as speech recognition, image recognition and machine translation software, Neural Networks.", "token2charspan": [[0, 2], [3, 6], [7, 12], [12, 13], [14, 18], [19, 23], [24, 25], [26, 33], [34, 41], [42, 50], [51, 59], [60, 64], [65, 70], [71, 82], [83, 85], [86, 93], [94, 100], [101, 105], [106, 108], [109, 115], [116, 127], [127, 128], [129, 134], [135, 146], [147, 150], [151, 158], [159, 170], [171, 179], [179, 180], [181, 187], [188, 196], [196, 197]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [6, 8, "university"], [15, 17, "researcher"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[0, 0, 6, 8, "physical", "", false, false], [0, 0, 6, 8, "role", "", false, false], [15, 17, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 3], "sentence": ["Allen", "received", "his", "Ph.D.", "from", "the", "University", "of", "Toronto", "in", "1979", "under", "the", "supervision", "of", "C.", "Raymond", "Pero", ","], "sentence-detokenized": "Allen received his Ph.D. from the University of Toronto in 1979 under the supervision of C. Raymond Pero,", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 24], [25, 29], [30, 33], [34, 44], [45, 47], [48, 55], [56, 58], [59, 63], [64, 69], [70, 73], [74, 85], [86, 88], [89, 91], [92, 99], [100, 104], [104, 105]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [5, 7, "field"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [19, 20, "product"], [23, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 7, "related-to", "supports", false, false], [10, 10, 5, 7, "type-of", "", true, false], [12, 12, 5, 7, "type-of", "", true, false], [14, 14, 5, 7, "type-of", "", true, false], [14, 14, 19, 20, "related-to", "converting_to", true, false], [23, 26, 5, 7, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["OpenCV", "supports", "some", "models", "from", "deep", "learning", "frameworks", "such", "as", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "after", "conversion", "to", "ONNX", "model", ")", "and", "Caffe", "according", "to", "a", "specific", "list", "of", "supported", "layers", "."], "sentence-detokenized": "OpenCV supports some models from deep learning frameworks such as TensorFlow, Torch, PyTorch (after conversion to ONNX model) and Caffe according to a specific list of supported layers.", "token2charspan": [[0, 6], [7, 15], [16, 20], [21, 27], [28, 32], [33, 37], [38, 46], [47, 57], [58, 62], [63, 65], [66, 76], [76, 77], [78, 83], [83, 84], [85, 92], [93, 94], [94, 99], [100, 110], [111, 113], [114, 118], [119, 124], [124, 125], [126, 129], [130, 135], [136, 145], [146, 148], [149, 150], [151, 159], [160, 164], [165, 167], [168, 177], [178, 184], [184, 185]]}
{"doc_key": "ai-test-384", "ner": [[2, 2, "researcher"], [9, 12, "organisation"], [14, 14, "organisation"], [18, 22, "organisation"], [26, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 9, 12, "role", "", false, false], [2, 2, 18, 22, "role", "", false, false], [2, 2, 26, 26, "related-to", "lectures_in", false, false], [14, 14, 9, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Previously", ",", "Christensen", "was", "the", "founding", "chair", "of", "the", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "and", "an", "IEEE", "Robotics", "and", "Automation", "Society", "Distinguished", "Lecturer", "in", "Robotics", "."], "sentence-detokenized": "Previously, Christensen was the founding chair of the European Robotics Research Network (EURON) and an IEEE Robotics and Automation Society Distinguished Lecturer in Robotics.", "token2charspan": [[0, 10], [10, 11], [12, 23], [24, 27], [28, 31], [32, 40], [41, 46], [47, 49], [50, 53], [54, 62], [63, 71], [72, 80], [81, 88], [89, 90], [90, 95], [95, 96], [97, 100], [101, 103], [104, 108], [109, 117], [118, 121], [122, 132], [133, 140], [141, 154], [155, 163], [164, 166], [167, 175], [175, 176]]}
{"doc_key": "ai-test-385", "ner": [[7, 7, "field"], [9, 11, "university"], [13, 13, "location"], [15, 21, "country"], [24, 24, "misc"], [26, 26, "field"], [29, 32, "organisation"], [34, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 11, 13, 13, "physical", "", false, false], [13, 13, 15, 21, "physical", "", false, false], [24, 24, 26, 26, "topic", "", false, false], [29, 32, 34, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "received", "a", "master", "'s", "degree", "in", "mathematics", "from", "Samarkand", "State", "University", ",", "Samarkand", ",", "Uzbek", "Soviet", "Socialist", "Republic", ",", "in", "1958", "and", "a", "doctorate", "in", "statistics", "from", "the", "Institute", "of", "Management", "Sciences", ",", "Moscow", ",", "in", "1964", "."], "sentence-detokenized": "He received a master's degree in mathematics from Samarkand State University, Samarkand, Uzbek Soviet Socialist Republic, in 1958 and a doctorate in statistics from the Institute of Management Sciences, Moscow, in 1964.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 20], [20, 22], [23, 29], [30, 32], [33, 44], [45, 49], [50, 59], [60, 65], [66, 76], [76, 77], [78, 87], [87, 88], [89, 94], [95, 101], [102, 111], [112, 120], [120, 121], [122, 124], [125, 129], [130, 133], [134, 135], [136, 145], [146, 148], [149, 159], [160, 164], [165, 168], [169, 178], [179, 181], [182, 192], [193, 201], [201, 202], [203, 209], [209, 210], [211, 213], [214, 218], [218, 219]]}
{"doc_key": "ai-test-386", "ner": [[7, 9, "organisation"], [12, 14, "product"], [33, 34, "field"], [36, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 9, 33, 34, "usage", "", false, false], [7, 9, 36, 38, "usage", "", false, false], [12, 14, 7, 9, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Increasingly", ",", "however", ",", "the", "work", "at", "Cycorp", "is", "about", "giving", "the", "Cyc", "system", "the", "ability", "to", "communicate", "with", "end", "users", "in", "natural", "language", "and", "support", "the", "continuous", "process", "of", "knowledge", "creation", "through", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "Increasingly, however, the work at Cycorp is about giving the Cyc system the ability to communicate with end users in natural language and support the continuous process of knowledge creation through machine learning and natural language understanding.", "token2charspan": [[0, 12], [12, 13], [14, 21], [21, 22], [23, 26], [27, 31], [32, 34], [35, 41], [42, 44], [45, 50], [51, 57], [58, 61], [62, 65], [66, 72], [73, 76], [77, 84], [85, 87], [88, 99], [100, 104], [105, 108], [109, 114], [115, 117], [118, 125], [126, 134], [135, 138], [139, 146], [147, 150], [151, 161], [162, 169], [170, 172], [173, 182], [183, 191], [192, 199], [200, 207], [208, 216], [217, 220], [221, 228], [229, 237], [238, 251], [251, 252]]}
{"doc_key": "ai-test-387", "ner": [[55, 55, "metrics"], [57, 57, "metrics"], [59, 59, "metrics"], [61, 62, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "if", "the", "most", "appropriate", "classifier", "for", "the", "problem", "is", "sought", ",", "the", "training", "dataset", "is", "used", "to", "train", "the", "candidate", "algorithms", ",", "the", "validation", "dataset", "is", "used", "to", "compare", "their", "features", "and", "decide", "which", "one", "to", "select", ",", "and", "finally", "the", "testing", "dataset", "is", "used", "to", "obtain", "the", "performance", "features", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", ",", "F-", "measure", ",", "etc", "."], "sentence-detokenized": "For example, if the most appropriate classifier for the problem is sought, the training dataset is used to train the candidate algorithms, the validation dataset is used to compare their features and decide which one to select, and finally the testing dataset is used to obtain the performance features such as accuracy, sensitivity, specificity, F-measure, etc.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 19], [20, 24], [25, 36], [37, 47], [48, 51], [52, 55], [56, 63], [64, 66], [67, 73], [73, 74], [75, 78], [79, 87], [88, 95], [96, 98], [99, 103], [104, 106], [107, 112], [113, 116], [117, 126], [127, 137], [137, 138], [139, 142], [143, 153], [154, 161], [162, 164], [165, 169], [170, 172], [173, 180], [181, 186], [187, 195], [196, 199], [200, 206], [207, 212], [213, 216], [217, 219], [220, 226], [226, 227], [228, 231], [232, 239], [240, 243], [244, 251], [252, 259], [260, 262], [263, 267], [268, 270], [271, 277], [278, 281], [282, 293], [294, 302], [303, 307], [308, 310], [311, 319], [319, 320], [321, 332], [332, 333], [334, 345], [345, 346], [347, 349], [349, 356], [356, 357], [358, 361], [361, 362]]}
{"doc_key": "ai-test-388", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "squared", "error", "is", "0.15", "."], "sentence-detokenized": "The mean squared error is 0.15.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 25], [26, 30], [30, 31]]}
{"doc_key": "ai-test-389", "ner": [[7, 13, "misc"], [3, 4, "organisation"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 7, 13, "role", "", false, false], [14, 15, 7, 13, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1979", ",", "the", "IEEE", "organized", "a", "competition", "for", "micromice", ",", "as", "shown", "in", "Spectrum", "magazine", "."], "sentence-detokenized": "In 1979, the IEEE organized a competition for micromice, as shown in Spectrum magazine.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 27], [28, 29], [30, 41], [42, 45], [46, 55], [55, 56], [57, 59], [60, 65], [66, 68], [69, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-390", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [11, 13, "task"], [15, 16, "task"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 7, "part-of", "", false, false], [11, 13, 6, 7, "part-of", "task_part_of_field", false, false], [15, 16, 6, 7, "part-of", "task_part_of_field", false, false], [19, 20, 6, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Gabor", "space", "is", "very", "useful", "in", "image", "processing", "applications", "such", "as", "optical", "character", "recognition", ",", "iris", "recognition", ",", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "Gabor space is very useful in image processing applications such as optical character recognition, iris recognition, and fingerprint recognition.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 19], [20, 26], [27, 29], [30, 35], [36, 46], [47, 59], [60, 64], [65, 67], [68, 75], [76, 85], [86, 97], [97, 98], [99, 103], [104, 115], [115, 116], [117, 120], [121, 132], [133, 144], [144, 145]]}
{"doc_key": "ai-test-391", "ner": [[7, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "via", "high", "-", "level", "interfaces", "to", "Java", "and", "Tcl", "."], "sentence-detokenized": "or via high-level interfaces to Java and Tcl.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [12, 17], [18, 28], [29, 31], [32, 36], [37, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-test-392", "ner": [[11, 12, "algorithm"], [20, 20, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 20, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "recent", "studies", ",", "kernel", "-", "based", "methods", ",", "such", "as", "support", "vector", "machines", ",", "have", "shown", "better", "performance", "in", "supervised", "."], "sentence-detokenized": "In recent studies, kernel-based methods, such as support vector machines, have shown better performance in supervised.", "token2charspan": [[0, 2], [3, 9], [10, 17], [17, 18], [19, 25], [25, 26], [26, 31], [32, 39], [39, 40], [41, 45], [46, 48], [49, 56], [57, 63], [64, 72], [72, 73], [74, 78], [79, 84], [85, 91], [92, 103], [104, 106], [107, 117], [117, 118]]}
{"doc_key": "ai-test-393", "ner": [[14, 14, "misc"], [23, 23, "researcher"], [25, 25, "researcher"], [33, 33, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 33, 33, "usage", "", false, false], [25, 25, 33, 33, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "illustrate", "the", "basic", "principles", "of", "packing", ",", "an", "analysis", "of", "the", "relationship", "between", "ozone", "and", "temperature", "is", "presented", "below", "(", "data", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "analysis", "done", "in", "R", ")", "."], "sentence-detokenized": "To illustrate the basic principles of packing, an analysis of the relationship between ozone and temperature is presented below (data from Rousseeuw and Leroy (1986), analysis done in R).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 34], [35, 37], [38, 45], [45, 46], [47, 49], [50, 58], [59, 61], [62, 65], [66, 78], [79, 86], [87, 92], [93, 96], [97, 108], [109, 111], [112, 121], [122, 127], [128, 129], [129, 133], [134, 138], [139, 148], [149, 152], [153, 158], [159, 160], [160, 164], [164, 165], [165, 166], [167, 175], [176, 180], [181, 183], [184, 185], [185, 186], [186, 187]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [11, 11, "product"], [18, 19, "product"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 0, 1, "artifact", "", false, false], [18, 19, 0, 1, "artifact", "", false, false], [21, 23, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Denso", "Wave", "is", "a", "subsidiary", "that", "manufactures", "automatic", "identification", "products", "(", "barcode", "readers", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "Denso Wave is a subsidiary that manufactures automatic identification products (barcode readers and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 15], [16, 26], [27, 31], [32, 44], [45, 54], [55, 69], [70, 78], [79, 80], [80, 87], [88, 95], [96, 99], [100, 107], [108, 116], [116, 117], [117, 118], [119, 129], [130, 136], [137, 140], [141, 153], [154, 159], [160, 171], [171, 172]]}
{"doc_key": "ai-test-395", "ner": [[2, 6, "metrics"], [10, 12, "metrics"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 6, 21, 21, "compare", "", false, false], [10, 12, 2, 6, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "the", "bilingual", "assessment", "within", "the", "study", "simply", "calculates", "the", "accuracy", "of", "the", "grams", "by", "adding", "equal", "weight", "to", "each", ",", "NIST", "also", "calculates", "how", "informative", "a", "given", "gram", "is", "."], "sentence-detokenized": "While the bilingual assessment within the study simply calculates the accuracy of the grams by adding equal weight to each, NIST also calculates how informative a given gram is.", "token2charspan": [[0, 5], [6, 9], [10, 19], [20, 30], [31, 37], [38, 41], [42, 47], [48, 54], [55, 65], [66, 69], [70, 78], [79, 81], [82, 85], [86, 91], [92, 94], [95, 101], [102, 107], [108, 114], [115, 117], [118, 122], [122, 123], [124, 128], [129, 133], [134, 144], [145, 148], [149, 160], [161, 162], [163, 168], [169, 173], [174, 176], [176, 177]]}
{"doc_key": "ai-test-396", "ner": [[17, 17, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "particular", ",", "they", "are", "used", "in", "the", "calculation", "of", "the", "likelihood", "of", "a", "tree", "(", "in", "Bayesian", "and", "maximum", "likelihood", "approaches", "to", "tree", "estimation", ")", "and", "are", "used", "to", "estimate", "the", "evolutionary", "distance", "between", "sequences", "based", "on", "the", "observed", "differences", "between", "sequences", "."], "sentence-detokenized": "In particular, they are used in the calculation of the likelihood of a tree (in Bayesian and maximum likelihood approaches to tree estimation) and are used to estimate the evolutionary distance between sequences based on the observed differences between sequences.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 19], [20, 23], [24, 28], [29, 31], [32, 35], [36, 47], [48, 50], [51, 54], [55, 65], [66, 68], [69, 70], [71, 75], [76, 77], [77, 79], [80, 88], [89, 92], [93, 100], [101, 111], [112, 122], [123, 125], [126, 130], [131, 141], [141, 142], [143, 146], [147, 150], [151, 155], [156, 158], [159, 167], [168, 171], [172, 184], [185, 193], [194, 201], [202, 211], [212, 217], [218, 220], [221, 224], [225, 233], [234, 245], [246, 253], [254, 263], [263, 264]]}
{"doc_key": "ai-test-397", "ner": [[0, 3, "conference"], [20, 21, "misc"], [23, 23, "misc"], [47, 48, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Audio", "Engineering", "Society", "recommends", "a", "sampling", "rate", "of", "48", "kHz", "for", "most", "applications", ",", "but", "recognizes", "44.1", "kHz", "for", "compact", "disc", "(", "CD", ")", "and", "other", "consumer", "applications", ",", "32", "kHz", "for", "broadcast", "-", "related", "applications", ",", "and", "96", "kHz", "for", "higher", "bandwidth", "or", "a", "relaxed", "anti-aliasing", "filter", "."], "sentence-detokenized": "The Audio Engineering Society recommends a sampling rate of 48 kHz for most applications, but recognizes 44.1 kHz for compact disc (CD) and other consumer applications, 32 kHz for broadcast-related applications, and 96 kHz for higher bandwidth or a relaxed anti-aliasing filter.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 40], [41, 42], [43, 51], [52, 56], [57, 59], [60, 62], [63, 66], [67, 70], [71, 75], [76, 88], [88, 89], [90, 93], [94, 104], [105, 109], [110, 113], [114, 117], [118, 125], [126, 130], [131, 132], [132, 134], [134, 135], [136, 139], [140, 145], [146, 154], [155, 167], [167, 168], [169, 171], [172, 175], [176, 179], [180, 189], [189, 190], [190, 197], [198, 210], [210, 211], [212, 215], [216, 218], [219, 222], [223, 226], [227, 233], [234, 243], [244, 246], [247, 248], [249, 256], [257, 270], [271, 277], [277, 278]]}
{"doc_key": "ai-test-398", "ner": [[9, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Word", "and", "concept", "affectivity", "resources", "have", "been", "created", "for", "WordNet", "{", "{", "cite", "journal"], "sentence-detokenized": "Word and concept affectivity resources have been created for WordNet {{cite journal", "token2charspan": [[0, 4], [5, 8], [9, 16], [17, 28], [29, 38], [39, 43], [44, 48], [49, 56], [57, 60], [61, 68], [69, 70], [70, 71], [71, 75], [76, 83]]}
{"doc_key": "ai-test-399", "ner": [[2, 10, "misc"], [26, 27, "person"], [32, 37, "person"], [42, 43, "person"], [49, 54, "organisation"], [71, 72, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[32, 37, 42, 43, "role", "acts_in", false, false], [49, 54, 42, 43, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "a", "red", "-", "and", "-", "green", "anaglyph", ",", "the", "audience", "was", "presented", "with", "three", "reels", "of", "tests", "that", "included", "rural", "scenes", ",", "test", "shots", "of", "Marie", "Doro", ",", "a", "segment", "on", "John", "B", ".", "Mason", ",", "who", "played", "several", "excerpts", "from", "Jim", "Feather", "(", "a", "film", "released", "by", "Famous", "Players", "-", "Lasky", "that", "year", ",", "but", "not", "in", "3D", ")", ",", "oriental", "dancers", ",", "and", "a", "roll", "of", "footage", "from", "Niagara", "Falls", "."], "sentence-detokenized": "In a red-and-green anaglyph, the audience was presented with three reels of tests that included rural scenes, test shots of Marie Doro, a segment on John B. Mason, who played several excerpts from Jim Feather (a film released by Famous Players-Lasky that year, but not in 3D), oriental dancers, and a roll of footage from Niagara Falls.", "token2charspan": [[0, 2], [3, 4], [5, 8], [8, 9], [9, 12], [12, 13], [13, 18], [19, 27], [27, 28], [29, 32], [33, 41], [42, 45], [46, 55], [56, 60], [61, 66], [67, 72], [73, 75], [76, 81], [82, 86], [87, 95], [96, 101], [102, 108], [108, 109], [110, 114], [115, 120], [121, 123], [124, 129], [130, 134], [134, 135], [136, 137], [138, 145], [146, 148], [149, 153], [154, 155], [155, 156], [157, 162], [162, 163], [164, 167], [168, 174], [175, 182], [183, 191], [192, 196], [197, 200], [201, 208], [209, 210], [210, 211], [212, 216], [217, 225], [226, 228], [229, 235], [236, 243], [243, 244], [244, 249], [250, 254], [255, 259], [259, 260], [261, 264], [265, 268], [269, 271], [272, 274], [274, 275], [275, 276], [277, 285], [286, 293], [293, 294], [295, 298], [299, 300], [301, 305], [306, 308], [309, 316], [317, 321], [322, 329], [330, 335], [335, 336]]}
{"doc_key": "ai-test-400", "ner": [[8, 11, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "concrete", "way", "of", "applying", "a", "maximum", "plausible", "estimate", "to", "this", "problem", "."], "sentence-detokenized": "This is a concrete way of applying a maximum plausible estimate to this problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 18], [19, 22], [23, 25], [26, 34], [35, 36], [37, 44], [45, 54], [55, 63], [64, 66], [67, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-test-401", "ner": [[0, 2, "product"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Crawlable", "web", "servers", ",", "and", "integrates", "features", "of", "sitemaps", "and", "RSS", "feeds", "into", "a", "decentralized", "mechanism", "for", "computational", "biologists", "and", "bioinformaticians", "to", "openly", "broadcast", "and", "retrieve", "metadata", "about", "biomedical", "resources", "."], "sentence-detokenized": "Crawlable web servers, and integrates features of sitemaps and RSS feeds into a decentralized mechanism for computational biologists and bioinformaticians to openly broadcast and retrieve metadata about biomedical resources.", "token2charspan": [[0, 9], [10, 13], [14, 21], [21, 22], [23, 26], [27, 37], [38, 46], [47, 49], [50, 58], [59, 62], [63, 66], [67, 72], [73, 77], [78, 79], [80, 93], [94, 103], [104, 107], [108, 121], [122, 132], [133, 136], [137, 154], [155, 157], [158, 164], [165, 174], [175, 178], [179, 187], [188, 196], [197, 202], [203, 213], [214, 223], [223, 224]]}
{"doc_key": "ai-test-402", "ner": [[5, 12, "misc"], [15, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "covered", "by", "the", "American", "National", "Standards", "Institute", "/", "NISO", "standard", "Z39.50", "and", "the", "International", "Organization", "for", "Standardization", "standard", "23950", "."], "sentence-detokenized": "It is covered by the American National Standards Institute/NISO standard Z39.50 and the International Organization for Standardization standard 23950.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 20], [21, 29], [30, 38], [39, 48], [49, 58], [58, 59], [59, 63], [64, 72], [73, 79], [80, 83], [84, 87], [88, 101], [102, 114], [115, 118], [119, 134], [135, 143], [144, 149], [149, 150]]}
{"doc_key": "ai-test-403", "ner": [[13, 16, "misc"], [21, 23, "metrics"], [25, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "encoder", "and", "decoder", "are", "trained", "to", "take", "a", "phrase", "and", "reproduce", "the", "single", "distribution", "of", "the", "corresponding", "paraphrase", ",", "minimizing", "perplexity", "using", "a", "simple", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The encoder and decoder are trained to take a phrase and reproduce the single distribution of the corresponding paraphrase, minimizing perplexity using a simple stochastic gradient descent.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 45], [46, 52], [53, 56], [57, 66], [67, 70], [71, 77], [78, 90], [91, 93], [94, 97], [98, 111], [112, 122], [122, 123], [124, 134], [135, 145], [146, 151], [152, 153], [154, 160], [161, 171], [172, 180], [181, 188], [188, 189]]}
{"doc_key": "ai-test-404", "ner": [[4, 7, "field"], [8, 10, "task"], [12, 17, "task"], [26, 30, "task"], [32, 37, "task"], [39, 45, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 10, 4, 7, "part-of", "task_part_of_field", false, false], [12, 17, 4, 7, "part-of", "task_part_of_field", false, false], [26, 30, 4, 7, "part-of", "task_part_of_field", false, false], [32, 37, 4, 7, "part-of", "task_part_of_field", false, false], [39, 45, 4, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "typical", "applications", "of", "pattern", "recognition", "techniques", "are", "automatic", "speech", "recognition", ",", "classification", "of", "text", "into", "several", "categories", "(", "e.g.", "spam", "/", "spam", "e-mails", ")", ",", "handwriting", "recognition", "on", "postal", "envelopes", ",", "automatic", "image", "recognition", "of", "human", "faces", "or", "extraction", "of", "handwriting", "images", "from", "medical", "forms", "."], "sentence-detokenized": "Other typical applications of pattern recognition techniques are automatic speech recognition, classification of text into several categories (e.g. spam/spam e-mails), handwriting recognition on postal envelopes, automatic image recognition of human faces or extraction of handwriting images from medical forms.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 29], [30, 37], [38, 49], [50, 60], [61, 64], [65, 74], [75, 81], [82, 93], [93, 94], [95, 109], [110, 112], [113, 117], [118, 122], [123, 130], [131, 141], [142, 143], [143, 147], [148, 152], [152, 153], [153, 157], [158, 165], [165, 166], [166, 167], [168, 179], [180, 191], [192, 194], [195, 201], [202, 211], [211, 212], [213, 222], [223, 228], [229, 240], [241, 243], [244, 249], [250, 255], [256, 258], [259, 269], [270, 272], [273, 284], [285, 291], [292, 296], [297, 304], [305, 310], [310, 311]]}
{"doc_key": "ai-test-405", "ner": [[0, 4, "algorithm"], [11, 12, "field"], [14, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 27, "task"], [30, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 12, 0, 4, "usage", "", false, false], [14, 15, 0, 4, "usage", "", false, false], [17, 18, 0, 4, "usage", "", false, false], [20, 22, 0, 4, "usage", "", false, false], [24, 27, 0, 4, "usage", "", false, false], [30, 31, 0, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Artificial", "neural", "networks", "are", "used", "for", "a", "variety", "of", "tasks", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "desktop", "and", "video", "gaming", ",", "and", "medical", "diagnostics", "."], "sentence-detokenized": "Artificial neural networks are used for a variety of tasks including computer vision, speech recognition, machine translation, social network filtering, desktop and video gaming, and medical diagnostics.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 30], [31, 35], [36, 39], [40, 41], [42, 49], [50, 52], [53, 58], [59, 68], [69, 77], [78, 84], [84, 85], [86, 92], [93, 104], [104, 105], [106, 113], [114, 125], [125, 126], [127, 133], [134, 141], [142, 151], [151, 152], [153, 160], [161, 164], [165, 170], [171, 177], [177, 178], [179, 182], [183, 190], [191, 202], [202, 203]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [17, 17, "product"], [20, 20, "organisation"], [21, 22, "product"], [24, 24, "product"], [26, 28, "product"], [30, 30, "product"], [32, 32, "programlang"], [37, 38, "field"], [46, 46, "product"], [51, 51, "algorithm"], [53, 53, "algorithm"], [56, 56, "algorithm"], [60, 60, "product"], [67, 67, "task"], [71, 73, "algorithm"], [76, 76, "product"], [78, 78, "product"], [81, 83, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [4, 4, 17, 17, "named", "same", false, false], [4, 4, 46, 46, "named", "same", false, false], [32, 32, 37, 38, "related-to", "used_for", false, false], [51, 51, 32, 32, "part-of", "", true, false], [51, 51, 46, 46, "origin", "", true, false], [53, 53, 32, 32, "part-of", "", true, false], [53, 53, 46, 46, "origin", "", true, false], [56, 56, 32, 32, "part-of", "", true, false], [56, 56, 46, 46, "origin", "", true, false], [60, 60, 67, 67, "related-to", "used_for", false, false], [71, 73, 60, 60, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Examples", "include", "Salford", "Systems", "CART", "(", "which", "licenses", "the", "proprietary", "code", "of", "the", "authors", "of", "the", "original", "CART", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "source", "statistical", "computing", "software", "environment", "that", "includes", "several", "implementations", "of", "CART", ",", "such", "as", "the", "rpart", ",", "party", ",", "and", "randomForest", "packages", ")", ",", "Weka", "(", "a", "free", "open", "source", "data", "mining", "package", "containing", "many", "decision", "tree", "algorithms", ")", ",", "Orange", ",", "KNIME", ",", "a", "Microsoft", "SQL", "Server", "programming", "language", ")", "."], "sentence-detokenized": "Examples include Salford Systems CART (which licenses the proprietary code of the authors of the original CART), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open source statistical computing software environment that includes several implementations of CART, such as the rpart, party, and randomForest packages), Weka (a free open source data mining package containing many decision tree algorithms), Orange, KNIME, a Microsoft SQL Server programming language).", "token2charspan": [[0, 8], [9, 16], [17, 24], [25, 32], [33, 37], [38, 39], [39, 44], [45, 53], [54, 57], [58, 69], [70, 74], [75, 77], [78, 81], [82, 89], [90, 92], [93, 96], [97, 105], [106, 110], [110, 111], [111, 112], [113, 116], [117, 121], [122, 129], [129, 130], [131, 141], [141, 142], [143, 146], [147, 157], [158, 163], [163, 164], [165, 171], [171, 172], [173, 174], [175, 176], [176, 178], [179, 183], [184, 190], [191, 202], [203, 212], [213, 221], [222, 233], [234, 238], [239, 247], [248, 255], [256, 271], [272, 274], [275, 279], [279, 280], [281, 285], [286, 288], [289, 292], [293, 298], [298, 299], [300, 305], [305, 306], [307, 310], [311, 323], [324, 332], [332, 333], [333, 334], [335, 339], [340, 341], [341, 342], [343, 347], [348, 352], [353, 359], [360, 364], [365, 371], [372, 379], [380, 390], [391, 395], [396, 404], [405, 409], [410, 420], [420, 421], [421, 422], [423, 429], [429, 430], [431, 436], [436, 437], [438, 439], [440, 449], [450, 453], [454, 460], [461, 472], [473, 481], [481, 482], [482, 483]]}
{"doc_key": "ai-test-407", "ner": [[0, 2, "algorithm"], [4, 7, "algorithm"], [10, 11, "researcher"], [13, 14, "university"], [16, 17, "researcher"], [19, 22, "organisation"], [24, 24, "organisation"], [33, 35, "researcher"], [37, 39, "researcher"], [41, 44, "organisation"], [55, 63, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 10, 11, "origin", "", false, false], [0, 2, 16, 17, "origin", "", false, false], [0, 2, 33, 35, "origin", "", false, false], [0, 2, 37, 39, "origin", "", false, false], [4, 7, 0, 2, "named", "", false, false], [10, 11, 13, 14, "physical", "", false, false], [10, 11, 13, 14, "role", "", false, false], [16, 17, 19, 22, "physical", "", false, false], [16, 17, 19, 22, "role", "", false, false], [24, 24, 19, 22, "named", "", false, false], [33, 35, 41, 44, "physical", "", false, false], [33, 35, 41, 44, "role", "", false, false], [37, 39, 41, 44, "physical", "", false, false], [37, 39, 41, 44, "role", "", false, false], [55, 63, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", "was", "first", "developed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", ",", "then", "further", "developed", "by", "Bishnu", "S.", "Atal", "and", "Manfred", "R.", "Schroeder", "at", "Bell", "Labs", "in", "the", "early", "and", "mid-1970s", ",", "becoming", "the", "basis", "for", "the", "first", "DSP", "chips", "with", "speech", "synthesizer", "in", "the", "late", "1970s", "."], "sentence-detokenized": "Linear predictive coding (LPC) was first developed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966, then further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs in the early and mid-1970s, becoming the basis for the first DSP chips with speech synthesizer in the late 1970s.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 40], [41, 50], [51, 53], [54, 62], [63, 70], [71, 73], [74, 80], [81, 91], [92, 95], [96, 101], [102, 107], [108, 110], [111, 117], [118, 127], [128, 131], [132, 141], [142, 143], [143, 146], [146, 147], [148, 150], [151, 155], [155, 156], [157, 161], [162, 169], [170, 179], [180, 182], [183, 189], [190, 192], [193, 197], [198, 201], [202, 209], [210, 212], [213, 222], [223, 225], [226, 230], [231, 235], [236, 238], [239, 242], [243, 248], [249, 252], [253, 262], [262, 263], [264, 272], [273, 276], [277, 282], [283, 286], [287, 290], [291, 296], [297, 300], [301, 306], [307, 311], [312, 318], [319, 330], [331, 333], [334, 337], [338, 342], [343, 348], [348, 349]]}
{"doc_key": "ai-test-408", "ner": [[0, 1, "metrics"], [6, 6, "metrics"], [8, 9, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 0, 1, "part-of", "", false, false], [8, 9, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Score", "F", "is", "a", "combination", "of", "precision", "and", "recall", "that", "produces", "a", "single", "score", "."], "sentence-detokenized": "Score F is a combination of precision and recall that produces a single score.", "token2charspan": [[0, 5], [6, 7], [8, 10], [11, 12], [13, 24], [25, 27], [28, 37], [38, 41], [42, 48], [49, 53], [54, 62], [63, 64], [65, 71], [72, 77], [77, 78]]}
{"doc_key": "ai-test-409", "ner": [[0, 1, "field"], [8, 11, "task"], [15, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 0, 1, "part-of", "task_part_of_field", false, false], [15, 18, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Image", "analysis", "tasks", "can", "be", "as", "simple", "as", "deciphering", "barcode", "labels", "or", "as", "complex", "as", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Image analysis tasks can be as simple as deciphering barcode labels or as complex as a facial recognition system.", "token2charspan": [[0, 5], [6, 14], [15, 20], [21, 24], [25, 27], [28, 30], [31, 37], [38, 40], [41, 52], [53, 60], [61, 67], [68, 70], [71, 73], [74, 81], [82, 84], [85, 86], [87, 93], [94, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-test-410", "ner": [[5, 8, "algorithm"], [26, 27, "algorithm"], [34, 36, "algorithm"], [40, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[34, 36, 26, 27, "type-of", "", false, false], [40, 40, 34, 36, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "special", "case", "of", "linear", "machines", "with", "support", "vectors", "can", "be", "solved", "more", "efficiently", "by", "the", "same", "kind", "of", "optimization", "algorithms", "of", "their", "close", "cousin", ",", "logistic", "regression", ";", "this", "class", "of", "algorithms", "involves", "stochastic", "gradient", "descent", "(", "e.g.", ",", "PEGASOS", ")", "."], "sentence-detokenized": "The special case of linear machines with support vectors can be solved more efficiently by the same kind of optimization algorithms of their close cousin, logistic regression; this class of algorithms involves stochastic gradient descent (e.g., PEGASOS).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 35], [36, 40], [41, 48], [49, 56], [57, 60], [61, 63], [64, 70], [71, 75], [76, 87], [88, 90], [91, 94], [95, 99], [100, 104], [105, 107], [108, 120], [121, 131], [132, 134], [135, 140], [141, 146], [147, 153], [153, 154], [155, 163], [164, 174], [174, 175], [176, 180], [181, 186], [187, 189], [190, 200], [201, 209], [210, 220], [221, 229], [230, 237], [238, 239], [239, 243], [243, 244], [245, 252], [252, 253], [253, 254]]}
{"doc_key": "ai-test-411", "ner": [[1, 1, "product"], [4, 4, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 4, 4, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["When", "Siri", "on", "an", "iOS", "device", "is", "asked", "Do", "you", "have", "a", "pet", "?", ",", "one", "of", "the", "responses", "is", "I", "had", "an", "AIBO", "."], "sentence-detokenized": "When Siri on an iOS device is asked Do you have a pet?, one of the responses is I had an AIBO.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 15], [16, 19], [20, 26], [27, 29], [30, 35], [36, 38], [39, 42], [43, 47], [48, 49], [50, 53], [53, 54], [54, 55], [56, 59], [60, 62], [63, 66], [67, 76], [77, 79], [80, 81], [82, 85], [86, 88], [89, 93], [93, 94]]}
{"doc_key": "ai-test-412", "ner": [[1, 2, "task"], [4, 6, "metrics"], [9, 9, "metrics"], [11, 11, "metrics"], [14, 14, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 1, 2, "part-of", "", false, false], [9, 9, 4, 6, "named", "", false, false], [11, 11, 1, 2, "part-of", "", false, false], [14, 14, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "information", "retrieval", ",", "positive", "predictive", "value", "is", "called", "precision", "and", "sensitivity", "is", "called", "recall", "."], "sentence-detokenized": "In information retrieval, positive predictive value is called precision and sensitivity is called recall.", "token2charspan": [[0, 2], [3, 14], [15, 24], [24, 25], [26, 34], [35, 45], [46, 51], [52, 54], [55, 61], [62, 71], [72, 75], [76, 87], [88, 90], [91, 97], [98, 104], [104, 105]]}
{"doc_key": "ai-test-413", "ner": [[11, 13, "field"], [15, 15, "task"], [17, 17, "task"], [19, 20, "task"], [38, 39, "task"], [41, 42, "task"], [44, 48, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 11, 13, "part-of", "task_part_of_field", false, false], [17, 17, 11, 13, "part-of", "task_part_of_field", false, false], [19, 20, 11, 13, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "particular", ",", "his", "research", "focuses", "on", "areas", "such", "as", "information", "extraction", "from", "text", "(", "mining", ",", "categorization", ",", "novelty", "detection", ")", "and", "on", "new", "theoretical", "frameworks", ",", "such", "as", "a", "unified", "utility", "-", "based", "theory", "that", "links", "information", "retrieval", ",", "automatic", "summarization", ",", "free", "-", "text", "question", "answering", ",", "and", "related", "tasks", "."], "sentence-detokenized": "In particular, his research focuses on areas such as information extraction from text (mining, categorization, novelty detection) and on new theoretical frameworks, such as a unified utility-based theory that links information retrieval, automatic summarization, free-text question answering, and related tasks.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 27], [28, 35], [36, 38], [39, 44], [45, 49], [50, 52], [53, 64], [65, 75], [76, 80], [81, 85], [86, 87], [87, 93], [93, 94], [95, 109], [109, 110], [111, 118], [119, 128], [128, 129], [130, 133], [134, 136], [137, 140], [141, 152], [153, 163], [163, 164], [165, 169], [170, 172], [173, 174], [175, 182], [183, 190], [190, 191], [191, 196], [197, 203], [204, 208], [209, 214], [215, 226], [227, 236], [236, 237], [238, 247], [248, 261], [261, 262], [263, 267], [267, 268], [268, 272], [273, 281], [282, 291], [291, 292], [293, 296], [297, 304], [305, 310], [310, 311]]}
{"doc_key": "ai-test-414", "ner": [[0, 1, "product"], [6, 8, "product"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 8, 0, 1, "part-of", "", false, false], [15, 16, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Delta", "robots", "have", "base", "-", "mounted", "rotary", "actuators", "that", "move", "a", "lightweight", ",", "rigid", ",", "parallelogram", "arm", "."], "sentence-detokenized": "Delta robots have base-mounted rotary actuators that move a lightweight, rigid, parallelogram arm.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 22], [22, 23], [23, 30], [31, 37], [38, 47], [48, 52], [53, 57], [58, 59], [60, 71], [71, 72], [73, 78], [78, 79], [80, 93], [94, 97], [97, 98]]}
{"doc_key": "ai-test-415", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "outcomes", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four outcomes can be formulated in a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 24], [25, 35], [36, 38], [39, 40], [41, 42], [43, 44], [45, 46], [47, 58], [59, 64], [65, 67], [68, 77], [78, 84], [85, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-416", "ner": [[3, 3, "field"], [29, 30, "task"], [36, 37, "task"], [43, 45, "task"], [47, 49, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[29, 30, 3, 3, "part-of", "task_part_of_field", false, false], [36, 37, 3, 3, "part-of", "task_part_of_field", false, false], [43, 45, 3, 3, "part-of", "task_part_of_field", false, false], [47, 49, 3, 3, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "actual", "data", "mining", "task", "is", "semi-automatic", "or", "automatic", "analysis", "of", "large", "amounts", "of", "data", "to", "extract", "unknown", ",", "interesting", "patterns", ",", "such", "as", "groups", "of", "data", "records", "(", "cluster", "analysis", ")", ",", "unusual", "records", "(", "anomaly", "detection", ")", ",", "and", "dependencies", "(", "association", "rule", "mining", ",", "sequential", "pattern", "mining", ")", "."], "sentence-detokenized": "The actual data mining task is semi-automatic or automatic analysis of large amounts of data to extract unknown, interesting patterns, such as groups of data records (cluster analysis), unusual records (anomaly detection), and dependencies (association rule mining, sequential pattern mining).", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 22], [23, 27], [28, 30], [31, 45], [46, 48], [49, 58], [59, 67], [68, 70], [71, 76], [77, 84], [85, 87], [88, 92], [93, 95], [96, 103], [104, 111], [111, 112], [113, 124], [125, 133], [133, 134], [135, 139], [140, 142], [143, 149], [150, 152], [153, 157], [158, 165], [166, 167], [167, 174], [175, 183], [183, 184], [184, 185], [186, 193], [194, 201], [202, 203], [203, 210], [211, 220], [220, 221], [221, 222], [223, 226], [227, 239], [240, 241], [241, 252], [253, 257], [258, 264], [264, 265], [266, 276], [277, 284], [285, 291], [291, 292], [292, 293]]}
{"doc_key": "ai-test-417", "ner": [[11, 12, "product"], [0, 1, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sentiment", "analysis", "has", "been", "shown", "to", "be", "a", "valuable", "technique", "for", "recommender", "systems", "."], "sentence-detokenized": "Sentiment analysis has been shown to be a valuable technique for recommender systems.", "token2charspan": [[0, 9], [10, 18], [19, 22], [23, 27], [28, 33], [34, 36], [37, 39], [40, 41], [42, 50], [51, 60], [61, 64], [65, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-test-418", "ner": [[2, 3, "misc"], [10, 13, "product"], [35, 35, "organisation"], [36, 37, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 10, 13, "usage", "", false, false], [35, 35, 36, 37, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Coincidentally", ",", "the", "Germans", "chose", "the", "operating", "frequency", "of", "the", "Wotan", "system", "very", "badly", "-", "it", "operates", "at", "45", "MHz", ",", "which", "happens", "to", "be", "the", "frequency", "of", "the", "powerful", "but", "non-functioning", "BBC", "TV", "transmitter", "at", "Alexandra", "Palace", "."], "sentence-detokenized": "Coincidentally, the Germans chose the operating frequency of the Wotan system very badly - it operates at 45 MHz, which happens to be the frequency of the powerful but non-functioning BBC TV transmitter at Alexandra Palace.", "token2charspan": [[0, 14], [14, 15], [16, 19], [20, 27], [28, 33], [34, 37], [38, 47], [48, 57], [58, 60], [61, 64], [65, 70], [71, 77], [78, 82], [83, 88], [89, 90], [91, 93], [94, 102], [103, 105], [106, 108], [109, 112], [112, 113], [114, 119], [120, 127], [128, 130], [131, 133], [134, 137], [138, 147], [148, 150], [151, 154], [155, 163], [164, 167], [168, 183], [184, 187], [188, 190], [191, 202], [203, 205], [206, 215], [216, 222], [222, 223]]}
{"doc_key": "ai-test-419", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "outcomes", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four outcomes can be formulated in a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 24], [25, 35], [36, 38], [39, 40], [41, 42], [43, 44], [45, 46], [47, 58], [59, 64], [65, 67], [68, 77], [78, 84], [85, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-420", "ner": [[1, 3, "misc"], [8, 8, "misc"], [12, 12, "product"], [14, 14, "product"], [16, 18, "product"], [26, 27, "misc"], [40, 42, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 12, 8, 8, "usage", "", false, false], [14, 14, 8, 8, "usage", "", false, false], [16, 18, 14, 14, "named", "", false, false], [26, 27, 8, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "Semantic", "Web", "applications", "and", "in", "relatively", "popular", "RDF", "applications", "such", "as", "RSS", "and", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "resources", "are", "typically", "represented", "by", "URIs", "that", "intentionally", "tag", "and", "can", "be", "used", "to", "access", "actual", "data", "on", "the", "World", "Wide", "Web", "."], "sentence-detokenized": "In Semantic Web applications and in relatively popular RDF applications such as RSS and FOAF (Friend a Friend), resources are typically represented by URIs that intentionally tag and can be used to access actual data on the World Wide Web.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 28], [29, 32], [33, 35], [36, 46], [47, 54], [55, 58], [59, 71], [72, 76], [77, 79], [80, 83], [84, 87], [88, 92], [93, 94], [94, 100], [101, 102], [103, 109], [109, 110], [110, 111], [112, 121], [122, 125], [126, 135], [136, 147], [148, 150], [151, 155], [156, 160], [161, 174], [175, 178], [179, 182], [183, 186], [187, 189], [190, 194], [195, 197], [198, 204], [205, 211], [212, 216], [217, 219], [220, 223], [224, 229], [230, 234], [235, 238], [238, 239]]}
{"doc_key": "ai-test-421", "ner": [[0, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "has", "studied", "this", "topic", "extensively"], "sentence-detokenized": "The Association for the Advancement of Artificial Intelligence has studied this topic extensively", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 74], [75, 79], [80, 85], [86, 97]]}
{"doc_key": "ai-test-422", "ner": [[6, 12, "product"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 19, 6, 12, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["What", "began", "as", "a", "curiosity", ",", "Apple", "'s", "Macintosh", "speech", "system", "has", "evolved", "into", "a", "fully", "supported", "PlainTalk", "program", "for", "people", "with", "vision", "problems", "."], "sentence-detokenized": "What began as a curiosity, Apple's Macintosh speech system has evolved into a fully supported PlainTalk program for people with vision problems.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 15], [16, 25], [25, 26], [27, 32], [32, 34], [35, 44], [45, 51], [52, 58], [59, 62], [63, 70], [71, 75], [76, 77], [78, 83], [84, 93], [94, 103], [104, 111], [112, 115], [116, 122], [123, 127], [128, 134], [135, 143], [143, 144]]}
{"doc_key": "ai-test-423", "ner": [[7, 7, "field"], [9, 10, "task"], [12, 13, "task"], [16, 17, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 7, 7, "part-of", "task_part_of_field", false, false], [12, 13, 7, 7, "part-of", "task_part_of_field", false, false], [16, 17, 7, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "areas", "of", "use", "of", "ontologies", "in", "NLP", "include", "information", "retrieval", ",", "information", "extraction", ",", "and", "automatic", "summarization", "."], "sentence-detokenized": "Other areas of use of ontologies in NLP include information retrieval, information extraction, and automatic summarization.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 47], [48, 59], [60, 69], [69, 70], [71, 82], [83, 93], [93, 94], [95, 98], [99, 108], [109, 122], [122, 123]]}
{"doc_key": "ai-test-424", "ner": [[6, 15, "organisation"], [16, 20, "organisation"], [24, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Institute", "collaborates", "closely", "with", "the", "Janelia", "Faculty", "of", "the", "Howard", "Hughes", "Medical", "Institute", ",", "the", "Allen", "Institute", "for", "Brain", "Science", ",", "and", "the", "National", "Institutes", "of", "Health", "to", "develop", "better", "methods", "for", "reconstructing", "neural", "architectures", "."], "sentence-detokenized": "The Institute collaborates closely with the Janelia Faculty of the Howard Hughes Medical Institute, the Allen Institute for Brain Science, and the National Institutes of Health to develop better methods for reconstructing neural architectures.", "token2charspan": [[0, 3], [4, 13], [14, 26], [27, 34], [35, 39], [40, 43], [44, 51], [52, 59], [60, 62], [63, 66], [67, 73], [74, 80], [81, 88], [89, 98], [98, 99], [100, 103], [104, 109], [110, 119], [120, 123], [124, 129], [130, 137], [137, 138], [139, 142], [143, 146], [147, 155], [156, 166], [167, 169], [170, 176], [177, 179], [180, 187], [188, 194], [195, 202], [203, 206], [207, 221], [222, 228], [229, 242], [242, 243]]}
{"doc_key": "ai-test-425", "ner": [[0, 0, "organisation"], [7, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 0, 0, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Google", "recently", "announced", "that", "in", "one", "day", "Google", "Translate", "translates", "enough", "text", "to", "fill", "1", "million", "books", "(", "2012", ")", "."], "sentence-detokenized": "Google recently announced that in one day Google Translate translates enough text to fill 1 million books (2012).", "token2charspan": [[0, 6], [7, 15], [16, 25], [26, 30], [31, 33], [34, 37], [38, 41], [42, 48], [49, 58], [59, 69], [70, 76], [77, 81], [82, 84], [85, 89], [90, 91], [92, 99], [100, 105], [106, 107], [107, 111], [111, 112], [112, 113]]}
{"doc_key": "ai-test-426", "ner": [[14, 15, "country"], [18, 19, "country"], [21, 21, "country"], [23, 23, "country"], [25, 25, "country"], [27, 28, "country"], [39, 40, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "events", "are", "held", "all", "over", "the", "world", "and", "are", "most", "popular", "in", "the", "United", "Kingdom", ",", "the", "United", "States", ",", "Japan", ",", "Singapore", ",", "India", ",", "South", "Korea", "and", "are", "becoming", "increasingly", "popular", "in", "subcontinent", "countries", "such", "as", "Sri", "Lanka", "."], "sentence-detokenized": "The events are held all over the world and are most popular in the United Kingdom, the United States, Japan, Singapore, India, South Korea and are becoming increasingly popular in subcontinent countries such as Sri Lanka.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 19], [20, 23], [24, 28], [29, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 59], [60, 62], [63, 66], [67, 73], [74, 81], [81, 82], [83, 86], [87, 93], [94, 100], [100, 101], [102, 107], [107, 108], [109, 118], [118, 119], [120, 125], [125, 126], [127, 132], [133, 138], [139, 142], [143, 146], [147, 155], [156, 168], [169, 176], [177, 179], [180, 192], [193, 202], [203, 207], [208, 210], [211, 214], [215, 220], [220, 221]]}
{"doc_key": "ai-test-427", "ner": [[6, 8, "programlang"], [11, 11, "programlang"], [13, 13, "programlang"], [15, 16, "programlang"], [18, 18, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "mostly", "developed", "in", "R", ",", "and", "sometimes", "in", "Java", ",", "C", ",", "C", "++", "and", "Fortran", "."], "sentence-detokenized": "These packages are mostly developed in R, and sometimes in Java, C, C++ and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 25], [26, 35], [36, 38], [39, 40], [40, 41], [42, 45], [46, 55], [56, 58], [59, 63], [63, 64], [65, 66], [66, 67], [68, 69], [69, 71], [72, 75], [76, 83], [83, 84]]}
{"doc_key": "ai-test-428", "ner": [[2, 11, "conference"], [8, 10, "conference"], [13, 13, "researcher"], [15, 16, "researcher"], [18, 20, "researcher"], [22, 25, "algorithm"], [29, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[8, 10, 2, 11, "named", "", false, false], [13, 13, 2, 11, "physical", "", false, false], [13, 13, 2, 11, "role", "", false, false], [13, 13, 18, 20, "role", "teams_up_with", false, false], [13, 13, 22, 25, "usage", "", false, false], [15, 16, 2, 11, "physical", "", false, false], [15, 16, 2, 11, "role", "", false, false], [15, 16, 18, 20, "role", "teams_up_with", false, false], [15, 16, 22, 25, "usage", "", false, false], [18, 20, 2, 11, "physical", "", false, false], [18, 20, 2, 11, "role", "", false, false], [18, 20, 22, 25, "usage", "", false, false], [22, 25, 29, 33, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["At", "the", "European", "Conference", "on", "Computer", "Vision", "(", "ECCV", ")", "in", "2006", ".", "Dalal", "and", "Triggs", "teamed", "with", "Cordelia", "Schmidt", "to", "apply", "HOG", "detectors", "to", "the", "problem", "of", "detecting", "people", "in", "movies", "and", "videos", "."], "sentence-detokenized": "At the European Conference on Computer Vision (ECCV) in 2006. Dalal and Triggs teamed with Cordelia Schmidt to apply HOG detectors to the problem of detecting people in movies and videos.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 26], [27, 29], [30, 38], [39, 45], [46, 47], [47, 51], [51, 52], [53, 55], [56, 60], [60, 61], [62, 67], [68, 71], [72, 78], [79, 85], [86, 90], [91, 99], [100, 107], [108, 110], [111, 116], [117, 120], [121, 130], [131, 133], [134, 137], [138, 145], [146, 148], [149, 158], [159, 165], [166, 168], [169, 175], [176, 179], [180, 186], [186, 187]]}
{"doc_key": "ai-test-429", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [11, 12, "task"], [19, 21, "metrics"], [23, 26, "metrics"], [29, 29, "metrics"], [33, 35, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 3, 11, 12, "related-to", "measured_with", false, false], [5, 5, 11, 12, "related-to", "measured_with", false, false], [19, 21, 11, 12, "related-to", "measured_with", false, false], [23, 26, 19, 21, "named", "", false, false], [29, 29, 19, 21, "named", "", false, false], [37, 37, 33, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "addition", "to", "sensitivity", "and", "specificity", ",", "the", "performance", "of", "a", "binary", "classification", "test", "can", "be", "measured", "by", "the", "positive", "predictive", "value", "(", "PPV", ")", ",", "also", "known", "as", "precision", ",", "and", "the", "negative", "predictive", "value", "(", "NPV", ")", "."], "sentence-detokenized": "In addition to sensitivity and specificity, the performance of a binary classification test can be measured by the positive predictive value (PPV), also known as precision, and the negative predictive value (NPV).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 42], [42, 43], [44, 47], [48, 59], [60, 62], [63, 64], [65, 71], [72, 86], [87, 91], [92, 95], [96, 98], [99, 107], [108, 110], [111, 114], [115, 123], [124, 134], [135, 140], [141, 142], [142, 145], [145, 146], [146, 147], [148, 152], [153, 158], [159, 161], [162, 171], [171, 172], [173, 176], [177, 180], [181, 189], [190, 200], [201, 206], [207, 208], [208, 211], [211, 212], [212, 213]]}
{"doc_key": "ai-test-430", "ner": [[14, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "models", "can", "give", "partial", "credit", "for", "overlapping", "matches", "(", "e.g.", "by", "using", "the", "Jaccard", "index", "criterion", "."], "sentence-detokenized": "Such models can give partial credit for overlapping matches (e.g. by using the Jaccard index criterion.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 28], [29, 35], [36, 39], [40, 51], [52, 59], [60, 61], [61, 65], [66, 68], [69, 74], [75, 78], [79, 86], [87, 92], [93, 102], [102, 103]]}
{"doc_key": "ai-test-431", "ner": [[24, 29, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Furthermore", ",", "in", "the", "case", "of", "estimation", "based", "on", "a", "single", "sample", ",", "it", "shows", "philosophical", "issues", "and", "possible", "misunderstandings", "in", "the", "use", "of", "maximum", "likelihood", "estimators", "and", "likelihood", "functions", "."], "sentence-detokenized": "Furthermore, in the case of estimation based on a single sample, it shows philosophical issues and possible misunderstandings in the use of maximum likelihood estimators and likelihood functions.", "token2charspan": [[0, 11], [11, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 38], [39, 44], [45, 47], [48, 49], [50, 56], [57, 63], [63, 64], [65, 67], [68, 73], [74, 87], [88, 94], [95, 98], [99, 107], [108, 125], [126, 128], [129, 132], [133, 136], [137, 139], [140, 147], [148, 158], [159, 169], [170, 173], [174, 184], [185, 194], [194, 195]]}
