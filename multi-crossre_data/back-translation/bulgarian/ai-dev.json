{"doc_key": "ai-dev-1", "ner": [[1, 1, "metrics"], [6, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 9, 1, 1, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Here", "accuracy", "is", "measured", "by", "the", "error", "rate", ",", "which", "is", "defined", "as", ":"], "sentence-detokenized": "Here accuracy is measured by the error rate, which is defined as:", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 25], [26, 28], [29, 32], [33, 38], [39, 43], [43, 44], [45, 50], [51, 53], [54, 61], [62, 64], [64, 65]]}
{"doc_key": "ai-dev-2", "ner": [[4, 4, "algorithm"], [11, 12, "misc"], [16, 19, "algorithm"], [17, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 11, 12, "type-of", "", false, false], [4, 4, 16, 19, "related-to", "", false, false], [4, 4, 17, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["From", "this", "perspective", ",", "SVM", "is", "closely", "related", "to", "other", "basic", "classification", "algorithms", ",", "such", "as", "regularized", "logistic", "least", "squares", "regression", "."], "sentence-detokenized": "From this perspective, SVM is closely related to other basic classification algorithms, such as regularized logistic least squares regression.", "token2charspan": [[0, 4], [5, 9], [10, 21], [21, 22], [23, 26], [27, 29], [30, 37], [38, 45], [46, 48], [49, 54], [55, 60], [61, 75], [76, 86], [86, 87], [88, 92], [93, 95], [96, 107], [108, 116], [117, 122], [123, 130], [131, 141], [141, 142]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [3, 6, "person"], [14, 15, "person"], [17, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 6, 0, 1, "named", "actor_plays_character", false, false], [3, 6, 0, 1, "origin", "actor_plays_character", false, false], [17, 19, 14, 15, "named", "actor_plays_character", false, false], [17, 19, 14, 15, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brian", "James", "is", "Leon", "Kowalski", ",", "a", "replicant", "who", "fights", "and", "works", ",", "and", "Joanna", "Cassidy", "is", "Zhora", ",", "a", "replicant", "-", "killer", "."], "sentence-detokenized": "Brian James is Leon Kowalski, a replicant who fights and works, and Joanna Cassidy is Zhora, a replicant-killer.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 19], [20, 28], [28, 29], [30, 31], [32, 41], [42, 45], [46, 52], [53, 56], [57, 62], [62, 63], [64, 67], [68, 74], [75, 82], [83, 85], [86, 91], [91, 92], [93, 94], [95, 104], [104, 105], [105, 111], [111, 112]]}
{"doc_key": "ai-dev-4", "ner": [[18, 21, "product"], [23, 23, "product"], [26, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 21, 26, 26, "physical", "", false, false], [23, 23, 18, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "photo", "that", "was", "scanned", ",", "stored", ",", "and", "recreated", "into", "digital", "pixels", "was", "shown", "to", "the", "Eastern", "Automated", "Standards", "Computer", "(", "SEAC", ")", "at", "NIST", "."], "sentence-detokenized": "The first photo that was scanned, stored, and recreated into digital pixels was shown to the Eastern Automated Standards Computer (SEAC) at NIST.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 20], [21, 24], [25, 32], [32, 33], [34, 40], [40, 41], [42, 45], [46, 55], [56, 60], [61, 68], [69, 75], [76, 79], [80, 85], [86, 88], [89, 92], [93, 100], [101, 110], [111, 120], [121, 129], [130, 131], [131, 135], [135, 136], [137, 139], [140, 144], [144, 145]]}
{"doc_key": "ai-dev-5", "ner": [[0, 8, "task"], [19, 20, "task"], [22, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 8, 19, 20, "part-of", "", false, false], [0, 8, 22, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Segmenting", "text", "into", "topics", "or", "discourses", "can", "be", "useful", "in", "some", "natural", "processing", "tasks", ":", "it", "can", "significantly", "improve", "information", "retrieval", "or", "speech", "recognition", "(", "either", "by", "indexing", "/", "recognizing", "documents", "more", "accurately", "or", "by", "providing", "the", "specific", "part", "of", "the", "document", "relevant", "to", "the", "query", "as", "a", "result", ")", "."], "sentence-detokenized": "Segmenting text into topics or discourses can be useful in some natural processing tasks: it can significantly improve information retrieval or speech recognition (either by indexing/recognizing documents more accurately or by providing the specific part of the document relevant to the query as a result).", "token2charspan": [[0, 10], [11, 15], [16, 20], [21, 27], [28, 30], [31, 41], [42, 45], [46, 48], [49, 55], [56, 58], [59, 63], [64, 71], [72, 82], [83, 88], [88, 89], [90, 92], [93, 96], [97, 110], [111, 118], [119, 130], [131, 140], [141, 143], [144, 150], [151, 162], [163, 164], [164, 170], [171, 173], [174, 182], [182, 183], [183, 194], [195, 204], [205, 209], [210, 220], [221, 223], [224, 226], [227, 236], [237, 240], [241, 249], [250, 254], [255, 257], [258, 261], [262, 270], [271, 279], [280, 282], [283, 286], [287, 292], [293, 295], [296, 297], [298, 304], [304, 305], [305, 306]]}
{"doc_key": "ai-dev-6", "ner": [[9, 12, "university"], [24, 27, "conference"], [28, 29, "university"], [39, 40, "researcher"], [42, 43, "researcher"], [45, 46, "researcher"], [48, 49, "researcher"], [51, 52, "researcher"], [54, 55, "researcher"], [57, 59, "researcher"], [62, 63, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[24, 27, 28, 29, "physical", "", false, false], [39, 40, 24, 27, "physical", "", false, false], [39, 40, 24, 27, "role", "", false, false], [39, 40, 24, 27, "temporal", "", false, false], [42, 43, 24, 27, "physical", "", false, false], [42, 43, 24, 27, "role", "", false, false], [42, 43, 24, 27, "temporal", "", false, false], [45, 46, 24, 27, "physical", "", false, false], [45, 46, 24, 27, "role", "", false, false], [45, 46, 24, 27, "temporal", "", false, false], [48, 49, 24, 27, "physical", "", false, false], [48, 49, 24, 27, "role", "", false, false], [48, 49, 24, 27, "temporal", "", false, false], [51, 52, 24, 27, "physical", "", false, false], [51, 52, 24, 27, "role", "", false, false], [51, 52, 24, 27, "temporal", "", false, false], [54, 55, 24, 27, "physical", "", false, false], [54, 55, 24, 27, "role", "", false, false], [54, 55, 24, 27, "temporal", "", false, false], [57, 59, 24, 27, "physical", "", false, false], [57, 59, 24, 27, "role", "", false, false], [57, 59, 24, 27, "temporal", "", false, false], [62, 63, 24, 27, "physical", "", false, false], [62, 63, 24, 27, "role", "", false, false], [62, 63, 24, 27, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["In", "1999", ",", "he", "organized", "such", "a", "symposium", "at", "Indiana", "University", ",", "and", "in", "April", "2000", ",", "he", "organized", "a", "larger", "symposium", "entitled", "\"", "Spiritual", "Robots", "\"", "at", "Stanford", "University", ",", "in", "which", "he", "moderated", "a", "panel", "consisting", "of", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", ",", "and", "John", "Koza", "."], "sentence-detokenized": "In 1999, he organized such a symposium at Indiana University, and in April 2000, he organized a larger symposium entitled \"Spiritual Robots\" at Stanford University, in which he moderated a panel consisting of Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland, and John Koza.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 21], [22, 26], [27, 28], [29, 38], [39, 41], [42, 49], [50, 60], [60, 61], [62, 65], [66, 68], [69, 74], [75, 79], [79, 80], [81, 83], [84, 93], [94, 95], [96, 102], [103, 112], [113, 121], [122, 123], [123, 132], [133, 139], [139, 140], [141, 143], [144, 152], [153, 163], [163, 164], [165, 167], [168, 173], [174, 176], [177, 186], [187, 188], [189, 194], [195, 205], [206, 208], [209, 212], [213, 221], [221, 222], [223, 227], [228, 235], [235, 236], [237, 242], [243, 248], [248, 249], [250, 255], [256, 262], [262, 263], [264, 268], [269, 272], [272, 273], [274, 279], [280, 285], [285, 286], [287, 291], [292, 297], [298, 305], [305, 306], [307, 310], [311, 315], [316, 320], [320, 321]]}
{"doc_key": "ai-dev-7", "ner": [[0, 2, "metrics"], [3, 3, "metrics"], [6, 6, "metrics"], [7, 9, "metrics"], [20, 20, "metrics"], [40, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 20, 20, "named", "", false, false], [3, 3, 0, 2, "named", "", false, false], [6, 6, 40, 40, "named", "", false, false], [7, 9, 6, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Both", "the", "precision", "p", "and", "the", "recall", "r", "of", "the", "test", "are", "taken", "into", "account", "when", "calculating", "the", "score", ":", "p", "is", "the", "number", "of", "true", "positives", "divided", "by", "the", "number", "of", "all", "positives", "returned", "by", "the", "classifier", ",", "and", "r", "is", "the", "number", "of", "true", "positives", "divided", "by", "the", "number", "of", "all", "relevant", "samples", "(", "all", "samples", "that", "should", "have", "been", "identified", "as", "positive", ")", "."], "sentence-detokenized": "Both the precision p and the recall r of the test are taken into account when calculating the score: p is the number of true positives divided by the number of all positives returned by the classifier, and r is the number of true positives divided by the number of all relevant samples (all samples that should have been identified as positive).", "token2charspan": [[0, 4], [5, 8], [9, 18], [19, 20], [21, 24], [25, 28], [29, 35], [36, 37], [38, 40], [41, 44], [45, 49], [50, 53], [54, 59], [60, 64], [65, 72], [73, 77], [78, 89], [90, 93], [94, 99], [99, 100], [101, 102], [103, 105], [106, 109], [110, 116], [117, 119], [120, 124], [125, 134], [135, 142], [143, 145], [146, 149], [150, 156], [157, 159], [160, 163], [164, 173], [174, 182], [183, 185], [186, 189], [190, 200], [200, 201], [202, 205], [206, 207], [208, 210], [211, 214], [215, 221], [222, 224], [225, 229], [230, 239], [240, 247], [248, 250], [251, 254], [255, 261], [262, 264], [265, 268], [269, 277], [278, 285], [286, 287], [287, 290], [291, 298], [299, 303], [304, 310], [311, 315], [316, 320], [321, 331], [332, 334], [335, 343], [343, 344], [344, 345]]}
{"doc_key": "ai-dev-8", "ner": [[2, 2, "organisation"], [25, 25, "product"], [33, 36, "person"], [40, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 25, 25, "artifact", "", false, false], [25, 25, 33, 36, "win-defeat", "", false, false], [25, 25, 40, 40, "win-defeat", "", true, false], [33, 36, 40, 40, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "the", "Google", "acquisition", ",", "the", "company", "has", "achieved", "a", "number", "of", "significant", "successes", ",", "perhaps", "the", "most", "notable", "of", "which", "is", "the", "creation", "of", "AlphaGo", ",", "a", "program", "that", "beat", "world", "champion", "Lee", "Sedol", "at", "the", "complex", "game", "of", "Go", "."], "sentence-detokenized": "Since the Google acquisition, the company has achieved a number of significant successes, perhaps the most notable of which is the creation of AlphaGo, a program that beat world champion Lee Sedol at the complex game of Go.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 28], [28, 29], [30, 33], [34, 41], [42, 45], [46, 54], [55, 56], [57, 63], [64, 66], [67, 78], [79, 88], [88, 89], [90, 97], [98, 101], [102, 106], [107, 114], [115, 117], [118, 123], [124, 126], [127, 130], [131, 139], [140, 142], [143, 150], [150, 151], [152, 153], [154, 161], [162, 166], [167, 171], [172, 177], [178, 186], [187, 190], [191, 196], [197, 199], [200, 203], [204, 211], [212, 216], [217, 219], [220, 222], [222, 223]]}
{"doc_key": "ai-dev-9", "ner": [[12, 13, "misc"], [26, 26, "field"], [30, 32, "product"], [50, 52, "misc"], [55, 56, "misc"], [59, 59, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 13, 26, 26, "part-of", "", false, false], [12, 13, 55, 56, "named", "same", false, false], [30, 32, 50, 52, "related-to", "", false, false], [30, 32, 55, 56, "usage", "", false, false], [30, 32, 59, 59, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Representing", "words", "given", "their", "context", "by", "dense", "fixed", "-", "size", "vectors", "(", "word", "embeddings", ")", "has", "become", "one", "of", "the", "most", "basic", "building", "blocks", "in", "several", "NLP", "systems", ".", "an", "unsupervised", "disambiguation", "system", "uses", "the", "similarity", "between", "word", "meanings", "in", "a", "fixed", "-", "context", "window", "to", "select", "the", "most", "appropriate", "word", "meaning", "using", "a", "pre-trained", "word", "embedding", "model", "and", "WordNet", "."], "sentence-detokenized": "Representing words given their context by dense fixed-size vectors (word embeddings) has become one of the most basic building blocks in several NLP systems. an unsupervised disambiguation system uses the similarity between word meanings in a fixed-context window to select the most appropriate word meaning using a pre-trained word embedding model and WordNet.", "token2charspan": [[0, 12], [13, 18], [19, 24], [25, 30], [31, 38], [39, 41], [42, 47], [48, 53], [53, 54], [54, 58], [59, 66], [67, 68], [68, 72], [73, 83], [83, 84], [85, 88], [89, 95], [96, 99], [100, 102], [103, 106], [107, 111], [112, 117], [118, 126], [127, 133], [134, 136], [137, 144], [145, 148], [149, 156], [156, 157], [158, 160], [161, 173], [174, 188], [189, 195], [196, 200], [201, 204], [205, 215], [216, 223], [224, 228], [229, 237], [238, 240], [241, 242], [243, 248], [248, 249], [249, 256], [257, 263], [264, 266], [267, 273], [274, 277], [278, 282], [283, 294], [295, 299], [300, 307], [308, 313], [314, 315], [316, 327], [328, 332], [333, 342], [343, 348], [349, 352], [353, 360], [360, 361]]}
{"doc_key": "ai-dev-10", "ner": [[0, 2, "field"], [4, 4, "field"], [6, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 0, 2, "part-of", "", false, false], [6, 15, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "techniques", "-", "supervised", "or", "unsupervised", "learning", "-", "are", "used", "to", "automatically", "create", "such", "rules", "."], "sentence-detokenized": "Machine learning techniques - supervised or unsupervised learning - are used to automatically create such rules.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [30, 40], [41, 43], [44, 56], [57, 65], [66, 67], [68, 71], [72, 76], [77, 79], [80, 93], [94, 100], [101, 105], [106, 111], [111, 112]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1969", ",", "Scheinman", "invented", "the", "Stanford", "Hand", ","], "sentence-detokenized": "In 1969, Scheinman invented the Stanford Hand,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 27], [28, 31], [32, 40], [41, 45], [45, 46]]}
{"doc_key": "ai-dev-12", "ner": [[1, 3, "metrics"], [8, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "the", "Log", "loss", "is", "differentiable", ",", "a", "gradient", "-", "based", "method", "can", "be", "used", "to", "optimize", "the", "model", "."], "sentence-detokenized": "Since the Log loss is differentiable, a gradient-based method can be used to optimize the model.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 18], [19, 21], [22, 36], [36, 37], [38, 39], [40, 48], [48, 49], [49, 54], [55, 61], [62, 65], [66, 68], [69, 73], [74, 76], [77, 85], [86, 89], [90, 95], [95, 96]]}
{"doc_key": "ai-dev-13", "ner": [[4, 5, "field"], [7, 9, "algorithm"], [11, 11, "algorithm"], [14, 16, "algorithm"], [19, 20, "field"], [30, 30, "task"], [32, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 9, 19, 20, "part-of", "", false, false], [11, 11, 7, 9, "named", "", false, false], [14, 16, 7, 9, "named", "", false, false], [19, 20, 4, 5, "part-of", "subfield", false, false], [30, 30, 19, 20, "part-of", "", false, false], [32, 33, 19, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "field", "of", "machine", "learning", ",", "support", "vector", "machines", "(", "SVMs", ",", "also", "support", "vector", "networks", ")", "are", "supervised", "learning", "models", "with", "learning", "algorithms", "that", "analyze", "data", "used", "for", "classification", "and", "regression", "analysis", "."], "sentence-detokenized": "In the field of machine learning, support vector machines (SVMs, also support vector networks) are supervised learning models with learning algorithms that analyze data used for classification and regression analysis.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 23], [24, 32], [32, 33], [34, 41], [42, 48], [49, 57], [58, 59], [59, 63], [63, 64], [65, 69], [70, 77], [78, 84], [85, 93], [93, 94], [95, 98], [99, 109], [110, 118], [119, 125], [126, 130], [131, 139], [140, 150], [151, 155], [156, 163], [164, 168], [169, 173], [174, 177], [178, 192], [193, 196], [197, 207], [208, 216], [216, 217]]}
{"doc_key": "ai-dev-14", "ner": [[8, 9, "task"], [11, 18, "task"], [29, 29, "metrics"], [31, 31, "metrics"], [33, 33, "researcher"], [35, 35, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 18, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "2002", ")", "as", "an", "automatic", "metric", "for", "machine", "translation", "(", "MT", ")", "evaluation", ",", "many", "other", "methods", "have", "been", "proposed", "to", "revise", "or", "improve", "it", ",", "such", "as", "TER", ",", "METEOR", ",", "Banerjee", "and", "Lavie", ",", "(", "2005", ")", ",", "etc", "."], "sentence-detokenized": "(2002) as an automatic metric for machine translation (MT) evaluation, many other methods have been proposed to revise or improve it, such as TER, METEOR, Banerjee and Lavie, (2005), etc.", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 9], [10, 12], [13, 22], [23, 29], [30, 33], [34, 41], [42, 53], [54, 55], [55, 57], [57, 58], [59, 69], [69, 70], [71, 75], [76, 81], [82, 89], [90, 94], [95, 99], [100, 108], [109, 111], [112, 118], [119, 121], [122, 129], [130, 132], [132, 133], [134, 138], [139, 141], [142, 145], [145, 146], [147, 153], [153, 154], [155, 163], [164, 167], [168, 173], [173, 174], [175, 176], [176, 180], [180, 181], [181, 182], [183, 186], [186, 187]]}
{"doc_key": "ai-dev-15", "ner": [[3, 4, "misc"], [8, 8, "organisation"], [8, 9, "organisation"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 8, 9, "origin", "", false, false], [8, 9, 8, 8, "part-of", "", false, false], [15, 16, 8, 9, "role", "", false, false], [18, 19, 8, 9, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "includes", "an", "upper", "ontology", "created", "by", "the", "IEEE", "P1600.1", "working", "group", "(", "originally", "by", "Ian", "Niles", "and", "Adam", "Pease", ")", "."], "sentence-detokenized": "It includes an upper ontology created by the IEEE P1600.1 working group (originally by Ian Niles and Adam Pease).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 20], [21, 29], [30, 37], [38, 40], [41, 44], [45, 49], [50, 57], [58, 65], [66, 71], [72, 73], [73, 83], [84, 86], [87, 90], [91, 96], [97, 100], [101, 105], [106, 111], [111, 112], [112, 113]]}
{"doc_key": "ai-dev-16", "ner": [[1, 5, "misc"], [32, 34, "algorithm"], [36, 37, "algorithm"], [41, 44, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[32, 34, 1, 5, "part-of", "", true, false], [36, 37, 1, 5, "part-of", "", true, false], [41, 44, 36, 37, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "cryoelectron", "tomography", ",", "where", "a", "limited", "number", "of", "projections", "are", "obtained", "due", "to", "hardware", "limitations", "and", "to", "avoid", "damage", "to", "the", "biological", "specimen", ",", "it", "can", "be", "used", "in", "conjunction", "with", "compressive", "sensing", "techniques", "or", "regularization", "functions", "(", "e.g.", ",", "Huber", "loss", ")", "to", "enhance", "the", "reconstruction", "for", "better", "interpretation", "."], "sentence-detokenized": "In cryoelectron tomography, where a limited number of projections are obtained due to hardware limitations and to avoid damage to the biological specimen, it can be used in conjunction with compressive sensing techniques or regularization functions (e.g., Huber loss) to enhance the reconstruction for better interpretation.", "token2charspan": [[0, 2], [3, 15], [16, 26], [26, 27], [28, 33], [34, 35], [36, 43], [44, 50], [51, 53], [54, 65], [66, 69], [70, 78], [79, 82], [83, 85], [86, 94], [95, 106], [107, 110], [111, 113], [114, 119], [120, 126], [127, 129], [130, 133], [134, 144], [145, 153], [153, 154], [155, 157], [158, 161], [162, 164], [165, 169], [170, 172], [173, 184], [185, 189], [190, 201], [202, 209], [210, 220], [221, 223], [224, 238], [239, 248], [249, 250], [250, 254], [254, 255], [256, 261], [262, 266], [266, 267], [268, 270], [271, 278], [279, 282], [283, 297], [298, 301], [302, 308], [309, 323], [323, 324]]}
{"doc_key": "ai-dev-17", "ner": [[3, 3, "misc"], [6, 6, "programlang"], [9, 12, "algorithm"], [11, 12, "algorithm"], [16, 19, "algorithm"], [23, 25, "product"], [28, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 6, 6, "part-of", "", false, false], [9, 12, 3, 3, "type-of", "", false, false], [11, 12, 3, 3, "type-of", "", false, false], [16, 19, 3, 3, "type-of", "", false, false], [23, 25, 6, 6, "general-affiliation", "", true, false], [23, 25, 6, 6, "part-of", "", true, false], [28, 28, 23, 25, "role", "publishes", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Implementation", "of", "several", "bleaching", "procedures", "in", "R", ",", "including", "ZCA", "and", "PCA", "bleaching", ",", "but", "also", "CCA", "bleaching", ",", "is", "available", "in", "the", "R", "bleaching", "package", "published", "in", "CRAN", "."], "sentence-detokenized": "Implementation of several bleaching procedures in R, including ZCA and PCA bleaching, but also CCA bleaching, is available in the R bleaching package published in CRAN.", "token2charspan": [[0, 14], [15, 17], [18, 25], [26, 35], [36, 46], [47, 49], [50, 51], [51, 52], [53, 62], [63, 66], [67, 70], [71, 74], [75, 84], [84, 85], [86, 89], [90, 94], [95, 98], [99, 108], [108, 109], [110, 112], [113, 122], [123, 125], [126, 129], [130, 131], [132, 141], [142, 149], [150, 159], [160, 162], [163, 167], [167, 168]]}
{"doc_key": "ai-dev-18", "ner": [[29, 29, "product"], [31, 31, "product"], [33, 33, "product"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [42, 43, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[29, 29, 33, 33, "compare", "", false, false], [29, 29, 35, 35, "compare", "", false, false], [29, 29, 37, 37, "compare", "", false, false], [29, 29, 39, 39, "compare", "", false, false], [29, 29, 42, 43, "compare", "", false, false], [31, 31, 33, 33, "compare", "", false, false], [31, 31, 35, 35, "compare", "", false, false], [31, 31, 37, 37, "compare", "", false, false], [31, 31, 39, 39, "compare", "", false, false], [31, 31, 42, 43, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Today", ",", "this", "field", "has", "become", "even", "more", "challenging", "and", "complex", "with", "the", "addition", "of", "languages", "and", "software", "for", "analyzing", "and", "designing", "circuits", ",", "systems", "and", "signals", "-", "from", "MATLAB", "and", "Simulink", "to", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "and", "even", "Assembly", "language", "."], "sentence-detokenized": "Today, this field has become even more challenging and complex with the addition of languages and software for analyzing and designing circuits, systems and signals - from MATLAB and Simulink to NumPy, VHDL, PSpice, Verilog and even Assembly language.", "token2charspan": [[0, 5], [5, 6], [7, 11], [12, 17], [18, 21], [22, 28], [29, 33], [34, 38], [39, 50], [51, 54], [55, 62], [63, 67], [68, 71], [72, 80], [81, 83], [84, 93], [94, 97], [98, 106], [107, 110], [111, 120], [121, 124], [125, 134], [135, 143], [143, 144], [145, 152], [153, 156], [157, 164], [165, 166], [167, 171], [172, 178], [179, 182], [183, 191], [192, 194], [195, 200], [200, 201], [202, 206], [206, 207], [208, 214], [214, 215], [216, 223], [224, 227], [228, 232], [233, 241], [242, 250], [250, 251]]}
{"doc_key": "ai-dev-19", "ner": [[5, 6, "person"], [14, 20, "person"], [16, 18, "organisation"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 18, 14, 20, "origin", "", false, false], [22, 22, 16, 18, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "company", "was", "founded", "by", "Kiichiro", "Toyoda", "in", "1937", "as", "a", "separate", "company", "from", "Sakichi", "Toyoda", "'s", "Toyota", "Industries", "company", "to", "create", "automobiles", "."], "sentence-detokenized": "The company was founded by Kiichiro Toyoda in 1937 as a separate company from Sakichi Toyoda's Toyota Industries company to create automobiles.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 35], [36, 42], [43, 45], [46, 50], [51, 53], [54, 55], [56, 64], [65, 72], [73, 77], [78, 85], [86, 92], [92, 94], [95, 101], [102, 112], [113, 120], [121, 123], [124, 130], [131, 142], [142, 143]]}
{"doc_key": "ai-dev-20", "ner": [[0, 1, "field"], [53, 56, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[53, 56, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Unsupervised", "learning", ",", "on", "the", "other", "hand", ",", "assumes", "training", "data", "that", "has", "not", "been", "manually", "labeled", ",", "and", "attempts", "to", "discover", "inherent", "patterns", "in", "the", "data", "that", "can", "then", "be", "used", "to", "determine", "the", "correct", "baseline", "for", "new", "data", "instances", ".", "A", "combination", "of", "the", "two", "that", "has", "recently", "been", "explored", "is", "semi-supervised", "learning", ",", "which", "uses", "a", "combination", "of", "labeled", "and", "unlabeled", "data", "(", "typically", "a", "small", "set", "of", "labeled", "data", "combined", "with", "a", "large", "amount", "of", "unlabeled", "data", ")", "."], "sentence-detokenized": "Unsupervised learning, on the other hand, assumes training data that has not been manually labeled, and attempts to discover inherent patterns in the data that can then be used to determine the correct baseline for new data instances. A combination of the two that has recently been explored is semi-supervised learning, which uses a combination of labeled and unlabeled data (typically a small set of labeled data combined with a large amount of unlabeled data).", "token2charspan": [[0, 12], [13, 21], [21, 22], [23, 25], [26, 29], [30, 35], [36, 40], [40, 41], [42, 49], [50, 58], [59, 63], [64, 68], [69, 72], [73, 76], [77, 81], [82, 90], [91, 98], [98, 99], [100, 103], [104, 112], [113, 115], [116, 124], [125, 133], [134, 142], [143, 145], [146, 149], [150, 154], [155, 159], [160, 163], [164, 168], [169, 171], [172, 176], [177, 179], [180, 189], [190, 193], [194, 201], [202, 210], [211, 214], [215, 218], [219, 223], [224, 233], [233, 234], [235, 236], [237, 248], [249, 251], [252, 255], [256, 259], [260, 264], [265, 268], [269, 277], [278, 282], [283, 291], [292, 294], [295, 310], [311, 319], [319, 320], [321, 326], [327, 331], [332, 333], [334, 345], [346, 348], [349, 356], [357, 360], [361, 370], [371, 375], [376, 377], [377, 386], [387, 388], [389, 394], [395, 398], [399, 401], [402, 409], [410, 414], [415, 423], [424, 428], [429, 430], [431, 436], [437, 443], [444, 446], [447, 456], [457, 461], [461, 462], [462, 463]]}
{"doc_key": "ai-dev-21", "ner": [[22, 22, "organisation"], [23, 24, "product"], [26, 27, "organisation"], [29, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 24, 22, 22, "artifact", "", false, false], [26, 27, 29, 29, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Despite", "these", "humanoid", "robots", "for", "utilitarian", "purposes", ",", "there", "are", "some", "humanoid", "robots", "that", "are", "designed", "for", "entertainment", "purposes", ",", "such", "as", "Sony", "'s", "QRIO", "and", "Wow", "Wee", "'s", "RoboSapien", "."], "sentence-detokenized": "Despite these humanoid robots for utilitarian purposes, there are some humanoid robots that are designed for entertainment purposes, such as Sony's QRIO and Wow Wee's RoboSapien.", "token2charspan": [[0, 7], [8, 13], [14, 22], [23, 29], [30, 33], [34, 45], [46, 54], [54, 55], [56, 61], [62, 65], [66, 70], [71, 79], [80, 86], [87, 91], [92, 95], [96, 104], [105, 108], [109, 122], [123, 131], [131, 132], [133, 137], [138, 140], [141, 145], [145, 147], [148, 152], [153, 156], [157, 160], [161, 164], [164, 166], [167, 177], [177, 178]]}
{"doc_key": "ai-dev-22", "ner": [[3, 3, "researcher"], [9, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 9, 15, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1991", ",", "Webber", "became", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "In 1991, Webber became a member of the Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 22], [23, 24], [25, 31], [32, 34], [35, 38], [39, 50], [51, 54], [55, 58], [59, 70], [71, 73], [74, 84], [85, 97], [97, 98]]}
{"doc_key": "ai-dev-23", "ner": [[6, 7, "field"], [9, 10, "field"], [20, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 23, 6, 7, "part-of", "task_part_of_field", false, false], [20, 23, 9, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["At", "this", "company", ",", "he", "develops", "data", "mining", "and", "database", "technologies", ",", "specifically", "high", "-", "level", "ontologies", "for", "intelligence", "and", "automated", "natural", "language", "understanding", "."], "sentence-detokenized": "At this company, he develops data mining and database technologies, specifically high-level ontologies for intelligence and automated natural language understanding.", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 19], [20, 28], [29, 33], [34, 40], [41, 44], [45, 53], [54, 66], [66, 67], [68, 80], [81, 85], [85, 86], [86, 91], [92, 102], [103, 106], [107, 119], [120, 123], [124, 133], [134, 141], [142, 150], [151, 164], [164, 165]]}
{"doc_key": "ai-dev-24", "ner": [[21, 22, "misc"], [25, 28, "misc"], [33, 34, "misc"], [36, 36, "country"], [39, 40, "organisation"], [42, 42, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[21, 22, 36, 36, "physical", "", false, false], [25, 28, 36, 36, "physical", "", false, false], [33, 34, 36, 36, "physical", "", false, false], [39, 40, 42, 42, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["However", ",", "recent", "years", "have", "seen", "the", "emergence", "of", "various", "e-services", "and", "related", "initiatives", "in", "developing", "countries", ",", "such", "as", "the", "Nemmadi", "Project", ",", "the", "MCA21", "Mission", "Mode", "Project", ",", "or", "more", "so", "Digital", "India", "in", "India", ";", "the", "e-Governance", "Directorate", "in", "Pakistan", ",", "etc."], "sentence-detokenized": "However, recent years have seen the emergence of various e-services and related initiatives in developing countries, such as the Nemmadi Project, the MCA21 Mission Mode Project, or more so Digital India in India; the e-Governance Directorate in Pakistan, etc.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 21], [22, 26], [27, 31], [32, 35], [36, 45], [46, 48], [49, 56], [57, 67], [68, 71], [72, 79], [80, 91], [92, 94], [95, 105], [106, 115], [115, 116], [117, 121], [122, 124], [125, 128], [129, 136], [137, 144], [144, 145], [146, 149], [150, 155], [156, 163], [164, 168], [169, 176], [176, 177], [178, 180], [181, 185], [186, 188], [189, 196], [197, 202], [203, 205], [206, 211], [211, 212], [213, 216], [217, 229], [230, 241], [242, 244], [245, 253], [253, 254], [255, 259]]}
{"doc_key": "ai-dev-25", "ner": [[6, 6, "misc"], [8, 8, "field"], [10, 10, "field"], [12, 14, "university"], [16, 18, "university"], [25, 29, "university"], [34, 34, "misc"], [36, 37, "field"], [40, 43, "misc"], [45, 46, "university"], [48, 50, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[6, 6, 8, 8, "topic", "", false, false], [6, 6, 10, 10, "topic", "", false, false], [6, 6, 12, 14, "origin", "", false, false], [12, 14, 16, 18, "part-of", "", false, false], [25, 29, 12, 14, "part-of", "", false, false], [34, 34, 36, 37, "topic", "", false, false], [34, 34, 45, 46, "origin", "", false, false], [40, 43, 45, 46, "origin", "", false, false], [45, 46, 48, 50, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "1979", ",", "he", "received", "a", "Ph.D.", "in", "Radiophysics", "and", "Electronics", "from", "Rajabazar", "Sains", "College", ",", "University", "of", "Calcutta", ",", "as", "a", "student", "of", "the", "Indian", "Statistical", "Institute", ",", "and", "in", "1982", ",", "another", "Ph.D.", "in", "Electrical", "Engineering", "and", "a", "Diploma", "of", "Imperial", "College", "from", "Imperial", "College", ",", "University", "of", "London", "."], "sentence-detokenized": "In 1979, he received a Ph.D. in Radiophysics and Electronics from Rajabazar Sains College, University of Calcutta, as a student of the Indian Statistical Institute, and in 1982, another Ph.D. in Electrical Engineering and a Diploma of Imperial College from Imperial College, University of London.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 20], [21, 22], [23, 28], [29, 31], [32, 44], [45, 48], [49, 60], [61, 65], [66, 75], [76, 81], [82, 89], [89, 90], [91, 101], [102, 104], [105, 113], [113, 114], [115, 117], [118, 119], [120, 127], [128, 130], [131, 134], [135, 141], [142, 153], [154, 163], [163, 164], [165, 168], [169, 171], [172, 176], [176, 177], [178, 185], [186, 191], [192, 194], [195, 205], [206, 217], [218, 221], [222, 223], [224, 231], [232, 234], [235, 243], [244, 251], [252, 256], [257, 265], [266, 273], [273, 274], [275, 285], [286, 288], [289, 295], [295, 296]]}
{"doc_key": "ai-dev-26", "ner": [[0, 1, "location"], [21, 24, "misc"], [32, 33, "misc"], [35, 37, "person"], [39, 40, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 24, 0, 1, "temporal", "", false, false], [32, 33, 0, 1, "temporal", "", false, false], [35, 37, 32, 33, "role", "actor_in", false, false], [39, 40, 32, 33, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Expo", "II", "was", "announced", "as", "the", "site", "of", "the", "world", "premiere", "of", "several", "films", "never", "before", "shown", "in", "3D", ",", "including", "\"", "The", "Diamond", "Magician", "\"", "and", "Universal", "'s", "short", "film", "\"", "Hawaiian", "Nights", "with", "Mamie", "Van", "Doren", "and", "Pinky", "Lee", ".", "\""], "sentence-detokenized": "Expo II was announced as the site of the world premiere of several films never before shown in 3D, including \"The Diamond Magician\" and Universal's short film \"Hawaiian Nights with Mamie Van Doren and Pinky Lee.\"", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 24], [25, 28], [29, 33], [34, 36], [37, 40], [41, 46], [47, 55], [56, 58], [59, 66], [67, 72], [73, 78], [79, 85], [86, 91], [92, 94], [95, 97], [97, 98], [99, 108], [109, 110], [110, 113], [114, 121], [122, 130], [130, 131], [132, 135], [136, 145], [145, 147], [148, 153], [154, 158], [159, 160], [160, 168], [169, 175], [176, 180], [181, 186], [187, 190], [191, 196], [197, 200], [201, 206], [207, 210], [210, 211], [211, 212]]}
{"doc_key": "ai-dev-27", "ner": [[7, 8, "researcher"], [16, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 16, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "maximum", "subarray", "problem", "was", "proposed", "by", "Wolf", "Grender", "in", "1977", "as", "a", "simplified", "model", "for", "maximum", "likelihood", "estimation", "of", "patterns", "in", "digital", "images", "."], "sentence-detokenized": "The maximum subarray problem was proposed by Wolf Grender in 1977 as a simplified model for maximum likelihood estimation of patterns in digital images.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 28], [29, 32], [33, 41], [42, 44], [45, 49], [50, 57], [58, 60], [61, 65], [66, 68], [69, 70], [71, 81], [82, 87], [88, 91], [92, 99], [100, 110], [111, 121], [122, 124], [125, 133], [134, 136], [137, 144], [145, 151], [151, 152]]}
{"doc_key": "ai-dev-28", "ner": [[0, 1, "product"], [3, 4, "product"], [6, 8, "product"], [10, 11, "product"], [13, 15, "product"], [17, 20, "product"], [31, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[31, 31, 0, 1, "part-of", "", false, false], [31, 31, 3, 4, "part-of", "", false, false], [31, 31, 6, 8, "part-of", "", false, false], [31, 31, 10, 11, "part-of", "", false, false], [31, 31, 13, 15, "part-of", "", false, false], [31, 31, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["iPhone", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", ",", "iPod", "Touch", "5", "G", "and", "newer", "models", "feature", "a", "more", "advanced", "voice", "assistant", "called", "Siri", "."], "sentence-detokenized": "iPhone 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G, iPod Touch 5G and newer models feature a more advanced voice assistant called Siri.", "token2charspan": [[0, 6], [7, 9], [9, 10], [11, 15], [16, 17], [17, 18], [19, 23], [24, 28], [29, 31], [31, 32], [33, 37], [38, 41], [41, 42], [43, 47], [48, 51], [52, 54], [54, 55], [56, 60], [61, 66], [67, 68], [68, 69], [70, 73], [74, 79], [80, 86], [87, 94], [95, 96], [97, 101], [102, 110], [111, 116], [117, 126], [127, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-dev-29", "ner": [[7, 8, "metrics"], [11, 14, "metrics"], [16, 17, "metrics"], [38, 42, "metrics"], [46, 49, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 14, 38, 42, "named", "", false, false], [16, 17, 11, 14, "named", "", false, false], [38, 42, 46, 49, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["It", "is", "easy", "to", "verify", "that", "the", "logistic", "loss", "and", "the", "binary", "cross", "-entropy", "loss", "(", "Log", "loss", ")", "are", "in", "fact", "the", "same", "(", "up", "to", "a", "multiplicative", "constant", "math", "\\", "frac", "{", "1", "}", "{", "The", "cross", "-entropy", "loss", "is", "closely", "related", "to", "the", "Kullback", "-", "Leibler", "discrepancy", "between", "the", "empirical", "distribution", "and", "the", "predicted", "distribution", "."], "sentence-detokenized": "It is easy to verify that the logistic loss and the binary cross-entropy loss (Log loss) are in fact the same (up to a multiplicative constant math\\ frac {1} {The cross-entropy loss is closely related to the Kullback-Leibler discrepancy between the empirical distribution and the predicted distribution.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 20], [21, 25], [26, 29], [30, 38], [39, 43], [44, 47], [48, 51], [52, 58], [59, 64], [64, 72], [73, 77], [78, 79], [79, 82], [83, 87], [87, 88], [89, 92], [93, 95], [96, 100], [101, 104], [105, 109], [110, 111], [111, 113], [114, 116], [117, 118], [119, 133], [134, 142], [143, 147], [147, 148], [149, 153], [154, 155], [155, 156], [156, 157], [158, 159], [159, 162], [163, 168], [168, 176], [177, 181], [182, 184], [185, 192], [193, 200], [201, 203], [204, 207], [208, 216], [216, 217], [217, 224], [225, 236], [237, 244], [245, 248], [249, 258], [259, 271], [272, 275], [276, 279], [280, 289], [290, 302], [302, 303]]}
{"doc_key": "ai-dev-30", "ner": [[0, 2, "algorithm"], [10, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 14, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "EM", "algorithm", "is", "used", "to", "find", "(", "local", ")", "maximum", "likelihood", "parameters", "of", "a", "statistical", "model", "in", "cases", "where", "the", "equations", "can", "not", "be", "solved", "directly", "."], "sentence-detokenized": "The EM algorithm is used to find (local) maximum likelihood parameters of a statistical model in cases where the equations cannot be solved directly.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 32], [33, 34], [34, 39], [39, 40], [41, 48], [49, 59], [60, 70], [71, 73], [74, 75], [76, 87], [88, 93], [94, 96], [97, 102], [103, 108], [109, 112], [113, 122], [123, 126], [126, 129], [130, 132], [133, 139], [140, 148], [148, 149]]}
{"doc_key": "ai-dev-31", "ner": [[10, 11, "task"], [14, 20, "task"], [23, 24, "task"], [26, 29, "task"], [32, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "research", "has", "been", "fundamental", "to", "the", "development", "of", "modern", "speech", "synthesis", "techniques", ",", "reading", "machines", "for", "the", "blind", ",", "the", "study", "of", "speech", "perception", "and", "recognition", ",", "and", "the", "development", "of", "motor", "theory", "of", "speech", "perception", "."], "sentence-detokenized": "This research has been fundamental to the development of modern speech synthesis techniques, reading machines for the blind, the study of speech perception and recognition, and the development of motor theory of speech perception.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 22], [23, 34], [35, 37], [38, 41], [42, 53], [54, 56], [57, 63], [64, 70], [71, 80], [81, 91], [91, 92], [93, 100], [101, 109], [110, 113], [114, 117], [118, 123], [123, 124], [125, 128], [129, 134], [135, 137], [138, 144], [145, 155], [156, 159], [160, 171], [171, 172], [173, 176], [177, 180], [181, 192], [193, 195], [196, 201], [202, 208], [209, 211], [212, 218], [219, 229], [229, 230]]}
{"doc_key": "ai-dev-32", "ner": [[0, 1, "product"], [2, 4, "misc"], [6, 6, "misc"], [10, 12, "misc"], [15, 15, "product"], [17, 17, "product"], [19, 19, "product"], [24, 24, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 0, 1, "origin", "", false, false], [2, 4, 10, 12, "type-of", "", false, false], [2, 4, 15, 15, "related-to", "program_for", false, false], [2, 4, 17, 17, "related-to", "program_for", false, false], [2, 4, 19, 19, "related-to", "program_for", false, false], [2, 4, 24, 24, "related-to", "program_for", false, false], [6, 6, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "Arduino", "Integrated", "Development", "Environment", "(", "IDE", ")", "is", "a", "cross", "-platform", "application", "(", "for", "Windows", ",", "macOS", "and", "Linux", ")", "written", "in", "the", "Java", "programming", "language", "."], "sentence-detokenized": "The Arduino Integrated Development Environment (IDE) is a cross-platform application (for Windows, macOS and Linux) written in the Java programming language.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 57], [58, 63], [63, 72], [73, 84], [85, 86], [86, 89], [90, 97], [97, 98], [99, 104], [105, 108], [109, 114], [114, 115], [116, 123], [124, 126], [127, 130], [131, 135], [136, 147], [148, 156], [156, 157]]}
{"doc_key": "ai-dev-33", "ner": [[0, 1, "algorithm"], [13, 13, "field"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 13, 13, "opposite", "", false, false], [14, 15, 13, 13, "related-to", "works_with", false, false], [17, 18, 13, 13, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Neural", "network", "research", "has", "stalled", "since", "the", "publication", "of", "the", "machine", "learning", "research", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", "."], "sentence-detokenized": "Neural network research has stalled since the publication of the machine learning research of Marvin Minsky and Seymour Papert (1969).", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 27], [28, 35], [36, 41], [42, 45], [46, 57], [58, 60], [61, 64], [65, 72], [73, 81], [82, 90], [91, 93], [94, 100], [101, 107], [108, 111], [112, 119], [120, 126], [127, 128], [128, 132], [132, 133], [133, 134]]}
{"doc_key": "ai-dev-34", "ner": [[17, 18, "organisation"], [20, 20, "organisation"], [22, 25, "country"], [27, 30, "organisation"], [32, 33, "country"], [35, 36, "organisation"], [39, 39, "country"], [41, 41, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[27, 30, 22, 25, "general-affiliation", "", false, false], [35, 36, 32, 33, "general-affiliation", "", false, false], [41, 41, 39, 39, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Only", "a", "few", "non-Japanese", "companies", "have", "managed", "to", "survive", "in", "this", "market", ",", "the", "main", "ones", "being", "Adept", "Technology", ",", "St\u00e4ubli", ",", "the", "Swedish", "-", "Swiss", "company", "ABB", "Asea", "Brown", "Boveri", ",", "the", "German", "company", "KUKA", "Robotics", "and", "the", "Italian", "company", "Comau", "."], "sentence-detokenized": "Only a few non-Japanese companies have managed to survive in this market, the main ones being Adept Technology, St\u00e4ubli, the Swedish-Swiss company ABB Asea Brown Boveri, the German company KUKA Robotics and the Italian company Comau.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 23], [24, 33], [34, 38], [39, 46], [47, 49], [50, 57], [58, 60], [61, 65], [66, 72], [72, 73], [74, 77], [78, 82], [83, 87], [88, 93], [94, 99], [100, 110], [110, 111], [112, 119], [119, 120], [121, 124], [125, 132], [132, 133], [133, 138], [139, 146], [147, 150], [151, 155], [156, 161], [162, 168], [168, 169], [170, 173], [174, 180], [181, 188], [189, 193], [194, 202], [203, 206], [207, 210], [211, 218], [219, 226], [227, 232], [232, 233]]}
{"doc_key": "ai-dev-35", "ner": [[9, 10, "conference"], [15, 17, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 17, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Research", "activities", "include", "an", "annual", "research", "conference", ",", "the", "RuleML", "Symposium", ",", "referred", "to", "as", "RuleML", "for", "short", "."], "sentence-detokenized": "Research activities include an annual research conference, the RuleML Symposium, referred to as RuleML for short.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 30], [31, 37], [38, 46], [47, 57], [57, 58], [59, 62], [63, 69], [70, 79], [79, 80], [81, 89], [90, 92], [93, 95], [96, 102], [103, 106], [107, 112], [112, 113]]}
{"doc_key": "ai-dev-36", "ner": [[9, 9, "field"], [11, 12, "field"], [14, 14, "field"], [17, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Concepts", "are", "used", "as", "formal", "tools", "or", "models", "in", "mathematics", ",", "computer", "science", ",", "databases", ",", "and", "artificial", "intelligence", ",", "where", "they", "are", "sometimes", "called", "classes", ",", "schemas", ",", "or", "categories", "."], "sentence-detokenized": "Concepts are used as formal tools or models in mathematics, computer science, databases, and artificial intelligence, where they are sometimes called classes, schemas, or categories.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 33], [34, 36], [37, 43], [44, 46], [47, 58], [58, 59], [60, 68], [69, 76], [76, 77], [78, 87], [87, 88], [89, 92], [93, 103], [104, 116], [116, 117], [118, 123], [124, 128], [129, 132], [133, 142], [143, 149], [150, 157], [157, 158], [159, 166], [166, 167], [168, 170], [171, 181], [181, 182]]}
{"doc_key": "ai-dev-37", "ner": [[6, 8, "organisation"], [11, 14, "organisation"], [17, 17, "organisation"], [18, 24, "organisation"], [28, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "won", "awards", "from", "the", "American", "Psychological", "Association", ",", "the", "National", "Academy", "of", "Sciences", ",", "the", "Royal", "Society", ",", "the", "Society", "for", "Cognitive", "Neuroscience", ",", "and", "the", "American", "Humanist", "Association", "."], "sentence-detokenized": "He has won awards from the American Psychological Association, the National Academy of Sciences, the Royal Society, the Society for Cognitive Neuroscience, and the American Humanist Association.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 17], [18, 22], [23, 26], [27, 35], [36, 49], [50, 61], [61, 62], [63, 66], [67, 75], [76, 83], [84, 86], [87, 95], [95, 96], [97, 100], [101, 106], [107, 114], [114, 115], [116, 119], [120, 127], [128, 131], [132, 141], [142, 154], [154, 155], [156, 159], [160, 163], [164, 172], [173, 181], [182, 193], [193, 194]]}
{"doc_key": "ai-dev-38", "ner": [[1, 2, "person"], [4, 5, "person"], [7, 8, "person"], [19, 23, "person"], [25, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[25, 31, 19, 23, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starring", "Harrison", "Ford", ",", "Rutger", "Hauer", "and", "Sean", "Young", ",", "the", "film", "is", "loosely", "based", "on", "the", "novel", "by", "Philip", "K", ".", "Dick", "'s", "\"", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "?", "\"", "(", "1968", ")", "."], "sentence-detokenized": "Starring Harrison Ford, Rutger Hauer and Sean Young, the film is loosely based on the novel by Philip K. Dick's \"Do Androids Dream of Electric Sheep?\" (1968).", "token2charspan": [[0, 8], [9, 17], [18, 22], [22, 23], [24, 30], [31, 36], [37, 40], [41, 45], [46, 51], [51, 52], [53, 56], [57, 61], [62, 64], [65, 72], [73, 78], [79, 81], [82, 85], [86, 91], [92, 94], [95, 101], [102, 103], [103, 104], [105, 109], [109, 111], [112, 113], [113, 115], [116, 124], [125, 130], [131, 133], [134, 142], [143, 148], [148, 149], [149, 150], [151, 152], [152, 156], [156, 157], [157, 158]]}
{"doc_key": "ai-dev-39", "ner": [[0, 1, "task"], [3, 5, "algorithm"], [11, 12, "field"], [14, 15, "task"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 3, 5, "usage", "", false, false], [0, 1, 11, 12, "part-of", "task_part_of_field", false, false], [0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 18, 19, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Image", "segmentation", "using", "k-means", "clustering", "algorithms", "has", "long", "been", "used", "for", "pattern", "recognition", ",", "object", "detection", ",", "and", "medical", "imaging", "."], "sentence-detokenized": "Image segmentation using k-means clustering algorithms has long been used for pattern recognition, object detection, and medical imaging.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 32], [33, 43], [44, 54], [55, 58], [59, 63], [64, 68], [69, 73], [74, 77], [78, 85], [86, 97], [97, 98], [99, 105], [106, 115], [115, 116], [117, 120], [121, 128], [129, 136], [136, 137]]}
{"doc_key": "ai-dev-40", "ner": [[14, 14, "algorithm"], [17, 20, "algorithm"], [31, 31, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["General", "sampling", "from", "the", "truncated", "normal", "can", "be", "achieved", "using", "approximations", "of", "the", "normal", "CDF", "and", "the", "probit", "function", ",", "and", "there", "is", "a", "codertnorm", "(", ")", "/", "code", "function", "in", "R", "to", "generate", "samples", "from", "the", "truncated", "normal", "."], "sentence-detokenized": "General sampling from the truncated normal can be achieved using approximations of the normal CDF and the probit function, and there is a codertnorm()/code function in R to generate samples from the truncated normal.", "token2charspan": [[0, 7], [8, 16], [17, 21], [22, 25], [26, 35], [36, 42], [43, 46], [47, 49], [50, 58], [59, 64], [65, 79], [80, 82], [83, 86], [87, 93], [94, 97], [98, 101], [102, 105], [106, 112], [113, 121], [121, 122], [123, 126], [127, 132], [133, 135], [136, 137], [138, 148], [148, 149], [149, 150], [150, 151], [151, 155], [156, 164], [165, 167], [168, 169], [170, 172], [173, 181], [182, 189], [190, 194], [195, 198], [199, 208], [209, 215], [215, 216]]}
{"doc_key": "ai-dev-41", "ner": [[6, 9, "university"], [11, 11, "university"], [13, 14, "university"], [16, 17, "university"], [19, 19, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "received", "honorary", "doctorates", "from", "the", "Universities", "of", "Newcastle", ",", "Surrey", ",", "Tel", "Aviv", ",", "Simon", "Fraser", "and", "Troms\u00f8", "."], "sentence-detokenized": "He has received honorary doctorates from the Universities of Newcastle, Surrey, Tel Aviv, Simon Fraser and Troms\u00f8.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 24], [25, 35], [36, 40], [41, 44], [45, 57], [58, 60], [61, 70], [70, 71], [72, 78], [78, 79], [80, 83], [84, 88], [88, 89], [90, 95], [96, 102], [103, 106], [107, 113], [113, 114]]}
{"doc_key": "ai-dev-42", "ner": [[0, 1, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "Java", "implementation", "using", "zero", "-", "based", "array", "indices", ",", "along", "with", "a", "convenient", "method", "for", "printing", "the", "solved", "sequence", "of", "operations", ":"], "sentence-detokenized": "A Java implementation using zero-based array indices, along with a convenient method for printing the solved sequence of operations:", "token2charspan": [[0, 1], [2, 6], [7, 21], [22, 27], [28, 32], [32, 33], [33, 38], [39, 44], [45, 52], [52, 53], [54, 59], [60, 64], [65, 66], [67, 77], [78, 84], [85, 88], [89, 97], [98, 101], [102, 108], [109, 117], [118, 120], [121, 131], [131, 132]]}
{"doc_key": "ai-dev-43", "ner": [[7, 8, "metrics"], [11, 17, "metrics"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 17, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Such", "networks", "are", "typically", "trained", "in", "the", "cross", "-entropy", "(", "or", "cross", "-entropy", ")", "regime", ",", "which", "is", "a", "nonlinear", "variant", "of", "multivariate", "logistic", "regression", "."], "sentence-detokenized": "Such networks are typically trained in the cross-entropy (or cross-entropy) regime, which is a nonlinear variant of multivariate logistic regression.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 27], [28, 35], [36, 38], [39, 42], [43, 48], [48, 56], [57, 58], [58, 60], [61, 66], [66, 74], [74, 75], [76, 82], [82, 83], [84, 89], [90, 92], [93, 94], [95, 104], [105, 112], [113, 115], [116, 128], [129, 137], [138, 148], [148, 149]]}
{"doc_key": "ai-dev-44", "ner": [[0, 0, "conference"], [3, 3, "misc"], [4, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["ACL", "has", "a", "European", "Section", "(", "European", "Section", "of", "the", "Association", "for", "Computational", "Linguistics", ")"], "sentence-detokenized": "ACL has a European Section (European Section of the Association for Computational Linguistics)", "token2charspan": [[0, 3], [4, 7], [8, 9], [10, 18], [19, 26], [27, 28], [28, 36], [37, 44], [45, 47], [48, 51], [52, 63], [64, 67], [68, 81], [82, 93], [93, 94]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 8, "researcher"], [27, 27, "misc"], [29, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 27, 27, "role", "", false, false], [6, 8, 27, 27, "role", "", false, false], [27, 27, 29, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "professors", ",", "Hal", "Abelson", "and", "Gerald", "J.", "Sussman", ",", "choose", "to", "remain", "neutral", "-", "over", "the", "next", "30", "years", "their", "group", "is", "variously", "referred", "to", "as", "Switzerland", "and", "Project", "MAC", "."], "sentence-detokenized": "Two professors, Hal Abelson and Gerald J. Sussman, choose to remain neutral - over the next 30 years their group is variously referred to as Switzerland and Project MAC.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 41], [42, 49], [49, 50], [51, 57], [58, 60], [61, 67], [68, 75], [76, 77], [78, 82], [83, 86], [87, 91], [92, 94], [95, 100], [101, 106], [107, 112], [113, 115], [116, 125], [126, 134], [135, 137], [138, 140], [141, 152], [153, 156], [157, 164], [165, 168], [168, 169]]}
{"doc_key": "ai-dev-46", "ner": [[2, 2, "misc"], [4, 4, "researcher"], [8, 10, "university"], [19, 25, "organisation"], [20, 23, "organisation"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 4, 4, "temporal", "", false, false], [4, 4, 19, 25, "physical", "", false, false], [4, 4, 19, 25, "role", "", false, false], [4, 4, 20, 23, "role", "", false, false], [20, 23, 8, 10, "part-of", "", false, false], [29, 30, 20, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["After", "his", "Ph.D.", ",", "Gahramani", "moved", "to", "the", "University", "of", "Toronto", "in", "1995", "as", "a", "postdoctoral", "fellow", "in", "the", "ITRC", "'s", "Artificial", "Intelligence", "Lab", ",", "where", "he", "worked", "with", "Jeffrey", "Hinton", "."], "sentence-detokenized": "After his Ph.D., Gahramani moved to the University of Toronto in 1995 as a postdoctoral fellow in the ITRC's Artificial Intelligence Lab, where he worked with Jeffrey Hinton.", "token2charspan": [[0, 5], [6, 9], [10, 15], [15, 16], [17, 26], [27, 32], [33, 35], [36, 39], [40, 50], [51, 53], [54, 61], [62, 64], [65, 69], [70, 72], [73, 74], [75, 87], [88, 94], [95, 97], [98, 101], [102, 106], [106, 108], [109, 119], [120, 132], [133, 136], [136, 137], [138, 143], [144, 146], [147, 153], [154, 158], [159, 166], [167, 173], [173, 174]]}
{"doc_key": "ai-dev-47", "ner": [[23, 24, "metrics"], [27, 27, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[27, 27, 23, 24, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Subsequent", "work", "focused", "on", "solving", "these", "problems", ",", "but", "it", "was", "only", "after", "the", "advent", "of", "the", "modern", "computer", "and", "the", "popularization", "of", "maximum", "likelihood", "estimation", "(", "MLE", ")", "techniques", "that", "research", "really", "took", "off", "."], "sentence-detokenized": "Subsequent work focused on solving these problems, but it was only after the advent of the modern computer and the popularization of maximum likelihood estimation (MLE) techniques that research really took off.", "token2charspan": [[0, 10], [11, 15], [16, 23], [24, 26], [27, 34], [35, 40], [41, 49], [49, 50], [51, 54], [55, 57], [58, 61], [62, 66], [67, 72], [73, 76], [77, 83], [84, 86], [87, 90], [91, 97], [98, 106], [107, 110], [111, 114], [115, 129], [130, 132], [133, 140], [141, 151], [152, 162], [163, 164], [164, 167], [167, 168], [169, 179], [180, 184], [185, 193], [194, 200], [201, 205], [206, 209], [209, 210]]}
{"doc_key": "ai-dev-48", "ner": [[5, 7, "person"], [9, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "series", "is", "produced", "by", "David", "Fincher", "and", "starring", "Kevin", "Spacey", "."], "sentence-detokenized": "The series is produced by David Fincher and starring Kevin Spacey.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 22], [23, 25], [26, 31], [32, 39], [40, 43], [44, 52], [53, 58], [59, 65], [65, 66]]}
{"doc_key": "ai-dev-49", "ner": [[17, 20, "metrics"], [23, 24, "algorithm"], [31, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 31, 33, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Due", "to", "limitations", "in", "computational", "power", ",", "current", "in", "silico", "methods", "usually", "have", "to", "replace", "speed", "with", "accuracy", ";", "for", "example", ",", "fast", "protein", "binding", "methods", "are", "used", "instead", "of", "costly", "free", "energy", "calculations", "."], "sentence-detokenized": "Due to limitations in computational power, current in silico methods usually have to replace speed with accuracy; for example, fast protein binding methods are used instead of costly free energy calculations.", "token2charspan": [[0, 3], [4, 6], [7, 18], [19, 21], [22, 35], [36, 41], [41, 42], [43, 50], [51, 53], [54, 60], [61, 68], [69, 76], [77, 81], [82, 84], [85, 92], [93, 98], [99, 103], [104, 112], [112, 113], [114, 117], [118, 125], [125, 126], [127, 131], [132, 139], [140, 147], [148, 155], [156, 159], [160, 164], [165, 172], [173, 175], [176, 182], [183, 187], [188, 194], [195, 207], [207, 208]]}
{"doc_key": "ai-dev-50", "ner": [[7, 7, "country"], [9, 9, "country"], [11, 11, "country"], [13, 13, "country"], [15, 15, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "over", "30", "sites", "in", "the", "USA", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "sentence-detokenized": "There are over 30 sites in the USA, Canada, Mexico, Brazil and Argentina.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 23], [24, 26], [27, 30], [31, 34], [34, 35], [36, 42], [42, 43], [44, 50], [50, 51], [52, 58], [59, 62], [63, 72], [72, 73]]}
{"doc_key": "ai-dev-51", "ner": [[4, 9, "field"], [10, 12, "product"], [14, 16, "algorithm"], [19, 20, "task"], [22, 23, "task"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 12, 4, 9, "part-of", "", false, false], [10, 12, 14, 16, "usage", "", false, false], [19, 20, 4, 9, "part-of", "task_part_of_field", false, false], [19, 20, 30, 30, "related-to", "performs", false, false], [22, 23, 4, 9, "part-of", "task_part_of_field", false, false], [22, 23, 30, 30, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Example", "of", "a", "typical", "computer", "vision", "computational", "pipeline", "for", "a", "face", "recognition", "system", "using", "k", "-", "NN", ",", "including", "feature", "extraction", "and", "dimensionality", "reduction", "preprocessing", "steps", "(", "typically", "implemented", "with", "OpenCV", ")", ":"], "sentence-detokenized": "Example of a typical computer vision computational pipeline for a face recognition system using k -NN, including feature extraction and dimensionality reduction preprocessing steps (typically implemented with OpenCV):", "token2charspan": [[0, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 36], [37, 50], [51, 59], [60, 63], [64, 65], [66, 70], [71, 82], [83, 89], [90, 95], [96, 97], [98, 99], [99, 101], [101, 102], [103, 112], [113, 120], [121, 131], [132, 135], [136, 150], [151, 160], [161, 174], [175, 180], [181, 182], [182, 191], [192, 203], [204, 208], [209, 215], [215, 216], [216, 217]]}
{"doc_key": "ai-dev-52", "ner": [[7, 9, "algorithm"], [12, 12, "misc"], [14, 15, "misc"], [17, 19, "misc"], [23, 23, "programlang"], [25, 25, "product"], [29, 30, "algorithm"], [32, 33, "misc"], [35, 35, "misc"], [37, 37, "misc"], [39, 39, "misc"], [45, 45, "misc"], [47, 48, "misc"], [50, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "a", "rich", "feature", "set", ",", "constraint", "logic", "programming", "libraries", ",", "multithreading", ",", "unit", "testing", ",", "graphical", "user", "interface", ",", "interaction", "with", "Java", ",", "ODBC", "and", "others", ",", "literate", "programming", ",", "web", "server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "developer", "tools", "(", "including", "IDE", "with", "graphical", "debugger", "and", "graphical", "profiler", ")", "and", "extensive", "documentation", "."], "sentence-detokenized": "It has a rich feature set, constraint logic programming libraries, multithreading, unit testing, graphical user interface, interaction with Java, ODBC and others, literate programming, web server, SGML, RDF, RDFS, developer tools (including IDE with graphical debugger and graphical profiler) and extensive documentation.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 13], [14, 21], [22, 25], [25, 26], [27, 37], [38, 43], [44, 55], [56, 65], [65, 66], [67, 81], [81, 82], [83, 87], [88, 95], [95, 96], [97, 106], [107, 111], [112, 121], [121, 122], [123, 134], [135, 139], [140, 144], [144, 145], [146, 150], [151, 154], [155, 161], [161, 162], [163, 171], [172, 183], [183, 184], [185, 188], [189, 195], [195, 196], [197, 201], [201, 202], [203, 206], [206, 207], [208, 212], [212, 213], [214, 223], [224, 229], [230, 231], [231, 240], [241, 244], [245, 249], [250, 259], [260, 268], [269, 272], [273, 282], [283, 291], [291, 292], [293, 296], [297, 306], [307, 320], [320, 321]]}
{"doc_key": "ai-dev-53", "ner": [[1, 2, "field"], [4, 5, "field"], [10, 12, "misc"], [14, 16, "misc"], [19, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 1, 2, "part-of", "", true, false], [10, 12, 4, 5, "part-of", "", false, false], [10, 12, 19, 21, "type-of", "", false, false], [14, 16, 1, 2, "part-of", "", false, false], [14, 16, 4, 5, "part-of", "", false, false], [14, 16, 19, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "computer", "vision", "and", "image", "processing", ",", "the", "notion", "of", "scale", "space", "representation", "and", "Gaussian", "derivative", "operators", "is", "a", "canonical", "multiscale", "representation", "."], "sentence-detokenized": "In computer vision and image processing, the notion of scale space representation and Gaussian derivative operators is a canonical multiscale representation.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 22], [23, 28], [29, 39], [39, 40], [41, 44], [45, 51], [52, 54], [55, 60], [61, 66], [67, 81], [82, 85], [86, 94], [95, 105], [106, 115], [116, 118], [119, 120], [121, 130], [131, 141], [142, 156], [156, 157]]}
{"doc_key": "ai-dev-54", "ner": [[6, 13, "organisation"], [20, 24, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 13, 20, 24, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "also", "president", "of", "the", "Foundation", "for", "Neural", "Information", "Processing", "Systems", ",", "a", "non-profit", "organization", "that", "runs", "the", "annual", "Neural", "Information", "Processing", "Systems", "Conference", "."], "sentence-detokenized": "He is also president of the Foundation for Neural Information Processing Systems, a non-profit organization that runs the annual Neural Information Processing Systems Conference.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 20], [21, 23], [24, 27], [28, 38], [39, 42], [43, 49], [50, 61], [62, 72], [73, 80], [80, 81], [82, 83], [84, 94], [95, 107], [108, 112], [113, 117], [118, 121], [122, 128], [129, 135], [136, 147], [148, 158], [159, 166], [167, 177], [177, 178]]}
{"doc_key": "ai-dev-55", "ner": [[1, 12, "task"], [6, 16, "metrics"], [13, 14, "misc"], [24, 24, "task"], [18, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 12, 6, 16, "usage", "", false, false], [6, 16, 13, 14, "type-of", "", false, false], [24, 24, 18, 24, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["For", "regression", "analysis", "problems", ",", "the", "squared", "error", "can", "be", "used", "as", "the", "loss", "function", ",", "and", "the", "cross", "-entropy", "can", "be", "used", "for", "classification", "."], "sentence-detokenized": "For regression analysis problems, the squared error can be used as the loss function, and the cross-entropy can be used for classification.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 32], [32, 33], [34, 37], [38, 45], [46, 51], [52, 55], [56, 58], [59, 63], [64, 66], [67, 70], [71, 75], [76, 84], [84, 85], [86, 89], [90, 93], [94, 99], [99, 107], [108, 111], [112, 114], [115, 119], [120, 123], [124, 138], [138, 139]]}
{"doc_key": "ai-dev-56", "ner": [[0, 0, "researcher"], [17, 20, "conference"], [24, 29, "conference"], [36, 37, "university"], [41, 43, "field"], [51, 55, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 17, 20, "role", "", false, false], [0, 0, 36, 37, "physical", "", false, false], [0, 0, 36, 37, "role", "", false, false], [0, 0, 51, 55, "role", "", false, false], [17, 20, 24, 29, "named", "same", false, false], [36, 37, 41, 43, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Lafferty", "has", "held", "many", "prestigious", "positions", ",", "including", "1", ")", "program", "co-chair", "and", "general", "co-chair", "of", "the", "Neural", "Information", "Processing", "Systems", "Foundation", "conferences", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", ")", ";", "2", ")", "co-director", "of", "CMU", "'s", "new", "doctoral", "program", "in", "machine", "learning", ";", "3", ")", "associate", "editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research"], "sentence-detokenized": "Lafferty has held many prestigious positions, including 1) program co-chair and general co-chair of the Neural Information Processing Systems Foundation conferences (Conference on Neural Information Processing Systems); 2) co-director of CMU's new doctoral program in machine learning; 3) associate editor of the Journal of Machine Learning Research", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 34], [35, 44], [44, 45], [46, 55], [56, 57], [57, 58], [59, 66], [67, 75], [76, 79], [80, 87], [88, 96], [97, 99], [100, 103], [104, 110], [111, 122], [123, 133], [134, 141], [142, 152], [153, 164], [165, 166], [166, 176], [177, 179], [180, 186], [187, 198], [199, 209], [210, 217], [217, 218], [218, 219], [220, 221], [221, 222], [223, 234], [235, 237], [238, 241], [241, 243], [244, 247], [248, 256], [257, 264], [265, 267], [268, 275], [276, 284], [284, 285], [286, 287], [287, 288], [289, 298], [299, 305], [306, 308], [309, 312], [313, 320], [321, 323], [324, 331], [332, 340], [341, 349]]}
{"doc_key": "ai-dev-57", "ner": [[0, 1, "misc"], [5, 5, "algorithm"], [7, 9, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 1, "type-of", "", false, false], [7, 9, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Convex", "algorithms", ",", "such", "as", "AdaBoost", "and", "LogitBoost", ",", "can", "be", "plagued", "by", "random", "noise", "so", "that", "they", "can", "not", "learn", "basic", "and", "learnable", "combinations", "of", "weak", "hypotheses", "."], "sentence-detokenized": "Convex algorithms, such as AdaBoost and LogitBoost, can be plagued by random noise so that they cannot learn basic and learnable combinations of weak hypotheses.", "token2charspan": [[0, 6], [7, 17], [17, 18], [19, 23], [24, 26], [27, 35], [36, 39], [40, 50], [50, 51], [52, 55], [56, 58], [59, 66], [67, 69], [70, 76], [77, 82], [83, 85], [86, 90], [91, 95], [96, 99], [99, 102], [103, 108], [109, 114], [115, 118], [119, 128], [129, 141], [142, 144], [145, 149], [150, 160], [160, 161]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [3, 8, "product"], [10, 12, "algorithm"], [18, 19, "algorithm"], [22, 27, "task"], [29, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 8, "type-of", "", false, false], [0, 0, 10, 12, "usage", "", false, false], [0, 0, 18, 19, "usage", "", false, false], [18, 19, 22, 27, "related-to", "used_for", true, false], [18, 19, 29, 31, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "is", "a", "shallow", "transfer", "machine", "translation", "system", "that", "uses", "finite", "state", "transducers", "for", "all", "lexical", "transformations", "and", "hidden", "Markov", "models", "for", "part", "-", "of", "-", "speech", "tagging", "or", "word", "category", "disambiguation", "."], "sentence-detokenized": "Apertium is a shallow transfer machine translation system that uses finite state transducers for all lexical transformations and hidden Markov models for part-of-speech tagging or word category disambiguation.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 21], [22, 30], [31, 38], [39, 50], [51, 57], [58, 62], [63, 67], [68, 74], [75, 80], [81, 92], [93, 96], [97, 100], [101, 108], [109, 124], [125, 128], [129, 135], [136, 142], [143, 149], [150, 153], [154, 158], [158, 159], [159, 161], [161, 162], [162, 168], [169, 176], [177, 179], [180, 184], [185, 193], [194, 208], [208, 209]]}
{"doc_key": "ai-dev-59", "ner": [[0, 3, "misc"], [13, 16, "metrics"], [31, 34, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 13, 16, "related-to", "", true, false], [13, 16, 31, 34, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "natural", "gradient", "of", "mathE", "f", "(", "x", ")", "/", "math", "corresponding", "to", "Fisher", "'s", "information", "metric", "(", "an", "information", "measure", "of", "the", "distance", "between", "probability", "distributions", "and", "the", "curvature", "of", "relative", "entropy", ")", "now", "reads"], "sentence-detokenized": "The natural gradient of mathE f (x) / math corresponding to Fisher's information metric (an information measure of the distance between probability distributions and the curvature of relative entropy) now reads", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 23], [24, 29], [30, 31], [32, 33], [33, 34], [34, 35], [36, 37], [38, 42], [43, 56], [57, 59], [60, 66], [66, 68], [69, 80], [81, 87], [88, 89], [89, 91], [92, 103], [104, 111], [112, 114], [115, 118], [119, 127], [128, 135], [136, 147], [148, 161], [162, 165], [166, 169], [170, 179], [180, 182], [183, 191], [192, 199], [199, 200], [201, 204], [205, 210]]}
{"doc_key": "ai-dev-60", "ner": [[0, 5, "programlang"], [6, 9, "product"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 0, 5, "origin", "", false, false], [11, 11, 0, 5, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "S", "programming", "language", "inspired", "the", "S", "'", "-", "PLUS", "and", "R", "systems", "."], "sentence-detokenized": "The S programming language inspired the S '-PLUS and R systems.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 26], [27, 35], [36, 39], [40, 41], [42, 43], [43, 44], [44, 48], [49, 52], [53, 54], [55, 62], [62, 63]]}
{"doc_key": "ai-dev-61", "ner": [[5, 5, "product"], [10, 10, "product"], [12, 14, "product"], [18, 20, "researcher"], [22, 23, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 10, 10, "named", "same", false, false], [12, 14, 10, 10, "origin", "derived_from", false, false], [12, 14, 18, 20, "origin", "", false, false], [12, 14, 22, 23, "origin", "", false, false], [12, 14, 26, 27, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "most", "influential", "implementation", "of", "Planner", "was", "a", "subset", "of", "Planner", "called", "Micro", "-", "Planner", ",", "implemented", "by", "Gerald", "J.", "Sussman", ",", "Eugene", "Charniak", ",", "and", "Terry", "Winograd", "."], "sentence-detokenized": "The most influential implementation of Planner was a subset of Planner called Micro-Planner, implemented by Gerald J. Sussman, Eugene Charniak, and Terry Winograd.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 35], [36, 38], [39, 46], [47, 50], [51, 52], [53, 59], [60, 62], [63, 70], [71, 77], [78, 83], [83, 84], [84, 91], [91, 92], [93, 104], [105, 107], [108, 114], [115, 117], [118, 125], [125, 126], [127, 133], [134, 142], [142, 143], [144, 147], [148, 153], [154, 162], [162, 163]]}
{"doc_key": "ai-dev-62", "ner": [[3, 6, "country"], [8, 10, "researcher"], [20, 20, "misc"], [21, 28, "university"], [35, 38, "misc"], [43, 44, "misc"], [51, 53, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[8, 10, 3, 6, "general-affiliation", "from_country", false, false], [21, 28, 20, 20, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1779", ",", "the", "German", "-", "Danish", "scientist", "Christian", "Gottlieb", "Kratzenstein", "won", "first", "prize", "in", "a", "competition", "announced", "by", "the", "Russian", "Imperial", "Academy", "of", "Sciences", "and", "Arts", "for", "his", "construction", "of", "models", "of", "the", "human", "vocal", "tract", "that", "could", "reproduce", "the", "five", "long", "vowel", "sounds", "(", "in", "the", "notation", "of", "the", "International", "Phonetic", "Alphabet", ":"], "sentence-detokenized": "In 1779, the German-Danish scientist Christian Gottlieb Kratzenstein won first prize in a competition announced by the Russian Imperial Academy of Sciences and Arts for his construction of models of the human vocal tract that could reproduce the five long vowel sounds (in the notation of the International Phonetic Alphabet:", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [19, 20], [20, 26], [27, 36], [37, 46], [47, 55], [56, 68], [69, 72], [73, 78], [79, 84], [85, 87], [88, 89], [90, 101], [102, 111], [112, 114], [115, 118], [119, 126], [127, 135], [136, 143], [144, 146], [147, 155], [156, 159], [160, 164], [165, 168], [169, 172], [173, 185], [186, 188], [189, 195], [196, 198], [199, 202], [203, 208], [209, 214], [215, 220], [221, 225], [226, 231], [232, 241], [242, 245], [246, 250], [251, 255], [256, 261], [262, 268], [269, 270], [270, 272], [273, 276], [277, 285], [286, 288], [289, 292], [293, 306], [307, 315], [316, 324], [324, 325]]}
{"doc_key": "ai-dev-63", "ner": [[3, 4, "product"], [6, 7, "misc"], [10, 15, "misc"], [32, 34, "misc"], [59, 60, "task"], [65, 66, "product"], [68, 68, "product"], [72, 75, "task"], [74, 76, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 4, 65, 66, "related-to", "supports_program", false, false], [3, 4, 68, 68, "related-to", "supports_program", false, false], [6, 7, 3, 4, "part-of", "", false, false], [10, 15, 3, 4, "part-of", "", false, false], [32, 34, 3, 4, "part-of", "", false, false], [59, 60, 3, 4, "part-of", "", false, false], [72, 75, 3, 4, "part-of", "", false, false], [74, 76, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["New", "features", "in", "Office", "XP", "include", "smart", "tags", ",", "a", "selection", "-", "based", "search", "feature", "that", "recognizes", "different", "types", "of", "text", "in", "a", "document", "so", "users", "can", "perform", "additional", "actions", ";", "a", "taskbar", "interface", "that", "brings", "together", "popular", "commands", "from", "the", "menu", "bar", "on", "the", "right", "side", "of", "the", "screen", "to", "make", "them", "easier", "to", "access", "quickly", ";", "new", "document", "collaboration", "capabilities", ",", "support", "for", "MSN", "Groups", "and", "SharePoint", ";", "and", "integrated", "handwriting", "and", "speech", "recognition", "capabilities", "."], "sentence-detokenized": "New features in Office XP include smart tags, a selection-based search feature that recognizes different types of text in a document so users can perform additional actions; a taskbar interface that brings together popular commands from the menu bar on the right side of the screen to make them easier to access quickly; new document collaboration capabilities, support for MSN Groups and SharePoint; and integrated handwriting and speech recognition capabilities.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 25], [26, 33], [34, 39], [40, 44], [44, 45], [46, 47], [48, 57], [57, 58], [58, 63], [64, 70], [71, 78], [79, 83], [84, 94], [95, 104], [105, 110], [111, 113], [114, 118], [119, 121], [122, 123], [124, 132], [133, 135], [136, 141], [142, 145], [146, 153], [154, 164], [165, 172], [172, 173], [174, 175], [176, 183], [184, 193], [194, 198], [199, 205], [206, 214], [215, 222], [223, 231], [232, 236], [237, 240], [241, 245], [246, 249], [250, 252], [253, 256], [257, 262], [263, 267], [268, 270], [271, 274], [275, 281], [282, 284], [285, 289], [290, 294], [295, 301], [302, 304], [305, 311], [312, 319], [319, 320], [321, 324], [325, 333], [334, 347], [348, 360], [360, 361], [362, 369], [370, 373], [374, 377], [378, 384], [385, 388], [389, 399], [399, 400], [401, 404], [405, 415], [416, 427], [428, 431], [432, 438], [439, 450], [451, 463], [463, 464]]}
{"doc_key": "ai-dev-64", "ner": [[11, 12, "algorithm"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 15, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "many", "applications", ",", "the", "units", "of", "these", "networks", "implement", "a", "sigmoid", "function", "as", "an", "activation", "function", "."], "sentence-detokenized": "In many applications, the units of these networks implement a sigmoid function as an activation function.", "token2charspan": [[0, 2], [3, 7], [8, 20], [20, 21], [22, 25], [26, 31], [32, 34], [35, 40], [41, 49], [50, 59], [60, 61], [62, 69], [70, 78], [79, 81], [82, 84], [85, 95], [96, 104], [104, 105]]}
{"doc_key": "ai-dev-65", "ner": [[3, 3, "researcher"], [12, 25, "organisation"], [29, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 12, 25, "role", "", false, false], [3, 3, 29, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2001", ",", "Meller", "was", "elected", "a", "foreign", "honorary", "member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "and", "in", "2003", "he", "was", "elected", "a", "fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In 2001, Meller was elected a foreign honorary member of the American Academy of Arts and Sciences, and in 2003 he was elected a fellow of the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 27], [28, 29], [30, 37], [38, 46], [47, 53], [54, 56], [57, 60], [61, 69], [70, 77], [78, 80], [81, 85], [86, 89], [90, 98], [98, 99], [100, 103], [104, 106], [107, 111], [112, 114], [115, 118], [119, 126], [127, 128], [129, 135], [136, 138], [139, 142], [143, 151], [152, 163], [164, 167], [168, 171], [172, 183], [184, 186], [187, 194], [194, 195]]}
{"doc_key": "ai-dev-66", "ner": [[4, 6, "task"], [10, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 10, 11, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Extending", "this", "concept", "to", "non", "-binary", "classifications", "leads", "to", "the", "confusion", "matrix", "."], "sentence-detokenized": "Extending this concept to non-binary classifications leads to the confusion matrix.", "token2charspan": [[0, 9], [10, 14], [15, 22], [23, 25], [26, 29], [29, 36], [37, 52], [53, 58], [59, 61], [62, 65], [66, 75], [76, 82], [82, 83]]}
{"doc_key": "ai-dev-67", "ner": [[13, 14, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "updated", "estimate", "of", "the", "measurement", "noise", "variance", "can", "be", "obtained", "from", "the", "maximum", "likelihood", "calculation"], "sentence-detokenized": "The updated estimate of the measurement noise variance can be obtained from the maximum likelihood calculation", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 23], [24, 27], [28, 39], [40, 45], [46, 54], [55, 58], [59, 61], [62, 70], [71, 75], [76, 79], [80, 87], [88, 98], [99, 110]]}
{"doc_key": "ai-dev-68", "ner": [[1, 2, "field"], [4, 5, "algorithm"], [8, 8, "field"], [9, 11, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 8, 8, "usage", "", true, false], [4, 5, 9, 11, "related-to", "", true, false], [8, 8, 1, 2, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "machine", "learning", ",", "a", "perceptron", "is", "a", "supervised", "binary", "classification", "learning", "algorithm", "."], "sentence-detokenized": "In machine learning, a perceptron is a supervised binary classification learning algorithm.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 22], [23, 33], [34, 36], [37, 38], [39, 49], [50, 56], [57, 71], [72, 80], [81, 90], [90, 91]]}
{"doc_key": "ai-dev-69", "ner": [[5, 6, "field"], [8, 8, "field"], [13, 18, "conference"], [21, 25, "conference"], [28, 34, "conference"], [37, 41, "conference"], [45, 49, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 18, 5, 6, "topic", "", false, false], [13, 18, 8, 8, "topic", "", false, false], [21, 25, 5, 6, "topic", "", false, false], [21, 25, 8, 8, "topic", "", false, false], [28, 34, 5, 6, "topic", "", false, false], [28, 34, 8, 8, "topic", "", false, false], [37, 41, 5, 6, "topic", "", false, false], [37, 41, 8, 8, "topic", "", false, false], [45, 49, 5, 6, "topic", "", false, false], [45, 49, 8, 8, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["She", "has", "also", "chaired", "several", "machine", "learning", "and", "vision", "conferences", ",", "including", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "the", "International", "Conference", "on", "Learner", "Representations", ",", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "the", "International", "Conference", "on", "Computer", "Vision", ",", "and", "the", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "She has also chaired several machine learning and vision conferences, including the Conference on Neural Information Processing Systems, the International Conference on Learner Representations, the Conference on Computer Vision and Pattern Recognition, the International Conference on Computer Vision, and the European Conference on Computer Vision.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 20], [21, 28], [29, 36], [37, 45], [46, 49], [50, 56], [57, 68], [68, 69], [70, 79], [80, 83], [84, 94], [95, 97], [98, 104], [105, 116], [117, 127], [128, 135], [135, 136], [137, 140], [141, 154], [155, 165], [166, 168], [169, 176], [177, 192], [192, 193], [194, 197], [198, 208], [209, 211], [212, 220], [221, 227], [228, 231], [232, 239], [240, 251], [251, 252], [253, 256], [257, 270], [271, 281], [282, 284], [285, 293], [294, 300], [300, 301], [302, 305], [306, 309], [310, 318], [319, 329], [330, 332], [333, 341], [342, 348], [348, 349]]}
{"doc_key": "ai-dev-70", "ner": [[0, 5, "algorithm"], [7, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 10, 0, 5, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "compression", "algorithm", "is", "also", "used", "for", "face", "recognition", "system", "in", "video", "sequence", "."], "sentence-detokenized": "The compression algorithm is also used for face recognition system in video sequence.", "token2charspan": [[0, 3], [4, 15], [16, 25], [26, 28], [29, 33], [34, 38], [39, 42], [43, 47], [48, 59], [60, 66], [67, 69], [70, 75], [76, 84], [84, 85]]}
{"doc_key": "ai-dev-71", "ner": [[0, 2, "task"], [7, 11, "organisation"], [21, 21, "conference"], [26, 34, "academicjournal"], [35, 35, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 21, 0, 2, "topic", "", false, false], [21, 21, 7, 11, "origin", "", false, false], [26, 34, 0, 2, "topic", "", false, false], [26, 34, 7, 11, "origin", "", true, false], [35, 35, 26, 34, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Dissemination", "of", "information", "is", "also", "part", "of", "ELRA", "'s", "mission", ",", "which", "is", "carried", "out", "both", "through", "the", "organisation", "of", "the", "LREC", "conference", "and", "through", "the", "publication", "of", "the", "Language", "Resources", "and", "Evaluation", "Journal", "by", "Springer", "."], "sentence-detokenized": "Dissemination of information is also part of ELRA's mission, which is carried out both through the organisation of the LREC conference and through the publication of the Language Resources and Evaluation Journal by Springer.", "token2charspan": [[0, 13], [14, 16], [17, 28], [29, 31], [32, 36], [37, 41], [42, 44], [45, 49], [49, 51], [52, 59], [59, 60], [61, 66], [67, 69], [70, 77], [78, 81], [82, 86], [87, 94], [95, 98], [99, 111], [112, 114], [115, 118], [119, 123], [124, 134], [135, 138], [139, 146], [147, 150], [151, 162], [163, 165], [166, 169], [170, 178], [179, 188], [189, 192], [193, 203], [204, 211], [212, 214], [215, 223], [223, 224]]}
{"doc_key": "ai-dev-72", "ner": [[1, 9, "field"], [11, 12, "field"], [15, 17, "field"], [19, 20, "field"], [56, 59, "field"], [62, 63, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 9, 56, 59, "named", "", false, false], [15, 17, 1, 9, "named", "", false, false], [62, 63, 11, 12, "part-of", "", true, false], [62, 63, 15, 17, "part-of", "", true, false], [62, 63, 56, 59, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "linear", "time", "-", "invariant", "(", "LTI", ")", "systems", "theory", ",", "control", "theory", ",", "and", "digital", "signal", "processing", "or", "signal", "processing", ",", "the", "relationship", "between", "the", "input", "signal", ",", "math", "\\", "displaystyle", "x", "(", "t", ")", "/", "math", ",", "and", "the", "output", "signal", ",", "math", "\\", "displaystyle", "y", "(", "t", ")", "/", "math", ",", "of", "an", "LTI", "system", "is", "governed", "by", "a", "convolution", "operation", ":"], "sentence-detokenized": "In linear time-invariant (LTI) systems theory, control theory, and digital signal processing or signal processing, the relationship between the input signal, math\\ displaystyle x(t)/math, and the output signal, math\\ displaystyle y(t)/math, of an LTI system is governed by a convolution operation:", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [15, 24], [25, 26], [26, 29], [29, 30], [31, 38], [39, 45], [45, 46], [47, 54], [55, 61], [61, 62], [63, 66], [67, 74], [75, 81], [82, 92], [93, 95], [96, 102], [103, 113], [113, 114], [115, 118], [119, 131], [132, 139], [140, 143], [144, 149], [150, 156], [156, 157], [158, 162], [162, 163], [164, 176], [177, 178], [178, 179], [179, 180], [180, 181], [181, 182], [182, 186], [186, 187], [188, 191], [192, 195], [196, 202], [203, 209], [209, 210], [211, 215], [215, 216], [217, 229], [230, 231], [231, 232], [232, 233], [233, 234], [234, 235], [235, 239], [239, 240], [241, 243], [244, 246], [247, 250], [251, 257], [258, 260], [261, 269], [270, 272], [273, 274], [275, 286], [287, 296], [296, 297]]}
{"doc_key": "ai-dev-73", "ner": [[16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 31, "field"], [33, 34, "product"], [36, 37, "field"], [39, 39, "field"], [42, 43, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Because", "of", "its", "comprehensiveness", ",", "this", "area", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimization", ",", "multiagent", "systems", ",", "swarm", "intelligence", ",", "statistics", ",", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Because of its comprehensiveness, this area is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimization, multiagent systems, swarm intelligence, statistics, and genetic algorithms.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 32], [32, 33], [34, 38], [39, 43], [44, 46], [47, 54], [55, 57], [58, 62], [63, 68], [69, 80], [80, 81], [82, 86], [87, 89], [90, 94], [95, 101], [101, 102], [103, 110], [111, 117], [117, 118], [119, 129], [130, 138], [138, 139], [140, 151], [152, 158], [158, 159], [160, 170], [170, 171], [171, 176], [177, 189], [189, 190], [191, 201], [202, 209], [209, 210], [211, 216], [217, 229], [229, 230], [231, 241], [241, 242], [243, 246], [247, 254], [255, 265], [265, 266]]}
{"doc_key": "ai-dev-74", "ner": [[0, 2, "algorithm"], [15, 16, "field"], [22, 24, "algorithm"], [26, 27, "algorithm"], [33, 34, "algorithm"], [38, 38, "algorithm"], [39, 42, "researcher"], [44, 45, "researcher"], [47, 49, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[15, 16, 0, 2, "usage", "", true, false], [22, 24, 15, 16, "part-of", "", true, false], [26, 27, 15, 16, "part-of", "", true, false], [33, 34, 15, 16, "part-of", "", true, false], [38, 38, 15, 16, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Stochastic", "gradient", "descent", "is", "a", "popular", "algorithm", "for", "training", "a", "wide", "range", "of", "models", "in", "machine", "learning", ",", "including", "(", "linear", ")", "support", "vector", "machines", ",", "logistic", "regression", "(", "see", ",", "e.g.", ",", "Vowpal", "Wabbit", ")", ",", "and", "graphical", "models", "Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastic gradient descent is a popular algorithm for training a wide range of models in machine learning, including (linear) support vector machines, logistic regression (see, e.g., Vowpal Wabbit), and graphical models Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 30], [31, 32], [33, 40], [41, 50], [51, 54], [55, 63], [64, 65], [66, 70], [71, 76], [77, 79], [80, 86], [87, 89], [90, 97], [98, 106], [106, 107], [108, 117], [118, 119], [119, 125], [125, 126], [127, 134], [135, 141], [142, 150], [150, 151], [152, 160], [161, 171], [172, 173], [173, 176], [176, 177], [178, 182], [182, 183], [184, 190], [191, 197], [197, 198], [198, 199], [200, 203], [204, 213], [214, 220], [221, 226], [227, 231], [232, 238], [238, 239], [240, 244], [245, 252], [252, 253], [254, 265], [266, 268], [269, 276], [277, 278], [278, 282], [282, 283], [283, 284]]}
{"doc_key": "ai-dev-75", "ner": [[8, 8, "organisation"], [12, 13, "product"], [21, 21, "country"], [23, 26, "university"], [28, 28, "location"], [30, 32, "university"], [34, 34, "location"], [36, 37, "university"], [39, 39, "location"], [41, 43, "university"], [45, 45, "location"], [47, 48, "university"], [50, 50, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 23, 26, "role", "donates_to", false, false], [8, 8, 30, 32, "role", "donates_to", false, false], [8, 8, 36, 37, "role", "donates_to", false, false], [8, 8, 41, 43, "role", "donates_to", false, false], [8, 8, 47, 48, "role", "donates_to", false, false], [12, 13, 8, 8, "origin", "donates", true, false], [23, 26, 28, 28, "physical", "", false, false], [28, 28, 21, 21, "physical", "", false, false], [30, 32, 34, 34, "physical", "", false, false], [34, 34, 21, 21, "physical", "", false, false], [36, 37, 39, 39, "physical", "", false, false], [39, 39, 21, 21, "physical", "", false, false], [41, 43, 45, 45, "physical", "", false, false], [45, 45, 21, 21, "physical", "", false, false], [47, 48, 50, 50, "physical", "", false, false], [50, 50, 21, 21, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["In", "August", "2011", ",", "it", "was", "announced", "that", "Hitachi", "would", "donate", "an", "electron", "microscope", "to", "each", "of", "the", "five", "universities", "in", "Indonesia", "(", "University", "of", "North", "Sumatra", "in", "Medan", ",", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Padjadjaran", "University", "in", "Bandung", ",", "Jenderal", "Soedirman", "University", "in", "Purukerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "sentence-detokenized": "In August 2011, it was announced that Hitachi would donate an electron microscope to each of the five universities in Indonesia (University of North Sumatra in Medan, Indonesian Christian University in Jakarta, Padjadjaran University in Bandung, Jenderal Soedirman University in Purukerto and Muhammadiyah University in Malang).", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 32], [33, 37], [38, 45], [46, 51], [52, 58], [59, 61], [62, 70], [71, 81], [82, 84], [85, 89], [90, 92], [93, 96], [97, 101], [102, 114], [115, 117], [118, 127], [128, 129], [129, 139], [140, 142], [143, 148], [149, 156], [157, 159], [160, 165], [165, 166], [167, 177], [178, 187], [188, 198], [199, 201], [202, 209], [209, 210], [211, 222], [223, 233], [234, 236], [237, 244], [244, 245], [246, 254], [255, 264], [265, 275], [276, 278], [279, 288], [289, 292], [293, 305], [306, 316], [317, 319], [320, 326], [326, 327], [327, 328]]}
{"doc_key": "ai-dev-76", "ner": [[2, 2, "field"], [0, 3, "field"], [7, 8, "algorithm"], [10, 11, "algorithm"], [20, 21, "field"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 0, 3, "part-of", "", false, false], [2, 2, 20, 21, "related-to", "", true, false], [2, 2, 26, 27, "related-to", "", true, false], [7, 8, 2, 2, "type-of", "", false, false], [10, 11, 2, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Operations", "research", "optimization", "techniques", ",", "such", "as", "linear", "programming", "or", "dynamic", "programming", ",", "are", "often", "impractical", "for", "large", "-", "scale", "software", "engineering", "problems", "due", "to", "their", "computational", "complexity", "."], "sentence-detokenized": "Operations research optimization techniques, such as linear programming or dynamic programming, are often impractical for large-scale software engineering problems due to their computational complexity.", "token2charspan": [[0, 10], [11, 19], [20, 32], [33, 43], [43, 44], [45, 49], [50, 52], [53, 59], [60, 71], [72, 74], [75, 82], [83, 94], [94, 95], [96, 99], [100, 105], [106, 117], [118, 121], [122, 127], [127, 128], [128, 133], [134, 142], [143, 154], [155, 163], [164, 167], [168, 170], [171, 176], [177, 190], [191, 201], [201, 202]]}
{"doc_key": "ai-dev-77", "ner": [[0, 0, "metrics"], [6, 6, "metrics"], [9, 11, "metrics"], [16, 17, "metrics"], [20, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 6, "compare", "", false, false], [0, 0, 9, 11, "compare", "", false, false], [16, 17, 9, 11, "part-of", "", false, false], [20, 29, 9, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sensitivity", "is", "not", "the", "same", "as", "precision", ",", "or", "positive", "predictive", "value", "(", "the", "ratio", "of", "true", "positives", "to", "combined", "true", "and", "false", "positives", ")", ",", "which", "is", "as", "much", "an", "indicator", "of", "the", "proportion", "of", "true", "positives", "in", "the", "study", "population", "as", "it", "is", "of", "the", "test", "."], "sentence-detokenized": "Sensitivity is not the same as precision, or positive predictive value (the ratio of true positives to combined true and false positives), which is as much an indicator of the proportion of true positives in the study population as it is of the test.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 22], [23, 27], [28, 30], [31, 40], [40, 41], [42, 44], [45, 53], [54, 64], [65, 70], [71, 72], [72, 75], [76, 81], [82, 84], [85, 89], [90, 99], [100, 102], [103, 111], [112, 116], [117, 120], [121, 126], [127, 136], [136, 137], [137, 138], [139, 144], [145, 147], [148, 150], [151, 155], [156, 158], [159, 168], [169, 171], [172, 175], [176, 186], [187, 189], [190, 194], [195, 204], [205, 207], [208, 211], [212, 217], [218, 228], [229, 231], [232, 234], [235, 237], [238, 240], [241, 244], [245, 249], [249, 250]]}
{"doc_key": "ai-dev-78", "ner": [[0, 1, "person"], [10, 21, "product"], [14, 14, "person"], [29, 29, "person"], [36, 38, "person"], [41, 41, "person"], [47, 48, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 41, 41, "named", "same", false, false], [10, 21, 0, 1, "artifact", "", false, false], [36, 38, 47, 48, "role", "convinces", false, false], [47, 48, 10, 21, "role", "producer", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Hampton", "Fancher", "'s", "screenplay", "!", "--", "not", "originally", "titled", "\"", "Android", "\"", "--", "see", "Sammon", ",", "pp.", "32", "and", "38", "for", "an", "explanation", "--", "was", "purchased", "in", "1977", ".", "Sammon", ",", "pp.", "23", "-", "30", "Producer", "Michael", "Dilley", "became", "interested", "in", "Fancher", "'s", "project", "and", "persuaded", "director", "Ridley", "Scott", "to", "film", "it", "."], "sentence-detokenized": "Hampton Fancher's screenplay! -- not originally titled \"Android\" -- see Sammon, pp. 32 and 38 for an explanation -- was purchased in 1977. Sammon, pp. 23-30 Producer Michael Dilley became interested in Fancher's project and persuaded director Ridley Scott to film it.", "token2charspan": [[0, 7], [8, 15], [15, 17], [18, 28], [28, 29], [30, 32], [33, 36], [37, 47], [48, 54], [55, 56], [56, 63], [63, 64], [65, 67], [68, 71], [72, 78], [78, 79], [80, 83], [84, 86], [87, 90], [91, 93], [94, 97], [98, 100], [101, 112], [113, 115], [116, 119], [120, 129], [130, 132], [133, 137], [137, 138], [139, 145], [145, 146], [147, 150], [151, 153], [153, 154], [154, 156], [157, 165], [166, 173], [174, 180], [181, 187], [188, 198], [199, 201], [202, 209], [209, 211], [212, 219], [220, 223], [224, 233], [234, 242], [243, 249], [250, 255], [256, 258], [259, 263], [264, 266], [266, 267]]}
{"doc_key": "ai-dev-79", "ner": [[0, 1, "field"], [3, 4, "task"], [6, 8, "task"], [10, 12, "misc"], [14, 15, "field"], [17, 19, "task"], [21, 22, "task"], [25, 25, "field"], [28, 31, "task"], [33, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [6, 8, 0, 1, "part-of", "", false, false], [10, 12, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false], [17, 19, 0, 1, "part-of", "", false, false], [21, 22, 0, 1, "part-of", "", false, false], [25, 25, 0, 1, "part-of", "", false, false], [28, 31, 0, 1, "part-of", "", false, false], [33, 33, 0, 1, "part-of", "", false, false], [35, 36, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Text", "analysis", "includes", "information", "retrieval", ",", "lexical", "analysis", "to", "study", "word", "frequency", "distribution", ",", "pattern", "recognition", ",", "tagging", "/", "annotation", ",", "information", "extraction", ",", "data", "mining", "techniques", "including", "link", "and", "association", "analysis", ",", "visualization", "and", "predictive", "analysis", "."], "sentence-detokenized": "Text analysis includes information retrieval, lexical analysis to study word frequency distribution, pattern recognition, tagging/annotation, information extraction, data mining techniques including link and association analysis, visualization and predictive analysis.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 34], [35, 44], [44, 45], [46, 53], [54, 62], [63, 65], [66, 71], [72, 76], [77, 86], [87, 99], [99, 100], [101, 108], [109, 120], [120, 121], [122, 129], [129, 130], [130, 140], [140, 141], [142, 153], [154, 164], [164, 165], [166, 170], [171, 177], [178, 188], [189, 198], [199, 203], [204, 207], [208, 219], [220, 228], [228, 229], [230, 243], [244, 247], [248, 258], [259, 267], [267, 268]]}
{"doc_key": "ai-dev-80", "ner": [[3, 3, "product"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Several", "indicators", "use", "WordNet", ",", "a", "manually", "created", "lexical", "database", "of", "English", "words", "."], "sentence-detokenized": "Several indicators use WordNet, a manually created lexical database of English words.", "token2charspan": [[0, 7], [8, 18], [19, 22], [23, 30], [30, 31], [32, 33], [34, 42], [43, 50], [51, 58], [59, 67], [68, 70], [71, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-81", "ner": [[8, 9, "field"], [11, 12, "task"], [14, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "system", "uses", "a", "combination", "of", "techniques", "from", "computational", "linguistics", ",", "information", "retrieval", "and", "knowledge", "representation", "to", "find", "answers", "."], "sentence-detokenized": "The system uses a combination of techniques from computational linguistics, information retrieval and knowledge representation to find answers.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 17], [18, 29], [30, 32], [33, 43], [44, 48], [49, 62], [63, 74], [74, 75], [76, 87], [88, 97], [98, 101], [102, 111], [112, 126], [127, 129], [130, 134], [135, 142], [142, 143]]}
{"doc_key": "ai-dev-82", "ner": [[5, 7, "metrics"], [13, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 13, 15, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "performance", "measure", ",", "the", "uncertainty", "ratio", "has", "an", "advantage", "over", "simple", "accuracy", "because", "it", "is", "not", "affected", "by", "the", "relative", "sizes", "of", "the", "different", "classes", "."], "sentence-detokenized": "As a performance measure, the uncertainty ratio has an advantage over simple accuracy because it is not affected by the relative sizes of the different classes.", "token2charspan": [[0, 2], [3, 4], [5, 16], [17, 24], [24, 25], [26, 29], [30, 41], [42, 47], [48, 51], [52, 54], [55, 64], [65, 69], [70, 76], [77, 85], [86, 93], [94, 96], [97, 99], [100, 103], [104, 112], [113, 115], [116, 119], [120, 128], [129, 134], [135, 137], [138, 141], [142, 151], [152, 159], [159, 160]]}
{"doc_key": "ai-dev-83", "ner": [[9, 10, "algorithm"], [12, 13, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Researchers", "have", "used", "a", "number", "of", "methods", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "hidden", "Markov", "models", ",", "etc", "."], "sentence-detokenized": "Researchers have used a number of methods such as optical flow, Kalman filtering, hidden Markov models, etc.", "token2charspan": [[0, 11], [12, 16], [17, 21], [22, 23], [24, 30], [31, 33], [34, 41], [42, 46], [47, 49], [50, 57], [58, 62], [62, 63], [64, 70], [71, 80], [80, 81], [82, 88], [89, 95], [96, 102], [102, 103], [104, 107], [107, 108]]}
{"doc_key": "ai-dev-84", "ner": [[15, 22, "conference"], [31, 34, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "has", "served", "as", "president", ",", "vice", "president", ",", "and", "secretary", "-", "treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "has", "served", "as", "a", "board", "member", "and", "board", "secretary", "of", "the", "Association", "for", "Computational", "Research", "."], "sentence-detokenized": "She has served as president, vice president, and secretary-treasurer of the Association for Computational Linguistics and has served as a board member and board secretary of the Association for Computational Research.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 17], [18, 27], [27, 28], [29, 33], [34, 43], [43, 44], [45, 48], [49, 58], [58, 59], [59, 68], [69, 71], [72, 75], [76, 87], [88, 91], [92, 105], [106, 117], [118, 121], [122, 125], [126, 132], [133, 135], [136, 137], [138, 143], [144, 150], [151, 154], [155, 160], [161, 170], [171, 173], [174, 177], [178, 189], [190, 193], [194, 207], [208, 216], [216, 217]]}
{"doc_key": "ai-dev-85", "ner": [[7, 7, "programlang"], [9, 9, "product"], [11, 11, "programlang"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 11, 11, "compare", "", false, false], [7, 7, 13, 14, "related-to", "supports", false, false], [9, 9, 11, 11, "compare", "", false, false], [9, 9, 13, 14, "related-to", "supports", false, false], [11, 11, 13, 14, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Like", "other", "similar", "languages", ",", "such", "as", "APL", "and", "MATLAB", ",", "R", "supports", "matrix", "arithmetic", "."], "sentence-detokenized": "Like other similar languages, such as APL and MATLAB, R supports matrix arithmetic.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 28], [28, 29], [30, 34], [35, 37], [38, 41], [42, 45], [46, 52], [52, 53], [54, 55], [56, 64], [65, 71], [72, 82], [82, 83]]}
{"doc_key": "ai-dev-86", "ner": [[7, 11, "misc"], [12, 13, "organisation"], [17, 18, "researcher"], [21, 23, "university"], [27, 32, "misc"], [34, 34, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 11, 12, 13, "physical", "", false, false], [7, 11, 27, 32, "temporal", "", false, false], [17, 18, 7, 11, "role", "arranges", false, false], [17, 18, 21, 23, "role", "works_for", false, false], [34, 34, 7, 11, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "7", "June", "2014", ",", "in", "a", "Turing", "Test", "competition", "at", "the", "Royal", "Society", ",", "organised", "by", "Kevin", "Warwick", "of", "the", "University", "of", "Reading", "to", "mark", "the", "60th", "anniversary", "of", "Turing", "'s", "death", ",", "Guestman", "won", "after", "33", "%", "of", "the", "judges", "were", "convinced", "the", "bot", "was", "human", "."], "sentence-detokenized": "On 7 June 2014, in a Turing Test competition at the Royal Society, organised by Kevin Warwick of the University of Reading to mark the 60th anniversary of Turing's death, Guestman won after 33% of the judges were convinced the bot was human.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 14], [14, 15], [16, 18], [19, 20], [21, 27], [28, 32], [33, 44], [45, 47], [48, 51], [52, 57], [58, 65], [65, 66], [67, 76], [77, 79], [80, 85], [86, 93], [94, 96], [97, 100], [101, 111], [112, 114], [115, 122], [123, 125], [126, 130], [131, 134], [135, 139], [140, 151], [152, 154], [155, 161], [161, 163], [164, 169], [169, 170], [171, 179], [180, 183], [184, 189], [190, 192], [192, 193], [194, 196], [197, 200], [201, 207], [208, 212], [213, 222], [223, 226], [227, 230], [231, 234], [235, 240], [240, 241]]}
{"doc_key": "ai-dev-87", "ner": [[0, 2, "product"], [4, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "collaborative", "robot", "or", "cobot", "is", "a", "robot", "that", "can", "safely", "and", "efficiently", "interact", "with", "human", "workers", "while", "performing", "simple", "industrial", "tasks", "."], "sentence-detokenized": "A collaborative robot or cobot is a robot that can safely and efficiently interact with human workers while performing simple industrial tasks.", "token2charspan": [[0, 1], [2, 15], [16, 21], [22, 24], [25, 30], [31, 33], [34, 35], [36, 41], [42, 46], [47, 50], [51, 57], [58, 61], [62, 73], [74, 82], [83, 87], [88, 93], [94, 101], [102, 107], [108, 118], [119, 125], [126, 136], [137, 142], [142, 143]]}
{"doc_key": "ai-dev-88", "ner": [[13, 14, "field"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 30, "task"], [32, 34, "task"], [37, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[17, 18, 13, 14, "part-of", "task_part_of_field", false, false], [20, 21, 13, 14, "part-of", "task_part_of_field", false, false], [23, 24, 13, 14, "part-of", "task_part_of_field", false, false], [26, 27, 13, 14, "part-of", "task_part_of_field", false, false], [29, 30, 13, 14, "part-of", "task_part_of_field", false, false], [32, 34, 13, 14, "part-of", "task_part_of_field", false, false], [37, 38, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "comprehensive", "framework", "has", "been", "applied", "to", "a", "wide", "variety", "of", "problems", "in", "computer", "vision", ",", "including", "feature", "detection", ",", "feature", "classification", ",", "image", "segmentation", ",", "image", "matching", ",", "motion", "estimation", ",", "shape", "signal", "computation", ",", "and", "object", "recognition", "."], "sentence-detokenized": "This comprehensive framework has been applied to a wide variety of problems in computer vision, including feature detection, feature classification, image segmentation, image matching, motion estimation, shape signal computation, and object recognition.", "token2charspan": [[0, 4], [5, 18], [19, 28], [29, 32], [33, 37], [38, 45], [46, 48], [49, 50], [51, 55], [56, 63], [64, 66], [67, 75], [76, 78], [79, 87], [88, 94], [94, 95], [96, 105], [106, 113], [114, 123], [123, 124], [125, 132], [133, 147], [147, 148], [149, 154], [155, 167], [167, 168], [169, 174], [175, 183], [183, 184], [185, 191], [192, 202], [202, 203], [204, 209], [210, 216], [217, 228], [228, 229], [230, 233], [234, 240], [241, 252], [252, 253]]}
{"doc_key": "ai-dev-89", "ner": [[5, 6, "task"], [8, 10, "algorithm"], [13, 14, "algorithm"], [26, 27, "algorithm"], [32, 33, "algorithm"], [36, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 8, 10, "part-of", "", false, false], [5, 6, 13, 14, "usage", "", false, false], [8, 10, 26, 27, "named", "same", false, false], [26, 27, 32, 33, "related-to", "", false, false], [26, 27, 36, 37, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "many", "practical", "applications", ",", "parameter", "estimation", "for", "na\u00efve", "Bayes", "models", "uses", "the", "maximum", "likelihood", "method", ";", "in", "other", "words", ",", "one", "can", "work", "with", "a", "na\u00efve", "Bayes", "model", "without", "assuming", "a", "Bayes", "likelihood", "or", "using", "Bayesian", "methods", "."], "sentence-detokenized": "In many practical applications, parameter estimation for na\u00efve Bayes models uses the maximum likelihood method; in other words, one can work with a na\u00efve Bayes model without assuming a Bayes likelihood or using Bayesian methods.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 30], [30, 31], [32, 41], [42, 52], [53, 56], [57, 62], [63, 68], [69, 75], [76, 80], [81, 84], [85, 92], [93, 103], [104, 110], [110, 111], [112, 114], [115, 120], [121, 126], [126, 127], [128, 131], [132, 135], [136, 140], [141, 145], [146, 147], [148, 153], [154, 159], [160, 165], [166, 173], [174, 182], [183, 184], [185, 190], [191, 201], [202, 204], [205, 210], [211, 219], [220, 227], [227, 228]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [12, 15, "university"], [17, 19, "researcher"], [21, 22, "misc"], [26, 26, "university"], [28, 28, "university"], [31, 31, "misc"], [38, 40, "university"], [46, 49, "misc"], [51, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 4, 12, 15, "physical", "", false, false], [2, 4, 12, 15, "role", "", false, false], [2, 4, 17, 19, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [17, 19, 26, 26, "physical", "", false, false], [17, 19, 26, 26, "role", "", false, false], [17, 19, 28, 28, "physical", "", false, false], [17, 19, 28, 28, "role", "", false, false], [17, 19, 38, 40, "physical", "", false, false], [17, 19, 38, 40, "role", "", false, false], [21, 22, 17, 19, "named", "", false, false], [31, 31, 17, 19, "origin", "", false, false], [46, 49, 17, 19, "artifact", "", false, false], [46, 49, 51, 54, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Brothers", "-", "Victor", "Gershevich", "Katz", ",", "American", "mathematician", ",", "professor", "at", "the", "Massachusetts", "Institute", "of", "Technology", ";", "Michael", "Gershevich", "Katz", ",", "Israeli", "mathematician", ",", "graduate", "of", "Harvard", "and", "Columbia", "Universities", "(", "PhD", ",", "1984", ")", ",", "professor", "at", "Bar-", "Ilan", "University", ",", "author", "of", "the", "monograph", "Systolic", "Geometry", "and", "Topology", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", "."], "sentence-detokenized": "Brothers - Victor Gershevich Katz, American mathematician, professor at the Massachusetts Institute of Technology; Michael Gershevich Katz, Israeli mathematician, graduate of Harvard and Columbia Universities (PhD, 1984), professor at Bar-Ilan University, author of the monograph Systolic Geometry and Topology (Mathematical Surveys and Monographs, vol.", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 28], [29, 33], [33, 34], [35, 43], [44, 57], [57, 58], [59, 68], [69, 71], [72, 75], [76, 89], [90, 99], [100, 102], [103, 113], [113, 114], [115, 122], [123, 133], [134, 138], [138, 139], [140, 147], [148, 161], [161, 162], [163, 171], [172, 174], [175, 182], [183, 186], [187, 195], [196, 208], [209, 210], [210, 213], [213, 214], [215, 219], [219, 220], [220, 221], [222, 231], [232, 234], [235, 239], [239, 243], [244, 254], [254, 255], [256, 262], [263, 265], [266, 269], [270, 279], [280, 288], [289, 297], [298, 301], [302, 310], [311, 312], [312, 324], [325, 332], [333, 336], [337, 347], [347, 348], [349, 352], [352, 353]]}
{"doc_key": "ai-dev-91", "ner": [[3, 6, "person"], [10, 11, "conference"], [16, 19, "organisation"], [22, 28, "location"], [32, 32, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 10, 11, "physical", "", false, false], [3, 6, 10, 11, "role", "", false, false], [3, 6, 16, 19, "role", "", false, false], [16, 19, 22, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2000", ",", "Manuel", "Toharia", ",", "a", "speaker", "at", "previous", "Campus", "parties", "and", "director", "of", "the", "Principe", "Felipe", "Science", "Museum", "in", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", ",", "suggested", "to", "Ragales", "that", "it", "expand", "and", "make", "the", "event", "more", "international", "by", "moving", "it", "to", "the", "famous", "museum", "."], "sentence-detokenized": "In 2000, Manuel Toharia, a speaker at previous Campus parties and director of the Principe Felipe Science Museum in the City of Arts and Sciences in Valencia, suggested to Ragales that it expand and make the event more international by moving it to the famous museum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 23], [23, 24], [25, 26], [27, 34], [35, 37], [38, 46], [47, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 81], [82, 90], [91, 97], [98, 105], [106, 112], [113, 115], [116, 119], [120, 124], [125, 127], [128, 132], [133, 136], [137, 145], [146, 148], [149, 157], [157, 158], [159, 168], [169, 171], [172, 179], [180, 184], [185, 187], [188, 194], [195, 198], [199, 203], [204, 207], [208, 213], [214, 218], [219, 232], [233, 235], [236, 242], [243, 245], [246, 248], [249, 252], [253, 259], [260, 266], [266, 267]]}
{"doc_key": "ai-dev-92", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Within", "20", "minutes", ",", "a", "facial", "recognition", "system", "identifies", "personal", "information", ",", "including", "last", "name", ",", "ID", "number", "and", "address", ",", "which", "is", "displayed", "on", "a", "street", "advertising", "screen", "."], "sentence-detokenized": "Within 20 minutes, a facial recognition system identifies personal information, including last name, ID number and address, which is displayed on a street advertising screen.", "token2charspan": [[0, 6], [7, 9], [10, 17], [17, 18], [19, 20], [21, 27], [28, 39], [40, 46], [47, 57], [58, 66], [67, 78], [78, 79], [80, 89], [90, 94], [95, 99], [99, 100], [101, 103], [104, 110], [111, 114], [115, 122], [122, 123], [124, 129], [130, 132], [133, 142], [143, 145], [146, 147], [148, 154], [155, 166], [167, 173], [173, 174]]}
{"doc_key": "ai-dev-93", "ner": [[6, 9, "field"], [8, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "research", "has", "increasingly", "focused", "on", "unsupervised", "and", "semi-supervised", "learning", "algorithms", "."], "sentence-detokenized": "Recent research has increasingly focused on unsupervised and semi-supervised learning algorithms.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 32], [33, 40], [41, 43], [44, 56], [57, 60], [61, 76], [77, 85], [86, 96], [96, 97]]}
{"doc_key": "ai-dev-94", "ner": [[4, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Compute", "this", "example", "with", "Python", "code", ":"], "sentence-detokenized": "Compute this example with Python code:", "token2charspan": [[0, 7], [8, 12], [13, 20], [21, 25], [26, 32], [33, 37], [37, 38]]}
{"doc_key": "ai-dev-95", "ner": [[7, 10, "task"], [14, 15, "field"], [18, 22, "algorithm"], [24, 24, "algorithm"], [28, 30, "algorithm"], [33, 34, "researcher"], [36, 37, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[18, 22, 14, 15, "part-of", "", false, false], [18, 22, 28, 30, "type-of", "", false, false], [18, 22, 33, 34, "origin", "", false, false], [18, 22, 36, 37, "origin", "", false, false], [24, 24, 18, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Today", ",", "however", ",", "many", "aspects", "of", "speech", "recognition", "have", "been", "captured", "by", "a", "deep", "learning", "method", "called", "long", "short", "-", "term", "memory", "(", "LSTM", ")", ",", "a", "recurrent", "neural", "network", "published", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "."], "sentence-detokenized": "Today, however, many aspects of speech recognition have been captured by a deep learning method called long short-term memory (LSTM), a recurrent neural network published by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997.", "token2charspan": [[0, 5], [5, 6], [7, 14], [14, 15], [16, 20], [21, 28], [29, 31], [32, 38], [39, 50], [51, 55], [56, 60], [61, 69], [70, 72], [73, 74], [75, 79], [80, 88], [89, 95], [96, 102], [103, 107], [108, 113], [113, 114], [114, 118], [119, 125], [126, 127], [127, 131], [131, 132], [132, 133], [134, 135], [136, 145], [146, 152], [153, 160], [161, 170], [171, 173], [174, 178], [179, 189], [190, 193], [194, 200], [201, 212], [213, 215], [216, 220], [220, 221]]}
{"doc_key": "ai-dev-96", "ner": [[9, 10, "algorithm"], [12, 12, "algorithm"], [19, 19, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 12, 12, "compare", "", false, false], [9, 10, 25, 25, "named", "same", false, false], [19, 19, 25, 25, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "preliminary", "experimental", "results", "with", "datasets", "with", "elevated", "noise", ",", "BrownBoost", "outperforms", "AdaBoost", "'s", "generalization", "error", ";", "however", ",", "LogitBoost", "performs", "just", "as", "well", "as", "BrownBoost", "."], "sentence-detokenized": "In preliminary experimental results with datasets with elevated noise, BrownBoost outperforms AdaBoost's generalization error; however, LogitBoost performs just as well as BrownBoost.", "token2charspan": [[0, 2], [3, 14], [15, 27], [28, 35], [36, 40], [41, 49], [50, 54], [55, 63], [64, 69], [69, 70], [71, 81], [82, 93], [94, 102], [102, 104], [105, 119], [120, 125], [125, 126], [127, 134], [134, 135], [136, 146], [147, 155], [156, 160], [161, 163], [164, 168], [169, 171], [172, 182], [182, 183]]}
{"doc_key": "ai-dev-97", "ner": [[0, 2, "algorithm"], [5, 6, "researcher"], [9, 9, "country"], [12, 14, "researcher"], [18, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 6, "part-of", "", false, false], [5, 6, 9, 9, "physical", "", false, false], [18, 20, 12, 14, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evolutionary", "programming", "was", "introduced", "by", "Lawrence", "Jogle", "in", "the", "USA", ",", "and", "John", "Henry", "Holland", "called", "his", "method", "the", "genetic", "algorithm", "."], "sentence-detokenized": "Evolutionary programming was introduced by Lawrence Jogle in the USA, and John Henry Holland called his method the genetic algorithm.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 57], [58, 60], [61, 64], [65, 68], [68, 69], [70, 73], [74, 78], [79, 84], [85, 92], [93, 99], [100, 103], [104, 110], [111, 114], [115, 122], [123, 132], [132, 133]]}
{"doc_key": "ai-dev-98", "ner": [[2, 2, "researcher"], [4, 4, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 11, 12, "role", "", false, false], [2, 2, 14, 15, "role", "", false, false], [2, 2, 17, 18, "role", "", false, false], [2, 2, 21, 22, "role", "", false, false], [4, 4, 11, 12, "role", "", false, false], [4, 4, 14, 15, "role", "", false, false], [4, 4, 17, 18, "role", "", false, false], [4, 4, 21, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Calculations", "by", "Doug", ",", "Allen", ",", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", ",", "and", "John", "McCarthy", ")", "indicate", "that", "this", "effort", "will", "require", "between", "1,000", "and", "3,000", "person", "-", "years", "of", "effort", ",", "far", "exceeding", "the", "standard", "academic", "project", "model", "."], "sentence-detokenized": "Calculations by Doug, Allen, and their colleagues (including Marvin Minsky, Allen Newell, Edward Feigenbaum, and John McCarthy) indicate that this effort will require between 1,000 and 3,000 person-years of effort, far exceeding the standard academic project model.", "token2charspan": [[0, 12], [13, 15], [16, 20], [20, 21], [22, 27], [27, 28], [29, 32], [33, 38], [39, 49], [50, 51], [51, 60], [61, 67], [68, 74], [74, 75], [76, 81], [82, 88], [88, 89], [90, 96], [97, 107], [107, 108], [109, 112], [113, 117], [118, 126], [126, 127], [128, 136], [137, 141], [142, 146], [147, 153], [154, 158], [159, 166], [167, 174], [175, 180], [181, 184], [185, 190], [191, 197], [197, 198], [198, 203], [204, 206], [207, 213], [213, 214], [215, 218], [219, 228], [229, 232], [233, 241], [242, 250], [251, 258], [259, 264], [264, 265]]}
{"doc_key": "ai-dev-99", "ner": [[5, 7, "metrics"], [11, 11, "metrics"], [14, 16, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 11, 11, "part-of", "implemented_in", false, false], [14, 16, 19, 19, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "common", "criteria", "are", "the", "mean", "squared", "error", "criterion", "applied", "in", "MSECriterion", "and", "the", "cross", "-entropy", "criterion", "applied", "in", "NLLCriterion", "."], "sentence-detokenized": "The common criteria are the mean squared error criterion applied in MSECriterion and the cross-entropy criterion applied in NLLCriterion.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 23], [24, 27], [28, 32], [33, 40], [41, 46], [47, 56], [57, 64], [65, 67], [68, 80], [81, 84], [85, 88], [89, 94], [94, 102], [103, 112], [113, 120], [121, 123], [124, 136], [136, 137]]}
{"doc_key": "ai-dev-100", "ner": [[0, 0, "researcher"], [9, 9, "organisation"], [13, 24, "misc"], [27, 30, "conference"], [40, 40, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 9, 9, "role", "", false, false], [0, 0, 27, 30, "role", "", false, false], [0, 0, 40, 40, "role", "", false, false], [13, 24, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zourada", "has", "served", "the", "engineering", "profession", "as", "a", "longtime", "IEEE", "volunteer", ":", "as", "IEEE", "Vice", "President", "for", "Technical", "Activities", "(", "TAB", "Chair", ")", "in", "2014", ",", "as", "IEEE", "Computational", "Intelligence", "Society", "President", "in", "2004", "-", "05", ",", "and", "as", "an", "ADCOM", "member", "in", "2009", "-", "14", ",", "2016", "-", "18", ",", "and", "previous", "years", "."], "sentence-detokenized": "Zourada has served the engineering profession as a longtime IEEE volunteer: as IEEE Vice President for Technical Activities (TAB Chair) in 2014, as IEEE Computational Intelligence Society President in 2004-05, and as an ADCOM member in 2009-14, 2016-18, and previous years.", "token2charspan": [[0, 7], [8, 11], [12, 18], [19, 22], [23, 34], [35, 45], [46, 48], [49, 50], [51, 59], [60, 64], [65, 74], [74, 75], [76, 78], [79, 83], [84, 88], [89, 98], [99, 102], [103, 112], [113, 123], [124, 125], [125, 128], [129, 134], [134, 135], [136, 138], [139, 143], [143, 144], [145, 147], [148, 152], [153, 166], [167, 179], [180, 187], [188, 197], [198, 200], [201, 205], [205, 206], [206, 208], [208, 209], [210, 213], [214, 216], [217, 219], [220, 225], [226, 232], [233, 235], [236, 240], [240, 241], [241, 243], [243, 244], [245, 249], [249, 250], [250, 252], [252, 253], [254, 257], [258, 266], [267, 272], [272, 273]]}
{"doc_key": "ai-dev-101", "ner": [[3, 8, "field"], [13, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 14, 3, 8, "part-of", "", false, false], [16, 17, 3, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "general", ",", "computational", "linguistics", "is", "based", "on", "the", "participation", "of", "linguists", ",", "computer", "scientists", ",", "artificial", "intelligence", "experts", ",", "mathematicians", ",", "logicians", ",", "philosophers", ",", "cognitive", "scientists", ",", "cognitive", "psychologists", ",", "psycholinguists", ",", "anthropologists", "and", "neuroscientists", ",", "etc", "."], "sentence-detokenized": "In general, computational linguistics is based on the participation of linguists, computer scientists, artificial intelligence experts, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists and neuroscientists, etc.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 25], [26, 37], [38, 40], [41, 46], [47, 49], [50, 53], [54, 67], [68, 70], [71, 80], [80, 81], [82, 90], [91, 101], [101, 102], [103, 113], [114, 126], [127, 134], [134, 135], [136, 150], [150, 151], [152, 161], [161, 162], [163, 175], [175, 176], [177, 186], [187, 197], [197, 198], [199, 208], [209, 222], [222, 223], [224, 239], [239, 240], [241, 256], [257, 260], [261, 276], [276, 277], [278, 281], [281, 282]]}
{"doc_key": "ai-dev-102", "ner": [[10, 12, "algorithm"], [14, 16, "algorithm"], [19, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["To", "exploit", "the", "correlations", "between", "frames", ",", "techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", ",", "and", "long", "term", "memory", "are", "often", "used", "."], "sentence-detokenized": "To exploit the correlations between frames, techniques such as dynamic Markov networks, convolutional neural networks, and long term memory are often used.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 27], [28, 35], [36, 42], [42, 43], [44, 54], [55, 59], [60, 62], [63, 70], [71, 77], [78, 86], [86, 87], [88, 101], [102, 108], [109, 117], [117, 118], [119, 122], [123, 127], [128, 132], [133, 139], [140, 143], [144, 149], [150, 154], [154, 155]]}
{"doc_key": "ai-dev-103", "ner": [[0, 0, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "is", "the", "first", "industrial", "robot", ","], "sentence-detokenized": "Unimate is the first industrial robot,", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 20], [21, 31], [32, 37], [37, 38]]}
{"doc_key": "ai-dev-104", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [7, 8, "researcher"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 11, 13, "win-defeat", "", false, false], [5, 6, 11, 13, "win-defeat", "", false, false], [7, 8, 11, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Together", "with", "Geoffrey", "Hinton", "and", "Jan", "Lekun", ",", "Bengio", "received", "the", "2018", "Turing", "Award", "."], "sentence-detokenized": "Together with Geoffrey Hinton and Jan Lekun, Bengio received the 2018 Turing Award.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 29], [30, 33], [34, 37], [38, 43], [43, 44], [45, 51], [52, 60], [61, 64], [65, 69], [70, 76], [77, 82], [82, 83]]}
{"doc_key": "ai-dev-105", "ner": [[2, 3, "country"], [22, 25, "misc"], [29, 30, "country"], [31, 32, "organisation"], [36, 37, "person"], [39, 40, "person"], [49, 51, "misc"], [56, 56, "country"], [61, 61, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[22, 25, 2, 3, "physical", "filmed_in", false, false], [36, 37, 31, 32, "role", "host", false, false], [39, 40, 31, 32, "role", "reporter", false, false], [49, 51, 2, 3, "physical", "filmed_in", false, false], [49, 51, 56, 56, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Additional", "series", "have", "been", "filmed", "on", "location", "in", "the", "UK", "for", "specific", "sectors", "of", "the", "global", "market", ",", "including", "two", "series", "of", "Robot", "Wars", "Extreme", "Warriors", "with", "US", "participants", "for", "the", "TNN", "network", "(", "with", "host", "Mick", "Foley", "and", "Rebecca", "Grant", "as", "box", "reporter", ")", ",", "two", "series", "of", "Dutch", "Robot", "Wars", "for", "distribution", "in", "the", "Netherlands", "and", "one", "series", "for", "Germany", "."], "sentence-detokenized": "Additional series have been filmed on location in the UK for specific sectors of the global market, including two series of Robot Wars Extreme Warriors with US participants for the TNN network (with host Mick Foley and Rebecca Grant as box reporter), two series of Dutch Robot Wars for distribution in the Netherlands and one series for Germany.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 27], [28, 34], [35, 37], [38, 46], [47, 49], [50, 53], [54, 56], [57, 60], [61, 69], [70, 77], [78, 80], [81, 84], [85, 91], [92, 98], [98, 99], [100, 109], [110, 113], [114, 120], [121, 123], [124, 129], [130, 134], [135, 142], [143, 151], [152, 156], [157, 159], [160, 172], [173, 176], [177, 180], [181, 184], [185, 192], [193, 194], [194, 198], [199, 203], [204, 208], [209, 214], [215, 218], [219, 226], [227, 232], [233, 235], [236, 239], [240, 248], [248, 249], [249, 250], [251, 254], [255, 261], [262, 264], [265, 270], [271, 276], [277, 281], [282, 285], [286, 298], [299, 301], [302, 305], [306, 317], [318, 321], [322, 325], [326, 332], [333, 336], [337, 344], [344, 345]]}
{"doc_key": "ai-dev-106", "ner": [[8, 8, "researcher"], [13, 13, "product"], [32, 33, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 13, 13, "role", "", false, false], [32, 33, 13, 13, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "many", "years", ",", "starting", "in", "1986", ",", "Miller", "led", "the", "development", "of", "WordNet", ",", "a", "large", "electronic", "directory", "that", "can", "be", "read", "on", "a", "computer", "and", "used", "in", "applications", "such", "as", "search", "engines", "."], "sentence-detokenized": "For many years, starting in 1986, Miller led the development of WordNet, a large electronic directory that can be read on a computer and used in applications such as search engines.", "token2charspan": [[0, 3], [4, 8], [9, 14], [14, 15], [16, 24], [25, 27], [28, 32], [32, 33], [34, 40], [41, 44], [45, 48], [49, 60], [61, 63], [64, 71], [71, 72], [73, 74], [75, 80], [81, 91], [92, 101], [102, 106], [107, 110], [111, 113], [114, 118], [119, 121], [122, 123], [124, 132], [133, 136], [137, 141], [142, 144], [145, 157], [158, 162], [163, 165], [166, 172], [173, 180], [180, 181]]}
{"doc_key": "ai-dev-107", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [12, 14, "researcher"], [19, 24, "organisation"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 12, 14, "origin", "", false, false], [3, 5, 27, 29, "win-defeat", "", false, false], [7, 9, 12, 14, "origin", "", false, false], [7, 9, 27, 29, "win-defeat", "", false, false], [12, 14, 19, 24, "physical", "", false, false], [12, 14, 19, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Since", "2009", ",", "recurrent", "neural", "networks", "and", "deep", "neural", "networks", "developed", "by", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "Swiss", "artificial", "intelligence", "lab", "IDSIA", "have", "won", "several", "international", "handwriting", "competitions", "."], "sentence-detokenized": "Since 2009, recurrent neural networks and deep neural networks developed by J\u00fcrgen Schmidhuber's research group at the Swiss artificial intelligence lab IDSIA have won several international handwriting competitions.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 21], [22, 28], [29, 37], [38, 41], [42, 46], [47, 53], [54, 62], [63, 72], [73, 75], [76, 82], [83, 94], [94, 96], [97, 105], [106, 111], [112, 114], [115, 118], [119, 124], [125, 135], [136, 148], [149, 152], [153, 158], [159, 163], [164, 167], [168, 175], [176, 189], [190, 201], [202, 214], [214, 215]]}
{"doc_key": "ai-dev-108", "ner": [[5, 6, "programlang"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "is", "implemented", "in", "C", "++", "and", "packaged", "for", "Python", "."], "sentence-detokenized": "The software is implemented in C++ and packaged for Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 30], [31, 32], [32, 34], [35, 38], [39, 47], [48, 51], [52, 58], [58, 59]]}
{"doc_key": "ai-dev-109", "ner": [[8, 9, "country"], [14, 15, "misc"], [20, 23, "misc"], [33, 33, "misc"], [36, 36, "misc"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 23, 8, 9, "temporal", "", false, false], [20, 23, 14, 15, "artifact", "", false, false], [20, 23, 38, 38, "physical", "", false, false], [36, 36, 33, 33, "named", "", false, false], [36, 36, 38, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1857", ",", "at", "the", "request", "of", "the", "Tokugawa", "shogunate", ",", "a", "group", "of", "Dutch", "engineers", "began", "work", "on", "the", "Nagasaki", "Yotetsusho", ",", "a", "modern", "Western", "-", "style", "foundry", "and", "shipyard", "near", "the", "Dutch", "settlement", "of", "Dejima", "in", "Nagasaki", "."], "sentence-detokenized": "In 1857, at the request of the Tokugawa shogunate, a group of Dutch engineers began work on the Nagasaki Yotetsusho, a modern Western-style foundry and shipyard near the Dutch settlement of Dejima in Nagasaki.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 39], [40, 49], [49, 50], [51, 52], [53, 58], [59, 61], [62, 67], [68, 77], [78, 83], [84, 88], [89, 91], [92, 95], [96, 104], [105, 115], [115, 116], [117, 118], [119, 125], [126, 133], [133, 134], [134, 139], [140, 147], [148, 151], [152, 160], [161, 165], [166, 169], [170, 175], [176, 186], [187, 189], [190, 196], [197, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-dev-110", "ner": [[10, 12, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["We", "make", "the", "most", "accurate", "estimate", "possible", "by", "measuring", "the", "mean", "squared", "error", "between", "math", "/", "math", "and", "math", "\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "we", "want", "math", "(", "y", "-\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", "^", "2", "/", "math", "to", "be", "minimum", ",", "both", "for", "mathx", "_", "1", ",\\", "points", ",", "x", "_n", "/", "math", ",", "and", "for", "points", "outside", "our", "sample", "."], "sentence-detokenized": "We make the most accurate estimate possible by measuring the mean squared error between math / math and math\\ hat {f} (x; D) / math: we want math (y -\\ hat {f} (x; D)) ^ 2 / math to be minimum, both for mathx _ 1,\\ points, x _n / math, and for points outside our sample.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 16], [17, 25], [26, 34], [35, 43], [44, 46], [47, 56], [57, 60], [61, 65], [66, 73], [74, 79], [80, 87], [88, 92], [93, 94], [95, 99], [100, 103], [104, 108], [108, 109], [110, 113], [114, 115], [115, 116], [116, 117], [118, 119], [119, 120], [120, 121], [122, 123], [123, 124], [125, 126], [127, 131], [131, 132], [133, 135], [136, 140], [141, 145], [146, 147], [147, 148], [149, 151], [152, 155], [156, 157], [157, 158], [158, 159], [160, 161], [161, 162], [162, 163], [164, 165], [165, 166], [166, 167], [168, 169], [170, 171], [172, 173], [174, 178], [179, 181], [182, 184], [185, 192], [192, 193], [194, 198], [199, 202], [203, 208], [209, 210], [211, 212], [212, 214], [215, 221], [221, 222], [223, 224], [225, 227], [228, 229], [230, 234], [234, 235], [236, 239], [240, 243], [244, 250], [251, 258], [259, 262], [263, 269], [269, 270]]}
{"doc_key": "ai-dev-111", "ner": [[6, 6, "researcher"], [14, 16, "organisation"], [22, 27, "product"], [34, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 14, 16, "role", "", false, false], [22, 27, 14, 16, "temporal", "", false, false], [22, 27, 34, 35, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "subsequently", "extended", "an", "invitation", "to", "Weidner", "to", "attend", "the", "annual", "meeting", "of", "the", "American", "Translators", "Association", "the", "following", "October", ",", "where", "Weidner", "'s", "machine", "translation", "system", "was", "hailed", "as", "an", "anticipated", "breakthrough", "in", "machine", "translation", "."], "sentence-detokenized": "He subsequently extended an invitation to Weidner to attend the annual meeting of the American Translators Association the following October, where Weidner's machine translation system was hailed as an anticipated breakthrough in machine translation.", "token2charspan": [[0, 2], [3, 15], [16, 24], [25, 27], [28, 38], [39, 41], [42, 49], [50, 52], [53, 59], [60, 63], [64, 70], [71, 78], [79, 81], [82, 85], [86, 94], [95, 106], [107, 118], [119, 122], [123, 132], [133, 140], [140, 141], [142, 147], [148, 155], [155, 157], [158, 165], [166, 177], [178, 184], [185, 188], [189, 195], [196, 198], [199, 201], [202, 213], [214, 226], [227, 229], [230, 237], [238, 249], [249, 250]]}
{"doc_key": "ai-dev-112", "ner": [[2, 10, "conference"], [8, 8, "conference"], [14, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 2, 10, "named", "", false, false], [8, 8, 2, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["At", "the", "2018", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "conference", ",", "researchers", "from", "Google", "presented", "the", "work", "."], "sentence-detokenized": "At the 2018 Neural Information Processing Systems (NeurIPS) conference, researchers from Google presented the work.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 30], [31, 41], [42, 49], [50, 51], [51, 58], [58, 59], [60, 70], [70, 71], [72, 83], [84, 88], [89, 95], [96, 105], [106, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-dev-113", "ner": [[0, 4, "algorithm"], [10, 12, "algorithm"], [15, 19, "metrics"], [23, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 10, 12, "usage", "", false, false], [10, 12, 15, 19, "related-to", "", true, false], [15, 19, 23, 27, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Baum", "-", "Welch", "algorithm", "uses", "the", "well", "-", "known", "EM", "algorithm", "to", "find", "a", "maximum", "likelihood", "estimate", "of", "the", "parameters", "of", "a", "hidden", "Markov", "model", "given", "a", "set", "of", "observed", "feature", "vectors", "."], "sentence-detokenized": "The Baum-Welch algorithm uses the well-known EM algorithm to find a maximum likelihood estimate of the parameters of a hidden Markov model given a set of observed feature vectors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [15, 24], [25, 29], [30, 33], [34, 38], [38, 39], [39, 44], [45, 47], [48, 57], [58, 60], [61, 65], [66, 67], [68, 75], [76, 86], [87, 95], [96, 98], [99, 102], [103, 113], [114, 116], [117, 118], [119, 125], [126, 132], [133, 138], [139, 144], [145, 146], [147, 150], [151, 153], [154, 162], [163, 170], [171, 178], [178, 179]]}
{"doc_key": "ai-dev-114", "ner": [[9, 9, "product"], [11, 11, "product"], [30, 31, "misc"], [36, 44, "product"], [50, 55, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[9, 9, 11, 11, "compare", "", false, false], [30, 31, 11, 11, "part-of", "", false, false], [36, 44, 11, 11, "part-of", "", false, false], [50, 55, 11, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": [")", "In", "addition", "to", "the", "taxonomic", "information", "contained", "in", "OpenCyc", ",", "ResearchCyc", "includes", "significantly", "more", "semantic", "knowledge", "(", "i.e.", ",", "additional", "facts", "and", "rules", ")", "involving", "the", "concepts", "in", "its", "knowledge", "base", ";", "it", "also", "includes", "a", "large", "lexicon", ",", "parsing", "and", "English", "generation", "tools", ",", "and", "Java", "-", "based", "interfaces", "for", "knowledge", "editing", "and", "querying", "."], "sentence-detokenized": ") In addition to the taxonomic information contained in OpenCyc, ResearchCyc includes significantly more semantic knowledge (i.e., additional facts and rules) involving the concepts in its knowledge base; it also includes a large lexicon, parsing and English generation tools, and Java-based interfaces for knowledge editing and querying.", "token2charspan": [[0, 1], [2, 4], [5, 13], [14, 16], [17, 20], [21, 30], [31, 42], [43, 52], [53, 55], [56, 63], [63, 64], [65, 76], [77, 85], [86, 99], [100, 104], [105, 113], [114, 123], [124, 125], [125, 129], [129, 130], [131, 141], [142, 147], [148, 151], [152, 157], [157, 158], [159, 168], [169, 172], [173, 181], [182, 184], [185, 188], [189, 198], [199, 203], [203, 204], [205, 207], [208, 212], [213, 221], [222, 223], [224, 229], [230, 237], [237, 238], [239, 246], [247, 250], [251, 258], [259, 269], [270, 275], [275, 276], [277, 280], [281, 285], [285, 286], [286, 291], [292, 302], [303, 306], [307, 316], [317, 324], [325, 328], [329, 337], [337, 338]]}
{"doc_key": "ai-dev-115", "ner": [[0, 2, "algorithm"], [5, 6, "task"], [10, 11, "field"], [13, 14, "field"], [17, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 6, "type-of", "", false, false], [5, 6, 10, 11, "part-of", "task_part_of_field", false, false], [5, 6, 13, 14, "part-of", "task_part_of_field", false, false], [5, 6, 17, 19, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Hoff", "transform", "is", "a", "feature", "extraction", "technique", "used", "in", "image", "analysis", ",", "computer", "vision", ",", "and", "digital", "image", "processing", "."], "sentence-detokenized": "The Hoff transform is a feature extraction technique used in image analysis, computer vision, and digital image processing.", "token2charspan": [[0, 3], [4, 8], [9, 18], [19, 21], [22, 23], [24, 31], [32, 42], [43, 52], [53, 57], [58, 60], [61, 66], [67, 75], [75, 76], [77, 85], [86, 92], [92, 93], [94, 97], [98, 105], [106, 111], [112, 122], [122, 123]]}
{"doc_key": "ai-dev-116", "ner": [[4, 4, "product"], [6, 10, "product"], [16, 16, "organisation"], [18, 18, "product"], [20, 21, "researcher"], [27, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 6, 10, "named", "", false, false], [4, 4, 16, 16, "artifact", "", false, false], [4, 4, 18, 18, "origin", "developed_from", false, false], [18, 18, 20, 21, "artifact", "", false, false], [27, 28, 16, 16, "role", "supported", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1978", ",", "the", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "robot", "was", "developed", "by", "Unimation", "from", "Vicarm", "(", "Victor", "Sheinman", ")", "and", "with", "support", "from", "General", "Motors", "."], "sentence-detokenized": "In 1978, the PUMA (Programmable Universal Machine for Assembly) robot was developed by Unimation from Vicarm (Victor Sheinman) and with support from General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 19], [19, 31], [32, 41], [42, 49], [50, 53], [54, 62], [62, 63], [64, 69], [70, 73], [74, 83], [84, 86], [87, 96], [97, 101], [102, 108], [109, 110], [110, 116], [117, 125], [125, 126], [127, 130], [131, 135], [136, 143], [144, 148], [149, 156], [157, 163], [163, 164]]}
{"doc_key": "ai-dev-117", "ner": [[0, 1, "algorithm"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 7, 8, "origin", "", false, false], [0, 1, 10, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "LSTM", "was", "proposed", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "The LSTM was proposed in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 21], [22, 24], [25, 29], [30, 32], [33, 37], [38, 48], [49, 52], [53, 59], [60, 71], [71, 72]]}
{"doc_key": "ai-dev-118", "ner": [[11, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "outcomes", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four outcomes can be formulated in a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 24], [25, 35], [36, 38], [39, 40], [41, 42], [43, 44], [45, 46], [47, 58], [59, 64], [65, 67], [68, 77], [78, 84], [85, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-dev-119", "ner": [[8, 8, "conference"], [11, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "also", "contributed", "greatly", "to", "the", "creation", "of", "ELRA", "and", "the", "LREC", "conference", "."], "sentence-detokenized": "He also contributed greatly to the creation of ELRA and the LREC conference.", "token2charspan": [[0, 2], [3, 7], [8, 19], [20, 27], [28, 30], [31, 34], [35, 43], [44, 46], [47, 51], [52, 55], [56, 59], [60, 64], [65, 75], [75, 76]]}
{"doc_key": "ai-dev-120", "ner": [[16, 17, "misc"], [20, 23, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 23, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "popular", "application", "of", "serial", "robots", "in", "modern", "industry", "is", "the", "pick", "-", "and", "-", "place", "assembly", "robot", "called", "the", "SCARA", "robot", ",", "which", "has", "four", "degrees", "of", "freedom", "."], "sentence-detokenized": "A popular application of serial robots in modern industry is the pick-and-place assembly robot called the SCARA robot, which has four degrees of freedom.", "token2charspan": [[0, 1], [2, 9], [10, 21], [22, 24], [25, 31], [32, 38], [39, 41], [42, 48], [49, 57], [58, 60], [61, 64], [65, 69], [69, 70], [70, 73], [73, 74], [74, 79], [80, 88], [89, 94], [95, 101], [102, 105], [106, 111], [112, 117], [117, 118], [119, 124], [125, 128], [129, 133], [134, 141], [142, 144], [145, 152], [152, 153]]}
{"doc_key": "ai-dev-121", "ner": [[13, 21, "conference"], [23, 23, "conference"], [27, 33, "conference"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 13, 21, "named", "", false, false], [37, 37, 27, 33, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "is", "a", "founding", "member", "and", "former", "chair", "(", "2006-2008", ")", "of", "the", "Special", "Interest", "Group", "on", "the", "Web", "as", "a", "Corpus", "(", "SIGWAC", ")", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "and", "a", "founding", "member", "of", "SENSEVAL", "."], "sentence-detokenized": "He is a founding member and former chair (2006-2008) of the Special Interest Group on the Web as a Corpus (SIGWAC) of the Association for Computational Linguistics, and a founding member of SENSEVAL.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 16], [17, 23], [24, 27], [28, 34], [35, 40], [41, 42], [42, 51], [51, 52], [53, 55], [56, 59], [60, 67], [68, 76], [77, 82], [83, 85], [86, 89], [90, 93], [94, 96], [97, 98], [99, 105], [106, 107], [107, 113], [113, 114], [115, 117], [118, 121], [122, 133], [134, 137], [138, 151], [152, 163], [163, 164], [165, 168], [169, 170], [171, 179], [180, 186], [187, 189], [190, 198], [198, 199]]}
{"doc_key": "ai-dev-122", "ner": [[3, 4, "product"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "platform", ",", "LinguaStream", "provides", "an", "extensive", "Java", "API", "."], "sentence-detokenized": "As a platform, LinguaStream provides an extensive Java API.", "token2charspan": [[0, 2], [3, 4], [5, 13], [13, 14], [15, 27], [28, 36], [37, 39], [40, 49], [50, 54], [55, 58], [58, 59]]}
{"doc_key": "ai-dev-123", "ner": [[11, 11, "programlang"], [13, 16, "misc"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 19, 21, "type-of", "", false, false], [13, 16, 19, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "robot", "kit", "is", "based", "on", "Android", "and", "is", "programmed", "using", "Java", ",", "the", "Blocks", "programming", "interface", "or", "other", "Android", "programming", "systems", "."], "sentence-detokenized": "The robot kit is based on Android and is programmed using Java, the Blocks programming interface or other Android programming systems.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 16], [17, 22], [23, 25], [26, 33], [34, 37], [38, 40], [41, 51], [52, 57], [58, 62], [62, 63], [64, 67], [68, 74], [75, 86], [87, 96], [97, 99], [100, 105], [106, 113], [114, 125], [126, 133], [133, 134]]}
{"doc_key": "ai-dev-124", "ner": [[14, 14, "algorithm"], [16, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "method", "of", "defining", "the", "linked", "list", "determines", "the", "use", "of", "depth", "-", "first", "search", "or", "breadth", "-", "first", "search", "."], "sentence-detokenized": "The method of defining the linked list determines the use of depth-first search or breadth-first search.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 22], [23, 26], [27, 33], [34, 38], [39, 49], [50, 53], [54, 57], [58, 60], [61, 66], [66, 67], [67, 72], [73, 79], [80, 82], [83, 90], [90, 91], [91, 96], [97, 103], [103, 104]]}
{"doc_key": "ai-dev-125", "ner": [[22, 23, "task"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "areas", "may", "signal", "the", "presence", "of", "objects", "or", "parts", "of", "objects", "in", "the", "image", "area", ",", "which", "may", "be", "applied", "to", "object", "recognition", "and", "/", "or", "object", "video", "tracking", "."], "sentence-detokenized": "These areas may signal the presence of objects or parts of objects in the image area, which may be applied to object recognition and/or object video tracking.", "token2charspan": [[0, 5], [6, 11], [12, 15], [16, 22], [23, 26], [27, 35], [36, 38], [39, 46], [47, 49], [50, 55], [56, 58], [59, 66], [67, 69], [70, 73], [74, 79], [80, 84], [84, 85], [86, 91], [92, 95], [96, 98], [99, 106], [107, 109], [110, 116], [117, 128], [129, 132], [132, 133], [133, 135], [136, 142], [143, 148], [149, 157], [157, 158]]}
{"doc_key": "ai-dev-126", "ner": [[4, 5, "algorithm"], [7, 7, "product"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 4, 5, "type-of", "", false, false], [7, 7, 13, 13, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "semantic", "network", "is", "WordNet", ",", "a", "lexical", "database", "in", "English", "."], "sentence-detokenized": "An example of a semantic network is WordNet, a lexical database in English.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 32], [33, 35], [36, 43], [43, 44], [45, 46], [47, 54], [55, 63], [64, 66], [67, 74], [74, 75]]}
{"doc_key": "ai-dev-127", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 12, "field"], [20, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 7, 8, "part-of", "", false, false], [0, 1, 10, 12, "named", "same", false, false], [0, 1, 10, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Speech", "recognition", "is", "an", "interdisciplinary", "subfield", "of", "computer", "science", "and", "computational", "linguistics", "that", "develops", "methodologies", "and", "technologies", "to", "enable", "the", "recognition", "and", "translation", "of", "spoken", "language", "into", "text", "by", "computers", "."], "sentence-detokenized": "Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies to enable the recognition and translation of spoken language into text by computers.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 24], [25, 42], [43, 51], [52, 54], [55, 63], [64, 71], [72, 75], [76, 89], [90, 101], [102, 106], [107, 115], [116, 129], [130, 133], [134, 146], [147, 149], [150, 156], [157, 160], [161, 172], [173, 176], [177, 188], [189, 191], [192, 198], [199, 207], [208, 212], [213, 217], [218, 220], [221, 230], [230, 231]]}
{"doc_key": "ai-dev-128", "ner": [[0, 1, "field"], [10, 11, "misc"], [16, 18, "field"], [20, 20, "task"], [22, 23, "task"], [45, 45, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 45, 45, "named", "same", false, false], [16, 18, 0, 1, "part-of", "subfield", false, false], [20, 20, 0, 1, "part-of", "", false, false], [20, 20, 16, 18, "part-of", "", false, false], [22, 23, 16, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Artificial", "intelligence", "has", "received", "the", "most", "attention", "in", "terms", "of", "applied", "ontology", "in", "subfields", "such", "as", "natural", "language", "processing", "within", "machine", "and", "knowledge", "representation", ",", "but", "ontology", "editors", "are", "often", "used", "in", "a", "number", "of", "fields", "such", "as", "education", "without", "the", "aim", "of", "contributing", "to", "AI", "."], "sentence-detokenized": "Artificial intelligence has received the most attention in terms of applied ontology in subfields such as natural language processing within machine and knowledge representation, but ontology editors are often used in a number of fields such as education without the aim of contributing to AI.", "token2charspan": [[0, 10], [11, 23], [24, 27], [28, 36], [37, 40], [41, 45], [46, 55], [56, 58], [59, 64], [65, 67], [68, 75], [76, 84], [85, 87], [88, 97], [98, 102], [103, 105], [106, 113], [114, 122], [123, 133], [134, 140], [141, 148], [149, 152], [153, 162], [163, 177], [177, 178], [179, 182], [183, 191], [192, 199], [200, 203], [204, 209], [210, 214], [215, 217], [218, 219], [220, 226], [227, 229], [230, 236], [237, 241], [242, 244], [245, 254], [255, 262], [263, 266], [267, 270], [271, 273], [274, 286], [287, 289], [290, 292], [292, 293]]}
{"doc_key": "ai-dev-129", "ner": [[6, 10, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 10, 11, 12, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "update", "rule", "is", "actually", "the", "stochastic", "gradient", "descent", "update", "for", "linear", "regression", "."], "sentence-detokenized": "This update rule is actually the stochastic gradient descent update for linear regression.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 28], [29, 32], [33, 43], [44, 52], [53, 60], [61, 67], [68, 71], [72, 78], [79, 89], [89, 90]]}
{"doc_key": "ai-dev-130", "ner": [[5, 12, "organisation"], [13, 16, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "elected", "to", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "the", "National", "Academy", "of", "Sciences", "and", "has", "received", "numerous", "awards", ":"], "sentence-detokenized": "He was elected to the American Academy of Arts and Sciences and the National Academy of Sciences and has received numerous awards:", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 46], [47, 50], [51, 59], [60, 63], [64, 67], [68, 76], [77, 84], [85, 87], [88, 96], [97, 100], [101, 104], [105, 113], [114, 122], [123, 129], [129, 130]]}
{"doc_key": "ai-dev-131", "ner": [[0, 8, "organisation"], [11, 12, "person"], [14, 18, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 8, 11, 12, "related-to", "written_about_by", false, false], [0, 8, 14, 18, "related-to", "written_about_by", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Honda", "'s", "latest", "school", "of", "thought", "on", "strategy", "is", "represented", "by", "Gary", "Hamel", "and", "K", ".", "\u041a", ".", "Prahalad", "in", "1989", "."], "sentence-detokenized": "Honda's latest school of thought on strategy is represented by Gary Hamel and K. \u041a. Prahalad in 1989.", "token2charspan": [[0, 5], [5, 7], [8, 14], [15, 21], [22, 24], [25, 32], [33, 35], [36, 44], [45, 47], [48, 59], [60, 62], [63, 67], [68, 73], [74, 77], [78, 79], [79, 80], [81, 82], [82, 83], [84, 92], [93, 95], [96, 100], [100, 101]]}
{"doc_key": "ai-dev-132", "ner": [[1, 1, "metrics"], [5, 7, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 5, 7, "related-to", "calculates", true, false], [1, 1, 18, 18, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "BLEU", "simply", "calculates", "the", "precision", "of", "the", "n-", "grams", "by", "adding", "an", "equal", "weight", "to", "each", ",", "NIST", "also", "calculates", "how", "informative", "a", "given", "n-", "gram", "is", "."], "sentence-detokenized": "While BLEU simply calculates the precision of the n-grams by adding an equal weight to each, NIST also calculates how informative a given n-gram is.", "token2charspan": [[0, 5], [6, 10], [11, 17], [18, 28], [29, 32], [33, 42], [43, 45], [46, 49], [50, 52], [52, 57], [58, 60], [61, 67], [68, 70], [71, 76], [77, 83], [84, 86], [87, 91], [91, 92], [93, 97], [98, 102], [103, 113], [114, 117], [118, 129], [130, 131], [132, 137], [138, 140], [140, 144], [145, 147], [147, 148]]}
{"doc_key": "ai-dev-133", "ner": [[0, 11, "misc"], [12, 15, "conference"], [17, 17, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 11, 12, 15, "temporal", "", false, false], [17, 17, 12, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2019", ",", "he", "was", "awarded", "the", "Lifetime", "Achievement", "Award", "by", "the", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "In 2019, he was awarded the Lifetime Achievement Award by the Association for Computational Linguistics (ACL).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 27], [28, 36], [37, 48], [49, 54], [55, 57], [58, 61], [62, 73], [74, 77], [78, 91], [92, 103], [104, 105], [105, 108], [108, 109], [109, 110]]}
{"doc_key": "ai-dev-134", "ner": [[0, 0, "researcher"], [6, 11, "organisation"], [13, 13, "organisation"], [20, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 11, "role", "", false, false], [0, 0, 20, 24, "role", "", false, false], [13, 13, 6, 11, "named", "", false, false], [26, 26, 20, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sikara", "is", "a", "Fellow", "of", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "and", "a", "member", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sikara is a Fellow of the Institute of Electrical and Electronics Engineers (IEEE) and a member of the American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 18], [19, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 65], [66, 75], [76, 77], [77, 81], [81, 82], [83, 86], [87, 88], [89, 95], [96, 98], [99, 102], [103, 111], [112, 123], [124, 127], [128, 138], [139, 151], [152, 153], [153, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-dev-135", "ner": [[2, 2, "product"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 11, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "following", "MATLAB", "code", "demonstrates", "a", "concrete", "solution", "to", "solve", "the", "nonlinear", "system", "of", "equations", "presented", "in", "the", "previous", "section", ":", "see", "also"], "sentence-detokenized": "The following MATLAB code demonstrates a concrete solution to solve the nonlinear system of equations presented in the previous section: see also", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 38], [39, 40], [41, 49], [50, 58], [59, 61], [62, 67], [68, 71], [72, 81], [82, 88], [89, 91], [92, 101], [102, 111], [112, 114], [115, 118], [119, 127], [128, 135], [135, 136], [137, 140], [141, 145]]}
{"doc_key": "ai-dev-136", "ner": [[0, 4, "product"], [13, 14, "field"], [36, 37, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 13, 14, "related-to", "trained_by", true, false], [0, 4, 36, 37, "related-to", "trained_by", true, false], [13, 14, 36, 37, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Pattern", "recognition", "systems", "are", "in", "many", "cases", "trained", "on", "labeled", "training", "data", "(", "supervised", "learning", ")", ",", "but", "when", "labeled", "data", "is", "not", "available", ",", "other", "algorithms", "can", "be", "used", "to", "detect", "previously", "unknown", "patterns", "(", "unsupervised", "learning", ")", "."], "sentence-detokenized": "Pattern recognition systems are in many cases trained on labeled training data (supervised learning), but when labeled data is not available, other algorithms can be used to detect previously unknown patterns (unsupervised learning).", "token2charspan": [[0, 7], [8, 19], [20, 27], [28, 31], [32, 34], [35, 39], [40, 45], [46, 53], [54, 56], [57, 64], [65, 73], [74, 78], [79, 80], [80, 90], [91, 99], [99, 100], [100, 101], [102, 105], [106, 110], [111, 118], [119, 123], [124, 126], [127, 130], [131, 140], [140, 141], [142, 147], [148, 158], [159, 162], [163, 165], [166, 170], [171, 173], [174, 180], [181, 191], [192, 199], [200, 208], [209, 210], [210, 222], [223, 231], [231, 232], [232, 233]]}
{"doc_key": "ai-dev-137", "ner": [[5, 6, "researcher"], [9, 10, "country"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 9, 10, "physical", "", false, false], [5, 6, 24, 25, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "was", "first", "used", "by", "Lawrence", "Jogle", "in", "the", "United", "States", "in", "1960", "to", "use", "simulated", "evolution", "as", "a", "learning", "process", "aimed", "at", "creating", "artificial", "intelligence", "."], "sentence-detokenized": "It was first used by Lawrence Jogle in the United States in 1960 to use simulated evolution as a learning process aimed at creating artificial intelligence.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 17], [18, 20], [21, 29], [30, 35], [36, 38], [39, 42], [43, 49], [50, 56], [57, 59], [60, 64], [65, 67], [68, 71], [72, 81], [82, 91], [92, 94], [95, 96], [97, 105], [106, 113], [114, 119], [120, 122], [123, 131], [132, 142], [143, 155], [155, 156]]}
{"doc_key": "ai-dev-138", "ner": [[0, 1, "field"], [10, 11, "field"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 10, 11, "part-of", "", false, false], [15, 16, 10, 11, "part-of", "", false, false], [18, 19, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Reinforcement", "learning", "is", "one", "of", "the", "three", "main", "paradigms", "for", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "unsupervised", "learning", "."], "sentence-detokenized": "Reinforcement learning is one of the three main paradigms for machine learning, along with supervised learning and unsupervised learning.", "token2charspan": [[0, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 42], [43, 47], [48, 57], [58, 61], [62, 69], [70, 78], [78, 79], [80, 85], [86, 90], [91, 101], [102, 110], [111, 114], [115, 127], [128, 136], [136, 137]]}
{"doc_key": "ai-dev-139", "ner": [[4, 5, "field"], [12, 14, "programlang"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 28, 29, "usage", "applies", false, false], [12, 14, 28, 29, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "such", "cases", ",", "cloud", "computing", "and", "the", "open", "source", "programming", "language", "R", "can", "help", "smaller", "banks", "adopt", "risk", "analytics", "and", "support", "branch", "-", "level", "monitoring", "by", "applying", "predictive", "analytics", "."], "sentence-detokenized": "In such cases, cloud computing and the open source programming language R can help smaller banks adopt risk analytics and support branch-level monitoring by applying predictive analytics.", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 20], [21, 30], [31, 34], [35, 38], [39, 43], [44, 50], [51, 62], [63, 71], [72, 73], [74, 77], [78, 82], [83, 90], [91, 96], [97, 102], [103, 107], [108, 117], [118, 121], [122, 129], [130, 136], [136, 137], [137, 142], [143, 153], [154, 156], [157, 165], [166, 176], [177, 186], [186, 187]]}
{"doc_key": "ai-dev-140", "ner": [[11, 12, "researcher"], [16, 16, "algorithm"], [20, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 20, 22, "named", "same", false, false], [16, 16, 11, 12, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["One", "of", "the", "first", "versions", "of", "the", "theorem", "was", "proved", "by", "George", "Tsibenko", "in", "1989", "for", "sigmoid", "activation", "functions", ".", "Tsibenko", ",", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "One of the first versions of the theorem was proved by George Tsibenko in 1989 for sigmoid activation functions. Tsibenko, G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 25], [26, 28], [29, 32], [33, 40], [41, 44], [45, 51], [52, 54], [55, 61], [62, 70], [71, 73], [74, 78], [79, 82], [83, 90], [91, 101], [102, 111], [111, 112], [113, 121], [121, 122], [123, 125], [126, 127], [127, 131], [131, 132], [132, 133], [134, 135], [136, 137], [137, 138], [138, 139], [139, 140], [141, 148], [148, 149]]}
{"doc_key": "ai-dev-141", "ner": [[6, 8, "algorithm"], [9, 9, "metrics"], [16, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 6, 8, "part-of", "", false, false], [16, 19, 9, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "process", ",", "known", "as", "cross-validation", ",", "the", "MSE", "is", "often", "referred", "to", "as", "the", "mean", "squared", "prediction", "error", "and", "is", "calculated", "as", "follows"], "sentence-detokenized": "In this process, known as cross-validation, the MSE is often referred to as the mean squared prediction error and is calculated as follows", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 22], [23, 25], [26, 42], [42, 43], [44, 47], [48, 51], [52, 54], [55, 60], [61, 69], [70, 72], [73, 75], [76, 79], [80, 84], [85, 92], [93, 103], [104, 109], [110, 113], [114, 116], [117, 127], [128, 130], [131, 138]]}
{"doc_key": "ai-dev-142", "ner": [[0, 0, "task"], [4, 6, "task"], [8, 12, "task"], [18, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "compare", "", false, false], [4, 6, 18, 20, "part-of", "", false, false], [8, 12, 4, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OMR", "generally", "differs", "from", "optical", "character", "recognition", "(", "OCR", ")", "in", "that", "it", "does", "not", "require", "a", "sophisticated", "pattern", "recognition", "mechanism", "."], "sentence-detokenized": "OMR generally differs from optical character recognition (OCR) in that it does not require a sophisticated pattern recognition mechanism.", "token2charspan": [[0, 3], [4, 13], [14, 21], [22, 26], [27, 34], [35, 44], [45, 56], [57, 58], [58, 61], [61, 62], [63, 65], [66, 70], [71, 73], [74, 78], [79, 82], [83, 90], [91, 92], [93, 106], [107, 114], [115, 126], [127, 136], [136, 137]]}
{"doc_key": "ai-dev-143", "ner": [[11, 11, "location"], [13, 13, "location"], [15, 15, "location"], [18, 19, "location"], [21, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 15, 15, "physical", "", false, false], [18, 19, 13, 13, "physical", "", false, false], [21, 22, 13, 13, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2018", "and", "2019", ",", "the", "championships", "are", "being", "held", "in", "Houston", "and", "Detroit", ",", "Michigan", ",", "at", "TCF", "Center", "and", "Ford", "Field", "."], "sentence-detokenized": "In 2018 and 2019, the championships are being held in Houston and Detroit, Michigan, at TCF Center and Ford Field.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 16], [16, 17], [18, 21], [22, 35], [36, 39], [40, 45], [46, 50], [51, 53], [54, 61], [62, 65], [66, 73], [73, 74], [75, 83], [83, 84], [85, 87], [88, 91], [92, 98], [99, 102], [103, 107], [108, 113], [113, 114]]}
{"doc_key": "ai-dev-144", "ner": [[0, 1, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 1, "part-of", "", false, false], [12, 13, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "viewed", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multi-class", "classification", "."], "sentence-detokenized": "Classification can be viewed as two separate problems - binary classification and multi-class classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 28], [29, 31], [32, 35], [36, 44], [45, 53], [54, 55], [56, 62], [63, 77], [78, 81], [82, 93], [94, 108], [108, 109]]}
{"doc_key": "ai-dev-145", "ner": [[4, 5, "product"], [8, 9, "product"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "type-of", "", false, false], [12, 13, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "examples", "of", "popular", "parallel", "robots", "are", "the", "Stewart", "platform", "and", "the", "Delta", "robot", "."], "sentence-detokenized": "Two examples of popular parallel robots are the Stewart platform and the Delta robot.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 23], [24, 32], [33, 39], [40, 43], [44, 47], [48, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-146", "ner": [[3, 8, "algorithm"], [22, 22, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 8, 22, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "However", ",", "the", "ReLU", "activation", "function", ",", "which", "is", "not", "differentiatable", "at", "0", ",", "has", "become", "quite", "popular", ",", "e.g.", "in", "AlexNet", ")"], "sentence-detokenized": "(However, the ReLU activation function, which is not differentiatable at 0, has become quite popular, e.g. in AlexNet)", "token2charspan": [[0, 1], [1, 8], [8, 9], [10, 13], [14, 18], [19, 29], [30, 38], [38, 39], [40, 45], [46, 48], [49, 52], [53, 69], [70, 72], [73, 74], [74, 75], [76, 79], [80, 86], [87, 92], [93, 100], [100, 101], [102, 106], [107, 109], [110, 117], [117, 118]]}
{"doc_key": "ai-dev-147", "ner": [[0, 3, "metrics"], [12, 13, "task"], [15, 15, "task"], [18, 19, "task"], [21, 22, "task"], [25, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 25, 26, "named", "", true, false], [12, 13, 0, 3, "usage", "", true, false], [15, 15, 12, 13, "part-of", "", false, false], [18, 19, 12, 13, "part-of", "", false, false], [21, 22, 12, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "F", "-", "point", "is", "often", "used", "in", "the", "field", "of", "information", "retrieval", "to", "measure", "search", "performance", ",", "document", "classification", "and", "query", "classification", "and", "therefore", "F_beta", "finds", "wide", "application", "."], "sentence-detokenized": "The F-point is often used in the field of information retrieval to measure search performance, document classification and query classification and therefore F_beta finds wide application.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 20], [21, 25], [26, 28], [29, 32], [33, 38], [39, 41], [42, 53], [54, 63], [64, 66], [67, 74], [75, 81], [82, 93], [93, 94], [95, 103], [104, 118], [119, 122], [123, 128], [129, 143], [144, 147], [148, 157], [158, 164], [165, 170], [171, 175], [176, 187], [187, 188]]}
{"doc_key": "ai-dev-148", "ner": [[17, 18, "algorithm"], [20, 20, "algorithm"], [23, 24, "algorithm"], [26, 26, "algorithm"], [30, 32, "algorithm"], [34, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 20, 17, 18, "named", "", false, false], [26, 26, 23, 24, "named", "", false, false], [34, 34, 30, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "is", "done", "by", "modeling", "the", "received", "signal", ",", "then", "using", "a", "statistical", "estimation", "method", "such", "as", "maximum", "likelihood", "(", "ML", ")", ",", "majority", "voting", "(", "MV", ")", ",", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "to", "decide", "which", "target", "in", "the", "library", "best", "fits", "the", "model", "built", "using", "the", "received", "signal", "."], "sentence-detokenized": "This is done by modeling the received signal, then using a statistical estimation method such as maximum likelihood (ML), majority voting (MV), or maximum a posteriori (MAP) to decide which target in the library best fits the model built using the received signal.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 24], [25, 28], [29, 37], [38, 44], [44, 45], [46, 50], [51, 56], [57, 58], [59, 70], [71, 81], [82, 88], [89, 93], [94, 96], [97, 104], [105, 115], [116, 117], [117, 119], [119, 120], [120, 121], [122, 130], [131, 137], [138, 139], [139, 141], [141, 142], [142, 143], [144, 146], [147, 154], [155, 156], [157, 167], [168, 169], [169, 172], [172, 173], [174, 176], [177, 183], [184, 189], [190, 196], [197, 199], [200, 203], [204, 211], [212, 216], [217, 221], [222, 225], [226, 231], [232, 237], [238, 243], [244, 247], [248, 256], [257, 263], [263, 264]]}
{"doc_key": "ai-dev-149", "ner": [[0, 0, "researcher"], [3, 3, "misc"], [5, 5, "field"], [8, 11, "university"], [16, 16, "misc"], [18, 19, "field"], [21, 22, "university"], [28, 29, "misc"], [30, 31, "field"], [34, 36, "university"], [44, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 0, 8, 11, "physical", "", false, false], [0, 0, 8, 11, "role", "", false, false], [0, 0, 21, 22, "physical", "", false, false], [0, 0, 21, 22, "role", "", false, false], [0, 0, 34, 36, "physical", "", false, false], [0, 0, 34, 36, "role", "", false, false], [3, 3, 0, 0, "origin", "", false, false], [3, 3, 5, 5, "topic", "", false, false], [16, 16, 0, 0, "origin", "", false, false], [16, 16, 18, 19, "topic", "", false, false], [28, 29, 0, 0, "origin", "", false, false], [28, 29, 30, 31, "topic", "", false, false], [44, 53, 28, 29, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Sova", "received", "his", "B.S.", "in", "mathematics", "from", "the", "Massachusetts", "Institute", "of", "Technology", "in", "1962", ",", "his", "M.S.", "in", "applied", "mathematics", "from", "Harvard", "University", "in", "1966", ",", "and", "his", "Ph.D.", "in", "computer", "science", "from", "the", "Vrije", "Universiteit", "Brussel", "in", "1999", ",", "with", "a", "dissertation", "entitled", "Knowledge", "Representation", ":", "Logical", ",", "Philosophical", ",", "and", "Computational", "Foundations", "."], "sentence-detokenized": "Sova received his B.S. in mathematics from the Massachusetts Institute of Technology in 1962, his M.S. in applied mathematics from Harvard University in 1966, and his Ph.D. in computer science from the Vrije Universiteit Brussel in 1999, with a dissertation entitled Knowledge Representation: Logical, Philosophical, and Computational Foundations.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 22], [23, 25], [26, 37], [38, 42], [43, 46], [47, 60], [61, 70], [71, 73], [74, 84], [85, 87], [88, 92], [92, 93], [94, 97], [98, 102], [103, 105], [106, 113], [114, 125], [126, 130], [131, 138], [139, 149], [150, 152], [153, 157], [157, 158], [159, 162], [163, 166], [167, 172], [173, 175], [176, 184], [185, 192], [193, 197], [198, 201], [202, 207], [208, 220], [221, 228], [229, 231], [232, 236], [236, 237], [238, 242], [243, 244], [245, 257], [258, 266], [267, 276], [277, 291], [291, 292], [293, 300], [300, 301], [302, 315], [315, 316], [317, 320], [321, 334], [335, 346], [346, 347]]}
{"doc_key": "ai-dev-150", "ner": [[1, 4, "task"], [10, 10, "task"], [18, 18, "metrics"], [20, 21, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 4, 10, 10, "general-affiliation", "", false, false], [18, 18, 1, 4, "part-of", "", true, false], [20, 21, 1, 4, "part-of", "", true, false], [24, 25, 1, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "paraphrase", "recognition", "can", "be", "posed", "as", "a", "classification", "problem", ",", "most", "standard", "evaluation", "metrics", ",", "such", "as", "accuracy", ",", "f1", "score", ",", "or", "ROC", "curve", ",", "perform", "reasonably", "well", "."], "sentence-detokenized": "Since paraphrase recognition can be posed as a classification problem, most standard evaluation metrics, such as accuracy, f1 score, or ROC curve, perform reasonably well.", "token2charspan": [[0, 5], [6, 16], [17, 28], [29, 32], [33, 35], [36, 41], [42, 44], [45, 46], [47, 61], [62, 69], [69, 70], [71, 75], [76, 84], [85, 95], [96, 103], [103, 104], [105, 109], [110, 112], [113, 121], [121, 122], [123, 125], [126, 131], [131, 132], [133, 135], [136, 139], [140, 145], [145, 146], [147, 154], [155, 165], [166, 170], [170, 171]]}
{"doc_key": "ai-dev-151", "ner": [[19, 21, "algorithm"], [29, 30, "algorithm"], [32, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 21, 29, 30, "opposite", "not_suited_for", false, false], [19, 21, 32, 36, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "makes", "it", "practical", "for", "the", "analysis", "of", "large", "datasets", "(", "hundreds", "or", "thousands", "of", "taxa", ")", "and", "for", "bootstrapping", ",", "for", "which", "other", "analysis", "methods", "(", "e.g.", ",", "maximum", "parsimony", ",", "maximum", "likelihood", ")", "may", "prove", "computationally", "prohibitive", "."], "sentence-detokenized": "This makes it practical for the analysis of large datasets (hundreds or thousands of taxa) and for bootstrapping, for which other analysis methods (e.g., maximum parsimony, maximum likelihood) may prove computationally prohibitive.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 31], [32, 40], [41, 43], [44, 49], [50, 58], [59, 60], [60, 68], [69, 71], [72, 81], [82, 84], [85, 89], [89, 90], [91, 94], [95, 98], [99, 112], [112, 113], [114, 117], [118, 123], [124, 129], [130, 138], [139, 146], [147, 148], [148, 152], [152, 153], [154, 161], [162, 171], [171, 172], [173, 180], [181, 191], [191, 192], [193, 196], [197, 202], [203, 218], [219, 230], [230, 231]]}
{"doc_key": "ai-dev-152", "ner": [[4, 6, "programlang"], [12, 15, "organisation"], [17, 20, "organisation"], [27, 27, "programlang"], [31, 42, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[17, 20, 12, 15, "named", "", false, false], [31, 42, 4, 6, "role", "submits", true, false], [31, 42, 12, 15, "role", "submits_to", true, false]], "relations_mapping_to_source": [1, 3, 4], "sentence": ["The", "submission", "of", "the", "DAML", "+", "OIL", "language", "in", "2002", "to", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", "was", "the", "result", "of", "work", "done", "by", "the", "DAML", "implementers", "and", "the", "European", "Union", "-", "United", "States", "Ad", "Hoc", "Joint", "Committee", "on", "Markup", "Languages", "."], "sentence-detokenized": "The submission of the DAML+OIL language in 2002 to the World Wide Web Consortium (W3C) was the result of work done by the DAML implementers and the European Union-United States Ad Hoc Joint Committee on Markup Languages.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 21], [22, 26], [26, 27], [27, 30], [31, 39], [40, 42], [43, 47], [48, 50], [51, 54], [55, 60], [61, 65], [66, 69], [70, 80], [81, 82], [82, 85], [85, 86], [87, 90], [91, 94], [95, 101], [102, 104], [105, 109], [110, 114], [115, 117], [118, 121], [122, 126], [127, 139], [140, 143], [144, 147], [148, 156], [157, 162], [162, 163], [163, 169], [170, 176], [177, 179], [180, 183], [184, 189], [190, 199], [200, 202], [203, 209], [210, 219], [219, 220]]}
{"doc_key": "ai-dev-153", "ner": [[3, 4, "misc"], [7, 8, "misc"], [11, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 3, 4, "part-of", "", true, false], [11, 17, 3, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "nonlinear", "normalization", "is", "when", "the", "normalization", "follows", "a", "sigmoidal", "function", ",", "in", "which", "case", "the", "normalized", "image", "is", "calculated", "using", "the", "formula"], "sentence-detokenized": "An example of nonlinear normalization is when the normalization follows a sigmoidal function, in which case the normalized image is calculated using the formula", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 23], [24, 37], [38, 40], [41, 45], [46, 49], [50, 63], [64, 71], [72, 73], [74, 83], [84, 92], [92, 93], [94, 96], [97, 102], [103, 107], [108, 111], [112, 122], [123, 128], [129, 131], [132, 142], [143, 148], [149, 152], [153, 160]]}
{"doc_key": "ai-dev-154", "ner": [[10, 10, "metrics"], [15, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 10, 15, 15, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "is", "pointed", "out", "that", "to", "overcome", "this", "problem", ",", "precision", "is", "usually", "combined", "with", "re-retrieval", "."], "sentence-detokenized": "It is pointed out that to overcome this problem, precision is usually combined with re-retrieval.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 17], [18, 22], [23, 25], [26, 34], [35, 39], [40, 47], [47, 48], [49, 58], [59, 61], [62, 69], [70, 78], [79, 83], [84, 96], [96, 97]]}
{"doc_key": "ai-dev-155", "ner": [[4, 6, "metrics"], [8, 10, "metrics"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 19, 8, 10, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Commonly", "used", "metrics", "are", "mean", "squared", "error", "and", "mean", "squared", "error", ",", "the", "latter", "being", "used", "in", "the", "Netflix", "Prize", "."], "sentence-detokenized": "Commonly used metrics are mean squared error and mean squared error, the latter being used in the Netflix Prize.", "token2charspan": [[0, 8], [9, 13], [14, 21], [22, 25], [26, 30], [31, 38], [39, 44], [45, 48], [49, 53], [54, 61], [62, 67], [67, 68], [69, 72], [73, 79], [80, 85], [86, 90], [91, 93], [94, 97], [98, 105], [106, 111], [111, 112]]}
{"doc_key": "ai-dev-156", "ner": [[10, 16, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "August", "2016", ",", "a", "research", "programme", "was", "announced", "with", "University", "College", "Hospital", "with", "the", "aim", "of", "developing", "an", "algorithm", "to", "automatically", "distinguish", "between", "healthy", "and", "cancerous", "tissue", "in", "the", "head", "and", "neck", "region", "."], "sentence-detokenized": "In August 2016, a research programme was announced with University College Hospital with the aim of developing an algorithm to automatically distinguish between healthy and cancerous tissue in the head and neck region.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 17], [18, 26], [27, 36], [37, 40], [41, 50], [51, 55], [56, 66], [67, 74], [75, 83], [84, 88], [89, 92], [93, 96], [97, 99], [100, 110], [111, 113], [114, 123], [124, 126], [127, 140], [141, 152], [153, 160], [161, 168], [169, 172], [173, 182], [183, 189], [190, 192], [193, 196], [197, 201], [202, 205], [206, 210], [211, 217], [217, 218]]}
{"doc_key": "ai-dev-157", "ner": [[3, 10, "researcher"], [16, 18, "organisation"], [21, 24, "organisation"], [27, 30, "organisation"], [33, 38, "organisation"], [41, 47, "organisation"], [51, 54, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 10, 16, 18, "role", "", false, false], [3, 10, 21, 24, "role", "", false, false], [3, 10, 27, 30, "role", "", false, false], [3, 10, 33, 38, "role", "", false, false], [3, 10, 41, 47, "role", "", false, false], [3, 10, 51, 54, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "influence", "of", "Posner", "'s", "theoretical", "and", "empirical", "contributions", "has", "been", "recognized", "through", "membership", "in", "the", "American", "Psychological", "Association", ",", "the", "Association", "for", "Psychological", "Science", ",", "the", "Society", "of", "Experimental", "Psychologists", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "The influence of Posner's theoretical and empirical contributions has been recognized through membership in the American Psychological Association, the Association for Psychological Science, the Society of Experimental Psychologists, the American Academy of Arts and Sciences, the American Association for the Advancement of Science, and the National Academy of Sciences.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 23], [23, 25], [26, 37], [38, 41], [42, 51], [52, 65], [66, 69], [70, 74], [75, 85], [86, 93], [94, 104], [105, 107], [108, 111], [112, 120], [121, 134], [135, 146], [146, 147], [148, 151], [152, 163], [164, 167], [168, 181], [182, 189], [189, 190], [191, 194], [195, 202], [203, 205], [206, 218], [219, 232], [232, 233], [234, 237], [238, 246], [247, 254], [255, 257], [258, 262], [263, 266], [267, 275], [275, 276], [277, 280], [281, 289], [290, 301], [302, 305], [306, 309], [310, 321], [322, 324], [325, 332], [332, 333], [334, 337], [338, 341], [342, 350], [351, 358], [359, 361], [362, 370], [370, 371]]}
{"doc_key": "ai-dev-158", "ner": [[2, 3, "product"], [7, 8, "field"], [12, 13, "task"], [15, 17, "task"], [19, 19, "task"], [22, 24, "task"], [26, 26, "task"], [29, 30, "field"], [33, 34, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 3, 7, 8, "usage", "", false, false], [12, 13, 7, 8, "part-of", "", false, false], [15, 17, 7, 8, "part-of", "", false, false], [19, 19, 15, 17, "named", "", false, false], [22, 24, 7, 8, "part-of", "", false, false], [26, 26, 22, 24, "named", "", false, false], [29, 30, 7, 8, "part-of", "", false, false], [33, 34, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["These", "intelligent", "chatbots", "use", "all", "kinds", "of", "artificial", "intelligence", ",", "such", "as", "image", "moderation", "and", "natural", "language", "understanding", "(", "NLU", ")", ",", "natural", "language", "generation", "(", "NLG", ")", ",", "machine", "learning", ",", "and", "deep", "learning", "."], "sentence-detokenized": "These intelligent chatbots use all kinds of artificial intelligence, such as image moderation and natural language understanding (NLU), natural language generation (NLG), machine learning, and deep learning.", "token2charspan": [[0, 5], [6, 17], [18, 26], [27, 30], [31, 34], [35, 40], [41, 43], [44, 54], [55, 67], [67, 68], [69, 73], [74, 76], [77, 82], [83, 93], [94, 97], [98, 105], [106, 114], [115, 128], [129, 130], [130, 133], [133, 134], [134, 135], [136, 143], [144, 152], [153, 163], [164, 165], [165, 168], [168, 169], [169, 170], [171, 178], [179, 187], [187, 188], [189, 192], [193, 197], [198, 206], [206, 207]]}
{"doc_key": "ai-dev-159", "ner": [[5, 7, "metrics"], [9, 9, "metrics"], [13, 13, "metrics"], [16, 23, "metrics"], [30, 32, "metrics"], [34, 34, "metrics"], [37, 43, "metrics"], [47, 49, "metrics"], [51, 51, "metrics"], [54, 60, "metrics"], [67, 69, "metrics"], [71, 71, "metrics"], [74, 80, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[9, 9, 5, 7, "named", "", false, false], [13, 13, 5, 7, "named", "", false, false], [16, 23, 5, 7, "named", "", false, false], [34, 34, 30, 32, "named", "", false, false], [37, 43, 30, 32, "named", "", false, false], [51, 51, 47, 49, "named", "", false, false], [54, 60, 47, 49, "named", "", false, false], [71, 71, 67, 69, "named", "", false, false], [74, 80, 67, 69, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "row", "ratios", "are", ":", "positive", "predictive", "value", "(", "PPV", ",", "also", "called", "precision", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "with", "the", "addition", "of", "the", "false", "detection", "rate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "and", "negative", "predictive", "value", "(", "NPV", ")", "(", "TN/", "(", "TN", "+", "FN", ")", ")", ",", "with", "the", "addition", "of", "the", "false", "miss", "rate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "The row ratios are: positive predictive value (PPV, also called precision) (TP/(TP + FP)), with the addition of the false detection rate (FDR) (FP/(TP + FP)); and negative predictive value (NPV) (TN/(TN + FN)), with the addition of the false miss rate (FOR) (FN/(TN + FN)).", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 18], [18, 19], [20, 28], [29, 39], [40, 45], [46, 47], [47, 50], [50, 51], [52, 56], [57, 63], [64, 73], [73, 74], [75, 76], [76, 78], [78, 79], [79, 80], [80, 82], [83, 84], [85, 87], [87, 88], [88, 89], [89, 90], [91, 95], [96, 99], [100, 108], [109, 111], [112, 115], [116, 121], [122, 131], [132, 136], [137, 138], [138, 141], [141, 142], [143, 144], [144, 146], [146, 147], [147, 148], [148, 150], [151, 152], [153, 155], [155, 156], [156, 157], [157, 158], [159, 162], [163, 171], [172, 182], [183, 188], [189, 190], [190, 193], [193, 194], [195, 196], [196, 199], [199, 200], [200, 202], [203, 204], [205, 207], [207, 208], [208, 209], [209, 210], [211, 215], [216, 219], [220, 228], [229, 231], [232, 235], [236, 241], [242, 246], [247, 251], [252, 253], [253, 256], [256, 257], [258, 259], [259, 261], [261, 262], [262, 263], [263, 265], [266, 267], [268, 270], [270, 271], [271, 272], [272, 273]]}
{"doc_key": "ai-dev-160", "ner": [[8, 9, "misc"], [15, 16, "algorithm"], [18, 18, "algorithm"], [22, 24, "algorithm"], [26, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[18, 18, 15, 16, "named", "", false, false], [26, 26, 22, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "information", "is", "a", "mixture", "of", "sitemaps", "and", "RSS", "feeds", "and", "was", "created", "using", "the", "Information", "Model", "(", "IM", ")", "and", "the", "Biomedical", "Resource", "Ontology", "(", "BRO", ")", "."], "sentence-detokenized": "The information is a mixture of sitemaps and RSS feeds and was created using the Information Model (IM) and the Biomedical Resource Ontology (BRO).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 20], [21, 28], [29, 31], [32, 40], [41, 44], [45, 48], [49, 54], [55, 58], [59, 62], [63, 70], [71, 76], [77, 80], [81, 92], [93, 98], [99, 100], [100, 102], [102, 103], [104, 107], [108, 111], [112, 122], [123, 131], [132, 140], [141, 142], [142, 145], [145, 146], [146, 147]]}
{"doc_key": "ai-dev-161", "ner": [[2, 3, "task"], [8, 10, "algorithm"], [12, 16, "algorithm"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 12, 16, "origin", "based_on", false, false], [12, 16, 8, 10, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "latter", "text", "recognition", "is", "based", "on", "a", "recurrent", "neural", "network", "(", "long", "short", "-", "term", "memory", ")", "and", "does", "not", "require", "a", "language", "model", "."], "sentence-detokenized": "The latter text recognition is based on a recurrent neural network (long short-term memory) and does not require a language model.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 27], [28, 30], [31, 36], [37, 39], [40, 41], [42, 51], [52, 58], [59, 66], [67, 68], [68, 72], [73, 78], [78, 79], [79, 83], [84, 90], [90, 91], [92, 95], [96, 100], [101, 104], [105, 112], [113, 114], [115, 123], [124, 129], [129, 130]]}
{"doc_key": "ai-dev-162", "ner": [[1, 2, "misc"], [5, 6, "metrics"], [9, 10, "algorithm"], [14, 15, "metrics"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 1, 2, "type-of", "", false, false], [9, 10, 5, 6, "related-to", "", true, false], [14, 15, 1, 2, "type-of", "", false, false], [18, 19, 14, 15, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Popular", "loss", "functions", "include", "the", "pivot", "loss", "(", "for", "linear", "SVMs", ")", "and", "the", "log", "loss", "(", "for", "logistic", "regression", ")", "."], "sentence-detokenized": "Popular loss functions include the pivot loss (for linear SVMs) and the log loss (for logistic regression).", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 30], [31, 34], [35, 40], [41, 45], [46, 47], [47, 50], [51, 57], [58, 62], [62, 63], [64, 67], [68, 71], [72, 75], [76, 80], [81, 82], [82, 85], [86, 94], [95, 105], [105, 106], [106, 107]]}
{"doc_key": "ai-dev-163", "ner": [[0, 0, "metrics"], [10, 16, "metrics"], [18, 18, "metrics"], [21, 23, "metrics"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 10, 16, "compare", "", false, false], [0, 0, 21, 23, "compare", "", false, false], [18, 18, 10, 16, "named", "", false, false], [25, 25, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "is", "designed", "to", "improve", "on", "traditional", "methods", "such", "as", "peak", "signal", "-", "to", "-", "noise", "ratio", "(", "PSNR", ")", "and", "mean", "squared", "error", "(", "MSE", ")", "."], "sentence-detokenized": "SSIM is designed to improve on traditional methods such as peak signal-to-noise ratio (PSNR) and mean squared error (MSE).", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 27], [28, 30], [31, 42], [43, 50], [51, 55], [56, 58], [59, 63], [64, 70], [70, 71], [71, 73], [73, 74], [74, 79], [80, 85], [86, 87], [87, 91], [91, 92], [93, 96], [97, 101], [102, 109], [110, 115], [116, 117], [117, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-dev-164", "ner": [[11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "inspired", "the", "next", "generation", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "His work inspired the next generation of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 26], [27, 37], [38, 40], [41, 49], [50, 61], [62, 66], [67, 69], [70, 76], [77, 83], [83, 84], [85, 89], [90, 97], [98, 101], [102, 106], [107, 113], [113, 114]]}
{"doc_key": "ai-dev-165", "ner": [[10, 13, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 10, 13, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "addition", ",", "pulse", "learning", "is", "non-differentiable", ",", "which", "eliminates", "back", "-", "propagation", "based", "learning", "methods", "such", "as", "gradient", "descent", "."], "sentence-detokenized": "In addition, pulse learning is non-differentiable, which eliminates back-propagation based learning methods such as gradient descent.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 18], [19, 27], [28, 30], [31, 49], [49, 50], [51, 56], [57, 67], [68, 72], [72, 73], [73, 84], [85, 90], [91, 99], [100, 107], [108, 112], [113, 115], [116, 124], [125, 132], [132, 133]]}
{"doc_key": "ai-dev-166", "ner": [[8, 9, "metrics"], [16, 17, "metrics"], [19, 19, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 16, 17, "related-to", "describes", false, false], [16, 17, 19, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "relations", "can", "be", "easily", "represented", "by", "a", "confusion", "matrix", ",", "a", "table", "that", "describes", "the", "accuracy", "of", "a", "classification", "model", "."], "sentence-detokenized": "These relations can be easily represented by a confusion matrix, a table that describes the accuracy of a classification model.", "token2charspan": [[0, 5], [6, 15], [16, 19], [20, 22], [23, 29], [30, 41], [42, 44], [45, 46], [47, 56], [57, 63], [63, 64], [65, 66], [67, 72], [73, 77], [78, 87], [88, 91], [92, 100], [101, 103], [104, 105], [106, 120], [121, 126], [126, 127]]}
{"doc_key": "ai-dev-167", "ner": [[2, 10, "conference"], [8, 8, "conference"], [14, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 2, 10, "named", "", false, false], [14, 14, 2, 10, "physical", "", false, false], [14, 14, 2, 10, "role", "", false, false], [14, 14, 2, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["At", "the", "2018", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "conference", ",", "researchers", "from", "Google", "presented", "work"], "sentence-detokenized": "At the 2018 Neural Information Processing Systems (NeurIPS) conference, researchers from Google presented work", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 30], [31, 41], [42, 49], [50, 51], [51, 58], [58, 59], [60, 70], [70, 71], [72, 83], [84, 88], [89, 95], [96, 105], [106, 110]]}
{"doc_key": "ai-dev-168", "ner": [[4, 4, "university"], [13, 14, "product"], [19, 22, "misc"], [23, 23, "conference"], [30, 33, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 14, 19, 22, "win-defeat", "", false, false], [19, 22, 23, 23, "temporal", "", false, false], [30, 33, 23, 23, "part-of", "", false, false], [30, 33, 23, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "his", "time", "at", "Duke", ",", "he", "worked", "on", "an", "automatic", "crossword", "solver", ",", "PROVERB", ",", "which", "won", "the", "Outstanding", "Paper", "Award", "from", "AAAI", "in", "1999", "and", "participated", "in", "the", "American", "Crossword", "Solving", "Tournament", "."], "sentence-detokenized": "During his time at Duke, he worked on an automatic crossword solver, PROVERB, which won the Outstanding Paper Award from AAAI in 1999 and participated in the American Crossword Solving Tournament.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 18], [19, 23], [23, 24], [25, 27], [28, 34], [35, 37], [38, 40], [41, 50], [51, 60], [61, 67], [67, 68], [69, 76], [76, 77], [78, 83], [84, 87], [88, 91], [92, 103], [104, 109], [110, 115], [116, 120], [121, 125], [126, 128], [129, 133], [134, 137], [138, 150], [151, 153], [154, 157], [158, 166], [167, 176], [177, 184], [185, 195], [195, 196]]}
{"doc_key": "ai-dev-169", "ner": [[2, 3, "location"], [5, 5, "location"], [14, 16, "country"], [18, 18, "country"], [20, 20, "country"], [22, 22, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 5, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Headquartered", "in", "Rochester", "Hills", ",", "Michigan", ",", "the", "company", "has", "10", "regional", "locations", "in", "the", "United", "States", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "sentence-detokenized": "Headquartered in Rochester Hills, Michigan, the company has 10 regional locations in the United States , Canada, Mexico and Brazil.", "token2charspan": [[0, 13], [14, 16], [17, 26], [27, 32], [32, 33], [34, 42], [42, 43], [44, 47], [48, 55], [56, 59], [60, 62], [63, 71], [72, 81], [82, 84], [85, 88], [89, 95], [96, 102], [103, 104], [105, 111], [111, 112], [113, 119], [120, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-dev-170", "ner": [[12, 12, "product"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "joins", "a", "collection", "of", "historically", "important", "robots", "that", "includes", "an", "early", "Unimate", "and", "an", "Odetics", "Odex", "1", "."], "sentence-detokenized": "He joins a collection of historically important robots that includes an early Unimate and an Odetics Odex 1.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 21], [22, 24], [25, 37], [38, 47], [48, 54], [55, 59], [60, 68], [69, 71], [72, 77], [78, 85], [86, 89], [90, 92], [93, 100], [101, 105], [106, 107], [107, 108]]}
{"doc_key": "ai-dev-171", "ner": [[7, 7, "researcher"], [12, 12, "organisation"], [14, 17, "researcher"], [22, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 12, 12, "physical", "", false, false], [7, 7, 12, 12, "role", "", false, false], [14, 17, 12, 12, "physical", "", false, false], [14, 17, 12, 12, "role", "", false, false], [14, 17, 22, 27, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["This", "issue", "'s", "guest", "editor", "will", "be", "David", "'s", "former", "colleague", "at", "NIST", ",", "Judah", "Levine", ",", "who", "is", "the", "most", "recent", "I.I", ".", "Award", "winner", ".", "Rabi", "."], "sentence-detokenized": "This issue's guest editor will be David's former colleague at NIST, Judah Levine, who is the most recent I.I. Award winner. Rabi.", "token2charspan": [[0, 4], [5, 10], [10, 12], [13, 18], [19, 25], [26, 30], [31, 33], [34, 39], [39, 41], [42, 48], [49, 58], [59, 61], [62, 66], [66, 67], [68, 73], [74, 80], [80, 81], [82, 85], [86, 88], [89, 92], [93, 97], [98, 104], [105, 108], [108, 109], [110, 115], [116, 122], [122, 123], [124, 128], [128, 129]]}
{"doc_key": "ai-dev-172", "ner": [[12, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "can", "be", "arranged", "in", "a", "2", "\u00d7", "2", "contingency", "table", "(", "confusion", "matrix", ")", ",", "usually", "with", "the", "test", "result", "on", "the", "vertical", "axis", "and", "the", "actual", "condition", "on", "the", "horizontal", "axis", "."], "sentence-detokenized": "They can be arranged in a 2 \u00d7 2 contingency table (confusion matrix), usually with the test result on the vertical axis and the actual condition on the horizontal axis.", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 20], [21, 23], [24, 25], [26, 27], [28, 29], [30, 31], [32, 43], [44, 49], [50, 51], [51, 60], [61, 67], [67, 68], [68, 69], [70, 77], [78, 82], [83, 86], [87, 91], [92, 98], [99, 101], [102, 105], [106, 114], [115, 119], [120, 123], [124, 127], [128, 134], [135, 144], [145, 147], [148, 151], [152, 162], [163, 167], [167, 168]]}
{"doc_key": "ai-dev-173", "ner": [[0, 4, "product"], [9, 9, "product"], [11, 11, "product"], [13, 14, "product"], [18, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 9, 9, "part-of", "", false, false], [0, 4, 11, 11, "part-of", "", false, false], [0, 4, 13, 14, "part-of", "", false, false], [0, 4, 18, 20, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Apple", "'s", "iOS", "operating", "system", ",", "used", "in", "the", "iPhone", ",", "iPad", "and", "iPod", "Touch", ",", "uses", "the", "VoiceOver", "speech", "synthesis", "feature", "."], "sentence-detokenized": "Apple's iOS operating system, used in the iPhone, iPad and iPod Touch, uses the VoiceOver speech synthesis feature.", "token2charspan": [[0, 5], [5, 7], [8, 11], [12, 21], [22, 28], [28, 29], [30, 34], [35, 37], [38, 41], [42, 48], [48, 49], [50, 54], [55, 58], [59, 63], [64, 69], [69, 70], [71, 75], [76, 79], [80, 89], [90, 96], [97, 106], [107, 114], [114, 115]]}
{"doc_key": "ai-dev-174", "ner": [[7, 9, "conference"], [15, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "the", "best", "system", "entering", "MUC", "-", "7", "achieved", "93.39", "%", "of", "the", "F", "-", "measure", ",", "while", "the", "human", "annotators", "obtained", "97.6", "%", "and", "96.95", "%", "."], "sentence-detokenized": "For example, the best system entering MUC-7 achieved 93.39% of the F-measure, while the human annotators obtained 97.6% and 96.95%.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 37], [38, 41], [41, 42], [42, 43], [44, 52], [53, 58], [58, 59], [60, 62], [63, 66], [67, 68], [68, 69], [69, 76], [76, 77], [78, 83], [84, 87], [88, 93], [94, 104], [105, 113], [114, 118], [118, 119], [120, 123], [124, 129], [129, 130], [130, 131]]}
{"doc_key": "ai-dev-175", "ner": [[12, 14, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 16, 12, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "done", "using", "standard", "neural", "network", "learning", "algorithms", ",", "such", "as", "stochastic", "gradient", "descent", "with", "backpropagation", "."], "sentence-detokenized": "This is done using standard neural network learning algorithms, such as stochastic gradient descent with backpropagation.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 18], [19, 27], [28, 34], [35, 42], [43, 51], [52, 62], [62, 63], [64, 68], [69, 71], [72, 82], [83, 91], [92, 99], [100, 104], [105, 120], [120, 121]]}
{"doc_key": "ai-dev-176", "ner": [[0, 1, "organisation"], [16, 16, "country"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 16, 16, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "is", "a", "top", "1000", "site", ",", "ranking", "about", "400th", "globally", "and", "150th", "in", "the", "US", "alone", ",", "according", "to", "Alexa", "'s", "rankings", "."], "sentence-detokenized": "Rotten Tomatoes is a top 1000 site, ranking about 400th globally and 150th in the US alone, according to Alexa's rankings.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 20], [21, 24], [25, 29], [30, 34], [34, 35], [36, 43], [44, 49], [50, 55], [56, 64], [65, 68], [69, 74], [75, 77], [78, 81], [82, 84], [85, 90], [90, 91], [92, 101], [102, 104], [105, 110], [110, 112], [113, 121], [121, 122]]}
{"doc_key": "ai-dev-177", "ner": [[15, 17, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "general", ",", "each", "training", "shows", "a", "gradual", "change", "over", "time", ",", "but", "describes", "a", "sigmoid", "function", "that", "has", "different", "manifestations", "depending", "on", "the", "time", "scale", "of", "the", "observation", "."], "sentence-detokenized": "In general, each training shows a gradual change over time, but describes a sigmoid function that has different manifestations depending on the time scale of the observation.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [17, 25], [26, 31], [32, 33], [34, 41], [42, 48], [49, 53], [54, 58], [58, 59], [60, 63], [64, 73], [74, 75], [76, 83], [84, 92], [93, 97], [98, 101], [102, 111], [112, 126], [127, 136], [137, 139], [140, 143], [144, 148], [149, 154], [155, 157], [158, 161], [162, 173], [173, 174]]}
{"doc_key": "ai-dev-178", "ner": [[0, 0, "metrics"], [5, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["SSD", "is", "also", "known", "as", "mean", "squared", "error", "."], "sentence-detokenized": "SSD is also known as mean squared error.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 17], [18, 20], [21, 25], [26, 33], [34, 39], [39, 40]]}
{"doc_key": "ai-dev-179", "ner": [[0, 3, "algorithm"], [5, 6, "algorithm"], [9, 16, "algorithm"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 23, 24, "related-to", "can_be_related_to", true, false], [5, 6, 23, 24, "related-to", "can_be_related_to", true, false], [9, 16, 23, 24, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Learning", "with", "decision", "trees", ",", "neural", "networks", "or", "a", "naive", "Bayes", "classifier", "can", "be", "used", "in", "combination", "with", "model", "quality", "measures", "such", "as", "balanced", "accuracy", "."], "sentence-detokenized": "Learning with decision trees, neural networks or a naive Bayes classifier can be used in combination with model quality measures such as balanced accuracy.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 28], [28, 29], [30, 36], [37, 45], [46, 48], [49, 50], [51, 56], [57, 62], [63, 73], [74, 77], [78, 80], [81, 85], [86, 88], [89, 100], [101, 105], [106, 111], [112, 119], [120, 128], [129, 133], [134, 136], [137, 145], [146, 154], [154, 155]]}
{"doc_key": "ai-dev-180", "ner": [[16, 16, "conference"], [22, 33, "conference"], [26, 31, "misc"], [37, 39, "product"], [46, 49, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[26, 31, 22, 33, "origin", "", false, false], [26, 31, 22, 33, "temporal", "", false, false], [37, 39, 26, 31, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "is", "a", "past", "president", "(", "1979", ")", "and", "first", "member", "(", "2011", ")", "of", "the", "ACL", ",", "a", "co-winner", "of", "the", "Association", "for", "Computing", "Machinery", "'s", "Software", "Systems", "Award", "in", "1992", "for", "his", "contributions", "to", "the", "Interlisp", "software", "system", ",", "and", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "He is a past president (1979) and first member (2011) of the ACL, a co-winner of the Association for Computing Machinery's Software Systems Award in 1992 for his contributions to the Interlisp software system, and a Fellow of the Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 22], [23, 24], [24, 28], [28, 29], [30, 33], [34, 39], [40, 46], [47, 48], [48, 52], [52, 53], [54, 56], [57, 60], [61, 64], [64, 65], [66, 67], [68, 77], [78, 80], [81, 84], [85, 96], [97, 100], [101, 110], [111, 120], [120, 122], [123, 131], [132, 139], [140, 145], [146, 148], [149, 153], [154, 157], [158, 161], [162, 175], [176, 178], [179, 182], [183, 192], [193, 201], [202, 208], [208, 209], [210, 213], [214, 215], [216, 222], [223, 225], [226, 229], [230, 241], [242, 245], [246, 255], [256, 265], [265, 266]]}
{"doc_key": "ai-dev-181", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 15, "researcher"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 27, 28, "related-to", "", false, false], [5, 6, 27, 28, "related-to", "", false, false], [8, 8, 27, 28, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Along", "with", "Jeffrey", "Hinton", "and", "Ian", "LeCun", ",", "Bengio", "is", "considered", "by", "Cade", "Metz", "to", "be", "one", "of", "the", "three", "people", "most", "responsible", "for", "the", "development", "of", "deep", "learning", "in", "the", "1990s", "and", "2000s", "."], "sentence-detokenized": "Along with Jeffrey Hinton and Ian LeCun, Bengio is considered by Cade Metz to be one of the three people most responsible for the development of deep learning in the 1990s and 2000s.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 25], [26, 29], [30, 33], [34, 39], [39, 40], [41, 47], [48, 50], [51, 61], [62, 64], [65, 69], [70, 74], [75, 77], [78, 80], [81, 84], [85, 87], [88, 91], [92, 97], [98, 104], [105, 109], [110, 121], [122, 125], [126, 129], [130, 141], [142, 144], [145, 149], [150, 158], [159, 161], [162, 165], [166, 171], [172, 175], [176, 181], [181, 182]]}
{"doc_key": "ai-dev-182", "ner": [[1, 2, "field"], [4, 5, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "information", "theory", "and", "computer", "science", ",", "code", "is", "usually", "viewed", "as", "an", "algorithm", "that", "uniquely", "represents", "characters", "from", "some", "source", "alphabet", "by", "encoded", "strings", "that", "may", "be", "in", "another", "target", "alphabet", "."], "sentence-detokenized": "In information theory and computer science, code is usually viewed as an algorithm that uniquely represents characters from some source alphabet by encoded strings that may be in another target alphabet.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 48], [49, 51], [52, 59], [60, 66], [67, 69], [70, 72], [73, 82], [83, 87], [88, 96], [97, 107], [108, 118], [119, 123], [124, 128], [129, 135], [136, 144], [145, 147], [148, 155], [156, 163], [164, 168], [169, 172], [173, 175], [176, 178], [179, 186], [187, 193], [194, 202], [202, 203]]}
{"doc_key": "ai-dev-183", "ner": [[7, 8, "algorithm"], [13, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 16, 7, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "relatively", "simple", "nonlinear", "function", ",", "the", "sigmoid", "function", ",", "such", "as", "the", "logistic", "function", ",", "also", "has", "an", "easily", "computable", "derivative", "that", "can", "be", "important", "in", "calculating", "weight", "updates", "in", "the", "network", "."], "sentence-detokenized": "A relatively simple nonlinear function, the sigmoid function, such as the logistic function, also has an easily computable derivative that can be important in calculating weight updates in the network.", "token2charspan": [[0, 1], [2, 12], [13, 19], [20, 29], [30, 38], [38, 39], [40, 43], [44, 51], [52, 60], [60, 61], [62, 66], [67, 69], [70, 73], [74, 82], [83, 91], [91, 92], [93, 97], [98, 101], [102, 104], [105, 111], [112, 122], [123, 133], [134, 138], [139, 142], [143, 145], [146, 155], [156, 158], [159, 170], [171, 177], [178, 185], [186, 188], [189, 192], [193, 200], [200, 201]]}
{"doc_key": "ai-dev-184", "ner": [[0, 1, "person"], [6, 6, "location"], [8, 8, "location"], [10, 12, "country"], [15, 15, "country"], [18, 20, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 6, 6, "physical", "", false, false], [6, 6, 8, 8, "physical", "", false, false], [8, 8, 10, 12, "physical", "", false, false], [8, 8, 15, 15, "physical", "", false, false], [8, 8, 18, 20, "physical", "", false, false], [15, 15, 10, 12, "origin", "", false, false], [18, 20, 15, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "was", "born", "in", "1887", "in", "Hronov", ",", "Bohemia", "(", "Austria", "-", "Hungary", ",", "later", "Czechoslovakia", ",", "now", "the", "Czech", "Republic", ")", "."], "sentence-detokenized": "\u010capek was born in 1887 in Hronov, Bohemia (Austria-Hungary, later Czechoslovakia, now the Czech Republic).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 41], [42, 43], [43, 50], [50, 51], [51, 58], [58, 59], [60, 65], [66, 80], [80, 81], [82, 85], [86, 89], [90, 95], [96, 104], [104, 105], [105, 106]]}
{"doc_key": "ai-dev-185", "ner": [[5, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "specialized", "software", "can", "tell", "RSS", "feeds", "."], "sentence-detokenized": "Some specialized software can tell RSS feeds.", "token2charspan": [[0, 4], [5, 16], [17, 25], [26, 29], [30, 34], [35, 38], [39, 44], [44, 45]]}
{"doc_key": "ai-dev-186", "ner": [[6, 7, "task"], [11, 12, "task"], [14, 14, "task"], [16, 16, "task"], [19, 20, "task"], [29, 31, "task"], [32, 33, "task"], [38, 39, "task"], [43, 45, "product"], [47, 48, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[6, 7, 11, 12, "related-to", "", true, false], [6, 7, 14, 14, "related-to", "", true, false], [6, 7, 16, 16, "related-to", "", true, false], [32, 33, 29, 31, "usage", "", true, false], [43, 45, 38, 39, "type-of", "", false, false], [47, 48, 38, 39, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Aspects", "of", "ontology", "editors", "include", ":", "visual", "navigation", "capabilities", "within", "the", "knowledge", "model", ",", "inference", "and", "extraction", "engines", ";", "module", "support", ";", "import", "and", "export", "of", "foreign", "languages", "for", "knowledge", "representation", "for", "ontology", "mapping", ";", "and", "support", "for", "meta", "-ontologies", ",", "such", "as", "OWL", "-", "S", ",", "Dublin", "Core", ",", "etc", "."], "sentence-detokenized": "Aspects of ontology editors include: visual navigation capabilities within the knowledge model, inference and extraction engines; module support; import and export of foreign languages for knowledge representation for ontology mapping; and support for meta-ontologies, such as OWL-S, Dublin Core, etc.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 27], [28, 35], [35, 36], [37, 43], [44, 54], [55, 67], [68, 74], [75, 78], [79, 88], [89, 94], [94, 95], [96, 105], [106, 109], [110, 120], [121, 128], [128, 129], [130, 136], [137, 144], [144, 145], [146, 152], [153, 156], [157, 163], [164, 166], [167, 174], [175, 184], [185, 188], [189, 198], [199, 213], [214, 217], [218, 226], [227, 234], [234, 235], [236, 239], [240, 247], [248, 251], [252, 256], [256, 267], [267, 268], [269, 273], [274, 276], [277, 280], [280, 281], [281, 282], [282, 283], [284, 290], [291, 295], [295, 296], [297, 300], [300, 301]]}
{"doc_key": "ai-dev-187", "ner": [[0, 3, "organisation"], [6, 11, "misc"], [13, 17, "task"], [20, 20, "field"], [23, 23, "misc"], [25, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 11, 0, 3, "origin", "", false, false], [13, 17, 6, 11, "part-of", "", false, false], [20, 20, 6, 11, "part-of", "", false, false], [23, 23, 20, 20, "type-of", "", false, false], [25, 30, 20, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "FBI", "has", "also", "introduced", "its", "Next", "Generation", "Identification", "program", ",", "which", "includes", "facial", "recognition", "as", "well", "as", "more", "traditional", "biometrics", "such", "as", "fingerprints", "and", "iris", "eye", "scans", "that", "can", "be", "used", "by", "both", "criminal", "and", "civilian", "databases", "."], "sentence-detokenized": "The FBI has also introduced its Next Generation Identification program, which includes facial recognition as well as more traditional biometrics such as fingerprints and iris eye scans that can be used by both criminal and civilian databases.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 27], [28, 31], [32, 36], [37, 47], [48, 62], [63, 70], [70, 71], [72, 77], [78, 86], [87, 93], [94, 105], [106, 108], [109, 113], [114, 116], [117, 121], [122, 133], [134, 144], [145, 149], [150, 152], [153, 165], [166, 169], [170, 174], [175, 178], [179, 184], [185, 189], [190, 193], [194, 196], [197, 201], [202, 204], [205, 209], [210, 218], [219, 222], [223, 231], [232, 241], [241, 242]]}
{"doc_key": "ai-dev-188", "ner": [[5, 7, "person"], [15, 16, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "2016", "season", ",", "Samantha", "Ponder", "was", "added", "as", "the", "lead", "in", "place", "of", "Molly", "McGrath", "."], "sentence-detokenized": "In the 2016 season, Samantha Ponder was added as the lead in place of Molly McGrath.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [18, 19], [20, 28], [29, 35], [36, 39], [40, 45], [46, 48], [49, 52], [53, 57], [58, 60], [61, 66], [67, 69], [70, 75], [76, 83], [83, 84]]}
{"doc_key": "ai-dev-189", "ner": [[3, 7, "algorithm"], [19, 23, "misc"], [25, 25, "misc"], [27, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "adversarial", "search", "algorithm", "that", "is", "commonly", "used", "to", "machine", "-", "play", "two", "-", "player", "games", "(", "tic", "-", "tac", "-", "toe", ",", "chess", ",", "Go", ",", "etc", "."], "sentence-detokenized": "This is an adversarial search algorithm that is commonly used to machine-play two-player games (tic-tac-toe, chess, Go, etc.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 29], [30, 39], [40, 44], [45, 47], [48, 56], [57, 61], [62, 64], [65, 72], [72, 73], [73, 77], [78, 81], [81, 82], [82, 88], [89, 94], [95, 96], [96, 99], [99, 100], [100, 103], [103, 104], [104, 107], [107, 108], [109, 114], [114, 115], [116, 118], [118, 119], [120, 123], [123, 124]]}
{"doc_key": "ai-dev-190", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 17, "field"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "involves", "the", "fields", "of", "computer", "vision", "or", "machine", "vision", "and", "medical", "imaging", "and", "makes", "extensive", "use", "of", "pattern", "recognition", ",", "digital", "geometry", "and", "signal", "processing", "."], "sentence-detokenized": "It involves the fields of computer vision or machine vision and medical imaging and makes extensive use of pattern recognition, digital geometry and signal processing.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 22], [23, 25], [26, 34], [35, 41], [42, 44], [45, 52], [53, 59], [60, 63], [64, 71], [72, 79], [80, 83], [84, 89], [90, 99], [100, 103], [104, 106], [107, 114], [115, 126], [126, 127], [128, 135], [136, 144], [145, 148], [149, 155], [156, 166], [166, 167]]}
{"doc_key": "ai-dev-191", "ner": [[2, 4, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "a", "facial", "recognition", "system", ",", "for", "example", ",", "the", "input", "is", "a", "picture", "of", "a", "person", "'s", "face", ",", "and", "the", "output", "label", "is", "that", "person", "'s", "name", "."], "sentence-detokenized": "In a facial recognition system, for example, the input is a picture of a person's face, and the output label is that person's name.", "token2charspan": [[0, 2], [3, 4], [5, 11], [12, 23], [24, 30], [30, 31], [32, 35], [36, 43], [43, 44], [45, 48], [49, 54], [55, 57], [58, 59], [60, 67], [68, 70], [71, 72], [73, 79], [79, 81], [82, 86], [86, 87], [88, 91], [92, 95], [96, 102], [103, 108], [109, 111], [112, 116], [117, 123], [123, 125], [126, 130], [130, 131]]}
{"doc_key": "ai-dev-192", "ner": [[0, 2, "organisation"], [5, 6, "product"], [11, 13, "product"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 6, "artifact", "", false, false], [5, 6, 11, 13, "part-of", "", false, false], [11, 13, 5, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc", "has", "introduced", "the", "Face", "ID", "feature", "in", "the", "flagship", "i", "Phone", "X", "as", "a", "successor", "to", "the", "fingerprint", "-", "based", "Touch", "ID", "biometric", "authentication", "system", "."], "sentence-detokenized": "Apple Inc has introduced the Face ID feature in the flagship iPhone X as a successor to the fingerprint-based Touch ID biometric authentication system.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 24], [25, 28], [29, 33], [34, 36], [37, 44], [45, 47], [48, 51], [52, 60], [61, 62], [62, 67], [68, 69], [70, 72], [73, 74], [75, 84], [85, 87], [88, 91], [92, 103], [103, 104], [104, 109], [110, 115], [116, 118], [119, 128], [129, 143], [144, 150], [150, 151]]}
{"doc_key": "ai-dev-193", "ner": [[2, 5, "metrics"], [8, 10, "metrics"], [21, 25, "metrics"], [28, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Either", "combine", "the", "F", "-", "measure", "with", "the", "R-", "squared", "estimated", "for", "the", "model", "'s", "raw", "output", "and", "target", ";", "or", "the", "cost", "/", "benefit", "matrix", "with", "the", "correlation", "coefficient", ",", "etc", "."], "sentence-detokenized": "Either combine the F-measure with the R-squared estimated for the model's raw output and target; or the cost/benefit matrix with the correlation coefficient, etc.", "token2charspan": [[0, 6], [7, 14], [15, 18], [19, 20], [20, 21], [21, 28], [29, 33], [34, 37], [38, 40], [40, 47], [48, 57], [58, 61], [62, 65], [66, 71], [71, 73], [74, 77], [78, 84], [85, 88], [89, 95], [95, 96], [97, 99], [100, 103], [104, 108], [108, 109], [109, 116], [117, 123], [124, 128], [129, 132], [133, 144], [145, 156], [156, 157], [158, 161], [161, 162]]}
{"doc_key": "ai-dev-194", "ner": [[6, 15, "conference"], [18, 20, "location"], [22, 22, "location"], [25, 29, "location"], [31, 31, "location"], [33, 37, "country"], [40, 42, "location"], [45, 49, "location"], [51, 51, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 15, 18, 20, "physical", "", false, false], [6, 15, 25, 29, "physical", "", false, false], [6, 15, 40, 42, "physical", "", false, false], [6, 15, 45, 49, "physical", "", false, false], [18, 20, 22, 22, "physical", "", false, false], [25, 29, 31, 31, "physical", "", false, false], [31, 31, 33, 37, "physical", "", false, false], [40, 42, 51, 51, "physical", "", false, false], [45, 49, 51, 51, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["For", "the", "past", "15", "years", ",", "the", "Spanish", "edition", "of", "the", "Campus", "Party", "has", "been", "held", "at", "the", "Colegio", "Miguel", "Hern\u00e1ndez", ",", "Ceulaj", "and", "the", "Municipal", "Sports", "Arena", "of", "Benalmadena", "in", "M\u00e1laga", ",", "Spain", ",", "as", "well", "as", "at", "the", "Valencia", "County", "Fair", "and", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "For the past 15 years, the Spanish edition of the Campus Party has been held at the Colegio Miguel Hern\u00e1ndez, Ceulaj and the Municipal Sports Arena of Benalmadena in M\u00e1laga, Spain, as well as at the Valencia County Fair and the City of Arts and Sciences in Valencia.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 15], [16, 21], [21, 22], [23, 26], [27, 34], [35, 42], [43, 45], [46, 49], [50, 56], [57, 62], [63, 66], [67, 71], [72, 76], [77, 79], [80, 83], [84, 91], [92, 98], [99, 108], [108, 109], [110, 116], [117, 120], [121, 124], [125, 134], [135, 141], [142, 147], [148, 150], [151, 162], [163, 165], [166, 172], [172, 173], [174, 179], [179, 180], [181, 183], [184, 188], [189, 191], [192, 194], [195, 198], [199, 207], [208, 214], [215, 219], [220, 223], [224, 227], [228, 232], [233, 235], [236, 240], [241, 244], [245, 253], [254, 256], [257, 265], [265, 266]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [16, 16, "programlang"], [20, 20, "product"], [22, 23, "product"], [26, 26, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 16, 0, 0, "general-affiliation", "", false, false], [20, 20, 16, 16, "part-of", "", false, false], [22, 23, 16, 16, "part-of", "", false, false], [26, 26, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["gnuplot", "can", "be", "used", "by", "a", "variety", "of", "programming", "languages", "for", "graphical", "data", "representation", ",", "including", "Perl", "(", "via", "the", "PDL", "and", "CPAN", "packages", ")", ",", "Python", "(", "via", ")", "."], "sentence-detokenized": "gnuplot can be used by a variety of programming languages for graphical data representation, including Perl (via the PDL and CPAN packages), Python (via).", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 19], [20, 22], [23, 24], [25, 32], [33, 35], [36, 47], [48, 57], [58, 61], [62, 71], [72, 76], [77, 91], [91, 92], [93, 102], [103, 107], [108, 109], [109, 112], [113, 116], [117, 120], [121, 124], [125, 129], [130, 138], [138, 139], [139, 140], [141, 147], [148, 149], [149, 152], [152, 153], [153, 154]]}
{"doc_key": "ai-dev-196", "ner": [[3, 5, "product"], [19, 19, "conference"], [21, 21, "conference"], [35, 35, "conference"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 3, 5, "topic", "", false, false], [21, 21, 3, 5, "topic", "", false, false], [35, 35, 3, 5, "topic", "", false, false], [37, 37, 3, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "field", "of", "spoken", "dialogue", "systems", "is", "quite", "large", "and", "includes", "research", "(", "presented", "at", "scientific", "conferences", "such", "as", "SIGdial", "and", "Interspeech", ")", "and", "a", "large", "industrial", "sector", "(", "with", "its", "own", "meetings", "such", "as", "SpeechTek", "and", "AVIOS", ")", "."], "sentence-detokenized": "The field of spoken dialogue systems is quite large and includes research (presented at scientific conferences such as SIGdial and Interspeech) and a large industrial sector (with its own meetings such as SpeechTek and AVIOS).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 28], [29, 36], [37, 39], [40, 45], [46, 51], [52, 55], [56, 64], [65, 73], [74, 75], [75, 84], [85, 87], [88, 98], [99, 110], [111, 115], [116, 118], [119, 126], [127, 130], [131, 142], [142, 143], [144, 147], [148, 149], [150, 155], [156, 166], [167, 173], [174, 175], [175, 179], [180, 183], [184, 187], [188, 196], [197, 201], [202, 204], [205, 214], [215, 218], [219, 224], [224, 225], [225, 226]]}
{"doc_key": "ai-dev-197", "ner": [[0, 2, "field"], [6, 7, "task"], [9, 11, "task"], [14, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 0, 2, "part-of", "task_part_of_field", false, false], [9, 11, 0, 2, "part-of", "task_part_of_field", false, false], [14, 16, 0, 2, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Natural", "language", "processing", "challenges", "often", "include", "speech", "recognition", ",", "natural", "language", "understanding", ",", "and", "natural", "language", "generation", "."], "sentence-detokenized": "Natural language processing challenges often include speech recognition, natural language understanding, and natural language generation.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 38], [39, 44], [45, 52], [53, 59], [60, 71], [71, 72], [73, 80], [81, 89], [90, 103], [103, 104], [105, 108], [109, 116], [117, 125], [126, 136], [136, 137]]}
{"doc_key": "ai-dev-198", "ner": [[5, 5, "product"], [8, 10, "product"], [37, 38, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 8, 10, "part-of", "", false, false], [5, 5, 37, 38, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "such", "as", "Siri", "from", "the", "iOS", "operating", "system", ",", "work", "with", "a", "pattern", "recognition", "technique", "similar", "to", "that", "of", "text", "-", "based", "systems", ",", "but", "in", "the", "former", ",", "user", "input", "is", "done", "through", "speech", "recognition", "."], "sentence-detokenized": "These systems, such as Siri from the iOS operating system, work with a pattern recognition technique similar to that of text-based systems, but in the former, user input is done through speech recognition.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 27], [28, 32], [33, 36], [37, 40], [41, 50], [51, 57], [57, 58], [59, 63], [64, 68], [69, 70], [71, 78], [79, 90], [91, 100], [101, 108], [109, 111], [112, 116], [117, 119], [120, 124], [124, 125], [125, 130], [131, 138], [138, 139], [140, 143], [144, 146], [147, 150], [151, 157], [157, 158], [159, 163], [164, 169], [170, 172], [173, 177], [178, 185], [186, 192], [193, 204], [204, 205]]}
{"doc_key": "ai-dev-199", "ner": [[0, 4, "algorithm"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 13, 14, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["More", "exotic", "fit", "functions", "that", "examine", "model", "detail", "include", "the", "area", "under", "the", "ROC", "curve", "and", "the", "rank", "measure", "."], "sentence-detokenized": "More exotic fit functions that examine model detail include the area under the ROC curve and the rank measure.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 25], [26, 30], [31, 38], [39, 44], [45, 51], [52, 59], [60, 63], [64, 68], [69, 74], [75, 78], [79, 82], [83, 88], [89, 92], [93, 96], [97, 101], [102, 109], [109, 110]]}
{"doc_key": "ai-dev-200", "ner": [[3, 6, "product"], [9, 14, "researcher"], [18, 20, "product"], [25, 28, "organisation"], [30, 33, "organisation"], [40, 42, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 6, 9, 14, "origin", "", false, false], [9, 14, 25, 28, "role", "", false, false], [18, 20, 9, 14, "origin", "", false, false], [30, 33, 25, 28, "named", "", false, false], [40, 42, 25, 28, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "term", "\"", "semantic", "web", "\"", "was", "coined", "by", "Tim", "Berners", "-", "Lee", ",", "the", "creator", "of", "the", "World", "Wide", "Web", "and", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "who", "oversaw", "the", "development", "of", "the", "proposed", "semantic", "web", "standards", "."], "sentence-detokenized": "The term \"semantic web\" was coined by Tim Berners-Lee, the creator of the World Wide Web and director of the World Wide Web Consortium (W3C), who oversaw the development of the proposed semantic web standards.", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 18], [19, 22], [22, 23], [24, 27], [28, 34], [35, 37], [38, 41], [42, 49], [49, 50], [50, 53], [53, 54], [55, 58], [59, 66], [67, 69], [70, 73], [74, 79], [80, 84], [85, 88], [89, 92], [93, 101], [102, 104], [105, 108], [109, 114], [115, 119], [120, 123], [124, 134], [135, 136], [136, 139], [139, 140], [140, 141], [142, 145], [146, 153], [154, 157], [158, 169], [170, 172], [173, 176], [177, 185], [186, 194], [195, 198], [199, 208], [208, 209]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [9, 9, "task"], [16, 17, "product"], [19, 23, "product"], [25, 25, "product"], [29, 30, "product"], [37, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 16, 17, "opposite", "", false, false], [0, 1, 19, 23, "opposite", "", false, false], [0, 1, 29, 30, "opposite", "", false, false], [0, 1, 37, 39, "part-of", "", false, false], [9, 9, 0, 1, "named", "", false, false], [25, 25, 19, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Machine", "translation", ",", "sometimes", "referred", "to", "by", "the", "acronym", "MT", "(", "not", "to", "be", "confused", "with", "computer-assisted", "translation", ",", "machine", "-", "assisted", "human", "translation", "(", "MAHT", ")", ",", "or", "interactive", "translation", ")", ",", "is", "a", "subfield", "of", "computational", "linguistics", "that", "studies", "the", "use", "of", "software", "to", "translate", "text", "or", "speech", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Machine translation, sometimes referred to by the acronym MT (not to be confused with computer-assisted translation, machine-assisted human translation (MAHT), or interactive translation), is a subfield of computational linguistics that studies the use of software to translate text or speech from one language to another.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 30], [31, 39], [40, 42], [43, 45], [46, 49], [50, 57], [58, 60], [61, 62], [62, 65], [66, 68], [69, 71], [72, 80], [81, 85], [86, 103], [104, 115], [115, 116], [117, 124], [124, 125], [125, 133], [134, 139], [140, 151], [152, 153], [153, 157], [157, 158], [158, 159], [160, 162], [163, 174], [175, 186], [186, 187], [187, 188], [189, 191], [192, 193], [194, 202], [203, 205], [206, 219], [220, 231], [232, 236], [237, 244], [245, 248], [249, 252], [253, 255], [256, 264], [265, 267], [268, 277], [278, 282], [283, 285], [286, 292], [293, 297], [298, 301], [302, 310], [311, 313], [314, 321], [321, 322]]}
{"doc_key": "ai-dev-202", "ner": [[1, 4, "product"], [9, 9, "university"], [14, 15, "researcher"], [17, 18, "researcher"], [42, 43, "location"], [45, 45, "location"], [49, 54, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 4, 14, 15, "artifact", "", false, false], [1, 4, 17, 18, "artifact", "", false, false], [14, 15, 9, 9, "physical", "", false, false], [14, 15, 9, 9, "role", "", false, false], [17, 18, 9, 9, "physical", "", false, false], [17, 18, 9, 9, "role", "", false, false], [42, 43, 45, 45, "physical", "", false, false], [49, 54, 42, 43, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Early", "cross", "-language", "MT", "systems", "were", "also", "created", "at", "Stanford", "in", "the", "1970s", "by", "Roger", "Shank", "and", "Yorick", "Wilkes", ";", "the", "former", "became", "the", "basis", "of", "a", "commercial", "money", "translation", "system", ",", "and", "the", "code", "of", "the", "latter", "is", "preserved", "at", "the", "Computer", "Museum", "in", "Boston", "as", "the", "first", "cross", "-", "language", "machine", "translation", "system", "."], "sentence-detokenized": "Early cross-language MT systems were also created at Stanford in the 1970s by Roger Shank and Yorick Wilkes; the former became the basis of a commercial money translation system, and the code of the latter is preserved at the Computer Museum in Boston as the first cross-language machine translation system.", "token2charspan": [[0, 5], [6, 11], [11, 20], [21, 23], [24, 31], [32, 36], [37, 41], [42, 49], [50, 52], [53, 61], [62, 64], [65, 68], [69, 74], [75, 77], [78, 83], [84, 89], [90, 93], [94, 100], [101, 107], [107, 108], [109, 112], [113, 119], [120, 126], [127, 130], [131, 136], [137, 139], [140, 141], [142, 152], [153, 158], [159, 170], [171, 177], [177, 178], [179, 182], [183, 186], [187, 191], [192, 194], [195, 198], [199, 205], [206, 208], [209, 218], [219, 221], [222, 225], [226, 234], [235, 241], [242, 244], [245, 251], [252, 254], [255, 258], [259, 264], [265, 270], [270, 271], [271, 279], [280, 287], [288, 299], [300, 306], [306, 307]]}
{"doc_key": "ai-dev-203", "ner": [[0, 0, "researcher"], [7, 11, "conference"], [13, 14, "conference"], [21, 25, "conference"], [27, 28, "conference"], [34, 39, "organisation"], [48, 48, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 7, 11, "role", "", false, false], [0, 0, 21, 25, "role", "", false, false], [0, 0, 34, 39, "role", "", false, false], [0, 0, 48, 48, "role", "", false, false], [13, 14, 7, 11, "named", "", false, false], [27, 28, 21, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sikara", "served", "as", "program", "chair", "of", "the", "Second", "International", "Semantic", "Web", "Conference", "(", "ISWC", "2003", ")", ";", "general", "chair", "of", "the", "Second", "International", "Autonomous", "Agents", "Conference", "(", "Agents", "98", ")", ";", "chair", "of", "the", "steering", "committee", "of", "the", "Agents", "Conference", "(", "1999-2001", ")", ";", "and", "chair", "of", "the", "AAAI", "Fellowship", "Committee", "(", "1993-1999", ")", ";"], "sentence-detokenized": "Sikara served as program chair of the Second International Semantic Web Conference (ISWC 2003); general chair of the Second International Autonomous Agents Conference (Agents 98); chair of the steering committee of the Agents Conference (1999-2001); and chair of the AAAI Fellowship Committee (1993-1999);", "token2charspan": [[0, 6], [7, 13], [14, 16], [17, 24], [25, 30], [31, 33], [34, 37], [38, 44], [45, 58], [59, 67], [68, 71], [72, 82], [83, 84], [84, 88], [89, 93], [93, 94], [94, 95], [96, 103], [104, 109], [110, 112], [113, 116], [117, 123], [124, 137], [138, 148], [149, 155], [156, 166], [167, 168], [168, 174], [175, 177], [177, 178], [178, 179], [180, 185], [186, 188], [189, 192], [193, 201], [202, 211], [212, 214], [215, 218], [219, 225], [226, 236], [237, 238], [238, 247], [247, 248], [248, 249], [250, 253], [254, 259], [260, 262], [263, 266], [267, 271], [272, 282], [283, 292], [293, 294], [294, 303], [303, 304], [304, 305]]}
{"doc_key": "ai-dev-204", "ner": [[11, 11, "conference"], [13, 16, "conference"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 11, 11, "named", "", false, false], [18, 20, 11, 11, "part-of", "", false, false], [18, 20, 11, 11, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2016", ",", "she", "was", "selected", "as", "the", "recipient", "of", "the", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "Lifetime", "Achievement", "Award", "."], "sentence-detokenized": "In 2016, she was selected as the recipient of the ACL (Association for Computational Linguistics) Lifetime Achievement Award.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 25], [26, 28], [29, 32], [33, 42], [43, 45], [46, 49], [50, 53], [54, 55], [55, 66], [67, 70], [71, 84], [85, 96], [96, 97], [98, 106], [107, 118], [119, 124], [124, 125]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P.", "Frasconi", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 30], [31, 39], [40, 43], [44, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-206", "ner": [[3, 3, "product"], [6, 7, "misc"], [9, 12, "programlang"], [18, 19, "product"], [33, 33, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 9, 12, "usage", "", false, false], [9, 12, 6, 7, "type-of", "", false, false], [9, 12, 18, 19, "related-to", "", false, false], [33, 33, 3, 3, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["For", "example", ",", "A.L.I.C.E.", "uses", "a", "markup", "language", "called", "AIML", "that", "is", "specific", "to", "its", "function", "as", "a", "dialog", "system", "and", "has", "since", "been", "adopted", "by", "various", "other", "developers", "of", "so", "-", "called", "Alicebots", "."], "sentence-detokenized": "For example, A.L.I.C.E. uses a markup language called AIML that is specific to its function as a dialog system and has since been adopted by various other developers of so-called Alicebots.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 23], [24, 28], [29, 30], [31, 37], [38, 46], [47, 53], [54, 58], [59, 63], [64, 66], [67, 75], [76, 78], [79, 82], [83, 91], [92, 94], [95, 96], [97, 103], [104, 110], [111, 114], [115, 118], [119, 124], [125, 129], [130, 137], [138, 140], [141, 148], [149, 154], [155, 165], [166, 168], [169, 171], [171, 172], [172, 178], [179, 188], [188, 189]]}
{"doc_key": "ai-dev-207", "ner": [[13, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2000", ",", "she", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2000, she was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 24], [25, 26], [27, 33], [34, 36], [37, 40], [41, 52], [53, 56], [57, 60], [61, 72], [73, 75], [76, 86], [87, 99], [99, 100]]}
{"doc_key": "ai-dev-208", "ner": [[0, 2, "misc"], [4, 4, "misc"], [10, 16, "misc"], [23, 25, "algorithm"], [33, 34, "field"], [36, 37, "field"], [40, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 10, 16, "type-of", "", false, false], [0, 2, 33, 34, "related-to", "performs", true, false], [0, 2, 36, 37, "related-to", "performs", true, false], [0, 2, 40, 41, "related-to", "performs", true, false], [4, 4, 0, 2, "named", "", false, false], [23, 25, 10, 16, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Learning", "classifier", "systems", "(", "LCS", ")", "are", "a", "family", "of", "rule", "-", "based", "machine", "learning", "algorithms", "that", "combine", "a", "detection", "component", ",", "typically", "a", "genetic", "algorithm", ",", "with", "a", "learning", "component", "that", "performs", "supervised", "learning", ",", "reinforcement", "learning", ",", "or", "unsupervised", "learning", "."], "sentence-detokenized": "Learning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a detection component, typically a genetic algorithm, with a learning component that performs supervised learning, reinforcement learning, or unsupervised learning.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 29], [29, 32], [32, 33], [34, 37], [38, 39], [40, 46], [47, 49], [50, 54], [54, 55], [55, 60], [61, 68], [69, 77], [78, 88], [89, 93], [94, 101], [102, 103], [104, 113], [114, 123], [123, 124], [125, 134], [135, 136], [137, 144], [145, 154], [154, 155], [156, 160], [161, 162], [163, 171], [172, 181], [182, 186], [187, 195], [196, 206], [207, 215], [215, 216], [217, 230], [231, 239], [239, 240], [241, 243], [244, 256], [257, 265], [265, 266]]}
{"doc_key": "ai-dev-209", "ner": [[14, 16, "algorithm"], [19, 19, "algorithm"], [27, 28, "algorithm"], [30, 32, "misc"], [40, 47, "algorithm"], [50, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 16, 27, 28, "origin", "", false, false], [14, 16, 30, 32, "usage", "", false, false], [19, 19, 14, 16, "named", "", false, false], [40, 47, 30, 32, "type-of", "", false, false], [40, 47, 50, 55, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "unknown", "parameters", "in", "each", "\u03b2subk", "/", "sub", "vector", "are", "typically", "jointly", "estimated", "by", "maximum", "a", "posteriori", "estimation", "(", "MAP", ")", ",", "which", "is", "an", "extension", "of", "maximum", "likelihood", "using", "regularization", "of", "the", "weights", "to", "prevent", "pathological", "solutions", "(", "typically", "a", "quadratic", "regularization", "function", "that", "is", "equivalent", "to", "fitting", "a", "Gaussian", "prior", "distribution", "with", "zero", "mean", "over", "the", "weights", ",", "but", "other", "distributions", "are", "possible", ")", "."], "sentence-detokenized": "The unknown parameters in each \u03b2subk/sub vector are typically jointly estimated by maximum a posteriori estimation (MAP), which is an extension of maximum likelihood using regularization of the weights to prevent pathological solutions (typically a quadratic regularization function that is equivalent to fitting a Gaussian prior distribution with zero mean over the weights, but other distributions are possible).", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 30], [31, 36], [36, 37], [37, 40], [41, 47], [48, 51], [52, 61], [62, 69], [70, 79], [80, 82], [83, 90], [91, 92], [93, 103], [104, 114], [115, 116], [116, 119], [119, 120], [120, 121], [122, 127], [128, 130], [131, 133], [134, 143], [144, 146], [147, 154], [155, 165], [166, 171], [172, 186], [187, 189], [190, 193], [194, 201], [202, 204], [205, 212], [213, 225], [226, 235], [236, 237], [237, 246], [247, 248], [249, 258], [259, 273], [274, 282], [283, 287], [288, 290], [291, 301], [302, 304], [305, 312], [313, 314], [315, 323], [324, 329], [330, 342], [343, 347], [348, 352], [353, 357], [358, 362], [363, 366], [367, 374], [374, 375], [376, 379], [380, 385], [386, 399], [400, 403], [404, 412], [412, 413], [413, 414]]}
{"doc_key": "ai-dev-210", "ner": [[9, 10, "researcher"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 9, 10, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "hierarchical", "structure", "of", "words", "is", "explicitly", "mapped", "in", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "The hierarchical structure of words is explicitly mapped in George Miller's Wordnet.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 29], [30, 35], [36, 38], [39, 49], [50, 56], [57, 59], [60, 66], [67, 73], [73, 75], [76, 83], [83, 84]]}
{"doc_key": "ai-dev-211", "ner": [[7, 12, "conference"], [19, 23, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 23, 7, 12, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "illustration", "of", "their", "capabilities", "is", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", ";", "this", "is", "the", "benchmark", "for", "object", "classification", "and", "detection", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "An illustration of their capabilities is the ImageNet Large Scale Visual Recognition Challenge; this is the benchmark for object classification and detection with millions of images and hundreds of object classes.", "token2charspan": [[0, 2], [3, 15], [16, 18], [19, 24], [25, 37], [38, 40], [41, 44], [45, 53], [54, 59], [60, 65], [66, 72], [73, 84], [85, 94], [94, 95], [96, 100], [101, 103], [104, 107], [108, 117], [118, 121], [122, 128], [129, 143], [144, 147], [148, 157], [158, 162], [163, 171], [172, 174], [175, 181], [182, 185], [186, 194], [195, 197], [198, 204], [205, 212], [212, 213]]}
{"doc_key": "ai-dev-212", "ner": [[1, 2, "misc"], [26, 26, "misc"], [28, 30, "person"], [33, 33, "misc"], [39, 41, "person"], [45, 49, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[26, 26, 1, 2, "general-affiliation", "", false, false], [33, 33, 1, 2, "general-affiliation", "", false, false], [33, 33, 28, 30, "artifact", "", false, false], [45, 49, 1, 2, "general-affiliation", "", false, false], [45, 49, 39, 41, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "science", "fiction", ",", "robots", "that", "look", "like", "women", "are", "often", "produced", "for", "use", "as", "domestic", "servants", "and", "sex", "slaves", ",", "as", "seen", "in", "the", "film", "Westworld", ",", "Paul", "J.", "McAuley", "'s", "novel", "Fairyland", "(", "1995", ")", ",", "and", "Lester", "Del", "Rey", "'s", "short", "story", "Helen", "O'", "Loy", "(", "1938", ")", ",", "and", "sometimes", "as", "warriors", ",", "assassins", ",", "or", "laborers", "."], "sentence-detokenized": "In science fiction, robots that look like women are often produced for use as domestic servants and sex slaves, as seen in the film Westworld, Paul J. McAuley's novel Fairyland (1995), and Lester Del Rey's short story Helen O'Loy (1938), and sometimes as warriors, assassins, or laborers.", "token2charspan": [[0, 2], [3, 10], [11, 18], [18, 19], [20, 26], [27, 31], [32, 36], [37, 41], [42, 47], [48, 51], [52, 57], [58, 66], [67, 70], [71, 74], [75, 77], [78, 86], [87, 95], [96, 99], [100, 103], [104, 110], [110, 111], [112, 114], [115, 119], [120, 122], [123, 126], [127, 131], [132, 141], [141, 142], [143, 147], [148, 150], [151, 158], [158, 160], [161, 166], [167, 176], [177, 178], [178, 182], [182, 183], [183, 184], [185, 188], [189, 195], [196, 199], [200, 203], [203, 205], [206, 211], [212, 217], [218, 223], [224, 226], [226, 229], [230, 231], [231, 235], [235, 236], [236, 237], [238, 241], [242, 251], [252, 254], [255, 263], [263, 264], [265, 274], [274, 275], [276, 278], [279, 287], [287, 288]]}
{"doc_key": "ai-dev-213", "ner": [[0, 1, "task"], [3, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["question", "answering", ",", "speech", "recognition", "and", "machine", "translation", "."], "sentence-detokenized": "question answering, speech recognition and machine translation.", "token2charspan": [[0, 8], [9, 18], [18, 19], [20, 26], [27, 38], [39, 42], [43, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-214", "ner": [[5, 6, "researcher"], [9, 13, "organisation"], [15, 18, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 9, 13, "role", "", false, false], [9, 13, 15, 18, "physical", "", false, false], [15, 18, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "seminal", "work", ",", "Harry", "Blum", "of", "the", "Cambridge", "Air", "Force", "Research", "Laboratories", "at", "Hanscom", "Air", "Force", "Base", "in", "Bedford", ",", "Massachusetts", ",", "defined", "a", "medial", "axis", "to", "compute", "the", "skeleton", "of", "a", "shape", "using", "an", "intuitive", "model", "of", "fire", "spread", "over", "a", "grass", "field", "where", "the", "field", "has", "the", "shape", "of", "the", "given", "shape", "."], "sentence-detokenized": "In his seminal work, Harry Blum of the Cambridge Air Force Research Laboratories at Hanscom Air Force Base in Bedford, Massachusetts, defined a medial axis to compute the skeleton of a shape using an intuitive model of fire spread over a grass field where the field has the shape of the given shape.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 19], [19, 20], [21, 26], [27, 31], [32, 34], [35, 38], [39, 48], [49, 52], [53, 58], [59, 67], [68, 80], [81, 83], [84, 91], [92, 95], [96, 101], [102, 106], [107, 109], [110, 117], [117, 118], [119, 132], [132, 133], [134, 141], [142, 143], [144, 150], [151, 155], [156, 158], [159, 166], [167, 170], [171, 179], [180, 182], [183, 184], [185, 190], [191, 196], [197, 199], [200, 209], [210, 215], [216, 218], [219, 223], [224, 230], [231, 235], [236, 237], [238, 243], [244, 249], [250, 255], [256, 259], [260, 265], [266, 269], [270, 273], [274, 279], [280, 282], [283, 286], [287, 292], [293, 298], [298, 299]]}
{"doc_key": "ai-dev-215", "ner": [[16, 16, "algorithm"], [18, 18, "algorithm"], [21, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 16, 21, 22, "compare", "", false, false], [18, 18, 21, 22, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "unlike", "loss-", "maximization", "algorithms", "that", "analytically", "minimize", "a", "convex", "loss", "function", "(", "e.g.", ",", "AdaBoost", "and", "LogitBoost", ")", ",", "Brown", "Boost", "solves", "a", "system", "of", "two", "equations", "and", "two", "unknowns", "using", "standard", "numerical", "methods", "."], "sentence-detokenized": "However, unlike loss-maximization algorithms that analytically minimize a convex loss function (e.g., AdaBoost and LogitBoost), BrownBoost solves a system of two equations and two unknowns using standard numerical methods.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 21], [21, 33], [34, 44], [45, 49], [50, 62], [63, 71], [72, 73], [74, 80], [81, 85], [86, 94], [95, 96], [96, 100], [100, 101], [102, 110], [111, 114], [115, 125], [125, 126], [126, 127], [128, 133], [133, 138], [139, 145], [146, 147], [148, 154], [155, 157], [158, 161], [162, 171], [172, 175], [176, 179], [180, 188], [189, 194], [195, 203], [204, 213], [214, 221], [221, 222]]}
{"doc_key": "ai-dev-216", "ner": [[0, 0, "researcher"], [8, 10, "misc"], [18, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 8, 10, "win-defeat", "", false, false], [0, 0, 18, 24, "role", "", false, false], [26, 26, 18, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getoor", "has", "multiple", "best", "paper", "awards", ",", "an", "NSF", "Career", "Award", ",", "and", "is", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Getoor has multiple best paper awards, an NSF Career Award, and is a member of the Association for the Advancement of Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 24], [25, 30], [31, 37], [37, 38], [39, 41], [42, 45], [46, 52], [53, 58], [58, 59], [60, 63], [64, 66], [67, 68], [69, 75], [76, 78], [79, 82], [83, 94], [95, 98], [99, 102], [103, 114], [115, 117], [118, 128], [129, 141], [142, 143], [143, 147], [147, 148], [148, 149]]}
{"doc_key": "ai-dev-217", "ner": [[0, 2, "misc"], [7, 13, "misc"], [18, 20, "misc"], [25, 33, "misc"], [36, 42, "misc"], [43, 47, "university"], [54, 59, "misc"], [64, 72, "misc"], [77, 83, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Member", "of", "ACM", "(", "2015", ")", "br", "Member", "of", "the", "Association", "for", "Computational", "Linguistics", "(", "2011", ")", "br", "Member", "of", "AAAI", "(", "1994", ")", "br", "Member", "of", "the", "International", "Speech", "Communication", "Association", "(", "2011", ")", "br", "Honorary", "Doctorate", "(", "Hedersdoktor", ")", "of", "the", "Royal", "Institute", "of", "Technology", "KTH", "(", "2007", ")", ".", ")", "br", "Columbia", "Engineering", "Alumni", "Association", "Teaching", "Award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Speech", "and", "Sound", "Processing", "Award", "(", "2011", ")", "br", "ISCA", "Medal", "of", "Scientific", "Achievement", "(", "2011", ")"], "sentence-detokenized": "Member of ACM (2015) br Member of the Association for Computational Linguistics (2011) br Member of AAAI (1994) br Member of the International Speech Communication Association (2011) br Honorary Doctorate (Hedersdoktor) of the Royal Institute of Technology KTH (2007).) br Columbia Engineering Alumni Association Teaching Award (2009) br IEEE James L. Flanagan Speech and Sound Processing Award (2011) br ISCA Medal of Scientific Achievement (2011)", "token2charspan": [[0, 6], [7, 9], [10, 13], [14, 15], [15, 19], [19, 20], [21, 23], [24, 30], [31, 33], [34, 37], [38, 49], [50, 53], [54, 67], [68, 79], [80, 81], [81, 85], [85, 86], [87, 89], [90, 96], [97, 99], [100, 104], [105, 106], [106, 110], [110, 111], [112, 114], [115, 121], [122, 124], [125, 128], [129, 142], [143, 149], [150, 163], [164, 175], [176, 177], [177, 181], [181, 182], [183, 185], [186, 194], [195, 204], [205, 206], [206, 218], [218, 219], [220, 222], [223, 226], [227, 232], [233, 242], [243, 245], [246, 256], [257, 260], [261, 262], [262, 266], [266, 267], [267, 268], [268, 269], [270, 272], [273, 281], [282, 293], [294, 300], [301, 312], [313, 321], [322, 327], [328, 329], [329, 333], [333, 334], [335, 337], [338, 342], [343, 348], [349, 351], [352, 360], [361, 367], [368, 371], [372, 377], [378, 388], [389, 394], [395, 396], [396, 400], [400, 401], [402, 404], [405, 409], [410, 415], [416, 418], [419, 429], [430, 441], [442, 443], [443, 447], [447, 448]]}
{"doc_key": "ai-dev-218", "ner": [[6, 6, "university"], [15, 18, "task"], [37, 39, "metrics"], [28, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[37, 39, 28, 30, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["A", "disappointing", "result", "from", "the", "same", "Stanford", "study", "(", "and", "from", "other", "attempts", "to", "improve", "translation", "with", "name", "recognition", ")", "is", "that", "in", "many", "cases", "the", "inclusion", "of", "named", "entity", "translation", "methods", "leads", "to", "a", "reduction", "in", "bilingual", "translation", "assessment", "scores", "."], "sentence-detokenized": "A disappointing result from the same Stanford study (and from other attempts to improve translation with name recognition) is that in many cases the inclusion of named entity translation methods leads to a reduction in bilingual translation assessment scores.", "token2charspan": [[0, 1], [2, 15], [16, 22], [23, 27], [28, 31], [32, 36], [37, 45], [46, 51], [52, 53], [53, 56], [57, 61], [62, 67], [68, 76], [77, 79], [80, 87], [88, 99], [100, 104], [105, 109], [110, 121], [121, 122], [123, 125], [126, 130], [131, 133], [134, 138], [139, 144], [145, 148], [149, 158], [159, 161], [162, 167], [168, 174], [175, 186], [187, 194], [195, 200], [201, 203], [204, 205], [206, 215], [216, 218], [219, 228], [229, 240], [241, 251], [252, 258], [258, 259]]}
{"doc_key": "ai-dev-219", "ner": [[0, 0, "organisation"], [11, 13, "organisation"], [15, 22, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "role", "works_with", false, false], [0, 0, 15, 22, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "used", "the", "PM", "data", "collected", "and", "worked", "with", "researchers", "at", "Johns", "Hopkins", "Hospital", "and", "Washington", "University", "School", "of", "Medicine", "to", "help", "answer", "specific", "questions", "about", "heart", "disease", ",", "such", "as", "whether", "weak", "hearts", "cause", "arrhythmia", "or", "vice", "versa", "."], "sentence-detokenized": "Medtronic used the PM data collected and worked with researchers at Johns Hopkins Hospital and Washington University School of Medicine to help answer specific questions about heart disease, such as whether weak hearts cause arrhythmia or vice versa.", "token2charspan": [[0, 9], [10, 14], [15, 18], [19, 21], [22, 26], [27, 36], [37, 40], [41, 47], [48, 52], [53, 64], [65, 67], [68, 73], [74, 81], [82, 90], [91, 94], [95, 105], [106, 116], [117, 123], [124, 126], [127, 135], [136, 138], [139, 143], [144, 150], [151, 159], [160, 169], [170, 175], [176, 181], [182, 189], [189, 190], [191, 195], [196, 198], [199, 206], [207, 211], [212, 218], [219, 224], [225, 235], [236, 238], [239, 243], [244, 249], [249, 250]]}
{"doc_key": "ai-dev-220", "ner": [[3, 7, "organisation"], [9, 9, "misc"], [12, 13, "person"], [15, 16, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 3, 7, "artifact", "made_by_studio", false, false], [12, 13, 9, 9, "role", "", false, false], [15, 16, 9, 9, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Next", "up", "was", "Paramount", "'s", "first", "feature", "film", ",", "Sangaree", ",", "starring", "Fernando", "Lamas", "and", "Arlene", "Dahl", "."], "sentence-detokenized": "Next up was Paramount's first feature film, Sangaree, starring Fernando Lamas and Arlene Dahl.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [21, 23], [24, 29], [30, 37], [38, 42], [42, 43], [44, 52], [52, 53], [54, 62], [63, 71], [72, 77], [78, 81], [82, 88], [89, 93], [93, 94]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [8, 10, "researcher"], [12, 15, "researcher"], [18, 19, "organisation"], [21, 24, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 10, "origin", "", false, false], [0, 0, 12, 15, "origin", "", false, false], [8, 10, 18, 19, "physical", "", false, false], [8, 10, 18, 19, "role", "", false, false], [12, 15, 21, 24, "physical", "", false, false], [12, 15, 21, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "is", "a", "knowledge", "representation", "language", "developed", "by", "Daniel", "G.", "Bobrow", "and", "Terry", "Winograd", "during", "their", "work", "at", "Xerox", "PARC", "and", "Stanford", "University", ",", "respectively", "."], "sentence-detokenized": "KRL is a knowledge representation language developed by Daniel G. Bobrow and Terry Winograd during their work at Xerox PARC and Stanford University, respectively.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 18], [19, 33], [34, 42], [43, 52], [53, 55], [56, 62], [63, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 98], [99, 104], [105, 109], [110, 112], [113, 118], [119, 123], [124, 127], [128, 136], [137, 147], [147, 148], [149, 161], [161, 162]]}
{"doc_key": "ai-dev-222", "ner": [[3, 10, "conference"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [22, 25, "researcher"], [33, 34, "task"], [36, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 10, 33, 34, "topic", "", true, false], [12, 13, 3, 10, "physical", "", false, false], [12, 13, 3, 10, "role", "", false, false], [12, 13, 3, 10, "temporal", "", false, false], [15, 16, 3, 10, "physical", "", false, false], [15, 16, 3, 10, "role", "", false, false], [15, 16, 3, 10, "temporal", "", false, false], [18, 19, 3, 10, "physical", "", false, false], [18, 19, 3, 10, "role", "", false, false], [18, 19, 3, 10, "temporal", "", false, false], [22, 25, 3, 10, "physical", "", false, false], [22, 25, 3, 10, "role", "", false, false], [22, 25, 3, 10, "temporal", "", false, false], [33, 34, 36, 38, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["At", "the", "2006", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", ",", "and", "Kwang", "-", "Ting", "Cheng", "presented", "an", "algorithm", "to", "significantly", "speed", "up", "human", "detection", "using", "HOG", "descriptor", "methods", "."], "sentence-detokenized": "At the 2006 IEEE Conference on Computer Vision and Pattern Recognition, Qiang Zhu, Shai Avidan, Mei-Chen Yeh, and Kwang-Ting Cheng presented an algorithm to significantly speed up human detection using HOG descriptor methods.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 27], [28, 30], [31, 39], [40, 46], [47, 50], [51, 58], [59, 70], [70, 71], [72, 77], [78, 81], [81, 82], [83, 87], [88, 94], [94, 95], [96, 104], [105, 108], [108, 109], [110, 113], [114, 119], [119, 120], [120, 124], [125, 130], [131, 140], [141, 143], [144, 153], [154, 156], [157, 170], [171, 176], [177, 179], [180, 185], [186, 195], [196, 201], [202, 205], [206, 216], [217, 224], [224, 225]]}
{"doc_key": "ai-dev-223", "ner": [[0, 0, "researcher"], [6, 8, "conference"], [9, 12, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 8, "role", "", false, false], [0, 0, 9, 12, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "is", "a", "member", "of", "the", "AAAI", "and", "the", "Society", "for", "Cognitive", "Science"], "sentence-detokenized": "Hayes is a member of the AAAI and the Society for Cognitive Science", "token2charspan": [[0, 5], [6, 8], [9, 10], [11, 17], [18, 20], [21, 24], [25, 29], [30, 33], [34, 37], [38, 45], [46, 49], [50, 59], [60, 67]]}
{"doc_key": "ai-dev-224", "ner": [[0, 1, "misc"], [5, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [19, 19, "field"], [21, 22, "field"], [24, 24, "field"], [27, 27, "field"], [29, 29, "field"], [31, 32, "field"], [40, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 1, 5, 5, "part-of", "", false, false], [0, 1, 5, 5, "usage", "", false, false], [0, 1, 7, 8, "part-of", "", false, false], [0, 1, 7, 8, "usage", "", false, false], [0, 1, 10, 11, "part-of", "", false, false], [0, 1, 10, 11, "usage", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [0, 1, 13, 13, "usage", "", false, false], [0, 1, 15, 16, "part-of", "", false, false], [0, 1, 15, 16, "usage", "", false, false], [0, 1, 19, 19, "part-of", "", false, false], [0, 1, 19, 19, "usage", "", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 21, 22, "usage", "", false, false], [0, 1, 24, 24, "part-of", "", false, false], [0, 1, 24, 24, "usage", "", false, false], [0, 1, 27, 27, "part-of", "", false, false], [0, 1, 27, 27, "usage", "", false, false], [0, 1, 29, 29, "part-of", "", false, false], [0, 1, 29, 29, "usage", "", false, false], [0, 1, 31, 32, "part-of", "", false, false], [0, 1, 31, 32, "usage", "", false, false], [0, 1, 40, 41, "part-of", "", false, false], [0, 1, 40, 41, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", ",", "and", "pretty", "much", "every", "area", "of", "applied", "science", "and", "engineering", "that", "involves", "time", "measurements", "."], "sentence-detokenized": "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering, and pretty much every area of applied science and engineering that involves time measurements.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 23], [24, 34], [34, 35], [36, 42], [43, 53], [53, 54], [55, 62], [63, 74], [74, 75], [76, 88], [88, 89], [90, 102], [103, 110], [110, 111], [112, 119], [120, 131], [131, 132], [133, 143], [144, 154], [154, 155], [156, 178], [178, 179], [180, 187], [188, 199], [199, 200], [201, 210], [210, 211], [212, 226], [227, 238], [238, 239], [240, 243], [244, 250], [251, 255], [256, 261], [262, 266], [267, 269], [270, 277], [278, 285], [286, 289], [290, 301], [302, 306], [307, 315], [316, 320], [321, 333], [333, 334]]}
{"doc_key": "ai-dev-225", "ner": [[13, 16, "metrics"], [37, 39, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "principle", ",", "exact", "recovery", "can", "be", "solved", "in", "the", "feasible", "range", "using", "maximum", "likelihood", ",", "but", "this", "is", "equivalent", "to", "solving", "a", "constrained", "or", "regularized", "cut", "problem", ",", "such", "as", "minimum", "bisection", ",", "which", "is", "usually", "NP", "-", "complete", "."], "sentence-detokenized": "In principle, exact recovery can be solved in the feasible range using maximum likelihood, but this is equivalent to solving a constrained or regularized cut problem, such as minimum bisection, which is usually NP-complete.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 19], [20, 28], [29, 32], [33, 35], [36, 42], [43, 45], [46, 49], [50, 58], [59, 64], [65, 70], [71, 78], [79, 89], [89, 90], [91, 94], [95, 99], [100, 102], [103, 113], [114, 116], [117, 124], [125, 126], [127, 138], [139, 141], [142, 153], [154, 157], [158, 165], [165, 166], [167, 171], [172, 174], [175, 182], [183, 192], [192, 193], [194, 199], [200, 202], [203, 210], [211, 213], [213, 214], [214, 222], [222, 223]]}
{"doc_key": "ai-dev-226", "ner": [[2, 6, "task"], [11, 13, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 13, 2, 6, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["in", "their", "pedestrian", "detection", "work", ",", "which", "was", "first", "described", "at", "BMVC", "in", "2009", "."], "sentence-detokenized": "in their pedestrian detection work, which was first described at BMVC in 2009.", "token2charspan": [[0, 2], [3, 8], [9, 19], [20, 29], [30, 34], [34, 35], [36, 41], [42, 45], [46, 51], [52, 61], [62, 64], [65, 69], [70, 72], [73, 77], [77, 78]]}
{"doc_key": "ai-dev-227", "ner": [[5, 9, "conference"], [11, 11, "researcher"], [14, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 5, 9, "physical", "", false, false], [11, 11, 5, 9, "role", "", false, false], [11, 11, 14, 22, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2007", ",", "at", "the", "International", "Conference", "on", "Computer", "Vision", ",", "Terzopoulos", "received", "the", "first", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "for", "pioneering", "and", "sustained", "research", "on", "deformable", "models", "and", "their", "applications", "."], "sentence-detokenized": "In 2007, at the International Conference on Computer Vision, Terzopoulos received the first IEEE PAMI Computer Vision Distinguished Researcher Award for pioneering and sustained research on deformable models and their applications.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 40], [41, 43], [44, 52], [53, 59], [59, 60], [61, 72], [73, 81], [82, 85], [86, 91], [92, 96], [97, 101], [102, 110], [111, 117], [118, 131], [132, 142], [143, 148], [149, 152], [153, 163], [164, 167], [168, 177], [178, 186], [187, 189], [190, 200], [201, 207], [208, 211], [212, 217], [218, 230], [230, 231]]}
{"doc_key": "ai-dev-228", "ner": [[0, 1, "task"], [4, 5, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 4, 5, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cluster", "analysis", ",", "or", "cluster", "analysis", ",", "involves", "distributing", "data", "points", "into", "clusters", "so", "that", "items", "in", "the", "same", "cluster", "are", "as", "similar", "as", "possible", "and", "items", "belonging", "to", "different", "clusters", "are", "as", "dissimilar", "as", "possible", "."], "sentence-detokenized": "Cluster analysis, or cluster analysis, involves distributing data points into clusters so that items in the same cluster are as similar as possible and items belonging to different clusters are as dissimilar as possible.", "token2charspan": [[0, 7], [8, 16], [16, 17], [18, 20], [21, 28], [29, 37], [37, 38], [39, 47], [48, 60], [61, 65], [66, 72], [73, 77], [78, 86], [87, 89], [90, 94], [95, 100], [101, 103], [104, 107], [108, 112], [113, 120], [121, 124], [125, 127], [128, 135], [136, 138], [139, 147], [148, 151], [152, 157], [158, 167], [168, 170], [171, 180], [181, 189], [190, 193], [194, 196], [197, 207], [208, 210], [211, 219], [219, 220]]}
{"doc_key": "ai-dev-229", "ner": [[11, 16, "field"], [18, 18, "field"], [20, 21, "task"], [26, 27, "field"], [23, 33, "field"], [38, 40, "field"], [44, 44, "field"], [47, 48, "task"], [50, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[11, 16, 18, 18, "named", "", false, false], [11, 16, 26, 27, "named", "", false, false], [11, 16, 38, 40, "named", "", false, false], [20, 21, 18, 18, "part-of", "task_part_of_field", false, false], [23, 33, 26, 27, "part-of", "", false, false], [44, 44, 38, 40, "part-of", "", false, false], [47, 48, 44, 44, "part-of", "", false, false], [50, 50, 44, 44, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["(", "2005", ")", ",", "we", "can", "distinguish", "three", "different", "perspectives", "on", "information", "extraction", "from", "text", ",", "namely", ":", "information", "extraction", "from", "text", "as", "information", "retrieval", ",", "information", "extraction", "from", "text", "as", "data", "mining", "from", "text", ",", "and", "information", "extraction", "from", "text", "as", "a", "data", "mining", "process", "(", "knowledge", "discovery", "in", "databases", ")", ".", "Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005), we can distinguish three different perspectives on information extraction from text, namely: information extraction from text as information retrieval, information extraction from text as data mining from text, and information extraction from text as a data mining process (knowledge discovery in databases). Hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [6, 7], [8, 10], [11, 14], [15, 26], [27, 32], [33, 42], [43, 55], [56, 58], [59, 70], [71, 81], [82, 86], [87, 91], [91, 92], [93, 99], [99, 100], [101, 112], [113, 123], [124, 128], [129, 133], [134, 136], [137, 148], [149, 158], [158, 159], [160, 171], [172, 182], [183, 187], [188, 192], [193, 195], [196, 200], [201, 207], [208, 212], [213, 217], [217, 218], [219, 222], [223, 234], [235, 245], [246, 250], [251, 255], [256, 258], [259, 260], [261, 265], [266, 272], [273, 280], [281, 282], [282, 291], [292, 301], [302, 304], [305, 314], [314, 315], [315, 316], [317, 322], [322, 323], [324, 326], [326, 327], [328, 338], [338, 339], [340, 342], [343, 346], [347, 351], [351, 352], [353, 355], [356, 357], [357, 361], [361, 362], [362, 363]]}
{"doc_key": "ai-dev-230", "ner": [[0, 2, "product"], [14, 19, "location"], [21, 21, "location"], [23, 23, "location"], [33, 34, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 14, 19, "related-to", "developed_for", false, false], [14, 19, 21, 21, "physical", "", false, false], [21, 21, 23, 23, "physical", "", false, false], [33, 34, 0, 2, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Rancho", "Arm", "was", "developed", "as", "a", "robotic", "arm", "to", "assist", "disabled", "patients", "at", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Center", "in", "Downey", ",", "California", ";", "this", "computer", "-", "controlled", "arm", "was", "purchased", "from", "Stanford", "University", "in", "1963", "."], "sentence-detokenized": "The Rancho Arm was developed as a robotic arm to assist disabled patients at Rancho Los Amigos National Rehabilitation Center in Downey, California; this computer-controlled arm was purchased from Stanford University in 1963.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 18], [19, 28], [29, 31], [32, 33], [34, 41], [42, 45], [46, 48], [49, 55], [56, 64], [65, 73], [74, 76], [77, 83], [84, 87], [88, 94], [95, 103], [104, 118], [119, 125], [126, 128], [129, 135], [135, 136], [137, 147], [147, 148], [149, 153], [154, 162], [162, 163], [163, 173], [174, 177], [178, 181], [182, 191], [192, 196], [197, 205], [206, 216], [217, 219], [220, 224], [224, 225]]}
{"doc_key": "ai-dev-231", "ner": [[2, 4, "university"], [6, 6, "researcher"], [9, 12, "organisation"], [21, 23, "organisation"], [27, 28, "researcher"], [30, 32, "researcher"], [46, 46, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[6, 6, 2, 4, "physical", "", false, false], [6, 6, 2, 4, "role", "", false, false], [6, 6, 9, 12, "role", "founder", false, false], [6, 6, 21, 23, "role", "founder", false, false], [21, 23, 46, 46, "physical", "", false, false], [27, 28, 21, 23, "role", "founder", false, false], [30, 32, 21, 23, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["At", "the", "University", "of", "California", ",", "Norman", "founded", "the", "Institute", "for", "Cognitive", "Science", "and", "was", "one", "of", "the", "organizers", "of", "the", "Cognitive", "Science", "Society", "(", "along", "with", "Roger", "Shank", ",", "Alan", "M.", "Collins", ",", "and", "others", ")", ",", "which", "held", "it", "s", "first", "meeting", "on", "the", "UC", "campus", "in", "1979", "."], "sentence-detokenized": "At the University of California, Norman founded the Institute for Cognitive Science and was one of the organizers of the Cognitive Science Society (along with Roger Shank, Alan M. Collins, and others), which held its first meeting on the UC campus in 1979.", "token2charspan": [[0, 2], [3, 6], [7, 17], [18, 20], [21, 31], [31, 32], [33, 39], [40, 47], [48, 51], [52, 61], [62, 65], [66, 75], [76, 83], [84, 87], [88, 91], [92, 95], [96, 98], [99, 102], [103, 113], [114, 116], [117, 120], [121, 130], [131, 138], [139, 146], [147, 148], [148, 153], [154, 158], [159, 164], [165, 170], [170, 171], [172, 176], [177, 179], [180, 187], [187, 188], [189, 192], [193, 199], [199, 200], [200, 201], [202, 207], [208, 212], [213, 215], [215, 216], [217, 222], [223, 230], [231, 233], [234, 237], [238, 240], [241, 247], [248, 250], [251, 255], [255, 256]]}
{"doc_key": "ai-dev-232", "ner": [[7, 8, "product"], [10, 11, "product"], [13, 14, "product"], [16, 19, "product"], [21, 22, "product"], [24, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[21, 22, 16, 19, "type-of", "", false, false], [24, 29, 16, 19, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "commonly", "used", "robot", "configurations", "are", "articulated", "robots", ",", "SCARA", "robots", ",", "delta", "robots", "and", "robots", "with", "Cartesian", "coordinates", "(", "gantry", "robots", "or", "x", "-", "y", "-", "z", "robots", ")", "."], "sentence-detokenized": "The most commonly used robot configurations are articulated robots, SCARA robots, delta robots and robots with Cartesian coordinates (gantry robots or x-y-z robots).", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 28], [29, 43], [44, 47], [48, 59], [60, 66], [66, 67], [68, 73], [74, 80], [80, 81], [82, 87], [88, 94], [95, 98], [99, 105], [106, 110], [111, 120], [121, 132], [133, 134], [134, 140], [141, 147], [148, 150], [151, 152], [152, 153], [153, 154], [154, 155], [155, 156], [157, 163], [163, 164], [164, 165]]}
{"doc_key": "ai-dev-233", "ner": [[9, 9, "programlang"], [10, 11, "misc"], [16, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 9, 9, "part-of", "", false, false], [16, 16, 10, 11, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Alternatively", ",", "it", "can", "be", "used", "directly", "with", "the", "Perl", "TM", "module", "(", "which", "also", "supports", "LTM", ")", "."], "sentence-detokenized": "Alternatively, it can be used directly with the Perl TM module (which also supports LTM).", "token2charspan": [[0, 13], [13, 14], [15, 17], [18, 21], [22, 24], [25, 29], [30, 38], [39, 43], [44, 47], [48, 52], [53, 55], [56, 62], [63, 64], [64, 69], [70, 74], [75, 83], [84, 87], [87, 88], [88, 89]]}
{"doc_key": "ai-dev-234", "ner": [[8, 8, "country"], [9, 10, "organisation"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 8, 8, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "competition", "was", "won", "by", "a", "US", "team", "from", "Newton", "Labs", "and", "was", "shown", "on", "CNN", "."], "sentence-detokenized": "The competition was won by a US team from Newton Labs and was shown on CNN.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 26], [27, 28], [29, 31], [32, 36], [37, 41], [42, 48], [49, 53], [54, 57], [58, 61], [62, 67], [68, 70], [71, 74], [74, 75]]}
{"doc_key": "ai-dev-235", "ner": [[3, 7, "misc"], [11, 12, "person"], [15, 16, "person"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 3, 7, "role", "directs", false, false], [15, 16, 3, 7, "role", "acts_in", false, false], [18, 19, 3, 7, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "short", "film", "The", "Butler", "'s", "in", "Love", ",", "directed", "by", "David", "Arquette", "and", "starring", "Elizabeth", "Berkeley", "and", "Thomas", "Jane", ",", "was", "released", "on", "June", "23", ",", "2008", "."], "sentence-detokenized": "The short film The Butler's in Love, directed by David Arquette and starring Elizabeth Berkeley and Thomas Jane, was released on June 23, 2008.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 18], [19, 25], [25, 27], [28, 30], [31, 35], [35, 36], [37, 45], [46, 48], [49, 54], [55, 63], [64, 67], [68, 76], [77, 86], [87, 95], [96, 99], [100, 106], [107, 111], [111, 112], [113, 116], [117, 125], [126, 128], [129, 133], [134, 136], [136, 137], [138, 142], [142, 143]]}
{"doc_key": "ai-dev-236", "ner": [[3, 4, "product"], [9, 11, "field"], [17, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 17, 17, "general-affiliation", "", false, false], [9, 11, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "Word", "Net", "is", "a", "resource", "including", "a", "taxonomy", "whose", "elements", "are", "the", "meanings", "of", "English", "words", "."], "sentence-detokenized": "For example, WordNet is a resource including a taxonomy whose elements are the meanings of English words.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [17, 20], [21, 23], [24, 25], [26, 34], [35, 44], [45, 46], [47, 55], [56, 61], [62, 70], [71, 74], [75, 78], [79, 87], [88, 90], [91, 98], [99, 104], [104, 105]]}
{"doc_key": "ai-dev-237", "ner": [[1, 4, "product"], [8, 8, "product"], [10, 10, "product"], [17, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 1, 4, "type-of", "", false, false], [8, 8, 17, 17, "related-to", "ability_to", false, false], [10, 10, 1, 4, "type-of", "", false, false], [10, 10, 17, 17, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Existing", "systems", "for", "humanoid", "robots", ",", "such", "as", "ASIMO", "and", "QRIO", ",", "use", "many", "motors", "to", "achieve", "locomotion", "."], "sentence-detokenized": "Existing systems for humanoid robots, such as ASIMO and QRIO, use many motors to achieve locomotion.", "token2charspan": [[0, 8], [9, 16], [17, 20], [21, 29], [30, 36], [36, 37], [38, 42], [43, 45], [46, 51], [52, 55], [56, 60], [60, 61], [62, 65], [66, 70], [71, 77], [78, 80], [81, 88], [89, 99], [99, 100]]}
{"doc_key": "ai-dev-238", "ner": [[0, 0, "metrics"], [7, 8, "metrics"], [10, 11, "metrics"], [13, 17, "misc"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 0, 0, "part-of", "", false, false], [10, 11, 0, 0, "part-of", "", false, false], [13, 17, 0, 0, "part-of", "", false, false], [20, 20, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "is", "designed", "with", "the", "factors", "of", "length", "penalty", ",", "precision", "penalty", ",", "n-", "gram", "word", "order", "penalty", ",", "and", "recall", "."], "sentence-detokenized": "LEPOR is designed with the factors of length penalty, precision penalty, n-gram word order penalty, and recall.", "token2charspan": [[0, 5], [6, 8], [9, 17], [18, 22], [23, 26], [27, 34], [35, 37], [38, 44], [45, 52], [52, 53], [54, 63], [64, 71], [71, 72], [73, 75], [75, 79], [80, 84], [85, 90], [91, 98], [98, 99], [100, 103], [104, 110], [110, 111]]}
{"doc_key": "ai-dev-239", "ner": [[5, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "based", "on", "the", "bilingual", "assessment", "metric", ",", "but", "with", "some", "changes", "."], "sentence-detokenized": "It is based on the bilingual assessment metric, but with some changes.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 14], [15, 18], [19, 28], [29, 39], [40, 46], [46, 47], [48, 51], [52, 56], [57, 61], [62, 69], [69, 70]]}
{"doc_key": "ai-dev-240", "ner": [[6, 6, "product"], [8, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "implementation", "in", "MATLAB", "/", "Octave", ":"], "sentence-detokenized": "This is an example implementation in MATLAB / Octave:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 33], [34, 36], [37, 43], [44, 45], [46, 52], [52, 53]]}
{"doc_key": "ai-dev-241", "ner": [[13, 13, "programlang"], [15, 15, "programlang"], [17, 17, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "designed", "to", "be", "used", "through", "a", "number", "of", "computer", "languages", "including", "Python", ",", "Ruby", "and", "Scheme", "."], "sentence-detokenized": "It is designed to be used through a number of computer languages including Python, Ruby and Scheme.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 20], [21, 25], [26, 33], [34, 35], [36, 42], [43, 45], [46, 54], [55, 64], [65, 74], [75, 81], [81, 82], [83, 87], [88, 91], [92, 98], [98, 99]]}
{"doc_key": "ai-dev-242", "ner": [[0, 2, "researcher"], [6, 6, "organisation"], [12, 12, "conference"], [17, 18, "academicjournal"], [23, 25, "organisation"], [31, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 6, 6, "role", "", false, false], [0, 2, 12, 12, "role", "", false, false], [0, 2, 17, 18, "role", "", false, false], [0, 2, 23, 25, "role", "", false, false], [0, 2, 31, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "has", "served", "as", "Secretary", "of", "AISB", ",", "President", "and", "Trustee", "of", "IJCAI", ",", "Associate", "Editor", "of", "Artificial", "Intelligence", ",", "Governor", "of", "the", "Cognitive", "Science", "Society", ",", "and", "President", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes has served as Secretary of AISB, President and Trustee of IJCAI, Associate Editor of Artificial Intelligence, Governor of the Cognitive Science Society, and President of the American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 32], [33, 37], [37, 38], [39, 48], [49, 52], [53, 60], [61, 63], [64, 69], [69, 70], [71, 80], [81, 87], [88, 90], [91, 101], [102, 114], [114, 115], [116, 124], [125, 127], [128, 131], [132, 141], [142, 149], [150, 157], [157, 158], [159, 162], [163, 172], [173, 175], [176, 179], [180, 188], [189, 200], [201, 204], [205, 215], [216, 228], [228, 229]]}
{"doc_key": "ai-dev-243", "ner": [[5, 13, "misc"], [17, 22, "misc"], [25, 26, "person"], [31, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 26, 5, 13, "role", "directed_by", false, false], [25, 26, 17, 22, "role", "directed_by", false, false], [25, 26, 31, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "of", "them", ",", "\"", "Now", "'s", "the", "Time", "to", "Put", "on", "Your", "Glasses", "\"", "and", "\"", "Around", "is", "Around", ",", "\"", "were", "directed", "by", "Norman", "McLaren", "in", "1951", "for", "the", "National", "Film", "Board", "of", "Canada", "."], "sentence-detokenized": "Two of them, \"Now's the Time to Put on Your Glasses\" and \"Around is Around,\" were directed by Norman McLaren in 1951 for the National Film Board of Canada.", "token2charspan": [[0, 3], [4, 6], [7, 11], [11, 12], [13, 14], [14, 17], [17, 19], [20, 23], [24, 28], [29, 31], [32, 35], [36, 38], [39, 43], [44, 51], [51, 52], [53, 56], [57, 58], [58, 64], [65, 67], [68, 74], [74, 75], [75, 76], [77, 81], [82, 90], [91, 93], [94, 100], [101, 108], [109, 111], [112, 116], [117, 120], [121, 124], [125, 133], [134, 138], [139, 144], [145, 147], [148, 154], [154, 155]]}
{"doc_key": "ai-dev-244", "ner": [[0, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "recommender", "system", "aims", "to", "predict", "the", "target", "user", "'s", "preference", "for", "an", "item", "."], "sentence-detokenized": "The recommender system aims to predict the target user's preference for an item.", "token2charspan": [[0, 3], [4, 15], [16, 22], [23, 27], [28, 30], [31, 38], [39, 42], [43, 49], [50, 54], [54, 56], [57, 67], [68, 71], [72, 74], [75, 79], [79, 80]]}
{"doc_key": "ai-dev-245", "ner": [[0, 0, "algorithm"], [4, 4, "field"], [6, 6, "field"], [8, 9, "field"], [11, 13, "field"], [15, 18, "field"], [17, 17, "field"], [20, 20, "field"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 4, "part-of", "", true, false], [0, 0, 6, 6, "part-of", "", true, false], [0, 0, 8, 9, "part-of", "", true, false], [0, 0, 11, 13, "part-of", "", true, false], [0, 0, 15, 18, "part-of", "", true, false], [0, 0, 17, 17, "part-of", "", true, false], [0, 0, 20, 20, "part-of", "", true, false], [0, 0, 23, 24, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Convolution", "has", "applications", "in", "probability", ",", "statistics", ",", "computer", "vision", ",", "natural", "language", "processing", ",", "image", "and", "signal", "processing", ",", "engineering", ",", "and", "differential", "equations", "."], "sentence-detokenized": "Convolution has applications in probability, statistics, computer vision, natural language processing, image and signal processing, engineering, and differential equations.", "token2charspan": [[0, 11], [12, 15], [16, 28], [29, 31], [32, 43], [43, 44], [45, 55], [55, 56], [57, 65], [66, 72], [72, 73], [74, 81], [82, 90], [91, 101], [101, 102], [103, 108], [109, 112], [113, 119], [120, 130], [130, 131], [132, 143], [143, 144], [145, 148], [149, 161], [162, 171], [171, 172]]}
{"doc_key": "ai-dev-246", "ner": [[0, 0, "field"], [3, 5, "task"], [7, 9, "task"], [11, 11, "task"], [12, 12, "task"], [13, 13, "task"], [15, 16, "task"], [18, 19, "task"], [22, 22, "task"], [24, 24, "task"], [27, 28, "task"], [30, 30, "field"], [32, 32, "field"], [34, 36, "field"], [38, 38, "field"], [41, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[0, 0, 3, 5, "part-of", "", true, false], [0, 0, 7, 9, "part-of", "", true, false], [0, 0, 11, 11, "part-of", "", true, false], [0, 0, 12, 12, "part-of", "", true, false], [0, 0, 13, 13, "part-of", "", true, false], [0, 0, 15, 16, "part-of", "", true, false], [0, 0, 18, 19, "part-of", "", true, false], [0, 0, 22, 22, "part-of", "", true, false], [0, 0, 24, 24, "part-of", "", true, false], [0, 0, 27, 28, "part-of", "", true, false], [0, 0, 30, 30, "part-of", "", true, false], [0, 0, 32, 32, "part-of", "", true, false], [0, 0, 34, 36, "part-of", "", true, false], [0, 0, 38, 38, "part-of", "", true, false], [0, 0, 41, 41, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["DSP", "applications", "include", "audio", "signal", "processing", ",", "audio", "signal", "compression", ",", "digital", "image", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communications", ",", "digital", "synthesizers", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", ",", "and", "biomedicine", "."], "sentence-detokenized": "DSP applications include audio signal processing, audio signal compression, digital image processing, video compression, speech processing, speech recognition, digital communications, digital synthesizers, radar, sonar, financial signal processing, seismology, and biomedicine.", "token2charspan": [[0, 3], [4, 16], [17, 24], [25, 30], [31, 37], [38, 48], [48, 49], [50, 55], [56, 62], [63, 74], [74, 75], [76, 83], [84, 89], [90, 100], [100, 101], [102, 107], [108, 119], [119, 120], [121, 127], [128, 138], [138, 139], [140, 146], [147, 158], [158, 159], [160, 167], [168, 182], [182, 183], [184, 191], [192, 204], [204, 205], [206, 211], [211, 212], [213, 218], [218, 219], [220, 229], [230, 236], [237, 247], [247, 248], [249, 259], [259, 260], [261, 264], [265, 276], [276, 277]]}
{"doc_key": "ai-dev-247", "ner": [[13, 15, "misc"], [23, 24, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "February", "20", ",", "1912", "-", "August", "11", ",", "2011", ")", "was", "an", "American", "inventor", "best", "known", "for", "creating", "the", "first", "industrial", "robot", ",", "Unimate", "."], "sentence-detokenized": "(February 20, 1912 - August 11, 2011) was an American inventor best known for creating the first industrial robot, Unimate.", "token2charspan": [[0, 1], [1, 9], [10, 12], [12, 13], [14, 18], [19, 20], [21, 27], [28, 30], [30, 31], [32, 36], [36, 37], [38, 41], [42, 44], [45, 53], [54, 62], [63, 67], [68, 73], [74, 77], [78, 86], [87, 90], [91, 96], [97, 107], [108, 113], [113, 114], [115, 122], [122, 123]]}
{"doc_key": "ai-dev-248", "ner": [[2, 4, "researcher"], [6, 8, "researcher"], [9, 9, "researcher"], [21, 23, "algorithm"], [25, 27, "algorithm"], [35, 36, "task"], [33, 36, "algorithm"], [42, 43, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 21, 23, "related-to", "writes_about", true, false], [6, 8, 21, 23, "related-to", "writes_about", true, false], [9, 9, 21, 23, "related-to", "writes_about", true, false], [21, 23, 25, 27, "related-to", "", true, false], [35, 36, 33, 36, "related-to", "", true, false], [42, 43, 33, 36, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Together", "with", "David", "E.", "Rumelhart", "and", "Ronald", "J.", "Williams", "Hinton", "co-authored", "a", "highly", "cited", "paper", "published", "in", "1986", "that", "popularized", "the", "backpropagation", "algorithm", "for", "training", "multilayer", "neural", "networks", ",", "The", "Dramatic", "Stage", "in", "Alex", "Net", "Image", "Recognition", ",", "designed", "by", "his", "student", "Alex", "Krizhevsky", "{{", "cite", "web"], "sentence-detokenized": "Together with David E. Rumelhart and Ronald J. Williams Hinton co-authored a highly cited paper published in 1986 that popularized the backpropagation algorithm for training multilayer neural networks, The Dramatic Stage in AlexNet Image Recognition, designed by his student Alex Krizhevsky {{cite web", "token2charspan": [[0, 8], [9, 13], [14, 19], [20, 22], [23, 32], [33, 36], [37, 43], [44, 46], [47, 55], [56, 62], [63, 74], [75, 76], [77, 83], [84, 89], [90, 95], [96, 105], [106, 108], [109, 113], [114, 118], [119, 130], [131, 134], [135, 150], [151, 160], [161, 164], [165, 173], [174, 184], [185, 191], [192, 200], [200, 201], [202, 205], [206, 214], [215, 220], [221, 223], [224, 228], [228, 231], [232, 237], [238, 249], [249, 250], [251, 259], [260, 262], [263, 266], [267, 274], [275, 279], [280, 290], [291, 293], [293, 297], [298, 301]]}
{"doc_key": "ai-dev-249", "ner": [[10, 12, "metrics"], [14, 16, "metrics"], [19, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "predicted", "value", "has", "a", "continuous", "distribution", ",", "the", "mean", "squared", "error", ",", "mean", "squared", "error", ",", "or", "median", "absolute", "deviation", "can", "be", "used", "to", "summarize", "the", "errors", "."], "sentence-detokenized": "When the predicted value has a continuous distribution, the mean squared error, mean squared error, or median absolute deviation can be used to summarize the errors.", "token2charspan": [[0, 4], [5, 8], [9, 18], [19, 24], [25, 28], [29, 30], [31, 41], [42, 54], [54, 55], [56, 59], [60, 64], [65, 72], [73, 78], [78, 79], [80, 84], [85, 92], [93, 98], [98, 99], [100, 102], [103, 109], [110, 118], [119, 128], [129, 132], [133, 135], [136, 140], [141, 143], [144, 153], [154, 157], [158, 164], [164, 165]]}
{"doc_key": "ai-dev-250", "ner": [[0, 1, "algorithm"], [10, 11, "field"], [9, 9, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 10, 11, "part-of", "", true, false], [0, 1, 9, 9, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Conceptual", "clustering", "developed", "mainly", "in", "the", "1980s", "as", "an", "unsupervised", "machine", "learning", "paradigm", "."], "sentence-detokenized": "Conceptual clustering developed mainly in the 1980s as an unsupervised machine learning paradigm.", "token2charspan": [[0, 10], [11, 21], [22, 31], [32, 38], [39, 41], [42, 45], [46, 51], [52, 54], [55, 57], [58, 70], [71, 78], [79, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-dev-251", "ner": [[10, 11, "product"], [31, 35, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "named", "entities", "can", "not", "be", "recognized", "by", "the", "machine", "translator", ",", "they", "may", "be", "mistranslated", "as", "common", "nouns", ",", "which", "is", "unlikely", "to", "affect", "the", "translation", "evaluation", "by", "the", "bilingual", "evaluation", "double", ",", "but", "will", "change", "the", "human", "readability", "of", "the", "text", "."], "sentence-detokenized": "If the named entities cannot be recognized by the machine translator, they may be mistranslated as common nouns, which is unlikely to affect the translation evaluation by the bilingual evaluation double, but will change the human readability of the text.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 21], [22, 25], [25, 28], [29, 31], [32, 42], [43, 45], [46, 49], [50, 57], [58, 68], [68, 69], [70, 74], [75, 78], [79, 81], [82, 95], [96, 98], [99, 105], [106, 111], [111, 112], [113, 118], [119, 121], [122, 130], [131, 133], [134, 140], [141, 144], [145, 156], [157, 167], [168, 170], [171, 174], [175, 184], [185, 195], [196, 202], [202, 203], [204, 207], [208, 212], [213, 219], [220, 223], [224, 229], [230, 241], [242, 244], [245, 248], [249, 253], [253, 254]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 22, "location"], [24, 24, "country"], [39, 40, "researcher"], [47, 50, "researcher"], [51, 52, "university"], [56, 57, "researcher"], [59, 60, "researcher"], [63, 64, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 22, "physical", "", false, false], [20, 22, 24, 24, "physical", "", false, false], [47, 50, 51, 52, "physical", "", false, false], [47, 50, 51, 52, "role", "", false, false], [56, 57, 51, 52, "physical", "", false, false], [56, 57, 51, 52, "role", "", false, false], [59, 60, 51, 52, "physical", "", false, false], [59, 60, 51, 52, "role", "", false, false], [63, 64, 51, 52, "physical", "", false, false], [63, 64, 51, 52, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Shank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "Computational", "Linguistics", "Conference", ",", "S\u00e5ng", "-", "S\u00e4by", ",", "Sweden", ",", "pages", "1-", "3", "This", "model", ",", "influenced", "in", "part", "by", "the", "work", "of", "Sidney", "Lamb", ",", "has", "been", "widely", "used", "by", "Shank", "'s", "students", "at", "Yale", "University", ",", "such", "as", "Robert", "Wilensky", ",", "Wendy", "Lechnert", ",", "and", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Shank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 Computational Linguistics Conference, S\u00e5ng-S\u00e4by, Sweden, pages 1-3 This model, influenced in part by the work of Sidney Lamb, has been widely used by Shank's students at Yale University, such as Robert Wilensky, Wendy Lechnert, and Janet Kolodner.", "token2charspan": [[0, 5], [6, 11], [11, 12], [13, 17], [17, 18], [19, 20], [21, 31], [32, 42], [43, 49], [50, 53], [54, 61], [62, 70], [71, 82], [83, 85], [86, 89], [90, 94], [95, 108], [109, 120], [121, 131], [131, 132], [133, 137], [137, 138], [138, 142], [142, 143], [144, 150], [150, 151], [152, 157], [158, 160], [160, 161], [162, 166], [167, 172], [172, 173], [174, 184], [185, 187], [188, 192], [193, 195], [196, 199], [200, 204], [205, 207], [208, 214], [215, 219], [219, 220], [221, 224], [225, 229], [230, 236], [237, 241], [242, 244], [245, 250], [250, 252], [253, 261], [262, 264], [265, 269], [270, 280], [280, 281], [282, 286], [287, 289], [290, 296], [297, 305], [305, 306], [307, 312], [313, 321], [321, 322], [323, 326], [327, 332], [333, 341], [341, 342]]}
{"doc_key": "ai-dev-253", "ner": [[2, 4, "algorithm"], [6, 6, "algorithm"], [13, 13, "algorithm"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 2, 4, "named", "", false, false], [13, 13, 2, 4, "named", "", false, false], [15, 16, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "improved", "maximum", "likelihood", "method", "(", "IMLM", ")", "is", "a", "combination", "of", "two", "MLM", "(", "maximum", "likelihood", ")", "estimators", "."], "sentence-detokenized": "The improved maximum likelihood method (IMLM) is a combination of two MLM (maximum likelihood) estimators.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 38], [39, 40], [40, 44], [44, 45], [46, 48], [49, 50], [51, 62], [63, 65], [66, 69], [70, 73], [74, 75], [75, 82], [83, 93], [93, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-254", "ner": [[21, 22, "metrics"], [25, 26, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[25, 26, 21, 22, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "methods", "can", "also", "analyze", "the", "program", "'s", "performance", "and", "its", "utility", ",", "and", "can", "therefore", "include", "an", "analysis", "of", "its", "confusion", "matrix", "(", "or", "confusion", "table", ")", "."], "sentence-detokenized": "These methods can also analyze the program's performance and its utility, and can therefore include an analysis of its confusion matrix (or confusion table).", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 22], [23, 30], [31, 34], [35, 42], [42, 44], [45, 56], [57, 60], [61, 64], [65, 72], [72, 73], [74, 77], [78, 81], [82, 91], [92, 99], [100, 102], [103, 111], [112, 114], [115, 118], [119, 128], [129, 135], [136, 137], [137, 139], [140, 149], [150, 155], [155, 156], [156, 157]]}
{"doc_key": "ai-dev-255", "ner": [[0, 0, "product"], [5, 6, "researcher"], [8, 9, "researcher"], [11, 13, "researcher"], [18, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 6, "origin", "", false, false], [0, 0, 8, 9, "origin", "", false, false], [0, 0, 11, 13, "origin", "", false, false], [0, 0, 18, 24, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "was", "first", "published", "by", "Herbert", "Bey", ",", "Tine", "Twitelaars", "and", "Luc", "Van", "Gool", "and", "presented", "at", "the", "European", "Conference", "on", "Computer", "Vision", "in", "2006", "."], "sentence-detokenized": "SURF was first published by Herbert Bey, Tine Twitelaars and Luc Van Gool and presented at the European Conference on Computer Vision in 2006.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 39], [39, 40], [41, 45], [46, 56], [57, 60], [61, 64], [65, 68], [69, 73], [74, 77], [78, 87], [88, 90], [91, 94], [95, 103], [104, 114], [115, 117], [118, 126], [127, 133], [134, 136], [137, 141], [141, 142]]}
{"doc_key": "ai-dev-256", "ner": [[0, 0, "task"], [10, 11, "field"], [13, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 10, 11, "part-of", "", false, false], [0, 0, 13, 14, "part-of", "", false, false], [0, 0, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "is", "an", "area", "of", "research", "in", "the", "field", "of", "pattern", "recognition", ",", "artificial", "intelligence", "and", "computer", "vision", "."], "sentence-detokenized": "OCR is an area of research in the field of pattern recognition, artificial intelligence and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 14], [15, 17], [18, 26], [27, 29], [30, 33], [34, 39], [40, 42], [43, 50], [51, 62], [62, 63], [64, 74], [75, 87], [88, 91], [92, 100], [101, 107], [107, 108]]}
{"doc_key": "ai-dev-257", "ner": [[4, 6, "metrics"], [9, 11, "algorithm"], [13, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 15, 9, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Continuing", "the", "example", "using", "maximum", "likelihood", "estimation", ",", "the", "probability", "density", "function", "(", "pdf", ")", "of", "noise", "for", "a", "mathwn", "/", "math", "sample", "is"], "sentence-detokenized": "Continuing the example using maximum likelihood estimation, the probability density function (pdf) of noise for a mathwn/math sample is", "token2charspan": [[0, 10], [11, 14], [15, 22], [23, 28], [29, 36], [37, 47], [48, 58], [58, 59], [60, 63], [64, 75], [76, 83], [84, 92], [93, 94], [94, 97], [97, 98], [99, 101], [102, 107], [108, 111], [112, 113], [114, 120], [120, 121], [121, 125], [126, 132], [133, 135]]}
{"doc_key": "ai-dev-258", "ner": [[2, 3, "field"], [5, 6, "task"], [8, 9, "task"], [11, 12, "task"], [14, 15, "task"], [17, 19, "task"], [21, 21, "task"], [23, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 33, "task"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 6, 2, 3, "part-of", "", false, false], [8, 9, 2, 3, "part-of", "", false, false], [11, 12, 2, 3, "part-of", "", false, false], [14, 15, 2, 3, "part-of", "", false, false], [17, 19, 2, 3, "part-of", "", false, false], [21, 21, 2, 3, "part-of", "", false, false], [23, 23, 2, 3, "part-of", "", false, false], [25, 26, 2, 3, "part-of", "", false, false], [28, 29, 2, 3, "part-of", "", false, false], [31, 33, 2, 3, "part-of", "", false, false], [36, 37, 2, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Subfields", "of", "computer", "vision", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "3D", "pose", "estimation", ",", "training", ",", "indexing", ",", "motion", "estimation", ",", "visual", "control", ",", "3D", "scene", "modeling", ",", "and", "image", "restoration", "."], "sentence-detokenized": "Subfields of computer vision include scene reconstruction, event detection, video tracking, object recognition, 3D pose estimation, training, indexing, motion estimation, visual control, 3D scene modeling, and image restoration.", "token2charspan": [[0, 9], [10, 12], [13, 21], [22, 28], [29, 36], [37, 42], [43, 57], [57, 58], [59, 64], [65, 74], [74, 75], [76, 81], [82, 90], [90, 91], [92, 98], [99, 110], [110, 111], [112, 114], [115, 119], [120, 130], [130, 131], [132, 140], [140, 141], [142, 150], [150, 151], [152, 158], [159, 169], [169, 170], [171, 177], [178, 185], [185, 186], [187, 189], [190, 195], [196, 204], [204, 205], [206, 209], [210, 215], [216, 227], [227, 228]]}
{"doc_key": "ai-dev-259", "ner": [[5, 9, "conference"], [11, 13, "researcher"], [14, 16, "misc"], [19, 19, "conference"], [25, 25, "researcher"], [27, 27, "researcher"], [29, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 9, 19, 19, "named", "", false, false], [11, 13, 14, 16, "win-defeat", "", false, false], [11, 13, 29, 30, "related-to", "writes_about", true, false], [14, 16, 5, 9, "temporal", "", false, false], [25, 25, 14, 16, "win-defeat", "", false, true], [25, 25, 29, 30, "related-to", "writes_about", true, false], [27, 27, 14, 16, "win-defeat", "", false, true], [27, 27, 29, 30, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["In", "2013", ",", "at", "the", "International", "Conference", "on", "Computer", "Vision", ",", "Terzopoulos", "received", "the", "Helmholtz", "Award", "for", "his", "1987", "ICCV", "paper", "in", "which", "he", "and", "Cass", "and", "Witkin", "presented", "active", "contour", "models", "."], "sentence-detokenized": "In 2013, at the International Conference on Computer Vision, Terzopoulos received the Helmholtz Award for his 1987 ICCV paper in which he and Cass and Witkin presented active contour models.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 40], [41, 43], [44, 52], [53, 59], [59, 60], [61, 72], [73, 81], [82, 85], [86, 95], [96, 101], [102, 105], [106, 109], [110, 114], [115, 119], [120, 125], [126, 128], [129, 134], [135, 137], [138, 141], [142, 146], [147, 150], [151, 157], [158, 167], [168, 174], [175, 182], [183, 189], [189, 190]]}
{"doc_key": "ai-dev-260", "ner": [[16, 17, "task"], [19, 21, "algorithm"], [23, 24, "algorithm"], [26, 28, "algorithm"], [30, 31, "algorithm"], [36, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[16, 17, 19, 21, "usage", "", true, false], [16, 17, 23, 24, "usage", "", true, false], [16, 17, 26, 28, "usage", "", true, false], [16, 17, 30, 31, "usage", "", true, false], [16, 17, 36, 36, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["If", "the", "regularization", "function", "There", "are", "many", "algorithms", "for", "solving", "such", "problems", ";", "popular", "ones", "for", "linear", "classification", "include", "Stochastic", "Gradient", "Descent", ")", "Gradient", "Descent", ",", "L", "-", "BFGS", ",", "Coordinate", "Descent", ",", "and", "Newton", "methods", "."], "sentence-detokenized": "If the regularization function There are many algorithms for solving such problems; popular ones for linear classification include Stochastic Gradient Descent) Gradient Descent, L-BFGS, Coordinate Descent, and Newton methods.", "token2charspan": [[0, 2], [3, 6], [7, 21], [22, 30], [31, 36], [37, 40], [41, 45], [46, 56], [57, 60], [61, 68], [69, 73], [74, 82], [82, 83], [84, 91], [92, 96], [97, 100], [101, 107], [108, 122], [123, 130], [131, 141], [142, 150], [151, 158], [158, 159], [160, 168], [169, 176], [176, 177], [178, 179], [179, 180], [180, 184], [184, 185], [186, 196], [197, 204], [204, 205], [206, 209], [210, 216], [217, 224], [224, 225]]}
{"doc_key": "ai-dev-261", "ner": [[0, 4, "algorithm"], [6, 6, "algorithm"], [12, 13, "researcher"], [15, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 12, 13, "origin", "", false, false], [6, 6, 0, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "Short", "-", "Term", "Memory", "(", "LSTM", ")", "networks", "were", "invented", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "and", "set", "accuracy", "records", "in", "multiple", "application", "areas", "."], "sentence-detokenized": "Long Short-Term Memory (LSTM) networks were invented by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997 and set accuracy records in multiple application areas.", "token2charspan": [[0, 4], [5, 10], [10, 11], [11, 15], [16, 22], [23, 24], [24, 28], [28, 29], [30, 38], [39, 43], [44, 52], [53, 55], [56, 60], [61, 71], [72, 75], [76, 82], [83, 94], [95, 97], [98, 102], [103, 106], [107, 110], [111, 119], [120, 127], [128, 130], [131, 139], [140, 151], [152, 157], [157, 158]]}
{"doc_key": "ai-dev-262", "ner": [[0, 0, "product"], [4, 6, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["TN", "was", "developed", "at", "Massachusetts", "General", "Hospital", "and", "has", "been", "tested", "in", "multiple", "scenarios", ",", "including", "retrieval", "of", "smoking", "data", ",", "family", "history", "of", "coronary", "disease", ",", "identification", "of", "patients", "with", "sleep", "disorders", ","], "sentence-detokenized": "TN was developed at Massachusetts General Hospital and has been tested in multiple scenarios, including retrieval of smoking data, family history of coronary disease, identification of patients with sleep disorders,", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 33], [34, 41], [42, 50], [51, 54], [55, 58], [59, 63], [64, 70], [71, 73], [74, 82], [83, 92], [92, 93], [94, 103], [104, 113], [114, 116], [117, 124], [125, 129], [129, 130], [131, 137], [138, 145], [146, 148], [149, 157], [158, 165], [165, 166], [167, 181], [182, 184], [185, 193], [194, 198], [199, 204], [205, 214], [214, 215]]}
{"doc_key": "ai-dev-263", "ner": [[3, 3, "researcher"], [8, 11, "product"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 11, "role", "sells", false, false], [8, 11, 17, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "in", "1961", "to", "General", "Motors", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered in 1961 to General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 83], [84, 86], [87, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-dev-264", "ner": [[0, 4, "conference"], [13, 14, "location"], [16, 16, "location"], [18, 20, "country"], [31, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 13, 14, "physical", "", false, false], [13, 14, 16, 16, "physical", "", false, false], [16, 16, 18, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Campus", "Party", "Europe", "took", "place", "from", "14", "to", "18", "April", "2010", "at", "the", "Caja", "M\u00e1gica", "in", "Madrid", ",", "Spain", ",", "with", "800", "participants", "from", "each", "of", "the", "27", "Member", "States", "of", "the", "European", "Union", "."], "sentence-detokenized": "Campus Party Europe took place from 14 to 18 April 2010 at the Caja M\u00e1gica in Madrid, Spain, with 800 participants from each of the 27 Member States of the European Union.", "token2charspan": [[0, 6], [7, 12], [13, 19], [20, 24], [25, 30], [31, 35], [36, 38], [39, 41], [42, 44], [45, 50], [51, 55], [56, 58], [59, 62], [63, 67], [68, 74], [75, 77], [78, 84], [84, 85], [86, 91], [91, 92], [93, 97], [98, 101], [102, 114], [115, 119], [120, 124], [125, 127], [128, 131], [132, 134], [135, 141], [142, 148], [149, 151], [152, 155], [156, 164], [165, 170], [170, 171]]}
{"doc_key": "ai-dev-265", "ner": [[9, 9, "organisation"], [11, 14, "organisation"], [16, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 21, 9, 9, "origin", "", false, false], [16, 21, 11, 14, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2016", ",", "a", "collaboration", "was", "announced", "between", "DeepMind", "and", "Moorfields", "Eye", "Hospital", "to", "develop", "applications", "of", "artificial", "intelligence", "in", "healthcare", "."], "sentence-detokenized": "In July 2016, a collaboration was announced between DeepMind and Moorfields Eye Hospital to develop applications of artificial intelligence in healthcare.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 15], [16, 29], [30, 33], [34, 43], [44, 51], [52, 60], [61, 64], [65, 75], [76, 79], [80, 88], [89, 91], [92, 99], [100, 112], [113, 115], [116, 126], [127, 139], [140, 142], [143, 153], [153, 154]]}
{"doc_key": "ai-dev-266", "ner": [[7, 8, "misc"], [13, 16, "university"], [18, 18, "university"], [20, 21, "university"], [23, 24, "university"], [26, 26, "university"], [28, 28, "university"], [30, 34, "university"], [36, 37, "university"], [39, 40, "university"], [42, 42, "university"], [45, 47, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[7, 8, 13, 16, "physical", "", false, false], [7, 8, 18, 18, "physical", "", false, false], [7, 8, 20, 21, "physical", "", false, false], [7, 8, 23, 24, "physical", "", false, false], [7, 8, 26, 26, "physical", "", false, false], [7, 8, 28, 28, "physical", "", false, false], [7, 8, 30, 34, "physical", "", false, false], [7, 8, 36, 37, "physical", "", false, false], [7, 8, 39, 40, "physical", "", false, false], [7, 8, 42, 42, "physical", "", false, false], [7, 8, 45, 47, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["In", "the", "end", ",", "they", "awarded", "eleven", "PR2s", "to", "various", "institutions", ",", "including", "the", "University", "of", "Freiburg", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "the", "Technical", "University", "of", "Munich", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", "and", "the", "University", "of", "Tokyo", "."], "sentence-detokenized": "In the end, they awarded eleven PR2s to various institutions, including the University of Freiburg, Bosch, Georgia Tech, KU Leuven, MIT, Stanford, the Technical University of Munich, UC Berkeley, U Penn, USC and the University of Tokyo.", "token2charspan": [[0, 2], [3, 6], [7, 10], [10, 11], [12, 16], [17, 24], [25, 31], [32, 36], [37, 39], [40, 47], [48, 60], [60, 61], [62, 71], [72, 75], [76, 86], [87, 89], [90, 98], [98, 99], [100, 105], [105, 106], [107, 114], [115, 119], [119, 120], [121, 123], [124, 130], [130, 131], [132, 135], [135, 136], [137, 145], [145, 146], [147, 150], [151, 160], [161, 171], [172, 174], [175, 181], [181, 182], [183, 185], [186, 194], [194, 195], [196, 197], [198, 202], [202, 203], [204, 207], [208, 211], [212, 215], [216, 226], [227, 229], [230, 235], [235, 236]]}
{"doc_key": "ai-dev-267", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [7, 7, "metrics"], [9, 11, "metrics"], [19, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 19, 20, "part-of", "", false, false], [5, 5, 19, 20, "part-of", "", false, false], [7, 7, 19, 20, "part-of", "", false, false], [9, 11, 19, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "number", "of", "TP", ",", "TN", ",", "FP", "and", "FN", "is", "usually", "stored", "in", "a", "table", "known", "as", "the", "confusion", "matrix", "."], "sentence-detokenized": "The number of TP, TN, FP and FN is usually stored in a table known as the confusion matrix.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 16], [16, 17], [18, 20], [20, 21], [22, 24], [25, 28], [29, 31], [32, 34], [35, 42], [43, 49], [50, 52], [53, 54], [55, 60], [61, 66], [67, 69], [70, 73], [74, 83], [84, 90], [90, 91]]}
{"doc_key": "ai-dev-268", "ner": [[0, 1, "metrics"], [3, 4, "metrics"], [6, 7, "metrics"], [9, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Information", "gain", ",", "cross", "-entropy", ",", "mutual", "information", "and", "odds", "ratio", "are", "commonly", "used", "as", "a", "set", "of", "features", "."], "sentence-detokenized": "Information gain, cross-entropy, mutual information and odds ratio are commonly used as a set of features.", "token2charspan": [[0, 11], [12, 16], [16, 17], [18, 23], [23, 31], [31, 32], [33, 39], [40, 51], [52, 55], [56, 60], [61, 66], [67, 70], [71, 79], [80, 84], [85, 87], [88, 89], [90, 93], [94, 96], [97, 105], [105, 106]]}
{"doc_key": "ai-dev-269", "ner": [[11, 12, "task"], [14, 15, "task"], [17, 17, "task"], [20, 20, "task"], [22, 22, "task"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[24, 24, 22, 22, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "successfully", "applied", "to", "a", "variety", "of", "problems", "including", "robot", "control", ",", "elevator", "scheduling", ",", "telecommunications", ",", ",", "pools", "and", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "It has been successfully applied to a variety of problems including robot control, elevator scheduling, telecommunications,, pools and Go (AlphaGo).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 32], [33, 35], [36, 37], [38, 45], [46, 48], [49, 57], [58, 67], [68, 73], [74, 81], [81, 82], [83, 91], [92, 102], [102, 103], [104, 122], [122, 123], [123, 124], [125, 130], [131, 134], [135, 137], [138, 139], [139, 146], [146, 147], [147, 148]]}
{"doc_key": "ai-dev-270", "ner": [[11, 14, "misc"], [17, 20, "university"], [23, 23, "location"], [25, 27, "location"], [29, 34, "location"], [37, 39, "location"], [41, 41, "location"], [43, 43, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 14, 17, 20, "physical", "", false, false], [17, 20, 23, 23, "physical", "", false, false], [23, 23, 25, 27, "physical", "", false, false], [29, 34, 37, 39, "physical", "", false, false], [37, 39, 41, 41, "physical", "", false, false], [41, 41, 43, 43, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "the", "first", "year", "of", "Mission", "8", ",", "the", "U.S.", "location", "was", "held", "at", "the", "Georgia", "Institute", "of", "Technology", "campus", "in", "Atlanta", ",", "Georgia", ",", "and", "the", "Asia", "-", "Pacific", "location", "was", "held", "at", "the", "Beihang", "University", "Gymnasium", "in", "Beijing", ",", "China", "."], "sentence-detokenized": "In 2018, the first year of Mission 8, the U.S. location was held at the Georgia Institute of Technology campus in Atlanta, Georgia, and the Asia-Pacific location was held at the Beihang University Gymnasium in Beijing, China.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 18], [19, 23], [24, 26], [27, 34], [35, 36], [36, 37], [38, 41], [42, 46], [47, 55], [56, 59], [60, 64], [65, 67], [68, 71], [72, 79], [80, 89], [90, 92], [93, 103], [104, 110], [111, 113], [114, 121], [121, 122], [123, 130], [130, 131], [132, 135], [136, 139], [140, 144], [144, 145], [145, 152], [153, 161], [162, 165], [166, 170], [171, 173], [174, 177], [178, 185], [186, 196], [197, 206], [207, 209], [210, 217], [217, 218], [219, 224], [224, 225]]}
{"doc_key": "ai-dev-271", "ner": [[0, 1, "field"], [6, 7, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "origin", "", false, false], [0, 1, 6, 7, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "is", "closely", "related", "to", "pattern", "recognition", "and", "is", "derived", "from", "artificial", "intelligence", "."], "sentence-detokenized": "Machine learning is closely related to pattern recognition and is derived from artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 35], [36, 38], [39, 46], [47, 58], [59, 62], [63, 65], [66, 73], [74, 78], [79, 89], [90, 102], [102, 103]]}
{"doc_key": "ai-dev-272", "ner": [[4, 4, "programlang"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "comes", "with", "3", "Java", "games", "that", "are", "controlled", "with", "the", "remote", "control", "and", "displayed", "on", "its", "LCD", "screen", "."], "sentence-detokenized": "It comes with 3 Java games that are controlled with the remote control and displayed on its LCD screen.", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 15], [16, 20], [21, 26], [27, 31], [32, 35], [36, 46], [47, 51], [52, 55], [56, 62], [63, 70], [71, 74], [75, 84], [85, 87], [88, 91], [92, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-dev-273", "ner": [[7, 15, "task"], [17, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 19, 7, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "commercially", "successful", "but", "specialized", "technique", "for", "computer", "vision", "-", "based", "pose", "estimation", "of", "articulated", "bodies", "is", "optical", "motion", "capture", "."], "sentence-detokenized": "A commercially successful but specialized technique for computer vision-based pose estimation of articulated bodies is optical motion capture.", "token2charspan": [[0, 1], [2, 14], [15, 25], [26, 29], [30, 41], [42, 51], [52, 55], [56, 64], [65, 71], [71, 72], [72, 77], [78, 82], [83, 93], [94, 96], [97, 108], [109, 115], [116, 118], [119, 126], [127, 133], [134, 141], [141, 142]]}
{"doc_key": "ai-dev-274", "ner": [[0, 1, "organisation"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SMC", "is", "very", "similar", "to", "the", "more", "popular", "Jaccard", "index", "."], "sentence-detokenized": "The SMC is very similar to the more popular Jaccard index.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 23], [24, 26], [27, 30], [31, 35], [36, 43], [44, 51], [52, 57], [57, 58]]}
{"doc_key": "ai-dev-275", "ner": [[0, 0, "product"], [2, 5, "product"], [7, 10, "product"], [19, 20, "researcher"], [26, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 7, 10, "named", "", false, false], [0, 0, 19, 20, "artifact", "", false, false], [0, 0, 26, 26, "artifact", "", false, false], [2, 5, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["PUMA", "(", "Programmable", "Universal", "Machine", "Assembly", "or", "Programmable", "Universal", "Manipulation", "Arm", ")", "is", "an", "industrial", "robotic", "arm", "developed", "by", "Victor", "Shainman", "at", "the", "pioneering", "robot", "company", "Unimation", "."], "sentence-detokenized": "PUMA (Programmable Universal Machine Assembly or Programmable Universal Manipulation Arm) is an industrial robotic arm developed by Victor Shainman at the pioneering robot company Unimation.", "token2charspan": [[0, 4], [5, 6], [6, 18], [19, 28], [29, 36], [37, 45], [46, 48], [49, 61], [62, 71], [72, 84], [85, 88], [88, 89], [90, 92], [93, 95], [96, 106], [107, 114], [115, 118], [119, 128], [129, 131], [132, 138], [139, 147], [148, 150], [151, 154], [155, 165], [166, 171], [172, 179], [180, 189], [189, 190]]}
{"doc_key": "ai-dev-276", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "written", "in", "Python", "."], "sentence-detokenized": "It is written in Python.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 23], [23, 24]]}
{"doc_key": "ai-dev-277", "ner": [[0, 1, "misc"], [2, 2, "misc"], [12, 12, "field"], [14, 15, "field"], [17, 17, "field"], [23, 24, "field"], [27, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7], "relations": [[0, 1, 2, 2, "related-to", "metric_for", true, false], [0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 15, "part-of", "", false, false], [0, 1, 17, 17, "part-of", "", false, false], [0, 1, 23, 24, "part-of", "", false, false], [0, 1, 27, 27, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6], "sentence": ["Bandwidth", "in", "hertz", "is", "a", "fundamental", "concept", "in", "many", "fields", ",", "including", "electronics", ",", "information", "theory", ",", "digital", "communications", ",", "radio", "communications", ",", "signal", "processing", ",", "and", "spectroscopy", ",", "and", "is", "one", "of", "the", "determining", "factors", "for", "the", "capacity", "of", "a", "communications", "channel", "."], "sentence-detokenized": "Bandwidth in hertz is a fundamental concept in many fields, including electronics, information theory, digital communications, radio communications, signal processing, and spectroscopy, and is one of the determining factors for the capacity of a communications channel.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 21], [22, 23], [24, 35], [36, 43], [44, 46], [47, 51], [52, 58], [58, 59], [60, 69], [70, 81], [81, 82], [83, 94], [95, 101], [101, 102], [103, 110], [111, 125], [125, 126], [127, 132], [133, 147], [147, 148], [149, 155], [156, 166], [166, 167], [168, 171], [172, 184], [184, 185], [186, 189], [190, 192], [193, 196], [197, 199], [200, 203], [204, 215], [216, 223], [224, 227], [228, 231], [232, 240], [241, 243], [244, 245], [246, 260], [261, 268], [268, 269]]}
{"doc_key": "ai-dev-278", "ner": [[8, 8, "algorithm"], [10, 10, "algorithm"], [17, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 17, 23, "part-of", "", false, false], [10, 10, 17, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "convex", "loss", "is", "used", "(", "as", "in", "AdaBoost", ",", "LogitBoost", ",", "and", "all", "members", "of", "the", "AnyBoost", "family", "of", "algorithms", ")", ",", "then", "an", "example", "with", "a", "larger", "margin", "will", "receive", "less", "(", "or", "equal", ")", "weight", "than", "an", "example", "with", "a", "smaller", "margin", "."], "sentence-detokenized": "If convex loss is used (as in AdaBoost, LogitBoost, and all members of the AnyBoost family of algorithms), then an example with a larger margin will receive less (or equal) weight than an example with a smaller margin.", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 17], [18, 22], [23, 24], [24, 26], [27, 29], [30, 38], [38, 39], [40, 50], [50, 51], [52, 55], [56, 59], [60, 67], [68, 70], [71, 74], [75, 83], [84, 90], [91, 93], [94, 104], [104, 105], [105, 106], [107, 111], [112, 114], [115, 122], [123, 127], [128, 129], [130, 136], [137, 143], [144, 148], [149, 156], [157, 161], [162, 163], [163, 165], [166, 171], [171, 172], [173, 179], [180, 184], [185, 187], [188, 195], [196, 200], [201, 202], [203, 210], [211, 217], [217, 218]]}
{"doc_key": "ai-dev-279", "ner": [[0, 0, "researcher"], [1, 1, "researcher"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 1, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sep", "Hochreiter", "'s", "1991", "thesis", "."], "sentence-detokenized": "Sep Hochreiter's 1991 thesis.", "token2charspan": [[0, 3], [4, 14], [14, 16], [17, 21], [22, 28], [28, 29]]}
{"doc_key": "ai-dev-280", "ner": [[4, 5, "algorithm"], [7, 7, "algorithm"], [10, 12, "algorithm"], [14, 14, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [27, 28, "algorithm"], [31, 32, "algorithm"], [34, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 7, 4, 5, "named", "", false, false], [14, 14, 10, 12, "named", "", false, false], [17, 19, 27, 28, "related-to", "", true, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Typical", "discriminative", "models", "include", "logistic", "regression", "(", "LR", ")", ",", "support", "vector", "machines", "(", "SVM", ")", ",", "conditional", "random", "fields", "(", "CRF", ")", "(", "set", "on", "an", "undirected", "graph", ")", ",", "decision", "trees", ",", "neural", "networks", ",", "and", "many", "others", "."], "sentence-detokenized": "Typical discriminative models include logistic regression (LR), support vector machines (SVM), conditional random fields (CRF) (set on an undirected graph), decision trees, neural networks, and many others.", "token2charspan": [[0, 7], [8, 22], [23, 29], [30, 37], [38, 46], [47, 57], [58, 59], [59, 61], [61, 62], [62, 63], [64, 71], [72, 78], [79, 87], [88, 89], [89, 92], [92, 93], [93, 94], [95, 106], [107, 113], [114, 120], [121, 122], [122, 125], [125, 126], [127, 128], [128, 131], [132, 134], [135, 137], [138, 148], [149, 154], [154, 155], [155, 156], [157, 165], [166, 171], [171, 172], [173, 179], [180, 188], [188, 189], [190, 193], [194, 198], [199, 205], [205, 206]]}
{"doc_key": "ai-dev-281", "ner": [[11, 13, "metrics"], [31, 34, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "then", "possible", "to", "use", "these", "probabilities", "and", "estimate", "the", "mean", "squared", "error", "(", "or", "similar", "measure", ")", "between", "the", "probabilities", "and", "the", "actual", "values", ",", "then", "combine", "with", "the", "confusion", "matrix", "to", "create", "very", "efficient", "goodness", "-", "of", "-", "fit", "functions", "for", "logistic", "regression", "."], "sentence-detokenized": "It is then possible to use these probabilities and estimate the mean squared error (or similar measure) between the probabilities and the actual values, then combine with the confusion matrix to create very efficient goodness-of-fit functions for logistic regression.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 19], [20, 22], [23, 26], [27, 32], [33, 46], [47, 50], [51, 59], [60, 63], [64, 68], [69, 76], [77, 82], [83, 84], [84, 86], [87, 94], [95, 102], [102, 103], [104, 111], [112, 115], [116, 129], [130, 133], [134, 137], [138, 144], [145, 151], [151, 152], [153, 157], [158, 165], [166, 170], [171, 174], [175, 184], [185, 191], [192, 194], [195, 201], [202, 206], [207, 216], [217, 225], [225, 226], [226, 228], [228, 229], [229, 232], [233, 242], [243, 246], [247, 255], [256, 266], [266, 267]]}
{"doc_key": "ai-dev-282", "ner": [[0, 0, "product"], [7, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "was", "first", "included", "in", "2005", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "."], "sentence-detokenized": "VoiceOver was first included in 2005 in Mac OS X Tiger (10.4).", "token2charspan": [[0, 9], [10, 13], [14, 19], [20, 28], [29, 31], [32, 36], [37, 39], [40, 43], [44, 46], [47, 48], [49, 54], [55, 56], [56, 60], [60, 61], [61, 62]]}
{"doc_key": "ai-dev-283", "ner": [[13, 16, "algorithm"], [19, 21, "misc"], [26, 27, "metrics"], [30, 35, "algorithm"], [61, 64, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 16, 19, 21, "related-to", "applied_to", false, false], [26, 27, 19, 21, "type-of", "", false, false], [26, 27, 30, 35, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "practice", ",", "machine", "learning", "algorithms", "deal", "with", "this", "either", "by", "using", "a", "convex", "approximation", "of", "the", "0", "-", "1", "loss", "function", "(", "such", "as", "the", "hinge", "loss", "for", "a", "Support", "vector", "machine", ")", "that", "is", "easier", "to", "optimize", ",", "or", "by", "imposing", "assumptions", "on", "the", "mathP", "(", "x", ",", "y", ")", "/", "math", "distribution", "(", "and", "thus", "ceasing", "to", "be", "agnostic", "learning", "algorithms", "for", "which", "the", "above", "result", "holds", ")", "."], "sentence-detokenized": "In practice, machine learning algorithms deal with this either by using a convex approximation of the 0-1 loss function (such as the hinge loss for a Support vector machine) that is easier to optimize, or by imposing assumptions on the mathP (x, y)/math distribution (and thus ceasing to be agnostic learning algorithms for which the above result holds).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 29], [30, 40], [41, 45], [46, 50], [51, 55], [56, 62], [63, 65], [66, 71], [72, 73], [74, 80], [81, 94], [95, 97], [98, 101], [102, 103], [103, 104], [104, 105], [106, 110], [111, 119], [120, 121], [121, 125], [126, 128], [129, 132], [133, 138], [139, 143], [144, 147], [148, 149], [150, 157], [158, 164], [165, 172], [172, 173], [174, 178], [179, 181], [182, 188], [189, 191], [192, 200], [200, 201], [202, 204], [205, 207], [208, 216], [217, 228], [229, 231], [232, 235], [236, 241], [242, 243], [243, 244], [244, 245], [246, 247], [247, 248], [248, 249], [249, 253], [254, 266], [267, 268], [268, 271], [272, 276], [277, 284], [285, 287], [288, 290], [291, 299], [300, 308], [309, 319], [320, 323], [324, 329], [330, 333], [334, 339], [340, 346], [347, 352], [352, 353], [353, 354]]}
{"doc_key": "ai-dev-284", "ner": [[0, 1, "misc"], [12, 14, "field"], [24, 25, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 12, 14, "usage", "", false, false], [0, 1, 24, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["\"", "Westworld", "(", "1973", ")", "was", "the", "first", "feature", "film", "to", "use", "digital", "image", "processing", "in", "photography", "to", "simulate", "the", "point", "of", "view", "of", "an", "android", "."], "sentence-detokenized": "\"Westworld (1973) was the first feature film to use digital image processing in photography to simulate the point of view of an android.", "token2charspan": [[0, 1], [1, 10], [11, 12], [12, 16], [16, 17], [18, 21], [22, 25], [26, 31], [32, 39], [40, 44], [45, 47], [48, 51], [52, 59], [60, 65], [66, 76], [77, 79], [80, 91], [92, 94], [95, 103], [104, 107], [108, 113], [114, 116], [117, 121], [122, 124], [125, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-dev-285", "ner": [[8, 9, "task"], [11, 12, "task"], [14, 14, "task"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Currently", ",", "it", "is", "also", "commonly", "used", "in", "speech", "recognition", ",", "speech", "synthesis", ",", "diarization", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "Currently, it is also commonly used in speech recognition, speech synthesis, diarization, Xavier Anguera et al.", "token2charspan": [[0, 9], [9, 10], [11, 13], [14, 16], [17, 21], [22, 30], [31, 35], [36, 38], [39, 45], [46, 57], [57, 58], [59, 65], [66, 75], [75, 76], [77, 88], [88, 89], [90, 96], [97, 104], [105, 107], [108, 110], [110, 111]]}
{"doc_key": "ai-dev-286", "ner": [[9, 13, "algorithm"], [18, 20, "algorithm"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 20, 9, 13, "type-of", "", false, false], [23, 25, 9, 13, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Here", ",", "math", "/", "sigma", "/", "math", "is", "an", "element", "-", "wise", "activation", "function", ",", "for", "example", ",", "a", "sigmoid", "function", "or", "a", "corrected", "linear", "unit", "."], "sentence-detokenized": "Here, math/sigma/math is an element-wise activation function, for example, a sigmoid function or a corrected linear unit.", "token2charspan": [[0, 4], [4, 5], [6, 10], [10, 11], [11, 16], [16, 17], [17, 21], [22, 24], [25, 27], [28, 35], [35, 36], [36, 40], [41, 51], [52, 60], [60, 61], [62, 65], [66, 73], [73, 74], [75, 76], [77, 84], [85, 93], [94, 96], [97, 98], [99, 108], [109, 115], [116, 120], [120, 121]]}
{"doc_key": "ai-dev-287", "ner": [[11, 13, "algorithm"], [21, 21, "misc"], [23, 23, "misc"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "phonological", "approaches", "(", "i.e.", ",", "all", "models", "based", "on", "a", "hidden", "Markov", "model", ")", "require", "separate", "components", "and", "training", "for", "pronunciation", ",", "acoustic", ",", "and", "language", "model", "."], "sentence-detokenized": "Traditional phonological approaches (i.e., all models based on a hidden Markov model) require separate components and training for pronunciation, acoustic, and language model.", "token2charspan": [[0, 11], [12, 24], [25, 35], [36, 37], [37, 41], [41, 42], [43, 46], [47, 53], [54, 59], [60, 62], [63, 64], [65, 71], [72, 78], [79, 84], [84, 85], [86, 93], [94, 102], [103, 113], [114, 117], [118, 126], [127, 130], [131, 144], [144, 145], [146, 154], [154, 155], [156, 159], [160, 168], [169, 174], [174, 175]]}
{"doc_key": "ai-dev-288", "ner": [[0, 5, "algorithm"], [7, 8, "field"], [10, 11, "field"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 5, 13, 14, "related-to", "used_for", false, false], [7, 8, 0, 5, "usage", "", false, false], [10, 11, 0, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Roberts", "cross", "operator", "is", "used", "in", "image", "processing", "and", "computer", "vision", "for", "edge", "detection", "."], "sentence-detokenized": "The Roberts cross operator is used in image processing and computer vision for edge detection.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 37], [38, 43], [44, 54], [55, 58], [59, 67], [68, 74], [75, 78], [79, 83], [84, 93], [93, 94]]}
{"doc_key": "ai-dev-289", "ner": [[0, 1, "metrics"], [3, 3, "metrics"], [23, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 23, 23, "opposite", "", false, false], [3, 3, 23, 23, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "sensitivity", "and", "specificity", "values", "do", "not", "depend", "on", "the", "percentage", "of", "positive", "cases", "in", "the", "population", "you", "are", "interested", "in", "(", "unlike", "precision", ",", "for", "example", ")", "."], "sentence-detokenized": "The sensitivity and specificity values do not depend on the percentage of positive cases in the population you are interested in (unlike precision, for example).", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 31], [32, 38], [39, 41], [42, 45], [46, 52], [53, 55], [56, 59], [60, 70], [71, 73], [74, 82], [83, 88], [89, 91], [92, 95], [96, 106], [107, 110], [111, 114], [115, 125], [126, 128], [129, 130], [130, 136], [137, 146], [146, 147], [148, 151], [152, 159], [159, 160], [160, 161]]}
{"doc_key": "ai-dev-290", "ner": [[1, 2, "algorithm"], [14, 14, "misc"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 14, 1, 2, "topic", "", false, false], [14, 14, 7, 8, "artifact", "", false, false], [14, 14, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["But", "perceptron", "models", "became", "very", "unpopular", "with", "Marvin", "Minsky", "and", "Seymour", "Pappert", "'s", "book", "Perceptrons", ",", "published", "in", "1969", "."], "sentence-detokenized": "But perceptron models became very unpopular with Marvin Minsky and Seymour Pappert's book Perceptrons, published in 1969.", "token2charspan": [[0, 3], [4, 14], [15, 21], [22, 28], [29, 33], [34, 43], [44, 48], [49, 55], [56, 62], [63, 66], [67, 74], [75, 82], [82, 84], [85, 89], [90, 101], [101, 102], [103, 112], [113, 115], [116, 120], [120, 121]]}
{"doc_key": "ai-dev-291", "ner": [[0, 3, "conference"], [7, 7, "organisation"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 21, 23, "topic", "", false, false], [7, 7, 0, 3, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "document", "understanding", "conferences", "held", "annually", "by", "NIST", "have", "developed", "sophisticated", "criteria", "for", "evaluating", "techniques", "that", "take", "on", "the", "challenge", "of", "summarizing", "many", "documents", "."], "sentence-detokenized": "The document understanding conferences held annually by NIST have developed sophisticated criteria for evaluating techniques that take on the challenge of summarizing many documents.", "token2charspan": [[0, 3], [4, 12], [13, 26], [27, 38], [39, 43], [44, 52], [53, 55], [56, 60], [61, 65], [66, 75], [76, 89], [90, 98], [99, 102], [103, 113], [114, 124], [125, 129], [130, 134], [135, 137], [138, 141], [142, 151], [152, 154], [155, 166], [167, 171], [172, 181], [181, 182]]}
{"doc_key": "ai-dev-292", "ner": [[0, 2, "product"], [25, 26, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 25, 26, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "parallel", "manipulator", "is", "designed", "so", "that", "each", "circuit", "is", "usually", "short", ",", "simple", "and", "thus", "can", "be", "rigid", "against", "unwanted", "movement", "compared", "to", "the", "serial", "manipulator", "."], "sentence-detokenized": "The parallel manipulator is designed so that each circuit is usually short, simple and thus can be rigid against unwanted movement compared to the serial manipulator.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 27], [28, 36], [37, 39], [40, 44], [45, 49], [50, 57], [58, 60], [61, 68], [69, 74], [74, 75], [76, 82], [83, 86], [87, 91], [92, 95], [96, 98], [99, 104], [105, 112], [113, 121], [122, 130], [131, 139], [140, 142], [143, 146], [147, 153], [154, 165], [165, 166]]}
{"doc_key": "ai-dev-293", "ner": [[25, 25, "misc"], [27, 31, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "manipulator", "is", "what", "makes", "the", "robot", "move", ",", "and", "the", "design", "of", "these", "systems", "can", "be", "divided", "into", "several", "general", "types", ",", "such", "as", "SCARA", "and", "Cartesian", "coordinate", "robot", ",", "which", "use", "different", "coordinate", "systems", "to", "guide", "the", "machine", "'s", "arms", "."], "sentence-detokenized": "The manipulator is what makes the robot move, and the design of these systems can be divided into several general types, such as SCARA and Cartesian coordinate robot, which use different coordinate systems to guide the machine's arms.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 23], [24, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 49], [50, 53], [54, 60], [61, 63], [64, 69], [70, 77], [78, 81], [82, 84], [85, 92], [93, 97], [98, 105], [106, 113], [114, 119], [119, 120], [121, 125], [126, 128], [129, 134], [135, 138], [139, 148], [149, 159], [160, 165], [165, 166], [167, 172], [173, 176], [177, 186], [187, 197], [198, 205], [206, 208], [209, 214], [215, 218], [219, 226], [226, 228], [229, 233], [233, 234]]}
{"doc_key": "ai-dev-294", "ner": [[5, 7, "country"], [11, 14, "organisation"], [17, 24, "organisation"], [25, 28, "organisation"], [31, 33, "organisation"], [37, 43, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 14, 5, 7, "physical", "", false, false], [17, 24, 5, 7, "physical", "", false, false], [25, 28, 5, 7, "physical", "", false, false], [31, 33, 5, 7, "physical", "", false, false], [37, 43, 5, 7, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "United", "States", ",", "he", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "Linguistic", "Society", "of", "America", ",", "the", "American", "Philosophical", "Association", ",", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In the United States, he is a member of the National Academy of Sciences, the American Academy of Arts and Sciences, the Linguistic Society of America, the American Philosophical Association, and the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 20], [20, 21], [22, 24], [25, 27], [28, 29], [30, 36], [37, 39], [40, 43], [44, 52], [53, 60], [61, 63], [64, 72], [72, 73], [74, 77], [78, 86], [87, 94], [95, 97], [98, 102], [103, 106], [107, 115], [115, 116], [117, 120], [121, 131], [132, 139], [140, 142], [143, 150], [150, 151], [152, 155], [156, 164], [165, 178], [179, 190], [190, 191], [192, 195], [196, 199], [200, 208], [209, 220], [221, 224], [225, 228], [229, 240], [241, 243], [244, 251], [251, 252]]}
{"doc_key": "ai-dev-295", "ner": [[8, 11, "algorithm"], [13, 13, "algorithm"], [20, 20, "algorithm"], [27, 28, "algorithm"], [33, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 11, 20, 20, "named", "", false, false], [13, 13, 8, 11, "named", "", false, false], [20, 20, 27, 28, "compare", "", false, false], [20, 20, 33, 35, "related-to", "performs", false, false], [27, 28, 33, 35, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["They", "gained", "great", "popularity", "with", "the", "popularity", "of", "the", "support", "vector", "machine", "(", "SVM", ")", "in", "the", "1990s", ",", "when", "SVM", "was", "found", "to", "be", "competitive", "with", "neural", "networks", "in", "tasks", "such", "as", "handwritten", "text", "recognition", "."], "sentence-detokenized": "They gained great popularity with the popularity of the support vector machine (SVM) in the 1990s, when SVM was found to be competitive with neural networks in tasks such as handwritten text recognition.", "token2charspan": [[0, 4], [5, 11], [12, 17], [18, 28], [29, 33], [34, 37], [38, 48], [49, 51], [52, 55], [56, 63], [64, 70], [71, 78], [79, 80], [80, 83], [83, 84], [85, 87], [88, 91], [92, 97], [97, 98], [99, 103], [104, 107], [108, 111], [112, 117], [118, 120], [121, 123], [124, 135], [136, 140], [141, 147], [148, 156], [157, 159], [160, 165], [166, 170], [171, 173], [174, 185], [186, 190], [191, 202], [202, 203]]}
{"doc_key": "ai-dev-296", "ner": [[2, 3, "misc"], [9, 9, "misc"], [13, 14, "algorithm"], [22, 25, "misc"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 9, "usage", "", false, false], [2, 3, 22, 25, "usage", "", false, false], [9, 9, 13, 14, "origin", "result_of_algorithm", false, false], [22, 25, 27, 28, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "empirical", "whitening", "transformation", "is", "obtained", "by", "estimating", "the", "covariance", "(", "e.g.", "by", "maximum", "likelihood", ")", "and", "subsequently", "constructing", "the", "corresponding", "estimated", "whitening", "matrix", "(", "e.g.", "by", "Cholesky", "decomposition", ")", "."], "sentence-detokenized": "The empirical whitening transformation is obtained by estimating the covariance (e.g. by maximum likelihood) and subsequently constructing the corresponding estimated whitening matrix (e.g. by Cholesky decomposition).", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 38], [39, 41], [42, 50], [51, 53], [54, 64], [65, 68], [69, 79], [80, 81], [81, 85], [86, 88], [89, 96], [97, 107], [107, 108], [109, 112], [113, 125], [126, 138], [139, 142], [143, 156], [157, 166], [167, 176], [177, 183], [184, 185], [185, 189], [190, 192], [193, 201], [202, 215], [215, 216], [216, 217]]}
{"doc_key": "ai-dev-297", "ner": [[0, 0, "organisation"], [8, 10, "product"], [24, 25, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 0, 0, "artifact", "", false, false], [24, 25, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "is", "the", "world", "'s", "largest", "manufacturer", "of", "Cartesian", "coordinate", "robots", "and", "is", "an", "established", "leader", "in", "low", "-", "cost", ",", "high", "-", "performance", "SCARA", "robots", "."], "sentence-detokenized": "IAI is the world's largest manufacturer of Cartesian coordinate robots and is an established leader in low-cost, high-performance SCARA robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [16, 18], [19, 26], [27, 39], [40, 42], [43, 52], [53, 63], [64, 70], [71, 74], [75, 77], [78, 80], [81, 92], [93, 99], [100, 102], [103, 106], [106, 107], [107, 111], [111, 112], [113, 117], [117, 118], [118, 129], [130, 135], [136, 142], [142, 143]]}
{"doc_key": "ai-dev-298", "ner": [[11, 11, "field"], [13, 14, "field"], [16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formal", "concept", "analysis", "finds", "practical", "applications", "in", "areas", "such", "as", "data", "mining", ",", "text", "mining", ",", "machine", "learning", ",", "knowledge", "management", ",", "semantic", "web", ",", "software", "development", ",", "chemistry", "and", "biology", "."], "sentence-detokenized": "Formal concept analysis finds practical applications in areas such as data mining, text mining, machine learning, knowledge management, semantic web, software development, chemistry and biology.", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 29], [30, 39], [40, 52], [53, 55], [56, 61], [62, 66], [67, 69], [70, 74], [75, 81], [81, 82], [83, 87], [88, 94], [94, 95], [96, 103], [104, 112], [112, 113], [114, 123], [124, 134], [134, 135], [136, 144], [145, 148], [148, 149], [150, 158], [159, 170], [170, 171], [172, 181], [182, 185], [186, 193], [193, 194]]}
{"doc_key": "ai-dev-299", "ner": [[1, 2, "field"], [4, 6, "field"], [10, 11, "field"], [17, 18, "field"], [29, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 17, 18, "part-of", "", false, false], [4, 6, 29, 31, "topic", "", false, false], [10, 11, 4, 6, "named", "", false, false], [17, 18, 1, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", ",", "machine", "learning", "theory", "(", "or", "simply", "learning", "theory", ")", "is", "a", "subfield", "of", "artificial", "intelligence", "devoted", "to", "the", "study", "of", "the", "design", "and", "analysis", "of", "machine", "learning", "algorithms", "."], "sentence-detokenized": "In computer science, machine learning theory (or simply learning theory) is a subfield of artificial intelligence devoted to the study of the design and analysis of machine learning algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 28], [29, 37], [38, 44], [45, 46], [46, 48], [49, 55], [56, 64], [65, 71], [71, 72], [73, 75], [76, 77], [78, 86], [87, 89], [90, 100], [101, 113], [114, 121], [122, 124], [125, 128], [129, 134], [135, 137], [138, 141], [142, 148], [149, 152], [153, 161], [162, 164], [165, 172], [173, 181], [182, 192], [192, 193]]}
{"doc_key": "ai-dev-300", "ner": [[0, 1, "algorithm"], [3, 3, "algorithm"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 1, "named", "", false, false], [11, 11, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Collaborative", "filtering", "(", "CF", ")", "is", "a", "technique", "used", "by", "the", "recommended", "systems", "."], "sentence-detokenized": "Collaborative filtering (CF) is a technique used by the recommended systems.", "token2charspan": [[0, 13], [14, 23], [24, 25], [25, 27], [27, 28], [29, 31], [32, 33], [34, 43], [44, 48], [49, 51], [52, 55], [56, 67], [68, 75], [75, 76]]}
{"doc_key": "ai-dev-301", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "false", "positive", "rate", "is", "the", "proportion", "of", "all", "negative", "results", "that", "still", "give", "a", "positive", "test", "result", ",", "i.e.", "the", "conditional", "probability", "of", "a", "positive", "test", "result", "given", "that", "no", "event", "has", "occurred", "."], "sentence-detokenized": "The false positive rate is the proportion of all negative results that still give a positive test result, i.e. the conditional probability of a positive test result given that no event has occurred.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 23], [24, 26], [27, 30], [31, 41], [42, 44], [45, 48], [49, 57], [58, 65], [66, 70], [71, 76], [77, 81], [82, 83], [84, 92], [93, 97], [98, 104], [104, 105], [106, 110], [111, 114], [115, 126], [127, 138], [139, 141], [142, 143], [144, 152], [153, 157], [158, 164], [165, 170], [171, 175], [176, 178], [179, 184], [185, 188], [189, 197], [197, 198]]}
{"doc_key": "ai-dev-302", "ner": [[1, 15, "misc"], [37, 38, "metrics"], [41, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 15, 37, 38, "topic", "", false, false], [1, 15, 41, 41, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "VLDB", "'", "8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pages", "422-433", ".", "showed", "that", "the", "values", "given", "for", "mathC", "/", "math", "and", "mathK", "/", "math", "typically", "imply", "relatively", "low", "accuracy", "of", "iteratively", "computed", "SimRank", "results", "."], "sentence-detokenized": "In VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, pages 422-433. showed that the values given for mathC/math and mathK/math typically imply relatively low accuracy of iteratively computed SimRank results.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [10, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 79], [80, 85], [85, 86], [87, 92], [93, 100], [100, 101], [102, 108], [109, 113], [114, 117], [118, 124], [125, 130], [131, 134], [135, 140], [140, 141], [141, 145], [146, 149], [150, 155], [155, 156], [156, 160], [161, 170], [171, 176], [177, 187], [188, 191], [192, 200], [201, 203], [204, 215], [216, 224], [225, 232], [233, 240], [240, 241]]}
{"doc_key": "ai-dev-303", "ner": [[5, 8, "misc"], [9, 9, "misc"], [15, 15, "person"], [17, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 5, 8, "general-affiliation", "", false, false], [9, 9, 15, 15, "artifact", "", false, false], [9, 9, 17, 19, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "June", "2015", ",", "the", "sci", "-", "fi", "drama", "Sense8", ",", "written", "and", "produced", "by", "Waschowski", "and", "J.", "Michael", "Straczynski", ",", "debuted", "."], "sentence-detokenized": "In June 2015, the sci-fi drama Sense8, written and produced by Waschowski and J. Michael Straczynski, debuted.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 21], [21, 22], [22, 24], [25, 30], [31, 37], [37, 38], [39, 46], [47, 50], [51, 59], [60, 62], [63, 73], [74, 77], [78, 80], [81, 88], [89, 100], [100, 101], [102, 109], [109, 110]]}
{"doc_key": "ai-dev-304", "ner": [[1, 1, "misc"], [6, 9, "product"], [23, 27, "misc"], [33, 33, "country"], [35, 35, "country"], [37, 37, "country"], [39, 39, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 1, 6, 9, "topic", "", false, false], [33, 33, 23, 27, "type-of", "", false, false], [35, 35, 23, 27, "type-of", "", false, false], [37, 37, 23, 27, "type-of", "", false, false], [39, 39, 23, 27, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Although", "Eurotra", "never", "delivered", "a", "working", "MT", "system", ",", "the", "project", "had", "a", "long", "-", "term", "impact", "on", "the", "nascent", "language", "industries", "in", "European", "member", "states", ",", "particularly", "in", "the", "southern", "countries", "of", "Greece", ",", "Italy", ",", "Spain", "and", "Portugal", "."], "sentence-detokenized": "Although Eurotra never delivered a working MT system, the project had a long-term impact on the nascent language industries in European member states, particularly in the southern countries of Greece, Italy, Spain and Portugal.", "token2charspan": [[0, 8], [9, 16], [17, 22], [23, 32], [33, 34], [35, 42], [43, 45], [46, 52], [52, 53], [54, 57], [58, 65], [66, 69], [70, 71], [72, 76], [76, 77], [77, 81], [82, 88], [89, 91], [92, 95], [96, 103], [104, 112], [113, 123], [124, 126], [127, 135], [136, 142], [143, 149], [149, 150], [151, 163], [164, 166], [167, 170], [171, 179], [180, 189], [190, 192], [193, 199], [199, 200], [201, 206], [206, 207], [208, 213], [214, 217], [218, 226], [226, 227]]}
{"doc_key": "ai-dev-305", "ner": [[0, 1, "algorithm"], [7, 9, "task"], [19, 21, "task"], [23, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 9, 0, 1, "usage", "", true, false], [19, 21, 7, 9, "named", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "autoencoder", "has", "been", "successfully", "applied", "to", "machine", "translation", "of", "human", "languages", ",", "which", "is", "commonly", "referred", "to", "as", "neural", "machine", "translation", "(", "NMT", ")", "."], "sentence-detokenized": "The autoencoder has been successfully applied to machine translation of human languages, which is commonly referred to as neural machine translation (NMT).", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 24], [25, 37], [38, 45], [46, 48], [49, 56], [57, 68], [69, 71], [72, 77], [78, 87], [87, 88], [89, 94], [95, 97], [98, 106], [107, 115], [116, 118], [119, 121], [122, 128], [129, 136], [137, 148], [149, 150], [150, 153], [153, 154], [154, 155]]}
{"doc_key": "ai-dev-306", "ner": [[9, 11, "metrics"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "examples", "of", "probability", "-", "based", "fitness", "functions", "include", "maximum", "likelihood", "estimation", "and", "hinge", "loss", "."], "sentence-detokenized": "Popular examples of probability-based fitness functions include maximum likelihood estimation and hinge loss.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 31], [31, 32], [32, 37], [38, 45], [46, 55], [56, 63], [64, 71], [72, 82], [83, 93], [94, 97], [98, 103], [104, 108], [108, 109]]}
{"doc_key": "ai-dev-307", "ner": [[0, 1, "field"], [11, 13, "task"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 13, 0, 1, "part-of", "", false, false], [15, 16, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "mining", "is", "a", "related", "area", "of", "research", "that", "focuses", "on", "exploratory", "data", "analysis", "through", "unsupervised", "learning", "."], "sentence-detokenized": "Data mining is a related area of research that focuses on exploratory data analysis through unsupervised learning.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 16], [17, 24], [25, 29], [30, 32], [33, 41], [42, 46], [47, 54], [55, 57], [58, 69], [70, 74], [75, 83], [84, 91], [92, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-dev-308", "ner": [[0, 1, "algorithm"], [13, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 15, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "encompasses", "techniques", "for", "comparing", "people", "with", "similar", "interests", "and", "creating", "a", "recommender", "system", "on", "that", "basis", "."], "sentence-detokenized": "Collaborative filtering encompasses techniques for comparing people with similar interests and creating a recommender system on that basis.", "token2charspan": [[0, 13], [14, 23], [24, 35], [36, 46], [47, 50], [51, 60], [61, 67], [68, 72], [73, 80], [81, 90], [91, 94], [95, 103], [104, 105], [106, 117], [118, 124], [125, 127], [128, 132], [133, 138], [138, 139]]}
{"doc_key": "ai-dev-309", "ner": [[3, 8, "algorithm"], [14, 14, "programlang"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 19, 3, 8, "type-of", "", false, false], [17, 19, 14, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "number", "of", "WordNet", "-", "based", "word", "similarity", "algorithms", "have", "been", "implemented", "in", "a", "Perl", "package", "called", "WordNet", "::", "Similarity", "."], "sentence-detokenized": "A number of WordNet-based word similarity algorithms have been implemented in a Perl package called WordNet::Similarity.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 19], [19, 20], [20, 25], [26, 30], [31, 41], [42, 52], [53, 57], [58, 62], [63, 74], [75, 77], [78, 79], [80, 84], [85, 92], [93, 99], [100, 107], [107, 109], [109, 119], [119, 120]]}
{"doc_key": "ai-dev-310", "ner": [[4, 4, "conference"], [6, 6, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 4, 4, "named", "", false, false], [10, 11, 4, 4, "temporal", "", false, false], [13, 14, 4, 4, "temporal", "", false, false], [16, 20, 4, 4, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Another", "paper", "presented", "at", "CVPR", "(", "CVPR", ")", "2000", "by", "Eric", "Miller", ",", "Nicholas", "Mazzakis", "and", "Paul", "Viola", "will", "be", "discussed", "."], "sentence-detokenized": "Another paper presented at CVPR (CVPR) 2000 by Eric Miller, Nicholas Mazzakis and Paul Viola will be discussed.", "token2charspan": [[0, 7], [8, 13], [14, 23], [24, 26], [27, 31], [32, 33], [33, 37], [37, 38], [39, 43], [44, 46], [47, 51], [52, 58], [58, 59], [60, 68], [69, 77], [78, 81], [82, 86], [87, 92], [93, 97], [98, 100], [101, 110], [110, 111]]}
{"doc_key": "ai-dev-311", "ner": [[0, 0, "algorithm"], [14, 15, "misc"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 20, 21, "compare", "", false, false], [20, 21, 14, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["QC", "has", "not", "been", "evaluated", "against", "traditional", "state", "-", "of", "-", "the", "-", "art", "clustering", "algorithms", ",", "apart", "from", "the", "Jaccard", "index", "."], "sentence-detokenized": "QC has not been evaluated against traditional state-of-the-art clustering algorithms, apart from the Jaccard index.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 15], [16, 25], [26, 33], [34, 45], [46, 51], [51, 52], [52, 54], [54, 55], [55, 58], [58, 59], [59, 62], [63, 73], [74, 84], [84, 85], [86, 91], [92, 96], [97, 100], [101, 108], [109, 114], [114, 115]]}
{"doc_key": "ai-dev-312", "ner": [[17, 21, "misc"], [12, 14, "misc"], [22, 23, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 14, 17, 21, "physical", "", false, false], [12, 14, 22, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hundreds", "of", "students", "from", "more", "than", "30", "countries", "take", "part", "in", "the", "Parade", "of", "Nations", "during", "the", "VEX", "Robotics", "World", "Championship", "at", "Freedom", "Hall", "."], "sentence-detokenized": "Hundreds of students from more than 30 countries take part in the Parade of Nations during the VEX Robotics World Championship at Freedom Hall.", "token2charspan": [[0, 8], [9, 11], [12, 20], [21, 25], [26, 30], [31, 35], [36, 38], [39, 48], [49, 53], [54, 58], [59, 61], [62, 65], [66, 72], [73, 75], [76, 83], [84, 90], [91, 94], [95, 98], [99, 107], [108, 113], [114, 126], [127, 129], [130, 137], [138, 142], [142, 143]]}
{"doc_key": "ai-dev-313", "ner": [[4, 7, "metrics"], [9, 9, "metrics"], [12, 14, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 4, 7, "named", "", false, false], [16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Other", "accuracy", "metrics", "include", "single", "word", "error", "rate", "(", "SWER", ")", "and", "command", "success", "rate", "(", "CSR", ")", "."], "sentence-detokenized": "Other accuracy metrics include single word error rate (SWER) and command success rate (CSR).", "token2charspan": [[0, 5], [6, 14], [15, 22], [23, 30], [31, 37], [38, 42], [43, 48], [49, 53], [54, 55], [55, 59], [59, 60], [61, 64], [65, 72], [73, 80], [81, 85], [86, 87], [87, 90], [90, 91], [91, 92]]}
{"doc_key": "ai-dev-314", "ner": [[7, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "presented", "their", "method", "and", "results", "at", "SIGGRAPH", "2000", "."], "sentence-detokenized": "They presented their method and results at SIGGRAPH 2000.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 27], [28, 31], [32, 39], [40, 42], [43, 51], [52, 56], [56, 57]]}
{"doc_key": "ai-dev-315", "ner": [[0, 2, "conference"], [7, 7, "misc"], [9, 16, "misc"], [17, 19, "conference"], [23, 26, "researcher"], [35, 36, "researcher"], [40, 42, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 7, 7, "origin", "", false, false], [7, 7, 17, 19, "physical", "", false, false], [7, 7, 17, 19, "temporal", "", false, false], [7, 7, 23, 26, "origin", "", false, false], [7, 7, 35, 36, "origin", "", false, false], [9, 16, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "KDD", "conference", "grew", "out", "of", "the", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "workshops", "at", "AAAI", "conferences", "that", "were", "started", "by", "Gregory", "I", ".", "Piatecki-Shapiro", "in", "1989", ",", "1991", ",", "and", "1993", "and", "Usama", "Fayad", "in", "1994", ".", "Machines", "|", "ACM", "."], "sentence-detokenized": "The KDD conference grew out of the KDD (Knowledge Discovery and Data Mining) workshops at AAAI conferences that were started by Gregory I. Piatecki-Shapiro in 1989, 1991, and 1993 and Usama Fayad in 1994. Machines | ACM.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 23], [24, 27], [28, 30], [31, 34], [35, 38], [39, 40], [40, 49], [50, 59], [60, 63], [64, 68], [69, 75], [75, 76], [77, 86], [87, 89], [90, 94], [95, 106], [107, 111], [112, 116], [117, 124], [125, 127], [128, 135], [136, 137], [137, 138], [139, 155], [156, 158], [159, 163], [163, 164], [165, 169], [169, 170], [171, 174], [175, 179], [180, 183], [184, 189], [190, 195], [196, 198], [199, 203], [203, 204], [205, 213], [214, 215], [216, 219], [219, 220]]}
{"doc_key": "ai-dev-316", "ner": [[7, 10, "conference"], [12, 12, "conference"], [16, 21, "organisation"], [23, 23, "organisation"], [27, 31, "conference"], [33, 33, "conference"], [37, 43, "conference"], [45, 45, "conference"], [49, 55, "conference"], [57, 57, "conference"], [62, 67, "conference"], [69, 69, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[12, 12, 7, 10, "named", "", false, false], [23, 23, 16, 21, "named", "", false, false], [33, 33, 27, 31, "named", "", false, false], [45, 45, 37, 43, "named", "", false, false], [57, 57, 49, 55, "named", "", false, false], [69, 69, 62, 67, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "is", "an", "elected", "member", "of", "the", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "(", "AAAS", ")", ",", "and", "the", "Society", "for", "Optics", "and", "Photonics", "Engineering", "(", "SPIE", ")", "."], "sentence-detokenized": "He is an elected member of the Association for Computing Machinery (ACM), the Institute of Electrical and Electronics Engineers (IEEE), the International Association for Pattern Recognition (IAPR), the Association for the Advancement of Artificial Intelligence (AAAI), the American Association for the Advancement of Science (AAAS), and the Society for Optics and Photonics Engineering (SPIE).", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 16], [17, 23], [24, 26], [27, 30], [31, 42], [43, 46], [47, 56], [57, 66], [67, 68], [68, 71], [71, 72], [72, 73], [74, 77], [78, 87], [88, 90], [91, 101], [102, 105], [106, 117], [118, 127], [128, 129], [129, 133], [133, 134], [134, 135], [136, 139], [140, 153], [154, 165], [166, 169], [170, 177], [178, 189], [190, 191], [191, 195], [195, 196], [196, 197], [198, 201], [202, 213], [214, 217], [218, 221], [222, 233], [234, 236], [237, 247], [248, 260], [261, 262], [262, 266], [266, 267], [267, 268], [269, 272], [273, 281], [282, 293], [294, 297], [298, 301], [302, 313], [314, 316], [317, 324], [325, 326], [326, 330], [330, 331], [331, 332], [333, 336], [337, 340], [341, 348], [349, 352], [353, 359], [360, 363], [364, 373], [374, 385], [386, 387], [387, 391], [391, 392], [392, 393]]}
{"doc_key": "ai-dev-317", "ner": [[0, 1, "field"], [3, 4, "field"], [16, 17, "field"], [31, 32, "field"], [51, 54, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 17, "named", "", false, false], [3, 4, 31, 32, "named", "", false, false], [31, 32, 51, 54, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "and", "data", "mining", "often", "use", "the", "same", "methods", "and", "overlap", "considerably", ",", "but", "while", "machine", "learning", "focuses", "on", "prediction", "based", "on", "known", "properties", "extracted", "from", "the", "training", "data", ",", "data", "mining", "focuses", "on", "discovering", "(", "previously", ")", "unknown", "properties", "in", "the", "data", "(", "this", "is", "the", "analysis", "stage", "of", "knowledge", "discovery", "in", "databases", ")", "."], "sentence-detokenized": "Machine learning and data mining often use the same methods and overlap considerably, but while machine learning focuses on prediction based on known properties extracted from the training data, data mining focuses on discovering (previously) unknown properties in the data (this is the analysis stage of knowledge discovery in databases).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 59], [60, 63], [64, 71], [72, 84], [84, 85], [86, 89], [90, 95], [96, 103], [104, 112], [113, 120], [121, 123], [124, 134], [135, 140], [141, 143], [144, 149], [150, 160], [161, 170], [171, 175], [176, 179], [180, 188], [189, 193], [193, 194], [195, 199], [200, 206], [207, 214], [215, 217], [218, 229], [230, 231], [231, 241], [241, 242], [243, 250], [251, 261], [262, 264], [265, 268], [269, 273], [274, 275], [275, 279], [280, 282], [283, 286], [287, 295], [296, 301], [302, 304], [305, 314], [315, 324], [325, 327], [328, 337], [337, 338], [338, 339]]}
{"doc_key": "ai-dev-318", "ner": [[0, 0, "product"], [4, 4, "programlang"], [11, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "general-affiliation", "", false, false], [0, 0, 4, 4, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "is", "written", "in", "Java", "and", "therefore", "runs", "on", "most", "modern", "operating", "systems", "."], "sentence-detokenized": "Indy is written in Java and therefore runs on most modern operating systems.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 23], [24, 27], [28, 37], [38, 42], [43, 45], [46, 50], [51, 57], [58, 67], [68, 75], [75, 76]]}
{"doc_key": "ai-dev-319", "ner": [[0, 0, "algorithm"], [5, 7, "algorithm"], [9, 9, "algorithm"], [15, 17, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 7, "type-of", "", true, false], [9, 9, 5, 7, "named", "", false, false], [15, 17, 5, 7, "type-of", "", true, false], [19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["NMF", "is", "an", "example", "of", "nonnegative", "quadratic", "programming", "(", "NQP", ")", ",", "just", "like", "the", "support", "vector", "machine", "(", "SVM", ")", "."], "sentence-detokenized": "NMF is an example of nonnegative quadratic programming (NQP), just like the support vector machine (SVM).", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 17], [18, 20], [21, 32], [33, 42], [43, 54], [55, 56], [56, 59], [59, 60], [60, 61], [62, 66], [67, 71], [72, 75], [76, 83], [84, 90], [91, 98], [99, 100], [100, 103], [103, 104], [104, 105]]}
{"doc_key": "ai-dev-320", "ner": [[8, 9, "misc"], [12, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 12, 17, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "method", "is", "based", "on", "the", "estimation", "of", "conditional", "probabilities", "by", "the", "nonparametric", "maximum", "likelihood", "method", ",", "which", "leads", "to"], "sentence-detokenized": "The method is based on the estimation of conditional probabilities by the nonparametric maximum likelihood method, which leads to", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 26], [27, 37], [38, 40], [41, 52], [53, 66], [67, 69], [70, 73], [74, 87], [88, 95], [96, 106], [107, 113], [113, 114], [115, 120], [121, 126], [127, 129]]}
{"doc_key": "ai-dev-321", "ner": [[7, 7, "algorithm"], [9, 11, "algorithm"], [13, 15, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Basic", "concepts", "related", "to", "spectral", "estimation", "include", "autocorrelation", ",", "multidimensional", "Fourier", "transform", ",", "mean", "squared", "error", ",", "and", "entropy", "."], "sentence-detokenized": "Basic concepts related to spectral estimation include autocorrelation, multidimensional Fourier transform, mean squared error, and entropy.", "token2charspan": [[0, 5], [6, 14], [15, 22], [23, 25], [26, 34], [35, 45], [46, 53], [54, 69], [69, 70], [71, 87], [88, 95], [96, 105], [105, 106], [107, 111], [112, 119], [120, 125], [125, 126], [127, 130], [131, 138], [138, 139]]}
{"doc_key": "ai-dev-322", "ner": [[4, 5, "algorithm"], [10, 10, "field"], [12, 12, "algorithm"], [14, 16, "algorithm"], [18, 19, "task"], [21, 21, "field"], [23, 23, "field"], [25, 26, "task"], [28, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[4, 5, 10, 10, "part-of", "", false, false], [4, 5, 12, 12, "part-of", "", false, false], [4, 5, 14, 16, "part-of", "", false, false], [4, 5, 18, 19, "part-of", "", false, false], [4, 5, 21, 21, "part-of", "", false, false], [4, 5, 23, 23, "part-of", "", false, false], [4, 5, 25, 26, "part-of", "", false, false], [4, 5, 28, 30, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "application", "areas", "of", "kernel", "methods", "are", "diverse", "and", "include", "geostatistics", ",", "kriging", ",", "inverse", "distance", "weighting", ",", "3D", "reconstruction", ",", "bioinformatics", ",", "chemoinformatics", ",", "information", "extraction", "and", "handwritten", "text", "recognition", "."], "sentence-detokenized": "The application areas of kernel methods are diverse and include geostatistics, kriging, inverse distance weighting, 3D reconstruction, bioinformatics, chemoinformatics, information extraction and handwritten text recognition.", "token2charspan": [[0, 3], [4, 15], [16, 21], [22, 24], [25, 31], [32, 39], [40, 43], [44, 51], [52, 55], [56, 63], [64, 77], [77, 78], [79, 86], [86, 87], [88, 95], [96, 104], [105, 114], [114, 115], [116, 118], [119, 133], [133, 134], [135, 149], [149, 150], [151, 167], [167, 168], [169, 180], [181, 191], [192, 195], [196, 207], [208, 212], [213, 224], [224, 225]]}
{"doc_key": "ai-dev-323", "ner": [[13, 23, "organisation"], [17, 21, "product"], [15, 15, "product"], [29, 32, "product"], [26, 26, "product"], [35, 36, "product"], [38, 39, "product"], [42, 43, "product"], [45, 47, "product"], [51, 52, "product"], [54, 54, "product"], [58, 63, "product"], [67, 68, "product"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[17, 21, 13, 23, "artifact", "", false, false], [17, 21, 35, 36, "compare", "", false, false], [17, 21, 38, 39, "compare", "", false, false], [17, 21, 42, 43, "compare", "", false, false], [17, 21, 45, 47, "compare", "", false, false], [17, 21, 51, 52, "compare", "", false, false], [17, 21, 54, 54, "compare", "", false, false], [17, 21, 58, 63, "compare", "", false, false], [17, 21, 67, 68, "compare", "", false, false], [15, 15, 17, 21, "named", "", false, false], [29, 32, 35, 36, "compare", "", false, false], [29, 32, 38, 39, "compare", "", false, false], [29, 32, 42, 43, "compare", "", false, false], [29, 32, 45, 47, "compare", "", false, false], [29, 32, 51, 52, "compare", "", false, false], [29, 32, 54, 54, "compare", "", false, false], [29, 32, 58, 63, "compare", "", false, false], [29, 32, 67, 68, "compare", "", false, false], [26, 26, 29, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Robots", "can", "be", "autonomous", "or", "semi-autonomous", ",", "and", "range", "from", "humanoids", "such", "as", "Honda", "'s", "ASIMO", "(", "Advanced", "Step", "in", "Innovative", "Mobility", ")", "and", "TOSY", "'s", "TOPIO", "(", "TOSY", "Ping", "Pong", "Playing", "Robot", ")", "to", "industrial", "robots", ",", "medical", "robots", ",", "patient", "assistance", "robots", ",", "therapy", "dog", "robots", ",", "collectively", "programmed", "robotic", "swarms", ",", "drones", "such", "as", "the", "General", "Atomics", "MQ", "-", "1", "Predator", ",", "and", "even", "microscopic", "nanorobots", "."], "sentence-detokenized": "Robots can be autonomous or semi-autonomous, and range from humanoids such as Honda's ASIMO (Advanced Step in Innovative Mobility) and TOSY's TOPIO (TOSY Ping Pong Playing Robot) to industrial robots, medical robots, patient assistance robots, therapy dog robots, collectively programmed robotic swarms, drones such as the General Atomics MQ-1 Predator, and even microscopic nanorobots.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 24], [25, 27], [28, 43], [43, 44], [45, 48], [49, 54], [55, 59], [60, 69], [70, 74], [75, 77], [78, 83], [83, 85], [86, 91], [92, 93], [93, 101], [102, 106], [107, 109], [110, 120], [121, 129], [129, 130], [131, 134], [135, 139], [139, 141], [142, 147], [148, 149], [149, 153], [154, 158], [159, 163], [164, 171], [172, 177], [177, 178], [179, 181], [182, 192], [193, 199], [199, 200], [201, 208], [209, 215], [215, 216], [217, 224], [225, 235], [236, 242], [242, 243], [244, 251], [252, 255], [256, 262], [262, 263], [264, 276], [277, 287], [288, 295], [296, 302], [302, 303], [304, 310], [311, 315], [316, 318], [319, 322], [323, 330], [331, 338], [339, 341], [341, 342], [342, 343], [344, 352], [352, 353], [354, 357], [358, 362], [363, 374], [375, 385], [385, 386]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 3, "product"], [9, 16, "university"], [18, 19, "researcher"], [21, 22, "researcher"], [24, 25, "researcher"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 18, 19, "artifact", "", false, false], [0, 0, 21, 22, "artifact", "", false, false], [0, 0, 24, 25, "artifact", "", false, false], [0, 0, 27, 28, "artifact", "", false, false], [2, 3, 18, 19, "artifact", "", false, false], [2, 3, 21, 22, "artifact", "", false, false], [2, 3, 24, 25, "artifact", "", false, false], [2, 3, 27, 28, "artifact", "", false, false], [18, 19, 9, 16, "physical", "", false, false], [21, 22, 9, 16, "physical", "", false, false], [24, 25, 9, 16, "physical", "", false, false], [27, 28, 9, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddie", "and", "Freddie", "II", "are", "robots", "created", "in", "the", "School", "of", "Informatics", "at", "the", "University", "of", "Edinburgh", "by", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "and", "Donald", "Michie", ",", "and", "are", "capable", "of", "assembling", "wooden", "blocks", "in", "a", "matter", "of", "hours", "."], "sentence-detokenized": "Freddie and Freddie II are robots created in the School of Informatics at the University of Edinburgh by Pat Ambler, Robin Popplestone, Austin Tate and Donald Michie, and are capable of assembling wooden blocks in a matter of hours.", "token2charspan": [[0, 7], [8, 11], [12, 19], [20, 22], [23, 26], [27, 33], [34, 41], [42, 44], [45, 48], [49, 55], [56, 58], [59, 70], [71, 73], [74, 77], [78, 88], [89, 91], [92, 101], [102, 104], [105, 108], [109, 115], [115, 116], [117, 122], [123, 134], [134, 135], [136, 142], [143, 147], [148, 151], [152, 158], [159, 165], [165, 166], [167, 170], [171, 174], [175, 182], [183, 185], [186, 196], [197, 203], [204, 210], [211, 213], [214, 215], [216, 222], [223, 225], [226, 231], [231, 232]]}
{"doc_key": "ai-dev-325", "ner": [[6, 6, "location"], [8, 10, "country"], [15, 17, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 8, 10, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["His", "childhood", "years", "were", "spent", "in", "Paris", ",", "France", ",", "where", "his", "parents", "emigrated", "from", "Lithuania", "in", "the", "early", "1920s", "."], "sentence-detokenized": "His childhood years were spent in Paris, France, where his parents emigrated from Lithuania in the early 1920s.", "token2charspan": [[0, 3], [4, 13], [14, 19], [20, 24], [25, 30], [31, 33], [34, 39], [39, 40], [41, 47], [47, 48], [49, 54], [55, 58], [59, 66], [67, 76], [77, 81], [82, 91], [92, 94], [95, 98], [99, 104], [105, 110], [110, 111]]}
{"doc_key": "ai-dev-326", "ner": [[0, 3, "researcher"], [6, 8, "misc"], [13, 16, "organisation"], [9, 11, "university"], [26, 32, "university"], [36, 37, "university"], [40, 42, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 6, 8, "role", "", false, false], [0, 3, 9, 11, "physical", "", false, false], [0, 3, 26, 32, "role", "", false, false], [0, 3, 36, 37, "role", "", false, false], [0, 3, 40, 42, "role", "", false, false], [6, 8, 13, 16, "part-of", "", false, false], [13, 16, 9, 11, "part-of", "", false, false], [36, 37, 26, 32, "part-of", "", false, false], [40, 42, 26, 32, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Previously", ",", "Dr.", "Paulos", "was", "an", "associate", "professor", "at", "Carnegie", "Mellon", "University", "'s", "School", "of", "Computer", "Science", ",", "where", "he", "was", "a", "faculty", "member", "at", "the", "Human", "-", "Computer", "Interaction", "Institute", ",", "as", "well", "as", "the", "Robotics", "Institute", "and", "the", "Entertainment", "Technology", "Center", "."], "sentence-detokenized": "Previously, Dr. Paulos was an associate professor at Carnegie Mellon University's School of Computer Science, where he was a faculty member at the Human-Computer Interaction Institute, as well as the Robotics Institute and the Entertainment Technology Center.", "token2charspan": [[0, 10], [10, 11], [12, 15], [16, 22], [23, 26], [27, 29], [30, 39], [40, 49], [50, 52], [53, 61], [62, 68], [69, 79], [79, 81], [82, 88], [89, 91], [92, 100], [101, 108], [108, 109], [110, 115], [116, 118], [119, 122], [123, 124], [125, 132], [133, 139], [140, 142], [143, 146], [147, 152], [152, 153], [153, 161], [162, 173], [174, 183], [183, 184], [185, 187], [188, 192], [193, 195], [196, 199], [200, 208], [209, 218], [219, 222], [223, 226], [227, 240], [241, 251], [252, 258], [258, 259]]}
{"doc_key": "ai-dev-327", "ner": [[3, 4, "researcher"], [6, 7, "university"], [10, 11, "product"], [18, 21, "product"], [27, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 6, 7, "physical", "", false, false], [3, 4, 6, 7, "role", "", false, false], [10, 11, 3, 4, "artifact", "", false, false], [10, 11, 18, 21, "type-of", "", false, false], [10, 11, 27, 27, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1969", ".", "Victor", "Shainman", "of", "Stanford", "University", "invented", "the", "Stanford", "Arm", ",", "an", "all", "-", "electric", ",", "6", "-", "axis", "robot", "designed", "to", "enable", "a", "handheld", "solution", "."], "sentence-detokenized": "In 1969. Victor Shainman of Stanford University invented the Stanford Arm, an all-electric, 6-axis robot designed to enable a handheld solution.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 24], [25, 27], [28, 36], [37, 47], [48, 56], [57, 60], [61, 69], [70, 73], [73, 74], [75, 77], [78, 81], [81, 82], [82, 90], [90, 91], [92, 93], [93, 94], [94, 98], [99, 104], [105, 113], [114, 116], [117, 123], [124, 125], [126, 134], [135, 143], [143, 144]]}
{"doc_key": "ai-dev-328", "ner": [[5, 5, "product"], [15, 16, "field"], [18, 22, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 15, 16, "related-to", "", false, false], [5, 5, 18, 22, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "creation", "and", "deployment", "of", "chatbots", "is", "still", "an", "evolving", "field", ",", "strongly", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ",", "so", "the", "solutions", "provided", ",", "while", "having", "obvious", "advantages", ",", "have", "some", "important", "limitations", "in", "terms", "of", "functionalities", "and", "use", "cases", "."], "sentence-detokenized": "The creation and deployment of chatbots is still an evolving field, strongly related to artificial intelligence and machine learning, so the solutions provided, while having obvious advantages, have some important limitations in terms of functionalities and use cases.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 27], [28, 30], [31, 39], [40, 42], [43, 48], [49, 51], [52, 60], [61, 66], [66, 67], [68, 76], [77, 84], [85, 87], [88, 98], [99, 111], [112, 115], [116, 123], [124, 132], [132, 133], [134, 136], [137, 140], [141, 150], [151, 159], [159, 160], [161, 166], [167, 173], [174, 181], [182, 192], [192, 193], [194, 198], [199, 203], [204, 213], [214, 225], [226, 228], [229, 234], [235, 237], [238, 253], [254, 257], [258, 261], [262, 267], [267, 268]]}
{"doc_key": "ai-dev-329", "ner": [[7, 10, "university"], [11, 12, "product"], [22, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 7, 10, "part-of", "", true, false], [22, 23, 11, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "terms", "of", "freely", "available", "resources", ",", "Carnegie", "Mellon", "University", "'s", "Sphinx", "toolkit", "is", "one", "place", "to", "start", "to", "learn", "more", "about", "speech", "recognition", "and", "start", "experimenting", "."], "sentence-detokenized": "In terms of freely available resources, Carnegie Mellon University's Sphinx toolkit is one place to start to learn more about speech recognition and start experimenting.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 18], [19, 28], [29, 38], [38, 39], [40, 48], [49, 55], [56, 66], [66, 68], [69, 75], [76, 83], [84, 86], [87, 90], [91, 96], [97, 99], [100, 105], [106, 108], [109, 114], [115, 119], [120, 125], [126, 132], [133, 144], [145, 148], [149, 154], [155, 168], [168, 169]]}
{"doc_key": "ai-dev-330", "ner": [[2, 4, "misc"], [13, 22, "misc"], [18, 18, "misc"], [24, 24, "university"], [26, 26, "location"], [28, 28, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 4, 13, 22, "temporal", "", false, false], [18, 18, 13, 22, "named", "", false, false], [18, 18, 26, 26, "physical", "", false, false], [24, 24, 18, 18, "role", "", false, false], [26, 26, 28, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "official", "RoboCup", "competition", "was", "preceded", "by", "the", "(", "often", "unrecognized", ")", "first", "International", "Microrobot", "World", "Cup", "(", "MIROSOT", ")", "soccer", "tournament", "held", "by", "KAIST", "in", "Daejeon", ",", "Korea", ",", "in", "November", "1996", "."], "sentence-detokenized": "The official RoboCup competition was preceded by the (often unrecognized) first International Microrobot World Cup (MIROSOT) soccer tournament held by KAIST in Daejeon, Korea, in November 1996.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 32], [33, 36], [37, 45], [46, 48], [49, 52], [53, 54], [54, 59], [60, 72], [72, 73], [74, 79], [80, 93], [94, 104], [105, 110], [111, 114], [115, 116], [116, 123], [123, 124], [125, 131], [132, 142], [143, 147], [148, 150], [151, 156], [157, 159], [160, 167], [167, 168], [169, 174], [174, 175], [176, 178], [179, 187], [188, 192], [192, 193]]}
{"doc_key": "ai-dev-331", "ner": [[5, 6, "metrics"], [23, 25, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "standard", "hinge", "loss", "math", "(", "1-", "yf", "(", "x", ")", ")", "_", "+", "/", "for", "marked", "data", ",", "the", "loss", "function", "math", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "math", "is", "introduced", "for", "unmarked", "data", "by", "allowing", "mathy", "=\\", "operatorname", "{", "sign", "}", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "In addition to the standard hinge loss math (1-yf (x)) _ + / for marked data, the loss function math (-1 | f (x) |) _ + / math is introduced for unmarked data by allowing mathy =\\ operatorname {sign} {f (x)} / math.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 27], [28, 33], [34, 38], [39, 43], [44, 45], [45, 47], [47, 49], [50, 51], [51, 52], [52, 53], [53, 54], [55, 56], [57, 58], [59, 60], [61, 64], [65, 71], [72, 76], [76, 77], [78, 81], [82, 86], [87, 95], [96, 100], [101, 102], [102, 103], [103, 104], [105, 106], [107, 108], [109, 110], [110, 111], [111, 112], [113, 114], [114, 115], [116, 117], [118, 119], [120, 121], [122, 126], [127, 129], [130, 140], [141, 144], [145, 153], [154, 158], [159, 161], [162, 170], [171, 176], [177, 179], [180, 192], [193, 194], [194, 198], [198, 199], [200, 201], [201, 202], [203, 204], [204, 205], [205, 206], [206, 207], [208, 209], [210, 214], [214, 215]]}
{"doc_key": "ai-dev-332", "ner": [[4, 4, "misc"], [10, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 10, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "particular", ",", "the", "RLS", "is", "designed", "to", "minimize", "the", "mean", "squared", "error", "between", "the", "predicted", "values", "and", "the", "true", "labels", ",", "subject", "to", "regularization", "."], "sentence-detokenized": "In particular, the RLS is designed to minimize the mean squared error between the predicted values and the true labels, subject to regularization.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 22], [23, 25], [26, 34], [35, 37], [38, 46], [47, 50], [51, 55], [56, 63], [64, 69], [70, 77], [78, 81], [82, 91], [92, 98], [99, 102], [103, 106], [107, 111], [112, 118], [118, 119], [120, 127], [128, 130], [131, 145], [145, 146]]}
{"doc_key": "ai-dev-333", "ner": [[7, 9, "algorithm"], [12, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 12, 15, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Essentially", ",", "this", "is", "a", "combination", "of", "maximum", "likelihood", "estimation", "with", "a", "regularisation", "procedure", "that", "favours", "simpler", "models", "over", "more", "complex", "ones", "."], "sentence-detokenized": "Essentially, this is a combination of maximum likelihood estimation with a regularisation procedure that favours simpler models over more complex ones.", "token2charspan": [[0, 11], [11, 12], [13, 17], [18, 20], [21, 22], [23, 34], [35, 37], [38, 45], [46, 56], [57, 67], [68, 72], [73, 74], [75, 89], [90, 99], [100, 104], [105, 112], [113, 120], [121, 127], [128, 132], [133, 137], [138, 145], [146, 150], [150, 151]]}
{"doc_key": "ai-dev-334", "ner": [[0, 4, "metrics"], [10, 10, "metrics"], [12, 12, "metrics"], [15, 17, "misc"], [22, 23, "misc"], [36, 41, "algorithm"], [37, 44, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 10, 0, 4, "named", "", false, false], [12, 12, 0, 4, "named", "", false, false], [15, 17, 22, 23, "related-to", "", false, false], [15, 17, 36, 41, "related-to", "ratio", false, false], [36, 41, 37, 44, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "frequency", "of", "true", "positives", "is", "also", "known", "as", "the", "sensitivity", ",", "recall", ",", "or", "detection", "probability", "of", "the", "mat.", "to", "the", "discrimination", "threshold", ")", "of", "the", "detection", "probability", "along", "the", "y", "-axis", "relative", "to", "the", "cumulative", "probability", "distribution", "function", "of", "the", "false", "alarm", "probability", "along", "the", "x-", "axis", "."], "sentence-detokenized": "The frequency of true positives is also known as the sensitivity, recall, or detection probability of the mat. to the discrimination threshold) of the detection probability along the y-axis relative to the cumulative probability distribution function of the false alarm probability along the x-axis.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 21], [22, 31], [32, 34], [35, 39], [40, 45], [46, 48], [49, 52], [53, 64], [64, 65], [66, 72], [72, 73], [74, 76], [77, 86], [87, 98], [99, 101], [102, 105], [106, 110], [111, 113], [114, 117], [118, 132], [133, 142], [142, 143], [144, 146], [147, 150], [151, 160], [161, 172], [173, 178], [179, 182], [183, 184], [184, 189], [190, 198], [199, 201], [202, 205], [206, 216], [217, 228], [229, 241], [242, 250], [251, 253], [254, 257], [258, 263], [264, 269], [270, 281], [282, 287], [288, 291], [292, 294], [294, 298], [298, 299]]}
{"doc_key": "ai-dev-335", "ner": [[2, 2, "misc"], [5, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 2, 2, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "the", "English", "language", ",", "Word", "Net", "is", "an", "example", "of", "a", "semantic", "network", "."], "sentence-detokenized": "In the English language, WordNet is an example of a semantic network.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 23], [23, 24], [25, 29], [29, 32], [33, 35], [36, 38], [39, 46], [47, 49], [50, 51], [52, 60], [61, 68], [68, 69]]}
{"doc_key": "ai-dev-336", "ner": [[5, 9, "product"], [11, 12, "product"], [25, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[25, 28, 5, 9, "usage", "", false, false], [25, 28, 11, 12, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "-", "term", "use", "of", "speech", "recognition", "software", "in", "combination", "with", "word", "processors", "has", "shown", "benefits", "for", "strengthening", "short", "-", "term", "memory", "in", "patients", "with", "cerebral", "AVMs", "who", "have", "been", "treated", "with", "resection", "."], "sentence-detokenized": "Long-term use of speech recognition software in combination with word processors has shown benefits for strengthening short-term memory in patients with cerebral AVMs who have been treated with resection.", "token2charspan": [[0, 4], [4, 5], [5, 9], [10, 13], [14, 16], [17, 23], [24, 35], [36, 44], [45, 47], [48, 59], [60, 64], [65, 69], [70, 80], [81, 84], [85, 90], [91, 99], [100, 103], [104, 117], [118, 123], [123, 124], [124, 128], [129, 135], [136, 138], [139, 147], [148, 152], [153, 161], [162, 166], [167, 170], [171, 175], [176, 180], [181, 188], [189, 193], [194, 203], [203, 204]]}
{"doc_key": "ai-dev-337", "ner": [[7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Its", "editors", "-", "in", "-", "chief", "are", "Ron", "Sun", ",", "Vasant", "Honavar", "and", "Greg", "Oden", "(", "from", "1999", "to", "2014", ")", "."], "sentence-detokenized": "Its editors-in-chief are Ron Sun, Vasant Honavar and Greg Oden (from 1999 to 2014).", "token2charspan": [[0, 3], [4, 11], [11, 12], [12, 14], [14, 15], [15, 20], [21, 24], [25, 28], [29, 32], [32, 33], [34, 40], [41, 48], [49, 52], [53, 57], [58, 62], [63, 64], [64, 68], [69, 73], [74, 76], [77, 81], [81, 82], [82, 83]]}
{"doc_key": "ai-dev-338", "ner": [[6, 8, "product"], [10, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 10, 12, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Their", "\"", "parallel", "\"", "distinction", "from", "serial", "manipulators", "is", "that", "the", "final", "performer", "(", "or", "\"", "arm", "\"", ")", "of", "that", "link", "(", "or", "\"", "hand", "\"", ")", "is", "directly", "connected", "to", "it", "s", "base", "by", "several", "(", "usually", "three", "or", "six", ")", "separate", "and", "independent", "links", "operating", "simultaneously", "."], "sentence-detokenized": "Their \"parallel\" distinction from serial manipulators is that the final performer (or \"arm\") of that link (or \"hand\") is directly connected to its base by several (usually three or six) separate and independent links operating simultaneously.", "token2charspan": [[0, 5], [6, 7], [7, 15], [15, 16], [17, 28], [29, 33], [34, 40], [41, 53], [54, 56], [57, 61], [62, 65], [66, 71], [72, 81], [82, 83], [83, 85], [86, 87], [87, 90], [90, 91], [91, 92], [93, 95], [96, 100], [101, 105], [106, 107], [107, 109], [110, 111], [111, 115], [115, 116], [116, 117], [118, 120], [121, 129], [130, 139], [140, 142], [143, 145], [145, 146], [147, 151], [152, 154], [155, 162], [163, 164], [164, 171], [172, 177], [178, 180], [181, 184], [184, 185], [186, 194], [195, 198], [199, 210], [211, 216], [217, 226], [227, 241], [241, 242]]}
{"doc_key": "ai-dev-339", "ner": [[5, 8, "researcher"], [17, 18, "researcher"], [19, 20, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"], [28, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "thesis", "advisor", "was", "Professor", "Cordell", "Green", ",", "and", "his", "thesis", "/", "oral", "competition", "committee", "included", "Professors", "Edward", "Feigenbaum", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Alan", "Newell", ",", "Herbert", "Simon", ",", "."], "sentence-detokenized": "His thesis advisor was Professor Cordell Green, and his thesis/oral competition committee included Professors Edward Feigenbaum Joshua Lederberg, Paul Cohen, Alan Newell, Herbert Simon,.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 22], [23, 32], [33, 40], [41, 46], [46, 47], [48, 51], [52, 55], [56, 62], [62, 63], [63, 67], [68, 79], [80, 89], [90, 98], [99, 109], [110, 116], [117, 127], [128, 134], [135, 144], [144, 145], [146, 150], [151, 156], [156, 157], [158, 162], [163, 169], [169, 170], [171, 178], [179, 184], [184, 185], [185, 186]]}
{"doc_key": "ai-dev-340", "ner": [[3, 5, "metrics"], [7, 10, "metrics"], [12, 14, "metrics"], [16, 18, "metrics"], [20, 23, "metrics"], [25, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "functions", "include", "mean", "squared", "error", ",", "root", "mean", "squared", "error", ",", "mean", "absolute", "error", ",", "relative", "squared", "error", ",", "root", "relative", "squared", "error", ",", "relative", "absolute", "error", ",", "and", "others", "."], "sentence-detokenized": "Such functions include mean squared error, root mean squared error, mean absolute error, relative squared error, root relative squared error, relative absolute error, and others.", "token2charspan": [[0, 4], [5, 14], [15, 22], [23, 27], [28, 35], [36, 41], [41, 42], [43, 47], [48, 52], [53, 60], [61, 66], [66, 67], [68, 72], [73, 81], [82, 87], [87, 88], [89, 97], [98, 105], [106, 111], [111, 112], [113, 117], [118, 126], [127, 134], [135, 140], [140, 141], [142, 150], [151, 159], [160, 165], [165, 166], [167, 170], [171, 177], [177, 178]]}
{"doc_key": "ai-dev-341", "ner": [[0, 0, "programlang"], [2, 2, "programlang"], [5, 7, "programlang"]], "ner_mapping_to_source": [0, 1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Python", ",", "Java", ",", "and", "MATLAB", "/", "OCTAVE", "connections", "exist", "."], "sentence-detokenized": "Python, Java, and MATLAB/OCTAVE connections exist.", "token2charspan": [[0, 6], [6, 7], [8, 12], [12, 13], [14, 17], [18, 24], [24, 25], [25, 31], [32, 43], [44, 49], [49, 50]]}
{"doc_key": "ai-dev-342", "ner": [[0, 0, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["MATLAB", "implementation", "can", "be", "found", "at", "."], "sentence-detokenized": "MATLAB implementation can be found at.", "token2charspan": [[0, 6], [7, 21], [22, 25], [26, 28], [29, 34], [35, 37], [37, 38]]}
{"doc_key": "ai-dev-343", "ner": [[0, 1, "researcher"], [8, 9, "field"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 1, "origin", "", false, false], [8, 9, 13, 14, "origin", "", false, false], [8, 9, 16, 17, "origin", "", false, false], [8, 9, 19, 20, "origin", "", false, false], [8, 9, 22, 25, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "is", "one", "of", "the", "founders", "of", "artificial", "intelligence", ",", "along", "with", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Alan", "Newell", "and", "Herbert", "A", ".", "Simon", "."], "sentence-detokenized": "John McCarthy is one of the founders of artificial intelligence, along with Alan Turing, Marvin Minsky, Alan Newell and Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 36], [37, 39], [40, 50], [51, 63], [63, 64], [65, 70], [71, 75], [76, 80], [81, 87], [87, 88], [89, 95], [96, 102], [102, 103], [104, 108], [109, 115], [116, 119], [120, 127], [128, 129], [129, 130], [131, 136], [136, 137]]}
{"doc_key": "ai-dev-344", "ner": [[10, 12, "product"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "parallel", "manipulator", "is", "a", "mechanical", "system", "that", "uses", "multiple", "serial", "manipulators", "to", "support", "a", "single", "platform", "or", "end", "performer", "."], "sentence-detokenized": "A parallel manipulator is a mechanical system that uses multiple serial manipulators to support a single platform or end performer.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 27], [28, 38], [39, 45], [46, 50], [51, 55], [56, 64], [65, 71], [72, 84], [85, 87], [88, 95], [96, 97], [98, 104], [105, 113], [114, 116], [117, 120], [121, 130], [130, 131]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [4, 4, "task"], [7, 7, "product"], [9, 18, "product"], [26, 26, "misc"], [29, 29, "misc"], [32, 33, "misc"], [36, 41, "task"], [44, 46, "product"], [50, 51, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 7, 0, 0, "part-of", "", false, false], [7, 7, 4, 4, "type-of", "", false, false], [9, 18, 7, 7, "named", "", false, false], [26, 26, 7, 7, "part-of", "", false, false], [29, 29, 7, 7, "part-of", "", false, false], [32, 33, 7, 7, "part-of", "", false, false], [36, 41, 7, 7, "part-of", "", false, false], [44, 46, 7, 7, "part-of", "", false, false], [50, 51, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "incorporates", "an", "information", "extraction", "system", "called", "ANNIE", "(", "A", "Nearly", "-", "New", "Information", "Extraction", "System", ")", ",", "which", "is", "a", "set", "of", "modules", "including", "a", "tokenizer", ",", "a", "gazetteer", ",", "a", "sentence", "separator", ",", "a", "part", "-", "of", "-", "speech", "tagger", ",", "a", "named", "entity", "recognizer", ",", "and", "a", "coreference", "tagger", "."], "sentence-detokenized": "GATE incorporates an information extraction system called ANNIE (A Nearly-New Information Extraction System), which is a set of modules including a tokenizer, a gazetteer, a sentence separator, a part-of-speech tagger, a named entity recognizer, and a coreference tagger.", "token2charspan": [[0, 4], [5, 17], [18, 20], [21, 32], [33, 43], [44, 50], [51, 57], [58, 63], [64, 65], [65, 66], [67, 73], [73, 74], [74, 77], [78, 89], [90, 100], [101, 107], [107, 108], [108, 109], [110, 115], [116, 118], [119, 120], [121, 124], [125, 127], [128, 135], [136, 145], [146, 147], [148, 157], [157, 158], [159, 160], [161, 170], [170, 171], [172, 173], [174, 182], [183, 192], [192, 193], [194, 195], [196, 200], [200, 201], [201, 203], [203, 204], [204, 210], [211, 217], [217, 218], [219, 220], [221, 226], [227, 233], [234, 244], [244, 245], [246, 249], [250, 251], [252, 263], [264, 270], [270, 271]]}
{"doc_key": "ai-dev-346", "ner": [[3, 5, "university"], [13, 14, "country"], [21, 24, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "graduated", "from", "Moscow", "State", "University", "and", "in", "November", "1978", "went", "to", "the", "United", "States", "thanks", "to", "the", "personal", "intervention", "of", "Senator", "Edward", "M.", "Kennedy", "."], "sentence-detokenized": "He graduated from Moscow State University and in November 1978 went to the United States thanks to the personal intervention of Senator Edward M. Kennedy.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 24], [25, 30], [31, 41], [42, 45], [46, 48], [49, 57], [58, 62], [63, 67], [68, 70], [71, 74], [75, 81], [82, 88], [89, 95], [96, 98], [99, 102], [103, 111], [112, 124], [125, 127], [128, 135], [136, 142], [143, 145], [146, 153], [153, 154]]}
{"doc_key": "ai-dev-347", "ner": [[3, 6, "organisation"], [9, 15, "misc"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 6, 9, 15, "win-defeat", "", false, false], [9, 15, 22, 23, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "the", "DeepMind", "AlphaGo", "team", "received", "the", "IJCAI", "'s", "first", "Marvin", "Minsky", "Medal", "for", "outstanding", "achievement", "in", "the", "field", "of", "artificial", "intelligence", "."], "sentence-detokenized": "In 2017, the DeepMind AlphaGo team received the IJCAI's first Marvin Minsky Medal for outstanding achievement in the field of artificial intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 21], [22, 29], [30, 34], [35, 43], [44, 47], [48, 53], [53, 55], [56, 61], [62, 68], [69, 75], [76, 81], [82, 85], [86, 97], [98, 109], [110, 112], [113, 116], [117, 122], [123, 125], [126, 136], [137, 149], [149, 150]]}
{"doc_key": "ai-dev-348", "ner": [[4, 5, "misc"], [9, 9, "misc"], [14, 14, "misc"], [23, 24, "misc"], [29, 29, "misc"], [35, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 9, 9, "related-to", "is_recorded_by", false, false], [9, 9, 14, 14, "cause-effect", "", false, false], [9, 9, 14, 14, "physical", "", false, false], [9, 9, 23, 24, "physical", "", false, false], [9, 9, 35, 35, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "ways", "in", "which", "anomalous", "propagation", "is", "recorded", "are", "troposcatters", "causing", "irregularities", "in", "the", "troposphere", ",", "scattering", "due", "to", "meteors", ",", "refraction", "in", "ionized", "regions", "and", "layers", "of", "the", "ionosphere", ",", "and", "reflection", "from", "the", "ionosphere", "."], "sentence-detokenized": "Other ways in which anomalous propagation is recorded are troposcatters causing irregularities in the troposphere, scattering due to meteors, refraction in ionized regions and layers of the ionosphere, and reflection from the ionosphere.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 19], [20, 29], [30, 41], [42, 44], [45, 53], [54, 57], [58, 71], [72, 79], [80, 94], [95, 97], [98, 101], [102, 113], [113, 114], [115, 125], [126, 129], [130, 132], [133, 140], [140, 141], [142, 152], [153, 155], [156, 163], [164, 171], [172, 175], [176, 182], [183, 185], [186, 189], [190, 200], [200, 201], [202, 205], [206, 216], [217, 221], [222, 225], [226, 236], [236, 237]]}
{"doc_key": "ai-dev-349", "ner": [[0, 2, "field"], [4, 4, "field"], [10, 10, "field"], [12, 13, "field"], [15, 16, "field"], [19, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 10, 10, "part-of", "", false, false], [0, 2, 12, 13, "part-of", "", false, false], [0, 2, 15, 16, "part-of", "", false, false], [0, 2, 19, 23, "part-of", "", false, false], [4, 4, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Natural", "language", "processing", "(", "NLP", ")", "is", "a", "subfield", "of", "linguistics", ",", "computer", "science", ",", "information", "engineering", ",", "and", "artificial", "intelligence", "that", "deals", "with", "the", "interaction", "between", "computers", "and", "human", "(", "natural", ")", "languages", ",", "specifically", "how", "to", "program", "computers", "to", "process", "and", "analyze", "large", "amounts", "of", "natural", "language", "data", "."], "sentence-detokenized": "Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence that deals with the interaction between computers and human (natural) languages, specifically how to program computers to process and analyze large amounts of natural language data.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [29, 32], [32, 33], [34, 36], [37, 38], [39, 47], [48, 50], [51, 62], [62, 63], [64, 72], [73, 80], [80, 81], [82, 93], [94, 105], [105, 106], [107, 110], [111, 121], [122, 134], [135, 139], [140, 145], [146, 150], [151, 154], [155, 166], [167, 174], [175, 184], [185, 188], [189, 194], [195, 196], [196, 203], [203, 204], [205, 214], [214, 215], [216, 228], [229, 232], [233, 235], [236, 243], [244, 253], [254, 256], [257, 264], [265, 268], [269, 276], [277, 282], [283, 290], [291, 293], [294, 301], [302, 310], [311, 315], [315, 316]]}
{"doc_key": "ai-dev-350", "ner": [[8, 9, "organisation"], [11, 12, "organisation"], [14, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "active", "youth", "groups", "fighting", "climate", "change", "include", "Extinction", "Rebellion", ",", "Sunrise", "Movement", ",", "SustainUS", "and", "others", "working", "both", "transnationally", "and", "locally", "."], "sentence-detokenized": "Other active youth groups fighting climate change include Extinction Rebellion, Sunrise Movement, SustainUS and others working both transnationally and locally.", "token2charspan": [[0, 5], [6, 12], [13, 18], [19, 25], [26, 34], [35, 42], [43, 49], [50, 57], [58, 68], [69, 78], [78, 79], [80, 87], [88, 96], [96, 97], [98, 107], [108, 111], [112, 118], [119, 126], [127, 131], [132, 147], [148, 151], [152, 159], [159, 160]]}
