{"doc_key": "ai-test-1", "ner": [[6, 8, "algorithm"], [10, 11, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "methods", "for", "generative", "models", "are", "naive", "Bayesian", "classifiers", ",", "Gaussian", "mixture", "models", ",", "variational", "autoencoders", "and", "others", "."], "sentence-detokenized": "Typical methods for generative models are naive Bayesian classifiers, Gaussian mixture models, variational autoencoders and others.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 30], [31, 37], [38, 41], [42, 47], [48, 56], [57, 68], [68, 69], [70, 78], [79, 86], [87, 93], [93, 94], [95, 106], [107, 119], [120, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-2", "ner": [[6, 6, "organisation"], [12, 12, "conference"], [15, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 12, 12, "role", "", false, false], [15, 21, 12, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Finally", ",", "every", "other", "year", ",", "ELRA", "organises", "a", "major", "conference", ",", "LREC", "-", "the", "International", "Conference", "on", "Language", "Resources", "and", "Evaluation", "."], "sentence-detokenized": "Finally, every other year, ELRA organises a major conference, LREC - the International Conference on Language Resources and Evaluation.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 20], [21, 25], [25, 26], [27, 31], [32, 41], [42, 43], [44, 49], [50, 60], [60, 61], [62, 66], [67, 68], [69, 72], [73, 86], [87, 97], [98, 100], [101, 109], [110, 119], [120, 123], [124, 134], [134, 135]]}
{"doc_key": "ai-test-3", "ner": [[7, 11, "algorithm"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "task", "is", "usually", "to", "obtain", "the", "maximum", "likely", "estimate", "of", "the", "HMM", "parameters", "given", "the", "output", "sequences", "."], "sentence-detokenized": "The task is usually to obtain the maximum likely estimate of the HMM parameters given the output sequences.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 22], [23, 29], [30, 33], [34, 41], [42, 48], [49, 57], [58, 60], [61, 64], [65, 68], [69, 79], [80, 85], [86, 89], [90, 96], [97, 106], [106, 107]]}
{"doc_key": "ai-test-4", "ner": [[1, 1, "algorithm"], [4, 6, "algorithm"], [8, 9, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 8, 9, "compare", "", false, false], [4, 6, 8, 9, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Unlike", "neural", "networks", "and", "support", "vector", "machines", ",", "AdaBoost", "'s", "training", "process", "selects", "only", "those", "features", "known", "to", "improve", "the", "predictive", "power", "of", "the", "model", ",", "which", "reduces", "the", "number", "of", "dimensions", "and", "can", "shorten", "the", "runtime", "by", "eliminating", "the", "need", "to", "count", "irrelevant", "features", "."], "sentence-detokenized": "Unlike neural networks and support vector machines, AdaBoost's training process selects only those features known to improve the predictive power of the model, which reduces the number of dimensions and can shorten the runtime by eliminating the need to count irrelevant features.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 26], [27, 34], [35, 41], [42, 50], [50, 51], [52, 60], [60, 62], [63, 71], [72, 79], [80, 87], [88, 92], [93, 98], [99, 107], [108, 113], [114, 116], [117, 124], [125, 128], [129, 139], [140, 145], [146, 148], [149, 152], [153, 158], [158, 159], [160, 165], [166, 173], [174, 177], [178, 184], [185, 187], [188, 198], [199, 202], [203, 206], [207, 214], [215, 218], [219, 226], [227, 229], [230, 241], [242, 245], [246, 250], [251, 253], [254, 259], [260, 270], [271, 279], [279, 280]]}
{"doc_key": "ai-test-5", "ner": [[0, 0, "misc"], [9, 13, "misc"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 9, 13, "part-of", "", false, false], [9, 13, 14, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponymy", "is", "one", "of", "the", "possible", "verb", "relationships", "in", "the", "semantic", "network", "of", "the", "Word", "Net", "database", "."], "sentence-detokenized": "Troponymy is one of the possible verb relationships in the semantic network of the WordNet database.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 19], [20, 23], [24, 32], [33, 37], [38, 51], [52, 54], [55, 58], [59, 67], [68, 75], [76, 78], [79, 82], [83, 87], [87, 90], [91, 99], [99, 100]]}
{"doc_key": "ai-test-6", "ner": [[7, 9, "task"], [10, 11, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Frame", "language", "is", "a", "technology", "used", "to", "represent", "knowledge", "in", "artificial", "intelligence", "."], "sentence-detokenized": "Frame language is a technology used to represent knowledge in artificial intelligence.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 19], [20, 30], [31, 35], [36, 38], [39, 48], [49, 58], [59, 61], [62, 72], [73, 85], [85, 86]]}
{"doc_key": "ai-test-7", "ner": [[3, 3, "metrics"], [7, 9, "metrics"], [12, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 7, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "addition", ",", "NIST", "differs", "from", "the", "bilingual", "assessment", "by", "calculating", "a", "penalty", "for", "brevity", ",", "as", "small", "differences", "in", "the", "length", "of", "a", "translation", "do", "not", "have", "such", "a", "large", "impact", "on", "the", "overall", "score", "."], "sentence-detokenized": "In addition, NIST differs from the bilingual assessment by calculating a penalty for brevity, as small differences in the length of a translation do not have such a large impact on the overall score.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 17], [18, 25], [26, 30], [31, 34], [35, 44], [45, 55], [56, 58], [59, 70], [71, 72], [73, 80], [81, 84], [85, 92], [92, 93], [94, 96], [97, 102], [103, 114], [115, 117], [118, 121], [122, 128], [129, 131], [132, 133], [134, 145], [146, 148], [149, 152], [153, 157], [158, 162], [163, 164], [165, 170], [171, 177], [178, 180], [181, 184], [185, 192], [193, 198], [198, 199]]}
{"doc_key": "ai-test-8", "ner": [[15, 16, "algorithm"], [19, 21, "algorithm"], [31, 32, "field"], [42, 43, "algorithm"], [45, 47, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 16, 31, 32, "usage", "", false, false], [19, 21, 31, 32, "usage", "", false, false], [42, 43, 31, 32, "type-of", "", false, false], [45, 47, 31, 32, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "model", "is", "initially", "applied", "to", "the", "training", "dataset", ",", "The", "model", "(", "e.g.", "a", "neural", "network", "or", "a", "naive", "Bayesian", "classifier", ")", "is", "trained", "on", "the", "training", "dataset", "using", "a", "supervised", "learning", "approach", ",", "e.g.", "by", "applying", "optimisation", "techniques", "such", "as", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The model is initially applied to the training dataset, The model (e.g. a neural network or a naive Bayesian classifier) is trained on the training dataset using a supervised learning approach, e.g. by applying optimisation techniques such as gradient descent or stochastic gradient descent.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 22], [23, 30], [31, 33], [34, 37], [38, 46], [47, 54], [54, 55], [56, 59], [60, 65], [66, 67], [67, 71], [72, 73], [74, 80], [81, 88], [89, 91], [92, 93], [94, 99], [100, 108], [109, 119], [119, 120], [121, 123], [124, 131], [132, 134], [135, 138], [139, 147], [148, 155], [156, 161], [162, 163], [164, 174], [175, 183], [184, 192], [192, 193], [194, 198], [199, 201], [202, 210], [211, 223], [224, 234], [235, 239], [240, 242], [243, 251], [252, 259], [260, 262], [263, 273], [274, 282], [283, 290], [290, 291]]}
{"doc_key": "ai-test-9", "ner": [[0, 4, "product"], [9, 9, "task"], [11, 11, "task"], [13, 14, "task"], [16, 17, "task"], [23, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 9, 0, 4, "usage", "", true, false], [11, 11, 0, 4, "usage", "", true, false], [13, 14, 0, 4, "usage", "", true, false], [16, 17, 0, 4, "usage", "", true, false], [23, 25, 0, 4, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "has", "been", "used", "in", "areas", "such", "as", "question", "answering", ",", "paraphrasing", ",", "text", "matching", "and", "information", "extraction", ",", "either", "directly", "or", "using", "semantic", "role", "labeling", "tools", "."], "sentence-detokenized": "FrameNet has been used in areas such as question answering, paraphrasing, text matching and information extraction, either directly or using semantic role labeling tools.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 25], [26, 31], [32, 36], [37, 39], [40, 48], [49, 58], [58, 59], [60, 72], [72, 73], [74, 78], [79, 87], [88, 91], [92, 103], [104, 114], [114, 115], [116, 122], [123, 131], [132, 134], [135, 140], [141, 149], [150, 154], [155, 163], [164, 169], [169, 170]]}
{"doc_key": "ai-test-10", "ner": [[6, 7, "field"], [12, 12, "misc"], [15, 15, "product"], [18, 18, "misc"], [21, 21, "product"], [24, 25, "field"], [28, 28, "product"], [31, 33, "misc"], [36, 36, "product"], [38, 38, "product"], [40, 40, "product"], [43, 44, "misc"], [48, 49, "product"], [51, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[15, 15, 12, 12, "general-affiliation", "", false, false], [21, 21, 18, 18, "general-affiliation", "", false, false], [28, 28, 24, 25, "general-affiliation", "", false, false], [36, 36, 31, 33, "type-of", "", false, false], [38, 38, 31, 33, "type-of", "", false, false], [40, 40, 31, 33, "type-of", "", false, false], [48, 49, 43, 44, "general-affiliation", "", false, false], [51, 52, 43, 44, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["This", "would", "include", "applications", "such", "as", "data", "analysis", "and", "extraction", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "generalised", "audit", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "analysis", "software", "(", "e.g.", "Crystal", "Reports", "and", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "This would include applications such as data analysis and extraction tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), generalised audit software (e.g. ACL, Arbutus, EAS), business analysis software (e.g. Crystal Reports and Business Objects), etc.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 31], [32, 36], [37, 39], [40, 44], [45, 53], [54, 57], [58, 68], [69, 74], [74, 75], [76, 88], [89, 90], [90, 94], [95, 100], [100, 101], [101, 102], [103, 112], [113, 114], [114, 118], [119, 125], [125, 126], [126, 127], [128, 139], [140, 148], [149, 150], [150, 154], [155, 158], [158, 159], [159, 160], [161, 172], [173, 178], [179, 187], [188, 189], [189, 193], [194, 197], [197, 198], [199, 206], [206, 207], [208, 211], [211, 212], [212, 213], [214, 222], [223, 231], [232, 240], [241, 242], [242, 246], [247, 254], [255, 262], [263, 266], [267, 275], [276, 283], [283, 284], [284, 285], [286, 289], [289, 290]]}
{"doc_key": "ai-test-11", "ner": [[4, 5, "organisation"], [9, 12, "researcher"], [16, 16, "organisation"], [19, 19, "product"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 9, 12, "origin", "", false, false], [9, 12, 16, 16, "role", "", false, false], [19, 19, 22, 23, "type-of", "", false, false], [22, 23, 9, 12, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "September", "2012", ",", "Rethink", "Robotics", ",", "founded", "by", "Rodney", "Brooks", ",", "who", "previously", "worked", "with", "iRobot", ",", "launched", "Baxter", "as", "an", "industrial", "robot", "designed", "to", "interact", "safely", "with", "people", "working", "nearby", "and", "programmed", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "In September 2012, Rethink Robotics, founded by Rodney Brooks, who previously worked with iRobot, launched Baxter as an industrial robot designed to interact safely with people working nearby and programmed to perform simple tasks.", "token2charspan": [[0, 2], [3, 12], [13, 17], [17, 18], [19, 26], [27, 35], [35, 36], [37, 44], [45, 47], [48, 54], [55, 61], [61, 62], [63, 66], [67, 77], [78, 84], [85, 89], [90, 96], [96, 97], [98, 106], [107, 113], [114, 116], [117, 119], [120, 130], [131, 136], [137, 145], [146, 148], [149, 157], [158, 164], [165, 169], [170, 176], [177, 184], [185, 191], [192, 195], [196, 206], [207, 209], [210, 217], [218, 224], [225, 230], [230, 231]]}
{"doc_key": "ai-test-12", "ner": [[1, 2, "field"], [5, 6, "task"], [8, 9, "task"], [11, 14, "task"], [16, 18, "task"], [20, 21, "task"], [23, 24, "task"], [27, 29, "task"], [32, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 6, 1, 2, "part-of", "task_part_of_field", false, false], [8, 9, 1, 2, "part-of", "task_part_of_field", false, false], [11, 14, 1, 2, "part-of", "task_part_of_field", false, false], [16, 18, 1, 2, "part-of", "task_part_of_field", false, false], [20, 21, 1, 2, "part-of", "task_part_of_field", false, false], [23, 24, 1, 2, "part-of", "task_part_of_field", false, false], [27, 29, 1, 2, "part-of", "task_part_of_field", false, false], [32, 36, 1, 2, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Typical", "text", "mining", "tasks", "include", "text", "categorisation", ",", "text", "clustering", ",", "concept", "/", "entity", "extraction", ",", "building", "detailed", "taxonomies", ",", "sentiment", "analysis", ",", "document", "summarisation", ",", "and", "entity", "relationship", "modelling", "(", "i.e.", "recognising", "relationships", "between", "named", "entities", ")", "."], "sentence-detokenized": "Typical text mining tasks include text categorisation, text clustering, concept/entity extraction, building detailed taxonomies, sentiment analysis, document summarisation, and entity relationship modelling (i.e. recognising relationships between named entities).", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 25], [26, 33], [34, 38], [39, 53], [53, 54], [55, 59], [60, 70], [70, 71], [72, 79], [79, 80], [80, 86], [87, 97], [97, 98], [99, 107], [108, 116], [117, 127], [127, 128], [129, 138], [139, 147], [147, 148], [149, 157], [158, 171], [171, 172], [173, 176], [177, 183], [184, 196], [197, 206], [207, 208], [208, 212], [213, 224], [225, 238], [239, 246], [247, 252], [253, 261], [261, 262], [262, 263]]}
{"doc_key": "ai-test-13", "ner": [[8, 8, "metrics"], [11, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "in", "such", "systems", ",", "derivatives", "reduce", "accuracy", "or", "the", "frequency", "of", "TRUE", "negative", "results", "."], "sentence-detokenized": "However, in such systems, derivatives reduce accuracy or the frequency of TRUE negative results.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 16], [17, 24], [24, 25], [26, 37], [38, 44], [45, 53], [54, 56], [57, 60], [61, 70], [71, 73], [74, 78], [79, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-14", "ner": [[4, 5, "task"], [11, 12, "misc"], [17, 19, "misc"], [31, 31, "product"], [33, 34, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 12, 4, 5, "temporal", "", false, false], [17, 19, 11, 12, "named", "", false, false], [31, 31, 11, 12, "usage", "", false, false], [33, 34, 11, 12, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "special", "case", "of", "keyword", "detection", "is", "the", "detection", "of", "a", "wake", "word", "(", "also", "known", "as", "a", "hot", "word", ")", ",", "which", "is", "used", "by", "personal", "digital", "assistants", "such", "as", "Alexa", "or", "Siri", "to", "wake", "up", "when", "their", "name", "is", "spoken", "."], "sentence-detokenized": "A special case of keyword detection is the detection of a wake word (also known as a hot word), which is used by personal digital assistants such as Alexa or Siri to wake up when their name is spoken.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 17], [18, 25], [26, 35], [36, 38], [39, 42], [43, 52], [53, 55], [56, 57], [58, 62], [63, 67], [68, 69], [69, 73], [74, 79], [80, 82], [83, 84], [85, 88], [89, 93], [93, 94], [94, 95], [96, 101], [102, 104], [105, 109], [110, 112], [113, 121], [122, 129], [130, 140], [141, 145], [146, 148], [149, 154], [155, 157], [158, 162], [163, 165], [166, 170], [171, 173], [174, 178], [179, 184], [185, 189], [190, 192], [193, 199], [199, 200]]}
{"doc_key": "ai-test-15", "ner": [[0, 1, "programlang"], [10, 10, "programlang"], [12, 12, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 0, 1, "part-of", "", false, false], [12, 12, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["\"", "Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "with", "Java", "."], "sentence-detokenized": "\"Prova is an open source programming language that combines Prolog with Java.", "token2charspan": [[0, 1], [1, 6], [7, 9], [10, 12], [13, 17], [18, 24], [25, 36], [37, 45], [46, 50], [51, 59], [60, 66], [67, 71], [72, 76], [76, 77]]}
{"doc_key": "ai-test-16", "ner": [[6, 7, "organisation"], [3, 4, "organisation"], [17, 19, "product"], [14, 16, "country"], [32, 32, "organisation"], [42, 42, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 3, 4, "part-of", "", false, false], [6, 7, 3, 4, "role", "sells", false, false], [6, 7, 14, 16, "role", "sells_to", false, false], [32, 32, 42, 42, "opposite", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "1987", ",", "Toshiba", "'s", "subsidiary", "Tocibai", "Machine", "was", "accused", "of", "illegally", "selling", "to", "the", "Soviet", "Union", "CNC", "milling", "cutters", "used", "to", "produce", "very", "quiet", "submarine", "propellers", ",", "in", "violation", "of", "the", "CoCom", "Agreement", ",", "an", "international", "embargo", "on", "certain", "countries", "within", "COMECON", "."], "sentence-detokenized": "In 1987, Toshiba's subsidiary Tocibai Machine was accused of illegally selling to the Soviet Union CNC milling cutters used to produce very quiet submarine propellers, in violation of the CoCom Agreement, an international embargo on certain countries within COMECON.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [16, 18], [19, 29], [30, 37], [38, 45], [46, 49], [50, 57], [58, 60], [61, 70], [71, 78], [79, 81], [82, 85], [86, 92], [93, 98], [99, 102], [103, 110], [111, 118], [119, 123], [124, 126], [127, 134], [135, 139], [140, 145], [146, 155], [156, 166], [166, 167], [168, 170], [171, 180], [181, 183], [184, 187], [188, 193], [194, 203], [203, 204], [205, 207], [208, 221], [222, 229], [230, 232], [233, 240], [241, 250], [251, 257], [258, 265], [265, 266]]}
{"doc_key": "ai-test-17", "ner": [[0, 1, "researcher"], [7, 10, "product"], [20, 25, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 0, 1, "artifact", "", false, false], [7, 10, 20, 25, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Engelberger", "'s", "most", "famous", "invention", ",", "the", "industrial", "robotic", "arm", "Unimate", ",", "was", "one", "of", "the", "first", "inductees", "into", "the", "Robotics", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberger's most famous invention, the industrial robotic arm Unimate, was one of the first inductees into the Robotics Hall of Fame in 2003.", "token2charspan": [[0, 11], [11, 13], [14, 18], [19, 25], [26, 35], [35, 36], [37, 40], [41, 51], [52, 59], [60, 63], [64, 71], [71, 72], [73, 76], [77, 80], [81, 83], [84, 87], [88, 93], [94, 103], [104, 108], [109, 112], [113, 121], [122, 126], [127, 129], [130, 134], [135, 137], [138, 142], [142, 143]]}
{"doc_key": "ai-test-18", "ner": [[3, 4, "misc"], [8, 8, "misc"], [10, 10, "person"], [13, 14, "field"], [15, 15, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 8, 8, "usage", "", false, false], [10, 10, 13, 14, "role", "", false, false], [13, 14, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Initially", "controlled", "through", "static", "html", "web", "pages", "using", "CGI", ",", "Dalton", "developed", "an", "augmented", "reality", "Java", "interface", "which", "was", "not", "very", "successful", "."], "sentence-detokenized": "Initially controlled through static html web pages using CGI, Dalton developed an augmented reality Java interface which was not very successful.", "token2charspan": [[0, 9], [10, 20], [21, 28], [29, 35], [36, 40], [41, 44], [45, 50], [51, 56], [57, 60], [60, 61], [62, 68], [69, 78], [79, 81], [82, 91], [92, 99], [100, 104], [105, 114], [115, 120], [121, 124], [125, 128], [129, 133], [134, 144], [144, 145]]}
{"doc_key": "ai-test-19", "ner": [[5, 8, "task"], [11, 11, "organisation"], [26, 26, "conference"], [30, 30, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 8, 11, 11, "origin", "", false, false], [26, 26, 30, 30, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "publication", "on", "the", "LMF", "specification", "to", "be", "ratified", "by", "ISO", "(", "this", "document", "became", "(", "in", "2015", ")", "the", "9th", "most", "cited", "document", "at", "LREC", "conferences", "among", "all", "LREC", "documents", ")", ":"], "sentence-detokenized": "The first publication on the LMF specification to be ratified by ISO (this document became (in 2015) the 9th most cited document at LREC conferences among all LREC documents):", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 24], [25, 28], [29, 32], [33, 46], [47, 49], [50, 52], [53, 61], [62, 64], [65, 68], [69, 70], [70, 74], [75, 83], [84, 90], [91, 92], [92, 94], [95, 99], [99, 100], [101, 104], [105, 108], [109, 113], [114, 119], [120, 128], [129, 131], [132, 136], [137, 148], [149, 154], [155, 158], [159, 163], [164, 173], [173, 174], [174, 175]]}
{"doc_key": "ai-test-20", "ner": [[0, 2, "metrics"], [15, 16, "metrics"], [17, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 0, 2, "usage", "", false, false], [15, 16, 17, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "confusion", "matrix", "or", "matching", "matrix", "is", "often", "used", "as", "a", "means", "of", "validating", "the", "accuracy", "of", "k", "-", "NN", "classification", "."], "sentence-detokenized": "The confusion matrix or matching matrix is often used as a means of validating the accuracy of k-NN classification.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 23], [24, 32], [33, 39], [40, 42], [43, 48], [49, 53], [54, 56], [57, 58], [59, 64], [65, 67], [68, 78], [79, 82], [83, 91], [92, 94], [95, 96], [96, 97], [97, 99], [100, 114], [114, 115]]}
{"doc_key": "ai-test-21", "ner": [[0, 1, "algorithm"], [12, 12, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 15, "part-of", "", false, false], [0, 1, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", "is", "one", "of", "the", "predictive", "modelling", "techniques", "used", "in", "statistics", ",", "data", "mining", "and", "machine", "learning", "."], "sentence-detokenized": "Decision tree learning is one of the predictive modelling techniques used in statistics, data mining and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 47], [48, 57], [58, 68], [69, 73], [74, 76], [77, 87], [87, 88], [89, 93], [94, 100], [101, 104], [105, 112], [113, 121], [121, 122]]}
{"doc_key": "ai-test-22", "ner": [[6, 6, "misc"], [14, 15, "field"], [19, 21, "algorithm"], [23, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 14, 15, "related-to", "", true, false], [19, 21, 14, 15, "type-of", "", false, false], [23, 23, 14, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["At", "runtime", ",", "the", "target", "sentence", "prosody", "is", "superimposed", "on", "these", "minimal", "units", "using", "signal", "processing", "techniques", "such", "as", "linear", "predictive", "coding", ",", "PSOLA"], "sentence-detokenized": "At runtime, the target sentence prosody is superimposed on these minimal units using signal processing techniques such as linear predictive coding, PSOLA", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 22], [23, 31], [32, 39], [40, 42], [43, 55], [56, 58], [59, 64], [65, 72], [73, 78], [79, 84], [85, 91], [92, 102], [103, 113], [114, 118], [119, 121], [122, 128], [129, 139], [140, 146], [146, 147], [148, 153]]}
{"doc_key": "ai-test-23", "ner": [[3, 4, "field"], [6, 8, "field"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 20, 3, 4, "usage", "", true, false], [19, 20, 6, 8, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "approach", "used", "artificial", "intelligence", "and", "machine", "learning", "to", "allow", "researchers", "to", "make", "explicit", "comparisons", "between", "normal", "and", "thermal", "facial", "images", "."], "sentence-detokenized": "The approach used artificial intelligence and machine learning to allow researchers to make explicit comparisons between normal and thermal facial images.", "token2charspan": [[0, 3], [4, 12], [13, 17], [18, 28], [29, 41], [42, 45], [46, 53], [54, 62], [63, 65], [66, 71], [72, 83], [84, 86], [87, 91], [92, 100], [101, 112], [113, 120], [121, 127], [128, 131], [132, 139], [140, 146], [147, 153], [153, 154]]}
{"doc_key": "ai-test-24", "ner": [[0, 2, "field"], [4, 5, "algorithm"], [10, 11, "task"], [14, 16, "misc"], [22, 23, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 0, 2, "part-of", "", false, false], [4, 5, 10, 11, "topic", "", false, false], [10, 11, 14, 16, "origin", "", false, false], [22, 23, 0, 2, "part-of", "", false, false], [22, 23, 4, 5, "topic", "", false, false], [25, 26, 0, 2, "part-of", "", false, false], [25, 26, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "computer", "science", ",", "evolutionary", "computation", "is", "a", "group", "of", "global", "optimisation", "algorithms", "inspired", "by", "biological", "evolution", ",", "and", "the", "branch", "of", "artificial", "intelligence", "and", "soft", "computing", "that", "studies", "these", "algorithms", "."], "sentence-detokenized": "In computer science, evolutionary computation is a group of global optimisation algorithms inspired by biological evolution, and the branch of artificial intelligence and soft computing that studies these algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 33], [34, 45], [46, 48], [49, 50], [51, 56], [57, 59], [60, 66], [67, 79], [80, 90], [91, 99], [100, 102], [103, 113], [114, 123], [123, 124], [125, 128], [129, 132], [133, 139], [140, 142], [143, 153], [154, 166], [167, 170], [171, 175], [176, 185], [186, 190], [191, 198], [199, 204], [205, 215], [215, 216]]}
{"doc_key": "ai-test-25", "ner": [[14, 15, "metrics"], [18, 21, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "it", "is", "possible", "to", "combine", "a", "given", "measure", "based", "on", "the", "confusion", "matrix", "with", "the", "root", "mean", "square", "error", "estimated", "between", "the", "raw", "model", "results", "and", "the", "actual", "values", "."], "sentence-detokenized": "For example, it is possible to combine a given measure based on the confusion matrix with the root mean square error estimated between the raw model results and the actual values.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 18], [19, 27], [28, 30], [31, 38], [39, 40], [41, 46], [47, 54], [55, 60], [61, 63], [64, 67], [68, 77], [78, 84], [85, 89], [90, 93], [94, 98], [99, 103], [104, 110], [111, 116], [117, 126], [127, 134], [135, 138], [139, 142], [143, 148], [149, 156], [157, 160], [161, 164], [165, 171], [172, 178], [178, 179]]}
{"doc_key": "ai-test-26", "ner": [[8, 10, "product"], [13, 13, "researcher"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 13, 13, "origin", "", false, false], [8, 10, 9, 9, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Most", "of", "them", "are", "results", "or", "variants", "of", "the", "word2vec", "model", "developed", "by", "Mikolov", "et", "al", "."], "sentence-detokenized": "Most of them are results or variants of the word2vec model developed by Mikolov et al.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 16], [17, 24], [25, 27], [28, 36], [37, 39], [40, 43], [44, 52], [53, 58], [59, 68], [69, 71], [72, 79], [80, 82], [83, 85], [85, 86]]}
{"doc_key": "ai-test-27", "ner": [[12, 12, "conference"], [15, 19, "conference"], [21, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 21, 15, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["During", "this", "period", ",", "a", "total", "of", "43", "publications", "were", "recognised", "by", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "During this period, a total of 43 publications were recognised by CVPR and the International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 6], [7, 11], [12, 18], [18, 19], [20, 21], [22, 27], [28, 30], [31, 33], [34, 46], [47, 51], [52, 62], [63, 65], [66, 70], [71, 74], [75, 78], [79, 92], [93, 103], [104, 106], [107, 115], [116, 122], [123, 124], [124, 128], [128, 129], [129, 130]]}
{"doc_key": "ai-test-28", "ner": [[0, 0, "product"], [12, 12, "field"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 12, "general-affiliation", "platform_for_education_about", false, false], [23, 24, 0, 0, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["AIBO", "has", "been", "widely", "used", "as", "a", "low", "-", "cost", "platform", "for", "AI", "training", "and", "research", ",", "as", "it", "integrates", "a", "computer", ",", "computer", "vision", "and", "articulators", ",", "which", "are", "significantly", "cheaper", "than", "conventional", "research", "robots", "."], "sentence-detokenized": "AIBO has been widely used as a low-cost platform for AI training and research, as it integrates a computer, computer vision and articulators, which are significantly cheaper than conventional research robots.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 20], [21, 25], [26, 28], [29, 30], [31, 34], [34, 35], [35, 39], [40, 48], [49, 52], [53, 55], [56, 64], [65, 68], [69, 77], [77, 78], [79, 81], [82, 84], [85, 95], [96, 97], [98, 106], [106, 107], [108, 116], [117, 123], [124, 127], [128, 140], [140, 141], [142, 147], [148, 151], [152, 165], [166, 173], [174, 178], [179, 191], [192, 200], [201, 207], [207, 208]]}
{"doc_key": "ai-test-29", "ner": [[6, 11, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "was", "Programme", "Chair", "of", "the", "2021", "International", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "She was Programme Chair of the 2021 International Conference on Computer Vision.", "token2charspan": [[0, 3], [4, 7], [8, 17], [18, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 72], [73, 79], [79, 80]]}
{"doc_key": "ai-test-30", "ner": [[0, 2, "researcher"], [5, 5, "organisation"], [15, 17, "organisation"], [23, 24, "organisation"], [35, 38, "product"], [40, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 5, 5, "role", "", false, false], [0, 2, 15, 17, "role", "", true, false], [15, 17, 23, 24, "role", "develops_with", false, false], [35, 38, 15, 17, "artifact", "", false, false], [40, 40, 35, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Scheinman", ",", "who", "received", "a", "Unimation", "grant", "to", "develop", "his", "projects", ",", "sold", "them", "to", "Unimation", ",", "which", ",", "with", "the", "support", "of", "General", "Motors", ",", "further", "developed", "them", "and", "later", "sold", "them", "as", "the", "Programmable", "Universal", "Assembly", "Machine", "(", "PUMA", ")", "."], "sentence-detokenized": "Scheinman, who received a Unimation grant to develop his projects, sold them to Unimation, which, with the support of General Motors, further developed them and later sold them as the Programmable Universal Assembly Machine (PUMA).", "token2charspan": [[0, 9], [9, 10], [11, 14], [15, 23], [24, 25], [26, 35], [36, 41], [42, 44], [45, 52], [53, 56], [57, 65], [65, 66], [67, 71], [72, 76], [77, 79], [80, 89], [89, 90], [91, 96], [96, 97], [98, 102], [103, 106], [107, 114], [115, 117], [118, 125], [126, 132], [132, 133], [134, 141], [142, 151], [152, 156], [157, 160], [161, 166], [167, 171], [172, 176], [177, 179], [180, 183], [184, 196], [197, 206], [207, 215], [216, 223], [224, 225], [225, 229], [229, 230], [230, 231]]}
{"doc_key": "ai-test-31", "ner": [[8, 9, "task"], [11, 13, "task"], [0, 0, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "general-affiliation", "works_with", false, false], [0, 0, 11, 13, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Gebel", "(", "2009", ")", "reviewed", "calibration", "methods", "for", "binary", "classification", "and", "multiclass", "classification", "tasks", "."], "sentence-detokenized": "Gebel (2009) reviewed calibration methods for binary classification and multiclass classification tasks.", "token2charspan": [[0, 5], [6, 7], [7, 11], [11, 12], [13, 21], [22, 33], [34, 41], [42, 45], [46, 52], [53, 67], [68, 71], [72, 82], [83, 97], [98, 103], [103, 104]]}
{"doc_key": "ai-test-32", "ner": [[4, 6, "task"], [8, 8, "task"], [11, 12, "task"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 4, 6, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["His", "research", "interests", "include", "Optical", "Character", "Recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "speech", "recognition", "technology", "and", "electronic", "keyboards", "."], "sentence-detokenized": "His research interests include Optical Character Recognition (OCR), speech synthesis, speech recognition technology and electronic keyboards.", "token2charspan": [[0, 3], [4, 12], [13, 22], [23, 30], [31, 38], [39, 48], [49, 60], [61, 62], [62, 65], [65, 66], [66, 67], [68, 74], [75, 84], [84, 85], [86, 92], [93, 104], [105, 115], [116, 119], [120, 130], [131, 140], [140, 141]]}
{"doc_key": "ai-test-33", "ner": [[8, 12, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "newer", "and", "more", "advanced", "methods", ",", "the", "Kaldi", "toolbox", "can", "be", "used", "."], "sentence-detokenized": "For newer and more advanced methods, the Kaldi toolbox can be used.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 18], [19, 27], [28, 35], [35, 36], [37, 40], [41, 46], [47, 54], [55, 58], [59, 61], [62, 66], [66, 67]]}
{"doc_key": "ai-test-34", "ner": [[0, 4, "researcher"], [8, 10, "organisation"], [15, 17, "organisation"], [22, 24, "organisation"], [30, 31, "researcher"], [32, 35, "organisation"], [40, 44, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 4, 8, 10, "role", "", false, false], [0, 4, 15, 17, "role", "", false, false], [0, 4, 22, 24, "role", "", false, false], [0, 4, 32, 35, "role", "", false, false], [0, 4, 40, 44, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson", "-", "Laird", "is", "a", "Fellow", "of", "the", "American", "Philosophical", "Society", ",", "a", "Fellow", "of", "the", "Royal", "Society", ",", "a", "Fellow", "of", "the", "British", "Academy", ",", "a", "Fellow", "of", "the", "William", "James", "Society", "for", "Psychological", "Science", "and", "a", "Fellow", "of", "the", "Society", "for", "Cognitive", "Science", "."], "sentence-detokenized": "Johnson-Laird is a Fellow of the American Philosophical Society, a Fellow of the Royal Society, a Fellow of the British Academy, a Fellow of the William James Society for Psychological Science and a Fellow of the Society for Cognitive Science.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 66], [67, 73], [74, 76], [77, 80], [81, 86], [87, 94], [94, 95], [96, 97], [98, 104], [105, 107], [108, 111], [112, 119], [120, 127], [127, 128], [129, 130], [131, 137], [138, 140], [141, 144], [145, 152], [153, 158], [159, 166], [167, 170], [171, 184], [185, 192], [193, 196], [197, 198], [199, 205], [206, 208], [209, 212], [213, 220], [221, 224], [225, 234], [235, 242], [242, 243]]}
{"doc_key": "ai-test-35", "ner": [[3, 8, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [20, 24, "algorithm"], [26, 30, "task"], [32, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 3, 8, "physical", "", false, false], [10, 11, 3, 8, "temporal", "", false, false], [13, 14, 3, 8, "physical", "", false, false], [13, 14, 3, 8, "temporal", "", false, false], [16, 17, 3, 8, "physical", "", false, false], [16, 17, 3, 8, "temporal", "", false, false], [20, 24, 16, 17, "role", "extends", false, false], [26, 30, 16, 17, "role", "extends", false, false], [32, 32, 26, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["At", "the", "2010", "IEEE", "International", "Conference", "on", "Image", "Processing", ",", "Rui", "Hu", ",", "Mark", "Banard", "and", "John", "Collomosse", "extended", "the", "HOG", "descriptor", "to", "be", "used", "in", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the 2010 IEEE International Conference on Image Processing, Rui Hu, Mark Banard and John Collomosse extended the HOG descriptor to be used in sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 30], [31, 41], [42, 44], [45, 50], [51, 61], [61, 62], [63, 66], [67, 69], [69, 70], [71, 75], [76, 82], [83, 86], [87, 91], [92, 102], [103, 111], [112, 115], [116, 119], [120, 130], [131, 133], [134, 136], [137, 141], [142, 144], [145, 151], [151, 152], [152, 157], [158, 163], [164, 173], [174, 175], [175, 179], [179, 180], [180, 181]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "uses", "a", "modified", "form", "of", "accuracy", "to", "compare", "a", "candidate", "'s", "translation", "with", "several", "reference", "translations", "."], "sentence-detokenized": "BLEU uses a modified form of accuracy to compare a candidate's translation with several reference translations.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 20], [21, 25], [26, 28], [29, 37], [38, 40], [41, 48], [49, 50], [51, 60], [60, 62], [63, 74], [75, 79], [80, 87], [88, 97], [98, 110], [110, 111]]}
{"doc_key": "ai-test-37", "ner": [[29, 30, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "case", "of", "general", "base", "space", "math", "(", "Y", ",\\", "mathcal", "{", "B", "},\\", "nu", ")", "/", "math", "(", "i.e.", "base", "space", "that", "is", "not", "countable", ")", ",", "relative", "entropy", "is", "usually", "considered", "."], "sentence-detokenized": "In the case of general base space math (Y,\\ mathcal {B},\\ nu) / math (i.e. base space that is not countable), relative entropy is usually considered.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 22], [23, 27], [28, 33], [34, 38], [39, 40], [40, 41], [41, 43], [44, 51], [52, 53], [53, 54], [54, 57], [58, 60], [60, 61], [62, 63], [64, 68], [69, 70], [70, 74], [75, 79], [80, 85], [86, 90], [91, 93], [94, 97], [98, 107], [107, 108], [108, 109], [110, 118], [119, 126], [127, 129], [130, 137], [138, 148], [148, 149]]}
{"doc_key": "ai-test-38", "ner": [[9, 10, "country"], [11, 13, "organisation"], [15, 15, "organisation"], [18, 19, "organisation"], [21, 21, "organisation"], [24, 26, "organisation"], [37, 39, "country"], [29, 34, "organisation"], [36, 36, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9], "relations": [[11, 13, 9, 10, "physical", "", false, false], [15, 15, 11, 13, "named", "", false, false], [21, 21, 18, 19, "named", "", false, false], [29, 34, 37, 39, "physical", "", false, false], [36, 36, 29, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 3, 4, 5], "sentence": ["In", "October", "2011", ",", "the", "existing", "partnership", "with", "the", "United", "States", "National", "Park", "Service", "(", "NPS", ")", ",", "Historic", "Scotland", "(", "HS", ")", ",", "World", "Monuments", "Fund", "and", "the", "National", "Institute", "of", "Anthropology", "and", "History", "(", "INAH", ")", "of", "Mexico", "was", "significantly", "expanded", "."], "sentence-detokenized": "In October 2011, the existing partnership with the United States National Park Service (NPS), Historic Scotland (HS), World Monuments Fund and the National Institute of Anthropology and History (INAH) of Mexico was significantly expanded.", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [17, 20], [21, 29], [30, 41], [42, 46], [47, 50], [51, 57], [58, 64], [65, 73], [74, 78], [79, 86], [87, 88], [88, 91], [91, 92], [92, 93], [94, 102], [103, 111], [112, 113], [113, 115], [115, 116], [116, 117], [118, 123], [124, 133], [134, 138], [139, 142], [143, 146], [147, 155], [156, 165], [166, 168], [169, 181], [182, 185], [186, 193], [194, 195], [195, 199], [199, 200], [201, 203], [204, 210], [211, 214], [215, 228], [229, 237], [237, 238]]}
{"doc_key": "ai-test-39", "ner": [[0, 2, "algorithm"], [7, 8, "field"], [12, 12, "product"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 12, 12, "part-of", "", false, false], [0, 2, 14, 14, "part-of", "", false, false], [12, 12, 7, 8, "general-affiliation", "", false, false], [14, 14, 7, 8, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Kernel", "SVM", "is", "available", "in", "many", "machine", "learning", "toolkits", ",", "including", "LIBSVM", ",", "MATLAB", "and", "others", "."], "sentence-detokenized": "The Kernel SVM is available in many machine learning toolkits, including LIBSVM, MATLAB and others.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 17], [18, 27], [28, 30], [31, 35], [36, 43], [44, 52], [53, 61], [61, 62], [63, 72], [73, 79], [79, 80], [81, 87], [88, 91], [92, 98], [98, 99]]}
{"doc_key": "ai-test-40", "ner": [[2, 6, "misc"], [18, 19, "location"], [21, 21, "location"], [23, 23, "country"], [7, 9, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 6, 18, 19, "physical", "", false, false], [2, 6, 7, 9, "temporal", "", false, false], [18, 19, 21, 21, "physical", "", false, false], [21, 21, 23, 23, "physical", "", false, false], [7, 9, 18, 19, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2009", "Loebner", "Prize", "competition", "for", "the", "Interspeech", "2009", "conference", "was", "held", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", ",", "Brighton", ",", "UK", "."], "sentence-detokenized": "The 2009 Loebner Prize competition for the Interspeech 2009 conference was held on 6 September 2009 at the Brighton Centre, Brighton, UK.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 34], [35, 38], [39, 42], [43, 54], [55, 59], [60, 70], [71, 74], [75, 79], [80, 82], [83, 84], [85, 94], [95, 99], [100, 102], [103, 106], [107, 115], [116, 122], [122, 123], [124, 132], [132, 133], [134, 136], [136, 137]]}
{"doc_key": "ai-test-41", "ner": [[0, 3, "product"], [10, 10, "product"], [17, 19, "product"], [20, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[20, 22, 0, 3, "part-of", "", false, false], [20, 22, 10, 10, "part-of", "", false, false], [20, 22, 17, 19, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "QRIO", "humanoid", "robot", "was", "developed", "as", "a", "successor", "to", "AIBO", "and", "runs", "on", "the", "same", "basic", "R", "-", "CODE", "Aperios", "operating", "system", "."], "sentence-detokenized": "The QRIO humanoid robot was developed as a successor to AIBO and runs on the same basic R-CODE Aperios operating system.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 23], [24, 27], [28, 37], [38, 40], [41, 42], [43, 52], [53, 55], [56, 60], [61, 64], [65, 69], [70, 72], [73, 76], [77, 81], [82, 87], [88, 89], [89, 90], [90, 94], [95, 102], [103, 112], [113, 119], [119, 120]]}
{"doc_key": "ai-test-42", "ner": [[0, 1, "misc"], [6, 9, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 0, 1, "cause-effect", "", true, false], [12, 13, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Speech", "waveforms", "are", "generated", "from", "the", "HMMs", "themselves", ",", "based", "on", "the", "maximum", "likelihood", "criterion", "."], "sentence-detokenized": "Speech waveforms are generated from the HMMs themselves, based on the maximum likelihood criterion.", "token2charspan": [[0, 6], [7, 16], [17, 20], [21, 30], [31, 35], [36, 39], [40, 44], [45, 55], [55, 56], [57, 62], [63, 65], [66, 69], [70, 77], [78, 88], [89, 98], [98, 99]]}
{"doc_key": "ai-test-43", "ner": [[0, 2, "product"], [6, 9, "task"], [11, 13, "task"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 6, 9, "type-of", "", false, false], [0, 2, 11, 13, "type-of", "", false, false], [0, 2, 17, 18, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["\"", "Google", "Translate", "is", "a", "free", "multilingual", "statistical", "machine", "translation", "and", "neural", "machine", "translation", "service", "developed", "by", "Google", "to", "translate", "text", "and", "websites", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "\"Google Translate is a free multilingual statistical machine translation and neural machine translation service developed by Google to translate text and websites from one language to another.", "token2charspan": [[0, 1], [1, 7], [8, 17], [18, 20], [21, 22], [23, 27], [28, 40], [41, 52], [53, 60], [61, 72], [73, 76], [77, 83], [84, 91], [92, 103], [104, 111], [112, 121], [122, 124], [125, 131], [132, 134], [135, 144], [145, 149], [150, 153], [154, 162], [163, 167], [168, 171], [172, 180], [181, 183], [184, 191], [191, 192]]}
{"doc_key": "ai-test-44", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [14, 18, "field"], [20, 22, "task"], [24, 25, "task"], [27, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[20, 22, 5, 6, "part-of", "", false, true], [20, 22, 8, 9, "part-of", "", false, true], [20, 22, 11, 12, "part-of", "", false, true], [24, 25, 5, 6, "part-of", "", false, true], [24, 25, 8, 9, "part-of", "", false, true], [24, 25, 11, 12, "part-of", "", false, true], [27, 30, 5, 6, "part-of", "", false, true], [27, 30, 8, 9, "part-of", "", false, true], [27, 30, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Skeletons", "are", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", "and", "digital", "image", "processing", ",", "such", "as", "optical", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", "or", "compression", "."], "sentence-detokenized": "Skeletons are widely used in computer vision, image analysis, pattern recognition and digital image processing, such as optical character recognition, fingerprint recognition, visual inspection or compression.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 25], [26, 28], [29, 37], [38, 44], [44, 45], [46, 51], [52, 60], [60, 61], [62, 69], [70, 81], [82, 85], [86, 93], [94, 99], [100, 110], [110, 111], [112, 116], [117, 119], [120, 127], [128, 137], [138, 149], [149, 150], [151, 162], [163, 174], [174, 175], [176, 182], [183, 193], [194, 196], [197, 208], [208, 209]]}
{"doc_key": "ai-test-45", "ner": [[0, 8, "conference"], [13, 16, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 8, 13, 16, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["\"", "ImageNet", "'s", "large", "-", "scale", "visual", "recognition", "challenge", "is", "a", "benchmark", "for", "object", "classification", "and", "detection", ",", "covering", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "\"ImageNet's large-scale visual recognition challenge is a benchmark for object classification and detection, covering millions of images and hundreds of object classes.", "token2charspan": [[0, 1], [1, 9], [9, 11], [12, 17], [17, 18], [18, 23], [24, 30], [31, 42], [43, 52], [53, 55], [56, 57], [58, 67], [68, 71], [72, 78], [79, 93], [94, 97], [98, 107], [107, 108], [109, 117], [118, 126], [127, 129], [130, 136], [137, 140], [141, 149], [150, 152], [153, 159], [160, 167], [167, 168]]}
{"doc_key": "ai-test-46", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [17, 20, "misc"], [23, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 17, 20, "part-of", "", false, false], [0, 2, 23, 26, "part-of", "", false, false], [4, 5, 17, 20, "part-of", "", false, false], [4, 5, 23, 26, "part-of", "", false, false], [7, 8, 17, 20, "part-of", "", false, false], [7, 8, 23, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "are", "considered", "by", "some", "to", "be", "the", "godfathers", "of", "artificial", "intelligence", "and", "the", "godfathers", "of", "deep", "learning", "."], "sentence-detokenized": "Bengio, along with Geoffrey Hinton and Yann LeCun, are considered by some to be the godfathers of artificial intelligence and the godfathers of deep learning.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 27], [28, 34], [35, 38], [39, 43], [44, 49], [49, 50], [51, 54], [55, 65], [66, 68], [69, 73], [74, 76], [77, 79], [80, 83], [84, 94], [95, 97], [98, 108], [109, 121], [122, 125], [126, 129], [130, 140], [141, 143], [144, 148], [149, 157], [157, 158]]}
{"doc_key": "ai-test-47", "ner": [[6, 6, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "IEEE", "Life", "Member", "."], "sentence-detokenized": "He is a member of the IEEE Life Member.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 26], [27, 31], [32, 38], [38, 39]]}
{"doc_key": "ai-test-48", "ner": [[0, 1, "organisation"], [14, 19, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 14, 19, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NSA", "Bethesda", "is", "responsible", "for", "operational", "support", "to", "the", "base", "'s", "main", "tenant", ",", "Walter", "Reed", "National", "Military", "Medical", "Centre", "."], "sentence-detokenized": "NSA Bethesda is responsible for operational support to the base's main tenant, Walter Reed National Military Medical Centre.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 31], [32, 43], [44, 51], [52, 54], [55, 58], [59, 63], [63, 65], [66, 70], [71, 77], [77, 78], [79, 85], [86, 90], [91, 99], [100, 108], [109, 116], [117, 123], [123, 124]]}
{"doc_key": "ai-test-49", "ner": [[6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "three", "main", "learning", "paradigms", "are", "supervised", "learning", ",", "unsupervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "The three main learning paradigms are supervised learning, unsupervised learning and reinforcement learning.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 23], [24, 33], [34, 37], [38, 48], [49, 57], [57, 58], [59, 71], [72, 80], [81, 84], [85, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-50", "ner": [[3, 3, "task"], [5, 9, "task"], [12, 16, "task"], [18, 19, "task"], [21, 23, "task"], [25, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "management", ",", "planning", "and", "scheduling", ",", "the", "ability", "to", "answer", "diagnostic", "and", "user", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", "and", "facial", "recognition", "."], "sentence-detokenized": "For example, management, planning and scheduling, the ability to answer diagnostic and user questions, handwriting recognition, natural language understanding, speech recognition and facial recognition.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 23], [23, 24], [25, 33], [34, 37], [38, 48], [48, 49], [50, 53], [54, 61], [62, 64], [65, 71], [72, 82], [83, 86], [87, 91], [92, 101], [101, 102], [103, 114], [115, 126], [126, 127], [128, 135], [136, 144], [145, 158], [158, 159], [160, 166], [167, 178], [179, 182], [183, 189], [190, 201], [201, 202]]}
{"doc_key": "ai-test-51", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "founding", "member", ")", "."], "sentence-detokenized": "In 1991, he was elected a Fellow of the Association for the Advancement of Artificial Intelligence (1990, founding member).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [99, 100], [100, 104], [104, 105], [106, 114], [115, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-test-52", "ner": [[11, 12, "misc"], [15, 16, "algorithm"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "by", "formulating", "the", "problem", "as", "a", "solution", "of", "a", "Toeplitz", "matrix", "and", "using", "Levinson", "recursion", ",", "we", "can", "relatively", "quickly", "estimate", "the", "filter", "with", "the", "smallest", "possible", "mean", "square", "error", "."], "sentence-detokenized": "However, by formulating the problem as a solution of a Toeplitz matrix and using Levinson recursion, we can relatively quickly estimate the filter with the smallest possible mean square error.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 23], [24, 27], [28, 35], [36, 38], [39, 40], [41, 49], [50, 52], [53, 54], [55, 63], [64, 70], [71, 74], [75, 80], [81, 89], [90, 99], [99, 100], [101, 103], [104, 107], [108, 118], [119, 126], [127, 135], [136, 139], [140, 146], [147, 151], [152, 155], [156, 164], [165, 173], [174, 178], [179, 185], [186, 191], [191, 192]]}
{"doc_key": "ai-test-53", "ner": [[0, 6, "conference"], [15, 19, "location"], [20, 21, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 15, 19, "physical", "", false, false], [15, 19, 20, 21, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "15th", "edition", "of", "Campus", "Party", "Spain", "will", "take", "place", "in", "July", "2011", "in", "the", "city", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "The 15th edition of Campus Party Spain will take place in July 2011 in the city of Arts and Sciences in Valencia.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 19], [20, 26], [27, 32], [33, 38], [39, 43], [44, 48], [49, 54], [55, 57], [58, 62], [63, 67], [68, 70], [71, 74], [75, 79], [80, 82], [83, 87], [88, 91], [92, 100], [101, 103], [104, 112], [112, 113]]}
{"doc_key": "ai-test-54", "ner": [[14, 14, "product"], [16, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Often", "this", "is", "only", "possible", "at", "the", "very", "end", "of", "complex", "games", "such", "as", "chess", "or", "go", ",", "because", "it", "is", "computationally", "impossible", "to", "look", "ahead", "to", "the", "end", "of", "the", "game", ",", "except", "at", "the", "end", "of", "the", "game", ",", "so", "positions", "are", "given", "finite", "values", "that", "measure", "the", "degree", "of", "confidence", "that", "they", "will", "lead", "to", "victory", "for", "one", "or", "other", "player", "."], "sentence-detokenized": "Often this is only possible at the very end of complex games such as chess or go, because it is computationally impossible to look ahead to the end of the game, except at the end of the game, so positions are given finite values that measure the degree of confidence that they will lead to victory for one or other player.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 18], [19, 27], [28, 30], [31, 34], [35, 39], [40, 43], [44, 46], [47, 54], [55, 60], [61, 65], [66, 68], [69, 74], [75, 77], [78, 80], [80, 81], [82, 89], [90, 92], [93, 95], [96, 111], [112, 122], [123, 125], [126, 130], [131, 136], [137, 139], [140, 143], [144, 147], [148, 150], [151, 154], [155, 159], [159, 160], [161, 167], [168, 170], [171, 174], [175, 178], [179, 181], [182, 185], [186, 190], [190, 191], [192, 194], [195, 204], [205, 208], [209, 214], [215, 221], [222, 228], [229, 233], [234, 241], [242, 245], [246, 252], [253, 255], [256, 266], [267, 271], [272, 276], [277, 281], [282, 286], [287, 289], [290, 297], [298, 301], [302, 305], [306, 308], [309, 314], [315, 321], [321, 322]]}
{"doc_key": "ai-test-55", "ner": [[4, 6, "algorithm"], [24, 25, "algorithm"], [27, 28, "algorithm"], [31, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 24, 25, "compare", "", false, false], [4, 6, 27, 28, "compare", "", false, false], [4, 6, 31, 35, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "difference", "between", "the", "multinomial", "logit", "model", "and", "many", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "that", "share", "the", "same", "basic", "configuration", "(", "perceptron", "algorithm", ",", "support", "vector", "machines", ",", "linear", "discriminant", "analysis", ",", "etc", "."], "sentence-detokenized": "The difference between the multinomial logit model and many other methods, models, algorithms, etc. that share the same basic configuration (perceptron algorithm, support vector machines, linear discriminant analysis, etc.", "token2charspan": [[0, 3], [4, 14], [15, 22], [23, 26], [27, 38], [39, 44], [45, 50], [51, 54], [55, 59], [60, 65], [66, 73], [73, 74], [75, 81], [81, 82], [83, 93], [93, 94], [95, 99], [100, 104], [105, 110], [111, 114], [115, 119], [120, 125], [126, 139], [140, 141], [141, 151], [152, 161], [161, 162], [163, 170], [171, 177], [178, 186], [186, 187], [188, 194], [195, 207], [208, 216], [216, 217], [218, 221], [221, 222]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "published", "by"], "sentence-detokenized": "Association for Computational Linguistics, published by", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 52], [53, 55]]}
{"doc_key": "ai-test-57", "ner": [[3, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "a", "computerised", "face", "recognition", "system", ",", "each", "face", "is", "represented", "by", "a", "large", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In a computerised face recognition system, each face is represented by a large number of pixel values.", "token2charspan": [[0, 2], [3, 4], [5, 17], [18, 22], [23, 34], [35, 41], [41, 42], [43, 47], [48, 52], [53, 55], [56, 67], [68, 70], [71, 72], [73, 78], [79, 85], [86, 88], [89, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-58", "ner": [[5, 8, "person"], [9, 11, "organisation"], [18, 19, "country"], [22, 22, "person"], [33, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 8, 9, 11, "role", "", false, false], [5, 8, 18, 19, "physical", "", false, false], [22, 22, 33, 35, "origin", "", false, false], [22, 22, 33, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2002", ",", "his", "son", "Daniel", "Pearl", ",", "a", "Wall", "Street", "Journal", "journalist", ",", "was", "kidnapped", "and", "murdered", "in", "Pakistan", ",", "prompting", "Judea", "and", "other", "family", "members", "and", "friends", "to", "set", "up", "the", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "In 2002, his son Daniel Pearl, a Wall Street Journal journalist, was kidnapped and murdered in Pakistan, prompting Judea and other family members and friends to set up the Daniel Pearl Foundation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 23], [24, 29], [29, 30], [31, 32], [33, 37], [38, 44], [45, 52], [53, 63], [63, 64], [65, 68], [69, 78], [79, 82], [83, 91], [92, 94], [95, 103], [103, 104], [105, 114], [115, 120], [121, 124], [125, 130], [131, 137], [138, 145], [146, 149], [150, 157], [158, 160], [161, 164], [165, 167], [168, 171], [172, 178], [179, 184], [185, 195], [195, 196]]}
{"doc_key": "ai-test-59", "ner": [[4, 6, "organisation"], [17, 18, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 17, 18, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "late", "2006", ",", "Red", "Envelope", "Entertainment", "has", "also", "started", "developing", "original", "content", "with", "filmmakers", "such", "as", "John", "Waters", "."], "sentence-detokenized": "Since late 2006, Red Envelope Entertainment has also started developing original content with filmmakers such as John Waters.", "token2charspan": [[0, 5], [6, 10], [11, 15], [15, 16], [17, 20], [21, 29], [30, 43], [44, 47], [48, 52], [53, 60], [61, 71], [72, 80], [81, 88], [89, 93], [94, 104], [105, 109], [110, 112], [113, 117], [118, 124], [124, 125]]}
{"doc_key": "ai-test-60", "ner": [[7, 11, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "building", "is", "now", "part", "of", "the", "Beth", "Israel", "Deaconess", "Medical", "Centre", "."], "sentence-detokenized": "The building is now part of the Beth Israel Deaconess Medical Centre.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 31], [32, 36], [37, 43], [44, 53], [54, 61], [62, 68], [68, 69]]}
{"doc_key": "ai-test-61", "ner": [[12, 13, "field"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "common", "theme", "of", "these", "works", "is", "the", "sign", "theory", "approach", "to", "artificial", "intelligence", "and", "knowledge", "representation", "."], "sentence-detokenized": "The common theme of these works is the sign theory approach to artificial intelligence and knowledge representation.", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 19], [20, 25], [26, 31], [32, 34], [35, 38], [39, 43], [44, 50], [51, 59], [60, 62], [63, 73], [74, 86], [87, 90], [91, 100], [101, 115], [115, 116]]}
{"doc_key": "ai-test-62", "ner": [[0, 7, "task"], [9, 9, "task"], [13, 14, "task"], [33, 34, "task"], [36, 38, "task"], [42, 44, "task"], [46, 46, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 7, 13, 14, "type-of", "", false, false], [0, 7, 42, 44, "compare", "", false, false], [0, 7, 42, 44, "opposite", "", false, false], [9, 9, 0, 7, "named", "", false, false], [33, 34, 42, 44, "part-of", "", false, false], [36, 38, 42, 44, "part-of", "", false, false], [42, 44, 13, 14, "type-of", "", false, false], [46, 46, 42, 44, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["For", "example", ",", "the", "term", "neural", "machine", "translation", "(", "NMT", ")", "emphasises", "that", "machine", "translation", "methods", "based", "on", "deep", "learning", "learn", "sequence", "transformations", "directly", ",", "eliminating", "the", "need", "for", "intermediate", "steps", "such", "as", "word", "comparison", "and", "language", "modelling", "that", "were", "used", "in", "statistical", "machine", "translation", "(", "SMT", ")", "."], "sentence-detokenized": "For example, the term neural machine translation (NMT) emphasises that machine translation methods based on deep learning learn sequence transformations directly, eliminating the need for intermediate steps such as word comparison and language modelling that were used in statistical machine translation (SMT).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 36], [37, 48], [49, 50], [50, 53], [53, 54], [55, 65], [66, 70], [71, 78], [79, 90], [91, 98], [99, 104], [105, 107], [108, 112], [113, 121], [122, 127], [128, 136], [137, 152], [153, 161], [161, 162], [163, 174], [175, 178], [179, 183], [184, 187], [188, 200], [201, 206], [207, 211], [212, 214], [215, 219], [220, 230], [231, 234], [235, 243], [244, 253], [254, 258], [259, 263], [264, 268], [269, 271], [272, 283], [284, 291], [292, 303], [304, 305], [305, 308], [308, 309], [309, 310]]}
{"doc_key": "ai-test-63", "ner": [[4, 4, "field"], [10, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 10, 11, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "research", "in", "the", "WSD", "field", "is", "carried", "out", "using", "Word", "Net", "as", "a", "reference", "value", "inventory", "."], "sentence-detokenized": "Most research in the WSD field is carried out using WordNet as a reference value inventory.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 24], [25, 30], [31, 33], [34, 41], [42, 45], [46, 51], [52, 56], [56, 59], [60, 62], [63, 64], [65, 74], [75, 80], [81, 90], [90, 91]]}
{"doc_key": "ai-test-64", "ner": [[11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Notable", "former", "PhD", "students", "and", "postdoctoral", "fellows", "in", "his", "group", "include", "Richard", "Zemel", "and", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Notable former PhD students and postdoctoral fellows in his group include Richard Zemel and Zoubin Ghahramani.", "token2charspan": [[0, 7], [8, 14], [15, 18], [19, 27], [28, 31], [32, 44], [45, 52], [53, 55], [56, 59], [60, 65], [66, 73], [74, 81], [82, 87], [88, 91], [92, 98], [99, 109], [109, 110]]}
{"doc_key": "ai-test-65", "ner": [[4, 5, "metrics"], [12, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 12, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Each", "prediction", "result", "or", "confusion", "matrix", "instance", "is", "one", "point", "in", "the", "ROC", "space", "."], "sentence-detokenized": "Each prediction result or confusion matrix instance is one point in the ROC space.", "token2charspan": [[0, 4], [5, 15], [16, 22], [23, 25], [26, 35], [36, 42], [43, 51], [52, 54], [55, 58], [59, 64], [65, 67], [68, 71], [72, 75], [76, 81], [81, 82]]}
{"doc_key": "ai-test-66", "ner": [[3, 3, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [17, 18, "product"], [19, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 19, 23, "physical", "", false, false], [7, 8, 19, 23, "physical", "", false, false], [10, 11, 19, 23, "physical", "", false, false], [17, 18, 3, 3, "artifact", "", false, false], [17, 18, 7, 8, "artifact", "", false, false], [17, 18, 10, 11, "artifact", "", false, false], [17, 18, 19, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1997", ",", "Thrun", "and", "his", "colleagues", "Wolfram", "Burgard", "and", "Dieter", "Fox", "created", "the", "world", "'s", "first", "robot", "guide", "at", "the", "Deutsches", "Museum", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "In 1997, Thrun and his colleagues Wolfram Burgard and Dieter Fox created the world's first robot guide at the Deutsches Museum Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 18], [19, 22], [23, 33], [34, 41], [42, 49], [50, 53], [54, 60], [61, 64], [65, 72], [73, 76], [77, 82], [82, 84], [85, 90], [91, 96], [97, 102], [103, 105], [106, 109], [110, 119], [120, 126], [127, 131], [132, 133], [133, 137], [137, 138], [138, 139]]}
{"doc_key": "ai-test-67", "ner": [[0, 3, "product"], [7, 7, "misc"], [23, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 3, "part-of", "", false, false], [23, 25, 0, 3, "usage", "", false, false], [27, 28, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "of", "semantic", "relations", "between", "words", "in", "more", "than", "200", "languages", ".", "It", "is", "mainly", "used", "for", "automatic", "natural", "language", "processing", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database of semantic relations between words in more than 200 languages. It is mainly used for automatic natural language processing and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 32], [33, 41], [42, 51], [52, 59], [60, 65], [66, 68], [69, 73], [74, 78], [79, 82], [83, 92], [92, 93], [94, 96], [97, 99], [100, 106], [107, 111], [112, 115], [116, 125], [126, 133], [134, 142], [143, 153], [154, 157], [158, 168], [169, 181], [182, 194], [194, 195]]}
{"doc_key": "ai-test-68", "ner": [[1, 7, "field"], [14, 17, "conference"], [20, 28, "conference"], [31, 31, "conference"], [34, 34, "conference"], [42, 43, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 17, 1, 7, "topic", "", false, false], [14, 17, 42, 43, "topic", "", false, false], [20, 28, 1, 7, "topic", "", false, false], [20, 28, 42, 43, "topic", "", false, false], [31, 31, 1, 7, "topic", "", false, false], [31, 31, 42, 43, "topic", "", false, false], [34, 34, 1, 7, "topic", "", false, false], [34, 34, 42, 43, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Conferences", "in", "the", "field", "of", "natural", "language", "processing", ",", "such", "as", "those", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "the", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "the", "EMNLP", "and", "the", "HLT", ",", "are", "starting", "to", "feature", "papers", "on", "language", "processing", "."], "sentence-detokenized": "Conferences in the field of natural language processing, such as those of the Association for Computational Linguistics, the North American Chapter of the Association for Computational Linguistics, the EMNLP and the HLT, are starting to feature papers on language processing.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 24], [25, 27], [28, 35], [36, 44], [45, 55], [55, 56], [57, 61], [62, 64], [65, 70], [71, 73], [74, 77], [78, 89], [90, 93], [94, 107], [108, 119], [119, 120], [121, 124], [125, 130], [131, 139], [140, 147], [148, 150], [151, 154], [155, 166], [167, 170], [171, 184], [185, 196], [196, 197], [198, 201], [202, 207], [208, 211], [212, 215], [216, 219], [219, 220], [221, 224], [225, 233], [234, 236], [237, 244], [245, 251], [252, 254], [255, 263], [264, 274], [274, 275]]}
{"doc_key": "ai-test-69", "ner": [[0, 2, "programlang"], [21, 28, "misc"], [34, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["\"", "The", "Java", "suite", "of", "applications", "uses", "a", "lexicon", "to", "parse", "variants", "of", "biomedical", "texts", ",", "linking", "words", "according", "to", "their", "parts", "of", "speech", ",", "which", "can", "be", "useful", "when", "searching", "the", "internet", "or", "electronic", "medical", "records", "."], "sentence-detokenized": "\"The Java suite of applications uses a lexicon to parse variants of biomedical texts, linking words according to their parts of speech, which can be useful when searching the internet or electronic medical records.", "token2charspan": [[0, 1], [1, 4], [5, 9], [10, 15], [16, 18], [19, 31], [32, 36], [37, 38], [39, 46], [47, 49], [50, 55], [56, 64], [65, 67], [68, 78], [79, 84], [84, 85], [86, 93], [94, 99], [100, 109], [110, 112], [113, 118], [119, 124], [125, 127], [128, 134], [134, 135], [136, 141], [142, 145], [146, 148], [149, 155], [156, 160], [161, 170], [171, 174], [175, 183], [184, 186], [187, 197], [198, 205], [206, 213], [213, 214]]}
{"doc_key": "ai-test-70", "ner": [[7, 7, "algorithm"], [9, 9, "algorithm"], [11, 11, "algorithm"], [13, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "many", "newer", "algorithms", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", "and", "others", "."], "sentence-detokenized": "There are many newer algorithms such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost and others.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 20], [21, 31], [32, 36], [37, 39], [40, 47], [47, 48], [49, 59], [59, 60], [61, 71], [71, 72], [73, 80], [80, 81], [82, 91], [92, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-test-71", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "implementation", "in", "Python", ":"], "sentence-detokenized": "This is an example implementation in Python:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 33], [34, 36], [37, 43], [43, 44]]}
{"doc_key": "ai-test-72", "ner": [[12, 12, "organisation"], [13, 13, "product"], [4, 6, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 12, 12, "artifact", "made_by_company", false, false], [4, 6, 13, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1982", ",", "the", "Intellivoice", "Voice", "Synthesis", "module", "was", "proposed", "for", "the", "Mattel", "Intellivision", "games", "console", "."], "sentence-detokenized": "In 1982, the Intellivoice Voice Synthesis module was proposed for the Mattel Intellivision games console.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 25], [26, 31], [32, 41], [42, 48], [49, 52], [53, 61], [62, 65], [66, 69], [70, 76], [77, 90], [91, 96], [97, 104], [104, 105]]}
{"doc_key": "ai-test-73", "ner": [[5, 8, "task"], [10, 17, "task"], [19, 20, "field"], [22, 24, "task"], [27, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 17, 5, 8, "part-of", "", false, false], [19, 20, 5, 8, "part-of", "", false, false], [22, 24, 5, 8, "part-of", "", false, false], [27, 31, 22, 24, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "has", "also", "worked", "on", "machine", "translation", ",", "both", "on", "high", "-", "fidelity", "knowledge", "-", "based", "MT", "and", "on", "machine", "learning", "for", "statistical", "machine", "translation", "(", "e.g.", "generalised", "example", "-", "based", "MT", ")", "."], "sentence-detokenized": "He has also worked on machine translation, both on high-fidelity knowledge-based MT and on machine learning for statistical machine translation (e.g. generalised example-based MT).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 21], [22, 29], [30, 41], [41, 42], [43, 47], [48, 50], [51, 55], [55, 56], [56, 64], [65, 74], [74, 75], [75, 80], [81, 83], [84, 87], [88, 90], [91, 98], [99, 107], [108, 111], [112, 123], [124, 131], [132, 143], [144, 145], [145, 149], [150, 161], [162, 169], [169, 170], [170, 175], [176, 178], [178, 179], [179, 180]]}
{"doc_key": "ai-test-74", "ner": [[0, 2, "misc"], [8, 8, "misc"], [29, 30, "algorithm"], [32, 33, "field"], [35, 36, "field"], [38, 38, "field"], [40, 41, "field"], [43, 43, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 29, 30, "general-affiliation", "", false, false], [0, 2, 32, 33, "general-affiliation", "", false, false], [0, 2, 35, 36, "general-affiliation", "", false, false], [0, 2, 38, 38, "general-affiliation", "", false, false], [0, 2, 40, 41, "general-affiliation", "", false, false], [0, 2, 43, 43, "general-affiliation", "", false, false], [8, 8, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\"", "Wolfram", "Mathematica", "(", "commonly", "referred", "to", "as", "Mathematica", ")", "is", "a", "state", "-", "of", "-", "the", "-", "art", "technical", "computing", "system", "that", "covers", "many", "technical", "areas", ",", "including", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "data", "science", ",", "visualisations", ",", "and", "more", "."], "sentence-detokenized": "\"Wolfram Mathematica (commonly referred to as Mathematica) is a state-of-the-art technical computing system that covers many technical areas, including neural networks, machine learning, image processing, geometry, data science, visualisations, and more.", "token2charspan": [[0, 1], [1, 8], [9, 20], [21, 22], [22, 30], [31, 39], [40, 42], [43, 45], [46, 57], [57, 58], [59, 61], [62, 63], [64, 69], [69, 70], [70, 72], [72, 73], [73, 76], [76, 77], [77, 80], [81, 90], [91, 100], [101, 107], [108, 112], [113, 119], [120, 124], [125, 134], [135, 140], [140, 141], [142, 151], [152, 158], [159, 167], [167, 168], [169, 176], [177, 185], [185, 186], [187, 192], [193, 203], [203, 204], [205, 213], [213, 214], [215, 219], [220, 227], [227, 228], [229, 243], [243, 244], [245, 248], [249, 253], [253, 254]]}
{"doc_key": "ai-test-75", "ner": [[2, 6, "product"], [10, 12, "researcher"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 2, 6, "type-of", "", false, false], [17, 17, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "digitally", "controlled", "and", "programmable", "robot", "was", "invented", "by", "George", "Devol", "in", "1954", "and", "eventually", "named", "Unimate", "."], "sentence-detokenized": "The first digitally controlled and programmable robot was invented by George Devol in 1954 and eventually named Unimate.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 30], [31, 34], [35, 47], [48, 53], [54, 57], [58, 66], [67, 69], [70, 76], [77, 82], [83, 85], [86, 90], [91, 94], [95, 105], [106, 111], [112, 119], [119, 120]]}
{"doc_key": "ai-test-76", "ner": [[1, 1, "algorithm"], [3, 3, "algorithm"], [18, 19, "task"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 3, 3, "compare", "", false, false], [3, 3, 18, 19, "general-affiliation", "", false, false], [3, 3, 21, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Like", "DBNs", ",", "DBMs", "can", "learn", "complex", "and", "abstract", "representations", "of", "internal", "input", "data", "in", "tasks", "such", "as", "object", "recognition", "or", "speech", "recognition", ",", "using", "limited", "labelled", "data", "to", "refine", "representations", "created", "using", "a", "large", "set", "of", "unlabelled", "sensory", "input", "data", "."], "sentence-detokenized": "Like DBNs, DBMs can learn complex and abstract representations of internal input data in tasks such as object recognition or speech recognition, using limited labelled data to refine representations created using a large set of unlabelled sensory input data.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 15], [16, 19], [20, 25], [26, 33], [34, 37], [38, 46], [47, 62], [63, 65], [66, 74], [75, 80], [81, 85], [86, 88], [89, 94], [95, 99], [100, 102], [103, 109], [110, 121], [122, 124], [125, 131], [132, 143], [143, 144], [145, 150], [151, 158], [159, 167], [168, 172], [173, 175], [176, 182], [183, 198], [199, 206], [207, 212], [213, 214], [215, 220], [221, 224], [225, 227], [228, 238], [239, 246], [247, 252], [253, 257], [257, 258]]}
{"doc_key": "ai-test-77", "ner": [[6, 11, "task"], [15, 15, "conference"], [17, 17, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 6, 11, "topic", "", false, false], [17, 17, 6, 11, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "scientific", "conferences", "at", "which", "work", "on", "vision", "-", "based", "activity", "recognition", "often", "appears", "are", "ICCV", "and", "CVPR", "."], "sentence-detokenized": "The scientific conferences at which work on vision-based activity recognition often appears are ICCV and CVPR.", "token2charspan": [[0, 3], [4, 14], [15, 26], [27, 29], [30, 35], [36, 40], [41, 43], [44, 50], [50, 51], [51, 56], [57, 65], [66, 77], [78, 83], [84, 91], [92, 95], [96, 100], [101, 104], [105, 109], [109, 110]]}
{"doc_key": "ai-test-78", "ner": [[0, 3, "field"], [4, 7, "algorithm"], [7, 7, "algorithm"], [17, 18, "metrics"], [20, 22, "metrics"], [24, 24, "metrics"], [40, 41, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 7, 0, 3, "part-of", "", false, false], [4, 7, 17, 18, "related-to", "finds", false, false], [4, 7, 20, 22, "related-to", "finds", false, false], [4, 7, 40, 41, "related-to", "", false, false], [7, 7, 4, 7, "named", "", false, false], [24, 24, 20, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "statistics", ",", "the", "expectation", "-maximisation", "(", "EM", ")", "algorithm", "is", "an", "iterative", "method", "for", "finding", "the", "maximum", "likelihood", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "estimates", "of", "the", "parameters", "of", "statistical", "models", "in", "which", "the", "model", "depends", "on", "unobserved", "latent", "variables", "."], "sentence-detokenized": "In statistics, the expectation-maximisation (EM) algorithm is an iterative method for finding the maximum likelihood or maximum a posteriori (MAP) estimates of the parameters of statistical models in which the model depends on unobserved latent variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 30], [30, 43], [44, 45], [45, 47], [47, 48], [49, 58], [59, 61], [62, 64], [65, 74], [75, 81], [82, 85], [86, 93], [94, 97], [98, 105], [106, 116], [117, 119], [120, 127], [128, 129], [130, 140], [141, 142], [142, 145], [145, 146], [147, 156], [157, 159], [160, 163], [164, 174], [175, 177], [178, 189], [190, 196], [197, 199], [200, 205], [206, 209], [210, 215], [216, 223], [224, 226], [227, 237], [238, 244], [245, 254], [254, 255]]}
{"doc_key": "ai-test-79", "ner": [[6, 17, "metrics"], [9, 11, "metrics"], [12, 13, "metrics"], [15, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 11, 6, 17, "named", "", false, false], [15, 15, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Similarly", ",", "researchers", "sometimes", "refer", "to", "false", "positive", "(", "FPR", ")", "and", "false", "negative", "(", "FNR", ")", "rates", "."], "sentence-detokenized": "Similarly, researchers sometimes refer to false positive (FPR) and false negative (FNR) rates.", "token2charspan": [[0, 9], [9, 10], [11, 22], [23, 32], [33, 38], [39, 41], [42, 47], [48, 56], [57, 58], [58, 61], [61, 62], [63, 66], [67, 72], [73, 81], [82, 83], [83, 86], [86, 87], [88, 93], [93, 94]]}
{"doc_key": "ai-test-80", "ner": [[6, 11, "metrics"], [13, 16, "field"], [19, 20, "metrics"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 16, 6, 11, "usage", "", false, false], [23, 24, 19, 20, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "concept", "is", "similar", "to", "the", "signal", "-", "to", "-", "noise", "ratio", "used", "in", "the", "natural", "sciences", "and", "the", "confusion", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "This concept is similar to the signal-to-noise ratio used in the natural sciences and the confusion matrix used in artificial intelligence.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 23], [24, 26], [27, 30], [31, 37], [37, 38], [38, 40], [40, 41], [41, 46], [47, 52], [53, 57], [58, 60], [61, 64], [65, 72], [73, 81], [82, 85], [86, 89], [90, 99], [100, 106], [107, 111], [112, 114], [115, 125], [126, 138], [138, 139]]}
{"doc_key": "ai-test-81", "ner": [[5, 6, "field"], [11, 14, "researcher"], [18, 19, "researcher"], [21, 26, "researcher"], [34, 44, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 11, 14, "general-affiliation", "", false, false], [5, 6, 18, 19, "general-affiliation", "", false, false], [5, 6, 21, 26, "general-affiliation", "", false, false], [34, 44, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Code", "of", "Ethics", "for", "Human", "Enhancement", ",", "originally", "introduced", "by", "Steve", "Mann", "in", "2004", "and", "refined", "by", "Ray", "Kurzweil", "and", "Marvin", "Minsky", "in", "2013", ",", "was", "finally", "adopted", "on", "25", "June", "2017", ".", "The", "Virtual", "Reality", "Conference", "in", "Toronto", "on", "June", "25", ",", "2017", "."], "sentence-detokenized": "The Code of Ethics for Human Enhancement, originally introduced by Steve Mann in 2004 and refined by Ray Kurzweil and Marvin Minsky in 2013, was finally adopted on 25 June 2017. The Virtual Reality Conference in Toronto on June 25, 2017.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 18], [19, 22], [23, 28], [29, 40], [40, 41], [42, 52], [53, 63], [64, 66], [67, 72], [73, 77], [78, 80], [81, 85], [86, 89], [90, 97], [98, 100], [101, 104], [105, 113], [114, 117], [118, 124], [125, 131], [132, 134], [135, 139], [139, 140], [141, 144], [145, 152], [153, 160], [161, 163], [164, 166], [167, 171], [172, 176], [176, 177], [178, 181], [182, 189], [190, 197], [198, 208], [209, 211], [212, 219], [220, 222], [223, 227], [228, 230], [230, 231], [232, 236], [236, 237]]}
{"doc_key": "ai-test-82", "ner": [[3, 5, "person"], [19, 21, "organisation"], [11, 12, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 19, 21, "role", "directed_for", false, false], [3, 5, 11, 12, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", ",", "Walter", "R.", "Booth", ",", "probably", "in", "collaboration", "with", "Cecil", "Hepworth", ",", "made", "10", "films", "for", "the", "UK", "'s", "Kinoplastikon", "."], "sentence-detokenized": "In 1913, Walter R. Booth, probably in collaboration with Cecil Hepworth, made 10 films for the UK's Kinoplastikon.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 18], [19, 24], [24, 25], [26, 34], [35, 37], [38, 51], [52, 56], [57, 62], [63, 71], [71, 72], [73, 77], [78, 80], [81, 86], [87, 90], [91, 94], [95, 97], [97, 99], [100, 113], [113, 114]]}
{"doc_key": "ai-test-83", "ner": [[8, 8, "location"], [9, 10, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 8, 8, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "unveiled", "their", "new", "robot", "at", "the", "1961", "Chicago", "Cow", "Palace", "Exhibition", "."], "sentence-detokenized": "They unveiled their new robot at the 1961 Chicago Cow Palace Exhibition.", "token2charspan": [[0, 4], [5, 13], [14, 19], [20, 23], [24, 29], [30, 32], [33, 36], [37, 41], [42, 49], [50, 53], [54, 60], [61, 71], [71, 72]]}
{"doc_key": "ai-test-84", "ner": [[1, 1, "product"], [5, 6, "task"], [9, 11, "field"], [14, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 5, 6, "usage", "", false, false], [1, 1, 9, 11, "usage", "", false, false], [1, 1, 14, 17, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Some", "chatbot", "applications", "use", "sophisticated", "word", "classification", "processes", ",", "natural", "language", "processing", "and", "sophisticated", "artificial", "intelligence", ",", "while", "others", "simply", "look", "for", "common", "keywords", "and", "generate", "answers", "using", "common", "phrases", "from", "a", "related", "library", "or", "database", "."], "sentence-detokenized": "Some chatbot applications use sophisticated word classification processes, natural language processing and sophisticated artificial intelligence, while others simply look for common keywords and generate answers using common phrases from a related library or database.", "token2charspan": [[0, 4], [5, 12], [13, 25], [26, 29], [30, 43], [44, 48], [49, 63], [64, 73], [73, 74], [75, 82], [83, 91], [92, 102], [103, 106], [107, 120], [121, 131], [132, 144], [144, 145], [146, 151], [152, 158], [159, 165], [166, 170], [171, 174], [175, 181], [182, 190], [191, 194], [195, 203], [204, 211], [212, 217], [218, 224], [225, 232], [233, 237], [238, 239], [240, 247], [248, 255], [256, 258], [259, 267], [267, 268]]}
{"doc_key": "ai-test-85", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "WaveNet", "model", "proposed", "in", "2016", "has", "excellent", "speech", "quality", "indicators", "."], "sentence-detokenized": "The WaveNet model proposed in 2016 has excellent speech quality indicators.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 38], [39, 48], [49, 55], [56, 63], [64, 74], [74, 75]]}
{"doc_key": "ai-test-86", "ner": [[3, 3, "product"], [4, 6, "misc"], [9, 9, "misc"], [11, 12, "misc"], [15, 16, "misc"], [19, 21, "organisation"], [23, 23, "organisation"], [25, 28, "organisation"], [30, 30, "organisation"], [32, 35, "organisation"], [37, 38, "organisation"], [40, 40, "organisation"], [42, 44, "organisation"], [47, 47, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[3, 3, 4, 6, "general-affiliation", "", false, false], [3, 3, 9, 9, "general-affiliation", "", false, false], [3, 3, 11, 12, "general-affiliation", "", false, false], [3, 3, 15, 16, "general-affiliation", "", false, false], [19, 21, 3, 3, "usage", "", false, false], [23, 23, 3, 3, "usage", "", false, false], [25, 28, 3, 3, "usage", "", false, false], [30, 30, 3, 3, "usage", "", false, false], [32, 35, 3, 3, "usage", "", false, false], [37, 38, 3, 3, "usage", "", false, false], [40, 40, 3, 3, "usage", "", false, false], [42, 44, 3, 3, "usage", "", false, false], [47, 47, 3, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organisations", "that", "use", "ALE", "for", "emergency", "management", ",", "disaster", "relief", ",", "routine", "communications", ",", "or", "emergency", "response", ":", "the", "American", "Red", "Cross", ",", "FEMA", ",", "Disaster", "Medical", "Assistance", "Teams", ",", "NATO", ",", "Federal", "Bureau", "of", "Investigation", ",", "United", "Nations", ",", "AT&T", ",", "Civil", "Air", "Patrol", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organisations that use ALE for emergency management, disaster relief, routine communications, or emergency response: the American Red Cross, FEMA, Disaster Medical Assistance Teams, NATO, Federal Bureau of Investigation, United Nations, AT&T, Civil Air Patrol, (ARES).", "token2charspan": [[0, 13], [14, 18], [19, 22], [23, 26], [27, 30], [31, 40], [41, 51], [51, 52], [53, 61], [62, 68], [68, 69], [70, 77], [78, 92], [92, 93], [94, 96], [97, 106], [107, 115], [115, 116], [117, 120], [121, 129], [130, 133], [134, 139], [139, 140], [141, 145], [145, 146], [147, 155], [156, 163], [164, 174], [175, 180], [180, 181], [182, 186], [186, 187], [188, 195], [196, 202], [203, 205], [206, 219], [219, 220], [221, 227], [228, 235], [235, 236], [237, 241], [241, 242], [243, 248], [249, 252], [253, 259], [259, 260], [261, 262], [262, 266], [266, 267], [267, 268]]}
{"doc_key": "ai-test-87", "ner": [[4, 10, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "simplicity", ",", "the", "Kronecker", "delta", "is", "used", "here", "(", "cf", ".", "the", "derivative", "of", "the", "sigma", "function", ",", "which", "is", "expressed", "via", "the", "function", "itself", ")", "."], "sentence-detokenized": "For simplicity, the Kronecker delta is used here (cf. the derivative of the sigma function, which is expressed via the function itself).", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 29], [30, 35], [36, 38], [39, 43], [44, 48], [49, 50], [50, 52], [52, 53], [54, 57], [58, 68], [69, 71], [72, 75], [76, 81], [82, 90], [90, 91], [92, 97], [98, 100], [101, 110], [111, 114], [115, 118], [119, 127], [128, 134], [134, 135], [135, 136]]}
{"doc_key": "ai-test-88", "ner": [[11, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "theory", ",", "based", "on", "philosophical", "foundations", ",", "was", "developed", "by", "Ray", "Solomonoff", "around", "1960", ".", "Samuel", "Rathmanner", "and", "Marcus", "Hutter", "."], "sentence-detokenized": "This theory, based on philosophical foundations, was developed by Ray Solomonoff around 1960. Samuel Rathmanner and Marcus Hutter.", "token2charspan": [[0, 4], [5, 11], [11, 12], [13, 18], [19, 21], [22, 35], [36, 47], [47, 48], [49, 52], [53, 62], [63, 65], [66, 69], [70, 80], [81, 87], [88, 92], [92, 93], [94, 100], [101, 111], [112, 115], [116, 122], [123, 129], [129, 130]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [10, 18, "misc"], [13, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 18, "type-of", "", false, false], [0, 0, 13, 15, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "a", "freely", "accessible", "database", "originally", "designed", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "has", "been", "extended", "by", "the", "addition", "of", "definitions", "and", "is", "now", "also", "considered", "a", "dictionary", "."], "sentence-detokenized": "WordNet, a freely accessible database originally designed as a semantic network based on psycholinguistic principles, has been extended by the addition of definitions and is now also considered a dictionary.", "token2charspan": [[0, 7], [7, 8], [9, 10], [11, 17], [18, 28], [29, 37], [38, 48], [49, 57], [58, 60], [61, 62], [63, 71], [72, 79], [80, 85], [86, 88], [89, 105], [106, 116], [116, 117], [118, 121], [122, 126], [127, 135], [136, 138], [139, 142], [143, 151], [152, 154], [155, 166], [167, 170], [171, 173], [174, 177], [178, 182], [183, 193], [194, 195], [196, 206], [206, 207]]}
{"doc_key": "ai-test-90", "ner": [[1, 3, "field"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 1, 3, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Advances", "in", "computer", "imaging", "research", "are", "presented", "in", "several", "venues", ",", "including", "SIGGRAPH", "publications", "and", "."], "sentence-detokenized": "Advances in computer imaging research are presented in several venues, including SIGGRAPH publications and.", "token2charspan": [[0, 8], [9, 11], [12, 20], [21, 28], [29, 37], [38, 41], [42, 51], [52, 54], [55, 62], [63, 69], [69, 70], [71, 80], [81, 89], [90, 102], [103, 106], [106, 107]]}
{"doc_key": "ai-test-91", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "considered", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multiclass", "classification", "."], "sentence-detokenized": "Classification can be considered as two separate problems - binary classification and multiclass classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 96], [97, 111], [111, 112]]}
{"doc_key": "ai-test-92", "ner": [[12, 12, "algorithm"], [17, 18, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 12, 12, "type-of", "", false, false], [21, 21, 17, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Advanced", "tools", "for", "prokaryotic", "and", "eukaryotic", "genomic", "gene", "discovery", "typically", "use", "sophisticated", "probabilistic", "models", ",", "such", "as", "Hidden", "Markov", "Models", "(", "HMMs", ")", ",", "to", "combine", "information", "from", "a", "variety", "of", "signal", "and", "content", "measurements", "."], "sentence-detokenized": "Advanced tools for prokaryotic and eukaryotic genomic gene discovery typically use sophisticated probabilistic models, such as Hidden Markov Models (HMMs), to combine information from a variety of signal and content measurements.", "token2charspan": [[0, 8], [9, 14], [15, 18], [19, 30], [31, 34], [35, 45], [46, 53], [54, 58], [59, 68], [69, 78], [79, 82], [83, 96], [97, 110], [111, 117], [117, 118], [119, 123], [124, 126], [127, 133], [134, 140], [141, 147], [148, 149], [149, 153], [153, 154], [154, 155], [156, 158], [159, 166], [167, 178], [179, 183], [184, 185], [186, 193], [194, 196], [197, 203], [204, 207], [208, 215], [216, 228], [228, 229]]}
{"doc_key": "ai-test-93", "ner": [[0, 0, "misc"], [3, 3, "misc"], [9, 10, "field"], [13, 15, "algorithm"], [17, 18, "algorithm"], [21, 24, "algorithm"], [32, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 9, 10, "part-of", "", false, false], [0, 0, 13, 15, "usage", "", false, false], [3, 3, 0, 0, "named", "", false, false], [17, 18, 0, 0, "origin", "", true, false], [21, 24, 17, 18, "named", "", false, false], [32, 33, 0, 0, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Neuroevolution", ",", "or", "neuroevolution", ",", "is", "a", "form", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "generate", "artificial", "neural", "networks", "(", "ANNs", ")", ",", "their", "parameters", ",", "topology", "and", "rules", ".", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuroevolution, or neuroevolution, is a form of artificial intelligence that uses evolutionary algorithms to generate artificial neural networks (ANNs), their parameters, topology and rules. and evolutionary robotics.", "token2charspan": [[0, 14], [14, 15], [16, 18], [19, 33], [33, 34], [35, 37], [38, 39], [40, 44], [45, 47], [48, 58], [59, 71], [72, 76], [77, 81], [82, 94], [95, 105], [106, 108], [109, 117], [118, 128], [129, 135], [136, 144], [145, 146], [146, 150], [150, 151], [151, 152], [153, 158], [159, 169], [169, 170], [171, 179], [180, 183], [184, 189], [189, 190], [191, 194], [195, 207], [208, 216], [216, 217]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [6, 6, "metrics"], [8, 8, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "IBM", "proposed", "and", "implemented", "the", "BLEU", "system", "Papineni", "et", "al", "."], "sentence-detokenized": "Since IBM proposed and implemented the BLEU system Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 34], [35, 38], [39, 43], [44, 50], [51, 59], [60, 62], [63, 65], [65, 66]]}
{"doc_key": "ai-test-95", "ner": [[11, 18, "conference"], [20, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 20, 11, 18, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "experts", "took", "part", "in", "a", "conference", "organised", "by", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "to", "discuss", "whether", "and", "to", "what", "extent", "computers", "and", "robots", "can", "acquire", "autonomy", "and", "whether", "these", "capabilities", "can", "pose", "a", "threat", "or", "a", "danger", "."], "sentence-detokenized": "In 2009, experts took part in a conference organised by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether and to what extent computers and robots can acquire autonomy and whether these capabilities can pose a threat or a danger.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 21], [22, 26], [27, 29], [30, 31], [32, 42], [43, 52], [53, 55], [56, 59], [60, 71], [72, 75], [76, 79], [80, 91], [92, 94], [95, 105], [106, 118], [119, 120], [120, 124], [124, 125], [126, 128], [129, 136], [137, 144], [145, 148], [149, 151], [152, 156], [157, 163], [164, 173], [174, 177], [178, 184], [185, 188], [189, 196], [197, 205], [206, 209], [210, 217], [218, 223], [224, 236], [237, 240], [241, 245], [246, 247], [248, 254], [255, 257], [258, 259], [260, 266], [266, 267]]}
{"doc_key": "ai-test-96", "ner": [[22, 23, "researcher"], [25, 26, "researcher"], [28, 33, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[28, 33, 22, 23, "artifact", "", false, false], [28, 33, 25, 26, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["After", "boosting", ",", "a", "200", "-", "feature", "classifier", "can", "achieve", "a", "95", "%", "detection", "rate", "at", "^", "{", "-", "5", "}", "/", "P.", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "After boosting, a 200-feature classifier can achieve a 95% detection rate at ^ {-5} / P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 17], [18, 21], [21, 22], [22, 29], [30, 40], [41, 44], [45, 52], [53, 54], [55, 57], [57, 58], [59, 68], [69, 73], [74, 76], [77, 78], [79, 80], [80, 81], [81, 82], [82, 83], [84, 85], [86, 88], [89, 94], [94, 95], [96, 98], [99, 104], [104, 105], [106, 112], [113, 117], [117, 118], [118, 122], [123, 129], [130, 139], [139, 140], [141, 145], [145, 146]]}
{"doc_key": "ai-test-97", "ner": [[6, 6, "programlang"], [12, 12, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "site", "was", "originally", "developed", "using", "Perl", ",", "but", "for", "security", "reasons", "IMDb", "no", "longer", "discloses", "what", "software", "it", "uses", "."], "sentence-detokenized": "The site was originally developed using Perl, but for security reasons IMDb no longer discloses what software it uses.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 23], [24, 33], [34, 39], [40, 44], [44, 45], [46, 49], [50, 53], [54, 62], [63, 70], [71, 75], [76, 78], [79, 85], [86, 95], [96, 100], [101, 109], [110, 112], [113, 117], [117, 118]]}
{"doc_key": "ai-test-98", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Demis", "Hassabi", ",", "Shane", "Legg", "and", "Mustafa", "Suleyman", "founded", "the", "start", "-", "up", "in", "2010", "."], "sentence-detokenized": "Demis Hassabi, Shane Legg and Mustafa Suleyman founded the start-up in 2010.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 20], [21, 25], [26, 29], [30, 37], [38, 46], [47, 54], [55, 58], [59, 64], [64, 65], [65, 67], [68, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-test-99", "ner": [[4, 5, "misc"], [8, 11, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 4, 5, "type-of", "", false, false], [24, 25, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "very", "commonly", "used", "loss", "functions", "are", "the", "root", "mean", "square", "error", ",", "mathL", "(", "a", ")", "=", "a^2", "/", "math", ",", "and", "the", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Two very commonly used loss functions are the root mean square error, mathL (a) = a^2/math, and the absolute loss, mathL (a) = |a |/math.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 27], [28, 37], [38, 41], [42, 45], [46, 50], [51, 55], [56, 62], [63, 68], [68, 69], [70, 75], [76, 77], [77, 78], [78, 79], [80, 81], [82, 85], [85, 86], [86, 90], [90, 91], [92, 95], [96, 99], [100, 108], [109, 113], [113, 114], [115, 120], [121, 122], [122, 123], [123, 124], [125, 126], [127, 128], [128, 129], [130, 131], [131, 132], [132, 136], [136, 137]]}
{"doc_key": "ai-test-100", "ner": [[2, 4, "algorithm"], [11, 13, "algorithm"], [15, 17, "algorithm"], [18, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 4, 11, 13, "type-of", "example_of", false, false], [11, 13, 18, 19, "related-to", "", false, false], [15, 17, 11, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "soft", "support", "vector", "machine", "described", "above", "is", "an", "example", "of", "empirical", "risk", "minimisation", "(", "ERM", ")", "for", "hinge", "losses", "."], "sentence-detokenized": "The soft support vector machine described above is an example of empirical risk minimisation (ERM) for hinge losses.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 23], [24, 31], [32, 41], [42, 47], [48, 50], [51, 53], [54, 61], [62, 64], [65, 74], [75, 79], [80, 92], [93, 94], [94, 97], [97, 98], [99, 102], [103, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-101", "ner": [[5, 6, "field"], [0, 2, "task"], [16, 16, "organisation"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[0, 2, 5, 6, "origin", "", false, false], [16, 16, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["Neural", "machine", "translation", "based", "on", "deep", "learning", "has", "made", "rapid", "advances", "in", "recent", "years", ",", "and", "Google", "has", "announced", "that", "its", "translation", "services", "now", "use", "this", "technology", "rather", "than", "the", "statistical", "methods", "of", "the", "past", "."], "sentence-detokenized": "Neural machine translation based on deep learning has made rapid advances in recent years, and Google has announced that its translation services now use this technology rather than the statistical methods of the past.", "token2charspan": [[0, 6], [7, 14], [15, 26], [27, 32], [33, 35], [36, 40], [41, 49], [50, 53], [54, 58], [59, 64], [65, 73], [74, 76], [77, 83], [84, 89], [89, 90], [91, 94], [95, 101], [102, 105], [106, 115], [116, 120], [121, 124], [125, 136], [137, 145], [146, 149], [150, 153], [154, 158], [159, 169], [170, 176], [177, 181], [182, 185], [186, 197], [198, 205], [206, 208], [209, 212], [213, 217], [217, 218]]}
{"doc_key": "ai-test-102", "ner": [[14, 14, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "usually", "results", "in", "significant", "performance", "gains", "when", "working", "with", "large", "corpora", "such", "as", "WordNet", "."], "sentence-detokenized": "This usually results in significant performance gains when working with large corpora such as WordNet.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 23], [24, 35], [36, 47], [48, 53], [54, 58], [59, 66], [67, 71], [72, 77], [78, 85], [86, 90], [91, 93], [94, 101], [101, 102]]}
{"doc_key": "ai-test-103", "ner": [[0, 1, "task"], [5, 7, "field"], [18, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 18, 20, "part-of", "", false, false], [18, 20, 5, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Face", "detection", "is", "used", "in", "biometrics", ",", "often", "as", "part", "of", "(", "or", "in", "combination", "with", ")", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Face detection is used in biometrics, often as part of (or in combination with) a facial recognition system.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 22], [23, 25], [26, 36], [36, 37], [38, 43], [44, 46], [47, 51], [52, 54], [55, 56], [56, 58], [59, 61], [62, 73], [74, 78], [78, 79], [80, 81], [82, 88], [89, 100], [101, 107], [107, 108]]}
{"doc_key": "ai-test-104", "ner": [[2, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["trained", "using", "maximum", "likelihood", "estimation", "."], "sentence-detokenized": "trained using maximum likelihood estimation.", "token2charspan": [[0, 7], [8, 13], [14, 21], [22, 32], [33, 43], [43, 44]]}
{"doc_key": "ai-test-105", "ner": [[4, 4, "country"], [6, 11, "organisation"], [13, 14, "location"], [16, 16, "country"], [18, 21, "organisation"], [22, 22, "country"], [27, 29, "organisation"], [31, 33, "organisation"], [34, 35, "country"], [44, 48, "organisation"], [49, 50, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[6, 11, 13, 14, "physical", "", false, false], [13, 14, 16, 16, "physical", "", false, false], [18, 21, 22, 22, "physical", "", false, false], [31, 33, 34, 35, "physical", "", false, false], [44, 48, 49, 50, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd", ".", "\"", "In", "Thailand", ",", "Komatsu", "(", "Shanghai", ")", "Ltd", ".", "1996", "In", "Shanghai", ",", "China", ",", "Industrial", "Power", "Alliance", "Ltd.", "Japan", ",", "joint", "venture", "with", "Cummins", ",", "1998", ",", "L&T-", "Komatsu", "Limited", "in", "India", "1998", "(", "shares", "sold", "in", "2013", ")", "and", "Komatsu", "Brasil", "International", "Ltda", ".", "In", "Brazil", "in", "1998", "."], "sentence-detokenized": "Ltd.\" In Thailand, Komatsu (Shanghai) Ltd. 1996 In Shanghai, China, Industrial Power Alliance Ltd. Japan, joint venture with Cummins, 1998, L&T-Komatsu Limited in India 1998 (shares sold in 2013) and Komatsu Brasil International Ltda. In Brazil in 1998.", "token2charspan": [[0, 3], [3, 4], [4, 5], [6, 8], [9, 17], [17, 18], [19, 26], [27, 28], [28, 36], [36, 37], [38, 41], [41, 42], [43, 47], [48, 50], [51, 59], [59, 60], [61, 66], [66, 67], [68, 78], [79, 84], [85, 93], [94, 98], [99, 104], [104, 105], [106, 111], [112, 119], [120, 124], [125, 132], [132, 133], [134, 138], [138, 139], [140, 144], [144, 151], [152, 159], [160, 162], [163, 168], [169, 173], [174, 175], [175, 181], [182, 186], [187, 189], [190, 194], [194, 195], [196, 199], [200, 207], [208, 214], [215, 228], [229, 233], [233, 234], [235, 237], [238, 244], [245, 247], [248, 252], [252, 253]]}
{"doc_key": "ai-test-106", "ner": [[0, 1, "organisation"], [4, 8, "misc"], [9, 9, "misc"], [11, 12, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 0, 1, "physical", "", false, false], [11, 12, 4, 8, "general-affiliation", "", false, false], [11, 12, 9, 9, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["dgp", "also", "occasionally", "hosts", "artists", "in", "residence", "(", "e.g.", "Oscar", "winner", "Chris", "Landreth", ")", "."], "sentence-detokenized": "dgp also occasionally hosts artists in residence (e.g. Oscar winner Chris Landreth).", "token2charspan": [[0, 3], [4, 8], [9, 21], [22, 27], [28, 35], [36, 38], [39, 48], [49, 50], [50, 54], [55, 60], [61, 67], [68, 73], [74, 82], [82, 83], [83, 84]]}
{"doc_key": "ai-test-107", "ner": [[7, 9, "misc"], [12, 14, "misc"], [17, 21, "misc"], [25, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "currently", "includes", "four", "sub-competitions", ":", "the", "RoboMaster", "Robotics", "Competition", ",", "the", "RoboMaster", "Technical", "Challenge", ",", "the", "ICRA", "RoboMaster", "Artificial", "Intelligence", "Challenge", "and", "the", "new", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "It currently includes four sub-competitions: the RoboMaster Robotics Competition, the RoboMaster Technical Challenge, the ICRA RoboMaster Artificial Intelligence Challenge and the new RoboMaster Youth Tournament.", "token2charspan": [[0, 2], [3, 12], [13, 21], [22, 26], [27, 43], [43, 44], [45, 48], [49, 59], [60, 68], [69, 80], [80, 81], [82, 85], [86, 96], [97, 106], [107, 116], [116, 117], [118, 121], [122, 126], [127, 137], [138, 148], [149, 161], [162, 171], [172, 175], [176, 179], [180, 183], [184, 194], [195, 200], [201, 211], [211, 212]]}
{"doc_key": "ai-test-108", "ner": [[7, 8, "field"], [15, 17, "algorithm"], [21, 22, "algorithm"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 21, 22, "usage", "", false, false], [7, 8, 24, 25, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "the", "early", "2000s", ",", "the", "dominant", "language", "processing", "strategy", "began", "to", "shift", "from", "the", "hidden", "Markov", "model", "towards", "more", "sophisticated", "neural", "networks", "and", "deep", "learning", "."], "sentence-detokenized": "In the early 2000s, the dominant language processing strategy began to shift from the hidden Markov model towards more sophisticated neural networks and deep learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 18], [18, 19], [20, 23], [24, 32], [33, 41], [42, 52], [53, 61], [62, 67], [68, 70], [71, 76], [77, 81], [82, 85], [86, 92], [93, 99], [100, 105], [106, 113], [114, 118], [119, 132], [133, 139], [140, 148], [149, 152], [153, 157], [158, 166], [166, 167]]}
{"doc_key": "ai-test-109", "ner": [[5, 8, "misc"], [19, 19, "metrics"], [21, 23, "metrics"], [29, 34, "metrics"], [35, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 21, 23, "related-to", "equal", false, false], [29, 34, 35, 36, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "equivalent", "expression", "for", "the", "binary", "target", "rate", "is", "that", "for", "each", "value", "of", "the", "sensitive", "characteristics", ",", "the", "positive", "and", "false", "positive", "rates", "are", "equal", "(", "so", "the", "false", "negative", "rate", "and", "the", "false", "negative", "rate", "are", "equal", ")", ":"], "sentence-detokenized": "Another equivalent expression for the binary target rate is that for each value of the sensitive characteristics, the positive and false positive rates are equal (so the false negative rate and the false negative rate are equal):", "token2charspan": [[0, 7], [8, 18], [19, 29], [30, 33], [34, 37], [38, 44], [45, 51], [52, 56], [57, 59], [60, 64], [65, 68], [69, 73], [74, 79], [80, 82], [83, 86], [87, 96], [97, 112], [112, 113], [114, 117], [118, 126], [127, 130], [131, 136], [137, 145], [146, 151], [152, 155], [156, 161], [162, 163], [163, 165], [166, 169], [170, 175], [176, 184], [185, 189], [190, 193], [194, 197], [198, 203], [204, 212], [213, 217], [218, 221], [222, 227], [227, 228], [228, 229]]}
{"doc_key": "ai-test-110", "ner": [[0, 0, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["MATLAB", "function", ","], "sentence-detokenized": "MATLAB function,", "token2charspan": [[0, 6], [7, 15], [15, 16]]}
{"doc_key": "ai-test-111", "ner": [[0, 2, "product"], [7, 11, "misc"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 11, 0, 2, "part-of", "", false, false], [16, 17, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "articulated", "robot", "is", "a", "robot", "with", "rotating", "joints", "(", "e.g.", "a", "legged", "robot", "or", "an", "industrial", "robot", ")", "."], "sentence-detokenized": "An articulated robot is a robot with rotating joints (e.g. a legged robot or an industrial robot).", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 23], [24, 25], [26, 31], [32, 36], [37, 45], [46, 52], [53, 54], [54, 58], [59, 60], [61, 67], [68, 73], [74, 76], [77, 79], [80, 90], [91, 96], [96, 97], [97, 98]]}
{"doc_key": "ai-test-112", "ner": [[0, 1, "product"], [6, 7, "product"], [9, 10, "product"], [14, 14, "misc"], [18, 19, "product"], [26, 28, "misc"], [32, 32, "location"], [34, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 14, 14, "general-affiliation", "nationality", false, false], [0, 1, 26, 28, "usage", "", false, false], [0, 1, 32, 32, "physical", "", false, false], [6, 7, 0, 1, "named", "", false, false], [9, 10, 0, 1, "named", "", false, false], [32, 32, 34, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["\"", "Pandora", "(", "also", "known", "as", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "an", "American", "music", "streaming", "and", "auto-recommendation", "system", "internet", "radio", "service", "developed", "by", "the", "Music", "Genome", "Project", "and", "based", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "\"Pandora (also known as Pandora Media or Pandora Radio) is an American music streaming and auto-recommendation system internet radio service developed by the Music Genome Project and based in Oakland, California.", "token2charspan": [[0, 1], [1, 8], [9, 10], [10, 14], [15, 20], [21, 23], [24, 31], [32, 37], [38, 40], [41, 48], [49, 54], [54, 55], [56, 58], [59, 61], [62, 70], [71, 76], [77, 86], [87, 90], [91, 110], [111, 117], [118, 126], [127, 132], [133, 140], [141, 150], [151, 153], [154, 157], [158, 163], [164, 170], [171, 178], [179, 182], [183, 188], [189, 191], [192, 199], [199, 200], [201, 211], [211, 212]]}
{"doc_key": "ai-test-113", "ner": [[6, 11, "organisation"], [17, 19, "organisation"], [24, 24, "conference"], [36, 36, "conference"], [38, 38, "conference"], [40, 40, "conference"], [42, 42, "conference"], [44, 44, "conference"], [46, 46, "conference"], [48, 48, "conference"], [50, 50, "conference"], [52, 52, "conference"], [54, 54, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "board", "member", "of", "the", "International", "Society", "for", "Machine", "Learning", ",", "a", "member", "of", "the", "AAAI", "Executive", "Council", ",", "was", "the", "2011", "ICML", "Chair", ",", "and", "has", "been", "a", "senior", "chair", "of", "conferences", "including", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", "and", "WWW", "."], "sentence-detokenized": "She is a board member of the International Society for Machine Learning, a member of the AAAI Executive Council, was the 2011 ICML Chair, and has been a senior chair of conferences including AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM and WWW.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 14], [15, 21], [22, 24], [25, 28], [29, 42], [43, 50], [51, 54], [55, 62], [63, 71], [71, 72], [73, 74], [75, 81], [82, 84], [85, 88], [89, 93], [94, 103], [104, 111], [111, 112], [113, 116], [117, 120], [121, 125], [126, 130], [131, 136], [136, 137], [138, 141], [142, 145], [146, 150], [151, 152], [153, 159], [160, 165], [166, 168], [169, 180], [181, 190], [191, 195], [195, 196], [197, 201], [201, 202], [203, 208], [208, 209], [210, 214], [214, 215], [216, 219], [219, 220], [221, 227], [227, 228], [229, 232], [232, 233], [234, 238], [238, 239], [240, 244], [245, 248], [249, 252], [252, 253]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [5, 10, "organisation"], [12, 12, "organisation"], [17, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 10, "role", "", false, false], [12, 12, 5, 10, "named", "", false, false], [17, 20, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "has", "developed", "a", "robocrane", "in", "which", "the", "platform", "hangs", "from", "six", "cables", "instead", "of", "six", "sockets", "."], "sentence-detokenized": "James S. Albus of the National Institute of Standards and Technology (NIST) has developed a robocrane in which the platform hangs from six cables instead of six sockets.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [74, 75], [76, 79], [80, 89], [90, 91], [92, 101], [102, 104], [105, 110], [111, 114], [115, 123], [124, 129], [130, 134], [135, 138], [139, 145], [146, 153], [154, 156], [157, 160], [161, 168], [168, 169]]}
{"doc_key": "ai-test-115", "ner": [[3, 5, "algorithm"], [8, 11, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 3, 5, "type-of", "", false, false], [13, 14, 8, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "class", "of", "direct", "search", "algorithms", "are", "various", "evolutionary", "algorithms", ",", "such", "as", "genetic", "algorithms", "."], "sentence-detokenized": "Another class of direct search algorithms are various evolutionary algorithms, such as genetic algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 23], [24, 30], [31, 41], [42, 45], [46, 53], [54, 66], [67, 77], [77, 78], [79, 83], [84, 86], [87, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-test-116", "ner": [[0, 0, "organisation"], [3, 3, "misc"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 0, "named", "", false, false], [6, 7, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "industrial", "robots", "and", "factory", "automation", "solutions", "."], "sentence-detokenized": "KUKA is a German manufacturer of industrial robots and factory automation solutions.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-117", "ner": [[4, 4, "misc"], [8, 10, "person"], [11, 17, "misc"], [19, 21, "person"], [22, 22, "misc"], [24, 26, "person"], [27, 28, "misc"], [30, 31, "person"], [33, 35, "misc"], [37, 39, "person"], [41, 46, "misc"], [48, 49, "person"], [51, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 10, 4, 4, "usage", "", false, false], [11, 17, 8, 10, "artifact", "", false, false], [19, 21, 4, 4, "usage", "", false, false], [22, 22, 19, 21, "artifact", "", false, false], [24, 26, 4, 4, "usage", "", false, false], [27, 28, 24, 26, "artifact", "", false, false], [30, 31, 4, 4, "usage", "", false, false], [33, 35, 30, 31, "artifact", "", false, false], [37, 39, 4, 4, "usage", "", false, false], [41, 46, 37, 39, "artifact", "", false, false], [48, 49, 4, 4, "usage", "", false, false], [51, 54, 48, 49, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Other", "films", "captured", "in", "IMAX", "in", "2016-2020", "include", "Zack", "Snyder", "'s", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", ",", "Clint", "Eastwood", "'s", "Sully", ",", "Damien", "Chazelle", "'s", "First", "Man", ",", "Patty", "Jenkins", "'", "Wonder", "Woman", "1984", ",", "Cary", "Joji", "Fukunaga", "'s", "There", "'s", "No", "Time", "to", "Die", "and", "Joseph", "Kosinski", "'s", "Top", "Gun", ":", "Maverick", "."], "sentence-detokenized": "Other films captured in IMAX in 2016-2020 include Zack Snyder's Batman v Superman: Dawn of Justice, Clint Eastwood's Sully, Damien Chazelle's First Man, Patty Jenkins' Wonder Woman 1984, Cary Joji Fukunaga's There's No Time to Die and Joseph Kosinski's Top Gun: Maverick.", "token2charspan": [[0, 5], [6, 11], [12, 20], [21, 23], [24, 28], [29, 31], [32, 41], [42, 49], [50, 54], [55, 61], [61, 63], [64, 70], [71, 72], [73, 81], [81, 82], [83, 87], [88, 90], [91, 98], [98, 99], [100, 105], [106, 114], [114, 116], [117, 122], [122, 123], [124, 130], [131, 139], [139, 141], [142, 147], [148, 151], [151, 152], [153, 158], [159, 166], [166, 167], [168, 174], [175, 180], [181, 185], [185, 186], [187, 191], [192, 196], [197, 205], [205, 207], [208, 213], [213, 215], [216, 218], [219, 223], [224, 226], [227, 230], [231, 234], [235, 241], [242, 250], [250, 252], [253, 256], [257, 260], [260, 261], [262, 270], [270, 271]]}
{"doc_key": "ai-test-118", "ner": [[4, 5, "misc"], [10, 12, "organisation"], [14, 20, "organisation"], [25, 25, "misc"], [32, 35, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 25, 25, "named", "", false, false], [10, 12, 4, 5, "usage", "", false, false], [10, 12, 32, 35, "physical", "", false, false], [14, 20, 10, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "pilot", "version", "of", "MICR", "E13B", "was", "shown", "to", "the", "American", "Bankers", "Association", "(", "ABA", ")", "in", "July", "1956", ",", "which", "adopted", "it", "as", "the", "MICR", "standard", "for", "negotiable", "documents", "in", "the", "United", "States", "in", "1958", "."], "sentence-detokenized": "A pilot version of MICR E13B was shown to the American Bankers Association (ABA) in July 1956, which adopted it as the MICR standard for negotiable documents in the United States in 1958.", "token2charspan": [[0, 1], [2, 7], [8, 15], [16, 18], [19, 23], [24, 28], [29, 32], [33, 38], [39, 41], [42, 45], [46, 54], [55, 62], [63, 74], [75, 76], [76, 79], [79, 80], [81, 83], [84, 88], [89, 93], [93, 94], [95, 100], [101, 108], [109, 111], [112, 114], [115, 118], [119, 123], [124, 132], [133, 136], [137, 147], [148, 157], [158, 160], [161, 164], [165, 171], [172, 178], [179, 181], [182, 186], [186, 187]]}
{"doc_key": "ai-test-119", "ner": [[0, 2, "misc"], [17, 18, "field"], [21, 22, "field"], [25, 25, "field"], [27, 28, "field"], [30, 30, "field"], [32, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[17, 18, 0, 2, "usage", "", false, false], [21, 22, 17, 18, "part-of", "", false, false], [25, 25, 0, 2, "usage", "", false, false], [27, 28, 0, 2, "usage", "", false, false], [30, 30, 0, 2, "usage", "", false, false], [32, 32, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "are", "widely", "used", "to", "solve", "a", "wide", "range", "of", "complex", "computational", "problems", ",", "including", "computer", "science", "(", "especially", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms are widely used to solve a wide range of complex computational problems, including computer science (especially artificial intelligence), mathematics, operations research, engineering and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 27], [28, 34], [35, 39], [40, 42], [43, 48], [49, 50], [51, 55], [56, 61], [62, 64], [65, 72], [73, 86], [87, 95], [95, 96], [97, 106], [107, 115], [116, 123], [124, 125], [125, 135], [136, 146], [147, 159], [159, 160], [160, 161], [162, 173], [173, 174], [175, 185], [186, 194], [194, 195], [196, 207], [208, 211], [212, 226], [226, 227]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [8, 8, "location"], [10, 10, "country"], [14, 14, "country"], [21, 22, "algorithm"], [24, 24, "algorithm"], [26, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 8, 8, "physical", "", false, false], [0, 1, 14, 14, "general-affiliation", "nationality", false, false], [0, 1, 21, 22, "general-affiliation", "topic_of_study", false, false], [0, 1, 24, 24, "general-affiliation", "topic_of_study", false, false], [8, 8, 10, 10, "physical", "", false, false], [24, 24, 26, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "born", "3", "September", "1947", "in", "Wollersdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "studies", "the", "use", "of", "bounded", "rationality", "and", "heuristics", "in", "decision", "-", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (born 3 September 1947 in Wollersdorf, Germany) is a German psychologist who studies the use of bounded rationality and heuristics in decision-making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 21], [22, 23], [24, 33], [34, 38], [39, 41], [42, 53], [53, 54], [55, 62], [62, 63], [64, 66], [67, 68], [69, 75], [76, 88], [89, 92], [93, 100], [101, 104], [105, 108], [109, 111], [112, 119], [120, 131], [132, 135], [136, 146], [147, 149], [150, 158], [158, 159], [159, 165], [165, 166]]}
{"doc_key": "ai-test-121", "ner": [[3, 6, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["to", "reduce", "the", "root", "mean", "square", "error", "."], "sentence-detokenized": "to reduce the root mean square error.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 18], [19, 23], [24, 30], [31, 36], [36, 37]]}
{"doc_key": "ai-test-122", "ner": [[13, 14, "misc"], [18, 19, "organisation"], [35, 37, "field"], [54, 56, "misc"], [64, 66, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 14, 18, 19, "origin", "", false, false], [54, 56, 64, 66, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "even", "an", "official", "language", "regulated", "by", "an", "academy", ",", "such", "as", "standard", "French", "regulated", "by", "the", "French", "Academy", ",", "is", "classified", "as", "a", "natural", "language", "(", "for", "example", ",", "in", "the", "field", "of", "natural", "language", "processing", ")", "because", "its", "normative", "points", "do", "not", "make", "it", "sufficiently", "constructive", "to", "be", "classified", "as", "a", "constructive", "language", "or", "sufficiently", "controllable", "to", "be", "classified", "as", "a", "controllable", "natural", "language", "."], "sentence-detokenized": "However, even an official language regulated by an academy, such as standard French regulated by the French Academy, is classified as a natural language (for example, in the field of natural language processing) because its normative points do not make it sufficiently constructive to be classified as a constructive language or sufficiently controllable to be classified as a controllable natural language.", "token2charspan": [[0, 7], [7, 8], [9, 13], [14, 16], [17, 25], [26, 34], [35, 44], [45, 47], [48, 50], [51, 58], [58, 59], [60, 64], [65, 67], [68, 76], [77, 83], [84, 93], [94, 96], [97, 100], [101, 107], [108, 115], [115, 116], [117, 119], [120, 130], [131, 133], [134, 135], [136, 143], [144, 152], [153, 154], [154, 157], [158, 165], [165, 166], [167, 169], [170, 173], [174, 179], [180, 182], [183, 190], [191, 199], [200, 210], [210, 211], [212, 219], [220, 223], [224, 233], [234, 240], [241, 243], [244, 247], [248, 252], [253, 255], [256, 268], [269, 281], [282, 284], [285, 287], [288, 298], [299, 301], [302, 303], [304, 316], [317, 325], [326, 328], [329, 341], [342, 354], [355, 357], [358, 360], [361, 371], [372, 374], [375, 376], [377, 389], [390, 397], [398, 406], [406, 407]]}
{"doc_key": "ai-test-123", "ner": [[12, 12, "metrics"], [15, 16, "metrics"], [18, 21, "metrics"], [40, 41, "metrics"], [43, 43, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[18, 21, 15, 16, "named", "", false, false], [43, 43, 40, 41, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "many", "other", "indicators", ",", "the", "simplest", "of", "which", "is", "the", "accuracy", "or", "the", "correct", "fraction", "(", "FC", ")", ",", "which", "shows", "what", "proportion", "of", "all", "cases", "are", "correctly", "assigned", "to", "a", "category", ";", "an", "additional", "indicator", "is", "the", "false", "fraction", "(", "FiC", ")", "."], "sentence-detokenized": "There are many other indicators, the simplest of which is the accuracy or the correct fraction (FC), which shows what proportion of all cases are correctly assigned to a category; an additional indicator is the false fraction (FiC).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 20], [21, 31], [31, 32], [33, 36], [37, 45], [46, 48], [49, 54], [55, 57], [58, 61], [62, 70], [71, 73], [74, 77], [78, 85], [86, 94], [95, 96], [96, 98], [98, 99], [99, 100], [101, 106], [107, 112], [113, 117], [118, 128], [129, 131], [132, 135], [136, 141], [142, 145], [146, 155], [156, 164], [165, 167], [168, 169], [170, 178], [178, 179], [180, 182], [183, 193], [194, 203], [204, 206], [207, 210], [211, 216], [217, 225], [226, 227], [227, 230], [230, 231], [231, 232]]}
{"doc_key": "ai-test-124", "ner": [[3, 3, "researcher"], [9, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 9, 12, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2016", ",", "Cardie", "became", "a", "member", "of", "the", "Association", "for", "Computational", "Linguistics", "."], "sentence-detokenized": "In 2016, Cardie became a member of the Association for Computational Linguistics.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 22], [23, 24], [25, 31], [32, 34], [35, 38], [39, 50], [51, 54], [55, 68], [69, 80], [80, 81]]}
{"doc_key": "ai-test-125", "ner": [[12, 14, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Learning", "the", "parameters", "math", "\\", "theta", "/", "math", "is", "usually", "done", "using", "maximum", "likelihood", "learning", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";\\", "theta", ")", "/", "math", "."], "sentence-detokenized": "Learning the parameters math\\ theta / math is usually done using maximum likelihood learning mathp (Y _ i | X _ i;\\ theta) / math.", "token2charspan": [[0, 8], [9, 12], [13, 23], [24, 28], [28, 29], [30, 35], [36, 37], [38, 42], [43, 45], [46, 53], [54, 58], [59, 64], [65, 72], [73, 83], [84, 92], [93, 98], [99, 100], [100, 101], [102, 103], [104, 105], [106, 107], [108, 109], [110, 111], [112, 113], [113, 115], [116, 121], [121, 122], [123, 124], [125, 129], [129, 130]]}
{"doc_key": "ai-test-126", "ner": [[0, 1, "task"], [3, 6, "algorithm"], [7, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 0, 1, "usage", "", true, false], [7, 9, 3, 6, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cluster", "analysis", "and", "factorisation", "of", "negative", "matrices", "for", "descriptive", "extraction", "."], "sentence-detokenized": "Cluster analysis and factorisation of negative matrices for descriptive extraction.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 34], [35, 37], [38, 46], [47, 55], [56, 59], [60, 71], [72, 82], [82, 83]]}
{"doc_key": "ai-test-127", "ner": [[0, 1, "field"], [4, 5, "field"], [17, 19, "field"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 19, 0, 1, "part-of", "", false, false], [17, 19, 4, 5, "part-of", "", false, false], [21, 22, 0, 1, "part-of", "", false, false], [21, 22, 4, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Computer", "science", "and", "the", "information", "technologies", "it", "enables", "have", "long", "challenged", "the", "ability", "of", "computers", "to", "perform", "natural", "language", "processing", "and", "machine", "learning", "."], "sentence-detokenized": "Computer science and the information technologies it enables have long challenged the ability of computers to perform natural language processing and machine learning.", "token2charspan": [[0, 8], [9, 16], [17, 20], [21, 24], [25, 36], [37, 49], [50, 52], [53, 60], [61, 65], [66, 70], [71, 81], [82, 85], [86, 93], [94, 96], [97, 106], [107, 109], [110, 117], [118, 125], [126, 134], [135, 145], [146, 149], [150, 157], [158, 166], [166, 167]]}
{"doc_key": "ai-test-128", "ner": [[4, 7, "algorithm"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 7, 10, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "The", "code", "for", "extracting", "Gabor", "features", "from", "images", "in", "MATLAB", "is", "available", "at"], "sentence-detokenized": "(The code for extracting Gabor features from images in MATLAB is available at", "token2charspan": [[0, 1], [1, 4], [5, 9], [10, 13], [14, 24], [25, 30], [31, 39], [40, 44], [45, 51], [52, 54], [55, 61], [62, 64], [65, 74], [75, 77]]}
{"doc_key": "ai-test-129", "ner": [[0, 1, "misc"], [16, 17, "algorithm"], [21, 21, "task"], [23, 23, "task"], [25, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 16, 17, "general-affiliation", "", false, false], [0, 1, 21, 21, "related-to", "solves_problem_of_type", false, false], [0, 1, 23, 23, "related-to", "solves_problem_of_type", false, false], [0, 1, 25, 26, "related-to", "solves_problem_of_type", false, false], [0, 1, 28, 29, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["\"", "NeuralExpert", "focuses", "the", "design", "specifications", "on", "the", "type", "of", "problem", "the", "user", "would", "like", "the", "neural", "network", "to", "solve", "(", "classification", ",", "prediction", ",", "function", "approximation", "or", "cluster", "analysis", ")", "."], "sentence-detokenized": "\"NeuralExpert focuses the design specifications on the type of problem the user would like the neural network to solve (classification, prediction, function approximation or cluster analysis).", "token2charspan": [[0, 1], [1, 13], [14, 21], [22, 25], [26, 32], [33, 47], [48, 50], [51, 54], [55, 59], [60, 62], [63, 70], [71, 74], [75, 79], [80, 85], [86, 90], [91, 94], [95, 101], [102, 109], [110, 112], [113, 118], [119, 120], [120, 134], [134, 135], [136, 146], [146, 147], [148, 156], [157, 170], [171, 173], [174, 181], [182, 190], [190, 191], [191, 192]]}
{"doc_key": "ai-test-130", "ner": [[2, 6, "misc"], [30, 33, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "size", "of", "the", "quantization", "step", "(", "\u0394", ")", "is", "small", "compared", "to", "the", "variation", "of", "the", "signal", "being", "quantized", ",", "it", "is", "relatively", "straightforward", "to", "show", "that", "the", "root", "mean", "square", "error", "resulting", "from", "such", "a", "rounding", "operation", "will", "be", "approximately", "equal", "to", "math\\", "Delta^2/12", "/math.math"], "sentence-detokenized": "When the size of the quantization step (\u0394) is small compared to the variation of the signal being quantized, it is relatively straightforward to show that the root mean square error resulting from such a rounding operation will be approximately equal to math\\Delta^2/12/math.math", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 20], [21, 33], [34, 38], [39, 40], [40, 41], [41, 42], [43, 45], [46, 51], [52, 60], [61, 63], [64, 67], [68, 77], [78, 80], [81, 84], [85, 91], [92, 97], [98, 107], [107, 108], [109, 111], [112, 114], [115, 125], [126, 141], [142, 144], [145, 149], [150, 154], [155, 158], [159, 163], [164, 168], [169, 175], [176, 181], [182, 191], [192, 196], [197, 201], [202, 203], [204, 212], [213, 222], [223, 227], [228, 230], [231, 244], [245, 250], [251, 253], [254, 259], [259, 269], [269, 279]]}
{"doc_key": "ai-test-131", "ner": [[16, 16, "product"], [26, 29, "researcher"], [31, 32, "researcher"], [34, 36, "researcher"], [38, 39, "researcher"], [41, 43, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Building", "a", "rich", "lexicon", "with", "the", "right", "ontology", "requires", "a", "lot", "of", "effort", ",", "e.g.", "the", "Wordnet", "lexicon", "took", "many", "man", "-", "years", "of", "effort", ".", "G.", "A", ".", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "Building a rich lexicon with the right ontology requires a lot of effort, e.g. the Wordnet lexicon took many man-years of effort. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 8], [9, 10], [11, 15], [16, 23], [24, 28], [29, 32], [33, 38], [39, 47], [48, 56], [57, 58], [59, 62], [63, 65], [66, 72], [72, 73], [74, 78], [79, 82], [83, 90], [91, 98], [99, 103], [104, 108], [109, 112], [112, 113], [113, 118], [119, 121], [122, 128], [128, 129], [130, 132], [133, 134], [134, 135], [136, 142], [142, 143], [144, 146], [147, 155], [155, 156], [157, 159], [160, 162], [163, 171], [171, 172], [173, 175], [176, 181], [181, 182], [183, 184], [184, 185], [186, 192], [192, 193]]}
{"doc_key": "ai-test-132", "ner": [[0, 2, "organisation"], [20, 21, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 21, 0, 2, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["\"", "Kawasaki", "'s", "portfolio", "also", "includes", "retractable", "roofs", ",", "floors", "and", "other", "giant", "structures", ";", "one", "such", "example", "is", "the", "Sapporo", "Dome", "retractable", "surface", "."], "sentence-detokenized": "\"Kawasaki's portfolio also includes retractable roofs, floors and other giant structures; one such example is the Sapporo Dome retractable surface.", "token2charspan": [[0, 1], [1, 9], [9, 11], [12, 21], [22, 26], [27, 35], [36, 47], [48, 53], [53, 54], [55, 61], [62, 65], [66, 71], [72, 77], [78, 88], [88, 89], [90, 93], [94, 98], [99, 106], [107, 109], [110, 113], [114, 121], [122, 126], [127, 138], [139, 146], [146, 147]]}
{"doc_key": "ai-test-133", "ner": [[0, 3, "metrics"], [5, 6, "metrics"], [8, 10, "metrics"], [16, 17, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 16, 17, "related-to", "", false, false], [0, 3, 39, 39, "opposite", "alternative_to", false, false], [5, 6, 0, 3, "type-of", "", false, false], [8, 10, 0, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa", "statistics", ",", "such", "as", "Fleiss", "kappa", "and", "Cohen", "'s", "kappa", ",", "are", "methods", "for", "calculating", "inter-rater", "reliability", "based", "on", "different", "assumptions", "about", "marginal", "or", "prior", "distributions", ",", "and", "are", "increasingly", "being", "used", "as", "alternatives", "to", "chance", "-", "corrected", "accuracy", "in", "other", "contexts", "."], "sentence-detokenized": "Kappa statistics, such as Fleiss kappa and Cohen's kappa, are methods for calculating inter-rater reliability based on different assumptions about marginal or prior distributions, and are increasingly being used as alternatives to chance-corrected accuracy in other contexts.", "token2charspan": [[0, 5], [6, 16], [16, 17], [18, 22], [23, 25], [26, 32], [33, 38], [39, 42], [43, 48], [48, 50], [51, 56], [56, 57], [58, 61], [62, 69], [70, 73], [74, 85], [86, 97], [98, 109], [110, 115], [116, 118], [119, 128], [129, 140], [141, 146], [147, 155], [156, 158], [159, 164], [165, 178], [178, 179], [180, 183], [184, 187], [188, 200], [201, 206], [207, 211], [212, 214], [215, 227], [228, 230], [231, 237], [237, 238], [238, 247], [248, 256], [257, 259], [260, 265], [266, 274], [274, 275]]}
{"doc_key": "ai-test-134", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [18, 18, "researcher"], [25, 27, "algorithm"], [29, 33, "algorithm"], [35, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 18, 18, "role", "student_of", false, false], [7, 8, 18, 18, "role", "student_of", false, false], [10, 11, 18, 18, "role", "student_of", false, false], [13, 14, 18, 18, "role", "student_of", false, false], [29, 33, 4, 5, "origin", "", false, false], [29, 33, 7, 8, "origin", "", false, false], [29, 33, 10, 11, "origin", "", false, false], [29, 33, 13, 14, "origin", "", false, false], [29, 33, 18, 18, "origin", "", false, false], [29, 33, 25, 27, "type-of", "", false, false], [35, 35, 29, 33, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Together", "with", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "and", "others", ",", "Schmidhuber", "published", "increasingly", "sophisticated", "versions", "of", "a", "recurrent", "neural", "network", "called", "Long", "Short", "-", "Term", "Memory", "(", "LSTM", ")", "."], "sentence-detokenized": "Together with his students Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves and others, Schmidhuber published increasingly sophisticated versions of a recurrent neural network called Long Short-Term Memory (LSTM).", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 26], [27, 31], [32, 42], [42, 43], [44, 49], [50, 54], [54, 55], [56, 60], [61, 68], [68, 69], [70, 74], [75, 81], [82, 85], [86, 92], [92, 93], [94, 105], [106, 115], [116, 128], [129, 142], [143, 151], [152, 154], [155, 156], [157, 166], [167, 173], [174, 181], [182, 188], [189, 193], [194, 199], [199, 200], [200, 204], [205, 211], [212, 213], [213, 217], [217, 218], [218, 219]]}
{"doc_key": "ai-test-135", "ner": [[4, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "The", "first", "Cobot", "KUKA", "LBR", "3", "is", "launched", "."], "sentence-detokenized": "2004 - The first Cobot KUKA LBR 3 is launched.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 22], [23, 27], [28, 31], [32, 33], [34, 36], [37, 45], [45, 46]]}
{"doc_key": "ai-test-136", "ner": [[12, 14, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "superficial", "methods", "used", "to", "train", "and", "then", "explain", "them", "are", "the", "Naive", "Bayes", "classifier", "and", "decision", "trees", "."], "sentence-detokenized": "Two superficial methods used to train and then explain them are the Naive Bayes classifier and decision trees.", "token2charspan": [[0, 3], [4, 15], [16, 23], [24, 28], [29, 31], [32, 37], [38, 41], [42, 46], [47, 54], [55, 59], [60, 63], [64, 67], [68, 73], [74, 79], [80, 90], [91, 94], [95, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-test-137", "ner": [[5, 5, "misc"], [12, 13, "person"], [15, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 12, 13, "origin", "", false, false], [5, 5, 15, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "practical", "forms", "of", "photography", "were", "introduced", "in", "January", "1839", "by", "Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "The first practical forms of photography were introduced in January 1839 by Louis Daguerre and Henry Fox Talbot.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 25], [26, 28], [29, 40], [41, 45], [46, 56], [57, 59], [60, 67], [68, 72], [73, 75], [76, 81], [82, 90], [91, 94], [95, 100], [101, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-138", "ner": [[3, 4, "task"], [7, 8, "task"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 15, 16, "part-of", "task_part_of_field", false, false], [7, 8, 15, 16, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "speech", "synthesis", "combined", "with", "speech", "recognition", "allows", "interaction", "with", "mobile", "devices", "through", "speech", "processing", "interfaces", "."], "sentence-detokenized": "For example, speech synthesis combined with speech recognition allows interaction with mobile devices through speech processing interfaces.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [30, 38], [39, 43], [44, 50], [51, 62], [63, 69], [70, 81], [82, 86], [87, 93], [94, 101], [102, 109], [110, 116], [117, 127], [128, 138], [138, 139]]}
{"doc_key": "ai-test-139", "ner": [[0, 1, "product"], [16, 16, "programlang"], [18, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 16, 16, "general-affiliation", "", false, false], [0, 1, 18, 19, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["\"", "Phidgets", "can", "be", "programmed", "using", "a", "wide", "range", "of", "software", "and", "programming", "languages", ",", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "\"Phidgets can be programmed using a wide range of software and programming languages, from Java to Microsoft Excel.", "token2charspan": [[0, 1], [1, 9], [10, 13], [14, 16], [17, 27], [28, 33], [34, 35], [36, 40], [41, 46], [47, 49], [50, 58], [59, 62], [63, 74], [75, 84], [84, 85], [86, 90], [91, 95], [96, 98], [99, 108], [109, 114], [114, 115]]}
{"doc_key": "ai-test-140", "ner": [[3, 4, "field"], [11, 12, "researcher"], [14, 19, "misc"], [22, 23, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 11, 12, "origin", "", false, false], [11, 12, 22, 23, "general-affiliation", "topic_of_study", false, false], [11, 12, 25, 26, "general-affiliation", "topic_of_study", false, false], [14, 19, 11, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "\"", "machine", "learning", "\"", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "an", "American", "IBM", "employee", "and", "a", "pioneer", "in", "computer", "games", "and", "artificial", "intelligence", "."], "sentence-detokenized": "The term \"machine learning\" was coined in 1959 by Arthur Samuel, an American IBM employee and a pioneer in computer games and artificial intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 17], [18, 26], [26, 27], [28, 31], [32, 38], [39, 41], [42, 46], [47, 49], [50, 56], [57, 63], [63, 64], [65, 67], [68, 76], [77, 80], [81, 89], [90, 93], [94, 95], [96, 103], [104, 106], [107, 115], [116, 121], [122, 125], [126, 136], [137, 149], [149, 150]]}
{"doc_key": "ai-test-141", "ner": [[0, 1, "misc"], [2, 3, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Israeli", "poet", "David", "Avidan", ",", "fascinated", "by", "future", "technologies", "and", "their", "relationship", "to", "art", ",", "wanted", "to", "explore", "the", "use", "of", "computers", "in", "writing", "literature", "."], "sentence-detokenized": "Israeli poet David Avidan, fascinated by future technologies and their relationship to art, wanted to explore the use of computers in writing literature.", "token2charspan": [[0, 7], [8, 12], [13, 18], [19, 25], [25, 26], [27, 37], [38, 40], [41, 47], [48, 60], [61, 64], [65, 70], [71, 83], [84, 86], [87, 90], [90, 91], [92, 98], [99, 101], [102, 109], [110, 113], [114, 117], [118, 120], [121, 130], [131, 133], [134, 141], [142, 152], [152, 153]]}
{"doc_key": "ai-test-142", "ner": [[7, 7, "misc"], [3, 10, "organisation"], [15, 18, "location"], [25, 26, "location"], [27, 28, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 10, 7, 7, "part-of", "", false, false], [27, 28, 25, 26, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "as", "part", "of", "the", "GATEway", "project", ",", "Oxbotica", "trialled", "seven", "autonomous", "shuttles", "in", "Greenwich", "along", "a", "two", "-", "mile", "river", "path", "near", "London", "'s", "O2", "arena", ",", "a", "route", "also", "used", "by", "pedestrians", "and", "cyclists", "."], "sentence-detokenized": "In 2017, as part of the GATEway project, Oxbotica trialled seven autonomous shuttles in Greenwich along a two-mile river path near London's O2 arena, a route also used by pedestrians and cyclists.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 16], [17, 19], [20, 23], [24, 31], [32, 39], [39, 40], [41, 49], [50, 58], [59, 64], [65, 75], [76, 84], [85, 87], [88, 97], [98, 103], [104, 105], [106, 109], [109, 110], [110, 114], [115, 120], [121, 125], [126, 130], [131, 137], [137, 139], [140, 142], [143, 148], [148, 149], [150, 151], [152, 157], [158, 162], [163, 167], [168, 170], [171, 182], [183, 186], [187, 195], [195, 196]]}
{"doc_key": "ai-test-143", "ner": [[8, 9, "task"], [13, 16, "metrics"], [22, 24, "misc"], [25, 25, "metrics"], [27, 27, "metrics"], [30, 30, "metrics"], [32, 32, "metrics"], [34, 37, "metrics"], [40, 40, "metrics"], [42, 42, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[13, 16, 22, 24, "related-to", "is_a", false, false], [13, 16, 25, 25, "usage", "", false, false], [13, 16, 27, 27, "usage", "", false, false], [25, 25, 30, 30, "named", "same", false, false], [27, 27, 42, 42, "named", "same", false, false], [30, 30, 40, 40, "opposite", "", false, false], [30, 30, 42, 42, "opposite", "", false, false], [32, 32, 30, 30, "named", "", false, false], [34, 37, 30, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["An", "unrelated", "but", "frequently", "used", "combination", "of", "key", "information", "retrieval", "statistics", "is", "the", "F-ratio", ",", "which", "is", "a", "(", "possibly", "weighted", ")", "harmonic", "average", "of", "recall", "and", "precision", ",", "where", "recall", "=", "sensitivity", "=", "actual", "number", "of", "hits", ",", "but", "specificity", "and", "precision", "are", "completely", "different", "indicators", "."], "sentence-detokenized": "An unrelated but frequently used combination of key information retrieval statistics is the F-ratio, which is a (possibly weighted) harmonic average of recall and precision, where recall = sensitivity = actual number of hits, but specificity and precision are completely different indicators.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 27], [28, 32], [33, 44], [45, 47], [48, 51], [52, 63], [64, 73], [74, 84], [85, 87], [88, 91], [92, 99], [99, 100], [101, 106], [107, 109], [110, 111], [112, 113], [113, 121], [122, 130], [130, 131], [132, 140], [141, 148], [149, 151], [152, 158], [159, 162], [163, 172], [172, 173], [174, 179], [180, 186], [187, 188], [189, 200], [201, 202], [203, 209], [210, 216], [217, 219], [220, 224], [224, 225], [226, 229], [230, 241], [242, 245], [246, 255], [256, 259], [260, 270], [271, 280], [281, 291], [291, 292]]}
{"doc_key": "ai-test-144", "ner": [[0, 2, "field"], [8, 8, "field"], [10, 10, "field"], [12, 12, "field"], [14, 15, "field"], [17, 18, "field"], [28, 29, "product"], [31, 34, "product"], [36, 37, "product"], [40, 43, "product"], [53, 59, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 8, 8, "origin", "takes_inspiration_from", false, false], [0, 2, 10, 10, "origin", "takes_inspiration_from", false, false], [0, 2, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 2, 14, 15, "origin", "takes_inspiration_from", false, false], [0, 2, 17, 18, "origin", "takes_inspiration_from", false, false], [28, 29, 0, 2, "origin", "", false, false], [31, 34, 0, 2, "origin", "", false, false], [36, 37, 0, 2, "origin", "", false, false], [40, 43, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "is", "an", "interdisciplinary", "field", "in", "which", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", "and", "electronic", "engineering", "are", "used", "to", "develop", "artificial", "nervous", "systems", "such", "as", "vision", "systems", ",", "head", "and", "eye", "systems", ",", "auditory", "processors", ",", "and", "autonomous", "robots", ",", "whose", "physical", "architecture", "and", "design", "principles", "are", "based", "on", "the", "architecture", "and", "principles", "of", "biological", "nervous", "systems", "."], "sentence-detokenized": "Neuromorphic engineering is an interdisciplinary field in which biology, physics, mathematics, computer science and electronic engineering are used to develop artificial nervous systems such as vision systems, head and eye systems, auditory processors, and autonomous robots, whose physical architecture and design principles are based on the architecture and principles of biological nervous systems.", "token2charspan": [[0, 12], [13, 24], [25, 27], [28, 30], [31, 48], [49, 54], [55, 57], [58, 63], [64, 71], [71, 72], [73, 80], [80, 81], [82, 93], [93, 94], [95, 103], [104, 111], [112, 115], [116, 126], [127, 138], [139, 142], [143, 147], [148, 150], [151, 158], [159, 169], [170, 177], [178, 185], [186, 190], [191, 193], [194, 200], [201, 208], [208, 209], [210, 214], [215, 218], [219, 222], [223, 230], [230, 231], [232, 240], [241, 251], [251, 252], [253, 256], [257, 267], [268, 274], [274, 275], [276, 281], [282, 290], [291, 303], [304, 307], [308, 314], [315, 325], [326, 329], [330, 335], [336, 338], [339, 342], [343, 355], [356, 359], [360, 370], [371, 373], [374, 384], [385, 392], [393, 400], [400, 401]]}
{"doc_key": "ai-test-145", "ner": [[3, 5, "metrics"], [9, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 9, 3, 5, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Specifically", ",", "the", "BIBO", "stability", "criterion", "requires", "that", "the", "ROC", "of", "the", "system", "covers", "a", "unit", "circle", "."], "sentence-detokenized": "Specifically, the BIBO stability criterion requires that the ROC of the system covers a unit circle.", "token2charspan": [[0, 12], [12, 13], [14, 17], [18, 22], [23, 32], [33, 42], [43, 51], [52, 56], [57, 60], [61, 64], [65, 67], [68, 71], [72, 78], [79, 85], [86, 87], [88, 92], [93, 99], [99, 100]]}
{"doc_key": "ai-test-146", "ner": [[10, 10, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "Since", "1998", ",", "the", "programme", "has", "been", "rewritten", "in", "Java", "."], "sentence-detokenized": "2 Since 1998, the programme has been rewritten in Java.", "token2charspan": [[0, 1], [2, 7], [8, 12], [12, 13], [14, 17], [18, 27], [28, 31], [32, 36], [37, 46], [47, 49], [50, 54], [54, 55]]}
{"doc_key": "ai-test-147", "ner": [[0, 1, "metrics"], [8, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 8, 11, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "MCC", "can", "be", "calculated", "directly", "from", "the", "confusion", "matrix", "using", "the", "formula", ":"], "sentence-detokenized": "The MCC can be calculated directly from the confusion matrix using the formula:", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 25], [26, 34], [35, 39], [40, 43], [44, 53], [54, 60], [61, 66], [67, 70], [71, 78], [78, 79]]}
{"doc_key": "ai-test-148", "ner": [[5, 12, "organisation"], [18, 22, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 12, 18, 22, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "developed", "by", "the", "Watson", "AI", "Lab", "team", "at", "MIT", "-", "IBM", "and", "first", "presented", "at", "the", "2018", "Learning", "Representations", "International", "Conference", "."], "sentence-detokenized": "It was developed by the Watson AI Lab team at MIT-IBM and first presented at the 2018 Learning Representations International Conference.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 23], [24, 30], [31, 33], [34, 37], [38, 42], [43, 45], [46, 49], [49, 50], [50, 53], [54, 57], [58, 63], [64, 73], [74, 76], [77, 80], [81, 85], [86, 94], [95, 110], [111, 124], [125, 135], [135, 136]]}
{"doc_key": "ai-test-149", "ner": [[2, 6, "metrics"], [15, 16, "metrics"], [18, 22, "metrics"], [47, 47, "metrics"], [49, 49, "metrics"], [54, 58, "metrics"], [60, 60, "metrics"], [62, 62, "metrics"], [65, 67, "metrics"], [72, 72, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[15, 16, 47, 47, "type-of", "", false, false], [15, 16, 54, 58, "related-to", "collapses_to_identity", false, false], [18, 22, 49, 49, "type-of", "", false, false], [18, 22, 54, 58, "related-to", "collapses_to_identity", false, false], [18, 22, 65, 67, "named", "same", false, false], [60, 60, 72, 72, "related-to", "collapses_to_identity", false, false], [62, 62, 72, 72, "related-to", "collapses_to_identity", false, false], [65, 67, 72, 72, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["When", "the", "prevalence", "of", "two", "positive", "TRUE", "variables", "is", "the", "same", ",", "as", "assumed", "by", "Fleiss", "kappa", "and", "F", "-", "score", ",", "i.e.", "the", "number", "of", "positive", "predictions", "coincides", "with", "the", "number", "of", "positive", "classes", "in", "the", "dichotomous", "(", "two", "-", "class", ")", "case", ",", "the", "different", "kappa", "and", "correlation", "measures", "coincide", "with", "the", "Youden", "'s", "J", ",", "and", "the", "recall", ",", "precision", ",", "and", "F", "-", "score", "similarly", "agree", "with", "the", "accuracy", "."], "sentence-detokenized": "When the prevalence of two positive TRUE variables is the same, as assumed by Fleiss kappa and F-score, i.e. the number of positive predictions coincides with the number of positive classes in the dichotomous (two-class) case, the different kappa and correlation measures coincide with the Youden's J, and the recall, precision, and F-score similarly agree with the accuracy.", "token2charspan": [[0, 4], [5, 8], [9, 19], [20, 22], [23, 26], [27, 35], [36, 40], [41, 50], [51, 53], [54, 57], [58, 62], [62, 63], [64, 66], [67, 74], [75, 77], [78, 84], [85, 90], [91, 94], [95, 96], [96, 97], [97, 102], [102, 103], [104, 108], [109, 112], [113, 119], [120, 122], [123, 131], [132, 143], [144, 153], [154, 158], [159, 162], [163, 169], [170, 172], [173, 181], [182, 189], [190, 192], [193, 196], [197, 208], [209, 210], [210, 213], [213, 214], [214, 219], [219, 220], [221, 225], [225, 226], [227, 230], [231, 240], [241, 246], [247, 250], [251, 262], [263, 271], [272, 280], [281, 285], [286, 289], [290, 296], [296, 298], [299, 300], [300, 301], [302, 305], [306, 309], [310, 316], [316, 317], [318, 327], [327, 328], [329, 332], [333, 334], [334, 335], [335, 340], [341, 350], [351, 356], [357, 361], [362, 365], [366, 374], [374, 375]]}
{"doc_key": "ai-test-150", "ner": [[11, 17, "misc"], [15, 15, "misc"], [10, 10, "conference"], [2, 18, "task"], [19, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 17, 10, 10, "part-of", "", false, false], [11, 17, 10, 10, "physical", "", false, false], [11, 17, 10, 10, "temporal", "", false, false], [15, 15, 11, 17, "named", "", false, false], [2, 18, 11, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "first", "NLI", "Joint", "Exercise", "was", "held", "at", "the", "2013", "NAACL", "Building", "Educational", "Applications", "(", "BEA", ")", "Workshop", ".", "Tetreault", "et", "al", ",", "2013", "29", "teams", "from", "all", "over", "the", "world", "took", "part", "in", "the", "competition", ",", "24", "of", "which", "also", "published", "a", "paper", "describing", "their", "systems", "and", "methods", "."], "sentence-detokenized": "The first NLI Joint Exercise was held at the 2013 NAACL Building Educational Applications (BEA) Workshop. Tetreault et al, 2013 29 teams from all over the world took part in the competition, 24 of which also published a paper describing their systems and methods.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 19], [20, 28], [29, 32], [33, 37], [38, 40], [41, 44], [45, 49], [50, 55], [56, 64], [65, 76], [77, 89], [90, 91], [91, 94], [94, 95], [96, 104], [104, 105], [106, 115], [116, 118], [119, 121], [121, 122], [123, 127], [128, 130], [131, 136], [137, 141], [142, 145], [146, 150], [151, 154], [155, 160], [161, 165], [166, 170], [171, 173], [174, 177], [178, 189], [189, 190], [191, 193], [194, 196], [197, 202], [203, 207], [208, 217], [218, 219], [220, 225], [226, 236], [237, 242], [243, 250], [251, 254], [255, 262], [262, 263]]}
{"doc_key": "ai-test-151", "ner": [[0, 2, "algorithm"], [5, 8, "algorithm"], [15, 16, "misc"], [20, 23, "misc"], [36, 37, "misc"], [40, 41, "algorithm"], [44, 44, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 5, 8, "type-of", "", false, false], [0, 2, 15, 16, "related-to", "finds", false, false], [20, 23, 15, 16, "type-of", "", false, false], [44, 44, 40, 41, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Viterbi", "algorithm", "is", "a", "dynamic", "programming", "algorithm", "for", "finding", "the", "most", "likely", "sequence", "of", "hidden", "states", ",", "called", "the", "Viterbi", "path", ",", "that", "determines", "the", "sequence", "of", "observed", "events", ",", "especially", "in", "the", "context", "of", "Markov", "information", "sources", "and", "Hidden", "Markov", "Models", "(", "HMMs", ")", "."], "sentence-detokenized": "The Viterbi algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states, called the Viterbi path, that determines the sequence of observed events, especially in the context of Markov information sources and Hidden Markov Models (HMMs).", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 24], [25, 26], [27, 34], [35, 46], [47, 56], [57, 60], [61, 68], [69, 72], [73, 77], [78, 84], [85, 93], [94, 96], [97, 103], [104, 110], [110, 111], [112, 118], [119, 122], [123, 130], [131, 135], [135, 136], [137, 141], [142, 152], [153, 156], [157, 165], [166, 168], [169, 177], [178, 184], [184, 185], [186, 196], [197, 199], [200, 203], [204, 211], [212, 214], [215, 221], [222, 233], [234, 241], [242, 245], [246, 252], [253, 259], [260, 266], [267, 268], [268, 272], [272, 273], [273, 274]]}
{"doc_key": "ai-test-152", "ner": [[0, 1, "field"], [3, 5, "algorithm"], [8, 10, "misc"], [12, 13, "algorithm"], [15, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 0, 1, "part-of", "", false, false], [3, 5, 8, 10, "general-affiliation", "", false, false], [3, 5, 12, 13, "related-to", "generalizes_from", false, false], [3, 5, 15, 18, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "polynomial", "logistic", "regression", "is", "a", "classification", "method", "that", "generalises", "logistic", "regression", "for", "multiclass", "classification", ",", "i.e.", "when", "there", "are", "more", "than", "two", "possible", "discrete", "outcomes", "."], "sentence-detokenized": "In statistics, polynomial logistic regression is a classification method that generalises logistic regression for multiclass classification, i.e. when there are more than two possible discrete outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 25], [26, 34], [35, 45], [46, 48], [49, 50], [51, 65], [66, 72], [73, 77], [78, 89], [90, 98], [99, 109], [110, 113], [114, 124], [125, 139], [139, 140], [141, 145], [146, 150], [151, 156], [157, 160], [161, 165], [166, 170], [171, 174], [175, 183], [184, 192], [193, 201], [201, 202]]}
{"doc_key": "ai-test-153", "ner": [[0, 2, "algorithm"], [10, 10, "field"], [12, 16, "field"], [17, 17, "task"], [18, 21, "task"], [23, 24, "task"], [26, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 10, 10, "part-of", "", false, false], [0, 2, 12, 16, "part-of", "", false, false], [17, 17, 0, 2, "usage", "", true, false], [18, 21, 0, 2, "usage", "", true, false], [23, 24, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden", "Markov", "models", "are", "known", "for", "their", "application", "in", "reinforcement", "learning", "and", "temporal", "pattern", "recognition", ",", "e.g.", "speech", "recognition", ",", "handwriting", "recognition", ",", "gesture", "recognition", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov models are known for their application in reinforcement learning and temporal pattern recognition, e.g. speech recognition, handwriting recognition, gesture recognition, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 30], [31, 34], [35, 40], [41, 52], [53, 55], [56, 69], [70, 78], [79, 82], [83, 91], [92, 99], [100, 111], [111, 112], [113, 117], [118, 124], [125, 136], [136, 137], [138, 149], [150, 161], [161, 162], [163, 170], [171, 182], [182, 183], [184, 188], [189, 196], [196, 197], [198, 202], [203, 211], [211, 212]]}
{"doc_key": "ai-test-154", "ner": [[7, 8, "misc"], [33, 35, "metrics"], [23, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 23, 27, "named", "", false, false], [33, 35, 23, 27, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "principle", ",", "this", "means", "that", "if", "a", "word", "has", "been", "seen", "more", "than", "k", "times", "during", "training", ",", "the", "conditional", "probability", "of", "the", "word", "given", "it", "s", "history", "is", "proportional", "to", "the", "maximum", "likelihood", "estimate", "."], "sentence-detokenized": "In principle, this means that if a word has been seen more than k times during training, the conditional probability of the word given its history is proportional to the maximum likelihood estimate.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 18], [19, 24], [25, 29], [30, 32], [33, 34], [35, 39], [40, 43], [44, 48], [49, 53], [54, 58], [59, 63], [64, 65], [66, 71], [72, 78], [79, 87], [87, 88], [89, 92], [93, 104], [105, 116], [117, 119], [120, 123], [124, 128], [129, 134], [135, 137], [137, 138], [139, 146], [147, 149], [150, 162], [163, 165], [166, 169], [170, 177], [178, 188], [189, 197], [197, 198]]}
{"doc_key": "ai-test-155", "ner": [[4, 5, "task"], [7, 9, "task"], [11, 15, "task"], [18, 22, "task"], [29, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[29, 30, 18, 22, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "knowledge", "representation", ",", "common", "sense", "reasoning", "and", "natural", "language", "understanding", "because", "he", "believes", "that", "a", "deep", "understanding", "of", "language", "can", "currently", "only", "be", "achieved", "by", "manually", "creating", "semantically", "rich", "formalisms", "and", "applying", "statistical", "preferences", "."], "sentence-detokenized": "He is interested in knowledge representation, common sense reasoning and natural language understanding because he believes that a deep understanding of language can currently only be achieved by manually creating semantically rich formalisms and applying statistical preferences.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 29], [30, 44], [44, 45], [46, 52], [53, 58], [59, 68], [69, 72], [73, 80], [81, 89], [90, 103], [104, 111], [112, 114], [115, 123], [124, 128], [129, 130], [131, 135], [136, 149], [150, 152], [153, 161], [162, 165], [166, 175], [176, 180], [181, 183], [184, 192], [193, 195], [196, 204], [205, 213], [214, 226], [227, 231], [232, 242], [243, 246], [247, 255], [256, 267], [268, 279], [279, 280]]}
{"doc_key": "ai-test-156", "ner": [[0, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["\"", "JavaScript", ",", "Python", "or"], "sentence-detokenized": "\"JavaScript, Python or", "token2charspan": [[0, 1], [1, 11], [11, 12], [13, 19], [20, 22]]}
{"doc_key": "ai-test-157", "ner": [[0, 2, "misc"], [6, 7, "misc"], [11, 11, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 7, "part-of", "", false, false], [6, 7, 11, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "Awards", "are", "published", "in", "AI", "Magazine", ",", "published", "by", "AAAI", "."], "sentence-detokenized": "The Newcomb Awards are published in AI Magazine, published by AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 32], [33, 35], [36, 38], [39, 47], [47, 48], [49, 58], [59, 61], [62, 66], [66, 67]]}
{"doc_key": "ai-test-158", "ner": [[0, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "root", "mean", "square", "error", "in", "a", "test", "set", "of", "100", "samples", "is", "0.084", ",", "i.e.", "less", "than", "the", "unnormalised", "error", "."], "sentence-detokenized": "The root mean square error in a test set of 100 samples is 0.084, i.e. less than the unnormalised error.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 20], [21, 26], [27, 29], [30, 31], [32, 36], [37, 40], [41, 43], [44, 47], [48, 55], [56, 58], [59, 64], [64, 65], [66, 70], [71, 75], [76, 80], [81, 84], [85, 97], [98, 103], [103, 104]]}
{"doc_key": "ai-test-159", "ner": [[0, 4, "metrics"], [9, 11, "field"], [17, 19, "task"], [21, 21, "task"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 11, 0, 4, "usage", "", false, false], [17, 19, 9, 11, "part-of", "task_part_of_field", false, false], [21, 21, 17, 19, "named", "", false, false], [24, 25, 9, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "F", "-", "score", "is", "widely", "used", "in", "the", "natural", "language", "processing", "literature", ",", "for", "example", "in", "Named", "Entity", "Recognition", "(", "NER", ")", "and", "word", "segmentation", "."], "sentence-detokenized": "The F-score is widely used in the natural language processing literature, for example in Named Entity Recognition (NER) and word segmentation.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 21], [22, 26], [27, 29], [30, 33], [34, 41], [42, 50], [51, 61], [62, 72], [72, 73], [74, 77], [78, 85], [86, 88], [89, 94], [95, 101], [102, 113], [114, 115], [115, 118], [118, 119], [120, 123], [124, 128], [129, 141], [141, 142]]}
{"doc_key": "ai-test-160", "ner": [[0, 1, "product"], [5, 6, "product"], [17, 18, "misc"], [20, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 17, 18, "related-to", "performs_task", false, false], [0, 1, 20, 21, "related-to", "performs_task", false, false], [5, 6, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "typically", "used", "in", "dialogue", "systems", "for", "a", "variety", "of", "purposes", ",", "including", "customer", "service", ",", "routing", "queries", "or", "collecting", "information", "."], "sentence-detokenized": "Chatbots are typically used in dialogue systems for a variety of purposes, including customer service, routing queries or collecting information.", "token2charspan": [[0, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 39], [40, 47], [48, 51], [52, 53], [54, 61], [62, 64], [65, 73], [73, 74], [75, 84], [85, 93], [94, 101], [101, 102], [103, 110], [111, 118], [119, 121], [122, 132], [133, 144], [144, 145]]}
{"doc_key": "ai-test-161", "ner": [[3, 9, "conference"], [13, 23, "conference"], [28, 38, "conference"], [45, 45, "conference"], [49, 52, "conference"], [54, 55, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 23, 3, 9, "named", "", false, false], [28, 38, 3, 9, "named", "", false, false], [45, 45, 28, 38, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Important", "journals", "include", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "later", "renamed", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", ",", "and", "since", "September", "2014", "renamed", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", ",", "following", "the", "merger", "with", "the", "ACM", "Journal", ")", ",", "Computer", "Speech", "and", "Language", "and", "Speech", "Communication", "."], "sentence-detokenized": "Important journals include IEEE Transactions on Speech and Audio Processing (later renamed IEEE Transactions on Audio, Speech and Language Processing, and since September 2014 renamed IEEE/ACM Transactions on Audio, Speech and Language Processing, following the merger with the ACM Journal), Computer Speech and Language and Speech Communication.", "token2charspan": [[0, 9], [10, 18], [19, 26], [27, 31], [32, 44], [45, 47], [48, 54], [55, 58], [59, 64], [65, 75], [76, 77], [77, 82], [83, 90], [91, 95], [96, 108], [109, 111], [112, 117], [117, 118], [119, 125], [126, 129], [130, 138], [139, 149], [149, 150], [151, 154], [155, 160], [161, 170], [171, 175], [176, 183], [184, 188], [188, 189], [189, 192], [193, 205], [206, 208], [209, 214], [214, 215], [216, 222], [223, 226], [227, 235], [236, 246], [246, 247], [248, 257], [258, 261], [262, 268], [269, 273], [274, 277], [278, 281], [282, 289], [289, 290], [290, 291], [292, 300], [301, 307], [308, 311], [312, 320], [321, 324], [325, 331], [332, 345], [345, 346]]}
{"doc_key": "ai-test-162", "ner": [[0, 1, "algorithm"], [5, 6, "task"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 0, 1, "usage", "", false, false], [5, 6, 8, 9, "part-of", "task_part_of_field", false, false], [5, 6, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "is", "often", "used", "for", "data", "clustering", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "EM is often used for data clustering in machine learning and computer vision.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 20], [21, 25], [26, 36], [37, 39], [40, 47], [48, 56], [57, 60], [61, 69], [70, 76], [76, 77]]}
{"doc_key": "ai-test-163", "ner": [[9, 11, "metrics"], [25, 27, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 25, 27, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["While", "there", "is", "no", "perfect", "way", "to", "describe", "the", "confusion", "matrix", "of", "positive", "and", "negative", "statements", "and", "negative", "results", "in", "a", "single", "number", ",", "the", "Mathews", "correlation", "coefficient", "is", "generally", "considered", "to", "be", "one", "of", "the", "best", "such", "indicators", "."], "sentence-detokenized": "While there is no perfect way to describe the confusion matrix of positive and negative statements and negative results in a single number, the Mathews correlation coefficient is generally considered to be one of the best such indicators.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 17], [18, 25], [26, 29], [30, 32], [33, 41], [42, 45], [46, 55], [56, 62], [63, 65], [66, 74], [75, 78], [79, 87], [88, 98], [99, 102], [103, 111], [112, 119], [120, 122], [123, 124], [125, 131], [132, 138], [138, 139], [140, 143], [144, 151], [152, 163], [164, 175], [176, 178], [179, 188], [189, 199], [200, 202], [203, 205], [206, 209], [210, 212], [213, 216], [217, 221], [222, 226], [227, 237], [237, 238]]}
{"doc_key": "ai-test-164", "ner": [[14, 16, "field"], [29, 31, "field"], [38, 39, "field"], [43, 44, "algorithm"], [46, 47, "task"], [49, 50, "algorithm"], [55, 58, "algorithm"], [60, 61, "algorithm"], [67, 70, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[38, 39, 29, 31, "part-of", "subfield", false, false], [43, 44, 38, 39, "part-of", "", false, true], [46, 47, 38, 39, "part-of", "", false, true], [49, 50, 38, 39, "part-of", "", false, true], [55, 58, 38, 39, "part-of", "", false, true], [60, 61, 38, 39, "part-of", "", false, true], [67, 70, 38, 39, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "the", "size", "and", "complexity", "of", "datasets", "increased", ",", "direct", ",", "hands", "-", "on", "data", "analysis", "was", "complemented", "by", "indirect", ",", "automated", "data", "processing", ",", "aided", "by", "other", "advances", "in", "computer", "science", ",", "especially", "in", "the", "field", "of", "machine", "learning", ",", "such", "as", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "decision", "-", "tree", "learning", "and", "decision", "rules", "(", "1960s", ")", ",", "and", "support", "-", "vector", "machines", "(", "1990", "s", ")", "."], "sentence-detokenized": "As the size and complexity of datasets increased, direct, hands-on data analysis was complemented by indirect, automated data processing, aided by other advances in computer science, especially in the field of machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision-tree learning and decision rules (1960s), and support-vector machines (1990s).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 15], [16, 26], [27, 29], [30, 38], [39, 48], [48, 49], [50, 56], [56, 57], [58, 63], [63, 64], [64, 66], [67, 71], [72, 80], [81, 84], [85, 97], [98, 100], [101, 109], [109, 110], [111, 120], [121, 125], [126, 136], [136, 137], [138, 143], [144, 146], [147, 152], [153, 161], [162, 164], [165, 173], [174, 181], [181, 182], [183, 193], [194, 196], [197, 200], [201, 206], [207, 209], [210, 217], [218, 226], [226, 227], [228, 232], [233, 235], [236, 242], [243, 251], [251, 252], [253, 260], [261, 269], [269, 270], [271, 278], [279, 289], [290, 291], [291, 296], [296, 297], [297, 298], [299, 307], [307, 308], [308, 312], [313, 321], [322, 325], [326, 334], [335, 340], [341, 342], [342, 347], [347, 348], [348, 349], [350, 353], [354, 361], [361, 362], [362, 368], [369, 377], [378, 379], [379, 383], [383, 384], [384, 385], [385, 386]]}
{"doc_key": "ai-test-165", "ner": [[4, 4, "researcher"], [23, 24, "misc"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 24, 4, 4, "artifact", "", false, false], [23, 24, 13, 14, "artifact", "", false, false], [23, 24, 16, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "autumn", "2005", ",", "Thrun", ",", "together", "with", "his", "long", "-", "time", "collaborators", "Dieter", "Fox", "and", "Wolfram", "Burgard", ",", "published", "the", "textbook", "\"", "Probabilistic", "Robotics", "\"", "."], "sentence-detokenized": "In autumn 2005, Thrun, together with his long-time collaborators Dieter Fox and Wolfram Burgard, published the textbook \"Probabilistic Robotics\".", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 21], [21, 22], [23, 31], [32, 36], [37, 40], [41, 45], [45, 46], [46, 50], [51, 64], [65, 71], [72, 75], [76, 79], [80, 87], [88, 95], [95, 96], [97, 106], [107, 110], [111, 119], [120, 121], [121, 134], [135, 143], [143, 144], [144, 145]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereiramath", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereiramath:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 49], [49, 50]]}
{"doc_key": "ai-test-167", "ner": [[0, 1, "task"], [3, 5, "task"], [7, 8, "field"], [14, 15, "field"], [17, 19, "field"], [21, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 17, 19, "part-of", "task_part_of_field", false, false], [3, 5, 0, 1, "named", "", false, false], [14, 15, 7, 8, "part-of", "subfield", false, false], [17, 19, 7, 8, "part-of", "subfield", false, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Question", "Answering", "(", "QA", ")", "is", "a", "computer", "science", "discipline", "in", "the", "fields", "of", "information", "retrieval", "and", "natural", "language", "processing", "(", "NLP", ")", ",", "which", "is", "concerned", "with", "the", "development", "of", "systems", "that", "automatically", "answer", "questions", "asked", "by", "people", "in", "natural", "language", "."], "sentence-detokenized": "Question Answering (QA) is a computer science discipline in the fields of information retrieval and natural language processing (NLP), which is concerned with the development of systems that automatically answer questions asked by people in natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 37], [38, 45], [46, 56], [57, 59], [60, 63], [64, 70], [71, 73], [74, 85], [86, 95], [96, 99], [100, 107], [108, 116], [117, 127], [128, 129], [129, 132], [132, 133], [133, 134], [135, 140], [141, 143], [144, 153], [154, 158], [159, 162], [163, 174], [175, 177], [178, 185], [186, 190], [191, 204], [205, 211], [212, 221], [222, 227], [228, 230], [231, 237], [238, 240], [241, 248], [249, 257], [257, 258]]}
{"doc_key": "ai-test-168", "ner": [[9, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "the", "version", "of", "the", "metric", "used", "in", "NIST", "assessments", "until", "2009", "used", "the", "shortest", "reference", "sentence", "instead", "."], "sentence-detokenized": "However, the version of the metric used in NIST assessments until 2009 used the shortest reference sentence instead.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 20], [21, 23], [24, 27], [28, 34], [35, 39], [40, 42], [43, 47], [48, 59], [60, 65], [66, 70], [71, 75], [76, 79], [80, 88], [89, 98], [99, 107], [108, 115], [115, 116]]}
{"doc_key": "ai-test-169", "ner": [[4, 4, "person"], [12, 12, "organisation"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 13, 13, "related-to", "invests_in", false, false], [13, 13, 12, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["27", "August", "2018", "\"", "Toyota", "announces", "a", "$", "500", "million", "investment", "in", "Uber", "autonomous", "cars", "."], "sentence-detokenized": "27 August 2018 \"Toyota announces a $500 million investment in Uber autonomous cars.", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 16], [16, 22], [23, 32], [33, 34], [35, 36], [36, 39], [40, 47], [48, 58], [59, 61], [62, 66], [67, 77], [78, 82], [82, 83]]}
{"doc_key": "ai-test-170", "ner": [[6, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sample", "maximum", "is", "the", "highest", "expected", "estimate", "of", "the", "population", "maximum", ",", "but", ",", "as", "discussed", "above", ",", "it", "is", "biased", "."], "sentence-detokenized": "The sample maximum is the highest expected estimate of the population maximum, but, as discussed above, it is biased.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 25], [26, 33], [34, 42], [43, 51], [52, 54], [55, 58], [59, 69], [70, 77], [77, 78], [79, 82], [82, 83], [84, 86], [87, 96], [97, 102], [102, 103], [104, 106], [107, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [3, 4, "misc"], [6, 12, "metrics"], [17, 19, "algorithm"], [21, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 4, "related-to", "overcomes", false, false], [0, 0, 6, 12, "related-to", "increases", false, false], [3, 4, 17, 19, "opposite", "", false, false], [3, 4, 21, 23, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "helps", "overcome", "synonymy", "by", "increasing", "recall", ",", "which", "is", "one", "of", "the", "most", "problematic", "limitations", "of", "logical", "keyword", "queries", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI helps overcome synonymy by increasing recall, which is one of the most problematic limitations of logical keyword queries and vector space models.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 27], [28, 30], [31, 41], [42, 48], [48, 49], [50, 55], [56, 58], [59, 62], [63, 65], [66, 69], [70, 74], [75, 86], [87, 98], [99, 101], [102, 109], [110, 117], [118, 125], [126, 129], [130, 136], [137, 142], [143, 149], [149, 150]]}
{"doc_key": "ai-test-172", "ner": [[0, 1, "task"], [18, 18, "programlang"], [20, 20, "programlang"], [22, 22, "programlang"], [24, 25, "programlang"], [27, 27, "programlang"], [29, 29, "programlang"], [31, 31, "programlang"], [33, 33, "programlang"], [35, 35, "programlang"], [37, 37, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 18, 18, "general-affiliation", "", false, false], [0, 1, 20, 20, "general-affiliation", "", false, false], [0, 1, 22, 22, "general-affiliation", "", false, false], [0, 1, 24, 25, "general-affiliation", "", false, false], [0, 1, 27, 27, "general-affiliation", "", false, false], [0, 1, 29, 29, "general-affiliation", "", false, false], [0, 1, 31, 31, "general-affiliation", "", false, false], [0, 1, 33, 33, "general-affiliation", "", false, false], [0, 1, 35, 35, "general-affiliation", "", false, false], [0, 1, 37, 37, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Data", "acquisition", "applications", "are", "typically", "controlled", "by", "programs", "developed", "using", "various", "general", "-", "purpose", "programming", "languages", "such", "as", "Assembler", ",", "BASIC", ",", "C", ",", "C", "++", ",", "C#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "Data acquisition applications are typically controlled by programs developed using various general-purpose programming languages such as Assembler, BASIC, C, C++, C#, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 4], [5, 16], [17, 29], [30, 33], [34, 43], [44, 54], [55, 57], [58, 66], [67, 76], [77, 82], [83, 90], [91, 98], [98, 99], [99, 106], [107, 118], [119, 128], [129, 133], [134, 136], [137, 146], [146, 147], [148, 153], [153, 154], [155, 156], [156, 157], [158, 159], [159, 161], [161, 162], [163, 165], [165, 166], [167, 174], [174, 175], [176, 180], [180, 181], [182, 189], [189, 190], [191, 195], [195, 196], [197, 203], [203, 204], [205, 209]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [8, 10, "product"], [11, 11, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 3, 3, "artifact", "", false, false], [8, 10, 11, 11, "physical", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2003", ",", "Honda", "launched", "advertising", "for", "the", "Cog", "in", "the", "UK", "and", "online", "."], "sentence-detokenized": "In 2003, Honda launched advertising for the Cog in the UK and online.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 35], [36, 39], [40, 43], [44, 47], [48, 50], [51, 54], [55, 57], [58, 61], [62, 68], [68, 69]]}
{"doc_key": "ai-test-174", "ner": [[0, 4, "conference"], [6, 7, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 6, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Association", "for", "Computational", "Linguistics", "defines", "computational", "linguistics", "as", ":"], "sentence-detokenized": "The Association for Computational Linguistics defines computational linguistics as:", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 45], [46, 53], [54, 67], [68, 79], [80, 82], [82, 83]]}
{"doc_key": "ai-test-175", "ner": [[0, 4, "algorithm"], [16, 20, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 16, 20, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Expectation", "maximisation", "algorithms", "used", "in", "minimum", "-variance", "filters", "and", "equalisers", "can", "be", "used", "to", "estimate", "the", "maximum", "likelihood", "estimates", "of", "the", "unknown", "state", "space", "parameters", "."], "sentence-detokenized": "Expectation maximisation algorithms used in minimum-variance filters and equalisers can be used to estimate the maximum likelihood estimates of the unknown state space parameters.", "token2charspan": [[0, 11], [12, 24], [25, 35], [36, 40], [41, 43], [44, 51], [51, 60], [61, 68], [69, 72], [73, 83], [84, 87], [88, 90], [91, 95], [96, 98], [99, 107], [108, 111], [112, 119], [120, 130], [131, 140], [141, 143], [144, 147], [148, 155], [156, 161], [162, 167], [168, 178], [178, 179]]}
{"doc_key": "ai-test-176", "ner": [[4, 4, "misc"], [6, 8, "person"], [10, 11, "person"], [13, 14, "person"], [17, 18, "misc"], [19, 20, "person"], [23, 24, "person"], [28, 28, "person"], [30, 31, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 8, 4, 4, "role", "actor_in", false, false], [10, 11, 4, 4, "role", "actor_in", false, false], [13, 14, 4, 4, "role", "actor_in", false, false], [19, 20, 17, 18, "role", "model_for", false, false], [28, 28, 30, 31, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "correspondents", "included", "former", "Baywatch", "actresses", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "and", "Traci", "Bingham", ",", "former", "Playboy", "beauty", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", "and", "identical", "twins", "Randy", "and", "Jason", "Sklar", "."], "sentence-detokenized": "The correspondents included former Baywatch actresses Donna D'Errico, Carmen Electra and Traci Bingham, former Playboy beauty Heidi Mark, comedian Arj Barker and identical twins Randy and Jason Sklar.", "token2charspan": [[0, 3], [4, 18], [19, 27], [28, 34], [35, 43], [44, 53], [54, 59], [60, 62], [62, 68], [68, 69], [70, 76], [77, 84], [85, 88], [89, 94], [95, 102], [102, 103], [104, 110], [111, 118], [119, 125], [126, 131], [132, 136], [136, 137], [138, 146], [147, 150], [151, 157], [158, 161], [162, 171], [172, 177], [178, 183], [184, 187], [188, 193], [194, 199], [199, 200]]}
{"doc_key": "ai-test-177", "ner": [[8, 9, "task"], [11, 11, "task"], [16, 19, "product"], [22, 23, "task"], [25, 28, "task"], [31, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [16, 19, 8, 9, "general-affiliation", "", false, false], [25, 28, 22, 23, "named", "", false, false], [31, 32, 22, 23, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "is", "typically", "used", "to", "generate", "representations", "for", "speech", "recognition", "(", "ASR", ")", ",", "e.g.", "in", "CMU", "'s", "Sphinx", "system", ",", "and", "speech", "synthesis", "(", "TTS", ")", ",", "e.g.", "in", "the", "Festival", "system", "."], "sentence-detokenized": "It is typically used to generate representations for speech recognition (ASR), e.g. in CMU's Sphinx system, and speech synthesis (TTS), e.g. in the Festival system.", "token2charspan": [[0, 2], [3, 5], [6, 15], [16, 20], [21, 23], [24, 32], [33, 48], [49, 52], [53, 59], [60, 71], [72, 73], [73, 76], [76, 77], [77, 78], [79, 83], [84, 86], [87, 90], [90, 92], [93, 99], [100, 106], [106, 107], [108, 111], [112, 118], [119, 128], [129, 130], [130, 133], [133, 134], [134, 135], [136, 140], [141, 143], [144, 147], [148, 156], [157, 163], [163, 164]]}
{"doc_key": "ai-test-178", "ner": [[0, 0, "metrics"], [2, 4, "metrics"], [6, 9, "metrics"], [12, 12, "metrics"], [24, 25, "metrics"], [27, 27, "metrics"], [41, 42, "metrics"], [44, 44, "metrics"], [46, 48, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 4, 0, 0, "named", "", false, false], [6, 9, 2, 4, "named", "", false, false], [12, 12, 0, 0, "named", "", false, false], [27, 27, 24, 25, "named", "", false, false], [44, 44, 41, 42, "named", "", false, false], [46, 48, 41, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sensitivity", "or", "TRUE", "Positive", "Rate", "(", "TPR", ")", ",", "also", "known", "as", "recall", ",", "is", "the", "proportion", "of", "people", "who", "have", "tested", "positive", "(", "TRUE", "Positive", ",", "TP", ")", "out", "of", "the", "total", "number", "of", "people", "who", "are", "actually", "positive", "(", "Condition", "Positive", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "Sensitivity or TRUE Positive Rate (TPR), also known as recall, is the proportion of people who have tested positive (TRUE Positive, TP) out of the total number of people who are actually positive (Condition Positive, CP = TP + FN).", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 28], [29, 33], [34, 35], [35, 38], [38, 39], [39, 40], [41, 45], [46, 51], [52, 54], [55, 61], [61, 62], [63, 65], [66, 69], [70, 80], [81, 83], [84, 90], [91, 94], [95, 99], [100, 106], [107, 115], [116, 117], [117, 121], [122, 130], [130, 131], [132, 134], [134, 135], [136, 139], [140, 142], [143, 146], [147, 152], [153, 159], [160, 162], [163, 169], [170, 173], [174, 177], [178, 186], [187, 195], [196, 197], [197, 206], [207, 215], [215, 216], [217, 219], [220, 221], [222, 224], [225, 226], [227, 229], [229, 230], [230, 231]]}
{"doc_key": "ai-test-179", "ner": [[3, 4, "task"], [12, 12, "conference"], [14, 15, "conference"], [17, 17, "conference"], [19, 21, "conference"], [23, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6], "relations": [[12, 12, 3, 4, "topic", "", false, false], [14, 15, 3, 4, "topic", "", false, false], [17, 17, 3, 4, "topic", "", false, false], [19, 21, 3, 4, "topic", "", false, false], [23, 24, 3, 4, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5], "sentence": ["The", "most", "popular", "speech", "recognition", "conferences", "held", "every", "year", "or", "two", "are", "SpeechTEK", "and", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "and", "IEEE", "ASRU", "."], "sentence-detokenized": "The most popular speech recognition conferences held every year or two are SpeechTEK and SpeechTEK Europe, ICASSP, Interspeech/Eurospeech and IEEE ASRU.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 23], [24, 35], [36, 47], [48, 52], [53, 58], [59, 63], [64, 66], [67, 70], [71, 74], [75, 84], [85, 88], [89, 98], [99, 105], [105, 106], [107, 113], [113, 114], [115, 126], [126, 127], [127, 137], [138, 141], [142, 146], [147, 151], [151, 152]]}
{"doc_key": "ai-test-180", "ner": [[0, 1, "researcher"], [4, 7, "researcher"], [18, 20, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 0, 1, "artifact", "", false, false], [22, 22, 4, 7, "artifact", "", false, false], [22, 22, 18, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["\"", "Devol", "worked", "with", "Engelberger", ",", "who", "was", "the", "company", "'s", "president", ",", "to", "design", "and", "manufacture", "an", "industrial", "robot", "under", "the", "Unimate", "brand", "."], "sentence-detokenized": "\"Devol worked with Engelberger, who was the company's president, to design and manufacture an industrial robot under the Unimate brand.", "token2charspan": [[0, 1], [1, 6], [7, 13], [14, 18], [19, 30], [30, 31], [32, 35], [36, 39], [40, 43], [44, 51], [51, 53], [54, 63], [63, 64], [65, 67], [68, 74], [75, 78], [79, 90], [91, 93], [94, 104], [105, 110], [111, 116], [117, 120], [121, 128], [129, 134], [134, 135]]}
{"doc_key": "ai-test-181", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [9, 15, "algorithm"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 9, 15, "general-affiliation", "", false, false], [5, 5, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "Hidden", "Markov", "Model", "(", "HMM", ")", "is", "a", "statistical", "Markov", "model", "that", "assumes", "that", "the", "modelled", "system", "is", "a", "Markov", "process", "with", "unobserved", "(", "hidden", ")", "states", "."], "sentence-detokenized": "A Hidden Markov Model (HMM) is a statistical Markov model that assumes that the modelled system is a Markov process with unobserved (hidden) states.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [22, 23], [23, 26], [26, 27], [28, 30], [31, 32], [33, 44], [45, 51], [52, 57], [58, 62], [63, 70], [71, 75], [76, 79], [80, 88], [89, 95], [96, 98], [99, 100], [101, 107], [108, 115], [116, 120], [121, 131], [132, 133], [133, 139], [139, 140], [141, 147], [147, 148]]}
{"doc_key": "ai-test-182", "ner": [[17, 19, "metrics"], [21, 21, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "characteristic", ",", "undesirable", "in", "many", "cases", ",", "has", "led", "researchers", "to", "use", "alternative", "methods", "such", "as", "mean", "absolute", "error", "or", "median", "."], "sentence-detokenized": "This characteristic, undesirable in many cases, has led researchers to use alternative methods such as mean absolute error or median.", "token2charspan": [[0, 4], [5, 19], [19, 20], [21, 32], [33, 35], [36, 40], [41, 46], [46, 47], [48, 51], [52, 55], [56, 67], [68, 70], [71, 74], [75, 86], [87, 94], [95, 99], [100, 102], [103, 107], [108, 116], [117, 122], [123, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-test-183", "ner": [[19, 20, "algorithm"], [28, 29, "field"], [31, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 20, 28, 29, "part-of", "", false, false], [19, 20, 31, 33, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "sequence", "(", "which", "depends", "on", "the", "results", "of", "previous", "feature", "testing", "at", "each", "stage", ")", "is", "called", "a", "decision", "tree", "and", "is", "applied", "in", "a", "field", "of", "machine", "learning", "called", "decision", "tree", "learning", "."], "sentence-detokenized": "This sequence (which depends on the results of previous feature testing at each stage) is called a decision tree and is applied in a field of machine learning called decision tree learning.", "token2charspan": [[0, 4], [5, 13], [14, 15], [15, 20], [21, 28], [29, 31], [32, 35], [36, 43], [44, 46], [47, 55], [56, 63], [64, 71], [72, 74], [75, 79], [80, 85], [85, 86], [87, 89], [90, 96], [97, 98], [99, 107], [108, 112], [113, 116], [117, 119], [120, 127], [128, 130], [131, 132], [133, 138], [139, 141], [142, 149], [150, 158], [159, 165], [166, 174], [175, 179], [180, 188], [188, 189]]}
{"doc_key": "ai-test-184", "ner": [[2, 3, "task"], [5, 5, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 5, 5, "compare", "", false, false], [19, 20, 5, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "with", "factor", "analysis", ",", "LCA", "can", "also", "be", "used", "to", "classify", "cases", "according", "to", "their", "membership", "of", "the", "maximum", "likelihood", "class", "."], "sentence-detokenized": "As with factor analysis, LCA can also be used to classify cases according to their membership of the maximum likelihood class.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 23], [23, 24], [25, 28], [29, 32], [33, 37], [38, 40], [41, 45], [46, 48], [49, 57], [58, 63], [64, 73], [74, 76], [77, 82], [83, 93], [94, 96], [97, 100], [101, 108], [109, 119], [120, 125], [125, 126]]}
{"doc_key": "ai-test-185", "ner": [[0, 3, "algorithm"], [5, 7, "metrics"], [9, 9, "metrics"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 5, 7, "usage", "", false, false], [5, 7, 11, 12, "related-to", "", false, false], [9, 9, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Supervised", "neural", "networks", "using", "the", "mean", "square", "error", "(", "MSE", ")", "cost", "function", "can", "use", "formal", "statistical", "methods", "to", "determine", "the", "reliability", "of", "the", "trained", "model", "."], "sentence-detokenized": "Supervised neural networks using the mean square error (MSE) cost function can use formal statistical methods to determine the reliability of the trained model.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 32], [33, 36], [37, 41], [42, 48], [49, 54], [55, 56], [56, 59], [59, 60], [61, 65], [66, 74], [75, 78], [79, 82], [83, 89], [90, 101], [102, 109], [110, 112], [113, 122], [123, 126], [127, 138], [139, 141], [142, 145], [146, 153], [154, 159], [159, 160]]}
{"doc_key": "ai-test-186", "ner": [[16, 19, "algorithm"], [20, 22, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 19, 20, 22, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "expressed", "directly", "as", "a", "linear", "program", ",", "but", "it", "is", "also", "equivalent", "to", "Tikhonov", "regulation", "with", "a", "hinge", "loss", "function", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "This can be expressed directly as a linear program, but it is also equivalent to Tikhonov regulation with a hinge loss function, mathV (f (x), y) = max (0, 1 - yf (x)) / math:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 21], [22, 30], [31, 33], [34, 35], [36, 42], [43, 50], [50, 51], [52, 55], [56, 58], [59, 61], [62, 66], [67, 77], [78, 80], [81, 89], [90, 100], [101, 105], [106, 107], [108, 113], [114, 118], [119, 127], [127, 128], [129, 134], [135, 136], [136, 137], [138, 139], [139, 140], [140, 141], [141, 142], [143, 144], [144, 145], [146, 147], [148, 151], [152, 153], [153, 154], [154, 155], [156, 157], [158, 159], [160, 162], [163, 164], [164, 165], [165, 166], [166, 167], [168, 169], [170, 174], [174, 175]]}
{"doc_key": "ai-test-187", "ner": [[5, 6, "researcher"], [12, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "method", "was", "described", "in", "Breiman", "'s", "original", "paper", "and", "implemented", "in", "the", "R", "package", "randomForest", "."], "sentence-detokenized": "This method was described in Breiman's original paper and implemented in the R package randomForest.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 25], [26, 28], [29, 36], [36, 38], [39, 47], [48, 53], [54, 57], [58, 69], [70, 72], [73, 76], [77, 78], [79, 86], [87, 99], [99, 100]]}
{"doc_key": "ai-test-188", "ner": [[7, 9, "metrics"], [36, 38, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "image", "quality", "indicators", ",", "such", "as", "PSNR", ",", "are", "usually", "applied", "to", "fixed", "resolution", "images", "and", "do", "not", "take", "into", "account", "some", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "changes", "in", "spatial", "resolution", "in", "the", "retina", "."], "sentence-detokenized": "Traditional image quality indicators, such as PSNR, are usually applied to fixed resolution images and do not take into account some aspects of the human visual system, such as changes in spatial resolution in the retina.", "token2charspan": [[0, 11], [12, 17], [18, 25], [26, 36], [36, 37], [38, 42], [43, 45], [46, 50], [50, 51], [52, 55], [56, 63], [64, 71], [72, 74], [75, 80], [81, 91], [92, 98], [99, 102], [103, 105], [106, 109], [110, 114], [115, 119], [120, 127], [128, 132], [133, 140], [141, 143], [144, 147], [148, 153], [154, 160], [161, 167], [167, 168], [169, 173], [174, 176], [177, 184], [185, 187], [188, 195], [196, 206], [207, 209], [210, 213], [214, 220], [220, 221]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [10, 12, "person"], [16, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 20, "role", "", false, false], [3, 4, 16, 20, "role", "", false, false], [6, 7, 16, 20, "role", "", false, false], [16, 20, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "and", "Macdonald", "Carey", "starred", "in", "Jack", "Broder", "'s", "colour", "film", "\"", "Hannah", "Lee", "\"", ",", "which", "premiered", "on", "19", "June", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru and Macdonald Carey starred in Jack Broder's colour film \"Hannah Lee\", which premiered on 19 June 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 55], [56, 60], [61, 67], [67, 69], [70, 76], [77, 81], [82, 83], [83, 89], [90, 93], [93, 94], [94, 95], [96, 101], [102, 111], [112, 114], [115, 117], [118, 122], [123, 127], [127, 128]]}
{"doc_key": "ai-test-190", "ner": [[4, 5, "task"], [11, 12, "field"], [17, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 11, 12, "usage", "", false, false], [17, 17, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "process", "is", "called", "image", "registration", "and", "uses", "a", "variety", "of", "computer", "vision", "techniques", ",", "usually", "involving", "tracking", "."], "sentence-detokenized": "This process is called image registration and uses a variety of computer vision techniques, usually involving tracking.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 22], [23, 28], [29, 41], [42, 45], [46, 50], [51, 52], [53, 60], [61, 63], [64, 72], [73, 79], [80, 90], [90, 91], [92, 99], [100, 109], [110, 118], [118, 119]]}
{"doc_key": "ai-test-191", "ner": [[17, 19, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Now", "let", "'s", "start", "to", "explore", "the", "various", "possible", "relationships", "between", "the", "predicted", "and", "actual", "outcome", ":", "The", "confusion", "matrix"], "sentence-detokenized": "Now let's start to explore the various possible relationships between the predicted and actual outcome: The confusion matrix", "token2charspan": [[0, 3], [4, 7], [7, 9], [10, 15], [16, 18], [19, 26], [27, 30], [31, 38], [39, 47], [48, 61], [62, 69], [70, 73], [74, 83], [84, 87], [88, 94], [95, 102], [102, 103], [104, 107], [108, 117], [118, 124]]}
{"doc_key": "ai-test-192", "ner": [[0, 1, "product"], [2, 4, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 2, 4, "part-of", "", false, false], [0, 1, 2, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "VOICEBOX", "language", "processing", "toolbox", "for", "MATLAB", "converts", "and", "performs", "inverse", "conversions", "like", ":"], "sentence-detokenized": "The VOICEBOX language processing toolbox for MATLAB converts and performs inverse conversions like:", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 32], [33, 40], [41, 44], [45, 51], [52, 60], [61, 64], [65, 73], [74, 81], [82, 93], [94, 98], [98, 99]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "general-affiliation", "", false, false], [0, 0, 11, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logic", "programming", "language", "related", "to", "artificial", "intelligence", "and", "computational", "linguistics", "."], "sentence-detokenized": "Prolog is a logic programming language related to artificial intelligence and computational linguistics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 17], [18, 29], [30, 38], [39, 46], [47, 49], [50, 60], [61, 73], [74, 77], [78, 91], [92, 103], [103, 104]]}
{"doc_key": "ai-test-194", "ner": [[0, 1, "researcher"], [9, 9, "field"], [11, 11, "field"], [17, 20, "organisation"], [23, 28, "organisation"], [32, 36, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 9, 9, "related-to", "works_with_topic", false, false], [0, 1, 11, 11, "related-to", "works_with_topic", false, false], [0, 1, 17, 20, "role", "", false, false], [0, 1, 23, 28, "role", "", false, false], [0, 1, 32, 36, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "numerous", "awards", "for", "her", "contributions", "to", "neurobiology", "and", "psychology", ",", "including", "Fellow", "of", "the", "Royal", "Society", "of", "London", ",", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "and", "Fellow", "of", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received numerous awards for her contributions to neurobiology and psychology, including Fellow of the Royal Society of London, Fellow of the Royal Society of Canada and Fellow of the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 35], [36, 39], [40, 43], [44, 57], [58, 60], [61, 73], [74, 77], [78, 88], [88, 89], [90, 99], [100, 106], [107, 109], [110, 113], [114, 119], [120, 127], [128, 130], [131, 137], [137, 138], [139, 145], [146, 148], [149, 152], [153, 158], [159, 166], [167, 169], [170, 176], [177, 180], [181, 187], [188, 190], [191, 194], [195, 203], [204, 211], [212, 214], [215, 223], [223, 224]]}
{"doc_key": "ai-test-195", "ner": [[8, 9, "field"], [14, 15, "task"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 15, 8, 9, "part-of", "task_part_of_field", false, false], [17, 18, 8, 9, "part-of", "task_part_of_field", false, false], [20, 21, 8, 9, "part-of", "task_part_of_field", false, false], [23, 24, 8, 9, "part-of", "task_part_of_field", false, false], [26, 26, 8, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Combining", "these", "operators", "can", "yield", "algorithms", "for", "many", "image", "processing", "tasks", ",", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "sharpening", ",", "image", "filtering", "and", "classification", "."], "sentence-detokenized": "Combining these operators can yield algorithms for many image processing tasks, such as feature extraction, image segmentation, image sharpening, image filtering and classification.", "token2charspan": [[0, 9], [10, 15], [16, 25], [26, 29], [30, 35], [36, 46], [47, 50], [51, 55], [56, 61], [62, 72], [73, 78], [78, 79], [80, 84], [85, 87], [88, 95], [96, 106], [106, 107], [108, 113], [114, 126], [126, 127], [128, 133], [134, 144], [144, 145], [146, 151], [152, 161], [162, 165], [166, 180], [180, 181]]}
{"doc_key": "ai-test-196", "ner": [[7, 9, "university"], [15, 16, "organisation"], [18, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 19, 15, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "has", "been", "a", "professor", "at", "the", "College", "de", "France", "since", "2017", "and", "Director", "of", "INSERM", "562", "\"", "Cognitive", "Neuroimaging", "\"", "since", "1989", "."], "sentence-detokenized": "He has been a professor at the College de France since 2017 and Director of INSERM 562 \"Cognitive Neuroimaging\" since 1989.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 13], [14, 23], [24, 26], [27, 30], [31, 38], [39, 41], [42, 48], [49, 54], [55, 59], [60, 63], [64, 72], [73, 75], [76, 82], [83, 86], [87, 88], [88, 97], [98, 110], [110, 111], [112, 117], [118, 122], [122, 123]]}
{"doc_key": "ai-test-197", "ner": [[12, 14, "algorithm"], [16, 21, "algorithm"], [24, 24, "algorithm"], [26, 33, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[24, 24, 26, 33, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "many", "approaches", "to", "learning", "these", "embeddings", ",", "in", "particular", "using", "Bayesian", "clustering", "systems", "or", "energy", "-", "based", "systems", ",", "and", "more", "recently", "TransE", "(", "2013", "conference", "on", "\"", "Neural", "Information", "Processing", "Systems", "\"", ")", "."], "sentence-detokenized": "There are many approaches to learning these embeddings, in particular using Bayesian clustering systems or energy-based systems, and more recently TransE (2013 conference on \"Neural Information Processing Systems\").", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 25], [26, 28], [29, 37], [38, 43], [44, 54], [54, 55], [56, 58], [59, 69], [70, 75], [76, 84], [85, 95], [96, 103], [104, 106], [107, 113], [113, 114], [114, 119], [120, 127], [127, 128], [129, 132], [133, 137], [138, 146], [147, 153], [154, 155], [155, 159], [160, 170], [171, 173], [174, 175], [175, 181], [182, 193], [194, 204], [205, 212], [212, 213], [213, 214], [214, 215]]}
{"doc_key": "ai-test-198", "ner": [[6, 10, "metrics"], [7, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 15, 6, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "an", "alternative", "to", "the", "Word", "Error", "Rate", "(", "WER", ")", "used", "in", "several", "countries", "."], "sentence-detokenized": "This is an alternative to the Word Error Rate (WER) used in several countries.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 25], [26, 29], [30, 34], [35, 40], [41, 45], [46, 47], [47, 50], [50, 51], [52, 56], [57, 59], [60, 67], [68, 77], [77, 78]]}
{"doc_key": "ai-test-199", "ner": [[0, 0, "algorithm"], [11, 12, "task"], [14, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 27, "task"], [29, 30, "task"], [45, 45, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 0, 0, "usage", "", false, false], [14, 15, 0, 0, "usage", "", false, false], [17, 18, 0, 0, "usage", "", false, false], [20, 22, 0, 0, "usage", "", false, false], [24, 27, 0, 0, "usage", "", false, false], [29, 30, 0, 0, "usage", "", false, false], [45, 45, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "are", "used", "for", "a", "wide", "range", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "board", "and", "video", "games", ",", "medical", "diagnostics", "and", "even", "activities", "that", "have", "traditionally", "been", "considered", "reserved", "for", "humans", ",", "such", "as", "painting", "."], "sentence-detokenized": "ANNs are used for a wide range of tasks, including computer vision, speech recognition, machine translation, social network filtering, board and video games, medical diagnostics and even activities that have traditionally been considered reserved for humans, such as painting.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 17], [18, 19], [20, 24], [25, 30], [31, 33], [34, 39], [39, 40], [41, 50], [51, 59], [60, 66], [66, 67], [68, 74], [75, 86], [86, 87], [88, 95], [96, 107], [107, 108], [109, 115], [116, 123], [124, 133], [133, 134], [135, 140], [141, 144], [145, 150], [151, 156], [156, 157], [158, 165], [166, 177], [178, 181], [182, 186], [187, 197], [198, 202], [203, 207], [208, 221], [222, 226], [227, 237], [238, 246], [247, 250], [251, 257], [257, 258], [259, 263], [264, 266], [267, 275], [275, 276]]}
{"doc_key": "ai-test-200", "ner": [[0, 4, "product"], [6, 6, "product"], [27, 29, "field"], [31, 31, "field"], [36, 36, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 27, 29, "related-to", "", false, false], [0, 4, 36, 36, "general-affiliation", "", false, false], [6, 6, 0, 4, "named", "", false, false], [31, 31, 27, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "is", "an", "open", "-", "source", "research", "platform", "and", "a", "collection", "of", "voice", ",", "audio", ",", "speech", ",", "text", "and", "natural", "language", "processing", "(", "NLP", ")", "algorithms", "written", "in", "Java", "and", "structured", "in", "a", "modular", "and", "extensible", "framework", "to", "facilitate", "the", "inclusion", "of", "new", "algorithms", "."], "sentence-detokenized": "The Modular Audio Recognition Framework (MARF) is an open-source research platform and a collection of voice, audio, speech, text and natural language processing (NLP) algorithms written in Java and structured in a modular and extensible framework to facilitate the inclusion of new algorithms.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 29], [30, 39], [40, 41], [41, 45], [45, 46], [47, 49], [50, 52], [53, 57], [57, 58], [58, 64], [65, 73], [74, 82], [83, 86], [87, 88], [89, 99], [100, 102], [103, 108], [108, 109], [110, 115], [115, 116], [117, 123], [123, 124], [125, 129], [130, 133], [134, 141], [142, 150], [151, 161], [162, 163], [163, 166], [166, 167], [168, 178], [179, 186], [187, 189], [190, 194], [195, 198], [199, 209], [210, 212], [213, 214], [215, 222], [223, 226], [227, 237], [238, 247], [248, 250], [251, 261], [262, 265], [266, 275], [276, 278], [279, 282], [283, 293], [293, 294]]}
{"doc_key": "ai-test-201", "ner": [[4, 6, "organisation"], [18, 18, "country"], [22, 24, "organisation"], [27, 28, "organisation"], [32, 33, "task"], [52, 54, "organisation"], [49, 51, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[22, 24, 18, 18, "physical", "", false, false], [22, 24, 32, 33, "usage", "", false, false], [22, 24, 52, 54, "named", "", false, false], [27, 28, 18, 18, "physical", "", false, false], [27, 28, 32, 33, "usage", "", false, false], [52, 54, 49, 51, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["A", "2018", "report", "by", "Big", "Brother", "Watch", ",", "a", "civil", "liberties", "and", "rights", "organisation", ",", "revealed", "that", "two", "UK", "police", "forces", "-", "South", "Wales", "Police", "and", "the", "Metropolitan", "Police", "-", "used", "instant", "facial", "recognition", "at", "public", "events", "and", "in", "public", "spaces", ".", "In", "September", "2019", ",", "the", "use", "of", "facial", "recognition", "by", "South", "Wales", "Police", "was", "declared", "legal", "."], "sentence-detokenized": "A 2018 report by Big Brother Watch, a civil liberties and rights organisation, revealed that two UK police forces - South Wales Police and the Metropolitan Police - used instant facial recognition at public events and in public spaces. In September 2019, the use of facial recognition by South Wales Police was declared legal.", "token2charspan": [[0, 1], [2, 6], [7, 13], [14, 16], [17, 20], [21, 28], [29, 34], [34, 35], [36, 37], [38, 43], [44, 53], [54, 57], [58, 64], [65, 77], [77, 78], [79, 87], [88, 92], [93, 96], [97, 99], [100, 106], [107, 113], [114, 115], [116, 121], [122, 127], [128, 134], [135, 138], [139, 142], [143, 155], [156, 162], [163, 164], [165, 169], [170, 177], [178, 184], [185, 196], [197, 199], [200, 206], [207, 213], [214, 217], [218, 220], [221, 227], [228, 234], [234, 235], [236, 238], [239, 248], [249, 253], [253, 254], [255, 258], [259, 262], [263, 265], [266, 272], [273, 284], [285, 287], [288, 293], [294, 299], [300, 306], [307, 310], [311, 319], [320, 325], [325, 326]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [5, 7, "programlang"], [10, 11, "field"], [13, 13, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 7, "general-affiliation", "", false, false], [0, 0, 10, 11, "related-to", "", false, false], [0, 0, 13, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "has", "been", "ported", "to", "R", ",", "a", "freely", "available", "statistical", "computing", "and", "graphics", "language", "and", "environment", "."], "sentence-detokenized": "ANIMAL has been ported to R, a freely available statistical computing and graphics language and environment.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [23, 25], [26, 27], [27, 28], [29, 30], [31, 37], [38, 47], [48, 59], [60, 69], [70, 73], [74, 82], [83, 91], [92, 95], [96, 107], [107, 108]]}
{"doc_key": "ai-test-203", "ner": [[0, 6, "algorithm"], [8, 10, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [23, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 17, 19, "opposite", "alternative to", false, false], [8, 10, 0, 6, "named", "", false, false], [21, 21, 17, 19, "named", "", false, false], [23, 26, 0, 6, "usage", "", false, false], [23, 26, 17, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "time", "-", "inhomogeneous", "hidden", "Bernoulli", "model", "(", "TI", "-", "HBM", ")", "is", "an", "alternative", "to", "the", "hidden", "Markov", "model", "(", "HMM", ")", "for", "automatic", "speech", "recognition", "."], "sentence-detokenized": "The time-inhomogeneous hidden Bernoulli model (TI-HBM) is an alternative to the hidden Markov model (HMM) for automatic speech recognition.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 22], [23, 29], [30, 39], [40, 45], [46, 47], [47, 49], [49, 50], [50, 53], [53, 54], [55, 57], [58, 60], [61, 72], [73, 75], [76, 79], [80, 86], [87, 93], [94, 99], [100, 101], [101, 104], [104, 105], [106, 109], [110, 119], [120, 126], [127, 138], [138, 139]]}
{"doc_key": "ai-test-204", "ner": [[4, 4, "organisation"], [7, 8, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 7, 8, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "Nvidia", "demonstrated", "at", "SIGGRAPH", "a", "new", "highlight", "rendering", "method", "that", "is", "said", "to", "be", "invisible", "to", "users", "."], "sentence-detokenized": "In July 2016, Nvidia demonstrated at SIGGRAPH a new highlight rendering method that is said to be invisible to users.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 33], [34, 36], [37, 45], [46, 47], [48, 51], [52, 61], [62, 71], [72, 78], [79, 83], [84, 86], [87, 91], [92, 94], [95, 97], [98, 107], [108, 110], [111, 116], [116, 117]]}
{"doc_key": "ai-test-205", "ner": [[4, 9, "misc"], [11, 16, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 9, 11, 16, "origin", "", false, false], [4, 9, 19, 20, "origin", "", false, false], [4, 9, 22, 25, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Both", "are", "based", "on", "the", "theory", "of", "speech", "acts", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "refined", "by", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both are based on the theory of speech acts developed by John Searle in the 1960s and refined by Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 17], [18, 21], [22, 28], [29, 31], [32, 38], [39, 43], [44, 53], [54, 56], [57, 61], [62, 68], [69, 71], [72, 75], [76, 81], [82, 85], [86, 93], [94, 96], [97, 102], [103, 111], [112, 115], [116, 122], [123, 125], [126, 129], [130, 135], [135, 136]]}
{"doc_key": "ai-test-206", "ner": [[0, 3, "algorithm"], [20, 22, "researcher"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 20, 22, "related-to", "", false, false], [23, 23, 20, 22, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "knowledge", "structure", "have", "led", "to", "powerful", "hierarchical", "models", "of", "knowledge", "organisation", "such", "as", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "Neural network models of concept formation and knowledge structure have led to powerful hierarchical models of knowledge organisation such as George Miller's Wordnet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 56], [57, 66], [67, 71], [72, 75], [76, 78], [79, 87], [88, 100], [101, 107], [108, 110], [111, 120], [121, 133], [134, 138], [139, 141], [142, 148], [149, 155], [155, 157], [158, 165], [165, 166]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [15, 16, "field"], [19, 21, "product"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 15, 16, "part-of", "", false, false], [0, 1, 24, 26, "part-of", "", false, false], [19, 21, 15, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Pattern", "matching", "has", "a", "wide", "range", "of", "applications", "and", "is", "used", "in", "areas", "such", "as", "facial", "recognition", "(", "see", "facial", "recognition", "system", ")", "and", "medical", "image", "processing", "."], "sentence-detokenized": "Pattern matching has a wide range of applications and is used in areas such as facial recognition (see facial recognition system) and medical image processing.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 22], [23, 27], [28, 33], [34, 36], [37, 49], [50, 53], [54, 56], [57, 61], [62, 64], [65, 70], [71, 75], [76, 78], [79, 85], [86, 97], [98, 99], [99, 102], [103, 109], [110, 121], [122, 128], [128, 129], [130, 133], [134, 141], [142, 147], [148, 158], [158, 159]]}
{"doc_key": "ai-test-208", "ner": [[15, 16, "researcher"], [18, 20, "researcher"], [21, 30, "organisation"], [32, 32, "organisation"], [39, 40, "algorithm"], [41, 48, "conference"], [50, 50, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 16, 21, 30, "role", "", false, false], [15, 16, 41, 48, "physical", "", false, false], [15, 16, 41, 48, "temporal", "", false, false], [15, 16, 50, 50, "physical", "", false, false], [18, 20, 21, 30, "role", "", false, false], [18, 20, 41, 48, "temporal", "", false, false], [32, 32, 21, 30, "named", "", false, false], [41, 48, 39, 40, "topic", "", false, false], [50, 50, 41, 48, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "it", "was", "not", "until", "2005", "that", "it", "became", "widely", "used", ",", "when", "researchers", "Navneet", "Dalal", "and", "Bill", "Triggs", "of", "the", "French", "National", "Research", "Institute", "for", "Computer", "Science", "and", "Automation", "(", "INRIA", ")", "presented", "their", "complementary", "work", "on", "HOG", "descriptors", "at", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "Conference", "(", "CVPR", ")", "."], "sentence-detokenized": "However, it was not until 2005 that it became widely used, when researchers Navneet Dalal and Bill Triggs of the French National Research Institute for Computer Science and Automation (INRIA) presented their complementary work on HOG descriptors at the Computer Vision and Pattern Recognition Conference (CVPR).", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 15], [16, 19], [20, 25], [26, 30], [31, 35], [36, 38], [39, 45], [46, 52], [53, 57], [57, 58], [59, 63], [64, 75], [76, 83], [84, 89], [90, 93], [94, 98], [99, 105], [106, 108], [109, 112], [113, 119], [120, 128], [129, 137], [138, 147], [148, 151], [152, 160], [161, 168], [169, 172], [173, 183], [184, 185], [185, 190], [190, 191], [192, 201], [202, 207], [208, 221], [222, 226], [227, 229], [230, 233], [234, 245], [246, 248], [249, 252], [253, 261], [262, 268], [269, 272], [273, 280], [281, 292], [293, 303], [304, 305], [305, 309], [309, 310], [310, 311]]}
{"doc_key": "ai-test-209", "ner": [[3, 3, "university"], [17, 24, "organisation"], [21, 22, "organisation"], [27, 28, "field"], [32, 34, "researcher"], [36, 39, "researcher"], [42, 44, "researcher"], [48, 51, "organisation"], [54, 56, "organisation"], [62, 63, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[21, 22, 27, 28, "related-to", "", false, false], [32, 34, 21, 22, "physical", "", false, false], [32, 34, 21, 22, "role", "", false, false], [36, 39, 21, 22, "physical", "", false, false], [36, 39, 21, 22, "role", "", false, false], [42, 44, 21, 22, "physical", "", false, false], [42, 44, 21, 22, "role", "", false, false], [62, 63, 54, 56, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Before", "joining", "the", "Penn", "faculty", "in", "2002", ",", "he", "worked", "for", "a", "decade", "(", "1991-2001", ")", "at", "AT", "&T", "Labs", "and", "Bell", "Labs", ",", "and", "led", "the", "Artificial", "Intelligence", "Division", "with", "colleagues", "Michael", "L.", "Littman", ",", "David", "A", ".", "McAllester", ",", "and", "Richard", "S.", "Sutton", ",", "and", "the", "Secure", "Systems", "Research", "Division", "and", "the", "Machine", "Learning", "Division", "(", "with", "members", "such", "as", "Michael", "Collins", "and", "the", "Head", ")", "."], "sentence-detokenized": "Before joining the Penn faculty in 2002, he worked for a decade (1991-2001) at AT&T Labs and Bell Labs, and led the Artificial Intelligence Division with colleagues Michael L. Littman, David A. McAllester, and Richard S. Sutton, and the Secure Systems Research Division and the Machine Learning Division (with members such as Michael Collins and the Head).", "token2charspan": [[0, 6], [7, 14], [15, 18], [19, 23], [24, 31], [32, 34], [35, 39], [39, 40], [41, 43], [44, 50], [51, 54], [55, 56], [57, 63], [64, 65], [65, 74], [74, 75], [76, 78], [79, 81], [81, 83], [84, 88], [89, 92], [93, 97], [98, 102], [102, 103], [104, 107], [108, 111], [112, 115], [116, 126], [127, 139], [140, 148], [149, 153], [154, 164], [165, 172], [173, 175], [176, 183], [183, 184], [185, 190], [191, 192], [192, 193], [194, 204], [204, 205], [206, 209], [210, 217], [218, 220], [221, 227], [227, 228], [229, 232], [233, 236], [237, 243], [244, 251], [252, 260], [261, 269], [270, 273], [274, 277], [278, 285], [286, 294], [295, 303], [304, 305], [305, 309], [310, 317], [318, 322], [323, 325], [326, 333], [334, 341], [342, 345], [346, 349], [350, 354], [354, 355], [355, 356]]}
{"doc_key": "ai-test-210", "ner": [[6, 7, "field"], [14, 15, "field"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 14, 15, "compare", "", false, false], [26, 27, 14, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["When", "the", "data", "is", "unlabelled", ",", "supervised", "learning", "is", "not", "possible", ",", "so", "an", "unsupervised", "learning", "approach", "is", "needed", ",", "which", "attempts", "to", "find", "a", "natural", "cluster", "analysis", "into", "groups", ",", "and", "then", "assigns", "the", "new", "data", "to", "these", "formed", "groups", "."], "sentence-detokenized": "When the data is unlabelled, supervised learning is not possible, so an unsupervised learning approach is needed, which attempts to find a natural cluster analysis into groups, and then assigns the new data to these formed groups.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 27], [27, 28], [29, 39], [40, 48], [49, 51], [52, 55], [56, 64], [64, 65], [66, 68], [69, 71], [72, 84], [85, 93], [94, 102], [103, 105], [106, 112], [112, 113], [114, 119], [120, 128], [129, 131], [132, 136], [137, 138], [139, 146], [147, 154], [155, 163], [164, 168], [169, 175], [175, 176], [177, 180], [181, 185], [186, 193], [194, 197], [198, 201], [202, 206], [207, 209], [210, 215], [216, 222], [223, 229], [229, 230]]}
{"doc_key": "ai-test-211", "ner": [[3, 4, "field"], [14, 20, "organisation"], [25, 26, "field"], [28, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 14, 20, "origin", "", false, false], [3, 4, 25, 26, "part-of", "", false, false], [3, 4, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "field", "of", "computer", "science", "developed", "in", "the", "1950s", "at", "academic", "institutions", "such", "as", "MIT", "'s", "A.I", ".", "Lab", ",", "initially", "as", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "This field of computer science developed in the 1950s at academic institutions such as MIT's A.I. Lab, initially as a branch of artificial intelligence and robotics.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 30], [31, 40], [41, 43], [44, 47], [48, 53], [54, 56], [57, 65], [66, 78], [79, 83], [84, 86], [87, 90], [90, 92], [93, 96], [96, 97], [98, 101], [101, 102], [103, 112], [113, 115], [116, 117], [118, 124], [125, 127], [128, 138], [139, 151], [152, 155], [156, 164], [164, 165]]}
{"doc_key": "ai-test-212", "ner": [[8, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "can", "also", "be", "replaced", "by", "the", "following", "Log", "loss", "equation", ":"], "sentence-detokenized": "It can also be replaced by the following Log loss equation:", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 23], [24, 26], [27, 30], [31, 40], [41, 44], [45, 49], [50, 58], [58, 59]]}
{"doc_key": "ai-test-213", "ner": [[0, 3, "organisation"], [6, 10, "organisation"], [14, 21, "university"], [22, 24, "university"], [26, 27, "university"], [30, 32, "university"], [33, 35, "country"], [40, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 40, 40, "related-to", "research_leader_in_field", false, false], [6, 10, 0, 3, "named", "", false, false], [6, 10, 40, 40, "related-to", "research_leader_in_field", false, false], [14, 21, 40, 40, "related-to", "research_leader_in_field", false, false], [22, 24, 40, 40, "related-to", "research_leader_in_field", false, false], [26, 27, 40, 40, "related-to", "research_leader_in_field", false, false], [30, 32, 33, 35, "physical", "", false, false], [30, 32, 40, 40, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "Shirley", "Ryan", "AbilityLab", "(", "formerly", "the", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "the", "University", "of", "California", "at", "Berkeley", ",", "the", "Massachusetts", "Institute", "of", "Technology", ",", "Stanford", "University", "and", "the", "University", "of", "Twente", "in", "the", "Netherlands", "are", "all", "leaders", "in", "biomechatronics", "research", "."], "sentence-detokenized": "The Shirley Ryan AbilityLab (formerly the Rehabilitation Institute of Chicago), the University of California at Berkeley, the Massachusetts Institute of Technology, Stanford University and the University of Twente in the Netherlands are all leaders in biomechatronics research.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 27], [28, 29], [29, 37], [38, 41], [42, 56], [57, 66], [67, 69], [70, 77], [77, 78], [78, 79], [80, 83], [84, 94], [95, 97], [98, 108], [109, 111], [112, 120], [120, 121], [122, 125], [126, 139], [140, 149], [150, 152], [153, 163], [163, 164], [165, 173], [174, 184], [185, 188], [189, 192], [193, 203], [204, 206], [207, 213], [214, 216], [217, 220], [221, 232], [233, 236], [237, 240], [241, 248], [249, 251], [252, 267], [268, 276], [276, 277]]}
{"doc_key": "ai-test-214", "ner": [[30, 36, "metrics"], [48, 49, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Given", "a", "set", "of", "forecast", "values", "and", "a", "corresponding", "set", "of", "actual", "values", "of", "X", "at", "different", "points", "in", "time", ",", "a", "common", "method", "of", "estimation", "is", "to", "use", "the", "root", "mean", "square", "error", "of", "the", "forecast", ";", "other", "indicators", "can", "also", "be", "used", "(", "see", "Forecasting", "#", "Forecasting", "accuracy", ")", "."], "sentence-detokenized": "Given a set of forecast values and a corresponding set of actual values of X at different points in time, a common method of estimation is to use the root mean square error of the forecast; other indicators can also be used (see Forecasting # Forecasting accuracy).", "token2charspan": [[0, 5], [6, 7], [8, 11], [12, 14], [15, 23], [24, 30], [31, 34], [35, 36], [37, 50], [51, 54], [55, 57], [58, 64], [65, 71], [72, 74], [75, 76], [77, 79], [80, 89], [90, 96], [97, 99], [100, 104], [104, 105], [106, 107], [108, 114], [115, 121], [122, 124], [125, 135], [136, 138], [139, 141], [142, 145], [146, 149], [150, 154], [155, 159], [160, 166], [167, 172], [173, 175], [176, 179], [180, 188], [188, 189], [190, 195], [196, 206], [207, 210], [211, 215], [216, 218], [219, 223], [224, 225], [225, 228], [229, 240], [241, 242], [243, 254], [255, 263], [263, 264], [264, 265]]}
{"doc_key": "ai-test-215", "ner": [[14, 14, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "indicators", ",", "such", "as", "the", "proportion", "of", "correct", "predictions", "(", "also", "known", "as", "accuracy", ")", ",", "are", "not", "useful", "when", "the", "two", "classes", "are", "very", "different", "in", "size", "."], "sentence-detokenized": "Other indicators, such as the proportion of correct predictions (also known as accuracy), are not useful when the two classes are very different in size.", "token2charspan": [[0, 5], [6, 16], [16, 17], [18, 22], [23, 25], [26, 29], [30, 40], [41, 43], [44, 51], [52, 63], [64, 65], [65, 69], [70, 75], [76, 78], [79, 87], [87, 88], [88, 89], [90, 93], [94, 97], [98, 104], [105, 109], [110, 113], [114, 117], [118, 125], [126, 129], [130, 134], [135, 144], [145, 147], [148, 152], [152, 153]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [11, 19, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 11, 19, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "made", "public", "at", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "conference", "in", "2000", "and", "five", "beta", "versions", "were", "released", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was made public at the Computer Vision and Pattern Recognition conference in 2000 and five beta versions were released between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 42], [43, 49], [50, 52], [53, 56], [57, 65], [66, 72], [73, 76], [77, 84], [85, 96], [97, 107], [108, 110], [111, 115], [116, 119], [120, 124], [125, 129], [130, 138], [139, 143], [144, 152], [153, 160], [161, 165], [166, 169], [170, 174], [174, 175]]}
{"doc_key": "ai-test-217", "ner": [[20, 20, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Results", "are", "presented", "showing", "a", "correlation", "with", "human", "judgement", "at", "corpus", "level", "of", "up", "to", "0.964", ",", "compared", "to", "a", "BLEU", "result", "of", "0.817", "using", "the", "same", "dataset", "."], "sentence-detokenized": "Results are presented showing a correlation with human judgement at corpus level of up to 0.964, compared to a BLEU result of 0.817 using the same dataset.", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 29], [30, 31], [32, 43], [44, 48], [49, 54], [55, 64], [65, 67], [68, 74], [75, 80], [81, 83], [84, 86], [87, 89], [90, 95], [95, 96], [97, 105], [106, 108], [109, 110], [111, 115], [116, 122], [123, 125], [126, 131], [132, 137], [138, 141], [142, 146], [147, 154], [154, 155]]}
{"doc_key": "ai-test-218", "ner": [[4, 4, "metrics"], [18, 18, "metrics"], [20, 22, "metrics"], [24, 43, "metrics"], [30, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 18, 18, "compare", "", false, false], [4, 4, 20, 22, "compare", "", false, false], [4, 4, 24, 43, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "early", "version", "of", "VMAF", "has", "been", "shown", "to", "outperform", "other", "image", "and", "video", "quality", "indicators", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", "and", "VQM", "-", "VFD", "in", "terms", "of", "predictive", "accuracy", "in", "three", "out", "of", "the", "four", "datasets", ",", "compared", "to", "subjective", "judgements", "."], "sentence-detokenized": "The early version of VMAF has been shown to outperform other image and video quality indicators such as SSIM, PSNR -HVS and VQM-VFD in terms of predictive accuracy in three out of the four datasets, compared to subjective judgements.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 20], [21, 25], [26, 29], [30, 34], [35, 40], [41, 43], [44, 54], [55, 60], [61, 66], [67, 70], [71, 76], [77, 84], [85, 95], [96, 100], [101, 103], [104, 108], [108, 109], [110, 114], [115, 116], [116, 119], [120, 123], [124, 127], [127, 128], [128, 131], [132, 134], [135, 140], [141, 143], [144, 154], [155, 163], [164, 166], [167, 172], [173, 176], [177, 179], [180, 183], [184, 188], [189, 197], [197, 198], [199, 207], [208, 210], [211, 221], [222, 232], [232, 233]]}
{"doc_key": "ai-test-219", "ner": [[20, 23, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 23, 27, 28, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "of", "the", "word", "\"", "mouse", "\"", "(", "animal", "or", "machine", ")", "is", "not", "important", "for", "machine", "translation", ",", "but", "is", "important", "for", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity of the word \"mouse\" (animal or machine) is not important for machine translation, but is important for information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 33], [34, 38], [39, 40], [40, 45], [45, 46], [47, 48], [48, 54], [55, 57], [58, 65], [65, 66], [67, 69], [70, 73], [74, 83], [84, 87], [88, 95], [96, 107], [107, 108], [109, 112], [113, 115], [116, 125], [126, 129], [130, 141], [142, 151], [151, 152]]}
{"doc_key": "ai-test-220", "ner": [[0, 1, "algorithm"], [9, 10, "field"], [12, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 1, "usage", "", false, false], [12, 16, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "coding", "was", "originally", "proposed", "in", "the", "field", "of", "computer", "vision", "to", "recognise", "2D", "and", "3D", "objects", ","], "sentence-detokenized": "Geometric coding was originally proposed in the field of computer vision to recognise 2D and 3D objects,", "token2charspan": [[0, 9], [10, 16], [17, 20], [21, 31], [32, 40], [41, 43], [44, 47], [48, 53], [54, 56], [57, 65], [66, 72], [73, 75], [76, 85], [86, 88], [89, 92], [93, 95], [96, 103], [103, 104]]}
{"doc_key": "ai-test-221", "ner": [[9, 10, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 9, 10, "part-of", "subfield", false, false], [17, 18, 9, 10, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "is", "one", "of", "the", "three", "main", "categories", "of", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "It is one of the three main categories of machine learning, along with supervised learning and reinforcement learning.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 12], [13, 16], [17, 22], [23, 27], [28, 38], [39, 41], [42, 49], [50, 58], [58, 59], [60, 65], [66, 70], [71, 81], [82, 90], [91, 94], [95, 108], [109, 117], [117, 118]]}
{"doc_key": "ai-test-222", "ner": [[4, 6, "field"], [16, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"], [27, 30, "field"], [32, 33, "field"], [35, 35, "field"], [37, 37, "field"], [39, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[4, 6, 16, 16, "part-of", "subfield", false, false], [4, 6, 18, 19, "part-of", "subfield", false, false], [4, 6, 21, 22, "part-of", "subfield", false, false], [4, 6, 24, 25, "part-of", "subfield", false, false], [4, 6, 27, 30, "part-of", "subfield", false, false], [4, 6, 32, 33, "part-of", "subfield", false, false], [4, 6, 35, 35, "part-of", "subfield", false, false], [4, 6, 37, 37, "part-of", "subfield", false, false], [4, 6, 39, 40, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Because", "of", "its", "generality", ",", "reinforcement", "learning", "is", "addressed", "in", "many", "other", "disciplines", ",", "such", "as", "games", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "AI", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Because of its generality, reinforcement learning is addressed in many other disciplines, such as games, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, AI, statistics and genetic algorithms.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [25, 26], [27, 40], [41, 49], [50, 52], [53, 62], [63, 65], [66, 70], [71, 76], [77, 88], [88, 89], [90, 94], [95, 97], [98, 103], [103, 104], [105, 112], [113, 119], [119, 120], [121, 131], [132, 140], [140, 141], [142, 153], [154, 160], [160, 161], [162, 172], [172, 173], [173, 178], [179, 191], [191, 192], [193, 204], [205, 212], [212, 213], [214, 216], [216, 217], [218, 228], [229, 232], [233, 240], [241, 251], [251, 252]]}
{"doc_key": "ai-test-223", "ner": [[0, 1, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "related-to", "", false, false], [0, 1, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pattern", "recognition", "is", "closely", "linked", "to", "artificial", "intelligence", "and", "machine", "learning", ","], "sentence-detokenized": "Pattern recognition is closely linked to artificial intelligence and machine learning,", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 37], [38, 40], [41, 51], [52, 64], [65, 68], [69, 76], [77, 85], [85, 86]]}
{"doc_key": "ai-test-224", "ner": [[10, 12, "algorithm"], [14, 15, "field"], [17, 18, "field"], [28, 29, "task"], [31, 31, "task"], [33, 34, "task"], [36, 37, "algorithm"], [39, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 12, 14, 15, "related-to", "", false, false], [10, 12, 17, 18, "related-to", "", false, false], [28, 29, 10, 12, "usage", "", true, false], [31, 31, 10, 12, "usage", "", true, false], [33, 34, 10, 12, "usage", "", true, false], [36, 37, 10, 12, "usage", "", true, false], [39, 41, 10, 12, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "software", "is", "used", "to", "design", ",", "train", "and", "deploy", "neural", "network", "models", "(", "supervised", "learning", "and", "unsupervised", "learning", ")", "to", "perform", "a", "variety", "of", "tasks", "such", "as", "data", "mining", ",", "classification", ",", "feature", "approximation", ",", "multivariate", "regression", "and", "time", "series", "prediction", "."], "sentence-detokenized": "The software is used to design, train and deploy neural network models (supervised learning and unsupervised learning) to perform a variety of tasks such as data mining, classification, feature approximation, multivariate regression and time series prediction.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [21, 23], [24, 30], [30, 31], [32, 37], [38, 41], [42, 48], [49, 55], [56, 63], [64, 70], [71, 72], [72, 82], [83, 91], [92, 95], [96, 108], [109, 117], [117, 118], [119, 121], [122, 129], [130, 131], [132, 139], [140, 142], [143, 148], [149, 153], [154, 156], [157, 161], [162, 168], [168, 169], [170, 184], [184, 185], [186, 193], [194, 207], [207, 208], [209, 221], [222, 232], [233, 236], [237, 241], [242, 248], [249, 259], [259, 260]]}
{"doc_key": "ai-test-225", "ner": [[11, 17, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", ",", "he", "was", "elected", "as", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016, he was elected as a member of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 28], [29, 35], [36, 38], [39, 42], [43, 54], [55, 58], [59, 62], [63, 74], [75, 77], [78, 88], [89, 101], [101, 102]]}
{"doc_key": "ai-test-226", "ner": [[5, 9, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", "and", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", ","], "sentence-detokenized": "She is a member of the National Academy of Sciences (since 2005) and the American Academy of Arts and Sciences (since 2009),", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 15], [16, 18], [19, 22], [23, 31], [32, 39], [40, 42], [43, 51], [52, 53], [53, 58], [59, 63], [63, 64], [65, 68], [69, 72], [73, 81], [82, 89], [90, 92], [93, 97], [98, 101], [102, 110], [111, 112], [112, 117], [118, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-test-227", "ner": [[3, 5, "misc"], [9, 14, "product"], [16, 17, "country"], [19, 19, "country"], [22, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 14, 3, 5, "temporal", "", false, false], [9, 14, 16, 17, "physical", "", false, false], [9, 14, 19, 19, "physical", "", false, false], [9, 14, 22, 24, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "the", "1973", "Yom", "Kippur", "War", ",", "Soviet", "-supplied", "surface", "-", "to", "-", "air", "missile", "batteries", "in", "Egypt", "and", "Syria", "severely", "damaged", "Israeli", "fighter", "jets", "."], "sentence-detokenized": "During the 1973 Yom Kippur War, Soviet-supplied surface-to-air missile batteries in Egypt and Syria severely damaged Israeli fighter jets.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 26], [27, 30], [30, 31], [32, 38], [38, 47], [48, 55], [55, 56], [56, 58], [58, 59], [59, 62], [63, 70], [71, 80], [81, 83], [84, 89], [90, 93], [94, 99], [100, 108], [109, 116], [117, 124], [125, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-test-228", "ner": [[10, 11, "product"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "source", "(", "free", ",", "but", "copyrighted", ")", "is", "the", "HTK", "book", "(", "and", "the", "accompanying", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another source (free, but copyrighted) is the HTK book (and the accompanying HTK toolkit).", "token2charspan": [[0, 7], [8, 14], [15, 16], [16, 20], [20, 21], [22, 25], [26, 37], [37, 38], [39, 41], [42, 45], [46, 49], [50, 54], [55, 56], [56, 59], [60, 63], [64, 76], [77, 80], [81, 88], [88, 89], [89, 90]]}
{"doc_key": "ai-test-229", "ner": [[0, 4, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "At", "the", "2004", "AAAI", "Spring", "Symposium", ",", "linguists", ",", "computer", "scientists", "and", "other", "interested", "researchers", "for", "the", "first", "time", "aligned", "their", "interests", "and", "proposed", "common", "tasks", "and", "benchmark", "datasets", "for", "systematic", "computational", "studies", "of", "affect", ",", "attractiveness", ",", "subjectivity", "and", "sentiment", "in", "text", "."], "sentence-detokenized": "- At the 2004 AAAI Spring Symposium, linguists, computer scientists and other interested researchers for the first time aligned their interests and proposed common tasks and benchmark datasets for systematic computational studies of affect, attractiveness, subjectivity and sentiment in text.", "token2charspan": [[0, 1], [2, 4], [5, 8], [9, 13], [14, 18], [19, 25], [26, 35], [35, 36], [37, 46], [46, 47], [48, 56], [57, 67], [68, 71], [72, 77], [78, 88], [89, 100], [101, 104], [105, 108], [109, 114], [115, 119], [120, 127], [128, 133], [134, 143], [144, 147], [148, 156], [157, 163], [164, 169], [170, 173], [174, 183], [184, 192], [193, 196], [197, 207], [208, 221], [222, 229], [230, 232], [233, 239], [239, 240], [241, 255], [255, 256], [257, 269], [270, 273], [274, 283], [284, 286], [287, 291], [291, 292]]}
{"doc_key": "ai-test-230", "ner": [[12, 18, "task"], [23, 24, "task"], [26, 28, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "single", "grid", "can", "be", "analysed", "both", "in", "terms", "of", "content", "(", "out", "of", "the", "corner", "of", "the", "eye", ")", "and", "structure", "(", "cluster", "analysis", ",", "principal", "component", "analysis", "and", "various", "structural", "indices", "related", "to", "the", "complexity", "and", "scope", "of", "the", "assessments", "are", "commonly", "used", ")", "."], "sentence-detokenized": "A single grid can be analysed both in terms of content (out of the corner of the eye) and structure (cluster analysis, principal component analysis and various structural indices related to the complexity and scope of the assessments are commonly used).", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 17], [18, 20], [21, 29], [30, 34], [35, 37], [38, 43], [44, 46], [47, 54], [55, 56], [56, 59], [60, 62], [63, 66], [67, 73], [74, 76], [77, 80], [81, 84], [84, 85], [86, 89], [90, 99], [100, 101], [101, 108], [109, 117], [117, 118], [119, 128], [129, 138], [139, 147], [148, 151], [152, 159], [160, 170], [171, 178], [179, 186], [187, 189], [190, 193], [194, 204], [205, 208], [209, 214], [215, 217], [218, 221], [222, 233], [234, 237], [238, 246], [247, 251], [251, 252], [252, 253]]}
{"doc_key": "ai-test-231", "ner": [[3, 3, "organisation"], [10, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", ",", "Toyota", "was", "seen", "as", "a", "laggard", "in", "self", "-", "driving", "cars", "and", "in", "need", "of", "innovation", "."], "sentence-detokenized": "In 2018, Toyota was seen as a laggard in self-driving cars and in need of innovation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 24], [25, 27], [28, 29], [30, 37], [38, 40], [41, 45], [45, 46], [46, 53], [54, 58], [59, 62], [63, 65], [66, 70], [71, 73], [74, 84], [84, 85]]}
{"doc_key": "ai-test-232", "ner": [[36, 37, "misc"], [39, 40, "misc"], [43, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "include", "natural", "objects", "such", "as", "land", ",", "sea", ",", "precipitation", "(", "rain", ",", "snow", "or", "hail", ")", ",", "sandstorms", ",", "animals", "(", "especially", "birds", ")", ",", "atmospheric", "turbulence", ",", "and", "other", "atmospheric", "phenomena", "such", "as", "ionospheric", "reflections", ",", "meteor", "trails", "and", "the", "three", "-", "body", "scattering", "spike", "."], "sentence-detokenized": "These include natural objects such as land, sea, precipitation (rain, snow or hail), sandstorms, animals (especially birds), atmospheric turbulence, and other atmospheric phenomena such as ionospheric reflections, meteor trails and the three-body scattering spike.", "token2charspan": [[0, 5], [6, 13], [14, 21], [22, 29], [30, 34], [35, 37], [38, 42], [42, 43], [44, 47], [47, 48], [49, 62], [63, 64], [64, 68], [68, 69], [70, 74], [75, 77], [78, 82], [82, 83], [83, 84], [85, 95], [95, 96], [97, 104], [105, 106], [106, 116], [117, 122], [122, 123], [123, 124], [125, 136], [137, 147], [147, 148], [149, 152], [153, 158], [159, 170], [171, 180], [181, 185], [186, 188], [189, 200], [201, 212], [212, 213], [214, 220], [221, 227], [228, 231], [232, 235], [236, 241], [241, 242], [242, 246], [247, 257], [258, 263], [263, 264]]}
{"doc_key": "ai-test-233", "ner": [[17, 22, "product"], [39, 40, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "planning", "and", "control", ",", "the", "key", "difference", "between", "humanoids", "and", "other", "types", "of", "robots", "(", "e.g.", "industrial", "robots", ")", "is", "that", "the", "robot", "'s", "movement", "must", "be", "similar", "to", "a", "human", "'s", ",", "using", "leg", "movement", ",", "especially", "bipedal", "gait", "."], "sentence-detokenized": "For planning and control, the key difference between humanoids and other types of robots (e.g. industrial robots) is that the robot's movement must be similar to a human's, using leg movement, especially bipedal gait.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 24], [24, 25], [26, 29], [30, 33], [34, 44], [45, 52], [53, 62], [63, 66], [67, 72], [73, 78], [79, 81], [82, 88], [89, 90], [90, 94], [95, 105], [106, 112], [112, 113], [114, 116], [117, 121], [122, 125], [126, 131], [131, 133], [134, 142], [143, 147], [148, 150], [151, 158], [159, 161], [162, 163], [164, 169], [169, 171], [171, 172], [173, 178], [179, 182], [183, 191], [191, 192], [193, 203], [204, 211], [212, 216], [216, 217]]}
{"doc_key": "ai-test-234", "ner": [[12, 13, "algorithm"], [21, 23, "misc"], [26, 26, "metrics"], [1, 3, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "curvature", "of", "the", "function", "varies", "significantly", "in", "different", "directions", ",", "gradient", "descent", "may", "require", "many", "iterations", "to", "calculate", "the", "local", "minimum", "with", "the", "required", "accuracy", "."], "sentence-detokenized": "If the curvature of the function varies significantly in different directions, gradient descent may require many iterations to calculate the local minimum with the required accuracy.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 23], [24, 32], [33, 39], [40, 53], [54, 56], [57, 66], [67, 77], [77, 78], [79, 87], [88, 95], [96, 99], [100, 107], [108, 112], [113, 123], [124, 126], [127, 136], [137, 140], [141, 146], [147, 154], [155, 159], [160, 163], [164, 172], [173, 181], [181, 182]]}
{"doc_key": "ai-test-235", "ner": [[0, 6, "misc"], [10, 10, "misc"], [27, 33, "conference"], [34, 34, "location"], [23, 41, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 10, 10, "part-of", "", true, false], [27, 33, 34, 34, "physical", "", false, true], [34, 34, 23, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "1997", "RoboCup", "2D", "Soccer", "Simulation", "League", "was", "the", "first", "RoboCup", "competition", ",", "held", "from", "23", "-", "29", "August", "1997", ".", "The", "RoboCup", "was", "held", "at", "the", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", "in", "Nagoya", ",", "Japan", ",", "on", "27th", "June", "1997", "."], "sentence-detokenized": "The 1997 RoboCup 2D Soccer Simulation League was the first RoboCup competition, held from 23-29 August 1997. The RoboCup was held at the International Joint Conference on Artificial Intelligence in Nagoya, Japan, on 27th June 1997.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 19], [20, 26], [27, 37], [38, 44], [45, 48], [49, 52], [53, 58], [59, 66], [67, 78], [78, 79], [80, 84], [85, 89], [90, 92], [92, 93], [93, 95], [96, 102], [103, 107], [107, 108], [109, 112], [113, 120], [121, 124], [125, 129], [130, 132], [133, 136], [137, 150], [151, 156], [157, 167], [168, 170], [171, 181], [182, 194], [195, 197], [198, 204], [204, 205], [206, 211], [211, 212], [213, 215], [216, 220], [221, 225], [226, 230], [230, 231]]}
{"doc_key": "ai-test-236", "ner": [[6, 6, "programlang"], [10, 10, "programlang"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "options", "include", "an", "embedded", "Python", "environment", "and", "the", "R", "console", ",", "as", "well", "as", "support", "for", "Rserve", "."], "sentence-detokenized": "Other programming options include an embedded Python environment and the R console, as well as support for Rserve.", "token2charspan": [[0, 5], [6, 17], [18, 25], [26, 33], [34, 36], [37, 45], [46, 52], [53, 64], [65, 68], [69, 72], [73, 74], [75, 82], [82, 83], [84, 86], [87, 91], [92, 94], [95, 102], [103, 106], [107, 113], [113, 114]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [8, 9, "field"], [11, 11, "field"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 23, "researcher"], [26, 27, "field"], [30, 31, "field"], [34, 35, "field"], [38, 38, "field"], [45, 59, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[16, 17, 11, 11, "related-to", "contributes_to_field", true, false], [19, 20, 11, 11, "related-to", "contributes_to_field", true, false], [22, 23, 11, 11, "related-to", "contributes_to_field", true, false], [34, 35, 30, 31, "part-of", "", false, false], [38, 38, 34, 35, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["From", "Bonn", ",", "he", "made", "major", "contributions", "to", "artificial", "intelligence", "and", "robotics", "(", "his", "students", "included", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Thrun", ")", ",", "software", "engineering", ",", "especially", "civil", "engineering", ",", "and", "information", "systems", ",", "especially", "geosciences", ".", "In", "2016", "he", "won", "the", "AAAI", "Classic", "Paper", "Award", ".", "In", "2014", ",", "he", "won", "the", "AAAI", "Classic", "Paper", "Award", "."], "sentence-detokenized": "From Bonn, he made major contributions to artificial intelligence and robotics (his students included Wolfram Burgard, Dieter Fox, Sebastian Thrun), software engineering, especially civil engineering, and information systems, especially geosciences. In 2016 he won the AAAI Classic Paper Award. In 2014, he won the AAAI Classic Paper Award.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 13], [14, 18], [19, 24], [25, 38], [39, 41], [42, 52], [53, 65], [66, 69], [70, 78], [79, 80], [80, 83], [84, 92], [93, 101], [102, 109], [110, 117], [117, 118], [119, 125], [126, 129], [129, 130], [131, 140], [141, 146], [146, 147], [147, 148], [149, 157], [158, 169], [169, 170], [171, 181], [182, 187], [188, 199], [199, 200], [201, 204], [205, 216], [217, 224], [224, 225], [226, 236], [237, 248], [248, 249], [250, 252], [253, 257], [258, 260], [261, 264], [265, 268], [269, 273], [274, 281], [282, 287], [288, 293], [293, 294], [295, 297], [298, 302], [302, 303], [304, 306], [307, 310], [311, 314], [315, 319], [320, 327], [328, 333], [334, 339], [339, 340]]}
{"doc_key": "ai-test-238", "ner": [[2, 7, "conference"], [29, 30, "location"], [31, 32, "location"], [34, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 7, 29, 30, "physical", "", false, false], [29, 30, 31, 32, "physical", "", false, false], [31, 32, 34, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "Campus", "Party", "in", "the", "US", "will", "take", "place", "from", "20", "-", "22", "August", ".", "The", "Campus", "Day", "will", "take", "place", "on", "the", "22nd", "of", "August", "at", "the", "TCF", "Centre", "in", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "The first Campus Party in the US will take place from 20-22 August. The Campus Day will take place on the 22nd of August at the TCF Centre in Detroit, Michigan.", "token2charspan": [[0, 3], [4, 9], [10, 16], [17, 22], [23, 25], [26, 29], [30, 32], [33, 37], [38, 42], [43, 48], [49, 53], [54, 56], [56, 57], [57, 59], [60, 66], [66, 67], [68, 71], [72, 78], [79, 82], [83, 87], [88, 92], [93, 98], [99, 101], [102, 105], [106, 110], [111, 113], [114, 120], [121, 123], [124, 127], [128, 131], [132, 138], [139, 141], [142, 149], [149, 150], [151, 159], [159, 160]]}
{"doc_key": "ai-test-239", "ner": [[2, 4, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 14, "misc"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 12, 14, "win-defeat", "", false, false], [5, 6, 12, 14, "win-defeat", "", false, false], [8, 8, 12, 14, "win-defeat", "", false, false], [12, 14, 22, 24, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Together", "with", "Yann", "LeCun", "and", "Yoshua", "Bengio", ",", "Hinton", "won", "the", "2018", "Turing", "Award", "for", "conceptual", "and", "engineering", "breakthroughs", "that", "have", "made", "deep", "neural", "networks", "an", "important", "component", "of", "computing", "."], "sentence-detokenized": "Together with Yann LeCun and Yoshua Bengio, Hinton won the 2018 Turing Award for conceptual and engineering breakthroughs that have made deep neural networks an important component of computing.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 24], [25, 28], [29, 35], [36, 42], [42, 43], [44, 50], [51, 54], [55, 58], [59, 63], [64, 70], [71, 76], [77, 80], [81, 91], [92, 95], [96, 107], [108, 121], [122, 126], [127, 131], [132, 136], [137, 141], [142, 148], [149, 157], [158, 160], [161, 170], [171, 180], [181, 183], [184, 193], [193, 194]]}
{"doc_key": "ai-test-240", "ner": [[0, 4, "product"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 11, 11, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["\"", "The", "Euler", "Math", "Toolbox", "uses", "a", "matrix", "language", "similar", "to", "MATLAB", ",", "a", "system", "that", "has", "been", "under", "development", "since", "the", "1970s", "."], "sentence-detokenized": "\"The Euler Math Toolbox uses a matrix language similar to MATLAB, a system that has been under development since the 1970s.", "token2charspan": [[0, 1], [1, 4], [5, 10], [11, 15], [16, 23], [24, 28], [29, 30], [31, 37], [38, 46], [47, 54], [55, 57], [58, 64], [64, 65], [66, 67], [68, 74], [75, 79], [80, 83], [84, 88], [89, 94], [95, 106], [107, 112], [113, 116], [117, 122], [122, 123]]}
{"doc_key": "ai-test-241", "ner": [[11, 11, "programlang"], [13, 14, "programlang"], [16, 16, "programlang"], [18, 18, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "some", "languages", "it", "is", "possible", "to", "port", "this", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "or", "D", ")", "."], "sentence-detokenized": "In some languages it is possible to port this (e.g. Scheme, Common Lisp, Perl or D).", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 20], [21, 23], [24, 32], [33, 35], [36, 40], [41, 45], [46, 47], [47, 51], [52, 58], [58, 59], [60, 66], [67, 71], [71, 72], [73, 77], [78, 80], [81, 82], [82, 83], [83, 84]]}
{"doc_key": "ai-test-242", "ner": [[13, 13, "misc"], [3, 4, "researcher"], [6, 7, "researcher"], [30, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 13, 3, 4, "artifact", "", false, false], [13, 13, 6, 7, "artifact", "", false, false], [13, 13, 30, 31, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1969", ",", "Marvin", "Minsky", "and", "Seymour", "Papert", "published", "their", "famous", "book", "\"", "Perceptrons", "\"", ",", "which", "showed", "that", "it", "is", "impossible", "for", "these", "classes", "of", "networks", "to", "learn", "the", "XOR", "function", "."], "sentence-detokenized": "In 1969, Marvin Minsky and Seymour Papert published their famous book \"Perceptrons\", which showed that it is impossible for these classes of networks to learn the XOR function.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 22], [23, 26], [27, 34], [35, 41], [42, 51], [52, 57], [58, 64], [65, 69], [70, 71], [71, 82], [82, 83], [83, 84], [85, 90], [91, 97], [98, 102], [103, 105], [106, 108], [109, 119], [120, 123], [124, 129], [130, 137], [138, 140], [141, 149], [150, 152], [153, 158], [159, 162], [163, 166], [167, 175], [175, 176]]}
{"doc_key": "ai-test-243", "ner": [[3, 7, "misc"], [12, 14, "product"], [19, 25, "organisation"], [28, 34, "organisation"], [36, 42, "location"], [44, 44, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[19, 25, 12, 14, "usage", "", false, false], [19, 25, 36, 42, "physical", "", false, false], [28, 34, 19, 25, "named", "", false, false], [36, 42, 44, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Much", "of", "the", "Russian", "scientific", "and", "technical", "documentation", "was", "translated", "using", "the", "SYSTRAN", "programme", "under", "the", "auspices", "of", "the", "US", "Air", "Force", "'s", "Foreign", "Technology", "Division", "(", "later", "the", "National", "Air", "and", "Space", "Intelligence", "Centre", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", ",", "Ohio", "."], "sentence-detokenized": "Much of the Russian scientific and technical documentation was translated using the SYSTRAN programme under the auspices of the US Air Force's Foreign Technology Division (later the National Air and Space Intelligence Centre) at Wright-Patterson Air Force Base, Ohio.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 19], [20, 30], [31, 34], [35, 44], [45, 58], [59, 62], [63, 73], [74, 79], [80, 83], [84, 91], [92, 101], [102, 107], [108, 111], [112, 120], [121, 123], [124, 127], [128, 130], [131, 134], [135, 140], [140, 142], [143, 150], [151, 161], [162, 170], [171, 172], [172, 177], [178, 181], [182, 190], [191, 194], [195, 198], [199, 204], [205, 217], [218, 224], [224, 225], [226, 228], [229, 235], [235, 236], [236, 245], [246, 249], [250, 255], [256, 260], [260, 261], [262, 266], [266, 267]]}
{"doc_key": "ai-test-244", "ner": [[0, 1, "field"], [4, 5, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-supervised", "learning", "is", "between", "unsupervised", "learning", "(", "with", "no", "marked", "training", "data", ")", "and", "supervised", "learning", "(", "with", "fully", "marked", "training", "data", ")", "."], "sentence-detokenized": "Semi-supervised learning is between unsupervised learning (with no marked training data) and supervised learning (with fully marked training data).", "token2charspan": [[0, 15], [16, 24], [25, 27], [28, 35], [36, 48], [49, 57], [58, 59], [59, 63], [64, 66], [67, 73], [74, 82], [83, 87], [87, 88], [89, 92], [93, 103], [104, 112], [113, 114], [114, 118], [119, 124], [125, 131], [132, 140], [141, 145], [145, 146], [146, 147]]}
{"doc_key": "ai-test-245", "ner": [[0, 4, "algorithm"], [7, 10, "algorithm"], [29, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 7, 10, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Ann", "-", "gram", "model", "is", "a", "probabilistic", "language", "model", "for", "predicting", "the", "next", "element", "of", "such", "a", "sequence", "(", "n", "-", "1", ")", "in", "the", "form", "of", "a", "Markov", "sequence", "model", "."], "sentence-detokenized": "The Ann -gram model is a probabilistic language model for predicting the next element of such a sequence (n - 1) in the form of a Markov sequence model.", "token2charspan": [[0, 3], [4, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 24], [25, 38], [39, 47], [48, 53], [54, 57], [58, 68], [69, 72], [73, 77], [78, 85], [86, 88], [89, 93], [94, 95], [96, 104], [105, 106], [106, 107], [108, 109], [110, 111], [111, 112], [113, 115], [116, 119], [120, 124], [125, 127], [128, 129], [130, 136], [137, 145], [146, 151], [151, 152]]}
{"doc_key": "ai-test-246", "ner": [[0, 2, "organisation"], [4, 4, "product"], [8, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 4, 4, "usage", "", false, false], [8, 14, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "used", "Cyc", "to", "create", "a", "natural", "language", "query", "interface", "for", "biomedical", "information", "covering", "decades", "of", "information", "on", "heart", "and", "thoracic", "surgery", "."], "sentence-detokenized": "The Cleveland Clinic used Cyc to create a natural language query interface for biomedical information covering decades of information on heart and thoracic surgery.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 29], [30, 32], [33, 39], [40, 41], [42, 49], [50, 58], [59, 64], [65, 74], [75, 78], [79, 89], [90, 101], [102, 110], [111, 118], [119, 121], [122, 133], [134, 136], [137, 142], [143, 146], [147, 155], [156, 163], [163, 164]]}
{"doc_key": "ai-test-247", "ner": [[5, 7, "country"], [9, 9, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 9, 9, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "incident", "strained", "relations", "between", "the", "United", "States", "and", "Japan", ",", "leading", "to", "the", "arrest", "and", "prosecution", "of", "two", "senior", "executives", "and", "the", "imposition", "of", "sanctions", "against", "the", "company", "by", "both", "countries", "."], "sentence-detokenized": "The incident strained relations between the United States and Japan, leading to the arrest and prosecution of two senior executives and the imposition of sanctions against the company by both countries.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 31], [32, 39], [40, 43], [44, 50], [51, 57], [58, 61], [62, 67], [67, 68], [69, 76], [77, 79], [80, 83], [84, 90], [91, 94], [95, 106], [107, 109], [110, 113], [114, 120], [121, 131], [132, 135], [136, 139], [140, 150], [151, 153], [154, 163], [164, 171], [172, 175], [176, 183], [184, 186], [187, 191], [192, 201], [201, 202]]}
{"doc_key": "ai-test-248", "ner": [[7, 9, "algorithm"], [12, 15, "field"], [22, 24, "misc"], [34, 34, "misc"], [39, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 12, 15, "type-of", "", false, false], [22, 24, 12, 15, "part-of", "", true, false], [34, 34, 12, 15, "part-of", "", true, false], [39, 40, 12, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "case", "of", "simulation", "using", "an", "artificial", "neural", "network", "or", "other", "machine", "learning", ",", "the", "optimisation", "of", "the", "parameters", "is", "called", "training", ",", "while", "the", "optimisation", "of", "the", "model", "'s", "hyperparameters", "is", "called", "tuning", ",", "and", "often", "uses", "cross", "-checking", "."], "sentence-detokenized": "In the case of simulation using an artificial neural network or other machine learning, the optimisation of the parameters is called training, while the optimisation of the model's hyperparameters is called tuning, and often uses cross-checking.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 25], [26, 31], [32, 34], [35, 45], [46, 52], [53, 60], [61, 63], [64, 69], [70, 77], [78, 86], [86, 87], [88, 91], [92, 104], [105, 107], [108, 111], [112, 122], [123, 125], [126, 132], [133, 141], [141, 142], [143, 148], [149, 152], [153, 165], [166, 168], [169, 172], [173, 178], [178, 180], [181, 196], [197, 199], [200, 206], [207, 213], [213, 214], [215, 218], [219, 224], [225, 229], [230, 235], [235, 244], [244, 245]]}
{"doc_key": "ai-test-249", "ner": [[8, 8, "country"], [10, 10, "country"], [12, 13, "country"], [16, 17, "organisation"], [19, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 17, 19, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "localised", "versions", "of", "the", "site", "in", "the", "UK", ",", "India", "and", "Australia", "were", "discontinued", "after", "Rotten", "Tomatoes", "acquired", "Fandango", "."], "sentence-detokenized": "The localised versions of the site in the UK, India and Australia were discontinued after Rotten Tomatoes acquired Fandango.", "token2charspan": [[0, 3], [4, 13], [14, 22], [23, 25], [26, 29], [30, 34], [35, 37], [38, 41], [42, 44], [44, 45], [46, 51], [52, 55], [56, 65], [66, 70], [71, 83], [84, 89], [90, 96], [97, 105], [106, 114], [115, 123], [123, 124]]}
{"doc_key": "ai-test-250", "ner": [[0, 1, "task"], [13, 14, "metrics"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 13, 14, "related-to", "", false, false], [13, 14, 24, 25, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "NER", "model", "is", "one", "of", "a", "number", "of", "methods", "for", "determining", "the", "accuracy", "of", "subtitles", "for", "live", "TV", "broadcasts", "and", "events", "created", "using", "speech", "recognition", "."], "sentence-detokenized": "The NER model is one of a number of methods for determining the accuracy of subtitles for live TV broadcasts and events created using speech recognition.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 25], [26, 32], [33, 35], [36, 43], [44, 47], [48, 59], [60, 63], [64, 72], [73, 75], [76, 85], [86, 89], [90, 94], [95, 97], [98, 108], [109, 112], [113, 119], [120, 127], [128, 133], [134, 140], [141, 152], [152, 153]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [4, 5, "university"], [8, 10, "university"], [11, 11, "location"], [14, 17, "university"], [21, 21, "university"], [22, 23, "location"], [27, 32, "university"], [33, 35, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 5, "physical", "", false, false], [0, 0, 4, 5, "role", "", false, false], [0, 0, 8, 10, "physical", "", false, false], [0, 0, 8, 10, "role", "", false, false], [0, 0, 14, 17, "physical", "", false, false], [0, 0, 14, 17, "role", "", false, false], [0, 0, 21, 21, "physical", "", false, false], [0, 0, 21, 21, "role", "", false, false], [0, 0, 27, 32, "physical", "", false, false], [0, 0, 27, 32, "role", "", false, false], [8, 10, 11, 11, "physical", "", false, false], [14, 17, 22, 23, "physical", "", false, false], [21, 21, 22, 23, "physical", "", false, false], [27, 32, 33, 35, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "has", "taught", "at", "Cambridge", "University", ",", "the", "Hebrew", "University", "of", "Jerusalem", ",", "the", "School", "of", "Advanced", "Studies", "and", "the", "\u00c9cole", "Polytechnique", "in", "Paris", ",", "and", "the", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "."], "sentence-detokenized": "Atran has taught at Cambridge University, the Hebrew University of Jerusalem, the School of Advanced Studies and the \u00c9cole Polytechnique in Paris, and the John Jay College of Criminal Justice in New York.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 40], [40, 41], [42, 45], [46, 52], [53, 63], [64, 66], [67, 76], [76, 77], [78, 81], [82, 88], [89, 91], [92, 100], [101, 108], [109, 112], [113, 116], [117, 122], [123, 136], [137, 139], [140, 145], [145, 146], [147, 150], [151, 154], [155, 159], [160, 163], [164, 171], [172, 174], [175, 183], [184, 191], [192, 194], [195, 198], [199, 203], [203, 204]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [4, 6, "task"], [18, 25, "researcher"], [21, 25, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "origin", "", false, false], [0, 0, 4, 6, "related-to", "", false, false], [4, 6, 21, 25, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "was", "an", "early", "natural", "language", "understanding", "computer", "programme", ",", "developed", "between", "1968", "and", "1970", ".", "Developed", "by", "Terry", "Winograd", "at", "MIT", "in", "1968", "-", "1970", "."], "sentence-detokenized": "SHRDLU was an early natural language understanding computer programme, developed between 1968 and 1970. Developed by Terry Winograd at MIT in 1968-1970.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 19], [20, 27], [28, 36], [37, 50], [51, 59], [60, 69], [69, 70], [71, 80], [81, 88], [89, 93], [94, 97], [98, 102], [102, 103], [104, 113], [114, 116], [117, 122], [123, 131], [132, 134], [135, 138], [139, 141], [142, 146], [146, 147], [147, 151], [151, 152]]}
{"doc_key": "ai-test-253", "ner": [[3, 5, "misc"], [6, 8, "field"], [9, 13, "university"], [14, 15, "location"], [17, 23, "country"], [27, 28, "university"], [31, 32, "misc"], [33, 37, "field"], [38, 41, "university"], [45, 47, "misc"], [48, 50, "field"], [55, 55, "misc"], [56, 66, "university"], [69, 70, "field"], [74, 75, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[3, 5, 6, 8, "topic", "", false, false], [3, 5, 9, 13, "origin", "", false, false], [9, 13, 14, 15, "physical", "", false, false], [9, 13, 27, 28, "role", "affiliated_with", false, false], [14, 15, 17, 23, "physical", "", false, false], [31, 32, 33, 37, "topic", "", false, false], [31, 32, 38, 41, "origin", "", false, false], [45, 47, 48, 50, "topic", "", false, false], [55, 55, 56, 66, "origin", "", false, false], [55, 55, 69, 70, "topic", "", false, false], [74, 75, 56, 66, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["He", "received", "a", "B.Sc", ".", "in", "electronics", "engineering", "from", "the", "B.M.S", ".", "Engineering", "College", "in", "Bangalore", ",", "India", ",", "in", "1982", ",", "when", "it", "was", "merged", "into", "Bangalore", "University", ",", "an", "M.Sc", ".", "in", "electrical", "and", "computer", "engineering", "from", "Drexel", "University", "in", "1984", ",", "an", "M.Sc", ".", "in", "computer", "science", "in", "1989", ",", "and", "a", "Ph.D.", "from", "the", "University", "of", "Wisconsin", "-", "Madison", "in", "1990", ",", "where", "he", "studied", "artificial", "intelligence", "and", "worked", "with", "Leonard", "Uhr", "."], "sentence-detokenized": "He received a B.Sc. in electronics engineering from the B.M.S. Engineering College in Bangalore, India, in 1982, when it was merged into Bangalore University, an M.Sc. in electrical and computer engineering from Drexel University in 1984, an M.Sc. in computer science in 1989, and a Ph.D. from the University of Wisconsin-Madison in 1990, where he studied artificial intelligence and worked with Leonard Uhr.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 18], [18, 19], [20, 22], [23, 34], [35, 46], [47, 51], [52, 55], [56, 61], [61, 62], [63, 74], [75, 82], [83, 85], [86, 95], [95, 96], [97, 102], [102, 103], [104, 106], [107, 111], [111, 112], [113, 117], [118, 120], [121, 124], [125, 131], [132, 136], [137, 146], [147, 157], [157, 158], [159, 161], [162, 166], [166, 167], [168, 170], [171, 181], [182, 185], [186, 194], [195, 206], [207, 211], [212, 218], [219, 229], [230, 232], [233, 237], [237, 238], [239, 241], [242, 246], [246, 247], [248, 250], [251, 259], [260, 267], [268, 270], [271, 275], [275, 276], [277, 280], [281, 282], [283, 288], [289, 293], [294, 297], [298, 308], [309, 311], [312, 321], [321, 322], [322, 329], [330, 332], [333, 337], [337, 338], [339, 344], [345, 347], [348, 355], [356, 366], [367, 379], [380, 383], [384, 390], [391, 395], [396, 403], [404, 407], [407, 408]]}
{"doc_key": "ai-test-254", "ner": [[7, 9, "metrics"], [11, 13, "metrics"], [18, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 13, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "usually", "measured", "in", "terms", "of", "Word", "Error", "Rate", "(", "WER", ")", "and", "speed", "in", "terms", "of", "a", "real", "-", "time", "factor", "."], "sentence-detokenized": "Accuracy is usually measured in terms of Word Error Rate (WER) and speed in terms of a real-time factor.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 28], [29, 31], [32, 37], [38, 40], [41, 45], [46, 51], [52, 56], [57, 58], [58, 61], [61, 62], [63, 66], [67, 72], [73, 75], [76, 81], [82, 84], [85, 86], [87, 91], [91, 92], [92, 96], [97, 103], [103, 104]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [8, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", ",", "Terry", "Winograd", "developed", "an", "early", "natural", "language", "processing", "engine", "capable", "of", "interpreting", "naturally", "written", "commands", "in", "a", "simple", "rule", "-", "based", "environment", "."], "sentence-detokenized": "In 1971, Terry Winograd developed an early natural language processing engine capable of interpreting naturally written commands in a simple rule-based environment.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 33], [34, 36], [37, 42], [43, 50], [51, 59], [60, 70], [71, 77], [78, 85], [86, 88], [89, 101], [102, 111], [112, 119], [120, 128], [129, 131], [132, 133], [134, 140], [141, 145], [145, 146], [146, 151], [152, 163], [163, 164]]}
{"doc_key": "ai-test-256", "ner": [[19, 20, "field"], [0, 1, "researcher"], [3, 6, "researcher"], [8, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 20, 0, 1, "related-to", "", false, false], [19, 20, 3, 6, "related-to", "", false, false], [19, 20, 8, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "and", "Allen", "Newell", "have", "all", "made", "their", "mark", "in", "the", "field", "of", "artificial", "intelligence", "."], "sentence-detokenized": "Marvin Minsky, Herbert A. Simon and Allen Newell have all made their mark in the field of artificial intelligence.", "token2charspan": [[0, 6], [7, 13], [13, 14], [15, 22], [23, 24], [24, 25], [26, 31], [32, 35], [36, 41], [42, 48], [49, 53], [54, 57], [58, 62], [63, 68], [69, 73], [74, 76], [77, 80], [81, 86], [87, 89], [90, 100], [101, 113], [113, 114]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [32, 33, "field"], [35, 36, "field"], [39, 40, "field"], [48, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[32, 33, 9, 10, "origin", "", true, false], [32, 33, 9, 10, "part-of", "", false, false], [32, 33, 39, 40, "compare", "", false, false], [35, 36, 9, 10, "origin", "", true, false], [35, 36, 9, 10, "part-of", "", false, false], [35, 36, 39, 40, "compare", "", false, false], [39, 40, 9, 10, "origin", "", true, false], [39, 40, 9, 10, "part-of", "", false, false], [39, 40, 48, 51, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "the", "second", "half", "of", "the", "20th", "century", ",", "electrical", "engineering", "itself", "branched", "out", "into", "several", "disciplines", "specialising", "in", "the", "design", "and", "analysis", "of", "systems", "that", "control", "physical", "signals", ",", "such", "as", "electronic", "engineering", "and", "computer", "engineering", ",", "while", "design", "engineering", "evolved", "to", "address", "the", "design", "of", "functional", "user", "-", "machine", "interfaces", "."], "sentence-detokenized": "In the second half of the 20th century, electrical engineering itself branched out into several disciplines specialising in the design and analysis of systems that control physical signals, such as electronic engineering and computer engineering, while design engineering evolved to address the design of functional user-machine interfaces.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 30], [31, 38], [38, 39], [40, 50], [51, 62], [63, 69], [70, 78], [79, 82], [83, 87], [88, 95], [96, 107], [108, 120], [121, 123], [124, 127], [128, 134], [135, 138], [139, 147], [148, 150], [151, 158], [159, 163], [164, 171], [172, 180], [181, 188], [188, 189], [190, 194], [195, 197], [198, 208], [209, 220], [221, 224], [225, 233], [234, 245], [245, 246], [247, 252], [253, 259], [260, 271], [272, 279], [280, 282], [283, 290], [291, 294], [295, 301], [302, 304], [305, 315], [316, 320], [320, 321], [321, 328], [329, 339], [339, 340]]}
{"doc_key": "ai-test-258", "ner": [[7, 7, "metrics"], [9, 10, "metrics"], [12, 15, "metrics"], [45, 47, "metrics"], [54, 56, "metrics"], [60, 66, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 15, 9, 10, "named", "", false, false], [45, 47, 54, 56, "named", "", false, false], [54, 56, 60, 66, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Perhaps", "the", "simplest", "statistical", "indicator", "is", "the", "accuracy", "or", "correct", "fraction", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "cases", "correctly", "classified", ";", "it", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "total", "population", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Perhaps the simplest statistical indicator is the accuracy or correct fraction (FC), which measures the proportion of cases correctly classified; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN)/total population = (TP + TN)/(TP + TN + FP + FN).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 32], [33, 42], [43, 45], [46, 49], [50, 58], [59, 61], [62, 69], [70, 78], [79, 80], [80, 82], [82, 83], [83, 84], [85, 90], [91, 99], [100, 103], [104, 114], [115, 117], [118, 123], [124, 133], [134, 144], [144, 145], [146, 148], [149, 151], [152, 155], [156, 161], [162, 164], [165, 168], [169, 175], [176, 178], [179, 186], [187, 202], [203, 205], [206, 209], [210, 215], [216, 222], [223, 225], [226, 233], [234, 236], [237, 246], [247, 262], [262, 263], [264, 265], [265, 267], [268, 269], [270, 272], [272, 273], [273, 274], [274, 279], [280, 290], [291, 292], [293, 294], [294, 296], [297, 298], [299, 301], [301, 302], [302, 303], [303, 304], [304, 306], [307, 308], [309, 311], [312, 313], [314, 316], [317, 318], [319, 321], [321, 322], [322, 323]]}
{"doc_key": "ai-test-259", "ner": [[11, 19, "conference"], [21, 23, "conference"], [25, 26, "location"], [30, 30, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 19, 25, 26, "physical", "", false, false], [21, 23, 11, 19, "named", "", false, false], [30, 30, 11, 19, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "academia", ",", "major", "research", "fora", "began", "in", "1995", "with", "the", "first", "international", "conference", "on", "data", "mining", "and", "knowledge", "discovery", "(", "KDD", "-", "95", ")", "in", "Montreal", ",", "sponsored", "by", "AAAI", "."], "sentence-detokenized": "In academia, major research fora began in 1995 with the first international conference on data mining and knowledge discovery (KDD-95) in Montreal, sponsored by AAAI.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 18], [19, 27], [28, 32], [33, 38], [39, 41], [42, 46], [47, 51], [52, 55], [56, 61], [62, 75], [76, 86], [87, 89], [90, 94], [95, 101], [102, 105], [106, 115], [116, 125], [126, 127], [127, 130], [130, 131], [131, 133], [133, 134], [135, 137], [138, 146], [146, 147], [148, 157], [158, 160], [161, 165], [165, 166]]}
{"doc_key": "ai-test-260", "ner": [[11, 12, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "approach", ",", "models", "are", "built", "using", "a", "variety", "of", "data", "mining", "and", "machine", "learning", "algorithms", "to", "predict", "how", "users", "will", "rate", "unrated", "items", "."], "sentence-detokenized": "In this approach, models are built using a variety of data mining and machine learning algorithms to predict how users will rate unrated items.", "token2charspan": [[0, 2], [3, 7], [8, 16], [16, 17], [18, 24], [25, 28], [29, 34], [35, 40], [41, 42], [43, 50], [51, 53], [54, 58], [59, 65], [66, 69], [70, 77], [78, 86], [87, 97], [98, 100], [101, 108], [109, 112], [113, 118], [119, 123], [124, 128], [129, 136], [137, 142], [142, 143]]}
{"doc_key": "ai-test-261", "ner": [[9, 9, "algorithm"], [14, 15, "algorithm"], [17, 18, "algorithm"], [25, 26, "misc"], [29, 30, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 14, 15, "related-to", "equivalent", false, false], [14, 15, 17, 18, "usage", "", false, false], [17, 18, 29, 30, "usage", "", false, false], [29, 30, 25, 26, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Given", "the", "above", ",", "we", "can", "see", "that", "the", "SVM", "approach", "is", "equivalent", "to", "empirical", "risk", "with", "Tikhonov", "regulation", ",", "where", "in", "this", "case", "the", "loss", "function", "is", "the", "hinge", "loss"], "sentence-detokenized": "Given the above, we can see that the SVM approach is equivalent to empirical risk with Tikhonov regulation, where in this case the loss function is the hinge loss", "token2charspan": [[0, 5], [6, 9], [10, 15], [15, 16], [17, 19], [20, 23], [24, 27], [28, 32], [33, 36], [37, 40], [41, 49], [50, 52], [53, 63], [64, 66], [67, 76], [77, 81], [82, 86], [87, 95], [96, 106], [106, 107], [108, 113], [114, 116], [117, 121], [122, 126], [127, 130], [131, 135], [136, 144], [145, 147], [148, 151], [152, 157], [158, 162]]}
{"doc_key": "ai-test-262", "ner": [[8, 9, "person"], [14, 15, "person"], [18, 18, "organisation"], [20, 21, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[20, 21, 18, 18, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2015", ",", "the", "show", "was", "hosted", "by", "Molly", "McGrath", ",", "with", "commentary", "from", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "."], "sentence-detokenized": "In 2015, the show was hosted by Molly McGrath, with commentary from Chris Rose and former UFC fighter Kenny Florian.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 21], [22, 28], [29, 31], [32, 37], [38, 45], [45, 46], [47, 51], [52, 62], [63, 67], [68, 73], [74, 78], [79, 82], [83, 89], [90, 93], [94, 101], [102, 107], [108, 115], [115, 116]]}
{"doc_key": "ai-test-263", "ner": [[5, 7, "product"], [12, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [21, 21, "researcher"], [24, 24, "researcher"], [33, 34, "researcher"], [35, 37, "task"], [39, 40, "product"], [42, 44, "researcher"], [45, 46, "task"], [49, 51, "researcher"], [52, 53, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[5, 7, 12, 14, "origin", "", false, false], [5, 7, 16, 17, "origin", "", false, false], [5, 7, 19, 20, "origin", "", false, false], [5, 7, 21, 21, "origin", "", false, false], [16, 17, 42, 44, "named", "same", false, false], [19, 20, 24, 24, "named", "same", false, false], [19, 20, 33, 34, "named", "same", false, false], [35, 37, 39, 40, "related-to", "", false, false], [39, 40, 33, 34, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "underground", "suite", ",", "called", "Micro", "-", "Planner", ",", "was", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "Sussman", ",", "and", "Winograd", "in", "1971", ",", "and", "has", "been", "used", "in", "Winograd", "'s", "natural", "language", "understanding", "programme", "at", "SHRDLU", ",", "Eugene", "Charniak", "'s", "story", "comprehension", "work", ",", "Thorne", "McCarty", "'s", "legal", "argumentation", "work", ",", "and", "several", "other", "projects", "."], "sentence-detokenized": "The underground suite, called Micro-Planner, was implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd Sussman, and Winograd in 1971, and has been used in Winograd's natural language understanding programme at SHRDLU, Eugene Charniak's story comprehension work, Thorne McCarty's legal argumentation work, and several other projects.", "token2charspan": [[0, 3], [4, 15], [16, 21], [21, 22], [23, 29], [30, 35], [35, 36], [36, 43], [43, 44], [45, 48], [49, 60], [61, 63], [64, 70], [71, 74], [75, 82], [82, 83], [84, 90], [91, 99], [100, 103], [104, 109], [110, 118], [119, 126], [126, 127], [128, 131], [132, 140], [141, 143], [144, 148], [148, 149], [150, 153], [154, 157], [158, 162], [163, 167], [168, 170], [171, 179], [179, 181], [182, 189], [190, 198], [199, 212], [213, 222], [223, 225], [226, 232], [232, 233], [234, 240], [241, 249], [249, 251], [252, 257], [258, 271], [272, 276], [276, 277], [278, 284], [285, 292], [292, 294], [295, 300], [301, 314], [315, 319], [319, 320], [321, 324], [325, 332], [333, 338], [339, 347], [347, 348]]}
{"doc_key": "ai-test-264", "ner": [[0, 1, "product"], [9, 10, "product"], [14, 16, "task"], [18, 19, "task"], [21, 23, "task"], [25, 26, "task"], [28, 29, "task"], [32, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 10, 0, 1, "usage", "", true, false], [14, 16, 9, 10, "part-of", "", true, false], [18, 19, 9, 10, "part-of", "", true, false], [21, 23, 9, 10, "part-of", "", true, false], [25, 26, 9, 10, "part-of", "", true, false], [28, 29, 9, 10, "part-of", "", true, false], [32, 34, 9, 10, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "is", "used", "for", "a", "wide", "range", "of", "information", "systems", "purposes", ",", "including", "word", "sense", "disambiguation", ",", "information", "retrieval", ",", "automatic", "text", "classification", ",", "automatic", "summarisation", ",", "machine", "translation", "and", "even", "automatic", "crossword", "puzzles", "."], "sentence-detokenized": "WordNet is used for a wide range of information systems purposes, including word sense disambiguation, information retrieval, automatic text classification, automatic summarisation, machine translation and even automatic crossword puzzles.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 15], [16, 19], [20, 21], [22, 26], [27, 32], [33, 35], [36, 47], [48, 55], [56, 64], [64, 65], [66, 75], [76, 80], [81, 86], [87, 101], [101, 102], [103, 114], [115, 124], [124, 125], [126, 135], [136, 140], [141, 155], [155, 156], [157, 166], [167, 180], [180, 181], [182, 189], [190, 201], [202, 205], [206, 210], [211, 220], [221, 230], [231, 238], [238, 239]]}
{"doc_key": "ai-test-265", "ner": [[0, 3, "researcher"], [6, 8, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 6, 8, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "was", "made", "a", "Fellow", "of", "the", "IEEE", "in", "1996", "."], "sentence-detokenized": "Keutzer was made a Fellow of the IEEE in 1996.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 37], [38, 40], [41, 45], [45, 46]]}
{"doc_key": "ai-test-266", "ner": [[8, 10, "algorithm"], [54, 56, "misc"], [66, 67, "algorithm"], [69, 70, "algorithm"], [72, 73, "algorithm"], [75, 76, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[66, 67, 54, 56, "type-of", "", false, false], [69, 70, 54, 56, "type-of", "", false, false], [72, 73, 54, 56, "type-of", "", false, false], [75, 76, 54, 56, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "widely", "used", "type", "of", "addition", "is", "the", "non-linear", "weighted", "sum", ",", "where", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "left", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "right", ")", "/", "math", ",", "where", "math", "\\", "textstyle", "K", "/", "math", "(", "usually", "called", "the", "activation", "function", ")", "is", "some", "predefined", "function", ",", "such", "as", "a", "hyperbolic", "tangent", ",", "sigmoid", "function", ",", "softmax", "function", "or", "straightening", "function", "."], "sentence-detokenized": "A widely used type of addition is the non-linear weighted sum, where math\\ textstyle f (x) = K\\ left (\\ sum _ i w _ i g _ i (x)\\ right) / math, where math\\ textstyle K / math (usually called the activation function) is some predefined function, such as a hyperbolic tangent, sigmoid function, softmax function or straightening function.", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 18], [19, 21], [22, 30], [31, 33], [34, 37], [38, 48], [49, 57], [58, 61], [61, 62], [63, 68], [69, 73], [73, 74], [75, 84], [85, 86], [87, 88], [88, 89], [89, 90], [91, 92], [93, 94], [94, 95], [96, 100], [101, 102], [102, 103], [104, 107], [108, 109], [110, 111], [112, 113], [114, 115], [116, 117], [118, 119], [120, 121], [122, 123], [124, 125], [125, 126], [126, 127], [127, 128], [129, 134], [134, 135], [136, 137], [138, 142], [142, 143], [144, 149], [150, 154], [154, 155], [156, 165], [166, 167], [168, 169], [170, 174], [175, 176], [176, 183], [184, 190], [191, 194], [195, 205], [206, 214], [214, 215], [216, 218], [219, 223], [224, 234], [235, 243], [243, 244], [245, 249], [250, 252], [253, 254], [255, 265], [266, 273], [273, 274], [275, 282], [283, 291], [291, 292], [293, 300], [301, 309], [310, 312], [313, 326], [327, 335], [335, 336]]}
{"doc_key": "ai-test-267", "ner": [[3, 3, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "film", "Westworld", ",", "female", "robots", "actually", "had", "relationships", "with", "male", "humans", "as", "part", "of", "a", "fictional", "holiday", "world", "paid", "for", "by", "customers", "."], "sentence-detokenized": "In the film Westworld, female robots actually had relationships with male humans as part of a fictional holiday world paid for by customers.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 21], [21, 22], [23, 29], [30, 36], [37, 45], [46, 49], [50, 63], [64, 68], [69, 73], [74, 80], [81, 83], [84, 88], [89, 91], [92, 93], [94, 103], [104, 111], [112, 117], [118, 122], [123, 126], [127, 129], [130, 139], [139, 140]]}
{"doc_key": "ai-test-268", "ner": [[5, 12, "task"], [20, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 12, 20, 25, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "process", "usually", "starts", "by", "extracting", "terminology", "and", "concepts", "or", "noun", "phrases", "from", "plain", "text", "using", "linguistic", "processors", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "phrase", "splitting", "."], "sentence-detokenized": "The process usually starts by extracting terminology and concepts or noun phrases from plain text using linguistic processors such as part-of-speech tagging and phrase splitting.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 26], [27, 29], [30, 40], [41, 52], [53, 56], [57, 65], [66, 68], [69, 73], [74, 81], [82, 86], [87, 92], [93, 97], [98, 103], [104, 114], [115, 125], [126, 130], [131, 133], [134, 138], [138, 139], [139, 141], [141, 142], [142, 148], [149, 156], [157, 160], [161, 167], [168, 177], [177, 178]]}
{"doc_key": "ai-test-269", "ner": [[13, 14, "field"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "demonstrated", "how", "the", "system", "works", "on", "several", "problems", "of", "interest", "to", "the", "machine", "learning", "community", ",", "including", "handwriting", "recognition", "."], "sentence-detokenized": "They demonstrated how the system works on several problems of interest to the machine learning community, including handwriting recognition.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 25], [26, 32], [33, 38], [39, 41], [42, 49], [50, 58], [59, 61], [62, 70], [71, 73], [74, 77], [78, 85], [86, 94], [95, 104], [104, 105], [106, 115], [116, 127], [128, 139], [139, 140]]}
{"doc_key": "ai-test-270", "ner": [[2, 2, "university"], [4, 4, "researcher"], [11, 11, "researcher"], [20, 20, "product"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 2, 2, "physical", "", false, false], [4, 4, 2, 2, "role", "", false, false], [20, 20, 11, 11, "origin", "", false, false], [20, 20, 17, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "at", "Stanford", ",", "Scheinman", "received", "a", "scholarship", "sponsored", "by", "George", "Devol", ",", "inventor", "of", "the", "first", "industrial", "robot", ",", "Unimate", "."], "sentence-detokenized": "While at Stanford, Scheinman received a scholarship sponsored by George Devol, inventor of the first industrial robot, Unimate.", "token2charspan": [[0, 5], [6, 8], [9, 17], [17, 18], [19, 28], [29, 37], [38, 39], [40, 51], [52, 61], [62, 64], [65, 71], [72, 77], [77, 78], [79, 87], [88, 90], [91, 94], [95, 100], [101, 111], [112, 117], [117, 118], [119, 126], [126, 127]]}
{"doc_key": "ai-test-271", "ner": [[7, 8, "task"], [11, 13, "metrics"], [15, 15, "metrics"], [24, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 11, 13, "usage", "", true, false], [15, 15, 11, 13, "named", "", false, false], [24, 26, 11, 13, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Although", "it", "was", "originally", "used", "to", "evaluate", "machine", "translations", ",", "the", "Bilingual", "Evaluation", "Double", "(", "BLEU", ")", "has", "also", "been", "successfully", "used", "to", "evaluate", "paraphrase", "generation", "models", "."], "sentence-detokenized": "Although it was originally used to evaluate machine translations, the Bilingual Evaluation Double (BLEU) has also been successfully used to evaluate paraphrase generation models.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 26], [27, 31], [32, 34], [35, 43], [44, 51], [52, 64], [64, 65], [66, 69], [70, 79], [80, 90], [91, 97], [98, 99], [99, 103], [103, 104], [105, 108], [109, 113], [114, 118], [119, 131], [132, 136], [137, 139], [140, 148], [149, 159], [160, 170], [171, 177], [177, 178]]}
{"doc_key": "ai-test-272", "ner": [[0, 0, "organisation"], [6, 8, "organisation"], [10, 12, "organisation"], [14, 14, "product"], [15, 16, "country"], [18, 18, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 8, "role", "licenses_to", false, false], [0, 0, 10, 12, "role", "licenses_to", false, false], [6, 8, 15, 16, "physical", "", false, false], [10, 12, 18, 18, "physical", "", false, false], [14, 14, 6, 8, "artifact", "produces", false, false], [14, 14, 10, 12, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "subsequently", "licensed", "its", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "which", "manufacture", "Unimates", "in", "Japan", "and", "England", "respectively", "."], "sentence-detokenized": "Unimation subsequently licensed its technology to Kawasaki Heavy Industries and GKN, which manufacture Unimates in Japan and England respectively.", "token2charspan": [[0, 9], [10, 22], [23, 31], [32, 35], [36, 46], [47, 49], [50, 58], [59, 64], [65, 75], [76, 79], [80, 83], [83, 84], [85, 90], [91, 102], [103, 111], [112, 114], [115, 120], [121, 124], [125, 132], [133, 145], [145, 146]]}
{"doc_key": "ai-test-273", "ner": [[20, 21, "conference"], [36, 37, "field"], [55, 59, "field"], [61, 61, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[36, 37, 55, 59, "compare", "", false, false], [61, 61, 55, 59, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "confusion", "between", "the", "two", "research", "communities", "(", "which", "often", "hold", "separate", "conferences", "and", "publish", "separate", "journals", ",", "ECML", "PKDD", "being", "a", "notable", "exception", ")", "stems", "from", "the", "underlying", "assumptions", "they", "make", ":", "in", "machine", "learning", ",", "performance", "is", "usually", "measured", "in", "terms", "of", "the", "ability", "to", "reconstruct", "known", "knowledge", ",", "while", "in", "knowledge", "discovery", "and", "data", "mining", "(", "KDD", ")", "the", "main", "task", "is", "to", "discover", "previously", "unknown", "knowledge", "."], "sentence-detokenized": "Much of the confusion between the two research communities (which often hold separate conferences and publish separate journals, ECML PKDD being a notable exception) stems from the underlying assumptions they make: in machine learning, performance is usually measured in terms of the ability to reconstruct known knowledge, while in knowledge discovery and data mining (KDD) the main task is to discover previously unknown knowledge.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 29], [30, 33], [34, 37], [38, 46], [47, 58], [59, 60], [60, 65], [66, 71], [72, 76], [77, 85], [86, 97], [98, 101], [102, 109], [110, 118], [119, 127], [127, 128], [129, 133], [134, 138], [139, 144], [145, 146], [147, 154], [155, 164], [164, 165], [166, 171], [172, 176], [177, 180], [181, 191], [192, 203], [204, 208], [209, 213], [213, 214], [215, 217], [218, 225], [226, 234], [234, 235], [236, 247], [248, 250], [251, 258], [259, 267], [268, 270], [271, 276], [277, 279], [280, 283], [284, 291], [292, 294], [295, 306], [307, 312], [313, 322], [322, 323], [324, 329], [330, 332], [333, 342], [343, 352], [353, 356], [357, 361], [362, 368], [369, 370], [370, 373], [373, 374], [375, 378], [379, 383], [384, 388], [389, 391], [392, 394], [395, 403], [404, 414], [415, 422], [423, 432], [432, 433]]}
{"doc_key": "ai-test-274", "ner": [[9, 10, "algorithm"], [2, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 2, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "modern", "automatic", "speech", "recognition", "systems", "are", "based", "on", "hidden", "Markov", "models", "."], "sentence-detokenized": "Most modern automatic speech recognition systems are based on hidden Markov models.", "token2charspan": [[0, 4], [5, 11], [12, 21], [22, 28], [29, 40], [41, 48], [49, 52], [53, 58], [59, 61], [62, 68], [69, 75], [76, 82], [82, 83]]}
{"doc_key": "ai-test-275", "ner": [[2, 2, "location"], [4, 6, "country"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 4, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": [",", "a", "Bangalore", ",", "India", "-", "based", "company", "specialising", "in", "online", "handwriting", "recognition", "software", "."], "sentence-detokenized": ", a Bangalore, India-based company specialising in online handwriting recognition software.", "token2charspan": [[0, 1], [2, 3], [4, 13], [13, 14], [15, 20], [20, 21], [21, 26], [27, 34], [35, 47], [48, 50], [51, 57], [58, 69], [70, 81], [82, 90], [90, 91]]}
{"doc_key": "ai-test-276", "ner": [[22, 23, "misc"], [50, 50, "metrics"], [52, 54, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[50, 50, 52, 54, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Do", "the", "repeated", "translations", "in", "both", "languages", "match", "one", "expression", "?", "I.e.", "does", "the", "method", "of", "translation", "show", "stationarity", "or", "produce", "a", "canonical", "form", "?", "Does", "the", "translation", "become", "stationary", "without", "losing", "the", "meaning", "of", "the", "original", "?", "This", "metric", "has", "been", "criticised", "because", "it", "does", "not", "correlate", "well", "with", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "scores", "."], "sentence-detokenized": "Do the repeated translations in both languages match one expression? I.e. does the method of translation show stationarity or produce a canonical form? Does the translation become stationary without losing the meaning of the original? This metric has been criticised because it does not correlate well with BLEU (BiLingual Evaluation Understudy) scores.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 28], [29, 31], [32, 36], [37, 46], [47, 52], [53, 56], [57, 67], [67, 68], [69, 73], [74, 78], [79, 82], [83, 89], [90, 92], [93, 104], [105, 109], [110, 122], [123, 125], [126, 133], [134, 135], [136, 145], [146, 150], [150, 151], [152, 156], [157, 160], [161, 172], [173, 179], [180, 190], [191, 198], [199, 205], [206, 209], [210, 217], [218, 220], [221, 224], [225, 233], [233, 234], [235, 239], [240, 246], [247, 250], [251, 255], [256, 266], [267, 274], [275, 277], [278, 282], [283, 286], [287, 296], [297, 301], [302, 306], [307, 311], [312, 313], [313, 322], [323, 333], [334, 344], [344, 345], [346, 352], [352, 353]]}
{"doc_key": "ai-test-277", "ner": [[6, 10, "organisation"], [15, 22, "organisation"], [12, 14, "university"], [24, 25, "university"], [27, 29, "field"], [32, 36, "organisation"], [39, 44, "organisation"], [50, 53, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[15, 22, 12, 14, "part-of", "", false, false], [24, 25, 27, 29, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "is", "a", "member", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", ",", "Stanford", "University", "'s", "Centre", "for", "Advanced", "Study", "in", "the", "Behavioural", "Sciences", ",", "MIT", "'s", "Centre", "for", "Cognitive", "Science", ",", "the", "Canadian", "Institute", "for", "Advanced", "Research", ",", "the", "Canadian", "Psychological", "Association", ",", "and", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "in", "1998", "."], "sentence-detokenized": "He is a member of the American Association for Artificial Intelligence, Stanford University's Centre for Advanced Study in the Behavioural Sciences, MIT's Centre for Cognitive Science, the Canadian Institute for Advanced Research, the Canadian Psychological Association, and was elected a Fellow of the Royal Society of Canada in 1998.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 42], [43, 46], [47, 57], [58, 70], [70, 71], [72, 80], [81, 91], [91, 93], [94, 100], [101, 104], [105, 113], [114, 119], [120, 122], [123, 126], [127, 138], [139, 147], [147, 148], [149, 152], [152, 154], [155, 161], [162, 165], [166, 175], [176, 183], [183, 184], [185, 188], [189, 197], [198, 207], [208, 211], [212, 220], [221, 229], [229, 230], [231, 234], [235, 243], [244, 257], [258, 269], [269, 270], [271, 274], [275, 278], [279, 286], [287, 288], [289, 295], [296, 298], [299, 302], [303, 308], [309, 316], [317, 319], [320, 326], [327, 329], [330, 334], [334, 335]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [17, 20, "misc"], [22, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 17, 20, "part-of", "", false, false], [0, 0, 22, 23, "part-of", "", false, false], [4, 5, 17, 20, "part-of", "", false, false], [4, 5, 22, 23, "part-of", "", false, false], [7, 8, 17, 20, "part-of", "", false, false], [7, 8, 22, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", ",", "along", "with", "Yoshua", "Bengio", "and", "Yann", "LeCun", ",", "are", "considered", "by", "some", "to", "be", "the", "godfathers", "of", "artificial", "intelligence", "and", "deep", "learning", "."], "sentence-detokenized": "Hinton, along with Yoshua Bengio and Yann LeCun, are considered by some to be the godfathers of artificial intelligence and deep learning.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 25], [26, 32], [33, 36], [37, 41], [42, 47], [47, 48], [49, 52], [53, 63], [64, 66], [67, 71], [72, 74], [75, 77], [78, 81], [82, 92], [93, 95], [96, 106], [107, 119], [120, 123], [124, 128], [129, 137], [137, 138]]}
{"doc_key": "ai-test-279", "ner": [[0, 1, "product"], [19, 19, "misc"], [21, 22, "misc"], [26, 26, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 19, 19, "related-to", "", false, false], [0, 1, 21, 22, "related-to", "", false, false], [19, 19, 26, 26, "named", "same", false, false], [28, 29, 26, 26, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "eSpeak", "project", ",", "a", "lightweight", "open", "-", "source", "language", "project", "with", "its", "own", "synthesis", "approach", ",", "experimented", "with", "Mandarin", "and", "Cantonese", ".", "May", "2010-2010", "\"", "eSpeak", "used", "Google", "Translate", "."], "sentence-detokenized": "The eSpeak project, a lightweight open-source language project with its own synthesis approach, experimented with Mandarin and Cantonese. May 2010-2010 \"eSpeak used Google Translate.", "token2charspan": [[0, 3], [4, 10], [11, 18], [18, 19], [20, 21], [22, 33], [34, 38], [38, 39], [39, 45], [46, 54], [55, 62], [63, 67], [68, 71], [72, 75], [76, 85], [86, 94], [94, 95], [96, 108], [109, 113], [114, 122], [123, 126], [127, 136], [136, 137], [138, 141], [142, 151], [152, 153], [153, 159], [160, 164], [165, 171], [172, 181], [181, 182]]}
{"doc_key": "ai-test-280", "ner": [[0, 2, "product"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 17, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Software", "Automatic", "Mouth", ",", "released", "in", "1982", ",", "was", "the", "first", "commercial", "fully", "software", "-", "based", "voice", "synthesis", "programme", "."], "sentence-detokenized": "Software Automatic Mouth, released in 1982, was the first commercial fully software-based voice synthesis programme.", "token2charspan": [[0, 8], [9, 18], [19, 24], [24, 25], [26, 34], [35, 37], [38, 42], [42, 43], [44, 47], [48, 51], [52, 57], [58, 68], [69, 74], [75, 83], [83, 84], [84, 89], [90, 95], [96, 105], [106, 115], [115, 116]]}
{"doc_key": "ai-test-281", "ner": [[4, 6, "metrics"], [8, 8, "metrics"], [13, 13, "metrics"], [15, 15, "metrics"], [18, 27, "metrics"], [28, 30, "metrics"], [32, 32, "metrics"], [35, 42, "metrics"], [45, 47, "metrics"], [49, 49, "metrics"], [54, 54, "metrics"], [56, 56, "metrics"], [59, 68, "metrics"], [69, 71, "metrics"], [73, 73, "metrics"], [76, 82, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[8, 8, 4, 6, "named", "", false, false], [13, 13, 4, 6, "named", "", false, false], [15, 15, 4, 6, "named", "", false, false], [18, 27, 4, 6, "named", "", false, false], [32, 32, 28, 30, "named", "", false, false], [35, 42, 28, 30, "named", "", false, false], [49, 49, 45, 47, "named", "", false, false], [54, 54, 45, 47, "named", "", false, false], [56, 56, 45, 47, "named", "", false, false], [59, 68, 45, 47, "named", "", false, false], [73, 73, 69, 71, "named", "", false, false], [76, 82, 69, 71, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["The", "column", "ratios", "are", "TRUE", "Positive", "Rate", "(", "TPR", ",", "also", "known", "as", "sensitivity", "or", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "plus", "FALSE", "Negative", "Rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "and", "TRUE", "Negative", "Rate", "(", "TNR", ",", "also", "known", "as", "specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "plus", "FALSE", "Positive", "Rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "The column ratios are TRUE Positive Rate (TPR, also known as sensitivity or recall) (TP / (TP + FN)), plus FALSE Negative Rate (FNR) (FN / (TP + FN)); and TRUE Negative Rate (TNR, also known as specificity, SPC) (TN / (TN + FP)), plus FALSE Positive Rate (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 21], [22, 26], [27, 35], [36, 40], [41, 42], [42, 45], [45, 46], [47, 51], [52, 57], [58, 60], [61, 72], [73, 75], [76, 82], [82, 83], [84, 85], [85, 87], [88, 89], [90, 91], [91, 93], [94, 95], [96, 98], [98, 99], [99, 100], [100, 101], [102, 106], [107, 112], [113, 121], [122, 126], [127, 128], [128, 131], [131, 132], [133, 134], [134, 136], [137, 138], [139, 140], [140, 142], [143, 144], [145, 147], [147, 148], [148, 149], [149, 150], [151, 154], [155, 159], [160, 168], [169, 173], [174, 175], [175, 178], [178, 179], [180, 184], [185, 190], [191, 193], [194, 205], [205, 206], [207, 210], [210, 211], [212, 213], [213, 215], [216, 217], [218, 219], [219, 221], [222, 223], [224, 226], [226, 227], [227, 228], [228, 229], [230, 234], [235, 240], [241, 249], [250, 254], [255, 256], [256, 259], [259, 260], [261, 262], [262, 264], [265, 266], [267, 268], [268, 270], [271, 272], [273, 275], [275, 276], [276, 277], [277, 278]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 15, 15, "role", "working_with", false, false], [2, 2, 15, 15, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "and", "Weber", "have", "also", "collaborated", "on", "many", "other", "robots", ",", "and", "their", "experience", "with", "Kismet"], "sentence-detokenized": "Edsinger and Weber have also collaborated on many other robots, and their experience with Kismet", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 28], [29, 41], [42, 44], [45, 49], [50, 55], [56, 62], [62, 63], [64, 67], [68, 73], [74, 84], [85, 89], [90, 96]]}
{"doc_key": "ai-test-283", "ner": [[0, 0, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 11, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["R", "functions", "are", "also", "available", "from", "several", "scripting", "languages", "such", "as", "Python", "."], "sentence-detokenized": "R functions are also available from several scripting languages such as Python.", "token2charspan": [[0, 1], [2, 11], [12, 15], [16, 20], [21, 30], [31, 35], [36, 43], [44, 53], [54, 63], [64, 68], [69, 71], [72, 78], [78, 79]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [10, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "was", "one", "of", "the", "first", "robot", "languages", "used", "in", "Unimate", "robots", "."], "sentence-detokenized": "VAL was one of the first robot languages used in Unimate robots.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 24], [25, 30], [31, 40], [41, 45], [46, 48], [49, 56], [57, 63], [63, 64]]}
{"doc_key": "ai-test-285", "ner": [[11, 16, "conference"], [18, 18, "conference"], [21, 22, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 16, 21, 22, "physical", "", false, false], [18, 18, 11, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["They", "first", "presented", "their", "database", "in", "a", "poster", "presentation", "at", "the", "2009", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "conference", "in", "Florida", "."], "sentence-detokenized": "They first presented their database in a poster presentation at the 2009 Computer Vision and Pattern Recognition (CVPR) conference in Florida.", "token2charspan": [[0, 4], [5, 10], [11, 20], [21, 26], [27, 35], [36, 38], [39, 40], [41, 47], [48, 60], [61, 63], [64, 67], [68, 72], [73, 81], [82, 88], [89, 92], [93, 100], [101, 112], [113, 114], [114, 118], [118, 119], [120, 130], [131, 133], [134, 141], [141, 142]]}
{"doc_key": "ai-test-286", "ner": [[0, 2, "misc"], [9, 10, "task"], [12, 13, "field"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 0, 2, "type-of", "", false, false], [12, 13, 0, 2, "type-of", "", false, false], [15, 16, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Categorisation", "tasks", "where", "no", "labels", "are", "provided", "are", "called", "unsupervised", "classification", ",", "unsupervised", "learning", ",", "cluster", "analysis", "."], "sentence-detokenized": "Categorisation tasks where no labels are provided are called unsupervised classification, unsupervised learning, cluster analysis.", "token2charspan": [[0, 14], [15, 20], [21, 26], [27, 29], [30, 36], [37, 40], [41, 49], [50, 53], [54, 60], [61, 73], [74, 88], [88, 89], [90, 102], [103, 111], [111, 112], [113, 120], [121, 129], [129, 130]]}
{"doc_key": "ai-test-287", "ner": [[3, 4, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "needs", "to", "recognise", "objects", ",", "recognise", "and", "locate", "people", "and", "further", "recognise", "emotions", "."], "sentence-detokenized": "It needs to recognise objects, recognise and locate people and further recognise emotions.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 21], [22, 29], [29, 30], [31, 40], [41, 44], [45, 51], [52, 58], [59, 62], [63, 70], [71, 80], [81, 89], [89, 90]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [8, 8, "misc"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "process", "is", "complex", "and", "involves", "encoding", "and", "recalling", "or", "reproducing", "."], "sentence-detokenized": "The process is complex and involves encoding and recalling or reproducing.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 26], [27, 35], [36, 44], [45, 48], [49, 58], [59, 61], [62, 73], [73, 74]]}
{"doc_key": "ai-test-289", "ner": [[10, 11, "product"], [15, 18, "product"], [32, 34, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 15, 18, "named", "", false, false], [10, 11, 32, 34, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "also", "known", "as", "parallel", "robots", "or", "generalised", "Stuart", "platforms", "(", "in", "a", "Stuart", "platform", ",", "the", "actuators", "are", "paired", "on", "both", "the", "base", "and", "the", "platform", ")", ",", "are", "articulated", "robots", "that", "use", "similar", "mechanisms", "to", "move", "either", "the", "base", "or", "one", "or", "more", "of", "the", "manipulator", "arms", "."], "sentence-detokenized": "These systems, also known as parallel robots or generalised Stuart platforms (in a Stuart platform, the actuators are paired on both the base and the platform), are articulated robots that use similar mechanisms to move either the base or one or more of the manipulator arms.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 25], [26, 28], [29, 37], [38, 44], [45, 47], [48, 59], [60, 66], [67, 76], [77, 78], [78, 80], [81, 82], [83, 89], [90, 98], [98, 99], [100, 103], [104, 113], [114, 117], [118, 124], [125, 127], [128, 132], [133, 136], [137, 141], [142, 145], [146, 149], [150, 158], [158, 159], [159, 160], [161, 164], [165, 176], [177, 183], [184, 188], [189, 192], [193, 200], [201, 211], [212, 214], [215, 219], [220, 226], [227, 230], [231, 235], [236, 238], [239, 242], [243, 245], [246, 250], [251, 253], [254, 257], [258, 269], [270, 274], [274, 275]]}
{"doc_key": "ai-test-290", "ner": [[0, 1, "field"], [5, 6, "field"], [13, 18, "field"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 5, 6, "part-of", "subfield", false, false], [0, 1, 13, 18, "compare", "", false, false], [13, 18, 21, 22, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "vision", ",", "as", "a", "systems", "engineering", "discipline", ",", "can", "be", "distinguished", "from", "computer", "vision", ",", "which", "is", "a", "form", "of", "computer", "science", "."], "sentence-detokenized": "Machine vision, as a systems engineering discipline, can be distinguished from computer vision, which is a form of computer science.", "token2charspan": [[0, 7], [8, 14], [14, 15], [16, 18], [19, 20], [21, 28], [29, 40], [41, 51], [51, 52], [53, 56], [57, 59], [60, 73], [74, 78], [79, 87], [88, 94], [94, 95], [96, 101], [102, 104], [105, 106], [107, 111], [112, 114], [115, 123], [124, 131], [131, 132]]}
{"doc_key": "ai-test-291", "ner": [[4, 7, "algorithm"], [10, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 7, 10, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "activation", "function", "of", "the", "LSTM", "gate", "is", "often", "a", "logistic", "sigmoid", "function", "."], "sentence-detokenized": "The activation function of the LSTM gate is often a logistic sigmoid function.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 26], [27, 30], [31, 35], [36, 40], [41, 43], [44, 49], [50, 51], [52, 60], [61, 68], [69, 77], [77, 78]]}
{"doc_key": "ai-test-292", "ner": [[5, 6, "metrics"], [18, 21, "metrics"], [23, 29, "metrics"], [31, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 18, 21, "named", "", false, false], [5, 6, 31, 33, "named", "", false, false], [23, 29, 18, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "a", "(", "necessarily", "unique", ")", "efficient", "estimator", "and", "hence", "a", "minimum", "variance", "unbiased", "estimator", "(", "MVUE", ")", ",", "and", "it", "is", "also", "a", "maximum", "likelihood", "estimator", "."], "sentence-detokenized": "In other words, the sample mean is a (necessarily unique) efficient estimator and hence a minimum variance unbiased estimator (MVUE), and it is also a maximum likelihood estimator.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 36], [37, 38], [38, 49], [50, 56], [56, 57], [58, 67], [68, 77], [78, 81], [82, 87], [88, 89], [90, 97], [98, 106], [107, 115], [116, 125], [126, 127], [127, 131], [131, 132], [132, 133], [134, 137], [138, 140], [141, 143], [144, 148], [149, 150], [151, 158], [159, 169], [170, 179], [179, 180]]}
{"doc_key": "ai-test-293", "ner": [[4, 5, "academicjournal"], [6, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [23, 23, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 23, 23, "topic", "", false, false], [4, 5, 26, 27, "topic", "", false, false], [6, 9, 4, 5, "role", "", false, false], [11, 12, 4, 5, "role", "", false, false], [14, 15, 4, 5, "role", "", false, false], [23, 23, 26, 27, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["A", "2001", "paper", "in", "Scientific", "American", "by", "Berners", "-", "Lee", ",", "James", "Hendler", "and", "Ora", "Lassila", "describes", "the", "expected", "evolution", "of", "the", "current", "web", "into", "the", "Semantic", "Web", "."], "sentence-detokenized": "A 2001 paper in Scientific American by Berners-Lee, James Hendler and Ora Lassila describes the expected evolution of the current web into the Semantic Web.", "token2charspan": [[0, 1], [2, 6], [7, 12], [13, 15], [16, 26], [27, 35], [36, 38], [39, 46], [46, 47], [47, 50], [50, 51], [52, 57], [58, 65], [66, 69], [70, 73], [74, 81], [82, 91], [92, 95], [96, 104], [105, 114], [115, 117], [118, 121], [122, 129], [130, 133], [134, 138], [139, 142], [143, 151], [152, 155], [155, 156]]}
{"doc_key": "ai-test-294", "ner": [[12, 15, "misc"], [17, 23, "person"], [30, 31, "person"]], "ner_mapping_to_source": [0, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "number", "of", "lesser", "-", "known", "actors", "at", "the", "time", "starred", "in", "The", "Razor", "Blade", "Runner", ":", "Sammon", ",", "pp.", "92-", "93", ".", "Sammon", ",", "pp.", "92", "-", "93", ".", "Nina", "Axelrod", "auditioned", "for", "the", "role", "."], "sentence-detokenized": "A number of lesser-known actors at the time starred in The Razor Blade Runner: Sammon, pp. 92-93. Sammon, pp. 92-93. Nina Axelrod auditioned for the role.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 18], [18, 19], [19, 24], [25, 31], [32, 34], [35, 38], [39, 43], [44, 51], [52, 54], [55, 58], [59, 64], [65, 70], [71, 77], [77, 78], [79, 85], [85, 86], [87, 90], [91, 94], [94, 96], [96, 97], [98, 104], [104, 105], [106, 109], [110, 112], [112, 113], [113, 115], [115, 116], [117, 121], [122, 129], [130, 140], [141, 144], [145, 148], [149, 153], [153, 154]]}
{"doc_key": "ai-test-295", "ner": [[3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 19, "researcher"], [15, 18, "university"], [24, 26, "product"], [28, 28, "product"], [34, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 4, 15, 18, "physical", "", false, false], [6, 7, 15, 18, "physical", "", false, false], [9, 10, 15, 18, "physical", "", false, false], [12, 19, 15, 18, "physical", "", false, false], [15, 18, 34, 34, "physical", "", true, false], [24, 26, 15, 18, "temporal", "", false, false], [28, 28, 15, 18, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1971", ",", "Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "and", "Terry", "Winograd", "visited", "the", "University", "of", "Edinburgh", "to", "spread", "the", "word", "about", "Micro", "-", "Planner", "and", "SHRDLU", ",", "and", "to", "question", "the", "Edinburgh", "logicians", "'", "basic", "method", "of", "uniform", "proof", "procedures", "."], "sentence-detokenized": "In 1971, Gerry Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited the University of Edinburgh to spread the word about Micro-Planner and SHRDLU, and to question the Edinburgh logicians' basic method of uniform proof procedures.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 22], [22, 23], [24, 30], [31, 39], [39, 40], [41, 48], [49, 55], [56, 59], [60, 65], [66, 74], [75, 82], [83, 86], [87, 97], [98, 100], [101, 110], [111, 113], [114, 120], [121, 124], [125, 129], [130, 135], [136, 141], [141, 142], [142, 149], [150, 153], [154, 160], [160, 161], [162, 165], [166, 168], [169, 177], [178, 181], [182, 191], [192, 201], [201, 202], [203, 208], [209, 215], [216, 218], [219, 226], [227, 232], [233, 243], [243, 244]]}
{"doc_key": "ai-test-296", "ner": [[0, 1, "researcher"], [7, 7, "field"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 11, 12, "role", "inspires", false, false], [0, 1, 14, 15, "role", "inspires", false, false], [0, 1, 17, 18, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Walter", "'s", "work", "inspired", "later", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work inspired later generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 22], [23, 28], [29, 40], [41, 43], [44, 52], [53, 64], [65, 69], [70, 72], [73, 79], [80, 86], [86, 87], [88, 92], [93, 100], [101, 104], [105, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-test-297", "ner": [[7, 7, "algorithm"], [10, 11, "researcher"], [17, 24, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 10, 11, "origin", "", false, false], [7, 7, 17, 24, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Subsequently", ",", "a", "similar", "GPU", "-", "based", "CNN", "developed", "by", "Alex", "Krizhevsky", "et", "al", ".", "won", "the", "2012", "ImageNet", "Large", "-", "Scale", "Visual", "Recognition", "Challenge", "."], "sentence-detokenized": "Subsequently, a similar GPU-based CNN developed by Alex Krizhevsky et al. won the 2012 ImageNet Large-Scale Visual Recognition Challenge.", "token2charspan": [[0, 12], [12, 13], [14, 15], [16, 23], [24, 27], [27, 28], [28, 33], [34, 37], [38, 47], [48, 50], [51, 55], [56, 66], [67, 69], [70, 72], [72, 73], [74, 77], [78, 81], [82, 86], [87, 95], [96, 101], [101, 102], [102, 107], [108, 114], [115, 126], [127, 136], [136, 137]]}
{"doc_key": "ai-test-298", "ner": [[0, 2, "misc"], [10, 12, "metrics"], [15, 16, "metrics"], [21, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 12, 0, 2, "type-of", "", false, false], [15, 16, 0, 2, "type-of", "", false, false], [15, 16, 21, 22, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "loss", "functions", "commonly", "used", "for", "probabilistic", "classification", "are", "the", "logarithmic", "loss", "function", "and", "the", "Brier", "score", "between", "the", "predicted", "and", "actual", "probability", "distribution", "."], "sentence-detokenized": "The loss functions commonly used for probabilistic classification are the logarithmic loss function and the Brier score between the predicted and actual probability distribution.", "token2charspan": [[0, 3], [4, 8], [9, 18], [19, 27], [28, 32], [33, 36], [37, 50], [51, 65], [66, 69], [70, 73], [74, 85], [86, 90], [91, 99], [100, 103], [104, 107], [108, 113], [114, 119], [120, 127], [128, 131], [132, 141], [142, 145], [146, 152], [153, 164], [165, 177], [177, 178]]}
{"doc_key": "ai-test-299", "ner": [[4, 4, "organisation"], [13, 13, "field"], [10, 10, "organisation"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 13, 13, "general-affiliation", "field_of_study", false, false], [4, 4, 17, 18, "part-of", "", false, false], [10, 10, 4, 4, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "May", "2016", ",", "NtechLab", "was", "accepted", "into", "an", "official", "NIST", "testing", "of", "biometric", "technologies", "among", "three", "Russian", "companies", "."], "sentence-detokenized": "In May 2016, NtechLab was accepted into an official NIST testing of biometric technologies among three Russian companies.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [22, 25], [26, 34], [35, 39], [40, 42], [43, 51], [52, 56], [57, 64], [65, 67], [68, 77], [78, 90], [91, 96], [97, 102], [103, 110], [111, 120], [120, 121]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "floating", "-", "point", "numbers", "only", "have", "a", "certain", "mathematical", "precision", "."], "sentence-detokenized": "However, floating-point numbers only have a certain mathematical precision.", "token2charspan": [[0, 7], [7, 8], [9, 17], [17, 18], [18, 23], [24, 31], [32, 36], [37, 41], [42, 43], [44, 51], [52, 64], [65, 74], [74, 75]]}
{"doc_key": "ai-test-301", "ner": [[4, 4, "organisation"], [10, 18, "conference"], [16, 16, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 10, 18, "role", "contributes_to", false, false], [16, 16, 10, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2015", ",", "many", "SenseTime", "papers", "were", "accepted", "for", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "conference", "."], "sentence-detokenized": "In 2015, many SenseTime papers were accepted for the Computer Vision and Pattern Recognition (CVPR) conference.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 13], [14, 23], [24, 30], [31, 35], [36, 44], [45, 48], [49, 52], [53, 61], [62, 68], [69, 72], [73, 80], [81, 92], [93, 94], [94, 98], [98, 99], [100, 110], [110, 111]]}
{"doc_key": "ai-test-302", "ner": [[5, 8, "task"], [10, 10, "task"], [13, 14, "task"], [16, 19, "task"], [22, 22, "field"], [55, 55, "misc"], [32, 35, "misc"], [36, 37, "conference"], [56, 56, "misc"], [59, 59, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10], "relations": [[5, 8, 22, 22, "part-of", "task_part_of_field", false, false], [10, 10, 5, 8, "named", "", false, false], [13, 14, 22, 22, "part-of", "task_part_of_field", false, false], [16, 19, 13, 14, "named", "", false, false], [32, 35, 36, 37, "temporal", "", false, false], [56, 56, 59, 59, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6], "sentence": ["He", "co-developed", "optimal", "algorithms", "for", "structure", "-from", "-", "motion", "(", "SFM", ",", "or", "visual", "SLAM", ",", "synchronous", "localisation", "and", "mapping", ",", "in", "Robotics", ";", "1998", ".", "He", "also", "described", "its", "ambiguity", "(", "David", "Marr", "Prize", "at", "ICCV", "1999", ")", ",", "as", "well", "as", "the", "recognizability", "and", "observability", "of", "fusion", "of", "visual", "and", "inertial", "sensors", "(", "Best", "Paper", "Award", ",", "Robotics", ",", "2015", ")", "."], "sentence-detokenized": "He co-developed optimal algorithms for structure-from-motion (SFM, or visual SLAM, synchronous localisation and mapping, in Robotics; 1998. He also described its ambiguity (David Marr Prize at ICCV 1999 ), as well as the recognizability and observability of fusion of visual and inertial sensors (Best Paper Award, Robotics, 2015).", "token2charspan": [[0, 2], [3, 15], [16, 23], [24, 34], [35, 38], [39, 48], [48, 53], [53, 54], [54, 60], [61, 62], [62, 65], [65, 66], [67, 69], [70, 76], [77, 81], [81, 82], [83, 94], [95, 107], [108, 111], [112, 119], [119, 120], [121, 123], [124, 132], [132, 133], [134, 138], [138, 139], [140, 142], [143, 147], [148, 157], [158, 161], [162, 171], [172, 173], [173, 178], [179, 183], [184, 189], [190, 192], [193, 197], [198, 202], [203, 204], [204, 205], [206, 208], [209, 213], [214, 216], [217, 220], [221, 236], [237, 240], [241, 254], [255, 257], [258, 264], [265, 267], [268, 274], [275, 278], [279, 287], [288, 295], [296, 297], [297, 301], [302, 307], [308, 313], [313, 314], [315, 323], [323, 324], [325, 329], [329, 330], [330, 331]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 11, "field"], [13, 14, "field"], [21, 22, "task"], [24, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 7, 8, "part-of", "task_part_of_field", false, false], [0, 1, 10, 11, "part-of", "task_part_of_field", false, false], [0, 1, 13, 14, "part-of", "task_part_of_field", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 24, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "a", "key", "tool", "in", "image", "processing", ",", "machine", "vision", "and", "computer", "vision", ",", "especially", "in", "the", "areas", "of", "feature", "detection", "and", "extraction", "."], "sentence-detokenized": "Edge detection is a key tool in image processing, machine vision and computer vision, especially in the areas of feature detection and extraction.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 19], [20, 23], [24, 28], [29, 31], [32, 37], [38, 48], [48, 49], [50, 57], [58, 64], [65, 68], [69, 77], [78, 84], [84, 85], [86, 96], [97, 99], [100, 103], [104, 109], [110, 112], [113, 120], [121, 130], [131, 134], [135, 145], [145, 146]]}
{"doc_key": "ai-test-305", "ner": [[10, 11, "misc"], [25, 28, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "example", "of", "this", "would", "be", "a", "variable", "such", "as", "outdoor", "temperature", "(", "mathtemp", "/", "math", ")", ",", "which", "in", "some", "cases", "can", "be", "recorded", "to", "several", "decimal", "places", "(", "depending", "on", "the", "sensor", "apparatus", ")", "."], "sentence-detokenized": "An example of this would be a variable such as outdoor temperature (mathtemp / math), which in some cases can be recorded to several decimal places (depending on the sensor apparatus).", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 18], [19, 24], [25, 27], [28, 29], [30, 38], [39, 43], [44, 46], [47, 54], [55, 66], [67, 68], [68, 76], [77, 78], [79, 83], [83, 84], [84, 85], [86, 91], [92, 94], [95, 99], [100, 105], [106, 109], [110, 112], [113, 121], [122, 124], [125, 132], [133, 140], [141, 147], [148, 149], [149, 158], [159, 161], [162, 165], [166, 172], [173, 182], [182, 183], [183, 184]]}
{"doc_key": "ai-test-306", "ner": [[4, 5, "person"], [7, 8, "person"], [10, 15, "person"], [19, 20, "person"], [22, 22, "misc"], [26, 26, "misc"], [28, 29, "person"], [31, 31, "organisation"], [33, 34, "person"], [37, 37, "organisation"], [39, 41, "person"], [42, 42, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[28, 29, 22, 22, "part-of", "", false, false], [28, 29, 26, 26, "role", "", false, false], [33, 34, 31, 31, "role", "", false, false], [39, 41, 37, 37, "role", "youtuber", false, false], [42, 42, 39, 41, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Returning", "as", "judges", "are", "Fon", "Davis", ",", "Jessica", "Chobot", "and", "Leland", "Melvin", ",", "as", "well", "as", "guest", "judges", "actor", "Clark", "Gregg", ",", "MythBusters", "host", "and", "former", "Battlebots", "builder", "Adam", "Savage", ",", "NFL", "player", "Vernon", "Davis", ",", "and", "YouTube", "star", "Michael", "Stevens", "aka", "Vsauce", "."], "sentence-detokenized": "Returning as judges are Fon Davis, Jessica Chobot and Leland Melvin, as well as guest judges actor Clark Gregg, MythBusters host and former Battlebots builder Adam Savage, NFL player Vernon Davis, and YouTube star Michael Stevens aka Vsauce.", "token2charspan": [[0, 9], [10, 12], [13, 19], [20, 23], [24, 27], [28, 33], [33, 34], [35, 42], [43, 49], [50, 53], [54, 60], [61, 67], [67, 68], [69, 71], [72, 76], [77, 79], [80, 85], [86, 92], [93, 98], [99, 104], [105, 110], [110, 111], [112, 123], [124, 128], [129, 132], [133, 139], [140, 150], [151, 158], [159, 163], [164, 170], [170, 171], [172, 175], [176, 182], [183, 189], [190, 195], [195, 196], [197, 200], [201, 208], [209, 213], [214, 221], [222, 229], [230, 233], [234, 240], [240, 241]]}
{"doc_key": "ai-test-307", "ner": [[10, 11, "algorithm"], [12, 16, "algorithm"], [18, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 18, 20, "part-of", "", false, false], [12, 16, 18, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "these", "methods", "have", "never", "overcome", "the", "non-uniform", "internal", "Gaussian", "mixture", "model", "/", "hidden", "Markov", "model", "(", "GMM", "-", "HMM", ")", "technique", "based", "on", "discriminatively", "trained", "generative", "language", "models", "."], "sentence-detokenized": "However, these methods have never overcome the non-uniform internal Gaussian mixture model/hidden Markov model (GMM-HMM) technique based on discriminatively trained generative language models.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 22], [23, 27], [28, 33], [34, 42], [43, 46], [47, 58], [59, 67], [68, 76], [77, 84], [85, 90], [90, 91], [91, 97], [98, 104], [105, 110], [111, 112], [112, 115], [115, 116], [116, 119], [119, 120], [121, 130], [131, 136], [137, 139], [140, 156], [157, 164], [165, 175], [176, 184], [185, 191], [191, 192]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "and", "SciPy", "provide", "convenient", "ways", "to", "apply", "these", "different", "methods", "."], "sentence-detokenized": "Software packages such as MATLAB, GNU Octave, Scilab and SciPy provide convenient ways to apply these different methods.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [53, 56], [57, 62], [63, 70], [71, 81], [82, 86], [87, 89], [90, 95], [96, 101], [102, 111], [112, 119], [119, 120]]}
{"doc_key": "ai-test-309", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [8, 9, "task"], [18, 19, "researcher"], [21, 22, "university"], [24, 25, "researcher"], [27, 30, "organisation"], [32, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 8, 9, "related-to", "", false, false], [0, 2, 18, 19, "origin", "", false, false], [0, 2, 24, 25, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [18, 19, 21, 22, "physical", "", false, false], [18, 19, 21, 22, "role", "", false, false], [24, 25, 27, 30, "physical", "", false, false], [24, 25, 27, 30, "role", "", false, false], [32, 32, 27, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Linear", "Predictive", "Coding", "(", "LPC", ")", ",", "a", "speech", "processing", "algorithm", ",", "was", "first", "proposed", "in", "1966", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "."], "sentence-detokenized": "Linear Predictive Coding (LPC), a speech processing algorithm, was first proposed in 1966 by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT).", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 72], [73, 81], [82, 84], [85, 89], [90, 92], [93, 101], [102, 109], [110, 112], [113, 119], [120, 130], [131, 134], [135, 140], [141, 146], [147, 149], [150, 156], [157, 166], [167, 170], [171, 180], [181, 182], [182, 185], [185, 186], [186, 187]]}
{"doc_key": "ai-test-310", "ner": [[12, 19, "conference"], [21, 24, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 24, 12, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2006", ",", "on", "the", "25th", "anniversary", "of", "the", "algorithm", ",", "the", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "held", "a", "workshop", "summarising", "recent", "contributions", "and", "variants", "of", "the", "original", "algorithm", ",", "mainly", "aimed", "at", "improving", "the", "speed", "of", "the", "algorithm", ",", "the", "robustness", "and", "accuracy", "of", "the", "estimated", "solutions", ",", "and", "the", "dependency", "on", "user", "defined", "constants", "."], "sentence-detokenized": "In 2006, on the 25th anniversary of the algorithm, the International Conference on Computer Vision and Pattern Recognition (CVPR) held a workshop summarising recent contributions and variants of the original algorithm, mainly aimed at improving the speed of the algorithm, the robustness and accuracy of the estimated solutions, and the dependency on user defined constants.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 20], [21, 32], [33, 35], [36, 39], [40, 49], [49, 50], [51, 54], [55, 68], [69, 79], [80, 82], [83, 91], [92, 98], [99, 102], [103, 110], [111, 122], [123, 124], [124, 128], [128, 129], [130, 134], [135, 136], [137, 145], [146, 157], [158, 164], [165, 178], [179, 182], [183, 191], [192, 194], [195, 198], [199, 207], [208, 217], [217, 218], [219, 225], [226, 231], [232, 234], [235, 244], [245, 248], [249, 254], [255, 257], [258, 261], [262, 271], [271, 272], [273, 276], [277, 287], [288, 291], [292, 300], [301, 303], [304, 307], [308, 317], [318, 327], [327, 328], [329, 332], [333, 336], [337, 347], [348, 350], [351, 355], [356, 363], [364, 373], [373, 374]]}
{"doc_key": "ai-test-311", "ner": [[4, 7, "university"], [10, 13, "organisation"], [15, 18, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Members", "have", "studied", "at", "the", "University", "of", "Debrecen", ",", "the", "Hungarian", "Academy", "of", "Sciences", ",", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "University", "and", "others", "."], "sentence-detokenized": "Members have studied at the University of Debrecen, the Hungarian Academy of Sciences, E\u00f6tv\u00f6s Lor\u00e1nd University and others.", "token2charspan": [[0, 7], [8, 12], [13, 20], [21, 23], [24, 27], [28, 38], [39, 41], [42, 50], [50, 51], [52, 55], [56, 65], [66, 73], [74, 76], [77, 85], [85, 86], [87, 93], [94, 100], [101, 111], [112, 115], [116, 122], [122, 123]]}
{"doc_key": "ai-test-312", "ner": [[5, 7, "algorithm"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "extend", "the", "application", "of", "SVM", "to", "cases", "where", "data", "are", "not", "linearly", "separable", ",", "we", "introduce", "a", "loss", "function", ","], "sentence-detokenized": "To extend the application of SVM to cases where data are not linearly separable, we introduce a loss function,", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 25], [26, 28], [29, 32], [33, 35], [36, 41], [42, 47], [48, 52], [53, 56], [57, 60], [61, 69], [70, 79], [79, 80], [81, 83], [84, 93], [94, 95], [96, 100], [101, 109], [109, 110]]}
{"doc_key": "ai-test-313", "ner": [[0, 1, "programlang"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 11, 12, "origin", "", false, false], [0, 1, 14, 15, "origin", "", false, false], [0, 1, 17, 18, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["\"", "Logo", "is", "an", "educational", "programming", "language", "developed", "in", "1967", "by", "Wally", "Feurzeig", ",", "Seymour", "Papert", "and", "Cynthia", "Solomon", "."], "sentence-detokenized": "\"Logo is an educational programming language developed in 1967 by Wally Feurzeig, Seymour Papert and Cynthia Solomon.", "token2charspan": [[0, 1], [1, 5], [6, 8], [9, 11], [12, 23], [24, 35], [36, 44], [45, 54], [55, 57], [58, 62], [63, 65], [66, 71], [72, 80], [80, 81], [82, 89], [90, 96], [97, 100], [101, 108], [109, 116], [116, 117]]}
{"doc_key": "ai-test-314", "ner": [[0, 4, "organisation"], [7, 12, "organisation"], [13, 16, "location"], [18, 18, "location"], [20, 20, "location"], [32, 38, "product"], [45, 51, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 4, 7, 12, "role", "works_for", false, false], [7, 12, 13, 16, "physical", "", false, false], [13, 16, 18, 18, "physical", "", false, false], [18, 18, 20, 20, "physical", "", false, false], [32, 38, 0, 4, "origin", "", false, false], [45, 51, 32, 38, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["\"", "The", "Eyring", "Research", "Institute", "helped", "the", "US", "Air", "Force", "Missile", "Directorate", "at", "Hilo", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", ",", "to", "develop", ",", "under", "the", "highest", "military", "secrecy", ",", "the", "advanced", "systems", "technology", "software", "that", "was", "the", "basis", "of", "what", "was", "later", "dubbed", "Reagan", "'s", "\"", "Star", "Wars", "\"", "programme", "."], "sentence-detokenized": "\"The Eyring Research Institute helped the US Air Force Missile Directorate at Hilo Air Force Base near Ogden, Utah, to develop, under the highest military secrecy, the advanced systems technology software that was the basis of what was later dubbed Reagan's \"Star Wars\" programme.", "token2charspan": [[0, 1], [1, 4], [5, 11], [12, 20], [21, 30], [31, 37], [38, 41], [42, 44], [45, 48], [49, 54], [55, 62], [63, 74], [75, 77], [78, 82], [83, 86], [87, 92], [93, 97], [98, 102], [103, 108], [108, 109], [110, 114], [114, 115], [116, 118], [119, 126], [126, 127], [128, 133], [134, 137], [138, 145], [146, 154], [155, 162], [162, 163], [164, 167], [168, 176], [177, 184], [185, 195], [196, 204], [205, 209], [210, 213], [214, 217], [218, 223], [224, 226], [227, 231], [232, 235], [236, 241], [242, 248], [249, 255], [255, 257], [258, 259], [259, 263], [264, 268], [268, 269], [270, 279], [279, 280]]}
{"doc_key": "ai-test-315", "ner": [[12, 13, "field"], [24, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Over", "several", "decades", ",", "he", "has", "explored", "and", "developed", "new", "areas", "of", "computer", "science", ",", "ranging", "from", "compilers", ",", "programming", "languages", "and", "system", "architecture", "John", "F", ".", "Sowa", "and", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "Over several decades, he has explored and developed new areas of computer science, ranging from compilers, programming languages and system architecture John F. Sowa and John Zachman (1992).", "token2charspan": [[0, 4], [5, 12], [13, 20], [20, 21], [22, 24], [25, 28], [29, 37], [38, 41], [42, 51], [52, 55], [56, 61], [62, 64], [65, 73], [74, 81], [81, 82], [83, 90], [91, 95], [96, 105], [105, 106], [107, 118], [119, 128], [129, 132], [133, 139], [140, 152], [153, 157], [158, 159], [159, 160], [161, 165], [166, 169], [170, 174], [175, 182], [183, 184], [184, 188], [188, 189], [189, 190]]}
{"doc_key": "ai-test-316", "ner": [[0, 2, "algorithm"], [7, 10, "algorithm"], [13, 16, "algorithm"], [19, 20, "field"], [22, 25, "field"], [27, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 10, 0, 2, "named", "", false, false], [13, 16, 0, 2, "named", "", false, false], [19, 20, 0, 2, "usage", "", false, false], [22, 25, 0, 2, "usage", "", false, false], [27, 31, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Sobel", "operator", ",", "sometimes", "called", "the", "Sobel", "-", "Feldman", "operator", "or", "the", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "especially", "in", "edge", "detection", "algorithms", ",", "to", "create", "an", "image", "that", "emphasises", "edges", "."], "sentence-detokenized": "The Sobel operator, sometimes called the Sobel-Feldman operator or the Sobel filter, is used in image processing and computer vision, especially in edge detection algorithms, to create an image that emphasises edges.", "token2charspan": [[0, 3], [4, 9], [10, 18], [18, 19], [20, 29], [30, 36], [37, 40], [41, 46], [46, 47], [47, 54], [55, 63], [64, 66], [67, 70], [71, 76], [77, 83], [83, 84], [85, 87], [88, 92], [93, 95], [96, 101], [102, 112], [113, 116], [117, 125], [126, 132], [132, 133], [134, 144], [145, 147], [148, 152], [153, 162], [163, 173], [173, 174], [175, 177], [178, 184], [185, 187], [188, 193], [194, 198], [199, 209], [210, 215], [215, 216]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [3, 4, "field"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 4, "compare", "", false, false], [0, 0, 3, 4, "type-of", "", false, false], [0, 0, 12, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "is", "a", "supervised", "learning", "algorithm", "that", "uses", "data", "labels", ",", "while", "PCA", "is", "a", "learning", "algorithm", "that", "ignores", "labels", "."], "sentence-detokenized": "LDA is a supervised learning algorithm that uses data labels, while PCA is a learning algorithm that ignores labels.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 19], [20, 28], [29, 38], [39, 43], [44, 48], [49, 53], [54, 60], [60, 61], [62, 67], [68, 71], [72, 74], [75, 76], [77, 85], [86, 95], [96, 100], [101, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "linear", "classification", "algorithms", "include", "Winnow", ",", "support", "vector", "machine", "and", "logistic", "regression", "."], "sentence-detokenized": "Other linear classification algorithms include Winnow, support vector machine and logistic regression.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 38], [39, 46], [47, 53], [53, 54], [55, 62], [63, 69], [70, 77], [78, 81], [82, 90], [91, 101], [101, 102]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [6, 7, "programlang"], [17, 19, "product"], [21, 21, "programlang"], [23, 23, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 7, "general-affiliation", "", true, false], [0, 0, 17, 19, "general-affiliation", "", true, false], [0, 0, 21, 21, "general-affiliation", "", true, false], [0, 0, 23, 23, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "consists", "of", "a", "library", "of", "C", "++", "classes", "and", "several", "layers", "of", "interpreted", "interfaces", ",", "including", "Tcl", "/", "Tk", ",", "Java", "and", "Python", "."], "sentence-detokenized": "VTK consists of a library of C++ classes and several layers of interpreted interfaces, including Tcl/Tk, Java and Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 17], [18, 25], [26, 28], [29, 30], [30, 32], [33, 40], [41, 44], [45, 52], [53, 59], [60, 62], [63, 74], [75, 85], [85, 86], [87, 96], [97, 100], [100, 101], [101, 103], [103, 104], [105, 109], [110, 113], [114, 120], [120, 121]]}
{"doc_key": "ai-test-320", "ner": [[15, 17, "task"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", ",", "there", "is", "processing", "noise", "in", "text", "produced", "by", "processing", "spontaneous", "speech", "using", "automatic", "speech", "recognition", "and", "printed", "or", "handwritten", "text", "using", "optical", "character", "recognition", "."], "sentence-detokenized": "In addition, there is processing noise in text produced by processing spontaneous speech using automatic speech recognition and printed or handwritten text using optical character recognition.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 18], [19, 21], [22, 32], [33, 38], [39, 41], [42, 46], [47, 55], [56, 58], [59, 69], [70, 81], [82, 88], [89, 94], [95, 104], [105, 111], [112, 123], [124, 127], [128, 135], [136, 138], [139, 150], [151, 155], [156, 161], [162, 169], [170, 179], [180, 191], [191, 192]]}
{"doc_key": "ai-test-321", "ner": [[0, 0, "researcher"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 10, 10, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "has", "written", "several", "books", "and", "led", "the", "development", "of", "WordNet", ",", "an", "online", "database", "of", "word", "interfaces", "available", "to", "computer", "programs", "."], "sentence-detokenized": "Miller has written several books and led the development of WordNet, an online database of word interfaces available to computer programs.", "token2charspan": [[0, 6], [7, 10], [11, 18], [19, 26], [27, 32], [33, 36], [37, 40], [41, 44], [45, 56], [57, 59], [60, 67], [67, 68], [69, 71], [72, 78], [79, 87], [88, 90], [91, 95], [96, 106], [107, 116], [117, 119], [120, 128], [129, 137], [137, 138]]}
{"doc_key": "ai-test-322", "ner": [[1, 1, "field"], [5, 7, "organisation"], [8, 11, "country"], [13, 14, "person"], [16, 18, "person"], [20, 21, "person"], [23, 26, "person"], [27, 28, "country"], [30, 33, "location"], [34, 37, "misc"], [38, 39, "person"], [41, 42, "person"], [43, 44, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[5, 7, 8, 11, "physical", "", false, false], [13, 14, 27, 28, "physical", "", false, false], [16, 18, 27, 28, "physical", "", false, false], [20, 21, 27, 28, "physical", "", false, false], [23, 26, 27, 28, "physical", "", false, false], [30, 33, 1, 1, "general-affiliation", "", false, false], [30, 33, 38, 39, "artifact", "", false, false], [34, 37, 38, 39, "named", "", false, false], [41, 42, 43, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Contemporary", "automata", "are", "represented", "by", "Cabaret", "Mechanical", "Theatre", "in", "the", "United", "Kingdom", ",", "Dug", "North", "and", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "in", "the", "United", "States", ",", "Le", "D\u00e9fenseur", "du", "Temps", "by", "the", "French", "artist", "Jacques", "Monestier", "and", "Fran\u00e7ois", "Junod", "in", "Switzerland", "."], "sentence-detokenized": "Contemporary automata are represented by Cabaret Mechanical Theatre in the United Kingdom, Dug North and Chomick + Meder, Arthur Ganson, Joe Jones in the United States, Le D\u00e9fenseur du Temps by the French artist Jacques Monestier and Fran\u00e7ois Junod in Switzerland.", "token2charspan": [[0, 12], [13, 21], [22, 25], [26, 37], [38, 40], [41, 48], [49, 59], [60, 67], [68, 70], [71, 74], [75, 81], [82, 89], [89, 90], [91, 94], [95, 100], [101, 104], [105, 112], [113, 114], [115, 120], [120, 121], [122, 128], [129, 135], [135, 136], [137, 140], [141, 146], [147, 149], [150, 153], [154, 160], [161, 167], [167, 168], [169, 171], [172, 181], [182, 184], [185, 190], [191, 193], [194, 197], [198, 204], [205, 211], [212, 219], [220, 229], [230, 233], [234, 242], [243, 248], [249, 251], [252, 263], [263, 264]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 21, 21, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "has", "standard", "codefor", "/", "code", "and", "codewhile", "/", "code", "loops", ",", "but", "(", "as", "in", "other", "similar", "programs", "such", "as", "R", ")", "encourages", "the", "use", "of", "vector", "notation", ",", "which", "is", "often", "faster", "."], "sentence-detokenized": "MATLAB has standard codefor/code and codewhile/code loops, but (as in other similar programs such as R) encourages the use of vector notation, which is often faster.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 27], [27, 28], [28, 32], [33, 36], [37, 46], [46, 47], [47, 51], [52, 57], [57, 58], [59, 62], [63, 64], [64, 66], [67, 69], [70, 75], [76, 83], [84, 92], [93, 97], [98, 100], [101, 102], [102, 103], [104, 114], [115, 118], [119, 122], [123, 125], [126, 132], [133, 141], [141, 142], [143, 148], [149, 151], [152, 157], [158, 164], [164, 165]]}
{"doc_key": "ai-test-324", "ner": [[0, 3, "researcher"], [8, 12, "conference"], [17, 18, "field"], [21, 24, "misc"], [27, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 21, 24, "win-defeat", "", false, false], [0, 3, 27, 36, "win-defeat", "", false, false], [21, 24, 8, 12, "temporal", "", false, false], [21, 24, 17, 18, "topic", "", false, false], [27, 36, 8, 12, "temporal", "", false, false], [27, 36, 17, 18, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2007", ",", "Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "for", "his", "achievements", "in", "computing", "education", ":", "the", "Karlstrom", "Outstanding", "Educator", "Award", "and", "the", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contribution", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "In 2007, Pausch received two awards from the Association for Computing Machinery for his achievements in computing education: the Karlstrom Outstanding Educator Award and the ACM SIGCSE Award for Outstanding Contribution to Computer Science Education.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 24], [25, 28], [29, 35], [36, 40], [41, 44], [45, 56], [57, 60], [61, 70], [71, 80], [81, 84], [85, 88], [89, 101], [102, 104], [105, 114], [115, 124], [124, 125], [126, 129], [130, 139], [140, 151], [152, 160], [161, 166], [167, 170], [171, 174], [175, 178], [179, 185], [186, 191], [192, 195], [196, 207], [208, 220], [221, 223], [224, 232], [233, 240], [241, 250], [250, 251]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [8, 8, "product"], [9, 12, "product"], [15, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 8, "role", "sells", false, false], [8, 8, 9, 12, "general-affiliation", "", false, false], [8, 8, 15, 18, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 86], [87, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-test-326", "ner": [[0, 1, "algorithm"], [5, 7, "field"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 1, "usage", "", false, false], [11, 12, 5, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantic", "networks", "are", "used", "in", "natural", "language", "processing", "applications", "such", "as", "semantic", "parsing", "."], "sentence-detokenized": "Semantic networks are used in natural language processing applications such as semantic parsing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 26], [27, 29], [30, 37], [38, 46], [47, 57], [58, 70], [71, 75], [76, 78], [79, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-327", "ner": [[4, 5, "field"], [7, 8, "field"], [10, 11, "task"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 8, 4, 5, "usage", "", false, false], [10, 11, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Some", "successful", "applications", "of", "deep", "learning", "are", "computer", "vision", "and", "speech", "recognition", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Some successful applications of deep learning are computer vision and speech recognition. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 31], [32, 36], [37, 45], [46, 49], [50, 58], [59, 65], [66, 69], [70, 76], [77, 88], [88, 89], [90, 97], [98, 101], [101, 102], [103, 108], [109, 115], [115, 116], [117, 123], [124, 133], [133, 134], [135, 141], [142, 143], [143, 144], [145, 147], [147, 148]]}
{"doc_key": "ai-test-328", "ner": [[5, 10, "product"], [16, 16, "misc"], [19, 22, "misc"], [25, 25, "product"], [29, 30, "task"], [32, 33, "task"], [35, 36, "task"], [38, 40, "field"], [42, 44, "task"], [46, 47, "field"], [50, 51, "task"], [54, 55, "task"], [57, 59, "task"], [61, 62, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[5, 10, 16, 16, "physical", "travels_to", false, false], [5, 10, 19, 22, "physical", "travels_to", false, false], [25, 25, 5, 10, "part-of", "", false, false], [25, 25, 5, 10, "role", "maintains", false, false], [25, 25, 29, 30, "related-to", "has_ability_to", false, false], [25, 25, 32, 33, "related-to", "has_ability_to", false, false], [25, 25, 35, 36, "related-to", "has_ability_to", false, false], [25, 25, 38, 40, "related-to", "has_ability_to", false, false], [25, 25, 42, 44, "related-to", "has_ability_to", false, false], [25, 25, 46, 47, "related-to", "has_ability_to", false, false], [25, 25, 50, 51, "related-to", "has_ability_to", false, false], [25, 25, 54, 55, "related-to", "has_ability_to", false, false], [25, 25, 57, 59, "related-to", "has_ability_to", false, false], [25, 25, 61, 62, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "addition", "to", "maintaining", "the", "systems", "of", "the", "Discovery", "One", "spacecraft", "during", "its", "interplanetary", "mission", "to", "Jupiter", "(", "or", "Saturn", "in", "the", "novel", ")", ",", "HAL", "is", "able", "to", "synthesise", "speech", ",", "recognise", "speech", ",", "recognise", "faces", ",", "process", "natural", "language", ",", "lip", "-", "read", ",", "appreciate", "art", ",", "perform", "affective", "calculations", ",", "perform", "automated", "reasoning", ",", "pilot", "a", "spacecraft", "and", "play", "chess", "."], "sentence-detokenized": "In addition to maintaining the systems of the Discovery One spacecraft during its interplanetary mission to Jupiter (or Saturn in the novel), HAL is able to synthesise speech, recognise speech, recognise faces, process natural language, lip-read, appreciate art, perform affective calculations, perform automated reasoning, pilot a spacecraft and play chess.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 38], [39, 41], [42, 45], [46, 55], [56, 59], [60, 70], [71, 77], [78, 81], [82, 96], [97, 104], [105, 107], [108, 115], [116, 117], [117, 119], [120, 126], [127, 129], [130, 133], [134, 139], [139, 140], [140, 141], [142, 145], [146, 148], [149, 153], [154, 156], [157, 167], [168, 174], [174, 175], [176, 185], [186, 192], [192, 193], [194, 203], [204, 209], [209, 210], [211, 218], [219, 226], [227, 235], [235, 236], [237, 240], [240, 241], [241, 245], [245, 246], [247, 257], [258, 261], [261, 262], [263, 270], [271, 280], [281, 293], [293, 294], [295, 302], [303, 312], [313, 322], [322, 323], [324, 329], [330, 331], [332, 342], [343, 346], [347, 351], [352, 357], [357, 358]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [4, 4, "country"], [7, 8, "country"], [12, 12, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 4, "physical", "", false, false], [0, 1, 7, 8, "physical", "", false, false], [0, 1, 12, 12, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr", "Julesz", "emigrated", "from", "Hungary", "to", "the", "United", "States", "after", "the", "1956", "Soviet", "invasion", "."], "sentence-detokenized": "Dr Julesz emigrated from Hungary to the United States after the 1956 Soviet invasion.", "token2charspan": [[0, 2], [3, 9], [10, 19], [20, 24], [25, 32], [33, 35], [36, 39], [40, 46], [47, 53], [54, 59], [60, 63], [64, 68], [69, 75], [76, 84], [84, 85]]}
{"doc_key": "ai-test-330", "ner": [[0, 2, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sigmoid", "activation", "functions", "use", "a", "second", "nonlinearity", "for", "large", "inputs", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+\\", "exp", "(", "-", "v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "Sigmoid activation functions use a second nonlinearity for large inputs: math\\ phi (v _ i) = (1 +\\ exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 7], [8, 18], [19, 28], [29, 32], [33, 34], [35, 41], [42, 54], [55, 58], [59, 64], [65, 71], [71, 72], [73, 77], [77, 78], [79, 82], [83, 84], [84, 85], [86, 87], [88, 89], [89, 90], [91, 92], [93, 94], [94, 95], [96, 98], [99, 102], [103, 104], [104, 105], [105, 106], [107, 108], [109, 110], [110, 111], [111, 112], [113, 114], [115, 116], [116, 118], [118, 119], [120, 121], [122, 126], [126, 127]]}
{"doc_key": "ai-test-331", "ner": [[13, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "probabilities", "are", "used", "to", "determine", "who", "the", "target", "is", ",", "using", "a", "maximum", "likelihood", "solution", "."], "sentence-detokenized": "These probabilities are used to determine who the target is, using a maximum likelihood solution.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 45], [46, 49], [50, 56], [57, 59], [59, 60], [61, 66], [67, 68], [69, 76], [77, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-332", "ner": [[4, 11, "university"], [12, 15, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "moved", "to", "the", "University", "of", "Konstanz", "in", "1984", "and", "to", "the", "University", "of", "Salzburg", "in", "1990", "."], "sentence-detokenized": "He moved to the University of Konstanz in 1984 and to the University of Salzburg in 1990.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 15], [16, 26], [27, 29], [30, 38], [39, 41], [42, 46], [47, 50], [51, 53], [54, 57], [58, 68], [69, 71], [72, 80], [81, 83], [84, 88], [88, 89]]}
{"doc_key": "ai-test-333", "ner": [[7, 8, "metrics"], [11, 13, "metrics"], [15, 17, "metrics"], [19, 19, "metrics"], [21, 22, "metrics"], [24, 26, "metrics"], [30, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 13, 7, 8, "origin", "based_on", false, false], [15, 17, 7, 8, "origin", "based_on", false, false], [19, 19, 7, 8, "origin", "based_on", false, false], [21, 22, 7, 8, "origin", "based_on", false, false], [24, 26, 7, 8, "origin", "based_on", false, false], [30, 35, 7, 8, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Some", "popular", "validation", "functions", "based", "on", "the", "confusion", "matrix", "are", ":", "sensitivity", "/", "specificity", ",", "recall", "/", "accuracy", ",", "F-matrix", ",", "Jaccard", "similarity", ",", "Matthews", "correlation", "coefficient", ",", "and", "the", "cost", "/", "gain", "matrix", ",", "which", "combines", "the", "costs", "and", "gains", "attributed", "to", "4", "different", "types", "of", "classification", "."], "sentence-detokenized": "Some popular validation functions based on the confusion matrix are: sensitivity/specificity, recall/accuracy, F-matrix, Jaccard similarity, Matthews correlation coefficient, and the cost/gain matrix, which combines the costs and gains attributed to 4 different types of classification.", "token2charspan": [[0, 4], [5, 12], [13, 23], [24, 33], [34, 39], [40, 42], [43, 46], [47, 56], [57, 63], [64, 67], [67, 68], [69, 80], [80, 81], [81, 92], [92, 93], [94, 100], [100, 101], [101, 109], [109, 110], [111, 119], [119, 120], [121, 128], [129, 139], [139, 140], [141, 149], [150, 161], [162, 173], [173, 174], [175, 178], [179, 182], [183, 187], [187, 188], [188, 192], [193, 199], [199, 200], [201, 206], [207, 215], [216, 219], [220, 225], [226, 229], [230, 235], [236, 246], [247, 249], [250, 251], [252, 261], [262, 267], [268, 270], [271, 285], [285, 286]]}
{"doc_key": "ai-test-334", "ner": [[6, 6, "product"], [8, 8, "product"], [10, 10, "product"], [12, 12, "product"], [15, 16, "programlang"], [27, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[27, 29, 6, 6, "part-of", "", false, false], [27, 29, 8, 8, "part-of", "", false, false], [27, 29, 10, 10, "part-of", "", false, false], [27, 29, 12, 12, "part-of", "", false, false], [27, 29, 15, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Common", "numerical", "programming", "environments", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "and", "the", "R", "language", "provide", "some", "of", "the", "simpler", "feature", "extraction", "methods", "(", "e.g.", "principal", "component", "analysis", ")", "using", "integrated", "commands", "."], "sentence-detokenized": "Common numerical programming environments such as MATLAB, SciLab, NumPy, Sklearn and the R language provide some of the simpler feature extraction methods (e.g. principal component analysis) using integrated commands.", "token2charspan": [[0, 6], [7, 16], [17, 28], [29, 41], [42, 46], [47, 49], [50, 56], [56, 57], [58, 64], [64, 65], [66, 71], [71, 72], [73, 80], [81, 84], [85, 88], [89, 90], [91, 99], [100, 107], [108, 112], [113, 115], [116, 119], [120, 127], [128, 135], [136, 146], [147, 154], [155, 156], [156, 160], [161, 170], [171, 180], [181, 189], [189, 190], [191, 196], [197, 207], [208, 216], [216, 217]]}
{"doc_key": "ai-test-335", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "were", "introduced", "to", "work", "with", "humans", "in", "industrial", "production", "tasks", "."], "sentence-detokenized": "Industrial robots were introduced to work with humans in industrial production tasks.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 33], [34, 36], [37, 41], [42, 46], [47, 53], [54, 56], [57, 67], [68, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-test-336", "ner": [[6, 6, "field"], [8, 11, "researcher"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 18, 19, "related-to", "", false, false], [6, 6, 21, 22, "related-to", "", false, false], [6, 6, 24, 25, "related-to", "", false, false], [8, 11, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "first", "published", "article", "on", "CG", ",", "John", "F", ".", "Sowa", "applied", "it", "to", "various", "topics", "in", "artificial", "intelligence", ",", "computer", "science", "and", "cognitive", "science", "."], "sentence-detokenized": "In his first published article on CG, John F. Sowa applied it to various topics in artificial intelligence, computer science and cognitive science.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [23, 30], [31, 33], [34, 36], [36, 37], [38, 42], [43, 44], [44, 45], [46, 50], [51, 58], [59, 61], [62, 64], [65, 72], [73, 79], [80, 82], [83, 93], [94, 106], [106, 107], [108, 116], [117, 124], [125, 128], [129, 138], [139, 146], [146, 147]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [4, 5, "metrics"], [8, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 5, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "by", "calculating", "a", "penalty", "for", "brevity", ",", "as", "small", "differences", "in", "translation", "length", "do", "not", "have", "such", "a", "large", "impact", "on", "the", "overall", "score", "."], "sentence-detokenized": "NIST also differs from BLEU by calculating a penalty for brevity, as small differences in translation length do not have such a large impact on the overall score.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 42], [43, 44], [45, 52], [53, 56], [57, 64], [64, 65], [66, 68], [69, 74], [75, 86], [87, 89], [90, 101], [102, 108], [109, 111], [112, 115], [116, 120], [121, 125], [126, 127], [128, 133], [134, 140], [141, 143], [144, 147], [148, 155], [156, 161], [161, 162]]}
{"doc_key": "ai-test-338", "ner": [[0, 8, "misc"], [16, 16, "conference"], [12, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 8, 16, 16, "temporal", "", false, false], [0, 8, 12, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "IJCAI", "Award", "for", "Research", "Excellence", "is", "a", "biennial", "award", "given", "to", "AI", "researchers", "at", "the", "IJCAI", "conference", "to", "recognise", "excellence", "in", "their", "careers", "."], "sentence-detokenized": "The IJCAI Award for Research Excellence is a biennial award given to AI researchers at the IJCAI conference to recognise excellence in their careers.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 28], [29, 39], [40, 42], [43, 44], [45, 53], [54, 59], [60, 65], [66, 68], [69, 71], [72, 83], [84, 86], [87, 90], [91, 96], [97, 107], [108, 110], [111, 120], [121, 131], [132, 134], [135, 140], [141, 148], [148, 149]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [6, 6, "conference"], [17, 23, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 6, "role", "", false, false], [0, 0, 17, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "was", "one", "of", "the", "first", "AAAI", "Fellows", "and", "is", "the", "only", "person", "to", "serve", "on", "the", "scientific", "advisory", "boards", "of", "Microsoft", "and", "Apple", "."], "sentence-detokenized": "Lenat was one of the first AAAI Fellows and is the only person to serve on the scientific advisory boards of Microsoft and Apple.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 16], [17, 20], [21, 26], [27, 31], [32, 39], [40, 43], [44, 46], [47, 50], [51, 55], [56, 62], [63, 65], [66, 71], [72, 74], [75, 78], [79, 89], [90, 98], [99, 105], [106, 108], [109, 118], [119, 122], [123, 128], [128, 129]]}
{"doc_key": "ai-test-340", "ner": [[0, 0, "algorithm"], [5, 6, "misc"], [9, 15, "metrics"], [19, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "related-to", "minimise", false, false], [9, 15, 5, 6, "type-of", "", false, false], [19, 19, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autocoders", "are", "trained", "to", "minimise", "reconstruction", "errors", "(", "e.g.", "root", "mean", "square", "error", ")", ",", "often", "referred", "to", "as", "losses", ":"], "sentence-detokenized": "Autocoders are trained to minimise reconstruction errors (e.g. root mean square error), often referred to as losses:", "token2charspan": [[0, 10], [11, 14], [15, 22], [23, 25], [26, 34], [35, 49], [50, 56], [57, 58], [58, 62], [63, 67], [68, 72], [73, 79], [80, 85], [85, 86], [86, 87], [88, 93], [94, 102], [103, 105], [106, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-341", "ner": [[29, 32, "misc"], [34, 34, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[34, 34, 29, 32, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "to", "using", "definitions", "is", "to", "take", "into", "account", "the", "common", "affinity", "of", "word", "meanings", "and", "calculate", "the", "similarity", "of", "each", "pair", "of", "word", "meanings", "based", "on", "some", "lexical", "knowledge", "base", "such", "as", "WordNet", "."], "sentence-detokenized": "An alternative to using definitions is to take into account the common affinity of word meanings and calculate the similarity of each pair of word meanings based on some lexical knowledge base such as WordNet.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 23], [24, 35], [36, 38], [39, 41], [42, 46], [47, 51], [52, 59], [60, 63], [64, 70], [71, 79], [80, 82], [83, 87], [88, 96], [97, 100], [101, 110], [111, 114], [115, 125], [126, 128], [129, 133], [134, 138], [139, 141], [142, 146], [147, 155], [156, 161], [162, 164], [165, 169], [170, 177], [178, 187], [188, 192], [193, 197], [198, 200], [201, 208], [208, 209]]}
{"doc_key": "ai-test-342", "ner": [[0, 2, "algorithm"], [9, 12, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 12, "origin", "", false, false], [9, 12, 17, 18, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "invented", "by", "Richard", "S.", "Sutton", "based", "on", "earlier", "work", "by", "Arthur", "Samuel", "on", "learning", "from", "time", "differences", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm invented by Richard S. Sutton based on earlier work by Arthur Samuel on learning from time differences.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 42], [43, 45], [46, 53], [54, 56], [57, 63], [64, 69], [70, 72], [73, 80], [81, 85], [86, 88], [89, 95], [96, 102], [103, 105], [106, 114], [115, 119], [120, 124], [125, 136], [136, 137]]}
{"doc_key": "ai-test-343", "ner": [[1, 2, "field"], [4, 4, "field"], [6, 7, "task"], [12, 14, "task"], [16, 18, "task"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 1, 2, "part-of", "task_part_of_field", false, false], [6, 7, 4, 4, "part-of", "task_part_of_field", false, false], [12, 14, 6, 7, "named", "", false, false], [16, 18, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "data", "mining", "and", "statistics", ",", "hierarchical", "clustering", "(", "also", "known", "as", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "cluster", "analysis", "method", "that", "aims", "to", "create", "a", "hierarchy", "of", "clusters", "."], "sentence-detokenized": "In data mining and statistics, hierarchical clustering (also known as hierarchical cluster analysis or HCA) is a cluster analysis method that aims to create a hierarchy of clusters.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 29], [29, 30], [31, 43], [44, 54], [55, 56], [56, 60], [61, 66], [67, 69], [70, 82], [83, 90], [91, 99], [100, 102], [103, 106], [106, 107], [108, 110], [111, 112], [113, 120], [121, 129], [130, 136], [137, 141], [142, 146], [147, 149], [150, 156], [157, 158], [159, 168], [169, 171], [172, 180], [180, 181]]}
{"doc_key": "ai-test-344", "ner": [[3, 4, "algorithm"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "concept", "of", "deconvolution", "is", "widely", "used", "in", "signal", "processing", "and", "image", "processing", "techniques", "."], "sentence-detokenized": "The concept of deconvolution is widely used in signal processing and image processing techniques.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 53], [54, 64], [65, 68], [69, 74], [75, 85], [86, 96], [96, 97]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [17, 18, "misc"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 17, 18, "related-to", "enhances", false, false], [0, 1, 17, 18, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "help", "to", "create", "and", "store", "spatial", "knowledge", ",", "allowing", "mental", "visualisation", "of", "images", "to", "reduce", "cognitive", "load", ",", "improve", "recall", "and", "learning", "."], "sentence-detokenized": "Cognitive maps help to create and store spatial knowledge, allowing mental visualisation of images to reduce cognitive load, improve recall and learning.", "token2charspan": [[0, 9], [10, 14], [15, 19], [20, 22], [23, 29], [30, 33], [34, 39], [40, 47], [48, 57], [57, 58], [59, 67], [68, 74], [75, 88], [89, 91], [92, 98], [99, 101], [102, 108], [109, 118], [119, 123], [123, 124], [125, 132], [133, 139], [140, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-test-346", "ner": [[6, 6, "programlang"], [8, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "interfaces", "to", "languages", "such", "as", "Python", ",", "C", "++", ",", "Java", "are", "usually", "provided", ")", "."], "sentence-detokenized": ", interfaces to languages such as Python, C++, Java are usually provided).", "token2charspan": [[0, 1], [2, 12], [13, 15], [16, 25], [26, 30], [31, 33], [34, 40], [40, 41], [42, 43], [43, 45], [45, 46], [47, 51], [52, 55], [56, 63], [64, 72], [72, 73], [73, 74]]}
{"doc_key": "ai-test-347", "ner": [[0, 3, "product"], [5, 5, "product"], [15, 16, "task"], [22, 24, "task"], [28, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 15, 16, "usage", "", false, false], [0, 3, 22, 24, "usage", "", false, false], [0, 3, 28, 33, "usage", "", false, false], [5, 5, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Voice", "User", "Interface", "(", "VUI", ")", "enables", "spoken", "human", "interaction", "with", "computers", ",", "using", "speech", "recognition", "to", "understand", "spoken", "commands", "and", "answers", "to", "questions", ",", "and", "plain", "text", "-", "to", "-", "speech", "to", "reproduce", "the", "response", "."], "sentence-detokenized": "The Voice User Interface (VUI) enables spoken human interaction with computers, using speech recognition to understand spoken commands and answers to questions, and plain text-to-speech to reproduce the response.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 24], [25, 26], [26, 29], [29, 30], [31, 38], [39, 45], [46, 51], [52, 63], [64, 68], [69, 78], [78, 79], [80, 85], [86, 92], [93, 104], [105, 107], [108, 118], [119, 125], [126, 134], [135, 138], [139, 146], [147, 149], [150, 159], [159, 160], [161, 164], [165, 170], [171, 175], [175, 176], [176, 178], [178, 179], [179, 185], [186, 188], [189, 198], [199, 202], [203, 211], [211, 212]]}
{"doc_key": "ai-test-348", "ner": [[0, 1, "programlang"], [4, 5, "misc"], [8, 8, "programlang"], [12, 15, "researcher"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 4, 5, "general-affiliation", "is_a", false, false], [0, 1, 8, 8, "general-affiliation", "made_with", false, false], [0, 1, 12, 15, "origin", "", false, false], [12, 15, 17, 18, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["\"", "Jess", "is", "a", "rule", "engine", "for", "the", "Java", "platform", "developed", "by", "Ernest", "Friedman", "-", "Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "\"Jess is a rule engine for the Java platform developed by Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 1], [1, 5], [6, 8], [9, 10], [11, 15], [16, 22], [23, 26], [27, 30], [31, 35], [36, 44], [45, 54], [55, 57], [58, 64], [65, 73], [73, 74], [74, 78], [79, 81], [82, 88], [89, 97], [97, 98]]}
{"doc_key": "ai-test-349", "ner": [[4, 7, "algorithm"], [20, 25, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 7, 20, 25, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "the", "case", "of", "multilayer", "perceptrons", ",", "where", "there", "is", "a", "hidden", "layer", ",", "more", "sophisticated", "algorithms", ",", "such", "as", "back", "-", "propagation", ",", "are", "needed", "."], "sentence-detokenized": "In the case of multilayer perceptrons, where there is a hidden layer, more sophisticated algorithms, such as back-propagation, are needed.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 25], [26, 37], [37, 38], [39, 44], [45, 50], [51, 53], [54, 55], [56, 62], [63, 68], [68, 69], [70, 74], [75, 88], [89, 99], [99, 100], [101, 105], [106, 108], [109, 113], [113, 114], [114, 125], [125, 126], [127, 130], [131, 137], [137, 138]]}
{"doc_key": "ai-test-350", "ner": [[0, 3, "product"], [4, 7, "product"], [11, 19, "algorithm"], [23, 27, "field"], [28, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 7, 0, 3, "part-of", "", false, false], [4, 7, 11, 19, "usage", "", false, true], [11, 19, 23, 27, "related-to", "performs", false, false], [28, 33, 23, 27, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["\"", "Google", "Translate", "'s", "neural", "machine", "translation", "system", "uses", "a", "large", "end", "-", "to", "-", "end", "artificial", "neural", "network", "that", "attempts", "to", "perform", "deep", "learning", ",", "in", "particular", "long", "short", "-", "term", "memory", "networks", "."], "sentence-detokenized": "\"Google Translate's neural machine translation system uses a large end-to-end artificial neural network that attempts to perform deep learning, in particular long short-term memory networks.", "token2charspan": [[0, 1], [1, 7], [8, 17], [17, 19], [20, 26], [27, 34], [35, 46], [47, 53], [54, 58], [59, 60], [61, 66], [67, 70], [70, 71], [71, 73], [73, 74], [74, 77], [78, 88], [89, 95], [96, 103], [104, 108], [109, 117], [118, 120], [121, 128], [129, 133], [134, 142], [142, 143], [144, 146], [147, 157], [158, 162], [163, 168], [168, 169], [169, 173], [174, 180], [181, 189], [189, 190]]}
{"doc_key": "ai-test-351", "ner": [[7, 7, "researcher"], [9, 9, "researcher"], [11, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "1970s", "and", "early", "1990s", ",", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "and", "others", "developed", "various", "approaches", "."], "sentence-detokenized": "In the 1970s and early 1990s, Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter and others developed various approaches.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 16], [17, 22], [23, 28], [28, 29], [30, 36], [36, 37], [38, 46], [46, 47], [48, 56], [56, 57], [58, 64], [65, 76], [76, 77], [78, 82], [83, 93], [93, 94], [95, 106], [107, 110], [111, 117], [118, 127], [128, 135], [136, 146], [146, 147]]}
{"doc_key": "ai-test-352", "ner": [[1, 1, "organisation"], [2, 3, "organisation"], [8, 9, "organisation"], [16, 17, "task"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 8, 9, "role", "licenses_from", false, false], [2, 3, 1, 1, "named", "", false, false], [14, 14, 1, 1, "origin", "", false, false], [14, 14, 16, 17, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc", "originally", "licensed", "software", "from", "Nuance", "to", "enable", "its", "digital", "assistant", "Siri", "to", "recognise", "speech", "."], "sentence-detokenized": "| Apple Apple Inc originally licensed software from Nuance to enable its digital assistant Siri to recognise speech.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 17], [18, 28], [29, 37], [38, 46], [47, 51], [52, 58], [59, 61], [62, 68], [69, 72], [73, 80], [81, 90], [91, 95], [96, 98], [99, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [4, 5, "misc"], [8, 9, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 5, "role", "releases_movies_in_genre", false, false], [8, 9, 0, 0, "role", "directs_for", false, false], [13, 14, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "has", "released", "several", "3D", "westerns", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia has released several 3D westerns produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 29], [30, 32], [33, 41], [42, 50], [51, 53], [54, 57], [58, 65], [66, 69], [70, 78], [79, 81], [82, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-test-354", "ner": [[9, 10, "field"], [12, 12, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "covers", "knowledge", "and", "research", "in", "the", "fields", "of", "computer", "science", ",", "linguistics", "and", "computer", "engineering", "."], "sentence-detokenized": "It covers knowledge and research in the fields of computer science, linguistics and computer engineering.", "token2charspan": [[0, 2], [3, 9], [10, 19], [20, 23], [24, 32], [33, 35], [36, 39], [40, 46], [47, 49], [50, 58], [59, 66], [66, 67], [68, 79], [80, 83], [84, 92], [93, 104], [104, 105]]}
{"doc_key": "ai-test-355", "ner": [[5, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", "is", "an", "example", "of", "R", "code", ":"], "sentence-detokenized": "Here is an example of R code:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 23], [24, 28], [28, 29]]}
{"doc_key": "ai-test-356", "ner": [[0, 2, "metrics"], [8, 10, "metrics"], [12, 12, "metrics"], [16, 18, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 8, 10, "part-of", "plotted_into", false, false], [0, 2, 16, 18, "part-of", "plotted_into", false, false], [12, 12, 8, 10, "named", "", false, false], [20, 20, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "ROC", "curve", "is", "generated", "by", "plotting", "the", "TRUE", "positive", "rate", "(", "TPR", ")", "and", "the", "FALSE", "positive", "rate", "(", "FPR", ")", "at", "different", "threshold", "settings", "."], "sentence-detokenized": "The ROC curve is generated by plotting the TRUE positive rate (TPR) and the FALSE positive rate (FPR) at different threshold settings.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 26], [27, 29], [30, 38], [39, 42], [43, 47], [48, 56], [57, 61], [62, 63], [63, 66], [66, 67], [68, 71], [72, 75], [76, 81], [82, 90], [91, 95], [96, 97], [97, 100], [100, 101], [102, 104], [105, 114], [115, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-test-357", "ner": [[0, 3, "field"], [6, 7, "researcher"], [9, 10, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 3, "related-to", "researches_field", false, false], [9, 10, 0, 3, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Research", "on", "machine", "learning", "stopped", "after", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", ","], "sentence-detokenized": "Research on machine learning stopped after Marvin Minsky and Seymour Papert (1969),", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 28], [29, 36], [37, 42], [43, 49], [50, 56], [57, 60], [61, 68], [69, 75], [76, 77], [77, 81], [81, 82], [82, 83]]}
{"doc_key": "ai-test-358", "ner": [[6, 6, "task"], [9, 10, "programlang"], [12, 14, "product"], [16, 17, "programlang"], [19, 19, "product"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 9, 10, "related-to", "used_to_build", false, false], [6, 6, 12, 14, "related-to", "used_to_build", false, false], [6, 6, 16, 17, "related-to", "used_to_build", false, false], [6, 6, 19, 19, "related-to", "used_to_build", false, false], [6, 6, 21, 21, "related-to", "used_to_build", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "programming", "environments", "used", "to", "develop", "DAQ", "applications", "include", "Stair", "Logic", ",", "Visual", "C", "++", ",", "Visual", "Basic", ",", "LabVIEW", "and", "MATLAB", "."], "sentence-detokenized": "Other programming environments used to develop DAQ applications include Stair Logic, Visual C++, Visual Basic, LabVIEW and MATLAB.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 38], [39, 46], [47, 50], [51, 63], [64, 71], [72, 77], [78, 83], [83, 84], [85, 91], [92, 93], [93, 95], [95, 96], [97, 103], [104, 109], [109, 110], [111, 118], [119, 122], [123, 129], [129, 130]]}
{"doc_key": "ai-test-359", "ner": [[16, 17, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "metric", "has", "been", "developed", "to", "overcome", "some", "of", "the", "problems", "associated", "with", "the", "more", "popular", "BLEU", "metric", "and", "to", "ensure", "a", "good", "correlation", "with", "human", "judgement", "at", "sentence", "or", "segment", "level", "."], "sentence-detokenized": "This metric has been developed to overcome some of the problems associated with the more popular BLEU metric and to ensure a good correlation with human judgement at sentence or segment level.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 30], [31, 33], [34, 42], [43, 47], [48, 50], [51, 54], [55, 63], [64, 74], [75, 79], [80, 83], [84, 88], [89, 96], [97, 101], [102, 108], [109, 112], [113, 115], [116, 122], [123, 124], [125, 129], [130, 141], [142, 146], [147, 152], [153, 162], [163, 165], [166, 174], [175, 177], [178, 185], [186, 191], [191, 192]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "-", "term", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "the", "semantic", "links", "between", "successive", "video", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long-term short-term memory are often used to exploit the semantic links between successive video frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [82, 83], [83, 87], [88, 93], [93, 94], [94, 98], [99, 105], [106, 109], [110, 115], [116, 120], [121, 123], [124, 131], [132, 135], [136, 144], [145, 150], [151, 158], [159, 169], [170, 175], [176, 182], [182, 183]]}
{"doc_key": "ai-test-361", "ner": [[7, 9, "product"], [14, 19, "product"], [23, 23, "product"], [43, 43, "product"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[23, 23, 14, 19, "part-of", "", false, false]], "relations_mapping_to_source": [3], "sentence": ["Mass", "-", "produced", "printed", "circuit", "boards", "(", "PCBs", ")", "are", "almost", "exclusively", "made", "using", "pick", "-", "and", "-", "place", "robots", ",", "usually", "with", "SCARA", "manipulators", ",", "which", "take", "small", "electronic", "components", "out", "of", "strips", "or", "trays", "and", "place", "them", "very", "precisely", "on", "the", "PCB", "."], "sentence-detokenized": "Mass-produced printed circuit boards (PCBs) are almost exclusively made using pick-and-place robots, usually with SCARA manipulators, which take small electronic components out of strips or trays and place them very precisely on the PCB.", "token2charspan": [[0, 4], [4, 5], [5, 13], [14, 21], [22, 29], [30, 36], [37, 38], [38, 42], [42, 43], [44, 47], [48, 54], [55, 66], [67, 71], [72, 77], [78, 82], [82, 83], [83, 86], [86, 87], [87, 92], [93, 99], [99, 100], [101, 108], [109, 113], [114, 119], [120, 132], [132, 133], [134, 139], [140, 144], [145, 150], [151, 161], [162, 172], [173, 176], [177, 179], [180, 186], [187, 189], [190, 195], [196, 199], [200, 205], [206, 210], [211, 215], [216, 225], [226, 228], [229, 232], [233, 236], [236, 237]]}
{"doc_key": "ai-test-362", "ner": [[4, 5, "field"], [15, 15, "algorithm"], [22, 23, "researcher"], [25, 26, "researcher"], [28, 31, "researcher"], [36, 37, "algorithm"], [38, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 4, 5, "part-of", "", false, false], [15, 15, 22, 23, "origin", "", false, false], [15, 15, 25, 26, "origin", "", false, false], [15, 15, 28, 31, "origin", "", false, false], [15, 15, 36, 37, "type-of", "", false, false], [36, 37, 38, 40, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "context", "of", "machine", "learning", ",", "where", "it", "is", "most", "widely", "used", "today", ",", "LDA", "was", "discovered", "independently", "in", "2003", "by", "David", "Blei", ",", "Andrew", "Ng", "and", "Michael", "I", ".", "Jordan", "and", "presented", "as", "a", "graphical", "model", "for", "topic", "discovery", "."], "sentence-detokenized": "In the context of machine learning, where it is most widely used today, LDA was discovered independently in 2003 by David Blei, Andrew Ng and Michael I. Jordan and presented as a graphical model for topic discovery.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 25], [26, 34], [34, 35], [36, 41], [42, 44], [45, 47], [48, 52], [53, 59], [60, 64], [65, 70], [70, 71], [72, 75], [76, 79], [80, 90], [91, 104], [105, 107], [108, 112], [113, 115], [116, 121], [122, 126], [126, 127], [128, 134], [135, 137], [138, 141], [142, 149], [150, 151], [151, 152], [153, 159], [160, 163], [164, 173], [174, 176], [177, 178], [179, 188], [189, 194], [195, 198], [199, 204], [205, 214], [214, 215]]}
{"doc_key": "ai-test-363", "ner": [[3, 3, "task"], [10, 10, "misc"], [6, 8, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[3, 3, 10, 10, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "eight", "na\u00efve", "WSI", "test", "data", "measurements", "for", "the", "different", "tauopathies", "yielded", "scores", "of", "0.92", ",", "0.72", "and", "0.81", "respectively", "."], "sentence-detokenized": "The eight na\u00efve WSI test data measurements for the different tauopathies yielded scores of 0.92, 0.72 and 0.81 respectively.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 24], [25, 29], [30, 42], [43, 46], [47, 50], [51, 60], [61, 72], [73, 80], [81, 87], [88, 90], [91, 95], [95, 96], [97, 101], [102, 105], [106, 110], [111, 123], [123, 124]]}
{"doc_key": "ai-test-364", "ner": [[2, 2, "field"], [6, 7, "field"], [9, 9, "field"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 9, 9, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Using", "advanced", "AR", "technologies", "(", "e.g.", "computer", "vision", ",", "AR", "cameras", "on", "smartphones", "and", "object", "recognition", ")", ",", "information", "about", "the", "real", "world", "around", "the", "user", "becomes", "interactive", "and", "digitally", "manipulated", "."], "sentence-detokenized": "Using advanced AR technologies (e.g. computer vision, AR cameras on smartphones and object recognition), information about the real world around the user becomes interactive and digitally manipulated.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 30], [31, 32], [32, 36], [37, 45], [46, 52], [52, 53], [54, 56], [57, 64], [65, 67], [68, 79], [80, 83], [84, 90], [91, 102], [102, 103], [103, 104], [105, 116], [117, 122], [123, 126], [127, 131], [132, 137], [138, 144], [145, 148], [149, 153], [154, 161], [162, 173], [174, 177], [178, 187], [188, 199], [199, 200]]}
{"doc_key": "ai-test-365", "ner": [[3, 3, "researcher"], [5, 7, "organisation"], [13, 13, "field"], [23, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 5, 7, "role", "forms_company", false, false], [5, 7, 13, 13, "related-to", "works_with", false, false], [5, 7, 23, 25, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2014", ",", "Schmidhuber", "founded", "Nnaisense", ",", "which", "worked", "on", "commercial", "applications", "of", "AI", "in", "areas", "such", "as", "finance", ",", "heavy", "industry", "and", "self", "-", "driving", "cars", "."], "sentence-detokenized": "In 2014, Schmidhuber founded Nnaisense, which worked on commercial applications of AI in areas such as finance, heavy industry and self-driving cars.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 28], [29, 38], [38, 39], [40, 45], [46, 52], [53, 55], [56, 66], [67, 79], [80, 82], [83, 85], [86, 88], [89, 94], [95, 99], [100, 102], [103, 110], [110, 111], [112, 117], [118, 126], [127, 130], [131, 135], [135, 136], [136, 143], [144, 148], [148, 149]]}
{"doc_key": "ai-test-366", "ner": [[24, 29, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "not", "only", "alters", "the", "results", "of", "all", "subsequent", "tests", "with", "the", "retained", "explanatory", "model", ",", "but", "can", "also", "introduce", "bias", "and", "change", "the", "mean", "square", "error", "of", "the", "estimate", "."], "sentence-detokenized": "This not only alters the results of all subsequent tests with the retained explanatory model, but can also introduce bias and change the mean square error of the estimate.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 20], [21, 24], [25, 32], [33, 35], [36, 39], [40, 50], [51, 56], [57, 61], [62, 65], [66, 74], [75, 86], [87, 92], [92, 93], [94, 97], [98, 101], [102, 106], [107, 116], [117, 121], [122, 125], [126, 132], [133, 136], [137, 141], [142, 148], [149, 154], [155, 157], [158, 161], [162, 170], [170, 171]]}
{"doc_key": "ai-test-367", "ner": [[0, 0, "misc"], [6, 6, "algorithm"], [7, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 0, 0, "usage", "", false, false], [6, 6, 7, 7, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Bigrams", "are", "used", "in", "most", "successful", "speech", "recognition", "models", "."], "sentence-detokenized": "Bigrams are used in most successful speech recognition models.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 24], [25, 35], [36, 42], [43, 54], [55, 61], [61, 62]]}
{"doc_key": "ai-test-368", "ner": [[3, 5, "field"], [13, 14, "misc"], [21, 23, "misc"], [9, 15, "organisation"], [34, 38, "misc"], [29, 32, "organisation"], [42, 46, "misc"], [47, 51, "organisation"], [62, 66, "misc"], [58, 61, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[13, 14, 3, 5, "topic", "", false, false], [21, 23, 9, 15, "origin", "", false, false], [34, 38, 29, 32, "origin", "", false, false], [42, 46, 47, 51, "origin", "", false, false], [62, 66, 58, 61, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["His", "research", "in", "cognitive", "psychology", "has", "earned", "him", "the", "American", "Psychological", "Association", "'s", "Early", "Career", "Award", "(", "1984", ")", "and", "the", "Boyd", "McCandless", "Award", "(", "1986", ")", ",", "the", "National", "Academy", "of", "Sciences", "'", "Troland", "Research", "Award", "(", "1993", ")", ",", "the", "Henry", "Dale", "Prize", "of", "the", "Royal", "Institution", "of", "Great", "Britain", "(", "2004", ")", ",", "and", "the", "Cognitive", "Neuroscience", "Society", "'s", "George", "Miller", "Prize", "(", "2010", ")", "."], "sentence-detokenized": "His research in cognitive psychology has earned him the American Psychological Association's Early Career Award (1984) and the Boyd McCandless Award (1986), the National Academy of Sciences' Troland Research Award (1993), the Henry Dale Prize of the Royal Institution of Great Britain (2004), and the Cognitive Neuroscience Society's George Miller Prize (2010).", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 25], [26, 36], [37, 40], [41, 47], [48, 51], [52, 55], [56, 64], [65, 78], [79, 90], [90, 92], [93, 98], [99, 105], [106, 111], [112, 113], [113, 117], [117, 118], [119, 122], [123, 126], [127, 131], [132, 142], [143, 148], [149, 150], [150, 154], [154, 155], [155, 156], [157, 160], [161, 169], [170, 177], [178, 180], [181, 189], [189, 190], [191, 198], [199, 207], [208, 213], [214, 215], [215, 219], [219, 220], [220, 221], [222, 225], [226, 231], [232, 236], [237, 242], [243, 245], [246, 249], [250, 255], [256, 267], [268, 270], [271, 276], [277, 284], [285, 286], [286, 290], [290, 291], [291, 292], [293, 296], [297, 300], [301, 310], [311, 323], [324, 331], [331, 333], [334, 340], [341, 347], [348, 353], [354, 355], [355, 359], [359, 360], [360, 361]]}
{"doc_key": "ai-test-369", "ner": [[0, 0, "misc"], [6, 8, "misc"], [9, 9, "product"], [13, 13, "researcher"], [15, 15, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"], [27, 29, "task"], [31, 34, "researcher"], [36, 40, "researcher"], [41, 42, "task"], [44, 44, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[0, 0, 6, 8, "named", "", false, false], [0, 0, 44, 44, "named", "", false, false], [6, 8, 13, 13, "origin", "", false, false], [6, 8, 15, 15, "origin", "", false, false], [6, 8, 27, 29, "related-to", "used_for", false, false], [9, 9, 6, 8, "usage", "", false, false], [9, 9, 41, 42, "named", "", false, false], [22, 23, 6, 8, "usage", "", false, false], [22, 23, 31, 34, "named", "same", false, false], [25, 26, 6, 8, "usage", "", false, false], [25, 26, 36, 40, "named", "same", false, false], [41, 42, 44, 44, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Eigenface", "(", "The", "method", "of", "using", "eigenfaces", "in", "face", "recognition", "was", "developed", "by", "Sirovich", "and", "Kirby", "(", "1987", ")", "and", "used", "by", "Matthew", "Turk", "and", "Alex", "Pentland", "for", "face", "classification", ".", "Turk", ",", "Matthew", "A", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "Eigenface (The method of using eigenfaces in face recognition was developed by Sirovich and Kirby (1987) and used by Matthew Turk and Alex Pentland for face classification. Turk, Matthew A and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 9], [10, 11], [11, 14], [15, 21], [22, 24], [25, 30], [31, 41], [42, 44], [45, 49], [50, 61], [62, 65], [66, 75], [76, 78], [79, 87], [88, 91], [92, 97], [98, 99], [99, 103], [103, 104], [105, 108], [109, 113], [114, 116], [117, 124], [125, 129], [130, 133], [134, 138], [139, 147], [148, 151], [152, 156], [157, 171], [171, 172], [173, 177], [177, 178], [179, 186], [187, 188], [189, 192], [193, 201], [201, 202], [203, 207], [208, 209], [209, 210], [211, 215], [216, 227], [228, 233], [234, 244], [244, 245]]}
{"doc_key": "ai-test-370", "ner": [[5, 14, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "lexical", "dictionary", "such", "as", "Word", "Net", "can", "then", "be", "used", "to", "understand", "the", "context", "."], "sentence-detokenized": "A lexical dictionary such as WordNet can then be used to understand the context.", "token2charspan": [[0, 1], [2, 9], [10, 20], [21, 25], [26, 28], [29, 33], [33, 36], [37, 40], [41, 45], [46, 48], [49, 53], [54, 56], [57, 67], [68, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-test-371", "ner": [[0, 0, "misc"], [7, 7, "misc"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 7, 7, "part-of", "", false, false], [7, 7, 13, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hyponymy", "is", "a", "commonly", "encoded", "relationship", "between", "syntaxes", "used", "in", "lexical", "databases", "like", "WordNet", "."], "sentence-detokenized": "Hyponymy is a commonly encoded relationship between syntaxes used in lexical databases like WordNet.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 22], [23, 30], [31, 43], [44, 51], [52, 60], [61, 65], [66, 68], [69, 76], [77, 86], [87, 91], [92, 99], [99, 100]]}
{"doc_key": "ai-test-372", "ner": [[0, 1, "organisation"], [8, 9, "programlang"], [11, 11, "programlang"], [40, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 8, 9, "general-affiliation", "", false, false], [0, 1, 11, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["\"", "OPeNDAP", "offers", "open", "-", "source", "libraries", "in", "C", "++", "and", "Java", ",", "but", "many", "customers", "rely", "on", "community", "-", "developed", "libraries", ",", "e.g.", "the", "libraries", "have", "built", "-", "in", "capabilities", "to", "retrieve", "(", "array", "-", "type", ")", "data", "from", "DAP", "servers", "."], "sentence-detokenized": "\"OPeNDAP offers open-source libraries in C++ and Java, but many customers rely on community-developed libraries, e.g. the libraries have built-in capabilities to retrieve (array-type) data from DAP servers.", "token2charspan": [[0, 1], [1, 8], [9, 15], [16, 20], [20, 21], [21, 27], [28, 37], [38, 40], [41, 42], [42, 44], [45, 48], [49, 53], [53, 54], [55, 58], [59, 63], [64, 73], [74, 78], [79, 81], [82, 91], [91, 92], [92, 101], [102, 111], [111, 112], [113, 117], [118, 121], [122, 131], [132, 136], [137, 142], [142, 143], [143, 145], [146, 158], [159, 161], [162, 170], [171, 172], [172, 177], [177, 178], [178, 182], [182, 183], [184, 188], [189, 193], [194, 197], [198, 205], [205, 206]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [8, 8, "product"], [17, 17, "country"], [28, 29, "misc"], [43, 43, "organisation"], [44, 44, "product"], [46, 46, "organisation"], [47, 51, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 17, 17, "opposite", "", false, false], [8, 8, 17, 17, "artifact", "", false, false], [28, 29, 8, 8, "part-of", "", false, false], [44, 44, 43, 43, "artifact", "", false, false], [47, 51, 46, 46, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "that", "page", ",", "Samurai", "Damashii", "reassessed", "the", "Senkousha", "as", "the", "crystallisation", "of", "four", "thousand", "years", "of", "Chinese", "scientific", "knowledge", ",", "commented", "on", "the", "crude", "design", "(", "e.g.", "Chinese", "cannon", "on", "the", "crotch", ")", "and", "juxtaposed", "it", "s", "image", "with", "that", "of", "the", "Honda", "ASIMO", "and", "Sony", "QRIO", "SDR", "-", "3", "X", "."], "sentence-detokenized": "On that page, Samurai Damashii reassessed the Senkousha as the crystallisation of four thousand years of Chinese scientific knowledge, commented on the crude design (e.g. Chinese cannon on the crotch) and juxtaposed its image with that of the Honda ASIMO and Sony QRIO SDR-3X.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 21], [22, 30], [31, 41], [42, 45], [46, 55], [56, 58], [59, 62], [63, 78], [79, 81], [82, 86], [87, 95], [96, 101], [102, 104], [105, 112], [113, 123], [124, 133], [133, 134], [135, 144], [145, 147], [148, 151], [152, 157], [158, 164], [165, 166], [166, 170], [171, 178], [179, 185], [186, 188], [189, 192], [193, 199], [199, 200], [201, 204], [205, 215], [216, 218], [218, 219], [220, 225], [226, 230], [231, 235], [236, 238], [239, 242], [243, 248], [249, 254], [255, 258], [259, 263], [264, 268], [269, 272], [272, 273], [273, 274], [274, 275], [275, 276]]}
{"doc_key": "ai-test-374", "ner": [[8, 9, "algorithm"], [18, 18, "product"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 18, 18, "part-of", "includes_functionality_of", false, false], [8, 9, 20, 20, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "also", "many", "programming", "libraries", "that", "include", "neural", "network", "functions", "and", "can", "be", "used", "optionally", "(", "e.g.", "TensorFlow", ",", "Theano", ",", "etc", "."], "sentence-detokenized": "There are also many programming libraries that include neural network functions and can be used optionally (e.g. TensorFlow, Theano, etc.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 31], [32, 41], [42, 46], [47, 54], [55, 61], [62, 69], [70, 79], [80, 83], [84, 87], [88, 90], [91, 95], [96, 106], [107, 108], [108, 112], [113, 123], [123, 124], [125, 131], [131, 132], [133, 136], [136, 137]]}
{"doc_key": "ai-test-375", "ner": [[6, 9, "conference"], [12, 14, "organisation"], [15, 21, "conference"], [23, 23, "conference"], [25, 25, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", ",", "the", "IEEE", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", "and", "SPIE", "."], "sentence-detokenized": "He is a member of the Association for Computing Machinery, the IEEE, the American Association for the Advancement of Science, IAPR and SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 33], [34, 37], [38, 47], [48, 57], [57, 58], [59, 62], [63, 67], [67, 68], [69, 72], [73, 81], [82, 93], [94, 97], [98, 101], [102, 113], [114, 116], [117, 124], [124, 125], [126, 130], [131, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-test-376", "ner": [[6, 7, "organisation"], [9, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 9, 10, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2011", ",", "a", "test", "by", "the", "RET", "with", "facial", "recognition", "cameras", "on", "trams", "ensured", "that", "people", "who", "were", "banned", "from", "using", "the", "city", "'s", "trams", "still", "did", "not", "trip", "."], "sentence-detokenized": "In 2011, a test by the RET with facial recognition cameras on trams ensured that people who were banned from using the city's trams still did not trip.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 15], [16, 18], [19, 22], [23, 26], [27, 31], [32, 38], [39, 50], [51, 58], [59, 61], [62, 67], [68, 75], [76, 80], [81, 87], [88, 91], [92, 96], [97, 103], [104, 108], [109, 114], [115, 118], [119, 123], [123, 125], [126, 131], [132, 137], [138, 141], [142, 145], [146, 150], [150, 151]]}
{"doc_key": "ai-test-377", "ner": [[2, 4, "person"], [6, 6, "organisation"], [14, 15, "person"], [17, 18, "person"], [21, 22, "person"], [24, 25, "person"], [27, 28, "person"], [30, 31, "person"], [33, 34, "person"], [36, 37, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[2, 4, 6, 6, "role", "works_for", false, false], [14, 15, 6, 6, "role", "works_for", false, false], [17, 18, 6, 6, "role", "works_for", false, false], [21, 22, 6, 6, "role", "works_for", false, false], [24, 25, 6, 6, "role", "works_for", false, false], [27, 28, 6, 6, "role", "works_for", false, false], [30, 31, 6, 6, "role", "works_for", false, false], [33, 34, 6, 6, "role", "works_for", false, false], [36, 37, 6, 6, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Adapted", "from", "Cole", "Porter", "'s", "popular", "Broadway", "musical", ",", "the", "film", "stars", "MGM", "singers", "Howard", "Keel", "and", "Kathryn", "Grayson", ",", "with", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "and", "Tommy", "Rall", "."], "sentence-detokenized": "Adapted from Cole Porter's popular Broadway musical, the film stars MGM singers Howard Keel and Kathryn Grayson, with Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar and Tommy Rall.", "token2charspan": [[0, 7], [8, 12], [13, 17], [18, 24], [24, 26], [27, 34], [35, 43], [44, 51], [51, 52], [53, 56], [57, 61], [62, 67], [68, 71], [72, 79], [80, 86], [87, 91], [92, 95], [96, 103], [104, 111], [111, 112], [113, 117], [118, 121], [122, 128], [128, 129], [130, 136], [137, 141], [141, 142], [143, 148], [149, 152], [152, 153], [154, 159], [160, 168], [168, 169], [170, 174], [175, 182], [183, 186], [187, 192], [193, 197], [197, 198]]}
{"doc_key": "ai-test-378", "ner": [[21, 25, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "applications", "should", "streamline", "call", "flows", ",", "minimise", "the", "number", "of", "prompts", ",", "eliminate", "unnecessary", "repetition", "and", "allow", "for", "a", "sophisticated", "mixed", "-initiative", "dialogue", "system", "that", "allows", "callers", "to", "enter", "multiple", "pieces", "of", "information", "in", "any", "order", "or", "combination", "in", "a", "single", "sentence", "."], "sentence-detokenized": "Such applications should streamline call flows, minimise the number of prompts, eliminate unnecessary repetition and allow for a sophisticated mixed-initiative dialogue system that allows callers to enter multiple pieces of information in any order or combination in a single sentence.", "token2charspan": [[0, 4], [5, 17], [18, 24], [25, 35], [36, 40], [41, 46], [46, 47], [48, 56], [57, 60], [61, 67], [68, 70], [71, 78], [78, 79], [80, 89], [90, 101], [102, 112], [113, 116], [117, 122], [123, 126], [127, 128], [129, 142], [143, 148], [148, 159], [160, 168], [169, 175], [176, 180], [181, 187], [188, 195], [196, 198], [199, 204], [205, 213], [214, 220], [221, 223], [224, 235], [236, 238], [239, 242], [243, 248], [249, 251], [252, 263], [264, 266], [267, 268], [269, 275], [276, 284], [284, 285]]}
{"doc_key": "ai-test-379", "ner": [[3, 4, "algorithm"], [7, 9, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 3, 4, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Therefore", ",", "traditional", "gradient", "descent", "(", "or", "stochastic", "gradient", "descent", ")", "methods", "can", "be", "applied", ",", "where", "the", "step", "is", "not", "taken", "in", "the", "direction", "of", "the", "gradient", "of", "the", "function", ",", "but", "in", "the", "direction", "of", "a", "vector", "chosen", "from", "a", "subgradient", "of", "the", "function", "."], "sentence-detokenized": "Therefore, traditional gradient descent (or stochastic gradient descent) methods can be applied, where the step is not taken in the direction of the gradient of the function, but in the direction of a vector chosen from a subgradient of the function.", "token2charspan": [[0, 9], [9, 10], [11, 22], [23, 31], [32, 39], [40, 41], [41, 43], [44, 54], [55, 63], [64, 71], [71, 72], [73, 80], [81, 84], [85, 87], [88, 95], [95, 96], [97, 102], [103, 106], [107, 111], [112, 114], [115, 118], [119, 124], [125, 127], [128, 131], [132, 141], [142, 144], [145, 148], [149, 157], [158, 160], [161, 164], [165, 173], [173, 174], [175, 178], [179, 181], [182, 185], [186, 195], [196, 198], [199, 200], [201, 207], [208, 214], [215, 219], [220, 221], [222, 233], [234, 236], [237, 240], [241, 249], [249, 250]]}
{"doc_key": "ai-test-380", "ner": [[7, 12, "metrics"], [13, 15, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Assuming", "that", "the", "distortion", "is", "measured", "in", "root", "mean", "square", "error", ",", "the", "distortion", "D", "is", "equal", "to", ":"], "sentence-detokenized": "Assuming that the distortion is measured in root mean square error, the distortion D is equal to:", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 28], [29, 31], [32, 40], [41, 43], [44, 48], [49, 53], [54, 60], [61, 66], [66, 67], [68, 71], [72, 82], [83, 84], [85, 87], [88, 93], [94, 96], [96, 97]]}
{"doc_key": "ai-test-381", "ner": [[4, 4, "algorithm"], [8, 9, "field"], [22, 23, "task"], [25, 26, "task"], [28, 29, "task"], [33, 34, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 8, 9, "part-of", "", false, false], [22, 23, 4, 4, "part-of", "", false, false], [25, 26, 4, 4, "part-of", "", false, false], [28, 29, 4, 4, "part-of", "", false, false], [33, 34, 4, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "1970s", ",", "MLP", "was", "a", "popular", "machine", "learning", "solution", ",", "with", "applications", "in", "a", "wide", "range", "of", "domains", "such", "as", "speech", "recognition", ",", "image", "recognition", "and", "machine", "translation", "software", ",", "and", "neural", "networks", "."], "sentence-detokenized": "In the 1970s, MLP was a popular machine learning solution, with applications in a wide range of domains such as speech recognition, image recognition and machine translation software, and neural networks.", "token2charspan": [[0, 2], [3, 6], [7, 12], [12, 13], [14, 17], [18, 21], [22, 23], [24, 31], [32, 39], [40, 48], [49, 57], [57, 58], [59, 63], [64, 76], [77, 79], [80, 81], [82, 86], [87, 92], [93, 95], [96, 103], [104, 108], [109, 111], [112, 118], [119, 130], [130, 131], [132, 137], [138, 149], [150, 153], [154, 161], [162, 173], [174, 182], [182, 183], [184, 187], [188, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [3, 3, "misc"], [4, 9, "university"], [15, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 9, "physical", "", false, false], [0, 0, 4, 9, "role", "", false, false], [3, 3, 0, 0, "origin", "", false, false], [15, 17, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "received", "his", "PhD", "from", "the", "University", "of", "Toronto", "in", "1979", "under", "the", "supervision", "of", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen received his PhD from the University of Toronto in 1979 under the supervision of C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 22], [23, 27], [28, 31], [32, 42], [43, 45], [46, 53], [54, 56], [57, 61], [62, 67], [68, 71], [72, 83], [84, 86], [87, 89], [90, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-383", "ner": [[0, 1, "product"], [4, 6, "field"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [19, 19, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 4, 6, "related-to", "supports", false, false], [10, 10, 4, 6, "type-of", "", true, false], [12, 12, 4, 6, "type-of", "", true, false], [14, 14, 4, 6, "type-of", "", true, false], [14, 14, 19, 19, "related-to", "converting_to", true, false], [23, 23, 4, 6, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["\"", "OpenCV", "supports", "some", "deep", "learning", "system", "models", "such", "as", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "converted", "to", "the", "ONNX", "model", ")", "and", "Caffe", ",", "according", "to", "a", "defined", "list", "of", "supported", "layers", "."], "sentence-detokenized": "\"OpenCV supports some deep learning system models such as TensorFlow, Torch, PyTorch (converted to the ONNX model) and Caffe, according to a defined list of supported layers.", "token2charspan": [[0, 1], [1, 7], [8, 16], [17, 21], [22, 26], [27, 35], [36, 42], [43, 49], [50, 54], [55, 57], [58, 68], [68, 69], [70, 75], [75, 76], [77, 84], [85, 86], [86, 95], [96, 98], [99, 102], [103, 107], [108, 113], [113, 114], [115, 118], [119, 124], [124, 125], [126, 135], [136, 138], [139, 140], [141, 148], [149, 153], [154, 156], [157, 166], [167, 173], [173, 174]]}
{"doc_key": "ai-test-384", "ner": [[2, 4, "researcher"], [9, 12, "organisation"], [14, 14, "organisation"], [24, 28, "organisation"], [20, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 9, 12, "role", "", false, false], [2, 4, 24, 28, "role", "", false, false], [2, 4, 20, 23, "related-to", "lectures_in", false, false], [14, 14, 9, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Previously", ",", "Christensen", "was", "a", "founding", "member", "of", "the", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "and", "a", "Distinguished", "Lecturer", "in", "Robotics", "at", "the", "IEEE", "Robotics", "and", "Automation", "Society", "."], "sentence-detokenized": "Previously, Christensen was a founding member of the European Robotics Research Network (EURON) and a Distinguished Lecturer in Robotics at the IEEE Robotics and Automation Society.", "token2charspan": [[0, 10], [10, 11], [12, 23], [24, 27], [28, 29], [30, 38], [39, 45], [46, 48], [49, 52], [53, 61], [62, 70], [71, 79], [80, 87], [88, 89], [89, 94], [94, 95], [96, 99], [100, 101], [102, 115], [116, 124], [125, 127], [128, 136], [137, 139], [140, 143], [144, 148], [149, 157], [158, 161], [162, 172], [173, 180], [180, 181]]}
{"doc_key": "ai-test-385", "ner": [[3, 8, "field"], [9, 11, "university"], [13, 13, "location"], [0, 21, "country"], [25, 25, "misc"], [26, 27, "field"], [29, 33, "organisation"], [35, 38, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 11, 13, 13, "physical", "", false, false], [13, 13, 0, 21, "physical", "", false, false], [25, 25, 26, 27, "topic", "", false, false], [29, 33, 35, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "obtained", "a", "Master", "'s", "degree", "in", "mathematics", "from", "Samarkand", "State", "University", "(", "Samarkand", ",", "Soviet", "Socialist", "Republic", "of", "Uzbekistan", ")", "in", "1958", "and", "a", "PhD", "in", "statistics", "from", "the", "Institute", "of", "Control", "Sciences", "(", "Moscow", ")", "in", "1964", "."], "sentence-detokenized": "He obtained a Master's degree in mathematics from Samarkand State University (Samarkand, Soviet Socialist Republic of Uzbekistan) in 1958 and a PhD in statistics from the Institute of Control Sciences (Moscow) in 1964.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 20], [20, 22], [23, 29], [30, 32], [33, 44], [45, 49], [50, 59], [60, 65], [66, 76], [77, 78], [78, 87], [87, 88], [89, 95], [96, 105], [106, 114], [115, 117], [118, 128], [128, 129], [130, 132], [133, 137], [138, 141], [142, 143], [144, 147], [148, 150], [151, 161], [162, 166], [167, 170], [171, 180], [181, 183], [184, 191], [192, 200], [201, 202], [202, 208], [208, 209], [210, 212], [213, 217], [217, 218]]}
{"doc_key": "ai-test-386", "ner": [[2, 2, "organisation"], [8, 11, "product"], [27, 28, "field"], [30, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 27, 28, "usage", "", false, false], [2, 2, 30, 32, "usage", "", false, false], [8, 11, 2, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "Cycorp", "is", "increasingly", "working", "to", "enable", "the", "Cyc", "system", "to", "communicate", "with", "end-users", "in", "natural", "language", "and", "to", "support", "the", "ongoing", "knowledge", "creation", "process", "through", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "However, Cycorp is increasingly working to enable the Cyc system to communicate with end-users in natural language and to support the ongoing knowledge creation process through machine learning and natural language understanding.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 18], [19, 31], [32, 39], [40, 42], [43, 49], [50, 53], [54, 57], [58, 64], [65, 67], [68, 79], [80, 84], [85, 94], [95, 97], [98, 105], [106, 114], [115, 118], [119, 121], [122, 129], [130, 133], [134, 141], [142, 151], [152, 160], [161, 168], [169, 176], [177, 184], [185, 193], [194, 197], [198, 205], [206, 214], [215, 228], [228, 229]]}
{"doc_key": "ai-test-387", "ner": [[57, 57, "metrics"], [59, 59, "metrics"], [61, 61, "metrics"], [63, 64, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "if", "you", "are", "looking", "for", "the", "most", "appropriate", "classifier", "to", "solve", "a", "problem", ",", "the", "training", "dataset", "is", "used", "to", "train", "candidate", "algorithms", ",", "the", "validation", "dataset", "is", "used", "to", "compare", "their", "results", "and", "decide", "which", "algorithm", "to", "choose", ",", "and", "finally", "the", "testing", "dataset", "is", "used", "to", "obtain", "performance", "characteristics", ",", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", ",", "F-", "measure", ",", "etc", "."], "sentence-detokenized": "For example, if you are looking for the most appropriate classifier to solve a problem, the training dataset is used to train candidate algorithms, the validation dataset is used to compare their results and decide which algorithm to choose, and finally the testing dataset is used to obtain performance characteristics, such as accuracy, sensitivity, specificity, F-measure, etc.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 19], [20, 23], [24, 31], [32, 35], [36, 39], [40, 44], [45, 56], [57, 67], [68, 70], [71, 76], [77, 78], [79, 86], [86, 87], [88, 91], [92, 100], [101, 108], [109, 111], [112, 116], [117, 119], [120, 125], [126, 135], [136, 146], [146, 147], [148, 151], [152, 162], [163, 170], [171, 173], [174, 178], [179, 181], [182, 189], [190, 195], [196, 203], [204, 207], [208, 214], [215, 220], [221, 230], [231, 233], [234, 240], [240, 241], [242, 245], [246, 253], [254, 257], [258, 265], [266, 273], [274, 276], [277, 281], [282, 284], [285, 291], [292, 303], [304, 319], [319, 320], [321, 325], [326, 328], [329, 337], [337, 338], [339, 350], [350, 351], [352, 363], [363, 364], [365, 367], [367, 374], [374, 375], [376, 379], [379, 380]]}
{"doc_key": "ai-test-388", "ner": [[0, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "root", "mean", "square", "error", "is", "0.15", "."], "sentence-detokenized": "The root mean square error is 0.15.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 20], [21, 26], [27, 29], [30, 34], [34, 35]]}
{"doc_key": "ai-test-389", "ner": [[7, 10, "misc"], [3, 4, "organisation"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 7, 10, "role", "", false, false], [14, 15, 7, 10, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1979", ",", "the", "IEEE", "organised", "a", "Micromouse", "competition", ",", "which", "was", "featured", "in", "Spectrum", "magazine", "."], "sentence-detokenized": "In 1979, the IEEE organised a Micromouse competition, which was featured in Spectrum magazine.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 27], [28, 29], [30, 40], [41, 52], [52, 53], [54, 59], [60, 63], [64, 72], [73, 75], [76, 84], [85, 93], [93, 94]]}
{"doc_key": "ai-test-390", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [11, 13, "task"], [15, 16, "task"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 7, "part-of", "", false, false], [11, 13, 6, 7, "part-of", "task_part_of_field", false, false], [15, 16, 6, 7, "part-of", "task_part_of_field", false, false], [18, 19, 6, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Gabor", "space", "is", "very", "useful", "in", "image", "processing", "applications", "such", "as", "optical", "character", "recognition", ",", "iris", "recognition", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "Gabor space is very useful in image processing applications such as optical character recognition, iris recognition and fingerprint recognition.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 19], [20, 26], [27, 29], [30, 35], [36, 46], [47, 59], [60, 64], [65, 67], [68, 75], [76, 85], [86, 97], [97, 98], [99, 103], [104, 115], [116, 119], [120, 131], [132, 143], [143, 144]]}
{"doc_key": "ai-test-391", "ner": [[7, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "via", "high", "-", "level", "interfaces", "to", "Java", "and", "Tcl", "."], "sentence-detokenized": "or via high-level interfaces to Java and Tcl.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [12, 17], [18, 28], [29, 31], [32, 36], [37, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-test-392", "ner": [[12, 14, "algorithm"], [20, 21, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 14, 20, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Recent", "research", "has", "shown", "that", "kernel", "-", "based", "approaches", ",", "such", "as", "support", "vector", "machines", ",", "have", "better", "performance", "on", "supervised", "data", "."], "sentence-detokenized": "Recent research has shown that kernel-based approaches, such as support vector machines, have better performance on supervised data.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 25], [26, 30], [31, 37], [37, 38], [38, 43], [44, 54], [54, 55], [56, 60], [61, 63], [64, 71], [72, 78], [79, 87], [87, 88], [89, 93], [94, 100], [101, 112], [113, 115], [116, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-393", "ner": [[22, 22, "researcher"], [24, 24, "researcher"], [31, 31, "programlang"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[22, 22, 31, 31, "usage", "", false, false], [24, 24, 31, 31, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "illustrate", "the", "basic", "principles", "of", "mixing", ",", "an", "analysis", "of", "the", "ozone", "-", "temperature", "relationship", "is", "presented", "below", "(", "data", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "analysis", "using", "R", ")", "."], "sentence-detokenized": "To illustrate the basic principles of mixing, an analysis of the ozone-temperature relationship is presented below (data from Rousseeuw and Leroy (1986), analysis using R).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 34], [35, 37], [38, 44], [44, 45], [46, 48], [49, 57], [58, 60], [61, 64], [65, 70], [70, 71], [71, 82], [83, 95], [96, 98], [99, 108], [109, 114], [115, 116], [116, 120], [121, 125], [126, 135], [136, 139], [140, 145], [146, 147], [147, 151], [151, 152], [152, 153], [154, 162], [163, 168], [169, 170], [170, 171], [171, 172]]}
{"doc_key": "ai-test-394", "ner": [[0, 2, "organisation"], [15, 15, "product"], [22, 23, "product"], [25, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 15, 0, 2, "artifact", "", false, false], [22, 23, 0, 2, "artifact", "", false, false], [25, 27, 0, 2, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["\"", "Denso", "Wave", "is", "a", "subsidiary", "of", "Denso", ",", "which", "manufactures", "automatic", "identification", "products", "(", "barcode", "scanners", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "\"Denso Wave is a subsidiary of Denso, which manufactures automatic identification products (barcode scanners and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 1], [1, 6], [7, 11], [12, 14], [15, 16], [17, 27], [28, 30], [31, 36], [36, 37], [38, 43], [44, 56], [57, 66], [67, 81], [82, 90], [91, 92], [92, 99], [100, 108], [109, 112], [113, 120], [121, 129], [129, 130], [130, 131], [132, 142], [143, 149], [150, 153], [154, 166], [167, 172], [173, 184], [184, 185]]}
{"doc_key": "ai-test-395", "ner": [[1, 4, "metrics"], [8, 13, "metrics"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 4, 22, 23, "compare", "", false, false], [8, 13, 1, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "a", "bilingual", "evaluation", "study", "simply", "calculates", "the", "accuracy", "of", "the", "n-", "grams", "by", "giving", "each", "of", "them", "an", "equal", "weight", ",", "NIST", "also", "calculates", "how", "informative", "a", "particular", "n-", "gram", "is", "."], "sentence-detokenized": "While a bilingual evaluation study simply calculates the accuracy of the n-grams by giving each of them an equal weight, NIST also calculates how informative a particular n-gram is.", "token2charspan": [[0, 5], [6, 7], [8, 17], [18, 28], [29, 34], [35, 41], [42, 52], [53, 56], [57, 65], [66, 68], [69, 72], [73, 75], [75, 80], [81, 83], [84, 90], [91, 95], [96, 98], [99, 103], [104, 106], [107, 112], [113, 119], [119, 120], [121, 125], [126, 130], [131, 141], [142, 145], [146, 157], [158, 159], [160, 170], [171, 173], [173, 177], [178, 180], [180, 181]]}
{"doc_key": "ai-test-396", "ner": [[15, 15, "algorithm"], [17, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "particular", ",", "they", "are", "used", "to", "calculate", "the", "probability", "of", "a", "tree", "(", "in", "Bayesian", "and", "maximum", "likelihood", "tree", "estimation", "methods", ")", ",", "and", "are", "used", "to", "estimate", "the", "evolutionary", "distance", "between", "sequences", "based", "on", "the", "observed", "differences", "between", "sequences", "."], "sentence-detokenized": "In particular, they are used to calculate the probability of a tree (in Bayesian and maximum likelihood tree estimation methods), and are used to estimate the evolutionary distance between sequences based on the observed differences between sequences.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 45], [46, 57], [58, 60], [61, 62], [63, 67], [68, 69], [69, 71], [72, 80], [81, 84], [85, 92], [93, 103], [104, 108], [109, 119], [120, 127], [127, 128], [128, 129], [130, 133], [134, 137], [138, 142], [143, 145], [146, 154], [155, 158], [159, 171], [172, 180], [181, 188], [189, 198], [199, 204], [205, 207], [208, 211], [212, 220], [221, 232], [233, 240], [241, 250], [250, 251]]}
{"doc_key": "ai-test-397", "ner": [[0, 3, "conference"], [19, 20, "misc"], [22, 22, "misc"], [46, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 19, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Audio", "Engineering", "Society", "recommends", "a", "sampling", "rate", "of", "48", "kHz", "for", "most", "applications", ",", "but", "recognises", "44.1", "kHz", "for", "discs", "(", "CDs", ")", "and", "other", "consumer", "applications", ",", "32", "kHz", "for", "transmission", "-", "related", "applications", ",", "and", "96", "kHz", "for", "higher", "bandwidth", "or", "with", "a", "smoothing", "filter", "."], "sentence-detokenized": "The Audio Engineering Society recommends a sampling rate of 48 kHz for most applications, but recognises 44.1 kHz for discs (CDs) and other consumer applications, 32 kHz for transmission-related applications, and 96 kHz for higher bandwidth or with a smoothing filter.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 40], [41, 42], [43, 51], [52, 56], [57, 59], [60, 62], [63, 66], [67, 70], [71, 75], [76, 88], [88, 89], [90, 93], [94, 104], [105, 109], [110, 113], [114, 117], [118, 123], [124, 125], [125, 128], [128, 129], [130, 133], [134, 139], [140, 148], [149, 161], [161, 162], [163, 165], [166, 169], [170, 173], [174, 186], [186, 187], [187, 194], [195, 207], [207, 208], [209, 212], [213, 215], [216, 219], [220, 223], [224, 230], [231, 240], [241, 243], [244, 248], [249, 250], [251, 260], [261, 267], [267, 268]]}
{"doc_key": "ai-test-398", "ner": [[9, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Word", "and", "concept", "affectivity", "sources", "have", "been", "created", "in", "WordNet", "{", "{", "cite", "journal"], "sentence-detokenized": "Word and concept affectivity sources have been created in WordNet {{cite journal", "token2charspan": [[0, 4], [5, 8], [9, 16], [17, 28], [29, 36], [37, 41], [42, 46], [47, 54], [55, 57], [58, 65], [66, 67], [67, 68], [68, 72], [73, 80]]}
{"doc_key": "ai-test-399", "ner": [[0, 6, "misc"], [24, 25, "person"], [27, 30, "person"], [35, 36, "person"], [45, 50, "organisation"], [67, 68, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[27, 30, 35, 36, "role", "acts_in", false, false], [45, 50, 35, 36, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "red", "-", "and", "-", "green", "anaglyph", "film", "showed", "the", "audience", "three", "reels", "of", "test", "footage", ",", "including", "rural", "scenes", ",", "test", "footage", "of", "Marie", "Doro", ",", "John", "B", ".", "Mason", "playing", "several", "excerpts", "from", "Jim", "Penman", "(", "a", "film", "released", "the", "same", "year", "by", "Famous", "Players", "-", "Lasky", ",", "but", "not", "in", "3", "-", "D", ")", ",", "footage", "of", "an", "Oriental", "dancer", ",", "and", "footage", "of", "Niagara", "Falls", "."], "sentence-detokenized": "The red-and-green anaglyph film showed the audience three reels of test footage, including rural scenes, test footage of Marie Doro, John B. Mason playing several excerpts from Jim Penman (a film released the same year by Famous Players-Lasky, but not in 3-D), footage of an Oriental dancer, and footage of Niagara Falls.", "token2charspan": [[0, 3], [4, 7], [7, 8], [8, 11], [11, 12], [12, 17], [18, 26], [27, 31], [32, 38], [39, 42], [43, 51], [52, 57], [58, 63], [64, 66], [67, 71], [72, 79], [79, 80], [81, 90], [91, 96], [97, 103], [103, 104], [105, 109], [110, 117], [118, 120], [121, 126], [127, 131], [131, 132], [133, 137], [138, 139], [139, 140], [141, 146], [147, 154], [155, 162], [163, 171], [172, 176], [177, 180], [181, 187], [188, 189], [189, 190], [191, 195], [196, 204], [205, 208], [209, 213], [214, 218], [219, 221], [222, 228], [229, 236], [236, 237], [237, 242], [242, 243], [244, 247], [248, 251], [252, 254], [255, 256], [256, 257], [257, 258], [258, 259], [259, 260], [261, 268], [269, 271], [272, 274], [275, 283], [284, 290], [290, 291], [292, 295], [296, 303], [304, 306], [307, 314], [315, 320], [320, 321]]}
{"doc_key": "ai-test-400", "ner": [[8, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "special", "way", "of", "implementing", "the", "maximum", "likelihood", "estimator", "to", "address", "this", "problem", "."], "sentence-detokenized": "This is a special way of implementing the maximum likelihood estimator to address this problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 17], [18, 21], [22, 24], [25, 37], [38, 41], [42, 49], [50, 60], [61, 70], [71, 73], [74, 81], [82, 86], [87, 94], [94, 95]]}
{"doc_key": "ai-test-401", "ner": [[3, 3, "misc"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Site", "maps", "and", "RSS", "feeds", "are", "combined", "into", "a", "decentralised", "mechanism", "for", "computational", "biologists", "and", "bioinformaticians", "to", "openly", "stream", "and", "retrieve", "metadata", "about", "biomedical", "resources", "."], "sentence-detokenized": "Site maps and RSS feeds are combined into a decentralised mechanism for computational biologists and bioinformaticians to openly stream and retrieve metadata about biomedical resources.", "token2charspan": [[0, 4], [5, 9], [10, 13], [14, 17], [18, 23], [24, 27], [28, 36], [37, 41], [42, 43], [44, 57], [58, 67], [68, 71], [72, 85], [86, 96], [97, 100], [101, 118], [119, 121], [122, 128], [129, 135], [136, 139], [140, 148], [149, 157], [158, 163], [164, 174], [175, 184], [184, 185]]}
{"doc_key": "ai-test-402", "ner": [[5, 12, "misc"], [15, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "covered", "by", "the", "American", "National", "Standards", "Institute", "/", "NISO", "standard", "Z39.50", "and", "the", "International", "Organization", "for", "Standardization", "standard", "23950", "."], "sentence-detokenized": "It is covered by the American National Standards Institute/NISO standard Z39.50 and the International Organization for Standardization standard 23950.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 20], [21, 29], [30, 38], [39, 48], [49, 58], [58, 59], [59, 63], [64, 72], [73, 79], [80, 83], [84, 87], [88, 101], [102, 114], [115, 118], [119, 134], [135, 143], [144, 149], [149, 150]]}
{"doc_key": "ai-test-403", "ner": [[12, 17, "misc"], [20, 20, "metrics"], [24, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Encoders", "and", "decoders", "are", "trained", "to", "take", "a", "phrase", "and", "reconstruct", "a", "single", "distribution", "of", "the", "corresponding", "paraphrase", ",", "minimising", "perplexity", "by", "using", "simple", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "Encoders and decoders are trained to take a phrase and reconstruct a single distribution of the corresponding paraphrase, minimising perplexity by using simple stochastic gradient descent.", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 25], [26, 33], [34, 36], [37, 41], [42, 43], [44, 50], [51, 54], [55, 66], [67, 68], [69, 75], [76, 88], [89, 91], [92, 95], [96, 109], [110, 120], [120, 121], [122, 132], [133, 143], [144, 146], [147, 152], [153, 159], [160, 170], [171, 179], [180, 187], [187, 188]]}
{"doc_key": "ai-test-404", "ner": [[4, 5, "field"], [8, 10, "task"], [12, 18, "task"], [28, 31, "task"], [33, 38, "task"], [40, 46, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 10, 4, 5, "part-of", "task_part_of_field", false, false], [12, 18, 4, 5, "part-of", "task_part_of_field", false, false], [28, 31, 4, 5, "part-of", "task_part_of_field", false, false], [33, 38, 4, 5, "part-of", "task_part_of_field", false, false], [40, 46, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "typical", "applications", "of", "pattern", "recognition", "techniques", "include", "automatic", "speech", "recognition", ",", "text", "classification", "into", "several", "categories", "(", "e.g.", "classification", "of", "spam", "and", "junk", "e-mail", "messages", ")", ",", "handwriting", "recognition", "on", "envelopes", ",", "automatic", "recognition", "of", "human", "facial", "images", "or", "extraction", "of", "handwriting", "images", "from", "medical", "forms", "."], "sentence-detokenized": "Other typical applications of pattern recognition techniques include automatic speech recognition, text classification into several categories (e.g. classification of spam and junk e-mail messages), handwriting recognition on envelopes, automatic recognition of human facial images or extraction of handwriting images from medical forms.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 29], [30, 37], [38, 49], [50, 60], [61, 68], [69, 78], [79, 85], [86, 97], [97, 98], [99, 103], [104, 118], [119, 123], [124, 131], [132, 142], [143, 144], [144, 148], [149, 163], [164, 166], [167, 171], [172, 175], [176, 180], [181, 187], [188, 196], [196, 197], [197, 198], [199, 210], [211, 222], [223, 225], [226, 235], [235, 236], [237, 246], [247, 258], [259, 261], [262, 267], [268, 274], [275, 281], [282, 284], [285, 295], [296, 298], [299, 310], [311, 317], [318, 322], [323, 330], [331, 336], [336, 337]]}
{"doc_key": "ai-test-405", "ner": [[0, 2, "algorithm"], [14, 15, "field"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 29, "task"], [32, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 15, 0, 2, "usage", "", false, false], [17, 18, 0, 2, "usage", "", false, false], [20, 21, 0, 2, "usage", "", false, false], [23, 24, 0, 2, "usage", "", false, false], [26, 29, 0, 2, "usage", "", false, false], [32, 33, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Artificial", "neural", "networks", "have", "been", "used", "for", "a", "wide", "range", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "filtering", ",", "board", "and", "video", "games", ",", "and", "medical", "diagnosis", "."], "sentence-detokenized": "Artificial neural networks have been used for a wide range of tasks, including computer vision, speech recognition, machine translation, social filtering, board and video games, and medical diagnosis.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 36], [37, 41], [42, 45], [46, 47], [48, 52], [53, 58], [59, 61], [62, 67], [67, 68], [69, 78], [79, 87], [88, 94], [94, 95], [96, 102], [103, 114], [114, 115], [116, 123], [124, 135], [135, 136], [137, 143], [144, 153], [153, 154], [155, 160], [161, 164], [165, 170], [171, 176], [176, 177], [178, 181], [182, 189], [190, 199], [199, 200]]}
{"doc_key": "ai-test-406", "ner": [[3, 4, "organisation"], [5, 5, "product"], [15, 15, "product"], [19, 19, "organisation"], [20, 21, "product"], [23, 23, "product"], [25, 27, "product"], [29, 29, "product"], [31, 31, "programlang"], [40, 43, "field"], [46, 46, "product"], [52, 52, "algorithm"], [54, 54, "algorithm"], [56, 56, "algorithm"], [59, 59, "product"], [65, 66, "task"], [70, 71, "algorithm"], [75, 75, "product"], [77, 77, "product"], [79, 81, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[5, 5, 3, 4, "origin", "", false, false], [5, 5, 15, 15, "named", "same", false, false], [5, 5, 46, 46, "named", "same", false, false], [31, 31, 40, 43, "related-to", "used_for", false, false], [52, 52, 31, 31, "part-of", "", true, false], [52, 52, 46, 46, "origin", "", true, false], [54, 54, 31, 31, "part-of", "", true, false], [54, 54, 46, 46, "origin", "", true, false], [56, 56, 31, 31, "part-of", "", true, false], [56, 56, 46, 46, "origin", "", true, false], [59, 59, 65, 66, "related-to", "used_for", false, false], [70, 71, 59, 59, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["For", "example", ",", "Salford", "Systems", "CART", "(", "which", "licensed", "the", "proprietary", "code", "of", "the", "original", "CART", "authors", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "-", "source", "software", "environment", "for", "statistical", "computing", ",", "which", "includes", "several", "CART", "implementations", "such", "as", "the", "packages", "rpart", ",", "party", "and", "randomForest", ")", ",", "Weka", "(", "a", "free", "open", "source", "data", "mining", "package", "containing", "many", "decision", "tree", "algorithms", ")", ",", "Orange", ",", "KNIME", ",", "Microsoft", "SQL", "Server", "programming", "language", ")", "."], "sentence-detokenized": "For example, Salford Systems CART (which licensed the proprietary code of the original CART authors), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open-source software environment for statistical computing, which includes several CART implementations such as the packages rpart, party and randomForest), Weka (a free open source data mining package containing many decision tree algorithms), Orange, KNIME, Microsoft SQL Server programming language).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 20], [21, 28], [29, 33], [34, 35], [35, 40], [41, 49], [50, 53], [54, 65], [66, 70], [71, 73], [74, 77], [78, 86], [87, 91], [92, 99], [99, 100], [100, 101], [102, 105], [106, 110], [111, 118], [118, 119], [120, 130], [130, 131], [132, 135], [136, 146], [147, 152], [152, 153], [154, 160], [160, 161], [162, 163], [164, 165], [165, 167], [168, 172], [172, 173], [173, 179], [180, 188], [189, 200], [201, 204], [205, 216], [217, 226], [226, 227], [228, 233], [234, 242], [243, 250], [251, 255], [256, 271], [272, 276], [277, 279], [280, 283], [284, 292], [293, 298], [298, 299], [300, 305], [306, 309], [310, 322], [322, 323], [323, 324], [325, 329], [330, 331], [331, 332], [333, 337], [338, 342], [343, 349], [350, 354], [355, 361], [362, 369], [370, 380], [381, 385], [386, 394], [395, 399], [400, 410], [410, 411], [411, 412], [413, 419], [419, 420], [421, 426], [426, 427], [428, 437], [438, 441], [442, 448], [449, 460], [461, 469], [469, 470], [470, 471]]}
{"doc_key": "ai-test-407", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [12, 13, "researcher"], [15, 16, "university"], [18, 19, "researcher"], [21, 24, "organisation"], [26, 31, "organisation"], [40, 42, "researcher"], [44, 47, "researcher"], [48, 49, "organisation"], [58, 63, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 12, 13, "origin", "", false, false], [0, 2, 18, 19, "origin", "", false, false], [0, 2, 40, 42, "origin", "", false, false], [0, 2, 44, 47, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [12, 13, 15, 16, "physical", "", false, false], [12, 13, 15, 16, "role", "", false, false], [18, 19, 21, 24, "physical", "", false, false], [18, 19, 21, 24, "role", "", false, false], [26, 31, 21, 24, "named", "", false, false], [40, 42, 48, 49, "physical", "", false, false], [40, 42, 48, 49, "role", "", false, false], [44, 47, 48, 49, "physical", "", false, false], [44, 47, 48, 49, "role", "", false, false], [58, 63, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Linear", "Predictive", "Coding", "(", "LPC", ")", "was", "first", "developed", "in", "1966", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", ",", "and", "was", "further", "developed", "in", "the", "early", "and", "mid-1960", "s", "by", "Bishnu", "S.", "Atal", "and", "Manfred", "R.", "Schroeder", "of", "Bell", "Labs", ",", "and", "became", "the", "basis", "of", "the", "first", "speech", "synthesiser", "DSP", "chips", "in", "the", "late", "1960s", "."], "sentence-detokenized": "Linear Predictive Coding (LPC) was first developed in 1966 by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT), and was further developed in the early and mid-1960s by Bishnu S. Atal and Manfred R. Schroeder of Bell Labs, and became the basis of the first speech synthesiser DSP chips in the late 1960s.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 40], [41, 50], [51, 53], [54, 58], [59, 61], [62, 70], [71, 78], [79, 81], [82, 88], [89, 99], [100, 103], [104, 109], [110, 115], [116, 118], [119, 125], [126, 135], [136, 139], [140, 149], [150, 151], [151, 154], [154, 155], [155, 156], [157, 160], [161, 164], [165, 172], [173, 182], [183, 185], [186, 189], [190, 195], [196, 199], [200, 208], [208, 209], [210, 212], [213, 219], [220, 222], [223, 227], [228, 231], [232, 239], [240, 242], [243, 252], [253, 255], [256, 260], [261, 265], [265, 266], [267, 270], [271, 277], [278, 281], [282, 287], [288, 290], [291, 294], [295, 300], [301, 307], [308, 319], [320, 323], [324, 329], [330, 332], [333, 336], [337, 341], [342, 347], [347, 348]]}
{"doc_key": "ai-test-408", "ner": [[0, 4, "metrics"], [8, 8, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 0, 4, "part-of", "", false, false], [10, 10, 0, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "F", "-", "score", "is", "the", "combination", "of", "precision", "and", "recall", ",", "which", "adds", "up", "to", "one", "point", "."], "sentence-detokenized": "The F-score is the combination of precision and recall, which adds up to one point.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 18], [19, 30], [31, 33], [34, 43], [44, 47], [48, 54], [54, 55], [56, 61], [62, 66], [67, 69], [70, 72], [73, 76], [77, 82], [82, 83]]}
{"doc_key": "ai-test-409", "ner": [[0, 1, "field"], [8, 13, "task"], [20, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 13, 0, 1, "part-of", "task_part_of_field", false, false], [20, 22, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Image", "analysis", "tasks", "can", "be", "as", "simple", "as", "scanning", "a", "barcode", "for", "d", "-tags", ",", "or", "as", "complex", "as", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Image analysis tasks can be as simple as scanning a barcode for d-tags, or as complex as a facial recognition system.", "token2charspan": [[0, 5], [6, 14], [15, 20], [21, 24], [25, 27], [28, 30], [31, 37], [38, 40], [41, 49], [50, 51], [52, 59], [60, 63], [64, 65], [65, 70], [70, 71], [72, 74], [75, 77], [78, 85], [86, 88], [89, 90], [91, 97], [98, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-test-410", "ner": [[5, 7, "algorithm"], [26, 27, "algorithm"], [35, 37, "algorithm"], [40, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[35, 37, 26, 27, "type-of", "", false, false], [40, 40, 35, 37, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "special", "case", "of", "linear", "support", "vector", "machines", "can", "be", "solved", "more", "efficiently", "by", "the", "same", "kind", "of", "algorithms", "that", "optimise", "it", "s", "close", "relative", ",", "logistic", "regression", ",", "a", "class", "of", "algorithms", "that", "includes", "stochastic", "gradient", "descent", "(", "e.g.", "PEGASOS", ")", "."], "sentence-detokenized": "The special case of linear support vector machines can be solved more efficiently by the same kind of algorithms that optimise its close relative, logistic regression, a class of algorithms that includes stochastic gradient descent (e.g. PEGASOS).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 34], [35, 41], [42, 50], [51, 54], [55, 57], [58, 64], [65, 69], [70, 81], [82, 84], [85, 88], [89, 93], [94, 98], [99, 101], [102, 112], [113, 117], [118, 126], [127, 129], [129, 130], [131, 136], [137, 145], [145, 146], [147, 155], [156, 166], [166, 167], [168, 169], [170, 175], [176, 178], [179, 189], [190, 194], [195, 203], [204, 214], [215, 223], [224, 231], [232, 233], [233, 237], [238, 245], [245, 246], [246, 247]]}
{"doc_key": "ai-test-411", "ner": [[1, 2, "product"], [4, 4, "product"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 4, 4, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["When", "Siri", "on", "an", "iOS", "device", "asks", "\"", "Do", "you", "have", "a", "pet", "?", "\"", ",", "one", "of", "the", "answers", "is", "\"", "I", "used", "to", "have", "an", "AIBO", "\"", "."], "sentence-detokenized": "When Siri on an iOS device asks \"Do you have a pet?\", one of the answers is \"I used to have an AIBO\".", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 15], [16, 19], [20, 26], [27, 31], [32, 33], [33, 35], [36, 39], [40, 44], [45, 46], [47, 50], [50, 51], [51, 52], [52, 53], [54, 57], [58, 60], [61, 64], [65, 72], [73, 75], [76, 77], [77, 78], [79, 83], [84, 86], [87, 91], [92, 94], [95, 99], [99, 100], [100, 101]]}
{"doc_key": "ai-test-412", "ner": [[0, 2, "task"], [4, 7, "metrics"], [10, 10, "metrics"], [12, 12, "metrics"], [15, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 7, 0, 2, "part-of", "", false, false], [10, 10, 4, 7, "named", "", false, false], [12, 12, 0, 2, "part-of", "", false, false], [15, 15, 12, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "information", "retrieval", ",", "a", "positive", "prediction", "value", "is", "called", "precision", "and", "sensitivity", "is", "called", "recall", "."], "sentence-detokenized": "In information retrieval, a positive prediction value is called precision and sensitivity is called recall.", "token2charspan": [[0, 2], [3, 14], [15, 24], [24, 25], [26, 27], [28, 36], [37, 47], [48, 53], [54, 56], [57, 63], [64, 73], [74, 77], [78, 89], [90, 92], [93, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-413", "ner": [[10, 11, "field"], [13, 13, "task"], [15, 15, "task"], [17, 18, "task"], [33, 34, "task"], [36, 37, "task"], [39, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 13, 10, 11, "part-of", "task_part_of_field", false, false], [15, 15, 10, 11, "part-of", "task_part_of_field", false, false], [17, 18, 10, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "particular", ",", "he", "has", "focused", "on", "areas", "such", "as", "text", "mining", "(", "extraction", ",", "categorisation", ",", "novelty", "detection", ")", "and", "new", "theoretical", "frameworks", ",", "such", "as", "unified", "utility", "-", "based", "theory", "combining", "information", "retrieval", ",", "automatic", "generalisation", ",", "free", "text", "question", "answering", ",", "and", "related", "tasks", "."], "sentence-detokenized": "In particular, he has focused on areas such as text mining (extraction, categorisation, novelty detection) and new theoretical frameworks, such as unified utility-based theory combining information retrieval, automatic generalisation, free text question answering, and related tasks.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 17], [18, 21], [22, 29], [30, 32], [33, 38], [39, 43], [44, 46], [47, 51], [52, 58], [59, 60], [60, 70], [70, 71], [72, 86], [86, 87], [88, 95], [96, 105], [105, 106], [107, 110], [111, 114], [115, 126], [127, 137], [137, 138], [139, 143], [144, 146], [147, 154], [155, 162], [162, 163], [163, 168], [169, 175], [176, 185], [186, 197], [198, 207], [207, 208], [209, 218], [219, 233], [233, 234], [235, 239], [240, 244], [245, 253], [254, 263], [263, 264], [265, 268], [269, 276], [277, 282], [282, 283]]}
{"doc_key": "ai-test-414", "ner": [[0, 1, "product"], [3, 4, "product"], [15, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [15, 18, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Delta", "robots", "have", "rotary", "actuators", "attached", "to", "the", "base", "that", "move", "a", "lightweight", ",", "rigid", "parallelogram", "-", "shaped", "arm", "."], "sentence-detokenized": "Delta robots have rotary actuators attached to the base that move a lightweight, rigid parallelogram-shaped arm.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 24], [25, 34], [35, 43], [44, 46], [47, 50], [51, 55], [56, 60], [61, 65], [66, 67], [68, 79], [79, 80], [81, 86], [87, 100], [100, 101], [101, 107], [108, 111], [111, 112]]}
{"doc_key": "ai-test-415", "ner": [[8, 12, "metrics"], [15, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "into", "a", "2", "\u00d7", "2", "contingency", "table", "or", "a", "confusion", "matrix", ",", "as", "below", ":"], "sentence-detokenized": "The four results can be formulated into a 2 \u00d7 2 contingency table or a confusion matrix, as below:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 39], [40, 41], [42, 43], [44, 45], [46, 47], [48, 59], [60, 65], [66, 68], [69, 70], [71, 80], [81, 87], [87, 88], [89, 91], [92, 97], [97, 98]]}
{"doc_key": "ai-test-416", "ner": [[4, 5, "field"], [31, 32, "task"], [38, 39, "task"], [44, 46, "task"], [48, 50, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[31, 32, 4, 5, "part-of", "task_part_of_field", false, false], [38, 39, 4, 5, "part-of", "task_part_of_field", false, false], [44, 46, 4, 5, "part-of", "task_part_of_field", false, false], [48, 50, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "real", "task", "of", "data", "mining", "is", "the", "semi-automatic", "or", "automatic", "analysis", "of", "large", "amounts", "of", "data", "to", "extract", "unknown", ",", "interesting", "patterns", ",", "such", "as", "groups", "of", "data", "records", "(", "cluster", "analysis", ")", ",", "unusual", "records", "(", "anomaly", "detection", ")", "and", "dependencies", "(", "association", "rule", "mining", ",", "sequential", "pattern", "mining", ")", "."], "sentence-detokenized": "The real task of data mining is the semi-automatic or automatic analysis of large amounts of data to extract unknown, interesting patterns, such as groups of data records (cluster analysis), unusual records (anomaly detection) and dependencies (association rule mining, sequential pattern mining).", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 16], [17, 21], [22, 28], [29, 31], [32, 35], [36, 50], [51, 53], [54, 63], [64, 72], [73, 75], [76, 81], [82, 89], [90, 92], [93, 97], [98, 100], [101, 108], [109, 116], [116, 117], [118, 129], [130, 138], [138, 139], [140, 144], [145, 147], [148, 154], [155, 157], [158, 162], [163, 170], [171, 172], [172, 179], [180, 188], [188, 189], [189, 190], [191, 198], [199, 206], [207, 208], [208, 215], [216, 225], [225, 226], [227, 230], [231, 243], [244, 245], [245, 256], [257, 261], [262, 268], [268, 269], [270, 280], [281, 288], [289, 295], [295, 296], [296, 297]]}
{"doc_key": "ai-test-417", "ner": [[9, 12, "product"], [0, 1, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 12, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sentiment", "analysis", "has", "proven", "to", "be", "a", "valuable", "method", "in", "a", "recommender", "system", "."], "sentence-detokenized": "Sentiment analysis has proven to be a valuable method in a recommender system.", "token2charspan": [[0, 9], [10, 18], [19, 22], [23, 29], [30, 32], [33, 35], [36, 37], [38, 46], [47, 53], [54, 56], [57, 58], [59, 70], [71, 77], [77, 78]]}
{"doc_key": "ai-test-418", "ner": [[2, 5, "misc"], [13, 13, "product"], [31, 31, "organisation"], [34, 36, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 5, 13, 13, "usage", "", false, false], [31, 31, 34, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Coincidentally", ",", "the", "Germans", "made", "a", "very", "poor", "choice", "of", "frequency", "for", "the", "Wotan", "system", ";", "it", "was", "operating", "at", "45", "MHz", ",", "the", "same", "frequency", "as", "the", "powerful", "but", "non-functioning", "BBC", "television", "transmitter", "at", "Alexandra", "Palace", "."], "sentence-detokenized": "Coincidentally, the Germans made a very poor choice of frequency for the Wotan system; it was operating at 45 MHz, the same frequency as the powerful but non-functioning BBC television transmitter at Alexandra Palace.", "token2charspan": [[0, 14], [14, 15], [16, 19], [20, 27], [28, 32], [33, 34], [35, 39], [40, 44], [45, 51], [52, 54], [55, 64], [65, 68], [69, 72], [73, 78], [79, 85], [85, 86], [87, 89], [90, 93], [94, 103], [104, 106], [107, 109], [110, 113], [113, 114], [115, 118], [119, 123], [124, 133], [134, 136], [137, 140], [141, 149], [150, 153], [154, 169], [170, 173], [174, 184], [185, 196], [197, 199], [200, 209], [210, 216], [216, 217]]}
{"doc_key": "ai-test-419", "ner": [[8, 12, "metrics"], [15, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "into", "a", "2", "\u00d7", "2", "contingency", "table", "or", "a", "confusion", "matrix", ",", "as", "below", ":"], "sentence-detokenized": "The four results can be formulated into a 2 \u00d7 2 contingency table or a confusion matrix, as below:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 39], [40, 41], [42, 43], [44, 45], [46, 47], [48, 59], [60, 65], [66, 68], [69, 70], [71, 80], [81, 87], [87, 88], [89, 91], [92, 97], [97, 98]]}
{"doc_key": "ai-test-420", "ner": [[0, 3, "misc"], [7, 7, "misc"], [11, 11, "product"], [13, 13, "product"], [15, 17, "product"], [25, 27, "misc"], [38, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 11, 7, 7, "usage", "", false, false], [13, 13, 7, 7, "usage", "", false, false], [15, 17, 13, 13, "named", "", false, false], [25, 27, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "Semantic", "Web", "applications", "and", "quite", "popular", "RDF", "applications", "such", "as", "RSS", "and", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "resources", "are", "usually", "represented", "by", "URIs", "that", "target", "and", "can", "be", "used", "to", "access", "actual", "data", "on", "the", "World", "Wide", "Web", "."], "sentence-detokenized": "In Semantic Web applications and quite popular RDF applications such as RSS and FOAF (Friend a Friend), resources are usually represented by URIs that target and can be used to access actual data on the World Wide Web.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 28], [29, 32], [33, 38], [39, 46], [47, 50], [51, 63], [64, 68], [69, 71], [72, 75], [76, 79], [80, 84], [85, 86], [86, 92], [93, 94], [95, 101], [101, 102], [102, 103], [104, 113], [114, 117], [118, 125], [126, 137], [138, 140], [141, 145], [146, 150], [151, 157], [158, 161], [162, 165], [166, 168], [169, 173], [174, 176], [177, 183], [184, 190], [191, 195], [196, 198], [199, 202], [203, 208], [209, 213], [214, 217], [217, 218]]}
{"doc_key": "ai-test-421", "ner": [[0, 13, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "has", "examined", "this", "topic", "in", "detail"], "sentence-detokenized": "The Association for the Advancement of Artificial Intelligence has examined this topic in detail", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 75], [76, 80], [81, 86], [87, 89], [90, 96]]}
{"doc_key": "ai-test-422", "ner": [[0, 7, "product"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 16, 0, 7, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["\"", "The", "Apple", "Macintosh", "talking", "system", ",", "which", "started", "as", "a", "curiosity", ",", "has", "evolved", "into", "PlainTalk", ",", "a", "fully", "supported", "application", "for", "people", "with", "vision", "problems", "."], "sentence-detokenized": "\"The Apple Macintosh talking system, which started as a curiosity, has evolved into PlainTalk, a fully supported application for people with vision problems.", "token2charspan": [[0, 1], [1, 4], [5, 10], [11, 20], [21, 28], [29, 35], [35, 36], [37, 42], [43, 50], [51, 53], [54, 55], [56, 65], [65, 66], [67, 70], [71, 78], [79, 83], [84, 93], [93, 94], [95, 96], [97, 102], [103, 112], [113, 124], [125, 128], [129, 135], [136, 140], [141, 147], [148, 156], [156, 157]]}
{"doc_key": "ai-test-423", "ner": [[5, 5, "field"], [7, 8, "task"], [10, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 5, 5, "part-of", "task_part_of_field", false, false], [10, 11, 5, 5, "part-of", "task_part_of_field", false, false], [13, 14, 5, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "uses", "of", "ontologies", "in", "NLP", "are", "information", "retrieval", ",", "information", "extraction", "and", "automatic", "generalisation", "."], "sentence-detokenized": "Other uses of ontologies in NLP are information retrieval, information extraction and automatic generalisation.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 24], [25, 27], [28, 31], [32, 35], [36, 47], [48, 57], [57, 58], [59, 70], [71, 81], [82, 85], [86, 95], [96, 110], [110, 111]]}
{"doc_key": "ai-test-424", "ner": [[7, 15, "organisation"], [18, 22, "organisation"], [25, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Institute", "has", "worked", "closely", "with", "the", "Janelia", "Farm", "Campus", "of", "the", "Howard", "Hughes", "Medical", "Institute", ",", "the", "Allen", "Institute", "for", "Brain", "Science", "and", "the", "National", "Institutes", "of", "Health", "to", "develop", "better", "methods", "for", "reconstructing", "neural", "architecture", "."], "sentence-detokenized": "The Institute has worked closely with the Janelia Farm Campus of the Howard Hughes Medical Institute, the Allen Institute for Brain Science and the National Institutes of Health to develop better methods for reconstructing neural architecture.", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 24], [25, 32], [33, 37], [38, 41], [42, 49], [50, 54], [55, 61], [62, 64], [65, 68], [69, 75], [76, 82], [83, 90], [91, 100], [100, 101], [102, 105], [106, 111], [112, 121], [122, 125], [126, 131], [132, 139], [140, 143], [144, 147], [148, 156], [157, 167], [168, 170], [171, 177], [178, 180], [181, 188], [189, 195], [196, 203], [204, 207], [208, 222], [223, 229], [230, 242], [242, 243]]}
{"doc_key": "ai-test-425", "ner": [[0, 0, "organisation"], [4, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 15, 0, 0, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Google", "recently", "announced", "that", "Google", "Translate", "translates", "approximately", "enough", "text", "to", "fill", "1", "million", "books", "in", "one", "day", "(", "2012", ")", "."], "sentence-detokenized": "Google recently announced that Google Translate translates approximately enough text to fill 1 million books in one day (2012).", "token2charspan": [[0, 6], [7, 15], [16, 25], [26, 30], [31, 37], [38, 47], [48, 58], [59, 72], [73, 79], [80, 84], [85, 87], [88, 92], [93, 94], [95, 102], [103, 108], [109, 111], [112, 115], [116, 119], [120, 121], [121, 125], [125, 126], [126, 127]]}
{"doc_key": "ai-test-426", "ner": [[15, 15, "country"], [18, 18, "country"], [20, 20, "country"], [22, 22, "country"], [24, 24, "country"], [26, 27, "country"], [36, 37, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Events", "take", "place", "all", "over", "the", "world", ",", "with", "the", "most", "popular", "ones", "in", "the", "UK", ",", "the", "USA", ",", "Japan", ",", "Singapore", ",", "India", ",", "South", "Korea", ",", "and", "growing", "popularity", "in", "sub-continental", "countries", "like", "Sri", "Lanka", "."], "sentence-detokenized": "Events take place all over the world, with the most popular ones in the UK, the USA, Japan, Singapore, India, South Korea, and growing popularity in sub-continental countries like Sri Lanka.", "token2charspan": [[0, 6], [7, 11], [12, 17], [18, 21], [22, 26], [27, 30], [31, 36], [36, 37], [38, 42], [43, 46], [47, 51], [52, 59], [60, 64], [65, 67], [68, 71], [72, 74], [74, 75], [76, 79], [80, 83], [83, 84], [85, 90], [90, 91], [92, 101], [101, 102], [103, 108], [108, 109], [110, 115], [116, 121], [121, 122], [123, 126], [127, 134], [135, 145], [146, 148], [149, 164], [165, 174], [175, 179], [180, 183], [184, 189], [189, 190]]}
{"doc_key": "ai-test-427", "ner": [[6, 6, "programlang"], [10, 10, "programlang"], [12, 12, "programlang"], [14, 15, "programlang"], [17, 17, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "mainly", "developed", "in", "R", ",", "sometimes", "in", "Java", ",", "C", ",", "C", "++", "and", "Fortran", "."], "sentence-detokenized": "These packages are mainly developed in R, sometimes in Java, C, C++ and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 25], [26, 35], [36, 38], [39, 40], [40, 41], [42, 51], [52, 54], [55, 59], [59, 60], [61, 62], [62, 63], [64, 65], [65, 67], [68, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-test-428", "ner": [[0, 9, "conference"], [11, 11, "conference"], [14, 14, "researcher"], [16, 16, "researcher"], [20, 21, "researcher"], [24, 25, "algorithm"], [30, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 11, 0, 9, "named", "", false, false], [14, 14, 0, 9, "physical", "", false, false], [14, 14, 0, 9, "role", "", false, false], [14, 14, 20, 21, "role", "teams_up_with", false, false], [14, 14, 24, 25, "usage", "", false, false], [16, 16, 0, 9, "physical", "", false, false], [16, 16, 0, 9, "role", "", false, false], [16, 16, 20, 21, "role", "teams_up_with", false, false], [16, 16, 24, 25, "usage", "", false, false], [20, 21, 0, 9, "physical", "", false, false], [20, 21, 0, 9, "role", "", false, false], [20, 21, 24, 25, "usage", "", false, false], [24, 25, 30, 35, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["In", "2006", ",", "at", "the", "European", "Conference", "on", "Computer", "Vision", "(", "ECCV", ")", ",", "Dalal", "and", "Triggs", ",", "together", "with", "Cordelia", "Schmid", ",", "applied", "HOG", "detectors", "to", "the", "problem", "of", "detecting", "people", "in", "movies", "and", "videos", "."], "sentence-detokenized": "In 2006, at the European Conference on Computer Vision (ECCV), Dalal and Triggs, together with Cordelia Schmid, applied HOG detectors to the problem of detecting people in movies and videos.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 24], [25, 35], [36, 38], [39, 47], [48, 54], [55, 56], [56, 60], [60, 61], [61, 62], [63, 68], [69, 72], [73, 79], [79, 80], [81, 89], [90, 94], [95, 103], [104, 110], [110, 111], [112, 119], [120, 123], [124, 133], [134, 136], [137, 140], [141, 148], [149, 151], [152, 161], [162, 168], [169, 171], [172, 178], [179, 182], [183, 189], [189, 190]]}
{"doc_key": "ai-test-429", "ner": [[3, 3, "metrics"], [5, 7, "metrics"], [11, 12, "task"], [20, 22, "metrics"], [24, 27, "metrics"], [30, 30, "metrics"], [33, 35, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 3, 11, 12, "related-to", "measured_with", false, false], [5, 7, 11, 12, "related-to", "measured_with", false, false], [20, 22, 11, 12, "related-to", "measured_with", false, false], [24, 27, 20, 22, "named", "", false, false], [30, 30, 20, 22, "named", "", false, false], [37, 37, 33, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "addition", "to", "sensitivity", "and", "specificity", ",", "the", "performance", "of", "a", "binary", "classification", "test", "can", "be", "measured", "in", "terms", "of", "positive", "predictive", "value", "(", "PPV", ")", ",", "also", "known", "as", "accuracy", ",", "and", "negative", "predictive", "value", "(", "NPV", ")", "."], "sentence-detokenized": "In addition to sensitivity and specificity, the performance of a binary classification test can be measured in terms of positive predictive value (PPV), also known as accuracy, and negative predictive value (NPV).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 42], [42, 43], [44, 47], [48, 59], [60, 62], [63, 64], [65, 71], [72, 86], [87, 91], [92, 95], [96, 98], [99, 107], [108, 110], [111, 116], [117, 119], [120, 128], [129, 139], [140, 145], [146, 147], [147, 150], [150, 151], [151, 152], [153, 157], [158, 163], [164, 166], [167, 175], [175, 176], [177, 180], [181, 189], [190, 200], [201, 206], [207, 208], [208, 211], [211, 212], [212, 213]]}
{"doc_key": "ai-test-430", "ner": [[11, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "models", "can", "partially", "estimate", "overlapping", "matches", "(", "e.g.", "using", "the", "Jaccard", "index", "criterion", ")", "."], "sentence-detokenized": "Such models can partially estimate overlapping matches (e.g. using the Jaccard index criterion).", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 25], [26, 34], [35, 46], [47, 54], [55, 56], [56, 60], [61, 66], [67, 70], [71, 78], [79, 84], [85, 94], [94, 95], [95, 96]]}
{"doc_key": "ai-test-431", "ner": [[20, 25, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Moreover", ",", "the", "use", "of", "single", "-", "sample", "estimation", "highlights", "the", "philosophical", "problems", "and", "potential", "misunderstandings", "in", "the", "use", "of", "maximum", "likelihood", "estimates", "and", "likelihood", "functions", "."], "sentence-detokenized": "Moreover, the use of single-sample estimation highlights the philosophical problems and potential misunderstandings in the use of maximum likelihood estimates and likelihood functions.", "token2charspan": [[0, 8], [8, 9], [10, 13], [14, 17], [18, 20], [21, 27], [27, 28], [28, 34], [35, 45], [46, 56], [57, 60], [61, 74], [75, 83], [84, 87], [88, 97], [98, 115], [116, 118], [119, 122], [123, 126], [127, 129], [130, 137], [138, 148], [149, 158], [159, 162], [163, 173], [174, 183], [183, 184]]}
