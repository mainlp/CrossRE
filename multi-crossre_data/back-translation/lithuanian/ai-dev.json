{"doc_key": "ai-dev-1", "ner": [[4, 4, "metrics"], [9, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 13, 4, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["In", "this", "case", ",", "accuracy", "is", "measured", "by", "the", "error", "rate", ",", "which", "is", "defined", "as", "follows", ":"], "sentence-detokenized": "In this case, accuracy is measured by the error rate, which is defined as follows:", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 22], [23, 25], [26, 34], [35, 37], [38, 41], [42, 47], [48, 52], [52, 53], [54, 59], [60, 62], [63, 70], [71, 73], [74, 81], [81, 82]]}
{"doc_key": "ai-dev-2", "ner": [[4, 4, "algorithm"], [11, 13, "misc"], [15, 17, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 11, 13, "type-of", "", false, false], [4, 4, 15, 17, "related-to", "", false, false], [4, 4, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "this", "respect", ",", "SVM", "is", "closely", "related", "to", "other", "basic", "classification", "algorithms", "such", "as", "regularised", "least", "squares", "logistic", "regression", "."], "sentence-detokenized": "In this respect, SVM is closely related to other basic classification algorithms such as regularised least squares logistic regression.", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 20], [21, 23], [24, 31], [32, 39], [40, 42], [43, 48], [49, 54], [55, 69], [70, 80], [81, 85], [86, 88], [89, 100], [101, 106], [107, 114], [115, 123], [124, 134], [134, 135]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [3, 4, "person"], [13, 15, "person"], [16, 20, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 0, 1, "named", "actor_plays_character", false, false], [3, 4, 0, 1, "origin", "actor_plays_character", false, false], [16, 20, 13, 15, "named", "actor_plays_character", false, false], [16, 20, 13, 15, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "plays", "Leon", "Kovalski", ",", "a", "fighter", "and", "worker", "replicant", ",", "and", "Joanna", "Cassidy", "plays", "Zhora", ",", "a", "murderous", "replicant", "."], "sentence-detokenized": "Brion James plays Leon Kovalski, a fighter and worker replicant, and Joanna Cassidy plays Zhora, a murderous replicant.", "token2charspan": [[0, 5], [6, 11], [12, 17], [18, 22], [23, 31], [31, 32], [33, 34], [35, 42], [43, 46], [47, 53], [54, 63], [63, 64], [65, 68], [69, 75], [76, 83], [84, 89], [90, 95], [95, 96], [97, 98], [99, 108], [109, 118], [118, 119]]}
{"doc_key": "ai-dev-4", "ner": [[16, 19, "product"], [21, 21, "product"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 19, 15, 15, "physical", "", false, false], [21, 21, 16, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "image", "scanned", ",", "saved", "and", "restored", "as", "digital", "pixels", "was", "displayed", "on", "the", "NIST", "Standards", "East", "Automated", "Computer", "(", "SEAC", ")", "."], "sentence-detokenized": "The first image scanned, saved and restored as digital pixels was displayed on the NIST Standards East Automated Computer (SEAC).", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [23, 24], [25, 30], [31, 34], [35, 43], [44, 46], [47, 54], [55, 61], [62, 65], [66, 75], [76, 78], [79, 82], [83, 87], [88, 97], [98, 102], [103, 112], [113, 121], [122, 123], [123, 127], [127, 128], [128, 129]]}
{"doc_key": "ai-dev-5", "ner": [[0, 6, "task"], [20, 21, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 20, 21, "part-of", "", false, false], [0, 6, 23, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Segmenting", "text", "into", "topics", "or", "discourse", "turns", "can", "be", "useful", "in", "some", "natural", "processing", "tasks", ":", "it", "can", "significantly", "improve", "information", "retrieval", "or", "speech", "recognition", "(", "either", "by", "more", "accurately", "indexing", "and", "/", "or", "identifying", "documents", "or", "by", "providing", "a", "specific", "part", "of", "the", "document", "matching", "the", "query", "as", "a", "result", ")", "."], "sentence-detokenized": "Segmenting text into topics or discourse turns can be useful in some natural processing tasks: it can significantly improve information retrieval or speech recognition (either by more accurately indexing and/or identifying documents or by providing a specific part of the document matching the query as a result).", "token2charspan": [[0, 10], [11, 15], [16, 20], [21, 27], [28, 30], [31, 40], [41, 46], [47, 50], [51, 53], [54, 60], [61, 63], [64, 68], [69, 76], [77, 87], [88, 93], [93, 94], [95, 97], [98, 101], [102, 115], [116, 123], [124, 135], [136, 145], [146, 148], [149, 155], [156, 167], [168, 169], [169, 175], [176, 178], [179, 183], [184, 194], [195, 203], [204, 207], [207, 208], [208, 210], [211, 222], [223, 232], [233, 235], [236, 238], [239, 248], [249, 250], [251, 259], [260, 264], [265, 267], [268, 271], [272, 280], [281, 289], [290, 293], [294, 299], [300, 302], [303, 304], [305, 311], [311, 312], [312, 313]]}
{"doc_key": "ai-dev-6", "ner": [[9, 10, "university"], [26, 30, "conference"], [21, 23, "university"], [36, 37, "researcher"], [39, 40, "researcher"], [42, 43, "researcher"], [45, 46, "researcher"], [48, 49, "researcher"], [51, 52, "researcher"], [54, 56, "researcher"], [58, 59, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[26, 30, 21, 23, "physical", "", false, false], [36, 37, 26, 30, "physical", "", false, false], [36, 37, 26, 30, "role", "", false, false], [36, 37, 26, 30, "temporal", "", false, false], [39, 40, 26, 30, "physical", "", false, false], [39, 40, 26, 30, "role", "", false, false], [39, 40, 26, 30, "temporal", "", false, false], [42, 43, 26, 30, "physical", "", false, false], [42, 43, 26, 30, "role", "", false, false], [42, 43, 26, 30, "temporal", "", false, false], [45, 46, 26, 30, "physical", "", false, false], [45, 46, 26, 30, "role", "", false, false], [45, 46, 26, 30, "temporal", "", false, false], [48, 49, 26, 30, "physical", "", false, false], [48, 49, 26, 30, "role", "", false, false], [48, 49, 26, 30, "temporal", "", false, false], [51, 52, 26, 30, "physical", "", false, false], [51, 52, 26, 30, "role", "", false, false], [51, 52, 26, 30, "temporal", "", false, false], [54, 56, 26, 30, "physical", "", false, false], [54, 56, 26, 30, "role", "", false, false], [54, 56, 26, 30, "temporal", "", false, false], [58, 59, 26, 30, "physical", "", false, false], [58, 59, 26, 30, "role", "", false, false], [58, 59, 26, 30, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["In", "1999", ",", "he", "organised", "such", "a", "symposium", "at", "Indiana", "University", ",", "and", "in", "April", "2000", "he", "organised", "a", "larger", "symposium", "at", "Stanford", "University", "entitled", "\"", "Spiritual", "Robots", "\"", ",", "where", "he", "chaired", "a", "panel", "including", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", "and", "John", "Koza", "."], "sentence-detokenized": "In 1999, he organised such a symposium at Indiana University, and in April 2000 he organised a larger symposium at Stanford University entitled \"Spiritual Robots\", where he chaired a panel including Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland and John Koza.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 21], [22, 26], [27, 28], [29, 38], [39, 41], [42, 49], [50, 60], [60, 61], [62, 65], [66, 68], [69, 74], [75, 79], [80, 82], [83, 92], [93, 94], [95, 101], [102, 111], [112, 114], [115, 123], [124, 134], [135, 143], [144, 145], [145, 154], [155, 161], [161, 162], [162, 163], [164, 169], [170, 172], [173, 180], [181, 182], [183, 188], [189, 198], [199, 202], [203, 211], [211, 212], [213, 217], [218, 225], [225, 226], [227, 232], [233, 238], [238, 239], [240, 245], [246, 252], [252, 253], [254, 258], [259, 262], [262, 263], [264, 269], [270, 275], [275, 276], [277, 281], [282, 287], [288, 295], [296, 299], [300, 304], [305, 309], [309, 310]]}
{"doc_key": "ai-dev-7", "ner": [[9, 10, "metrics"], [13, 14, "metrics"], [18, 18, "metrics"], [19, 20, "metrics"], [22, 22, "metrics"], [41, 43, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 10, 22, 22, "named", "", false, false], [13, 14, 9, 10, "named", "", false, false], [18, 18, 41, 43, "named", "", false, false], [19, 20, 18, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "calculation", "of", "the", "score", "takes", "into", "account", "the", "precision", "of", "the", "test", ",", "p", ",", "and", "the", "response", ",", "r", ":", "p", "is", "the", "number", "of", "true", "positives", "divided", "by", "the", "number", "of", "total", "positives", "reported", "by", "the", "classifier", "and", "r", "is", "the", "number", "of", "true", "positives", "divided", "by", "the", "number", "of", "total", "eligible", "samples", "(", "all", "samples", "that", "should", "have", "been", "detected", "as", "positive", ")", "."], "sentence-detokenized": "The calculation of the score takes into account the precision of the test, p, and the response, r: p is the number of true positives divided by the number of total positives reported by the classifier and r is the number of true positives divided by the number of total eligible samples (all samples that should have been detected as positive).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 22], [23, 28], [29, 34], [35, 39], [40, 47], [48, 51], [52, 61], [62, 64], [65, 68], [69, 73], [73, 74], [75, 76], [76, 77], [78, 81], [82, 85], [86, 94], [94, 95], [96, 97], [97, 98], [99, 100], [101, 103], [104, 107], [108, 114], [115, 117], [118, 122], [123, 132], [133, 140], [141, 143], [144, 147], [148, 154], [155, 157], [158, 163], [164, 173], [174, 182], [183, 185], [186, 189], [190, 200], [201, 204], [205, 206], [207, 209], [210, 213], [214, 220], [221, 223], [224, 228], [229, 238], [239, 246], [247, 249], [250, 253], [254, 260], [261, 263], [264, 269], [270, 278], [279, 286], [287, 288], [288, 291], [292, 299], [300, 304], [305, 311], [312, 316], [317, 321], [322, 330], [331, 333], [334, 342], [342, 343], [343, 344]]}
{"doc_key": "ai-dev-8", "ner": [[21, 21, "product"], [34, 36, "person"], [31, 33, "misc"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[21, 21, 34, 36, "win-defeat", "", false, false], [21, 21, 31, 33, "win-defeat", "", true, false], [34, 36, 31, 33, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Since", "the", "acquisition", "of", "Google", ",", "the", "company", "has", "made", "a", "number", "of", "significant", "achievements", ",", "most", "notably", "the", "development", "of", "AlphaGo", ",", "which", "beat", "the", "world", "champion", "of", "the", "challenging", "game", "of", "Go", ",", "Lee", "Sedol", "."], "sentence-detokenized": "Since the acquisition of Google, the company has made a number of significant achievements, most notably the development of AlphaGo, which beat the world champion of the challenging game of Go, Lee Sedol.", "token2charspan": [[0, 5], [6, 9], [10, 21], [22, 24], [25, 31], [31, 32], [33, 36], [37, 44], [45, 48], [49, 53], [54, 55], [56, 62], [63, 65], [66, 77], [78, 90], [90, 91], [92, 96], [97, 104], [105, 108], [109, 120], [121, 123], [124, 131], [131, 132], [133, 138], [139, 143], [144, 147], [148, 153], [154, 162], [163, 165], [166, 169], [170, 181], [182, 186], [187, 189], [190, 192], [192, 193], [194, 197], [198, 203], [203, 204]]}
{"doc_key": "ai-dev-9", "ner": [[12, 13, "misc"], [25, 25, "field"], [26, 27, "product"], [44, 50, "misc"], [52, 53, "misc"], [56, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 13, 25, 25, "part-of", "", false, false], [12, 13, 52, 53, "named", "same", false, false], [26, 27, 44, 50, "related-to", "", false, false], [26, 27, 52, 53, "usage", "", false, false], [26, 27, 56, 56, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Representing", "words", "in", "their", "context", "using", "fixed", "-", "size", "dense", "vectors", "(", "word", "embeddings", ")", "has", "become", "one", "of", "the", "key", "building", "blocks", "of", "several", "NLP", "systems.Unsupervised", "disambiguation", "uses", "the", "similarity", "of", "word", "meanings", "in", "a", "fixed", "context", "window", "to", "select", "the", "most", "appropriate", "meaning", "of", "a", "word", ",", "using", "a", "pre-trained", "word", "embedding", "model", "and", "WordNet", "."], "sentence-detokenized": "Representing words in their context using fixed-size dense vectors (word embeddings) has become one of the key building blocks of several NLP systems.Unsupervised disambiguation uses the similarity of word meanings in a fixed context window to select the most appropriate meaning of a word, using a pre-trained word embedding model and WordNet.", "token2charspan": [[0, 12], [13, 18], [19, 21], [22, 27], [28, 35], [36, 41], [42, 47], [47, 48], [48, 52], [53, 58], [59, 66], [67, 68], [68, 72], [73, 83], [83, 84], [85, 88], [89, 95], [96, 99], [100, 102], [103, 106], [107, 110], [111, 119], [120, 126], [127, 129], [130, 137], [138, 141], [142, 162], [163, 177], [178, 182], [183, 186], [187, 197], [198, 200], [201, 205], [206, 214], [215, 217], [218, 219], [220, 225], [226, 233], [234, 240], [241, 243], [244, 250], [251, 254], [255, 259], [260, 271], [272, 279], [280, 282], [283, 284], [285, 289], [289, 290], [291, 296], [297, 298], [299, 310], [311, 315], [316, 325], [326, 331], [332, 335], [336, 343], [343, 344]]}
{"doc_key": "ai-dev-10", "ner": [[0, 1, "field"], [11, 12, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "methods", "are", "used", "to", "automatically", "identify", "such", "rules", "-", "supervised", "learning", "or", "unsupervised", "learning", "."], "sentence-detokenized": "Machine learning methods are used to automatically identify such rules - supervised learning or unsupervised learning.", "token2charspan": [[0, 7], [8, 16], [17, 24], [25, 28], [29, 33], [34, 36], [37, 50], [51, 59], [60, 64], [65, 70], [71, 72], [73, 83], [84, 92], [93, 95], [96, 108], [109, 117], [117, 118]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1969", ",", "Scheinman", "invents", "the", "Stanford", "Hand", ","], "sentence-detokenized": "In 1969, Scheinman invents the Stanford Hand,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 26], [27, 30], [31, 39], [40, 44], [44, 45]]}
{"doc_key": "ai-dev-12", "ner": [[2, 3, "metrics"], [8, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "the", "Log", "losses", "are", "graded", ",", "a", "gradient", "-", "based", "approach", "can", "be", "used", "to", "optimise", "the", "model", "."], "sentence-detokenized": "Since the Log losses are graded, a gradient-based approach can be used to optimise the model.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 20], [21, 24], [25, 31], [31, 32], [33, 34], [35, 43], [43, 44], [44, 49], [50, 58], [59, 62], [63, 65], [66, 70], [71, 73], [74, 82], [83, 86], [87, 92], [92, 93]]}
{"doc_key": "ai-dev-13", "ner": [[1, 2, "field"], [4, 6, "algorithm"], [8, 8, "algorithm"], [11, 13, "algorithm"], [16, 17, "field"], [26, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 6, 16, 17, "part-of", "", false, false], [8, 8, 4, 6, "named", "", false, false], [11, 13, 4, 6, "named", "", false, false], [16, 17, 1, 2, "part-of", "subfield", false, false], [26, 26, 16, 17, "part-of", "", false, false], [28, 29, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "machine", "learning", ",", "support", "vector", "machines", "(", "SVMs", ",", "also", "support", "vector", "networks", ")", "are", "supervised", "learning", "models", "with", "learning", "algorithms", "that", "analyse", "data", "for", "classification", "and", "regression", "analysis", "."], "sentence-detokenized": "In machine learning, support vector machines (SVMs, also support vector networks) are supervised learning models with learning algorithms that analyse data for classification and regression analysis.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 28], [29, 35], [36, 44], [45, 46], [46, 50], [50, 51], [52, 56], [57, 64], [65, 71], [72, 80], [80, 81], [82, 85], [86, 96], [97, 105], [106, 112], [113, 117], [118, 126], [127, 137], [138, 142], [143, 150], [151, 155], [156, 159], [160, 174], [175, 178], [179, 189], [190, 198], [198, 199]]}
{"doc_key": "ai-dev-14", "ner": [[9, 10, "task"], [12, 12, "task"], [24, 24, "metrics"], [26, 26, "metrics"], [28, 28, "researcher"], [30, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 12, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "2002", ")", "as", "an", "automatic", "metric", "for", "evaluating", "machine", "translation", "(", "MT", ")", ",", "many", "other", "methods", "have", "been", "proposed", ",", "such", "as", "TER", ",", "METEOR", ",", "Banerjee", "and", "Lavie", "(", "2005", ")", ",", "etc", "."], "sentence-detokenized": "(2002) as an automatic metric for evaluating machine translation (MT), many other methods have been proposed, such as TER, METEOR, Banerjee and Lavie (2005), etc.", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 9], [10, 12], [13, 22], [23, 29], [30, 33], [34, 44], [45, 52], [53, 64], [65, 66], [66, 68], [68, 69], [69, 70], [71, 75], [76, 81], [82, 89], [90, 94], [95, 99], [100, 108], [108, 109], [110, 114], [115, 117], [118, 121], [121, 122], [123, 129], [129, 130], [131, 139], [140, 143], [144, 149], [150, 151], [151, 155], [155, 156], [156, 157], [158, 161], [161, 162]]}
{"doc_key": "ai-dev-15", "ner": [[3, 7, "misc"], [8, 8, "organisation"], [11, 11, "organisation"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 7, 11, 11, "origin", "", false, false], [11, 11, 8, 8, "part-of", "", false, false], [14, 15, 11, 11, "role", "", false, false], [17, 18, 11, 11, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "contains", "the", "upper", "ontology", "developed", "by", "the", "IEEE", "working", "group", "P1600.1", "(", "authors", "Ian", "Niles", "and", "Adam", "Pease", ")", "."], "sentence-detokenized": "It contains the upper ontology developed by the IEEE working group P1600.1 (authors Ian Niles and Adam Pease).", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 21], [22, 30], [31, 40], [41, 43], [44, 47], [48, 52], [53, 60], [61, 66], [67, 74], [75, 76], [76, 83], [84, 87], [88, 93], [94, 97], [98, 102], [103, 108], [108, 109], [109, 110]]}
{"doc_key": "ai-dev-16", "ner": [[0, 4, "misc"], [30, 32, "algorithm"], [34, 35, "algorithm"], [38, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[30, 32, 0, 4, "part-of", "", true, false], [34, 35, 0, 4, "part-of", "", true, false], [38, 41, 34, 35, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "cryoelectron", "tomography", ",", "when", "hardware", "limitations", "result", "in", "a", "limited", "number", "of", "projections", "and", "to", "avoid", "damage", "to", "the", "biological", "sample", ",", "it", "can", "be", "used", "in", "combination", "with", "compression", "sensing", "techniques", "or", "regularisation", "functions", "(", "e.g.", "Huber", "loss", ")", "to", "improve", "reconstruction", "and", "enhance", "interpretation", "."], "sentence-detokenized": "In cryoelectron tomography, when hardware limitations result in a limited number of projections and to avoid damage to the biological sample, it can be used in combination with compression sensing techniques or regularisation functions (e.g. Huber loss) to improve reconstruction and enhance interpretation.", "token2charspan": [[0, 2], [3, 15], [16, 26], [26, 27], [28, 32], [33, 41], [42, 53], [54, 60], [61, 63], [64, 65], [66, 73], [74, 80], [81, 83], [84, 95], [96, 99], [100, 102], [103, 108], [109, 115], [116, 118], [119, 122], [123, 133], [134, 140], [140, 141], [142, 144], [145, 148], [149, 151], [152, 156], [157, 159], [160, 171], [172, 176], [177, 188], [189, 196], [197, 207], [208, 210], [211, 225], [226, 235], [236, 237], [237, 241], [242, 247], [248, 252], [252, 253], [254, 256], [257, 264], [265, 279], [280, 283], [284, 291], [292, 306], [306, 307]]}
{"doc_key": "ai-dev-17", "ner": [[4, 4, "misc"], [21, 21, "programlang"], [8, 9, "algorithm"], [11, 16, "algorithm"], [17, 18, "algorithm"], [27, 30, "product"], [33, 33, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 4, 21, 21, "part-of", "", false, false], [8, 9, 4, 4, "type-of", "", false, false], [11, 16, 4, 4, "type-of", "", false, false], [17, 18, 4, 4, "type-of", "", false, false], [27, 30, 21, 21, "general-affiliation", "", true, false], [27, 30, 21, 21, "part-of", "", true, false], [33, 33, 27, 30, "role", "publishes", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "implementation", "of", "several", "bleaching", "procedures", ",", "including", "ZCA", "bleaching", "and", "PCA", "bleaching", ",", "as", "well", "as", "CCA", "bleaching", ",", "in", "R", ",", "is", "provided", "in", "the", "R", "package", "for", "bleaching", "published", "by", "CRAN", "."], "sentence-detokenized": "The implementation of several bleaching procedures, including ZCA bleaching and PCA bleaching, as well as CCA bleaching, in R, is provided in the R package for bleaching published by CRAN.", "token2charspan": [[0, 3], [4, 18], [19, 21], [22, 29], [30, 39], [40, 50], [50, 51], [52, 61], [62, 65], [66, 75], [76, 79], [80, 83], [84, 93], [93, 94], [95, 97], [98, 102], [103, 105], [106, 109], [110, 119], [119, 120], [121, 123], [124, 125], [125, 126], [127, 129], [130, 138], [139, 141], [142, 145], [146, 147], [148, 155], [156, 159], [160, 169], [170, 179], [180, 182], [183, 187], [187, 188]]}
{"doc_key": "ai-dev-18", "ner": [[29, 29, "product"], [31, 31, "product"], [33, 33, "product"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [42, 43, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[29, 29, 33, 33, "compare", "", false, false], [29, 29, 35, 35, "compare", "", false, false], [29, 29, 37, 37, "compare", "", false, false], [29, 29, 39, 39, "compare", "", false, false], [29, 29, 42, 43, "compare", "", false, false], [31, 31, 33, 33, "compare", "", false, false], [31, 31, 35, 35, "compare", "", false, false], [31, 31, 37, 37, "compare", "", false, false], [31, 31, 39, 39, "compare", "", false, false], [31, 31, 42, 43, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Today", ",", "the", "field", "has", "become", "even", "more", "complex", ",", "with", "the", "emergence", "of", "more", "languages", "and", "software", "for", "circuit", ",", "system", "and", "signal", "analysis", "and", "design", "-", "from", "MATLAB", "and", "Simulink", "to", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "and", "even", "assembly", "language", "."], "sentence-detokenized": "Today, the field has become even more complex, with the emergence of more languages and software for circuit, system and signal analysis and design - from MATLAB and Simulink to NumPy, VHDL, PSpice, Verilog and even assembly language.", "token2charspan": [[0, 5], [5, 6], [7, 10], [11, 16], [17, 20], [21, 27], [28, 32], [33, 37], [38, 45], [45, 46], [47, 51], [52, 55], [56, 65], [66, 68], [69, 73], [74, 83], [84, 87], [88, 96], [97, 100], [101, 108], [108, 109], [110, 116], [117, 120], [121, 127], [128, 136], [137, 140], [141, 147], [148, 149], [150, 154], [155, 161], [162, 165], [166, 174], [175, 177], [178, 183], [183, 184], [185, 189], [189, 190], [191, 197], [197, 198], [199, 206], [207, 210], [211, 215], [216, 224], [225, 233], [233, 234]]}
{"doc_key": "ai-dev-19", "ner": [[7, 10, "person"], [14, 15, "person"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 14, 15, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "company", "was", "founded", "in", "1937", "by", "Kiichiro", "Toyoda", "as", "the", "automotive", "division", "of", "Sakichi", "Toyoda", "'s", "Toyota", "Industries", "."], "sentence-detokenized": "The company was founded in 1937 by Kiichiro Toyoda as the automotive division of Sakichi Toyoda's Toyota Industries.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 31], [32, 34], [35, 43], [44, 50], [51, 53], [54, 57], [58, 68], [69, 77], [78, 80], [81, 88], [89, 95], [95, 97], [98, 104], [105, 115], [115, 116]]}
{"doc_key": "ai-dev-20", "ner": [[0, 1, "field"], [55, 58, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[55, 58, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Unsupervised", "learning", ",", "on", "the", "other", "hand", ",", "relies", "on", "training", "data", "that", "has", "not", "been", "hand", "-", "labelled", ",", "and", "tries", "to", "find", "patterns", "in", "the", "data", "that", "can", "be", "used", "to", "determine", "the", "correct", "output", "value", "for", "new", "data", "instances", ".", "Recently", ",", "a", "combination", "of", "these", "two", "approaches", "has", "been", "explored", "-", "semi-supervised", "learning", ",", "which", "uses", "a", "combination", "of", "labelled", "and", "unlabelled", "data", "(", "typically", "a", "small", "set", "of", "labelled", "data", "together", "with", "a", "large", "amount", "of", "unlabelled", "data", ")", "."], "sentence-detokenized": "Unsupervised learning, on the other hand, relies on training data that has not been hand-labelled, and tries to find patterns in the data that can be used to determine the correct output value for new data instances. Recently, a combination of these two approaches has been explored - semi-supervised learning, which uses a combination of labelled and unlabelled data (typically a small set of labelled data together with a large amount of unlabelled data).", "token2charspan": [[0, 12], [13, 21], [21, 22], [23, 25], [26, 29], [30, 35], [36, 40], [40, 41], [42, 48], [49, 51], [52, 60], [61, 65], [66, 70], [71, 74], [75, 78], [79, 83], [84, 88], [88, 89], [89, 97], [97, 98], [99, 102], [103, 108], [109, 111], [112, 116], [117, 125], [126, 128], [129, 132], [133, 137], [138, 142], [143, 146], [147, 149], [150, 154], [155, 157], [158, 167], [168, 171], [172, 179], [180, 186], [187, 192], [193, 196], [197, 200], [201, 205], [206, 215], [215, 216], [217, 225], [225, 226], [227, 228], [229, 240], [241, 243], [244, 249], [250, 253], [254, 264], [265, 268], [269, 273], [274, 282], [283, 284], [285, 300], [301, 309], [309, 310], [311, 316], [317, 321], [322, 323], [324, 335], [336, 338], [339, 347], [348, 351], [352, 362], [363, 367], [368, 369], [369, 378], [379, 380], [381, 386], [387, 390], [391, 393], [394, 402], [403, 407], [408, 416], [417, 421], [422, 423], [424, 429], [430, 436], [437, 439], [440, 450], [451, 455], [455, 456], [456, 457]]}
{"doc_key": "ai-dev-21", "ner": [[20, 21, "organisation"], [22, 22, "product"], [24, 25, "organisation"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 20, 21, "artifact", "", false, false], [24, 25, 26, 27, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "addition", "to", "these", "humanoid", "robots", "for", "utilitarian", "applications", ",", "there", "are", "some", "humanoid", "robots", "for", "entertainment", ",", "such", "as", "Sony", "'s", "QRIO", "and", "Wow", "Wee", "'s", "RoboSapien", "."], "sentence-detokenized": "In addition to these humanoid robots for utilitarian applications, there are some humanoid robots for entertainment, such as Sony's QRIO and Wow Wee's RoboSapien.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 20], [21, 29], [30, 36], [37, 40], [41, 52], [53, 65], [65, 66], [67, 72], [73, 76], [77, 81], [82, 90], [91, 97], [98, 101], [102, 115], [115, 116], [117, 121], [122, 124], [125, 129], [129, 131], [132, 136], [137, 140], [141, 144], [145, 148], [148, 150], [151, 161], [161, 162]]}
{"doc_key": "ai-dev-22", "ner": [[3, 4, "researcher"], [10, 16, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 10, 16, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1991", ",", "Mr", "Webber", "became", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "In 1991, Mr Webber became a member of the Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 18], [19, 25], [26, 27], [28, 34], [35, 37], [38, 41], [42, 53], [54, 57], [58, 61], [62, 73], [74, 76], [77, 87], [88, 100], [100, 101]]}
{"doc_key": "ai-dev-23", "ner": [[6, 7, "field"], [9, 9, "field"], [21, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 24, 6, 7, "part-of", "task_part_of_field", false, false], [21, 24, 9, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "company", ",", "he", "developed", "data", "mining", "and", "database", "technology", ",", "more", "specifically", "high", "-", "level", "ontologies", "for", "intelligence", "and", "automatic", "natural", "language", "understanding", "."], "sentence-detokenized": "In this company, he developed data mining and database technology, more specifically high-level ontologies for intelligence and automatic natural language understanding.", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 19], [20, 29], [30, 34], [35, 41], [42, 45], [46, 54], [55, 65], [65, 66], [67, 71], [72, 84], [85, 89], [89, 90], [90, 95], [96, 106], [107, 110], [111, 123], [124, 127], [128, 137], [138, 145], [146, 154], [155, 168], [168, 169]]}
{"doc_key": "ai-dev-24", "ner": [[22, 23, "misc"], [26, 29, "misc"], [35, 36, "misc"], [37, 38, "country"], [41, 42, "organisation"], [43, 44, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[22, 23, 37, 38, "physical", "", false, false], [26, 29, 37, 38, "physical", "", false, false], [35, 36, 37, 38, "physical", "", false, false], [41, 42, 43, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["However", ",", "in", "recent", "years", ",", "developing", "countries", "have", "seen", "the", "emergence", "of", "various", "e-services", "and", "related", "initiatives", ",", "such", "as", "the", "Nemmadi", "project", ",", "the", "MCA21", "mission", "mode", "project", ",", "or", "even", "more", "so", "Digital", "India", "in", "India", ",", "the", "e-Governance", "Directorate", "in", "Pakistan", ",", "etc."], "sentence-detokenized": "However, in recent years, developing countries have seen the emergence of various e-services and related initiatives, such as the Nemmadi project, the MCA21 mission mode project, or even more so Digital India in India, the e-Governance Directorate in Pakistan, etc.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 18], [19, 24], [24, 25], [26, 36], [37, 46], [47, 51], [52, 56], [57, 60], [61, 70], [71, 73], [74, 81], [82, 92], [93, 96], [97, 104], [105, 116], [116, 117], [118, 122], [123, 125], [126, 129], [130, 137], [138, 145], [145, 146], [147, 150], [151, 156], [157, 164], [165, 169], [170, 177], [177, 178], [179, 181], [182, 186], [187, 191], [192, 194], [195, 202], [203, 208], [209, 211], [212, 217], [217, 218], [219, 222], [223, 235], [236, 247], [248, 250], [251, 259], [259, 260], [261, 265]]}
{"doc_key": "ai-dev-25", "ner": [[3, 3, "misc"], [5, 6, "field"], [8, 9, "field"], [10, 25, "university"], [19, 27, "university"], [11, 13, "university"], [35, 35, "misc"], [37, 39, "field"], [40, 55, "misc"], [43, 47, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10], "relations": [[3, 3, 5, 6, "topic", "", false, false], [3, 3, 8, 9, "topic", "", false, false], [3, 3, 10, 25, "origin", "", false, false], [10, 25, 19, 27, "part-of", "", false, false], [11, 13, 10, 25, "part-of", "", false, false], [35, 35, 37, 39, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "obtained", "a", "PhD", "in", "Radio", "Physics", "and", "Electronics", "from", "the", "Indian", "Statistical", "Institute", "as", "a", "student", "at", "the", "University", "of", "Calcutta", "'s", "Rajbazar", "Science", "College", ",", "Calcutta", "campus", ",", "in", "1979", ",", "and", "a", "PhD", "in", "Electrical", "Engineering", "from", "Imperial", "College", ",", "University", "of", "London", ",", "in", "1982", ",", "and", "a", "Diploma", "from", "Imperial", "College", "."], "sentence-detokenized": "He obtained a PhD in Radio Physics and Electronics from the Indian Statistical Institute as a student at the University of Calcutta's Rajbazar Science College, Calcutta campus, in 1979, and a PhD in Electrical Engineering from Imperial College, University of London, in 1982, and a Diploma from Imperial College.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 17], [18, 20], [21, 26], [27, 34], [35, 38], [39, 50], [51, 55], [56, 59], [60, 66], [67, 78], [79, 88], [89, 91], [92, 93], [94, 101], [102, 104], [105, 108], [109, 119], [120, 122], [123, 131], [131, 133], [134, 142], [143, 150], [151, 158], [158, 159], [160, 168], [169, 175], [175, 176], [177, 179], [180, 184], [184, 185], [186, 189], [190, 191], [192, 195], [196, 198], [199, 209], [210, 221], [222, 226], [227, 235], [236, 243], [243, 244], [245, 255], [256, 258], [259, 265], [265, 266], [267, 269], [270, 274], [274, 275], [276, 279], [280, 281], [282, 289], [290, 294], [295, 303], [304, 311], [311, 312]]}
{"doc_key": "ai-dev-26", "ner": [[5, 9, "location"], [23, 24, "misc"], [30, 31, "misc"], [33, 35, "person"], [37, 38, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[23, 24, 5, 9, "temporal", "", false, false], [30, 31, 5, 9, "temporal", "", false, false], [33, 35, 30, 31, "role", "actor_in", false, false], [37, 38, 30, 31, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "has", "been", "announced", "that", "Expo", "II", "will", "host", "the", "world", "premiere", "of", "several", "films", "never", "before", "seen", "in", "3D", ",", "including", "The", "Diamond", "Wizard", "and", "Universal", "'s", "short", "film", "Hawaiian", "Nights", "with", "Mamie", "Van", "Doren", "and", "Pinky", "Lee", "."], "sentence-detokenized": "It has been announced that Expo II will host the world premiere of several films never before seen in 3D, including The Diamond Wizard and Universal's short film Hawaiian Nights with Mamie Van Doren and Pinky Lee.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 21], [22, 26], [27, 31], [32, 34], [35, 39], [40, 44], [45, 48], [49, 54], [55, 63], [64, 66], [67, 74], [75, 80], [81, 86], [87, 93], [94, 98], [99, 101], [102, 104], [104, 105], [106, 115], [116, 119], [120, 127], [128, 134], [135, 138], [139, 148], [148, 150], [151, 156], [157, 161], [162, 170], [171, 177], [178, 182], [183, 188], [189, 192], [193, 198], [199, 202], [203, 208], [209, 212], [212, 213]]}
{"doc_key": "ai-dev-27", "ner": [[3, 4, "researcher"], [15, 21, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 15, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1977", ",", "Ulf", "Grenander", "proposed", "the", "maximum", "subset", "problem", "as", "a", "simplified", "model", "to", "estimate", "maximum", "likelihood", "models", "in", "digital", "images", "."], "sentence-detokenized": "In 1977, Ulf Grenander proposed the maximum subset problem as a simplified model to estimate maximum likelihood models in digital images.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 22], [23, 31], [32, 35], [36, 43], [44, 50], [51, 58], [59, 61], [62, 63], [64, 74], [75, 80], [81, 83], [84, 92], [93, 100], [101, 111], [112, 118], [119, 121], [122, 129], [130, 136], [136, 137]]}
{"doc_key": "ai-dev-28", "ner": [[0, 2, "product"], [4, 5, "product"], [7, 9, "product"], [11, 12, "product"], [15, 16, "product"], [18, 21, "product"], [32, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[32, 32, 0, 2, "part-of", "", false, false], [32, 32, 4, 5, "part-of", "", false, false], [32, 32, 7, 9, "part-of", "", false, false], [32, 32, 11, 12, "part-of", "", false, false], [32, 32, 15, 16, "part-of", "", false, false], [32, 32, 18, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["\"", "iPhone", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", ",", "iPod", "Touch", "5", "G", "and", "later", "devices", "feature", "a", "more", "advanced", "voice", "assistant", "called", "Siri", "."], "sentence-detokenized": "\"iPhone 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G, iPod Touch 5G and later devices feature a more advanced voice assistant called Siri.", "token2charspan": [[0, 1], [1, 7], [8, 10], [10, 11], [12, 16], [17, 18], [18, 19], [20, 24], [25, 29], [30, 32], [32, 33], [34, 38], [39, 42], [42, 43], [44, 48], [49, 52], [53, 55], [55, 56], [57, 61], [62, 67], [68, 69], [69, 70], [71, 74], [75, 80], [81, 88], [89, 96], [97, 98], [99, 103], [104, 112], [113, 118], [119, 128], [129, 135], [136, 140], [140, 141]]}
{"doc_key": "ai-dev-29", "ner": [[7, 8, "metrics"], [11, 14, "metrics"], [16, 17, "metrics"], [46, 49, "metrics"], [54, 57, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 14, 46, 49, "named", "", false, false], [16, 17, 11, 14, "named", "", false, false], [46, 49, 54, 57, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["It", "is", "easy", "to", "check", "that", "the", "logistic", "loss", "and", "the", "binary", "cross", "-entropy", "loss", "(", "Log", "loss", ")", "are", "indeed", "the", "same", "(", "up", "to", "the", "multidimensional", "constant", "math", "\\", "frac", "{", "1", "}", "{", "\\", "log", "(", "2", ")", "}", "/", "math", ")", ".", "Cross", "-entropy", "losses", "are", "closely", "related", "to", "the", "Kullback", "-", "Leibler", "divergence", "between", "the", "empirical", "distribution", "and", "the", "predicted", "distribution", "."], "sentence-detokenized": "It is easy to check that the logistic loss and the binary cross-entropy loss (Log loss) are indeed the same (up to the multidimensional constant math\\ frac {1} {\\ log (2)} / math). Cross-entropy losses are closely related to the Kullback-Leibler divergence between the empirical distribution and the predicted distribution.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 19], [20, 24], [25, 28], [29, 37], [38, 42], [43, 46], [47, 50], [51, 57], [58, 63], [63, 71], [72, 76], [77, 78], [78, 81], [82, 86], [86, 87], [88, 91], [92, 98], [99, 102], [103, 107], [108, 109], [109, 111], [112, 114], [115, 118], [119, 135], [136, 144], [145, 149], [149, 150], [151, 155], [156, 157], [157, 158], [158, 159], [160, 161], [161, 162], [163, 166], [167, 168], [168, 169], [169, 170], [170, 171], [172, 173], [174, 178], [178, 179], [179, 180], [181, 186], [186, 194], [195, 201], [202, 205], [206, 213], [214, 221], [222, 224], [225, 228], [229, 237], [237, 238], [238, 245], [246, 256], [257, 264], [265, 268], [269, 278], [279, 291], [292, 295], [296, 299], [300, 309], [310, 322], [322, 323]]}
{"doc_key": "ai-dev-30", "ner": [[0, 2, "algorithm"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "EM", "algorithm", "is", "used", "to", "find", "the", "(", "local", ")", "maximum", "likelihood", "parameters", "of", "a", "statistical", "model", "when", "the", "equations", "can", "not", "be", "solved", "directly", "."], "sentence-detokenized": "The EM algorithm is used to find the (local) maximum likelihood parameters of a statistical model when the equations cannot be solved directly.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 32], [33, 36], [37, 38], [38, 43], [43, 44], [45, 52], [53, 63], [64, 74], [75, 77], [78, 79], [80, 91], [92, 97], [98, 102], [103, 106], [107, 116], [117, 120], [120, 123], [124, 126], [127, 133], [134, 142], [142, 143]]}
{"doc_key": "ai-dev-31", "ner": [[10, 11, "task"], [14, 16, "task"], [18, 19, "task"], [21, 24, "task"], [25, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "research", "has", "been", "instrumental", "in", "the", "development", "of", "modern", "speech", "synthesis", "techniques", ",", "blind", "reading", "devices", ",", "speech", "perception", "and", "speech", "recognition", ",", "and", "motor", "theory", "of", "speech", "perception", "."], "sentence-detokenized": "This research has been instrumental in the development of modern speech synthesis techniques, blind reading devices, speech perception and speech recognition, and motor theory of speech perception.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 22], [23, 35], [36, 38], [39, 42], [43, 54], [55, 57], [58, 64], [65, 71], [72, 81], [82, 92], [92, 93], [94, 99], [100, 107], [108, 115], [115, 116], [117, 123], [124, 134], [135, 138], [139, 145], [146, 157], [157, 158], [159, 162], [163, 168], [169, 175], [176, 178], [179, 185], [186, 196], [196, 197]]}
{"doc_key": "ai-dev-32", "ner": [[2, 2, "product"], [3, 5, "misc"], [7, 7, "misc"], [11, 13, "misc"], [16, 16, "product"], [18, 18, "product"], [20, 22, "product"], [25, 25, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 5, 2, 2, "origin", "", false, false], [3, 5, 11, 13, "type-of", "", false, false], [3, 5, 16, 16, "related-to", "program_for", false, false], [3, 5, 18, 18, "related-to", "program_for", false, false], [3, 5, 20, 22, "related-to", "program_for", false, false], [3, 5, 25, 25, "related-to", "program_for", false, false], [7, 7, 3, 5, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\"", "The", "Arduino", "Integrated", "Development", "Environment", "(", "IDE", ")", "is", "a", "cross", "-platform", "application", "(", "for", "Windows", ",", "macOS", "and", "Linux", ")", "written", "in", "the", "Java", "programming", "language", "."], "sentence-detokenized": "\"The Arduino Integrated Development Environment (IDE) is a cross-platform application (for Windows, macOS and Linux) written in the Java programming language.", "token2charspan": [[0, 1], [1, 4], [5, 12], [13, 23], [24, 35], [36, 47], [48, 49], [49, 52], [52, 53], [54, 56], [57, 58], [59, 64], [64, 73], [74, 85], [86, 87], [87, 90], [91, 98], [98, 99], [100, 105], [106, 109], [110, 115], [115, 116], [117, 124], [125, 127], [128, 131], [132, 136], [137, 148], [149, 157], [157, 158]]}
{"doc_key": "ai-dev-33", "ner": [[18, 19, "algorithm"], [9, 11, "field"], [1, 2, "researcher"], [4, 5, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[18, 19, 9, 11, "opposite", "", false, false], [1, 2, 9, 11, "related-to", "works_with", false, false], [4, 5, 9, 11, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["After", "Marvin", "Minsky", "and", "Seymour", "Papert", "published", "their", "research", "on", "machine", "learning", "(", "1969", ")", ",", "research", "on", "neural", "networks", "stopped", "."], "sentence-detokenized": "After Marvin Minsky and Seymour Papert published their research on machine learning (1969), research on neural networks stopped.", "token2charspan": [[0, 5], [6, 12], [13, 19], [20, 23], [24, 31], [32, 38], [39, 48], [49, 54], [55, 63], [64, 66], [67, 74], [75, 83], [84, 85], [85, 89], [89, 90], [90, 91], [92, 100], [101, 103], [104, 110], [111, 119], [120, 127], [127, 128]]}
{"doc_key": "ai-dev-34", "ner": [[18, 19, "organisation"], [21, 21, "organisation"], [24, 26, "country"], [28, 31, "organisation"], [34, 34, "country"], [36, 37, "organisation"], [40, 40, "country"], [42, 42, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[28, 31, 24, 26, "general-affiliation", "", false, false], [36, 37, 34, 34, "general-affiliation", "", false, false], [42, 42, 40, 40, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Only", "a", "few", "non-Japanese", "companies", "have", "finally", "managed", "to", "survive", "in", "this", "market", ",", "the", "main", "ones", "being", "Adept", "Technology", ",", "St\u00e4ubli", ",", "the", "Swedish", "-", "Swiss", "company", "ABB", "Asea", "Brown", "Boveri", ",", "the", "German", "company", "KUKA", "Robotics", "and", "the", "Italian", "company", "Comau", "."], "sentence-detokenized": "Only a few non-Japanese companies have finally managed to survive in this market, the main ones being Adept Technology, St\u00e4ubli, the Swedish-Swiss company ABB Asea Brown Boveri, the German company KUKA Robotics and the Italian company Comau.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 23], [24, 33], [34, 38], [39, 46], [47, 54], [55, 57], [58, 65], [66, 68], [69, 73], [74, 80], [80, 81], [82, 85], [86, 90], [91, 95], [96, 101], [102, 107], [108, 118], [118, 119], [120, 127], [127, 128], [129, 132], [133, 140], [140, 141], [141, 146], [147, 154], [155, 158], [159, 163], [164, 169], [170, 176], [176, 177], [178, 181], [182, 188], [189, 196], [197, 201], [202, 210], [211, 214], [215, 218], [219, 226], [227, 234], [235, 240], [240, 241]]}
{"doc_key": "ai-dev-35", "ner": [[8, 9, "conference"], [14, 14, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 14, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Research", "activities", "include", "the", "annual", "research", "conference", "\"", "RuleML", "Symposium", "\"", ",", "abbreviated", "as", "RuleML", "."], "sentence-detokenized": "Research activities include the annual research conference \"RuleML Symposium\", abbreviated as RuleML.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 31], [32, 38], [39, 47], [48, 58], [59, 60], [60, 66], [67, 76], [76, 77], [77, 78], [79, 90], [91, 93], [94, 100], [100, 101]]}
{"doc_key": "ai-dev-36", "ner": [[8, 9, "field"], [11, 12, "field"], [14, 14, "field"], [16, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Concepts", "are", "used", "as", "formal", "tools", "or", "models", "in", "mathematics", ",", "computer", "science", ",", "databases", "and", "artificial", "intelligence", ",", "where", "they", "are", "sometimes", "called", "classes", ",", "schemas", "or", "categories", "."], "sentence-detokenized": "Concepts are used as formal tools or models in mathematics, computer science, databases and artificial intelligence, where they are sometimes called classes, schemas or categories.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 33], [34, 36], [37, 43], [44, 46], [47, 58], [58, 59], [60, 68], [69, 76], [76, 77], [78, 87], [88, 91], [92, 102], [103, 115], [115, 116], [117, 122], [123, 127], [128, 131], [132, 141], [142, 148], [149, 156], [156, 157], [158, 165], [166, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-dev-37", "ner": [[6, 8, "organisation"], [11, 14, "organisation"], [17, 18, "organisation"], [21, 23, "organisation"], [26, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "received", "awards", "from", "the", "American", "Psychological", "Association", ",", "the", "National", "Academy", "of", "Sciences", ",", "the", "Royal", "Society", ",", "the", "Cognitive", "Neuroscience", "Society", "and", "the", "American", "Humanist", "Association", "."], "sentence-detokenized": "He has received awards from the American Psychological Association, the National Academy of Sciences, the Royal Society, the Cognitive Neuroscience Society and the American Humanist Association.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 22], [23, 27], [28, 31], [32, 40], [41, 54], [55, 66], [66, 67], [68, 71], [72, 80], [81, 88], [89, 91], [92, 100], [100, 101], [102, 105], [106, 111], [112, 119], [119, 120], [121, 124], [125, 134], [135, 147], [148, 155], [156, 159], [160, 163], [164, 172], [173, 181], [182, 193], [193, 194]]}
{"doc_key": "ai-dev-38", "ner": [[0, 2, "person"], [4, 5, "person"], [7, 8, "person"], [16, 19, "person"], [23, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[23, 40, 16, 19, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starring", "Harrison", "Ford", ",", "Rutger", "Hauer", "and", "Sean", "Young", ",", "the", "film", "is", "loosely", "based", "on", "Philip", "K", ".", "Dick", "'s", "novel", "\"", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "?", "\"", "(", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "?", ",", "1968", ")", "."], "sentence-detokenized": "Starring Harrison Ford, Rutger Hauer and Sean Young, the film is loosely based on Philip K. Dick's novel \"Do Androids Dream of Electric Sheep?\" (Do Androids Dream of Electric Sheep?, 1968).", "token2charspan": [[0, 8], [9, 17], [18, 22], [22, 23], [24, 30], [31, 36], [37, 40], [41, 45], [46, 51], [51, 52], [53, 56], [57, 61], [62, 64], [65, 72], [73, 78], [79, 81], [82, 88], [89, 90], [90, 91], [92, 96], [96, 98], [99, 104], [105, 106], [106, 108], [109, 117], [118, 123], [124, 126], [127, 135], [136, 141], [141, 142], [142, 143], [144, 145], [145, 147], [148, 156], [157, 162], [163, 165], [166, 174], [175, 180], [180, 181], [181, 182], [183, 187], [187, 188], [188, 189]]}
{"doc_key": "ai-dev-39", "ner": [[0, 1, "task"], [3, 6, "algorithm"], [11, 12, "field"], [14, 15, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 3, 6, "usage", "", false, false], [0, 1, 11, 12, "part-of", "task_part_of_field", false, false], [0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Image", "segmentation", "using", "k-means", "clustering", "algorithms", "has", "long", "been", "used", "for", "pattern", "recognition", ",", "object", "detection", "and", "medical", "imaging", "."], "sentence-detokenized": "Image segmentation using k-means clustering algorithms has long been used for pattern recognition, object detection and medical imaging.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 32], [33, 43], [44, 54], [55, 58], [59, 63], [64, 68], [69, 73], [74, 77], [78, 85], [86, 97], [97, 98], [99, 105], [106, 115], [116, 119], [120, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-dev-40", "ner": [[16, 16, "algorithm"], [19, 20, "algorithm"], [23, 23, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "total", "sample", "from", "the", "truncated", "normal", "can", "be", "constructed", "using", "approximations", "of", "the", "normal", "'s", "CDF", "and", "the", "probit", "function", ",", "and", "R", "is", "a", "function", "codertnorm", "(", ")", "/", "code", "for", "generating", "truncated", "normal", "samples", "."], "sentence-detokenized": "The total sample from the truncated normal can be constructed using approximations of the normal's CDF and the probit function, and R is a function codertnorm()/code for generating truncated normal samples.", "token2charspan": [[0, 3], [4, 9], [10, 16], [17, 21], [22, 25], [26, 35], [36, 42], [43, 46], [47, 49], [50, 61], [62, 67], [68, 82], [83, 85], [86, 89], [90, 96], [96, 98], [99, 102], [103, 106], [107, 110], [111, 117], [118, 126], [126, 127], [128, 131], [132, 133], [134, 136], [137, 138], [139, 147], [148, 158], [158, 159], [159, 160], [160, 161], [161, 165], [166, 169], [170, 180], [181, 190], [191, 197], [198, 205], [205, 206]]}
{"doc_key": "ai-dev-41", "ner": [[7, 10, "university"], [12, 12, "university"], [14, 15, "university"], [17, 18, "university"], [20, 20, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "also", "received", "honorary", "doctorates", "from", "the", "Universities", "of", "Newcastle", ",", "Surrey", ",", "Tel", "Aviv", ",", "Simon", "Fraser", "and", "Troms\u00f8", "."], "sentence-detokenized": "He has also received honorary doctorates from the Universities of Newcastle, Surrey, Tel Aviv, Simon Fraser and Troms\u00f8.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 29], [30, 40], [41, 45], [46, 49], [50, 62], [63, 65], [66, 75], [75, 76], [77, 83], [83, 84], [85, 88], [89, 93], [93, 94], [95, 100], [101, 107], [108, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-dev-42", "ner": [[0, 2, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["\"", "A", "Java", "implementation", "using", "zero", "-", "based", "array", "indices", "and", "a", "convenient", "method", "for", "printing", "a", "resolvable", "order", "of", "operations", ":"], "sentence-detokenized": "\"A Java implementation using zero-based array indices and a convenient method for printing a resolvable order of operations:", "token2charspan": [[0, 1], [1, 2], [3, 7], [8, 22], [23, 28], [29, 33], [33, 34], [34, 39], [40, 45], [46, 53], [54, 57], [58, 59], [60, 70], [71, 77], [78, 81], [82, 90], [91, 92], [93, 103], [104, 109], [110, 112], [113, 123], [123, 124]]}
{"doc_key": "ai-dev-43", "ner": [[7, 8, "metrics"], [11, 12, "metrics"], [20, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Such", "networks", "are", "typically", "trained", "in", "the", "cross", "-entropy", "(", "or", "cross", "-entropy", ")", "regime", "using", "a", "non-linear", "version", "of", "polynomial", "logistic", "regression", "."], "sentence-detokenized": "Such networks are typically trained in the cross-entropy (or cross-entropy) regime using a non-linear version of polynomial logistic regression.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 27], [28, 35], [36, 38], [39, 42], [43, 48], [48, 56], [57, 58], [58, 60], [61, 66], [66, 74], [74, 75], [76, 82], [83, 88], [89, 90], [91, 101], [102, 109], [110, 112], [113, 123], [124, 132], [133, 143], [143, 144]]}
{"doc_key": "ai-dev-44", "ner": [[0, 1, "conference"], [4, 4, "misc"], [5, 15, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ACL", "has", "a", "European", "Chapter", "(", "the", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ")"], "sentence-detokenized": "The ACL has a European Chapter (the European Chapter of the Association for Computational Linguistics)", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 13], [14, 22], [23, 30], [31, 32], [32, 35], [36, 44], [45, 52], [53, 55], [56, 59], [60, 71], [72, 75], [76, 89], [90, 101], [101, 102]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 8, "researcher"], [20, 20, "misc"], [22, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 20, 20, "role", "", false, false], [6, 8, 20, 20, "role", "", false, false], [20, 20, 22, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "professors", ",", "Hal", "Abelson", "and", "Gerald", "Jay", "Sussman", ",", "decided", "to", "remain", "neutral", "-", "their", "group", "has", "been", "called", "Switzerland", "and", "Project", "MAC", "for", "30", "years", "."], "sentence-detokenized": "Two professors, Hal Abelson and Gerald Jay Sussman, decided to remain neutral - their group has been called Switzerland and Project MAC for 30 years.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 50], [50, 51], [52, 59], [60, 62], [63, 69], [70, 77], [78, 79], [80, 85], [86, 91], [92, 95], [96, 100], [101, 107], [108, 119], [120, 123], [124, 131], [132, 135], [136, 139], [140, 142], [143, 148], [148, 149]]}
{"doc_key": "ai-dev-46", "ner": [[1, 3, "misc"], [5, 5, "researcher"], [9, 11, "university"], [20, 20, "organisation"], [23, 27, "organisation"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 3, 5, 5, "temporal", "", false, false], [5, 5, 20, 20, "physical", "", false, false], [5, 5, 20, 20, "role", "", false, false], [5, 5, 23, 27, "role", "", false, false], [23, 27, 9, 11, "part-of", "", false, false], [29, 30, 23, 27, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["After", "completing", "his", "PhD", ",", "Ghahramani", "moved", "to", "the", "University", "of", "Toronto", "in", "1995", ",", "where", "he", "worked", "as", "an", "ITRC", "postdoctoral", "fellow", "in", "the", "Artificial", "Intelligence", "Lab", "with", "Geoffrey", "Hinton", "."], "sentence-detokenized": "After completing his PhD, Ghahramani moved to the University of Toronto in 1995, where he worked as an ITRC postdoctoral fellow in the Artificial Intelligence Lab with Geoffrey Hinton.", "token2charspan": [[0, 5], [6, 16], [17, 20], [21, 24], [24, 25], [26, 36], [37, 42], [43, 45], [46, 49], [50, 60], [61, 63], [64, 71], [72, 74], [75, 79], [79, 80], [81, 86], [87, 89], [90, 96], [97, 99], [100, 102], [103, 107], [108, 120], [121, 127], [128, 130], [131, 134], [135, 145], [146, 158], [159, 162], [163, 167], [168, 176], [177, 183], [183, 184]]}
{"doc_key": "ai-dev-47", "ner": [[23, 24, "metrics"], [26, 26, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[26, 26, 23, 24, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Subsequent", "work", "has", "focused", "on", "these", "problems", ",", "but", "it", "is", "only", "with", "the", "advent", "of", "the", "modern", "computer", "and", "the", "popularity", "of", "Maximum", "Likelihood", "(", "MLE", ")", "parameter", "estimation", "methods", "that", "research", "has", "really", "taken", "off", "."], "sentence-detokenized": "Subsequent work has focused on these problems, but it is only with the advent of the modern computer and the popularity of Maximum Likelihood (MLE) parameter estimation methods that research has really taken off.", "token2charspan": [[0, 10], [11, 15], [16, 19], [20, 27], [28, 30], [31, 36], [37, 45], [45, 46], [47, 50], [51, 53], [54, 56], [57, 61], [62, 66], [67, 70], [71, 77], [78, 80], [81, 84], [85, 91], [92, 100], [101, 104], [105, 108], [109, 119], [120, 122], [123, 130], [131, 141], [142, 143], [143, 146], [146, 147], [148, 157], [158, 168], [169, 176], [177, 181], [182, 190], [191, 194], [195, 201], [202, 207], [208, 211], [211, 212]]}
{"doc_key": "ai-dev-48", "ner": [[5, 7, "person"], [9, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "series", "was", "produced", "by", "David", "Fincher", "and", "starred", "Kevin", "Spacey", "."], "sentence-detokenized": "The series was produced by David Fincher and starred Kevin Spacey.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 40], [41, 44], [45, 52], [53, 58], [59, 65], [65, 66]]}
{"doc_key": "ai-dev-49", "ner": [[16, 18, "metrics"], [21, 22, "algorithm"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 22, 27, 28, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Due", "to", "limited", "computational", "power", ",", "current", "in", "silico", "methods", "usually", "have", "to", "trade", "speed", "for", "accuracy", ",", "e.g.", "using", "fast", "protein", "splicing", "methods", "instead", "of", "expensive", "free", "energy", "calculations", "."], "sentence-detokenized": "Due to limited computational power, current in silico methods usually have to trade speed for accuracy, e.g. using fast protein splicing methods instead of expensive free energy calculations.", "token2charspan": [[0, 3], [4, 6], [7, 14], [15, 28], [29, 34], [34, 35], [36, 43], [44, 46], [47, 53], [54, 61], [62, 69], [70, 74], [75, 77], [78, 83], [84, 89], [90, 93], [94, 102], [102, 103], [104, 108], [109, 114], [115, 119], [120, 127], [128, 136], [137, 144], [145, 152], [153, 155], [156, 165], [166, 170], [171, 177], [178, 190], [190, 191]]}
{"doc_key": "ai-dev-50", "ner": [[7, 8, "country"], [10, 10, "country"], [12, 12, "country"], [14, 14, "country"], [16, 16, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "had", "more", "than", "30", "branches", "in", "the", "US", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "sentence-detokenized": "It had more than 30 branches in the US, Canada, Mexico, Brazil and Argentina.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 19], [20, 28], [29, 31], [32, 35], [36, 38], [38, 39], [40, 46], [46, 47], [48, 54], [54, 55], [56, 62], [63, 66], [67, 76], [76, 77]]}
{"doc_key": "ai-dev-51", "ner": [[4, 5, "field"], [10, 12, "product"], [14, 16, "algorithm"], [23, 24, "task"], [26, 27, "task"], [32, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 12, 4, 5, "part-of", "", false, false], [10, 12, 14, 16, "usage", "", false, false], [23, 24, 4, 5, "part-of", "task_part_of_field", false, false], [23, 24, 32, 32, "related-to", "performs", false, false], [26, 27, 4, 5, "part-of", "task_part_of_field", false, false], [26, 27, 32, 32, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Example", "of", "a", "typical", "computer", "vision", "computational", "pipeline", "for", "a", "face", "recognition", "system", "using", "k", "-", "NN", ",", "including", "the", "pre-processing", "steps", "of", "feature", "extraction", "and", "dimensionality", "reduction", "(", "usually", "implemented", "using", "OpenCV", ")", ":"], "sentence-detokenized": "Example of a typical computer vision computational pipeline for a face recognition system using k -NN, including the pre-processing steps of feature extraction and dimensionality reduction (usually implemented using OpenCV):", "token2charspan": [[0, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 36], [37, 50], [51, 59], [60, 63], [64, 65], [66, 70], [71, 82], [83, 89], [90, 95], [96, 97], [98, 99], [99, 101], [101, 102], [103, 112], [113, 116], [117, 131], [132, 137], [138, 140], [141, 148], [149, 159], [160, 163], [164, 178], [179, 188], [189, 190], [190, 197], [198, 209], [210, 215], [216, 222], [222, 223], [223, 224]]}
{"doc_key": "ai-dev-52", "ner": [[8, 10, "algorithm"], [13, 13, "misc"], [15, 16, "misc"], [18, 18, "misc"], [22, 22, "programlang"], [24, 24, "product"], [28, 29, "algorithm"], [32, 33, "misc"], [35, 35, "misc"], [37, 37, "misc"], [39, 39, "misc"], [46, 46, "misc"], [49, 50, "misc"], [54, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "a", "wide", "range", "of", "features", ",", "constraint", "logic", "programming", "libraries", ",", "multithreading", ",", "unit", "testing", ",", "GUI", ",", "interfacing", "with", "Java", ",", "ODBC", ",", "etc.", ",", "literate", "programming", ",", "a", "web", "server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "developer", "tools", "(", "including", "an", "IDE", "with", "a", "GUI", "debugger", "and", "a", "GUI", "profiler", ")", ",", "and", "extensive", "documentation", "."], "sentence-detokenized": "It has a wide range of features, constraint logic programming libraries, multithreading, unit testing, GUI, interfacing with Java, ODBC, etc., literate programming, a web server, SGML, RDF, RDFS, developer tools (including an IDE with a GUI debugger and a GUI profiler), and extensive documentation.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 13], [14, 19], [20, 22], [23, 31], [31, 32], [33, 43], [44, 49], [50, 61], [62, 71], [71, 72], [73, 87], [87, 88], [89, 93], [94, 101], [101, 102], [103, 106], [106, 107], [108, 119], [120, 124], [125, 129], [129, 130], [131, 135], [135, 136], [137, 141], [141, 142], [143, 151], [152, 163], [163, 164], [165, 166], [167, 170], [171, 177], [177, 178], [179, 183], [183, 184], [185, 188], [188, 189], [190, 194], [194, 195], [196, 205], [206, 211], [212, 213], [213, 222], [223, 225], [226, 229], [230, 234], [235, 236], [237, 240], [241, 249], [250, 253], [254, 255], [256, 259], [260, 268], [268, 269], [269, 270], [271, 274], [275, 284], [285, 298], [298, 299]]}
{"doc_key": "ai-dev-53", "ner": [[1, 2, "field"], [4, 7, "field"], [10, 12, "misc"], [14, 16, "misc"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 1, 2, "part-of", "", true, false], [10, 12, 4, 7, "part-of", "", false, false], [10, 12, 18, 20, "type-of", "", false, false], [14, 16, 1, 2, "part-of", "", false, false], [14, 16, 4, 7, "part-of", "", false, false], [14, 16, 18, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "computer", "vision", "and", "image", "processing", ",", "the", "concept", "of", "scalable", "spatial", "imaging", "and", "Gaussian", "derivative", "operators", "is", "canonical", "multiscale", "imaging", "."], "sentence-detokenized": "In computer vision and image processing, the concept of scalable spatial imaging and Gaussian derivative operators is canonical multiscale imaging.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 22], [23, 28], [29, 39], [39, 40], [41, 44], [45, 52], [53, 55], [56, 64], [65, 72], [73, 80], [81, 84], [85, 93], [94, 104], [105, 114], [115, 117], [118, 127], [128, 138], [139, 146], [146, 147]]}
{"doc_key": "ai-dev-54", "ner": [[6, 11, "organisation"], [20, 27, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 11, 20, 27, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "also", "President", "of", "the", "Foundation", "for", "Neural", "Information", "Processing", "Systems", ",", "a", "non-profit", "organisation", "that", "oversees", "the", "annual", "conference", "\"", "Conference", "on", "Neural", "Information", "Processing", "Systems", "\"", "."], "sentence-detokenized": "He is also President of the Foundation for Neural Information Processing Systems, a non-profit organisation that oversees the annual conference \"Conference on Neural Information Processing Systems\".", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 20], [21, 23], [24, 27], [28, 38], [39, 42], [43, 49], [50, 61], [62, 72], [73, 80], [80, 81], [82, 83], [84, 94], [95, 107], [108, 112], [113, 121], [122, 125], [126, 132], [133, 143], [144, 145], [145, 155], [156, 158], [159, 165], [166, 177], [178, 188], [189, 196], [196, 197], [197, 198]]}
{"doc_key": "ai-dev-55", "ner": [[0, 2, "task"], [6, 16, "metrics"], [13, 14, "misc"], [18, 18, "task"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 6, 16, "usage", "", false, false], [6, 16, 13, 14, "type-of", "", false, false], [18, 18, 22, 23, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["For", "regression", "analysis", "tasks", ",", "the", "squared", "error", "can", "be", "used", "as", "a", "loss", "function", ",", "and", "for", "classification", "tasks", ",", "the", "cross", "-entropy", "can", "be", "used", "."], "sentence-detokenized": "For regression analysis tasks, the squared error can be used as a loss function, and for classification tasks, the cross-entropy can be used.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 29], [29, 30], [31, 34], [35, 42], [43, 48], [49, 52], [53, 55], [56, 60], [61, 63], [64, 65], [66, 70], [71, 79], [79, 80], [81, 84], [85, 88], [89, 103], [104, 109], [109, 110], [111, 114], [115, 120], [120, 128], [129, 132], [133, 135], [136, 140], [140, 141]]}
{"doc_key": "ai-dev-56", "ner": [[0, 3, "researcher"], [15, 16, "university"], [18, 19, "field"], [28, 43, "conference"]], "ner_mapping_to_source": [0, 3, 4, 5], "relations": [[0, 3, 15, 16, "physical", "", false, false], [0, 3, 15, 16, "role", "", false, false], [0, 3, 28, 43, "role", "", false, false], [15, 16, 18, 19, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [1, 2, 3, 5], "sentence": ["Lafferty", "has", "held", "a", "number", "of", "prestigious", "positions", ",", "including", ":", "1", ")", "co-director", "of", "CMU", "'s", "new", "Machine", "Learning", "PhD", "programme", ";", "2", ")", "associate", "editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research", ";", "3", ")", "editor", "of", "the", "Journal", "of", "Machine", "Learning", "."], "sentence-detokenized": "Lafferty has held a number of prestigious positions, including: 1) co-director of CMU's new Machine Learning PhD programme; 2) associate editor of the Journal of Machine Learning Research; 3) editor of the Journal of Machine Learning.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 19], [20, 26], [27, 29], [30, 41], [42, 51], [51, 52], [53, 62], [62, 63], [64, 65], [65, 66], [67, 78], [79, 81], [82, 85], [85, 87], [88, 91], [92, 99], [100, 108], [109, 112], [113, 122], [122, 123], [124, 125], [125, 126], [127, 136], [137, 143], [144, 146], [147, 150], [151, 158], [159, 161], [162, 169], [170, 178], [179, 187], [187, 188], [189, 190], [190, 191], [192, 198], [199, 201], [202, 205], [206, 213], [214, 216], [217, 224], [225, 233], [233, 234]]}
{"doc_key": "ai-dev-57", "ner": [[0, 3, "misc"], [4, 4, "algorithm"], [6, 6, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 0, 3, "type-of", "", false, false], [6, 6, 0, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Convex", "algorithms", "such", "as", "AdaBoost", "and", "LogitBoost", "can", "be", "thwarted", "by", "random", "noise", ",", "making", "them", "unable", "to", "learn", "basic", "and", "learnable", "combinations", "of", "weak", "hypotheses", "."], "sentence-detokenized": "Convex algorithms such as AdaBoost and LogitBoost can be thwarted by random noise, making them unable to learn basic and learnable combinations of weak hypotheses.", "token2charspan": [[0, 6], [7, 17], [18, 22], [23, 25], [26, 34], [35, 38], [39, 49], [50, 53], [54, 56], [57, 65], [66, 68], [69, 75], [76, 81], [81, 82], [83, 89], [90, 94], [95, 101], [102, 104], [105, 110], [111, 116], [117, 120], [121, 130], [131, 143], [144, 146], [147, 151], [152, 162], [162, 163]]}
{"doc_key": "ai-dev-58", "ner": [[0, 1, "product"], [4, 8, "product"], [11, 14, "algorithm"], [20, 21, "algorithm"], [24, 29, "task"], [31, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 4, 8, "type-of", "", false, false], [0, 1, 11, 14, "usage", "", false, false], [0, 1, 20, 21, "usage", "", false, false], [20, 21, 24, 29, "related-to", "used_for", true, false], [20, 21, 31, 33, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["\"", "Apertium", "is", "a", "shallow", "transfer", "machine", "translation", "system", "that", "uses", "finite", "-", "state", "transducers", "for", "all", "lexical", "transformations", "and", "hidden", "Markov", "models", "for", "part", "-", "of", "-", "speech", "tagging", "or", "word", "category", "disambiguation", "."], "sentence-detokenized": "\"Apertium is a shallow transfer machine translation system that uses finite-state transducers for all lexical transformations and hidden Markov models for part-of-speech tagging or word category disambiguation.", "token2charspan": [[0, 1], [1, 9], [10, 12], [13, 14], [15, 22], [23, 31], [32, 39], [40, 51], [52, 58], [59, 63], [64, 68], [69, 75], [75, 76], [76, 81], [82, 93], [94, 97], [98, 101], [102, 109], [110, 125], [126, 129], [130, 136], [137, 143], [144, 150], [151, 154], [155, 159], [159, 160], [160, 162], [162, 163], [163, 169], [170, 177], [178, 180], [181, 185], [186, 194], [195, 209], [209, 210]]}
{"doc_key": "ai-dev-59", "ner": [[0, 2, "misc"], [14, 16, "metrics"], [29, 30, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 14, 16, "related-to", "", true, false], [14, 16, 29, 30, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "natural", "gradient", "mathE", "f", "(", "x", ")", "/", "math", ",", "corresponding", "to", "the", "Fisher", "information", "metric", "(", "a", "measure", "of", "the", "information", "distance", "between", "probability", "distributions", "and", "the", "relative", "entropy", "curve", ")", ",", "now", "reads"], "sentence-detokenized": "The natural gradient mathE f (x) / math, corresponding to the Fisher information metric (a measure of the information distance between probability distributions and the relative entropy curve), now reads", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 26], [27, 28], [29, 30], [30, 31], [31, 32], [33, 34], [35, 39], [39, 40], [41, 54], [55, 57], [58, 61], [62, 68], [69, 80], [81, 87], [88, 89], [89, 90], [91, 98], [99, 101], [102, 105], [106, 117], [118, 126], [127, 134], [135, 146], [147, 160], [161, 164], [165, 168], [169, 177], [178, 185], [186, 191], [191, 192], [192, 193], [194, 197], [198, 203]]}
{"doc_key": "ai-dev-60", "ner": [[0, 3, "programlang"], [6, 9, "product"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 0, 3, "origin", "", false, false], [11, 11, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "S", "programming", "language", "inspired", "the", "S", "'", "-", "PLUS", "and", "R", "systems", "."], "sentence-detokenized": "The S programming language inspired the S '-PLUS and R systems.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 26], [27, 35], [36, 39], [40, 41], [42, 43], [43, 44], [44, 48], [49, 52], [53, 54], [55, 62], [62, 63]]}
{"doc_key": "ai-dev-61", "ner": [[5, 5, "product"], [11, 11, "product"], [13, 17, "product"], [19, 21, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 11, 11, "named", "same", false, false], [13, 17, 11, 11, "origin", "derived_from", false, false], [13, 17, 19, 21, "origin", "", false, false], [13, 17, 23, 24, "origin", "", false, false], [13, 17, 26, 27, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "most", "influential", "implementation", "of", "Planner", "has", "been", "a", "subset", "of", "Planner", "called", "Micro", "-", "Planner", ",", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "."], "sentence-detokenized": "The most influential implementation of Planner has been a subset of Planner called Micro-Planner, implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 35], [36, 38], [39, 46], [47, 50], [51, 55], [56, 57], [58, 64], [65, 67], [68, 75], [76, 82], [83, 88], [88, 89], [89, 96], [96, 97], [98, 109], [110, 112], [113, 119], [120, 123], [124, 131], [131, 132], [133, 139], [140, 148], [149, 152], [153, 158], [159, 167], [167, 168]]}
{"doc_key": "ai-dev-62", "ner": [[4, 6, "country"], [8, 10, "researcher"], [20, 20, "misc"], [21, 28, "university"], [33, 34, "misc"], [43, 43, "misc"], [45, 47, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[8, 10, 4, 6, "general-affiliation", "from_country", false, false], [21, 28, 20, 20, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1779", ",", "the", "German", "-", "Danish", "scientist", "Christian", "Gottlieb", "Kratzenstein", "won", "first", "prize", "in", "a", "competition", "organised", "by", "the", "Russian", "Imperial", "Academy", "of", "Sciences", "and", "Arts", "for", "his", "models", "of", "the", "human", "vocal", "tract", ",", "which", "were", "able", "to", "produce", "five", "long", "vowels", "(", "International", "Phonetic", "Alphabet", "inscription", ":"], "sentence-detokenized": "In 1779, the German-Danish scientist Christian Gottlieb Kratzenstein won first prize in a competition organised by the Russian Imperial Academy of Sciences and Arts for his models of the human vocal tract, which were able to produce five long vowels (International Phonetic Alphabet inscription:", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [19, 20], [20, 26], [27, 36], [37, 46], [47, 55], [56, 68], [69, 72], [73, 78], [79, 84], [85, 87], [88, 89], [90, 101], [102, 111], [112, 114], [115, 118], [119, 126], [127, 135], [136, 143], [144, 146], [147, 155], [156, 159], [160, 164], [165, 168], [169, 172], [173, 179], [180, 182], [183, 186], [187, 192], [193, 198], [199, 204], [204, 205], [206, 211], [212, 216], [217, 221], [222, 224], [225, 232], [233, 237], [238, 242], [243, 249], [250, 251], [251, 264], [265, 273], [274, 282], [283, 294], [294, 295]]}
{"doc_key": "ai-dev-63", "ner": [[3, 5, "product"], [7, 8, "misc"], [11, 16, "misc"], [32, 35, "misc"], [56, 56, "task"], [61, 62, "product"], [64, 64, "product"], [68, 69, "task"], [71, 72, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 5, 61, 62, "related-to", "supports_program", false, false], [3, 5, 64, 64, "related-to", "supports_program", false, false], [7, 8, 3, 5, "part-of", "", false, false], [11, 16, 3, 5, "part-of", "", false, false], [32, 35, 3, 5, "part-of", "", false, false], [56, 56, 3, 5, "part-of", "", false, false], [68, 69, 3, 5, "part-of", "", false, false], [71, 72, 3, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["New", "features", "in", "Office", "XP", "include", ":", "smart", "bookmarks", ",", "a", "choice", "-", "based", "search", "function", "that", "recognises", "different", "types", "of", "text", "in", "a", "document", "so", "users", "can", "take", "additional", "actions", ";", "a", "taskbar", "interface", "that", "concentrates", "popular", "menu", "bar", "commands", "on", "the", "right", "-", "hand", "side", "of", "the", "screen", "for", "quick", "access", ";", "new", "document", "collaboration", "capabilities", ",", "support", "for", "MSN", "Groups", "and", "SharePoint", ";", "and", "integrated", "handwriting", "recognition", "and", "speech", "recognition", "features", "."], "sentence-detokenized": "New features in Office XP include: smart bookmarks, a choice-based search function that recognises different types of text in a document so users can take additional actions; a taskbar interface that concentrates popular menu bar commands on the right-hand side of the screen for quick access; new document collaboration capabilities, support for MSN Groups and SharePoint; and integrated handwriting recognition and speech recognition features.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 25], [26, 33], [33, 34], [35, 40], [41, 50], [50, 51], [52, 53], [54, 60], [60, 61], [61, 66], [67, 73], [74, 82], [83, 87], [88, 98], [99, 108], [109, 114], [115, 117], [118, 122], [123, 125], [126, 127], [128, 136], [137, 139], [140, 145], [146, 149], [150, 154], [155, 165], [166, 173], [173, 174], [175, 176], [177, 184], [185, 194], [195, 199], [200, 212], [213, 220], [221, 225], [226, 229], [230, 238], [239, 241], [242, 245], [246, 251], [251, 252], [252, 256], [257, 261], [262, 264], [265, 268], [269, 275], [276, 279], [280, 285], [286, 292], [292, 293], [294, 297], [298, 306], [307, 320], [321, 333], [333, 334], [335, 342], [343, 346], [347, 350], [351, 357], [358, 361], [362, 372], [372, 373], [374, 377], [378, 388], [389, 400], [401, 412], [413, 416], [417, 423], [424, 435], [436, 444], [444, 445]]}
{"doc_key": "ai-dev-64", "ner": [[11, 12, "algorithm"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 15, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "many", "applications", ",", "the", "units", "of", "these", "networks", "use", "a", "sigmoid", "function", "as", "an", "activation", "function", "."], "sentence-detokenized": "In many applications, the units of these networks use a sigmoid function as an activation function.", "token2charspan": [[0, 2], [3, 7], [8, 20], [20, 21], [22, 25], [26, 31], [32, 34], [35, 40], [41, 49], [50, 53], [54, 55], [56, 63], [64, 72], [73, 75], [76, 78], [79, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-dev-65", "ner": [[3, 4, "researcher"], [12, 17, "organisation"], [26, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 12, 17, "role", "", false, false], [3, 4, 26, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2001", ",", "Mehler", "was", "elected", "a", "Foreign", "Honorary", "Member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "and", "in", "2003", "a", "Fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In 2001, Mehler was elected a Foreign Honorary Member of the American Academy of Arts and Sciences, and in 2003 a Fellow of the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 27], [28, 29], [30, 37], [38, 46], [47, 53], [54, 56], [57, 60], [61, 69], [70, 77], [78, 80], [81, 85], [86, 89], [90, 98], [98, 99], [100, 103], [104, 106], [107, 111], [112, 113], [114, 120], [121, 123], [124, 127], [128, 136], [137, 148], [149, 152], [153, 156], [157, 168], [169, 171], [172, 179], [179, 180]]}
{"doc_key": "ai-dev-66", "ner": [[4, 9, "task"], [10, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 9, 10, 11, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Extending", "this", "concept", "to", "non", "-binary", "classifications", "results", "in", "a", "confusion", "matrix", "."], "sentence-detokenized": "Extending this concept to non-binary classifications results in a confusion matrix.", "token2charspan": [[0, 9], [10, 14], [15, 22], [23, 25], [26, 29], [29, 36], [37, 52], [53, 60], [61, 63], [64, 65], [66, 75], [76, 82], [82, 83]]}
{"doc_key": "ai-dev-67", "ner": [[15, 16, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "updated", "estimate", "of", "the", "variance", "of", "the", "measurement", "noise", "can", "be", "obtained", "from", "the", "maximum", "likelihood", "calculation"], "sentence-detokenized": "An updated estimate of the variance of the measurement noise can be obtained from the maximum likelihood calculation", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 22], [23, 26], [27, 35], [36, 38], [39, 42], [43, 54], [55, 60], [61, 64], [65, 67], [68, 76], [77, 81], [82, 85], [86, 93], [94, 104], [105, 116]]}
{"doc_key": "ai-dev-68", "ner": [[4, 5, "field"], [7, 8, "algorithm"], [13, 15, "field"], [16, 17, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 13, 15, "usage", "", true, false], [7, 8, 16, 17, "related-to", "", true, false], [13, 15, 4, 5, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "field", "of", "machine", "learning", ",", "a", "perceptron", "is", "an", "algorithm", "for", "supervised", "learning", "of", "binary", "classification", "."], "sentence-detokenized": "In the field of machine learning, a perceptron is an algorithm for supervised learning of binary classification.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 23], [24, 32], [32, 33], [34, 35], [36, 46], [47, 49], [50, 52], [53, 62], [63, 66], [67, 77], [78, 86], [87, 89], [90, 96], [97, 111], [111, 112]]}
{"doc_key": "ai-dev-69", "ner": [[9, 10, "field"], [12, 12, "field"], [17, 21, "conference"], [24, 28, "conference"], [31, 37, "conference"], [40, 44, "conference"], [47, 51, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[17, 21, 9, 10, "topic", "", false, false], [17, 21, 12, 12, "topic", "", false, false], [24, 28, 9, 10, "topic", "", false, false], [24, 28, 12, 12, "topic", "", false, false], [31, 37, 9, 10, "topic", "", false, false], [31, 37, 12, 12, "topic", "", false, false], [40, 44, 9, 10, "topic", "", false, false], [40, 44, 12, 12, "topic", "", false, false], [47, 51, 9, 10, "topic", "", false, false], [47, 51, 12, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["She", "has", "also", "been", "the", "area", "leader", "for", "several", "machine", "learning", "and", "vision", "conferences", ",", "including", "the", "Neural", "Information", "Processing", "Systems", "Conference", ",", "the", "International", "Conference", "on", "Learning", "Representations", ",", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "the", "International", "Conference", "on", "Computer", "Vision", "and", "the", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "She has also been the area leader for several machine learning and vision conferences, including the Neural Information Processing Systems Conference, the International Conference on Learning Representations, the Conference on Computer Vision and Pattern Recognition, the International Conference on Computer Vision and the European Conference on Computer Vision.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 17], [18, 21], [22, 26], [27, 33], [34, 37], [38, 45], [46, 53], [54, 62], [63, 66], [67, 73], [74, 85], [85, 86], [87, 96], [97, 100], [101, 107], [108, 119], [120, 130], [131, 138], [139, 149], [149, 150], [151, 154], [155, 168], [169, 179], [180, 182], [183, 191], [192, 207], [207, 208], [209, 212], [213, 223], [224, 226], [227, 235], [236, 242], [243, 246], [247, 254], [255, 266], [266, 267], [268, 271], [272, 285], [286, 296], [297, 299], [300, 308], [309, 315], [316, 319], [320, 323], [324, 332], [333, 343], [344, 346], [347, 355], [356, 362], [362, 363]]}
{"doc_key": "ai-dev-70", "ner": [[0, 2, "algorithm"], [7, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "condensation", "algorithm", "was", "also", "used", "for", "face", "recognition", "in", "the", "video", "sequence", "."], "sentence-detokenized": "The condensation algorithm was also used for face recognition in the video sequence.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 30], [31, 35], [36, 40], [41, 44], [45, 49], [50, 61], [62, 64], [65, 68], [69, 74], [75, 83], [83, 84]]}
{"doc_key": "ai-dev-71", "ner": [[0, 1, "task"], [6, 7, "organisation"], [12, 15, "conference"], [16, 20, "academicjournal"], [24, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 15, 0, 1, "topic", "", false, false], [12, 15, 6, 7, "origin", "", false, false], [16, 20, 0, 1, "topic", "", false, false], [16, 20, 6, 7, "origin", "", true, false], [24, 24, 16, 20, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Information", "dissemination", "is", "also", "one", "of", "ELRA", "'s", "missions", ",", "through", "the", "LREC", "conference", "and", "the", "Language", "Resources", "and", "Evaluation", "Journal", ",", "edited", "by", "Springer", "."], "sentence-detokenized": "Information dissemination is also one of ELRA's missions, through the LREC conference and the Language Resources and Evaluation Journal, edited by Springer.", "token2charspan": [[0, 11], [12, 25], [26, 28], [29, 33], [34, 37], [38, 40], [41, 45], [45, 47], [48, 56], [56, 57], [58, 65], [66, 69], [70, 74], [75, 85], [86, 89], [90, 93], [94, 102], [103, 112], [113, 116], [117, 127], [128, 135], [135, 136], [137, 143], [144, 146], [147, 155], [155, 156]]}
{"doc_key": "ai-dev-72", "ner": [[0, 9, "field"], [11, 12, "field"], [14, 16, "field"], [18, 19, "field"], [54, 56, "field"], [61, 61, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 9, 54, 56, "named", "", false, false], [14, 16, 0, 9, "named", "", false, false], [61, 61, 11, 12, "part-of", "", true, false], [61, 61, 14, 16, "part-of", "", true, false], [61, 61, 54, 56, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "linear", "time", "-", "invariant", "(", "LTI", ")", "system", "theory", ",", "control", "theory", "and", "digital", "signal", "processing", "or", "signal", "processing", ",", "the", "relationship", "between", "the", "input", "signal", ",", "math", "\\", "displaystyle", "x", "(", "t", ")", "/", "math", ",", "and", "the", "output", "signal", ",", "math", "\\", "displaystyle", "y", "(", "t", ")", "/", "math", ",", "of", "an", "LTI", "system", "is", "determined", "by", "a", "convolution", "operation", ":"], "sentence-detokenized": "In linear time-invariant (LTI) system theory, control theory and digital signal processing or signal processing, the relationship between the input signal, math\\ displaystyle x(t)/math, and the output signal, math\\ displaystyle y(t)/math, of an LTI system is determined by a convolution operation:", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [15, 24], [25, 26], [26, 29], [29, 30], [31, 37], [38, 44], [44, 45], [46, 53], [54, 60], [61, 64], [65, 72], [73, 79], [80, 90], [91, 93], [94, 100], [101, 111], [111, 112], [113, 116], [117, 129], [130, 137], [138, 141], [142, 147], [148, 154], [154, 155], [156, 160], [160, 161], [162, 174], [175, 176], [176, 177], [177, 178], [178, 179], [179, 180], [180, 184], [184, 185], [186, 189], [190, 193], [194, 200], [201, 207], [207, 208], [209, 213], [213, 214], [215, 227], [228, 229], [229, 230], [230, 231], [231, 232], [232, 233], [233, 237], [237, 238], [239, 241], [242, 244], [245, 248], [249, 255], [256, 258], [259, 269], [270, 272], [273, 274], [275, 286], [287, 296], [296, 297]]}
{"doc_key": "ai-dev-73", "ner": [[20, 21, "field"], [23, 24, "field"], [26, 27, "field"], [29, 30, "field"], [32, 35, "field"], [37, 38, "product"], [40, 41, "field"], [43, 43, "field"], [45, 46, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Because", "of", "its", "generality", ",", "it", "is", "a", "field", "that", "has", "been", "explored", "in", "many", "other", "disciplines", ",", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "paradigm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Because of its generality, it is a field that has been explored in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, paradigm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [25, 26], [27, 29], [30, 32], [33, 34], [35, 40], [41, 45], [46, 49], [50, 54], [55, 63], [64, 66], [67, 71], [72, 77], [78, 89], [89, 90], [91, 95], [96, 98], [99, 103], [104, 110], [110, 111], [112, 119], [120, 126], [126, 127], [128, 138], [139, 147], [147, 148], [149, 160], [161, 167], [167, 168], [169, 179], [179, 180], [180, 185], [186, 198], [198, 199], [200, 211], [212, 219], [219, 220], [221, 229], [230, 242], [242, 243], [244, 254], [255, 258], [259, 266], [267, 277], [277, 278]]}
{"doc_key": "ai-dev-74", "ner": [[0, 2, "algorithm"], [12, 13, "field"], [20, 21, "algorithm"], [24, 25, "algorithm"], [31, 32, "algorithm"], [36, 36, "algorithm"], [37, 39, "researcher"], [41, 42, "researcher"], [44, 46, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[12, 13, 0, 2, "usage", "", true, false], [20, 21, 12, 13, "part-of", "", true, false], [24, 25, 12, 13, "part-of", "", true, false], [31, 32, 12, 13, "part-of", "", true, false], [36, 36, 12, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Stochastic", "gradient", "descent", "is", "a", "popular", "algorithm", "for", "training", "a", "variety", "of", "machine", "learning", "models", ",", "including", "(", "linear", ")", "support", "vector", "machines", ",", "logistic", "regression", "(", "see", ",", "e.g.", ",", "Vowpal", "Wabbit", ")", ",", "and", "graphical", "models.Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastic gradient descent is a popular algorithm for training a variety of machine learning models, including (linear) support vector machines, logistic regression (see, e.g., Vowpal Wabbit), and graphical models.Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 30], [31, 32], [33, 40], [41, 50], [51, 54], [55, 63], [64, 65], [66, 73], [74, 76], [77, 84], [85, 93], [94, 100], [100, 101], [102, 111], [112, 113], [113, 119], [119, 120], [121, 128], [129, 135], [136, 144], [144, 145], [146, 154], [155, 165], [166, 167], [167, 170], [170, 171], [172, 176], [176, 177], [178, 184], [185, 191], [191, 192], [192, 193], [194, 197], [198, 207], [208, 220], [221, 225], [226, 232], [232, 233], [234, 238], [239, 246], [246, 247], [248, 259], [260, 262], [263, 270], [271, 272], [272, 276], [276, 277], [277, 278]]}
{"doc_key": "ai-dev-75", "ner": [[8, 8, "organisation"], [12, 13, "product"], [16, 16, "country"], [19, 22, "university"], [23, 24, "location"], [26, 29, "university"], [30, 30, "location"], [32, 34, "university"], [35, 35, "location"], [37, 39, "university"], [41, 41, "location"], [43, 45, "university"], [46, 46, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 19, 22, "role", "donates_to", false, false], [8, 8, 26, 29, "role", "donates_to", false, false], [8, 8, 32, 34, "role", "donates_to", false, false], [8, 8, 37, 39, "role", "donates_to", false, false], [8, 8, 43, 45, "role", "donates_to", false, false], [12, 13, 8, 8, "origin", "donates", true, false], [19, 22, 23, 24, "physical", "", false, false], [23, 24, 16, 16, "physical", "", false, false], [26, 29, 30, 30, "physical", "", false, false], [30, 30, 16, 16, "physical", "", false, false], [32, 34, 35, 35, "physical", "", false, false], [35, 35, 16, 16, "physical", "", false, false], [37, 39, 41, 41, "physical", "", false, false], [41, 41, 16, 16, "physical", "", false, false], [43, 45, 46, 46, "physical", "", false, false], [46, 46, 16, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["In", "August", "2011", ",", "it", "was", "announced", "that", "Hitachi", "would", "donate", "an", "electron", "microscope", "to", "five", "Indonesian", "universities", "(", "University", "of", "North", "Sumatra", "in", "Medan", ",", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Padjadjaran", "University", "in", "Bandung", ",", "Jenderal", "Soedirman", "University", "in", "Purwokerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "sentence-detokenized": "In August 2011, it was announced that Hitachi would donate an electron microscope to five Indonesian universities (University of North Sumatra in Medan, Indonesian Christian University in Jakarta, Padjadjaran University in Bandung, Jenderal Soedirman University in Purwokerto and Muhammadiyah University in Malang).", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 32], [33, 37], [38, 45], [46, 51], [52, 58], [59, 61], [62, 70], [71, 81], [82, 84], [85, 89], [90, 100], [101, 113], [114, 115], [115, 125], [126, 128], [129, 134], [135, 142], [143, 145], [146, 151], [151, 152], [153, 163], [164, 173], [174, 184], [185, 187], [188, 195], [195, 196], [197, 208], [209, 219], [220, 222], [223, 230], [230, 231], [232, 240], [241, 250], [251, 261], [262, 264], [265, 275], [276, 279], [280, 292], [293, 303], [304, 306], [307, 313], [313, 314], [314, 315]]}
{"doc_key": "ai-dev-76", "ner": [[0, 0, "field"], [3, 4, "field"], [8, 9, "algorithm"], [11, 12, "algorithm"], [22, 23, "field"], [28, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 4, "part-of", "", false, false], [0, 0, 22, 23, "related-to", "", true, false], [0, 0, 28, 29, "related-to", "", true, false], [8, 9, 0, 0, "type-of", "", false, false], [11, 12, 0, 0, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Optimisation", "methods", "for", "exploratory", "operations", ",", "such", "as", "linear", "programming", "or", "dynamic", "programming", ",", "are", "often", "impractical", "for", "solving", "large", "-", "scale", "software", "engineering", "problems", "due", "to", "their", "computational", "complexity", "."], "sentence-detokenized": "Optimisation methods for exploratory operations, such as linear programming or dynamic programming, are often impractical for solving large-scale software engineering problems due to their computational complexity.", "token2charspan": [[0, 12], [13, 20], [21, 24], [25, 36], [37, 47], [47, 48], [49, 53], [54, 56], [57, 63], [64, 75], [76, 78], [79, 86], [87, 98], [98, 99], [100, 103], [104, 109], [110, 121], [122, 125], [126, 133], [134, 139], [139, 140], [140, 145], [146, 154], [155, 166], [167, 175], [176, 179], [180, 182], [183, 188], [189, 202], [203, 213], [213, 214]]}
{"doc_key": "ai-dev-77", "ner": [[0, 0, "metrics"], [6, 6, "metrics"], [8, 12, "metrics"], [15, 16, "metrics"], [19, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 6, "compare", "", false, false], [0, 0, 8, 12, "compare", "", false, false], [15, 16, 8, 12, "part-of", "", false, false], [19, 22, 8, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sensitivity", "is", "not", "the", "same", "as", "accuracy", "or", "positive", "predictive", "value", "(", "the", "ratio", "of", "true", "positives", "to", "all", "true", "and", "false", "positives", ")", ",", "which", "is", "as", "much", "a", "statement", "about", "the", "proportion", "of", "true", "positives", "in", "the", "population", "as", "it", "is", "about", "the", "test", "."], "sentence-detokenized": "Sensitivity is not the same as accuracy or positive predictive value (the ratio of true positives to all true and false positives), which is as much a statement about the proportion of true positives in the population as it is about the test.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 22], [23, 27], [28, 30], [31, 39], [40, 42], [43, 51], [52, 62], [63, 68], [69, 70], [70, 73], [74, 79], [80, 82], [83, 87], [88, 97], [98, 100], [101, 104], [105, 109], [110, 113], [114, 119], [120, 129], [129, 130], [130, 131], [132, 137], [138, 140], [141, 143], [144, 148], [149, 150], [151, 160], [161, 166], [167, 170], [171, 181], [182, 184], [185, 189], [190, 199], [200, 202], [203, 206], [207, 217], [218, 220], [221, 223], [224, 226], [227, 232], [233, 236], [237, 241], [241, 242]]}
{"doc_key": "ai-dev-78", "ner": [[0, 2, "person"], [11, 11, "person"], [27, 27, "person"], [35, 36, "person"], [40, 41, "person"], [46, 47, "person"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6], "relations": [[0, 2, 40, 41, "named", "same", false, false], [35, 36, 46, 47, "role", "convinces", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["The", "Hampton", "Fancher", "scenario", "!", "--", "originally", "unnamed", "Android", "--", "see", "Sammon", ",", "pp.", "32", "and", "38", ",", "for", "an", "explanation", "--", "was", "chosen", "in", "1977", ",", "Sammon", ",", "pp.", "23", "-", "30", ".", "Producer", "Michael", "Deeley", "became", "interested", "in", "Fancher", "'s", "draft", "and", "persuaded", "director", "Ridley", "Scott", "to", "screen", "it", "."], "sentence-detokenized": "The Hampton Fancher scenario! -- originally unnamed Android -- see Sammon, pp. 32 and 38, for an explanation -- was chosen in 1977, Sammon, pp. 23-30. Producer Michael Deeley became interested in Fancher's draft and persuaded director Ridley Scott to screen it.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 28], [28, 29], [30, 32], [33, 43], [44, 51], [52, 59], [60, 62], [63, 66], [67, 73], [73, 74], [75, 78], [79, 81], [82, 85], [86, 88], [88, 89], [90, 93], [94, 96], [97, 108], [109, 111], [112, 115], [116, 122], [123, 125], [126, 130], [130, 131], [132, 138], [138, 139], [140, 143], [144, 146], [146, 147], [147, 149], [149, 150], [151, 159], [160, 167], [168, 174], [175, 181], [182, 192], [193, 195], [196, 203], [203, 205], [206, 211], [212, 215], [216, 225], [226, 234], [235, 241], [242, 247], [248, 250], [251, 257], [258, 260], [260, 261]]}
{"doc_key": "ai-dev-79", "ner": [[0, 1, "field"], [3, 4, "task"], [6, 8, "task"], [11, 14, "misc"], [16, 17, "field"], [19, 21, "task"], [23, 24, "task"], [26, 27, "field"], [30, 33, "task"], [35, 35, "task"], [37, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [6, 8, 0, 1, "part-of", "", false, false], [11, 14, 0, 1, "part-of", "", false, false], [16, 17, 0, 1, "part-of", "", false, false], [19, 21, 0, 1, "part-of", "", false, false], [23, 24, 0, 1, "part-of", "", false, false], [26, 27, 0, 1, "part-of", "", false, false], [30, 33, 0, 1, "part-of", "", false, false], [35, 35, 0, 1, "part-of", "", false, false], [37, 38, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Text", "analysis", "includes", "information", "retrieval", ",", "lexical", "analysis", "to", "investigate", "the", "frequency", "distribution", "of", "words", ",", "pattern", "recognition", ",", "tagging", "/", "annotation", ",", "information", "extraction", ",", "data", "mining", "techniques", "including", "linkage", "and", "association", "analysis", ",", "visualisation", "and", "predictive", "analysis", "."], "sentence-detokenized": "Text analysis includes information retrieval, lexical analysis to investigate the frequency distribution of words, pattern recognition, tagging/annotation, information extraction, data mining techniques including linkage and association analysis, visualisation and predictive analysis.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 34], [35, 44], [44, 45], [46, 53], [54, 62], [63, 65], [66, 77], [78, 81], [82, 91], [92, 104], [105, 107], [108, 113], [113, 114], [115, 122], [123, 134], [134, 135], [136, 143], [143, 144], [144, 154], [154, 155], [156, 167], [168, 178], [178, 179], [180, 184], [185, 191], [192, 202], [203, 212], [213, 220], [221, 224], [225, 236], [237, 245], [245, 246], [247, 260], [261, 264], [265, 275], [276, 284], [284, 285]]}
{"doc_key": "ai-dev-80", "ner": [[3, 3, "product"], [10, 11, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Several", "indicators", "use", "WordNet", ",", "a", "manual", "lexical", "database", "of", "English", "words", "."], "sentence-detokenized": "Several indicators use WordNet, a manual lexical database of English words.", "token2charspan": [[0, 7], [8, 18], [19, 22], [23, 30], [30, 31], [32, 33], [34, 40], [41, 48], [49, 57], [58, 60], [61, 68], [69, 74], [74, 75]]}
{"doc_key": "ai-dev-81", "ner": [[3, 4, "field"], [6, 7, "task"], [9, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "system", "uses", "computational", "linguistics", ",", "information", "retrieval", "and", "knowledge", "representation", "techniques", "to", "find", "answers", "."], "sentence-detokenized": "The system uses computational linguistics, information retrieval and knowledge representation techniques to find answers.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 29], [30, 41], [41, 42], [43, 54], [55, 64], [65, 68], [69, 78], [79, 93], [94, 104], [105, 107], [108, 112], [113, 120], [120, 121]]}
{"doc_key": "ai-dev-82", "ner": [[0, 2, "metrics"], [8, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 8, 8, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "uncertainty", "factor", "has", "an", "advantage", "over", "simple", "accuracy", "as", "a", "performance", "indicator", "because", "it", "is", "not", "affected", "by", "the", "relative", "size", "of", "different", "classes", "."], "sentence-detokenized": "The uncertainty factor has an advantage over simple accuracy as a performance indicator because it is not affected by the relative size of different classes.", "token2charspan": [[0, 3], [4, 15], [16, 22], [23, 26], [27, 29], [30, 39], [40, 44], [45, 51], [52, 60], [61, 63], [64, 65], [66, 77], [78, 87], [88, 95], [96, 98], [99, 101], [102, 105], [106, 114], [115, 117], [118, 121], [122, 130], [131, 135], [136, 138], [139, 148], [149, 156], [156, 157]]}
{"doc_key": "ai-dev-83", "ner": [[10, 11, "algorithm"], [13, 14, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Researchers", "have", "tested", "a", "wide", "range", "of", "techniques", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "hidden", "Markov", "models", ",", "etc", "."], "sentence-detokenized": "Researchers have tested a wide range of techniques such as optical flow, Kalman filtering, hidden Markov models, etc.", "token2charspan": [[0, 11], [12, 16], [17, 23], [24, 25], [26, 30], [31, 36], [37, 39], [40, 50], [51, 55], [56, 58], [59, 66], [67, 71], [71, 72], [73, 79], [80, 89], [89, 90], [91, 97], [98, 104], [105, 111], [111, 112], [113, 116], [116, 117]]}
{"doc_key": "ai-dev-84", "ner": [[14, 17, "conference"], [35, 38, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "has", "served", "as", "President", ",", "Vice", "President", "and", "Secretary", "-", "Treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "and", "as", "a", "member", "of", "the", "Board", "of", "Directors", "and", "Secretary", "of", "the", "Board", "of", "the", "Association", "for", "Computational", "Research", "."], "sentence-detokenized": "She has served as President, Vice President and Secretary-Treasurer of the Association for Computational Linguistics, and as a member of the Board of Directors and Secretary of the Board of the Association for Computational Research.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 17], [18, 27], [27, 28], [29, 33], [34, 43], [44, 47], [48, 57], [57, 58], [58, 67], [68, 70], [71, 74], [75, 86], [87, 90], [91, 104], [105, 116], [116, 117], [118, 121], [122, 124], [125, 126], [127, 133], [134, 136], [137, 140], [141, 146], [147, 149], [150, 159], [160, 163], [164, 173], [174, 176], [177, 180], [181, 186], [187, 189], [190, 193], [194, 205], [206, 209], [210, 223], [224, 232], [232, 233]]}
{"doc_key": "ai-dev-85", "ner": [[6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 10, 10, "compare", "", false, false], [6, 6, 12, 13, "related-to", "supports", false, false], [8, 8, 10, 10, "compare", "", false, false], [8, 8, 12, 13, "related-to", "supports", false, false], [10, 10, 12, 13, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Like", "other", "similar", "languages", "such", "as", "APL", "and", "MATLAB", ",", "R", "supports", "matrix", "arithmetic", "."], "sentence-detokenized": "Like other similar languages such as APL and MATLAB, R supports matrix arithmetic.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 28], [29, 33], [34, 36], [37, 40], [41, 44], [45, 51], [51, 52], [53, 54], [55, 63], [64, 70], [71, 81], [81, 82]]}
{"doc_key": "ai-dev-86", "ner": [[8, 9, "misc"], [5, 7, "organisation"], [14, 15, "researcher"], [18, 20, "university"], [24, 29, "misc"], [31, 31, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 5, 7, "physical", "", false, false], [8, 9, 24, 29, "temporal", "", false, false], [14, 15, 8, 9, "role", "arranges", false, false], [14, 15, 18, 20, "role", "works_for", false, false], [31, 31, 8, 9, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["7", "June", "2014", "In", "the", "Royal", "Society", "'s", "Turing", "Test", "competition", ",", "organised", "by", "Kevin", "Warwick", "of", "the", "University", "of", "Reading", "to", "commemorate", "the", "60th", "anniversary", "of", "Turing", "'s", "death", ",", "Goostman", "won", "when", "33", "%", "of", "the", "judges", "were", "convinced", "the", "robot", "was", "human", "."], "sentence-detokenized": "7 June 2014 In the Royal Society's Turing Test competition, organised by Kevin Warwick of the University of Reading to commemorate the 60th anniversary of Turing's death, Goostman won when 33% of the judges were convinced the robot was human.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 14], [15, 18], [19, 24], [25, 32], [32, 34], [35, 41], [42, 46], [47, 58], [58, 59], [60, 69], [70, 72], [73, 78], [79, 86], [87, 89], [90, 93], [94, 104], [105, 107], [108, 115], [116, 118], [119, 130], [131, 134], [135, 139], [140, 151], [152, 154], [155, 161], [161, 163], [164, 169], [169, 170], [171, 179], [180, 183], [184, 188], [189, 191], [191, 192], [193, 195], [196, 199], [200, 206], [207, 211], [212, 221], [222, 225], [226, 231], [232, 235], [236, 241], [241, 242]]}
{"doc_key": "ai-dev-87", "ner": [[0, 2, "product"], [5, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "collaborative", "robot", ",", "or", "cobot", ",", "is", "a", "robot", "that", "can", "safely", "and", "efficiently", "interact", "with", "humans", "to", "perform", "simple", "industrial", "tasks", "."], "sentence-detokenized": "A collaborative robot, or cobot, is a robot that can safely and efficiently interact with humans to perform simple industrial tasks.", "token2charspan": [[0, 1], [2, 15], [16, 21], [21, 22], [23, 25], [26, 31], [31, 32], [33, 35], [36, 37], [38, 43], [44, 48], [49, 52], [53, 59], [60, 63], [64, 75], [76, 84], [85, 89], [90, 96], [97, 99], [100, 107], [108, 114], [115, 125], [126, 131], [131, 132]]}
{"doc_key": "ai-dev-88", "ner": [[11, 12, "field"], [16, 17, "task"], [19, 20, "task"], [22, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[16, 17, 11, 12, "part-of", "task_part_of_field", false, false], [19, 20, 11, 12, "part-of", "task_part_of_field", false, false], [22, 23, 11, 12, "part-of", "task_part_of_field", false, false], [25, 26, 11, 12, "part-of", "task_part_of_field", false, false], [28, 29, 11, 12, "part-of", "task_part_of_field", false, false], [31, 33, 11, 12, "part-of", "task_part_of_field", false, false], [35, 36, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "general", "framework", "has", "been", "applied", "to", "a", "wide", "range", "of", "computer", "vision", "problems", ",", "including", "feature", "detection", ",", "feature", "classification", ",", "image", "segmentation", ",", "image", "matching", ",", "motion", "estimation", ",", "shape", "feature", "counting", "and", "object", "recognition", "."], "sentence-detokenized": "This general framework has been applied to a wide range of computer vision problems, including feature detection, feature classification, image segmentation, image matching, motion estimation, shape feature counting and object recognition.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 26], [27, 31], [32, 39], [40, 42], [43, 44], [45, 49], [50, 55], [56, 58], [59, 67], [68, 74], [75, 83], [83, 84], [85, 94], [95, 102], [103, 112], [112, 113], [114, 121], [122, 136], [136, 137], [138, 143], [144, 156], [156, 157], [158, 163], [164, 172], [172, 173], [174, 180], [181, 191], [191, 192], [193, 198], [199, 206], [207, 215], [216, 219], [220, 226], [227, 238], [238, 239]]}
{"doc_key": "ai-dev-89", "ner": [[11, 15, "task"], [16, 18, "algorithm"], [6, 7, "algorithm"], [31, 32, "algorithm"], [36, 37, "algorithm"], [42, 43, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 15, 16, 18, "part-of", "", false, false], [11, 15, 6, 7, "usage", "", false, false], [16, 18, 31, 32, "named", "same", false, false], [31, 32, 36, 37, "related-to", "", false, false], [31, 32, 42, 43, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "many", "practical", "applications", ",", "the", "maximum", "likelihood", "approach", "is", "used", "to", "estimate", "the", "parameters", "of", "naive", "Bayesian", "models", ";", "in", "other", "words", ",", "it", "is", "possible", "to", "work", "with", "a", "naive", "Bayesian", "model", "without", "assuming", "Bayesian", "likelihood", "and", "without", "using", "any", "Bayesian", "methods", "."], "sentence-detokenized": "In many practical applications, the maximum likelihood approach is used to estimate the parameters of naive Bayesian models; in other words, it is possible to work with a naive Bayesian model without assuming Bayesian likelihood and without using any Bayesian methods.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 30], [30, 31], [32, 35], [36, 43], [44, 54], [55, 63], [64, 66], [67, 71], [72, 74], [75, 83], [84, 87], [88, 98], [99, 101], [102, 107], [108, 116], [117, 123], [123, 124], [125, 127], [128, 133], [134, 139], [139, 140], [141, 143], [144, 146], [147, 155], [156, 158], [159, 163], [164, 168], [169, 170], [171, 176], [177, 185], [186, 191], [192, 199], [200, 208], [209, 217], [218, 228], [229, 232], [233, 240], [241, 246], [247, 250], [251, 259], [260, 267], [267, 268]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [12, 15, "university"], [17, 19, "researcher"], [21, 22, "misc"], [26, 26, "university"], [28, 28, "university"], [32, 33, "misc"], [38, 40, "university"], [46, 49, "misc"], [51, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 4, 12, 15, "physical", "", false, false], [2, 4, 12, 15, "role", "", false, false], [2, 4, 17, 19, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [17, 19, 26, 26, "physical", "", false, false], [17, 19, 26, 26, "role", "", false, false], [17, 19, 28, 28, "physical", "", false, false], [17, 19, 28, 28, "role", "", false, false], [17, 19, 38, 40, "physical", "", false, false], [17, 19, 38, 40, "role", "", false, false], [21, 22, 17, 19, "named", "", false, false], [32, 33, 17, 19, "origin", "", false, false], [46, 49, 17, 19, "artifact", "", false, false], [46, 49, 51, 54, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Brothers", "-", "Victor", "Gershevich", "Katz", ",", "American", "mathematician", ",", "professor", "at", "the", "Massachusetts", "Institute", "of", "Technology", ";", "Mikhail", "Gershevich", "Katz", ",", "Israeli", "mathematician", ",", "graduate", "of", "Harvard", "and", "Columbia", "Universities", "(", "Ph.D.", ",", "1984", ")", ",", "professor", "at", "Bar-", "Ilan", "University", ",", "author", "of", "the", "monograph", "Systolic", "Geometry", "and", "Topology", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "Vol", "."], "sentence-detokenized": "Brothers - Victor Gershevich Katz, American mathematician, professor at the Massachusetts Institute of Technology; Mikhail Gershevich Katz, Israeli mathematician, graduate of Harvard and Columbia Universities (Ph.D., 1984), professor at Bar-Ilan University, author of the monograph Systolic Geometry and Topology (Mathematical Surveys and Monographs, Vol.", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 28], [29, 33], [33, 34], [35, 43], [44, 57], [57, 58], [59, 68], [69, 71], [72, 75], [76, 89], [90, 99], [100, 102], [103, 113], [113, 114], [115, 122], [123, 133], [134, 138], [138, 139], [140, 147], [148, 161], [161, 162], [163, 171], [172, 174], [175, 182], [183, 186], [187, 195], [196, 208], [209, 210], [210, 215], [215, 216], [217, 221], [221, 222], [222, 223], [224, 233], [234, 236], [237, 241], [241, 245], [246, 256], [256, 257], [258, 264], [265, 267], [268, 271], [272, 281], [282, 290], [291, 299], [300, 303], [304, 312], [313, 314], [314, 326], [327, 334], [335, 338], [339, 349], [349, 350], [351, 354], [354, 355]]}
{"doc_key": "ai-dev-91", "ner": [[3, 4, "person"], [10, 11, "conference"], [16, 20, "organisation"], [21, 28, "location"], [33, 33, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 10, 11, "physical", "", false, false], [3, 4, 10, 11, "role", "", false, false], [3, 4, 16, 20, "role", "", false, false], [16, 20, 21, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2000", ",", "Manuel", "Toharia", ",", "a", "speaker", "at", "previous", "Campus", "Parties", "and", "Director", "of", "the", "Pr\u00edncipe", "Felipe", "'s", "Science", "Museum", "in", "Valencia", "'s", "City", "of", "Art", "and", "Science", ",", "proposed", "to", "expand", "Ragageles", "and", "make", "it", "an", "international", "event", "by", "moving", "it", "to", "the", "famous", "museum", "."], "sentence-detokenized": "In 2000, Manuel Toharia, a speaker at previous Campus Parties and Director of the Pr\u00edncipe Felipe's Science Museum in Valencia's City of Art and Science, proposed to expand Ragageles and make it an international event by moving it to the famous museum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 23], [23, 24], [25, 26], [27, 34], [35, 37], [38, 46], [47, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 81], [82, 90], [91, 97], [97, 99], [100, 107], [108, 114], [115, 117], [118, 126], [126, 128], [129, 133], [134, 136], [137, 140], [141, 144], [145, 152], [152, 153], [154, 162], [163, 165], [166, 172], [173, 182], [183, 186], [187, 191], [192, 194], [195, 197], [198, 211], [212, 217], [218, 220], [221, 227], [228, 230], [231, 233], [234, 237], [238, 244], [245, 251], [251, 252]]}
{"doc_key": "ai-dev-92", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Within", "20", "minutes", ",", "the", "facial", "recognition", "system", "identifies", "personal", "information", ",", "including", "name", ",", "ID", "number", "and", "address", ",", "which", "is", "displayed", "on", "an", "advertising", "screen", "in", "the", "street", "."], "sentence-detokenized": "Within 20 minutes, the facial recognition system identifies personal information, including name, ID number and address, which is displayed on an advertising screen in the street.", "token2charspan": [[0, 6], [7, 9], [10, 17], [17, 18], [19, 22], [23, 29], [30, 41], [42, 48], [49, 59], [60, 68], [69, 80], [80, 81], [82, 91], [92, 96], [96, 97], [98, 100], [101, 107], [108, 111], [112, 119], [119, 120], [121, 126], [127, 129], [130, 139], [140, 142], [143, 145], [146, 157], [158, 164], [165, 167], [168, 171], [172, 178], [178, 179]]}
{"doc_key": "ai-dev-93", "ner": [[0, 1, "field"], [3, 4, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Unsupervised", "learning", "and", "semi-supervised", "learning", "algorithms", "have", "recently", "gained", "increasing", "attention", "in", "research", "."], "sentence-detokenized": "Unsupervised learning and semi-supervised learning algorithms have recently gained increasing attention in research.", "token2charspan": [[0, 12], [13, 21], [22, 25], [26, 41], [42, 50], [51, 61], [62, 66], [67, 75], [76, 82], [83, 93], [94, 103], [104, 106], [107, 115], [115, 116]]}
{"doc_key": "ai-dev-94", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Calculating", "this", "example", "using", "Python", "code", ":"], "sentence-detokenized": "Calculating this example using Python code:", "token2charspan": [[0, 11], [12, 16], [17, 24], [25, 30], [31, 37], [38, 42], [42, 43]]}
{"doc_key": "ai-dev-95", "ner": [[7, 8, "task"], [15, 16, "field"], [20, 23, "algorithm"], [25, 25, "algorithm"], [35, 39, "algorithm"], [28, 29, "researcher"], [31, 32, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[20, 23, 15, 16, "part-of", "", false, false], [20, 23, 35, 39, "type-of", "", false, false], [20, 23, 28, 29, "origin", "", false, false], [20, 23, 31, 32, "origin", "", false, false], [25, 25, 20, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Today", ",", "however", ",", "many", "aspects", "of", "speech", "recognition", "have", "been", "taken", "over", "by", "a", "deep", "learning", "approach", "called", "long", "short", "-", "term", "memory", "(", "LSTM", ")", "-", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "published", "a", "recurrent", "neural", "network", "in", "1997", "."], "sentence-detokenized": "Today, however, many aspects of speech recognition have been taken over by a deep learning approach called long short-term memory (LSTM) - Sepp Hochreiter and J\u00fcrgen Schmidhuber published a recurrent neural network in 1997.", "token2charspan": [[0, 5], [5, 6], [7, 14], [14, 15], [16, 20], [21, 28], [29, 31], [32, 38], [39, 50], [51, 55], [56, 60], [61, 66], [67, 71], [72, 74], [75, 76], [77, 81], [82, 90], [91, 99], [100, 106], [107, 111], [112, 117], [117, 118], [118, 122], [123, 129], [130, 131], [131, 135], [135, 136], [137, 138], [139, 143], [144, 154], [155, 158], [159, 165], [166, 177], [178, 187], [188, 189], [190, 199], [200, 206], [207, 214], [215, 217], [218, 222], [222, 223]]}
{"doc_key": "ai-dev-96", "ner": [[9, 9, "algorithm"], [11, 13, "algorithm"], [20, 20, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 11, 13, "compare", "", false, false], [9, 9, 25, 25, "named", "same", false, false], [20, 20, 25, 25, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Based", "on", "preliminary", "experimental", "results", "with", "noisy", "datasets", ",", "BrownBoost", "outperformed", "AdaBoost", "in", "terms", "of", "generalisation", "error", ";", "however", ",", "LogitBoost", "performed", "as", "well", "as", "BrownBoost", "."], "sentence-detokenized": "Based on preliminary experimental results with noisy datasets, BrownBoost outperformed AdaBoost in terms of generalisation error; however, LogitBoost performed as well as BrownBoost.", "token2charspan": [[0, 5], [6, 8], [9, 20], [21, 33], [34, 41], [42, 46], [47, 52], [53, 61], [61, 62], [63, 73], [74, 86], [87, 95], [96, 98], [99, 104], [105, 107], [108, 122], [123, 128], [128, 129], [130, 137], [137, 138], [139, 149], [150, 159], [160, 162], [163, 167], [168, 170], [171, 181], [181, 182]]}
{"doc_key": "ai-dev-97", "ner": [[0, 1, "algorithm"], [8, 10, "researcher"], [5, 6, "country"], [12, 14, "researcher"], [18, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 8, 10, "part-of", "", false, false], [8, 10, 5, 6, "physical", "", false, false], [18, 20, 12, 14, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evolutionary", "programming", "was", "introduced", "in", "the", "USA", "by", "Lawrence", "J.", "Fogel", "and", "John", "Henry", "Holland", "called", "his", "method", "the", "genetic", "algorithm", "."], "sentence-detokenized": "Evolutionary programming was introduced in the USA by Lawrence J. Fogel and John Henry Holland called his method the genetic algorithm.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 39], [40, 42], [43, 46], [47, 50], [51, 53], [54, 62], [63, 65], [66, 71], [72, 75], [76, 80], [81, 86], [87, 94], [95, 101], [102, 105], [106, 112], [113, 116], [117, 124], [125, 134], [134, 135]]}
{"doc_key": "ai-dev-98", "ner": [[3, 3, "researcher"], [5, 5, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"], [1, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 11, 12, "role", "", false, false], [3, 3, 14, 15, "role", "", false, false], [3, 3, 17, 18, "role", "", false, false], [3, 3, 1, 21, "role", "", false, false], [5, 5, 11, 12, "role", "", false, false], [5, 5, 14, 15, "role", "", false, false], [5, 5, 17, 18, "role", "", false, false], [5, 5, 1, 21, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Calculations", "made", "by", "Doug", ",", "Alan", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", "and", "John", "McCarthy", ")", "have", "estimated", "that", "the", "effort", "will", "take", "between", "1,000", "and", "3,000", "man", "-years", ",", "well", "beyond", "the", "standard", "academic", "project", "model", "."], "sentence-detokenized": "Calculations made by Doug, Alan and their colleagues (including Marvin Minsky, Allen Newell, Edward Feigenbaum and John McCarthy) have estimated that the effort will take between 1,000 and 3,000 man-years, well beyond the standard academic project model.", "token2charspan": [[0, 12], [13, 17], [18, 20], [21, 25], [25, 26], [27, 31], [32, 35], [36, 41], [42, 52], [53, 54], [54, 63], [64, 70], [71, 77], [77, 78], [79, 84], [85, 91], [91, 92], [93, 99], [100, 110], [111, 114], [115, 119], [120, 128], [128, 129], [130, 134], [135, 144], [145, 149], [150, 153], [154, 160], [161, 165], [166, 170], [171, 178], [179, 184], [185, 188], [189, 194], [195, 198], [198, 204], [204, 205], [206, 210], [211, 217], [218, 221], [222, 230], [231, 239], [240, 247], [248, 253], [253, 254]]}
{"doc_key": "ai-dev-99", "ner": [[7, 9, "metrics"], [13, 14, "metrics"], [16, 18, "metrics"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 9, 13, 14, "part-of", "implemented_in", false, false], [16, 18, 21, 21, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "commonly", "used", "criteria", "are", "the", "mean", "square", "error", "criterion", "implemented", "in", "MSECriterion", "and", "the", "cross", "-entropy", "criterion", "implemented", "in", "NLLCriterion", "."], "sentence-detokenized": "The most commonly used criteria are the mean square error criterion implemented in MSECriterion and the cross-entropy criterion implemented in NLLCriterion.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 31], [32, 35], [36, 39], [40, 44], [45, 51], [52, 57], [58, 67], [68, 79], [80, 82], [83, 95], [96, 99], [100, 103], [104, 109], [109, 117], [118, 127], [128, 139], [140, 142], [143, 155], [155, 156]]}
{"doc_key": "ai-dev-100", "ner": [[0, 0, "researcher"], [7, 7, "organisation"], [10, 23, "misc"], [28, 33, "conference"], [41, 42, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 7, 7, "role", "", false, false], [0, 0, 28, 33, "role", "", false, false], [0, 0, 41, 42, "role", "", false, false], [10, 23, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zurada", "has", "been", "a", "long", "-", "time", "IEEE", "volunteer", ":", "he", "was", "IEEE", "Vice", "President", "for", "Technical", "Activities", "(", "TAB", "Chair", ")", "in", "2014", ",", "President", "of", "the", "IEEE", "Society", "for", "Computational", "Intelligence", "in", "2004-", "2005", ",", "and", "a", "member", "of", "ADCOM", "in", "2009-2014", ",", "2016-2018", ",", "and", "the", "years", "before", "."], "sentence-detokenized": "Zurada has been a long-time IEEE volunteer: he was IEEE Vice President for Technical Activities (TAB Chair) in 2014, President of the IEEE Society for Computational Intelligence in 2004-2005, and a member of ADCOM in 2009-2014, 2016-2018, and the years before.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 17], [18, 22], [22, 23], [23, 27], [28, 32], [33, 42], [42, 43], [44, 46], [47, 50], [51, 55], [56, 60], [61, 70], [71, 74], [75, 84], [85, 95], [96, 97], [97, 100], [101, 106], [106, 107], [108, 110], [111, 115], [115, 116], [117, 126], [127, 129], [130, 133], [134, 138], [139, 146], [147, 150], [151, 164], [165, 177], [178, 180], [181, 186], [186, 190], [190, 191], [192, 195], [196, 197], [198, 204], [205, 207], [208, 213], [214, 216], [217, 226], [226, 227], [228, 237], [237, 238], [239, 242], [243, 246], [247, 252], [253, 259], [259, 260]]}
{"doc_key": "ai-dev-101", "ner": [[3, 4, "field"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 4, "part-of", "", false, false], [11, 12, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "general", ",", "computational", "linguistics", "involves", "linguists", ",", "computer", "scientists", ",", "artificial", "intelligence", "specialists", ",", "mathematicians", ",", "logicians", ",", "philosophers", ",", "cognitive", "scientists", ",", "cognitive", "psychologists", ",", "psycholinguists", ",", "anthropologists", ",", "neuroscientists", ",", "etc", "."], "sentence-detokenized": "In general, computational linguistics involves linguists, computer scientists, artificial intelligence specialists, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists, neuroscientists, etc.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 25], [26, 37], [38, 46], [47, 56], [56, 57], [58, 66], [67, 77], [77, 78], [79, 89], [90, 102], [103, 114], [114, 115], [116, 130], [130, 131], [132, 141], [141, 142], [143, 155], [155, 156], [157, 166], [167, 177], [177, 178], [179, 188], [189, 202], [202, 203], [204, 219], [219, 220], [221, 236], [236, 237], [238, 253], [253, 254], [255, 258], [258, 259]]}
{"doc_key": "ai-dev-102", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Methods", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "-", "term", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "inter", "-", "frame", "correlations", "."], "sentence-detokenized": "Methods such as dynamic Markov networks, convolutional neural networks and long-term short-term memory are often used to exploit inter-frame correlations.", "token2charspan": [[0, 7], [8, 12], [13, 15], [16, 23], [24, 30], [31, 39], [39, 40], [41, 54], [55, 61], [62, 70], [71, 74], [75, 79], [79, 80], [80, 84], [85, 90], [90, 91], [91, 95], [96, 102], [103, 106], [107, 112], [113, 117], [118, 120], [121, 128], [129, 134], [134, 135], [135, 140], [141, 153], [153, 154]]}
{"doc_key": "ai-dev-103", "ner": [[0, 1, "product"], [5, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 5, 6, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["\"", "Unimate", "was", "the", "first", "industrial", "robot", ","], "sentence-detokenized": "\"Unimate was the first industrial robot,", "token2charspan": [[0, 1], [1, 8], [9, 12], [13, 16], [17, 22], [23, 33], [34, 39], [39, 40]]}
{"doc_key": "ai-dev-104", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 11, 13, "win-defeat", "", false, false], [5, 6, 11, 13, "win-defeat", "", false, false], [8, 8, 11, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Together", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "won", "the", "2018", "Turing", "Award", "."], "sentence-detokenized": "Together with Geoffrey Hinton and Yann LeCun, Bengio won the 2018 Turing Award.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 29], [30, 33], [34, 38], [39, 44], [44, 45], [46, 52], [53, 56], [57, 60], [61, 65], [66, 72], [73, 78], [78, 79]]}
{"doc_key": "ai-dev-105", "ner": [[6, 8, "country"], [20, 23, "misc"], [26, 26, "country"], [28, 31, "organisation"], [35, 36, "person"], [39, 41, "person"], [47, 49, "misc"], [51, 53, "country"], [58, 59, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[20, 23, 6, 8, "physical", "filmed_in", false, false], [35, 36, 28, 31, "role", "host", false, false], [39, 41, 28, 31, "role", "reporter", false, false], [47, 49, 6, 8, "physical", "filmed_in", false, false], [47, 49, 51, 53, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Additional", "series", "were", "filmed", "on", "location", "in", "the", "UK", ",", "targeting", "specific", "sectors", "of", "the", "global", "market", ",", "including", "two", "Robot", "Wars", "Extreme", "Warriors", "series", "with", "US", "competitors", "for", "the", "TNN", "network", "(", "hosted", "by", "Mick", "Foley", ",", "with", "Rebecca", "Grant", "as", "reporter", ")", ",", "two", "Robot", "Wars", "series", "for", "distribution", "in", "the", "Netherlands", ",", "and", "one", "series", "for", "Germany", "."], "sentence-detokenized": "Additional series were filmed on location in the UK, targeting specific sectors of the global market, including two Robot Wars Extreme Warriors series with US competitors for the TNN network (hosted by Mick Foley, with Rebecca Grant as reporter), two Robot Wars series for distribution in the Netherlands, and one series for Germany.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 29], [30, 32], [33, 41], [42, 44], [45, 48], [49, 51], [51, 52], [53, 62], [63, 71], [72, 79], [80, 82], [83, 86], [87, 93], [94, 100], [100, 101], [102, 111], [112, 115], [116, 121], [122, 126], [127, 134], [135, 143], [144, 150], [151, 155], [156, 158], [159, 170], [171, 174], [175, 178], [179, 182], [183, 190], [191, 192], [192, 198], [199, 201], [202, 206], [207, 212], [212, 213], [214, 218], [219, 226], [227, 232], [233, 235], [236, 244], [244, 245], [245, 246], [247, 250], [251, 256], [257, 261], [262, 268], [269, 272], [273, 285], [286, 288], [289, 292], [293, 304], [304, 305], [306, 309], [310, 313], [314, 320], [321, 324], [325, 332], [332, 333]]}
{"doc_key": "ai-dev-106", "ner": [[3, 3, "researcher"], [12, 14, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 12, 14, "role", "", false, false], [26, 27, 12, 14, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Since", "1986", ",", "Miller", "has", "led", "for", "many", "years", "the", "development", "of", "WordNet", ",", "a", "large", "computer", "-", "readable", "electronic", "manual", "used", "in", "applications", "such", "as", "search", "engines", "."], "sentence-detokenized": "Since 1986, Miller has led for many years the development of WordNet, a large computer-readable electronic manual used in applications such as search engines.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 18], [19, 22], [23, 26], [27, 30], [31, 35], [36, 41], [42, 45], [46, 57], [58, 60], [61, 68], [68, 69], [70, 71], [72, 77], [78, 86], [86, 87], [87, 95], [96, 106], [107, 113], [114, 118], [119, 121], [122, 134], [135, 139], [140, 142], [143, 149], [150, 157], [157, 158]]}
{"doc_key": "ai-dev-107", "ner": [[3, 4, "algorithm"], [7, 9, "algorithm"], [12, 14, "researcher"], [17, 24, "organisation"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 12, 14, "origin", "", false, false], [3, 4, 27, 29, "win-defeat", "", false, false], [7, 9, 12, 14, "origin", "", false, false], [7, 9, 27, 29, "win-defeat", "", false, false], [12, 14, 17, 24, "physical", "", false, false], [12, 14, 17, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Since", "2009", ",", "recurrent", "neural", "networks", "and", "deep", "neural", "networks", "developed", "by", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "Swiss", "Artificial", "Intelligence", "Laboratory", "IDSIA", "have", "won", "several", "international", "handwriting", "competitions", "."], "sentence-detokenized": "Since 2009, recurrent neural networks and deep neural networks developed by J\u00fcrgen Schmidhuber's research group at the Swiss Artificial Intelligence Laboratory IDSIA have won several international handwriting competitions.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 21], [22, 28], [29, 37], [38, 41], [42, 46], [47, 53], [54, 62], [63, 72], [73, 75], [76, 82], [83, 94], [94, 96], [97, 105], [106, 111], [112, 114], [115, 118], [119, 124], [125, 135], [136, 148], [149, 159], [160, 165], [166, 170], [171, 174], [175, 182], [183, 196], [197, 208], [209, 221], [221, 222]]}
{"doc_key": "ai-dev-108", "ner": [[5, 6, "programlang"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "is", "implemented", "in", "C", "+++", "and", "adapted", "to", "Python", "."], "sentence-detokenized": "The software is implemented in C+++ and adapted to Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 30], [31, 32], [32, 35], [36, 39], [40, 47], [48, 50], [51, 57], [57, 58]]}
{"doc_key": "ai-dev-109", "ner": [[8, 9, "country"], [14, 15, "misc"], [29, 30, "misc"], [34, 36, "misc"], [37, 37, "misc"], [39, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[29, 30, 8, 9, "temporal", "", false, false], [29, 30, 14, 15, "artifact", "", false, false], [29, 30, 39, 39, "physical", "", false, false], [37, 37, 34, 36, "named", "", false, false], [37, 37, 39, 39, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1857", ",", "at", "the", "request", "of", "the", "Tokugawa", "shogunate", ",", "a", "group", "of", "Dutch", "engineers", "began", "to", "build", "a", "modern", "western", "-", "style", "foundry", "and", "shipyard", ",", "the", "Nagasaki", "Yotetsusho", ",", "near", "the", "Dutch", "settlement", "of", "Dejima", ",", "Nagasaki", "."], "sentence-detokenized": "In 1857, at the request of the Tokugawa shogunate, a group of Dutch engineers began to build a modern western-style foundry and shipyard, the Nagasaki Yotetsusho, near the Dutch settlement of Dejima, Nagasaki.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 39], [40, 49], [49, 50], [51, 52], [53, 58], [59, 61], [62, 67], [68, 77], [78, 83], [84, 86], [87, 92], [93, 94], [95, 101], [102, 109], [109, 110], [110, 115], [116, 123], [124, 127], [128, 136], [136, 137], [138, 141], [142, 150], [151, 161], [161, 162], [163, 167], [168, 171], [172, 177], [178, 188], [189, 191], [192, 198], [198, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-dev-110", "ner": [[9, 12, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["We", "are", "as", "accurate", "as", "possible", "in", "determining", "the", "root", "mean", "square", "error", "between", "mathy", "/", "math", "and", "math", "_", "hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "we", "want", "math", "(", "y", "-", "_", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", "^", "2", "/", "math", "to", "be", "the", "minimum", "for", "both", "mathx", "_", "1", ",\\", "points", ",", "x", "_n", "/", "math", ",", "and", "the", "points", "that", "are", "not", "in", "our", "sample", "."], "sentence-detokenized": "We are as accurate as possible in determining the root mean square error between mathy / math and math _ hat {f} (x; D) / math: we want math (y - _ hat {f} (x; D)) ^ 2 / math to be the minimum for both mathx _ 1,\\ points, x _n / math, and the points that are not in our sample.", "token2charspan": [[0, 2], [3, 6], [7, 9], [10, 18], [19, 21], [22, 30], [31, 33], [34, 45], [46, 49], [50, 54], [55, 59], [60, 66], [67, 72], [73, 80], [81, 86], [87, 88], [89, 93], [94, 97], [98, 102], [103, 104], [105, 108], [109, 110], [110, 111], [111, 112], [113, 114], [114, 115], [115, 116], [117, 118], [118, 119], [120, 121], [122, 126], [126, 127], [128, 130], [131, 135], [136, 140], [141, 142], [142, 143], [144, 145], [146, 147], [148, 151], [152, 153], [153, 154], [154, 155], [156, 157], [157, 158], [158, 159], [160, 161], [161, 162], [162, 163], [164, 165], [166, 167], [168, 169], [170, 174], [175, 177], [178, 180], [181, 184], [185, 192], [193, 196], [197, 201], [202, 207], [208, 209], [210, 211], [211, 213], [214, 220], [220, 221], [222, 223], [224, 226], [227, 228], [229, 233], [233, 234], [235, 238], [239, 242], [243, 249], [250, 254], [255, 258], [259, 262], [263, 265], [266, 269], [270, 276], [276, 277]]}
{"doc_key": "ai-dev-111", "ner": [[3, 3, "researcher"], [10, 14, "organisation"], [21, 25, "product"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 10, 14, "role", "", false, false], [21, 25, 10, 14, "temporal", "", false, false], [21, 25, 33, 34, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "later", "invited", "Vydner", "to", "attend", "the", "annual", "meeting", "of", "the", "American", "Translators", "Association", "in", "October", "the", "following", "year", ",", "where", "Vydner", "'s", "machine", "translation", "system", "was", "hailed", "as", "a", "likely", "breakthrough", "in", "machine", "translation", "."], "sentence-detokenized": "He later invited Vydner to attend the annual meeting of the American Translators Association in October the following year, where Vydner's machine translation system was hailed as a likely breakthrough in machine translation.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 23], [24, 26], [27, 33], [34, 37], [38, 44], [45, 52], [53, 55], [56, 59], [60, 68], [69, 80], [81, 92], [93, 95], [96, 103], [104, 107], [108, 117], [118, 122], [122, 123], [124, 129], [130, 136], [136, 138], [139, 146], [147, 158], [159, 165], [166, 169], [170, 176], [177, 179], [180, 181], [182, 188], [189, 201], [202, 204], [205, 212], [213, 224], [224, 225]]}
{"doc_key": "ai-dev-112", "ner": [[8, 16, "conference"], [14, 16, "conference"], [0, 1, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 16, 8, 16, "named", "", false, false], [14, 16, 8, 16, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["\"", "Google", "researchers", "presented", "this", "work", "at", "the", "2018", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "conference", "."], "sentence-detokenized": "\"Google researchers presented this work at the 2018 Neural Information Processing Systems (NeurIPS) conference.", "token2charspan": [[0, 1], [1, 7], [8, 19], [20, 29], [30, 34], [35, 39], [40, 42], [43, 46], [47, 51], [52, 58], [59, 70], [71, 81], [82, 89], [90, 91], [91, 98], [98, 99], [100, 110], [110, 111]]}
{"doc_key": "ai-dev-113", "ner": [[0, 4, "algorithm"], [10, 12, "algorithm"], [14, 18, "metrics"], [22, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 10, 12, "usage", "", false, false], [10, 12, 14, 18, "related-to", "", true, false], [14, 18, 22, 27, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Baum", "-", "Welch", "algorithm", "uses", "the", "well", "-", "known", "EM", "algorithm", "to", "find", "the", "maximum", "likelihood", "estimate", "of", "the", "parameters", "of", "a", "hidden", "Markov", "model", "given", "a", "set", "of", "observed", "feature", "vectors", "."], "sentence-detokenized": "The Baum-Welch algorithm uses the well-known EM algorithm to find the maximum likelihood estimate of the parameters of a hidden Markov model given a set of observed feature vectors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [15, 24], [25, 29], [30, 33], [34, 38], [38, 39], [39, 44], [45, 47], [48, 57], [58, 60], [61, 65], [66, 69], [70, 77], [78, 88], [89, 97], [98, 100], [101, 104], [105, 115], [116, 118], [119, 120], [121, 127], [128, 134], [135, 140], [141, 146], [147, 148], [149, 152], [153, 155], [156, 164], [165, 172], [173, 180], [180, 181]]}
{"doc_key": "ai-dev-114", "ner": [[4, 4, "product"], [9, 9, "product"], [27, 29, "misc"], [34, 42, "product"], [45, 45, "programlang"], [46, 51, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 9, 9, "compare", "", false, false], [27, 29, 9, 9, "part-of", "", false, false], [34, 42, 9, 9, "part-of", "", false, false], [46, 51, 9, 9, "part-of", "", false, false], [46, 51, 45, 45, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": [")", "In", "addition", "to", "OpenCyc", "'s", "taxonomic", "information", ",", "ResearchCyc", "includes", "much", "more", "semantic", "knowledge", "(", "i.e.", "additional", "facts", "and", "rules", ")", "related", "to", "the", "concepts", "in", "the", "knowledge", "base", ",", "as", "well", "as", "a", "large", "lexicon", ",", "English", "parsing", "and", "generation", "tools", ",", "and", "Java", "interfaces", "for", "knowledge", "editing", "and", "querying", "."], "sentence-detokenized": ") In addition to OpenCyc's taxonomic information, ResearchCyc includes much more semantic knowledge (i.e. additional facts and rules) related to the concepts in the knowledge base, as well as a large lexicon, English parsing and generation tools, and Java interfaces for knowledge editing and querying.", "token2charspan": [[0, 1], [2, 4], [5, 13], [14, 16], [17, 24], [24, 26], [27, 36], [37, 48], [48, 49], [50, 61], [62, 70], [71, 75], [76, 80], [81, 89], [90, 99], [100, 101], [101, 105], [106, 116], [117, 122], [123, 126], [127, 132], [132, 133], [134, 141], [142, 144], [145, 148], [149, 157], [158, 160], [161, 164], [165, 174], [175, 179], [179, 180], [181, 183], [184, 188], [189, 191], [192, 193], [194, 199], [200, 207], [207, 208], [209, 216], [217, 224], [225, 228], [229, 239], [240, 245], [245, 246], [247, 250], [251, 255], [256, 266], [267, 270], [271, 280], [281, 288], [289, 292], [293, 301], [301, 302]]}
{"doc_key": "ai-dev-115", "ner": [[0, 2, "algorithm"], [5, 6, "task"], [10, 11, "field"], [13, 14, "field"], [16, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 6, "type-of", "", false, false], [5, 6, 10, 11, "part-of", "task_part_of_field", false, false], [5, 6, 13, 14, "part-of", "task_part_of_field", false, false], [5, 6, 16, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Hough", "transform", "is", "a", "feature", "extraction", "method", "used", "in", "image", "analysis", ",", "computer", "vision", "and", "digital", "image", "processing", "."], "sentence-detokenized": "The Hough transform is a feature extraction method used in image analysis, computer vision and digital image processing.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 22], [23, 24], [25, 32], [33, 43], [44, 50], [51, 55], [56, 58], [59, 64], [65, 73], [73, 74], [75, 83], [84, 90], [91, 94], [95, 102], [103, 108], [109, 119], [119, 120]]}
{"doc_key": "ai-dev-116", "ner": [[6, 6, "product"], [8, 12, "product"], [3, 3, "organisation"], [16, 16, "product"], [18, 22, "researcher"], [25, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 8, 12, "named", "", false, false], [6, 6, 3, 3, "artifact", "", false, false], [6, 6, 16, 16, "origin", "developed_from", false, false], [16, 16, 18, 22, "artifact", "", false, false], [25, 26, 3, 3, "role", "supported", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1978", ",", "Unimation", "developed", "the", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "robot", "from", "Vicarm", "(", "Victor", "Scheinman", ")", ",", "with", "support", "from", "General", "Motors", "."], "sentence-detokenized": "In 1978, Unimation developed the PUMA (Programmable Universal Machine for Assembly) robot from Vicarm (Victor Scheinman), with support from General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 28], [29, 32], [33, 37], [38, 39], [39, 51], [52, 61], [62, 69], [70, 73], [74, 82], [82, 83], [84, 89], [90, 94], [95, 101], [102, 103], [103, 109], [110, 119], [119, 120], [120, 121], [122, 126], [127, 134], [135, 139], [140, 147], [148, 154], [154, 155]]}
{"doc_key": "ai-dev-117", "ner": [[0, 1, "algorithm"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 7, 8, "origin", "", false, false], [0, 1, 10, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "LSTM", "was", "proposed", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "The LSTM was proposed in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 21], [22, 24], [25, 29], [30, 32], [33, 37], [38, 48], [49, 52], [53, 59], [60, 71], [71, 72]]}
{"doc_key": "ai-dev-118", "ner": [[11, 12, "metrics"], [15, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "into", "a", "2", "\u00d7", "2", "contingency", "table", "or", "a", "confusion", "matrix", ",", "as", "below", ":"], "sentence-detokenized": "The four results can be formulated into a 2 \u00d7 2 contingency table or a confusion matrix, as below:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 39], [40, 41], [42, 43], [44, 45], [46, 47], [48, 59], [60, 65], [66, 68], [69, 70], [71, 80], [81, 87], [87, 88], [89, 91], [92, 97], [97, 98]]}
{"doc_key": "ai-dev-119", "ner": [[7, 7, "conference"], [10, 11, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "also", "instrumental", "in", "setting", "up", "ELRA", "and", "the", "LREC", "Conference", "."], "sentence-detokenized": "He was also instrumental in setting up ELRA and the LREC Conference.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 27], [28, 35], [36, 38], [39, 43], [44, 47], [48, 51], [52, 56], [57, 67], [67, 68]]}
{"doc_key": "ai-dev-120", "ner": [[11, 13, "misc"], [15, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 18, 11, 13, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "popular", "application", "of", "serial", "robots", "in", "industry", "today", "is", "an", "assembly", "robot", "called", "the", "SCARA", "robot", ",", "which", "has", "four", "degrees", "of", "freedom", "."], "sentence-detokenized": "A popular application of serial robots in industry today is an assembly robot called the SCARA robot, which has four degrees of freedom.", "token2charspan": [[0, 1], [2, 9], [10, 21], [22, 24], [25, 31], [32, 38], [39, 41], [42, 50], [51, 56], [57, 59], [60, 62], [63, 71], [72, 77], [78, 84], [85, 88], [89, 94], [95, 100], [100, 101], [102, 107], [108, 111], [112, 116], [117, 124], [125, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-dev-121", "ner": [[10, 16, "conference"], [23, 23, "conference"], [17, 21, "conference"], [34, 34, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 10, 16, "named", "", false, false], [34, 34, 17, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "a", "founding", "member", "and", "former", "chair", "of", "the", "Web", "as", "Corpus", "Special", "Interest", "Group", "of", "the", "Association", "for", "Computational", "Linguistics", "(", "SIGWAC", ")", "(", "2006-2008", ")", ",", "and", "a", "founding", "member", "of", "SENSEVAL", "."], "sentence-detokenized": "He was a founding member and former chair of the Web as Corpus Special Interest Group of the Association for Computational Linguistics (SIGWAC) (2006-2008), and a founding member of SENSEVAL.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 17], [18, 24], [25, 28], [29, 35], [36, 41], [42, 44], [45, 48], [49, 52], [53, 55], [56, 62], [63, 70], [71, 79], [80, 85], [86, 88], [89, 92], [93, 104], [105, 108], [109, 122], [123, 134], [135, 136], [136, 142], [142, 143], [144, 145], [145, 154], [154, 155], [155, 156], [157, 160], [161, 162], [163, 171], [172, 178], [179, 181], [182, 190], [190, 191]]}
{"doc_key": "ai-dev-122", "ner": [[4, 4, "product"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 4, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "platform", ",", "LinguaStream", "provides", "an", "extensive", "Java", "API", "."], "sentence-detokenized": "As a platform, LinguaStream provides an extensive Java API.", "token2charspan": [[0, 2], [3, 4], [5, 13], [13, 14], [15, 27], [28, 36], [37, 39], [40, 49], [50, 54], [55, 58], [58, 59]]}
{"doc_key": "ai-dev-123", "ner": [[12, 14, "programlang"], [15, 17, "misc"], [20, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 14, 20, 22, "type-of", "", false, false], [15, 17, 20, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "robot", "kit", "is", "Android", "-", "based", "and", "can", "be", "programmed", "using", "Java", ",", "the", "Blocks", "programming", "interface", "or", "other", "Android", "programming", "systems", "."], "sentence-detokenized": "The robot kit is Android-based and can be programmed using Java, the Blocks programming interface or other Android programming systems.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 16], [17, 24], [24, 25], [25, 30], [31, 34], [35, 38], [39, 41], [42, 52], [53, 58], [59, 63], [63, 64], [65, 68], [69, 75], [76, 87], [88, 97], [98, 100], [101, 106], [107, 114], [115, 126], [127, 134], [134, 135]]}
{"doc_key": "ai-dev-124", "ner": [[12, 14, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "way", "the", "linked", "list", "is", "defined", "determines", "whether", "to", "use", "a", "depth", "search", "or", "a", "width", "search", "."], "sentence-detokenized": "The way the linked list is defined determines whether to use a depth search or a width search.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 18], [19, 23], [24, 26], [27, 34], [35, 45], [46, 53], [54, 56], [57, 60], [61, 62], [63, 68], [69, 75], [76, 78], [79, 80], [81, 86], [87, 93], [93, 94]]}
{"doc_key": "ai-dev-125", "ner": [[21, 22, "task"], [26, 28, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "regions", "can", "signal", "the", "presence", "of", "objects", "or", "parts", "of", "objects", "in", "the", "image", "area", "and", "can", "be", "used", "for", "object", "recognition", "and", "/", "or", "object", "image", "tracking", "."], "sentence-detokenized": "These regions can signal the presence of objects or parts of objects in the image area and can be used for object recognition and/or object image tracking.", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 24], [25, 28], [29, 37], [38, 40], [41, 48], [49, 51], [52, 57], [58, 60], [61, 68], [69, 71], [72, 75], [76, 81], [82, 86], [87, 90], [91, 94], [95, 97], [98, 102], [103, 106], [107, 113], [114, 125], [126, 129], [129, 130], [130, 132], [133, 139], [140, 145], [146, 154], [154, 155]]}
{"doc_key": "ai-dev-126", "ner": [[4, 5, "algorithm"], [7, 9, "product"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 4, 5, "type-of", "", false, false], [7, 9, 13, 13, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "semantic", "network", "is", "WordNet", ",", "a", "database", "of", "the", "English", "lexicon", "."], "sentence-detokenized": "An example of a semantic network is WordNet, a database of the English lexicon.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 32], [33, 35], [36, 43], [43, 44], [45, 46], [47, 55], [56, 58], [59, 62], [63, 70], [71, 78], [78, 79]]}
{"doc_key": "ai-dev-127", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 11, "field"], [21, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 7, 8, "part-of", "", false, false], [0, 1, 10, 11, "named", "same", false, false], [0, 1, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Speech", "recognition", "is", "an", "interdisciplinary", "field", "of", "computer", "science", "and", "computational", "linguistics", ",", "which", "develops", "techniques", "and", "technologies", "that", "allow", "computers", "to", "recognise", "and", "translate", "spoken", "language", "into", "text", "."], "sentence-detokenized": "Speech recognition is an interdisciplinary field of computer science and computational linguistics, which develops techniques and technologies that allow computers to recognise and translate spoken language into text.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 24], [25, 42], [43, 48], [49, 51], [52, 60], [61, 68], [69, 72], [73, 86], [87, 98], [98, 99], [100, 105], [106, 114], [115, 125], [126, 129], [130, 142], [143, 147], [148, 153], [154, 163], [164, 166], [167, 176], [177, 180], [181, 190], [191, 197], [198, 206], [207, 211], [212, 216], [216, 217]]}
{"doc_key": "ai-dev-128", "ner": [[0, 1, "field"], [4, 5, "misc"], [10, 13, "field"], [9, 9, "task"], [15, 16, "task"], [39, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 39, 40, "named", "same", false, false], [10, 13, 0, 1, "part-of", "subfield", false, false], [9, 9, 0, 1, "part-of", "", false, false], [9, 9, 10, 13, "part-of", "", false, false], [15, 16, 10, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["While", "AI", "focuses", "on", "applied", "ontology", "areas", "such", "as", "machine", "processing", "of", "natural", "language", "and", "knowledge", "representation", ",", "ontology", "editors", "are", "often", "used", "in", "a", "variety", "of", "domains", ",", "such", "as", "education", ",", "without", "the", "intention", "of", "contributing", "to", "artificial", "intelligence", "."], "sentence-detokenized": "While AI focuses on applied ontology areas such as machine processing of natural language and knowledge representation, ontology editors are often used in a variety of domains, such as education, without the intention of contributing to artificial intelligence.", "token2charspan": [[0, 5], [6, 8], [9, 16], [17, 19], [20, 27], [28, 36], [37, 42], [43, 47], [48, 50], [51, 58], [59, 69], [70, 72], [73, 80], [81, 89], [90, 93], [94, 103], [104, 118], [118, 119], [120, 128], [129, 136], [137, 140], [141, 146], [147, 151], [152, 154], [155, 156], [157, 164], [165, 167], [168, 175], [175, 176], [177, 181], [182, 184], [185, 194], [194, 195], [196, 203], [204, 207], [208, 217], [218, 220], [221, 233], [234, 236], [237, 247], [248, 260], [260, 261]]}
{"doc_key": "ai-dev-129", "ner": [[6, 15, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 15, 13, 14, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "update", "rule", "is", "actually", "a", "stochastic", "update", "of", "the", "descent", "of", "the", "linear", "regression", "gradient", "."], "sentence-detokenized": "This update rule is actually a stochastic update of the descent of the linear regression gradient.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 28], [29, 30], [31, 41], [42, 48], [49, 51], [52, 55], [56, 63], [64, 66], [67, 70], [71, 77], [78, 88], [89, 97], [97, 98]]}
{"doc_key": "ai-dev-130", "ner": [[6, 11, "organisation"], [14, 20, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "been", "elected", "to", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "the", "National", "Academy", "of", "Sciences", ",", "and", "has", "received", "numerous", "awards", ":"], "sentence-detokenized": "He has been elected to the American Academy of Arts and Sciences and the National Academy of Sciences, and has received numerous awards:", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 22], [23, 26], [27, 35], [36, 43], [44, 46], [47, 51], [52, 55], [56, 64], [65, 68], [69, 72], [73, 81], [82, 89], [90, 92], [93, 101], [101, 102], [103, 106], [107, 110], [111, 119], [120, 128], [129, 135], [135, 136]]}
{"doc_key": "ai-dev-131", "ner": [[7, 8, "organisation"], [13, 14, "person"], [16, 20, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 13, 14, "related-to", "written_about_by", false, false], [7, 8, 16, 20, "related-to", "written_about_by", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "recent", "school", "of", "thought", "on", "Honda", "'s", "strategy", "was", "presented", "by", "Gary", "Hamel", "and", "C.K", ".", "Prahalad", "in", "1989", "."], "sentence-detokenized": "The most recent school of thought on Honda's strategy was presented by Gary Hamel and C.K. Prahalad in 1989.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 22], [23, 25], [26, 33], [34, 36], [37, 42], [42, 44], [45, 53], [54, 57], [58, 67], [68, 70], [71, 75], [76, 81], [82, 85], [86, 89], [89, 90], [91, 99], [100, 102], [103, 107], [107, 108]]}
{"doc_key": "ai-dev-132", "ner": [[1, 1, "metrics"], [5, 8, "metrics"], [17, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 5, 8, "related-to", "calculates", true, false], [1, 1, 17, 18, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "BLEU", "simply", "calculates", "the", "accuracy", "of", "the", "n-grams", ",", "giving", "each", "one", "an", "equal", "weight", ",", "NIST", "also", "calculates", "how", "informative", "a", "particular", "n-", "gram", "is", "."], "sentence-detokenized": "While BLEU simply calculates the accuracy of the n-grams, giving each one an equal weight, NIST also calculates how informative a particular n-gram is.", "token2charspan": [[0, 5], [6, 10], [11, 17], [18, 28], [29, 32], [33, 41], [42, 44], [45, 48], [49, 56], [56, 57], [58, 64], [65, 69], [70, 73], [74, 76], [77, 82], [83, 89], [89, 90], [91, 95], [96, 100], [101, 111], [112, 115], [116, 127], [128, 129], [130, 140], [141, 143], [143, 147], [148, 150], [150, 151]]}
{"doc_key": "ai-dev-133", "ner": [[4, 8, "misc"], [9, 13, "conference"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 8, 9, 13, "temporal", "", false, false], [15, 15, 9, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "awarded", "the", "2019", "Lifetime", "Achievement", "Award", "by", "the", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "He was awarded the 2019 Lifetime Achievement Award by the Association for Computational Linguistics (ACL).", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 18], [19, 23], [24, 32], [33, 44], [45, 50], [51, 53], [54, 57], [58, 69], [70, 73], [74, 87], [88, 99], [100, 101], [101, 104], [104, 105], [105, 106]]}
{"doc_key": "ai-dev-134", "ner": [[0, 2, "researcher"], [5, 11, "organisation"], [13, 13, "organisation"], [20, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 11, "role", "", false, false], [0, 2, 20, 24, "role", "", false, false], [13, 13, 5, 11, "named", "", false, false], [26, 26, 20, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "is", "a", "Fellow", "of", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "and", "a", "member", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara is a Fellow of the Institute of Electrical and Electronics Engineers (IEEE) and a member of the American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 18], [19, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 65], [66, 75], [76, 77], [77, 81], [81, 82], [83, 86], [87, 88], [89, 95], [96, 98], [99, 102], [103, 111], [112, 123], [124, 127], [128, 138], [139, 151], [152, 153], [153, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-dev-135", "ner": [[2, 2, "product"], [7, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 7, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "following", "MATLAB", "code", "demonstrates", "a", "specific", "way", "of", "solving", "the", "nonlinear", "system", "of", "equations", "presented", "in", "the", "previous", "section", ":", "see", "also", "."], "sentence-detokenized": "The following MATLAB code demonstrates a specific way of solving the nonlinear system of equations presented in the previous section: see also.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 38], [39, 40], [41, 49], [50, 53], [54, 56], [57, 64], [65, 68], [69, 78], [79, 85], [86, 88], [89, 98], [99, 108], [109, 111], [112, 115], [116, 124], [125, 132], [132, 133], [134, 137], [138, 142], [142, 143]]}
{"doc_key": "ai-dev-136", "ner": [[4, 6, "product"], [14, 18, "field"], [37, 38, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 14, 18, "related-to", "trained_by", true, false], [4, 6, 37, 38, "related-to", "trained_by", true, false], [14, 18, 37, 38, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "most", "cases", ",", "pattern", "recognition", "systems", "are", "trained", "on", "labelled", "training", "data", "(", "supervised", "learning", ")", ",", "but", "when", "labelled", "data", "is", "not", "available", ",", "other", "algorithms", "can", "be", "used", "to", "discover", "previously", "unknown", "patterns", "(", "unsupervised", "learning", ")", "."], "sentence-detokenized": "In most cases, pattern recognition systems are trained on labelled training data (supervised learning), but when labelled data is not available, other algorithms can be used to discover previously unknown patterns (unsupervised learning).", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 22], [23, 34], [35, 42], [43, 46], [47, 54], [55, 57], [58, 66], [67, 75], [76, 80], [81, 82], [82, 92], [93, 101], [101, 102], [102, 103], [104, 107], [108, 112], [113, 121], [122, 126], [127, 129], [130, 133], [134, 143], [143, 144], [145, 150], [151, 161], [162, 165], [166, 168], [169, 173], [174, 176], [177, 185], [186, 196], [197, 204], [205, 213], [214, 215], [215, 227], [228, 236], [236, 237], [237, 238]]}
{"doc_key": "ai-dev-137", "ner": [[15, 17, "researcher"], [13, 13, "country"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 17, 13, 13, "physical", "", false, false], [15, 17, 28, 29, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "was", "first", "introduced", "in", "1960", ".", "It", "was", "first", "used", "in", "the", "US", "by", "Lawrence", "J.", "Fogel", "to", "use", "simulated", "evolution", "as", "a", "learning", "process", "to", "create", "artificial", "intelligence", "."], "sentence-detokenized": "It was first introduced in 1960. It was first used in the US by Lawrence J. Fogel to use simulated evolution as a learning process to create artificial intelligence.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 23], [24, 26], [27, 31], [31, 32], [33, 35], [36, 39], [40, 45], [46, 50], [51, 53], [54, 57], [58, 60], [61, 63], [64, 72], [73, 75], [76, 81], [82, 84], [85, 88], [89, 98], [99, 108], [109, 111], [112, 113], [114, 122], [123, 130], [131, 133], [134, 140], [141, 151], [152, 164], [164, 165]]}
{"doc_key": "ai-dev-138", "ner": [[0, 1, "field"], [10, 11, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 10, 11, "part-of", "", false, false], [14, 15, 10, 11, "part-of", "", false, false], [17, 18, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Reinforcement", "learning", "is", "one", "of", "the", "three", "main", "paradigms", "of", "machine", "learning", ",", "alongside", "supervised", "learning", "and", "unsupervised", "learning", "."], "sentence-detokenized": "Reinforcement learning is one of the three main paradigms of machine learning, alongside supervised learning and unsupervised learning.", "token2charspan": [[0, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 42], [43, 47], [48, 57], [58, 60], [61, 68], [69, 77], [77, 78], [79, 88], [89, 99], [100, 108], [109, 112], [113, 125], [126, 134], [134, 135]]}
{"doc_key": "ai-dev-139", "ner": [[4, 5, "field"], [12, 12, "programlang"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 28, 29, "usage", "applies", false, false], [12, 12, 28, 29, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "such", "cases", ",", "cloud", "computing", "and", "the", "open", "source", "programming", "language", "R", "can", "help", "smaller", "banks", "to", "apply", "risk", "analysis", "and", "support", "branch", "-", "level", "monitoring", "through", "predictive", "analytics", "."], "sentence-detokenized": "In such cases, cloud computing and the open source programming language R can help smaller banks to apply risk analysis and support branch-level monitoring through predictive analytics.", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 20], [21, 30], [31, 34], [35, 38], [39, 43], [44, 50], [51, 62], [63, 71], [72, 73], [74, 77], [78, 82], [83, 90], [91, 96], [97, 99], [100, 105], [106, 110], [111, 119], [120, 123], [124, 131], [132, 138], [138, 139], [139, 144], [145, 155], [156, 163], [164, 174], [175, 184], [184, 185]]}
{"doc_key": "ai-dev-140", "ner": [[13, 14, "researcher"], [16, 16, "algorithm"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 14, 20, 21, "named", "same", false, false], [16, 16, 13, 14, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["One", "of", "the", "first", "versions", "of", "the", "theorem", "was", "proved", "in", "1989", "by", "George", "Cybenko", "for", "sigmoid", "activation", "functions", ".", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "One of the first versions of the theorem was proved in 1989 by George Cybenko for sigmoid activation functions. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 25], [26, 28], [29, 32], [33, 40], [41, 44], [45, 51], [52, 54], [55, 59], [60, 62], [63, 69], [70, 77], [78, 81], [82, 89], [90, 100], [101, 110], [110, 111], [112, 119], [120, 122], [123, 124], [124, 128], [128, 129], [129, 130], [131, 132], [133, 134], [134, 135], [135, 136], [136, 137], [138, 145], [145, 146]]}
{"doc_key": "ai-dev-141", "ner": [[6, 9, "algorithm"], [10, 11, "metrics"], [17, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 6, 9, "part-of", "", false, false], [17, 21, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "process", ",", "known", "as", "cross", "-checking", ",", "the", "MSE", "is", "often", "referred", "to", "as", "the", "mean", "square", "error", "of", "prediction", "and", "is", "calculated", "as", "follows"], "sentence-detokenized": "In this process, known as cross-checking, the MSE is often referred to as the mean square error of prediction and is calculated as follows", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 22], [23, 25], [26, 31], [31, 40], [40, 41], [42, 45], [46, 49], [50, 52], [53, 58], [59, 67], [68, 70], [71, 73], [74, 77], [78, 82], [83, 89], [90, 95], [96, 98], [99, 109], [110, 113], [114, 116], [117, 127], [128, 130], [131, 138]]}
{"doc_key": "ai-dev-142", "ner": [[0, 0, "task"], [4, 6, "task"], [8, 12, "task"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "compare", "", false, false], [4, 6, 18, 19, "part-of", "", false, false], [8, 12, 4, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OMR", "generally", "differs", "from", "Optical", "Character", "Recognition", "(", "OCR", ")", "in", "that", "it", "does", "not", "require", "a", "sophisticated", "pattern", "recognition", "engine", "."], "sentence-detokenized": "OMR generally differs from Optical Character Recognition (OCR) in that it does not require a sophisticated pattern recognition engine.", "token2charspan": [[0, 3], [4, 13], [14, 21], [22, 26], [27, 34], [35, 44], [45, 56], [57, 58], [58, 61], [61, 62], [63, 65], [66, 70], [71, 73], [74, 78], [79, 82], [83, 90], [91, 92], [93, 106], [107, 114], [115, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-dev-143", "ner": [[8, 9, "location"], [11, 11, "location"], [13, 15, "location"], [17, 18, "location"], [20, 21, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 11, 13, 15, "physical", "", false, false], [17, 18, 11, 11, "physical", "", false, false], [20, 21, 11, 11, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "2018", "and", "2019", "championships", "will", "be", "held", "in", "Houston", "and", "Detroit", ",", "Michigan", ",", "at", "the", "TCF", "Center", "and", "Ford", "Field", "."], "sentence-detokenized": "The 2018 and 2019 championships will be held in Houston and Detroit, Michigan, at the TCF Center and Ford Field.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 17], [18, 31], [32, 36], [37, 39], [40, 44], [45, 47], [48, 55], [56, 59], [60, 67], [67, 68], [69, 77], [77, 78], [79, 81], [82, 85], [86, 89], [90, 96], [97, 100], [101, 105], [106, 111], [111, 112]]}
{"doc_key": "ai-dev-144", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "considered", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multiclass", "classification", "."], "sentence-detokenized": "Classification can be considered as two separate problems - binary classification and multiclass classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 96], [97, 111], [111, 112]]}
{"doc_key": "ai-dev-145", "ner": [[4, 5, "product"], [8, 9, "product"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "type-of", "", false, false], [12, 13, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "examples", "of", "popular", "parallel", "robots", "are", "the", "Stewart", "platform", "and", "the", "Delta", "robot", "."], "sentence-detokenized": "Two examples of popular parallel robots are the Stewart platform and the Delta robot.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 23], [24, 32], [33, 39], [40, 43], [44, 47], [48, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-146", "ner": [[4, 8, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 8, 21, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "Nevertheless", ",", "the", "ReLU", "activation", "function", ",", "which", "is", "non-differentiated", "at", "0", ",", "has", "become", "quite", "popular", ",", "e.g.", "in", "AlexNet", ")", "."], "sentence-detokenized": "(Nevertheless, the ReLU activation function, which is non-differentiated at 0, has become quite popular, e.g. in AlexNet).", "token2charspan": [[0, 1], [1, 13], [13, 14], [15, 18], [19, 23], [24, 34], [35, 43], [43, 44], [45, 50], [51, 53], [54, 72], [73, 75], [76, 77], [77, 78], [79, 82], [83, 89], [90, 95], [96, 103], [103, 104], [105, 109], [110, 112], [113, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-dev-147", "ner": [[0, 4, "metrics"], [11, 12, "task"], [18, 18, "task"], [20, 21, "task"], [23, 24, "task"], [29, 30, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 4, 29, 30, "named", "", true, false], [11, 12, 0, 4, "usage", "", true, false], [18, 18, 11, 12, "part-of", "", false, false], [20, 21, 11, 12, "part-of", "", false, false], [23, 24, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "F", "-", "score", "is", "often", "used", "in", "the", "field", "of", "information", "retrieval", "to", "evaluate", "the", "performance", "of", "search", ",", "document", "classification", "and", "query", "classification", ",", "which", "is", "why", "F_beta", "is", "widely", "used", "."], "sentence-detokenized": "The F-score is often used in the field of information retrieval to evaluate the performance of search, document classification and query classification, which is why F_beta is widely used.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 20], [21, 25], [26, 28], [29, 32], [33, 38], [39, 41], [42, 53], [54, 63], [64, 66], [67, 75], [76, 79], [80, 91], [92, 94], [95, 101], [101, 102], [103, 111], [112, 126], [127, 130], [131, 136], [137, 151], [151, 152], [153, 158], [159, 161], [162, 165], [166, 172], [173, 175], [176, 182], [183, 187], [187, 188]]}
{"doc_key": "ai-dev-148", "ner": [[16, 17, "algorithm"], [19, 19, "algorithm"], [22, 23, "algorithm"], [25, 25, "algorithm"], [28, 30, "algorithm"], [32, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[19, 19, 16, 17, "named", "", false, false], [25, 25, 22, 23, "named", "", false, false], [32, 32, 28, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "is", "done", "by", "modelling", "the", "received", "signal", "and", "applying", "a", "statistical", "estimation", "method", "such", "as", "maximum", "likelihood", "(", "ML", ")", ",", "majority", "voting", "(", "MV", ")", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "to", "decide", "which", "library", "target", "best", "fits", "the", "model", "built", "from", "the", "received", "signal", "."], "sentence-detokenized": "This is done by modelling the received signal and applying a statistical estimation method such as maximum likelihood (ML), majority voting (MV) or maximum a posteriori (MAP) to decide which library target best fits the model built from the received signal.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 25], [26, 29], [30, 38], [39, 45], [46, 49], [50, 58], [59, 60], [61, 72], [73, 83], [84, 90], [91, 95], [96, 98], [99, 106], [107, 117], [118, 119], [119, 121], [121, 122], [122, 123], [124, 132], [133, 139], [140, 141], [141, 143], [143, 144], [145, 147], [148, 155], [156, 157], [158, 168], [169, 170], [170, 173], [173, 174], [175, 177], [178, 184], [185, 190], [191, 198], [199, 205], [206, 210], [211, 215], [216, 219], [220, 225], [226, 231], [232, 236], [237, 240], [241, 249], [250, 256], [256, 257]]}
{"doc_key": "ai-dev-149", "ner": [[0, 0, "researcher"], [3, 3, "misc"], [4, 6, "field"], [7, 11, "university"], [16, 24, "misc"], [17, 19, "field"], [20, 23, "university"], [28, 28, "misc"], [28, 32, "field"], [33, 38, "university"], [43, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 0, 7, 11, "physical", "", false, false], [0, 0, 7, 11, "role", "", false, false], [0, 0, 20, 23, "physical", "", false, false], [0, 0, 20, 23, "role", "", false, false], [0, 0, 33, 38, "physical", "", false, false], [0, 0, 33, 38, "role", "", false, false], [3, 3, 0, 0, "origin", "", false, false], [3, 3, 4, 6, "topic", "", false, false], [16, 24, 0, 0, "origin", "", false, false], [16, 24, 17, 19, "topic", "", false, false], [28, 28, 0, 0, "origin", "", false, false], [28, 28, 28, 32, "topic", "", false, false], [43, 51, 28, 28, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Sowa", "received", "a", "BSc", "in", "Mathematics", "from", "the", "Massachusetts", "Institute", "of", "Technology", "in", "1962", ",", "an", "MSc", "in", "Applied", "Mathematics", "from", "Harvard", "University", "in", "1966", ",", "and", "a", "PhD", "in", "Computer", "Science", "from", "the", "Universit\u00e9", "de", "Bruxelles", "Vrije", "in", "1999", ",", "entitled", "\"", "Knowledge", "Representation", ":", "Logical", ",", "Philosophical", "and", "Computational", "Foundations", "\"", "."], "sentence-detokenized": "Sowa received a BSc in Mathematics from the Massachusetts Institute of Technology in 1962, an MSc in Applied Mathematics from Harvard University in 1966, and a PhD in Computer Science from the Universit\u00e9 de Bruxelles Vrije in 1999, entitled \"Knowledge Representation: Logical, Philosophical and Computational Foundations\".", "token2charspan": [[0, 4], [5, 13], [14, 15], [16, 19], [20, 22], [23, 34], [35, 39], [40, 43], [44, 57], [58, 67], [68, 70], [71, 81], [82, 84], [85, 89], [89, 90], [91, 93], [94, 97], [98, 100], [101, 108], [109, 120], [121, 125], [126, 133], [134, 144], [145, 147], [148, 152], [152, 153], [154, 157], [158, 159], [160, 163], [164, 166], [167, 175], [176, 183], [184, 188], [189, 192], [193, 203], [204, 206], [207, 216], [217, 222], [223, 225], [226, 230], [230, 231], [232, 240], [241, 242], [242, 251], [252, 266], [266, 267], [268, 275], [275, 276], [277, 290], [291, 294], [295, 308], [309, 320], [320, 321], [321, 322]]}
{"doc_key": "ai-dev-150", "ner": [[1, 2, "task"], [8, 8, "task"], [17, 17, "metrics"], [19, 20, "metrics"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 8, 8, "general-affiliation", "", false, false], [17, 17, 1, 2, "part-of", "", true, false], [19, 20, 1, 2, "part-of", "", true, false], [22, 23, 1, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "paraphrase", "recognition", "can", "be", "presented", "as", "a", "classification", "problem", ",", "most", "standard", "evaluation", "indicators", "such", "as", "accuracy", ",", "f1", "score", "or", "ROC", "curve", "perform", "quite", "well", "."], "sentence-detokenized": "Since paraphrase recognition can be presented as a classification problem, most standard evaluation indicators such as accuracy, f1 score or ROC curve perform quite well.", "token2charspan": [[0, 5], [6, 16], [17, 28], [29, 32], [33, 35], [36, 45], [46, 48], [49, 50], [51, 65], [66, 73], [73, 74], [75, 79], [80, 88], [89, 99], [100, 110], [111, 115], [116, 118], [119, 127], [127, 128], [129, 131], [132, 137], [138, 140], [141, 144], [145, 150], [151, 158], [159, 164], [165, 169], [169, 170]]}
{"doc_key": "ai-dev-151", "ner": [[17, 19, "algorithm"], [25, 26, "algorithm"], [28, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 19, 25, 26, "opposite", "not_suited_for", false, false], [17, 19, 28, 29, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "makes", "it", "practical", "for", "analysing", "large", "datasets", "(", "hundreds", "or", "thousands", "of", "taxa", ")", "and", "for", "bootstrapping", ",", "where", "other", "analysis", "techniques", "(", "e.g.", "maximum", "parsimony", ",", "maximum", "likelihood", ")", "may", "be", "computationally", "too", "complex", "."], "sentence-detokenized": "This makes it practical for analysing large datasets (hundreds or thousands of taxa) and for bootstrapping, where other analysis techniques (e.g. maximum parsimony, maximum likelihood) may be computationally too complex.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 37], [38, 43], [44, 52], [53, 54], [54, 62], [63, 65], [66, 75], [76, 78], [79, 83], [83, 84], [85, 88], [89, 92], [93, 106], [106, 107], [108, 113], [114, 119], [120, 128], [129, 139], [140, 141], [141, 145], [146, 153], [154, 163], [163, 164], [165, 172], [173, 183], [183, 184], [185, 188], [189, 191], [192, 207], [208, 211], [212, 219], [219, 220]]}
{"doc_key": "ai-dev-152", "ner": [[4, 6, "programlang"], [10, 13, "organisation"], [15, 18, "organisation"], [22, 23, "programlang"], [27, 37, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[15, 18, 10, 13, "named", "", false, false], [27, 37, 4, 6, "role", "submits", true, false], [27, 37, 10, 13, "role", "submits_to", true, false]], "relations_mapping_to_source": [1, 3, 4], "sentence": ["2002", "Submission", "of", "the", "DAML", "+", "OIL", "language", "to", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", "-", "work", "carried", "out", "by", "the", "DAML", "contractors", "and", "the", "European", "Union", "/", "United", "States", "Ad", "Hoc", "Joint", "Markup", "Language", "Committee", "."], "sentence-detokenized": "2002 Submission of the DAML+OIL language to the World Wide Web Consortium (W3C) - work carried out by the DAML contractors and the European Union/United States Ad Hoc Joint Markup Language Committee.", "token2charspan": [[0, 4], [5, 15], [16, 18], [19, 22], [23, 27], [27, 28], [28, 31], [32, 40], [41, 43], [44, 47], [48, 53], [54, 58], [59, 62], [63, 73], [74, 75], [75, 78], [78, 79], [80, 81], [82, 86], [87, 94], [95, 98], [99, 101], [102, 105], [106, 110], [111, 122], [123, 126], [127, 130], [131, 139], [140, 145], [145, 146], [146, 152], [153, 159], [160, 162], [163, 166], [167, 172], [173, 179], [180, 188], [189, 198], [198, 199]]}
{"doc_key": "ai-dev-153", "ner": [[3, 4, "misc"], [8, 8, "misc"], [13, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 3, 4, "part-of", "", true, false], [13, 19, 3, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "non-linear", "normalisation", "is", "when", "the", "normalisation", "is", "based", "on", "the", "sigma", "function", ",", "in", "which", "case", "the", "normalised", "image", "is", "calculated", "using", "the", "formula"], "sentence-detokenized": "An example of non-linear normalisation is when the normalisation is based on the sigma function, in which case the normalised image is calculated using the formula", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 38], [39, 41], [42, 46], [47, 50], [51, 64], [65, 67], [68, 73], [74, 76], [77, 80], [81, 86], [87, 95], [95, 96], [97, 99], [100, 105], [106, 110], [111, 114], [115, 125], [126, 131], [132, 134], [135, 145], [146, 151], [152, 155], [156, 163]]}
{"doc_key": "ai-dev-154", "ner": [[4, 5, "metrics"], [9, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 9, 13, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "noted", "that", "accuracy", "is", "usually", "combined", "with", "recall", "to", "solve", "this", "problem", "."], "sentence-detokenized": "It was noted that accuracy is usually combined with recall to solve this problem.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 17], [18, 26], [27, 29], [30, 37], [38, 46], [47, 51], [52, 58], [59, 61], [62, 67], [68, 72], [73, 80], [80, 81]]}
{"doc_key": "ai-dev-155", "ner": [[7, 10, "metrics"], [13, 18, "metrics"], [25, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[25, 27, 13, 18, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "most", "commonly", "used", "indicators", "are", "the", "root", "mean", "square", "error", "and", "the", "root", "mean", "square", "error", ",", "the", "latter", "of", "which", "was", "used", "in", "the", "Netflix", "award", "."], "sentence-detokenized": "The most commonly used indicators are the root mean square error and the root mean square error, the latter of which was used in the Netflix award.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 33], [34, 37], [38, 41], [42, 46], [47, 51], [52, 58], [59, 64], [65, 68], [69, 72], [73, 77], [78, 82], [83, 89], [90, 95], [95, 96], [97, 100], [101, 107], [108, 110], [111, 116], [117, 120], [121, 125], [126, 128], [129, 132], [133, 140], [141, 146], [146, 147]]}
{"doc_key": "ai-dev-156", "ner": [[8, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "August", "2016", ",", "a", "research", "programme", "with", "University", "College", "Hospital", "was", "announced", "to", "develop", "an", "algorithm", "that", "can", "automatically", "distinguish", "between", "healthy", "and", "cancerous", "tissue", "in", "the", "head", "and", "neck", "."], "sentence-detokenized": "In August 2016, a research programme with University College Hospital was announced to develop an algorithm that can automatically distinguish between healthy and cancerous tissue in the head and neck.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 17], [18, 26], [27, 36], [37, 41], [42, 52], [53, 60], [61, 69], [70, 73], [74, 83], [84, 86], [87, 94], [95, 97], [98, 107], [108, 112], [113, 116], [117, 130], [131, 142], [143, 150], [151, 158], [159, 162], [163, 172], [173, 179], [180, 182], [183, 186], [187, 191], [192, 195], [196, 200], [200, 201]]}
{"doc_key": "ai-dev-157", "ner": [[0, 1, "researcher"], [12, 15, "organisation"], [18, 21, "organisation"], [24, 27, "organisation"], [30, 35, "organisation"], [38, 44, "organisation"], [47, 50, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 12, 15, "role", "", false, false], [0, 1, 18, 21, "role", "", false, false], [0, 1, 24, 27, "role", "", false, false], [0, 1, 30, 35, "role", "", false, false], [0, 1, 38, 44, "role", "", false, false], [0, 1, 47, 50, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Posner", "'s", "theoretical", "and", "empirical", "contributions", "have", "been", "recognised", "through", "membership", "in", "the", "American", "Psychological", "Association", ",", "the", "Association", "for", "Psychological", "Science", ",", "the", "Society", "for", "Experimental", "Psychology", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Posner's theoretical and empirical contributions have been recognised through membership in the American Psychological Association, the Association for Psychological Science, the Society for Experimental Psychology, the American Academy of Arts and Sciences, the American Association for the Advancement of Science and the National Academy of Sciences.", "token2charspan": [[0, 6], [6, 8], [9, 20], [21, 24], [25, 34], [35, 48], [49, 53], [54, 58], [59, 69], [70, 77], [78, 88], [89, 91], [92, 95], [96, 104], [105, 118], [119, 130], [130, 131], [132, 135], [136, 147], [148, 151], [152, 165], [166, 173], [173, 174], [175, 178], [179, 186], [187, 190], [191, 203], [204, 214], [214, 215], [216, 219], [220, 228], [229, 236], [237, 239], [240, 244], [245, 248], [249, 257], [257, 258], [259, 262], [263, 271], [272, 283], [284, 287], [288, 291], [292, 303], [304, 306], [307, 314], [315, 318], [319, 322], [323, 331], [332, 339], [340, 342], [343, 351], [351, 352]]}
{"doc_key": "ai-dev-158", "ner": [[2, 3, "product"], [7, 10, "field"], [12, 13, "task"], [15, 17, "task"], [19, 19, "task"], [22, 24, "task"], [26, 26, "task"], [29, 30, "field"], [32, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 3, 7, 10, "usage", "", false, false], [12, 13, 7, 10, "part-of", "", false, false], [15, 17, 7, 10, "part-of", "", false, false], [19, 19, 15, 17, "named", "", false, false], [22, 24, 7, 10, "part-of", "", false, false], [26, 26, 22, 24, "named", "", false, false], [29, 30, 7, 10, "part-of", "", false, false], [32, 33, 7, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["These", "smart", "chatbots", "use", "all", "kinds", "of", "artificial", "intelligence", ",", "such", "as", "image", "moderation", "and", "natural", "language", "understanding", "(", "NLU", ")", ",", "natural", "language", "generation", "(", "NLG", ")", ",", "machine", "learning", "and", "deep", "learning", "."], "sentence-detokenized": "These smart chatbots use all kinds of artificial intelligence, such as image moderation and natural language understanding (NLU), natural language generation (NLG), machine learning and deep learning.", "token2charspan": [[0, 5], [6, 11], [12, 20], [21, 24], [25, 28], [29, 34], [35, 37], [38, 48], [49, 61], [61, 62], [63, 67], [68, 70], [71, 76], [77, 87], [88, 91], [92, 99], [100, 108], [109, 122], [123, 124], [124, 127], [127, 128], [128, 129], [130, 137], [138, 146], [147, 157], [158, 159], [159, 162], [162, 163], [163, 164], [165, 172], [173, 181], [182, 185], [186, 190], [191, 199], [199, 200]]}
{"doc_key": "ai-dev-159", "ner": [[8, 10, "metrics"], [12, 14, "metrics"], [17, 17, "metrics"], [20, 29, "metrics"], [31, 33, "metrics"], [35, 35, "metrics"], [38, 45, "metrics"], [49, 51, "metrics"], [53, 53, "metrics"], [56, 65, "metrics"], [67, 69, "metrics"], [71, 71, "metrics"], [74, 80, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[12, 14, 8, 10, "named", "", false, false], [17, 17, 8, 10, "named", "", false, false], [20, 29, 8, 10, "named", "", false, false], [35, 35, 31, 33, "named", "", false, false], [38, 45, 31, 33, "named", "", false, false], [53, 53, 49, 51, "named", "", false, false], [56, 65, 49, 51, "named", "", false, false], [71, 71, 67, 69, "named", "", false, false], [74, 80, 67, 69, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "ratios", "of", "the", "series", "are", ":", "the", "positive", "predictive", "value", "(", "PPV", ",", "also", "known", "as", "accuracy", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "plus", "the", "false", "discovery", "rate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "and", "the", "negative", "predictive", "value", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "plus", "the", "false", "miss", "rate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "The ratios of the series are: the positive predictive value (PPV, also known as accuracy) (TP / (TP + FP)), plus the false discovery rate (FDR) (FP / (TP + FP)); and the negative predictive value (NPV) (TN / (TN + FN)), plus the false miss rate (FOR) (FN / (TN + FN)).", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 17], [18, 24], [25, 28], [28, 29], [30, 33], [34, 42], [43, 53], [54, 59], [60, 61], [61, 64], [64, 65], [66, 70], [71, 76], [77, 79], [80, 88], [88, 89], [90, 91], [91, 93], [94, 95], [96, 97], [97, 99], [100, 101], [102, 104], [104, 105], [105, 106], [106, 107], [108, 112], [113, 116], [117, 122], [123, 132], [133, 137], [138, 139], [139, 142], [142, 143], [144, 145], [145, 147], [148, 149], [150, 151], [151, 153], [154, 155], [156, 158], [158, 159], [159, 160], [160, 161], [162, 165], [166, 169], [170, 178], [179, 189], [190, 195], [196, 197], [197, 200], [200, 201], [202, 203], [203, 205], [206, 207], [208, 209], [209, 211], [212, 213], [214, 216], [216, 217], [217, 218], [218, 219], [220, 224], [225, 228], [229, 234], [235, 239], [240, 244], [245, 246], [246, 249], [249, 250], [251, 252], [252, 254], [255, 256], [257, 258], [258, 260], [261, 262], [263, 265], [265, 266], [266, 267], [267, 268]]}
{"doc_key": "ai-dev-160", "ner": [[8, 9, "misc"], [14, 15, "algorithm"], [17, 17, "algorithm"], [21, 23, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 17, 14, 15, "named", "", false, false], [25, 25, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "information", "is", "a", "mixture", "of", "sitemaps", "and", "RSS", "feeds", ",", "created", "using", "an", "Information", "Model", "(", "IM", ")", "and", "a", "Biomedical", "Resource", "Ontology", "(", "BRO", ")", "."], "sentence-detokenized": "This information is a mixture of sitemaps and RSS feeds, created using an Information Model (IM) and a Biomedical Resource Ontology (BRO).", "token2charspan": [[0, 4], [5, 16], [17, 19], [20, 21], [22, 29], [30, 32], [33, 41], [42, 45], [46, 49], [50, 55], [55, 56], [57, 64], [65, 70], [71, 73], [74, 85], [86, 91], [92, 93], [93, 95], [95, 96], [97, 100], [101, 102], [103, 113], [114, 122], [123, 131], [132, 133], [133, 136], [136, 137], [137, 138]]}
{"doc_key": "ai-dev-161", "ner": [[2, 3, "task"], [8, 10, "algorithm"], [12, 18, "algorithm"], [25, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 12, 18, "origin", "based_on", false, false], [12, 18, 8, 10, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "latest", "text", "recognition", "is", "based", "on", "a", "recurrent", "neural", "network", "(", "long", "-", "term", "short", "-", "term", "memory", ")", "and", "does", "not", "require", "a", "language", "model", "."], "sentence-detokenized": "The latest text recognition is based on a recurrent neural network (long-term short-term memory) and does not require a language model.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 27], [28, 30], [31, 36], [37, 39], [40, 41], [42, 51], [52, 58], [59, 66], [67, 68], [68, 72], [72, 73], [73, 77], [78, 83], [83, 84], [84, 88], [89, 95], [95, 96], [97, 100], [101, 105], [106, 109], [110, 117], [118, 119], [120, 128], [129, 134], [134, 135]]}
{"doc_key": "ai-dev-162", "ner": [[3, 4, "misc"], [7, 8, "metrics"], [11, 12, "algorithm"], [16, 17, "metrics"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 3, 4, "type-of", "", false, false], [11, 12, 7, 8, "related-to", "", true, false], [16, 17, 3, 4, "type-of", "", false, false], [20, 21, 16, 17, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "most", "popular", "loss", "functions", "are", "the", "hinge", "loss", "(", "for", "linear", "SVMs", ")", "and", "the", "logarithmic", "loss", "(", "for", "logistic", "regression", ")", "."], "sentence-detokenized": "The most popular loss functions are the hinge loss (for linear SVMs) and the logarithmic loss (for logistic regression).", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 21], [22, 31], [32, 35], [36, 39], [40, 45], [46, 50], [51, 52], [52, 55], [56, 62], [63, 67], [67, 68], [69, 72], [73, 76], [77, 88], [89, 93], [94, 95], [95, 98], [99, 107], [108, 118], [118, 119], [119, 120]]}
{"doc_key": "ai-dev-163", "ner": [[0, 0, "metrics"], [9, 15, "metrics"], [17, 17, "metrics"], [20, 22, "metrics"], [24, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 9, 15, "compare", "", false, false], [0, 0, 20, 22, "compare", "", false, false], [17, 17, 9, 15, "named", "", false, false], [24, 24, 20, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "is", "designed", "to", "improve", "traditional", "methods", "such", "as", "peak", "signal", "-", "to", "-", "noise", "ratio", "(", "PSNR", ")", "and", "mean", "square", "error", "(", "MSE", ")", "."], "sentence-detokenized": "SSIM is designed to improve traditional methods such as peak signal-to-noise ratio (PSNR) and mean square error (MSE).", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 27], [28, 39], [40, 47], [48, 52], [53, 55], [56, 60], [61, 67], [67, 68], [68, 70], [70, 71], [71, 76], [77, 82], [83, 84], [84, 88], [88, 89], [90, 93], [94, 98], [99, 105], [106, 111], [112, 113], [113, 116], [116, 117], [117, 118]]}
{"doc_key": "ai-dev-164", "ner": [[10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "inspired", "later", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "His work inspired later generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 23], [24, 35], [36, 38], [39, 47], [48, 59], [60, 64], [65, 67], [68, 74], [75, 81], [81, 82], [83, 87], [88, 95], [96, 99], [100, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-dev-165", "ner": [[17, 18, "algorithm"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", ",", "pulse", "training", "is", "not", "differentiated", ",", "so", "backscatter", "-", "based", "training", "methods", "such", "as", "gradient", "descent", "can", "not", "be", "used", "."], "sentence-detokenized": "In addition, pulse training is not differentiated, so backscatter-based training methods such as gradient descent cannot be used.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 18], [19, 27], [28, 30], [31, 34], [35, 49], [49, 50], [51, 53], [54, 65], [65, 66], [66, 71], [72, 80], [81, 88], [89, 93], [94, 96], [97, 105], [106, 113], [114, 117], [117, 120], [121, 123], [124, 128], [128, 129]]}
{"doc_key": "ai-dev-166", "ner": [[8, 9, "metrics"], [15, 19, "metrics"], [18, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 15, 19, "related-to", "describes", false, false], [15, 19, 18, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "relationships", "can", "be", "easily", "represented", "using", "a", "confusion", "matrix", ",", "a", "table", "describing", "the", "accuracy", "of", "the", "classification", "model", "."], "sentence-detokenized": "These relationships can be easily represented using a confusion matrix, a table describing the accuracy of the classification model.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 26], [27, 33], [34, 45], [46, 51], [52, 53], [54, 63], [64, 70], [70, 71], [72, 73], [74, 79], [80, 90], [91, 94], [95, 103], [104, 106], [107, 110], [111, 125], [126, 131], [131, 132]]}
{"doc_key": "ai-dev-167", "ner": [[6, 14, "conference"], [12, 12, "conference"], [0, 0, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 6, 14, "named", "", false, false], [0, 0, 6, 14, "physical", "", false, false], [0, 0, 6, 14, "role", "", false, false], [0, 0, 6, 14, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "researchers", "presented", "work", "at", "the", "2018", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "conference"], "sentence-detokenized": "Google researchers presented work at the 2018 Neural Information Processing Systems (NeurIPS) conference", "token2charspan": [[0, 6], [7, 18], [19, 28], [29, 33], [34, 36], [37, 40], [41, 45], [46, 52], [53, 64], [65, 75], [76, 83], [84, 85], [85, 92], [92, 93], [94, 104]]}
{"doc_key": "ai-dev-168", "ner": [[2, 2, "university"], [6, 6, "product"], [16, 18, "misc"], [15, 15, "conference"], [25, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 16, 18, "win-defeat", "", false, false], [16, 18, 15, 15, "temporal", "", false, false], [25, 28, 15, 15, "part-of", "", false, false], [25, 28, 15, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "at", "Duke", ",", "he", "developed", "PROVERB", ",", "an", "automated", "crossword", "solver", "that", "won", "the", "AAAI", "Outstanding", "Paper", "Award", "in", "1999", "and", "participated", "in", "the", "American", "Crossword", "Puzzle", "Tournament", "."], "sentence-detokenized": "While at Duke, he developed PROVERB, an automated crossword solver that won the AAAI Outstanding Paper Award in 1999 and participated in the American Crossword Puzzle Tournament.", "token2charspan": [[0, 5], [6, 8], [9, 13], [13, 14], [15, 17], [18, 27], [28, 35], [35, 36], [37, 39], [40, 49], [50, 59], [60, 66], [67, 71], [72, 75], [76, 79], [80, 84], [85, 96], [97, 102], [103, 108], [109, 111], [112, 116], [117, 120], [121, 133], [134, 136], [137, 140], [141, 149], [150, 159], [160, 166], [167, 177], [177, 178]]}
{"doc_key": "ai-dev-169", "ner": [[5, 6, "location"], [8, 8, "location"], [16, 17, "country"], [19, 19, "country"], [21, 21, "country"], [23, 23, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 8, 8, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "company", "was", "headquartered", "in", "Rochester", "Hills", ",", "Michigan", ",", "and", "had", "10", "regional", "offices", "in", "the", "US", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "sentence-detokenized": "The company was headquartered in Rochester Hills, Michigan, and had 10 regional offices in the US, Canada, Mexico and Brazil.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 29], [30, 32], [33, 42], [43, 48], [48, 49], [50, 58], [58, 59], [60, 63], [64, 67], [68, 70], [71, 79], [80, 87], [88, 90], [91, 94], [95, 97], [97, 98], [99, 105], [105, 106], [107, 113], [114, 117], [118, 124], [124, 125]]}
{"doc_key": "ai-dev-170", "ner": [[11, 11, "product"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "joins", "a", "collection", "of", "historically", "important", "robots", "including", "the", "early", "Unimate", "and", "the", "Odetics", "Odex", "1", "."], "sentence-detokenized": "It joins a collection of historically important robots including the early Unimate and the Odetics Odex 1.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 21], [22, 24], [25, 37], [38, 47], [48, 54], [55, 64], [65, 68], [69, 74], [75, 82], [83, 86], [87, 90], [91, 98], [99, 103], [104, 105], [105, 106]]}
{"doc_key": "ai-dev-171", "ner": [[7, 8, "researcher"], [10, 10, "organisation"], [12, 13, "researcher"], [23, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 10, 10, "physical", "", false, false], [7, 8, 10, 10, "role", "", false, false], [12, 13, 10, 10, "physical", "", false, false], [12, 13, 10, 10, "role", "", false, false], [12, 13, 23, 26, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["This", "issue", "'s", "guest", "editor", "will", "be", "David", "'s", "former", "NIST", "colleague", "Judah", "Levine", ",", "who", "is", "the", "most", "recent", "recipient", "of", "the", "I.I", ".", "Rabi", "Award", "."], "sentence-detokenized": "This issue's guest editor will be David's former NIST colleague Judah Levine, who is the most recent recipient of the I.I. Rabi Award.", "token2charspan": [[0, 4], [5, 10], [10, 12], [13, 18], [19, 25], [26, 30], [31, 33], [34, 39], [39, 41], [42, 48], [49, 53], [54, 63], [64, 69], [70, 76], [76, 77], [78, 81], [82, 84], [85, 88], [89, 93], [94, 100], [101, 110], [111, 113], [114, 117], [118, 121], [121, 122], [123, 127], [128, 133], [133, 134]]}
{"doc_key": "ai-dev-172", "ner": [[13, 18, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "can", "be", "arranged", "in", "a", "2", "\u00d7", "2", "contingency", "table", "(", "a", "confusion", "matrix", ")", ",", "with", "the", "vertical", "axis", "usually", "containing", "the", "test", "result", "and", "the", "horizontal", "axis", "the", "actual", "condition", "."], "sentence-detokenized": "These can be arranged in a 2 \u00d7 2 contingency table (a confusion matrix), with the vertical axis usually containing the test result and the horizontal axis the actual condition.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 21], [22, 24], [25, 26], [27, 28], [29, 30], [31, 32], [33, 44], [45, 50], [51, 52], [52, 53], [54, 63], [64, 70], [70, 71], [71, 72], [73, 77], [78, 81], [82, 90], [91, 95], [96, 103], [104, 114], [115, 118], [119, 123], [124, 130], [131, 134], [135, 138], [139, 149], [150, 154], [155, 158], [159, 165], [166, 175], [175, 176]]}
{"doc_key": "ai-dev-173", "ner": [[0, 5, "product"], [7, 7, "product"], [9, 9, "product"], [11, 12, "product"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 7, 7, "part-of", "", false, false], [0, 5, 9, 9, "part-of", "", false, false], [0, 5, 11, 12, "part-of", "", false, false], [0, 5, 14, 16, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["\"", "The", "Apple", "iOS", "operating", "system", "for", "iPhone", ",", "iPad", "and", "iPod", "Touch", "uses", "VoiceOver", "speech", "synthesis", "access", "."], "sentence-detokenized": "\"The Apple iOS operating system for iPhone, iPad and iPod Touch uses VoiceOver speech synthesis access.", "token2charspan": [[0, 1], [1, 4], [5, 10], [11, 14], [15, 24], [25, 31], [32, 35], [36, 42], [42, 43], [44, 48], [49, 52], [53, 57], [58, 63], [64, 68], [69, 78], [79, 85], [86, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-dev-174", "ner": [[7, 9, "conference"], [14, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "the", "best", "system", "in", "MUC", "-", "7", "scored", "93.39", "%", "on", "the", "F-matrix", ",", "while", "the", "human", "annotators", "scored", "97.6", "%", "and", "96.95", "%", "."], "sentence-detokenized": "For example, the best system in MUC-7 scored 93.39% on the F-matrix, while the human annotators scored 97.6% and 96.95%.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 31], [32, 35], [35, 36], [36, 37], [38, 44], [45, 50], [50, 51], [52, 54], [55, 58], [59, 67], [67, 68], [69, 74], [75, 78], [79, 84], [85, 95], [96, 102], [103, 107], [107, 108], [109, 112], [113, 118], [118, 119], [119, 120]]}
{"doc_key": "ai-dev-175", "ner": [[11, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 11, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "done", "using", "standard", "neural", "network", "training", "algorithms", "such", "as", "stochastic", "gradient", "descent", "with", "backscattering", "."], "sentence-detokenized": "This is done using standard neural network training algorithms such as stochastic gradient descent with backscattering.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 18], [19, 27], [28, 34], [35, 42], [43, 51], [52, 62], [63, 67], [68, 70], [71, 81], [82, 90], [91, 98], [99, 103], [104, 118], [118, 119]]}
{"doc_key": "ai-dev-176", "ner": [[0, 2, "organisation"], [26, 26, "country"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 26, 26, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["\"", "Rotten", "Tomatoes", "is", "among", "the", "top", "1000", "websites", ",", "and", "according", "to", "Alexa", "'s", "website", "rankings", ",", "ranks", "around", "400th", "worldwide", "and", "150th", "in", "the", "US", "alone", "."], "sentence-detokenized": "\"Rotten Tomatoes is among the top 1000 websites, and according to Alexa's website rankings, ranks around 400th worldwide and 150th in the US alone.", "token2charspan": [[0, 1], [1, 7], [8, 16], [17, 19], [20, 25], [26, 29], [30, 33], [34, 38], [39, 47], [47, 48], [49, 52], [53, 62], [63, 65], [66, 71], [71, 73], [74, 81], [82, 90], [90, 91], [92, 97], [98, 104], [105, 110], [111, 120], [121, 124], [125, 130], [131, 133], [134, 137], [138, 140], [141, 146], [146, 147]]}
{"doc_key": "ai-dev-177", "ner": [[15, 18, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "general", ",", "all", "learning", "shows", "a", "gradual", "change", "over", "time", ",", "but", "describes", "a", "sigmoid", "function", "that", "has", "a", "different", "shape", "depending", "on", "the", "time", "scale", "of", "observation", "."], "sentence-detokenized": "In general, all learning shows a gradual change over time, but describes a sigmoid function that has a different shape depending on the time scale of observation.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 24], [25, 30], [31, 32], [33, 40], [41, 47], [48, 52], [53, 57], [57, 58], [59, 62], [63, 72], [73, 74], [75, 82], [83, 91], [92, 96], [97, 100], [101, 102], [103, 112], [113, 118], [119, 128], [129, 131], [132, 135], [136, 140], [141, 146], [147, 149], [150, 161], [161, 162]]}
{"doc_key": "ai-dev-178", "ner": [[0, 1, "metrics"], [5, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 5, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["SSD", "is", "also", "known", "as", "root", "mean", "square", "error", "."], "sentence-detokenized": "SSD is also known as root mean square error.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 17], [18, 20], [21, 25], [26, 30], [31, 37], [38, 43], [43, 44]]}
{"doc_key": "ai-dev-179", "ner": [[0, 2, "algorithm"], [4, 5, "algorithm"], [8, 10, "algorithm"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 22, 23, "related-to", "can_be_related_to", true, false], [4, 5, 22, 23, "related-to", "can_be_related_to", true, false], [8, 10, 22, 23, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", ",", "neural", "networks", "or", "a", "naive", "Bayesian", "classifier", "can", "be", "used", "in", "combination", "with", "model", "quality", "indicators", "such", "as", "balanced", "accuracy", "."], "sentence-detokenized": "Decision tree learning, neural networks or a naive Bayesian classifier can be used in combination with model quality indicators such as balanced accuracy.", "token2charspan": [[0, 8], [9, 13], [14, 22], [22, 23], [24, 30], [31, 39], [40, 42], [43, 44], [45, 50], [51, 59], [60, 70], [71, 74], [75, 77], [78, 82], [83, 85], [86, 97], [98, 102], [103, 108], [109, 116], [117, 127], [128, 132], [133, 135], [136, 144], [145, 153], [153, 154]]}
{"doc_key": "ai-dev-180", "ner": [[6, 17, "conference"], [26, 30, "conference"], [31, 33, "misc"], [39, 41, "product"], [48, 51, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[31, 33, 26, 30, "origin", "", false, false], [31, 33, 26, 30, "temporal", "", false, false], [39, 41, 31, 33, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "is", "a", "past", "president", "of", "the", "ACL", "(", "1979", ")", "and", "the", "first", "member", "of", "the", "ACL", "(", "2011", ")", ",", "a", "co-recipient", "of", "the", "1992", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "for", "his", "contribution", "to", "the", "Interlisp", "programming", "system", ",", "and", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "He is a past president of the ACL (1979) and the first member of the ACL (2011), a co-recipient of the 1992 Association for Computing Machinery Software Systems Award for his contribution to the Interlisp programming system, and a member of the Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 22], [23, 25], [26, 29], [30, 33], [34, 35], [35, 39], [39, 40], [41, 44], [45, 48], [49, 54], [55, 61], [62, 64], [65, 68], [69, 72], [73, 74], [74, 78], [78, 79], [79, 80], [81, 82], [83, 95], [96, 98], [99, 102], [103, 107], [108, 119], [120, 123], [124, 133], [134, 143], [144, 152], [153, 160], [161, 166], [167, 170], [171, 174], [175, 187], [188, 190], [191, 194], [195, 204], [205, 216], [217, 223], [223, 224], [225, 228], [229, 230], [231, 237], [238, 240], [241, 244], [245, 256], [257, 260], [261, 270], [271, 280], [280, 281]]}
{"doc_key": "ai-dev-181", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 9, "researcher"], [22, 26, "field"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[2, 3, 22, 26, "related-to", "", false, false], [5, 6, 22, 26, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "is", "considered", "one", "of", "the", "three", "people", "who", "contributed", "most", "to", "the", "advances", "in", "deep", "learning", "in", "the", "1990s", "and", "1980s", "."], "sentence-detokenized": "Along with Geoffrey Hinton and Yann LeCun, Bengio is considered one of the three people who contributed most to the advances in deep learning in the 1990s and 1980s.", "token2charspan": [[0, 5], [6, 10], [11, 19], [20, 26], [27, 30], [31, 35], [36, 41], [41, 42], [43, 49], [50, 52], [53, 63], [64, 67], [68, 70], [71, 74], [75, 80], [81, 87], [88, 91], [92, 103], [104, 108], [109, 111], [112, 115], [116, 124], [125, 127], [128, 132], [133, 141], [142, 144], [145, 148], [149, 154], [155, 158], [159, 164], [164, 165]]}
{"doc_key": "ai-dev-182", "ner": [[0, 2, "field"], [4, 5, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "information", "theory", "and", "computer", "science", ",", "a", "code", "is", "usually", "considered", "to", "be", "an", "algorithm", "that", "unambiguously", "represents", "the", "characters", "of", "a", "given", "source", "alphabet", "in", "encoded", "strings", ",", "which", "may", "be", "from", "another", "target", "alphabet", "."], "sentence-detokenized": "In information theory and computer science, a code is usually considered to be an algorithm that unambiguously represents the characters of a given source alphabet in encoded strings, which may be from another target alphabet.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 45], [46, 50], [51, 53], [54, 61], [62, 72], [73, 75], [76, 78], [79, 81], [82, 91], [92, 96], [97, 110], [111, 121], [122, 125], [126, 136], [137, 139], [140, 141], [142, 147], [148, 154], [155, 163], [164, 166], [167, 174], [175, 182], [182, 183], [184, 189], [190, 193], [194, 196], [197, 201], [202, 209], [210, 216], [217, 225], [225, 226]]}
{"doc_key": "ai-dev-183", "ner": [[8, 9, "algorithm"], [14, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 17, 8, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "relatively", "simple", "non", "-linear", "function", ",", "the", "sigma", "function", ",", "such", "as", "the", "logistic", "function", ",", "also", "has", "an", "easy", "-", "to", "-", "compute", "derivative", "that", "can", "be", "important", "for", "calculating", "updates", "to", "network", "weights", "."], "sentence-detokenized": "A relatively simple non-linear function, the sigma function, such as the logistic function, also has an easy-to-compute derivative that can be important for calculating updates to network weights.", "token2charspan": [[0, 1], [2, 12], [13, 19], [20, 23], [23, 30], [31, 39], [39, 40], [41, 44], [45, 50], [51, 59], [59, 60], [61, 65], [66, 68], [69, 72], [73, 81], [82, 90], [90, 91], [92, 96], [97, 100], [101, 103], [104, 108], [108, 109], [109, 111], [111, 112], [112, 119], [120, 130], [131, 135], [136, 139], [140, 142], [143, 152], [153, 156], [157, 168], [169, 176], [177, 179], [180, 187], [188, 195], [195, 196]]}
{"doc_key": "ai-dev-184", "ner": [[0, 0, "person"], [6, 6, "location"], [8, 8, "location"], [10, 12, "country"], [15, 15, "country"], [18, 20, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 6, "physical", "", false, false], [6, 6, 8, 8, "physical", "", false, false], [8, 8, 10, 12, "physical", "", false, false], [8, 8, 15, 15, "physical", "", false, false], [8, 8, 18, 20, "physical", "", false, false], [15, 15, 10, 12, "origin", "", false, false], [18, 20, 15, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "was", "born", "in", "1887", "in", "Hronov", ",", "Bohemia", "(", "Austria", "-", "Hungary", ",", "later", "Czechoslovakia", ",", "now", "the", "Czech", "Republic", ")", "."], "sentence-detokenized": "\u010capek was born in 1887 in Hronov, Bohemia (Austria-Hungary, later Czechoslovakia, now the Czech Republic).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 41], [42, 43], [43, 50], [50, 51], [51, 58], [58, 59], [60, 65], [66, 80], [80, 81], [82, 85], [86, 89], [90, 95], [96, 104], [104, 105], [105, 106]]}
{"doc_key": "ai-dev-185", "ner": [[5, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "specialised", "software", "can", "map", "RSS", "feeds", "."], "sentence-detokenized": "Some specialised software can map RSS feeds.", "token2charspan": [[0, 4], [5, 16], [17, 25], [26, 29], [30, 33], [34, 37], [38, 43], [43, 44]]}
{"doc_key": "ai-dev-186", "ner": [[5, 6, "task"], [8, 11, "task"], [13, 13, "task"], [16, 16, "task"], [18, 20, "task"], [27, 28, "task"], [30, 32, "task"], [36, 39, "task"], [40, 42, "product"], [44, 45, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[5, 6, 8, 11, "related-to", "", true, false], [5, 6, 13, 13, "related-to", "", true, false], [5, 6, 16, 16, "related-to", "", true, false], [30, 32, 27, 28, "usage", "", true, false], [40, 42, 36, 39, "type-of", "", false, false], [44, 45, 36, 39, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Aspects", "of", "ontology", "editors", ":", "visual", "navigation", "capabilities", "in", "the", "knowledge", "model", ",", "inference", "engines", "and", "extraction", ";", "support", "for", "modules", ";", "import", "and", "export", "of", "foreign", "knowledge", "representation", "languages", "for", "ontology", "matching", ";", "support", "for", "meta", "-ontologies", "such", "as", "OWL", "-", "S", ",", "Dublin", "Core", "etc", "."], "sentence-detokenized": "Aspects of ontology editors: visual navigation capabilities in the knowledge model, inference engines and extraction; support for modules; import and export of foreign knowledge representation languages for ontology matching; support for meta-ontologies such as OWL-S, Dublin Core etc.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 27], [27, 28], [29, 35], [36, 46], [47, 59], [60, 62], [63, 66], [67, 76], [77, 82], [82, 83], [84, 93], [94, 101], [102, 105], [106, 116], [116, 117], [118, 125], [126, 129], [130, 137], [137, 138], [139, 145], [146, 149], [150, 156], [157, 159], [160, 167], [168, 177], [178, 192], [193, 202], [203, 206], [207, 215], [216, 224], [224, 225], [226, 233], [234, 237], [238, 242], [242, 253], [254, 258], [259, 261], [262, 265], [265, 266], [266, 267], [267, 268], [269, 275], [276, 280], [281, 284], [284, 285]]}
{"doc_key": "ai-dev-187", "ner": [[0, 1, "organisation"], [6, 11, "misc"], [13, 15, "task"], [19, 20, "field"], [22, 22, "misc"], [24, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 11, 0, 1, "origin", "", false, false], [13, 15, 6, 11, "part-of", "", false, false], [19, 20, 6, 11, "part-of", "", false, false], [22, 22, 19, 20, "type-of", "", false, false], [24, 28, 19, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "FBI", "has", "also", "launched", "a", "Next", "Generation", "Identification", "Programme", ",", "which", "includes", "facial", "recognition", "as", "well", "as", "traditional", "biometrics", "such", "as", "fingerprints", "and", "iris", "scans", "that", "can", "be", "pulled", "from", "criminal", "and", "civil", "databases", "."], "sentence-detokenized": "The FBI has also launched a Next Generation Identification Programme, which includes facial recognition as well as traditional biometrics such as fingerprints and iris scans that can be pulled from criminal and civil databases.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 25], [26, 27], [28, 32], [33, 43], [44, 58], [59, 68], [68, 69], [70, 75], [76, 84], [85, 91], [92, 103], [104, 106], [107, 111], [112, 114], [115, 126], [127, 137], [138, 142], [143, 145], [146, 158], [159, 162], [163, 167], [168, 173], [174, 178], [179, 182], [183, 185], [186, 192], [193, 197], [198, 206], [207, 210], [211, 216], [217, 226], [226, 227]]}
{"doc_key": "ai-dev-188", "ner": [[5, 6, "person"], [8, 9, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "2016", "season", ",", "Samantha", "Ponder", "replaced", "Molly", "McGrath", "as", "host", "."], "sentence-detokenized": "In the 2016 season, Samantha Ponder replaced Molly McGrath as host.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [18, 19], [20, 28], [29, 35], [36, 44], [45, 50], [51, 58], [59, 61], [62, 66], [66, 67]]}
{"doc_key": "ai-dev-189", "ner": [[3, 9, "algorithm"], [18, 22, "misc"], [24, 24, "misc"], [26, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "a", "counter", "-", "search", "algorithm", "commonly", "used", "for", "machine", "search", "in", "two", "-", "player", "games", "(", "tic", "-", "tac", "-", "toe", ",", "chess", ",", "Go", ",", "etc", ".", ")"], "sentence-detokenized": "It is a counter-search algorithm commonly used for machine search in two-player games (tic-tac-toe, chess, Go, etc.)", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 15], [15, 16], [16, 22], [23, 32], [33, 41], [42, 46], [47, 50], [51, 58], [59, 65], [66, 68], [69, 72], [72, 73], [73, 79], [80, 85], [86, 87], [87, 90], [90, 91], [91, 94], [94, 95], [95, 98], [98, 99], [100, 105], [105, 106], [107, 109], [109, 110], [111, 114], [114, 115], [115, 116]]}
{"doc_key": "ai-dev-190", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "covers", "the", "fields", "of", "computer", "vision", "or", "machine", "vision", "and", "medical", "imaging", "and", "makes", "extensive", "use", "of", "pattern", "recognition", ",", "digital", "geometry", "and", "signal", "processing", "."], "sentence-detokenized": "It covers the fields of computer vision or machine vision and medical imaging and makes extensive use of pattern recognition, digital geometry and signal processing.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 20], [21, 23], [24, 32], [33, 39], [40, 42], [43, 50], [51, 57], [58, 61], [62, 69], [70, 77], [78, 81], [82, 87], [88, 97], [98, 101], [102, 104], [105, 112], [113, 124], [124, 125], [126, 133], [134, 142], [143, 146], [147, 153], [154, 164], [164, 165]]}
{"doc_key": "ai-dev-191", "ner": [[0, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "in", "a", "facial", "recognition", "system", ",", "the", "input", "would", "be", "a", "photo", "of", "a", "person", "'s", "face", "and", "the", "output", "would", "be", "the", "person", "'s", "name", "."], "sentence-detokenized": "For example, in a facial recognition system, the input would be a photo of a person's face and the output would be the person's name.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 17], [18, 24], [25, 36], [37, 43], [43, 44], [45, 48], [49, 54], [55, 60], [61, 63], [64, 65], [66, 71], [72, 74], [75, 76], [77, 83], [83, 85], [86, 90], [91, 94], [95, 98], [99, 105], [106, 111], [112, 114], [115, 118], [119, 125], [125, 127], [128, 132], [132, 133]]}
{"doc_key": "ai-dev-192", "ner": [[0, 2, "organisation"], [5, 6, "product"], [10, 12, "product"], [24, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 6, "artifact", "", false, false], [5, 6, 10, 12, "part-of", "", false, false], [10, 12, 5, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["\"", "Apple", "Inc", "has", "introduced", "Face", "ID", "on", "its", "flagship", "i", "Phone", "X", "as", "a", "biometric", "authentication", "system", "to", "replace", "the", "fingerprint", "-", "based", "Touch", "ID", "."], "sentence-detokenized": "\"Apple Inc has introduced Face ID on its flagship iPhone X as a biometric authentication system to replace the fingerprint-based Touch ID.", "token2charspan": [[0, 1], [1, 6], [7, 10], [11, 14], [15, 25], [26, 30], [31, 33], [34, 36], [37, 40], [41, 49], [50, 51], [51, 56], [57, 58], [59, 61], [62, 63], [64, 73], [74, 88], [89, 95], [96, 98], [99, 106], [107, 110], [111, 122], [122, 123], [123, 128], [129, 134], [135, 137], [137, 138]]}
{"doc_key": "ai-dev-193", "ner": [[2, 5, "metrics"], [8, 12, "metrics"], [25, 26, "metrics"], [29, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Or", "combine", "the", "F", "-", "measure", "with", "the", "R-", "squared", "estimated", "in", "the", "case", "of", "the", "raw", "model", "output", "and", "the", "target", ";", "or", "the", "cost-benefit", "matrix", "with", "the", "correlation", "coefficient", ";", "etc", "."], "sentence-detokenized": "Or combine the F-measure with the R-squared estimated in the case of the raw model output and the target; or the cost-benefit matrix with the correlation coefficient; etc.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 16], [16, 17], [17, 24], [25, 29], [30, 33], [34, 36], [36, 43], [44, 53], [54, 56], [57, 60], [61, 65], [66, 68], [69, 72], [73, 76], [77, 82], [83, 89], [90, 93], [94, 97], [98, 104], [104, 105], [106, 108], [109, 112], [113, 125], [126, 132], [133, 137], [138, 141], [142, 153], [154, 165], [165, 166], [167, 170], [170, 171]]}
{"doc_key": "ai-dev-194", "ner": [[7, 13, "conference"], [16, 18, "location"], [20, 20, "location"], [22, 25, "location"], [26, 27, "location"], [29, 29, "country"], [35, 38, "location"], [42, 46, "location"], [41, 41, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 13, 16, 18, "physical", "", false, false], [7, 13, 22, 25, "physical", "", false, false], [7, 13, 35, 38, "physical", "", false, false], [7, 13, 42, 46, "physical", "", false, false], [16, 18, 20, 20, "physical", "", false, false], [22, 25, 26, 27, "physical", "", false, false], [26, 27, 29, 29, "physical", "", false, false], [35, 38, 41, 41, "physical", "", false, false], [42, 46, 41, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Over", "the", "last", "15", "years", ",", "the", "Campus", "Party", "in", "Spain", "has", "been", "held", "at", "the", "Colegio", "Miguel", "Hern\u00e1ndez", ",", "Ceulaj", "and", "Benalm\u00e1dena", "Municipal", "Sports", "Arena", "in", "Malaga", ",", "Spain", ";", "as", "well", "as", "at", "the", "Valencia", "County", "Fair", "and", "the", "Valencia", "City", "of", "Arts", "and", "Science", "."], "sentence-detokenized": "Over the last 15 years, the Campus Party in Spain has been held at the Colegio Miguel Hern\u00e1ndez, Ceulaj and Benalm\u00e1dena Municipal Sports Arena in Malaga, Spain; as well as at the Valencia County Fair and the Valencia City of Arts and Science.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 22], [22, 23], [24, 27], [28, 34], [35, 40], [41, 43], [44, 49], [50, 53], [54, 58], [59, 63], [64, 66], [67, 70], [71, 78], [79, 85], [86, 95], [95, 96], [97, 103], [104, 107], [108, 119], [120, 129], [130, 136], [137, 142], [143, 145], [146, 152], [152, 153], [154, 159], [159, 160], [161, 163], [164, 168], [169, 171], [172, 174], [175, 178], [179, 187], [188, 194], [195, 199], [200, 203], [204, 207], [208, 216], [217, 221], [222, 224], [225, 229], [230, 233], [234, 241], [241, 242]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [12, 12, "programlang"], [15, 15, "product"], [17, 17, "product"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 0, 0, "general-affiliation", "", false, false], [15, 15, 12, 12, "part-of", "", false, false], [17, 17, 12, 12, "part-of", "", false, false], [21, 21, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Gnuplot", "can", "be", "used", "in", "a", "variety", "of", "programming", "languages", ",", "including", "Perl", "(", "via", "PDL", "and", "CPAN", "packages", ")", ",", "Python", "(", "via", ")", "."], "sentence-detokenized": "Gnuplot can be used in a variety of programming languages, including Perl (via PDL and CPAN packages), Python (via).", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 19], [20, 22], [23, 24], [25, 32], [33, 35], [36, 47], [48, 57], [57, 58], [59, 68], [69, 73], [74, 75], [75, 78], [79, 82], [83, 86], [87, 91], [92, 100], [100, 101], [101, 102], [103, 109], [110, 111], [111, 114], [114, 115], [115, 116]]}
{"doc_key": "ai-dev-196", "ner": [[3, 5, "product"], [19, 19, "conference"], [21, 21, "conference"], [35, 35, "conference"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 3, 5, "topic", "", false, false], [21, 21, 3, 5, "topic", "", false, false], [35, 35, 3, 5, "topic", "", false, false], [37, 37, 3, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "field", "of", "speech", "dialogue", "systems", "is", "quite", "broad", "and", "includes", "research", "(", "presented", "at", "scientific", "conferences", "such", "as", "SIGdial", "and", "Interspeech", ")", "and", "a", "large", "industrial", "sector", "(", "with", "its", "own", "meetings", ",", "e.g.", "SpeechTek", "and", "AVIOS", ")", "."], "sentence-detokenized": "The field of speech dialogue systems is quite broad and includes research (presented at scientific conferences such as SIGdial and Interspeech) and a large industrial sector (with its own meetings, e.g. SpeechTek and AVIOS).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 28], [29, 36], [37, 39], [40, 45], [46, 51], [52, 55], [56, 64], [65, 73], [74, 75], [75, 84], [85, 87], [88, 98], [99, 110], [111, 115], [116, 118], [119, 126], [127, 130], [131, 142], [142, 143], [144, 147], [148, 149], [150, 155], [156, 166], [167, 173], [174, 175], [175, 179], [180, 183], [184, 187], [188, 196], [196, 197], [198, 202], [203, 212], [213, 216], [217, 222], [222, 223], [223, 224]]}
{"doc_key": "ai-dev-197", "ner": [[0, 2, "field"], [6, 7, "task"], [9, 11, "task"], [13, 15, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 0, 2, "part-of", "task_part_of_field", false, false], [9, 11, 0, 2, "part-of", "task_part_of_field", false, false], [13, 15, 0, 2, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Natural", "language", "processing", "tasks", "often", "involve", "speech", "recognition", ",", "natural", "language", "understanding", "and", "natural", "language", "production", "."], "sentence-detokenized": "Natural language processing tasks often involve speech recognition, natural language understanding and natural language production.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 33], [34, 39], [40, 47], [48, 54], [55, 66], [66, 67], [68, 75], [76, 84], [85, 98], [99, 102], [103, 110], [111, 119], [120, 130], [130, 131]]}
{"doc_key": "ai-dev-198", "ner": [[5, 5, "product"], [6, 10, "product"], [34, 35, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 6, 10, "part-of", "", false, false], [5, 5, 34, 35, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "such", "as", "Siri", "for", "the", "iOS", "operating", "system", ",", "follow", "a", "similar", "pattern", "recognition", "approach", "to", "text", "-", "based", "systems", ",", "but", "in", "the", "former", ",", "user", "input", "is", "provided", "through", "speech", "recognition", "."], "sentence-detokenized": "These systems, such as Siri for the iOS operating system, follow a similar pattern recognition approach to text-based systems, but in the former, user input is provided through speech recognition.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 27], [28, 31], [32, 35], [36, 39], [40, 49], [50, 56], [56, 57], [58, 64], [65, 66], [67, 74], [75, 82], [83, 94], [95, 103], [104, 106], [107, 111], [111, 112], [112, 117], [118, 125], [125, 126], [127, 130], [131, 133], [134, 137], [138, 144], [144, 145], [146, 150], [151, 156], [157, 159], [160, 168], [169, 176], [177, 183], [184, 195], [195, 196]]}
{"doc_key": "ai-dev-199", "ner": [[0, 8, "algorithm"], [17, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 8, 17, 18, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["More", "exotic", "goodness", "-", "of", "-", "fit", "functions", "that", "investigate", "model", "detail", "include", "the", "area", "under", "the", "ROC", "curve", "and", "the", "rank", "measure", "."], "sentence-detokenized": "More exotic goodness-of-fit functions that investigate model detail include the area under the ROC curve and the rank measure.", "token2charspan": [[0, 4], [5, 11], [12, 20], [20, 21], [21, 23], [23, 24], [24, 27], [28, 37], [38, 42], [43, 54], [55, 60], [61, 67], [68, 75], [76, 79], [80, 84], [85, 90], [91, 94], [95, 98], [99, 104], [105, 108], [109, 112], [113, 117], [118, 125], [125, 126]]}
{"doc_key": "ai-dev-200", "ner": [[3, 4, "product"], [17, 20, "researcher"], [12, 15, "product"], [25, 28, "organisation"], [30, 33, "organisation"], [39, 43, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 17, 20, "origin", "", false, false], [17, 20, 25, 28, "role", "", false, false], [12, 15, 17, 20, "origin", "", false, false], [30, 33, 25, 28, "named", "", false, false], [39, 43, 25, 28, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "term", "\"", "Semantic", "Web", "\"", "was", "coined", "by", "the", "inventor", "of", "the", "World", "Wide", "Web", ",", "Tim", "Berners", "-", "Lee", ",", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "oversees", "the", "development", "of", "proposed", "standards", "for", "the", "Semantic", "Web", "."], "sentence-detokenized": "The term \"Semantic Web\" was coined by the inventor of the World Wide Web, Tim Berners-Lee, director of the World Wide Web Consortium (W3C), which oversees the development of proposed standards for the Semantic Web.", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 18], [19, 22], [22, 23], [24, 27], [28, 34], [35, 37], [38, 41], [42, 50], [51, 53], [54, 57], [58, 63], [64, 68], [69, 72], [72, 73], [74, 77], [78, 85], [85, 86], [86, 89], [89, 90], [91, 99], [100, 102], [103, 106], [107, 112], [113, 117], [118, 121], [122, 132], [133, 134], [134, 137], [137, 138], [138, 139], [140, 145], [146, 154], [155, 158], [159, 170], [171, 173], [174, 182], [183, 192], [193, 196], [197, 200], [201, 209], [210, 213], [213, 214]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [6, 6, "task"], [13, 14, "product"], [16, 20, "product"], [22, 22, "product"], [25, 30, "product"], [33, 34, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 13, 14, "opposite", "", false, false], [0, 1, 16, 20, "opposite", "", false, false], [0, 1, 25, 30, "opposite", "", false, false], [0, 1, 33, 34, "part-of", "", false, false], [6, 6, 0, 1, "named", "", false, false], [22, 22, 16, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Machine", "translation", ",", "sometimes", "abbreviated", "as", "MT", "(", "not", "to", "be", "confused", "with", "machine", "translation", ",", "machine", "-", "assisted", "human", "translation", "(", "MAHT", ")", "or", "interactive", "translation", ")", ",", "is", "a", "branch", "of", "computational", "linguistics", "that", "deals", "with", "the", "use", "of", "software", "to", "translate", "text", "or", "language", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Machine translation, sometimes abbreviated as MT (not to be confused with machine translation, machine-assisted human translation (MAHT) or interactive translation), is a branch of computational linguistics that deals with the use of software to translate text or language from one language to another.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 30], [31, 42], [43, 45], [46, 48], [49, 50], [50, 53], [54, 56], [57, 59], [60, 68], [69, 73], [74, 81], [82, 93], [93, 94], [95, 102], [102, 103], [103, 111], [112, 117], [118, 129], [130, 131], [131, 135], [135, 136], [137, 139], [140, 151], [152, 163], [163, 164], [164, 165], [166, 168], [169, 170], [171, 177], [178, 180], [181, 194], [195, 206], [207, 211], [212, 217], [218, 222], [223, 226], [227, 230], [231, 233], [234, 242], [243, 245], [246, 255], [256, 260], [261, 263], [264, 272], [273, 277], [278, 281], [282, 290], [291, 293], [294, 301], [301, 302]]}
{"doc_key": "ai-dev-202", "ner": [[1, 4, "product"], [8, 11, "university"], [14, 15, "researcher"], [17, 18, "researcher"], [41, 43, "location"], [44, 45, "location"], [49, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 4, 14, 15, "artifact", "", false, false], [1, 4, 17, 18, "artifact", "", false, false], [14, 15, 8, 11, "physical", "", false, false], [14, 15, 8, 11, "role", "", false, false], [17, 18, 8, 11, "physical", "", false, false], [17, 18, 8, 11, "role", "", false, false], [41, 43, 44, 45, "physical", "", false, false], [49, 52, 41, 43, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Early", "interlingual", "machine", "translation", "systems", "were", "also", "developed", "at", "Stanford", "in", "the", "1970s", "by", "Roger", "Schank", "and", "Yorick", "Wilks", ";", "the", "former", "became", "the", "basis", "for", "a", "commercial", "money", "transfer", "system", ",", "and", "the", "code", "for", "the", "latter", "is", "preserved", "at", "the", "Computer", "Museum", "in", "Boston", "as", "the", "first", "interlingual", "machine", "translation", "system", "."], "sentence-detokenized": "Early interlingual machine translation systems were also developed at Stanford in the 1970s by Roger Schank and Yorick Wilks; the former became the basis for a commercial money transfer system, and the code for the latter is preserved at the Computer Museum in Boston as the first interlingual machine translation system.", "token2charspan": [[0, 5], [6, 18], [19, 26], [27, 38], [39, 46], [47, 51], [52, 56], [57, 66], [67, 69], [70, 78], [79, 81], [82, 85], [86, 91], [92, 94], [95, 100], [101, 107], [108, 111], [112, 118], [119, 124], [124, 125], [126, 129], [130, 136], [137, 143], [144, 147], [148, 153], [154, 157], [158, 159], [160, 170], [171, 176], [177, 185], [186, 192], [192, 193], [194, 197], [198, 201], [202, 206], [207, 210], [211, 214], [215, 221], [222, 224], [225, 234], [235, 237], [238, 241], [242, 250], [251, 257], [258, 260], [261, 267], [268, 270], [271, 274], [275, 280], [281, 293], [294, 301], [302, 313], [314, 320], [320, 321]]}
{"doc_key": "ai-dev-203", "ner": [[0, 0, "researcher"], [6, 10, "conference"], [12, 13, "conference"], [20, 25, "conference"], [27, 28, "conference"], [34, 39, "organisation"], [45, 45, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 6, 10, "role", "", false, false], [0, 0, 20, 25, "role", "", false, false], [0, 0, 34, 39, "role", "", false, false], [0, 0, 45, 45, "role", "", false, false], [12, 13, 6, 10, "named", "", false, false], [27, 28, 20, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sycara", "was", "Programme", "Chair", "of", "the", "Second", "International", "Semantic", "Web", "Conference", "(", "ISWC", "2003", ")", ";", "General", "Chair", "of", "the", "Second", "International", "Conference", "on", "Autonomous", "Agents", "(", "Agents", "98", ")", ";", "Chair", "of", "the", "Steering", "Committee", "of", "the", "Agents", "Conference", "(", "1999-2001", ")", ";", "and", "AAAI", "Fellowship", "Chair", "(", "1993-1999", ")", ";"], "sentence-detokenized": "Sycara was Programme Chair of the Second International Semantic Web Conference (ISWC 2003); General Chair of the Second International Conference on Autonomous Agents (Agents 98); Chair of the Steering Committee of the Agents Conference (1999-2001); and AAAI Fellowship Chair (1993-1999);", "token2charspan": [[0, 6], [7, 10], [11, 20], [21, 26], [27, 29], [30, 33], [34, 40], [41, 54], [55, 63], [64, 67], [68, 78], [79, 80], [80, 84], [85, 89], [89, 90], [90, 91], [92, 99], [100, 105], [106, 108], [109, 112], [113, 119], [120, 133], [134, 144], [145, 147], [148, 158], [159, 165], [166, 167], [167, 173], [174, 176], [176, 177], [177, 178], [179, 184], [185, 187], [188, 191], [192, 200], [201, 210], [211, 213], [214, 217], [218, 224], [225, 235], [236, 237], [237, 246], [246, 247], [247, 248], [249, 252], [253, 257], [258, 268], [269, 274], [275, 276], [276, 285], [285, 286], [286, 287]]}
{"doc_key": "ai-dev-204", "ner": [[11, 11, "conference"], [13, 16, "conference"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 11, 11, "named", "", false, false], [18, 20, 11, 11, "part-of", "", false, false], [18, 20, 11, 11, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2016", ",", "she", "was", "selected", "as", "a", "recipient", "of", "the", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "Lifetime", "Achievement", "Award", "."], "sentence-detokenized": "In 2016, she was selected as a recipient of the ACL (Association for Computational Linguistics) Lifetime Achievement Award.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 25], [26, 28], [29, 30], [31, 40], [41, 43], [44, 47], [48, 51], [52, 53], [53, 64], [65, 68], [69, 82], [83, 94], [94, 95], [96, 104], [105, 116], [117, 122], [122, 123]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P.", "Frasconi", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 30], [31, 39], [40, 43], [44, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-206", "ner": [[0, 5, "product"], [9, 10, "misc"], [12, 14, "programlang"], [18, 23, "product"], [34, 34, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 12, 14, "usage", "", false, false], [12, 14, 9, 10, "type-of", "", false, false], [12, 14, 18, 23, "related-to", "", false, false], [34, 34, 0, 5, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["For", "example", ",", "\"", "A.L.I.C.E", ".", "\"", "uses", "a", "markup", "language", "called", "AIML", ",", "which", "is", "specific", "to", "the", "dialogue", "system", "and", "has", "been", "adopted", "by", "various", "other", "developers", "of", "so", "-", "called", "\"", "Alicebots", "\"", "."], "sentence-detokenized": "For example, \"A.L.I.C.E.\" uses a markup language called AIML, which is specific to the dialogue system and has been adopted by various other developers of so-called \"Alicebots\".", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 14], [14, 23], [23, 24], [24, 25], [26, 30], [31, 32], [33, 39], [40, 48], [49, 55], [56, 60], [60, 61], [62, 67], [68, 70], [71, 79], [80, 82], [83, 86], [87, 95], [96, 102], [103, 106], [107, 110], [111, 115], [116, 123], [124, 126], [127, 134], [135, 140], [141, 151], [152, 154], [155, 157], [157, 158], [158, 164], [165, 166], [166, 175], [175, 176], [176, 177]]}
{"doc_key": "ai-dev-207", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2000", ",", "she", "was", "elected", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2000, she was elected a member of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 24], [25, 26], [27, 33], [34, 36], [37, 40], [41, 52], [53, 56], [57, 60], [61, 72], [73, 75], [76, 86], [87, 99], [99, 100]]}
{"doc_key": "ai-dev-208", "ner": [[0, 2, "misc"], [4, 6, "misc"], [10, 15, "misc"], [23, 25, "algorithm"], [33, 34, "field"], [36, 37, "field"], [39, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 10, 15, "type-of", "", false, false], [0, 2, 33, 34, "related-to", "performs", true, false], [0, 2, 36, 37, "related-to", "performs", true, false], [0, 2, 39, 40, "related-to", "performs", true, false], [4, 6, 0, 2, "named", "", false, false], [23, 25, 10, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Learning", "Classifier", "Systems", "(", "LCS", ")", "are", "a", "group", "of", "rule", "-", "based", "machine", "learning", "algorithms", "that", "combine", "a", "discovery", "component", ",", "usually", "a", "genetic", "algorithm", ",", "with", "a", "learning", "component", "that", "performs", "supervised", "learning", ",", "reinforcement", "learning", "or", "unsupervised", "learning", "."], "sentence-detokenized": "Learning Classifier Systems (LCS) are a group of rule-based machine learning algorithms that combine a discovery component, usually a genetic algorithm, with a learning component that performs supervised learning, reinforcement learning or unsupervised learning.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 29], [29, 32], [32, 33], [34, 37], [38, 39], [40, 45], [46, 48], [49, 53], [53, 54], [54, 59], [60, 67], [68, 76], [77, 87], [88, 92], [93, 100], [101, 102], [103, 112], [113, 122], [122, 123], [124, 131], [132, 133], [134, 141], [142, 151], [151, 152], [153, 157], [158, 159], [160, 168], [169, 178], [179, 183], [184, 192], [193, 203], [204, 212], [212, 213], [214, 227], [228, 236], [237, 239], [240, 252], [253, 261], [261, 262]]}
{"doc_key": "ai-dev-209", "ner": [[14, 16, "algorithm"], [18, 18, "algorithm"], [28, 29, "algorithm"], [33, 34, "misc"], [41, 47, "algorithm"], [50, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 16, 28, 29, "origin", "", false, false], [14, 16, 33, 34, "usage", "", false, false], [18, 18, 14, 16, "named", "", false, false], [41, 47, 33, 34, "type-of", "", false, false], [41, 47, 50, 55, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "unknown", "parameters", "of", "each", "vector", "\u03b2subk", "/", "sub", "are", "usually", "jointly", "estimated", "using", "maximum", "a", "posteriori", "(", "MAP", ")", "estimation", ",", "which", "is", "an", "extension", "of", "the", "maximum", "likelihood", "method", "using", "weight", "regularisation", "to", "avoid", "pathological", "solutions", "(", "usually", "a", "quadratic", "regularisation", "function", ",", "which", "is", "equivalent", "to", "a", "zero-mean", "Gaussian", "prior", "distribution", ",", "but", "other", "distributions", "are", "possible", ")", "."], "sentence-detokenized": "The unknown parameters of each vector \u03b2subk/sub are usually jointly estimated using maximum a posteriori (MAP) estimation, which is an extension of the maximum likelihood method using weight regularisation to avoid pathological solutions (usually a quadratic regularisation function, which is equivalent to a zero-mean Gaussian prior distribution, but other distributions are possible).", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 30], [31, 37], [38, 43], [43, 44], [44, 47], [48, 51], [52, 59], [60, 67], [68, 77], [78, 83], [84, 91], [92, 93], [94, 104], [105, 106], [106, 109], [109, 110], [111, 121], [121, 122], [123, 128], [129, 131], [132, 134], [135, 144], [145, 147], [148, 151], [152, 159], [160, 170], [171, 177], [178, 183], [184, 190], [191, 205], [206, 208], [209, 214], [215, 227], [228, 237], [238, 239], [239, 246], [247, 248], [249, 258], [259, 273], [274, 282], [282, 283], [284, 289], [290, 292], [293, 303], [304, 306], [307, 308], [309, 318], [319, 327], [328, 333], [334, 346], [346, 347], [348, 351], [352, 357], [358, 371], [372, 375], [376, 384], [384, 385], [385, 386]]}
{"doc_key": "ai-dev-210", "ner": [[9, 11, "researcher"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 9, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "hierarchical", "structure", "of", "words", "is", "clearly", "illustrated", "in", "George", "Miller", "'s", "word", "web", "."], "sentence-detokenized": "The hierarchical structure of words is clearly illustrated in George Miller's word web.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 29], [30, 35], [36, 38], [39, 46], [47, 58], [59, 61], [62, 68], [69, 75], [75, 77], [78, 82], [83, 86], [86, 87]]}
{"doc_key": "ai-dev-211", "ner": [[5, 12, "conference"], [17, 20, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 20, 5, 12, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Their", "capabilities", "are", "illustrated", "by", "ImageNet", "'s", "large", "-", "scale", "visual", "recognition", "challenge", ",", "a", "benchmark", "for", "object", "classification", "and", "detection", ",", "covering", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "Their capabilities are illustrated by ImageNet's large-scale visual recognition challenge, a benchmark for object classification and detection, covering millions of images and hundreds of object classes.", "token2charspan": [[0, 5], [6, 18], [19, 22], [23, 34], [35, 37], [38, 46], [46, 48], [49, 54], [54, 55], [55, 60], [61, 67], [68, 79], [80, 89], [89, 90], [91, 92], [93, 102], [103, 106], [107, 113], [114, 128], [129, 132], [133, 142], [142, 143], [144, 152], [153, 161], [162, 164], [165, 171], [172, 175], [176, 184], [185, 187], [188, 194], [195, 202], [202, 203]]}
{"doc_key": "ai-dev-212", "ner": [[0, 2, "misc"], [18, 18, "misc"], [20, 22, "person"], [25, 25, "misc"], [30, 32, "person"], [36, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 18, 0, 2, "general-affiliation", "", false, false], [25, 25, 0, 2, "general-affiliation", "", false, false], [25, 25, 20, 22, "artifact", "", false, false], [36, 38, 0, 2, "general-affiliation", "", false, false], [36, 38, 30, 32, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "science", "fiction", ",", "female", "robots", "are", "often", "produced", "as", "domestic", "servants", "and", "sexual", "slaves", ",", "e.g.", "in", "Westworld", ",", "Paul", "J.", "McAuley", "'s", "novel", "Fairyland", "(", "1995", ")", ",", "Lester", "del", "Rey", "'s", "short", "story", "Helen", "O'", "Loy", "(", "1938", ")", ",", "and", "occasionally", "as", "warriors", ",", "assassins", "or", "labourers", "."], "sentence-detokenized": "In science fiction, female robots are often produced as domestic servants and sexual slaves, e.g. in Westworld, Paul J. McAuley's novel Fairyland (1995), Lester del Rey's short story Helen O'Loy (1938), and occasionally as warriors, assassins or labourers.", "token2charspan": [[0, 2], [3, 10], [11, 18], [18, 19], [20, 26], [27, 33], [34, 37], [38, 43], [44, 52], [53, 55], [56, 64], [65, 73], [74, 77], [78, 84], [85, 91], [91, 92], [93, 97], [98, 100], [101, 110], [110, 111], [112, 116], [117, 119], [120, 127], [127, 129], [130, 135], [136, 145], [146, 147], [147, 151], [151, 152], [152, 153], [154, 160], [161, 164], [165, 168], [168, 170], [171, 176], [177, 182], [183, 188], [189, 191], [191, 194], [195, 196], [196, 200], [200, 201], [201, 202], [203, 206], [207, 219], [220, 222], [223, 231], [231, 232], [233, 242], [243, 245], [246, 255], [255, 256]]}
{"doc_key": "ai-dev-213", "ner": [[0, 1, "task"], [3, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["question", "answering", ",", "speech", "recognition", "and", "machine", "translation", "."], "sentence-detokenized": "question answering, speech recognition and machine translation.", "token2charspan": [[0, 8], [9, 18], [18, 19], [20, 26], [27, 38], [39, 42], [43, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-214", "ner": [[5, 6, "researcher"], [10, 14, "organisation"], [15, 18, "location"], [19, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 10, 14, "role", "", false, false], [10, 14, 15, 18, "physical", "", false, false], [15, 18, 19, 20, "physical", "", false, false], [19, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "main", "work", ",", "Harry", "Blum", "of", "the", "Air", "Force", "Cambridge", "Research", "Laboratory", "at", "Hanscom", "Air", "Force", "Base", "in", "Bedford", ",", "Massachusetts", ",", "has", "defined", "a", "medial", "axis", "for", "calculating", "the", "skeleton", "of", "a", "figure", ",", "based", "on", "an", "intuitive", "model", "of", "the", "spread", "of", "a", "fire", "in", "a", "grass", "field", ",", "where", "the", "field", "has", "the", "shape", "of", "a", "given", "figure", "."], "sentence-detokenized": "In his main work, Harry Blum of the Air Force Cambridge Research Laboratory at Hanscom Air Force Base in Bedford, Massachusetts, has defined a medial axis for calculating the skeleton of a figure, based on an intuitive model of the spread of a fire in a grass field, where the field has the shape of a given figure.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [16, 17], [18, 23], [24, 28], [29, 31], [32, 35], [36, 39], [40, 45], [46, 55], [56, 64], [65, 75], [76, 78], [79, 86], [87, 90], [91, 96], [97, 101], [102, 104], [105, 112], [112, 113], [114, 127], [127, 128], [129, 132], [133, 140], [141, 142], [143, 149], [150, 154], [155, 158], [159, 170], [171, 174], [175, 183], [184, 186], [187, 188], [189, 195], [195, 196], [197, 202], [203, 205], [206, 208], [209, 218], [219, 224], [225, 227], [228, 231], [232, 238], [239, 241], [242, 243], [244, 248], [249, 251], [252, 253], [254, 259], [260, 265], [265, 266], [267, 272], [273, 276], [277, 282], [283, 286], [287, 290], [291, 296], [297, 299], [300, 301], [302, 307], [308, 314], [314, 315]]}
{"doc_key": "ai-dev-215", "ner": [[14, 14, "algorithm"], [16, 16, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 19, 20, "compare", "", false, false], [16, 16, 19, 20, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "unlike", "boosting", "algorithms", "that", "analytically", "minimise", "a", "convex", "loss", "function", "(", "e.g.", "AdaBoost", "and", "LogitBoost", ")", ",", "Brown", "Boost", "solves", "a", "system", "of", "two", "equations", "and", "two", "unknowns", "using", "standard", "numerical", "methods", "."], "sentence-detokenized": "However, unlike boosting algorithms that analytically minimise a convex loss function (e.g. AdaBoost and LogitBoost), BrownBoost solves a system of two equations and two unknowns using standard numerical methods.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 24], [25, 35], [36, 40], [41, 53], [54, 62], [63, 64], [65, 71], [72, 76], [77, 85], [86, 87], [87, 91], [92, 100], [101, 104], [105, 115], [115, 116], [116, 117], [118, 123], [123, 128], [129, 135], [136, 137], [138, 144], [145, 147], [148, 151], [152, 161], [162, 165], [166, 169], [170, 178], [179, 184], [185, 193], [194, 203], [204, 211], [211, 212]]}
{"doc_key": "ai-dev-216", "ner": [[0, 2, "researcher"], [11, 13, "misc"], [19, 25, "conference"], [27, 27, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 11, 13, "win-defeat", "", false, false], [0, 2, 19, 25, "role", "", false, false], [27, 27, 19, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getoor", "is", "the", "recipient", "of", "several", "best", "paper", "awards", ",", "an", "NSF", "Career", "Award", "and", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Getoor is the recipient of several best paper awards, an NSF Career Award and a member of the Association for the Advancement of Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 13], [14, 23], [24, 26], [27, 34], [35, 39], [40, 45], [46, 52], [52, 53], [54, 56], [57, 60], [61, 67], [68, 73], [74, 77], [78, 79], [80, 86], [87, 89], [90, 93], [94, 105], [106, 109], [110, 113], [114, 125], [126, 128], [129, 139], [140, 152], [153, 154], [154, 158], [158, 159], [159, 160]]}
{"doc_key": "ai-dev-217", "ner": [[0, 1, "misc"], [6, 12, "misc"], [17, 19, "misc"], [24, 30, "misc"], [35, 38, "misc"], [42, 48, "university"], [53, 63, "misc"], [68, 76, "misc"], [81, 85, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACM", "Fellow", "(", "2015", ")", "br", "Fellow", "of", "the", "Association", "for", "Computational", "Linguistics", "(", "2011", ")", "br", "Fellow", "of", "AAAI", "(", "1994", ")", "br", "Fellow", "of", "the", "International", "Speech", "Communication", "Association", "(", "2011", ")", "br", "Honorary", "Doctor", "of", "Science", "(", "Hedersdoktor", ")", "from", "the", "KTH", "Royal", "Institute", "of", "Technology", "(", "2007", ")", "br", "Alumni", "Association", "of", "the", "Columbia", "School", "of", "Engineering", "Outstanding", "Teaching", "Award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Speech", "and", "Audio", "Processing", "Award", "(", "2011", ")", "br", "ISCA", "Medal", "of", "Science", "Achievement", "(", "2011", ")"], "sentence-detokenized": "ACM Fellow (2015) br Fellow of the Association for Computational Linguistics (2011) br Fellow of AAAI (1994) br Fellow of the International Speech Communication Association (2011) br Honorary Doctor of Science (Hedersdoktor) from the KTH Royal Institute of Technology (2007) br Alumni Association of the Columbia School of Engineering Outstanding Teaching Award (2009) br IEEE James L. Flanagan Speech and Audio Processing Award (2011) br ISCA Medal of Science Achievement (2011)", "token2charspan": [[0, 3], [4, 10], [11, 12], [12, 16], [16, 17], [18, 20], [21, 27], [28, 30], [31, 34], [35, 46], [47, 50], [51, 64], [65, 76], [77, 78], [78, 82], [82, 83], [84, 86], [87, 93], [94, 96], [97, 101], [102, 103], [103, 107], [107, 108], [109, 111], [112, 118], [119, 121], [122, 125], [126, 139], [140, 146], [147, 160], [161, 172], [173, 174], [174, 178], [178, 179], [180, 182], [183, 191], [192, 198], [199, 201], [202, 209], [210, 211], [211, 223], [223, 224], [225, 229], [230, 233], [234, 237], [238, 243], [244, 253], [254, 256], [257, 267], [268, 269], [269, 273], [273, 274], [275, 277], [278, 284], [285, 296], [297, 299], [300, 303], [304, 312], [313, 319], [320, 322], [323, 334], [335, 346], [347, 355], [356, 361], [362, 363], [363, 367], [367, 368], [369, 371], [372, 376], [377, 382], [383, 385], [386, 394], [395, 401], [402, 405], [406, 411], [412, 422], [423, 428], [429, 430], [430, 434], [434, 435], [436, 438], [439, 443], [444, 449], [450, 452], [453, 460], [461, 472], [473, 474], [474, 478], [478, 479]]}
{"doc_key": "ai-dev-218", "ner": [[5, 5, "university"], [14, 17, "task"], [31, 31, "metrics"], [26, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[31, 31, 26, 28, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "result", "of", "the", "same", "Stanford", "study", "(", "and", "other", "attempts", "to", "improve", "the", "translation", "of", "name", "recognition", ")", "is", "disappointing", ",", "as", "the", "inclusion", "of", "named", "entity", "translation", "methods", "reduces", "bilingual", "scores", "many", "times", "over", "."], "sentence-detokenized": "The result of the same Stanford study (and other attempts to improve the translation of name recognition) is disappointing, as the inclusion of named entity translation methods reduces bilingual scores many times over.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 17], [18, 22], [23, 31], [32, 37], [38, 39], [39, 42], [43, 48], [49, 57], [58, 60], [61, 68], [69, 72], [73, 84], [85, 87], [88, 92], [93, 104], [104, 105], [106, 108], [109, 122], [122, 123], [124, 126], [127, 130], [131, 140], [141, 143], [144, 149], [150, 156], [157, 168], [169, 176], [177, 184], [185, 194], [195, 201], [202, 206], [207, 212], [213, 217], [217, 218]]}
{"doc_key": "ai-dev-219", "ner": [[0, 1, "organisation"], [13, 15, "organisation"], [17, 24, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 13, 15, "role", "works_with", false, false], [0, 1, 17, 24, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["\"", "Medtronic", "uses", "the", "PM", "data", "it", "collects", "to", "collaborate", "with", "researchers", "at", "Johns", "Hopkins", "Hospital", "and", "Washington", "University", "School", "of", "Medicine", "to", "help", "answer", "specific", "questions", "about", "heart", "disease", ",", "such", "as", "whether", "a", "weak", "heart", "causes", "arrhythmia", "or", "vice", "versa", "."], "sentence-detokenized": "\"Medtronic uses the PM data it collects to collaborate with researchers at Johns Hopkins Hospital and Washington University School of Medicine to help answer specific questions about heart disease, such as whether a weak heart causes arrhythmia or vice versa.", "token2charspan": [[0, 1], [1, 10], [11, 15], [16, 19], [20, 22], [23, 27], [28, 30], [31, 39], [40, 42], [43, 54], [55, 59], [60, 71], [72, 74], [75, 80], [81, 88], [89, 97], [98, 101], [102, 112], [113, 123], [124, 130], [131, 133], [134, 142], [143, 145], [146, 150], [151, 157], [158, 166], [167, 176], [177, 182], [183, 188], [189, 196], [196, 197], [198, 202], [203, 205], [206, 213], [214, 215], [216, 220], [221, 226], [227, 233], [234, 244], [245, 247], [248, 252], [253, 258], [258, 259]]}
{"doc_key": "ai-dev-220", "ner": [[4, 5, "organisation"], [10, 10, "misc"], [13, 14, "person"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 4, 5, "artifact", "made_by_studio", false, false], [13, 14, 10, 10, "role", "", false, false], [16, 17, 10, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "was", "followed", "by", "Paramount", "'s", "first", "feature", "film", ",", "Sangaree", ",", "with", "Fernando", "Lamas", "and", "Arlene", "Dahl", "."], "sentence-detokenized": "This was followed by Paramount's first feature film, Sangaree, with Fernando Lamas and Arlene Dahl.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 30], [30, 32], [33, 38], [39, 46], [47, 51], [51, 52], [53, 61], [61, 62], [63, 67], [68, 76], [77, 82], [83, 86], [87, 93], [94, 98], [98, 99]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [8, 10, "researcher"], [12, 13, "researcher"], [15, 16, "organisation"], [18, 20, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 10, "origin", "", false, false], [0, 0, 12, 13, "origin", "", false, false], [8, 10, 15, 16, "physical", "", false, false], [8, 10, 15, 16, "role", "", false, false], [12, 13, 18, 20, "physical", "", false, false], [12, 13, 18, 20, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "is", "a", "knowledge", "representation", "language", "developed", "by", "Daniel", "G.", "Bobrow", "and", "Terry", "Winograd", "at", "Xerox", "PARC", "and", "Stanford", "University", "respectively", "."], "sentence-detokenized": "KRL is a knowledge representation language developed by Daniel G. Bobrow and Terry Winograd at Xerox PARC and Stanford University respectively.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 18], [19, 33], [34, 42], [43, 52], [53, 55], [56, 62], [63, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 94], [95, 100], [101, 105], [106, 109], [110, 118], [119, 129], [130, 142], [142, 143]]}
{"doc_key": "ai-dev-222", "ner": [[3, 10, "conference"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [22, 25, "researcher"], [34, 37, "task"], [40, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 10, 34, 37, "topic", "", true, false], [12, 13, 3, 10, "physical", "", false, false], [12, 13, 3, 10, "role", "", false, false], [12, 13, 3, 10, "temporal", "", false, false], [15, 16, 3, 10, "physical", "", false, false], [15, 16, 3, 10, "role", "", false, false], [15, 16, 3, 10, "temporal", "", false, false], [18, 19, 3, 10, "physical", "", false, false], [18, 19, 3, 10, "role", "", false, false], [18, 19, 3, 10, "temporal", "", false, false], [22, 25, 3, 10, "physical", "", false, false], [22, 25, 3, 10, "role", "", false, false], [22, 25, 3, 10, "temporal", "", false, false], [34, 37, 40, 42, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["At", "the", "2006", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", ",", "and", "Kwang", "-", "Ting", "Cheng", "presented", "an", "algorithm", "that", "significantly", "speeds", "up", "the", "detection", "of", "human", "beings", "by", "using", "HOG", "descriptor", "methods", "."], "sentence-detokenized": "At the 2006 IEEE Conference on Computer Vision and Pattern Recognition, Qiang Zhu, Shai Avidan, Mei-Chen Yeh, and Kwang-Ting Cheng presented an algorithm that significantly speeds up the detection of human beings by using HOG descriptor methods.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 27], [28, 30], [31, 39], [40, 46], [47, 50], [51, 58], [59, 70], [70, 71], [72, 77], [78, 81], [81, 82], [83, 87], [88, 94], [94, 95], [96, 104], [105, 108], [108, 109], [110, 113], [114, 119], [119, 120], [120, 124], [125, 130], [131, 140], [141, 143], [144, 153], [154, 158], [159, 172], [173, 179], [180, 182], [183, 186], [187, 196], [197, 199], [200, 205], [206, 212], [213, 215], [216, 221], [222, 225], [226, 236], [237, 244], [244, 245]]}
{"doc_key": "ai-dev-223", "ner": [[0, 2, "researcher"], [6, 6, "conference"], [9, 12, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 6, "role", "", false, false], [0, 2, 9, 12, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "is", "a", "member", "of", "the", "AAAI", "and", "the", "Society", "for", "Cognitive", "Science", "."], "sentence-detokenized": "Hayes is a member of the AAAI and the Society for Cognitive Science.", "token2charspan": [[0, 5], [6, 8], [9, 10], [11, 17], [18, 20], [21, 24], [25, 29], [30, 33], [34, 37], [38, 45], [46, 49], [50, 59], [60, 67], [67, 68]]}
{"doc_key": "ai-dev-224", "ner": [[0, 1, "misc"], [5, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 32, "field"], [36, 38, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 1, 5, 5, "part-of", "", false, false], [0, 1, 5, 5, "usage", "", false, false], [0, 1, 7, 8, "part-of", "", false, false], [0, 1, 7, 8, "usage", "", false, false], [0, 1, 10, 11, "part-of", "", false, false], [0, 1, 10, 11, "usage", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [0, 1, 13, 13, "usage", "", false, false], [0, 1, 15, 16, "part-of", "", false, false], [0, 1, 15, 16, "usage", "", false, false], [0, 1, 18, 19, "part-of", "", false, false], [0, 1, 18, 19, "usage", "", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 21, 22, "usage", "", false, false], [0, 1, 24, 24, "part-of", "", false, false], [0, 1, 24, 24, "usage", "", false, false], [0, 1, 26, 27, "part-of", "", false, false], [0, 1, 26, 27, "usage", "", false, false], [0, 1, 29, 29, "part-of", "", false, false], [0, 1, 29, 29, "usage", "", false, false], [0, 1, 31, 32, "part-of", "", false, false], [0, 1, 31, 32, "usage", "", false, false], [0, 1, 36, 38, "part-of", "", false, false], [0, 1, 36, 38, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", "and", "many", "other", "applications", "in", "science", "and", "engineering", "where", "time", "measurements", "are", "taken", "."], "sentence-detokenized": "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering and many other applications in science and engineering where time measurements are taken.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 23], [24, 34], [34, 35], [36, 42], [43, 53], [53, 54], [55, 62], [63, 74], [74, 75], [76, 88], [88, 89], [90, 102], [103, 110], [110, 111], [112, 119], [120, 131], [131, 132], [133, 143], [144, 154], [154, 155], [156, 178], [178, 179], [180, 187], [188, 199], [199, 200], [201, 210], [210, 211], [212, 226], [227, 238], [239, 242], [243, 247], [248, 253], [254, 266], [267, 269], [270, 277], [278, 281], [282, 293], [294, 299], [300, 304], [305, 317], [318, 321], [322, 327], [327, 328]]}
{"doc_key": "ai-dev-225", "ner": [[13, 16, "metrics"], [36, 38, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "principle", ",", "exact", "reproduction", "can", "be", "solved", "in", "its", "feasible", "domain", "using", "maximum", "likelihood", ",", "but", "this", "implies", "solving", "a", "constrained", "or", "regularised", "cut", "problem", ",", "e.g.", "the", "minimum", "cut", "problem", ",", "which", "is", "typically", "NP", "-", "complete", "."], "sentence-detokenized": "In principle, exact reproduction can be solved in its feasible domain using maximum likelihood, but this implies solving a constrained or regularised cut problem, e.g. the minimum cut problem, which is typically NP-complete.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 19], [20, 32], [33, 36], [37, 39], [40, 46], [47, 49], [50, 53], [54, 62], [63, 69], [70, 75], [76, 83], [84, 94], [94, 95], [96, 99], [100, 104], [105, 112], [113, 120], [121, 122], [123, 134], [135, 137], [138, 149], [150, 153], [154, 161], [161, 162], [163, 167], [168, 171], [172, 179], [180, 183], [184, 191], [191, 192], [193, 198], [199, 201], [202, 211], [212, 214], [214, 215], [215, 223], [223, 224]]}
{"doc_key": "ai-dev-226", "ner": [[4, 9, "task"], [13, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 15, 4, 9, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["in", "his", "work", "on", "pedestrian", "detection", ",", "which", "was", "first", "described", "in", "the", "BMVC", "in", "2009", "."], "sentence-detokenized": "in his work on pedestrian detection, which was first described in the BMVC in 2009.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 25], [26, 35], [35, 36], [37, 42], [43, 46], [47, 52], [53, 62], [63, 65], [66, 69], [70, 74], [75, 77], [78, 82], [82, 83]]}
{"doc_key": "ai-dev-227", "ner": [[3, 7, "conference"], [9, 9, "researcher"], [13, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 3, 7, "physical", "", false, false], [9, 9, 3, 7, "role", "", false, false], [9, 9, 13, 21, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["At", "the", "2007", "International", "Conference", "on", "Computer", "Vision", ",", "Terzopoulos", "was", "awarded", "the", "IEEE", "PAMI", "Computer", "Vision", "Outstanding", "Researcher", "Award", "for", "his", "pioneering", "and", "sustained", "research", "on", "deformable", "models", "and", "their", "applications", "."], "sentence-detokenized": "At the 2007 International Conference on Computer Vision, Terzopoulos was awarded the IEEE PAMI Computer Vision Outstanding Researcher Award for his pioneering and sustained research on deformable models and their applications.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 25], [26, 36], [37, 39], [40, 48], [49, 55], [55, 56], [57, 68], [69, 72], [73, 80], [81, 84], [85, 89], [90, 94], [95, 103], [104, 110], [111, 122], [123, 133], [134, 139], [140, 143], [144, 147], [148, 158], [159, 162], [163, 172], [173, 181], [182, 184], [185, 195], [196, 202], [203, 206], [207, 212], [213, 225], [225, 226]]}
{"doc_key": "ai-dev-228", "ner": [[0, 1, "task"], [4, 5, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 4, 5, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cluster", "analysis", ",", "or", "cluster", "analysis", ",", "involves", "assigning", "data", "points", "to", "clusters", "in", "such", "a", "way", "that", "items", "belonging", "to", "the", "same", "cluster", "are", "as", "similar", "as", "possible", "and", "items", "belonging", "to", "different", "clusters", "are", "as", "dissimilar", "as", "possible", "."], "sentence-detokenized": "Cluster analysis, or cluster analysis, involves assigning data points to clusters in such a way that items belonging to the same cluster are as similar as possible and items belonging to different clusters are as dissimilar as possible.", "token2charspan": [[0, 7], [8, 16], [16, 17], [18, 20], [21, 28], [29, 37], [37, 38], [39, 47], [48, 57], [58, 62], [63, 69], [70, 72], [73, 81], [82, 84], [85, 89], [90, 91], [92, 95], [96, 100], [101, 106], [107, 116], [117, 119], [120, 123], [124, 128], [129, 136], [137, 140], [141, 143], [144, 151], [152, 154], [155, 163], [164, 167], [168, 173], [174, 183], [184, 186], [187, 196], [197, 205], [206, 209], [210, 212], [213, 223], [224, 226], [227, 235], [235, 236]]}
{"doc_key": "ai-dev-229", "ner": [[8, 9, "field"], [15, 16, "field"], [18, 19, "task"], [21, 22, "field"], [25, 26, "field"], [28, 29, "field"], [31, 32, "field"], [34, 35, "task"], [36, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 9, 15, 16, "named", "", false, false], [8, 9, 21, 22, "named", "", false, false], [8, 9, 28, 29, "named", "", false, false], [18, 19, 15, 16, "part-of", "task_part_of_field", false, false], [25, 26, 21, 22, "part-of", "", false, false], [31, 32, 28, 29, "part-of", "", false, false], [34, 35, 31, 32, "part-of", "", false, false], [36, 37, 31, 32, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["(", "2005", ")", ",", "three", "different", "approaches", "to", "text", "mining", "can", "be", "distinguished", ",", "i.e.", "text", "mining", "as", "information", "extraction", ",", "text", "mining", "as", "textual", "data", "mining", "and", "text", "mining", "as", "data", "mining", "(", "knowledge", "discovery", "in", "databases", ")", ".", "Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005), three different approaches to text mining can be distinguished, i.e. text mining as information extraction, text mining as textual data mining and text mining as data mining (knowledge discovery in databases). Hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [6, 7], [8, 13], [14, 23], [24, 34], [35, 37], [38, 42], [43, 49], [50, 53], [54, 56], [57, 70], [70, 71], [72, 76], [77, 81], [82, 88], [89, 91], [92, 103], [104, 114], [114, 115], [116, 120], [121, 127], [128, 130], [131, 138], [139, 143], [144, 150], [151, 154], [155, 159], [160, 166], [167, 169], [170, 174], [175, 181], [182, 183], [183, 192], [193, 202], [203, 205], [206, 215], [215, 216], [216, 217], [218, 223], [223, 224], [225, 227], [227, 228], [229, 239], [239, 240], [241, 243], [244, 247], [248, 252], [252, 253], [254, 256], [257, 258], [258, 262], [262, 263], [263, 264]]}
{"doc_key": "ai-dev-230", "ner": [[2, 3, "product"], [14, 21, "location"], [23, 23, "location"], [25, 28, "location"], [31, 34, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 14, 21, "related-to", "developed_for", false, false], [14, 21, 23, 23, "physical", "", false, false], [23, 23, 25, 28, "physical", "", false, false], [31, 34, 2, 3, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["\"", "The", "Rancho", "Arm", "was", "developed", "as", "a", "robotic", "arm", "to", "assist", "disabled", "patients", "at", "the", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Centre", "in", "Downey", ",", "California", ",", "and", "was", "purchased", "by", "Stanford", "University", "in", "1963", "."], "sentence-detokenized": "\"The Rancho Arm was developed as a robotic arm to assist disabled patients at the Rancho Los Amigos National Rehabilitation Centre in Downey, California, and was purchased by Stanford University in 1963.", "token2charspan": [[0, 1], [1, 4], [5, 11], [12, 15], [16, 19], [20, 29], [30, 32], [33, 34], [35, 42], [43, 46], [47, 49], [50, 56], [57, 65], [66, 74], [75, 77], [78, 81], [82, 88], [89, 92], [93, 99], [100, 108], [109, 123], [124, 130], [131, 133], [134, 140], [140, 141], [142, 152], [152, 153], [154, 157], [158, 161], [162, 171], [172, 174], [175, 183], [184, 194], [195, 197], [198, 202], [202, 203]]}
{"doc_key": "ai-dev-231", "ner": [[0, 1, "university"], [3, 3, "researcher"], [9, 12, "organisation"], [20, 22, "organisation"], [25, 26, "researcher"], [28, 30, "researcher"], [43, 43, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 0, 1, "physical", "", false, false], [3, 3, 0, 1, "role", "", false, false], [3, 3, 9, 12, "role", "founder", false, false], [3, 3, 20, 22, "role", "founder", false, false], [20, 22, 43, 43, "physical", "", false, false], [25, 26, 20, 22, "role", "founder", false, false], [28, 30, 20, 22, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["At", "UCSD", ",", "Norman", "was", "a", "founding", "member", "of", "the", "Cognitive", "Science", "Institute", "and", "one", "of", "the", "organisers", "of", "the", "Cognitive", "Science", "Society", "(", "with", "Roger", "Schank", ",", "Allan", "M.", "Collins", "and", "others", ")", ",", "which", "held", "it", "s", "first", "meeting", "on", "the", "UCSD", "campus", "in", "1979", "."], "sentence-detokenized": "At UCSD, Norman was a founding member of the Cognitive Science Institute and one of the organisers of the Cognitive Science Society (with Roger Schank, Allan M. Collins and others), which held its first meeting on the UCSD campus in 1979.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 21], [22, 30], [31, 37], [38, 40], [41, 44], [45, 54], [55, 62], [63, 72], [73, 76], [77, 80], [81, 83], [84, 87], [88, 98], [99, 101], [102, 105], [106, 115], [116, 123], [124, 131], [132, 133], [133, 137], [138, 143], [144, 150], [150, 151], [152, 157], [158, 160], [161, 168], [169, 172], [173, 179], [179, 180], [180, 181], [182, 187], [188, 192], [193, 195], [195, 196], [197, 202], [203, 210], [211, 213], [214, 217], [218, 222], [223, 229], [230, 232], [233, 237], [237, 238]]}
{"doc_key": "ai-dev-232", "ner": [[6, 7, "product"], [9, 10, "product"], [12, 13, "product"], [15, 17, "product"], [19, 20, "product"], [22, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[19, 20, 15, 17, "type-of", "", false, false], [22, 27, 15, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "common", "robot", "configurations", "are", "articulated", "robots", ",", "SCARA", "robots", ",", "delta", "robots", "and", "Cartesian", "coordinate", "robots", "(", "gate", "robots", "or", "x", "-", "y", "-", "z", "robots", ")", "."], "sentence-detokenized": "The most common robot configurations are articulated robots, SCARA robots, delta robots and Cartesian coordinate robots (gate robots or x-y-z robots).", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 21], [22, 36], [37, 40], [41, 52], [53, 59], [59, 60], [61, 66], [67, 73], [73, 74], [75, 80], [81, 87], [88, 91], [92, 101], [102, 112], [113, 119], [120, 121], [121, 125], [126, 132], [133, 135], [136, 137], [137, 138], [138, 139], [139, 140], [140, 141], [142, 148], [148, 149], [149, 150]]}
{"doc_key": "ai-dev-233", "ner": [[8, 8, "programlang"], [9, 10, "misc"], [15, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 8, 8, "part-of", "", false, false], [15, 15, 9, 10, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "can", "also", "be", "used", "directly", "with", "the", "Perl", "module", "TM", "(", "which", "also", "supports", "LTM", ")", "."], "sentence-detokenized": "It can also be used directly with the Perl module TM (which also supports LTM).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 19], [20, 28], [29, 33], [34, 37], [38, 42], [43, 49], [50, 52], [53, 54], [54, 59], [60, 64], [65, 73], [74, 77], [77, 78], [78, 79]]}
{"doc_key": "ai-dev-234", "ner": [[6, 6, "country"], [9, 12, "organisation"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 12, 6, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "competition", "was", "won", "by", "a", "US", "team", "from", "Newton", "Labs", "and", "was", "broadcast", "on", "CNN", "."], "sentence-detokenized": "The competition was won by a US team from Newton Labs and was broadcast on CNN.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 26], [27, 28], [29, 31], [32, 36], [37, 41], [42, 48], [49, 53], [54, 57], [58, 61], [62, 71], [72, 74], [75, 78], [78, 79]]}
{"doc_key": "ai-dev-235", "ner": [[9, 13, "misc"], [18, 20, "person"], [22, 23, "person"], [25, 29, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[18, 20, 9, 13, "role", "directs", false, false], [22, 23, 9, 13, "role", "acts_in", false, false], [25, 29, 9, 13, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["On", "23", "June", "2008", ",", "the", "short", "film", "\"", "The", "Butler", "'s", "in", "Love", "\"", ",", "directed", "by", "David", "Arquette", "and", "starring", "Elizabeth", "Berkley", "and", "Thomas", "Jane", ",", "was", "released", "."], "sentence-detokenized": "On 23 June 2008, the short film \"The Butler's in Love\", directed by David Arquette and starring Elizabeth Berkley and Thomas Jane, was released.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 15], [15, 16], [17, 20], [21, 26], [27, 31], [32, 33], [33, 36], [37, 43], [43, 45], [46, 48], [49, 53], [53, 54], [54, 55], [56, 64], [65, 67], [68, 73], [74, 82], [83, 86], [87, 95], [96, 105], [106, 113], [114, 117], [118, 124], [125, 129], [129, 130], [131, 134], [135, 143], [143, 144]]}
{"doc_key": "ai-dev-236", "ner": [[3, 4, "product"], [7, 7, "field"], [15, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 15, 15, "general-affiliation", "", false, false], [7, 7, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "Word", "Net", "is", "a", "taxonomy", "resource", "whose", "elements", "are", "the", "meanings", "of", "English", "words", "."], "sentence-detokenized": "For example, WordNet is a taxonomy resource whose elements are the meanings of English words.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [17, 20], [21, 23], [24, 25], [26, 34], [35, 43], [44, 49], [50, 58], [59, 62], [63, 66], [67, 75], [76, 78], [79, 86], [87, 92], [92, 93]]}
{"doc_key": "ai-dev-237", "ner": [[1, 5, "product"], [7, 7, "product"], [9, 9, "product"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 1, 5, "type-of", "", false, false], [7, 7, 15, 16, "related-to", "ability_to", false, false], [9, 9, 1, 5, "type-of", "", false, false], [9, 9, 15, 16, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Existing", "humanoid", "robot", "systems", ",", "such", "as", "ASIMO", "and", "QRIO", ",", "use", "multiple", "motors", "to", "move", "around", "."], "sentence-detokenized": "Existing humanoid robot systems, such as ASIMO and QRIO, use multiple motors to move around.", "token2charspan": [[0, 8], [9, 17], [18, 23], [24, 31], [31, 32], [33, 37], [38, 40], [41, 46], [47, 50], [51, 55], [55, 56], [57, 60], [61, 69], [70, 76], [77, 79], [80, 84], [85, 91], [91, 92]]}
{"doc_key": "ai-dev-238", "ner": [[0, 0, "metrics"], [11, 12, "metrics"], [14, 14, "metrics"], [16, 21, "misc"], [23, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 12, 0, 0, "part-of", "", false, false], [14, 14, 0, 0, "part-of", "", false, false], [16, 21, 0, 0, "part-of", "", false, false], [23, 23, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "is", "designed", "to", "take", "into", "account", "the", "factors", "of", "enhanced", "length", "penalty", ",", "accuracy", ",", "n", "-", "gram", "word", "order", "penalty", "and", "recall", "."], "sentence-detokenized": "LEPOR is designed to take into account the factors of enhanced length penalty, accuracy, n-gram word order penalty and recall.", "token2charspan": [[0, 5], [6, 8], [9, 17], [18, 20], [21, 25], [26, 30], [31, 38], [39, 42], [43, 50], [51, 53], [54, 62], [63, 69], [70, 77], [77, 78], [79, 87], [87, 88], [89, 90], [90, 91], [91, 95], [96, 100], [101, 106], [107, 114], [115, 118], [119, 125], [125, 126]]}
{"doc_key": "ai-dev-239", "ner": [[5, 11, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "based", "on", "the", "student", "metric", "for", "bilingual", "assessment", ",", "but", "with", "some", "modifications", "."], "sentence-detokenized": "It is based on the student metric for bilingual assessment, but with some modifications.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 14], [15, 18], [19, 26], [27, 33], [34, 37], [38, 47], [48, 58], [58, 59], [60, 63], [64, 68], [69, 73], [74, 87], [87, 88]]}
{"doc_key": "ai-dev-240", "ner": [[6, 6, "product"], [8, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "of", "a", "MATLAB", "/", "Octave", "implementation", ":"], "sentence-detokenized": "This is an example of a MATLAB / Octave implementation:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 23], [24, 30], [31, 32], [33, 39], [40, 54], [54, 55]]}
{"doc_key": "ai-dev-241", "ner": [[15, 15, "programlang"], [17, 17, "programlang"], [19, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "designed", "to", "be", "usable", "in", "a", "wide", "range", "of", "computer", "languages", ",", "including", "Python", ",", "Ruby", "and", "Scheme", "."], "sentence-detokenized": "It is designed to be usable in a wide range of computer languages, including Python, Ruby and Scheme.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 20], [21, 27], [28, 30], [31, 32], [33, 37], [38, 43], [44, 46], [47, 55], [56, 65], [65, 66], [67, 76], [77, 83], [83, 84], [85, 89], [90, 93], [94, 100], [100, 101]]}
{"doc_key": "ai-dev-242", "ner": [[0, 0, "researcher"], [6, 7, "organisation"], [13, 14, "conference"], [22, 23, "academicjournal"], [28, 31, "organisation"], [37, 41, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 7, "role", "", false, false], [0, 0, 13, 14, "role", "", false, false], [0, 0, 22, 23, "role", "", false, false], [0, 0, 28, 31, "role", "", false, false], [0, 0, 37, 41, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "has", "served", "as", "Secretary", "of", "the", "AISB", ",", "President", "and", "Trustee", "of", "the", "IJCAI", ",", "Associate", "Editor", "of", "the", "Journal", "of", "Artificial", "Intelligence", ",", "a", "Trustee", "of", "the", "Cognitive", "Science", "Society", ",", "and", "President", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes has served as Secretary of the AISB, President and Trustee of the IJCAI, Associate Editor of the Journal of Artificial Intelligence, a Trustee of the Cognitive Science Society, and President of the American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 32], [33, 36], [37, 41], [41, 42], [43, 52], [53, 56], [57, 64], [65, 67], [68, 71], [72, 77], [77, 78], [79, 88], [89, 95], [96, 98], [99, 102], [103, 110], [111, 113], [114, 124], [125, 137], [137, 138], [139, 140], [141, 148], [149, 151], [152, 155], [156, 165], [166, 173], [174, 181], [181, 182], [183, 186], [187, 196], [197, 199], [200, 203], [204, 212], [213, 224], [225, 228], [229, 239], [240, 252], [252, 253]]}
{"doc_key": "ai-dev-243", "ner": [[4, 12, "misc"], [14, 16, "misc"], [21, 24, "person"], [25, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 24, 4, 12, "role", "directed_by", false, false], [21, 24, 14, 16, "role", "directed_by", false, false], [21, 24, 25, 29, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "of", "them", ",", "Now", "is", "the", "Time", "to", "Put", "on", "Your", "Glasses", "and", "Around", "is", "Around", ",", "were", "directed", "by", "Norman", "McLaren", "for", "the", "National", "Film", "Board", "of", "Canada", "in", "1951", "."], "sentence-detokenized": "Two of them, Now is the Time to Put on Your Glasses and Around is Around, were directed by Norman McLaren for the National Film Board of Canada in 1951.", "token2charspan": [[0, 3], [4, 6], [7, 11], [11, 12], [13, 16], [17, 19], [20, 23], [24, 28], [29, 31], [32, 35], [36, 38], [39, 43], [44, 51], [52, 55], [56, 62], [63, 65], [66, 72], [72, 73], [74, 78], [79, 87], [88, 90], [91, 97], [98, 105], [106, 109], [110, 113], [114, 122], [123, 127], [128, 133], [134, 136], [137, 143], [144, 146], [147, 151], [151, 152]]}
{"doc_key": "ai-dev-244", "ner": [[3, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "purpose", "of", "the", "recommender", "system", "is", "to", "predict", "the", "target", "user", "'s", "preference", "for", "the", "product", "."], "sentence-detokenized": "The purpose of the recommender system is to predict the target user's preference for the product.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 18], [19, 30], [31, 37], [38, 40], [41, 43], [44, 51], [52, 55], [56, 62], [63, 67], [67, 69], [70, 80], [81, 84], [85, 88], [89, 96], [96, 97]]}
{"doc_key": "ai-dev-245", "ner": [[0, 0, "algorithm"], [4, 4, "field"], [6, 6, "field"], [8, 9, "field"], [11, 13, "field"], [15, 18, "field"], [17, 17, "field"], [20, 20, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 4, "part-of", "", true, false], [0, 0, 6, 6, "part-of", "", true, false], [0, 0, 8, 9, "part-of", "", true, false], [0, 0, 11, 13, "part-of", "", true, false], [0, 0, 15, 18, "part-of", "", true, false], [0, 0, 17, 17, "part-of", "", true, false], [0, 0, 20, 20, "part-of", "", true, false], [0, 0, 22, 23, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Convolution", "is", "used", "in", "probability", ",", "statistics", ",", "computer", "vision", ",", "natural", "language", "processing", ",", "image", "and", "signal", "processing", ",", "engineering", "and", "differential", "equations", "."], "sentence-detokenized": "Convolution is used in probability, statistics, computer vision, natural language processing, image and signal processing, engineering and differential equations.", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 22], [23, 34], [34, 35], [36, 46], [46, 47], [48, 56], [57, 63], [63, 64], [65, 72], [73, 81], [82, 92], [92, 93], [94, 99], [100, 103], [104, 110], [111, 121], [121, 122], [123, 134], [135, 138], [139, 151], [152, 161], [161, 162]]}
{"doc_key": "ai-dev-246", "ner": [[0, 0, "field"], [3, 5, "task"], [7, 8, "task"], [10, 10, "task"], [11, 11, "task"], [12, 12, "task"], [14, 15, "task"], [17, 18, "task"], [20, 21, "task"], [23, 23, "task"], [26, 27, "task"], [29, 29, "field"], [31, 31, "field"], [33, 35, "field"], [37, 37, "field"], [39, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[0, 0, 3, 5, "part-of", "", true, false], [0, 0, 7, 8, "part-of", "", true, false], [0, 0, 10, 10, "part-of", "", true, false], [0, 0, 11, 11, "part-of", "", true, false], [0, 0, 12, 12, "part-of", "", true, false], [0, 0, 14, 15, "part-of", "", true, false], [0, 0, 17, 18, "part-of", "", true, false], [0, 0, 20, 21, "part-of", "", true, false], [0, 0, 23, 23, "part-of", "", true, false], [0, 0, 26, 27, "part-of", "", true, false], [0, 0, 29, 29, "part-of", "", true, false], [0, 0, 31, 31, "part-of", "", true, false], [0, 0, 33, 35, "part-of", "", true, false], [0, 0, 37, 37, "part-of", "", true, false], [0, 0, 39, 39, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["DSP", "applications", "include", "audio", "signal", "processing", ",", "audio", "compression", ",", "digital", "image", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communications", ",", "digital", "synthesizers", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", "and", "biomedicine", "."], "sentence-detokenized": "DSP applications include audio signal processing, audio compression, digital image processing, video compression, speech processing, speech recognition, digital communications, digital synthesizers, radar, sonar, financial signal processing, seismology and biomedicine.", "token2charspan": [[0, 3], [4, 16], [17, 24], [25, 30], [31, 37], [38, 48], [48, 49], [50, 55], [56, 67], [67, 68], [69, 76], [77, 82], [83, 93], [93, 94], [95, 100], [101, 112], [112, 113], [114, 120], [121, 131], [131, 132], [133, 139], [140, 151], [151, 152], [153, 160], [161, 175], [175, 176], [177, 184], [185, 197], [197, 198], [199, 204], [204, 205], [206, 211], [211, 212], [213, 222], [223, 229], [230, 240], [240, 241], [242, 252], [253, 256], [257, 268], [268, 269]]}
{"doc_key": "ai-dev-247", "ner": [[11, 14, "misc"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "20", "February", "1912", "-", "11", "August", "2011", ")", "was", "an", "American", "inventor", ",", "best", "known", "for", "creating", "the", "first", "industrial", "robot", ",", "Unimate", "."], "sentence-detokenized": "(20 February 1912 - 11 August 2011) was an American inventor, best known for creating the first industrial robot, Unimate.", "token2charspan": [[0, 1], [1, 3], [4, 12], [13, 17], [18, 19], [20, 22], [23, 29], [30, 34], [34, 35], [36, 39], [40, 42], [43, 51], [52, 60], [60, 61], [62, 66], [67, 72], [73, 76], [77, 85], [86, 89], [90, 95], [96, 106], [107, 112], [112, 113], [114, 121], [121, 122]]}
{"doc_key": "ai-dev-248", "ner": [[2, 4, "researcher"], [6, 8, "researcher"], [10, 10, "researcher"], [19, 27, "algorithm"], [23, 25, "algorithm"], [31, 32, "task"], [37, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 4, 19, 27, "related-to", "writes_about", true, false], [6, 8, 19, 27, "related-to", "writes_about", true, false], [10, 10, 19, 27, "related-to", "writes_about", true, false], [19, 27, 23, 25, "related-to", "", true, false], [31, 32, 37, 37, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Along", "with", "David", "E.", "Rumelhart", "and", "Ronald", "J.", "Williams", ",", "Hinton", "co-authored", "a", "highly", "cited", "1986", "paper", "popularising", "the", "Backpropagation", "algorithm", "for", "training", "multi-layer", "neural", "networks", ",", "A", "dramatic", "milestone", "in", "image", "recognition", "was", "the", "development", "of", "AlexNet", "{", "{{", "cite", "web"], "sentence-detokenized": "Along with David E. Rumelhart and Ronald J. Williams, Hinton co-authored a highly cited 1986 paper popularising the Backpropagation algorithm for training multi-layer neural networks, A dramatic milestone in image recognition was the development of AlexNet {{{cite web", "token2charspan": [[0, 5], [6, 10], [11, 16], [17, 19], [20, 29], [30, 33], [34, 40], [41, 43], [44, 52], [52, 53], [54, 60], [61, 72], [73, 74], [75, 81], [82, 87], [88, 92], [93, 98], [99, 111], [112, 115], [116, 131], [132, 141], [142, 145], [146, 154], [155, 166], [167, 173], [174, 182], [182, 183], [184, 185], [186, 194], [195, 204], [205, 207], [208, 213], [214, 225], [226, 229], [230, 233], [234, 245], [246, 248], [249, 256], [257, 258], [258, 260], [260, 264], [265, 268]]}
{"doc_key": "ai-dev-249", "ner": [[9, 11, "metrics"], [14, 17, "metrics"], [20, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "predicted", "value", "is", "uniformly", "distributed", ",", "the", "mean", "square", "error", ",", "the", "root", "mean", "square", "error", "or", "the", "mean", "absolute", "deviation", "can", "be", "used", "to", "summarise", "the", "errors", "."], "sentence-detokenized": "When the predicted value is uniformly distributed, the mean square error, the root mean square error or the mean absolute deviation can be used to summarise the errors.", "token2charspan": [[0, 4], [5, 8], [9, 18], [19, 24], [25, 27], [28, 37], [38, 49], [49, 50], [51, 54], [55, 59], [60, 66], [67, 72], [72, 73], [74, 77], [78, 82], [83, 87], [88, 94], [95, 100], [101, 103], [104, 107], [108, 112], [113, 121], [122, 131], [132, 135], [136, 138], [139, 143], [144, 146], [147, 156], [157, 160], [161, 167], [167, 168]]}
{"doc_key": "ai-dev-250", "ner": [[0, 1, "algorithm"], [10, 11, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 10, 11, "part-of", "", true, false], [0, 1, 14, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Conceptual", "clustering", "was", "mainly", "developed", "in", "the", "1970s", "as", "a", "machine", "learning", "paradigm", "for", "unsupervised", "learning", "."], "sentence-detokenized": "Conceptual clustering was mainly developed in the 1970s as a machine learning paradigm for unsupervised learning.", "token2charspan": [[0, 10], [11, 21], [22, 25], [26, 32], [33, 42], [43, 45], [46, 49], [50, 55], [56, 58], [59, 60], [61, 68], [69, 77], [78, 86], [87, 90], [91, 103], [104, 112], [112, 113]]}
{"doc_key": "ai-dev-251", "ner": [[2, 3, "product"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "machine", "translator", "is", "unable", "to", "recognise", "the", "named", "entities", ",", "they", "may", "be", "mistranslated", "as", "generic", "nouns", ",", "which", "is", "unlikely", "to", "affect", "the", "evaluation", "of", "the", "bilingual", "evaluation", "double", ",", "but", "will", "change", "the", "human", "readability", "of", "the", "text", "."], "sentence-detokenized": "If the machine translator is unable to recognise the named entities, they may be mistranslated as generic nouns, which is unlikely to affect the evaluation of the bilingual evaluation double, but will change the human readability of the text.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 25], [26, 28], [29, 35], [36, 38], [39, 48], [49, 52], [53, 58], [59, 67], [67, 68], [69, 73], [74, 77], [78, 80], [81, 94], [95, 97], [98, 105], [106, 111], [111, 112], [113, 118], [119, 121], [122, 130], [131, 133], [134, 140], [141, 144], [145, 155], [156, 158], [159, 162], [163, 172], [173, 183], [184, 190], [190, 191], [192, 195], [196, 200], [201, 207], [208, 211], [212, 217], [218, 229], [230, 232], [233, 236], [237, 241], [241, 242]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 22, "location"], [24, 24, "country"], [39, 41, "researcher"], [48, 48, "researcher"], [52, 52, "university"], [56, 57, "researcher"], [59, 60, "researcher"], [62, 63, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 22, "physical", "", false, false], [20, 22, 24, 24, "physical", "", false, false], [48, 48, 52, 52, "physical", "", false, false], [48, 48, 52, 52, "role", "", false, false], [56, 57, 52, 52, "physical", "", false, false], [56, 57, 52, 52, "role", "", false, false], [59, 60, 52, 52, "physical", "", false, false], [59, 60, 52, 52, "role", "", false, false], [62, 63, 52, 52, "physical", "", false, false], [62, 63, 52, 52, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng", "-", "S\u00e4by", ",", "Sweden", ",", "pp.", "1", "-", "3", ".", "This", "model", ",", "partly", "influenced", "by", "the", "work", "of", "Sydney", "Lamb", ",", "has", "been", "used", "extensively", "by", "Schank", "'s", "students", "at", "Yale", ",", "such", "as", "Robert", "Wilensky", ",", "Wendy", "Lehnert", "and", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, pp. 1-3. This model, partly influenced by the work of Sydney Lamb, has been used extensively by Schank's students at Yale, such as Robert Wilensky, Wendy Lehnert and Janet Kolodner.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 130], [130, 131], [131, 135], [135, 136], [137, 143], [143, 144], [145, 148], [149, 150], [150, 151], [151, 152], [152, 153], [154, 158], [159, 164], [164, 165], [166, 172], [173, 183], [184, 186], [187, 190], [191, 195], [196, 198], [199, 205], [206, 210], [210, 211], [212, 215], [216, 220], [221, 225], [226, 237], [238, 240], [241, 247], [247, 249], [250, 258], [259, 261], [262, 266], [266, 267], [268, 272], [273, 275], [276, 282], [283, 291], [291, 292], [293, 298], [299, 306], [307, 310], [311, 316], [317, 325], [325, 326]]}
{"doc_key": "ai-dev-253", "ner": [[2, 4, "algorithm"], [6, 9, "algorithm"], [13, 13, "algorithm"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 9, 2, 4, "named", "", false, false], [13, 13, 2, 4, "named", "", false, false], [15, 16, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Improved", "Maximum", "Likelihood", "Method", "(", "IMLM", ")", "is", "a", "combination", "of", "two", "MLM", "(", "Maximum", "Likelihood", ")", "estimates", "."], "sentence-detokenized": "The Improved Maximum Likelihood Method (IMLM) is a combination of two MLM (Maximum Likelihood) estimates.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 38], [39, 40], [40, 44], [44, 45], [46, 48], [49, 50], [51, 62], [63, 65], [66, 69], [70, 73], [74, 75], [75, 82], [83, 93], [93, 94], [95, 104], [104, 105]]}
{"doc_key": "ai-dev-254", "ner": [[17, 18, "metrics"], [21, 22, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 22, 17, 18, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "methods", "can", "also", "analyse", "the", "output", "of", "a", "programme", "and", "its", "usefulness", ",", "and", "therefore", "its", "confusion", "matrix", "(", "or", "confusion", "table", ")", "."], "sentence-detokenized": "These methods can also analyse the output of a programme and its usefulness, and therefore its confusion matrix (or confusion table).", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 22], [23, 30], [31, 34], [35, 41], [42, 44], [45, 46], [47, 56], [57, 60], [61, 64], [65, 75], [75, 76], [77, 80], [81, 90], [91, 94], [95, 104], [105, 111], [112, 113], [113, 115], [116, 125], [126, 131], [131, 132], [132, 133]]}
{"doc_key": "ai-dev-255", "ner": [[0, 2, "product"], [5, 6, "researcher"], [8, 9, "researcher"], [11, 13, "researcher"], [18, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 6, "origin", "", false, false], [0, 2, 8, 9, "origin", "", false, false], [0, 2, 11, 13, "origin", "", false, false], [0, 2, 18, 22, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "was", "first", "published", "by", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", "and", "Luc", "Van", "Gool", "and", "presented", "at", "the", "2006", "European", "Computer", "Vision", "Conference", "."], "sentence-detokenized": "SURF was first published by Herbert Bay, Tinne Tuytelaars and Luc Van Gool and presented at the 2006 European Computer Vision Conference.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 39], [39, 40], [41, 46], [47, 57], [58, 61], [62, 65], [66, 69], [70, 74], [75, 78], [79, 88], [89, 91], [92, 95], [96, 100], [101, 109], [110, 118], [119, 125], [126, 136], [136, 137]]}
{"doc_key": "ai-dev-256", "ner": [[0, 0, "task"], [6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 7, "part-of", "", false, false], [0, 0, 9, 10, "part-of", "", false, false], [0, 0, 12, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "is", "a", "research", "area", "in", "pattern", "recognition", ",", "artificial", "intelligence", "and", "computer", "vision", "."], "sentence-detokenized": "OCR is a research area in pattern recognition, artificial intelligence and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 17], [18, 22], [23, 25], [26, 33], [34, 45], [45, 46], [47, 57], [58, 70], [71, 74], [75, 83], [84, 90], [90, 91]]}
{"doc_key": "ai-dev-257", "ner": [[7, 9, "metrics"], [12, 14, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Continuing", "with", "the", "example", "and", "using", "the", "maximum", "likelihood", "estimator", ",", "the", "probability", "density", "function", "(", "pdf", ")", "of", "the", "single", "-", "sample", "mathwn", "/", "math", "noise", "is", "as", "follows"], "sentence-detokenized": "Continuing with the example and using the maximum likelihood estimator, the probability density function (pdf) of the single-sample mathwn/math noise is as follows", "token2charspan": [[0, 10], [11, 15], [16, 19], [20, 27], [28, 31], [32, 37], [38, 41], [42, 49], [50, 60], [61, 70], [70, 71], [72, 75], [76, 87], [88, 95], [96, 104], [105, 106], [106, 109], [109, 110], [111, 113], [114, 117], [118, 124], [124, 125], [125, 131], [132, 138], [138, 139], [139, 143], [144, 149], [150, 152], [153, 155], [156, 163]]}
{"doc_key": "ai-dev-258", "ner": [[3, 4, "field"], [6, 7, "task"], [9, 10, "task"], [12, 13, "task"], [15, 16, "task"], [18, 20, "task"], [22, 22, "task"], [24, 24, "task"], [26, 27, "task"], [29, 30, "task"], [32, 34, "task"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[6, 7, 3, 4, "part-of", "", false, false], [9, 10, 3, 4, "part-of", "", false, false], [12, 13, 3, 4, "part-of", "", false, false], [15, 16, 3, 4, "part-of", "", false, false], [18, 20, 3, 4, "part-of", "", false, false], [22, 22, 3, 4, "part-of", "", false, false], [24, 24, 3, 4, "part-of", "", false, false], [26, 27, 3, 4, "part-of", "", false, false], [29, 30, 3, 4, "part-of", "", false, false], [32, 34, 3, 4, "part-of", "", false, false], [36, 37, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["The", "sub-fields", "of", "computer", "vision", "include", "scene", "reconstruction", ",", "event", "detection", ",", "image", "tracking", ",", "object", "recognition", ",", "3D", "pose", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "control", ",", "3D", "scene", "modelling", "and", "image", "playback", "."], "sentence-detokenized": "The sub-fields of computer vision include scene reconstruction, event detection, image tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual control, 3D scene modelling and image playback.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 26], [27, 33], [34, 41], [42, 47], [48, 62], [62, 63], [64, 69], [70, 79], [79, 80], [81, 86], [87, 95], [95, 96], [97, 103], [104, 115], [115, 116], [117, 119], [120, 124], [125, 135], [135, 136], [137, 145], [145, 146], [147, 155], [155, 156], [157, 163], [164, 174], [174, 175], [176, 182], [183, 190], [190, 191], [192, 194], [195, 200], [201, 210], [211, 214], [215, 220], [221, 229], [229, 230]]}
{"doc_key": "ai-dev-259", "ner": [[10, 16, "conference"], [3, 3, "researcher"], [7, 9, "misc"], [18, 19, "conference"], [28, 28, "researcher"], [30, 30, "researcher"], [22, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 16, 18, 19, "named", "", false, false], [3, 3, 7, 9, "win-defeat", "", false, false], [3, 3, 22, 23, "related-to", "writes_about", true, false], [7, 9, 10, 16, "temporal", "", false, false], [28, 28, 7, 9, "win-defeat", "", false, true], [28, 28, 22, 23, "related-to", "writes_about", true, false], [30, 30, 7, 9, "win-defeat", "", false, true], [30, 30, 22, 23, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["In", "2013", ",", "Terzopoulos", "was", "awarded", "the", "Helmholtz", "Prize", "at", "the", "International", "Conference", "on", "Computer", "Vision", "for", "his", "1987", "ICCV", "paper", "on", "active", "contour", "models", ",", "co-authored", "with", "Kass", "and", "Witkin", "."], "sentence-detokenized": "In 2013, Terzopoulos was awarded the Helmholtz Prize at the International Conference on Computer Vision for his 1987 ICCV paper on active contour models, co-authored with Kass and Witkin.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 24], [25, 32], [33, 36], [37, 46], [47, 52], [53, 55], [56, 59], [60, 73], [74, 84], [85, 87], [88, 96], [97, 103], [104, 107], [108, 111], [112, 116], [117, 121], [122, 127], [128, 130], [131, 137], [138, 145], [146, 152], [152, 153], [154, 165], [166, 170], [171, 175], [176, 179], [180, 186], [186, 187]]}
{"doc_key": "ai-dev-260", "ner": [[14, 15, "task"], [18, 20, "algorithm"], [22, 23, "algorithm"], [25, 27, "algorithm"], [29, 30, "algorithm"], [32, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 15, 18, 20, "usage", "", true, false], [14, 15, 22, 23, "usage", "", true, false], [14, 15, 25, 27, "usage", "", true, false], [14, 15, 29, 30, "usage", "", true, false], [14, 15, 32, 32, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["If", "the", "regularisation", "function", "There", "are", "many", "algorithms", "for", "solving", "such", "problems", ";", "popular", "linear", "classification", "algorithms", "include", "stochastic", "gradient", "descent", ",", "gradient", "descent", ",", "L", "-", "BFGS", ",", "coordinate", "descent", "and", "Newton", "methods", "."], "sentence-detokenized": "If the regularisation function There are many algorithms for solving such problems; popular linear classification algorithms include stochastic gradient descent, gradient descent, L-BFGS, coordinate descent and Newton methods.", "token2charspan": [[0, 2], [3, 6], [7, 21], [22, 30], [31, 36], [37, 40], [41, 45], [46, 56], [57, 60], [61, 68], [69, 73], [74, 82], [82, 83], [84, 91], [92, 98], [99, 113], [114, 124], [125, 132], [133, 143], [144, 152], [153, 160], [160, 161], [162, 170], [171, 178], [178, 179], [180, 181], [181, 182], [182, 186], [186, 187], [188, 198], [199, 206], [207, 210], [211, 217], [218, 225], [225, 226]]}
{"doc_key": "ai-dev-261", "ner": [[9, 13, "algorithm"], [15, 15, "algorithm"], [3, 4, "researcher"], [6, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 13, 3, 4, "origin", "", false, false], [15, 15, 9, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1997", ",", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "invented", "Long", "Short", "-", "Term", "Memory", "(", "LSTM", ")", "networks", "and", "set", "accuracy", "records", "in", "a", "wide", "range", "of", "applications", "."], "sentence-detokenized": "In 1997, Sepp Hochreiter and J\u00fcrgen Schmidhuber invented Long Short-Term Memory (LSTM) networks and set accuracy records in a wide range of applications.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 13], [14, 24], [25, 28], [29, 35], [36, 47], [48, 56], [57, 61], [62, 67], [67, 68], [68, 72], [73, 79], [80, 81], [81, 85], [85, 86], [87, 95], [96, 99], [100, 103], [104, 112], [113, 120], [121, 123], [124, 125], [126, 130], [131, 136], [137, 139], [140, 152], [152, 153]]}
{"doc_key": "ai-dev-262", "ner": [[0, 0, "product"], [3, 6, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 3, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["TN", "was", "developed", "in", "a", "Massachusetts", "hospital", "and", "tested", "in", "a", "variety", "of", "scenarios", ",", "including", "smoking", "status", ",", "family", "history", "of", "coronary", "artery", "disease", ",", "and", "identification", "of", "patients", "with", "sleep", "disorders", ","], "sentence-detokenized": "TN was developed in a Massachusetts hospital and tested in a variety of scenarios, including smoking status, family history of coronary artery disease, and identification of patients with sleep disorders,", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 21], [22, 35], [36, 44], [45, 48], [49, 55], [56, 58], [59, 60], [61, 68], [69, 71], [72, 81], [81, 82], [83, 92], [93, 100], [101, 107], [107, 108], [109, 115], [116, 123], [124, 126], [127, 135], [136, 142], [143, 150], [150, 151], [152, 155], [156, 170], [171, 173], [174, 182], [183, 187], [188, 193], [194, 203], [203, 204]]}
{"doc_key": "ai-dev-263", "ner": [[3, 3, "researcher"], [8, 8, "product"], [15, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 8, "role", "sells", false, false], [8, 8, 15, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 86], [87, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-dev-264", "ner": [[6, 8, "conference"], [19, 21, "location"], [12, 22, "location"], [15, 24, "country"], [35, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 19, 21, "physical", "", false, false], [19, 21, 12, 22, "physical", "", false, false], [12, 22, 15, 24, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["14", "-", "18", "April", "2010", "The", "Campus", "Party", "Europe", "conference", "took", "place", "in", "Madrid", ",", "Spain", ",", "at", "the", "Caja", "M\u00e1gica", "in", "Madrid", ",", "Spain", ",", "and", "was", "attended", "by", "800", "participants", "from", "all", "27", "EU", "Member", "States", "."], "sentence-detokenized": "14-18 April 2010 The Campus Party Europe conference took place in Madrid, Spain, at the Caja M\u00e1gica in Madrid, Spain, and was attended by 800 participants from all 27 EU Member States.", "token2charspan": [[0, 2], [2, 3], [3, 5], [6, 11], [12, 16], [17, 20], [21, 27], [28, 33], [34, 40], [41, 51], [52, 56], [57, 62], [63, 65], [66, 72], [72, 73], [74, 79], [79, 80], [81, 83], [84, 87], [88, 92], [93, 99], [100, 102], [103, 109], [109, 110], [111, 116], [116, 117], [118, 121], [122, 125], [126, 134], [135, 137], [138, 141], [142, 154], [155, 159], [160, 163], [164, 166], [167, 169], [170, 176], [177, 183], [183, 184]]}
{"doc_key": "ai-dev-265", "ner": [[4, 4, "organisation"], [6, 8, "organisation"], [14, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 18, 4, 4, "origin", "", false, false], [14, 18, 6, 8, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2016", ",", "DeepMind", "and", "Moorfields", "Eye", "Hospital", "announced", "a", "collaboration", "to", "develop", "artificial", "intelligence", "applications", "for", "healthcare", "."], "sentence-detokenized": "In July 2016, DeepMind and Moorfields Eye Hospital announced a collaboration to develop artificial intelligence applications for healthcare.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 22], [23, 26], [27, 37], [38, 41], [42, 50], [51, 60], [61, 62], [63, 76], [77, 79], [80, 87], [88, 98], [99, 111], [112, 124], [125, 128], [129, 139], [139, 140]]}
{"doc_key": "ai-dev-266", "ner": [[7, 8, "misc"], [13, 14, "university"], [16, 16, "university"], [18, 19, "university"], [21, 22, "university"], [24, 24, "university"], [26, 26, "university"], [28, 31, "university"], [33, 37, "university"], [38, 38, "university"], [40, 40, "university"], [43, 45, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[7, 8, 13, 14, "physical", "", false, false], [7, 8, 16, 16, "physical", "", false, false], [7, 8, 18, 19, "physical", "", false, false], [7, 8, 21, 22, "physical", "", false, false], [7, 8, 24, 24, "physical", "", false, false], [7, 8, 26, 26, "physical", "", false, false], [7, 8, 28, 31, "physical", "", false, false], [7, 8, 33, 37, "physical", "", false, false], [7, 8, 38, 38, "physical", "", false, false], [7, 8, 40, 40, "physical", "", false, false], [7, 8, 43, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["In", "the", "end", ",", "they", "awarded", "eleven", "PR2s", "to", "different", "institutions", ",", "including", "Freiburg", "University", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "Technical", "University", "of", "Munich", ",", "UC", "Berkeley", ",", "University", "of", "Pennsylvania", ",", "USA", "and", "the", "University", "of", "Tokyo", "."], "sentence-detokenized": "In the end, they awarded eleven PR2s to different institutions, including Freiburg University, Bosch, Georgia Tech, KU Leuven, MIT, Stanford, Technical University of Munich, UC Berkeley, University of Pennsylvania, USA and the University of Tokyo.", "token2charspan": [[0, 2], [3, 6], [7, 10], [10, 11], [12, 16], [17, 24], [25, 31], [32, 36], [37, 39], [40, 49], [50, 62], [62, 63], [64, 73], [74, 82], [83, 93], [93, 94], [95, 100], [100, 101], [102, 109], [110, 114], [114, 115], [116, 118], [119, 125], [125, 126], [127, 130], [130, 131], [132, 140], [140, 141], [142, 151], [152, 162], [163, 165], [166, 172], [172, 173], [174, 176], [177, 185], [185, 186], [187, 197], [198, 200], [201, 213], [213, 214], [215, 218], [219, 222], [223, 226], [227, 237], [238, 240], [241, 246], [246, 247]]}
{"doc_key": "ai-dev-267", "ner": [[0, 1, "metrics"], [3, 3, "metrics"], [5, 5, "metrics"], [7, 7, "metrics"], [17, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 17, 18, "part-of", "", false, false], [3, 3, 17, 18, "part-of", "", false, false], [5, 5, 17, 18, "part-of", "", false, false], [7, 7, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "TP", ",", "TN", ",", "FP", "and", "FN", "figures", "are", "usually", "entered", "in", "a", "table", "called", "a", "confusion", "matrix", "."], "sentence-detokenized": "The TP, TN, FP and FN figures are usually entered in a table called a confusion matrix.", "token2charspan": [[0, 3], [4, 6], [6, 7], [8, 10], [10, 11], [12, 14], [15, 18], [19, 21], [22, 29], [30, 33], [34, 41], [42, 49], [50, 52], [53, 54], [55, 60], [61, 67], [68, 69], [70, 79], [80, 86], [86, 87]]}
{"doc_key": "ai-dev-268", "ner": [[7, 8, "metrics"], [10, 11, "metrics"], [13, 14, "metrics"], [16, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "set", "of", "attributes", "typically", "used", "are", "information", "gain", ",", "cross", "-entropy", ",", "mutual", "information", "and", "odds", "ratio", "."], "sentence-detokenized": "The set of attributes typically used are information gain, cross-entropy, mutual information and odds ratio.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 21], [22, 31], [32, 36], [37, 40], [41, 52], [53, 57], [57, 58], [59, 64], [64, 72], [72, 73], [74, 80], [81, 92], [93, 96], [97, 101], [102, 107], [107, 108]]}
{"doc_key": "ai-dev-269", "ner": [[12, 13, "task"], [15, 16, "task"], [18, 18, "task"], [20, 20, "task"], [22, 22, "task"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[24, 24, 22, 22, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "successfully", "applied", "to", "a", "wide", "range", "of", "problems", "including", "robot", "control", ",", "lift", "planning", ",", "telecommunications", ",", "checkers", "and", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "It has been successfully applied to a wide range of problems including robot control, lift planning, telecommunications, checkers and Go (AlphaGo).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 32], [33, 35], [36, 37], [38, 42], [43, 48], [49, 51], [52, 60], [61, 70], [71, 76], [77, 84], [84, 85], [86, 90], [91, 99], [99, 100], [101, 119], [119, 120], [121, 129], [130, 133], [134, 136], [137, 138], [138, 145], [145, 146], [146, 147]]}
{"doc_key": "ai-dev-270", "ner": [[11, 16, "misc"], [17, 20, "university"], [22, 23, "location"], [25, 27, "location"], [29, 34, "location"], [35, 37, "location"], [38, 39, "location"], [41, 41, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 16, 17, 20, "physical", "", false, false], [17, 20, 22, 23, "physical", "", false, false], [22, 23, 25, 27, "physical", "", false, false], [29, 34, 35, 37, "physical", "", false, false], [35, 37, 38, 39, "physical", "", false, false], [38, 39, 41, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "the", "inaugural", "year", "of", "Mission", "8", ",", "the", "Americas", "site", "was", "located", "at", "the", "Georgia", "Institute", "of", "Technology", "campus", "in", "Atlanta", ",", "Georgia", ",", "and", "the", "Asia", "-", "Pacific", "site", "at", "the", "Beihang", "University", "Gymnasium", "in", "Beijing", ",", "China", "."], "sentence-detokenized": "In 2018, the inaugural year of Mission 8, the Americas site was located at the Georgia Institute of Technology campus in Atlanta, Georgia, and the Asia-Pacific site at the Beihang University Gymnasium in Beijing, China.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 38], [39, 40], [40, 41], [42, 45], [46, 54], [55, 59], [60, 63], [64, 71], [72, 74], [75, 78], [79, 86], [87, 96], [97, 99], [100, 110], [111, 117], [118, 120], [121, 128], [128, 129], [130, 137], [137, 138], [139, 142], [143, 146], [147, 151], [151, 152], [152, 159], [160, 164], [165, 167], [168, 171], [172, 179], [180, 190], [191, 200], [201, 203], [204, 211], [211, 212], [213, 218], [218, 219]]}
{"doc_key": "ai-dev-271", "ner": [[0, 1, "field"], [6, 7, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "origin", "", false, false], [0, 1, 6, 7, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "is", "closely", "related", "to", "pattern", "recognition", "and", "has", "its", "origins", "in", "artificial", "intelligence", "."], "sentence-detokenized": "Machine learning is closely related to pattern recognition and has its origins in artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 35], [36, 38], [39, 46], [47, 58], [59, 62], [63, 66], [67, 70], [71, 78], [79, 81], [82, 92], [93, 105], [105, 106]]}
{"doc_key": "ai-dev-272", "ner": [[3, 3, "programlang"], [13, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "contains", "3", "Java", "games", ",", "controlled", "by", "remote", "control", "and", "displayed", "on", "an", "LCD", "screen", "."], "sentence-detokenized": "It contains 3 Java games, controlled by remote control and displayed on an LCD screen.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 18], [19, 24], [24, 25], [26, 36], [37, 39], [40, 46], [47, 54], [55, 58], [59, 68], [69, 71], [72, 74], [75, 78], [79, 85], [85, 86]]}
{"doc_key": "ai-dev-273", "ner": [[7, 15, "task"], [17, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 19, 7, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "commercially", "successful", "but", "specialised", "method", "for", "computer", "vision", "-", "based", "assessment", "of", "hinged", "body", "posture", "is", "optical", "motion", "capture", "."], "sentence-detokenized": "A commercially successful but specialised method for computer vision-based assessment of hinged body posture is optical motion capture.", "token2charspan": [[0, 1], [2, 14], [15, 25], [26, 29], [30, 41], [42, 48], [49, 52], [53, 61], [62, 68], [68, 69], [69, 74], [75, 85], [86, 88], [89, 95], [96, 100], [101, 108], [109, 111], [112, 119], [120, 126], [127, 134], [134, 135]]}
{"doc_key": "ai-dev-274", "ner": [[0, 1, "organisation"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SMC", "is", "very", "similar", "to", "the", "more", "popular", "Jaccard", "Index", "."], "sentence-detokenized": "The SMC is very similar to the more popular Jaccard Index.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 23], [24, 26], [27, 30], [31, 35], [36, 43], [44, 51], [52, 57], [57, 58]]}
{"doc_key": "ai-dev-275", "ner": [[0, 0, "product"], [2, 5, "product"], [7, 10, "product"], [19, 22, "researcher"], [29, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 7, 10, "named", "", false, false], [0, 0, 19, 22, "artifact", "", false, false], [0, 0, 29, 29, "artifact", "", false, false], [2, 5, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["PUMA", "(", "Programmable", "Universal", "Assembly", "Machine", "or", "Programmable", "Universal", "Manipulative", "Arm", ")", "is", "an", "industrial", "robotic", "arm", "developed", "by", "Victor", "Scheinman", ",", "who", "works", "for", "the", "innovative", "robotics", "company", "Unimation", "."], "sentence-detokenized": "PUMA (Programmable Universal Assembly Machine or Programmable Universal Manipulative Arm) is an industrial robotic arm developed by Victor Scheinman, who works for the innovative robotics company Unimation.", "token2charspan": [[0, 4], [5, 6], [6, 18], [19, 28], [29, 37], [38, 45], [46, 48], [49, 61], [62, 71], [72, 84], [85, 88], [88, 89], [90, 92], [93, 95], [96, 106], [107, 114], [115, 118], [119, 128], [129, 131], [132, 138], [139, 148], [148, 149], [150, 153], [154, 159], [160, 163], [164, 167], [168, 178], [179, 187], [188, 195], [196, 205], [205, 206]]}
{"doc_key": "ai-dev-276", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "written", "in", "Python", "."], "sentence-detokenized": "It is written in Python.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 23], [23, 24]]}
{"doc_key": "ai-dev-277", "ner": [[0, 0, "misc"], [1, 2, "misc"], [11, 11, "field"], [13, 14, "field"], [16, 16, "field"], [19, 19, "field"], [22, 23, "field"], [25, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 1, 2, "related-to", "metric_for", true, false], [0, 0, 11, 11, "part-of", "", false, false], [0, 0, 13, 14, "part-of", "", false, false], [0, 0, 16, 16, "part-of", "", false, false], [0, 0, 19, 19, "part-of", "", false, false], [0, 0, 22, 23, "part-of", "", false, false], [0, 0, 25, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Bandwidth", "in", "Hertz", "is", "a", "key", "concept", "in", "many", "fields", "including", "electronics", ",", "information", "theory", ",", "digital", "communications", ",", "radio", "communications", ",", "signal", "processing", "and", "spectroscopy", ",", "and", "is", "one", "of", "the", "factors", "that", "determine", "the", "bandwidth", "of", "a", "given", "communication", "channel", "."], "sentence-detokenized": "Bandwidth in Hertz is a key concept in many fields including electronics, information theory, digital communications, radio communications, signal processing and spectroscopy, and is one of the factors that determine the bandwidth of a given communication channel.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 21], [22, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 50], [51, 60], [61, 72], [72, 73], [74, 85], [86, 92], [92, 93], [94, 101], [102, 116], [116, 117], [118, 123], [124, 138], [138, 139], [140, 146], [147, 157], [158, 161], [162, 174], [174, 175], [176, 179], [180, 182], [183, 186], [187, 189], [190, 193], [194, 201], [202, 206], [207, 216], [217, 220], [221, 230], [231, 233], [234, 235], [236, 241], [242, 255], [256, 263], [263, 264]]}
{"doc_key": "ai-dev-278", "ner": [[9, 9, "algorithm"], [11, 11, "algorithm"], [14, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 14, 21, "part-of", "", false, false], [11, 11, 14, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "a", "convex", "loss", "is", "used", "(", "as", "in", "AdaBoost", ",", "LogitBoost", "and", "all", "algorithms", "in", "the", "AnyBoost", "family", ")", ",", "the", "example", "with", "the", "higher", "margin", "will", "have", "a", "lower", "(", "or", "the", "same", ")", "weight", "than", "the", "example", "with", "the", "lower", "margin", "."], "sentence-detokenized": "If a convex loss is used (as in AdaBoost, LogitBoost and all algorithms in the AnyBoost family), the example with the higher margin will have a lower (or the same) weight than the example with the lower margin.", "token2charspan": [[0, 2], [3, 4], [5, 11], [12, 16], [17, 19], [20, 24], [25, 26], [26, 28], [29, 31], [32, 40], [40, 41], [42, 52], [53, 56], [57, 60], [61, 71], [72, 74], [75, 78], [79, 87], [88, 94], [94, 95], [95, 96], [97, 100], [101, 108], [109, 113], [114, 117], [118, 124], [125, 131], [132, 136], [137, 141], [142, 143], [144, 149], [150, 151], [151, 153], [154, 157], [158, 162], [162, 163], [164, 170], [171, 175], [176, 179], [180, 187], [188, 192], [193, 196], [197, 202], [203, 209], [209, 210]]}
{"doc_key": "ai-dev-279", "ner": [[0, 5, "researcher"], [6, 6, "researcher"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 5, 6, 6, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sepp", "Hochreiter", "'s", "1991", "thesis", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Sepp Hochreiter's 1991 thesis Sepp Hochreiter.", "token2charspan": [[0, 4], [5, 15], [15, 17], [18, 22], [23, 29], [30, 34], [35, 45], [45, 46]]}
{"doc_key": "ai-dev-280", "ner": [[4, 5, "algorithm"], [7, 7, "algorithm"], [10, 11, "algorithm"], [14, 14, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [27, 28, "algorithm"], [31, 32, "algorithm"], [34, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 7, 4, 5, "named", "", false, false], [14, 14, 10, 11, "named", "", false, false], [17, 19, 27, 28, "related-to", "", true, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Typical", "discriminative", "models", "include", "logistic", "regression", "(", "LR", ")", ",", "support", "vector", "machines", "(", "SVM", ")", ",", "conditional", "random", "fields", "(", "CRF", ")", "(", "defined", "via", "an", "undirected", "graph", ")", ",", "decision", "trees", ",", "neural", "networks", "and", "many", "others", "."], "sentence-detokenized": "Typical discriminative models include logistic regression (LR), support vector machines (SVM), conditional random fields (CRF) (defined via an undirected graph), decision trees, neural networks and many others.", "token2charspan": [[0, 7], [8, 22], [23, 29], [30, 37], [38, 46], [47, 57], [58, 59], [59, 61], [61, 62], [62, 63], [64, 71], [72, 78], [79, 87], [88, 89], [89, 92], [92, 93], [93, 94], [95, 106], [107, 113], [114, 120], [121, 122], [122, 125], [125, 126], [127, 128], [128, 135], [136, 139], [140, 142], [143, 153], [154, 159], [159, 160], [160, 161], [162, 170], [171, 176], [176, 177], [178, 184], [185, 193], [194, 197], [198, 202], [203, 209], [209, 210]]}
{"doc_key": "ai-dev-281", "ner": [[12, 17, "metrics"], [36, 38, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "then", "also", "possible", "to", "use", "these", "probabilities", "to", "estimate", "the", "root", "mean", "square", "error", "(", "or", "some", "other", "similar", "measure", ")", "between", "the", "probabilities", "and", "the", "actual", "values", ",", "then", "combine", "it", "with", "the", "mixing", "matrix", "to", "produce", "very", "efficient", "logistic", "regression", "goodness", "of", "fit", "functions", "."], "sentence-detokenized": "It is then also possible to use these probabilities to estimate the root mean square error (or some other similar measure) between the probabilities and the actual values, then combine it with the mixing matrix to produce very efficient logistic regression goodness of fit functions.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 15], [16, 24], [25, 27], [28, 31], [32, 37], [38, 51], [52, 54], [55, 63], [64, 67], [68, 72], [73, 77], [78, 84], [85, 90], [91, 92], [92, 94], [95, 99], [100, 105], [106, 113], [114, 121], [121, 122], [123, 130], [131, 134], [135, 148], [149, 152], [153, 156], [157, 163], [164, 170], [170, 171], [172, 176], [177, 184], [185, 187], [188, 192], [193, 196], [197, 203], [204, 210], [211, 213], [214, 221], [222, 226], [227, 236], [237, 245], [246, 256], [257, 265], [266, 268], [269, 272], [273, 282], [282, 283]]}
{"doc_key": "ai-dev-282", "ner": [[0, 1, "product"], [7, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 7, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "was", "first", "deployed", "in", "2005", "on", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "."], "sentence-detokenized": "VoiceOver was first deployed in 2005 on Mac OS X Tiger (10.4).", "token2charspan": [[0, 9], [10, 13], [14, 19], [20, 28], [29, 31], [32, 36], [37, 39], [40, 43], [44, 46], [47, 48], [49, 54], [55, 56], [56, 60], [60, 61], [61, 62]]}
{"doc_key": "ai-dev-283", "ner": [[13, 16, "algorithm"], [20, 21, "misc"], [27, 31, "metrics"], [24, 26, "algorithm"], [57, 65, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 16, 20, 21, "related-to", "applied_to", false, false], [27, 31, 20, 21, "type-of", "", false, false], [27, 31, 24, 26, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "practice", ",", "machine", "learning", "algorithms", "deal", "with", "this", "either", "by", "applying", "a", "convex", "approximation", "of", "the", "0", "-", "1", "loss", "function", "(", "e.g.", "support", "vector", "machine", "loss", ")", ",", "which", "is", "easier", "to", "optimise", ",", "or", "by", "applying", "assumptions", "on", "the", "distribution", "mathP", "(", "x", ",", "y", ")", "/", "math", "(", "and", "thus", "ceasing", "to", "be", "agnostic", "learning", "algorithms", ",", "which", "are", "subject", "to", "the", "result", "above", ")", "."], "sentence-detokenized": "In practice, machine learning algorithms deal with this either by applying a convex approximation of the 0-1 loss function (e.g. support vector machine loss), which is easier to optimise, or by applying assumptions on the distribution mathP (x, y)/math (and thus ceasing to be agnostic learning algorithms, which are subject to the result above).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 29], [30, 40], [41, 45], [46, 50], [51, 55], [56, 62], [63, 65], [66, 74], [75, 76], [77, 83], [84, 97], [98, 100], [101, 104], [105, 106], [106, 107], [107, 108], [109, 113], [114, 122], [123, 124], [124, 128], [129, 136], [137, 143], [144, 151], [152, 156], [156, 157], [157, 158], [159, 164], [165, 167], [168, 174], [175, 177], [178, 186], [186, 187], [188, 190], [191, 193], [194, 202], [203, 214], [215, 217], [218, 221], [222, 234], [235, 240], [241, 242], [242, 243], [243, 244], [245, 246], [246, 247], [247, 248], [248, 252], [253, 254], [254, 257], [258, 262], [263, 270], [271, 273], [274, 276], [277, 285], [286, 294], [295, 305], [305, 306], [307, 312], [313, 316], [317, 324], [325, 327], [328, 331], [332, 338], [339, 344], [344, 345], [345, 346]]}
{"doc_key": "ai-dev-284", "ner": [[0, 1, "misc"], [12, 14, "field"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 12, 14, "usage", "", false, false], [0, 1, 22, 23, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["\"", "Westworld", "(", "1973", ")", "was", "the", "first", "feature", "film", "to", "use", "digital", "image", "processing", "for", "photography", "to", "simulate", "the", "attitude", "of", "an", "android", "."], "sentence-detokenized": "\"Westworld (1973) was the first feature film to use digital image processing for photography to simulate the attitude of an android.", "token2charspan": [[0, 1], [1, 10], [11, 12], [12, 16], [16, 17], [18, 21], [22, 25], [26, 31], [32, 39], [40, 44], [45, 47], [48, 51], [52, 59], [60, 65], [66, 76], [77, 80], [81, 92], [93, 95], [96, 104], [105, 108], [109, 117], [118, 120], [121, 123], [124, 131], [131, 132]]}
{"doc_key": "ai-dev-285", "ner": [[7, 8, "task"], [10, 11, "task"], [13, 13, "task"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "now", "also", "commonly", "used", "in", "speech", "recognition", ",", "speech", "synthesis", ",", "diarisation", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "It is now also commonly used in speech recognition, speech synthesis, diarisation, Xavier Anguera et al.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 14], [15, 23], [24, 28], [29, 31], [32, 38], [39, 50], [50, 51], [52, 58], [59, 68], [68, 69], [70, 81], [81, 82], [83, 89], [90, 97], [98, 100], [101, 103], [103, 104]]}
{"doc_key": "ai-dev-286", "ner": [[9, 17, "algorithm"], [22, 23, "algorithm"], [26, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 23, 9, 17, "type-of", "", false, false], [26, 28, 9, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Here", ",", "math", "/", "sigma", "/", "math", "is", "the", "activation", "function", "in", "terms", "of", "the", "number", "of", "elements", ",", "for", "example", "the", "sigma", "function", "or", "the", "rectified", "linear", "unit", "."], "sentence-detokenized": "Here, math/sigma/math is the activation function in terms of the number of elements, for example the sigma function or the rectified linear unit.", "token2charspan": [[0, 4], [4, 5], [6, 10], [10, 11], [11, 16], [16, 17], [17, 21], [22, 24], [25, 28], [29, 39], [40, 48], [49, 51], [52, 57], [58, 60], [61, 64], [65, 71], [72, 74], [75, 83], [83, 84], [85, 88], [89, 96], [97, 100], [101, 106], [107, 115], [116, 118], [119, 122], [123, 132], [133, 139], [140, 144], [144, 145]]}
{"doc_key": "ai-dev-287", "ner": [[8, 11, "algorithm"], [20, 20, "misc"], [22, 22, "misc"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "phonetic", "(", "i.e.", "all", "models", "based", "on", "the", "hidden", "Markov", "model", ")", "approaches", "required", "separate", "components", "and", "training", "for", "pronunciation", ",", "acoustic", "and", "speech", "models", "."], "sentence-detokenized": "Traditional phonetic (i.e. all models based on the hidden Markov model) approaches required separate components and training for pronunciation, acoustic and speech models.", "token2charspan": [[0, 11], [12, 20], [21, 22], [22, 26], [27, 30], [31, 37], [38, 43], [44, 46], [47, 50], [51, 57], [58, 64], [65, 70], [70, 71], [72, 82], [83, 91], [92, 100], [101, 111], [112, 115], [116, 124], [125, 128], [129, 142], [142, 143], [144, 152], [153, 156], [157, 163], [164, 170], [170, 171]]}
{"doc_key": "ai-dev-288", "ner": [[0, 3, "algorithm"], [7, 8, "field"], [10, 11, "field"], [12, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 12, 14, "related-to", "used_for", false, false], [7, 8, 0, 3, "usage", "", false, false], [10, 11, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Roberts", "Cross", "Operator", "is", "used", "in", "image", "processing", "and", "computer", "vision", "to", "detect", "edges", "."], "sentence-detokenized": "The Roberts Cross Operator is used in image processing and computer vision to detect edges.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 37], [38, 43], [44, 54], [55, 58], [59, 67], [68, 74], [75, 77], [78, 84], [85, 90], [90, 91]]}
{"doc_key": "ai-dev-289", "ner": [[0, 0, "metrics"], [2, 2, "metrics"], [23, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 23, 23, "opposite", "", false, false], [2, 2, 23, 23, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Sensitivity", "and", "specificity", "values", "do", "not", "depend", "on", "the", "percentage", "of", "positive", "cases", "in", "the", "study", "population", "(", "unlike", ",", "for", "example", ",", "accuracy", ")", "."], "sentence-detokenized": "Sensitivity and specificity values do not depend on the percentage of positive cases in the study population (unlike, for example, accuracy).", "token2charspan": [[0, 11], [12, 15], [16, 27], [28, 34], [35, 37], [38, 41], [42, 48], [49, 51], [52, 55], [56, 66], [67, 69], [70, 78], [79, 84], [85, 87], [88, 91], [92, 97], [98, 108], [109, 110], [110, 116], [116, 117], [118, 121], [122, 129], [129, 130], [131, 139], [139, 140], [140, 141]]}
{"doc_key": "ai-dev-290", "ner": [[2, 3, "algorithm"], [15, 19, "misc"], [8, 9, "researcher"], [11, 13, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 19, 2, 3, "topic", "", false, false], [15, 19, 8, 9, "artifact", "", false, false], [15, 19, 11, 13, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "perceptron", "models", "were", "greatly", "popularised", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "'s", "book", "Perceptrons", ",", "published", "in", "1969", "."], "sentence-detokenized": "However, perceptron models were greatly popularised by Marvin Minsky and Seymour Papert's book Perceptrons, published in 1969.", "token2charspan": [[0, 7], [7, 8], [9, 19], [20, 26], [27, 31], [32, 39], [40, 51], [52, 54], [55, 61], [62, 68], [69, 72], [73, 80], [81, 87], [87, 89], [90, 94], [95, 106], [106, 107], [108, 117], [118, 120], [121, 125], [125, 126]]}
{"doc_key": "ai-dev-291", "ner": [[3, 5, "conference"], [0, 0, "organisation"], [20, 22, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 20, 22, "topic", "", false, false], [0, 0, 3, 5, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["NIST", "'s", "annual", "Document", "Understanding", "Conferences", "have", "developed", "sophisticated", "evaluation", "criteria", "for", "assessing", "methods", "that", "take", "on", "the", "challenge", "of", "summarising", "multiple", "documents", "."], "sentence-detokenized": "NIST's annual Document Understanding Conferences have developed sophisticated evaluation criteria for assessing methods that take on the challenge of summarising multiple documents.", "token2charspan": [[0, 4], [4, 6], [7, 13], [14, 22], [23, 36], [37, 48], [49, 53], [54, 63], [64, 77], [78, 88], [89, 97], [98, 101], [102, 111], [112, 119], [120, 124], [125, 129], [130, 132], [133, 136], [137, 146], [147, 149], [150, 161], [162, 170], [171, 180], [180, 181]]}
{"doc_key": "ai-dev-292", "ner": [[0, 2, "product"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 21, 23, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "parallel", "manipulator", "is", "designed", "so", "that", "each", "circuit", "is", "generally", "short", ",", "simple", "and", "can", "therefore", "be", "rigid", "compared", "to", "a", "serial", "manipulator", "."], "sentence-detokenized": "The parallel manipulator is designed so that each circuit is generally short, simple and can therefore be rigid compared to a serial manipulator.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 27], [28, 36], [37, 39], [40, 44], [45, 49], [50, 57], [58, 60], [61, 70], [71, 76], [76, 77], [78, 84], [85, 88], [89, 92], [93, 102], [103, 105], [106, 111], [112, 120], [121, 123], [124, 125], [126, 132], [133, 144], [144, 145]]}
{"doc_key": "ai-dev-293", "ner": [[25, 25, "misc"], [27, 31, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "manipulator", "is", "what", "makes", "the", "robot", "move", ",", "and", "the", "design", "of", "these", "systems", "can", "be", "divided", "into", "several", "common", "types", ",", "such", "as", "SCARA", "and", "Cartesian", "coordinate", "robots", ",", "which", "use", "different", "coordinate", "systems", "to", "guide", "the", "machine", "'s", "arms", "."], "sentence-detokenized": "The manipulator is what makes the robot move, and the design of these systems can be divided into several common types, such as SCARA and Cartesian coordinate robots, which use different coordinate systems to guide the machine's arms.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 23], [24, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 49], [50, 53], [54, 60], [61, 63], [64, 69], [70, 77], [78, 81], [82, 84], [85, 92], [93, 97], [98, 105], [106, 112], [113, 118], [118, 119], [120, 124], [125, 127], [128, 133], [134, 137], [138, 147], [148, 158], [159, 165], [165, 166], [167, 172], [173, 176], [177, 186], [187, 197], [198, 205], [206, 208], [209, 214], [215, 218], [219, 226], [226, 228], [229, 233], [233, 234]]}
{"doc_key": "ai-dev-294", "ner": [[0, 3, "country"], [10, 14, "organisation"], [17, 24, "organisation"], [25, 28, "organisation"], [31, 33, "organisation"], [36, 42, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 14, 0, 3, "physical", "", false, false], [17, 24, 0, 3, "physical", "", false, false], [25, 28, 0, 3, "physical", "", false, false], [31, 33, 0, 3, "physical", "", false, false], [36, 42, 0, 3, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "United", "States", ",", "he", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "Linguistic", "Society", "of", "America", ",", "the", "American", "Philosophical", "Association", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In the United States, he is a member of the National Academy of Sciences, the American Academy of Arts and Sciences, the Linguistic Society of America, the American Philosophical Association and the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 20], [20, 21], [22, 24], [25, 27], [28, 29], [30, 36], [37, 39], [40, 43], [44, 52], [53, 60], [61, 63], [64, 72], [72, 73], [74, 77], [78, 86], [87, 94], [95, 97], [98, 102], [103, 106], [107, 115], [115, 116], [117, 120], [121, 131], [132, 139], [140, 142], [143, 150], [150, 151], [152, 155], [156, 164], [165, 178], [179, 190], [191, 194], [195, 198], [199, 207], [208, 219], [220, 223], [224, 227], [228, 239], [240, 242], [243, 250], [250, 251]]}
{"doc_key": "ai-dev-295", "ner": [[8, 11, "algorithm"], [13, 15, "algorithm"], [24, 25, "algorithm"], [28, 29, "algorithm"], [34, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 11, 24, 25, "named", "", false, false], [13, 15, 8, 11, "named", "", false, false], [24, 25, 28, 29, "compare", "", false, false], [24, 25, 34, 35, "related-to", "performs", false, false], [28, 29, 34, 35, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Their", "popularity", "grew", "out", "of", "the", "popularity", "of", "the", "support", "vector", "machine", "(", "SVM", ")", "in", "the", "1990s", ",", "when", "it", "was", "found", "that", "SVMs", "could", "compete", "with", "neural", "networks", "in", "tasks", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "Their popularity grew out of the popularity of the support vector machine (SVM) in the 1990s, when it was found that SVMs could compete with neural networks in tasks such as handwriting recognition.", "token2charspan": [[0, 5], [6, 16], [17, 21], [22, 25], [26, 28], [29, 32], [33, 43], [44, 46], [47, 50], [51, 58], [59, 65], [66, 73], [74, 75], [75, 78], [78, 79], [80, 82], [83, 86], [87, 92], [92, 93], [94, 98], [99, 101], [102, 105], [106, 111], [112, 116], [117, 121], [122, 127], [128, 135], [136, 140], [141, 147], [148, 156], [157, 159], [160, 165], [166, 170], [171, 173], [174, 185], [186, 197], [197, 198]]}
{"doc_key": "ai-dev-296", "ner": [[2, 3, "misc"], [9, 11, "misc"], [12, 13, "algorithm"], [22, 25, "misc"], [26, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 11, "usage", "", false, false], [2, 3, 22, 25, "usage", "", false, false], [9, 11, 12, 13, "origin", "result_of_algorithm", false, false], [22, 25, 26, 27, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "empirical", "whitening", "transformation", "is", "obtained", "by", "estimating", "the", "covariance", "(", "e.g.", "maximum", "likelihood", "method", ")", "and", "then", "constructing", "the", "corresponding", "estimated", "whitening", "matrix", "(", "e.g.", "Cholesky", "decomposition", "method", ")", "."], "sentence-detokenized": "The empirical whitening transformation is obtained by estimating the covariance (e.g. maximum likelihood method) and then constructing the corresponding estimated whitening matrix (e.g. Cholesky decomposition method).", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 38], [39, 41], [42, 50], [51, 53], [54, 64], [65, 68], [69, 79], [80, 81], [81, 85], [86, 93], [94, 104], [105, 111], [111, 112], [113, 116], [117, 121], [122, 134], [135, 138], [139, 152], [153, 162], [163, 172], [173, 179], [180, 181], [181, 185], [186, 194], [195, 208], [209, 215], [215, 216], [216, 217]]}
{"doc_key": "ai-dev-297", "ner": [[0, 0, "organisation"], [8, 10, "product"], [23, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 0, 0, "artifact", "", false, false], [23, 24, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "is", "the", "world", "'s", "largest", "manufacturer", "of", "Cartesian", "coordinate", "robots", "and", "a", "recognised", "leader", "in", "low", "-", "cost", ",", "high", "-", "performance", "SCARA", "robots", "."], "sentence-detokenized": "IAI is the world's largest manufacturer of Cartesian coordinate robots and a recognised leader in low-cost, high-performance SCARA robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [16, 18], [19, 26], [27, 39], [40, 42], [43, 52], [53, 63], [64, 70], [71, 74], [75, 76], [77, 87], [88, 94], [95, 97], [98, 101], [101, 102], [102, 106], [106, 107], [108, 112], [112, 113], [113, 124], [125, 130], [131, 137], [137, 138]]}
{"doc_key": "ai-dev-298", "ner": [[10, 11, "field"], [13, 14, "field"], [16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [26, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formal", "concept", "analysis", "has", "practical", "applications", "in", "areas", "such", "as", "data", "mining", ",", "text", "mining", ",", "machine", "learning", ",", "knowledge", "management", ",", "semantic", "web", ",", "software", "development", ",", "chemistry", "and", "biology", "."], "sentence-detokenized": "Formal concept analysis has practical applications in areas such as data mining, text mining, machine learning, knowledge management, semantic web, software development, chemistry and biology.", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 27], [28, 37], [38, 50], [51, 53], [54, 59], [60, 64], [65, 67], [68, 72], [73, 79], [79, 80], [81, 85], [86, 92], [92, 93], [94, 101], [102, 110], [110, 111], [112, 121], [122, 132], [132, 133], [134, 142], [143, 146], [146, 147], [148, 156], [157, 168], [168, 169], [170, 179], [180, 183], [184, 191], [191, 192]]}
{"doc_key": "ai-dev-299", "ner": [[0, 2, "field"], [4, 6, "field"], [10, 11, "field"], [17, 19, "field"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 17, 19, "part-of", "", false, false], [4, 6, 26, 27, "topic", "", false, false], [10, 11, 4, 6, "named", "", false, false], [17, 19, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", ",", "machine", "learning", "theory", "(", "or", "simply", "learning", "theory", ")", "is", "a", "branch", "of", "artificial", "intelligence", "dedicated", "to", "the", "design", "and", "analysis", "of", "machine", "learning", "algorithms", "."], "sentence-detokenized": "In computer science, machine learning theory (or simply learning theory) is a branch of artificial intelligence dedicated to the design and analysis of machine learning algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 28], [29, 37], [38, 44], [45, 46], [46, 48], [49, 55], [56, 64], [65, 71], [71, 72], [73, 75], [76, 77], [78, 84], [85, 87], [88, 98], [99, 111], [112, 121], [122, 124], [125, 128], [129, 135], [136, 139], [140, 148], [149, 151], [152, 159], [160, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-dev-300", "ner": [[0, 1, "algorithm"], [3, 3, "algorithm"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 1, "named", "", false, false], [10, 10, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Collaborative", "filtering", "(", "CF", ")", "is", "a", "technique", "used", "in", "recommender", "systems", "."], "sentence-detokenized": "Collaborative filtering (CF) is a technique used in recommender systems.", "token2charspan": [[0, 13], [14, 23], [24, 25], [25, 27], [27, 28], [29, 31], [32, 33], [34, 43], [44, 48], [49, 51], [52, 63], [64, 71], [71, 72]]}
{"doc_key": "ai-dev-301", "ner": [[0, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "false", "positive", "rate", "is", "the", "proportion", "of", "all", "negative", "results", "that", "are", "still", "positive", ",", "i.e.", "the", "conditional", "probability", "of", "a", "positive", "test", "result", "if", "the", "event", "did", "not", "occur", "."], "sentence-detokenized": "The false positive rate is the proportion of all negative results that are still positive, i.e. the conditional probability of a positive test result if the event did not occur.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 23], [24, 26], [27, 30], [31, 41], [42, 44], [45, 48], [49, 57], [58, 65], [66, 70], [71, 74], [75, 80], [81, 89], [89, 90], [91, 95], [96, 99], [100, 111], [112, 123], [124, 126], [127, 128], [129, 137], [138, 142], [143, 149], [150, 152], [153, 156], [157, 162], [163, 166], [167, 170], [171, 176], [176, 177]]}
{"doc_key": "ai-dev-302", "ner": [[1, 15, "misc"], [38, 44, "metrics"], [43, 43, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 15, 38, 44, "topic", "", false, false], [1, 15, 43, 43, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "VLDB", "'", "8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pp.", "422--433", ".", "showed", "that", "the", "reported", "values", "of", "mathC", "/", "math", "and", "mathK", "/", "math", "tend", "to", "indicate", "relatively", "low", "accuracy", "of", "the", "iteratively", "computed", "SimRank", "score", "."], "sentence-detokenized": "In VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, pp. 422--433. showed that the reported values of mathC/math and mathK/math tend to indicate relatively low accuracy of the iteratively computed SimRank score.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [10, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 79], [80, 85], [85, 86], [87, 90], [91, 99], [99, 100], [101, 107], [108, 112], [113, 116], [117, 125], [126, 132], [133, 135], [136, 141], [141, 142], [142, 146], [147, 150], [151, 156], [156, 157], [157, 161], [162, 166], [167, 169], [170, 178], [179, 189], [190, 193], [194, 202], [203, 205], [206, 209], [210, 221], [222, 230], [231, 238], [239, 244], [244, 245]]}
{"doc_key": "ai-dev-303", "ner": [[5, 7, "misc"], [8, 8, "misc"], [14, 15, "person"], [17, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 5, 7, "general-affiliation", "", false, false], [8, 8, 14, 15, "artifact", "", false, false], [8, 8, 17, 19, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "June", "2015", ",", "the", "science", "fiction", "drama", "Sense8", ",", "written", "and", "produced", "by", "the", "Wachowskis", "and", "J.", "Michael", "Straczynski", ",", "debuted", "."], "sentence-detokenized": "In June 2015, the science fiction drama Sense8, written and produced by the Wachowskis and J. Michael Straczynski, debuted.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 25], [26, 33], [34, 39], [40, 46], [46, 47], [48, 55], [56, 59], [60, 68], [69, 71], [72, 75], [76, 86], [87, 90], [91, 93], [94, 101], [102, 113], [113, 114], [115, 122], [122, 123]]}
{"doc_key": "ai-dev-304", "ner": [[1, 1, "misc"], [6, 9, "product"], [24, 28, "misc"], [36, 36, "country"], [38, 38, "country"], [40, 40, "country"], [42, 42, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 1, 6, 9, "topic", "", false, false], [36, 36, 24, 28, "type-of", "", false, false], [38, 38, 24, 28, "type-of", "", false, false], [40, 40, 24, 28, "type-of", "", false, false], [42, 42, 24, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Although", "Eurotra", "never", "delivered", "a", "working", "MT", "system", ",", "the", "project", "has", "had", "a", "significant", "long", "-", "term", "impact", "on", "the", "emerging", "language", "industry", "in", "the", "European", "Member", "States", ",", "particularly", "in", "the", "southern", "countries", "of", "Greece", ",", "Italy", ",", "Spain", "and", "Portugal", "."], "sentence-detokenized": "Although Eurotra never delivered a working MT system, the project has had a significant long-term impact on the emerging language industry in the European Member States, particularly in the southern countries of Greece, Italy, Spain and Portugal.", "token2charspan": [[0, 8], [9, 16], [17, 22], [23, 32], [33, 34], [35, 42], [43, 45], [46, 52], [52, 53], [54, 57], [58, 65], [66, 69], [70, 73], [74, 75], [76, 87], [88, 92], [92, 93], [93, 97], [98, 104], [105, 107], [108, 111], [112, 120], [121, 129], [130, 138], [139, 141], [142, 145], [146, 154], [155, 161], [162, 168], [168, 169], [170, 182], [183, 185], [186, 189], [190, 198], [199, 208], [209, 211], [212, 218], [218, 219], [220, 225], [225, 226], [227, 232], [233, 236], [237, 245], [245, 246]]}
{"doc_key": "ai-dev-305", "ner": [[0, 3, "algorithm"], [8, 12, "task"], [18, 20, "task"], [22, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 12, 0, 3, "usage", "", true, false], [18, 20, 8, 12, "named", "", false, false], [22, 22, 18, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "automatic", "encoder", "has", "been", "successfully", "applied", "to", "machine", "translation", "of", "human", "languages", ",", "commonly", "referred", "to", "as", "neural", "machine", "translation", "(", "NMT", ")", "."], "sentence-detokenized": "The automatic encoder has been successfully applied to machine translation of human languages, commonly referred to as neural machine translation (NMT).", "token2charspan": [[0, 3], [4, 13], [14, 21], [22, 25], [26, 30], [31, 43], [44, 51], [52, 54], [55, 62], [63, 74], [75, 77], [78, 83], [84, 93], [93, 94], [95, 103], [104, 112], [113, 115], [116, 118], [119, 125], [126, 133], [134, 145], [146, 147], [147, 150], [150, 151], [151, 152]]}
{"doc_key": "ai-dev-306", "ner": [[9, 11, "metrics"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "examples", "of", "probability", "-", "based", "fitness", "functions", "are", "maximum", "likelihood", "estimation", "and", "pivot", "loss", "."], "sentence-detokenized": "Popular examples of probability-based fitness functions are maximum likelihood estimation and pivot loss.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 31], [31, 32], [32, 37], [38, 45], [46, 55], [56, 59], [60, 67], [68, 78], [79, 89], [90, 93], [94, 99], [100, 104], [104, 105]]}
{"doc_key": "ai-dev-307", "ner": [[0, 1, "field"], [11, 13, "task"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 13, 0, 1, "part-of", "", false, false], [15, 16, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "mining", "is", "a", "related", "field", "of", "study", "that", "focuses", "on", "exploratory", "data", "analysis", "through", "unsupervised", "learning", "."], "sentence-detokenized": "Data mining is a related field of study that focuses on exploratory data analysis through unsupervised learning.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 33], [34, 39], [40, 44], [45, 52], [53, 55], [56, 67], [68, 72], [73, 81], [82, 89], [90, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-dev-308", "ner": [[0, 1, "algorithm"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "involves", "methods", "for", "selecting", "people", "with", "similar", "interests", "to", "build", "a", "recommendation", "system", "."], "sentence-detokenized": "Collaborative filtering involves methods for selecting people with similar interests to build a recommendation system.", "token2charspan": [[0, 13], [14, 23], [24, 32], [33, 40], [41, 44], [45, 54], [55, 61], [62, 66], [67, 74], [75, 84], [85, 87], [88, 93], [94, 95], [96, 110], [111, 117], [117, 118]]}
{"doc_key": "ai-dev-309", "ner": [[1, 8, "algorithm"], [11, 11, "programlang"], [13, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 1, 8, "type-of", "", false, false], [13, 16, 11, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Several", "WordNet", "-", "based", "word", "similarity", "algorithms", "are", "implemented", "in", "the", "Perl", "package", "WordNet", ":", ":", "Similarity", "."], "sentence-detokenized": "Several WordNet-based word similarity algorithms are implemented in the Perl package WordNet:: Similarity.", "token2charspan": [[0, 7], [8, 15], [15, 16], [16, 21], [22, 26], [27, 37], [38, 48], [49, 52], [53, 64], [65, 67], [68, 71], [72, 76], [77, 84], [85, 92], [92, 93], [93, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-310", "ner": [[14, 16, "conference"], [4, 5, "researcher"], [7, 8, "researcher"], [10, 20, "researcher"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[4, 5, 14, 16, "temporal", "", false, false], [7, 8, 14, 16, "temporal", "", false, false], [10, 20, 14, 16, "temporal", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Another", "paper", "presented", "by", "Erik", "Miller", ",", "Nicholas", "Matsakis", "and", "Paul", "Viola", "at", "the", "CVPR", "in", "2000", "will", "also", "be", "discussed", "."], "sentence-detokenized": "Another paper presented by Erik Miller, Nicholas Matsakis and Paul Viola at the CVPR in 2000 will also be discussed.", "token2charspan": [[0, 7], [8, 13], [14, 23], [24, 26], [27, 31], [32, 38], [38, 39], [40, 48], [49, 57], [58, 61], [62, 66], [67, 72], [73, 75], [76, 79], [80, 84], [85, 87], [88, 92], [93, 97], [98, 102], [103, 105], [106, 115], [115, 116]]}
{"doc_key": "ai-dev-311", "ner": [[0, 0, "algorithm"], [7, 10, "misc"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 15, 16, "compare", "", false, false], [15, 16, 7, 10, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["QC", "was", "not", "assessed", "by", "traditional", "modern", "clustering", "algorithms", ",", "with", "the", "exception", "of", "the", "Jaccard", "index", "."], "sentence-detokenized": "QC was not assessed by traditional modern clustering algorithms, with the exception of the Jaccard index.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 19], [20, 22], [23, 34], [35, 41], [42, 52], [53, 63], [63, 64], [65, 69], [70, 73], [74, 83], [84, 86], [87, 90], [91, 98], [99, 104], [104, 105]]}
{"doc_key": "ai-dev-312", "ner": [[2, 7, "misc"], [8, 10, "misc"], [13, 15, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 2, 7, "physical", "", false, false], [8, 10, 13, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "the", "VEX", "Robotics", "World", "Championships", ",", "a", "Parade", "of", "Nations", "takes", "place", "in", "Freedom", "Hall", ",", "with", "hundreds", "of", "students", "from", "more", "than", "30", "countries", "."], "sentence-detokenized": "During the VEX Robotics World Championships, a Parade of Nations takes place in Freedom Hall, with hundreds of students from more than 30 countries.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 23], [24, 29], [30, 43], [43, 44], [45, 46], [47, 53], [54, 56], [57, 64], [65, 70], [71, 76], [77, 79], [80, 87], [88, 92], [92, 93], [94, 98], [99, 107], [108, 110], [111, 119], [120, 124], [125, 129], [130, 134], [135, 137], [138, 147], [147, 148]]}
{"doc_key": "ai-dev-313", "ner": [[4, 7, "metrics"], [9, 9, "metrics"], [12, 14, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 4, 7, "named", "", false, false], [16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Other", "accuracy", "indicators", "include", "Single", "Word", "Error", "Rate", "(", "SWER", ")", "and", "Command", "Success", "Rate", "(", "CSR", ")", "."], "sentence-detokenized": "Other accuracy indicators include Single Word Error Rate (SWER) and Command Success Rate (CSR).", "token2charspan": [[0, 5], [6, 14], [15, 25], [26, 33], [34, 40], [41, 45], [46, 51], [52, 56], [57, 58], [58, 62], [62, 63], [64, 67], [68, 75], [76, 83], [84, 88], [89, 90], [90, 93], [93, 94], [94, 95]]}
{"doc_key": "ai-dev-314", "ner": [[7, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "presented", "their", "approach", "and", "results", "at", "SIGGRAPH", "2000", "."], "sentence-detokenized": "They presented their approach and results at SIGGRAPH 2000.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 29], [30, 33], [34, 41], [42, 44], [45, 53], [54, 58], [58, 59]]}
{"doc_key": "ai-dev-315", "ner": [[0, 2, "conference"], [7, 7, "misc"], [9, 13, "misc"], [16, 20, "conference"], [24, 30, "researcher"], [39, 40, "researcher"], [44, 46, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 7, 7, "origin", "", false, false], [7, 7, 16, 20, "physical", "", false, false], [7, 7, 16, 20, "temporal", "", false, false], [7, 7, 24, 30, "origin", "", false, false], [7, 7, 39, 40, "origin", "", false, false], [9, 13, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "KDD", "conference", "grew", "out", "of", "the", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "workshops", "at", "AAAI", "conferences", ",", "which", "were", "started", "by", "Gregory", "I", ".", "Piatetsky", "-", "Shapiro", "in", "1989", ",", "1991", "and", "1993", ",", "and", "by", "Usama", "Fayyad", "in", "1994", ".", "Machines", "|", "ACM", "."], "sentence-detokenized": "The KDD conference grew out of the KDD (Knowledge Discovery and Data Mining) workshops at AAAI conferences, which were started by Gregory I. Piatetsky-Shapiro in 1989, 1991 and 1993, and by Usama Fayyad in 1994. Machines | ACM.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 23], [24, 27], [28, 30], [31, 34], [35, 38], [39, 40], [40, 49], [50, 59], [60, 63], [64, 68], [69, 75], [75, 76], [77, 86], [87, 89], [90, 94], [95, 106], [106, 107], [108, 113], [114, 118], [119, 126], [127, 129], [130, 137], [138, 139], [139, 140], [141, 150], [150, 151], [151, 158], [159, 161], [162, 166], [166, 167], [168, 172], [173, 176], [177, 181], [181, 182], [183, 186], [187, 189], [190, 195], [196, 202], [203, 205], [206, 210], [210, 211], [212, 220], [221, 222], [223, 226], [226, 227]]}
{"doc_key": "ai-dev-316", "ner": [[8, 11, "conference"], [13, 13, "conference"], [17, 22, "organisation"], [24, 24, "organisation"], [28, 32, "conference"], [34, 34, "conference"], [38, 44, "conference"], [46, 46, "conference"], [50, 56, "conference"], [58, 58, "conference"], [63, 68, "conference"], [70, 70, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[13, 13, 8, 11, "named", "", false, false], [24, 24, 17, 22, "named", "", false, false], [34, 34, 28, 32, "named", "", false, false], [46, 46, 38, 44, "named", "", false, false], [58, 58, 50, 56, "named", "", false, false], [70, 70, 63, 68, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "has", "been", "elected", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "(", "AAAS", ")", ",", "and", "the", "Society", "for", "Optics", "and", "Photonics", "Instrumentation", "(", "SPIE", ")", "."], "sentence-detokenized": "He has been elected a Fellow of the Association for Computing Machinery (ACM), the Institute of Electrical and Electronics Engineers (IEEE), the International Association for Pattern Recognition (IAPR), the Association for the Advancement of Artificial Intelligence (AAAI), the American Association for the Advancement of Science (AAAS), and the Society for Optics and Photonics Instrumentation (SPIE).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 21], [22, 28], [29, 31], [32, 35], [36, 47], [48, 51], [52, 61], [62, 71], [72, 73], [73, 76], [76, 77], [77, 78], [79, 82], [83, 92], [93, 95], [96, 106], [107, 110], [111, 122], [123, 132], [133, 134], [134, 138], [138, 139], [139, 140], [141, 144], [145, 158], [159, 170], [171, 174], [175, 182], [183, 194], [195, 196], [196, 200], [200, 201], [201, 202], [203, 206], [207, 218], [219, 222], [223, 226], [227, 238], [239, 241], [242, 252], [253, 265], [266, 267], [267, 271], [271, 272], [272, 273], [274, 277], [278, 286], [287, 298], [299, 302], [303, 306], [307, 318], [319, 321], [322, 329], [330, 331], [331, 335], [335, 336], [336, 337], [338, 341], [342, 345], [346, 353], [354, 357], [358, 364], [365, 368], [369, 378], [379, 394], [395, 396], [396, 400], [400, 401], [401, 402]]}
{"doc_key": "ai-dev-317", "ner": [[0, 1, "field"], [3, 4, "field"], [15, 16, "field"], [30, 34, "field"], [49, 54, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 15, 16, "named", "", false, false], [3, 4, 30, 34, "named", "", false, false], [30, 34, 49, 54, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "and", "data", "mining", "often", "use", "the", "same", "techniques", "and", "overlap", "substantially", ",", "but", "machine", "learning", "focuses", "on", "prediction", "based", "on", "known", "features", "learned", "from", "training", "data", ",", "while", "data", "mining", "focuses", "on", "the", "discovery", "of", "(", "previously", ")", "unknown", "features", "in", "the", "data", "(", "this", "is", "the", "knowledge", "discovery", "analysis", "phase", "of", "databases", ")", "."], "sentence-detokenized": "Machine learning and data mining often use the same techniques and overlap substantially, but machine learning focuses on prediction based on known features learned from training data, while data mining focuses on the discovery of (previously) unknown features in the data (this is the knowledge discovery analysis phase of databases).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 62], [63, 66], [67, 74], [75, 88], [88, 89], [90, 93], [94, 101], [102, 110], [111, 118], [119, 121], [122, 132], [133, 138], [139, 141], [142, 147], [148, 156], [157, 164], [165, 169], [170, 178], [179, 183], [183, 184], [185, 190], [191, 195], [196, 202], [203, 210], [211, 213], [214, 217], [218, 227], [228, 230], [231, 232], [232, 242], [242, 243], [244, 251], [252, 260], [261, 263], [264, 267], [268, 272], [273, 274], [274, 278], [279, 281], [282, 285], [286, 295], [296, 305], [306, 314], [315, 320], [321, 323], [324, 333], [333, 334], [334, 335]]}
{"doc_key": "ai-dev-318", "ner": [[0, 1, "product"], [5, 5, "programlang"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 5, 5, "general-affiliation", "", false, false], [0, 1, 5, 5, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["\"", "Indy", "is", "written", "in", "Java", ",", "so", "it", "works", "on", "most", "modern", "operating", "systems", "."], "sentence-detokenized": "\"Indy is written in Java, so it works on most modern operating systems.", "token2charspan": [[0, 1], [1, 5], [6, 8], [9, 16], [17, 19], [20, 24], [24, 25], [26, 28], [29, 31], [32, 37], [38, 40], [41, 45], [46, 52], [53, 62], [63, 70], [70, 71]]}
{"doc_key": "ai-dev-319", "ner": [[0, 0, "algorithm"], [5, 7, "algorithm"], [9, 9, "algorithm"], [15, 17, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 7, "type-of", "", true, false], [9, 9, 5, 7, "named", "", false, false], [15, 17, 5, 7, "type-of", "", true, false], [19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["NMF", "is", "a", "case", "of", "negative", "quadratic", "programming", "(", "NQP", ")", ",", "as", "is", "the", "support", "vector", "machine", "(", "SVM", ")", "."], "sentence-detokenized": "NMF is a case of negative quadratic programming (NQP), as is the support vector machine (SVM).", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 13], [14, 16], [17, 25], [26, 35], [36, 47], [48, 49], [49, 52], [52, 53], [53, 54], [55, 57], [58, 60], [61, 64], [65, 72], [73, 79], [80, 87], [88, 89], [89, 92], [92, 93], [93, 94]]}
{"doc_key": "ai-dev-320", "ner": [[8, 9, "misc"], [12, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 12, 14, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "method", "is", "based", "on", "the", "estimation", "of", "conditional", "probabilities", "using", "a", "non-parametric", "maximum", "likelihood", "method", ",", "which", "results", "in"], "sentence-detokenized": "The method is based on the estimation of conditional probabilities using a non-parametric maximum likelihood method, which results in", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 26], [27, 37], [38, 40], [41, 52], [53, 66], [67, 72], [73, 74], [75, 89], [90, 97], [98, 108], [109, 115], [115, 116], [117, 122], [123, 130], [131, 133]]}
{"doc_key": "ai-dev-321", "ner": [[6, 6, "algorithm"], [8, 10, "algorithm"], [12, 15, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Basic", "concepts", "of", "spectral", "estimation", ":", "autocorrelation", ",", "multiple", "Fourier", "transform", ",", "root", "mean", "square", "error", "and", "entropy", "."], "sentence-detokenized": "Basic concepts of spectral estimation: autocorrelation, multiple Fourier transform, root mean square error and entropy.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [27, 37], [37, 38], [39, 54], [54, 55], [56, 64], [65, 72], [73, 82], [82, 83], [84, 88], [89, 93], [94, 100], [101, 106], [107, 110], [111, 118], [118, 119]]}
{"doc_key": "ai-dev-322", "ner": [[2, 3, "algorithm"], [7, 7, "field"], [9, 9, "algorithm"], [11, 13, "algorithm"], [15, 16, "task"], [18, 18, "field"], [20, 20, "field"], [22, 23, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 3, 7, 7, "part-of", "", false, false], [2, 3, 9, 9, "part-of", "", false, false], [2, 3, 11, 13, "part-of", "", false, false], [2, 3, 15, 16, "part-of", "", false, false], [2, 3, 18, 18, "part-of", "", false, false], [2, 3, 20, 20, "part-of", "", false, false], [2, 3, 22, 23, "part-of", "", false, false], [2, 3, 25, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Applications", "of", "kernel", "methods", "are", "diverse", ":", "geostatistics", ",", "kriging", ",", "inverse", "distance", "estimation", ",", "3D", "reconstruction", ",", "bioinformatics", ",", "chemoinformatics", ",", "information", "extraction", "and", "handwriting", "recognition", "."], "sentence-detokenized": "Applications of kernel methods are diverse: geostatistics, kriging, inverse distance estimation, 3D reconstruction, bioinformatics, chemoinformatics, information extraction and handwriting recognition.", "token2charspan": [[0, 12], [13, 15], [16, 22], [23, 30], [31, 34], [35, 42], [42, 43], [44, 57], [57, 58], [59, 66], [66, 67], [68, 75], [76, 84], [85, 95], [95, 96], [97, 99], [100, 114], [114, 115], [116, 130], [130, 131], [132, 148], [148, 149], [150, 161], [162, 172], [173, 176], [177, 188], [189, 200], [200, 201]]}
{"doc_key": "ai-dev-323", "ner": [[12, 13, "organisation"], [14, 18, "product"], [20, 20, "product"], [23, 23, "organisation"], [24, 29, "product"], [31, 31, "product"], [35, 36, "product"], [38, 41, "product"], [43, 45, "product"], [47, 49, "product"], [53, 54, "product"], [56, 60, "product"], [64, 70, "product"], [74, 75, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[14, 18, 12, 13, "artifact", "", false, false], [14, 18, 35, 36, "compare", "", false, false], [14, 18, 38, 41, "compare", "", false, false], [14, 18, 43, 45, "compare", "", false, false], [14, 18, 47, 49, "compare", "", false, false], [14, 18, 53, 54, "compare", "", false, false], [14, 18, 56, 60, "compare", "", false, false], [14, 18, 64, 70, "compare", "", false, false], [14, 18, 74, 75, "compare", "", false, false], [20, 20, 14, 18, "named", "", false, false], [24, 29, 23, 23, "artifact", "", false, false], [24, 29, 35, 36, "compare", "", false, false], [24, 29, 38, 41, "compare", "", false, false], [24, 29, 43, 45, "compare", "", false, false], [24, 29, 47, 49, "compare", "", false, false], [24, 29, 53, 54, "compare", "", false, false], [24, 29, 56, 60, "compare", "", false, false], [24, 29, 64, 70, "compare", "", false, false], [24, 29, 74, 75, "compare", "", false, false], [31, 31, 24, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Robots", "can", "be", "autonomous", "or", "semi-autonomous", "and", "range", "from", "humanoids", "such", "as", "Honda", "'s", "Advanced", "Step", "for", "Innovative", "Mobility", "(", "ASIMO", ")", "and", "TOSY", "'s", "ping", "-", "pong", "playing", "robot", "(", "TOPIO", ")", ",", "to", "industrial", "robots", ",", "medical", "operating", "theatre", "robots", ",", "patient", "assistance", "robots", ",", "therapy", "dog", "robots", ",", "collectively", "programmable", "robotic", "teams", ",", "unmanned", "aerial", "vehicles", "(", "UAVs", ")", "such", "as", "General", "Atomics", "'", "MQ", "-", "1", "Predator", ",", "and", "even", "microscopic", "nanorobots", "."], "sentence-detokenized": "Robots can be autonomous or semi-autonomous and range from humanoids such as Honda's Advanced Step for Innovative Mobility (ASIMO) and TOSY's ping-pong playing robot (TOPIO), to industrial robots, medical operating theatre robots, patient assistance robots, therapy dog robots, collectively programmable robotic teams, unmanned aerial vehicles (UAVs) such as General Atomics' MQ-1 Predator, and even microscopic nanorobots.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 24], [25, 27], [28, 43], [44, 47], [48, 53], [54, 58], [59, 68], [69, 73], [74, 76], [77, 82], [82, 84], [85, 93], [94, 98], [99, 102], [103, 113], [114, 122], [123, 124], [124, 129], [129, 130], [131, 134], [135, 139], [139, 141], [142, 146], [146, 147], [147, 151], [152, 159], [160, 165], [166, 167], [167, 172], [172, 173], [173, 174], [175, 177], [178, 188], [189, 195], [195, 196], [197, 204], [205, 214], [215, 222], [223, 229], [229, 230], [231, 238], [239, 249], [250, 256], [256, 257], [258, 265], [266, 269], [270, 276], [276, 277], [278, 290], [291, 303], [304, 311], [312, 317], [317, 318], [319, 327], [328, 334], [335, 343], [344, 345], [345, 349], [349, 350], [351, 355], [356, 358], [359, 366], [367, 374], [374, 375], [376, 378], [378, 379], [379, 380], [381, 389], [389, 390], [391, 394], [395, 399], [400, 411], [412, 422], [422, 423]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 3, "product"], [19, 28, "university"], [8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 8, 9, "artifact", "", false, false], [0, 0, 11, 12, "artifact", "", false, false], [0, 0, 14, 15, "artifact", "", false, false], [0, 0, 17, 18, "artifact", "", false, false], [2, 3, 8, 9, "artifact", "", false, false], [2, 3, 11, 12, "artifact", "", false, false], [2, 3, 14, 15, "artifact", "", false, false], [2, 3, 17, 18, "artifact", "", false, false], [8, 9, 19, 28, "physical", "", false, false], [11, 12, 19, 28, "physical", "", false, false], [14, 15, 19, 28, "physical", "", false, false], [17, 18, 19, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "and", "Freddy", "II", "were", "robots", "built", "by", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "and", "Donald", "Mitchie", "at", "the", "School", "of", "Informatics", "at", "the", "University", "of", "Edinburgh", ",", "which", "could", "assemble", "wooden", "blocks", "in", "a", "few", "hours", "."], "sentence-detokenized": "Freddy and Freddy II were robots built by Pat Ambler, Robin Popplestone, Austin Tate and Donald Mitchie at the School of Informatics at the University of Edinburgh, which could assemble wooden blocks in a few hours.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 25], [26, 32], [33, 38], [39, 41], [42, 45], [46, 52], [52, 53], [54, 59], [60, 71], [71, 72], [73, 79], [80, 84], [85, 88], [89, 95], [96, 103], [104, 106], [107, 110], [111, 117], [118, 120], [121, 132], [133, 135], [136, 139], [140, 150], [151, 153], [154, 163], [163, 164], [165, 170], [171, 176], [177, 185], [186, 192], [193, 199], [200, 202], [203, 204], [205, 208], [209, 214], [214, 215]]}
{"doc_key": "ai-dev-325", "ner": [[5, 5, "location"], [7, 9, "country"], [14, 15, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 7, 9, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "spent", "his", "childhood", "in", "Paris", ",", "France", ",", "where", "his", "parents", "emigrated", "from", "Lithuania", "in", "the", "early", "1920s", "."], "sentence-detokenized": "He spent his childhood in Paris, France, where his parents emigrated from Lithuania in the early 1920s.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 22], [23, 25], [26, 31], [31, 32], [33, 39], [39, 40], [41, 46], [47, 50], [51, 58], [59, 68], [69, 73], [74, 83], [84, 86], [87, 90], [91, 96], [97, 102], [102, 103]]}
{"doc_key": "ai-dev-326", "ner": [[2, 3, "researcher"], [6, 11, "misc"], [16, 19, "organisation"], [12, 15, "university"], [26, 30, "university"], [34, 36, "university"], [39, 41, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 3, 6, 11, "role", "", false, false], [2, 3, 12, 15, "physical", "", false, false], [2, 3, 26, 30, "role", "", false, false], [2, 3, 34, 36, "role", "", false, false], [2, 3, 39, 41, "role", "", false, false], [6, 11, 16, 19, "part-of", "", false, false], [16, 19, 12, 15, "part-of", "", false, false], [34, 36, 26, 30, "part-of", "", false, false], [39, 41, 26, 30, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Previously", ",", "Dr", "Paulos", "held", "the", "Cooper-", "Siegel", "Associate", "Professor", "Chair", "at", "Carnegie", "Mellon", "University", "'s", "School", "of", "Computer", "Science", ",", "where", "he", "taught", "at", "the", "Human", "-", "Computer", "Interaction", "Institute", "and", "worked", "at", "the", "Robotics", "Institute", "and", "the", "Entertainment", "Technology", "Center", "."], "sentence-detokenized": "Previously, Dr Paulos held the Cooper-Siegel Associate Professor Chair at Carnegie Mellon University's School of Computer Science, where he taught at the Human-Computer Interaction Institute and worked at the Robotics Institute and the Entertainment Technology Center.", "token2charspan": [[0, 10], [10, 11], [12, 14], [15, 21], [22, 26], [27, 30], [31, 38], [38, 44], [45, 54], [55, 64], [65, 70], [71, 73], [74, 82], [83, 89], [90, 100], [100, 102], [103, 109], [110, 112], [113, 121], [122, 129], [129, 130], [131, 136], [137, 139], [140, 146], [147, 149], [150, 153], [154, 159], [159, 160], [160, 168], [169, 180], [181, 190], [191, 194], [195, 201], [202, 204], [205, 208], [209, 217], [218, 227], [228, 231], [232, 235], [236, 249], [250, 260], [261, 267], [267, 268]]}
{"doc_key": "ai-dev-327", "ner": [[3, 4, "researcher"], [6, 7, "university"], [10, 11, "product"], [18, 22, "product"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 6, 7, "physical", "", false, false], [3, 4, 6, 7, "role", "", false, false], [10, 11, 3, 4, "artifact", "", false, false], [10, 11, 18, 22, "type-of", "", false, false], [10, 11, 24, 25, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1969", ",", "Victor", "Scheinman", "of", "Stanford", "University", "invented", "the", "Stanford", "Arm", ",", "an", "all", "-", "electric", ",", "6", "-", "axis", "articulated", "robot", "for", "arm", "solving", "."], "sentence-detokenized": "In 1969, Victor Scheinman of Stanford University invented the Stanford Arm, an all-electric, 6-axis articulated robot for arm solving.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 25], [26, 28], [29, 37], [38, 48], [49, 57], [58, 61], [62, 70], [71, 74], [74, 75], [76, 78], [79, 82], [82, 83], [83, 91], [91, 92], [93, 94], [94, 95], [95, 99], [100, 111], [112, 117], [118, 121], [122, 125], [126, 133], [133, 134]]}
{"doc_key": "ai-dev-328", "ner": [[5, 7, "product"], [15, 16, "field"], [18, 22, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 15, 16, "related-to", "", false, false], [5, 7, 18, 22, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "development", "and", "deployment", "of", "chatbots", "is", "still", "an", "evolving", "field", ",", "closely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ",", "and", "the", "proposed", "solutions", ",", "while", "having", "obvious", "advantages", ",", "have", "some", "important", "limitations", "in", "terms", "of", "functionality", "and", "use", "cases", "."], "sentence-detokenized": "The development and deployment of chatbots is still an evolving field, closely related to artificial intelligence and machine learning, and the proposed solutions, while having obvious advantages, have some important limitations in terms of functionality and use cases.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 30], [31, 33], [34, 42], [43, 45], [46, 51], [52, 54], [55, 63], [64, 69], [69, 70], [71, 78], [79, 86], [87, 89], [90, 100], [101, 113], [114, 117], [118, 125], [126, 134], [134, 135], [136, 139], [140, 143], [144, 152], [153, 162], [162, 163], [164, 169], [170, 176], [177, 184], [185, 195], [195, 196], [197, 201], [202, 206], [207, 216], [217, 228], [229, 231], [232, 237], [238, 240], [241, 254], [255, 258], [259, 262], [263, 268], [268, 269]]}
{"doc_key": "ai-dev-329", "ner": [[7, 9, "university"], [11, 12, "product"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 7, 9, "part-of", "", true, false], [20, 21, 11, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "terms", "of", "freely", "available", "resources", ",", "Carnegie", "Mellon", "University", "'s", "Sphinx", "toolkit", "is", "one", "place", "to", "start", "learning", "about", "speech", "recognition", "and", "experimenting", "."], "sentence-detokenized": "In terms of freely available resources, Carnegie Mellon University's Sphinx toolkit is one place to start learning about speech recognition and experimenting.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 18], [19, 28], [29, 38], [38, 39], [40, 48], [49, 55], [56, 66], [66, 68], [69, 75], [76, 83], [84, 86], [87, 90], [91, 96], [97, 99], [100, 105], [106, 114], [115, 120], [121, 127], [128, 139], [140, 143], [144, 157], [157, 158]]}
{"doc_key": "ai-dev-330", "ner": [[2, 6, "misc"], [12, 17, "misc"], [19, 22, "misc"], [24, 31, "university"], [29, 29, "location"], [31, 31, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 6, 12, 17, "temporal", "", false, false], [19, 22, 12, 17, "named", "", false, false], [19, 22, 29, 29, "physical", "", false, false], [24, 31, 19, 22, "role", "", false, false], [29, 29, 31, 31, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "official", "RoboCup", "was", "preceded", "by", "the", "(", "often", "unrecognised", ")", "first", "International", "Microrobot", "World", "Cup", "Soccer", "Tournament", "(", "MIROSOT", ")", ",", "organised", "by", "KAIST", "in", "November", "1996", "in", "Taejon", ",", "Korea", "."], "sentence-detokenized": "The official RoboCup was preceded by the (often unrecognised) first International Microrobot World Cup Soccer Tournament (MIROSOT), organised by KAIST in November 1996 in Taejon, Korea.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 24], [25, 33], [34, 36], [37, 40], [41, 42], [42, 47], [48, 60], [60, 61], [62, 67], [68, 81], [82, 92], [93, 98], [99, 102], [103, 109], [110, 120], [121, 122], [122, 129], [129, 130], [130, 131], [132, 141], [142, 144], [145, 150], [151, 153], [154, 162], [163, 167], [168, 170], [171, 177], [177, 178], [179, 184], [184, 185]]}
{"doc_key": "ai-dev-331", "ner": [[5, 6, "metrics"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "standard", "pivot", "loss", "math", "(", "1-", "yf", "(", "x", ")", ")", "_", "+", "/", "math", "for", "signed", "data", ",", "the", "loss", "function", "math", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "math", "is", "introduced", "for", "unsigned", "data", "by", "allowing", "mathy", "=\\", "operator", "name", "{", "sign", "}", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "In addition to the standard pivot loss math (1-yf (x)) _ + / math for signed data, the loss function math (-1 | f (x) |) _ + / math is introduced for unsigned data by allowing mathy =\\ operator name {sign} {f (x)} / math.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 27], [28, 33], [34, 38], [39, 43], [44, 45], [45, 47], [47, 49], [50, 51], [51, 52], [52, 53], [53, 54], [55, 56], [57, 58], [59, 60], [61, 65], [66, 69], [70, 76], [77, 81], [81, 82], [83, 86], [87, 91], [92, 100], [101, 105], [106, 107], [107, 108], [108, 109], [110, 111], [112, 113], [114, 115], [115, 116], [116, 117], [118, 119], [119, 120], [121, 122], [123, 124], [125, 126], [127, 131], [132, 134], [135, 145], [146, 149], [150, 158], [159, 163], [164, 166], [167, 175], [176, 181], [182, 184], [185, 193], [194, 198], [199, 200], [200, 204], [204, 205], [206, 207], [207, 208], [209, 210], [210, 211], [211, 212], [212, 213], [214, 215], [216, 220], [220, 221]]}
{"doc_key": "ai-dev-332", "ner": [[4, 4, "misc"], [10, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 10, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "particular", ",", "the", "RLS", "is", "designed", "to", "minimise", "the", "root", "mean", "square", "error", "between", "the", "predicted", "values", "and", "the", "TRUE", "labels", ",", "taking", "into", "account", "regulation", "."], "sentence-detokenized": "In particular, the RLS is designed to minimise the root mean square error between the predicted values and the TRUE labels, taking into account regulation.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 22], [23, 25], [26, 34], [35, 37], [38, 46], [47, 50], [51, 55], [56, 60], [61, 67], [68, 73], [74, 81], [82, 85], [86, 95], [96, 102], [103, 106], [107, 110], [111, 115], [116, 122], [122, 123], [124, 130], [131, 135], [136, 143], [144, 154], [154, 155]]}
{"doc_key": "ai-dev-333", "ner": [[6, 8, "algorithm"], [11, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 11, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "essentially", "a", "combination", "of", "maximum", "likelihood", "estimation", "with", "a", "regulatory", "procedure", "that", "favours", "simpler", "models", "over", "more", "complex", "ones", "."], "sentence-detokenized": "This is essentially a combination of maximum likelihood estimation with a regulatory procedure that favours simpler models over more complex ones.", "token2charspan": [[0, 4], [5, 7], [8, 19], [20, 21], [22, 33], [34, 36], [37, 44], [45, 55], [56, 66], [67, 71], [72, 73], [74, 84], [85, 94], [95, 99], [100, 107], [108, 115], [116, 122], [123, 127], [128, 132], [133, 140], [141, 145], [145, 146]]}
{"doc_key": "ai-dev-334", "ner": [[0, 4, "metrics"], [9, 9, "metrics"], [11, 11, "metrics"], [13, 15, "misc"], [21, 22, "misc"], [45, 47, "algorithm"], [35, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 9, 0, 4, "named", "", false, false], [11, 11, 0, 4, "named", "", false, false], [13, 15, 21, 22, "related-to", "", false, false], [13, 15, 45, 47, "related-to", "ratio", false, false], [45, 47, 35, 38, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "true", "positive", "rate", "is", "also", "referred", "to", "as", "sensitivity", ",", "recall", "or", "probability", "of", "detection", "(", "measured", "up", "to", "the", "discrimination", "threshold", ")", "on", "the", "y", "-axis", "of", "the", "probability", "of", "detection", "and", "the", "probability", "of", "false", "alarm", "on", "the", "x-", "axis", "of", "the", "cumulative", "distribution", "function", "."], "sentence-detokenized": "The true positive rate is also referred to as sensitivity, recall or probability of detection (measured up to the discrimination threshold) on the y-axis of the probability of detection and the probability of false alarm on the x-axis of the cumulative distribution function.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 25], [26, 30], [31, 39], [40, 42], [43, 45], [46, 57], [57, 58], [59, 65], [66, 68], [69, 80], [81, 83], [84, 93], [94, 95], [95, 103], [104, 106], [107, 109], [110, 113], [114, 128], [129, 138], [138, 139], [140, 142], [143, 146], [147, 148], [148, 153], [154, 156], [157, 160], [161, 172], [173, 175], [176, 185], [186, 189], [190, 193], [194, 205], [206, 208], [209, 214], [215, 220], [221, 223], [224, 227], [228, 230], [230, 234], [235, 237], [238, 241], [242, 252], [253, 265], [266, 274], [274, 275]]}
{"doc_key": "ai-dev-335", "ner": [[1, 1, "misc"], [3, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 1, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "English", ",", "Word", "Net", "is", "an", "example", "of", "a", "semantic", "network", "."], "sentence-detokenized": "In English, WordNet is an example of a semantic network.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [16, 19], [20, 22], [23, 25], [26, 33], [34, 36], [37, 38], [39, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-dev-336", "ner": [[5, 8, "product"], [11, 12, "product"], [20, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 26, 5, 8, "usage", "", false, false], [20, 26, 11, 12, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "-", "term", "use", "of", "speech", "recognition", "software", "in", "combination", "with", "text", "editors", "has", "shown", "that", "patients", "who", "have", "undergone", "AVM", "resection", "of", "the", "brain", "benefit", "from", "short", "-", "term", "memory", "recovery", "."], "sentence-detokenized": "Long-term use of speech recognition software in combination with text editors has shown that patients who have undergone AVM resection of the brain benefit from short-term memory recovery.", "token2charspan": [[0, 4], [4, 5], [5, 9], [10, 13], [14, 16], [17, 23], [24, 35], [36, 44], [45, 47], [48, 59], [60, 64], [65, 69], [70, 77], [78, 81], [82, 87], [88, 92], [93, 101], [102, 105], [106, 110], [111, 120], [121, 124], [125, 134], [135, 137], [138, 141], [142, 147], [148, 155], [156, 160], [161, 166], [166, 167], [167, 171], [172, 178], [179, 187], [187, 188]]}
{"doc_key": "ai-dev-337", "ner": [[0, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "was", "edited", "by", "Ron", "Sun", ",", "Vasant", "Honavar", "and", "Gregg", "Oden", "(", "1999-2014", ")", "."], "sentence-detokenized": "It was edited by Ron Sun, Vasant Honavar and Gregg Oden (1999-2014).", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 20], [21, 24], [24, 25], [26, 32], [33, 40], [41, 44], [45, 50], [51, 55], [56, 57], [57, 66], [66, 67], [67, 68]]}
{"doc_key": "ai-dev-338", "ner": [[2, 8, "product"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 8, 11, 12, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "parallel", "manipulator", "differs", "from", "a", "serial", "manipulator", "in", "that", "the", "end", "-effector", "(", "or", "'", "arm", "'", ")", "of", "this", "link", "is", "directly", "connected", "to", "the", "base", "by", "a", "number", "of", "(", "usually", "three", "or", "six", ")", "separate", "and", "independent", "simultaneous", "links", "."], "sentence-detokenized": "A parallel manipulator differs from a serial manipulator in that the end-effector (or 'arm') of this link is directly connected to the base by a number of (usually three or six) separate and independent simultaneous links.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 30], [31, 35], [36, 37], [38, 44], [45, 56], [57, 59], [60, 64], [65, 68], [69, 72], [72, 81], [82, 83], [83, 85], [86, 87], [87, 90], [90, 91], [91, 92], [93, 95], [96, 100], [101, 105], [106, 108], [109, 117], [118, 127], [128, 130], [131, 134], [135, 139], [140, 142], [143, 144], [145, 151], [152, 154], [155, 156], [156, 163], [164, 169], [170, 172], [173, 176], [176, 177], [178, 186], [187, 190], [191, 202], [203, 215], [216, 221], [221, 222]]}
{"doc_key": "ai-dev-339", "ner": [[5, 7, "researcher"], [16, 17, "researcher"], [18, 20, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"], [28, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "dissertation", "advisor", "was", "Professor", "Cordell", "Green", "and", "his", "dissertation", "/", "oral", "committee", "consisted", "of", "Professors", "Edward", "Feigenbaum", ",", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", ",", "Herbert", "Simon", ",", "."], "sentence-detokenized": "His dissertation advisor was Professor Cordell Green and his dissertation/oral committee consisted of Professors Edward Feigenbaum, Joshua Lederberg, Paul Cohen, Allen Newell, Herbert Simon,.", "token2charspan": [[0, 3], [4, 16], [17, 24], [25, 28], [29, 38], [39, 46], [47, 52], [53, 56], [57, 60], [61, 73], [73, 74], [74, 78], [79, 88], [89, 98], [99, 101], [102, 112], [113, 119], [120, 130], [130, 131], [132, 138], [139, 148], [148, 149], [150, 154], [155, 160], [160, 161], [162, 167], [168, 174], [174, 175], [176, 183], [184, 189], [189, 190], [190, 191]]}
{"doc_key": "ai-dev-340", "ner": [[3, 5, "metrics"], [7, 10, "metrics"], [12, 14, "metrics"], [16, 18, "metrics"], [20, 24, "metrics"], [25, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "functions", "are", "mean", "square", "error", ",", "root", "mean", "square", "error", ",", "mean", "absolute", "error", ",", "relative", "square", "error", ",", "relative", "squared", "error", ",", "relative", "absolute", "error", "and", "others", "."], "sentence-detokenized": "These functions are mean square error, root mean square error, mean absolute error, relative square error, relative squared error, relative absolute error and others.", "token2charspan": [[0, 5], [6, 15], [16, 19], [20, 24], [25, 31], [32, 37], [37, 38], [39, 43], [44, 48], [49, 55], [56, 61], [61, 62], [63, 67], [68, 76], [77, 82], [82, 83], [84, 92], [93, 99], [100, 105], [105, 106], [107, 115], [116, 123], [124, 129], [129, 130], [131, 139], [140, 148], [149, 154], [155, 158], [159, 165], [165, 166]]}
{"doc_key": "ai-dev-341", "ner": [[2, 2, "programlang"], [4, 4, "programlang"], [6, 8, "programlang"]], "ner_mapping_to_source": [0, 1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Interfaces", "to", "Python", ",", "Java", "and", "MATLAB", "/", "OCTAVE", "are", "available", "."], "sentence-detokenized": "Interfaces to Python, Java and MATLAB/OCTAVE are available.", "token2charspan": [[0, 10], [11, 13], [14, 20], [20, 21], [22, 26], [27, 30], [31, 37], [37, 38], [38, 44], [45, 48], [49, 58], [58, 59]]}
{"doc_key": "ai-dev-342", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "MATLAB", "implementation", "can", "be", "found", "in", "."], "sentence-detokenized": "The MATLAB implementation can be found in.", "token2charspan": [[0, 3], [4, 10], [11, 25], [26, 29], [30, 32], [33, 38], [39, 41], [41, 42]]}
{"doc_key": "ai-dev-343", "ner": [[0, 5, "researcher"], [8, 9, "field"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 5, "origin", "", false, false], [8, 9, 13, 14, "origin", "", false, false], [8, 9, 16, 17, "origin", "", false, false], [8, 9, 19, 20, "origin", "", false, false], [8, 9, 22, 25, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "is", "one", "of", "the", "pioneers", "of", "artificial", "intelligence", ",", "along", "with", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", "and", "Herbert", "A", ".", "Simon", "."], "sentence-detokenized": "John McCarthy is one of the pioneers of artificial intelligence, along with Alan Turing, Marvin Minsky, Allen Newell and Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 36], [37, 39], [40, 50], [51, 63], [63, 64], [65, 70], [71, 75], [76, 80], [81, 87], [87, 88], [89, 95], [96, 102], [102, 103], [104, 109], [110, 116], [117, 120], [121, 128], [129, 130], [130, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-dev-344", "ner": [[10, 11, "product"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "parallel", "manipulator", "is", "a", "mechanical", "system", "that", "uses", "multiple", "serial", "manipulators", "to", "support", "a", "single", "platform", "or", "final", "execution", "step", "."], "sentence-detokenized": "A parallel manipulator is a mechanical system that uses multiple serial manipulators to support a single platform or final execution step.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 27], [28, 38], [39, 45], [46, 50], [51, 55], [56, 64], [65, 71], [72, 84], [85, 87], [88, 95], [96, 97], [98, 104], [105, 113], [114, 116], [117, 122], [123, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [3, 4, "task"], [7, 7, "product"], [9, 19, "product"], [27, 27, "misc"], [30, 30, "misc"], [33, 34, "misc"], [37, 42, "task"], [45, 47, "product"], [50, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 7, 0, 0, "part-of", "", false, false], [7, 7, 3, 4, "type-of", "", false, false], [9, 19, 7, 7, "named", "", false, false], [27, 27, 7, 7, "part-of", "", false, false], [30, 30, 7, 7, "part-of", "", false, false], [33, 34, 7, 7, "part-of", "", false, false], [37, 42, 7, 7, "part-of", "", false, false], [45, 47, 7, 7, "part-of", "", false, false], [50, 52, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "includes", "an", "information", "extraction", "system", "called", "ANNIE", "(", "A", "Nearly", "-", "New", "Information", "Extraction", "System", ")", ",", "which", "is", "a", "set", "of", "modules", "consisting", "of", "a", "tokeniser", ",", "a", "gazetteer", ",", "a", "sentence", "splitter", ",", "a", "part", "-", "of", "-", "speech", "tagger", ",", "a", "named", "entity", "recogniser", "and", "a", "cross", "-reference", "tagger", "."], "sentence-detokenized": "GATE includes an information extraction system called ANNIE (A Nearly-New Information Extraction System), which is a set of modules consisting of a tokeniser, a gazetteer, a sentence splitter, a part-of-speech tagger, a named entity recogniser and a cross-reference tagger.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 28], [29, 39], [40, 46], [47, 53], [54, 59], [60, 61], [61, 62], [63, 69], [69, 70], [70, 73], [74, 85], [86, 96], [97, 103], [103, 104], [104, 105], [106, 111], [112, 114], [115, 116], [117, 120], [121, 123], [124, 131], [132, 142], [143, 145], [146, 147], [148, 157], [157, 158], [159, 160], [161, 170], [170, 171], [172, 173], [174, 182], [183, 191], [191, 192], [193, 194], [195, 199], [199, 200], [200, 202], [202, 203], [203, 209], [210, 216], [216, 217], [218, 219], [220, 225], [226, 232], [233, 243], [244, 247], [248, 249], [250, 255], [255, 265], [266, 272], [272, 273]]}
{"doc_key": "ai-dev-346", "ner": [[3, 6, "university"], [10, 11, "country"], [7, 24, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "graduated", "from", "Moscow", "State", "University", "and", "left", "for", "the", "United", "States", "in", "November", "1978", ",", "following", "the", "personal", "intervention", "of", "Senator", "Edward", "M.", "Kennedy", "."], "sentence-detokenized": "He graduated from Moscow State University and left for the United States in November 1978, following the personal intervention of Senator Edward M. Kennedy.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 24], [25, 30], [31, 41], [42, 45], [46, 50], [51, 54], [55, 58], [59, 65], [66, 72], [73, 75], [76, 84], [85, 89], [89, 90], [91, 100], [101, 104], [105, 113], [114, 126], [127, 129], [130, 137], [138, 144], [145, 147], [148, 155], [155, 156]]}
{"doc_key": "ai-dev-347", "ner": [[4, 6, "organisation"], [9, 14, "misc"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 9, 14, "win-defeat", "", false, false], [9, 14, 18, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "the", "DeepMind", "AlphaGo", "team", "received", "the", "first", "IJCAI", "Marvin", "Minsky", "Medal", "for", "outstanding", "achievements", "in", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2017, the DeepMind AlphaGo team received the first IJCAI Marvin Minsky Medal for outstanding achievements in Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 21], [22, 29], [30, 34], [35, 43], [44, 47], [48, 53], [54, 59], [60, 66], [67, 73], [74, 79], [80, 83], [84, 95], [96, 108], [109, 111], [112, 122], [123, 135], [135, 136]]}
{"doc_key": "ai-dev-348", "ner": [[1, 2, "misc"], [5, 5, "misc"], [13, 14, "misc"], [16, 16, "misc"], [20, 20, "misc"]], "ner_mapping_to_source": [0, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "anomalous", "propagation", "pathways", "include", "tropospheric", "irregularities", ",", "meteor", "scattering", ",", "refraction", "from", "ionised", "regions", "and", "ionospheric", "layers", ",", "and", "ionospheric", "reflection", "."], "sentence-detokenized": "Other anomalous propagation pathways include tropospheric irregularities, meteor scattering, refraction from ionised regions and ionospheric layers, and ionospheric reflection.", "token2charspan": [[0, 5], [6, 15], [16, 27], [28, 36], [37, 44], [45, 57], [58, 72], [72, 73], [74, 80], [81, 91], [91, 92], [93, 103], [104, 108], [109, 116], [117, 124], [125, 128], [129, 140], [141, 147], [147, 148], [149, 152], [153, 164], [165, 175], [175, 176]]}
{"doc_key": "ai-dev-349", "ner": [[0, 2, "field"], [4, 7, "field"], [10, 10, "field"], [12, 13, "field"], [15, 16, "field"], [18, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 10, 10, "part-of", "", false, false], [0, 2, 12, 13, "part-of", "", false, false], [0, 2, 15, 16, "part-of", "", false, false], [0, 2, 18, 23, "part-of", "", false, false], [4, 7, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Natural", "Language", "Processing", "(", "NLP", ")", "is", "a", "branch", "of", "linguistics", ",", "computer", "science", ",", "information", "engineering", "and", "artificial", "intelligence", "that", "deals", "with", "the", "interaction", "between", "computers", "and", "human", "(", "natural", ")", "languages", ",", "and", "in", "particular", "with", "how", "to", "program", "computers", "to", "process", "and", "analyse", "large", "amounts", "of", "natural", "language", "data", "."], "sentence-detokenized": "Natural Language Processing (NLP) is a branch of linguistics, computer science, information engineering and artificial intelligence that deals with the interaction between computers and human (natural) languages, and in particular with how to program computers to process and analyse large amounts of natural language data.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [29, 32], [32, 33], [34, 36], [37, 38], [39, 45], [46, 48], [49, 60], [60, 61], [62, 70], [71, 78], [78, 79], [80, 91], [92, 103], [104, 107], [108, 118], [119, 131], [132, 136], [137, 142], [143, 147], [148, 151], [152, 163], [164, 171], [172, 181], [182, 185], [186, 191], [192, 193], [193, 200], [200, 201], [202, 211], [211, 212], [213, 216], [217, 219], [220, 230], [231, 235], [236, 239], [240, 242], [243, 250], [251, 260], [261, 263], [264, 271], [272, 275], [276, 283], [284, 289], [290, 297], [298, 300], [301, 308], [309, 317], [318, 322], [322, 323]]}
{"doc_key": "ai-dev-350", "ner": [[8, 9, "organisation"], [11, 12, "organisation"], [14, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "active", "youth", "-", "led", "climate", "groups", "include", "Extinction", "Rebellion", ",", "Sunrise", "Movement", ",", "SustainUS", "and", "others", ",", "working", "both", "internationally", "and", "locally", "."], "sentence-detokenized": "Other active youth-led climate groups include Extinction Rebellion, Sunrise Movement, SustainUS and others, working both internationally and locally.", "token2charspan": [[0, 5], [6, 12], [13, 18], [18, 19], [19, 22], [23, 30], [31, 37], [38, 45], [46, 56], [57, 66], [66, 67], [68, 75], [76, 84], [84, 85], [86, 95], [96, 99], [100, 106], [106, 107], [108, 115], [116, 120], [121, 136], [137, 140], [141, 148], [148, 149]]}
