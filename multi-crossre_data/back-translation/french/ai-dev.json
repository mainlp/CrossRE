{"doc_key": "ai-dev-1", "ner": [[2, 2, "metrics"], [7, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 2, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Here", ",", "accuracy", "is", "measured", "by", "the", "error", "rate", ",", "which", "is", "defined", "as", "follows", ":"], "sentence-detokenized": "Here, accuracy is measured by the error rate, which is defined as follows:", "token2charspan": [[0, 4], [4, 5], [6, 14], [15, 17], [18, 26], [27, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 51], [52, 54], [55, 62], [63, 65], [66, 73], [73, 74]]}
{"doc_key": "ai-dev-2", "ner": [[4, 4, "algorithm"], [11, 12, "misc"], [15, 17, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 11, 12, "type-of", "", false, false], [4, 4, 15, 17, "related-to", "", false, false], [4, 4, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "this", "respect", ",", "SVM", "is", "closely", "related", "to", "other", "fundamental", "classification", "algorithms", "such", "as", "least", "squares", "regularised", "logistic", "regression", "."], "sentence-detokenized": "In this respect, SVM is closely related to other fundamental classification algorithms such as least squares regularised logistic regression.", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 20], [21, 23], [24, 31], [32, 39], [40, 42], [43, 48], [49, 60], [61, 75], [76, 86], [87, 91], [92, 94], [95, 100], [101, 108], [109, 120], [121, 129], [130, 140], [140, 141]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [3, 4, "person"], [13, 14, "person"], [16, 16, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 0, 1, "named", "actor_plays_character", false, false], [3, 4, 0, 1, "origin", "actor_plays_character", false, false], [16, 16, 13, 14, "named", "actor_plays_character", false, false], [16, 16, 13, 14, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "plays", "Leon", "Kowalski", ",", "a", "replicant", "fighter", "and", "worker", ",", "and", "Joanna", "Cassidy", "plays", "Zhora", ",", "a", "replicant", "assassin", "."], "sentence-detokenized": "Brion James plays Leon Kowalski, a replicant fighter and worker, and Joanna Cassidy plays Zhora, a replicant assassin.", "token2charspan": [[0, 5], [6, 11], [12, 17], [18, 22], [23, 31], [31, 32], [33, 34], [35, 44], [45, 52], [53, 56], [57, 63], [63, 64], [65, 68], [69, 75], [76, 83], [84, 89], [90, 95], [95, 96], [97, 98], [99, 108], [109, 117], [117, 118]]}
{"doc_key": "ai-dev-4", "ner": [[17, 20, "product"], [22, 22, "product"], [25, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 20, 25, 25, "physical", "", false, false], [22, 22, 17, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "image", "to", "be", "scanned", ",", "stored", "and", "recreated", "in", "digital", "pixels", "was", "displayed", "on", "the", "Standards", "Eastern", "Automatic", "Computer", "(", "SEAC", ")", "at", "NIST", "."], "sentence-detokenized": "The first image to be scanned, stored and recreated in digital pixels was displayed on the Standards Eastern Automatic Computer (SEAC) at NIST.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 18], [19, 21], [22, 29], [29, 30], [31, 37], [38, 41], [42, 51], [52, 54], [55, 62], [63, 69], [70, 73], [74, 83], [84, 86], [87, 90], [91, 100], [101, 108], [109, 118], [119, 127], [128, 129], [129, 133], [133, 134], [135, 137], [138, 142], [142, 143]]}
{"doc_key": "ai-dev-5", "ner": [[0, 8, "task"], [22, 23, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 8, 22, 23, "part-of", "", false, false], [0, 8, 25, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Segmentation", "of", "text", "into", "topics", "or", "turns", "of", "speech", "can", "be", "useful", "in", "some", "natural", "processing", "tasks", ":", "it", "can", "greatly", "improve", "information", "retrieval", "or", "speech", "recognition", "(", "by", "indexing", "/", "recognising", "documents", "more", "accurately", "or", "by", "giving", "the", "specific", "part", "of", "a", "document", "matching", "the", "query", "as", "a", "result", ")", "."], "sentence-detokenized": "Segmentation of text into topics or turns of speech can be useful in some natural processing tasks: it can greatly improve information retrieval or speech recognition (by indexing/recognising documents more accurately or by giving the specific part of a document matching the query as a result).", "token2charspan": [[0, 12], [13, 15], [16, 20], [21, 25], [26, 32], [33, 35], [36, 41], [42, 44], [45, 51], [52, 55], [56, 58], [59, 65], [66, 68], [69, 73], [74, 81], [82, 92], [93, 98], [98, 99], [100, 102], [103, 106], [107, 114], [115, 122], [123, 134], [135, 144], [145, 147], [148, 154], [155, 166], [167, 168], [168, 170], [171, 179], [179, 180], [180, 191], [192, 201], [202, 206], [207, 217], [218, 220], [221, 223], [224, 230], [231, 234], [235, 243], [244, 248], [249, 251], [252, 253], [254, 262], [263, 271], [272, 275], [276, 281], [282, 284], [285, 286], [287, 293], [293, 294], [294, 295]]}
{"doc_key": "ai-dev-6", "ner": [[8, 9, "university"], [21, 22, "conference"], [25, 26, "university"], [35, 36, "researcher"], [38, 39, "researcher"], [41, 42, "researcher"], [44, 45, "researcher"], [47, 48, "researcher"], [50, 51, "researcher"], [53, 55, "researcher"], [57, 58, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[21, 22, 25, 26, "physical", "", false, false], [35, 36, 21, 22, "physical", "", false, false], [35, 36, 21, 22, "role", "", false, false], [35, 36, 21, 22, "temporal", "", false, false], [38, 39, 21, 22, "physical", "", false, false], [38, 39, 21, 22, "role", "", false, false], [38, 39, 21, 22, "temporal", "", false, false], [41, 42, 21, 22, "physical", "", false, false], [41, 42, 21, 22, "role", "", false, false], [41, 42, 21, 22, "temporal", "", false, false], [44, 45, 21, 22, "physical", "", false, false], [44, 45, 21, 22, "role", "", false, false], [44, 45, 21, 22, "temporal", "", false, false], [47, 48, 21, 22, "physical", "", false, false], [47, 48, 21, 22, "role", "", false, false], [47, 48, 21, 22, "temporal", "", false, false], [50, 51, 21, 22, "physical", "", false, false], [50, 51, 21, 22, "role", "", false, false], [50, 51, 21, 22, "temporal", "", false, false], [53, 55, 21, 22, "physical", "", false, false], [53, 55, 21, 22, "role", "", false, false], [53, 55, 21, 22, "temporal", "", false, false], [57, 58, 21, 22, "physical", "", false, false], [57, 58, 21, 22, "role", "", false, false], [57, 58, 21, 22, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["In", "1999", "he", "organised", "such", "a", "symposium", "at", "Indiana", "University", "and", "in", "April", "2000", "he", "organised", "a", "larger", "symposium", "entitled", "\"", "Spiritual", "Robots", "\"", "at", "Stanford", "University", ",", "where", "he", "moderated", "a", "panel", "consisting", "of", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", "and", "John", "Koza", "."], "sentence-detokenized": "In 1999 he organised such a symposium at Indiana University and in April 2000 he organised a larger symposium entitled \"Spiritual Robots\" at Stanford University, where he moderated a panel consisting of Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland and John Koza.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 20], [21, 25], [26, 27], [28, 37], [38, 40], [41, 48], [49, 59], [60, 63], [64, 66], [67, 72], [73, 77], [78, 80], [81, 90], [91, 92], [93, 99], [100, 109], [110, 118], [119, 120], [120, 129], [130, 136], [136, 137], [138, 140], [141, 149], [150, 160], [160, 161], [162, 167], [168, 170], [171, 180], [181, 182], [183, 188], [189, 199], [200, 202], [203, 206], [207, 215], [215, 216], [217, 221], [222, 229], [229, 230], [231, 236], [237, 242], [242, 243], [244, 249], [250, 256], [256, 257], [258, 262], [263, 266], [266, 267], [268, 273], [274, 279], [279, 280], [281, 285], [286, 291], [292, 299], [300, 303], [304, 308], [309, 313], [313, 314]]}
{"doc_key": "ai-dev-7", "ner": [[4, 4, "metrics"], [5, 5, "metrics"], [8, 8, "metrics"], [9, 9, "metrics"], [18, 18, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 18, 18, "named", "", false, false], [5, 5, 4, 4, "named", "", false, false], [8, 8, 39, 39, "named", "", false, false], [9, 9, 8, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "considers", "both", "the", "precision", "p", "and", "the", "recall", "r", "of", "the", "test", "to", "calculate", "the", "score", ":", "p", "is", "the", "number", "of", "correct", "positives", "divided", "by", "the", "number", "of", "all", "positive", "results", "returned", "by", "the", "classifier", ",", "and", "r", "is", "the", "number", "of", "correct", "positives", "divided", "by", "the", "number", "of", "all", "relevant", "samples", "(", "all", "samples", "that", "should", "have", "been", "identified", "as", "positive", ")", "."], "sentence-detokenized": "It considers both the precision p and the recall r of the test to calculate the score: p is the number of correct positives divided by the number of all positive results returned by the classifier, and r is the number of correct positives divided by the number of all relevant samples (all samples that should have been identified as positive).", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 21], [22, 31], [32, 33], [34, 37], [38, 41], [42, 48], [49, 50], [51, 53], [54, 57], [58, 62], [63, 65], [66, 75], [76, 79], [80, 85], [85, 86], [87, 88], [89, 91], [92, 95], [96, 102], [103, 105], [106, 113], [114, 123], [124, 131], [132, 134], [135, 138], [139, 145], [146, 148], [149, 152], [153, 161], [162, 169], [170, 178], [179, 181], [182, 185], [186, 196], [196, 197], [198, 201], [202, 203], [204, 206], [207, 210], [211, 217], [218, 220], [221, 228], [229, 238], [239, 246], [247, 249], [250, 253], [254, 260], [261, 263], [264, 267], [268, 276], [277, 284], [285, 286], [286, 289], [290, 297], [298, 302], [303, 309], [310, 314], [315, 319], [320, 330], [331, 333], [334, 342], [342, 343], [343, 344]]}
{"doc_key": "ai-dev-8", "ner": [[2, 2, "organisation"], [23, 23, "product"], [31, 32, "person"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 23, 23, "artifact", "", false, false], [23, 23, 31, 32, "win-defeat", "", false, false], [23, 23, 38, 38, "win-defeat", "", true, false], [31, 32, 38, 38, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "the", "Google", "acquisition", ",", "the", "company", "has", "had", "a", "number", "of", "significant", "achievements", ",", "perhaps", "the", "most", "notable", "being", "the", "creation", "of", "AlphaGo", ",", "a", "program", "that", "beat", "world", "champion", "Lee", "Sedol", "at", "the", "complex", "game", "of", "Go", "."], "sentence-detokenized": "Since the Google acquisition, the company has had a number of significant achievements, perhaps the most notable being the creation of AlphaGo, a program that beat world champion Lee Sedol at the complex game of Go.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 28], [28, 29], [30, 33], [34, 41], [42, 45], [46, 49], [50, 51], [52, 58], [59, 61], [62, 73], [74, 86], [86, 87], [88, 95], [96, 99], [100, 104], [105, 112], [113, 118], [119, 122], [123, 131], [132, 134], [135, 142], [142, 143], [144, 145], [146, 153], [154, 158], [159, 163], [164, 169], [170, 178], [179, 182], [183, 188], [189, 191], [192, 195], [196, 203], [204, 208], [209, 211], [212, 214], [214, 215]]}
{"doc_key": "ai-dev-9", "ner": [[13, 14, "misc"], [27, 27, "field"], [31, 33, "product"], [50, 50, "misc"], [54, 55, "misc"], [58, 58, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 14, 27, 27, "part-of", "", false, false], [13, 14, 54, 55, "named", "same", false, false], [31, 33, 50, 50, "related-to", "", false, false], [31, 33, 54, 55, "usage", "", false, false], [31, 33, 58, 58, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Context", "-", "aware", "representation", "of", "words", "by", "dense", "vectors", "of", "fixed", "size", "(", "word", "embedding", ")", "has", "become", "one", "of", "the", "most", "fundamental", "building", "blocks", "of", "many", "NLP", "systems", ".", "An", "unsupervised", "disambiguation", "system", "uses", "the", "similarity", "between", "word", "meanings", "in", "a", "fixed", "context", "window", "to", "select", "the", "most", "appropriate", "meaning", "using", "a", "pre-trained", "word", "integration", "model", "and", "WordNet", "."], "sentence-detokenized": "Context-aware representation of words by dense vectors of fixed size (word embedding) has become one of the most fundamental building blocks of many NLP systems. An unsupervised disambiguation system uses the similarity between word meanings in a fixed context window to select the most appropriate meaning using a pre-trained word integration model and WordNet.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 28], [29, 31], [32, 37], [38, 40], [41, 46], [47, 54], [55, 57], [58, 63], [64, 68], [69, 70], [70, 74], [75, 84], [84, 85], [86, 89], [90, 96], [97, 100], [101, 103], [104, 107], [108, 112], [113, 124], [125, 133], [134, 140], [141, 143], [144, 148], [149, 152], [153, 160], [160, 161], [162, 164], [165, 177], [178, 192], [193, 199], [200, 204], [205, 208], [209, 219], [220, 227], [228, 232], [233, 241], [242, 244], [245, 246], [247, 252], [253, 260], [261, 267], [268, 270], [271, 277], [278, 281], [282, 286], [287, 298], [299, 306], [307, 312], [313, 314], [315, 326], [327, 331], [332, 343], [344, 349], [350, 353], [354, 361], [361, 362]]}
{"doc_key": "ai-dev-10", "ner": [[0, 1, "field"], [5, 5, "field"], [7, 7, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 1, "part-of", "", false, false], [7, 7, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "techniques", ",", "both", "supervised", "and", "unsupervised", ",", "have", "been", "used", "to", "induce", "these", "rules", "automatically", "."], "sentence-detokenized": "Machine learning techniques, both supervised and unsupervised, have been used to induce these rules automatically.", "token2charspan": [[0, 7], [8, 16], [17, 27], [27, 28], [29, 33], [34, 44], [45, 48], [49, 61], [61, 62], [63, 67], [68, 72], [73, 77], [78, 80], [81, 87], [88, 93], [94, 99], [100, 113], [113, 114]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1969", ",", "Scheinman", "invented", "the", "Stanford", "arm", ","], "sentence-detokenized": "In 1969, Scheinman invented the Stanford arm,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 27], [28, 31], [32, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-dev-12", "ner": [[2, 3, "metrics"], [8, 11, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "the", "Log", "loss", "is", "differentiable", ",", "a", "gradient", "-", "based", "method", "can", "be", "used", "to", "optimise", "the", "model", "."], "sentence-detokenized": "As the Log loss is differentiable, a gradient-based method can be used to optimise the model.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 15], [16, 18], [19, 33], [33, 34], [35, 36], [37, 45], [45, 46], [46, 51], [52, 58], [59, 62], [63, 65], [66, 70], [71, 73], [74, 82], [83, 86], [87, 92], [92, 93]]}
{"doc_key": "ai-dev-13", "ner": [[4, 5, "field"], [7, 9, "algorithm"], [11, 11, "algorithm"], [16, 18, "algorithm"], [21, 22, "field"], [33, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 9, 21, 22, "part-of", "", false, false], [11, 11, 7, 9, "named", "", false, false], [16, 18, 7, 9, "named", "", false, false], [21, 22, 4, 5, "part-of", "subfield", false, false], [33, 33, 21, 22, "part-of", "", false, false], [35, 36, 21, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "field", "of", "machine", "learning", ",", "support", "vector", "machines", "(", "SVMs", ",", "also", "known", "as", "support", "vector", "networks", ")", "are", "supervised", "learning", "models", "with", "learning", "algorithms", "that", "analyse", "the", "data", "used", "for", "classification", "and", "regression", "analysis", "."], "sentence-detokenized": "In the field of machine learning, support vector machines (SVMs, also known as support vector networks) are supervised learning models with learning algorithms that analyse the data used for classification and regression analysis.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 23], [24, 32], [32, 33], [34, 41], [42, 48], [49, 57], [58, 59], [59, 63], [63, 64], [65, 69], [70, 75], [76, 78], [79, 86], [87, 93], [94, 102], [102, 103], [104, 107], [108, 118], [119, 127], [128, 134], [135, 139], [140, 148], [149, 159], [160, 164], [165, 172], [173, 176], [177, 181], [182, 186], [187, 190], [191, 205], [206, 209], [210, 220], [221, 229], [229, 230]]}
{"doc_key": "ai-dev-14", "ner": [[9, 9, "task"], [11, 11, "task"], [29, 29, "metrics"], [31, 31, "metrics"], [33, 33, "researcher"], [35, 35, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 9, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "2002", ")", "as", "an", "automatic", "metric", "for", "machine", "translation", "(", "MT", ")", "evaluation", ",", "many", "other", "methods", "have", "been", "proposed", "to", "revise", "or", "improve", "it", ",", "such", "as", "TER", ",", "METEOR", ",", "Banerjee", "and", "Lavie", "(", "2005", ")", ",", "etc", "."], "sentence-detokenized": "(2002) as an automatic metric for machine translation (MT) evaluation, many other methods have been proposed to revise or improve it, such as TER, METEOR, Banerjee and Lavie (2005), etc.", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 9], [10, 12], [13, 22], [23, 29], [30, 33], [34, 41], [42, 53], [54, 55], [55, 57], [57, 58], [59, 69], [69, 70], [71, 75], [76, 81], [82, 89], [90, 94], [95, 99], [100, 108], [109, 111], [112, 118], [119, 121], [122, 129], [130, 132], [132, 133], [134, 138], [139, 141], [142, 145], [145, 146], [147, 153], [153, 154], [155, 163], [164, 167], [168, 173], [174, 175], [175, 179], [179, 180], [180, 181], [182, 185], [185, 186]]}
{"doc_key": "ai-dev-15", "ner": [[3, 4, "misc"], [9, 12, "organisation"], [10, 10, "organisation"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 10, 10, "origin", "", false, false], [10, 10, 9, 12, "part-of", "", false, false], [16, 17, 10, 10, "role", "", false, false], [19, 20, 10, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "includes", "a", "top", "ontology", ",", "created", "by", "the", "IEEE", "P1600.1", "working", "group", "(", "initially", "by", "Ian", "Niles", "and", "Adam", "Pease", ")", "."], "sentence-detokenized": "It includes a top ontology, created by the IEEE P1600.1 working group (initially by Ian Niles and Adam Pease).", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 17], [18, 26], [26, 27], [28, 35], [36, 38], [39, 42], [43, 47], [48, 55], [56, 63], [64, 69], [70, 71], [71, 80], [81, 83], [84, 87], [88, 93], [94, 97], [98, 102], [103, 108], [108, 109], [109, 110]]}
{"doc_key": "ai-dev-16", "ner": [[1, 5, "misc"], [29, 31, "algorithm"], [33, 34, "algorithm"], [37, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[29, 31, 1, 5, "part-of", "", true, false], [33, 34, 1, 5, "part-of", "", true, false], [37, 38, 33, 34, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "cryo-electron", "tomography", ",", "where", "a", "limited", "number", "of", "projections", "are", "acquired", "due", "to", "hardware", "limitations", "and", "to", "avoid", "damage", "to", "biological", "specimens", ",", "it", "can", "be", "used", "with", "compressive", "detection", "techniques", "or", "regularisation", "functions", "(", "e.g.", "Huber", "loss", ")", "to", "improve", "reconstruction", "and", "allow", "better", "interpretation", "."], "sentence-detokenized": "In cryo-electron tomography, where a limited number of projections are acquired due to hardware limitations and to avoid damage to biological specimens, it can be used with compressive detection techniques or regularisation functions (e.g. Huber loss) to improve reconstruction and allow better interpretation.", "token2charspan": [[0, 2], [3, 16], [17, 27], [27, 28], [29, 34], [35, 36], [37, 44], [45, 51], [52, 54], [55, 66], [67, 70], [71, 79], [80, 83], [84, 86], [87, 95], [96, 107], [108, 111], [112, 114], [115, 120], [121, 127], [128, 130], [131, 141], [142, 151], [151, 152], [153, 155], [156, 159], [160, 162], [163, 167], [168, 172], [173, 184], [185, 194], [195, 205], [206, 208], [209, 223], [224, 233], [234, 235], [235, 239], [240, 245], [246, 250], [250, 251], [252, 254], [255, 262], [263, 277], [278, 281], [282, 287], [288, 294], [295, 309], [309, 310]]}
{"doc_key": "ai-dev-17", "ner": [[4, 4, "misc"], [7, 7, "programlang"], [10, 11, "algorithm"], [13, 14, "algorithm"], [17, 18, "algorithm"], [24, 26, "product"], [29, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 4, 7, 7, "part-of", "", false, false], [10, 11, 4, 4, "type-of", "", false, false], [13, 14, 4, 4, "type-of", "", false, false], [17, 18, 4, 4, "type-of", "", false, false], [24, 26, 7, 7, "general-affiliation", "", true, false], [24, 26, 7, 7, "part-of", "", true, false], [29, 29, 24, 26, "role", "publishes", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["An", "implementation", "of", "several", "whitening", "procedures", "in", "R", ",", "including", "ZCA", "whitening", "and", "PCA", "whitening", "but", "also", "CCA", "whitening", ",", "is", "available", "in", "the", "R", "whitening", "package", "published", "on", "CRAN", "."], "sentence-detokenized": "An implementation of several whitening procedures in R, including ZCA whitening and PCA whitening but also CCA whitening, is available in the R whitening package published on CRAN.", "token2charspan": [[0, 2], [3, 17], [18, 20], [21, 28], [29, 38], [39, 49], [50, 52], [53, 54], [54, 55], [56, 65], [66, 69], [70, 79], [80, 83], [84, 87], [88, 97], [98, 101], [102, 106], [107, 110], [111, 120], [120, 121], [122, 124], [125, 134], [135, 137], [138, 141], [142, 143], [144, 153], [154, 161], [162, 171], [172, 174], [175, 179], [179, 180]]}
{"doc_key": "ai-dev-18", "ner": [[29, 29, "product"], [31, 31, "product"], [33, 33, "product"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [42, 43, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[29, 29, 33, 33, "compare", "", false, false], [29, 29, 35, 35, "compare", "", false, false], [29, 29, 37, 37, "compare", "", false, false], [29, 29, 39, 39, "compare", "", false, false], [29, 29, 42, 43, "compare", "", false, false], [31, 31, 33, 33, "compare", "", false, false], [31, 31, 35, 35, "compare", "", false, false], [31, 31, 37, 37, "compare", "", false, false], [31, 31, 39, 39, "compare", "", false, false], [31, 31, 42, 43, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Today", ",", "the", "field", "has", "become", "even", "more", "daunting", "and", "complex", "with", "the", "addition", "of", "languages", "and", "software", "for", "circuit", ",", "system", "and", "signal", "analysis", "and", "design", ",", "from", "MATLAB", "and", "Simulink", "to", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "and", "even", "assembly", "language", "."], "sentence-detokenized": "Today, the field has become even more daunting and complex with the addition of languages and software for circuit, system and signal analysis and design, from MATLAB and Simulink to NumPy, VHDL, PSpice, Verilog and even assembly language.", "token2charspan": [[0, 5], [5, 6], [7, 10], [11, 16], [17, 20], [21, 27], [28, 32], [33, 37], [38, 46], [47, 50], [51, 58], [59, 63], [64, 67], [68, 76], [77, 79], [80, 89], [90, 93], [94, 102], [103, 106], [107, 114], [114, 115], [116, 122], [123, 126], [127, 133], [134, 142], [143, 146], [147, 153], [153, 154], [155, 159], [160, 166], [167, 170], [171, 179], [180, 182], [183, 188], [188, 189], [190, 194], [194, 195], [196, 202], [202, 203], [204, 211], [212, 215], [216, 220], [221, 229], [230, 238], [238, 239]]}
{"doc_key": "ai-dev-19", "ner": [[5, 6, "person"], [15, 16, "person"], [17, 19, "organisation"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 19, 15, 16, "origin", "", false, false], [22, 22, 17, 19, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "company", "was", "founded", "by", "Kiichiro", "Toyoda", "in", "1937", "as", "a", "spin", "-", "off", "from", "Sakichi", "Toyoda", "'s", "Toyota", "Industries", "to", "create", "automobiles", "."], "sentence-detokenized": "The company was founded by Kiichiro Toyoda in 1937 as a spin-off from Sakichi Toyoda's Toyota Industries to create automobiles.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 35], [36, 42], [43, 45], [46, 50], [51, 53], [54, 55], [56, 60], [60, 61], [61, 64], [65, 69], [70, 77], [78, 84], [84, 86], [87, 93], [94, 104], [105, 107], [108, 114], [115, 126], [126, 127]]}
{"doc_key": "ai-dev-20", "ner": [[0, 9, "field"], [54, 55, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[54, 55, 0, 9, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Unsupervised", "learning", ",", "on", "the", "other", "hand", ",", "relies", "on", "training", "data", "that", "has", "not", "been", "manually", "labelled", "and", "attempts", "to", "find", "patterns", "inherent", "in", "the", "data", "that", "can", "then", "be", "used", "to", "determine", "the", "correct", "output", "value", "for", "new", "data", "instances", ".", "A", "combination", "of", "the", "two", "that", "has", "recently", "been", "explored", "is", "semi-supervised", "learning", ",", "which", "uses", "a", "combination", "of", "labelled", "and", "unlabelled", "data", "(", "usually", "a", "small", "set", "of", "labelled", "data", "combined", "with", "a", "large", "amount", "of", "unlabelled", "data", ")", "."], "sentence-detokenized": "Unsupervised learning, on the other hand, relies on training data that has not been manually labelled and attempts to find patterns inherent in the data that can then be used to determine the correct output value for new data instances. A combination of the two that has recently been explored is semi-supervised learning, which uses a combination of labelled and unlabelled data (usually a small set of labelled data combined with a large amount of unlabelled data).", "token2charspan": [[0, 12], [13, 21], [21, 22], [23, 25], [26, 29], [30, 35], [36, 40], [40, 41], [42, 48], [49, 51], [52, 60], [61, 65], [66, 70], [71, 74], [75, 78], [79, 83], [84, 92], [93, 101], [102, 105], [106, 114], [115, 117], [118, 122], [123, 131], [132, 140], [141, 143], [144, 147], [148, 152], [153, 157], [158, 161], [162, 166], [167, 169], [170, 174], [175, 177], [178, 187], [188, 191], [192, 199], [200, 206], [207, 212], [213, 216], [217, 220], [221, 225], [226, 235], [235, 236], [237, 238], [239, 250], [251, 253], [254, 257], [258, 261], [262, 266], [267, 270], [271, 279], [280, 284], [285, 293], [294, 296], [297, 312], [313, 321], [321, 322], [323, 328], [329, 333], [334, 335], [336, 347], [348, 350], [351, 359], [360, 363], [364, 374], [375, 379], [380, 381], [381, 388], [389, 390], [391, 396], [397, 400], [401, 403], [404, 412], [413, 417], [418, 426], [427, 431], [432, 433], [434, 439], [440, 446], [447, 449], [450, 460], [461, 465], [465, 466], [466, 467]]}
{"doc_key": "ai-dev-21", "ner": [[16, 16, "organisation"], [18, 18, "product"], [20, 21, "organisation"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[18, 18, 16, 16, "artifact", "", false, false], [20, 21, 23, 23, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Despite", "these", "utilitarian", "humanoid", "robots", ",", "there", "are", "humanoid", "robots", "for", "entertainment", "purposes", ",", "such", "as", "Sony", "'s", "QRIO", "and", "Wow", "Wee", "'s", "RoboSapien", "."], "sentence-detokenized": "Despite these utilitarian humanoid robots, there are humanoid robots for entertainment purposes, such as Sony's QRIO and Wow Wee's RoboSapien.", "token2charspan": [[0, 7], [8, 13], [14, 25], [26, 34], [35, 41], [41, 42], [43, 48], [49, 52], [53, 61], [62, 68], [69, 72], [73, 86], [87, 95], [95, 96], [97, 101], [102, 104], [105, 109], [109, 111], [112, 116], [117, 120], [121, 124], [125, 128], [128, 130], [131, 141], [141, 142]]}
{"doc_key": "ai-dev-22", "ner": [[0, 0, "researcher"], [6, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 12, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Webber", "became", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "in", "1991", ","], "sentence-detokenized": "Webber became a member of the Association for the Advancement of Artificial Intelligence in 1991,", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 49], [50, 61], [62, 64], [65, 75], [76, 88], [89, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-dev-23", "ner": [[6, 7, "field"], [9, 9, "field"], [20, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 23, 6, 7, "part-of", "task_part_of_field", false, false], [20, 23, 9, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["With", "this", "company", ",", "he", "developed", "data", "mining", "and", "database", "technology", ",", "specifically", "high", "-", "level", "ontologies", "for", "intelligence", "and", "automatic", "natural", "language", "understanding", "."], "sentence-detokenized": "With this company, he developed data mining and database technology, specifically high-level ontologies for intelligence and automatic natural language understanding.", "token2charspan": [[0, 4], [5, 9], [10, 17], [17, 18], [19, 21], [22, 31], [32, 36], [37, 43], [44, 47], [48, 56], [57, 67], [67, 68], [69, 81], [82, 86], [86, 87], [87, 92], [93, 103], [104, 107], [108, 120], [121, 124], [125, 134], [135, 142], [143, 151], [152, 165], [165, 166]]}
{"doc_key": "ai-dev-24", "ner": [[21, 22, "misc"], [25, 28, "misc"], [30, 31, "misc"], [33, 33, "country"], [36, 37, "organisation"], [39, 39, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[21, 22, 33, 33, "physical", "", false, false], [25, 28, 33, 33, "physical", "", false, false], [30, 31, 33, 33, "physical", "", false, false], [36, 37, 39, 39, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["However", ",", "in", "recent", "years", ",", "there", "have", "been", "various", "e-services", "and", "related", "initiatives", "in", "developing", "countries", ",", "such", "as", "the", "Nemmadi", "project", ",", "the", "MCA21", "Mission", "Mode", "project", "or", "Digital", "India", "in", "India", ";", "the", "e-Government", "Directorate", "in", "Pakistan", ";", "etc."], "sentence-detokenized": "However, in recent years, there have been various e-services and related initiatives in developing countries, such as the Nemmadi project, the MCA21 Mission Mode project or Digital India in India; the e-Government Directorate in Pakistan; etc.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 18], [19, 24], [24, 25], [26, 31], [32, 36], [37, 41], [42, 49], [50, 60], [61, 64], [65, 72], [73, 84], [85, 87], [88, 98], [99, 108], [108, 109], [110, 114], [115, 117], [118, 121], [122, 129], [130, 137], [137, 138], [139, 142], [143, 148], [149, 156], [157, 161], [162, 169], [170, 172], [173, 180], [181, 186], [187, 189], [190, 195], [195, 196], [197, 200], [201, 213], [214, 225], [226, 228], [229, 237], [237, 238], [239, 243]]}
{"doc_key": "ai-dev-25", "ner": [[0, 0, "misc"], [2, 2, "field"], [4, 4, "field"], [6, 8, "university"], [10, 12, "university"], [20, 22, "university"], [26, 26, "misc"], [28, 29, "field"], [32, 35, "misc"], [37, 39, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10], "relations": [[0, 0, 2, 2, "topic", "", false, false], [0, 0, 4, 4, "topic", "", false, false], [0, 0, 6, 8, "origin", "", false, false], [6, 8, 10, 12, "part-of", "", false, false], [20, 22, 6, 8, "part-of", "", false, false], [26, 26, 28, 29, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["D.", "in", "Radiophysics", "and", "Electronics", "from", "Rajabazar", "Science", "College", ",", "University", "of", "Calcutta", "in", "1979", "as", "a", "student", "of", "the", "Indian", "Statistical", "Institute", ",", "and", "another", "Ph.D.", "in", "Electrical", "Engineering", "and", "a", "Diploma", "from", "Imperial", "College", ",", "University", "of", "London", "in", "1982", "."], "sentence-detokenized": "D. in Radiophysics and Electronics from Rajabazar Science College, University of Calcutta in 1979 as a student of the Indian Statistical Institute, and another Ph.D. in Electrical Engineering and a Diploma from Imperial College, University of London in 1982.", "token2charspan": [[0, 2], [3, 5], [6, 18], [19, 22], [23, 34], [35, 39], [40, 49], [50, 57], [58, 65], [65, 66], [67, 77], [78, 80], [81, 89], [90, 92], [93, 97], [98, 100], [101, 102], [103, 110], [111, 113], [114, 117], [118, 124], [125, 136], [137, 146], [146, 147], [148, 151], [152, 159], [160, 165], [166, 168], [169, 179], [180, 191], [192, 195], [196, 197], [198, 205], [206, 210], [211, 219], [220, 227], [227, 228], [229, 239], [240, 242], [243, 249], [250, 252], [253, 257], [257, 258]]}
{"doc_key": "ai-dev-26", "ner": [[0, 2, "location"], [22, 24, "misc"], [31, 32, "misc"], [34, 36, "person"], [38, 39, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[22, 24, 0, 2, "temporal", "", false, false], [31, 32, 0, 2, "temporal", "", false, false], [34, 36, 31, 32, "role", "actor_in", false, false], [38, 39, 31, 32, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Expo", "II", "was", "announced", "as", "the", "venue", "for", "the", "world", "premiere", "of", "several", "never", "-", "before", "-", "seen", "3D", "films", ",", "including", "The", "Diamond", "Wizard", "and", "the", "Universal", "short", "film", ",", "Hawaiian", "Nights", "with", "Mamie", "Van", "Doren", "and", "Pinky", "Lee", "."], "sentence-detokenized": "Expo II was announced as the venue for the world premiere of several never-before-seen 3D films, including The Diamond Wizard and the Universal short film, Hawaiian Nights with Mamie Van Doren and Pinky Lee.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 24], [25, 28], [29, 34], [35, 38], [39, 42], [43, 48], [49, 57], [58, 60], [61, 68], [69, 74], [74, 75], [75, 81], [81, 82], [82, 86], [87, 89], [90, 95], [95, 96], [97, 106], [107, 110], [111, 118], [119, 125], [126, 129], [130, 133], [134, 143], [144, 149], [150, 154], [154, 155], [156, 164], [165, 171], [172, 176], [177, 182], [183, 186], [187, 192], [193, 196], [197, 202], [203, 206], [206, 207]]}
{"doc_key": "ai-dev-27", "ner": [[7, 8, "researcher"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 16, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "maximum", "subarray", "problem", "was", "proposed", "by", "Ulf", "Grenander", "in", "1977", "as", "a", "simplified", "model", "for", "maximum", "likelihood", "estimation", "of", "patterns", "in", "scanned", "images", "."], "sentence-detokenized": "The maximum subarray problem was proposed by Ulf Grenander in 1977 as a simplified model for maximum likelihood estimation of patterns in scanned images.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 28], [29, 32], [33, 41], [42, 44], [45, 48], [49, 58], [59, 61], [62, 66], [67, 69], [70, 71], [72, 82], [83, 88], [89, 92], [93, 100], [101, 111], [112, 122], [123, 125], [126, 134], [135, 137], [138, 145], [146, 152], [152, 153]]}
{"doc_key": "ai-dev-28", "ner": [[1, 2, "product"], [4, 5, "product"], [7, 9, "product"], [11, 12, "product"], [14, 16, "product"], [18, 21, "product"], [32, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[32, 32, 1, 2, "part-of", "", false, false], [32, 32, 4, 5, "part-of", "", false, false], [32, 32, 7, 9, "part-of", "", false, false], [32, 32, 11, 12, "part-of", "", false, false], [32, 32, 14, 16, "part-of", "", false, false], [32, 32, 18, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "iPhone", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", ",", "iPod", "Touch", "5", "G", "and", "later", "all", "have", "a", "more", "advanced", "voice", "assistant", "called", "Siri", "."], "sentence-detokenized": "The iPhone 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G, iPod Touch 5G and later all have a more advanced voice assistant called Siri.", "token2charspan": [[0, 3], [4, 10], [11, 13], [13, 14], [15, 19], [20, 21], [21, 22], [23, 27], [28, 32], [33, 35], [35, 36], [37, 41], [42, 45], [45, 46], [47, 51], [52, 55], [56, 58], [58, 59], [60, 64], [65, 70], [71, 72], [72, 73], [74, 77], [78, 83], [84, 87], [88, 92], [93, 94], [95, 99], [100, 108], [109, 114], [115, 124], [125, 131], [132, 136], [136, 137]]}
{"doc_key": "ai-dev-29", "ner": [[7, 8, "metrics"], [11, 14, "metrics"], [16, 17, "metrics"], [49, 51, "metrics"], [57, 60, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 14, 49, 51, "named", "", false, false], [16, 17, 11, 14, "named", "", false, false], [49, 51, 57, 60, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["It", "is", "easy", "to", "verify", "that", "the", "logistic", "loss", "and", "the", "binary", "cross", "-entropy", "loss", "(", "Log", "loss", ")", "are", "in", "fact", "the", "same", "(", "up", "to", "a", "multiplicative", "constant", "math", "{", "1", "}", "frac", "{", "1", "}", "log", "(", "2", ")", "}", "/", "math", ")", ".", "{", "The", "cross", "-entropy", "loss", "is", "closely", "related", "to", "the", "Kullback", "-", "Leibler", "divergence", "between", "the", "empirical", "and", "the", "predicted", "distribution", "."], "sentence-detokenized": "It is easy to verify that the logistic loss and the binary cross-entropy loss (Log loss) are in fact the same (up to a multiplicative constant math {1} frac {1} log (2)} / math). {The cross-entropy loss is closely related to the Kullback-Leibler divergence between the empirical and the predicted distribution.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 20], [21, 25], [26, 29], [30, 38], [39, 43], [44, 47], [48, 51], [52, 58], [59, 64], [64, 72], [73, 77], [78, 79], [79, 82], [83, 87], [87, 88], [89, 92], [93, 95], [96, 100], [101, 104], [105, 109], [110, 111], [111, 113], [114, 116], [117, 118], [119, 133], [134, 142], [143, 147], [148, 149], [149, 150], [150, 151], [152, 156], [157, 158], [158, 159], [159, 160], [161, 164], [165, 166], [166, 167], [167, 168], [168, 169], [170, 171], [172, 176], [176, 177], [177, 178], [179, 180], [180, 183], [184, 189], [189, 197], [198, 202], [203, 205], [206, 213], [214, 221], [222, 224], [225, 228], [229, 237], [237, 238], [238, 245], [246, 256], [257, 264], [265, 268], [269, 278], [279, 282], [283, 286], [287, 296], [297, 309], [309, 310]]}
{"doc_key": "ai-dev-30", "ner": [[1, 2, "algorithm"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 1, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "EM", "algorithm", "is", "used", "to", "find", "the", "(", "local", ")", "maximum", "likelihood", "parameters", "of", "a", "statistical", "model", "in", "cases", "where", "the", "equations", "can", "not", "be", "solved", "directly", "."], "sentence-detokenized": "The EM algorithm is used to find the (local) maximum likelihood parameters of a statistical model in cases where the equations cannot be solved directly.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 32], [33, 36], [37, 38], [38, 43], [43, 44], [45, 52], [53, 63], [64, 74], [75, 77], [78, 79], [80, 91], [92, 97], [98, 100], [101, 106], [107, 112], [113, 116], [117, 126], [127, 130], [130, 133], [134, 136], [137, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-dev-31", "ner": [[9, 10, "task"], [13, 17, "task"], [22, 23, "task"], [25, 25, "task"], [32, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "research", "was", "fundamental", "to", "the", "development", "of", "modern", "speech", "synthesis", "techniques", ",", "reading", "machines", "for", "the", "blind", ",", "the", "study", "of", "speech", "perception", "and", "recognition", ",", "and", "the", "development", "of", "the", "motor", "theory", "of", "speech", "perception", "."], "sentence-detokenized": "This research was fundamental to the development of modern speech synthesis techniques, reading machines for the blind, the study of speech perception and recognition, and the development of the motor theory of speech perception.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 29], [30, 32], [33, 36], [37, 48], [49, 51], [52, 58], [59, 65], [66, 75], [76, 86], [86, 87], [88, 95], [96, 104], [105, 108], [109, 112], [113, 118], [118, 119], [120, 123], [124, 129], [130, 132], [133, 139], [140, 150], [151, 154], [155, 166], [166, 167], [168, 171], [172, 175], [176, 187], [188, 190], [191, 194], [195, 200], [201, 207], [208, 210], [211, 217], [218, 228], [228, 229]]}
{"doc_key": "ai-dev-32", "ner": [[1, 1, "product"], [2, 4, "misc"], [6, 6, "misc"], [10, 12, "misc"], [15, 15, "product"], [17, 17, "product"], [19, 19, "product"], [24, 24, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 1, 1, "origin", "", false, false], [2, 4, 10, 12, "type-of", "", false, false], [2, 4, 15, 15, "related-to", "program_for", false, false], [2, 4, 17, 17, "related-to", "program_for", false, false], [2, 4, 19, 19, "related-to", "program_for", false, false], [2, 4, 24, 24, "related-to", "program_for", false, false], [6, 6, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "Arduino", "Integrated", "Development", "Environment", "(", "IDE", ")", "is", "a", "cross", "-platform", "application", "(", "for", "Windows", ",", "macOS", "and", "Linux", ")", "written", "in", "the", "Java", "programming", "language", "."], "sentence-detokenized": "The Arduino Integrated Development Environment (IDE) is a cross-platform application (for Windows, macOS and Linux) written in the Java programming language.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 57], [58, 63], [63, 72], [73, 84], [85, 86], [86, 89], [90, 97], [97, 98], [99, 104], [105, 108], [109, 114], [114, 115], [116, 123], [124, 126], [127, 130], [131, 135], [136, 147], [148, 156], [156, 157]]}
{"doc_key": "ai-dev-33", "ner": [[2, 3, "algorithm"], [11, 12, "field"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 11, 12, "opposite", "", false, false], [14, 15, 11, 12, "related-to", "works_with", false, false], [17, 18, 11, 12, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Research", "on", "neural", "networks", "stagnated", "after", "the", "publication", "of", "research", "on", "machine", "learning", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", "."], "sentence-detokenized": "Research on neural networks stagnated after the publication of research on machine learning by Marvin Minsky and Seymour Papert (1969).", "token2charspan": [[0, 8], [9, 11], [12, 18], [19, 27], [28, 37], [38, 43], [44, 47], [48, 59], [60, 62], [63, 71], [72, 74], [75, 82], [83, 91], [92, 94], [95, 101], [102, 108], [109, 112], [113, 120], [121, 127], [128, 129], [129, 133], [133, 134], [134, 135]]}
{"doc_key": "ai-dev-34", "ner": [[18, 19, "organisation"], [21, 21, "organisation"], [24, 24, "country"], [26, 26, "country"], [28, 31, "organisation"], [34, 34, "country"], [36, 37, "organisation"], [40, 40, "country"], [42, 42, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[28, 31, 24, 24, "general-affiliation", "", false, false], [28, 31, 26, 26, "general-affiliation", "", false, false], [36, 37, 34, 34, "general-affiliation", "", false, false], [42, 42, 40, 40, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Only", "a", "few", "non-Japanese", "companies", "eventually", "managed", "to", "survive", "in", "this", "market", ",", "the", "main", "ones", "being", ":", "Adept", "Technology", ",", "St\u00e4ubli", ",", "the", "Swedish", "and", "Swiss", "company", "ABB", "Asea", "Brown", "Boveri", ",", "the", "German", "company", "KUKA", "Robotics", "and", "the", "Italian", "company", "Comau", "."], "sentence-detokenized": "Only a few non-Japanese companies eventually managed to survive in this market, the main ones being: Adept Technology, St\u00e4ubli, the Swedish and Swiss company ABB Asea Brown Boveri, the German company KUKA Robotics and the Italian company Comau.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 23], [24, 33], [34, 44], [45, 52], [53, 55], [56, 63], [64, 66], [67, 71], [72, 78], [78, 79], [80, 83], [84, 88], [89, 93], [94, 99], [99, 100], [101, 106], [107, 117], [117, 118], [119, 126], [126, 127], [128, 131], [132, 139], [140, 143], [144, 149], [150, 157], [158, 161], [162, 166], [167, 172], [173, 179], [179, 180], [181, 184], [185, 191], [192, 199], [200, 204], [205, 213], [214, 217], [218, 221], [222, 229], [230, 237], [238, 243], [243, 244]]}
{"doc_key": "ai-dev-35", "ner": [[9, 10, "conference"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Research", "activities", "include", "an", "annual", "research", "conference", ",", "the", "RuleML", "Symposium", ",", "also", "known", "as", "RuleML", "."], "sentence-detokenized": "Research activities include an annual research conference, the RuleML Symposium, also known as RuleML.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 30], [31, 37], [38, 46], [47, 57], [57, 58], [59, 62], [63, 69], [70, 79], [79, 80], [81, 85], [86, 91], [92, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-dev-36", "ner": [[9, 9, "field"], [11, 12, "field"], [14, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Concepts", "are", "used", "as", "formal", "tools", "or", "models", "in", "mathematics", ",", "computer", "science", ",", "databases", "and", "artificial", "intelligence", ",", "where", "they", "are", "sometimes", "called", "classes", ",", "schemas", "or", "categories", "."], "sentence-detokenized": "Concepts are used as formal tools or models in mathematics, computer science, databases and artificial intelligence, where they are sometimes called classes, schemas or categories.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 33], [34, 36], [37, 43], [44, 46], [47, 58], [58, 59], [60, 68], [69, 76], [76, 77], [78, 87], [88, 91], [92, 102], [103, 115], [115, 116], [117, 122], [123, 127], [128, 131], [132, 141], [142, 148], [149, 156], [156, 157], [158, 165], [166, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-dev-37", "ner": [[6, 8, "organisation"], [11, 14, "organisation"], [17, 17, "organisation"], [19, 21, "organisation"], [24, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "received", "awards", "from", "the", "American", "Psychological", "Association", ",", "the", "National", "Academy", "of", "Sciences", ",", "the", "Royal", ",", "Cognitive", "Neuroscience", "Society", "and", "the", "American", "Humanist", "Association", "."], "sentence-detokenized": "He has received awards from the American Psychological Association, the National Academy of Sciences, the Royal, Cognitive Neuroscience Society and the American Humanist Association.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 22], [23, 27], [28, 31], [32, 40], [41, 54], [55, 66], [66, 67], [68, 71], [72, 80], [81, 88], [89, 91], [92, 100], [100, 101], [102, 105], [106, 111], [111, 112], [113, 122], [123, 135], [136, 143], [144, 147], [148, 151], [152, 160], [161, 169], [170, 181], [181, 182]]}
{"doc_key": "ai-dev-38", "ner": [[1, 2, "person"], [4, 5, "person"], [7, 8, "person"], [16, 19, "person"], [22, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[22, 27, 16, 19, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starring", "Harrison", "Ford", ",", "Rutger", "Hauer", "and", "Sean", "Young", ",", "the", "film", "is", "loosely", "based", "on", "Philip", "K", ".", "Dick", "'s", "novel", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "(", "1968", ")", "."], "sentence-detokenized": "Starring Harrison Ford, Rutger Hauer and Sean Young, the film is loosely based on Philip K. Dick's novel Do Androids Dream of Electric Sheep (1968).", "token2charspan": [[0, 8], [9, 17], [18, 22], [22, 23], [24, 30], [31, 36], [37, 40], [41, 45], [46, 51], [51, 52], [53, 56], [57, 61], [62, 64], [65, 72], [73, 78], [79, 81], [82, 88], [89, 90], [90, 91], [92, 96], [96, 98], [99, 104], [105, 107], [108, 116], [117, 122], [123, 125], [126, 134], [135, 140], [141, 142], [142, 146], [146, 147], [147, 148]]}
{"doc_key": "ai-dev-39", "ner": [[0, 1, "task"], [3, 6, "algorithm"], [11, 12, "field"], [14, 15, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 3, 6, "usage", "", false, false], [0, 1, 11, 12, "part-of", "task_part_of_field", false, false], [0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Image", "segmentation", "using", "k-means", "clustering", "algorithms", "has", "long", "been", "used", "for", "pattern", "recognition", ",", "object", "detection", "and", "medical", "imaging", "."], "sentence-detokenized": "Image segmentation using k-means clustering algorithms has long been used for pattern recognition, object detection and medical imaging.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 32], [33, 43], [44, 54], [55, 58], [59, 63], [64, 68], [69, 73], [74, 77], [78, 85], [86, 97], [97, 98], [99, 105], [106, 115], [116, 119], [120, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-dev-40", "ner": [[14, 14, "algorithm"], [16, 17, "algorithm"], [20, 20, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["General", "sampling", "from", "the", "truncated", "normal", "can", "be", "done", "using", "approximations", "to", "the", "normal", "CDF", "and", "probit", "function", ",", "and", "R", "has", "a", "codertnorm", "(", ")", "/", "code", "function", "to", "generate", "truncated", "normal", "samples", "."], "sentence-detokenized": "General sampling from the truncated normal can be done using approximations to the normal CDF and probit function, and R has a codertnorm () / code function to generate truncated normal samples.", "token2charspan": [[0, 7], [8, 16], [17, 21], [22, 25], [26, 35], [36, 42], [43, 46], [47, 49], [50, 54], [55, 60], [61, 75], [76, 78], [79, 82], [83, 89], [90, 93], [94, 97], [98, 104], [105, 113], [113, 114], [115, 118], [119, 120], [121, 124], [125, 126], [127, 137], [138, 139], [139, 140], [141, 142], [143, 147], [148, 156], [157, 159], [160, 168], [169, 178], [179, 185], [186, 193], [193, 194]]}
{"doc_key": "ai-dev-41", "ner": [[7, 8, "university"], [10, 11, "university"], [13, 15, "university"], [17, 19, "university"], [21, 22, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "also", "received", "honorary", "doctorates", "from", "Newcastle", "University", ",", "Surrey", "University", ",", "Tel", "Aviv", "University", ",", "Simon", "Fraser", "University", "and", "Troms\u00f8", "University", "."], "sentence-detokenized": "He has also received honorary doctorates from Newcastle University, Surrey University, Tel Aviv University, Simon Fraser University and Troms\u00f8 University.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 29], [30, 40], [41, 45], [46, 55], [56, 66], [66, 67], [68, 74], [75, 85], [85, 86], [87, 90], [91, 95], [96, 106], [106, 107], [108, 113], [114, 120], [121, 131], [132, 135], [136, 142], [143, 153], [153, 154]]}
{"doc_key": "ai-dev-42", "ner": [[1, 1, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "Java", "implementation", "using", "zero", "-", "based", "array", "indexes", "and", "a", "convenient", "method", "for", "printing", "the", "order", "of", "solved", "operations", ":"], "sentence-detokenized": "A Java implementation using zero-based array indexes and a convenient method for printing the order of solved operations:", "token2charspan": [[0, 1], [2, 6], [7, 21], [22, 27], [28, 32], [32, 33], [33, 38], [39, 44], [45, 52], [53, 56], [57, 58], [59, 69], [70, 76], [77, 80], [81, 89], [90, 93], [94, 99], [100, 102], [103, 109], [110, 120], [120, 121]]}
{"doc_key": "ai-dev-43", "ner": [[7, 8, "metrics"], [17, 19, "algorithm"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "networks", "are", "usually", "trained", "under", "a", "cross", "-entropy", "regime", ",", "which", "gives", "a", "non-linear", "variant", "of", "multinomial", "logistic", "regression", "."], "sentence-detokenized": "These networks are usually trained under a cross-entropy regime, which gives a non-linear variant of multinomial logistic regression.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 26], [27, 34], [35, 40], [41, 42], [43, 48], [48, 56], [57, 63], [63, 64], [65, 70], [71, 76], [77, 78], [79, 89], [90, 97], [98, 100], [101, 112], [113, 121], [122, 132], [132, 133]]}
{"doc_key": "ai-dev-44", "ner": [[1, 1, "conference"], [4, 4, "misc"], [5, 14, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 1, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ACL", "has", "a", "European", "chapter", "(", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ")", "."], "sentence-detokenized": "The ACL has a European chapter (European Chapter of the Association for Computational Linguistics).", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 13], [14, 22], [23, 30], [31, 32], [32, 40], [41, 48], [49, 51], [52, 55], [56, 67], [68, 71], [72, 85], [86, 97], [97, 98], [98, 99]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 8, "researcher"], [21, 21, "misc"], [24, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 21, 21, "role", "", false, false], [6, 8, 21, 21, "role", "", false, false], [21, 21, 24, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "professors", ",", "Hal", "Abelson", "and", "Gerald", "Jay", "Sussman", ",", "chose", "to", "remain", "neutral", "-", "their", "group", "was", "referred", "to", "as", "Switzerland", "and", "the", "MAC", "Project", "for", "the", "next", "30", "years", "."], "sentence-detokenized": "Two professors, Hal Abelson and Gerald Jay Sussman, chose to remain neutral - their group was referred to as Switzerland and the MAC Project for the next 30 years.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 50], [50, 51], [52, 57], [58, 60], [61, 67], [68, 75], [76, 77], [78, 83], [84, 89], [90, 93], [94, 102], [103, 105], [106, 108], [109, 120], [121, 124], [125, 128], [129, 132], [133, 140], [141, 144], [145, 148], [149, 153], [154, 156], [157, 162], [162, 163]]}
{"doc_key": "ai-dev-46", "ner": [[2, 2, "misc"], [4, 4, "researcher"], [7, 9, "university"], [14, 14, "organisation"], [19, 21, "organisation"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 4, 4, "temporal", "", false, false], [4, 4, 14, 14, "physical", "", false, false], [4, 4, 14, 14, "role", "", false, false], [4, 4, 19, 21, "role", "", false, false], [19, 21, 7, 9, "part-of", "", false, false], [27, 28, 19, 21, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["After", "his", "PhD", ",", "Ghahramani", "joined", "the", "University", "of", "Toronto", "in", "1995", "as", "a", "CIRT", "postdoctoral", "fellow", "in", "the", "Artificial", "Intelligence", "Laboratory", ",", "where", "he", "worked", "with", "Geoffrey", "Hinton", "."], "sentence-detokenized": "After his PhD, Ghahramani joined the University of Toronto in 1995 as a CIRT postdoctoral fellow in the Artificial Intelligence Laboratory, where he worked with Geoffrey Hinton.", "token2charspan": [[0, 5], [6, 9], [10, 13], [13, 14], [15, 25], [26, 32], [33, 36], [37, 47], [48, 50], [51, 58], [59, 61], [62, 66], [67, 69], [70, 71], [72, 76], [77, 89], [90, 96], [97, 99], [100, 103], [104, 114], [115, 127], [128, 138], [138, 139], [140, 145], [146, 148], [149, 155], [156, 160], [161, 169], [170, 176], [176, 177]]}
{"doc_key": "ai-dev-47", "ner": [[24, 25, "metrics"], [28, 28, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[28, 28, 24, 25, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Subsequent", "work", "has", "attempted", "to", "solve", "these", "problems", ",", "but", "it", "was", "not", "until", "the", "advent", "of", "the", "modern", "computer", "and", "the", "popularisation", "of", "Maximum", "Likelihood", "Parameterisation", "(", "MLP", ")", "techniques", "that", "the", "research", "really", "took", "off", "."], "sentence-detokenized": "Subsequent work has attempted to solve these problems, but it was not until the advent of the modern computer and the popularisation of Maximum Likelihood Parameterisation (MLP) techniques that the research really took off.", "token2charspan": [[0, 10], [11, 15], [16, 19], [20, 29], [30, 32], [33, 38], [39, 44], [45, 53], [53, 54], [55, 58], [59, 61], [62, 65], [66, 69], [70, 75], [76, 79], [80, 86], [87, 89], [90, 93], [94, 100], [101, 109], [110, 113], [114, 117], [118, 132], [133, 135], [136, 143], [144, 154], [155, 171], [172, 173], [173, 176], [176, 177], [178, 188], [189, 193], [194, 197], [198, 206], [207, 213], [214, 218], [219, 222], [222, 223]]}
{"doc_key": "ai-dev-48", "ner": [[5, 6, "person"], [9, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "series", "was", "produced", "by", "David", "Fincher", "and", "stars", "Kevin", "Spacey", "."], "sentence-detokenized": "The series was produced by David Fincher and stars Kevin Spacey.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 40], [41, 44], [45, 50], [51, 56], [57, 63], [63, 64]]}
{"doc_key": "ai-dev-49", "ner": [[18, 18, "metrics"], [25, 26, "algorithm"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[25, 26, 31, 32, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Due", "to", "the", "limits", "of", "computational", "power", ",", "current", "in", "silico", "methods", "generally", "have", "to", "trade", "speed", "for", "accuracy", ";", "for", "example", ",", "using", "fast", "protein", "docking", "methods", "instead", "of", "expensive", "free", "energy", "calculations", "."], "sentence-detokenized": "Due to the limits of computational power, current in silico methods generally have to trade speed for accuracy; for example, using fast protein docking methods instead of expensive free energy calculations.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 17], [18, 20], [21, 34], [35, 40], [40, 41], [42, 49], [50, 52], [53, 59], [60, 67], [68, 77], [78, 82], [83, 85], [86, 91], [92, 97], [98, 101], [102, 110], [110, 111], [112, 115], [116, 123], [123, 124], [125, 130], [131, 135], [136, 143], [144, 151], [152, 159], [160, 167], [168, 170], [171, 180], [181, 185], [186, 192], [193, 205], [205, 206]]}
{"doc_key": "ai-dev-50", "ner": [[7, 8, "country"], [10, 10, "country"], [12, 12, "country"], [14, 14, "country"], [16, 16, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "had", "over", "30", "sites", "in", "the", "United", "States", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "sentence-detokenized": "It had over 30 sites in the United States, Canada, Mexico, Brazil and Argentina.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 20], [21, 23], [24, 27], [28, 34], [35, 41], [41, 42], [43, 49], [49, 50], [51, 57], [57, 58], [59, 65], [66, 69], [70, 79], [79, 80]]}
{"doc_key": "ai-dev-51", "ner": [[6, 6, "field"], [10, 12, "product"], [14, 16, "algorithm"], [23, 24, "task"], [26, 27, "task"], [32, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 12, 6, 6, "part-of", "", false, false], [10, 12, 14, 16, "usage", "", false, false], [23, 24, 6, 6, "part-of", "task_part_of_field", false, false], [23, 24, 32, 32, "related-to", "performs", false, false], [26, 27, 6, 6, "part-of", "task_part_of_field", false, false], [26, 27, 32, 32, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["An", "example", "of", "a", "typical", "computer", "vision", "pipeline", "for", "a", "face", "recognition", "system", "using", "k", "-", "NN", ",", "including", "the", "pre-processing", "steps", "of", "feature", "extraction", "and", "dimension", "reduction", "(", "usually", "implemented", "with", "OpenCV", ")", ":"], "sentence-detokenized": "An example of a typical computer vision pipeline for a face recognition system using k -NN, including the pre-processing steps of feature extraction and dimension reduction (usually implemented with OpenCV):", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 23], [24, 32], [33, 39], [40, 48], [49, 52], [53, 54], [55, 59], [60, 71], [72, 78], [79, 84], [85, 86], [87, 88], [88, 90], [90, 91], [92, 101], [102, 105], [106, 120], [121, 126], [127, 129], [130, 137], [138, 148], [149, 152], [153, 162], [163, 172], [173, 174], [174, 181], [182, 193], [194, 198], [199, 205], [205, 206], [206, 207]]}
{"doc_key": "ai-dev-52", "ner": [[9, 11, "algorithm"], [13, 13, "misc"], [15, 16, "misc"], [18, 18, "misc"], [22, 22, "programlang"], [24, 24, "product"], [28, 29, "algorithm"], [31, 32, "misc"], [34, 34, "misc"], [36, 36, "misc"], [38, 38, "misc"], [45, 45, "misc"], [48, 50, "misc"], [50, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "a", "rich", "feature", "set", ",", "libraries", "for", "constraint", "logic", "programming", ",", "multithreading", ",", "unit", "testing", ",", "GUI", ",", "interfacing", "with", "Java", ",", "ODBC", "and", "others", ",", "lettered", "programming", ",", "web", "server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "development", "tools", "(", "including", "an", "IDE", "with", "a", "debugger", "and", "GUI", "profiler", ")", "and", "extensive", "documentation"], "sentence-detokenized": "It has a rich feature set, libraries for constraint logic programming, multithreading, unit testing, GUI, interfacing with Java, ODBC and others, lettered programming, web server, SGML, RDF, RDFS, development tools (including an IDE with a debugger and GUI profiler) and extensive documentation", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 13], [14, 21], [22, 25], [25, 26], [27, 36], [37, 40], [41, 51], [52, 57], [58, 69], [69, 70], [71, 85], [85, 86], [87, 91], [92, 99], [99, 100], [101, 104], [104, 105], [106, 117], [118, 122], [123, 127], [127, 128], [129, 133], [134, 137], [138, 144], [144, 145], [146, 154], [155, 166], [166, 167], [168, 171], [172, 178], [178, 179], [180, 184], [184, 185], [186, 189], [189, 190], [191, 195], [195, 196], [197, 208], [209, 214], [215, 216], [216, 225], [226, 228], [229, 232], [233, 237], [238, 239], [240, 248], [249, 252], [253, 256], [257, 265], [265, 266], [267, 270], [271, 280], [281, 294]]}
{"doc_key": "ai-dev-53", "ner": [[4, 5, "field"], [7, 8, "field"], [13, 15, "misc"], [18, 21, "misc"], [23, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 15, 4, 5, "part-of", "", true, false], [13, 15, 7, 8, "part-of", "", false, false], [13, 15, 23, 26, "type-of", "", false, false], [18, 21, 4, 5, "part-of", "", false, false], [18, 21, 7, 8, "part-of", "", false, false], [18, 21, 23, 26, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "field", "of", "computer", "vision", "and", "image", "processing", ",", "the", "notion", "of", "scale", "space", "representation", "and", "the", "Gaussian", "derivative", "operators", "constitute", "a", "canonical", "multi", "-scale", "representation", "."], "sentence-detokenized": "In the field of computer vision and image processing, the notion of scale space representation and the Gaussian derivative operators constitute a canonical multi-scale representation.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 24], [25, 31], [32, 35], [36, 41], [42, 52], [52, 53], [54, 57], [58, 64], [65, 67], [68, 73], [74, 79], [80, 94], [95, 98], [99, 102], [103, 111], [112, 122], [123, 132], [133, 143], [144, 145], [146, 155], [156, 161], [161, 167], [168, 182], [182, 183]]}
{"doc_key": "ai-dev-54", "ner": [[7, 11, "organisation"], [20, 24, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 11, 20, 24, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "also", "the", "president", "of", "the", "Neural", "Information", "Processing", "Systems", "Foundation", ",", "a", "non-profit", "organisation", "that", "oversees", "the", "annual", "Neural", "Information", "Processing", "Systems", "Conference", "."], "sentence-detokenized": "He is also the president of the Neural Information Processing Systems Foundation, a non-profit organisation that oversees the annual Neural Information Processing Systems Conference.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 14], [15, 24], [25, 27], [28, 31], [32, 38], [39, 50], [51, 61], [62, 69], [70, 80], [80, 81], [82, 83], [84, 94], [95, 107], [108, 112], [113, 121], [122, 125], [126, 132], [133, 139], [140, 151], [152, 162], [163, 170], [171, 181], [181, 182]]}
{"doc_key": "ai-dev-55", "ner": [[1, 3, "task"], [6, 7, "metrics"], [13, 14, "misc"], [17, 17, "task"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 6, 7, "usage", "", false, false], [6, 7, 13, 14, "type-of", "", false, false], [17, 17, 20, 21, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["For", "regression", "analysis", "problems", ",", "the", "squared", "error", "can", "be", "used", "as", "a", "loss", "function", ",", "for", "classification", ",", "the", "cross", "-entropy", "can", "be", "used", "."], "sentence-detokenized": "For regression analysis problems, the squared error can be used as a loss function, for classification, the cross-entropy can be used.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 32], [32, 33], [34, 37], [38, 45], [46, 51], [52, 55], [56, 58], [59, 63], [64, 66], [67, 68], [69, 73], [74, 82], [82, 83], [84, 87], [88, 102], [102, 103], [104, 107], [108, 113], [113, 121], [122, 125], [126, 128], [129, 133], [133, 134]]}
{"doc_key": "ai-dev-56", "ner": [[0, 1, "researcher"], [20, 23, "conference"], [20, 25, "conference"], [32, 32, "university"], [35, 36, "field"], [46, 50, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 20, 23, "role", "", false, false], [0, 1, 32, 32, "physical", "", false, false], [0, 1, 32, 32, "role", "", false, false], [0, 1, 46, 50, "role", "", false, false], [20, 23, 20, 25, "named", "same", false, false], [32, 32, 35, 36, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Dr.", "Lafferty", "has", "held", "many", "prestigious", "positions", "including", ":", "1", ")", "Program", "Co-", "Chair", "and", "General", "Co-", "Chair", "of", "the", "Neural", "Information", "Processing", "Systems", "Foundation", "Conferences", ";", "2", ")", "Co-", "Director", "of", "CMU", "'s", "new", "Machine", "Learning", "Ph.D.", "program", ";", "3", ")", "Associate", "Editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research", "."], "sentence-detokenized": "Dr. Lafferty has held many prestigious positions including: 1) Program Co-Chair and General Co-Chair of the Neural Information Processing Systems Foundation Conferences; 2) Co-Director of CMU's new Machine Learning Ph.D. program; 3) Associate Editor of the Journal of Machine Learning Research.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 21], [22, 26], [27, 38], [39, 48], [49, 58], [58, 59], [60, 61], [61, 62], [63, 70], [71, 74], [74, 79], [80, 83], [84, 91], [92, 95], [95, 100], [101, 103], [104, 107], [108, 114], [115, 126], [127, 137], [138, 145], [146, 156], [157, 168], [168, 169], [170, 171], [171, 172], [173, 176], [176, 184], [185, 187], [188, 191], [191, 193], [194, 197], [198, 205], [206, 214], [215, 220], [221, 228], [228, 229], [230, 231], [231, 232], [233, 242], [243, 249], [250, 252], [253, 256], [257, 264], [265, 267], [268, 275], [276, 284], [285, 293], [293, 294]]}
{"doc_key": "ai-dev-57", "ner": [[0, 1, "misc"], [5, 5, "algorithm"], [7, 7, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 1, "type-of", "", false, false], [7, 7, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Convex", "algorithms", ",", "such", "as", "AdaBoost", "and", "LogitBoost", ",", "can", "be", "defeated", "by", "random", "noise", ",", "so", "that", "they", "can", "not", "learn", "basic", "and", "learnable", "combinations", "of", "weak", "assumptions", "."], "sentence-detokenized": "Convex algorithms, such as AdaBoost and LogitBoost, can be defeated by random noise, so that they cannot learn basic and learnable combinations of weak assumptions.", "token2charspan": [[0, 6], [7, 17], [17, 18], [19, 23], [24, 26], [27, 35], [36, 39], [40, 50], [50, 51], [52, 55], [56, 58], [59, 67], [68, 70], [71, 77], [78, 83], [83, 84], [85, 87], [88, 92], [93, 97], [98, 101], [101, 104], [105, 110], [111, 116], [117, 120], [121, 130], [131, 143], [144, 146], [147, 151], [152, 163], [163, 164]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [3, 7, "product"], [11, 13, "algorithm"], [21, 22, "algorithm"], [25, 30, "task"], [32, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 7, "type-of", "", false, false], [0, 0, 11, 13, "usage", "", false, false], [0, 0, 21, 22, "usage", "", false, false], [21, 22, 25, 30, "related-to", "used_for", true, false], [21, 22, 32, 34, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "is", "a", "surface", "transfer", "machine", "translation", "system", ",", "which", "uses", "finite", "state", "transducers", "for", "all", "its", "lexical", "transformations", ",", "and", "hidden", "Markov", "models", "for", "part", "-", "of", "-", "speech", "marking", "or", "word", "category", "disambiguation", "."], "sentence-detokenized": "Apertium is a surface transfer machine translation system, which uses finite state transducers for all its lexical transformations, and hidden Markov models for part-of-speech marking or word category disambiguation.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 21], [22, 30], [31, 38], [39, 50], [51, 57], [57, 58], [59, 64], [65, 69], [70, 76], [77, 82], [83, 94], [95, 98], [99, 102], [103, 106], [107, 114], [115, 130], [130, 131], [132, 135], [136, 142], [143, 149], [150, 156], [157, 160], [161, 165], [165, 166], [166, 168], [168, 169], [169, 175], [176, 183], [184, 186], [187, 191], [192, 200], [201, 215], [215, 216]]}
{"doc_key": "ai-dev-59", "ner": [[1, 2, "misc"], [14, 17, "metrics"], [31, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 14, 17, "related-to", "", true, false], [14, 17, 31, 32, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "natural", "gradient", "of", "mathE", "f", "(", "x", ")", "/", "math", ",", "consistent", "with", "Fisher", "'s", "information", "metric", "(", "a", "measure", "of", "informational", "distance", "between", "probability", "distributions", "and", "the", "curvature", "of", "relative", "entropy", ")", ",", "now", "reads", "as", "follows"], "sentence-detokenized": "The natural gradient of mathE f (x) / math, consistent with Fisher's information metric (a measure of informational distance between probability distributions and the curvature of relative entropy), now reads as follows", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 23], [24, 29], [30, 31], [32, 33], [33, 34], [34, 35], [36, 37], [38, 42], [42, 43], [44, 54], [55, 59], [60, 66], [66, 68], [69, 80], [81, 87], [88, 89], [89, 90], [91, 98], [99, 101], [102, 115], [116, 124], [125, 132], [133, 144], [145, 158], [159, 162], [163, 166], [167, 176], [177, 179], [180, 188], [189, 196], [196, 197], [197, 198], [199, 202], [203, 208], [209, 211], [212, 219]]}
{"doc_key": "ai-dev-60", "ner": [[1, 3, "programlang"], [6, 9, "product"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 1, 3, "origin", "", false, false], [11, 11, 1, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "S", "programming", "language", "inspired", "the", "S", "'", "-", "PLUS", "and", "R", "systems", "."], "sentence-detokenized": "The S programming language inspired the S'-PLUS and R systems.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 26], [27, 35], [36, 39], [40, 41], [41, 42], [42, 43], [43, 47], [48, 51], [52, 53], [54, 61], [61, 62]]}
{"doc_key": "ai-dev-61", "ner": [[5, 5, "product"], [10, 10, "product"], [13, 15, "product"], [19, 21, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 10, 10, "named", "same", false, false], [13, 15, 10, 10, "origin", "derived_from", false, false], [13, 15, 19, 21, "origin", "", false, false], [13, 15, 23, 24, "origin", "", false, false], [13, 15, 26, 27, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "most", "influential", "implementation", "of", "Planner", "was", "the", "subset", "of", "Planner", ",", "called", "Micro", "-", "Planner", ",", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "."], "sentence-detokenized": "The most influential implementation of Planner was the subset of Planner, called Micro-Planner, implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 35], [36, 38], [39, 46], [47, 50], [51, 54], [55, 61], [62, 64], [65, 72], [72, 73], [74, 80], [81, 86], [86, 87], [87, 94], [94, 95], [96, 107], [108, 110], [111, 117], [118, 121], [122, 129], [129, 130], [131, 137], [138, 146], [147, 150], [151, 156], [157, 165], [165, 166]]}
{"doc_key": "ai-dev-62", "ner": [[4, 6, "country"], [8, 10, "researcher"], [21, 21, "misc"], [20, 26, "university"], [35, 36, "misc"], [43, 43, "misc"], [46, 48, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[8, 10, 4, 6, "general-affiliation", "from_country", false, false], [20, 26, 21, 21, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1779", ",", "the", "German", "-", "Danish", "scientist", "Christian", "Gottlieb", "Kratzenstein", "won", "first", "prize", "in", "a", "competition", "announced", "by", "the", "Imperial", "Russian", "Academy", "of", "Sciences", "and", "Arts", "for", "the", "models", "he", "constructed", "of", "the", "human", "vocal", "tract", "capable", "of", "producing", "the", "five", "long", "vowels", "(", "in", "International", "Phonetic", "Alphabet", "notation", ":"], "sentence-detokenized": "In 1779, the German-Danish scientist Christian Gottlieb Kratzenstein won first prize in a competition announced by the Imperial Russian Academy of Sciences and Arts for the models he constructed of the human vocal tract capable of producing the five long vowels (in International Phonetic Alphabet notation:", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [19, 20], [20, 26], [27, 36], [37, 46], [47, 55], [56, 68], [69, 72], [73, 78], [79, 84], [85, 87], [88, 89], [90, 101], [102, 111], [112, 114], [115, 118], [119, 127], [128, 135], [136, 143], [144, 146], [147, 155], [156, 159], [160, 164], [165, 168], [169, 172], [173, 179], [180, 182], [183, 194], [195, 197], [198, 201], [202, 207], [208, 213], [214, 219], [220, 227], [228, 230], [231, 240], [241, 244], [245, 249], [250, 254], [255, 261], [262, 263], [263, 265], [266, 279], [280, 288], [289, 297], [298, 306], [306, 307]]}
{"doc_key": "ai-dev-63", "ner": [[3, 4, "product"], [6, 7, "misc"], [10, 14, "misc"], [32, 34, "misc"], [57, 58, "task"], [63, 64, "product"], [66, 66, "product"], [72, 73, "task"], [75, 76, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 4, 63, 64, "related-to", "supports_program", false, false], [3, 4, 66, 66, "related-to", "supports_program", false, false], [6, 7, 3, 4, "part-of", "", false, false], [10, 14, 3, 4, "part-of", "", false, false], [32, 34, 3, 4, "part-of", "", false, false], [57, 58, 3, 4, "part-of", "", false, false], [72, 73, 3, 4, "part-of", "", false, false], [75, 76, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["New", "features", "in", "Office", "XP", "include", "Smart", "Tags", ",", "a", "selection", "-", "based", "search", "feature", "that", "recognises", "different", "types", "of", "text", "in", "a", "document", "so", "users", "can", "perform", "additional", "actions", ";", "a", "task", "pane", "interface", "that", "groups", "the", "most", "common", "menu", "bar", "commands", "on", "the", "right", "-", "hand", "side", "of", "the", "screen", "for", "easy", "access", ";", "new", "document", "collaboration", "capabilities", ";", "support", "for", "MSN", "Groups", "and", "SharePoint", ";", "and", "built", "-", "in", "handwriting", "recognition", "and", "voice", "recognition", "capabilities", "."], "sentence-detokenized": "New features in Office XP include Smart Tags, a selection-based search feature that recognises different types of text in a document so users can perform additional actions; a task pane interface that groups the most common menu bar commands on the right-hand side of the screen for easy access; new document collaboration capabilities; support for MSN Groups and SharePoint; and built-in handwriting recognition and voice recognition capabilities.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 25], [26, 33], [34, 39], [40, 44], [44, 45], [46, 47], [48, 57], [57, 58], [58, 63], [64, 70], [71, 78], [79, 83], [84, 94], [95, 104], [105, 110], [111, 113], [114, 118], [119, 121], [122, 123], [124, 132], [133, 135], [136, 141], [142, 145], [146, 153], [154, 164], [165, 172], [172, 173], [174, 175], [176, 180], [181, 185], [186, 195], [196, 200], [201, 207], [208, 211], [212, 216], [217, 223], [224, 228], [229, 232], [233, 241], [242, 244], [245, 248], [249, 254], [254, 255], [255, 259], [260, 264], [265, 267], [268, 271], [272, 278], [279, 282], [283, 287], [288, 294], [294, 295], [296, 299], [300, 308], [309, 322], [323, 335], [335, 336], [337, 344], [345, 348], [349, 352], [353, 359], [360, 363], [364, 374], [374, 375], [376, 379], [380, 385], [385, 386], [386, 388], [389, 400], [401, 412], [413, 416], [417, 422], [423, 434], [435, 447], [447, 448]]}
{"doc_key": "ai-dev-64", "ner": [[11, 12, "algorithm"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 15, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "many", "applications", ",", "the", "units", "in", "these", "networks", "apply", "a", "sigmoid", "function", "as", "the", "activation", "function", "."], "sentence-detokenized": "In many applications, the units in these networks apply a sigmoid function as the activation function.", "token2charspan": [[0, 2], [3, 7], [8, 20], [20, 21], [22, 25], [26, 31], [32, 34], [35, 40], [41, 49], [50, 55], [56, 57], [58, 65], [66, 74], [75, 77], [78, 81], [82, 92], [93, 101], [101, 102]]}
{"doc_key": "ai-dev-65", "ner": [[3, 4, "researcher"], [12, 17, "organisation"], [29, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 12, 17, "role", "", false, false], [3, 4, 29, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2001", ",", "Mehler", "was", "elected", "an", "Honorary", "Foreign", "Member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "and", "in", "2003", "he", "was", "elected", "a", "Fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In 2001, Mehler was elected an Honorary Foreign Member of the American Academy of Arts and Sciences, and in 2003 he was elected a Fellow of the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 27], [28, 30], [31, 39], [40, 47], [48, 54], [55, 57], [58, 61], [62, 70], [71, 78], [79, 81], [82, 86], [87, 90], [91, 99], [99, 100], [101, 104], [105, 107], [108, 112], [113, 115], [116, 119], [120, 127], [128, 129], [130, 136], [137, 139], [140, 143], [144, 152], [153, 164], [165, 168], [169, 172], [173, 184], [185, 187], [188, 195], [195, 196]]}
{"doc_key": "ai-dev-66", "ner": [[4, 6, "task"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 9, 10, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Extending", "this", "concept", "to", "non", "-binary", "classifications", "gives", "the", "confusion", "matrix", "."], "sentence-detokenized": "Extending this concept to non-binary classifications gives the confusion matrix.", "token2charspan": [[0, 9], [10, 14], [15, 22], [23, 25], [26, 29], [29, 36], [37, 52], [53, 58], [59, 62], [63, 72], [73, 79], [79, 80]]}
{"doc_key": "ai-dev-67", "ner": [[15, 16, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "updated", "estimate", "of", "the", "variance", "of", "the", "measurement", "noise", "can", "be", "obtained", "by", "the", "maximum", "likelihood", "calculation", "."], "sentence-detokenized": "An updated estimate of the variance of the measurement noise can be obtained by the maximum likelihood calculation.", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 22], [23, 26], [27, 35], [36, 38], [39, 42], [43, 54], [55, 60], [61, 64], [65, 67], [68, 76], [77, 79], [80, 83], [84, 91], [92, 102], [103, 114], [114, 115]]}
{"doc_key": "ai-dev-68", "ner": [[1, 2, "field"], [5, 5, "algorithm"], [8, 9, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 8, 9, "usage", "", true, false], [5, 5, 12, 13, "related-to", "", true, false], [8, 9, 1, 2, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "machine", "learning", ",", "the", "perceptron", "is", "a", "supervised", "learning", "algorithm", "for", "binary", "classification", "."], "sentence-detokenized": "In machine learning, the perceptron is a supervised learning algorithm for binary classification.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 24], [25, 35], [36, 38], [39, 40], [41, 51], [52, 60], [61, 70], [71, 74], [75, 81], [82, 96], [96, 97]]}
{"doc_key": "ai-dev-69", "ner": [[7, 8, "field"], [10, 10, "field"], [14, 19, "conference"], [22, 26, "conference"], [29, 35, "conference"], [38, 42, "conference"], [45, 49, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 19, 7, 8, "topic", "", false, false], [14, 19, 10, 10, "topic", "", false, false], [22, 26, 7, 8, "topic", "", false, false], [22, 26, 10, 10, "topic", "", false, false], [29, 35, 7, 8, "topic", "", false, false], [29, 35, 10, 10, "topic", "", false, false], [38, 42, 7, 8, "topic", "", false, false], [38, 42, 10, 10, "topic", "", false, false], [45, 49, 7, 8, "topic", "", false, false], [45, 49, 10, 10, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["She", "has", "also", "chaired", "several", "conferences", "on", "machine", "learning", "and", "vision", ",", "including", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "the", "International", "Conference", "on", "Learning", "Representations", ",", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "the", "International", "Conference", "on", "Computer", "Vision", "and", "the", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "She has also chaired several conferences on machine learning and vision, including the Conference on Neural Information Processing Systems, the International Conference on Learning Representations, the Conference on Computer Vision and Pattern Recognition, the International Conference on Computer Vision and the European Conference on Computer Vision.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 20], [21, 28], [29, 40], [41, 43], [44, 51], [52, 60], [61, 64], [65, 71], [71, 72], [73, 82], [83, 86], [87, 97], [98, 100], [101, 107], [108, 119], [120, 130], [131, 138], [138, 139], [140, 143], [144, 157], [158, 168], [169, 171], [172, 180], [181, 196], [196, 197], [198, 201], [202, 212], [213, 215], [216, 224], [225, 231], [232, 235], [236, 243], [244, 255], [255, 256], [257, 260], [261, 274], [275, 285], [286, 288], [289, 297], [298, 304], [305, 308], [309, 312], [313, 321], [322, 332], [333, 335], [336, 344], [345, 351], [351, 352]]}
{"doc_key": "ai-dev-70", "ner": [[1, 2, "algorithm"], [9, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 1, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "condensation", "algorithm", "has", "also", "been", "used", "for", "a", "facial", "recognition", "system", "in", "a", "video", "sequence", "."], "sentence-detokenized": "The condensation algorithm has also been used for a facial recognition system in a video sequence.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 30], [31, 35], [36, 40], [41, 45], [46, 49], [50, 51], [52, 58], [59, 70], [71, 77], [78, 80], [81, 82], [83, 88], [89, 97], [97, 98]]}
{"doc_key": "ai-dev-71", "ner": [[0, 3, "task"], [7, 7, "organisation"], [20, 20, "conference"], [25, 29, "academicjournal"], [32, 32, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 20, 0, 3, "topic", "", false, false], [20, 20, 7, 7, "origin", "", false, false], [25, 29, 0, 3, "topic", "", false, false], [25, 29, 7, 7, "origin", "", true, false], [32, 32, 25, 29, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Dissemination", "of", "information", "is", "also", "part", "of", "ELRA", "'s", "mission", ",", "which", "is", "reflected", "both", "in", "the", "organisation", "of", "the", "LREC", "conference", "and", "in", "the", "Language", "Resources", "and", "Evaluation", "Journal", "published", "by", "Springer", "."], "sentence-detokenized": "Dissemination of information is also part of ELRA's mission, which is reflected both in the organisation of the LREC conference and in the Language Resources and Evaluation Journal published by Springer.", "token2charspan": [[0, 13], [14, 16], [17, 28], [29, 31], [32, 36], [37, 41], [42, 44], [45, 49], [49, 51], [52, 59], [59, 60], [61, 66], [67, 69], [70, 79], [80, 84], [85, 87], [88, 91], [92, 104], [105, 107], [108, 111], [112, 116], [117, 127], [128, 131], [132, 134], [135, 138], [139, 147], [148, 157], [158, 161], [162, 172], [173, 180], [181, 190], [191, 193], [194, 202], [202, 203]]}
{"doc_key": "ai-dev-72", "ner": [[1, 9, "field"], [11, 12, "field"], [14, 16, "field"], [18, 19, "field"], [53, 54, "field"], [59, 59, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 9, 53, 54, "named", "", false, false], [14, 16, 1, 9, "named", "", false, false], [59, 59, 11, 12, "part-of", "", true, false], [59, 59, 14, 16, "part-of", "", true, false], [59, 59, 53, 54, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "linear", "time", "-", "invariant", "(", "LTI", ")", "system", "theory", ",", "control", "theory", "and", "digital", "signal", "processing", "or", "signal", "processing", ",", "the", "relationship", "between", "the", "input", "signal", ",", "math", "displaystyle", "x", "(", "t", ")", "/", "math", ",", "and", "the", "output", "signal", ",", "math", "displaystyle", "y", "(", "t", ")", "/", "math", ",", "of", "an", "LTI", "system", "is", "governed", "by", "a", "convolution", "operation", ":"], "sentence-detokenized": "In linear time-invariant (LTI) system theory, control theory and digital signal processing or signal processing, the relationship between the input signal, math displaystyle x (t) / math, and the output signal, math displaystyle y (t) / math, of an LTI system is governed by a convolution operation:", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [15, 24], [25, 26], [26, 29], [29, 30], [31, 37], [38, 44], [44, 45], [46, 53], [54, 60], [61, 64], [65, 72], [73, 79], [80, 90], [91, 93], [94, 100], [101, 111], [111, 112], [113, 116], [117, 129], [130, 137], [138, 141], [142, 147], [148, 154], [154, 155], [156, 160], [161, 173], [174, 175], [176, 177], [177, 178], [178, 179], [180, 181], [182, 186], [186, 187], [188, 191], [192, 195], [196, 202], [203, 209], [209, 210], [211, 215], [216, 228], [229, 230], [231, 232], [232, 233], [233, 234], [235, 236], [237, 241], [241, 242], [243, 245], [246, 248], [249, 252], [253, 259], [260, 262], [263, 271], [272, 274], [275, 276], [277, 288], [289, 298], [298, 299]]}
{"doc_key": "ai-dev-73", "ner": [[16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 31, "field"], [33, 34, "product"], [36, 37, "field"], [39, 39, "field"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Because", "of", "its", "generality", ",", "the", "field", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "artificial", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Because of its generality, the field is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, artificial intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [25, 26], [27, 30], [31, 36], [37, 39], [40, 47], [48, 50], [51, 55], [56, 61], [62, 73], [73, 74], [75, 79], [80, 82], [83, 87], [88, 94], [94, 95], [96, 103], [104, 110], [110, 111], [112, 122], [123, 131], [131, 132], [133, 144], [145, 151], [151, 152], [153, 163], [163, 164], [164, 169], [170, 182], [182, 183], [184, 195], [196, 203], [203, 204], [205, 215], [216, 228], [228, 229], [230, 240], [241, 244], [245, 252], [253, 263], [263, 264]]}
{"doc_key": "ai-dev-74", "ner": [[0, 2, "algorithm"], [15, 16, "field"], [22, 23, "algorithm"], [26, 27, "algorithm"], [34, 35, "algorithm"], [38, 38, "algorithm"], [39, 41, "researcher"], [43, 44, "researcher"], [46, 48, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[15, 16, 0, 2, "usage", "", true, false], [22, 23, 15, 16, "part-of", "", true, false], [26, 27, 15, 16, "part-of", "", true, false], [34, 35, 15, 16, "part-of", "", true, false], [38, 38, 15, 16, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Stochastic", "gradient", "descent", "is", "a", "popular", "algorithm", "for", "training", "a", "wide", "range", "of", "models", "in", "machine", "learning", ",", "including", "(", "linear", ")", "support", "vector", "machines", ",", "logistic", "regression", "(", "see", ",", "for", "example", ",", "Vowpal", "Wabbit", ")", "and", "graphical", "models.Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastic gradient descent is a popular algorithm for training a wide range of models in machine learning, including (linear) support vector machines, logistic regression (see, for example, Vowpal Wabbit) and graphical models.Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 30], [31, 32], [33, 40], [41, 50], [51, 54], [55, 63], [64, 65], [66, 70], [71, 76], [77, 79], [80, 86], [87, 89], [90, 97], [98, 106], [106, 107], [108, 117], [118, 119], [119, 125], [125, 126], [127, 134], [135, 141], [142, 150], [150, 151], [152, 160], [161, 171], [172, 173], [173, 176], [176, 177], [178, 181], [182, 189], [189, 190], [191, 197], [198, 204], [204, 205], [206, 209], [210, 219], [220, 232], [233, 237], [238, 244], [244, 245], [246, 250], [251, 258], [258, 259], [260, 271], [272, 274], [275, 282], [283, 284], [284, 288], [288, 289], [289, 290]]}
{"doc_key": "ai-dev-75", "ner": [[8, 8, "organisation"], [12, 13, "product"], [21, 21, "country"], [23, 25, "university"], [27, 27, "location"], [29, 31, "university"], [33, 33, "location"], [35, 36, "university"], [38, 38, "location"], [40, 42, "university"], [44, 44, "location"], [46, 47, "university"], [49, 49, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 23, 25, "role", "donates_to", false, false], [8, 8, 29, 31, "role", "donates_to", false, false], [8, 8, 35, 36, "role", "donates_to", false, false], [8, 8, 40, 42, "role", "donates_to", false, false], [8, 8, 46, 47, "role", "donates_to", false, false], [12, 13, 8, 8, "origin", "donates", true, false], [23, 25, 27, 27, "physical", "", false, false], [27, 27, 21, 21, "physical", "", false, false], [29, 31, 33, 33, "physical", "", false, false], [33, 33, 21, 21, "physical", "", false, false], [35, 36, 38, 38, "physical", "", false, false], [38, 38, 21, 21, "physical", "", false, false], [40, 42, 44, 44, "physical", "", false, false], [44, 44, 21, 21, "physical", "", false, false], [46, 47, 49, 49, "physical", "", false, false], [49, 49, 21, 21, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["In", "August", "2011", ",", "it", "was", "announced", "that", "Hitachi", "would", "donate", "an", "electron", "microscope", "to", "each", "of", "the", "five", "universities", "in", "Indonesia", "(", "North", "Sumatra", "University", "in", "Medan", ",", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Padjadjaran", "University", "in", "Bandung", ",", "Jenderal", "Soedirman", "University", "in", "Purwokerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "sentence-detokenized": "In August 2011, it was announced that Hitachi would donate an electron microscope to each of the five universities in Indonesia (North Sumatra University in Medan, Indonesian Christian University in Jakarta, Padjadjaran University in Bandung, Jenderal Soedirman University in Purwokerto and Muhammadiyah University in Malang).", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 32], [33, 37], [38, 45], [46, 51], [52, 58], [59, 61], [62, 70], [71, 81], [82, 84], [85, 89], [90, 92], [93, 96], [97, 101], [102, 114], [115, 117], [118, 127], [128, 129], [129, 134], [135, 142], [143, 153], [154, 156], [157, 162], [162, 163], [164, 174], [175, 184], [185, 195], [196, 198], [199, 206], [206, 207], [208, 219], [220, 230], [231, 233], [234, 241], [241, 242], [243, 251], [252, 261], [262, 272], [273, 275], [276, 286], [287, 290], [291, 303], [304, 314], [315, 317], [318, 324], [324, 325], [325, 326]]}
{"doc_key": "ai-dev-76", "ner": [[2, 2, "field"], [0, 1, "field"], [7, 8, "algorithm"], [10, 11, "algorithm"], [20, 21, "field"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 0, 1, "part-of", "", false, false], [2, 2, 20, 21, "related-to", "", true, false], [2, 2, 26, 27, "related-to", "", true, false], [7, 8, 2, 2, "type-of", "", false, false], [10, 11, 2, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Operations", "research", "optimisation", "techniques", ",", "such", "as", "linear", "programming", "or", "dynamic", "programming", ",", "are", "often", "impractical", "for", "large", "-", "scale", "software", "engineering", "problems", "due", "to", "their", "computational", "complexity", "."], "sentence-detokenized": "Operations research optimisation techniques, such as linear programming or dynamic programming, are often impractical for large-scale software engineering problems due to their computational complexity.", "token2charspan": [[0, 10], [11, 19], [20, 32], [33, 43], [43, 44], [45, 49], [50, 52], [53, 59], [60, 71], [72, 74], [75, 82], [83, 94], [94, 95], [96, 99], [100, 105], [106, 117], [118, 121], [122, 127], [127, 128], [128, 133], [134, 142], [143, 154], [155, 163], [164, 167], [168, 170], [171, 176], [177, 190], [191, 201], [201, 202]]}
{"doc_key": "ai-dev-77", "ner": [[0, 0, "metrics"], [4, 4, "metrics"], [6, 8, "metrics"], [12, 13, "metrics"], [15, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 4, 4, "compare", "", false, false], [0, 0, 6, 8, "compare", "", false, false], [12, 13, 6, 8, "part-of", "", false, false], [15, 18, 6, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sensitivity", "is", "different", "from", "accuracy", "or", "positive", "predictive", "value", "(", "ratio", "of", "TRUE", "positives", "to", "TRUE", "and", "FALSE", "positives", "combined", ")", ",", "which", "is", "as", "much", "a", "statement", "about", "the", "proportion", "of", "true", "positives", "in", "the", "population", "tested", "as", "it", "is", "about", "the", "test", "."], "sentence-detokenized": "Sensitivity is different from accuracy or positive predictive value (ratio of TRUE positives to TRUE and FALSE positives combined), which is as much a statement about the proportion of true positives in the population tested as it is about the test.", "token2charspan": [[0, 11], [12, 14], [15, 24], [25, 29], [30, 38], [39, 41], [42, 50], [51, 61], [62, 67], [68, 69], [69, 74], [75, 77], [78, 82], [83, 92], [93, 95], [96, 100], [101, 104], [105, 110], [111, 120], [121, 129], [129, 130], [130, 131], [132, 137], [138, 140], [141, 143], [144, 148], [149, 150], [151, 160], [161, 166], [167, 170], [171, 181], [182, 184], [185, 189], [190, 199], [200, 202], [203, 206], [207, 217], [218, 224], [225, 227], [228, 230], [231, 233], [234, 239], [240, 243], [244, 248], [248, 249]]}
{"doc_key": "ai-dev-78", "ner": [[1, 2, "person"], [10, 10, "product"], [13, 13, "person"], [27, 27, "person"], [34, 35, "person"], [39, 39, "person"], [45, 46, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 2, 39, 39, "named", "same", false, false], [10, 10, 1, 2, "artifact", "", false, false], [34, 35, 45, 46, "role", "convinces", false, false], [45, 46, 10, 10, "role", "producer", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Hampton", "Fancher", "!", "--", "which", "was", "not", "originally", "called", "Android", "-", "see", "Sammon", ",", "pp.", "32", "-", "38", "for", "explanation", "--", "was", "optioned", "in", "1977", ".", "Sammon", ",", "pp.", "23", "-", "30", "Producer", "Michael", "Deeley", "became", "interested", "in", "Fancher", "'s", "project", "and", "convinced", "director", "Ridley", "Scott", "to", "make", "it", "."], "sentence-detokenized": "The Hampton Fancher! -- which was not originally called Android - see Sammon, pp. 32-38 for explanation -- was optioned in 1977. Sammon, pp. 23-30 Producer Michael Deeley became interested in Fancher's project and convinced director Ridley Scott to make it.", "token2charspan": [[0, 3], [4, 11], [12, 19], [19, 20], [21, 23], [24, 29], [30, 33], [34, 37], [38, 48], [49, 55], [56, 63], [64, 65], [66, 69], [70, 76], [76, 77], [78, 81], [82, 84], [84, 85], [85, 87], [88, 91], [92, 103], [104, 106], [107, 110], [111, 119], [120, 122], [123, 127], [127, 128], [129, 135], [135, 136], [137, 140], [141, 143], [143, 144], [144, 146], [147, 155], [156, 163], [164, 170], [171, 177], [178, 188], [189, 191], [192, 199], [199, 201], [202, 209], [210, 213], [214, 223], [224, 232], [233, 239], [240, 245], [246, 248], [249, 253], [254, 256], [256, 257]]}
{"doc_key": "ai-dev-79", "ner": [[0, 1, "field"], [3, 4, "task"], [6, 7, "task"], [11, 14, "misc"], [16, 17, "field"], [19, 21, "task"], [23, 24, "task"], [26, 27, "field"], [30, 33, "task"], [35, 35, "task"], [37, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [6, 7, 0, 1, "part-of", "", false, false], [11, 14, 0, 1, "part-of", "", false, false], [16, 17, 0, 1, "part-of", "", false, false], [19, 21, 0, 1, "part-of", "", false, false], [23, 24, 0, 1, "part-of", "", false, false], [26, 27, 0, 1, "part-of", "", false, false], [30, 33, 0, 1, "part-of", "", false, false], [35, 35, 0, 1, "part-of", "", false, false], [37, 38, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Text", "analysis", "includes", "information", "retrieval", ",", "lexical", "analysis", "to", "study", "the", "frequency", "distribution", "of", "words", ",", "pattern", "recognition", ",", "labelling", "and", "annotation", ",", "information", "extraction", ",", "data", "mining", "techniques", "including", "link", "and", "association", "analysis", ",", "visualisation", "and", "predictive", "analysis", "."], "sentence-detokenized": "Text analysis includes information retrieval, lexical analysis to study the frequency distribution of words, pattern recognition, labelling and annotation, information extraction, data mining techniques including link and association analysis, visualisation and predictive analysis.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 34], [35, 44], [44, 45], [46, 53], [54, 62], [63, 65], [66, 71], [72, 75], [76, 85], [86, 98], [99, 101], [102, 107], [107, 108], [109, 116], [117, 128], [128, 129], [130, 139], [140, 143], [144, 154], [154, 155], [156, 167], [168, 178], [178, 179], [180, 184], [185, 191], [192, 202], [203, 212], [213, 217], [218, 221], [222, 233], [234, 242], [242, 243], [244, 257], [258, 261], [262, 272], [273, 281], [281, 282]]}
{"doc_key": "ai-dev-80", "ner": [[3, 3, "product"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Several", "measures", "use", "WordNet", ",", "a", "manually", "constructed", "lexical", "database", "of", "English", "words", "."], "sentence-detokenized": "Several measures use WordNet, a manually constructed lexical database of English words.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 28], [28, 29], [30, 31], [32, 40], [41, 52], [53, 60], [61, 69], [70, 72], [73, 80], [81, 86], [86, 87]]}
{"doc_key": "ai-dev-81", "ner": [[6, 7, "field"], [9, 10, "task"], [12, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "system", "uses", "a", "combination", "of", "computational", "linguistics", ",", "information", "retrieval", "and", "knowledge", "representation", "techniques", "to", "find", "answers", "."], "sentence-detokenized": "The system uses a combination of computational linguistics, information retrieval and knowledge representation techniques to find answers.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 17], [18, 29], [30, 32], [33, 46], [47, 58], [58, 59], [60, 71], [72, 81], [82, 85], [86, 95], [96, 110], [111, 121], [122, 124], [125, 129], [130, 137], [137, 138]]}
{"doc_key": "ai-dev-82", "ner": [[6, 7, "metrics"], [13, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 13, 16, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "performance", "measure", ",", "the", "uncertainty", "coefficient", "has", "the", "advantage", "over", "simple", "precision", "that", "it", "is", "not", "affected", "by", "the", "relative", "sizes", "of", "the", "different", "classes", "."], "sentence-detokenized": "As a performance measure, the uncertainty coefficient has the advantage over simple precision that it is not affected by the relative sizes of the different classes.", "token2charspan": [[0, 2], [3, 4], [5, 16], [17, 24], [24, 25], [26, 29], [30, 41], [42, 53], [54, 57], [58, 61], [62, 71], [72, 76], [77, 83], [84, 93], [94, 98], [99, 101], [102, 104], [105, 108], [109, 117], [118, 120], [121, 124], [125, 133], [134, 139], [140, 142], [143, 146], [147, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-dev-83", "ner": [[9, 10, "algorithm"], [12, 13, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "researchers", "tried", "a", "number", "of", "methods", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "hidden", "Markov", "models", ",", "etc", "."], "sentence-detokenized": "The researchers tried a number of methods such as optical flow, Kalman filtering, hidden Markov models, etc.", "token2charspan": [[0, 3], [4, 15], [16, 21], [22, 23], [24, 30], [31, 33], [34, 41], [42, 46], [47, 49], [50, 57], [58, 62], [62, 63], [64, 70], [71, 80], [80, 81], [82, 88], [89, 95], [96, 102], [102, 103], [104, 107], [107, 108]]}
{"doc_key": "ai-dev-84", "ner": [[14, 17, "conference"], [35, 37, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "has", "served", "as", "President", ",", "Vice", "President", "and", "Secretary", "-", "Treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "has", "been", "a", "member", "of", "the", "Board", "of", "Directors", "and", "Secretary", "to", "the", "Board", "of", "the", "Computing", "Research", "Association", "."], "sentence-detokenized": "She has served as President, Vice President and Secretary-Treasurer of the Association for Computational Linguistics and has been a member of the Board of Directors and Secretary to the Board of the Computing Research Association.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 17], [18, 27], [27, 28], [29, 33], [34, 43], [44, 47], [48, 57], [57, 58], [58, 67], [68, 70], [71, 74], [75, 86], [87, 90], [91, 104], [105, 116], [117, 120], [121, 124], [125, 129], [130, 131], [132, 138], [139, 141], [142, 145], [146, 151], [152, 154], [155, 164], [165, 168], [169, 178], [179, 181], [182, 185], [186, 191], [192, 194], [195, 198], [199, 208], [209, 217], [218, 229], [229, 230]]}
{"doc_key": "ai-dev-85", "ner": [[6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 10, 10, "compare", "", false, false], [6, 6, 12, 13, "related-to", "supports", false, false], [8, 8, 10, 10, "compare", "", false, false], [8, 8, 12, 13, "related-to", "supports", false, false], [10, 10, 12, 13, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Like", "other", "similar", "languages", "such", "as", "APL", "and", "MATLAB", ",", "R", "supports", "matrix", "arithmetic", "."], "sentence-detokenized": "Like other similar languages such as APL and MATLAB, R supports matrix arithmetic.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 28], [29, 33], [34, 36], [37, 40], [41, 44], [45, 51], [51, 52], [53, 54], [55, 63], [64, 70], [71, 81], [81, 82]]}
{"doc_key": "ai-dev-86", "ner": [[7, 8, "misc"], [12, 13, "organisation"], [17, 18, "researcher"], [21, 23, "university"], [27, 32, "misc"], [34, 34, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 8, 12, 13, "physical", "", false, false], [7, 8, 27, 32, "temporal", "", false, false], [17, 18, 7, 8, "role", "arranges", false, false], [17, 18, 21, 23, "role", "works_for", false, false], [34, 34, 7, 8, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "7", "June", "2014", ",", "in", "a", "Turing", "test", "competition", "at", "the", "Royal", "Society", ",", "organised", "by", "Kevin", "Warwick", "of", "the", "University", "of", "Reading", "to", "mark", "the", "60th", "anniversary", "of", "Turing", "'s", "death", ",", "Goostman", "won", "after", "33", "per", "cent", "of", "the", "judges", "were", "convinced", "that", "the", "bot", "was", "human", "."], "sentence-detokenized": "On 7 June 2014, in a Turing test competition at the Royal Society, organised by Kevin Warwick of the University of Reading to mark the 60th anniversary of Turing's death, Goostman won after 33 per cent of the judges were convinced that the bot was human.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 14], [14, 15], [16, 18], [19, 20], [21, 27], [28, 32], [33, 44], [45, 47], [48, 51], [52, 57], [58, 65], [65, 66], [67, 76], [77, 79], [80, 85], [86, 93], [94, 96], [97, 100], [101, 111], [112, 114], [115, 122], [123, 125], [126, 130], [131, 134], [135, 139], [140, 151], [152, 154], [155, 161], [161, 163], [164, 169], [169, 170], [171, 179], [180, 183], [184, 189], [190, 192], [193, 196], [197, 201], [202, 204], [205, 208], [209, 215], [216, 220], [221, 230], [231, 235], [236, 239], [240, 243], [244, 247], [248, 253], [253, 254]]}
{"doc_key": "ai-dev-87", "ner": [[1, 2, "product"], [4, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "collaborative", "robot", "or", "cobot", "is", "a", "robot", "that", "can", "interact", "safely", "and", "effectively", "with", "human", "workers", "while", "performing", "simple", "industrial", "tasks", "."], "sentence-detokenized": "A collaborative robot or cobot is a robot that can interact safely and effectively with human workers while performing simple industrial tasks.", "token2charspan": [[0, 1], [2, 15], [16, 21], [22, 24], [25, 30], [31, 33], [34, 35], [36, 41], [42, 46], [47, 50], [51, 59], [60, 66], [67, 70], [71, 82], [83, 87], [88, 93], [94, 101], [102, 107], [108, 118], [119, 125], [126, 136], [137, 142], [142, 143]]}
{"doc_key": "ai-dev-88", "ner": [[11, 12, "field"], [16, 17, "task"], [19, 20, "task"], [22, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[16, 17, 11, 12, "part-of", "task_part_of_field", false, false], [19, 20, 11, 12, "part-of", "task_part_of_field", false, false], [22, 23, 11, 12, "part-of", "task_part_of_field", false, false], [25, 26, 11, 12, "part-of", "task_part_of_field", false, false], [28, 29, 11, 12, "part-of", "task_part_of_field", false, false], [31, 33, 11, 12, "part-of", "task_part_of_field", false, false], [35, 36, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "general", "framework", "has", "been", "applied", "to", "a", "wide", "variety", "of", "computer", "vision", "problems", ",", "including", "feature", "detection", ",", "feature", "classification", ",", "image", "segmentation", ",", "image", "matching", ",", "motion", "estimation", ",", "shape", "index", "computation", "and", "object", "recognition", "."], "sentence-detokenized": "This general framework has been applied to a wide variety of computer vision problems, including feature detection, feature classification, image segmentation, image matching, motion estimation, shape index computation and object recognition.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 26], [27, 31], [32, 39], [40, 42], [43, 44], [45, 49], [50, 57], [58, 60], [61, 69], [70, 76], [77, 85], [85, 86], [87, 96], [97, 104], [105, 114], [114, 115], [116, 123], [124, 138], [138, 139], [140, 145], [146, 158], [158, 159], [160, 165], [166, 174], [174, 175], [176, 182], [183, 193], [193, 194], [195, 200], [201, 206], [207, 218], [219, 222], [223, 229], [230, 241], [241, 242]]}
{"doc_key": "ai-dev-89", "ner": [[6, 7, "task"], [9, 11, "algorithm"], [14, 15, "algorithm"], [27, 28, "algorithm"], [32, 33, "algorithm"], [36, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 9, 11, "part-of", "", false, false], [6, 7, 14, 15, "usage", "", false, false], [9, 11, 27, 28, "named", "same", false, false], [27, 28, 32, 33, "related-to", "", false, false], [27, 28, 36, 37, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "many", "practical", "applications", ",", "the", "parameter", "estimation", "of", "naive", "Bayes", "models", "uses", "the", "maximum", "likelihood", "method", ";", "in", "other", "words", ",", "one", "can", "work", "with", "the", "naive", "Bayes", "model", "without", "accepting", "Bayesian", "probability", "or", "using", "Bayesian", "methods", "."], "sentence-detokenized": "In many practical applications, the parameter estimation of naive Bayes models uses the maximum likelihood method; in other words, one can work with the naive Bayes model without accepting Bayesian probability or using Bayesian methods.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 30], [30, 31], [32, 35], [36, 45], [46, 56], [57, 59], [60, 65], [66, 71], [72, 78], [79, 83], [84, 87], [88, 95], [96, 106], [107, 113], [113, 114], [115, 117], [118, 123], [124, 129], [129, 130], [131, 134], [135, 138], [139, 143], [144, 148], [149, 152], [153, 158], [159, 164], [165, 170], [171, 178], [179, 188], [189, 197], [198, 209], [210, 212], [213, 218], [219, 227], [228, 235], [235, 236]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [12, 15, "university"], [17, 19, "researcher"], [21, 22, "misc"], [26, 26, "university"], [28, 28, "university"], [31, 31, "misc"], [38, 40, "university"], [46, 49, "misc"], [51, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 4, 12, 15, "physical", "", false, false], [2, 4, 12, 15, "role", "", false, false], [2, 4, 17, 19, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [17, 19, 26, 26, "physical", "", false, false], [17, 19, 26, 26, "role", "", false, false], [17, 19, 28, 28, "physical", "", false, false], [17, 19, 28, 28, "role", "", false, false], [17, 19, 38, 40, "physical", "", false, false], [17, 19, 38, 40, "role", "", false, false], [21, 22, 17, 19, "named", "", false, false], [31, 31, 17, 19, "origin", "", false, false], [46, 49, 17, 19, "artifact", "", false, false], [46, 49, 51, 54, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Brothers", "-", "Victor", "Gershevich", "Katz", ",", "American", "mathematician", ",", "professor", "at", "the", "Massachusetts", "Institute", "of", "Technology", ";", "Mikhail", "Gershevich", "Katz", ",", "Israeli", "mathematician", ",", "graduate", "of", "Harvard", "and", "Columbia", "Universities", "(", "Ph.D.", ",", "1984", ")", ",", "professor", "at", "Bar-", "Ilan", "University", ",", "author", "of", "the", "monograph", "Systolic", "Geometry", "and", "Topology", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", "."], "sentence-detokenized": "Brothers - Victor Gershevich Katz, American mathematician, professor at the Massachusetts Institute of Technology; Mikhail Gershevich Katz, Israeli mathematician, graduate of Harvard and Columbia Universities (Ph.D., 1984), professor at Bar-Ilan University, author of the monograph Systolic Geometry and Topology (Mathematical Surveys and Monographs, vol.", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 28], [29, 33], [33, 34], [35, 43], [44, 57], [57, 58], [59, 68], [69, 71], [72, 75], [76, 89], [90, 99], [100, 102], [103, 113], [113, 114], [115, 122], [123, 133], [134, 138], [138, 139], [140, 147], [148, 161], [161, 162], [163, 171], [172, 174], [175, 182], [183, 186], [187, 195], [196, 208], [209, 210], [210, 215], [215, 216], [217, 221], [221, 222], [222, 223], [224, 233], [234, 236], [237, 241], [241, 245], [246, 256], [256, 257], [258, 264], [265, 267], [268, 271], [272, 281], [282, 290], [291, 299], [300, 303], [304, 312], [313, 314], [314, 326], [327, 334], [335, 338], [339, 349], [349, 350], [351, 354], [354, 355]]}
{"doc_key": "ai-dev-91", "ner": [[3, 4, "person"], [10, 11, "conference"], [16, 19, "organisation"], [22, 28, "location"], [32, 32, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 10, 11, "physical", "", false, false], [3, 4, 10, 11, "role", "", false, false], [3, 4, 16, 19, "role", "", false, false], [16, 19, 22, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2000", ",", "Manuel", "Toharia", ",", "a", "speaker", "at", "previous", "Campus", "Parties", "and", "director", "of", "the", "Pr\u00edncipe", "Felipe", "Science", "Museum", "in", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", ",", "suggested", "that", "Ragageles", "expand", "and", "make", "the", "event", "more", "international", "by", "moving", "it", "to", "the", "famous", "museum", "."], "sentence-detokenized": "In 2000, Manuel Toharia, a speaker at previous Campus Parties and director of the Pr\u00edncipe Felipe Science Museum in the City of Arts and Sciences in Valencia, suggested that Ragageles expand and make the event more international by moving it to the famous museum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 23], [23, 24], [25, 26], [27, 34], [35, 37], [38, 46], [47, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 81], [82, 90], [91, 97], [98, 105], [106, 112], [113, 115], [116, 119], [120, 124], [125, 127], [128, 132], [133, 136], [137, 145], [146, 148], [149, 157], [157, 158], [159, 168], [169, 173], [174, 183], [184, 190], [191, 194], [195, 199], [200, 203], [204, 209], [210, 214], [215, 228], [229, 231], [232, 238], [239, 241], [242, 244], [245, 248], [249, 255], [256, 262], [262, 263]]}
{"doc_key": "ai-dev-92", "ner": [[5, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Within", "20", "minutes", ",", "a", "facial", "recognition", "system", "identifies", "personal", "information", ",", "including", "surname", ",", "ID", "number", "and", "address", ",", "which", "is", "displayed", "in", "the", "street", "on", "an", "advertising", "screen", "."], "sentence-detokenized": "Within 20 minutes, a facial recognition system identifies personal information, including surname, ID number and address, which is displayed in the street on an advertising screen.", "token2charspan": [[0, 6], [7, 9], [10, 17], [17, 18], [19, 20], [21, 27], [28, 39], [40, 46], [47, 57], [58, 66], [67, 78], [78, 79], [80, 89], [90, 97], [97, 98], [99, 101], [102, 108], [109, 112], [113, 120], [120, 121], [122, 127], [128, 130], [131, 140], [141, 143], [144, 147], [148, 154], [155, 157], [158, 160], [161, 172], [173, 179], [179, 180]]}
{"doc_key": "ai-dev-93", "ner": [[6, 9, "field"], [8, 8, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "research", "has", "increasingly", "focused", "on", "unsupervised", "and", "semi-supervised", "learning", "algorithms", "."], "sentence-detokenized": "Recent research has increasingly focused on unsupervised and semi-supervised learning algorithms.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 32], [33, 40], [41, 43], [44, 56], [57, 60], [61, 76], [77, 85], [86, 96], [96, 97]]}
{"doc_key": "ai-dev-94", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Calculation", "of", "this", "example", "using", "the", "Python", "code", ":"], "sentence-detokenized": "Calculation of this example using the Python code :", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 27], [28, 33], [34, 37], [38, 44], [45, 49], [50, 51]]}
{"doc_key": "ai-dev-95", "ner": [[7, 12, "task"], [15, 16, "field"], [19, 22, "algorithm"], [24, 24, "algorithm"], [28, 30, "algorithm"], [33, 34, "researcher"], [36, 37, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[19, 22, 15, 16, "part-of", "", false, false], [19, 22, 28, 30, "type-of", "", false, false], [19, 22, 33, 34, "origin", "", false, false], [19, 22, 36, 37, "origin", "", false, false], [24, 24, 19, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Today", ",", "however", ",", "many", "aspects", "of", "speech", "recognition", "have", "been", "taken", "over", "by", "a", "deep", "learning", "method", "called", "long", "-", "term", "memory", "(", "LSTM", ")", ",", "a", "recurrent", "neural", "network", "published", "by", "Sepp", "Hochreiter", "&", "J\u00fcrgen", "Schmidhuber", "in", "1997", "."], "sentence-detokenized": "Today, however, many aspects of speech recognition have been taken over by a deep learning method called long-term memory (LSTM), a recurrent neural network published by Sepp Hochreiter & J\u00fcrgen Schmidhuber in 1997.", "token2charspan": [[0, 5], [5, 6], [7, 14], [14, 15], [16, 20], [21, 28], [29, 31], [32, 38], [39, 50], [51, 55], [56, 60], [61, 66], [67, 71], [72, 74], [75, 76], [77, 81], [82, 90], [91, 97], [98, 104], [105, 109], [109, 110], [110, 114], [115, 121], [122, 123], [123, 127], [127, 128], [128, 129], [130, 131], [132, 141], [142, 148], [149, 156], [157, 166], [167, 169], [170, 174], [175, 185], [186, 187], [188, 194], [195, 206], [207, 209], [210, 214], [214, 215]]}
{"doc_key": "ai-dev-96", "ner": [[9, 9, "algorithm"], [15, 15, "algorithm"], [19, 19, "algorithm"], [24, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 15, 15, "compare", "", false, false], [9, 9, 24, 24, "named", "same", false, false], [19, 19, 24, 24, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "preliminary", "experimental", "results", "with", "noisy", "data", "sets", ",", "BrownBoost", "outperformed", "the", "generalisation", "error", "of", "AdaBoost", ";", "however", ",", "LogitBoost", "performed", "as", "well", "as", "BrownBoost", "."], "sentence-detokenized": "In preliminary experimental results with noisy data sets, BrownBoost outperformed the generalisation error of AdaBoost; however, LogitBoost performed as well as BrownBoost.", "token2charspan": [[0, 2], [3, 14], [15, 27], [28, 35], [36, 40], [41, 46], [47, 51], [52, 56], [56, 57], [58, 68], [69, 81], [82, 85], [86, 100], [101, 106], [107, 109], [110, 118], [118, 119], [120, 127], [127, 128], [129, 139], [140, 149], [150, 152], [153, 157], [158, 160], [161, 171], [171, 172]]}
{"doc_key": "ai-dev-97", "ner": [[0, 2, "algorithm"], [5, 7, "researcher"], [10, 11, "country"], [14, 16, "researcher"], [21, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 7, "part-of", "", false, false], [5, 7, 10, 11, "physical", "", false, false], [21, 22, 14, 16, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evolutionary", "programming", "was", "introduced", "by", "Lawrence", "J.", "Fogel", "in", "the", "United", "States", ",", "while", "John", "Henry", "Holland", "called", "his", "method", "a", "genetic", "algorithm", "."], "sentence-detokenized": "Evolutionary programming was introduced by Lawrence J. Fogel in the United States, while John Henry Holland called his method a genetic algorithm.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 54], [55, 60], [61, 63], [64, 67], [68, 74], [75, 81], [81, 82], [83, 88], [89, 93], [94, 99], [100, 107], [108, 114], [115, 118], [119, 125], [126, 127], [128, 135], [136, 145], [145, 146]]}
{"doc_key": "ai-dev-98", "ner": [[3, 3, "researcher"], [5, 5, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 11, 12, "role", "", false, false], [3, 3, 14, 15, "role", "", false, false], [3, 3, 17, 18, "role", "", false, false], [3, 3, 20, 21, "role", "", false, false], [5, 5, 11, 12, "role", "", false, false], [5, 5, 14, 15, "role", "", false, false], [5, 5, 17, 18, "role", "", false, false], [5, 5, 20, 21, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Backwards", "calculations", "by", "Doug", ",", "Alan", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", "and", "John", "McCarthy", ")", "indicated", "that", "this", "effort", "would", "require", "between", "1000", "and", "3000", "person", "-", "years", ",", "well", "beyond", "the", "standard", "university", "project", "model", "."], "sentence-detokenized": "Backwards calculations by Doug, Alan and their colleagues (including Marvin Minsky, Allen Newell, Edward Feigenbaum and John McCarthy) indicated that this effort would require between 1000 and 3000 person-years, well beyond the standard university project model.", "token2charspan": [[0, 9], [10, 22], [23, 25], [26, 30], [30, 31], [32, 36], [37, 40], [41, 46], [47, 57], [58, 59], [59, 68], [69, 75], [76, 82], [82, 83], [84, 89], [90, 96], [96, 97], [98, 104], [105, 115], [116, 119], [120, 124], [125, 133], [133, 134], [135, 144], [145, 149], [150, 154], [155, 161], [162, 167], [168, 175], [176, 183], [184, 188], [189, 192], [193, 197], [198, 204], [204, 205], [205, 210], [210, 211], [212, 216], [217, 223], [224, 227], [228, 236], [237, 247], [248, 255], [256, 261], [261, 262]]}
{"doc_key": "ai-dev-99", "ner": [[5, 7, "metrics"], [11, 11, "metrics"], [14, 16, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 11, 11, "part-of", "implemented_in", false, false], [14, 16, 19, 19, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "common", "criteria", "are", "the", "mean", "square", "error", "criterion", "implemented", "in", "MSECriterion", "and", "the", "cross", "-entropy", "criterion", "implemented", "in", "NLLCriterion", "."], "sentence-detokenized": "The common criteria are the mean square error criterion implemented in MSECriterion and the cross-entropy criterion implemented in NLLCriterion.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 23], [24, 27], [28, 32], [33, 39], [40, 45], [46, 55], [56, 67], [68, 70], [71, 83], [84, 87], [88, 91], [92, 97], [97, 105], [106, 115], [116, 127], [128, 130], [131, 143], [143, 144]]}
{"doc_key": "ai-dev-100", "ner": [[0, 0, "researcher"], [11, 11, "organisation"], [15, 25, "misc"], [31, 34, "conference"], [42, 42, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 11, 11, "role", "", false, false], [0, 0, 31, 34, "role", "", false, false], [0, 0, 42, 42, "role", "", false, false], [15, 25, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zurada", "has", "served", "the", "engineering", "profession", "as", "a", "long", "-", "time", "IEEE", "volunteer", ":", "in", "2014", ",", "he", "served", "as", "IEEE", "Vice", "President", "for", "Technical", "Activities", "(", "TAB", "Chair", ")", ",", "IEEE", "Computational", "Intelligence", "Society", "Chair", "in", "2004", "-", "05", ",", "and", "ADCOM", "member", "in", "2009", "-", "14", ",", "2016", "-", "18", "and", "previous", "years", "."], "sentence-detokenized": "Zurada has served the engineering profession as a long-time IEEE volunteer: in 2014, he served as IEEE Vice President for Technical Activities (TAB Chair), IEEE Computational Intelligence Society Chair in 2004-05, and ADCOM member in 2009-14, 2016-18 and previous years.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 21], [22, 33], [34, 44], [45, 47], [48, 49], [50, 54], [54, 55], [55, 59], [60, 64], [65, 74], [74, 75], [76, 78], [79, 83], [83, 84], [85, 87], [88, 94], [95, 97], [98, 102], [103, 107], [108, 117], [118, 121], [122, 131], [132, 142], [143, 144], [144, 147], [148, 153], [153, 154], [154, 155], [156, 160], [161, 174], [175, 187], [188, 195], [196, 201], [202, 204], [205, 209], [209, 210], [210, 212], [212, 213], [214, 217], [218, 223], [224, 230], [231, 233], [234, 238], [238, 239], [239, 241], [241, 242], [243, 247], [247, 248], [248, 250], [251, 254], [255, 263], [264, 269], [269, 270]]}
{"doc_key": "ai-dev-101", "ner": [[3, 4, "field"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 4, "part-of", "", false, false], [11, 12, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "general", ",", "computational", "linguistics", "involves", "linguists", ",", "computer", "scientists", ",", "artificial", "intelligence", "experts", ",", "mathematicians", ",", "logicians", ",", "philosophers", ",", "cognitive", "scientists", ",", "cognitive", "psychologists", ",", "psycholinguists", ",", "anthropologists", "and", "neuroscientists", ",", "among", "others", "."], "sentence-detokenized": "In general, computational linguistics involves linguists, computer scientists, artificial intelligence experts, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists and neuroscientists, among others.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 25], [26, 37], [38, 46], [47, 56], [56, 57], [58, 66], [67, 77], [77, 78], [79, 89], [90, 102], [103, 110], [110, 111], [112, 126], [126, 127], [128, 137], [137, 138], [139, 151], [151, 152], [153, 162], [163, 173], [173, 174], [175, 184], [185, 198], [198, 199], [200, 215], [215, 216], [217, 232], [233, 236], [237, 252], [252, 253], [254, 259], [260, 266], [266, 267]]}
{"doc_key": "ai-dev-102", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "-", "term", "memory", "are", "often", "used", "to", "exploit", "correlations", "between", "images", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long-term memory are often used to exploit correlations between images.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [82, 83], [83, 87], [88, 94], [95, 98], [99, 104], [105, 109], [110, 112], [113, 120], [121, 133], [134, 141], [142, 148], [148, 149]]}
{"doc_key": "ai-dev-103", "ner": [[0, 0, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "was", "the", "first", "industrial", "robot", ","], "sentence-detokenized": "Unimate was the first industrial robot,", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 21], [22, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-dev-104", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 11, 13, "win-defeat", "", false, false], [5, 6, 11, 13, "win-defeat", "", false, false], [8, 8, 11, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "won", "the", "2018", "Turing", "Award", "."], "sentence-detokenized": "Along with Geoffrey Hinton and Yann LeCun, Bengio won the 2018 Turing Award.", "token2charspan": [[0, 5], [6, 10], [11, 19], [20, 26], [27, 30], [31, 35], [36, 41], [41, 42], [43, 49], [50, 53], [54, 57], [58, 62], [63, 69], [70, 75], [75, 76]]}
{"doc_key": "ai-dev-105", "ner": [[6, 6, "country"], [20, 23, "misc"], [28, 28, "organisation"], [32, 33, "person"], [35, 36, "person"], [47, 49, "misc"], [54, 54, "country"], [60, 60, "country"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[20, 23, 6, 6, "physical", "filmed_in", false, false], [32, 33, 28, 28, "role", "host", false, false], [35, 36, 28, 28, "role", "reporter", false, false], [47, 49, 6, 6, "physical", "filmed_in", false, false], [47, 49, 54, 54, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "series", "were", "shot", "at", "the", "UK", "site", "for", "specific", "sectors", "of", "the", "global", "market", ",", "including", "two", "series", "of", "Robot", "Wars", "Extreme", "Warriors", "with", "US", "contestants", "for", "TNN", "(", "hosted", "by", "Mick", "Foley", "with", "Rebecca", "Grant", "as", "stand", "-", "in", "reporter", ")", ",", "two", "series", "of", "Dutch", "Robot", "Wars", "for", "distribution", "in", "the", "Netherlands", "and", "a", "single", "series", "for", "Germany", "."], "sentence-detokenized": "Other series were shot at the UK site for specific sectors of the global market, including two series of Robot Wars Extreme Warriors with US contestants for TNN (hosted by Mick Foley with Rebecca Grant as stand-in reporter), two series of Dutch Robot Wars for distribution in the Netherlands and a single series for Germany.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 22], [23, 25], [26, 29], [30, 32], [33, 37], [38, 41], [42, 50], [51, 58], [59, 61], [62, 65], [66, 72], [73, 79], [79, 80], [81, 90], [91, 94], [95, 101], [102, 104], [105, 110], [111, 115], [116, 123], [124, 132], [133, 137], [138, 140], [141, 152], [153, 156], [157, 160], [161, 162], [162, 168], [169, 171], [172, 176], [177, 182], [183, 187], [188, 195], [196, 201], [202, 204], [205, 210], [210, 211], [211, 213], [214, 222], [222, 223], [223, 224], [225, 228], [229, 235], [236, 238], [239, 244], [245, 250], [251, 255], [256, 259], [260, 272], [273, 275], [276, 279], [280, 291], [292, 295], [296, 297], [298, 304], [305, 311], [312, 315], [316, 323], [323, 324]]}
{"doc_key": "ai-dev-106", "ner": [[6, 6, "researcher"], [11, 11, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 11, 11, "role", "", false, false], [26, 27, 11, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "many", "years", "from", "1986", ",", "Miller", "led", "the", "development", "of", "WordNet", ",", "a", "large", "computer", "-", "readable", "electronic", "reference", "for", "use", "in", "applications", "such", "as", "search", "engines", "."], "sentence-detokenized": "For many years from 1986, Miller led the development of WordNet, a large computer-readable electronic reference for use in applications such as search engines.", "token2charspan": [[0, 3], [4, 8], [9, 14], [15, 19], [20, 24], [24, 25], [26, 32], [33, 36], [37, 40], [41, 52], [53, 55], [56, 63], [63, 64], [65, 66], [67, 72], [73, 81], [81, 82], [82, 90], [91, 101], [102, 111], [112, 115], [116, 119], [120, 122], [123, 135], [136, 140], [141, 143], [144, 150], [151, 158], [158, 159]]}
{"doc_key": "ai-dev-107", "ner": [[4, 5, "algorithm"], [8, 11, "algorithm"], [14, 15, "researcher"], [21, 24, "organisation"], [28, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 14, 15, "origin", "", false, false], [4, 5, 28, 30, "win-defeat", "", false, false], [8, 11, 14, 15, "origin", "", false, false], [8, 11, 28, 30, "win-defeat", "", false, false], [14, 15, 21, 24, "physical", "", false, false], [14, 15, 21, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Since", "2009", ",", "the", "recurrent", "neural", "networks", "and", "deep", "feedforward", "neural", "networks", "developed", "in", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "Swiss", "AI", "Lab", "IDSIA", "have", "won", "several", "international", "writing", "competitions", "."], "sentence-detokenized": "Since 2009, the recurrent neural networks and deep feedforward neural networks developed in J\u00fcrgen Schmidhuber's research group at the Swiss AI Lab IDSIA have won several international writing competitions.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 15], [16, 25], [26, 32], [33, 41], [42, 45], [46, 50], [51, 62], [63, 69], [70, 78], [79, 88], [89, 91], [92, 98], [99, 110], [110, 112], [113, 121], [122, 127], [128, 130], [131, 134], [135, 140], [141, 143], [144, 147], [148, 153], [154, 158], [159, 162], [163, 170], [171, 184], [185, 192], [193, 205], [205, 206]]}
{"doc_key": "ai-dev-108", "ner": [[5, 6, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "is", "implemented", "in", "C", "++", "and", "is", "wrapped", "for", "Python", "."], "sentence-detokenized": "The software is implemented in C++ and is wrapped for Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 30], [31, 32], [32, 34], [35, 38], [39, 41], [42, 49], [50, 53], [54, 60], [60, 61]]}
{"doc_key": "ai-dev-109", "ner": [[8, 9, "country"], [14, 15, "misc"], [20, 21, "misc"], [33, 34, "misc"], [36, 36, "misc"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 8, 9, "temporal", "", false, false], [20, 21, 14, 15, "artifact", "", false, false], [20, 21, 38, 38, "physical", "", false, false], [36, 36, 33, 34, "named", "", false, false], [36, 36, 38, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1857", ",", "at", "the", "request", "of", "the", "Tokugawa", "Shogunate", ",", "a", "group", "of", "Dutch", "engineers", "began", "work", "on", "the", "Nagasaki", "Yotetsusho", ",", "a", "modern", "Western", "-", "style", "shipyard", "and", "foundry", "near", "the", "Dutch", "settlement", "of", "Dejima", ",", "Nagasaki", "."], "sentence-detokenized": "In 1857, at the request of the Tokugawa Shogunate, a group of Dutch engineers began work on the Nagasaki Yotetsusho, a modern Western-style shipyard and foundry near the Dutch settlement of Dejima, Nagasaki.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 39], [40, 49], [49, 50], [51, 52], [53, 58], [59, 61], [62, 67], [68, 77], [78, 83], [84, 88], [89, 91], [92, 95], [96, 104], [105, 115], [115, 116], [117, 118], [119, 125], [126, 133], [133, 134], [134, 139], [140, 148], [149, 152], [153, 160], [161, 165], [166, 169], [170, 175], [176, 186], [187, 189], [190, 196], [196, 197], [198, 206], [206, 207]]}
{"doc_key": "ai-dev-110", "ner": [[9, 11, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["We", "do", "the", "best", "we", "can", "by", "measuring", "the", "mean", "square", "error", "between", "mathy", "/", "math", "and", "math", "hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "we", "want", "math", "(", "y", "-", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", "^", "2", "/", "math", "to", "be", "minimal", ",", "both", "for", "mathx", "_", "1.5", "points", ",", "x", "_n", "/", "math", "and", "for", "points", "outside", "our", "sample", "."], "sentence-detokenized": "We do the best we can by measuring the mean square error between mathy / math and math hat {f} (x; D) / math: we want math (y - hat {f} (x; D)) ^ 2 / math to be minimal, both for mathx _ 1.5 points, x _n / math and for points outside our sample.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 14], [15, 17], [18, 21], [22, 24], [25, 34], [35, 38], [39, 43], [44, 50], [51, 56], [57, 64], [65, 70], [71, 72], [73, 77], [78, 81], [82, 86], [87, 90], [91, 92], [92, 93], [93, 94], [95, 96], [96, 97], [97, 98], [99, 100], [100, 101], [102, 103], [104, 108], [108, 109], [110, 112], [113, 117], [118, 122], [123, 124], [124, 125], [126, 127], [128, 131], [132, 133], [133, 134], [134, 135], [136, 137], [137, 138], [138, 139], [140, 141], [141, 142], [142, 143], [144, 145], [146, 147], [148, 149], [150, 154], [155, 157], [158, 160], [161, 168], [168, 169], [170, 174], [175, 178], [179, 184], [185, 186], [187, 190], [191, 197], [197, 198], [199, 200], [201, 203], [204, 205], [206, 210], [211, 214], [215, 218], [219, 225], [226, 233], [234, 237], [238, 244], [244, 245]]}
{"doc_key": "ai-dev-111", "ner": [[3, 5, "researcher"], [12, 14, "organisation"], [21, 25, "product"], [34, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 12, 14, "role", "", false, false], [21, 25, 12, 14, "temporal", "", false, false], [21, 25, 34, 35, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "then", "invited", "Mr", "Wydner", "to", "attend", "the", "annual", "meeting", "of", "the", "American", "Translators", "Association", "the", "following", "October", ",", "where", "the", "Weidner", "machine", "translation", "system", "was", "hailed", "as", "a", "hoped", "-", "for", "breakthrough", "in", "machine", "translation", "."], "sentence-detokenized": "He then invited Mr Wydner to attend the annual meeting of the American Translators Association the following October, where the Weidner machine translation system was hailed as a hoped-for breakthrough in machine translation.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 18], [19, 25], [26, 28], [29, 35], [36, 39], [40, 46], [47, 54], [55, 57], [58, 61], [62, 70], [71, 82], [83, 94], [95, 98], [99, 108], [109, 116], [116, 117], [118, 123], [124, 127], [128, 135], [136, 143], [144, 155], [156, 162], [163, 166], [167, 173], [174, 176], [177, 178], [179, 184], [184, 185], [185, 188], [189, 201], [202, 204], [205, 212], [213, 224], [224, 225]]}
{"doc_key": "ai-dev-112", "ner": [[2, 10, "conference"], [8, 8, "conference"], [12, 12, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 2, 10, "named", "", false, false], [8, 8, 2, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["At", "the", "2018", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "conference", ",", "Google", "researchers", "presented", "this", "work", "."], "sentence-detokenized": "At the 2018 Neural Information Processing Systems (NeurIPS) conference, Google researchers presented this work.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 30], [31, 41], [42, 49], [50, 51], [51, 58], [58, 59], [60, 70], [70, 71], [72, 78], [79, 90], [91, 100], [101, 105], [106, 110], [110, 111]]}
{"doc_key": "ai-dev-113", "ner": [[1, 4, "algorithm"], [10, 11, "algorithm"], [15, 18, "metrics"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 4, 10, 11, "usage", "", false, false], [10, 11, 15, 18, "related-to", "", true, false], [15, 18, 23, 25, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Baum", "-", "Welch", "algorithm", "uses", "the", "well", "-", "known", "EM", "algorithm", "to", "find", "the", "maximum", "likelihood", "estimate", "of", "the", "parameters", "of", "a", "hidden", "Markov", "model", ",", "given", "a", "set", "of", "observed", "feature", "vectors", "."], "sentence-detokenized": "The Baum-Welch algorithm uses the well-known EM algorithm to find the maximum likelihood estimate of the parameters of a hidden Markov model, given a set of observed feature vectors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [15, 24], [25, 29], [30, 33], [34, 38], [38, 39], [39, 44], [45, 47], [48, 57], [58, 60], [61, 65], [66, 69], [70, 77], [78, 88], [89, 97], [98, 100], [101, 104], [105, 115], [116, 118], [119, 120], [121, 127], [128, 134], [135, 140], [140, 141], [142, 147], [148, 149], [150, 153], [154, 156], [157, 165], [166, 173], [174, 181], [181, 182]]}
{"doc_key": "ai-dev-114", "ner": [[9, 9, "product"], [11, 11, "product"], [31, 32, "misc"], [38, 46, "product"], [49, 51, "programlang"], [52, 57, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 9, 11, 11, "compare", "", false, false], [31, 32, 11, 11, "part-of", "", false, false], [38, 46, 11, 11, "part-of", "", false, false], [52, 57, 11, 11, "part-of", "", false, false], [52, 57, 49, 51, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": [")", "In", "addition", "to", "the", "taxonomic", "information", "contained", "in", "OpenCyc", ",", "ResearchCyc", "includes", "much", "more", "semantic", "knowledge", "(", "i.e.", "additional", "facts", "and", "rules", "of", "thumb", ")", "involving", "the", "concepts", "in", "its", "knowledge", "base", ";", "it", "also", "includes", "a", "large", "lexicon", ",", "analysis", "and", "generation", "tools", "in", "English", ",", "and", "Java", "-", "based", "interfaces", "for", "editing", "and", "querying", "knowledge", "."], "sentence-detokenized": ") In addition to the taxonomic information contained in OpenCyc, ResearchCyc includes much more semantic knowledge (i.e. additional facts and rules of thumb) involving the concepts in its knowledge base; it also includes a large lexicon, analysis and generation tools in English, and Java-based interfaces for editing and querying knowledge.", "token2charspan": [[0, 1], [2, 4], [5, 13], [14, 16], [17, 20], [21, 30], [31, 42], [43, 52], [53, 55], [56, 63], [63, 64], [65, 76], [77, 85], [86, 90], [91, 95], [96, 104], [105, 114], [115, 116], [116, 120], [121, 131], [132, 137], [138, 141], [142, 147], [148, 150], [151, 156], [156, 157], [158, 167], [168, 171], [172, 180], [181, 183], [184, 187], [188, 197], [198, 202], [202, 203], [204, 206], [207, 211], [212, 220], [221, 222], [223, 228], [229, 236], [236, 237], [238, 246], [247, 250], [251, 261], [262, 267], [268, 270], [271, 278], [278, 279], [280, 283], [284, 288], [288, 289], [289, 294], [295, 305], [306, 309], [310, 317], [318, 321], [322, 330], [331, 340], [340, 341]]}
{"doc_key": "ai-dev-115", "ner": [[0, 3, "algorithm"], [5, 6, "task"], [10, 11, "field"], [13, 14, "field"], [16, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 5, 6, "type-of", "", false, false], [5, 6, 10, 11, "part-of", "task_part_of_field", false, false], [5, 6, 13, 14, "part-of", "task_part_of_field", false, false], [5, 6, 16, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Hough", "transform", "is", "a", "feature", "extraction", "technique", "used", "in", "image", "analysis", ",", "computer", "vision", "and", "digital", "image", "processing", "."], "sentence-detokenized": "The Hough transform is a feature extraction technique used in image analysis, computer vision and digital image processing.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 22], [23, 24], [25, 32], [33, 43], [44, 53], [54, 58], [59, 61], [62, 67], [68, 76], [76, 77], [78, 86], [87, 93], [94, 97], [98, 105], [106, 111], [112, 122], [122, 123]]}
{"doc_key": "ai-dev-116", "ner": [[4, 4, "product"], [6, 10, "product"], [16, 16, "organisation"], [18, 18, "product"], [20, 21, "researcher"], [28, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 6, 10, "named", "", false, false], [4, 4, 16, 16, "artifact", "", false, false], [4, 4, 18, 18, "origin", "developed_from", false, false], [18, 18, 20, 21, "artifact", "", false, false], [28, 29, 16, 16, "role", "supported", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1978", ",", "the", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "robot", "was", "developed", "by", "Unimation", "from", "Vicarm", "(", "Victor", "Scheinman", ")", "and", "with", "the", "support", "of", "General", "Motors", "."], "sentence-detokenized": "In 1978, the PUMA (Programmable Universal Machine for Assembly) robot was developed by Unimation from Vicarm (Victor Scheinman) and with the support of General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 19], [19, 31], [32, 41], [42, 49], [50, 53], [54, 62], [62, 63], [64, 69], [70, 73], [74, 83], [84, 86], [87, 96], [97, 101], [102, 108], [109, 110], [110, 116], [117, 126], [126, 127], [128, 131], [132, 136], [137, 140], [141, 148], [149, 151], [152, 159], [160, 166], [166, 167]]}
{"doc_key": "ai-dev-117", "ner": [[1, 1, "algorithm"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 7, 8, "origin", "", false, false], [1, 1, 10, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "LSTM", "was", "proposed", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "The LSTM was proposed in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 21], [22, 24], [25, 29], [30, 32], [33, 37], [38, 48], [49, 52], [53, 59], [60, 71], [71, 72]]}
{"doc_key": "ai-dev-118", "ner": [[11, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "outcomes", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four outcomes can be formulated in a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 24], [25, 35], [36, 38], [39, 40], [41, 42], [43, 44], [45, 46], [47, 58], [59, 64], [65, 67], [68, 77], [78, 84], [85, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-dev-119", "ner": [[8, 8, "conference"], [11, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "also", "instrumental", "in", "the", "creation", "of", "ELRA", "and", "the", "LREC", "conference", "."], "sentence-detokenized": "He was also instrumental in the creation of ELRA and the LREC conference.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 27], [28, 31], [32, 40], [41, 43], [44, 48], [49, 52], [53, 56], [57, 61], [62, 72], [72, 73]]}
{"doc_key": "ai-dev-120", "ner": [[16, 17, "misc"], [21, 22, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 22, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "popular", "application", "of", "serial", "robots", "in", "industry", "today", "is", "the", "pick", "-", "and", "-", "place", "assembly", "robot", ",", "called", "a", "SCARA", "robot", ",", "which", "has", "four", "degrees", "of", "freedom", "."], "sentence-detokenized": "A popular application of serial robots in industry today is the pick-and-place assembly robot, called a SCARA robot, which has four degrees of freedom.", "token2charspan": [[0, 1], [2, 9], [10, 21], [22, 24], [25, 31], [32, 38], [39, 41], [42, 50], [51, 56], [57, 59], [60, 63], [64, 68], [68, 69], [69, 72], [72, 73], [73, 78], [79, 87], [88, 93], [93, 94], [95, 101], [102, 103], [104, 109], [110, 115], [115, 116], [117, 122], [123, 126], [127, 131], [132, 139], [140, 142], [143, 150], [150, 151]]}
{"doc_key": "ai-dev-121", "ner": [[13, 19, "conference"], [21, 21, "conference"], [25, 28, "conference"], [34, 34, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 13, 19, "named", "", false, false], [34, 34, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "a", "founding", "member", "and", "former", "chair", "(", "2006-2008", ")", "of", "the", "Special", "Interest", "Group", "on", "Web", "as", "Corpus", "(", "SIGWAC", ")", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "a", "founding", "organiser", "of", "SENSEVAL", "."], "sentence-detokenized": "He was a founding member and former chair (2006-2008) of the Special Interest Group on Web as Corpus (SIGWAC) of the Association for Computational Linguistics and a founding organiser of SENSEVAL.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 17], [18, 24], [25, 28], [29, 35], [36, 41], [42, 43], [43, 52], [52, 53], [54, 56], [57, 60], [61, 68], [69, 77], [78, 83], [84, 86], [87, 90], [91, 93], [94, 100], [101, 102], [102, 108], [108, 109], [110, 112], [113, 116], [117, 128], [129, 132], [133, 146], [147, 158], [159, 162], [163, 164], [165, 173], [174, 183], [184, 186], [187, 195], [195, 196]]}
{"doc_key": "ai-dev-122", "ner": [[4, 4, "product"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 4, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "platform", ",", "LinguaStream", "provides", "an", "extended", "Java", "API", "."], "sentence-detokenized": "As a platform, LinguaStream provides an extended Java API.", "token2charspan": [[0, 2], [3, 4], [5, 13], [13, 14], [15, 27], [28, 36], [37, 39], [40, 48], [49, 53], [54, 57], [57, 58]]}
{"doc_key": "ai-dev-123", "ner": [[12, 12, "programlang"], [15, 17, "misc"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 21, 23, "type-of", "", false, false], [15, 17, 21, 23, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "robot", "kit", "is", "based", "on", "Android", ",", "and", "is", "programmed", "using", "Java", ",", "the", "Blocks", "programming", "interface", ",", "or", "other", "Android", "programming", "systems", "."], "sentence-detokenized": "The robot kit is based on Android, and is programmed using Java, the Blocks programming interface, or other Android programming systems.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 16], [17, 22], [23, 25], [26, 33], [33, 34], [35, 38], [39, 41], [42, 52], [53, 58], [59, 63], [63, 64], [65, 68], [69, 75], [76, 87], [88, 97], [97, 98], [99, 101], [102, 107], [108, 115], [116, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-dev-124", "ner": [[12, 13, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "method", "of", "defining", "the", "linked", "list", "specifies", "whether", "to", "use", "a", "depth", "search", "or", "a", "width", "search", "."], "sentence-detokenized": "The method of defining the linked list specifies whether to use a depth search or a width search.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 22], [23, 26], [27, 33], [34, 38], [39, 48], [49, 56], [57, 59], [60, 63], [64, 65], [66, 71], [72, 78], [79, 81], [82, 83], [84, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-dev-125", "ner": [[20, 21, "task"], [25, 28, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "regions", "could", "signal", "the", "presence", "of", "objects", "or", "parts", "of", "objects", "in", "the", "image", "domain", ",", "with", "application", "to", "object", "recognition", "and", "/", "or", "video", "tracking", "of", "objects", "."], "sentence-detokenized": "These regions could signal the presence of objects or parts of objects in the image domain, with application to object recognition and/or video tracking of objects.", "token2charspan": [[0, 5], [6, 13], [14, 19], [20, 26], [27, 30], [31, 39], [40, 42], [43, 50], [51, 53], [54, 59], [60, 62], [63, 70], [71, 73], [74, 77], [78, 83], [84, 90], [90, 91], [92, 96], [97, 108], [109, 111], [112, 118], [119, 130], [131, 134], [134, 135], [135, 137], [138, 143], [144, 152], [153, 155], [156, 163], [163, 164]]}
{"doc_key": "ai-dev-126", "ner": [[4, 5, "algorithm"], [7, 7, "product"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 4, 5, "type-of", "", false, false], [7, 7, 13, 13, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "semantic", "network", "is", "WordNet", ",", "a", "lexical", "database", "of", "English", "."], "sentence-detokenized": "An example of a semantic network is WordNet, a lexical database of English.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 32], [33, 35], [36, 43], [43, 44], [45, 46], [47, 54], [55, 63], [64, 66], [67, 74], [74, 75]]}
{"doc_key": "ai-dev-127", "ner": [[0, 3, "task"], [7, 8, "field"], [10, 11, "field"], [19, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 7, 8, "part-of", "", false, false], [0, 3, 10, 11, "named", "same", false, false], [0, 3, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Speech", "recognition", "is", "an", "interdisciplinary", "sub-field", "of", "computer", "science", "and", "computational", "linguistics", "that", "develops", "methodologies", "and", "technologies", "for", "the", "recognition", "and", "translation", "of", "spoken", "language", "into", "text", "by", "computers", "."], "sentence-detokenized": "Speech recognition is an interdisciplinary sub-field of computer science and computational linguistics that develops methodologies and technologies for the recognition and translation of spoken language into text by computers.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 24], [25, 42], [43, 52], [53, 55], [56, 64], [65, 72], [73, 76], [77, 90], [91, 102], [103, 107], [108, 116], [117, 130], [131, 134], [135, 147], [148, 151], [152, 155], [156, 167], [168, 171], [172, 183], [184, 186], [187, 193], [194, 202], [203, 207], [208, 212], [213, 215], [216, 225], [225, 226]]}
{"doc_key": "ai-dev-128", "ner": [[0, 1, "field"], [8, 9, "misc"], [14, 16, "field"], [19, 19, "task"], [21, 22, "task"], [44, 44, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 44, 44, "named", "same", false, false], [14, 16, 0, 1, "part-of", "subfield", false, false], [19, 19, 0, 1, "part-of", "", false, false], [19, 19, 14, 16, "part-of", "", false, false], [21, 22, 14, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Artificial", "intelligence", "has", "received", "the", "most", "attention", "for", "ontology", "applied", "in", "subfields", "such", "as", "natural", "language", "processing", "in", "the", "machine", "and", "knowledge", "representation", ",", "but", "ontology", "editors", "are", "often", "used", "in", "a", "range", "of", "fields", "such", "as", "education", "without", "the", "intention", "of", "contributing", "to", "AI", "."], "sentence-detokenized": "Artificial intelligence has received the most attention for ontology applied in subfields such as natural language processing in the machine and knowledge representation, but ontology editors are often used in a range of fields such as education without the intention of contributing to AI.", "token2charspan": [[0, 10], [11, 23], [24, 27], [28, 36], [37, 40], [41, 45], [46, 55], [56, 59], [60, 68], [69, 76], [77, 79], [80, 89], [90, 94], [95, 97], [98, 105], [106, 114], [115, 125], [126, 128], [129, 132], [133, 140], [141, 144], [145, 154], [155, 169], [169, 170], [171, 174], [175, 183], [184, 191], [192, 195], [196, 201], [202, 206], [207, 209], [210, 211], [212, 217], [218, 220], [221, 227], [228, 232], [233, 235], [236, 245], [246, 253], [254, 257], [258, 267], [268, 270], [271, 283], [284, 286], [287, 289], [289, 290]]}
{"doc_key": "ai-dev-129", "ner": [[7, 9, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 12, 13, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "update", "rule", "is", "in", "fact", "the", "stochastic", "gradient", "descent", "update", "for", "linear", "regression", "."], "sentence-detokenized": "This update rule is in fact the stochastic gradient descent update for linear regression.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 22], [23, 27], [28, 31], [32, 42], [43, 51], [52, 59], [60, 66], [67, 70], [71, 77], [78, 88], [88, 89]]}
{"doc_key": "ai-dev-130", "ner": [[5, 10, "organisation"], [13, 16, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "elected", "to", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "the", "National", "Academy", "of", "Sciences", "and", "received", "a", "series", "of", "awards", ":"], "sentence-detokenized": "He was elected to the American Academy of Arts and Sciences and the National Academy of Sciences and received a series of awards:", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 46], [47, 50], [51, 59], [60, 63], [64, 67], [68, 76], [77, 84], [85, 87], [88, 96], [97, 100], [101, 109], [110, 111], [112, 118], [119, 121], [122, 128], [128, 129]]}
{"doc_key": "ai-dev-131", "ner": [[7, 7, "organisation"], [14, 15, "person"], [17, 20, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 14, 15, "related-to", "written_about_by", false, false], [7, 7, 17, 20, "related-to", "written_about_by", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "recent", "school", "of", "thought", "on", "Honda", "'s", "strategy", "has", "been", "proposed", "by", "Gary", "Hamel", "and", "C.", "K", ".", "Prahalad", "in", "1989", "."], "sentence-detokenized": "The most recent school of thought on Honda's strategy has been proposed by Gary Hamel and C. K. Prahalad in 1989.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 22], [23, 25], [26, 33], [34, 36], [37, 42], [42, 44], [45, 53], [54, 57], [58, 62], [63, 71], [72, 74], [75, 79], [80, 85], [86, 89], [90, 92], [93, 94], [94, 95], [96, 104], [105, 107], [108, 112], [112, 113]]}
{"doc_key": "ai-dev-132", "ner": [[1, 1, "metrics"], [5, 6, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 5, 6, "related-to", "calculates", true, false], [1, 1, 17, 17, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "BLEU", "simply", "calculates", "the", "accuracy", "of", "a", "gram", "by", "adding", "an", "equal", "weight", "to", "each", ",", "NIST", "also", "calculates", "the", "degree", "of", "information", "of", "a", "particular", "gram", "."], "sentence-detokenized": "While BLEU simply calculates the accuracy of a gram by adding an equal weight to each, NIST also calculates the degree of information of a particular gram.", "token2charspan": [[0, 5], [6, 10], [11, 17], [18, 28], [29, 32], [33, 41], [42, 44], [45, 46], [47, 51], [52, 54], [55, 61], [62, 64], [65, 70], [71, 77], [78, 80], [81, 85], [85, 86], [87, 91], [92, 96], [97, 107], [108, 111], [112, 118], [119, 121], [122, 133], [134, 136], [137, 138], [139, 149], [150, 154], [154, 155]]}
{"doc_key": "ai-dev-133", "ner": [[5, 15, "misc"], [6, 9, "conference"], [11, 11, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 15, 6, 9, "temporal", "", false, false], [11, 11, 6, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "honoured", "with", "the", "2019", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "Lifetime", "Achievement", "Award", "."], "sentence-detokenized": "He was honoured with the 2019 Association for Computational Linguistics (ACL) Lifetime Achievement Award.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 20], [21, 24], [25, 29], [30, 41], [42, 45], [46, 59], [60, 71], [72, 73], [73, 76], [76, 77], [78, 86], [87, 98], [99, 104], [104, 105]]}
{"doc_key": "ai-dev-134", "ner": [[0, 2, "researcher"], [6, 11, "organisation"], [13, 13, "organisation"], [17, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 6, 11, "role", "", false, false], [0, 2, 17, 21, "role", "", false, false], [13, 13, 6, 11, "named", "", false, false], [23, 23, 17, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "is", "a", "member", "of", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "and", "the", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara is a member of the Institute of Electrical and Electronics Engineers (IEEE) and the American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 18], [19, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 65], [66, 75], [76, 77], [77, 81], [81, 82], [83, 86], [87, 90], [91, 99], [100, 111], [112, 115], [116, 126], [127, 139], [140, 141], [141, 145], [145, 146], [146, 147]]}
{"doc_key": "ai-dev-135", "ner": [[2, 2, "product"], [10, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 10, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "following", "MATLAB", "code", "demonstrates", "a", "concrete", "solution", "to", "the", "system", "of", "nonlinear", "equations", "presented", "in", "the", "previous", "section", ":", "See", "also"], "sentence-detokenized": "The following MATLAB code demonstrates a concrete solution to the system of nonlinear equations presented in the previous section: See also", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 38], [39, 40], [41, 49], [50, 58], [59, 61], [62, 65], [66, 72], [73, 75], [76, 85], [86, 95], [96, 105], [106, 108], [109, 112], [113, 121], [122, 129], [129, 130], [131, 134], [135, 139]]}
{"doc_key": "ai-dev-136", "ner": [[4, 6, "product"], [14, 15, "field"], [37, 38, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 14, 15, "related-to", "trained_by", true, false], [4, 6, 37, 38, "related-to", "trained_by", true, false], [14, 15, 37, 38, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "many", "cases", ",", "pattern", "recognition", "systems", "are", "trained", "on", "labelled", "training", "data", "(", "supervised", "learning", ")", ",", "but", "where", "no", "labelled", "data", "is", "available", ",", "other", "algorithms", "can", "be", "used", "to", "discover", "previously", "unknown", "patterns", "(", "unsupervised", "learning", ")", "."], "sentence-detokenized": "In many cases, pattern recognition systems are trained on labelled training data (supervised learning), but where no labelled data is available, other algorithms can be used to discover previously unknown patterns (unsupervised learning).", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 22], [23, 34], [35, 42], [43, 46], [47, 54], [55, 57], [58, 66], [67, 75], [76, 80], [81, 82], [82, 92], [93, 101], [101, 102], [102, 103], [104, 107], [108, 113], [114, 116], [117, 125], [126, 130], [131, 133], [134, 143], [143, 144], [145, 150], [151, 161], [162, 165], [166, 168], [169, 173], [174, 176], [177, 185], [186, 196], [197, 204], [205, 213], [214, 215], [215, 227], [228, 236], [236, 237], [237, 238]]}
{"doc_key": "ai-dev-137", "ner": [[5, 7, "researcher"], [10, 10, "country"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 10, 10, "physical", "", false, false], [5, 7, 23, 24, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "was", "first", "used", "by", "Lawrence", "J.", "Fogel", "in", "the", "US", "in", "1960", "to", "use", "simulated", "evolution", "as", "a", "learning", "process", "to", "generate", "artificial", "intelligence", "."], "sentence-detokenized": "It was first used by Lawrence J. Fogel in the US in 1960 to use simulated evolution as a learning process to generate artificial intelligence.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 17], [18, 20], [21, 29], [30, 32], [33, 38], [39, 41], [42, 45], [46, 48], [49, 51], [52, 56], [57, 59], [60, 63], [64, 73], [74, 83], [84, 86], [87, 88], [89, 97], [98, 105], [106, 108], [109, 117], [118, 128], [129, 141], [141, 142]]}
{"doc_key": "ai-dev-138", "ner": [[0, 2, "field"], [10, 11, "field"], [15, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 10, 11, "part-of", "", false, false], [15, 15, 10, 11, "part-of", "", false, false], [17, 18, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Reinforcement", "learning", "is", "one", "of", "the", "three", "basic", "paradigms", "of", "machine", "learning", ",", "along", "with", "supervised", "and", "unsupervised", "learning", "."], "sentence-detokenized": "Reinforcement learning is one of the three basic paradigms of machine learning, along with supervised and unsupervised learning.", "token2charspan": [[0, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 42], [43, 48], [49, 58], [59, 61], [62, 69], [70, 78], [78, 79], [80, 85], [86, 90], [91, 101], [102, 105], [106, 118], [119, 127], [127, 128]]}
{"doc_key": "ai-dev-139", "ner": [[4, 5, "field"], [12, 12, "programlang"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 28, 29, "usage", "applies", false, false], [12, 12, 28, 29, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "case", ",", "cloud", "computing", "and", "the", "open", "source", "programming", "language", "R", "can", "help", "small", "banks", "adopt", "risk", "analysis", "and", "support", "branch", "-", "level", "supervision", "by", "applying", "predictive", "analytics", "."], "sentence-detokenized": "In this case, cloud computing and the open source programming language R can help small banks adopt risk analysis and support branch-level supervision by applying predictive analytics.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 19], [20, 29], [30, 33], [34, 37], [38, 42], [43, 49], [50, 61], [62, 70], [71, 72], [73, 76], [77, 81], [82, 87], [88, 93], [94, 99], [100, 104], [105, 113], [114, 117], [118, 125], [126, 132], [132, 133], [133, 138], [139, 150], [151, 153], [154, 162], [163, 173], [174, 183], [183, 184]]}
{"doc_key": "ai-dev-140", "ner": [[11, 12, "researcher"], [20, 22, "algorithm"], [24, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 24, 25, "named", "same", false, false], [20, 22, 11, 12, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["One", "of", "the", "first", "versions", "of", "the", "theorem", "was", "proved", "by", "George", "Cybenko", "in", "1989", "for", "the", "activation", "functions", "of", "the", "sigmoid", "function", ".", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "One of the first versions of the theorem was proved by George Cybenko in 1989 for the activation functions of the sigmoid function. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 25], [26, 28], [29, 32], [33, 40], [41, 44], [45, 51], [52, 54], [55, 61], [62, 69], [70, 72], [73, 77], [78, 81], [82, 85], [86, 96], [97, 106], [107, 109], [110, 113], [114, 121], [122, 130], [130, 131], [132, 139], [140, 142], [143, 144], [144, 148], [148, 149], [149, 150], [151, 152], [153, 154], [154, 155], [155, 156], [156, 157], [158, 165], [165, 166]]}
{"doc_key": "ai-dev-141", "ner": [[6, 6, "algorithm"], [9, 10, "metrics"], [16, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 6, 6, "part-of", "", false, false], [16, 21, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "process", ",", "known", "as", "cross-validation", ",", "the", "MSE", "is", "often", "referred", "to", "as", "the", "root", "mean", "square", "error", "of", "prediction", ",", "and", "is", "calculated", "as", "follows"], "sentence-detokenized": "In this process, known as cross-validation, the MSE is often referred to as the root mean square error of prediction, and is calculated as follows", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 22], [23, 25], [26, 42], [42, 43], [44, 47], [48, 51], [52, 54], [55, 60], [61, 69], [70, 72], [73, 75], [76, 79], [80, 84], [85, 89], [90, 96], [97, 102], [103, 105], [106, 116], [116, 117], [118, 121], [122, 124], [125, 135], [136, 138], [139, 146]]}
{"doc_key": "ai-dev-142", "ner": [[0, 0, "task"], [5, 7, "task"], [9, 9, "task"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 7, "compare", "", false, false], [5, 7, 21, 22, "part-of", "", false, false], [9, 9, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OMR", "is", "generally", "distinguished", "from", "optical", "character", "recognition", "(", "OCR", ")", "by", "the", "fact", "that", "it", "does", "not", "require", "a", "complex", "pattern", "recognition", "engine", "."], "sentence-detokenized": "OMR is generally distinguished from optical character recognition (OCR) by the fact that it does not require a complex pattern recognition engine.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 30], [31, 35], [36, 43], [44, 53], [54, 65], [66, 67], [67, 70], [70, 71], [72, 74], [75, 78], [79, 83], [84, 88], [89, 91], [92, 96], [97, 100], [101, 108], [109, 110], [111, 118], [119, 126], [127, 138], [139, 145], [145, 146]]}
{"doc_key": "ai-dev-143", "ner": [[10, 10, "location"], [12, 12, "location"], [14, 14, "location"], [18, 19, "location"], [21, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 14, 14, "physical", "", false, false], [18, 19, 12, 12, "physical", "", false, false], [21, 22, 12, 12, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2018", "and", "2019", ",", "the", "championship", "was", "held", "in", "Houston", "and", "Detroit", ",", "Michigan", ",", "at", "the", "TCF", "Center", "and", "Ford", "Field", "."], "sentence-detokenized": "In 2018 and 2019, the championship was held in Houston and Detroit, Michigan, at the TCF Center and Ford Field.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 16], [16, 17], [18, 21], [22, 34], [35, 38], [39, 43], [44, 46], [47, 54], [55, 58], [59, 66], [66, 67], [68, 76], [76, 77], [78, 80], [81, 84], [85, 88], [89, 95], [96, 99], [100, 104], [105, 110], [110, 111]]}
{"doc_key": "ai-dev-144", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "seen", "as", "two", "distinct", "problems", ":", "binary", "classification", "and", "multi-class", "classification", "."], "sentence-detokenized": "Classification can be seen as two distinct problems: binary classification and multi-class classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 26], [27, 29], [30, 33], [34, 42], [43, 51], [51, 52], [53, 59], [60, 74], [75, 78], [79, 90], [91, 105], [105, 106]]}
{"doc_key": "ai-dev-145", "ner": [[4, 5, "product"], [8, 9, "product"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "type-of", "", false, false], [12, 13, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "examples", "of", "popular", "parallel", "robots", "are", "the", "Stewart", "platform", "and", "the", "Delta", "robot", "."], "sentence-detokenized": "Two examples of popular parallel robots are the Stewart platform and the Delta robot.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 23], [24, 32], [33, 39], [40, 43], [44, 47], [48, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-146", "ner": [[4, 6, "algorithm"], [22, 22, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 22, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "Nevertheless", ",", "the", "ReLU", "activation", "function", ",", "which", "is", "indistinguishable", "from", "0", ",", "has", "become", "quite", "popular", ",", "for", "example", "in", "AlexNet", ".", ")"], "sentence-detokenized": "(Nevertheless, the ReLU activation function, which is indistinguishable from 0, has become quite popular, for example in AlexNet.)", "token2charspan": [[0, 1], [1, 13], [13, 14], [15, 18], [19, 23], [24, 34], [35, 43], [43, 44], [45, 50], [51, 53], [54, 71], [72, 76], [77, 78], [78, 79], [80, 83], [84, 90], [91, 96], [97, 104], [104, 105], [106, 109], [110, 117], [118, 120], [121, 128], [128, 129], [129, 130]]}
{"doc_key": "ai-dev-147", "ner": [[1, 4, "metrics"], [11, 12, "task"], [18, 18, "task"], [20, 21, "task"], [23, 24, "task"], [27, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 4, 27, 28, "named", "", true, false], [11, 12, 1, 4, "usage", "", true, false], [18, 18, 11, 12, "part-of", "", false, false], [20, 21, 11, 12, "part-of", "", false, false], [23, 24, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "F", "-", "score", "is", "often", "used", "in", "the", "field", "of", "information", "retrieval", "to", "measure", "the", "performance", "of", "search", ",", "document", "classification", "and", "query", "classification", ".", "The", "F_beta", "is", "therefore", "widely", "used", "."], "sentence-detokenized": "The F-score is often used in the field of information retrieval to measure the performance of search, document classification and query classification. The F_beta is therefore widely used.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 20], [21, 25], [26, 28], [29, 32], [33, 38], [39, 41], [42, 53], [54, 63], [64, 66], [67, 74], [75, 78], [79, 90], [91, 93], [94, 100], [100, 101], [102, 110], [111, 125], [126, 129], [130, 135], [136, 150], [150, 151], [152, 155], [156, 162], [163, 165], [166, 175], [176, 182], [183, 187], [187, 188]]}
{"doc_key": "ai-dev-148", "ner": [[17, 18, "algorithm"], [20, 20, "algorithm"], [23, 24, "algorithm"], [26, 26, "algorithm"], [29, 31, "algorithm"], [33, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 20, 17, 18, "named", "", false, false], [26, 26, 23, 24, "named", "", false, false], [33, 33, 29, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "is", "done", "by", "modelling", "the", "received", "signal", "and", "then", "using", "a", "statistical", "estimation", "method", "such", "as", "maximum", "likelihood", "(", "ML", ")", ",", "majority", "voting", "(", "MV", ")", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "to", "decide", "which", "target", "in", "the", "library", "best", "fits", "the", "model", "built", "using", "the", "received", "signal", "."], "sentence-detokenized": "This is done by modelling the received signal and then using a statistical estimation method such as maximum likelihood (ML), majority voting (MV) or maximum a posteriori (MAP) to decide which target in the library best fits the model built using the received signal.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 25], [26, 29], [30, 38], [39, 45], [46, 49], [50, 54], [55, 60], [61, 62], [63, 74], [75, 85], [86, 92], [93, 97], [98, 100], [101, 108], [109, 119], [120, 121], [121, 123], [123, 124], [124, 125], [126, 134], [135, 141], [142, 143], [143, 145], [145, 146], [147, 149], [150, 157], [158, 159], [160, 170], [171, 172], [172, 175], [175, 176], [177, 179], [180, 186], [187, 192], [193, 199], [200, 202], [203, 206], [207, 214], [215, 219], [220, 224], [225, 228], [229, 234], [235, 240], [241, 246], [247, 250], [251, 259], [260, 266], [266, 267]]}
{"doc_key": "ai-dev-149", "ner": [[0, 2, "researcher"], [5, 5, "misc"], [7, 7, "field"], [10, 13, "university"], [18, 18, "misc"], [20, 22, "field"], [23, 24, "university"], [30, 30, "misc"], [32, 33, "field"], [36, 38, "university"], [45, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 10, 13, "physical", "", false, false], [0, 2, 10, 13, "role", "", false, false], [0, 2, 23, 24, "physical", "", false, false], [0, 2, 23, 24, "role", "", false, false], [0, 2, 36, 38, "physical", "", false, false], [0, 2, 36, 38, "role", "", false, false], [5, 5, 0, 2, "origin", "", false, false], [5, 5, 7, 7, "topic", "", false, false], [18, 18, 0, 2, "origin", "", false, false], [18, 18, 20, 22, "topic", "", false, false], [30, 30, 0, 2, "origin", "", false, false], [30, 30, 32, 33, "topic", "", false, false], [45, 54, 30, 30, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Dr", ".", "Sowa", "received", "a", "BS", "in", "Mathematics", "from", "the", "Massachusetts", "Institute", "of", "Technology", "in", "1962", ",", "an", "MA", "in", "Applied", "Science", "from", "Harvard", "University", "in", "1966", ",", "and", "a", "PhD", "in", "Computer", "Science", "from", "the", "Vrije", "Universiteit", "Brussel", "in", "1999", "on", "a", "dissertation", "entitled", "Knowledge", "Representation", ":", "Logical", ",", "Philosophical", ",", "and", "Computational", "Foundations", "."], "sentence-detokenized": "Dr. Sowa received a BS in Mathematics from the Massachusetts Institute of Technology in 1962, an MA in Applied Science from Harvard University in 1966, and a PhD in Computer Science from the Vrije Universiteit Brussel in 1999 on a dissertation entitled Knowledge Representation: Logical, Philosophical, and Computational Foundations.", "token2charspan": [[0, 2], [2, 3], [4, 8], [9, 17], [18, 19], [20, 22], [23, 25], [26, 37], [38, 42], [43, 46], [47, 60], [61, 70], [71, 73], [74, 84], [85, 87], [88, 92], [92, 93], [94, 96], [97, 99], [100, 102], [103, 110], [111, 118], [119, 123], [124, 131], [132, 142], [143, 145], [146, 150], [150, 151], [152, 155], [156, 157], [158, 161], [162, 164], [165, 173], [174, 181], [182, 186], [187, 190], [191, 196], [197, 209], [210, 217], [218, 220], [221, 225], [226, 228], [229, 230], [231, 243], [244, 252], [253, 262], [263, 277], [277, 278], [279, 286], [286, 287], [288, 301], [301, 302], [303, 306], [307, 320], [321, 332], [332, 333]]}
{"doc_key": "ai-dev-150", "ner": [[1, 2, "task"], [8, 8, "task"], [17, 17, "metrics"], [19, 20, "metrics"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 8, 8, "general-affiliation", "", false, false], [17, 17, 1, 2, "part-of", "", true, false], [19, 20, 1, 2, "part-of", "", true, false], [22, 23, 1, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "paraphrase", "recognition", "can", "be", "posed", "as", "a", "classification", "problem", ",", "most", "standard", "evaluation", "measures", "such", "as", "accuracy", ",", "f1", "score", "or", "ROC", "curve", "give", "relatively", "good", "results", "."], "sentence-detokenized": "Since paraphrase recognition can be posed as a classification problem, most standard evaluation measures such as accuracy, f1 score or ROC curve give relatively good results.", "token2charspan": [[0, 5], [6, 16], [17, 28], [29, 32], [33, 35], [36, 41], [42, 44], [45, 46], [47, 61], [62, 69], [69, 70], [71, 75], [76, 84], [85, 95], [96, 104], [105, 109], [110, 112], [113, 121], [121, 122], [123, 125], [126, 131], [132, 134], [135, 138], [139, 144], [145, 149], [150, 160], [161, 165], [166, 173], [173, 174]]}
{"doc_key": "ai-dev-151", "ner": [[19, 19, "algorithm"], [28, 29, "algorithm"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 19, 28, 29, "opposite", "not_suited_for", false, false], [19, 19, 31, 32, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "makes", "it", "practical", "for", "the", "analysis", "of", "large", "datasets", "(", "hundreds", "or", "thousands", "of", "taxa", ")", "and", "for", "bootstrapping", ",", "where", "other", "means", "of", "analysis", "(", "e.g.", "maximum", "parsimony", ",", "maximum", "likelihood", ")", "may", "be", "computationally", "prohibitive", "."], "sentence-detokenized": "This makes it practical for the analysis of large datasets (hundreds or thousands of taxa) and for bootstrapping, where other means of analysis (e.g. maximum parsimony, maximum likelihood) may be computationally prohibitive.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 31], [32, 40], [41, 43], [44, 49], [50, 58], [59, 60], [60, 68], [69, 71], [72, 81], [82, 84], [85, 89], [89, 90], [91, 94], [95, 98], [99, 112], [112, 113], [114, 119], [120, 125], [126, 131], [132, 134], [135, 143], [144, 145], [145, 149], [150, 157], [158, 167], [167, 168], [169, 176], [177, 187], [187, 188], [189, 192], [193, 195], [196, 211], [212, 223], [223, 224]]}
{"doc_key": "ai-dev-152", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [9, 12, "organisation"], [14, 14, "organisation"], [22, 22, "programlang"], [26, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 22, 22, "named", "same", false, false], [14, 14, 9, 12, "named", "", false, false], [26, 35, 4, 4, "role", "submits", true, false], [26, 35, 6, 6, "role", "submits", true, false], [26, 35, 9, 12, "role", "submits_to", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2002", "submission", "of", "DAML", "+", "OIL", "to", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ";", "the", "work", "carried", "out", "by", "DAML", "contractors", "and", "the", "ad", "hoc", "EU", "/", "US", "Joint", "Committee", "on", "Markup", "Languages", "."], "sentence-detokenized": "The 2002 submission of DAML + OIL to the World Wide Web Consortium (W3C); the work carried out by DAML contractors and the ad hoc EU/US Joint Committee on Markup Languages.", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 22], [23, 27], [28, 29], [30, 33], [34, 36], [37, 40], [41, 46], [47, 51], [52, 55], [56, 66], [67, 68], [68, 71], [71, 72], [72, 73], [74, 77], [78, 82], [83, 90], [91, 94], [95, 97], [98, 102], [103, 114], [115, 118], [119, 122], [123, 125], [126, 129], [130, 132], [132, 133], [133, 135], [136, 141], [142, 151], [152, 154], [155, 161], [162, 171], [171, 172]]}
{"doc_key": "ai-dev-153", "ner": [[3, 4, "misc"], [8, 8, "misc"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 3, 4, "part-of", "", true, false], [11, 12, 3, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "non-linear", "normalisation", "is", "where", "the", "normalisation", "follows", "a", "sigmoid", "function", ".", "In", "this", "case", ",", "the", "normalised", "image", "is", "calculated", "according", "to", "the", "following", "formula"], "sentence-detokenized": "An example of non-linear normalisation is where the normalisation follows a sigmoid function. In this case, the normalised image is calculated according to the following formula", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 38], [39, 41], [42, 47], [48, 51], [52, 65], [66, 73], [74, 75], [76, 83], [84, 92], [92, 93], [94, 96], [97, 101], [102, 106], [106, 107], [108, 111], [112, 122], [123, 128], [129, 131], [132, 142], [143, 152], [153, 155], [156, 159], [160, 169], [170, 177]]}
{"doc_key": "ai-dev-154", "ner": [[5, 5, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 10, 10, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "pointed", "out", "that", "precision", "is", "usually", "combined", "with", "recall", "to", "overcome", "this", "problem", "."], "sentence-detokenized": "It was pointed out that precision is usually combined with recall to overcome this problem.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 18], [19, 23], [24, 33], [34, 36], [37, 44], [45, 53], [54, 58], [59, 65], [66, 68], [69, 77], [78, 82], [83, 90], [90, 91]]}
{"doc_key": "ai-dev-155", "ner": [[5, 7, "metrics"], [10, 13, "metrics"], [22, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 23, 10, 13, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Commonly", "used", "measures", "are", "the", "mean", "square", "error", "and", "the", "root", "mean", "square", "error", ",", "the", "latter", "having", "been", "used", "in", "the", "Netflix", "award", "."], "sentence-detokenized": "Commonly used measures are the mean square error and the root mean square error, the latter having been used in the Netflix award.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 26], [27, 30], [31, 35], [36, 42], [43, 48], [49, 52], [53, 56], [57, 61], [62, 66], [67, 73], [74, 79], [79, 80], [81, 84], [85, 91], [92, 98], [99, 103], [104, 108], [109, 111], [112, 115], [116, 123], [124, 129], [129, 130]]}
{"doc_key": "ai-dev-156", "ner": [[8, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "August", "2016", ",", "a", "research", "programme", "with", "University", "College", "Hospital", "was", "announced", "with", "the", "aim", "of", "developing", "an", "algorithm", "capable", "of", "automatically", "differentiating", "healthy", "and", "cancerous", "tissue", "in", "the", "head", "and", "neck", "areas", "."], "sentence-detokenized": "In August 2016, a research programme with University College Hospital was announced with the aim of developing an algorithm capable of automatically differentiating healthy and cancerous tissue in the head and neck areas.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 17], [18, 26], [27, 36], [37, 41], [42, 52], [53, 60], [61, 69], [70, 73], [74, 83], [84, 88], [89, 92], [93, 96], [97, 99], [100, 110], [111, 113], [114, 123], [124, 131], [132, 134], [135, 148], [149, 164], [165, 172], [173, 176], [177, 186], [187, 193], [194, 196], [197, 200], [201, 205], [206, 209], [210, 214], [215, 220], [220, 221]]}
{"doc_key": "ai-dev-157", "ner": [[3, 3, "researcher"], [19, 21, "organisation"], [24, 27, "organisation"], [30, 33, "organisation"], [36, 41, "organisation"], [44, 50, "organisation"], [54, 57, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 19, 21, "role", "", false, false], [3, 3, 24, 27, "role", "", false, false], [3, 3, 30, 33, "role", "", false, false], [3, 3, 36, 41, "role", "", false, false], [3, 3, 44, 50, "role", "", false, false], [3, 3, 54, 57, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "impact", "of", "Posner", "'s", "theoretical", "and", "empirical", "contributions", "has", "been", "recognized", "by", "the", "award", "of", "fellowships", "to", "the", "American", "Psychological", "Association", ",", "the", "Association", "for", "Psychological", "Science", ",", "the", "Society", "of", "Experimental", "Psychologists", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "The impact of Posner's theoretical and empirical contributions has been recognized by the award of fellowships to the American Psychological Association, the Association for Psychological Science, the Society of Experimental Psychologists, the American Academy of Arts and Sciences, the American Association for the Advancement of Science, and the National Academy of Sciences.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 20], [20, 22], [23, 34], [35, 38], [39, 48], [49, 62], [63, 66], [67, 71], [72, 82], [83, 85], [86, 89], [90, 95], [96, 98], [99, 110], [111, 113], [114, 117], [118, 126], [127, 140], [141, 152], [152, 153], [154, 157], [158, 169], [170, 173], [174, 187], [188, 195], [195, 196], [197, 200], [201, 208], [209, 211], [212, 224], [225, 238], [238, 239], [240, 243], [244, 252], [253, 260], [261, 263], [264, 268], [269, 272], [273, 281], [281, 282], [283, 286], [287, 295], [296, 307], [308, 311], [312, 315], [316, 327], [328, 330], [331, 338], [338, 339], [340, 343], [344, 347], [348, 356], [357, 364], [365, 367], [368, 376], [376, 377]]}
{"doc_key": "ai-dev-158", "ner": [[2, 2, "product"], [7, 8, "field"], [12, 13, "task"], [15, 17, "task"], [19, 19, "task"], [22, 24, "task"], [26, 26, "task"], [29, 30, "field"], [32, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 2, 7, 8, "usage", "", false, false], [12, 13, 7, 8, "part-of", "", false, false], [15, 17, 7, 8, "part-of", "", false, false], [19, 19, 15, 17, "named", "", false, false], [22, 24, 7, 8, "part-of", "", false, false], [26, 26, 22, 24, "named", "", false, false], [29, 30, 7, 8, "part-of", "", false, false], [32, 33, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["These", "intelligent", "chatbots", "use", "all", "kinds", "of", "artificial", "intelligence", ",", "such", "as", "image", "moderation", "and", "natural", "language", "understanding", "(", "NLU", ")", ",", "natural", "language", "generation", "(", "NLG", ")", ",", "machine", "learning", "and", "deep", "learning", "."], "sentence-detokenized": "These intelligent chatbots use all kinds of artificial intelligence, such as image moderation and natural language understanding (NLU), natural language generation (NLG), machine learning and deep learning.", "token2charspan": [[0, 5], [6, 17], [18, 26], [27, 30], [31, 34], [35, 40], [41, 43], [44, 54], [55, 67], [67, 68], [69, 73], [74, 76], [77, 82], [83, 93], [94, 97], [98, 105], [106, 114], [115, 128], [129, 130], [130, 133], [133, 134], [134, 135], [136, 143], [144, 152], [153, 163], [164, 165], [165, 168], [168, 169], [169, 170], [171, 178], [179, 187], [188, 191], [192, 196], [197, 205], [205, 206]]}
{"doc_key": "ai-dev-159", "ner": [[5, 7, "metrics"], [9, 9, "metrics"], [12, 12, "metrics"], [15, 21, "metrics"], [27, 29, "metrics"], [31, 31, "metrics"], [34, 40, "metrics"], [45, 47, "metrics"], [49, 49, "metrics"], [52, 58, "metrics"], [64, 66, "metrics"], [68, 68, "metrics"], [71, 77, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[9, 9, 5, 7, "named", "", false, false], [12, 12, 5, 7, "named", "", false, false], [15, 21, 5, 7, "named", "", false, false], [31, 31, 27, 29, "named", "", false, false], [34, 40, 27, 29, "named", "", false, false], [49, 49, 45, 47, "named", "", false, false], [52, 58, 45, 47, "named", "", false, false], [68, 68, 64, 66, "named", "", false, false], [71, 77, 64, 66, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "line", "ratios", "are", "the", "positive", "predictive", "value", "(", "PPV", ",", "or", "accuracy", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "supplemented", "by", "the", "false", "discovery", "rate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "and", "the", "negative", "predictive", "value", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "supplemented", "by", "the", "false", "omission", "rate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")"], "sentence-detokenized": "The line ratios are the positive predictive value (PPV, or accuracy) (TP / (TP + FP)), supplemented by the false discovery rate (FDR) (FP / (TP + FP)); and the negative predictive value (NPV) (TN / (TN + FN)), supplemented by the false omission rate (FOR) (FN / (TN + FN))", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 19], [20, 23], [24, 32], [33, 43], [44, 49], [50, 51], [51, 54], [54, 55], [56, 58], [59, 67], [67, 68], [69, 70], [70, 72], [73, 74], [75, 76], [76, 78], [79, 80], [81, 83], [83, 84], [84, 85], [85, 86], [87, 99], [100, 102], [103, 106], [107, 112], [113, 122], [123, 127], [128, 129], [129, 132], [132, 133], [134, 135], [135, 137], [138, 139], [140, 141], [141, 143], [144, 145], [146, 148], [148, 149], [149, 150], [150, 151], [152, 155], [156, 159], [160, 168], [169, 179], [180, 185], [186, 187], [187, 190], [190, 191], [192, 193], [193, 195], [196, 197], [198, 199], [199, 201], [202, 203], [204, 206], [206, 207], [207, 208], [208, 209], [210, 222], [223, 225], [226, 229], [230, 235], [236, 244], [245, 249], [250, 251], [251, 254], [254, 255], [256, 257], [257, 259], [260, 261], [262, 263], [263, 265], [266, 267], [268, 270], [270, 271], [271, 272]]}
{"doc_key": "ai-dev-160", "ner": [[8, 8, "misc"], [14, 15, "algorithm"], [17, 17, "algorithm"], [21, 23, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 17, 14, 15, "named", "", false, false], [25, 25, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "information", "is", "a", "mixture", "of", "sitemaps", "and", "RSS", "and", "is", "created", "using", "the", "Information", "Model", "(", "IM", ")", "and", "the", "Biomedical", "Resource", "Ontology", "(", "BRO", ")", "."], "sentence-detokenized": "The information is a mixture of sitemaps and RSS and is created using the Information Model (IM) and the Biomedical Resource Ontology (BRO).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 20], [21, 28], [29, 31], [32, 40], [41, 44], [45, 48], [49, 52], [53, 55], [56, 63], [64, 69], [70, 73], [74, 85], [86, 91], [92, 93], [93, 95], [95, 96], [97, 100], [101, 104], [105, 115], [116, 124], [125, 133], [134, 135], [135, 138], [138, 139], [139, 140]]}
{"doc_key": "ai-dev-161", "ner": [[1, 2, "task"], [7, 9, "algorithm"], [11, 14, "algorithm"], [21, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 11, 14, "origin", "based_on", false, false], [11, 14, 7, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Recent", "text", "recognition", "is", "based", "on", "a", "recurrent", "neural", "network", "(", "long", "-", "term", "memory", ")", "and", "does", "not", "require", "a", "language", "model", "."], "sentence-detokenized": "Recent text recognition is based on a recurrent neural network (long-term memory) and does not require a language model.", "token2charspan": [[0, 6], [7, 11], [12, 23], [24, 26], [27, 32], [33, 35], [36, 37], [38, 47], [48, 54], [55, 62], [63, 64], [64, 68], [68, 69], [69, 73], [74, 80], [80, 81], [82, 85], [86, 90], [91, 94], [95, 102], [103, 104], [105, 113], [114, 119], [119, 120]]}
{"doc_key": "ai-dev-162", "ner": [[3, 4, "misc"], [7, 8, "metrics"], [11, 12, "algorithm"], [16, 17, "metrics"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 3, 4, "type-of", "", false, false], [11, 12, 7, 8, "related-to", "", true, false], [16, 17, 3, 4, "type-of", "", false, false], [20, 21, 16, 17, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "most", "common", "loss", "functions", "are", "the", "hinge", "loss", "(", "for", "linear", "SVMs", ")", "and", "the", "logarithmic", "loss", "(", "for", "logistic", "regression", ")", "."], "sentence-detokenized": "The most common loss functions are the hinge loss (for linear SVMs) and the logarithmic loss (for logistic regression).", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 20], [21, 30], [31, 34], [35, 38], [39, 44], [45, 49], [50, 51], [51, 54], [55, 61], [62, 66], [66, 67], [68, 71], [72, 75], [76, 87], [88, 92], [93, 94], [94, 97], [98, 106], [107, 117], [117, 118], [118, 119]]}
{"doc_key": "ai-dev-163", "ner": [[0, 0, "metrics"], [10, 16, "metrics"], [18, 18, "metrics"], [21, 23, "metrics"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 10, 16, "compare", "", false, false], [0, 0, 21, 23, "compare", "", false, false], [18, 18, 10, 16, "named", "", false, false], [25, 25, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "is", "designed", "to", "improve", "on", "traditional", "methods", "such", "as", "maximum", "signal", "-", "to", "-", "noise", "ratio", "(", "PSNR", ")", "and", "mean", "square", "error", "(", "MSE", ")", "."], "sentence-detokenized": "SSIM is designed to improve on traditional methods such as maximum signal-to-noise ratio (PSNR) and mean square error (MSE).", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 27], [28, 30], [31, 42], [43, 50], [51, 55], [56, 58], [59, 66], [67, 73], [73, 74], [74, 76], [76, 77], [77, 82], [83, 88], [89, 90], [90, 94], [94, 95], [96, 99], [100, 104], [105, 111], [112, 117], [118, 119], [119, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-dev-164", "ner": [[11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "inspired", "later", "generations", "of", "robotics", "researchers", ",", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "His work inspired later generations of robotics researchers, such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 23], [24, 35], [36, 38], [39, 47], [48, 59], [59, 60], [61, 65], [66, 68], [69, 75], [76, 82], [82, 83], [84, 88], [89, 96], [97, 100], [101, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-dev-165", "ner": [[11, 13, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 11, 13, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "addition", ",", "pulse", "training", "is", "not", "differentiable", ",", "which", "eliminates", "backpropagation", "-", "based", "training", "methods", "such", "as", "gradient", "descent", "."], "sentence-detokenized": "In addition, pulse training is not differentiable, which eliminates backpropagation-based training methods such as gradient descent.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 18], [19, 27], [28, 30], [31, 34], [35, 49], [49, 50], [51, 56], [57, 67], [68, 83], [83, 84], [84, 89], [90, 98], [99, 106], [107, 111], [112, 114], [115, 123], [124, 131], [131, 132]]}
{"doc_key": "ai-dev-166", "ner": [[8, 9, "metrics"], [16, 17, "metrics"], [19, 19, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 16, 17, "related-to", "describes", false, false], [16, 17, 19, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "relationships", "can", "be", "easily", "represented", "by", "a", "confusion", "matrix", ",", "a", "table", "that", "describes", "the", "accuracy", "of", "a", "classification", "model", "."], "sentence-detokenized": "These relationships can be easily represented by a confusion matrix, a table that describes the accuracy of a classification model.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 26], [27, 33], [34, 45], [46, 48], [49, 50], [51, 60], [61, 67], [67, 68], [69, 70], [71, 76], [77, 81], [82, 91], [92, 95], [96, 104], [105, 107], [108, 109], [110, 124], [125, 130], [130, 131]]}
{"doc_key": "ai-dev-167", "ner": [[2, 10, "conference"], [8, 10, "conference"], [14, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 2, 10, "named", "", false, false], [14, 14, 2, 10, "physical", "", false, false], [14, 14, 2, 10, "role", "", false, false], [14, 14, 2, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["At", "the", "2018", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "conference", ",", "researchers", "from", "Google", "presented", "the", "work", "."], "sentence-detokenized": "At the 2018 Neural Information Processing Systems (NeurIPS) conference, researchers from Google presented the work.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 30], [31, 41], [42, 49], [50, 51], [51, 58], [58, 59], [60, 70], [70, 71], [72, 83], [84, 88], [89, 95], [96, 105], [106, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-dev-168", "ner": [[2, 2, "university"], [12, 12, "product"], [19, 21, "misc"], [18, 18, "conference"], [26, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 19, 21, "win-defeat", "", false, false], [19, 21, 18, 18, "temporal", "", false, false], [26, 29, 18, 18, "part-of", "", false, false], [26, 29, 18, 18, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "at", "Duke", ",", "he", "worked", "on", "an", "automatic", "crossword", "solver", ",", "PROVERB", ",", "which", "won", "the", "1999", "AAAI", "Outstanding", "Paper", "Award", "and", "participated", "in", "the", "American", "Crossword", "Puzzle", "Tournament", "."], "sentence-detokenized": "While at Duke, he worked on an automatic crossword solver, PROVERB, which won the 1999 AAAI Outstanding Paper Award and participated in the American Crossword Puzzle Tournament.", "token2charspan": [[0, 5], [6, 8], [9, 13], [13, 14], [15, 17], [18, 24], [25, 27], [28, 30], [31, 40], [41, 50], [51, 57], [57, 58], [59, 66], [66, 67], [68, 73], [74, 77], [78, 81], [82, 86], [87, 91], [92, 103], [104, 109], [110, 115], [116, 119], [120, 132], [133, 135], [136, 139], [140, 148], [149, 158], [159, 165], [166, 176], [176, 177]]}
{"doc_key": "ai-dev-169", "ner": [[5, 6, "location"], [8, 8, "location"], [16, 17, "country"], [19, 19, "country"], [21, 21, "country"], [23, 23, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 8, 8, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "company", "is", "headquartered", "in", "Rochester", "Hills", ",", "Michigan", "and", "has", "10", "regional", "locations", "in", "the", "United", "States", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "sentence-detokenized": "The company is headquartered in Rochester Hills, Michigan and has 10 regional locations in the United States, Canada, Mexico and Brazil.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 41], [42, 47], [47, 48], [49, 57], [58, 61], [62, 65], [66, 68], [69, 77], [78, 87], [88, 90], [91, 94], [95, 101], [102, 108], [108, 109], [110, 116], [116, 117], [118, 124], [125, 128], [129, 135], [135, 136]]}
{"doc_key": "ai-dev-170", "ner": [[12, 12, "product"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "joins", "a", "collection", "of", "historically", "important", "robots", "that", "includes", "an", "earlier", "Unimate", "and", "the", "Odetics", "Odex", "1", "."], "sentence-detokenized": "It joins a collection of historically important robots that includes an earlier Unimate and the Odetics Odex 1.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 21], [22, 24], [25, 37], [38, 47], [48, 54], [55, 59], [60, 68], [69, 71], [72, 79], [80, 87], [88, 91], [92, 95], [96, 103], [104, 108], [109, 110], [110, 111]]}
{"doc_key": "ai-dev-171", "ner": [[8, 8, "researcher"], [13, 13, "organisation"], [15, 16, "researcher"], [26, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 13, 13, "physical", "", false, false], [8, 8, 13, 13, "role", "", false, false], [15, 16, 13, 13, "physical", "", false, false], [15, 16, 13, 13, "role", "", false, false], [15, 16, 26, 31, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "guest", "editor", "for", "this", "issue", "will", "be", "David", "'s", "former", "colleague", "at", "NIST", ",", "Judah", "Levine", ",", "who", "is", "the", "most", "recent", "winner", "of", "the", "I", ".", "I", "..", "Rabi", "Award", "."], "sentence-detokenized": "The guest editor for this issue will be David's former colleague at NIST, Judah Levine, who is the most recent winner of the I. I.. Rabi Award.", "token2charspan": [[0, 3], [4, 9], [10, 16], [17, 20], [21, 25], [26, 31], [32, 36], [37, 39], [40, 45], [45, 47], [48, 54], [55, 64], [65, 67], [68, 72], [72, 73], [74, 79], [80, 86], [86, 87], [88, 91], [92, 94], [95, 98], [99, 103], [104, 110], [111, 117], [118, 120], [121, 124], [125, 126], [126, 127], [128, 129], [129, 131], [132, 136], [137, 142], [142, 143]]}
{"doc_key": "ai-dev-172", "ner": [[12, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "can", "be", "arranged", "in", "a", "2", "\u00d7", "2", "contingency", "table", "(", "confusion", "matrix", ")", ",", "with", "the", "test", "result", "on", "the", "vertical", "axis", "and", "the", "actual", "condition", "on", "the", "horizontal", "axis", "by", "convention", "."], "sentence-detokenized": "These can be arranged in a 2 \u00d7 2 contingency table (confusion matrix), with the test result on the vertical axis and the actual condition on the horizontal axis by convention.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 21], [22, 24], [25, 26], [27, 28], [29, 30], [31, 32], [33, 44], [45, 50], [51, 52], [52, 61], [62, 68], [68, 69], [69, 70], [71, 75], [76, 79], [80, 84], [85, 91], [92, 94], [95, 98], [99, 107], [108, 112], [113, 116], [117, 120], [121, 127], [128, 137], [138, 140], [141, 144], [145, 155], [156, 160], [161, 163], [164, 174], [174, 175]]}
{"doc_key": "ai-dev-173", "ner": [[1, 4, "product"], [8, 8, "product"], [10, 10, "product"], [12, 13, "product"], [15, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 4, 8, 8, "part-of", "", false, false], [1, 4, 10, 10, "part-of", "", false, false], [1, 4, 12, 13, "part-of", "", false, false], [1, 4, 15, 20, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Apple", "iOS", "operating", "system", "used", "on", "the", "iPhone", ",", "iPad", "and", "iPod", "Touch", "uses", "VoiceOver", "text", "-", "to", "-", "speech", "accessibility", "."], "sentence-detokenized": "The Apple iOS operating system used on the iPhone, iPad and iPod Touch uses VoiceOver text-to-speech accessibility.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 23], [24, 30], [31, 35], [36, 38], [39, 42], [43, 49], [49, 50], [51, 55], [56, 59], [60, 64], [65, 70], [71, 75], [76, 85], [86, 90], [90, 91], [91, 93], [93, 94], [94, 100], [101, 114], [114, 115]]}
{"doc_key": "ai-dev-174", "ner": [[7, 9, "conference"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "the", "best", "system", "entering", "MUC", "-", "7", "achieved", "93.39", "%", "F-measurement", "while", "the", "human", "annotators", "achieved", "97.6", "%", "and", "96.95", "%", "."], "sentence-detokenized": "For example, the best system entering MUC-7 achieved 93.39% F-measurement while the human annotators achieved 97.6% and 96.95%.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 37], [38, 41], [41, 42], [42, 43], [44, 52], [53, 58], [58, 59], [60, 73], [74, 79], [80, 83], [84, 89], [90, 100], [101, 109], [110, 114], [114, 115], [116, 119], [120, 125], [125, 126], [126, 127]]}
{"doc_key": "ai-dev-175", "ner": [[12, 14, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 16, 12, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "done", "using", "standard", "neural", "network", "training", "algorithms", ",", "such", "as", "stochastic", "gradient", "descent", "with", "backpropagation", "."], "sentence-detokenized": "This is done using standard neural network training algorithms, such as stochastic gradient descent with backpropagation.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 18], [19, 27], [28, 34], [35, 42], [43, 51], [52, 62], [62, 63], [64, 68], [69, 71], [72, 82], [83, 91], [92, 99], [100, 104], [105, 120], [120, 121]]}
{"doc_key": "ai-dev-176", "ner": [[0, 1, "organisation"], [18, 18, "country"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 18, 18, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "is", "a", "top", "1000", "site", ",", "ranking", "around", "400th", "in", "the", "world", "and", "150th", "in", "the", "US", "alone", ",", "according", "to", "the", "ranking", "site", "Alexa", "."], "sentence-detokenized": "Rotten Tomatoes is a top 1000 site, ranking around 400th in the world and 150th in the US alone, according to the ranking site Alexa.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 20], [21, 24], [25, 29], [30, 34], [34, 35], [36, 43], [44, 50], [51, 56], [57, 59], [60, 63], [64, 69], [70, 73], [74, 79], [80, 82], [83, 86], [87, 89], [90, 95], [95, 96], [97, 106], [107, 109], [110, 113], [114, 121], [122, 126], [127, 132], [132, 133]]}
{"doc_key": "ai-dev-177", "ner": [[15, 16, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "general", ",", "all", "learning", "shows", "a", "progressive", "evolution", "over", "time", ",", "but", "describes", "a", "sigmoid", "function", "that", "has", "different", "appearances", "depending", "on", "the", "time", "scale", "of", "observation", "."], "sentence-detokenized": "In general, all learning shows a progressive evolution over time, but describes a sigmoid function that has different appearances depending on the time scale of observation.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 24], [25, 30], [31, 32], [33, 44], [45, 54], [55, 59], [60, 64], [64, 65], [66, 69], [70, 79], [80, 81], [82, 89], [90, 98], [99, 103], [104, 107], [108, 117], [118, 129], [130, 139], [140, 142], [143, 146], [147, 151], [152, 157], [158, 160], [161, 172], [172, 173]]}
{"doc_key": "ai-dev-178", "ner": [[1, 2, "metrics"], [7, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SSD", "is", "also", "known", "as", "the", "mean", "square", "error", "."], "sentence-detokenized": "The SSD is also known as the mean square error.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 21], [22, 24], [25, 28], [29, 33], [34, 40], [41, 46], [46, 47]]}
{"doc_key": "ai-dev-179", "ner": [[0, 2, "algorithm"], [4, 5, "algorithm"], [8, 10, "algorithm"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 22, 23, "related-to", "can_be_related_to", true, false], [4, 5, 22, 23, "related-to", "can_be_related_to", true, false], [8, 10, 22, 23, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", ",", "neural", "networks", "or", "a", "naive", "Bayes", "classifier", "could", "be", "used", "in", "combination", "with", "model", "quality", "measures", "such", "as", "balanced", "accuracy"], "sentence-detokenized": "Decision tree learning, neural networks or a naive Bayes classifier could be used in combination with model quality measures such as balanced accuracy", "token2charspan": [[0, 8], [9, 13], [14, 22], [22, 23], [24, 30], [31, 39], [40, 42], [43, 44], [45, 50], [51, 56], [57, 67], [68, 73], [74, 76], [77, 81], [82, 84], [85, 96], [97, 101], [102, 107], [108, 115], [116, 124], [125, 129], [130, 132], [133, 141], [142, 150]]}
{"doc_key": "ai-dev-180", "ner": [[16, 16, "conference"], [22, 26, "conference"], [21, 29, "misc"], [35, 37, "product"], [44, 47, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 29, 22, 26, "origin", "", false, false], [21, 29, 22, 26, "temporal", "", false, false], [35, 37, 21, 29, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "is", "a", "past", "president", "(", "1979", ")", "and", "inaugural", "member", "(", "2011", ")", "of", "the", "ACL", ",", "a", "co-recipient", "of", "the", "1992", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "for", "his", "contribution", "to", "the", "Interlisp", "programming", "system", ",", "and", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "He is a past president (1979) and inaugural member (2011) of the ACL, a co-recipient of the 1992 Association for Computing Machinery Software Systems Award for his contribution to the Interlisp programming system, and a member of the Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 22], [23, 24], [24, 28], [28, 29], [30, 33], [34, 43], [44, 50], [51, 52], [52, 56], [56, 57], [58, 60], [61, 64], [65, 68], [68, 69], [70, 71], [72, 84], [85, 87], [88, 91], [92, 96], [97, 108], [109, 112], [113, 122], [123, 132], [133, 141], [142, 149], [150, 155], [156, 159], [160, 163], [164, 176], [177, 179], [180, 183], [184, 193], [194, 205], [206, 212], [212, 213], [214, 217], [218, 219], [220, 226], [227, 229], [230, 233], [234, 245], [246, 249], [250, 259], [260, 269], [269, 270]]}
{"doc_key": "ai-dev-181", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 9, "researcher"], [12, 18, "researcher"], [25, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 25, 28, "related-to", "", false, false], [5, 6, 25, 28, "related-to", "", false, false], [8, 9, 25, 28, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "is", "considered", "by", "Cade", "Metz", "to", "be", "one", "of", "the", "three", "people", "most", "responsible", "for", "advancing", "deep", "learning", "in", "the", "1990s", "and", "2000s", "."], "sentence-detokenized": "Along with Geoffrey Hinton and Yann LeCun, Bengio is considered by Cade Metz to be one of the three people most responsible for advancing deep learning in the 1990s and 2000s.", "token2charspan": [[0, 5], [6, 10], [11, 19], [20, 26], [27, 30], [31, 35], [36, 41], [41, 42], [43, 49], [50, 52], [53, 63], [64, 66], [67, 71], [72, 76], [77, 79], [80, 82], [83, 86], [87, 89], [90, 93], [94, 99], [100, 106], [107, 111], [112, 123], [124, 127], [128, 137], [138, 142], [143, 151], [152, 154], [155, 158], [159, 164], [165, 168], [169, 174], [174, 175]]}
{"doc_key": "ai-dev-182", "ner": [[1, 2, "field"], [4, 5, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "information", "theory", "and", "computer", "science", ",", "a", "code", "is", "generally", "regarded", "as", "an", "algorithm", "that", "uniquely", "represents", "symbols", "in", "a", "certain", "source", "alphabet", "by", "coded", "strings", ",", "which", "may", "be", "in", "another", "target", "alphabet", "."], "sentence-detokenized": "In information theory and computer science, a code is generally regarded as an algorithm that uniquely represents symbols in a certain source alphabet by coded strings, which may be in another target alphabet.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 45], [46, 50], [51, 53], [54, 63], [64, 72], [73, 75], [76, 78], [79, 88], [89, 93], [94, 102], [103, 113], [114, 121], [122, 124], [125, 126], [127, 134], [135, 141], [142, 150], [151, 153], [154, 159], [160, 167], [167, 168], [169, 174], [175, 178], [179, 181], [182, 184], [185, 192], [193, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-dev-183", "ner": [[8, 9, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 8, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "fairly", "simple", "non", "-linear", "function", ",", "the", "sigmoid", "function", ",", "like", "the", "logistic", "function", ",", "also", "has", "an", "easily", "calculated", "derivative", ",", "which", "can", "be", "important", "when", "calculating", "updates", "to", "the", "weights", "in", "the", "network", "."], "sentence-detokenized": "A fairly simple non-linear function, the sigmoid function, like the logistic function, also has an easily calculated derivative, which can be important when calculating updates to the weights in the network.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 19], [19, 26], [27, 35], [35, 36], [37, 40], [41, 48], [49, 57], [57, 58], [59, 63], [64, 67], [68, 76], [77, 85], [85, 86], [87, 91], [92, 95], [96, 98], [99, 105], [106, 116], [117, 127], [127, 128], [129, 134], [135, 138], [139, 141], [142, 151], [152, 156], [157, 168], [169, 176], [177, 179], [180, 183], [184, 191], [192, 194], [195, 198], [199, 206], [206, 207]]}
{"doc_key": "ai-dev-184", "ner": [[0, 1, "person"], [4, 4, "location"], [6, 6, "location"], [8, 10, "country"], [13, 13, "country"], [17, 18, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 4, 4, "physical", "", false, false], [4, 4, 6, 6, "physical", "", false, false], [6, 6, 8, 10, "physical", "", false, false], [6, 6, 13, 13, "physical", "", false, false], [6, 6, 17, 18, "physical", "", false, false], [13, 13, 8, 10, "origin", "", false, false], [17, 18, 13, 13, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "was", "born", "in", "Hronov", ",", "Bohemia", "(", "Austria", "-", "Hungary", ",", "later", "Czechoslovakia", ",", "now", "the", "Czech", "Republic", ")", "in", "1887", "."], "sentence-detokenized": "\u010capek was born in Hronov, Bohemia (Austria-Hungary, later Czechoslovakia, now the Czech Republic) in 1887.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 24], [24, 25], [26, 33], [34, 35], [35, 42], [42, 43], [43, 50], [50, 51], [52, 57], [58, 72], [72, 73], [74, 77], [78, 81], [82, 87], [88, 96], [96, 97], [98, 100], [101, 105], [105, 106]]}
{"doc_key": "ai-dev-185", "ner": [[5, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "specialised", "software", "can", "narrate", "RSS", "."], "sentence-detokenized": "Some specialised software can narrate RSS.", "token2charspan": [[0, 4], [5, 16], [17, 25], [26, 29], [30, 37], [38, 41], [41, 42]]}
{"doc_key": "ai-dev-186", "ner": [[6, 7, "task"], [11, 12, "task"], [14, 14, "task"], [17, 17, "task"], [19, 20, "task"], [27, 28, "task"], [31, 32, "task"], [37, 38, "task"], [41, 43, "product"], [45, 46, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[6, 7, 11, 12, "related-to", "", true, false], [6, 7, 14, 14, "related-to", "", true, false], [6, 7, 17, 17, "related-to", "", true, false], [31, 32, 27, 28, "usage", "", true, false], [41, 43, 37, 38, "type-of", "", false, false], [45, 46, 37, 38, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Aspects", "of", "ontology", "editors", "include", ":", "visual", "navigation", "capabilities", "in", "the", "knowledge", "model", ",", "inference", "engines", "and", "extraction", ";", "module", "support", ";", "import", "and", "export", "of", "foreign", "knowledge", "representation", "languages", "for", "ontology", "mapping", ";", "and", "support", "for", "meta", "-ontologies", "such", "as", "OWL", "-", "S", ",", "Dublin", "Core", ",", "etc", "."], "sentence-detokenized": "Aspects of ontology editors include: visual navigation capabilities in the knowledge model, inference engines and extraction; module support; import and export of foreign knowledge representation languages for ontology mapping; and support for meta-ontologies such as OWL-S, Dublin Core, etc.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 27], [28, 35], [35, 36], [37, 43], [44, 54], [55, 67], [68, 70], [71, 74], [75, 84], [85, 90], [90, 91], [92, 101], [102, 109], [110, 113], [114, 124], [124, 125], [126, 132], [133, 140], [140, 141], [142, 148], [149, 152], [153, 159], [160, 162], [163, 170], [171, 180], [181, 195], [196, 205], [206, 209], [210, 218], [219, 226], [226, 227], [228, 231], [232, 239], [240, 243], [244, 248], [248, 259], [260, 264], [265, 267], [268, 271], [271, 272], [272, 273], [273, 274], [275, 281], [282, 286], [286, 287], [288, 291], [291, 292]]}
{"doc_key": "ai-dev-187", "ner": [[1, 1, "organisation"], [7, 10, "misc"], [14, 15, "task"], [22, 22, "field"], [25, 25, "misc"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 10, 1, 1, "origin", "", false, false], [14, 15, 7, 10, "part-of", "", false, false], [22, 22, 7, 10, "part-of", "", false, false], [25, 25, 22, 22, "type-of", "", false, false], [27, 28, 22, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "FBI", "has", "also", "implemented", "it", "s", "next", "generation", "identification", "programme", ",", "which", "includes", "facial", "recognition", ",", "as", "well", "as", "more", "traditional", "biometrics", "such", "as", "fingerprints", "and", "iris", "scans", ",", "which", "can", "be", "extracted", "from", "criminal", "and", "civil", "databases", "."], "sentence-detokenized": "The FBI has also implemented its next generation identification programme, which includes facial recognition, as well as more traditional biometrics such as fingerprints and iris scans, which can be extracted from criminal and civil databases.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 28], [29, 31], [31, 32], [33, 37], [38, 48], [49, 63], [64, 73], [73, 74], [75, 80], [81, 89], [90, 96], [97, 108], [108, 109], [110, 112], [113, 117], [118, 120], [121, 125], [126, 137], [138, 148], [149, 153], [154, 156], [157, 169], [170, 173], [174, 178], [179, 184], [184, 185], [186, 191], [192, 195], [196, 198], [199, 208], [209, 213], [214, 222], [223, 226], [227, 232], [233, 242], [242, 243]]}
{"doc_key": "ai-dev-188", "ner": [[5, 7, "person"], [15, 16, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "2016", "season", ",", "Samantha", "Ponder", "has", "been", "added", "as", "a", "host", ",", "replacing", "Molly", "McGrath", "."], "sentence-detokenized": "For the 2016 season, Samantha Ponder has been added as a host, replacing Molly McGrath.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 19], [19, 20], [21, 29], [30, 36], [37, 40], [41, 45], [46, 51], [52, 54], [55, 56], [57, 61], [61, 62], [63, 72], [73, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-dev-189", "ner": [[3, 5, "algorithm"], [18, 22, "misc"], [24, 24, "misc"], [26, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "adversarial", "search", "algorithm", "commonly", "used", "for", "the", "automatic", "play", "of", "two", "-", "player", "games", "(", "Tic", "-", "tac", "-", "toe", ",", "chess", ",", "go", ",", "etc.", ")", "."], "sentence-detokenized": "This is an adversarial search algorithm commonly used for the automatic play of two-player games (Tic-tac-toe, chess, go, etc.).", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 29], [30, 39], [40, 48], [49, 53], [54, 57], [58, 61], [62, 71], [72, 76], [77, 79], [80, 83], [83, 84], [84, 90], [91, 96], [97, 98], [98, 101], [101, 102], [102, 105], [105, 106], [106, 109], [109, 110], [111, 116], [116, 117], [118, 120], [120, 121], [122, 126], [126, 127], [127, 128]]}
{"doc_key": "ai-dev-190", "ner": [[6, 9, "field"], [8, 8, "field"], [11, 12, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "draws", "on", "the", "fields", "of", "computer", "or", "machine", "vision", "and", "medical", "imaging", ",", "and", "makes", "extensive", "use", "of", "pattern", "recognition", ",", "digital", "geometry", "and", "signal", "processing", "."], "sentence-detokenized": "It draws on the fields of computer or machine vision and medical imaging, and makes extensive use of pattern recognition, digital geometry and signal processing.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 15], [16, 22], [23, 25], [26, 34], [35, 37], [38, 45], [46, 52], [53, 56], [57, 64], [65, 72], [72, 73], [74, 77], [78, 83], [84, 93], [94, 97], [98, 100], [101, 108], [109, 120], [120, 121], [122, 129], [130, 138], [139, 142], [143, 149], [150, 160], [160, 161]]}
{"doc_key": "ai-dev-191", "ner": [[2, 4, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "a", "facial", "recognition", "system", ",", "for", "example", ",", "the", "image", "of", "a", "person", "'s", "face", "is", "the", "input", "and", "the", "output", "tag", "is", "that", "person", "'s", "name", "."], "sentence-detokenized": "In a facial recognition system, for example, the image of a person's face is the input and the output tag is that person's name.", "token2charspan": [[0, 2], [3, 4], [5, 11], [12, 23], [24, 30], [30, 31], [32, 35], [36, 43], [43, 44], [45, 48], [49, 54], [55, 57], [58, 59], [60, 66], [66, 68], [69, 73], [74, 76], [77, 80], [81, 86], [87, 90], [91, 94], [95, 101], [102, 105], [106, 108], [109, 113], [114, 120], [120, 122], [123, 127], [127, 128]]}
{"doc_key": "ai-dev-192", "ner": [[0, 1, "organisation"], [4, 5, "product"], [9, 11, "product"], [18, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 5, "artifact", "", false, false], [4, 5, 9, 11, "part-of", "", false, false], [9, 11, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc", "has", "introduced", "Face", "ID", "on", "the", "flagship", "i", "Phone", "X", "as", "a", "biometric", "authentication", "successor", "to", "Touch", "ID", ",", "a", "fingerprint", "-", "based", "system", "."], "sentence-detokenized": "Apple Inc has introduced Face ID on the flagship iPhone X as a biometric authentication successor to Touch ID, a fingerprint-based system.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 24], [25, 29], [30, 32], [33, 35], [36, 39], [40, 48], [49, 50], [50, 55], [56, 57], [58, 60], [61, 62], [63, 72], [73, 87], [88, 97], [98, 100], [101, 106], [107, 109], [109, 110], [111, 112], [113, 124], [124, 125], [125, 130], [131, 137], [137, 138]]}
{"doc_key": "ai-dev-193", "ner": [[5, 7, "metrics"], [10, 11, "metrics"], [24, 27, "metrics"], [30, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["You", "can", "also", "combine", "the", "F", "-", "measure", "with", "the", "R-", "square", "evaluated", "for", "the", "raw", "model", "output", "and", "the", "target", ",", "or", "the", "cost", "/", "gain", "matrix", "with", "the", "correlation", "coefficient", ",", "etc", "."], "sentence-detokenized": "You can also combine the F-measure with the R-square evaluated for the raw model output and the target, or the cost/gain matrix with the correlation coefficient, etc.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 20], [21, 24], [25, 26], [26, 27], [27, 34], [35, 39], [40, 43], [44, 46], [46, 52], [53, 62], [63, 66], [67, 70], [71, 74], [75, 80], [81, 87], [88, 91], [92, 95], [96, 102], [102, 103], [104, 106], [107, 110], [111, 115], [115, 116], [116, 120], [121, 127], [128, 132], [133, 136], [137, 148], [149, 160], [160, 161], [162, 165], [165, 166]]}
{"doc_key": "ai-dev-194", "ner": [[1, 7, "conference"], [11, 13, "location"], [15, 15, "location"], [18, 21, "location"], [23, 23, "location"], [25, 29, "country"], [32, 34, "location"], [37, 41, "location"], [43, 45, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[1, 7, 11, 13, "physical", "", false, false], [1, 7, 18, 21, "physical", "", false, false], [1, 7, 32, 34, "physical", "", false, false], [1, 7, 37, 41, "physical", "", false, false], [11, 13, 15, 15, "physical", "", false, false], [18, 21, 23, 23, "physical", "", false, false], [23, 23, 25, 29, "physical", "", false, false], [32, 34, 43, 45, "physical", "", false, false], [37, 41, 43, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "Spanish", "edition", "of", "Campus", "Party", "has", "been", "held", "at", "the", "Colegio", "Miguel", "Hern\u00e1ndez", ",", "Ceulaj", "and", "the", "Benalm\u00e1dena", "Municipal", "Sports", "Arena", "in", "M\u00e1laga", ",", "Spain", ",", "as", "well", "as", "at", "the", "Valencia", "County", "Fair", "and", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "for", "the", "past", "15", "years", "."], "sentence-detokenized": "The Spanish edition of Campus Party has been held at the Colegio Miguel Hern\u00e1ndez, Ceulaj and the Benalm\u00e1dena Municipal Sports Arena in M\u00e1laga, Spain, as well as at the Valencia County Fair and the City of Arts and Sciences in Valencia for the past 15 years.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 22], [23, 29], [30, 35], [36, 39], [40, 44], [45, 49], [50, 52], [53, 56], [57, 64], [65, 71], [72, 81], [81, 82], [83, 89], [90, 93], [94, 97], [98, 109], [110, 119], [120, 126], [127, 132], [133, 135], [136, 142], [142, 143], [144, 149], [149, 150], [151, 153], [154, 158], [159, 161], [162, 164], [165, 168], [169, 177], [178, 184], [185, 189], [190, 193], [194, 197], [198, 202], [203, 205], [206, 210], [211, 214], [215, 223], [224, 226], [227, 235], [236, 239], [240, 243], [244, 248], [249, 251], [252, 257], [257, 258]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [15, 15, "programlang"], [19, 19, "product"], [21, 21, "product"], [25, 25, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 15, 0, 0, "general-affiliation", "", false, false], [19, 19, 15, 15, "part-of", "", false, false], [21, 21, 15, 15, "part-of", "", false, false], [25, 25, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["gnuplot", "can", "be", "used", "from", "a", "variety", "of", "programming", "languages", "to", "graph", "data", ",", "including", "Perl", "(", "via", "the", "PDL", "and", "CPAN", "packages", ")", ",", "Python", "(", "via", ")", "."], "sentence-detokenized": "gnuplot can be used from a variety of programming languages to graph data, including Perl (via the PDL and CPAN packages), Python (via ).", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 19], [20, 24], [25, 26], [27, 34], [35, 37], [38, 49], [50, 59], [60, 62], [63, 68], [69, 73], [73, 74], [75, 84], [85, 89], [90, 91], [91, 94], [95, 98], [99, 102], [103, 106], [107, 111], [112, 120], [120, 121], [121, 122], [123, 129], [130, 131], [131, 134], [135, 136], [136, 137]]}
{"doc_key": "ai-dev-196", "ner": [[3, 5, "product"], [19, 19, "conference"], [21, 21, "conference"], [35, 35, "conference"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 3, 5, "topic", "", false, false], [21, 21, 3, 5, "topic", "", false, false], [35, 35, 3, 5, "topic", "", false, false], [37, 37, 3, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "field", "of", "spoken", "dialogue", "systems", "is", "quite", "broad", "and", "includes", "research", "(", "presented", "at", "scientific", "conferences", "such", "as", "SIGdial", "and", "Interspeech", ")", "and", "a", "large", "industrial", "sector", "(", "with", "its", "own", "meetings", "such", "as", "SpeechTek", "and", "AVIOS", ")", "."], "sentence-detokenized": "The field of spoken dialogue systems is quite broad and includes research (presented at scientific conferences such as SIGdial and Interspeech) and a large industrial sector (with its own meetings such as SpeechTek and AVIOS).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 28], [29, 36], [37, 39], [40, 45], [46, 51], [52, 55], [56, 64], [65, 73], [74, 75], [75, 84], [85, 87], [88, 98], [99, 110], [111, 115], [116, 118], [119, 126], [127, 130], [131, 142], [142, 143], [144, 147], [148, 149], [150, 155], [156, 166], [167, 173], [174, 175], [175, 179], [180, 183], [184, 187], [188, 196], [197, 201], [202, 204], [205, 214], [215, 218], [219, 224], [224, 225], [225, 226]]}
{"doc_key": "ai-dev-197", "ner": [[3, 5, "field"], [8, 9, "task"], [11, 13, "task"], [15, 17, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 3, 5, "part-of", "task_part_of_field", false, false], [11, 13, 3, 5, "part-of", "task_part_of_field", false, false], [15, 17, 3, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "challenges", "of", "natural", "language", "processing", "often", "concern", "speech", "recognition", ",", "natural", "language", "understanding", "and", "natural", "language", "generation", "."], "sentence-detokenized": "The challenges of natural language processing often concern speech recognition, natural language understanding and natural language generation.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 25], [26, 34], [35, 45], [46, 51], [52, 59], [60, 66], [67, 78], [78, 79], [80, 87], [88, 96], [97, 110], [111, 114], [115, 122], [123, 131], [132, 142], [142, 143]]}
{"doc_key": "ai-dev-198", "ner": [[5, 5, "product"], [8, 10, "product"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 8, 10, "part-of", "", false, false], [5, 5, 35, 36, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "such", "as", "Siri", "in", "the", "iOS", "operating", "system", ",", "operate", "using", "a", "similar", "pattern", "recognition", "technique", "to", "text", "-", "based", "systems", ",", "but", "in", "the", "former", "case", "the", "user", "input", "is", "through", "voice", "recognition", "."], "sentence-detokenized": "These systems, such as Siri in the iOS operating system, operate using a similar pattern recognition technique to text-based systems, but in the former case the user input is through voice recognition.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 27], [28, 30], [31, 34], [35, 38], [39, 48], [49, 55], [55, 56], [57, 64], [65, 70], [71, 72], [73, 80], [81, 88], [89, 100], [101, 110], [111, 113], [114, 118], [118, 119], [119, 124], [125, 132], [132, 133], [134, 137], [138, 140], [141, 144], [145, 151], [152, 156], [157, 160], [161, 165], [166, 171], [172, 174], [175, 182], [183, 188], [189, 200], [200, 201]]}
{"doc_key": "ai-dev-199", "ner": [[1, 3, "algorithm"], [16, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 3, 16, 17, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["More", "exotic", "fitness", "functions", "that", "explore", "the", "granularity", "of", "the", "model", "include", "the", "area", "under", "the", "ROC", "curve", "and", "the", "rank", "measure", "."], "sentence-detokenized": "More exotic fitness functions that explore the granularity of the model include the area under the ROC curve and the rank measure.", "token2charspan": [[0, 4], [5, 11], [12, 19], [20, 29], [30, 34], [35, 42], [43, 46], [47, 58], [59, 61], [62, 65], [66, 71], [72, 79], [80, 83], [84, 88], [89, 94], [95, 98], [99, 102], [103, 108], [109, 112], [113, 116], [117, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-dev-200", "ner": [[3, 6, "product"], [9, 12, "researcher"], [18, 20, "product"], [25, 28, "organisation"], [30, 30, "organisation"], [40, 44, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 6, 9, 12, "origin", "", false, false], [9, 12, 25, 28, "role", "", false, false], [18, 20, 9, 12, "origin", "", false, false], [30, 30, 25, 28, "named", "", false, false], [40, 44, 25, 28, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "term", "\"", "Semantic", "Web", "\"", "was", "coined", "by", "Tim", "Berners", "-", "Lee", ",", "the", "inventor", "of", "the", "World", "Wide", "Web", "and", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "oversees", "the", "development", "of", "the", "proposed", "standards", "for", "the", "Semantic", "Web", "."], "sentence-detokenized": "The term \"Semantic Web\" was coined by Tim Berners-Lee, the inventor of the World Wide Web and director of the World Wide Web Consortium (W3C), which oversees the development of the proposed standards for the Semantic Web.", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 18], [19, 22], [22, 23], [24, 27], [28, 34], [35, 37], [38, 41], [42, 49], [49, 50], [50, 53], [53, 54], [55, 58], [59, 67], [68, 70], [71, 74], [75, 80], [81, 85], [86, 89], [90, 93], [94, 102], [103, 105], [106, 109], [110, 115], [116, 120], [121, 124], [125, 135], [136, 137], [137, 140], [140, 141], [141, 142], [143, 148], [149, 157], [158, 161], [162, 173], [174, 176], [177, 180], [181, 189], [190, 199], [200, 203], [204, 207], [208, 216], [217, 220], [220, 221]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [7, 7, "task"], [14, 15, "product"], [17, 19, "product"], [21, 21, "product"], [24, 25, "product"], [32, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 14, 15, "opposite", "", false, false], [0, 1, 17, 19, "opposite", "", false, false], [0, 1, 24, 25, "opposite", "", false, false], [0, 1, 32, 33, "part-of", "", false, false], [7, 7, 0, 1, "named", "", false, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Machine", "translation", ",", "sometimes", "referred", "to", "as", "MT", "(", "not", "to", "be", "confused", "with", "computer-assisted", "translation", ",", "computer-assisted", "human", "translation", "(", "CAHT", ")", "or", "interactive", "translation", ")", ",", "is", "a", "sub-field", "of", "computational", "linguistics", "that", "studies", "the", "use", "of", "software", "to", "translate", "text", "or", "speech", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Machine translation, sometimes referred to as MT (not to be confused with computer-assisted translation, computer-assisted human translation (CAHT) or interactive translation), is a sub-field of computational linguistics that studies the use of software to translate text or speech from one language to another.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 30], [31, 39], [40, 42], [43, 45], [46, 48], [49, 50], [50, 53], [54, 56], [57, 59], [60, 68], [69, 73], [74, 91], [92, 103], [103, 104], [105, 122], [123, 128], [129, 140], [141, 142], [142, 146], [146, 147], [148, 150], [151, 162], [163, 174], [174, 175], [175, 176], [177, 179], [180, 181], [182, 191], [192, 194], [195, 208], [209, 220], [221, 225], [226, 233], [234, 237], [238, 241], [242, 244], [245, 253], [254, 256], [257, 266], [267, 271], [272, 274], [275, 281], [282, 286], [287, 290], [291, 299], [300, 302], [303, 310], [310, 311]]}
{"doc_key": "ai-dev-202", "ner": [[2, 5, "product"], [9, 11, "university"], [14, 15, "researcher"], [17, 18, "researcher"], [43, 44, "location"], [46, 46, "location"], [50, 53, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 5, 14, 15, "artifact", "", false, false], [2, 5, 17, 18, "artifact", "", false, false], [14, 15, 9, 11, "physical", "", false, false], [14, 15, 9, 11, "role", "", false, false], [17, 18, 9, 11, "physical", "", false, false], [17, 18, 9, 11, "role", "", false, false], [43, 44, 46, 46, "physical", "", false, false], [50, 53, 43, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "first", "interlingual", "MT", "systems", "were", "also", "built", "at", "Stanford", "in", "the", "1970s", "by", "Roger", "Schank", "and", "Yorick", "Wilks", ";", "the", "former", "became", "the", "basis", "of", "a", "commercial", "system", "for", "money", "transfer", ",", "and", "the", "code", "for", "the", "latter", "is", "preserved", "in", "the", "Computer", "Museum", "in", "Boston", "as", "the", "first", "interlingual", "machine", "translation", "system", "."], "sentence-detokenized": "The first interlingual MT systems were also built at Stanford in the 1970s by Roger Schank and Yorick Wilks; the former became the basis of a commercial system for money transfer, and the code for the latter is preserved in the Computer Museum in Boston as the first interlingual machine translation system.", "token2charspan": [[0, 3], [4, 9], [10, 22], [23, 25], [26, 33], [34, 38], [39, 43], [44, 49], [50, 52], [53, 61], [62, 64], [65, 68], [69, 74], [75, 77], [78, 83], [84, 90], [91, 94], [95, 101], [102, 107], [107, 108], [109, 112], [113, 119], [120, 126], [127, 130], [131, 136], [137, 139], [140, 141], [142, 152], [153, 159], [160, 163], [164, 169], [170, 178], [178, 179], [180, 183], [184, 187], [188, 192], [193, 196], [197, 200], [201, 207], [208, 210], [211, 220], [221, 223], [224, 227], [228, 236], [237, 243], [244, 246], [247, 253], [254, 256], [257, 260], [261, 266], [267, 279], [280, 287], [288, 299], [300, 306], [306, 307]]}
{"doc_key": "ai-dev-203", "ner": [[0, 1, "researcher"], [7, 11, "conference"], [13, 14, "conference"], [21, 26, "conference"], [28, 29, "conference"], [35, 40, "organisation"], [49, 49, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 7, 11, "role", "", false, false], [0, 1, 21, 26, "role", "", false, false], [0, 1, 35, 40, "role", "", false, false], [0, 1, 49, 49, "role", "", false, false], [13, 14, 7, 11, "named", "", false, false], [28, 29, 21, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Mr.", "Sycara", "was", "Program", "Chair", "of", "the", "Second", "International", "Semantic", "Web", "Conference", "(", "ISWC", "2003", ")", ",", "General", "Chair", "of", "the", "Second", "International", "Conference", "on", "Autonomous", "Agents", "(", "Agents", "98", ")", ",", "Chair", "of", "the", "Steering", "Committee", "of", "the", "Agents", "Conference", "(", "1999-2001", ")", ",", "and", "Chair", "of", "the", "AAAI", "Scholarship", "Committee", "(", "1993-1999", ")", ";"], "sentence-detokenized": "Mr. Sycara was Program Chair of the Second International Semantic Web Conference (ISWC 2003), General Chair of the Second International Conference on Autonomous Agents (Agents 98), Chair of the Steering Committee of the Agents Conference (1999-2001), and Chair of the AAAI Scholarship Committee (1993-1999);", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 22], [23, 28], [29, 31], [32, 35], [36, 42], [43, 56], [57, 65], [66, 69], [70, 80], [81, 82], [82, 86], [87, 91], [91, 92], [92, 93], [94, 101], [102, 107], [108, 110], [111, 114], [115, 121], [122, 135], [136, 146], [147, 149], [150, 160], [161, 167], [168, 169], [169, 175], [176, 178], [178, 179], [179, 180], [181, 186], [187, 189], [190, 193], [194, 202], [203, 212], [213, 215], [216, 219], [220, 226], [227, 237], [238, 239], [239, 248], [248, 249], [249, 250], [251, 254], [255, 260], [261, 263], [264, 267], [268, 272], [273, 284], [285, 294], [295, 296], [296, 305], [305, 306], [306, 307]]}
{"doc_key": "ai-dev-204", "ner": [[21, 21, "conference"], [16, 19, "conference"], [11, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 19, 21, 21, "named", "", false, false], [11, 14, 21, 21, "part-of", "", false, false], [11, 14, 21, 21, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2016", ",", "she", "was", "selected", "as", "the", "recipient", "of", "the", "Lifetime", "Achievement", "Award", "of", "the", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "In 2016, she was selected as the recipient of the Lifetime Achievement Award of the Association for Computational Linguistics (ACL).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 25], [26, 28], [29, 32], [33, 42], [43, 45], [46, 49], [50, 58], [59, 70], [71, 76], [77, 79], [80, 83], [84, 95], [96, 99], [100, 113], [114, 125], [126, 127], [127, 130], [130, 131], [131, 132]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 8, "researcher"], [11, 12, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P.", "Frasconi", ",", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi, and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 30], [31, 39], [39, 40], [41, 44], [45, 51], [52, 63], [63, 64]]}
{"doc_key": "ai-dev-206", "ner": [[3, 3, "product"], [6, 7, "misc"], [9, 9, "programlang"], [19, 20, "product"], [32, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 9, 9, "usage", "", false, false], [9, 9, 6, 7, "type-of", "", false, false], [9, 9, 19, 20, "related-to", "", false, false], [32, 32, 3, 3, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["For", "example", ",", "A.L.I.C.E.", "uses", "a", "markup", "language", "called", "AIML", ",", "which", "is", "specific", "to", "its", "function", "as", "a", "dialogue", "system", ",", "and", "which", "has", "since", "been", "adopted", "by", "various", "other", "\"", "Alicebots", "\"", "developers", "."], "sentence-detokenized": "For example, A.L.I.C.E. uses a markup language called AIML, which is specific to its function as a dialogue system, and which has since been adopted by various other \"Alicebots\" developers.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 23], [24, 28], [29, 30], [31, 37], [38, 46], [47, 53], [54, 58], [58, 59], [60, 65], [66, 68], [69, 77], [78, 80], [81, 84], [85, 93], [94, 96], [97, 98], [99, 107], [108, 114], [114, 115], [116, 119], [120, 125], [126, 129], [130, 135], [136, 140], [141, 148], [149, 151], [152, 159], [160, 165], [166, 167], [167, 176], [176, 177], [178, 188], [188, 189]]}
{"doc_key": "ai-dev-207", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2000", ",", "she", "was", "elected", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2000, she was elected a member of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 24], [25, 26], [27, 33], [34, 36], [37, 40], [41, 52], [53, 56], [57, 60], [61, 72], [73, 75], [76, 86], [87, 99], [99, 100]]}
{"doc_key": "ai-dev-208", "ner": [[0, 2, "misc"], [4, 4, "misc"], [10, 15, "misc"], [24, 25, "algorithm"], [34, 35, "field"], [37, 38, "field"], [40, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 10, 15, "type-of", "", false, false], [0, 2, 34, 35, "related-to", "performs", true, false], [0, 2, 37, 38, "related-to", "performs", true, false], [0, 2, 40, 41, "related-to", "performs", true, false], [4, 4, 0, 2, "named", "", false, false], [24, 25, 10, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Learning", "classification", "systems", "(", "LCS", ")", "are", "a", "family", "of", "rule", "-", "based", "machine", "learning", "algorithms", "that", "combine", "a", "discovery", "component", ",", "usually", "a", "genetic", "algorithm", ",", "with", "a", "learning", "component", ",", "performing", "either", "supervised", "learning", ",", "reinforcement", "learning", "or", "unsupervised", "learning", "."], "sentence-detokenized": "Learning classification systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, usually a genetic algorithm, with a learning component, performing either supervised learning, reinforcement learning or unsupervised learning.", "token2charspan": [[0, 8], [9, 23], [24, 31], [32, 33], [33, 36], [36, 37], [38, 41], [42, 43], [44, 50], [51, 53], [54, 58], [58, 59], [59, 64], [65, 72], [73, 81], [82, 92], [93, 97], [98, 105], [106, 107], [108, 117], [118, 127], [127, 128], [129, 136], [137, 138], [139, 146], [147, 156], [156, 157], [158, 162], [163, 164], [165, 173], [174, 183], [183, 184], [185, 195], [196, 202], [203, 213], [214, 222], [222, 223], [224, 237], [238, 246], [247, 249], [250, 262], [263, 271], [271, 272]]}
{"doc_key": "ai-dev-209", "ner": [[14, 16, "algorithm"], [19, 19, "algorithm"], [27, 28, "algorithm"], [31, 32, "misc"], [42, 44, "algorithm"], [52, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 16, 27, 28, "origin", "", false, false], [14, 16, 31, 32, "usage", "", false, false], [19, 19, 14, 16, "named", "", false, false], [42, 44, 31, 32, "type-of", "", false, false], [42, 44, 52, 55, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "unknown", "parameters", "of", "each", "\u03b2subk", "/", "sub", "vector", "are", "usually", "jointly", "estimated", "by", "maximum", "a", "posteriori", "estimation", "(", "MAP", ")", ",", "which", "is", "an", "extension", "of", "maximum", "likelihood", "using", "a", "regularisation", "of", "the", "weights", "to", "avoid", "pathological", "solutions", "(", "usually", "a", "squared", "regularisation", "function", ",", "which", "is", "equivalent", "to", "placing", "a", "zero-mean", "Gaussian", "prior", "distribution", "on", "the", "weights", ",", "but", "other", "distributions", "are", "also", "possible", ")", "."], "sentence-detokenized": "The unknown parameters of each \u03b2subk / sub vector are usually jointly estimated by maximum a posteriori estimation (MAP), which is an extension of maximum likelihood using a regularisation of the weights to avoid pathological solutions (usually a squared regularisation function, which is equivalent to placing a zero-mean Gaussian prior distribution on the weights, but other distributions are also possible).", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 30], [31, 36], [37, 38], [39, 42], [43, 49], [50, 53], [54, 61], [62, 69], [70, 79], [80, 82], [83, 90], [91, 92], [93, 103], [104, 114], [115, 116], [116, 119], [119, 120], [120, 121], [122, 127], [128, 130], [131, 133], [134, 143], [144, 146], [147, 154], [155, 165], [166, 171], [172, 173], [174, 188], [189, 191], [192, 195], [196, 203], [204, 206], [207, 212], [213, 225], [226, 235], [236, 237], [237, 244], [245, 246], [247, 254], [255, 269], [270, 278], [278, 279], [280, 285], [286, 288], [289, 299], [300, 302], [303, 310], [311, 312], [313, 322], [323, 331], [332, 337], [338, 350], [351, 353], [354, 357], [358, 365], [365, 366], [367, 370], [371, 376], [377, 390], [391, 394], [395, 399], [400, 408], [408, 409], [409, 410]]}
{"doc_key": "ai-dev-210", "ner": [[10, 11, "researcher"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 13, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "hierarchical", "structure", "of", "words", "has", "been", "explicitly", "mapped", "in", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "The hierarchical structure of words has been explicitly mapped in George Miller's Wordnet.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 29], [30, 35], [36, 39], [40, 44], [45, 55], [56, 62], [63, 65], [66, 72], [73, 79], [79, 81], [82, 89], [89, 90]]}
{"doc_key": "ai-dev-211", "ner": [[7, 16, "conference"], [20, 23, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 23, 7, 16, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "example", "of", "their", "capabilities", "is", "the", "ImageNet", "large", "-", "scale", "visual", "recognition", "challenge", ",", "which", "is", "a", "benchmark", "in", "object", "classification", "and", "detection", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "An example of their capabilities is the ImageNet large-scale visual recognition challenge, which is a benchmark in object classification and detection, with millions of images and hundreds of object classes.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 19], [20, 32], [33, 35], [36, 39], [40, 48], [49, 54], [54, 55], [55, 60], [61, 67], [68, 79], [80, 89], [89, 90], [91, 96], [97, 99], [100, 101], [102, 111], [112, 114], [115, 121], [122, 136], [137, 140], [141, 150], [150, 151], [152, 156], [157, 165], [166, 168], [169, 175], [176, 179], [180, 188], [189, 191], [192, 198], [199, 206], [206, 207]]}
{"doc_key": "ai-dev-212", "ner": [[1, 2, "misc"], [23, 23, "misc"], [25, 27, "person"], [30, 30, "misc"], [35, 37, "person"], [41, 43, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[23, 23, 1, 2, "general-affiliation", "", false, false], [30, 30, 1, 2, "general-affiliation", "", false, false], [30, 30, 25, 27, "artifact", "", false, false], [41, 43, 1, 2, "general-affiliation", "", false, false], [41, 43, 35, 37, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "science", "fiction", ",", "female", "-", "looking", "robots", "are", "often", "produced", "to", "serve", "as", "servants", "and", "sex", "slaves", ",", "as", "in", "the", "film", "Westworld", ",", "Paul", "J.", "McAuley", "'s", "novel", "Fairyland", "(", "1995", ")", "and", "Lester", "del", "Rey", "'s", "short", "story", "Helen", "O'", "Loy", "(", "1938", ")", ",", "and", "sometimes", "as", "warriors", ",", "killers", "or", "labourers", "."], "sentence-detokenized": "In science fiction, female-looking robots are often produced to serve as servants and sex slaves, as in the film Westworld, Paul J. McAuley's novel Fairyland (1995) and Lester del Rey's short story Helen O'Loy (1938), and sometimes as warriors, killers or labourers.", "token2charspan": [[0, 2], [3, 10], [11, 18], [18, 19], [20, 26], [26, 27], [27, 34], [35, 41], [42, 45], [46, 51], [52, 60], [61, 63], [64, 69], [70, 72], [73, 81], [82, 85], [86, 89], [90, 96], [96, 97], [98, 100], [101, 103], [104, 107], [108, 112], [113, 122], [122, 123], [124, 128], [129, 131], [132, 139], [139, 141], [142, 147], [148, 157], [158, 159], [159, 163], [163, 164], [165, 168], [169, 175], [176, 179], [180, 183], [183, 185], [186, 191], [192, 197], [198, 203], [204, 206], [206, 209], [210, 211], [211, 215], [215, 216], [216, 217], [218, 221], [222, 231], [232, 234], [235, 243], [243, 244], [245, 252], [253, 255], [256, 265], [265, 266]]}
{"doc_key": "ai-dev-213", "ner": [[0, 1, "task"], [3, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["question", "answering", ",", "speech", "recognition", "and", "machine", "translation", "."], "sentence-detokenized": "question answering, speech recognition and machine translation.", "token2charspan": [[0, 8], [9, 18], [18, 19], [20, 26], [27, 38], [39, 42], [43, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-214", "ner": [[5, 6, "researcher"], [9, 13, "organisation"], [15, 18, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 9, 13, "role", "", false, false], [9, 13, 15, 18, "physical", "", false, false], [15, 18, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "seminal", "paper", ",", "Harry", "Blum", "of", "the", "Air", "Force", "Cambridge", "Research", "Laboratories", "at", "Hanscom", "Air", "Force", "Base", ",", "Bedford", ",", "Massachusetts", ",", "defined", "a", "median", "axis", "for", "calculating", "the", "skeleton", "of", "a", "shape", ",", "using", "an", "intuitive", "model", "of", "fire", "spread", "over", "a", "field", "of", "grass", ",", "where", "the", "field", "has", "the", "shape", "of", "the", "given", "shape", "."], "sentence-detokenized": "In his seminal paper, Harry Blum of the Air Force Cambridge Research Laboratories at Hanscom Air Force Base, Bedford, Massachusetts, defined a median axis for calculating the skeleton of a shape, using an intuitive model of fire spread over a field of grass, where the field has the shape of the given shape.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 20], [20, 21], [22, 27], [28, 32], [33, 35], [36, 39], [40, 43], [44, 49], [50, 59], [60, 68], [69, 81], [82, 84], [85, 92], [93, 96], [97, 102], [103, 107], [107, 108], [109, 116], [116, 117], [118, 131], [131, 132], [133, 140], [141, 142], [143, 149], [150, 154], [155, 158], [159, 170], [171, 174], [175, 183], [184, 186], [187, 188], [189, 194], [194, 195], [196, 201], [202, 204], [205, 214], [215, 220], [221, 223], [224, 228], [229, 235], [236, 240], [241, 242], [243, 248], [249, 251], [252, 257], [257, 258], [259, 264], [265, 268], [269, 274], [275, 278], [279, 282], [283, 288], [289, 291], [292, 295], [296, 301], [302, 307], [307, 308]]}
{"doc_key": "ai-dev-215", "ner": [[14, 14, "algorithm"], [16, 16, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 19, 20, "compare", "", false, false], [16, 16, 19, 20, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "unlike", "boosting", "algorithms", "that", "analytically", "minimize", "a", "convex", "loss", "function", "(", "e.g.", "AdaBoost", "and", "LogitBoost", ")", ",", "Brown", "Boost", "solves", "a", "system", "of", "two", "equations", "and", "two", "unknowns", "using", "standard", "numerical", "methods", "."], "sentence-detokenized": "However, unlike boosting algorithms that analytically minimize a convex loss function (e.g. AdaBoost and LogitBoost), BrownBoost solves a system of two equations and two unknowns using standard numerical methods.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 24], [25, 35], [36, 40], [41, 53], [54, 62], [63, 64], [65, 71], [72, 76], [77, 85], [86, 87], [87, 91], [92, 100], [101, 104], [105, 115], [115, 116], [116, 117], [118, 123], [123, 128], [129, 135], [136, 137], [138, 144], [145, 147], [148, 151], [152, 161], [162, 165], [166, 169], [170, 178], [179, 184], [185, 193], [194, 203], [204, 211], [211, 212]]}
{"doc_key": "ai-dev-216", "ner": [[0, 0, "researcher"], [9, 11, "misc"], [18, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 9, 11, "win-defeat", "", false, false], [0, 0, 18, 24, "role", "", false, false], [26, 26, 18, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getoor", "has", "received", "several", "best", "paper", "awards", ",", "an", "NSF", "career", "award", "and", "is", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Getoor has received several best paper awards, an NSF career award and is a member of the Association for the Advancement of Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 27], [28, 32], [33, 38], [39, 45], [45, 46], [47, 49], [50, 53], [54, 60], [61, 66], [67, 70], [71, 73], [74, 75], [76, 82], [83, 85], [86, 89], [90, 101], [102, 105], [106, 109], [110, 121], [122, 124], [125, 135], [136, 148], [149, 150], [150, 154], [154, 155], [155, 156]]}
{"doc_key": "ai-dev-217", "ner": [[0, 1, "misc"], [6, 10, "misc"], [15, 16, "misc"], [21, 25, "misc"], [30, 31, "misc"], [35, 39, "university"], [44, 52, "misc"], [57, 65, "misc"], [70, 74, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACM", "Fellow", "(", "2015", ")", "br", "Association", "for", "Computational", "Linguistics", "Fellow", "(", "2011", ")", "br", "AAAI", "Fellow", "(", "1994", ")", "br", "International", "Speech", "Communication", "Association", "Fellow", "(", "2011", ")", "br", "Honorary", "Doctorate", "(", "Hedersdoktor", ")", "KTH", "Royal", "Institute", "of", "Technology", "(", "2007", ")", "br", "Columbia", "Engineering", "School", "Alumni", "Association", "Distinguished", "Faculty", "Teaching", "award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Speech", "and", "Audio", "Processing", "Award", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")"], "sentence-detokenized": "ACM Fellow (2015) br Association for Computational Linguistics Fellow (2011) br AAAI Fellow (1994) br International Speech Communication Association Fellow (2011) br Honorary Doctorate (Hedersdoktor) KTH Royal Institute of Technology (2007) br Columbia Engineering School Alumni Association Distinguished Faculty Teaching award (2009) br IEEE James L. Flanagan Speech and Audio Processing Award (2011) br ISCA Medal for Scientific Achievement (2011)", "token2charspan": [[0, 3], [4, 10], [11, 12], [12, 16], [16, 17], [18, 20], [21, 32], [33, 36], [37, 50], [51, 62], [63, 69], [70, 71], [71, 75], [75, 76], [77, 79], [80, 84], [85, 91], [92, 93], [93, 97], [97, 98], [99, 101], [102, 115], [116, 122], [123, 136], [137, 148], [149, 155], [156, 157], [157, 161], [161, 162], [163, 165], [166, 174], [175, 184], [185, 186], [186, 198], [198, 199], [200, 203], [204, 209], [210, 219], [220, 222], [223, 233], [234, 235], [235, 239], [239, 240], [241, 243], [244, 252], [253, 264], [265, 271], [272, 278], [279, 290], [291, 304], [305, 312], [313, 321], [322, 327], [328, 329], [329, 333], [333, 334], [335, 337], [338, 342], [343, 348], [349, 351], [352, 360], [361, 367], [368, 371], [372, 377], [378, 388], [389, 394], [395, 396], [396, 400], [400, 401], [402, 404], [405, 409], [410, 415], [416, 419], [420, 430], [431, 442], [443, 444], [444, 448], [448, 449]]}
{"doc_key": "ai-dev-218", "ner": [[6, 6, "university"], [14, 16, "task"], [28, 30, "metrics"], [39, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[28, 30, 39, 41, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["A", "frustrating", "result", "of", "the", "same", "Stanford", "study", "(", "and", "other", "attempts", "to", "improve", "name", "recognition", "translation", ")", "is", "that", ",", "in", "many", "cases", ",", "a", "decrease", "in", "bilingual", "evaluation", "doubling", "scores", "for", "translation", "results", "from", "the", "inclusion", "of", "named", "entity", "translation", "methods", "."], "sentence-detokenized": "A frustrating result of the same Stanford study (and other attempts to improve name recognition translation) is that, in many cases, a decrease in bilingual evaluation doubling scores for translation results from the inclusion of named entity translation methods.", "token2charspan": [[0, 1], [2, 13], [14, 20], [21, 23], [24, 27], [28, 32], [33, 41], [42, 47], [48, 49], [49, 52], [53, 58], [59, 67], [68, 70], [71, 78], [79, 83], [84, 95], [96, 107], [107, 108], [109, 111], [112, 116], [116, 117], [118, 120], [121, 125], [126, 131], [131, 132], [133, 134], [135, 143], [144, 146], [147, 156], [157, 167], [168, 176], [177, 183], [184, 187], [188, 199], [200, 207], [208, 212], [213, 216], [217, 226], [227, 229], [230, 235], [236, 242], [243, 254], [255, 262], [262, 263]]}
{"doc_key": "ai-dev-219", "ner": [[0, 1, "organisation"], [12, 14, "organisation"], [17, 23, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 12, 14, "role", "works_with", false, false], [0, 1, 17, 23, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "is", "using", "the", "collected", "PM", "data", "and", "collaborating", "with", "researchers", "at", "Johns", "Hopkins", "Hospital", "and", "the", "University", "of", "Washington", "School", "of", "Medicine", "to", "help", "answer", "specific", "questions", "about", "heart", "disease", ",", "such", "as", "whether", "a", "weak", "heart", "causes", "arrhythmias", "or", "vice", "versa", "."], "sentence-detokenized": "Medtronic is using the collected PM data and collaborating with researchers at Johns Hopkins Hospital and the University of Washington School of Medicine to help answer specific questions about heart disease, such as whether a weak heart causes arrhythmias or vice versa.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 22], [23, 32], [33, 35], [36, 40], [41, 44], [45, 58], [59, 63], [64, 75], [76, 78], [79, 84], [85, 92], [93, 101], [102, 105], [106, 109], [110, 120], [121, 123], [124, 134], [135, 141], [142, 144], [145, 153], [154, 156], [157, 161], [162, 168], [169, 177], [178, 187], [188, 193], [194, 199], [200, 207], [207, 208], [209, 213], [214, 216], [217, 224], [225, 226], [227, 231], [232, 237], [238, 244], [245, 256], [257, 259], [260, 264], [265, 270], [270, 271]]}
{"doc_key": "ai-dev-220", "ner": [[1, 1, "organisation"], [6, 6, "misc"], [9, 10, "person"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 1, 1, "artifact", "made_by_studio", false, false], [9, 10, 6, 6, "role", "", false, false], [12, 13, 6, 6, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Then", "Paramount", "'s", "first", "film", ",", "Sangaree", ",", "with", "Fernando", "Lamas", "and", "Arlene", "Dahl", "."], "sentence-detokenized": "Then Paramount's first film, Sangaree, with Fernando Lamas and Arlene Dahl.", "token2charspan": [[0, 4], [5, 14], [14, 16], [17, 22], [23, 27], [27, 28], [29, 37], [37, 38], [39, 43], [44, 52], [53, 58], [59, 62], [63, 69], [70, 74], [74, 75]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [8, 10, "researcher"], [12, 13, "researcher"], [17, 18, "organisation"], [20, 21, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 10, "origin", "", false, false], [0, 0, 12, 13, "origin", "", false, false], [8, 10, 17, 18, "physical", "", false, false], [8, 10, 17, 18, "role", "", false, false], [12, 13, 20, 21, "physical", "", false, false], [12, 13, 20, 21, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "is", "a", "knowledge", "representation", "language", "developed", "by", "Daniel", "G.", "Bobrow", "and", "Terry", "Winograd", "while", "working", "at", "Xerox", "PARC", "and", "Stanford", "University", "respectively", "."], "sentence-detokenized": "KRL is a knowledge representation language developed by Daniel G. Bobrow and Terry Winograd while working at Xerox PARC and Stanford University respectively.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 18], [19, 33], [34, 42], [43, 52], [53, 55], [56, 62], [63, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 97], [98, 105], [106, 108], [109, 114], [115, 119], [120, 123], [124, 132], [133, 143], [144, 156], [156, 157]]}
{"doc_key": "ai-dev-222", "ner": [[3, 10, "conference"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 24, "researcher"], [31, 32, "task"], [34, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 10, 31, 32, "topic", "", true, false], [12, 13, 3, 10, "physical", "", false, false], [12, 13, 3, 10, "role", "", false, false], [12, 13, 3, 10, "temporal", "", false, false], [15, 16, 3, 10, "physical", "", false, false], [15, 16, 3, 10, "role", "", false, false], [15, 16, 3, 10, "temporal", "", false, false], [18, 19, 3, 10, "physical", "", false, false], [18, 19, 3, 10, "role", "", false, false], [18, 19, 3, 10, "temporal", "", false, false], [21, 24, 3, 10, "physical", "", false, false], [21, 24, 3, 10, "role", "", false, false], [21, 24, 3, 10, "temporal", "", false, false], [31, 32, 34, 36, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["At", "the", "2006", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", "and", "Kwang", "-", "Ting", "Cheng", "presented", "an", "algorithm", "for", "significantly", "accelerating", "human", "detection", "using", "HOG", "descriptor", "methods", "."], "sentence-detokenized": "At the 2006 IEEE Conference on Computer Vision and Pattern Recognition, Qiang Zhu, Shai Avidan, Mei-Chen Yeh and Kwang-Ting Cheng presented an algorithm for significantly accelerating human detection using HOG descriptor methods.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 27], [28, 30], [31, 39], [40, 46], [47, 50], [51, 58], [59, 70], [70, 71], [72, 77], [78, 81], [81, 82], [83, 87], [88, 94], [94, 95], [96, 104], [105, 108], [109, 112], [113, 118], [118, 119], [119, 123], [124, 129], [130, 139], [140, 142], [143, 152], [153, 156], [157, 170], [171, 183], [184, 189], [190, 199], [200, 205], [206, 209], [210, 220], [221, 228], [228, 229]]}
{"doc_key": "ai-dev-223", "ner": [[0, 1, "researcher"], [8, 8, "conference"], [11, 13, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 8, 8, "role", "", false, false], [0, 1, 11, 13, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mr", "Hayes", "is", "a", "founding", "member", "of", "the", "AAAI", "and", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Mr Hayes is a founding member of the AAAI and the Cognitive Science Society.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 13], [14, 22], [23, 29], [30, 32], [33, 36], [37, 41], [42, 45], [46, 49], [50, 59], [60, 67], [68, 75], [75, 76]]}
{"doc_key": "ai-dev-224", "ner": [[0, 1, "misc"], [5, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 35, "field"], [42, 43, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 1, 5, 5, "part-of", "", false, false], [0, 1, 5, 5, "usage", "", false, false], [0, 1, 7, 8, "part-of", "", false, false], [0, 1, 7, 8, "usage", "", false, false], [0, 1, 10, 11, "part-of", "", false, false], [0, 1, 10, 11, "usage", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [0, 1, 13, 13, "usage", "", false, false], [0, 1, 15, 16, "part-of", "", false, false], [0, 1, 15, 16, "usage", "", false, false], [0, 1, 18, 19, "part-of", "", false, false], [0, 1, 18, 19, "usage", "", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 21, 22, "usage", "", false, false], [0, 1, 24, 24, "part-of", "", false, false], [0, 1, 24, 24, "usage", "", false, false], [0, 1, 26, 27, "part-of", "", false, false], [0, 1, 26, 27, "usage", "", false, false], [0, 1, 29, 29, "part-of", "", false, false], [0, 1, 29, 29, "usage", "", false, false], [0, 1, 31, 35, "part-of", "", false, false], [0, 1, 31, 35, "usage", "", false, false], [0, 1, 42, 43, "part-of", "", false, false], [0, 1, 42, 43, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", "and", ",", "in", "general", ",", "in", "all", "fields", "of", "applied", "science", "and", "engineering", "that", "involve", "time", "measurements", "."], "sentence-detokenized": "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering and, in general, in all fields of applied science and engineering that involve time measurements.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 23], [24, 34], [34, 35], [36, 42], [43, 53], [53, 54], [55, 62], [63, 74], [74, 75], [76, 88], [88, 89], [90, 102], [103, 110], [110, 111], [112, 119], [120, 131], [131, 132], [133, 143], [144, 154], [154, 155], [156, 178], [178, 179], [180, 187], [188, 199], [199, 200], [201, 210], [210, 211], [212, 226], [227, 238], [239, 242], [242, 243], [244, 246], [247, 254], [254, 255], [256, 258], [259, 262], [263, 269], [270, 272], [273, 280], [281, 288], [289, 292], [293, 304], [305, 309], [310, 317], [318, 322], [323, 335], [335, 336]]}
{"doc_key": "ai-dev-225", "ner": [[13, 14, "metrics"], [34, 36, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "principle", ",", "exact", "recovery", "can", "be", "solved", "in", "its", "feasibility", "domain", "using", "maximum", "likelihood", ",", "but", "this", "amounts", "to", "solving", "a", "constrained", "or", "regularised", "cutting", "problem", "such", "as", "minimal", "bisection", "which", "is", "typically", "NP", "-", "complete", "."], "sentence-detokenized": "In principle, exact recovery can be solved in its feasibility domain using maximum likelihood, but this amounts to solving a constrained or regularised cutting problem such as minimal bisection which is typically NP-complete.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 19], [20, 28], [29, 32], [33, 35], [36, 42], [43, 45], [46, 49], [50, 61], [62, 68], [69, 74], [75, 82], [83, 93], [93, 94], [95, 98], [99, 103], [104, 111], [112, 114], [115, 122], [123, 124], [125, 136], [137, 139], [140, 151], [152, 159], [160, 167], [168, 172], [173, 175], [176, 183], [184, 193], [194, 199], [200, 202], [203, 212], [213, 215], [215, 216], [216, 224], [224, 225]]}
{"doc_key": "ai-dev-226", "ner": [[2, 3, "task"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 2, 3, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["in", "their", "pedestrian", "detection", "work", ",", "which", "was", "first", "described", "at", "the", "BMVC", "in", "2009", "."], "sentence-detokenized": "in their pedestrian detection work, which was first described at the BMVC in 2009.", "token2charspan": [[0, 2], [3, 8], [9, 19], [20, 29], [30, 34], [34, 35], [36, 41], [42, 45], [46, 51], [52, 61], [62, 64], [65, 68], [69, 73], [74, 76], [77, 81], [81, 82]]}
{"doc_key": "ai-dev-227", "ner": [[5, 9, "conference"], [11, 12, "researcher"], [15, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 5, 9, "physical", "", false, false], [11, 12, 5, 9, "role", "", false, false], [11, 12, 15, 22, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2007", ",", "at", "the", "International", "Conference", "on", "Computer", "Vision", ",", "Dr.", "Terzopoulos", "received", "the", "first", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "for", "his", "pioneering", "and", "sustained", "research", "on", "deformable", "models", "and", "their", "applications", "."], "sentence-detokenized": "In 2007, at the International Conference on Computer Vision, Dr. Terzopoulos received the first IEEE PAMI Computer Vision Distinguished Researcher Award for his pioneering and sustained research on deformable models and their applications.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 40], [41, 43], [44, 52], [53, 59], [59, 60], [61, 64], [65, 76], [77, 85], [86, 89], [90, 95], [96, 100], [101, 105], [106, 114], [115, 121], [122, 135], [136, 146], [147, 152], [153, 156], [157, 160], [161, 171], [172, 175], [176, 185], [186, 194], [195, 197], [198, 208], [209, 215], [216, 219], [220, 225], [226, 238], [238, 239]]}
{"doc_key": "ai-dev-228", "ner": [[0, 0, "task"], [1, 1, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 1, 1, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cluster", "analysis", "involves", "assigning", "data", "points", "to", "clusters", "so", "that", "items", "in", "the", "same", "cluster", "are", "as", "similar", "as", "possible", ",", "while", "items", "in", "different", "clusters", "are", "as", "dissimilar", "as", "possible", "."], "sentence-detokenized": "Cluster analysis involves assigning data points to clusters so that items in the same cluster are as similar as possible, while items in different clusters are as dissimilar as possible.", "token2charspan": [[0, 7], [8, 16], [17, 25], [26, 35], [36, 40], [41, 47], [48, 50], [51, 59], [60, 62], [63, 67], [68, 73], [74, 76], [77, 80], [81, 85], [86, 93], [94, 97], [98, 100], [101, 108], [109, 111], [112, 120], [120, 121], [122, 127], [128, 133], [134, 136], [137, 146], [147, 155], [156, 159], [160, 162], [163, 173], [174, 176], [177, 185], [185, 186]]}
{"doc_key": "ai-dev-229", "ner": [[11, 12, "field"], [15, 16, "field"], [18, 19, "task"], [21, 22, "field"], [25, 26, "field"], [29, 30, "field"], [33, 34, "field"], [37, 38, "task"], [40, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[11, 12, 15, 16, "named", "", false, false], [11, 12, 21, 22, "named", "", false, false], [11, 12, 29, 30, "named", "", false, false], [18, 19, 15, 16, "part-of", "task_part_of_field", false, false], [25, 26, 21, 22, "part-of", "", false, false], [33, 34, 29, 30, "part-of", "", false, false], [37, 38, 33, 34, "part-of", "", false, false], [40, 40, 33, 34, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["(", "2005", ")", ",", "we", "can", "distinguish", "three", "different", "perspectives", "of", "text", "mining", ",", "namely", "text", "mining", "as", "information", "extraction", ",", "text", "mining", "as", "text", "data", "mining", ",", "and", "text", "mining", "as", "a", "data", "mining", "process", "(", "knowledge", "discovery", "in", "databases", ")", ".", "Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005), we can distinguish three different perspectives of text mining, namely text mining as information extraction, text mining as text data mining, and text mining as a data mining process (knowledge discovery in databases).Hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [6, 7], [8, 10], [11, 14], [15, 26], [27, 32], [33, 42], [43, 55], [56, 58], [59, 63], [64, 70], [70, 71], [72, 78], [79, 83], [84, 90], [91, 93], [94, 105], [106, 116], [116, 117], [118, 122], [123, 129], [130, 132], [133, 137], [138, 142], [143, 149], [149, 150], [151, 154], [155, 159], [160, 166], [167, 169], [170, 171], [172, 176], [177, 183], [184, 191], [192, 193], [193, 202], [203, 212], [213, 215], [216, 225], [225, 226], [226, 227], [227, 232], [232, 233], [234, 236], [236, 237], [238, 248], [248, 249], [250, 252], [253, 256], [257, 261], [261, 262], [263, 265], [266, 267], [267, 271], [271, 272], [272, 273]]}
{"doc_key": "ai-dev-230", "ner": [[1, 2, "product"], [15, 20, "location"], [22, 22, "location"], [24, 24, "location"], [34, 35, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 15, 20, "related-to", "developed_for", false, false], [15, 20, 22, 22, "physical", "", false, false], [22, 22, 24, 24, "physical", "", false, false], [34, 35, 1, 2, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Rancho", "Arm", "was", "developed", "as", "a", "robotic", "arm", "to", "assist", "disabled", "patients", "at", "the", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Center", "in", "Downey", ",", "California", ";", "this", "computer", "-", "controlled", "arm", "was", "purchased", "by", "Stanford", "University", "in", "1963", "."], "sentence-detokenized": "The Rancho Arm was developed as a robotic arm to assist disabled patients at the Rancho Los Amigos National Rehabilitation Center in Downey, California; this computer-controlled arm was purchased by Stanford University in 1963.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 18], [19, 28], [29, 31], [32, 33], [34, 41], [42, 45], [46, 48], [49, 55], [56, 64], [65, 73], [74, 76], [77, 80], [81, 87], [88, 91], [92, 98], [99, 107], [108, 122], [123, 129], [130, 132], [133, 139], [139, 140], [141, 151], [151, 152], [153, 157], [158, 166], [166, 167], [167, 177], [178, 181], [182, 185], [186, 195], [196, 198], [199, 207], [208, 218], [219, 221], [222, 226], [226, 227]]}
{"doc_key": "ai-dev-231", "ner": [[1, 1, "university"], [3, 3, "researcher"], [10, 14, "organisation"], [22, 24, "organisation"], [28, 29, "researcher"], [31, 33, "researcher"], [46, 46, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 1, 1, "physical", "", false, false], [3, 3, 1, 1, "role", "", false, false], [3, 3, 10, 14, "role", "founder", false, false], [3, 3, 22, 24, "role", "founder", false, false], [22, 24, 46, 46, "physical", "", false, false], [28, 29, 22, 24, "role", "founder", false, false], [31, 33, 22, 24, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["At", "UCSD", ",", "Norman", "was", "one", "of", "the", "founders", "of", "the", "Institute", "for", "Cognitive", "Science", "and", "one", "of", "the", "organizers", "of", "the", "Cognitive", "Science", "Society", "(", "along", "with", "Roger", "Schank", ",", "Allan", "M.", "Collins", "and", "others", ")", ",", "which", "held", "it", "s", "first", "meeting", "on", "the", "UCSD", "campus", "in", "1979", "."], "sentence-detokenized": "At UCSD, Norman was one of the founders of the Institute for Cognitive Science and one of the organizers of the Cognitive Science Society (along with Roger Schank, Allan M. Collins and others), which held its first meeting on the UCSD campus in 1979.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 23], [24, 26], [27, 30], [31, 39], [40, 42], [43, 46], [47, 56], [57, 60], [61, 70], [71, 78], [79, 82], [83, 86], [87, 89], [90, 93], [94, 104], [105, 107], [108, 111], [112, 121], [122, 129], [130, 137], [138, 139], [139, 144], [145, 149], [150, 155], [156, 162], [162, 163], [164, 169], [170, 172], [173, 180], [181, 184], [185, 191], [191, 192], [192, 193], [194, 199], [200, 204], [205, 207], [207, 208], [209, 214], [215, 222], [223, 225], [226, 229], [230, 234], [235, 241], [242, 244], [245, 249], [249, 250]]}
{"doc_key": "ai-dev-232", "ner": [[7, 8, "product"], [10, 11, "product"], [13, 14, "product"], [16, 18, "product"], [20, 21, "product"], [23, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 16, 18, "type-of", "", false, false], [23, 28, 16, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "commonly", "used", "robot", "configurations", "are", "articulated", "robots", ",", "SCARA", "robots", ",", "delta", "robots", "and", "Cartesian", "coordinate", "robots", "(", "gantry", "robots", "or", "x", "-", "y", "-", "z", "robots", ")", "."], "sentence-detokenized": "The most commonly used robot configurations are articulated robots, SCARA robots, delta robots and Cartesian coordinate robots (gantry robots or x-y-z robots).", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 28], [29, 43], [44, 47], [48, 59], [60, 66], [66, 67], [68, 73], [74, 80], [80, 81], [82, 87], [88, 94], [95, 98], [99, 108], [109, 119], [120, 126], [127, 128], [128, 134], [135, 141], [142, 144], [145, 146], [146, 147], [147, 148], [148, 149], [149, 150], [151, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-dev-233", "ner": [[8, 8, "programlang"], [9, 10, "misc"], [15, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 8, 8, "part-of", "", false, false], [15, 15, 9, 10, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "can", "also", "be", "used", "directly", "with", "the", "Perl", "TM", "module", "(", "which", "also", "supports", "LTM", ")", "."], "sentence-detokenized": "It can also be used directly with the Perl TM module (which also supports LTM).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 19], [20, 28], [29, 33], [34, 37], [38, 42], [43, 45], [46, 52], [53, 54], [54, 59], [60, 64], [65, 73], [74, 77], [77, 78], [78, 79]]}
{"doc_key": "ai-dev-234", "ner": [[9, 10, "organisation"], [15, 15, "organisation"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "competition", "was", "won", "by", "an", "American", "team", "from", "Newton", "Labs", "and", "was", "broadcast", "on", "CNN", "."], "sentence-detokenized": "The competition was won by an American team from Newton Labs and was broadcast on CNN.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 26], [27, 29], [30, 38], [39, 43], [44, 48], [49, 55], [56, 60], [61, 64], [65, 68], [69, 78], [79, 81], [82, 85], [85, 86]]}
{"doc_key": "ai-dev-235", "ner": [[0, 4, "misc"], [11, 12, "person"], [15, 16, "person"], [18, 21, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 0, 4, "role", "directs", false, false], [15, 16, 0, 4, "role", "acts_in", false, false], [18, 21, 0, 4, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Butler", "'s", "in", "Love", ",", "a", "short", "film", "directed", "by", "David", "Arquette", "and", "starring", "Elizabeth", "Berkley", "and", "Thomas", "Jane", ",", "was", "released", "on", "23", "June", "2008", "."], "sentence-detokenized": "The Butler's in Love, a short film directed by David Arquette and starring Elizabeth Berkley and Thomas Jane, was released on 23 June 2008.", "token2charspan": [[0, 3], [4, 10], [10, 12], [13, 15], [16, 20], [20, 21], [22, 23], [24, 29], [30, 34], [35, 43], [44, 46], [47, 52], [53, 61], [62, 65], [66, 74], [75, 84], [85, 92], [93, 96], [97, 103], [104, 108], [108, 109], [110, 113], [114, 122], [123, 125], [126, 128], [129, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-dev-236", "ner": [[3, 4, "product"], [10, 10, "field"], [20, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 20, 20, "general-affiliation", "", false, false], [10, 10, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "Word", "Net", "is", "a", "resource", "comprising", "a", "taxonomy", ",", "the", "elements", "of", "which", "are", "the", "meanings", "of", "English", "words", "."], "sentence-detokenized": "For example, WordNet is a resource comprising a taxonomy, the elements of which are the meanings of English words.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [17, 20], [21, 23], [24, 25], [26, 34], [35, 45], [46, 47], [48, 56], [56, 57], [58, 61], [62, 70], [71, 73], [74, 79], [80, 83], [84, 87], [88, 96], [97, 99], [100, 107], [108, 113], [113, 114]]}
{"doc_key": "ai-dev-237", "ner": [[1, 3, "product"], [7, 7, "product"], [9, 9, "product"], [15, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 1, 3, "type-of", "", false, false], [7, 7, 15, 15, "related-to", "ability_to", false, false], [9, 9, 1, 3, "type-of", "", false, false], [9, 9, 15, 15, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Existing", "humanoid", "robot", "systems", ",", "such", "as", "ASIMO", "and", "QRIO", ",", "use", "multiple", "motors", "for", "locomotion", "."], "sentence-detokenized": "Existing humanoid robot systems, such as ASIMO and QRIO, use multiple motors for locomotion.", "token2charspan": [[0, 8], [9, 17], [18, 23], [24, 31], [31, 32], [33, 37], [38, 40], [41, 46], [47, 50], [51, 55], [55, 56], [57, 60], [61, 69], [70, 76], [77, 80], [81, 91], [91, 92]]}
{"doc_key": "ai-dev-238", "ner": [[0, 0, "metrics"], [5, 9, "metrics"], [11, 11, "metrics"], [13, 17, "misc"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false], [13, 17, 0, 0, "part-of", "", false, false], [19, 19, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "is", "designed", "with", "the", "penalty", "factors", "of", "improved", "length", ",", "precision", ",", "n-", "gram", "word", "order", "penalty", "and", "recall", "."], "sentence-detokenized": "LEPOR is designed with the penalty factors of improved length, precision, n-gram word order penalty and recall.", "token2charspan": [[0, 5], [6, 8], [9, 17], [18, 22], [23, 26], [27, 34], [35, 42], [43, 45], [46, 54], [55, 61], [61, 62], [63, 72], [72, 73], [74, 76], [76, 80], [81, 85], [86, 91], [92, 99], [100, 103], [104, 110], [110, 111]]}
{"doc_key": "ai-dev-239", "ner": [[5, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "based", "on", "the", "bilingual", "evaluation", "metric", ",", "but", "with", "some", "modifications", "."], "sentence-detokenized": "It is based on the bilingual evaluation metric, but with some modifications.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 14], [15, 18], [19, 28], [29, 39], [40, 46], [46, 47], [48, 51], [52, 56], [57, 61], [62, 75], [75, 76]]}
{"doc_key": "ai-dev-240", "ner": [[8, 8, "product"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "of", "an", "implementation", "in", "MATLAB", "/", "Octave", ":"], "sentence-detokenized": "This is an example of an implementation in MATLAB / Octave :", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 24], [25, 39], [40, 42], [43, 49], [50, 51], [52, 58], [59, 60]]}
{"doc_key": "ai-dev-241", "ner": [[14, 14, "programlang"], [16, 16, "programlang"], [18, 18, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "designed", "to", "be", "used", "by", "a", "number", "of", "computer", "languages", ",", "including", "Python", ",", "Ruby", "and", "Scheme", "."], "sentence-detokenized": "It is designed to be used by a number of computer languages, including Python, Ruby and Scheme.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 20], [21, 25], [26, 28], [29, 30], [31, 37], [38, 40], [41, 49], [50, 59], [59, 60], [61, 70], [71, 77], [77, 78], [79, 83], [84, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-dev-242", "ner": [[0, 1, "researcher"], [8, 8, "organisation"], [15, 15, "conference"], [20, 21, "academicjournal"], [26, 28, "organisation"], [33, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 8, 8, "role", "", false, false], [0, 1, 15, 15, "role", "", false, false], [0, 1, 20, 21, "role", "", false, false], [0, 1, 26, 28, "role", "", false, false], [0, 1, 33, 37, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Dr", "Hayes", "has", "served", "as", "Secretary", "of", "the", "AISB", ",", "President", "and", "Trustee", "of", "the", "IJCAI", ",", "Associate", "Editor", "of", "Artificial", "Intelligence", ",", "Governor", "of", "the", "Cognitive", "Science", "Society", "and", "President", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Dr Hayes has served as Secretary of the AISB, President and Trustee of the IJCAI, Associate Editor of Artificial Intelligence, Governor of the Cognitive Science Society and President of the American Association for Artificial Intelligence.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 19], [20, 22], [23, 32], [33, 35], [36, 39], [40, 44], [44, 45], [46, 55], [56, 59], [60, 67], [68, 70], [71, 74], [75, 80], [80, 81], [82, 91], [92, 98], [99, 101], [102, 112], [113, 125], [125, 126], [127, 135], [136, 138], [139, 142], [143, 152], [153, 160], [161, 168], [169, 172], [173, 182], [183, 185], [186, 189], [190, 198], [199, 210], [211, 214], [215, 225], [226, 238], [238, 239]]}
{"doc_key": "ai-dev-243", "ner": [[4, 14, "misc"], [16, 18, "misc"], [23, 24, "person"], [29, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 24, 4, 14, "role", "directed_by", false, false], [23, 24, 16, 18, "role", "directed_by", false, false], [23, 24, 29, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "of", "them", ",", "Now", "is", "the", "Time", "(", "to", "Put", "On", "Your", "Glasses", ")", "and", "Around", "is", "Around", ",", "were", "directed", "by", "Norman", "McLaren", "in", "1951", "for", "the", "National", "Film", "Board", "of", "Canada", "."], "sentence-detokenized": "Two of them, Now is the Time (to Put On Your Glasses) and Around is Around, were directed by Norman McLaren in 1951 for the National Film Board of Canada.", "token2charspan": [[0, 3], [4, 6], [7, 11], [11, 12], [13, 16], [17, 19], [20, 23], [24, 28], [29, 30], [30, 32], [33, 36], [37, 39], [40, 44], [45, 52], [52, 53], [54, 57], [58, 64], [65, 67], [68, 74], [74, 75], [76, 80], [81, 89], [90, 92], [93, 99], [100, 107], [108, 110], [111, 115], [116, 119], [120, 123], [124, 132], [133, 137], [138, 143], [144, 146], [147, 153], [153, 154]]}
{"doc_key": "ai-dev-244", "ner": [[1, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "recommendation", "system", "aims", "to", "predict", "the", "preference", "for", "an", "item", "of", "a", "target", "user", "."], "sentence-detokenized": "A recommendation system aims to predict the preference for an item of a target user.", "token2charspan": [[0, 1], [2, 16], [17, 23], [24, 28], [29, 31], [32, 39], [40, 43], [44, 54], [55, 58], [59, 61], [62, 66], [67, 69], [70, 71], [72, 78], [79, 83], [83, 84]]}
{"doc_key": "ai-dev-245", "ner": [[0, 0, "algorithm"], [4, 4, "field"], [6, 6, "field"], [8, 9, "field"], [11, 13, "field"], [15, 15, "field"], [17, 18, "field"], [20, 20, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 4, "part-of", "", true, false], [0, 0, 6, 6, "part-of", "", true, false], [0, 0, 8, 9, "part-of", "", true, false], [0, 0, 11, 13, "part-of", "", true, false], [0, 0, 15, 15, "part-of", "", true, false], [0, 0, 17, 18, "part-of", "", true, false], [0, 0, 20, 20, "part-of", "", true, false], [0, 0, 22, 23, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Convolution", "has", "applications", "in", "probability", ",", "statistics", ",", "computer", "vision", ",", "natural", "language", "processing", ",", "image", "and", "signal", "processing", ",", "engineering", "and", "differential", "equations", "."], "sentence-detokenized": "Convolution has applications in probability, statistics, computer vision, natural language processing, image and signal processing, engineering and differential equations.", "token2charspan": [[0, 11], [12, 15], [16, 28], [29, 31], [32, 43], [43, 44], [45, 55], [55, 56], [57, 65], [66, 72], [72, 73], [74, 81], [82, 90], [91, 101], [101, 102], [103, 108], [109, 112], [113, 119], [120, 130], [130, 131], [132, 143], [144, 147], [148, 160], [161, 170], [170, 171]]}
{"doc_key": "ai-dev-246", "ner": [[0, 0, "field"], [3, 5, "task"], [7, 8, "task"], [10, 10, "task"], [11, 11, "task"], [12, 12, "task"], [14, 15, "task"], [17, 18, "task"], [20, 21, "task"], [23, 23, "task"], [26, 27, "task"], [29, 29, "field"], [31, 31, "field"], [33, 35, "field"], [37, 37, "field"], [39, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[0, 0, 3, 5, "part-of", "", true, false], [0, 0, 7, 8, "part-of", "", true, false], [0, 0, 10, 10, "part-of", "", true, false], [0, 0, 11, 11, "part-of", "", true, false], [0, 0, 12, 12, "part-of", "", true, false], [0, 0, 14, 15, "part-of", "", true, false], [0, 0, 17, 18, "part-of", "", true, false], [0, 0, 20, 21, "part-of", "", true, false], [0, 0, 23, 23, "part-of", "", true, false], [0, 0, 26, 27, "part-of", "", true, false], [0, 0, 29, 29, "part-of", "", true, false], [0, 0, 31, 31, "part-of", "", true, false], [0, 0, 33, 35, "part-of", "", true, false], [0, 0, 37, 37, "part-of", "", true, false], [0, 0, 39, 39, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["DSP", "applications", "include", "audio", "signal", "processing", ",", "audio", "compression", ",", "digital", "image", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communications", ",", "digital", "synthesizers", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", "and", "biomedicine", "."], "sentence-detokenized": "DSP applications include audio signal processing, audio compression, digital image processing, video compression, speech processing, speech recognition, digital communications, digital synthesizers, radar, sonar, financial signal processing, seismology and biomedicine.", "token2charspan": [[0, 3], [4, 16], [17, 24], [25, 30], [31, 37], [38, 48], [48, 49], [50, 55], [56, 67], [67, 68], [69, 76], [77, 82], [83, 93], [93, 94], [95, 100], [101, 112], [112, 113], [114, 120], [121, 131], [131, 132], [133, 139], [140, 151], [151, 152], [153, 160], [161, 175], [175, 176], [177, 184], [185, 197], [197, 198], [199, 204], [204, 205], [206, 211], [211, 212], [213, 222], [223, 229], [230, 240], [240, 241], [242, 252], [253, 256], [257, 268], [268, 269]]}
{"doc_key": "ai-dev-247", "ner": [[13, 14, "misc"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "February", "20", ",", "1912", "-", "August", "11", ",", "2011", ")", "was", "an", "American", "inventor", ",", "best", "known", "for", "creating", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "(February 20, 1912 - August 11, 2011) was an American inventor, best known for creating Unimate, the first industrial robot.", "token2charspan": [[0, 1], [1, 9], [10, 12], [12, 13], [14, 18], [19, 20], [21, 27], [28, 30], [30, 31], [32, 36], [36, 37], [38, 41], [42, 44], [45, 53], [54, 62], [62, 63], [64, 68], [69, 74], [75, 78], [79, 87], [88, 95], [95, 96], [97, 100], [101, 106], [107, 117], [118, 123], [123, 124]]}
{"doc_key": "ai-dev-248", "ner": [[2, 4, "researcher"], [6, 8, "researcher"], [10, 10, "researcher"], [22, 23, "algorithm"], [26, 28, "algorithm"], [32, 33, "task"], [37, 38, "algorithm"], [43, 44, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 22, 23, "related-to", "writes_about", true, false], [6, 8, 22, 23, "related-to", "writes_about", true, false], [10, 10, 22, 23, "related-to", "writes_about", true, false], [22, 23, 26, 28, "related-to", "", true, false], [32, 33, 37, 38, "related-to", "", true, false], [43, 44, 37, 38, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Along", "with", "David", "E.", "Rumelhart", "and", "Ronald", "J.", "Williams", ",", "Hinton", "co-authored", "a", "highly", "cited", "paper", "published", "in", "1986", "that", "popularised", "the", "backpropagation", "algorithm", "for", "training", "multilayer", "neural", "networks", ".", "The", "spectacular", "image", "recognition", "stage", "of", "the", "Alex", "Net", "designed", "by", "his", "student", "Alex", "Krizhevsky", "{{", "cite", "web"], "sentence-detokenized": "Along with David E. Rumelhart and Ronald J. Williams, Hinton co-authored a highly cited paper published in 1986 that popularised the backpropagation algorithm for training multilayer neural networks. The spectacular image recognition stage of the AlexNet designed by his student Alex Krizhevsky {{cite web", "token2charspan": [[0, 5], [6, 10], [11, 16], [17, 19], [20, 29], [30, 33], [34, 40], [41, 43], [44, 52], [52, 53], [54, 60], [61, 72], [73, 74], [75, 81], [82, 87], [88, 93], [94, 103], [104, 106], [107, 111], [112, 116], [117, 128], [129, 132], [133, 148], [149, 158], [159, 162], [163, 171], [172, 182], [183, 189], [190, 198], [198, 199], [200, 203], [204, 215], [216, 221], [222, 233], [234, 239], [240, 242], [243, 246], [247, 251], [251, 254], [255, 263], [264, 266], [267, 270], [271, 278], [279, 283], [284, 294], [295, 297], [297, 301], [302, 305]]}
{"doc_key": "ai-dev-249", "ner": [[11, 13, "metrics"], [15, 18, "metrics"], [20, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "value", "to", "be", "predicted", "is", "continuously", "distributed", ",", "the", "mean", "square", "error", ",", "root", "mean", "square", "error", "or", "median", "absolute", "deviation", "can", "be", "used", "to", "summarise", "the", "errors", "."], "sentence-detokenized": "When the value to be predicted is continuously distributed, the mean square error, root mean square error or median absolute deviation can be used to summarise the errors.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 17], [18, 20], [21, 30], [31, 33], [34, 46], [47, 58], [58, 59], [60, 63], [64, 68], [69, 75], [76, 81], [81, 82], [83, 87], [88, 92], [93, 99], [100, 105], [106, 108], [109, 115], [116, 124], [125, 134], [135, 138], [139, 141], [142, 146], [147, 149], [150, 159], [160, 163], [164, 170], [170, 171]]}
{"doc_key": "ai-dev-250", "ner": [[0, 1, "algorithm"], [9, 10, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 9, 10, "part-of", "", true, false], [0, 1, 13, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Conceptual", "clustering", "developed", "mainly", "in", "the", "1980s", "as", "a", "machine", "learning", "paradigm", "for", "unsupervised", "learning", "."], "sentence-detokenized": "Conceptual clustering developed mainly in the 1980s as a machine learning paradigm for unsupervised learning.", "token2charspan": [[0, 10], [11, 21], [22, 31], [32, 38], [39, 41], [42, 45], [46, 51], [52, 54], [55, 56], [57, 64], [65, 73], [74, 82], [83, 86], [87, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-dev-251", "ner": [[9, 10, "product"], [30, 36, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "named", "entities", "can", "not", "be", "recognised", "by", "the", "machine", "translator", ",", "they", "may", "be", "mistakenly", "translated", "as", "common", "nouns", ",", "which", "would", "probably", "not", "affect", "the", "score", "of", "the", "understudy", "in", "the", "bilingual", "evaluation", "of", "the", "translation", "but", "would", "alter", "the", "human", "readability", "of", "the", "text", "."], "sentence-detokenized": "If named entities cannot be recognised by the machine translator, they may be mistakenly translated as common nouns, which would probably not affect the score of the understudy in the bilingual evaluation of the translation but would alter the human readability of the text.", "token2charspan": [[0, 2], [3, 8], [9, 17], [18, 21], [21, 24], [25, 27], [28, 38], [39, 41], [42, 45], [46, 53], [54, 64], [64, 65], [66, 70], [71, 74], [75, 77], [78, 88], [89, 99], [100, 102], [103, 109], [110, 115], [115, 116], [117, 122], [123, 128], [129, 137], [138, 141], [142, 148], [149, 152], [153, 158], [159, 161], [162, 165], [166, 176], [177, 179], [180, 183], [184, 193], [194, 204], [205, 207], [208, 211], [212, 223], [224, 227], [228, 233], [234, 239], [240, 243], [244, 249], [250, 261], [262, 264], [265, 268], [269, 273], [273, 274]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 22, "location"], [24, 24, "country"], [38, 39, "researcher"], [45, 45, "researcher"], [49, 50, "university"], [54, 55, "researcher"], [57, 58, "researcher"], [60, 61, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 22, "physical", "", false, false], [20, 22, 24, 24, "physical", "", false, false], [45, 45, 49, 50, "physical", "", false, false], [45, 45, 49, 50, "role", "", false, false], [54, 55, 49, 50, "physical", "", false, false], [54, 55, 49, 50, "role", "", false, false], [57, 58, 49, 50, "physical", "", false, false], [57, 58, 49, 50, "role", "", false, false], [60, 61, 49, 50, "physical", "", false, false], [60, 61, 49, 50, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng", "-", "S\u00e4by", ",", "Sweden", ",", "pages", "1-", "3", "This", "model", ",", "partly", "influenced", "by", "the", "work", "of", "Sydney", "Lamb", ",", "was", "widely", "used", "by", "Schank", "'s", "students", "at", "Yale", "University", ",", "such", "as", "Robert", "Wilensky", ",", "Wendy", "Lehnert", "and", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, pages 1-3 This model, partly influenced by the work of Sydney Lamb, was widely used by Schank's students at Yale University, such as Robert Wilensky, Wendy Lehnert and Janet Kolodner.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 130], [130, 131], [131, 135], [135, 136], [137, 143], [143, 144], [145, 150], [151, 153], [153, 154], [155, 159], [160, 165], [165, 166], [167, 173], [174, 184], [185, 187], [188, 191], [192, 196], [197, 199], [200, 206], [207, 211], [211, 212], [213, 216], [217, 223], [224, 228], [229, 231], [232, 238], [238, 240], [241, 249], [250, 252], [253, 257], [258, 268], [268, 269], [270, 274], [275, 277], [278, 284], [285, 293], [293, 294], [295, 300], [301, 308], [309, 312], [313, 318], [319, 327], [327, 328]]}
{"doc_key": "ai-dev-253", "ner": [[0, 4, "algorithm"], [6, 6, "algorithm"], [13, 13, "algorithm"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 0, 4, "named", "", false, false], [13, 13, 0, 4, "named", "", false, false], [15, 16, 0, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "improved", "maximum", "likelihood", "method", "(", "IMLM", ")", "is", "a", "combination", "of", "two", "MLM", "(", "maximum", "likelihood", ")", "estimators", "."], "sentence-detokenized": "The improved maximum likelihood method (IMLM) is a combination of two MLM (maximum likelihood) estimators.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 38], [39, 40], [40, 44], [44, 45], [46, 48], [49, 50], [51, 62], [63, 65], [66, 69], [70, 73], [74, 75], [75, 82], [83, 93], [93, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-254", "ner": [[20, 21, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[24, 25, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "methods", "can", "also", "analyse", "the", "results", "of", "a", "programme", "and", "its", "usefulness", "and", "may", "therefore", "involve", "analysis", "of", "its", "confusion", "matrix", "(", "or", "confusion", "table", ")", "."], "sentence-detokenized": "These methods can also analyse the results of a programme and its usefulness and may therefore involve analysis of its confusion matrix (or confusion table).", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 22], [23, 30], [31, 34], [35, 42], [43, 45], [46, 47], [48, 57], [58, 61], [62, 65], [66, 76], [77, 80], [81, 84], [85, 94], [95, 102], [103, 111], [112, 114], [115, 118], [119, 128], [129, 135], [136, 137], [137, 139], [140, 149], [150, 155], [155, 156], [156, 157]]}
{"doc_key": "ai-dev-255", "ner": [[0, 0, "product"], [5, 6, "researcher"], [8, 9, "researcher"], [11, 13, "researcher"], [19, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 6, "origin", "", false, false], [0, 0, 8, 9, "origin", "", false, false], [0, 0, 11, 13, "origin", "", false, false], [0, 0, 19, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "was", "first", "published", "by", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", "and", "Luc", "Van", "Gool", ",", "and", "presented", "at", "the", "2006", "European", "Computer", "Vision", "Conference", "."], "sentence-detokenized": "SURF was first published by Herbert Bay, Tinne Tuytelaars and Luc Van Gool, and presented at the 2006 European Computer Vision Conference.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 39], [39, 40], [41, 46], [47, 57], [58, 61], [62, 65], [66, 69], [70, 74], [74, 75], [76, 79], [80, 89], [90, 92], [93, 96], [97, 101], [102, 110], [111, 119], [120, 126], [127, 137], [137, 138]]}
{"doc_key": "ai-dev-256", "ner": [[0, 2, "task"], [7, 8, "field"], [10, 11, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 7, 8, "part-of", "", false, false], [0, 2, 10, 11, "part-of", "", false, false], [0, 2, 13, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "is", "a", "field", "of", "research", "in", "pattern", "recognition", ",", "artificial", "intelligence", "and", "computer", "vision", "."], "sentence-detokenized": "OCR is a field of research in pattern recognition, artificial intelligence and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 14], [15, 17], [18, 26], [27, 29], [30, 37], [38, 49], [49, 50], [51, 61], [62, 74], [75, 78], [79, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-dev-257", "ner": [[5, 7, "metrics"], [10, 12, "algorithm"], [14, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 10, 12, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Continuing", "the", "example", "using", "the", "maximum", "likelihood", "estimator", ",", "the", "probability", "density", "function", "(", "pdf", ")", "of", "the", "noise", "for", "a", "mathwn", "/", "math", "sample", "is"], "sentence-detokenized": "Continuing the example using the maximum likelihood estimator, the probability density function (pdf) of the noise for a mathwn / math sample is", "token2charspan": [[0, 10], [11, 14], [15, 22], [23, 28], [29, 32], [33, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 78], [79, 86], [87, 95], [96, 97], [97, 100], [100, 101], [102, 104], [105, 108], [109, 114], [115, 118], [119, 120], [121, 127], [128, 129], [130, 134], [135, 141], [142, 144]]}
{"doc_key": "ai-dev-258", "ner": [[3, 4, "field"], [6, 7, "task"], [9, 10, "task"], [12, 13, "task"], [15, 16, "task"], [18, 20, "task"], [22, 22, "task"], [24, 24, "task"], [26, 27, "task"], [29, 30, "task"], [32, 34, "task"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[6, 7, 3, 4, "part-of", "", false, false], [9, 10, 3, 4, "part-of", "", false, false], [12, 13, 3, 4, "part-of", "", false, false], [15, 16, 3, 4, "part-of", "", false, false], [18, 20, 3, 4, "part-of", "", false, false], [22, 22, 3, 4, "part-of", "", false, false], [24, 24, 3, 4, "part-of", "", false, false], [26, 27, 3, 4, "part-of", "", false, false], [29, 30, 3, 4, "part-of", "", false, false], [32, 34, 3, 4, "part-of", "", false, false], [36, 37, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["The", "subfields", "of", "computer", "vision", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "3D", "pose", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "servoing", ",", "3D", "scene", "modelling", "and", "image", "restoration", "."], "sentence-detokenized": "The subfields of computer vision include scene reconstruction, event detection, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual servoing, 3D scene modelling and image restoration.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 25], [26, 32], [33, 40], [41, 46], [47, 61], [61, 62], [63, 68], [69, 78], [78, 79], [80, 85], [86, 94], [94, 95], [96, 102], [103, 114], [114, 115], [116, 118], [119, 123], [124, 134], [134, 135], [136, 144], [144, 145], [146, 154], [154, 155], [156, 162], [163, 173], [173, 174], [175, 181], [182, 190], [190, 191], [192, 194], [195, 200], [201, 210], [211, 214], [215, 220], [221, 232], [232, 233]]}
{"doc_key": "ai-dev-259", "ner": [[5, 9, "conference"], [11, 11, "researcher"], [14, 15, "misc"], [18, 19, "conference"], [22, 22, "researcher"], [24, 24, "researcher"], [26, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 9, 18, 19, "named", "", false, false], [11, 11, 14, 15, "win-defeat", "", false, false], [11, 11, 26, 27, "related-to", "writes_about", true, false], [14, 15, 5, 9, "temporal", "", false, false], [22, 22, 14, 15, "win-defeat", "", false, true], [22, 22, 26, 27, "related-to", "writes_about", true, false], [24, 24, 14, 15, "win-defeat", "", false, true], [24, 24, 26, 27, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["In", "2013", ",", "at", "the", "International", "Conference", "on", "Computer", "Vision", ",", "Terzopoulos", "received", "a", "Helmholtz", "Award", "for", "his", "1987", "ICCV", "paper", "with", "Kass", "and", "Witkin", "on", "active", "contour", "models", "."], "sentence-detokenized": "In 2013, at the International Conference on Computer Vision, Terzopoulos received a Helmholtz Award for his 1987 ICCV paper with Kass and Witkin on active contour models.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 40], [41, 43], [44, 52], [53, 59], [59, 60], [61, 72], [73, 81], [82, 83], [84, 93], [94, 99], [100, 103], [104, 107], [108, 112], [113, 117], [118, 123], [124, 128], [129, 133], [134, 137], [138, 144], [145, 147], [148, 154], [155, 162], [163, 169], [169, 170]]}
{"doc_key": "ai-dev-260", "ner": [[15, 16, "task"], [18, 20, "algorithm"], [24, 26, "algorithm"], [22, 26, "algorithm"], [28, 29, "algorithm"], [31, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 16, 18, 20, "usage", "", true, false], [15, 16, 24, 26, "usage", "", true, false], [15, 16, 22, 26, "usage", "", true, false], [15, 16, 28, 29, "usage", "", true, false], [15, 16, 31, 31, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["There", "are", "many", "algorithms", "for", "solving", "this", "type", "of", "problem", ";", "the", "most", "popular", "for", "linear", "classification", "are", "stochastic", "gradient", "descent", ",", "L", "-", "BFGS", "gradient", "descent", ",", "coordinate", "descent", "and", "Newton", "'s", "methods", "."], "sentence-detokenized": "There are many algorithms for solving this type of problem; the most popular for linear classification are stochastic gradient descent, L-BFGS gradient descent, coordinate descent and Newton's methods.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 25], [26, 29], [30, 37], [38, 42], [43, 47], [48, 50], [51, 58], [58, 59], [60, 63], [64, 68], [69, 76], [77, 80], [81, 87], [88, 102], [103, 106], [107, 117], [118, 126], [127, 134], [134, 135], [136, 137], [137, 138], [138, 142], [143, 151], [152, 159], [159, 160], [161, 171], [172, 179], [180, 183], [184, 190], [190, 192], [193, 200], [200, 201]]}
{"doc_key": "ai-dev-261", "ner": [[0, 2, "algorithm"], [5, 7, "algorithm"], [10, 11, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 10, 11, "origin", "", false, false], [5, 7, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "Term", "Memory", "Networks", "(", "LSTM", ")", "were", "invented", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "and", "have", "set", "new", "records", "for", "accuracy", "in", "a", "variety", "of", "applications", "."], "sentence-detokenized": "Long Term Memory Networks (LSTM) were invented by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997 and have set new records for accuracy in a variety of applications.", "token2charspan": [[0, 4], [5, 9], [10, 16], [17, 25], [26, 27], [27, 31], [31, 32], [33, 37], [38, 46], [47, 49], [50, 54], [55, 65], [66, 69], [70, 76], [77, 88], [89, 91], [92, 96], [97, 100], [101, 105], [106, 109], [110, 113], [114, 121], [122, 125], [126, 134], [135, 137], [138, 139], [140, 147], [148, 150], [151, 163], [163, 164]]}
{"doc_key": "ai-dev-262", "ner": [[0, 0, "product"], [5, 7, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["TN", "was", "developed", "at", "the", "Massachusetts", "General", "Hospital", "and", "has", "been", "tested", "in", "multiple", "scenarios", ",", "including", "extraction", "of", "smoking", "status", ",", "family", "history", "of", "coronary", "heart", "disease", ",", "identification", "of", "patients", "with", "sleep", "disorders", ","], "sentence-detokenized": "TN was developed at the Massachusetts General Hospital and has been tested in multiple scenarios, including extraction of smoking status, family history of coronary heart disease, identification of patients with sleep disorders,", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 23], [24, 37], [38, 45], [46, 54], [55, 58], [59, 62], [63, 67], [68, 74], [75, 77], [78, 86], [87, 96], [96, 97], [98, 107], [108, 118], [119, 121], [122, 129], [130, 136], [136, 137], [138, 144], [145, 152], [153, 155], [156, 164], [165, 170], [171, 178], [178, 179], [180, 194], [195, 197], [198, 206], [207, 211], [212, 217], [218, 227], [227, 228]]}
{"doc_key": "ai-dev-263", "ner": [[3, 3, "researcher"], [8, 8, "product"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 8, "role", "sells", false, false], [8, 8, 17, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "shipped", "in", "1961", "to", "General", "Motors", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was shipped in 1961 to General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 73], [74, 76], [77, 81], [82, 84], [85, 92], [93, 99], [99, 100]]}
{"doc_key": "ai-dev-264", "ner": [[0, 2, "conference"], [13, 14, "location"], [16, 16, "location"], [18, 18, "country"], [28, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 13, 14, "physical", "", false, false], [13, 14, 16, 16, "physical", "", false, false], [16, 16, 18, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Campus", "Party", "Europe", "was", "held", "from", "14", "to", "18", "April", "2010", "at", "the", "Caja", "M\u00e1gica", "in", "Madrid", ",", "Spain", ",", "with", "800", "participants", "from", "each", "of", "the", "27", "EU", "Member", "States", "."], "sentence-detokenized": "Campus Party Europe was held from 14 to 18 April 2010 at the Caja M\u00e1gica in Madrid, Spain, with 800 participants from each of the 27 EU Member States.", "token2charspan": [[0, 6], [7, 12], [13, 19], [20, 23], [24, 28], [29, 33], [34, 36], [37, 39], [40, 42], [43, 48], [49, 53], [54, 56], [57, 60], [61, 65], [66, 72], [73, 75], [76, 82], [82, 83], [84, 89], [89, 90], [91, 95], [96, 99], [100, 112], [113, 117], [118, 122], [123, 125], [126, 129], [130, 132], [133, 135], [136, 142], [143, 149], [149, 150]]}
{"doc_key": "ai-dev-265", "ner": [[7, 7, "organisation"], [10, 12, "organisation"], [17, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 20, 7, 7, "origin", "", false, false], [17, 20, 10, 12, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2016", ",", "a", "collaboration", "between", "DeepMind", "and", "the", "Moorfields", "Eye", "Hospital", "was", "announced", "to", "develop", "AI", "applications", "for", "healthcare", "."], "sentence-detokenized": "In July 2016, a collaboration between DeepMind and the Moorfields Eye Hospital was announced to develop AI applications for healthcare.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 15], [16, 29], [30, 37], [38, 46], [47, 50], [51, 54], [55, 65], [66, 69], [70, 78], [79, 82], [83, 92], [93, 95], [96, 103], [104, 106], [107, 119], [120, 123], [124, 134], [134, 135]]}
{"doc_key": "ai-dev-266", "ner": [[5, 5, "misc"], [12, 14, "university"], [16, 16, "university"], [18, 19, "university"], [21, 22, "university"], [24, 24, "university"], [26, 26, "university"], [28, 31, "university"], [33, 34, "university"], [36, 37, "university"], [39, 39, "university"], [42, 44, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 5, 12, 14, "physical", "", false, false], [5, 5, 16, 16, "physical", "", false, false], [5, 5, 18, 19, "physical", "", false, false], [5, 5, 21, 22, "physical", "", false, false], [5, 5, 24, 24, "physical", "", false, false], [5, 5, 26, 26, "physical", "", false, false], [5, 5, 28, 31, "physical", "", false, false], [5, 5, 33, 34, "physical", "", false, false], [5, 5, 36, 37, "physical", "", false, false], [5, 5, 39, 39, "physical", "", false, false], [5, 5, 42, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["They", "ended", "up", "awarding", "eleven", "PR2s", "to", "various", "institutions", ",", "including", "the", "University", "of", "Freiburg", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "Technical", "University", "of", "Munich", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", "and", "the", "University", "of", "Tokyo", "."], "sentence-detokenized": "They ended up awarding eleven PR2s to various institutions, including the University of Freiburg, Bosch, Georgia Tech, KU Leuven, MIT, Stanford, Technical University of Munich, UC Berkeley, U Penn, USC and the University of Tokyo.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 29], [30, 34], [35, 37], [38, 45], [46, 58], [58, 59], [60, 69], [70, 73], [74, 84], [85, 87], [88, 96], [96, 97], [98, 103], [103, 104], [105, 112], [113, 117], [117, 118], [119, 121], [122, 128], [128, 129], [130, 133], [133, 134], [135, 143], [143, 144], [145, 154], [155, 165], [166, 168], [169, 175], [175, 176], [177, 179], [180, 188], [188, 189], [190, 191], [192, 196], [196, 197], [198, 201], [202, 205], [206, 209], [210, 220], [221, 223], [224, 229], [229, 230]]}
{"doc_key": "ai-dev-267", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [7, 7, "metrics"], [9, 9, "metrics"], [18, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 18, 19, "part-of", "", false, false], [5, 5, 18, 19, "part-of", "", false, false], [7, 7, 18, 19, "part-of", "", false, false], [9, 9, 18, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "counts", "of", "TP", ",", "TN", ",", "FP", "and", "FN", "are", "usually", "kept", "in", "a", "table", "called", "a", "confusion", "matrix", "."], "sentence-detokenized": "The counts of TP, TN, FP and FN are usually kept in a table called a confusion matrix.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 16], [16, 17], [18, 20], [20, 21], [22, 24], [25, 28], [29, 31], [32, 35], [36, 43], [44, 48], [49, 51], [52, 53], [54, 59], [60, 66], [67, 68], [69, 78], [79, 85], [85, 86]]}
{"doc_key": "ai-dev-268", "ner": [[6, 7, "metrics"], [9, 10, "metrics"], [12, 13, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "a", "set", "of", "characteristics", ",", "information", "gain", ",", "cross", "-entropy", ",", "mutual", "information", "and", "odds", "ratio", "are", "generally", "used", "."], "sentence-detokenized": "As a set of characteristics, information gain, cross-entropy, mutual information and odds ratio are generally used.", "token2charspan": [[0, 2], [3, 4], [5, 8], [9, 11], [12, 27], [27, 28], [29, 40], [41, 45], [45, 46], [47, 52], [52, 60], [60, 61], [62, 68], [69, 80], [81, 84], [85, 89], [90, 95], [96, 99], [100, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-dev-269", "ner": [[12, 13, "task"], [15, 16, "task"], [18, 18, "task"], [20, 20, "task"], [23, 25, "task"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[27, 27, 23, 25, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "successfully", "applied", "to", "a", "variety", "of", "problems", ",", "including", "robot", "control", ",", "lift", "programming", ",", "telecommunications", ",", "checkers", "and", "the", "game", "of", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "It has been successfully applied to a variety of problems, including robot control, lift programming, telecommunications, checkers and the game of Go (AlphaGo).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 32], [33, 35], [36, 37], [38, 45], [46, 48], [49, 57], [57, 58], [59, 68], [69, 74], [75, 82], [82, 83], [84, 88], [89, 100], [100, 101], [102, 120], [120, 121], [122, 130], [131, 134], [135, 138], [139, 143], [144, 146], [147, 149], [150, 151], [151, 158], [158, 159], [159, 160]]}
{"doc_key": "ai-dev-270", "ner": [[11, 14, "misc"], [20, 23, "university"], [25, 25, "location"], [27, 27, "location"], [31, 35, "location"], [39, 41, "location"], [43, 43, "location"], [44, 45, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 14, 20, 23, "physical", "", false, false], [20, 23, 25, 25, "physical", "", false, false], [25, 25, 27, 27, "physical", "", false, false], [31, 35, 39, 41, "physical", "", false, false], [39, 41, 43, 43, "physical", "", false, false], [43, 43, 44, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "the", "inaugural", "year", "of", "Mission", "8", ",", "the", "US", "site", "was", "held", "on", "the", "campus", "of", "the", "Georgia", "Institute", "of", "Technology", "in", "Atlanta", ",", "Georgia", ",", "and", "the", "Asia", "/", "Pacific", "site", "was", "held", "at", "the", "Beihang", "University", "Gymnasium", "in", "Beijing", ",", "China", "."], "sentence-detokenized": "In 2018, the inaugural year of Mission 8, the US site was held on the campus of the Georgia Institute of Technology in Atlanta, Georgia, and the Asia/Pacific site was held at the Beihang University Gymnasium in Beijing, China.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 38], [39, 40], [40, 41], [42, 45], [46, 48], [49, 53], [54, 57], [58, 62], [63, 65], [66, 69], [70, 76], [77, 79], [80, 83], [84, 91], [92, 101], [102, 104], [105, 115], [116, 118], [119, 126], [126, 127], [128, 135], [135, 136], [137, 140], [141, 144], [145, 149], [149, 150], [150, 157], [158, 162], [163, 166], [167, 171], [172, 174], [175, 178], [179, 186], [187, 197], [198, 207], [208, 210], [211, 218], [218, 219], [220, 225], [225, 226]]}
{"doc_key": "ai-dev-271", "ner": [[0, 2, "field"], [6, 7, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 7, "origin", "", false, false], [0, 2, 6, 7, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "is", "strongly", "linked", "to", "pattern", "recognition", "and", "is", "derived", "from", "artificial", "intelligence", "."], "sentence-detokenized": "Machine learning is strongly linked to pattern recognition and is derived from artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 28], [29, 35], [36, 38], [39, 46], [47, 58], [59, 62], [63, 65], [66, 73], [74, 78], [79, 89], [90, 102], [102, 103]]}
{"doc_key": "ai-dev-272", "ner": [[4, 4, "programlang"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "comes", "with", "3", "Java", "games", "that", "are", "controlled", "by", "the", "remote", "control", "and", "displayed", "on", "its", "LCD", "screen", "."], "sentence-detokenized": "It comes with 3 Java games that are controlled by the remote control and displayed on its LCD screen.", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 15], [16, 20], [21, 26], [27, 31], [32, 35], [36, 46], [47, 49], [50, 53], [54, 60], [61, 68], [69, 72], [73, 82], [83, 85], [86, 89], [90, 93], [94, 100], [100, 101]]}
{"doc_key": "ai-dev-273", "ner": [[11, 20, "task"], [0, 2, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 11, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Optical", "motion", "capture", "is", "a", "commercially", "successful", "but", "specialised", "technique", "for", "estimating", "the", "pose", "of", "articulated", "bodies", "based", "on", "computer", "vision", "."], "sentence-detokenized": "Optical motion capture is a commercially successful but specialised technique for estimating the pose of articulated bodies based on computer vision.", "token2charspan": [[0, 7], [8, 14], [15, 22], [23, 25], [26, 27], [28, 40], [41, 51], [52, 55], [56, 67], [68, 77], [78, 81], [82, 92], [93, 96], [97, 101], [102, 104], [105, 116], [117, 123], [124, 129], [130, 132], [133, 141], [142, 148], [148, 149]]}
{"doc_key": "ai-dev-274", "ner": [[0, 1, "organisation"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SMC", "is", "very", "similar", "to", "the", "more", "popular", "Jaccard", "index", "."], "sentence-detokenized": "The SMC is very similar to the more popular Jaccard index.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 23], [24, 26], [27, 30], [31, 35], [36, 43], [44, 51], [52, 57], [57, 58]]}
{"doc_key": "ai-dev-275", "ner": [[1, 1, "product"], [3, 7, "product"], [10, 13, "product"], [22, 25, "researcher"], [29, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 10, 13, "named", "", false, false], [1, 1, 22, 25, "artifact", "", false, false], [1, 1, 29, 29, "artifact", "", false, false], [3, 7, 1, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ",", "or", "Programmable", "Universal", "Manipulation", "Arm", ")", "is", "an", "industrial", "robot", "arm", "developed", "by", "Victor", "Scheinman", "at", "the", "pioneering", "robot", "company", "Unimation", "."], "sentence-detokenized": "The PUMA (Programmable Universal Machine for Assembly, or Programmable Universal Manipulation Arm) is an industrial robot arm developed by Victor Scheinman at the pioneering robot company Unimation.", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 22], [23, 32], [33, 40], [41, 44], [45, 53], [53, 54], [55, 57], [58, 70], [71, 80], [81, 93], [94, 97], [97, 98], [99, 101], [102, 104], [105, 115], [116, 121], [122, 125], [126, 135], [136, 138], [139, 145], [146, 155], [156, 158], [159, 162], [163, 173], [174, 179], [180, 187], [188, 197], [197, 198]]}
{"doc_key": "ai-dev-276", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "written", "in", "Python", "."], "sentence-detokenized": "It is written in Python.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 23], [23, 24]]}
{"doc_key": "ai-dev-277", "ner": [[1, 3, "misc"], [0, 0, "misc"], [11, 11, "field"], [13, 14, "field"], [16, 16, "field"], [22, 23, "field"], [25, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7], "relations": [[1, 3, 0, 0, "related-to", "metric_for", true, false], [1, 3, 11, 11, "part-of", "", false, false], [1, 3, 13, 14, "part-of", "", false, false], [1, 3, 16, 16, "part-of", "", false, false], [1, 3, 22, 23, "part-of", "", false, false], [1, 3, 25, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6], "sentence": ["Hertz", "bandwidth", "is", "a", "central", "concept", "in", "many", "fields", ",", "including", "electronics", ",", "information", "theory", ",", "digital", "communications", ",", "radio", "communications", ",", "signal", "processing", "and", "spectroscopy", ".", "It", "is", "one", "of", "the", "determining", "factors", "of", "the", "capacity", "of", "a", "given", "communication", "channel", "."], "sentence-detokenized": "Hertz bandwidth is a central concept in many fields, including electronics, information theory, digital communications, radio communications, signal processing and spectroscopy. It is one of the determining factors of the capacity of a given communication channel.", "token2charspan": [[0, 5], [6, 15], [16, 18], [19, 20], [21, 28], [29, 36], [37, 39], [40, 44], [45, 51], [51, 52], [53, 62], [63, 74], [74, 75], [76, 87], [88, 94], [94, 95], [96, 103], [104, 118], [118, 119], [120, 125], [126, 140], [140, 141], [142, 148], [149, 159], [160, 163], [164, 176], [176, 177], [178, 180], [181, 183], [184, 187], [188, 190], [191, 194], [195, 206], [207, 214], [215, 217], [218, 221], [222, 230], [231, 233], [234, 235], [236, 241], [242, 255], [256, 263], [263, 264]]}
{"doc_key": "ai-dev-278", "ner": [[9, 9, "algorithm"], [11, 11, "algorithm"], [17, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 17, 20, "part-of", "", false, false], [11, 11, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "a", "convex", "loss", "is", "used", "(", "as", "in", "AdaBoost", ",", "LogitBoost", "and", "all", "members", "of", "the", "AnyBoost", "family", "of", "algorithms", ")", ",", "an", "example", "with", "a", "higher", "margin", "will", "receive", "less", "weight", "(", "or", "equal", "weight", ")", "than", "an", "example", "with", "a", "lower", "margin", "."], "sentence-detokenized": "If a convex loss is used (as in AdaBoost, LogitBoost and all members of the AnyBoost family of algorithms), an example with a higher margin will receive less weight (or equal weight) than an example with a lower margin.", "token2charspan": [[0, 2], [3, 4], [5, 11], [12, 16], [17, 19], [20, 24], [25, 26], [26, 28], [29, 31], [32, 40], [40, 41], [42, 52], [53, 56], [57, 60], [61, 68], [69, 71], [72, 75], [76, 84], [85, 91], [92, 94], [95, 105], [105, 106], [106, 107], [108, 110], [111, 118], [119, 123], [124, 125], [126, 132], [133, 139], [140, 144], [145, 152], [153, 157], [158, 164], [165, 166], [166, 168], [169, 174], [175, 181], [181, 182], [183, 187], [188, 190], [191, 198], [199, 203], [204, 205], [206, 211], [212, 218], [218, 219]]}
{"doc_key": "ai-dev-279", "ner": [[0, 1, "researcher"], [7, 8, "researcher"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sepp", "Hochreiter", "'s", "diploma", "thesis", "from", "1991", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Sepp Hochreiter's diploma thesis from 1991 Sepp Hochreiter.", "token2charspan": [[0, 4], [5, 15], [15, 17], [18, 25], [26, 32], [33, 37], [38, 42], [43, 47], [48, 58], [58, 59]]}
{"doc_key": "ai-dev-280", "ner": [[4, 5, "algorithm"], [7, 7, "algorithm"], [10, 12, "algorithm"], [14, 14, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [27, 28, "algorithm"], [31, 32, "algorithm"], [34, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 7, 4, 5, "named", "", false, false], [14, 14, 10, 12, "named", "", false, false], [17, 19, 27, 28, "related-to", "", true, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Typical", "discriminative", "models", "include", "logistic", "regression", "(", "LR", ")", ",", "support", "vector", "machines", "(", "SVM", ")", ",", "conditional", "random", "fields", "(", "CRF", ")", "(", "specified", "on", "an", "undirected", "graph", ")", ",", "decision", "trees", ",", "neural", "networks", "and", "many", "others", "."], "sentence-detokenized": "Typical discriminative models include logistic regression (LR), support vector machines (SVM), conditional random fields (CRF) (specified on an undirected graph), decision trees, neural networks and many others.", "token2charspan": [[0, 7], [8, 22], [23, 29], [30, 37], [38, 46], [47, 57], [58, 59], [59, 61], [61, 62], [62, 63], [64, 71], [72, 78], [79, 87], [88, 89], [89, 92], [92, 93], [93, 94], [95, 106], [107, 113], [114, 120], [121, 122], [122, 125], [125, 126], [127, 128], [128, 137], [138, 140], [141, 143], [144, 154], [155, 160], [160, 161], [161, 162], [163, 171], [172, 177], [177, 178], [179, 185], [186, 194], [195, 198], [199, 203], [204, 210], [210, 211]]}
{"doc_key": "ai-dev-281", "ner": [[11, 13, "metrics"], [35, 36, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "also", "possible", "to", "use", "these", "probabilities", "and", "estimate", "the", "mean", "square", "error", "(", "or", "some", "other", "similar", "measure", ")", "between", "the", "probabilities", "and", "the", "actual", "values", ",", "and", "then", "combine", "it", "with", "the", "confusion", "matrix", "to", "create", "very", "efficient", "fitness", "functions", "for", "logistic", "regression", "."], "sentence-detokenized": "It is also possible to use these probabilities and estimate the mean square error (or some other similar measure) between the probabilities and the actual values, and then combine it with the confusion matrix to create very efficient fitness functions for logistic regression.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 19], [20, 22], [23, 26], [27, 32], [33, 46], [47, 50], [51, 59], [60, 63], [64, 68], [69, 75], [76, 81], [82, 83], [83, 85], [86, 90], [91, 96], [97, 104], [105, 112], [112, 113], [114, 121], [122, 125], [126, 139], [140, 143], [144, 147], [148, 154], [155, 161], [161, 162], [163, 166], [167, 171], [172, 179], [180, 182], [183, 187], [188, 191], [192, 201], [202, 208], [209, 211], [212, 218], [219, 223], [224, 233], [234, 241], [242, 251], [252, 255], [256, 264], [265, 275], [275, 276]]}
{"doc_key": "ai-dev-282", "ner": [[0, 3, "product"], [6, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 6, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "first", "appeared", "in", "2005", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "."], "sentence-detokenized": "VoiceOver first appeared in 2005 in Mac OS X Tiger (10.4).", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 27], [28, 32], [33, 35], [36, 39], [40, 42], [43, 44], [45, 50], [51, 52], [52, 56], [56, 57], [57, 58]]}
{"doc_key": "ai-dev-283", "ner": [[13, 15, "algorithm"], [19, 21, "misc"], [26, 27, "metrics"], [30, 32, "algorithm"], [62, 64, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 15, 19, 21, "related-to", "applied_to", false, false], [26, 27, 19, 21, "type-of", "", false, false], [26, 27, 30, 32, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "practice", ",", "machine", "learning", "algorithms", "cope", "with", "this", "either", "by", "employing", "a", "convex", "approximation", "of", "the", "0", "-", "1", "loss", "function", "(", "such", "as", "the", "hinge", "loss", "for", "the", "Support", "vector", "machine", ")", ",", "which", "is", "easier", "to", "optimise", ",", "or", "by", "imposing", "assumptions", "on", "the", "mathP", "(", "x", ",", "y", ")", "/", "math", "distribution", "(", "and", "thus", "cease", "to", "be", "agnostic", "learning", "algorithms", "to", "which", "the", "above", "result", "applies", ")", "."], "sentence-detokenized": "In practice, machine learning algorithms cope with this either by employing a convex approximation of the 0-1 loss function (such as the hinge loss for the Support vector machine), which is easier to optimise, or by imposing assumptions on the mathP (x, y) / math distribution (and thus cease to be agnostic learning algorithms to which the above result applies).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 29], [30, 40], [41, 45], [46, 50], [51, 55], [56, 62], [63, 65], [66, 75], [76, 77], [78, 84], [85, 98], [99, 101], [102, 105], [106, 107], [107, 108], [108, 109], [110, 114], [115, 123], [124, 125], [125, 129], [130, 132], [133, 136], [137, 142], [143, 147], [148, 151], [152, 155], [156, 163], [164, 170], [171, 178], [178, 179], [179, 180], [181, 186], [187, 189], [190, 196], [197, 199], [200, 208], [208, 209], [210, 212], [213, 215], [216, 224], [225, 236], [237, 239], [240, 243], [244, 249], [250, 251], [251, 252], [252, 253], [254, 255], [255, 256], [257, 258], [259, 263], [264, 276], [277, 278], [278, 281], [282, 286], [287, 292], [293, 295], [296, 298], [299, 307], [308, 316], [317, 327], [328, 330], [331, 336], [337, 340], [341, 346], [347, 353], [354, 361], [361, 362], [362, 363]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [11, 13, "field"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "usage", "", false, false], [0, 0, 17, 18, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Westworld", "(", "1973", ")", "was", "the", "first", "feature", "film", "to", "use", "digital", "image", "processing", "to", "simulate", "an", "android", "'s", "point", "of", "view", "."], "sentence-detokenized": "Westworld (1973) was the first feature film to use digital image processing to simulate an android's point of view.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 20], [21, 24], [25, 30], [31, 38], [39, 43], [44, 46], [47, 50], [51, 58], [59, 64], [65, 75], [76, 78], [79, 87], [88, 90], [91, 98], [98, 100], [101, 106], [107, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-dev-285", "ner": [[7, 8, "task"], [10, 11, "task"], [13, 13, "task"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "now", "also", "commonly", "used", "in", "speech", "recognition", ",", "speech", "synthesis", ",", "diarisation", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "It is now also commonly used in speech recognition, speech synthesis, diarisation, Xavier Anguera et al.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 14], [15, 23], [24, 28], [29, 31], [32, 38], [39, 50], [50, 51], [52, 58], [59, 68], [68, 69], [70, 81], [81, 82], [83, 89], [90, 97], [98, 100], [101, 103], [103, 104]]}
{"doc_key": "ai-dev-286", "ner": [[7, 9, "algorithm"], [14, 15, "algorithm"], [18, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 7, 9, "type-of", "", false, false], [18, 20, 7, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Here", ",", "sigma", "/", "math", "is", "an", "elemental", "activation", "function", ",", "such", "as", "a", "sigmoid", "function", "or", "a", "rectified", "linear", "unit", "."], "sentence-detokenized": "Here, sigma/math is an elemental activation function, such as a sigmoid function or a rectified linear unit.", "token2charspan": [[0, 4], [4, 5], [6, 11], [11, 12], [12, 16], [17, 19], [20, 22], [23, 32], [33, 43], [44, 52], [52, 53], [54, 58], [59, 61], [62, 63], [64, 71], [72, 80], [81, 83], [84, 85], [86, 95], [96, 102], [103, 107], [107, 108]]}
{"doc_key": "ai-dev-287", "ner": [[8, 14, "algorithm"], [23, 23, "misc"], [27, 27, "misc"], [24, 32, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "phonetic", "-", "based", "approaches", "(", "i.e.", "all", "models", "based", "on", "the", "Hidden", "Markov", "Model", ")", "required", "separate", "components", "and", "training", "for", "the", "pronunciation", "model", ",", "the", "acoustic", "model", "and", "the", "linguistic", "model", "."], "sentence-detokenized": "Traditional phonetic-based approaches (i.e. all models based on the Hidden Markov Model) required separate components and training for the pronunciation model, the acoustic model and the linguistic model.", "token2charspan": [[0, 11], [12, 20], [20, 21], [21, 26], [27, 37], [38, 39], [39, 43], [44, 47], [48, 54], [55, 60], [61, 63], [64, 67], [68, 74], [75, 81], [82, 87], [87, 88], [89, 97], [98, 106], [107, 117], [118, 121], [122, 130], [131, 134], [135, 138], [139, 152], [153, 158], [158, 159], [160, 163], [164, 172], [173, 178], [179, 182], [183, 186], [187, 197], [198, 203], [203, 204]]}
{"doc_key": "ai-dev-288", "ner": [[1, 3, "algorithm"], [7, 8, "field"], [10, 11, "field"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 13, 14, "related-to", "used_for", false, false], [7, 8, 1, 3, "usage", "", false, false], [10, 11, 1, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Roberts", "cross", "operator", "is", "used", "in", "image", "processing", "and", "computer", "vision", "for", "edge", "detection", "."], "sentence-detokenized": "The Roberts cross operator is used in image processing and computer vision for edge detection.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 37], [38, 43], [44, 54], [55, 58], [59, 67], [68, 74], [75, 78], [79, 83], [84, 93], [93, 94]]}
{"doc_key": "ai-dev-289", "ner": [[0, 0, "metrics"], [2, 2, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 19, 19, "opposite", "", false, false], [2, 2, 19, 19, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Sensitivity", "and", "specificity", "values", "are", "independent", "of", "the", "percentage", "of", "positive", "cases", "in", "the", "population", "of", "interest", "(", "unlike", "accuracy", ",", "for", "example", ")", "."], "sentence-detokenized": "Sensitivity and specificity values are independent of the percentage of positive cases in the population of interest (unlike accuracy, for example).", "token2charspan": [[0, 11], [12, 15], [16, 27], [28, 34], [35, 38], [39, 50], [51, 53], [54, 57], [58, 68], [69, 71], [72, 80], [81, 86], [87, 89], [90, 93], [94, 104], [105, 107], [108, 116], [117, 118], [118, 124], [125, 133], [133, 134], [135, 138], [139, 146], [146, 147], [147, 148]]}
{"doc_key": "ai-dev-290", "ner": [[1, 2, "algorithm"], [10, 10, "misc"], [12, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 1, 2, "topic", "", false, false], [10, 10, 12, 13, "artifact", "", false, false], [10, 10, 15, 16, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["But", "perceptron", "models", "were", "made", "very", "unpopular", "by", "the", "book", "Perceptrons", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", ",", "published", "in", "1969", "."], "sentence-detokenized": "But perceptron models were made very unpopular by the book Perceptrons by Marvin Minsky and Seymour Papert, published in 1969.", "token2charspan": [[0, 3], [4, 14], [15, 21], [22, 26], [27, 31], [32, 36], [37, 46], [47, 49], [50, 53], [54, 58], [59, 70], [71, 73], [74, 80], [81, 87], [88, 91], [92, 99], [100, 106], [106, 107], [108, 117], [118, 120], [121, 125], [125, 126]]}
{"doc_key": "ai-dev-291", "ner": [[3, 5, "conference"], [2, 2, "organisation"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 18, 19, "topic", "", false, false], [2, 2, 3, 5, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "annual", "NIST", "Document", "Comprehension", "Conferences", "have", "developed", "sophisticated", "evaluation", "criteria", "for", "techniques", "that", "accept", "the", "challenge", "of", "multi-document", "summarisation", "."], "sentence-detokenized": "The annual NIST Document Comprehension Conferences have developed sophisticated evaluation criteria for techniques that accept the challenge of multi-document summarisation.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 24], [25, 38], [39, 50], [51, 55], [56, 65], [66, 79], [80, 90], [91, 99], [100, 103], [104, 114], [115, 119], [120, 126], [127, 130], [131, 140], [141, 143], [144, 158], [159, 172], [172, 173]]}
{"doc_key": "ai-dev-292", "ner": [[1, 2, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 26, 27, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "parallel", "manipulator", "is", "designed", "so", "that", "each", "chain", "is", "generally", "short", ",", "simple", "and", "can", "therefore", "be", "rigid", "against", "unwanted", "movement", ",", "compared", "to", "a", "serial", "manipulator", "."], "sentence-detokenized": "A parallel manipulator is designed so that each chain is generally short, simple and can therefore be rigid against unwanted movement, compared to a serial manipulator.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 34], [35, 37], [38, 42], [43, 47], [48, 53], [54, 56], [57, 66], [67, 72], [72, 73], [74, 80], [81, 84], [85, 88], [89, 98], [99, 101], [102, 107], [108, 115], [116, 124], [125, 133], [133, 134], [135, 143], [144, 146], [147, 148], [149, 155], [156, 167], [167, 168]]}
{"doc_key": "ai-dev-293", "ner": [[27, 27, "misc"], [29, 31, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "manipulator", "is", "what", "allows", "the", "robot", "to", "move", ",", "and", "the", "design", "of", "these", "systems", "can", "be", "classified", "into", "several", "common", "types", ",", "such", "as", "the", "SCARA", "and", "Cartesian", "coordinate", "robot", ",", "which", "use", "different", "coordinate", "systems", "to", "direct", "the", "machine", "arms", "."], "sentence-detokenized": "The manipulator is what allows the robot to move, and the design of these systems can be classified into several common types, such as the SCARA and Cartesian coordinate robot, which use different coordinate systems to direct the machine arms.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 23], [24, 30], [31, 34], [35, 40], [41, 43], [44, 48], [48, 49], [50, 53], [54, 57], [58, 64], [65, 67], [68, 73], [74, 81], [82, 85], [86, 88], [89, 99], [100, 104], [105, 112], [113, 119], [120, 125], [125, 126], [127, 131], [132, 134], [135, 138], [139, 144], [145, 148], [149, 158], [159, 169], [170, 175], [175, 176], [177, 182], [183, 186], [187, 196], [197, 207], [208, 215], [216, 218], [219, 225], [226, 229], [230, 237], [238, 242], [242, 243]]}
{"doc_key": "ai-dev-294", "ner": [[2, 3, "country"], [11, 14, "organisation"], [17, 22, "organisation"], [25, 28, "organisation"], [31, 33, "organisation"], [36, 42, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 14, 2, 3, "physical", "", false, false], [17, 22, 2, 3, "physical", "", false, false], [25, 28, 2, 3, "physical", "", false, false], [31, 33, 2, 3, "physical", "", false, false], [36, 42, 2, 3, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "United", "States", ",", "he", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "Linguistic", "Society", "of", "America", ",", "the", "American", "Philosophical", "Association", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In the United States, he is a member of the National Academy of Sciences, the American Academy of Arts and Sciences, the Linguistic Society of America, the American Philosophical Association and the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 20], [20, 21], [22, 24], [25, 27], [28, 29], [30, 36], [37, 39], [40, 43], [44, 52], [53, 60], [61, 63], [64, 72], [72, 73], [74, 77], [78, 86], [87, 94], [95, 97], [98, 102], [103, 106], [107, 115], [115, 116], [117, 120], [121, 131], [132, 139], [140, 142], [143, 150], [150, 151], [152, 155], [156, 164], [165, 178], [179, 190], [191, 194], [195, 198], [199, 207], [208, 219], [220, 223], [224, 227], [228, 239], [240, 242], [243, 250], [250, 251]]}
{"doc_key": "ai-dev-295", "ner": [[9, 11, "algorithm"], [13, 13, "algorithm"], [20, 20, "algorithm"], [24, 25, "algorithm"], [30, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 11, 20, 20, "named", "", false, false], [13, 13, 9, 11, "named", "", false, false], [20, 20, 24, 25, "compare", "", false, false], [20, 20, 30, 31, "related-to", "performs", false, false], [24, 25, 30, 31, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["They", "came", "to", "prominence", "with", "the", "popularity", "of", "the", "support", "vector", "machine", "(", "SVM", ")", "in", "the", "1990s", ",", "when", "SVM", "proved", "competitive", "with", "neural", "networks", "in", "tasks", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "They came to prominence with the popularity of the support vector machine (SVM) in the 1990s, when SVM proved competitive with neural networks in tasks such as handwriting recognition.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 23], [24, 28], [29, 32], [33, 43], [44, 46], [47, 50], [51, 58], [59, 65], [66, 73], [74, 75], [75, 78], [78, 79], [80, 82], [83, 86], [87, 92], [92, 93], [94, 98], [99, 102], [103, 109], [110, 121], [122, 126], [127, 133], [134, 142], [143, 145], [146, 151], [152, 156], [157, 159], [160, 171], [172, 183], [183, 184]]}
{"doc_key": "ai-dev-296", "ner": [[0, 3, "misc"], [9, 9, "misc"], [13, 14, "algorithm"], [22, 23, "misc"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 9, 9, "usage", "", false, false], [0, 3, 22, 23, "usage", "", false, false], [9, 9, 13, 14, "origin", "result_of_algorithm", false, false], [22, 23, 27, 28, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["An", "empirical", "whitening", "transform", "is", "obtained", "by", "estimating", "the", "covariance", "(", "e.g.", "by", "maximum", "likelihood", ")", "and", "then", "constructing", "a", "corresponding", "estimated", "whitening", "matrix", "(", "e.g.", "by", "Cholesky", "decomposition", ")", "."], "sentence-detokenized": "An empirical whitening transform is obtained by estimating the covariance (e.g. by maximum likelihood) and then constructing a corresponding estimated whitening matrix (e.g. by Cholesky decomposition).", "token2charspan": [[0, 2], [3, 12], [13, 22], [23, 32], [33, 35], [36, 44], [45, 47], [48, 58], [59, 62], [63, 73], [74, 75], [75, 79], [80, 82], [83, 90], [91, 101], [101, 102], [103, 106], [107, 111], [112, 124], [125, 126], [127, 140], [141, 150], [151, 160], [161, 167], [168, 169], [169, 173], [174, 176], [177, 185], [186, 199], [199, 200], [200, 201]]}
{"doc_key": "ai-dev-297", "ner": [[0, 2, "organisation"], [8, 9, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 0, 2, "artifact", "", false, false], [24, 24, 0, 2, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "is", "the", "world", "'s", "largest", "manufacturer", "of", "Cartesian", "coordinate", "robots", "and", "is", "a", "recognized", "leader", "in", "low", "-", "cost", ",", "high", "-", "performance", "SCARA", "robots", "."], "sentence-detokenized": "IAI is the world's largest manufacturer of Cartesian coordinate robots and is a recognized leader in low-cost, high-performance SCARA robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [16, 18], [19, 26], [27, 39], [40, 42], [43, 52], [53, 63], [64, 70], [71, 74], [75, 77], [78, 79], [80, 90], [91, 97], [98, 100], [101, 104], [104, 105], [105, 109], [109, 110], [111, 115], [115, 116], [116, 127], [128, 133], [134, 140], [140, 141]]}
{"doc_key": "ai-dev-298", "ner": [[10, 11, "field"], [13, 14, "field"], [16, 17, "field"], [19, 20, "field"], [23, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formal", "concept", "analysis", "has", "practical", "applications", "in", "areas", "such", "as", "data", "mining", ",", "text", "mining", ",", "machine", "learning", ",", "knowledge", "management", ",", "the", "semantic", "web", ",", "software", "development", ",", "chemistry", "and", "biology", "."], "sentence-detokenized": "Formal concept analysis has practical applications in areas such as data mining, text mining, machine learning, knowledge management, the semantic web, software development, chemistry and biology.", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 27], [28, 37], [38, 50], [51, 53], [54, 59], [60, 64], [65, 67], [68, 72], [73, 79], [79, 80], [81, 85], [86, 92], [92, 93], [94, 101], [102, 110], [110, 111], [112, 121], [122, 132], [132, 133], [134, 137], [138, 146], [147, 150], [150, 151], [152, 160], [161, 172], [172, 173], [174, 183], [184, 187], [188, 195], [195, 196]]}
{"doc_key": "ai-dev-299", "ner": [[1, 2, "field"], [4, 6, "field"], [10, 11, "field"], [17, 18, "field"], [29, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 17, 18, "part-of", "", false, false], [4, 6, 29, 30, "topic", "", false, false], [10, 11, 4, 6, "named", "", false, false], [17, 18, 1, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", ",", "computational", "learning", "theory", "(", "or", "simply", "learning", "theory", ")", "is", "a", "subfield", "of", "artificial", "intelligence", "devoted", "to", "the", "study", "of", "the", "design", "and", "analysis", "of", "machine", "learning", "algorithms", "."], "sentence-detokenized": "In computer science, computational learning theory (or simply learning theory) is a subfield of artificial intelligence devoted to the study of the design and analysis of machine learning algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 34], [35, 43], [44, 50], [51, 52], [52, 54], [55, 61], [62, 70], [71, 77], [77, 78], [79, 81], [82, 83], [84, 92], [93, 95], [96, 106], [107, 119], [120, 127], [128, 130], [131, 134], [135, 140], [141, 143], [144, 147], [148, 154], [155, 158], [159, 167], [168, 170], [171, 178], [179, 187], [188, 198], [198, 199]]}
{"doc_key": "ai-dev-300", "ner": [[0, 1, "algorithm"], [3, 5, "algorithm"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 0, 1, "named", "", false, false], [10, 10, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Collaborative", "filtering", "(", "CF", ")", "is", "a", "technique", "used", "by", "recommender", "systems", "."], "sentence-detokenized": "Collaborative filtering (CF) is a technique used by recommender systems.", "token2charspan": [[0, 13], [14, 23], [24, 25], [25, 27], [27, 28], [29, 31], [32, 33], [34, 43], [44, 48], [49, 51], [52, 63], [64, 71], [71, 72]]}
{"doc_key": "ai-dev-301", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "FALSE", "positive", "rate", "is", "the", "proportion", "of", "all", "negatives", "that", "still", "give", "positive", "results", ",", "i.e.", "the", "conditional", "probability", "of", "a", "positive", "result", "given", "an", "event", "that", "was", "not", "present", "."], "sentence-detokenized": "The FALSE positive rate is the proportion of all negatives that still give positive results, i.e. the conditional probability of a positive result given an event that was not present.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 23], [24, 26], [27, 30], [31, 41], [42, 44], [45, 48], [49, 58], [59, 63], [64, 69], [70, 74], [75, 83], [84, 91], [91, 92], [93, 97], [98, 101], [102, 113], [114, 125], [126, 128], [129, 130], [131, 139], [140, 146], [147, 152], [153, 155], [156, 161], [162, 166], [167, 170], [171, 174], [175, 182], [182, 183]]}
{"doc_key": "ai-dev-302", "ner": [[1, 15, "misc"], [37, 37, "metrics"], [40, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 15, 37, 37, "topic", "", false, false], [1, 15, 40, 40, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "VLDB", "'", "8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pages", "422--433", ".", "showed", "that", "the", "values", "given", "for", "mathC", "/", "math", "and", "mathK", "/", "math", "generally", "imply", "relatively", "low", "accuracy", "of", "the", "SimRank", "scores", "calculated", "per", "iteration", "."], "sentence-detokenized": "In VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, pages 422--433. showed that the values given for mathC / math and mathK / math generally imply relatively low accuracy of the SimRank scores calculated per iteration.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [10, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 79], [80, 85], [85, 86], [87, 92], [93, 101], [101, 102], [103, 109], [110, 114], [115, 118], [119, 125], [126, 131], [132, 135], [136, 141], [142, 143], [144, 148], [149, 152], [153, 158], [159, 160], [161, 165], [166, 175], [176, 181], [182, 192], [193, 196], [197, 205], [206, 208], [209, 212], [213, 220], [221, 227], [228, 238], [239, 242], [243, 252], [252, 253]]}
{"doc_key": "ai-dev-303", "ner": [[1, 4, "misc"], [5, 5, "misc"], [18, 18, "person"], [20, 22, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 1, 4, "general-affiliation", "", false, false], [5, 5, 18, 18, "artifact", "", false, false], [5, 5, 20, 22, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "sci", "-", "fi", "drama", "Sense8", "debuted", "in", "June", "2015", ".", "It", "was", "written", "and", "produced", "by", "the", "Wachowskis", "and", "J.", "Michael", "Straczynski", "."], "sentence-detokenized": "The sci-fi drama Sense8 debuted in June 2015. It was written and produced by the Wachowskis and J. Michael Straczynski.", "token2charspan": [[0, 3], [4, 7], [7, 8], [8, 10], [11, 16], [17, 23], [24, 31], [32, 34], [35, 39], [40, 44], [44, 45], [46, 48], [49, 52], [53, 60], [61, 64], [65, 73], [74, 76], [77, 80], [81, 91], [92, 95], [96, 98], [99, 106], [107, 118], [118, 119]]}
{"doc_key": "ai-dev-304", "ner": [[1, 1, "misc"], [6, 7, "product"], [25, 27, "misc"], [35, 35, "country"], [37, 37, "country"], [39, 39, "country"], [41, 41, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 1, 6, 7, "topic", "", false, false], [35, 35, 25, 27, "type-of", "", false, false], [37, 37, 25, 27, "type-of", "", false, false], [39, 39, 25, 27, "type-of", "", false, false], [41, 41, 25, 27, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Although", "Eurotra", "never", "delivered", "an", "operational", "MT", "system", ",", "the", "project", "had", "a", "considerable", "long", "-", "term", "impact", "on", "the", "nascent", "language", "industries", "in", "the", "EU", "Member", "States", ",", "particularly", "in", "the", "southern", "countries", "of", "Greece", ",", "Italy", ",", "Spain", "and", "Portugal", "."], "sentence-detokenized": "Although Eurotra never delivered an operational MT system, the project had a considerable long-term impact on the nascent language industries in the EU Member States, particularly in the southern countries of Greece, Italy, Spain and Portugal.", "token2charspan": [[0, 8], [9, 16], [17, 22], [23, 32], [33, 35], [36, 47], [48, 50], [51, 57], [57, 58], [59, 62], [63, 70], [71, 74], [75, 76], [77, 89], [90, 94], [94, 95], [95, 99], [100, 106], [107, 109], [110, 113], [114, 121], [122, 130], [131, 141], [142, 144], [145, 148], [149, 151], [152, 158], [159, 165], [165, 166], [167, 179], [180, 182], [183, 186], [187, 195], [196, 205], [206, 208], [209, 215], [215, 216], [217, 222], [222, 223], [224, 229], [230, 233], [234, 242], [242, 243]]}
{"doc_key": "ai-dev-305", "ner": [[0, 1, "algorithm"], [8, 9, "task"], [18, 20, "task"], [22, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 0, 1, "usage", "", true, false], [18, 20, 8, 9, "named", "", false, false], [22, 22, 18, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "autoencoder", "has", "been", "successfully", "applied", "to", "the", "machine", "translation", "of", "human", "languages", ",", "generally", "referred", "to", "as", "neural", "machine", "translation", "(", "NMT", ")", "."], "sentence-detokenized": "The autoencoder has been successfully applied to the machine translation of human languages, generally referred to as neural machine translation (NMT).", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 24], [25, 37], [38, 45], [46, 48], [49, 52], [53, 60], [61, 72], [73, 75], [76, 81], [82, 91], [91, 92], [93, 102], [103, 111], [112, 114], [115, 117], [118, 124], [125, 132], [133, 144], [145, 146], [146, 149], [149, 150], [150, 151]]}
{"doc_key": "ai-dev-306", "ner": [[9, 11, "metrics"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "examples", "of", "probability", "-", "based", "fitness", "functions", "include", "maximum", "likelihood", "estimation", "and", "hinge", "loss", "."], "sentence-detokenized": "Popular examples of probability-based fitness functions include maximum likelihood estimation and hinge loss.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 31], [31, 32], [32, 37], [38, 45], [46, 55], [56, 63], [64, 71], [72, 82], [83, 93], [94, 97], [98, 103], [104, 108], [108, 109]]}
{"doc_key": "ai-dev-307", "ner": [[0, 3, "field"], [12, 15, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 15, 0, 3, "part-of", "", false, false], [17, 18, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "mining", "is", "a", "related", "field", "of", "study", ",", "focusing", "on", "the", "exploratory", "analysis", "of", "data", "through", "unsupervised", "learning", "."], "sentence-detokenized": "Data mining is a related field of study, focusing on the exploratory analysis of data through unsupervised learning.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 33], [34, 39], [39, 40], [41, 49], [50, 52], [53, 56], [57, 68], [69, 77], [78, 80], [81, 85], [86, 93], [94, 106], [107, 115], [115, 116]]}
{"doc_key": "ai-dev-308", "ner": [[0, 1, "algorithm"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "encompasses", "techniques", "for", "matching", "people", "with", "similar", "interests", "and", "creating", "a", "recommendation", "system", "on", "that", "basis", "."], "sentence-detokenized": "Collaborative filtering encompasses techniques for matching people with similar interests and creating a recommendation system on that basis.", "token2charspan": [[0, 13], [14, 23], [24, 35], [36, 46], [47, 50], [51, 59], [60, 66], [67, 71], [72, 79], [80, 89], [90, 93], [94, 102], [103, 104], [105, 119], [120, 126], [127, 129], [130, 134], [135, 140], [140, 141]]}
{"doc_key": "ai-dev-309", "ner": [[3, 8, "algorithm"], [13, 13, "programlang"], [16, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 19, 3, 8, "type-of", "", false, false], [16, 19, 13, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "number", "of", "WordNet", "-", "based", "word", "similarity", "algorithms", "are", "implemented", "in", "a", "Perl", "package", "called", "WordNet", ":", ":", "Similarity", "."], "sentence-detokenized": "A number of WordNet-based word similarity algorithms are implemented in a Perl package called WordNet:: Similarity.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 19], [19, 20], [20, 25], [26, 30], [31, 41], [42, 52], [53, 56], [57, 68], [69, 71], [72, 73], [74, 78], [79, 86], [87, 93], [94, 101], [101, 102], [102, 103], [104, 114], [114, 115]]}
{"doc_key": "ai-dev-310", "ner": [[5, 5, "conference"], [8, 9, "researcher"], [11, 12, "researcher"], [14, 17, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Another", "paper", ",", "presented", "at", "CVPR", "2000", "by", "Erik", "Miller", ",", "Nicholas", "Matsakis", "and", "Paul", "Viola", ",", "will", "also", "be", "discussed", "."], "sentence-detokenized": "Another paper, presented at CVPR 2000 by Erik Miller, Nicholas Matsakis and Paul Viola, will also be discussed.", "token2charspan": [[0, 7], [8, 13], [13, 14], [15, 24], [25, 27], [28, 32], [33, 37], [38, 40], [41, 45], [46, 52], [52, 53], [54, 62], [63, 71], [72, 75], [76, 80], [81, 86], [86, 87], [88, 92], [93, 97], [98, 100], [101, 110], [110, 111]]}
{"doc_key": "ai-dev-311", "ner": [[0, 1, "algorithm"], [7, 11, "misc"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 15, 16, "compare", "", false, false], [15, 16, 7, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["QC", "was", "not", "evaluated", "against", "traditional", "modern", "clustering", "algorithms", ",", "with", "the", "exception", "of", "the", "Jaccard", "index", "."], "sentence-detokenized": "QC was not evaluated against traditional modern clustering algorithms, with the exception of the Jaccard index.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 20], [21, 28], [29, 40], [41, 47], [48, 58], [59, 69], [69, 70], [71, 75], [76, 79], [80, 89], [90, 92], [93, 96], [97, 104], [105, 110], [110, 111]]}
{"doc_key": "ai-dev-312", "ner": [[2, 5, "misc"], [8, 10, "misc"], [15, 16, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 2, 5, "physical", "", false, false], [8, 10, 15, 16, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "the", "VEX", "Robotics", "World", "Championship", ",", "a", "Parade", "of", "Nations", "is", "held", "in", "the", "Freedom", "Hall", ",", "with", "hundreds", "of", "students", "from", "over", "30", "countries", "participating", "."], "sentence-detokenized": "During the VEX Robotics World Championship, a Parade of Nations is held in the Freedom Hall, with hundreds of students from over 30 countries participating.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 23], [24, 29], [30, 42], [42, 43], [44, 45], [46, 52], [53, 55], [56, 63], [64, 66], [67, 71], [72, 74], [75, 78], [79, 86], [87, 91], [91, 92], [93, 97], [98, 106], [107, 109], [110, 118], [119, 123], [124, 128], [129, 131], [132, 141], [142, 155], [155, 156]]}
{"doc_key": "ai-dev-313", "ner": [[5, 8, "metrics"], [10, 10, "metrics"], [13, 15, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 5, 8, "named", "", false, false], [17, 17, 13, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Other", "measures", "of", "accuracy", "include", "Single", "Word", "Error", "Rate", "(", "SWER", ")", "and", "Command", "Success", "Rate", "(", "CSR", ")", "."], "sentence-detokenized": "Other measures of accuracy include Single Word Error Rate (SWER) and Command Success Rate (CSR).", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [27, 34], [35, 41], [42, 46], [47, 52], [53, 57], [58, 59], [59, 63], [63, 64], [65, 68], [69, 76], [77, 84], [85, 89], [90, 91], [91, 94], [94, 95], [95, 96]]}
{"doc_key": "ai-dev-314", "ner": [[7, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "presented", "their", "method", "and", "results", "at", "SIGGRAPH", "2000", "."], "sentence-detokenized": "They presented their method and results at SIGGRAPH 2000.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 27], [28, 31], [32, 39], [40, 42], [43, 51], [52, 56], [56, 57]]}
{"doc_key": "ai-dev-315", "ner": [[0, 2, "conference"], [7, 7, "misc"], [9, 13, "misc"], [18, 20, "conference"], [26, 31, "researcher"], [41, 42, "researcher"], [46, 48, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 7, 7, "origin", "", false, false], [7, 7, 18, 20, "physical", "", false, false], [7, 7, 18, 20, "temporal", "", false, false], [7, 7, 26, 31, "origin", "", false, false], [7, 7, 41, 42, "origin", "", false, false], [9, 13, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "KDD", "conference", "grew", "out", "of", "the", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "workshops", "held", "at", "the", "AAAI", "conferences", ",", "which", "were", "initiated", "by", "Gregory", "I", ".", "Piatetsky", "-", "Shapiro", "in", "1989", ",", "1991", "and", "1993", ",", "and", "by", "Usama", "Fayyad", "in", "1994", ".", "Machinery", "|", "ACM", "."], "sentence-detokenized": "The KDD conference grew out of the KDD (Knowledge Discovery and Data Mining) workshops held at the AAAI conferences, which were initiated by Gregory I. Piatetsky-Shapiro in 1989, 1991 and 1993, and by Usama Fayyad in 1994. Machinery | ACM.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 23], [24, 27], [28, 30], [31, 34], [35, 38], [39, 40], [40, 49], [50, 59], [60, 63], [64, 68], [69, 75], [75, 76], [77, 86], [87, 91], [92, 94], [95, 98], [99, 103], [104, 115], [115, 116], [117, 122], [123, 127], [128, 137], [138, 140], [141, 148], [149, 150], [150, 151], [152, 161], [161, 162], [162, 169], [170, 172], [173, 177], [177, 178], [179, 183], [184, 187], [188, 192], [192, 193], [194, 197], [198, 200], [201, 206], [207, 213], [214, 216], [217, 221], [221, 222], [223, 232], [233, 234], [235, 238], [238, 239]]}
{"doc_key": "ai-dev-316", "ner": [[8, 11, "conference"], [13, 13, "conference"], [17, 22, "organisation"], [24, 24, "organisation"], [28, 32, "conference"], [34, 34, "conference"], [38, 44, "conference"], [46, 46, "conference"], [50, 55, "conference"], [57, 57, "conference"], [61, 66, "conference"], [68, 68, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[13, 13, 8, 11, "named", "", false, false], [24, 24, 17, 22, "named", "", false, false], [34, 34, 28, 32, "named", "", false, false], [46, 46, 38, 44, "named", "", false, false], [57, 57, 50, 55, "named", "", false, false], [68, 68, 61, 66, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "has", "been", "elected", "to", "membership", "in", "the", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "the", "American", "Association", "for", "Advancement", "of", "Science", "(", "AAAS", ")", "and", "the", "Society", "for", "Optics", "and", "Photonics", "Technology", "(", "SPIE", ")", "."], "sentence-detokenized": "He has been elected to membership in the Association for Computing Machinery (ACM), the Institute of Electrical and Electronics Engineers (IEEE), the International Association for Pattern Recognition (IAPR), the Association for the Advancement of Artificial Intelligence (AAAI), the American Association for Advancement of Science (AAAS) and the Society for Optics and Photonics Technology (SPIE).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 22], [23, 33], [34, 36], [37, 40], [41, 52], [53, 56], [57, 66], [67, 76], [77, 78], [78, 81], [81, 82], [82, 83], [84, 87], [88, 97], [98, 100], [101, 111], [112, 115], [116, 127], [128, 137], [138, 139], [139, 143], [143, 144], [144, 145], [146, 149], [150, 163], [164, 175], [176, 179], [180, 187], [188, 199], [200, 201], [201, 205], [205, 206], [206, 207], [208, 211], [212, 223], [224, 227], [228, 231], [232, 243], [244, 246], [247, 257], [258, 270], [271, 272], [272, 276], [276, 277], [277, 278], [279, 282], [283, 291], [292, 303], [304, 307], [308, 319], [320, 322], [323, 330], [331, 332], [332, 336], [336, 337], [338, 341], [342, 345], [346, 353], [354, 357], [358, 364], [365, 368], [369, 378], [379, 389], [390, 391], [391, 395], [395, 396], [396, 397]]}
{"doc_key": "ai-dev-317", "ner": [[0, 1, "field"], [3, 4, "field"], [16, 17, "field"], [32, 33, "field"], [52, 55, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 17, "named", "", false, false], [3, 4, 32, 33, "named", "", false, false], [32, 33, 52, 55, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "and", "data", "mining", "often", "use", "the", "same", "methods", "and", "overlap", "significantly", ",", "but", "whereas", "machine", "learning", "focuses", "on", "prediction", ",", "based", "on", "known", "properties", "learned", "from", "the", "training", "data", ",", "data", "mining", "focuses", "on", "discovering", "(", "previously", ")", "unknown", "properties", "in", "the", "data", "(", "this", "is", "the", "analysis", "stage", "of", "knowledge", "discovery", "in", "databases", ")", "."], "sentence-detokenized": "Machine learning and data mining often use the same methods and overlap significantly, but whereas machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on discovering (previously) unknown properties in the data (this is the analysis stage of knowledge discovery in databases).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 59], [60, 63], [64, 71], [72, 85], [85, 86], [87, 90], [91, 98], [99, 106], [107, 115], [116, 123], [124, 126], [127, 137], [137, 138], [139, 144], [145, 147], [148, 153], [154, 164], [165, 172], [173, 177], [178, 181], [182, 190], [191, 195], [195, 196], [197, 201], [202, 208], [209, 216], [217, 219], [220, 231], [232, 233], [233, 243], [243, 244], [245, 252], [253, 263], [264, 266], [267, 270], [271, 275], [276, 277], [277, 281], [282, 284], [285, 288], [289, 297], [298, 303], [304, 306], [307, 316], [317, 326], [327, 329], [330, 339], [339, 340], [340, 341]]}
{"doc_key": "ai-dev-318", "ner": [[0, 0, "product"], [4, 4, "programlang"], [11, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "general-affiliation", "", false, false], [0, 0, 4, 4, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "is", "written", "in", "Java", "and", "therefore", "runs", "on", "most", "modern", "operating", "systems", "."], "sentence-detokenized": "Indy is written in Java and therefore runs on most modern operating systems.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 23], [24, 27], [28, 37], [38, 42], [43, 45], [46, 50], [51, 57], [58, 67], [68, 75], [75, 76]]}
{"doc_key": "ai-dev-319", "ner": [[0, 0, "algorithm"], [5, 7, "algorithm"], [9, 9, "algorithm"], [15, 17, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 7, "type-of", "", true, false], [9, 9, 5, 7, "named", "", false, false], [15, 17, 5, 7, "type-of", "", true, false], [19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["NMF", "is", "an", "instance", "of", "non-negative", "quadratic", "programming", "(", "NQP", ")", ",", "as", "is", "the", "support", "vector", "machine", "(", "SVM", ")", "."], "sentence-detokenized": "NMF is an instance of non-negative quadratic programming (NQP), as is the support vector machine (SVM).", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 18], [19, 21], [22, 34], [35, 44], [45, 56], [57, 58], [58, 61], [61, 62], [62, 63], [64, 66], [67, 69], [70, 73], [74, 81], [82, 88], [89, 96], [97, 98], [98, 101], [101, 102], [102, 103]]}
{"doc_key": "ai-dev-320", "ner": [[8, 9, "misc"], [12, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 12, 14, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "method", "is", "based", "on", "the", "estimation", "of", "conditional", "probabilities", "using", "the", "non-parametric", "maximum", "likelihood", "method", "which", "leads", "to"], "sentence-detokenized": "The method is based on the estimation of conditional probabilities using the non-parametric maximum likelihood method which leads to", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 26], [27, 37], [38, 40], [41, 52], [53, 66], [67, 72], [73, 76], [77, 91], [92, 99], [100, 110], [111, 117], [118, 123], [124, 129], [130, 132]]}
{"doc_key": "ai-dev-321", "ner": [[7, 7, "algorithm"], [9, 12, "algorithm"], [14, 16, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "basic", "concepts", "of", "spectral", "estimation", "include", "autocorrelation", ",", "multi", "-D", "Fourier", "transform", ",", "mean", "square", "error", "and", "entropy", "."], "sentence-detokenized": "The basic concepts of spectral estimation include autocorrelation, multi-D Fourier transform, mean square error and entropy.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 21], [22, 30], [31, 41], [42, 49], [50, 65], [65, 66], [67, 72], [72, 74], [75, 82], [83, 92], [92, 93], [94, 98], [99, 105], [106, 111], [112, 115], [116, 123], [123, 124]]}
{"doc_key": "ai-dev-322", "ner": [[4, 5, "algorithm"], [10, 10, "field"], [12, 12, "algorithm"], [14, 16, "algorithm"], [18, 19, "task"], [21, 21, "field"], [23, 23, "field"], [25, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[4, 5, 10, 10, "part-of", "", false, false], [4, 5, 12, 12, "part-of", "", false, false], [4, 5, 14, 16, "part-of", "", false, false], [4, 5, 18, 19, "part-of", "", false, false], [4, 5, 21, 21, "part-of", "", false, false], [4, 5, 23, 23, "part-of", "", false, false], [4, 5, 25, 26, "part-of", "", false, false], [4, 5, 28, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "application", "areas", "of", "kernel", "methods", "are", "varied", "and", "include", "geostatistics", ",", "kriging", ",", "inverse", "distance", "weighting", ",", "3D", "reconstruction", ",", "bioinformatics", ",", "chemoinformatics", ",", "information", "extraction", "and", "handwriting", "recognition", "."], "sentence-detokenized": "The application areas of kernel methods are varied and include geostatistics, kriging, inverse distance weighting, 3D reconstruction, bioinformatics, chemoinformatics, information extraction and handwriting recognition.", "token2charspan": [[0, 3], [4, 15], [16, 21], [22, 24], [25, 31], [32, 39], [40, 43], [44, 50], [51, 54], [55, 62], [63, 76], [76, 77], [78, 85], [85, 86], [87, 94], [95, 103], [104, 113], [113, 114], [115, 117], [118, 132], [132, 133], [134, 148], [148, 149], [150, 166], [166, 167], [168, 179], [180, 190], [191, 194], [195, 206], [207, 218], [218, 219]]}
{"doc_key": "ai-dev-323", "ner": [[12, 12, "organisation"], [16, 20, "product"], [14, 14, "product"], [23, 27, "organisation"], [28, 31, "product"], [25, 25, "product"], [34, 34, "product"], [37, 37, "product"], [40, 42, "product"], [44, 46, "product"], [50, 51, "product"], [53, 53, "product"], [56, 62, "product"], [66, 68, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[16, 20, 12, 12, "artifact", "", false, false], [16, 20, 34, 34, "compare", "", false, false], [16, 20, 37, 37, "compare", "", false, false], [16, 20, 40, 42, "compare", "", false, false], [16, 20, 44, 46, "compare", "", false, false], [16, 20, 50, 51, "compare", "", false, false], [16, 20, 53, 53, "compare", "", false, false], [16, 20, 56, 62, "compare", "", false, false], [16, 20, 66, 68, "compare", "", false, false], [14, 14, 16, 20, "named", "", false, false], [28, 31, 23, 27, "artifact", "", false, false], [28, 31, 34, 34, "compare", "", false, false], [28, 31, 37, 37, "compare", "", false, false], [28, 31, 40, 42, "compare", "", false, false], [28, 31, 44, 46, "compare", "", false, false], [28, 31, 50, 51, "compare", "", false, false], [28, 31, 53, 53, "compare", "", false, false], [28, 31, 56, 62, "compare", "", false, false], [28, 31, 66, 68, "compare", "", false, false], [25, 25, 28, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Robots", "can", "be", "autonomous", "or", "semi-autonomous", "and", "range", "from", "humanoids", "such", "as", "Honda", "'s", "ASIMO", "(", "Advanced", "Step", "in", "Innovative", "Mobility", ")", "and", "TOSY", "'s", "TOPIO", "(", "TOSY", "Ping", "Pong", "Playing", "Robot", ")", "to", "industrial", "robots", ",", "medical", "robots", ",", "patient", "assistance", "robots", ",", "canine", "therapy", "robots", ",", "collectively", "programmed", "swarm", "robots", ",", "drones", "such", "as", "General", "Atomics", "'", "MQ", "-", "1", "Predator", ",", "and", "even", "microscopic", "nano", "robots", "."], "sentence-detokenized": "Robots can be autonomous or semi-autonomous and range from humanoids such as Honda's ASIMO (Advanced Step in Innovative Mobility) and TOSY's TOPIO (TOSY Ping Pong Playing Robot) to industrial robots, medical robots, patient assistance robots, canine therapy robots, collectively programmed swarm robots, drones such as General Atomics' MQ-1 Predator, and even microscopic nano robots.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 24], [25, 27], [28, 43], [44, 47], [48, 53], [54, 58], [59, 68], [69, 73], [74, 76], [77, 82], [82, 84], [85, 90], [91, 92], [92, 100], [101, 105], [106, 108], [109, 119], [120, 128], [128, 129], [130, 133], [134, 138], [138, 140], [141, 146], [147, 148], [148, 152], [153, 157], [158, 162], [163, 170], [171, 176], [176, 177], [178, 180], [181, 191], [192, 198], [198, 199], [200, 207], [208, 214], [214, 215], [216, 223], [224, 234], [235, 241], [241, 242], [243, 249], [250, 257], [258, 264], [264, 265], [266, 278], [279, 289], [290, 295], [296, 302], [302, 303], [304, 310], [311, 315], [316, 318], [319, 326], [327, 334], [334, 335], [336, 338], [338, 339], [339, 340], [341, 349], [349, 350], [351, 354], [355, 359], [360, 371], [372, 376], [377, 383], [383, 384]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 3, "product"], [9, 15, "university"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 17, 18, "artifact", "", false, false], [0, 0, 20, 21, "artifact", "", false, false], [0, 0, 23, 24, "artifact", "", false, false], [0, 0, 26, 27, "artifact", "", false, false], [2, 3, 17, 18, "artifact", "", false, false], [2, 3, 20, 21, "artifact", "", false, false], [2, 3, 23, 24, "artifact", "", false, false], [2, 3, 26, 27, "artifact", "", false, false], [17, 18, 9, 15, "physical", "", false, false], [20, 21, 9, 15, "physical", "", false, false], [23, 24, 9, 15, "physical", "", false, false], [26, 27, 9, 15, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "and", "Freddy", "II", "were", "robots", "built", "at", "the", "University", "of", "Edinburgh", "'s", "School", "of", "Computing", "by", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "and", "Donald", "Mitchie", ",", "and", "were", "capable", "of", "assembling", "wooden", "blocks", "in", "several", "hours", "."], "sentence-detokenized": "Freddy and Freddy II were robots built at the University of Edinburgh's School of Computing by Pat Ambler, Robin Popplestone, Austin Tate and Donald Mitchie, and were capable of assembling wooden blocks in several hours.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 25], [26, 32], [33, 38], [39, 41], [42, 45], [46, 56], [57, 59], [60, 69], [69, 71], [72, 78], [79, 81], [82, 91], [92, 94], [95, 98], [99, 105], [105, 106], [107, 112], [113, 124], [124, 125], [126, 132], [133, 137], [138, 141], [142, 148], [149, 156], [156, 157], [158, 161], [162, 166], [167, 174], [175, 177], [178, 188], [189, 195], [196, 202], [203, 205], [206, 213], [214, 219], [219, 220]]}
{"doc_key": "ai-dev-325", "ner": [[5, 5, "location"], [7, 7, "country"], [15, 17, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 7, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "spent", "his", "childhood", "in", "Paris", ",", "France", ",", "where", "his", "parents", "had", "emigrated", "from", "Lithuania", "in", "the", "early", "1920s", "."], "sentence-detokenized": "He spent his childhood in Paris, France, where his parents had emigrated from Lithuania in the early 1920s.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 22], [23, 25], [26, 31], [31, 32], [33, 39], [39, 40], [41, 46], [47, 50], [51, 58], [59, 62], [63, 72], [73, 77], [78, 87], [88, 90], [91, 94], [95, 100], [101, 106], [106, 107]]}
{"doc_key": "ai-dev-326", "ner": [[2, 3, "researcher"], [6, 9, "misc"], [12, 15, "organisation"], [17, 19, "university"], [29, 34, "university"], [41, 43, "university"], [46, 49, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 3, 6, 9, "role", "", false, false], [2, 3, 17, 19, "physical", "", false, false], [2, 3, 29, 34, "role", "", false, false], [2, 3, 41, 43, "role", "", false, false], [2, 3, 46, 49, "role", "", false, false], [6, 9, 12, 15, "part-of", "", false, false], [12, 15, 17, 19, "part-of", "", false, false], [41, 43, 29, 34, "part-of", "", false, false], [46, 49, 29, 34, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Previously", ",", "Dr.", "Paulos", "held", "the", "Cooper-", "Siegel", "Associate", "Professorship", "in", "the", "School", "of", "Computer", "Science", "at", "Carnegie", "Mellon", "University", ",", "where", "he", "was", "a", "faculty", "member", "in", "the", "Institute", "for", "Human", "-", "Computer", "Interaction", "and", "a", "faculty", "member", "in", "the", "Institute", "for", "Robotics", "and", "the", "Center", "for", "Entertainment", "Technology", "."], "sentence-detokenized": "Previously, Dr. Paulos held the Cooper-Siegel Associate Professorship in the School of Computer Science at Carnegie Mellon University, where he was a faculty member in the Institute for Human-Computer Interaction and a faculty member in the Institute for Robotics and the Center for Entertainment Technology.", "token2charspan": [[0, 10], [10, 11], [12, 15], [16, 22], [23, 27], [28, 31], [32, 39], [39, 45], [46, 55], [56, 69], [70, 72], [73, 76], [77, 83], [84, 86], [87, 95], [96, 103], [104, 106], [107, 115], [116, 122], [123, 133], [133, 134], [135, 140], [141, 143], [144, 147], [148, 149], [150, 157], [158, 164], [165, 167], [168, 171], [172, 181], [182, 185], [186, 191], [191, 192], [192, 200], [201, 212], [213, 216], [217, 218], [219, 226], [227, 233], [234, 236], [237, 240], [241, 250], [251, 254], [255, 263], [264, 267], [268, 271], [272, 278], [279, 282], [283, 296], [297, 307], [307, 308]]}
{"doc_key": "ai-dev-327", "ner": [[3, 4, "researcher"], [6, 7, "university"], [10, 11, "product"], [14, 22, "product"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 6, 7, "physical", "", false, false], [3, 4, 6, 7, "role", "", false, false], [10, 11, 3, 4, "artifact", "", false, false], [10, 11, 14, 22, "type-of", "", false, false], [10, 11, 27, 28, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1969", ",", "Victor", "Scheinman", "of", "Stanford", "University", "invented", "the", "Stanford", "Arm", ",", "a", "6", "-", "axis", ",", "all", "-", "electric", "articulated", "robot", "designed", "to", "provide", "an", "arm", "solution", "."], "sentence-detokenized": "In 1969, Victor Scheinman of Stanford University invented the Stanford Arm, a 6-axis, all-electric articulated robot designed to provide an arm solution.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 25], [26, 28], [29, 37], [38, 48], [49, 57], [58, 61], [62, 70], [71, 74], [74, 75], [76, 77], [78, 79], [79, 80], [80, 84], [84, 85], [86, 89], [89, 90], [90, 98], [99, 110], [111, 116], [117, 125], [126, 128], [129, 136], [137, 139], [140, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-dev-328", "ner": [[5, 5, "product"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 15, 16, "related-to", "", false, false], [5, 5, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "creation", "and", "implementation", "of", "chatbots", "is", "still", "a", "developing", "field", ",", "strongly", "linked", "to", "artificial", "intelligence", "and", "machine", "learning", ",", "so", "the", "solutions", "provided", ",", "while", "having", "obvious", "advantages", ",", "have", "significant", "limitations", "in", "terms", "of", "functionality", "and", "use", "cases", "."], "sentence-detokenized": "The creation and implementation of chatbots is still a developing field, strongly linked to artificial intelligence and machine learning, so the solutions provided, while having obvious advantages, have significant limitations in terms of functionality and use cases.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 31], [32, 34], [35, 43], [44, 46], [47, 52], [53, 54], [55, 65], [66, 71], [71, 72], [73, 81], [82, 88], [89, 91], [92, 102], [103, 115], [116, 119], [120, 127], [128, 136], [136, 137], [138, 140], [141, 144], [145, 154], [155, 163], [163, 164], [165, 170], [171, 177], [178, 185], [186, 196], [196, 197], [198, 202], [203, 214], [215, 226], [227, 229], [230, 235], [236, 238], [239, 252], [253, 256], [257, 260], [261, 266], [266, 267]]}
{"doc_key": "ai-dev-329", "ner": [[11, 13, "university"], [8, 9, "product"], [22, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 11, 13, "part-of", "", true, false], [22, 23, 8, 9, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "terms", "of", "freely", "available", "resources", ",", "the", "Sphinx", "toolkit", "from", "Carnegie", "Mellon", "University", "is", "a", "good", "place", "to", "start", "learning", "about", "speech", "recognition", "and", "start", "experimenting", "."], "sentence-detokenized": "In terms of freely available resources, the Sphinx toolkit from Carnegie Mellon University is a good place to start learning about speech recognition and start experimenting.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 18], [19, 28], [29, 38], [38, 39], [40, 43], [44, 50], [51, 58], [59, 63], [64, 72], [73, 79], [80, 90], [91, 93], [94, 95], [96, 100], [101, 106], [107, 109], [110, 115], [116, 124], [125, 130], [131, 137], [138, 149], [150, 153], [154, 159], [160, 173], [173, 174]]}
{"doc_key": "ai-dev-330", "ner": [[0, 4, "misc"], [13, 21, "misc"], [9, 18, "misc"], [24, 24, "university"], [26, 26, "location"], [28, 28, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 4, 13, 21, "temporal", "", false, false], [9, 18, 13, 21, "named", "", false, false], [9, 18, 26, 26, "physical", "", false, false], [24, 24, 9, 18, "role", "", false, false], [26, 26, 28, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "official", "RoboCup", "competition", "was", "preceded", "by", "the", "first", ",", "often", "overlooked", ",", "International", "MicroRobot", "World", "Cup", "(", "MIROSOT", ")", "football", "tournament", "organised", "by", "KAIST", "in", "Taejon", ",", "Korea", ",", "in", "November", "1996", "."], "sentence-detokenized": "The official RoboCup competition was preceded by the first, often overlooked, International MicroRobot World Cup (MIROSOT) football tournament organised by KAIST in Taejon, Korea, in November 1996.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 32], [33, 36], [37, 45], [46, 48], [49, 52], [53, 58], [58, 59], [60, 65], [66, 76], [76, 77], [78, 91], [92, 102], [103, 108], [109, 112], [113, 114], [114, 121], [121, 122], [123, 131], [132, 142], [143, 152], [153, 155], [156, 161], [162, 164], [165, 171], [171, 172], [173, 178], [178, 179], [180, 182], [183, 191], [192, 196], [196, 197]]}
{"doc_key": "ai-dev-331", "ner": [[5, 6, "metrics"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "standard", "hinge", "loss", "math", "(", "1-", "yf", "(", "x", ")", ")", "_", "+", "/", "math", "for", "labelled", "data", ",", "a", "loss", "function", "math", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "math", "is", "introduced", "on", "unlabelled", "data", "by", "letting", "mathy", "=", "operator", "name", "{", "sign", "}", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "In addition to the standard hinge loss math (1-yf (x)) _ + / math for labelled data, a loss function math (-1 | f (x) |) _ + / math is introduced on unlabelled data by letting mathy = operator name {sign} {f (x)} / math.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 27], [28, 33], [34, 38], [39, 43], [44, 45], [45, 47], [47, 49], [50, 51], [51, 52], [52, 53], [53, 54], [55, 56], [57, 58], [59, 60], [61, 65], [66, 69], [70, 78], [79, 83], [83, 84], [85, 86], [87, 91], [92, 100], [101, 105], [106, 107], [107, 108], [108, 109], [110, 111], [112, 113], [114, 115], [115, 116], [116, 117], [118, 119], [119, 120], [121, 122], [123, 124], [125, 126], [127, 131], [132, 134], [135, 145], [146, 148], [149, 159], [160, 164], [165, 167], [168, 175], [176, 181], [182, 183], [184, 192], [193, 197], [198, 199], [199, 203], [203, 204], [205, 206], [206, 207], [208, 209], [209, 210], [210, 211], [211, 212], [213, 214], [215, 219], [219, 220]]}
{"doc_key": "ai-dev-332", "ner": [[3, 3, "misc"], [9, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 9, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "particular", ",", "RLS", "is", "designed", "to", "minimise", "the", "mean", "square", "error", "between", "predicted", "values", "and", "TRUE", "labels", ",", "subject", "to", "regularisation", "."], "sentence-detokenized": "In particular, RLS is designed to minimise the mean square error between predicted values and TRUE labels, subject to regularisation.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 21], [22, 30], [31, 33], [34, 42], [43, 46], [47, 51], [52, 58], [59, 64], [65, 72], [73, 82], [83, 89], [90, 93], [94, 98], [99, 105], [105, 106], [107, 114], [115, 117], [118, 132], [132, 133]]}
{"doc_key": "ai-dev-333", "ner": [[4, 6, "algorithm"], [9, 10, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Essentially", ",", "this", "combines", "maximum", "likelihood", "estimation", "with", "a", "regularisation", "procedure", "that", "favours", "simpler", "models", "over", "more", "complex", "ones", "."], "sentence-detokenized": "Essentially, this combines maximum likelihood estimation with a regularisation procedure that favours simpler models over more complex ones.", "token2charspan": [[0, 11], [11, 12], [13, 17], [18, 26], [27, 34], [35, 45], [46, 56], [57, 61], [62, 63], [64, 78], [79, 88], [89, 93], [94, 101], [102, 109], [110, 116], [117, 121], [122, 126], [127, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-dev-334", "ner": [[1, 4, "metrics"], [10, 10, "metrics"], [12, 12, "metrics"], [15, 17, "misc"], [20, 21, "misc"], [35, 37, "algorithm"], [40, 43, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 10, 1, 4, "named", "", false, false], [12, 12, 1, 4, "named", "", false, false], [15, 17, 20, 21, "related-to", "", false, false], [15, 17, 35, 37, "related-to", "ratio", false, false], [35, 37, 40, 43, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "true", "positive", "rate", "is", "also", "referred", "to", "as", "the", "sensitivity", ",", "recall", "or", "mathematical", "probability", "of", "detection", "at", "the", "discrimination", "threshold", ")", "of", "the", "probability", "of", "detection", "on", "the", "y", "-axis", "relative", "to", "the", "cumulative", "distribution", "function", "of", "the", "probability", "of", "false", "alarm", "on", "the", "x-", "axis", "."], "sentence-detokenized": "The true positive rate is also referred to as the sensitivity, recall or mathematical probability of detection at the discrimination threshold) of the probability of detection on the y-axis relative to the cumulative distribution function of the probability of false alarm on the x-axis.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 25], [26, 30], [31, 39], [40, 42], [43, 45], [46, 49], [50, 61], [61, 62], [63, 69], [70, 72], [73, 85], [86, 97], [98, 100], [101, 110], [111, 113], [114, 117], [118, 132], [133, 142], [142, 143], [144, 146], [147, 150], [151, 162], [163, 165], [166, 175], [176, 178], [179, 182], [183, 184], [184, 189], [190, 198], [199, 201], [202, 205], [206, 216], [217, 229], [230, 238], [239, 241], [242, 245], [246, 257], [258, 260], [261, 266], [267, 272], [273, 275], [276, 279], [280, 282], [282, 286], [286, 287]]}
{"doc_key": "ai-dev-335", "ner": [[3, 3, "misc"], [0, 1, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 3, 3, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Word", "Net", "is", "an", "example", "of", "a", "semantic", "network", "."], "sentence-detokenized": "WordNet is an example of a semantic network.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 13], [14, 21], [22, 24], [25, 26], [27, 35], [36, 43], [43, 44]]}
{"doc_key": "ai-dev-336", "ner": [[3, 5, "product"], [9, 10, "product"], [23, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 26, 3, 5, "usage", "", false, false], [23, 26, 9, 10, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolonged", "use", "of", "speech", "recognition", "software", "in", "combination", "with", "word", "processing", "has", "shown", "benefits", "for", "short", "-", "term", "memory", "enhancement", "in", "patients", "with", "cerebral", "AVMs", "who", "have", "been", "treated", "by", "resection", "."], "sentence-detokenized": "Prolonged use of speech recognition software in combination with word processing has shown benefits for short-term memory enhancement in patients with cerebral AVMs who have been treated by resection.", "token2charspan": [[0, 9], [10, 13], [14, 16], [17, 23], [24, 35], [36, 44], [45, 47], [48, 59], [60, 64], [65, 69], [70, 80], [81, 84], [85, 90], [91, 99], [100, 103], [104, 109], [109, 110], [110, 114], [115, 121], [122, 133], [134, 136], [137, 145], [146, 150], [151, 159], [160, 164], [165, 168], [169, 173], [174, 178], [179, 186], [187, 189], [190, 199], [199, 200]]}
{"doc_key": "ai-dev-337", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Its", "founding", "editors", "were", "Ron", "Sun", ",", "Vasant", "Honavar", "and", "Gregg", "Oden", "(", "from", "1999", "to", "2014", ")", "."], "sentence-detokenized": "Its founding editors were Ron Sun, Vasant Honavar and Gregg Oden (from 1999 to 2014).", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 25], [26, 29], [30, 33], [33, 34], [35, 41], [42, 49], [50, 53], [54, 59], [60, 64], [65, 66], [66, 70], [71, 75], [76, 78], [79, 83], [83, 84], [84, 85]]}
{"doc_key": "ai-dev-338", "ner": [[10, 11, "product"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 16, 17, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Their", "\"", "parallel", "\"", "distinction", ",", "as", "opposed", "to", "a", "serial", "manipulator", ",", "is", "that", "the", "end", "effector", "(", "or", "\"", "hand", "\"", ")", "of", "this", "link", "(", "or", "\"", "arm", "\"", ")", "is", "directly", "connected", "to", "it", "s", "base", "by", "a", "number", "(", "usually", "three", "or", "six", ")", "of", "separate", "and", "independent", "links", "operating", "simultaneously", "."], "sentence-detokenized": "Their \"parallel\" distinction, as opposed to a serial manipulator, is that the end effector (or \"hand\") of this link (or \"arm\") is directly connected to its base by a number (usually three or six) of separate and independent links operating simultaneously.", "token2charspan": [[0, 5], [6, 7], [7, 15], [15, 16], [17, 28], [28, 29], [30, 32], [33, 40], [41, 43], [44, 45], [46, 52], [53, 64], [64, 65], [66, 68], [69, 73], [74, 77], [78, 81], [82, 90], [91, 92], [92, 94], [95, 96], [96, 100], [100, 101], [101, 102], [103, 105], [106, 110], [111, 115], [116, 117], [117, 119], [120, 121], [121, 124], [124, 125], [125, 126], [127, 129], [130, 138], [139, 148], [149, 151], [152, 154], [154, 155], [156, 160], [161, 163], [164, 165], [166, 172], [173, 174], [174, 181], [182, 187], [188, 190], [191, 194], [194, 195], [196, 198], [199, 207], [208, 211], [212, 223], [224, 229], [230, 239], [240, 254], [254, 255]]}
{"doc_key": "ai-dev-339", "ner": [[5, 6, "researcher"], [17, 18, "researcher"], [19, 21, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "thesis", "supervisor", "was", "Professor", "Cordell", "Green", ",", "and", "his", "thesis", "/", "oral", "committee", "consisted", "of", "Professors", "Edward", "Feigenbaum", ",", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", ",", "Herbert", "Simon", "."], "sentence-detokenized": "His thesis supervisor was Professor Cordell Green, and his thesis/oral committee consisted of Professors Edward Feigenbaum, Joshua Lederberg, Paul Cohen, Allen Newell, Herbert Simon.", "token2charspan": [[0, 3], [4, 10], [11, 21], [22, 25], [26, 35], [36, 43], [44, 49], [49, 50], [51, 54], [55, 58], [59, 65], [65, 66], [66, 70], [71, 80], [81, 90], [91, 93], [94, 104], [105, 111], [112, 122], [122, 123], [124, 130], [131, 140], [140, 141], [142, 146], [147, 152], [152, 153], [154, 159], [160, 166], [166, 167], [168, 175], [176, 181], [181, 182]]}
{"doc_key": "ai-dev-340", "ner": [[3, 5, "metrics"], [7, 10, "metrics"], [12, 14, "metrics"], [16, 18, "metrics"], [20, 23, "metrics"], [25, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "functions", "include", "mean", "square", "error", ",", "root", "mean", "square", "error", ",", "mean", "absolute", "error", ",", "relative", "square", "error", ",", "relative", "root", "square", "error", ",", "relative", "absolute", "error", ",", "and", "others", "."], "sentence-detokenized": "These functions include mean square error, root mean square error, mean absolute error, relative square error, relative root square error, relative absolute error, and others.", "token2charspan": [[0, 5], [6, 15], [16, 23], [24, 28], [29, 35], [36, 41], [41, 42], [43, 47], [48, 52], [53, 59], [60, 65], [65, 66], [67, 71], [72, 80], [81, 86], [86, 87], [88, 96], [97, 103], [104, 109], [109, 110], [111, 119], [120, 124], [125, 131], [132, 137], [137, 138], [139, 147], [148, 156], [157, 162], [162, 163], [164, 167], [168, 174], [174, 175]]}
{"doc_key": "ai-dev-341", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "links", "in", "Python", ",", "Java", "and", "MATLAB", "/", "OCTAVE", "."], "sentence-detokenized": "There are links in Python, Java and MATLAB / OCTAVE.", "token2charspan": [[0, 5], [6, 9], [10, 15], [16, 18], [19, 25], [25, 26], [27, 31], [32, 35], [36, 42], [43, 44], [45, 51], [51, 52]]}
{"doc_key": "ai-dev-342", "ner": [[3, 3, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "implementation", "in", "MATLAB", "can", "be", "found", "on", "the", "website", "."], "sentence-detokenized": "An implementation in MATLAB can be found on the website.", "token2charspan": [[0, 2], [3, 17], [18, 20], [21, 27], [28, 31], [32, 34], [35, 40], [41, 43], [44, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-dev-343", "ner": [[0, 1, "researcher"], [9, 10, "field"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 10, 0, 1, "origin", "", false, false], [9, 10, 14, 15, "origin", "", false, false], [9, 10, 17, 18, "origin", "", false, false], [9, 10, 20, 21, "origin", "", false, false], [9, 10, 23, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "is", "one", "of", "the", "founding", "fathers", "of", "artificial", "intelligence", ",", "along", "with", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", "and", "Herbert", "A", ".", "Simon", "."], "sentence-detokenized": "John McCarthy is one of the founding fathers of artificial intelligence, along with Alan Turing, Marvin Minsky, Allen Newell and Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 36], [37, 44], [45, 47], [48, 58], [59, 71], [71, 72], [73, 78], [79, 83], [84, 88], [89, 95], [95, 96], [97, 103], [104, 110], [110, 111], [112, 117], [118, 124], [125, 128], [129, 136], [137, 138], [138, 139], [140, 145], [145, 146]]}
{"doc_key": "ai-dev-344", "ner": [[10, 12, "product"], [20, 21, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "parallel", "manipulator", "is", "a", "mechanical", "system", "that", "uses", "several", "manipulators", "in", "series", "to", "support", "a", "single", "platform", ",", "or", "end", "effector", "."], "sentence-detokenized": "A parallel manipulator is a mechanical system that uses several manipulators in series to support a single platform, or end effector.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 27], [28, 38], [39, 45], [46, 50], [51, 55], [56, 63], [64, 76], [77, 79], [80, 86], [87, 89], [90, 97], [98, 99], [100, 106], [107, 115], [115, 116], [117, 119], [120, 123], [124, 132], [132, 133]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [3, 4, "task"], [7, 7, "product"], [9, 15, "product"], [26, 26, "misc"], [29, 29, "misc"], [32, 33, "misc"], [36, 41, "task"], [44, 47, "product"], [50, 51, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 7, 0, 0, "part-of", "", false, false], [7, 7, 3, 4, "type-of", "", false, false], [9, 15, 7, 7, "named", "", false, false], [26, 26, 7, 7, "part-of", "", false, false], [29, 29, 7, 7, "part-of", "", false, false], [32, 33, 7, 7, "part-of", "", false, false], [36, 41, 7, 7, "part-of", "", false, false], [44, 47, 7, 7, "part-of", "", false, false], [50, 51, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "includes", "an", "information", "extraction", "system", "called", "ANNIE", "(", "A", "Nearly", "-", "New", "Information", "Extraction", "System", ")", ",", "which", "is", "a", "set", "of", "modules", "including", "a", "tokenizer", ",", "a", "gazetteer", ",", "a", "sentence", "separator", ",", "a", "part", "-", "of", "-", "speech", "tagging", ",", "a", "named", "entity", "recognition", "transducer", "and", "a", "coreference", "tagger", "."], "sentence-detokenized": "GATE includes an information extraction system called ANNIE (A Nearly-New Information Extraction System), which is a set of modules including a tokenizer, a gazetteer, a sentence separator, a part-of-speech tagging, a named entity recognition transducer and a coreference tagger.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 28], [29, 39], [40, 46], [47, 53], [54, 59], [60, 61], [61, 62], [63, 69], [69, 70], [70, 73], [74, 85], [86, 96], [97, 103], [103, 104], [104, 105], [106, 111], [112, 114], [115, 116], [117, 120], [121, 123], [124, 131], [132, 141], [142, 143], [144, 153], [153, 154], [155, 156], [157, 166], [166, 167], [168, 169], [170, 178], [179, 188], [188, 189], [190, 191], [192, 196], [196, 197], [197, 199], [199, 200], [200, 206], [207, 214], [214, 215], [216, 217], [218, 223], [224, 230], [231, 242], [243, 253], [254, 257], [258, 259], [260, 271], [272, 278], [278, 279]]}
{"doc_key": "ai-dev-346", "ner": [[3, 5, "university"], [14, 15, "country"], [22, 25, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "graduated", "from", "Moscow", "State", "University", "and", "in", "November", "1978", "he", "left", "for", "the", "United", "States", "thanks", "to", "the", "personal", "intervention", "of", "Senator", "Edward", "M.", "Kennedy", "."], "sentence-detokenized": "He graduated from Moscow State University and in November 1978 he left for the United States thanks to the personal intervention of Senator Edward M. Kennedy .", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 24], [25, 30], [31, 41], [42, 45], [46, 48], [49, 57], [58, 62], [63, 65], [66, 70], [71, 74], [75, 78], [79, 85], [86, 92], [93, 99], [100, 102], [103, 106], [107, 115], [116, 128], [129, 131], [132, 139], [140, 146], [147, 149], [150, 157], [158, 159]]}
{"doc_key": "ai-dev-347", "ner": [[4, 7, "organisation"], [10, 16, "misc"], [21, 21, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 7, 10, 16, "win-defeat", "", false, false], [10, 16, 21, 21, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "the", "DeepMind", "AlphaGo", "team", "was", "awarded", "the", "first", "Marvin", "Minsky", "Medal", "by", "the", "IJCAI", "for", "outstanding", "achievements", "in", "AI", "."], "sentence-detokenized": "In 2017, the DeepMind AlphaGo team was awarded the first Marvin Minsky Medal by the IJCAI for outstanding achievements in AI.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 21], [22, 29], [30, 34], [35, 38], [39, 46], [47, 50], [51, 56], [57, 63], [64, 70], [71, 76], [77, 79], [80, 83], [84, 89], [90, 93], [94, 105], [106, 118], [119, 121], [122, 124], [124, 125]]}
{"doc_key": "ai-dev-348", "ner": [[0, 2, "misc"], [6, 6, "misc"], [11, 11, "misc"], [19, 20, "misc"], [25, 25, "misc"], [30, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 6, 6, "related-to", "is_recorded_by", false, false], [6, 6, 11, 11, "cause-effect", "", false, false], [6, 6, 11, 11, "physical", "", false, false], [6, 6, 19, 20, "physical", "", false, false], [6, 6, 30, 30, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Abnormal", "propagation", "is", "also", "recorded", "by", "troposcatters", "causing", "irregularities", "in", "the", "troposphere", ",", "scattering", "from", "meteors", ",", "refraction", "in", "ionised", "regions", "and", "layers", "of", "the", "ionosphere", "and", "reflection", "from", "the", "ionosphere", "."], "sentence-detokenized": "Abnormal propagation is also recorded by troposcatters causing irregularities in the troposphere, scattering from meteors, refraction in ionised regions and layers of the ionosphere and reflection from the ionosphere.", "token2charspan": [[0, 8], [9, 20], [21, 23], [24, 28], [29, 37], [38, 40], [41, 54], [55, 62], [63, 77], [78, 80], [81, 84], [85, 96], [96, 97], [98, 108], [109, 113], [114, 121], [121, 122], [123, 133], [134, 136], [137, 144], [145, 152], [153, 156], [157, 163], [164, 166], [167, 170], [171, 181], [182, 185], [186, 196], [197, 201], [202, 205], [206, 216], [216, 217]]}
{"doc_key": "ai-dev-349", "ner": [[0, 2, "field"], [4, 7, "field"], [10, 10, "field"], [12, 13, "field"], [15, 16, "field"], [18, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 10, 10, "part-of", "", false, false], [0, 2, 12, 13, "part-of", "", false, false], [0, 2, 15, 16, "part-of", "", false, false], [0, 2, 18, 21, "part-of", "", false, false], [4, 7, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Natural", "Language", "Processing", "(", "NLP", ")", "is", "a", "sub-field", "of", "linguistics", ",", "computer", "science", ",", "information", "engineering", "and", "artificial", "intelligence", "concerned", "with", "the", "interaction", "between", "computers", "and", "human", "(", "natural", ")", "languages", ",", "in", "particular", "how", "to", "program", "computers", "to", "process", "and", "analyse", "large", "amounts", "of", "natural", "language", "data", "."], "sentence-detokenized": "Natural Language Processing (NLP) is a sub-field of linguistics, computer science, information engineering and artificial intelligence concerned with the interaction between computers and human (natural) languages, in particular how to program computers to process and analyse large amounts of natural language data.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [29, 32], [32, 33], [34, 36], [37, 38], [39, 48], [49, 51], [52, 63], [63, 64], [65, 73], [74, 81], [81, 82], [83, 94], [95, 106], [107, 110], [111, 121], [122, 134], [135, 144], [145, 149], [150, 153], [154, 165], [166, 173], [174, 183], [184, 187], [188, 193], [194, 195], [195, 202], [202, 203], [204, 213], [213, 214], [215, 217], [218, 228], [229, 232], [233, 235], [236, 243], [244, 253], [254, 256], [257, 264], [265, 268], [269, 276], [277, 282], [283, 290], [291, 293], [294, 301], [302, 310], [311, 315], [315, 316]]}
{"doc_key": "ai-dev-350", "ner": [[5, 6, "organisation"], [9, 10, "organisation"], [12, 13, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "youth", "climate", "groups", "include", "Extinction", "Rebellion", ",", "the", "Sunrise", "Movement", ",", "SustainUS", "and", "other", "groups", "working", "at", "transnational", "and", "local", "levels", "."], "sentence-detokenized": "Other youth climate groups include Extinction Rebellion, the Sunrise Movement, SustainUS and other groups working at transnational and local levels.", "token2charspan": [[0, 5], [6, 11], [12, 19], [20, 26], [27, 34], [35, 45], [46, 55], [55, 56], [57, 60], [61, 68], [69, 77], [77, 78], [79, 88], [89, 92], [93, 98], [99, 105], [106, 113], [114, 116], [117, 130], [131, 134], [135, 140], [141, 147], [147, 148]]}
