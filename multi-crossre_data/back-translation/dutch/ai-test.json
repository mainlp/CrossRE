{"doc_key": "ai-test-1", "ner": [[5, 7, "algorithm"], [9, 9, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "generative", "modelling", "approaches", "include", "naive", "Bayes", "classifiers", ",", "Gaussian", "mixture", "models", "and", "variational", "autoencoders", "."], "sentence-detokenized": "Typical generative modelling approaches include naive Bayes classifiers, Gaussian mixture models and variational autoencoders.", "token2charspan": [[0, 7], [8, 18], [19, 28], [29, 39], [40, 47], [48, 53], [54, 59], [60, 71], [71, 72], [73, 81], [82, 89], [90, 96], [97, 100], [101, 112], [113, 125], [125, 126]]}
{"doc_key": "ai-test-2", "ner": [[5, 5, "organisation"], [10, 10, "conference"], [13, 18, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 10, 10, "role", "", false, false], [13, 18, 10, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Finally", ",", "every", "other", "year", "ELRA", "organises", "a", "major", "conference", "LREC", ",", "the", "International", "Language", "Resources", "and", "Evaluation", "Conference", "."], "sentence-detokenized": "Finally, every other year ELRA organises a major conference LREC, the International Language Resources and Evaluation Conference.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 20], [21, 25], [26, 30], [31, 40], [41, 42], [43, 48], [49, 59], [60, 64], [64, 65], [66, 69], [70, 83], [84, 92], [93, 102], [103, 106], [107, 117], [118, 128], [128, 129]]}
{"doc_key": "ai-test-3", "ner": [[7, 9, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "task", "is", "usually", "to", "derive", "the", "maximum", "likelihood", "estimate", "of", "the", "parameters", "of", "the", "HMM", ",", "given", "the", "output", "series", "."], "sentence-detokenized": "The task is usually to derive the maximum likelihood estimate of the parameters of the HMM, given the output series.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 22], [23, 29], [30, 33], [34, 41], [42, 52], [53, 61], [62, 64], [65, 68], [69, 79], [80, 82], [83, 86], [87, 90], [90, 91], [92, 97], [98, 101], [102, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-4", "ner": [[1, 1, "algorithm"], [4, 6, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Unlike", "neural", "networks", "and", "Support", "vector", "machine", ",", "the", "AdaBoost", "training", "process", "selects", "only", "those", "features", "known", "to", "improve", "the", "predictive", "power", "of", "the", "model", ",", "reducing", "dimensionality", "and", "potentially", "improving", "execution", "time", "because", "irrelevant", "features", "do", "not", "need", "to", "be", "computed", "."], "sentence-detokenized": "Unlike neural networks and Support vector machine, the AdaBoost training process selects only those features known to improve the predictive power of the model, reducing dimensionality and potentially improving execution time because irrelevant features do not need to be computed.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 26], [27, 34], [35, 41], [42, 49], [49, 50], [51, 54], [55, 63], [64, 72], [73, 80], [81, 88], [89, 93], [94, 99], [100, 108], [109, 114], [115, 117], [118, 125], [126, 129], [130, 140], [141, 146], [147, 149], [150, 153], [154, 159], [159, 160], [161, 169], [170, 184], [185, 188], [189, 200], [201, 210], [211, 220], [221, 225], [226, 233], [234, 244], [245, 253], [254, 256], [257, 260], [261, 265], [266, 268], [269, 271], [272, 280], [280, 281]]}
{"doc_key": "ai-test-5", "ner": [[0, 0, "misc"], [11, 12, "misc"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 12, "part-of", "", false, false], [11, 12, 15, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponymy", "is", "one", "of", "the", "possible", "relations", "between", "verbs", "in", "the", "semantic", "network", "of", "the", "Word", "Net", "database", "."], "sentence-detokenized": "Troponymy is one of the possible relations between verbs in the semantic network of the WordNet database.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 19], [20, 23], [24, 32], [33, 42], [43, 50], [51, 56], [57, 59], [60, 63], [64, 72], [73, 80], [81, 83], [84, 87], [88, 92], [92, 95], [96, 104], [104, 105]]}
{"doc_key": "ai-test-6", "ner": [[8, 9, "task"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "framework", "language", "is", "a", "technology", "used", "for", "knowledge", "representation", "in", "artificial", "intelligence", "."], "sentence-detokenized": "A framework language is a technology used for knowledge representation in artificial intelligence.", "token2charspan": [[0, 1], [2, 11], [12, 20], [21, 23], [24, 25], [26, 36], [37, 41], [42, 45], [46, 55], [56, 70], [71, 73], [74, 84], [85, 97], [97, 98]]}
{"doc_key": "ai-test-7", "ner": [[0, 0, "metrics"], [4, 6, "metrics"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 6, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "Bilingual", "evaluation", "understudy", "in", "its", "calculation", "of", "the", "brevity", "penalty", "in", "that", "small", "variations", "in", "the", "length", "of", "translation", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from Bilingual evaluation understudy in its calculation of the brevity penalty in that small variations in the length of translation do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 32], [33, 43], [44, 54], [55, 57], [58, 61], [62, 73], [74, 76], [77, 80], [81, 88], [89, 96], [97, 99], [100, 104], [105, 110], [111, 121], [122, 124], [125, 128], [129, 135], [136, 138], [139, 150], [151, 153], [154, 157], [158, 164], [165, 168], [169, 176], [177, 182], [183, 185], [186, 190], [190, 191]]}
{"doc_key": "ai-test-8", "ner": [[15, 16, "algorithm"], [19, 21, "algorithm"], [40, 41, "algorithm"], [43, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "model", "is", "initially", "fitted", "to", "a", "training", "dataset", ",", "The", "model", "(", "e.g.", "a", "neural", "net", "or", "a", "naive", "Bayes", "classifier", ")", "is", "trained", "on", "the", "training", "dataset", "using", "a", "supervised", "method", ",", "e.g.", "using", "optimisation", "methods", "such", "as", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The model is initially fitted to a training dataset, The model (e.g. a neural net or a naive Bayes classifier) is trained on the training dataset using a supervised method, e.g. using optimisation methods such as gradient descent or stochastic gradient descent.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 22], [23, 29], [30, 32], [33, 34], [35, 43], [44, 51], [51, 52], [53, 56], [57, 62], [63, 64], [64, 68], [69, 70], [71, 77], [78, 81], [82, 84], [85, 86], [87, 92], [93, 98], [99, 109], [109, 110], [111, 113], [114, 121], [122, 124], [125, 128], [129, 137], [138, 145], [146, 151], [152, 153], [154, 164], [165, 171], [171, 172], [173, 177], [178, 183], [184, 196], [197, 204], [205, 209], [210, 212], [213, 221], [222, 229], [230, 232], [233, 243], [244, 252], [253, 260], [260, 261]]}
{"doc_key": "ai-test-9", "ner": [[0, 0, "product"], [8, 9, "task"], [11, 11, "task"], [13, 15, "task"], [18, 19, "task"], [25, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 0, "usage", "", true, false], [11, 11, 0, 0, "usage", "", true, false], [13, 15, 0, 0, "usage", "", true, false], [18, 19, 0, 0, "usage", "", true, false], [25, 27, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "has", "been", "used", "in", "applications", "such", "as", "question", "answering", ",", "paraphrasing", ",", "recognising", "textual", "entailment", ",", "and", "information", "extraction", ",", "either", "directly", "or", "using", "Semantic", "Role", "Labelling", "tools", "."], "sentence-detokenized": "FrameNet has been used in applications such as question answering, paraphrasing, recognising textual entailment, and information extraction, either directly or using Semantic Role Labelling tools.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 25], [26, 38], [39, 43], [44, 46], [47, 55], [56, 65], [65, 66], [67, 79], [79, 80], [81, 92], [93, 100], [101, 111], [111, 112], [113, 116], [117, 128], [129, 139], [139, 140], [141, 147], [148, 156], [157, 159], [160, 165], [166, 174], [175, 179], [180, 189], [190, 195], [195, 196]]}
{"doc_key": "ai-test-10", "ner": [[11, 11, "misc"], [14, 14, "product"], [17, 17, "misc"], [20, 20, "product"], [23, 24, "field"], [27, 27, "product"], [30, 32, "misc"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [42, 43, "misc"], [46, 47, "product"], [49, 50, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[14, 14, 11, 11, "general-affiliation", "", false, false], [20, 20, 17, 17, "general-affiliation", "", false, false], [27, 27, 23, 24, "general-affiliation", "", false, false], [35, 35, 30, 32, "type-of", "", false, false], [37, 37, 30, 32, "type-of", "", false, false], [39, 39, 30, 32, "type-of", "", false, false], [46, 47, 42, 43, "general-affiliation", "", false, false], [49, 50, 42, 43, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["This", "includes", "programmes", "such", "as", "data", "analysis", "and", "extraction", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "general", "auditing", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "e.g.", "Crystal", "Reports", "and", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "This includes programmes such as data analysis and extraction tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), general auditing software (e.g. ACL, Arbutus, EAS), business intelligence (e.g. Crystal Reports and Business Objects), etc.", "token2charspan": [[0, 4], [5, 13], [14, 24], [25, 29], [30, 32], [33, 37], [38, 46], [47, 50], [51, 61], [62, 67], [67, 68], [69, 81], [82, 83], [83, 87], [88, 93], [93, 94], [94, 95], [96, 105], [106, 107], [107, 111], [112, 118], [118, 119], [119, 120], [121, 132], [133, 141], [142, 143], [143, 147], [148, 151], [151, 152], [152, 153], [154, 161], [162, 170], [171, 179], [180, 181], [181, 185], [186, 189], [189, 190], [191, 198], [198, 199], [200, 203], [203, 204], [204, 205], [206, 214], [215, 227], [228, 229], [229, 233], [234, 241], [242, 249], [250, 253], [254, 262], [263, 270], [270, 271], [271, 272], [273, 276], [276, 277]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 6, "researcher"], [11, 11, "organisation"], [14, 14, "product"], [20, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "origin", "", false, false], [5, 6, 11, 11, "role", "", false, false], [14, 14, 20, 21, "type-of", "", false, false], [20, 21, 5, 6, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", "-", "founded", "by", "Rodney", "Brooks", ",", "formerly", "employed", "by", "iRobot", "-", "introduced", "Baxter", "in", "September", "2012", ";", "an", "industrial", "robot", "designed", "to", "work", "safely", "with", "neighbouring", "human", "workers", ",", "and", "programmable", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "Rethink Robotics - founded by Rodney Brooks, formerly employed by iRobot - introduced Baxter in September 2012; an industrial robot designed to work safely with neighbouring human workers, and programmable to perform simple tasks.", "token2charspan": [[0, 7], [8, 16], [17, 18], [19, 26], [27, 29], [30, 36], [37, 43], [43, 44], [45, 53], [54, 62], [63, 65], [66, 72], [73, 74], [75, 85], [86, 92], [93, 95], [96, 105], [106, 110], [110, 111], [112, 114], [115, 125], [126, 131], [132, 140], [141, 143], [144, 148], [149, 155], [156, 160], [161, 173], [174, 179], [180, 187], [187, 188], [189, 192], [193, 205], [206, 208], [209, 216], [217, 223], [224, 229], [229, 230]]}
{"doc_key": "ai-test-12", "ner": [[1, 2, "field"], [5, 6, "task"], [8, 9, "task"], [11, 14, "task"], [16, 19, "task"], [21, 22, "task"], [24, 25, "task"], [28, 30, "task"], [37, 39, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 6, 1, 2, "part-of", "task_part_of_field", false, false], [8, 9, 1, 2, "part-of", "task_part_of_field", false, false], [11, 14, 1, 2, "part-of", "task_part_of_field", false, false], [16, 19, 1, 2, "part-of", "task_part_of_field", false, false], [21, 22, 1, 2, "part-of", "task_part_of_field", false, false], [24, 25, 1, 2, "part-of", "task_part_of_field", false, false], [28, 30, 1, 2, "part-of", "task_part_of_field", false, false], [37, 39, 1, 2, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Typical", "text", "mining", "tasks", "include", "text", "categorisation", ",", "text", "clustering", ",", "concept", "/", "entity", "extraction", ",", "production", "of", "granular", "taxonomies", ",", "sentiment", "analysis", ",", "document", "summarisation", ",", "and", "entity", "relationship", "modelling", "(", "i.e.", ",", "learning", "relationships", "between", "name", "entity", "recognition", ")", "."], "sentence-detokenized": "Typical text mining tasks include text categorisation, text clustering, concept/entity extraction, production of granular taxonomies, sentiment analysis, document summarisation, and entity relationship modelling (i.e., learning relationships between name entity recognition).", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 25], [26, 33], [34, 38], [39, 53], [53, 54], [55, 59], [60, 70], [70, 71], [72, 79], [79, 80], [80, 86], [87, 97], [97, 98], [99, 109], [110, 112], [113, 121], [122, 132], [132, 133], [134, 143], [144, 152], [152, 153], [154, 162], [163, 176], [176, 177], [178, 181], [182, 188], [189, 201], [202, 211], [212, 213], [213, 217], [217, 218], [219, 227], [228, 241], [242, 249], [250, 254], [255, 261], [262, 273], [273, 274], [274, 275]]}
{"doc_key": "ai-test-13", "ner": [[4, 4, "metrics"], [7, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nevertheless", ",", "voting", "reduces", "precision", ",", "or", "the", "TRUENegative", "rate", ",", "for", "such", "systems", "."], "sentence-detokenized": "Nevertheless, voting reduces precision, or the TRUENegative rate, for such systems.", "token2charspan": [[0, 12], [12, 13], [14, 20], [21, 28], [29, 38], [38, 39], [40, 42], [43, 46], [47, 59], [60, 64], [64, 65], [66, 69], [70, 74], [75, 82], [82, 83]]}
{"doc_key": "ai-test-14", "ner": [[4, 5, "task"], [7, 8, "misc"], [11, 13, "misc"], [24, 24, "product"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 4, 5, "temporal", "", false, false], [11, 13, 7, 8, "named", "", false, false], [24, 24, 7, 8, "usage", "", false, false], [26, 26, 7, 8, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "special", "case", "of", "keyword", "spotting", "is", "wake", "word", "(", "also", "called", "hot", "word", ")", "detection", "which", "is", "used", "by", "personal", "digital", "assistants", "like", "Alexa", "or", "Siri", "to", "wake", "up", "when", "their", "name", "is", "spoken", "."], "sentence-detokenized": "A special case of keyword spotting is wake word (also called hot word) detection which is used by personal digital assistants like Alexa or Siri to wake up when their name is spoken.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 17], [18, 25], [26, 34], [35, 37], [38, 42], [43, 47], [48, 49], [49, 53], [54, 60], [61, 64], [65, 69], [69, 70], [71, 80], [81, 86], [87, 89], [90, 94], [95, 97], [98, 106], [107, 114], [115, 125], [126, 130], [131, 136], [137, 139], [140, 144], [145, 147], [148, 152], [153, 155], [156, 160], [161, 166], [167, 171], [172, 174], [175, 181], [181, 182]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [8, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "with", "Java", "."], "sentence-detokenized": "Prova is an open source programming language that combines Prolog with Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 16], [17, 23], [24, 35], [36, 44], [45, 49], [50, 58], [59, 65], [66, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-test-16", "ner": [[3, 4, "organisation"], [9, 9, "organisation"], [16, 20, "product"], [30, 31, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 9, 9, "part-of", "", false, false], [3, 4, 9, 9, "role", "sells", false, false], [3, 4, 30, 31, "role", "sells_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1987", ",", "Tocibai", "Machine", ",", "a", "subsidiary", "of", "Toshiba", ",", "was", "accused", "of", "illegally", "selling", "CNC", "milling", "equipment", "for", "the", "production", "of", "very", "quiet", "propellers", "for", "submarines", "to", "the", "Soviet", "Union", ",", "in", "violation", "of", "the", "CoCom", "agreement", ",", "an", "international", "embargo", "against", "certain", "countries", "towards", "COMECON", "countries", "."], "sentence-detokenized": "In 1987, Tocibai Machine, a subsidiary of Toshiba, was accused of illegally selling CNC milling equipment for the production of very quiet propellers for submarines to the Soviet Union, in violation of the CoCom agreement, an international embargo against certain countries towards COMECON countries.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 24], [24, 25], [26, 27], [28, 38], [39, 41], [42, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 75], [76, 83], [84, 87], [88, 95], [96, 105], [106, 109], [110, 113], [114, 124], [125, 127], [128, 132], [133, 138], [139, 149], [150, 153], [154, 164], [165, 167], [168, 171], [172, 178], [179, 184], [184, 185], [186, 188], [189, 198], [199, 201], [202, 205], [206, 211], [212, 221], [221, 222], [223, 225], [226, 239], [240, 247], [248, 255], [256, 263], [264, 273], [274, 281], [282, 289], [290, 299], [299, 300]]}
{"doc_key": "ai-test-17", "ner": [[0, 1, "researcher"], [7, 10, "product"], [23, 26, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 0, 1, "artifact", "", false, false], [7, 10, 23, 26, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Engelberger", "'s", "most", "famous", "co-invention", ",", "the", "Unimate", "industrial", "robot", "arm", ",", "was", "one", "of", "the", "first", "people", "to", "be", "inducted", "into", "the", "Robot", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberger's most famous co-invention, the Unimate industrial robot arm, was one of the first people to be inducted into the Robot Hall of Fame in 2003.", "token2charspan": [[0, 11], [11, 13], [14, 18], [19, 25], [26, 38], [38, 39], [40, 43], [44, 51], [52, 62], [63, 68], [69, 72], [72, 73], [74, 77], [78, 81], [82, 84], [85, 88], [89, 94], [95, 101], [102, 104], [105, 107], [108, 116], [117, 121], [122, 125], [126, 131], [132, 136], [137, 139], [140, 144], [145, 147], [148, 152], [152, 153]]}
{"doc_key": "ai-test-18", "ner": [[3, 4, "misc"], [8, 8, "misc"], [10, 11, "person"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 8, 8, "usage", "", false, false], [10, 11, 13, 14, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Originally", "controlled", "via", "static", "html", "web", "pages", "using", "CGI", ",", "Dalton", "introduced", "an", "augmented", "reality", "Java", "-", "based", "interface", "that", "had", "limited", "success", "."], "sentence-detokenized": "Originally controlled via static html web pages using CGI, Dalton introduced an augmented reality Java-based interface that had limited success.", "token2charspan": [[0, 10], [11, 21], [22, 25], [26, 32], [33, 37], [38, 41], [42, 47], [48, 53], [54, 57], [57, 58], [59, 65], [66, 76], [77, 79], [80, 89], [90, 97], [98, 102], [102, 103], [103, 108], [109, 118], [119, 123], [124, 127], [128, 135], [136, 143], [143, 144]]}
{"doc_key": "ai-test-19", "ner": [[5, 6, "task"], [10, 10, "organisation"], [29, 29, "conference"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[5, 6, 10, 10, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "publication", "on", "the", "LMF", "specification", "as", "ratified", "by", "ISO", "(", "this", "paper", "became", "(", "in", "2015", ")", "the", "9th", "most", "cited", "paper", "within", "the", "LREC", "conferences", "of", "LREC", "papers", ")", ":"], "sentence-detokenized": "The first publication on the LMF specification as ratified by ISO (this paper became (in 2015) the 9th most cited paper within the LREC conferences of LREC papers):", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 24], [25, 28], [29, 32], [33, 46], [47, 49], [50, 58], [59, 61], [62, 65], [66, 67], [67, 71], [72, 77], [78, 84], [85, 86], [86, 88], [89, 93], [93, 94], [95, 98], [99, 102], [103, 107], [108, 113], [114, 119], [120, 126], [127, 130], [131, 135], [136, 147], [148, 150], [151, 155], [156, 162], [162, 163], [163, 164]]}
{"doc_key": "ai-test-20", "ner": [[1, 2, "metrics"], [15, 15, "metrics"], [17, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 1, 2, "usage", "", false, false], [15, 15, 17, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "confusion", "matrix", "or", "similarity", "matrix", "is", "often", "used", "as", "a", "tool", "to", "validate", "the", "accuracy", "of", "k", "-", "NN", "classification", "."], "sentence-detokenized": "A confusion matrix or similarity matrix is often used as a tool to validate the accuracy of k -NN classification.", "token2charspan": [[0, 1], [2, 11], [12, 18], [19, 21], [22, 32], [33, 39], [40, 42], [43, 48], [49, 53], [54, 56], [57, 58], [59, 63], [64, 66], [67, 75], [76, 79], [80, 88], [89, 91], [92, 93], [94, 95], [95, 97], [98, 112], [112, 113]]}
{"doc_key": "ai-test-21", "ner": [[12, 12, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Decision", "tree", "learning", "is", "one", "of", "the", "predictive", "modelling", "approaches", "used", "in", "statistics", ",", "data", "mining", "and", "machine", "learning", "."], "sentence-detokenized": "Decision tree learning is one of the predictive modelling approaches used in statistics, data mining and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 47], [48, 57], [58, 68], [69, 73], [74, 76], [77, 87], [87, 88], [89, 93], [94, 100], [101, 104], [105, 112], [113, 121], [121, 122]]}
{"doc_key": "ai-test-22", "ner": [[4, 4, "misc"], [20, 22, "algorithm"], [24, 24, "algorithm"]], "ner_mapping_to_source": [0, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["During", "execution", ",", "the", "prosody", "of", "a", "sentence", "is", "superimposed", "over", "these", "minimal", "units", "using", "signal", "processing", "techniques", "such", "as", "linear", "predictive", "coding", ",", "PSOLA"], "sentence-detokenized": "During execution, the prosody of a sentence is superimposed over these minimal units using signal processing techniques such as linear predictive coding, PSOLA", "token2charspan": [[0, 6], [7, 16], [16, 17], [18, 21], [22, 29], [30, 32], [33, 34], [35, 43], [44, 46], [47, 59], [60, 64], [65, 70], [71, 78], [79, 84], [85, 90], [91, 97], [98, 108], [109, 119], [120, 124], [125, 127], [128, 134], [135, 145], [146, 152], [152, 153], [154, 159]]}
{"doc_key": "ai-test-23", "ner": [[3, 4, "field"], [6, 7, "field"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 3, 4, "usage", "", true, false], [17, 18, 6, 7, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "approach", "used", "artificial", "intelligence", "and", "machine", "learning", "to", "enable", "researchers", "to", "visibly", "compare", "conventional", "and", "thermal", "face", "images", "."], "sentence-detokenized": "This approach used artificial intelligence and machine learning to enable researchers to visibly compare conventional and thermal face images.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 29], [30, 42], [43, 46], [47, 54], [55, 63], [64, 66], [67, 73], [74, 85], [86, 88], [89, 96], [97, 104], [105, 117], [118, 121], [122, 129], [130, 134], [135, 141], [141, 142]]}
{"doc_key": "ai-test-24", "ner": [[1, 2, "field"], [4, 5, "algorithm"], [12, 13, "task"], [16, 17, "misc"], [23, 24, "field"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 1, 2, "part-of", "", false, false], [4, 5, 12, 13, "topic", "", false, false], [12, 13, 16, 17, "origin", "", false, false], [23, 24, 1, 2, "part-of", "", false, false], [23, 24, 4, 5, "topic", "", false, false], [26, 27, 1, 2, "part-of", "", false, false], [26, 27, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "computer", "science", ",", "evolutionary", "computing", "is", "a", "family", "of", "algorithms", "for", "global", "optimisation", "inspired", "by", "biological", "evolution", ",", "and", "the", "subfield", "of", "artificial", "intelligence", "and", "soft", "computing", "that", "studies", "these", "algorithms", "."], "sentence-detokenized": "In computer science, evolutionary computing is a family of algorithms for global optimisation inspired by biological evolution, and the subfield of artificial intelligence and soft computing that studies these algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 33], [34, 43], [44, 46], [47, 48], [49, 55], [56, 58], [59, 69], [70, 73], [74, 80], [81, 93], [94, 102], [103, 105], [106, 116], [117, 126], [126, 127], [128, 131], [132, 135], [136, 144], [145, 147], [148, 158], [159, 171], [172, 175], [176, 180], [181, 190], [191, 195], [196, 203], [204, 209], [210, 220], [220, 221]]}
{"doc_key": "ai-test-25", "ner": [[7, 7, "metrics"], [14, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "one", "can", "combine", "a", "confusion", "matrix", "-", "based", "measure", "with", "the", "mean", "squared", "error", "between", "the", "raw", "model", "outputs", "and", "the", "actual", "values", "."], "sentence-detokenized": "For example, one can combine a confusion matrix-based measure with the mean squared error between the raw model outputs and the actual values.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 20], [21, 28], [29, 30], [31, 40], [41, 47], [47, 48], [48, 53], [54, 61], [62, 66], [67, 70], [71, 75], [76, 83], [84, 89], [90, 97], [98, 101], [102, 105], [106, 111], [112, 119], [120, 123], [124, 127], [128, 134], [135, 141], [141, 142]]}
{"doc_key": "ai-test-26", "ner": [[9, 9, "researcher"], [5, 6, "product"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Most", "are", "results", "of", "the", "word2vec", "model", "developed", "by", "Mikolov", "et", "al", ".", "or", "variants", "thereof", "."], "sentence-detokenized": "Most are results of the word2vec model developed by Mikolov et al. or variants thereof.", "token2charspan": [[0, 4], [5, 8], [9, 16], [17, 19], [20, 23], [24, 32], [33, 38], [39, 48], [49, 51], [52, 59], [60, 62], [63, 65], [65, 66], [67, 69], [70, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-test-27", "ner": [[13, 13, "conference"], [16, 20, "conference"], [22, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 22, 16, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["During", "this", "period", ",", "a", "total", "of", "43", "publications", "were", "recognised", "by", "the", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "During this period, a total of 43 publications were recognised by the CVPR and the International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 6], [7, 11], [12, 18], [18, 19], [20, 21], [22, 27], [28, 30], [31, 33], [34, 46], [47, 51], [52, 62], [63, 65], [66, 69], [70, 74], [75, 78], [79, 82], [83, 96], [97, 107], [108, 110], [111, 119], [120, 126], [127, 128], [128, 132], [132, 133], [133, 134]]}
{"doc_key": "ai-test-28", "ner": [[1, 2, "product"], [12, 13, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 12, 13, "general-affiliation", "platform_for_education_about", false, false], [24, 25, 1, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "AIBO", "is", "widely", "used", "as", "a", "low", "-", "cost", "platform", "for", "artificial", "intelligence", "education", "and", "research", ",", "as", "it", "integrates", "a", "computer", ",", "computer", "vision", "and", "hinges", "into", "a", "package", "that", "is", "much", "cheaper", "than", "conventional", "research", "robots", "."], "sentence-detokenized": "The AIBO is widely used as a low-cost platform for artificial intelligence education and research, as it integrates a computer, computer vision and hinges into a package that is much cheaper than conventional research robots.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 18], [19, 23], [24, 26], [27, 28], [29, 32], [32, 33], [33, 37], [38, 46], [47, 50], [51, 61], [62, 74], [75, 84], [85, 88], [89, 97], [97, 98], [99, 101], [102, 104], [105, 115], [116, 117], [118, 126], [126, 127], [128, 136], [137, 143], [144, 147], [148, 154], [155, 159], [160, 161], [162, 169], [170, 174], [175, 177], [178, 182], [183, 190], [191, 195], [196, 208], [209, 217], [218, 224], [224, 225]]}
{"doc_key": "ai-test-29", "ner": [[6, 11, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "was", "programme", "chair", "of", "the", "International", "Conference", "on", "Computer", "Vision", "2021", "."], "sentence-detokenized": "She was programme chair of the International Conference on Computer Vision 2021.", "token2charspan": [[0, 3], [4, 7], [8, 17], [18, 23], [24, 26], [27, 30], [31, 44], [45, 55], [56, 58], [59, 67], [68, 74], [75, 79], [79, 80]]}
{"doc_key": "ai-test-30", "ner": [[11, 11, "researcher"], [5, 5, "organisation"], [16, 16, "organisation"], [25, 26, "organisation"], [33, 37, "product"], [39, 39, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 5, 5, "role", "", false, false], [11, 11, 16, 16, "role", "", true, false], [16, 16, 25, 26, "role", "develops_with", false, false], [33, 37, 16, 16, "artifact", "", false, false], [39, 39, 33, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["After", "receiving", "a", "grant", "from", "Unimation", "to", "develop", "his", "designs", ",", "Scheinman", "sold", "these", "designs", "to", "Unimation", ",", "which", "further", "developed", "them", "with", "support", "from", "General", "Motors", "and", "later", "marketed", "them", "as", "the", "Programmable", "Universal", "Machine", "for", "Assembly", "(", "PUMA", ")", "."], "sentence-detokenized": "After receiving a grant from Unimation to develop his designs, Scheinman sold these designs to Unimation, which further developed them with support from General Motors and later marketed them as the Programmable Universal Machine for Assembly (PUMA).", "token2charspan": [[0, 5], [6, 15], [16, 17], [18, 23], [24, 28], [29, 38], [39, 41], [42, 49], [50, 53], [54, 61], [61, 62], [63, 72], [73, 77], [78, 83], [84, 91], [92, 94], [95, 104], [104, 105], [106, 111], [112, 119], [120, 129], [130, 134], [135, 139], [140, 147], [148, 152], [153, 160], [161, 167], [168, 171], [172, 177], [178, 186], [187, 191], [192, 194], [195, 198], [199, 211], [212, 221], [222, 229], [230, 233], [234, 242], [243, 244], [244, 248], [248, 249], [249, 250]]}
{"doc_key": "ai-test-31", "ner": [[8, 9, "task"], [11, 13, "task"], [0, 0, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "general-affiliation", "works_with", false, false], [0, 0, 11, 13, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Gebel", "(", "2009", ")", "reviews", "calibration", "methods", "for", "binary", "classification", "and", "multi-class", "classification", "tasks"], "sentence-detokenized": "Gebel (2009) reviews calibration methods for binary classification and multi-class classification tasks", "token2charspan": [[0, 5], [6, 7], [7, 11], [11, 12], [13, 20], [21, 32], [33, 40], [41, 44], [45, 51], [52, 66], [67, 70], [71, 82], [83, 97], [98, 103]]}
{"doc_key": "ai-test-32", "ner": [[7, 9, "task"], [11, 11, "task"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "involved", "in", "areas", "such", "as", "optical", "character", "recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "speech", "recognition", "technology", ",", "and", "electronic", "keyboard", "instruments", "."], "sentence-detokenized": "He is involved in areas such as optical character recognition (OCR), speech synthesis, speech recognition technology, and electronic keyboard instruments.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 23], [24, 28], [29, 31], [32, 39], [40, 49], [50, 61], [62, 63], [63, 66], [66, 67], [67, 68], [69, 75], [76, 85], [85, 86], [87, 93], [94, 105], [106, 116], [116, 117], [118, 121], [122, 132], [133, 141], [142, 153], [153, 154]]}
{"doc_key": "ai-test-33", "ner": [[7, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "more", "recent", "and", "advanced", "techniques", ",", "the", "Kaldi", "toolkit", "can", "be", "used", "."], "sentence-detokenized": "For more recent and advanced techniques, the Kaldi toolkit can be used.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 19], [20, 28], [29, 39], [39, 40], [41, 44], [45, 50], [51, 58], [59, 62], [63, 65], [66, 70], [70, 71]]}
{"doc_key": "ai-test-34", "ner": [[0, 2, "researcher"], [8, 10, "organisation"], [16, 17, "organisation"], [23, 24, "organisation"], [27, 28, "researcher"], [32, 35, "organisation"], [42, 44, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 8, 10, "role", "", false, false], [0, 2, 16, 17, "role", "", false, false], [0, 2, 23, 24, "role", "", false, false], [0, 2, 32, 35, "role", "", false, false], [0, 2, 42, 44, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson", "-", "Laird", "is", "a", "Fellow", "of", "the", "American", "Philosophical", "Society", ",", "a", "Fellow", "of", "the", "Royal", "Society", ",", "a", "Fellow", "of", "the", "British", "Academy", ",", "a", "William", "James", "Fellow", "of", "the", "Association", "for", "Psychological", "Science", ",", "and", "a", "Fellow", "of", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Johnson-Laird is a Fellow of the American Philosophical Society, a Fellow of the Royal Society, a Fellow of the British Academy, a William James Fellow of the Association for Psychological Science, and a Fellow of the Cognitive Science Society.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 66], [67, 73], [74, 76], [77, 80], [81, 86], [87, 94], [94, 95], [96, 97], [98, 104], [105, 107], [108, 111], [112, 119], [120, 127], [127, 128], [129, 130], [131, 138], [139, 144], [145, 151], [152, 154], [155, 158], [159, 170], [171, 174], [175, 188], [189, 196], [196, 197], [198, 201], [202, 203], [204, 210], [211, 213], [214, 217], [218, 227], [228, 235], [236, 243], [243, 244]]}
{"doc_key": "ai-test-35", "ner": [[3, 8, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [17, 18, "researcher"], [21, 22, "algorithm"], [26, 30, "task"], [32, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 3, 8, "physical", "", false, false], [10, 11, 3, 8, "temporal", "", false, false], [13, 14, 3, 8, "physical", "", false, false], [13, 14, 3, 8, "temporal", "", false, false], [17, 18, 3, 8, "physical", "", false, false], [17, 18, 3, 8, "temporal", "", false, false], [21, 22, 17, 18, "role", "extends", false, false], [26, 30, 17, 18, "role", "extends", false, false], [32, 32, 26, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["At", "the", "2010", "IEEE", "International", "Conference", "on", "Image", "Processing", ",", "Rui", "Hu", ",", "Mark", "Banard", ",", "and", "John", "Collomosse", "extended", "the", "HOG", "descriptor", "for", "use", "in", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the 2010 IEEE International Conference on Image Processing, Rui Hu, Mark Banard, and John Collomosse extended the HOG descriptor for use in sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 30], [31, 41], [42, 44], [45, 50], [51, 61], [61, 62], [63, 66], [67, 69], [69, 70], [71, 75], [76, 82], [82, 83], [84, 87], [88, 92], [93, 103], [104, 112], [113, 116], [117, 120], [121, 131], [132, 135], [136, 139], [140, 142], [143, 149], [149, 150], [150, 155], [156, 161], [162, 171], [172, 173], [173, 177], [177, 178], [178, 179]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "uses", "a", "modified", "form", "of", "precision", "to", "compare", "a", "candidate", "translation", "with", "multiple", "reference", "translations", "."], "sentence-detokenized": "BLEU uses a modified form of precision to compare a candidate translation with multiple reference translations.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 20], [21, 25], [26, 28], [29, 38], [39, 41], [42, 49], [50, 51], [52, 61], [62, 73], [74, 78], [79, 87], [88, 97], [98, 110], [110, 111]]}
{"doc_key": "ai-test-37", "ner": [[34, 35, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "case", "of", "a", "general", "base", "space", "math", "(", "Y", ",", "mathcal", "{", "B", "},\\now", ")", "/", "math", "(", "i.e.", "a", "base", "space", "that", "is", "not", "countable", ")", ",", "one", "usually", "considers", "the", "relative", "entropy", "."], "sentence-detokenized": "For the case of a general base space math (Y,mathcal {B},\\now) / math (i.e. a base space that is not countable), one usually considers the relative entropy.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 15], [16, 17], [18, 25], [26, 30], [31, 36], [37, 41], [42, 43], [43, 44], [44, 45], [45, 52], [53, 54], [54, 55], [55, 61], [61, 62], [63, 64], [65, 69], [70, 71], [71, 75], [76, 77], [78, 82], [83, 88], [89, 93], [94, 96], [97, 100], [101, 110], [110, 111], [111, 112], [113, 116], [117, 124], [125, 134], [135, 138], [139, 147], [148, 155], [155, 156]]}
{"doc_key": "ai-test-38", "ner": [[18, 19, "country"], [10, 12, "organisation"], [14, 14, "organisation"], [29, 29, "country"], [21, 22, "organisation"], [24, 24, "organisation"], [32, 34, "organisation"], [47, 47, "country"], [37, 42, "organisation"], [44, 44, "organisation"], [53, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11], "relations": [[10, 12, 18, 19, "physical", "", false, false], [14, 14, 10, 12, "named", "", false, false], [21, 22, 29, 29, "physical", "", false, false], [24, 24, 21, 22, "named", "", false, false], [37, 42, 47, 47, "physical", "", false, false], [44, 44, 37, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["As", "of", "October", "2011", ",", "already", "existing", "partnerships", "with", "the", "National", "Park", "Service", "(", "NPS", ")", "of", "the", "United", "States", ",", "Historic", "Scotland", "(", "HS", ")", "of", "the", "United", "Kingdom", ",", "the", "World", "Monuments", "Fund", "and", "the", "Instituto", "Nacional", "de", "Antropolog\u00eda", "y", "Historia", "(", "INAH", ")", "of", "Mexico", "had", "been", "significantly", "expanded", ",", "CyArk", "website"], "sentence-detokenized": "As of October 2011, already existing partnerships with the National Park Service (NPS) of the United States, Historic Scotland (HS) of the United Kingdom, the World Monuments Fund and the Instituto Nacional de Antropolog\u00eda y Historia (INAH) of Mexico had been significantly expanded, CyArk website", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 18], [18, 19], [20, 27], [28, 36], [37, 49], [50, 54], [55, 58], [59, 67], [68, 72], [73, 80], [81, 82], [82, 85], [85, 86], [87, 89], [90, 93], [94, 100], [101, 107], [107, 108], [109, 117], [118, 126], [127, 128], [128, 130], [130, 131], [132, 134], [135, 138], [139, 145], [146, 153], [153, 154], [155, 158], [159, 164], [165, 174], [175, 179], [180, 183], [184, 187], [188, 197], [198, 206], [207, 209], [210, 222], [223, 224], [225, 233], [234, 235], [235, 239], [239, 240], [241, 243], [244, 250], [251, 254], [255, 259], [260, 273], [274, 282], [282, 283], [284, 289], [290, 297]]}
{"doc_key": "ai-test-39", "ner": [[0, 1, "algorithm"], [6, 8, "field"], [12, 12, "product"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 14, "part-of", "", false, false], [12, 12, 6, 8, "general-affiliation", "", false, false], [14, 14, 6, 8, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kernel", "SVMs", "are", "available", "in", "many", "machine", "-", "learning", "toolkits", ",", "including", "LIBSVM", ",", "MATLAB", ",", "and", "others", "."], "sentence-detokenized": "Kernel SVMs are available in many machine-learning toolkits, including LIBSVM, MATLAB, and others.", "token2charspan": [[0, 6], [7, 11], [12, 15], [16, 25], [26, 28], [29, 33], [34, 41], [41, 42], [42, 50], [51, 59], [59, 60], [61, 70], [71, 77], [77, 78], [79, 85], [85, 86], [87, 90], [91, 97], [97, 98]]}
{"doc_key": "ai-test-40", "ner": [[2, 4, "misc"], [13, 14, "location"], [16, 16, "location"], [17, 20, "country"], [23, 25, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 13, 14, "physical", "", false, false], [2, 4, 23, 25, "temporal", "", false, false], [13, 14, 16, 16, "physical", "", false, false], [16, 16, 17, 20, "physical", "", false, false], [23, 25, 13, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2009", "Loebner", "Prize", "competition", "was", "held", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", ",", "Brighton", "UK", ",", "in", "conjunction", "with", "the", "Interspeech", "2009", "conference", "."], "sentence-detokenized": "The 2009 Loebner Prize competition was held on 6 September 2009 at the Brighton Centre, Brighton UK, in conjunction with the Interspeech 2009 conference.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 34], [35, 38], [39, 43], [44, 46], [47, 48], [49, 58], [59, 63], [64, 66], [67, 70], [71, 79], [80, 86], [86, 87], [88, 96], [97, 99], [99, 100], [101, 103], [104, 115], [116, 120], [121, 124], [125, 136], [137, 141], [142, 152], [152, 153]]}
{"doc_key": "ai-test-41", "ner": [[2, 3, "product"], [10, 10, "product"], [18, 20, "product"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 23, 2, 3, "part-of", "", false, false], [21, 23, 10, 10, "part-of", "", false, false], [21, 23, 18, 20, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "humanoid", "QRIO", "robot", "is", "designed", "as", "a", "successor", "to", "AIBO", ",", "and", "runs", "on", "the", "same", "basic", "R", "-", "CODE", "Aperios", "operating", "system", "."], "sentence-detokenized": "The humanoid QRIO robot is designed as a successor to AIBO, and runs on the same basic R-CODE Aperios operating system.", "token2charspan": [[0, 3], [4, 12], [13, 17], [18, 23], [24, 26], [27, 35], [36, 38], [39, 40], [41, 50], [51, 53], [54, 58], [58, 59], [60, 63], [64, 68], [69, 71], [72, 75], [76, 80], [81, 86], [87, 88], [88, 89], [89, 93], [94, 101], [102, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-test-42", "ner": [[0, 1, "misc"], [5, 5, "algorithm"], [10, 11, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 1, "cause-effect", "", true, false], [10, 11, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Speech", "waveforms", "are", "generated", "from", "HMMs", "themselves", "based", "on", "the", "maximum", "likelihood", "criterion", "."], "sentence-detokenized": "Speech waveforms are generated from HMMs themselves based on the maximum likelihood criterion.", "token2charspan": [[0, 6], [7, 16], [17, 20], [21, 30], [31, 35], [36, 40], [41, 51], [52, 57], [58, 60], [61, 64], [65, 72], [73, 83], [84, 93], [93, 94]]}
{"doc_key": "ai-test-43", "ner": [[0, 1, "product"], [5, 8, "task"], [10, 12, "task"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 5, 8, "type-of", "", false, false], [0, 1, 10, 12, "type-of", "", false, false], [0, 1, 16, 16, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "is", "a", "free", "multilingual", "statistical", "machine", "translation", "and", "neural", "machine", "translation", "service", "developed", "by", "Google", ",", "to", "translate", "text", "and", "websites", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Google Translate is a free multilingual statistical machine translation and neural machine translation service developed by Google, to translate text and websites from one language to another.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 39], [40, 51], [52, 59], [60, 71], [72, 75], [76, 82], [83, 90], [91, 102], [103, 110], [111, 120], [121, 123], [124, 130], [130, 131], [132, 134], [135, 144], [145, 149], [150, 153], [154, 162], [163, 167], [168, 171], [172, 180], [181, 183], [184, 191], [191, 192]]}
{"doc_key": "ai-test-44", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [14, 16, "field"], [21, 23, "task"], [25, 26, "task"], [28, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[21, 23, 5, 6, "part-of", "", false, true], [21, 23, 8, 9, "part-of", "", false, true], [21, 23, 11, 12, "part-of", "", false, true], [25, 26, 5, 6, "part-of", "", false, true], [25, 26, 8, 9, "part-of", "", false, true], [25, 26, 11, 12, "part-of", "", false, true], [28, 31, 5, 6, "part-of", "", false, true], [28, 31, 8, 9, "part-of", "", false, true], [28, 31, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Skeletons", "are", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", "and", "digital", "image", "processing", "for", "purposes", "such", "as", "optical", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", "or", "compression", "."], "sentence-detokenized": "Skeletons are widely used in computer vision, image analysis, pattern recognition and digital image processing for purposes such as optical character recognition, fingerprint recognition, visual inspection or compression.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 25], [26, 28], [29, 37], [38, 44], [44, 45], [46, 51], [52, 60], [60, 61], [62, 69], [70, 81], [82, 85], [86, 93], [94, 99], [100, 110], [111, 114], [115, 123], [124, 128], [129, 131], [132, 139], [140, 149], [150, 161], [161, 162], [163, 174], [175, 186], [186, 187], [188, 194], [195, 205], [206, 208], [209, 220], [220, 221]]}
{"doc_key": "ai-test-45", "ner": [[1, 6, "conference"], [11, 14, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 6, 11, 14, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "is", "a", "benchmark", "for", "object", "classification", "and", "detection", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark for object classification and detection, with millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 58], [59, 68], [69, 72], [73, 79], [80, 94], [95, 98], [99, 108], [108, 109], [110, 114], [115, 123], [124, 126], [127, 133], [134, 137], [138, 146], [147, 149], [150, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-test-46", "ner": [[0, 11, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [15, 17, "misc"], [19, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 11, 15, 17, "part-of", "", false, false], [0, 11, 19, 22, "part-of", "", false, false], [4, 5, 15, 17, "part-of", "", false, false], [4, 5, 19, 22, "part-of", "", false, false], [7, 8, 15, 17, "part-of", "", false, false], [7, 8, 19, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "is", "called", "by", "some", "the", "Godfathers", "of", "AI", "and", "Godfathers", "of", "Deep", "Learning", "."], "sentence-detokenized": "Bengio, along with Geoffrey Hinton and Yann LeCun, is called by some the Godfathers of AI and Godfathers of Deep Learning.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 27], [28, 34], [35, 38], [39, 43], [44, 49], [49, 50], [51, 53], [54, 60], [61, 63], [64, 68], [69, 72], [73, 83], [84, 86], [87, 89], [90, 93], [94, 104], [105, 107], [108, 112], [113, 121], [121, 122]]}
{"doc_key": "ai-test-47", "ner": [[7, 7, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "Life", "Fellow", "of", "the", "IEEE", "."], "sentence-detokenized": "He is a Life Fellow of the IEEE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 19], [20, 22], [23, 26], [27, 31], [31, 32]]}
{"doc_key": "ai-test-48", "ner": [[0, 1, "organisation"], [14, 19, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 14, 19, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NSA", "Bethesda", "is", "responsible", "for", "the", "operational", "support", "of", "its", "main", "tenant", ",", "the", "Walter", "Reed", "National", "Military", "Medical", "Center", "."], "sentence-detokenized": "NSA Bethesda is responsible for the operational support of its main tenant, the Walter Reed National Military Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 31], [32, 35], [36, 47], [48, 55], [56, 58], [59, 62], [63, 67], [68, 74], [74, 75], [76, 79], [80, 86], [87, 91], [92, 100], [101, 109], [110, 117], [118, 124], [124, 125]]}
{"doc_key": "ai-test-49", "ner": [[6, 7, "field"], [9, 10, "field"], [12, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "three", "main", "learning", "paradigms", "are", "supervised", "learning", ",", "unsupervised", "learning", "and", "reinforcement", "-", "based", "learning", "."], "sentence-detokenized": "The three main learning paradigms are supervised learning, unsupervised learning and reinforcement-based learning.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 23], [24, 33], [34, 37], [38, 48], [49, 57], [57, 58], [59, 71], [72, 80], [81, 84], [85, 98], [98, 99], [99, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-50", "ner": [[2, 2, "task"], [4, 6, "task"], [11, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Examples", "include", "monitoring", ",", "scheduling", "and", "programming", ",", "the", "ability", "to", "answer", "diagnostic", "and", "consumer", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", "and", "face", "recognition", "."], "sentence-detokenized": "Examples include monitoring, scheduling and programming, the ability to answer diagnostic and consumer questions, handwriting recognition, natural language understanding, speech recognition and face recognition.", "token2charspan": [[0, 8], [9, 16], [17, 27], [27, 28], [29, 39], [40, 43], [44, 55], [55, 56], [57, 60], [61, 68], [69, 71], [72, 78], [79, 89], [90, 93], [94, 102], [103, 112], [112, 113], [114, 125], [126, 137], [137, 138], [139, 146], [147, 155], [156, 169], [169, 170], [171, 177], [178, 189], [190, 193], [194, 198], [199, 210], [210, 211]]}
{"doc_key": "ai-test-51", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", ",", "he", "was", "elected", "a", "fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "founding", "fellow", ")", "."], "sentence-detokenized": "In 1991, he was elected a fellow of the Association for the Advancement of Artificial Intelligence (1990, founding fellow).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [99, 100], [100, 104], [104, 105], [106, 114], [115, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-test-52", "ner": [[11, 12, "misc"], [15, 16, "algorithm"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "by", "formulating", "the", "problem", "as", "the", "solution", "of", "a", "Toeplitz", "matrix", "and", "using", "Levinson", "recursion", ",", "we", "can", "relatively", "quickly", "estimate", "a", "filter", "with", "the", "smallest", "possible", "mean", "squared", "error", "."], "sentence-detokenized": "However, by formulating the problem as the solution of a Toeplitz matrix and using Levinson recursion, we can relatively quickly estimate a filter with the smallest possible mean squared error.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 23], [24, 27], [28, 35], [36, 38], [39, 42], [43, 51], [52, 54], [55, 56], [57, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 101], [101, 102], [103, 105], [106, 109], [110, 120], [121, 128], [129, 137], [138, 139], [140, 146], [147, 151], [152, 155], [156, 164], [165, 173], [174, 178], [179, 186], [187, 192], [192, 193]]}
{"doc_key": "ai-test-53", "ner": [[5, 10, "conference"], [16, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 10, 16, 20, "physical", "", false, false], [16, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2011", ",", "the", "15th", "edition", "of", "Campus", "Party", "Spain", "will", "take", "place", "at", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "In July 2011, the 15th edition of Campus Party Spain will take place at the City of Arts and Sciences in Valencia.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 22], [23, 30], [31, 33], [34, 40], [41, 46], [47, 52], [53, 57], [58, 62], [63, 68], [69, 71], [72, 75], [76, 80], [81, 83], [84, 88], [89, 92], [93, 101], [102, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-54", "ner": [[13, 13, "product"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "often", "only", "possible", "at", "the", "end", "of", "complicated", "games", "such", "as", "chess", "or", "go", ",", "because", "it", "is", "computationally", "infeasible", "to", "look", "ahead", "to", "the", "completion", "of", "the", "game", "except", "towards", "the", "end", ",", "and", "instead", "positions", "are", "given", "finite", "values", "as", "estimates", "of", "the", "degree", "of", "belief", "that", "they", "will", "lead", "to", "a", "victory", "for", "one", "player", "or", "the", "other", "."], "sentence-detokenized": "This is often only possible at the end of complicated games such as chess or go, because it is computationally infeasible to look ahead to the completion of the game except towards the end, and instead positions are given finite values as estimates of the degree of belief that they will lead to a victory for one player or the other.", "token2charspan": [[0, 4], [5, 7], [8, 13], [14, 18], [19, 27], [28, 30], [31, 34], [35, 38], [39, 41], [42, 53], [54, 59], [60, 64], [65, 67], [68, 73], [74, 76], [77, 79], [79, 80], [81, 88], [89, 91], [92, 94], [95, 110], [111, 121], [122, 124], [125, 129], [130, 135], [136, 138], [139, 142], [143, 153], [154, 156], [157, 160], [161, 165], [166, 172], [173, 180], [181, 184], [185, 188], [188, 189], [190, 193], [194, 201], [202, 211], [212, 215], [216, 221], [222, 228], [229, 235], [236, 238], [239, 248], [249, 251], [252, 255], [256, 262], [263, 265], [266, 272], [273, 277], [278, 282], [283, 287], [288, 292], [293, 295], [296, 297], [298, 305], [306, 309], [310, 313], [314, 320], [321, 323], [324, 327], [328, 333], [333, 334]]}
{"doc_key": "ai-test-55", "ner": [[4, 51, "algorithm"], [24, 25, "algorithm"], [27, 28, "algorithm"], [31, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 51, 24, 25, "compare", "", false, false], [4, 51, 27, 28, "compare", "", false, false], [4, 51, 31, 33, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "difference", "between", "the", "multinomial", "logit", "model", "and", "numerous", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "with", "the", "same", "basic", "setup", "(", "the", "perceptron", "algorithm", ",", "support", "vector", "machines", ",", "linear", "discriminant", "analysis", ",", "etc.", ")", "is", "that", "the", "multinomial", "logit", "model", "is", "not", "the", "same", "as", "the", "multinomial", "logit", "model", "."], "sentence-detokenized": "The difference between the multinomial logit model and numerous other methods, models, algorithms, etc. with the same basic setup (the perceptron algorithm, support vector machines, linear discriminant analysis, etc.) is that the multinomial logit model is not the same as the multinomial logit model.", "token2charspan": [[0, 3], [4, 14], [15, 22], [23, 26], [27, 38], [39, 44], [45, 50], [51, 54], [55, 63], [64, 69], [70, 77], [77, 78], [79, 85], [85, 86], [87, 97], [97, 98], [99, 103], [104, 108], [109, 112], [113, 117], [118, 123], [124, 129], [130, 131], [131, 134], [135, 145], [146, 155], [155, 156], [157, 164], [165, 171], [172, 180], [180, 181], [182, 188], [189, 201], [202, 210], [210, 211], [212, 216], [216, 217], [218, 220], [221, 225], [226, 229], [230, 241], [242, 247], [248, 253], [254, 256], [257, 260], [261, 264], [265, 269], [270, 272], [273, 276], [277, 288], [289, 294], [295, 300], [300, 301]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "published", "by"], "sentence-detokenized": "Association for Computational Linguistics, published by", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 52], [53, 55]]}
{"doc_key": "ai-test-57", "ner": [[3, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "an", "automated", "face", "recognition", "system", ",", "each", "face", "is", "represented", "by", "a", "large", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In an automated face recognition system, each face is represented by a large number of pixel values.", "token2charspan": [[0, 2], [3, 5], [6, 15], [16, 20], [21, 32], [33, 39], [39, 40], [41, 45], [46, 50], [51, 53], [54, 65], [66, 68], [69, 70], [71, 76], [77, 83], [84, 86], [87, 92], [93, 99], [99, 100]]}
{"doc_key": "ai-test-58", "ner": [[6, 7, "person"], [14, 19, "organisation"], [23, 25, "country"], [27, 27, "person"], [38, 40, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 7, 14, 19, "role", "", false, false], [6, 7, 23, 25, "physical", "", false, false], [27, 27, 38, 40, "origin", "", false, false], [27, 27, 38, 40, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2002", ",", "his", "son", ",", "Daniel", "Pearl", ",", "a", "journalist", "working", "for", "the", "Wall", "Street", "Journal", ",", "was", "kidnapped", "and", "murdered", "in", "Pakistan", ",", "which", "led", "Judea", "and", "the", "other", "family", "members", "and", "friends", "to", "establish", "the", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "In 2002, his son, Daniel Pearl, a journalist working for the Wall Street Journal, was kidnapped and murdered in Pakistan, which led Judea and the other family members and friends to establish the Daniel Pearl Foundation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [16, 17], [18, 24], [25, 30], [30, 31], [32, 33], [34, 44], [45, 52], [53, 56], [57, 60], [61, 65], [66, 72], [73, 80], [80, 81], [82, 85], [86, 95], [96, 99], [100, 108], [109, 111], [112, 120], [120, 121], [122, 127], [128, 131], [132, 137], [138, 141], [142, 145], [146, 151], [152, 158], [159, 166], [167, 170], [171, 178], [179, 181], [182, 191], [192, 195], [196, 202], [203, 208], [209, 219], [219, 220]]}
{"doc_key": "ai-test-59", "ner": [[4, 6, "organisation"], [15, 16, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 15, 16, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["From", "late", "2006", ",", "Red", "Envelope", "Entertainment", "also", "started", "producing", "original", "content", "with", "filmmakers", "like", "John", "Waters", "."], "sentence-detokenized": "From late 2006, Red Envelope Entertainment also started producing original content with filmmakers like John Waters.", "token2charspan": [[0, 4], [5, 9], [10, 14], [14, 15], [16, 19], [20, 28], [29, 42], [43, 47], [48, 55], [56, 65], [66, 74], [75, 82], [83, 87], [88, 98], [99, 103], [104, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-60", "ner": [[7, 11, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "building", "is", "now", "part", "of", "the", "Beth", "Israel", "Deaconess", "Medical", "Centre", "."], "sentence-detokenized": "The building is now part of the Beth Israel Deaconess Medical Centre.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 31], [32, 36], [37, 43], [44, 53], [54, 61], [62, 68], [68, 69]]}
{"doc_key": "ai-test-61", "ner": [[18, 19, "field"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "common", "theme", "of", "this", "work", "is", "the", "application", "of", "a", "sign", "-", "theoretic", "perspective", "to", "issues", "of", "artificial", "intelligence", "and", "knowledge", "representation", "."], "sentence-detokenized": "A common theme of this work is the application of a sign-theoretic perspective to issues of artificial intelligence and knowledge representation.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 46], [47, 49], [50, 51], [52, 56], [56, 57], [57, 66], [67, 78], [79, 81], [82, 88], [89, 91], [92, 102], [103, 115], [116, 119], [120, 129], [130, 144], [144, 145]]}
{"doc_key": "ai-test-62", "ner": [[4, 6, "task"], [8, 8, "task"], [20, 21, "task"], [39, 40, "task"], [42, 43, "task"], [48, 50, "task"], [52, 52, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 6, 20, 21, "type-of", "", false, false], [4, 6, 48, 50, "compare", "", false, false], [4, 6, 48, 50, "opposite", "", false, false], [8, 8, 4, 6, "named", "", false, false], [39, 40, 48, 50, "part-of", "", false, false], [42, 43, 48, 50, "part-of", "", false, false], [48, 50, 20, 21, "type-of", "", false, false], [52, 52, 48, 50, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Thus", ",", "the", "term", "neural", "machine", "translation", "(", "NMT", ")", "highlights", "the", "fact", "that", "deep", "learning", "-", "based", "approaches", "to", "machine", "translation", "learn", "sequence", "-", "to", "-", "sequence", "transformations", "directly", ",", "avoiding", "the", "need", "for", "intermediate", "steps", "such", "as", "word", "alignment", "and", "language", "modelling", "that", "was", "used", "in", "statistical", "machine", "translation", "(", "SMT", ")", "."], "sentence-detokenized": "Thus, the term neural machine translation (NMT) highlights the fact that deep learning-based approaches to machine translation learn sequence-to-sequence transformations directly, avoiding the need for intermediate steps such as word alignment and language modelling that was used in statistical machine translation (SMT).", "token2charspan": [[0, 4], [4, 5], [6, 9], [10, 14], [15, 21], [22, 29], [30, 41], [42, 43], [43, 46], [46, 47], [48, 58], [59, 62], [63, 67], [68, 72], [73, 77], [78, 86], [86, 87], [87, 92], [93, 103], [104, 106], [107, 114], [115, 126], [127, 132], [133, 141], [141, 142], [142, 144], [144, 145], [145, 153], [154, 169], [170, 178], [178, 179], [180, 188], [189, 192], [193, 197], [198, 201], [202, 214], [215, 220], [221, 225], [226, 228], [229, 233], [234, 243], [244, 247], [248, 256], [257, 266], [267, 271], [272, 275], [276, 280], [281, 283], [284, 295], [296, 303], [304, 315], [316, 317], [317, 320], [320, 321], [321, 322]]}
{"doc_key": "ai-test-63", "ner": [[3, 3, "field"], [7, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 7, 8, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "research", "on", "WSD", "is", "conducted", "using", "Word", "Net", "as", "a", "reference", "phrase", "inventory", "for", "."], "sentence-detokenized": "Most research on WSD is conducted using WordNet as a reference phrase inventory for.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 23], [24, 33], [34, 39], [40, 44], [44, 47], [48, 50], [51, 52], [53, 62], [63, 69], [70, 79], [80, 83], [83, 84]]}
{"doc_key": "ai-test-64", "ner": [[13, 14, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Well", "-", "known", "former", "PhD", "students", "and", "postdoctoral", "researchers", "from", "his", "group", "include", "Richard", "Zemel", ",", "and", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Well-known former PhD students and postdoctoral researchers from his group include Richard Zemel, and Zoubin Ghahramani.", "token2charspan": [[0, 4], [4, 5], [5, 10], [11, 17], [18, 21], [22, 30], [31, 34], [35, 47], [48, 59], [60, 64], [65, 68], [69, 74], [75, 82], [83, 90], [91, 96], [96, 97], [98, 101], [102, 108], [109, 119], [119, 120]]}
{"doc_key": "ai-test-65", "ner": [[7, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Each", "prediction", "result", "or", "instance", "of", "a", "confusion", "matrix", "represents", "a", "point", "in", "ROC", "space", "."], "sentence-detokenized": "Each prediction result or instance of a confusion matrix represents a point in ROC space.", "token2charspan": [[0, 4], [5, 15], [16, 22], [23, 25], [26, 34], [35, 37], [38, 39], [40, 49], [50, 56], [57, 67], [68, 69], [70, 75], [76, 78], [79, 82], [83, 88], [88, 89]]}
{"doc_key": "ai-test-66", "ner": [[3, 3, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [17, 19, "product"], [22, 24, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 22, 24, "physical", "", false, false], [7, 8, 22, 24, "physical", "", false, false], [10, 11, 22, 24, "physical", "", false, false], [17, 19, 3, 3, "artifact", "", false, false], [17, 19, 7, 8, "artifact", "", false, false], [17, 19, 10, 11, "artifact", "", false, false], [17, 19, 22, 24, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1997", ",", "Thrun", "and", "his", "colleagues", "Wolfram", "Burgard", "and", "Dieter", "Fox", "developed", "the", "world", "'s", "first", "robotic", "tour", "guide", "at", "the", "Deutsches", "Museum", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "In 1997, Thrun and his colleagues Wolfram Burgard and Dieter Fox developed the world's first robotic tour guide at the Deutsches Museum Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 18], [19, 22], [23, 33], [34, 41], [42, 49], [50, 53], [54, 60], [61, 64], [65, 74], [75, 78], [79, 84], [84, 86], [87, 92], [93, 100], [101, 105], [106, 111], [112, 114], [115, 118], [119, 128], [129, 135], [136, 140], [141, 142], [142, 146], [146, 147], [147, 148]]}
{"doc_key": "ai-test-67", "ner": [[0, 1, "product"], [7, 7, "misc"], [23, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 1, "part-of", "", false, false], [23, 25, 0, 1, "usage", "", false, false], [27, 28, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "of", "semantic", "relationships", "between", "words", "in", "more", "than", "200", "languages", ".", "It", "is", "mainly", "used", "in", "automatic", "natural", "language", "processing", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database of semantic relationships between words in more than 200 languages. It is mainly used in automatic natural language processing and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 32], [33, 41], [42, 55], [56, 63], [64, 69], [70, 72], [73, 77], [78, 82], [83, 86], [87, 96], [96, 97], [98, 100], [101, 103], [104, 110], [111, 115], [116, 118], [119, 128], [129, 136], [137, 145], [146, 156], [157, 160], [161, 171], [172, 184], [185, 197], [197, 198]]}
{"doc_key": "ai-test-68", "ner": [[5, 7, "field"], [11, 14, "conference"], [16, 24, "conference"], [26, 26, "conference"], [29, 29, "conference"], [37, 38, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 14, 5, 7, "topic", "", false, false], [11, 14, 37, 38, "topic", "", false, false], [16, 24, 5, 7, "topic", "", false, false], [16, 24, 37, 38, "topic", "", false, false], [26, 26, 5, 7, "topic", "", false, false], [26, 26, 37, 38, "topic", "", false, false], [29, 29, 5, 7, "topic", "", false, false], [29, 29, 37, 38, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Conferences", "in", "the", "field", "of", "natural", "language", "processing", ",", "such", "as", "Association", "for", "Computational", "Linguistics", ",", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", ",", "and", "HLT", ",", "are", "starting", "to", "include", "papers", "on", "speech", "processing", "."], "sentence-detokenized": "Conferences in the field of natural language processing, such as Association for Computational Linguistics, North American Chapter of the Association for Computational Linguistics, EMNLP, and HLT, are starting to include papers on speech processing.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 24], [25, 27], [28, 35], [36, 44], [45, 55], [55, 56], [57, 61], [62, 64], [65, 76], [77, 80], [81, 94], [95, 106], [106, 107], [108, 113], [114, 122], [123, 130], [131, 133], [134, 137], [138, 149], [150, 153], [154, 167], [168, 179], [179, 180], [181, 186], [186, 187], [188, 191], [192, 195], [195, 196], [197, 200], [201, 209], [210, 212], [213, 220], [221, 227], [228, 230], [231, 237], [238, 248], [248, 249]]}
{"doc_key": "ai-test-69", "ner": [[19, 20, "misc"], [34, 36, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "set", "of", "Java", "programmes", "uses", "the", "lexicon", "to", "search", "variations", "in", "biomedical", "texts", "by", "relating", "words", "to", "their", "speech", "parts", ",", "which", "can", "be", "useful", "when", "searching", "on", "the", "web", "or", "in", "an", "electronic", "medical", "record", "."], "sentence-detokenized": "A set of Java programmes uses the lexicon to search variations in biomedical texts by relating words to their speech parts, which can be useful when searching on the web or in an electronic medical record.", "token2charspan": [[0, 1], [2, 5], [6, 8], [9, 13], [14, 24], [25, 29], [30, 33], [34, 41], [42, 44], [45, 51], [52, 62], [63, 65], [66, 76], [77, 82], [83, 85], [86, 94], [95, 100], [101, 103], [104, 109], [110, 116], [117, 122], [122, 123], [124, 129], [130, 133], [134, 136], [137, 143], [144, 148], [149, 158], [159, 161], [162, 165], [166, 169], [170, 172], [173, 175], [176, 178], [179, 189], [190, 197], [198, 204], [204, 205]]}
{"doc_key": "ai-test-70", "ner": [[9, 9, "algorithm"], [11, 11, "algorithm"], [13, 13, "algorithm"], [15, 15, "algorithm"], [17, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "many", "more", "recent", "algorithms", ",", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", ",", "and", "others", "."], "sentence-detokenized": "There are many more recent algorithms, such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost, and others.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 26], [27, 37], [37, 38], [39, 43], [44, 46], [47, 54], [54, 55], [56, 66], [66, 67], [68, 78], [78, 79], [80, 87], [87, 88], [89, 98], [98, 99], [100, 103], [104, 110], [110, 111]]}
{"doc_key": "ai-test-71", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "implementation", "in", "Python", ":"], "sentence-detokenized": "This is an example implementation in Python:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 33], [34, 36], [37, 43], [43, 44]]}
{"doc_key": "ai-test-72", "ner": [[1, 1, "organisation"], [2, 2, "product"], [7, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 1, 1, "artifact", "made_by_company", false, false], [7, 9, 2, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Mattel", "Intellivision", "game", "console", "offered", "the", "Intellivoice", "Voice", "Synthesis", "module", "in", "1982", "."], "sentence-detokenized": "The Mattel Intellivision game console offered the Intellivoice Voice Synthesis module in 1982.", "token2charspan": [[0, 3], [4, 10], [11, 24], [25, 29], [30, 37], [38, 45], [46, 49], [50, 62], [63, 68], [69, 78], [79, 85], [86, 88], [89, 93], [93, 94]]}
{"doc_key": "ai-test-73", "ner": [[5, 6, "task"], [9, 15, "task"], [17, 18, "field"], [20, 22, "task"], [26, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 15, 5, 6, "part-of", "", false, false], [17, 18, 5, 6, "part-of", "", false, false], [20, 22, 5, 6, "part-of", "", false, false], [26, 30, 20, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "has", "also", "worked", "on", "machine", "translation", ",", "both", "high", "-", "precision", "knowledge", "-", "based", "MT", "and", "machine", "learning", "for", "Statistical", "Machine", "Translation", "(", "such", "as", "generalised", "sample", "-", "based", "MT", ")", "."], "sentence-detokenized": "He has also worked on machine translation, both high-precision knowledge-based MT and machine learning for Statistical Machine Translation (such as generalised sample-based MT).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 21], [22, 29], [30, 41], [41, 42], [43, 47], [48, 52], [52, 53], [53, 62], [63, 72], [72, 73], [73, 78], [79, 81], [82, 85], [86, 93], [94, 102], [103, 106], [107, 118], [119, 126], [127, 138], [139, 140], [140, 144], [145, 147], [148, 159], [160, 166], [166, 167], [167, 172], [173, 175], [175, 176], [176, 177]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [5, 5, "misc"], [20, 21, "algorithm"], [23, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 32, "field"], [34, 34, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 20, 21, "general-affiliation", "", false, false], [0, 1, 23, 24, "general-affiliation", "", false, false], [0, 1, 26, 27, "general-affiliation", "", false, false], [0, 1, 29, 29, "general-affiliation", "", false, false], [0, 1, 31, 32, "general-affiliation", "", false, false], [0, 1, 34, 34, "general-affiliation", "", false, false], [5, 5, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "commonly", "called", "Mathematica", ")", "is", "a", "modern", "technical", "computing", "system", "that", "covers", "most", "technical", "areas", "-", "including", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "data", "science", ",", "visualisations", ",", "and", "others", "."], "sentence-detokenized": "Wolfram Mathematica (commonly called Mathematica) is a modern technical computing system that covers most technical areas - including neural networks, machine learning, image processing, geometry, data science, visualisations, and others.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 29], [30, 36], [37, 48], [48, 49], [50, 52], [53, 54], [55, 61], [62, 71], [72, 81], [82, 88], [89, 93], [94, 100], [101, 105], [106, 115], [116, 121], [122, 123], [124, 133], [134, 140], [141, 149], [149, 150], [151, 158], [159, 167], [167, 168], [169, 174], [175, 185], [185, 186], [187, 195], [195, 196], [197, 201], [202, 209], [209, 210], [211, 225], [225, 226], [227, 230], [231, 237], [237, 238]]}
{"doc_key": "ai-test-75", "ner": [[2, 6, "product"], [10, 11, "researcher"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 19, 2, 6, "type-of", "", false, false], [19, 19, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "digitally", "controlled", "and", "programmable", "robot", "was", "invented", "by", "George", "Devol", "in", "1954", "and", "was", "eventually", "named", "the", "Unimate", "."], "sentence-detokenized": "The first digitally controlled and programmable robot was invented by George Devol in 1954 and was eventually named the Unimate.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 30], [31, 34], [35, 47], [48, 53], [54, 57], [58, 66], [67, 69], [70, 76], [77, 82], [83, 85], [86, 90], [91, 94], [95, 98], [99, 109], [110, 115], [116, 119], [120, 127], [127, 128]]}
{"doc_key": "ai-test-76", "ner": [[1, 1, "algorithm"], [3, 3, "algorithm"], [17, 18, "task"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 3, 3, "compare", "", false, false], [3, 3, 17, 18, "general-affiliation", "", false, false], [3, 3, 20, 21, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Like", "DBNs", ",", "DBMs", "can", "learn", "complex", "and", "abstract", "internal", "representations", "of", "input", "in", "tasks", "such", "as", "object", "recognition", "or", "speech", "recognition", ",", "using", "limited", ",", "labelled", "data", "to", "refine", "representations", "built", "using", "a", "large", "set", "of", "unlabelled", "sensory", "input", "data", "."], "sentence-detokenized": "Like DBNs, DBMs can learn complex and abstract internal representations of input in tasks such as object recognition or speech recognition, using limited, labelled data to refine representations built using a large set of unlabelled sensory input data.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 15], [16, 19], [20, 25], [26, 33], [34, 37], [38, 46], [47, 55], [56, 71], [72, 74], [75, 80], [81, 83], [84, 89], [90, 94], [95, 97], [98, 104], [105, 116], [117, 119], [120, 126], [127, 138], [138, 139], [140, 145], [146, 153], [153, 154], [155, 163], [164, 168], [169, 171], [172, 178], [179, 194], [195, 200], [201, 206], [207, 208], [209, 214], [215, 218], [219, 221], [222, 232], [233, 240], [241, 246], [247, 251], [251, 252]]}
{"doc_key": "ai-test-77", "ner": [[3, 8, "task"], [12, 12, "conference"], [14, 14, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 3, 8, "topic", "", false, false], [14, 14, 3, 8, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Scientific", "conferences", "where", "vision", "-", "based", "activity", "recognition", "is", "often", "discussed", "are", "ICCV", "and", "CVPR", "."], "sentence-detokenized": "Scientific conferences where vision-based activity recognition is often discussed are ICCV and CVPR.", "token2charspan": [[0, 10], [11, 22], [23, 28], [29, 35], [35, 36], [36, 41], [42, 50], [51, 62], [63, 65], [66, 71], [72, 81], [82, 85], [86, 90], [91, 94], [95, 99], [99, 100]]}
{"doc_key": "ai-test-78", "ner": [[1, 10, "field"], [4, 5, "algorithm"], [7, 7, "algorithm"], [16, 17, "metrics"], [19, 21, "metrics"], [23, 23, "metrics"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 5, 1, 10, "part-of", "", false, false], [4, 5, 16, 17, "related-to", "finds", false, false], [4, 5, 19, 21, "related-to", "finds", false, false], [4, 5, 38, 39, "related-to", "", false, false], [7, 7, 4, 5, "named", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "statistics", ",", "an", "expectation", "-maximisation", "(", "EM", ")", "algorithm", "is", "an", "iterative", "method", "to", "find", "maximum", "likelihood", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "estimates", "of", "parameters", "in", "statistical", "models", ",", "where", "the", "model", "depends", "on", "unobserved", "latent", "variables", "."], "sentence-detokenized": "In statistics, an expectation-maximisation (EM) algorithm is an iterative method to find maximum likelihood or maximum a posteriori (MAP) estimates of parameters in statistical models, where the model depends on unobserved latent variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 17], [18, 29], [29, 42], [43, 44], [44, 46], [46, 47], [48, 57], [58, 60], [61, 63], [64, 73], [74, 80], [81, 83], [84, 88], [89, 96], [97, 107], [108, 110], [111, 118], [119, 120], [121, 131], [132, 133], [133, 136], [136, 137], [138, 147], [148, 150], [151, 161], [162, 164], [165, 176], [177, 183], [183, 184], [185, 190], [191, 194], [195, 200], [201, 208], [209, 211], [212, 222], [223, 229], [230, 239], [239, 240]]}
{"doc_key": "ai-test-79", "ner": [[7, 9, "metrics"], [11, 14, "metrics"], [15, 17, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 14, 7, 9, "named", "", false, false], [19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Similarly", ",", "researchers", "sometimes", "report", "both", "the", "FALSE", "Positive", "Rate", "(", "FPR", ")", "and", "the", "FALSE", "Negative", "Rate", "(", "FNR", ")", "."], "sentence-detokenized": "Similarly, researchers sometimes report both the FALSE Positive Rate (FPR) and the FALSE Negative Rate (FNR).", "token2charspan": [[0, 9], [9, 10], [11, 22], [23, 32], [33, 39], [40, 44], [45, 48], [49, 54], [55, 63], [64, 68], [69, 70], [70, 73], [73, 74], [75, 78], [79, 82], [83, 88], [89, 97], [98, 102], [103, 104], [104, 107], [107, 108], [108, 109]]}
{"doc_key": "ai-test-80", "ner": [[6, 11, "metrics"], [15, 15, "field"], [18, 19, "metrics"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 15, 6, 11, "usage", "", false, false], [22, 23, 18, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "concept", "is", "similar", "to", "the", "signal", "-", "to", "-", "noise", "ratio", "used", "in", "the", "sciences", "and", "the", "confusion", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "The concept is similar to the signal-to-noise ratio used in the sciences and the confusion matrix used in artificial intelligence.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 25], [26, 29], [30, 36], [36, 37], [37, 39], [39, 40], [40, 45], [46, 51], [52, 56], [57, 59], [60, 63], [64, 72], [73, 76], [77, 80], [81, 90], [91, 97], [98, 102], [103, 105], [106, 116], [117, 129], [129, 130]]}
{"doc_key": "ai-test-81", "ner": [[5, 6, "field"], [13, 14, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [31, 34, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 13, 14, "general-affiliation", "", false, false], [5, 6, 20, 21, "general-affiliation", "", false, false], [5, 6, 23, 24, "general-affiliation", "", false, false], [31, 34, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Code", "of", "Ethics", "on", "Human", "Augmentation", ",", "originally", "introduced", "in", "2004", "by", "Steve", "Mann", "and", "refined", "in", "2013", "with", "Ray", "Kurzweil", "and", "Marvin", "Minsky", ",", "was", "finally", "endorsed", "at", "the", "Virtual", "Reality", "Toronto", "conference", "on", "25", "June", "2017", "."], "sentence-detokenized": "The Code of Ethics on Human Augmentation, originally introduced in 2004 by Steve Mann and refined in 2013 with Ray Kurzweil and Marvin Minsky, was finally endorsed at the Virtual Reality Toronto conference on 25 June 2017.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 18], [19, 21], [22, 27], [28, 40], [40, 41], [42, 52], [53, 63], [64, 66], [67, 71], [72, 74], [75, 80], [81, 85], [86, 89], [90, 97], [98, 100], [101, 105], [106, 110], [111, 114], [115, 123], [124, 127], [128, 134], [135, 141], [141, 142], [143, 146], [147, 154], [155, 163], [164, 166], [167, 170], [171, 178], [179, 186], [187, 194], [195, 205], [206, 208], [209, 211], [212, 216], [217, 221], [221, 222]]}
{"doc_key": "ai-test-82", "ner": [[3, 5, "person"], [11, 13, "organisation"], [19, 20, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 11, 13, "role", "directed_for", false, false], [3, 5, 19, 20, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", ",", "Walter", "R.", "Booth", "directed", "10", "films", "for", "the", "U.K", ".", "Kinoplastikon", ",", "presumably", "in", "collaboration", "with", "Cecil", "Hepworth", "."], "sentence-detokenized": "In 1913, Walter R. Booth directed 10 films for the U.K. Kinoplastikon, presumably in collaboration with Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 18], [19, 24], [25, 33], [34, 36], [37, 42], [43, 46], [47, 50], [51, 54], [54, 55], [56, 69], [69, 70], [71, 81], [82, 84], [85, 98], [99, 103], [104, 109], [110, 118], [118, 119]]}
{"doc_key": "ai-test-83", "ner": [[11, 11, "location"], [13, 14, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 11, 11, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "introduced", "their", "new", "robot", "in", "1961", "at", "a", "fair", "at", "Chicago", "'s", "Cow", "Palace", "."], "sentence-detokenized": "They introduced their new robot in 1961 at a fair at Chicago's Cow Palace.", "token2charspan": [[0, 4], [5, 15], [16, 21], [22, 25], [26, 31], [32, 34], [35, 39], [40, 42], [43, 44], [45, 49], [50, 52], [53, 60], [60, 62], [63, 66], [67, 73], [73, 74]]}
{"doc_key": "ai-test-84", "ner": [[9, 9, "field"], [15, 16, "field"]], "ner_mapping_to_source": [2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "chatbot", "applications", "use", "elaborate", "word", "classification", "processes", ",", "natural", "language", "processing", "engines", "and", "advanced", "artificial", "intelligence", ";", "others", "simply", "scan", "for", "common", "keywords", "and", "generate", "responses", "based", "on", "commonly", "used", "phrases", "from", "an", "associated", "library", "or", "database", "."], "sentence-detokenized": "Some chatbot applications use elaborate word classification processes, natural language processing engines and advanced artificial intelligence; others simply scan for common keywords and generate responses based on commonly used phrases from an associated library or database.", "token2charspan": [[0, 4], [5, 12], [13, 25], [26, 29], [30, 39], [40, 44], [45, 59], [60, 69], [69, 70], [71, 78], [79, 87], [88, 98], [99, 106], [107, 110], [111, 119], [120, 130], [131, 143], [143, 144], [145, 151], [152, 158], [159, 163], [164, 167], [168, 174], [175, 183], [184, 187], [188, 196], [197, 206], [207, 212], [213, 215], [216, 224], [225, 229], [230, 237], [238, 242], [243, 245], [246, 256], [257, 264], [265, 267], [268, 276], [276, 277]]}
{"doc_key": "ai-test-85", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "WaveNet", "model", "proposed", "in", "2016", "delivers", "excellent", "voice", "quality", "performance", "."], "sentence-detokenized": "The WaveNet model proposed in 2016 delivers excellent voice quality performance.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 43], [44, 53], [54, 59], [60, 67], [68, 79], [79, 80]]}
{"doc_key": "ai-test-86", "ner": [[4, 4, "product"], [6, 7, "misc"], [9, 10, "misc"], [12, 13, "misc"], [15, 18, "misc"], [20, 22, "organisation"], [24, 24, "organisation"], [27, 29, "organisation"], [31, 31, "organisation"], [33, 36, "organisation"], [38, 39, "organisation"], [41, 41, "organisation"], [43, 45, "organisation"], [48, 48, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 4, 6, 7, "general-affiliation", "", false, false], [4, 4, 9, 10, "general-affiliation", "", false, false], [4, 4, 12, 13, "general-affiliation", "", false, false], [4, 4, 15, 18, "general-affiliation", "", false, false], [20, 22, 4, 4, "usage", "", false, false], [24, 24, 4, 4, "usage", "", false, false], [27, 29, 4, 4, "usage", "", false, false], [31, 31, 4, 4, "usage", "", false, false], [33, 36, 4, 4, "usage", "", false, false], [38, 39, 4, 4, "usage", "", false, false], [41, 41, 4, 4, "usage", "", false, false], [43, 45, 4, 4, "usage", "", false, false], [48, 48, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organisations", "known", "to", "use", "ALE", "for", "emergency", "management", ",", "disaster", "response", ",", "ordinary", "communications", "or", "response", "to", "extraordinary", "situations", ":", "American", "Red", "Cross", ",", "FEMA", ",", "Disaster", "Medical", "Assistance", "Teams", ",", "NATO", ",", "Federal", "Bureau", "of", "Investigation", ",", "United", "Nations", ",", "AT&T", ",", "Civil", "Air", "Patrol", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organisations known to use ALE for emergency management, disaster response, ordinary communications or response to extraordinary situations: American Red Cross, FEMA, Disaster Medical Assistance Teams, NATO, Federal Bureau of Investigation, United Nations, AT&T, Civil Air Patrol, (ARES).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 30], [31, 34], [35, 44], [45, 55], [55, 56], [57, 65], [66, 74], [74, 75], [76, 84], [85, 99], [100, 102], [103, 111], [112, 114], [115, 128], [129, 139], [139, 140], [141, 149], [150, 153], [154, 159], [159, 160], [161, 165], [165, 166], [167, 175], [176, 183], [184, 194], [195, 200], [200, 201], [202, 206], [206, 207], [208, 215], [216, 222], [223, 225], [226, 239], [239, 240], [241, 247], [248, 255], [255, 256], [257, 261], [261, 262], [263, 268], [269, 272], [273, 279], [279, 280], [281, 282], [282, 286], [286, 287], [287, 288]]}
{"doc_key": "ai-test-87", "ner": [[6, 7, "algorithm"], [17, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", ",", "for", "simplicity", ",", "the", "Kronecker", "delta", "is", "used", "(", "cf", ".", "the", "derivative", "of", "a", "sigmoid", "function", ",", "expressed", "via", "the", "function", "itself", ")", "."], "sentence-detokenized": "Here, for simplicity, the Kronecker delta is used (cf. the derivative of a sigmoid function, expressed via the function itself).", "token2charspan": [[0, 4], [4, 5], [6, 9], [10, 20], [20, 21], [22, 25], [26, 35], [36, 41], [42, 44], [45, 49], [50, 51], [51, 53], [53, 54], [55, 58], [59, 69], [70, 72], [73, 74], [75, 82], [83, 91], [91, 92], [93, 102], [103, 106], [107, 110], [111, 119], [120, 126], [126, 127], [127, 128]]}
{"doc_key": "ai-test-88", "ner": [[15, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "theory", "is", "based", "on", "philosophical", "foundations", ",", "and", "was", "founded", "around", "1960", "by", "Ray", "Solomonoff", ".", "Samuel", "Rathmanner", "and", "Marcus", "Hutter", "."], "sentence-detokenized": "The theory is based on philosophical foundations, and was founded around 1960 by Ray Solomonoff. Samuel Rathmanner and Marcus Hutter.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 36], [37, 48], [48, 49], [50, 53], [54, 57], [58, 65], [66, 72], [73, 77], [78, 80], [81, 84], [85, 95], [95, 96], [97, 103], [104, 114], [115, 118], [119, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [11, 12, "misc"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 12, "type-of", "", false, false], [0, 0, 15, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "a", "freely", "accessible", "database", "originally", "set", "up", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "was", "expanded", "by", "adding", "definitions", "and", "is", "now", "also", "seen", "as", "a", "dictionary", "."], "sentence-detokenized": "WordNet, a freely accessible database originally set up as a semantic network based on psycholinguistic principles, was expanded by adding definitions and is now also seen as a dictionary.", "token2charspan": [[0, 7], [7, 8], [9, 10], [11, 17], [18, 28], [29, 37], [38, 48], [49, 52], [53, 55], [56, 58], [59, 60], [61, 69], [70, 77], [78, 83], [84, 86], [87, 103], [104, 114], [114, 115], [116, 119], [120, 128], [129, 131], [132, 138], [139, 150], [151, 154], [155, 157], [158, 161], [162, 166], [167, 171], [172, 174], [175, 176], [177, 187], [187, 188]]}
{"doc_key": "ai-test-90", "ner": [[2, 2, "field"], [14, 14, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 14, 2, 2, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Advances", "in", "computational", "imaging", "research", "are", "presented", "in", "several", "venues", ",", "including", "publications", "by", "SIGGRAPH", "and", "the", "."], "sentence-detokenized": "Advances in computational imaging research are presented in several venues, including publications by SIGGRAPH and the.", "token2charspan": [[0, 8], [9, 11], [12, 25], [26, 33], [34, 42], [43, 46], [47, 56], [57, 59], [60, 67], [68, 74], [74, 75], [76, 85], [86, 98], [99, 101], [102, 110], [111, 114], [115, 118], [118, 119]]}
{"doc_key": "ai-test-91", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "understood", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multi-class", "classification", "."], "sentence-detokenized": "Classification can be understood as two separate problems - binary classification and multi-class classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 97], [98, 112], [112, 113]]}
{"doc_key": "ai-test-92", "ner": [[12, 12, "algorithm"], [17, 18, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 12, 12, "type-of", "", false, false], [21, 21, 17, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Advanced", "gene", "finders", "for", "both", "prokaryotic", "and", "eukaryotic", "genomes", "typically", "use", "complex", "probabilistic", "models", ",", "such", "as", "hidden", "Markov", "models", "(", "HMMs", ")", "to", "combine", "information", "from", "a", "variety", "of", "different", "signal", "and", "content", "measurements", "."], "sentence-detokenized": "Advanced gene finders for both prokaryotic and eukaryotic genomes typically use complex probabilistic models, such as hidden Markov models (HMMs) to combine information from a variety of different signal and content measurements.", "token2charspan": [[0, 8], [9, 13], [14, 21], [22, 25], [26, 30], [31, 42], [43, 46], [47, 57], [58, 65], [66, 75], [76, 79], [80, 87], [88, 101], [102, 108], [108, 109], [110, 114], [115, 117], [118, 124], [125, 131], [132, 138], [139, 140], [140, 144], [144, 145], [146, 148], [149, 156], [157, 168], [169, 173], [174, 175], [176, 183], [184, 186], [187, 196], [197, 203], [204, 207], [208, 215], [216, 228], [228, 229]]}
{"doc_key": "ai-test-93", "ner": [[0, 0, "misc"], [3, 3, "misc"], [9, 10, "field"], [13, 14, "algorithm"], [17, 18, "algorithm"], [21, 21, "algorithm"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 9, 10, "part-of", "", false, false], [0, 0, 13, 14, "usage", "", false, false], [3, 3, 0, 0, "named", "", false, false], [17, 18, 0, 0, "origin", "", true, false], [21, 21, 17, 18, "named", "", false, false], [31, 32, 0, 0, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Neuro-evolution", ",", "or", "neuro-evolution", ",", "is", "a", "form", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "generate", "artificial", "neural", "networks", "(", "ANN", ")", ",", "parameters", ",", "topology", "and", "rules", ".", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuro-evolution, or neuro-evolution, is a form of artificial intelligence that uses evolutionary algorithms to generate artificial neural networks (ANN), parameters, topology and rules. and evolutionary robotics.", "token2charspan": [[0, 15], [15, 16], [17, 19], [20, 35], [35, 36], [37, 39], [40, 41], [42, 46], [47, 49], [50, 60], [61, 73], [74, 78], [79, 83], [84, 96], [97, 107], [108, 110], [111, 119], [120, 130], [131, 137], [138, 146], [147, 148], [148, 151], [151, 152], [152, 153], [154, 164], [164, 165], [166, 174], [175, 178], [179, 184], [184, 185], [186, 189], [190, 202], [203, 211], [211, 212]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [5, 5, "metrics"], [8, 8, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "IBM", "proposed", "and", "realised", "BLEU", "'s", "system", "Papineni", "et", "al", "."], "sentence-detokenized": "Since IBM proposed and realised BLEU's system Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 31], [32, 36], [36, 38], [39, 45], [46, 54], [55, 57], [58, 60], [60, 61]]}
{"doc_key": "ai-test-95", "ner": [[12, 18, "conference"], [20, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 20, 12, 18, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "experts", "took", "part", "in", "a", "conference", "organised", "by", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "to", "discuss", "whether", "computers", "and", "robots", "could", "acquire", "some", "autonomy", ",", "and", "to", "what", "extent", "these", "capabilities", "could", "pose", "a", "threat", "or", "danger", "."], "sentence-detokenized": "In 2009, experts took part in a conference organised by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether computers and robots could acquire some autonomy, and to what extent these capabilities could pose a threat or danger.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 21], [22, 26], [27, 29], [30, 31], [32, 42], [43, 52], [53, 55], [56, 59], [60, 71], [72, 75], [76, 79], [80, 91], [92, 94], [95, 105], [106, 118], [119, 120], [120, 124], [124, 125], [126, 128], [129, 136], [137, 144], [145, 154], [155, 158], [159, 165], [166, 171], [172, 179], [180, 184], [185, 193], [193, 194], [195, 198], [199, 201], [202, 206], [207, 213], [214, 219], [220, 232], [233, 238], [239, 243], [244, 245], [246, 252], [253, 255], [256, 262], [262, 263]]}
{"doc_key": "ai-test-96", "ner": [[24, 25, "researcher"], [27, 28, "researcher"], [30, 35, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[30, 35, 24, 25, "artifact", "", false, false], [30, 35, 27, 28, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["After", "boosting", ",", "a", "classifier", "composed", "of", "200", "features", "can", "yield", "a", "95", "%", "detection", "rate", "at", "a", "^", "{", "-", "5", "}", "/", "P.", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "After boosting, a classifier composed of 200 features can yield a 95% detection rate at a ^ {-5} / P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 17], [18, 28], [29, 37], [38, 40], [41, 44], [45, 53], [54, 57], [58, 63], [64, 65], [66, 68], [68, 69], [70, 79], [80, 84], [85, 87], [88, 89], [90, 91], [92, 93], [93, 94], [94, 95], [95, 96], [97, 98], [99, 101], [102, 107], [107, 108], [109, 111], [112, 117], [117, 118], [119, 125], [126, 130], [130, 131], [131, 135], [136, 142], [143, 152], [152, 153], [154, 158], [158, 159]]}
{"doc_key": "ai-test-97", "ner": [[9, 9, "organisation"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "website", "was", "originally", "Perl", "-", "based", ",", "but", "IMDb", "no", "longer", "discloses", "which", "software", "it", "uses", "for", "security", "reasons", "."], "sentence-detokenized": "The website was originally Perl-based, but IMDb no longer discloses which software it uses for security reasons.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 26], [27, 31], [31, 32], [32, 37], [37, 38], [39, 42], [43, 47], [48, 50], [51, 57], [58, 67], [68, 73], [74, 82], [83, 85], [86, 90], [91, 94], [95, 103], [104, 111], [111, 112]]}
{"doc_key": "ai-test-98", "ner": [[9, 10, "researcher"], [12, 13, "researcher"], [15, 16, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "start", "-", "up", "was", "founded", "in", "2010", "by", "Demis", "Hassabis", ",", "Shane", "Legg", "and", "Mustafa", "Suleyman", "."], "sentence-detokenized": "The start-up was founded in 2010 by Demis Hassabis, Shane Legg and Mustafa Suleyman.", "token2charspan": [[0, 3], [4, 9], [9, 10], [10, 12], [13, 16], [17, 24], [25, 27], [28, 32], [33, 35], [36, 41], [42, 50], [50, 51], [52, 57], [58, 62], [63, 66], [67, 74], [75, 83], [83, 84]]}
{"doc_key": "ai-test-99", "ner": [[4, 5, "misc"], [8, 10, "metrics"], [25, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 4, 5, "type-of", "", false, false], [25, 26, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "very", "commonly", "used", "loss", "functions", "are", "the", "mean", "squared", "error", ",", "mathL", "(", "a", ")", "=", "a", "^", "2", "/", "math", ",", "and", "the", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "math", "."], "sentence-detokenized": "Two very commonly used loss functions are the mean squared error, mathL (a) = a ^ 2 / math, and the absolute loss, mathL (a) = | a | math.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 27], [28, 37], [38, 41], [42, 45], [46, 50], [51, 58], [59, 64], [64, 65], [66, 71], [72, 73], [73, 74], [74, 75], [76, 77], [78, 79], [80, 81], [82, 83], [84, 85], [86, 90], [90, 91], [92, 95], [96, 99], [100, 108], [109, 113], [113, 114], [115, 120], [121, 122], [122, 123], [123, 124], [125, 126], [127, 128], [129, 130], [131, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-test-100", "ner": [[3, 5, "algorithm"], [12, 14, "algorithm"], [16, 16, "algorithm"], [19, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 12, 14, "type-of", "example_of", false, false], [12, 14, 19, 20, "related-to", "", false, false], [16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "soft", "-margin", "support", "vector", "machine", "described", "above", "is", "an", "example", "of", "empirical", "risk", "minimisation", "(", "ERM", ")", "for", "hinge", "loss", "."], "sentence-detokenized": "The soft-margin support vector machine described above is an example of empirical risk minimisation (ERM) for hinge loss.", "token2charspan": [[0, 3], [4, 8], [8, 15], [16, 23], [24, 30], [31, 38], [39, 48], [49, 54], [55, 57], [58, 60], [61, 68], [69, 71], [72, 81], [82, 86], [87, 99], [100, 101], [101, 104], [104, 105], [106, 109], [110, 115], [116, 120], [120, 121]]}
{"doc_key": "ai-test-101", "ner": [[11, 11, "task"], [0, 2, "task"], [22, 22, "organisation"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[0, 2, 11, 11, "type-of", "", false, false], [22, 22, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["Neural", "machine", "translation", ",", "a", "deep", "learning", "-", "based", "approach", "to", "MT", ",", "has", "made", "rapid", "progress", "in", "recent", "years", ",", "and", "Google", "has", "announced", "that", "its", "translation", "services", "now", "use", "this", "technology", "instead", "of", "its", "previous", "statistical", "methods", "."], "sentence-detokenized": "Neural machine translation, a deep learning-based approach to MT, has made rapid progress in recent years, and Google has announced that its translation services now use this technology instead of its previous statistical methods.", "token2charspan": [[0, 6], [7, 14], [15, 26], [26, 27], [28, 29], [30, 34], [35, 43], [43, 44], [44, 49], [50, 58], [59, 61], [62, 64], [64, 65], [66, 69], [70, 74], [75, 80], [81, 89], [90, 92], [93, 99], [100, 105], [105, 106], [107, 110], [111, 117], [118, 121], [122, 131], [132, 136], [137, 140], [141, 152], [153, 161], [162, 165], [166, 169], [170, 174], [175, 185], [186, 193], [194, 196], [197, 200], [201, 209], [210, 221], [222, 229], [229, 230]]}
{"doc_key": "ai-test-102", "ner": [[14, 14, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "generally", "yields", "very", "large", "performance", "improvements", "when", "working", "with", "large", "corpora", "such", "as", "WordNet", "."], "sentence-detokenized": "This generally yields very large performance improvements when working with large corpora such as WordNet.", "token2charspan": [[0, 4], [5, 14], [15, 21], [22, 26], [27, 32], [33, 44], [45, 57], [58, 62], [63, 70], [71, 75], [76, 81], [82, 89], [90, 94], [95, 97], [98, 105], [105, 106]]}
{"doc_key": "ai-test-103", "ner": [[0, 1, "task"], [5, 5, "field"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 17, 19, "part-of", "", false, false], [17, 19, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Face", "detection", "is", "used", "in", "biometrics", ",", "often", "as", "part", "of", "(", "or", "together", "with", ")", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Face detection is used in biometrics, often as part of (or together with) a facial recognition system.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 22], [23, 25], [26, 36], [36, 37], [38, 43], [44, 46], [47, 51], [52, 54], [55, 56], [56, 58], [59, 67], [68, 72], [72, 73], [74, 75], [76, 82], [83, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-104", "ner": [[2, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["trained", "by", "maximum", "likelihood", "estimation", "."], "sentence-detokenized": "trained by maximum likelihood estimation.", "token2charspan": [[0, 7], [8, 10], [11, 18], [19, 29], [30, 40], [40, 41]]}
{"doc_key": "ai-test-105", "ner": [[3, 3, "country"], [5, 9, "organisation"], [13, 13, "location"], [15, 15, "country"], [17, 20, "organisation"], [22, 22, "country"], [28, 28, "organisation"], [33, 35, "organisation"], [37, 37, "country"], [48, 51, "organisation"], [53, 53, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 9, 13, 13, "physical", "", false, false], [13, 13, 15, 15, "physical", "", false, false], [17, 20, 22, 22, "physical", "", false, false], [33, 35, 37, 37, "physical", "", false, false], [48, 51, 53, 53, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd", ".", "in", "Thailand", ";", "Komatsu", "(", "Shanghai", ")", "Ltd.", "in", "1996", "in", "Shanghai", ",", "China", ";", "Industrial", "Power", "Alliance", "Ltd.", "in", "Japan", ",", "a", "joint", "venture", "with", "Cummins", ",", "in", "1998", ";", "L&T-", "Komatsu", "Limited", "in", "India", "in", "1998", "(", "shares", "sold", "in", "2013", ")", ";", "and", "Komatsu", "Brasil", "International", "Ltda.", "in", "Brazil", "in", "1998", "."], "sentence-detokenized": "Ltd. in Thailand; Komatsu (Shanghai) Ltd. in 1996 in Shanghai, China; Industrial Power Alliance Ltd. in Japan, a joint venture with Cummins, in 1998; L&T-Komatsu Limited in India in 1998 (shares sold in 2013); and Komatsu Brasil International Ltda. in Brazil in 1998.", "token2charspan": [[0, 3], [3, 4], [5, 7], [8, 16], [16, 17], [18, 25], [26, 27], [27, 35], [35, 36], [37, 41], [42, 44], [45, 49], [50, 52], [53, 61], [61, 62], [63, 68], [68, 69], [70, 80], [81, 86], [87, 95], [96, 100], [101, 103], [104, 109], [109, 110], [111, 112], [113, 118], [119, 126], [127, 131], [132, 139], [139, 140], [141, 143], [144, 148], [148, 149], [150, 154], [154, 161], [162, 169], [170, 172], [173, 178], [179, 181], [182, 186], [187, 188], [188, 194], [195, 199], [200, 202], [203, 207], [207, 208], [208, 209], [210, 213], [214, 221], [222, 228], [229, 242], [243, 248], [249, 251], [252, 258], [259, 261], [262, 266], [266, 267]]}
{"doc_key": "ai-test-106", "ner": [[0, 0, "organisation"], [4, 6, "misc"], [11, 12, "person"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[11, 12, 0, 0, "physical", "", false, false], [11, 12, 4, 6, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["dgp", "also", "occasionally", "hosts", "artists", "in", "residence", "(", "e.g.", "Oscar-", "winner", "Chris", "Landreth", "."], "sentence-detokenized": "dgp also occasionally hosts artists in residence (e.g. Oscar-winner Chris Landreth.", "token2charspan": [[0, 3], [4, 8], [9, 21], [22, 27], [28, 35], [36, 38], [39, 48], [49, 50], [50, 54], [55, 61], [61, 67], [68, 73], [74, 82], [82, 83]]}
{"doc_key": "ai-test-107", "ner": [[7, 9, "misc"], [12, 14, "misc"], [17, 20, "misc"], [25, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "currently", "includes", "four", "sub-competitions", "-", "the", "RoboMaster", "Robotics", "Competition", ",", "the", "RoboMaster", "Technical", "Challenge", ",", "the", "ICRA", "RoboMaster", "AI", "Challenge", ",", "and", "the", "new", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "It currently includes four sub-competitions - the RoboMaster Robotics Competition, the RoboMaster Technical Challenge, the ICRA RoboMaster AI Challenge, and the new RoboMaster Youth Tournament.", "token2charspan": [[0, 2], [3, 12], [13, 21], [22, 26], [27, 43], [44, 45], [46, 49], [50, 60], [61, 69], [70, 81], [81, 82], [83, 86], [87, 97], [98, 107], [108, 117], [117, 118], [119, 122], [123, 127], [128, 138], [139, 141], [142, 151], [151, 152], [153, 156], [157, 160], [161, 164], [165, 175], [176, 181], [182, 192], [192, 193]]}
{"doc_key": "ai-test-108", "ner": [[15, 17, "algorithm"], [21, 22, "algorithm"], [24, 25, "field"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["By", "the", "early", "2000s", ",", "the", "dominant", "speech", "processing", "strategy", "began", "to", "shift", "from", "the", "hidden", "Markov", "model", "to", "more", "modern", "neural", "networks", "and", "deep", "learning", "."], "sentence-detokenized": "By the early 2000s, the dominant speech processing strategy began to shift from the hidden Markov model to more modern neural networks and deep learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 18], [18, 19], [20, 23], [24, 32], [33, 39], [40, 50], [51, 59], [60, 65], [66, 68], [69, 74], [75, 79], [80, 83], [84, 90], [91, 97], [98, 103], [104, 106], [107, 111], [112, 118], [119, 125], [126, 134], [135, 138], [139, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-test-109", "ner": [[9, 11, "misc"], [16, 18, "metrics"], [21, 25, "metrics"], [30, 32, "metrics"], [35, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 18, 21, 25, "related-to", "equal", false, false], [30, 32, 35, 39, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "equivalent", "expression", ",", "in", "the", "case", "of", "a", "binary", "target", "figure", ",", "is", "that", "the", "TRUE", "position", "figure", "and", "the", "FALSE", "position", "figure", "are", "equal", "(", "and", "thus", "the", "FALSE", "negative", "figure", "and", "the", "TRUE", "negative", "figure", "are", "equal", ")", "for", "each", "value", "of", "the", "sensitive", "features", ":"], "sentence-detokenized": "Another equivalent expression, in the case of a binary target figure, is that the TRUE position figure and the FALSE position figure are equal (and thus the FALSE negative figure and the TRUE negative figure are equal) for each value of the sensitive features:", "token2charspan": [[0, 7], [8, 18], [19, 29], [29, 30], [31, 33], [34, 37], [38, 42], [43, 45], [46, 47], [48, 54], [55, 61], [62, 68], [68, 69], [70, 72], [73, 77], [78, 81], [82, 86], [87, 95], [96, 102], [103, 106], [107, 110], [111, 116], [117, 125], [126, 132], [133, 136], [137, 142], [143, 144], [144, 147], [148, 152], [153, 156], [157, 162], [163, 171], [172, 178], [179, 182], [183, 186], [187, 191], [192, 200], [201, 207], [208, 211], [212, 217], [217, 218], [219, 222], [223, 227], [228, 233], [234, 236], [237, 240], [241, 250], [251, 259], [259, 260]]}
{"doc_key": "ai-test-110", "ner": [[1, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "MATLAB", "function", ","], "sentence-detokenized": "The MATLAB function,", "token2charspan": [[0, 3], [4, 10], [11, 19], [19, 20]]}
{"doc_key": "ai-test-111", "ner": [[1, 2, "product"], [7, 7, "misc"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 1, 2, "part-of", "", false, false], [17, 18, 1, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "articulated", "robot", "is", "a", "robot", "with", "rotating", "joints", "(", "e.g.", "a", "robot", "with", "legs", "or", "an", "industrial", "robot", ")", "."], "sentence-detokenized": "An articulated robot is a robot with rotating joints (e.g. a robot with legs or an industrial robot).", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 23], [24, 25], [26, 31], [32, 36], [37, 45], [46, 52], [53, 54], [54, 58], [59, 60], [61, 66], [67, 71], [72, 76], [77, 79], [80, 82], [83, 93], [94, 99], [99, 100], [100, 101]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [5, 6, "product"], [8, 9, "product"], [13, 13, "misc"], [21, 25, "product"], [28, 30, "misc"], [34, 34, "location"], [36, 36, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 13, 13, "general-affiliation", "nationality", false, false], [0, 0, 28, 30, "usage", "", false, false], [0, 0, 34, 34, "physical", "", false, false], [5, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [34, 34, 36, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "also", "known", "as", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "an", "American", "internet", "radio", "service", "for", "music", "streaming", "and", "automated", "recommendation", "system", ",", "powered", "by", "the", "Music", "Genome", "Project", "and", "headquartered", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (also known as Pandora Media or Pandora Radio) is an American internet radio service for music streaming and automated recommendation system, powered by the Music Genome Project and headquartered in Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 30], [31, 36], [37, 39], [40, 47], [48, 53], [53, 54], [55, 57], [58, 60], [61, 69], [70, 78], [79, 84], [85, 92], [93, 96], [97, 102], [103, 112], [113, 116], [117, 126], [127, 141], [142, 148], [148, 149], [150, 157], [158, 160], [161, 164], [165, 170], [171, 177], [178, 185], [186, 189], [190, 203], [204, 206], [207, 214], [214, 215], [216, 226], [226, 227]]}
{"doc_key": "ai-test-113", "ner": [[7, 10, "organisation"], [18, 21, "organisation"], [27, 28, "conference"], [40, 40, "conference"], [42, 42, "conference"], [44, 44, "conference"], [46, 46, "conference"], [48, 48, "conference"], [50, 50, "conference"], [52, 52, "conference"], [54, 54, "conference"], [56, 56, "conference"], [58, 58, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "board", "member", "of", "the", "International", "Machine", "Learning", "Society", ",", "has", "been", "a", "member", "of", "the", "Executive", "Council", "of", "AAAI", ",", "was", "PC", "co-chair", "of", "ICML", "2011", ",", "and", "has", "served", "as", "senior", "PC", "member", "for", "conferences", "including", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", "and", "WWW", "."], "sentence-detokenized": "She is a board member of the International Machine Learning Society, has been a member of the Executive Council of AAAI, was PC co-chair of ICML 2011, and has served as senior PC member for conferences including AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM and WWW.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 14], [15, 21], [22, 24], [25, 28], [29, 42], [43, 50], [51, 59], [60, 67], [67, 68], [69, 72], [73, 77], [78, 79], [80, 86], [87, 89], [90, 93], [94, 103], [104, 111], [112, 114], [115, 119], [119, 120], [121, 124], [125, 127], [128, 136], [137, 139], [140, 144], [145, 149], [149, 150], [151, 154], [155, 158], [159, 165], [166, 168], [169, 175], [176, 178], [179, 185], [186, 189], [190, 201], [202, 211], [212, 216], [216, 217], [218, 222], [222, 223], [224, 229], [229, 230], [231, 235], [235, 236], [237, 240], [240, 241], [242, 248], [248, 249], [250, 253], [253, 254], [255, 259], [259, 260], [261, 265], [266, 269], [270, 273], [273, 274]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [5, 10, "organisation"], [12, 12, "organisation"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 10, "role", "", false, false], [12, 12, 5, 10, "named", "", false, false], [16, 16, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "developed", "the", "Robocrane", ",", "in", "which", "the", "platform", "hangs", "from", "six", "cables", "instead", "of", "being", "supported", "by", "six", "jacks", "."], "sentence-detokenized": "James S. Albus of the National Institute of Standards and Technology (NIST) developed the Robocrane, in which the platform hangs from six cables instead of being supported by six jacks.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [74, 75], [76, 85], [86, 89], [90, 99], [99, 100], [101, 103], [104, 109], [110, 113], [114, 122], [123, 128], [129, 133], [134, 137], [138, 144], [145, 152], [153, 155], [156, 161], [162, 171], [172, 174], [175, 178], [179, 184], [184, 185]]}
{"doc_key": "ai-test-115", "ner": [[3, 5, "algorithm"], [9, 10, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 3, 5, "type-of", "", false, false], [13, 14, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "class", "of", "direct", "search", "algorithms", "are", "the", "various", "evolutionary", "algorithms", ",", "e.g.", "genetic", "algorithms", "."], "sentence-detokenized": "Another class of direct search algorithms are the various evolutionary algorithms, e.g. genetic algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 23], [24, 30], [31, 41], [42, 45], [46, 49], [50, 57], [58, 70], [71, 81], [81, 82], [83, 87], [88, 95], [96, 106], [106, 107]]}
{"doc_key": "ai-test-116", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 0, 0, "named", "", false, false], [6, 6, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "industrial", "robots", "and", "factory", "automation", "solutions", "."], "sentence-detokenized": "KUKA is a German manufacturer of industrial robots and factory automation solutions.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-117", "ner": [[11, 12, "person"], [15, 20, "misc"], [22, 23, "person"], [25, 25, "misc"], [27, 28, "person"], [30, 31, "misc"], [33, 34, "person"], [36, 38, "misc"], [40, 42, "person"], [44, 47, "misc"], [49, 50, "person"], [52, 55, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[15, 20, 11, 12, "artifact", "", false, false], [25, 25, 22, 23, "artifact", "", false, false], [30, 31, 27, 28, "artifact", "", false, false], [36, 38, 33, 34, "artifact", "", false, false], [44, 47, 40, 42, "artifact", "", false, false], [52, 55, 49, 50, "artifact", "", false, false]], "relations_mapping_to_source": [1, 3, 5, 7, 9, 11], "sentence": ["Other", "films", "between", "2016", "and", "2020", "shot", "with", "IMAX", "cameras", "included", "Zack", "Snyder", "'s", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", ",", "Clint", "Eastwood", "'s", "Sully", ",", "Damien", "Chazelle", "'s", "First", "Man", ",", "Patty", "Jenkins", "'", "Wonder", "Woman", "1984", ",", "Cary", "Joji", "Fukunaga", "'s", "No", "Time", "to", "Die", "and", "Joseph", "Kosinski", "'s", "Top", "Gun", ":", "Maverick", "."], "sentence-detokenized": "Other films between 2016 and 2020 shot with IMAX cameras included Zack Snyder's Batman v Superman: Dawn of Justice, Clint Eastwood's Sully, Damien Chazelle's First Man, Patty Jenkins' Wonder Woman 1984, Cary Joji Fukunaga's No Time to Die and Joseph Kosinski's Top Gun: Maverick.", "token2charspan": [[0, 5], [6, 11], [12, 19], [20, 24], [25, 28], [29, 33], [34, 38], [39, 43], [44, 48], [49, 56], [57, 65], [66, 70], [71, 77], [77, 79], [80, 86], [87, 88], [89, 97], [97, 98], [99, 103], [104, 106], [107, 114], [114, 115], [116, 121], [122, 130], [130, 132], [133, 138], [138, 139], [140, 146], [147, 155], [155, 157], [158, 163], [164, 167], [167, 168], [169, 174], [175, 182], [182, 183], [184, 190], [191, 196], [197, 201], [201, 202], [203, 207], [208, 212], [213, 221], [221, 223], [224, 226], [227, 231], [232, 234], [235, 238], [239, 242], [243, 249], [250, 258], [258, 260], [261, 264], [265, 268], [268, 269], [270, 278], [278, 279]]}
{"doc_key": "ai-test-118", "ner": [[2, 3, "misc"], [12, 14, "organisation"], [16, 16, "organisation"], [31, 32, "country"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[12, 14, 2, 3, "usage", "", false, false], [12, 14, 31, 32, "physical", "", false, false], [16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["The", "trial", "MICR", "E13B", "font", "was", "shown", "in", "July", "1956", "to", "the", "American", "Bankers", "Association", "(", "ABA", ")", ",", "which", "approved", "it", "as", "the", "MICR", "standard", "for", "negotiable", "documents", "in", "the", "United", "States", "in", "1958", "."], "sentence-detokenized": "The trial MICR E13B font was shown in July 1956 to the American Bankers Association (ABA), which approved it as the MICR standard for negotiable documents in the United States in 1958.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 19], [20, 24], [25, 28], [29, 34], [35, 37], [38, 42], [43, 47], [48, 50], [51, 54], [55, 63], [64, 71], [72, 83], [84, 85], [85, 88], [88, 89], [89, 90], [91, 96], [97, 105], [106, 108], [109, 111], [112, 115], [116, 120], [121, 129], [130, 133], [134, 144], [145, 154], [155, 157], [158, 161], [162, 168], [169, 175], [176, 178], [179, 183], [183, 184]]}
{"doc_key": "ai-test-119", "ner": [[0, 2, "misc"], [15, 16, "field"], [19, 20, "field"], [23, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 16, 0, 2, "usage", "", false, false], [19, 20, 15, 16, "part-of", "", false, false], [23, 23, 0, 2, "usage", "", false, false], [25, 26, 0, 2, "usage", "", false, false], [28, 28, 0, 2, "usage", "", false, false], [30, 30, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "are", "widely", "applied", "to", "many", "difficult", "computational", "problems", ",", "including", "problems", "from", "computer", "science", "(", "especially", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms are widely applied to many difficult computational problems, including problems from computer science (especially artificial intelligence), mathematics, operations research, engineering and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 27], [28, 34], [35, 42], [43, 45], [46, 50], [51, 60], [61, 74], [75, 83], [83, 84], [85, 94], [95, 103], [104, 108], [109, 117], [118, 125], [126, 127], [127, 137], [138, 148], [149, 161], [161, 162], [162, 163], [164, 175], [175, 176], [177, 187], [188, 196], [196, 197], [198, 209], [210, 213], [214, 228], [228, 229]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [8, 8, "location"], [10, 10, "country"], [14, 14, "country"], [22, 23, "algorithm"], [25, 25, "algorithm"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 8, 8, "physical", "", false, false], [0, 1, 14, 14, "general-affiliation", "nationality", false, false], [0, 1, 22, 23, "general-affiliation", "topic_of_study", false, false], [0, 1, 25, 25, "general-affiliation", "topic_of_study", false, false], [8, 8, 10, 10, "physical", "", false, false], [25, 25, 27, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "born", "3", "September", "1947", ",", "Wallersdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "has", "studied", "the", "use", "of", "bounded", "rationality", "and", "heuristics", "in", "decision", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (born 3 September 1947, Wallersdorf, Germany) is a German psychologist who has studied the use of bounded rationality and heuristics in decision making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 21], [22, 23], [24, 33], [34, 38], [38, 39], [40, 51], [51, 52], [53, 60], [60, 61], [62, 64], [65, 66], [67, 73], [74, 86], [87, 90], [91, 94], [95, 102], [103, 106], [107, 110], [111, 113], [114, 121], [122, 133], [134, 137], [138, 148], [149, 151], [152, 160], [161, 167], [167, 168]]}
{"doc_key": "ai-test-121", "ner": [[3, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["to", "minimise", "the", "mean", "squared", "error", "."], "sentence-detokenized": "to minimise the mean squared error.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [21, 28], [29, 34], [34, 35]]}
{"doc_key": "ai-test-122", "ner": [[12, 13, "misc"], [16, 17, "organisation"], [30, 32, "field"], [50, 51, "misc"], [60, 62, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 16, 17, "origin", "", false, false], [50, 51, 60, 62, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["But", "even", "an", "official", "language", "with", "a", "regulatory", "academy", ",", "such", "as", "Standard", "French", "with", "the", "Acad\u00e9mie", "fran\u00e7aise", ",", "is", "classified", "as", "a", "natural", "language", "(", "e.g.", "in", "terms", "of", "natural", "language", "processing", ")", ",", "because", "by", "its", "prescriptive", "points", "it", "is", "not", "constructed", "enough", "to", "be", "classified", "as", "a", "constructed", "language", "or", "controlled", "enough", "to", "be", "classified", "as", "a", "controlled", "natural", "language", "."], "sentence-detokenized": "But even an official language with a regulatory academy, such as Standard French with the Acad\u00e9mie fran\u00e7aise, is classified as a natural language (e.g. in terms of natural language processing), because by its prescriptive points it is not constructed enough to be classified as a constructed language or controlled enough to be classified as a controlled natural language.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 20], [21, 29], [30, 34], [35, 36], [37, 47], [48, 55], [55, 56], [57, 61], [62, 64], [65, 73], [74, 80], [81, 85], [86, 89], [90, 98], [99, 108], [108, 109], [110, 112], [113, 123], [124, 126], [127, 128], [129, 136], [137, 145], [146, 147], [147, 151], [152, 154], [155, 160], [161, 163], [164, 171], [172, 180], [181, 191], [191, 192], [192, 193], [194, 201], [202, 204], [205, 208], [209, 221], [222, 228], [229, 231], [232, 234], [235, 238], [239, 250], [251, 257], [258, 260], [261, 263], [264, 274], [275, 277], [278, 279], [280, 291], [292, 300], [301, 303], [304, 314], [315, 321], [322, 324], [325, 327], [328, 338], [339, 341], [342, 343], [344, 354], [355, 362], [363, 371], [371, 372]]}
{"doc_key": "ai-test-123", "ner": [[13, 13, "metrics"], [15, 16, "metrics"], [18, 18, "metrics"], [36, 37, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[18, 18, 15, 16, "named", "", false, false], [39, 39, 36, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "a", "number", "of", "other", "measures", ",", "the", "simplest", "of", "which", "is", "accuracy", "or", "Fraction", "Correct", "(", "FC", ")", ",", "which", "measures", "the", "fraction", "of", "all", "cases", "that", "are", "correctly", "categorised", ";", "its", "complement", "is", "Fraction", "Incorrect", "(", "FiC", ")", "."], "sentence-detokenized": "There are a number of other measures, the simplest of which is accuracy or Fraction Correct (FC), which measures the fraction of all cases that are correctly categorised; its complement is Fraction Incorrect (FiC).", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 18], [19, 21], [22, 27], [28, 36], [36, 37], [38, 41], [42, 50], [51, 53], [54, 59], [60, 62], [63, 71], [72, 74], [75, 83], [84, 91], [92, 93], [93, 95], [95, 96], [96, 97], [98, 103], [104, 112], [113, 116], [117, 125], [126, 128], [129, 132], [133, 138], [139, 143], [144, 147], [148, 157], [158, 169], [169, 170], [171, 174], [175, 185], [186, 188], [189, 197], [198, 207], [208, 209], [209, 212], [212, 213], [213, 214]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [6, 9, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 9, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "became", "a", "Fellow", "of", "the", "Association", "for", "Computational", "Linguistics", "in", "2016", "."], "sentence-detokenized": "Cardie became a Fellow of the Association for Computational Linguistics in 2016.", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 59], [60, 71], [72, 74], [75, 79], [79, 80]]}
{"doc_key": "ai-test-125", "ner": [[11, 13, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Learning", "the", "parameters", "math", "theta", "/", "math", "is", "usually", "done", "by", "maximum", "likelihood", "learning", "for", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";", "ath", "theta", ")", "/", "math", "."], "sentence-detokenized": "Learning the parameters math theta / math is usually done by maximum likelihood learning for mathp (Y _ i | X _ i;ath theta) / math.", "token2charspan": [[0, 8], [9, 12], [13, 23], [24, 28], [29, 34], [35, 36], [37, 41], [42, 44], [45, 52], [53, 57], [58, 60], [61, 68], [69, 79], [80, 88], [89, 92], [93, 98], [99, 100], [100, 101], [102, 103], [104, 105], [106, 107], [108, 109], [110, 111], [112, 113], [113, 114], [114, 117], [118, 123], [123, 124], [125, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-126", "ner": [[0, 1, "task"], [4, 6, "algorithm"], [8, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 0, 1, "usage", "", true, false], [8, 9, 4, 6, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cluster", "analysis", ",", "and", "non-negative", "matrix", "factorisation", "for", "descriptive", "mining", "."], "sentence-detokenized": "Cluster analysis, and non-negative matrix factorisation for descriptive mining.", "token2charspan": [[0, 7], [8, 16], [16, 17], [18, 21], [22, 34], [35, 41], [42, 55], [56, 59], [60, 71], [72, 78], [78, 79]]}
{"doc_key": "ai-test-127", "ner": [[1, 2, "field"], [5, 6, "field"], [15, 17, "field"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 17, 1, 2, "part-of", "", false, false], [15, 17, 5, 6, "part-of", "", false, false], [21, 22, 1, 2, "part-of", "", false, false], [21, 22, 5, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", "and", "the", "information", "technology", "it", "enables", ",", "the", "ability", "of", "computers", "to", "process", "natural", "language", "and", "engage", "in", "machine", "learning", "has", "been", "a", "long", "-", "standing", "challenge", "."], "sentence-detokenized": "In computer science and the information technology it enables, the ability of computers to process natural language and engage in machine learning has been a long-standing challenge.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 23], [24, 27], [28, 39], [40, 50], [51, 53], [54, 61], [61, 62], [63, 66], [67, 74], [75, 77], [78, 87], [88, 90], [91, 98], [99, 106], [107, 115], [116, 119], [120, 126], [127, 129], [130, 137], [138, 146], [147, 150], [151, 155], [156, 157], [158, 162], [162, 163], [163, 171], [172, 181], [181, 182]]}
{"doc_key": "ai-test-128", "ner": [[3, 5, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 5, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "Code", "for", "Gabor", "feature", "extraction", "from", "images", "in", "MATLAB", "can", "be", "found", "at"], "sentence-detokenized": "(Code for Gabor feature extraction from images in MATLAB can be found at", "token2charspan": [[0, 1], [1, 5], [6, 9], [10, 15], [16, 23], [24, 34], [35, 39], [40, 46], [47, 49], [50, 56], [57, 60], [61, 63], [64, 69], [70, 72]]}
{"doc_key": "ai-test-129", "ner": [[1, 1, "misc"], [13, 16, "algorithm"], [20, 20, "task"], [22, 22, "task"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 1, 13, 16, "general-affiliation", "", false, false], [1, 1, 20, 20, "related-to", "solves_problem_of_type", false, false], [1, 1, 22, 22, "related-to", "solves_problem_of_type", false, false], [1, 1, 24, 25, "related-to", "solves_problem_of_type", false, false], [1, 1, 27, 28, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "NeuralExpert", "centres", "the", "design", "specifications", "around", "the", "type", "of", "problem", "the", "user", "wants", "the", "neural", "network", "to", "solve", "(", "Classification", ",", "Prediction", ",", "Function", "approach", "or", "Cluster", "analysis", ")", "."], "sentence-detokenized": "The NeuralExpert centres the design specifications around the type of problem the user wants the neural network to solve (Classification, Prediction, Function approach or Cluster analysis).", "token2charspan": [[0, 3], [4, 16], [17, 24], [25, 28], [29, 35], [36, 50], [51, 57], [58, 61], [62, 66], [67, 69], [70, 77], [78, 81], [82, 86], [87, 92], [93, 96], [97, 103], [104, 111], [112, 114], [115, 120], [121, 122], [122, 136], [136, 137], [138, 148], [148, 149], [150, 158], [159, 167], [168, 170], [171, 178], [179, 187], [187, 188], [188, 189]]}
{"doc_key": "ai-test-130", "ner": [[2, 4, "misc"], [28, 30, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "quantisation", "step", "size", "(", "\u0394", ")", "is", "small", "relative", "to", "the", "variation", "in", "the", "signal", "being", "quantised", ",", "it", "is", "relatively", "easy", "to", "show", "that", "the", "average", "squared", "error", "caused", "by", "such", "a", "rounding", "operation", "will", "be", "approximately", "maths", "Delta", "^", "2", "/", "12", "/", "math.math"], "sentence-detokenized": "When the quantisation step size (\u0394) is small relative to the variation in the signal being quantised, it is relatively easy to show that the average squared error caused by such a rounding operation will be approximately maths Delta ^ 2 / 12 / math.math", "token2charspan": [[0, 4], [5, 8], [9, 21], [22, 26], [27, 31], [32, 33], [33, 34], [34, 35], [36, 38], [39, 44], [45, 53], [54, 56], [57, 60], [61, 70], [71, 73], [74, 77], [78, 84], [85, 90], [91, 100], [100, 101], [102, 104], [105, 107], [108, 118], [119, 123], [124, 126], [127, 131], [132, 136], [137, 140], [141, 148], [149, 156], [157, 162], [163, 169], [170, 172], [173, 177], [178, 179], [180, 188], [189, 198], [199, 203], [204, 206], [207, 220], [221, 226], [227, 232], [233, 234], [235, 236], [237, 238], [239, 241], [242, 243], [244, 253]]}
{"doc_key": "ai-test-131", "ner": [[18, 18, "product"], [28, 31, "researcher"], [33, 34, "researcher"], [36, 38, "researcher"], [40, 41, "researcher"], [43, 45, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "construction", "of", "a", "rich", "lexicon", "with", "a", "suitable", "ontology", "requires", "considerable", "effort", ";", "for", "example", ",", "the", "Wordnet", "lexicon", "took", "many", "man", "-", "years", "of", "work", ".", "G.", "A", ".", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "The construction of a rich lexicon with a suitable ontology requires considerable effort; for example, the Wordnet lexicon took many man-years of work. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 3], [4, 16], [17, 19], [20, 21], [22, 26], [27, 34], [35, 39], [40, 41], [42, 50], [51, 59], [60, 68], [69, 81], [82, 88], [88, 89], [90, 93], [94, 101], [101, 102], [103, 106], [107, 114], [115, 122], [123, 127], [128, 132], [133, 136], [136, 137], [137, 142], [143, 145], [146, 150], [150, 151], [152, 154], [155, 156], [156, 157], [158, 164], [164, 165], [166, 168], [169, 177], [177, 178], [179, 181], [182, 184], [185, 193], [193, 194], [195, 197], [198, 203], [203, 204], [205, 206], [206, 207], [208, 214], [214, 215]]}
{"doc_key": "ai-test-132", "ner": [[0, 0, "organisation"], [15, 16, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kawasaki", "'s", "portfolio", "also", "includes", "retractable", "roofs", ",", "floors", "and", "other", "giant", "structures", ",", "the", "Sapporo", "Dome", "'", "retractable", "surface", "being", "one", "example", "."], "sentence-detokenized": "Kawasaki's portfolio also includes retractable roofs, floors and other giant structures, the Sapporo Dome' retractable surface being one example.", "token2charspan": [[0, 8], [8, 10], [11, 20], [21, 25], [26, 34], [35, 46], [47, 52], [52, 53], [54, 60], [61, 64], [65, 70], [71, 76], [77, 87], [87, 88], [89, 92], [93, 100], [101, 105], [105, 106], [107, 118], [119, 126], [127, 132], [133, 136], [137, 144], [144, 145]]}
{"doc_key": "ai-test-133", "ner": [[0, 1, "metrics"], [4, 6, "metrics"], [8, 10, "metrics"], [15, 16, "metrics"], [38, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 15, 16, "related-to", "", false, false], [0, 1, 38, 38, "opposite", "alternative_to", false, false], [4, 6, 0, 1, "type-of", "", false, false], [8, 10, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa", "statistics", "such", "as", "Fleiss", "'", "kappa", "and", "Cohen", "'s", "kappa", "are", "methods", "to", "calculate", "inter-rater", "reliability", "based", "on", "different", "assumptions", "about", "the", "marginal", "or", "prior", "distributions", ",", "and", "are", "increasingly", "used", "as", "probability", "-", "adjusted", "alternatives", "for", "accuracy", "in", "other", "contexts", "."], "sentence-detokenized": "Kappa statistics such as Fleiss' kappa and Cohen's kappa are methods to calculate inter-rater reliability based on different assumptions about the marginal or prior distributions, and are increasingly used as probability-adjusted alternatives for accuracy in other contexts.", "token2charspan": [[0, 5], [6, 16], [17, 21], [22, 24], [25, 31], [31, 32], [33, 38], [39, 42], [43, 48], [48, 50], [51, 56], [57, 60], [61, 68], [69, 71], [72, 81], [82, 93], [94, 105], [106, 111], [112, 114], [115, 124], [125, 136], [137, 142], [143, 146], [147, 155], [156, 158], [159, 164], [165, 178], [178, 179], [180, 183], [184, 187], [188, 200], [201, 205], [206, 208], [209, 220], [220, 221], [221, 229], [230, 242], [243, 246], [247, 255], [256, 258], [259, 264], [265, 273], [273, 274]]}
{"doc_key": "ai-test-134", "ner": [[3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 13, "researcher"], [17, 17, "researcher"], [26, 28, "algorithm"], [31, 35, "algorithm"], [37, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 4, 17, 17, "role", "student_of", false, false], [6, 7, 17, 17, "role", "student_of", false, false], [9, 10, 17, 17, "role", "student_of", false, false], [12, 13, 17, 17, "role", "student_of", false, false], [31, 35, 3, 4, "origin", "", false, false], [31, 35, 6, 7, "origin", "", false, false], [31, 35, 9, 10, "origin", "", false, false], [31, 35, 12, 13, "origin", "", false, false], [31, 35, 17, 17, "origin", "", false, false], [31, 35, 26, 28, "type-of", "", false, false], [37, 37, 31, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["With", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "and", "others", ",", "Schmidhuber", "published", "increasingly", "sophisticated", "versions", "of", "a", "type", "of", "recurrent", "neural", "network", "called", "the", "long", "-", "short", "term", "memory", "(", "LSTM", ")", "."], "sentence-detokenized": "With his students Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves and others, Schmidhuber published increasingly sophisticated versions of a type of recurrent neural network called the long-short term memory (LSTM).", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 22], [23, 33], [33, 34], [35, 40], [41, 45], [45, 46], [47, 51], [52, 59], [59, 60], [61, 65], [66, 72], [73, 76], [77, 83], [83, 84], [85, 96], [97, 106], [107, 119], [120, 133], [134, 142], [143, 145], [146, 147], [148, 152], [153, 155], [156, 165], [166, 172], [173, 180], [181, 187], [188, 191], [192, 196], [196, 197], [197, 202], [203, 207], [208, 214], [215, 216], [216, 220], [220, 221], [221, 222]]}
{"doc_key": "ai-test-135", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "The", "first", "Cobot", "KUKA", "LBR", "3", "is", "released", "."], "sentence-detokenized": "2004 - The first Cobot KUKA LBR 3 is released.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 22], [23, 27], [28, 31], [32, 33], [34, 36], [37, 45], [45, 46]]}
{"doc_key": "ai-test-136", "ner": [[10, 12, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "shallow", "approaches", "used", "to", "train", "and", "then", "disambiguate", "are", "Naive", "Bayes", "classifier", "and", "decision", "trees", "."], "sentence-detokenized": "Two shallow approaches used to train and then disambiguate are Naive Bayes classifier and decision trees.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 27], [28, 30], [31, 36], [37, 40], [41, 45], [46, 58], [59, 62], [63, 68], [69, 74], [75, 85], [86, 89], [90, 98], [99, 104], [104, 105]]}
{"doc_key": "ai-test-137", "ner": [[5, 5, "misc"], [12, 13, "person"], [15, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 12, 13, "origin", "", false, false], [5, 5, 15, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "practical", "forms", "of", "photography", "were", "introduced", "in", "January", "1839", "by", "Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "The first practical forms of photography were introduced in January 1839 by Louis Daguerre and Henry Fox Talbot.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 25], [26, 28], [29, 40], [41, 45], [46, 56], [57, 59], [60, 67], [68, 72], [73, 75], [76, 81], [82, 90], [91, 94], [95, 100], [101, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-138", "ner": [[3, 4, "task"], [8, 9, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "speech", "synthesis", ",", "combined", "with", "speech", "recognition", ",", "enables", "interaction", "with", "mobile", "devices", "via", "language", "processing", "interfaces", "."], "sentence-detokenized": "For example, speech synthesis, combined with speech recognition, enables interaction with mobile devices via language processing interfaces.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [29, 30], [31, 39], [40, 44], [45, 51], [52, 63], [63, 64], [65, 72], [73, 84], [85, 89], [90, 96], [97, 104], [105, 108], [109, 117], [118, 128], [129, 139], [139, 140]]}
{"doc_key": "ai-test-139", "ner": [[0, 0, "product"], [15, 15, "programlang"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 15, 15, "general-affiliation", "", false, false], [0, 0, 17, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Phidgets", "can", "be", "programmed", "with", "a", "variety", "of", "software", "and", "programming", "languages", ",", "ranging", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "Phidgets can be programmed with a variety of software and programming languages, ranging from Java to Microsoft Excel.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 26], [27, 31], [32, 33], [34, 41], [42, 44], [45, 53], [54, 57], [58, 69], [70, 79], [79, 80], [81, 88], [89, 93], [94, 98], [99, 101], [102, 111], [112, 117], [117, 118]]}
{"doc_key": "ai-test-140", "ner": [[2, 3, "field"], [9, 10, "researcher"], [13, 14, "misc"], [18, 19, "field"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 10, "origin", "", false, false], [9, 10, 18, 19, "general-affiliation", "topic_of_study", false, false], [9, 10, 21, 22, "general-affiliation", "topic_of_study", false, false], [13, 14, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "machine", "learning", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "an", "American", "IBMer", "and", "pioneer", "of", "computer", "games", "and", "artificial", "intelligence", "."], "sentence-detokenized": "The term machine learning was coined in 1959 by Arthur Samuel, an American IBMer and pioneer of computer games and artificial intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 25], [26, 29], [30, 36], [37, 39], [40, 44], [45, 47], [48, 54], [55, 61], [61, 62], [63, 65], [66, 74], [75, 80], [81, 84], [85, 92], [93, 95], [96, 104], [105, 110], [111, 114], [115, 125], [126, 138], [138, 139]]}
{"doc_key": "ai-test-141", "ner": [[0, 1, "misc"], [2, 3, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Israeli", "poet", "David", "Avidan", ",", "fascinated", "by", "future", "technologies", "and", "their", "relationship", "to", "art", ",", "wanted", "to", "explore", "the", "use", "of", "computers", "for", "writing", "literature", "."], "sentence-detokenized": "Israeli poet David Avidan, fascinated by future technologies and their relationship to art, wanted to explore the use of computers for writing literature.", "token2charspan": [[0, 7], [8, 12], [13, 18], [19, 25], [25, 26], [27, 37], [38, 40], [41, 47], [48, 60], [61, 64], [65, 70], [71, 83], [84, 86], [87, 90], [90, 91], [92, 98], [99, 101], [102, 109], [110, 113], [114, 117], [118, 120], [121, 130], [131, 134], [135, 142], [143, 153], [153, 154]]}
{"doc_key": "ai-test-142", "ner": [[4, 5, "misc"], [9, 9, "organisation"], [19, 19, "location"], [33, 33, "location"], [35, 37, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 4, 5, "part-of", "", false, false], [35, 37, 33, 33, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "part", "of", "the", "GATEway", "Project", "in", "2017", ",", "Oxbotica", "conducted", "a", "trial", "of", "seven", "autonomous", "shuttle", "buses", "in", "Greenwich", ".", "They", "navigated", "along", "a", "two", "-", "mile", "path", "along", "the", "river", "near", "London", "'s", "The", "O2", "Arena", ",", "on", "a", "route", "also", "used", "by", "pedestrians", "and", "cyclists", "."], "sentence-detokenized": "As part of the GATEway Project in 2017, Oxbotica conducted a trial of seven autonomous shuttle buses in Greenwich. They navigated along a two-mile path along the river near London's The O2 Arena, on a route also used by pedestrians and cyclists.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 30], [31, 33], [34, 38], [38, 39], [40, 48], [49, 58], [59, 60], [61, 66], [67, 69], [70, 75], [76, 86], [87, 94], [95, 100], [101, 103], [104, 113], [113, 114], [115, 119], [120, 129], [130, 135], [136, 137], [138, 141], [141, 142], [142, 146], [147, 151], [152, 157], [158, 161], [162, 167], [168, 172], [173, 179], [179, 181], [182, 185], [186, 188], [189, 194], [194, 195], [196, 198], [199, 200], [201, 206], [207, 211], [212, 216], [217, 219], [220, 231], [232, 235], [236, 244], [244, 245]]}
{"doc_key": "ai-test-143", "ner": [[10, 11, "task"], [14, 16, "metrics"], [25, 26, "misc"], [28, 28, "metrics"], [30, 30, "metrics"], [33, 33, "metrics"], [35, 35, "metrics"], [37, 39, "metrics"], [42, 42, "metrics"], [44, 44, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[14, 16, 25, 26, "related-to", "is_a", false, false], [14, 16, 28, 28, "usage", "", false, false], [14, 16, 30, 30, "usage", "", false, false], [28, 28, 33, 33, "named", "same", false, false], [30, 30, 44, 44, "named", "same", false, false], [33, 33, 42, 42, "opposite", "", false, false], [33, 33, 44, 44, "opposite", "", false, false], [35, 35, 33, 33, "named", "", false, false], [37, 39, 33, 33, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["An", "unrelated", "but", "often", "used", "combination", "of", "basic", "statistics", "from", "information", "retrieval", "is", "the", "F", "-", "score", ",", "which", "is", "a", "(", "possibly", "weighted", ")", "harmonic", "average", "of", "recall", "and", "precision", ",", "where", "recall", "=", "sensitivity", "=", "true", "positive", "rate", ",", "but", "specificity", "and", "precision", "are", "totally", "different", "measures", "."], "sentence-detokenized": "An unrelated but often used combination of basic statistics from information retrieval is the F-score, which is a (possibly weighted) harmonic average of recall and precision, where recall = sensitivity = true positive rate, but specificity and precision are totally different measures.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 22], [23, 27], [28, 39], [40, 42], [43, 48], [49, 59], [60, 64], [65, 76], [77, 86], [87, 89], [90, 93], [94, 95], [95, 96], [96, 101], [101, 102], [103, 108], [109, 111], [112, 113], [114, 115], [115, 123], [124, 132], [132, 133], [134, 142], [143, 150], [151, 153], [154, 160], [161, 164], [165, 174], [174, 175], [176, 181], [182, 188], [189, 190], [191, 202], [203, 204], [205, 209], [210, 218], [219, 223], [223, 224], [225, 228], [229, 240], [241, 244], [245, 254], [255, 258], [259, 266], [267, 276], [277, 285], [285, 286]]}
{"doc_key": "ai-test-144", "ner": [[0, 1, "field"], [10, 10, "field"], [12, 12, "field"], [14, 14, "field"], [16, 17, "field"], [19, 20, "field"], [29, 30, "product"], [32, 35, "product"], [37, 38, "product"], [40, 41, "product"], [54, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 10, "origin", "takes_inspiration_from", false, false], [0, 1, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 1, 14, 14, "origin", "takes_inspiration_from", false, false], [0, 1, 16, 17, "origin", "takes_inspiration_from", false, false], [0, 1, 19, 20, "origin", "takes_inspiration_from", false, false], [29, 30, 0, 1, "origin", "", false, false], [32, 35, 0, 1, "origin", "", false, false], [37, 38, 0, 1, "origin", "", false, false], [40, 41, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "is", "an", "interdisciplinary", "field", "that", "draws", "inspiration", "from", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", "and", "electrical", "engineering", "to", "design", "artificial", "neural", "systems", ",", "such", "as", "vision", "systems", ",", "head", "-", "eye", "systems", ",", "auditory", "processors", "and", "autonomous", "robots", ",", "whose", "physical", "architecture", "and", "design", "principles", "are", "based", "on", "those", "of", "biological", "nervous", "systems", "."], "sentence-detokenized": "Neuromorphic engineering is an interdisciplinary field that draws inspiration from biology, physics, mathematics, computer science and electrical engineering to design artificial neural systems, such as vision systems, head-eye systems, auditory processors and autonomous robots, whose physical architecture and design principles are based on those of biological nervous systems.", "token2charspan": [[0, 12], [13, 24], [25, 27], [28, 30], [31, 48], [49, 54], [55, 59], [60, 65], [66, 77], [78, 82], [83, 90], [90, 91], [92, 99], [99, 100], [101, 112], [112, 113], [114, 122], [123, 130], [131, 134], [135, 145], [146, 157], [158, 160], [161, 167], [168, 178], [179, 185], [186, 193], [193, 194], [195, 199], [200, 202], [203, 209], [210, 217], [217, 218], [219, 223], [223, 224], [224, 227], [228, 235], [235, 236], [237, 245], [246, 256], [257, 260], [261, 271], [272, 278], [278, 279], [280, 285], [286, 294], [295, 307], [308, 311], [312, 318], [319, 329], [330, 333], [334, 339], [340, 342], [343, 348], [349, 351], [352, 362], [363, 370], [371, 378], [378, 379]]}
{"doc_key": "ai-test-145", "ner": [[5, 7, "metrics"], [11, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 11, 5, 7, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "be", "precise", ",", "the", "BIBO", "stability", "criterion", "requires", "that", "the", "ROC", "of", "the", "system", "includes", "the", "unit", "circle", "."], "sentence-detokenized": "To be precise, the BIBO stability criterion requires that the ROC of the system includes the unit circle.", "token2charspan": [[0, 2], [3, 5], [6, 13], [13, 14], [15, 18], [19, 23], [24, 33], [34, 43], [44, 52], [53, 57], [58, 61], [62, 65], [66, 68], [69, 72], [73, 79], [80, 88], [89, 92], [93, 97], [98, 104], [104, 105]]}
{"doc_key": "ai-test-146", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "The", "programme", "was", "rewritten", "in", "Java", "from", "1998", "."], "sentence-detokenized": "2 The programme was rewritten in Java from 1998.", "token2charspan": [[0, 1], [2, 5], [6, 15], [16, 19], [20, 29], [30, 32], [33, 37], [38, 42], [43, 47], [47, 48]]}
{"doc_key": "ai-test-147", "ner": [[1, 1, "metrics"], [8, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 8, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "MCC", "can", "be", "calculated", "directly", "from", "the", "confusion", "matrix", "using", "the", "formula", ":"], "sentence-detokenized": "The MCC can be calculated directly from the confusion matrix using the formula:", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 25], [26, 34], [35, 39], [40, 43], [44, 53], [54, 60], [61, 66], [67, 70], [71, 78], [78, 79]]}
{"doc_key": "ai-test-148", "ner": [[8, 13, "organisation"], [22, 27, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 13, 22, 27, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "developed", "by", "a", "team", "from", "the", "MIT", "-", "IBM", "Watson", "AI", "Lab", "and", "presented", "for", "the", "first", "time", "at", "the", "2018", "International", "Conference", "on", "Learning", "Representations", "."], "sentence-detokenized": "It was developed by a team from the MIT-IBM Watson AI Lab and presented for the first time at the 2018 International Conference on Learning Representations.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 31], [32, 35], [36, 39], [39, 40], [40, 43], [44, 50], [51, 53], [54, 57], [58, 61], [62, 71], [72, 75], [76, 79], [80, 85], [86, 90], [91, 93], [94, 97], [98, 102], [103, 116], [117, 127], [128, 130], [131, 139], [140, 155], [155, 156]]}
{"doc_key": "ai-test-149", "ner": [[2, 3, "metrics"], [14, 15, "metrics"], [17, 19, "metrics"], [45, 45, "metrics"], [47, 47, "metrics"], [53, 55, "metrics"], [58, 58, "metrics"], [60, 60, "metrics"], [62, 64, "metrics"], [69, 69, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[14, 15, 45, 45, "type-of", "", false, false], [14, 15, 53, 55, "related-to", "collapses_to_identity", false, false], [17, 19, 47, 47, "type-of", "", false, false], [17, 19, 53, 55, "related-to", "collapses_to_identity", false, false], [17, 19, 62, 64, "named", "same", false, false], [58, 58, 69, 69, "related-to", "collapses_to_identity", false, false], [60, 60, 69, 69, "related-to", "collapses_to_identity", false, false], [62, 64, 69, 69, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["When", "the", "TRUE", "prevalences", "for", "the", "two", "positive", "variables", "are", "equal", "as", "assumed", "in", "Fleiss", "kappa", "and", "F", "-", "score", ",", "i.e.", "the", "number", "of", "positive", "predictions", "corresponds", "to", "the", "number", "of", "positive", "classes", "in", "the", "dichotomous", "(", "two", "classes", ")", "case", ",", "the", "different", "kappa", "and", "correlation", "measures", "coincide", "to", "identity", "with", "Youden", "'s", "J", ",", "and", "recall", ",", "precision", "and", "F", "-", "score", "are", "similarly", "identical", "with", "accuracy", "."], "sentence-detokenized": "When the TRUE prevalences for the two positive variables are equal as assumed in Fleiss kappa and F-score, i.e. the number of positive predictions corresponds to the number of positive classes in the dichotomous (two classes) case, the different kappa and correlation measures coincide to identity with Youden's J, and recall, precision and F-score are similarly identical with accuracy.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 25], [26, 29], [30, 33], [34, 37], [38, 46], [47, 56], [57, 60], [61, 66], [67, 69], [70, 77], [78, 80], [81, 87], [88, 93], [94, 97], [98, 99], [99, 100], [100, 105], [105, 106], [107, 111], [112, 115], [116, 122], [123, 125], [126, 134], [135, 146], [147, 158], [159, 161], [162, 165], [166, 172], [173, 175], [176, 184], [185, 192], [193, 195], [196, 199], [200, 211], [212, 213], [213, 216], [217, 224], [224, 225], [226, 230], [230, 231], [232, 235], [236, 245], [246, 251], [252, 255], [256, 267], [268, 276], [277, 285], [286, 288], [289, 297], [298, 302], [303, 309], [309, 311], [312, 313], [313, 314], [315, 318], [319, 325], [325, 326], [327, 336], [337, 340], [341, 342], [342, 343], [343, 348], [349, 352], [353, 362], [363, 372], [373, 377], [378, 386], [386, 387]]}
{"doc_key": "ai-test-150", "ner": [[1, 4, "misc"], [6, 6, "misc"], [9, 9, "conference"], [14, 17, "task"], [18, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 4, 9, 9, "part-of", "", false, false], [1, 4, 9, 9, "physical", "", false, false], [1, 4, 9, 9, "temporal", "", false, false], [6, 6, 1, 4, "named", "", false, false], [14, 17, 1, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Building", "Educational", "Applications", "workshop", "(", "BEA", ")", "at", "NAACL", "2013", "hosted", "the", "inaugural", "NLI", "shared", "task", ".", "Tetreault", "et", "al", ",", "2013", "The", "competition", "resulted", "in", "29", "submissions", "from", "teams", "around", "the", "world", ",", "24", "of", "which", "also", "published", "a", "paper", "describing", "their", "systems", "and", "approaches", "."], "sentence-detokenized": "The Building Educational Applications workshop (BEA) at NAACL 2013 hosted the inaugural NLI shared task. Tetreault et al, 2013 The competition resulted in 29 submissions from teams around the world, 24 of which also published a paper describing their systems and approaches.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 37], [38, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 61], [62, 66], [67, 73], [74, 77], [78, 87], [88, 91], [92, 98], [99, 103], [103, 104], [105, 114], [115, 117], [118, 120], [120, 121], [122, 126], [127, 130], [131, 142], [143, 151], [152, 154], [155, 157], [158, 169], [170, 174], [175, 180], [181, 187], [188, 191], [192, 197], [197, 198], [199, 201], [202, 204], [205, 210], [211, 215], [216, 225], [226, 227], [228, 233], [234, 244], [245, 250], [251, 258], [259, 262], [263, 273], [273, 274]]}
{"doc_key": "ai-test-151", "ner": [[1, 2, "algorithm"], [5, 7, "algorithm"], [15, 16, "misc"], [20, 21, "misc"], [37, 37, "misc"], [41, 42, "algorithm"], [45, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 2, 5, 7, "type-of", "", false, false], [1, 2, 15, 16, "related-to", "finds", false, false], [20, 21, 15, 16, "type-of", "", false, false], [45, 45, 41, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Viterbi", "algorithm", "is", "a", "dynamic", "programming", "algorithm", "for", "finding", "the", "most", "likely", "sequence", "of", "hidden", "states", ",", "called", "the", "Viterbi", "path", ",", "that", "results", "in", "a", "sequence", "of", "observed", "events", ",", "especially", "in", "the", "context", "of", "Markov", "information", "sources", "and", "hidden", "Markov", "models", "(", "HMM", ")", "."], "sentence-detokenized": "The Viterbi algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states, called the Viterbi path, that results in a sequence of observed events, especially in the context of Markov information sources and hidden Markov models (HMM).", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 24], [25, 26], [27, 34], [35, 46], [47, 56], [57, 60], [61, 68], [69, 72], [73, 77], [78, 84], [85, 93], [94, 96], [97, 103], [104, 110], [110, 111], [112, 118], [119, 122], [123, 130], [131, 135], [135, 136], [137, 141], [142, 149], [150, 152], [153, 154], [155, 163], [164, 166], [167, 175], [176, 182], [182, 183], [184, 194], [195, 197], [198, 201], [202, 209], [210, 212], [213, 219], [220, 231], [232, 239], [240, 243], [244, 250], [251, 257], [258, 264], [265, 266], [266, 269], [269, 270], [270, 271]]}
{"doc_key": "ai-test-152", "ner": [[1, 1, "field"], [3, 5, "algorithm"], [8, 9, "misc"], [12, 13, "algorithm"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 1, 1, "part-of", "", false, false], [3, 5, 8, 9, "general-affiliation", "", false, false], [3, 5, 12, 13, "related-to", "generalizes_from", false, false], [3, 5, 15, 16, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "multinomial", "logistic", "regression", "is", "a", "classification", "method", "that", "generalises", "logistic", "regression", "to", "multiclass", "classification", ",", "i.e.", "with", "more", "than", "two", "possible", "discrete", "outcomes", "."], "sentence-detokenized": "In statistics, multinomial logistic regression is a classification method that generalises logistic regression to multiclass classification, i.e. with more than two possible discrete outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 26], [27, 35], [36, 46], [47, 49], [50, 51], [52, 66], [67, 73], [74, 78], [79, 90], [91, 99], [100, 110], [111, 113], [114, 124], [125, 139], [139, 140], [141, 145], [146, 150], [151, 155], [156, 160], [161, 164], [165, 173], [174, 182], [183, 191], [191, 192]]}
{"doc_key": "ai-test-153", "ner": [[0, 2, "algorithm"], [10, 11, "field"], [13, 15, "field"], [18, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 10, 11, "part-of", "", false, false], [0, 2, 13, 15, "part-of", "", false, false], [18, 18, 0, 2, "usage", "", true, false], [20, 21, 0, 2, "usage", "", true, false], [23, 24, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden", "Markov", "models", "are", "well", "known", "for", "their", "applications", "in", "reinforcement", "learning", "and", "temporal", "pattern", "recognition", "such", "as", "speech", ",", "handwriting", "recognition", ",", "gesture", "recognition", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov models are well known for their applications in reinforcement learning and temporal pattern recognition such as speech, handwriting recognition, gesture recognition, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 29], [30, 35], [36, 39], [40, 45], [46, 58], [59, 61], [62, 75], [76, 84], [85, 88], [89, 97], [98, 105], [106, 117], [118, 122], [123, 125], [126, 132], [132, 133], [134, 145], [146, 157], [157, 158], [159, 166], [167, 178], [178, 179], [180, 184], [185, 192], [192, 193], [194, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-154", "ner": [[7, 8, "misc"], [33, 35, "metrics"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 38, 39, "named", "", false, false], [33, 35, 38, 39, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "essence", ",", "this", "means", "that", "if", "the", "n-gram", "has", "been", "seen", "more", "than", "k", "times", "in", "training", ",", "the", "conditional", "probability", "of", "a", "word", "given", "it", "s", "history", "is", "proportional", "to", "the", "maximum", "likelihood", "estimate", "of", "thatn", "-", "gram", "."], "sentence-detokenized": "In essence, this means that if the n-gram has been seen more than k times in training, the conditional probability of a word given its history is proportional to the maximum likelihood estimate of thatn -gram.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [17, 22], [23, 27], [28, 30], [31, 34], [35, 41], [42, 45], [46, 50], [51, 55], [56, 60], [61, 65], [66, 67], [68, 73], [74, 76], [77, 85], [85, 86], [87, 90], [91, 102], [103, 114], [115, 117], [118, 119], [120, 124], [125, 130], [131, 133], [133, 134], [135, 142], [143, 145], [146, 158], [159, 161], [162, 165], [166, 173], [174, 184], [185, 193], [194, 196], [197, 202], [203, 204], [204, 208], [208, 209]]}
{"doc_key": "ai-test-155", "ner": [[4, 5, "task"], [7, 9, "task"], [12, 14, "task"], [18, 20, "task"], [28, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[28, 30, 18, 20, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "knowledge", "representation", ",", "common", "sense", "reasoning", ",", "and", "natural", "language", "comprehension", ",", "believing", "that", "deep", "language", "comprehension", "can", "currently", "only", "be", "achieved", "through", "significant", "hand", "-", "engineering", "of", "semantically", "-", "rich", "formalisms", "combined", "with", "statistical", "preferences", "."], "sentence-detokenized": "He is interested in knowledge representation, common sense reasoning, and natural language comprehension, believing that deep language comprehension can currently only be achieved through significant hand-engineering of semantically-rich formalisms combined with statistical preferences.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 29], [30, 44], [44, 45], [46, 52], [53, 58], [59, 68], [68, 69], [70, 73], [74, 81], [82, 90], [91, 104], [104, 105], [106, 115], [116, 120], [121, 125], [126, 134], [135, 148], [149, 152], [153, 162], [163, 167], [168, 170], [171, 179], [180, 187], [188, 199], [200, 204], [204, 205], [205, 216], [217, 219], [220, 232], [232, 233], [233, 237], [238, 248], [249, 257], [258, 262], [263, 274], [275, 286], [286, 287]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "JavaScript", ",", "Python", "or"], "sentence-detokenized": "In JavaScript, Python or", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 24]]}
{"doc_key": "ai-test-157", "ner": [[1, 2, "misc"], [7, 9, "misc"], [11, 12, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 7, 9, "part-of", "", false, false], [7, 9, 11, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "Awards", "are", "announced", "in", "the", "AI", "Magazine", "published", "by", "the", "AAAI", "."], "sentence-detokenized": "The Newcomb Awards are announced in the AI Magazine published by the AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 32], [33, 35], [36, 39], [40, 42], [43, 51], [52, 61], [62, 64], [65, 68], [69, 73], [73, 74]]}
{"doc_key": "ai-test-158", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "squared", "error", "on", "a", "test", "set", "of", "100", "examples", "is", "0.084", ",", "which", "is", "smaller", "than", "the", "non-normalised", "error", "."], "sentence-detokenized": "The mean squared error on a test set of 100 examples is 0.084, which is smaller than the non-normalised error.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 25], [26, 27], [28, 32], [33, 36], [37, 39], [40, 43], [44, 52], [53, 55], [56, 61], [61, 62], [63, 68], [69, 71], [72, 79], [80, 84], [85, 88], [89, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-test-159", "ner": [[1, 3, "metrics"], [9, 11, "field"], [18, 20, "task"], [22, 22, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 11, 1, 3, "usage", "", false, false], [18, 20, 9, 11, "part-of", "task_part_of_field", false, false], [22, 22, 18, 20, "named", "", false, false], [25, 26, 9, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "F", "-", "score", "is", "widely", "used", "in", "the", "natural", "language", "processing", "literature", ",", "such", "as", "for", "evaluating", "named", "entity", "recognition", "(", "NER", ")", "and", "word", "segmentation", "."], "sentence-detokenized": "The F-score is widely used in the natural language processing literature, such as for evaluating named entity recognition (NER) and word segmentation.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 21], [22, 26], [27, 29], [30, 33], [34, 41], [42, 50], [51, 61], [62, 72], [72, 73], [74, 78], [79, 81], [82, 85], [86, 96], [97, 102], [103, 109], [110, 121], [122, 123], [123, 126], [126, 127], [128, 131], [132, 136], [137, 149], [149, 150]]}
{"doc_key": "ai-test-160", "ner": [[0, 0, "product"], [5, 6, "product"], [16, 17, "misc"], [19, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 16, 17, "related-to", "performs_task", false, false], [0, 0, 19, 20, "related-to", "performs_task", false, false], [5, 6, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "usually", "used", "in", "dialogue", "systems", "for", "various", "purposes", ",", "such", "as", "customer", "service", ",", "routing", "requests", "or", "gathering", "information", "."], "sentence-detokenized": "Chatbots are usually used in dialogue systems for various purposes, such as customer service, routing requests or gathering information.", "token2charspan": [[0, 8], [9, 12], [13, 20], [21, 25], [26, 28], [29, 37], [38, 45], [46, 49], [50, 57], [58, 66], [66, 67], [68, 72], [73, 75], [76, 84], [85, 92], [92, 93], [94, 101], [102, 110], [111, 113], [114, 123], [124, 135], [135, 136]]}
{"doc_key": "ai-test-161", "ner": [[4, 10, "conference"], [14, 22, "conference"], [28, 38, "conference"], [48, 51, "conference"], [54, 55, "conference"]], "ner_mapping_to_source": [0, 1, 2, 4, 5], "relations": [[14, 22, 4, 10, "named", "", false, false], [28, 38, 4, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Key", "journals", "include", "the", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "later", "renamed", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "and", "since", "Sept", "2014", "renamed", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "after", "merging", "with", "an", "ACM", "publication", ")", ",", "Computer", "Speech", "and", "Language", ",", "and", "Speech", "Communication", "."], "sentence-detokenized": "Key journals include the IEEE Transactions on Speech and Audio Processing (later renamed IEEE Transactions on Audio, Speech and Language Processing and since Sept 2014 renamed IEEE / ACM Transactions on Audio, Speech and Language Processing - after merging with an ACM publication), Computer Speech and Language, and Speech Communication.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 24], [25, 29], [30, 42], [43, 45], [46, 52], [53, 56], [57, 62], [63, 73], [74, 75], [75, 80], [81, 88], [89, 93], [94, 106], [107, 109], [110, 115], [115, 116], [117, 123], [124, 127], [128, 136], [137, 147], [148, 151], [152, 157], [158, 162], [163, 167], [168, 175], [176, 180], [181, 182], [183, 186], [187, 199], [200, 202], [203, 208], [208, 209], [210, 216], [217, 220], [221, 229], [230, 240], [241, 242], [243, 248], [249, 256], [257, 261], [262, 264], [265, 268], [269, 280], [280, 281], [281, 282], [283, 291], [292, 298], [299, 302], [303, 311], [311, 312], [313, 316], [317, 323], [324, 337], [337, 338]]}
{"doc_key": "ai-test-162", "ner": [[0, 0, "algorithm"], [5, 6, "task"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 0, 0, "usage", "", false, false], [5, 6, 8, 9, "part-of", "task_part_of_field", false, false], [5, 6, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "is", "often", "used", "for", "clustering", "data", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "EM is often used for clustering data in machine learning and computer vision.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 20], [21, 31], [32, 36], [37, 39], [40, 47], [48, 56], [57, 60], [61, 69], [70, 76], [76, 77]]}
{"doc_key": "ai-test-163", "ner": [[9, 10, "metrics"], [24, 26, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 24, 26, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["Although", "there", "is", "no", "perfect", "way", "to", "describe", "the", "confusion", "matrix", "of", "TRUE", "and", "ONWARE", "positives", "and", "negatives", "with", "a", "single", "number", ",", "the", "Matthews", "correlation", "coefficient", "is", "widely", "regarded", "as", "one", "of", "the", "best", "measures", "."], "sentence-detokenized": "Although there is no perfect way to describe the confusion matrix of TRUE and ONWARE positives and negatives with a single number, the Matthews correlation coefficient is widely regarded as one of the best measures.", "token2charspan": [[0, 8], [9, 14], [15, 17], [18, 20], [21, 28], [29, 32], [33, 35], [36, 44], [45, 48], [49, 58], [59, 65], [66, 68], [69, 73], [74, 77], [78, 84], [85, 94], [95, 98], [99, 108], [109, 113], [114, 115], [116, 122], [123, 129], [129, 130], [131, 134], [135, 143], [144, 155], [156, 167], [168, 170], [171, 177], [178, 186], [187, 189], [190, 193], [194, 196], [197, 200], [201, 205], [206, 214], [214, 215]]}
{"doc_key": "ai-test-164", "ner": [[15, 16, "field"], [31, 32, "field"], [36, 37, "field"], [41, 42, "algorithm"], [44, 45, "task"], [47, 48, "algorithm"], [53, 55, "algorithm"], [57, 58, "algorithm"], [64, 66, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[36, 37, 31, 32, "part-of", "subfield", false, false], [41, 42, 36, 37, "part-of", "", false, true], [44, 45, 36, 37, "part-of", "", false, true], [47, 48, 36, 37, "part-of", "", false, true], [53, 55, 36, 37, "part-of", "", false, true], [57, 58, 36, 37, "part-of", "", false, true], [64, 66, 36, 37, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "the", "size", "and", "complexity", "of", "data", "collections", "increased", ",", "direct", ",", "hands", "-", "on", "data", "analysis", "was", "complemented", "by", "indirect", ",", "automated", "data", "processing", ",", "helped", "by", "other", "discoveries", "in", "computer", "science", ",", "especially", "in", "machine", "learning", ",", "such", "as", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "decision", "tree", "learning", "and", "decision", "rules", "(", "1960s", ")", ",", "and", "support", "vector", "machines", "(", "1990", "s", ")", "."], "sentence-detokenized": "As the size and complexity of data collections increased, direct, hands-on data analysis was complemented by indirect, automated data processing, helped by other discoveries in computer science, especially in machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision tree learning and decision rules (1960s), and support vector machines (1990s).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 15], [16, 26], [27, 29], [30, 34], [35, 46], [47, 56], [56, 57], [58, 64], [64, 65], [66, 71], [71, 72], [72, 74], [75, 79], [80, 88], [89, 92], [93, 105], [106, 108], [109, 117], [117, 118], [119, 128], [129, 133], [134, 144], [144, 145], [146, 152], [153, 155], [156, 161], [162, 173], [174, 176], [177, 185], [186, 193], [193, 194], [195, 205], [206, 208], [209, 216], [217, 225], [225, 226], [227, 231], [232, 234], [235, 241], [242, 250], [250, 251], [252, 259], [260, 268], [268, 269], [270, 277], [278, 288], [289, 290], [290, 295], [295, 296], [296, 297], [298, 306], [307, 311], [312, 320], [321, 324], [325, 333], [334, 339], [340, 341], [341, 346], [346, 347], [347, 348], [349, 352], [353, 360], [361, 367], [368, 376], [377, 378], [378, 382], [382, 383], [383, 384], [384, 385]]}
{"doc_key": "ai-test-165", "ner": [[4, 4, "researcher"], [23, 24, "misc"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 24, 4, 4, "artifact", "", false, false], [23, 24, 13, 14, "artifact", "", false, false], [23, 24, 16, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "autumn", "2005", ",", "Thrun", ",", "together", "with", "his", "long", "-", "time", "collaborators", "Dieter", "Fox", "and", "Wolfram", "Burgard", ",", "published", "a", "textbook", "entitled", "Probabilistic", "Robotics", "."], "sentence-detokenized": "In autumn 2005, Thrun, together with his long-time collaborators Dieter Fox and Wolfram Burgard, published a textbook entitled Probabilistic Robotics.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 21], [21, 22], [23, 31], [32, 36], [37, 40], [41, 45], [45, 46], [46, 50], [51, 64], [65, 71], [72, 75], [76, 79], [80, 87], [88, 95], [95, 96], [97, 106], [107, 108], [109, 117], [118, 126], [127, 140], [141, 149], [149, 150]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereiramath", "as", "follows", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereiramath as follows:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 49], [50, 52], [53, 60], [60, 61]]}
{"doc_key": "ai-test-167", "ner": [[0, 1, "task"], [3, 3, "task"], [9, 13, "field"], [15, 16, "field"], [18, 24, "field"], [26, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 15, 16, "part-of", "task_part_of_field", false, false], [0, 1, 18, 24, "part-of", "task_part_of_field", false, false], [3, 3, 0, 1, "named", "", false, false], [15, 16, 9, 13, "part-of", "subfield", false, false], [18, 24, 9, 13, "part-of", "subfield", false, false], [26, 26, 18, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Question", "Answering", "(", "QA", ")", "is", "a", "discipline", "within", "computer", "science", "in", "the", "field", "of", "information", "retrieval", "and", "natural", "language", "processing", "(", "Natural", "Language", "Processing", "-", "NLP", ")", ",", "concerned", "with", "building", "systems", "that", "automatically", "answer", "questions", "posed", "by", "humans", "in", "a", "natural", "language", "."], "sentence-detokenized": "Question Answering (QA) is a discipline within computer science in the field of information retrieval and natural language processing (Natural Language Processing - NLP), concerned with building systems that automatically answer questions posed by humans in a natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 39], [40, 46], [47, 55], [56, 63], [64, 66], [67, 70], [71, 76], [77, 79], [80, 91], [92, 101], [102, 105], [106, 113], [114, 122], [123, 133], [134, 135], [135, 142], [143, 151], [152, 162], [163, 164], [165, 168], [168, 169], [169, 170], [171, 180], [181, 185], [186, 194], [195, 202], [203, 207], [208, 221], [222, 228], [229, 238], [239, 244], [245, 247], [248, 254], [255, 257], [258, 259], [260, 267], [268, 276], [276, 277]]}
{"doc_key": "ai-test-168", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "the", "version", "of", "metrics", "used", "by", "NIST", "evaluations", "before", "2009", "used", "the", "shortest", "reference", "sentence", "."], "sentence-detokenized": "However, the version of metrics used by NIST evaluations before 2009 used the shortest reference sentence.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 20], [21, 23], [24, 31], [32, 36], [37, 39], [40, 44], [45, 56], [57, 63], [64, 68], [69, 73], [74, 77], [78, 86], [87, 96], [97, 105], [105, 106]]}
{"doc_key": "ai-test-169", "ner": [[5, 5, "person"], [13, 13, "organisation"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 15, 16, "related-to", "invests_in", false, false], [15, 16, 13, 13, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["On", "27", "August", "2018", ",", "Toyota", "announced", "a", "$", "500", "million", "investment", "in", "Uber", "'s", "autonomous", "cars", "."], "sentence-detokenized": "On 27 August 2018, Toyota announced a $500 million investment in Uber's autonomous cars.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 17], [17, 18], [19, 25], [26, 35], [36, 37], [38, 39], [39, 42], [43, 50], [51, 61], [62, 64], [65, 69], [69, 71], [72, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-test-170", "ner": [[5, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sample", "maximum", "is", "the", "maximum", "-likelihood", "estimator", "for", "the", "population", "maximum", ",", "but", "as", "discussed", "above", ",", "it", "is", "biased", "."], "sentence-detokenized": "The sample maximum is the maximum-likelihood estimator for the population maximum, but as discussed above, it is biased.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 25], [26, 33], [33, 44], [45, 54], [55, 58], [59, 62], [63, 73], [74, 81], [81, 82], [83, 86], [87, 89], [90, 99], [100, 105], [105, 106], [107, 109], [110, 112], [113, 119], [119, 120]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [3, 3, "misc"], [6, 6, "metrics"], [15, 17, "algorithm"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 3, "related-to", "overcomes", false, false], [0, 0, 6, 6, "related-to", "increases", false, false], [3, 3, 15, 17, "opposite", "", false, false], [3, 3, 19, 21, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "helps", "overcome", "synonymy", "by", "increasing", "recall", ",", "one", "of", "the", "most", "problematic", "limitations", "of", "Boolean", "keyword", "queries", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI helps overcome synonymy by increasing recall, one of the most problematic limitations of Boolean keyword queries and vector space models.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 27], [28, 30], [31, 41], [42, 48], [48, 49], [50, 53], [54, 56], [57, 60], [61, 65], [66, 77], [78, 89], [90, 92], [93, 100], [101, 108], [109, 116], [117, 120], [121, 127], [128, 133], [134, 140], [140, 141]]}
{"doc_key": "ai-test-172", "ner": [[18, 18, "programlang"], [20, 20, "programlang"], [22, 22, "programlang"], [24, 26, "programlang"], [28, 29, "programlang"], [31, 31, "programlang"], [33, 33, "programlang"], [35, 35, "programlang"], [37, 37, "programlang"], [39, 39, "programlang"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [], "relations_mapping_to_source": [], "sentence": ["Data", "acquisition", "applications", "are", "usually", "controlled", "by", "software", "programmes", "developed", "using", "various", "general", "purpose", "programming", "languages", "such", "as", "Assembly", ",", "BASIC", ",", "C", ",", "C", "+", "+", ",", "C", "#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "Data acquisition applications are usually controlled by software programmes developed using various general purpose programming languages such as Assembly, BASIC, C, C + +, C #, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 4], [5, 16], [17, 29], [30, 33], [34, 41], [42, 52], [53, 55], [56, 64], [65, 75], [76, 85], [86, 91], [92, 99], [100, 107], [108, 115], [116, 127], [128, 137], [138, 142], [143, 145], [146, 154], [154, 155], [156, 161], [161, 162], [163, 164], [164, 165], [166, 167], [168, 169], [170, 171], [171, 172], [173, 174], [175, 176], [176, 177], [178, 185], [185, 186], [187, 191], [191, 192], [193, 200], [200, 201], [202, 206], [206, 207], [208, 214], [214, 215], [216, 220]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [10, 10, "country"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2003", ",", "Honda", "released", "its", "gear", "advertising", "in", "the", "UK", "and", "on", "the", "internet", "."], "sentence-detokenized": "In 2003, Honda released its gear advertising in the UK and on the internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 27], [28, 32], [33, 44], [45, 47], [48, 51], [52, 54], [55, 58], [59, 61], [62, 65], [66, 74], [74, 75]]}
{"doc_key": "ai-test-174", "ner": [[1, 4, "conference"], [6, 7, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 4, 6, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Association", "for", "Computational", "Linguistics", "defines", "computational", "linguistics", "as", ":"], "sentence-detokenized": "The Association for Computational Linguistics defines computational linguistics as:", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 45], [46, 53], [54, 67], [68, 79], [80, 82], [82, 83]]}
{"doc_key": "ai-test-175", "ner": [[0, 2, "algorithm"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 11, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Expectation", "maximisation", "algorithms", "can", "be", "used", "to", "compute", "approximate", "maximum", "likelihood", "estimates", "of", "unknown", "state", "space", "parameters", "within", "minimum", "-variance", "filters", "and", "smoothers", "."], "sentence-detokenized": "Expectation maximisation algorithms can be used to compute approximate maximum likelihood estimates of unknown state space parameters within minimum-variance filters and smoothers.", "token2charspan": [[0, 11], [12, 24], [25, 35], [36, 39], [40, 42], [43, 47], [48, 50], [51, 58], [59, 70], [71, 78], [79, 89], [90, 99], [100, 102], [103, 110], [111, 116], [117, 122], [123, 133], [134, 140], [141, 148], [148, 157], [158, 165], [166, 169], [170, 179], [179, 180]]}
{"doc_key": "ai-test-176", "ner": [[5, 7, "person"], [9, 10, "person"], [12, 13, "person"], [16, 17, "misc"], [18, 19, "person"], [22, 23, "person"], [27, 27, "person"], [29, 30, "person"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "relations": [[18, 19, 16, 17, "role", "model_for", false, false], [27, 27, 29, 30, "social", "family", false, false]], "relations_mapping_to_source": [3, 4], "sentence": ["Correspondents", "included", "former", "Baywatch", "actresses", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "and", "Traci", "Bingham", ",", "former", "Playboy", "Playmate", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", "and", "identical", "twins", "Randy", "and", "Jason", "Sklar", "."], "sentence-detokenized": "Correspondents included former Baywatch actresses Donna D'Errico, Carmen Electra and Traci Bingham, former Playboy Playmate Heidi Mark, comedian Arj Barker and identical twins Randy and Jason Sklar.", "token2charspan": [[0, 14], [15, 23], [24, 30], [31, 39], [40, 49], [50, 55], [56, 58], [58, 64], [64, 65], [66, 72], [73, 80], [81, 84], [85, 90], [91, 98], [98, 99], [100, 106], [107, 114], [115, 123], [124, 129], [130, 134], [134, 135], [136, 144], [145, 148], [149, 155], [156, 159], [160, 169], [170, 175], [176, 181], [182, 185], [186, 191], [192, 197], [197, 198]]}
{"doc_key": "ai-test-177", "ner": [[8, 9, "task"], [11, 11, "task"], [16, 18, "product"], [21, 22, "task"], [24, 24, "task"], [29, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [16, 18, 8, 9, "general-affiliation", "", false, false], [24, 24, 21, 22, "named", "", false, false], [29, 30, 21, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "is", "commonly", "used", "to", "generate", "representations", "for", "speech", "recognition", "(", "ASR", ")", ",", "e.g.", "the", "CMU", "Sphinx", "system", ",", "and", "speech", "synthesis", "(", "TTS", ")", ",", "e.g.", "the", "Festival", "system", "."], "sentence-detokenized": "It is commonly used to generate representations for speech recognition (ASR), e.g. the CMU Sphinx system, and speech synthesis (TTS), e.g. the Festival system.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 19], [20, 22], [23, 31], [32, 47], [48, 51], [52, 58], [59, 70], [71, 72], [72, 75], [75, 76], [76, 77], [78, 82], [83, 86], [87, 90], [91, 97], [98, 104], [104, 105], [106, 109], [110, 116], [117, 126], [127, 128], [128, 131], [131, 132], [132, 133], [134, 138], [139, 142], [143, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-test-178", "ner": [[0, 0, "metrics"], [2, 4, "metrics"], [6, 6, "metrics"], [10, 11, "metrics"], [25, 26, "metrics"], [28, 28, "metrics"], [38, 39, "metrics"], [41, 41, "metrics"], [43, 45, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 4, 0, 0, "named", "", false, false], [6, 6, 2, 4, "named", "", false, false], [10, 11, 0, 0, "named", "", false, false], [28, 28, 25, 26, "named", "", false, false], [41, 41, 38, 39, "named", "", false, false], [43, 45, 38, 39, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sensitivity", "or", "TRUE", "Positive", "Rate", "(", "TPR", ")", ",", "also", "called", "recall", ",", "is", "the", "percentage", "of", "people", "who", "test", "positive", "and", "are", "positive", "(", "TRUE", "Positive", ",", "TP", ")", "of", "all", "people", "who", "are", "actually", "positive", "(", "Condition", "Positive", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "Sensitivity or TRUE Positive Rate (TPR), also called recall, is the percentage of people who test positive and are positive (TRUE Positive, TP) of all people who are actually positive (Condition Positive, CP = TP + FN).", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 28], [29, 33], [34, 35], [35, 38], [38, 39], [39, 40], [41, 45], [46, 52], [53, 59], [59, 60], [61, 63], [64, 67], [68, 78], [79, 81], [82, 88], [89, 92], [93, 97], [98, 106], [107, 110], [111, 114], [115, 123], [124, 125], [125, 129], [130, 138], [138, 139], [140, 142], [142, 143], [144, 146], [147, 150], [151, 157], [158, 161], [162, 165], [166, 174], [175, 183], [184, 185], [185, 194], [195, 203], [203, 204], [205, 207], [208, 209], [210, 212], [213, 214], [215, 217], [217, 218], [218, 219]]}
{"doc_key": "ai-test-179", "ner": [[12, 12, "conference"], [14, 15, "conference"], [17, 17, "conference"], [19, 19, "conference"], [21, 21, "conference"], [25, 26, "conference"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "speech", "recognition", "conferences", "held", "every", "year", "or", "every", "two", "years", "are", "SpeechTEK", "and", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", ",", "and", "the", "IEEE", "ASRU", "."], "sentence-detokenized": "Popular speech recognition conferences held every year or every two years are SpeechTEK and SpeechTEK Europe, ICASSP, Interspeech / Eurospeech, and the IEEE ASRU.", "token2charspan": [[0, 7], [8, 14], [15, 26], [27, 38], [39, 43], [44, 49], [50, 54], [55, 57], [58, 63], [64, 67], [68, 73], [74, 77], [78, 87], [88, 91], [92, 101], [102, 108], [108, 109], [110, 116], [116, 117], [118, 129], [130, 131], [132, 142], [142, 143], [144, 147], [148, 151], [152, 156], [157, 161], [161, 162]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [3, 3, "researcher"], [17, 18, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 0, 0, "artifact", "", false, false], [23, 23, 3, 3, "artifact", "", false, false], [23, 23, 17, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "worked", "with", "Engelberger", ",", "who", "was", "chairman", "of", "the", "company", ",", "to", "develop", "and", "produce", "an", "industrial", "robot", "under", "the", "brand", "name", "Unimate", "."], "sentence-detokenized": "Devol worked with Engelberger, who was chairman of the company, to develop and produce an industrial robot under the brand name Unimate.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 29], [29, 30], [31, 34], [35, 38], [39, 47], [48, 50], [51, 54], [55, 62], [62, 63], [64, 66], [67, 74], [75, 78], [79, 86], [87, 89], [90, 100], [101, 106], [107, 112], [113, 116], [117, 122], [123, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-test-181", "ner": [[1, 3, "algorithm"], [5, 5, "algorithm"], [9, 11, "algorithm"], [22, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 9, 11, "general-affiliation", "", false, false], [5, 5, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "hidden", "Markov", "model", "(", "HMM", ")", "is", "a", "statistical", "Markov", "model", "in", "which", "the", "modelled", "system", "is", "assumed", "to", "be", "a", "Markov", "process", "with", "unobserved", "(", "hidden", ")", "states", "."], "sentence-detokenized": "A hidden Markov model (HMM) is a statistical Markov model in which the modelled system is assumed to be a Markov process with unobserved (hidden) states.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [22, 23], [23, 26], [26, 27], [28, 30], [31, 32], [33, 44], [45, 51], [52, 57], [58, 60], [61, 66], [67, 70], [71, 79], [80, 86], [87, 89], [90, 97], [98, 100], [101, 103], [104, 105], [106, 112], [113, 120], [121, 125], [126, 136], [137, 138], [138, 144], [144, 145], [146, 152], [152, 153]]}
{"doc_key": "ai-test-182", "ner": [[19, 21, "metrics"], [28, 28, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "property", ",", "which", "is", "undesirable", "in", "many", "applications", ",", "has", "led", "researchers", "to", "use", "alternatives", "such", "as", "the", "mean", "absolute", "error", ",", "or", "that", "based", "on", "the", "median", "."], "sentence-detokenized": "This property, which is undesirable in many applications, has led researchers to use alternatives such as the mean absolute error, or that based on the median.", "token2charspan": [[0, 4], [5, 13], [13, 14], [15, 20], [21, 23], [24, 35], [36, 38], [39, 43], [44, 56], [56, 57], [58, 61], [62, 65], [66, 77], [78, 80], [81, 84], [85, 97], [98, 102], [103, 105], [106, 109], [110, 114], [115, 123], [124, 129], [129, 130], [131, 133], [134, 138], [139, 144], [145, 147], [148, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-test-183", "ner": [[22, 23, "algorithm"], [30, 32, "field"], [34, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 23, 30, 32, "part-of", "", false, false], [22, 23, 34, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Such", "a", "sequence", "(", "which", "depends", "on", "the", "outcome", "of", "the", "examination", "of", "previous", "attributes", "at", "each", "stage", ")", "is", "called", "a", "decision", "tree", "and", "applied", "to", "the", "field", "of", "machine", "learning", "known", "as", "decision", "tree", "learning", "."], "sentence-detokenized": "Such a sequence (which depends on the outcome of the examination of previous attributes at each stage) is called a decision tree and applied to the field of machine learning known as decision tree learning.", "token2charspan": [[0, 4], [5, 6], [7, 15], [16, 17], [17, 22], [23, 30], [31, 33], [34, 37], [38, 45], [46, 48], [49, 52], [53, 64], [65, 67], [68, 76], [77, 87], [88, 90], [91, 95], [96, 101], [101, 102], [103, 105], [106, 112], [113, 114], [115, 123], [124, 128], [129, 132], [133, 140], [141, 143], [144, 147], [148, 153], [154, 156], [157, 164], [165, 173], [174, 179], [180, 182], [183, 191], [192, 196], [197, 205], [205, 206]]}
{"doc_key": "ai-test-184", "ner": [[2, 3, "task"], [5, 5, "algorithm"], [16, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 5, 5, "compare", "", false, false], [16, 20, 5, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Similar", "to", "factor", "analysis", ",", "LCA", "can", "also", "be", "used", "to", "classify", "cases", "according", "to", "their", "maximum", "likelihood", "of", "belonging", "to", "a", "particular", "class", "."], "sentence-detokenized": "Similar to factor analysis, LCA can also be used to classify cases according to their maximum likelihood of belonging to a particular class.", "token2charspan": [[0, 7], [8, 10], [11, 17], [18, 26], [26, 27], [28, 31], [32, 35], [36, 40], [41, 43], [44, 48], [49, 51], [52, 60], [61, 66], [67, 76], [77, 79], [80, 85], [86, 93], [94, 104], [105, 107], [108, 117], [118, 120], [121, 122], [123, 133], [134, 139], [139, 140]]}
{"doc_key": "ai-test-185", "ner": [[0, 3, "algorithm"], [6, 8, "metrics"], [10, 10, "metrics"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 6, 8, "usage", "", false, false], [6, 8, 12, 13, "related-to", "", false, false], [10, 10, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["For", "supervised", "neural", "networks", "using", "a", "mean", "square", "error", "(", "MSE", ")", "cost", "function", ",", "formal", "statistical", "methods", "can", "be", "used", "to", "determine", "the", "reliability", "of", "the", "trained", "model", "."], "sentence-detokenized": "For supervised neural networks using a mean square error (MSE) cost function, formal statistical methods can be used to determine the reliability of the trained model.", "token2charspan": [[0, 3], [4, 14], [15, 21], [22, 30], [31, 36], [37, 38], [39, 43], [44, 50], [51, 56], [57, 58], [58, 61], [61, 62], [63, 67], [68, 76], [76, 77], [78, 84], [85, 96], [97, 104], [105, 108], [109, 111], [112, 116], [117, 119], [120, 129], [130, 133], [134, 145], [146, 148], [149, 152], [153, 160], [161, 166], [166, 167]]}
{"doc_key": "ai-test-186", "ner": [[16, 17, "algorithm"], [20, 22, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 20, 22, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "expressed", "directly", "as", "a", "linear", "programme", ",", "but", "it", "is", "also", "equivalent", "to", "Tikhonov", "regularisation", "with", "the", "hinge", "loss", "function", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "This can be expressed directly as a linear programme, but it is also equivalent to Tikhonov regularisation with the hinge loss function, mathV (f (x), y) = max (0, 1 - yf (x)) / math:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 21], [22, 30], [31, 33], [34, 35], [36, 42], [43, 52], [52, 53], [54, 57], [58, 60], [61, 63], [64, 68], [69, 79], [80, 82], [83, 91], [92, 106], [107, 111], [112, 115], [116, 121], [122, 126], [127, 135], [135, 136], [137, 142], [143, 144], [144, 145], [146, 147], [147, 148], [148, 149], [149, 150], [151, 152], [152, 153], [154, 155], [156, 159], [160, 161], [161, 162], [162, 163], [164, 165], [166, 167], [168, 170], [171, 172], [172, 173], [173, 174], [174, 175], [176, 177], [178, 182], [182, 183]]}
{"doc_key": "ai-test-187", "ner": [[6, 6, "researcher"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "technique", "was", "described", "in", "Breiman", "'s", "original", "article", "and", "is", "implemented", "in", "the", "R", "package", "randomForest", "."], "sentence-detokenized": "The following technique was described in Breiman's original article and is implemented in the R package randomForest.", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 27], [28, 37], [38, 40], [41, 48], [48, 50], [51, 59], [60, 67], [68, 71], [72, 74], [75, 86], [87, 89], [90, 93], [94, 95], [96, 103], [104, 116], [116, 117]]}
{"doc_key": "ai-test-188", "ner": [[8, 8, "metrics"], [41, 41, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "measures", "of", "image", "quality", ",", "such", "as", "PSNR", ",", "are", "usually", "performed", "on", "fixed", "-", "resolution", "images", "and", "do", "not", "take", "into", "account", "certain", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "the", "change", "in", "spatial", "resolution", "across", "the", "retina", "."], "sentence-detokenized": "Traditional measures of image quality, such as PSNR, are usually performed on fixed-resolution images and do not take into account certain aspects of the human visual system, such as the change in spatial resolution across the retina.", "token2charspan": [[0, 11], [12, 20], [21, 23], [24, 29], [30, 37], [37, 38], [39, 43], [44, 46], [47, 51], [51, 52], [53, 56], [57, 64], [65, 74], [75, 77], [78, 83], [83, 84], [84, 94], [95, 101], [102, 105], [106, 108], [109, 112], [113, 117], [118, 122], [123, 130], [131, 138], [139, 146], [147, 149], [150, 153], [154, 159], [160, 166], [167, 173], [173, 174], [175, 179], [180, 182], [183, 186], [187, 193], [194, 196], [197, 204], [205, 215], [216, 222], [223, 226], [227, 233], [233, 234]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [14, 15, "person"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 18, 19, "role", "", false, false], [3, 4, 18, 19, "role", "", false, false], [6, 7, 18, 19, "role", "", false, false], [18, 19, 14, 15, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "and", "Macdonald", "Carey", "played", "the", "lead", "roles", "in", "the", "Jack", "Broder", "colour", "production", "Hannah", "Lee", ",", "which", "premiered", "on", "19", "June", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru and Macdonald Carey played the lead roles in the Jack Broder colour production Hannah Lee, which premiered on 19 June 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 28], [29, 38], [39, 44], [45, 51], [52, 55], [56, 60], [61, 66], [67, 69], [70, 73], [74, 78], [79, 85], [86, 92], [93, 103], [104, 110], [111, 114], [114, 115], [116, 121], [122, 131], [132, 134], [135, 137], [138, 142], [143, 147], [147, 148]]}
{"doc_key": "ai-test-190", "ner": [[4, 5, "task"], [10, 12, "field"], [17, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 10, 12, "usage", "", false, false], [17, 17, 10, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["That", "process", "is", "called", "image", "capture", ",", "and", "uses", "various", "computer", "vision", "methods", ",", "mostly", "related", "to", "tracking", "."], "sentence-detokenized": "That process is called image capture, and uses various computer vision methods, mostly related to tracking.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 22], [23, 28], [29, 36], [36, 37], [38, 41], [42, 46], [47, 54], [55, 63], [64, 70], [71, 78], [78, 79], [80, 86], [87, 94], [95, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-191", "ner": [[18, 19, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Let", "us", "now", "start", "by", "explaining", "the", "different", "possible", "relationships", "between", "the", "predicted", "and", "the", "actual", "outcome", ":", "Confusion", "matrix"], "sentence-detokenized": "Let us now start by explaining the different possible relationships between the predicted and the actual outcome: Confusion matrix", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 19], [20, 30], [31, 34], [35, 44], [45, 53], [54, 67], [68, 75], [76, 79], [80, 89], [90, 93], [94, 97], [98, 104], [105, 112], [112, 113], [114, 123], [124, 130]]}
{"doc_key": "ai-test-192", "ner": [[1, 4, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "VOICEBOX", "speech", "processing", "toolbox", "for", "MATLAB", "implements", "the", "conversion", "and", "its", "inverse", "as", ":"], "sentence-detokenized": "The VOICEBOX speech processing toolbox for MATLAB implements the conversion and its inverse as:", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 30], [31, 38], [39, 42], [43, 49], [50, 60], [61, 64], [65, 75], [76, 79], [80, 83], [84, 91], [92, 94], [94, 95]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "general-affiliation", "", false, false], [0, 0, 11, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logic", "programming", "language", "associated", "with", "artificial", "intelligence", "and", "computational", "linguistics", "."], "sentence-detokenized": "Prolog is a logic programming language associated with artificial intelligence and computational linguistics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 17], [18, 29], [30, 38], [39, 49], [50, 54], [55, 65], [66, 78], [79, 82], [83, 96], [97, 108], [108, 109]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [9, 9, "field"], [11, 11, "field"], [17, 20, "organisation"], [23, 26, "organisation"], [29, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 9, 9, "related-to", "works_with_topic", false, false], [0, 0, 11, 11, "related-to", "works_with_topic", false, false], [0, 0, 17, 20, "role", "", false, false], [0, 0, 23, 26, "role", "", false, false], [0, 0, 29, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "numerous", "awards", "for", "her", "contributions", "to", "neuroscience", "and", "psychology", ",", "including", "memberships", "of", "the", "Royal", "Society", "of", "London", ",", "the", "Royal", "Society", "of", "Canada", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received numerous awards for her contributions to neuroscience and psychology, including memberships of the Royal Society of London, the Royal Society of Canada and the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 35], [36, 39], [40, 43], [44, 57], [58, 60], [61, 73], [74, 77], [78, 88], [88, 89], [90, 99], [100, 111], [112, 114], [115, 118], [119, 124], [125, 132], [133, 135], [136, 142], [142, 143], [144, 147], [148, 153], [154, 161], [162, 164], [165, 171], [172, 175], [176, 179], [180, 188], [189, 196], [197, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-test-195", "ner": [[17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [30, 30, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["By", "combining", "these", "operators", ",", "one", "can", "obtain", "algorithms", "for", "many", "image", "processing", "tasks", ",", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "sharpening", ",", "image", "filtering", ",", "and", "classification", "."], "sentence-detokenized": "By combining these operators, one can obtain algorithms for many image processing tasks, such as feature extraction, image segmentation, image sharpening, image filtering, and classification.", "token2charspan": [[0, 2], [3, 12], [13, 18], [19, 28], [28, 29], [30, 33], [34, 37], [38, 44], [45, 55], [56, 59], [60, 64], [65, 70], [71, 81], [82, 87], [87, 88], [89, 93], [94, 96], [97, 104], [105, 115], [115, 116], [117, 122], [123, 135], [135, 136], [137, 142], [143, 153], [153, 154], [155, 160], [161, 170], [170, 171], [172, 175], [176, 190], [190, 191]]}
{"doc_key": "ai-test-196", "ner": [[10, 12, "university"], [16, 18, "organisation"], [20, 21, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 21, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "2017", ",", "he", "has", "been", "a", "professor", "at", "the", "Coll\u00e8ge", "de", "France", "and", "director", "of", "INSERM", "Unit", "562", ",", "Cognitive", "Neuroimaging", ",", "since", "1989", "."], "sentence-detokenized": "Since 2017, he has been a professor at the Coll\u00e8ge de France and director of INSERM Unit 562, Cognitive Neuroimaging, since 1989.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 14], [15, 18], [19, 23], [24, 25], [26, 35], [36, 38], [39, 42], [43, 50], [51, 53], [54, 60], [61, 64], [65, 73], [74, 76], [77, 83], [84, 88], [89, 92], [92, 93], [94, 103], [104, 116], [116, 117], [118, 123], [124, 128], [128, 129]]}
{"doc_key": "ai-test-197", "ner": [[11, 13, "algorithm"], [15, 18, "algorithm"], [23, 23, "algorithm"], [25, 31, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 25, 31, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "many", "approaches", "to", "learning", "these", "embeddings", ",", "notably", "using", "Bayesian", "clustering", "frameworks", "or", "energy", "-", "based", "frameworks", ",", "and", "more", "recently", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", "2013", ")", "."], "sentence-detokenized": "There are many approaches to learning these embeddings, notably using Bayesian clustering frameworks or energy-based frameworks, and more recently TransE (Conference on Neural Information Processing Systems 2013).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 25], [26, 28], [29, 37], [38, 43], [44, 54], [54, 55], [56, 63], [64, 69], [70, 78], [79, 89], [90, 100], [101, 103], [104, 110], [110, 111], [111, 116], [117, 127], [127, 128], [129, 132], [133, 137], [138, 146], [147, 153], [154, 155], [155, 165], [166, 168], [169, 175], [176, 187], [188, 198], [199, 206], [207, 211], [211, 212], [212, 213]]}
{"doc_key": "ai-test-198", "ner": [[6, 8, "metrics"], [10, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 12, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "is", "an", "alternative", "to", "the", "word", "error", "rate", "(", "Word", "Error", "Rate", ")", "used", "in", "several", "countries", "."], "sentence-detokenized": "It is an alternative to the word error rate (Word Error Rate) used in several countries.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 23], [24, 27], [28, 32], [33, 38], [39, 43], [44, 45], [45, 49], [50, 55], [56, 60], [60, 61], [62, 66], [67, 69], [70, 77], [78, 87], [87, 88]]}
{"doc_key": "ai-test-199", "ner": [[0, 0, "algorithm"], [11, 12, "task"], [14, 15, "task"], [17, 18, "task"], [20, 22, "task"], [25, 28, "task"], [30, 31, "task"], [45, 45, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 0, 0, "usage", "", false, false], [14, 15, 0, 0, "usage", "", false, false], [17, 18, 0, 0, "usage", "", false, false], [20, 22, 0, 0, "usage", "", false, false], [25, 28, 0, 0, "usage", "", false, false], [30, 31, 0, 0, "usage", "", false, false], [45, 45, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "have", "been", "used", "for", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "filtering", "social", "networks", ",", "playing", "board", "and", "video", "games", ",", "medical", "diagnosis", ",", "and", "even", "in", "activities", "traditionally", "considered", "reserved", "for", "humans", ",", "such", "as", "painting", "."], "sentence-detokenized": "ANNs have been used for a variety of tasks, including computer vision, speech recognition, machine translation, filtering social networks, playing board and video games, medical diagnosis, and even in activities traditionally considered reserved for humans, such as painting.", "token2charspan": [[0, 4], [5, 9], [10, 14], [15, 19], [20, 23], [24, 25], [26, 33], [34, 36], [37, 42], [42, 43], [44, 53], [54, 62], [63, 69], [69, 70], [71, 77], [78, 89], [89, 90], [91, 98], [99, 110], [110, 111], [112, 121], [122, 128], [129, 137], [137, 138], [139, 146], [147, 152], [153, 156], [157, 162], [163, 168], [168, 169], [170, 177], [178, 187], [187, 188], [189, 192], [193, 197], [198, 200], [201, 211], [212, 225], [226, 236], [237, 245], [246, 249], [250, 256], [256, 257], [258, 262], [263, 265], [266, 274], [274, 275]]}
{"doc_key": "ai-test-200", "ner": [[0, 3, "product"], [5, 5, "product"], [27, 29, "field"], [31, 31, "field"], [36, 36, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 27, 29, "related-to", "", false, false], [0, 3, 36, 36, "general-affiliation", "", false, false], [5, 5, 0, 3, "named", "", false, false], [31, 31, 27, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "is", "an", "open", "-", "source", "research", "platform", "and", "collection", "of", "algorithms", "for", "speech", ",", "sound", ",", "speech", ",", "text", "and", "natural", "language", "processing", "(", "NLP", ")", ",", "written", "in", "Java", "and", "arranged", "in", "a", "modular", "and", "extensible", "framework", "that", "seeks", "to", "facilitate", "the", "addition", "of", "new", "algorithms", "."], "sentence-detokenized": "Modular Audio Recognition Framework (MARF) is an open-source research platform and collection of algorithms for speech, sound, speech, text and natural language processing (NLP), written in Java and arranged in a modular and extensible framework that seeks to facilitate the addition of new algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 25], [26, 35], [36, 37], [37, 41], [41, 42], [43, 45], [46, 48], [49, 53], [53, 54], [54, 60], [61, 69], [70, 78], [79, 82], [83, 93], [94, 96], [97, 107], [108, 111], [112, 118], [118, 119], [120, 125], [125, 126], [127, 133], [133, 134], [135, 139], [140, 143], [144, 151], [152, 160], [161, 171], [172, 173], [173, 176], [176, 177], [177, 178], [179, 186], [187, 189], [190, 194], [195, 198], [199, 207], [208, 210], [211, 212], [213, 220], [221, 224], [225, 235], [236, 245], [246, 250], [251, 256], [257, 259], [260, 270], [271, 274], [275, 283], [284, 286], [287, 290], [291, 301], [301, 302]]}
{"doc_key": "ai-test-201", "ner": [[12, 14, "organisation"], [18, 18, "country"], [22, 24, "organisation"], [27, 28, "organisation"], [33, 34, "task"], [47, 49, "organisation"], [53, 54, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[22, 24, 18, 18, "physical", "", false, false], [22, 24, 33, 34, "usage", "", false, false], [22, 24, 47, 49, "named", "", false, false], [27, 28, 18, 18, "physical", "", false, false], [27, 28, 33, 34, "usage", "", false, false], [47, 49, 53, 54, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "a", "report", "by", "civil", "liberties", "and", "rights", "campaign", "organisation", "Big", "Brother", "Watch", "revealed", "that", "two", "UK", "police", "forces", ",", "South", "Wales", "Police", "and", "the", "Metropolitan", "Police", ",", "were", "using", "live", "facial", "recognition", "at", "public", "events", "and", "in", "public", "places", ",", "in", "September", "2019", ",", "South", "Wales", "Police", "'s", "use", "of", "facial", "recognition", "was", "declared", "lawful", "."], "sentence-detokenized": "In 2018, a report by civil liberties and rights campaign organisation Big Brother Watch revealed that two UK police forces, South Wales Police and the Metropolitan Police, were using live facial recognition at public events and in public places, in September 2019, South Wales Police's use of facial recognition was declared lawful.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 20], [21, 26], [27, 36], [37, 40], [41, 47], [48, 56], [57, 69], [70, 73], [74, 81], [82, 87], [88, 96], [97, 101], [102, 105], [106, 108], [109, 115], [116, 122], [122, 123], [124, 129], [130, 135], [136, 142], [143, 146], [147, 150], [151, 163], [164, 170], [170, 171], [172, 176], [177, 182], [183, 187], [188, 194], [195, 206], [207, 209], [210, 216], [217, 223], [224, 227], [228, 230], [231, 237], [238, 244], [244, 245], [246, 248], [249, 258], [259, 263], [263, 264], [265, 270], [271, 276], [277, 283], [283, 285], [286, 289], [290, 292], [293, 299], [300, 311], [312, 315], [316, 324], [325, 331], [331, 332]]}
{"doc_key": "ai-test-202", "ner": [[0, 2, "product"], [5, 5, "programlang"], [14, 15, "field"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 5, "general-affiliation", "", false, false], [0, 2, 14, 15, "related-to", "", false, false], [0, 2, 17, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "has", "been", "ported", "to", "R", ",", "a", "freely", "available", "language", "and", "environment", "for", "statistical", "calculations", "and", "graphs", "."], "sentence-detokenized": "ANIMAL has been ported to R, a freely available language and environment for statistical calculations and graphs.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [23, 25], [26, 27], [27, 28], [29, 30], [31, 37], [38, 47], [48, 56], [57, 60], [61, 72], [73, 76], [77, 88], [89, 101], [102, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-test-203", "ner": [[0, 6, "algorithm"], [8, 10, "algorithm"], [16, 18, "algorithm"], [20, 20, "algorithm"], [23, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 16, 18, "opposite", "alternative to", false, false], [8, 10, 0, 6, "named", "", false, false], [20, 20, 16, 18, "named", "", false, false], [23, 25, 0, 6, "usage", "", false, false], [23, 25, 16, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Time", "-", "in", "-homogeneous", "hidden", "Bernoulli", "model", "(", "TI", "-", "HBM", ")", "is", "an", "alternative", "to", "hidden", "Markov", "model", "(", "HMM", ")", "for", "automatic", "speech", "recognition", "."], "sentence-detokenized": "Time-in-homogeneous hidden Bernoulli model (TI-HBM) is an alternative to hidden Markov model (HMM) for automatic speech recognition.", "token2charspan": [[0, 4], [4, 5], [5, 7], [7, 19], [20, 26], [27, 36], [37, 42], [43, 44], [44, 46], [46, 47], [47, 50], [50, 51], [52, 54], [55, 57], [58, 69], [70, 72], [73, 79], [80, 86], [87, 92], [93, 94], [94, 97], [97, 98], [99, 102], [103, 112], [113, 119], [120, 131], [131, 132]]}
{"doc_key": "ai-test-204", "ner": [[4, 4, "organisation"], [7, 7, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 7, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "Nvidia", "demonstrated", "at", "SIGGRAPH", "a", "new", "method", "of", "foveated", "rendering", "claimed", "to", "be", "invisible", "to", "users", "."], "sentence-detokenized": "In July 2016, Nvidia demonstrated at SIGGRAPH a new method of foveated rendering claimed to be invisible to users.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 33], [34, 36], [37, 45], [46, 47], [48, 51], [52, 58], [59, 61], [62, 70], [71, 80], [81, 88], [89, 91], [92, 94], [95, 104], [105, 107], [108, 113], [113, 114]]}
{"doc_key": "ai-test-205", "ner": [[3, 5, "misc"], [9, 10, "researcher"], [17, 18, "researcher"], [20, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 9, 10, "origin", "", false, false], [3, 5, 17, 18, "origin", "", false, false], [3, 5, 20, 20, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Both", "rely", "on", "speech", "act", "theory", ",", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "improved", "by", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both rely on speech act theory, developed by John Searle in the 1960s and improved by Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 19], [20, 23], [24, 30], [30, 31], [32, 41], [42, 44], [45, 49], [50, 56], [57, 59], [60, 63], [64, 69], [70, 73], [74, 82], [83, 85], [86, 91], [92, 100], [101, 104], [105, 111], [112, 114], [115, 118], [119, 124], [124, 125]]}
{"doc_key": "ai-test-206", "ner": [[0, 2, "algorithm"], [22, 23, "researcher"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 22, 23, "related-to", "", false, false], [25, 25, 22, 23, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "the", "structure", "of", "knowledge", "have", "produced", "powerful", "hierarchical", "models", "of", "knowledge", "organisation", ",", "such", "as", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "Neural network models of concept formation and the structure of knowledge have produced powerful hierarchical models of knowledge organisation, such as George Miller's Wordnet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 50], [51, 60], [61, 63], [64, 73], [74, 78], [79, 87], [88, 96], [97, 109], [110, 116], [117, 119], [120, 129], [130, 142], [142, 143], [144, 148], [149, 151], [152, 158], [159, 165], [165, 167], [168, 175], [175, 176]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [12, 13, "field"], [16, 18, "product"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 13, "part-of", "", false, false], [0, 1, 21, 23, "part-of", "", false, false], [16, 18, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Template", "matching", "has", "several", "applications", "and", "is", "used", "in", "areas", "such", "as", "face", "recognition", "(", "see", "face", "recognition", "system", ")", "and", "medical", "image", "processing", "."], "sentence-detokenized": "Template matching has several applications and is used in areas such as face recognition (see face recognition system) and medical image processing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 29], [30, 42], [43, 46], [47, 49], [50, 54], [55, 57], [58, 63], [64, 68], [69, 71], [72, 76], [77, 88], [89, 90], [90, 93], [94, 98], [99, 110], [111, 117], [117, 118], [119, 122], [123, 130], [131, 136], [137, 147], [147, 148]]}
{"doc_key": "ai-test-208", "ner": [[11, 12, "researcher"], [14, 15, "researcher"], [20, 29, "organisation"], [31, 31, "organisation"], [39, 40, "algorithm"], [43, 49, "conference"], [51, 51, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 12, 20, 29, "role", "", false, false], [11, 12, 43, 49, "physical", "", false, false], [11, 12, 43, 49, "temporal", "", false, false], [11, 12, 51, 51, "physical", "", false, false], [14, 15, 20, 29, "role", "", false, false], [14, 15, 43, 49, "temporal", "", false, false], [31, 31, 20, 29, "named", "", false, false], [43, 49, 39, 40, "topic", "", false, false], [51, 51, 43, 49, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "it", "s", "use", "became", "widespread", "only", "in", "2005", "when", "Navneet", "Dalal", "and", "Bill", "Triggs", ",", "researchers", "for", "the", "French", "National", "Institute", "for", "Research", "in", "Computer", "Science", "and", "Automation", "(", "INRIA", ")", ",", "presented", "their", "complementary", "work", "on", "HOG", "descriptors", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "However, its use became widespread only in 2005 when Navneet Dalal and Bill Triggs, researchers for the French National Institute for Research in Computer Science and Automation (INRIA), presented their complementary work on HOG descriptors at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 7], [7, 8], [9, 11], [11, 12], [13, 16], [17, 23], [24, 34], [35, 39], [40, 42], [43, 47], [48, 52], [53, 60], [61, 66], [67, 70], [71, 75], [76, 82], [82, 83], [84, 95], [96, 99], [100, 103], [104, 110], [111, 119], [120, 129], [130, 133], [134, 142], [143, 145], [146, 154], [155, 162], [163, 166], [167, 177], [178, 179], [179, 184], [184, 185], [185, 186], [187, 196], [197, 202], [203, 216], [217, 221], [222, 224], [225, 228], [229, 240], [241, 243], [244, 247], [248, 258], [259, 261], [262, 270], [271, 277], [278, 281], [282, 289], [290, 301], [302, 303], [303, 307], [307, 308], [308, 309]]}
{"doc_key": "ai-test-209", "ner": [[3, 3, "university"], [16, 18, "organisation"], [20, 21, "organisation"], [34, 36, "researcher"], [38, 41, "researcher"], [44, 46, "researcher"], [49, 52, "organisation"], [56, 58, "organisation"], [63, 64, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9], "relations": [[34, 36, 20, 21, "physical", "", false, false], [34, 36, 20, 21, "role", "", false, false], [38, 41, 20, 21, "physical", "", false, false], [38, 41, 20, 21, "role", "", false, false], [44, 46, 20, 21, "physical", "", false, false], [44, 46, 20, 21, "role", "", false, false], [63, 64, 56, 58, "role", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "sentence": ["Before", "joining", "the", "Penn", "faculty", "in", "2002", ",", "he", "spent", "10", "years", "(", "1991-2001", ")", "at", "AT", "&T", "Labs", "and", "Bell", "Labs", ",", "including", "as", "head", "of", "the", "AI", "department", "with", "colleagues", "such", "as", "Michael", "L.", "Littman", ",", "David", "A", ".", "McAllester", ",", "and", "Richard", "S.", "Sutton", ";", "the", "Secure", "Systems", "Research", "department", ";", "and", "the", "Machine", "Learning", "department", "with", "members", "such", "as", "Michael", "Collins", "and", "the", "leader", ")", "."], "sentence-detokenized": "Before joining the Penn faculty in 2002, he spent 10 years (1991-2001) at AT&T Labs and Bell Labs, including as head of the AI department with colleagues such as Michael L. Littman, David A. McAllester, and Richard S. Sutton; the Secure Systems Research department; and the Machine Learning department with members such as Michael Collins and the leader).", "token2charspan": [[0, 6], [7, 14], [15, 18], [19, 23], [24, 31], [32, 34], [35, 39], [39, 40], [41, 43], [44, 49], [50, 52], [53, 58], [59, 60], [60, 69], [69, 70], [71, 73], [74, 76], [76, 78], [79, 83], [84, 87], [88, 92], [93, 97], [97, 98], [99, 108], [109, 111], [112, 116], [117, 119], [120, 123], [124, 126], [127, 137], [138, 142], [143, 153], [154, 158], [159, 161], [162, 169], [170, 172], [173, 180], [180, 181], [182, 187], [188, 189], [189, 190], [191, 201], [201, 202], [203, 206], [207, 214], [215, 217], [218, 224], [224, 225], [226, 229], [230, 236], [237, 244], [245, 253], [254, 264], [264, 265], [266, 269], [270, 273], [274, 281], [282, 290], [291, 301], [302, 306], [307, 314], [315, 319], [320, 322], [323, 330], [331, 338], [339, 342], [343, 346], [347, 353], [353, 354], [354, 355]]}
{"doc_key": "ai-test-210", "ner": [[5, 7, "field"], [13, 14, "field"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 13, 14, "compare", "", false, false], [25, 26, 13, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["When", "data", "are", "unlabelled", ",", "supervised", "learning", "is", "not", "possible", ",", "and", "an", "unsupervised", "learning", "approach", "is", "required", ",", "which", "attempts", "to", "find", "a", "natural", "Cluster", "analysis", "for", "groups", ",", "and", "then", "map", "new", "data", "into", "these", "formed", "groups", "."], "sentence-detokenized": "When data are unlabelled, supervised learning is not possible, and an unsupervised learning approach is required, which attempts to find a natural Cluster analysis for groups, and then map new data into these formed groups.", "token2charspan": [[0, 4], [5, 9], [10, 13], [14, 24], [24, 25], [26, 36], [37, 45], [46, 48], [49, 52], [53, 61], [61, 62], [63, 66], [67, 69], [70, 82], [83, 91], [92, 100], [101, 103], [104, 112], [112, 113], [114, 119], [120, 128], [129, 131], [132, 136], [137, 138], [139, 146], [147, 154], [155, 163], [164, 167], [168, 174], [174, 175], [176, 179], [180, 184], [185, 188], [189, 192], [193, 197], [198, 202], [203, 208], [209, 215], [216, 222], [222, 223]]}
{"doc_key": "ai-test-211", "ner": [[3, 4, "field"], [15, 18, "organisation"], [25, 26, "field"], [28, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 15, 18, "origin", "", false, false], [3, 4, 25, 26, "part-of", "", false, false], [3, 4, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "field", "of", "computer", "science", "developed", "in", "the", "1950s", "at", "academic", "institutions", "such", "as", "the", "MIT", "A.I", ".", "Lab", ",", "originally", "as", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "This field of computer science developed in the 1950s at academic institutions such as the MIT A.I. Lab, originally as a branch of artificial intelligence and robotics.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 30], [31, 40], [41, 43], [44, 47], [48, 53], [54, 56], [57, 65], [66, 78], [79, 83], [84, 86], [87, 90], [91, 94], [95, 98], [98, 99], [100, 103], [103, 104], [105, 115], [116, 118], [119, 120], [121, 127], [128, 130], [131, 141], [142, 154], [155, 158], [159, 167], [167, 168]]}
{"doc_key": "ai-test-212", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "can", "also", "be", "replaced", "by", "the", "log", "-", "loss", "equation", "below", ":"], "sentence-detokenized": "It can also be replaced by the log-loss equation below:", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 23], [24, 26], [27, 30], [31, 34], [34, 35], [35, 39], [40, 48], [49, 54], [54, 55]]}
{"doc_key": "ai-test-213", "ner": [[1, 3, "organisation"], [7, 10, "organisation"], [14, 18, "university"], [20, 20, "university"], [22, 23, "university"], [25, 28, "university"], [30, 31, "country"], [36, 36, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 3, 36, 36, "related-to", "research_leader_in_field", false, false], [7, 10, 1, 3, "named", "", false, false], [7, 10, 36, 36, "related-to", "research_leader_in_field", false, false], [14, 18, 36, 36, "related-to", "research_leader_in_field", false, false], [20, 20, 36, 36, "related-to", "research_leader_in_field", false, false], [22, 23, 36, 36, "related-to", "research_leader_in_field", false, false], [25, 28, 30, 31, "physical", "", false, false], [25, 28, 36, 36, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "Shirley", "Ryan", "AbilityLab", "(", "formerly", "the", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "the", "University", "of", "California", "at", "Berkeley", ",", "MIT", ",", "Stanford", "University", "and", "the", "University", "of", "Twente", "in", "the", "Netherlands", "are", "the", "leaders", "in", "biomechatronics", "research", "."], "sentence-detokenized": "The Shirley Ryan AbilityLab (formerly the Rehabilitation Institute of Chicago), the University of California at Berkeley, MIT, Stanford University and the University of Twente in the Netherlands are the leaders in biomechatronics research.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 27], [28, 29], [29, 37], [38, 41], [42, 56], [57, 66], [67, 69], [70, 77], [77, 78], [78, 79], [80, 83], [84, 94], [95, 97], [98, 108], [109, 111], [112, 120], [120, 121], [122, 125], [125, 126], [127, 135], [136, 146], [147, 150], [151, 154], [155, 165], [166, 168], [169, 175], [176, 178], [179, 182], [183, 194], [195, 198], [199, 202], [203, 210], [211, 213], [214, 229], [230, 238], [238, 239]]}
{"doc_key": "ai-test-214", "ner": [[28, 31, "metrics"], [42, 43, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Given", "a", "range", "of", "predicted", "values", "and", "a", "corresponding", "range", "of", "actual", "values", "for", "X", "for", "different", "time", "periods", ",", "a", "common", "evaluation", "technique", "is", "to", "use", "the", "mean", "squared", "prediction", "error", ";", "other", "measures", "are", "also", "available", "(", "see", "forecasting", "#", "prediction", "accuracy", ")", "."], "sentence-detokenized": "Given a range of predicted values and a corresponding range of actual values for X for different time periods, a common evaluation technique is to use the mean squared prediction error; other measures are also available (see forecasting # prediction accuracy).", "token2charspan": [[0, 5], [6, 7], [8, 13], [14, 16], [17, 26], [27, 33], [34, 37], [38, 39], [40, 53], [54, 59], [60, 62], [63, 69], [70, 76], [77, 80], [81, 82], [83, 86], [87, 96], [97, 101], [102, 109], [109, 110], [111, 112], [113, 119], [120, 130], [131, 140], [141, 143], [144, 146], [147, 150], [151, 154], [155, 159], [160, 167], [168, 178], [179, 184], [184, 185], [186, 191], [192, 200], [201, 204], [205, 209], [210, 219], [220, 221], [221, 224], [225, 236], [237, 238], [239, 249], [250, 258], [258, 259], [259, 260]]}
{"doc_key": "ai-test-215", "ner": [[13, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "measures", ",", "such", "as", "the", "percentage", "of", "correct", "predictions", "(", "also", "called", "accuracy", ")", ",", "are", "not", "useful", "when", "the", "two", "classes", "are", "very", "different", "in", "size", "."], "sentence-detokenized": "Other measures, such as the percentage of correct predictions (also called accuracy), are not useful when the two classes are very different in size.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 20], [21, 23], [24, 27], [28, 38], [39, 41], [42, 49], [50, 61], [62, 63], [63, 67], [68, 74], [75, 83], [83, 84], [84, 85], [86, 89], [90, 93], [94, 100], [101, 105], [106, 109], [110, 113], [114, 121], [122, 125], [126, 130], [131, 140], [141, 143], [144, 148], [148, 149]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [15, 19, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 15, 19, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "released", "to", "the", "public", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "in", "2000", ",", "and", "five", "betas", "were", "released", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was released to the public at the Conference on Computer Vision and Pattern Recognition in 2000, and five betas were released between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 46], [47, 49], [50, 53], [54, 60], [61, 63], [64, 67], [68, 78], [79, 81], [82, 90], [91, 97], [98, 101], [102, 109], [110, 121], [122, 124], [125, 129], [129, 130], [131, 134], [135, 139], [140, 145], [146, 150], [151, 159], [160, 167], [168, 172], [173, 176], [177, 181], [181, 182]]}
{"doc_key": "ai-test-217", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Results", "were", "presented", "showing", "a", "correlation", "up", "to", "0.964", "with", "human", "assessment", "at", "corpus", "level", ",", "compared", "with", "a", "BLEU", "result", "of", "0.817", "for", "the", "same", "data", "set", "."], "sentence-detokenized": "Results were presented showing a correlation up to 0.964 with human assessment at corpus level, compared with a BLEU result of 0.817 for the same data set.", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 30], [31, 32], [33, 44], [45, 47], [48, 50], [51, 56], [57, 61], [62, 67], [68, 78], [79, 81], [82, 88], [89, 94], [94, 95], [96, 104], [105, 109], [110, 111], [112, 116], [117, 123], [124, 126], [127, 132], [133, 136], [137, 140], [141, 145], [146, 150], [151, 154], [154, 155]]}
{"doc_key": "ai-test-218", "ner": [[4, 4, "metrics"], [18, 18, "metrics"], [20, 22, "metrics"], [24, 26, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 18, 18, "compare", "", false, false], [4, 4, 20, 22, "compare", "", false, false], [4, 4, 24, 26, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["An", "early", "version", "of", "VMAF", "has", "been", "shown", "to", "outperform", "other", "image", "and", "video", "quality", "metrics", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", "and", "VQM", "-", "VFD", "on", "three", "out", "of", "four", "datasets", "in", "terms", "of", "predictive", "accuracy", "when", "compared", "with", "subjective", "ratings", "."], "sentence-detokenized": "An early version of VMAF has been shown to outperform other image and video quality metrics such as SSIM, PSNR -HVS and VQM-VFD on three out of four datasets in terms of predictive accuracy when compared with subjective ratings.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 19], [20, 24], [25, 28], [29, 33], [34, 39], [40, 42], [43, 53], [54, 59], [60, 65], [66, 69], [70, 75], [76, 83], [84, 91], [92, 96], [97, 99], [100, 104], [104, 105], [106, 110], [111, 112], [112, 115], [116, 119], [120, 123], [123, 124], [124, 127], [128, 130], [131, 136], [137, 140], [141, 143], [144, 148], [149, 157], [158, 160], [161, 166], [167, 169], [170, 180], [181, 189], [190, 194], [195, 203], [204, 208], [209, 219], [220, 227], [227, 228]]}
{"doc_key": "ai-test-219", "ner": [[18, 19, "task"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 26, 27, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "of", "\"", "mouse", "\"", "(", "animal", "or", "device", ")", "is", "not", "relevant", "in", "machine", "translation", ",", "but", "it", "is", "relevant", "in", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity of \"mouse\" (animal or device) is not relevant in machine translation, but it is relevant in information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 31], [31, 36], [36, 37], [38, 39], [39, 45], [46, 48], [49, 55], [55, 56], [57, 59], [60, 63], [64, 72], [73, 75], [76, 83], [84, 95], [95, 96], [97, 100], [101, 103], [104, 106], [107, 115], [116, 118], [119, 130], [131, 140], [140, 141]]}
{"doc_key": "ai-test-220", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 1, "usage", "", false, false], [9, 10, 6, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "hashing", "was", "originally", "proposed", "in", "computer", "vision", "for", "object", "recognition", "in", "2D", "and", "3D", ","], "sentence-detokenized": "Geometric hashing was originally proposed in computer vision for object recognition in 2D and 3D,", "token2charspan": [[0, 9], [10, 17], [18, 21], [22, 32], [33, 41], [42, 44], [45, 53], [54, 60], [61, 64], [65, 71], [72, 83], [84, 86], [87, 89], [90, 93], [94, 96], [96, 97]]}
{"doc_key": "ai-test-221", "ner": [[9, 10, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 9, 10, "part-of", "subfield", false, false], [17, 18, 9, 10, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "is", "one", "of", "the", "three", "main", "categories", "of", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "It is one of the three main categories of machine learning, along with supervised learning and reinforcement learning.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 12], [13, 16], [17, 22], [23, 27], [28, 38], [39, 41], [42, 49], [50, 58], [58, 59], [60, 65], [66, 70], [71, 81], [82, 90], [91, 94], [95, 108], [109, 117], [117, 118]]}
{"doc_key": "ai-test-222", "ner": [[0, 1, "field"], [17, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 31, "field"], [33, 34, "field"], [36, 37, "field"], [39, 39, "field"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 1, 17, 17, "part-of", "subfield", false, false], [0, 1, 19, 20, "part-of", "subfield", false, false], [0, 1, 22, 23, "part-of", "subfield", false, false], [0, 1, 25, 26, "part-of", "subfield", false, false], [0, 1, 28, 31, "part-of", "subfield", false, false], [0, 1, 33, 34, "part-of", "subfield", false, false], [0, 1, 36, 37, "part-of", "subfield", false, false], [0, 1, 39, 39, "part-of", "subfield", false, false], [0, 1, 41, 42, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Reinforcement", "learning", ",", "because", "of", "its", "generality", ",", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "game", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Reinforcement learning, because of its generality, is studied in many other disciplines, such as game, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 13], [14, 22], [22, 23], [24, 31], [32, 34], [35, 38], [39, 49], [49, 50], [51, 53], [54, 61], [62, 64], [65, 69], [70, 75], [76, 87], [87, 88], [89, 93], [94, 96], [97, 101], [101, 102], [103, 110], [111, 117], [117, 118], [119, 129], [130, 138], [138, 139], [140, 151], [152, 158], [158, 159], [160, 170], [170, 171], [171, 176], [177, 189], [189, 190], [191, 202], [203, 210], [210, 211], [212, 217], [218, 230], [230, 231], [232, 242], [243, 246], [247, 254], [255, 265], [265, 266]]}
{"doc_key": "ai-test-223", "ner": [[0, 1, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "related-to", "", false, false], [0, 1, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pattern", "recognition", "is", "closely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ","], "sentence-detokenized": "Pattern recognition is closely related to artificial intelligence and machine learning,", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 38], [39, 41], [42, 52], [53, 65], [66, 69], [70, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-224", "ner": [[9, 9, "algorithm"], [13, 14, "field"], [16, 17, "field"], [29, 30, "task"], [32, 32, "task"], [34, 35, "task"], [37, 38, "algorithm"], [40, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 9, 13, 14, "related-to", "", false, false], [9, 9, 16, 17, "related-to", "", false, false], [29, 30, 9, 9, "usage", "", true, false], [32, 32, 9, 9, "usage", "", true, false], [34, 35, 9, 9, "usage", "", true, false], [37, 38, 9, 9, "usage", "", true, false], [40, 42, 9, 9, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["It", "is", "used", "to", "design", ",", "train", "and", "deploy", "neural", "network", "models", "(", "supervised", "learning", "and", "unsupervised", "learning", ")", "to", "perform", "a", "wide", "range", "of", "tasks", ",", "such", "as", "data", "mining", ",", "classification", ",", "feature", "approximation", ",", "multivariate", "regression", "and", "time", "series", "prediction", "."], "sentence-detokenized": "It is used to design, train and deploy neural network models (supervised learning and unsupervised learning) to perform a wide range of tasks, such as data mining, classification, feature approximation, multivariate regression and time series prediction.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 20], [20, 21], [22, 27], [28, 31], [32, 38], [39, 45], [46, 53], [54, 60], [61, 62], [62, 72], [73, 81], [82, 85], [86, 98], [99, 107], [107, 108], [109, 111], [112, 119], [120, 121], [122, 126], [127, 132], [133, 135], [136, 141], [141, 142], [143, 147], [148, 150], [151, 155], [156, 162], [162, 163], [164, 178], [178, 179], [180, 187], [188, 201], [201, 202], [203, 215], [216, 226], [227, 230], [231, 235], [236, 242], [243, 253], [253, 254]]}
{"doc_key": "ai-test-225", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016, he was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-test-226", "ner": [[6, 9, "organisation"], [15, 20, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", ",", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", ","], "sentence-detokenized": "She is a member of the National Academy of Sciences (since 2005), American Academy of Arts and Sciences (since 2009),", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 15], [16, 18], [19, 22], [23, 31], [32, 39], [40, 42], [43, 51], [52, 53], [53, 58], [59, 63], [63, 64], [64, 65], [66, 74], [75, 82], [83, 85], [86, 90], [91, 94], [95, 103], [104, 105], [105, 110], [111, 115], [115, 116], [116, 117]]}
{"doc_key": "ai-test-227", "ner": [[3, 5, "misc"], [17, 17, "country"], [19, 19, "country"], [24, 26, "misc"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["During", "the", "1973", "Yom", "Kippur", "war", ",", "Soviet", "-supplied", "surface", "-", "to", "-", "air", "missile", "batteries", "in", "Egypt", "and", "Syria", "caused", "heavy", "damage", "to", "Israeli", "fighter", "planes", "."], "sentence-detokenized": "During the 1973 Yom Kippur war, Soviet-supplied surface-to-air missile batteries in Egypt and Syria caused heavy damage to Israeli fighter planes.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 26], [27, 30], [30, 31], [32, 38], [38, 47], [48, 55], [55, 56], [56, 58], [58, 59], [59, 62], [63, 70], [71, 80], [81, 83], [84, 89], [90, 93], [94, 99], [100, 106], [107, 112], [113, 119], [120, 122], [123, 130], [131, 138], [139, 145], [145, 146]]}
{"doc_key": "ai-test-228", "ner": [[9, 10, "product"], [14, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 15, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "resource", "(", "free", "but", "copyrighted", ")", "is", "the", "HTK", "book", "(", "and", "its", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another resource (free but copyrighted) is the HTK book (and its HTK toolkit).", "token2charspan": [[0, 7], [8, 16], [17, 18], [18, 22], [23, 26], [27, 38], [38, 39], [40, 42], [43, 46], [47, 50], [51, 55], [56, 57], [57, 60], [61, 64], [65, 68], [69, 76], [76, 77], [77, 78]]}
{"doc_key": "ai-test-229", "ner": [[5, 6, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "were", "taken", "at", "the", "2004", "AAAI", "Spring", "Symposium", "where", "linguists", ",", "computer", "scientists", "and", "other", "interested", "researchers", "aligned", "their", "interests", "for", "the", "first", "time", "and", "proposed", "shared", "tasks", "and", "benchmark", "datasets", "for", "the", "systematic", "computational", "investigation", "of", "affect", ",", "appeal", ",", "subjectivity", ",", "and", "sentiment", "in", "text", "."], "sentence-detokenized": "- were taken at the 2004 AAAI Spring Symposium where linguists, computer scientists and other interested researchers aligned their interests for the first time and proposed shared tasks and benchmark datasets for the systematic computational investigation of affect, appeal, subjectivity, and sentiment in text.", "token2charspan": [[0, 1], [2, 6], [7, 12], [13, 15], [16, 19], [20, 24], [25, 29], [30, 36], [37, 46], [47, 52], [53, 62], [62, 63], [64, 72], [73, 83], [84, 87], [88, 93], [94, 104], [105, 116], [117, 124], [125, 130], [131, 140], [141, 144], [145, 148], [149, 154], [155, 159], [160, 163], [164, 172], [173, 179], [180, 185], [186, 189], [190, 199], [200, 208], [209, 212], [213, 216], [217, 227], [228, 241], [242, 255], [256, 258], [259, 265], [265, 266], [267, 273], [273, 274], [275, 287], [287, 288], [289, 292], [293, 302], [303, 305], [306, 310], [310, 311]]}
{"doc_key": "ai-test-230", "ner": [[10, 10, "task"], [16, 17, "task"], [19, 21, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "single", "grid", "can", "be", "analysed", "for", "both", "content", "(", "eyeballing", ")", "and", "structure", "(", "using", "cluster", "analysis", ",", "principal", "component", "analysis", "and", "a", "set", "of", "structure", "indices", "related", "to", "the", "complexity", "and", "range", "of", "assessments", "as", "the", "main", "techniques", ")", "."], "sentence-detokenized": "A single grid can be analysed for both content (eyeballing) and structure (using cluster analysis, principal component analysis and a set of structure indices related to the complexity and range of assessments as the main techniques).", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 17], [18, 20], [21, 29], [30, 33], [34, 38], [39, 46], [47, 48], [48, 58], [58, 59], [60, 63], [64, 73], [74, 75], [75, 80], [81, 88], [89, 97], [97, 98], [99, 108], [109, 118], [119, 127], [128, 131], [132, 133], [134, 137], [138, 140], [141, 150], [151, 158], [159, 166], [167, 169], [170, 173], [174, 184], [185, 188], [189, 194], [195, 197], [198, 209], [210, 212], [213, 216], [217, 221], [222, 232], [232, 233], [233, 234]]}
{"doc_key": "ai-test-231", "ner": [[3, 3, "organisation"], [10, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", ",", "Toyota", "was", "seen", "as", "lagging", "behind", "in", "self", "-", "driving", "cars", "and", "in", "need", "of", "innovation", "."], "sentence-detokenized": "In 2018, Toyota was seen as lagging behind in self-driving cars and in need of innovation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 24], [25, 27], [28, 35], [36, 42], [43, 45], [46, 50], [50, 51], [51, 58], [59, 63], [64, 67], [68, 70], [71, 75], [76, 78], [79, 89], [89, 90]]}
{"doc_key": "ai-test-232", "ner": [[40, 43, "misc"], [45, 46, "misc"], [48, 52, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "targets", "include", "natural", "objects", "such", "as", "the", "ground", ",", "the", "sea", ",", "precipitation", "(", "such", "as", "rain", ",", "snow", "or", "hail", ")", ",", "sandstorms", ",", "animals", "(", "especially", "birds", ")", ",", "atmospheric", "turbulence", "and", "other", "atmospheric", "effects", "such", "as", "reflections", "from", "the", "ionosphere", ",", "meteor", "trails", "and", "three", "-", "body", "scattering", "peaks", "."], "sentence-detokenized": "Such targets include natural objects such as the ground, the sea, precipitation (such as rain, snow or hail), sandstorms, animals (especially birds), atmospheric turbulence and other atmospheric effects such as reflections from the ionosphere, meteor trails and three-body scattering peaks.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 28], [29, 36], [37, 41], [42, 44], [45, 48], [49, 55], [55, 56], [57, 60], [61, 64], [64, 65], [66, 79], [80, 81], [81, 85], [86, 88], [89, 93], [93, 94], [95, 99], [100, 102], [103, 107], [107, 108], [108, 109], [110, 120], [120, 121], [122, 129], [130, 131], [131, 141], [142, 147], [147, 148], [148, 149], [150, 161], [162, 172], [173, 176], [177, 182], [183, 194], [195, 202], [203, 207], [208, 210], [211, 222], [223, 227], [228, 231], [232, 242], [242, 243], [244, 250], [251, 257], [258, 261], [262, 267], [267, 268], [268, 272], [273, 283], [284, 289], [289, 290]]}
{"doc_key": "ai-test-233", "ner": [[18, 19, "product"], [36, 37, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "planning", "and", "control", ",", "the", "essential", "difference", "between", "humanoids", "and", "other", "types", "of", "robots", "(", "such", "as", "industrial", "ones", ")", "is", "that", "the", "robot", "'s", "movement", "should", "resemble", "humans", ",", "using", "leg", "movement", ",", "especially", "bipedal", "gait", "."], "sentence-detokenized": "In planning and control, the essential difference between humanoids and other types of robots (such as industrial ones) is that the robot's movement should resemble humans, using leg movement, especially bipedal gait.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 23], [23, 24], [25, 28], [29, 38], [39, 49], [50, 57], [58, 67], [68, 71], [72, 77], [78, 83], [84, 86], [87, 93], [94, 95], [95, 99], [100, 102], [103, 113], [114, 118], [118, 119], [120, 122], [123, 127], [128, 131], [132, 137], [137, 139], [140, 148], [149, 155], [156, 164], [165, 171], [171, 172], [173, 178], [179, 182], [183, 191], [191, 192], [193, 203], [204, 211], [212, 216], [216, 217]]}
{"doc_key": "ai-test-234", "ner": [[1, 2, "algorithm"], [10, 11, "misc"], [14, 14, "metrics"], [17, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "gradient", "descent", "may", "require", "many", "iterations", "to", "compute", "a", "local", "minimum", "with", "required", "accuracy", "if", "the", "curvature", "in", "different", "directions", "is", "very", "different", "for", "the", "given", "function", "."], "sentence-detokenized": "The gradient descent may require many iterations to compute a local minimum with required accuracy if the curvature in different directions is very different for the given function.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 24], [25, 32], [33, 37], [38, 48], [49, 51], [52, 59], [60, 61], [62, 67], [68, 75], [76, 80], [81, 89], [90, 98], [99, 101], [102, 105], [106, 115], [116, 118], [119, 128], [129, 139], [140, 142], [143, 147], [148, 157], [158, 161], [162, 165], [166, 171], [172, 180], [180, 181]]}
{"doc_key": "ai-test-235", "ner": [[1, 6, "misc"], [17, 22, "conference"], [26, 26, "location"], [28, 28, "country"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[17, 22, 26, 26, "physical", "", false, true], [26, 26, 28, 28, "physical", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["The", "1997", "RoboCup", "2D", "Soccer", "Simulation", "League", "was", "the", "first", "RoboCup", "competition", "organised", "as", "part", "of", "the", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", ",", "held", "in", "Nagoya", ",", "Japan", ",", "from", "23", "to", "29", "August", "1997", "."], "sentence-detokenized": "The 1997 RoboCup 2D Soccer Simulation League was the first RoboCup competition organised as part of the International Joint Conference on Artificial Intelligence, held in Nagoya, Japan, from 23 to 29 August 1997.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 19], [20, 26], [27, 37], [38, 44], [45, 48], [49, 52], [53, 58], [59, 66], [67, 78], [79, 88], [89, 91], [92, 96], [97, 99], [100, 103], [104, 117], [118, 123], [124, 134], [135, 137], [138, 148], [149, 161], [161, 162], [163, 167], [168, 170], [171, 177], [177, 178], [179, 184], [184, 185], [186, 190], [191, 193], [194, 196], [197, 199], [200, 206], [207, 211], [211, 212]]}
{"doc_key": "ai-test-236", "ner": [[11, 11, "programlang"], [16, 16, "product"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "options", "include", "an", "embedded", "Python", "environment", ",", "and", "an", "R", "Console", "plus", "support", "for", "Rserve", "."], "sentence-detokenized": "Other programming options include an embedded Python environment, and an R Console plus support for Rserve.", "token2charspan": [[0, 5], [6, 17], [18, 25], [26, 33], [34, 36], [37, 45], [46, 52], [53, 64], [64, 65], [66, 69], [70, 72], [73, 74], [75, 82], [83, 87], [88, 95], [96, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [8, 9, "field"], [11, 11, "field"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [32, 33, "field"], [38, 38, "field"], [41, 42, "field"], [47, 56, "field"], [52, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[14, 15, 11, 11, "related-to", "contributes_to_field", true, false], [17, 18, 11, 11, "related-to", "contributes_to_field", true, false], [20, 21, 11, 11, "related-to", "contributes_to_field", true, false], [41, 42, 38, 38, "part-of", "", false, false], [47, 56, 41, 42, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["From", "Bonn", ",", "he", "has", "contributed", "fundamentally", "to", "artificial", "intelligence", "and", "robotics", "(", "with", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Thrun", "among", "his", "students", ")", ",", "and", "to", "the", "development", "of", "software", "engineering", ",", "especially", "in", "civil", "engineering", ",", "and", "information", "systems", ",", "especially", "in", "the", "geosciences", ".", "won", "the", "2016.2014", "AAAI", "Classic", "Paper", "award", "."], "sentence-detokenized": "From Bonn, he has contributed fundamentally to artificial intelligence and robotics (with Wolfram Burgard, Dieter Fox, Sebastian Thrun among his students), and to the development of software engineering, especially in civil engineering, and information systems, especially in the geosciences. won the 2016.2014 AAAI Classic Paper award.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 13], [14, 17], [18, 29], [30, 43], [44, 46], [47, 57], [58, 70], [71, 74], [75, 83], [84, 85], [85, 89], [90, 97], [98, 105], [105, 106], [107, 113], [114, 117], [117, 118], [119, 128], [129, 134], [135, 140], [141, 144], [145, 153], [153, 154], [154, 155], [156, 159], [160, 162], [163, 166], [167, 178], [179, 181], [182, 190], [191, 202], [202, 203], [204, 214], [215, 217], [218, 223], [224, 235], [235, 236], [237, 240], [241, 252], [253, 260], [260, 261], [262, 272], [273, 275], [276, 279], [280, 291], [291, 292], [293, 296], [297, 300], [301, 310], [311, 315], [316, 323], [324, 329], [330, 335], [335, 336]]}
{"doc_key": "ai-test-238", "ner": [[2, 6, "conference"], [17, 18, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 6, 17, 18, "physical", "", false, false], [17, 18, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "USA", "edition", "of", "Campus", "Party", "will", "take", "place", "from", "20", "to", "22", "August", "at", "the", "TCF", "Centre", "in", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "The first USA edition of Campus Party will take place from 20 to 22 August at the TCF Centre in Detroit, Michigan.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 21], [22, 24], [25, 31], [32, 37], [38, 42], [43, 47], [48, 53], [54, 58], [59, 61], [62, 64], [65, 67], [68, 74], [75, 77], [78, 81], [82, 85], [86, 92], [93, 95], [96, 103], [103, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-239", "ner": [[2, 3, "researcher"], [6, 7, "researcher"], [9, 9, "researcher"], [13, 14, "misc"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 13, 14, "win-defeat", "", false, false], [6, 7, 13, 14, "win-defeat", "", false, false], [9, 9, 13, 14, "win-defeat", "", false, false], [13, 14, 23, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Along", "with", "Yann", "LeCun", ",", "and", "Yoshua", "Bengio", ",", "Hinton", "won", "the", "2018", "Turing", "Award", "for", "conceptual", "and", "technical", "breakthroughs", "that", "have", "made", "deep", "neural", "networks", "a", "critical", "component", "of", "computing", "."], "sentence-detokenized": "Along with Yann LeCun, and Yoshua Bengio, Hinton won the 2018 Turing Award for conceptual and technical breakthroughs that have made deep neural networks a critical component of computing.", "token2charspan": [[0, 5], [6, 10], [11, 15], [16, 21], [21, 22], [23, 26], [27, 33], [34, 40], [40, 41], [42, 48], [49, 52], [53, 56], [57, 61], [62, 68], [69, 74], [75, 78], [79, 89], [90, 93], [94, 103], [104, 117], [118, 122], [123, 127], [128, 132], [133, 137], [138, 144], [145, 153], [154, 155], [156, 164], [165, 174], [175, 177], [178, 187], [187, 188]]}
{"doc_key": "ai-test-240", "ner": [[0, 2, "product"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Euler", "Math", "Toolbox", "uses", "a", "matrix", "language", "similar", "to", "MATLAB", ",", "a", "system", "that", "had", "been", "in", "development", "since", "the", "1970s", "."], "sentence-detokenized": "Euler Math Toolbox uses a matrix language similar to MATLAB, a system that had been in development since the 1970s.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 23], [24, 25], [26, 32], [33, 41], [42, 49], [50, 52], [53, 59], [59, 60], [61, 62], [63, 69], [70, 74], [75, 78], [79, 83], [84, 86], [87, 98], [99, 104], [105, 108], [109, 114], [114, 115]]}
{"doc_key": "ai-test-241", "ner": [[7, 7, "programlang"], [9, 10, "programlang"], [12, 12, "programlang"], [14, 14, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "languages", "enable", "this", "portably", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "or", "D", ")", "."], "sentence-detokenized": "Some languages enable this portably (e.g. Scheme, Common Lisp, Perl or D).", "token2charspan": [[0, 4], [5, 14], [15, 21], [22, 26], [27, 35], [36, 37], [37, 41], [42, 48], [48, 49], [50, 56], [57, 61], [61, 62], [63, 67], [68, 70], [71, 72], [72, 73], [73, 74]]}
{"doc_key": "ai-test-242", "ner": [[14, 16, "misc"], [7, 8, "researcher"], [10, 11, "researcher"], [29, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 16, 7, 8, "artifact", "", false, false], [14, 16, 10, 11, "artifact", "", false, false], [14, 16, 29, 30, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1969", ",", "a", "famous", "book", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", ",", "entitled", "Perceptrons", ",", "showed", "that", "it", "was", "impossible", "for", "these", "classes", "of", "networks", "to", "learn", "an", "XOR", "function", "."], "sentence-detokenized": "In 1969, a famous book by Marvin Minsky and Seymour Papert, entitled Perceptrons, showed that it was impossible for these classes of networks to learn an XOR function.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 22], [23, 25], [26, 32], [33, 39], [40, 43], [44, 51], [52, 58], [58, 59], [60, 68], [69, 80], [80, 81], [82, 88], [89, 93], [94, 96], [97, 100], [101, 111], [112, 115], [116, 121], [122, 129], [130, 132], [133, 141], [142, 144], [145, 150], [151, 153], [154, 157], [158, 166], [166, 167]]}
{"doc_key": "ai-test-243", "ner": [[3, 7, "misc"], [11, 13, "product"], [17, 20, "organisation"], [24, 29, "organisation"], [32, 37, "location"], [39, 39, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 20, 11, 13, "usage", "", false, false], [17, 20, 32, 37, "physical", "", false, false], [24, 29, 17, 20, "named", "", false, false], [32, 37, 39, 39, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Large", "numbers", "of", "Russian", "scientific", "and", "technical", "documents", "were", "translated", "using", "SYSTRAN", "under", "the", "auspices", "of", "the", "USAF", "Foreign", "Technology", "Division", "(", "later", "the", "National", "Air", "and", "Space", "Intelligence", "Center", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", ",", "Ohio", "."], "sentence-detokenized": "Large numbers of Russian scientific and technical documents were translated using SYSTRAN under the auspices of the USAF Foreign Technology Division (later the National Air and Space Intelligence Center) at Wright-Patterson Air Force Base, Ohio.", "token2charspan": [[0, 5], [6, 13], [14, 16], [17, 24], [25, 35], [36, 39], [40, 49], [50, 59], [60, 64], [65, 75], [76, 81], [82, 89], [90, 95], [96, 99], [100, 108], [109, 111], [112, 115], [116, 120], [121, 128], [129, 139], [140, 148], [149, 150], [150, 155], [156, 159], [160, 168], [169, 172], [173, 176], [177, 182], [183, 195], [196, 202], [202, 203], [204, 206], [207, 213], [213, 214], [214, 223], [224, 227], [228, 233], [234, 238], [238, 239], [240, 244], [244, 245]]}
{"doc_key": "ai-test-244", "ner": [[0, 1, "field"], [4, 5, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-supervised", "learning", "falls", "between", "non-supervised", "learning", "(", "without", "labelled", "training", "data", ")", "and", "supervised", "learning", "(", "with", "fully", "labelled", "training", "data", ")", "."], "sentence-detokenized": "Semi-supervised learning falls between non-supervised learning (without labelled training data) and supervised learning (with fully labelled training data).", "token2charspan": [[0, 15], [16, 24], [25, 30], [31, 38], [39, 53], [54, 62], [63, 64], [64, 71], [72, 80], [81, 89], [90, 94], [94, 95], [96, 99], [100, 110], [111, 119], [120, 121], [121, 125], [126, 131], [132, 140], [141, 149], [150, 154], [154, 155], [155, 156]]}
{"doc_key": "ai-test-245", "ner": [[0, 3, "algorithm"], [8, 10, "algorithm"], [32, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 8, 10, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ann", "-", "gram", "model", "is", "a", "type", "of", "probabilistic", "language", "model", "for", "predicting", "the", "next", "item", "in", "such", "a", "sequence", "in", "the", "form", "of", "an", "(", "n", "-", "1", ")", "-", "order", "Markov", "model", ".efficiently", "."], "sentence-detokenized": "Ann -gram model is a type of probabilistic language model for predicting the next item in such a sequence in the form of an (n - 1) -order Markov model .efficiently.", "token2charspan": [[0, 3], [4, 5], [5, 9], [10, 15], [16, 18], [19, 20], [21, 25], [26, 28], [29, 42], [43, 51], [52, 57], [58, 61], [62, 72], [73, 76], [77, 81], [82, 86], [87, 89], [90, 94], [95, 96], [97, 105], [106, 108], [109, 112], [113, 117], [118, 120], [121, 123], [124, 125], [125, 126], [127, 128], [129, 130], [130, 131], [132, 133], [133, 138], [139, 145], [146, 151], [152, 164], [164, 165]]}
{"doc_key": "ai-test-246", "ner": [[1, 2, "organisation"], [4, 5, "product"], [8, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 4, 5, "usage", "", false, false], [8, 14, 1, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "used", "Cyc", "to", "develop", "a", "natural", "language", "query", "interface", "of", "biomedical", "information", "covering", "decades", "of", "information", "on", "cardiothoracic", "surgery", "."], "sentence-detokenized": "The Cleveland Clinic used Cyc to develop a natural language query interface of biomedical information covering decades of information on cardiothoracic surgery.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 29], [30, 32], [33, 40], [41, 42], [43, 50], [51, 59], [60, 65], [66, 75], [76, 78], [79, 89], [90, 101], [102, 110], [111, 118], [119, 121], [122, 133], [134, 136], [137, 151], [152, 159], [159, 160]]}
{"doc_key": "ai-test-247", "ner": [[2, 2, "country"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "incident", "strained", "US", "-", "Japan", "relations", "and", "led", "to", "the", "arrest", "and", "prosecution", "of", "two", "senior", "executives", ",", "as", "well", "as", "the", "imposition", "of", "sanctions", "on", "the", "company", "by", "both", "countries", "."], "sentence-detokenized": "The incident strained US-Japan relations and led to the arrest and prosecution of two senior executives, as well as the imposition of sanctions on the company by both countries.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 24], [24, 25], [25, 30], [31, 40], [41, 44], [45, 48], [49, 51], [52, 55], [56, 62], [63, 66], [67, 78], [79, 81], [82, 85], [86, 92], [93, 103], [103, 104], [105, 107], [108, 112], [113, 115], [116, 119], [120, 130], [131, 133], [134, 143], [144, 146], [147, 150], [151, 158], [159, 161], [162, 166], [167, 176], [176, 177]]}
{"doc_key": "ai-test-248", "ner": [[8, 9, "algorithm"], [12, 15, "field"], [23, 23, "misc"], [36, 36, "misc"], [40, 41, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 9, 12, 15, "type-of", "", false, false], [23, 23, 12, 15, "part-of", "", true, false], [36, 36, 12, 15, "part-of", "", true, false], [40, 41, 12, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["If", "the", "modelling", "is", "done", "by", "an", "artificial", "neural", "network", "or", "other", "form", "of", "machine", "learning", ",", "the", "optimisation", "of", "parameters", "is", "called", "training", ",", "while", "the", "optimisation", "of", "the", "hyperparameters", "of", "the", "model", "is", "called", "tuning", "and", "is", "often", "used", "cross-validation", "."], "sentence-detokenized": "If the modelling is done by an artificial neural network or other form of machine learning, the optimisation of parameters is called training, while the optimisation of the hyperparameters of the model is called tuning and is often used cross-validation.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 30], [31, 41], [42, 48], [49, 56], [57, 59], [60, 65], [66, 70], [71, 73], [74, 81], [82, 90], [90, 91], [92, 95], [96, 108], [109, 111], [112, 122], [123, 125], [126, 132], [133, 141], [141, 142], [143, 148], [149, 152], [153, 165], [166, 168], [169, 172], [173, 188], [189, 191], [192, 195], [196, 201], [202, 204], [205, 211], [212, 218], [219, 222], [223, 225], [226, 231], [232, 236], [237, 253], [253, 254]]}
{"doc_key": "ai-test-249", "ner": [[7, 7, "country"], [9, 9, "country"], [12, 12, "country"], [20, 21, "organisation"], [16, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 21, 16, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Localised", "versions", "of", "the", "site", "in", "the", "UK", ",", "India", ",", "and", "Australia", "were", "discontinued", "following", "Fandango", "'s", "acquisition", "of", "Rotten", "Tomatoes", "."], "sentence-detokenized": "Localised versions of the site in the UK, India, and Australia were discontinued following Fandango's acquisition of Rotten Tomatoes.", "token2charspan": [[0, 9], [10, 18], [19, 21], [22, 25], [26, 30], [31, 33], [34, 37], [38, 40], [40, 41], [42, 47], [47, 48], [49, 52], [53, 62], [63, 67], [68, 80], [81, 90], [91, 99], [99, 101], [102, 113], [114, 116], [117, 123], [124, 132], [132, 133]]}
{"doc_key": "ai-test-250", "ner": [[13, 13, "metrics"], [24, 25, "task"]], "ner_mapping_to_source": [1, 2], "relations": [[13, 13, 24, 25, "related-to", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["The", "NER", "model", "is", "one", "of", "a", "number", "of", "methods", "to", "determine", "the", "accuracy", "of", "live", "subtitling", "in", "television", "broadcasts", "and", "events", "produced", "with", "speech", "recognition", "."], "sentence-detokenized": "The NER model is one of a number of methods to determine the accuracy of live subtitling in television broadcasts and events produced with speech recognition.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 25], [26, 32], [33, 35], [36, 43], [44, 46], [47, 56], [57, 60], [61, 69], [70, 72], [73, 77], [78, 88], [89, 91], [92, 102], [103, 113], [114, 117], [118, 124], [125, 133], [134, 138], [139, 145], [146, 157], [157, 158]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [4, 7, "university"], [9, 11, "university"], [13, 13, "location"], [16, 20, "university"], [22, 24, "university"], [26, 26, "location"], [29, 35, "university"], [37, 39, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 7, "physical", "", false, false], [0, 0, 4, 7, "role", "", false, false], [0, 0, 9, 11, "physical", "", false, false], [0, 0, 9, 11, "role", "", false, false], [0, 0, 16, 20, "physical", "", false, false], [0, 0, 16, 20, "role", "", false, false], [0, 0, 22, 24, "physical", "", false, false], [0, 0, 22, 24, "role", "", false, false], [0, 0, 29, 35, "physical", "", false, false], [0, 0, 29, 35, "role", "", false, false], [9, 11, 13, 13, "physical", "", false, false], [16, 20, 26, 26, "physical", "", false, false], [22, 24, 26, 26, "physical", "", false, false], [29, 35, 37, 39, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "has", "taught", "at", "the", "University", "of", "Cambridge", ",", "the", "Hebrew", "University", "in", "Jerusalem", ",", "the", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "and", "the", "\u00c9cole", "Polytechnique", "in", "Paris", ",", "and", "the", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "City", "."], "sentence-detokenized": "Atran has taught at the University of Cambridge, the Hebrew University in Jerusalem, the \u00c9cole pratique des hautes \u00e9tudes and the \u00c9cole Polytechnique in Paris, and the John Jay College of Criminal Justice in New York City.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 47], [47, 48], [49, 52], [53, 59], [60, 70], [71, 73], [74, 83], [83, 84], [85, 88], [89, 94], [95, 103], [104, 107], [108, 114], [115, 121], [122, 125], [126, 129], [130, 135], [136, 149], [150, 152], [153, 158], [158, 159], [160, 163], [164, 167], [168, 172], [173, 176], [177, 184], [185, 187], [188, 196], [197, 204], [205, 207], [208, 211], [212, 216], [217, 221], [221, 222]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [6, 9, "task"], [13, 14, "researcher"], [16, 16, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 9, "origin", "", false, false], [0, 0, 6, 9, "related-to", "", false, false], [6, 9, 16, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "was", "an", "early", "computer", "programme", "for", "understanding", "natural", "language", ",", "developed", "by", "Terry", "Winograd", "at", "MIT", "in", "1968-", "1970"], "sentence-detokenized": "SHRDLU was an early computer programme for understanding natural language, developed by Terry Winograd at MIT in 1968-1970", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 19], [20, 28], [29, 38], [39, 42], [43, 56], [57, 64], [65, 73], [73, 74], [75, 84], [85, 87], [88, 93], [94, 102], [103, 105], [106, 109], [110, 112], [113, 118], [118, 122]]}
{"doc_key": "ai-test-253", "ner": [[3, 3, "misc"], [5, 6, "field"], [9, 13, "university"], [15, 15, "location"], [17, 17, "country"], [26, 29, "university"], [32, 32, "misc"], [34, 37, "field"], [41, 42, "university"], [46, 46, "misc"], [48, 49, "field"], [54, 54, "misc"], [62, 66, "university"], [70, 72, "field"], [76, 77, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[3, 3, 5, 6, "topic", "", false, false], [3, 3, 9, 13, "origin", "", false, false], [9, 13, 15, 15, "physical", "", false, false], [9, 13, 26, 29, "role", "affiliated_with", false, false], [15, 15, 17, 17, "physical", "", false, false], [32, 32, 34, 37, "topic", "", false, false], [32, 32, 41, 42, "origin", "", false, false], [46, 46, 48, 49, "topic", "", false, false], [54, 54, 62, 66, "origin", "", false, false], [54, 54, 70, 72, "topic", "", false, false], [76, 77, 62, 66, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["He", "obtained", "a", "B.E.", "in", "electrical", "engineering", "from", "the", "B.M.S", ".", "College", "of", "Engineering", "in", "Bangalore", ",", "India", "in", "1982", ",", "when", "it", "was", "affiliated", "to", "the", "University", "of", "Bangalore", ",", "an", "M.S.", "in", "electrical", "and", "computer", "engineering", "in", "1984", "from", "Drexel", "University", ",", "and", "an", "M.S.", "in", "computer", "science", "in", "1989", "and", "a", "Ph.D.", "in", "1990", ",", "respectively", ",", "from", "the", "University", "of", "Wisconsin", "-", "Madison", ",", "where", "he", "studied", "Artificial", "Intelligence", "and", "worked", "with", "Leonard", "Uhr", "."], "sentence-detokenized": "He obtained a B.E. in electrical engineering from the B.M.S. College of Engineering in Bangalore, India in 1982, when it was affiliated to the University of Bangalore, an M.S. in electrical and computer engineering in 1984 from Drexel University, and an M.S. in computer science in 1989 and a Ph.D. in 1990, respectively, from the University of Wisconsin-Madison, where he studied Artificial Intelligence and worked with Leonard Uhr.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 18], [19, 21], [22, 32], [33, 44], [45, 49], [50, 53], [54, 59], [59, 60], [61, 68], [69, 71], [72, 83], [84, 86], [87, 96], [96, 97], [98, 103], [104, 106], [107, 111], [111, 112], [113, 117], [118, 120], [121, 124], [125, 135], [136, 138], [139, 142], [143, 153], [154, 156], [157, 166], [166, 167], [168, 170], [171, 175], [176, 178], [179, 189], [190, 193], [194, 202], [203, 214], [215, 217], [218, 222], [223, 227], [228, 234], [235, 245], [245, 246], [247, 250], [251, 253], [254, 258], [259, 261], [262, 270], [271, 278], [279, 281], [282, 286], [287, 290], [291, 292], [293, 298], [299, 301], [302, 306], [306, 307], [308, 320], [320, 321], [322, 326], [327, 330], [331, 341], [342, 344], [345, 354], [354, 355], [355, 362], [362, 363], [364, 369], [370, 372], [373, 380], [381, 391], [392, 404], [405, 408], [409, 415], [416, 420], [421, 428], [429, 432], [432, 433]]}
{"doc_key": "ai-test-254", "ner": [[6, 8, "metrics"], [10, 10, "metrics"], [19, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "usually", "measured", "by", "the", "word", "error", "rate", "(", "WER", ")", ",", "while", "speed", "is", "measured", "by", "the", "real", "time", "factor", "."], "sentence-detokenized": "Accuracy is usually measured by the word error rate (WER), while speed is measured by the real time factor.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 28], [29, 31], [32, 35], [36, 40], [41, 46], [47, 51], [52, 53], [53, 56], [56, 57], [57, 58], [59, 64], [65, 70], [71, 73], [74, 82], [83, 85], [86, 89], [90, 94], [95, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [8, 8, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 8, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", ",", "Terry", "Winograd", "developed", "an", "early", "natural", "language", "processing", "machine", "capable", "of", "interpreting", "naturally", "written", "commands", "within", "a", "simple", "rule", "-", "governed", "environment", "."], "sentence-detokenized": "In 1971, Terry Winograd developed an early natural language processing machine capable of interpreting naturally written commands within a simple rule-governed environment.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 33], [34, 36], [37, 42], [43, 50], [51, 59], [60, 70], [71, 78], [79, 86], [87, 89], [90, 102], [103, 112], [113, 120], [121, 129], [130, 136], [137, 138], [139, 145], [146, 150], [150, 151], [151, 159], [160, 171], [171, 172]]}
{"doc_key": "ai-test-256", "ner": [[1, 2, "field"], [4, 5, "researcher"], [7, 10, "researcher"], [13, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 4, 5, "related-to", "", false, false], [1, 2, 7, 10, "related-to", "", false, false], [1, 2, 13, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "artificial", "intelligence", ",", "Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", ",", "and", "Allen", "Newell", "are", "prominent", "."], "sentence-detokenized": "In artificial intelligence, Marvin Minsky, Herbert A. Simon, and Allen Newell are prominent.", "token2charspan": [[0, 2], [3, 13], [14, 26], [26, 27], [28, 34], [35, 41], [41, 42], [43, 50], [51, 52], [52, 53], [54, 59], [59, 60], [61, 64], [65, 70], [71, 77], [78, 81], [82, 91], [91, 92]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [31, 32, "field"], [34, 35, "field"], [38, 39, "field"], [48, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[31, 32, 9, 10, "origin", "", true, false], [31, 32, 9, 10, "part-of", "", false, false], [31, 32, 38, 39, "compare", "", false, false], [34, 35, 9, 10, "origin", "", true, false], [34, 35, 9, 10, "part-of", "", false, false], [34, 35, 38, 39, "compare", "", false, false], [38, 39, 9, 10, "origin", "", true, false], [38, 39, 9, 10, "part-of", "", false, false], [38, 39, 48, 51, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "the", "second", "half", "of", "the", "20th", "century", ",", "electrical", "engineering", "split", "into", "several", "disciplines", "that", "specialised", "in", "the", "design", "and", "analysis", "of", "systems", "that", "manipulate", "physical", "signals", ";", "examples", "include", "electrical", "engineering", "and", "computer", "engineering", ";", "while", "design", "engineering", "developed", "to", "deal", "with", "the", "functional", "design", "of", "user", "-", "machine", "interfaces", "."], "sentence-detokenized": "In the second half of the 20th century, electrical engineering split into several disciplines that specialised in the design and analysis of systems that manipulate physical signals; examples include electrical engineering and computer engineering; while design engineering developed to deal with the functional design of user-machine interfaces.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 30], [31, 38], [38, 39], [40, 50], [51, 62], [63, 68], [69, 73], [74, 81], [82, 93], [94, 98], [99, 110], [111, 113], [114, 117], [118, 124], [125, 128], [129, 137], [138, 140], [141, 148], [149, 153], [154, 164], [165, 173], [174, 181], [181, 182], [183, 191], [192, 199], [200, 210], [211, 222], [223, 226], [227, 235], [236, 247], [247, 248], [249, 254], [255, 261], [262, 273], [274, 283], [284, 286], [287, 291], [292, 296], [297, 300], [301, 311], [312, 318], [319, 321], [322, 326], [326, 327], [327, 334], [335, 345], [345, 346]]}
{"doc_key": "ai-test-258", "ner": [[5, 5, "metrics"], [7, 8, "metrics"], [10, 10, "metrics"], [44, 46, "metrics"], [53, 55, "metrics"], [59, 65, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 10, 7, 8, "named", "", false, false], [44, 46, 53, 55, "named", "", false, false], [53, 55, 59, 65, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Perhaps", "the", "simplest", "statistic", "is", "accuracy", "or", "Fraction", "Correct", "(", "FC", ")", ",", "which", "measures", "the", "fraction", "of", "all", "instances", "classified", "correctly", ";", "it", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "Total", "population", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Perhaps the simplest statistic is accuracy or Fraction Correct (FC), which measures the fraction of all instances classified correctly; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN) / Total population = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 30], [31, 33], [34, 42], [43, 45], [46, 54], [55, 62], [63, 64], [64, 66], [66, 67], [67, 68], [69, 74], [75, 83], [84, 87], [88, 96], [97, 99], [100, 103], [104, 113], [114, 124], [125, 134], [134, 135], [136, 138], [139, 141], [142, 145], [146, 151], [152, 154], [155, 158], [159, 165], [166, 168], [169, 176], [177, 192], [193, 195], [196, 199], [200, 205], [206, 212], [213, 215], [216, 223], [224, 226], [227, 236], [237, 252], [252, 253], [254, 255], [255, 257], [258, 259], [260, 262], [262, 263], [264, 265], [266, 271], [272, 282], [283, 284], [285, 286], [286, 288], [289, 290], [291, 293], [293, 294], [295, 296], [297, 298], [298, 300], [301, 302], [303, 305], [306, 307], [308, 310], [311, 312], [313, 315], [315, 316], [316, 317]]}
{"doc_key": "ai-test-259", "ner": [[16, 23, "conference"], [25, 27, "conference"], [32, 32, "location"], [36, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 23, 32, 32, "physical", "", false, false], [25, 27, 16, 23, "named", "", false, false], [36, 38, 16, 23, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "academic", "community", ",", "the", "main", "forums", "for", "research", "began", "in", "1995", ",", "when", "the", "first", "international", "conference", "Data", "Mining", "and", "Knowledge", "Discovery", "(", "KDD", "-", "95", ")", "was", "launched", "in", "Montreal", "under", "the", "auspices", "of", "the", "AAAI", "."], "sentence-detokenized": "In the academic community, the main forums for research began in 1995, when the first international conference Data Mining and Knowledge Discovery (KDD-95) was launched in Montreal under the auspices of the AAAI.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 25], [25, 26], [27, 30], [31, 35], [36, 42], [43, 46], [47, 55], [56, 61], [62, 64], [65, 69], [69, 70], [71, 75], [76, 79], [80, 85], [86, 99], [100, 110], [111, 115], [116, 122], [123, 126], [127, 136], [137, 146], [147, 148], [148, 151], [151, 152], [152, 154], [154, 155], [156, 159], [160, 168], [169, 171], [172, 180], [181, 186], [187, 190], [191, 199], [200, 202], [203, 206], [207, 211], [211, 212]]}
{"doc_key": "ai-test-260", "ner": [[9, 10, "field"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "approach", ",", "models", "are", "developed", "using", "various", "data", "mining", "and", "machine", "-", "learning", "algorithms", "to", "predict", "users", "'", "ratings", "of", "unrated", "items", "."], "sentence-detokenized": "In this approach, models are developed using various data mining and machine-learning algorithms to predict users' ratings of unrated items.", "token2charspan": [[0, 2], [3, 7], [8, 16], [16, 17], [18, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 57], [58, 64], [65, 68], [69, 76], [76, 77], [77, 85], [86, 96], [97, 99], [100, 107], [108, 113], [113, 114], [115, 122], [123, 125], [126, 133], [134, 139], [139, 140]]}
{"doc_key": "ai-test-261", "ner": [[16, 17, "algorithm"], [19, 20, "algorithm"], [24, 25, "misc"], [31, 32, "metrics"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[16, 17, 19, 20, "usage", "", false, false], [19, 20, 31, 32, "usage", "", false, false], [31, 32, 24, 25, "type-of", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["In", "light", "of", "the", "above", "discussion", ",", "we", "see", "that", "the", "SVM", "technique", "is", "equivalent", "to", "empirical", "risk", "with", "Tikhonov", "regularisation", ",", "where", "the", "loss", "function", "in", "this", "case", "is", "the", "hinge", "loss"], "sentence-detokenized": "In light of the above discussion, we see that the SVM technique is equivalent to empirical risk with Tikhonov regularisation, where the loss function in this case is the hinge loss", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 15], [16, 21], [22, 32], [32, 33], [34, 36], [37, 40], [41, 45], [46, 49], [50, 53], [54, 63], [64, 66], [67, 77], [78, 80], [81, 90], [91, 95], [96, 100], [101, 109], [110, 124], [124, 125], [126, 131], [132, 135], [136, 140], [141, 149], [150, 152], [153, 157], [158, 162], [163, 165], [166, 169], [170, 175], [176, 180]]}
{"doc_key": "ai-test-262", "ner": [[6, 7, "person"], [10, 11, "person"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "2015", "edition", "was", "presented", "by", "Molly", "McGrath", ",", "with", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "as", "commentators", "."], "sentence-detokenized": "The 2015 edition was presented by Molly McGrath, with Chris Rose and former UFC fighter Kenny Florian as commentators.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 30], [31, 33], [34, 39], [40, 47], [47, 48], [49, 53], [54, 59], [60, 64], [65, 68], [69, 75], [76, 79], [80, 87], [88, 93], [94, 101], [102, 104], [105, 117], [117, 118]]}
{"doc_key": "ai-test-263", "ner": [[3, 5, "product"], [9, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [18, 18, "researcher"], [21, 21, "researcher"], [27, 27, "researcher"], [29, 32, "task"], [34, 34, "product"], [36, 37, "researcher"], [39, 40, "task"], [43, 45, "researcher"], [48, 49, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[3, 5, 9, 11, "origin", "", false, false], [3, 5, 13, 14, "origin", "", false, false], [3, 5, 16, 17, "origin", "", false, false], [3, 5, 18, 18, "origin", "", false, false], [13, 14, 36, 37, "named", "same", false, false], [16, 17, 21, 21, "named", "same", false, false], [16, 17, 27, 27, "named", "same", false, false], [29, 32, 34, 34, "related-to", "", false, false], [34, 34, 27, 27, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["A", "subset", "called", "Micro", "-", "Planner", "was", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "Sussman", ",", "and", "Winograd", "1971", "and", "was", "used", "in", "Winograd", "'s", "natural", "-", "language", "comprehension", "programme", "SHRDLU", ",", "Eugene", "Charniak", "'s", "story", "comprehension", "work", ",", "Thorne", "McCarty", "'s", "work", "on", "legal", "reasoning", ",", "and", "some", "other", "projects", "."], "sentence-detokenized": "A subset called Micro-Planner was implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd Sussman, and Winograd 1971 and was used in Winograd's natural-language comprehension programme SHRDLU, Eugene Charniak's story comprehension work, Thorne McCarty's work on legal reasoning, and some other projects.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [21, 22], [22, 29], [30, 33], [34, 45], [46, 48], [49, 55], [56, 59], [60, 67], [67, 68], [69, 75], [76, 84], [85, 88], [89, 94], [95, 103], [104, 111], [111, 112], [113, 116], [117, 125], [126, 130], [131, 134], [135, 138], [139, 143], [144, 146], [147, 155], [155, 157], [158, 165], [165, 166], [166, 174], [175, 188], [189, 198], [199, 205], [205, 206], [207, 213], [214, 222], [222, 224], [225, 230], [231, 244], [245, 249], [249, 250], [251, 257], [258, 265], [265, 267], [268, 272], [273, 275], [276, 281], [282, 291], [291, 292], [293, 296], [297, 301], [302, 307], [308, 316], [316, 317]]}
{"doc_key": "ai-test-264", "ner": [[0, 1, "product"], [11, 12, "product"], [15, 18, "task"], [20, 21, "task"], [23, 25, "task"], [27, 28, "task"], [31, 31, "task"], [34, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 0, 1, "usage", "", true, false], [15, 18, 11, 12, "part-of", "", true, false], [20, 21, 11, 12, "part-of", "", true, false], [23, 25, 11, 12, "part-of", "", true, false], [27, 28, 11, 12, "part-of", "", true, false], [31, 31, 11, 12, "part-of", "", true, false], [34, 37, 11, 12, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "has", "been", "used", "for", "a", "number", "of", "purposes", "in", "information", "systems", ",", "including", "word", "-", "phrase", "disambiguation", ",", "information", "retrieval", ",", "automatic", "text", "classification", ",", "automatic", "summaries", ",", "automatic", "translation", "and", "even", "automatic", "crossword", "puzzle", "generation", "."], "sentence-detokenized": "WordNet has been used for a number of purposes in information systems, including word-phrase disambiguation, information retrieval, automatic text classification, automatic summaries, automatic translation and even automatic crossword puzzle generation.", "token2charspan": [[0, 4], [4, 7], [8, 11], [12, 16], [17, 21], [22, 25], [26, 27], [28, 34], [35, 37], [38, 46], [47, 49], [50, 61], [62, 69], [69, 70], [71, 80], [81, 85], [85, 86], [86, 92], [93, 107], [107, 108], [109, 120], [121, 130], [130, 131], [132, 141], [142, 146], [147, 161], [161, 162], [163, 172], [173, 182], [182, 183], [184, 193], [194, 205], [206, 209], [210, 214], [215, 224], [225, 234], [235, 241], [242, 252], [252, 253]]}
{"doc_key": "ai-test-265", "ner": [[0, 0, "researcher"], [7, 7, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 7, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "was", "appointed", "a", "Fellow", "of", "the", "IEEE", "in", "1996", "."], "sentence-detokenized": "Keutzer was appointed a Fellow of the IEEE in 1996.", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 23], [24, 30], [31, 33], [34, 37], [38, 42], [43, 45], [46, 50], [50, 51]]}
{"doc_key": "ai-test-266", "ner": [[8, 10, "algorithm"], [61, 63, "misc"], [73, 74, "algorithm"], [76, 77, "algorithm"], [79, 80, "algorithm"], [82, 83, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[73, 74, 61, 63, "type-of", "", false, false], [76, 77, 61, 63, "type-of", "", false, false], [79, 80, 61, 63, "type-of", "", false, false], [82, 83, 61, 63, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "commonly", "used", "type", "of", "composition", "is", "the", "non-linear", "weighted", "sum", ",", "where", "maths", "f", "(", "x", ")", "=", "K", "(", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "/", "mathematics", "left", "(", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "/", "mathematics", "right", ")", ",", "where", "maths", "K", "/", "mathematics", "(", "commonly", "called", "activation", "function", ")", "is", "a", "predefined", "function", ",", "such", "as", "the", "hyperbolic", "tangent", ",", "sigmoid", "function", ",", "softmax", "function", "or", "rectification", "function", "."], "sentence-detokenized": "A commonly used type of composition is the non-linear weighted sum, where maths f (x) = K(sum _ i w _ i g _ i (x)/mathematics left (sum _ i w _ i g _ i (x)/mathematics right), where maths K / mathematics (commonly called activation function) is a predefined function, such as the hyperbolic tangent, sigmoid function, softmax function or rectification function.", "token2charspan": [[0, 1], [2, 10], [11, 15], [16, 20], [21, 23], [24, 35], [36, 38], [39, 42], [43, 53], [54, 62], [63, 66], [66, 67], [68, 73], [74, 79], [80, 81], [82, 83], [83, 84], [84, 85], [86, 87], [88, 89], [89, 90], [90, 93], [94, 95], [96, 97], [98, 99], [100, 101], [102, 103], [104, 105], [106, 107], [108, 109], [110, 111], [111, 112], [112, 113], [113, 114], [114, 125], [126, 130], [131, 132], [132, 135], [136, 137], [138, 139], [140, 141], [142, 143], [144, 145], [146, 147], [148, 149], [150, 151], [152, 153], [153, 154], [154, 155], [155, 156], [156, 167], [168, 173], [173, 174], [174, 175], [176, 181], [182, 187], [188, 189], [190, 191], [192, 203], [204, 205], [205, 213], [214, 220], [221, 231], [232, 240], [240, 241], [242, 244], [245, 246], [247, 257], [258, 266], [266, 267], [268, 272], [273, 275], [276, 279], [280, 290], [291, 298], [298, 299], [300, 307], [308, 316], [316, 317], [318, 325], [326, 334], [335, 337], [338, 351], [352, 360], [360, 361]]}
{"doc_key": "ai-test-267", "ner": [[3, 8, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "film", "Westworld", ",", "female", "robots", "actually", "have", "sexual", "intercourse", "with", "human", "men", "as", "part", "of", "the", "imaginary", "holiday", "world", "that", "human", "customers", "pay", "for", "."], "sentence-detokenized": "In the film Westworld, female robots actually have sexual intercourse with human men as part of the imaginary holiday world that human customers pay for.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 21], [21, 22], [23, 29], [30, 36], [37, 45], [46, 50], [51, 57], [58, 69], [70, 74], [75, 80], [81, 84], [85, 87], [88, 92], [93, 95], [96, 99], [100, 109], [110, 117], [118, 123], [124, 128], [129, 134], [135, 144], [145, 148], [149, 152], [152, 153]]}
{"doc_key": "ai-test-268", "ner": [[6, 7, "task"], [21, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 21, 26, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Usually", ",", "the", "process", "starts", "with", "terminology", "extraction", "and", "concepts", "or", "noun", "phrases", "from", "plain", "text", "using", "linguistic", "processors", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "phrase", "chunking", "."], "sentence-detokenized": "Usually, the process starts with terminology extraction and concepts or noun phrases from plain text using linguistic processors such as part-of-speech tagging and phrase chunking.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 20], [21, 27], [28, 32], [33, 44], [45, 55], [56, 59], [60, 68], [69, 71], [72, 76], [77, 84], [85, 89], [90, 95], [96, 100], [101, 106], [107, 117], [118, 128], [129, 133], [134, 136], [137, 141], [141, 142], [142, 144], [144, 145], [145, 151], [152, 159], [160, 163], [164, 170], [171, 179], [179, 180]]}
{"doc_key": "ai-test-269", "ner": [[18, 19, "task"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "demonstrated", "its", "performance", "on", "a", "number", "of", "problems", "of", "interest", "to", "the", "machine", "learning", "community", ",", "including", "handwriting", "recognition", "."], "sentence-detokenized": "They demonstrated its performance on a number of problems of interest to the machine learning community, including handwriting recognition.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 33], [34, 36], [37, 38], [39, 45], [46, 48], [49, 57], [58, 60], [61, 69], [70, 72], [73, 76], [77, 84], [85, 93], [94, 103], [103, 104], [105, 114], [115, 126], [127, 138], [138, 139]]}
{"doc_key": "ai-test-270", "ner": [[1, 3, "university"], [5, 5, "researcher"], [11, 12, "researcher"], [18, 18, "product"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 1, 3, "physical", "", false, false], [5, 5, 1, 3, "role", "", false, false], [18, 18, 11, 12, "origin", "", false, false], [18, 18, 22, 23, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "studying", "at", "Stanford", ",", "Scheinman", "received", "a", "scholarship", "sponsored", "by", "George", "Devol", ",", "the", "inventor", "of", "the", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "While studying at Stanford, Scheinman received a scholarship sponsored by George Devol, the inventor of the Unimate, the first industrial robot.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [26, 27], [28, 37], [38, 46], [47, 48], [49, 60], [61, 70], [71, 73], [74, 80], [81, 86], [86, 87], [88, 91], [92, 100], [101, 103], [104, 107], [108, 115], [115, 116], [117, 120], [121, 126], [127, 137], [138, 143], [143, 144]]}
{"doc_key": "ai-test-271", "ner": [[5, 6, "task"], [9, 12, "metrics"], [14, 14, "metrics"], [23, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 9, 12, "usage", "", true, false], [14, 14, 9, 12, "named", "", false, false], [23, 25, 9, 12, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Although", "originally", "used", "to", "evaluate", "machine", "translation", ",", "the", "Bilingual", "Evaluation", "Support", "Unit", "(", "BLEU", ")", "has", "also", "been", "successfully", "used", "to", "evaluate", "paraphrase", "generation", "models", "."], "sentence-detokenized": "Although originally used to evaluate machine translation, the Bilingual Evaluation Support Unit (BLEU) has also been successfully used to evaluate paraphrase generation models.", "token2charspan": [[0, 8], [9, 19], [20, 24], [25, 27], [28, 36], [37, 44], [45, 56], [56, 57], [58, 61], [62, 71], [72, 82], [83, 90], [91, 95], [96, 97], [97, 101], [101, 102], [103, 106], [107, 111], [112, 116], [117, 129], [130, 134], [135, 137], [138, 146], [147, 157], [158, 168], [169, 175], [175, 176]]}
{"doc_key": "ai-test-272", "ner": [[0, 0, "organisation"], [6, 8, "organisation"], [10, 10, "organisation"], [14, 21, "product"], [17, 17, "country"], [19, 19, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 8, "role", "licenses_to", false, false], [0, 0, 10, 10, "role", "licenses_to", false, false], [6, 8, 17, 17, "physical", "", false, false], [10, 10, 19, 19, "physical", "", false, false], [14, 21, 6, 8, "artifact", "produces", false, false], [14, 21, 10, 10, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "later", "licensed", "its", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "which", "manufactured", "the", "Unimates", "in", "Japan", "and", "England", ",", "respectively", "."], "sentence-detokenized": "Unimation later licensed its technology to Kawasaki Heavy Industries and GKN, which manufactured the Unimates in Japan and England, respectively.", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 57], [58, 68], [69, 72], [73, 76], [76, 77], [78, 83], [84, 96], [97, 100], [101, 109], [110, 112], [113, 118], [119, 122], [123, 130], [130, 131], [132, 144], [144, 145]]}
{"doc_key": "ai-test-273", "ner": [[18, 20, "conference"], [35, 36, "field"], [54, 58, "field"], [60, 60, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[35, 36, 54, 58, "compare", "", false, false], [60, 60, 54, 58, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "confusion", "between", "these", "two", "research", "communities", "(", "which", "often", "have", "separate", "conferences", "and", "journals", ",", "ECML", "PKDD", "being", "an", "important", "exception", ")", "stems", "from", "the", "basic", "assumptions", "they", "work", "with", ":", "in", "machine", "learning", ",", "performance", "is", "usually", "evaluated", "with", "respect", "to", "the", "ability", "to", "reproduce", "known", "knowledge", ",", "while", "in", "knowledge", "discovery", "and", "data", "mining", "(", "KDD", ")", ",", "the", "main", "task", "is", "the", "discovery", "of", "previously", "unknown", "knowledge", "."], "sentence-detokenized": "Much of the confusion between these two research communities (which often have separate conferences and journals, ECML PKDD being an important exception) stems from the basic assumptions they work with: in machine learning, performance is usually evaluated with respect to the ability to reproduce known knowledge, while in knowledge discovery and data mining (KDD), the main task is the discovery of previously unknown knowledge.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 29], [30, 35], [36, 39], [40, 48], [49, 60], [61, 62], [62, 67], [68, 73], [74, 78], [79, 87], [88, 99], [100, 103], [104, 112], [112, 113], [114, 118], [119, 123], [124, 129], [130, 132], [133, 142], [143, 152], [152, 153], [154, 159], [160, 164], [165, 168], [169, 174], [175, 186], [187, 191], [192, 196], [197, 201], [201, 202], [203, 205], [206, 213], [214, 222], [222, 223], [224, 235], [236, 238], [239, 246], [247, 256], [257, 261], [262, 269], [270, 272], [273, 276], [277, 284], [285, 287], [288, 297], [298, 303], [304, 313], [313, 314], [315, 320], [321, 323], [324, 333], [334, 343], [344, 347], [348, 352], [353, 359], [360, 361], [361, 364], [364, 365], [365, 366], [367, 370], [371, 375], [376, 380], [381, 383], [384, 387], [388, 397], [398, 400], [401, 411], [412, 419], [420, 429], [429, 430]]}
{"doc_key": "ai-test-274", "ner": [[0, 0, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hidden", "Markov", "models", "form", "the", "basis", "of", "most", "modern", "automatic", "speech", "recognition", "systems", "."], "sentence-detokenized": "Hidden Markov models form the basis of most modern automatic speech recognition systems.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 25], [26, 29], [30, 35], [36, 38], [39, 43], [44, 50], [51, 60], [61, 67], [68, 79], [80, 87], [87, 88]]}
{"doc_key": "ai-test-275", "ner": [[4, 4, "location"], [6, 6, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 6, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": [",", "a", "company", "in", "Bangalore", ",", "India", ",", "specialising", "in", "online", "handwriting", "recognition", "software", "."], "sentence-detokenized": ", a company in Bangalore, India, specialising in online handwriting recognition software.", "token2charspan": [[0, 1], [2, 3], [4, 11], [12, 14], [15, 24], [24, 25], [26, 31], [31, 32], [33, 45], [46, 48], [49, 55], [56, 67], [68, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-276", "ner": [[22, 23, "misc"], [48, 50, "metrics"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Do", "repeated", "translations", "converge", "to", "a", "single", "expression", "in", "both", "languages", "?", "I.e.", "does", "the", "translation", "method", "exhibit", "stationarity", "or", "produce", "a", "canonical", "form", "?", "Does", "the", "translation", "become", "stationary", "without", "losing", "the", "original", "meaning", "?", "This", "metric", "has", "been", "criticised", "for", "not", "correlating", "well", "with", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "scores", "."], "sentence-detokenized": "Do repeated translations converge to a single expression in both languages? I.e. does the translation method exhibit stationarity or produce a canonical form? Does the translation become stationary without losing the original meaning? This metric has been criticised for not correlating well with BLEU (BiLingual Evaluation Understudy) scores.", "token2charspan": [[0, 2], [3, 11], [12, 24], [25, 33], [34, 36], [37, 38], [39, 45], [46, 56], [57, 59], [60, 64], [65, 74], [74, 75], [76, 80], [81, 85], [86, 89], [90, 101], [102, 108], [109, 116], [117, 129], [130, 132], [133, 140], [141, 142], [143, 152], [153, 157], [157, 158], [159, 163], [164, 167], [168, 179], [180, 186], [187, 197], [198, 205], [206, 212], [213, 216], [217, 225], [226, 233], [233, 234], [235, 239], [240, 246], [247, 250], [251, 255], [256, 266], [267, 270], [271, 274], [275, 286], [287, 291], [292, 296], [297, 301], [302, 303], [303, 312], [313, 323], [324, 334], [334, 335], [336, 342], [342, 343]]}
{"doc_key": "ai-test-277", "ner": [[6, 10, "organisation"], [13, 20, "organisation"], [22, 23, "university"], [26, 26, "university"], [29, 30, "field"], [33, 37, "organisation"], [40, 42, "organisation"], [51, 54, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[13, 20, 22, 23, "part-of", "", false, false], [26, 26, 29, 30, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "is", "a", "member", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", ",", "the", "Center", "for", "Advanced", "Study", "in", "the", "Behavioral", "Sciences", "at", "Stanford", "University", ",", "the", "MIT", "Center", "for", "Cognitive", "Science", ",", "the", "Canadian", "Institute", "for", "Advanced", "Research", ",", "the", "Canadian", "Psychological", "Association", ",", "and", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "in", "1998", "."], "sentence-detokenized": "He is a member of the American Association for Artificial Intelligence, the Center for Advanced Study in the Behavioral Sciences at Stanford University, the MIT Center for Cognitive Science, the Canadian Institute for Advanced Research, the Canadian Psychological Association, and was elected a Fellow of the Royal Society of Canada in 1998.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 42], [43, 46], [47, 57], [58, 70], [70, 71], [72, 75], [76, 82], [83, 86], [87, 95], [96, 101], [102, 104], [105, 108], [109, 119], [120, 128], [129, 131], [132, 140], [141, 151], [151, 152], [153, 156], [157, 160], [161, 167], [168, 171], [172, 181], [182, 189], [189, 190], [191, 194], [195, 203], [204, 213], [214, 217], [218, 226], [227, 235], [235, 236], [237, 240], [241, 249], [250, 263], [264, 275], [275, 276], [277, 280], [281, 284], [285, 292], [293, 294], [295, 301], [302, 304], [305, 308], [309, 314], [315, 322], [323, 325], [326, 332], [333, 335], [336, 340], [340, 341]]}
{"doc_key": "ai-test-278", "ner": [[0, 11, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [15, 17, "misc"], [19, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 11, 15, 17, "part-of", "", false, false], [0, 11, 19, 22, "part-of", "", false, false], [4, 5, 15, 17, "part-of", "", false, false], [4, 5, 19, 22, "part-of", "", false, false], [7, 8, 15, 17, "part-of", "", false, false], [7, 8, 19, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "-", "along", "with", "Yoshua", "Bengio", "and", "Yann", "LeCun", "-", "is", "called", "by", "some", "the", "Godfathers", "of", "AI", "and", "Godfathers", "of", "Deep", "Learning", "."], "sentence-detokenized": "Hinton - along with Yoshua Bengio and Yann LeCun - is called by some the Godfathers of AI and Godfathers of Deep Learning.", "token2charspan": [[0, 6], [7, 8], [9, 14], [15, 19], [20, 26], [27, 33], [34, 37], [38, 42], [43, 48], [49, 50], [51, 53], [54, 60], [61, 63], [64, 68], [69, 72], [73, 83], [84, 86], [87, 89], [90, 93], [94, 104], [105, 107], [108, 112], [113, 121], [121, 122]]}
{"doc_key": "ai-test-279", "ner": [[7, 7, "product"], [20, 20, "misc"], [22, 23, "misc"], [24, 24, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 7, 20, 20, "related-to", "", false, false], [7, 7, 22, 23, "related-to", "", false, false], [20, 20, 24, 24, "named", "same", false, false], [28, 29, 24, 24, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "lightweight", "open", "-", "source", "speech", "project", "eSpeak", ",", "which", "has", "its", "own", "approach", "to", "synthesis", ",", "has", "experimented", "with", "Mandarin", "and", "Cantonese", ".", "eSpeak", "was", "used", "by", "Google", "Translate", "from", "May", "2010-2010", "."], "sentence-detokenized": "The lightweight open-source speech project eSpeak, which has its own approach to synthesis, has experimented with Mandarin and Cantonese. eSpeak was used by Google Translate from May 2010-2010.", "token2charspan": [[0, 3], [4, 15], [16, 20], [20, 21], [21, 27], [28, 34], [35, 42], [43, 49], [49, 50], [51, 56], [57, 60], [61, 64], [65, 68], [69, 77], [78, 80], [81, 90], [90, 91], [92, 95], [96, 108], [109, 113], [114, 122], [123, 126], [127, 136], [136, 137], [138, 144], [145, 148], [149, 153], [154, 156], [157, 163], [164, 173], [174, 178], [179, 182], [183, 192], [192, 193]]}
{"doc_key": "ai-test-280", "ner": [[0, 2, "product"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 16, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Software", "Automatic", "Mouth", ",", "also", "released", "in", "1982", ",", "was", "the", "first", "commercial", "all", "-", "software", "speech", "synthesis", "programme", "."], "sentence-detokenized": "Software Automatic Mouth, also released in 1982, was the first commercial all-software speech synthesis programme.", "token2charspan": [[0, 8], [9, 18], [19, 24], [24, 25], [26, 30], [31, 39], [40, 42], [43, 47], [47, 48], [49, 52], [53, 56], [57, 62], [63, 73], [74, 77], [77, 78], [78, 86], [87, 93], [94, 103], [104, 113], [113, 114]]}
{"doc_key": "ai-test-281", "ner": [[4, 6, "metrics"], [8, 8, "metrics"], [11, 13, "metrics"], [15, 15, "metrics"], [18, 24, "metrics"], [30, 32, "metrics"], [34, 34, "metrics"], [37, 43, "metrics"], [47, 49, "metrics"], [51, 51, "metrics"], [56, 56, "metrics"], [58, 58, "metrics"], [61, 67, "metrics"], [72, 75, "metrics"], [77, 77, "metrics"], [80, 87, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[8, 8, 4, 6, "named", "", false, false], [11, 13, 4, 6, "named", "", false, false], [15, 15, 4, 6, "named", "", false, false], [18, 24, 4, 6, "named", "", false, false], [34, 34, 30, 32, "named", "", false, false], [37, 43, 30, 32, "named", "", false, false], [51, 51, 47, 49, "named", "", false, false], [56, 56, 47, 49, "named", "", false, false], [58, 58, 47, 49, "named", "", false, false], [61, 67, 47, 49, "named", "", false, false], [77, 77, 72, 75, "named", "", false, false], [80, 87, 72, 75, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["The", "column", "ratios", "are", "TRUE", "Positive", "Rate", "(", "TPR", ",", "also", "known", "as", "sensitivity", "or", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "supplemented", "by", "the", "FALSE", "Negative", "Rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "and", "TRUE", "Negative", "Rate", "(", "TNR", ",", "also", "known", "as", "specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "supplemented", "by", "the", "FALSE", "Positive", "Rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "The column ratios are TRUE Positive Rate (TPR, also known as sensitivity or recall) (TP / (TP + FN)), supplemented by the FALSE Negative Rate (FNR) (FN / (TP + FN)); and TRUE Negative Rate (TNR, also known as specificity, SPC) (TN / (TN + FP)), supplemented by the FALSE Positive Rate (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 21], [22, 26], [27, 35], [36, 40], [41, 42], [42, 45], [45, 46], [47, 51], [52, 57], [58, 60], [61, 72], [73, 75], [76, 82], [82, 83], [84, 85], [85, 87], [88, 89], [90, 91], [91, 93], [94, 95], [96, 98], [98, 99], [99, 100], [100, 101], [102, 114], [115, 117], [118, 121], [122, 127], [128, 136], [137, 141], [142, 143], [143, 146], [146, 147], [148, 149], [149, 151], [152, 153], [154, 155], [155, 157], [158, 159], [160, 162], [162, 163], [163, 164], [164, 165], [166, 169], [170, 174], [175, 183], [184, 188], [189, 190], [190, 193], [193, 194], [195, 199], [200, 205], [206, 208], [209, 220], [220, 221], [222, 225], [225, 226], [227, 228], [228, 230], [231, 232], [233, 234], [234, 236], [237, 238], [239, 241], [241, 242], [242, 243], [243, 244], [245, 257], [258, 260], [261, 264], [265, 270], [271, 279], [280, 284], [285, 286], [286, 289], [289, 290], [291, 292], [292, 294], [295, 296], [297, 298], [298, 300], [301, 302], [303, 305], [305, 306], [306, 307], [307, 308]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 16, 16, "role", "working_with", false, false], [2, 2, 16, 16, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "and", "Weber", "also", "worked", "together", "on", "many", "other", "robots", ",", "and", "their", "experience", "with", "the", "Kismet"], "sentence-detokenized": "Edsinger and Weber also worked together on many other robots, and their experience with the Kismet", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 30], [31, 39], [40, 42], [43, 47], [48, 53], [54, 60], [60, 61], [62, 65], [66, 71], [72, 82], [83, 87], [88, 91], [92, 98]]}
{"doc_key": "ai-test-283", "ner": [[10, 10, "programlang"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["R", "functionality", "accessible", "from", "various", "scripting", "languages", ",", "such", "as", "Python", ",", "are", "also", "available", "."], "sentence-detokenized": "R functionality accessible from various scripting languages, such as Python, are also available.", "token2charspan": [[0, 1], [2, 15], [16, 26], [27, 31], [32, 39], [40, 49], [50, 59], [59, 60], [61, 65], [66, 68], [69, 75], [75, 76], [77, 80], [81, 85], [86, 95], [95, 96]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "was", "one", "of", "the", "first", "robot", "languages", "and", "was", "used", "in", "Unimate", "robots", "."], "sentence-detokenized": "VAL was one of the first robot languages and was used in Unimate robots.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 24], [25, 30], [31, 40], [41, 44], [45, 48], [49, 53], [54, 56], [57, 64], [65, 71], [71, 72]]}
{"doc_key": "ai-test-285", "ner": [[10, 17, "conference"], [19, 19, "conference"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 17, 22, 22, "physical", "", false, false], [19, 19, 10, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["They", "first", "presented", "their", "database", "as", "a", "poster", "at", "the", "2009", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "in", "Florida", "."], "sentence-detokenized": "They first presented their database as a poster at the 2009 Conference on Computer Vision and Pattern Recognition (CVPR) in Florida.", "token2charspan": [[0, 4], [5, 10], [11, 20], [21, 26], [27, 35], [36, 38], [39, 40], [41, 47], [48, 50], [51, 54], [55, 59], [60, 70], [71, 73], [74, 82], [83, 89], [90, 93], [94, 101], [102, 113], [114, 115], [115, 119], [119, 120], [121, 123], [124, 131], [131, 132]]}
{"doc_key": "ai-test-286", "ner": [[0, 1, "misc"], [9, 10, "task"], [12, 13, "field"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 0, 1, "type-of", "", false, false], [12, 13, 0, 1, "type-of", "", false, false], [15, 16, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Categorisation", "tasks", "where", "no", "labels", "are", "provided", "are", "called", "unsupervised", "classification", ",", "unsupervised", "learning", ",", "cluster", "analysis", "."], "sentence-detokenized": "Categorisation tasks where no labels are provided are called unsupervised classification, unsupervised learning, cluster analysis.", "token2charspan": [[0, 14], [15, 20], [21, 26], [27, 29], [30, 36], [37, 40], [41, 49], [50, 53], [54, 60], [61, 73], [74, 88], [88, 89], [90, 102], [103, 111], [111, 112], [113, 120], [121, 129], [129, 130]]}
{"doc_key": "ai-test-287", "ner": [[2, 3, "task"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "should", "Object", "recognition", ",", "recognise", "and", "locate", "people", "and", "further", "emotion", "recognition", "."], "sentence-detokenized": "It should Object recognition, recognise and locate people and further emotion recognition.", "token2charspan": [[0, 2], [3, 9], [10, 16], [17, 28], [28, 29], [30, 39], [40, 43], [44, 50], [51, 57], [58, 61], [62, 69], [70, 77], [78, 89], [89, 90]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [8, 8, "misc"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "process", "is", "complex", "and", "involves", "coding", "and", "recall", "or", "retrieval", "."], "sentence-detokenized": "The process is complex and involves coding and recall or retrieval.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 26], [27, 35], [36, 42], [43, 46], [47, 53], [54, 56], [57, 66], [66, 67]]}
{"doc_key": "ai-test-289", "ner": [[9, 10, "product"], [17, 18, "product"], [35, 35, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 17, 18, "named", "", false, false], [9, 10, 35, 35, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "also", "called", "parallel", "robots", "or", "generalised", "Stewart", "platforms", "(", "in", "the", "case", "of", "the", "Stewart", "platform", ",", "the", "actuators", "are", "coupled", "both", "at", "the", "base", "and", "on", "the", "platform", ")", ",", "are", "articulated", "robots", "that", "use", "similar", "mechanisms", "to", "move", "either", "the", "robot", "on", "its", "base", "or", "one", "or", "more", "manipulator", "arms", "."], "sentence-detokenized": "These systems, also called parallel robots or generalised Stewart platforms (in the case of the Stewart platform, the actuators are coupled both at the base and on the platform), are articulated robots that use similar mechanisms to move either the robot on its base or one or more manipulator arms.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 26], [27, 35], [36, 42], [43, 45], [46, 57], [58, 65], [66, 75], [76, 77], [77, 79], [80, 83], [84, 88], [89, 91], [92, 95], [96, 103], [104, 112], [112, 113], [114, 117], [118, 127], [128, 131], [132, 139], [140, 144], [145, 147], [148, 151], [152, 156], [157, 160], [161, 163], [164, 167], [168, 176], [176, 177], [177, 178], [179, 182], [183, 194], [195, 201], [202, 206], [207, 210], [211, 218], [219, 229], [230, 232], [233, 237], [238, 244], [245, 248], [249, 254], [255, 257], [258, 261], [262, 266], [267, 269], [270, 273], [274, 276], [277, 281], [282, 293], [294, 298], [298, 299]]}
{"doc_key": "ai-test-290", "ner": [[0, 1, "field"], [4, 5, "field"], [12, 13, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 5, "part-of", "subfield", false, false], [0, 1, 12, 13, "compare", "", false, false], [12, 13, 18, 19, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "vision", "as", "a", "systems", "engineering", "discipline", "can", "be", "considered", "distinct", "from", "computer", "vision", ",", "a", "form", "of", "computer", "science", "."], "sentence-detokenized": "Machine vision as a systems engineering discipline can be considered distinct from computer vision, a form of computer science.", "token2charspan": [[0, 7], [8, 14], [15, 17], [18, 19], [20, 27], [28, 39], [40, 50], [51, 54], [55, 57], [58, 68], [69, 77], [78, 82], [83, 91], [92, 98], [98, 99], [100, 101], [102, 106], [107, 109], [110, 118], [119, 126], [126, 127]]}
{"doc_key": "ai-test-291", "ner": [[4, 5, "algorithm"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 9, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "activation", "function", "of", "LSTM", "gates", "is", "often", "the", "logistic", "sigmoid", "function", "."], "sentence-detokenized": "The activation function of LSTM gates is often the logistic sigmoid function.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 26], [27, 31], [32, 37], [38, 40], [41, 46], [47, 50], [51, 59], [60, 67], [68, 76], [76, 77]]}
{"doc_key": "ai-test-292", "ner": [[5, 6, "metrics"], [20, 23, "metrics"], [25, 25, "metrics"], [33, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 20, 23, "named", "", false, false], [5, 6, 33, 35, "named", "", false, false], [25, 25, 20, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "the", "(", "necessarily", "unique", ")", "efficient", "estimator", ",", "and", "thus", "also", "the", "minimum", "variance", "unbiased", "estimator", "(", "MVUE", ")", ",", "in", "addition", "to", "being", "the", "maximum", "likelihood", "estimator", "."], "sentence-detokenized": "In other words, the sample mean is the (necessarily unique) efficient estimator, and thus also the minimum variance unbiased estimator (MVUE), in addition to being the maximum likelihood estimator.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 38], [39, 40], [40, 51], [52, 58], [58, 59], [60, 69], [70, 79], [79, 80], [81, 84], [85, 89], [90, 94], [95, 98], [99, 106], [107, 115], [116, 124], [125, 134], [135, 136], [136, 140], [140, 141], [141, 142], [143, 145], [146, 154], [155, 157], [158, 163], [164, 167], [168, 175], [176, 186], [187, 196], [196, 197]]}
{"doc_key": "ai-test-293", "ner": [[2, 2, "academicjournal"], [6, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [22, 22, "product"], [25, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 22, 22, "topic", "", false, false], [2, 2, 25, 26, "topic", "", false, false], [6, 8, 2, 2, "role", "", false, false], [10, 11, 2, 2, "role", "", false, false], [13, 14, 2, 2, "role", "", false, false], [22, 22, 25, 26, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "2001", "Scientific", "American", "article", "by", "Berners", "-", "Lee", ",", "James", "Hendler", "and", "Ora", "Lassila", "describes", "an", "expected", "evolution", "of", "the", "existing", "Web", "towards", "a", "Semantic", "Web", "."], "sentence-detokenized": "The 2001 Scientific American article by Berners-Lee, James Hendler and Ora Lassila describes an expected evolution of the existing Web towards a Semantic Web.", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 28], [29, 36], [37, 39], [40, 47], [47, 48], [48, 51], [51, 52], [53, 58], [59, 66], [67, 70], [71, 74], [75, 82], [83, 92], [93, 95], [96, 104], [105, 114], [115, 117], [118, 121], [122, 130], [131, 134], [135, 142], [143, 144], [145, 153], [154, 157], [157, 158]]}
{"doc_key": "ai-test-294", "ner": [[0, 1, "misc"], [12, 13, "person"], [15, 15, "person"], [35, 35, "person"], [41, 42, "person"]], "ner_mapping_to_source": [0, 1, 2, 4, 5], "relations": [[12, 13, 0, 1, "role", "actor_in_work", false, false], [15, 15, 12, 13, "named", "", false, false], [15, 15, 12, 13, "origin", "", false, false], [41, 42, 15, 15, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 4], "sentence": ["Blade", "Runner", "used", "a", "number", "of", "then", "lesser", "-", "known", "actors", ":", "Sean", "Young", "plays", "Rachael", ",", "an", "experimental", "replicant", "implanted", "with", "Tyrell", "'s", "niece", "'s", "memories", ",", "making", "her", "believe", "she", "is", "human", ";", "Sammon", ",", "pp.", "92", "-", "93", "Nina", "Axelrod", "auditioned", "for", "the", "role", "."], "sentence-detokenized": "Blade Runner used a number of then lesser-known actors: Sean Young plays Rachael, an experimental replicant implanted with Tyrell's niece's memories, making her believe she is human; Sammon, pp. 92-93 Nina Axelrod auditioned for the role.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 19], [20, 26], [27, 29], [30, 34], [35, 41], [41, 42], [42, 47], [48, 54], [54, 55], [56, 60], [61, 66], [67, 72], [73, 80], [80, 81], [82, 84], [85, 97], [98, 107], [108, 117], [118, 122], [123, 129], [129, 131], [132, 137], [137, 139], [140, 148], [148, 149], [150, 156], [157, 160], [161, 168], [169, 172], [173, 175], [176, 181], [181, 182], [183, 189], [189, 190], [191, 194], [195, 197], [197, 198], [198, 200], [201, 205], [206, 213], [214, 224], [225, 228], [229, 232], [233, 237], [237, 238]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [13, 15, "university"], [23, 25, "product"], [27, 27, "product"], [43, 43, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 13, 15, "physical", "", false, false], [3, 4, 13, 15, "physical", "", false, false], [6, 7, 13, 15, "physical", "", false, false], [9, 10, 13, 15, "physical", "", false, false], [13, 15, 43, 43, "physical", "", true, false], [23, 25, 13, 15, "temporal", "", false, false], [27, 27, 13, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "and", "Terry", "Winograd", "visited", "the", "University", "of", "Edinburgh", "in", "1971", "to", "spread", "the", "news", "about", "Micro", "-", "Planner", "and", "SHRDLU", "and", "cast", "doubt", "on", "the", "solution-oriented", "unified", "proof", "that", "had", "been", "the", "mainstay", "of", "the", "Edinburgh", "Logicists", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited the University of Edinburgh in 1971 to spread the news about Micro-Planner and SHRDLU and cast doubt on the solution-oriented unified proof that had been the mainstay of the Edinburgh Logicists.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 56], [57, 65], [66, 73], [74, 77], [78, 88], [89, 91], [92, 101], [102, 104], [105, 109], [110, 112], [113, 119], [120, 123], [124, 128], [129, 134], [135, 140], [140, 141], [141, 148], [149, 152], [153, 159], [160, 163], [164, 168], [169, 174], [175, 177], [178, 181], [182, 199], [200, 207], [208, 213], [214, 218], [219, 222], [223, 227], [228, 231], [232, 240], [241, 243], [244, 247], [248, 257], [258, 267], [267, 268]]}
{"doc_key": "ai-test-296", "ner": [[0, 0, "researcher"], [7, 7, "field"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 11, 12, "role", "inspires", false, false], [0, 0, 14, 15, "role", "inspires", false, false], [0, 0, 17, 18, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Walter", "'s", "work", "inspired", "later", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work inspired later generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 22], [23, 28], [29, 40], [41, 43], [44, 52], [53, 64], [65, 69], [70, 72], [73, 79], [80, 86], [86, 87], [88, 92], [93, 100], [101, 104], [105, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-test-297", "ner": [[7, 7, "algorithm"], [9, 10, "researcher"], [15, 21, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 9, 10, "origin", "", false, false], [7, 7, 15, 21, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Then", ",", "a", "similar", "GPU", "-", "based", "CNN", "by", "Alex", "Krizhevsky", "et", "al", "won", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "2012", "."], "sentence-detokenized": "Then, a similar GPU-based CNN by Alex Krizhevsky et al won the ImageNet Large Scale Visual Recognition Challenge 2012.", "token2charspan": [[0, 4], [4, 5], [6, 7], [8, 15], [16, 19], [19, 20], [20, 25], [26, 29], [30, 32], [33, 37], [38, 48], [49, 51], [52, 54], [55, 58], [59, 62], [63, 71], [72, 77], [78, 83], [84, 90], [91, 102], [103, 112], [113, 117], [117, 118]]}
{"doc_key": "ai-test-298", "ner": [[2, 3, "misc"], [8, 9, "metrics"], [12, 13, "metrics"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 2, 3, "type-of", "", false, false], [12, 13, 2, 3, "type-of", "", false, false], [12, 13, 18, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Commonly", "used", "loss", "functions", "for", "probabilistic", "classification", "are", "log", "loss", "and", "the", "Brier", "score", "between", "the", "predicted", "and", "TRUE", "probability", "distributions", "."], "sentence-detokenized": "Commonly used loss functions for probabilistic classification are log loss and the Brier score between the predicted and TRUE probability distributions.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 28], [29, 32], [33, 46], [47, 61], [62, 65], [66, 69], [70, 74], [75, 78], [79, 82], [83, 88], [89, 94], [95, 102], [103, 106], [107, 116], [117, 120], [121, 125], [126, 137], [138, 151], [151, 152]]}
{"doc_key": "ai-test-299", "ner": [[4, 4, "organisation"], [19, 19, "field"], [22, 22, "organisation"], [9, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 19, 19, "general-affiliation", "field_of_study", false, false], [4, 4, 9, 10, "part-of", "", false, false], [22, 22, 4, 4, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "May", "2016", ",", "NtechLab", ",", "of", "the", "three", "Russian", "companies", ",", "was", "admitted", "to", "the", "official", "testing", "of", "biometric", "technology", "by", "NIST", "."], "sentence-detokenized": "In May 2016, NtechLab, of the three Russian companies, was admitted to the official testing of biometric technology by NIST.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [21, 22], [23, 25], [26, 29], [30, 35], [36, 43], [44, 53], [53, 54], [55, 58], [59, 67], [68, 70], [71, 74], [75, 83], [84, 91], [92, 94], [95, 104], [105, 115], [116, 118], [119, 123], [123, 124]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Floating", "-", "point", "numbers", ",", "however", ",", "have", "only", "a", "certain", "mathematical", "precision", "."], "sentence-detokenized": "Floating-point numbers, however, have only a certain mathematical precision.", "token2charspan": [[0, 8], [8, 9], [9, 14], [15, 22], [22, 23], [24, 31], [31, 32], [33, 37], [38, 42], [43, 44], [45, 52], [53, 65], [66, 75], [75, 76]]}
{"doc_key": "ai-test-301", "ner": [[5, 5, "organisation"], [12, 18, "conference"], [20, 20, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 12, 18, "role", "contributes_to", false, false], [20, 20, 12, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2015", ",", "many", "of", "SenseTime", "'s", "papers", "were", "accepted", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "In 2015, many of SenseTime's papers were accepted at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 13], [14, 16], [17, 26], [26, 28], [29, 35], [36, 40], [41, 49], [50, 52], [53, 56], [57, 67], [68, 70], [71, 79], [80, 86], [87, 90], [91, 98], [99, 110], [111, 112], [112, 116], [116, 117], [117, 118]]}
{"doc_key": "ai-test-302", "ner": [[5, 7, "task"], [9, 9, "task"], [12, 13, "task"], [15, 18, "task"], [21, 21, "field"], [23, 25, "misc"], [27, 33, "conference"], [41, 43, "misc"], [45, 46, "conference"], [62, 64, "misc"], [66, 66, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 7, 21, 21, "part-of", "task_part_of_field", false, false], [9, 9, 5, 7, "named", "", false, false], [12, 13, 21, 21, "part-of", "task_part_of_field", false, false], [15, 18, 12, 13, "named", "", false, false], [23, 25, 27, 33, "temporal", "", false, false], [41, 43, 45, 46, "temporal", "", false, false], [62, 64, 66, 66, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["He", "co-developed", "optimal", "algorithms", "for", "Structure", "From", "Motion", "(", "SFM", ",", "or", "Visual", "SLAM", ",", "simultaneous", "localisation", "and", "mapping", ",", "in", "Robotics", ";", "Best", "Paper", "Award", "at", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "1998", ")", ",", "characterised", "its", "ambiguities", "(", "David", "Marr", "Prize", "at", "ICCV", "1999", ")", ",", "also", "characterised", "the", "identifiability", "and", "observability", "of", "visual", "-", "inertial", "sensor", "fusion", "(", "Best", "Paper", "Award", "at", "Robotics", "2015", ")", "."], "sentence-detokenized": "He co-developed optimal algorithms for Structure From Motion (SFM, or Visual SLAM, simultaneous localisation and mapping, in Robotics; Best Paper Award at Conference on Computer Vision and Pattern Recognition 1998), characterised its ambiguities (David Marr Prize at ICCV 1999), also characterised the identifiability and observability of visual-inertial sensor fusion (Best Paper Award at Robotics 2015).", "token2charspan": [[0, 2], [3, 15], [16, 23], [24, 34], [35, 38], [39, 48], [49, 53], [54, 60], [61, 62], [62, 65], [65, 66], [67, 69], [70, 76], [77, 81], [81, 82], [83, 95], [96, 108], [109, 112], [113, 120], [120, 121], [122, 124], [125, 133], [133, 134], [135, 139], [140, 145], [146, 151], [152, 154], [155, 165], [166, 168], [169, 177], [178, 184], [185, 188], [189, 196], [197, 208], [209, 213], [213, 214], [214, 215], [216, 229], [230, 233], [234, 245], [246, 247], [247, 252], [253, 257], [258, 263], [264, 266], [267, 271], [272, 276], [276, 277], [277, 278], [279, 283], [284, 297], [298, 301], [302, 317], [318, 321], [322, 335], [336, 338], [339, 345], [345, 346], [346, 354], [355, 361], [362, 368], [369, 370], [370, 374], [375, 380], [381, 386], [387, 389], [390, 398], [399, 403], [403, 404], [404, 405]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 11, "field"], [13, 14, "field"], [21, 22, "task"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 7, 8, "part-of", "task_part_of_field", false, false], [0, 1, 10, 11, "part-of", "task_part_of_field", false, false], [0, 1, 13, 14, "part-of", "task_part_of_field", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 24, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "a", "fundamental", "tool", "in", "image", "processing", ",", "machine", "vision", "and", "computer", "vision", ",", "especially", "in", "the", "areas", "of", "feature", "detection", "and", "feature", "extraction", "."], "sentence-detokenized": "Edge detection is a fundamental tool in image processing, machine vision and computer vision, especially in the areas of feature detection and feature extraction.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 19], [20, 31], [32, 36], [37, 39], [40, 45], [46, 56], [56, 57], [58, 65], [66, 72], [73, 76], [77, 85], [86, 92], [92, 93], [94, 104], [105, 107], [108, 111], [112, 117], [118, 120], [121, 128], [129, 138], [139, 142], [143, 150], [151, 161], [161, 162]]}
{"doc_key": "ai-test-305", "ner": [[8, 9, "misc"], [21, 28, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "example", "of", "this", "is", "a", "variable", "like", "outdoor", "temperature", "(", "mathtemp", "/", "math", ")", ",", "which", "in", "a", "given", "application", "can", "be", "recorded", "to", "a", "few", "decimal", "places", "(", "depending", "on", "the", "measuring", "equipment", ")", "."], "sentence-detokenized": "An example of this is a variable like outdoor temperature (mathtemp / math), which in a given application can be recorded to a few decimal places (depending on the measuring equipment).", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 18], [19, 21], [22, 23], [24, 32], [33, 37], [38, 45], [46, 57], [58, 59], [59, 67], [68, 69], [70, 74], [74, 75], [75, 76], [77, 82], [83, 85], [86, 87], [88, 93], [94, 105], [106, 109], [110, 112], [113, 121], [122, 124], [125, 126], [127, 130], [131, 138], [139, 145], [146, 147], [147, 156], [157, 159], [160, 163], [164, 173], [174, 183], [183, 184], [184, 185]]}
{"doc_key": "ai-test-306", "ner": [[3, 4, "person"], [6, 7, "person"], [9, 10, "person"], [18, 19, "person"], [27, 28, "person"], [30, 30, "organisation"], [32, 33, "person"], [37, 38, "person"], [41, 41, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 6, 7, 8, 10, 11], "relations": [[32, 33, 30, 30, "role", "", false, false], [41, 41, 37, 38, "named", "", false, false]], "relations_mapping_to_source": [2, 4], "sentence": ["Returning", "judges", "are", "Fon", "Davis", ",", "Jessica", "Chobot", "and", "Leland", "Melvin", ",", "as", "well", "as", "guest", "judges", "actor", "Clark", "Gregg", ",", "MythBusters", "presenter", "and", "former", "Battlebots", "builder", "Adam", "Savage", ",", "NFL", "tightend", "Vernon", "Davis", "and", "YouTube", "star", "Michael", "Stevens", "a.k.a", ".", "Vsauce", "."], "sentence-detokenized": "Returning judges are Fon Davis, Jessica Chobot and Leland Melvin, as well as guest judges actor Clark Gregg, MythBusters presenter and former Battlebots builder Adam Savage, NFL tightend Vernon Davis and YouTube star Michael Stevens a.k.a. Vsauce.", "token2charspan": [[0, 9], [10, 16], [17, 20], [21, 24], [25, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 57], [58, 64], [64, 65], [66, 68], [69, 73], [74, 76], [77, 82], [83, 89], [90, 95], [96, 101], [102, 107], [107, 108], [109, 120], [121, 130], [131, 134], [135, 141], [142, 152], [153, 160], [161, 165], [166, 172], [172, 173], [174, 177], [178, 186], [187, 193], [194, 199], [200, 203], [204, 211], [212, 216], [217, 224], [225, 232], [233, 238], [238, 239], [240, 246], [246, 247]]}
{"doc_key": "ai-test-307", "ner": [[13, 14, "algorithm"], [15, 19, "algorithm"], [21, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 14, 21, 23, "part-of", "", false, false], [15, 19, 21, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["But", "these", "methods", "have", "never", "won", "out", "over", "the", "non-uniform", "internal", "-", "manual", "Gaussian", "mixture", "model", "/", "Hidden", "Markov", "model", "(", "GMM", "-", "HMM", ")", "technology", ",", "based", "on", "generative", "speech", "models", "trained", "discriminatively", "."], "sentence-detokenized": "But these methods have never won out over the non-uniform internal-manual Gaussian mixture model/Hidden Markov model (GMM-HMM) technology, based on generative speech models trained discriminatively.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 22], [23, 28], [29, 32], [33, 36], [37, 41], [42, 45], [46, 57], [58, 66], [66, 67], [67, 73], [74, 82], [83, 90], [91, 96], [96, 97], [97, 103], [104, 110], [111, 116], [117, 118], [118, 121], [121, 122], [122, 125], [125, 126], [127, 137], [137, 138], [139, 144], [145, 147], [148, 158], [159, 165], [166, 172], [173, 180], [181, 197], [197, 198]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", ",", "and", "SciPy", "provide", "convenient", "ways", "to", "apply", "these", "different", "methods", "."], "sentence-detokenized": "Software packages such as MATLAB, GNU Octave, Scilab, and SciPy provide convenient ways to apply these different methods.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [52, 53], [54, 57], [58, 63], [64, 71], [72, 82], [83, 87], [88, 90], [91, 96], [97, 102], [103, 112], [113, 120], [120, 121]]}
{"doc_key": "ai-test-309", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [8, 9, "task"], [18, 19, "researcher"], [21, 22, "university"], [24, 25, "researcher"], [27, 30, "organisation"], [32, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 8, 9, "related-to", "", false, false], [0, 2, 18, 19, "origin", "", false, false], [0, 2, 24, 25, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [18, 19, 21, 22, "physical", "", false, false], [18, 19, 21, 22, "role", "", false, false], [24, 25, 27, 30, "physical", "", false, false], [24, 25, 27, 30, "role", "", false, false], [32, 32, 27, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", ",", "a", "speech", "processing", "algorithm", ",", "was", "first", "proposed", "in", "1966", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "."], "sentence-detokenized": "Linear predictive coding (LPC), a speech processing algorithm, was first proposed in 1966 by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT).", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 72], [73, 81], [82, 84], [85, 89], [90, 92], [93, 101], [102, 109], [110, 112], [113, 119], [120, 130], [131, 134], [135, 140], [141, 146], [147, 149], [150, 156], [157, 166], [167, 170], [171, 180], [181, 182], [182, 185], [185, 186], [186, 187]]}
{"doc_key": "ai-test-310", "ner": [[20, 27, "conference"], [29, 29, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[29, 29, 20, 27, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2006", ",", "on", "the", "occasion", "of", "the", "25th", "anniversary", "of", "the", "algorithm", ",", "a", "workshop", "was", "organised", "at", "the", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "to", "provide", "an", "overview", "of", "the", "most", "recent", "contributions", "and", "variations", "to", "the", "original", "algorithm", ",", "mostly", "aimed", "at", "improving", "the", "speed", "of", "the", "algorithm", ",", "the", "robustness", "and", "accuracy", "of", "the", "estimated", "solution", ",", "and", "reducing", "the", "dependence", "on", "user", "-", "defined", "constants", "."], "sentence-detokenized": "In 2006, on the occasion of the 25th anniversary of the algorithm, a workshop was organised at the International Conference on Computer Vision and Pattern Recognition (CVPR) to provide an overview of the most recent contributions and variations to the original algorithm, mostly aimed at improving the speed of the algorithm, the robustness and accuracy of the estimated solution, and reducing the dependence on user-defined constants.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 24], [25, 27], [28, 31], [32, 36], [37, 48], [49, 51], [52, 55], [56, 65], [65, 66], [67, 68], [69, 77], [78, 81], [82, 91], [92, 94], [95, 98], [99, 112], [113, 123], [124, 126], [127, 135], [136, 142], [143, 146], [147, 154], [155, 166], [167, 168], [168, 172], [172, 173], [174, 176], [177, 184], [185, 187], [188, 196], [197, 199], [200, 203], [204, 208], [209, 215], [216, 229], [230, 233], [234, 244], [245, 247], [248, 251], [252, 260], [261, 270], [270, 271], [272, 278], [279, 284], [285, 287], [288, 297], [298, 301], [302, 307], [308, 310], [311, 314], [315, 324], [324, 325], [326, 329], [330, 340], [341, 344], [345, 353], [354, 356], [357, 360], [361, 370], [371, 379], [379, 380], [381, 384], [385, 393], [394, 397], [398, 408], [409, 411], [412, 416], [416, 417], [417, 424], [425, 434], [434, 435]]}
{"doc_key": "ai-test-311", "ner": [[3, 4, "university"], [7, 10, "organisation"], [12, 14, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Members", "went", "to", "Debrecen", "University", ",", "the", "Hungarian", "Academy", "of", "Sciences", ",", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "University", ",", "etc", "."], "sentence-detokenized": "Members went to Debrecen University, the Hungarian Academy of Sciences, E\u00f6tv\u00f6s Lor\u00e1nd University, etc.", "token2charspan": [[0, 7], [8, 12], [13, 15], [16, 24], [25, 35], [35, 36], [37, 40], [41, 50], [51, 58], [59, 61], [62, 70], [70, 71], [72, 78], [79, 85], [86, 96], [96, 97], [98, 101], [101, 102]]}
{"doc_key": "ai-test-312", "ner": [[2, 2, "algorithm"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 16, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "extend", "SVM", "to", "cases", "where", "the", "data", "are", "not", "linearly", "separable", ",", "we", "introduce", "the", "loss", "function", ","], "sentence-detokenized": "To extend SVM to cases where the data are not linearly separable, we introduce the loss function,", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 16], [17, 22], [23, 28], [29, 32], [33, 37], [38, 41], [42, 45], [46, 54], [55, 64], [64, 65], [66, 68], [69, 78], [79, 82], [83, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-313", "ner": [[0, 0, "programlang"], [10, 11, "researcher"], [13, 14, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 10, 11, "origin", "", false, false], [0, 0, 13, 14, "origin", "", false, false], [0, 0, 17, 18, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "is", "an", "educational", "programming", "language", "designed", "in", "1967", "by", "Wally", "Feurzeig", ",", "Seymour", "Papert", ",", "and", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo is an educational programming language designed in 1967 by Wally Feurzeig, Seymour Papert, and Cynthia Solomon.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 34], [35, 43], [44, 52], [53, 55], [56, 60], [61, 63], [64, 69], [70, 78], [78, 79], [80, 87], [88, 94], [94, 95], [96, 99], [100, 107], [108, 115], [115, 116]]}
{"doc_key": "ai-test-314", "ner": [[0, 3, "organisation"], [10, 15, "organisation"], [17, 20, "location"], [22, 22, "location"], [24, 24, "location"], [35, 38, "product"], [41, 48, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 10, 15, "role", "works_for", false, false], [10, 15, 17, 20, "physical", "", false, false], [17, 20, 22, 22, "physical", "", false, false], [22, 22, 24, 24, "physical", "", false, false], [35, 38, 0, 3, "origin", "", false, false], [41, 48, 35, 38, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "Eyring", "Research", "Institute", "played", "a", "key", "role", "in", "the", "U.S.", "Air", "Force", "'s", "missile", "directorate", "at", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", "to", "produce", ",", "in", "the", "greatest", "military", "secrecy", ",", "the", "Intelligent", "Systems", "Technology", "Software", "that", "underpinned", "Reagan", "'s", "later", "-", "mentioned", "Star", "Wars", "programme", "."], "sentence-detokenized": "The Eyring Research Institute played a key role in the U.S. Air Force's missile directorate at Hill Air Force Base near Ogden, Utah to produce, in the greatest military secrecy, the Intelligent Systems Technology Software that underpinned Reagan's later-mentioned Star Wars programme.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 29], [30, 36], [37, 38], [39, 42], [43, 47], [48, 50], [51, 54], [55, 59], [60, 63], [64, 69], [69, 71], [72, 79], [80, 91], [92, 94], [95, 99], [100, 103], [104, 109], [110, 114], [115, 119], [120, 125], [125, 126], [127, 131], [132, 134], [135, 142], [142, 143], [144, 146], [147, 150], [151, 159], [160, 168], [169, 176], [176, 177], [178, 181], [182, 193], [194, 201], [202, 212], [213, 221], [222, 226], [227, 238], [239, 245], [245, 247], [248, 253], [253, 254], [254, 263], [264, 268], [269, 273], [274, 283], [283, 284]]}
{"doc_key": "ai-test-315", "ner": [[12, 13, "field"], [23, 26, "researcher"], [28, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Over", "decades", ",", "he", "has", "researched", "and", "worked", "on", "emerging", "areas", "of", "computer", "science", ",", "from", "compiler", ",", "programming", "languages", "and", "system", "architecture", "John", "F", ".", "Sowa", "and", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "Over decades, he has researched and worked on emerging areas of computer science, from compiler, programming languages and system architecture John F. Sowa and John Zachman (1992).", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 16], [17, 20], [21, 31], [32, 35], [36, 42], [43, 45], [46, 54], [55, 60], [61, 63], [64, 72], [73, 80], [80, 81], [82, 86], [87, 95], [95, 96], [97, 108], [109, 118], [119, 122], [123, 129], [130, 142], [143, 147], [148, 149], [149, 150], [151, 155], [156, 159], [160, 164], [165, 172], [173, 174], [174, 178], [178, 179], [179, 180]]}
{"doc_key": "ai-test-316", "ner": [[1, 2, "algorithm"], [6, 9, "algorithm"], [11, 12, "algorithm"], [17, 18, "field"], [20, 21, "field"], [25, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 9, 1, 2, "named", "", false, false], [11, 12, 1, 2, "named", "", false, false], [17, 18, 1, 2, "usage", "", false, false], [20, 21, 1, 2, "usage", "", false, false], [25, 27, 1, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Sobel", "operator", ",", "sometimes", "called", "Sobel", "-", "Feldman", "operator", "or", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "especially", "in", "edge", "detection", "algorithms", ",", "where", "it", "creates", "an", "image", "that", "emphasises", "edges", "."], "sentence-detokenized": "The Sobel operator, sometimes called Sobel-Feldman operator or Sobel filter, is used in image processing and computer vision, especially in edge detection algorithms, where it creates an image that emphasises edges.", "token2charspan": [[0, 3], [4, 9], [10, 18], [18, 19], [20, 29], [30, 36], [37, 42], [42, 43], [43, 50], [51, 59], [60, 62], [63, 68], [69, 75], [75, 76], [77, 79], [80, 84], [85, 87], [88, 93], [94, 104], [105, 108], [109, 117], [118, 124], [124, 125], [126, 136], [137, 139], [140, 144], [145, 154], [155, 165], [165, 166], [167, 172], [173, 175], [176, 183], [184, 186], [187, 192], [193, 197], [198, 208], [209, 214], [214, 215]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [3, 3, "field"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 3, "compare", "", false, false], [0, 0, 3, 3, "type-of", "", false, false], [0, 0, 15, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "is", "a", "supervised", "learning", "algorithm", "that", "uses", "the", "labels", "of", "the", "data", ",", "while", "PCA", "is", "a", "learning", "algorithm", "that", "ignores", "the", "labels", "."], "sentence-detokenized": "LDA is a supervised learning algorithm that uses the labels of the data, while PCA is a learning algorithm that ignores the labels.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 19], [20, 28], [29, 38], [39, 43], [44, 48], [49, 52], [53, 59], [60, 62], [63, 66], [67, 71], [71, 72], [73, 78], [79, 82], [83, 85], [86, 87], [88, 96], [97, 106], [107, 111], [112, 119], [120, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "linear", "classification", "algorithms", "include", "Winnow", ",", "support", "vector", "machine", "and", "logistic", "regression", "."], "sentence-detokenized": "Other linear classification algorithms include Winnow, support vector machine and logistic regression.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 38], [39, 46], [47, 53], [53, 54], [55, 62], [63, 69], [70, 77], [78, 81], [82, 90], [91, 101], [101, 102]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [4, 6, "programlang"], [16, 18, "product"], [20, 20, "programlang"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 4, 6, "general-affiliation", "", true, false], [0, 0, 16, 18, "general-affiliation", "", true, false], [0, 0, 20, 20, "general-affiliation", "", true, false], [0, 0, 22, 22, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "consists", "of", "a", "C", "+", "+", "class", "library", "and", "several", "interpreted", "interface", "layers", ",", "including", "Tcl", "/", "Tk", ",", "Java", "and", "Python", "."], "sentence-detokenized": "VTK consists of a C + + class library and several interpreted interface layers, including Tcl / Tk, Java and Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 17], [18, 19], [20, 21], [22, 23], [24, 29], [30, 37], [38, 41], [42, 49], [50, 61], [62, 71], [72, 78], [78, 79], [80, 89], [90, 93], [94, 95], [96, 98], [98, 99], [100, 104], [105, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-320", "ner": [[7, 9, "task"], [16, 18, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Text", "produced", "by", "processing", "spontaneous", "speech", "using", "automatic", "speech", "recognition", "and", "printed", "or", "handwritten", "text", "using", "optical", "character", "recognition", "also", "contains", "processing", "noise", "."], "sentence-detokenized": "Text produced by processing spontaneous speech using automatic speech recognition and printed or handwritten text using optical character recognition also contains processing noise.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 27], [28, 39], [40, 46], [47, 52], [53, 62], [63, 69], [70, 81], [82, 85], [86, 93], [94, 96], [97, 108], [109, 113], [114, 119], [120, 127], [128, 137], [138, 149], [150, 154], [155, 163], [164, 174], [175, 180], [180, 181]]}
{"doc_key": "ai-test-321", "ner": [[0, 0, "researcher"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 9, 9, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "wrote", "several", "books", "and", "led", "the", "development", "of", "WordNet", ",", "an", "online", "database", "of", "word", "associations", "that", "can", "be", "used", "by", "computer", "programmes", "."], "sentence-detokenized": "Miller wrote several books and led the development of WordNet, an online database of word associations that can be used by computer programmes.", "token2charspan": [[0, 6], [7, 12], [13, 20], [21, 26], [27, 30], [31, 34], [35, 38], [39, 50], [51, 53], [54, 61], [61, 62], [63, 65], [66, 72], [73, 81], [82, 84], [85, 89], [90, 102], [103, 107], [108, 111], [112, 114], [115, 119], [120, 122], [123, 131], [132, 142], [142, 143]]}
{"doc_key": "ai-test-322", "ner": [[1, 1, "field"], [8, 10, "organisation"], [13, 13, "country"], [15, 16, "person"], [18, 20, "person"], [22, 23, "person"], [25, 26, "person"], [29, 29, "country"], [31, 34, "location"], [36, 37, "misc"], [38, 39, "person"], [42, 43, "person"], [45, 45, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 10, 13, 13, "physical", "", false, false], [15, 16, 29, 29, "physical", "", false, false], [18, 20, 29, 29, "physical", "", false, false], [22, 23, 29, 29, "physical", "", false, false], [25, 26, 29, 29, "physical", "", false, false], [31, 34, 1, 1, "general-affiliation", "", false, false], [31, 34, 38, 39, "artifact", "", false, false], [36, 37, 38, 39, "named", "", false, false], [42, 43, 45, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Contemporary", "automata", "are", "represented", "by", "the", "works", "of", "Cabaret", "Mechanical", "Theatre", "in", "the", "UK", ",", "Dug", "North", "and", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "in", "the", "US", ",", "Le", "D\u00e9fenseur", "du", "Temps", "by", "French", "artist", "Jacques", "Monestier", ",", "and", "Fran\u00e7ois", "Junod", "in", "Switzerland", "."], "sentence-detokenized": "Contemporary automata are represented by the works of Cabaret Mechanical Theatre in the UK, Dug North and Chomick + Meder, Arthur Ganson, Joe Jones in the US, Le D\u00e9fenseur du Temps by French artist Jacques Monestier, and Fran\u00e7ois Junod in Switzerland.", "token2charspan": [[0, 12], [13, 21], [22, 25], [26, 37], [38, 40], [41, 44], [45, 50], [51, 53], [54, 61], [62, 72], [73, 80], [81, 83], [84, 87], [88, 90], [90, 91], [92, 95], [96, 101], [102, 105], [106, 113], [114, 115], [116, 121], [121, 122], [123, 129], [130, 136], [136, 137], [138, 141], [142, 147], [148, 150], [151, 154], [155, 157], [157, 158], [159, 161], [162, 171], [172, 174], [175, 180], [181, 183], [184, 190], [191, 197], [198, 205], [206, 215], [215, 216], [217, 220], [221, 229], [230, 235], [236, 238], [239, 250], [250, 251]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 21, 21, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "includes", "standard", "codefor", "/", "code", "and", "codewhile", "/", "code", "loops", ",", "but", "(", "as", "in", "other", "similar", "applications", "such", "as", "R", ")", ",", "the", "use", "of", "vectorised", "notation", "is", "encouraged", "and", "is", "often", "faster", "to", "execute", "."], "sentence-detokenized": "MATLAB includes standard codefor/code and codewhile/code loops, but (as in other similar applications such as R), the use of vectorised notation is encouraged and is often faster to execute.", "token2charspan": [[0, 6], [7, 15], [16, 24], [25, 32], [32, 33], [33, 37], [38, 41], [42, 51], [51, 52], [52, 56], [57, 62], [62, 63], [64, 67], [68, 69], [69, 71], [72, 74], [75, 80], [81, 88], [89, 101], [102, 106], [107, 109], [110, 111], [111, 112], [112, 113], [114, 117], [118, 121], [122, 124], [125, 135], [136, 144], [145, 147], [148, 158], [159, 162], [163, 165], [166, 171], [172, 178], [179, 181], [182, 189], [189, 190]]}
{"doc_key": "ai-test-324", "ner": [[3, 4, "researcher"], [9, 12, "conference"], [17, 19, "field"], [22, 28, "misc"], [31, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 22, 28, "win-defeat", "", false, false], [3, 4, 31, 40, "win-defeat", "", false, false], [22, 28, 9, 12, "temporal", "", false, false], [22, 28, 17, 19, "topic", "", false, false], [31, 40, 9, 12, "temporal", "", false, false], [31, 40, 17, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2007", ",", "Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "for", "his", "achievements", "in", "computer", "science", "education", ":", "the", "Karl", "V", ".", "Karlstrom", "Outstanding", "Educator", "Award", "and", "the", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contributions", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "In 2007, Pausch received two awards from the Association for Computing Machinery for his achievements in computer science education: the Karl V. Karlstrom Outstanding Educator Award and the ACM SIGCSE Award for Outstanding Contributions to Computer Science Education.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 24], [25, 28], [29, 35], [36, 40], [41, 44], [45, 56], [57, 60], [61, 70], [71, 80], [81, 84], [85, 88], [89, 101], [102, 104], [105, 113], [114, 121], [122, 131], [131, 132], [133, 136], [137, 141], [142, 143], [143, 144], [145, 154], [155, 166], [167, 175], [176, 181], [182, 185], [186, 189], [190, 193], [194, 200], [201, 206], [207, 210], [211, 222], [223, 236], [237, 239], [240, 248], [249, 256], [257, 266], [266, 267]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [8, 8, "product"], [9, 9, "product"], [15, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 8, "role", "sells", false, false], [8, 8, 9, 9, "general-affiliation", "", false, false], [8, 8, 15, 16, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "shipped", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was shipped to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 73], [74, 76], [77, 84], [85, 91], [92, 94], [95, 99], [99, 100]]}
{"doc_key": "ai-test-326", "ner": [[0, 1, "algorithm"], [5, 7, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 0, 1, "usage", "", false, false], [12, 13, 5, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantic", "networks", "are", "used", "in", "natural", "language", "processing", "applications", ",", "such", "as", "semantic", "parsing", "."], "sentence-detokenized": "Semantic networks are used in natural language processing applications, such as semantic parsing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 26], [27, 29], [30, 37], [38, 46], [47, 57], [58, 70], [70, 71], [72, 76], [77, 79], [80, 88], [89, 96], [96, 97]]}
{"doc_key": "ai-test-327", "ner": [[4, 5, "field"], [7, 8, "field"], [10, 11, "task"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 8, 4, 5, "usage", "", false, false], [10, 11, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Some", "successful", "applications", "of", "deep", "learning", "include", "computer", "vision", "and", "speech", "recognition", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Some successful applications of deep learning include computer vision and speech recognition. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 31], [32, 36], [37, 45], [46, 53], [54, 62], [63, 69], [70, 73], [74, 80], [81, 92], [92, 93], [94, 101], [102, 105], [105, 106], [107, 112], [113, 119], [119, 120], [121, 127], [128, 137], [137, 138], [139, 145], [146, 147], [147, 148], [149, 151], [151, 152]]}
{"doc_key": "ai-test-328", "ner": [[3, 8, "product"], [14, 14, "misc"], [17, 17, "misc"], [23, 23, "product"], [27, 28, "task"], [30, 31, "task"], [33, 34, "task"], [36, 38, "field"], [40, 41, "task"], [43, 44, "field"], [46, 47, "task"], [49, 50, "task"], [52, 53, "task"], [55, 55, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[3, 8, 14, 14, "physical", "travels_to", false, false], [3, 8, 17, 17, "physical", "travels_to", false, false], [23, 23, 3, 8, "part-of", "", false, false], [23, 23, 3, 8, "role", "maintains", false, false], [23, 23, 27, 28, "related-to", "has_ability_to", false, false], [23, 23, 30, 31, "related-to", "has_ability_to", false, false], [23, 23, 33, 34, "related-to", "has_ability_to", false, false], [23, 23, 36, 38, "related-to", "has_ability_to", false, false], [23, 23, 40, 41, "related-to", "has_ability_to", false, false], [23, 23, 43, 44, "related-to", "has_ability_to", false, false], [23, 23, 46, 47, "related-to", "has_ability_to", false, false], [23, 23, 49, 50, "related-to", "has_ability_to", false, false], [23, 23, 52, 53, "related-to", "has_ability_to", false, false], [23, 23, 55, 55, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Besides", "maintaining", "the", "systems", "of", "the", "Discovery", "One", "spacecraft", "during", "its", "interplanetary", "mission", "to", "Jupiter", "(", "or", "Saturn", "in", "the", "novel", ")", ",", "HAL", "is", "capable", "of", "speech", "synthesis", ",", "speech", "recognition", ",", "face", "recognition", ",", "natural", "language", "processing", ",", "lip", "reading", ",", "art", "appreciation", ",", "Affective", "computing", ",", "automated", "reasoning", ",", "spacecraft", "control", "and", "chess", "."], "sentence-detokenized": "Besides maintaining the systems of the Discovery One spacecraft during its interplanetary mission to Jupiter (or Saturn in the novel), HAL is capable of speech synthesis, speech recognition, face recognition, natural language processing, lip reading, art appreciation, Affective computing, automated reasoning, spacecraft control and chess.", "token2charspan": [[0, 7], [8, 19], [20, 23], [24, 31], [32, 34], [35, 38], [39, 48], [49, 52], [53, 63], [64, 70], [71, 74], [75, 89], [90, 97], [98, 100], [101, 108], [109, 110], [110, 112], [113, 119], [120, 122], [123, 126], [127, 132], [132, 133], [133, 134], [135, 138], [139, 141], [142, 149], [150, 152], [153, 159], [160, 169], [169, 170], [171, 177], [178, 189], [189, 190], [191, 195], [196, 207], [207, 208], [209, 216], [217, 225], [226, 236], [236, 237], [238, 241], [242, 249], [249, 250], [251, 254], [255, 267], [267, 268], [269, 278], [279, 288], [288, 289], [290, 299], [300, 309], [309, 310], [311, 321], [322, 329], [330, 333], [334, 339], [339, 340]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [4, 4, "country"], [6, 8, "country"], [13, 15, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 4, "physical", "", false, false], [0, 1, 6, 8, "physical", "", false, false], [0, 1, 13, 15, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr", "Julesz", "emigrated", "from", "Hungary", "to", "the", "United", "States", "after", "the", "invasion", "of", "the", "Soviet", "Union", "in", "1956", "."], "sentence-detokenized": "Dr Julesz emigrated from Hungary to the United States after the invasion of the Soviet Union in 1956.", "token2charspan": [[0, 2], [3, 9], [10, 19], [20, 24], [25, 32], [33, 35], [36, 39], [40, 46], [47, 53], [54, 59], [60, 63], [64, 72], [73, 75], [76, 79], [80, 86], [87, 92], [93, 95], [96, 100], [100, 101]]}
{"doc_key": "ai-test-330", "ner": [[3, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Activation", "functions", "with", "Sigmoidal", "function", "use", "a", "second", "non-linearity", "for", "large", "inputs", ":", "math", ".", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+", "exp", "(", "-", "v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "Activation functions with Sigmoidal function use a second non-linearity for large inputs: math. phi (v _ i) = (1 + exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 10], [11, 20], [21, 25], [26, 35], [36, 44], [45, 48], [49, 50], [51, 57], [58, 71], [72, 75], [76, 81], [82, 88], [88, 89], [90, 94], [94, 95], [96, 99], [100, 101], [101, 102], [103, 104], [105, 106], [106, 107], [108, 109], [110, 111], [111, 112], [113, 114], [115, 118], [119, 120], [120, 121], [121, 122], [123, 124], [125, 126], [126, 127], [127, 128], [129, 130], [131, 132], [132, 134], [134, 135], [136, 137], [138, 142], [142, 143]]}
{"doc_key": "ai-test-331", "ner": [[12, 14, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "probabilities", "are", "used", "to", "determine", "what", "the", "target", "is", "using", "a", "maximum", "likelihood", "decision", "."], "sentence-detokenized": "These probabilities are used to determine what the target is using a maximum likelihood decision.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 46], [47, 50], [51, 57], [58, 60], [61, 66], [67, 68], [69, 76], [77, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-332", "ner": [[4, 6, "university"], [12, 14, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "transferred", "to", "the", "University", "of", "Konstanz", "in", "1984", "and", "to", "the", "University", "of", "Salzburg", "in", "1990", "."], "sentence-detokenized": "He transferred to the University of Konstanz in 1984 and to the University of Salzburg in 1990.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 21], [22, 32], [33, 35], [36, 44], [45, 47], [48, 52], [53, 56], [57, 59], [60, 63], [64, 74], [75, 77], [78, 86], [87, 89], [90, 94], [94, 95]]}
{"doc_key": "ai-test-333", "ner": [[7, 8, "metrics"], [10, 12, "metrics"], [14, 16, "metrics"], [18, 18, "metrics"], [20, 21, "metrics"], [23, 25, "metrics"], [28, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 12, 7, 8, "origin", "based_on", false, false], [14, 16, 7, 8, "origin", "based_on", false, false], [18, 18, 7, 8, "origin", "based_on", false, false], [20, 21, 7, 8, "origin", "based_on", false, false], [23, 25, 7, 8, "origin", "based_on", false, false], [28, 31, 7, 8, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Some", "popular", "fitness", "functions", "based", "on", "the", "confusion", "matrix", "are", "sensitivity", "/", "specificity", ",", "recall", "/", "precision", ",", "F-measure", ",", "Jaccard", "similarity", ",", "Matthews", "correlation", "coefficient", ",", "and", "cost", "/", "profit", "matrix", "combining", "the", "cost", "and", "profit", "assigned", "to", "the", "4", "different", "types", "of", "ratings", "."], "sentence-detokenized": "Some popular fitness functions based on the confusion matrix are sensitivity/specificity, recall/precision, F-measure, Jaccard similarity, Matthews correlation coefficient, and cost/profit matrix combining the cost and profit assigned to the 4 different types of ratings.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 30], [31, 36], [37, 39], [40, 43], [44, 53], [54, 60], [61, 64], [65, 76], [76, 77], [77, 88], [88, 89], [90, 96], [96, 97], [97, 106], [106, 107], [108, 117], [117, 118], [119, 126], [127, 137], [137, 138], [139, 147], [148, 159], [160, 171], [171, 172], [173, 176], [177, 181], [181, 182], [182, 188], [189, 195], [196, 205], [206, 209], [210, 214], [215, 218], [219, 225], [226, 234], [235, 237], [238, 241], [242, 243], [244, 253], [254, 259], [260, 262], [263, 270], [270, 271]]}
{"doc_key": "ai-test-334", "ner": [[6, 6, "product"], [8, 8, "product"], [10, 10, "product"], [12, 12, "product"], [15, 16, "programlang"], [27, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[27, 30, 6, 6, "part-of", "", false, false], [27, 30, 8, 8, "part-of", "", false, false], [27, 30, 10, 10, "part-of", "", false, false], [27, 30, 12, 12, "part-of", "", false, false], [27, 30, 15, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Common", "numerical", "programming", "environments", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "and", "the", "R", "language", "offer", "some", "of", "the", "simpler", "feature", "extraction", "techniques", "(", "e.g.", "principal", "-", "component", "analysis", ")", "via", "built", "-", "in", "commands", "."], "sentence-detokenized": "Common numerical programming environments such as MATLAB, SciLab, NumPy, Sklearn and the R language offer some of the simpler feature extraction techniques (e.g. principal-component analysis) via built-in commands.", "token2charspan": [[0, 6], [7, 16], [17, 28], [29, 41], [42, 46], [47, 49], [50, 56], [56, 57], [58, 64], [64, 65], [66, 71], [71, 72], [73, 80], [81, 84], [85, 88], [89, 90], [91, 99], [100, 105], [106, 110], [111, 113], [114, 117], [118, 125], [126, 133], [134, 144], [145, 155], [156, 157], [157, 161], [162, 171], [171, 172], [172, 181], [182, 190], [190, 191], [192, 195], [196, 201], [201, 202], [202, 204], [205, 213], [213, 214]]}
{"doc_key": "ai-test-335", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "have", "been", "implemented", "to", "work", "with", "humans", "in", "performing", "industrial", "manufacturing", "tasks", "."], "sentence-detokenized": "Industrial robots have been implemented to work with humans in performing industrial manufacturing tasks.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 27], [28, 39], [40, 42], [43, 47], [48, 52], [53, 59], [60, 62], [63, 73], [74, 84], [85, 98], [99, 104], [104, 105]]}
{"doc_key": "ai-test-336", "ner": [[6, 12, "field"], [8, 11, "researcher"], [21, 22, "field"], [24, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 12, 21, 22, "related-to", "", false, false], [6, 12, 24, 25, "related-to", "", false, false], [6, 12, 27, 28, "related-to", "", false, false], [8, 11, 6, 12, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "first", "published", "paper", "on", "CGs", ",", "John", "F", ".", "Sowa", "applied", "them", "to", "a", "wide", "range", "of", "topics", "in", "artificial", "intelligence", ",", "computer", "science", "and", "cognitive", "science", "."], "sentence-detokenized": "In the first published paper on CGs, John F. Sowa applied them to a wide range of topics in artificial intelligence, computer science and cognitive science.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [23, 28], [29, 31], [32, 35], [35, 36], [37, 41], [42, 43], [43, 44], [45, 49], [50, 57], [58, 62], [63, 65], [66, 67], [68, 72], [73, 78], [79, 81], [82, 88], [89, 91], [92, 102], [103, 115], [115, 116], [117, 125], [126, 133], [134, 137], [138, 147], [148, 155], [155, 156]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [4, 4, "metrics"], [10, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "in", "its", "calculation", "of", "the", "brevity", "penalty", ",", "in", "that", "small", "variations", "in", "translation", "length", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from BLEU in its calculation of the brevity penalty, in that small variations in translation length do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 46], [47, 49], [50, 53], [54, 61], [62, 69], [69, 70], [71, 73], [74, 78], [79, 84], [85, 95], [96, 98], [99, 110], [111, 117], [118, 120], [121, 124], [125, 131], [132, 135], [136, 143], [144, 149], [150, 152], [153, 157], [157, 158]]}
{"doc_key": "ai-test-338", "ner": [[1, 5, "misc"], [12, 13, "field"]], "ner_mapping_to_source": [0, 2], "relations": [[1, 5, 12, 13, "topic", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["The", "IJCAI", "Award", "for", "Research", "Excellence", "is", "a", "biennial", "award", "presented", "to", "artificial", "intelligence", "researchers", "at", "the", "IJCAI", "conference", "in", "recognition", "of", "career", "excellence", "."], "sentence-detokenized": "The IJCAI Award for Research Excellence is a biennial award presented to artificial intelligence researchers at the IJCAI conference in recognition of career excellence.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 28], [29, 39], [40, 42], [43, 44], [45, 53], [54, 59], [60, 69], [70, 72], [73, 83], [84, 96], [97, 108], [109, 111], [112, 115], [116, 121], [122, 132], [133, 135], [136, 147], [148, 150], [151, 157], [158, 168], [168, 169]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [9, 9, "conference"], [17, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 9, 9, "role", "", false, false], [0, 0, 17, 28, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "was", "one", "of", "the", "original", "Fellows", "of", "the", "AAAI", ",", "and", "is", "the", "only", "person", "to", "have", "served", "on", "the", "scientific", "advisory", "boards", "of", "both", "Microsoft", "and", "Apple", "."], "sentence-detokenized": "Lenat was one of the original Fellows of the AAAI, and is the only person to have served on the scientific advisory boards of both Microsoft and Apple.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 16], [17, 20], [21, 29], [30, 37], [38, 40], [41, 44], [45, 49], [49, 50], [51, 54], [55, 57], [58, 61], [62, 66], [67, 73], [74, 76], [77, 81], [82, 88], [89, 91], [92, 95], [96, 106], [107, 115], [116, 122], [123, 125], [126, 130], [131, 140], [141, 144], [145, 150], [150, 151]]}
{"doc_key": "ai-test-340", "ner": [[0, 0, "algorithm"], [5, 6, "misc"], [10, 12, "metrics"], [19, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "related-to", "minimise", false, false], [10, 12, 5, 6, "type-of", "", false, false], [19, 19, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoders", "are", "trained", "to", "minimise", "reconstruction", "errors", "(", "such", "as", "mean", "squared", "error", ")", ",", "often", "referred", "to", "as", "loss", ":"], "sentence-detokenized": "Autoencoders are trained to minimise reconstruction errors (such as mean squared error), often referred to as loss:", "token2charspan": [[0, 12], [13, 16], [17, 24], [25, 27], [28, 36], [37, 51], [52, 58], [59, 60], [60, 64], [65, 67], [68, 72], [73, 80], [81, 86], [86, 87], [87, 88], [89, 94], [95, 103], [104, 106], [107, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-test-341", "ner": [[28, 30, "misc"], [33, 33, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[33, 33, 28, 30, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "to", "using", "definitions", "is", "to", "consider", "the", "general", "relatedness", "between", "word", "phrases", "and", "calculate", "the", "similarity", "of", "each", "pair", "of", "word", "phrases", "based", "on", "a", "given", "lexical", "knowledge", "base", "such", "as", "WordNet", "."], "sentence-detokenized": "An alternative to using definitions is to consider the general relatedness between word phrases and calculate the similarity of each pair of word phrases based on a given lexical knowledge base such as WordNet.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 23], [24, 35], [36, 38], [39, 41], [42, 50], [51, 54], [55, 62], [63, 74], [75, 82], [83, 87], [88, 95], [96, 99], [100, 109], [110, 113], [114, 124], [125, 127], [128, 132], [133, 137], [138, 140], [141, 145], [146, 153], [154, 159], [160, 162], [163, 164], [165, 170], [171, 178], [179, 188], [189, 193], [194, 198], [199, 201], [202, 209], [209, 210]]}
{"doc_key": "ai-test-342", "ner": [[0, 2, "algorithm"], [9, 11, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 11, "origin", "", false, false], [9, 11, 17, 18, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "invented", "by", "Richard", "S.", "Sutton", "based", "on", "earlier", "work", "by", "Arthur", "Samuel", "on", "learning", "temporal", "differences", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm invented by Richard S. Sutton based on earlier work by Arthur Samuel on learning temporal differences.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 42], [43, 45], [46, 53], [54, 56], [57, 63], [64, 69], [70, 72], [73, 80], [81, 85], [86, 88], [89, 95], [96, 102], [103, 105], [106, 114], [115, 123], [124, 135], [135, 136]]}
{"doc_key": "ai-test-343", "ner": [[1, 2, "field"], [4, 4, "field"], [6, 7, "task"], [11, 13, "task"], [15, 15, "task"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 1, 2, "part-of", "task_part_of_field", false, false], [6, 7, 4, 4, "part-of", "task_part_of_field", false, false], [11, 13, 6, 7, "named", "", false, false], [15, 15, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "data", "mining", "and", "statistics", ",", "hierarchical", "clustering", "(", "also", "called", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "method", "of", "cluster", "analysis", "that", "attempts", "to", "build", "a", "hierarchy", "of", "clusters", "."], "sentence-detokenized": "In data mining and statistics, hierarchical clustering (also called hierarchical cluster analysis or HCA) is a method of cluster analysis that attempts to build a hierarchy of clusters.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 29], [29, 30], [31, 43], [44, 54], [55, 56], [56, 60], [61, 67], [68, 80], [81, 88], [89, 97], [98, 100], [101, 104], [104, 105], [106, 108], [109, 110], [111, 117], [118, 120], [121, 128], [129, 137], [138, 142], [143, 151], [152, 154], [155, 160], [161, 162], [163, 172], [173, 175], [176, 184], [184, 185]]}
{"doc_key": "ai-test-344", "ner": [[3, 3, "algorithm"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "concept", "of", "deconvolution", "is", "widely", "used", "in", "signal", "processing", "and", "image", "processing", "techniques", "."], "sentence-detokenized": "The concept of deconvolution is widely used in signal processing and image processing techniques.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 53], [54, 64], [65, 68], [69, 74], [75, 85], [86, 96], [96, 97]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [20, 21, "misc"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 20, 21, "related-to", "enhances", false, false], [0, 1, 20, 21, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "serve", "to", "build", "and", "accumulate", "spatial", "knowledge", "by", "enabling", "the", "mind", "'s", "eye", "to", "visualise", "images", "to", "reduce", "cognitive", "load", "and", "improve", "information", "recall", "and", "learning", "."], "sentence-detokenized": "Cognitive maps serve to build and accumulate spatial knowledge by enabling the mind's eye to visualise images to reduce cognitive load and improve information recall and learning.", "token2charspan": [[0, 9], [10, 14], [15, 20], [21, 23], [24, 29], [30, 33], [34, 44], [45, 52], [53, 62], [63, 65], [66, 74], [75, 78], [79, 83], [83, 85], [86, 89], [90, 92], [93, 102], [103, 109], [110, 112], [113, 119], [120, 129], [130, 134], [135, 138], [139, 146], [147, 158], [159, 165], [166, 169], [170, 178], [178, 179]]}
{"doc_key": "ai-test-346", "ner": [[9, 9, "programlang"], [11, 13, "programlang"], [15, 15, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "which", "typically", "provide", "bindings", "with", "languages", "such", "as", "Python", ",", "C", "+", "+", ",", "Java", ")", "."], "sentence-detokenized": ", which typically provide bindings with languages such as Python, C + +, Java).", "token2charspan": [[0, 1], [2, 7], [8, 17], [18, 25], [26, 34], [35, 39], [40, 49], [50, 54], [55, 57], [58, 64], [64, 65], [66, 67], [68, 69], [70, 71], [71, 72], [73, 77], [77, 78], [78, 79]]}
{"doc_key": "ai-test-347", "ner": [[1, 3, "product"], [5, 5, "product"], [15, 16, "task"], [22, 23, "task"], [27, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 15, 16, "usage", "", false, false], [1, 3, 22, 23, "usage", "", false, false], [1, 3, 27, 31, "usage", "", false, false], [5, 5, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "voice", "-user", "interface", "(", "VUI", ")", "enables", "spoken", "human", "interaction", "with", "computers", ",", "using", "speech", "recognition", "to", "understand", "spoken", "commands", "and", "answer", "questions", ",", "and", "usually", "text", "-", "to", "-", "speech", "to", "play", "back", "a", "response", "."], "sentence-detokenized": "A voice-user interface (VUI) enables spoken human interaction with computers, using speech recognition to understand spoken commands and answer questions, and usually text-to-speech to play back a response.", "token2charspan": [[0, 1], [2, 7], [7, 12], [13, 22], [23, 24], [24, 27], [27, 28], [29, 36], [37, 43], [44, 49], [50, 61], [62, 66], [67, 76], [76, 77], [78, 83], [84, 90], [91, 102], [103, 105], [106, 116], [117, 123], [124, 132], [133, 136], [137, 143], [144, 153], [153, 154], [155, 158], [159, 166], [167, 171], [171, 172], [172, 174], [174, 175], [175, 181], [182, 184], [185, 189], [190, 194], [195, 196], [197, 205], [205, 206]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 4, "misc"], [11, 14, "researcher"], [16, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[0, 0, 3, 4, "general-affiliation", "is_a", false, false], [0, 0, 11, 14, "origin", "", false, false], [11, 14, 16, 17, "role", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["Jess", "is", "a", "rule", "engine", "for", "the", "Java", "platform", "developed", "by", "Ernest", "Friedman", "-", "Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "Jess is a rule engine for the Java platform developed by Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 14], [15, 21], [22, 25], [26, 29], [30, 34], [35, 43], [44, 53], [54, 56], [57, 63], [64, 72], [72, 73], [73, 77], [78, 80], [81, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-349", "ner": [[1, 2, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 15, 15, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "multilayer", "perceptrons", ",", "where", "a", "hidden", "layer", "exists", ",", "more", "sophisticated", "algorithms", "such", "as", "backpropagation", "should", "be", "used", "."], "sentence-detokenized": "For multilayer perceptrons, where a hidden layer exists, more sophisticated algorithms such as backpropagation should be used.", "token2charspan": [[0, 3], [4, 14], [15, 26], [26, 27], [28, 33], [34, 35], [36, 42], [43, 48], [49, 55], [55, 56], [57, 61], [62, 75], [76, 86], [87, 91], [92, 94], [95, 110], [111, 117], [118, 120], [121, 125], [125, 126]]}
{"doc_key": "ai-test-350", "ner": [[0, 1, "product"], [2, 7, "product"], [10, 17, "algorithm"], [23, 23, "field"], [26, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 7, 0, 1, "part-of", "", false, false], [2, 7, 10, 17, "usage", "", false, true], [10, 17, 23, 23, "related-to", "performs", false, false], [26, 32, 23, 23, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "Translate", "'s", "neural", "machine", "translation", "system", "uses", "a", "large", "end", "-", "to", "-", "end", "artificial", "neural", "network", "that", "attempts", "to", "perform", "deep", "learning", ",", "particularly", "networks", "with", "long", "short", "-", "term", "memory", "."], "sentence-detokenized": "Google Translate's neural machine translation system uses a large end-to-end artificial neural network that attempts to perform deep learning, particularly networks with long short-term memory.", "token2charspan": [[0, 6], [7, 16], [16, 18], [19, 25], [26, 33], [34, 45], [46, 52], [53, 57], [58, 59], [60, 65], [66, 69], [69, 70], [70, 72], [72, 73], [73, 76], [77, 87], [88, 94], [95, 102], [103, 107], [108, 116], [117, 119], [120, 127], [128, 132], [133, 141], [141, 142], [143, 155], [156, 164], [165, 169], [170, 174], [175, 180], [180, 181], [181, 185], [186, 192], [192, 193]]}
{"doc_key": "ai-test-351", "ner": [[15, 15, "researcher"], [17, 17, "researcher"], [19, 19, "researcher"], [21, 22, "researcher"], [24, 25, "researcher"], [27, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "1980s", "and", "early", "1990s", ",", "several", "methods", "were", "developed", "for", "this", "purpose", "by", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "and", "others", "."], "sentence-detokenized": "In the 1980s and early 1990s, several methods were developed for this purpose by Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter and others.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 16], [17, 22], [23, 28], [28, 29], [30, 37], [38, 45], [46, 50], [51, 60], [61, 64], [65, 69], [70, 77], [78, 80], [81, 87], [87, 88], [89, 97], [97, 98], [99, 107], [107, 108], [109, 115], [116, 127], [127, 128], [129, 133], [134, 144], [144, 145], [146, 157], [158, 161], [162, 168], [168, 169]]}
{"doc_key": "ai-test-352", "ner": [[0, 1, "organisation"], [2, 3, "organisation"], [8, 8, "organisation"], [11, 13, "task"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 8, 8, "role", "licenses_from", false, false], [2, 3, 0, 1, "named", "", false, false], [17, 17, 0, 1, "origin", "", false, false], [17, 17, 11, 13, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc.", "originally", "licensed", "software", "from", "Nuance", "to", "provide", "voice", "recognition", "to", "its", "digital", "assistant", "Siri", "."], "sentence-detokenized": "| Apple Apple Inc. originally licensed software from Nuance to provide voice recognition to its digital assistant Siri.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 18], [19, 29], [30, 38], [39, 47], [48, 52], [53, 59], [60, 62], [63, 70], [71, 76], [77, 88], [89, 91], [92, 95], [96, 103], [104, 113], [114, 118], [118, 119]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [8, 9, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 4, "role", "releases_movies_in_genre", false, false], [8, 9, 0, 0, "role", "directs_for", false, false], [13, 14, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "released", "several", "3D", "westerns", ",", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia released several 3D westerns, produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 28], [29, 37], [37, 38], [39, 47], [48, 50], [51, 54], [55, 62], [63, 66], [67, 75], [76, 78], [79, 86], [87, 93], [93, 94]]}
{"doc_key": "ai-test-354", "ner": [[6, 7, "field"], [9, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "includes", "knowledge", "and", "research", "in", "computer", "science", ",", "linguistics", "and", "computer", "engineering", "."], "sentence-detokenized": "It includes knowledge and research in computer science, linguistics and computer engineering.", "token2charspan": [[0, 2], [3, 11], [12, 21], [22, 25], [26, 34], [35, 37], [38, 46], [47, 54], [54, 55], [56, 67], [68, 71], [72, 80], [81, 92], [92, 93]]}
{"doc_key": "ai-test-355", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", "is", "an", "example", "of", "R", "code", ":"], "sentence-detokenized": "Here is an example of R code:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 23], [24, 28], [28, 29]]}
{"doc_key": "ai-test-356", "ner": [[1, 2, "metrics"], [10, 11, "metrics"], [13, 13, "metrics"], [17, 20, "metrics"], [22, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 10, 11, "part-of", "plotted_into", false, false], [1, 2, 17, 20, "part-of", "plotted_into", false, false], [13, 13, 10, 11, "named", "", false, false], [22, 22, 17, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "ROC", "curve", "is", "obtained", "by", "plotting", "the", "number", "of", "TRUE", "positives", "(", "TPR", ")", "against", "the", "number", "of", "FALSE", "positives", "(", "FPR", ")", "at", "different", "threshold", "settings", "."], "sentence-detokenized": "The ROC curve is obtained by plotting the number of TRUE positives (TPR) against the number of FALSE positives (FPR) at different threshold settings.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 25], [26, 28], [29, 37], [38, 41], [42, 48], [49, 51], [52, 56], [57, 66], [67, 68], [68, 71], [71, 72], [73, 80], [81, 84], [85, 91], [92, 94], [95, 100], [101, 110], [111, 112], [112, 115], [115, 116], [117, 119], [120, 129], [130, 139], [140, 148], [148, 149]]}
{"doc_key": "ai-test-357", "ner": [[6, 7, "field"], [9, 10, "researcher"], [12, 13, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 6, 7, "related-to", "researches_field", false, false], [12, 13, 6, 7, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Research", "stagnated", "after", "the", "study", "of", "machine", "learning", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", ","], "sentence-detokenized": "Research stagnated after the study of machine learning by Marvin Minsky and Seymour Papert (1969),", "token2charspan": [[0, 8], [9, 18], [19, 24], [25, 28], [29, 34], [35, 37], [38, 45], [46, 54], [55, 57], [58, 64], [65, 71], [72, 75], [76, 83], [84, 90], [91, 92], [92, 96], [96, 97], [97, 98]]}
{"doc_key": "ai-test-358", "ner": [[9, 10, "programlang"], [12, 14, "product"], [16, 17, "programlang"], [19, 19, "product"], [21, 21, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "environments", "used", "to", "build", "DAQ", "applications", "are", "ladder", "logic", ",", "Visual", "C", "++", ",", "Visual", "Basic", ",", "LabVIEW", "and", "MATLAB", "."], "sentence-detokenized": "Other programming environments used to build DAQ applications are ladder logic, Visual C ++, Visual Basic, LabVIEW and MATLAB.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 38], [39, 44], [45, 48], [49, 61], [62, 65], [66, 72], [73, 78], [78, 79], [80, 86], [87, 88], [89, 91], [91, 92], [93, 99], [100, 105], [105, 106], [107, 114], [115, 118], [119, 125], [125, 126]]}
{"doc_key": "ai-test-359", "ner": [[15, 19, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "metric", "was", "designed", "to", "solve", "some", "of", "the", "problems", "found", "in", "the", "more", "popular", "BLEU", "metric", ",", "and", "also", "to", "produce", "good", "correlation", "with", "human", "judgment", "at", "the", "sentence", "or", "segment", "level", "."], "sentence-detokenized": "The metric was designed to solve some of the problems found in the more popular BLEU metric, and also to produce good correlation with human judgment at the sentence or segment level.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 37], [38, 40], [41, 44], [45, 53], [54, 59], [60, 62], [63, 66], [67, 71], [72, 79], [80, 84], [85, 91], [91, 92], [93, 96], [97, 101], [102, 104], [105, 112], [113, 117], [118, 129], [130, 134], [135, 140], [141, 149], [150, 152], [153, 156], [157, 165], [166, 168], [169, 176], [177, 182], [182, 183]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "Convolutional", "neural", "networks", "and", "Long", "Short", "Term", "Memory", "are", "often", "used", "to", "exploit", "the", "semantic", "correlations", "between", "consecutive", "video", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, Convolutional neural networks and Long Short Term Memory are often used to exploit the semantic correlations between consecutive video frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [83, 88], [89, 93], [94, 100], [101, 104], [105, 110], [111, 115], [116, 118], [119, 126], [127, 130], [131, 139], [140, 152], [153, 160], [161, 172], [173, 178], [179, 185], [185, 186]]}
{"doc_key": "ai-test-361", "ner": [[7, 7, "product"], [14, 19, "product"], [39, 39, "product"]], "ner_mapping_to_source": [1, 2, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Mass", "-", "produced", "printed", "circuit", "boards", "(", "PCBs", ")", "are", "almost", "exclusively", "manufactured", "by", "pick", "-", "and", "-", "place", "robots", ",", "usually", "with", "SCARA", "manipulators", ",", "which", "extract", "tiny", "electronic", "components", "from", "strips", "or", "trays", "and", "place", "them", "on", "PCBs", "with", "great", "accuracy", "."], "sentence-detokenized": "Mass-produced printed circuit boards (PCBs) are almost exclusively manufactured by pick-and-place robots, usually with SCARA manipulators, which extract tiny electronic components from strips or trays and place them on PCBs with great accuracy.", "token2charspan": [[0, 4], [4, 5], [5, 13], [14, 21], [22, 29], [30, 36], [37, 38], [38, 42], [42, 43], [44, 47], [48, 54], [55, 66], [67, 79], [80, 82], [83, 87], [87, 88], [88, 91], [91, 92], [92, 97], [98, 104], [104, 105], [106, 113], [114, 118], [119, 124], [125, 137], [137, 138], [139, 144], [145, 152], [153, 157], [158, 168], [169, 179], [180, 184], [185, 191], [192, 194], [195, 200], [201, 204], [205, 210], [211, 215], [216, 218], [219, 223], [224, 228], [229, 234], [235, 243], [243, 244]]}
{"doc_key": "ai-test-362", "ner": [[4, 5, "field"], [15, 15, "algorithm"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 29, "researcher"], [37, 38, "algorithm"], [40, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 4, 5, "part-of", "", false, false], [15, 15, 20, 21, "origin", "", false, false], [15, 15, 23, 24, "origin", "", false, false], [15, 15, 26, 29, "origin", "", false, false], [15, 15, 37, 38, "type-of", "", false, false], [37, 38, 40, 41, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "context", "of", "machine", "learning", ",", "where", "it", "is", "most", "commonly", "applied", "today", ",", "LDA", "was", "independently", "rediscovered", "by", "David", "Blei", ",", "Andrew", "Ng", "and", "Michael", "I", ".", "Jordan", "in", "2003", ",", "and", "proposed", "as", "a", "graphical", "model", "for", "topic", "discovery", "."], "sentence-detokenized": "In the context of machine learning, where it is most commonly applied today, LDA was independently rediscovered by David Blei, Andrew Ng and Michael I. Jordan in 2003, and proposed as a graphical model for topic discovery.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 25], [26, 34], [34, 35], [36, 41], [42, 44], [45, 47], [48, 52], [53, 61], [62, 69], [70, 75], [75, 76], [77, 80], [81, 84], [85, 98], [99, 111], [112, 114], [115, 120], [121, 125], [125, 126], [127, 133], [134, 136], [137, 140], [141, 148], [149, 150], [150, 151], [152, 158], [159, 161], [162, 166], [166, 167], [168, 171], [172, 180], [181, 183], [184, 185], [186, 195], [196, 201], [202, 205], [206, 211], [212, 221], [221, 222]]}
{"doc_key": "ai-test-363", "ner": [[9, 9, "task"], [12, 13, "misc"], [16, 16, "metrics"], [18, 18, "metrics"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 12, 13, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "measured", "performance", "on", "test", "data", "of", "eight", "naive", "WSI", "across", "different", "tauopathies", "resulted", "in", "the", "recall", ",", "precision", ",", "and", "an", "F1", "score", "of", "0.92", ",", "0.72", ",", "and", "0.81", ",", "respectively", "."], "sentence-detokenized": "The measured performance on test data of eight naive WSI across different tauopathies resulted in the recall, precision, and an F1 score of 0.92, 0.72, and 0.81, respectively.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 27], [28, 32], [33, 37], [38, 40], [41, 46], [47, 52], [53, 56], [57, 63], [64, 73], [74, 85], [86, 94], [95, 97], [98, 101], [102, 108], [108, 109], [110, 119], [119, 120], [121, 124], [125, 127], [128, 130], [131, 136], [137, 139], [140, 144], [144, 145], [146, 150], [150, 151], [152, 155], [156, 160], [160, 161], [162, 174], [174, 175]]}
{"doc_key": "ai-test-364", "ner": [[8, 9, "field"], [18, 19, "task"]], "ner_mapping_to_source": [1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Using", "advanced", "AR", "technologies", "(", "e.g.", "addition", "of", "computer", "vision", ",", "integration", "of", "AR", "cameras", "in", "smartphone", "and", "object", "recognition", ")", ",", "information", "about", "the", "user", "'s", "surrounding", "real", "world", "is", "interactively", "and", "digitally", "manipulated", "."], "sentence-detokenized": "Using advanced AR technologies (e.g. addition of computer vision, integration of AR cameras in smartphone and object recognition), information about the user's surrounding real world is interactively and digitally manipulated.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 30], [31, 32], [32, 36], [37, 45], [46, 48], [49, 57], [58, 64], [64, 65], [66, 77], [78, 80], [81, 83], [84, 91], [92, 94], [95, 105], [106, 109], [110, 116], [117, 128], [128, 129], [129, 130], [131, 142], [143, 148], [149, 152], [153, 157], [157, 159], [160, 171], [172, 176], [177, 182], [183, 185], [186, 199], [200, 203], [204, 213], [214, 225], [225, 226]]}
{"doc_key": "ai-test-365", "ner": [[3, 3, "researcher"], [8, 8, "organisation"], [16, 17, "field"], [27, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 8, "role", "forms_company", false, false], [8, 8, 16, 17, "related-to", "works_with", false, false], [8, 8, 27, 30, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2014", ",", "Schmidhuber", "founded", "a", "company", ",", "Nnaisense", ",", "to", "work", "on", "commercial", "applications", "of", "artificial", "intelligence", "in", "areas", "such", "as", "finance", ",", "heavy", "industry", "and", "self", "-", "driving", "cars", "."], "sentence-detokenized": "In 2014, Schmidhuber founded a company, Nnaisense, to work on commercial applications of artificial intelligence in areas such as finance, heavy industry and self-driving cars.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 28], [29, 30], [31, 38], [38, 39], [40, 49], [49, 50], [51, 53], [54, 58], [59, 61], [62, 72], [73, 85], [86, 88], [89, 99], [100, 112], [113, 115], [116, 121], [122, 126], [127, 129], [130, 137], [137, 138], [139, 144], [145, 153], [154, 157], [158, 162], [162, 163], [163, 170], [171, 175], [175, 176]]}
{"doc_key": "ai-test-366", "ner": [[25, 27, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Not", "only", "does", "this", "change", "the", "performance", "of", "all", "subsequent", "tests", "on", "the", "chosen", "explanatory", "model", ",", "it", "can", "also", "introduce", "bias", "and", "change", "the", "mean", "squared", "error", "in", "the", "estimation", "."], "sentence-detokenized": "Not only does this change the performance of all subsequent tests on the chosen explanatory model, it can also introduce bias and change the mean squared error in the estimation.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 18], [19, 25], [26, 29], [30, 41], [42, 44], [45, 48], [49, 59], [60, 65], [66, 68], [69, 72], [73, 79], [80, 91], [92, 97], [97, 98], [99, 101], [102, 105], [106, 110], [111, 120], [121, 125], [126, 129], [130, 136], [137, 140], [141, 145], [146, 153], [154, 159], [160, 162], [163, 166], [167, 177], [177, 178]]}
{"doc_key": "ai-test-367", "ner": [[0, 0, "misc"], [9, 10, "task"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Bigrams", "are", "used", "in", "most", "successful", "language", "models", "for", "speech", "recognition", "."], "sentence-detokenized": "Bigrams are used in most successful language models for speech recognition.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 24], [25, 35], [36, 44], [45, 51], [52, 55], [56, 62], [63, 74], [74, 75]]}
{"doc_key": "ai-test-368", "ner": [[3, 6, "field"], [8, 10, "misc"], [15, 17, "misc"], [22, 24, "organisation"], [27, 29, "misc"], [35, 38, "organisation"], [41, 43, "misc"], [49, 53, "organisation"], [57, 59, "misc"], [65, 67, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[8, 10, 3, 6, "topic", "", false, false], [15, 17, 22, 24, "origin", "", false, false], [27, 29, 35, 38, "origin", "", false, false], [41, 43, 49, 53, "origin", "", false, false], [57, 59, 65, 67, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["His", "research", "in", "cognitive", "psychology", "was", "awarded", "the", "Early", "Career", "Award", "(", "1984", ")", "and", "Boyd", "McCandless", "Award", "1986", ")", "from", "the", "American", "Psychological", "Association", ",", "the", "Troland", "Research", "Award", "(", "1993", ")", "from", "the", "National", "Academy", "of", "Sciences", ",", "the", "Henry", "Dale", "Prize", "(", "2004", ")", "from", "the", "Royal", "Institution", "of", "Great", "Britain", ",", "and", "the", "George", "Miller", "Prize", "(", "2010", ")", "from", "the", "Cognitive", "Neuroscience", "Society", "."], "sentence-detokenized": "His research in cognitive psychology was awarded the Early Career Award (1984) and Boyd McCandless Award 1986) from the American Psychological Association, the Troland Research Award (1993) from the National Academy of Sciences, the Henry Dale Prize (2004) from the Royal Institution of Great Britain, and the George Miller Prize (2010) from the Cognitive Neuroscience Society.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 25], [26, 36], [37, 40], [41, 48], [49, 52], [53, 58], [59, 65], [66, 71], [72, 73], [73, 77], [77, 78], [79, 82], [83, 87], [88, 98], [99, 104], [105, 109], [109, 110], [111, 115], [116, 119], [120, 128], [129, 142], [143, 154], [154, 155], [156, 159], [160, 167], [168, 176], [177, 182], [183, 184], [184, 188], [188, 189], [190, 194], [195, 198], [199, 207], [208, 215], [216, 218], [219, 227], [227, 228], [229, 232], [233, 238], [239, 243], [244, 249], [250, 251], [251, 255], [255, 256], [257, 261], [262, 265], [266, 271], [272, 283], [284, 286], [287, 292], [293, 300], [300, 301], [302, 305], [306, 309], [310, 316], [317, 323], [324, 329], [330, 331], [331, 335], [335, 336], [337, 341], [342, 345], [346, 355], [356, 368], [369, 376], [376, 377]]}
{"doc_key": "ai-test-369", "ner": [[1, 1, "misc"], [7, 7, "misc"], [9, 11, "product"], [15, 15, "researcher"], [17, 17, "researcher"], [24, 25, "researcher"], [27, 28, "researcher"], [30, 31, "task"], [33, 36, "researcher"], [38, 42, "researcher"], [43, 44, "task"], [46, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[1, 1, 7, 7, "named", "", false, false], [1, 1, 46, 46, "named", "", false, false], [7, 7, 15, 15, "origin", "", false, false], [7, 7, 17, 17, "origin", "", false, false], [7, 7, 30, 31, "related-to", "used_for", false, false], [9, 11, 7, 7, "usage", "", false, false], [9, 11, 43, 44, "named", "", false, false], [24, 25, 7, 7, "usage", "", false, false], [24, 25, 33, 36, "named", "same", false, false], [27, 28, 7, 7, "usage", "", false, false], [27, 28, 38, 42, "named", "same", false, false], [43, 44, 46, 46, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["An", "eigenface", "(", "The", "approach", "of", "using", "eigenfaces", "for", "face", "recognition", "systems", "was", "developed", "by", "Sirovich", "and", "Kirby", "(", "1987", ")", "and", "used", "by", "Matthew", "Turk", "and", "Alex", "Pentland", "in", "face", "classification", ".", "Turk", ",", "Matthew", "A", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "An eigenface (The approach of using eigenfaces for face recognition systems was developed by Sirovich and Kirby (1987) and used by Matthew Turk and Alex Pentland in face classification. Turk, Matthew A and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 2], [3, 12], [13, 14], [14, 17], [18, 26], [27, 29], [30, 35], [36, 46], [47, 50], [51, 55], [56, 67], [68, 75], [76, 79], [80, 89], [90, 92], [93, 101], [102, 105], [106, 111], [112, 113], [113, 117], [117, 118], [119, 122], [123, 127], [128, 130], [131, 138], [139, 143], [144, 147], [148, 152], [153, 161], [162, 164], [165, 169], [170, 184], [184, 185], [186, 190], [190, 191], [192, 199], [200, 201], [202, 205], [206, 214], [214, 215], [216, 220], [221, 222], [222, 223], [224, 228], [229, 240], [241, 246], [247, 257], [257, 258]]}
{"doc_key": "ai-test-370", "ner": [[5, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "lexical", "dictionary", "such", "as", "Word", "Net", "can", "then", "be", "used", "to", "understand", "the", "context", "."], "sentence-detokenized": "A lexical dictionary such as WordNet can then be used to understand the context.", "token2charspan": [[0, 1], [2, 9], [10, 20], [21, 25], [26, 28], [29, 33], [33, 36], [37, 40], [41, 45], [46, 48], [49, 53], [54, 56], [57, 67], [68, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-test-371", "ner": [[0, 0, "misc"], [8, 9, "misc"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "part-of", "", false, false], [8, 9, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hyponymy", "is", "the", "most", "frequently", "encoded", "relationship", "between", "synsets", "used", "in", "lexical", "databases", "such", "as", "WordNet", "."], "sentence-detokenized": "Hyponymy is the most frequently encoded relationship between synsets used in lexical databases such as WordNet.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 20], [21, 31], [32, 39], [40, 52], [53, 60], [61, 68], [69, 73], [74, 76], [77, 84], [85, 94], [95, 99], [100, 102], [103, 110], [110, 111]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [7, 8, "programlang"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 7, 8, "general-affiliation", "", false, false], [0, 0, 10, 10, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "offers", "open", "-", "source", "libraries", "in", "C", "++", "and", "Java", ",", "but", "many", "customers", "rely", "on", "libraries", "developed", "by", "the", "community", ",", "such", "as", "libraries", "that", "have", "built", "-", "in", "capabilities", "to", "retrieve", "(", "array", "-", "like", ")", "data", "from", "DAP", "servers", "."], "sentence-detokenized": "OPeNDAP offers open-source libraries in C++ and Java, but many customers rely on libraries developed by the community, such as libraries that have built-in capabilities to retrieve (array-like) data from DAP servers.", "token2charspan": [[0, 7], [8, 14], [15, 19], [19, 20], [20, 26], [27, 36], [37, 39], [40, 41], [41, 43], [44, 47], [48, 52], [52, 53], [54, 57], [58, 62], [63, 72], [73, 77], [78, 80], [81, 90], [91, 100], [101, 103], [104, 107], [108, 117], [117, 118], [119, 123], [124, 126], [127, 136], [137, 141], [142, 146], [147, 152], [152, 153], [153, 155], [156, 168], [169, 171], [172, 180], [181, 182], [182, 187], [187, 188], [188, 192], [192, 193], [194, 198], [199, 203], [204, 207], [208, 215], [215, 216]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [8, 8, "product"], [13, 13, "country"], [30, 31, "misc"], [45, 45, "organisation"], [47, 47, "product"], [49, 50, "organisation"], [51, 54, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 13, 13, "opposite", "", false, false], [8, 8, 13, 13, "artifact", "", false, false], [30, 31, 8, 8, "part-of", "", false, false], [47, 47, 45, 45, "artifact", "", false, false], [51, 54, 49, 50, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "that", "page", ",", "Samurai", "Damashii", "exaggerated", "the", "Senkousha", "as", "the", "crystallisation", "of", "China", "'s", "four", "thousand", "years", "of", "scientific", "knowledge", ",", "commented", "on", "its", "crude", "design", "(", "e.g.", "the", "Chinese", "cannon", "on", "its", "crotch", ")", ",", "and", "placed", "it", "s", "image", "between", "images", "of", "Honda", "'s", "ASIMO", "and", "Sony", "'s", "QRIO", "SDR", "-", "3X", "to", "juxtapose", "them", "."], "sentence-detokenized": "On that page, Samurai Damashii exaggerated the Senkousha as the crystallisation of China's four thousand years of scientific knowledge, commented on its crude design (e.g. the Chinese cannon on its crotch), and placed its image between images of Honda's ASIMO and Sony's QRIO SDR-3X to juxtapose them.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 21], [22, 30], [31, 42], [43, 46], [47, 56], [57, 59], [60, 63], [64, 79], [80, 82], [83, 88], [88, 90], [91, 95], [96, 104], [105, 110], [111, 113], [114, 124], [125, 134], [134, 135], [136, 145], [146, 148], [149, 152], [153, 158], [159, 165], [166, 167], [167, 171], [172, 175], [176, 183], [184, 190], [191, 193], [194, 197], [198, 204], [204, 205], [205, 206], [207, 210], [211, 217], [218, 220], [220, 221], [222, 227], [228, 235], [236, 242], [243, 245], [246, 251], [251, 253], [254, 259], [260, 263], [264, 268], [268, 270], [271, 275], [276, 279], [279, 280], [280, 282], [283, 285], [286, 295], [296, 300], [300, 301]]}
{"doc_key": "ai-test-374", "ner": [[8, 8, "algorithm"], [21, 21, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 21, 21, "part-of", "includes_functionality_of", false, false], [8, 8, 23, 23, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "also", "many", "programming", "libraries", "that", "contain", "neural", "network", "functionality", "that", "can", "be", "used", "in", "custom", "implementations", "(", "such", "as", "TensorFlow", ",", "Theano", ",", "etc.", ")", "."], "sentence-detokenized": "There are also many programming libraries that contain neural network functionality that can be used in custom implementations (such as TensorFlow, Theano, etc.).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 31], [32, 41], [42, 46], [47, 54], [55, 61], [62, 69], [70, 83], [84, 88], [89, 92], [93, 95], [96, 100], [101, 103], [104, 110], [111, 126], [127, 128], [128, 132], [133, 135], [136, 146], [146, 147], [148, 154], [154, 155], [156, 160], [160, 161], [161, 162]]}
{"doc_key": "ai-test-375", "ner": [[6, 9, "conference"], [11, 11, "organisation"], [13, 19, "conference"], [21, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", "and", "SPIE", "."], "sentence-detokenized": "He is a Fellow of the Association for Computing Machinery, IEEE, American Association for the Advancement of Science, IAPR and SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 33], [34, 37], [38, 47], [48, 57], [57, 58], [59, 63], [63, 64], [65, 73], [74, 85], [86, 89], [90, 93], [94, 105], [106, 108], [109, 116], [116, 117], [118, 122], [123, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-376", "ner": [[2, 2, "organisation"], [5, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 5, 7, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "2011", "RET", "trial", "of", "face", "-", "recognition", "cameras", "mounted", "on", "trams", "ensured", "that", "people", "banned", "from", "city", "trams", "did", "not", "sneak", "through", "anyway", "."], "sentence-detokenized": "A 2011 RET trial of face-recognition cameras mounted on trams ensured that people banned from city trams did not sneak through anyway.", "token2charspan": [[0, 1], [2, 6], [7, 10], [11, 16], [17, 19], [20, 24], [24, 25], [25, 36], [37, 44], [45, 52], [53, 55], [56, 61], [62, 69], [70, 74], [75, 81], [82, 88], [89, 93], [94, 98], [99, 104], [105, 108], [109, 112], [113, 118], [119, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-test-377", "ner": [[7, 8, "person"], [19, 20, "person"], [22, 25, "person"], [31, 32, "person"], [34, 35, "person"], [37, 38, "person"], [40, 41, "person"], [43, 44, "person"], [46, 47, "person"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "film", ",", "an", "adaptation", "of", "Cole", "Porter", "'s", "popular", "Broadway", "musical", ",", "the", "MGM", "songbird", "team", "of", "Howard", "Keel", "and", "Kathryn", "Grayson", "played", "the", "lead", "roles", ",", "supported", "by", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "and", "Tommy", "Rall", "."], "sentence-detokenized": "In the film, an adaptation of Cole Porter's popular Broadway musical, the MGM songbird team of Howard Keel and Kathryn Grayson played the lead roles, supported by Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar and Tommy Rall.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 15], [16, 26], [27, 29], [30, 34], [35, 41], [41, 43], [44, 51], [52, 60], [61, 68], [68, 69], [70, 73], [74, 77], [78, 86], [87, 91], [92, 94], [95, 101], [102, 106], [107, 110], [111, 118], [119, 126], [127, 133], [134, 137], [138, 142], [143, 148], [148, 149], [150, 159], [160, 162], [163, 166], [167, 173], [173, 174], [175, 181], [182, 186], [186, 187], [188, 193], [194, 197], [197, 198], [199, 204], [205, 213], [213, 214], [215, 219], [220, 227], [228, 231], [232, 237], [238, 242], [242, 243]]}
{"doc_key": "ai-test-378", "ner": [[20, 23, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "applications", "should", "streamline", "call", "flows", ",", "minimise", "the", "number", "of", "prompts", ",", "eliminate", "unnecessary", "repetitions", "and", "enable", "a", "comprehensive", "mixed", "-initiative", "dialogue", "system", ",", "where", "the", "caller", "can", "enter", "different", "data", "in", "a", "single", "utterance", ",", "in", "any", "order", "or", "combination", "."], "sentence-detokenized": "Such applications should streamline call flows, minimise the number of prompts, eliminate unnecessary repetitions and enable a comprehensive mixed-initiative dialogue system, where the caller can enter different data in a single utterance, in any order or combination.", "token2charspan": [[0, 4], [5, 17], [18, 24], [25, 35], [36, 40], [41, 46], [46, 47], [48, 56], [57, 60], [61, 67], [68, 70], [71, 78], [78, 79], [80, 89], [90, 101], [102, 113], [114, 117], [118, 124], [125, 126], [127, 140], [141, 146], [146, 157], [158, 166], [167, 173], [173, 174], [175, 180], [181, 184], [185, 191], [192, 195], [196, 201], [202, 211], [212, 216], [217, 219], [220, 221], [222, 228], [229, 238], [238, 239], [240, 242], [243, 246], [247, 252], [253, 255], [256, 267], [267, 268]]}
{"doc_key": "ai-test-379", "ner": [[9, 9, "algorithm"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "such", ",", "traditional", "gradient", "descent", "methods", "(", "or", "stochastic", "gradient", "descent", "methods", ")", "can", "be", "adapted", ",", "where", "instead", "of", "taking", "a", "step", "towards", "the", "gradient", "of", "the", "function", ",", "a", "step", "is", "taken", "towards", "a", "vector", "selected", "from", "the", "subgradient", "of", "the", "function", "."], "sentence-detokenized": "As such, traditional gradient descent methods (or stochastic gradient descent methods) can be adapted, where instead of taking a step towards the gradient of the function, a step is taken towards a vector selected from the subgradient of the function.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 29], [30, 37], [38, 45], [46, 47], [47, 49], [50, 60], [61, 69], [70, 77], [78, 85], [85, 86], [87, 90], [91, 93], [94, 101], [101, 102], [103, 108], [109, 116], [117, 119], [120, 126], [127, 128], [129, 133], [134, 141], [142, 145], [146, 154], [155, 157], [158, 161], [162, 170], [170, 171], [172, 173], [174, 178], [179, 181], [182, 187], [188, 195], [196, 197], [198, 204], [205, 213], [214, 218], [219, 222], [223, 234], [235, 237], [238, 241], [242, 250], [250, 251]]}
{"doc_key": "ai-test-380", "ner": [[11, 13, "metrics"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "it", "is", "assumed", "that", "the", "distortion", "is", "measured", "using", "the", "mean", "squared", "error", ",", "then", "the", "distortion", "D", ",", "given", "by", ":"], "sentence-detokenized": "If it is assumed that the distortion is measured using the mean squared error, then the distortion D, given by:", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 16], [17, 21], [22, 25], [26, 36], [37, 39], [40, 48], [49, 54], [55, 58], [59, 63], [64, 71], [72, 77], [77, 78], [79, 83], [84, 87], [88, 98], [99, 100], [100, 101], [102, 107], [108, 110], [110, 111]]}
{"doc_key": "ai-test-381", "ner": [[0, 0, "algorithm"], [6, 7, "field"], [19, 20, "task"], [22, 23, "task"], [26, 27, "task"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 7, "part-of", "", false, false], [19, 20, 0, 0, "part-of", "", false, false], [22, 23, 0, 0, "part-of", "", false, false], [26, 27, 0, 0, "part-of", "", false, false], [30, 31, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["MLPs", "were", "a", "popular", "solution", "for", "machine", "learning", "in", "the", "1980s", ",", "finding", "applications", "in", "fields", "as", "diverse", "as", "speech", "recognition", ",", "image", "recognition", ",", "and", "machine", "translation", "software", ",", "Neural", "Networks", "."], "sentence-detokenized": "MLPs were a popular solution for machine learning in the 1980s, finding applications in fields as diverse as speech recognition, image recognition, and machine translation software, Neural Networks.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 19], [20, 28], [29, 32], [33, 40], [41, 49], [50, 52], [53, 56], [57, 62], [62, 63], [64, 71], [72, 84], [85, 87], [88, 94], [95, 97], [98, 105], [106, 108], [109, 115], [116, 127], [127, 128], [129, 134], [135, 146], [146, 147], [148, 151], [152, 159], [160, 171], [172, 180], [180, 181], [182, 188], [189, 197], [197, 198]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [1, 3, "misc"], [6, 8, "university"], [16, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 8, "physical", "", false, false], [0, 0, 6, 8, "role", "", false, false], [1, 3, 0, 0, "origin", "", false, false], [16, 18, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "received", "his", "PhD", "from", "the", "University", "of", "Toronto", "in", "1979", ",", "under", "the", "supervision", "of", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen received his PhD from the University of Toronto in 1979, under the supervision of C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 22], [23, 27], [28, 31], [32, 42], [43, 45], [46, 53], [54, 56], [57, 61], [61, 62], [63, 68], [69, 72], [73, 84], [85, 87], [88, 90], [91, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [5, 7, "field"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [20, 21, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 7, "related-to", "supports", false, false], [10, 10, 5, 7, "type-of", "", true, false], [12, 12, 5, 7, "type-of", "", true, false], [14, 14, 5, 7, "type-of", "", true, false], [14, 14, 20, 21, "related-to", "converting_to", true, false], [24, 24, 5, 7, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["OpenCV", "supports", "some", "models", "from", "deep", "learning", "frameworks", "such", "as", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "after", "conversion", "to", "an", "ONNX", "model", ")", "and", "Caffe", "according", "to", "a", "defined", "list", "of", "supported", "layers", "."], "sentence-detokenized": "OpenCV supports some models from deep learning frameworks such as TensorFlow, Torch, PyTorch (after conversion to an ONNX model) and Caffe according to a defined list of supported layers.", "token2charspan": [[0, 6], [7, 15], [16, 20], [21, 27], [28, 32], [33, 37], [38, 46], [47, 57], [58, 62], [63, 65], [66, 76], [76, 77], [78, 83], [83, 84], [85, 92], [93, 94], [94, 99], [100, 110], [111, 113], [114, 116], [117, 121], [122, 127], [127, 128], [129, 132], [133, 138], [139, 148], [149, 151], [152, 153], [154, 161], [162, 166], [167, 169], [170, 179], [180, 186], [186, 187]]}
{"doc_key": "ai-test-384", "ner": [[0, 0, "researcher"], [7, 10, "organisation"], [12, 12, "organisation"], [16, 20, "organisation"], [24, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 7, 10, "role", "", false, false], [0, 0, 16, 20, "role", "", false, false], [0, 0, 24, 24, "related-to", "lectures_in", false, false], [12, 12, 7, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Christensen", "was", "previously", "founding", "president", "of", "the", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "and", "an", "IEEE", "Robotics", "and", "Automation", "Society", "Distinguished", "Lecturer", "in", "Robotics", "."], "sentence-detokenized": "Christensen was previously founding president of the European Robotics Research Network (EURON) and an IEEE Robotics and Automation Society Distinguished Lecturer in Robotics.", "token2charspan": [[0, 11], [12, 15], [16, 26], [27, 35], [36, 45], [46, 48], [49, 52], [53, 61], [62, 70], [71, 79], [80, 87], [88, 89], [89, 94], [94, 95], [96, 99], [100, 102], [103, 107], [108, 116], [117, 120], [121, 131], [132, 139], [140, 153], [154, 162], [163, 165], [166, 174], [174, 175]]}
{"doc_key": "ai-test-385", "ner": [[7, 7, "field"], [9, 11, "university"], [13, 13, "location"], [15, 19, "country"], [24, 24, "misc"], [26, 26, "field"], [29, 32, "organisation"], [34, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 11, 13, 13, "physical", "", false, false], [13, 13, 15, 19, "physical", "", false, false], [24, 24, 26, 26, "topic", "", false, false], [29, 32, 34, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "received", "his", "master", "'s", "degree", "in", "mathematics", "from", "Samarkand", "State", "University", ",", "Samarkand", ",", "Soviet", "Socialist", "Republic", "of", "Uzbekistan", "in", "1958", "and", "his", "PhD", "in", "statistics", "from", "the", "Institute", "of", "Control", "Science", ",", "Moscow", "in", "1964", "."], "sentence-detokenized": "He received his master's degree in mathematics from Samarkand State University, Samarkand, Soviet Socialist Republic of Uzbekistan in 1958 and his PhD in statistics from the Institute of Control Science, Moscow in 1964.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 22], [22, 24], [25, 31], [32, 34], [35, 46], [47, 51], [52, 61], [62, 67], [68, 78], [78, 79], [80, 89], [89, 90], [91, 97], [98, 107], [108, 116], [117, 119], [120, 130], [131, 133], [134, 138], [139, 142], [143, 146], [147, 150], [151, 153], [154, 164], [165, 169], [170, 173], [174, 183], [184, 186], [187, 194], [195, 202], [202, 203], [204, 210], [211, 213], [214, 218], [218, 219]]}
{"doc_key": "ai-test-386", "ner": [[5, 6, "organisation"], [11, 13, "product"], [30, 31, "field"], [33, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 30, 31, "usage", "", false, false], [5, 6, 33, 35, "usage", "", false, false], [11, 13, 5, 6, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "the", "work", "at", "Cycorp", "is", "increasingly", "about", "enabling", "the", "Cyc", "system", "to", "communicate", "in", "natural", "language", "with", "end", "users", "and", "assist", "in", "the", "ongoing", "knowledge", "creation", "process", "via", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "However, the work at Cycorp is increasingly about enabling the Cyc system to communicate in natural language with end users and assist in the ongoing knowledge creation process via machine learning and natural language understanding.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 30], [31, 43], [44, 49], [50, 58], [59, 62], [63, 66], [67, 73], [74, 76], [77, 88], [89, 91], [92, 99], [100, 108], [109, 113], [114, 117], [118, 123], [124, 127], [128, 134], [135, 137], [138, 141], [142, 149], [150, 159], [160, 168], [169, 176], [177, 180], [181, 188], [189, 197], [198, 201], [202, 209], [210, 218], [219, 232], [232, 233]]}
{"doc_key": "ai-test-387", "ner": [[57, 57, "metrics"], [59, 59, "metrics"], [61, 61, "metrics"], [63, 64, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "if", "the", "most", "appropriate", "classifier", "for", "the", "problem", "is", "sought", ",", "the", "training", "dataset", "is", "used", "to", "train", "the", "candidate", "algorithms", ",", "the", "validation", "dataset", "is", "used", "to", "compare", "their", "performance", "and", "decide", "which", "one", "should", "be", "taken", ",", "and", "finally", "the", "test", "dataset", "is", "used", "to", "obtain", "the", "performance", "characteristics", ",", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", ",", "F-", "measure", ",", "and", "so", "on", "."], "sentence-detokenized": "For example, if the most appropriate classifier for the problem is sought, the training dataset is used to train the candidate algorithms, the validation dataset is used to compare their performance and decide which one should be taken, and finally the test dataset is used to obtain the performance characteristics, such as accuracy, sensitivity, specificity, F-measure, and so on.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 19], [20, 24], [25, 36], [37, 47], [48, 51], [52, 55], [56, 63], [64, 66], [67, 73], [73, 74], [75, 78], [79, 87], [88, 95], [96, 98], [99, 103], [104, 106], [107, 112], [113, 116], [117, 126], [127, 137], [137, 138], [139, 142], [143, 153], [154, 161], [162, 164], [165, 169], [170, 172], [173, 180], [181, 186], [187, 198], [199, 202], [203, 209], [210, 215], [216, 219], [220, 226], [227, 229], [230, 235], [235, 236], [237, 240], [241, 248], [249, 252], [253, 257], [258, 265], [266, 268], [269, 273], [274, 276], [277, 283], [284, 287], [288, 299], [300, 315], [315, 316], [317, 321], [322, 324], [325, 333], [333, 334], [335, 346], [346, 347], [348, 359], [359, 360], [361, 363], [363, 370], [370, 371], [372, 375], [376, 378], [379, 381], [381, 382]]}
{"doc_key": "ai-test-388", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "squared", "error", "is", "0.15", "."], "sentence-detokenized": "The mean squared error is 0.15.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 25], [26, 30], [30, 31]]}
{"doc_key": "ai-test-389", "ner": [[7, 8, "misc"], [4, 4, "organisation"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 7, 8, "role", "", false, false], [13, 13, 7, 8, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1979", ",", "the", "IEEE", "organised", "a", "Micromouse", "competition", ",", "as", "featured", "in", "Spectrum", "magazine", "."], "sentence-detokenized": "In 1979, the IEEE organised a Micromouse competition, as featured in Spectrum magazine.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 27], [28, 29], [30, 40], [41, 52], [52, 53], [54, 56], [57, 65], [66, 68], [69, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-390", "ner": [[1, 2, "algorithm"], [12, 14, "task"], [16, 17, "task"], [19, 20, "task"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Gabor", "space", "is", "very", "useful", "in", "image", "processing", "applications", "such", "as", "optical", "character", "recognition", ",", "iris", "recognition", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "The Gabor space is very useful in image processing applications such as optical character recognition, iris recognition and fingerprint recognition.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 18], [19, 23], [24, 30], [31, 33], [34, 39], [40, 50], [51, 63], [64, 68], [69, 71], [72, 79], [80, 89], [90, 101], [101, 102], [103, 107], [108, 119], [120, 123], [124, 135], [136, 147], [147, 148]]}
{"doc_key": "ai-test-391", "ner": [[7, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "via", "high", "-", "level", "interfaces", "to", "Java", "and", "Tcl", "."], "sentence-detokenized": "or via high-level interfaces to Java and Tcl.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [12, 17], [18, 28], [29, 31], [32, 36], [37, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-test-392", "ner": [[10, 11, "algorithm"], [18, 18, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 18, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "recent", "research", ",", "kernel", "-", "based", "methods", "such", "as", "support", "vector", "machines", "have", "shown", "superior", "performance", "in", "supervised", "."], "sentence-detokenized": "In recent research, kernel-based methods such as support vector machines have shown superior performance in supervised.", "token2charspan": [[0, 2], [3, 9], [10, 18], [18, 19], [20, 26], [26, 27], [27, 32], [33, 40], [41, 45], [46, 48], [49, 56], [57, 63], [64, 72], [73, 77], [78, 83], [84, 92], [93, 104], [105, 107], [108, 118], [118, 119]]}
{"doc_key": "ai-test-393", "ner": [[17, 17, "misc"], [23, 23, "researcher"], [25, 25, "researcher"], [33, 33, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 33, 33, "usage", "", false, false], [25, 25, 33, 33, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "illustrate", "the", "basic", "principles", "of", "bagging", ",", "the", "following", "is", "an", "analysis", "of", "the", "relationship", "between", "ozone", "and", "temperature", "(", "data", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "analysis", "performed", "in", "R", ")", "."], "sentence-detokenized": "To illustrate the basic principles of bagging, the following is an analysis of the relationship between ozone and temperature (data from Rousseeuw and Leroy (1986), analysis performed in R).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 34], [35, 37], [38, 45], [45, 46], [47, 50], [51, 60], [61, 63], [64, 66], [67, 75], [76, 78], [79, 82], [83, 95], [96, 103], [104, 109], [110, 113], [114, 125], [126, 127], [127, 131], [132, 136], [137, 146], [147, 150], [151, 156], [157, 158], [158, 162], [162, 163], [163, 164], [165, 173], [174, 183], [184, 186], [187, 188], [188, 189], [189, 190]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [18, 18, "product"], [6, 23, "product"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[18, 18, 0, 1, "artifact", "", false, false], [6, 23, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["Denso", "Wave", "is", "a", "subsidiary", "that", "manufactures", "automatic", "identification", "products", "(", "barcode", "readers", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "Denso Wave is a subsidiary that manufactures automatic identification products (barcode readers and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 15], [16, 26], [27, 31], [32, 44], [45, 54], [55, 69], [70, 78], [79, 80], [80, 87], [88, 95], [96, 99], [100, 107], [108, 116], [116, 117], [117, 118], [119, 129], [130, 136], [137, 140], [141, 153], [154, 159], [160, 171], [171, 172]]}
{"doc_key": "ai-test-395", "ner": [[1, 4, "metrics"], [7, 9, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 4, 19, 19, "compare", "", false, false], [7, 9, 1, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Whereas", "the", "bilingual", "evaluation", "study", "simply", "calculates", "the", "precision", "of", "n-", "grams", "and", "assigns", "equal", "weight", "to", "each", ",", "NIST", "also", "calculates", "how", "informative", "a", "given", "n-", "gram", "is", "."], "sentence-detokenized": "Whereas the bilingual evaluation study simply calculates the precision of n-grams and assigns equal weight to each, NIST also calculates how informative a given n-gram is.", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 32], [33, 38], [39, 45], [46, 56], [57, 60], [61, 70], [71, 73], [74, 76], [76, 81], [82, 85], [86, 93], [94, 99], [100, 106], [107, 109], [110, 114], [114, 115], [116, 120], [121, 125], [126, 136], [137, 140], [141, 152], [153, 154], [155, 160], [161, 163], [163, 167], [168, 170], [170, 171]]}
{"doc_key": "ai-test-396", "ner": [[15, 15, "algorithm"], [17, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "particular", ",", "they", "are", "used", "in", "calculating", "the", "probability", "of", "a", "tree", "(", "in", "Bayesian", "and", "maximum", "likelihood", "approaches", "to", "tree", "estimation", ")", "and", "they", "are", "used", "to", "estimate", "the", "evolutionary", "distance", "between", "sequences", "based", "on", "the", "observed", "differences", "between", "them", "."], "sentence-detokenized": "In particular, they are used in calculating the probability of a tree (in Bayesian and maximum likelihood approaches to tree estimation) and they are used to estimate the evolutionary distance between sequences based on the observed differences between them.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 19], [20, 23], [24, 28], [29, 31], [32, 43], [44, 47], [48, 59], [60, 62], [63, 64], [65, 69], [70, 71], [71, 73], [74, 82], [83, 86], [87, 94], [95, 105], [106, 116], [117, 119], [120, 124], [125, 135], [135, 136], [137, 140], [141, 145], [146, 149], [150, 154], [155, 157], [158, 166], [167, 170], [171, 183], [184, 192], [193, 200], [201, 210], [211, 216], [217, 219], [220, 223], [224, 232], [233, 244], [245, 252], [253, 257], [257, 258]]}
{"doc_key": "ai-test-397", "ner": [[1, 3, "conference"], [22, 23, "misc"], [25, 25, "misc"], [46, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 25, 22, 23, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Audio", "Engineering", "Society", "recommends", "a", "sampling", "frequency", "of", "48", "kHz", "for", "most", "applications", ",", "but", "gives", "recognition", "to", "44.1", "kHz", "for", "Compact", "Disc", "(", "CD", ")", "and", "other", "consumer", "applications", ",", "32", "kHz", "for", "transmission", "applications", ",", "and", "96", "kHz", "for", "wider", "bandwidth", "or", "relaxed", "anti-aliasing", "filter", "ing", "."], "sentence-detokenized": "The Audio Engineering Society recommends a sampling frequency of 48 kHz for most applications, but gives recognition to 44.1 kHz for Compact Disc (CD) and other consumer applications, 32 kHz for transmission applications, and 96 kHz for wider bandwidth or relaxed anti-aliasing filter ing.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 40], [41, 42], [43, 51], [52, 61], [62, 64], [65, 67], [68, 71], [72, 75], [76, 80], [81, 93], [93, 94], [95, 98], [99, 104], [105, 116], [117, 119], [120, 124], [125, 128], [129, 132], [133, 140], [141, 145], [146, 147], [147, 149], [149, 150], [151, 154], [155, 160], [161, 169], [170, 182], [182, 183], [184, 186], [187, 190], [191, 194], [195, 207], [208, 220], [220, 221], [222, 225], [226, 228], [229, 232], [233, 236], [237, 242], [243, 252], [253, 255], [256, 263], [264, 277], [278, 284], [285, 288], [288, 289]]}
{"doc_key": "ai-test-398", "ner": [[10, 10, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sources", "for", "affectivity", "of", "words", "and", "concepts", "were", "created", "for", "WordNet", "{", "{", "cite", "journal"], "sentence-detokenized": "Sources for affectivity of words and concepts were created for WordNet {{cite journal", "token2charspan": [[0, 7], [8, 11], [12, 23], [24, 26], [27, 32], [33, 36], [37, 45], [46, 50], [51, 58], [59, 62], [63, 70], [71, 72], [72, 73], [73, 77], [78, 85]]}
{"doc_key": "ai-test-399", "ner": [[1, 3, "misc"], [20, 21, "person"], [26, 29, "person"], [34, 36, "person"], [44, 47, "organisation"], [64, 65, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[26, 29, 34, 36, "role", "acts_in", false, false], [44, 47, 34, 36, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "red", "-green", "anaglyph", ",", "audiences", "were", "shown", "three", "reels", "of", "tests", ",", "including", "countryside", "scenes", ",", "test", "shots", "of", "Marie", "Doro", ",", "a", "segment", "of", "John", "B", ".", "Mason", "playing", "some", "passages", "from", "Jim", "the", "Penman", "(", "a", "film", "released", "that", "year", "by", "Famous", "Players", "-", "Lasky", ",", "but", "not", "in", "3D", ")", ",", "Oriental", "dancers", ",", "and", "a", "reel", "of", "footage", "of", "Niagara", "Falls", "."], "sentence-detokenized": "In red-green anaglyph, audiences were shown three reels of tests, including countryside scenes, test shots of Marie Doro, a segment of John B. Mason playing some passages from Jim the Penman (a film released that year by Famous Players-Lasky, but not in 3D), Oriental dancers, and a reel of footage of Niagara Falls.", "token2charspan": [[0, 2], [3, 6], [6, 12], [13, 21], [21, 22], [23, 32], [33, 37], [38, 43], [44, 49], [50, 55], [56, 58], [59, 64], [64, 65], [66, 75], [76, 87], [88, 94], [94, 95], [96, 100], [101, 106], [107, 109], [110, 115], [116, 120], [120, 121], [122, 123], [124, 131], [132, 134], [135, 139], [140, 141], [141, 142], [143, 148], [149, 156], [157, 161], [162, 170], [171, 175], [176, 179], [180, 183], [184, 190], [191, 192], [192, 193], [194, 198], [199, 207], [208, 212], [213, 217], [218, 220], [221, 227], [228, 235], [235, 236], [236, 241], [241, 242], [243, 246], [247, 250], [251, 253], [254, 256], [256, 257], [257, 258], [259, 267], [268, 275], [275, 276], [277, 280], [281, 282], [283, 287], [288, 290], [291, 298], [299, 301], [302, 309], [310, 315], [315, 316]]}
{"doc_key": "ai-test-400", "ner": [[7, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "special", "way", "to", "perform", "maximum", "likelihood", "estimation", "for", "this", "problem", "."], "sentence-detokenized": "This is a special way to perform maximum likelihood estimation for this problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 17], [18, 21], [22, 24], [25, 32], [33, 40], [41, 51], [52, 62], [63, 66], [67, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-test-401", "ner": [[0, 4, "product"], [14, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Crawler", "-", "friendly", "Web", "Servers", ",", "and", "it", "integrates", "the", "features", "of", "sitemaps", "and", "RSS", "feeds", "into", "a", "decentralised", "mechanism", "for", "computational", "biologists", "and", "bioinformaticians", "to", "openly", "broadcast", "and", "retrieve", "meta", "-", "data", "on", "biomedical", "resources", "."], "sentence-detokenized": "Crawler-friendly Web Servers, and it integrates the features of sitemaps and RSS feeds into a decentralised mechanism for computational biologists and bioinformaticians to openly broadcast and retrieve meta-data on biomedical resources.", "token2charspan": [[0, 7], [7, 8], [8, 16], [17, 20], [21, 28], [28, 29], [30, 33], [34, 36], [37, 47], [48, 51], [52, 60], [61, 63], [64, 72], [73, 76], [77, 80], [81, 86], [87, 91], [92, 93], [94, 107], [108, 117], [118, 121], [122, 135], [136, 146], [147, 150], [151, 168], [169, 171], [172, 178], [179, 188], [189, 192], [193, 201], [202, 206], [206, 207], [207, 211], [212, 214], [215, 225], [226, 235], [235, 236]]}
{"doc_key": "ai-test-402", "ner": [[3, 12, "misc"], [14, 21, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "falls", "under", "standard", "Z39.50", "of", "the", "American", "National", "Standards", "Institute", "/", "NISO", "and", "standard", "23950", "of", "the", "International", "Organisation", "for", "Standardisation", "."], "sentence-detokenized": "It falls under standard Z39.50 of the American National Standards Institute / NISO and standard 23950 of the International Organisation for Standardisation.", "token2charspan": [[0, 2], [3, 8], [9, 14], [15, 23], [24, 30], [31, 33], [34, 37], [38, 46], [47, 55], [56, 65], [66, 75], [76, 77], [78, 82], [83, 86], [87, 95], [96, 101], [102, 104], [105, 108], [109, 122], [123, 135], [136, 139], [140, 155], [155, 156]]}
{"doc_key": "ai-test-403", "ner": [[13, 16, "misc"], [23, 23, "metrics"], [26, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "encoder", "and", "decoder", "are", "trained", "to", "take", "a", "phrase", "and", "reproduce", "the", "one", "-", "hot", "distribution", "of", "a", "corresponding", "paraphrase", "by", "minimising", "perplexity", "using", "simple", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The encoder and decoder are trained to take a phrase and reproduce the one-hot distribution of a corresponding paraphrase by minimising perplexity using simple stochastic gradient descent.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 45], [46, 52], [53, 56], [57, 66], [67, 70], [71, 74], [74, 75], [75, 78], [79, 91], [92, 94], [95, 96], [97, 110], [111, 121], [122, 124], [125, 135], [136, 146], [147, 152], [153, 159], [160, 170], [171, 179], [180, 187], [187, 188]]}
{"doc_key": "ai-test-404", "ner": [[8, 10, "task"], [12, 17, "task"], [26, 30, "task"], [32, 38, "task"], [41, 46, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "typical", "applications", "of", "pattern", "recognition", "techniques", "include", "automatic", "speech", "recognition", ",", "classification", "of", "text", "into", "different", "categories", "(", "e.g.", "spam", "/", "non-spam", "e-mails", ")", ",", "handwriting", "recognition", "on", "postal", "envelopes", ",", "automatic", "recognition", "of", "images", "of", "human", "faces", ",", "or", "handwriting", "image", "extraction", "from", "medical", "forms", "."], "sentence-detokenized": "Other typical applications of pattern recognition techniques include automatic speech recognition, classification of text into different categories (e.g. spam/ non-spam e-mails), handwriting recognition on postal envelopes, automatic recognition of images of human faces, or handwriting image extraction from medical forms.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 29], [30, 37], [38, 49], [50, 60], [61, 68], [69, 78], [79, 85], [86, 97], [97, 98], [99, 113], [114, 116], [117, 121], [122, 126], [127, 136], [137, 147], [148, 149], [149, 153], [154, 158], [158, 159], [160, 168], [169, 176], [176, 177], [177, 178], [179, 190], [191, 202], [203, 205], [206, 212], [213, 222], [222, 223], [224, 233], [234, 245], [246, 248], [249, 255], [256, 258], [259, 264], [265, 270], [270, 271], [272, 274], [275, 286], [287, 292], [293, 303], [304, 308], [309, 316], [317, 322], [322, 323]]}
{"doc_key": "ai-test-405", "ner": [[0, 2, "algorithm"], [13, 14, "field"], [16, 17, "task"], [19, 20, "task"], [22, 24, "task"], [26, 30, "task"], [32, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 14, 0, 2, "usage", "", false, false], [16, 17, 0, 2, "usage", "", false, false], [19, 20, 0, 2, "usage", "", false, false], [22, 24, 0, 2, "usage", "", false, false], [26, 30, 0, 2, "usage", "", false, false], [32, 33, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Artificial", "neural", "networks", "have", "been", "used", "for", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "board", "and", "video", "game", "playing", "and", "medical", "diagnosis", "."], "sentence-detokenized": "Artificial neural networks have been used for a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, board and video game playing and medical diagnosis.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 36], [37, 41], [42, 45], [46, 47], [48, 55], [56, 58], [59, 64], [64, 65], [66, 75], [76, 84], [85, 91], [91, 92], [93, 99], [100, 111], [111, 112], [113, 120], [121, 132], [132, 133], [134, 140], [141, 148], [149, 158], [158, 159], [160, 165], [166, 169], [170, 175], [176, 180], [181, 188], [189, 192], [193, 200], [201, 210], [210, 211]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [17, 17, "organisation"], [18, 19, "product"], [21, 21, "product"], [23, 25, "product"], [27, 27, "product"], [29, 29, "programlang"], [38, 39, "field"], [50, 50, "algorithm"], [52, 52, "algorithm"], [54, 54, "algorithm"], [58, 58, "product"], [78, 78, "product"], [80, 80, "product"], [83, 85, "product"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [29, 29, 38, 39, "related-to", "used_for", false, false], [50, 50, 29, 29, "part-of", "", true, false], [52, 52, 29, 29, "part-of", "", true, false], [54, 54, 29, 29, "part-of", "", true, false]], "relations_mapping_to_source": [0, 3, 4, 6, 8], "sentence": ["Examples", "include", "Salford", "Systems", "CART", "(", "which", "licenses", "proprietary", "code", "from", "the", "original", "CART", "authors", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "-", "source", "software", "environment", "for", "statistical", "computation", ",", "which", "includes", "several", "CART", "implementations", ",", "such", "as", "the", "rpart", ",", "party", "and", "randomForest", "packages", ")", ",", "Weka", "(", "a", "free", "and", "open", "-", "source", "data", "mining", "package", ",", "which", "includes", "many", "decision", "tree", "algorithms", ")", ",", "Orange", ",", "KNIME", ",", "the", "Microsoft", "SQL", "Server", "programming", "language", ")", "."], "sentence-detokenized": "Examples include Salford Systems CART (which licenses proprietary code from the original CART authors), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open-source software environment for statistical computation, which includes several CART implementations, such as the rpart, party and randomForest packages), Weka (a free and open-source data mining package, which includes many decision tree algorithms), Orange, KNIME, the Microsoft SQL Server programming language).", "token2charspan": [[0, 8], [9, 16], [17, 24], [25, 32], [33, 37], [38, 39], [39, 44], [45, 53], [54, 65], [66, 70], [71, 75], [76, 79], [80, 88], [89, 93], [94, 101], [101, 102], [102, 103], [104, 107], [108, 112], [113, 120], [120, 121], [122, 132], [132, 133], [134, 137], [138, 148], [149, 154], [154, 155], [156, 162], [162, 163], [164, 165], [166, 167], [167, 169], [170, 174], [174, 175], [175, 181], [182, 190], [191, 202], [203, 206], [207, 218], [219, 230], [230, 231], [232, 237], [238, 246], [247, 254], [255, 259], [260, 275], [275, 276], [277, 281], [282, 284], [285, 288], [289, 294], [294, 295], [296, 301], [302, 305], [306, 318], [319, 327], [327, 328], [328, 329], [330, 334], [335, 336], [336, 337], [338, 342], [343, 346], [347, 351], [351, 352], [352, 358], [359, 363], [364, 370], [371, 378], [378, 379], [380, 385], [386, 394], [395, 399], [400, 408], [409, 413], [414, 424], [424, 425], [425, 426], [427, 433], [433, 434], [435, 440], [440, 441], [442, 445], [446, 455], [456, 459], [460, 466], [467, 478], [479, 487], [487, 488], [488, 489]]}
{"doc_key": "ai-test-407", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "researcher"], [13, 14, "university"], [16, 17, "researcher"], [19, 22, "organisation"], [24, 24, "organisation"], [34, 36, "researcher"], [38, 40, "researcher"], [42, 44, "organisation"], [57, 62, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 10, 11, "origin", "", false, false], [0, 2, 16, 17, "origin", "", false, false], [0, 2, 34, 36, "origin", "", false, false], [0, 2, 38, 40, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [10, 11, 13, 14, "physical", "", false, false], [10, 11, 13, 14, "role", "", false, false], [16, 17, 19, 22, "physical", "", false, false], [16, 17, 19, 22, "role", "", false, false], [24, 24, 19, 22, "named", "", false, false], [34, 36, 42, 44, "physical", "", false, false], [34, 36, 42, 44, "role", "", false, false], [38, 40, 42, 44, "physical", "", false, false], [38, 40, 42, 44, "role", "", false, false], [57, 62, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", "was", "first", "developed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", ",", "and", "then", "further", "developed", "by", "Bishnu", "S.", "Atal", "and", "Manfred", "R.", "Schroeder", "at", "Bell", "Labs", "in", "the", "early", "and", "mid-1970s", ",", "and", "became", "a", "basis", "for", "the", "first", "speech", "synthesiser", "DSP", "chips", "in", "the", "late", "1970s", "."], "sentence-detokenized": "Linear predictive coding (LPC) was first developed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966, and then further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs in the early and mid-1970s, and became a basis for the first speech synthesiser DSP chips in the late 1970s.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 40], [41, 50], [51, 53], [54, 62], [63, 70], [71, 73], [74, 80], [81, 91], [92, 95], [96, 101], [102, 107], [108, 110], [111, 117], [118, 127], [128, 131], [132, 141], [142, 143], [143, 146], [146, 147], [148, 150], [151, 155], [155, 156], [157, 160], [161, 165], [166, 173], [174, 183], [184, 186], [187, 193], [194, 196], [197, 201], [202, 205], [206, 213], [214, 216], [217, 226], [227, 229], [230, 234], [235, 239], [240, 242], [243, 246], [247, 252], [253, 256], [257, 266], [266, 267], [268, 271], [272, 278], [279, 280], [281, 286], [287, 290], [291, 294], [295, 300], [301, 307], [308, 319], [320, 323], [324, 329], [330, 332], [333, 336], [337, 341], [342, 347], [347, 348]]}
{"doc_key": "ai-test-408", "ner": [[1, 3, "metrics"], [8, 8, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 1, 3, "part-of", "", false, false], [10, 10, 1, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "F", "-", "score", "is", "a", "combination", "of", "precision", "and", "recall", ",", "and", "provides", "a", "single", "score", "."], "sentence-detokenized": "An F-score is a combination of precision and recall, and provides a single score.", "token2charspan": [[0, 2], [3, 4], [4, 5], [5, 10], [11, 13], [14, 15], [16, 27], [28, 30], [31, 40], [41, 44], [45, 51], [51, 52], [53, 56], [57, 65], [66, 67], [68, 74], [75, 80], [80, 81]]}
{"doc_key": "ai-test-409", "ner": [[8, 11, "task"], [16, 17, "product"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Image", "analysis", "tasks", "can", "be", "as", "simple", "as", "reading", "barcode", "d", "tags", "or", "as", "advanced", "as", "facial", "recognition", "."], "sentence-detokenized": "Image analysis tasks can be as simple as reading barcode d tags or as advanced as facial recognition.", "token2charspan": [[0, 5], [6, 14], [15, 20], [21, 24], [25, 27], [28, 30], [31, 37], [38, 40], [41, 48], [49, 56], [57, 58], [59, 63], [64, 66], [67, 69], [70, 78], [79, 81], [82, 88], [89, 100], [100, 101]]}
{"doc_key": "ai-test-410", "ner": [[5, 8, "algorithm"], [26, 27, "algorithm"], [34, 36, "algorithm"], [39, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[34, 36, 26, 27, "type-of", "", false, false], [39, 39, 34, 36, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "special", "case", "of", "linear", "support", "-", "vector", "machines", "can", "be", "solved", "more", "efficiently", "with", "the", "same", "kind", "of", "algorithms", "to", "optimise", "its", "close", "cousin", ",", "logistic", "regression", ";", "this", "class", "of", "algorithms", "includes", "Stochastic", "gradient", "descent", "(", "e.g.", "PEGASOS", ")", "."], "sentence-detokenized": "The special case of linear support-vector machines can be solved more efficiently with the same kind of algorithms to optimise its close cousin, logistic regression; this class of algorithms includes Stochastic gradient descent (e.g. PEGASOS).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 34], [34, 35], [35, 41], [42, 50], [51, 54], [55, 57], [58, 64], [65, 69], [70, 81], [82, 86], [87, 90], [91, 95], [96, 100], [101, 103], [104, 114], [115, 117], [118, 126], [127, 130], [131, 136], [137, 143], [143, 144], [145, 153], [154, 164], [164, 165], [166, 170], [171, 176], [177, 179], [180, 190], [191, 199], [200, 210], [211, 219], [220, 227], [228, 229], [229, 233], [234, 241], [241, 242], [242, 243]]}
{"doc_key": "ai-test-411", "ner": [[1, 1, "product"], [25, 25, "product"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "Siri", "on", "an", "iOS", "device", "is", "asked", "Do", "you", "have", "a", "pet", ",", "one", "of", "the", "answers", "is", ":", "I", "used", "to", "have", "an", "AIBO", "."], "sentence-detokenized": "When Siri on an iOS device is asked Do you have a pet, one of the answers is: I used to have an AIBO.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 15], [16, 19], [20, 26], [27, 29], [30, 35], [36, 38], [39, 42], [43, 47], [48, 49], [50, 53], [53, 54], [55, 58], [59, 61], [62, 65], [66, 73], [74, 76], [76, 77], [78, 79], [80, 84], [85, 87], [88, 92], [93, 95], [96, 100], [100, 101]]}
{"doc_key": "ai-test-412", "ner": [[1, 8, "task"], [4, 6, "metrics"], [9, 9, "metrics"], [12, 12, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 1, 8, "part-of", "", false, false], [9, 9, 4, 6, "named", "", false, false], [12, 12, 1, 8, "part-of", "", false, false], [13, 13, 12, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "information", "retrieval", ",", "positive", "predictive", "value", "is", "called", "precision", ",", "and", "sensitivity", "recall", "."], "sentence-detokenized": "In information retrieval, positive predictive value is called precision, and sensitivity recall.", "token2charspan": [[0, 2], [3, 14], [15, 24], [24, 25], [26, 34], [35, 45], [46, 51], [52, 54], [55, 61], [62, 71], [71, 72], [73, 76], [77, 88], [89, 95], [95, 96]]}
{"doc_key": "ai-test-413", "ner": [[10, 11, "field"], [13, 13, "task"], [15, 15, "task"], [17, 18, "task"], [32, 33, "task"], [35, 36, "task"], [38, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 13, 10, 11, "part-of", "task_part_of_field", false, false], [15, 15, 10, 11, "part-of", "task_part_of_field", false, false], [17, 18, 10, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "particular", ",", "his", "research", "focused", "on", "areas", "such", "as", "text", "mining", "(", "extraction", ",", "categorisation", ",", "novelty", "detection", ")", "and", "new", "theoretical", "frameworks", "such", "as", "a", "unified", "utility", "theory", "that", "bridges", "information", "retrieval", ",", "automatic", "summaries", ",", "free", "-", "text", "query", "answering", "and", "related", "tasks", "."], "sentence-detokenized": "In particular, his research focused on areas such as text mining (extraction, categorisation, novelty detection) and new theoretical frameworks such as a unified utility theory that bridges information retrieval, automatic summaries, free-text query answering and related tasks.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 27], [28, 35], [36, 38], [39, 44], [45, 49], [50, 52], [53, 57], [58, 64], [65, 66], [66, 76], [76, 77], [78, 92], [92, 93], [94, 101], [102, 111], [111, 112], [113, 116], [117, 120], [121, 132], [133, 143], [144, 148], [149, 151], [152, 153], [154, 161], [162, 169], [170, 176], [177, 181], [182, 189], [190, 201], [202, 211], [211, 212], [213, 222], [223, 232], [232, 233], [234, 238], [238, 239], [239, 243], [244, 249], [250, 259], [260, 263], [264, 271], [272, 277], [277, 278]]}
{"doc_key": "ai-test-414", "ner": [[0, 0, "product"], [6, 7, "product"], [9, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 0, "part-of", "", false, false], [9, 18, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Delta", "robots", "have", "base", "-", "mounted", "rotary", "actuators", "that", "move", "a", "lightweight", ",", "rigid", ",", "parallelogram", "-", "shaped", "arm", "."], "sentence-detokenized": "Delta robots have base-mounted rotary actuators that move a lightweight, rigid, parallelogram-shaped arm.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 22], [22, 23], [23, 30], [31, 37], [38, 47], [48, 52], [53, 57], [58, 59], [60, 71], [71, 72], [73, 78], [78, 79], [80, 93], [93, 94], [94, 100], [101, 104], [104, 105]]}
{"doc_key": "ai-test-415", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "outcomes", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four outcomes can be formulated in a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 24], [25, 35], [36, 38], [39, 40], [41, 42], [43, 44], [45, 46], [47, 58], [59, 64], [65, 67], [68, 77], [78, 84], [85, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-416", "ner": [[30, 31, "task"], [37, 38, "task"], [43, 45, "task"], [47, 49, "task"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "actual", "data", "mining", "task", "is", "the", "semi-automatic", "or", "automatic", "analysis", "of", "large", "amounts", "of", "data", "to", "extract", "unknown", ",", "interesting", "patterns", ",", "such", "as", "groups", "of", "data", "records", "(", "cluster", "analysis", ")", ",", "unusual", "records", "(", "anomaly", "detection", ")", "and", "dependencies", "(", "association", "rule", "mining", ",", "sequential", "pattern", "mining", ")", "."], "sentence-detokenized": "The actual data mining task is the semi-automatic or automatic analysis of large amounts of data to extract unknown, interesting patterns, such as groups of data records (cluster analysis), unusual records (anomaly detection) and dependencies (association rule mining, sequential pattern mining).", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 22], [23, 27], [28, 30], [31, 34], [35, 49], [50, 52], [53, 62], [63, 71], [72, 74], [75, 80], [81, 88], [89, 91], [92, 96], [97, 99], [100, 107], [108, 115], [115, 116], [117, 128], [129, 137], [137, 138], [139, 143], [144, 146], [147, 153], [154, 156], [157, 161], [162, 169], [170, 171], [171, 178], [179, 187], [187, 188], [188, 189], [190, 197], [198, 205], [206, 207], [207, 214], [215, 224], [224, 225], [226, 229], [230, 242], [243, 244], [244, 255], [256, 260], [261, 267], [267, 268], [269, 279], [280, 287], [288, 294], [294, 295], [295, 296]]}
{"doc_key": "ai-test-417", "ner": [[2, 3, "product"], [5, 6, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 5, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "a", "recommendation", "system", ",", "sentiment", "analysis", "has", "proven", "to", "be", "a", "valuable", "technique", "."], "sentence-detokenized": "For a recommendation system, sentiment analysis has proven to be a valuable technique.", "token2charspan": [[0, 3], [4, 5], [6, 20], [21, 27], [27, 28], [29, 38], [39, 47], [48, 51], [52, 58], [59, 61], [62, 64], [65, 66], [67, 75], [76, 85], [85, 86]]}
{"doc_key": "ai-test-418", "ner": [[3, 3, "misc"], [37, 38, "location"]], "ner_mapping_to_source": [0, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Coincidentally", ",", "the", "Germans", "had", "chosen", "the", "working", "frequency", "of", "the", "Wotan", "system", "very", "badly", ";", "it", "operated", "on", "45", "MHz", ",", "which", "happened", "to", "be", "the", "frequency", "of", "the", "powerful", "but", "dormant", "BBC", "television", "station", "in", "Alexandra", "Palace", "."], "sentence-detokenized": "Coincidentally, the Germans had chosen the working frequency of the Wotan system very badly; it operated on 45 MHz, which happened to be the frequency of the powerful but dormant BBC television station in Alexandra Palace.", "token2charspan": [[0, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 50], [51, 60], [61, 63], [64, 67], [68, 73], [74, 80], [81, 85], [86, 91], [91, 92], [93, 95], [96, 104], [105, 107], [108, 110], [111, 114], [114, 115], [116, 121], [122, 130], [131, 133], [134, 136], [137, 140], [141, 150], [151, 153], [154, 157], [158, 166], [167, 170], [171, 178], [179, 182], [183, 193], [194, 201], [202, 204], [205, 214], [215, 221], [221, 222]]}
{"doc_key": "ai-test-419", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "outcomes", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four outcomes can be formulated in a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 24], [25, 35], [36, 38], [39, 40], [41, 42], [43, 44], [45, 46], [47, 58], [59, 64], [65, 67], [68, 77], [78, 84], [85, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-420", "ner": [[1, 3, "misc"], [11, 11, "misc"], [14, 14, "product"], [16, 16, "product"], [18, 20, "product"], [28, 28, "misc"], [36, 38, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 14, 11, 11, "usage", "", false, false], [16, 16, 11, 11, "usage", "", false, false], [18, 20, 16, 16, "named", "", false, false], [28, 28, 11, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "Semantic", "Web", "applications", ",", "and", "in", "relatively", "popular", "applications", "of", "RDF", "such", "as", "RSS", "and", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "resources", "are", "usually", "represented", "by", "URIs", "that", "intentionally", "designate", "current", "data", "on", "the", "World", "Wide", "Web", ",", "and", "can", "be", "used", "to", "access", "them", "."], "sentence-detokenized": "In Semantic Web applications, and in relatively popular applications of RDF such as RSS and FOAF (Friend a Friend), resources are usually represented by URIs that intentionally designate current data on the World Wide Web, and can be used to access them.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 28], [28, 29], [30, 33], [34, 36], [37, 47], [48, 55], [56, 68], [69, 71], [72, 75], [76, 80], [81, 83], [84, 87], [88, 91], [92, 96], [97, 98], [98, 104], [105, 106], [107, 113], [113, 114], [114, 115], [116, 125], [126, 129], [130, 137], [138, 149], [150, 152], [153, 157], [158, 162], [163, 176], [177, 186], [187, 194], [195, 199], [200, 202], [203, 206], [207, 212], [213, 217], [218, 221], [221, 222], [223, 226], [227, 230], [231, 233], [234, 238], [239, 241], [242, 248], [249, 253], [253, 254]]}
{"doc_key": "ai-test-421", "ner": [[1, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "has", "studied", "this", "topic", "in", "depth"], "sentence-detokenized": "The Association for the Advancement of Artificial Intelligence has studied this topic in depth", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 74], [75, 79], [80, 85], [86, 88], [89, 94]]}
{"doc_key": "ai-test-422", "ner": [[5, 9, "product"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 17, 5, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starting", "as", "a", "curiosity", ",", "Apple", "Macintosh", "'s", "speech", "system", "has", "evolved", "into", "a", "fully", "supported", "application", "PlainTalk", ",", "for", "people", "with", "sight", "problems", "."], "sentence-detokenized": "Starting as a curiosity, Apple Macintosh's speech system has evolved into a fully supported application PlainTalk, for people with sight problems.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 23], [23, 24], [25, 30], [31, 40], [40, 42], [43, 49], [50, 56], [57, 60], [61, 68], [69, 73], [74, 75], [76, 81], [82, 91], [92, 103], [104, 113], [113, 114], [115, 118], [119, 125], [126, 130], [131, 136], [137, 145], [145, 146]]}
{"doc_key": "ai-test-423", "ner": [[6, 6, "field"], [8, 9, "task"], [11, 12, "task"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 6, 6, "part-of", "task_part_of_field", false, false], [11, 12, 6, 6, "part-of", "task_part_of_field", false, false], [14, 15, 6, 6, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "application", "areas", "for", "ontologies", "within", "NLP", "include", "information", "retrieval", ",", "information", "extraction", "and", "automatic", "summaries", "."], "sentence-detokenized": "Other application areas for ontologies within NLP include information retrieval, information extraction and automatic summaries.", "token2charspan": [[0, 5], [6, 17], [18, 23], [24, 27], [28, 38], [39, 45], [46, 49], [50, 57], [58, 69], [70, 79], [79, 80], [81, 92], [93, 103], [104, 107], [108, 117], [118, 127], [127, 128]]}
{"doc_key": "ai-test-424", "ner": [[6, 13, "organisation"], [16, 20, "organisation"], [23, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "institute", "has", "worked", "closely", "with", "Howard", "Hughes", "Medical", "Institute", "'s", "Janelia", "Farm", "Campus", ",", "the", "Allen", "Institute", "for", "Brain", "Science", "and", "the", "National", "Institutes", "of", "Health", "to", "develop", "better", "methods", "for", "reconstructing", "neuronal", "architectures", "."], "sentence-detokenized": "The institute has worked closely with Howard Hughes Medical Institute's Janelia Farm Campus, the Allen Institute for Brain Science and the National Institutes of Health to develop better methods for reconstructing neuronal architectures.", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 24], [25, 32], [33, 37], [38, 44], [45, 51], [52, 59], [60, 69], [69, 71], [72, 79], [80, 84], [85, 91], [91, 92], [93, 96], [97, 102], [103, 112], [113, 116], [117, 122], [123, 130], [131, 134], [135, 138], [139, 147], [148, 158], [159, 161], [162, 168], [169, 171], [172, 179], [180, 186], [187, 194], [195, 198], [199, 213], [214, 222], [223, 236], [236, 237]]}
{"doc_key": "ai-test-425", "ner": [[2, 2, "organisation"], [5, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 2, 2, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Recently", ",", "Google", "announced", "that", "Google", "Translate", "translates", "about", "enough", "text", "to", "fill", "1", "million", "books", "in", "one", "day", "(", "2012", ")", "."], "sentence-detokenized": "Recently, Google announced that Google Translate translates about enough text to fill 1 million books in one day (2012).", "token2charspan": [[0, 8], [8, 9], [10, 16], [17, 26], [27, 31], [32, 38], [39, 48], [49, 59], [60, 65], [66, 72], [73, 77], [78, 80], [81, 85], [86, 87], [88, 95], [96, 101], [102, 104], [105, 108], [109, 112], [113, 114], [114, 118], [118, 119], [119, 120]]}
{"doc_key": "ai-test-426", "ner": [[10, 10, "country"], [12, 13, "country"], [15, 15, "country"], [17, 17, "country"], [19, 19, "country"], [21, 22, "country"], [33, 34, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Events", "are", "held", "worldwide", "and", "are", "most", "popular", "in", "the", "UK", ",", "the", "US", ",", "Japan", ",", "Singapore", ",", "India", ",", "South", "Korea", "and", "are", "becoming", "increasingly", "popular", "in", "sub-continental", "countries", "such", "as", "Sri", "Lanka", "."], "sentence-detokenized": "Events are held worldwide and are most popular in the UK, the US, Japan, Singapore, India, South Korea and are becoming increasingly popular in sub-continental countries such as Sri Lanka.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 25], [26, 29], [30, 33], [34, 38], [39, 46], [47, 49], [50, 53], [54, 56], [56, 57], [58, 61], [62, 64], [64, 65], [66, 71], [71, 72], [73, 82], [82, 83], [84, 89], [89, 90], [91, 96], [97, 102], [103, 106], [107, 110], [111, 119], [120, 132], [133, 140], [141, 143], [144, 159], [160, 169], [170, 174], [175, 177], [178, 181], [182, 187], [187, 188]]}
{"doc_key": "ai-test-427", "ner": [[6, 6, "programlang"], [11, 11, "programlang"], [13, 13, "programlang"], [15, 17, "programlang"], [20, 20, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "developed", "mainly", "in", "R", ",", "and", "sometimes", "in", "Java", ",", "C", ",", "C", "+", "+", ",", "and", "Fortran", "."], "sentence-detokenized": "These packages are developed mainly in R, and sometimes in Java, C, C + +, and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 28], [29, 35], [36, 38], [39, 40], [40, 41], [42, 45], [46, 55], [56, 58], [59, 63], [63, 64], [65, 66], [66, 67], [68, 69], [70, 71], [72, 73], [73, 74], [75, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-test-428", "ner": [[4, 9, "conference"], [11, 11, "conference"], [14, 14, "researcher"], [16, 16, "researcher"], [20, 21, "researcher"], [23, 25, "algorithm"], [30, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 11, 4, 9, "named", "", false, false], [14, 14, 4, 9, "physical", "", false, false], [14, 14, 4, 9, "role", "", false, false], [14, 14, 20, 21, "role", "teams_up_with", false, false], [14, 14, 23, 25, "usage", "", false, false], [16, 16, 4, 9, "physical", "", false, false], [16, 16, 4, 9, "role", "", false, false], [16, 16, 20, 21, "role", "teams_up_with", false, false], [16, 16, 23, 25, "usage", "", false, false], [20, 21, 4, 9, "physical", "", false, false], [20, 21, 4, 9, "role", "", false, false], [20, 21, 23, 25, "usage", "", false, false], [23, 25, 30, 35, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["As", "part", "of", "the", "2006", "European", "Conference", "on", "Computer", "Vision", "(", "ECCV", ")", ",", "Dalal", "and", "Triggs", ",", "together", "with", "Cordelia", "Schmid", ",", "applied", "HOG", "detectors", "to", "the", "problem", "of", "human", "detection", "in", "films", "and", "videos", "."], "sentence-detokenized": "As part of the 2006 European Conference on Computer Vision (ECCV), Dalal and Triggs, together with Cordelia Schmid, applied HOG detectors to the problem of human detection in films and videos.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 19], [20, 28], [29, 39], [40, 42], [43, 51], [52, 58], [59, 60], [60, 64], [64, 65], [65, 66], [67, 72], [73, 76], [77, 83], [83, 84], [85, 93], [94, 98], [99, 107], [108, 114], [114, 115], [116, 123], [124, 127], [128, 137], [138, 140], [141, 144], [145, 152], [153, 155], [156, 161], [162, 171], [172, 174], [175, 180], [181, 184], [185, 191], [191, 192]]}
{"doc_key": "ai-test-429", "ner": [[1, 1, "metrics"], [3, 3, "metrics"], [9, 9, "task"], [17, 19, "metrics"], [21, 21, "metrics"], [27, 27, "metrics"], [31, 33, "metrics"], [35, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 1, 9, 9, "related-to", "measured_with", false, false], [3, 3, 9, 9, "related-to", "measured_with", false, false], [17, 19, 9, 9, "related-to", "measured_with", false, false], [21, 21, 17, 19, "named", "", false, false], [27, 27, 17, 19, "named", "", false, false], [35, 35, 31, 33, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Besides", "sensitivity", "and", "specificity", ",", "the", "performance", "of", "a", "binary", "classification", "test", "can", "be", "measured", "by", "the", "positive", "predictive", "value", "(", "PPV", ")", ",", "also", "known", "as", "precision", ",", "and", "the", "negative", "predictive", "value", "(", "NPV", ")", "."], "sentence-detokenized": "Besides sensitivity and specificity, the performance of a binary classification test can be measured by the positive predictive value (PPV), also known as precision, and the negative predictive value (NPV).", "token2charspan": [[0, 7], [8, 19], [20, 23], [24, 35], [35, 36], [37, 40], [41, 52], [53, 55], [56, 57], [58, 64], [65, 79], [80, 84], [85, 88], [89, 91], [92, 100], [101, 103], [104, 107], [108, 116], [117, 127], [128, 133], [134, 135], [135, 138], [138, 139], [139, 140], [141, 145], [146, 151], [152, 154], [155, 164], [164, 165], [166, 169], [170, 173], [174, 182], [183, 193], [194, 199], [200, 201], [201, 204], [204, 205], [205, 206]]}
{"doc_key": "ai-test-430", "ner": [[14, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "models", "may", "give", "partial", "credit", "for", "overlapping", "agreements", "(", "such", "as", "using", "the", "Jaccard", "index", "criterion", "."], "sentence-detokenized": "Such models may give partial credit for overlapping agreements (such as using the Jaccard index criterion.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 28], [29, 35], [36, 39], [40, 51], [52, 62], [63, 64], [64, 68], [69, 71], [72, 77], [78, 81], [82, 89], [90, 95], [96, 105], [105, 106]]}
{"doc_key": "ai-test-431", "ner": [[20, 25, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Furthermore", ",", "in", "the", "case", "of", "single", "-", "sample", "estimation", ",", "philosophical", "issues", "and", "possible", "misunderstandings", "in", "the", "use", "of", "maximum", "likelihood", "estimators", "and", "likelihood", "functions", "are", "revealed", "."], "sentence-detokenized": "Furthermore, in the case of single-sample estimation, philosophical issues and possible misunderstandings in the use of maximum likelihood estimators and likelihood functions are revealed.", "token2charspan": [[0, 11], [11, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 34], [34, 35], [35, 41], [42, 52], [52, 53], [54, 67], [68, 74], [75, 78], [79, 87], [88, 105], [106, 108], [109, 112], [113, 116], [117, 119], [120, 127], [128, 138], [139, 149], [150, 153], [154, 164], [165, 174], [175, 178], [179, 187], [187, 188]]}
