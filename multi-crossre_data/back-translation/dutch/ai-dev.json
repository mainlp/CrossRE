{"doc_key": "ai-dev-1", "ner": [[2, 2, "metrics"], [7, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 2, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Here", ",", "accuracy", "is", "measured", "by", "the", "error", "rate", ",", "which", "is", "defined", "as", ":"], "sentence-detokenized": "Here, accuracy is measured by the error rate, which is defined as:", "token2charspan": [[0, 4], [4, 5], [6, 14], [15, 17], [18, 26], [27, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 51], [52, 54], [55, 62], [63, 65], [65, 66]]}
{"doc_key": "ai-dev-2", "ner": [[6, 9, "algorithm"], [13, 14, "misc"], [18, 21, "algorithm"], [22, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 9, 13, 14, "type-of", "", false, false], [6, 9, 18, 21, "related-to", "", false, false], [6, 9, 22, 23, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["From", "this", "point", "of", "view", ",", "SVM", "is", "closely", "related", "to", "other", "fundamental", "classification", "algorithms", ",", "such", "as", "regularised", "least", "-", "squares", "logistic", "regression", "."], "sentence-detokenized": "From this point of view, SVM is closely related to other fundamental classification algorithms, such as regularised least-squares logistic regression.", "token2charspan": [[0, 4], [5, 9], [10, 15], [16, 18], [19, 23], [23, 24], [25, 28], [29, 31], [32, 39], [40, 47], [48, 50], [51, 56], [57, 68], [69, 83], [84, 94], [94, 95], [96, 100], [101, 103], [104, 115], [116, 121], [121, 122], [122, 129], [130, 138], [139, 149], [149, 150]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [3, 4, "person"], [14, 15, "person"], [17, 17, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 0, 1, "named", "actor_plays_character", false, false], [3, 4, 0, 1, "origin", "actor_plays_character", false, false], [17, 17, 14, 15, "named", "actor_plays_character", false, false], [17, 17, 14, 15, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "portrays", "Leon", "Kowalski", ",", "a", "replicant", "who", "fights", "and", "works", ",", "and", "Joanna", "Cassidy", "portrays", "Zhora", ",", "a", "replicant", "who", "is", "an", "assassin", "for", "hire", "."], "sentence-detokenized": "Brion James portrays Leon Kowalski, a replicant who fights and works, and Joanna Cassidy portrays Zhora, a replicant who is an assassin for hire.", "token2charspan": [[0, 5], [6, 11], [12, 20], [21, 25], [26, 34], [34, 35], [36, 37], [38, 47], [48, 51], [52, 58], [59, 62], [63, 68], [68, 69], [70, 73], [74, 80], [81, 88], [89, 97], [98, 103], [103, 104], [105, 106], [107, 116], [117, 120], [121, 123], [124, 126], [127, 135], [136, 139], [140, 144], [144, 145]]}
{"doc_key": "ai-dev-4", "ner": [[16, 19, "product"], [21, 21, "product"], [14, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 19, 14, 14, "physical", "", false, false], [21, 21, 16, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "image", "scanned", ",", "stored", "and", "recreated", "in", "digital", "pixels", "was", "displayed", "on", "NIST", "'s", "Standard", "Eastern", "Automatic", "Computer", "(", "SEAC", ")", "."], "sentence-detokenized": "The first image scanned, stored and recreated in digital pixels was displayed on NIST's Standard Eastern Automatic Computer (SEAC).", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [23, 24], [25, 31], [32, 35], [36, 45], [46, 48], [49, 56], [57, 63], [64, 67], [68, 77], [78, 80], [81, 85], [85, 87], [88, 96], [97, 104], [105, 114], [115, 123], [124, 125], [125, 129], [129, 130], [130, 131]]}
{"doc_key": "ai-dev-5", "ner": [[0, 6, "task"], [20, 21, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 20, 21, "part-of", "", false, false], [0, 6, 23, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Segmenting", "the", "text", "into", "topics", "or", "discourses", "can", "be", "useful", "for", "some", "natural", "processing", "tasks", ":", "it", "can", "significantly", "improve", "information", "retrieval", "or", "speech", "recognition", "(", "by", "indexing", "/", "recognising", "documents", "more", "accurately", "or", "providing", "the", "specific", "part", "of", "a", "document", "that", "matches", "the", "query", "as", "a", "result", ")", "."], "sentence-detokenized": "Segmenting the text into topics or discourses can be useful for some natural processing tasks: it can significantly improve information retrieval or speech recognition (by indexing/recognising documents more accurately or providing the specific part of a document that matches the query as a result).", "token2charspan": [[0, 10], [11, 14], [15, 19], [20, 24], [25, 31], [32, 34], [35, 45], [46, 49], [50, 52], [53, 59], [60, 63], [64, 68], [69, 76], [77, 87], [88, 93], [93, 94], [95, 97], [98, 101], [102, 115], [116, 123], [124, 135], [136, 145], [146, 148], [149, 155], [156, 167], [168, 169], [169, 171], [172, 180], [180, 181], [181, 192], [193, 202], [203, 207], [208, 218], [219, 221], [222, 231], [232, 235], [236, 244], [245, 249], [250, 252], [253, 254], [255, 263], [264, 268], [269, 276], [277, 280], [281, 286], [287, 289], [290, 291], [292, 298], [298, 299], [299, 300]]}
{"doc_key": "ai-dev-6", "ner": [[9, 10, "university"], [23, 24, "conference"], [26, 27, "university"], [36, 37, "researcher"], [39, 40, "researcher"], [42, 43, "researcher"], [45, 46, "researcher"], [48, 49, "researcher"], [51, 52, "researcher"], [54, 56, "researcher"], [58, 59, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[23, 24, 26, 27, "physical", "", false, false], [36, 37, 23, 24, "physical", "", false, false], [36, 37, 23, 24, "role", "", false, false], [36, 37, 23, 24, "temporal", "", false, false], [39, 40, 23, 24, "physical", "", false, false], [39, 40, 23, 24, "role", "", false, false], [39, 40, 23, 24, "temporal", "", false, false], [42, 43, 23, 24, "physical", "", false, false], [42, 43, 23, 24, "role", "", false, false], [42, 43, 23, 24, "temporal", "", false, false], [45, 46, 23, 24, "physical", "", false, false], [45, 46, 23, 24, "role", "", false, false], [45, 46, 23, 24, "temporal", "", false, false], [48, 49, 23, 24, "physical", "", false, false], [48, 49, 23, 24, "role", "", false, false], [48, 49, 23, 24, "temporal", "", false, false], [51, 52, 23, 24, "physical", "", false, false], [51, 52, 23, 24, "role", "", false, false], [51, 52, 23, 24, "temporal", "", false, false], [54, 56, 23, 24, "physical", "", false, false], [54, 56, 23, 24, "role", "", false, false], [54, 56, 23, 24, "temporal", "", false, false], [58, 59, 23, 24, "physical", "", false, false], [58, 59, 23, 24, "role", "", false, false], [58, 59, 23, 24, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["In", "1999", ",", "he", "organised", "a", "similar", "symposium", "at", "Indiana", "University", ",", "and", "in", "April", "2000", ",", "he", "organised", "a", "larger", "symposium", "entitled", "Spiritual", "Robots", "at", "Stanford", "University", ",", "where", "he", "moderated", "a", "panel", "consisting", "of", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", "and", "John", "Koza", "."], "sentence-detokenized": "In 1999, he organised a similar symposium at Indiana University, and in April 2000, he organised a larger symposium entitled Spiritual Robots at Stanford University, where he moderated a panel consisting of Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland and John Koza.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 21], [22, 23], [24, 31], [32, 41], [42, 44], [45, 52], [53, 63], [63, 64], [65, 68], [69, 71], [72, 77], [78, 82], [82, 83], [84, 86], [87, 96], [97, 98], [99, 105], [106, 115], [116, 124], [125, 134], [135, 141], [142, 144], [145, 153], [154, 164], [164, 165], [166, 171], [172, 174], [175, 184], [185, 186], [187, 192], [193, 203], [204, 206], [207, 210], [211, 219], [219, 220], [221, 225], [226, 233], [233, 234], [235, 240], [241, 246], [246, 247], [248, 253], [254, 260], [260, 261], [262, 266], [267, 270], [270, 271], [272, 277], [278, 283], [283, 284], [285, 289], [290, 295], [296, 303], [304, 307], [308, 312], [313, 317], [317, 318]]}
{"doc_key": "ai-dev-7", "ner": [[7, 7, "metrics"], [8, 8, "metrics"], [11, 11, "metrics"], [12, 12, "metrics"], [19, 19, "metrics"], [41, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 7, 19, 19, "named", "", false, false], [8, 8, 7, 7, "named", "", false, false], [11, 11, 41, 41, "named", "", false, false], [12, 12, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["To", "calculate", "the", "score", ",", "both", "the", "precision", "p", "and", "the", "recall", "r", "of", "the", "test", "are", "considered", ":", "p", "is", "the", "number", "of", "correct", "positive", "results", "divided", "by", "the", "number", "of", "all", "positive", "results", "returned", "by", "the", "classifier", ",", "and", "r", "is", "the", "number", "of", "correct", "positive", "results", "divided", "by", "the", "number", "of", "all", "relevant", "samples", "(", "all", "samples", "that", "should", "have", "been", "identified", "as", "positive", ")", "."], "sentence-detokenized": "To calculate the score, both the precision p and the recall r of the test are considered: p is the number of correct positive results divided by the number of all positive results returned by the classifier, and r is the number of correct positive results divided by the number of all relevant samples (all samples that should have been identified as positive).", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 22], [22, 23], [24, 28], [29, 32], [33, 42], [43, 44], [45, 48], [49, 52], [53, 59], [60, 61], [62, 64], [65, 68], [69, 73], [74, 77], [78, 88], [88, 89], [90, 91], [92, 94], [95, 98], [99, 105], [106, 108], [109, 116], [117, 125], [126, 133], [134, 141], [142, 144], [145, 148], [149, 155], [156, 158], [159, 162], [163, 171], [172, 179], [180, 188], [189, 191], [192, 195], [196, 206], [206, 207], [208, 211], [212, 213], [214, 216], [217, 220], [221, 227], [228, 230], [231, 238], [239, 247], [248, 255], [256, 263], [264, 266], [267, 270], [271, 277], [278, 280], [281, 284], [285, 293], [294, 301], [302, 303], [303, 306], [307, 314], [315, 319], [320, 326], [327, 331], [332, 336], [337, 347], [348, 350], [351, 359], [359, 360], [360, 361]]}
{"doc_key": "ai-dev-8", "ner": [[3, 4, "organisation"], [24, 24, "product"], [32, 33, "person"], [37, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 24, 24, "artifact", "", false, false], [24, 24, 32, 33, "win-defeat", "", false, false], [24, 24, 37, 38, "win-defeat", "", true, false], [32, 33, 37, 38, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "its", "acquisition", "by", "Google", ",", "the", "company", "has", "had", "a", "number", "of", "significant", "successes", ",", "perhaps", "the", "most", "notable", "being", "the", "creation", "of", "AlphaGo", ",", "a", "programme", "that", "beat", "world", "champion", "Lee", "Sedol", "in", "the", "complex", "Go", "game", "."], "sentence-detokenized": "Since its acquisition by Google, the company has had a number of significant successes, perhaps the most notable being the creation of AlphaGo, a programme that beat world champion Lee Sedol in the complex Go game.", "token2charspan": [[0, 5], [6, 9], [10, 21], [22, 24], [25, 31], [31, 32], [33, 36], [37, 44], [45, 48], [49, 52], [53, 54], [55, 61], [62, 64], [65, 76], [77, 86], [86, 87], [88, 95], [96, 99], [100, 104], [105, 112], [113, 118], [119, 122], [123, 131], [132, 134], [135, 142], [142, 143], [144, 145], [146, 155], [156, 160], [161, 165], [166, 171], [172, 180], [181, 184], [185, 190], [191, 193], [194, 197], [198, 205], [206, 208], [209, 213], [213, 214]]}
{"doc_key": "ai-dev-9", "ner": [[16, 18, "misc"], [34, 36, "product"], [53, 54, "misc"], [62, 62, "product"]], "ner_mapping_to_source": [0, 2, 3, 5], "relations": [[34, 36, 53, 54, "related-to", "", false, false], [34, 36, 62, 62, "usage", "", false, false]], "relations_mapping_to_source": [2, 4], "sentence": ["Representing", "words", "taking", "their", "context", "into", "account", "by", "means", "of", "dense", "fixed", "-", "size", "vectors", "(", "word", "-", "embeddings", ")", "has", "become", "one", "of", "the", "most", "fundamental", "blocks", "in", "various", "NLP", "systems", ".", "An", "unsupervised", "disambiguation", "system", "uses", "the", "similarity", "between", "word", "phrases", "in", "a", "fixed", "context", "window", "to", "select", "the", "most", "appropriate", "word", "phrase", "using", "a", "pre-trained", "word", "-embedding", "model", "and", "WordNet", "."], "sentence-detokenized": "Representing words taking their context into account by means of dense fixed-size vectors (word-embeddings) has become one of the most fundamental blocks in various NLP systems. An unsupervised disambiguation system uses the similarity between word phrases in a fixed context window to select the most appropriate word phrase using a pre-trained word-embedding model and WordNet.", "token2charspan": [[0, 12], [13, 18], [19, 25], [26, 31], [32, 39], [40, 44], [45, 52], [53, 55], [56, 61], [62, 64], [65, 70], [71, 76], [76, 77], [77, 81], [82, 89], [90, 91], [91, 95], [95, 96], [96, 106], [106, 107], [108, 111], [112, 118], [119, 122], [123, 125], [126, 129], [130, 134], [135, 146], [147, 153], [154, 156], [157, 164], [165, 168], [169, 176], [176, 177], [178, 180], [181, 193], [194, 208], [209, 215], [216, 220], [221, 224], [225, 235], [236, 243], [244, 248], [249, 256], [257, 259], [260, 261], [262, 267], [268, 275], [276, 282], [283, 285], [286, 292], [293, 296], [297, 301], [302, 313], [314, 318], [319, 325], [326, 331], [332, 333], [334, 345], [346, 350], [350, 360], [361, 366], [367, 370], [371, 378], [378, 379]]}
{"doc_key": "ai-dev-10", "ner": [[5, 6, "field"], [8, 9, "field"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Machine", "learning", "techniques", ",", "both", "supervised", "learning", "and", "unsupervised", "learning", ",", "have", "been", "used", "to", "induce", "such", "rules", "automatically", "."], "sentence-detokenized": "Machine learning techniques, both supervised learning and unsupervised learning, have been used to induce such rules automatically.", "token2charspan": [[0, 7], [8, 16], [17, 27], [27, 28], [29, 33], [34, 44], [45, 53], [54, 57], [58, 70], [71, 79], [79, 80], [81, 85], [86, 90], [91, 95], [96, 98], [99, 105], [106, 110], [111, 116], [117, 130], [130, 131]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1969", ",", "Scheinman", "invented", "the", "Stanford", "arm", ","], "sentence-detokenized": "In 1969, Scheinman invented the Stanford arm,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 27], [28, 31], [32, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-dev-12", "ner": [[2, 3, "metrics"], [8, 9, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "the", "log", "loss", "is", "differentiable", ",", "a", "gradient", "method", "can", "be", "used", "to", "optimise", "the", "model", "."], "sentence-detokenized": "Since the log loss is differentiable, a gradient method can be used to optimise the model.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 18], [19, 21], [22, 36], [36, 37], [38, 39], [40, 48], [49, 55], [56, 59], [60, 62], [63, 67], [68, 70], [71, 79], [80, 83], [84, 89], [89, 90]]}
{"doc_key": "ai-dev-13", "ner": [[1, 2, "field"], [4, 7, "algorithm"], [9, 9, "algorithm"], [12, 15, "algorithm"], [18, 18, "field"], [31, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[4, 7, 18, 18, "part-of", "", false, false], [9, 9, 4, 7, "named", "", false, false], [12, 15, 4, 7, "named", "", false, false], [18, 18, 1, 2, "part-of", "subfield", false, false], [31, 32, 18, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5], "sentence": ["In", "machine", "learning", ",", "support", "-", "vector", "machines", "(", "SVMs", ",", "also", "support", "-", "vector", "networks", ")", "are", "supervised", "learning", "models", "with", "learning", "algorithms", "that", "analyse", "data", "used", "for", "classification", "and", "regression", "analysis", "."], "sentence-detokenized": "In machine learning, support-vector machines (SVMs, also support-vector networks) are supervised learning models with learning algorithms that analyse data used for classification and regression analysis.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 28], [28, 29], [29, 35], [36, 44], [45, 46], [46, 50], [50, 51], [52, 56], [57, 64], [64, 65], [65, 71], [72, 80], [80, 81], [82, 85], [86, 96], [97, 105], [106, 112], [113, 117], [118, 126], [127, 137], [138, 142], [143, 150], [151, 155], [156, 160], [161, 164], [165, 179], [180, 183], [184, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-dev-14", "ner": [[8, 9, "task"], [11, 11, "task"], [29, 29, "metrics"], [31, 31, "metrics"], [33, 33, "researcher"], [35, 35, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "2002", ")", "as", "the", "automatic", "metric", "for", "machine", "translation", "(", "MT", ")", "evaluation", ",", "many", "other", "methods", "have", "been", "proposed", "to", "revise", "or", "improve", "it", ",", "such", "as", "TER", ",", "METEOR", ",", "Banerjee", "and", "Lavie", ",", "(", "2005", ")", "etc", "."], "sentence-detokenized": "(2002) as the automatic metric for machine translation (MT) evaluation, many other methods have been proposed to revise or improve it, such as TER, METEOR, Banerjee and Lavie, (2005) etc.", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 9], [10, 13], [14, 23], [24, 30], [31, 34], [35, 42], [43, 54], [55, 56], [56, 58], [58, 59], [60, 70], [70, 71], [72, 76], [77, 82], [83, 90], [91, 95], [96, 100], [101, 109], [110, 112], [113, 119], [120, 122], [123, 130], [131, 133], [133, 134], [135, 139], [140, 142], [143, 146], [146, 147], [148, 154], [154, 155], [156, 164], [165, 168], [169, 174], [174, 175], [176, 177], [177, 181], [181, 182], [183, 186], [186, 187]]}
{"doc_key": "ai-dev-15", "ner": [[5, 5, "misc"], [12, 12, "organisation"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[5, 5, 12, 12, "origin", "", false, false], [16, 17, 12, 12, "role", "", false, false], [19, 20, 12, 12, "role", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["It", "includes", "a", "top", "shelf", "ontology", "created", "by", "the", "IEEE", "working", "group", "P1600.1", "(", "originally", "by", "Ian", "Niles", "and", "Adam", "Pease", ")", "."], "sentence-detokenized": "It includes a top shelf ontology created by the IEEE working group P1600.1 (originally by Ian Niles and Adam Pease).", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 17], [18, 23], [24, 32], [33, 40], [41, 43], [44, 47], [48, 52], [53, 60], [61, 66], [67, 74], [75, 76], [76, 86], [87, 89], [90, 93], [94, 99], [100, 103], [104, 108], [109, 114], [114, 115], [115, 116]]}
{"doc_key": "ai-dev-16", "ner": [[1, 2, "misc"], [32, 36, "algorithm"], [38, 39, "algorithm"], [42, 43, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[32, 36, 1, 2, "part-of", "", true, false], [38, 39, 1, 2, "part-of", "", true, false], [42, 43, 38, 39, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "cryo-electron", "tomography", ",", "where", "a", "limited", "number", "of", "projections", "are", "obtained", "due", "to", "hardware", "limitations", "and", "to", "avoid", "damaging", "the", "biological", "sample", ",", "this", "technique", "can", "be", "used", "in", "combination", "with", "\"", "compressive", "sensing", "\"", "techniques", "or", "regularisation", "functions", "(", "e.g.", "Huber", "loss", ")", "to", "improve", "the", "reconstruction", "for", "better", "interpretation", "."], "sentence-detokenized": "In cryo-electron tomography, where a limited number of projections are obtained due to hardware limitations and to avoid damaging the biological sample, this technique can be used in combination with \"compressive sensing\" techniques or regularisation functions (e.g. Huber loss) to improve the reconstruction for better interpretation.", "token2charspan": [[0, 2], [3, 16], [17, 27], [27, 28], [29, 34], [35, 36], [37, 44], [45, 51], [52, 54], [55, 66], [67, 70], [71, 79], [80, 83], [84, 86], [87, 95], [96, 107], [108, 111], [112, 114], [115, 120], [121, 129], [130, 133], [134, 144], [145, 151], [151, 152], [153, 157], [158, 167], [168, 171], [172, 174], [175, 179], [180, 182], [183, 194], [195, 199], [200, 201], [201, 212], [213, 220], [220, 221], [222, 232], [233, 235], [236, 250], [251, 260], [261, 262], [262, 266], [267, 272], [273, 277], [277, 278], [279, 281], [282, 289], [290, 293], [294, 308], [309, 312], [313, 319], [320, 334], [334, 335]]}
{"doc_key": "ai-dev-17", "ner": [[4, 4, "misc"], [7, 7, "programlang"], [10, 11, "algorithm"], [13, 14, "algorithm"], [19, 20, "algorithm"], [26, 28, "product"], [31, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 4, 7, 7, "part-of", "", false, false], [10, 11, 4, 4, "type-of", "", false, false], [13, 14, 4, 4, "type-of", "", false, false], [19, 20, 4, 4, "type-of", "", false, false], [26, 28, 7, 7, "general-affiliation", "", true, false], [26, 28, 7, 7, "part-of", "", true, false], [31, 31, 26, 28, "role", "publishes", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["An", "implementation", "of", "several", "whitening", "procedures", "in", "R", ",", "including", "ZCA", "whitening", "and", "PCA", "whitening", ",", "as", "well", "as", "CCA", "whitening", ",", "is", "available", "in", "the", "whitening", "R", "package", "published", "on", "CRAN", "."], "sentence-detokenized": "An implementation of several whitening procedures in R, including ZCA whitening and PCA whitening, as well as CCA whitening, is available in the whitening R package published on CRAN.", "token2charspan": [[0, 2], [3, 17], [18, 20], [21, 28], [29, 38], [39, 49], [50, 52], [53, 54], [54, 55], [56, 65], [66, 69], [70, 79], [80, 83], [84, 87], [88, 97], [97, 98], [99, 101], [102, 106], [107, 109], [110, 113], [114, 123], [123, 124], [125, 127], [128, 137], [138, 140], [141, 144], [145, 154], [155, 156], [157, 164], [165, 174], [175, 177], [178, 182], [182, 183]]}
{"doc_key": "ai-dev-18", "ner": [[29, 29, "product"], [31, 31, "product"], [33, 33, "product"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [42, 43, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[29, 29, 33, 33, "compare", "", false, false], [29, 29, 35, 35, "compare", "", false, false], [29, 29, 37, 37, "compare", "", false, false], [29, 29, 39, 39, "compare", "", false, false], [29, 29, 42, 43, "compare", "", false, false], [31, 31, 33, 33, "compare", "", false, false], [31, 31, 35, 35, "compare", "", false, false], [31, 31, 37, 37, "compare", "", false, false], [31, 31, 39, 39, "compare", "", false, false], [31, 31, 42, 43, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Today", ",", "the", "field", "has", "become", "even", "more", "daunting", "and", "complex", "with", "the", "addition", "of", "languages", "and", "software", "for", "circuit", ",", "system", "and", "signal", "analysis", "and", "design", ",", "from", "MATLAB", "and", "Simulink", "to", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "and", "even", "assembly", "language", "."], "sentence-detokenized": "Today, the field has become even more daunting and complex with the addition of languages and software for circuit, system and signal analysis and design, from MATLAB and Simulink to NumPy, VHDL, PSpice, Verilog and even assembly language.", "token2charspan": [[0, 5], [5, 6], [7, 10], [11, 16], [17, 20], [21, 27], [28, 32], [33, 37], [38, 46], [47, 50], [51, 58], [59, 63], [64, 67], [68, 76], [77, 79], [80, 89], [90, 93], [94, 102], [103, 106], [107, 114], [114, 115], [116, 122], [123, 126], [127, 133], [134, 142], [143, 146], [147, 153], [153, 154], [155, 159], [160, 166], [167, 170], [171, 179], [180, 182], [183, 188], [188, 189], [190, 194], [194, 195], [196, 202], [202, 203], [204, 211], [212, 215], [216, 220], [221, 229], [230, 238], [238, 239]]}
{"doc_key": "ai-dev-19", "ner": [[7, 8, "person"], [16, 18, "person"], [19, 20, "organisation"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 20, 16, 18, "origin", "", false, false], [25, 25, 19, 20, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "company", "was", "founded", "in", "1937", "by", "Kiichiro", "Toyoda", ",", "as", "a", "spin", "-", "off", "of", "Sakichi", "Toyoda", "'s", "Toyota", "Industries", "company", ",", "to", "produce", "cars", "."], "sentence-detokenized": "The company was founded in 1937 by Kiichiro Toyoda, as a spin-off of Sakichi Toyoda's Toyota Industries company, to produce cars.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 31], [32, 34], [35, 43], [44, 50], [50, 51], [52, 54], [55, 56], [57, 61], [61, 62], [62, 65], [66, 68], [69, 76], [77, 83], [83, 85], [86, 92], [93, 103], [104, 111], [111, 112], [113, 115], [116, 123], [124, 128], [128, 129]]}
{"doc_key": "ai-dev-20", "ner": [[3, 5, "field"], [48, 49, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[48, 49, 3, 5, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["In", "contrast", ",", "unsupervised", "learning", "assumes", "training", "data", "that", "is", "not", "hand", "-", "labelled", ",", "and", "attempts", "to", "find", "inherent", "patterns", "in", "the", "data", "that", "can", "then", "be", "used", "to", "determine", "the", "appropriate", "output", "value", "for", "new", "data", "instances", ".", "A", "combination", "of", "the", "two", "recently", "explored", "is", "semi-supervised", "learning", ",", "which", "uses", "a", "combination", "of", "labelled", "and", "unlabelled", "data", "(", "usually", "a", "small", "set", "of", "labelled", "data", "combined", "with", "a", "large", "amount", "of", "unlabelled", "data", ")", "."], "sentence-detokenized": "In contrast, unsupervised learning assumes training data that is not hand-labelled, and attempts to find inherent patterns in the data that can then be used to determine the appropriate output value for new data instances. A combination of the two recently explored is semi-supervised learning, which uses a combination of labelled and unlabelled data (usually a small set of labelled data combined with a large amount of unlabelled data).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 25], [26, 34], [35, 42], [43, 51], [52, 56], [57, 61], [62, 64], [65, 68], [69, 73], [73, 74], [74, 82], [82, 83], [84, 87], [88, 96], [97, 99], [100, 104], [105, 113], [114, 122], [123, 125], [126, 129], [130, 134], [135, 139], [140, 143], [144, 148], [149, 151], [152, 156], [157, 159], [160, 169], [170, 173], [174, 185], [186, 192], [193, 198], [199, 202], [203, 206], [207, 211], [212, 221], [221, 222], [223, 224], [225, 236], [237, 239], [240, 243], [244, 247], [248, 256], [257, 265], [266, 268], [269, 284], [285, 293], [293, 294], [295, 300], [301, 305], [306, 307], [308, 319], [320, 322], [323, 331], [332, 335], [336, 346], [347, 351], [352, 353], [353, 360], [361, 362], [363, 368], [369, 372], [373, 375], [376, 384], [385, 389], [390, 398], [399, 403], [404, 405], [406, 411], [412, 418], [419, 421], [422, 432], [433, 437], [437, 438], [438, 439]]}
{"doc_key": "ai-dev-21", "ner": [[20, 21, "organisation"], [22, 22, "product"], [24, 25, "organisation"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 20, 21, "artifact", "", false, false], [24, 25, 27, 27, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Despite", "these", "humanoid", "robots", "for", "utilitarian", "use", ",", "there", "are", "also", "some", "humanoid", "robots", "intended", "for", "entertainment", ",", "such", "as", "Sony", "'s", "QRIO", "and", "Wow", "Wee", "'s", "RoboSapien", "."], "sentence-detokenized": "Despite these humanoid robots for utilitarian use, there are also some humanoid robots intended for entertainment, such as Sony's QRIO and Wow Wee's RoboSapien.", "token2charspan": [[0, 7], [8, 13], [14, 22], [23, 29], [30, 33], [34, 45], [46, 49], [49, 50], [51, 56], [57, 60], [61, 65], [66, 70], [71, 79], [80, 86], [87, 95], [96, 99], [100, 113], [113, 114], [115, 119], [120, 122], [123, 127], [127, 129], [130, 134], [135, 138], [139, 142], [143, 146], [146, 148], [149, 159], [159, 160]]}
{"doc_key": "ai-dev-22", "ner": [[0, 0, "researcher"], [6, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 12, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Webber", "became", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "in", "1991", ","], "sentence-detokenized": "Webber became a Fellow of the Association for the Advancement of Artificial Intelligence in 1991,", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 49], [50, 61], [62, 64], [65, 75], [76, 88], [89, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-dev-23", "ner": [[6, 6, "field"], [19, 22, "task"]], "ner_mapping_to_source": [0, 2], "relations": [[19, 22, 6, 6, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["With", "this", "company", ",", "he", "developed", "data-mining", "and", "database", "technology", ",", "specifically", "high", "-", "level", "ontologies", "for", "intelligence", "and", "automated", "natural", "language", "understanding", "."], "sentence-detokenized": "With this company, he developed data-mining and database technology, specifically high-level ontologies for intelligence and automated natural language understanding.", "token2charspan": [[0, 4], [5, 9], [10, 17], [17, 18], [19, 21], [22, 31], [32, 43], [44, 47], [48, 56], [57, 67], [67, 68], [69, 81], [82, 86], [86, 87], [87, 92], [93, 103], [104, 107], [108, 120], [121, 124], [125, 134], [135, 142], [143, 151], [152, 165], [165, 166]]}
{"doc_key": "ai-dev-24", "ner": [[19, 20, "misc"], [22, 25, "misc"], [28, 29, "misc"], [31, 31, "country"], [33, 35, "organisation"], [37, 37, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[19, 20, 31, 31, "physical", "", false, false], [22, 25, 31, 31, "physical", "", false, false], [28, 29, 31, 31, "physical", "", false, false], [33, 35, 37, 37, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "recent", "years", ",", "however", ",", "several", "e-services", "and", "related", "initiatives", "have", "emerged", "in", "developing", "countries", ",", "such", "as", "Project", "Nemmadi", ",", "MCA21", "Mission", "Mode", "Project", "or", "still", "Digital", "India", "in", "India", ";", "Electronic", "Government", "Directorate", "in", "Pakistan", ";", "etc."], "sentence-detokenized": "In recent years, however, several e-services and related initiatives have emerged in developing countries, such as Project Nemmadi, MCA21 Mission Mode Project or still Digital India in India; Electronic Government Directorate in Pakistan; etc.", "token2charspan": [[0, 2], [3, 9], [10, 15], [15, 16], [17, 24], [24, 25], [26, 33], [34, 44], [45, 48], [49, 56], [57, 68], [69, 73], [74, 81], [82, 84], [85, 95], [96, 105], [105, 106], [107, 111], [112, 114], [115, 122], [123, 130], [130, 131], [132, 137], [138, 145], [146, 150], [151, 158], [159, 161], [162, 167], [168, 175], [176, 181], [182, 184], [185, 190], [190, 191], [192, 202], [203, 213], [214, 225], [226, 228], [229, 237], [237, 238], [239, 243]]}
{"doc_key": "ai-dev-25", "ner": [[4, 6, "misc"], [30, 30, "field"], [32, 32, "field"], [9, 11, "university"], [15, 17, "university"], [23, 29, "university"], [38, 41, "misc"], [54, 55, "field"], [59, 63, "misc"], [44, 44, "university"], [46, 50, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[4, 6, 30, 30, "topic", "", false, false], [4, 6, 32, 32, "topic", "", false, false], [4, 6, 9, 11, "origin", "", false, false], [9, 11, 15, 17, "part-of", "", false, false], [23, 29, 9, 11, "part-of", "", false, false], [38, 41, 54, 55, "topic", "", false, false], [38, 41, 44, 44, "origin", "", false, false], [59, 63, 44, 44, "origin", "", false, false], [44, 44, 46, 50, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "1979", ",", "he", "received", "his", "PhD", "from", "the", "Rajabazar", "Science", "College", "campus", "of", "the", "University", "of", "Calcutta", "as", "a", "student", "of", "the", "Indian", "Statistical", "Institute", "in", "the", "field", "of", "radiophysics", "and", "electronics", ",", "and", "in", "1982", ",", "he", "received", "his", "PhD", "from", "Imperial", "College", ",", "University", "of", "London", ",", "in", "the", "field", "of", "electrical", "engineering", ",", "along", "with", "his", "degree", "from", "Imperial", "College", "."], "sentence-detokenized": "In 1979, he received his PhD from the Rajabazar Science College campus of the University of Calcutta as a student of the Indian Statistical Institute in the field of radiophysics and electronics, and in 1982, he received his PhD from Imperial College, University of London, in the field of electrical engineering, along with his degree from Imperial College.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 20], [21, 24], [25, 28], [29, 33], [34, 37], [38, 47], [48, 55], [56, 63], [64, 70], [71, 73], [74, 77], [78, 88], [89, 91], [92, 100], [101, 103], [104, 105], [106, 113], [114, 116], [117, 120], [121, 127], [128, 139], [140, 149], [150, 152], [153, 156], [157, 162], [163, 165], [166, 178], [179, 182], [183, 194], [194, 195], [196, 199], [200, 202], [203, 207], [207, 208], [209, 211], [212, 220], [221, 224], [225, 228], [229, 233], [234, 242], [243, 250], [250, 251], [252, 262], [263, 265], [266, 272], [272, 273], [274, 276], [277, 280], [281, 286], [287, 289], [290, 300], [301, 312], [312, 313], [314, 319], [320, 324], [325, 328], [329, 335], [336, 340], [341, 349], [350, 357], [357, 358]]}
{"doc_key": "ai-dev-26", "ner": [[0, 1, "location"], [24, 26, "misc"], [32, 33, "misc"], [35, 37, "person"], [39, 40, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[24, 26, 0, 1, "temporal", "", false, false], [32, 33, 0, 1, "temporal", "", false, false], [35, 37, 32, 33, "role", "actor_in", false, false], [39, 40, 32, 33, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Expo", "II", "was", "announced", "as", "the", "venue", "for", "the", "world", "premiere", "of", "several", "films", "that", "had", "never", "before", "been", "seen", "in", "3D", ",", "including", "The", "Diamond", "Wizard", "and", "Universal", "'s", "short", "film", "Hawaiian", "Nights", "starring", "Mamie", "Van", "Doren", "and", "Pinky", "Lee", "."], "sentence-detokenized": "Expo II was announced as the venue for the world premiere of several films that had never before been seen in 3D, including The Diamond Wizard and Universal's short film Hawaiian Nights starring Mamie Van Doren and Pinky Lee.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 24], [25, 28], [29, 34], [35, 38], [39, 42], [43, 48], [49, 57], [58, 60], [61, 68], [69, 74], [75, 79], [80, 83], [84, 89], [90, 96], [97, 101], [102, 106], [107, 109], [110, 112], [112, 113], [114, 123], [124, 127], [128, 135], [136, 142], [143, 146], [147, 156], [156, 158], [159, 164], [165, 169], [170, 178], [179, 185], [186, 194], [195, 200], [201, 204], [205, 210], [211, 214], [215, 220], [221, 224], [224, 225]]}
{"doc_key": "ai-dev-27", "ner": [[9, 10, "researcher"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 16, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "maximum", "subarray", "problem", "was", "proposed", "in", "1977", "by", "Ulf", "Grenander", "as", "a", "simplified", "model", "for", "maximum", "likelihood", "estimation", "of", "patterns", "in", "digitised", "images", "."], "sentence-detokenized": "The maximum subarray problem was proposed in 1977 by Ulf Grenander as a simplified model for maximum likelihood estimation of patterns in digitised images.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 28], [29, 32], [33, 41], [42, 44], [45, 49], [50, 52], [53, 56], [57, 66], [67, 69], [70, 71], [72, 82], [83, 88], [89, 92], [93, 100], [101, 111], [112, 122], [123, 125], [126, 134], [135, 137], [138, 147], [148, 154], [154, 155]]}
{"doc_key": "ai-dev-28", "ner": [[1, 2, "product"], [4, 5, "product"], [7, 9, "product"], [11, 12, "product"], [14, 16, "product"], [18, 21, "product"], [32, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[32, 32, 1, 2, "part-of", "", false, false], [32, 32, 4, 5, "part-of", "", false, false], [32, 32, 7, 9, "part-of", "", false, false], [32, 32, 11, 12, "part-of", "", false, false], [32, 32, 14, 16, "part-of", "", false, false], [32, 32, 18, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "iPhone", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", "and", "iPod", "Touch", "5", "G", "and", "later", "all", "feature", "a", "more", "advanced", "voice", "assistant", "called", "Siri", "."], "sentence-detokenized": "The iPhone 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G and iPod Touch 5G and later all feature a more advanced voice assistant called Siri.", "token2charspan": [[0, 3], [4, 10], [11, 13], [13, 14], [15, 19], [20, 21], [21, 22], [23, 27], [28, 32], [33, 35], [35, 36], [37, 41], [42, 45], [45, 46], [47, 51], [52, 55], [56, 58], [59, 62], [63, 67], [68, 73], [74, 75], [75, 76], [77, 80], [81, 86], [87, 90], [91, 98], [99, 100], [101, 105], [106, 114], [115, 120], [121, 130], [131, 137], [138, 142], [142, 143]]}
{"doc_key": "ai-dev-29", "ner": [[7, 8, "metrics"], [10, 14, "metrics"], [16, 17, "metrics"], [37, 39, "metrics"], [45, 48, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 14, 37, 39, "named", "", false, false], [16, 17, 10, 14, "named", "", false, false], [37, 39, 45, 48, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["It", "is", "easy", "to", "check", "that", "the", "logistic", "loss", "and", "the", "binary", "cross", "entropy", "loss", "(", "Log", "loss", ")", "are", "in", "fact", "equal", "(", "up", "to", "a", "multiplicative", "constant", "math", "}", "frac", "{", "1", "}", "{", "The", "cross", "entropy", "loss", "is", "closely", "related", "to", "the", "Kullback", "-", "Leibler", "divergence", "between", "the", "empirical", "distribution", "and", "the", "predicted", "distribution", "."], "sentence-detokenized": "It is easy to check that the logistic loss and the binary cross entropy loss (Log loss) are in fact equal (up to a multiplicative constant math} frac {1} {The cross entropy loss is closely related to the Kullback-Leibler divergence between the empirical distribution and the predicted distribution.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 19], [20, 24], [25, 28], [29, 37], [38, 42], [43, 46], [47, 50], [51, 57], [58, 63], [64, 71], [72, 76], [77, 78], [78, 81], [82, 86], [86, 87], [88, 91], [92, 94], [95, 99], [100, 105], [106, 107], [107, 109], [110, 112], [113, 114], [115, 129], [130, 138], [139, 143], [143, 144], [145, 149], [150, 151], [151, 152], [152, 153], [154, 155], [155, 158], [159, 164], [165, 172], [173, 177], [178, 180], [181, 188], [189, 196], [197, 199], [200, 203], [204, 212], [212, 213], [213, 220], [221, 231], [232, 239], [240, 243], [244, 253], [254, 266], [267, 270], [271, 274], [275, 284], [285, 297], [297, 298]]}
{"doc_key": "ai-dev-30", "ner": [[1, 2, "algorithm"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 10, 1, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "EM", "algorithm", "is", "used", "to", "find", "(", "local", ")", "maximum", "likelihood", "parameters", "of", "a", "statistical", "model", "in", "cases", "where", "the", "equations", "can", "not", "be", "solved", "directly", "."], "sentence-detokenized": "The EM algorithm is used to find (local) maximum likelihood parameters of a statistical model in cases where the equations cannot be solved directly.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 32], [33, 34], [34, 39], [39, 40], [41, 48], [49, 59], [60, 70], [71, 73], [74, 75], [76, 87], [88, 93], [94, 96], [97, 102], [103, 108], [109, 112], [113, 122], [123, 126], [126, 129], [130, 132], [133, 139], [140, 148], [148, 149]]}
{"doc_key": "ai-dev-31", "ner": [[11, 12, "task"], [14, 18, "task"], [23, 24, "task"], [26, 27, "task"], [34, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "research", "was", "fundamental", "to", "the", "development", "of", "modern", "techniques", "of", "speech", "synthesis", ",", "reading", "machines", "for", "the", "blind", ",", "the", "study", "of", "speech", "perception", "and", "speech", "recognition", ",", "and", "the", "development", "of", "the", "motor", "theory", "of", "speech", "perception", "."], "sentence-detokenized": "This research was fundamental to the development of modern techniques of speech synthesis, reading machines for the blind, the study of speech perception and speech recognition, and the development of the motor theory of speech perception.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 29], [30, 32], [33, 36], [37, 48], [49, 51], [52, 58], [59, 69], [70, 72], [73, 79], [80, 89], [89, 90], [91, 98], [99, 107], [108, 111], [112, 115], [116, 121], [121, 122], [123, 126], [127, 132], [133, 135], [136, 142], [143, 153], [154, 157], [158, 164], [165, 176], [176, 177], [178, 181], [182, 185], [186, 197], [198, 200], [201, 204], [205, 210], [211, 217], [218, 220], [221, 227], [228, 238], [238, 239]]}
{"doc_key": "ai-dev-32", "ner": [[1, 1, "product"], [2, 4, "misc"], [6, 6, "misc"], [10, 12, "misc"], [15, 15, "product"], [17, 17, "product"], [19, 19, "product"], [24, 24, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 1, 1, "origin", "", false, false], [2, 4, 10, 12, "type-of", "", false, false], [2, 4, 15, 15, "related-to", "program_for", false, false], [2, 4, 17, 17, "related-to", "program_for", false, false], [2, 4, 19, 19, "related-to", "program_for", false, false], [2, 4, 24, 24, "related-to", "program_for", false, false], [6, 6, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "Arduino", "integrated", "development", "environment", "(", "IDE", ")", "is", "a", "cross", "-platform", "application", "(", "for", "Windows", ",", "macOS", "and", "Linux", ")", "written", "in", "the", "Java", "programming", "language", "."], "sentence-detokenized": "The Arduino integrated development environment (IDE) is a cross-platform application (for Windows, macOS and Linux) written in the Java programming language.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 57], [58, 63], [63, 72], [73, 84], [85, 86], [86, 89], [90, 97], [97, 98], [99, 104], [105, 108], [109, 114], [114, 115], [116, 123], [124, 126], [127, 130], [131, 135], [136, 147], [148, 156], [156, 157]]}
{"doc_key": "ai-dev-33", "ner": [[2, 3, "algorithm"], [9, 10, "field"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 9, 10, "opposite", "", false, false], [13, 14, 9, 10, "related-to", "works_with", false, false], [16, 17, 9, 10, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Research", "on", "neural", "networks", "stagnated", "after", "the", "publication", "of", "machine", "learning", "research", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", "."], "sentence-detokenized": "Research on neural networks stagnated after the publication of machine learning research by Marvin Minsky and Seymour Papert (1969).", "token2charspan": [[0, 8], [9, 11], [12, 18], [19, 27], [28, 37], [38, 43], [44, 47], [48, 59], [60, 62], [63, 70], [71, 79], [80, 88], [89, 91], [92, 98], [99, 105], [106, 109], [110, 117], [118, 124], [125, 126], [126, 130], [130, 131], [131, 132]]}
{"doc_key": "ai-dev-34", "ner": [[18, 19, "organisation"], [21, 21, "organisation"], [23, 25, "country"], [27, 30, "organisation"], [32, 32, "country"], [34, 35, "organisation"], [37, 37, "country"], [39, 39, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[27, 30, 23, 25, "general-affiliation", "", false, false], [34, 35, 32, 32, "general-affiliation", "", false, false], [39, 39, 37, 37, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Only", "a", "few", "non-Japanese", "companies", "eventually", "managed", "to", "survive", "in", "this", "market", ",", "the", "main", "ones", "being", ":", "Adept", "Technology", ",", "St\u00e4ubli", ",", "Swedish", "-", "Swiss", "company", "ABB", "Asea", "Brown", "Boveri", ",", "German", "company", "KUKA", "Robotics", "and", "Italian", "company", "Comau", "."], "sentence-detokenized": "Only a few non-Japanese companies eventually managed to survive in this market, the main ones being: Adept Technology, St\u00e4ubli, Swedish-Swiss company ABB Asea Brown Boveri, German company KUKA Robotics and Italian company Comau.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 23], [24, 33], [34, 44], [45, 52], [53, 55], [56, 63], [64, 66], [67, 71], [72, 78], [78, 79], [80, 83], [84, 88], [89, 93], [94, 99], [99, 100], [101, 106], [107, 117], [117, 118], [119, 126], [126, 127], [128, 135], [135, 136], [136, 141], [142, 149], [150, 153], [154, 158], [159, 164], [165, 171], [171, 172], [173, 179], [180, 187], [188, 192], [193, 201], [202, 205], [206, 213], [214, 221], [222, 227], [227, 228]]}
{"doc_key": "ai-dev-35", "ner": [[9, 10, "conference"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Research", "activities", "include", "an", "annual", "research", "conference", ",", "the", "RuleML", "Symposium", ",", "also", "known", "as", "RuleML", "for", "short", "."], "sentence-detokenized": "Research activities include an annual research conference, the RuleML Symposium, also known as RuleML for short.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 30], [31, 37], [38, 46], [47, 57], [57, 58], [59, 62], [63, 69], [70, 79], [79, 80], [81, 85], [86, 91], [92, 94], [95, 101], [102, 105], [106, 111], [111, 112]]}
{"doc_key": "ai-dev-36", "ner": [[9, 9, "field"], [11, 12, "field"], [14, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Concepts", "are", "used", "as", "formal", "tools", "or", "models", "in", "mathematics", ",", "computer", "science", ",", "databases", "and", "artificial", "intelligence", ",", "where", "they", "are", "sometimes", "called", "classes", ",", "schemas", "or", "categories", "."], "sentence-detokenized": "Concepts are used as formal tools or models in mathematics, computer science, databases and artificial intelligence, where they are sometimes called classes, schemas or categories.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 33], [34, 36], [37, 43], [44, 46], [47, 58], [58, 59], [60, 68], [69, 76], [76, 77], [78, 87], [88, 91], [92, 102], [103, 115], [115, 116], [117, 122], [123, 127], [128, 131], [132, 141], [142, 148], [149, 156], [156, 157], [158, 165], [166, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-dev-37", "ner": [[6, 8, "organisation"], [11, 14, "organisation"], [17, 17, "organisation"], [20, 22, "organisation"], [25, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "won", "awards", "from", "the", "American", "Psychological", "Association", ",", "the", "National", "Academy", "of", "Sciences", ",", "the", "Royal", ",", "the", "Cognitive", "Neuroscience", "Society", "and", "the", "American", "Humanist", "Association", "."], "sentence-detokenized": "He has won awards from the American Psychological Association, the National Academy of Sciences, the Royal, the Cognitive Neuroscience Society and the American Humanist Association.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 17], [18, 22], [23, 26], [27, 35], [36, 49], [50, 61], [61, 62], [63, 66], [67, 75], [76, 83], [84, 86], [87, 95], [95, 96], [97, 100], [101, 106], [106, 107], [108, 111], [112, 121], [122, 134], [135, 142], [143, 146], [147, 150], [151, 159], [160, 168], [169, 180], [180, 181]]}
{"doc_key": "ai-dev-38", "ner": [[1, 2, "person"], [4, 5, "person"], [7, 12, "person"], [16, 19, "person"], [22, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[22, 27, 16, 19, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starring", "Harrison", "Ford", ",", "Rutger", "Hauer", "and", "Sean", "Young", ",", "the", "film", "is", "loosely", "based", "on", "Philip", "K", ".", "Dick", "'s", "novel", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "(", "1968", ")", "."], "sentence-detokenized": "Starring Harrison Ford, Rutger Hauer and Sean Young, the film is loosely based on Philip K. Dick's novel Do Androids Dream of Electric Sheep (1968).", "token2charspan": [[0, 8], [9, 17], [18, 22], [22, 23], [24, 30], [31, 36], [37, 40], [41, 45], [46, 51], [51, 52], [53, 56], [57, 61], [62, 64], [65, 72], [73, 78], [79, 81], [82, 88], [89, 90], [90, 91], [92, 96], [96, 98], [99, 104], [105, 107], [108, 116], [117, 122], [123, 125], [126, 134], [135, 140], [141, 142], [142, 146], [146, 147], [147, 148]]}
{"doc_key": "ai-dev-39", "ner": [[0, 1, "task"], [3, 5, "algorithm"], [11, 12, "field"], [14, 15, "task"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 3, 5, "usage", "", false, false], [0, 1, 11, 12, "part-of", "task_part_of_field", false, false], [0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 18, 19, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Image", "segmentation", "using", "k-means", "clustering", "algorithms", "has", "long", "been", "used", "for", "pattern", "recognition", ",", "object", "detection", ",", "and", "medical", "imaging", "."], "sentence-detokenized": "Image segmentation using k-means clustering algorithms has long been used for pattern recognition, object detection, and medical imaging.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 32], [33, 43], [44, 54], [55, 58], [59, 63], [64, 68], [69, 73], [74, 77], [78, 85], [86, 97], [97, 98], [99, 105], [106, 115], [115, 116], [117, 120], [121, 128], [129, 136], [136, 137]]}
{"doc_key": "ai-dev-40", "ner": [[14, 14, "algorithm"], [17, 18, "algorithm"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["General", "sampling", "from", "the", "truncated", "normal", "can", "be", "achieved", "using", "approximations", "of", "the", "normal", "CDF", "and", "the", "probit", "function", ",", "and", "R", "has", "a", "function", "encoding", "norm", "(", ")", "/", "code", "for", "generating", "truncated", "-normal", "samples", "."], "sentence-detokenized": "General sampling from the truncated normal can be achieved using approximations of the normal CDF and the probit function, and R has a function encoding norm () / code for generating truncated-normal samples.", "token2charspan": [[0, 7], [8, 16], [17, 21], [22, 25], [26, 35], [36, 42], [43, 46], [47, 49], [50, 58], [59, 64], [65, 79], [80, 82], [83, 86], [87, 93], [94, 97], [98, 101], [102, 105], [106, 112], [113, 121], [121, 122], [123, 126], [127, 128], [129, 132], [133, 134], [135, 143], [144, 152], [153, 157], [158, 159], [159, 160], [161, 162], [163, 167], [168, 171], [172, 182], [183, 192], [192, 199], [200, 207], [207, 208]]}
{"doc_key": "ai-dev-41", "ner": [[8, 10, "university"], [12, 12, "university"], [14, 16, "university"], [18, 20, "university"], [23, 25, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "also", "received", "honorary", "doctorates", "from", "the", "universities", "of", "Newcastle", ",", "Surrey", ",", "Tel", "Aviv", "University", ",", "Simon", "Fraser", "University", "and", "the", "University", "of", "Troms\u00f8", "."], "sentence-detokenized": "He has also received honorary doctorates from the universities of Newcastle, Surrey, Tel Aviv University, Simon Fraser University and the University of Troms\u00f8.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 29], [30, 40], [41, 45], [46, 49], [50, 62], [63, 65], [66, 75], [75, 76], [77, 83], [83, 84], [85, 88], [89, 93], [94, 104], [104, 105], [106, 111], [112, 118], [119, 129], [130, 133], [134, 137], [138, 148], [149, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-dev-42", "ner": [[1, 1, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "Java", "implementation", "that", "uses", "null", "-", "based", "array", "indexes", "along", "with", "an", "easy", "method", "to", "print", "the", "resolved", "sequence", "of", "operations", ":"], "sentence-detokenized": "A Java implementation that uses null-based array indexes along with an easy method to print the resolved sequence of operations:", "token2charspan": [[0, 1], [2, 6], [7, 21], [22, 26], [27, 31], [32, 36], [36, 37], [37, 42], [43, 48], [49, 56], [57, 62], [63, 67], [68, 70], [71, 75], [76, 82], [83, 85], [86, 91], [92, 95], [96, 104], [105, 113], [114, 116], [117, 127], [127, 128]]}
{"doc_key": "ai-dev-43", "ner": [[7, 9, "metrics"], [12, 13, "metrics"], [17, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Such", "networks", "are", "usually", "trained", "under", "a", "Cross", "-", "entropy", "(", "or", "cross", "-entropy", ")", "regime", ",", "yielding", "a", "non-linear", "variant", "of", "multinomial", "logistic", "regression", "."], "sentence-detokenized": "Such networks are usually trained under a Cross-entropy (or cross-entropy) regime, yielding a non-linear variant of multinomial logistic regression.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 25], [26, 33], [34, 39], [40, 41], [42, 47], [47, 48], [48, 55], [56, 57], [57, 59], [60, 65], [65, 73], [73, 74], [75, 81], [81, 82], [83, 91], [92, 93], [94, 104], [105, 112], [113, 115], [116, 127], [128, 136], [137, 147], [147, 148]]}
{"doc_key": "ai-dev-44", "ner": [[1, 1, "conference"], [4, 4, "misc"], [6, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 1, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ACL", "has", "a", "European", "(", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ")"], "sentence-detokenized": "The ACL has a European (European Chapter of the Association for Computational Linguistics)", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 13], [14, 22], [23, 24], [24, 32], [33, 40], [41, 43], [44, 47], [48, 59], [60, 63], [64, 77], [78, 89], [89, 90]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 8, "researcher"], [20, 20, "misc"], [19, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 20, 20, "role", "", false, false], [6, 8, 20, 20, "role", "", false, false], [20, 20, 19, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "professors", ",", "Hal", "Abelson", "and", "Gerald", "Jay", "Sussman", ",", "chose", "to", "remain", "neutral", "-", "their", "group", "was", "alternately", "called", "Switzerland", "and", "Project", "MAC", "for", "the", "next", "30", "years", "."], "sentence-detokenized": "Two professors, Hal Abelson and Gerald Jay Sussman, chose to remain neutral - their group was alternately called Switzerland and Project MAC for the next 30 years.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 50], [50, 51], [52, 57], [58, 60], [61, 67], [68, 75], [76, 77], [78, 83], [84, 89], [90, 93], [94, 105], [106, 112], [113, 124], [125, 128], [129, 136], [137, 140], [141, 144], [145, 148], [149, 153], [154, 156], [157, 162], [162, 163]]}
{"doc_key": "ai-dev-46", "ner": [[2, 2, "misc"], [4, 4, "researcher"], [8, 10, "university"], [15, 15, "organisation"], [20, 22, "organisation"], [28, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 4, 4, "temporal", "", false, false], [4, 4, 15, 15, "physical", "", false, false], [4, 4, 15, 15, "role", "", false, false], [4, 4, 20, 22, "role", "", false, false], [20, 22, 8, 10, "part-of", "", false, false], [28, 29, 20, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["After", "his", "PhD", ",", "Ghahramani", "went", "to", "the", "University", "of", "Toronto", "in", "1995", "as", "an", "ITRC", "Postdoctoral", "Fellow", "in", "the", "Artificial", "Intelligence", "Lab", ",", "where", "he", "worked", "with", "Geoffrey", "Hinton", "."], "sentence-detokenized": "After his PhD, Ghahramani went to the University of Toronto in 1995 as an ITRC Postdoctoral Fellow in the Artificial Intelligence Lab, where he worked with Geoffrey Hinton.", "token2charspan": [[0, 5], [6, 9], [10, 13], [13, 14], [15, 25], [26, 30], [31, 33], [34, 37], [38, 48], [49, 51], [52, 59], [60, 62], [63, 67], [68, 70], [71, 73], [74, 78], [79, 91], [92, 98], [99, 101], [102, 105], [106, 116], [117, 129], [130, 133], [133, 134], [135, 140], [141, 143], [144, 150], [151, 155], [156, 164], [165, 171], [171, 172]]}
{"doc_key": "ai-dev-47", "ner": [[21, 22, "metrics"], [24, 24, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[24, 24, 21, 22, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Later", "works", "emphasised", "tackling", "these", "problems", ",", "but", "it", "was", "not", "until", "the", "advent", "of", "modern", "computers", "and", "the", "popularisation", "of", "maximum", "likelihood", "(", "MLE", ")", "parameterisation", "techniques", "that", "research", "really", "took", "off", "."], "sentence-detokenized": "Later works emphasised tackling these problems, but it was not until the advent of modern computers and the popularisation of maximum likelihood (MLE) parameterisation techniques that research really took off.", "token2charspan": [[0, 5], [6, 11], [12, 22], [23, 31], [32, 37], [38, 46], [46, 47], [48, 51], [52, 54], [55, 58], [59, 62], [63, 68], [69, 72], [73, 79], [80, 82], [83, 89], [90, 99], [100, 103], [104, 107], [108, 122], [123, 125], [126, 133], [134, 144], [145, 146], [146, 149], [149, 150], [151, 167], [168, 178], [179, 183], [184, 192], [193, 199], [200, 204], [205, 208], [208, 209]]}
{"doc_key": "ai-dev-48", "ner": [[5, 6, "person"], [9, 14, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "series", "was", "produced", "by", "David", "Fincher", ",", "and", "Kevin", "Spacey", "played", "the", "lead", "role", "."], "sentence-detokenized": "The series was produced by David Fincher, and Kevin Spacey played the lead role.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 40], [40, 41], [42, 45], [46, 51], [52, 58], [59, 65], [66, 69], [70, 74], [75, 79], [79, 80]]}
{"doc_key": "ai-dev-49", "ner": [[16, 16, "metrics"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Due", "to", "limited", "computational", "power", ",", "current", "in", "silico", "methods", "usually", "have", "to", "trade", "speed", "for", "accuracy", ";", "for", "example", ",", "fast", "protein", "docking", "methods", "can", "be", "used", "instead", "of", "costly", "free", "energy", "calculations", "."], "sentence-detokenized": "Due to limited computational power, current in silico methods usually have to trade speed for accuracy; for example, fast protein docking methods can be used instead of costly free energy calculations.", "token2charspan": [[0, 3], [4, 6], [7, 14], [15, 28], [29, 34], [34, 35], [36, 43], [44, 46], [47, 53], [54, 61], [62, 69], [70, 74], [75, 77], [78, 83], [84, 89], [90, 93], [94, 102], [102, 103], [104, 107], [108, 115], [115, 116], [117, 121], [122, 129], [130, 137], [138, 145], [146, 149], [150, 152], [153, 157], [158, 165], [166, 168], [169, 175], [176, 180], [181, 187], [188, 200], [200, 201]]}
{"doc_key": "ai-dev-50", "ner": [[8, 8, "country"], [10, 10, "country"], [12, 12, "country"], [14, 14, "country"], [16, 16, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "had", "more", "than", "30", "branches", "in", "the", "US", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "sentence-detokenized": "It had more than 30 branches in the US , Canada, Mexico, Brazil and Argentina.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 19], [20, 28], [29, 31], [32, 35], [36, 38], [39, 40], [41, 47], [47, 48], [49, 55], [55, 56], [57, 63], [64, 67], [68, 77], [77, 78]]}
{"doc_key": "ai-dev-51", "ner": [[5, 6, "field"], [10, 11, "product"], [13, 15, "algorithm"], [18, 19, "task"], [21, 22, "task"], [29, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 11, 5, 6, "part-of", "", false, false], [10, 11, 13, 15, "usage", "", false, false], [18, 19, 5, 6, "part-of", "task_part_of_field", false, false], [18, 19, 29, 29, "related-to", "performs", false, false], [21, 22, 5, 6, "part-of", "task_part_of_field", false, false], [21, 22, 29, 29, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["An", "example", "of", "a", "typical", "computer", "vision", "computation", "pipeline", "for", "face", "recognition", "using", "k", "-", "NN", ",", "including", "feature", "extraction", "and", "dimension", "reduction", "pre-processing", "steps", "(", "usually", "performed", "with", "OpenCV", ")", ":"], "sentence-detokenized": "An example of a typical computer vision computation pipeline for face recognition using k -NN, including feature extraction and dimension reduction pre-processing steps (usually performed with OpenCV):", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 23], [24, 32], [33, 39], [40, 51], [52, 60], [61, 64], [65, 69], [70, 81], [82, 87], [88, 89], [90, 91], [91, 93], [93, 94], [95, 104], [105, 112], [113, 123], [124, 127], [128, 137], [138, 147], [148, 162], [163, 168], [169, 170], [170, 177], [178, 187], [188, 192], [193, 199], [199, 200], [200, 201]]}
{"doc_key": "ai-dev-52", "ner": [[10, 12, "algorithm"], [14, 14, "misc"], [16, 17, "misc"], [19, 19, "misc"], [23, 23, "programlang"], [25, 25, "product"], [29, 30, "algorithm"], [33, 34, "misc"], [36, 36, "misc"], [38, 38, "misc"], [40, 40, "misc"], [47, 47, "misc"], [50, 51, "misc"], [53, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "a", "rich", "set", "of", "features", ",", "libraries", "for", "constraint", "logic", "programming", ",", "multithreading", ",", "unit", "testing", ",", "GUI", ",", "interfacing", "with", "Java", ",", "ODBC", "and", "others", ",", "literate", "programming", ",", "a", "web", "server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "developer", "tools", "(", "including", "an", "IDE", "with", "a", "GUI", "debugger", "and", "GUI", "profiler", ")", ",", "and", "extensive", "documentation", "."], "sentence-detokenized": "It has a rich set of features, libraries for constraint logic programming, multithreading, unit testing, GUI, interfacing with Java, ODBC and others, literate programming, a web server, SGML, RDF, RDFS, developer tools (including an IDE with a GUI debugger and GUI profiler), and extensive documentation.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 13], [14, 17], [18, 20], [21, 29], [29, 30], [31, 40], [41, 44], [45, 55], [56, 61], [62, 73], [73, 74], [75, 89], [89, 90], [91, 95], [96, 103], [103, 104], [105, 108], [108, 109], [110, 121], [122, 126], [127, 131], [131, 132], [133, 137], [138, 141], [142, 148], [148, 149], [150, 158], [159, 170], [170, 171], [172, 173], [174, 177], [178, 184], [184, 185], [186, 190], [190, 191], [192, 195], [195, 196], [197, 201], [201, 202], [203, 212], [213, 218], [219, 220], [220, 229], [230, 232], [233, 236], [237, 241], [242, 243], [244, 247], [248, 256], [257, 260], [261, 264], [265, 273], [273, 274], [274, 275], [276, 279], [280, 289], [290, 303], [303, 304]]}
{"doc_key": "ai-dev-53", "ner": [[1, 2, "field"], [4, 5, "field"], [10, 12, "misc"], [14, 16, "misc"], [19, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 1, 2, "part-of", "", true, false], [10, 12, 4, 5, "part-of", "", false, false], [10, 12, 19, 22, "type-of", "", false, false], [14, 16, 1, 2, "part-of", "", false, false], [14, 16, 4, 5, "part-of", "", false, false], [14, 16, 19, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "computer", "vision", "and", "image", "processing", ",", "the", "concept", "of", "scale", "space", "representation", "and", "Gaussian", "derived", "operators", "as", "a", "canonical", "multi", "-scale", "representation", "."], "sentence-detokenized": "In computer vision and image processing, the concept of scale space representation and Gaussian derived operators as a canonical multi-scale representation.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 22], [23, 28], [29, 39], [39, 40], [41, 44], [45, 52], [53, 55], [56, 61], [62, 67], [68, 82], [83, 86], [87, 95], [96, 103], [104, 113], [114, 116], [117, 118], [119, 128], [129, 134], [134, 140], [141, 155], [155, 156]]}
{"doc_key": "ai-dev-54", "ner": [[6, 10, "organisation"], [19, 24, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 10, 19, 24, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "also", "president", "of", "the", "Neural", "Information", "Processing", "Systems", "Foundation", ",", "a", "non-profit", "organisation", "that", "oversees", "the", "annual", "Conference", "on", "Neural", "Information", "Processing", "Systems", "."], "sentence-detokenized": "He is also president of the Neural Information Processing Systems Foundation, a non-profit organisation that oversees the annual Conference on Neural Information Processing Systems.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 20], [21, 23], [24, 27], [28, 34], [35, 46], [47, 57], [58, 65], [66, 76], [76, 77], [78, 79], [80, 90], [91, 103], [104, 108], [109, 117], [118, 121], [122, 128], [129, 139], [140, 142], [143, 149], [150, 161], [162, 172], [173, 180], [180, 181]]}
{"doc_key": "ai-dev-55", "ner": [[6, 12, "metrics"], [13, 14, "misc"], [17, 17, "task"], [20, 21, "metrics"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[6, 12, 13, 14, "type-of", "", false, false], [17, 17, 20, 21, "usage", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["For", "regression", "analysis", "problems", ",", "the", "squared", "error", "can", "be", "used", "as", "a", "loss", "function", ";", "for", "classification", ",", "the", "cross", "entropy", "can", "be", "used", "."], "sentence-detokenized": "For regression analysis problems, the squared error can be used as a loss function; for classification, the cross entropy can be used.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 32], [32, 33], [34, 37], [38, 45], [46, 51], [52, 55], [56, 58], [59, 63], [64, 66], [67, 68], [69, 73], [74, 82], [82, 83], [84, 87], [88, 102], [102, 103], [104, 107], [108, 113], [114, 121], [122, 125], [126, 128], [129, 133], [133, 134]]}
{"doc_key": "ai-dev-56", "ner": [[0, 0, "researcher"], [17, 20, "conference"], [22, 27, "conference"], [36, 36, "university"], [40, 41, "field"], [50, 54, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 17, 20, "role", "", false, false], [0, 0, 36, 36, "physical", "", false, false], [0, 0, 36, 36, "role", "", false, false], [0, 0, 50, 54, "role", "", false, false], [17, 20, 22, 27, "named", "same", false, false], [36, 36, 40, 41, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Lafferty", "held", "many", "prestigious", "positions", ",", "including", ":", "1", ")", "programme", "co-chair", "and", "general", "co-chair", "of", "the", "Neural", "Information", "Processing", "Systems", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", ")", "Foundation", "conferences", ";", "2", ")", "co-director", "of", "CMU", "'s", "new", "Ph.D.", "Machine", "Learning", "Program", ";", "3", ")", "associate", "editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research"], "sentence-detokenized": "Lafferty held many prestigious positions, including: 1) programme co-chair and general co-chair of the Neural Information Processing Systems (Conference on Neural Information Processing Systems) Foundation conferences; 2) co-director of CMU's new Ph.D. Machine Learning Program; 3) associate editor of the Journal of Machine Learning Research", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 30], [31, 40], [40, 41], [42, 51], [51, 52], [53, 54], [54, 55], [56, 65], [66, 74], [75, 78], [79, 86], [87, 95], [96, 98], [99, 102], [103, 109], [110, 121], [122, 132], [133, 140], [141, 142], [142, 152], [153, 155], [156, 162], [163, 174], [175, 185], [186, 193], [193, 194], [195, 205], [206, 217], [217, 218], [219, 220], [220, 221], [222, 233], [234, 236], [237, 240], [240, 242], [243, 246], [247, 252], [253, 260], [261, 269], [270, 277], [277, 278], [279, 280], [280, 281], [282, 291], [292, 298], [299, 301], [302, 305], [306, 313], [314, 316], [317, 324], [325, 333], [334, 342]]}
{"doc_key": "ai-dev-57", "ner": [[0, 1, "misc"], [5, 5, "algorithm"], [7, 7, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 1, "type-of", "", false, false], [7, 7, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Convex", "algorithms", ",", "such", "as", "AdaBoost", "and", "LogitBoost", ",", "can", "be", "defeated", "by", "random", "noise", ",", "so", "they", "can", "not", "learn", "elementary", "and", "learnable", "combinations", "of", "weak", "hypotheses", "."], "sentence-detokenized": "Convex algorithms, such as AdaBoost and LogitBoost, can be defeated by random noise, so they cannot learn elementary and learnable combinations of weak hypotheses.", "token2charspan": [[0, 6], [7, 17], [17, 18], [19, 23], [24, 26], [27, 35], [36, 39], [40, 50], [50, 51], [52, 55], [56, 58], [59, 67], [68, 70], [71, 77], [78, 83], [83, 84], [85, 87], [88, 92], [93, 96], [96, 99], [100, 105], [106, 116], [117, 120], [121, 130], [131, 143], [144, 146], [147, 151], [152, 162], [162, 163]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [3, 8, "product"], [11, 13, "algorithm"], [20, 20, "algorithm"], [24, 29, "task"], [31, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 8, "type-of", "", false, false], [0, 0, 11, 13, "usage", "", false, false], [0, 0, 20, 20, "usage", "", false, false], [20, 20, 24, 29, "related-to", "used_for", true, false], [20, 20, 31, 33, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "is", "a", "machine", "translation", "system", "with", "shallow", "transfer", ",", "using", "finite", "state", "inverters", "for", "all", "lexical", "transformations", ",", "and", "hidden", "Markov", "models", "for", "part", "-", "of", "-", "speech", "tagging", "or", "word", "category", "disambiguation", "."], "sentence-detokenized": "Apertium is a machine translation system with shallow transfer, using finite state inverters for all lexical transformations, and hidden Markov models for part-of-speech tagging or word category disambiguation.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 21], [22, 33], [34, 40], [41, 45], [46, 53], [54, 62], [62, 63], [64, 69], [70, 76], [77, 82], [83, 92], [93, 96], [97, 100], [101, 108], [109, 124], [124, 125], [126, 129], [130, 136], [137, 143], [144, 150], [151, 154], [155, 159], [159, 160], [160, 162], [162, 163], [163, 169], [170, 177], [178, 180], [181, 185], [186, 194], [195, 209], [209, 210]]}
{"doc_key": "ai-dev-59", "ner": [[1, 2, "misc"], [16, 18, "metrics"], [31, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 16, 18, "related-to", "", true, false], [16, 18, 31, 32, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "natural", "gradient", "of", "mathE", "f", "(", "x", ")", "/", "math", ",", "in", "accordance", "with", "the", "Fisher", "information", "metric", "(", "an", "informative", "distance", "measure", "between", "probability", "distributions", "and", "the", "curvature", "of", "relative", "entropy", ")", ",", "now", "reads"], "sentence-detokenized": "The natural gradient of mathE f (x) / math, in accordance with the Fisher information metric (an informative distance measure between probability distributions and the curvature of relative entropy), now reads", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 23], [24, 29], [30, 31], [32, 33], [33, 34], [34, 35], [36, 37], [38, 42], [42, 43], [44, 46], [47, 57], [58, 62], [63, 66], [67, 73], [74, 85], [86, 92], [93, 94], [94, 96], [97, 108], [109, 117], [118, 125], [126, 133], [134, 145], [146, 159], [160, 163], [164, 167], [168, 177], [178, 180], [181, 189], [190, 197], [197, 198], [198, 199], [200, 203], [204, 209]]}
{"doc_key": "ai-dev-60", "ner": [[1, 8, "programlang"], [10, 13, "product"], [15, 15, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 13, 1, 8, "origin", "", false, false], [15, 15, 1, 8, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "programming", "language", "S", "was", "the", "inspiration", "for", "the", "systems", "S", "'", "-", "PLUS", "and", "R."], "sentence-detokenized": "The programming language S was the inspiration for the systems S '-PLUS and R.", "token2charspan": [[0, 3], [4, 15], [16, 24], [25, 26], [27, 30], [31, 34], [35, 46], [47, 50], [51, 54], [55, 62], [63, 64], [65, 66], [66, 67], [67, 71], [72, 75], [76, 78]]}
{"doc_key": "ai-dev-61", "ner": [[5, 5, "product"], [10, 10, "product"], [12, 14, "product"], [18, 20, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 10, 10, "named", "same", false, false], [12, 14, 10, 10, "origin", "derived_from", false, false], [12, 14, 18, 20, "origin", "", false, false], [12, 14, 22, 23, "origin", "", false, false], [12, 14, 25, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "most", "influential", "implementation", "of", "Planner", "was", "the", "subset", "of", "Planner", "called", "Micro", "-", "Planner", ",", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "."], "sentence-detokenized": "The most influential implementation of Planner was the subset of Planner called Micro-Planner, implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 35], [36, 38], [39, 46], [47, 50], [51, 54], [55, 61], [62, 64], [65, 72], [73, 79], [80, 85], [85, 86], [86, 93], [93, 94], [95, 106], [107, 109], [110, 116], [117, 120], [121, 128], [128, 129], [130, 136], [137, 145], [146, 149], [150, 155], [156, 164], [164, 165]]}
{"doc_key": "ai-dev-62", "ner": [[3, 5, "country"], [7, 9, "researcher"], [19, 19, "misc"], [20, 25, "university"], [33, 34, "misc"], [44, 44, "misc"], [50, 53, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[7, 9, 3, 5, "general-affiliation", "from_country", false, false], [20, 25, 19, 19, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1779", ",", "German", "-", "Danish", "scientist", "Christian", "Gottlieb", "Kratzenstein", "won", "first", "prize", "in", "a", "competition", "announced", "by", "the", "Russian", "Imperial", "Academy", "of", "Sciences", "and", "Arts", "for", "models", "he", "built", "of", "the", "human", "vocal", "tract", "that", "could", "be", "used", "to", "produce", "the", "five", "long", "vowels", "(", "in", "the", "notation", "of", "the", "International", "Phonetic", "Alphabet", ":"], "sentence-detokenized": "In 1779, German-Danish scientist Christian Gottlieb Kratzenstein won first prize in a competition announced by the Russian Imperial Academy of Sciences and Arts for models he built of the human vocal tract that could be used to produce the five long vowels (in the notation of the International Phonetic Alphabet:", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [15, 16], [16, 22], [23, 32], [33, 42], [43, 51], [52, 64], [65, 68], [69, 74], [75, 80], [81, 83], [84, 85], [86, 97], [98, 107], [108, 110], [111, 114], [115, 122], [123, 131], [132, 139], [140, 142], [143, 151], [152, 155], [156, 160], [161, 164], [165, 171], [172, 174], [175, 180], [181, 183], [184, 187], [188, 193], [194, 199], [200, 205], [206, 210], [211, 216], [217, 219], [220, 224], [225, 227], [228, 235], [236, 239], [240, 244], [245, 249], [250, 256], [257, 258], [258, 260], [261, 264], [265, 273], [274, 276], [277, 280], [281, 294], [295, 303], [304, 312], [312, 313]]}
{"doc_key": "ai-dev-63", "ner": [[3, 4, "product"], [6, 7, "misc"], [10, 14, "misc"], [33, 35, "misc"], [58, 59, "task"], [64, 65, "product"], [67, 67, "product"], [71, 72, "task"], [74, 75, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 4, 64, 65, "related-to", "supports_program", false, false], [3, 4, 67, 67, "related-to", "supports_program", false, false], [6, 7, 3, 4, "part-of", "", false, false], [10, 14, 3, 4, "part-of", "", false, false], [33, 35, 3, 4, "part-of", "", false, false], [58, 59, 3, 4, "part-of", "", false, false], [71, 72, 3, 4, "part-of", "", false, false], [74, 75, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["New", "features", "in", "Office", "XP", "include", "smart", "tags", ",", "a", "selection", "-", "based", "search", "function", "that", "recognises", "different", "types", "of", "text", "in", "a", "document", ",", "allowing", "users", "to", "perform", "additional", "actions", ";", "a", "task", "window", "interface", "that", "consolidates", "popular", "commands", "from", "the", "menu", "bar", "on", "the", "right", "side", "of", "the", "screen", "to", "make", "them", "quickly", "accessible", ";", "new", "document", "collaboration", "capabilities", ",", "support", "for", "MSN", "Groups", "and", "SharePoint", ";", "and", "integrated", "handwriting", "recognition", "and", "speech", "recognition", "capabilities", "."], "sentence-detokenized": "New features in Office XP include smart tags, a selection-based search function that recognises different types of text in a document, allowing users to perform additional actions; a task window interface that consolidates popular commands from the menu bar on the right side of the screen to make them quickly accessible; new document collaboration capabilities, support for MSN Groups and SharePoint; and integrated handwriting recognition and speech recognition capabilities.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 25], [26, 33], [34, 39], [40, 44], [44, 45], [46, 47], [48, 57], [57, 58], [58, 63], [64, 70], [71, 79], [80, 84], [85, 95], [96, 105], [106, 111], [112, 114], [115, 119], [120, 122], [123, 124], [125, 133], [133, 134], [135, 143], [144, 149], [150, 152], [153, 160], [161, 171], [172, 179], [179, 180], [181, 182], [183, 187], [188, 194], [195, 204], [205, 209], [210, 222], [223, 230], [231, 239], [240, 244], [245, 248], [249, 253], [254, 257], [258, 260], [261, 264], [265, 270], [271, 275], [276, 278], [279, 282], [283, 289], [290, 292], [293, 297], [298, 302], [303, 310], [311, 321], [321, 322], [323, 326], [327, 335], [336, 349], [350, 362], [362, 363], [364, 371], [372, 375], [376, 379], [380, 386], [387, 390], [391, 401], [401, 402], [403, 406], [407, 417], [418, 429], [430, 441], [442, 445], [446, 452], [453, 464], [465, 477], [477, 478]]}
{"doc_key": "ai-dev-64", "ner": [[11, 12, "algorithm"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 15, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "many", "applications", ",", "the", "units", "of", "these", "networks", "apply", "a", "sigmoid", "function", "as", "an", "activation", "function", "."], "sentence-detokenized": "In many applications, the units of these networks apply a sigmoid function as an activation function.", "token2charspan": [[0, 2], [3, 7], [8, 20], [20, 21], [22, 25], [26, 31], [32, 34], [35, 40], [41, 49], [50, 55], [56, 57], [58, 65], [66, 74], [75, 77], [78, 80], [81, 91], [92, 100], [100, 101]]}
{"doc_key": "ai-dev-65", "ner": [[3, 5, "researcher"], [11, 16, "organisation"], [27, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 11, 16, "role", "", false, false], [3, 5, 27, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2001", ",", "Mehler", "was", "elected", "foreign", "honorary", "member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "and", "in", "2003", "he", "was", "elected", "Fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In 2001, Mehler was elected foreign honorary member of the American Academy of Arts and Sciences, and in 2003 he was elected Fellow of the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 27], [28, 35], [36, 44], [45, 51], [52, 54], [55, 58], [59, 67], [68, 75], [76, 78], [79, 83], [84, 87], [88, 96], [96, 97], [98, 101], [102, 104], [105, 109], [110, 112], [113, 116], [117, 124], [125, 131], [132, 134], [135, 138], [139, 147], [148, 159], [160, 163], [164, 167], [168, 179], [180, 182], [183, 190], [190, 191]]}
{"doc_key": "ai-dev-66", "ner": [[4, 6, "task"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 9, 10, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Extending", "this", "concept", "to", "non", "-binary", "classifiers", "yields", "the", "confusion", "matrix", "."], "sentence-detokenized": "Extending this concept to non-binary classifiers yields the confusion matrix.", "token2charspan": [[0, 9], [10, 14], [15, 22], [23, 25], [26, 29], [29, 36], [37, 48], [49, 55], [56, 59], [60, 69], [70, 76], [76, 77]]}
{"doc_key": "ai-dev-67", "ner": [[15, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "updated", "estimate", "of", "the", "variance", "of", "the", "measurement", "noise", "can", "be", "obtained", "using", "the", "maximum", "plausibility", "calculation"], "sentence-detokenized": "An updated estimate of the variance of the measurement noise can be obtained using the maximum plausibility calculation", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 22], [23, 26], [27, 35], [36, 38], [39, 42], [43, 54], [55, 60], [61, 64], [65, 67], [68, 76], [77, 82], [83, 86], [87, 94], [95, 107], [108, 119]]}
{"doc_key": "ai-dev-68", "ner": [[1, 6, "field"], [5, 5, "algorithm"], [10, 11, "field"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 10, 11, "usage", "", true, false], [5, 5, 13, 14, "related-to", "", true, false], [10, 11, 1, 6, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "machine", "learning", ",", "the", "perceptron", "is", "an", "algorithm", "for", "supervised", "learning", "of", "binary", "classification", "."], "sentence-detokenized": "In machine learning, the perceptron is an algorithm for supervised learning of binary classification.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 24], [25, 35], [36, 38], [39, 41], [42, 51], [52, 55], [56, 66], [67, 75], [76, 78], [79, 85], [86, 100], [100, 101]]}
{"doc_key": "ai-dev-69", "ner": [[6, 7, "field"], [9, 9, "field"], [12, 18, "conference"], [20, 25, "conference"], [27, 34, "conference"], [36, 41, "conference"], [44, 49, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 18, 6, 7, "topic", "", false, false], [12, 18, 9, 9, "topic", "", false, false], [20, 25, 6, 7, "topic", "", false, false], [20, 25, 9, 9, "topic", "", false, false], [27, 34, 6, 7, "topic", "", false, false], [27, 34, 9, 9, "topic", "", false, false], [36, 41, 6, 7, "topic", "", false, false], [36, 41, 9, 9, "topic", "", false, false], [44, 49, 6, 7, "topic", "", false, false], [44, 49, 9, 9, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["She", "also", "chaired", "several", "conferences", "on", "machine", "learning", "and", "vision", ",", "including", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "the", "International", "Conference", "on", "Learning", "Representations", ",", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "the", "International", "Conference", "on", "Computer", "Vision", ",", "and", "the", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "She also chaired several conferences on machine learning and vision, including the Conference on Neural Information Processing Systems, the International Conference on Learning Representations, the Conference on Computer Vision and Pattern Recognition, the International Conference on Computer Vision, and the European Conference on Computer Vision.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 24], [25, 36], [37, 39], [40, 47], [48, 56], [57, 60], [61, 67], [67, 68], [69, 78], [79, 82], [83, 93], [94, 96], [97, 103], [104, 115], [116, 126], [127, 134], [134, 135], [136, 139], [140, 153], [154, 164], [165, 167], [168, 176], [177, 192], [192, 193], [194, 197], [198, 208], [209, 211], [212, 220], [221, 227], [228, 231], [232, 239], [240, 251], [251, 252], [253, 256], [257, 270], [271, 281], [282, 284], [285, 293], [294, 300], [300, 301], [302, 305], [306, 309], [310, 318], [319, 329], [330, 332], [333, 341], [342, 348], [348, 349]]}
{"doc_key": "ai-dev-70", "ner": [[1, 2, "algorithm"], [9, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 1, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "condensation", "algorithm", "has", "also", "been", "used", "for", "a", "face", "recognition", "system", "in", "a", "video", "sequence", "."], "sentence-detokenized": "The condensation algorithm has also been used for a face recognition system in a video sequence.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 30], [31, 35], [36, 40], [41, 45], [46, 49], [50, 51], [52, 56], [57, 68], [69, 75], [76, 78], [79, 80], [81, 86], [87, 95], [95, 96]]}
{"doc_key": "ai-dev-71", "ner": [[0, 3, "task"], [7, 8, "organisation"], [18, 18, "conference"], [22, 26, "academicjournal"], [30, 30, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[18, 18, 0, 3, "topic", "", false, false], [18, 18, 7, 8, "origin", "", false, false], [22, 26, 0, 3, "topic", "", false, false], [22, 26, 7, 8, "origin", "", true, false], [30, 30, 22, 26, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Dissemination", "of", "information", "is", "also", "part", "of", "ELRA", "'s", "duties", ",", "fulfilled", "through", "both", "the", "organisation", "of", "the", "LREC", "conference", "and", "the", "Language", "Resources", "and", "Evaluation", "Journal", ",", "published", "by", "Springer", "."], "sentence-detokenized": "Dissemination of information is also part of ELRA's duties, fulfilled through both the organisation of the LREC conference and the Language Resources and Evaluation Journal, published by Springer.", "token2charspan": [[0, 13], [14, 16], [17, 28], [29, 31], [32, 36], [37, 41], [42, 44], [45, 49], [49, 51], [52, 58], [58, 59], [60, 69], [70, 77], [78, 82], [83, 86], [87, 99], [100, 102], [103, 106], [107, 111], [112, 122], [123, 126], [127, 130], [131, 139], [140, 149], [150, 153], [154, 164], [165, 172], [172, 173], [174, 183], [184, 186], [187, 195], [195, 196]]}
{"doc_key": "ai-dev-72", "ner": [[1, 9, "field"], [11, 12, "field"], [15, 17, "field"], [19, 20, "field"], [54, 55, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 9, 54, 55, "named", "", false, false], [15, 17, 1, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "linear", "time", "-", "invariant", "(", "LTI", ")", "system", "theory", ",", "control", "theory", "and", "in", "digital", "signal", "processing", "or", "signal", "processing", ",", "the", "relationship", "between", "the", "input", "signal", ",", "math", "displaystyle", "x", "(", "t", ")", "/", "math", ",", "and", "the", "output", "signal", ",", "math", "displaystyle", "y", "(", "t", ")", "/", "math", ",", "of", "an", "LTI", "system", "is", "governed", "by", "a", "convolution", "operation", ":"], "sentence-detokenized": "In linear time-invariant (LTI) system theory, control theory and in digital signal processing or signal processing, the relationship between the input signal, math displaystyle x (t) / math, and the output signal, math displaystyle y (t) / math, of an LTI system is governed by a convolution operation:", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [15, 24], [25, 26], [26, 29], [29, 30], [31, 37], [38, 44], [44, 45], [46, 53], [54, 60], [61, 64], [65, 67], [68, 75], [76, 82], [83, 93], [94, 96], [97, 103], [104, 114], [114, 115], [116, 119], [120, 132], [133, 140], [141, 144], [145, 150], [151, 157], [157, 158], [159, 163], [164, 176], [177, 178], [179, 180], [180, 181], [181, 182], [183, 184], [185, 189], [189, 190], [191, 194], [195, 198], [199, 205], [206, 212], [212, 213], [214, 218], [219, 231], [232, 233], [234, 235], [235, 236], [236, 237], [238, 239], [240, 244], [244, 245], [246, 248], [249, 251], [252, 255], [256, 262], [263, 265], [266, 274], [275, 277], [278, 279], [280, 291], [292, 301], [301, 302]]}
{"doc_key": "ai-dev-73", "ner": [[16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 31, "field"], [33, 34, "product"], [36, 37, "field"], [39, 39, "field"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Due", "to", "its", "generality", ",", "the", "field", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Due to its generality, the field is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 21], [21, 22], [23, 26], [27, 32], [33, 35], [36, 43], [44, 46], [47, 51], [52, 57], [58, 69], [69, 70], [71, 75], [76, 78], [79, 83], [84, 90], [90, 91], [92, 99], [100, 106], [106, 107], [108, 118], [119, 127], [127, 128], [129, 140], [141, 147], [147, 148], [149, 159], [159, 160], [160, 165], [166, 178], [178, 179], [180, 191], [192, 199], [199, 200], [201, 206], [207, 219], [219, 220], [221, 231], [232, 235], [236, 243], [244, 254], [254, 255]]}
{"doc_key": "ai-dev-74", "ner": [[0, 2, "algorithm"], [15, 16, "field"], [22, 23, "algorithm"], [26, 27, "algorithm"], [34, 35, "algorithm"], [38, 38, "algorithm"], [39, 41, "researcher"], [43, 44, "researcher"], [46, 48, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[15, 16, 0, 2, "usage", "", true, false], [22, 23, 15, 16, "part-of", "", true, false], [26, 27, 15, 16, "part-of", "", true, false], [34, 35, 15, 16, "part-of", "", true, false], [38, 38, 15, 16, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Stochastic", "gradient", "descent", "is", "a", "popular", "algorithm", "for", "training", "a", "wide", "range", "of", "models", "in", "machine", "learning", ",", "including", "(", "linear", ")", "support", "vector", "machines", ",", "logistic", "regression", "(", "see", ",", "for", "example", ",", "Vowpal", "Wabbit", ")", "and", "graphical", "models.Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastic gradient descent is a popular algorithm for training a wide range of models in machine learning, including (linear) support vector machines, logistic regression (see, for example, Vowpal Wabbit) and graphical models.Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 30], [31, 32], [33, 40], [41, 50], [51, 54], [55, 63], [64, 65], [66, 70], [71, 76], [77, 79], [80, 86], [87, 89], [90, 97], [98, 106], [106, 107], [108, 117], [118, 119], [119, 125], [125, 126], [127, 134], [135, 141], [142, 150], [150, 151], [152, 160], [161, 171], [172, 173], [173, 176], [176, 177], [178, 181], [182, 189], [189, 190], [191, 197], [198, 204], [204, 205], [206, 209], [210, 219], [220, 232], [233, 237], [238, 244], [244, 245], [246, 250], [251, 258], [258, 259], [260, 271], [272, 274], [275, 282], [283, 284], [284, 288], [288, 289], [289, 290]]}
{"doc_key": "ai-dev-75", "ner": [[8, 8, "organisation"], [12, 13, "product"], [20, 20, "country"], [22, 25, "university"], [27, 27, "location"], [29, 31, "university"], [33, 33, "location"], [35, 36, "university"], [38, 38, "location"], [40, 42, "university"], [44, 44, "location"], [46, 47, "university"], [49, 49, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 22, 25, "role", "donates_to", false, false], [8, 8, 29, 31, "role", "donates_to", false, false], [8, 8, 35, 36, "role", "donates_to", false, false], [8, 8, 40, 42, "role", "donates_to", false, false], [8, 8, 46, 47, "role", "donates_to", false, false], [12, 13, 8, 8, "origin", "donates", true, false], [22, 25, 27, 27, "physical", "", false, false], [27, 27, 20, 20, "physical", "", false, false], [29, 31, 33, 33, "physical", "", false, false], [33, 33, 20, 20, "physical", "", false, false], [35, 36, 38, 38, "physical", "", false, false], [38, 38, 20, 20, "physical", "", false, false], [40, 42, 44, 44, "physical", "", false, false], [44, 44, 20, 20, "physical", "", false, false], [46, 47, 49, 49, "physical", "", false, false], [49, 49, 20, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["In", "August", "2011", ",", "it", "was", "announced", "that", "Hitachi", "would", "donate", "an", "electron", "microscope", "to", "each", "of", "five", "universities", "in", "Indonesia", "(", "University", "of", "North", "Sumatra", "in", "Medan", ",", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Padjadjaran", "University", "in", "Bandung", ",", "Jenderal", "Soedirman", "University", "in", "Purwokerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "sentence-detokenized": "In August 2011, it was announced that Hitachi would donate an electron microscope to each of five universities in Indonesia (University of North Sumatra in Medan, Indonesian Christian University in Jakarta, Padjadjaran University in Bandung, Jenderal Soedirman University in Purwokerto and Muhammadiyah University in Malang).", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 32], [33, 37], [38, 45], [46, 51], [52, 58], [59, 61], [62, 70], [71, 81], [82, 84], [85, 89], [90, 92], [93, 97], [98, 110], [111, 113], [114, 123], [124, 125], [125, 135], [136, 138], [139, 144], [145, 152], [153, 155], [156, 161], [161, 162], [163, 173], [174, 183], [184, 194], [195, 197], [198, 205], [205, 206], [207, 218], [219, 229], [230, 232], [233, 240], [240, 241], [242, 250], [251, 260], [261, 271], [272, 274], [275, 285], [286, 289], [290, 302], [303, 313], [314, 316], [317, 323], [323, 324], [324, 325]]}
{"doc_key": "ai-dev-76", "ner": [[3, 4, "field"], [8, 9, "algorithm"], [11, 12, "algorithm"], [21, 22, "field"], [27, 28, "metrics"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Optimisation", "techniques", "from", "operations", "research", ",", "such", "as", "linear", "programming", "or", "dynamic", "programming", ",", "are", "often", "impractical", "for", "large", "-", "scale", "software", "engineering", "problems", "because", "of", "their", "computational", "complexity", "."], "sentence-detokenized": "Optimisation techniques from operations research, such as linear programming or dynamic programming, are often impractical for large-scale software engineering problems because of their computational complexity.", "token2charspan": [[0, 12], [13, 23], [24, 28], [29, 39], [40, 48], [48, 49], [50, 54], [55, 57], [58, 64], [65, 76], [77, 79], [80, 87], [88, 99], [99, 100], [101, 104], [105, 110], [111, 122], [123, 126], [127, 132], [132, 133], [133, 138], [139, 147], [148, 159], [160, 168], [169, 176], [177, 179], [180, 185], [186, 199], [200, 210], [210, 211]]}
{"doc_key": "ai-dev-77", "ner": [[0, 0, "metrics"], [6, 6, "metrics"], [8, 10, "metrics"], [17, 18, "metrics"], [24, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 6, "compare", "", false, false], [0, 0, 8, 10, "compare", "", false, false], [17, 18, 8, 10, "part-of", "", false, false], [24, 27, 8, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sensitivity", "is", "not", "the", "same", "as", "precision", "or", "positive", "predictive", "value", "(", "ratio", "of", "the", "number", "of", "TRUE", "positives", "to", "the", "number", "of", "combined", "TRUE", "and", "FALSE", "positives", ")", ",", "which", "is", "as", "much", "a", "statement", "about", "the", "percentage", "of", "actual", "positives", "in", "the", "population", "tested", "as", "it", "is", "about", "the", "test", "."], "sentence-detokenized": "Sensitivity is not the same as precision or positive predictive value (ratio of the number of TRUE positives to the number of combined TRUE and FALSE positives), which is as much a statement about the percentage of actual positives in the population tested as it is about the test.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 22], [23, 27], [28, 30], [31, 40], [41, 43], [44, 52], [53, 63], [64, 69], [70, 71], [71, 76], [77, 79], [80, 83], [84, 90], [91, 93], [94, 98], [99, 108], [109, 111], [112, 115], [116, 122], [123, 125], [126, 134], [135, 139], [140, 143], [144, 149], [150, 159], [159, 160], [160, 161], [162, 167], [168, 170], [171, 173], [174, 178], [179, 180], [181, 190], [191, 196], [197, 200], [201, 211], [212, 214], [215, 221], [222, 231], [232, 234], [235, 238], [239, 249], [250, 256], [257, 259], [260, 262], [263, 265], [266, 271], [272, 275], [276, 280], [280, 281]]}
{"doc_key": "ai-dev-78", "ner": [[3, 4, "person"], [9, 9, "product"], [12, 12, "person"], [26, 26, "person"], [33, 34, "person"], [38, 38, "person"], [44, 45, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 4, 38, 38, "named", "same", false, false], [9, 9, 3, 4, "artifact", "", false, false], [33, 34, 44, 45, "role", "convinces", false, false], [44, 45, 9, 9, "role", "producer", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "screenplay", "by", "Hampton", "Fancher", "!", "--", "initially", "untitled", "Android", "-", "See", "Sammon", ",", "pp.", "32", "and", "38", "for", "explanation", "--", "was", "optioned", "in", "1977", ".", "Sammon", ",", "pp.", "23", "-", "30", "Producer", "Michael", "Deeley", "became", "interested", "in", "Fancher", "'s", "concept", "and", "convinced", "director", "Ridley", "Scott", "to", "film", "it", "."], "sentence-detokenized": "The screenplay by Hampton Fancher! -- initially untitled Android - See Sammon, pp. 32 and 38 for explanation -- was optioned in 1977. Sammon, pp. 23-30 Producer Michael Deeley became interested in Fancher's concept and convinced director Ridley Scott to film it.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 25], [26, 33], [33, 34], [35, 37], [38, 47], [48, 56], [57, 64], [65, 66], [67, 70], [71, 77], [77, 78], [79, 82], [83, 85], [86, 89], [90, 92], [93, 96], [97, 108], [109, 111], [112, 115], [116, 124], [125, 127], [128, 132], [132, 133], [134, 140], [140, 141], [142, 145], [146, 148], [148, 149], [149, 151], [152, 160], [161, 168], [169, 175], [176, 182], [183, 193], [194, 196], [197, 204], [204, 206], [207, 214], [215, 218], [219, 228], [229, 237], [238, 244], [245, 250], [251, 253], [254, 258], [259, 261], [261, 262]]}
{"doc_key": "ai-dev-79", "ner": [[0, 1, "field"], [3, 4, "task"], [6, 7, "task"], [10, 12, "misc"], [14, 15, "field"], [17, 19, "task"], [21, 22, "task"], [28, 31, "task"], [33, 33, "task"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [6, 7, 0, 1, "part-of", "", false, false], [10, 12, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false], [17, 19, 0, 1, "part-of", "", false, false], [21, 22, 0, 1, "part-of", "", false, false], [28, 31, 0, 1, "part-of", "", false, false], [33, 33, 0, 1, "part-of", "", false, false], [36, 37, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9], "sentence": ["Text", "analysis", "includes", "information", "retrieval", ",", "lexical", "analysis", "to", "study", "word", "frequency", "distributions", ",", "pattern", "recognition", ",", "tagging", "/", "annotation", ",", "information", "extraction", ",", "data", "mining", "techniques", "including", "link", "and", "association", "analysis", ",", "visualisation", ",", "and", "predictive", "analysis", "."], "sentence-detokenized": "Text analysis includes information retrieval, lexical analysis to study word frequency distributions, pattern recognition, tagging/annotation, information extraction, data mining techniques including link and association analysis, visualisation, and predictive analysis.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 34], [35, 44], [44, 45], [46, 53], [54, 62], [63, 65], [66, 71], [72, 76], [77, 86], [87, 100], [100, 101], [102, 109], [110, 121], [121, 122], [123, 130], [130, 131], [131, 141], [141, 142], [143, 154], [155, 165], [165, 166], [167, 171], [172, 178], [179, 189], [190, 199], [200, 204], [205, 208], [209, 220], [221, 229], [229, 230], [231, 244], [244, 245], [246, 249], [250, 260], [261, 269], [269, 270]]}
{"doc_key": "ai-dev-80", "ner": [[3, 3, "product"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Several", "metrics", "use", "WordNet", ",", "a", "manually", "compiled", "lexical", "database", "of", "English", "words", "."], "sentence-detokenized": "Several metrics use WordNet, a manually compiled lexical database of English words.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 27], [27, 28], [29, 30], [31, 39], [40, 48], [49, 56], [57, 65], [66, 68], [69, 76], [77, 82], [82, 83]]}
{"doc_key": "ai-dev-81", "ner": [[8, 9, "field"], [11, 12, "task"], [14, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "system", "uses", "a", "combination", "of", "techniques", "from", "computational", "linguistics", ",", "information", "retrieval", "and", "knowledge", "representation", "to", "find", "answers", "."], "sentence-detokenized": "The system uses a combination of techniques from computational linguistics, information retrieval and knowledge representation to find answers.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 17], [18, 29], [30, 32], [33, 43], [44, 48], [49, 62], [63, 74], [74, 75], [76, 87], [88, 97], [98, 101], [102, 111], [112, 126], [127, 129], [130, 134], [135, 142], [142, 143]]}
{"doc_key": "ai-dev-82", "ner": [[6, 7, "metrics"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 13, 14, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "performance", "measure", ",", "the", "uncertainty", "coefficient", "has", "the", "advantage", "over", "simple", "accuracy", "in", "that", "it", "is", "not", "affected", "by", "the", "relative", "size", "of", "different", "classes", "."], "sentence-detokenized": "As a performance measure, the uncertainty coefficient has the advantage over simple accuracy in that it is not affected by the relative size of different classes.", "token2charspan": [[0, 2], [3, 4], [5, 16], [17, 24], [24, 25], [26, 29], [30, 41], [42, 53], [54, 57], [58, 61], [62, 71], [72, 76], [77, 83], [84, 92], [93, 95], [96, 100], [101, 103], [104, 106], [107, 110], [111, 119], [120, 122], [123, 126], [127, 135], [136, 140], [141, 143], [144, 153], [154, 161], [161, 162]]}
{"doc_key": "ai-dev-83", "ner": [[10, 11, "algorithm"], [13, 14, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Researchers", "have", "tried", "a", "number", "of", "methods", ",", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "hidden", "Markov", "models", ",", "etc", "."], "sentence-detokenized": "Researchers have tried a number of methods, such as optical flow, Kalman filtering, hidden Markov models, etc.", "token2charspan": [[0, 11], [12, 16], [17, 22], [23, 24], [25, 31], [32, 34], [35, 42], [42, 43], [44, 48], [49, 51], [52, 59], [60, 64], [64, 65], [66, 72], [73, 82], [82, 83], [84, 90], [91, 97], [98, 104], [104, 105], [106, 109], [109, 110]]}
{"doc_key": "ai-dev-84", "ner": [[12, 15, "conference"], [26, 28, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "has", "been", "president", ",", "vice-president", "and", "secretary", "-", "treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "board", "member", "and", "secretary", "of", "the", "board", "of", "the", "Computing", "Research", "Association", "."], "sentence-detokenized": "She has been president, vice-president and secretary-treasurer of the Association for Computational Linguistics and board member and secretary of the board of the Computing Research Association.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 22], [22, 23], [24, 38], [39, 42], [43, 52], [52, 53], [53, 62], [63, 65], [66, 69], [70, 81], [82, 85], [86, 99], [100, 111], [112, 115], [116, 121], [122, 128], [129, 132], [133, 142], [143, 145], [146, 149], [150, 155], [156, 158], [159, 162], [163, 172], [173, 181], [182, 193], [193, 194]]}
{"doc_key": "ai-dev-85", "ner": [[7, 7, "programlang"], [9, 9, "product"], [11, 11, "programlang"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 11, 11, "compare", "", false, false], [7, 7, 13, 14, "related-to", "supports", false, false], [9, 9, 11, 11, "compare", "", false, false], [9, 9, 13, 14, "related-to", "supports", false, false], [11, 11, 13, 14, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Like", "other", "similar", "languages", ",", "such", "as", "APL", "and", "MATLAB", ",", "R", "supports", "matrix", "arithmetic", "."], "sentence-detokenized": "Like other similar languages, such as APL and MATLAB, R supports matrix arithmetic.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 28], [28, 29], [30, 34], [35, 37], [38, 41], [42, 45], [46, 52], [52, 53], [54, 55], [56, 64], [65, 71], [72, 82], [82, 83]]}
{"doc_key": "ai-dev-86", "ner": [[9, 10, "organisation"], [16, 17, "researcher"], [20, 22, "university"], [26, 31, "misc"], [5, 5, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[16, 17, 20, 22, "role", "works_for", false, false]], "relations_mapping_to_source": [3], "sentence": ["On", "7", "June", "2014", ",", "Goostman", "won", "in", "a", "Royal", "Society", "Turing", "test", "contest", "organised", "by", "Kevin", "Warwick", "of", "the", "University", "of", "Reading", "to", "mark", "the", "60th", "anniversary", "of", "Turing", "'s", "death", ",", "after", "33", "%", "of", "the", "judges", "were", "convinced", "the", "bot", "was", "human", "."], "sentence-detokenized": "On 7 June 2014, Goostman won in a Royal Society Turing test contest organised by Kevin Warwick of the University of Reading to mark the 60th anniversary of Turing's death, after 33% of the judges were convinced the bot was human.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 14], [14, 15], [16, 24], [25, 28], [29, 31], [32, 33], [34, 39], [40, 47], [48, 54], [55, 59], [60, 67], [68, 77], [78, 80], [81, 86], [87, 94], [95, 97], [98, 101], [102, 112], [113, 115], [116, 123], [124, 126], [127, 131], [132, 135], [136, 140], [141, 152], [153, 155], [156, 162], [162, 164], [165, 170], [170, 171], [172, 177], [178, 180], [180, 181], [182, 184], [185, 188], [189, 195], [196, 200], [201, 210], [211, 214], [215, 218], [219, 222], [223, 228], [228, 229]]}
{"doc_key": "ai-dev-87", "ner": [[1, 2, "product"], [4, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "collaborative", "robot", "or", "cobot", "is", "a", "robot", "that", "can", "safely", "and", "effectively", "cooperate", "with", "human", "workers", "in", "performing", "simple", "industrial", "tasks", "."], "sentence-detokenized": "A collaborative robot or cobot is a robot that can safely and effectively cooperate with human workers in performing simple industrial tasks.", "token2charspan": [[0, 1], [2, 15], [16, 21], [22, 24], [25, 30], [31, 33], [34, 35], [36, 41], [42, 46], [47, 50], [51, 57], [58, 61], [62, 73], [74, 83], [84, 88], [89, 94], [95, 102], [103, 105], [106, 116], [117, 123], [124, 134], [135, 140], [140, 141]]}
{"doc_key": "ai-dev-88", "ner": [[13, 14, "field"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 30, "task"], [32, 34, "task"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[17, 18, 13, 14, "part-of", "task_part_of_field", false, false], [20, 21, 13, 14, "part-of", "task_part_of_field", false, false], [23, 24, 13, 14, "part-of", "task_part_of_field", false, false], [26, 27, 13, 14, "part-of", "task_part_of_field", false, false], [29, 30, 13, 14, "part-of", "task_part_of_field", false, false], [32, 34, 13, 14, "part-of", "task_part_of_field", false, false], [36, 37, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "general", "framework", "has", "been", "applied", "to", "a", "wide", "variety", "of", "problems", "in", "computer", "vision", ",", "including", "feature", "detection", ",", "feature", "classification", ",", "image", "segmentation", ",", "image", "matching", ",", "motion", "estimation", ",", "shape", "signal", "computation", "and", "object", "recognition", "."], "sentence-detokenized": "This general framework has been applied to a wide variety of problems in computer vision, including feature detection, feature classification, image segmentation, image matching, motion estimation, shape signal computation and object recognition.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 26], [27, 31], [32, 39], [40, 42], [43, 44], [45, 49], [50, 57], [58, 60], [61, 69], [70, 72], [73, 81], [82, 88], [88, 89], [90, 99], [100, 107], [108, 117], [117, 118], [119, 126], [127, 141], [141, 142], [143, 148], [149, 161], [161, 162], [163, 168], [169, 177], [177, 178], [179, 185], [186, 196], [196, 197], [198, 203], [204, 210], [211, 222], [223, 226], [227, 233], [234, 245], [245, 246]]}
{"doc_key": "ai-dev-89", "ner": [[5, 7, "task"], [8, 10, "algorithm"], [13, 14, "algorithm"], [26, 26, "algorithm"], [32, 33, "algorithm"], [36, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 7, 8, 10, "part-of", "", false, false], [5, 7, 13, 14, "usage", "", false, false], [8, 10, 26, 26, "named", "same", false, false], [26, 26, 32, 33, "related-to", "", false, false], [26, 26, 36, 37, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "many", "practical", "applications", ",", "parameter", "estimation", "of", "naive", "Bayes", "models", "uses", "the", "maximum", "likelihood", "method", ";", "in", "other", "words", ",", "one", "can", "work", "with", "the", "naive", "Bayes", "model", "without", "accepting", "a", "Bayesian", "likelihood", "or", "using", "Bayesian", "methods", "."], "sentence-detokenized": "In many practical applications, parameter estimation of naive Bayes models uses the maximum likelihood method; in other words, one can work with the naive Bayes model without accepting a Bayesian likelihood or using Bayesian methods.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 30], [30, 31], [32, 41], [42, 52], [53, 55], [56, 61], [62, 67], [68, 74], [75, 79], [80, 83], [84, 91], [92, 102], [103, 109], [109, 110], [111, 113], [114, 119], [120, 125], [125, 126], [127, 130], [131, 134], [135, 139], [140, 144], [145, 148], [149, 154], [155, 160], [161, 166], [167, 174], [175, 184], [185, 186], [187, 195], [196, 206], [207, 209], [210, 215], [216, 224], [225, 232], [232, 233]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [12, 15, "university"], [17, 19, "researcher"], [21, 22, "misc"], [26, 26, "university"], [28, 28, "university"], [31, 31, "misc"], [38, 40, "university"], [46, 49, "misc"], [51, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 4, 12, 15, "physical", "", false, false], [2, 4, 12, 15, "role", "", false, false], [2, 4, 17, 19, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [17, 19, 26, 26, "physical", "", false, false], [17, 19, 26, 26, "role", "", false, false], [17, 19, 28, 28, "physical", "", false, false], [17, 19, 28, 28, "role", "", false, false], [17, 19, 38, 40, "physical", "", false, false], [17, 19, 38, 40, "role", "", false, false], [21, 22, 17, 19, "named", "", false, false], [31, 31, 17, 19, "origin", "", false, false], [46, 49, 17, 19, "artifact", "", false, false], [46, 49, 51, 54, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Brothers", "-", "Victor", "Gershevich", "Katz", ",", "American", "mathematician", ",", "professor", "at", "the", "Massachusetts", "Institute", "of", "Technology", ";", "Mikhail", "Gershevich", "Katz", ",", "Israeli", "mathematician", ",", "graduate", "of", "Harvard", "and", "Columbia", "universities", "(", "Ph.D.", ",", "1984", ")", ",", "professor", "at", "Bar-", "Ilan", "University", ",", "author", "of", "the", "monograph", "Systolic", "Geometry", "and", "Topology", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", "."], "sentence-detokenized": "Brothers - Victor Gershevich Katz, American mathematician, professor at the Massachusetts Institute of Technology; Mikhail Gershevich Katz, Israeli mathematician, graduate of Harvard and Columbia universities (Ph.D. , 1984), professor at Bar-Ilan University, author of the monograph Systolic Geometry and Topology (Mathematical Surveys and Monographs, vol.", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 28], [29, 33], [33, 34], [35, 43], [44, 57], [57, 58], [59, 68], [69, 71], [72, 75], [76, 89], [90, 99], [100, 102], [103, 113], [113, 114], [115, 122], [123, 133], [134, 138], [138, 139], [140, 147], [148, 161], [161, 162], [163, 171], [172, 174], [175, 182], [183, 186], [187, 195], [196, 208], [209, 210], [210, 215], [216, 217], [218, 222], [222, 223], [223, 224], [225, 234], [235, 237], [238, 242], [242, 246], [247, 257], [257, 258], [259, 265], [266, 268], [269, 272], [273, 282], [283, 291], [292, 300], [301, 304], [305, 313], [314, 315], [315, 327], [328, 335], [336, 339], [340, 350], [350, 351], [352, 355], [355, 356]]}
{"doc_key": "ai-dev-91", "ner": [[3, 4, "person"], [10, 11, "conference"], [17, 22, "organisation"], [24, 30, "location"], [34, 34, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 10, 11, "physical", "", false, false], [3, 4, 10, 11, "role", "", false, false], [3, 4, 17, 22, "role", "", false, false], [17, 22, 24, 30, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2000", ",", "Manuel", "Toharia", ",", "a", "speaker", "at", "previous", "Campus", "Parties", ",", "and", "director", "of", "the", "Pr\u00edncipe", "Felipe", "'s", "Museum", "of", "Sciences", "in", "Valencia", "'s", "City", "of", "Arts", "and", "Sciences", ",", "suggested", "that", "Ragageles", "expand", "the", "event", "and", "make", "it", "more", "international", "by", "moving", "it", "to", "the", "famous", "museum", "."], "sentence-detokenized": "In 2000, Manuel Toharia, a speaker at previous Campus Parties, and director of the Pr\u00edncipe Felipe's Museum of Sciences in Valencia's City of Arts and Sciences, suggested that Ragageles expand the event and make it more international by moving it to the famous museum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 23], [23, 24], [25, 26], [27, 34], [35, 37], [38, 46], [47, 53], [54, 61], [61, 62], [63, 66], [67, 75], [76, 78], [79, 82], [83, 91], [92, 98], [98, 100], [101, 107], [108, 110], [111, 119], [120, 122], [123, 131], [131, 133], [134, 138], [139, 141], [142, 146], [147, 150], [151, 159], [159, 160], [161, 170], [171, 175], [176, 185], [186, 192], [193, 196], [197, 202], [203, 206], [207, 211], [212, 214], [215, 219], [220, 233], [234, 236], [237, 243], [244, 246], [247, 249], [250, 253], [254, 260], [261, 267], [267, 268]]}
{"doc_key": "ai-dev-92", "ner": [[5, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Within", "20", "minutes", ",", "a", "facial", "recognition", "system", "identifies", "personal", "information", ",", "including", "surname", ",", "ID", "number", "and", "address", ",", "displayed", "on", "an", "advertising", "screen", "on", "the", "street", "."], "sentence-detokenized": "Within 20 minutes, a facial recognition system identifies personal information, including surname, ID number and address, displayed on an advertising screen on the street.", "token2charspan": [[0, 6], [7, 9], [10, 17], [17, 18], [19, 20], [21, 27], [28, 39], [40, 46], [47, 57], [58, 66], [67, 78], [78, 79], [80, 89], [90, 97], [97, 98], [99, 101], [102, 108], [109, 112], [113, 120], [120, 121], [122, 131], [132, 134], [135, 137], [138, 149], [150, 156], [157, 159], [160, 163], [164, 170], [170, 171]]}
{"doc_key": "ai-dev-93", "ner": [[6, 7, "field"], [9, 9, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "research", "has", "increasingly", "focused", "on", "unsupervised", "learning", "and", "semi-supervised", "learning", "algorithms", "."], "sentence-detokenized": "Recent research has increasingly focused on unsupervised learning and semi-supervised learning algorithms.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 32], [33, 40], [41, 43], [44, 56], [57, 65], [66, 69], [70, 85], [86, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-94", "ner": [[5, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Calculation", "of", "this", "example", "with", "Python", "code", ":"], "sentence-detokenized": "Calculation of this example with Python code:", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 27], [28, 32], [33, 39], [40, 44], [44, 45]]}
{"doc_key": "ai-dev-95", "ner": [[7, 8, "task"], [14, 16, "field"], [19, 23, "algorithm"], [25, 25, "algorithm"], [29, 31, "algorithm"], [35, 36, "researcher"], [38, 39, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[19, 23, 14, 16, "part-of", "", false, false], [19, 23, 29, 31, "type-of", "", false, false], [19, 23, 35, 36, "origin", "", false, false], [19, 23, 38, 39, "origin", "", false, false], [25, 25, 19, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Today", ",", "however", ",", "many", "aspects", "of", "speech", "recognition", "have", "been", "adopted", "by", "a", "deep", "-", "learning", "method", "called", "Long", "short", "-", "term", "memory", "(", "LSTM", ")", ",", "a", "recurrent", "neural", "network", ",", "published", "by", "Sepp", "Hochreiter", "&", "J\u00fcrgen", "Schmidhuber", "in", "1997", "."], "sentence-detokenized": "Today, however, many aspects of speech recognition have been adopted by a deep-learning method called Long short-term memory (LSTM), a recurrent neural network, published by Sepp Hochreiter & J\u00fcrgen Schmidhuber in 1997.", "token2charspan": [[0, 5], [5, 6], [7, 14], [14, 15], [16, 20], [21, 28], [29, 31], [32, 38], [39, 50], [51, 55], [56, 60], [61, 68], [69, 71], [72, 73], [74, 78], [78, 79], [79, 87], [88, 94], [95, 101], [102, 106], [107, 112], [112, 113], [113, 117], [118, 124], [125, 126], [126, 130], [130, 131], [131, 132], [133, 134], [135, 144], [145, 151], [152, 159], [159, 160], [161, 170], [171, 173], [174, 178], [179, 189], [190, 191], [192, 198], [199, 210], [211, 213], [214, 218], [218, 219]]}
{"doc_key": "ai-dev-96", "ner": [[11, 13, "algorithm"], [17, 17, "algorithm"], [21, 21, "algorithm"], [26, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 13, 17, 17, "compare", "", false, false], [11, 13, 26, 26, "named", "same", false, false], [21, 21, 26, 26, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "preliminary", "experimental", "results", "with", "data", "sets", "with", "high", "noise", ",", "BrownBoost", "outperformed", "the", "generalisation", "error", "of", "AdaBoost", ";", "however", ",", "LogitBoost", "performed", "as", "well", "as", "BrownBoost", "."], "sentence-detokenized": "In preliminary experimental results with data sets with high noise, BrownBoost outperformed the generalisation error of AdaBoost; however, LogitBoost performed as well as BrownBoost.", "token2charspan": [[0, 2], [3, 14], [15, 27], [28, 35], [36, 40], [41, 45], [46, 50], [51, 55], [56, 60], [61, 66], [66, 67], [68, 78], [79, 91], [92, 95], [96, 110], [111, 116], [117, 119], [120, 128], [128, 129], [130, 137], [137, 138], [139, 149], [150, 159], [160, 162], [163, 167], [168, 170], [171, 181], [181, 182]]}
{"doc_key": "ai-dev-97", "ner": [[0, 1, "algorithm"], [5, 7, "researcher"], [10, 10, "country"], [13, 15, "researcher"], [16, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 7, "part-of", "", false, false], [5, 7, 10, 10, "physical", "", false, false], [16, 21, 13, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evolutionary", "programming", "was", "introduced", "by", "Lawrence", "J.", "Fogel", "in", "the", "US", ",", "while", "John", "Henry", "Holland", "called", "his", "method", "a", "genetic", "algorithm", "."], "sentence-detokenized": "Evolutionary programming was introduced by Lawrence J. Fogel in the US, while John Henry Holland called his method a genetic algorithm.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 54], [55, 60], [61, 63], [64, 67], [68, 70], [70, 71], [72, 77], [78, 82], [83, 88], [89, 96], [97, 103], [104, 107], [108, 114], [115, 116], [117, 124], [125, 134], [134, 135]]}
{"doc_key": "ai-dev-98", "ner": [[2, 2, "researcher"], [4, 4, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 10, 11, "role", "", false, false], [2, 2, 13, 14, "role", "", false, false], [2, 2, 16, 17, "role", "", false, false], [2, 2, 19, 20, "role", "", false, false], [4, 4, 10, 11, "role", "", false, false], [4, 4, 13, 14, "role", "", false, false], [4, 4, 16, 17, "role", "", false, false], [4, 4, 19, 20, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Calculations", "by", "Doug", ",", "Alan", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", "and", "John", "McCarthy", ")", "indicated", "that", "that", "effort", "would", "require", "between", "1,000", "and", "3,000", "person", "-", "years", ",", "far", "more", "than", "the", "standard", "academic", "project", "model", "."], "sentence-detokenized": "Calculations by Doug, Alan and their colleagues (including Marvin Minsky, Allen Newell, Edward Feigenbaum and John McCarthy) indicated that that effort would require between 1,000 and 3,000 person-years, far more than the standard academic project model.", "token2charspan": [[0, 12], [13, 15], [16, 20], [20, 21], [22, 26], [27, 30], [31, 36], [37, 47], [48, 49], [49, 58], [59, 65], [66, 72], [72, 73], [74, 79], [80, 86], [86, 87], [88, 94], [95, 105], [106, 109], [110, 114], [115, 123], [123, 124], [125, 134], [135, 139], [140, 144], [145, 151], [152, 157], [158, 165], [166, 173], [174, 179], [180, 183], [184, 189], [190, 196], [196, 197], [197, 202], [202, 203], [204, 207], [208, 212], [213, 217], [218, 221], [222, 230], [231, 239], [240, 247], [248, 253], [253, 254]]}
{"doc_key": "ai-dev-99", "ner": [[4, 6, "metrics"], [10, 10, "metrics"], [13, 16, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 10, 10, "part-of", "implemented_in", false, false], [13, 16, 18, 18, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Common", "criteria", "are", "the", "Mean", "Squared", "Error", "criterion", "implemented", "in", "MSECriterion", "and", "the", "Cross", "-entropy", "criterion", "implemented", "in", "NLLCriterion", "."], "sentence-detokenized": "Common criteria are the Mean Squared Error criterion implemented in MSECriterion and the Cross-entropy criterion implemented in NLLCriterion.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 23], [24, 28], [29, 36], [37, 42], [43, 52], [53, 64], [65, 67], [68, 80], [81, 84], [85, 88], [89, 94], [94, 102], [103, 112], [113, 124], [125, 127], [128, 140], [140, 141]]}
{"doc_key": "ai-dev-100", "ner": [[0, 0, "researcher"], [11, 11, "organisation"], [15, 22, "misc"], [31, 34, "conference"], [40, 40, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 11, 11, "role", "", false, false], [0, 0, 31, 34, "role", "", false, false], [0, 0, 40, 40, "role", "", false, false], [15, 22, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zurada", "has", "served", "the", "engineering", "profession", "as", "a", "long", "-", "time", "IEEE", "volunteer", ":", "as", "2014", "IEEE", "Vice", "-", "President", "-", "Technical", "Activities", "(", "TAB", "Chair", ")", ",", "as", "President", "of", "IEEE", "Computational", "Intelligence", "Society", "in", "2004", "-", "05", "and", "ADCOM", "member", "in", "2009", "-", "14", ",", "2016", "-", "18", "and", "earlier", "years", "."], "sentence-detokenized": "Zurada has served the engineering profession as a long-time IEEE volunteer: as 2014 IEEE Vice-President-Technical Activities (TAB Chair), as President of IEEE Computational Intelligence Society in 2004-05 and ADCOM member in 2009-14, 2016-18 and earlier years.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 21], [22, 33], [34, 44], [45, 47], [48, 49], [50, 54], [54, 55], [55, 59], [60, 64], [65, 74], [74, 75], [76, 78], [79, 83], [84, 88], [89, 93], [93, 94], [94, 103], [103, 104], [104, 113], [114, 124], [125, 126], [126, 129], [130, 135], [135, 136], [136, 137], [138, 140], [141, 150], [151, 153], [154, 158], [159, 172], [173, 185], [186, 193], [194, 196], [197, 201], [201, 202], [202, 204], [205, 208], [209, 214], [215, 221], [222, 224], [225, 229], [229, 230], [230, 232], [232, 233], [234, 238], [238, 239], [239, 241], [242, 245], [246, 253], [254, 259], [259, 260]]}
{"doc_key": "ai-dev-101", "ner": [[3, 5, "field"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 5, "part-of", "", false, false], [11, 12, 3, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "general", ",", "computational", "linguistics", "involves", "linguists", ",", "computer", "scientists", ",", "artificial", "intelligence", "experts", ",", "mathematicians", ",", "logicians", ",", "philosophers", ",", "cognitive", "scientists", ",", "cognitive", "psychologists", ",", "psycholinguists", ",", "anthropologists", "and", "neuroscientists", ",", "to", "name", "a", "few", "."], "sentence-detokenized": "In general, computational linguistics involves linguists, computer scientists, artificial intelligence experts, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists and neuroscientists, to name a few.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 25], [26, 37], [38, 46], [47, 56], [56, 57], [58, 66], [67, 77], [77, 78], [79, 89], [90, 102], [103, 110], [110, 111], [112, 126], [126, 127], [128, 137], [137, 138], [139, 151], [151, 152], [153, 162], [163, 173], [173, 174], [175, 184], [185, 198], [198, 199], [200, 215], [215, 216], [217, 232], [233, 236], [237, 252], [252, 253], [254, 256], [257, 261], [262, 263], [264, 267], [267, 268]]}
{"doc_key": "ai-dev-102", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "Convolutional", "neural", "networks", "and", "Long", "-", "term", "memories", "are", "often", "used", "to", "exploit", "interframe", "correlations", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, Convolutional neural networks and Long-term memories are often used to exploit interframe correlations.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [82, 83], [83, 87], [88, 96], [97, 100], [101, 106], [107, 111], [112, 114], [115, 122], [123, 133], [134, 146], [146, 147]]}
{"doc_key": "ai-dev-103", "ner": [[0, 0, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "was", "the", "first", "industrial", "robot", ","], "sentence-detokenized": "Unimate was the first industrial robot,", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 21], [22, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-dev-104", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 11, 13, "win-defeat", "", false, false], [5, 6, 11, 13, "win-defeat", "", false, false], [8, 8, 11, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Together", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "won", "the", "2018", "Turing", "Award", "."], "sentence-detokenized": "Together with Geoffrey Hinton and Yann LeCun, Bengio won the 2018 Turing Award.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 29], [30, 33], [34, 38], [39, 44], [44, 45], [46, 52], [53, 56], [57, 60], [61, 65], [66, 72], [73, 78], [78, 79]]}
{"doc_key": "ai-dev-105", "ner": [[6, 6, "country"], [20, 23, "misc"], [25, 25, "country"], [29, 30, "organisation"], [34, 35, "person"], [37, 38, "person"], [47, 49, "misc"], [53, 54, "country"], [60, 60, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[20, 23, 6, 6, "physical", "filmed_in", false, false], [34, 35, 29, 30, "role", "host", false, false], [37, 38, 29, 30, "role", "reporter", false, false], [47, 49, 6, 6, "physical", "filmed_in", false, false], [47, 49, 53, 54, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Additional", "series", "were", "filmed", "at", "the", "UK", "location", "for", "specific", "sectors", "of", "the", "global", "market", ",", "including", "two", "series", "of", "Robot", "Wars", "Extreme", "Warriors", "featuring", "US", "competitors", "for", "the", "TNN", "network", "(", "presented", "by", "Mick", "Foley", "with", "Rebecca", "Grant", "as", "pit", "reporter", ")", ",", "two", "of", "the", "Dutch", "Robot", "Wars", "for", "distribution", "in", "the", "Netherlands", "and", "a", "single", "series", "for", "Germany", "."], "sentence-detokenized": "Additional series were filmed at the UK location for specific sectors of the global market, including two series of Robot Wars Extreme Warriors featuring US competitors for the TNN network (presented by Mick Foley with Rebecca Grant as pit reporter), two of the Dutch Robot Wars for distribution in the Netherlands and a single series for Germany.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 29], [30, 32], [33, 36], [37, 39], [40, 48], [49, 52], [53, 61], [62, 69], [70, 72], [73, 76], [77, 83], [84, 90], [90, 91], [92, 101], [102, 105], [106, 112], [113, 115], [116, 121], [122, 126], [127, 134], [135, 143], [144, 153], [154, 156], [157, 168], [169, 172], [173, 176], [177, 180], [181, 188], [189, 190], [190, 199], [200, 202], [203, 207], [208, 213], [214, 218], [219, 226], [227, 232], [233, 235], [236, 239], [240, 248], [248, 249], [249, 250], [251, 254], [255, 257], [258, 261], [262, 267], [268, 273], [274, 278], [279, 282], [283, 295], [296, 298], [299, 302], [303, 314], [315, 318], [319, 320], [321, 327], [328, 334], [335, 338], [339, 346], [346, 347]]}
{"doc_key": "ai-dev-106", "ner": [[4, 28, "researcher"], [9, 9, "product"], [23, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 28, 9, 9, "role", "", false, false], [23, 24, 9, 9, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Starting", "in", "1986", ",", "Miller", "led", "the", "development", "of", "WordNet", ",", "a", "large", "computer", "-", "readable", "electronic", "reference", "usable", "in", "applications", "such", "as", "search", "engines", ",", "for", "many", "years", "."], "sentence-detokenized": "Starting in 1986, Miller led the development of WordNet, a large computer-readable electronic reference usable in applications such as search engines, for many years.", "token2charspan": [[0, 8], [9, 11], [12, 16], [16, 17], [18, 24], [25, 28], [29, 32], [33, 44], [45, 47], [48, 55], [55, 56], [57, 58], [59, 64], [65, 73], [73, 74], [74, 82], [83, 93], [94, 103], [104, 110], [111, 113], [114, 126], [127, 131], [132, 134], [135, 141], [142, 149], [149, 150], [151, 154], [155, 159], [160, 165], [165, 166]]}
{"doc_key": "ai-dev-107", "ner": [[3, 4, "algorithm"], [7, 10, "algorithm"], [13, 14, "researcher"], [20, 23, "organisation"], [25, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 13, 14, "origin", "", false, false], [3, 4, 25, 29, "win-defeat", "", false, false], [7, 10, 13, 14, "origin", "", false, false], [7, 10, 25, 29, "win-defeat", "", false, false], [13, 14, 20, 23, "physical", "", false, false], [13, 14, 20, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Since", "2009", ",", "recurrent", "neural", "networks", "and", "deep", "feedforward", "neural", "networks", "developed", "in", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "Swiss", "AI", "Lab", "IDSIA", "have", "won", "several", "international", "handwriting", "competitions", "..."], "sentence-detokenized": "Since 2009, recurrent neural networks and deep feedforward neural networks developed in J\u00fcrgen Schmidhuber's research group at the Swiss AI Lab IDSIA have won several international handwriting competitions ...", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 21], [22, 28], [29, 37], [38, 41], [42, 46], [47, 58], [59, 65], [66, 74], [75, 84], [85, 87], [88, 94], [95, 106], [106, 108], [109, 117], [118, 123], [124, 126], [127, 130], [131, 136], [137, 139], [140, 143], [144, 149], [150, 154], [155, 158], [159, 166], [167, 180], [181, 192], [193, 205], [206, 209]]}
{"doc_key": "ai-dev-108", "ner": [[5, 6, "programlang"], [12, 12, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "is", "implemented", "in", "C", "++", "and", "it", "is", "packaged", "for", "Python", "."], "sentence-detokenized": "The software is implemented in C++ and it is packaged for Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 30], [31, 32], [32, 34], [35, 38], [39, 41], [42, 44], [45, 53], [54, 57], [58, 64], [64, 65]]}
{"doc_key": "ai-dev-109", "ner": [[8, 9, "country"], [14, 15, "misc"], [20, 21, "misc"], [34, 34, "misc"], [37, 37, "misc"], [40, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 8, 9, "temporal", "", false, false], [20, 21, 14, 15, "artifact", "", false, false], [20, 21, 40, 40, "physical", "", false, false], [37, 37, 34, 34, "named", "", false, false], [37, 37, 40, 40, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1857", ",", "at", "the", "request", "of", "the", "Tokugawa", "Shogunate", ",", "a", "group", "of", "Dutch", "engineers", "began", "construction", "of", "the", "Nagasaki", "Yotetsusho", ",", "a", "modern", ",", "Western", "-", "looking", "foundry", "and", "shipyard", "near", "the", "Dutch", "settlement", "of", "Dejima", ",", "in", "Nagasaki", "."], "sentence-detokenized": "In 1857, at the request of the Tokugawa Shogunate, a group of Dutch engineers began construction of the Nagasaki Yotetsusho, a modern, Western-looking foundry and shipyard near the Dutch settlement of Dejima, in Nagasaki.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 39], [40, 49], [49, 50], [51, 52], [53, 58], [59, 61], [62, 67], [68, 77], [78, 83], [84, 96], [97, 99], [100, 103], [104, 112], [113, 123], [123, 124], [125, 126], [127, 133], [133, 134], [135, 142], [142, 143], [143, 150], [151, 158], [159, 162], [163, 171], [172, 176], [177, 180], [181, 186], [187, 197], [198, 200], [201, 207], [207, 208], [209, 211], [212, 220], [220, 221]]}
{"doc_key": "ai-dev-110", "ner": [[10, 12, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["We", "make", "it", "as", "accurate", "as", "possible", "by", "measuring", "the", "mean", "squared", "error", "between", "mathy", "/", "math", "and", "math", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "we", "want", "math", "(", "y", "-", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", "^", "2", "/", "math", "to", "be", "minimal", ",", "both", "for", "mathx", "_", "1", ",^", "points", ",", "x", "_n", "/", "math", "and", "for", "points", "outside", "our", "sample", "."], "sentence-detokenized": "We make it as accurate as possible by measuring the mean squared error between mathy / math and math {f} (x; D) / math: we want math (y -hat {f} (x; D)) ^ 2 / math to be minimal, both for mathx _ 1,^ points, x _n / math and for points outside our sample.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 13], [14, 22], [23, 25], [26, 34], [35, 37], [38, 47], [48, 51], [52, 56], [57, 64], [65, 70], [71, 78], [79, 84], [85, 86], [87, 91], [92, 95], [96, 100], [101, 102], [102, 103], [103, 104], [105, 106], [106, 107], [107, 108], [109, 110], [110, 111], [112, 113], [114, 118], [118, 119], [120, 122], [123, 127], [128, 132], [133, 134], [134, 135], [136, 137], [137, 140], [141, 142], [142, 143], [143, 144], [145, 146], [146, 147], [147, 148], [149, 150], [150, 151], [151, 152], [153, 154], [155, 156], [157, 158], [159, 163], [164, 166], [167, 169], [170, 177], [177, 178], [179, 183], [184, 187], [188, 193], [194, 195], [196, 197], [197, 199], [200, 206], [206, 207], [208, 209], [210, 212], [213, 214], [215, 219], [220, 223], [224, 227], [228, 234], [235, 242], [243, 246], [247, 253], [253, 254]]}
{"doc_key": "ai-dev-111", "ner": [[3, 3, "researcher"], [13, 15, "organisation"], [23, 26, "product"], [27, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 13, 15, "role", "", false, false], [23, 26, 13, 15, "temporal", "", false, false], [23, 26, 27, 37, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "then", "sent", "Wydner", "an", "invitation", "to", "attend", "the", "annual", "meeting", "of", "the", "American", "Translators", "Association", "that", "followed", "in", "October", ",", "where", "the", "Weidner", "Machine", "Translation", "System", "was", "hailed", "as", "a", "hoped", "-", "for", "breakthrough", "in", "machine", "translation", "."], "sentence-detokenized": "He then sent Wydner an invitation to attend the annual meeting of the American Translators Association that followed in October, where the Weidner Machine Translation System was hailed as a hoped-for breakthrough in machine translation.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 19], [20, 22], [23, 33], [34, 36], [37, 43], [44, 47], [48, 54], [55, 62], [63, 65], [66, 69], [70, 78], [79, 90], [91, 102], [103, 107], [108, 116], [117, 119], [120, 127], [127, 128], [129, 134], [135, 138], [139, 146], [147, 154], [155, 166], [167, 173], [174, 177], [178, 184], [185, 187], [188, 189], [190, 195], [195, 196], [196, 199], [200, 212], [213, 215], [216, 223], [224, 235], [235, 236]]}
{"doc_key": "ai-dev-112", "ner": [[2, 8, "conference"], [10, 10, "conference"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 2, 8, "named", "", false, false], [10, 10, 2, 8, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["At", "the", "2018", "Conference", "on", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", ",", "researchers", "from", "Google", "presented", "the", "work", "."], "sentence-detokenized": "At the 2018 Conference on Neural Information Processing Systems (NeurIPS), researchers from Google presented the work.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 22], [23, 25], [26, 32], [33, 44], [45, 55], [56, 63], [64, 65], [65, 72], [72, 73], [73, 74], [75, 86], [87, 91], [92, 98], [99, 108], [109, 112], [113, 117], [117, 118]]}
{"doc_key": "ai-dev-113", "ner": [[1, 4, "algorithm"], [10, 12, "algorithm"], [15, 17, "metrics"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 4, 10, 12, "usage", "", false, false], [10, 12, 15, 17, "related-to", "", true, false], [15, 17, 23, 25, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Baum", "-", "Welch", "algorithm", "uses", "the", "well", "-", "known", "EM", "algorithm", "to", "find", "the", "maximum", "likelihood", "estimate", "of", "the", "parameters", "of", "a", "hidden", "Markov", "model", ",", "given", "a", "set", "of", "observed", "feature", "vectors", "."], "sentence-detokenized": "The Baum-Welch algorithm uses the well-known EM algorithm to find the maximum likelihood estimate of the parameters of a hidden Markov model, given a set of observed feature vectors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [15, 24], [25, 29], [30, 33], [34, 38], [38, 39], [39, 44], [45, 47], [48, 57], [58, 60], [61, 65], [66, 69], [70, 77], [78, 88], [89, 97], [98, 100], [101, 104], [105, 115], [116, 118], [119, 120], [121, 127], [128, 134], [135, 140], [140, 141], [142, 147], [148, 149], [150, 153], [154, 156], [157, 165], [166, 173], [174, 181], [181, 182]]}
{"doc_key": "ai-dev-114", "ner": [[8, 8, "product"], [10, 10, "product"], [31, 32, "misc"], [38, 45, "product"], [51, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[8, 8, 10, 10, "compare", "", false, false], [31, 32, 10, 10, "part-of", "", false, false], [38, 45, 10, 10, "part-of", "", false, false], [51, 56, 10, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": [")", "In", "addition", "to", "the", "taxonomic", "information", "in", "OpenCyc", ",", "ResearchCyc", "contains", "considerably", "more", "semantic", "knowledge", "(", "i.e.", "additional", "facts", "and", "rules", "of", "thumb", ")", "related", "to", "the", "concepts", "in", "its", "knowledge", "base", ";", "it", "also", "contains", "a", "large", "lexicon", ",", "English", "parsing", "and", "generation", "tools", ",", "and", "Java", "-", "based", "interfaces", "for", "knowledge", "editing", "and", "queries", "."], "sentence-detokenized": ") In addition to the taxonomic information in OpenCyc, ResearchCyc contains considerably more semantic knowledge (i.e. additional facts and rules of thumb) related to the concepts in its knowledge base; it also contains a large lexicon, English parsing and generation tools, and Java-based interfaces for knowledge editing and queries.", "token2charspan": [[0, 1], [2, 4], [5, 13], [14, 16], [17, 20], [21, 30], [31, 42], [43, 45], [46, 53], [53, 54], [55, 66], [67, 75], [76, 88], [89, 93], [94, 102], [103, 112], [113, 114], [114, 118], [119, 129], [130, 135], [136, 139], [140, 145], [146, 148], [149, 154], [154, 155], [156, 163], [164, 166], [167, 170], [171, 179], [180, 182], [183, 186], [187, 196], [197, 201], [201, 202], [203, 205], [206, 210], [211, 219], [220, 221], [222, 227], [228, 235], [235, 236], [237, 244], [245, 252], [253, 256], [257, 267], [268, 273], [273, 274], [275, 278], [279, 283], [283, 284], [284, 289], [290, 300], [301, 304], [305, 314], [315, 322], [323, 326], [327, 334], [334, 335]]}
{"doc_key": "ai-dev-115", "ner": [[1, 2, "algorithm"], [10, 11, "field"], [13, 14, "field"], [16, 18, "field"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Hough", "transform", "is", "a", "feature", "extraction", "technique", "used", "in", "image", "analysis", ",", "computer", "vision", "and", "digital", "image", "processing", "."], "sentence-detokenized": "The Hough transform is a feature extraction technique used in image analysis, computer vision and digital image processing.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 22], [23, 24], [25, 32], [33, 43], [44, 53], [54, 58], [59, 61], [62, 67], [68, 76], [76, 77], [78, 86], [87, 93], [94, 97], [98, 105], [106, 111], [112, 122], [122, 123]]}
{"doc_key": "ai-dev-116", "ner": [[7, 11, "product"], [16, 16, "organisation"], [19, 19, "product"], [21, 22, "researcher"], [28, 29, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[19, 19, 21, 22, "artifact", "", false, false], [28, 29, 16, 16, "role", "supported", false, false]], "relations_mapping_to_source": [3, 4], "sentence": ["In", "1978", ",", "the", "PUMA", "robot", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "was", "developed", "by", "Unimation", "based", "on", "Vicarm", "(", "Victor", "Scheinman", ")", "and", "with", "support", "from", "General", "Motors", "."], "sentence-detokenized": "In 1978, the PUMA robot (Programmable Universal Machine for Assembly) was developed by Unimation based on Vicarm (Victor Scheinman) and with support from General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 23], [24, 25], [25, 37], [38, 47], [48, 55], [56, 59], [60, 68], [68, 69], [70, 73], [74, 83], [84, 86], [87, 96], [97, 102], [103, 105], [106, 112], [113, 114], [114, 120], [121, 130], [130, 131], [132, 135], [136, 140], [141, 148], [149, 153], [154, 161], [162, 168], [168, 169]]}
{"doc_key": "ai-dev-117", "ner": [[0, 0, "algorithm"], [6, 7, "researcher"], [9, 10, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 7, "origin", "", false, false], [0, 0, 9, 10, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["LSTM", "was", "proposed", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "LSTM was proposed in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 25], [26, 28], [29, 33], [34, 44], [45, 48], [49, 55], [56, 67], [67, 68]]}
{"doc_key": "ai-dev-118", "ner": [[11, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "outcomes", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four outcomes can be formulated in a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 24], [25, 35], [36, 38], [39, 40], [41, 42], [43, 44], [45, 46], [47, 58], [59, 64], [65, 67], [68, 77], [78, 84], [85, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-dev-119", "ner": [[7, 7, "conference"], [10, 11, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "also", "contributed", "a", "lot", "by", "founding", "ELRA", "and", "the", "LREC", "conference", "."], "sentence-detokenized": "He also contributed a lot by founding ELRA and the LREC conference.", "token2charspan": [[0, 2], [3, 7], [8, 19], [20, 21], [22, 25], [26, 28], [29, 37], [38, 42], [43, 46], [47, 50], [51, 55], [56, 66], [66, 67]]}
{"doc_key": "ai-dev-120", "ner": [[17, 18, "misc"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[22, 23, 17, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "popular", "application", "for", "serial", "robots", "in", "today", "'s", "industry", "is", "the", "pick", "-", "and", "-", "place", "assembly", "robot", ",", "called", "a", "SCARA", "robot", ",", "which", "has", "four", "degrees", "of", "freedom", "."], "sentence-detokenized": "A popular application for serial robots in today's industry is the pick-and-place assembly robot, called a SCARA robot, which has four degrees of freedom.", "token2charspan": [[0, 1], [2, 9], [10, 21], [22, 25], [26, 32], [33, 39], [40, 42], [43, 48], [48, 50], [51, 59], [60, 62], [63, 66], [67, 71], [71, 72], [72, 75], [75, 76], [76, 81], [82, 90], [91, 96], [96, 97], [98, 104], [105, 106], [107, 112], [113, 118], [118, 119], [120, 125], [126, 129], [130, 134], [135, 142], [143, 145], [146, 153], [153, 154]]}
{"doc_key": "ai-dev-121", "ner": [[13, 19, "conference"], [21, 21, "conference"], [25, 28, "conference"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 13, 19, "named", "", false, false], [37, 37, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "a", "founding", "member", "and", "former", "chairman", "(", "2006-2008", ")", "of", "the", "Special", "Interest", "Group", "on", "Web", "as", "Corpus", "(", "SIGWAC", ")", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "also", "one", "of", "the", "founding", "organisers", "of", "SENSEVAL", "."], "sentence-detokenized": "He was a founding member and former chairman (2006-2008) of the Special Interest Group on Web as Corpus (SIGWAC) of the Association for Computational Linguistics and also one of the founding organisers of SENSEVAL.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 17], [18, 24], [25, 28], [29, 35], [36, 44], [45, 46], [46, 55], [55, 56], [57, 59], [60, 63], [64, 71], [72, 80], [81, 86], [87, 89], [90, 93], [94, 96], [97, 103], [104, 105], [105, 111], [111, 112], [113, 115], [116, 119], [120, 131], [132, 135], [136, 149], [150, 161], [162, 165], [166, 170], [171, 174], [175, 177], [178, 181], [182, 190], [191, 201], [202, 204], [205, 213], [213, 214]]}
{"doc_key": "ai-dev-122", "ner": [[4, 4, "product"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 4, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "platform", ",", "LinguaStream", "offers", "a", "comprehensive", "Java", "API", "."], "sentence-detokenized": "As a platform, LinguaStream offers a comprehensive Java API.", "token2charspan": [[0, 2], [3, 4], [5, 13], [13, 14], [15, 27], [28, 34], [35, 36], [37, 50], [51, 55], [56, 59], [59, 60]]}
{"doc_key": "ai-dev-123", "ner": [[11, 11, "programlang"], [14, 16, "misc"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 19, 21, "type-of", "", false, false], [14, 16, 19, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "robot", "kit", "is", "Android", "-", "based", "and", "is", "programmed", "using", "Java", ",", "the", "Blocks", "programming", "interface", "or", "other", "Android", "programming", "systems", "."], "sentence-detokenized": "The robot kit is Android-based and is programmed using Java, the Blocks programming interface or other Android programming systems.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 16], [17, 24], [24, 25], [25, 30], [31, 34], [35, 37], [38, 48], [49, 54], [55, 59], [59, 60], [61, 64], [65, 71], [72, 83], [84, 93], [94, 96], [97, 102], [103, 110], [111, 122], [123, 130], [130, 131]]}
{"doc_key": "ai-dev-124", "ner": [[12, 15, "algorithm"], [18, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "method", "for", "defining", "the", "linked", "list", "specifies", "the", "use", "of", "a", "depth", "-", "first", "search", "or", "a", "breadth", "-", "first", "search", "."], "sentence-detokenized": "The method for defining the linked list specifies the use of a depth-first search or a breadth-first search.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 27], [28, 34], [35, 39], [40, 49], [50, 53], [54, 57], [58, 60], [61, 62], [63, 68], [68, 69], [69, 74], [75, 81], [82, 84], [85, 86], [87, 94], [94, 95], [95, 100], [101, 107], [107, 108]]}
{"doc_key": "ai-dev-125", "ner": [[20, 21, "task"], [25, 27, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "areas", "could", "indicate", "the", "presence", "of", "objects", "or", "parts", "of", "objects", "in", "the", "image", "domain", ",", "with", "application", "to", "object", "recognition", "and", "/", "or", "object", "video", "tracking", "."], "sentence-detokenized": "These areas could indicate the presence of objects or parts of objects in the image domain, with application to object recognition and/or object video tracking.", "token2charspan": [[0, 5], [6, 11], [12, 17], [18, 26], [27, 30], [31, 39], [40, 42], [43, 50], [51, 53], [54, 59], [60, 62], [63, 70], [71, 73], [74, 77], [78, 83], [84, 90], [90, 91], [92, 96], [97, 108], [109, 111], [112, 118], [119, 130], [131, 134], [134, 135], [135, 137], [138, 144], [145, 150], [151, 159], [159, 160]]}
{"doc_key": "ai-dev-126", "ner": [[4, 5, "algorithm"], [7, 7, "product"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 4, 5, "type-of", "", false, false], [7, 7, 13, 13, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "semantic", "network", "is", "WordNet", ",", "a", "lexical", "database", "of", "English", "."], "sentence-detokenized": "An example of a semantic network is WordNet, a lexical database of English.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 32], [33, 35], [36, 43], [43, 44], [45, 46], [47, 54], [55, 63], [64, 66], [67, 74], [74, 75]]}
{"doc_key": "ai-dev-127", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 11, "field"], [20, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 7, 8, "part-of", "", false, false], [0, 1, 10, 11, "named", "same", false, false], [0, 1, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Speech", "recognition", "is", "an", "interdisciplinary", "subfield", "of", "computer", "science", "and", "computational", "linguistics", "that", "develops", "methodologies", "and", "technologies", "that", "enable", "the", "recognition", "and", "translation", "of", "spoken", "language", "into", "text", "by", "computers", "."], "sentence-detokenized": "Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that enable the recognition and translation of spoken language into text by computers.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 24], [25, 42], [43, 51], [52, 54], [55, 63], [64, 71], [72, 75], [76, 89], [90, 101], [102, 106], [107, 115], [116, 129], [130, 133], [134, 146], [147, 151], [152, 158], [159, 162], [163, 174], [175, 178], [179, 190], [191, 193], [194, 200], [201, 209], [210, 214], [215, 219], [220, 222], [223, 232], [232, 233]]}
{"doc_key": "ai-dev-128", "ner": [[0, 1, "field"], [10, 11, "misc"], [16, 18, "field"], [20, 21, "task"], [23, 24, "task"], [46, 46, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 46, 46, "named", "same", false, false], [16, 18, 0, 1, "part-of", "subfield", false, false], [20, 21, 0, 1, "part-of", "", false, false], [20, 21, 16, 18, "part-of", "", false, false], [23, 24, 16, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Artificial", "intelligence", "has", "received", "the", "most", "attention", "in", "terms", "of", "applied", "ontology", "in", "subfields", "such", "as", "natural", "language", "processing", "within", "machine", "learning", "and", "knowledge", "representation", ",", "but", "ontology", "editors", "are", "often", "used", "in", "a", "range", "of", "areas", "such", "as", "education", "without", "the", "intention", "of", "contributing", "to", "AI", "."], "sentence-detokenized": "Artificial intelligence has received the most attention in terms of applied ontology in subfields such as natural language processing within machine learning and knowledge representation, but ontology editors are often used in a range of areas such as education without the intention of contributing to AI.", "token2charspan": [[0, 10], [11, 23], [24, 27], [28, 36], [37, 40], [41, 45], [46, 55], [56, 58], [59, 64], [65, 67], [68, 75], [76, 84], [85, 87], [88, 97], [98, 102], [103, 105], [106, 113], [114, 122], [123, 133], [134, 140], [141, 148], [149, 157], [158, 161], [162, 171], [172, 186], [186, 187], [188, 191], [192, 200], [201, 208], [209, 212], [213, 218], [219, 223], [224, 226], [227, 228], [229, 234], [235, 237], [238, 243], [244, 248], [249, 251], [252, 261], [262, 269], [270, 273], [274, 283], [284, 286], [287, 299], [300, 302], [303, 305], [305, 306]]}
{"doc_key": "ai-dev-129", "ner": [[6, 6, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 6, 11, 12, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "update", "rule", "is", "basically", "the", "stochastic", "gradient", "descent", "update", "for", "linear", "regression", "."], "sentence-detokenized": "This update rule is basically the stochastic gradient descent update for linear regression.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 29], [30, 33], [34, 44], [45, 53], [54, 61], [62, 68], [69, 72], [73, 79], [80, 90], [90, 91]]}
{"doc_key": "ai-dev-130", "ner": [[5, 10, "organisation"], [13, 16, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "elected", "to", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "the", "National", "Academy", "of", "Sciences", "and", "received", "a", "series", "of", "awards", ":"], "sentence-detokenized": "He was elected to the American Academy of Arts and Sciences and the National Academy of Sciences and received a series of awards:", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 46], [47, 50], [51, 59], [60, 63], [64, 67], [68, 76], [77, 84], [85, 87], [88, 96], [97, 100], [101, 109], [110, 111], [112, 118], [119, 121], [122, 128], [128, 129]]}
{"doc_key": "ai-dev-131", "ner": [[7, 7, "organisation"], [14, 15, "person"], [17, 19, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 14, 15, "related-to", "written_about_by", false, false], [7, 7, 17, 19, "related-to", "written_about_by", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "recent", "line", "of", "thinking", "on", "Honda", "'s", "strategy", "was", "put", "forward", "by", "Gary", "Hamel", "and", "C.K", ".", "Prahalad", "in", "1989", "."], "sentence-detokenized": "The most recent line of thinking on Honda's strategy was put forward by Gary Hamel and C.K. Prahalad in 1989.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 20], [21, 23], [24, 32], [33, 35], [36, 41], [41, 43], [44, 52], [53, 56], [57, 60], [61, 68], [69, 71], [72, 76], [77, 82], [83, 86], [87, 90], [90, 91], [92, 100], [101, 103], [104, 108], [108, 109]]}
{"doc_key": "ai-dev-132", "ner": [[1, 1, "metrics"], [5, 6, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 5, 6, "related-to", "calculates", true, false], [1, 1, 18, 18, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Whereas", "BLEU", "simply", "calculates", "the", "precision", "of", "a", "gram", "and", "assigns", "an", "equal", "weight", "to", "each", "gram", ",", "NIST", "also", "calculates", "how", "informative", "a", "given", "gram", "is", "."], "sentence-detokenized": "Whereas BLEU simply calculates the precision of a gram and assigns an equal weight to each gram, NIST also calculates how informative a given gram is.", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 30], [31, 34], [35, 44], [45, 47], [48, 49], [50, 54], [55, 58], [59, 66], [67, 69], [70, 75], [76, 82], [83, 85], [86, 90], [91, 95], [95, 96], [97, 101], [102, 106], [107, 117], [118, 121], [122, 133], [134, 135], [136, 141], [142, 146], [147, 149], [149, 150]]}
{"doc_key": "ai-dev-133", "ner": [[5, 8, "misc"], [11, 14, "conference"], [16, 16, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 8, 11, 14, "temporal", "", false, false], [16, 16, 11, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "honoured", "with", "the", "2019", "Lifetime", "Achievement", "Award", "from", "the", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "He was honoured with the 2019 Lifetime Achievement Award from the Association for Computational Linguistics (ACL).", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 20], [21, 24], [25, 29], [30, 38], [39, 50], [51, 56], [57, 61], [62, 65], [66, 77], [78, 81], [82, 95], [96, 107], [108, 109], [109, 112], [112, 113], [113, 114]]}
{"doc_key": "ai-dev-134", "ner": [[0, 0, "researcher"], [5, 11, "organisation"], [13, 13, "organisation"], [21, 25, "conference"], [27, 27, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 11, "role", "", false, false], [0, 0, 21, 25, "role", "", false, false], [13, 13, 5, 11, "named", "", false, false], [27, 27, 21, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "is", "a", "Fellow", "of", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "and", "a", "Fellow", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara is a Fellow of the Institute of Electrical and Electronics Engineers (IEEE), and a Fellow of the American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 18], [19, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 65], [66, 75], [76, 77], [77, 81], [81, 82], [82, 83], [84, 87], [88, 89], [90, 96], [97, 99], [100, 103], [104, 112], [113, 124], [125, 128], [129, 139], [140, 152], [153, 154], [154, 158], [158, 159], [159, 160]]}
{"doc_key": "ai-dev-135", "ner": [[11, 12, "misc"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "MATLAB", "code", "demonstrates", "a", "concrete", "solution", "for", "solving", "the", "non-linear", "system", "of", "equations", "presented", "in", "the", "previous", "chapter", ":", "See", "also"], "sentence-detokenized": "The following MATLAB code demonstrates a concrete solution for solving the non-linear system of equations presented in the previous chapter: See also", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 38], [39, 40], [41, 49], [50, 58], [59, 62], [63, 70], [71, 74], [75, 85], [86, 92], [93, 95], [96, 105], [106, 115], [116, 118], [119, 122], [123, 131], [132, 139], [139, 140], [141, 144], [145, 149]]}
{"doc_key": "ai-dev-136", "ner": [[0, 2, "product"], [14, 15, "field"], [37, 38, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 14, 15, "related-to", "trained_by", true, false], [0, 2, 37, 38, "related-to", "trained_by", true, false], [14, 15, 37, 38, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Pattern", "recognition", "systems", "are", "in", "many", "cases", "trained", "based", "on", "labelled", "training", "data", "(", "supervised", "learning", ")", ",", "but", "if", "labelled", "data", "is", "not", "available", ",", "other", "algorithms", "can", "be", "used", "to", "discover", "previously", "unknown", "patterns", "(", "unsupervised", "learning", ")", "."], "sentence-detokenized": "Pattern recognition systems are in many cases trained based on labelled training data (supervised learning), but if labelled data is not available, other algorithms can be used to discover previously unknown patterns (unsupervised learning).", "token2charspan": [[0, 7], [8, 19], [20, 27], [28, 31], [32, 34], [35, 39], [40, 45], [46, 53], [54, 59], [60, 62], [63, 71], [72, 80], [81, 85], [86, 87], [87, 97], [98, 106], [106, 107], [107, 108], [109, 112], [113, 115], [116, 124], [125, 129], [130, 132], [133, 136], [137, 146], [146, 147], [148, 153], [154, 164], [165, 168], [169, 171], [172, 176], [177, 179], [180, 188], [189, 199], [200, 207], [208, 216], [217, 218], [218, 230], [231, 239], [239, 240], [240, 241]]}
{"doc_key": "ai-dev-137", "ner": [[5, 7, "researcher"], [10, 10, "country"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 10, 10, "physical", "", false, false], [5, 7, 26, 27, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "was", "first", "used", "by", "Lawrence", "J.", "Fogel", "in", "the", "US", "in", "1960", "to", "use", "simulated", "evolution", "as", "a", "learning", "process", "with", "the", "aim", "of", "generating", "artificial", "intelligence", "."], "sentence-detokenized": "It was first used by Lawrence J. Fogel in the US in 1960 to use simulated evolution as a learning process with the aim of generating artificial intelligence.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 17], [18, 20], [21, 29], [30, 32], [33, 38], [39, 41], [42, 45], [46, 48], [49, 51], [52, 56], [57, 59], [60, 63], [64, 73], [74, 83], [84, 86], [87, 88], [89, 97], [98, 105], [106, 110], [111, 114], [115, 118], [119, 121], [122, 132], [133, 143], [144, 156], [156, 157]]}
{"doc_key": "ai-dev-138", "ner": [[0, 1, "field"], [9, 11, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 9, 11, "part-of", "", false, false], [14, 15, 9, 11, "part-of", "", false, false], [17, 18, 9, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Reinforcement", "learning", "is", "one", "of", "the", "three", "basic", "paradigms", "for", "machine", "learning", ",", "alongside", "supervised", "learning", "and", "unsupervised", "learning", "."], "sentence-detokenized": "Reinforcement learning is one of the three basic paradigms for machine learning, alongside supervised learning and unsupervised learning.", "token2charspan": [[0, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 42], [43, 48], [49, 58], [59, 62], [63, 70], [71, 79], [79, 80], [81, 90], [91, 101], [102, 110], [111, 114], [115, 127], [128, 136], [136, 137]]}
{"doc_key": "ai-dev-139", "ner": [[4, 5, "field"], [12, 12, "programlang"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 28, 29, "usage", "applies", false, false], [12, 12, 28, 29, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "such", "cases", ",", "cloud", "computing", "and", "the", "open", "source", "programming", "language", "R", "can", "help", "smaller", "banks", "apply", "risk", "analysis", "and", "support", "branch", "-", "level", "supervision", "by", "applying", "predictive", "analytics", "."], "sentence-detokenized": "In such cases, cloud computing and the open source programming language R can help smaller banks apply risk analysis and support branch-level supervision by applying predictive analytics.", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 20], [21, 30], [31, 34], [35, 38], [39, 43], [44, 50], [51, 62], [63, 71], [72, 73], [74, 77], [78, 82], [83, 90], [91, 96], [97, 102], [103, 107], [108, 116], [117, 120], [121, 128], [129, 135], [135, 136], [136, 141], [142, 153], [154, 156], [157, 165], [166, 176], [177, 186], [186, 187]]}
{"doc_key": "ai-dev-140", "ner": [[13, 14, "researcher"], [19, 20, "algorithm"], [22, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 14, 22, 23, "named", "same", false, false], [19, 20, 13, 14, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["One", "of", "the", "first", "versions", "of", "the", "theorem", "was", "proved", "in", "1989", "by", "George", "Cybenko", "for", "activation", "functions", "with", "sigmoid", "function", ".", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "One of the first versions of the theorem was proved in 1989 by George Cybenko for activation functions with sigmoid function. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 25], [26, 28], [29, 32], [33, 40], [41, 44], [45, 51], [52, 54], [55, 59], [60, 62], [63, 69], [70, 77], [78, 81], [82, 92], [93, 102], [103, 107], [108, 115], [116, 124], [124, 125], [126, 133], [134, 136], [137, 138], [138, 142], [142, 143], [143, 144], [145, 146], [147, 148], [148, 149], [149, 150], [150, 151], [152, 159], [159, 160]]}
{"doc_key": "ai-dev-141", "ner": [[6, 6, "algorithm"], [9, 9, "metrics"], [14, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 6, 6, "part-of", "", false, false], [14, 17, 9, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "process", ",", "known", "as", "cross-validation", ",", "the", "MSE", "is", "often", "called", "the", "mean", "squared", "prediction", "error", ",", "and", "is", "calculated", "as"], "sentence-detokenized": "In this process, known as cross-validation, the MSE is often called the mean squared prediction error, and is calculated as", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 22], [23, 25], [26, 42], [42, 43], [44, 47], [48, 51], [52, 54], [55, 60], [61, 67], [68, 71], [72, 76], [77, 84], [85, 95], [96, 101], [101, 102], [103, 106], [107, 109], [110, 120], [121, 123]]}
{"doc_key": "ai-dev-142", "ner": [[0, 2, "task"], [4, 6, "task"], [8, 8, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 4, 6, "compare", "", false, false], [8, 8, 4, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["OMR", "generally", "differs", "from", "optical", "character", "recognition", "(", "OCR", ")", "in", "that", "it", "does", "not", "require", "a", "complicated", "pattern", "recognition", "engine", "."], "sentence-detokenized": "OMR generally differs from optical character recognition (OCR) in that it does not require a complicated pattern recognition engine.", "token2charspan": [[0, 3], [4, 13], [14, 21], [22, 26], [27, 34], [35, 44], [45, 56], [57, 58], [58, 61], [61, 62], [63, 65], [66, 70], [71, 73], [74, 78], [79, 82], [83, 90], [91, 92], [93, 104], [105, 112], [113, 124], [125, 131], [131, 132]]}
{"doc_key": "ai-dev-143", "ner": [[10, 10, "location"], [12, 12, "location"], [14, 14, "location"], [17, 18, "location"], [20, 21, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 14, 14, "physical", "", false, false], [17, 18, 12, 12, "physical", "", false, false], [20, 21, 12, 12, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2018", "and", "2019", ",", "the", "championship", "was", "held", "in", "Houston", "and", "Detroit", ",", "Michigan", "at", "the", "TCF", "Centre", "and", "Ford", "Field", "."], "sentence-detokenized": "In 2018 and 2019, the championship was held in Houston and Detroit, Michigan at the TCF Centre and Ford Field.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 16], [16, 17], [18, 21], [22, 34], [35, 38], [39, 43], [44, 46], [47, 54], [55, 58], [59, 66], [66, 67], [68, 76], [77, 79], [80, 83], [84, 87], [88, 94], [95, 98], [99, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-dev-144", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "understood", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multi-class", "classification", "."], "sentence-detokenized": "Classification can be understood as two separate problems - binary classification and multi-class classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 97], [98, 112], [112, 113]]}
{"doc_key": "ai-dev-145", "ner": [[4, 5, "product"], [8, 9, "product"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "type-of", "", false, false], [12, 13, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "examples", "of", "popular", "parallel", "robots", "are", "the", "Stewart", "platform", "and", "the", "Delta", "robot", "."], "sentence-detokenized": "Two examples of popular parallel robots are the Stewart platform and the Delta robot.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 23], [24, 32], [33, 39], [40, 43], [44, 47], [48, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-146", "ner": [[4, 6, "algorithm"], [22, 22, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 22, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "Nevertheless", ",", "the", "ReLU", "activation", "function", ",", "which", "is", "not", "differentiable", "at", "0", ",", "has", "become", "quite", "popular", ",", "e.g.", "in", "AlexNet", ")"], "sentence-detokenized": "(Nevertheless, the ReLU activation function, which is not differentiable at 0, has become quite popular, e.g. in AlexNet)", "token2charspan": [[0, 1], [1, 13], [13, 14], [15, 18], [19, 23], [24, 34], [35, 43], [43, 44], [45, 50], [51, 53], [54, 57], [58, 72], [73, 75], [76, 77], [77, 78], [79, 82], [83, 89], [90, 95], [96, 103], [103, 104], [105, 109], [110, 112], [113, 120], [120, 121]]}
{"doc_key": "ai-dev-147", "ner": [[1, 3, "metrics"], [8, 8, "task"], [15, 16, "task"], [18, 20, "task"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 3, 4, 5], "relations": [[1, 3, 23, 24, "named", "", true, false], [8, 8, 1, 3, "usage", "", true, false], [15, 16, 8, 8, "part-of", "", false, false], [18, 20, 8, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 3, 4], "sentence": ["The", "F", "-", "score", "is", "often", "used", "in", "information", "retrieval", "for", "measuring", "search", "performance", ",", "document", "classification", "and", "search", "query", "classification", ",", "and", "F_beta", "is", "therefore", "often", "used", "."], "sentence-detokenized": "The F-score is often used in information retrieval for measuring search performance, document classification and search query classification, and F_beta is therefore often used.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 20], [21, 25], [26, 28], [29, 40], [41, 50], [51, 54], [55, 64], [65, 71], [72, 83], [83, 84], [85, 93], [94, 108], [109, 112], [113, 119], [120, 125], [126, 140], [140, 141], [142, 145], [146, 152], [153, 155], [156, 165], [166, 171], [172, 176], [176, 177]]}
{"doc_key": "ai-dev-148", "ner": [[17, 18, "algorithm"], [20, 20, "algorithm"], [23, 24, "algorithm"], [26, 26, "algorithm"], [29, 31, "algorithm"], [33, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 20, 17, 18, "named", "", false, false], [26, 26, 23, 24, "named", "", false, false], [33, 33, 29, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "is", "done", "by", "modelling", "the", "received", "signal", "and", "then", "using", "a", "statistical", "estimation", "method", "such", "as", "maximum", "likelihood", "(", "ML", ")", ",", "majority", "voting", "(", "MV", ")", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "to", "make", "a", "decision", "on", "which", "target", "in", "the", "library", "best", "fits", "the", "model", "built", "using", "the", "received", "signal", "."], "sentence-detokenized": "This is done by modelling the received signal and then using a statistical estimation method such as maximum likelihood (ML), majority voting (MV) or maximum a posteriori (MAP) to make a decision on which target in the library best fits the model built using the received signal.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 25], [26, 29], [30, 38], [39, 45], [46, 49], [50, 54], [55, 60], [61, 62], [63, 74], [75, 85], [86, 92], [93, 97], [98, 100], [101, 108], [109, 119], [120, 121], [121, 123], [123, 124], [124, 125], [126, 134], [135, 141], [142, 143], [143, 145], [145, 146], [147, 149], [150, 157], [158, 159], [160, 170], [171, 172], [172, 175], [175, 176], [177, 179], [180, 184], [185, 186], [187, 195], [196, 198], [199, 204], [205, 211], [212, 214], [215, 218], [219, 226], [227, 231], [232, 236], [237, 240], [241, 246], [247, 252], [253, 258], [259, 262], [263, 271], [272, 278], [278, 279]]}
{"doc_key": "ai-dev-149", "ner": [[0, 1, "researcher"], [3, 3, "misc"], [5, 5, "field"], [8, 11, "university"], [16, 16, "misc"], [18, 19, "field"], [21, 22, "university"], [28, 28, "misc"], [30, 31, "field"], [34, 36, "university"], [43, 52, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 8, 11, "physical", "", false, false], [0, 1, 8, 11, "role", "", false, false], [0, 1, 21, 22, "physical", "", false, false], [0, 1, 21, 22, "role", "", false, false], [0, 1, 34, 36, "physical", "", false, false], [0, 1, 34, 36, "role", "", false, false], [3, 3, 0, 1, "origin", "", false, false], [3, 3, 5, 5, "topic", "", false, false], [16, 16, 0, 1, "origin", "", false, false], [16, 16, 18, 19, "topic", "", false, false], [28, 28, 0, 1, "origin", "", false, false], [28, 28, 30, 31, "topic", "", false, false], [43, 52, 28, 28, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Sowa", "received", "a", "BS", "in", "mathematics", "from", "the", "Massachusetts", "Institute", "of", "Technology", "in", "1962", ",", "an", "MA", "in", "applied", "sciences", "from", "Harvard", "University", "in", "1966", ",", "and", "a", "PhD", "in", "computer", "science", "from", "the", "Vrije", "Universiteit", "Brussel", "in", "1999", "on", "a", "thesis", "entitled", "Knowledge", "Representation", ":", "Logical", ",", "Philosophical", ",", "and", "Computational", "Foundations", "."], "sentence-detokenized": "Sowa received a BS in mathematics from the Massachusetts Institute of Technology in 1962, an MA in applied sciences from Harvard University in 1966, and a PhD in computer science from the Vrije Universiteit Brussel in 1999 on a thesis entitled Knowledge Representation: Logical, Philosophical, and Computational Foundations.", "token2charspan": [[0, 4], [5, 13], [14, 15], [16, 18], [19, 21], [22, 33], [34, 38], [39, 42], [43, 56], [57, 66], [67, 69], [70, 80], [81, 83], [84, 88], [88, 89], [90, 92], [93, 95], [96, 98], [99, 106], [107, 115], [116, 120], [121, 128], [129, 139], [140, 142], [143, 147], [147, 148], [149, 152], [153, 154], [155, 158], [159, 161], [162, 170], [171, 178], [179, 183], [184, 187], [188, 193], [194, 206], [207, 214], [215, 217], [218, 222], [223, 225], [226, 227], [228, 234], [235, 243], [244, 253], [254, 268], [268, 269], [270, 277], [277, 278], [279, 292], [292, 293], [294, 297], [298, 311], [312, 323], [323, 324]]}
{"doc_key": "ai-dev-150", "ner": [[1, 2, "task"], [17, 17, "metrics"], [19, 20, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[17, 17, 1, 2, "part-of", "", true, false], [19, 20, 1, 2, "part-of", "", true, false], [24, 25, 1, 2, "part-of", "", true, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Since", "paraphrase", "recognition", "can", "be", "posed", "as", "a", "classification", "problem", ",", "most", "standard", "evaluation", "metrics", "such", "as", "accuracy", ",", "f1-", "score", ",", "or", "an", "ROC", "curve", "perform", "relatively", "well", "."], "sentence-detokenized": "Since paraphrase recognition can be posed as a classification problem, most standard evaluation metrics such as accuracy, f1-score, or an ROC curve perform relatively well.", "token2charspan": [[0, 5], [6, 16], [17, 28], [29, 32], [33, 35], [36, 41], [42, 44], [45, 46], [47, 61], [62, 69], [69, 70], [71, 75], [76, 84], [85, 95], [96, 103], [104, 108], [109, 111], [112, 120], [120, 121], [122, 125], [125, 130], [130, 131], [132, 134], [135, 137], [138, 141], [142, 147], [148, 155], [156, 166], [167, 171], [171, 172]]}
{"doc_key": "ai-dev-151", "ner": [[20, 20, "algorithm"], [29, 30, "algorithm"], [32, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 20, 29, 30, "opposite", "not_suited_for", false, false], [20, 20, 32, 33, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "makes", "it", "practical", "for", "the", "analysis", "of", "large", "data", "sets", "(", "hundreds", "or", "thousands", "of", "taxa", ")", "and", "for", "bootstrapping", ",", "for", "which", "other", "analysis", "methods", "(", "e.g.", "maximum", "parsimony", ",", "maximum", "likelihood", ")", "require", "too", "much", "computational", "time", "."], "sentence-detokenized": "This makes it practical for the analysis of large data sets (hundreds or thousands of taxa) and for bootstrapping, for which other analysis methods (e.g. maximum parsimony, maximum likelihood) require too much computational time.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 31], [32, 40], [41, 43], [44, 49], [50, 54], [55, 59], [60, 61], [61, 69], [70, 72], [73, 82], [83, 85], [86, 90], [90, 91], [92, 95], [96, 99], [100, 113], [113, 114], [115, 118], [119, 124], [125, 130], [131, 139], [140, 147], [148, 149], [149, 153], [154, 161], [162, 171], [171, 172], [173, 180], [181, 191], [191, 192], [193, 200], [201, 204], [205, 209], [210, 223], [224, 228], [228, 229]]}
{"doc_key": "ai-dev-152", "ner": [[5, 5, "programlang"], [11, 14, "organisation"], [16, 16, "organisation"], [30, 41, "organisation"]], "ner_mapping_to_source": [0, 2, 3, 5], "relations": [[16, 16, 11, 14, "named", "", false, false], [30, 41, 5, 5, "role", "submits", true, false], [30, 41, 11, 14, "role", "submits_to", true, false]], "relations_mapping_to_source": [1, 2, 4], "sentence": ["The", "2002", "submission", "of", "the", "DAML", "+", "OIL", "language", "to", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", "is", "the", "result", "of", "the", "work", "of", "the", "DAML", "contractors", "and", "the", "European", "Union", "-", "United", "States", "Ad", "Hoc", "Joint", "Committee", "on", "Markup", "Languages", "."], "sentence-detokenized": "The 2002 submission of the DAML + OIL language to the World Wide Web Consortium (W3C) is the result of the work of the DAML contractors and the European Union-United States Ad Hoc Joint Committee on Markup Languages.", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 22], [23, 26], [27, 31], [32, 33], [34, 37], [38, 46], [47, 49], [50, 53], [54, 59], [60, 64], [65, 68], [69, 79], [80, 81], [81, 84], [84, 85], [86, 88], [89, 92], [93, 99], [100, 102], [103, 106], [107, 111], [112, 114], [115, 118], [119, 123], [124, 135], [136, 139], [140, 143], [144, 152], [153, 158], [158, 159], [159, 165], [166, 172], [173, 175], [176, 179], [180, 185], [186, 195], [196, 198], [199, 205], [206, 215], [215, 216]]}
{"doc_key": "ai-dev-153", "ner": [[3, 4, "misc"], [8, 8, "misc"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 3, 4, "part-of", "", true, false], [11, 12, 3, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "non-linear", "normalisation", "is", "when", "the", "normalisation", "follows", "a", "sigmoid", "function", ";", "in", "that", "case", ",", "the", "normalised", "image", "is", "calculated", "according", "to", "the", "formula"], "sentence-detokenized": "An example of non-linear normalisation is when the normalisation follows a sigmoid function; in that case, the normalised image is calculated according to the formula", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 38], [39, 41], [42, 46], [47, 50], [51, 64], [65, 72], [73, 74], [75, 82], [83, 91], [91, 92], [93, 95], [96, 100], [101, 105], [105, 106], [107, 110], [111, 121], [122, 127], [128, 130], [131, 141], [142, 151], [152, 154], [155, 158], [159, 166]]}
{"doc_key": "ai-dev-154", "ner": [[5, 5, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 10, 10, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "pointed", "out", "that", "precision", "is", "usually", "linked", "to", "recall", "to", "solve", "this", "problem"], "sentence-detokenized": "It was pointed out that precision is usually linked to recall to solve this problem", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 18], [19, 23], [24, 33], [34, 36], [37, 44], [45, 51], [52, 54], [55, 61], [62, 64], [65, 70], [71, 75], [76, 83]]}
{"doc_key": "ai-dev-155", "ner": [[6, 9, "metrics"], [11, 14, "metrics"], [22, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 23, 11, 14, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "most", "commonly", "used", "measures", "are", "root", "mean", "square", "error", "and", "root", "mean", "square", "error", ";", "the", "latter", "was", "used", "for", "the", "Netflix", "price", "."], "sentence-detokenized": "The most commonly used measures are root mean square error and root mean square error; the latter was used for the Netflix price.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 31], [32, 35], [36, 40], [41, 45], [46, 52], [53, 58], [59, 62], [63, 67], [68, 72], [73, 79], [80, 85], [85, 86], [87, 90], [91, 97], [98, 101], [102, 106], [107, 110], [111, 114], [115, 122], [123, 128], [128, 129]]}
{"doc_key": "ai-dev-156", "ner": [[8, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "August", "2016", ",", "a", "research", "programme", "with", "University", "College", "Hospital", "was", "announced", "with", "the", "aim", "of", "developing", "an", "algorithm", "that", "can", "automatically", "distinguish", "between", "healthy", "and", "cancerous", "tissue", "in", "head", "and", "neck", "areas", "."], "sentence-detokenized": "In August 2016, a research programme with University College Hospital was announced with the aim of developing an algorithm that can automatically distinguish between healthy and cancerous tissue in head and neck areas.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 17], [18, 26], [27, 36], [37, 41], [42, 52], [53, 60], [61, 69], [70, 73], [74, 83], [84, 88], [89, 92], [93, 96], [97, 99], [100, 110], [111, 113], [114, 123], [124, 128], [129, 132], [133, 146], [147, 158], [159, 166], [167, 174], [175, 178], [179, 188], [189, 195], [196, 198], [199, 203], [204, 207], [208, 212], [213, 218], [218, 219]]}
{"doc_key": "ai-dev-157", "ner": [[3, 4, "researcher"], [16, 18, "organisation"], [21, 24, "organisation"], [27, 30, "organisation"], [33, 38, "organisation"], [41, 47, "organisation"], [51, 54, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 4, 16, 18, "role", "", false, false], [3, 4, 21, 24, "role", "", false, false], [3, 4, 27, 30, "role", "", false, false], [3, 4, 33, 38, "role", "", false, false], [3, 4, 41, 47, "role", "", false, false], [3, 4, 51, 54, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "impact", "of", "Posner", "'s", "theoretical", "and", "empirical", "contributions", "has", "been", "recognised", "through", "fellowships", "in", "the", "American", "Psychological", "Association", ",", "the", "Association", "for", "Psychological", "Science", ",", "the", "Society", "of", "Experimental", "Psychologists", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "The impact of Posner's theoretical and empirical contributions has been recognised through fellowships in the American Psychological Association, the Association for Psychological Science, the Society of Experimental Psychologists, the American Academy of Arts and Sciences, the American Association for the Advancement of Science, and the National Academy of Sciences.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 20], [20, 22], [23, 34], [35, 38], [39, 48], [49, 62], [63, 66], [67, 71], [72, 82], [83, 90], [91, 102], [103, 105], [106, 109], [110, 118], [119, 132], [133, 144], [144, 145], [146, 149], [150, 161], [162, 165], [166, 179], [180, 187], [187, 188], [189, 192], [193, 200], [201, 203], [204, 216], [217, 230], [230, 231], [232, 235], [236, 244], [245, 252], [253, 255], [256, 260], [261, 264], [265, 273], [273, 274], [275, 278], [279, 287], [288, 299], [300, 303], [304, 307], [308, 319], [320, 322], [323, 330], [330, 331], [332, 335], [336, 339], [340, 348], [349, 356], [357, 359], [360, 368], [368, 369]]}
{"doc_key": "ai-dev-158", "ner": [[2, 2, "product"], [7, 8, "field"], [12, 13, "task"], [15, 17, "task"], [19, 19, "task"], [22, 24, "task"], [26, 26, "task"], [29, 30, "field"], [32, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 2, 7, 8, "usage", "", false, false], [12, 13, 7, 8, "part-of", "", false, false], [15, 17, 7, 8, "part-of", "", false, false], [19, 19, 15, 17, "named", "", false, false], [22, 24, 7, 8, "part-of", "", false, false], [26, 26, 22, 24, "named", "", false, false], [29, 30, 7, 8, "part-of", "", false, false], [32, 33, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["These", "intelligent", "chatbots", "use", "many", "forms", "of", "artificial", "intelligence", ",", "such", "as", "image", "moderation", "and", "natural", "language", "understanding", "(", "NLU", ")", ",", "natural", "language", "generation", "(", "NLG", ")", ",", "machine", "learning", "and", "deep", "learning", "."], "sentence-detokenized": "These intelligent chatbots use many forms of artificial intelligence, such as image moderation and natural language understanding (NLU), natural language generation (NLG), machine learning and deep learning.", "token2charspan": [[0, 5], [6, 17], [18, 26], [27, 30], [31, 35], [36, 41], [42, 44], [45, 55], [56, 68], [68, 69], [70, 74], [75, 77], [78, 83], [84, 94], [95, 98], [99, 106], [107, 115], [116, 129], [130, 131], [131, 134], [134, 135], [135, 136], [137, 144], [145, 153], [154, 164], [165, 166], [166, 169], [169, 170], [170, 171], [172, 179], [180, 188], [189, 192], [193, 197], [198, 206], [206, 207]]}
{"doc_key": "ai-dev-159", "ner": [[4, 6, "metrics"], [8, 8, "metrics"], [12, 12, "metrics"], [15, 21, "metrics"], [27, 29, "metrics"], [31, 31, "metrics"], [34, 40, "metrics"], [44, 46, "metrics"], [48, 48, "metrics"], [51, 56, "metrics"], [63, 65, "metrics"], [67, 67, "metrics"], [70, 76, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 4, 6, "named", "", false, false], [12, 12, 4, 6, "named", "", false, false], [15, 21, 4, 6, "named", "", false, false], [31, 31, 27, 29, "named", "", false, false], [34, 40, 27, 29, "named", "", false, false], [48, 48, 44, 46, "named", "", false, false], [51, 56, 44, 46, "named", "", false, false], [67, 67, 63, 65, "named", "", false, false], [70, 76, 63, 65, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "row", "ratios", "are", "Positive", "Predictive", "Value", "(", "PPV", ",", "also", "called", "precision", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "supplemented", "by", "the", "FALSE", "Discovery", "Rate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "and", "Negative", "Predictive", "Value", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "supplemented", "by", "the", "FALSE", "Omission", "Rate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "The row ratios are Positive Predictive Value (PPV, also called precision) (TP / (TP + FP)), supplemented by the FALSE Discovery Rate (FDR) (FP / (TP + FP)); and Negative Predictive Value (NPV) (TN / (TN + FN)), supplemented by the FALSE Omission Rate (FOR) (FN / (TN + FN)).", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 18], [19, 27], [28, 38], [39, 44], [45, 46], [46, 49], [49, 50], [51, 55], [56, 62], [63, 72], [72, 73], [74, 75], [75, 77], [78, 79], [80, 81], [81, 83], [84, 85], [86, 88], [88, 89], [89, 90], [90, 91], [92, 104], [105, 107], [108, 111], [112, 117], [118, 127], [128, 132], [133, 134], [134, 137], [137, 138], [139, 140], [140, 142], [143, 144], [145, 146], [146, 148], [149, 150], [151, 153], [153, 154], [154, 155], [155, 156], [157, 160], [161, 169], [170, 180], [181, 186], [187, 188], [188, 191], [191, 192], [193, 194], [194, 196], [197, 198], [199, 200], [200, 202], [203, 204], [205, 207], [207, 208], [208, 209], [209, 210], [211, 223], [224, 226], [227, 230], [231, 236], [237, 245], [246, 250], [251, 252], [252, 255], [255, 256], [257, 258], [258, 260], [261, 262], [263, 264], [264, 266], [267, 268], [269, 271], [271, 272], [272, 273], [273, 274]]}
{"doc_key": "ai-dev-160", "ner": [[8, 8, "misc"], [14, 15, "algorithm"], [17, 17, "algorithm"], [20, 23, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 17, 14, 15, "named", "", false, false], [25, 25, 20, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "information", "is", "a", "mix", "of", "sitemaps", "and", "RSS", "and", "is", "created", "using", "the", "Information", "Model", "(", "IM", ")", "and", "the", "Biomedical", "Resource", "Ontology", "(", "BRO", ")", "."], "sentence-detokenized": "The information is a mix of sitemaps and RSS and is created using the Information Model (IM) and the Biomedical Resource Ontology (BRO).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 20], [21, 24], [25, 27], [28, 36], [37, 40], [41, 44], [45, 48], [49, 51], [52, 59], [60, 65], [66, 69], [70, 81], [82, 87], [88, 89], [89, 91], [91, 92], [93, 96], [97, 100], [101, 111], [112, 120], [121, 129], [130, 131], [131, 134], [134, 135], [135, 136]]}
{"doc_key": "ai-dev-161", "ner": [[1, 2, "task"], [6, 9, "algorithm"], [11, 16, "algorithm"], [23, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 11, 16, "origin", "based_on", false, false], [11, 16, 6, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Recent", "text", "recognition", "is", "based", "on", "a", "recurrent", "neural", "network", "(", "long", "-", "short", "-", "term", "memory", ")", "and", "does", "not", "require", "a", "language", "model", "."], "sentence-detokenized": "Recent text recognition is based on a recurrent neural network (long-short-term memory) and does not require a language model.", "token2charspan": [[0, 6], [7, 11], [12, 23], [24, 26], [27, 32], [33, 35], [36, 37], [38, 47], [48, 54], [55, 62], [63, 64], [64, 68], [68, 69], [69, 74], [74, 75], [75, 79], [80, 86], [86, 87], [88, 91], [92, 96], [97, 100], [101, 108], [109, 110], [111, 119], [120, 125], [125, 126]]}
{"doc_key": "ai-dev-162", "ner": [[1, 2, "misc"], [5, 6, "metrics"], [9, 10, "algorithm"], [14, 15, "metrics"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 1, 2, "type-of", "", false, false], [9, 10, 5, 6, "related-to", "", true, false], [14, 15, 1, 2, "type-of", "", false, false], [18, 19, 14, 15, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Popular", "loss", "functions", "are", "the", "hinge", "loss", "(", "for", "linear", "SVMs", ")", "and", "the", "log", "loss", "(", "for", "logistic", "regression", ")", "."], "sentence-detokenized": "Popular loss functions are the hinge loss (for linear SVMs) and the log loss (for logistic regression).", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 26], [27, 30], [31, 36], [37, 41], [42, 43], [43, 46], [47, 53], [54, 58], [58, 59], [60, 63], [64, 67], [68, 71], [72, 76], [77, 78], [78, 81], [82, 90], [91, 101], [101, 102], [102, 103]]}
{"doc_key": "ai-dev-163", "ner": [[0, 0, "metrics"], [10, 16, "metrics"], [18, 18, "metrics"], [21, 23, "metrics"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 10, 16, "compare", "", false, false], [0, 0, 21, 23, "compare", "", false, false], [18, 18, 10, 16, "named", "", false, false], [25, 25, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "is", "designed", "to", "improve", "on", "traditional", "methods", "such", "as", "peak", "signal", "-", "to", "-", "noise", "ratio", "(", "PSNR", ")", "and", "mean", "square", "error", "(", "MSE", ")", "."], "sentence-detokenized": "SSIM is designed to improve on traditional methods such as peak signal-to-noise ratio (PSNR) and mean square error (MSE).", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 27], [28, 30], [31, 42], [43, 50], [51, 55], [56, 58], [59, 63], [64, 70], [70, 71], [71, 73], [73, 74], [74, 79], [80, 85], [86, 87], [87, 91], [91, 92], [93, 96], [97, 101], [102, 108], [109, 114], [115, 116], [116, 119], [119, 120], [120, 121]]}
{"doc_key": "ai-dev-164", "ner": [[10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "inspired", "later", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "His work inspired later generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 23], [24, 35], [36, 38], [39, 47], [48, 59], [60, 64], [65, 67], [68, 74], [75, 81], [81, 82], [83, 87], [88, 95], [96, 99], [100, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-dev-165", "ner": [[16, 20, "algorithm"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Furthermore", ",", "pulse", "training", "is", "not", "differentiable", ",", "so", "backpropagation", "-", "based", "training", "methods", "such", "as", "gradient", "descent", "are", "not", "possible", "."], "sentence-detokenized": "Furthermore, pulse training is not differentiable, so backpropagation-based training methods such as gradient descent are not possible.", "token2charspan": [[0, 11], [11, 12], [13, 18], [19, 27], [28, 30], [31, 34], [35, 49], [49, 50], [51, 53], [54, 69], [69, 70], [70, 75], [76, 84], [85, 92], [93, 97], [98, 100], [101, 109], [110, 117], [118, 121], [122, 125], [126, 134], [134, 135]]}
{"doc_key": "ai-dev-166", "ner": [[8, 9, "metrics"], [15, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 15, 15, "related-to", "describes", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "relationships", "can", "be", "easily", "represented", "by", "a", "confusion", "matrix", ",", "a", "table", "describing", "the", "accuracy", "of", "a", "classification", "model", "."], "sentence-detokenized": "These relationships can be easily represented by a confusion matrix, a table describing the accuracy of a classification model.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 26], [27, 33], [34, 45], [46, 48], [49, 50], [51, 60], [61, 67], [67, 68], [69, 70], [71, 76], [77, 87], [88, 91], [92, 100], [101, 103], [104, 105], [106, 120], [121, 126], [126, 127]]}
{"doc_key": "ai-dev-167", "ner": [[2, 8, "conference"], [10, 10, "conference"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 2, 8, "named", "", false, false], [15, 15, 2, 8, "physical", "", false, false], [15, 15, 2, 8, "role", "", false, false], [15, 15, 2, 8, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["At", "the", "2018", "Conference", "on", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", ",", "researchers", "from", "Google", "presented", "the", "work"], "sentence-detokenized": "At the 2018 Conference on Neural Information Processing Systems (NeurIPS), researchers from Google presented the work", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 22], [23, 25], [26, 32], [33, 44], [45, 55], [56, 63], [64, 65], [65, 72], [72, 73], [73, 74], [75, 86], [87, 91], [92, 98], [99, 108], [109, 112], [113, 117]]}
{"doc_key": "ai-dev-168", "ner": [[4, 4, "university"], [13, 13, "product"], [18, 20, "misc"], [22, 22, "conference"], [29, 32, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 18, 20, "win-defeat", "", false, false], [18, 20, 22, 22, "temporal", "", false, false], [29, 32, 22, 22, "part-of", "", false, false], [29, 32, 22, 22, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "his", "time", "at", "Duke", ",", "he", "worked", "on", "an", "automated", "crossword", "solver", "PROVERB", ",", "which", "won", "an", "Outstanding", "Paper", "Award", "from", "AAAI", "in", "1999", "and", "competed", "in", "the", "American", "Crossword", "Puzzle", "Tournament", "."], "sentence-detokenized": "During his time at Duke, he worked on an automated crossword solver PROVERB, which won an Outstanding Paper Award from AAAI in 1999 and competed in the American Crossword Puzzle Tournament.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 18], [19, 23], [23, 24], [25, 27], [28, 34], [35, 37], [38, 40], [41, 50], [51, 60], [61, 67], [68, 75], [75, 76], [77, 82], [83, 86], [87, 89], [90, 101], [102, 107], [108, 113], [114, 118], [119, 123], [124, 126], [127, 131], [132, 135], [136, 144], [145, 147], [148, 151], [152, 160], [161, 170], [171, 177], [178, 188], [188, 189]]}
{"doc_key": "ai-dev-169", "ner": [[2, 3, "location"], [5, 5, "location"], [14, 15, "country"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 5, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Headquartered", "in", "Rochester", "Hills", ",", "Michigan", ",", "the", "company", "has", "10", "regional", "offices", "in", "the", "US", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "sentence-detokenized": "Headquartered in Rochester Hills, Michigan, the company has 10 regional offices in the US , Canada, Mexico and Brazil.", "token2charspan": [[0, 13], [14, 16], [17, 26], [27, 32], [32, 33], [34, 42], [42, 43], [44, 47], [48, 55], [56, 59], [60, 62], [63, 71], [72, 79], [80, 82], [83, 86], [87, 89], [90, 91], [92, 98], [98, 99], [100, 106], [107, 110], [111, 117], [117, 118]]}
{"doc_key": "ai-dev-170", "ner": [[12, 12, "product"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "joins", "a", "collection", "of", "historically", "significant", "robots", ",", "including", "an", "early", "Unimate", "and", "the", "Odetics", "Odex", "1", "."], "sentence-detokenized": "It joins a collection of historically significant robots, including an early Unimate and the Odetics Odex 1.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 21], [22, 24], [25, 37], [38, 49], [50, 56], [56, 57], [58, 67], [68, 70], [71, 76], [77, 84], [85, 88], [89, 92], [93, 100], [101, 105], [106, 107], [107, 108]]}
{"doc_key": "ai-dev-171", "ner": [[6, 7, "researcher"], [11, 11, "organisation"], [13, 16, "researcher"], [22, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 11, 11, "physical", "", false, false], [6, 7, 11, 11, "role", "", false, false], [13, 16, 11, 11, "physical", "", false, false], [13, 16, 11, 11, "role", "", false, false], [13, 16, 22, 25, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Guest", "editor", "for", "that", "issue", "is", "David", "'s", "former", "colleague", "at", "NIST", ",", "Judah", "Levine", ",", "the", "most", "recent", "recipient", "of", "the", "I.I", ".", "Rabi", "Award", "."], "sentence-detokenized": "Guest editor for that issue is David's former colleague at NIST, Judah Levine, the most recent recipient of the I.I. Rabi Award.", "token2charspan": [[0, 5], [6, 12], [13, 16], [17, 21], [22, 27], [28, 30], [31, 36], [36, 38], [39, 45], [46, 55], [56, 58], [59, 63], [63, 64], [65, 70], [71, 77], [77, 78], [79, 82], [83, 87], [88, 94], [95, 104], [105, 107], [108, 111], [112, 115], [115, 116], [117, 121], [122, 127], [127, 128]]}
{"doc_key": "ai-dev-172", "ner": [[12, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "can", "be", "arranged", "in", "a", "2", "\u00d7", "2", "contingency", "table", "(", "confusion", "matrix", ")", ",", "traditionally", "with", "the", "test", "result", "on", "the", "vertical", "axis", "and", "the", "actual", "state", "on", "the", "horizontal", "axis", "."], "sentence-detokenized": "These can be arranged in a 2 \u00d7 2 contingency table (confusion matrix), traditionally with the test result on the vertical axis and the actual state on the horizontal axis.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 21], [22, 24], [25, 26], [27, 28], [29, 30], [31, 32], [33, 44], [45, 50], [51, 52], [52, 61], [62, 68], [68, 69], [69, 70], [71, 84], [85, 89], [90, 93], [94, 98], [99, 105], [106, 108], [109, 112], [113, 121], [122, 126], [127, 130], [131, 134], [135, 141], [142, 147], [148, 150], [151, 154], [155, 165], [166, 170], [170, 171]]}
{"doc_key": "ai-dev-173", "ner": [[1, 5, "product"], [8, 8, "product"], [10, 10, "product"], [12, 13, "product"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 5, 8, 8, "part-of", "", false, false], [1, 5, 10, 10, "part-of", "", false, false], [1, 5, 12, 13, "part-of", "", false, false], [1, 5, 17, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Apple", "iOS", "operating", "system", "used", "on", "the", "iPhone", ",", "iPad", "and", "iPod", "Touch", "uses", "VoiceOver", "accessibility", "by", "speech", "synthesis", "."], "sentence-detokenized": "The Apple iOS operating system used on the iPhone, iPad and iPod Touch uses VoiceOver accessibility by speech synthesis.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 23], [24, 30], [31, 35], [36, 38], [39, 42], [43, 49], [49, 50], [51, 55], [56, 59], [60, 64], [65, 70], [71, 75], [76, 85], [86, 99], [100, 102], [103, 109], [110, 119], [119, 120]]}
{"doc_key": "ai-dev-174", "ner": [[4, 6, "conference"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "best", "system", "entering", "MUC", "-", "7", ",", "for", "example", ",", "scored", "93.39", "%", "of", "the", "F", "-", "measure", ",", "while", "human", "annotators", "scored", "97.6", "%", "and", "96.95", "%", "."], "sentence-detokenized": "The best system entering MUC-7, for example, scored 93.39% of the F-measure, while human annotators scored 97.6% and 96.95%.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 24], [25, 28], [28, 29], [29, 30], [30, 31], [32, 35], [36, 43], [43, 44], [45, 51], [52, 57], [57, 58], [59, 61], [62, 65], [66, 67], [67, 68], [68, 75], [75, 76], [77, 82], [83, 88], [89, 99], [100, 106], [107, 111], [111, 112], [113, 116], [117, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-dev-175", "ner": [[11, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 11, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "done", "using", "standard", "neural", "network", "training", "algorithms", "such", "as", "stochastic", "gradient", "descent", "with", "backpropagation", "."], "sentence-detokenized": "This is done using standard neural network training algorithms such as stochastic gradient descent with backpropagation.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 18], [19, 27], [28, 34], [35, 42], [43, 51], [52, 62], [63, 67], [68, 70], [71, 81], [82, 90], [91, 98], [99, 103], [104, 119], [119, 120]]}
{"doc_key": "ai-dev-176", "ner": [[0, 1, "organisation"], [19, 19, "country"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 19, 19, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "is", "a", "top", "1000", "site", ",", "ranking", "around", "#", "400", "worldwide", "and", "top", "150", "only", "for", "the", "US", ",", "according", "to", "website", "ranker", "Alexa", "."], "sentence-detokenized": "Rotten Tomatoes is a top 1000 site, ranking around #400 worldwide and top 150 only for the US, according to website ranker Alexa.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 20], [21, 24], [25, 29], [30, 34], [34, 35], [36, 43], [44, 50], [51, 52], [52, 55], [56, 65], [66, 69], [70, 73], [74, 77], [78, 82], [83, 86], [87, 90], [91, 93], [93, 94], [95, 104], [105, 107], [108, 115], [116, 122], [123, 128], [128, 129]]}
{"doc_key": "ai-dev-177", "ner": [[16, 17, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "general", ",", "all", "learning", "shows", "a", "step", "change", "over", "time", ",", "but", "it", "describes", "a", "Sigmoid", "function", "that", "has", "different", "manifestations", "depending", "on", "the", "time", "scale", "of", "observation", "."], "sentence-detokenized": "In general, all learning shows a step change over time, but it describes a Sigmoid function that has different manifestations depending on the time scale of observation.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 24], [25, 30], [31, 32], [33, 37], [38, 44], [45, 49], [50, 54], [54, 55], [56, 59], [60, 62], [63, 72], [73, 74], [75, 82], [83, 91], [92, 96], [97, 100], [101, 110], [111, 125], [126, 135], [136, 138], [139, 142], [143, 147], [148, 153], [154, 156], [157, 168], [168, 169]]}
{"doc_key": "ai-dev-178", "ner": [[1, 1, "metrics"], [6, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SSD", "is", "also", "known", "as", "mean", "squared", "error", "."], "sentence-detokenized": "The SSD is also known as mean squared error.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 21], [22, 24], [25, 29], [30, 37], [38, 43], [43, 44]]}
{"doc_key": "ai-dev-179", "ner": [[0, 2, "algorithm"], [4, 5, "algorithm"], [8, 13, "algorithm"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 24, 25, "related-to", "can_be_related_to", true, false], [4, 5, 24, 25, "related-to", "can_be_related_to", true, false], [8, 13, 24, 25, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", ",", "neural", "networks", "or", "a", "naive", "Bayes", "classifier", "can", "be", "used", ",", "in", "combination", "with", "measures", "of", "model", "quality", "such", "as", "balanced", "accuracy"], "sentence-detokenized": "Decision tree learning, neural networks or a naive Bayes classifier can be used, in combination with measures of model quality such as balanced accuracy", "token2charspan": [[0, 8], [9, 13], [14, 22], [22, 23], [24, 30], [31, 39], [40, 42], [43, 44], [45, 50], [51, 56], [57, 67], [68, 71], [72, 74], [75, 79], [79, 80], [81, 83], [84, 95], [96, 100], [101, 109], [110, 112], [113, 118], [119, 126], [127, 131], [132, 134], [135, 143], [144, 152]]}
{"doc_key": "ai-dev-180", "ner": [[15, 15, "conference"], [20, 27, "conference"], [24, 24, "misc"], [32, 34, "product"], [40, 43, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[24, 24, 20, 27, "origin", "", false, false], [24, 24, 20, 27, "temporal", "", false, false], [32, 34, 24, 24, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "is", "past", "president", "(", "1979", ")", "and", "inaugural", "Fellow", "(", "2011", ")", "of", "the", "ACL", ",", "co-winner", "of", "the", "Association", "for", "Computing", "Machinery", "Award", "in", "1992", "for", "his", "contribution", "to", "the", "Interlisp", "programming", "system", ",", "and", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "He is past president (1979) and inaugural Fellow (2011) of the ACL, co-winner of the Association for Computing Machinery Award in 1992 for his contribution to the Interlisp programming system, and Fellow of the Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 20], [21, 22], [22, 26], [26, 27], [28, 31], [32, 41], [42, 48], [49, 50], [50, 54], [54, 55], [56, 58], [59, 62], [63, 66], [66, 67], [68, 77], [78, 80], [81, 84], [85, 96], [97, 100], [101, 110], [111, 120], [121, 126], [127, 129], [130, 134], [135, 138], [139, 142], [143, 155], [156, 158], [159, 162], [163, 172], [173, 184], [185, 191], [191, 192], [193, 196], [197, 203], [204, 206], [207, 210], [211, 222], [223, 226], [227, 236], [237, 246], [246, 247]]}
{"doc_key": "ai-dev-181", "ner": [[2, 3, "researcher"], [5, 10, "researcher"], [8, 8, "researcher"], [12, 13, "researcher"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 27, 28, "related-to", "", false, false], [5, 10, 27, 28, "related-to", "", false, false], [8, 8, 27, 28, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "is", "considered", "by", "Cade", "Metz", "to", "be", "one", "of", "the", "three", "people", "most", "responsible", "for", "the", "advancement", "of", "deep", "learning", "in", "the", "1990s", "and", "2000s", "."], "sentence-detokenized": "Along with Geoffrey Hinton and Yann LeCun, Bengio is considered by Cade Metz to be one of the three people most responsible for the advancement of deep learning in the 1990s and 2000s.", "token2charspan": [[0, 5], [6, 10], [11, 19], [20, 26], [27, 30], [31, 35], [36, 41], [41, 42], [43, 49], [50, 52], [53, 63], [64, 66], [67, 71], [72, 76], [77, 79], [80, 82], [83, 86], [87, 89], [90, 93], [94, 99], [100, 106], [107, 111], [112, 123], [124, 127], [128, 131], [132, 143], [144, 146], [147, 151], [152, 160], [161, 163], [164, 167], [168, 173], [174, 177], [178, 183], [183, 184]]}
{"doc_key": "ai-dev-182", "ner": [[1, 2, "field"], [4, 5, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "information", "theory", "and", "computer", "science", ",", "a", "code", "is", "usually", "regarded", "as", "an", "algorithm", "that", "uniquely", "represents", "symbols", "from", "a", "particular", "source", "alphabet", "by", "encoded", "sequences", ",", "which", "may", "be", "in", "a", "different", "target", "alphabet", "."], "sentence-detokenized": "In information theory and computer science, a code is usually regarded as an algorithm that uniquely represents symbols from a particular source alphabet by encoded sequences, which may be in a different target alphabet.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 45], [46, 50], [51, 53], [54, 61], [62, 70], [71, 73], [74, 76], [77, 86], [87, 91], [92, 100], [101, 111], [112, 119], [120, 124], [125, 126], [127, 137], [138, 144], [145, 153], [154, 156], [157, 164], [165, 174], [174, 175], [176, 181], [182, 185], [186, 188], [189, 191], [192, 193], [194, 203], [204, 210], [211, 219], [219, 220]]}
{"doc_key": "ai-dev-183", "ner": [[8, 9, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 8, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "fairly", "simple", "non", "-linear", "function", ",", "the", "sigmoid", "function", "like", "the", "logistic", "function", "also", "has", "an", "easy", "-", "to", "-", "calculate", "derivative", ",", "which", "can", "be", "important", "when", "calculating", "weight", "updates", "in", "the", "network", "."], "sentence-detokenized": "A fairly simple non-linear function, the sigmoid function like the logistic function also has an easy-to-calculate derivative, which can be important when calculating weight updates in the network.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 19], [19, 26], [27, 35], [35, 36], [37, 40], [41, 48], [49, 57], [58, 62], [63, 66], [67, 75], [76, 84], [85, 89], [90, 93], [94, 96], [97, 101], [101, 102], [102, 104], [104, 105], [105, 114], [115, 125], [125, 126], [127, 132], [133, 136], [137, 139], [140, 149], [150, 154], [155, 166], [167, 173], [174, 181], [182, 184], [185, 188], [189, 196], [196, 197]]}
{"doc_key": "ai-dev-184", "ner": [[0, 0, "person"], [4, 4, "location"], [6, 6, "location"], [8, 10, "country"], [13, 13, "country"], [17, 17, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 4, "physical", "", false, false], [4, 4, 6, 6, "physical", "", false, false], [6, 6, 8, 10, "physical", "", false, false], [6, 6, 13, 13, "physical", "", false, false], [6, 6, 17, 17, "physical", "", false, false], [13, 13, 8, 10, "origin", "", false, false], [17, 17, 13, 13, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "was", "born", "in", "Hronov", ",", "Bohemia", "(", "Austria", "-", "Hungary", ",", "later", "Czechoslovakia", ",", "now", "the", "Czech", "Republic", ")", "in", "1887", "."], "sentence-detokenized": "\u010capek was born in Hronov, Bohemia (Austria-Hungary, later Czechoslovakia, now the Czech Republic) in 1887.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 24], [24, 25], [26, 33], [34, 35], [35, 42], [42, 43], [43, 50], [50, 51], [52, 57], [58, 72], [72, 73], [74, 77], [78, 81], [82, 87], [88, 96], [96, 97], [98, 100], [101, 105], [105, 106]]}
{"doc_key": "ai-dev-185", "ner": [[5, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "specialised", "software", "can", "tell", "RSS", "."], "sentence-detokenized": "Some specialised software can tell RSS.", "token2charspan": [[0, 4], [5, 16], [17, 25], [26, 29], [30, 34], [35, 38], [38, 39]]}
{"doc_key": "ai-dev-186", "ner": [[5, 5, "task"], [10, 11, "task"], [16, 16, "task"], [18, 19, "task"], [27, 29, "task"], [31, 32, "task"], [37, 38, "task"], [41, 43, "product"], [45, 46, "product"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8, 9], "relations": [[5, 5, 10, 11, "related-to", "", true, false], [5, 5, 16, 16, "related-to", "", true, false], [31, 32, 27, 29, "usage", "", true, false], [41, 43, 37, 38, "type-of", "", false, false], [45, 46, 37, 38, "type-of", "", false, false]], "relations_mapping_to_source": [0, 2, 3, 4, 5], "sentence": ["Aspects", "of", "ontology", "editors", "include", "visual", "navigation", "capabilities", "within", "the", "knowledge", "model", ",", "inference", "engines", "and", "extraction", ";", "module", "support", ";", "import", "and", "export", "of", "foreign", "languages", "for", "knowledge", "representation", "for", "ontology", "matching", ";", "and", "support", "for", "meta", "-ontologies", "such", "as", "OWL", "-", "S", ",", "Dublin", "Core", ",", "etc", "."], "sentence-detokenized": "Aspects of ontology editors include visual navigation capabilities within the knowledge model, inference engines and extraction; module support; import and export of foreign languages for knowledge representation for ontology matching; and support for meta-ontologies such as OWL-S, Dublin Core, etc.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 27], [28, 35], [36, 42], [43, 53], [54, 66], [67, 73], [74, 77], [78, 87], [88, 93], [93, 94], [95, 104], [105, 112], [113, 116], [117, 127], [127, 128], [129, 135], [136, 143], [143, 144], [145, 151], [152, 155], [156, 162], [163, 165], [166, 173], [174, 183], [184, 187], [188, 197], [198, 212], [213, 216], [217, 225], [226, 234], [234, 235], [236, 239], [240, 247], [248, 251], [252, 256], [256, 267], [268, 272], [273, 275], [276, 279], [279, 280], [280, 281], [281, 282], [283, 289], [290, 294], [294, 295], [296, 299], [299, 300]]}
{"doc_key": "ai-dev-187", "ner": [[1, 1, "organisation"], [6, 9, "misc"], [11, 12, "task"], [17, 18, "field"], [21, 21, "misc"], [23, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 9, 1, 1, "origin", "", false, false], [11, 12, 6, 9, "part-of", "", false, false], [17, 18, 6, 9, "part-of", "", false, false], [21, 21, 17, 18, "type-of", "", false, false], [23, 24, 17, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "FBI", "has", "also", "established", "a", "Next", "Generation", "Identification", "programme", "with", "facial", "recognition", ",", "alongside", "more", "traditional", "biometric", "data", "such", "as", "fingerprints", "and", "iris", "scans", ",", "which", "can", "be", "extracted", "from", "both", "criminal", "and", "civil", "databases", "."], "sentence-detokenized": "The FBI has also established a Next Generation Identification programme with facial recognition, alongside more traditional biometric data such as fingerprints and iris scans, which can be extracted from both criminal and civil databases.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 28], [29, 30], [31, 35], [36, 46], [47, 61], [62, 71], [72, 76], [77, 83], [84, 95], [95, 96], [97, 106], [107, 111], [112, 123], [124, 133], [134, 138], [139, 143], [144, 146], [147, 159], [160, 163], [164, 168], [169, 174], [174, 175], [176, 181], [182, 185], [186, 188], [189, 198], [199, 203], [204, 208], [209, 217], [218, 221], [222, 227], [228, 237], [237, 238]]}
{"doc_key": "ai-dev-188", "ner": [[5, 6, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "2016", "season", ",", "Samantha", "Ponder", "was", "added", "as", "presenter", ",", "replacing", "Molly", "McGrath", "."], "sentence-detokenized": "For the 2016 season, Samantha Ponder was added as presenter, replacing Molly McGrath.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 19], [19, 20], [21, 29], [30, 36], [37, 40], [41, 46], [47, 49], [50, 59], [59, 60], [61, 70], [71, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-dev-189", "ner": [[3, 5, "algorithm"], [17, 21, "misc"], [23, 23, "misc"], [25, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "an", "adversarial", "search", "algorithm", "commonly", "used", "for", "machine", "-", "playing", "two", "-", "player", "games", "(", "Tic", "-", "tac", "-", "toe", ",", "Chess", ",", "Go", ",", "etc.", ")", ",", "but", "it", "is", "also", "used", "for", "the", "development", "of", "the", "game", "."], "sentence-detokenized": "It is an adversarial search algorithm commonly used for machine-playing two-player games (Tic-tac-toe, Chess, Go, etc.), but it is also used for the development of the game.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 27], [28, 37], [38, 46], [47, 51], [52, 55], [56, 63], [63, 64], [64, 71], [72, 75], [75, 76], [76, 82], [83, 88], [89, 90], [90, 93], [93, 94], [94, 97], [97, 98], [98, 101], [101, 102], [103, 108], [108, 109], [110, 112], [112, 113], [114, 118], [118, 119], [119, 120], [121, 124], [125, 127], [128, 130], [131, 135], [136, 140], [141, 144], [145, 148], [149, 160], [161, 163], [164, 167], [168, 172], [172, 173]]}
{"doc_key": "ai-dev-190", "ner": [[5, 6, "field"], [8, 9, "field"], [12, 13, "field"], [20, 21, "field"], [23, 24, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "covers", "the", "fields", "of", "computer", "vision", "or", "machine", "vision", ",", "and", "medical", "imaging", ",", "and", "makes", "intensive", "use", "of", "pattern", "recognition", ",", "digital", "geometry", ",", "and", "signal", "processing", "."], "sentence-detokenized": "It covers the fields of computer vision or machine vision, and medical imaging, and makes intensive use of pattern recognition, digital geometry, and signal processing.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 20], [21, 23], [24, 32], [33, 39], [40, 42], [43, 50], [51, 57], [57, 58], [59, 62], [63, 70], [71, 78], [78, 79], [80, 83], [84, 89], [90, 99], [100, 103], [104, 106], [107, 114], [115, 126], [126, 127], [128, 135], [136, 144], [144, 145], [146, 149], [150, 156], [157, 167], [167, 168]]}
{"doc_key": "ai-dev-191", "ner": [[2, 4, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "a", "facial", "recognition", "system", ",", "for", "example", ",", "a", "picture", "of", "a", "person", "'s", "face", "would", "be", "the", "input", ",", "and", "the", "output", "label", "would", "be", "that", "person", "'s", "name", "."], "sentence-detokenized": "In a facial recognition system, for example, a picture of a person's face would be the input, and the output label would be that person's name.", "token2charspan": [[0, 2], [3, 4], [5, 11], [12, 23], [24, 30], [30, 31], [32, 35], [36, 43], [43, 44], [45, 46], [47, 54], [55, 57], [58, 59], [60, 66], [66, 68], [69, 73], [74, 79], [80, 82], [83, 86], [87, 92], [92, 93], [94, 97], [98, 101], [102, 108], [109, 114], [115, 120], [121, 123], [124, 128], [129, 135], [135, 137], [138, 142], [142, 143]]}
{"doc_key": "ai-dev-192", "ner": [[0, 1, "organisation"], [3, 4, "product"], [8, 10, "product"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 3, 4, "artifact", "", false, false], [3, 4, 8, 10, "part-of", "", false, false], [8, 10, 3, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc", "introduced", "Face", "ID", "on", "its", "flagship", "i", "Phone", "X", "as", "a", "biometric", "authentication", "successor", "to", "Touch", "ID", ",", "a", "fingerprint", "-", "based", "system", "."], "sentence-detokenized": "Apple Inc introduced Face ID on its flagship iPhone X as a biometric authentication successor to Touch ID, a fingerprint-based system.", "token2charspan": [[0, 5], [6, 9], [10, 20], [21, 25], [26, 28], [29, 31], [32, 35], [36, 44], [45, 46], [46, 51], [52, 53], [54, 56], [57, 58], [59, 68], [69, 83], [84, 93], [94, 96], [97, 102], [103, 105], [105, 106], [107, 108], [109, 120], [120, 121], [121, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-dev-193", "ner": [[3, 5, "metrics"], [8, 10, "metrics"], [22, 25, "metrics"], [28, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Or", "combine", "the", "F", "-", "measure", "with", "the", "R-", "squared", "evaluated", "for", "the", "raw", "model", "output", "and", "the", "target", ";", "or", "the", "cost", "/", "profit", "matrix", "with", "the", "correlation", "coefficient", ",", "and", "so", "on", "."], "sentence-detokenized": "Or combine the F-measure with the R-squared evaluated for the raw model output and the target; or the cost/profit matrix with the correlation coefficient, and so on.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 16], [16, 17], [17, 24], [25, 29], [30, 33], [34, 36], [36, 43], [44, 53], [54, 57], [58, 61], [62, 65], [66, 71], [72, 78], [79, 82], [83, 86], [87, 93], [93, 94], [95, 97], [98, 101], [102, 106], [106, 107], [107, 113], [114, 120], [121, 125], [126, 129], [130, 141], [142, 153], [153, 154], [155, 158], [159, 161], [162, 164], [164, 165]]}
{"doc_key": "ai-dev-194", "ner": [[1, 5, "conference"], [16, 18, "location"], [20, 20, "location"], [24, 28, "location"], [30, 30, "location"], [32, 32, "country"], [38, 40, "location"], [43, 47, "location"], [49, 49, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[1, 5, 16, 18, "physical", "", false, false], [1, 5, 24, 28, "physical", "", false, false], [1, 5, 38, 40, "physical", "", false, false], [1, 5, 43, 47, "physical", "", false, false], [16, 18, 20, 20, "physical", "", false, false], [24, 28, 30, 30, "physical", "", false, false], [30, 30, 32, 32, "physical", "", false, false], [38, 40, 49, 49, "physical", "", false, false], [43, 47, 49, 49, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "Spanish", "edition", "of", "Campus", "Party", "has", "taken", "place", "for", "the", "past", "15", "years", "at", "the", "Colegio", "Miguel", "Hern\u00e1ndez", ",", "Ceulaj", ",", "and", "the", "Municipal", "Sports", "Arena", "of", "Benalm\u00e1dena", "in", "M\u00e1laga", ",", "Spain", ";", "and", "at", "both", "the", "Valencia", "County", "Fair", "and", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "The Spanish edition of Campus Party has taken place for the past 15 years at the Colegio Miguel Hern\u00e1ndez, Ceulaj, and the Municipal Sports Arena of Benalm\u00e1dena in M\u00e1laga, Spain; and at both the Valencia County Fair and the City of Arts and Sciences in Valencia.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 22], [23, 29], [30, 35], [36, 39], [40, 45], [46, 51], [52, 55], [56, 59], [60, 64], [65, 67], [68, 73], [74, 76], [77, 80], [81, 88], [89, 95], [96, 105], [105, 106], [107, 113], [113, 114], [115, 118], [119, 122], [123, 132], [133, 139], [140, 145], [146, 148], [149, 160], [161, 163], [164, 170], [170, 171], [172, 177], [177, 178], [179, 182], [183, 185], [186, 190], [191, 194], [195, 203], [204, 210], [211, 215], [216, 219], [220, 223], [224, 228], [229, 231], [232, 236], [237, 240], [241, 249], [250, 252], [253, 261], [261, 262]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [14, 14, "programlang"], [17, 17, "product"], [23, 23, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[14, 14, 0, 0, "general-affiliation", "", false, false], [17, 17, 14, 14, "part-of", "", false, false], [23, 23, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 3], "sentence": ["gnuplot", "can", "be", "used", "from", "several", "programming", "languages", "to", "graphically", "display", "data", ",", "including", "Perl", "(", "via", "PDL", "and", "CPAN", "packages", ")", ",", "Python", "(", "via", ")", "."], "sentence-detokenized": "gnuplot can be used from several programming languages to graphically display data, including Perl (via PDL and CPAN packages), Python (via).", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 19], [20, 24], [25, 32], [33, 44], [45, 54], [55, 57], [58, 69], [70, 77], [78, 82], [82, 83], [84, 93], [94, 98], [99, 100], [100, 103], [104, 107], [108, 111], [112, 116], [117, 125], [125, 126], [126, 127], [128, 134], [135, 136], [136, 139], [139, 140], [140, 141]]}
{"doc_key": "ai-dev-196", "ner": [[3, 5, "product"], [19, 19, "conference"], [21, 21, "conference"], [35, 35, "conference"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 3, 5, "topic", "", false, false], [21, 21, 3, 5, "topic", "", false, false], [35, 35, 3, 5, "topic", "", false, false], [37, 37, 3, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "field", "of", "spoken", "dialogue", "systems", "is", "quite", "large", ",", "encompassing", "research", "(", "covered", "at", "scientific", "conferences", "such", "as", "SIGdial", "and", "Interspeech", ")", "and", "a", "large", "industrial", "sector", "(", "with", "its", "own", "meetings", "such", "as", "SpeechTek", "and", "AVIOS", ")", "."], "sentence-detokenized": "The field of spoken dialogue systems is quite large, encompassing research (covered at scientific conferences such as SIGdial and Interspeech) and a large industrial sector (with its own meetings such as SpeechTek and AVIOS).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 28], [29, 36], [37, 39], [40, 45], [46, 51], [51, 52], [53, 65], [66, 74], [75, 76], [76, 83], [84, 86], [87, 97], [98, 109], [110, 114], [115, 117], [118, 125], [126, 129], [130, 141], [141, 142], [143, 146], [147, 148], [149, 154], [155, 165], [166, 172], [173, 174], [174, 178], [179, 182], [183, 186], [187, 195], [196, 200], [201, 203], [204, 213], [214, 217], [218, 223], [223, 224], [224, 225]]}
{"doc_key": "ai-dev-197", "ner": [[2, 4, "field"], [7, 8, "task"], [10, 12, "task"], [14, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 2, 4, "part-of", "task_part_of_field", false, false], [10, 12, 2, 4, "part-of", "task_part_of_field", false, false], [14, 16, 2, 4, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Challenges", "in", "natural", "language", "processing", "often", "involve", "speech", "recognition", ",", "natural", "language", "understanding", "and", "natural", "language", "generation", "."], "sentence-detokenized": "Challenges in natural language processing often involve speech recognition, natural language understanding and natural language generation.", "token2charspan": [[0, 10], [11, 13], [14, 21], [22, 30], [31, 41], [42, 47], [48, 55], [56, 62], [63, 74], [74, 75], [76, 83], [84, 92], [93, 106], [107, 110], [111, 118], [119, 127], [128, 138], [138, 139]]}
{"doc_key": "ai-dev-198", "ner": [[5, 5, "product"], [8, 10, "product"], [40, 41, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 8, 10, "part-of", "", false, false], [5, 5, 40, 41, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "such", "as", "Siri", "of", "the", "iOS", "operating", "system", ",", "work", "on", "the", "basis", "of", "a", "similar", "pattern", "recognition", "technique", "to", "that", "of", "text", "-", "based", "systems", ",", "but", "in", "the", "former", ",", "user", "input", "takes", "place", "through", "voice", "recognition", "."], "sentence-detokenized": "These systems, such as Siri of the iOS operating system, work on the basis of a similar pattern recognition technique to that of text-based systems, but in the former, user input takes place through voice recognition.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 27], [28, 30], [31, 34], [35, 38], [39, 48], [49, 55], [55, 56], [57, 61], [62, 64], [65, 68], [69, 74], [75, 77], [78, 79], [80, 87], [88, 95], [96, 107], [108, 117], [118, 120], [121, 125], [126, 128], [129, 133], [133, 134], [134, 139], [140, 147], [147, 148], [149, 152], [153, 155], [156, 159], [160, 166], [166, 167], [168, 172], [173, 178], [179, 184], [185, 190], [191, 198], [199, 204], [205, 216], [216, 217]]}
{"doc_key": "ai-dev-199", "ner": [[1, 3, "algorithm"], [16, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 3, 16, 17, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["More", "exotic", "fitness", "functions", "that", "explore", "the", "granularity", "of", "the", "model", "include", "the", "area", "under", "the", "ROC", "curve", "and", "the", "rank", "."], "sentence-detokenized": "More exotic fitness functions that explore the granularity of the model include the area under the ROC curve and the rank.", "token2charspan": [[0, 4], [5, 11], [12, 19], [20, 29], [30, 34], [35, 42], [43, 46], [47, 58], [59, 61], [62, 65], [66, 71], [72, 79], [80, 83], [84, 88], [89, 94], [95, 98], [99, 102], [103, 108], [109, 112], [113, 116], [117, 121], [121, 122]]}
{"doc_key": "ai-dev-200", "ner": [[2, 3, "product"], [7, 10, "researcher"], [16, 18, "product"], [23, 26, "organisation"], [28, 28, "organisation"], [37, 41, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 7, 10, "origin", "", false, false], [7, 10, 23, 26, "role", "", false, false], [16, 18, 7, 10, "origin", "", false, false], [28, 28, 23, 26, "named", "", false, false], [37, 41, 23, 26, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "term", "Semantic", "Web", "was", "coined", "by", "Tim", "Berners", "-", "Lee", ",", "the", "inventor", "of", "the", "World", "Wide", "Web", "and", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "oversees", "the", "development", "of", "proposed", "standards", "for", "the", "Semantic", "Web", "."], "sentence-detokenized": "The term Semantic Web was coined by Tim Berners-Lee, the inventor of the World Wide Web and director of the World Wide Web Consortium (W3C), which oversees the development of proposed standards for the Semantic Web.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 25], [26, 32], [33, 35], [36, 39], [40, 47], [47, 48], [48, 51], [51, 52], [53, 56], [57, 65], [66, 68], [69, 72], [73, 78], [79, 83], [84, 87], [88, 91], [92, 100], [101, 103], [104, 107], [108, 113], [114, 118], [119, 122], [123, 133], [134, 135], [135, 138], [138, 139], [139, 140], [141, 146], [147, 155], [156, 159], [160, 171], [172, 174], [175, 183], [184, 193], [194, 197], [198, 201], [202, 210], [211, 214], [214, 215]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [9, 9, "task"], [16, 17, "product"], [19, 23, "product"], [25, 25, "product"], [28, 29, "product"], [36, 37, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 16, 17, "opposite", "", false, false], [0, 1, 19, 23, "opposite", "", false, false], [0, 1, 28, 29, "opposite", "", false, false], [0, 1, 36, 37, "part-of", "", false, false], [9, 9, 0, 1, "named", "", false, false], [25, 25, 19, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Machine", "translation", ",", "sometimes", "referred", "to", "by", "the", "abbreviation", "MT", "(", "not", "to", "be", "confused", "with", "computer-assisted", "translation", ",", "machine", "-", "assisted", "human", "translation", "(", "MAHT", ")", "or", "interactive", "translation", ")", ",", "is", "a", "subfield", "of", "computational", "linguistics", "that", "investigates", "the", "use", "of", "software", "to", "translate", "text", "or", "speech", "from", "one", "language", "into", "another", "."], "sentence-detokenized": "Machine translation, sometimes referred to by the abbreviation MT (not to be confused with computer-assisted translation, machine-assisted human translation (MAHT) or interactive translation), is a subfield of computational linguistics that investigates the use of software to translate text or speech from one language into another.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 30], [31, 39], [40, 42], [43, 45], [46, 49], [50, 62], [63, 65], [66, 67], [67, 70], [71, 73], [74, 76], [77, 85], [86, 90], [91, 108], [109, 120], [120, 121], [122, 129], [129, 130], [130, 138], [139, 144], [145, 156], [157, 158], [158, 162], [162, 163], [164, 166], [167, 178], [179, 190], [190, 191], [191, 192], [193, 195], [196, 197], [198, 206], [207, 209], [210, 223], [224, 235], [236, 240], [241, 253], [254, 257], [258, 261], [262, 264], [265, 273], [274, 276], [277, 286], [287, 291], [292, 294], [295, 301], [302, 306], [307, 310], [311, 319], [320, 324], [325, 332], [332, 333]]}
{"doc_key": "ai-dev-202", "ner": [[1, 3, "product"], [8, 8, "university"], [13, 14, "researcher"], [16, 17, "researcher"], [39, 41, "location"], [43, 43, "location"], [47, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 3, 13, 14, "artifact", "", false, false], [1, 3, 16, 17, "artifact", "", false, false], [13, 14, 8, 8, "physical", "", false, false], [13, 14, 8, 8, "role", "", false, false], [16, 17, 8, 8, "physical", "", false, false], [16, 17, 8, 8, "role", "", false, false], [39, 41, 43, 43, "physical", "", false, false], [47, 50, 39, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Early", "interlingual", "MT", "systems", "were", "also", "built", "at", "Stanford", "in", "the", "1970s", "by", "Roger", "Schank", "and", "Yorick", "Wilks", ";", "the", "former", "became", "the", "basis", "of", "a", "commercial", "money", "transfer", "system", ",", "and", "the", "latter", "'s", "code", "is", "preserved", "at", "The", "Computer", "Museum", "in", "Boston", "as", "the", "first", "interlingual", "machine", "translation", "system", "."], "sentence-detokenized": "Early interlingual MT systems were also built at Stanford in the 1970s by Roger Schank and Yorick Wilks; the former became the basis of a commercial money transfer system, and the latter's code is preserved at The Computer Museum in Boston as the first interlingual machine translation system.", "token2charspan": [[0, 5], [6, 18], [19, 21], [22, 29], [30, 34], [35, 39], [40, 45], [46, 48], [49, 57], [58, 60], [61, 64], [65, 70], [71, 73], [74, 79], [80, 86], [87, 90], [91, 97], [98, 103], [103, 104], [105, 108], [109, 115], [116, 122], [123, 126], [127, 132], [133, 135], [136, 137], [138, 148], [149, 154], [155, 163], [164, 170], [170, 171], [172, 175], [176, 179], [180, 186], [186, 188], [189, 193], [194, 196], [197, 206], [207, 209], [210, 213], [214, 222], [223, 229], [230, 232], [233, 239], [240, 242], [243, 246], [247, 252], [253, 265], [266, 273], [274, 285], [286, 292], [292, 293]]}
{"doc_key": "ai-dev-203", "ner": [[0, 0, "researcher"], [6, 10, "conference"], [12, 13, "conference"], [20, 25, "conference"], [27, 28, "conference"], [34, 39, "organisation"], [48, 48, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 6, 10, "role", "", false, false], [0, 0, 20, 25, "role", "", false, false], [0, 0, 34, 39, "role", "", false, false], [0, 0, 48, 48, "role", "", false, false], [12, 13, 6, 10, "named", "", false, false], [27, 28, 20, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sycara", "was", "programme", "chair", "of", "the", "second", "International", "Semantic", "Web", "Conference", "(", "ISWC", "2003", ")", ";", "general", "chair", "of", "the", "second", "International", "Conference", "on", "Autonomous", "Agents", "(", "Agents", "98", ")", ";", "chair", "of", "the", "steering", "committee", "of", "the", "Agents", "Conference", "(", "1999-2001", ")", ";", "scholarship", "chair", "of", "the", "AAAI", "(", "1993-1999", ")", ";"], "sentence-detokenized": "Sycara was programme chair of the second International Semantic Web Conference (ISWC 2003); general chair of the second International Conference on Autonomous Agents (Agents 98); chair of the steering committee of the Agents Conference (1999-2001); scholarship chair of the AAAI (1993-1999);", "token2charspan": [[0, 6], [7, 10], [11, 20], [21, 26], [27, 29], [30, 33], [34, 40], [41, 54], [55, 63], [64, 67], [68, 78], [79, 80], [80, 84], [85, 89], [89, 90], [90, 91], [92, 99], [100, 105], [106, 108], [109, 112], [113, 119], [120, 133], [134, 144], [145, 147], [148, 158], [159, 165], [166, 167], [167, 173], [174, 176], [176, 177], [177, 178], [179, 184], [185, 187], [188, 191], [192, 200], [201, 210], [211, 213], [214, 217], [218, 224], [225, 235], [236, 237], [237, 246], [246, 247], [247, 248], [249, 260], [261, 266], [267, 269], [270, 273], [274, 278], [279, 280], [280, 289], [289, 290], [290, 291]]}
{"doc_key": "ai-dev-204", "ner": [[8, 8, "conference"], [10, 13, "conference"], [15, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 13, 8, 8, "named", "", false, false], [15, 17, 8, 8, "part-of", "", false, false], [15, 17, 8, 8, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2016", ",", "she", "was", "chosen", "as", "the", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "Lifetime", "Achievement", "Award", "winner", "."], "sentence-detokenized": "In 2016, she was chosen as the ACL (Association for Computational Linguistics) Lifetime Achievement Award winner.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 23], [24, 26], [27, 30], [31, 34], [35, 36], [36, 47], [48, 51], [52, 65], [66, 77], [77, 78], [79, 87], [88, 99], [100, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 8, "researcher"], [11, 12, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P.", "Frasconi", ",", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi, and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 30], [31, 39], [39, 40], [41, 44], [45, 51], [52, 63], [63, 64]]}
{"doc_key": "ai-dev-206", "ner": [[3, 3, "product"], [6, 7, "misc"], [9, 9, "programlang"], [19, 20, "product"], [38, 38, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 9, 9, "usage", "", false, false], [9, 9, 6, 7, "type-of", "", false, false], [9, 9, 19, 20, "related-to", "", false, false], [38, 38, 3, 3, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["For", "instance", ",", "A.L.I.C.E.", "uses", "a", "markup", "language", "called", "AIML", ",", "which", "is", "specific", "to", "its", "function", "as", "a", "dialogue", "system", ",", "and", "which", "has", "since", "been", "adopted", "by", "several", "other", "developers", "of", ",", "so", "-", "called", ",", "Alicebots", "."], "sentence-detokenized": "For instance, A.L.I.C.E. uses a markup language called AIML, which is specific to its function as a dialogue system, and which has since been adopted by several other developers of, so-called, Alicebots.", "token2charspan": [[0, 3], [4, 12], [12, 13], [14, 24], [25, 29], [30, 31], [32, 38], [39, 47], [48, 54], [55, 59], [59, 60], [61, 66], [67, 69], [70, 78], [79, 81], [82, 85], [86, 94], [95, 97], [98, 99], [100, 108], [109, 115], [115, 116], [117, 120], [121, 126], [127, 130], [131, 136], [137, 141], [142, 149], [150, 152], [153, 160], [161, 166], [167, 177], [178, 180], [180, 181], [182, 184], [184, 185], [185, 191], [191, 192], [193, 202], [202, 203]]}
{"doc_key": "ai-dev-207", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2000", ",", "she", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2000, she was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 24], [25, 26], [27, 33], [34, 36], [37, 40], [41, 52], [53, 56], [57, 60], [61, 72], [73, 75], [76, 86], [87, 99], [99, 100]]}
{"doc_key": "ai-dev-208", "ner": [[0, 2, "misc"], [4, 4, "misc"], [10, 15, "misc"], [24, 25, "algorithm"], [34, 35, "field"], [37, 38, "field"], [41, 42, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 10, 15, "type-of", "", false, false], [0, 2, 34, 35, "related-to", "performs", true, false], [0, 2, 37, 38, "related-to", "performs", true, false], [0, 2, 41, 42, "related-to", "performs", true, false], [4, 4, 0, 2, "named", "", false, false], [24, 25, 10, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Learning", "classification", "systems", "(", "LCS", ")", "are", "a", "family", "of", "rule", "-", "based", "machine", "learning", "algorithms", "that", "combine", "a", "discovery", "component", ",", "usually", "a", "genetic", "algorithm", ",", "with", "a", "learning", "component", ",", "applying", "either", "supervised", "learning", ",", "reinforcement", "learning", ",", "or", "unsupervised", "learning", "."], "sentence-detokenized": "Learning classification systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, usually a genetic algorithm, with a learning component, applying either supervised learning, reinforcement learning, or unsupervised learning.", "token2charspan": [[0, 8], [9, 23], [24, 31], [32, 33], [33, 36], [36, 37], [38, 41], [42, 43], [44, 50], [51, 53], [54, 58], [58, 59], [59, 64], [65, 72], [73, 81], [82, 92], [93, 97], [98, 105], [106, 107], [108, 117], [118, 127], [127, 128], [129, 136], [137, 138], [139, 146], [147, 156], [156, 157], [158, 162], [163, 164], [165, 173], [174, 183], [183, 184], [185, 193], [194, 200], [201, 211], [212, 220], [220, 221], [222, 235], [236, 244], [244, 245], [246, 248], [249, 261], [262, 270], [270, 271]]}
{"doc_key": "ai-dev-209", "ner": [[14, 16, "algorithm"], [18, 18, "algorithm"], [27, 28, "algorithm"], [30, 30, "misc"], [41, 43, "algorithm"], [51, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 16, 27, 28, "origin", "", false, false], [14, 16, 30, 30, "usage", "", false, false], [18, 18, 14, 16, "named", "", false, false], [41, 43, 30, 30, "type-of", "", false, false], [41, 43, 51, 54, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "unknown", "parameters", "in", "each", "vector", "\u03b2subk", "/", "sub", "are", "usually", "estimated", "jointly", "by", "maximum", "a", "posteriori", "(", "MAP", ")", "estimation", ",", "which", "is", "an", "extension", "of", "maximum", "likelihood", "with", "regularisation", "of", "the", "weights", "to", "avoid", "pathological", "solutions", "(", "usually", "a", "quadratic", "regularising", "function", ",", "which", "is", "equivalent", "to", "placing", "a", "zero-mean", "Gaussian", "priority", "distribution", "on", "the", "weights", ",", "but", "other", "distributions", "are", "also", "possible", ")", "."], "sentence-detokenized": "The unknown parameters in each vector \u03b2subk/sub are usually estimated jointly by maximum a posteriori (MAP) estimation, which is an extension of maximum likelihood with regularisation of the weights to avoid pathological solutions (usually a quadratic regularising function, which is equivalent to placing a zero-mean Gaussian priority distribution on the weights, but other distributions are also possible).", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 30], [31, 37], [38, 43], [43, 44], [44, 47], [48, 51], [52, 59], [60, 69], [70, 77], [78, 80], [81, 88], [89, 90], [91, 101], [102, 103], [103, 106], [106, 107], [108, 118], [118, 119], [120, 125], [126, 128], [129, 131], [132, 141], [142, 144], [145, 152], [153, 163], [164, 168], [169, 183], [184, 186], [187, 190], [191, 198], [199, 201], [202, 207], [208, 220], [221, 230], [231, 232], [232, 239], [240, 241], [242, 251], [252, 264], [265, 273], [273, 274], [275, 280], [281, 283], [284, 294], [295, 297], [298, 305], [306, 307], [308, 317], [318, 326], [327, 335], [336, 348], [349, 351], [352, 355], [356, 363], [363, 364], [365, 368], [369, 374], [375, 388], [389, 392], [393, 397], [398, 406], [406, 407], [407, 408]]}
{"doc_key": "ai-dev-210", "ner": [[9, 10, "researcher"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 9, 10, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "hierarchical", "structure", "of", "words", "is", "explicitly", "mapped", "in", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "The hierarchical structure of words is explicitly mapped in George Miller's Wordnet.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 29], [30, 35], [36, 38], [39, 49], [50, 56], [57, 59], [60, 66], [67, 73], [73, 75], [76, 83], [83, 84]]}
{"doc_key": "ai-dev-211", "ner": [[9, 14, "conference"], [21, 24, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 24, 9, 14, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "illustration", "of", "their", "capabilities", "is", "provided", "by", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", ";", "this", "is", "a", "benchmark", "in", "object", "classification", "and", "detection", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "An illustration of their capabilities is provided by the ImageNet Large Scale Visual Recognition Challenge; this is a benchmark in object classification and detection, with millions of images and hundreds of object classes.", "token2charspan": [[0, 2], [3, 15], [16, 18], [19, 24], [25, 37], [38, 40], [41, 49], [50, 52], [53, 56], [57, 65], [66, 71], [72, 77], [78, 84], [85, 96], [97, 106], [106, 107], [108, 112], [113, 115], [116, 117], [118, 127], [128, 130], [131, 137], [138, 152], [153, 156], [157, 166], [166, 167], [168, 172], [173, 181], [182, 184], [185, 191], [192, 195], [196, 204], [205, 207], [208, 214], [215, 222], [222, 223]]}
{"doc_key": "ai-dev-212", "ner": [[1, 6, "misc"], [20, 20, "misc"], [22, 24, "person"], [27, 27, "misc"], [33, 35, "person"], [38, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 20, 1, 6, "general-affiliation", "", false, false], [27, 27, 1, 6, "general-affiliation", "", false, false], [27, 27, 22, 24, "artifact", "", false, false], [38, 40, 1, 6, "general-affiliation", "", false, false], [38, 40, 33, 35, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "science", "fiction", ",", "female", "robots", "are", "often", "produced", "as", "domestic", "servants", "and", "sexual", "slaves", ",", "as", "in", "the", "film", "Westworld", ",", "Paul", "J.", "McAuley", "'s", "novel", "Fairyland", "(", "1995", ")", ",", "and", "Lester", "del", "Rey's", "short", "story", "Helen", "O'", "Loy", "(", "1938", ")", ",", "and", "sometimes", "as", "warriors", ",", "assassins", "or", "workers", "."], "sentence-detokenized": "In science fiction, female robots are often produced as domestic servants and sexual slaves, as in the film Westworld, Paul J. McAuley's novel Fairyland (1995), and Lester del Rey's short story Helen O'Loy (1938), and sometimes as warriors, assassins or workers.", "token2charspan": [[0, 2], [3, 10], [11, 18], [18, 19], [20, 26], [27, 33], [34, 37], [38, 43], [44, 52], [53, 55], [56, 64], [65, 73], [74, 77], [78, 84], [85, 91], [91, 92], [93, 95], [96, 98], [99, 102], [103, 107], [108, 117], [117, 118], [119, 123], [124, 126], [127, 134], [134, 136], [137, 142], [143, 152], [153, 154], [154, 158], [158, 159], [159, 160], [161, 164], [165, 171], [172, 175], [176, 181], [182, 187], [188, 193], [194, 199], [200, 202], [202, 205], [206, 207], [207, 211], [211, 212], [212, 213], [214, 217], [218, 227], [228, 230], [231, 239], [239, 240], [241, 250], [251, 253], [254, 261], [261, 262]]}
{"doc_key": "ai-dev-213", "ner": [[0, 1, "task"], [3, 4, "task"], [7, 8, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["answering", "questions", ",", "voice", "recognition", ",", "and", "automatic", "translation", "."], "sentence-detokenized": "answering questions, voice recognition, and automatic translation.", "token2charspan": [[0, 9], [10, 19], [19, 20], [21, 26], [27, 38], [38, 39], [40, 43], [44, 53], [54, 65], [65, 66]]}
{"doc_key": "ai-dev-214", "ner": [[5, 6, "researcher"], [9, 13, "organisation"], [15, 18, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 9, 13, "role", "", false, false], [9, 13, 15, 18, "physical", "", false, false], [15, 18, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "seminal", "paper", ",", "Harry", "Blum", "of", "the", "Air", "Force", "Cambridge", "Research", "Laboratories", "at", "Hanscom", "Air", "Force", "Base", "in", "Bedford", ",", "Massachusetts", ",", "defined", "a", "medial", "axis", "for", "calculating", "a", "skeleton", "of", "a", "shape", ",", "using", "an", "intuitive", "model", "of", "fire", "propagation", "on", "a", "grass", "field", ",", "where", "the", "field", "has", "the", "shape", "of", "the", "given", "shape", "."], "sentence-detokenized": "In his seminal paper, Harry Blum of the Air Force Cambridge Research Laboratories at Hanscom Air Force Base in Bedford, Massachusetts, defined a medial axis for calculating a skeleton of a shape, using an intuitive model of fire propagation on a grass field, where the field has the shape of the given shape.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 20], [20, 21], [22, 27], [28, 32], [33, 35], [36, 39], [40, 43], [44, 49], [50, 59], [60, 68], [69, 81], [82, 84], [85, 92], [93, 96], [97, 102], [103, 107], [108, 110], [111, 118], [118, 119], [120, 133], [133, 134], [135, 142], [143, 144], [145, 151], [152, 156], [157, 160], [161, 172], [173, 174], [175, 183], [184, 186], [187, 188], [189, 194], [194, 195], [196, 201], [202, 204], [205, 214], [215, 220], [221, 223], [224, 228], [229, 240], [241, 243], [244, 245], [246, 251], [252, 257], [257, 258], [259, 264], [265, 268], [269, 274], [275, 278], [279, 282], [283, 288], [289, 291], [292, 295], [296, 301], [302, 307], [307, 308]]}
{"doc_key": "ai-dev-215", "ner": [[14, 14, "algorithm"], [16, 16, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 19, 20, "compare", "", false, false], [16, 16, 19, 20, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "unlike", "boosting", "algorithms", "that", "analytically", "minimise", "a", "convex", "loss", "function", "(", "e.g.", "AdaBoost", "and", "LogitBoost", ")", ",", "Brown", "Boost", "solves", "a", "system", "of", "two", "equations", "and", "two", "unknowns", "using", "standard", "numerical", "methods", "."], "sentence-detokenized": "However, unlike boosting algorithms that analytically minimise a convex loss function (e.g. AdaBoost and LogitBoost), BrownBoost solves a system of two equations and two unknowns using standard numerical methods.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 24], [25, 35], [36, 40], [41, 53], [54, 62], [63, 64], [65, 71], [72, 76], [77, 85], [86, 87], [87, 91], [92, 100], [101, 104], [105, 115], [115, 116], [116, 117], [118, 123], [123, 128], [129, 135], [136, 137], [138, 144], [145, 147], [148, 151], [152, 161], [162, 165], [166, 169], [170, 178], [179, 184], [185, 193], [194, 203], [204, 211], [211, 212]]}
{"doc_key": "ai-dev-216", "ner": [[0, 0, "researcher"], [11, 13, "misc"], [18, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 11, 13, "win-defeat", "", false, false], [0, 0, 18, 24, "role", "", false, false], [26, 26, 18, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getoor", "has", "won", "multiple", "\"", "best", "paper", "\"", "awards", ",", "an", "NSF", "Career", "Award", ",", "and", "is", "an", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "Fellow", "."], "sentence-detokenized": "Getoor has won multiple \"best paper\" awards, an NSF Career Award, and is an Association for the Advancement of Artificial Intelligence (AAAI) Fellow.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 23], [24, 25], [25, 29], [30, 35], [35, 36], [37, 43], [43, 44], [45, 47], [48, 51], [52, 58], [59, 64], [64, 65], [66, 69], [70, 72], [73, 75], [76, 87], [88, 91], [92, 95], [96, 107], [108, 110], [111, 121], [122, 134], [135, 136], [136, 140], [140, 141], [142, 148], [148, 149]]}
{"doc_key": "ai-dev-217", "ner": [[0, 1, "misc"], [6, 10, "misc"], [15, 16, "misc"], [21, 25, "misc"], [30, 31, "misc"], [35, 39, "university"], [44, 52, "misc"], [57, 65, "misc"], [70, 74, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACM", "Fellow", "(", "2015", ")", "br", "Association", "for", "Computational", "Linguistics", "Fellow", "(", "2011", ")", "br", "AAAI", "Fellow", "(", "1994", ")", "br", "International", "Speech", "Communication", "Association", "Fellow", "(", "2011", ")", "br", "Honorary", "Doctorate", "(", "Hederdoktor", ")", "KTH", "Royal", "Institute", "of", "Technology", "(", "2007", ")", "br", "Columbia", "Engineering", "School", "Alumni", "Association", "Distinguished", "Faculty", "Teaching", "award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Speech", "and", "Audio", "Processing", "Award", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")"], "sentence-detokenized": "ACM Fellow (2015) br Association for Computational Linguistics Fellow (2011) br AAAI Fellow (1994) br International Speech Communication Association Fellow (2011) br Honorary Doctorate (Hederdoktor) KTH Royal Institute of Technology (2007) br Columbia Engineering School Alumni Association Distinguished Faculty Teaching award (2009) br IEEE James L. Flanagan Speech and Audio Processing Award (2011) br ISCA Medal for Scientific Achievement (2011)", "token2charspan": [[0, 3], [4, 10], [11, 12], [12, 16], [16, 17], [18, 20], [21, 32], [33, 36], [37, 50], [51, 62], [63, 69], [70, 71], [71, 75], [75, 76], [77, 79], [80, 84], [85, 91], [92, 93], [93, 97], [97, 98], [99, 101], [102, 115], [116, 122], [123, 136], [137, 148], [149, 155], [156, 157], [157, 161], [161, 162], [163, 165], [166, 174], [175, 184], [185, 186], [186, 197], [197, 198], [199, 202], [203, 208], [209, 218], [219, 221], [222, 232], [233, 234], [234, 238], [238, 239], [240, 242], [243, 251], [252, 263], [264, 270], [271, 277], [278, 289], [290, 303], [304, 311], [312, 320], [321, 326], [327, 328], [328, 332], [332, 333], [334, 336], [337, 341], [342, 347], [348, 350], [351, 359], [360, 366], [367, 370], [371, 376], [377, 387], [388, 393], [394, 395], [395, 399], [399, 400], [401, 403], [404, 408], [409, 414], [415, 418], [419, 429], [430, 441], [442, 443], [443, 447], [447, 448]]}
{"doc_key": "ai-dev-218", "ner": [[6, 6, "university"], [15, 19, "task"], [23, 25, "metrics"], [39, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 25, 39, 41, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["A", "frustrating", "result", "of", "the", "same", "Stanford", "study", "(", "and", "of", "other", "attempts", "to", "improve", "the", "translation", "of", "name", "recognisations", ")", "is", "that", "bilingual", "evaluation", "understudies", "'", "translation", "scores", "will", "often", "drop", "as", "a", "result", "of", "the", "inclusion", "of", "name", "entity", "translation", "methods", "."], "sentence-detokenized": "A frustrating result of the same Stanford study (and of other attempts to improve the translation of name recognisations) is that bilingual evaluation understudies' translation scores will often drop as a result of the inclusion of name entity translation methods.", "token2charspan": [[0, 1], [2, 13], [14, 20], [21, 23], [24, 27], [28, 32], [33, 41], [42, 47], [48, 49], [49, 52], [53, 55], [56, 61], [62, 70], [71, 73], [74, 81], [82, 85], [86, 97], [98, 100], [101, 105], [106, 120], [120, 121], [122, 124], [125, 129], [130, 139], [140, 150], [151, 163], [163, 164], [165, 176], [177, 183], [184, 188], [189, 194], [195, 199], [200, 202], [203, 204], [205, 211], [212, 214], [215, 218], [219, 228], [229, 231], [232, 236], [237, 243], [244, 255], [256, 263], [263, 264]]}
{"doc_key": "ai-dev-219", "ner": [[6, 7, "organisation"], [12, 14, "organisation"], [16, 21, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 12, 14, "role", "works_with", false, false], [6, 7, 16, 21, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Using", "the", "PM", "data", "collected", ",", "Medtronic", "is", "working", "with", "researchers", "at", "Johns", "Hopkins", "Hospital", "and", "Washington", "University", "School", "of", "Medicine", "to", "help", "answer", "specific", "questions", "about", "heart", "disease", ",", "such", "as", "whether", "a", "weak", "heart", "causes", "arrhythmias", "or", "vice", "versa", "."], "sentence-detokenized": "Using the PM data collected, Medtronic is working with researchers at Johns Hopkins Hospital and Washington University School of Medicine to help answer specific questions about heart disease, such as whether a weak heart causes arrhythmias or vice versa.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 17], [18, 27], [27, 28], [29, 38], [39, 41], [42, 49], [50, 54], [55, 66], [67, 69], [70, 75], [76, 83], [84, 92], [93, 96], [97, 107], [108, 118], [119, 125], [126, 128], [129, 137], [138, 140], [141, 145], [146, 152], [153, 161], [162, 171], [172, 177], [178, 183], [184, 191], [191, 192], [193, 197], [198, 200], [201, 208], [209, 210], [211, 215], [216, 221], [222, 228], [229, 240], [241, 243], [244, 248], [249, 254], [254, 255]]}
{"doc_key": "ai-dev-220", "ner": [[2, 2, "organisation"], [8, 8, "misc"], [10, 11, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 2, 2, "artifact", "made_by_studio", false, false], [10, 11, 8, 8, "role", "", false, false], [13, 14, 8, 8, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Then", "came", "Paramount", "'s", "first", "feature", "film", ",", "Sangaree", "starring", "Fernando", "Lamas", "and", "Arlene", "Dahl", "."], "sentence-detokenized": "Then came Paramount's first feature film, Sangaree starring Fernando Lamas and Arlene Dahl.", "token2charspan": [[0, 4], [5, 9], [10, 19], [19, 21], [22, 27], [28, 35], [36, 40], [40, 41], [42, 50], [51, 59], [60, 68], [69, 74], [75, 78], [79, 85], [86, 90], [90, 91]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [8, 10, "researcher"], [12, 13, "researcher"], [18, 19, "organisation"], [16, 22, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 10, "origin", "", false, false], [0, 0, 12, 13, "origin", "", false, false], [8, 10, 18, 19, "physical", "", false, false], [8, 10, 18, 19, "role", "", false, false], [12, 13, 16, 22, "physical", "", false, false], [12, 13, 16, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "is", "a", "knowledge", "representation", "language", "developed", "by", "Daniel", "G.", "Bobrow", "and", "Terry", "Winograd", "when", "they", "worked", "at", "Xerox", "PARC", "and", "Stanford", "University", ",", "respectively", "."], "sentence-detokenized": "KRL is a knowledge representation language developed by Daniel G. Bobrow and Terry Winograd when they worked at Xerox PARC and Stanford University, respectively.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 18], [19, 33], [34, 42], [43, 52], [53, 55], [56, 62], [63, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 96], [97, 101], [102, 108], [109, 111], [112, 117], [118, 122], [123, 126], [127, 135], [136, 146], [146, 147], [148, 160], [160, 161]]}
{"doc_key": "ai-dev-222", "ner": [[3, 10, "conference"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [22, 25, "researcher"], [33, 34, "task"], [36, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 10, 33, 34, "topic", "", true, false], [12, 13, 3, 10, "physical", "", false, false], [12, 13, 3, 10, "role", "", false, false], [12, 13, 3, 10, "temporal", "", false, false], [15, 16, 3, 10, "physical", "", false, false], [15, 16, 3, 10, "role", "", false, false], [15, 16, 3, 10, "temporal", "", false, false], [18, 19, 3, 10, "physical", "", false, false], [18, 19, 3, 10, "role", "", false, false], [18, 19, 3, 10, "temporal", "", false, false], [22, 25, 3, 10, "physical", "", false, false], [22, 25, 3, 10, "role", "", false, false], [22, 25, 3, 10, "temporal", "", false, false], [33, 34, 36, 38, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["At", "the", "2006", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", ",", "and", "Kwang", "-", "Ting", "Cheng", "presented", "an", "algorithm", "to", "significantly", "speed", "up", "human", "detection", "using", "HOG", "descriptor", "methods", "."], "sentence-detokenized": "At the 2006 IEEE Conference on Computer Vision and Pattern Recognition, Qiang Zhu, Shai Avidan, Mei-Chen Yeh, and Kwang-Ting Cheng presented an algorithm to significantly speed up human detection using HOG descriptor methods.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 27], [28, 30], [31, 39], [40, 46], [47, 50], [51, 58], [59, 70], [70, 71], [72, 77], [78, 81], [81, 82], [83, 87], [88, 94], [94, 95], [96, 104], [105, 108], [108, 109], [110, 113], [114, 119], [119, 120], [120, 124], [125, 130], [131, 140], [141, 143], [144, 153], [154, 156], [157, 170], [171, 176], [177, 179], [180, 185], [186, 195], [196, 201], [202, 205], [206, 216], [217, 224], [224, 225]]}
{"doc_key": "ai-dev-223", "ner": [[0, 0, "researcher"], [6, 6, "conference"], [10, 12, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 6, "role", "", false, false], [0, 0, 10, 12, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "is", "a", "charter", "Fellow", "of", "AAAI", "and", "of", "the", "Cognitive", "Science", "Society"], "sentence-detokenized": "Hayes is a charter Fellow of AAAI and of the Cognitive Science Society", "token2charspan": [[0, 5], [6, 8], [9, 10], [11, 18], [19, 25], [26, 28], [29, 33], [34, 37], [38, 40], [41, 44], [45, 54], [55, 62], [63, 70]]}
{"doc_key": "ai-dev-224", "ner": [[0, 1, "misc"], [5, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 34, "field"], [40, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 1, 5, 5, "part-of", "", false, false], [0, 1, 5, 5, "usage", "", false, false], [0, 1, 7, 8, "part-of", "", false, false], [0, 1, 7, 8, "usage", "", false, false], [0, 1, 10, 11, "part-of", "", false, false], [0, 1, 10, 11, "usage", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [0, 1, 13, 13, "usage", "", false, false], [0, 1, 15, 16, "part-of", "", false, false], [0, 1, 15, 16, "usage", "", false, false], [0, 1, 18, 19, "part-of", "", false, false], [0, 1, 18, 19, "usage", "", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 21, 22, "usage", "", false, false], [0, 1, 24, 24, "part-of", "", false, false], [0, 1, 24, 24, "usage", "", false, false], [0, 1, 26, 27, "part-of", "", false, false], [0, 1, 26, 27, "usage", "", false, false], [0, 1, 29, 29, "part-of", "", false, false], [0, 1, 29, 29, "usage", "", false, false], [0, 1, 31, 34, "part-of", "", false, false], [0, 1, 31, 34, "usage", "", false, false], [0, 1, 40, 41, "part-of", "", false, false], [0, 1, 40, 41, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", ",", "and", "largely", "in", "any", "field", "of", "applied", "science", "and", "engineering", "involving", "measurements", "in", "time", "."], "sentence-detokenized": "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering, and largely in any field of applied science and engineering involving measurements in time.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 23], [24, 34], [34, 35], [36, 42], [43, 53], [53, 54], [55, 62], [63, 74], [74, 75], [76, 88], [88, 89], [90, 102], [103, 110], [110, 111], [112, 119], [120, 131], [131, 132], [133, 143], [144, 154], [154, 155], [156, 178], [178, 179], [180, 187], [188, 199], [199, 200], [201, 210], [210, 211], [212, 226], [227, 238], [238, 239], [240, 243], [244, 251], [252, 254], [255, 258], [259, 264], [265, 267], [268, 275], [276, 283], [284, 287], [288, 299], [300, 309], [310, 322], [323, 325], [326, 330], [330, 331]]}
{"doc_key": "ai-dev-225", "ner": [[13, 14, "metrics"], [35, 37, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "principle", ",", "exact", "recovery", "in", "the", "feasible", "range", "can", "be", "solved", "using", "maximum", "likelihood", ",", "but", "this", "amounts", "to", "solving", "a", "constrained", "or", "regularised", "cutting", "problem", "such", "as", "minimum", "bisection", ",", "which", "is", "usually", "NP", "-", "complete", "."], "sentence-detokenized": "In principle, exact recovery in the feasible range can be solved using maximum likelihood, but this amounts to solving a constrained or regularised cutting problem such as minimum bisection, which is usually NP-complete.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 19], [20, 28], [29, 31], [32, 35], [36, 44], [45, 50], [51, 54], [55, 57], [58, 64], [65, 70], [71, 78], [79, 89], [89, 90], [91, 94], [95, 99], [100, 107], [108, 110], [111, 118], [119, 120], [121, 132], [133, 135], [136, 147], [148, 155], [156, 163], [164, 168], [169, 171], [172, 179], [180, 189], [189, 190], [191, 196], [197, 199], [200, 207], [208, 210], [210, 211], [211, 219], [219, 220]]}
{"doc_key": "ai-dev-226", "ner": [[2, 3, "task"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 2, 3, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["in", "their", "pedestrian", "detection", "work", ",", "which", "was", "first", "described", "at", "the", "BMVC", "in", "2009", "."], "sentence-detokenized": "in their pedestrian detection work, which was first described at the BMVC in 2009.", "token2charspan": [[0, 2], [3, 8], [9, 19], [20, 29], [30, 34], [34, 35], [36, 41], [42, 45], [46, 51], [52, 61], [62, 64], [65, 68], [69, 73], [74, 76], [77, 81], [81, 82]]}
{"doc_key": "ai-dev-227", "ner": [[17, 21, "conference"], [3, 3, "researcher"], [7, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 17, 21, "physical", "", false, false], [3, 3, 17, 21, "role", "", false, false], [3, 3, 7, 14, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2007", ",", "Terzopoulos", "was", "awarded", "the", "inaugural", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "at", "the", "International", "Conference", "on", "Computer", "Vision", "for", "pioneering", "and", "sustained", "research", "on", "deformable", "models", "and", "their", "applications", "."], "sentence-detokenized": "In 2007, Terzopoulos was awarded the inaugural IEEE PAMI Computer Vision Distinguished Researcher Award at the International Conference on Computer Vision for pioneering and sustained research on deformable models and their applications.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 24], [25, 32], [33, 36], [37, 46], [47, 51], [52, 56], [57, 65], [66, 72], [73, 86], [87, 97], [98, 103], [104, 106], [107, 110], [111, 124], [125, 135], [136, 138], [139, 147], [148, 154], [155, 158], [159, 169], [170, 173], [174, 183], [184, 192], [193, 195], [196, 206], [207, 213], [214, 217], [218, 223], [224, 236], [236, 237]]}
{"doc_key": "ai-dev-228", "ner": [[0, 1, "task"], [3, 6, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 3, 6, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cluster", "analysis", "or", "cluster", "analysis", "involves", "assigning", "data", "points", "to", "clusters", "such", "that", "items", "in", "the", "same", "cluster", "match", "as", "much", "as", "possible", ",", "while", "items", "belonging", "to", "different", "clusters", "differ", "as", "much", "as", "possible", "."], "sentence-detokenized": "Cluster analysis or cluster analysis involves assigning data points to clusters such that items in the same cluster match as much as possible, while items belonging to different clusters differ as much as possible.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 36], [37, 45], [46, 55], [56, 60], [61, 67], [68, 70], [71, 79], [80, 84], [85, 89], [90, 95], [96, 98], [99, 102], [103, 107], [108, 115], [116, 121], [122, 124], [125, 129], [130, 132], [133, 141], [141, 142], [143, 148], [149, 154], [155, 164], [165, 167], [168, 177], [178, 186], [187, 193], [194, 196], [197, 201], [202, 204], [205, 213], [213, 214]]}
{"doc_key": "ai-dev-229", "ner": [[6, 12, "field"], [15, 16, "field"], [18, 19, "task"], [21, 22, "field"], [24, 26, "field"], [28, 29, "field"], [31, 32, "field"], [34, 35, "task"], [37, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 12, 15, 16, "named", "", false, false], [6, 12, 21, 22, "named", "", false, false], [6, 12, 28, 29, "named", "", false, false], [18, 19, 15, 16, "part-of", "task_part_of_field", false, false], [24, 26, 21, 22, "part-of", "", false, false], [31, 32, 28, 29, "part-of", "", false, false], [34, 35, 31, 32, "part-of", "", false, false], [37, 37, 31, 32, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["(", "2005", ")", ",", "we", "can", "distinguish", "three", "different", "perspectives", "on", "text", "mining", ",", "namely", "text", "mining", "as", "information", "extraction", ",", "text", "mining", "as", "text", "data", "mining", "and", "text", "mining", "as", "data", "mining", "(", "Knowledge", "Discovery", "in", "Databases", ")", ".", "Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005), we can distinguish three different perspectives on text mining, namely text mining as information extraction, text mining as text data mining and text mining as data mining (Knowledge Discovery in Databases).Hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [6, 7], [8, 10], [11, 14], [15, 26], [27, 32], [33, 42], [43, 55], [56, 58], [59, 63], [64, 70], [70, 71], [72, 78], [79, 83], [84, 90], [91, 93], [94, 105], [106, 116], [116, 117], [118, 122], [123, 129], [130, 132], [133, 137], [138, 142], [143, 149], [150, 153], [154, 158], [159, 165], [166, 168], [169, 173], [174, 180], [181, 182], [182, 191], [192, 201], [202, 204], [205, 214], [214, 215], [215, 216], [216, 221], [221, 222], [223, 225], [225, 226], [227, 237], [237, 238], [239, 241], [242, 245], [246, 250], [250, 251], [252, 254], [255, 256], [256, 260], [260, 261], [261, 262]]}
{"doc_key": "ai-dev-230", "ner": [[1, 2, "product"], [15, 20, "location"], [22, 22, "location"], [24, 24, "location"], [34, 35, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 15, 20, "related-to", "developed_for", false, false], [15, 20, 22, 22, "physical", "", false, false], [22, 22, 24, 24, "physical", "", false, false], [34, 35, 1, 2, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Rancho", "Arm", "was", "developed", "as", "a", "robotic", "arm", "to", "help", "disabled", "patients", "at", "the", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Centre", "in", "Downey", ",", "California", ";", "this", "computer", "-", "controlled", "arm", "was", "purchased", "by", "Stanford", "University", "in", "1963", "."], "sentence-detokenized": "The Rancho Arm was developed as a robotic arm to help disabled patients at the Rancho Los Amigos National Rehabilitation Centre in Downey, California; this computer-controlled arm was purchased by Stanford University in 1963.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 18], [19, 28], [29, 31], [32, 33], [34, 41], [42, 45], [46, 48], [49, 53], [54, 62], [63, 71], [72, 74], [75, 78], [79, 85], [86, 89], [90, 96], [97, 105], [106, 120], [121, 127], [128, 130], [131, 137], [137, 138], [139, 149], [149, 150], [151, 155], [156, 164], [164, 165], [165, 175], [176, 179], [180, 183], [184, 193], [194, 196], [197, 205], [206, 216], [217, 219], [220, 224], [224, 225]]}
{"doc_key": "ai-dev-231", "ner": [[1, 1, "university"], [3, 3, "researcher"], [10, 14, "organisation"], [22, 24, "organisation"], [28, 29, "researcher"], [31, 33, "researcher"], [45, 45, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 1, 1, "physical", "", false, false], [3, 3, 1, 1, "role", "", false, false], [3, 3, 10, 14, "role", "founder", false, false], [3, 3, 22, 24, "role", "founder", false, false], [22, 24, 45, 45, "physical", "", false, false], [28, 29, 22, 24, "role", "founder", false, false], [31, 33, 22, 24, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["At", "UCSD", ",", "Norman", "was", "one", "of", "the", "founders", "of", "the", "Institute", "for", "Cognitive", "Science", "and", "one", "of", "the", "organisers", "of", "the", "Cognitive", "Science", "Society", "(", "along", "with", "Roger", "Schank", ",", "Allan", "M.", "Collins", ",", "and", "others", ")", ",", "which", "held", "its", "first", "meeting", "on", "UCSD", "'s", "campus", "in", "1979", "."], "sentence-detokenized": "At UCSD, Norman was one of the founders of the Institute for Cognitive Science and one of the organisers of the Cognitive Science Society (along with Roger Schank, Allan M. Collins, and others), which held its first meeting on UCSD's campus in 1979.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 23], [24, 26], [27, 30], [31, 39], [40, 42], [43, 46], [47, 56], [57, 60], [61, 70], [71, 78], [79, 82], [83, 86], [87, 89], [90, 93], [94, 104], [105, 107], [108, 111], [112, 121], [122, 129], [130, 137], [138, 139], [139, 144], [145, 149], [150, 155], [156, 162], [162, 163], [164, 169], [170, 172], [173, 180], [180, 181], [182, 185], [186, 192], [192, 193], [193, 194], [195, 200], [201, 205], [206, 209], [210, 215], [216, 223], [224, 226], [227, 231], [231, 233], [234, 240], [241, 243], [244, 248], [248, 249]]}
{"doc_key": "ai-dev-232", "ner": [[7, 8, "product"], [10, 11, "product"], [13, 14, "product"], [16, 18, "product"], [21, 22, "product"], [24, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[21, 22, 16, 18, "type-of", "", false, false], [24, 29, 16, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "commonly", "used", "robot", "configurations", "are", "articulated", "robots", ",", "SCARA", "robots", ",", "delta", "robots", "and", "cartesian", "coordinate", "robots", ",", "(", "portal", "robots", "or", "x", "-", "y", "-", "z", "robots", ")", "."], "sentence-detokenized": "The most commonly used robot configurations are articulated robots, SCARA robots, delta robots and cartesian coordinate robots, (portal robots or x-y-z robots).", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 28], [29, 43], [44, 47], [48, 59], [60, 66], [66, 67], [68, 73], [74, 80], [80, 81], [82, 87], [88, 94], [95, 98], [99, 108], [109, 119], [120, 126], [126, 127], [128, 129], [129, 135], [136, 142], [143, 145], [146, 147], [147, 148], [148, 149], [149, 150], [150, 151], [152, 158], [158, 159], [159, 160]]}
{"doc_key": "ai-dev-233", "ner": [[9, 9, "programlang"], [10, 11, "misc"], [16, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 9, 9, "part-of", "", false, false], [16, 16, 10, 11, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Alternatively", ",", "it", "can", "be", "used", "directly", "with", "the", "Perl", "Module", "TM", "(", "which", "also", "supports", "LTM", ")", "."], "sentence-detokenized": "Alternatively, it can be used directly with the Perl Module TM (which also supports LTM).", "token2charspan": [[0, 13], [13, 14], [15, 17], [18, 21], [22, 24], [25, 29], [30, 38], [39, 43], [44, 47], [48, 52], [53, 59], [60, 62], [63, 64], [64, 69], [70, 74], [75, 83], [84, 87], [87, 88], [88, 89]]}
{"doc_key": "ai-dev-234", "ner": [[5, 5, "country"], [8, 9, "organisation"], [17, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 5, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "was", "won", "by", "an", "American", "team", "from", "Newton", "Labs", ",", "and", "the", "competition", "was", "featured", "on", "CNN", "."], "sentence-detokenized": "This was won by an American team from Newton Labs, and the competition was featured on CNN.", "token2charspan": [[0, 4], [5, 8], [9, 12], [13, 15], [16, 18], [19, 27], [28, 32], [33, 37], [38, 44], [45, 49], [49, 50], [51, 54], [55, 58], [59, 70], [71, 74], [75, 83], [84, 86], [87, 90], [90, 91]]}
{"doc_key": "ai-dev-235", "ner": [[0, 4, "misc"], [11, 12, "person"], [15, 16, "person"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 0, 4, "role", "directs", false, false], [15, 16, 0, 4, "role", "acts_in", false, false], [18, 19, 0, 4, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Butler", "'s", "in", "Love", ",", "a", "short", "film", "directed", "by", "David", "Arquette", "and", "starring", "Elizabeth", "Berkley", "and", "Thomas", "Jane", ",", "was", "released", "on", "23", "June", "2008", "."], "sentence-detokenized": "The Butler's in Love, a short film directed by David Arquette and starring Elizabeth Berkley and Thomas Jane, was released on 23 June 2008.", "token2charspan": [[0, 3], [4, 10], [10, 12], [13, 15], [16, 20], [20, 21], [22, 23], [24, 29], [30, 34], [35, 43], [44, 46], [47, 52], [53, 61], [62, 65], [66, 74], [75, 84], [85, 92], [93, 96], [97, 103], [104, 108], [108, 109], [110, 113], [114, 122], [123, 125], [126, 128], [129, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-dev-236", "ner": [[0, 0, "product"], [10, 10, "field"], [17, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 17, 17, "general-affiliation", "", false, false], [10, 10, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "for", "example", ",", "is", "a", "resource", "with", "a", "taxonomy", ",", "whose", "elements", "are", "meanings", "of", "English", "words", "."], "sentence-detokenized": "WordNet, for example, is a resource with a taxonomy, whose elements are meanings of English words.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 20], [20, 21], [22, 24], [25, 26], [27, 35], [36, 40], [41, 42], [43, 51], [51, 52], [53, 58], [59, 67], [68, 71], [72, 80], [81, 83], [84, 91], [92, 97], [97, 98]]}
{"doc_key": "ai-dev-237", "ner": [[1, 3, "product"], [6, 6, "product"], [8, 8, "product"], [14, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 1, 3, "type-of", "", false, false], [6, 6, 14, 14, "related-to", "ability_to", false, false], [8, 8, 1, 3, "type-of", "", false, false], [8, 8, 14, 14, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Existing", "humanoid", "robotic", "systems", "such", "as", "ASIMO", "and", "QRIO", "use", "many", "motors", "to", "enable", "locomotion", "."], "sentence-detokenized": "Existing humanoid robotic systems such as ASIMO and QRIO use many motors to enable locomotion.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 33], [34, 38], [39, 41], [42, 47], [48, 51], [52, 56], [57, 60], [61, 65], [66, 72], [73, 75], [76, 82], [83, 93], [93, 94]]}
{"doc_key": "ai-dev-238", "ner": [[0, 0, "metrics"], [7, 8, "metrics"], [10, 10, "metrics"], [12, 16, "misc"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 0, 0, "part-of", "", false, false], [10, 10, 0, 0, "part-of", "", false, false], [12, 16, 0, 0, "part-of", "", false, false], [19, 19, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "is", "designed", "with", "the", "factors", "improved", "length", "penalty", ",", "precision", ",", "n-", "gram", "word", "order", "penalty", ",", "and", "recall", "."], "sentence-detokenized": "LEPOR is designed with the factors improved length penalty, precision, n-gram word order penalty, and recall.", "token2charspan": [[0, 5], [6, 8], [9, 17], [18, 22], [23, 26], [27, 34], [35, 43], [44, 50], [51, 58], [58, 59], [60, 69], [69, 70], [71, 73], [73, 77], [78, 82], [83, 88], [89, 96], [96, 97], [98, 101], [102, 108], [108, 109]]}
{"doc_key": "ai-dev-239", "ner": [[5, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "based", "on", "the", "metrics", "for", "bilingual", "assessment", "students", ",", "but", "with", "some", "modifications", "."], "sentence-detokenized": "It is based on the metrics for bilingual assessment students, but with some modifications.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 14], [15, 18], [19, 26], [27, 30], [31, 40], [41, 51], [52, 60], [60, 61], [62, 65], [66, 70], [71, 75], [76, 89], [89, 90]]}
{"doc_key": "ai-dev-240", "ner": [[6, 6, "product"], [8, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "sample", "implementation", "in", "MATLAB", "/", "Octave", ":"], "sentence-detokenized": "This is a sample implementation in MATLAB / Octave:", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 31], [32, 34], [35, 41], [42, 43], [44, 50], [50, 51]]}
{"doc_key": "ai-dev-241", "ner": [[14, 14, "programlang"], [16, 16, "programlang"], [18, 18, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "designed", "to", "be", "used", "using", "a", "number", "of", "computer", "languages", ",", "including", "Python", ",", "Ruby", "and", "Scheme", "."], "sentence-detokenized": "It is designed to be used using a number of computer languages, including Python, Ruby and Scheme.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 20], [21, 25], [26, 31], [32, 33], [34, 40], [41, 43], [44, 52], [53, 62], [62, 63], [64, 73], [74, 80], [80, 81], [82, 86], [87, 90], [91, 97], [97, 98]]}
{"doc_key": "ai-dev-242", "ner": [[0, 0, "researcher"], [6, 6, "organisation"], [13, 13, "conference"], [18, 19, "academicjournal"], [24, 26, "organisation"], [31, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 6, "role", "", false, false], [0, 0, 13, 13, "role", "", false, false], [0, 0, 18, 19, "role", "", false, false], [0, 0, 24, 26, "role", "", false, false], [0, 0, 31, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "has", "been", "secretary", "of", "the", "AISB", ",", "president", "and", "trustee", "of", "the", "IJCAI", ",", "associate", "editor", "of", "Artificial", "Intelligence", ",", "governor", "of", "the", "Cognitive", "Science", "Society", "and", "president", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes has been secretary of the AISB, president and trustee of the IJCAI, associate editor of Artificial Intelligence, governor of the Cognitive Science Society and president of the American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 24], [25, 27], [28, 31], [32, 36], [36, 37], [38, 47], [48, 51], [52, 59], [60, 62], [63, 66], [67, 72], [72, 73], [74, 83], [84, 90], [91, 93], [94, 104], [105, 117], [117, 118], [119, 127], [128, 130], [131, 134], [135, 144], [145, 152], [153, 160], [161, 164], [165, 174], [175, 177], [178, 181], [182, 190], [191, 202], [203, 206], [207, 217], [218, 230], [230, 231]]}
{"doc_key": "ai-dev-243", "ner": [[4, 14, "misc"], [16, 18, "misc"], [23, 25, "person"], [27, 31, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 25, 4, 14, "role", "directed_by", false, false], [23, 25, 16, 18, "role", "directed_by", false, false], [23, 25, 27, 31, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "of", "them", ",", "Now", "is", "the", "Time", "(", "to", "Put", "On", "Your", "Glasses", ")", "and", "Around", "is", "Around", ",", "were", "directed", "by", "Norman", "McLaren", "for", "the", "National", "Film", "Board", "of", "Canada", "in", "1951", "."], "sentence-detokenized": "Two of them, Now is the Time (to Put On Your Glasses) and Around is Around, were directed by Norman McLaren for the National Film Board of Canada in 1951.", "token2charspan": [[0, 3], [4, 6], [7, 11], [11, 12], [13, 16], [17, 19], [20, 23], [24, 28], [29, 30], [30, 32], [33, 36], [37, 39], [40, 44], [45, 52], [52, 53], [54, 57], [58, 64], [65, 67], [68, 74], [74, 75], [76, 80], [81, 89], [90, 92], [93, 99], [100, 107], [108, 111], [112, 115], [116, 124], [125, 129], [130, 135], [136, 138], [139, 145], [146, 148], [149, 153], [153, 154]]}
{"doc_key": "ai-dev-244", "ner": [[1, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "recommendation", "system", "aims", "to", "predict", "an", "intended", "user", "'s", "preference", "for", "an", "item", "."], "sentence-detokenized": "A recommendation system aims to predict an intended user's preference for an item.", "token2charspan": [[0, 1], [2, 16], [17, 23], [24, 28], [29, 31], [32, 39], [40, 42], [43, 51], [52, 56], [56, 58], [59, 69], [70, 73], [74, 76], [77, 81], [81, 82]]}
{"doc_key": "ai-dev-245", "ner": [[0, 0, "algorithm"], [4, 5, "field"], [7, 7, "field"], [9, 10, "field"], [12, 14, "field"], [16, 16, "field"], [18, 19, "field"], [21, 21, "field"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 5, "part-of", "", true, false], [0, 0, 7, 7, "part-of", "", true, false], [0, 0, 9, 10, "part-of", "", true, false], [0, 0, 12, 14, "part-of", "", true, false], [0, 0, 16, 16, "part-of", "", true, false], [0, 0, 18, 19, "part-of", "", true, false], [0, 0, 21, 21, "part-of", "", true, false], [0, 0, 23, 24, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Convolution", "has", "applications", "in", "probability", "theory", ",", "statistics", ",", "computer", "vision", ",", "natural", "language", "processing", ",", "image", "and", "signal", "processing", ",", "engineering", "and", "differential", "equations", "."], "sentence-detokenized": "Convolution has applications in probability theory, statistics, computer vision, natural language processing, image and signal processing, engineering and differential equations.", "token2charspan": [[0, 11], [12, 15], [16, 28], [29, 31], [32, 43], [44, 50], [50, 51], [52, 62], [62, 63], [64, 72], [73, 79], [79, 80], [81, 88], [89, 97], [98, 108], [108, 109], [110, 115], [116, 119], [120, 126], [127, 137], [137, 138], [139, 150], [151, 154], [155, 167], [168, 177], [177, 178]]}
{"doc_key": "ai-dev-246", "ner": [[2, 2, "field"], [4, 6, "task"], [8, 9, "task"], [11, 11, "task"], [12, 13, "task"], [15, 16, "task"], [18, 19, "task"], [21, 22, "task"], [24, 24, "task"], [27, 28, "task"], [30, 30, "field"], [32, 32, "field"], [34, 36, "field"], [38, 38, "field"], [40, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[2, 2, 4, 6, "part-of", "", true, false], [2, 2, 8, 9, "part-of", "", true, false], [2, 2, 11, 11, "part-of", "", true, false], [2, 2, 12, 13, "part-of", "", true, false], [2, 2, 15, 16, "part-of", "", true, false], [2, 2, 18, 19, "part-of", "", true, false], [2, 2, 21, 22, "part-of", "", true, false], [2, 2, 24, 24, "part-of", "", true, false], [2, 2, 27, 28, "part-of", "", true, false], [2, 2, 30, 30, "part-of", "", true, false], [2, 2, 32, 32, "part-of", "", true, false], [2, 2, 34, 36, "part-of", "", true, false], [2, 2, 38, 38, "part-of", "", true, false], [2, 2, 40, 40, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Applications", "of", "DSP", "include", "audio", "signal", "processing", ",", "audio", "compression", ",", "digital", "image", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communication", ",", "digital", "synthesisers", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", "and", "biomedicine", "."], "sentence-detokenized": "Applications of DSP include audio signal processing, audio compression, digital image processing, video compression, speech processing, speech recognition, digital communication, digital synthesisers, radar, sonar, financial signal processing, seismology and biomedicine.", "token2charspan": [[0, 12], [13, 15], [16, 19], [20, 27], [28, 33], [34, 40], [41, 51], [51, 52], [53, 58], [59, 70], [70, 71], [72, 79], [80, 85], [86, 96], [96, 97], [98, 103], [104, 115], [115, 116], [117, 123], [124, 134], [134, 135], [136, 142], [143, 154], [154, 155], [156, 163], [164, 177], [177, 178], [179, 186], [187, 199], [199, 200], [201, 206], [206, 207], [208, 213], [213, 214], [215, 224], [225, 231], [232, 242], [242, 243], [244, 254], [255, 258], [259, 270], [270, 271]]}
{"doc_key": "ai-dev-247", "ner": [[11, 12, "misc"], [19, 20, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "20", "February", "1912", "-", "11", "August", "2011", ")", "was", "an", "American", "inventor", ",", "best", "known", "for", "his", "invention", "of", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "(20 February 1912 - 11 August 2011) was an American inventor, best known for his invention of Unimate, the first industrial robot.", "token2charspan": [[0, 1], [1, 3], [4, 12], [13, 17], [18, 19], [20, 22], [23, 29], [30, 34], [34, 35], [36, 39], [40, 42], [43, 51], [52, 60], [60, 61], [62, 66], [67, 72], [73, 76], [77, 80], [81, 90], [91, 93], [94, 101], [101, 102], [103, 106], [107, 112], [113, 123], [124, 129], [129, 130]]}
{"doc_key": "ai-dev-248", "ner": [[2, 4, "researcher"], [6, 8, "researcher"], [10, 10, "researcher"], [22, 23, "algorithm"], [26, 28, "algorithm"], [32, 33, "task"], [37, 37, "algorithm"], [43, 44, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 22, 23, "related-to", "writes_about", true, false], [6, 8, 22, 23, "related-to", "writes_about", true, false], [10, 10, 22, 23, "related-to", "writes_about", true, false], [22, 23, 26, 28, "related-to", "", true, false], [32, 33, 37, 37, "related-to", "", true, false], [43, 44, 37, 37, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Along", "with", "David", "E.", "Rumelhart", "and", "Ronald", "J.", "Williams", ",", "Hinton", "co-authored", "a", "highly", "cited", "paper", "published", "in", "1986", "that", "popularised", "the", "backpropagation", "algorithm", "for", "training", "multilayer", "neural", "networks", ".", "The", "impressive", "image", "recognition", "milestone", "of", "the", "AlexNet", ",", "designed", "by", "his", "student", "Alex", "Krizhevsky", "{{", "cite", "web"], "sentence-detokenized": "Along with David E. Rumelhart and Ronald J. Williams, Hinton co-authored a highly cited paper published in 1986 that popularised the backpropagation algorithm for training multilayer neural networks. The impressive image recognition milestone of the AlexNet, designed by his student Alex Krizhevsky {{cite web", "token2charspan": [[0, 5], [6, 10], [11, 16], [17, 19], [20, 29], [30, 33], [34, 40], [41, 43], [44, 52], [52, 53], [54, 60], [61, 72], [73, 74], [75, 81], [82, 87], [88, 93], [94, 103], [104, 106], [107, 111], [112, 116], [117, 128], [129, 132], [133, 148], [149, 158], [159, 162], [163, 171], [172, 182], [183, 189], [190, 198], [198, 199], [200, 203], [204, 214], [215, 220], [221, 232], [233, 242], [243, 245], [246, 249], [250, 257], [257, 258], [259, 267], [268, 270], [271, 274], [275, 282], [283, 287], [288, 298], [299, 301], [301, 305], [306, 309]]}
{"doc_key": "ai-dev-249", "ner": [[8, 10, "metrics"], [12, 14, "metrics"], [16, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "predicted", "value", "is", "continuously", "distributed", ",", "mean-", "squared", "error", ",", "mean", "-squared", "error", "or", "median", "-", "absolute", "deviation", "can", "be", "used", "to", "summarise", "the", "errors", "."], "sentence-detokenized": "When the predicted value is continuously distributed, mean-squared error, mean-squared error or median-absolute deviation can be used to summarise the errors.", "token2charspan": [[0, 4], [5, 8], [9, 18], [19, 24], [25, 27], [28, 40], [41, 52], [52, 53], [54, 59], [59, 66], [67, 72], [72, 73], [74, 78], [78, 86], [87, 92], [93, 95], [96, 102], [102, 103], [103, 111], [112, 121], [122, 125], [126, 128], [129, 133], [134, 136], [137, 146], [147, 150], [151, 157], [157, 158]]}
{"doc_key": "ai-dev-250", "ner": [[0, 1, "algorithm"], [13, 14, "field"], [12, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 13, 14, "part-of", "", true, false], [0, 1, 12, 12, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Conceptual", "clustering", "developed", "mainly", "in", "the", "1980s", ",", "as", "a", "paradigm", "for", "unsupervised", "machine", "learning", "."], "sentence-detokenized": "Conceptual clustering developed mainly in the 1980s, as a paradigm for unsupervised machine learning.", "token2charspan": [[0, 10], [11, 21], [22, 31], [32, 38], [39, 41], [42, 45], [46, 51], [51, 52], [53, 55], [56, 57], [58, 66], [67, 70], [71, 83], [84, 91], [92, 100], [100, 101]]}
{"doc_key": "ai-dev-251", "ner": [[9, 10, "product"], [33, 34, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "named", "entities", "can", "not", "be", "recognised", "by", "the", "machine", "translator", ",", "they", "may", "be", "mistranslated", "as", "common", "nouns", ",", "which", "would", "most", "likely", "not", "affect", "the", "assessment", "of", "the", "translation", "by", "the", "bilingual", "evaluator", ",", "but", "would", "affect", "the", "readability", "of", "the", "text", "by", "humans", "."], "sentence-detokenized": "If named entities cannot be recognised by the machine translator, they may be mistranslated as common nouns, which would most likely not affect the assessment of the translation by the bilingual evaluator, but would affect the readability of the text by humans.", "token2charspan": [[0, 2], [3, 8], [9, 17], [18, 21], [21, 24], [25, 27], [28, 38], [39, 41], [42, 45], [46, 53], [54, 64], [64, 65], [66, 70], [71, 74], [75, 77], [78, 91], [92, 94], [95, 101], [102, 107], [107, 108], [109, 114], [115, 120], [121, 125], [126, 132], [133, 136], [137, 143], [144, 147], [148, 158], [159, 161], [162, 165], [166, 177], [178, 180], [181, 184], [185, 194], [195, 204], [204, 205], [206, 209], [210, 215], [216, 222], [223, 226], [227, 238], [239, 241], [242, 245], [246, 250], [251, 253], [254, 260], [260, 261]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 22, "location"], [24, 24, "country"], [38, 39, "researcher"], [45, 45, "researcher"], [49, 50, "university"], [54, 55, "researcher"], [57, 58, "researcher"], [61, 62, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 22, "physical", "", false, false], [20, 22, 24, 24, "physical", "", false, false], [45, 45, 49, 50, "physical", "", false, false], [45, 45, 49, 50, "role", "", false, false], [54, 55, 49, 50, "physical", "", false, false], [54, 55, 49, 50, "role", "", false, false], [57, 58, 49, 50, "physical", "", false, false], [57, 58, 49, 50, "role", "", false, false], [61, 62, 49, 50, "physical", "", false, false], [61, 62, 49, 50, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng", "-", "S\u00e4by", ",", "Sweden", ",", "pages", "1-", "3", "This", "model", ",", "partly", "influenced", "by", "the", "work", "of", "Sydney", "Lamb", ",", "was", "used", "extensively", "by", "Schank", "'s", "students", "at", "Yale", "University", ",", "such", "as", "Robert", "Wilensky", ",", "Wendy", "Lehnert", ",", "and", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, pages 1-3 This model, partly influenced by the work of Sydney Lamb, was used extensively by Schank's students at Yale University, such as Robert Wilensky, Wendy Lehnert, and Janet Kolodner.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 130], [130, 131], [131, 135], [135, 136], [137, 143], [143, 144], [145, 150], [151, 153], [153, 154], [155, 159], [160, 165], [165, 166], [167, 173], [174, 184], [185, 187], [188, 191], [192, 196], [197, 199], [200, 206], [207, 211], [211, 212], [213, 216], [217, 221], [222, 233], [234, 236], [237, 243], [243, 245], [246, 254], [255, 257], [258, 262], [263, 273], [273, 274], [275, 279], [280, 282], [283, 289], [290, 298], [298, 299], [300, 305], [306, 313], [313, 314], [315, 318], [319, 324], [325, 333], [333, 334]]}
{"doc_key": "ai-dev-253", "ner": [[2, 4, "algorithm"], [6, 6, "algorithm"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[6, 6, 2, 4, "named", "", false, false], [13, 14, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["The", "enhanced", "maximum", "likelihood", "method", "(", "IMLM", ")", "is", "a", "combination", "of", "two", "maximum", "likelihood", "(", "MLM", ")", "estimators", "."], "sentence-detokenized": "The enhanced maximum likelihood method (IMLM) is a combination of two maximum likelihood (MLM) estimators.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 38], [39, 40], [40, 44], [44, 45], [46, 48], [49, 50], [51, 62], [63, 65], [66, 69], [70, 77], [78, 88], [89, 90], [90, 93], [93, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-254", "ner": [[20, 21, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[24, 25, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "these", "methods", ",", "the", "output", "and", "utility", "of", "a", "programme", "can", "also", "be", "analysed", "and", ",", "consequently", ",", "the", "confusion", "matrix", "(", "or", "confusion", "table", ")", "can", "be", "analysed", "."], "sentence-detokenized": "In these methods, the output and utility of a programme can also be analysed and, consequently, the confusion matrix (or confusion table) can be analysed.", "token2charspan": [[0, 2], [3, 8], [9, 16], [16, 17], [18, 21], [22, 28], [29, 32], [33, 40], [41, 43], [44, 45], [46, 55], [56, 59], [60, 64], [65, 67], [68, 76], [77, 80], [80, 81], [82, 94], [94, 95], [96, 99], [100, 109], [110, 116], [117, 118], [118, 120], [121, 130], [131, 136], [136, 137], [138, 141], [142, 144], [145, 153], [153, 154]]}
{"doc_key": "ai-dev-255", "ner": [[0, 0, "product"], [5, 6, "researcher"], [8, 9, "researcher"], [12, 14, "researcher"], [20, 25, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 6, "origin", "", false, false], [0, 0, 8, 9, "origin", "", false, false], [0, 0, 12, 14, "origin", "", false, false], [0, 0, 20, 25, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "was", "first", "published", "by", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", ",", "and", "Luc", "Van", "Gool", ",", "and", "presented", "at", "the", "European", "Conference", "on", "Computer", "Vision", "2006", "."], "sentence-detokenized": "SURF was first published by Herbert Bay, Tinne Tuytelaars, and Luc Van Gool, and presented at the European Conference on Computer Vision 2006.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 39], [39, 40], [41, 46], [47, 57], [57, 58], [59, 62], [63, 66], [67, 70], [71, 75], [75, 76], [77, 80], [81, 90], [91, 93], [94, 97], [98, 106], [107, 117], [118, 120], [121, 129], [130, 136], [137, 141], [141, 142]]}
{"doc_key": "ai-dev-256", "ner": [[0, 0, "task"], [7, 8, "field"], [10, 11, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 8, "part-of", "", false, false], [0, 0, 10, 11, "part-of", "", false, false], [0, 0, 13, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "is", "an", "area", "of", "research", "in", "pattern", "recognition", ",", "artificial", "intelligence", "and", "computer", "vision", "."], "sentence-detokenized": "OCR is an area of research in pattern recognition, artificial intelligence and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 14], [15, 17], [18, 26], [27, 29], [30, 37], [38, 49], [49, 50], [51, 61], [62, 74], [75, 78], [79, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-dev-257", "ner": [[2, 4, "metrics"], [8, 10, "algorithm"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 8, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "the", "maximum", "-likelihood", "estimator", "example", ",", "the", "probability", "density", "function", "(", "pdf", ")", "of", "the", "noise", "for", "one", "sample", "is", "mathwn", "/", "math"], "sentence-detokenized": "In the maximum-likelihood estimator example, the probability density function (pdf) of the noise for one sample is mathwn / math", "token2charspan": [[0, 2], [3, 6], [7, 14], [14, 25], [26, 35], [36, 43], [43, 44], [45, 48], [49, 60], [61, 68], [69, 77], [78, 79], [79, 82], [82, 83], [84, 86], [87, 90], [91, 96], [97, 100], [101, 104], [105, 111], [112, 114], [115, 121], [122, 123], [124, 128]]}
{"doc_key": "ai-dev-258", "ner": [[2, 3, "field"], [5, 6, "task"], [8, 9, "task"], [11, 12, "task"], [14, 15, "task"], [17, 19, "task"], [21, 21, "task"], [23, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 33, "task"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 6, 2, 3, "part-of", "", false, false], [8, 9, 2, 3, "part-of", "", false, false], [11, 12, 2, 3, "part-of", "", false, false], [14, 15, 2, 3, "part-of", "", false, false], [17, 19, 2, 3, "part-of", "", false, false], [21, 21, 2, 3, "part-of", "", false, false], [23, 23, 2, 3, "part-of", "", false, false], [25, 26, 2, 3, "part-of", "", false, false], [28, 29, 2, 3, "part-of", "", false, false], [31, 33, 2, 3, "part-of", "", false, false], [36, 37, 2, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Subdomains", "of", "computer", "vision", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "3D", "pose", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "servoing", ",", "3D", "scene", "modelling", ",", "and", "image", "restoration", "."], "sentence-detokenized": "Subdomains of computer vision include scene reconstruction, event detection, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual servoing, 3D scene modelling, and image restoration.", "token2charspan": [[0, 10], [11, 13], [14, 22], [23, 29], [30, 37], [38, 43], [44, 58], [58, 59], [60, 65], [66, 75], [75, 76], [77, 82], [83, 91], [91, 92], [93, 99], [100, 111], [111, 112], [113, 115], [116, 120], [121, 131], [131, 132], [133, 141], [141, 142], [143, 151], [151, 152], [153, 159], [160, 170], [170, 171], [172, 178], [179, 187], [187, 188], [189, 191], [192, 197], [198, 207], [207, 208], [209, 212], [213, 218], [219, 230], [230, 231]]}
{"doc_key": "ai-dev-259", "ner": [[10, 14, "conference"], [3, 3, "researcher"], [6, 7, "misc"], [17, 17, "conference"], [21, 21, "researcher"], [23, 23, "researcher"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 14, 17, 17, "named", "", false, false], [3, 3, 6, 7, "win-defeat", "", false, false], [3, 3, 25, 25, "related-to", "writes_about", true, false], [6, 7, 10, 14, "temporal", "", false, false], [21, 21, 6, 7, "win-defeat", "", false, true], [21, 21, 25, 25, "related-to", "writes_about", true, false], [23, 23, 6, 7, "win-defeat", "", false, true], [23, 23, 25, 25, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["In", "2013", ",", "Terzopoulos", "received", "a", "Helmholtz", "Prize", "at", "the", "International", "Conference", "on", "Computer", "Vision", "for", "his", "1987", "ICCV", "paper", "with", "Kass", "and", "Witkin", "on", "active", "contour", "models", "."], "sentence-detokenized": "In 2013, Terzopoulos received a Helmholtz Prize at the International Conference on Computer Vision for his 1987 ICCV paper with Kass and Witkin on active contour models.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 29], [30, 31], [32, 41], [42, 47], [48, 50], [51, 54], [55, 68], [69, 79], [80, 82], [83, 91], [92, 98], [99, 102], [103, 106], [107, 111], [112, 116], [117, 122], [123, 127], [128, 132], [133, 136], [137, 143], [144, 146], [147, 153], [154, 161], [162, 168], [168, 169]]}
{"doc_key": "ai-dev-260", "ner": [[16, 17, "task"], [19, 19, "algorithm"], [20, 21, "algorithm"], [23, 25, "algorithm"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 17, 19, 19, "usage", "", true, false], [16, 17, 20, 21, "usage", "", true, false], [16, 17, 23, 25, "usage", "", true, false], [16, 17, 27, 28, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["As", "the", "regularisation", "function", "There", "are", "many", "algorithms", "for", "solving", "such", "problems", ";", "popular", "algorithms", "for", "linear", "classification", "include", "stochastic", "gradient", "descent", ",", "L", "-", "BFGS", ",", "coordinate", "descent", "and", "Newton", "methods", "."], "sentence-detokenized": "As the regularisation function There are many algorithms for solving such problems; popular algorithms for linear classification include stochastic gradient descent, L-BFGS, coordinate descent and Newton methods.", "token2charspan": [[0, 2], [3, 6], [7, 21], [22, 30], [31, 36], [37, 40], [41, 45], [46, 56], [57, 60], [61, 68], [69, 73], [74, 82], [82, 83], [84, 91], [92, 102], [103, 106], [107, 113], [114, 128], [129, 136], [137, 147], [148, 156], [157, 164], [164, 165], [166, 167], [167, 168], [168, 172], [172, 173], [174, 184], [185, 192], [193, 196], [197, 203], [204, 211], [211, 212]]}
{"doc_key": "ai-dev-261", "ner": [[7, 7, "algorithm"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Long", "short", "-", "term", "memory", "networks", "(", "LSTM", ")", "were", "invented", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "and", "set", "precision", "records", "in", "various", "application", "domains", "."], "sentence-detokenized": "Long short-term memory networks (LSTM) were invented in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber and set precision records in various application domains.", "token2charspan": [[0, 4], [5, 10], [10, 11], [11, 15], [16, 22], [23, 31], [32, 33], [33, 37], [37, 38], [39, 43], [44, 52], [53, 55], [56, 60], [61, 63], [64, 68], [69, 79], [80, 83], [84, 90], [91, 102], [103, 106], [107, 110], [111, 120], [121, 128], [129, 131], [132, 139], [140, 151], [152, 159], [159, 160]]}
{"doc_key": "ai-dev-262", "ner": [[0, 0, "product"], [4, 6, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["TN", "was", "developed", "at", "Massachusetts", "General", "Hospital", "and", "tested", "in", "multiple", "scenarios", ",", "including", "extraction", "of", "smoking", "status", ",", "family", "history", "of", "coronary", "heart", "disease", ",", "identification", "of", "patients", "with", "sleep", "disorders", ","], "sentence-detokenized": "TN was developed at Massachusetts General Hospital and tested in multiple scenarios, including extraction of smoking status, family history of coronary heart disease, identification of patients with sleep disorders,", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 33], [34, 41], [42, 50], [51, 54], [55, 61], [62, 64], [65, 73], [74, 83], [83, 84], [85, 94], [95, 105], [106, 108], [109, 116], [117, 123], [123, 124], [125, 131], [132, 139], [140, 142], [143, 151], [152, 157], [158, 165], [165, 166], [167, 181], [182, 184], [185, 193], [194, 198], [199, 204], [205, 214], [214, 215]]}
{"doc_key": "ai-dev-263", "ner": [[3, 3, "researcher"], [8, 8, "product"], [15, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 8, "role", "sells", false, false], [8, 8, 15, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "shipped", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was shipped to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 73], [74, 76], [77, 84], [85, 91], [92, 94], [95, 99], [99, 100]]}
{"doc_key": "ai-dev-264", "ner": [[1, 3, "conference"], [14, 15, "location"], [17, 17, "location"], [19, 19, "country"], [29, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 14, 15, "physical", "", false, false], [14, 15, 17, 17, "physical", "", false, false], [17, 17, 19, 19, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Campus", "Party", "Europe", "was", "held", "from", "14", "to", "18", "April", "2010", "at", "the", "Caja", "M\u00e1gica", "in", "Madrid", ",", "Spain", ",", "with", "800", "participants", "from", "each", "of", "the", "27", "European", "Union", "member", "states", "."], "sentence-detokenized": "The Campus Party Europe was held from 14 to 18 April 2010 at the Caja M\u00e1gica in Madrid, Spain, with 800 participants from each of the 27 European Union member states.", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 23], [24, 27], [28, 32], [33, 37], [38, 40], [41, 43], [44, 46], [47, 52], [53, 57], [58, 60], [61, 64], [65, 69], [70, 76], [77, 79], [80, 86], [86, 87], [88, 93], [93, 94], [95, 99], [100, 103], [104, 116], [117, 121], [122, 126], [127, 129], [130, 133], [134, 136], [137, 145], [146, 151], [152, 158], [159, 165], [165, 166]]}
{"doc_key": "ai-dev-265", "ner": [[7, 7, "organisation"], [9, 11, "organisation"], [16, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 19, 7, 7, "origin", "", false, false], [16, 19, 9, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2016", ",", "a", "collaboration", "between", "DeepMind", "and", "Moorfields", "Eye", "Hospital", "was", "announced", "to", "develop", "AI", "applications", "for", "healthcare", "."], "sentence-detokenized": "In July 2016, a collaboration between DeepMind and Moorfields Eye Hospital was announced to develop AI applications for healthcare.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 15], [16, 29], [30, 37], [38, 46], [47, 50], [51, 61], [62, 65], [66, 74], [75, 78], [79, 88], [89, 91], [92, 99], [100, 102], [103, 115], [116, 119], [120, 130], [130, 131]]}
{"doc_key": "ai-dev-266", "ner": [[4, 4, "misc"], [10, 13, "university"], [15, 15, "university"], [17, 18, "university"], [20, 21, "university"], [23, 23, "university"], [25, 25, "university"], [27, 30, "university"], [32, 33, "university"], [35, 36, "university"], [38, 38, "university"], [41, 44, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[4, 4, 10, 13, "physical", "", false, false], [4, 4, 15, 15, "physical", "", false, false], [4, 4, 17, 18, "physical", "", false, false], [4, 4, 20, 21, "physical", "", false, false], [4, 4, 23, 23, "physical", "", false, false], [4, 4, 25, 25, "physical", "", false, false], [4, 4, 27, 30, "physical", "", false, false], [4, 4, 32, 33, "physical", "", false, false], [4, 4, 35, 36, "physical", "", false, false], [4, 4, 38, 38, "physical", "", false, false], [4, 4, 41, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["They", "eventually", "awarded", "11", "PR2s", "to", "various", "institutions", ",", "including", "the", "University", "of", "Freiburg", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "Technical", "University", "of", "Munich", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", ",", "and", "the", "University", "of", "Tokyo", "."], "sentence-detokenized": "They eventually awarded 11 PR2s to various institutions, including the University of Freiburg, Bosch, Georgia Tech, KU Leuven, MIT, Stanford, Technical University of Munich, UC Berkeley, U Penn, USC, and the University of Tokyo.", "token2charspan": [[0, 4], [5, 15], [16, 23], [24, 26], [27, 31], [32, 34], [35, 42], [43, 55], [55, 56], [57, 66], [67, 70], [71, 81], [82, 84], [85, 93], [93, 94], [95, 100], [100, 101], [102, 109], [110, 114], [114, 115], [116, 118], [119, 125], [125, 126], [127, 130], [130, 131], [132, 140], [140, 141], [142, 151], [152, 162], [163, 165], [166, 172], [172, 173], [174, 176], [177, 185], [185, 186], [187, 188], [189, 193], [193, 194], [195, 198], [198, 199], [200, 203], [204, 207], [208, 218], [219, 221], [222, 227], [227, 228]]}
{"doc_key": "ai-dev-267", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [7, 7, "metrics"], [10, 10, "metrics"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 20, 21, "part-of", "", false, false], [5, 5, 20, 21, "part-of", "", false, false], [7, 7, 20, 21, "part-of", "", false, false], [10, 10, 20, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "counts", "of", "TP", ",", "TN", ",", "FP", ",", "and", "FN", "are", "usually", "kept", "in", "a", "table", "known", "as", "the", "confusion", "matrix", "."], "sentence-detokenized": "The counts of TP, TN, FP, and FN are usually kept in a table known as the confusion matrix.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 16], [16, 17], [18, 20], [20, 21], [22, 24], [24, 25], [26, 29], [30, 32], [33, 36], [37, 44], [45, 49], [50, 52], [53, 54], [55, 60], [61, 66], [67, 69], [70, 73], [74, 83], [84, 90], [90, 91]]}
{"doc_key": "ai-dev-268", "ner": [[0, 1, "metrics"], [3, 4, "metrics"], [6, 7, "metrics"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Information", "gain", ",", "cross", "entropy", ",", "mutual", "information", "and", "probability", "ratio", "are", "commonly", "used", "as", "features", "."], "sentence-detokenized": "Information gain, cross entropy, mutual information and probability ratio are commonly used as features.", "token2charspan": [[0, 11], [12, 16], [16, 17], [18, 23], [24, 31], [31, 32], [33, 39], [40, 51], [52, 55], [56, 67], [68, 73], [74, 77], [78, 86], [87, 91], [92, 94], [95, 103], [103, 104]]}
{"doc_key": "ai-dev-269", "ner": [[10, 11, "task"], [13, 14, "task"], [16, 16, "task"], [18, 18, "task"], [20, 20, "task"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[22, 22, 20, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "successfully", "applied", "to", "several", "problems", ",", "including", "robot", "control", ",", "lift", "planning", ",", "telecommunications", ",", "checkers", "and", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "It has been successfully applied to several problems, including robot control, lift planning, telecommunications, checkers and Go (AlphaGo).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 32], [33, 35], [36, 43], [44, 52], [52, 53], [54, 63], [64, 69], [70, 77], [77, 78], [79, 83], [84, 92], [92, 93], [94, 112], [112, 113], [114, 122], [123, 126], [127, 129], [130, 131], [131, 138], [138, 139], [139, 140]]}
{"doc_key": "ai-dev-270", "ner": [[11, 12, "misc"], [20, 23, "university"], [25, 25, "location"], [27, 27, "location"], [31, 36, "location"], [39, 42, "location"], [44, 44, "location"], [45, 46, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 20, 23, "physical", "", false, false], [20, 23, 25, 25, "physical", "", false, false], [25, 25, 27, 27, "physical", "", false, false], [31, 36, 39, 42, "physical", "", false, false], [39, 42, 44, 44, "physical", "", false, false], [44, 44, 45, 46, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "the", "inaugural", "year", "of", "Mission", "8", ",", "the", "US", "location", "was", "held", "at", "the", "campus", "of", "the", "Georgia", "Institute", "of", "Technology", "in", "Atlanta", ",", "Georgia", ",", "and", "the", "Asia", "/", "Pacific", "location", "took", "place", "at", "the", "Gymnasium", "of", "Beihang", "University", "in", "Beijing", ",", "China", "."], "sentence-detokenized": "In 2018, the inaugural year of Mission 8, the US location was held at the campus of the Georgia Institute of Technology in Atlanta, Georgia, and the Asia/Pacific location took place at the Gymnasium of Beihang University in Beijing, China.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 38], [39, 40], [40, 41], [42, 45], [46, 48], [49, 57], [58, 61], [62, 66], [67, 69], [70, 73], [74, 80], [81, 83], [84, 87], [88, 95], [96, 105], [106, 108], [109, 119], [120, 122], [123, 130], [130, 131], [132, 139], [139, 140], [141, 144], [145, 148], [149, 153], [153, 154], [154, 161], [162, 170], [171, 175], [176, 181], [182, 184], [185, 188], [189, 198], [199, 201], [202, 209], [210, 220], [221, 223], [224, 231], [231, 232], [233, 238], [238, 239]]}
{"doc_key": "ai-dev-271", "ner": [[0, 1, "field"], [6, 7, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "origin", "", false, false], [0, 1, 6, 7, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "is", "strongly", "related", "to", "pattern", "recognition", "and", "comes", "from", "artificial", "intelligence", "."], "sentence-detokenized": "Machine learning is strongly related to pattern recognition and comes from artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 28], [29, 36], [37, 39], [40, 47], [48, 59], [60, 63], [64, 69], [70, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-dev-272", "ner": [[14, 15, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "comes", "with", "3", "Java", "games", "controlled", "by", "remote", "control", "and", "displayed", "on", "the", "LCD", "screen", "."], "sentence-detokenized": "It comes with 3 Java games controlled by remote control and displayed on the LCD screen.", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 15], [16, 20], [21, 26], [27, 37], [38, 40], [41, 47], [48, 55], [56, 59], [60, 69], [70, 72], [73, 76], [77, 80], [81, 87], [87, 88]]}
{"doc_key": "ai-dev-273", "ner": [[5, 17, "task"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 21, 5, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "commercially", "successful", "but", "specialised", "computer", "vision", "-", "based", "technique", "for", "estimating", "the", "pose", "of", "an", "articulated", "body", "is", "optical", "motion", "capture", "."], "sentence-detokenized": "A commercially successful but specialised computer vision-based technique for estimating the pose of an articulated body is optical motion capture.", "token2charspan": [[0, 1], [2, 14], [15, 25], [26, 29], [30, 41], [42, 50], [51, 57], [57, 58], [58, 63], [64, 73], [74, 77], [78, 88], [89, 92], [93, 97], [98, 100], [101, 103], [104, 115], [116, 120], [121, 123], [124, 131], [132, 138], [139, 146], [146, 147]]}
{"doc_key": "ai-dev-274", "ner": [[1, 2, "organisation"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 9, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SMC", "is", "very", "similar", "to", "the", "more", "popular", "Jaccard", "index", "."], "sentence-detokenized": "The SMC is very similar to the more popular Jaccard index.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 23], [24, 26], [27, 30], [31, 35], [36, 43], [44, 51], [52, 57], [57, 58]]}
{"doc_key": "ai-dev-275", "ner": [[1, 1, "product"], [3, 7, "product"], [10, 13, "product"], [22, 23, "researcher"], [28, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 10, 13, "named", "", false, false], [1, 1, 22, 23, "artifact", "", false, false], [1, 1, 28, 28, "artifact", "", false, false], [3, 7, 1, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ",", "or", "Programmable", "Universal", "Manipulation", "Arm", ")", "is", "an", "industrial", "robotic", "arm", "developed", "by", "Victor", "Scheinman", "at", "pioneering", "robotics", "company", "Unimation", "."], "sentence-detokenized": "The PUMA (Programmable Universal Machine for Assembly, or Programmable Universal Manipulation Arm) is an industrial robotic arm developed by Victor Scheinman at pioneering robotics company Unimation.", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 22], [23, 32], [33, 40], [41, 44], [45, 53], [53, 54], [55, 57], [58, 70], [71, 80], [81, 93], [94, 97], [97, 98], [99, 101], [102, 104], [105, 115], [116, 123], [124, 127], [128, 137], [138, 140], [141, 147], [148, 157], [158, 160], [161, 171], [172, 180], [181, 188], [189, 198], [198, 199]]}
{"doc_key": "ai-dev-276", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "written", "in", "Python", "."], "sentence-detokenized": "It is written in Python.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 23], [23, 24]]}
{"doc_key": "ai-dev-277", "ner": [[0, 0, "misc"], [2, 2, "misc"], [12, 12, "field"], [14, 15, "field"], [17, 17, "field"], [23, 24, "field"], [26, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7], "relations": [[0, 0, 2, 2, "related-to", "metric_for", true, false], [0, 0, 12, 12, "part-of", "", false, false], [0, 0, 14, 15, "part-of", "", false, false], [0, 0, 17, 17, "part-of", "", false, false], [0, 0, 23, 24, "part-of", "", false, false], [0, 0, 26, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6], "sentence": ["Bandwidth", "in", "hertz", "is", "a", "central", "concept", "in", "many", "fields", ",", "including", "electronics", ",", "information", "theory", ",", "digital", "communications", ",", "radio", "communications", ",", "signal", "processing", "and", "spectroscopy", ",", "and", "is", "one", "of", "the", "determinants", "of", "the", "capacity", "of", "a", "given", "communication", "channel", "."], "sentence-detokenized": "Bandwidth in hertz is a central concept in many fields, including electronics, information theory, digital communications, radio communications, signal processing and spectroscopy, and is one of the determinants of the capacity of a given communication channel.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 21], [22, 23], [24, 31], [32, 39], [40, 42], [43, 47], [48, 54], [54, 55], [56, 65], [66, 77], [77, 78], [79, 90], [91, 97], [97, 98], [99, 106], [107, 121], [121, 122], [123, 128], [129, 143], [143, 144], [145, 151], [152, 162], [163, 166], [167, 179], [179, 180], [181, 184], [185, 187], [188, 191], [192, 194], [195, 198], [199, 211], [212, 214], [215, 218], [219, 227], [228, 230], [231, 232], [233, 238], [239, 252], [253, 260], [260, 261]]}
{"doc_key": "ai-dev-278", "ner": [[9, 9, "algorithm"], [11, 11, "algorithm"], [18, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 18, 21, "part-of", "", false, false], [11, 11, 18, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "a", "convex", "loss", "is", "used", "(", "as", "in", "AdaBoost", ",", "LogitBoost", ",", "and", "all", "members", "of", "the", "AnyBoost", "family", "of", "algorithms", ")", "then", "an", "example", "with", "a", "higher", "margin", "will", "be", "given", "less", "(", "or", "equal", ")", "weight", "than", "an", "example", "with", "a", "lower", "margin", "."], "sentence-detokenized": "If a convex loss is used (as in AdaBoost, LogitBoost, and all members of the AnyBoost family of algorithms) then an example with a higher margin will be given less (or equal) weight than an example with a lower margin.", "token2charspan": [[0, 2], [3, 4], [5, 11], [12, 16], [17, 19], [20, 24], [25, 26], [26, 28], [29, 31], [32, 40], [40, 41], [42, 52], [52, 53], [54, 57], [58, 61], [62, 69], [70, 72], [73, 76], [77, 85], [86, 92], [93, 95], [96, 106], [106, 107], [108, 112], [113, 115], [116, 123], [124, 128], [129, 130], [131, 137], [138, 144], [145, 149], [150, 152], [153, 158], [159, 163], [164, 165], [165, 167], [168, 173], [173, 174], [175, 181], [182, 186], [187, 189], [190, 197], [198, 202], [203, 204], [205, 210], [211, 217], [217, 218]]}
{"doc_key": "ai-dev-279", "ner": [[0, 2, "researcher"], [6, 7, "researcher"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sepp", "Hochreiter", "'s", "1991", "graduation", "thesis", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Sepp Hochreiter's 1991 graduation thesis Sepp Hochreiter.", "token2charspan": [[0, 4], [5, 15], [15, 17], [18, 22], [23, 33], [34, 40], [41, 45], [46, 56], [56, 57]]}
{"doc_key": "ai-dev-280", "ner": [[4, 5, "algorithm"], [7, 7, "algorithm"], [10, 11, "algorithm"], [14, 14, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [27, 28, "algorithm"], [31, 32, "algorithm"], [34, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 7, 4, 5, "named", "", false, false], [14, 14, 10, 11, "named", "", false, false], [17, 19, 27, 28, "related-to", "", true, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Typical", "discriminative", "models", "include", "logistic", "regression", "(", "LR", ")", ",", "support", "vector", "machines", "(", "SVM", ")", ",", "conditional", "random", "fields", "(", "CRFs", ")", "(", "specified", "over", "an", "undirected", "graph", ")", ",", "decision", "trees", ",", "neural", "networks", "and", "many", "others", "."], "sentence-detokenized": "Typical discriminative models include logistic regression (LR), support vector machines (SVM), conditional random fields (CRFs) (specified over an undirected graph), decision trees, neural networks and many others.", "token2charspan": [[0, 7], [8, 22], [23, 29], [30, 37], [38, 46], [47, 57], [58, 59], [59, 61], [61, 62], [62, 63], [64, 71], [72, 78], [79, 87], [88, 89], [89, 92], [92, 93], [93, 94], [95, 106], [107, 113], [114, 120], [121, 122], [122, 126], [126, 127], [128, 129], [129, 138], [139, 143], [144, 146], [147, 157], [158, 163], [163, 164], [164, 165], [166, 174], [175, 180], [180, 181], [182, 188], [189, 197], [198, 201], [202, 206], [207, 213], [213, 214]]}
{"doc_key": "ai-dev-281", "ner": [[12, 14, "metrics"], [35, 36, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Then", "it", "is", "also", "possible", "to", "use", "these", "probabilities", "and", "evaluate", "the", "mean", "squared", "error", "(", "or", "another", "similar", "measure", ")", "between", "the", "probabilities", "and", "the", "true", "values", ",", "and", "then", "combine", "this", "with", "the", "confusion", "matrix", "to", "create", "highly", "efficient", "fitness", "functions", "for", "logistic", "regression", "."], "sentence-detokenized": "Then it is also possible to use these probabilities and evaluate the mean squared error (or another similar measure) between the probabilities and the true values, and then combine this with the confusion matrix to create highly efficient fitness functions for logistic regression.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 15], [16, 24], [25, 27], [28, 31], [32, 37], [38, 51], [52, 55], [56, 64], [65, 68], [69, 73], [74, 81], [82, 87], [88, 89], [89, 91], [92, 99], [100, 107], [108, 115], [115, 116], [117, 124], [125, 128], [129, 142], [143, 146], [147, 150], [151, 155], [156, 162], [162, 163], [164, 167], [168, 172], [173, 180], [181, 185], [186, 190], [191, 194], [195, 204], [205, 211], [212, 214], [215, 221], [222, 228], [229, 238], [239, 246], [247, 256], [257, 260], [261, 269], [270, 280], [280, 281]]}
{"doc_key": "ai-dev-282", "ner": [[0, 0, "product"], [5, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "was", "first", "used", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "in", "2005", "."], "sentence-detokenized": "VoiceOver was first used in Mac OS X Tiger (10.4) in 2005.", "token2charspan": [[0, 9], [10, 13], [14, 19], [20, 24], [25, 27], [28, 31], [32, 34], [35, 36], [37, 42], [43, 44], [44, 48], [48, 49], [50, 52], [53, 57], [57, 58]]}
{"doc_key": "ai-dev-283", "ner": [[12, 13, "algorithm"], [19, 20, "misc"], [24, 26, "metrics"], [28, 30, "algorithm"], [60, 62, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 19, 20, "related-to", "applied_to", false, false], [24, 26, 19, 20, "type-of", "", false, false], [24, 26, 28, 30, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "practice", ",", "machine", "learning", "algorithms", "deal", "with", "this", "by", "using", "a", "convex", "approximation", "of", "the", "0", "-", "1", "loss", "function", "(", "such", "as", "the", "hinge", "loss", "for", "Support", "vector", "machine", ")", ",", "which", "is", "easier", "to", "optimise", ",", "or", "by", "making", "assumptions", "about", "the", "distribution", "mathP", "(", "x", ",", "y", ")", "/", "math", "(", "and", "thus", "ceasing", "to", "be", "agnostic", "learning", "algorithms", "for", "which", "the", "above", "result", "holds", ")", "."], "sentence-detokenized": "In practice, machine learning algorithms deal with this by using a convex approximation of the 0-1 loss function (such as the hinge loss for Support vector machine), which is easier to optimise, or by making assumptions about the distribution mathP (x, y) / math (and thus ceasing to be agnostic learning algorithms for which the above result holds).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 29], [30, 40], [41, 45], [46, 50], [51, 55], [56, 58], [59, 64], [65, 66], [67, 73], [74, 87], [88, 90], [91, 94], [95, 96], [96, 97], [97, 98], [99, 103], [104, 112], [113, 114], [114, 118], [119, 121], [122, 125], [126, 131], [132, 136], [137, 140], [141, 148], [149, 155], [156, 163], [163, 164], [164, 165], [166, 171], [172, 174], [175, 181], [182, 184], [185, 193], [193, 194], [195, 197], [198, 200], [201, 207], [208, 219], [220, 225], [226, 229], [230, 242], [243, 248], [249, 250], [250, 251], [251, 252], [253, 254], [254, 255], [256, 257], [258, 262], [263, 264], [264, 267], [268, 272], [273, 280], [281, 283], [284, 286], [287, 295], [296, 304], [305, 315], [316, 319], [320, 325], [326, 329], [330, 335], [336, 342], [343, 348], [348, 349], [349, 350]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [10, 13, "field"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 13, "usage", "", false, false], [0, 0, 22, 22, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Westworld", "(", "1973", ")", "was", "the", "first", "feature", "film", "to", "use", "digital", "image", "processing", "to", "simulate", "the", "point", "of", "view", "of", "an", "android", "."], "sentence-detokenized": "Westworld (1973) was the first feature film to use digital image processing to simulate the point of view of an android.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 20], [21, 24], [25, 30], [31, 38], [39, 43], [44, 46], [47, 50], [51, 58], [59, 64], [65, 75], [76, 78], [79, 87], [88, 91], [92, 97], [98, 100], [101, 105], [106, 108], [109, 111], [112, 119], [119, 120]]}
{"doc_key": "ai-dev-285", "ner": [[7, 8, "task"], [10, 11, "task"], [13, 13, "task"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "now", "also", "widely", "used", "in", "speech", "recognition", ",", "speech", "synthesis", ",", "diaresis", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "It is now also widely used in speech recognition, speech synthesis, diaresis, Xavier Anguera et al.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 14], [15, 21], [22, 26], [27, 29], [30, 36], [37, 48], [48, 49], [50, 56], [57, 66], [66, 67], [68, 76], [76, 77], [78, 84], [85, 92], [93, 95], [96, 98], [98, 99]]}
{"doc_key": "ai-dev-286", "ner": [[8, 10, "algorithm"], [15, 16, "algorithm"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 8, 10, "type-of", "", false, false], [19, 21, 8, 10, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Here", ",", "math", "sigma", "/", "math", "is", "an", "elementwise", "activation", "function", ",", "such", "as", "a", "sigmoid", "function", "or", "a", "rectified", "linear", "unit", "."], "sentence-detokenized": "Here, math sigma / math is an elementwise activation function, such as a sigmoid function or a rectified linear unit.", "token2charspan": [[0, 4], [4, 5], [6, 10], [11, 16], [17, 18], [19, 23], [24, 26], [27, 29], [30, 41], [42, 52], [53, 61], [61, 62], [63, 67], [68, 70], [71, 72], [73, 80], [81, 89], [90, 92], [93, 94], [95, 104], [105, 111], [112, 116], [116, 117]]}
{"doc_key": "ai-dev-287", "ner": [[7, 8, "algorithm"], [21, 21, "misc"], [23, 23, "misc"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "phonetics", "-", "based", "(", "i.e.", "all", "hidden", "Markov", "model", "-", "based", ")", "approaches", "required", "separate", "components", "and", "training", "for", "the", "pronunciation", ",", "acoustic", "and", "language", "model", "."], "sentence-detokenized": "Traditional phonetics-based (i.e. all hidden Markov model-based) approaches required separate components and training for the pronunciation, acoustic and language model.", "token2charspan": [[0, 11], [12, 21], [21, 22], [22, 27], [28, 29], [29, 33], [34, 37], [38, 44], [45, 51], [52, 57], [57, 58], [58, 63], [63, 64], [65, 75], [76, 84], [85, 93], [94, 104], [105, 108], [109, 117], [118, 121], [122, 125], [126, 139], [139, 140], [141, 149], [150, 153], [154, 162], [163, 168], [168, 169]]}
{"doc_key": "ai-dev-288", "ner": [[1, 3, "algorithm"], [7, 8, "field"], [10, 11, "field"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 13, 14, "related-to", "used_for", false, false], [7, 8, 1, 3, "usage", "", false, false], [10, 11, 1, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Roberts", "cross", "operator", "is", "used", "in", "image", "processing", "and", "computer", "vision", "for", "edge", "detection", "."], "sentence-detokenized": "The Roberts cross operator is used in image processing and computer vision for edge detection.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 37], [38, 43], [44, 54], [55, 58], [59, 67], [68, 74], [75, 78], [79, 83], [84, 93], [93, 94]]}
{"doc_key": "ai-dev-289", "ner": [[0, 0, "metrics"], [2, 2, "metrics"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 21, 21, "opposite", "", false, false], [2, 2, 21, 21, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Sensitivity", "and", "specificity", "values", "are", "agnostic", "to", "the", "percentage", "of", "positive", "cases", "in", "the", "population", "of", "interest", "(", "as", "opposed", "to", "precision", ",", "for", "example", ")", "."], "sentence-detokenized": "Sensitivity and specificity values are agnostic to the percentage of positive cases in the population of interest (as opposed to precision, for example).", "token2charspan": [[0, 11], [12, 15], [16, 27], [28, 34], [35, 38], [39, 47], [48, 50], [51, 54], [55, 65], [66, 68], [69, 77], [78, 83], [84, 86], [87, 90], [91, 101], [102, 104], [105, 113], [114, 115], [115, 117], [118, 125], [126, 128], [129, 138], [138, 139], [140, 143], [144, 151], [151, 152], [152, 153]]}
{"doc_key": "ai-dev-290", "ner": [[1, 2, "algorithm"], [15, 15, "misc"], [8, 9, "researcher"], [11, 12, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 15, 1, 2, "topic", "", false, false], [15, 15, 8, 9, "artifact", "", false, false], [15, 15, 11, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["But", "perceptron", "models", "were", "made", "very", "unpopular", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "'s", "book", "Perceptrons", ",", "published", "in", "1969", "."], "sentence-detokenized": "But perceptron models were made very unpopular by Marvin Minsky and Seymour Papert's book Perceptrons, published in 1969.", "token2charspan": [[0, 3], [4, 14], [15, 21], [22, 26], [27, 31], [32, 36], [37, 46], [47, 49], [50, 56], [57, 63], [64, 67], [68, 75], [76, 82], [82, 84], [85, 89], [90, 101], [101, 102], [103, 112], [113, 115], [116, 120], [120, 121]]}
{"doc_key": "ai-dev-291", "ner": [[1, 3, "conference"], [8, 8, "organisation"], [18, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 3, 18, 25, "topic", "", false, false], [8, 8, 1, 3, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Document", "Understanding", "Conferences", ",", "held", "annually", "by", "NIST", ",", "have", "developed", "sophisticated", "evaluation", "criteria", "for", "techniques", "that", "take", "on", "the", "challenge", "of", "summarising", "multiple", "documents", "."], "sentence-detokenized": "The Document Understanding Conferences, held annually by NIST, have developed sophisticated evaluation criteria for techniques that take on the challenge of summarising multiple documents.", "token2charspan": [[0, 3], [4, 12], [13, 26], [27, 38], [38, 39], [40, 44], [45, 53], [54, 56], [57, 61], [61, 62], [63, 67], [68, 77], [78, 91], [92, 102], [103, 111], [112, 115], [116, 126], [127, 131], [132, 136], [137, 139], [140, 143], [144, 153], [154, 156], [157, 168], [169, 177], [178, 187], [187, 188]]}
{"doc_key": "ai-dev-292", "ner": [[1, 2, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 26, 27, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "parallel", "manipulator", "is", "designed", "so", "that", "each", "chain", "is", "usually", "short", "and", "simple", "and", "thus", "can", "be", "inflexible", "against", "unwanted", "movements", ",", "compared", "to", "a", "serial", "manipulator", "."], "sentence-detokenized": "A parallel manipulator is designed so that each chain is usually short and simple and thus can be inflexible against unwanted movements, compared to a serial manipulator.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 34], [35, 37], [38, 42], [43, 47], [48, 53], [54, 56], [57, 64], [65, 70], [71, 74], [75, 81], [82, 85], [86, 90], [91, 94], [95, 97], [98, 108], [109, 116], [117, 125], [126, 135], [135, 136], [137, 145], [146, 148], [149, 150], [151, 157], [158, 169], [169, 170]]}
{"doc_key": "ai-dev-293", "ner": [[25, 25, "misc"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "manipulator", "is", "what", "makes", "the", "robot", "move", ",", "and", "the", "design", "of", "these", "systems", "can", "be", "classified", "into", "several", "common", "types", ",", "such", "as", "SCARA", "and", "Cartesian", "coordinate", "robotics", ",", "which", "use", "different", "coordinate", "systems", "to", "guide", "the", "arms", "of", "the", "machine", "."], "sentence-detokenized": "The manipulator is what makes the robot move, and the design of these systems can be classified into several common types, such as SCARA and Cartesian coordinate robotics, which use different coordinate systems to guide the arms of the machine.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 23], [24, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 49], [50, 53], [54, 60], [61, 63], [64, 69], [70, 77], [78, 81], [82, 84], [85, 95], [96, 100], [101, 108], [109, 115], [116, 121], [121, 122], [123, 127], [128, 130], [131, 136], [137, 140], [141, 150], [151, 161], [162, 170], [170, 171], [172, 177], [178, 181], [182, 191], [192, 202], [203, 210], [211, 213], [214, 219], [220, 223], [224, 228], [229, 231], [232, 235], [236, 243], [243, 244]]}
{"doc_key": "ai-dev-294", "ner": [[2, 3, "country"], [11, 14, "organisation"], [17, 22, "organisation"], [25, 28, "organisation"], [31, 33, "organisation"], [37, 43, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 14, 2, 3, "physical", "", false, false], [17, 22, 2, 3, "physical", "", false, false], [25, 28, 2, 3, "physical", "", false, false], [31, 33, 2, 3, "physical", "", false, false], [37, 43, 2, 3, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "United", "States", ",", "he", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "Linguistic", "Society", "of", "America", ",", "the", "American", "Philosophical", "Association", ",", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In the United States, he is a member of the National Academy of Sciences, the American Academy of Arts and Sciences, the Linguistic Society of America, the American Philosophical Association, and the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 20], [20, 21], [22, 24], [25, 27], [28, 29], [30, 36], [37, 39], [40, 43], [44, 52], [53, 60], [61, 63], [64, 72], [72, 73], [74, 77], [78, 86], [87, 94], [95, 97], [98, 102], [103, 106], [107, 115], [115, 116], [117, 120], [121, 131], [132, 139], [140, 142], [143, 150], [150, 151], [152, 155], [156, 164], [165, 178], [179, 190], [190, 191], [192, 195], [196, 199], [200, 208], [209, 220], [221, 224], [225, 228], [229, 240], [241, 243], [244, 251], [251, 252]]}
{"doc_key": "ai-dev-295", "ner": [[9, 11, "algorithm"], [13, 13, "algorithm"], [25, 27, "algorithm"], [29, 30, "algorithm"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 11, 25, 27, "named", "", false, false], [13, 13, 9, 11, "named", "", false, false], [25, 27, 29, 30, "compare", "", false, false], [25, 27, 35, 36, "related-to", "performs", false, false], [29, 30, 35, 36, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["They", "became", "very", "popular", "with", "the", "popularity", "of", "the", "support", "vector", "machine", "(", "SVM", ")", "in", "the", "1990s", ",", "when", "it", "was", "found", "that", "the", "SVM", "could", "compete", "with", "neural", "networks", "in", "tasks", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "They became very popular with the popularity of the support vector machine (SVM) in the 1990s, when it was found that the SVM could compete with neural networks in tasks such as handwriting recognition.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 24], [25, 29], [30, 33], [34, 44], [45, 47], [48, 51], [52, 59], [60, 66], [67, 74], [75, 76], [76, 79], [79, 80], [81, 83], [84, 87], [88, 93], [93, 94], [95, 99], [100, 102], [103, 106], [107, 112], [113, 117], [118, 121], [122, 125], [126, 131], [132, 139], [140, 144], [145, 151], [152, 160], [161, 163], [164, 169], [170, 174], [175, 177], [178, 189], [190, 201], [201, 202]]}
{"doc_key": "ai-dev-296", "ner": [[2, 3, "misc"], [9, 9, "misc"], [13, 14, "algorithm"], [22, 23, "misc"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 9, "usage", "", false, false], [2, 3, 22, 23, "usage", "", false, false], [9, 9, 13, 14, "origin", "result_of_algorithm", false, false], [22, 23, 27, 28, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["An", "empirical", "whitening", "transformation", "is", "obtained", "by", "estimating", "the", "covariance", "(", "e.g.", "by", "maximum", "likelihood", ")", "and", "then", "constructing", "a", "corresponding", "estimated", "whitening", "matrix", "(", "e.g.", "by", "Cholesky", "decomposition", ")", "."], "sentence-detokenized": "An empirical whitening transformation is obtained by estimating the covariance (e.g. by maximum likelihood) and then constructing a corresponding estimated whitening matrix (e.g. by Cholesky decomposition).", "token2charspan": [[0, 2], [3, 12], [13, 22], [23, 37], [38, 40], [41, 49], [50, 52], [53, 63], [64, 67], [68, 78], [79, 80], [80, 84], [85, 87], [88, 95], [96, 106], [106, 107], [108, 111], [112, 116], [117, 129], [130, 131], [132, 145], [146, 155], [156, 165], [166, 172], [173, 174], [174, 178], [179, 181], [182, 190], [191, 204], [204, 205], [205, 206]]}
{"doc_key": "ai-dev-297", "ner": [[0, 0, "organisation"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["IAI", "is", "the", "world", "'s", "largest", "manufacturer", "of", "cartesian", "coordinate", "robots", "and", "is", "an", "established", "leader", "in", "low", "-", "cost", ",", "high", "-", "performance", "SCARA", "robots", "."], "sentence-detokenized": "IAI is the world's largest manufacturer of cartesian coordinate robots and is an established leader in low-cost, high-performance SCARA robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [16, 18], [19, 26], [27, 39], [40, 42], [43, 52], [53, 63], [64, 70], [71, 74], [75, 77], [78, 80], [81, 92], [93, 99], [100, 102], [103, 106], [106, 107], [107, 111], [111, 112], [113, 117], [117, 118], [118, 129], [130, 135], [136, 142], [142, 143]]}
{"doc_key": "ai-dev-298", "ner": [[10, 11, "field"], [13, 14, "field"], [16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formal", "concept", "analysis", "finds", "practical", "application", "in", "fields", "such", "as", "data", "mining", ",", "text", "mining", ",", "machine", "learning", ",", "knowledge", "management", ",", "semantic", "web", ",", "software", "development", ",", "chemistry", "and", "biology", "."], "sentence-detokenized": "Formal concept analysis finds practical application in fields such as data mining, text mining, machine learning, knowledge management, semantic web, software development, chemistry and biology.", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 29], [30, 39], [40, 51], [52, 54], [55, 61], [62, 66], [67, 69], [70, 74], [75, 81], [81, 82], [83, 87], [88, 94], [94, 95], [96, 103], [104, 112], [112, 113], [114, 123], [124, 134], [134, 135], [136, 144], [145, 148], [148, 149], [150, 158], [159, 170], [170, 171], [172, 181], [182, 185], [186, 193], [193, 194]]}
{"doc_key": "ai-dev-299", "ner": [[1, 2, "field"], [4, 6, "field"], [10, 11, "field"], [17, 19, "field"], [30, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 17, 19, "part-of", "", false, false], [4, 6, 30, 32, "topic", "", false, false], [10, 11, 4, 6, "named", "", false, false], [17, 19, 1, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", ",", "computational", "learning", "theory", "(", "or", "simply", "learning", "theory", ")", "is", "a", "subfield", "of", "artificial", "intelligence", "concerned", "with", "the", "study", "of", "the", "design", "and", "analysis", "of", "algorithms", "for", "machine", "learning", "."], "sentence-detokenized": "In computer science, computational learning theory (or simply learning theory) is a subfield of artificial intelligence concerned with the study of the design and analysis of algorithms for machine learning.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 34], [35, 43], [44, 50], [51, 52], [52, 54], [55, 61], [62, 70], [71, 77], [77, 78], [79, 81], [82, 83], [84, 92], [93, 95], [96, 106], [107, 119], [120, 129], [130, 134], [135, 138], [139, 144], [145, 147], [148, 151], [152, 158], [159, 162], [163, 171], [172, 174], [175, 185], [186, 189], [190, 197], [198, 206], [206, 207]]}
{"doc_key": "ai-dev-300", "ner": [[0, 1, "algorithm"], [3, 3, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "(", "CF", ")", "is", "a", "technique", "used", "by", "recommendation", "systems", "."], "sentence-detokenized": "Collaborative filtering (CF) is a technique used by recommendation systems.", "token2charspan": [[0, 13], [14, 23], [24, 25], [25, 27], [27, 28], [29, 31], [32, 33], [34, 43], [44, 48], [49, 51], [52, 66], [67, 74], [74, 75]]}
{"doc_key": "ai-dev-301", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "FALSE", "positive", "rate", "is", "the", "proportion", "of", "all", "negatives", "that", "still", "yield", "a", "positive", "test", "result", ",", "i.e.", "the", "conditional", "probability", "of", "a", "positive", "test", "result", "given", "an", "event", "that", "was", "not", "present", "."], "sentence-detokenized": "The FALSE positive rate is the proportion of all negatives that still yield a positive test result, i.e. the conditional probability of a positive test result given an event that was not present.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 23], [24, 26], [27, 30], [31, 41], [42, 44], [45, 48], [49, 58], [59, 63], [64, 69], [70, 75], [76, 77], [78, 86], [87, 91], [92, 98], [98, 99], [100, 104], [105, 108], [109, 120], [121, 132], [133, 135], [136, 137], [138, 146], [147, 151], [152, 158], [159, 164], [165, 167], [168, 173], [174, 178], [179, 182], [183, 186], [187, 194], [194, 195]]}
{"doc_key": "ai-dev-302", "ner": [[1, 15, "misc"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 15, 37, 37, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "VLDB", "'", "8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pp.", "422-433", ".", "found", "that", "the", "given", "values", "for", "mathC", "/", "math", "and", "mathK", "/", "math", "generally", "imply", "relatively", "low", "accuracy", "of", "the", "iteratively", "computed", "SimRank", "scores", "."], "sentence-detokenized": "In VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, pp. 422-433. found that the given values for mathC / math and mathK / math generally imply relatively low accuracy of the iteratively computed SimRank scores.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [10, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 79], [80, 85], [85, 86], [87, 90], [91, 98], [98, 99], [100, 105], [106, 110], [111, 114], [115, 120], [121, 127], [128, 131], [132, 137], [138, 139], [140, 144], [145, 148], [149, 154], [155, 156], [157, 161], [162, 171], [172, 177], [178, 188], [189, 192], [193, 201], [202, 204], [205, 208], [209, 220], [221, 229], [230, 237], [238, 244], [244, 245]]}
{"doc_key": "ai-dev-303", "ner": [[5, 7, "misc"], [8, 8, "misc"], [15, 16, "person"], [18, 20, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 5, 7, "general-affiliation", "", false, false], [8, 8, 15, 16, "artifact", "", false, false], [8, 8, 18, 20, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "June", "2015", ",", "the", "science", "fiction", "drama", "Sense8", "debuted", ",", "written", "and", "produced", "by", "The", "Wachowskis", "and", "J.", "Michael", "Straczynski", "."], "sentence-detokenized": "In June 2015, the science fiction drama Sense8 debuted, written and produced by The Wachowskis and J. Michael Straczynski.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 25], [26, 33], [34, 39], [40, 46], [47, 54], [54, 55], [56, 63], [64, 67], [68, 76], [77, 79], [80, 83], [84, 94], [95, 98], [99, 101], [102, 109], [110, 121], [121, 122]]}
{"doc_key": "ai-dev-304", "ner": [[1, 1, "misc"], [6, 7, "product"], [26, 28, "misc"], [36, 36, "country"], [38, 38, "country"], [40, 40, "country"], [42, 42, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 1, 6, 7, "topic", "", false, false], [36, 36, 26, 28, "type-of", "", false, false], [38, 38, 26, 28, "type-of", "", false, false], [40, 40, 26, 28, "type-of", "", false, false], [42, 42, 26, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Although", "Eurotra", "never", "produced", "a", "working", "MT", "system", ",", "the", "project", "had", "a", "far", "-", "reaching", "long", "-", "term", "effect", "on", "the", "burgeoning", "language", "industries", "in", "European", "Member", "States", ",", "especially", "in", "the", "southern", "countries", "of", "Greece", ",", "Italy", ",", "Spain", "and", "Portugal", "."], "sentence-detokenized": "Although Eurotra never produced a working MT system, the project had a far-reaching long-term effect on the burgeoning language industries in European Member States, especially in the southern countries of Greece, Italy, Spain and Portugal.", "token2charspan": [[0, 8], [9, 16], [17, 22], [23, 31], [32, 33], [34, 41], [42, 44], [45, 51], [51, 52], [53, 56], [57, 64], [65, 68], [69, 70], [71, 74], [74, 75], [75, 83], [84, 88], [88, 89], [89, 93], [94, 100], [101, 103], [104, 107], [108, 118], [119, 127], [128, 138], [139, 141], [142, 150], [151, 157], [158, 164], [164, 165], [166, 176], [177, 179], [180, 183], [184, 192], [193, 202], [203, 205], [206, 212], [212, 213], [214, 219], [219, 220], [221, 226], [227, 230], [231, 239], [239, 240]]}
{"doc_key": "ai-dev-305", "ner": [[0, 0, "algorithm"], [7, 8, "task"], [15, 17, "task"], [19, 19, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 0, 0, "usage", "", true, false], [15, 17, 7, 8, "named", "", false, false], [19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoder", "has", "been", "successfully", "applied", "to", "the", "machine", "translation", "of", "human", "languages", ",", "commonly", "called", "neural", "machine", "translation", "(", "NMT", ")", "."], "sentence-detokenized": "Autoencoder has been successfully applied to the machine translation of human languages, commonly called neural machine translation (NMT).", "token2charspan": [[0, 11], [12, 15], [16, 20], [21, 33], [34, 41], [42, 44], [45, 48], [49, 56], [57, 68], [69, 71], [72, 77], [78, 87], [87, 88], [89, 97], [98, 104], [105, 111], [112, 119], [120, 131], [132, 133], [133, 136], [136, 137], [137, 138]]}
{"doc_key": "ai-dev-306", "ner": [[9, 11, "metrics"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "examples", "of", "probability", "-", "based", "fitness", "functions", "include", "maximum", "-likelihood", "estimation", "and", "hinge", "loss", "."], "sentence-detokenized": "Popular examples of probability-based fitness functions include maximum-likelihood estimation and hinge loss.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 31], [31, 32], [32, 37], [38, 45], [46, 55], [56, 63], [64, 71], [71, 82], [83, 93], [94, 97], [98, 103], [104, 108], [108, 109]]}
{"doc_key": "ai-dev-307", "ner": [[0, 1, "field"], [10, 12, "task"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 12, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "mining", "is", "a", "related", "field", ",", "which", "focuses", "on", "exploratory", "data", "analysis", "through", "unsupervised", "learning", "."], "sentence-detokenized": "Data mining is a related field, which focuses on exploratory data analysis through unsupervised learning.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 16], [17, 24], [25, 30], [30, 31], [32, 37], [38, 45], [46, 48], [49, 60], [61, 65], [66, 74], [75, 82], [83, 95], [96, 104], [104, 105]]}
{"doc_key": "ai-dev-308", "ner": [[0, 1, "algorithm"], [13, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "includes", "techniques", "to", "bring", "together", "people", "with", "similar", "interests", "and", "create", "a", "recommendation", "system", "based", "on", "them", "."], "sentence-detokenized": "Collaborative filtering includes techniques to bring together people with similar interests and create a recommendation system based on them.", "token2charspan": [[0, 13], [14, 23], [24, 32], [33, 43], [44, 46], [47, 52], [53, 61], [62, 68], [69, 73], [74, 81], [82, 91], [92, 95], [96, 102], [103, 104], [105, 119], [120, 126], [127, 132], [133, 135], [136, 140], [140, 141]]}
{"doc_key": "ai-dev-309", "ner": [[3, 8, "algorithm"], [17, 20, "product"]], "ner_mapping_to_source": [0, 2], "relations": [[17, 20, 3, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "number", "of", "WordNet", "-", "based", "word", "similarity", "algorithms", "have", "been", "implemented", "in", "a", "Perl", "package", "called", "WordNet", ":", ":", "Similarity", "."], "sentence-detokenized": "A number of WordNet-based word similarity algorithms have been implemented in a Perl package called WordNet:: Similarity.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 19], [19, 20], [20, 25], [26, 30], [31, 41], [42, 52], [53, 57], [58, 62], [63, 74], [75, 77], [78, 79], [80, 84], [85, 92], [93, 99], [100, 107], [107, 108], [108, 109], [110, 120], [120, 121]]}
{"doc_key": "ai-dev-310", "ner": [[5, 5, "conference"], [7, 7, "conference"], [11, 12, "researcher"], [14, 15, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 7, 5, 5, "named", "", false, false], [11, 12, 5, 5, "temporal", "", false, false], [14, 15, 5, 5, "temporal", "", false, false], [18, 19, 5, 5, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Another", "paper", "presented", "at", "the", "CVPR", "(", "CVPR", ")", "2000", "by", "Erik", "Miller", ",", "Nicholas", "Matsakis", ",", "and", "Paul", "Viola", "will", "also", "be", "discussed", "."], "sentence-detokenized": "Another paper presented at the CVPR (CVPR) 2000 by Erik Miller, Nicholas Matsakis, and Paul Viola will also be discussed.", "token2charspan": [[0, 7], [8, 13], [14, 23], [24, 26], [27, 30], [31, 35], [36, 37], [37, 41], [41, 42], [43, 47], [48, 50], [51, 55], [56, 62], [62, 63], [64, 72], [73, 81], [81, 82], [83, 86], [87, 91], [92, 97], [98, 102], [103, 107], [108, 110], [111, 120], [120, 121]]}
{"doc_key": "ai-dev-311", "ner": [[0, 0, "algorithm"], [8, 9, "misc"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 15, "compare", "", false, false], [14, 15, 8, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["QC", "has", "not", "been", "evaluated", "against", "traditional", "modern", "clustering", "algorithms", ",", "apart", "from", "the", "Jaccard", "index", "."], "sentence-detokenized": "QC has not been evaluated against traditional modern clustering algorithms, apart from the Jaccard index.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 15], [16, 25], [26, 33], [34, 45], [46, 52], [53, 63], [64, 74], [74, 75], [76, 81], [82, 86], [87, 90], [91, 98], [99, 104], [104, 105]]}
{"doc_key": "ai-dev-312", "ner": [[2, 12, "misc"], [8, 10, "misc"], [15, 16, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 2, 12, "physical", "", false, false], [8, 10, 15, 16, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "the", "VEX", "Robotics", "World", "Championship", ",", "a", "Parade", "of", "Nations", "will", "be", "held", "in", "Freedom", "Hall", ",", "with", "hundreds", "of", "students", "from", "more", "than", "30", "countries", "taking", "part", "."], "sentence-detokenized": "During the VEX Robotics World Championship, a Parade of Nations will be held in Freedom Hall, with hundreds of students from more than 30 countries taking part.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 23], [24, 29], [30, 42], [42, 43], [44, 45], [46, 52], [53, 55], [56, 63], [64, 68], [69, 71], [72, 76], [77, 79], [80, 87], [88, 92], [92, 93], [94, 98], [99, 107], [108, 110], [111, 119], [120, 124], [125, 129], [130, 134], [135, 137], [138, 147], [148, 154], [155, 159], [159, 160]]}
{"doc_key": "ai-dev-313", "ner": [[5, 8, "metrics"], [10, 10, "metrics"], [13, 15, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 5, 8, "named", "", false, false], [17, 17, 13, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Other", "measures", "of", "accuracy", "include", "Single", "Word", "Error", "Rate", "(", "SWER", ")", "and", "Command", "Success", "Rate", "(", "CSR", ")", "."], "sentence-detokenized": "Other measures of accuracy include Single Word Error Rate (SWER) and Command Success Rate (CSR).", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [27, 34], [35, 41], [42, 46], [47, 52], [53, 57], [58, 59], [59, 63], [63, 64], [65, 68], [69, 76], [77, 84], [85, 89], [90, 91], [91, 94], [94, 95], [95, 96]]}
{"doc_key": "ai-dev-314", "ner": [[7, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "presented", "their", "methodology", "and", "results", "in", "SIGGRAPH", "2000", "."], "sentence-detokenized": "They presented their methodology and results in SIGGRAPH 2000.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 32], [33, 36], [37, 44], [45, 47], [48, 56], [57, 61], [61, 62]]}
{"doc_key": "ai-dev-315", "ner": [[1, 2, "conference"], [6, 10, "misc"], [16, 17, "conference"], [20, 25, "researcher"], [35, 36, "researcher"], [40, 42, "conference"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "KDD", "conference", "grew", "out", "of", "Knowledge", "Discovery", "and", "Data", "Mining", "(", "KDD", ")", "workshops", "at", "AAAI", "conferences", "organised", "by", "Gregory", "I", ".", "Piatetsky", "-", "Shapiro", "in", "1989", ",", "1991", "and", "1993", ",", "and", "by", "Usama", "Fayyad", "in", "1994", ".", "Machinery", "|", "ACM", "."], "sentence-detokenized": "The KDD conference grew out of Knowledge Discovery and Data Mining (KDD) workshops at AAAI conferences organised by Gregory I. Piatetsky-Shapiro in 1989, 1991 and 1993, and by Usama Fayyad in 1994. Machinery | ACM.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 23], [24, 27], [28, 30], [31, 40], [41, 50], [51, 54], [55, 59], [60, 66], [67, 68], [68, 71], [71, 72], [73, 82], [83, 85], [86, 90], [91, 102], [103, 112], [113, 115], [116, 123], [124, 125], [125, 126], [127, 136], [136, 137], [137, 144], [145, 147], [148, 152], [152, 153], [154, 158], [159, 162], [163, 167], [167, 168], [169, 172], [173, 175], [176, 181], [182, 188], [189, 191], [192, 196], [196, 197], [198, 207], [208, 209], [210, 213], [213, 214]]}
{"doc_key": "ai-dev-316", "ner": [[8, 11, "conference"], [13, 13, "conference"], [17, 22, "organisation"], [24, 24, "organisation"], [28, 32, "conference"], [34, 34, "conference"], [38, 44, "conference"], [46, 46, "conference"], [49, 55, "conference"], [57, 57, "conference"], [62, 67, "conference"], [69, 69, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[13, 13, 8, 11, "named", "", false, false], [24, 24, 17, 22, "named", "", false, false], [34, 34, 28, 32, "named", "", false, false], [46, 46, 38, 44, "named", "", false, false], [57, 57, 49, 55, "named", "", false, false], [69, 69, 62, 67, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "has", "been", "elected", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "the", "American", "Association", "for", "Advancement", "of", "Science", "(", "AAAS", ")", ",", "and", "the", "Society", "for", "Optics", "and", "Photonics", "Technology", "(", "SPIE", ")", "."], "sentence-detokenized": "He has been elected a Fellow of the Association for Computing Machinery (ACM), the Institute of Electrical and Electronics Engineers (IEEE), the International Association for Pattern Recognition (IAPR), the Association for the Advancement of Artificial Intelligence (AAAI), the American Association for Advancement of Science (AAAS), and the Society for Optics and Photonics Technology (SPIE).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 21], [22, 28], [29, 31], [32, 35], [36, 47], [48, 51], [52, 61], [62, 71], [72, 73], [73, 76], [76, 77], [77, 78], [79, 82], [83, 92], [93, 95], [96, 106], [107, 110], [111, 122], [123, 132], [133, 134], [134, 138], [138, 139], [139, 140], [141, 144], [145, 158], [159, 170], [171, 174], [175, 182], [183, 194], [195, 196], [196, 200], [200, 201], [201, 202], [203, 206], [207, 218], [219, 222], [223, 226], [227, 238], [239, 241], [242, 252], [253, 265], [266, 267], [267, 271], [271, 272], [272, 273], [274, 277], [278, 286], [287, 298], [299, 302], [303, 314], [315, 317], [318, 325], [326, 327], [327, 331], [331, 332], [332, 333], [334, 337], [338, 341], [342, 349], [350, 353], [354, 360], [361, 364], [365, 374], [375, 385], [386, 387], [387, 391], [391, 392], [392, 393]]}
{"doc_key": "ai-dev-317", "ner": [[0, 1, "field"], [3, 4, "field"], [18, 20, "field"], [33, 34, "field"], [55, 58, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 18, 20, "named", "", false, false], [3, 4, 33, 34, "named", "", false, false], [33, 34, 55, 58, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "and", "data", "mining", "often", "use", "the", "same", "methods", "and", "there", "is", "considerable", "overlap", ",", "but", "while", "machine", "learning", "focuses", "on", "prediction", ",", "based", "on", "known", "properties", "learned", "from", "training", "data", ",", "data", "mining", "focuses", "on", "the", "discovery", "of", "(", "previously", ")", "unknown", "properties", "in", "the", "data", "(", "this", "is", "the", "analysis", "step", "of", "knowledge", "discovery", "in", "databases", ")", "."], "sentence-detokenized": "Machine learning and data mining often use the same methods and there is considerable overlap, but while machine learning focuses on prediction, based on known properties learned from training data, data mining focuses on the discovery of (previously) unknown properties in the data (this is the analysis step of knowledge discovery in databases).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 59], [60, 63], [64, 69], [70, 72], [73, 85], [86, 93], [93, 94], [95, 98], [99, 104], [105, 112], [113, 121], [122, 129], [130, 132], [133, 143], [143, 144], [145, 150], [151, 153], [154, 159], [160, 170], [171, 178], [179, 183], [184, 192], [193, 197], [197, 198], [199, 203], [204, 210], [211, 218], [219, 221], [222, 225], [226, 235], [236, 238], [239, 240], [240, 250], [250, 251], [252, 259], [260, 270], [271, 273], [274, 277], [278, 282], [283, 284], [284, 288], [289, 291], [292, 295], [296, 304], [305, 309], [310, 312], [313, 322], [323, 332], [333, 335], [336, 345], [345, 346], [346, 347]]}
{"doc_key": "ai-dev-318", "ner": [[0, 0, "product"], [4, 4, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 4, "general-affiliation", "", false, false], [0, 0, 4, 4, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "is", "written", "in", "Java", "and", "therefore", "runs", "on", "most", "modern", "operating", "systems", "."], "sentence-detokenized": "Indy is written in Java and therefore runs on most modern operating systems.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 23], [24, 27], [28, 37], [38, 42], [43, 45], [46, 50], [51, 57], [58, 67], [68, 75], [75, 76]]}
{"doc_key": "ai-dev-319", "ner": [[0, 0, "algorithm"], [5, 7, "algorithm"], [9, 9, "algorithm"], [15, 17, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 7, "type-of", "", true, false], [9, 9, 5, 7, "named", "", false, false], [15, 17, 5, 7, "type-of", "", true, false], [19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["NMF", "is", "an", "instance", "of", "non-negative", "quadratic", "programming", "(", "NQP", ")", ",", "as", "is", "the", "support", "vector", "machine", "(", "SVM", ")", "."], "sentence-detokenized": "NMF is an instance of non-negative quadratic programming (NQP), as is the support vector machine (SVM).", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 18], [19, 21], [22, 34], [35, 44], [45, 56], [57, 58], [58, 61], [61, 62], [62, 63], [64, 66], [67, 69], [70, 73], [74, 81], [82, 88], [89, 96], [97, 98], [98, 101], [101, 102], [102, 103]]}
{"doc_key": "ai-dev-320", "ner": [[7, 8, "misc"], [11, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 11, 11, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "method", "is", "based", "on", "estimating", "the", "conditional", "probabilities", "using", "the", "non-parametric", "maximum", "likelihood", "method", ",", "which", "leads"], "sentence-detokenized": "The method is based on estimating the conditional probabilities using the non-parametric maximum likelihood method, which leads", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 33], [34, 37], [38, 49], [50, 63], [64, 69], [70, 73], [74, 88], [89, 96], [97, 107], [108, 114], [114, 115], [116, 121], [122, 127]]}
{"doc_key": "ai-dev-321", "ner": [[8, 8, "algorithm"], [10, 13, "algorithm"], [15, 16, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "basic", "concepts", "involved", "in", "spectral", "estimation", "are", "autocorrelation", ",", "multi", "-D", "Fourier", "transform", ",", "mean-squared", "error", "and", "entropy", "."], "sentence-detokenized": "The basic concepts involved in spectral estimation are autocorrelation, multi-D Fourier transform, mean-squared error and entropy.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 27], [28, 30], [31, 39], [40, 50], [51, 54], [55, 70], [70, 71], [72, 77], [77, 79], [80, 87], [88, 97], [97, 98], [99, 111], [112, 117], [118, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-dev-322", "ner": [[4, 5, "algorithm"], [10, 10, "field"], [12, 12, "algorithm"], [14, 16, "algorithm"], [18, 19, "task"], [21, 21, "field"], [23, 23, "field"], [25, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[4, 5, 10, 10, "part-of", "", false, false], [4, 5, 12, 12, "part-of", "", false, false], [4, 5, 14, 16, "part-of", "", false, false], [4, 5, 18, 19, "part-of", "", false, false], [4, 5, 21, 21, "part-of", "", false, false], [4, 5, 23, 23, "part-of", "", false, false], [4, 5, 25, 26, "part-of", "", false, false], [4, 5, 28, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "application", "areas", "of", "kernel", "methods", "are", "diverse", "and", "include", "geostatistics", ",", "kriging", ",", "inverse", "distance", "weighting", ",", "3D", "reconstruction", ",", "bioinformatics", ",", "chemoinformatics", ",", "information", "extraction", "and", "handwriting", "recognition", "."], "sentence-detokenized": "The application areas of kernel methods are diverse and include geostatistics, kriging, inverse distance weighting, 3D reconstruction, bioinformatics, chemoinformatics, information extraction and handwriting recognition.", "token2charspan": [[0, 3], [4, 15], [16, 21], [22, 24], [25, 31], [32, 39], [40, 43], [44, 51], [52, 55], [56, 63], [64, 77], [77, 78], [79, 86], [86, 87], [88, 95], [96, 104], [105, 114], [114, 115], [116, 118], [119, 133], [133, 134], [135, 149], [149, 150], [151, 167], [167, 168], [169, 180], [181, 191], [192, 195], [196, 207], [208, 219], [219, 220]]}
{"doc_key": "ai-dev-323", "ner": [[12, 12, "organisation"], [14, 18, "product"], [20, 20, "product"], [23, 23, "organisation"], [25, 28, "product"], [30, 30, "product"], [33, 33, "product"], [36, 36, "product"], [40, 42, "product"], [44, 46, "product"], [50, 51, "product"], [53, 54, "product"], [57, 62, "product"], [66, 67, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[14, 18, 12, 12, "artifact", "", false, false], [14, 18, 33, 33, "compare", "", false, false], [14, 18, 36, 36, "compare", "", false, false], [14, 18, 40, 42, "compare", "", false, false], [14, 18, 44, 46, "compare", "", false, false], [14, 18, 50, 51, "compare", "", false, false], [14, 18, 53, 54, "compare", "", false, false], [14, 18, 57, 62, "compare", "", false, false], [14, 18, 66, 67, "compare", "", false, false], [20, 20, 14, 18, "named", "", false, false], [25, 28, 23, 23, "artifact", "", false, false], [25, 28, 33, 33, "compare", "", false, false], [25, 28, 36, 36, "compare", "", false, false], [25, 28, 40, 42, "compare", "", false, false], [25, 28, 44, 46, "compare", "", false, false], [25, 28, 50, 51, "compare", "", false, false], [25, 28, 53, 54, "compare", "", false, false], [25, 28, 57, 62, "compare", "", false, false], [25, 28, 66, 67, "compare", "", false, false], [30, 30, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Robots", "can", "be", "autonomous", "or", "semi-autonomous", "and", "range", "from", "humanoids", "such", "as", "Honda", "'s", "Advanced", "Step", "in", "Innovative", "Mobility", "(", "ASIMO", ")", "and", "TOSY", "'s", "Ping", "Pong", "Playing", "Robot", "(", "TOPIO", ")", "to", "industrial", "robots", ",", "medical", "surgical", "robots", ",", "patient", "support", "robots", ",", "dog", "therapy", "robots", ",", "collectively", "programmed", "swarm", "robots", ",", "UAV", "drones", "such", "as", "General", "Atomics", "MQ", "-", "1", "Predator", ",", "and", "even", "microscopic", "nanorobots", "."], "sentence-detokenized": "Robots can be autonomous or semi-autonomous and range from humanoids such as Honda's Advanced Step in Innovative Mobility (ASIMO) and TOSY's Ping Pong Playing Robot (TOPIO) to industrial robots, medical surgical robots, patient support robots, dog therapy robots, collectively programmed swarm robots, UAV drones such as General Atomics MQ-1 Predator, and even microscopic nanorobots.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 24], [25, 27], [28, 43], [44, 47], [48, 53], [54, 58], [59, 68], [69, 73], [74, 76], [77, 82], [82, 84], [85, 93], [94, 98], [99, 101], [102, 112], [113, 121], [122, 123], [123, 128], [128, 129], [130, 133], [134, 138], [138, 140], [141, 145], [146, 150], [151, 158], [159, 164], [165, 166], [166, 171], [171, 172], [173, 175], [176, 186], [187, 193], [193, 194], [195, 202], [203, 211], [212, 218], [218, 219], [220, 227], [228, 235], [236, 242], [242, 243], [244, 247], [248, 255], [256, 262], [262, 263], [264, 276], [277, 287], [288, 293], [294, 300], [300, 301], [302, 305], [306, 312], [313, 317], [318, 320], [321, 328], [329, 336], [337, 339], [339, 340], [340, 341], [342, 350], [350, 351], [352, 355], [356, 360], [361, 372], [373, 383], [383, 384]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 3, "product"], [9, 13, "university"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [24, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 15, 16, "artifact", "", false, false], [0, 0, 18, 19, "artifact", "", false, false], [0, 0, 21, 22, "artifact", "", false, false], [0, 0, 24, 29, "artifact", "", false, false], [2, 3, 15, 16, "artifact", "", false, false], [2, 3, 18, 19, "artifact", "", false, false], [2, 3, 21, 22, "artifact", "", false, false], [2, 3, 24, 29, "artifact", "", false, false], [15, 16, 9, 13, "physical", "", false, false], [18, 19, 9, 13, "physical", "", false, false], [21, 22, 9, 13, "physical", "", false, false], [24, 29, 9, 13, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "and", "Freddy", "II", "were", "robots", "built", "at", "Edinburgh", "University", "'s", "Computer", "Science", "School", "by", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "and", "Donald", "Mitchie", ",", "capable", "of", "assembling", "wooden", "blocks", "in", "a", "few", "hours", "."], "sentence-detokenized": "Freddy and Freddy II were robots built at Edinburgh University's Computer Science School by Pat Ambler, Robin Popplestone, Austin Tate and Donald Mitchie, capable of assembling wooden blocks in a few hours.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 25], [26, 32], [33, 38], [39, 41], [42, 51], [52, 62], [62, 64], [65, 73], [74, 81], [82, 88], [89, 91], [92, 95], [96, 102], [102, 103], [104, 109], [110, 121], [121, 122], [123, 129], [130, 134], [135, 138], [139, 145], [146, 153], [153, 154], [155, 162], [163, 165], [166, 176], [177, 183], [184, 190], [191, 193], [194, 195], [196, 199], [200, 205], [205, 206]]}
{"doc_key": "ai-dev-325", "ner": [[5, 5, "location"], [7, 7, "country"], [16, 16, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 7, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "spent", "his", "childhood", "in", "Paris", ",", "France", ",", "to", "which", "his", "parents", "had", "emigrated", "from", "Lithuania", "in", "the", "early", "1920s", "."], "sentence-detokenized": "He spent his childhood in Paris, France, to which his parents had emigrated from Lithuania in the early 1920s.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 22], [23, 25], [26, 31], [31, 32], [33, 39], [39, 40], [41, 43], [44, 49], [50, 53], [54, 61], [62, 65], [66, 75], [76, 80], [81, 90], [91, 93], [94, 97], [98, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-dev-326", "ner": [[2, 3, "researcher"], [6, 11, "misc"], [14, 17, "organisation"], [19, 21, "university"], [29, 33, "university"], [39, 40, "university"], [44, 46, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 3, 6, 11, "role", "", false, false], [2, 3, 19, 21, "physical", "", false, false], [2, 3, 29, 33, "role", "", false, false], [2, 3, 39, 40, "role", "", false, false], [2, 3, 44, 46, "role", "", false, false], [6, 11, 14, 17, "part-of", "", false, false], [14, 17, 19, 21, "part-of", "", false, false], [39, 40, 29, 33, "part-of", "", false, false], [44, 46, 29, 33, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Previously", ",", "Dr", "Paulos", "held", "the", "Cooper-", "Siegel", "Chair", "of", "Associate", "Professor", "in", "the", "School", "of", "Computer", "Science", "at", "Carnegie", "Mellon", "University", ",", "where", "he", "was", "faculty", "in", "the", "Human", "-", "Computer", "Interaction", "Institute", "with", "faculty", "appointments", "in", "the", "Robotics", "Institute", "and", "in", "the", "Entertainment", "Technology", "Centre", "."], "sentence-detokenized": "Previously, Dr Paulos held the Cooper-Siegel Chair of Associate Professor in the School of Computer Science at Carnegie Mellon University, where he was faculty in the Human-Computer Interaction Institute with faculty appointments in the Robotics Institute and in the Entertainment Technology Centre.", "token2charspan": [[0, 10], [10, 11], [12, 14], [15, 21], [22, 26], [27, 30], [31, 38], [38, 44], [45, 50], [51, 53], [54, 63], [64, 73], [74, 76], [77, 80], [81, 87], [88, 90], [91, 99], [100, 107], [108, 110], [111, 119], [120, 126], [127, 137], [137, 138], [139, 144], [145, 147], [148, 151], [152, 159], [160, 162], [163, 166], [167, 172], [172, 173], [173, 181], [182, 193], [194, 203], [204, 208], [209, 216], [217, 229], [230, 232], [233, 236], [237, 245], [246, 255], [256, 259], [260, 262], [263, 266], [267, 280], [281, 291], [292, 298], [298, 299]]}
{"doc_key": "ai-dev-327", "ner": [[7, 8, "researcher"], [4, 10, "university"], [11, 12, "product"], [19, 24, "product"], [29, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 4, 10, "physical", "", false, false], [7, 8, 4, 10, "role", "", false, false], [11, 12, 7, 8, "artifact", "", false, false], [11, 12, 19, 24, "type-of", "", false, false], [11, 12, 29, 30, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1969", ",", "at", "Stanford", "University", ",", "Victor", "Scheinman", "invented", "the", "Stanford", "arm", ",", "an", "all", "-", "electric", ",", "6", "-", "axis", ",", "articulating", "robot", "designed", "to", "enable", "an", "arm", "solution", "."], "sentence-detokenized": "In 1969, at Stanford University, Victor Scheinman invented the Stanford arm, an all-electric, 6-axis, articulating robot designed to enable an arm solution.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 20], [21, 31], [31, 32], [33, 39], [40, 49], [50, 58], [59, 62], [63, 71], [72, 75], [75, 76], [77, 79], [80, 83], [83, 84], [84, 92], [92, 93], [94, 95], [95, 96], [96, 100], [100, 101], [102, 114], [115, 120], [121, 129], [130, 132], [133, 139], [140, 142], [143, 146], [147, 155], [155, 156]]}
{"doc_key": "ai-dev-328", "ner": [[5, 5, "product"], [16, 17, "field"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 16, 17, "related-to", "", false, false], [5, 5, 19, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "creation", "and", "implementation", "of", "chatbots", "is", "still", "in", "full", "development", "and", "is", "closely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ",", "so", "the", "solutions", "offered", ",", "while", "offering", "clear", "advantages", ",", "have", "some", "significant", "limitations", "in", "terms", "of", "functionality", "and", "use", "cases", "."], "sentence-detokenized": "The creation and implementation of chatbots is still in full development and is closely related to artificial intelligence and machine learning, so the solutions offered, while offering clear advantages, have some significant limitations in terms of functionality and use cases.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 31], [32, 34], [35, 43], [44, 46], [47, 52], [53, 55], [56, 60], [61, 72], [73, 76], [77, 79], [80, 87], [88, 95], [96, 98], [99, 109], [110, 122], [123, 126], [127, 134], [135, 143], [143, 144], [145, 147], [148, 151], [152, 161], [162, 169], [169, 170], [171, 176], [177, 185], [186, 191], [192, 202], [202, 203], [204, 208], [209, 213], [214, 225], [226, 237], [238, 240], [241, 246], [247, 249], [250, 263], [264, 267], [268, 271], [272, 277], [277, 278]]}
{"doc_key": "ai-dev-329", "ner": [[7, 9, "university"], [11, 12, "product"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 7, 9, "part-of", "", true, false], [24, 25, 11, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "terms", "of", "freely", "available", "resources", ",", "Carnegie", "Mellon", "University", "'s", "Sphinx", "toolkit", "is", "a", "place", "to", "start", ",", "both", "to", "learn", "more", "about", "speech", "recognition", "and", "to", "experiment", "."], "sentence-detokenized": "In terms of freely available resources, Carnegie Mellon University's Sphinx toolkit is a place to start, both to learn more about speech recognition and to experiment.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 18], [19, 28], [29, 38], [38, 39], [40, 48], [49, 55], [56, 66], [66, 68], [69, 75], [76, 83], [84, 86], [87, 88], [89, 94], [95, 97], [98, 103], [103, 104], [105, 109], [110, 112], [113, 118], [119, 123], [124, 129], [130, 136], [137, 148], [149, 152], [153, 155], [156, 166], [166, 167]]}
{"doc_key": "ai-dev-330", "ner": [[2, 3, "misc"], [13, 19, "misc"], [21, 21, "misc"], [25, 25, "university"], [27, 27, "location"], [29, 29, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 13, 19, "temporal", "", false, false], [21, 21, 13, 19, "named", "", false, false], [21, 21, 27, 27, "physical", "", false, false], [25, 25, 21, 21, "role", "", false, false], [27, 27, 29, 29, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "formal", "RoboCup", "competition", "was", "preceded", "by", "the", "(", "often", "misunderstood", ")", "first", "International", "Micro", "Robot", "World", "Cup", "Soccer", "Tournament", "(", "MIROSOT", ")", "held", "by", "KAIST", "in", "Taejon", ",", "Korea", ",", "in", "November", "1996", "."], "sentence-detokenized": "The formal RoboCup competition was preceded by the (often misunderstood) first International Micro Robot World Cup Soccer Tournament (MIROSOT) held by KAIST in Taejon, Korea, in November 1996.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 30], [31, 34], [35, 43], [44, 46], [47, 50], [51, 52], [52, 57], [58, 71], [71, 72], [73, 78], [79, 92], [93, 98], [99, 104], [105, 110], [111, 114], [115, 121], [122, 132], [133, 134], [134, 141], [141, 142], [143, 147], [148, 150], [151, 156], [157, 159], [160, 166], [166, 167], [168, 173], [173, 174], [175, 177], [178, 186], [187, 191], [191, 192]]}
{"doc_key": "ai-dev-331", "ner": [[5, 6, "metrics"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "standard", "hinge", "loss", "maths", "(", "1-", "yf", "(", "x", ")", ")", "_", "+", "/", "maths", "for", "labelled", "data", ",", "a", "loss", "function", "math", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "math", "introduced", "over", "the", "unlabelled", "data", "by", "mathy", "=", "operator", "name", "{", "sign", "}", "{", "f", "(", "x", ")", "}", "/", "maths", "."], "sentence-detokenized": "In addition to the standard hinge loss maths (1-yf (x)) _ + / maths for labelled data, a loss function math (-1 | f (x) |) _ + / math introduced over the unlabelled data by mathy = operator name {sign} {f (x)} / maths.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 27], [28, 33], [34, 38], [39, 44], [45, 46], [46, 48], [48, 50], [51, 52], [52, 53], [53, 54], [54, 55], [56, 57], [58, 59], [60, 61], [62, 67], [68, 71], [72, 80], [81, 85], [85, 86], [87, 88], [89, 93], [94, 102], [103, 107], [108, 109], [109, 110], [110, 111], [112, 113], [114, 115], [116, 117], [117, 118], [118, 119], [120, 121], [121, 122], [123, 124], [125, 126], [127, 128], [129, 133], [134, 144], [145, 149], [150, 153], [154, 164], [165, 169], [170, 172], [173, 178], [179, 180], [181, 189], [190, 194], [195, 196], [196, 200], [200, 201], [202, 203], [203, 204], [205, 206], [206, 207], [207, 208], [208, 209], [210, 211], [212, 217], [217, 218]]}
{"doc_key": "ai-dev-332", "ner": [[3, 3, "misc"], [9, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 9, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "particular", ",", "RLS", "is", "designed", "to", "minimise", "the", "mean", "squared", "error", "between", "predicted", "values", "and", "TRUE", "labels", ",", "subject", "to", "regularisation", "."], "sentence-detokenized": "In particular, RLS is designed to minimise the mean squared error between predicted values and TRUE labels, subject to regularisation.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 21], [22, 30], [31, 33], [34, 42], [43, 46], [47, 51], [52, 59], [60, 65], [66, 73], [74, 83], [84, 90], [91, 94], [95, 99], [100, 106], [106, 107], [108, 115], [116, 118], [119, 133], [133, 134]]}
{"doc_key": "ai-dev-333", "ner": [[7, 9, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 12, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Essentially", ",", "this", "is", "a", "combination", "of", "maximum", "-likelihood", "estimation", "with", "a", "regularisation", "procedure", "that", "favours", "simpler", "models", "over", "more", "complex", "ones", "."], "sentence-detokenized": "Essentially, this is a combination of maximum-likelihood estimation with a regularisation procedure that favours simpler models over more complex ones.", "token2charspan": [[0, 11], [11, 12], [13, 17], [18, 20], [21, 22], [23, 34], [35, 37], [38, 45], [45, 56], [57, 67], [68, 72], [73, 74], [75, 89], [90, 99], [100, 104], [105, 112], [113, 120], [121, 127], [128, 132], [133, 137], [138, 145], [146, 150], [150, 151]]}
{"doc_key": "ai-dev-334", "ner": [[1, 4, "metrics"], [8, 8, "metrics"], [10, 10, "metrics"], [12, 13, "misc"], [17, 18, "misc"], [30, 32, "algorithm"], [35, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[8, 8, 1, 4, "named", "", false, false], [10, 10, 1, 4, "named", "", false, false], [12, 13, 17, 18, "related-to", "", false, false], [12, 13, 30, 32, "related-to", "ratio", false, false], [30, 32, 35, 37, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "percentage", "of", "true", "-positives", "is", "also", "called", "sensitivity", ",", "recall", "or", "detection", "probability", "up", "to", "the", "discrimination", "threshold", ")", "of", "the", "detection", "probability", "on", "the", "y", "-axis", "versus", "the", "cumulative", "distribution", "function", "of", "the", "false", "warning", "probability", "on", "the", "x-", "axis", "."], "sentence-detokenized": "The percentage of true-positives is also called sensitivity, recall or detection probability up to the discrimination threshold) of the detection probability on the y-axis versus the cumulative distribution function of the false warning probability on the x-axis.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 22], [22, 32], [33, 35], [36, 40], [41, 47], [48, 59], [59, 60], [61, 67], [68, 70], [71, 80], [81, 92], [93, 95], [96, 98], [99, 102], [103, 117], [118, 127], [127, 128], [129, 131], [132, 135], [136, 145], [146, 157], [158, 160], [161, 164], [165, 166], [166, 171], [172, 178], [179, 182], [183, 193], [194, 206], [207, 215], [216, 218], [219, 222], [223, 228], [229, 236], [237, 248], [249, 251], [252, 255], [256, 258], [258, 262], [262, 263]]}
{"doc_key": "ai-dev-335", "ner": [[1, 1, "misc"], [3, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 1, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "English", ",", "Word", "Net", "is", "an", "example", "of", "a", "semantic", "network", "."], "sentence-detokenized": "In English, WordNet is an example of a semantic network.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [16, 19], [20, 22], [23, 25], [26, 33], [34, 36], [37, 38], [39, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-dev-336", "ner": [[5, 7, "product"], [11, 12, "product"], [23, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 23, 5, 7, "usage", "", false, false], [23, 23, 11, 12, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "-", "term", "use", "of", "speech", "recognition", "software", "in", "combination", "with", "word", "processors", "has", "shown", "benefits", "for", "short", "-", "term", "memory", "enhancement", "in", "brain", "AVM", "patients", "treated", "with", "resection", "."], "sentence-detokenized": "Long-term use of speech recognition software in combination with word processors has shown benefits for short-term memory enhancement in brain AVM patients treated with resection.", "token2charspan": [[0, 4], [4, 5], [5, 9], [10, 13], [14, 16], [17, 23], [24, 35], [36, 44], [45, 47], [48, 59], [60, 64], [65, 69], [70, 80], [81, 84], [85, 90], [91, 99], [100, 103], [104, 109], [109, 110], [110, 114], [115, 121], [122, 133], [134, 136], [137, 142], [143, 146], [147, 155], [156, 163], [164, 168], [169, 178], [178, 179]]}
{"doc_key": "ai-dev-337", "ner": [[8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "founding", "editors", "-", "in", "-", "chief", "were", "Ron", "Sun", ",", "Vasant", "Honavar", "and", "Gregg", "Oden", "(", "from", "1999", "to", "2014", ")", "."], "sentence-detokenized": "The founding editors-in-chief were Ron Sun, Vasant Honavar and Gregg Oden (from 1999 to 2014).", "token2charspan": [[0, 3], [4, 12], [13, 20], [20, 21], [21, 23], [23, 24], [24, 29], [30, 34], [35, 38], [39, 42], [42, 43], [44, 50], [51, 58], [59, 62], [63, 68], [69, 73], [74, 75], [75, 79], [80, 84], [85, 87], [88, 92], [92, 93], [93, 94]]}
{"doc_key": "ai-dev-338", "ner": [[7, 8, "product"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 12, 13, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Their", "\"", "parallel", "\"", "distinction", "from", "a", "serial", "manipulator", "is", "that", "the", "end", "effector", "(", "or", "\"", "hand", "\"", ")", "of", "this", "coupler", "(", "or", "\"", "arm", "\"", ")", "is", "directly", "connected", "to", "its", "base", "by", "a", "number", "(", "usually", "three", "or", "six", ")", "of", "separate", "and", "independent", "couplers", "operating", "simultaneously", "."], "sentence-detokenized": "Their \"parallel\" distinction from a serial manipulator is that the end effector (or \"hand\") of this coupler (or \"arm\") is directly connected to its base by a number (usually three or six) of separate and independent couplers operating simultaneously.", "token2charspan": [[0, 5], [6, 7], [7, 15], [15, 16], [17, 28], [29, 33], [34, 35], [36, 42], [43, 54], [55, 57], [58, 62], [63, 66], [67, 70], [71, 79], [80, 81], [81, 83], [84, 85], [85, 89], [89, 90], [90, 91], [92, 94], [95, 99], [100, 107], [108, 109], [109, 111], [112, 113], [113, 116], [116, 117], [117, 118], [119, 121], [122, 130], [131, 140], [141, 143], [144, 147], [148, 152], [153, 155], [156, 157], [158, 164], [165, 166], [166, 173], [174, 179], [180, 182], [183, 186], [186, 187], [188, 190], [191, 199], [200, 203], [204, 215], [216, 224], [225, 234], [235, 249], [249, 250]]}
{"doc_key": "ai-dev-339", "ner": [[5, 6, "researcher"], [16, 17, "researcher"], [18, 20, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"], [28, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "thesis", "advisor", "was", "Professor", "Cordell", "Green", ",", "and", "his", "thesis", "/", "oral", "committee", "included", "Professors", "Edward", "Feigenbaum", ",", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", ",", "Herbert", "Simon", ",", "."], "sentence-detokenized": "His thesis advisor was Professor Cordell Green, and his thesis/ oral committee included Professors Edward Feigenbaum, Joshua Lederberg, Paul Cohen, Allen Newell, Herbert Simon,.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 22], [23, 32], [33, 40], [41, 46], [46, 47], [48, 51], [52, 55], [56, 62], [62, 63], [64, 68], [69, 78], [79, 87], [88, 98], [99, 105], [106, 116], [116, 117], [118, 124], [125, 134], [134, 135], [136, 140], [141, 146], [146, 147], [148, 153], [154, 160], [160, 161], [162, 169], [170, 175], [175, 176], [176, 177]]}
{"doc_key": "ai-dev-340", "ner": [[3, 5, "metrics"], [7, 9, "metrics"], [12, 13, "metrics"], [15, 17, "metrics"], [23, 23, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "functions", "include", "mean", "squared", "error", ",", "mean", "squared", "error", ",", "mean", "absolute", "error", ",", "relative", "squared", "error", ",", "relative", "squared", "error", ",", "relative", "absolute", "error", ",", "and", "others", "."], "sentence-detokenized": "Such functions include mean squared error, mean squared error, mean absolute error, relative squared error, relative squared error, relative absolute error, and others.", "token2charspan": [[0, 4], [5, 14], [15, 22], [23, 27], [28, 35], [36, 41], [41, 42], [43, 47], [48, 55], [56, 61], [61, 62], [63, 67], [68, 76], [77, 82], [82, 83], [84, 92], [93, 100], [101, 106], [106, 107], [108, 116], [117, 124], [125, 130], [130, 131], [132, 140], [141, 149], [150, 155], [155, 156], [157, 160], [161, 167], [167, 168]]}
{"doc_key": "ai-dev-341", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "bindings", "in", "Python", ",", "Java", "and", "MATLAB", "/", "OCTAVE", "."], "sentence-detokenized": "There are bindings in Python, Java and MATLAB / OCTAVE.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 21], [22, 28], [28, 29], [30, 34], [35, 38], [39, 45], [46, 47], [48, 54], [54, 55]]}
{"doc_key": "ai-dev-342", "ner": [[3, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "implementation", "in", "MATLAB", "can", "be", "found", "at", "the", "."], "sentence-detokenized": "An implementation in MATLAB can be found at the.", "token2charspan": [[0, 2], [3, 17], [18, 20], [21, 27], [28, 31], [32, 34], [35, 40], [41, 43], [44, 47], [47, 48]]}
{"doc_key": "ai-dev-343", "ner": [[0, 1, "researcher"], [9, 10, "field"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [24, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 10, 0, 1, "origin", "", false, false], [9, 10, 14, 15, "origin", "", false, false], [9, 10, 17, 18, "origin", "", false, false], [9, 10, 20, 21, "origin", "", false, false], [9, 10, 24, 27, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "is", "one", "of", "the", "founding", "fathers", "of", "artificial", "intelligence", ",", "along", "with", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "and", "Herbert", "A", ".", "Simon", "."], "sentence-detokenized": "John McCarthy is one of the founding fathers of artificial intelligence, along with Alan Turing, Marvin Minsky, Allen Newell, and Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 36], [37, 44], [45, 47], [48, 58], [59, 71], [71, 72], [73, 78], [79, 83], [84, 88], [89, 95], [95, 96], [97, 103], [104, 110], [110, 111], [112, 117], [118, 124], [124, 125], [126, 129], [130, 137], [138, 139], [139, 140], [141, 146], [146, 147]]}
{"doc_key": "ai-dev-344", "ner": [[10, 12, "product"], [19, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "parallel", "manipulator", "is", "a", "mechanical", "system", "that", "uses", "several", "serial", "manipulators", "to", "support", "a", "single", "platform", ",", "or", "end-effector", "."], "sentence-detokenized": "A parallel manipulator is a mechanical system that uses several serial manipulators to support a single platform, or end-effector.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 27], [28, 38], [39, 45], [46, 50], [51, 55], [56, 63], [64, 70], [71, 83], [84, 86], [87, 94], [95, 96], [97, 103], [104, 112], [112, 113], [114, 116], [117, 129], [129, 130]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [3, 4, "task"], [7, 7, "product"], [9, 15, "product"], [28, 28, "misc"], [31, 31, "misc"], [34, 35, "misc"], [37, 44, "task"], [45, 48, "product"], [51, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 7, 0, 0, "part-of", "", false, false], [7, 7, 3, 4, "type-of", "", false, false], [9, 15, 7, 7, "named", "", false, false], [28, 28, 7, 7, "part-of", "", false, false], [31, 31, 7, 7, "part-of", "", false, false], [34, 35, 7, 7, "part-of", "", false, false], [37, 44, 7, 7, "part-of", "", false, false], [45, 48, 7, 7, "part-of", "", false, false], [51, 52, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "includes", "an", "information", "extraction", "system", "called", "ANNIE", "(", "A", "Nearly", "-", "New", "Information", "Extraction", "System", ")", ",", "which", "consists", "of", "a", "set", "of", "modules", "consisting", "of", "a", "tokeniser", ",", "a", "gazetteer", ",", "a", "sentence", "splitter", ",", "Part", "-", "of", "-", "speech", "tagging", ",", "a", "Named", "entity", "recognition", "transducer", "and", "a", "coreference", "tagger", "."], "sentence-detokenized": "GATE includes an information extraction system called ANNIE (A Nearly-New Information Extraction System), which consists of a set of modules consisting of a tokeniser, a gazetteer, a sentence splitter, Part-of-speech tagging, a Named entity recognition transducer and a coreference tagger.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 28], [29, 39], [40, 46], [47, 53], [54, 59], [60, 61], [61, 62], [63, 69], [69, 70], [70, 73], [74, 85], [86, 96], [97, 103], [103, 104], [104, 105], [106, 111], [112, 120], [121, 123], [124, 125], [126, 129], [130, 132], [133, 140], [141, 151], [152, 154], [155, 156], [157, 166], [166, 167], [168, 169], [170, 179], [179, 180], [181, 182], [183, 191], [192, 200], [200, 201], [202, 206], [206, 207], [207, 209], [209, 210], [210, 216], [217, 224], [224, 225], [226, 227], [228, 233], [234, 240], [241, 252], [253, 263], [264, 267], [268, 269], [270, 281], [282, 288], [288, 289]]}
{"doc_key": "ai-dev-346", "ner": [[3, 5, "university"], [13, 14, "country"], [21, 24, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "graduated", "from", "Moscow", "State", "University", "and", "in", "November", "1978", "left", "for", "the", "United", "States", "thanks", "to", "the", "personal", "intervention", "of", "Senator", "Edward", "M.", "Kennedy", "..."], "sentence-detokenized": "He graduated from Moscow State University and in November 1978 left for the United States thanks to the personal intervention of Senator Edward M. Kennedy...", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 24], [25, 30], [31, 41], [42, 45], [46, 48], [49, 57], [58, 62], [63, 67], [68, 71], [72, 75], [76, 82], [83, 89], [90, 96], [97, 99], [100, 103], [104, 112], [113, 125], [126, 128], [129, 136], [137, 143], [144, 146], [147, 154], [154, 157]]}
{"doc_key": "ai-dev-347", "ner": [[4, 5, "organisation"], [9, 13, "misc"], [18, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 9, 13, "win-defeat", "", false, false], [9, 13, 18, 18, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "the", "DeepMind", "AlphaGo", "team", "received", "the", "inaugural", "IJCAI", "Marvin", "Minsky", "Medal", "for", "Outstanding", "Achievements", "in", "AI", "."], "sentence-detokenized": "In 2017, the DeepMind AlphaGo team received the inaugural IJCAI Marvin Minsky Medal for Outstanding Achievements in AI.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 21], [22, 29], [30, 34], [35, 43], [44, 47], [48, 57], [58, 63], [64, 70], [71, 77], [78, 83], [84, 87], [88, 99], [100, 112], [113, 115], [116, 118], [118, 119]]}
{"doc_key": "ai-dev-348", "ner": [[4, 5, "misc"], [10, 10, "misc"], [15, 15, "misc"], [24, 25, "misc"], [30, 30, "misc"], [36, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 10, 10, "related-to", "is_recorded_by", false, false], [10, 10, 15, 15, "cause-effect", "", false, false], [10, 10, 15, 15, "physical", "", false, false], [10, 10, 24, 25, "physical", "", false, false], [10, 10, 36, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "ways", "in", "which", "anomalous", "propagation", "is", "recorded", "is", "by", "troposcatters", "causing", "irregularities", "in", "the", "troposphere", ",", "scattering", "by", "meteors", ",", "refraction", "in", "the", "ionised", "regions", "and", "layers", "of", "the", "ionosphere", ",", "and", "reflection", "from", "the", "ionosphere", "."], "sentence-detokenized": "Other ways in which anomalous propagation is recorded is by troposcatters causing irregularities in the troposphere, scattering by meteors, refraction in the ionised regions and layers of the ionosphere, and reflection from the ionosphere.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 19], [20, 29], [30, 41], [42, 44], [45, 53], [54, 56], [57, 59], [60, 73], [74, 81], [82, 96], [97, 99], [100, 103], [104, 115], [115, 116], [117, 127], [128, 130], [131, 138], [138, 139], [140, 150], [151, 153], [154, 157], [158, 165], [166, 173], [174, 177], [178, 184], [185, 187], [188, 191], [192, 202], [202, 203], [204, 207], [208, 218], [219, 223], [224, 227], [228, 238], [238, 239]]}
{"doc_key": "ai-dev-349", "ner": [[0, 2, "field"], [4, 4, "field"], [10, 10, "field"], [12, 13, "field"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 10, 10, "part-of", "", false, false], [0, 2, 12, 13, "part-of", "", false, false], [0, 2, 15, 16, "part-of", "", false, false], [0, 2, 18, 19, "part-of", "", false, false], [4, 4, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Natural", "language", "processing", "(", "NLP", ")", "is", "a", "subfield", "of", "linguistics", ",", "computer", "science", ",", "computer", "science", "and", "artificial", "intelligence", "that", "deals", "with", "the", "interaction", "between", "computers", "and", "human", "(", "natural", ")", "languages", ",", "particularly", "how", "computers", "can", "be", "programmed", "to", "process", "and", "analyse", "large", "amounts", "of", "data", "in", "natural", "language", "."], "sentence-detokenized": "Natural language processing (NLP) is a subfield of linguistics, computer science, computer science and artificial intelligence that deals with the interaction between computers and human (natural) languages, particularly how computers can be programmed to process and analyse large amounts of data in natural language.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [29, 32], [32, 33], [34, 36], [37, 38], [39, 47], [48, 50], [51, 62], [62, 63], [64, 72], [73, 80], [80, 81], [82, 90], [91, 98], [99, 102], [103, 113], [114, 126], [127, 131], [132, 137], [138, 142], [143, 146], [147, 158], [159, 166], [167, 176], [177, 180], [181, 186], [187, 188], [188, 195], [195, 196], [197, 206], [206, 207], [208, 220], [221, 224], [225, 234], [235, 238], [239, 241], [242, 252], [253, 255], [256, 263], [264, 267], [268, 275], [276, 281], [282, 289], [290, 292], [293, 297], [298, 300], [301, 308], [309, 317], [317, 318]]}
{"doc_key": "ai-dev-350", "ner": [[8, 9, "organisation"], [12, 13, "organisation"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "active", "youth", "-", "led", "climate", "groups", "include", "Extinction", "Rebellion", ",", "the", "Sunrise", "Movement", ",", "SustainUS", "and", "others", "working", "at", "both", "transnational", "and", "local", "levels", "."], "sentence-detokenized": "Other active youth-led climate groups include Extinction Rebellion, the Sunrise Movement, SustainUS and others working at both transnational and local levels.", "token2charspan": [[0, 5], [6, 12], [13, 18], [18, 19], [19, 22], [23, 30], [31, 37], [38, 45], [46, 56], [57, 66], [66, 67], [68, 71], [72, 79], [80, 88], [88, 89], [90, 99], [100, 103], [104, 110], [111, 118], [119, 121], [122, 126], [127, 140], [141, 144], [145, 150], [151, 157], [157, 158]]}
