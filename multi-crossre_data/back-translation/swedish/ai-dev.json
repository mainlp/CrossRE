{"doc_key": "ai-dev-1", "ner": [[2, 2, "metrics"], [7, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 2, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Here", ",", "accuracy", "is", "measured", "by", "the", "error", "rate", ",", "which", "is", "defined", "as", ":"], "sentence-detokenized": "Here, accuracy is measured by the error rate, which is defined as:", "token2charspan": [[0, 4], [4, 5], [6, 14], [15, 17], [18, 26], [27, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 51], [52, 54], [55, 62], [63, 65], [65, 66]]}
{"doc_key": "ai-dev-2", "ner": [[4, 4, "algorithm"], [11, 14, "misc"], [16, 23, "algorithm"], [17, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 11, 14, "type-of", "", false, false], [4, 4, 16, 23, "related-to", "", false, false], [4, 4, 17, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["From", "this", "perspective", ",", "SVM", "is", "closely", "related", "to", "other", "basic", "classification", "algorithms", ",", "such", "as", "regularized", "logistic", "regression", "with", "the", "least", "squares", "method", "."], "sentence-detokenized": "From this perspective, SVM is closely related to other basic classification algorithms, such as regularized logistic regression with the least squares method.", "token2charspan": [[0, 4], [5, 9], [10, 21], [21, 22], [23, 26], [27, 29], [30, 37], [38, 45], [46, 48], [49, 54], [55, 60], [61, 75], [76, 86], [86, 87], [88, 92], [93, 95], [96, 107], [108, 116], [117, 127], [128, 132], [133, 136], [137, 142], [143, 150], [151, 157], [157, 158]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [3, 4, "person"], [13, 14, "person"], [16, 16, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 0, 1, "named", "actor_plays_character", false, false], [3, 4, 0, 1, "origin", "actor_plays_character", false, false], [16, 16, 13, 14, "named", "actor_plays_character", false, false], [16, 16, 13, 14, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "plays", "Leon", "Kowalski", ",", "a", "fighting", "and", "working", "replicant", ",", "and", "Joanna", "Cassidy", "plays", "Zhora", ",", "a", "replicant", "assassin", "."], "sentence-detokenized": "Brion James plays Leon Kowalski, a fighting and working replicant, and Joanna Cassidy plays Zhora, a replicant assassin.", "token2charspan": [[0, 5], [6, 11], [12, 17], [18, 22], [23, 31], [31, 32], [33, 34], [35, 43], [44, 47], [48, 55], [56, 65], [65, 66], [67, 70], [71, 77], [78, 85], [86, 91], [92, 97], [97, 98], [99, 100], [101, 110], [111, 119], [119, 120]]}
{"doc_key": "ai-dev-4", "ner": [[17, 20, "product"], [22, 22, "product"], [25, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 20, 25, 25, "physical", "", false, false], [22, 22, 17, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "image", "to", "be", "scanned", ",", "stored", "and", "reproduced", "in", "digital", "pixels", "was", "displayed", "on", "the", "Standards", "Eastern", "Automatic", "Computer", "(", "SEAC", ")", "at", "NIST", "."], "sentence-detokenized": "The first image to be scanned, stored and reproduced in digital pixels was displayed on the Standards Eastern Automatic Computer (SEAC) at NIST.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 18], [19, 21], [22, 29], [29, 30], [31, 37], [38, 41], [42, 52], [53, 55], [56, 63], [64, 70], [71, 74], [75, 84], [85, 87], [88, 91], [92, 101], [102, 109], [110, 119], [120, 128], [129, 130], [130, 134], [134, 135], [136, 138], [139, 143], [143, 144]]}
{"doc_key": "ai-dev-5", "ner": [[0, 6, "task"], [20, 21, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 20, 21, "part-of", "", false, false], [0, 6, 23, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Segmenting", "text", "into", "topics", "or", "discourse", "turns", "can", "be", "useful", "in", "some", "natural", "processing", "tasks", ":", "it", "can", "significantly", "improve", "information", "retrieval", "or", "speech", "recognition", "(", "by", "indexing", "/", "recognizing", "documents", "more", "accurately", "or", "by", "providing", "the", "specific", "part", "of", "a", "document", "corresponding", "to", "the", "query", "as", "a", "result", ")", "."], "sentence-detokenized": "Segmenting text into topics or discourse turns can be useful in some natural processing tasks: it can significantly improve information retrieval or speech recognition (by indexing/recognizing documents more accurately or by providing the specific part of a document corresponding to the query as a result).", "token2charspan": [[0, 10], [11, 15], [16, 20], [21, 27], [28, 30], [31, 40], [41, 46], [47, 50], [51, 53], [54, 60], [61, 63], [64, 68], [69, 76], [77, 87], [88, 93], [93, 94], [95, 97], [98, 101], [102, 115], [116, 123], [124, 135], [136, 145], [146, 148], [149, 155], [156, 167], [168, 169], [169, 171], [172, 180], [180, 181], [181, 192], [193, 202], [203, 207], [208, 218], [219, 221], [222, 224], [225, 234], [235, 238], [239, 247], [248, 252], [253, 255], [256, 257], [258, 266], [267, 280], [281, 283], [284, 287], [288, 293], [294, 296], [297, 298], [299, 305], [305, 306], [306, 307]]}
{"doc_key": "ai-dev-6", "ner": [[1, 2, "university"], [21, 22, "conference"], [24, 27, "university"], [34, 35, "researcher"], [37, 38, "researcher"], [40, 41, "researcher"], [43, 44, "researcher"], [46, 47, "researcher"], [49, 50, "researcher"], [52, 54, "researcher"], [56, 57, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[21, 22, 24, 27, "physical", "", false, false], [34, 35, 21, 22, "physical", "", false, false], [34, 35, 21, 22, "role", "", false, false], [34, 35, 21, 22, "temporal", "", false, false], [37, 38, 21, 22, "physical", "", false, false], [37, 38, 21, 22, "role", "", false, false], [37, 38, 21, 22, "temporal", "", false, false], [40, 41, 21, 22, "physical", "", false, false], [40, 41, 21, 22, "role", "", false, false], [40, 41, 21, 22, "temporal", "", false, false], [43, 44, 21, 22, "physical", "", false, false], [43, 44, 21, 22, "role", "", false, false], [43, 44, 21, 22, "temporal", "", false, false], [46, 47, 21, 22, "physical", "", false, false], [46, 47, 21, 22, "role", "", false, false], [46, 47, 21, 22, "temporal", "", false, false], [49, 50, 21, 22, "physical", "", false, false], [49, 50, 21, 22, "role", "", false, false], [49, 50, 21, 22, "temporal", "", false, false], [52, 54, 21, 22, "physical", "", false, false], [52, 54, 21, 22, "role", "", false, false], [52, 54, 21, 22, "temporal", "", false, false], [56, 57, 21, 22, "physical", "", false, false], [56, 57, 21, 22, "role", "", false, false], [56, 57, 21, 22, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["At", "Indiana", "University", "in", "1999", "he", "organised", "such", "a", "symposium", ",", "and", "in", "April", "2000", "he", "organised", "a", "major", "symposium", "entitled", "Spiritual", "Robots", "at", "Stanford", "University", ",", "where", "he", "led", "a", "panel", "consisting", "of", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", "and", "John", "Koza", "."], "sentence-detokenized": "At Indiana University in 1999 he organised such a symposium, and in April 2000 he organised a major symposium entitled Spiritual Robots at Stanford University, where he led a panel consisting of Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland and John Koza.", "token2charspan": [[0, 2], [3, 10], [11, 21], [22, 24], [25, 29], [30, 32], [33, 42], [43, 47], [48, 49], [50, 59], [59, 60], [61, 64], [65, 67], [68, 73], [74, 78], [79, 81], [82, 91], [92, 93], [94, 99], [100, 109], [110, 118], [119, 128], [129, 135], [136, 138], [139, 147], [148, 158], [158, 159], [160, 165], [166, 168], [169, 172], [173, 174], [175, 180], [181, 191], [192, 194], [195, 198], [199, 207], [207, 208], [209, 213], [214, 221], [221, 222], [223, 228], [229, 234], [234, 235], [236, 241], [242, 248], [248, 249], [250, 254], [255, 258], [258, 259], [260, 265], [266, 271], [271, 272], [273, 277], [278, 283], [284, 291], [292, 295], [296, 300], [301, 305], [305, 306]]}
{"doc_key": "ai-dev-7", "ner": [[6, 6, "metrics"], [7, 7, "metrics"], [10, 10, "metrics"], [11, 11, "metrics"], [20, 20, "metrics"], [42, 42, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 20, 20, "named", "", false, false], [7, 7, 6, 6, "named", "", false, false], [10, 10, 42, 42, "named", "", false, false], [11, 11, 10, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "takes", "into", "account", "both", "the", "precision", "p", "and", "the", "recall", "r", "of", "the", "test", "to", "calculate", "the", "score", ":", "p", "is", "the", "number", "of", "correct", "positive", "results", "divided", "by", "the", "number", "of", "all", "positive", "results", "returned", "by", "the", "classifier", ",", "and", "r", "is", "the", "number", "of", "correct", "positive", "results", "divided", "by", "the", "number", "of", "all", "relevant", "samples", "(", "all", "samples", "that", "should", "have", "been", "identified", "as", "positive", ")", "."], "sentence-detokenized": "It takes into account both the precision p and the recall r of the test to calculate the score: p is the number of correct positive results divided by the number of all positive results returned by the classifier, and r is the number of correct positive results divided by the number of all relevant samples (all samples that should have been identified as positive).", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 21], [22, 26], [27, 30], [31, 40], [41, 42], [43, 46], [47, 50], [51, 57], [58, 59], [60, 62], [63, 66], [67, 71], [72, 74], [75, 84], [85, 88], [89, 94], [94, 95], [96, 97], [98, 100], [101, 104], [105, 111], [112, 114], [115, 122], [123, 131], [132, 139], [140, 147], [148, 150], [151, 154], [155, 161], [162, 164], [165, 168], [169, 177], [178, 185], [186, 194], [195, 197], [198, 201], [202, 212], [212, 213], [214, 217], [218, 219], [220, 222], [223, 226], [227, 233], [234, 236], [237, 244], [245, 253], [254, 261], [262, 269], [270, 272], [273, 276], [277, 283], [284, 286], [287, 290], [291, 299], [300, 307], [308, 309], [309, 312], [313, 320], [321, 325], [326, 332], [333, 337], [338, 342], [343, 353], [354, 356], [357, 365], [365, 366], [366, 367]]}
{"doc_key": "ai-dev-8", "ner": [[1, 2, "organisation"], [25, 27, "product"], [33, 34, "person"], [40, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 25, 27, "artifact", "", false, false], [25, 27, 33, 34, "win-defeat", "", false, false], [25, 27, 40, 40, "win-defeat", "", true, false], [33, 34, 40, 40, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "Google", "'s", "acquisition", ",", "the", "company", "has", "achieved", "a", "number", "of", "significant", "results", ",", "perhaps", "the", "most", "notable", "of", "which", "is", "the", "creation", "of", "AlphaGo", ",", "a", "program", "that", "defeated", "world", "champion", "Lee", "Sedol", "in", "the", "complex", "game", "of", "Go", "."], "sentence-detokenized": "Since Google's acquisition, the company has achieved a number of significant results, perhaps the most notable of which is the creation of AlphaGo, a program that defeated world champion Lee Sedol in the complex game of Go.", "token2charspan": [[0, 5], [6, 12], [12, 14], [15, 26], [26, 27], [28, 31], [32, 39], [40, 43], [44, 52], [53, 54], [55, 61], [62, 64], [65, 76], [77, 84], [84, 85], [86, 93], [94, 97], [98, 102], [103, 110], [111, 113], [114, 119], [120, 122], [123, 126], [127, 135], [136, 138], [139, 146], [146, 147], [148, 149], [150, 157], [158, 162], [163, 171], [172, 177], [178, 186], [187, 190], [191, 196], [197, 199], [200, 203], [204, 211], [212, 216], [217, 219], [220, 222], [222, 223]]}
{"doc_key": "ai-dev-9", "ner": [[14, 15, "misc"], [32, 34, "product"], [53, 54, "misc"], [58, 59, "misc"], [62, 62, "product"]], "ner_mapping_to_source": [0, 2, 3, 4, 5], "relations": [[14, 15, 58, 59, "named", "same", false, false], [32, 34, 53, 54, "related-to", "", false, false], [32, 34, 58, 59, "usage", "", false, false], [32, 34, 62, 62, "usage", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4], "sentence": ["Representing", "words", "with", "respect", "to", "their", "context", "by", "dense", "fixed", "-", "size", "vectors", "(", "word", "embeddings", ")", "has", "become", "one", "of", "the", "most", "fundamental", "blocks", "in", "several", "NLP", "systems", ".", "In", "an", "unsupervised", "discrimination", "system", ",", "the", "similarity", "between", "word", "sensors", "in", "a", "fixed", "context", "window", "is", "used", "to", "select", "the", "most", "appropriate", "word", "sensor", "using", "a", "pre-trained", "word", "embedding", "model", "and", "WordNet", "."], "sentence-detokenized": "Representing words with respect to their context by dense fixed-size vectors (word embeddings) has become one of the most fundamental blocks in several NLP systems. In an unsupervised discrimination system, the similarity between word sensors in a fixed context window is used to select the most appropriate word sensor using a pre-trained word embedding model and WordNet.", "token2charspan": [[0, 12], [13, 18], [19, 23], [24, 31], [32, 34], [35, 40], [41, 48], [49, 51], [52, 57], [58, 63], [63, 64], [64, 68], [69, 76], [77, 78], [78, 82], [83, 93], [93, 94], [95, 98], [99, 105], [106, 109], [110, 112], [113, 116], [117, 121], [122, 133], [134, 140], [141, 143], [144, 151], [152, 155], [156, 163], [163, 164], [165, 167], [168, 170], [171, 183], [184, 198], [199, 205], [205, 206], [207, 210], [211, 221], [222, 229], [230, 234], [235, 242], [243, 245], [246, 247], [248, 253], [254, 261], [262, 268], [269, 271], [272, 276], [277, 279], [280, 286], [287, 290], [291, 295], [296, 307], [308, 312], [313, 319], [320, 325], [326, 327], [328, 339], [340, 344], [345, 354], [355, 360], [361, 364], [365, 372], [372, 373]]}
{"doc_key": "ai-dev-10", "ner": [[0, 2, "field"], [5, 5, "field"], [7, 8, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 2, "part-of", "", false, false], [7, 8, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "techniques", ",", "either", "supervised", "or", "unsupervised", "learning", ",", "have", "been", "used", "to", "create", "such", "rules", "automatically", "."], "sentence-detokenized": "Machine learning techniques, either supervised or unsupervised learning, have been used to create such rules automatically.", "token2charspan": [[0, 7], [8, 16], [17, 27], [27, 28], [29, 35], [36, 46], [47, 49], [50, 62], [63, 71], [71, 72], [73, 77], [78, 82], [83, 87], [88, 90], [91, 97], [98, 102], [103, 108], [109, 122], [122, 123]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1969", ",", "Scheinman", "invented", "the", "Stanford", "arm", ","], "sentence-detokenized": "In 1969, Scheinman invented the Stanford arm,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 27], [28, 31], [32, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-dev-12", "ner": [[1, 3, "metrics"], [8, 11, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "the", "log", "loss", "is", "differentiable", ",", "a", "gradient", "-", "based", "approach", "can", "be", "used", "to", "optimize", "the", "model", "."], "sentence-detokenized": "Since the log loss is differentiable, a gradient-based approach can be used to optimize the model.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 18], [19, 21], [22, 36], [36, 37], [38, 39], [40, 48], [48, 49], [49, 54], [55, 63], [64, 67], [68, 70], [71, 75], [76, 78], [79, 87], [88, 91], [92, 97], [97, 98]]}
{"doc_key": "ai-dev-13", "ner": [[1, 2, "field"], [4, 6, "algorithm"], [8, 8, "algorithm"], [11, 13, "algorithm"], [16, 16, "field"], [27, 27, "task"], [29, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 6, 16, 16, "part-of", "", false, false], [8, 8, 4, 6, "named", "", false, false], [11, 13, 4, 6, "named", "", false, false], [16, 16, 1, 2, "part-of", "subfield", false, false], [27, 27, 16, 16, "part-of", "", false, false], [29, 30, 16, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "machine", "learning", ",", "support", "vector", "machines", "(", "SVMs", ",", "also", "support", "vector", "networks", ")", "are", "supervised", "learning", "models", "with", "learning", "algorithms", "that", "analyze", "data", "used", "for", "classification", "and", "regression", "analysis", "."], "sentence-detokenized": "In machine learning, support vector machines (SVMs, also support vector networks) are supervised learning models with learning algorithms that analyze data used for classification and regression analysis.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 28], [29, 35], [36, 44], [45, 46], [46, 50], [50, 51], [52, 56], [57, 64], [65, 71], [72, 80], [80, 81], [82, 85], [86, 96], [97, 105], [106, 112], [113, 117], [118, 126], [127, 137], [138, 142], [143, 150], [151, 155], [156, 160], [161, 164], [165, 179], [180, 183], [184, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-dev-14", "ner": [[10, 11, "task"], [26, 26, "metrics"], [28, 28, "metrics"], [30, 30, "researcher"], [32, 32, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "(", "2002", ")", "as", "an", "automatic", "measure", "for", "evaluating", "machine", "translation", ",", "many", "other", "methods", "have", "been", "proposed", "to", "revise", "or", "improve", "it", ",", "e.g.", "TER", ",", "METEOR", ",", "Banerjee", "and", "Lavie", ",", "(", "2005", ")", "etc", "."], "sentence-detokenized": ", (2002) as an automatic measure for evaluating machine translation, many other methods have been proposed to revise or improve it, e.g. TER, METEOR, Banerjee and Lavie, (2005) etc.", "token2charspan": [[0, 1], [2, 3], [3, 7], [7, 8], [9, 11], [12, 14], [15, 24], [25, 32], [33, 36], [37, 47], [48, 55], [56, 67], [67, 68], [69, 73], [74, 79], [80, 87], [88, 92], [93, 97], [98, 106], [107, 109], [110, 116], [117, 119], [120, 127], [128, 130], [130, 131], [132, 136], [137, 140], [140, 141], [142, 148], [148, 149], [150, 158], [159, 162], [163, 168], [168, 169], [170, 171], [171, 175], [175, 176], [177, 180], [180, 181]]}
{"doc_key": "ai-dev-15", "ner": [[3, 4, "misc"], [9, 9, "organisation"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[3, 4, 9, 9, "origin", "", false, false], [15, 16, 9, 9, "role", "", false, false], [18, 19, 9, 9, "role", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["It", "contains", "an", "upper", "ontology", "created", "by", "the", "IEEE", "P1600.1", "working", "group", "(", "originally", "by", "Ian", "Niles", "and", "Adam", "Pease", ")", "."], "sentence-detokenized": "It contains an upper ontology created by the IEEE P1600.1 working group (originally by Ian Niles and Adam Pease).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 20], [21, 29], [30, 37], [38, 40], [41, 44], [45, 49], [50, 57], [58, 65], [66, 71], [72, 73], [73, 83], [84, 86], [87, 90], [91, 96], [97, 100], [101, 105], [106, 111], [111, 112], [112, 113]]}
{"doc_key": "ai-dev-16", "ner": [[1, 5, "misc"], [32, 34, "algorithm"], [36, 37, "algorithm"], [40, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[32, 34, 1, 5, "part-of", "", true, false], [36, 37, 1, 5, "part-of", "", true, false], [40, 41, 36, 37, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "cryo-electron", "tomography", ",", "where", "a", "limited", "number", "of", "projections", "are", "acquired", "due", "to", "hardware", "limitations", "and", "to", "avoid", "damage", "to", "the", "biological", "sample", ",", "it", "can", "be", "used", "in", "conjunction", "with", "compressive", "sensing", "techniques", "or", "control", "features", "(", "e.g.", "Huber", "loss", ")", "to", "improve", "the", "reconstruction", "and", "obtain", "a", "better", "interpretation", "."], "sentence-detokenized": "In cryo-electron tomography, where a limited number of projections are acquired due to hardware limitations and to avoid damage to the biological sample, it can be used in conjunction with compressive sensing techniques or control features (e.g. Huber loss) to improve the reconstruction and obtain a better interpretation.", "token2charspan": [[0, 2], [3, 16], [17, 27], [27, 28], [29, 34], [35, 36], [37, 44], [45, 51], [52, 54], [55, 66], [67, 70], [71, 79], [80, 83], [84, 86], [87, 95], [96, 107], [108, 111], [112, 114], [115, 120], [121, 127], [128, 130], [131, 134], [135, 145], [146, 152], [152, 153], [154, 156], [157, 160], [161, 163], [164, 168], [169, 171], [172, 183], [184, 188], [189, 200], [201, 208], [209, 219], [220, 222], [223, 230], [231, 239], [240, 241], [241, 245], [246, 251], [252, 256], [256, 257], [258, 260], [261, 268], [269, 272], [273, 287], [288, 291], [292, 298], [299, 300], [301, 307], [308, 322], [322, 323]]}
{"doc_key": "ai-dev-17", "ner": [[7, 7, "programlang"], [10, 11, "algorithm"], [13, 14, "algorithm"], [17, 18, "algorithm"], [24, 26, "product"], [29, 29, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [[24, 26, 7, 7, "general-affiliation", "", true, false], [24, 26, 7, 7, "part-of", "", true, false], [29, 29, 24, 26, "role", "publishes", false, false]], "relations_mapping_to_source": [4, 5, 6], "sentence": ["An", "implementation", "of", "several", "bleaching", "procedures", "in", "R", ",", "including", "ZCA", "bleaching", "and", "PCA", "bleaching", "but", "also", "CCA", "bleaching", ",", "is", "available", "in", "the", "R", "whitening", "package", "published", "on", "CRAN", "."], "sentence-detokenized": "An implementation of several bleaching procedures in R, including ZCA bleaching and PCA bleaching but also CCA bleaching, is available in the R whitening package published on CRAN.", "token2charspan": [[0, 2], [3, 17], [18, 20], [21, 28], [29, 38], [39, 49], [50, 52], [53, 54], [54, 55], [56, 65], [66, 69], [70, 79], [80, 83], [84, 87], [88, 97], [98, 101], [102, 106], [107, 110], [111, 120], [120, 121], [122, 124], [125, 134], [135, 137], [138, 141], [142, 143], [144, 153], [154, 161], [162, 171], [172, 174], [175, 179], [179, 180]]}
{"doc_key": "ai-dev-18", "ner": [[28, 28, "product"], [30, 30, "product"], [32, 32, "product"], [34, 34, "product"], [36, 36, "product"], [38, 38, "product"], [41, 42, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[28, 28, 32, 32, "compare", "", false, false], [28, 28, 34, 34, "compare", "", false, false], [28, 28, 36, 36, "compare", "", false, false], [28, 28, 38, 38, "compare", "", false, false], [28, 28, 41, 42, "compare", "", false, false], [30, 30, 32, 32, "compare", "", false, false], [30, 30, 34, 34, "compare", "", false, false], [30, 30, 36, 36, "compare", "", false, false], [30, 30, 38, 38, "compare", "", false, false], [30, 30, 41, 42, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Today", ",", "the", "field", "has", "become", "even", "more", "daunting", "and", "complex", "with", "the", "advent", "of", "circuit", ",", "system", "and", "signal", "analysis", "and", "design", "languages", "and", "software", ",", "from", "MATLAB", "and", "Simulink", "to", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "and", "even", "assembly", "languages", "."], "sentence-detokenized": "Today, the field has become even more daunting and complex with the advent of circuit, system and signal analysis and design languages and software, from MATLAB and Simulink to NumPy, VHDL, PSpice, Verilog and even assembly languages.", "token2charspan": [[0, 5], [5, 6], [7, 10], [11, 16], [17, 20], [21, 27], [28, 32], [33, 37], [38, 46], [47, 50], [51, 58], [59, 63], [64, 67], [68, 74], [75, 77], [78, 85], [85, 86], [87, 93], [94, 97], [98, 104], [105, 113], [114, 117], [118, 124], [125, 134], [135, 138], [139, 147], [147, 148], [149, 153], [154, 160], [161, 164], [165, 173], [174, 176], [177, 182], [182, 183], [184, 188], [188, 189], [190, 196], [196, 197], [198, 205], [206, 209], [210, 214], [215, 223], [224, 233], [233, 234]]}
{"doc_key": "ai-dev-19", "ner": [[5, 6, "person"], [16, 18, "person"], [19, 20, "organisation"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 20, 16, 18, "origin", "", false, false], [24, 24, 19, 20, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "company", "was", "founded", "by", "Kiichiro", "Toyoda", "in", "1937", ",", "as", "a", "spin", "-", "off", "from", "Sakichi", "Toyoda", "'s", "Toyota", "Industries", "company", "to", "create", "cars", "."], "sentence-detokenized": "The company was founded by Kiichiro Toyoda in 1937, as a spin-off from Sakichi Toyoda's Toyota Industries company to create cars.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 35], [36, 42], [43, 45], [46, 50], [50, 51], [52, 54], [55, 56], [57, 61], [61, 62], [62, 65], [66, 70], [71, 78], [79, 85], [85, 87], [88, 94], [95, 105], [106, 113], [114, 116], [117, 123], [124, 128], [128, 129]]}
{"doc_key": "ai-dev-20", "ner": [[0, 1, "field"], [55, 58, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[55, 58, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Unsupervised", "learning", ",", "on", "the", "other", "hand", ",", "starts", "from", "training", "data", "that", "has", "not", "been", "labelled", "by", "hand", "and", "tries", "to", "find", "inherent", "patterns", "in", "the", "data", "that", "can", "then", "be", "used", "to", "determine", "the", "correct", "output", "value", "for", "new", "data", "instances", ".", "A", "combination", "of", "the", "two", "that", "has", "recently", "been", "explored", "is", "semi-supervised", "learning", ",", "which", "uses", "a", "combination", "of", "labelled", "and", "unlabelled", "data", "(", "usually", "a", "small", "set", "of", "labelled", "data", "combined", "with", "a", "large", "set", "of", "unlabelled", "data", ")", "."], "sentence-detokenized": "Unsupervised learning, on the other hand, starts from training data that has not been labelled by hand and tries to find inherent patterns in the data that can then be used to determine the correct output value for new data instances. A combination of the two that has recently been explored is semi-supervised learning, which uses a combination of labelled and unlabelled data (usually a small set of labelled data combined with a large set of unlabelled data).", "token2charspan": [[0, 12], [13, 21], [21, 22], [23, 25], [26, 29], [30, 35], [36, 40], [40, 41], [42, 48], [49, 53], [54, 62], [63, 67], [68, 72], [73, 76], [77, 80], [81, 85], [86, 94], [95, 97], [98, 102], [103, 106], [107, 112], [113, 115], [116, 120], [121, 129], [130, 138], [139, 141], [142, 145], [146, 150], [151, 155], [156, 159], [160, 164], [165, 167], [168, 172], [173, 175], [176, 185], [186, 189], [190, 197], [198, 204], [205, 210], [211, 214], [215, 218], [219, 223], [224, 233], [233, 234], [235, 236], [237, 248], [249, 251], [252, 255], [256, 259], [260, 264], [265, 268], [269, 277], [278, 282], [283, 291], [292, 294], [295, 310], [311, 319], [319, 320], [321, 326], [327, 331], [332, 333], [334, 345], [346, 348], [349, 357], [358, 361], [362, 372], [373, 377], [378, 379], [379, 386], [387, 388], [389, 394], [395, 398], [399, 401], [402, 410], [411, 415], [416, 424], [425, 429], [430, 431], [432, 437], [438, 441], [442, 444], [445, 455], [456, 460], [460, 461], [461, 462]]}
{"doc_key": "ai-dev-21", "ner": [[17, 18, "organisation"], [19, 19, "product"], [21, 23, "organisation"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 19, 17, 18, "artifact", "", false, false], [21, 23, 24, 24, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Despite", "these", "utility", "humanoid", "robots", ",", "there", "are", "some", "humanoid", "robots", "designed", "for", "entertainment", ",", "such", "as", "Sony", "'s", "QRIO", "and", "Wow", "Wee", "'s", "RoboSapien", "."], "sentence-detokenized": "Despite these utility humanoid robots, there are some humanoid robots designed for entertainment, such as Sony's QRIO and Wow Wee's RoboSapien.", "token2charspan": [[0, 7], [8, 13], [14, 21], [22, 30], [31, 37], [37, 38], [39, 44], [45, 48], [49, 53], [54, 62], [63, 69], [70, 78], [79, 82], [83, 96], [96, 97], [98, 102], [103, 105], [106, 110], [110, 112], [113, 117], [118, 121], [122, 125], [126, 129], [129, 131], [132, 142], [142, 143]]}
{"doc_key": "ai-dev-22", "ner": [[0, 0, "researcher"], [6, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 12, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Webber", "became", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "in", "1991", ","], "sentence-detokenized": "Webber became a member of the Association for the Advancement of Artificial Intelligence in 1991,", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 49], [50, 61], [62, 64], [65, 75], [76, 88], [89, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-dev-23", "ner": [[6, 7, "field"], [21, 24, "task"]], "ner_mapping_to_source": [0, 2], "relations": [[21, 24, 6, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["With", "this", "company", ",", "he", "developed", "data", "mining", "and", "database", "technologies", ",", "more", "specifically", "high", "-", "level", "ontologies", "for", "intelligence", "and", "automated", "natural", "language", "understanding", "."], "sentence-detokenized": "With this company, he developed data mining and database technologies, more specifically high-level ontologies for intelligence and automated natural language understanding.", "token2charspan": [[0, 4], [5, 9], [10, 17], [17, 18], [19, 21], [22, 31], [32, 36], [37, 43], [44, 47], [48, 56], [57, 69], [69, 70], [71, 75], [76, 88], [89, 93], [93, 94], [94, 99], [100, 110], [111, 114], [115, 127], [128, 131], [132, 141], [142, 149], [150, 158], [159, 172], [172, 173]]}
{"doc_key": "ai-dev-24", "ner": [[18, 19, "misc"], [21, 24, "misc"], [26, 27, "misc"], [29, 29, "country"], [31, 33, "organisation"], [35, 35, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 19, 29, 29, "physical", "", false, false], [21, 24, 29, 29, "physical", "", false, false], [26, 27, 29, 29, "physical", "", false, false], [31, 33, 35, 35, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["However", ",", "in", "recent", "years", ",", "various", "e-services", "and", "related", "initiatives", "have", "emerged", "in", "developing", "countries", ",", "e.g.", "Project", "Nemmadi", ",", "MCA21", "Mission", "Mode", "Project", "or", "Digital", "India", "in", "India", ",", "Electronic", "Government", "Directorate", "in", "Pakistan", ",", "etc."], "sentence-detokenized": "However, in recent years, various e-services and related initiatives have emerged in developing countries, e.g. Project Nemmadi, MCA21 Mission Mode Project or Digital India in India, Electronic Government Directorate in Pakistan, etc.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 18], [19, 24], [24, 25], [26, 33], [34, 44], [45, 48], [49, 56], [57, 68], [69, 73], [74, 81], [82, 84], [85, 95], [96, 105], [105, 106], [107, 111], [112, 119], [120, 127], [127, 128], [129, 134], [135, 142], [143, 147], [148, 155], [156, 158], [159, 166], [167, 172], [173, 175], [176, 181], [181, 182], [183, 193], [194, 204], [205, 216], [217, 219], [220, 228], [228, 229], [230, 234]]}
{"doc_key": "ai-dev-25", "ner": [[1, 3, "misc"], [5, 6, "field"], [8, 8, "field"], [11, 13, "university"], [17, 19, "university"], [27, 29, "university"], [33, 33, "misc"], [35, 36, "field"], [40, 45, "misc"], [46, 46, "university"], [48, 50, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[1, 3, 5, 6, "topic", "", false, false], [1, 3, 8, 8, "topic", "", false, false], [1, 3, 11, 13, "origin", "", false, false], [11, 13, 17, 19, "part-of", "", false, false], [27, 29, 11, 13, "part-of", "", false, false], [33, 33, 35, 36, "topic", "", false, false], [33, 33, 46, 46, "origin", "", false, false], [40, 45, 46, 46, "origin", "", false, false], [46, 46, 48, 50, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["He", "obtained", "his", "PhD", "in", "Radio", "Physics", "and", "Electronics", "from", "the", "Rajabazar", "Science", "College", "campus", "of", "the", "University", "of", "Calcutta", "in", "1979", "as", "a", "student", "of", "the", "Indian", "Statistical", "Institute", ",", "and", "his", "PhD", "in", "Electrical", "Engineering", "along", "with", "a", "diploma", "from", "Imperial", "College", "at", "Imperial", "College", ",", "University", "of", "London", ",", "in", "1982", "."], "sentence-detokenized": "He obtained his PhD in Radio Physics and Electronics from the Rajabazar Science College campus of the University of Calcutta in 1979 as a student of the Indian Statistical Institute, and his PhD in Electrical Engineering along with a diploma from Imperial College at Imperial College, University of London, in 1982.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 19], [20, 22], [23, 28], [29, 36], [37, 40], [41, 52], [53, 57], [58, 61], [62, 71], [72, 79], [80, 87], [88, 94], [95, 97], [98, 101], [102, 112], [113, 115], [116, 124], [125, 127], [128, 132], [133, 135], [136, 137], [138, 145], [146, 148], [149, 152], [153, 159], [160, 171], [172, 181], [181, 182], [183, 186], [187, 190], [191, 194], [195, 197], [198, 208], [209, 220], [221, 226], [227, 231], [232, 233], [234, 241], [242, 246], [247, 255], [256, 263], [264, 266], [267, 275], [276, 283], [283, 284], [285, 295], [296, 298], [299, 305], [305, 306], [307, 309], [310, 314], [314, 315]]}
{"doc_key": "ai-dev-26", "ner": [[0, 1, "location"], [21, 23, "misc"], [28, 29, "misc"], [31, 33, "person"], [35, 36, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 23, 0, 1, "temporal", "", false, false], [28, 29, 0, 1, "temporal", "", false, false], [31, 33, 28, 29, "role", "actor_in", false, false], [35, 36, 28, 29, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Expo", "II", "was", "announced", "as", "the", "venue", "for", "the", "world", "premiere", "of", "several", "films", "never", "before", "shown", "in", "3D", ",", "including", "The", "Diamond", "Wizard", "and", "the", "Universal", "short", "Hawaiian", "Nights", "starring", "Mamie", "Van", "Doren", "and", "Pinky", "Lee", "."], "sentence-detokenized": "Expo II was announced as the venue for the world premiere of several films never before shown in 3D, including The Diamond Wizard and the Universal short Hawaiian Nights starring Mamie Van Doren and Pinky Lee.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 24], [25, 28], [29, 34], [35, 38], [39, 42], [43, 48], [49, 57], [58, 60], [61, 68], [69, 74], [75, 80], [81, 87], [88, 93], [94, 96], [97, 99], [99, 100], [101, 110], [111, 114], [115, 122], [123, 129], [130, 133], [134, 137], [138, 147], [148, 153], [154, 162], [163, 169], [170, 178], [179, 184], [185, 188], [189, 194], [195, 198], [199, 204], [205, 208], [208, 209]]}
{"doc_key": "ai-dev-27", "ner": [[7, 8, "researcher"], [16, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 16, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "maximum", "subset", "problem", "was", "proposed", "by", "Ulf", "Grenander", "in", "1977", "as", "a", "simplified", "model", "for", "maximum", "likelihood", "estimation", "of", "patterns", "in", "digitised", "images", "."], "sentence-detokenized": "The maximum subset problem was proposed by Ulf Grenander in 1977 as a simplified model for maximum likelihood estimation of patterns in digitised images.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 26], [27, 30], [31, 39], [40, 42], [43, 46], [47, 56], [57, 59], [60, 64], [65, 67], [68, 69], [70, 80], [81, 86], [87, 90], [91, 98], [99, 109], [110, 120], [121, 123], [124, 132], [133, 135], [136, 145], [146, 152], [152, 153]]}
{"doc_key": "ai-dev-28", "ner": [[0, 1, "product"], [3, 4, "product"], [6, 8, "product"], [10, 11, "product"], [13, 15, "product"], [17, 20, "product"], [31, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[31, 31, 0, 1, "part-of", "", false, false], [31, 31, 3, 4, "part-of", "", false, false], [31, 31, 6, 8, "part-of", "", false, false], [31, 31, 10, 11, "part-of", "", false, false], [31, 31, 13, 15, "part-of", "", false, false], [31, 31, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["iPhone", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", ",", "iPod", "Touch", "5", "G", "and", "later", "all", "have", "a", "more", "advanced", "voice", "assistant", "called", "Siri", "."], "sentence-detokenized": "iPhone 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G, iPod Touch 5G and later all have a more advanced voice assistant called Siri.", "token2charspan": [[0, 6], [7, 9], [9, 10], [11, 15], [16, 17], [17, 18], [19, 23], [24, 28], [29, 31], [31, 32], [33, 37], [38, 41], [41, 42], [43, 47], [48, 51], [52, 54], [54, 55], [56, 60], [61, 66], [67, 68], [68, 69], [70, 73], [74, 79], [80, 83], [84, 88], [89, 90], [91, 95], [96, 104], [105, 110], [111, 120], [121, 127], [128, 132], [132, 133]]}
{"doc_key": "ai-dev-29", "ner": [[7, 8, "metrics"], [11, 14, "metrics"], [16, 17, "metrics"], [43, 46, "metrics"], [52, 55, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 14, 43, 46, "named", "", false, false], [16, 17, 11, 14, "named", "", false, false], [43, 46, 52, 55, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["It", "is", "easy", "to", "check", "that", "the", "logistic", "loss", "and", "the", "binary", "cross", "-entropy", "loss", "(", "log", "loss", ")", "are", "actually", "the", "same", "(", "up", "to", "a", "multiplicative", "constant", "math", "\\", "frac", "{", "1", "}", "{", "\\", "log", "(", "2", ")", "}", "/", "The", "cross", "-entropy", "loss", "is", "closely", "related", "to", "the", "Kullback", "-", "Leibler", "divergence", "between", "the", "empirical", "distribution", "and", "the", "predicted", "distribution", "."], "sentence-detokenized": "It is easy to check that the logistic loss and the binary cross-entropy loss (log loss) are actually the same (up to a multiplicative constant math\\ frac {1} {\\ log (2)} / The cross-entropy loss is closely related to the Kullback-Leibler divergence between the empirical distribution and the predicted distribution.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 19], [20, 24], [25, 28], [29, 37], [38, 42], [43, 46], [47, 50], [51, 57], [58, 63], [63, 71], [72, 76], [77, 78], [78, 81], [82, 86], [86, 87], [88, 91], [92, 100], [101, 104], [105, 109], [110, 111], [111, 113], [114, 116], [117, 118], [119, 133], [134, 142], [143, 147], [147, 148], [149, 153], [154, 155], [155, 156], [156, 157], [158, 159], [159, 160], [161, 164], [165, 166], [166, 167], [167, 168], [168, 169], [170, 171], [172, 175], [176, 181], [181, 189], [190, 194], [195, 197], [198, 205], [206, 213], [214, 216], [217, 220], [221, 229], [229, 230], [230, 237], [238, 248], [249, 256], [257, 260], [261, 270], [271, 283], [284, 287], [288, 291], [292, 301], [302, 314], [314, 315]]}
{"doc_key": "ai-dev-30", "ner": [[0, 2, "algorithm"], [12, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "EM", "algorithm", "is", "used", "to", "find", "(", "local", ")", "parameters", "with", "maximum", "likelihood", "for", "a", "statistical", "model", "in", "cases", "where", "the", "equations", "can", "not", "be", "solved", "directly", "."], "sentence-detokenized": "The EM algorithm is used to find (local) parameters with maximum likelihood for a statistical model in cases where the equations cannot be solved directly.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 32], [33, 34], [34, 39], [39, 40], [41, 51], [52, 56], [57, 64], [65, 75], [76, 79], [80, 81], [82, 93], [94, 99], [100, 102], [103, 108], [109, 114], [115, 118], [119, 128], [129, 132], [132, 135], [136, 138], [139, 145], [146, 154], [154, 155]]}
{"doc_key": "ai-dev-31", "ner": [[9, 10, "task"], [13, 17, "task"], [22, 23, "task"], [25, 26, "task"], [33, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "research", "was", "fundamental", "to", "the", "development", "of", "modern", "speech", "synthesis", "techniques", ",", "reading", "machines", "for", "the", "blind", ",", "the", "study", "of", "speech", "perception", "and", "speech", "recognition", ",", "and", "the", "development", "of", "the", "motor", "theory", "of", "speech", "perception", "."], "sentence-detokenized": "This research was fundamental to the development of modern speech synthesis techniques, reading machines for the blind, the study of speech perception and speech recognition, and the development of the motor theory of speech perception.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 29], [30, 32], [33, 36], [37, 48], [49, 51], [52, 58], [59, 65], [66, 75], [76, 86], [86, 87], [88, 95], [96, 104], [105, 108], [109, 112], [113, 118], [118, 119], [120, 123], [124, 129], [130, 132], [133, 139], [140, 150], [151, 154], [155, 161], [162, 173], [173, 174], [175, 178], [179, 182], [183, 194], [195, 197], [198, 201], [202, 207], [208, 214], [215, 217], [218, 224], [225, 235], [235, 236]]}
{"doc_key": "ai-dev-32", "ner": [[0, 1, "product"], [2, 4, "misc"], [6, 6, "misc"], [10, 12, "misc"], [15, 15, "product"], [17, 17, "product"], [19, 19, "product"], [24, 24, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 0, 1, "origin", "", false, false], [2, 4, 10, 12, "type-of", "", false, false], [2, 4, 15, 15, "related-to", "program_for", false, false], [2, 4, 17, 17, "related-to", "program_for", false, false], [2, 4, 19, 19, "related-to", "program_for", false, false], [2, 4, 24, 24, "related-to", "program_for", false, false], [6, 6, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "Arduino", "Integrated", "Development", "Environment", "(", "IDE", ")", "is", "a", "cross", "-platform", "application", "(", "for", "Windows", ",", "macOS", "and", "Linux", ")", "written", "in", "the", "Java", "programming", "language", "."], "sentence-detokenized": "The Arduino Integrated Development Environment (IDE) is a cross-platform application (for Windows, macOS and Linux) written in the Java programming language.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 57], [58, 63], [63, 72], [73, 84], [85, 86], [86, 89], [90, 97], [97, 98], [99, 104], [105, 108], [109, 114], [114, 115], [116, 123], [124, 126], [127, 130], [131, 135], [136, 147], [148, 156], [156, 157]]}
{"doc_key": "ai-dev-33", "ner": [[2, 3, "algorithm"], [18, 19, "field"], [6, 7, "researcher"], [9, 10, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 18, 19, "opposite", "", false, false], [6, 7, 18, 19, "related-to", "works_with", false, false], [9, 10, 18, 19, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Research", "on", "neural", "networks", "stagnated", "after", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", "published", "their", "research", "on", "machine", "learning", "."], "sentence-detokenized": "Research on neural networks stagnated after Marvin Minsky and Seymour Papert (1969) published their research on machine learning.", "token2charspan": [[0, 8], [9, 11], [12, 18], [19, 27], [28, 37], [38, 43], [44, 50], [51, 57], [58, 61], [62, 69], [70, 76], [77, 78], [78, 82], [82, 83], [84, 93], [94, 99], [100, 108], [109, 111], [112, 119], [120, 128], [128, 129]]}
{"doc_key": "ai-dev-34", "ner": [[19, 20, "organisation"], [22, 22, "organisation"], [25, 27, "country"], [29, 32, "organisation"], [35, 35, "country"], [37, 38, "organisation"], [41, 41, "country"], [43, 43, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[29, 32, 25, 27, "general-affiliation", "", false, false], [37, 38, 35, 35, "general-affiliation", "", false, false], [43, 43, 41, 41, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Only", "a", "few", "non-Japanese", "companies", "managed", "to", "survive", "in", "this", "market", ",", "the", "most", "important", "of", "which", "are", ":", "Adept", "Technology", ",", "St\u00e4ubli", ",", "the", "Swedish", "-", "Swiss", "company", "ABB", "Asea", "Brown", "Boveri", ",", "the", "German", "company", "KUKA", "Robotics", "and", "the", "Italian", "company", "Comau", "."], "sentence-detokenized": "Only a few non-Japanese companies managed to survive in this market, the most important of which are: Adept Technology, St\u00e4ubli, the Swedish-Swiss company ABB Asea Brown Boveri, the German company KUKA Robotics and the Italian company Comau.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 23], [24, 33], [34, 41], [42, 44], [45, 52], [53, 55], [56, 60], [61, 67], [67, 68], [69, 72], [73, 77], [78, 87], [88, 90], [91, 96], [97, 100], [100, 101], [102, 107], [108, 118], [118, 119], [120, 127], [127, 128], [129, 132], [133, 140], [140, 141], [141, 146], [147, 154], [155, 158], [159, 163], [164, 169], [170, 176], [176, 177], [178, 181], [182, 188], [189, 196], [197, 201], [202, 210], [211, 214], [215, 218], [219, 226], [227, 234], [235, 240], [240, 241]]}
{"doc_key": "ai-dev-35", "ner": [[9, 10, "conference"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Research", "activities", "include", "an", "annual", "research", "conference", ",", "the", "RuleML", "Symposium", ",", "also", "known", "as", "RuleML", "."], "sentence-detokenized": "Research activities include an annual research conference, the RuleML Symposium, also known as RuleML.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 30], [31, 37], [38, 46], [47, 57], [57, 58], [59, 62], [63, 69], [70, 79], [79, 80], [81, 85], [86, 91], [92, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-dev-36", "ner": [[9, 9, "field"], [11, 12, "field"], [14, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Concepts", "are", "used", "as", "formal", "tools", "or", "models", "in", "mathematics", ",", "computer", "science", ",", "databases", "and", "artificial", "intelligence", ",", "where", "they", "are", "sometimes", "called", "classes", ",", "schemas", "or", "categories", "."], "sentence-detokenized": "Concepts are used as formal tools or models in mathematics, computer science, databases and artificial intelligence, where they are sometimes called classes, schemas or categories.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 33], [34, 36], [37, 43], [44, 46], [47, 58], [58, 59], [60, 68], [69, 76], [76, 77], [78, 87], [88, 91], [92, 102], [103, 115], [115, 116], [117, 122], [123, 127], [128, 131], [132, 141], [142, 148], [149, 156], [156, 157], [158, 165], [166, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-dev-37", "ner": [[6, 8, "organisation"], [11, 14, "organisation"], [16, 17, "organisation"], [19, 21, "organisation"], [24, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "received", "awards", "from", "the", "American", "Psychological", "Association", ",", "the", "National", "Academy", "of", "Sciences", ",", "the", "Royal", ",", "Cognitive", "Neuroscience", "Society", "and", "the", "American", "Humanist", "Association", "."], "sentence-detokenized": "He has received awards from the American Psychological Association, the National Academy of Sciences, the Royal, Cognitive Neuroscience Society and the American Humanist Association.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 22], [23, 27], [28, 31], [32, 40], [41, 54], [55, 66], [66, 67], [68, 71], [72, 80], [81, 88], [89, 91], [92, 100], [100, 101], [102, 105], [106, 111], [111, 112], [113, 122], [123, 135], [136, 143], [144, 147], [148, 151], [152, 160], [161, 169], [170, 181], [181, 182]]}
{"doc_key": "ai-dev-38", "ner": [[0, 4, "person"], [6, 7, "person"], [9, 10, "person"], [16, 20, "person"], [22, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[22, 28, 16, 20, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "film", "stars", "Harrison", "Ford", ",", "Rutger", "Hauer", "and", "Sean", "Young", "and", "is", "loosely", "based", "on", "Philip", "K", ".", "Dick", "'s", "novel", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "?", "(", "1968", ")", "."], "sentence-detokenized": "The film stars Harrison Ford, Rutger Hauer and Sean Young and is loosely based on Philip K. Dick's novel Do Androids Dream of Electric Sheep? (1968).", "token2charspan": [[0, 3], [4, 8], [9, 14], [15, 23], [24, 28], [28, 29], [30, 36], [37, 42], [43, 46], [47, 51], [52, 57], [58, 61], [62, 64], [65, 72], [73, 78], [79, 81], [82, 88], [89, 90], [90, 91], [92, 96], [96, 98], [99, 104], [105, 107], [108, 116], [117, 122], [123, 125], [126, 134], [135, 140], [140, 141], [142, 143], [143, 147], [147, 148], [148, 149]]}
{"doc_key": "ai-dev-39", "ner": [[0, 2, "task"], [3, 5, "algorithm"], [11, 12, "field"], [14, 15, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 3, 5, "usage", "", false, false], [0, 2, 11, 12, "part-of", "task_part_of_field", false, false], [0, 2, 14, 15, "part-of", "task_part_of_field", false, false], [0, 2, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Image", "segmentation", "using", "k-means", "clustering", "algorithms", "has", "long", "been", "used", "for", "pattern", "recognition", ",", "object", "detection", "and", "medical", "imaging", "."], "sentence-detokenized": "Image segmentation using k-means clustering algorithms has long been used for pattern recognition, object detection and medical imaging.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 32], [33, 43], [44, 54], [55, 58], [59, 63], [64, 68], [69, 73], [74, 77], [78, 85], [86, 97], [97, 98], [99, 105], [106, 115], [116, 119], [120, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-dev-40", "ner": [[14, 14, "algorithm"], [17, 18, "algorithm"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["General", "sampling", "from", "the", "truncated", "norm", "can", "be", "achieved", "using", "approximations", "of", "the", "normal", "CDF", "and", "the", "probit", "function", ",", "and", "R", "has", "a", "function", "codertnorm", "(", ")", "/", "code", "to", "generate", "truncated", "normal", "samples", "."], "sentence-detokenized": "General sampling from the truncated norm can be achieved using approximations of the normal CDF and the probit function, and R has a function codertnorm()/code to generate truncated normal samples.", "token2charspan": [[0, 7], [8, 16], [17, 21], [22, 25], [26, 35], [36, 40], [41, 44], [45, 47], [48, 56], [57, 62], [63, 77], [78, 80], [81, 84], [85, 91], [92, 95], [96, 99], [100, 103], [104, 110], [111, 119], [119, 120], [121, 124], [125, 126], [127, 130], [131, 132], [133, 141], [142, 152], [152, 153], [153, 154], [154, 155], [155, 159], [160, 162], [163, 171], [172, 181], [182, 188], [189, 196], [196, 197]]}
{"doc_key": "ai-dev-41", "ner": [[8, 10, "university"], [12, 12, "university"], [14, 16, "university"], [18, 20, "university"], [22, 23, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "also", "received", "honorary", "doctorates", "from", "the", "Universities", "of", "Newcastle", ",", "Surrey", ",", "Tel", "Aviv", "University", ",", "Simon", "Fraser", "University", "and", "Troms\u00f8", "University", "."], "sentence-detokenized": "He has also received honorary doctorates from the Universities of Newcastle, Surrey, Tel Aviv University, Simon Fraser University and Troms\u00f8 University.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 29], [30, 40], [41, 45], [46, 49], [50, 62], [63, 65], [66, 75], [75, 76], [77, 83], [83, 84], [85, 88], [89, 93], [94, 104], [104, 105], [106, 111], [112, 118], [119, 129], [130, 133], [134, 140], [141, 151], [151, 152]]}
{"doc_key": "ai-dev-42", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "Java", "implementation", "that", "uses", "zero", "-", "based", "array", "indexes", "along", "with", "a", "convenient", "method", "for", "printing", "the", "resolved", "order", "of", "operations", ":"], "sentence-detokenized": "A Java implementation that uses zero-based array indexes along with a convenient method for printing the resolved order of operations:", "token2charspan": [[0, 1], [2, 6], [7, 21], [22, 26], [27, 31], [32, 36], [36, 37], [37, 42], [43, 48], [49, 56], [57, 62], [63, 67], [68, 69], [70, 80], [81, 87], [88, 91], [92, 100], [101, 104], [105, 113], [114, 119], [120, 122], [123, 133], [133, 134]]}
{"doc_key": "ai-dev-43", "ner": [[7, 8, "metrics"], [11, 12, "metrics"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Such", "networks", "are", "usually", "trained", "under", "a", "cross", "entropy", "(", "or", "cross", "entropy", ")", "regime", ",", "which", "provides", "a", "non-linear", "variant", "of", "multinomial", "logistic", "regression", "."], "sentence-detokenized": "Such networks are usually trained under a cross entropy (or cross entropy) regime, which provides a non-linear variant of multinomial logistic regression.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 25], [26, 33], [34, 39], [40, 41], [42, 47], [48, 55], [56, 57], [57, 59], [60, 65], [66, 73], [73, 74], [75, 81], [81, 82], [83, 88], [89, 97], [98, 99], [100, 110], [111, 118], [119, 121], [122, 133], [134, 142], [143, 153], [153, 154]]}
{"doc_key": "ai-dev-44", "ner": [[0, 0, "conference"], [3, 3, "misc"], [4, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["ACL", "has", "a", "European", "chapter", "(", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ")", "."], "sentence-detokenized": "ACL has a European chapter (European Chapter of the Association for Computational Linguistics).", "token2charspan": [[0, 3], [4, 7], [8, 9], [10, 18], [19, 26], [27, 28], [28, 36], [37, 44], [45, 47], [48, 51], [52, 63], [64, 67], [68, 81], [82, 93], [93, 94], [94, 95]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 8, "researcher"], [25, 25, "misc"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 25, 25, "role", "", false, false], [6, 8, 25, 25, "role", "", false, false], [25, 25, 27, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "professors", ",", "Hal", "Abelson", "and", "Gerald", "Jay", "Sussman", ",", "chose", "to", "remain", "neutral", "-", "their", "group", "was", "known", "for", "the", "next", "30", "years", "as", "Switzerland", "and", "Project", "MAC", "."], "sentence-detokenized": "Two professors, Hal Abelson and Gerald Jay Sussman, chose to remain neutral - their group was known for the next 30 years as Switzerland and Project MAC.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 50], [50, 51], [52, 57], [58, 60], [61, 67], [68, 75], [76, 77], [78, 83], [84, 89], [90, 93], [94, 99], [100, 103], [104, 107], [108, 112], [113, 115], [116, 121], [122, 124], [125, 136], [137, 140], [141, 148], [149, 152], [152, 153]]}
{"doc_key": "ai-dev-46", "ner": [[3, 3, "misc"], [5, 5, "researcher"], [9, 11, "university"], [16, 16, "organisation"], [21, 23, "organisation"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 5, 5, "temporal", "", false, false], [5, 5, 16, 16, "physical", "", false, false], [5, 5, 16, 16, "role", "", false, false], [5, 5, 21, 23, "role", "", false, false], [21, 23, 9, 11, "part-of", "", false, false], [29, 30, 21, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["After", "completing", "his", "PhD", ",", "Ghahramani", "moved", "to", "the", "University", "of", "Toronto", "in", "1995", "as", "an", "ITRC", "Postdoctoral", "Fellow", "in", "the", "Artificial", "Intelligence", "Lab", ",", "where", "he", "worked", "with", "Geoffrey", "Hinton", "."], "sentence-detokenized": "After completing his PhD, Ghahramani moved to the University of Toronto in 1995 as an ITRC Postdoctoral Fellow in the Artificial Intelligence Lab, where he worked with Geoffrey Hinton.", "token2charspan": [[0, 5], [6, 16], [17, 20], [21, 24], [24, 25], [26, 36], [37, 42], [43, 45], [46, 49], [50, 60], [61, 63], [64, 71], [72, 74], [75, 79], [80, 82], [83, 85], [86, 90], [91, 103], [104, 110], [111, 113], [114, 117], [118, 128], [129, 141], [142, 145], [145, 146], [147, 152], [153, 155], [156, 162], [163, 167], [168, 176], [177, 183], [183, 184]]}
{"doc_key": "ai-dev-47", "ner": [[23, 24, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Later", "work", "focused", "on", "solving", "these", "problems", ",", "but", "it", "was", "n't", "until", "the", "advent", "of", "the", "modern", "computer", "and", "the", "popularisation", "of", "Maximum", "Likelihood", "(", "MLE", ")", "techniques", "that", "research", "really", "took", "off", "."], "sentence-detokenized": "Later work focused on solving these problems, but it wasn't until the advent of the modern computer and the popularisation of Maximum Likelihood (MLE) techniques that research really took off.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 21], [22, 29], [30, 35], [36, 44], [44, 45], [46, 49], [50, 52], [53, 56], [56, 59], [60, 65], [66, 69], [70, 76], [77, 79], [80, 83], [84, 90], [91, 99], [100, 103], [104, 107], [108, 122], [123, 125], [126, 133], [134, 144], [145, 146], [146, 149], [149, 150], [151, 161], [162, 166], [167, 175], [176, 182], [183, 187], [188, 191], [191, 192]]}
{"doc_key": "ai-dev-48", "ner": [[5, 7, "person"], [9, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "series", "was", "produced", "by", "David", "Fincher", "and", "starred", "Kevin", "Spacey", "."], "sentence-detokenized": "The series was produced by David Fincher and starred Kevin Spacey.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 40], [41, 44], [45, 52], [53, 58], [59, 65], [65, 66]]}
{"doc_key": "ai-dev-49", "ner": [[18, 21, "metrics"], [26, 27, "algorithm"], [30, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[26, 27, 30, 32, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Due", "to", "the", "limitations", "of", "computing", "power", ",", "current", "in", "silico", "methods", "usually", "have", "to", "trade", "speed", "for", "accuracy", ",", "e.g.", "by", "using", "fast", "methods", "for", "protein", "docking", "instead", "of", "free", "energy", "calculations", "which", "are", "costly", "."], "sentence-detokenized": "Due to the limitations of computing power, current in silico methods usually have to trade speed for accuracy, e.g. by using fast methods for protein docking instead of free energy calculations which are costly.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 22], [23, 25], [26, 35], [36, 41], [41, 42], [43, 50], [51, 53], [54, 60], [61, 68], [69, 76], [77, 81], [82, 84], [85, 90], [91, 96], [97, 100], [101, 109], [109, 110], [111, 115], [116, 118], [119, 124], [125, 129], [130, 137], [138, 141], [142, 149], [150, 157], [158, 165], [166, 168], [169, 173], [174, 180], [181, 193], [194, 199], [200, 203], [204, 210], [210, 211]]}
{"doc_key": "ai-dev-50", "ner": [[8, 8, "country"], [10, 10, "country"], [12, 12, "country"], [14, 14, "country"], [16, 16, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "company", "had", "over", "30", "plants", "in", "the", "US", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "sentence-detokenized": "The company had over 30 plants in the US, Canada, Mexico, Brazil and Argentina.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 20], [21, 23], [24, 30], [31, 33], [34, 37], [38, 40], [40, 41], [42, 48], [48, 49], [50, 56], [56, 57], [58, 64], [65, 68], [69, 78], [78, 79]]}
{"doc_key": "ai-dev-51", "ner": [[5, 6, "field"], [11, 13, "product"], [15, 17, "algorithm"], [23, 24, "task"], [26, 27, "task"], [32, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 13, 5, 6, "part-of", "", false, false], [11, 13, 15, 17, "usage", "", false, false], [23, 24, 5, 6, "part-of", "task_part_of_field", false, false], [23, 24, 32, 32, "related-to", "performs", false, false], [26, 27, 5, 6, "part-of", "task_part_of_field", false, false], [26, 27, 32, 32, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["An", "example", "of", "a", "typical", "computer", "vision", "computational", "pipeline", "for", "a", "face", "recognition", "system", "with", "k", "-", "NNN", ",", "including", "preprocessing", "steps", "for", "feature", "extraction", "and", "dimension", "reduction", "(", "usually", "implemented", "with", "OpenCV", ")", ":"], "sentence-detokenized": "An example of a typical computer vision computational pipeline for a face recognition system with k -NNN, including preprocessing steps for feature extraction and dimension reduction (usually implemented with OpenCV):", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 23], [24, 32], [33, 39], [40, 53], [54, 62], [63, 66], [67, 68], [69, 73], [74, 85], [86, 92], [93, 97], [98, 99], [100, 101], [101, 104], [104, 105], [106, 115], [116, 129], [130, 135], [136, 139], [140, 147], [148, 158], [159, 162], [163, 172], [173, 182], [183, 184], [184, 191], [192, 203], [204, 208], [209, 215], [215, 216], [216, 217]]}
{"doc_key": "ai-dev-52", "ner": [[9, 11, "algorithm"], [13, 13, "misc"], [15, 16, "misc"], [18, 18, "misc"], [22, 22, "programlang"], [24, 24, "product"], [28, 29, "algorithm"], [32, 33, "misc"], [35, 35, "misc"], [37, 37, "misc"], [39, 39, "misc"], [47, 47, "misc"], [49, 50, "misc"], [52, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "a", "rich", "feature", "set", ",", "libraries", "for", "constrained", "logic", "programming", ",", "multithreading", ",", "unit", "testing", ",", "GUI", ",", "interfaces", "to", "Java", ",", "ODBC", "and", "others", ",", "literary", "programming", ",", "a", "web", "server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "tools", "for", "developers", "(", "including", "an", "IDE", "with", "GUI", "debugger", "and", "GUI", "profiling", ")", "and", "extensive", "documentation", "."], "sentence-detokenized": "It has a rich feature set, libraries for constrained logic programming, multithreading, unit testing, GUI, interfaces to Java, ODBC and others, literary programming, a web server, SGML, RDF, RDFS, tools for developers (including an IDE with GUI debugger and GUI profiling) and extensive documentation.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 13], [14, 21], [22, 25], [25, 26], [27, 36], [37, 40], [41, 52], [53, 58], [59, 70], [70, 71], [72, 86], [86, 87], [88, 92], [93, 100], [100, 101], [102, 105], [105, 106], [107, 117], [118, 120], [121, 125], [125, 126], [127, 131], [132, 135], [136, 142], [142, 143], [144, 152], [153, 164], [164, 165], [166, 167], [168, 171], [172, 178], [178, 179], [180, 184], [184, 185], [186, 189], [189, 190], [191, 195], [195, 196], [197, 202], [203, 206], [207, 217], [218, 219], [219, 228], [229, 231], [232, 235], [236, 240], [241, 244], [245, 253], [254, 257], [258, 261], [262, 271], [271, 272], [273, 276], [277, 286], [287, 300], [300, 301]]}
{"doc_key": "ai-dev-53", "ner": [[1, 2, "field"], [4, 5, "field"], [10, 13, "misc"], [15, 19, "misc"], [20, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 13, 1, 2, "part-of", "", true, false], [10, 13, 4, 5, "part-of", "", false, false], [10, 13, 20, 24, "type-of", "", false, false], [15, 19, 1, 2, "part-of", "", false, false], [15, 19, 4, 5, "part-of", "", false, false], [15, 19, 20, 24, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "computer", "vision", "and", "image", "processing", ",", "the", "concept", "of", "representation", "of", "scale", "space", "and", "Gaussian", "derivative", "operators", "is", "a", "canonical", "representation", "in", "multiple", "scales", "."], "sentence-detokenized": "In computer vision and image processing, the concept of representation of scale space and Gaussian derivative operators is a canonical representation in multiple scales.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 22], [23, 28], [29, 39], [39, 40], [41, 44], [45, 52], [53, 55], [56, 70], [71, 73], [74, 79], [80, 85], [86, 89], [90, 98], [99, 109], [110, 119], [120, 122], [123, 124], [125, 134], [135, 149], [150, 152], [153, 161], [162, 168], [168, 169]]}
{"doc_key": "ai-dev-54", "ner": [[7, 11, "organisation"], [20, 24, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 11, 20, 24, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "also", "the", "President", "of", "the", "Neural", "Information", "Processing", "Systems", "Foundation", ",", "a", "non-profit", "organization", "that", "oversees", "the", "annual", "Neural", "Information", "Processing", "Systems", "Conference", "."], "sentence-detokenized": "He is also the President of the Neural Information Processing Systems Foundation, a non-profit organization that oversees the annual Neural Information Processing Systems Conference.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 14], [15, 24], [25, 27], [28, 31], [32, 38], [39, 50], [51, 61], [62, 69], [70, 80], [80, 81], [82, 83], [84, 94], [95, 107], [108, 112], [113, 121], [122, 125], [126, 132], [133, 139], [140, 151], [152, 162], [163, 170], [171, 181], [181, 182]]}
{"doc_key": "ai-dev-55", "ner": [[1, 2, "task"], [5, 6, "metrics"], [12, 13, "misc"], [16, 17, "task"], [18, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 5, 6, "usage", "", false, false], [5, 6, 12, 13, "type-of", "", false, false], [16, 17, 18, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["For", "regression", "analyses", ",", "the", "squared", "error", "can", "be", "used", "as", "the", "loss", "function", ",", "for", "classification", "the", "cross", "entropy", "can", "be", "used", "."], "sentence-detokenized": "For regression analyses, the squared error can be used as the loss function, for classification the cross entropy can be used.", "token2charspan": [[0, 3], [4, 14], [15, 23], [23, 24], [25, 28], [29, 36], [37, 42], [43, 46], [47, 49], [50, 54], [55, 57], [58, 61], [62, 66], [67, 75], [75, 76], [77, 80], [81, 95], [96, 99], [100, 105], [106, 113], [114, 117], [118, 120], [121, 125], [125, 126]]}
{"doc_key": "ai-dev-56", "ner": [[0, 0, "researcher"], [21, 24, "conference"], [20, 20, "conference"], [30, 30, "university"], [36, 37, "field"], [45, 49, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 21, 24, "role", "", false, false], [0, 0, 30, 30, "physical", "", false, false], [0, 0, 30, 30, "role", "", false, false], [0, 0, 45, 49, "role", "", false, false], [21, 24, 20, 20, "named", "same", false, false], [30, 30, 36, 37, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Lafferty", "held", "many", "prestigious", "positions", ",", "including", ":", "1", ")", "program", "co-chair", "and", "general", "co-chair", "of", "the", "Foundation", "'s", "Conference", "on", "Neural", "Information", "Processing", "Systems", ";", "2", ")", "co-director", "of", "CMU", "'s", "new", "doctoral", "program", "in", "machine", "learning", ";", "3", ")", "associate", "editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research", "."], "sentence-detokenized": "Lafferty held many prestigious positions, including: 1) program co-chair and general co-chair of the Foundation's Conference on Neural Information Processing Systems; 2) co-director of CMU's new doctoral program in machine learning; 3) associate editor of the Journal of Machine Learning Research.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 30], [31, 40], [40, 41], [42, 51], [51, 52], [53, 54], [54, 55], [56, 63], [64, 72], [73, 76], [77, 84], [85, 93], [94, 96], [97, 100], [101, 111], [111, 113], [114, 124], [125, 127], [128, 134], [135, 146], [147, 157], [158, 165], [165, 166], [167, 168], [168, 169], [170, 181], [182, 184], [185, 188], [188, 190], [191, 194], [195, 203], [204, 211], [212, 214], [215, 222], [223, 231], [231, 232], [233, 234], [234, 235], [236, 245], [246, 252], [253, 255], [256, 259], [260, 267], [268, 270], [271, 278], [279, 287], [288, 296], [296, 297]]}
{"doc_key": "ai-dev-57", "ner": [[0, 1, "misc"], [5, 5, "algorithm"], [7, 7, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 1, "type-of", "", false, false], [7, 7, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Convex", "algorithms", ",", "such", "as", "AdaBoost", "and", "LogitBoost", ",", "can", "be", "defeated", "by", "random", "noise", "so", "that", "they", "can", "not", "learn", "basic", "and", "learnable", "combinations", "of", "weak", "hypotheses", "."], "sentence-detokenized": "Convex algorithms, such as AdaBoost and LogitBoost, can be defeated by random noise so that they cannot learn basic and learnable combinations of weak hypotheses.", "token2charspan": [[0, 6], [7, 17], [17, 18], [19, 23], [24, 26], [27, 35], [36, 39], [40, 50], [50, 51], [52, 55], [56, 58], [59, 67], [68, 70], [71, 77], [78, 83], [84, 86], [87, 91], [92, 96], [97, 100], [100, 103], [104, 109], [110, 115], [116, 119], [120, 129], [130, 142], [143, 145], [146, 150], [151, 161], [161, 162]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [3, 7, "product"], [10, 12, "algorithm"], [19, 19, "algorithm"], [23, 28, "task"], [30, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 7, "type-of", "", false, false], [0, 0, 10, 12, "usage", "", false, false], [0, 0, 19, 19, "usage", "", false, false], [19, 19, 23, 28, "related-to", "used_for", true, false], [19, 19, 30, 32, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "is", "a", "surface", "transfer", "machine", "translation", "system", "that", "uses", "finite", "state", "transducers", "for", "all", "its", "lexical", "transformations", "and", "hidden", "Markov", "models", "for", "part", "-", "of", "-", "speech", "tagging", "or", "word", "category", "disambiguation", "."], "sentence-detokenized": "Apertium is a surface transfer machine translation system that uses finite state transducers for all its lexical transformations and hidden Markov models for part-of-speech tagging or word category disambiguation.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 21], [22, 30], [31, 38], [39, 50], [51, 57], [58, 62], [63, 67], [68, 74], [75, 80], [81, 92], [93, 96], [97, 100], [101, 104], [105, 112], [113, 128], [129, 132], [133, 139], [140, 146], [147, 153], [154, 157], [158, 162], [162, 163], [163, 165], [165, 166], [166, 172], [173, 180], [181, 183], [184, 188], [189, 197], [198, 212], [212, 213]]}
{"doc_key": "ai-dev-59", "ner": [[1, 2, "misc"], [15, 17, "metrics"], [33, 34, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 15, 17, "related-to", "", true, false], [15, 17, 33, 34, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "natural", "gradient", "of", "mathE", "f", "(", "x", ")", "/", "math", ",", "consistent", "with", "the", "Fisher", "information", "metric", "(", "a", "measure", "of", "the", "information", "distance", "between", "probability", "distributions", "and", "the", "curvature", "of", "the", "relative", "entropy", ")", ",", "is", "now"], "sentence-detokenized": "The natural gradient of mathE f (x) / math, consistent with the Fisher information metric (a measure of the information distance between probability distributions and the curvature of the relative entropy), is now", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 23], [24, 29], [30, 31], [32, 33], [33, 34], [34, 35], [36, 37], [38, 42], [42, 43], [44, 54], [55, 59], [60, 63], [64, 70], [71, 82], [83, 89], [90, 91], [91, 92], [93, 100], [101, 103], [104, 107], [108, 119], [120, 128], [129, 136], [137, 148], [149, 162], [163, 166], [167, 170], [171, 180], [181, 183], [184, 187], [188, 196], [197, 204], [204, 205], [205, 206], [207, 209], [210, 213]]}
{"doc_key": "ai-dev-60", "ner": [[0, 4, "programlang"], [7, 10, "product"], [12, 12, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 0, 4, "origin", "", false, false], [12, 12, 0, 4, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "S", "programming", "language", "has", "inspired", "the", "S", "'", "-", "PLUS", "and", "R", "systems", "."], "sentence-detokenized": "The S programming language has inspired the S'-PLUS and R systems.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 26], [27, 30], [31, 39], [40, 43], [44, 45], [45, 46], [46, 47], [47, 51], [52, 55], [56, 57], [58, 65], [65, 66]]}
{"doc_key": "ai-dev-61", "ner": [[5, 5, "product"], [10, 10, "product"], [12, 14, "product"], [18, 20, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 10, 10, "named", "same", false, false], [12, 14, 10, 10, "origin", "derived_from", false, false], [12, 14, 18, 20, "origin", "", false, false], [12, 14, 22, 23, "origin", "", false, false], [12, 14, 25, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "most", "influential", "implementation", "of", "Planner", "was", "the", "subset", "of", "Planner", "called", "Micro", "-", "Planner", ",", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "."], "sentence-detokenized": "The most influential implementation of Planner was the subset of Planner called Micro-Planner, implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 35], [36, 38], [39, 46], [47, 50], [51, 54], [55, 61], [62, 64], [65, 72], [73, 79], [80, 85], [85, 86], [86, 93], [93, 94], [95, 106], [107, 109], [110, 116], [117, 120], [121, 128], [128, 129], [130, 136], [137, 145], [146, 149], [150, 155], [156, 164], [164, 165]]}
{"doc_key": "ai-dev-62", "ner": [[4, 6, "country"], [8, 10, "researcher"], [20, 20, "misc"], [21, 26, "university"], [35, 37, "misc"], [43, 44, "misc"], [49, 51, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[8, 10, 4, 6, "general-affiliation", "from_country", false, false], [21, 26, 20, 20, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1779", ",", "the", "German", "-", "Democratic", "scientist", "Christian", "Gottlieb", "Kratzenstein", "won", "first", "prize", "in", "a", "competition", "organised", "by", "the", "Russian", "Imperial", "Academy", "of", "Sciences", "and", "Arts", "for", "the", "models", "he", "built", "of", "the", "human", "vocal", "cords", "that", "could", "produce", "the", "five", "long", "vowel", "sounds", "(", "according", "to", "the", "International", "Phonetic", "Alphabet", ")", ":"], "sentence-detokenized": "In 1779, the German-Democratic scientist Christian Gottlieb Kratzenstein won first prize in a competition organised by the Russian Imperial Academy of Sciences and Arts for the models he built of the human vocal cords that could produce the five long vowel sounds (according to the International Phonetic Alphabet):", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [19, 20], [20, 30], [31, 40], [41, 50], [51, 59], [60, 72], [73, 76], [77, 82], [83, 88], [89, 91], [92, 93], [94, 105], [106, 115], [116, 118], [119, 122], [123, 130], [131, 139], [140, 147], [148, 150], [151, 159], [160, 163], [164, 168], [169, 172], [173, 176], [177, 183], [184, 186], [187, 192], [193, 195], [196, 199], [200, 205], [206, 211], [212, 217], [218, 222], [223, 228], [229, 236], [237, 240], [241, 245], [246, 250], [251, 256], [257, 263], [264, 265], [265, 274], [275, 277], [278, 281], [282, 295], [296, 304], [305, 313], [313, 314], [314, 315]]}
{"doc_key": "ai-dev-63", "ner": [[3, 4, "product"], [6, 7, "misc"], [10, 14, "misc"], [32, 34, "misc"], [55, 56, "task"], [61, 62, "product"], [64, 64, "product"], [68, 69, "task"], [71, 72, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 4, 61, 62, "related-to", "supports_program", false, false], [3, 4, 64, 64, "related-to", "supports_program", false, false], [6, 7, 3, 4, "part-of", "", false, false], [10, 14, 3, 4, "part-of", "", false, false], [32, 34, 3, 4, "part-of", "", false, false], [55, 56, 3, 4, "part-of", "", false, false], [68, 69, 3, 4, "part-of", "", false, false], [71, 72, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["New", "features", "in", "Office", "XP", "include", "smart", "tags", ",", "a", "selection", "-", "based", "search", "function", "that", "recognises", "different", "types", "of", "text", "in", "a", "document", "so", "users", "can", "perform", "additional", "actions", ",", "a", "task", "pane", "interface", "that", "gathers", "popular", "commands", "in", "the", "menu", "bar", "on", "the", "right", "side", "of", "the", "screen", "for", "quick", "access", ",", "new", "document", "collaboration", "features", ",", "support", "for", "MSN", "Groups", "and", "SharePoint", ",", "and", "integrated", "handwriting", "recognition", "and", "speech", "recognition", "."], "sentence-detokenized": "New features in Office XP include smart tags, a selection-based search function that recognises different types of text in a document so users can perform additional actions, a task pane interface that gathers popular commands in the menu bar on the right side of the screen for quick access, new document collaboration features, support for MSN Groups and SharePoint, and integrated handwriting recognition and speech recognition.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 25], [26, 33], [34, 39], [40, 44], [44, 45], [46, 47], [48, 57], [57, 58], [58, 63], [64, 70], [71, 79], [80, 84], [85, 95], [96, 105], [106, 111], [112, 114], [115, 119], [120, 122], [123, 124], [125, 133], [134, 136], [137, 142], [143, 146], [147, 154], [155, 165], [166, 173], [173, 174], [175, 176], [177, 181], [182, 186], [187, 196], [197, 201], [202, 209], [210, 217], [218, 226], [227, 229], [230, 233], [234, 238], [239, 242], [243, 245], [246, 249], [250, 255], [256, 260], [261, 263], [264, 267], [268, 274], [275, 278], [279, 284], [285, 291], [291, 292], [293, 296], [297, 305], [306, 319], [320, 328], [328, 329], [330, 337], [338, 341], [342, 345], [346, 352], [353, 356], [357, 367], [367, 368], [369, 372], [373, 383], [384, 395], [396, 407], [408, 411], [412, 418], [419, 430], [430, 431]]}
{"doc_key": "ai-dev-64", "ner": [[11, 12, "algorithm"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 15, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "many", "applications", ",", "the", "devices", "in", "these", "networks", "use", "a", "sigmoid", "function", "as", "an", "activation", "function", "."], "sentence-detokenized": "In many applications, the devices in these networks use a sigmoid function as an activation function.", "token2charspan": [[0, 2], [3, 7], [8, 20], [20, 21], [22, 25], [26, 33], [34, 36], [37, 42], [43, 51], [52, 55], [56, 57], [58, 65], [66, 74], [75, 77], [78, 80], [81, 91], [92, 100], [100, 101]]}
{"doc_key": "ai-dev-65", "ner": [[3, 3, "researcher"], [12, 17, "organisation"], [29, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 12, 17, "role", "", false, false], [3, 3, 29, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2001", ",", "Mehler", "was", "elected", "an", "Honorary", "Foreign", "Member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "and", "in", "2003", "he", "was", "elected", "a", "Fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In 2001, Mehler was elected an Honorary Foreign Member of the American Academy of Arts and Sciences, and in 2003 he was elected a Fellow of the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 27], [28, 30], [31, 39], [40, 47], [48, 54], [55, 57], [58, 61], [62, 70], [71, 78], [79, 81], [82, 86], [87, 90], [91, 99], [99, 100], [101, 104], [105, 107], [108, 112], [113, 115], [116, 119], [120, 127], [128, 129], [130, 136], [137, 139], [140, 143], [144, 152], [153, 164], [165, 168], [169, 172], [173, 184], [185, 187], [188, 195], [195, 196]]}
{"doc_key": "ai-dev-66", "ner": [[4, 6, "task"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 9, 10, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Extending", "this", "concept", "to", "non", "-binary", "classifications", "yields", "the", "confusion", "matrix", "."], "sentence-detokenized": "Extending this concept to non-binary classifications yields the confusion matrix.", "token2charspan": [[0, 9], [10, 14], [15, 22], [23, 25], [26, 29], [29, 36], [37, 52], [53, 59], [60, 63], [64, 73], [74, 80], [80, 81]]}
{"doc_key": "ai-dev-67", "ner": [[16, 17, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "updated", "estimate", "of", "the", "variance", "of", "the", "measurement", "noise", "can", "be", "obtained", "by", "calculating", "the", "maximum", "likelihood", "."], "sentence-detokenized": "An updated estimate of the variance of the measurement noise can be obtained by calculating the maximum likelihood.", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 22], [23, 26], [27, 35], [36, 38], [39, 42], [43, 54], [55, 60], [61, 64], [65, 67], [68, 76], [77, 79], [80, 91], [92, 95], [96, 103], [104, 114], [114, 115]]}
{"doc_key": "ai-dev-68", "ner": [[1, 2, "field"], [4, 5, "algorithm"], [10, 11, "field"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 10, 11, "usage", "", true, false], [4, 5, 13, 14, "related-to", "", true, false], [10, 11, 1, 2, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "machine", "learning", ",", "the", "perceptron", "is", "an", "algorithm", "for", "supervised", "learning", "of", "binary", "classification", "."], "sentence-detokenized": "In machine learning, the perceptron is an algorithm for supervised learning of binary classification.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 24], [25, 35], [36, 38], [39, 41], [42, 51], [52, 55], [56, 66], [67, 75], [76, 78], [79, 85], [86, 100], [100, 101]]}
{"doc_key": "ai-dev-69", "ner": [[7, 8, "field"], [10, 10, "field"], [14, 19, "conference"], [22, 26, "conference"], [29, 35, "conference"], [38, 42, "conference"], [45, 49, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 19, 7, 8, "topic", "", false, false], [14, 19, 10, 10, "topic", "", false, false], [22, 26, 7, 8, "topic", "", false, false], [22, 26, 10, 10, "topic", "", false, false], [29, 35, 7, 8, "topic", "", false, false], [29, 35, 10, 10, "topic", "", false, false], [38, 42, 7, 8, "topic", "", false, false], [38, 42, 10, 10, "topic", "", false, false], [45, 49, 7, 8, "topic", "", false, false], [45, 49, 10, 10, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["She", "has", "also", "chaired", "several", "conferences", "on", "machine", "learning", "and", "vision", ",", "including", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "the", "International", "Conference", "on", "Learning", "Representations", ",", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "the", "International", "Conference", "on", "Computer", "Vision", "and", "the", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "She has also chaired several conferences on machine learning and vision, including the Conference on Neural Information Processing Systems, the International Conference on Learning Representations, the Conference on Computer Vision and Pattern Recognition, the International Conference on Computer Vision and the European Conference on Computer Vision.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 20], [21, 28], [29, 40], [41, 43], [44, 51], [52, 60], [61, 64], [65, 71], [71, 72], [73, 82], [83, 86], [87, 97], [98, 100], [101, 107], [108, 119], [120, 130], [131, 138], [138, 139], [140, 143], [144, 157], [158, 168], [169, 171], [172, 180], [181, 196], [196, 197], [198, 201], [202, 212], [213, 215], [216, 224], [225, 231], [232, 235], [236, 243], [244, 255], [255, 256], [257, 260], [261, 274], [275, 285], [286, 288], [289, 297], [298, 304], [305, 308], [309, 312], [313, 321], [322, 332], [333, 335], [336, 344], [345, 351], [351, 352]]}
{"doc_key": "ai-dev-70", "ner": [[0, 2, "algorithm"], [8, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "condensation", "algorithm", "has", "also", "been", "used", "for", "face", "recognition", "systems", "in", "a", "video", "sequence", "."], "sentence-detokenized": "The condensation algorithm has also been used for face recognition systems in a video sequence.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 30], [31, 35], [36, 40], [41, 45], [46, 49], [50, 54], [55, 66], [67, 74], [75, 77], [78, 79], [80, 85], [86, 94], [94, 95]]}
{"doc_key": "ai-dev-71", "ner": [[0, 2, "task"], [7, 7, "organisation"], [17, 17, "conference"], [23, 26, "academicjournal"], [22, 27, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 17, 0, 2, "topic", "", false, false], [17, 17, 7, 7, "origin", "", false, false], [23, 26, 0, 2, "topic", "", false, false], [23, 26, 7, 7, "origin", "", true, false], [22, 27, 23, 26, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Dissemination", "of", "information", "is", "also", "part", "of", "ELRA", "'s", "mission", ",", "both", "through", "the", "organisation", "of", "the", "LREC", "conference", "and", "through", "the", "Springer", "Language", "Resources", "and", "Evaluation", "Journal", "."], "sentence-detokenized": "Dissemination of information is also part of ELRA's mission, both through the organisation of the LREC conference and through the Springer Language Resources and Evaluation Journal.", "token2charspan": [[0, 13], [14, 16], [17, 28], [29, 31], [32, 36], [37, 41], [42, 44], [45, 49], [49, 51], [52, 59], [59, 60], [61, 65], [66, 73], [74, 77], [78, 90], [91, 93], [94, 97], [98, 102], [103, 113], [114, 117], [118, 125], [126, 129], [130, 138], [139, 147], [148, 157], [158, 161], [162, 172], [173, 180], [180, 181]]}
{"doc_key": "ai-dev-72", "ner": [[2, 11, "field"], [14, 15, "field"], [19, 21, "field"], [23, 24, "field"], [60, 61, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 11, 60, 61, "named", "", false, false], [19, 21, 2, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "the", "theory", "of", "linear", "time", "-", "invariant", "(", "LTI", ")", "systems", ",", "in", "control", "theory", ",", "and", "in", "digital", "signal", "processing", "or", "signal", "processing", ",", "the", "relationship", "between", "the", "input", "signal", ",", "math", "\\", "displaystyle", "x", "(", "t", ")", "/", "math", ",", "and", "the", "output", "signal", ",", "math", "\\", "displaystyle", "y", "(", "t", ")", "/", "math", ",", "in", "an", "LTI", "system", "is", "governed", "by", "a", "convolution", "operation", ":"], "sentence-detokenized": "In the theory of linear time-invariant (LTI) systems, in control theory, and in digital signal processing or signal processing, the relationship between the input signal, math\\ displaystyle x(t)/math, and the output signal, math\\ displaystyle y(t)/math, in an LTI system is governed by a convolution operation:", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 23], [24, 28], [28, 29], [29, 38], [39, 40], [40, 43], [43, 44], [45, 52], [52, 53], [54, 56], [57, 64], [65, 71], [71, 72], [73, 76], [77, 79], [80, 87], [88, 94], [95, 105], [106, 108], [109, 115], [116, 126], [126, 127], [128, 131], [132, 144], [145, 152], [153, 156], [157, 162], [163, 169], [169, 170], [171, 175], [175, 176], [177, 189], [190, 191], [191, 192], [192, 193], [193, 194], [194, 195], [195, 199], [199, 200], [201, 204], [205, 208], [209, 215], [216, 222], [222, 223], [224, 228], [228, 229], [230, 242], [243, 244], [244, 245], [245, 246], [246, 247], [247, 248], [248, 252], [252, 253], [254, 256], [257, 259], [260, 263], [264, 270], [271, 273], [274, 282], [283, 285], [286, 287], [288, 299], [300, 309], [309, 310]]}
{"doc_key": "ai-dev-73", "ner": [[16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 31, "field"], [33, 34, "product"], [36, 37, "field"], [39, 39, "field"], [42, 43, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Because", "of", "its", "generality", ",", "the", "field", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimization", ",", "multiagent", "systems", ",", "swarm", "intelligence", ",", "statistics", ",", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Because of its generality, the field is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimization, multiagent systems, swarm intelligence, statistics, and genetic algorithms.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [25, 26], [27, 30], [31, 36], [37, 39], [40, 47], [48, 50], [51, 55], [56, 61], [62, 73], [73, 74], [75, 79], [80, 82], [83, 87], [88, 94], [94, 95], [96, 103], [104, 110], [110, 111], [112, 122], [123, 131], [131, 132], [133, 144], [145, 151], [151, 152], [153, 163], [163, 164], [164, 169], [170, 182], [182, 183], [184, 194], [195, 202], [202, 203], [204, 209], [210, 222], [222, 223], [224, 234], [234, 235], [236, 239], [240, 247], [248, 258], [258, 259]]}
{"doc_key": "ai-dev-74", "ner": [[0, 4, "algorithm"], [13, 15, "field"], [25, 26, "algorithm"], [30, 31, "algorithm"], [35, 35, "algorithm"], [36, 38, "researcher"], [40, 41, "researcher"], [43, 45, "researcher"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[13, 15, 0, 4, "usage", "", true, false], [25, 26, 13, 15, "part-of", "", true, false], [30, 31, 13, 15, "part-of", "", true, false], [35, 35, 13, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 2, 3, 4], "sentence": ["Stochastic", "gradient", "descent", "is", "a", "popular", "algorithm", "for", "training", "a", "wide", "range", "of", "machine", "learning", "models", ",", "including", "(", "linear", ")", "support", "vector", "machines", ",", "logistic", "regression", "(", "see", "e.g.", "Vowpal", "Wabbit", ")", ",", "and", "graphical", "models.Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastic gradient descent is a popular algorithm for training a wide range of machine learning models, including (linear) support vector machines, logistic regression (see e.g. Vowpal Wabbit), and graphical models.Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 30], [31, 32], [33, 40], [41, 50], [51, 54], [55, 63], [64, 65], [66, 70], [71, 76], [77, 79], [80, 87], [88, 96], [97, 103], [103, 104], [105, 114], [115, 116], [116, 122], [122, 123], [124, 131], [132, 138], [139, 147], [147, 148], [149, 157], [158, 168], [169, 170], [170, 173], [174, 178], [179, 185], [186, 192], [192, 193], [193, 194], [195, 198], [199, 208], [209, 221], [222, 226], [227, 233], [233, 234], [235, 239], [240, 247], [247, 248], [249, 260], [261, 263], [264, 271], [272, 273], [273, 277], [277, 278], [278, 279]]}
{"doc_key": "ai-dev-75", "ner": [[8, 8, "organisation"], [12, 13, "product"], [20, 20, "country"], [22, 25, "university"], [27, 27, "location"], [29, 31, "university"], [33, 33, "location"], [35, 36, "university"], [38, 38, "location"], [40, 42, "university"], [44, 44, "location"], [46, 47, "university"], [49, 49, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 22, 25, "role", "donates_to", false, false], [8, 8, 29, 31, "role", "donates_to", false, false], [8, 8, 35, 36, "role", "donates_to", false, false], [8, 8, 40, 42, "role", "donates_to", false, false], [8, 8, 46, 47, "role", "donates_to", false, false], [12, 13, 8, 8, "origin", "donates", true, false], [22, 25, 27, 27, "physical", "", false, false], [27, 27, 20, 20, "physical", "", false, false], [29, 31, 33, 33, "physical", "", false, false], [33, 33, 20, 20, "physical", "", false, false], [35, 36, 38, 38, "physical", "", false, false], [38, 38, 20, 20, "physical", "", false, false], [40, 42, 44, 44, "physical", "", false, false], [44, 44, 20, 20, "physical", "", false, false], [46, 47, 49, 49, "physical", "", false, false], [49, 49, 20, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["In", "August", "2011", ",", "it", "was", "announced", "that", "Hitachi", "would", "donate", "an", "electron", "microscope", "to", "each", "of", "five", "universities", "in", "Indonesia", "(", "University", "of", "North", "Sumatra", "in", "Medan", ",", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Padjadjaran", "University", "in", "Bandung", ",", "Jenderal", "Soedirman", "University", "in", "Purwokerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "sentence-detokenized": "In August 2011, it was announced that Hitachi would donate an electron microscope to each of five universities in Indonesia (University of North Sumatra in Medan, Indonesian Christian University in Jakarta, Padjadjaran University in Bandung, Jenderal Soedirman University in Purwokerto and Muhammadiyah University in Malang).", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 32], [33, 37], [38, 45], [46, 51], [52, 58], [59, 61], [62, 70], [71, 81], [82, 84], [85, 89], [90, 92], [93, 97], [98, 110], [111, 113], [114, 123], [124, 125], [125, 135], [136, 138], [139, 144], [145, 152], [153, 155], [156, 161], [161, 162], [163, 173], [174, 183], [184, 194], [195, 197], [198, 205], [205, 206], [207, 218], [219, 229], [230, 232], [233, 240], [240, 241], [242, 250], [251, 260], [261, 271], [272, 274], [275, 285], [286, 289], [290, 302], [303, 313], [314, 316], [317, 323], [323, 324], [324, 325]]}
{"doc_key": "ai-dev-76", "ner": [[3, 6, "field"], [8, 9, "algorithm"], [11, 12, "algorithm"], [27, 27, "metrics"]], "ner_mapping_to_source": [1, 2, 3, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Optimization", "techniques", "from", "operations", "research", ",", "such", "as", "linear", "programming", "or", "dynamic", "programming", ",", "are", "often", "impractical", "for", "large", "-", "scale", "software", "development", "problems", "due", "to", "their", "complexity", "."], "sentence-detokenized": "Optimization techniques from operations research, such as linear programming or dynamic programming, are often impractical for large-scale software development problems due to their complexity.", "token2charspan": [[0, 12], [13, 23], [24, 28], [29, 39], [40, 48], [48, 49], [50, 54], [55, 57], [58, 64], [65, 76], [77, 79], [80, 87], [88, 99], [99, 100], [101, 104], [105, 110], [111, 122], [123, 126], [127, 132], [132, 133], [133, 138], [139, 147], [148, 159], [160, 168], [169, 172], [173, 175], [176, 181], [182, 192], [192, 193]]}
{"doc_key": "ai-dev-77", "ner": [[0, 0, "metrics"], [6, 6, "metrics"], [8, 10, "metrics"], [15, 16, "metrics"], [19, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 6, "compare", "", false, false], [0, 0, 8, 10, "compare", "", false, false], [15, 16, 8, 10, "part-of", "", false, false], [19, 22, 8, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sensitivity", "is", "not", "the", "same", "as", "precision", "or", "positive", "predictive", "value", "(", "the", "ratio", "of", "true", "positives", "to", "combined", "true", "and", "false", "positives", ")", ",", "which", "is", "as", "much", "a", "statement", "about", "the", "proportion", "of", "actual", "positives", "in", "the", "population", "being", "tested", "as", "it", "is", "about", "the", "test", "."], "sentence-detokenized": "Sensitivity is not the same as precision or positive predictive value (the ratio of true positives to combined true and false positives), which is as much a statement about the proportion of actual positives in the population being tested as it is about the test.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 22], [23, 27], [28, 30], [31, 40], [41, 43], [44, 52], [53, 63], [64, 69], [70, 71], [71, 74], [75, 80], [81, 83], [84, 88], [89, 98], [99, 101], [102, 110], [111, 115], [116, 119], [120, 125], [126, 135], [135, 136], [136, 137], [138, 143], [144, 146], [147, 149], [150, 154], [155, 156], [157, 166], [167, 172], [173, 176], [177, 187], [188, 190], [191, 197], [198, 207], [208, 210], [211, 214], [215, 225], [226, 231], [232, 238], [239, 241], [242, 244], [245, 247], [248, 253], [254, 257], [258, 262], [262, 263]]}
{"doc_key": "ai-dev-78", "ner": [[3, 4, "person"], [9, 9, "product"], [12, 12, "person"], [27, 27, "person"], [34, 35, "person"], [39, 40, "person"], [45, 47, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 4, 39, 40, "named", "same", false, false], [9, 9, 3, 4, "artifact", "", false, false], [34, 35, 45, 47, "role", "convinces", false, false], [45, 47, 9, 9, "role", "producer", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "screenplay", "by", "Hampton", "Fancher", "--", "not", "originally", "titled", "Android", "--", "see", "Sammon", ",", "pp.", "32", "and", "38", "for", "an", "explanation", "--", "was", "optioned", "in", "1977", ".", "Sammon", ",", "pp.", "23", "-", "30", "Producer", "Michael", "Deeley", "became", "interested", "in", "Fancher", "'s", "draft", "and", "convinced", "director", "Ridley", "Scott", "to", "film", "it", "."], "sentence-detokenized": "The screenplay by Hampton Fancher -- not originally titled Android -- see Sammon, pp. 32 and 38 for an explanation -- was optioned in 1977. Sammon, pp. 23-30 Producer Michael Deeley became interested in Fancher's draft and convinced director Ridley Scott to film it.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 25], [26, 33], [34, 36], [37, 40], [41, 51], [52, 58], [59, 66], [67, 69], [70, 73], [74, 80], [80, 81], [82, 85], [86, 88], [89, 92], [93, 95], [96, 99], [100, 102], [103, 114], [115, 117], [118, 121], [122, 130], [131, 133], [134, 138], [138, 139], [140, 146], [146, 147], [148, 151], [152, 154], [154, 155], [155, 157], [158, 166], [167, 174], [175, 181], [182, 188], [189, 199], [200, 202], [203, 210], [210, 212], [213, 218], [219, 222], [223, 232], [233, 241], [242, 248], [249, 254], [255, 257], [258, 262], [263, 265], [265, 266]]}
{"doc_key": "ai-dev-79", "ner": [[0, 1, "field"], [3, 4, "task"], [6, 7, "task"], [10, 12, "misc"], [14, 15, "field"], [17, 19, "task"], [21, 22, "task"], [28, 31, "task"], [33, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [6, 7, 0, 1, "part-of", "", false, false], [10, 12, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false], [17, 19, 0, 1, "part-of", "", false, false], [21, 22, 0, 1, "part-of", "", false, false], [28, 31, 0, 1, "part-of", "", false, false], [33, 33, 0, 1, "part-of", "", false, false], [35, 36, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9], "sentence": ["Text", "analysis", "includes", "information", "retrieval", ",", "lexical", "analysis", "to", "study", "word", "frequency", "distributions", ",", "pattern", "recognition", ",", "tagging", "/", "annotation", ",", "information", "extraction", ",", "data", "mining", "techniques", "including", "link", "and", "association", "analysis", ",", "visualisation", "and", "predictive", "analysis", "."], "sentence-detokenized": "Text analysis includes information retrieval, lexical analysis to study word frequency distributions, pattern recognition, tagging/annotation, information extraction, data mining techniques including link and association analysis, visualisation and predictive analysis.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 34], [35, 44], [44, 45], [46, 53], [54, 62], [63, 65], [66, 71], [72, 76], [77, 86], [87, 100], [100, 101], [102, 109], [110, 121], [121, 122], [123, 130], [130, 131], [131, 141], [141, 142], [143, 154], [155, 165], [165, 166], [167, 171], [172, 178], [179, 189], [190, 199], [200, 204], [205, 208], [209, 220], [221, 229], [229, 230], [231, 244], [245, 248], [249, 259], [260, 268], [268, 269]]}
{"doc_key": "ai-dev-80", "ner": [[3, 3, "product"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Several", "surveys", "use", "WordNet", ",", "a", "manually", "constructed", "lexical", "database", "of", "English", "words", "."], "sentence-detokenized": "Several surveys use WordNet, a manually constructed lexical database of English words.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 27], [27, 28], [29, 30], [31, 39], [40, 51], [52, 59], [60, 68], [69, 71], [72, 79], [80, 85], [85, 86]]}
{"doc_key": "ai-dev-81", "ner": [[8, 9, "field"], [11, 12, "task"], [14, 19, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "system", "uses", "a", "combination", "of", "techniques", "from", "computational", "linguistics", ",", "information", "retrieval", "and", "knowledge", "representation", "to", "find", "the", "answers", "."], "sentence-detokenized": "The system uses a combination of techniques from computational linguistics, information retrieval and knowledge representation to find the answers.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 17], [18, 29], [30, 32], [33, 43], [44, 48], [49, 62], [63, 74], [74, 75], [76, 87], [88, 97], [98, 101], [102, 111], [112, 126], [127, 129], [130, 134], [135, 138], [139, 146], [146, 147]]}
{"doc_key": "ai-dev-82", "ner": [[0, 2, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "uncertainty", "coefficient", "has", "the", "advantage", "that", "it", "is", "not", "affected", "by", "the", "relative", "size", "of", "the", "different", "classes", "."], "sentence-detokenized": "The uncertainty coefficient has the advantage that it is not affected by the relative size of the different classes.", "token2charspan": [[0, 3], [4, 15], [16, 27], [28, 31], [32, 35], [36, 45], [46, 50], [51, 53], [54, 56], [57, 60], [61, 69], [70, 72], [73, 76], [77, 85], [86, 90], [91, 93], [94, 97], [98, 107], [108, 115], [115, 116]]}
{"doc_key": "ai-dev-83", "ner": [[11, 12, "algorithm"], [14, 15, "algorithm"], [17, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Researchers", "have", "attempted", "to", "use", "a", "number", "of", "methods", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "hidden", "Markov", "models", ",", "etc", "."], "sentence-detokenized": "Researchers have attempted to use a number of methods such as optical flow, Kalman filtering, hidden Markov models, etc.", "token2charspan": [[0, 11], [12, 16], [17, 26], [27, 29], [30, 33], [34, 35], [36, 42], [43, 45], [46, 53], [54, 58], [59, 61], [62, 69], [70, 74], [74, 75], [76, 82], [83, 92], [92, 93], [94, 100], [101, 107], [108, 114], [114, 115], [116, 119], [119, 120]]}
{"doc_key": "ai-dev-84", "ner": [[14, 17, "conference"], [31, 33, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "has", "served", "as", "President", ",", "Vice", "President", ",", "Secretary", "and", "Treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "has", "been", "a", "Board", "Member", "and", "Secretary", "of", "the", "Board", "of", "the", "Computing", "Research", "Association", "."], "sentence-detokenized": "She has served as President, Vice President, Secretary and Treasurer of the Association for Computational Linguistics and has been a Board Member and Secretary of the Board of the Computing Research Association.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 17], [18, 27], [27, 28], [29, 33], [34, 43], [43, 44], [45, 54], [55, 58], [59, 68], [69, 71], [72, 75], [76, 87], [88, 91], [92, 105], [106, 117], [118, 121], [122, 125], [126, 130], [131, 132], [133, 138], [139, 145], [146, 149], [150, 159], [160, 162], [163, 166], [167, 172], [173, 175], [176, 179], [180, 189], [190, 198], [199, 210], [210, 211]]}
{"doc_key": "ai-dev-85", "ner": [[6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 10, 10, "compare", "", false, false], [6, 6, 12, 13, "related-to", "supports", false, false], [8, 8, 10, 10, "compare", "", false, false], [8, 8, 12, 13, "related-to", "supports", false, false], [10, 10, 12, 13, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Like", "other", "similar", "languages", "such", "as", "APL", "and", "MATLAB", ",", "R", "supports", "matrix", "arithmetic", "."], "sentence-detokenized": "Like other similar languages such as APL and MATLAB, R supports matrix arithmetic.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 28], [29, 33], [34, 36], [37, 40], [41, 44], [45, 51], [51, 52], [53, 54], [55, 63], [64, 70], [71, 81], [81, 82]]}
{"doc_key": "ai-dev-86", "ner": [[13, 14, "organisation"], [18, 19, "researcher"], [22, 24, "university"], [28, 33, "misc"], [5, 5, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[18, 19, 22, 24, "role", "works_for", false, false]], "relations_mapping_to_source": [3], "sentence": ["On", "7", "June", "2014", ",", "Goostman", "won", "a", "Turing", "test", "competition", "at", "the", "Royal", "Society", ",", "organised", "by", "Kevin", "Warwick", "of", "the", "University", "of", "Reading", "to", "commemorate", "the", "60th", "anniversary", "of", "Turing", "'s", "death", ",", "after", "33", "%", "of", "the", "judges", "were", "convinced", "that", "the", "robot", "was", "human", "."], "sentence-detokenized": "On 7 June 2014, Goostman won a Turing test competition at the Royal Society, organised by Kevin Warwick of the University of Reading to commemorate the 60th anniversary of Turing's death, after 33% of the judges were convinced that the robot was human.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 14], [14, 15], [16, 24], [25, 28], [29, 30], [31, 37], [38, 42], [43, 54], [55, 57], [58, 61], [62, 67], [68, 75], [75, 76], [77, 86], [87, 89], [90, 95], [96, 103], [104, 106], [107, 110], [111, 121], [122, 124], [125, 132], [133, 135], [136, 147], [148, 151], [152, 156], [157, 168], [169, 171], [172, 178], [178, 180], [181, 186], [186, 187], [188, 193], [194, 196], [196, 197], [198, 200], [201, 204], [205, 211], [212, 216], [217, 226], [227, 231], [232, 235], [236, 241], [242, 245], [246, 251], [251, 252]]}
{"doc_key": "ai-dev-87", "ner": [[1, 2, "product"], [4, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "collaborative", "robot", "or", "cobot", "is", "a", "robot", "that", "can", "safely", "and", "efficiently", "interact", "with", "humans", "when", "performing", "simple", "industrial", "tasks", "."], "sentence-detokenized": "A collaborative robot or cobot is a robot that can safely and efficiently interact with humans when performing simple industrial tasks.", "token2charspan": [[0, 1], [2, 15], [16, 21], [22, 24], [25, 30], [31, 33], [34, 35], [36, 41], [42, 46], [47, 50], [51, 57], [58, 61], [62, 73], [74, 82], [83, 87], [88, 94], [95, 99], [100, 110], [111, 117], [118, 128], [129, 134], [134, 135]]}
{"doc_key": "ai-dev-88", "ner": [[13, 14, "field"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 30, "task"], [32, 34, "task"], [37, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[17, 18, 13, 14, "part-of", "task_part_of_field", false, false], [20, 21, 13, 14, "part-of", "task_part_of_field", false, false], [23, 24, 13, 14, "part-of", "task_part_of_field", false, false], [26, 27, 13, 14, "part-of", "task_part_of_field", false, false], [29, 30, 13, 14, "part-of", "task_part_of_field", false, false], [32, 34, 13, 14, "part-of", "task_part_of_field", false, false], [37, 38, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "comprehensive", "framework", "has", "been", "applied", "to", "a", "wide", "range", "of", "problems", "in", "computer", "vision", ",", "including", "feature", "detection", ",", "feature", "classification", ",", "image", "segmentation", ",", "image", "matching", ",", "motion", "estimation", ",", "shape", "indication", "computation", ",", "and", "object", "recognition", "."], "sentence-detokenized": "This comprehensive framework has been applied to a wide range of problems in computer vision, including feature detection, feature classification, image segmentation, image matching, motion estimation, shape indication computation, and object recognition.", "token2charspan": [[0, 4], [5, 18], [19, 28], [29, 32], [33, 37], [38, 45], [46, 48], [49, 50], [51, 55], [56, 61], [62, 64], [65, 73], [74, 76], [77, 85], [86, 92], [92, 93], [94, 103], [104, 111], [112, 121], [121, 122], [123, 130], [131, 145], [145, 146], [147, 152], [153, 165], [165, 166], [167, 172], [173, 181], [181, 182], [183, 189], [190, 200], [200, 201], [202, 207], [208, 218], [219, 230], [230, 231], [232, 235], [236, 242], [243, 254], [254, 255]]}
{"doc_key": "ai-dev-89", "ner": [[5, 6, "task"], [8, 10, "algorithm"], [13, 17, "algorithm"], [26, 26, "algorithm"], [31, 32, "algorithm"], [36, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 8, 10, "part-of", "", false, false], [5, 6, 13, 17, "usage", "", false, false], [8, 10, 26, 26, "named", "same", false, false], [26, 26, 31, 32, "related-to", "", false, false], [26, 26, 36, 37, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "many", "practical", "applications", ",", "parameter", "estimation", "for", "naive", "Bayesian", "models", "uses", "the", "maximum", "likelihood", "method", ";", "in", "other", "words", ",", "one", "can", "work", "with", "the", "naive", "Bayesian", "model", "without", "accepting", "Bayesian", "probability", "or", "using", "any", "Bayesian", "methods", "."], "sentence-detokenized": "In many practical applications, parameter estimation for naive Bayesian models uses the maximum likelihood method; in other words, one can work with the naive Bayesian model without accepting Bayesian probability or using any Bayesian methods.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 30], [30, 31], [32, 41], [42, 52], [53, 56], [57, 62], [63, 71], [72, 78], [79, 83], [84, 87], [88, 95], [96, 106], [107, 113], [113, 114], [115, 117], [118, 123], [124, 129], [129, 130], [131, 134], [135, 138], [139, 143], [144, 148], [149, 152], [153, 158], [159, 167], [168, 173], [174, 181], [182, 191], [192, 200], [201, 212], [213, 215], [216, 221], [222, 225], [226, 234], [235, 242], [242, 243]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [12, 15, "university"], [17, 19, "researcher"], [21, 22, "misc"], [27, 27, "university"], [24, 26, "misc"], [37, 39, "university"], [45, 48, "misc"], [50, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10], "relations": [[2, 4, 12, 15, "physical", "", false, false], [2, 4, 12, 15, "role", "", false, false], [2, 4, 17, 19, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [17, 19, 27, 27, "physical", "", false, false], [17, 19, 27, 27, "role", "", false, false], [17, 19, 37, 39, "physical", "", false, false], [17, 19, 37, 39, "role", "", false, false], [21, 22, 17, 19, "named", "", false, false], [24, 26, 17, 19, "origin", "", false, false], [45, 48, 17, 19, "artifact", "", false, false], [45, 48, 50, 53, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13], "sentence": ["Brothers", "-", "Victor", "Gershevich", "Katz", ",", "American", "mathematician", ",", "professor", "at", "the", "Massachusetts", "Institute", "of", "Technology", ";", "Mikhail", "Gershevich", "Katz", ",", "Israeli", "mathematician", ",", "doctoral", "student", "at", "Harvard", "and", "Columbia", "Universities", "(", "1984", ")", ",", "professor", "at", "Bar-", "Ilan", "University", ",", "author", "of", "the", "monograph", "Systolic", "Geometry", "and", "Topology", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", "."], "sentence-detokenized": "Brothers - Victor Gershevich Katz, American mathematician, professor at the Massachusetts Institute of Technology; Mikhail Gershevich Katz, Israeli mathematician, doctoral student at Harvard and Columbia Universities (1984), professor at Bar-Ilan University, author of the monograph Systolic Geometry and Topology (Mathematical Surveys and Monographs, vol.", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 28], [29, 33], [33, 34], [35, 43], [44, 57], [57, 58], [59, 68], [69, 71], [72, 75], [76, 89], [90, 99], [100, 102], [103, 113], [113, 114], [115, 122], [123, 133], [134, 138], [138, 139], [140, 147], [148, 161], [161, 162], [163, 171], [172, 179], [180, 182], [183, 190], [191, 194], [195, 203], [204, 216], [217, 218], [218, 222], [222, 223], [223, 224], [225, 234], [235, 237], [238, 242], [242, 246], [247, 257], [257, 258], [259, 265], [266, 268], [269, 272], [273, 282], [283, 291], [292, 300], [301, 304], [305, 313], [314, 315], [315, 327], [328, 335], [336, 339], [340, 350], [350, 351], [352, 355], [355, 356]]}
{"doc_key": "ai-dev-91", "ner": [[3, 6, "person"], [10, 11, "conference"], [16, 19, "organisation"], [21, 27, "location"], [31, 31, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 10, 11, "physical", "", false, false], [3, 6, 10, 11, "role", "", false, false], [3, 6, 16, 19, "role", "", false, false], [16, 19, 21, 27, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2000", ",", "Manuel", "Toharia", ",", "a", "speaker", "at", "previous", "Campus", "Parties", "and", "director", "of", "the", "Pr\u00edncipe", "Felipe", "Science", "Museum", "in", "Valencia", "'s", "city", "of", "art", "and", "science", ",", "proposed", "that", "Ragageles", "expand", "the", "event", "and", "make", "it", "more", "international", "by", "moving", "it", "to", "the", "famous", "museum", "."], "sentence-detokenized": "In 2000, Manuel Toharia, a speaker at previous Campus Parties and director of the Pr\u00edncipe Felipe Science Museum in Valencia's city of art and science, proposed that Ragageles expand the event and make it more international by moving it to the famous museum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 23], [23, 24], [25, 26], [27, 34], [35, 37], [38, 46], [47, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 81], [82, 90], [91, 97], [98, 105], [106, 112], [113, 115], [116, 124], [124, 126], [127, 131], [132, 134], [135, 138], [139, 142], [143, 150], [150, 151], [152, 160], [161, 165], [166, 175], [176, 182], [183, 186], [187, 192], [193, 196], [197, 201], [202, 204], [205, 209], [210, 223], [224, 226], [227, 233], [234, 236], [237, 239], [240, 243], [244, 250], [251, 257], [257, 258]]}
{"doc_key": "ai-dev-92", "ner": [[5, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Within", "20", "minutes", ",", "a", "facial", "recognition", "system", "identifies", "personal", "information", ",", "including", "family", "name", ",", "ID", "number", "and", "address", ",", "displayed", "on", "the", "street", "on", "an", "advertising", "screen", "."], "sentence-detokenized": "Within 20 minutes, a facial recognition system identifies personal information, including family name, ID number and address, displayed on the street on an advertising screen.", "token2charspan": [[0, 6], [7, 9], [10, 17], [17, 18], [19, 20], [21, 27], [28, 39], [40, 46], [47, 57], [58, 66], [67, 78], [78, 79], [80, 89], [90, 96], [97, 101], [101, 102], [103, 105], [106, 112], [113, 116], [117, 124], [124, 125], [126, 135], [136, 138], [139, 142], [143, 149], [150, 152], [153, 155], [156, 167], [168, 174], [174, 175]]}
{"doc_key": "ai-dev-93", "ner": [[8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "research", "has", "increasingly", "focused", "on", "algorithms", "for", "unsupervised", "learning", "and", "semi-supervised", "learning", "."], "sentence-detokenized": "Recent research has increasingly focused on algorithms for unsupervised learning and semi-supervised learning.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 32], [33, 40], [41, 43], [44, 54], [55, 58], [59, 71], [72, 80], [81, 84], [85, 100], [101, 109], [109, 110]]}
{"doc_key": "ai-dev-94", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Calculation", "of", "this", "example", "using", "Python", "code", ":"], "sentence-detokenized": "Calculation of this example using Python code:", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 27], [28, 33], [34, 40], [41, 45], [45, 46]]}
{"doc_key": "ai-dev-95", "ner": [[7, 8, "task"], [15, 15, "field"], [19, 23, "algorithm"], [25, 25, "algorithm"], [29, 31, "algorithm"], [34, 35, "researcher"], [37, 38, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[19, 23, 15, 15, "part-of", "", false, false], [19, 23, 29, 31, "type-of", "", false, false], [19, 23, 34, 35, "origin", "", false, false], [19, 23, 37, 38, "origin", "", false, false], [25, 25, 19, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Today", ",", "however", ",", "many", "aspects", "of", "speech", "recognition", "have", "been", "taken", "over", "by", "a", "deep", "learning", "method", "called", "long", "short", "-", "term", "memory", "(", "LSTM", ")", ",", "a", "recurrent", "neural", "network", "published", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "."], "sentence-detokenized": "Today, however, many aspects of speech recognition have been taken over by a deep learning method called long short-term memory (LSTM), a recurrent neural network published by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997.", "token2charspan": [[0, 5], [5, 6], [7, 14], [14, 15], [16, 20], [21, 28], [29, 31], [32, 38], [39, 50], [51, 55], [56, 60], [61, 66], [67, 71], [72, 74], [75, 76], [77, 81], [82, 90], [91, 97], [98, 104], [105, 109], [110, 115], [115, 116], [116, 120], [121, 127], [128, 129], [129, 133], [133, 134], [134, 135], [136, 137], [138, 147], [148, 154], [155, 162], [163, 172], [173, 175], [176, 180], [181, 191], [192, 195], [196, 202], [203, 214], [215, 217], [218, 222], [222, 223]]}
{"doc_key": "ai-dev-96", "ner": [[8, 8, "algorithm"], [10, 11, "algorithm"], [16, 16, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 10, 11, "compare", "", false, false], [8, 8, 21, 21, "named", "same", false, false], [16, 16, 21, 21, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "preliminary", "experimental", "results", "with", "noisy", "datasets", ",", "BrownBoost", "outperformed", "AdaBoost", "'s", "generalization", "error", ",", "but", "LogitBoost", "performed", "as", "well", "as", "BrownBoost", "."], "sentence-detokenized": "In preliminary experimental results with noisy datasets, BrownBoost outperformed AdaBoost's generalization error, but LogitBoost performed as well as BrownBoost.", "token2charspan": [[0, 2], [3, 14], [15, 27], [28, 35], [36, 40], [41, 46], [47, 55], [55, 56], [57, 67], [68, 80], [81, 89], [89, 91], [92, 106], [107, 112], [112, 113], [114, 117], [118, 128], [129, 138], [139, 141], [142, 146], [147, 149], [150, 160], [160, 161]]}
{"doc_key": "ai-dev-97", "ner": [[0, 1, "algorithm"], [5, 7, "researcher"], [10, 11, "country"], [14, 16, "researcher"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 7, "part-of", "", false, false], [5, 7, 10, 11, "physical", "", false, false], [20, 21, 14, 16, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evolutionary", "programming", "was", "introduced", "by", "Lawrence", "J.", "Fogel", "in", "the", "United", "States", ",", "while", "John", "Henry", "Holland", "called", "his", "method", "genetic", "algorithm", "."], "sentence-detokenized": "Evolutionary programming was introduced by Lawrence J. Fogel in the United States, while John Henry Holland called his method genetic algorithm.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 54], [55, 60], [61, 63], [64, 67], [68, 74], [75, 81], [81, 82], [83, 88], [89, 93], [94, 99], [100, 107], [108, 114], [115, 118], [119, 125], [126, 133], [134, 143], [143, 144]]}
{"doc_key": "ai-dev-98", "ner": [[0, 0, "researcher"], [2, 2, "researcher"], [8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 8, 9, "role", "", false, false], [0, 0, 11, 12, "role", "", false, false], [0, 0, 14, 15, "role", "", false, false], [0, 0, 17, 18, "role", "", false, false], [2, 2, 8, 9, "role", "", false, false], [2, 2, 11, 12, "role", "", false, false], [2, 2, 14, 15, "role", "", false, false], [2, 2, 17, 18, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Doug", ",", "Alan", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", "and", "John", "McCarthy", ")", "estimated", "that", "this", "would", "require", "between", "1,000", "and", "3,000", "person", "-", "years", ",", "which", "is", "far", "more", "than", "the", "standard", "academic", "project", "model", "."], "sentence-detokenized": "Doug, Alan and their colleagues (including Marvin Minsky, Allen Newell, Edward Feigenbaum and John McCarthy) estimated that this would require between 1,000 and 3,000 person-years, which is far more than the standard academic project model.", "token2charspan": [[0, 4], [4, 5], [6, 10], [11, 14], [15, 20], [21, 31], [32, 33], [33, 42], [43, 49], [50, 56], [56, 57], [58, 63], [64, 70], [70, 71], [72, 78], [79, 89], [90, 93], [94, 98], [99, 107], [107, 108], [109, 118], [119, 123], [124, 128], [129, 134], [135, 142], [143, 150], [151, 156], [157, 160], [161, 166], [167, 173], [173, 174], [174, 179], [179, 180], [181, 186], [187, 189], [190, 193], [194, 198], [199, 203], [204, 207], [208, 216], [217, 225], [226, 233], [234, 239], [239, 240]]}
{"doc_key": "ai-dev-99", "ner": [[4, 6, "metrics"], [11, 11, "metrics"], [14, 16, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 11, 11, "part-of", "implemented_in", false, false], [14, 16, 20, 20, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Common", "criteria", "are", "the", "mean", "square", "error", "criterion", "implemented", "in", "the", "MSECriterion", "and", "the", "cross", "entropy", "criterion", "implemented", "in", "the", "NLLCriterion", "."], "sentence-detokenized": "Common criteria are the mean square error criterion implemented in the MSECriterion and the cross entropy criterion implemented in the NLLCriterion.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 23], [24, 28], [29, 35], [36, 41], [42, 51], [52, 63], [64, 66], [67, 70], [71, 83], [84, 87], [88, 91], [92, 97], [98, 105], [106, 115], [116, 127], [128, 130], [131, 134], [135, 147], [147, 148]]}
{"doc_key": "ai-dev-100", "ner": [[0, 0, "researcher"], [13, 13, "organisation"], [16, 27, "misc"], [33, 36, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 13, 13, "role", "", false, false], [0, 0, 33, 36, "role", "", false, false], [16, 27, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 3], "sentence": ["Zurada", "has", "served", "the", "engineering", "profession", "as", "a", "long", "-", "time", "volunteer", "with", "IEEE", ":", "as", "Vice", "Chair", "of", "IEEE", "Technical", "Activities", "(", "TAB", "Chair", ")", "in", "2014", ",", "as", "Chair", "of", "the", "IEEE", "Computational", "Intelligence", "Society", "in", "2004", "-", "05", ",", "and", "as", "an", "ADCOM", "member", "in", "2009", "-", "14", ",", "2016", "-", "18", "and", "prior", "years", "."], "sentence-detokenized": "Zurada has served the engineering profession as a long-time volunteer with IEEE: as Vice Chair of IEEE Technical Activities (TAB Chair) in 2014, as Chair of the IEEE Computational Intelligence Society in 2004-05, and as an ADCOM member in 2009-14, 2016-18 and prior years.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 21], [22, 33], [34, 44], [45, 47], [48, 49], [50, 54], [54, 55], [55, 59], [60, 69], [70, 74], [75, 79], [79, 80], [81, 83], [84, 88], [89, 94], [95, 97], [98, 102], [103, 112], [113, 123], [124, 125], [125, 128], [129, 134], [134, 135], [136, 138], [139, 143], [143, 144], [145, 147], [148, 153], [154, 156], [157, 160], [161, 165], [166, 179], [180, 192], [193, 200], [201, 203], [204, 208], [208, 209], [209, 211], [211, 212], [213, 216], [217, 219], [220, 222], [223, 228], [229, 235], [236, 238], [239, 243], [243, 244], [244, 246], [246, 247], [248, 252], [252, 253], [253, 255], [256, 259], [260, 265], [266, 271], [271, 272]]}
{"doc_key": "ai-dev-101", "ner": [[3, 6, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 3, 6, "part-of", "", false, false], [12, 13, 3, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "general", ",", "computational", "linguistics", "draws", "on", "linguists", ",", "computer", "scientists", ",", "artificial", "intelligence", "experts", ",", "mathematicians", ",", "logicians", ",", "philosophers", ",", "cognitive", "scientists", ",", "cognitive", "psychologists", ",", "psycholinguists", ",", "anthropologists", "and", "neuroscientists", ",", "among", "others", "."], "sentence-detokenized": "In general, computational linguistics draws on linguists, computer scientists, artificial intelligence experts, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists and neuroscientists, among others.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 25], [26, 37], [38, 43], [44, 46], [47, 56], [56, 57], [58, 66], [67, 77], [77, 78], [79, 89], [90, 102], [103, 110], [110, 111], [112, 126], [126, 127], [128, 137], [137, 138], [139, 151], [151, 152], [153, 162], [163, 173], [173, 174], [175, 184], [185, 198], [198, 199], [200, 215], [215, 216], [217, 232], [233, 236], [237, 252], [252, 253], [254, 259], [260, 266], [266, 267]]}
{"doc_key": "ai-dev-102", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "term", "memory", "are", "often", "used", "to", "exploit", "the", "correlations", "between", "the", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long term memory are often used to exploit the correlations between the frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [83, 87], [88, 94], [95, 98], [99, 104], [105, 109], [110, 112], [113, 120], [121, 124], [125, 137], [138, 145], [146, 149], [150, 156], [156, 157]]}
{"doc_key": "ai-dev-103", "ner": [[0, 2, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "was", "the", "first", "industrial", "robot", ","], "sentence-detokenized": "Unimate was the first industrial robot,", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 21], [22, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-dev-104", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 11, 13, "win-defeat", "", false, false], [5, 6, 11, 13, "win-defeat", "", false, false], [8, 8, 11, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Together", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "won", "the", "Turing", "Award", "2018", "."], "sentence-detokenized": "Together with Geoffrey Hinton and Yann LeCun, Bengio won the Turing Award 2018.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 29], [30, 33], [34, 38], [39, 44], [44, 45], [46, 52], [53, 56], [57, 60], [61, 67], [68, 73], [74, 78], [78, 79]]}
{"doc_key": "ai-dev-105", "ner": [[6, 6, "country"], [20, 23, "misc"], [25, 25, "country"], [29, 30, "organisation"], [34, 35, "person"], [39, 40, "person"], [46, 48, "misc"], [53, 53, "country"], [59, 59, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[20, 23, 6, 6, "physical", "filmed_in", false, false], [34, 35, 29, 30, "role", "host", false, false], [39, 40, 29, 30, "role", "reporter", false, false], [46, 48, 6, 6, "physical", "filmed_in", false, false], [46, 48, 53, 53, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Additional", "series", "were", "filmed", "in", "the", "UK", "arena", "for", "specific", "sectors", "of", "the", "global", "market", ",", "including", "two", "series", "of", "Robot", "Wars", "Extreme", "Warriors", "with", "US", "competitors", "for", "the", "TNN", "network", "(", "hosted", "by", "Mick", "Foley", "and", "reported", "by", "Rebecca", "Grant", ")", ",", "two", "series", "of", "Dutch", "Robot", "Wars", "for", "distribution", "in", "the", "Netherlands", "and", "a", "single", "series", "for", "Germany", "."], "sentence-detokenized": "Additional series were filmed in the UK arena for specific sectors of the global market, including two series of Robot Wars Extreme Warriors with US competitors for the TNN network (hosted by Mick Foley and reported by Rebecca Grant), two series of Dutch Robot Wars for distribution in the Netherlands and a single series for Germany.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 29], [30, 32], [33, 36], [37, 39], [40, 45], [46, 49], [50, 58], [59, 66], [67, 69], [70, 73], [74, 80], [81, 87], [87, 88], [89, 98], [99, 102], [103, 109], [110, 112], [113, 118], [119, 123], [124, 131], [132, 140], [141, 145], [146, 148], [149, 160], [161, 164], [165, 168], [169, 172], [173, 180], [181, 182], [182, 188], [189, 191], [192, 196], [197, 202], [203, 206], [207, 215], [216, 218], [219, 226], [227, 232], [232, 233], [233, 234], [235, 238], [239, 245], [246, 248], [249, 254], [255, 260], [261, 265], [266, 269], [270, 282], [283, 285], [286, 289], [290, 301], [302, 305], [306, 307], [308, 314], [315, 321], [322, 325], [326, 333], [333, 334]]}
{"doc_key": "ai-dev-106", "ner": [[8, 8, "researcher"], [13, 15, "product"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 13, 15, "role", "", false, false], [30, 31, 13, 15, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "many", "years", ",", "starting", "in", "1986", ",", "Miller", "led", "the", "development", "of", "WordNet", ",", "a", "large", "computer", "-", "readable", "electronic", "reference", "that", "can", "be", "used", "in", "programs", "such", "as", "search", "engines", "."], "sentence-detokenized": "For many years, starting in 1986, Miller led the development of WordNet, a large computer-readable electronic reference that can be used in programs such as search engines.", "token2charspan": [[0, 3], [4, 8], [9, 14], [14, 15], [16, 24], [25, 27], [28, 32], [32, 33], [34, 40], [41, 44], [45, 48], [49, 60], [61, 63], [64, 71], [71, 72], [73, 74], [75, 80], [81, 89], [89, 90], [90, 98], [99, 109], [110, 119], [120, 124], [125, 128], [129, 131], [132, 136], [137, 139], [140, 148], [149, 153], [154, 156], [157, 163], [164, 171], [171, 172]]}
{"doc_key": "ai-dev-107", "ner": [[4, 5, "algorithm"], [8, 11, "algorithm"], [14, 16, "researcher"], [21, 24, "organisation"], [28, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 14, 16, "origin", "", false, false], [4, 5, 28, 30, "win-defeat", "", false, false], [8, 11, 14, 16, "origin", "", false, false], [8, 11, 28, 30, "win-defeat", "", false, false], [14, 16, 21, 24, "physical", "", false, false], [14, 16, 21, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Since", "2009", ",", "the", "recurrent", "neural", "networks", "and", "deep", "feedforward", "neural", "networks", "developed", "in", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "Swiss", "AI", "laboratory", "IDSIA", "have", "won", "several", "international", "handwriting", "competitions", "..."], "sentence-detokenized": "Since 2009, the recurrent neural networks and deep feedforward neural networks developed in J\u00fcrgen Schmidhuber's research group at the Swiss AI laboratory IDSIA have won several international handwriting competitions...", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 15], [16, 25], [26, 32], [33, 41], [42, 45], [46, 50], [51, 62], [63, 69], [70, 78], [79, 88], [89, 91], [92, 98], [99, 110], [110, 112], [113, 121], [122, 127], [128, 130], [131, 134], [135, 140], [141, 143], [144, 154], [155, 160], [161, 165], [166, 169], [170, 177], [178, 191], [192, 203], [204, 216], [216, 219]]}
{"doc_key": "ai-dev-108", "ner": [[5, 6, "programlang"], [12, 12, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "is", "implemented", "in", "C", "+++", "and", "it", "is", "packaged", "for", "Python", "."], "sentence-detokenized": "The software is implemented in C+++ and it is packaged for Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 30], [31, 32], [32, 35], [36, 39], [40, 42], [43, 45], [46, 54], [55, 58], [59, 65], [65, 66]]}
{"doc_key": "ai-dev-109", "ner": [[8, 9, "country"], [14, 15, "misc"], [18, 21, "misc"], [31, 33, "misc"], [34, 34, "misc"], [36, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 21, 8, 9, "temporal", "", false, false], [18, 21, 14, 15, "artifact", "", false, false], [18, 21, 36, 36, "physical", "", false, false], [34, 34, 31, 33, "named", "", false, false], [34, 34, 36, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1857", ",", "at", "the", "request", "of", "the", "Tokugawa", "Shogunate", ",", "a", "group", "of", "Dutch", "engineers", "began", "building", "Nagasaki", "Yotetsusho", ",", "a", "modern", "Western", "-", "style", "foundry", "and", "shipyard", "near", "the", "Dutch", "settlement", "of", "Dejima", "in", "Nagasaki", "."], "sentence-detokenized": "In 1857, at the request of the Tokugawa Shogunate, a group of Dutch engineers began building Nagasaki Yotetsusho, a modern Western-style foundry and shipyard near the Dutch settlement of Dejima in Nagasaki.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 39], [40, 49], [49, 50], [51, 52], [53, 58], [59, 61], [62, 67], [68, 77], [78, 83], [84, 92], [93, 101], [102, 112], [112, 113], [114, 115], [116, 122], [123, 130], [130, 131], [131, 136], [137, 144], [145, 148], [149, 157], [158, 162], [163, 166], [167, 172], [173, 183], [184, 186], [187, 193], [194, 196], [197, 205], [205, 206]]}
{"doc_key": "ai-dev-110", "ner": [[10, 12, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["We", "do", "as", "well", "as", "possible", "exactly", "by", "measuring", "the", "mean", "square", "error", "between", "mathy", "/", "math", "and", "math", "\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "we", "want", "math", "(", "y", "-\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", "^", "2", "/", "math", "to", "be", "minimal", ",", "both", "for", "mathx", "_", "1", ".\\", "points", ",", "x", "_n", "/", "math", "and", "for", "points", "outside", "our", "sample", "."], "sentence-detokenized": "We do as well as possible exactly by measuring the mean square error between mathy/math and math\\ hat {f} (x; D) / math: we want math (y -\\ hat {f} (x; D)) ^ 2 / math to be minimal, both for mathx _ 1.\\ points, x _n / math and for points outside our sample.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 13], [14, 16], [17, 25], [26, 33], [34, 36], [37, 46], [47, 50], [51, 55], [56, 62], [63, 68], [69, 76], [77, 82], [82, 83], [83, 87], [88, 91], [92, 96], [96, 97], [98, 101], [102, 103], [103, 104], [104, 105], [106, 107], [107, 108], [108, 109], [110, 111], [111, 112], [113, 114], [115, 119], [119, 120], [121, 123], [124, 128], [129, 133], [134, 135], [135, 136], [137, 139], [140, 143], [144, 145], [145, 146], [146, 147], [148, 149], [149, 150], [150, 151], [152, 153], [153, 154], [154, 155], [156, 157], [158, 159], [160, 161], [162, 166], [167, 169], [170, 172], [173, 180], [180, 181], [182, 186], [187, 190], [191, 196], [197, 198], [199, 200], [200, 202], [203, 209], [209, 210], [211, 212], [213, 215], [216, 217], [218, 222], [223, 226], [227, 230], [231, 237], [238, 245], [246, 249], [250, 256], [256, 257]]}
{"doc_key": "ai-dev-111", "ner": [[3, 3, "researcher"], [7, 10, "organisation"], [17, 23, "product"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 7, 10, "role", "", false, false], [17, 23, 7, 10, "temporal", "", false, false], [17, 23, 27, 28, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "then", "invited", "Wydner", "to", "attend", "the", "American", "Translators", "Association", "'s", "annual", "meeting", "in", "October", ",", "where", "Weidner", "'s", "machine", "translation", "system", "made", "a", "hopeful", "breakthrough", "in", "machine", "translation", "."], "sentence-detokenized": "He then invited Wydner to attend the American Translators Association's annual meeting in October, where Weidner's machine translation system made a hopeful breakthrough in machine translation.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 22], [23, 25], [26, 32], [33, 36], [37, 45], [46, 57], [58, 69], [69, 71], [72, 78], [79, 86], [87, 89], [90, 97], [97, 98], [99, 104], [105, 112], [112, 114], [115, 122], [123, 134], [135, 141], [142, 146], [147, 148], [149, 156], [157, 169], [170, 172], [173, 180], [181, 192], [192, 193]]}
{"doc_key": "ai-dev-112", "ner": [[2, 10, "conference"], [8, 8, "conference"], [14, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 2, 10, "named", "", false, false], [8, 8, 2, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["At", "the", "2018", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "conference", ",", "researchers", "from", "Google", "presented", "the", "work", "."], "sentence-detokenized": "At the 2018 Neural Information Processing Systems (NeurIPS) conference, researchers from Google presented the work.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 30], [31, 41], [42, 49], [50, 51], [51, 58], [58, 59], [60, 70], [70, 71], [72, 83], [84, 88], [89, 95], [96, 105], [106, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-dev-113", "ner": [[0, 4, "algorithm"], [10, 11, "algorithm"], [15, 17, "metrics"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 10, 11, "usage", "", false, false], [10, 11, 15, 17, "related-to", "", true, false], [15, 17, 23, 25, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Baum", "-", "Welch", "algorithm", "uses", "the", "well", "-", "known", "EM", "algorithm", "to", "find", "the", "maximum", "likelihood", "estimate", "of", "the", "parameters", "of", "a", "hidden", "Markov", "model", "with", "a", "set", "of", "observed", "function", "vectors", "."], "sentence-detokenized": "The Baum-Welch algorithm uses the well-known EM algorithm to find the maximum likelihood estimate of the parameters of a hidden Markov model with a set of observed function vectors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [15, 24], [25, 29], [30, 33], [34, 38], [38, 39], [39, 44], [45, 47], [48, 57], [58, 60], [61, 65], [66, 69], [70, 77], [78, 88], [89, 97], [98, 100], [101, 104], [105, 115], [116, 118], [119, 120], [121, 127], [128, 134], [135, 140], [141, 145], [146, 147], [148, 151], [152, 154], [155, 163], [164, 172], [173, 180], [180, 181]]}
{"doc_key": "ai-dev-114", "ner": [[7, 7, "product"], [9, 9, "product"], [29, 30, "misc"], [33, 44, "product"], [50, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[7, 7, 9, 9, "compare", "", false, false], [29, 30, 9, 9, "part-of", "", false, false], [33, 44, 9, 9, "part-of", "", false, false], [50, 56, 9, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "addition", "to", "the", "taxonomic", "information", "in", "OpenCyc", ",", "ResearchCyc", "contains", "much", "more", "semantic", "knowledge", "(", "i.e.", "additional", "facts", "and", "rules", "of", "thumb", ")", "about", "the", "concepts", "in", "the", "knowledge", "base", ",", "a", "large", "dictionary", ",", "tools", "for", "analysing", "and", "generating", "English", "-", "language", "information", ",", "and", "Java", "-", "based", "interfaces", "for", "editing", "and", "searching", "the", "knowledge", "."], "sentence-detokenized": "In addition to the taxonomic information in OpenCyc, ResearchCyc contains much more semantic knowledge (i.e. additional facts and rules of thumb) about the concepts in the knowledge base, a large dictionary, tools for analysing and generating English-language information, and Java-based interfaces for editing and searching the knowledge.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 28], [29, 40], [41, 43], [44, 51], [51, 52], [53, 64], [65, 73], [74, 78], [79, 83], [84, 92], [93, 102], [103, 104], [104, 108], [109, 119], [120, 125], [126, 129], [130, 135], [136, 138], [139, 144], [144, 145], [146, 151], [152, 155], [156, 164], [165, 167], [168, 171], [172, 181], [182, 186], [186, 187], [188, 189], [190, 195], [196, 206], [206, 207], [208, 213], [214, 217], [218, 227], [228, 231], [232, 242], [243, 250], [250, 251], [251, 259], [260, 271], [271, 272], [273, 276], [277, 281], [281, 282], [282, 287], [288, 298], [299, 302], [303, 310], [311, 314], [315, 324], [325, 328], [329, 338], [338, 339]]}
{"doc_key": "ai-dev-115", "ner": [[0, 2, "algorithm"], [5, 6, "task"], [10, 11, "field"], [13, 14, "field"], [16, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 6, "type-of", "", false, false], [5, 6, 10, 11, "part-of", "task_part_of_field", false, false], [5, 6, 13, 14, "part-of", "task_part_of_field", false, false], [5, 6, 16, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Hough", "transform", "is", "a", "feature", "extraction", "technique", "used", "in", "image", "analysis", ",", "computer", "vision", "and", "digital", "image", "processing", "."], "sentence-detokenized": "The Hough transform is a feature extraction technique used in image analysis, computer vision and digital image processing.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 22], [23, 24], [25, 32], [33, 43], [44, 53], [54, 58], [59, 61], [62, 67], [68, 76], [76, 77], [78, 86], [87, 93], [94, 97], [98, 105], [106, 111], [112, 122], [122, 123]]}
{"doc_key": "ai-dev-116", "ner": [[6, 6, "product"], [8, 12, "product"], [3, 3, "organisation"], [16, 16, "product"], [18, 21, "researcher"], [25, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 8, 12, "named", "", false, false], [6, 6, 3, 3, "artifact", "", false, false], [6, 6, 16, 16, "origin", "developed_from", false, false], [16, 16, 18, 21, "artifact", "", false, false], [25, 26, 3, 3, "role", "supported", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1978", ",", "Unimation", "developed", "the", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "robot", "from", "Vicarm", "(", "Victor", "Scheinman", ")", "and", "with", "support", "from", "General", "Motors", "."], "sentence-detokenized": "In 1978, Unimation developed the PUMA (Programmable Universal Machine for Assembly) robot from Vicarm (Victor Scheinman) and with support from General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 28], [29, 32], [33, 37], [38, 39], [39, 51], [52, 61], [62, 69], [70, 73], [74, 82], [82, 83], [84, 89], [90, 94], [95, 101], [102, 103], [103, 109], [110, 119], [119, 120], [121, 124], [125, 129], [130, 137], [138, 142], [143, 150], [151, 157], [157, 158]]}
{"doc_key": "ai-dev-117", "ner": [[0, 1, "algorithm"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 7, 8, "origin", "", false, false], [0, 1, 10, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "LSTM", "was", "proposed", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "The LSTM was proposed in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 21], [22, 24], [25, 29], [30, 32], [33, 37], [38, 48], [49, 52], [53, 59], [60, 71], [71, 72]]}
{"doc_key": "ai-dev-118", "ner": [[10, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated in a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 76], [77, 83], [84, 86], [87, 94], [94, 95]]}
{"doc_key": "ai-dev-119", "ner": [[7, 7, "conference"], [10, 11, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "also", "contributed", "greatly", "by", "setting", "up", "ELRA", "and", "the", "LREC", "conference", "."], "sentence-detokenized": "He also contributed greatly by setting up ELRA and the LREC conference.", "token2charspan": [[0, 2], [3, 7], [8, 19], [20, 27], [28, 30], [31, 38], [39, 41], [42, 46], [47, 50], [51, 54], [55, 59], [60, 70], [70, 71]]}
{"doc_key": "ai-dev-120", "ner": [[11, 13, "misc"], [21, 22, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 22, 11, 13, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "popular", "application", "for", "serial", "robots", "in", "today", "'s", "industry", "is", "assembly", "robots", "for", "picking", "and", "placing", ",", "so", "-", "called", "SCARA", "robots", ",", "which", "have", "four", "degrees", "of", "freedom", "."], "sentence-detokenized": "A popular application for serial robots in today's industry is assembly robots for picking and placing, so-called SCARA robots, which have four degrees of freedom.", "token2charspan": [[0, 1], [2, 9], [10, 21], [22, 25], [26, 32], [33, 39], [40, 42], [43, 48], [48, 50], [51, 59], [60, 62], [63, 71], [72, 78], [79, 82], [83, 90], [91, 94], [95, 102], [102, 103], [104, 106], [106, 107], [107, 113], [114, 119], [120, 126], [126, 127], [128, 133], [134, 138], [139, 143], [144, 151], [152, 154], [155, 162], [162, 163]]}
{"doc_key": "ai-dev-121", "ner": [[14, 20, "conference"], [22, 22, "conference"], [26, 29, "conference"], [36, 36, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 14, 20, "named", "", false, false], [36, 36, 26, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "one", "of", "the", "founders", "and", "former", "chair", "(", "2006-2008", ")", "of", "the", "Special", "Interest", "Group", "on", "Web", "as", "Corpus", "(", "SIGWAC", ")", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "one", "of", "the", "founders", "of", "SENSEVAL", "."], "sentence-detokenized": "He was one of the founders and former chair (2006-2008) of the Special Interest Group on Web as Corpus (SIGWAC) of the Association for Computational Linguistics and one of the founders of SENSEVAL.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 17], [18, 26], [27, 30], [31, 37], [38, 43], [44, 45], [45, 54], [54, 55], [56, 58], [59, 62], [63, 70], [71, 79], [80, 85], [86, 88], [89, 92], [93, 95], [96, 102], [103, 104], [104, 110], [110, 111], [112, 114], [115, 118], [119, 130], [131, 134], [135, 148], [149, 160], [161, 164], [165, 168], [169, 171], [172, 175], [176, 184], [185, 187], [188, 196], [196, 197]]}
{"doc_key": "ai-dev-122", "ner": [[4, 4, "product"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 4, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "platform", ",", "LinguaStream", "provides", "a", "comprehensive", "Java", "API", "."], "sentence-detokenized": "As a platform, LinguaStream provides a comprehensive Java API.", "token2charspan": [[0, 2], [3, 4], [5, 13], [13, 14], [15, 27], [28, 36], [37, 38], [39, 52], [53, 57], [58, 61], [61, 62]]}
{"doc_key": "ai-dev-123", "ner": [[11, 11, "programlang"], [13, 16, "misc"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 19, 21, "type-of", "", false, false], [13, 16, 19, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "robot", "kit", "is", "Android", "-", "based", "and", "is", "programmed", "using", "Java", ",", "the", "Blocks", "programming", "interface", "or", "other", "Android", "programming", "systems", "."], "sentence-detokenized": "The robot kit is Android-based and is programmed using Java, the Blocks programming interface or other Android programming systems.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 16], [17, 24], [24, 25], [25, 30], [31, 34], [35, 37], [38, 48], [49, 54], [55, 59], [59, 60], [61, 64], [65, 71], [72, 83], [84, 93], [94, 96], [97, 102], [103, 110], [111, 122], [123, 130], [130, 131]]}
{"doc_key": "ai-dev-124", "ner": [[12, 15, "algorithm"], [18, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "method", "for", "defining", "the", "linked", "list", "specifies", "the", "use", "of", "a", "depth", "-", "first", "search", "or", "a", "width", "-", "first", "search", "."], "sentence-detokenized": "The method for defining the linked list specifies the use of a depth-first search or a width-first search.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 27], [28, 34], [35, 39], [40, 49], [50, 53], [54, 57], [58, 60], [61, 62], [63, 68], [68, 69], [69, 74], [75, 81], [82, 84], [85, 86], [87, 92], [92, 93], [93, 98], [99, 105], [105, 106]]}
{"doc_key": "ai-dev-125", "ner": [[22, 23, "task"], [27, 30, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "areas", "can", "signal", "the", "presence", "of", "objects", "or", "parts", "of", "objects", "in", "the", "image", "domain", ",", "which", "can", "be", "used", "for", "object", "recognition", "and", "/", "or", "video", "tracking", "of", "objects", "."], "sentence-detokenized": "These areas can signal the presence of objects or parts of objects in the image domain, which can be used for object recognition and/or video tracking of objects.", "token2charspan": [[0, 5], [6, 11], [12, 15], [16, 22], [23, 26], [27, 35], [36, 38], [39, 46], [47, 49], [50, 55], [56, 58], [59, 66], [67, 69], [70, 73], [74, 79], [80, 86], [86, 87], [88, 93], [94, 97], [98, 100], [101, 105], [106, 109], [110, 116], [117, 128], [129, 132], [132, 133], [133, 135], [136, 141], [142, 150], [151, 153], [154, 161], [161, 162]]}
{"doc_key": "ai-dev-126", "ner": [[4, 5, "algorithm"], [7, 9, "product"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 4, 5, "type-of", "", false, false], [7, 9, 13, 13, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "semantic", "network", "is", "WordNet", ",", "a", "lexical", "database", "for", "English", "."], "sentence-detokenized": "An example of a semantic network is WordNet, a lexical database for English.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 32], [33, 35], [36, 43], [43, 44], [45, 46], [47, 54], [55, 63], [64, 67], [68, 75], [75, 76]]}
{"doc_key": "ai-dev-127", "ner": [[0, 3, "task"], [7, 8, "field"], [10, 11, "field"], [21, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 7, 8, "part-of", "", false, false], [0, 3, 10, 11, "named", "same", false, false], [0, 3, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Speech", "recognition", "is", "an", "interdisciplinary", "subfield", "of", "computer", "science", "and", "computational", "linguistics", "that", "develops", "methods", "and", "technologies", "to", "enable", "computers", "to", "recognise", "and", "translate", "spoken", "language", "into", "text", "."], "sentence-detokenized": "Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methods and technologies to enable computers to recognise and translate spoken language into text.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 24], [25, 42], [43, 51], [52, 54], [55, 63], [64, 71], [72, 75], [76, 89], [90, 101], [102, 106], [107, 115], [116, 123], [124, 127], [128, 140], [141, 143], [144, 150], [151, 160], [161, 163], [164, 173], [174, 177], [178, 187], [188, 194], [195, 203], [204, 208], [209, 213], [213, 214]]}
{"doc_key": "ai-dev-128", "ner": [[0, 1, "field"], [7, 8, "misc"], [13, 15, "field"], [17, 18, "task"], [20, 21, "task"], [45, 46, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 45, 46, "named", "same", false, false], [13, 15, 0, 1, "part-of", "subfield", false, false], [17, 18, 0, 1, "part-of", "", false, false], [17, 18, 13, 15, "part-of", "", false, false], [20, 21, 13, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Artificial", "intelligence", "has", "received", "most", "attention", "in", "applied", "ontology", "in", "subfields", "such", "as", "natural", "language", "processing", "in", "machine", "learning", "and", "knowledge", "representation", ",", "but", "ontology", "editors", "are", "often", "used", "in", "a", "range", "of", "areas", ",", "such", "as", "education", ",", "without", "the", "intention", "of", "contributing", "to", "artificial", "intelligence", "."], "sentence-detokenized": "Artificial intelligence has received most attention in applied ontology in subfields such as natural language processing in machine learning and knowledge representation, but ontology editors are often used in a range of areas, such as education, without the intention of contributing to artificial intelligence.", "token2charspan": [[0, 10], [11, 23], [24, 27], [28, 36], [37, 41], [42, 51], [52, 54], [55, 62], [63, 71], [72, 74], [75, 84], [85, 89], [90, 92], [93, 100], [101, 109], [110, 120], [121, 123], [124, 131], [132, 140], [141, 144], [145, 154], [155, 169], [169, 170], [171, 174], [175, 183], [184, 191], [192, 195], [196, 201], [202, 206], [207, 209], [210, 211], [212, 217], [218, 220], [221, 226], [226, 227], [228, 232], [233, 235], [236, 245], [245, 246], [247, 254], [255, 258], [259, 268], [269, 271], [272, 284], [285, 287], [288, 298], [299, 311], [311, 312]]}
{"doc_key": "ai-dev-129", "ner": [[7, 7, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 7, 11, 12, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "update", "rule", "is", "in", "fact", "the", "stochastic", "gradient", "update", "for", "linear", "regression", "."], "sentence-detokenized": "This update rule is in fact the stochastic gradient update for linear regression.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 22], [23, 27], [28, 31], [32, 42], [43, 51], [52, 58], [59, 62], [63, 69], [70, 80], [80, 81]]}
{"doc_key": "ai-dev-130", "ner": [[5, 10, "organisation"], [13, 16, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "elected", "to", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "the", "National", "Academy", "of", "Sciences", "and", "has", "received", "a", "number", "of", "awards", ":"], "sentence-detokenized": "He was elected to the American Academy of Arts and Sciences and the National Academy of Sciences and has received a number of awards:", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 46], [47, 50], [51, 59], [60, 63], [64, 67], [68, 76], [77, 84], [85, 87], [88, 96], [97, 100], [101, 104], [105, 113], [114, 115], [116, 122], [123, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-dev-131", "ner": [[4, 5, "organisation"], [11, 12, "person"], [14, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 11, 12, "related-to", "written_about_by", false, false], [4, 5, 14, 17, "related-to", "written_about_by", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "latest", "thinking", "on", "Honda", "'s", "strategy", "was", "put", "forward", "by", "Gary", "Hamel", "and", "C.", "K", ".", "Prahalad", "in", "1989", "."], "sentence-detokenized": "The latest thinking on Honda's strategy was put forward by Gary Hamel and C. K. Prahalad in 1989.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 22], [23, 28], [28, 30], [31, 39], [40, 43], [44, 47], [48, 55], [56, 58], [59, 63], [64, 69], [70, 73], [74, 76], [77, 78], [78, 79], [80, 88], [89, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-dev-132", "ner": [[1, 1, "metrics"], [5, 6, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 5, 6, "related-to", "calculates", true, false], [1, 1, 19, 19, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "BLEU", "simply", "calculates", "the", "precision", "of", "an", "n-", "gram", "by", "giving", "equal", "weight", "to", "each", "n-", "gram", ",", "NIST", "also", "calculates", "how", "informative", "a", "given", "n-", "gram", "is", "."], "sentence-detokenized": "While BLEU simply calculates the precision of an n-gram by giving equal weight to each n-gram, NIST also calculates how informative a given n-gram is.", "token2charspan": [[0, 5], [6, 10], [11, 17], [18, 28], [29, 32], [33, 42], [43, 45], [46, 48], [49, 51], [51, 55], [56, 58], [59, 65], [66, 71], [72, 78], [79, 81], [82, 86], [87, 89], [89, 93], [93, 94], [95, 99], [100, 104], [105, 115], [116, 119], [120, 131], [132, 133], [134, 139], [140, 142], [142, 146], [147, 149], [149, 150]]}
{"doc_key": "ai-dev-133", "ner": [[5, 8, "misc"], [11, 14, "conference"], [16, 16, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 8, 11, 14, "temporal", "", false, false], [16, 16, 11, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "honored", "with", "the", "2019", "Lifetime", "Achievement", "Award", "from", "the", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "He was honored with the 2019 Lifetime Achievement Award from the Association for Computational Linguistics (ACL).", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 19], [20, 23], [24, 28], [29, 37], [38, 49], [50, 55], [56, 60], [61, 64], [65, 76], [77, 80], [81, 94], [95, 106], [107, 108], [108, 111], [111, 112], [112, 113]]}
{"doc_key": "ai-dev-134", "ner": [[0, 2, "researcher"], [6, 11, "organisation"], [13, 13, "organisation"], [17, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 6, 11, "role", "", false, false], [0, 2, 17, 21, "role", "", false, false], [13, 13, 6, 11, "named", "", false, false], [23, 23, 17, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "is", "a", "member", "of", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "and", "the", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara is a member of the Institute of Electrical and Electronics Engineers (IEEE) and the American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 18], [19, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 65], [66, 75], [76, 77], [77, 81], [81, 82], [83, 86], [87, 90], [91, 99], [100, 111], [112, 115], [116, 126], [127, 139], [140, 141], [141, 145], [145, 146], [146, 147]]}
{"doc_key": "ai-dev-135", "ner": [[11, 11, "misc"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "MATLAB", "code", "shows", "a", "concrete", "solution", "to", "solve", "the", "non-linear", "system", "of", "equations", "presented", "in", "the", "previous", "section", ":", "see", "also"], "sentence-detokenized": "The following MATLAB code shows a concrete solution to solve the non-linear system of equations presented in the previous section: see also", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 31], [32, 33], [34, 42], [43, 51], [52, 54], [55, 60], [61, 64], [65, 75], [76, 82], [83, 85], [86, 95], [96, 105], [106, 108], [109, 112], [113, 121], [122, 129], [129, 130], [131, 134], [135, 139]]}
{"doc_key": "ai-dev-136", "ner": [[0, 2, "product"], [13, 14, "field"], [36, 37, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 13, 14, "related-to", "trained_by", true, false], [0, 2, 36, 37, "related-to", "trained_by", true, false], [13, 14, 36, 37, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Pattern", "recognition", "systems", "are", "in", "many", "cases", "trained", "from", "labelled", "training", "data", "(", "supervised", "learning", ")", ",", "but", "when", "no", "labelled", "data", "is", "available", ",", "other", "algorithms", "can", "be", "used", "to", "detect", "previously", "unknown", "patterns", "(", "unsupervised", "learning", ")", "."], "sentence-detokenized": "Pattern recognition systems are in many cases trained from labelled training data (supervised learning), but when no labelled data is available, other algorithms can be used to detect previously unknown patterns (unsupervised learning).", "token2charspan": [[0, 7], [8, 19], [20, 27], [28, 31], [32, 34], [35, 39], [40, 45], [46, 53], [54, 58], [59, 67], [68, 76], [77, 81], [82, 83], [83, 93], [94, 102], [102, 103], [103, 104], [105, 108], [109, 113], [114, 116], [117, 125], [126, 130], [131, 133], [134, 143], [143, 144], [145, 150], [151, 161], [162, 165], [166, 168], [169, 173], [174, 176], [177, 183], [184, 194], [195, 202], [203, 211], [212, 213], [213, 225], [226, 234], [234, 235], [235, 236]]}
{"doc_key": "ai-dev-137", "ner": [[5, 7, "researcher"], [10, 10, "country"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 10, 10, "physical", "", false, false], [5, 7, 26, 27, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "was", "first", "used", "by", "Lawrence", "J.", "Fogel", "in", "the", "USA", "in", "1960", "to", "use", "simulated", "evolution", "as", "a", "learning", "process", "for", "the", "purpose", "of", "creating", "artificial", "intelligence", "."], "sentence-detokenized": "It was first used by Lawrence J. Fogel in the USA in 1960 to use simulated evolution as a learning process for the purpose of creating artificial intelligence.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 17], [18, 20], [21, 29], [30, 32], [33, 38], [39, 41], [42, 45], [46, 49], [50, 52], [53, 57], [58, 60], [61, 64], [65, 74], [75, 84], [85, 87], [88, 89], [90, 98], [99, 106], [107, 110], [111, 114], [115, 122], [123, 125], [126, 134], [135, 145], [146, 158], [158, 159]]}
{"doc_key": "ai-dev-138", "ner": [[0, 1, "field"], [9, 10, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 9, 10, "part-of", "", false, false], [14, 15, 9, 10, "part-of", "", false, false], [17, 18, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Reinforcement", "learning", "is", "one", "of", "three", "basic", "paradigms", "of", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "unsupervised", "learning", "."], "sentence-detokenized": "Reinforcement learning is one of three basic paradigms of machine learning, along with supervised learning and unsupervised learning.", "token2charspan": [[0, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 38], [39, 44], [45, 54], [55, 57], [58, 65], [66, 74], [74, 75], [76, 81], [82, 86], [87, 97], [98, 106], [107, 110], [111, 123], [124, 132], [132, 133]]}
{"doc_key": "ai-dev-139", "ner": [[4, 5, "field"], [10, 10, "programlang"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 28, 29, "usage", "applies", false, false], [10, 10, 28, 29, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "such", "cases", ",", "cloud", "services", "and", "the", "open", "source", "R", "programming", "language", "can", "help", "smaller", "banks", "to", "implement", "risk", "analysis", "and", "support", "branch", "-", "level", "monitoring", "using", "predictive", "analytics", "."], "sentence-detokenized": "In such cases, cloud services and the open source R programming language can help smaller banks to implement risk analysis and support branch-level monitoring using predictive analytics.", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 20], [21, 29], [30, 33], [34, 37], [38, 42], [43, 49], [50, 51], [52, 63], [64, 72], [73, 76], [77, 81], [82, 89], [90, 95], [96, 98], [99, 108], [109, 113], [114, 122], [123, 126], [127, 134], [135, 141], [141, 142], [142, 147], [148, 158], [159, 164], [165, 175], [176, 185], [185, 186]]}
{"doc_key": "ai-dev-140", "ner": [[11, 12, "researcher"], [19, 20, "algorithm"], [22, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 22, 23, "named", "same", false, false], [19, 20, 11, 12, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["One", "of", "the", "first", "versions", "of", "the", "theorem", "was", "proved", "by", "George", "Cybenko", "in", "1989", "for", "activation", "functions", "with", "sigmoid", "function", ".", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "One of the first versions of the theorem was proved by George Cybenko in 1989 for activation functions with sigmoid function. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 25], [26, 28], [29, 32], [33, 40], [41, 44], [45, 51], [52, 54], [55, 61], [62, 69], [70, 72], [73, 77], [78, 81], [82, 92], [93, 102], [103, 107], [108, 115], [116, 124], [124, 125], [126, 133], [134, 136], [137, 138], [138, 142], [142, 143], [143, 144], [145, 146], [147, 148], [148, 149], [149, 150], [150, 151], [152, 159], [159, 160]]}
{"doc_key": "ai-dev-141", "ner": [[5, 7, "algorithm"], [8, 9, "metrics"], [15, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 5, 7, "part-of", "", false, false], [15, 20, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "process", ",", "called", "cross-validation", ",", "the", "MSE", "is", "often", "referred", "to", "as", "the", "mean-", "squared", "prediction", "error", "and", "is", "calculated", "as", "follows"], "sentence-detokenized": "In this process, called cross-validation, the MSE is often referred to as the mean-squared prediction error and is calculated as follows", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 23], [24, 40], [40, 41], [42, 45], [46, 49], [50, 52], [53, 58], [59, 67], [68, 70], [71, 73], [74, 77], [78, 83], [83, 90], [91, 101], [102, 107], [108, 111], [112, 114], [115, 125], [126, 128], [129, 136]]}
{"doc_key": "ai-dev-142", "ner": [[0, 0, "task"], [4, 6, "task"], [8, 8, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 6, "compare", "", false, false], [8, 8, 4, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["OMR", "generally", "differs", "from", "Optical", "Character", "Recognition", "(", "OCR", ")", "in", "that", "it", "does", "not", "require", "a", "complex", "pattern", "recognition", "engine", "."], "sentence-detokenized": "OMR generally differs from Optical Character Recognition (OCR) in that it does not require a complex pattern recognition engine.", "token2charspan": [[0, 3], [4, 13], [14, 21], [22, 26], [27, 34], [35, 44], [45, 56], [57, 58], [58, 61], [61, 62], [63, 65], [66, 70], [71, 73], [74, 78], [79, 82], [83, 90], [91, 92], [93, 100], [101, 108], [109, 120], [121, 127], [127, 128]]}
{"doc_key": "ai-dev-143", "ner": [[11, 11, "location"], [13, 13, "location"], [15, 15, "location"], [18, 19, "location"], [21, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 15, 15, "physical", "", false, false], [18, 19, 13, 13, "physical", "", false, false], [21, 22, 13, 13, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2018", "and", "2019", ",", "the", "championship", "will", "be", "held", "in", "Houston", "and", "Detroit", ",", "Michigan", "at", "the", "TCF", "Center", "and", "Ford", "Field", "."], "sentence-detokenized": "In 2018 and 2019, the championship will be held in Houston and Detroit, Michigan at the TCF Center and Ford Field.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 16], [16, 17], [18, 21], [22, 34], [35, 39], [40, 42], [43, 47], [48, 50], [51, 58], [59, 62], [63, 70], [70, 71], [72, 80], [81, 83], [84, 87], [88, 91], [92, 98], [99, 102], [103, 107], [108, 113], [113, 114]]}
{"doc_key": "ai-dev-144", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "considered", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multi-class", "classification", "."], "sentence-detokenized": "Classification can be considered as two separate problems - binary classification and multi-class classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 97], [98, 112], [112, 113]]}
{"doc_key": "ai-dev-145", "ner": [[4, 5, "product"], [8, 9, "product"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "type-of", "", false, false], [12, 13, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "examples", "of", "popular", "parallel", "robots", "are", "the", "Stewart", "platform", "and", "the", "Delta", "robot", "."], "sentence-detokenized": "Two examples of popular parallel robots are the Stewart platform and the Delta robot.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 23], [24, 32], [33, 39], [40, 43], [44, 47], [48, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-146", "ner": [[0, 6, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 6, 21, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "However", ",", "the", "ReLU", "activation", "function", ",", "which", "is", "non-differentiable", "at", "0", ",", "has", "become", "quite", "popular", ",", "e.g.", "in", "AlexNet", ")", "."], "sentence-detokenized": "(However, the ReLU activation function, which is non-differentiable at 0, has become quite popular, e.g. in AlexNet).", "token2charspan": [[0, 1], [1, 8], [8, 9], [10, 13], [14, 18], [19, 29], [30, 38], [38, 39], [40, 45], [46, 48], [49, 67], [68, 70], [71, 72], [72, 73], [74, 77], [78, 84], [85, 90], [91, 98], [98, 99], [100, 104], [105, 107], [108, 115], [115, 116], [116, 117]]}
{"doc_key": "ai-dev-147", "ner": [[0, 3, "metrics"], [11, 12, "task"], [18, 18, "task"], [20, 21, "task"], [23, 26, "task"], [27, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 27, 29, "named", "", true, false], [11, 12, 0, 3, "usage", "", true, false], [18, 18, 11, 12, "part-of", "", false, false], [20, 21, 11, 12, "part-of", "", false, false], [23, 26, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "F", "-", "score", "is", "widely", "used", "in", "the", "field", "of", "information", "retrieval", "to", "measure", "the", "performance", "of", "search", ",", "document", "classification", "and", "query", "classification", ",", "and", "F_beta", "therefore", "has", "a", "broad", "application", "."], "sentence-detokenized": "The F-score is widely used in the field of information retrieval to measure the performance of search, document classification and query classification, and F_beta therefore has a broad application.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 21], [22, 26], [27, 29], [30, 33], [34, 39], [40, 42], [43, 54], [55, 64], [65, 67], [68, 75], [76, 79], [80, 91], [92, 94], [95, 101], [101, 102], [103, 111], [112, 126], [127, 130], [131, 136], [137, 151], [151, 152], [153, 156], [157, 163], [164, 173], [174, 177], [178, 179], [180, 185], [186, 197], [197, 198]]}
{"doc_key": "ai-dev-148", "ner": [[18, 19, "algorithm"], [21, 21, "algorithm"], [24, 25, "algorithm"], [27, 27, "algorithm"], [30, 32, "algorithm"], [34, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[21, 21, 18, 19, "named", "", false, false], [27, 27, 24, 25, "named", "", false, false], [34, 34, 30, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "is", "done", "by", "modelling", "the", "received", "signal", "and", "then", "using", "a", "statistical", "estimation", "method", ",", "such", "as", "maximum", "likelihood", "(", "ML", ")", ",", "majority", "voting", "(", "MV", ")", "or", "maximum", "a", "posteriori", "(", "MAP", ")", ",", "to", "make", "a", "decision", "about", "which", "target", "in", "the", "library", "best", "fits", "the", "model", "built", "using", "the", "received", "signal", "."], "sentence-detokenized": "This is done by modelling the received signal and then using a statistical estimation method, such as maximum likelihood (ML), majority voting (MV) or maximum a posteriori (MAP), to make a decision about which target in the library best fits the model built using the received signal.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 25], [26, 29], [30, 38], [39, 45], [46, 49], [50, 54], [55, 60], [61, 62], [63, 74], [75, 85], [86, 92], [92, 93], [94, 98], [99, 101], [102, 109], [110, 120], [121, 122], [122, 124], [124, 125], [125, 126], [127, 135], [136, 142], [143, 144], [144, 146], [146, 147], [148, 150], [151, 158], [159, 160], [161, 171], [172, 173], [173, 176], [176, 177], [177, 178], [179, 181], [182, 186], [187, 188], [189, 197], [198, 203], [204, 209], [210, 216], [217, 219], [220, 223], [224, 231], [232, 236], [237, 241], [242, 245], [246, 251], [252, 257], [258, 263], [264, 267], [268, 276], [277, 283], [283, 284]]}
{"doc_key": "ai-dev-149", "ner": [[0, 0, "researcher"], [3, 3, "misc"], [5, 5, "field"], [8, 11, "university"], [16, 16, "misc"], [18, 19, "field"], [21, 22, "university"], [28, 28, "misc"], [30, 31, "field"], [34, 36, "university"], [43, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 0, 8, 11, "physical", "", false, false], [0, 0, 8, 11, "role", "", false, false], [0, 0, 21, 22, "physical", "", false, false], [0, 0, 21, 22, "role", "", false, false], [0, 0, 34, 36, "physical", "", false, false], [0, 0, 34, 36, "role", "", false, false], [3, 3, 0, 0, "origin", "", false, false], [3, 3, 5, 5, "topic", "", false, false], [16, 16, 0, 0, "origin", "", false, false], [16, 16, 18, 19, "topic", "", false, false], [28, 28, 0, 0, "origin", "", false, false], [28, 28, 30, 31, "topic", "", false, false], [43, 51, 28, 28, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Sowa", "received", "a", "BS", "in", "Mathematics", "from", "the", "Massachusetts", "Institute", "of", "Technology", "in", "1962", ",", "an", "MA", "in", "Applied", "Mathematics", "from", "Harvard", "University", "in", "1966", ",", "and", "a", "PhD", "in", "Computer", "Science", "from", "the", "Vrije", "Universiteit", "Brussel", "in", "1999", "on", "a", "thesis", "entitled", "Knowledge", "Representation", ":", "Logical", ",", "Philosophical", "and", "Computational", "Foundations", "."], "sentence-detokenized": "Sowa received a BS in Mathematics from the Massachusetts Institute of Technology in 1962, an MA in Applied Mathematics from Harvard University in 1966, and a PhD in Computer Science from the Vrije Universiteit Brussel in 1999 on a thesis entitled Knowledge Representation: Logical, Philosophical and Computational Foundations.", "token2charspan": [[0, 4], [5, 13], [14, 15], [16, 18], [19, 21], [22, 33], [34, 38], [39, 42], [43, 56], [57, 66], [67, 69], [70, 80], [81, 83], [84, 88], [88, 89], [90, 92], [93, 95], [96, 98], [99, 106], [107, 118], [119, 123], [124, 131], [132, 142], [143, 145], [146, 150], [150, 151], [152, 155], [156, 157], [158, 161], [162, 164], [165, 173], [174, 181], [182, 186], [187, 190], [191, 196], [197, 209], [210, 217], [218, 220], [221, 225], [226, 228], [229, 230], [231, 237], [238, 246], [247, 256], [257, 271], [271, 272], [273, 280], [280, 281], [282, 295], [296, 299], [300, 313], [314, 325], [325, 326]]}
{"doc_key": "ai-dev-150", "ner": [[1, 2, "task"], [16, 16, "metrics"], [18, 19, "metrics"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[16, 16, 1, 2, "part-of", "", true, false], [18, 19, 1, 2, "part-of", "", true, false], [22, 23, 1, 2, "part-of", "", true, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Since", "rewriting", "recognition", "can", "be", "considered", "a", "classification", "problem", ",", "most", "standard", "evaluations", ",", "such", "as", "accuracy", ",", "f1", "score", "or", "an", "ROC", "curve", ",", "work", "relatively", "well", "."], "sentence-detokenized": "Since rewriting recognition can be considered a classification problem, most standard evaluations, such as accuracy, f1 score or an ROC curve, work relatively well.", "token2charspan": [[0, 5], [6, 15], [16, 27], [28, 31], [32, 34], [35, 45], [46, 47], [48, 62], [63, 70], [70, 71], [72, 76], [77, 85], [86, 97], [97, 98], [99, 103], [104, 106], [107, 115], [115, 116], [117, 119], [120, 125], [126, 128], [129, 131], [132, 135], [136, 141], [141, 142], [143, 147], [148, 158], [159, 163], [163, 164]]}
{"doc_key": "ai-dev-151", "ner": [[20, 20, "algorithm"], [29, 30, "algorithm"], [32, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 20, 29, 30, "opposite", "not_suited_for", false, false], [20, 20, 32, 33, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "makes", "it", "practical", "for", "the", "analysis", "of", "large", "data", "sets", "(", "hundreds", "or", "thousands", "of", "taxa", ")", "and", "for", "bootstrapping", ",", "for", "which", "other", "analysis", "methods", "(", "e.g.", "maximum", "parsimony", ",", "maximum", "likelihood", ")", "may", "be", "too", "difficult", "to", "compute", "."], "sentence-detokenized": "This makes it practical for the analysis of large data sets (hundreds or thousands of taxa) and for bootstrapping, for which other analysis methods (e.g. maximum parsimony, maximum likelihood) may be too difficult to compute.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 31], [32, 40], [41, 43], [44, 49], [50, 54], [55, 59], [60, 61], [61, 69], [70, 72], [73, 82], [83, 85], [86, 90], [90, 91], [92, 95], [96, 99], [100, 113], [113, 114], [115, 118], [119, 124], [125, 130], [131, 139], [140, 147], [148, 149], [149, 153], [154, 161], [162, 171], [171, 172], [173, 180], [181, 191], [191, 192], [193, 196], [197, 199], [200, 203], [204, 213], [214, 216], [217, 224], [224, 225]]}
{"doc_key": "ai-dev-152", "ner": [[5, 5, "programlang"], [7, 7, "programlang"], [11, 14, "organisation"], [16, 19, "organisation"], [26, 36, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[16, 19, 11, 14, "named", "", false, false], [26, 36, 5, 5, "role", "submits", true, false], [26, 36, 7, 7, "role", "submits", true, false], [26, 36, 11, 14, "role", "submits_to", true, false]], "relations_mapping_to_source": [1, 2, 3, 4], "sentence": ["The", "2002", "submission", "of", "the", "DAML", "+", "OIL", "language", "to", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "the", "work", "of", "DAML", "developers", "and", "the", "European", "Union", "/", "US", "ad", "hoc", "Joint", "Committee", "on", "Markup", "Languages", "."], "sentence-detokenized": "The 2002 submission of the DAML + OIL language to the World Wide Web Consortium (W3C), the work of DAML developers and the European Union/US ad hoc Joint Committee on Markup Languages.", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 22], [23, 26], [27, 31], [32, 33], [34, 37], [38, 46], [47, 49], [50, 53], [54, 59], [60, 64], [65, 68], [69, 79], [80, 81], [81, 84], [84, 85], [85, 86], [87, 90], [91, 95], [96, 98], [99, 103], [104, 114], [115, 118], [119, 122], [123, 131], [132, 137], [137, 138], [138, 140], [141, 143], [144, 147], [148, 153], [154, 163], [164, 166], [167, 173], [174, 183], [183, 184]]}
{"doc_key": "ai-dev-153", "ner": [[3, 4, "misc"], [7, 8, "misc"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 3, 4, "part-of", "", true, false], [11, 12, 3, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "non-linear", "normalization", "is", "when", "the", "normalization", "follows", "a", "sigmoid", "function", ",", "in", "which", "case", "the", "normalized", "image", "is", "calculated", "according", "to", "the", "formula"], "sentence-detokenized": "An example of non-linear normalization is when the normalization follows a sigmoid function, in which case the normalized image is calculated according to the formula", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 38], [39, 41], [42, 46], [47, 50], [51, 64], [65, 72], [73, 74], [75, 82], [83, 91], [91, 92], [93, 95], [96, 101], [102, 106], [107, 110], [111, 121], [122, 127], [128, 130], [131, 141], [142, 151], [152, 154], [155, 158], [159, 166]]}
{"doc_key": "ai-dev-154", "ner": [[6, 6, "metrics"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 6, 11, 12, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "pointed", "out", "that", "precision", "is", "usually", "combined", "with", "recall", "to", "solve", "this", "problem", "."], "sentence-detokenized": "It has been pointed out that precision is usually combined with recall to solve this problem.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 23], [24, 28], [29, 38], [39, 41], [42, 49], [50, 58], [59, 63], [64, 70], [71, 73], [74, 79], [80, 84], [85, 92], [92, 93]]}
{"doc_key": "ai-dev-155", "ner": [[5, 7, "metrics"], [9, 17, "metrics"], [23, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 9, 17, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "most", "common", "metrics", "are", "mean", "square", "error", "and", "root", "mean", "square", "error", ",", "the", "latter", "of", "which", "has", "been", "used", "in", "the", "Netflix", "Prize", "."], "sentence-detokenized": "The most common metrics are mean square error and root mean square error, the latter of which has been used in the Netflix Prize.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 23], [24, 27], [28, 32], [33, 39], [40, 45], [46, 49], [50, 54], [55, 59], [60, 66], [67, 72], [72, 73], [74, 77], [78, 84], [85, 87], [88, 93], [94, 97], [98, 102], [103, 107], [108, 110], [111, 114], [115, 122], [123, 128], [128, 129]]}
{"doc_key": "ai-dev-156", "ner": [[10, 13, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "August", "2016", ",", "a", "research", "programme", "was", "announced", "with", "University", "College", "Hospital", "to", "develop", "an", "algorithm", "that", "can", "automatically", "distinguish", "between", "healthy", "and", "cancerous", "tissues", "in", "the", "head", "and", "neck", "region", "."], "sentence-detokenized": "In August 2016, a research programme was announced with University College Hospital to develop an algorithm that can automatically distinguish between healthy and cancerous tissues in the head and neck region.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 17], [18, 26], [27, 36], [37, 40], [41, 50], [51, 55], [56, 66], [67, 74], [75, 83], [84, 86], [87, 94], [95, 97], [98, 107], [108, 112], [113, 116], [117, 130], [131, 142], [143, 150], [151, 158], [159, 162], [163, 172], [173, 180], [181, 183], [184, 187], [188, 192], [193, 196], [197, 201], [202, 208], [208, 209]]}
{"doc_key": "ai-dev-157", "ner": [[3, 4, "researcher"], [16, 18, "organisation"], [21, 24, "organisation"], [27, 30, "organisation"], [33, 38, "organisation"], [41, 47, "organisation"], [51, 54, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 4, 16, 18, "role", "", false, false], [3, 4, 21, 24, "role", "", false, false], [3, 4, 27, 30, "role", "", false, false], [3, 4, 33, 38, "role", "", false, false], [3, 4, 41, 47, "role", "", false, false], [3, 4, 51, 54, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "impact", "of", "Posner", "'s", "theoretical", "and", "empirical", "contributions", "has", "been", "recognized", "through", "membership", "in", "the", "American", "Psychological", "Association", ",", "the", "Association", "for", "Psychological", "Science", ",", "the", "Society", "of", "Experimental", "Psychologists", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "The impact of Posner's theoretical and empirical contributions has been recognized through membership in the American Psychological Association, the Association for Psychological Science, the Society of Experimental Psychologists, the American Academy of Arts and Sciences, the American Association for the Advancement of Science, and the National Academy of Sciences.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 20], [20, 22], [23, 34], [35, 38], [39, 48], [49, 62], [63, 66], [67, 71], [72, 82], [83, 90], [91, 101], [102, 104], [105, 108], [109, 117], [118, 131], [132, 143], [143, 144], [145, 148], [149, 160], [161, 164], [165, 178], [179, 186], [186, 187], [188, 191], [192, 199], [200, 202], [203, 215], [216, 229], [229, 230], [231, 234], [235, 243], [244, 251], [252, 254], [255, 259], [260, 263], [264, 272], [272, 273], [274, 277], [278, 286], [287, 298], [299, 302], [303, 306], [307, 318], [319, 321], [322, 329], [329, 330], [331, 334], [335, 338], [339, 347], [348, 355], [356, 358], [359, 367], [367, 368]]}
{"doc_key": "ai-dev-158", "ner": [[2, 5, "product"], [9, 12, "field"], [14, 15, "task"], [17, 19, "task"], [21, 21, "task"], [24, 26, "task"], [28, 28, "task"], [31, 32, "field"], [34, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 5, 9, 12, "usage", "", false, false], [14, 15, 9, 12, "part-of", "", false, false], [17, 19, 9, 12, "part-of", "", false, false], [21, 21, 17, 19, "named", "", false, false], [24, 26, 9, 12, "part-of", "", false, false], [28, 28, 24, 26, "named", "", false, false], [31, 32, 9, 12, "part-of", "", false, false], [34, 35, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["These", "intelligent", "chatbots", "make", "use", "of", "all", "types", "of", "artificial", "intelligence", ",", "such", "as", "image", "moderation", "and", "natural", "language", "understanding", "(", "NLU", ")", ",", "natural", "language", "generation", "(", "NLG", ")", ",", "machine", "learning", "and", "deep", "learning", "."], "sentence-detokenized": "These intelligent chatbots make use of all types of artificial intelligence, such as image moderation and natural language understanding (NLU), natural language generation (NLG), machine learning and deep learning.", "token2charspan": [[0, 5], [6, 17], [18, 26], [27, 31], [32, 35], [36, 38], [39, 42], [43, 48], [49, 51], [52, 62], [63, 75], [75, 76], [77, 81], [82, 84], [85, 90], [91, 101], [102, 105], [106, 113], [114, 122], [123, 136], [137, 138], [138, 141], [141, 142], [142, 143], [144, 151], [152, 160], [161, 171], [172, 173], [173, 176], [176, 177], [177, 178], [179, 186], [187, 195], [196, 199], [200, 204], [205, 213], [213, 214]]}
{"doc_key": "ai-dev-159", "ner": [[4, 6, "metrics"], [8, 8, "metrics"], [12, 12, "metrics"], [15, 21, "metrics"], [26, 28, "metrics"], [30, 30, "metrics"], [33, 40, "metrics"], [43, 45, "metrics"], [47, 47, "metrics"], [50, 57, "metrics"], [61, 63, "metrics"], [65, 65, "metrics"], [68, 74, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 4, 6, "named", "", false, false], [12, 12, 4, 6, "named", "", false, false], [15, 21, 4, 6, "named", "", false, false], [30, 30, 26, 28, "named", "", false, false], [33, 40, 26, 28, "named", "", false, false], [47, 47, 43, 45, "named", "", false, false], [50, 57, 43, 45, "named", "", false, false], [65, 65, 61, 63, "named", "", false, false], [68, 74, 61, 63, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "computational", "ratios", "are", "positive", "predictive", "value", "(", "PPV", ",", "also", "called", "precision", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "complemented", "by", "FALSE", "Discovery", "Rate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ",", "and", "negative", "predictive", "value", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "complemented", "by", "FALSE", "Omission", "Rate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "The computational ratios are positive predictive value (PPV, also called precision) (TP / (TP + FP)), complemented by FALSE Discovery Rate (FDR) (FP / (TP + FP)), and negative predictive value (NPV) (TN / (TN + FN)), complemented by FALSE Omission Rate (FOR) (FN / (TN + FN)).", "token2charspan": [[0, 3], [4, 17], [18, 24], [25, 28], [29, 37], [38, 48], [49, 54], [55, 56], [56, 59], [59, 60], [61, 65], [66, 72], [73, 82], [82, 83], [84, 85], [85, 87], [88, 89], [90, 91], [91, 93], [94, 95], [96, 98], [98, 99], [99, 100], [100, 101], [102, 114], [115, 117], [118, 123], [124, 133], [134, 138], [139, 140], [140, 143], [143, 144], [145, 146], [146, 148], [149, 150], [151, 152], [152, 154], [155, 156], [157, 159], [159, 160], [160, 161], [161, 162], [163, 166], [167, 175], [176, 186], [187, 192], [193, 194], [194, 197], [197, 198], [199, 200], [200, 202], [203, 204], [205, 206], [206, 208], [209, 210], [211, 213], [213, 214], [214, 215], [215, 216], [217, 229], [230, 232], [233, 238], [239, 247], [248, 252], [253, 254], [254, 257], [257, 258], [259, 260], [260, 262], [263, 264], [265, 266], [266, 268], [269, 270], [271, 273], [273, 274], [274, 275], [275, 276]]}
{"doc_key": "ai-dev-160", "ner": [[8, 8, "misc"], [14, 15, "algorithm"], [17, 17, "algorithm"], [21, 23, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 17, 14, 15, "named", "", false, false], [25, 25, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "information", "is", "a", "mixture", "of", "sitemaps", "and", "RSS", "and", "is", "created", "using", "the", "Information", "Model", "(", "IM", ")", "and", "the", "Biomedical", "Resource", "Ontology", "(", "BRO", ")", "."], "sentence-detokenized": "The information is a mixture of sitemaps and RSS and is created using the Information Model (IM) and the Biomedical Resource Ontology (BRO).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 20], [21, 28], [29, 31], [32, 40], [41, 44], [45, 48], [49, 52], [53, 55], [56, 63], [64, 69], [70, 73], [74, 85], [86, 91], [92, 93], [93, 95], [95, 96], [97, 100], [101, 104], [105, 115], [116, 124], [125, 133], [134, 135], [135, 138], [138, 139], [139, 140]]}
{"doc_key": "ai-dev-161", "ner": [[1, 3, "task"], [6, 8, "algorithm"], [10, 15, "algorithm"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 10, 15, "origin", "based_on", false, false], [10, 15, 6, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Recent", "text", "recognition", "relies", "on", "a", "recurrent", "neural", "network", "(", "long", "-", "term", "memory", ")", "and", "does", "not", "require", "a", "language", "model", "."], "sentence-detokenized": "Recent text recognition relies on a recurrent neural network (long-term memory) and does not require a language model.", "token2charspan": [[0, 6], [7, 11], [12, 23], [24, 30], [31, 33], [34, 35], [36, 45], [46, 52], [53, 60], [61, 62], [62, 66], [66, 67], [67, 71], [72, 78], [78, 79], [80, 83], [84, 88], [89, 92], [93, 100], [101, 102], [103, 111], [112, 117], [117, 118]]}
{"doc_key": "ai-dev-162", "ner": [[1, 4, "misc"], [5, 6, "metrics"], [9, 10, "algorithm"], [14, 15, "metrics"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 1, 4, "type-of", "", false, false], [9, 10, 5, 6, "related-to", "", true, false], [14, 15, 1, 4, "type-of", "", false, false], [18, 19, 14, 15, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Popular", "loss", "functions", "include", "the", "hinge", "loss", "(", "for", "linear", "SVM", ")", "and", "the", "log", "loss", "(", "for", "logistic", "regression", ")", "."], "sentence-detokenized": "Popular loss functions include the hinge loss (for linear SVM) and the log loss (for logistic regression).", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 30], [31, 34], [35, 40], [41, 45], [46, 47], [47, 50], [51, 57], [58, 61], [61, 62], [63, 66], [67, 70], [71, 74], [75, 79], [80, 81], [81, 84], [85, 93], [94, 104], [104, 105], [105, 106]]}
{"doc_key": "ai-dev-163", "ner": [[0, 0, "metrics"], [12, 18, "metrics"], [10, 10, "metrics"], [23, 25, "metrics"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 12, 18, "compare", "", false, false], [0, 0, 23, 25, "compare", "", false, false], [10, 10, 12, 18, "named", "", false, false], [21, 21, 23, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "is", "designed", "to", "improve", "on", "traditional", "methods", "such", "as", "PSNR", "(", "peak", "signal", "-", "to", "-", "noise", "ratio", ")", "and", "MSE", "(", "mean", "squared", "error", ")", "."], "sentence-detokenized": "SSIM is designed to improve on traditional methods such as PSNR (peak signal-to-noise ratio) and MSE (mean squared error).", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 27], [28, 30], [31, 42], [43, 50], [51, 55], [56, 58], [59, 63], [64, 65], [65, 69], [70, 76], [76, 77], [77, 79], [79, 80], [80, 85], [86, 91], [91, 92], [93, 96], [97, 100], [101, 102], [102, 106], [107, 114], [115, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-dev-164", "ner": [[10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "inspired", "subsequent", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "His work inspired subsequent generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 28], [29, 40], [41, 43], [44, 52], [53, 64], [65, 69], [70, 72], [73, 79], [80, 86], [86, 87], [88, 92], [93, 100], [101, 104], [105, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-dev-165", "ner": [[18, 19, "algorithm"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", ",", "pulse", "training", "is", "not", "differentiable", ",", "which", "eliminates", "backpropagation", "-", "based", "training", "methods", "such", "as", "gradient", "descent", "."], "sentence-detokenized": "In addition, pulse training is not differentiable, which eliminates backpropagation-based training methods such as gradient descent.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 18], [19, 27], [28, 30], [31, 34], [35, 49], [49, 50], [51, 56], [57, 67], [68, 83], [83, 84], [84, 89], [90, 98], [99, 106], [107, 111], [112, 114], [115, 123], [124, 131], [131, 132]]}
{"doc_key": "ai-dev-166", "ner": [[8, 11, "metrics"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 11, 15, 16, "related-to", "describes", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "relationship", "can", "be", "easily", "represented", "by", "a", "confusion", "matrix", ",", "a", "table", "describing", "the", "accuracy", "of", "a", "classification", "model", "."], "sentence-detokenized": "This relationship can be easily represented by a confusion matrix, a table describing the accuracy of a classification model.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 24], [25, 31], [32, 43], [44, 46], [47, 48], [49, 58], [59, 65], [65, 66], [67, 68], [69, 74], [75, 85], [86, 89], [90, 98], [99, 101], [102, 103], [104, 118], [119, 124], [124, 125]]}
{"doc_key": "ai-dev-167", "ner": [[2, 10, "conference"], [8, 8, "conference"], [14, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 2, 10, "named", "", false, false], [14, 14, 2, 10, "physical", "", false, false], [14, 14, 2, 10, "role", "", false, false], [14, 14, 2, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["At", "the", "2018", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "conference", ",", "researchers", "from", "Google", "presented", "work"], "sentence-detokenized": "At the 2018 Neural Information Processing Systems (NeurIPS) conference, researchers from Google presented work", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 30], [31, 41], [42, 49], [50, 51], [51, 58], [58, 59], [60, 70], [70, 71], [72, 83], [84, 88], [89, 95], [96, 105], [106, 110]]}
{"doc_key": "ai-dev-168", "ner": [[4, 4, "university"], [14, 14, "product"], [19, 21, "misc"], [25, 25, "conference"], [30, 33, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 14, 19, 21, "win-defeat", "", false, false], [19, 21, 25, 25, "temporal", "", false, false], [30, 33, 25, 25, "part-of", "", false, false], [30, 33, 25, 25, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "his", "time", "at", "Duke", ",", "he", "worked", "on", "an", "automated", "crossword", "solver", ",", "PROVERB", ",", "which", "won", "an", "Outstanding", "Paper", "Award", "in", "1999", "from", "AAAI", "and", "competed", "in", "the", "American", "Crossword", "Puzzle", "Tournament", "."], "sentence-detokenized": "During his time at Duke, he worked on an automated crossword solver, PROVERB, which won an Outstanding Paper Award in 1999 from AAAI and competed in the American Crossword Puzzle Tournament.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 18], [19, 23], [23, 24], [25, 27], [28, 34], [35, 37], [38, 40], [41, 50], [51, 60], [61, 67], [67, 68], [69, 76], [76, 77], [78, 83], [84, 87], [88, 90], [91, 102], [103, 108], [109, 114], [115, 117], [118, 122], [123, 127], [128, 132], [133, 136], [137, 145], [146, 148], [149, 152], [153, 161], [162, 171], [172, 178], [179, 189], [189, 190]]}
{"doc_key": "ai-dev-169", "ner": [[5, 6, "location"], [8, 8, "location"], [16, 17, "country"], [19, 19, "country"], [21, 21, "country"], [23, 23, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 8, 8, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "company", "was", "headquartered", "in", "Rochester", "Hills", ",", "Michigan", ",", "with", "ten", "regional", "offices", "in", "the", "United", "States", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "sentence-detokenized": "The company was headquartered in Rochester Hills, Michigan, with ten regional offices in the United States, Canada, Mexico and Brazil.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 29], [30, 32], [33, 42], [43, 48], [48, 49], [50, 58], [58, 59], [60, 64], [65, 68], [69, 77], [78, 85], [86, 88], [89, 92], [93, 99], [100, 106], [106, 107], [108, 114], [114, 115], [116, 122], [123, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-dev-170", "ner": [[12, 12, "product"], [14, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "joins", "a", "collection", "of", "historically", "important", "robots", "that", "includes", "an", "early", "Unimate", "and", "Odetic", "'s", "Odex", "1", "."], "sentence-detokenized": "It joins a collection of historically important robots that includes an early Unimate and Odetic's Odex 1.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 21], [22, 24], [25, 37], [38, 47], [48, 54], [55, 59], [60, 68], [69, 71], [72, 77], [78, 85], [86, 89], [90, 96], [96, 98], [99, 103], [104, 105], [105, 106]]}
{"doc_key": "ai-dev-171", "ner": [[8, 9, "researcher"], [13, 13, "organisation"], [15, 16, "researcher"], [25, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 13, 13, "physical", "", false, false], [8, 9, 13, 13, "role", "", false, false], [15, 16, 13, 13, "physical", "", false, false], [15, 16, 13, 13, "role", "", false, false], [15, 16, 25, 30, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["A", "guest", "editor", "for", "that", "issue", "will", "be", "David", "'s", "former", "colleague", "at", "NIST", ",", "Judah", "Levine", ",", "who", "is", "the", "latest", "recipient", "of", "the", "I.I.I", ".", "award", ".", "Rabi", "Award", "."], "sentence-detokenized": "A guest editor for that issue will be David's former colleague at NIST, Judah Levine, who is the latest recipient of the I.I.I. award. Rabi Award.", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 18], [19, 23], [24, 29], [30, 34], [35, 37], [38, 43], [43, 45], [46, 52], [53, 62], [63, 65], [66, 70], [70, 71], [72, 77], [78, 84], [84, 85], [86, 89], [90, 92], [93, 96], [97, 103], [104, 113], [114, 116], [117, 120], [121, 126], [126, 127], [128, 133], [133, 134], [135, 139], [140, 145], [145, 146]]}
{"doc_key": "ai-dev-172", "ner": [[12, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "can", "be", "arranged", "in", "a", "2", "\u00d7", "2", "contingency", "table", "(", "confusion", "matrix", ")", ",", "usually", "with", "the", "test", "result", "on", "the", "vertical", "axis", "and", "the", "actual", "state", "on", "the", "horizontal", "axis", "."], "sentence-detokenized": "These can be arranged in a 2 \u00d7 2 contingency table (confusion matrix), usually with the test result on the vertical axis and the actual state on the horizontal axis.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 21], [22, 24], [25, 26], [27, 28], [29, 30], [31, 32], [33, 44], [45, 50], [51, 52], [52, 61], [62, 68], [68, 69], [69, 70], [71, 78], [79, 83], [84, 87], [88, 92], [93, 99], [100, 102], [103, 106], [107, 115], [116, 120], [121, 124], [125, 128], [129, 135], [136, 141], [142, 144], [145, 148], [149, 159], [160, 164], [164, 165]]}
{"doc_key": "ai-dev-173", "ner": [[0, 4, "product"], [7, 7, "product"], [9, 9, "product"], [11, 12, "product"], [14, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 7, 7, "part-of", "", false, false], [0, 4, 9, 9, "part-of", "", false, false], [0, 4, 11, 12, "part-of", "", false, false], [0, 4, 14, 17, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Apple", "'s", "iOS", "operating", "system", "used", "on", "iPhone", ",", "iPad", "and", "iPod", "Touch", "uses", "VoiceOver", "speech", "synthesis", "for", "accessibility", "."], "sentence-detokenized": "Apple's iOS operating system used on iPhone, iPad and iPod Touch uses VoiceOver speech synthesis for accessibility.", "token2charspan": [[0, 5], [5, 7], [8, 11], [12, 21], [22, 28], [29, 33], [34, 36], [37, 43], [43, 44], [45, 49], [50, 53], [54, 58], [59, 64], [65, 69], [70, 79], [80, 86], [87, 96], [97, 100], [101, 114], [114, 115]]}
{"doc_key": "ai-dev-174", "ner": [[9, 11, "conference"], [17, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "the", "best", "system", "that", "entered", "the", "MUC", "-", "7", "scored", "93.39", "%", "on", "the", "F", "-", "measure", ",", "while", "human", "commentators", "scored", "97.6", "%", "and", "96.95", "%", "."], "sentence-detokenized": "For example, the best system that entered the MUC-7 scored 93.39% on the F-measure, while human commentators scored 97.6% and 96.95%.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 33], [34, 41], [42, 45], [46, 49], [49, 50], [50, 51], [52, 58], [59, 64], [64, 65], [66, 68], [69, 72], [73, 74], [74, 75], [75, 82], [82, 83], [84, 89], [90, 95], [96, 108], [109, 115], [116, 120], [120, 121], [122, 125], [126, 131], [131, 132], [132, 133]]}
{"doc_key": "ai-dev-175", "ner": [[12, 14, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 16, 12, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "done", "using", "standard", "neural", "network", "training", "algorithms", ",", "such", "as", "stochastic", "gradient", "descent", "with", "backpropagation", "."], "sentence-detokenized": "This is done using standard neural network training algorithms, such as stochastic gradient descent with backpropagation.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 18], [19, 27], [28, 34], [35, 42], [43, 51], [52, 62], [62, 63], [64, 68], [69, 71], [72, 82], [83, 91], [92, 99], [100, 104], [105, 120], [120, 121]]}
{"doc_key": "ai-dev-176", "ner": [[0, 2, "organisation"], [20, 20, "country"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 20, 20, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "is", "one", "of", "the", "top", "1000", "websites", ",", "ranking", "around", "400", "in", "the", "world", "and", "150", "in", "the", "US", ",", "according", "to", "Alexa", "."], "sentence-detokenized": "Rotten Tomatoes is one of the top 1000 websites, ranking around 400 in the world and 150 in the US, according to Alexa.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 22], [23, 25], [26, 29], [30, 33], [34, 38], [39, 47], [47, 48], [49, 56], [57, 63], [64, 67], [68, 70], [71, 74], [75, 80], [81, 84], [85, 88], [89, 91], [92, 95], [96, 98], [98, 99], [100, 109], [110, 112], [113, 118], [118, 119]]}
{"doc_key": "ai-dev-177", "ner": [[15, 16, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "general", ",", "all", "learning", "exhibits", "a", "step", "change", "over", "time", ",", "but", "describes", "a", "sigmoid", "function", "that", "has", "a", "different", "appearance", "depending", "on", "the", "time", "period", "of", "observation", "."], "sentence-detokenized": "In general, all learning exhibits a step change over time, but describes a sigmoid function that has a different appearance depending on the time period of observation.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 24], [25, 33], [34, 35], [36, 40], [41, 47], [48, 52], [53, 57], [57, 58], [59, 62], [63, 72], [73, 74], [75, 82], [83, 91], [92, 96], [97, 100], [101, 102], [103, 112], [113, 123], [124, 133], [134, 136], [137, 140], [141, 145], [146, 152], [153, 155], [156, 167], [167, 168]]}
{"doc_key": "ai-dev-178", "ner": [[0, 0, "metrics"], [5, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["SSD", "is", "also", "known", "as", "mean", "squared", "error", "."], "sentence-detokenized": "SSD is also known as mean squared error.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 17], [18, 20], [21, 25], [26, 33], [34, 39], [39, 40]]}
{"doc_key": "ai-dev-179", "ner": [[0, 2, "algorithm"], [4, 5, "algorithm"], [8, 10, "algorithm"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 24, 25, "related-to", "can_be_related_to", true, false], [4, 5, 24, 25, "related-to", "can_be_related_to", true, false], [8, 10, 24, 25, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Learning", "decision", "trees", ",", "neural", "networks", "or", "a", "naive", "Bayes", "classifier", "can", "be", "used", "in", "combination", "with", "measures", "of", "model", "quality", ",", "such", "as", "balanced", "accuracy", "."], "sentence-detokenized": "Learning decision trees, neural networks or a naive Bayes classifier can be used in combination with measures of model quality, such as balanced accuracy.", "token2charspan": [[0, 8], [9, 17], [18, 23], [23, 24], [25, 31], [32, 40], [41, 43], [44, 45], [46, 51], [52, 57], [58, 68], [69, 72], [73, 75], [76, 80], [81, 83], [84, 95], [96, 100], [101, 109], [110, 112], [113, 118], [119, 126], [126, 127], [128, 132], [133, 135], [136, 144], [145, 153], [153, 154]]}
{"doc_key": "ai-dev-180", "ner": [[19, 22, "conference"], [26, 35, "conference"], [30, 32, "misc"], [40, 42, "product"], [50, 53, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[30, 32, 26, 35, "origin", "", false, false], [30, 32, 26, 35, "temporal", "", false, false], [40, 42, 30, 32, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "has", "served", "as", "President", "(", "1979", ")", "and", "is", "one", "of", "the", "first", "members", "(", "2011", ")", "of", "ACL", ",", "is", "a", "co-recipient", "of", "the", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "in", "1992", "for", "his", "contribution", "to", "the", "Interlisp", "programming", "system", ",", "and", "is", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "He has served as President (1979) and is one of the first members (2011) of ACL, is a co-recipient of the Association for Computing Machinery Software Systems Award in 1992 for his contribution to the Interlisp programming system, and is a member of the Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 26], [27, 28], [28, 32], [32, 33], [34, 37], [38, 40], [41, 44], [45, 47], [48, 51], [52, 57], [58, 65], [66, 67], [67, 71], [71, 72], [73, 75], [76, 79], [79, 80], [81, 83], [84, 85], [86, 98], [99, 101], [102, 105], [106, 117], [118, 121], [122, 131], [132, 141], [142, 150], [151, 158], [159, 164], [165, 167], [168, 172], [173, 176], [177, 180], [181, 193], [194, 196], [197, 200], [201, 210], [211, 222], [223, 229], [229, 230], [231, 234], [235, 237], [238, 239], [240, 246], [247, 249], [250, 253], [254, 265], [266, 269], [270, 279], [280, 289], [289, 290]]}
{"doc_key": "ai-dev-181", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 15, "researcher"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 27, 28, "related-to", "", false, false], [5, 6, 27, 28, "related-to", "", false, false], [8, 8, 27, 28, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "is", "considered", "by", "Cade", "Metz", "to", "be", "one", "of", "the", "three", "people", "most", "responsible", "for", "the", "development", "of", "deep", "learning", "in", "the", "1990s", "and", "2000s", "."], "sentence-detokenized": "Along with Geoffrey Hinton and Yann LeCun, Bengio is considered by Cade Metz to be one of the three people most responsible for the development of deep learning in the 1990s and 2000s.", "token2charspan": [[0, 5], [6, 10], [11, 19], [20, 26], [27, 30], [31, 35], [36, 41], [41, 42], [43, 49], [50, 52], [53, 63], [64, 66], [67, 71], [72, 76], [77, 79], [80, 82], [83, 86], [87, 89], [90, 93], [94, 99], [100, 106], [107, 111], [112, 123], [124, 127], [128, 131], [132, 143], [144, 146], [147, 151], [152, 160], [161, 163], [164, 167], [168, 173], [174, 177], [178, 183], [183, 184]]}
{"doc_key": "ai-dev-182", "ner": [[1, 2, "field"], [4, 5, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "information", "theory", "and", "computer", "science", ",", "a", "code", "is", "usually", "considered", "as", "an", "algorithm", "that", "uniquely", "represents", "symbols", "from", "a", "source", "alphabet", "by", "encoded", "strings", ",", "which", "may", "be", "in", "another", "target", "alphabet", "."], "sentence-detokenized": "In information theory and computer science, a code is usually considered as an algorithm that uniquely represents symbols from a source alphabet by encoded strings, which may be in another target alphabet.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 45], [46, 50], [51, 53], [54, 61], [62, 72], [73, 75], [76, 78], [79, 88], [89, 93], [94, 102], [103, 113], [114, 121], [122, 126], [127, 128], [129, 135], [136, 144], [145, 147], [148, 155], [156, 163], [163, 164], [165, 170], [171, 174], [175, 177], [178, 180], [181, 188], [189, 195], [196, 204], [204, 205]]}
{"doc_key": "ai-dev-183", "ner": [[7, 8, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 7, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "rather", "simple", "non-linear", "function", ",", "the", "sigmoid", "function", ",", "such", "as", "the", "logistic", "function", ",", "also", "has", "an", "easily", "calculated", "derivative", ",", "which", "can", "be", "important", "when", "calculating", "the", "weight", "updates", "in", "the", "network", "."], "sentence-detokenized": "A rather simple non-linear function, the sigmoid function, such as the logistic function, also has an easily calculated derivative, which can be important when calculating the weight updates in the network.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 26], [27, 35], [35, 36], [37, 40], [41, 48], [49, 57], [57, 58], [59, 63], [64, 66], [67, 70], [71, 79], [80, 88], [88, 89], [90, 94], [95, 98], [99, 101], [102, 108], [109, 119], [120, 130], [130, 131], [132, 137], [138, 141], [142, 144], [145, 154], [155, 159], [160, 171], [172, 175], [176, 182], [183, 190], [191, 193], [194, 197], [198, 205], [205, 206]]}
{"doc_key": "ai-dev-184", "ner": [[0, 0, "person"], [4, 4, "location"], [6, 6, "location"], [8, 10, "country"], [13, 13, "country"], [16, 18, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 4, "physical", "", false, false], [4, 4, 6, 6, "physical", "", false, false], [6, 6, 8, 10, "physical", "", false, false], [6, 6, 13, 13, "physical", "", false, false], [6, 6, 16, 18, "physical", "", false, false], [13, 13, 8, 10, "origin", "", false, false], [16, 18, 13, 13, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "was", "born", "in", "Hronov", "in", "Bohemia", "(", "Austria", "-", "Hungary", ",", "later", "Czechoslovakia", ",", "now", "the", "Czech", "Republic", ")", "in", "1887", "."], "sentence-detokenized": "\u010capek was born in Hronov in Bohemia (Austria-Hungary, later Czechoslovakia, now the Czech Republic) in 1887.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 24], [25, 27], [28, 35], [36, 37], [37, 44], [44, 45], [45, 52], [52, 53], [54, 59], [60, 74], [74, 75], [76, 79], [80, 83], [84, 89], [90, 98], [98, 99], [100, 102], [103, 107], [107, 108]]}
{"doc_key": "ai-dev-185", "ner": [[7, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "specialised", "software", "can", "tell", "you", "about", "RSS", "."], "sentence-detokenized": "Some specialised software can tell you about RSS.", "token2charspan": [[0, 4], [5, 16], [17, 25], [26, 29], [30, 34], [35, 38], [39, 44], [45, 48], [48, 49]]}
{"doc_key": "ai-dev-186", "ner": [[6, 6, "task"], [11, 12, "task"], [17, 17, "task"], [19, 21, "task"], [32, 33, "task"], [38, 38, "task"], [41, 43, "product"], [45, 46, "product"]], "ner_mapping_to_source": [0, 1, 3, 4, 6, 7, 8, 9], "relations": [[6, 6, 11, 12, "related-to", "", true, false], [6, 6, 17, 17, "related-to", "", true, false], [41, 43, 38, 38, "type-of", "", false, false], [45, 46, 38, 38, "type-of", "", false, false]], "relations_mapping_to_source": [0, 2, 4, 5], "sentence": ["Aspects", "of", "ontology", "editors", "include", ":", "visual", "navigation", "capabilities", "within", "the", "knowledge", "model", ",", "inference", "engines", "and", "extraction", ",", "support", "for", "modules", ",", "import", "and", "export", "of", "foreign", "knowledge", "representation", "languages", "for", "ontology", "matching", ",", "and", "support", "for", "metaontologies", "such", "as", "OWL", "-", "S", ",", "Dublin", "Core", ",", "etc", "."], "sentence-detokenized": "Aspects of ontology editors include: visual navigation capabilities within the knowledge model, inference engines and extraction, support for modules, import and export of foreign knowledge representation languages for ontology matching, and support for metaontologies such as OWL-S, Dublin Core, etc.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 27], [28, 35], [35, 36], [37, 43], [44, 54], [55, 67], [68, 74], [75, 78], [79, 88], [89, 94], [94, 95], [96, 105], [106, 113], [114, 117], [118, 128], [128, 129], [130, 137], [138, 141], [142, 149], [149, 150], [151, 157], [158, 161], [162, 168], [169, 171], [172, 179], [180, 189], [190, 204], [205, 214], [215, 218], [219, 227], [228, 236], [236, 237], [238, 241], [242, 249], [250, 253], [254, 268], [269, 273], [274, 276], [277, 280], [280, 281], [281, 282], [282, 283], [284, 290], [291, 295], [295, 296], [297, 300], [300, 301]]}
{"doc_key": "ai-dev-187", "ner": [[0, 1, "organisation"], [7, 10, "misc"], [14, 15, "task"], [22, 23, "field"], [26, 26, "misc"], [28, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 10, 0, 1, "origin", "", false, false], [14, 15, 7, 10, "part-of", "", false, false], [22, 23, 7, 10, "part-of", "", false, false], [26, 26, 22, 23, "type-of", "", false, false], [28, 29, 22, 23, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "FBI", "has", "also", "set", "up", "its", "Next", "Generation", "Identification", "program", ",", "which", "includes", "facial", "recognition", ",", "as", "well", "as", "more", "traditional", "biometric", "data", "such", "as", "fingerprints", "and", "iris", "scans", ",", "which", "can", "be", "retrieved", "from", "both", "criminal", "and", "civilian", "databases", "."], "sentence-detokenized": "The FBI has also set up its Next Generation Identification program, which includes facial recognition, as well as more traditional biometric data such as fingerprints and iris scans, which can be retrieved from both criminal and civilian databases.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 20], [21, 23], [24, 27], [28, 32], [33, 43], [44, 58], [59, 66], [66, 67], [68, 73], [74, 82], [83, 89], [90, 101], [101, 102], [103, 105], [106, 110], [111, 113], [114, 118], [119, 130], [131, 140], [141, 145], [146, 150], [151, 153], [154, 166], [167, 170], [171, 175], [176, 181], [181, 182], [183, 188], [189, 192], [193, 195], [196, 205], [206, 210], [211, 215], [216, 224], [225, 228], [229, 237], [238, 247], [247, 248]]}
{"doc_key": "ai-dev-188", "ner": [[5, 6, "person"], [8, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["During", "the", "2016", "season", ",", "Samantha", "Ponder", "replaced", "Molly", "McGrath", "as", "host", "."], "sentence-detokenized": "During the 2016 season, Samantha Ponder replaced Molly McGrath as host.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [22, 23], [24, 32], [33, 39], [40, 48], [49, 54], [55, 62], [63, 65], [66, 70], [70, 71]]}
{"doc_key": "ai-dev-189", "ner": [[3, 7, "algorithm"], [19, 23, "misc"], [25, 25, "misc"], [27, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "an", "adversarial", "search", "algorithm", "that", "is", "often", "used", "for", "machine", "playing", "of", "two", "-", "player", "games", "(", "tic", "-", "tac", "-", "toe", ",", "chess", ",", "go", ",", "etc.", ")", "."], "sentence-detokenized": "It is an adversarial search algorithm that is often used for machine playing of two-player games (tic-tac-toe, chess, go, etc.).", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 27], [28, 37], [38, 42], [43, 45], [46, 51], [52, 56], [57, 60], [61, 68], [69, 76], [77, 79], [80, 83], [83, 84], [84, 90], [91, 96], [97, 98], [98, 101], [101, 102], [102, 105], [105, 106], [106, 109], [109, 110], [111, 116], [116, 117], [118, 120], [120, 121], [122, 126], [126, 127], [127, 128]]}
{"doc_key": "ai-dev-190", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 13, "field"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "covers", "the", "areas", "of", "computer", "vision", "or", "machine", "vision", "and", "medical", "imaging", "and", "makes", "extensive", "use", "of", "pattern", "recognition", ",", "digital", "geometry", "and", "signal", "processing", "."], "sentence-detokenized": "It covers the areas of computer vision or machine vision and medical imaging and makes extensive use of pattern recognition, digital geometry and signal processing.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 19], [20, 22], [23, 31], [32, 38], [39, 41], [42, 49], [50, 56], [57, 60], [61, 68], [69, 76], [77, 80], [81, 86], [87, 96], [97, 100], [101, 103], [104, 111], [112, 123], [123, 124], [125, 132], [133, 141], [142, 145], [146, 152], [153, 163], [163, 164]]}
{"doc_key": "ai-dev-191", "ner": [[5, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "in", "a", "facial", "recognition", "system", ",", "the", "input", "information", "is", "a", "picture", "of", "a", "person", "'s", "face", ",", "and", "the", "output", "label", "is", "the", "person", "'s", "name", "."], "sentence-detokenized": "For example, in a facial recognition system, the input information is a picture of a person's face, and the output label is the person's name.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 17], [18, 24], [25, 36], [37, 43], [43, 44], [45, 48], [49, 54], [55, 66], [67, 69], [70, 71], [72, 79], [80, 82], [83, 84], [85, 91], [91, 93], [94, 98], [98, 99], [100, 103], [104, 107], [108, 114], [115, 120], [121, 123], [124, 127], [128, 134], [134, 136], [137, 141], [141, 142]]}
{"doc_key": "ai-dev-192", "ner": [[0, 1, "organisation"], [3, 4, "product"], [8, 10, "product"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 3, 4, "artifact", "", false, false], [3, 4, 8, 10, "part-of", "", false, false], [8, 10, 3, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc", "introduced", "Face", "ID", "on", "the", "flagship", "i", "Phone", "X", "as", "a", "biometric", "authentication", "successor", "to", "Touch", "ID", ",", "a", "fingerprint", "-", "based", "system", "."], "sentence-detokenized": "Apple Inc introduced Face ID on the flagship iPhone X as a biometric authentication successor to Touch ID, a fingerprint-based system.", "token2charspan": [[0, 5], [6, 9], [10, 20], [21, 25], [26, 28], [29, 31], [32, 35], [36, 44], [45, 46], [46, 51], [52, 53], [54, 56], [57, 58], [59, 68], [69, 83], [84, 93], [94, 96], [97, 102], [103, 105], [105, 106], [107, 108], [109, 120], [120, 121], [121, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-dev-193", "ner": [[2, 5, "metrics"], [8, 9, "metrics"], [22, 25, "metrics"], [27, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Or", "combine", "the", "F", "-", "measure", "with", "the", "R-", "squared", "evaluated", "for", "the", "raw", "model", "output", "and", "the", "target", ",", "or", "the", "cost", "/", "benefit", "matrix", "with", "the", "correlation", "coefficient", ",", "and", "so", "on", "."], "sentence-detokenized": "Or combine the F-measure with the R-squared evaluated for the raw model output and the target, or the cost/benefit matrix with the correlation coefficient, and so on.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 16], [16, 17], [17, 24], [25, 29], [30, 33], [34, 36], [36, 43], [44, 53], [54, 57], [58, 61], [62, 65], [66, 71], [72, 78], [79, 82], [83, 86], [87, 93], [93, 94], [95, 97], [98, 101], [102, 106], [106, 107], [107, 114], [115, 121], [122, 126], [127, 130], [131, 142], [143, 154], [154, 155], [156, 159], [160, 162], [163, 165], [165, 166]]}
{"doc_key": "ai-dev-194", "ner": [[1, 6, "conference"], [12, 14, "location"], [16, 16, "location"], [19, 23, "location"], [25, 25, "location"], [27, 27, "country"], [35, 37, "location"], [40, 44, "location"], [46, 48, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[1, 6, 12, 14, "physical", "", false, false], [1, 6, 19, 23, "physical", "", false, false], [1, 6, 35, 37, "physical", "", false, false], [1, 6, 40, 44, "physical", "", false, false], [12, 14, 16, 16, "physical", "", false, false], [19, 23, 25, 25, "physical", "", false, false], [25, 25, 27, 27, "physical", "", false, false], [35, 37, 46, 48, "physical", "", false, false], [40, 44, 46, 48, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "Spanish", "edition", "of", "the", "Campus", "Party", "has", "been", "held", "at", "the", "Colegio", "Miguel", "Hern\u00e1ndez", ",", "Ceulaj", "and", "the", "municipal", "sports", "stadium", "in", "Benalm\u00e1dena", "in", "M\u00e1laga", ",", "Spain", ",", "as", "well", "as", "at", "both", "the", "Valencia", "County", "Fair", "and", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "for", "the", "past", "15", "years", "."], "sentence-detokenized": "The Spanish edition of the Campus Party has been held at the Colegio Miguel Hern\u00e1ndez, Ceulaj and the municipal sports stadium in Benalm\u00e1dena in M\u00e1laga, Spain, as well as at both the Valencia County Fair and the City of Arts and Sciences in Valencia for the past 15 years.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 22], [23, 26], [27, 33], [34, 39], [40, 43], [44, 48], [49, 53], [54, 56], [57, 60], [61, 68], [69, 75], [76, 85], [85, 86], [87, 93], [94, 97], [98, 101], [102, 111], [112, 118], [119, 126], [127, 129], [130, 141], [142, 144], [145, 151], [151, 152], [153, 158], [158, 159], [160, 162], [163, 167], [168, 170], [171, 173], [174, 178], [179, 182], [183, 191], [192, 198], [199, 203], [204, 207], [208, 211], [212, 216], [217, 219], [220, 224], [225, 228], [229, 237], [238, 240], [241, 249], [250, 253], [254, 257], [258, 262], [263, 265], [266, 271], [271, 272]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [15, 15, "programlang"], [19, 19, "product"], [25, 25, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[15, 15, 0, 0, "general-affiliation", "", false, false], [19, 19, 15, 15, "part-of", "", false, false], [25, 25, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 3], "sentence": ["gnuplot", "can", "be", "used", "from", "various", "programming", "languages", "to", "create", "graphs", "for", "data", ",", "including", "Perl", "(", "via", "the", "PDL", "and", "CPAN", "packages", ")", ",", "Python", "(", "via", ")", "."], "sentence-detokenized": "gnuplot can be used from various programming languages to create graphs for data, including Perl (via the PDL and CPAN packages), Python (via).", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 19], [20, 24], [25, 32], [33, 44], [45, 54], [55, 57], [58, 64], [65, 71], [72, 75], [76, 80], [80, 81], [82, 91], [92, 96], [97, 98], [98, 101], [102, 105], [106, 109], [110, 113], [114, 118], [119, 127], [127, 128], [128, 129], [130, 136], [137, 138], [138, 141], [141, 142], [142, 143]]}
{"doc_key": "ai-dev-196", "ner": [[3, 5, "product"], [20, 20, "conference"], [22, 22, "conference"], [36, 36, "conference"], [38, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 20, 3, 5, "topic", "", false, false], [22, 22, 3, 5, "topic", "", false, false], [36, 36, 3, 5, "topic", "", false, false], [38, 38, 3, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "field", "of", "spoken", "dialogue", "systems", "is", "quite", "large", ",", "encompassing", "both", "research", "(", "presented", "at", "scientific", "conferences", "such", "as", "SIGdial", "and", "Interspeech", ")", "and", "a", "large", "industrial", "sector", "(", "with", "its", "own", "meetings", "such", "as", "SpeechTek", "and", "AVIOS", ")", "."], "sentence-detokenized": "The field of spoken dialogue systems is quite large, encompassing both research (presented at scientific conferences such as SIGdial and Interspeech) and a large industrial sector (with its own meetings such as SpeechTek and AVIOS).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 28], [29, 36], [37, 39], [40, 45], [46, 51], [51, 52], [53, 65], [66, 70], [71, 79], [80, 81], [81, 90], [91, 93], [94, 104], [105, 116], [117, 121], [122, 124], [125, 132], [133, 136], [137, 148], [148, 149], [150, 153], [154, 155], [156, 161], [162, 172], [173, 179], [180, 181], [181, 185], [186, 189], [190, 193], [194, 202], [203, 207], [208, 210], [211, 220], [221, 224], [225, 230], [230, 231], [231, 232]]}
{"doc_key": "ai-dev-197", "ner": [[2, 4, "field"], [7, 8, "task"], [10, 12, "task"], [14, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 2, 4, "part-of", "task_part_of_field", false, false], [10, 12, 2, 4, "part-of", "task_part_of_field", false, false], [14, 16, 2, 4, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Challenges", "in", "natural", "language", "processing", "often", "include", "speech", "recognition", ",", "natural", "language", "understanding", "and", "natural", "language", "generation", "."], "sentence-detokenized": "Challenges in natural language processing often include speech recognition, natural language understanding and natural language generation.", "token2charspan": [[0, 10], [11, 13], [14, 21], [22, 30], [31, 41], [42, 47], [48, 55], [56, 62], [63, 74], [74, 75], [76, 83], [84, 92], [93, 106], [107, 110], [111, 118], [119, 127], [128, 138], [138, 139]]}
{"doc_key": "ai-dev-198", "ner": [[5, 5, "product"], [8, 10, "product"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 8, 10, "part-of", "", false, false], [5, 5, 33, 34, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "such", "as", "Siri", "in", "the", "iOS", "operating", "system", ",", "use", "a", "similar", "pattern", "recognition", "technology", "to", "text", "-", "based", "systems", ",", "but", "in", "the", "former", ",", "user", "input", "is", "through", "speech", "recognition", "."], "sentence-detokenized": "These systems, such as Siri in the iOS operating system, use a similar pattern recognition technology to text-based systems, but in the former, user input is through speech recognition.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 27], [28, 30], [31, 34], [35, 38], [39, 48], [49, 55], [55, 56], [57, 60], [61, 62], [63, 70], [71, 78], [79, 90], [91, 101], [102, 104], [105, 109], [109, 110], [110, 115], [116, 123], [123, 124], [125, 128], [129, 131], [132, 135], [136, 142], [142, 143], [144, 148], [149, 154], [155, 157], [158, 165], [166, 172], [173, 184], [184, 185]]}
{"doc_key": "ai-dev-199", "ner": [[1, 3, "algorithm"], [16, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 3, 16, 17, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["More", "exotic", "fitness", "functions", "that", "explore", "the", "granularity", "of", "the", "model", "include", "the", "area", "under", "the", "ROC", "curve", "and", "the", "rank", "measure", "."], "sentence-detokenized": "More exotic fitness functions that explore the granularity of the model include the area under the ROC curve and the rank measure.", "token2charspan": [[0, 4], [5, 11], [12, 19], [20, 29], [30, 34], [35, 42], [43, 46], [47, 58], [59, 61], [62, 65], [66, 71], [72, 79], [80, 83], [84, 88], [89, 94], [95, 98], [99, 102], [103, 108], [109, 112], [113, 116], [117, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-dev-200", "ner": [[2, 3, "product"], [7, 12, "researcher"], [16, 18, "product"], [23, 26, "organisation"], [28, 28, "organisation"], [37, 41, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 7, 12, "origin", "", false, false], [7, 12, 23, 26, "role", "", false, false], [16, 18, 7, 12, "origin", "", false, false], [28, 28, 23, 26, "named", "", false, false], [37, 41, 23, 26, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "term", "Semantic", "Web", "was", "coined", "by", "Tim", "Berners", "-", "Lee", ",", "the", "inventor", "of", "the", "World", "Wide", "Web", "and", "head", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "oversees", "the", "development", "of", "proposed", "standards", "for", "the", "Semantic", "Web", "."], "sentence-detokenized": "The term Semantic Web was coined by Tim Berners-Lee, the inventor of the World Wide Web and head of the World Wide Web Consortium (W3C), which oversees the development of proposed standards for the Semantic Web.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 25], [26, 32], [33, 35], [36, 39], [40, 47], [47, 48], [48, 51], [51, 52], [53, 56], [57, 65], [66, 68], [69, 72], [73, 78], [79, 83], [84, 87], [88, 91], [92, 96], [97, 99], [100, 103], [104, 109], [110, 114], [115, 118], [119, 129], [130, 131], [131, 134], [134, 135], [135, 136], [137, 142], [143, 151], [152, 155], [156, 167], [168, 170], [171, 179], [180, 189], [190, 193], [194, 197], [198, 206], [207, 210], [210, 211]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [7, 7, "task"], [14, 17, "product"], [19, 23, "product"], [25, 25, "product"], [28, 33, "product"], [36, 37, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 14, 17, "opposite", "", false, false], [0, 1, 19, 23, "opposite", "", false, false], [0, 1, 28, 33, "opposite", "", false, false], [0, 1, 36, 37, "part-of", "", false, false], [7, 7, 0, 1, "named", "", false, false], [25, 25, 19, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Machine", "translation", ",", "sometimes", "referred", "to", "as", "MT", "(", "not", "to", "be", "confused", "with", "computer", "-", "aided", "translation", ",", "machine", "-", "aided", "human", "translation", "(", "MAHT", ")", "or", "interactive", "translation", ")", ",", "is", "a", "sub-field", "of", "computational", "linguistics", "that", "examines", "the", "use", "of", "software", "to", "translate", "text", "or", "speech", "from", "one", "language", "into", "another", "."], "sentence-detokenized": "Machine translation, sometimes referred to as MT (not to be confused with computer-aided translation, machine-aided human translation (MAHT) or interactive translation), is a sub-field of computational linguistics that examines the use of software to translate text or speech from one language into another.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 30], [31, 39], [40, 42], [43, 45], [46, 48], [49, 50], [50, 53], [54, 56], [57, 59], [60, 68], [69, 73], [74, 82], [82, 83], [83, 88], [89, 100], [100, 101], [102, 109], [109, 110], [110, 115], [116, 121], [122, 133], [134, 135], [135, 139], [139, 140], [141, 143], [144, 155], [156, 167], [167, 168], [168, 169], [170, 172], [173, 174], [175, 184], [185, 187], [188, 201], [202, 213], [214, 218], [219, 227], [228, 231], [232, 235], [236, 238], [239, 247], [248, 250], [251, 260], [261, 265], [266, 268], [269, 275], [276, 280], [281, 284], [285, 293], [294, 298], [299, 306], [306, 307]]}
{"doc_key": "ai-dev-202", "ner": [[1, 3, "product"], [8, 8, "university"], [13, 14, "researcher"], [16, 17, "researcher"], [39, 41, "location"], [43, 43, "location"], [47, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 3, 13, 14, "artifact", "", false, false], [1, 3, 16, 17, "artifact", "", false, false], [13, 14, 8, 8, "physical", "", false, false], [13, 14, 8, 8, "role", "", false, false], [16, 17, 8, 8, "physical", "", false, false], [16, 17, 8, 8, "role", "", false, false], [39, 41, 43, 43, "physical", "", false, false], [47, 50, 39, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Early", "interlingual", "MT", "systems", "were", "also", "built", "at", "Stanford", "in", "the", "1970s", "by", "Roger", "Schank", "and", "Yorick", "Wilks", ";", "the", "former", "became", "the", "basis", "for", "a", "commercial", "money", "transfer", "system", ",", "and", "the", "latter", "'s", "code", "is", "preserved", "at", "The", "Computer", "Museum", "in", "Boston", "as", "the", "first", "interlingual", "machine", "translation", "system", "."], "sentence-detokenized": "Early interlingual MT systems were also built at Stanford in the 1970s by Roger Schank and Yorick Wilks; the former became the basis for a commercial money transfer system, and the latter's code is preserved at The Computer Museum in Boston as the first interlingual machine translation system.", "token2charspan": [[0, 5], [6, 18], [19, 21], [22, 29], [30, 34], [35, 39], [40, 45], [46, 48], [49, 57], [58, 60], [61, 64], [65, 70], [71, 73], [74, 79], [80, 86], [87, 90], [91, 97], [98, 103], [103, 104], [105, 108], [109, 115], [116, 122], [123, 126], [127, 132], [133, 136], [137, 138], [139, 149], [150, 155], [156, 164], [165, 171], [171, 172], [173, 176], [177, 180], [181, 187], [187, 189], [190, 194], [195, 197], [198, 207], [208, 210], [211, 214], [215, 223], [224, 230], [231, 233], [234, 240], [241, 243], [244, 247], [248, 253], [254, 266], [267, 274], [275, 286], [287, 293], [293, 294]]}
{"doc_key": "ai-dev-203", "ner": [[0, 1, "researcher"], [8, 14, "conference"], [16, 17, "conference"], [24, 29, "conference"], [31, 32, "conference"], [38, 43, "organisation"], [52, 52, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 8, 14, "role", "", false, false], [0, 1, 24, 29, "role", "", false, false], [0, 1, 38, 43, "role", "", false, false], [0, 1, 52, 52, "role", "", false, false], [16, 17, 8, 14, "named", "", false, false], [31, 32, 24, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sycara", "has", "served", "as", "Program", "Chair", "of", "the", "Second", "International", "Conference", "on", "the", "Semantic", "Web", "(", "ISWC", "2003", ")", ",", "General", "Chair", "of", "the", "Second", "International", "Conference", "on", "Autonomous", "Agents", "(", "Agents", "98", ")", ",", "Chair", "of", "the", "Steering", "Committee", "of", "the", "Agents", "Conference", "(", "1999-2001", ")", ",", "and", "Chair", "of", "the", "AAAI", "Fellowship", "(", "1993-1999", ")", ";"], "sentence-detokenized": "Sycara has served as Program Chair of the Second International Conference on the Semantic Web (ISWC 2003), General Chair of the Second International Conference on Autonomous Agents (Agents 98), Chair of the Steering Committee of the Agents Conference (1999-2001), and Chair of the AAAI Fellowship (1993-1999);", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 28], [29, 34], [35, 37], [38, 41], [42, 48], [49, 62], [63, 73], [74, 76], [77, 80], [81, 89], [90, 93], [94, 95], [95, 99], [100, 104], [104, 105], [105, 106], [107, 114], [115, 120], [121, 123], [124, 127], [128, 134], [135, 148], [149, 159], [160, 162], [163, 173], [174, 180], [181, 182], [182, 188], [189, 191], [191, 192], [192, 193], [194, 199], [200, 202], [203, 206], [207, 215], [216, 225], [226, 228], [229, 232], [233, 239], [240, 250], [251, 252], [252, 261], [261, 262], [262, 263], [264, 267], [268, 273], [274, 276], [277, 280], [281, 285], [286, 296], [297, 298], [298, 307], [307, 308], [308, 309]]}
{"doc_key": "ai-dev-204", "ner": [[10, 10, "conference"], [12, 15, "conference"], [17, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 15, 10, 10, "named", "", false, false], [17, 19, 10, 10, "part-of", "", false, false], [17, 19, 10, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2016", ",", "she", "was", "named", "the", "winner", "of", "the", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "Lifetime", "Achievement", "Award", "."], "sentence-detokenized": "In 2016, she was named the winner of the ACL (Association for Computational Linguistics) Lifetime Achievement Award.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 22], [23, 26], [27, 33], [34, 36], [37, 40], [41, 44], [45, 46], [46, 57], [58, 61], [62, 75], [76, 87], [87, 88], [89, 97], [98, 109], [110, 115], [115, 116]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P.", "Frasconi", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 30], [31, 39], [40, 43], [44, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-206", "ner": [[3, 3, "product"], [6, 7, "misc"], [9, 11, "programlang"], [19, 23, "product"], [35, 35, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 9, 11, "usage", "", false, false], [9, 11, 6, 7, "type-of", "", false, false], [9, 11, 19, 23, "related-to", "", false, false], [35, 35, 3, 3, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["For", "example", ",", "A.L.I.C.E.", "uses", "a", "markup", "language", "called", "AIML", ",", "which", "is", "specific", "to", "its", "function", "as", "a", "dialogue", "system", "and", "which", "has", "since", "been", "adopted", "by", "various", "other", "developers", "of", "so", "-", "called", "Alicebots", "."], "sentence-detokenized": "For example, A.L.I.C.E. uses a markup language called AIML, which is specific to its function as a dialogue system and which has since been adopted by various other developers of so-called Alicebots.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 23], [24, 28], [29, 30], [31, 37], [38, 46], [47, 53], [54, 58], [58, 59], [60, 65], [66, 68], [69, 77], [78, 80], [81, 84], [85, 93], [94, 96], [97, 98], [99, 107], [108, 114], [115, 118], [119, 124], [125, 128], [129, 134], [135, 139], [140, 147], [148, 150], [151, 158], [159, 164], [165, 175], [176, 178], [179, 181], [181, 182], [182, 188], [189, 198], [198, 199]]}
{"doc_key": "ai-dev-207", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2000", ",", "she", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2000, she was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 24], [25, 26], [27, 33], [34, 36], [37, 40], [41, 52], [53, 56], [57, 60], [61, 72], [73, 75], [76, 86], [87, 99], [99, 100]]}
{"doc_key": "ai-dev-208", "ner": [[0, 2, "misc"], [4, 4, "misc"], [10, 15, "misc"], [24, 25, "algorithm"], [34, 35, "field"], [37, 38, "field"], [40, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 10, 15, "type-of", "", false, false], [0, 2, 34, 35, "related-to", "performs", true, false], [0, 2, 37, 38, "related-to", "performs", true, false], [0, 2, 40, 41, "related-to", "performs", true, false], [4, 4, 0, 2, "named", "", false, false], [24, 25, 10, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Learning", "classification", "systems", "(", "LCS", ")", "are", "a", "family", "of", "rule", "-", "based", "machine", "learning", "algorithms", "that", "combine", "a", "discovery", "component", ",", "usually", "a", "genetic", "algorithm", ",", "with", "a", "learning", "component", "that", "performs", "either", "supervised", "learning", ",", "reinforcement", "learning", "or", "unsupervised", "learning", "."], "sentence-detokenized": "Learning classification systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, usually a genetic algorithm, with a learning component that performs either supervised learning, reinforcement learning or unsupervised learning.", "token2charspan": [[0, 8], [9, 23], [24, 31], [32, 33], [33, 36], [36, 37], [38, 41], [42, 43], [44, 50], [51, 53], [54, 58], [58, 59], [59, 64], [65, 72], [73, 81], [82, 92], [93, 97], [98, 105], [106, 107], [108, 117], [118, 127], [127, 128], [129, 136], [137, 138], [139, 146], [147, 156], [156, 157], [158, 162], [163, 164], [165, 173], [174, 183], [184, 188], [189, 197], [198, 204], [205, 215], [216, 224], [224, 225], [226, 239], [240, 248], [249, 251], [252, 264], [265, 273], [273, 274]]}
{"doc_key": "ai-dev-209", "ner": [[14, 15, "algorithm"], [19, 19, "algorithm"], [27, 28, "algorithm"], [30, 31, "misc"], [41, 43, "algorithm"], [51, 56, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 15, 27, 28, "origin", "", false, false], [14, 15, 30, 31, "usage", "", false, false], [19, 19, 14, 15, "named", "", false, false], [41, 43, 30, 31, "type-of", "", false, false], [41, 43, 51, 56, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "unknown", "parameters", "of", "each", "vector", "\u03b2subk", "/", "sub", "are", "usually", "jointly", "estimated", "using", "maximum", "a", "posteriori", "estimation", "(", "MAP", ")", ",", "which", "is", "an", "extension", "of", "maximum", "likelihood", "using", "regularization", "of", "the", "weights", "to", "prevent", "pathological", "solutions", "(", "usually", "a", "quadratic", "regularization", "function", ",", "which", "is", "equivalent", "to", "placing", "a", "Gaussian", "prior", "distribution", "with", "zero", "mean", "on", "the", "weights", ",", "but", "other", "distributions", "are", "also", "possible", ")", "."], "sentence-detokenized": "The unknown parameters of each vector \u03b2subk/sub are usually jointly estimated using maximum a posteriori estimation (MAP), which is an extension of maximum likelihood using regularization of the weights to prevent pathological solutions (usually a quadratic regularization function, which is equivalent to placing a Gaussian prior distribution with zero mean on the weights, but other distributions are also possible).", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 30], [31, 37], [38, 43], [43, 44], [44, 47], [48, 51], [52, 59], [60, 67], [68, 77], [78, 83], [84, 91], [92, 93], [94, 104], [105, 115], [116, 117], [117, 120], [120, 121], [121, 122], [123, 128], [129, 131], [132, 134], [135, 144], [145, 147], [148, 155], [156, 166], [167, 172], [173, 187], [188, 190], [191, 194], [195, 202], [203, 205], [206, 213], [214, 226], [227, 236], [237, 238], [238, 245], [246, 247], [248, 257], [258, 272], [273, 281], [281, 282], [283, 288], [289, 291], [292, 302], [303, 305], [306, 313], [314, 315], [316, 324], [325, 330], [331, 343], [344, 348], [349, 353], [354, 358], [359, 361], [362, 365], [366, 373], [373, 374], [375, 378], [379, 384], [385, 398], [399, 402], [403, 407], [408, 416], [416, 417], [417, 418]]}
{"doc_key": "ai-dev-210", "ner": [[10, 12, "researcher"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 13, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "hierarchical", "structure", "of", "words", "has", "been", "explicitly", "mapped", "in", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "The hierarchical structure of words has been explicitly mapped in George Miller's Wordnet.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 29], [30, 35], [36, 39], [40, 44], [45, 55], [56, 62], [63, 65], [66, 72], [73, 79], [79, 81], [82, 89], [89, 90]]}
{"doc_key": "ai-dev-211", "ner": [[0, 8, "conference"], [19, 22, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 22, 0, 8, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "is", "an", "illustration", "of", "their", "capabilities", ".", "This", "is", "a", "benchmark", "for", "object", "classification", "and", "detection", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge is an illustration of their capabilities. This is a benchmark for object classification and detection, with millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 59], [60, 72], [73, 75], [76, 81], [82, 94], [94, 95], [96, 100], [101, 103], [104, 105], [106, 115], [116, 119], [120, 126], [127, 141], [142, 145], [146, 155], [155, 156], [157, 161], [162, 170], [171, 173], [174, 180], [181, 184], [185, 193], [194, 196], [197, 203], [204, 211], [211, 212]]}
{"doc_key": "ai-dev-212", "ner": [[1, 2, "misc"], [25, 25, "misc"], [27, 30, "person"], [32, 32, "misc"], [37, 40, "person"], [43, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[25, 25, 1, 2, "general-affiliation", "", false, false], [32, 32, 1, 2, "general-affiliation", "", false, false], [32, 32, 27, 30, "artifact", "", false, false], [43, 45, 1, 2, "general-affiliation", "", false, false], [43, 45, 37, 40, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "science", "fiction", ",", "female", "-", "looking", "robots", "are", "often", "produced", "to", "be", "used", "as", "domestic", "servants", "and", "sexual", "slaves", ",", "as", "in", "the", "film", "Westworld", ",", "Paul", "J.", "McAuley", "'s", "novel", "Fairyland", "(", "1995", ")", "and", "Lester", "del", "Rey", "'s", "short", "story", "Helen", "O'", "Loy", "(", "1938", ")", ",", "and", "sometimes", "as", "warriors", ",", "assassins", "or", "workers", "."], "sentence-detokenized": "In science fiction, female-looking robots are often produced to be used as domestic servants and sexual slaves, as in the film Westworld, Paul J. McAuley's novel Fairyland (1995) and Lester del Rey's short story Helen O'Loy (1938), and sometimes as warriors, assassins or workers.", "token2charspan": [[0, 2], [3, 10], [11, 18], [18, 19], [20, 26], [26, 27], [27, 34], [35, 41], [42, 45], [46, 51], [52, 60], [61, 63], [64, 66], [67, 71], [72, 74], [75, 83], [84, 92], [93, 96], [97, 103], [104, 110], [110, 111], [112, 114], [115, 117], [118, 121], [122, 126], [127, 136], [136, 137], [138, 142], [143, 145], [146, 153], [153, 155], [156, 161], [162, 171], [172, 173], [173, 177], [177, 178], [179, 182], [183, 189], [190, 193], [194, 197], [197, 199], [200, 205], [206, 211], [212, 217], [218, 220], [220, 223], [224, 225], [225, 229], [229, 230], [230, 231], [232, 235], [236, 245], [246, 248], [249, 257], [257, 258], [259, 268], [269, 271], [272, 279], [279, 280]]}
{"doc_key": "ai-dev-213", "ner": [[0, 1, "task"], [3, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["question", "answering", ",", "speech", "recognition", "and", "machine", "translation", "."], "sentence-detokenized": "question answering, speech recognition and machine translation.", "token2charspan": [[0, 8], [9, 18], [18, 19], [20, 26], [27, 38], [39, 42], [43, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-214", "ner": [[5, 6, "researcher"], [8, 12, "organisation"], [14, 17, "location"], [19, 19, "location"], [21, 21, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 8, 12, "role", "", false, false], [8, 12, 14, 17, "physical", "", false, false], [14, 17, 19, 19, "physical", "", false, false], [19, 19, 21, 21, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "seminal", "paper", ",", "Harry", "Blum", "of", "Air", "Force", "Cambridge", "Research", "Laboratories", "at", "Hanscom", "Air", "Force", "Base", "in", "Bedford", ",", "Massachusetts", ",", "defined", "a", "medial", "axis", "to", "calculate", "the", "skeleton", "of", "a", "shape", "using", "an", "intuitive", "model", "of", "fire", "spread", "on", "a", "grass", "field", ",", "where", "the", "field", "has", "the", "given", "shape", "."], "sentence-detokenized": "In his seminal paper, Harry Blum of Air Force Cambridge Research Laboratories at Hanscom Air Force Base in Bedford, Massachusetts, defined a medial axis to calculate the skeleton of a shape using an intuitive model of fire spread on a grass field, where the field has the given shape.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 20], [20, 21], [22, 27], [28, 32], [33, 35], [36, 39], [40, 45], [46, 55], [56, 64], [65, 77], [78, 80], [81, 88], [89, 92], [93, 98], [99, 103], [104, 106], [107, 114], [114, 115], [116, 129], [129, 130], [131, 138], [139, 140], [141, 147], [148, 152], [153, 155], [156, 165], [166, 169], [170, 178], [179, 181], [182, 183], [184, 189], [190, 195], [196, 198], [199, 208], [209, 214], [215, 217], [218, 222], [223, 229], [230, 232], [233, 234], [235, 240], [241, 246], [246, 247], [248, 253], [254, 257], [258, 263], [264, 267], [268, 271], [272, 277], [278, 283], [283, 284]]}
{"doc_key": "ai-dev-215", "ner": [[13, 13, "algorithm"], [15, 15, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 18, 19, "compare", "", false, false], [15, 15, 18, 19, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Unlike", "boosting", "algorithms", "that", "analytically", "minimize", "a", "convex", "loss", "function", "(", "e.g.", ",", "AdaBoost", "and", "LogitBoost", ")", ",", "Brown", "Boost", "solves", "a", "system", "of", "two", "equations", "and", "two", "unknowns", "using", "standard", "numerical", "methods", "."], "sentence-detokenized": "Unlike boosting algorithms that analytically minimize a convex loss function (e.g., AdaBoost and LogitBoost), BrownBoost solves a system of two equations and two unknowns using standard numerical methods.", "token2charspan": [[0, 6], [7, 15], [16, 26], [27, 31], [32, 44], [45, 53], [54, 55], [56, 62], [63, 67], [68, 76], [77, 78], [78, 82], [82, 83], [84, 92], [93, 96], [97, 107], [107, 108], [108, 109], [110, 115], [115, 120], [121, 127], [128, 129], [130, 136], [137, 139], [140, 143], [144, 153], [154, 157], [158, 161], [162, 170], [171, 176], [177, 185], [186, 195], [196, 203], [203, 204]]}
{"doc_key": "ai-dev-216", "ner": [[0, 0, "researcher"], [9, 11, "misc"], [18, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 9, 11, "win-defeat", "", false, false], [0, 0, 18, 24, "role", "", false, false], [26, 26, 18, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getoor", "has", "received", "several", "best", "paper", "awards", ",", "an", "NSF", "Career", "Award", "and", "is", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Getoor has received several best paper awards, an NSF Career Award and is a member of the Association for the Advancement of Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 27], [28, 32], [33, 38], [39, 45], [45, 46], [47, 49], [50, 53], [54, 60], [61, 66], [67, 70], [71, 73], [74, 75], [76, 82], [83, 85], [86, 89], [90, 101], [102, 105], [106, 109], [110, 121], [122, 124], [125, 135], [136, 148], [149, 150], [150, 154], [154, 155], [155, 156]]}
{"doc_key": "ai-dev-217", "ner": [[0, 1, "misc"], [6, 10, "misc"], [15, 16, "misc"], [21, 25, "misc"], [34, 37, "university"], [42, 50, "misc"], [55, 63, "misc"], [68, 72, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACM", "Fellow", "(", "2015", ")", "br", "Association", "for", "Computational", "Linguistics", "Fellow", "(", "2011", ")", "br", "AAAI", "Fellow", "(", "1994", ")", "br", "International", "Speech", "Communication", "Association", "Fellow", "(", "2011", ")", "br", "Honorary", "Doctorate", "from", "the", "Royal", "Institute", "of", "Technology", "(", "2007", ")", "br", "Columbia", "Engineering", "School", "Alumni", "Association", "Distinguished", "Faculty", "Teaching", "award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Speech", "and", "Audio", "Processing", "Award", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")"], "sentence-detokenized": "ACM Fellow (2015) br Association for Computational Linguistics Fellow (2011) br AAAI Fellow (1994) br International Speech Communication Association Fellow (2011) br Honorary Doctorate from the Royal Institute of Technology (2007) br Columbia Engineering School Alumni Association Distinguished Faculty Teaching award (2009) br IEEE James L. Flanagan Speech and Audio Processing Award (2011) br ISCA Medal for Scientific Achievement (2011)", "token2charspan": [[0, 3], [4, 10], [11, 12], [12, 16], [16, 17], [18, 20], [21, 32], [33, 36], [37, 50], [51, 62], [63, 69], [70, 71], [71, 75], [75, 76], [77, 79], [80, 84], [85, 91], [92, 93], [93, 97], [97, 98], [99, 101], [102, 115], [116, 122], [123, 136], [137, 148], [149, 155], [156, 157], [157, 161], [161, 162], [163, 165], [166, 174], [175, 184], [185, 189], [190, 193], [194, 199], [200, 209], [210, 212], [213, 223], [224, 225], [225, 229], [229, 230], [231, 233], [234, 242], [243, 254], [255, 261], [262, 268], [269, 280], [281, 294], [295, 302], [303, 311], [312, 317], [318, 319], [319, 323], [323, 324], [325, 327], [328, 332], [333, 338], [339, 341], [342, 350], [351, 357], [358, 361], [362, 367], [368, 378], [379, 384], [385, 386], [386, 390], [390, 391], [392, 394], [395, 399], [400, 405], [406, 409], [410, 420], [421, 432], [433, 434], [434, 438], [438, 439]]}
{"doc_key": "ai-dev-218", "ner": [[6, 6, "university"], [15, 18, "task"], [28, 29, "metrics"], [39, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[28, 29, 39, 41, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["A", "frustrating", "result", "of", "the", "same", "Stanford", "study", "(", "and", "other", "attempts", "to", "improve", "the", "translation", "of", "name", "recognition", ")", "is", "that", "many", "times", "a", "decrease", "in", "the", "bilingual", "evaluation", "results", "for", "translation", "will", "result", "from", "the", "inclusion", "of", "named", "entity", "translation", "methods", "."], "sentence-detokenized": "A frustrating result of the same Stanford study (and other attempts to improve the translation of name recognition) is that many times a decrease in the bilingual evaluation results for translation will result from the inclusion of named entity translation methods.", "token2charspan": [[0, 1], [2, 13], [14, 20], [21, 23], [24, 27], [28, 32], [33, 41], [42, 47], [48, 49], [49, 52], [53, 58], [59, 67], [68, 70], [71, 78], [79, 82], [83, 94], [95, 97], [98, 102], [103, 114], [114, 115], [116, 118], [119, 123], [124, 128], [129, 134], [135, 136], [137, 145], [146, 148], [149, 152], [153, 162], [163, 173], [174, 181], [182, 185], [186, 197], [198, 202], [203, 209], [210, 214], [215, 218], [219, 228], [229, 231], [232, 237], [238, 244], [245, 256], [257, 264], [264, 265]]}
{"doc_key": "ai-dev-219", "ner": [[0, 0, "organisation"], [11, 13, "organisation"], [15, 20, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "role", "works_with", false, false], [0, 0, 15, 20, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "uses", "the", "collected", "PM", "data", "and", "collaborates", "with", "researchers", "at", "Johns", "Hopkins", "Hospital", "and", "Washington", "University", "School", "of", "Medicine", "to", "help", "answer", "specific", "questions", "about", "heart", "disease", ",", "such", "as", "whether", "weak", "hearts", "cause", "arrhythmias", "or", "vice", "versa", "."], "sentence-detokenized": "Medtronic uses the collected PM data and collaborates with researchers at Johns Hopkins Hospital and Washington University School of Medicine to help answer specific questions about heart disease, such as whether weak hearts cause arrhythmias or vice versa.", "token2charspan": [[0, 9], [10, 14], [15, 18], [19, 28], [29, 31], [32, 36], [37, 40], [41, 53], [54, 58], [59, 70], [71, 73], [74, 79], [80, 87], [88, 96], [97, 100], [101, 111], [112, 122], [123, 129], [130, 132], [133, 141], [142, 144], [145, 149], [150, 156], [157, 165], [166, 175], [176, 181], [182, 187], [188, 195], [195, 196], [197, 201], [202, 204], [205, 212], [213, 217], [218, 224], [225, 230], [231, 242], [243, 245], [246, 250], [251, 256], [256, 257]]}
{"doc_key": "ai-dev-220", "ner": [[4, 5, "organisation"], [10, 10, "misc"], [13, 14, "person"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 4, 5, "artifact", "made_by_studio", false, false], [13, 14, 10, 10, "role", "", false, false], [16, 17, 10, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "was", "followed", "by", "Paramount", "'s", "first", "feature", "film", ",", "Sangaree", ",", "starring", "Fernando", "Lamas", "and", "Arlene", "Dahl", "."], "sentence-detokenized": "This was followed by Paramount's first feature film, Sangaree, starring Fernando Lamas and Arlene Dahl.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 30], [30, 32], [33, 38], [39, 46], [47, 51], [51, 52], [53, 61], [61, 62], [63, 71], [72, 80], [81, 86], [87, 90], [91, 97], [98, 102], [102, 103]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [8, 10, "researcher"], [12, 14, "researcher"], [15, 16, "organisation"], [18, 19, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 10, "origin", "", false, false], [0, 0, 12, 14, "origin", "", false, false], [8, 10, 15, 16, "physical", "", false, false], [8, 10, 15, 16, "role", "", false, false], [12, 14, 18, 19, "physical", "", false, false], [12, 14, 18, 19, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "is", "a", "knowledge", "representation", "language", "developed", "by", "Daniel", "G.", "Bobrow", "and", "Terry", "Winograd", "at", "Xerox", "PARC", "and", "Stanford", "University", ",", "respectively", "."], "sentence-detokenized": "KRL is a knowledge representation language developed by Daniel G. Bobrow and Terry Winograd at Xerox PARC and Stanford University, respectively.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 18], [19, 33], [34, 42], [43, 52], [53, 55], [56, 62], [63, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 94], [95, 100], [101, 105], [106, 109], [110, 118], [119, 129], [129, 130], [131, 143], [143, 144]]}
{"doc_key": "ai-dev-222", "ner": [[2, 9, "conference"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 24, "researcher"], [32, 34, "task"], [35, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 9, 32, 34, "topic", "", true, false], [12, 13, 2, 9, "physical", "", false, false], [12, 13, 2, 9, "role", "", false, false], [12, 13, 2, 9, "temporal", "", false, false], [15, 16, 2, 9, "physical", "", false, false], [15, 16, 2, 9, "role", "", false, false], [15, 16, 2, 9, "temporal", "", false, false], [18, 19, 2, 9, "physical", "", false, false], [18, 19, 2, 9, "role", "", false, false], [18, 19, 2, 9, "temporal", "", false, false], [21, 24, 2, 9, "physical", "", false, false], [21, 24, 2, 9, "role", "", false, false], [21, 24, 2, 9, "temporal", "", false, false], [32, 34, 35, 36, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["At", "the", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "2006", ",", "Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", "and", "Kwang", "-", "Ting", "Cheng", "presented", "an", "algorithm", "to", "significantly", "speed", "up", "human", "detection", "using", "HOG", "descriptors", "."], "sentence-detokenized": "At the IEEE Conference on Computer Vision and Pattern Recognition 2006, Qiang Zhu, Shai Avidan, Mei-Chen Yeh and Kwang-Ting Cheng presented an algorithm to significantly speed up human detection using HOG descriptors.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 22], [23, 25], [26, 34], [35, 41], [42, 45], [46, 53], [54, 65], [66, 70], [70, 71], [72, 77], [78, 81], [81, 82], [83, 87], [88, 94], [94, 95], [96, 104], [105, 108], [109, 112], [113, 118], [118, 119], [119, 123], [124, 129], [130, 139], [140, 142], [143, 152], [153, 155], [156, 169], [170, 175], [176, 178], [179, 184], [185, 194], [195, 200], [201, 204], [205, 216], [216, 217]]}
{"doc_key": "ai-dev-223", "ner": [[0, 2, "researcher"], [5, 5, "conference"], [8, 10, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 5, 5, "role", "", false, false], [0, 2, 8, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "is", "a", "member", "of", "AAAI", "and", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Hayes is a member of AAAI and the Cognitive Science Society.", "token2charspan": [[0, 5], [6, 8], [9, 10], [11, 17], [18, 20], [21, 25], [26, 29], [30, 33], [34, 43], [44, 51], [52, 59], [59, 60]]}
{"doc_key": "ai-dev-224", "ner": [[0, 1, "misc"], [5, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 34, "field"], [38, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 1, 5, 5, "part-of", "", false, false], [0, 1, 5, 5, "usage", "", false, false], [0, 1, 7, 8, "part-of", "", false, false], [0, 1, 7, 8, "usage", "", false, false], [0, 1, 10, 11, "part-of", "", false, false], [0, 1, 10, 11, "usage", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [0, 1, 13, 13, "usage", "", false, false], [0, 1, 15, 16, "part-of", "", false, false], [0, 1, 15, 16, "usage", "", false, false], [0, 1, 18, 19, "part-of", "", false, false], [0, 1, 18, 19, "usage", "", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 21, 22, "usage", "", false, false], [0, 1, 24, 24, "part-of", "", false, false], [0, 1, 24, 24, "usage", "", false, false], [0, 1, 26, 27, "part-of", "", false, false], [0, 1, 26, 27, "usage", "", false, false], [0, 1, 29, 29, "part-of", "", false, false], [0, 1, 29, 29, "usage", "", false, false], [0, 1, 31, 34, "part-of", "", false, false], [0, 1, 31, 34, "usage", "", false, false], [0, 1, 38, 39, "part-of", "", false, false], [0, 1, 38, 39, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "economics", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", "and", "virtually", "all", "areas", "of", "applied", "science", "and", "technology", "involving", "temporal", "measurements", "."], "sentence-detokenized": "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical economics, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering and virtually all areas of applied science and technology involving temporal measurements.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 23], [24, 34], [34, 35], [36, 42], [43, 53], [53, 54], [55, 62], [63, 74], [74, 75], [76, 88], [88, 89], [90, 102], [103, 112], [112, 113], [114, 121], [122, 133], [133, 134], [135, 145], [146, 156], [156, 157], [158, 180], [180, 181], [182, 189], [190, 201], [201, 202], [203, 212], [212, 213], [214, 228], [229, 240], [241, 244], [245, 254], [255, 258], [259, 264], [265, 267], [268, 275], [276, 283], [284, 287], [288, 298], [299, 308], [309, 317], [318, 330], [330, 331]]}
{"doc_key": "ai-dev-225", "ner": [[13, 14, "metrics"], [34, 36, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "principle", ",", "exact", "recovery", "can", "be", "solved", "within", "the", "feasible", "range", "using", "maximum", "likelihood", ",", "but", "this", "involves", "solving", "a", "constrained", "or", "regularized", "problem", ",", "such", "as", "least", "division", ",", "which", "is", "usually", "NP", "-", "complete", "."], "sentence-detokenized": "In principle, exact recovery can be solved within the feasible range using maximum likelihood, but this involves solving a constrained or regularized problem, such as least division, which is usually NP-complete.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 19], [20, 28], [29, 32], [33, 35], [36, 42], [43, 49], [50, 53], [54, 62], [63, 68], [69, 74], [75, 82], [83, 93], [93, 94], [95, 98], [99, 103], [104, 112], [113, 120], [121, 122], [123, 134], [135, 137], [138, 149], [150, 157], [157, 158], [159, 163], [164, 166], [167, 172], [173, 181], [181, 182], [183, 188], [189, 191], [192, 199], [200, 202], [202, 203], [203, 211], [211, 212]]}
{"doc_key": "ai-dev-226", "ner": [[2, 4, "task"], [9, 9, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 9, 2, 4, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["in", "their", "pedestrian", "detection", "work", ",", "first", "described", "at", "BMVC", "2009", "."], "sentence-detokenized": "in their pedestrian detection work, first described at BMVC 2009.", "token2charspan": [[0, 2], [3, 8], [9, 19], [20, 29], [30, 34], [34, 35], [36, 41], [42, 51], [52, 54], [55, 59], [60, 64], [64, 65]]}
{"doc_key": "ai-dev-227", "ner": [[2, 6, "conference"], [9, 9, "researcher"], [13, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 2, 6, "physical", "", false, false], [9, 9, 2, 6, "role", "", false, false], [9, 9, 13, 21, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["At", "the", "International", "Conference", "on", "Computer", "Vision", "2007", ",", "Terzopoulos", "was", "awarded", "the", "first", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "for", "pioneering", "and", "sustained", "research", "on", "deformable", "models", "and", "their", "applications", "."], "sentence-detokenized": "At the International Conference on Computer Vision 2007, Terzopoulos was awarded the first IEEE PAMI Computer Vision Distinguished Researcher Award for pioneering and sustained research on deformable models and their applications.", "token2charspan": [[0, 2], [3, 6], [7, 20], [21, 31], [32, 34], [35, 43], [44, 50], [51, 55], [55, 56], [57, 68], [69, 72], [73, 80], [81, 84], [85, 90], [91, 95], [96, 100], [101, 109], [110, 116], [117, 130], [131, 141], [142, 147], [148, 151], [152, 162], [163, 166], [167, 176], [177, 185], [186, 188], [189, 199], [200, 206], [207, 210], [211, 216], [217, 229], [229, 230]]}
{"doc_key": "ai-dev-228", "ner": [[0, 1, "task"], [3, 4, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 3, 4, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cluster", "analysis", "or", "cluster", "analysis", "means", "that", "data", "points", "are", "assigned", "to", "clusters", "so", "that", "items", "in", "the", "same", "cluster", "are", "as", "similar", "as", "possible", ",", "while", "items", "belonging", "to", "different", "clusters", "are", "as", "different", "as", "possible", "."], "sentence-detokenized": "Cluster analysis or cluster analysis means that data points are assigned to clusters so that items in the same cluster are as similar as possible, while items belonging to different clusters are as different as possible.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 36], [37, 42], [43, 47], [48, 52], [53, 59], [60, 63], [64, 72], [73, 75], [76, 84], [85, 87], [88, 92], [93, 98], [99, 101], [102, 105], [106, 110], [111, 118], [119, 122], [123, 125], [126, 133], [134, 136], [137, 145], [145, 146], [147, 152], [153, 158], [159, 168], [169, 171], [172, 181], [182, 190], [191, 194], [195, 197], [198, 207], [208, 210], [211, 219], [219, 220]]}
{"doc_key": "ai-dev-229", "ner": [[11, 12, "field"], [15, 16, "field"], [18, 19, "task"], [21, 22, "field"], [24, 26, "field"], [28, 29, "field"], [31, 32, "field"], [34, 35, "task"], [37, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[11, 12, 15, 16, "named", "", false, false], [11, 12, 21, 22, "named", "", false, false], [11, 12, 28, 29, "named", "", false, false], [18, 19, 15, 16, "part-of", "task_part_of_field", false, false], [24, 26, 21, 22, "part-of", "", false, false], [31, 32, 28, 29, "part-of", "", false, false], [34, 35, 31, 32, "part-of", "", false, false], [37, 37, 31, 32, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["(", "2005", ")", "we", "can", "distinguish", "between", "three", "different", "perspectives", "on", "text", "mining", ",", "namely", "text", "mining", "as", "information", "extraction", ",", "text", "mining", "as", "text", "data", "extraction", "and", "text", "mining", "as", "data", "extraction", "(", "Knowledge", "Discovery", "in", "Databases", ")", ".", "Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005) we can distinguish between three different perspectives on text mining, namely text mining as information extraction, text mining as text data extraction and text mining as data extraction (Knowledge Discovery in Databases).Hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 9], [10, 13], [14, 25], [26, 33], [34, 39], [40, 49], [50, 62], [63, 65], [66, 70], [71, 77], [77, 78], [79, 85], [86, 90], [91, 97], [98, 100], [101, 112], [113, 123], [123, 124], [125, 129], [130, 136], [137, 139], [140, 144], [145, 149], [150, 160], [161, 164], [165, 169], [170, 176], [177, 179], [180, 184], [185, 195], [196, 197], [197, 206], [207, 216], [217, 219], [220, 229], [229, 230], [230, 231], [231, 236], [236, 237], [238, 240], [240, 241], [242, 252], [252, 253], [254, 256], [257, 260], [261, 265], [265, 266], [267, 269], [270, 271], [271, 275], [275, 276], [276, 277]]}
{"doc_key": "ai-dev-230", "ner": [[0, 2, "product"], [15, 20, "location"], [22, 22, "location"], [24, 24, "location"], [37, 38, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 15, 20, "related-to", "developed_for", false, false], [15, 20, 22, 22, "physical", "", false, false], [22, 22, 24, 24, "physical", "", false, false], [37, 38, 0, 2, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Rancho", "Arm", "was", "developed", "as", "a", "robotic", "arm", "to", "help", "disabled", "patients", "at", "the", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Center", "in", "Downey", ",", "California", ".", "In", "1963", ",", "the", "computer", "-", "controlled", "arm", "was", "purchased", "by", "Stanford", "University", "."], "sentence-detokenized": "The Rancho Arm was developed as a robotic arm to help disabled patients at the Rancho Los Amigos National Rehabilitation Center in Downey, California. In 1963, the computer-controlled arm was purchased by Stanford University.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 18], [19, 28], [29, 31], [32, 33], [34, 41], [42, 45], [46, 48], [49, 53], [54, 62], [63, 71], [72, 74], [75, 78], [79, 85], [86, 89], [90, 96], [97, 105], [106, 120], [121, 127], [128, 130], [131, 137], [137, 138], [139, 149], [149, 150], [151, 153], [154, 158], [158, 159], [160, 163], [164, 172], [172, 173], [173, 183], [184, 187], [188, 191], [192, 201], [202, 204], [205, 213], [214, 224], [224, 225]]}
{"doc_key": "ai-dev-231", "ner": [[1, 1, "university"], [3, 3, "researcher"], [11, 14, "organisation"], [22, 24, "organisation"], [28, 29, "researcher"], [31, 33, "researcher"], [47, 47, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 1, 1, "physical", "", false, false], [3, 3, 1, 1, "role", "", false, false], [3, 3, 11, 14, "role", "founder", false, false], [3, 3, 22, 24, "role", "founder", false, false], [22, 24, 47, 47, "physical", "", false, false], [28, 29, 22, 24, "role", "founder", false, false], [31, 33, 22, 24, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["At", "UCSD", ",", "Norman", "was", "one", "of", "the", "founders", "of", "the", "Institute", "for", "Cognitive", "Science", "and", "one", "of", "the", "organizers", "of", "the", "Cognitive", "Science", "Society", "(", "along", "with", "Roger", "Schank", ",", "Allan", "M.", "Collins", ",", "and", "others", ")", ",", "which", "held", "it", "s", "first", "meeting", "on", "the", "UCSD", "campus", "in", "1979", "."], "sentence-detokenized": "At UCSD, Norman was one of the founders of the Institute for Cognitive Science and one of the organizers of the Cognitive Science Society (along with Roger Schank, Allan M. Collins, and others), which held its first meeting on the UCSD campus in 1979.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 23], [24, 26], [27, 30], [31, 39], [40, 42], [43, 46], [47, 56], [57, 60], [61, 70], [71, 78], [79, 82], [83, 86], [87, 89], [90, 93], [94, 104], [105, 107], [108, 111], [112, 121], [122, 129], [130, 137], [138, 139], [139, 144], [145, 149], [150, 155], [156, 162], [162, 163], [164, 169], [170, 172], [173, 180], [180, 181], [182, 185], [186, 192], [192, 193], [193, 194], [195, 200], [201, 205], [206, 208], [208, 209], [210, 215], [216, 223], [224, 226], [227, 230], [231, 235], [236, 242], [243, 245], [246, 250], [250, 251]]}
{"doc_key": "ai-dev-232", "ner": [[6, 7, "product"], [9, 10, "product"], [12, 13, "product"], [15, 18, "product"], [20, 21, "product"], [23, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 15, 18, "type-of", "", false, false], [23, 28, 15, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "common", "robot", "configurations", "are", "guided", "robots", ",", "SCARA", "robots", ",", "delta", "robots", "and", "robots", "with", "Cartesian", "coordinates", "(", "portal", "robots", "or", "x", "-", "y", "-", "z", "robots", ")", "."], "sentence-detokenized": "The most common robot configurations are guided robots, SCARA robots, delta robots and robots with Cartesian coordinates (portal robots or x-y-z robots).", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 21], [22, 36], [37, 40], [41, 47], [48, 54], [54, 55], [56, 61], [62, 68], [68, 69], [70, 75], [76, 82], [83, 86], [87, 93], [94, 98], [99, 108], [109, 120], [121, 122], [122, 128], [129, 135], [136, 138], [139, 140], [140, 141], [141, 142], [142, 143], [143, 144], [145, 151], [151, 152], [152, 153]]}
{"doc_key": "ai-dev-233", "ner": [[8, 8, "programlang"], [9, 10, "misc"], [15, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 8, 8, "part-of", "", false, false], [15, 15, 9, 10, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Alternatively", ",", "it", "can", "be", "used", "directly", "with", "Perl", "Module", "TM", "(", "which", "also", "supports", "LTM", ")", "."], "sentence-detokenized": "Alternatively, it can be used directly with Perl Module TM (which also supports LTM).", "token2charspan": [[0, 13], [13, 14], [15, 17], [18, 21], [22, 24], [25, 29], [30, 38], [39, 43], [44, 48], [49, 55], [56, 58], [59, 60], [60, 65], [66, 70], [71, 79], [80, 83], [83, 84], [84, 85]]}
{"doc_key": "ai-dev-234", "ner": [[5, 5, "country"], [8, 12, "organisation"], [17, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 12, 5, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "won", "by", "an", "American", "team", "from", "Newton", "Labs", ",", "and", "the", "competition", "was", "broadcast", "on", "CNN", "."], "sentence-detokenized": "It was won by an American team from Newton Labs, and the competition was broadcast on CNN.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 16], [17, 25], [26, 30], [31, 35], [36, 42], [43, 47], [47, 48], [49, 52], [53, 56], [57, 68], [69, 72], [73, 82], [83, 85], [86, 89], [89, 90]]}
{"doc_key": "ai-dev-235", "ner": [[0, 4, "misc"], [11, 12, "person"], [15, 16, "person"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 0, 4, "role", "directs", false, false], [15, 16, 0, 4, "role", "acts_in", false, false], [18, 19, 0, 4, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Butler", "'s", "in", "Love", ",", "a", "short", "film", "directed", "by", "David", "Arquette", "and", "starring", "Elizabeth", "Berkley", "and", "Thomas", "Jane", ",", "was", "released", "on", "23", "June", "2008", "."], "sentence-detokenized": "The Butler's in Love, a short film directed by David Arquette and starring Elizabeth Berkley and Thomas Jane, was released on 23 June 2008.", "token2charspan": [[0, 3], [4, 10], [10, 12], [13, 15], [16, 20], [20, 21], [22, 23], [24, 29], [30, 34], [35, 43], [44, 46], [47, 52], [53, 61], [62, 65], [66, 74], [75, 84], [85, 92], [93, 96], [97, 103], [104, 108], [108, 109], [110, 113], [114, 122], [123, 125], [126, 128], [129, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-dev-236", "ner": [[0, 5, "product"], [10, 10, "field"], [16, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 5, 16, 16, "general-affiliation", "", false, false], [10, 10, 0, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "for", "example", ",", "is", "a", "resource", "with", "a", "taxonomy", "whose", "elements", "are", "meanings", "of", "English", "words", "."], "sentence-detokenized": "WordNet, for example, is a resource with a taxonomy whose elements are meanings of English words.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 20], [20, 21], [22, 24], [25, 26], [27, 35], [36, 40], [41, 42], [43, 51], [52, 57], [58, 66], [67, 70], [71, 79], [80, 82], [83, 90], [91, 96], [96, 97]]}
{"doc_key": "ai-dev-237", "ner": [[1, 3, "product"], [6, 6, "product"], [8, 8, "product"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 1, 3, "type-of", "", false, false], [6, 6, 13, 14, "related-to", "ability_to", false, false], [8, 8, 1, 3, "type-of", "", false, false], [8, 8, 13, 14, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Existing", "humanoid", "robotic", "systems", "such", "as", "ASIMO", "and", "QRIO", "use", "many", "motors", "to", "move", "around", "."], "sentence-detokenized": "Existing humanoid robotic systems such as ASIMO and QRIO use many motors to move around.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 33], [34, 38], [39, 41], [42, 47], [48, 51], [52, 56], [57, 60], [61, 65], [66, 72], [73, 75], [76, 80], [81, 87], [87, 88]]}
{"doc_key": "ai-dev-238", "ner": [[0, 0, "metrics"], [8, 9, "metrics"], [11, 11, "metrics"], [13, 17, "misc"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false], [13, 17, 0, 0, "part-of", "", false, false], [19, 19, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "is", "designed", "with", "the", "factors", "of", "improved", "length", "penalty", ",", "precision", ",", "n-", "gram", "word", "order", "penalty", "and", "revocation", "."], "sentence-detokenized": "LEPOR is designed with the factors of improved length penalty, precision, n-gram word order penalty and revocation.", "token2charspan": [[0, 5], [6, 8], [9, 17], [18, 22], [23, 26], [27, 34], [35, 37], [38, 46], [47, 53], [54, 61], [61, 62], [63, 72], [72, 73], [74, 76], [76, 80], [81, 85], [86, 91], [92, 99], [100, 103], [104, 114], [114, 115]]}
{"doc_key": "ai-dev-239", "ner": [[5, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "based", "on", "the", "measurement", "methodology", "of", "the", "bilingual", "evaluation", ",", "but", "with", "some", "modifications", "."], "sentence-detokenized": "It is based on the measurement methodology of the bilingual evaluation, but with some modifications.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 14], [15, 18], [19, 30], [31, 42], [43, 45], [46, 49], [50, 59], [60, 70], [70, 71], [72, 75], [76, 80], [81, 85], [86, 99], [99, 100]]}
{"doc_key": "ai-dev-240", "ner": [[8, 10, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "of", "an", "implementation", "in", "MATLAB", "/", "Octave", ":"], "sentence-detokenized": "This is an example of an implementation in MATLAB/Octave:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 24], [25, 39], [40, 42], [43, 49], [49, 50], [50, 56], [56, 57]]}
{"doc_key": "ai-dev-241", "ner": [[14, 14, "programlang"], [16, 16, "programlang"], [18, 18, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "designed", "to", "be", "used", "with", "a", "number", "of", "computer", "languages", ",", "including", "Python", ",", "Ruby", "and", "Scheme", "."], "sentence-detokenized": "It is designed to be used with a number of computer languages, including Python, Ruby and Scheme.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 20], [21, 25], [26, 30], [31, 32], [33, 39], [40, 42], [43, 51], [52, 61], [61, 62], [63, 72], [73, 79], [79, 80], [81, 85], [86, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-dev-242", "ner": [[0, 3, "researcher"], [7, 7, "organisation"], [13, 13, "conference"], [18, 19, "academicjournal"], [24, 26, "organisation"], [32, 36, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 7, 7, "role", "", false, false], [0, 3, 13, 13, "role", "", false, false], [0, 3, 18, 19, "role", "", false, false], [0, 3, 24, 26, "role", "", false, false], [0, 3, 32, 36, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "has", "served", "as", "Secretary", "of", "the", "AISB", ",", "President", "and", "Trustee", "of", "IJCAI", ",", "Associate", "Editor", "of", "Artificial", "Intelligence", ",", "Governor", "of", "the", "Cognitive", "Science", "Society", ",", "and", "President", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes has served as Secretary of the AISB, President and Trustee of IJCAI, Associate Editor of Artificial Intelligence, Governor of the Cognitive Science Society, and President of the American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 32], [33, 36], [37, 41], [41, 42], [43, 52], [53, 56], [57, 64], [65, 67], [68, 73], [73, 74], [75, 84], [85, 91], [92, 94], [95, 105], [106, 118], [118, 119], [120, 128], [129, 131], [132, 135], [136, 145], [146, 153], [154, 161], [161, 162], [163, 166], [167, 176], [177, 179], [180, 183], [184, 192], [193, 204], [205, 208], [209, 219], [220, 232], [232, 233]]}
{"doc_key": "ai-dev-243", "ner": [[4, 14, "misc"], [16, 18, "misc"], [23, 24, "person"], [29, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 24, 4, 14, "role", "directed_by", false, false], [23, 24, 16, 18, "role", "directed_by", false, false], [23, 24, 29, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "of", "them", ",", "Now", "is", "the", "Time", "(", "to", "Put", "On", "Your", "Glasses", ")", "and", "Around", "is", "Around", ",", "were", "directed", "by", "Norman", "McLaren", "in", "1951", "for", "the", "National", "Film", "Board", "of", "Canada", "."], "sentence-detokenized": "Two of them, Now is the Time (to Put On Your Glasses) and Around is Around, were directed by Norman McLaren in 1951 for the National Film Board of Canada.", "token2charspan": [[0, 3], [4, 6], [7, 11], [11, 12], [13, 16], [17, 19], [20, 23], [24, 28], [29, 30], [30, 32], [33, 36], [37, 39], [40, 44], [45, 52], [52, 53], [54, 57], [58, 64], [65, 67], [68, 74], [74, 75], [76, 80], [81, 89], [90, 92], [93, 99], [100, 107], [108, 110], [111, 115], [116, 119], [120, 123], [124, 132], [133, 137], [138, 143], [144, 146], [147, 153], [153, 154]]}
{"doc_key": "ai-dev-244", "ner": [[1, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "recommendation", "system", "aims", "to", "predict", "a", "target", "user", "'s", "preferences", "for", "a", "product", "."], "sentence-detokenized": "A recommendation system aims to predict a target user's preferences for a product.", "token2charspan": [[0, 1], [2, 16], [17, 23], [24, 28], [29, 31], [32, 39], [40, 41], [42, 48], [49, 53], [53, 55], [56, 67], [68, 71], [72, 73], [74, 81], [81, 82]]}
{"doc_key": "ai-dev-245", "ner": [[0, 0, "algorithm"], [4, 4, "field"], [6, 6, "field"], [8, 9, "field"], [11, 13, "field"], [15, 15, "field"], [17, 18, "field"], [20, 20, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 4, "part-of", "", true, false], [0, 0, 6, 6, "part-of", "", true, false], [0, 0, 8, 9, "part-of", "", true, false], [0, 0, 11, 13, "part-of", "", true, false], [0, 0, 15, 15, "part-of", "", true, false], [0, 0, 17, 18, "part-of", "", true, false], [0, 0, 20, 20, "part-of", "", true, false], [0, 0, 22, 23, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Convolution", "has", "applications", "in", "probability", ",", "statistics", ",", "computer", "vision", ",", "natural", "language", "processing", ",", "image", "and", "signal", "processing", ",", "engineering", "and", "differential", "equations", "."], "sentence-detokenized": "Convolution has applications in probability, statistics, computer vision, natural language processing, image and signal processing, engineering and differential equations.", "token2charspan": [[0, 11], [12, 15], [16, 28], [29, 31], [32, 43], [43, 44], [45, 55], [55, 56], [57, 65], [66, 72], [72, 73], [74, 81], [82, 90], [91, 101], [101, 102], [103, 108], [109, 112], [113, 119], [120, 130], [130, 131], [132, 143], [144, 147], [148, 160], [161, 170], [170, 171]]}
{"doc_key": "ai-dev-246", "ner": [[2, 2, "field"], [4, 6, "task"], [8, 9, "task"], [11, 11, "task"], [12, 13, "task"], [15, 16, "task"], [18, 19, "task"], [21, 22, "task"], [24, 24, "task"], [27, 28, "task"], [30, 30, "field"], [32, 32, "field"], [34, 36, "field"], [38, 38, "field"], [40, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[2, 2, 4, 6, "part-of", "", true, false], [2, 2, 8, 9, "part-of", "", true, false], [2, 2, 11, 11, "part-of", "", true, false], [2, 2, 12, 13, "part-of", "", true, false], [2, 2, 15, 16, "part-of", "", true, false], [2, 2, 18, 19, "part-of", "", true, false], [2, 2, 21, 22, "part-of", "", true, false], [2, 2, 24, 24, "part-of", "", true, false], [2, 2, 27, 28, "part-of", "", true, false], [2, 2, 30, 30, "part-of", "", true, false], [2, 2, 32, 32, "part-of", "", true, false], [2, 2, 34, 36, "part-of", "", true, false], [2, 2, 38, 38, "part-of", "", true, false], [2, 2, 40, 40, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Applications", "of", "DSP", "include", "audio", "signal", "processing", ",", "audio", "compression", ",", "digital", "image", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communications", ",", "digital", "synthesis", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", "and", "biomedicine", "."], "sentence-detokenized": "Applications of DSP include audio signal processing, audio compression, digital image processing, video compression, speech processing, speech recognition, digital communications, digital synthesis, radar, sonar, financial signal processing, seismology and biomedicine.", "token2charspan": [[0, 12], [13, 15], [16, 19], [20, 27], [28, 33], [34, 40], [41, 51], [51, 52], [53, 58], [59, 70], [70, 71], [72, 79], [80, 85], [86, 96], [96, 97], [98, 103], [104, 115], [115, 116], [117, 123], [124, 134], [134, 135], [136, 142], [143, 154], [154, 155], [156, 163], [164, 178], [178, 179], [180, 187], [188, 197], [197, 198], [199, 204], [204, 205], [206, 211], [211, 212], [213, 222], [223, 229], [230, 240], [240, 241], [242, 252], [253, 256], [257, 268], [268, 269]]}
{"doc_key": "ai-dev-247", "ner": [[11, 12, "misc"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "20", "February", "1912", "-", "11", "August", "2011", ")", "was", "an", "American", "inventor", ",", "best", "known", "for", "creating", "the", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "(20 February 1912-11 August 2011) was an American inventor, best known for creating the Unimate, the first industrial robot.", "token2charspan": [[0, 1], [1, 3], [4, 12], [13, 17], [17, 18], [18, 20], [21, 27], [28, 32], [32, 33], [34, 37], [38, 40], [41, 49], [50, 58], [58, 59], [60, 64], [65, 70], [71, 74], [75, 83], [84, 87], [88, 95], [95, 96], [97, 100], [101, 106], [107, 117], [118, 123], [123, 124]]}
{"doc_key": "ai-dev-248", "ner": [[2, 4, "researcher"], [6, 8, "researcher"], [10, 10, "researcher"], [21, 23, "algorithm"], [26, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 21, 23, "related-to", "writes_about", true, false], [6, 8, 21, 23, "related-to", "writes_about", true, false], [10, 10, 21, 23, "related-to", "writes_about", true, false], [21, 23, 26, 28, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Together", "with", "David", "E.", "Rumelhart", "and", "Ronald", "J.", "Williams", ",", "Hinton", "co-authored", "a", "widely", "cited", "paper", "published", "in", "1986", "that", "popularized", "the", "backpropagation", "algorithm", "for", "training", "multilayer", "neural", "networks", "."], "sentence-detokenized": "Together with David E. Rumelhart and Ronald J. Williams, Hinton co-authored a widely cited paper published in 1986 that popularized the backpropagation algorithm for training multilayer neural networks.", "token2charspan": [[0, 8], [9, 13], [14, 19], [20, 22], [23, 32], [33, 36], [37, 43], [44, 46], [47, 55], [55, 56], [57, 63], [64, 75], [76, 77], [78, 84], [85, 90], [91, 96], [97, 106], [107, 109], [110, 114], [115, 119], [120, 131], [132, 135], [136, 151], [152, 161], [162, 165], [166, 174], [175, 185], [186, 192], [193, 201], [201, 202]]}
{"doc_key": "ai-dev-249", "ner": [[8, 10, "metrics"], [12, 15, "metrics"], [17, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "value", "predicted", "is", "continuously", "distributed", ",", "mean", "square", "error", ",", "root", "mean", "square", "error", "or", "median", "absolute", "deviation", "can", "be", "used", "to", "summarize", "the", "errors", "."], "sentence-detokenized": "When the value predicted is continuously distributed, mean square error, root mean square error or median absolute deviation can be used to summarize the errors.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 40], [41, 52], [52, 53], [54, 58], [59, 65], [66, 71], [71, 72], [73, 77], [78, 82], [83, 89], [90, 95], [96, 98], [99, 105], [106, 114], [115, 124], [125, 128], [129, 131], [132, 136], [137, 139], [140, 149], [150, 153], [154, 160], [160, 161]]}
{"doc_key": "ai-dev-250", "ner": [[0, 1, "algorithm"], [10, 13, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 10, 13, "part-of", "", true, false], [0, 1, 14, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Conceptual", "clustering", "was", "developed", "mainly", "in", "the", "1980s", "as", "a", "machine", "learning", "paradigm", "for", "unsupervised", "learning", "."], "sentence-detokenized": "Conceptual clustering was developed mainly in the 1980s as a machine learning paradigm for unsupervised learning.", "token2charspan": [[0, 10], [11, 21], [22, 25], [26, 35], [36, 42], [43, 45], [46, 49], [50, 55], [56, 58], [59, 60], [61, 68], [69, 77], [78, 86], [87, 90], [91, 103], [104, 112], [112, 113]]}
{"doc_key": "ai-dev-251", "ner": [[8, 10, "product"], [30, 31, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "named", "entities", "can", "not", "be", "recognised", "by", "the", "machine", "translator", ",", "they", "may", "be", "incorrectly", "translated", "as", "common", "nouns", ",", "which", "would", "probably", "not", "affect", "the", "translation", "in", "the", "bilingual", "evaluation", ",", "but", "it", "would", "change", "the", "readability", "of", "the", "text", "for", "humans", "."], "sentence-detokenized": "If named entities cannot be recognised by the machine translator, they may be incorrectly translated as common nouns, which would probably not affect the translation in the bilingual evaluation, but it would change the readability of the text for humans.", "token2charspan": [[0, 2], [3, 8], [9, 17], [18, 21], [21, 24], [25, 27], [28, 38], [39, 41], [42, 45], [46, 53], [54, 64], [64, 65], [66, 70], [71, 74], [75, 77], [78, 89], [90, 100], [101, 103], [104, 110], [111, 116], [116, 117], [118, 123], [124, 129], [130, 138], [139, 142], [143, 149], [150, 153], [154, 165], [166, 168], [169, 172], [173, 182], [183, 193], [193, 194], [195, 198], [199, 201], [202, 207], [208, 214], [215, 218], [219, 230], [231, 233], [234, 237], [238, 242], [243, 246], [247, 253], [253, 254]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 22, "location"], [24, 24, "country"], [38, 39, "researcher"], [45, 46, "researcher"], [49, 52, "university"], [54, 55, "researcher"], [57, 58, "researcher"], [60, 61, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 22, "physical", "", false, false], [20, 22, 24, 24, "physical", "", false, false], [45, 46, 49, 52, "physical", "", false, false], [45, 46, 49, 52, "role", "", false, false], [54, 55, 49, 52, "physical", "", false, false], [54, 55, 49, 52, "role", "", false, false], [57, 58, 49, 52, "physical", "", false, false], [57, 58, 49, 52, "role", "", false, false], [60, 61, 49, 52, "physical", "", false, false], [60, 61, 49, 52, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng", "-", "S\u00e4by", ",", "Sweden", ",", "pages", "1-", "3", "This", "model", ",", "partly", "influenced", "by", "the", "work", "of", "Sydney", "Lamb", ",", "was", "widely", "used", "by", "Schank", "'s", "students", "at", "Yale", "University", ",", "for", "example", "Robert", "Wilensky", ",", "Wendy", "Lehnert", "and", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, pages 1-3 This model, partly influenced by the work of Sydney Lamb, was widely used by Schank's students at Yale University, for example Robert Wilensky, Wendy Lehnert and Janet Kolodner.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 130], [130, 131], [131, 135], [135, 136], [137, 143], [143, 144], [145, 150], [151, 153], [153, 154], [155, 159], [160, 165], [165, 166], [167, 173], [174, 184], [185, 187], [188, 191], [192, 196], [197, 199], [200, 206], [207, 211], [211, 212], [213, 216], [217, 223], [224, 228], [229, 231], [232, 238], [238, 240], [241, 249], [250, 252], [253, 257], [258, 268], [268, 269], [270, 273], [274, 281], [282, 288], [289, 297], [297, 298], [299, 304], [305, 312], [313, 316], [317, 322], [323, 331], [331, 332]]}
{"doc_key": "ai-dev-253", "ner": [[1, 3, "algorithm"], [5, 8, "algorithm"], [12, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[5, 8, 1, 3, "named", "", false, false], [12, 16, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["Improved", "maximum", "likelihood", "method", "(", "IMLM", ")", "is", "a", "combination", "of", "two", "maximum", "likelihood", "estimators", "(", "MLM", ")", "."], "sentence-detokenized": "Improved maximum likelihood method (IMLM) is a combination of two maximum likelihood estimators (MLM).", "token2charspan": [[0, 8], [9, 16], [17, 27], [28, 34], [35, 36], [36, 40], [40, 41], [42, 44], [45, 46], [47, 58], [59, 61], [62, 65], [66, 73], [74, 84], [85, 95], [96, 97], [97, 100], [100, 101], [101, 102]]}
{"doc_key": "ai-dev-254", "ner": [[20, 21, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[24, 25, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "methods", "can", "also", "analyse", "a", "programme", "'s", "performance", "and", "its", "usefulness", "and", "may", "therefore", "include", "an", "analysis", "of", "its", "confusion", "matrix", "(", "or", "confusion", "table", ")", "."], "sentence-detokenized": "These methods can also analyse a programme's performance and its usefulness and may therefore include an analysis of its confusion matrix (or confusion table).", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 22], [23, 30], [31, 32], [33, 42], [42, 44], [45, 56], [57, 60], [61, 64], [65, 75], [76, 79], [80, 83], [84, 93], [94, 101], [102, 104], [105, 113], [114, 116], [117, 120], [121, 130], [131, 137], [138, 139], [139, 141], [142, 151], [152, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-dev-255", "ner": [[0, 0, "product"], [5, 6, "researcher"], [8, 9, "researcher"], [11, 13, "researcher"], [18, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 6, "origin", "", false, false], [0, 0, 8, 9, "origin", "", false, false], [0, 0, 11, 13, "origin", "", false, false], [0, 0, 18, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "was", "first", "published", "by", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", "and", "Luc", "Van", "Gool", "and", "presented", "at", "the", "2006", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "SURF was first published by Herbert Bay, Tinne Tuytelaars and Luc Van Gool and presented at the 2006 European Conference on Computer Vision.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 39], [39, 40], [41, 46], [47, 57], [58, 61], [62, 65], [66, 69], [70, 74], [75, 78], [79, 88], [89, 91], [92, 95], [96, 100], [101, 109], [110, 120], [121, 123], [124, 132], [133, 139], [139, 140]]}
{"doc_key": "ai-dev-256", "ner": [[0, 2, "task"], [6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 6, 7, "part-of", "", false, false], [0, 2, 9, 10, "part-of", "", false, false], [0, 2, 12, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "is", "a", "research", "area", "in", "pattern", "recognition", ",", "artificial", "intelligence", "and", "computer", "vision", "."], "sentence-detokenized": "OCR is a research area in pattern recognition, artificial intelligence and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 17], [18, 22], [23, 25], [26, 33], [34, 45], [45, 46], [47, 57], [58, 70], [71, 74], [75, 83], [84, 90], [90, 91]]}
{"doc_key": "ai-dev-257", "ner": [[6, 9, "metrics"], [12, 14, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Continuing", "with", "the", "example", "and", "using", "the", "maximum", "likelihood", "estimator", ",", "the", "probability", "density", "function", "(", "pdf", ")", "of", "the", "noise", "for", "a", "sample", "mathwn", "/", "math", "is", "as", "follows"], "sentence-detokenized": "Continuing with the example and using the maximum likelihood estimator, the probability density function (pdf) of the noise for a sample mathwn/math is as follows", "token2charspan": [[0, 10], [11, 15], [16, 19], [20, 27], [28, 31], [32, 37], [38, 41], [42, 49], [50, 60], [61, 70], [70, 71], [72, 75], [76, 87], [88, 95], [96, 104], [105, 106], [106, 109], [109, 110], [111, 113], [114, 117], [118, 123], [124, 127], [128, 129], [130, 136], [137, 143], [143, 144], [144, 148], [149, 151], [152, 154], [155, 162]]}
{"doc_key": "ai-dev-258", "ner": [[2, 3, "field"], [5, 6, "task"], [8, 9, "task"], [11, 12, "task"], [14, 15, "task"], [17, 19, "task"], [21, 21, "task"], [23, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 6, 2, 3, "part-of", "", false, false], [8, 9, 2, 3, "part-of", "", false, false], [11, 12, 2, 3, "part-of", "", false, false], [14, 15, 2, 3, "part-of", "", false, false], [17, 19, 2, 3, "part-of", "", false, false], [21, 21, 2, 3, "part-of", "", false, false], [23, 23, 2, 3, "part-of", "", false, false], [25, 26, 2, 3, "part-of", "", false, false], [28, 29, 2, 3, "part-of", "", false, false], [31, 33, 2, 3, "part-of", "", false, false], [35, 36, 2, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Sub-areas", "of", "computer", "vision", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "3D", "position", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "servoing", ",", "3D", "scene", "modelling", "and", "image", "restoration", "."], "sentence-detokenized": "Sub-areas of computer vision include scene reconstruction, event detection, video tracking, object recognition, 3D position estimation, learning, indexing, motion estimation, visual servoing, 3D scene modelling and image restoration.", "token2charspan": [[0, 9], [10, 12], [13, 21], [22, 28], [29, 36], [37, 42], [43, 57], [57, 58], [59, 64], [65, 74], [74, 75], [76, 81], [82, 90], [90, 91], [92, 98], [99, 110], [110, 111], [112, 114], [115, 123], [124, 134], [134, 135], [136, 144], [144, 145], [146, 154], [154, 155], [156, 162], [163, 173], [173, 174], [175, 181], [182, 190], [190, 191], [192, 194], [195, 200], [201, 210], [211, 214], [215, 220], [221, 232], [232, 233]]}
{"doc_key": "ai-dev-259", "ner": [[3, 7, "conference"], [9, 9, "researcher"], [13, 14, "misc"], [17, 17, "conference"], [21, 21, "researcher"], [23, 23, "researcher"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 7, 17, 17, "named", "", false, false], [9, 9, 13, 14, "win-defeat", "", false, false], [9, 9, 25, 25, "related-to", "writes_about", true, false], [13, 14, 3, 7, "temporal", "", false, false], [21, 21, 13, 14, "win-defeat", "", false, true], [21, 21, 25, 25, "related-to", "writes_about", true, false], [23, 23, 13, 14, "win-defeat", "", false, true], [23, 23, 25, 25, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["At", "the", "2013", "International", "Conference", "on", "Computer", "Vision", ",", "Terzopoulos", "was", "awarded", "a", "Helmholtz", "Prize", "for", "his", "1987", "ICCV", "paper", "with", "Kass", "and", "Witkin", "on", "active", "contour", "models", "."], "sentence-detokenized": "At the 2013 International Conference on Computer Vision, Terzopoulos was awarded a Helmholtz Prize for his 1987 ICCV paper with Kass and Witkin on active contour models.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 25], [26, 36], [37, 39], [40, 48], [49, 55], [55, 56], [57, 68], [69, 72], [73, 80], [81, 82], [83, 92], [93, 98], [99, 102], [103, 106], [107, 111], [112, 116], [117, 122], [123, 127], [128, 132], [133, 136], [137, 143], [144, 146], [147, 153], [154, 161], [162, 168], [168, 169]]}
{"doc_key": "ai-dev-260", "ner": [[16, 17, "task"], [19, 21, "algorithm"], [23, 24, "algorithm"], [26, 28, "algorithm"], [30, 31, "algorithm"], [34, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[16, 17, 19, 21, "usage", "", true, false], [16, 17, 23, 24, "usage", "", true, false], [16, 17, 26, 28, "usage", "", true, false], [16, 17, 30, 31, "usage", "", true, false], [16, 17, 34, 35, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["About", "the", "regularization", "function", "There", "are", "many", "algorithms", "for", "solving", "such", "problems", ";", "popular", "algorithms", "for", "linear", "classification", "include", "stochastic", "gradient", "descent", ")", "gradient", "descent", ",", "L", "-", "BFGS", ",", "coordinate", "descent", ",", "and", "Newton", "'s", "methods", "."], "sentence-detokenized": "About the regularization function There are many algorithms for solving such problems; popular algorithms for linear classification include stochastic gradient descent) gradient descent, L-BFGS, coordinate descent, and Newton's methods.", "token2charspan": [[0, 5], [6, 9], [10, 24], [25, 33], [34, 39], [40, 43], [44, 48], [49, 59], [60, 63], [64, 71], [72, 76], [77, 85], [85, 86], [87, 94], [95, 105], [106, 109], [110, 116], [117, 131], [132, 139], [140, 150], [151, 159], [160, 167], [167, 168], [169, 177], [178, 185], [185, 186], [187, 188], [188, 189], [189, 193], [193, 194], [195, 205], [206, 213], [213, 214], [215, 218], [219, 225], [225, 227], [228, 235], [235, 236]]}
{"doc_key": "ai-dev-261", "ner": [[0, 4, "algorithm"], [12, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[0, 4, 12, 13, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Long", "short", "-", "term", "memory", "(", "LSTM", ")", "networks", "were", "invented", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "and", "have", "set", "records", "for", "accuracy", "in", "several", "application", "areas", "."], "sentence-detokenized": "Long short-term memory (LSTM) networks were invented by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997 and have set records for accuracy in several application areas.", "token2charspan": [[0, 4], [5, 10], [10, 11], [11, 15], [16, 22], [23, 24], [24, 28], [28, 29], [30, 38], [39, 43], [44, 52], [53, 55], [56, 60], [61, 71], [72, 75], [76, 82], [83, 94], [95, 97], [98, 102], [103, 106], [107, 111], [112, 115], [116, 123], [124, 127], [128, 136], [137, 139], [140, 147], [148, 159], [160, 165], [165, 166]]}
{"doc_key": "ai-dev-262", "ner": [[0, 0, "product"], [4, 6, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["TN", "was", "developed", "at", "Massachusetts", "General", "Hospital", "and", "tested", "in", "several", "scenarios", ",", "including", "smoking", "status", ",", "family", "history", "of", "coronary", "artery", "disease", "and", "identifying", "patients", "with", "sleep", "disorders", ","], "sentence-detokenized": "TN was developed at Massachusetts General Hospital and tested in several scenarios, including smoking status, family history of coronary artery disease and identifying patients with sleep disorders,", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 33], [34, 41], [42, 50], [51, 54], [55, 61], [62, 64], [65, 72], [73, 82], [82, 83], [84, 93], [94, 101], [102, 108], [108, 109], [110, 116], [117, 124], [125, 127], [128, 136], [137, 143], [144, 151], [152, 155], [156, 167], [168, 176], [177, 181], [182, 187], [188, 197], [197, 198]]}
{"doc_key": "ai-dev-263", "ner": [[3, 3, "researcher"], [15, 16, "organisation"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 86], [87, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-dev-264", "ner": [[0, 2, "conference"], [12, 13, "location"], [15, 15, "location"], [17, 17, "country"], [27, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 12, 13, "physical", "", false, false], [12, 13, 15, 15, "physical", "", false, false], [15, 15, 17, 17, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Campus", "Party", "Europe", "was", "held", "on", "14", "-", "18", "April", "2010", "at", "Caja", "M\u00e1gica", "in", "Madrid", ",", "Spain", ",", "with", "800", "participants", "from", "each", "of", "the", "27", "EU", "Member", "States", "."], "sentence-detokenized": "Campus Party Europe was held on 14-18 April 2010 at Caja M\u00e1gica in Madrid, Spain, with 800 participants from each of the 27 EU Member States.", "token2charspan": [[0, 6], [7, 12], [13, 19], [20, 23], [24, 28], [29, 31], [32, 34], [34, 35], [35, 37], [38, 43], [44, 48], [49, 51], [52, 56], [57, 63], [64, 66], [67, 73], [73, 74], [75, 80], [80, 81], [82, 86], [87, 90], [91, 103], [104, 108], [109, 113], [114, 116], [117, 120], [121, 123], [124, 126], [127, 133], [134, 140], [140, 141]]}
{"doc_key": "ai-dev-265", "ner": [[4, 4, "organisation"], [6, 8, "organisation"], [14, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 17, 4, 4, "origin", "", false, false], [14, 17, 6, 8, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2016", ",", "DeepMind", "and", "Moorfields", "Eye", "Hospital", "announced", "a", "collaboration", "to", "develop", "AI", "applications", "for", "healthcare", "."], "sentence-detokenized": "In July 2016, DeepMind and Moorfields Eye Hospital announced a collaboration to develop AI applications for healthcare.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 22], [23, 26], [27, 37], [38, 41], [42, 50], [51, 60], [61, 62], [63, 76], [77, 79], [80, 87], [88, 90], [91, 103], [104, 107], [108, 118], [118, 119]]}
{"doc_key": "ai-dev-266", "ner": [[5, 5, "misc"], [12, 14, "university"], [16, 16, "university"], [18, 19, "university"], [21, 22, "university"], [24, 24, "university"], [26, 26, "university"], [28, 31, "university"], [33, 34, "university"], [36, 37, "university"], [39, 39, "university"], [42, 44, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 5, 12, 14, "physical", "", false, false], [5, 5, 16, 16, "physical", "", false, false], [5, 5, 18, 19, "physical", "", false, false], [5, 5, 21, 22, "physical", "", false, false], [5, 5, 24, 24, "physical", "", false, false], [5, 5, 26, 26, "physical", "", false, false], [5, 5, 28, 31, "physical", "", false, false], [5, 5, 33, 34, "physical", "", false, false], [5, 5, 36, 37, "physical", "", false, false], [5, 5, 39, 39, "physical", "", false, false], [5, 5, 42, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["They", "ended", "up", "awarding", "eleven", "PR2s", "to", "various", "institutions", ",", "including", "the", "University", "of", "Freiburg", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "Technical", "University", "of", "Munich", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", "and", "the", "University", "of", "Tokyo", "."], "sentence-detokenized": "They ended up awarding eleven PR2s to various institutions, including the University of Freiburg, Bosch, Georgia Tech, KU Leuven, MIT, Stanford, Technical University of Munich, UC Berkeley, U Penn, USC and the University of Tokyo.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 29], [30, 34], [35, 37], [38, 45], [46, 58], [58, 59], [60, 69], [70, 73], [74, 84], [85, 87], [88, 96], [96, 97], [98, 103], [103, 104], [105, 112], [113, 117], [117, 118], [119, 121], [122, 128], [128, 129], [130, 133], [133, 134], [135, 143], [143, 144], [145, 154], [155, 165], [166, 168], [169, 175], [175, 176], [177, 179], [180, 188], [188, 189], [190, 191], [192, 196], [196, 197], [198, 201], [202, 205], [206, 209], [210, 220], [221, 223], [224, 229], [229, 230]]}
{"doc_key": "ai-dev-267", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [7, 7, "metrics"], [9, 10, "metrics"], [18, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 18, 19, "part-of", "", false, false], [5, 5, 18, 19, "part-of", "", false, false], [7, 7, 18, 19, "part-of", "", false, false], [9, 10, 18, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "count", "of", "TP", ",", "TN", ",", "FP", "and", "FN", "is", "usually", "entered", "into", "a", "table", "called", "the", "confusion", "matrix", "."], "sentence-detokenized": "The count of TP, TN, FP and FN is usually entered into a table called the confusion matrix.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 15], [15, 16], [17, 19], [19, 20], [21, 23], [24, 27], [28, 30], [31, 33], [34, 41], [42, 49], [50, 54], [55, 56], [57, 62], [63, 69], [70, 73], [74, 83], [84, 90], [90, 91]]}
{"doc_key": "ai-dev-268", "ner": [[0, 1, "metrics"], [3, 4, "metrics"], [6, 7, "metrics"], [9, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Information", "gain", ",", "cross", "-entropy", ",", "mutual", "information", "and", "odds", "ratio", "are", "usually", "used", "as", "feature", "composition", "."], "sentence-detokenized": "Information gain, cross-entropy, mutual information and odds ratio are usually used as feature composition.", "token2charspan": [[0, 11], [12, 16], [16, 17], [18, 23], [23, 31], [31, 32], [33, 39], [40, 51], [52, 55], [56, 60], [61, 66], [67, 70], [71, 78], [79, 83], [84, 86], [87, 94], [95, 106], [106, 107]]}
{"doc_key": "ai-dev-269", "ner": [[12, 13, "task"], [15, 16, "task"], [18, 18, "task"], [20, 20, "task"], [22, 22, "task"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[24, 24, 22, 22, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "successfully", "applied", "to", "a", "variety", "of", "problems", ",", "including", "robot", "control", ",", "elevator", "planning", ",", "telecommunications", ",", "checkers", "and", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "It has been successfully applied to a variety of problems, including robot control, elevator planning, telecommunications, checkers and Go (AlphaGo).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 32], [33, 35], [36, 37], [38, 45], [46, 48], [49, 57], [57, 58], [59, 68], [69, 74], [75, 82], [82, 83], [84, 92], [93, 101], [101, 102], [103, 121], [121, 122], [123, 131], [132, 135], [136, 138], [139, 140], [140, 147], [147, 148], [148, 149]]}
{"doc_key": "ai-dev-270", "ner": [[11, 16, "misc"], [17, 20, "university"], [22, 22, "location"], [24, 24, "location"], [28, 33, "location"], [35, 37, "location"], [39, 39, "location"], [41, 41, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 16, 17, 20, "physical", "", false, false], [17, 20, 22, 22, "physical", "", false, false], [22, 22, 24, 24, "physical", "", false, false], [28, 33, 35, 37, "physical", "", false, false], [35, 37, 39, 39, "physical", "", false, false], [39, 39, 41, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "the", "first", "year", "of", "Mission", "8", ",", "the", "US", "event", "was", "held", "at", "the", "Georgia", "Institute", "of", "Technology", "in", "Atlanta", ",", "Georgia", ",", "and", "the", "Asia", "-", "Pacific", "event", "was", "held", "at", "Beihang", "University", "Gymnasium", "in", "Beijing", ",", "China", "."], "sentence-detokenized": "In 2018, the first year of Mission 8, the US event was held at the Georgia Institute of Technology in Atlanta, Georgia, and the Asia-Pacific event was held at Beihang University Gymnasium in Beijing, China.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 18], [19, 23], [24, 26], [27, 34], [35, 36], [36, 37], [38, 41], [42, 44], [45, 50], [51, 54], [55, 59], [60, 62], [63, 66], [67, 74], [75, 84], [85, 87], [88, 98], [99, 101], [102, 109], [109, 110], [111, 118], [118, 119], [120, 123], [124, 127], [128, 132], [132, 133], [133, 140], [141, 146], [147, 150], [151, 155], [156, 158], [159, 166], [167, 177], [178, 187], [188, 190], [191, 198], [198, 199], [200, 205], [205, 206]]}
{"doc_key": "ai-dev-271", "ner": [[0, 1, "field"], [6, 10, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 10, "origin", "", false, false], [0, 1, 6, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "is", "strongly", "related", "to", "pattern", "recognition", "and", "has", "its", "origins", "in", "artificial", "intelligence", "."], "sentence-detokenized": "Machine learning is strongly related to pattern recognition and has its origins in artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 28], [29, 36], [37, 39], [40, 47], [48, 59], [60, 63], [64, 67], [68, 71], [72, 79], [80, 82], [83, 93], [94, 106], [106, 107]]}
{"doc_key": "ai-dev-272", "ner": [[16, 18, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "comes", "with", "3", "Java", "games", "that", "are", "controlled", "with", "the", "remote", "control", "and", "displayed", "on", "the", "LCD", "screen", "."], "sentence-detokenized": "It comes with 3 Java games that are controlled with the remote control and displayed on the LCD screen.", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 15], [16, 20], [21, 26], [27, 31], [32, 35], [36, 46], [47, 51], [52, 55], [56, 62], [63, 70], [71, 74], [75, 84], [85, 87], [88, 91], [92, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-dev-273", "ner": [[7, 17, "task"], [18, 20, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 20, 7, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "commercially", "successful", "but", "specialised", "technique", "for", "estimating", "the", "position", "of", "articulated", "bodies", "based", "on", "computer", "vision", "is", "optical", "motion", "capture", "."], "sentence-detokenized": "A commercially successful but specialised technique for estimating the position of articulated bodies based on computer vision is optical motion capture.", "token2charspan": [[0, 1], [2, 14], [15, 25], [26, 29], [30, 41], [42, 51], [52, 55], [56, 66], [67, 70], [71, 79], [80, 82], [83, 94], [95, 101], [102, 107], [108, 110], [111, 119], [120, 126], [127, 129], [130, 137], [138, 144], [145, 152], [152, 153]]}
{"doc_key": "ai-dev-274", "ner": [[0, 1, "organisation"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SMC", "is", "very", "similar", "to", "the", "more", "popular", "Jaccard", "index", "."], "sentence-detokenized": "The SMC is very similar to the more popular Jaccard index.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 23], [24, 26], [27, 30], [31, 35], [36, 43], [44, 51], [52, 57], [57, 58]]}
{"doc_key": "ai-dev-275", "ner": [[0, 0, "product"], [2, 6, "product"], [9, 12, "product"], [20, 21, "researcher"], [27, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 9, 12, "named", "", false, false], [0, 0, 20, 21, "artifact", "", false, false], [0, 0, 27, 27, "artifact", "", false, false], [2, 6, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ",", "or", "Programmable", "Universal", "Manipulation", "Arm", ")", "is", "an", "industrial", "robot", "developed", "by", "Victor", "Scheinman", "at", "the", "pioneering", "robotics", "company", "Unimation", "."], "sentence-detokenized": "PUMA (Programmable Universal Machine for Assembly, or Programmable Universal Manipulation Arm) is an industrial robot developed by Victor Scheinman at the pioneering robotics company Unimation.", "token2charspan": [[0, 4], [5, 6], [6, 18], [19, 28], [29, 36], [37, 40], [41, 49], [49, 50], [51, 53], [54, 66], [67, 76], [77, 89], [90, 93], [93, 94], [95, 97], [98, 100], [101, 111], [112, 117], [118, 127], [128, 130], [131, 137], [138, 147], [148, 150], [151, 154], [155, 165], [166, 174], [175, 182], [183, 192], [192, 193]]}
{"doc_key": "ai-dev-276", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "written", "in", "Python", "."], "sentence-detokenized": "It is written in Python.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 23], [23, 24]]}
{"doc_key": "ai-dev-277", "ner": [[0, 0, "misc"], [2, 2, "misc"], [12, 12, "field"], [14, 15, "field"], [17, 17, "field"], [23, 24, "field"], [26, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7], "relations": [[0, 0, 2, 2, "related-to", "metric_for", true, false], [0, 0, 12, 12, "part-of", "", false, false], [0, 0, 14, 15, "part-of", "", false, false], [0, 0, 17, 17, "part-of", "", false, false], [0, 0, 23, 24, "part-of", "", false, false], [0, 0, 26, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6], "sentence": ["Bandwidth", "in", "hertz", "is", "a", "key", "concept", "in", "many", "fields", ",", "including", "electronics", ",", "information", "theory", ",", "digital", "communications", ",", "radio", "communications", ",", "signal", "processing", "and", "spectroscopy", ",", "and", "is", "one", "of", "the", "determining", "factors", "for", "the", "capacity", "of", "a", "given", "communication", "channel", "."], "sentence-detokenized": "Bandwidth in hertz is a key concept in many fields, including electronics, information theory, digital communications, radio communications, signal processing and spectroscopy, and is one of the determining factors for the capacity of a given communication channel.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 21], [22, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 50], [50, 51], [52, 61], [62, 73], [73, 74], [75, 86], [87, 93], [93, 94], [95, 102], [103, 117], [117, 118], [119, 124], [125, 139], [139, 140], [141, 147], [148, 158], [159, 162], [163, 175], [175, 176], [177, 180], [181, 183], [184, 187], [188, 190], [191, 194], [195, 206], [207, 214], [215, 218], [219, 222], [223, 231], [232, 234], [235, 236], [237, 242], [243, 256], [257, 264], [264, 265]]}
{"doc_key": "ai-dev-278", "ner": [[9, 9, "algorithm"], [11, 11, "algorithm"], [18, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 18, 21, "part-of", "", false, false], [11, 11, 18, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "a", "convex", "loss", "is", "used", "(", "as", "in", "AdaBoost", ",", "LogitBoost", ",", "and", "all", "members", "of", "the", "AnyBoost", "family", "of", "algorithms", ")", ",", "a", "higher", "-", "margin", "example", "will", "receive", "less", "(", "or", "the", "same", ")", "weight", "as", "a", "lower", "-", "margin", "example", "."], "sentence-detokenized": "If a convex loss is used (as in AdaBoost, LogitBoost, and all members of the AnyBoost family of algorithms), a higher-margin example will receive less (or the same) weight as a lower-margin example.", "token2charspan": [[0, 2], [3, 4], [5, 11], [12, 16], [17, 19], [20, 24], [25, 26], [26, 28], [29, 31], [32, 40], [40, 41], [42, 52], [52, 53], [54, 57], [58, 61], [62, 69], [70, 72], [73, 76], [77, 85], [86, 92], [93, 95], [96, 106], [106, 107], [107, 108], [109, 110], [111, 117], [117, 118], [118, 124], [125, 132], [133, 137], [138, 145], [146, 150], [151, 152], [152, 154], [155, 158], [159, 163], [163, 164], [165, 171], [172, 174], [175, 176], [177, 182], [182, 183], [183, 189], [190, 197], [197, 198]]}
{"doc_key": "ai-dev-279", "ner": [[0, 2, "researcher"], [6, 7, "researcher"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sepp", "Hochreiter", "'s", "thesis", "from", "1991", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Sepp Hochreiter's thesis from 1991 Sepp Hochreiter.", "token2charspan": [[0, 4], [5, 15], [15, 17], [18, 24], [25, 29], [30, 34], [35, 39], [40, 50], [50, 51]]}
{"doc_key": "ai-dev-280", "ner": [[4, 5, "algorithm"], [7, 7, "algorithm"], [14, 14, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [27, 28, "algorithm"], [31, 32, "algorithm"], [34, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[7, 7, 4, 5, "named", "", false, false], [17, 19, 27, 28, "related-to", "", true, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["Typical", "discriminant", "models", "are", "logistic", "regression", "(", "LR", ")", ",", "support", "vector", "machines", "(", "SVM", ")", ",", "conditional", "random", "fields", "(", "CRF", ")", "(", "specified", "over", "an", "undirected", "graph", ")", ",", "decision", "trees", ",", "neural", "networks", "and", "many", "others", "."], "sentence-detokenized": "Typical discriminant models are logistic regression (LR), support vector machines (SVM), conditional random fields (CRF) (specified over an undirected graph), decision trees, neural networks and many others.", "token2charspan": [[0, 7], [8, 20], [21, 27], [28, 31], [32, 40], [41, 51], [52, 53], [53, 55], [55, 56], [56, 57], [58, 65], [66, 72], [73, 81], [82, 83], [83, 86], [86, 87], [87, 88], [89, 100], [101, 107], [108, 114], [115, 116], [116, 119], [119, 120], [121, 122], [122, 131], [132, 136], [137, 139], [140, 150], [151, 156], [156, 157], [157, 158], [159, 167], [168, 173], [173, 174], [175, 181], [182, 190], [191, 194], [195, 199], [200, 206], [206, 207]]}
{"doc_key": "ai-dev-281", "ner": [[11, 13, "metrics"], [35, 36, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "also", "possible", "to", "use", "these", "probabilities", "and", "evaluate", "the", "mean", "square", "error", "(", "or", "some", "other", "similar", "measure", ")", "between", "the", "probabilities", "and", "the", "actual", "values", ",", "and", "then", "combine", "this", "with", "the", "confusion", "matrix", "to", "create", "very", "efficient", "fitness", "functions", "for", "logistic", "regression", "."], "sentence-detokenized": "It is also possible to use these probabilities and evaluate the mean square error (or some other similar measure) between the probabilities and the actual values, and then combine this with the confusion matrix to create very efficient fitness functions for logistic regression.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 19], [20, 22], [23, 26], [27, 32], [33, 46], [47, 50], [51, 59], [60, 63], [64, 68], [69, 75], [76, 81], [82, 83], [83, 85], [86, 90], [91, 96], [97, 104], [105, 112], [112, 113], [114, 121], [122, 125], [126, 139], [140, 143], [144, 147], [148, 154], [155, 161], [161, 162], [163, 166], [167, 171], [172, 179], [180, 184], [185, 189], [190, 193], [194, 203], [204, 210], [211, 213], [214, 220], [221, 225], [226, 235], [236, 243], [244, 253], [254, 257], [258, 266], [267, 277], [277, 278]]}
{"doc_key": "ai-dev-282", "ner": [[0, 0, "product"], [7, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "was", "first", "available", "in", "2005", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "."], "sentence-detokenized": "VoiceOver was first available in 2005 in Mac OS X Tiger (10.4).", "token2charspan": [[0, 9], [10, 13], [14, 19], [20, 29], [30, 32], [33, 37], [38, 40], [41, 44], [45, 47], [48, 49], [50, 55], [56, 57], [57, 61], [61, 62], [62, 63]]}
{"doc_key": "ai-dev-283", "ner": [[13, 15, "algorithm"], [17, 21, "misc"], [24, 26, "metrics"], [28, 30, "algorithm"], [59, 61, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 15, 17, 21, "related-to", "applied_to", false, false], [24, 26, 17, 21, "type-of", "", false, false], [24, 26, 28, 30, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "practice", ",", "machine", "learning", "algorithms", "deal", "with", "this", "either", "by", "using", "a", "convex", "approximation", "of", "the", "0", "-", "1", "loss", "function", "(", "like", "hinge", "-", "loss", "for", "support", "vector", "machines", ")", ",", "which", "is", "easier", "to", "optimize", ",", "or", "by", "making", "assumptions", "about", "the", "distribution", "mathP", "(", "x", ",", "y", ")", "/", "math", "(", "and", "thus", "stop", "being", "agnostic", "learning", "algorithms", "as", "the", "above", "results", "hold", "for", ")", "."], "sentence-detokenized": "In practice, machine learning algorithms deal with this either by using a convex approximation of the 0-1 loss function (like hinge-loss for support vector machines), which is easier to optimize, or by making assumptions about the distribution mathP(x, y)/math (and thus stop being agnostic learning algorithms as the above results hold for).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 29], [30, 40], [41, 45], [46, 50], [51, 55], [56, 62], [63, 65], [66, 71], [72, 73], [74, 80], [81, 94], [95, 97], [98, 101], [102, 103], [103, 104], [104, 105], [106, 110], [111, 119], [120, 121], [121, 125], [126, 131], [131, 132], [132, 136], [137, 140], [141, 148], [149, 155], [156, 164], [164, 165], [165, 166], [167, 172], [173, 175], [176, 182], [183, 185], [186, 194], [194, 195], [196, 198], [199, 201], [202, 208], [209, 220], [221, 226], [227, 230], [231, 243], [244, 249], [249, 250], [250, 251], [251, 252], [253, 254], [254, 255], [255, 256], [256, 260], [261, 262], [262, 265], [266, 270], [271, 275], [276, 281], [282, 290], [291, 299], [300, 310], [311, 313], [314, 317], [318, 323], [324, 331], [332, 336], [337, 340], [340, 341], [341, 342]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [11, 12, "field"], [18, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 12, "usage", "", false, false], [0, 0, 18, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Westworld", "(", "1973", ")", "was", "the", "first", "feature", "film", "to", "use", "digital", "imaging", "of", "photography", "to", "simulate", "an", "android", "'s", "point", "of", "view", "."], "sentence-detokenized": "Westworld (1973) was the first feature film to use digital imaging of photography to simulate an android's point of view.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 20], [21, 24], [25, 30], [31, 38], [39, 43], [44, 46], [47, 50], [51, 58], [59, 66], [67, 69], [70, 81], [82, 84], [85, 93], [94, 96], [97, 104], [104, 106], [107, 112], [113, 115], [116, 120], [120, 121]]}
{"doc_key": "ai-dev-285", "ner": [[7, 8, "task"], [10, 11, "task"], [13, 13, "task"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "now", "also", "widely", "used", "for", "speech", "recognition", ",", "speech", "synthesis", ",", "diarization", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "It is now also widely used for speech recognition, speech synthesis, diarization, Xavier Anguera et al.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 14], [15, 21], [22, 26], [27, 30], [31, 37], [38, 49], [49, 50], [51, 57], [58, 67], [67, 68], [69, 80], [80, 81], [82, 88], [89, 96], [97, 99], [100, 102], [102, 103]]}
{"doc_key": "ai-dev-286", "ner": [[8, 10, "algorithm"], [14, 15, "algorithm"], [18, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 8, 10, "type-of", "", false, false], [18, 20, 8, 10, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Here", "math", "\\", "sigma", "/", "math", "is", "an", "elementwise", "activation", "function", ",", "e.g.", "a", "sigmoid", "function", "or", "a", "rectified", "linear", "unit", "."], "sentence-detokenized": "Here math\\ sigma/math is an elementwise activation function, e.g. a sigmoid function or a rectified linear unit.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 16], [16, 17], [17, 21], [22, 24], [25, 27], [28, 39], [40, 50], [51, 59], [59, 60], [61, 65], [66, 67], [68, 75], [76, 84], [85, 87], [88, 89], [90, 99], [100, 106], [107, 111], [111, 112]]}
{"doc_key": "ai-dev-287", "ner": [[11, 13, "algorithm"], [22, 22, "misc"], [24, 24, "misc"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "phonetic", "-", "based", "methods", "(", "i.e.", "all", "models", "based", "on", "hidden", "Markov", "models", ")", "require", "separate", "components", "and", "training", "for", "the", "pronunciation", ",", "acoustics", "and", "language", "models", "."], "sentence-detokenized": "Traditional phonetic-based methods (i.e. all models based on hidden Markov models) require separate components and training for the pronunciation, acoustics and language models.", "token2charspan": [[0, 11], [12, 20], [20, 21], [21, 26], [27, 34], [35, 36], [36, 40], [41, 44], [45, 51], [52, 57], [58, 60], [61, 67], [68, 74], [75, 81], [81, 82], [83, 90], [91, 99], [100, 110], [111, 114], [115, 123], [124, 127], [128, 131], [132, 145], [145, 146], [147, 156], [157, 160], [161, 169], [170, 176], [176, 177]]}
{"doc_key": "ai-dev-288", "ner": [[0, 3, "algorithm"], [7, 8, "field"], [10, 11, "field"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 13, 14, "related-to", "used_for", false, false], [7, 8, 0, 3, "usage", "", false, false], [10, 11, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Robert", "'s", "cross", "operator", "is", "used", "in", "image", "processing", "and", "computer", "vision", "to", "detect", "edges", "."], "sentence-detokenized": "Robert's cross operator is used in image processing and computer vision to detect edges.", "token2charspan": [[0, 6], [6, 8], [9, 14], [15, 23], [24, 26], [27, 31], [32, 34], [35, 40], [41, 51], [52, 55], [56, 64], [65, 71], [72, 74], [75, 81], [82, 87], [87, 88]]}
{"doc_key": "ai-dev-289", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 25, 25, "opposite", "", false, false], [5, 5, 25, 25, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "values", "for", "sensitivity", "and", "specificity", "are", "independent", "of", "the", "proportion", "of", "positive", "cases", "in", "the", "population", "of", "interest", "(", "unlike", ",", "for", "example", ",", "precision", ")", "."], "sentence-detokenized": "The values for sensitivity and specificity are independent of the proportion of positive cases in the population of interest (unlike, for example, precision).", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 26], [27, 30], [31, 42], [43, 46], [47, 58], [59, 61], [62, 65], [66, 76], [77, 79], [80, 88], [89, 94], [95, 97], [98, 101], [102, 112], [113, 115], [116, 124], [125, 126], [126, 132], [132, 133], [134, 137], [138, 145], [145, 146], [147, 156], [156, 157], [157, 158]]}
{"doc_key": "ai-dev-290", "ner": [[2, 4, "algorithm"], [14, 14, "misc"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 14, 2, 4, "topic", "", false, false], [14, 14, 16, 17, "artifact", "", false, false], [14, 14, 19, 20, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "the", "Perceptron", "models", "became", "very", "unpopular", "with", "the", "publication", "of", "the", "book", "Perceptrons", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "in", "1969", "."], "sentence-detokenized": "However, the Perceptron models became very unpopular with the publication of the book Perceptrons by Marvin Minsky and Seymour Papert in 1969.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 23], [24, 30], [31, 37], [38, 42], [43, 52], [53, 57], [58, 61], [62, 73], [74, 76], [77, 80], [81, 85], [86, 97], [98, 100], [101, 107], [108, 114], [115, 118], [119, 126], [127, 133], [134, 136], [137, 141], [141, 142]]}
{"doc_key": "ai-dev-291", "ner": [[1, 3, "conference"], [8, 8, "organisation"], [22, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 3, 22, 24, "topic", "", false, false], [8, 8, 1, 3, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Document", "Understanding", "Conferences", ",", "conducted", "annually", "by", "NIST", ",", "have", "developed", "sophisticated", "evaluation", "criteria", "for", "techniques", "that", "address", "the", "challenge", "of", "summarizing", "multiple", "documents", "."], "sentence-detokenized": "The Document Understanding Conferences, conducted annually by NIST, have developed sophisticated evaluation criteria for techniques that address the challenge of summarizing multiple documents.", "token2charspan": [[0, 3], [4, 12], [13, 26], [27, 38], [38, 39], [40, 49], [50, 58], [59, 61], [62, 66], [66, 67], [68, 72], [73, 82], [83, 96], [97, 107], [108, 116], [117, 120], [121, 131], [132, 136], [137, 144], [145, 148], [149, 158], [159, 161], [162, 173], [174, 182], [183, 192], [192, 193]]}
{"doc_key": "ai-dev-292", "ner": [[1, 2, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 26, 27, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "parallel", "manipulator", "is", "designed", "so", "that", "each", "chain", "is", "usually", "short", "and", "simple", "and", "thus", "can", "be", "rigid", "against", "unwanted", "movements", ",", "compared", "to", "a", "serial", "manipulator", "."], "sentence-detokenized": "A parallel manipulator is designed so that each chain is usually short and simple and thus can be rigid against unwanted movements, compared to a serial manipulator.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 34], [35, 37], [38, 42], [43, 47], [48, 53], [54, 56], [57, 64], [65, 70], [71, 74], [75, 81], [82, 85], [86, 90], [91, 94], [95, 97], [98, 103], [104, 111], [112, 120], [121, 130], [130, 131], [132, 140], [141, 143], [144, 145], [146, 152], [153, 164], [164, 165]]}
{"doc_key": "ai-dev-293", "ner": [[26, 26, "misc"], [28, 30, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "the", "manipulator", "that", "makes", "the", "robot", "move", ",", "and", "the", "design", "of", "these", "systems", "can", "be", "divided", "into", "several", "common", "types", ",", "such", "as", "SCARA", "and", "Cartesian", "coordinate", "robots", ",", "which", "use", "different", "coordinate", "systems", "to", "control", "the", "arms", "of", "the", "machine", "."], "sentence-detokenized": "It is the manipulator that makes the robot move, and the design of these systems can be divided into several common types, such as SCARA and Cartesian coordinate robots, which use different coordinate systems to control the arms of the machine.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 21], [22, 26], [27, 32], [33, 36], [37, 42], [43, 47], [47, 48], [49, 52], [53, 56], [57, 63], [64, 66], [67, 72], [73, 80], [81, 84], [85, 87], [88, 95], [96, 100], [101, 108], [109, 115], [116, 121], [121, 122], [123, 127], [128, 130], [131, 136], [137, 140], [141, 150], [151, 161], [162, 168], [168, 169], [170, 175], [176, 179], [180, 189], [190, 200], [201, 208], [209, 211], [212, 219], [220, 223], [224, 228], [229, 231], [232, 235], [236, 243], [243, 244]]}
{"doc_key": "ai-dev-294", "ner": [[2, 3, "country"], [11, 14, "organisation"], [17, 22, "organisation"], [25, 28, "organisation"], [31, 33, "organisation"], [36, 42, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 14, 2, 3, "physical", "", false, false], [17, 22, 2, 3, "physical", "", false, false], [25, 28, 2, 3, "physical", "", false, false], [31, 33, 2, 3, "physical", "", false, false], [36, 42, 2, 3, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "United", "States", ",", "he", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "Linguistic", "Society", "of", "America", ",", "the", "American", "Philosophical", "Association", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In the United States, he is a member of the National Academy of Sciences, the American Academy of Arts and Sciences, the Linguistic Society of America, the American Philosophical Association and the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 20], [20, 21], [22, 24], [25, 27], [28, 29], [30, 36], [37, 39], [40, 43], [44, 52], [53, 60], [61, 63], [64, 72], [72, 73], [74, 77], [78, 86], [87, 94], [95, 97], [98, 102], [103, 106], [107, 115], [115, 116], [117, 120], [121, 131], [132, 139], [140, 142], [143, 150], [150, 151], [152, 155], [156, 164], [165, 178], [179, 190], [191, 194], [195, 198], [199, 207], [208, 219], [220, 223], [224, 227], [228, 239], [240, 242], [243, 250], [250, 251]]}
{"doc_key": "ai-dev-295", "ner": [[11, 14, "algorithm"], [16, 16, "algorithm"], [23, 25, "algorithm"], [31, 32, "algorithm"], [37, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 14, 23, 25, "named", "", false, false], [16, 16, 11, 14, "named", "", false, false], [23, 25, 31, 32, "compare", "", false, false], [23, 25, 37, 38, "related-to", "performs", false, false], [31, 32, 37, 38, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["They", "received", "much", "attention", "in", "the", "context", "of", "the", "popularity", "of", "the", "support", "vector", "machine", "(", "SVM", ")", "in", "the", "1990s", ",", "when", "the", "SVM", "was", "shown", "to", "be", "competitive", "with", "neural", "networks", "in", "tasks", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "They received much attention in the context of the popularity of the support vector machine (SVM) in the 1990s, when the SVM was shown to be competitive with neural networks in tasks such as handwriting recognition.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 28], [29, 31], [32, 35], [36, 43], [44, 46], [47, 50], [51, 61], [62, 64], [65, 68], [69, 76], [77, 83], [84, 91], [92, 93], [93, 96], [96, 97], [98, 100], [101, 104], [105, 110], [110, 111], [112, 116], [117, 120], [121, 124], [125, 128], [129, 134], [135, 137], [138, 140], [141, 152], [153, 157], [158, 164], [165, 173], [174, 176], [177, 182], [183, 187], [188, 190], [191, 202], [203, 214], [214, 215]]}
{"doc_key": "ai-dev-296", "ner": [[2, 3, "misc"], [8, 9, "misc"], [13, 14, "algorithm"], [22, 25, "misc"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 8, 9, "usage", "", false, false], [2, 3, 22, 25, "usage", "", false, false], [8, 9, 13, 14, "origin", "result_of_algorithm", false, false], [22, 25, 27, 28, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["An", "empirical", "fading", "transformer", "is", "obtained", "by", "estimating", "the", "covariance", "(", "e.g.", "by", "maximum", "likelihood", ")", "and", "then", "constructing", "a", "corresponding", "estimated", "fading", "matrix", "(", "e.g.", "by", "Cholesky", "decomposition", ")", "."], "sentence-detokenized": "An empirical fading transformer is obtained by estimating the covariance (e.g. by maximum likelihood) and then constructing a corresponding estimated fading matrix (e.g. by Cholesky decomposition).", "token2charspan": [[0, 2], [3, 12], [13, 19], [20, 31], [32, 34], [35, 43], [44, 46], [47, 57], [58, 61], [62, 72], [73, 74], [74, 78], [79, 81], [82, 89], [90, 100], [100, 101], [102, 105], [106, 110], [111, 123], [124, 125], [126, 139], [140, 149], [150, 156], [157, 163], [164, 165], [165, 169], [170, 172], [173, 181], [182, 195], [195, 196], [196, 197]]}
{"doc_key": "ai-dev-297", "ner": [[0, 2, "organisation"], [8, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 8, 0, 2, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["IAI", "is", "the", "world", "'s", "largest", "manufacturer", "of", "Cartesian", "coordinate", "robots", "and", "is", "an", "established", "leader", "in", "low", "-", "cost", ",", "high", "-", "performance", "SCARA", "robots", "."], "sentence-detokenized": "IAI is the world's largest manufacturer of Cartesian coordinate robots and is an established leader in low-cost, high-performance SCARA robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [16, 18], [19, 26], [27, 39], [40, 42], [43, 52], [53, 63], [64, 70], [71, 74], [75, 77], [78, 80], [81, 92], [93, 99], [100, 102], [103, 106], [106, 107], [107, 111], [111, 112], [113, 117], [117, 118], [118, 129], [130, 135], [136, 142], [142, 143]]}
{"doc_key": "ai-dev-298", "ner": [[10, 11, "field"], [13, 14, "field"], [16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formal", "conceptual", "analysis", "has", "practical", "applications", "in", "areas", "such", "as", "data", "mining", ",", "text", "mining", ",", "machine", "learning", ",", "knowledge", "management", ",", "semantic", "web", ",", "software", "development", ",", "chemistry", "and", "biology", "."], "sentence-detokenized": "Formal conceptual analysis has practical applications in areas such as data mining, text mining, machine learning, knowledge management, semantic web, software development, chemistry and biology.", "token2charspan": [[0, 6], [7, 17], [18, 26], [27, 30], [31, 40], [41, 53], [54, 56], [57, 62], [63, 67], [68, 70], [71, 75], [76, 82], [82, 83], [84, 88], [89, 95], [95, 96], [97, 104], [105, 113], [113, 114], [115, 124], [125, 135], [135, 136], [137, 145], [146, 149], [149, 150], [151, 159], [160, 171], [171, 172], [173, 182], [183, 186], [187, 194], [194, 195]]}
{"doc_key": "ai-dev-299", "ner": [[1, 2, "field"], [4, 6, "field"], [10, 11, "field"], [17, 18, "field"], [29, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 17, 18, "part-of", "", false, false], [4, 6, 29, 30, "topic", "", false, false], [10, 11, 4, 6, "named", "", false, false], [17, 18, 1, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", ",", "computational", "learning", "theory", "(", "or", "just", "learning", "theory", ")", "is", "a", "subfield", "of", "artificial", "intelligence", "devoted", "to", "the", "study", "of", "the", "design", "and", "analysis", "of", "machine", "learning", "algorithms", "."], "sentence-detokenized": "In computer science, computational learning theory (or just learning theory) is a subfield of artificial intelligence devoted to the study of the design and analysis of machine learning algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 34], [35, 43], [44, 50], [51, 52], [52, 54], [55, 59], [60, 68], [69, 75], [75, 76], [77, 79], [80, 81], [82, 90], [91, 93], [94, 104], [105, 117], [118, 125], [126, 128], [129, 132], [133, 138], [139, 141], [142, 145], [146, 152], [153, 156], [157, 165], [166, 168], [169, 176], [177, 185], [186, 196], [196, 197]]}
{"doc_key": "ai-dev-300", "ner": [[0, 1, "algorithm"], [3, 3, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "Filtering", "(", "CF", ")", "is", "a", "technique", "used", "in", "recommendation", "systems", "."], "sentence-detokenized": "Collaborative Filtering (CF) is a technique used in recommendation systems.", "token2charspan": [[0, 13], [14, 23], [24, 25], [25, 27], [27, 28], [29, 31], [32, 33], [34, 43], [44, 48], [49, 51], [52, 66], [67, 74], [74, 75]]}
{"doc_key": "ai-dev-301", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "false", "positive", "rate", "is", "the", "proportion", "of", "all", "negative", "results", "that", "still", "yield", "positive", "test", "results", ",", "i.e.", "the", "conditional", "probability", "of", "a", "positive", "test", "result", "given", "an", "event", "that", "was", "not", "present", "."], "sentence-detokenized": "The false positive rate is the proportion of all negative results that still yield positive test results, i.e. the conditional probability of a positive test result given an event that was not present.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 23], [24, 26], [27, 30], [31, 41], [42, 44], [45, 48], [49, 57], [58, 65], [66, 70], [71, 76], [77, 82], [83, 91], [92, 96], [97, 104], [104, 105], [106, 110], [111, 114], [115, 126], [127, 138], [139, 141], [142, 143], [144, 152], [153, 157], [158, 164], [165, 170], [171, 173], [174, 179], [180, 184], [185, 188], [189, 192], [193, 200], [200, 201]]}
{"doc_key": "ai-dev-302", "ner": [[1, 15, "misc"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 15, 37, 37, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "VLDB", "'", "8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pages", "422-433", ".", "showed", "that", "the", "given", "values", "for", "mathC", "/", "math", "and", "mathK", "/", "math", "generally", "imply", "relatively", "low", "accuracy", "for", "iteratively", "computed", "SimRank", "scores", "."], "sentence-detokenized": "In VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, pages 422-433. showed that the given values for mathC/math and mathK/math generally imply relatively low accuracy for iteratively computed SimRank scores.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [10, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 79], [80, 85], [85, 86], [87, 92], [93, 100], [100, 101], [102, 108], [109, 113], [114, 117], [118, 123], [124, 130], [131, 134], [135, 140], [140, 141], [141, 145], [146, 149], [150, 155], [155, 156], [156, 160], [161, 170], [171, 176], [177, 187], [188, 191], [192, 200], [201, 204], [205, 216], [217, 225], [226, 233], [234, 240], [240, 241]]}
{"doc_key": "ai-dev-303", "ner": [[0, 3, "misc"], [4, 4, "misc"], [15, 16, "person"], [18, 20, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 0, 3, "general-affiliation", "", false, false], [4, 4, 15, 16, "artifact", "", false, false], [4, 4, 18, 20, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "science", "fiction", "drama", "Sense8", "premiered", "in", "June", "2015", "and", "was", "written", "and", "produced", "by", "The", "Wachowskis", "and", "J.", "Michael", "Straczynski", "."], "sentence-detokenized": "The science fiction drama Sense8 premiered in June 2015 and was written and produced by The Wachowskis and J. Michael Straczynski.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 25], [26, 32], [33, 42], [43, 45], [46, 50], [51, 55], [56, 59], [60, 63], [64, 71], [72, 75], [76, 84], [85, 87], [88, 91], [92, 102], [103, 106], [107, 109], [110, 117], [118, 129], [129, 130]]}
{"doc_key": "ai-dev-304", "ner": [[0, 0, "misc"], [5, 6, "product"], [26, 28, "misc"], [36, 36, "country"], [38, 38, "country"], [40, 40, "country"], [42, 42, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 6, "topic", "", false, false], [36, 36, 26, 28, "type-of", "", false, false], [38, 38, 26, 28, "type-of", "", false, false], [40, 40, 26, 28, "type-of", "", false, false], [42, 42, 26, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Eurotra", "never", "delivered", "a", "working", "MT", "system", ",", "but", "the", "project", "had", "a", "far", "-", "reaching", "long", "-", "term", "impact", "on", "the", "nascent", "language", "industries", "in", "European", "Member", "States", ",", "particularly", "in", "the", "southern", "countries", "of", "Greece", ",", "Italy", ",", "Spain", "and", "Portugal", "."], "sentence-detokenized": "Eurotra never delivered a working MT system, but the project had a far-reaching long-term impact on the nascent language industries in European Member States, particularly in the southern countries of Greece, Italy, Spain and Portugal.", "token2charspan": [[0, 7], [8, 13], [14, 23], [24, 25], [26, 33], [34, 36], [37, 43], [43, 44], [45, 48], [49, 52], [53, 60], [61, 64], [65, 66], [67, 70], [70, 71], [71, 79], [80, 84], [84, 85], [85, 89], [90, 96], [97, 99], [100, 103], [104, 111], [112, 120], [121, 131], [132, 134], [135, 143], [144, 150], [151, 157], [157, 158], [159, 171], [172, 174], [175, 178], [179, 187], [188, 197], [198, 200], [201, 207], [207, 208], [209, 214], [214, 215], [216, 221], [222, 225], [226, 234], [234, 235]]}
{"doc_key": "ai-dev-305", "ner": [[0, 0, "algorithm"], [7, 9, "task"], [19, 21, "task"], [23, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 9, 0, 0, "usage", "", true, false], [19, 21, 7, 9, "named", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoder", "has", "been", "successfully", "applied", "to", "the", "machine", "translation", "of", "human", "languages", ",", "which", "is", "commonly", "referred", "to", "as", "neural", "machine", "translation", "(", "NMT", ")", "."], "sentence-detokenized": "Autoencoder has been successfully applied to the machine translation of human languages, which is commonly referred to as neural machine translation (NMT).", "token2charspan": [[0, 11], [12, 15], [16, 20], [21, 33], [34, 41], [42, 44], [45, 48], [49, 56], [57, 68], [69, 71], [72, 77], [78, 87], [87, 88], [89, 94], [95, 97], [98, 106], [107, 115], [116, 118], [119, 121], [122, 128], [129, 136], [137, 148], [149, 150], [150, 153], [153, 154], [154, 155]]}
{"doc_key": "ai-dev-306", "ner": [[9, 11, "metrics"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "examples", "of", "fitness", "functions", "based", "on", "probabilities", "are", "maximum", "likelihood", "estimation", "and", "hinge", "loss", "."], "sentence-detokenized": "Popular examples of fitness functions based on probabilities are maximum likelihood estimation and hinge loss.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 37], [38, 43], [44, 46], [47, 60], [61, 64], [65, 72], [73, 83], [84, 94], [95, 98], [99, 104], [105, 109], [109, 110]]}
{"doc_key": "ai-dev-307", "ner": [[0, 3, "field"], [11, 13, "task"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 13, 0, 3, "part-of", "", false, false], [15, 16, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "mining", "is", "a", "related", "field", "of", "study", "that", "focuses", "on", "exploratory", "data", "analysis", "through", "unsupervised", "learning", "."], "sentence-detokenized": "Data mining is a related field of study that focuses on exploratory data analysis through unsupervised learning.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 33], [34, 39], [40, 44], [45, 52], [53, 55], [56, 67], [68, 72], [73, 81], [82, 89], [90, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-dev-308", "ner": [[0, 1, "algorithm"], [13, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 15, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "involves", "techniques", "for", "matching", "people", "with", "similar", "interests", "and", "creating", "a", "recommendation", "system", "on", "this", "basis", "."], "sentence-detokenized": "Collaborative filtering involves techniques for matching people with similar interests and creating a recommendation system on this basis.", "token2charspan": [[0, 13], [14, 23], [24, 32], [33, 43], [44, 47], [48, 56], [57, 63], [64, 68], [69, 76], [77, 86], [87, 90], [91, 99], [100, 101], [102, 116], [117, 123], [124, 126], [127, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-dev-309", "ner": [[3, 8, "algorithm"], [16, 19, "product"]], "ner_mapping_to_source": [0, 2], "relations": [[16, 19, 3, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "number", "of", "WordNet", "-", "based", "word", "similarity", "algorithms", "are", "implemented", "in", "a", "Perl", "package", "called", "WordNet", ":", ":", "Similarity", "."], "sentence-detokenized": "A number of WordNet-based word similarity algorithms are implemented in a Perl package called WordNet:: Similarity.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 19], [19, 20], [20, 25], [26, 30], [31, 41], [42, 52], [53, 56], [57, 68], [69, 71], [72, 73], [74, 78], [79, 86], [87, 93], [94, 101], [101, 102], [102, 103], [104, 114], [114, 115]]}
{"doc_key": "ai-dev-310", "ner": [[4, 4, "conference"], [6, 6, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 4, 4, "named", "", false, false], [10, 11, 4, 4, "temporal", "", false, false], [13, 14, 4, 4, "temporal", "", false, false], [16, 17, 4, 4, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Another", "paper", "presented", "at", "CVPR", "(", "CVPR", ")", "2000", "by", "Erik", "Miller", ",", "Nicholas", "Matsakis", "and", "Paul", "Viola", "will", "also", "be", "discussed", "."], "sentence-detokenized": "Another paper presented at CVPR (CVPR) 2000 by Erik Miller, Nicholas Matsakis and Paul Viola will also be discussed.", "token2charspan": [[0, 7], [8, 13], [14, 23], [24, 26], [27, 31], [32, 33], [33, 37], [37, 38], [39, 43], [44, 46], [47, 51], [52, 58], [58, 59], [60, 68], [69, 77], [78, 81], [82, 86], [87, 92], [93, 97], [98, 102], [103, 105], [106, 115], [115, 116]]}
{"doc_key": "ai-dev-311", "ner": [[0, 0, "algorithm"], [8, 9, "misc"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 15, "compare", "", false, false], [14, 15, 8, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["QC", "has", "not", "been", "evaluated", "against", "traditional", "modern", "clustering", "algorithms", ",", "apart", "from", "the", "Jaccard", "index", "."], "sentence-detokenized": "QC has not been evaluated against traditional modern clustering algorithms, apart from the Jaccard index.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 15], [16, 25], [26, 33], [34, 45], [46, 52], [53, 63], [64, 74], [74, 75], [76, 81], [82, 86], [87, 90], [91, 98], [99, 104], [104, 105]]}
{"doc_key": "ai-dev-312", "ner": [[2, 5, "misc"], [8, 10, "misc"], [14, 16, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 2, 5, "physical", "", false, false], [8, 10, 14, 16, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "the", "VEX", "Robotics", "World", "Championships", ",", "a", "Parade", "of", "Nations", "is", "held", "in", "Freedom", "Hall", "with", "hundreds", "of", "students", "from", "more", "than", "30", "countries", "."], "sentence-detokenized": "During the VEX Robotics World Championships, a Parade of Nations is held in Freedom Hall with hundreds of students from more than 30 countries.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 23], [24, 29], [30, 43], [43, 44], [45, 46], [47, 53], [54, 56], [57, 64], [65, 67], [68, 72], [73, 75], [76, 83], [84, 88], [89, 93], [94, 102], [103, 105], [106, 114], [115, 119], [120, 124], [125, 129], [130, 132], [133, 142], [142, 143]]}
{"doc_key": "ai-dev-313", "ner": [[5, 8, "metrics"], [10, 10, "metrics"], [13, 15, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 5, 8, "named", "", false, false], [17, 17, 13, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Other", "measures", "of", "accuracy", "are", "Single", "Word", "Error", "Rate", "(", "SWER", ")", "and", "Command", "Success", "Rate", "(", "CSR", ")", "."], "sentence-detokenized": "Other measures of accuracy are Single Word Error Rate (SWER) and Command Success Rate (CSR).", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [27, 30], [31, 37], [38, 42], [43, 48], [49, 53], [54, 55], [55, 59], [59, 60], [61, 64], [65, 72], [73, 80], [81, 85], [86, 87], [87, 90], [90, 91], [91, 92]]}
{"doc_key": "ai-dev-314", "ner": [[7, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "presented", "their", "method", "and", "results", "in", "SIGGRAPH", "2000", "."], "sentence-detokenized": "They presented their method and results in SIGGRAPH 2000.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 27], [28, 31], [32, 39], [40, 42], [43, 51], [52, 56], [56, 57]]}
{"doc_key": "ai-dev-315", "ner": [[0, 2, "conference"], [7, 11, "misc"], [18, 19, "conference"], [23, 28, "researcher"], [37, 38, "researcher"], [42, 44, "conference"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "KDD", "conference", "grew", "out", "of", "the", "Knowledge", "Discovery", "and", "Data", "Mining", "(", "KDD", ")", "workshops", "at", "the", "AAAI", "conferences", ",", "started", "by", "Gregory", "I", ".", "Piatetsky", "-", "Shapiro", "in", "1989", ",", "1991", "and", "1993", ",", "and", "Usama", "Fayyad", "in", "1994", ".", "Machinery", "|", "ACM", "."], "sentence-detokenized": "The KDD conference grew out of the Knowledge Discovery and Data Mining (KDD) workshops at the AAAI conferences, started by Gregory I. Piatetsky-Shapiro in 1989, 1991 and 1993, and Usama Fayyad in 1994. Machinery | ACM.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 23], [24, 27], [28, 30], [31, 34], [35, 44], [45, 54], [55, 58], [59, 63], [64, 70], [71, 72], [72, 75], [75, 76], [77, 86], [87, 89], [90, 93], [94, 98], [99, 110], [110, 111], [112, 119], [120, 122], [123, 130], [131, 132], [132, 133], [134, 143], [143, 144], [144, 151], [152, 154], [155, 159], [159, 160], [161, 165], [166, 169], [170, 174], [174, 175], [176, 179], [180, 185], [186, 192], [193, 195], [196, 200], [200, 201], [202, 211], [212, 213], [214, 217], [217, 218]]}
{"doc_key": "ai-dev-316", "ner": [[8, 11, "conference"], [13, 13, "conference"], [17, 22, "organisation"], [24, 24, "organisation"], [28, 32, "conference"], [34, 34, "conference"], [38, 44, "conference"], [46, 46, "conference"], [50, 55, "conference"], [57, 57, "conference"], [61, 66, "conference"], [68, 68, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[13, 13, 8, 11, "named", "", false, false], [24, 24, 17, 22, "named", "", false, false], [34, 34, 28, 32, "named", "", false, false], [46, 46, 38, 44, "named", "", false, false], [57, 57, 50, 55, "named", "", false, false], [68, 68, 61, 66, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "has", "been", "elected", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "the", "American", "Association", "for", "Advancement", "of", "Science", "(", "AAAS", ")", "and", "the", "Society", "for", "Optics", "and", "Photonics", "Technology", "(", "SPIE", ")", "."], "sentence-detokenized": "He has been elected a member of the Association for Computing Machinery (ACM), the Institute of Electrical and Electronics Engineers (IEEE), the International Association for Pattern Recognition (IAPR), the Association for the Advancement of Artificial Intelligence (AAAI), the American Association for Advancement of Science (AAAS) and the Society for Optics and Photonics Technology (SPIE).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 21], [22, 28], [29, 31], [32, 35], [36, 47], [48, 51], [52, 61], [62, 71], [72, 73], [73, 76], [76, 77], [77, 78], [79, 82], [83, 92], [93, 95], [96, 106], [107, 110], [111, 122], [123, 132], [133, 134], [134, 138], [138, 139], [139, 140], [141, 144], [145, 158], [159, 170], [171, 174], [175, 182], [183, 194], [195, 196], [196, 200], [200, 201], [201, 202], [203, 206], [207, 218], [219, 222], [223, 226], [227, 238], [239, 241], [242, 252], [253, 265], [266, 267], [267, 271], [271, 272], [272, 273], [274, 277], [278, 286], [287, 298], [299, 302], [303, 314], [315, 317], [318, 325], [326, 327], [327, 331], [331, 332], [333, 336], [337, 340], [341, 348], [349, 352], [353, 359], [360, 363], [364, 373], [374, 384], [385, 386], [386, 390], [390, 391], [391, 392]]}
{"doc_key": "ai-dev-317", "ner": [[0, 1, "field"], [3, 4, "field"], [19, 20, "field"], [34, 35, "field"], [55, 58, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 19, 20, "named", "", false, false], [3, 4, 34, 35, "named", "", false, false], [34, 35, 55, 58, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "and", "data", "mining", "often", "use", "the", "same", "methods", "and", "overlap", "to", "a", "large", "extent", ",", "but", "while", "machine", "learning", "focuses", "on", "predictions", ",", "based", "on", "known", "properties", "learned", "from", "training", "data", ",", "data", "mining", "focuses", "on", "the", "discovery", "of", "(", "previously", ")", "unknown", "properties", "in", "data", "(", "this", "is", "the", "analysis", "step", "for", "knowledge", "discovery", "in", "databases", ")", "."], "sentence-detokenized": "Machine learning and data mining often use the same methods and overlap to a large extent, but while machine learning focuses on predictions, based on known properties learned from training data, data mining focuses on the discovery of (previously) unknown properties in data (this is the analysis step for knowledge discovery in databases).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 59], [60, 63], [64, 71], [72, 74], [75, 76], [77, 82], [83, 89], [89, 90], [91, 94], [95, 100], [101, 108], [109, 117], [118, 125], [126, 128], [129, 140], [140, 141], [142, 147], [148, 150], [151, 156], [157, 167], [168, 175], [176, 180], [181, 189], [190, 194], [194, 195], [196, 200], [201, 207], [208, 215], [216, 218], [219, 222], [223, 232], [233, 235], [236, 237], [237, 247], [247, 248], [249, 256], [257, 267], [268, 270], [271, 275], [276, 277], [277, 281], [282, 284], [285, 288], [289, 297], [298, 302], [303, 306], [307, 316], [317, 326], [327, 329], [330, 339], [339, 340], [340, 341]]}
{"doc_key": "ai-dev-318", "ner": [[0, 0, "product"], [4, 5, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 5, "general-affiliation", "", false, false], [0, 0, 4, 5, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "is", "written", "in", "Java", "and", "can", "therefore", "run", "on", "most", "modern", "operating", "systems", "."], "sentence-detokenized": "Indy is written in Java and can therefore run on most modern operating systems.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 23], [24, 27], [28, 31], [32, 41], [42, 45], [46, 48], [49, 53], [54, 60], [61, 70], [71, 78], [78, 79]]}
{"doc_key": "ai-dev-319", "ner": [[0, 2, "algorithm"], [5, 7, "algorithm"], [9, 9, "algorithm"], [15, 17, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 7, "type-of", "", true, false], [9, 9, 5, 7, "named", "", false, false], [15, 17, 5, 7, "type-of", "", true, false], [19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["NMF", "is", "an", "example", "of", "nonnegative", "quadratic", "programming", "(", "NQP", ")", ",", "as", "is", "the", "support", "vector", "machine", "(", "SVM", ")", "."], "sentence-detokenized": "NMF is an example of nonnegative quadratic programming (NQP), as is the support vector machine (SVM).", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 17], [18, 20], [21, 32], [33, 42], [43, 54], [55, 56], [56, 59], [59, 60], [60, 61], [62, 64], [65, 67], [68, 71], [72, 79], [80, 86], [87, 94], [95, 96], [96, 99], [99, 100], [100, 101]]}
{"doc_key": "ai-dev-320", "ner": [[7, 8, "misc"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 11, 12, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "methodology", "is", "based", "on", "estimating", "the", "conditional", "probabilities", "using", "the", "non-parametric", "maximum", "likelihood", "method", "which", "leads", "to"], "sentence-detokenized": "The methodology is based on estimating the conditional probabilities using the non-parametric maximum likelihood method which leads to", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 24], [25, 27], [28, 38], [39, 42], [43, 54], [55, 68], [69, 74], [75, 78], [79, 93], [94, 101], [102, 112], [113, 119], [120, 125], [126, 131], [132, 134]]}
{"doc_key": "ai-dev-321", "ner": [[8, 8, "algorithm"], [10, 13, "algorithm"], [15, 17, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "basic", "concepts", "involved", "in", "spectral", "estimation", "are", "autocorrelation", ",", "multi", "-D", "Fourier", "transform", ",", "mean", "squared", "error", "and", "entropy", "."], "sentence-detokenized": "The basic concepts involved in spectral estimation are autocorrelation, multi-D Fourier transform, mean squared error and entropy.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 27], [28, 30], [31, 39], [40, 50], [51, 54], [55, 70], [70, 71], [72, 77], [77, 79], [80, 87], [88, 97], [97, 98], [99, 103], [104, 111], [112, 117], [118, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-dev-322", "ner": [[0, 3, "algorithm"], [9, 9, "field"], [11, 11, "algorithm"], [13, 15, "algorithm"], [17, 18, "task"], [20, 20, "field"], [22, 22, "field"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 3, 9, 9, "part-of", "", false, false], [0, 3, 11, 11, "part-of", "", false, false], [0, 3, 13, 15, "part-of", "", false, false], [0, 3, 17, 18, "part-of", "", false, false], [0, 3, 20, 20, "part-of", "", false, false], [0, 3, 22, 22, "part-of", "", false, false], [0, 3, 24, 25, "part-of", "", false, false], [0, 3, 27, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "core", "methods", "have", "many", "different", "applications", ",", "including", "geostatistics", ",", "kriging", ",", "inverse", "distance", "weighting", ",", "3D", "reconstruction", ",", "bioinformatics", ",", "chemoinformatics", ",", "information", "retrieval", "and", "handwriting", "recognition", "."], "sentence-detokenized": "The core methods have many different applications, including geostatistics, kriging, inverse distance weighting, 3D reconstruction, bioinformatics, chemoinformatics, information retrieval and handwriting recognition.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 21], [22, 26], [27, 36], [37, 49], [49, 50], [51, 60], [61, 74], [74, 75], [76, 83], [83, 84], [85, 92], [93, 101], [102, 111], [111, 112], [113, 115], [116, 130], [130, 131], [132, 146], [146, 147], [148, 164], [164, 165], [166, 177], [178, 187], [188, 191], [192, 203], [204, 215], [215, 216]]}
{"doc_key": "ai-dev-323", "ner": [[13, 17, "product"], [19, 19, "product"], [22, 22, "organisation"], [24, 28, "product"], [30, 30, "product"], [36, 36, "product"], [40, 42, "product"], [44, 46, "product"], [50, 52, "product"], [54, 55, "product"], [57, 63, "product"], [66, 68, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13], "relations": [[13, 17, 36, 36, "compare", "", false, false], [13, 17, 40, 42, "compare", "", false, false], [13, 17, 44, 46, "compare", "", false, false], [13, 17, 50, 52, "compare", "", false, false], [13, 17, 54, 55, "compare", "", false, false], [13, 17, 57, 63, "compare", "", false, false], [13, 17, 66, 68, "compare", "", false, false], [19, 19, 13, 17, "named", "", false, false], [24, 28, 22, 22, "artifact", "", false, false], [24, 28, 36, 36, "compare", "", false, false], [24, 28, 40, 42, "compare", "", false, false], [24, 28, 44, 46, "compare", "", false, false], [24, 28, 50, 52, "compare", "", false, false], [24, 28, 54, 55, "compare", "", false, false], [24, 28, 57, 63, "compare", "", false, false], [24, 28, 66, 68, "compare", "", false, false], [30, 30, 24, 28, "named", "", false, false]], "relations_mapping_to_source": [2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Robots", "can", "be", "autonomous", "or", "semi-autonomous", "and", "range", "from", "humanoids", "like", "Honda", "'s", "Advanced", "Step", "in", "Innovative", "Mobility", "(", "ASIMO", ")", "and", "TOSY", "'s", "TOSY", "Ping", "Pong", "Playing", "Robot", "(", "TOPIO", ")", "to", "industrial", "robots", ",", "medical", "operating", "robots", ",", "patient", "assistance", "robots", ",", "canine", "therapy", "robots", ",", "collectively", "programmed", "swarms", "of", "robots", ",", "UAV", "robots", "like", "General", "Atomic", "'s", "MQ", "-", "1", "Predator", "and", "even", "microscopic", "nano", "robots", "."], "sentence-detokenized": "Robots can be autonomous or semi-autonomous and range from humanoids like Honda's Advanced Step in Innovative Mobility (ASIMO) and TOSY's TOSY Ping Pong Playing Robot (TOPIO) to industrial robots, medical operating robots, patient assistance robots, canine therapy robots, collectively programmed swarms of robots, UAV robots like General Atomic's MQ-1 Predator and even microscopic nano robots.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 24], [25, 27], [28, 43], [44, 47], [48, 53], [54, 58], [59, 68], [69, 73], [74, 79], [79, 81], [82, 90], [91, 95], [96, 98], [99, 109], [110, 118], [119, 120], [120, 125], [125, 126], [127, 130], [131, 135], [135, 137], [138, 142], [143, 147], [148, 152], [153, 160], [161, 166], [167, 168], [168, 173], [173, 174], [175, 177], [178, 188], [189, 195], [195, 196], [197, 204], [205, 214], [215, 221], [221, 222], [223, 230], [231, 241], [242, 248], [248, 249], [250, 256], [257, 264], [265, 271], [271, 272], [273, 285], [286, 296], [297, 303], [304, 306], [307, 313], [313, 314], [315, 318], [319, 325], [326, 330], [331, 338], [339, 345], [345, 347], [348, 350], [350, 351], [351, 352], [353, 361], [362, 365], [366, 370], [371, 382], [383, 387], [388, 394], [394, 395]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 3, "product"], [21, 26, "university"], [8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 8, 9, "artifact", "", false, false], [0, 0, 11, 12, "artifact", "", false, false], [0, 0, 14, 15, "artifact", "", false, false], [0, 0, 17, 18, "artifact", "", false, false], [2, 3, 8, 9, "artifact", "", false, false], [2, 3, 11, 12, "artifact", "", false, false], [2, 3, 14, 15, "artifact", "", false, false], [2, 3, 17, 18, "artifact", "", false, false], [8, 9, 21, 26, "physical", "", false, false], [11, 12, 21, 26, "physical", "", false, false], [14, 15, 21, 26, "physical", "", false, false], [17, 18, 21, 26, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "and", "Freddy", "II", "were", "robots", "built", "by", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "and", "Donald", "Mitchie", "at", "the", "University", "of", "Edinburgh", "School", "of", "Informatics", "that", "could", "assemble", "wooden", "blocks", "in", "hours", "."], "sentence-detokenized": "Freddy and Freddy II were robots built by Pat Ambler, Robin Popplestone, Austin Tate and Donald Mitchie at the University of Edinburgh School of Informatics that could assemble wooden blocks in hours.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 25], [26, 32], [33, 38], [39, 41], [42, 45], [46, 52], [52, 53], [54, 59], [60, 71], [71, 72], [73, 79], [80, 84], [85, 88], [89, 95], [96, 103], [104, 106], [107, 110], [111, 121], [122, 124], [125, 134], [135, 141], [142, 144], [145, 156], [157, 161], [162, 167], [168, 176], [177, 183], [184, 190], [191, 193], [194, 199], [199, 200]]}
{"doc_key": "ai-dev-325", "ner": [[5, 5, "location"], [7, 7, "country"], [15, 15, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 7, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "spent", "his", "childhood", "in", "Paris", ",", "France", ",", "where", "his", "parents", "had", "emigrated", "from", "Lithuania", "in", "the", "early", "1920s", "."], "sentence-detokenized": "He spent his childhood in Paris, France, where his parents had emigrated from Lithuania in the early 1920s.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 22], [23, 25], [26, 31], [31, 32], [33, 39], [39, 40], [41, 46], [47, 50], [51, 58], [59, 62], [63, 72], [73, 77], [78, 87], [88, 90], [91, 94], [95, 100], [101, 106], [106, 107]]}
{"doc_key": "ai-dev-326", "ner": [[0, 0, "researcher"], [4, 8, "misc"], [11, 14, "organisation"], [16, 18, "university"], [28, 32, "university"], [38, 39, "university"], [43, 45, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 4, 8, "role", "", false, false], [0, 0, 16, 18, "physical", "", false, false], [0, 0, 28, 32, "role", "", false, false], [0, 0, 38, 39, "role", "", false, false], [0, 0, 43, 45, "role", "", false, false], [4, 8, 11, 14, "part-of", "", false, false], [11, 14, 16, 18, "part-of", "", false, false], [38, 39, 28, 32, "part-of", "", false, false], [43, 45, 28, 32, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Paulos", "previously", "held", "the", "Cooper-", "Siegel", "Associate", "Professor", "Chair", "in", "the", "School", "of", "Computer", "Science", "at", "Carnegie", "Mellon", "University", ",", "where", "he", "was", "a", "faculty", "member", "in", "the", "Human", "-", "Computer", "Interaction", "Institute", "with", "honorary", "appointments", "in", "the", "Robotics", "Institute", "and", "in", "the", "Entertainment", "Technology", "Center", "."], "sentence-detokenized": "Paulos previously held the Cooper-Siegel Associate Professor Chair in the School of Computer Science at Carnegie Mellon University, where he was a faculty member in the Human-Computer Interaction Institute with honorary appointments in the Robotics Institute and in the Entertainment Technology Center.", "token2charspan": [[0, 6], [7, 17], [18, 22], [23, 26], [27, 34], [34, 40], [41, 50], [51, 60], [61, 66], [67, 69], [70, 73], [74, 80], [81, 83], [84, 92], [93, 100], [101, 103], [104, 112], [113, 119], [120, 130], [130, 131], [132, 137], [138, 140], [141, 144], [145, 146], [147, 154], [155, 161], [162, 164], [165, 168], [169, 174], [174, 175], [175, 183], [184, 195], [196, 205], [206, 210], [211, 219], [220, 232], [233, 235], [236, 239], [240, 248], [249, 258], [259, 262], [263, 265], [266, 269], [270, 283], [284, 294], [295, 301], [301, 302]]}
{"doc_key": "ai-dev-327", "ner": [[3, 4, "researcher"], [6, 7, "university"], [10, 13, "product"], [18, 22, "product"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 6, 7, "physical", "", false, false], [3, 4, 6, 7, "role", "", false, false], [10, 13, 3, 4, "artifact", "", false, false], [10, 13, 18, 22, "type-of", "", false, false], [10, 13, 27, 28, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1969", ",", "Victor", "Scheinman", "of", "Stanford", "University", "invented", "the", "Stanford", "Arm", ",", "an", "all", "-", "electric", ",", "6", "-", "axis", "articulated", "robot", "designed", "to", "enable", "an", "arm", "solution", "."], "sentence-detokenized": "In 1969, Victor Scheinman of Stanford University invented the Stanford Arm, an all-electric, 6-axis articulated robot designed to enable an arm solution.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 25], [26, 28], [29, 37], [38, 48], [49, 57], [58, 61], [62, 70], [71, 74], [74, 75], [76, 78], [79, 82], [82, 83], [83, 91], [91, 92], [93, 94], [94, 95], [95, 99], [100, 111], [112, 117], [118, 126], [127, 129], [130, 136], [137, 139], [140, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-dev-328", "ner": [[5, 5, "product"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 14, 15, "related-to", "", false, false], [5, 5, 17, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "creation", "and", "deployment", "of", "chatbots", "is", "still", "a", "developing", "area", "strongly", "linked", "to", "artificial", "intelligence", "and", "machine", "learning", ",", "so", "although", "the", "solutions", "provided", "have", "obvious", "advantages", ",", "they", "have", "some", "limitations", "in", "terms", "of", "functionality", "and", "use", "cases", "."], "sentence-detokenized": "The creation and deployment of chatbots is still a developing area strongly linked to artificial intelligence and machine learning, so although the solutions provided have obvious advantages, they have some limitations in terms of functionality and use cases.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 27], [28, 30], [31, 39], [40, 42], [43, 48], [49, 50], [51, 61], [62, 66], [67, 75], [76, 82], [83, 85], [86, 96], [97, 109], [110, 113], [114, 121], [122, 130], [130, 131], [132, 134], [135, 143], [144, 147], [148, 157], [158, 166], [167, 171], [172, 179], [180, 190], [190, 191], [192, 196], [197, 201], [202, 206], [207, 218], [219, 221], [222, 227], [228, 230], [231, 244], [245, 248], [249, 252], [253, 258], [258, 259]]}
{"doc_key": "ai-dev-329", "ner": [[7, 8, "university"], [11, 13, "product"], [22, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 13, 7, 8, "part-of", "", true, false], [22, 23, 11, 13, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "terms", "of", "freely", "available", "resources", ",", "Carnegie", "Mellon", "University", "'s", "Sphinx", "toolkit", "is", "a", "good", "starting", "point", "to", "learn", "more", "about", "speech", "recognition", "and", "start", "experimenting", "."], "sentence-detokenized": "In terms of freely available resources, Carnegie Mellon University's Sphinx toolkit is a good starting point to learn more about speech recognition and start experimenting.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 18], [19, 28], [29, 38], [38, 39], [40, 48], [49, 55], [56, 66], [66, 68], [69, 75], [76, 83], [84, 86], [87, 88], [89, 93], [94, 102], [103, 108], [109, 111], [112, 117], [118, 122], [123, 128], [129, 135], [136, 147], [148, 151], [152, 157], [158, 171], [171, 172]]}
{"doc_key": "ai-dev-330", "ner": [[2, 3, "misc"], [13, 19, "misc"], [21, 21, "misc"], [26, 26, "university"], [28, 28, "location"], [30, 30, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 13, 19, "temporal", "", false, false], [21, 21, 13, 19, "named", "", false, false], [21, 21, 28, 28, "physical", "", false, false], [26, 26, 21, 21, "role", "", false, false], [28, 28, 30, 30, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "formal", "RoboCup", "competition", "was", "preceded", "by", "the", "(", "often", "overlooked", ")", "first", "international", "Micro", "Robot", "World", "Cup", "Soccer", "Tournament", "(", "MIROSOT", ")", ",", "hosted", "by", "KAIST", "in", "Taejon", ",", "Korea", ",", "in", "November", "1996", "."], "sentence-detokenized": "The formal RoboCup competition was preceded by the (often overlooked) first international Micro Robot World Cup Soccer Tournament (MIROSOT), hosted by KAIST in Taejon, Korea, in November 1996.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 30], [31, 34], [35, 43], [44, 46], [47, 50], [51, 52], [52, 57], [58, 68], [68, 69], [70, 75], [76, 89], [90, 95], [96, 101], [102, 107], [108, 111], [112, 118], [119, 129], [130, 131], [131, 138], [138, 139], [139, 140], [141, 147], [148, 150], [151, 156], [157, 159], [160, 166], [166, 167], [168, 173], [173, 174], [175, 177], [178, 186], [187, 191], [191, 192]]}
{"doc_key": "ai-dev-331", "ner": [[7, 8, "metrics"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "usual", "calculation", "of", "hinge", "losses", "(", "1-", "yf", "(", "x", ")", ")", "_", "+", "/", "math", "for", "labeled", "data", ",", "a", "loss", "function", "math", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "math", "is", "introduced", "over", "the", "unlabeled", "data", "by", "letting", "mathy", "=\\", "operatorname", "{", "sign", "}", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "In addition to the usual calculation of hinge losses (1-yf (x)) _ + / math for labeled data, a loss function math (-1 | f (x) |) _ + / math is introduced over the unlabeled data by letting mathy =\\ operatorname {sign} {f (x)} / math.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 24], [25, 36], [37, 39], [40, 45], [46, 52], [53, 54], [54, 56], [56, 58], [59, 60], [60, 61], [61, 62], [62, 63], [64, 65], [66, 67], [68, 69], [70, 74], [75, 78], [79, 86], [87, 91], [91, 92], [93, 94], [95, 99], [100, 108], [109, 113], [114, 115], [115, 116], [116, 117], [118, 119], [120, 121], [122, 123], [123, 124], [124, 125], [126, 127], [127, 128], [129, 130], [131, 132], [133, 134], [135, 139], [140, 142], [143, 153], [154, 158], [159, 162], [163, 172], [173, 177], [178, 180], [181, 188], [189, 194], [195, 197], [198, 210], [211, 212], [212, 216], [216, 217], [218, 219], [219, 220], [221, 222], [222, 223], [223, 224], [224, 225], [226, 227], [228, 232], [232, 233]]}
{"doc_key": "ai-dev-332", "ner": [[0, 1, "misc"], [8, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "RLS", "is", "specifically", "designed", "to", "minimize", "the", "mean", "squared", "error", "between", "the", "predicted", "values", "and", "the", "actual", "labels", ",", "subject", "to", "regulation", "."], "sentence-detokenized": "The RLS is specifically designed to minimize the mean squared error between the predicted values and the actual labels, subject to regulation.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 23], [24, 32], [33, 35], [36, 44], [45, 48], [49, 53], [54, 61], [62, 67], [68, 75], [76, 79], [80, 89], [90, 96], [97, 100], [101, 104], [105, 111], [112, 118], [118, 119], [120, 127], [128, 130], [131, 141], [141, 142]]}
{"doc_key": "ai-dev-333", "ner": [[5, 7, "algorithm"], [10, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 10, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "essence", ",", "this", "combines", "maximum", "likelihood", "estimation", "with", "a", "regression", "procedure", "that", "favors", "simpler", "models", "over", "more", "complex", "models", "."], "sentence-detokenized": "In essence, this combines maximum likelihood estimation with a regression procedure that favors simpler models over more complex models.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [17, 25], [26, 33], [34, 44], [45, 55], [56, 60], [61, 62], [63, 73], [74, 83], [84, 88], [89, 95], [96, 103], [104, 110], [111, 115], [116, 120], [121, 128], [129, 135], [135, 136]]}
{"doc_key": "ai-dev-334", "ner": [[1, 3, "metrics"], [9, 9, "metrics"], [11, 11, "metrics"], [13, 14, "misc"], [16, 17, "misc"], [30, 32, "algorithm"], [35, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 9, 1, 3, "named", "", false, false], [11, 11, 1, 3, "named", "", false, false], [13, 14, 16, 17, "related-to", "", false, false], [13, 14, 30, 32, "related-to", "ratio", false, false], [30, 32, 35, 37, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "true", "positive", "rate", "is", "also", "known", "as", "the", "sensitivity", ",", "recall", "or", "detection", "probability", "(", "discrimination", "threshold", "matrix", ")", "of", "the", "detection", "probability", "on", "the", "y", "-axis", "versus", "the", "cumulative", "distribution", "function", "of", "the", "false", "alarm", "probability", "on", "the", "x-", "axis", "."], "sentence-detokenized": "The true positive rate is also known as the sensitivity, recall or detection probability (discrimination threshold matrix) of the detection probability on the y-axis versus the cumulative distribution function of the false alarm probability on the x-axis.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 25], [26, 30], [31, 36], [37, 39], [40, 43], [44, 55], [55, 56], [57, 63], [64, 66], [67, 76], [77, 88], [89, 90], [90, 104], [105, 114], [115, 121], [121, 122], [123, 125], [126, 129], [130, 139], [140, 151], [152, 154], [155, 158], [159, 160], [160, 165], [166, 172], [173, 176], [177, 187], [188, 200], [201, 209], [210, 212], [213, 216], [217, 222], [223, 228], [229, 240], [241, 243], [244, 247], [248, 250], [250, 254], [254, 255]]}
{"doc_key": "ai-dev-335", "ner": [[1, 1, "misc"], [3, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 1, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "English", ",", "Word", "Net", "is", "an", "example", "of", "a", "semantic", "network", "."], "sentence-detokenized": "In English, WordNet is an example of a semantic network.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [16, 19], [20, 22], [23, 25], [26, 33], [34, 36], [37, 38], [39, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-dev-336", "ner": [[3, 5, "product"], [8, 9, "product"], [27, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[27, 27, 3, 5, "usage", "", false, false], [27, 27, 8, 9, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolonged", "use", "of", "speech", "recognition", "software", "together", "with", "word", "processors", "has", "been", "shown", "to", "be", "beneficial", "in", "strengthening", "short", "-", "term", "memory", "in", "AVM", "patients", "in", "the", "brain", "treated", "with", "resection", "."], "sentence-detokenized": "Prolonged use of speech recognition software together with word processors has been shown to be beneficial in strengthening short-term memory in AVM patients in the brain treated with resection.", "token2charspan": [[0, 9], [10, 13], [14, 16], [17, 23], [24, 35], [36, 44], [45, 53], [54, 58], [59, 63], [64, 74], [75, 78], [79, 83], [84, 89], [90, 92], [93, 95], [96, 106], [107, 109], [110, 123], [124, 129], [129, 130], [130, 134], [135, 141], [142, 144], [145, 148], [149, 157], [158, 160], [161, 164], [165, 170], [171, 178], [179, 183], [184, 193], [193, 194]]}
{"doc_key": "ai-dev-337", "ner": [[8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Its", "founding", "editors", "-", "in", "-", "chief", "were", "Ron", "Sun", ",", "Vasant", "Honavar", "and", "Gregg", "Oden", "(", "from", "1999", "to", "2014", ")", "."], "sentence-detokenized": "Its founding editors-in-chief were Ron Sun, Vasant Honavar and Gregg Oden (from 1999 to 2014).", "token2charspan": [[0, 3], [4, 12], [13, 20], [20, 21], [21, 23], [23, 24], [24, 29], [30, 34], [35, 38], [39, 42], [42, 43], [44, 50], [51, 58], [59, 62], [63, 68], [69, 73], [74, 75], [75, 79], [80, 84], [85, 87], [88, 92], [92, 93], [93, 94]]}
{"doc_key": "ai-dev-338", "ner": [[8, 9, "product"], [13, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 13, 20, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "\"", "parallel", "\"", "difference", "compared", "to", "a", "serial", "manipulator", "is", "that", "the", "end", "(", "or", "\"", "hand", "\"", ")", "of", "this", "link", "(", "or", "\"", "arm", "\"", ")", "is", "directly", "connected", "to", "it", "s", "base", "by", "a", "number", "(", "usually", "three", "or", "six", ")", "of", "separate", "and", "independent", "links", "operating", "simultaneously", "."], "sentence-detokenized": "The \"parallel\" difference compared to a serial manipulator is that the end (or \"hand\") of this link (or \"arm\") is directly connected to its base by a number (usually three or six) of separate and independent links operating simultaneously.", "token2charspan": [[0, 3], [4, 5], [5, 13], [13, 14], [15, 25], [26, 34], [35, 37], [38, 39], [40, 46], [47, 58], [59, 61], [62, 66], [67, 70], [71, 74], [75, 76], [76, 78], [79, 80], [80, 84], [84, 85], [85, 86], [87, 89], [90, 94], [95, 99], [100, 101], [101, 103], [104, 105], [105, 108], [108, 109], [109, 110], [111, 113], [114, 122], [123, 132], [133, 135], [136, 138], [138, 139], [140, 144], [145, 147], [148, 149], [150, 156], [157, 158], [158, 165], [166, 171], [172, 174], [175, 178], [178, 179], [180, 182], [183, 191], [192, 195], [196, 207], [208, 213], [214, 223], [224, 238], [238, 239]]}
{"doc_key": "ai-dev-339", "ner": [[5, 6, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "thesis", "advisor", "was", "Professor", "Cordell", "Green", ",", "and", "his", "thesis", "/", "oral", "committee", "consisted", "of", "Professors", "Edward", "Feigenbaum", ",", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", ",", "Herbert", "Simon", ",", "..."], "sentence-detokenized": "His thesis advisor was Professor Cordell Green, and his thesis/oral committee consisted of Professors Edward Feigenbaum, Joshua Lederberg, Paul Cohen, Allen Newell, Herbert Simon,...", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 22], [23, 32], [33, 40], [41, 46], [46, 47], [48, 51], [52, 55], [56, 62], [62, 63], [63, 67], [68, 77], [78, 87], [88, 90], [91, 101], [102, 108], [109, 119], [119, 120], [121, 127], [128, 137], [137, 138], [139, 143], [144, 149], [149, 150], [151, 156], [157, 163], [163, 164], [165, 172], [173, 178], [178, 179], [179, 182]]}
{"doc_key": "ai-dev-340", "ner": [[3, 5, "metrics"], [7, 10, "metrics"], [12, 14, "metrics"], [16, 18, "metrics"], [20, 23, "metrics"], [25, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "functions", "include", "mean", "square", "error", ",", "root", "mean", "square", "error", ",", "absolute", "mean", "error", ",", "relative", "squared", "error", ",", "root", "relative", "squared", "error", ",", "relative", "absolute", "error", ",", "etc", "."], "sentence-detokenized": "Such functions include mean square error, root mean square error, absolute mean error, relative squared error, root relative squared error, relative absolute error, etc.", "token2charspan": [[0, 4], [5, 14], [15, 22], [23, 27], [28, 34], [35, 40], [40, 41], [42, 46], [47, 51], [52, 58], [59, 64], [64, 65], [66, 74], [75, 79], [80, 85], [85, 86], [87, 95], [96, 103], [104, 109], [109, 110], [111, 115], [116, 124], [125, 132], [133, 138], [138, 139], [140, 148], [149, 157], [158, 163], [163, 164], [165, 168], [168, 169]]}
{"doc_key": "ai-dev-341", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "bindings", "in", "Python", ",", "Java", "and", "MATLAB", "/", "OCTAVE", "."], "sentence-detokenized": "There are bindings in Python, Java and MATLAB / OCTAVE.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 21], [22, 28], [28, 29], [30, 34], [35, 38], [39, 45], [46, 47], [48, 54], [54, 55]]}
{"doc_key": "ai-dev-342", "ner": [[3, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "implementation", "in", "MATLAB", "is", "available", "on", "the", "website", "."], "sentence-detokenized": "An implementation in MATLAB is available on the website.", "token2charspan": [[0, 2], [3, 17], [18, 20], [21, 27], [28, 30], [31, 40], [41, 43], [44, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-dev-343", "ner": [[0, 2, "researcher"], [8, 9, "field"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 2, "origin", "", false, false], [8, 9, 13, 14, "origin", "", false, false], [8, 9, 16, 17, "origin", "", false, false], [8, 9, 19, 20, "origin", "", false, false], [8, 9, 22, 25, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "is", "one", "of", "the", "founders", "of", "artificial", "intelligence", ",", "along", "with", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", "and", "Herbert", "A", ".", "Simon", "."], "sentence-detokenized": "John McCarthy is one of the founders of artificial intelligence, along with Alan Turing, Marvin Minsky, Allen Newell and Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 36], [37, 39], [40, 50], [51, 63], [63, 64], [65, 70], [71, 75], [76, 80], [81, 87], [87, 88], [89, 95], [96, 102], [102, 103], [104, 109], [110, 116], [117, 120], [121, 128], [129, 130], [130, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-dev-344", "ner": [[10, 12, "product"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "parallel", "manipulator", "is", "a", "mechanical", "system", "that", "uses", "multiple", "serial", "manipulators", "to", "support", "a", "single", "platform", "or", "end", "function", "."], "sentence-detokenized": "A parallel manipulator is a mechanical system that uses multiple serial manipulators to support a single platform or end function.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 27], [28, 38], [39, 45], [46, 50], [51, 55], [56, 64], [65, 71], [72, 84], [85, 87], [88, 95], [96, 97], [98, 104], [105, 113], [114, 116], [117, 120], [121, 129], [129, 130]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [3, 4, "task"], [7, 7, "product"], [9, 15, "product"], [27, 27, "misc"], [30, 30, "misc"], [33, 34, "misc"], [37, 42, "task"], [45, 48, "product"], [51, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 7, 0, 0, "part-of", "", false, false], [7, 7, 3, 4, "type-of", "", false, false], [9, 15, 7, 7, "named", "", false, false], [27, 27, 7, 7, "part-of", "", false, false], [30, 30, 7, 7, "part-of", "", false, false], [33, 34, 7, 7, "part-of", "", false, false], [37, 42, 7, 7, "part-of", "", false, false], [45, 48, 7, 7, "part-of", "", false, false], [51, 52, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "contains", "an", "information", "extraction", "system", "called", "ANNIE", "(", "A", "Nearly", "-", "New", "Information", "Extraction", "System", ")", ",", "which", "is", "a", "set", "of", "modules", "consisting", "of", "a", "tokenizer", ",", "a", "gazetteer", ",", "a", "sentence", "splitter", ",", "a", "part", "-", "of", "-", "speech", "tagging", ",", "a", "named", "entity", "identification", "transducer", "and", "a", "coreference", "tagging", "."], "sentence-detokenized": "GATE contains an information extraction system called ANNIE (A Nearly-New Information Extraction System), which is a set of modules consisting of a tokenizer, a gazetteer, a sentence splitter, a part-of-speech tagging, a named entity identification transducer and a coreference tagging.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 28], [29, 39], [40, 46], [47, 53], [54, 59], [60, 61], [61, 62], [63, 69], [69, 70], [70, 73], [74, 85], [86, 96], [97, 103], [103, 104], [104, 105], [106, 111], [112, 114], [115, 116], [117, 120], [121, 123], [124, 131], [132, 142], [143, 145], [146, 147], [148, 157], [157, 158], [159, 160], [161, 170], [170, 171], [172, 173], [174, 182], [183, 191], [191, 192], [193, 194], [195, 199], [199, 200], [200, 202], [202, 203], [203, 209], [210, 217], [217, 218], [219, 220], [221, 226], [227, 233], [234, 248], [249, 259], [260, 263], [264, 265], [266, 277], [278, 285], [285, 286]]}
{"doc_key": "ai-dev-346", "ner": [[3, 5, "university"], [14, 15, "country"], [22, 25, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "graduated", "from", "Moscow", "State", "University", "and", "in", "November", "1978", "he", "went", "to", "the", "United", "States", "thanks", "to", "the", "personal", "intervention", "of", "Senator", "Edward", "M.", "Kennedy", "."], "sentence-detokenized": "He graduated from Moscow State University and in November 1978 he went to the United States thanks to the personal intervention of Senator Edward M. Kennedy.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 24], [25, 30], [31, 41], [42, 45], [46, 48], [49, 57], [58, 62], [63, 65], [66, 70], [71, 73], [74, 77], [78, 84], [85, 91], [92, 98], [99, 101], [102, 105], [106, 114], [115, 127], [128, 130], [131, 138], [139, 145], [146, 148], [149, 156], [156, 157]]}
{"doc_key": "ai-dev-347", "ner": [[4, 8, "organisation"], [9, 13, "misc"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 8, 9, 13, "win-defeat", "", false, false], [9, 13, 18, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "the", "DeepMind", "AlphaGo", "team", "received", "the", "inaugural", "IJCAI", "Marvin", "Minsky", "Medal", "for", "outstanding", "achievement", "in", "artificial", "intelligence", "."], "sentence-detokenized": "In 2017, the DeepMind AlphaGo team received the inaugural IJCAI Marvin Minsky Medal for outstanding achievement in artificial intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 21], [22, 29], [30, 34], [35, 43], [44, 47], [48, 57], [58, 63], [64, 70], [71, 77], [78, 83], [84, 87], [88, 99], [100, 111], [112, 114], [115, 125], [126, 138], [138, 139]]}
{"doc_key": "ai-dev-348", "ner": [[4, 5, "misc"], [8, 9, "misc"], [15, 15, "misc"], [25, 25, "misc"], [24, 30, "misc"], [36, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 8, 9, "related-to", "is_recorded_by", false, false], [8, 9, 15, 15, "cause-effect", "", false, false], [8, 9, 15, 15, "physical", "", false, false], [8, 9, 25, 25, "physical", "", false, false], [8, 9, 36, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "ways", "of", "detecting", "anomalous", "propagation", "are", "through", "tropospheric", "catheters", "that", "cause", "irregularities", "in", "the", "troposphere", ",", "scattering", "due", "to", "meteors", ",", "refraction", "in", "ionised", "regions", "and", "layers", "of", "the", "ionosphere", ",", "and", "reflection", "from", "the", "ionosphere", "."], "sentence-detokenized": "Other ways of detecting anomalous propagation are through tropospheric catheters that cause irregularities in the troposphere, scattering due to meteors, refraction in ionised regions and layers of the ionosphere, and reflection from the ionosphere.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 23], [24, 33], [34, 45], [46, 49], [50, 57], [58, 70], [71, 80], [81, 85], [86, 91], [92, 106], [107, 109], [110, 113], [114, 125], [125, 126], [127, 137], [138, 141], [142, 144], [145, 152], [152, 153], [154, 164], [165, 167], [168, 175], [176, 183], [184, 187], [188, 194], [195, 197], [198, 201], [202, 212], [212, 213], [214, 217], [218, 228], [229, 233], [234, 237], [238, 248], [248, 249]]}
{"doc_key": "ai-dev-349", "ner": [[0, 2, "field"], [4, 4, "field"], [10, 10, "field"], [12, 13, "field"], [15, 16, "field"], [18, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 10, 10, "part-of", "", false, false], [0, 2, 12, 13, "part-of", "", false, false], [0, 2, 15, 16, "part-of", "", false, false], [0, 2, 18, 23, "part-of", "", false, false], [4, 4, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Natural", "Language", "Processing", "(", "NLP", ")", "is", "a", "sub-field", "of", "linguistics", ",", "computer", "science", ",", "information", "technology", "and", "artificial", "intelligence", "that", "deals", "with", "the", "interaction", "between", "computers", "and", "human", "(", "natural", ")", "languages", ",", "in", "particular", "how", "to", "program", "computers", "to", "process", "and", "analyse", "large", "amounts", "of", "data", "from", "natural", "languages", "."], "sentence-detokenized": "Natural Language Processing (NLP) is a sub-field of linguistics, computer science, information technology and artificial intelligence that deals with the interaction between computers and human (natural) languages, in particular how to program computers to process and analyse large amounts of data from natural languages.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [29, 32], [32, 33], [34, 36], [37, 38], [39, 48], [49, 51], [52, 63], [63, 64], [65, 73], [74, 81], [81, 82], [83, 94], [95, 105], [106, 109], [110, 120], [121, 133], [134, 138], [139, 144], [145, 149], [150, 153], [154, 165], [166, 173], [174, 183], [184, 187], [188, 193], [194, 195], [195, 202], [202, 203], [204, 213], [213, 214], [215, 217], [218, 228], [229, 232], [233, 235], [236, 243], [244, 253], [254, 256], [257, 264], [265, 268], [269, 276], [277, 282], [283, 290], [291, 293], [294, 298], [299, 303], [304, 311], [312, 321], [321, 322]]}
{"doc_key": "ai-dev-350", "ner": [[8, 9, "organisation"], [11, 12, "organisation"], [14, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "active", "youth", "-", "led", "climate", "groups", "include", "Extinction", "Rebellion", ",", "Sunrise", "Movement", ",", "SustainUS", "and", "others", "working", "at", "both", "transnational", "and", "local", "levels", "."], "sentence-detokenized": "Other active youth-led climate groups include Extinction Rebellion, Sunrise Movement, SustainUS and others working at both transnational and local levels.", "token2charspan": [[0, 5], [6, 12], [13, 18], [18, 19], [19, 22], [23, 30], [31, 37], [38, 45], [46, 56], [57, 66], [66, 67], [68, 75], [76, 84], [84, 85], [86, 95], [96, 99], [100, 106], [107, 114], [115, 117], [118, 122], [123, 136], [137, 140], [141, 146], [147, 153], [153, 154]]}
