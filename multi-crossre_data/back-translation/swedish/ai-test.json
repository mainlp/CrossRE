{"doc_key": "ai-test-1", "ner": [[4, 6, "algorithm"], [8, 9, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "generative", "models", "are", "naive", "Bayes", "classifiers", ",", "Gaussian", "mixture", "models", ",", "variational", "autoencoders", "and", "others", "."], "sentence-detokenized": "Typical generative models are naive Bayes classifiers, Gaussian mixture models, variational autoencoders and others.", "token2charspan": [[0, 7], [8, 18], [19, 25], [26, 29], [30, 35], [36, 41], [42, 53], [53, 54], [55, 63], [64, 71], [72, 78], [78, 79], [80, 91], [92, 104], [105, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-2", "ner": [[5, 5, "organisation"], [11, 11, "conference"], [14, 19, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 11, 11, "role", "", false, false], [14, 19, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Finally", ",", "every", "two", "years", "ELRA", "organises", "a", "major", "conference", ",", "LREC", ",", "the", "International", "Language", "Resources", "and", "Evaluation", "Conference", "."], "sentence-detokenized": "Finally, every two years ELRA organises a major conference, LREC, the International Language Resources and Evaluation Conference.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 18], [19, 24], [25, 29], [30, 39], [40, 41], [42, 47], [48, 58], [58, 59], [60, 64], [64, 65], [66, 69], [70, 83], [84, 92], [93, 102], [103, 106], [107, 117], [118, 128], [128, 129]]}
{"doc_key": "ai-test-3", "ner": [[7, 16, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "task", "is", "usually", "to", "obtain", "an", "estimate", "of", "the", "parameters", "of", "the", "HMM", "with", "maximum", "likelihood", ",", "given", "the", "output", "sequences", "."], "sentence-detokenized": "The task is usually to obtain an estimate of the parameters of the HMM with maximum likelihood, given the output sequences.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 22], [23, 29], [30, 32], [33, 41], [42, 44], [45, 48], [49, 59], [60, 62], [63, 66], [67, 70], [71, 75], [76, 83], [84, 94], [94, 95], [96, 101], [102, 105], [106, 112], [113, 122], [122, 123]]}
{"doc_key": "ai-test-4", "ner": [[1, 1, "algorithm"], [4, 6, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Unlike", "neural", "networks", "and", "support", "vector", "machines", ",", "the", "AdaBoost", "training", "process", "selects", "only", "those", "features", "that", "are", "known", "to", "improve", "the", "predictive", "ability", "of", "the", "model", ",", "thus", "reducing", "dimensionality", "and", "potentially", "improving", "performance", "because", "irrelevant", "features", "do", "not", "need", "to", "be", "computed", "."], "sentence-detokenized": "Unlike neural networks and support vector machines, the AdaBoost training process selects only those features that are known to improve the predictive ability of the model, thus reducing dimensionality and potentially improving performance because irrelevant features do not need to be computed.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 26], [27, 34], [35, 41], [42, 50], [50, 51], [52, 55], [56, 64], [65, 73], [74, 81], [82, 89], [90, 94], [95, 100], [101, 109], [110, 114], [115, 118], [119, 124], [125, 127], [128, 135], [136, 139], [140, 150], [151, 158], [159, 161], [162, 165], [166, 171], [171, 172], [173, 177], [178, 186], [187, 201], [202, 205], [206, 217], [218, 227], [228, 239], [240, 247], [248, 258], [259, 267], [268, 270], [271, 274], [275, 279], [280, 282], [283, 285], [286, 294], [294, 295]]}
{"doc_key": "ai-test-5", "ner": [[0, 1, "misc"], [11, 13, "misc"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 11, 13, "part-of", "", false, false], [11, 13, 15, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponymy", "is", "one", "of", "the", "possible", "relations", "between", "verbs", "in", "the", "semantic", "network", "of", "the", "Word", "Net", "database", "."], "sentence-detokenized": "Troponymy is one of the possible relations between verbs in the semantic network of the WordNet database.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 19], [20, 23], [24, 32], [33, 42], [43, 50], [51, 56], [57, 59], [60, 63], [64, 72], [73, 80], [81, 83], [84, 87], [88, 92], [92, 95], [96, 104], [104, 105]]}
{"doc_key": "ai-test-6", "ner": [[8, 9, "task"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "frame", "language", "is", "a", "technique", "used", "for", "knowledge", "representation", "in", "artificial", "intelligence", "."], "sentence-detokenized": "A frame language is a technique used for knowledge representation in artificial intelligence.", "token2charspan": [[0, 1], [2, 7], [8, 16], [17, 19], [20, 21], [22, 31], [32, 36], [37, 40], [41, 50], [51, 65], [66, 68], [69, 79], [80, 92], [92, 93]]}
{"doc_key": "ai-test-7", "ner": [[0, 0, "metrics"], [5, 7, "metrics"], [13, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 5, 7, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "the", "Bilingual", "Evaluation", "Substudy", "in", "its", "calculation", "of", "the", "penalty", "for", "brevity", ",", "as", "small", "variations", "in", "translation", "length", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from the Bilingual Evaluation Substudy in its calculation of the penalty for brevity, as small variations in translation length do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 26], [27, 36], [37, 47], [48, 56], [57, 59], [60, 63], [64, 75], [76, 78], [79, 82], [83, 90], [91, 94], [95, 102], [102, 103], [104, 106], [107, 112], [113, 123], [124, 126], [127, 138], [139, 145], [146, 148], [149, 152], [153, 159], [160, 163], [164, 171], [172, 177], [178, 180], [181, 185], [185, 186]]}
{"doc_key": "ai-test-8", "ner": [[15, 16, "algorithm"], [19, 21, "algorithm"], [31, 31, "field"], [41, 42, "algorithm"], [44, 46, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 16, 31, 31, "usage", "", false, false], [19, 21, 31, 31, "usage", "", false, false], [41, 42, 31, 31, "type-of", "", false, false], [44, 46, 31, 31, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "model", "is", "initially", "fitted", "to", "a", "training", "dataset", ",", "The", "model", "(", "e.g.", "a", "neural", "network", "or", "a", "naive", "Bayes", "classifier", ")", "is", "trained", "on", "the", "training", "dataset", "using", "a", "supervised", "learning", "method", ",", "e.g.", "using", "optimization", "methods", "such", "as", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The model is initially fitted to a training dataset, The model (e.g. a neural network or a naive Bayes classifier) is trained on the training dataset using a supervised learning method, e.g. using optimization methods such as gradient descent or stochastic gradient descent.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 22], [23, 29], [30, 32], [33, 34], [35, 43], [44, 51], [51, 52], [53, 56], [57, 62], [63, 64], [64, 68], [69, 70], [71, 77], [78, 85], [86, 88], [89, 90], [91, 96], [97, 102], [103, 113], [113, 114], [115, 117], [118, 125], [126, 128], [129, 132], [133, 141], [142, 149], [150, 155], [156, 157], [158, 168], [169, 177], [178, 184], [184, 185], [186, 190], [191, 196], [197, 209], [210, 217], [218, 222], [223, 225], [226, 234], [235, 242], [243, 245], [246, 256], [257, 265], [266, 273], [273, 274]]}
{"doc_key": "ai-test-9", "ner": [[0, 0, "product"], [8, 9, "task"], [11, 11, "task"], [13, 15, "task"], [17, 18, "task"], [27, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 0, "usage", "", true, false], [11, 11, 0, 0, "usage", "", true, false], [13, 15, 0, 0, "usage", "", true, false], [17, 18, 0, 0, "usage", "", true, false], [27, 30, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "has", "been", "used", "in", "applications", "such", "as", "query", "answering", ",", "paraphrasing", ",", "textual", "meaning", "identification", "and", "information", "extraction", ",", "either", "directly", "or", "with", "the", "help", "of", "semantic", "role", "tagging", "tools", "."], "sentence-detokenized": "FrameNet has been used in applications such as query answering, paraphrasing, textual meaning identification and information extraction, either directly or with the help of semantic role tagging tools.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 25], [26, 38], [39, 43], [44, 46], [47, 52], [53, 62], [62, 63], [64, 76], [76, 77], [78, 85], [86, 93], [94, 108], [109, 112], [113, 124], [125, 135], [135, 136], [137, 143], [144, 152], [153, 155], [156, 160], [161, 164], [165, 169], [170, 172], [173, 181], [182, 186], [187, 194], [195, 200], [200, 201]]}
{"doc_key": "ai-test-10", "ner": [[5, 6, "field"], [11, 11, "misc"], [14, 14, "product"], [17, 17, "misc"], [20, 20, "product"], [23, 24, "field"], [27, 27, "product"], [30, 32, "misc"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [42, 43, "misc"], [46, 47, "product"], [49, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[14, 14, 11, 11, "general-affiliation", "", false, false], [20, 20, 17, 17, "general-affiliation", "", false, false], [27, 27, 23, 24, "general-affiliation", "", false, false], [35, 35, 30, 32, "type-of", "", false, false], [37, 37, 30, 32, "type-of", "", false, false], [39, 39, 30, 32, "type-of", "", false, false], [46, 47, 42, 43, "general-affiliation", "", false, false], [49, 50, 42, 43, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["This", "includes", "software", "such", "as", "data", "analysis", "and", "extraction", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "general", "audit", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "e.g.", "Crystal", "Reports", "and", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "This includes software such as data analysis and extraction tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), general audit software (e.g. ACL, Arbutus, EAS), business intelligence (e.g. Crystal Reports and Business Objects), etc.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 27], [28, 30], [31, 35], [36, 44], [45, 48], [49, 59], [60, 65], [65, 66], [67, 79], [80, 81], [81, 85], [86, 91], [91, 92], [92, 93], [94, 103], [104, 105], [105, 109], [110, 116], [116, 117], [117, 118], [119, 130], [131, 139], [140, 141], [141, 145], [146, 149], [149, 150], [150, 151], [152, 159], [160, 165], [166, 174], [175, 176], [176, 180], [181, 184], [184, 185], [186, 193], [193, 194], [195, 198], [198, 199], [199, 200], [201, 209], [210, 222], [223, 224], [224, 228], [229, 236], [237, 244], [245, 248], [249, 257], [258, 265], [265, 266], [266, 267], [268, 271], [271, 272]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 6, "researcher"], [10, 10, "organisation"], [13, 13, "product"], [19, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "origin", "", false, false], [5, 6, 10, 10, "role", "", false, false], [13, 13, 19, 20, "type-of", "", false, false], [19, 20, 5, 6, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", "-", "founded", "by", "Rodney", "Brooks", ",", "formerly", "of", "iRobot", "-", "introduced", "Baxter", "in", "September", "2012", "as", "an", "industrial", "robot", "designed", "to", "safely", "interact", "with", "nearby", "human", "workers", "and", "be", "programmable", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "Rethink Robotics - founded by Rodney Brooks, formerly of iRobot - introduced Baxter in September 2012 as an industrial robot designed to safely interact with nearby human workers and be programmable to perform simple tasks.", "token2charspan": [[0, 7], [8, 16], [17, 18], [19, 26], [27, 29], [30, 36], [37, 43], [43, 44], [45, 53], [54, 56], [57, 63], [64, 65], [66, 76], [77, 83], [84, 86], [87, 96], [97, 101], [102, 104], [105, 107], [108, 118], [119, 124], [125, 133], [134, 136], [137, 143], [144, 152], [153, 157], [158, 164], [165, 170], [171, 178], [179, 182], [183, 185], [186, 198], [199, 201], [202, 209], [210, 216], [217, 222], [222, 223]]}
{"doc_key": "ai-test-12", "ner": [[5, 6, "task"], [8, 9, "task"], [11, 14, "task"], [16, 19, "task"], [21, 22, "task"], [24, 25, "task"], [27, 29, "task"], [35, 36, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "text", "mining", "tasks", "include", "text", "categorisation", ",", "text", "clustering", ",", "concept", "/", "entity", "extraction", ",", "production", "of", "granular", "taxonomies", ",", "sentiment", "analysis", ",", "document", "summarisation", "and", "entity", "relationship", "modelling", "(", "i.e.", "learning", "relationships", "between", "named", "entities", ")", "."], "sentence-detokenized": "Typical text mining tasks include text categorisation, text clustering, concept/entity extraction, production of granular taxonomies, sentiment analysis, document summarisation and entity relationship modelling (i.e. learning relationships between named entities).", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 25], [26, 33], [34, 38], [39, 53], [53, 54], [55, 59], [60, 70], [70, 71], [72, 79], [79, 80], [80, 86], [87, 97], [97, 98], [99, 109], [110, 112], [113, 121], [122, 132], [132, 133], [134, 143], [144, 152], [152, 153], [154, 162], [163, 176], [177, 180], [181, 187], [188, 200], [201, 210], [211, 212], [212, 216], [217, 225], [226, 239], [240, 247], [248, 253], [254, 262], [262, 263], [263, 264]]}
{"doc_key": "ai-test-13", "ner": [[4, 5, "metrics"], [9, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nevertheless", ",", "stuttering", "reduces", "the", "precision", ",", "or", "the", "proportion", "of", "true", "negative", "responses", ",", "of", "such", "systems", "."], "sentence-detokenized": "Nevertheless, stuttering reduces the precision, or the proportion of true negative responses, of such systems.", "token2charspan": [[0, 12], [12, 13], [14, 24], [25, 32], [33, 36], [37, 46], [46, 47], [48, 50], [51, 54], [55, 65], [66, 68], [69, 73], [74, 82], [83, 92], [92, 93], [94, 96], [97, 101], [102, 109], [109, 110]]}
{"doc_key": "ai-test-14", "ner": [[4, 5, "task"], [10, 13, "misc"], [17, 18, "misc"], [27, 27, "product"], [29, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 13, 4, 5, "temporal", "", false, false], [17, 18, 10, 13, "named", "", false, false], [27, 27, 10, 13, "usage", "", false, false], [29, 29, 10, 13, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "special", "case", "of", "keyword", "spotting", "is", "the", "detection", "of", "wake", "-", "up", "words", "(", "also", "called", "hot", "words", ")", "used", "by", "personal", "digital", "assistants", "such", "as", "Alexa", "or", "Siri", "to", "wake", "up", "when", "their", "name", "is", "spoken", "."], "sentence-detokenized": "A special case of keyword spotting is the detection of wake-up words (also called hot words) used by personal digital assistants such as Alexa or Siri to wake up when their name is spoken.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 17], [18, 25], [26, 34], [35, 37], [38, 41], [42, 51], [52, 54], [55, 59], [59, 60], [60, 62], [63, 68], [69, 70], [70, 74], [75, 81], [82, 85], [86, 91], [91, 92], [93, 97], [98, 100], [101, 109], [110, 117], [118, 128], [129, 133], [134, 136], [137, 142], [143, 145], [146, 150], [151, 153], [154, 158], [159, 161], [162, 166], [167, 172], [173, 177], [178, 180], [181, 187], [187, 188]]}
{"doc_key": "ai-test-15", "ner": [[0, 2, "programlang"], [9, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 2, "part-of", "", false, false], [11, 11, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "with", "Java", "."], "sentence-detokenized": "Prova is an open source programming language that combines Prolog with Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 16], [17, 23], [24, 35], [36, 44], [45, 49], [50, 58], [59, 65], [66, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-test-16", "ner": [[3, 4, "organisation"], [9, 9, "organisation"], [16, 18, "product"], [28, 29, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 9, 9, "part-of", "", false, false], [3, 4, 9, 9, "role", "sells", false, false], [3, 4, 28, 29, "role", "sells_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1987", ",", "Tocibai", "Machine", ",", "a", "subsidiary", "of", "Toshiba", ",", "was", "accused", "of", "illegally", "selling", "CNC", "milling", "machines", "used", "to", "make", "very", "quiet", "submarine", "propellers", "to", "the", "Soviet", "Union", "in", "violation", "of", "the", "CoCom", "agreement", ",", "an", "international", "embargo", "on", "certain", "countries", "against", "COMECON", "countries", "."], "sentence-detokenized": "In 1987, Tocibai Machine, a subsidiary of Toshiba, was accused of illegally selling CNC milling machines used to make very quiet submarine propellers to the Soviet Union in violation of the CoCom agreement, an international embargo on certain countries against COMECON countries.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 24], [24, 25], [26, 27], [28, 38], [39, 41], [42, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 75], [76, 83], [84, 87], [88, 95], [96, 104], [105, 109], [110, 112], [113, 117], [118, 122], [123, 128], [129, 138], [139, 149], [150, 152], [153, 156], [157, 163], [164, 169], [170, 172], [173, 182], [183, 185], [186, 189], [190, 195], [196, 205], [205, 206], [207, 209], [210, 223], [224, 231], [232, 234], [235, 242], [243, 252], [253, 260], [261, 268], [269, 278], [278, 279]]}
{"doc_key": "ai-test-17", "ner": [[0, 1, "researcher"], [7, 10, "product"], [22, 25, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 0, 1, "artifact", "", false, false], [7, 10, 22, 25, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Engelberger", "'s", "most", "famous", "co-invention", ",", "the", "Unimate", "industrial", "robot", "arm", ",", "was", "one", "of", "the", "first", "to", "be", "inducted", "into", "the", "Robot", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberger's most famous co-invention, the Unimate industrial robot arm, was one of the first to be inducted into the Robot Hall of Fame in 2003.", "token2charspan": [[0, 11], [11, 13], [14, 18], [19, 25], [26, 38], [38, 39], [40, 43], [44, 51], [52, 62], [63, 68], [69, 72], [72, 73], [74, 77], [78, 81], [82, 84], [85, 88], [89, 94], [95, 97], [98, 100], [101, 109], [110, 114], [115, 118], [119, 124], [125, 129], [130, 132], [133, 137], [138, 140], [141, 145], [145, 146]]}
{"doc_key": "ai-test-18", "ner": [[3, 3, "misc"], [8, 8, "misc"], [10, 11, "person"], [18, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 8, "usage", "", false, false], [10, 11, 18, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Originally", "controlled", "via", "static", "html", "web", "pages", "using", "CGI", ",", "Dalton", "'s", "work", "introduced", "a", "Java", "-", "based", "augmented", "reality", "interface", "that", "had", "limited", "success", "."], "sentence-detokenized": "Originally controlled via static html web pages using CGI, Dalton's work introduced a Java-based augmented reality interface that had limited success.", "token2charspan": [[0, 10], [11, 21], [22, 25], [26, 32], [33, 37], [38, 41], [42, 47], [48, 53], [54, 57], [57, 58], [59, 65], [65, 67], [68, 72], [73, 83], [84, 85], [86, 90], [90, 91], [91, 96], [97, 106], [107, 114], [115, 124], [125, 129], [130, 133], [134, 141], [142, 149], [149, 150]]}
{"doc_key": "ai-test-19", "ner": [[5, 7, "task"], [11, 11, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 11, 11, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "publication", "on", "the", "LMF", "specification", "to", "be", "ratified", "by", "ISO", "(", "this", "article", "became", "(", "in", "2015", ")", "the", "ninth", "most", "cited", "article", "in", "the", "LREC", "conferences", "from", "LREC", "articles", ")", ":"], "sentence-detokenized": "The first publication on the LMF specification to be ratified by ISO (this article became (in 2015) the ninth most cited article in the LREC conferences from LREC articles):", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 24], [25, 28], [29, 32], [33, 46], [47, 49], [50, 52], [53, 61], [62, 64], [65, 68], [69, 70], [70, 74], [75, 82], [83, 89], [90, 91], [91, 93], [94, 98], [98, 99], [100, 103], [104, 109], [110, 114], [115, 120], [121, 128], [129, 131], [132, 135], [136, 140], [141, 152], [153, 157], [158, 162], [163, 171], [171, 172], [172, 173]]}
{"doc_key": "ai-test-20", "ner": [[1, 2, "metrics"], [15, 16, "metrics"], [18, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 1, 2, "usage", "", false, false], [15, 16, 18, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "confusion", "matrix", "or", "matching", "matrix", "is", "often", "used", "as", "a", "tool", "to", "validate", "the", "accuracy", "of", "the", "k", "-", "NN", "classification", "."], "sentence-detokenized": "A confusion matrix or matching matrix is often used as a tool to validate the accuracy of the k -NN classification.", "token2charspan": [[0, 1], [2, 11], [12, 18], [19, 21], [22, 30], [31, 37], [38, 40], [41, 46], [47, 51], [52, 54], [55, 56], [57, 61], [62, 64], [65, 73], [74, 77], [78, 86], [87, 89], [90, 93], [94, 95], [96, 97], [97, 99], [100, 114], [114, 115]]}
{"doc_key": "ai-test-21", "ner": [[0, 1, "algorithm"], [12, 12, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 15, "part-of", "", false, false], [0, 1, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", "is", "one", "of", "the", "predictive", "modelling", "methods", "used", "in", "statistics", ",", "data", "mining", "and", "machine", "learning", "."], "sentence-detokenized": "Decision tree learning is one of the predictive modelling methods used in statistics, data mining and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 47], [48, 57], [58, 65], [66, 70], [71, 73], [74, 84], [84, 85], [86, 90], [91, 97], [98, 101], [102, 109], [110, 118], [118, 119]]}
{"doc_key": "ai-test-22", "ner": [[4, 5, "misc"], [21, 23, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["At", "runtime", ",", "the", "target", "prosody", "for", "a", "sentence", "is", "superimposed", "on", "these", "minimal", "units", "using", "signal", "processing", "techniques", "such", "as", "linear", "predictive", "coding", ",", "PSOLA"], "sentence-detokenized": "At runtime, the target prosody for a sentence is superimposed on these minimal units using signal processing techniques such as linear predictive coding, PSOLA", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 22], [23, 30], [31, 34], [35, 36], [37, 45], [46, 48], [49, 61], [62, 64], [65, 70], [71, 78], [79, 84], [85, 90], [91, 97], [98, 108], [109, 119], [120, 124], [125, 127], [128, 134], [135, 145], [146, 152], [152, 153], [154, 159]]}
{"doc_key": "ai-test-23", "ner": [[3, 4, "field"], [6, 7, "field"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 3, 4, "usage", "", true, false], [17, 18, 6, 7, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "approach", "used", "artificial", "intelligence", "and", "machine", "learning", "to", "allow", "researchers", "to", "visually", "compare", "conventional", "and", "thermal", "facial", "images", "."], "sentence-detokenized": "This approach used artificial intelligence and machine learning to allow researchers to visually compare conventional and thermal facial images.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 29], [30, 42], [43, 46], [47, 54], [55, 63], [64, 66], [67, 72], [73, 84], [85, 87], [88, 96], [97, 104], [105, 117], [118, 121], [122, 129], [130, 136], [137, 143], [143, 144]]}
{"doc_key": "ai-test-24", "ner": [[1, 2, "field"], [4, 5, "algorithm"], [10, 11, "task"], [15, 16, "misc"], [22, 23, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 1, 2, "part-of", "", false, false], [4, 5, 10, 11, "topic", "", false, false], [10, 11, 15, 16, "origin", "", false, false], [22, 23, 1, 2, "part-of", "", false, false], [22, 23, 4, 5, "topic", "", false, false], [25, 26, 1, 2, "part-of", "", false, false], [25, 26, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "computer", "science", ",", "evolutionary", "computation", "is", "a", "family", "of", "global", "optimization", "algorithms", "inspired", "by", "biological", "evolution", ",", "and", "the", "subfield", "of", "artificial", "intelligence", "and", "soft", "computation", "that", "studies", "these", "algorithms", "."], "sentence-detokenized": "In computer science, evolutionary computation is a family of global optimization algorithms inspired by biological evolution, and the subfield of artificial intelligence and soft computation that studies these algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 33], [34, 45], [46, 48], [49, 50], [51, 57], [58, 60], [61, 67], [68, 80], [81, 91], [92, 100], [101, 103], [104, 114], [115, 124], [124, 125], [126, 129], [130, 133], [134, 142], [143, 145], [146, 156], [157, 169], [170, 173], [174, 178], [179, 190], [191, 195], [196, 203], [204, 209], [210, 220], [220, 221]]}
{"doc_key": "ai-test-25", "ner": [[11, 12, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "one", "can", "combine", "a", "measure", "based", "on", "the", "confusion", "matrix", "with", "the", "mean", "square", "error", "evaluated", "between", "the", "raw", "model", "results", "and", "the", "actual", "values", "."], "sentence-detokenized": "For example, one can combine a measure based on the confusion matrix with the mean square error evaluated between the raw model results and the actual values.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 20], [21, 28], [29, 30], [31, 38], [39, 44], [45, 47], [48, 51], [52, 61], [62, 68], [69, 73], [74, 77], [78, 82], [83, 89], [90, 95], [96, 105], [106, 113], [114, 117], [118, 121], [122, 127], [128, 135], [136, 139], [140, 143], [144, 150], [151, 157], [157, 158]]}
{"doc_key": "ai-test-26", "ner": [[7, 8, "product"], [11, 11, "researcher"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 11, 11, "origin", "", false, false], [7, 8, 18, 18, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Most", "of", "them", "are", "results", "of", "the", "word2vec", "model", "developed", "by", "Mikolov", "et", "al", ".", "or", "variants", "of", "word2vec", "."], "sentence-detokenized": "Most of them are results of the word2vec model developed by Mikolov et al. or variants of word2vec.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 16], [17, 24], [25, 27], [28, 31], [32, 40], [41, 46], [47, 56], [57, 59], [60, 67], [68, 70], [71, 73], [73, 74], [75, 77], [78, 86], [87, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-27", "ner": [[13, 13, "conference"], [16, 20, "conference"], [22, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 22, 16, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["During", "this", "time", ",", "a", "total", "of", "43", "publications", "have", "been", "recognised", "by", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "During this time, a total of 43 publications have been recognised by CVPR and the International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 6], [7, 11], [12, 16], [16, 17], [18, 19], [20, 25], [26, 28], [29, 31], [32, 44], [45, 49], [50, 54], [55, 65], [66, 68], [69, 73], [74, 77], [78, 81], [82, 95], [96, 106], [107, 109], [110, 118], [119, 125], [126, 127], [127, 131], [131, 132], [132, 133]]}
{"doc_key": "ai-test-28", "ner": [[0, 0, "product"], [12, 19, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 19, "general-affiliation", "platform_for_education_about", false, false], [24, 25, 0, 0, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["AIBO", "has", "been", "widely", "used", "as", "a", "low", "-", "cost", "platform", "for", "artificial", "intelligence", "education", "and", "research", ",", "as", "it", "integrates", "a", "computer", ",", "computer", "vision", "and", "articulators", "into", "a", "package", "that", "is", "much", "cheaper", "than", "conventional", "research", "robots", "."], "sentence-detokenized": "AIBO has been widely used as a low-cost platform for artificial intelligence education and research, as it integrates a computer, computer vision and articulators into a package that is much cheaper than conventional research robots.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 20], [21, 25], [26, 28], [29, 30], [31, 34], [34, 35], [35, 39], [40, 48], [49, 52], [53, 63], [64, 76], [77, 86], [87, 90], [91, 99], [99, 100], [101, 103], [104, 106], [107, 117], [118, 119], [120, 128], [128, 129], [130, 138], [139, 145], [146, 149], [150, 162], [163, 167], [168, 169], [170, 177], [178, 182], [183, 185], [186, 190], [191, 198], [199, 203], [204, 216], [217, 225], [226, 232], [232, 233]]}
{"doc_key": "ai-test-29", "ner": [[7, 12, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "was", "the", "programme", "chair", "of", "the", "International", "Conference", "on", "Computer", "Vision", "2021", "."], "sentence-detokenized": "She was the programme chair of the International Conference on Computer Vision 2021.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 21], [22, 27], [28, 30], [31, 34], [35, 48], [49, 59], [60, 62], [63, 71], [72, 78], [79, 83], [83, 84]]}
{"doc_key": "ai-test-30", "ner": [[0, 0, "researcher"], [5, 5, "organisation"], [14, 14, "organisation"], [23, 24, "organisation"], [32, 36, "product"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 5, 5, "role", "", false, false], [0, 0, 14, 14, "role", "", true, false], [14, 14, 23, 24, "role", "develops_with", false, false], [32, 36, 14, 14, "artifact", "", false, false], [30, 30, 32, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Scheinman", "received", "a", "grant", "from", "Unimation", "to", "develop", "his", "designs", "and", "sold", "them", "to", "Unimation", ",", "which", "further", "developed", "them", "with", "support", "from", "General", "Motors", "and", "later", "marketed", "them", "as", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "."], "sentence-detokenized": "Scheinman received a grant from Unimation to develop his designs and sold them to Unimation, which further developed them with support from General Motors and later marketed them as PUMA (Programmable Universal Machine for Assembly).", "token2charspan": [[0, 9], [10, 18], [19, 20], [21, 26], [27, 31], [32, 41], [42, 44], [45, 52], [53, 56], [57, 64], [65, 68], [69, 73], [74, 78], [79, 81], [82, 91], [91, 92], [93, 98], [99, 106], [107, 116], [117, 121], [122, 126], [127, 134], [135, 139], [140, 147], [148, 154], [155, 158], [159, 164], [165, 173], [174, 178], [179, 181], [182, 186], [187, 188], [188, 200], [201, 210], [211, 218], [219, 222], [223, 231], [231, 232], [232, 233]]}
{"doc_key": "ai-test-31", "ner": [[11, 14, "task"], [13, 14, "task"], [0, 0, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 14, "general-affiliation", "works_with", false, false], [0, 0, 13, 14, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Gebel", "(", "2009", ")", "provides", "an", "overview", "of", "calibration", "methods", "for", "binary", "and", "multi-class", "classification", "."], "sentence-detokenized": "Gebel (2009) provides an overview of calibration methods for binary and multi-class classification.", "token2charspan": [[0, 5], [6, 7], [7, 11], [11, 12], [13, 21], [22, 24], [25, 33], [34, 36], [37, 48], [49, 56], [57, 60], [61, 67], [68, 71], [72, 83], [84, 98], [98, 99]]}
{"doc_key": "ai-test-32", "ner": [[7, 9, "task"], [11, 11, "task"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "involved", "in", "areas", "such", "as", "optical", "character", "recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "speech", "recognition", "technology", "and", "electronic", "keyboard", "instruments", "."], "sentence-detokenized": "He is involved in areas such as optical character recognition (OCR), speech synthesis, speech recognition technology and electronic keyboard instruments.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 23], [24, 28], [29, 31], [32, 39], [40, 49], [50, 61], [62, 63], [63, 66], [66, 67], [67, 68], [69, 75], [76, 85], [85, 86], [87, 93], [94, 105], [106, 116], [117, 120], [121, 131], [132, 140], [141, 152], [152, 153]]}
{"doc_key": "ai-test-33", "ner": [[7, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "newer", "and", "more", "modern", "techniques", ",", "the", "Kaldi", "toolbox", "can", "be", "used", "."], "sentence-detokenized": "For newer and more modern techniques, the Kaldi toolbox can be used.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 18], [19, 25], [26, 36], [36, 37], [38, 41], [42, 47], [48, 55], [56, 59], [60, 62], [63, 67], [67, 68]]}
{"doc_key": "ai-test-34", "ner": [[0, 4, "researcher"], [8, 10, "organisation"], [16, 17, "organisation"], [23, 24, "organisation"], [27, 28, "researcher"], [32, 35, "organisation"], [41, 43, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 4, 8, 10, "role", "", false, false], [0, 4, 16, 17, "role", "", false, false], [0, 4, 23, 24, "role", "", false, false], [0, 4, 32, 35, "role", "", false, false], [0, 4, 41, 43, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson", "-", "Laird", "is", "a", "Fellow", "of", "the", "American", "Philosophical", "Society", ",", "a", "Fellow", "of", "the", "Royal", "Society", ",", "a", "Fellow", "of", "the", "British", "Academy", ",", "a", "William", "James", "Fellow", "of", "the", "Association", "for", "Psychological", "Science", "and", "a", "Fellow", "of", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Johnson-Laird is a Fellow of the American Philosophical Society, a Fellow of the Royal Society, a Fellow of the British Academy, a William James Fellow of the Association for Psychological Science and a Fellow of the Cognitive Science Society.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 66], [67, 73], [74, 76], [77, 80], [81, 86], [87, 94], [94, 95], [96, 97], [98, 104], [105, 107], [108, 111], [112, 119], [120, 127], [127, 128], [129, 130], [131, 138], [139, 144], [145, 151], [152, 154], [155, 158], [159, 170], [171, 174], [175, 188], [189, 196], [197, 200], [201, 202], [203, 209], [210, 212], [213, 216], [217, 226], [227, 234], [235, 242], [242, 243]]}
{"doc_key": "ai-test-35", "ner": [[2, 7, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [20, 21, "algorithm"], [25, 29, "task"], [31, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 2, 7, "physical", "", false, false], [10, 11, 2, 7, "temporal", "", false, false], [13, 14, 2, 7, "physical", "", false, false], [13, 14, 2, 7, "temporal", "", false, false], [16, 17, 2, 7, "physical", "", false, false], [16, 17, 2, 7, "temporal", "", false, false], [20, 21, 16, 17, "role", "extends", false, false], [25, 29, 16, 17, "role", "extends", false, false], [31, 31, 25, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["At", "the", "IEEE", "International", "Conference", "on", "Image", "Processing", "2010", ",", "Rui", "Hu", ",", "Mark", "Banard", "and", "John", "Collomosse", "extended", "the", "HOG", "descriptor", "for", "use", "in", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the IEEE International Conference on Image Processing 2010, Rui Hu, Mark Banard and John Collomosse extended the HOG descriptor for use in sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 25], [26, 36], [37, 39], [40, 45], [46, 56], [57, 61], [61, 62], [63, 66], [67, 69], [69, 70], [71, 75], [76, 82], [83, 86], [87, 91], [92, 102], [103, 111], [112, 115], [116, 119], [120, 130], [131, 134], [135, 138], [139, 141], [142, 148], [148, 149], [149, 154], [155, 160], [161, 170], [171, 172], [172, 176], [176, 177], [177, 178]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "uses", "a", "modified", "form", "of", "precision", "to", "compare", "a", "candidate", "translation", "with", "several", "reference", "translations", "."], "sentence-detokenized": "BLEU uses a modified form of precision to compare a candidate translation with several reference translations.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 20], [21, 25], [26, 28], [29, 38], [39, 41], [42, 49], [50, 51], [52, 61], [62, 73], [74, 78], [79, 86], [87, 96], [97, 109], [109, 110]]}
{"doc_key": "ai-test-37", "ner": [[37, 38, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "case", "of", "a", "general", "basis", "space", "math", "(", "Y", ",\\", "mathcal", "{", "B", "},\\", "now", ")", "/", "math", "(", "i.e.", "a", "basis", "space", "that", "is", "not", "countable", ")", ",", "one", "usually", "takes", "into", "account", "the", "relative", "entropy", "."], "sentence-detokenized": "In the case of a general basis space math (Y,\\ mathcal {B},\\ now) / math (i.e. a basis space that is not countable), one usually takes into account the relative entropy.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 36], [37, 41], [42, 43], [43, 44], [44, 46], [47, 54], [55, 56], [56, 57], [57, 60], [61, 64], [64, 65], [66, 67], [68, 72], [73, 74], [74, 78], [79, 80], [81, 86], [87, 92], [93, 97], [98, 100], [101, 104], [105, 114], [114, 115], [115, 116], [117, 120], [121, 128], [129, 134], [135, 139], [140, 147], [148, 151], [152, 160], [161, 168], [168, 169]]}
{"doc_key": "ai-test-38", "ner": [[7, 8, "country"], [9, 11, "organisation"], [13, 13, "organisation"], [19, 20, "organisation"], [22, 22, "organisation"], [26, 28, "organisation"], [30, 31, "country"], [32, 37, "organisation"], [39, 39, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9], "relations": [[9, 11, 7, 8, "physical", "", false, false], [13, 13, 9, 11, "named", "", false, false], [22, 22, 19, 20, "named", "", false, false], [32, 37, 30, 31, "physical", "", false, false], [39, 39, 32, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 3, 4, 5], "sentence": ["By", "October", "2011", ",", "existing", "partnerships", "with", "the", "US", "National", "Park", "Service", "(", "NPS", ")", ",", "the", "UK", "'s", "Historic", "Scotland", "(", "HS", ")", ",", "the", "World", "Monuments", "Fund", "and", "Mexico", "'s", "Instituto", "Nacional", "de", "Antropolog\u00eda", "y", "Historia", "(", "INAH", ")", "had", "been", "significantly", "expanded", "."], "sentence-detokenized": "By October 2011, existing partnerships with the US National Park Service (NPS), the UK's Historic Scotland (HS), the World Monuments Fund and Mexico's Instituto Nacional de Antropolog\u00eda y Historia (INAH) had been significantly expanded.", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [17, 25], [26, 38], [39, 43], [44, 47], [48, 50], [51, 59], [60, 64], [65, 72], [73, 74], [74, 77], [77, 78], [78, 79], [80, 83], [84, 86], [86, 88], [89, 97], [98, 106], [107, 108], [108, 110], [110, 111], [111, 112], [113, 116], [117, 122], [123, 132], [133, 137], [138, 141], [142, 148], [148, 150], [151, 160], [161, 169], [170, 172], [173, 185], [186, 187], [188, 196], [197, 198], [198, 202], [202, 203], [204, 207], [208, 212], [213, 226], [227, 235], [235, 236]]}
{"doc_key": "ai-test-39", "ner": [[0, 1, "algorithm"], [6, 8, "field"], [11, 11, "product"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 11, 11, "part-of", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [11, 11, 6, 8, "general-affiliation", "", false, false], [13, 13, 6, 8, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SVM", "kernels", "are", "available", "in", "many", "machine", "learning", "toolkits", ",", "including", "LIBSVM", ",", "MATLAB", "and", "others", "."], "sentence-detokenized": "SVM kernels are available in many machine learning toolkits, including LIBSVM, MATLAB and others.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 25], [26, 28], [29, 33], [34, 41], [42, 50], [51, 59], [59, 60], [61, 70], [71, 77], [77, 78], [79, 85], [86, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-test-40", "ner": [[2, 4, "misc"], [13, 15, "location"], [16, 16, "location"], [18, 18, "country"], [24, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 13, 15, "physical", "", false, false], [2, 4, 24, 26, "temporal", "", false, false], [13, 15, 16, 16, "physical", "", false, false], [16, 16, 18, 18, "physical", "", false, false], [24, 26, 13, 15, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2009", "Loebner", "Prize", "competition", "was", "held", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", "in", "Brighton", ",", "UK", ",", "in", "conjunction", "with", "the", "Interspeech", "2009", "conference", "."], "sentence-detokenized": "The 2009 Loebner Prize competition was held on 6 September 2009 at the Brighton Centre in Brighton, UK, in conjunction with the Interspeech 2009 conference.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 34], [35, 38], [39, 43], [44, 46], [47, 48], [49, 58], [59, 63], [64, 66], [67, 70], [71, 79], [80, 86], [87, 89], [90, 98], [98, 99], [100, 102], [102, 103], [104, 106], [107, 118], [119, 123], [124, 127], [128, 139], [140, 144], [145, 155], [155, 156]]}
{"doc_key": "ai-test-41", "ner": [[1, 3, "product"], [10, 11, "product"], [16, 18, "product"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 21, 1, 3, "part-of", "", false, false], [19, 21, 10, 11, "part-of", "", false, false], [19, 21, 16, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "QRIO", "humanoid", "robot", "was", "designed", "as", "a", "successor", "to", "AIBO", "and", "shares", "the", "same", "basic", "R", "-", "CODE", "Aperios", "operating", "system", "."], "sentence-detokenized": "The QRIO humanoid robot was designed as a successor to AIBO and shares the same basic R-CODE Aperios operating system.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 23], [24, 27], [28, 36], [37, 39], [40, 41], [42, 51], [52, 54], [55, 59], [60, 63], [64, 70], [71, 74], [75, 79], [80, 85], [86, 87], [87, 88], [88, 92], [93, 100], [101, 110], [111, 117], [117, 118]]}
{"doc_key": "ai-test-42", "ner": [[0, 1, "misc"], [5, 6, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 0, 1, "cause-effect", "", true, false], [11, 12, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Speech", "waveforms", "are", "generated", "from", "the", "HMMs", "themselves", "based", "on", "the", "maximum", "likelihood", "criterion", "."], "sentence-detokenized": "Speech waveforms are generated from the HMMs themselves based on the maximum likelihood criterion.", "token2charspan": [[0, 6], [7, 16], [17, 20], [21, 30], [31, 35], [36, 39], [40, 44], [45, 55], [56, 61], [62, 64], [65, 68], [69, 76], [77, 87], [88, 97], [97, 98]]}
{"doc_key": "ai-test-43", "ner": [[0, 3, "product"], [5, 8, "task"], [10, 10, "task"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 5, 8, "type-of", "", false, false], [0, 3, 10, 10, "type-of", "", false, false], [0, 3, 16, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "is", "a", "free", "multilingual", "statistical", "machine", "translation", "and", "neural", "machine", "translation", "service", "developed", "by", "Google", "to", "translate", "text", "and", "websites", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Google Translate is a free multilingual statistical machine translation and neural machine translation service developed by Google to translate text and websites from one language to another.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 39], [40, 51], [52, 59], [60, 71], [72, 75], [76, 82], [83, 90], [91, 102], [103, 110], [111, 120], [121, 123], [124, 130], [131, 133], [134, 143], [144, 148], [149, 152], [153, 161], [162, 166], [167, 170], [171, 179], [180, 182], [183, 190], [190, 191]]}
{"doc_key": "ai-test-44", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [14, 17, "field"], [19, 21, "task"], [23, 24, "task"], [26, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[19, 21, 5, 6, "part-of", "", false, true], [19, 21, 8, 9, "part-of", "", false, true], [19, 21, 11, 12, "part-of", "", false, true], [23, 24, 5, 6, "part-of", "", false, true], [23, 24, 8, 9, "part-of", "", false, true], [23, 24, 11, 12, "part-of", "", false, true], [26, 29, 5, 6, "part-of", "", false, true], [26, 29, 8, 9, "part-of", "", false, true], [26, 29, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Skeletons", "are", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", "and", "digital", "image", "processing", "for", "e.g.", "optical", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", "or", "compression", "."], "sentence-detokenized": "Skeletons are widely used in computer vision, image analysis, pattern recognition and digital image processing for e.g. optical character recognition, fingerprint recognition, visual inspection or compression.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 25], [26, 28], [29, 37], [38, 44], [44, 45], [46, 51], [52, 60], [60, 61], [62, 69], [70, 81], [82, 85], [86, 93], [94, 99], [100, 110], [111, 114], [115, 119], [120, 127], [128, 137], [138, 149], [149, 150], [151, 162], [163, 174], [174, 175], [176, 182], [183, 193], [194, 196], [197, 208], [208, 209]]}
{"doc_key": "ai-test-45", "ner": [[0, 6, "conference"], [11, 14, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 6, 11, 14, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "is", "a", "benchmark", "for", "object", "classification", "and", "detection", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark for object classification and detection, with millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 58], [59, 68], [69, 72], [73, 79], [80, 94], [95, 98], [99, 108], [108, 109], [110, 114], [115, 123], [124, 126], [127, 133], [134, 137], [138, 146], [147, 149], [150, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-test-46", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 11, "researcher"], [15, 17, "misc"], [20, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 15, 17, "part-of", "", false, false], [0, 0, 20, 23, "part-of", "", false, false], [4, 5, 15, 17, "part-of", "", false, false], [4, 5, 20, 23, "part-of", "", false, false], [7, 11, 15, 17, "part-of", "", false, false], [7, 11, 20, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "are", "called", "by", "some", "the", "godfathers", "of", "AI", "and", "the", "godfathers", "of", "Deep", "Learning", "."], "sentence-detokenized": "Bengio, along with Geoffrey Hinton and Yann LeCun, are called by some the godfathers of AI and the godfathers of Deep Learning.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 27], [28, 34], [35, 38], [39, 43], [44, 49], [49, 50], [51, 54], [55, 61], [62, 64], [65, 69], [70, 73], [74, 84], [85, 87], [88, 90], [91, 94], [95, 98], [99, 109], [110, 112], [113, 117], [118, 126], [126, 127]]}
{"doc_key": "ai-test-47", "ner": [[7, 7, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "Life", "Fellow", "of", "the", "IEEE", "."], "sentence-detokenized": "He is a Life Fellow of the IEEE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 19], [20, 22], [23, 26], [27, 31], [31, 32]]}
{"doc_key": "ai-test-48", "ner": [[0, 1, "organisation"], [13, 18, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 18, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NSA", "Bethesda", "is", "responsible", "for", "providing", "operational", "support", "to", "the", "largest", "tenant", ",", "Walter", "Reed", "National", "Military", "Medical", "Center", "."], "sentence-detokenized": "NSA Bethesda is responsible for providing operational support to the largest tenant, Walter Reed National Military Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 31], [32, 41], [42, 53], [54, 61], [62, 64], [65, 68], [69, 76], [77, 83], [83, 84], [85, 91], [92, 96], [97, 105], [106, 114], [115, 122], [123, 129], [129, 130]]}
{"doc_key": "ai-test-49", "ner": [[6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "three", "major", "learning", "paradigms", "are", "supervised", "learning", ",", "unsupervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "The three major learning paradigms are supervised learning, unsupervised learning and reinforcement learning.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 24], [25, 34], [35, 38], [39, 49], [50, 58], [58, 59], [60, 72], [73, 81], [82, 85], [86, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-test-50", "ner": [[2, 2, "task"], [4, 6, "task"], [10, 14, "task"], [16, 17, "task"], [19, 21, "task"], [23, 24, "task"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Examples", "include", "control", ",", "planning", "and", "scheduling", ",", "ability", "to", "answer", "diagnostic", "and", "consumer", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", "and", "face", "recognition", "."], "sentence-detokenized": "Examples include control, planning and scheduling, ability to answer diagnostic and consumer questions, handwriting recognition, natural language understanding, speech recognition and face recognition.", "token2charspan": [[0, 8], [9, 16], [17, 24], [24, 25], [26, 34], [35, 38], [39, 49], [49, 50], [51, 58], [59, 61], [62, 68], [69, 79], [80, 83], [84, 92], [93, 102], [102, 103], [104, 115], [116, 127], [127, 128], [129, 136], [137, 145], [146, 159], [159, 160], [161, 167], [168, 179], [180, 183], [184, 188], [189, 200], [200, 201]]}
{"doc_key": "ai-test-51", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", "he", "was", "elected", "as", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "founding", "member", ")", "."], "sentence-detokenized": "In 1991 he was elected as a member of the Association for the Advancement of Artificial Intelligence (1990, founding member).", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 25], [26, 27], [28, 34], [35, 37], [38, 41], [42, 53], [54, 57], [58, 61], [62, 73], [74, 76], [77, 87], [88, 100], [101, 102], [102, 106], [106, 107], [108, 116], [117, 123], [123, 124], [124, 125]]}
{"doc_key": "ai-test-52", "ner": [[9, 10, "misc"], [13, 14, "algorithm"], [25, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["By", "formulating", "the", "problem", "as", "the", "solution", "of", "a", "Toeplitz", "matrix", "and", "using", "Levinson", "recursion", ",", "we", "can", "relatively", "quickly", "estimate", "a", "filter", "with", "minimum", "mean", "squared", "error", "."], "sentence-detokenized": "By formulating the problem as the solution of a Toeplitz matrix and using Levinson recursion, we can relatively quickly estimate a filter with minimum mean squared error.", "token2charspan": [[0, 2], [3, 14], [15, 18], [19, 26], [27, 29], [30, 33], [34, 42], [43, 45], [46, 47], [48, 56], [57, 63], [64, 67], [68, 73], [74, 82], [83, 92], [92, 93], [94, 96], [97, 100], [101, 111], [112, 119], [120, 128], [129, 130], [131, 137], [138, 142], [143, 150], [151, 155], [156, 163], [164, 169], [169, 170]]}
{"doc_key": "ai-test-53", "ner": [[5, 10, "conference"], [16, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 10, 16, 20, "physical", "", false, false], [16, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2011", ",", "the", "15th", "edition", "of", "Campus", "Party", "Spain", "will", "be", "held", "at", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "In July 2011, the 15th edition of Campus Party Spain will be held at the City of Arts and Sciences in Valencia.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 22], [23, 30], [31, 33], [34, 40], [41, 46], [47, 52], [53, 57], [58, 60], [61, 65], [66, 68], [69, 72], [73, 77], [78, 80], [81, 85], [86, 89], [90, 98], [99, 101], [102, 110], [110, 111]]}
{"doc_key": "ai-test-54", "ner": [[13, 13, "product"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Often", "this", "is", "only", "possible", "at", "the", "end", "of", "complex", "games", "such", "as", "chess", "or", "go", ",", "since", "it", "is", "not", "possible", "to", "look", "ahead", "as", "far", "as", "the", "end", "of", "the", "game", ",", "except", "towards", "the", "end", ",", "and", "instead", "positions", "are", "given", "finite", "values", "as", "estimates", "of", "the", "degree", "of", "belief", "that", "they", "will", "lead", "to", "a", "win", "for", "one", "player", "or", "the", "other", "."], "sentence-detokenized": "Often this is only possible at the end of complex games such as chess or go, since it is not possible to look ahead as far as the end of the game, except towards the end, and instead positions are given finite values as estimates of the degree of belief that they will lead to a win for one player or the other.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 18], [19, 27], [28, 30], [31, 34], [35, 38], [39, 41], [42, 49], [50, 55], [56, 60], [61, 63], [64, 69], [70, 72], [73, 75], [75, 76], [77, 82], [83, 85], [86, 88], [89, 92], [93, 101], [102, 104], [105, 109], [110, 115], [116, 118], [119, 122], [123, 125], [126, 129], [130, 133], [134, 136], [137, 140], [141, 145], [145, 146], [147, 153], [154, 161], [162, 165], [166, 169], [169, 170], [171, 174], [175, 182], [183, 192], [193, 196], [197, 202], [203, 209], [210, 216], [217, 219], [220, 229], [230, 232], [233, 236], [237, 243], [244, 246], [247, 253], [254, 258], [259, 263], [264, 268], [269, 273], [274, 276], [277, 278], [279, 282], [283, 286], [287, 290], [291, 297], [298, 300], [301, 304], [305, 310], [310, 311]]}
{"doc_key": "ai-test-55", "ner": [[4, 50, "algorithm"], [25, 26, "algorithm"], [32, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[4, 50, 25, 26, "compare", "", false, false], [4, 50, 32, 34, "compare", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["The", "difference", "between", "the", "multinomial", "logit", "model", "and", "many", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "with", "the", "same", "basic", "set", "-", "up", "(", "perceptual", "algorithm", ",", "support", "vector", "machines", ",", "linear", "discriminant", "analysis", ",", "etc.", ")", "is", "that", "the", "logit", "model", "is", "not", "the", "same", "as", "the", "logit", "model", "."], "sentence-detokenized": "The difference between the multinomial logit model and many other methods, models, algorithms, etc. with the same basic set-up (perceptual algorithm, support vector machines, linear discriminant analysis, etc.) is that the logit model is not the same as the logit model.", "token2charspan": [[0, 3], [4, 14], [15, 22], [23, 26], [27, 38], [39, 44], [45, 50], [51, 54], [55, 59], [60, 65], [66, 73], [73, 74], [75, 81], [81, 82], [83, 93], [93, 94], [95, 99], [100, 104], [105, 108], [109, 113], [114, 119], [120, 123], [123, 124], [124, 126], [127, 128], [128, 138], [139, 148], [148, 149], [150, 157], [158, 164], [165, 173], [173, 174], [175, 181], [182, 194], [195, 203], [203, 204], [205, 209], [209, 210], [211, 213], [214, 218], [219, 222], [223, 228], [229, 234], [235, 237], [238, 241], [242, 245], [246, 250], [251, 253], [254, 257], [258, 263], [264, 269], [269, 270]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "published", "by"], "sentence-detokenized": "Association for Computational Linguistics, published by", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 52], [53, 55]]}
{"doc_key": "ai-test-57", "ner": [[3, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "a", "computerised", "face", "recognition", "system", ",", "each", "face", "is", "represented", "by", "a", "large", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In a computerised face recognition system, each face is represented by a large number of pixel values.", "token2charspan": [[0, 2], [3, 4], [5, 17], [18, 22], [23, 34], [35, 41], [41, 42], [43, 47], [48, 52], [53, 55], [56, 67], [68, 70], [71, 72], [73, 78], [79, 85], [86, 88], [89, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-58", "ner": [[5, 6, "person"], [13, 21, "organisation"], [22, 22, "country"], [25, 25, "person"], [35, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 13, 21, "role", "", false, false], [5, 6, 22, 22, "physical", "", false, false], [25, 25, 35, 37, "origin", "", false, false], [25, 25, 35, 37, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2002", ",", "his", "son", "Daniel", "Pearl", ",", "a", "journalist", "working", "for", "the", "Wall", "Street", "Journal", ",", "was", "kidnapped", "and", "murdered", "in", "Pakistan", ",", "prompting", "Judea", "and", "other", "family", "members", "and", "friends", "to", "create", "the", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "In 2002, his son Daniel Pearl, a journalist working for the Wall Street Journal, was kidnapped and murdered in Pakistan, prompting Judea and other family members and friends to create the Daniel Pearl Foundation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 23], [24, 29], [29, 30], [31, 32], [33, 43], [44, 51], [52, 55], [56, 59], [60, 64], [65, 71], [72, 79], [79, 80], [81, 84], [85, 94], [95, 98], [99, 107], [108, 110], [111, 119], [119, 120], [121, 130], [131, 136], [137, 140], [141, 146], [147, 153], [154, 161], [162, 165], [166, 173], [174, 176], [177, 183], [184, 187], [188, 194], [195, 200], [201, 211], [211, 212]]}
{"doc_key": "ai-test-59", "ner": [[4, 6, "organisation"], [17, 18, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 17, 18, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "late", "2006", ",", "Red", "Envelope", "Entertainment", "also", "expanded", "into", "producing", "original", "content", "with", "filmmakers", "such", "as", "John", "Waters", "."], "sentence-detokenized": "In late 2006, Red Envelope Entertainment also expanded into producing original content with filmmakers such as John Waters.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 26], [27, 40], [41, 45], [46, 54], [55, 59], [60, 69], [70, 78], [79, 86], [87, 91], [92, 102], [103, 107], [108, 110], [111, 115], [116, 122], [122, 123]]}
{"doc_key": "ai-test-60", "ner": [[6, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "building", "is", "now", "part", "of", "Beth", "Israel", "Deaconess", "Medical", "Center", "."], "sentence-detokenized": "The building is now part of Beth Israel Deaconess Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 32], [33, 39], [40, 49], [50, 57], [58, 64], [64, 65]]}
{"doc_key": "ai-test-61", "ner": [[16, 17, "field"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "common", "theme", "in", "this", "work", "is", "to", "adopt", "a", "character-theoretic", "perspective", "on", "issues", "related", "to", "artificial", "intelligence", "and", "knowledge", "representation", "."], "sentence-detokenized": "A common theme in this work is to adopt a character-theoretic perspective on issues related to artificial intelligence and knowledge representation.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 17], [18, 22], [23, 27], [28, 30], [31, 33], [34, 39], [40, 41], [42, 61], [62, 73], [74, 76], [77, 83], [84, 91], [92, 94], [95, 105], [106, 118], [119, 122], [123, 132], [133, 147], [147, 148]]}
{"doc_key": "ai-test-62", "ner": [[2, 4, "task"], [6, 9, "task"], [20, 21, "task"], [38, 39, "task"], [41, 42, "task"], [45, 47, "task"], [49, 49, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 4, 20, 21, "type-of", "", false, false], [2, 4, 45, 47, "compare", "", false, false], [2, 4, 45, 47, "opposite", "", false, false], [6, 9, 2, 4, "named", "", false, false], [38, 39, 45, 47, "part-of", "", false, false], [41, 42, 45, 47, "part-of", "", false, false], [45, 47, 20, 21, "type-of", "", false, false], [49, 49, 45, 47, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "term", "neural", "machine", "translation", "(", "NMT", ")", ",", "for", "example", ",", "emphasises", "the", "fact", "that", "deep", "learning", "-", "based", "machine", "translation", "methods", "directly", "learn", "sequence", "-", "to", "-", "sequence", "transformations", ",", "thus", "avoiding", "intermediate", "steps", "such", "as", "word", "alignment", "and", "language", "modelling", "used", "in", "statistical", "machine", "translation", "(", "SMT", ")", "."], "sentence-detokenized": "The term neural machine translation (NMT), for example, emphasises the fact that deep learning-based machine translation methods directly learn sequence-to-sequence transformations, thus avoiding intermediate steps such as word alignment and language modelling used in statistical machine translation (SMT).", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 23], [24, 35], [36, 37], [37, 40], [40, 41], [41, 42], [43, 46], [47, 54], [54, 55], [56, 66], [67, 70], [71, 75], [76, 80], [81, 85], [86, 94], [94, 95], [95, 100], [101, 108], [109, 120], [121, 128], [129, 137], [138, 143], [144, 152], [152, 153], [153, 155], [155, 156], [156, 164], [165, 180], [180, 181], [182, 186], [187, 195], [196, 208], [209, 214], [215, 219], [220, 222], [223, 227], [228, 237], [238, 241], [242, 250], [251, 260], [261, 265], [266, 268], [269, 280], [281, 288], [289, 300], [301, 302], [302, 305], [305, 306], [306, 307]]}
{"doc_key": "ai-test-63", "ner": [[4, 5, "field"], [10, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 10, 11, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "research", "in", "the", "WSD", "field", "is", "carried", "out", "using", "Word", "Net", "as", "a", "reference", "list", "of", "meanings", "."], "sentence-detokenized": "Most research in the WSD field is carried out using WordNet as a reference list of meanings.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 24], [25, 30], [31, 33], [34, 41], [42, 45], [46, 51], [52, 56], [56, 59], [60, 62], [63, 64], [65, 74], [75, 79], [80, 82], [83, 91], [91, 92]]}
{"doc_key": "ai-test-64", "ner": [[9, 10, "researcher"], [12, 13, "researcher"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Among", "his", "former", "PhD", "students", "and", "postdoctoral", "researchers", "are", "Richard", "Zemel", "and", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Among his former PhD students and postdoctoral researchers are Richard Zemel and Zoubin Ghahramani.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 20], [21, 29], [30, 33], [34, 46], [47, 58], [59, 62], [63, 70], [71, 76], [77, 80], [81, 87], [88, 98], [98, 99]]}
{"doc_key": "ai-test-65", "ner": [[7, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Each", "prediction", "result", "or", "instance", "in", "a", "confusion", "matrix", "represents", "a", "point", "in", "the", "ROC", "area", "."], "sentence-detokenized": "Each prediction result or instance in a confusion matrix represents a point in the ROC area.", "token2charspan": [[0, 4], [5, 15], [16, 22], [23, 25], [26, 34], [35, 37], [38, 39], [40, 49], [50, 56], [57, 67], [68, 69], [70, 75], [76, 78], [79, 82], [83, 86], [87, 91], [91, 92]]}
{"doc_key": "ai-test-66", "ner": [[3, 3, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [17, 18, "product"], [21, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 21, 23, "physical", "", false, false], [7, 8, 21, 23, "physical", "", false, false], [10, 11, 21, 23, "physical", "", false, false], [17, 18, 3, 3, "artifact", "", false, false], [17, 18, 7, 8, "artifact", "", false, false], [17, 18, 10, 11, "artifact", "", false, false], [17, 18, 21, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1997", ",", "Thrun", "and", "his", "colleagues", "Wolfram", "Burgard", "and", "Dieter", "Fox", "developed", "the", "world", "'s", "first", "robot", "guide", "in", "the", "Deutsches", "Museum", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "In 1997, Thrun and his colleagues Wolfram Burgard and Dieter Fox developed the world's first robot guide in the Deutsches Museum Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 18], [19, 22], [23, 33], [34, 41], [42, 49], [50, 53], [54, 60], [61, 64], [65, 74], [75, 78], [79, 84], [84, 86], [87, 92], [93, 98], [99, 104], [105, 107], [108, 111], [112, 121], [122, 128], [129, 133], [134, 135], [135, 139], [139, 140], [140, 141]]}
{"doc_key": "ai-test-67", "ner": [[0, 3, "product"], [7, 7, "misc"], [23, 26, "field"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 3, "part-of", "", false, false], [23, 26, 0, 3, "usage", "", false, false], [28, 29, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "with", "semantic", "relationships", "between", "words", "in", "more", "than", "200", "languages", ".", "It", "is", "mainly", "used", "for", "automatic", "processing", "of", "natural", "languages", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database with semantic relationships between words in more than 200 languages. It is mainly used for automatic processing of natural languages and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 34], [35, 43], [44, 57], [58, 65], [66, 71], [72, 74], [75, 79], [80, 84], [85, 88], [89, 98], [98, 99], [100, 102], [103, 105], [106, 112], [113, 117], [118, 121], [122, 131], [132, 142], [143, 145], [146, 153], [154, 163], [164, 167], [168, 178], [179, 191], [192, 204], [204, 205]]}
{"doc_key": "ai-test-68", "ner": [[5, 7, "field"], [12, 15, "conference"], [18, 26, "conference"], [28, 28, "conference"], [30, 30, "conference"], [38, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 15, 5, 7, "topic", "", false, false], [12, 15, 38, 39, "topic", "", false, false], [18, 26, 5, 7, "topic", "", false, false], [18, 26, 38, 39, "topic", "", false, false], [28, 28, 5, 7, "topic", "", false, false], [28, 28, 38, 39, "topic", "", false, false], [30, 30, 5, 7, "topic", "", false, false], [30, 30, 38, 39, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Conferences", "in", "the", "field", "of", "natural", "language", "processing", ",", "such", "as", "the", "Association", "for", "Computational", "Linguistics", ",", "the", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", "and", "HLT", ",", "are", "beginning", "to", "include", "papers", "on", "speech", "processing", "."], "sentence-detokenized": "Conferences in the field of natural language processing, such as the Association for Computational Linguistics, the North American Chapter of the Association for Computational Linguistics, EMNLP and HLT, are beginning to include papers on speech processing.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 24], [25, 27], [28, 35], [36, 44], [45, 55], [55, 56], [57, 61], [62, 64], [65, 68], [69, 80], [81, 84], [85, 98], [99, 110], [110, 111], [112, 115], [116, 121], [122, 130], [131, 138], [139, 141], [142, 145], [146, 157], [158, 161], [162, 175], [176, 187], [187, 188], [189, 194], [195, 198], [199, 202], [202, 203], [204, 207], [208, 217], [218, 220], [221, 228], [229, 235], [236, 238], [239, 245], [246, 256], [256, 257]]}
{"doc_key": "ai-test-69", "ner": [[20, 22, "misc"], [34, 35, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "set", "of", "Java", "programs", "uses", "the", "dictionary", "to", "process", "the", "variations", "in", "biomedical", "texts", "by", "relating", "words", "to", "their", "parts", "of", "speech", ",", "which", "can", "be", "helpful", "when", "searching", "the", "web", "or", "an", "electronic", "journal", "."], "sentence-detokenized": "A set of Java programs uses the dictionary to process the variations in biomedical texts by relating words to their parts of speech, which can be helpful when searching the web or an electronic journal.", "token2charspan": [[0, 1], [2, 5], [6, 8], [9, 13], [14, 22], [23, 27], [28, 31], [32, 42], [43, 45], [46, 53], [54, 57], [58, 68], [69, 71], [72, 82], [83, 88], [89, 91], [92, 100], [101, 106], [107, 109], [110, 115], [116, 121], [122, 124], [125, 131], [131, 132], [133, 138], [139, 142], [143, 145], [146, 153], [154, 158], [159, 168], [169, 172], [173, 176], [177, 179], [180, 182], [183, 193], [194, 201], [201, 202]]}
{"doc_key": "ai-test-70", "ner": [[7, 7, "algorithm"], [9, 9, "algorithm"], [11, 11, "algorithm"], [13, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "many", "newer", "algorithms", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", "and", "others", "."], "sentence-detokenized": "There are many newer algorithms such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost and others.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 20], [21, 31], [32, 36], [37, 39], [40, 47], [47, 48], [49, 59], [59, 60], [61, 71], [71, 72], [73, 80], [80, 81], [82, 91], [92, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-test-71", "ner": [[8, 8, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "of", "an", "implementation", "in", "Python", ":"], "sentence-detokenized": "This is an example of an implementation in Python:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 24], [25, 39], [40, 42], [43, 49], [49, 50]]}
{"doc_key": "ai-test-72", "ner": [[0, 1, "organisation"], [7, 8, "task"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Mattel", "'s", "Intellivision", "game", "console", "offered", "the", "Intellivoice", "Voice", "Synthesis", "module", "in", "1982", "."], "sentence-detokenized": "Mattel's Intellivision game console offered the Intellivoice Voice Synthesis module in 1982.", "token2charspan": [[0, 6], [6, 8], [9, 22], [23, 27], [28, 35], [36, 43], [44, 47], [48, 60], [61, 66], [67, 76], [77, 83], [84, 86], [87, 91], [91, 92]]}
{"doc_key": "ai-test-73", "ner": [[5, 6, "task"], [9, 15, "task"], [17, 18, "field"], [20, 22, "task"], [25, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 15, 5, 6, "part-of", "", false, false], [17, 18, 5, 6, "part-of", "", false, false], [20, 22, 5, 6, "part-of", "", false, false], [25, 29, 20, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "has", "also", "worked", "on", "machine", "translation", ",", "both", "high", "-", "precision", "knowledge", "-", "based", "MT", "and", "machine", "learning", "for", "statistical", "machine", "translation", "(", "e.g.", "generalised", "example", "-", "based", "MT", ")", "."], "sentence-detokenized": "He has also worked on machine translation, both high-precision knowledge-based MT and machine learning for statistical machine translation (e.g. generalised example-based MT).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 21], [22, 29], [30, 41], [41, 42], [43, 47], [48, 52], [52, 53], [53, 62], [63, 72], [72, 73], [73, 78], [79, 81], [82, 85], [86, 93], [94, 102], [103, 106], [107, 118], [119, 126], [127, 138], [139, 140], [140, 144], [145, 156], [157, 164], [164, 165], [165, 170], [171, 173], [173, 174], [174, 175]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [7, 7, "misc"], [22, 23, "algorithm"], [25, 26, "field"], [28, 29, "field"], [31, 31, "field"], [33, 34, "field"], [36, 36, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 22, 23, "general-affiliation", "", false, false], [0, 1, 25, 26, "general-affiliation", "", false, false], [0, 1, 28, 29, "general-affiliation", "", false, false], [0, 1, 31, 31, "general-affiliation", "", false, false], [0, 1, 33, 34, "general-affiliation", "", false, false], [0, 1, 36, 36, "general-affiliation", "", false, false], [7, 7, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "commonly", "referred", "to", "as", "Mathematica", ")", "is", "a", "modern", "technical", "computing", "system", "that", "spans", "most", "engineering", "fields", "-", "including", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "computer", "science", ",", "visualizations", "and", "more", "."], "sentence-detokenized": "Wolfram Mathematica (commonly referred to as Mathematica) is a modern technical computing system that spans most engineering fields - including neural networks, machine learning, image processing, geometry, computer science, visualizations and more.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 29], [30, 38], [39, 41], [42, 44], [45, 56], [56, 57], [58, 60], [61, 62], [63, 69], [70, 79], [80, 89], [90, 96], [97, 101], [102, 107], [108, 112], [113, 124], [125, 131], [132, 133], [134, 143], [144, 150], [151, 159], [159, 160], [161, 168], [169, 177], [177, 178], [179, 184], [185, 195], [195, 196], [197, 205], [205, 206], [207, 215], [216, 223], [223, 224], [225, 239], [240, 243], [244, 248], [248, 249]]}
{"doc_key": "ai-test-75", "ner": [[2, 6, "product"], [10, 11, "researcher"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 2, 6, "type-of", "", false, false], [17, 17, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "digitally", "controlled", "and", "programmable", "robot", "was", "invented", "by", "George", "Devol", "in", "1954", "and", "was", "called", "Unimate", "."], "sentence-detokenized": "The first digitally controlled and programmable robot was invented by George Devol in 1954 and was called Unimate.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 30], [31, 34], [35, 47], [48, 53], [54, 57], [58, 66], [67, 69], [70, 76], [77, 82], [83, 85], [86, 90], [91, 94], [95, 98], [99, 105], [106, 113], [113, 114]]}
{"doc_key": "ai-test-76", "ner": [[1, 1, "algorithm"], [3, 3, "algorithm"], [18, 19, "task"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 3, 3, "compare", "", false, false], [3, 3, 18, 19, "general-affiliation", "", false, false], [3, 3, 21, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Like", "DBNs", ",", "DBMs", "can", "learn", "complex", "and", "abstract", "internal", "representations", "of", "the", "input", "to", "tasks", "such", "as", "object", "recognition", "or", "speech", "recognition", ",", "using", "limited", ",", "labeled", "data", "to", "fine", "-", "tune", "the", "representations", "built", "using", "a", "large", "set", "of", "unlabeled", "sensory", "input", "data", "."], "sentence-detokenized": "Like DBNs, DBMs can learn complex and abstract internal representations of the input to tasks such as object recognition or speech recognition, using limited, labeled data to fine-tune the representations built using a large set of unlabeled sensory input data.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 15], [16, 19], [20, 25], [26, 33], [34, 37], [38, 46], [47, 55], [56, 71], [72, 74], [75, 78], [79, 84], [85, 87], [88, 93], [94, 98], [99, 101], [102, 108], [109, 120], [121, 123], [124, 130], [131, 142], [142, 143], [144, 149], [150, 157], [157, 158], [159, 166], [167, 171], [172, 174], [175, 179], [179, 180], [180, 184], [185, 188], [189, 204], [205, 210], [211, 216], [217, 218], [219, 224], [225, 228], [229, 231], [232, 241], [242, 249], [250, 255], [256, 260], [260, 261]]}
{"doc_key": "ai-test-77", "ner": [[5, 10, "task"], [14, 14, "conference"], [16, 16, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 5, 10, "topic", "", false, false], [16, 16, 5, 10, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Scientific", "conferences", "where", "work", "on", "vision", "-", "based", "activity", "recognition", "is", "frequently", "presented", "are", "ICCV", "and", "CVPR", "."], "sentence-detokenized": "Scientific conferences where work on vision-based activity recognition is frequently presented are ICCV and CVPR.", "token2charspan": [[0, 10], [11, 22], [23, 28], [29, 33], [34, 36], [37, 43], [43, 44], [44, 49], [50, 58], [59, 70], [71, 73], [74, 84], [85, 94], [95, 98], [99, 103], [104, 107], [108, 112], [112, 113]]}
{"doc_key": "ai-test-78", "ner": [[1, 1, "field"], [4, 5, "algorithm"], [16, 17, "metrics"], [19, 21, "metrics"], [23, 23, "metrics"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6], "relations": [[4, 5, 1, 1, "part-of", "", false, false], [4, 5, 16, 17, "related-to", "finds", false, false], [4, 5, 19, 21, "related-to", "finds", false, false], [4, 5, 38, 38, "related-to", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5], "sentence": ["In", "statistics", ",", "an", "expectation", "-maximization", "(", "EM", ")", "algorithm", "is", "an", "iterative", "method", "for", "finding", "maximum", "likelihood", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "estimates", "of", "parameters", "in", "statistical", "models", ",", "where", "the", "model", "depends", "on", "unobserved", "latent", "variables", "."], "sentence-detokenized": "In statistics, an expectation-maximization (EM) algorithm is an iterative method for finding maximum likelihood or maximum a posteriori (MAP) estimates of parameters in statistical models, where the model depends on unobserved latent variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 17], [18, 29], [29, 42], [43, 44], [44, 46], [46, 47], [48, 57], [58, 60], [61, 63], [64, 73], [74, 80], [81, 84], [85, 92], [93, 100], [101, 111], [112, 114], [115, 122], [123, 124], [125, 135], [136, 137], [137, 140], [140, 141], [142, 151], [152, 154], [155, 165], [166, 168], [169, 180], [181, 187], [187, 188], [189, 194], [195, 198], [199, 204], [205, 212], [213, 215], [216, 226], [227, 233], [234, 243], [243, 244]]}
{"doc_key": "ai-test-79", "ner": [[7, 11, "metrics"], [14, 16, "metrics"], [17, 21, "metrics"], [23, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 16, 7, 11, "named", "", false, false], [23, 23, 17, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Similarly", ",", "investigators", "sometimes", "report", "both", "the", "number", "of", "false", "positive", "responses", "(", "FPR", ")", "and", "the", "number", "of", "false", "negative", "responses", "(", "FNR", ")", "."], "sentence-detokenized": "Similarly, investigators sometimes report both the number of false positive responses (FPR) and the number of false negative responses (FNR).", "token2charspan": [[0, 9], [9, 10], [11, 24], [25, 34], [35, 41], [42, 46], [47, 50], [51, 57], [58, 60], [61, 66], [67, 75], [76, 85], [86, 87], [87, 90], [90, 91], [92, 95], [96, 99], [100, 106], [107, 109], [110, 115], [116, 124], [125, 134], [135, 136], [136, 139], [139, 140], [140, 141]]}
{"doc_key": "ai-test-80", "ner": [[6, 11, "metrics"], [14, 14, "field"], [17, 18, "metrics"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 14, 6, 11, "usage", "", false, false], [21, 22, 17, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "concept", "is", "similar", "to", "the", "signal", "-", "to", "-", "noise", "ratio", "used", "in", "science", "and", "the", "confusion", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "The concept is similar to the signal-to-noise ratio used in science and the confusion matrix used in artificial intelligence.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 25], [26, 29], [30, 36], [36, 37], [37, 39], [39, 40], [40, 45], [46, 51], [52, 56], [57, 59], [60, 67], [68, 71], [72, 75], [76, 85], [86, 92], [93, 97], [98, 100], [101, 111], [112, 124], [124, 125]]}
{"doc_key": "ai-test-81", "ner": [[5, 6, "field"], [11, 12, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [31, 34, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 11, 12, "general-affiliation", "", false, false], [5, 6, 18, 19, "general-affiliation", "", false, false], [5, 6, 21, 22, "general-affiliation", "", false, false], [31, 34, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Code", "of", "Ethics", "for", "Human", "Augmentation", ",", "originally", "launched", "by", "Steve", "Mann", "in", "2004", "and", "refined", "with", "Ray", "Kurzweil", "and", "Marvin", "Minsky", "in", "2013", ",", "was", "finally", "ratified", "at", "the", "Virtual", "Reality", "Toronto", "conference", "on", "25", "June", "2017", "."], "sentence-detokenized": "The Code of Ethics for Human Augmentation, originally launched by Steve Mann in 2004 and refined with Ray Kurzweil and Marvin Minsky in 2013, was finally ratified at the Virtual Reality Toronto conference on 25 June 2017.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 18], [19, 22], [23, 28], [29, 41], [41, 42], [43, 53], [54, 62], [63, 65], [66, 71], [72, 76], [77, 79], [80, 84], [85, 88], [89, 96], [97, 101], [102, 105], [106, 114], [115, 118], [119, 125], [126, 132], [133, 135], [136, 140], [140, 141], [142, 145], [146, 153], [154, 162], [163, 165], [166, 169], [170, 177], [178, 185], [186, 193], [194, 204], [205, 207], [208, 210], [211, 215], [216, 220], [220, 221]]}
{"doc_key": "ai-test-82", "ner": [[3, 5, "person"], [11, 13, "organisation"], [19, 20, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 11, 13, "role", "directed_for", false, false], [3, 5, 19, 20, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", ",", "Walter", "R.", "Booth", "directed", "ten", "films", "for", "the", "British", "cinema", "label", ",", "probably", "in", "collaboration", "with", "Cecil", "Hepworth", "."], "sentence-detokenized": "In 1913, Walter R. Booth directed ten films for the British cinema label, probably in collaboration with Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 18], [19, 24], [25, 33], [34, 37], [38, 43], [44, 47], [48, 51], [52, 59], [60, 66], [67, 72], [72, 73], [74, 82], [83, 85], [86, 99], [100, 104], [105, 110], [111, 119], [119, 120]]}
{"doc_key": "ai-test-83", "ner": [[16, 16, "location"], [13, 14, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 16, 16, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "unveiled", "their", "new", "robot", "in", "1961", "at", "a", "trade", "show", "at", "the", "Cow", "Palace", "in", "Chicago", "."], "sentence-detokenized": "They unveiled their new robot in 1961 at a trade show at the Cow Palace in Chicago.", "token2charspan": [[0, 4], [5, 13], [14, 19], [20, 23], [24, 29], [30, 32], [33, 37], [38, 40], [41, 42], [43, 48], [49, 53], [54, 56], [57, 60], [61, 64], [65, 71], [72, 74], [75, 82], [82, 83]]}
{"doc_key": "ai-test-84", "ner": [[9, 10, "field"], [14, 17, "field"]], "ner_mapping_to_source": [2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "chatbot", "applications", "use", "extensive", "word", "classification", "processes", ",", "natural", "language", "processors", "and", "sophisticated", "artificial", "intelligence", ",", "while", "others", "simply", "search", "for", "common", "keywords", "and", "generate", "answers", "using", "common", "phrases", "retrieved", "from", "an", "associated", "library", "or", "database", "."], "sentence-detokenized": "Some chatbot applications use extensive word classification processes, natural language processors and sophisticated artificial intelligence, while others simply search for common keywords and generate answers using common phrases retrieved from an associated library or database.", "token2charspan": [[0, 4], [5, 12], [13, 25], [26, 29], [30, 39], [40, 44], [45, 59], [60, 69], [69, 70], [71, 78], [79, 87], [88, 98], [99, 102], [103, 116], [117, 127], [128, 140], [140, 141], [142, 147], [148, 154], [155, 161], [162, 168], [169, 172], [173, 179], [180, 188], [189, 192], [193, 201], [202, 209], [210, 215], [216, 222], [223, 230], [231, 240], [241, 245], [246, 248], [249, 259], [260, 267], [268, 270], [271, 279], [279, 280]]}
{"doc_key": "ai-test-85", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "WaveNet", "model", "proposed", "in", "2016", "gives", "good", "results", "in", "terms", "of", "speech", "quality", "."], "sentence-detokenized": "The WaveNet model proposed in 2016 gives good results in terms of speech quality.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 40], [41, 45], [46, 53], [54, 56], [57, 62], [63, 65], [66, 72], [73, 80], [80, 81]]}
{"doc_key": "ai-test-86", "ner": [[4, 4, "product"], [6, 7, "misc"], [9, 10, "misc"], [12, 13, "misc"], [16, 19, "misc"], [22, 24, "organisation"], [26, 26, "organisation"], [28, 29, "organisation"], [32, 32, "organisation"], [35, 38, "organisation"], [41, 42, "organisation"], [44, 44, "organisation"], [47, 49, "organisation"], [51, 51, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 4, 6, 7, "general-affiliation", "", false, false], [4, 4, 9, 10, "general-affiliation", "", false, false], [4, 4, 12, 13, "general-affiliation", "", false, false], [4, 4, 16, 19, "general-affiliation", "", false, false], [22, 24, 4, 4, "usage", "", false, false], [26, 26, 4, 4, "usage", "", false, false], [28, 29, 4, 4, "usage", "", false, false], [32, 32, 4, 4, "usage", "", false, false], [35, 38, 4, 4, "usage", "", false, false], [41, 42, 4, 4, "usage", "", false, false], [44, 44, 4, 4, "usage", "", false, false], [47, 49, 4, 4, "usage", "", false, false], [51, 51, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organizations", "known", "to", "use", "ALE", "for", "disaster", "management", ",", "disaster", "relief", ",", "routine", "communications", ",", "or", "response", "to", "extraordinary", "situations", ":", "the", "American", "Red", "Cross", ",", "FEMA", ",", "disaster", "medical", "groups", ",", "NATO", ",", "the", "Federal", "Bureau", "of", "Investigation", ",", "the", "United", "Nations", ",", "AT&T", ",", "the", "Civil", "Air", "Patrol", "(", "ARES", ")", "."], "sentence-detokenized": "Organizations known to use ALE for disaster management, disaster relief, routine communications, or response to extraordinary situations: the American Red Cross, FEMA, disaster medical groups, NATO, the Federal Bureau of Investigation, the United Nations, AT&T, the Civil Air Patrol (ARES).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 30], [31, 34], [35, 43], [44, 54], [54, 55], [56, 64], [65, 71], [71, 72], [73, 80], [81, 95], [95, 96], [97, 99], [100, 108], [109, 111], [112, 125], [126, 136], [136, 137], [138, 141], [142, 150], [151, 154], [155, 160], [160, 161], [162, 166], [166, 167], [168, 176], [177, 184], [185, 191], [191, 192], [193, 197], [197, 198], [199, 202], [203, 210], [211, 217], [218, 220], [221, 234], [234, 235], [236, 239], [240, 246], [247, 254], [254, 255], [256, 260], [260, 261], [262, 265], [266, 271], [272, 275], [276, 282], [283, 284], [284, 288], [288, 289], [289, 290]]}
{"doc_key": "ai-test-87", "ner": [[2, 3, "algorithm"], [15, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", "the", "Kronecker", "delta", "is", "used", "for", "simplicity", "(", "cf", ".", "the", "derivative", "of", "a", "sigmoid", "function", ",", "which", "is", "expressed", "via", "the", "function", "itself", ")", "."], "sentence-detokenized": "Here the Kronecker delta is used for simplicity (cf. the derivative of a sigmoid function, which is expressed via the function itself).", "token2charspan": [[0, 4], [5, 8], [9, 18], [19, 24], [25, 27], [28, 32], [33, 36], [37, 47], [48, 49], [49, 51], [51, 52], [53, 56], [57, 67], [68, 70], [71, 72], [73, 80], [81, 89], [89, 90], [91, 96], [97, 99], [100, 109], [110, 113], [114, 117], [118, 126], [127, 133], [133, 134], [134, 135]]}
{"doc_key": "ai-test-88", "ner": [[11, 12, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "theory", "is", "based", "on", "philosophical", "foundations", "and", "was", "founded", "by", "Ray", "Solomonoff", "around", "1960", ".", "Samuel", "Rathmanner", "and", "Marcus", "Hutter", "."], "sentence-detokenized": "The theory is based on philosophical foundations and was founded by Ray Solomonoff around 1960. Samuel Rathmanner and Marcus Hutter.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 36], [37, 48], [49, 52], [53, 56], [57, 64], [65, 67], [68, 71], [72, 82], [83, 89], [90, 94], [94, 95], [96, 102], [103, 113], [114, 117], [118, 124], [125, 131], [131, 132]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [10, 11, "misc"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 11, "type-of", "", false, false], [0, 0, 14, 15, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "a", "freely", "accessible", "database", "originally", "designed", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "was", "expanded", "to", "include", "definitions", "and", "is", "now", "also", "considered", "a", "dictionary", "."], "sentence-detokenized": "WordNet, a freely accessible database originally designed as a semantic network based on psycholinguistic principles, was expanded to include definitions and is now also considered a dictionary.", "token2charspan": [[0, 7], [7, 8], [9, 10], [11, 17], [18, 28], [29, 37], [38, 48], [49, 57], [58, 60], [61, 62], [63, 71], [72, 79], [80, 85], [86, 88], [89, 105], [106, 116], [116, 117], [118, 121], [122, 130], [131, 133], [134, 141], [142, 153], [154, 157], [158, 160], [161, 164], [165, 169], [170, 180], [181, 182], [183, 193], [193, 194]]}
{"doc_key": "ai-test-90", "ner": [[2, 3, "field"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 2, 3, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Advances", "in", "computational", "imaging", "research", "are", "presented", "in", "several", "places", ",", "including", "SIGGRAPH", "and", "SIGGRAPH", "publications", "."], "sentence-detokenized": "Advances in computational imaging research are presented in several places, including SIGGRAPH and SIGGRAPH publications.", "token2charspan": [[0, 8], [9, 11], [12, 25], [26, 33], [34, 42], [43, 46], [47, 56], [57, 59], [60, 67], [68, 74], [74, 75], [76, 85], [86, 94], [95, 98], [99, 107], [108, 120], [120, 121]]}
{"doc_key": "ai-test-91", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "considered", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multi-class", "classification", "."], "sentence-detokenized": "Classification can be considered as two separate problems - binary classification and multi-class classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 97], [98, 112], [112, 113]]}
{"doc_key": "ai-test-92", "ner": [[12, 12, "algorithm"], [17, 17, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 12, 12, "type-of", "", false, false], [21, 21, 17, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Advanced", "gene", "finders", "for", "both", "prokaryotic", "and", "eukaryotic", "genomes", "typically", "use", "complex", "probabilistic", "models", ",", "such", "as", "hidden", "Markov", "models", "(", "HMMs", ")", ",", "to", "combine", "information", "from", "a", "variety", "of", "signal", "and", "content", "measurements", "."], "sentence-detokenized": "Advanced gene finders for both prokaryotic and eukaryotic genomes typically use complex probabilistic models, such as hidden Markov models (HMMs), to combine information from a variety of signal and content measurements.", "token2charspan": [[0, 8], [9, 13], [14, 21], [22, 25], [26, 30], [31, 42], [43, 46], [47, 57], [58, 65], [66, 75], [76, 79], [80, 87], [88, 101], [102, 108], [108, 109], [110, 114], [115, 117], [118, 124], [125, 131], [132, 138], [139, 140], [140, 144], [144, 145], [145, 146], [147, 149], [150, 157], [158, 169], [170, 174], [175, 176], [177, 184], [185, 187], [188, 194], [195, 198], [199, 206], [207, 219], [219, 220]]}
{"doc_key": "ai-test-93", "ner": [[0, 0, "misc"], [5, 7, "field"], [9, 10, "algorithm"], [13, 14, "algorithm"], [17, 17, "algorithm"], [27, 28, "algorithm"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [[17, 17, 13, 14, "named", "", false, false]], "relations_mapping_to_source": [4], "sentence": ["Neuroevolution", "is", "a", "form", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "generate", "artificial", "neural", "networks", "(", "ANNs", ")", ",", "parameters", ",", "topology", "and", "rules", ".", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuroevolution is a form of artificial intelligence that uses evolutionary algorithms to generate artificial neural networks (ANNs), parameters, topology and rules. and evolutionary robotics.", "token2charspan": [[0, 14], [15, 17], [18, 19], [20, 24], [25, 27], [28, 38], [39, 51], [52, 56], [57, 61], [62, 74], [75, 85], [86, 88], [89, 97], [98, 108], [109, 115], [116, 124], [125, 126], [126, 130], [130, 131], [131, 132], [133, 143], [143, 144], [145, 153], [154, 157], [158, 163], [163, 164], [165, 168], [169, 181], [182, 190], [190, 191]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [6, 7, "metrics"], [8, 8, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "IBM", "proposed", "and", "implemented", "the", "BLEU", "system", "Papineni", "et", "al", "."], "sentence-detokenized": "Since IBM proposed and implemented the BLEU system Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 34], [35, 38], [39, 43], [44, 50], [51, 59], [60, 62], [63, 65], [65, 66]]}
{"doc_key": "ai-test-95", "ner": [[11, 17, "conference"], [19, 19, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 19, 11, 17, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "experts", "participated", "in", "a", "conference", "organised", "by", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "to", "discuss", "whether", "computers", "and", "robots", "could", "become", "autonomous", "and", "to", "what", "extent", "these", "abilities", "could", "pose", "a", "threat", "or", "a", "danger", "."], "sentence-detokenized": "In 2009, experts participated in a conference organised by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether computers and robots could become autonomous and to what extent these abilities could pose a threat or a danger.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 29], [30, 32], [33, 34], [35, 45], [46, 55], [56, 58], [59, 62], [63, 74], [75, 78], [79, 82], [83, 94], [95, 97], [98, 108], [109, 121], [122, 123], [123, 127], [127, 128], [129, 131], [132, 139], [140, 147], [148, 157], [158, 161], [162, 168], [169, 174], [175, 181], [182, 192], [193, 196], [197, 199], [200, 204], [205, 211], [212, 217], [218, 227], [228, 233], [234, 238], [239, 240], [241, 247], [248, 250], [251, 252], [253, 259], [259, 260]]}
{"doc_key": "ai-test-96", "ner": [[26, 28, "metrics"], [29, 31, "researcher"], [33, 34, "researcher"], [36, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[36, 41, 26, 28, "topic", "", false, false], [36, 41, 29, 31, "artifact", "", false, false], [36, 41, 33, 34, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["After", "boosting", ",", "a", "classifier", "constructed", "from", "200", "features", "can", "provide", "a", "detection", "rate", "of", "95", "%", "at", "a", "^", "{", "-", "5", "}", "/", "math", "FALSE", "positive", "rate", ".P", ".", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "After boosting, a classifier constructed from 200 features can provide a detection rate of 95% at a ^ {-5} / math FALSE positive rate .P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 17], [18, 28], [29, 40], [41, 45], [46, 49], [50, 58], [59, 62], [63, 70], [71, 72], [73, 82], [83, 87], [88, 90], [91, 93], [93, 94], [95, 97], [98, 99], [100, 101], [102, 103], [103, 104], [104, 105], [105, 106], [107, 108], [109, 113], [114, 119], [120, 128], [129, 133], [134, 136], [136, 137], [138, 143], [143, 144], [145, 147], [148, 153], [153, 154], [155, 161], [162, 166], [166, 167], [167, 171], [172, 178], [179, 188], [188, 189], [190, 194], [194, 195]]}
{"doc_key": "ai-test-97", "ner": [[9, 9, "organisation"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "site", "was", "originally", "Perl", "-", "based", ",", "but", "IMDb", "no", "longer", "reveals", "which", "software", "it", "uses", "for", "security", "reasons", "."], "sentence-detokenized": "The site was originally Perl-based, but IMDb no longer reveals which software it uses for security reasons.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 23], [24, 28], [28, 29], [29, 34], [34, 35], [36, 39], [40, 44], [45, 47], [48, 54], [55, 62], [63, 68], [69, 77], [78, 80], [81, 85], [86, 89], [90, 98], [99, 106], [106, 107]]}
{"doc_key": "ai-test-98", "ner": [[10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "start", "-", "up", "company", "was", "founded", "in", "2010", "by", "Demis", "Hassabis", ",", "Shane", "Legg", "and", "Mustafa", "Suleyman", "."], "sentence-detokenized": "The start-up company was founded in 2010 by Demis Hassabis, Shane Legg and Mustafa Suleyman.", "token2charspan": [[0, 3], [4, 9], [9, 10], [10, 12], [13, 20], [21, 24], [25, 32], [33, 35], [36, 40], [41, 43], [44, 49], [50, 58], [58, 59], [60, 65], [66, 70], [71, 74], [75, 82], [83, 91], [91, 92]]}
{"doc_key": "ai-test-99", "ner": [[3, 4, "misc"], [7, 9, "metrics"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 3, 4, "type-of", "", false, false], [22, 23, 3, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "very", "common", "loss", "functions", "are", "the", "mean", "square", "error", ",", "mathL", "(", "a", ")", "=", "a^2", "/", "math", ",", "and", "the", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Two very common loss functions are the mean square error, mathL (a) = a^2/math, and the absolute loss, mathL (a) = | a |/math.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 20], [21, 30], [31, 34], [35, 38], [39, 43], [44, 50], [51, 56], [56, 57], [58, 63], [64, 65], [65, 66], [66, 67], [68, 69], [70, 73], [73, 74], [74, 78], [78, 79], [80, 83], [84, 87], [88, 96], [97, 101], [101, 102], [103, 108], [109, 110], [110, 111], [111, 112], [113, 114], [115, 116], [117, 118], [119, 120], [120, 121], [121, 125], [125, 126]]}
{"doc_key": "ai-test-100", "ner": [[3, 5, "algorithm"], [13, 15, "algorithm"], [17, 17, "algorithm"], [20, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 13, 15, "type-of", "example_of", false, false], [13, 15, 20, 22, "related-to", "", false, false], [17, 17, 13, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "soft", "-margin", "support", "vector", "machine", "described", "above", "is", "an", "example", "of", "an", "empirical", "risk", "minimisation", "(", "ERM", ")", "for", "joi", "nt", "loss", "."], "sentence-detokenized": "The soft-margin support vector machine described above is an example of an empirical risk minimisation (ERM) for joint loss.", "token2charspan": [[0, 3], [4, 8], [8, 15], [16, 23], [24, 30], [31, 38], [39, 48], [49, 54], [55, 57], [58, 60], [61, 68], [69, 71], [72, 74], [75, 84], [85, 89], [90, 102], [103, 104], [104, 107], [107, 108], [109, 112], [113, 116], [116, 118], [119, 123], [123, 124]]}
{"doc_key": "ai-test-101", "ner": [[11, 11, "task"], [0, 2, "task"], [22, 22, "organisation"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[0, 2, 11, 11, "type-of", "", false, false], [22, 22, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["Neural", "machine", "translation", ",", "a", "deep", "learning", "-", "based", "approach", "to", "MT", ",", "has", "made", "rapid", "progress", "in", "recent", "years", ",", "and", "Google", "has", "announced", "that", "its", "translation", "services", "now", "use", "this", "technology", "in", "place", "of", "previous", "statistical", "methods", "."], "sentence-detokenized": "Neural machine translation, a deep learning-based approach to MT, has made rapid progress in recent years, and Google has announced that its translation services now use this technology in place of previous statistical methods.", "token2charspan": [[0, 6], [7, 14], [15, 26], [26, 27], [28, 29], [30, 34], [35, 43], [43, 44], [44, 49], [50, 58], [59, 61], [62, 64], [64, 65], [66, 69], [70, 74], [75, 80], [81, 89], [90, 92], [93, 99], [100, 105], [105, 106], [107, 110], [111, 117], [118, 121], [122, 131], [132, 136], [137, 140], [141, 152], [153, 161], [162, 165], [166, 169], [170, 174], [175, 185], [186, 188], [189, 194], [195, 197], [198, 206], [207, 218], [219, 226], [226, 227]]}
{"doc_key": "ai-test-102", "ner": [[14, 14, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "tends", "to", "give", "very", "large", "performance", "increases", "when", "working", "with", "large", "corpora", "like", "WordNet", "."], "sentence-detokenized": "This tends to give very large performance increases when working with large corpora like WordNet.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 18], [19, 23], [24, 29], [30, 41], [42, 51], [52, 56], [57, 64], [65, 69], [70, 75], [76, 83], [84, 88], [89, 96], [96, 97]]}
{"doc_key": "ai-test-103", "ner": [[0, 1, "task"], [5, 5, "field"], [18, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 18, 20, "part-of", "", false, false], [18, 20, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Face", "detection", "is", "used", "in", "biometrics", ",", "often", "as", "part", "of", "(", "or", "in", "conjunction", "with", ")", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Face detection is used in biometrics, often as part of (or in conjunction with) a facial recognition system.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 22], [23, 25], [26, 36], [36, 37], [38, 43], [44, 46], [47, 51], [52, 54], [55, 56], [56, 58], [59, 61], [62, 73], [74, 78], [78, 79], [80, 81], [82, 88], [89, 100], [101, 107], [107, 108]]}
{"doc_key": "ai-test-104", "ner": [[2, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["trained", "using", "maximum", "likelihood", "estimation", "."], "sentence-detokenized": "trained using maximum likelihood estimation.", "token2charspan": [[0, 7], [8, 13], [14, 21], [22, 32], [33, 43], [43, 44]]}
{"doc_key": "ai-test-105", "ner": [[2, 2, "country"], [4, 8, "organisation"], [12, 12, "location"], [14, 14, "country"], [16, 19, "organisation"], [21, 21, "country"], [27, 27, "organisation"], [32, 36, "organisation"], [38, 38, "country"], [48, 51, "organisation"], [53, 53, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[4, 8, 12, 12, "physical", "", false, false], [12, 12, 14, 14, "physical", "", false, false], [16, 19, 21, 21, "physical", "", false, false], [32, 36, 38, 38, "physical", "", false, false], [48, 51, 53, 53, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd.", "in", "Thailand", ",", "Komatsu", "(", "Shanghai", ")", "Ltd.", "in", "1996", "in", "Shanghai", ",", "China", ",", "Industrial", "Power", "Alliance", "Ltd.", "in", "Japan", ",", "a", "joint", "venture", "with", "Cummins", ",", "in", "1998", ",", "L", "&", "T-", "Komatsu", "Limited", "in", "India", "in", "1998", "(", "shares", "sold", "in", "2013", ")", "and", "Komatsu", "Brasil", "International", "Ltda.", "in", "Brazil", "in", "1998", "."], "sentence-detokenized": "Ltd. in Thailand, Komatsu (Shanghai) Ltd. in 1996 in Shanghai, China, Industrial Power Alliance Ltd. in Japan, a joint venture with Cummins, in 1998, L & T-Komatsu Limited in India in 1998 (shares sold in 2013) and Komatsu Brasil International Ltda. in Brazil in 1998.", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 25], [26, 27], [27, 35], [35, 36], [37, 41], [42, 44], [45, 49], [50, 52], [53, 61], [61, 62], [63, 68], [68, 69], [70, 80], [81, 86], [87, 95], [96, 100], [101, 103], [104, 109], [109, 110], [111, 112], [113, 118], [119, 126], [127, 131], [132, 139], [139, 140], [141, 143], [144, 148], [148, 149], [150, 151], [152, 153], [154, 156], [156, 163], [164, 171], [172, 174], [175, 180], [181, 183], [184, 188], [189, 190], [190, 196], [197, 201], [202, 204], [205, 209], [209, 210], [211, 214], [215, 222], [223, 229], [230, 243], [244, 249], [250, 252], [253, 259], [260, 262], [263, 267], [267, 268]]}
{"doc_key": "ai-test-106", "ner": [[0, 0, "organisation"], [4, 6, "misc"], [11, 12, "person"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[11, 12, 0, 0, "physical", "", false, false], [11, 12, 4, 6, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["dgp", "also", "occasionally", "hosts", "artists", "in", "residence", "(", "e.g.", "Oscar", "winner", "Chris", "Landreth", ")", "."], "sentence-detokenized": "dgp also occasionally hosts artists in residence (e.g. Oscar winner Chris Landreth).", "token2charspan": [[0, 3], [4, 8], [9, 21], [22, 27], [28, 35], [36, 38], [39, 48], [49, 50], [50, 54], [55, 60], [61, 67], [68, 73], [74, 82], [82, 83], [83, 84]]}
{"doc_key": "ai-test-107", "ner": [[6, 8, "misc"], [10, 12, "misc"], [14, 17, "misc"], [21, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "currently", "comprises", "four", "sub-competitions", "-", "RoboMaster", "Robotics", "Competition", ",", "RoboMaster", "Technical", "Challenge", ",", "ICRA", "RoboMaster", "AI", "Challenge", "and", "the", "new", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "It currently comprises four sub-competitions - RoboMaster Robotics Competition, RoboMaster Technical Challenge, ICRA RoboMaster AI Challenge and the new RoboMaster Youth Tournament.", "token2charspan": [[0, 2], [3, 12], [13, 22], [23, 27], [28, 44], [45, 46], [47, 57], [58, 66], [67, 78], [78, 79], [80, 90], [91, 100], [101, 110], [110, 111], [112, 116], [117, 127], [128, 130], [131, 140], [141, 144], [145, 148], [149, 152], [153, 163], [164, 169], [170, 180], [180, 181]]}
{"doc_key": "ai-test-108", "ner": [[15, 17, "algorithm"], [21, 22, "algorithm"], [24, 25, "field"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "early", "2000s", ",", "the", "dominant", "speech", "processing", "strategy", "began", "to", "shift", "from", "the", "Hidden", "Markov", "Model", "to", "more", "modern", "neural", "networks", "and", "deep", "learning", "."], "sentence-detokenized": "In the early 2000s, the dominant speech processing strategy began to shift from the Hidden Markov Model to more modern neural networks and deep learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 18], [18, 19], [20, 23], [24, 32], [33, 39], [40, 50], [51, 59], [60, 65], [66, 68], [69, 74], [75, 79], [80, 83], [84, 90], [91, 97], [98, 103], [104, 106], [107, 111], [112, 118], [119, 125], [126, 134], [135, 138], [139, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-test-109", "ner": [[9, 11, "misc"], [16, 18, "metrics"], [21, 23, "metrics"], [30, 32, "metrics"], [35, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 18, 21, 23, "related-to", "equal", false, false], [30, 32, 35, 37, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "equivalent", "expression", ",", "in", "the", "case", "of", "a", "binary", "target", "value", ",", "is", "that", "the", "true", "positive", "value", "and", "the", "false", "positive", "value", "are", "equal", "(", "and", "therefore", "the", "false", "negative", "value", "and", "the", "true", "negative", "value", "are", "equal", ")", "for", "each", "value", "of", "the", "sensitive", "properties", ":"], "sentence-detokenized": "Another equivalent expression, in the case of a binary target value, is that the true positive value and the false positive value are equal (and therefore the false negative value and the true negative value are equal) for each value of the sensitive properties:", "token2charspan": [[0, 7], [8, 18], [19, 29], [29, 30], [31, 33], [34, 37], [38, 42], [43, 45], [46, 47], [48, 54], [55, 61], [62, 67], [67, 68], [69, 71], [72, 76], [77, 80], [81, 85], [86, 94], [95, 100], [101, 104], [105, 108], [109, 114], [115, 123], [124, 129], [130, 133], [134, 139], [140, 141], [141, 144], [145, 154], [155, 158], [159, 164], [165, 173], [174, 179], [180, 183], [184, 187], [188, 192], [193, 201], [202, 207], [208, 211], [212, 217], [217, 218], [219, 222], [223, 227], [228, 233], [234, 236], [237, 240], [241, 250], [251, 261], [261, 262]]}
{"doc_key": "ai-test-110", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "MATLAB", "function", ","], "sentence-detokenized": "The MATLAB function,", "token2charspan": [[0, 3], [4, 10], [11, 19], [19, 20]]}
{"doc_key": "ai-test-111", "ner": [[1, 2, "product"], [7, 7, "misc"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 1, 2, "part-of", "", false, false], [16, 17, 1, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "articulated", "robot", "is", "a", "robot", "with", "rotating", "joints", "(", "e.g.", "a", "legged", "robot", "or", "an", "industrial", "robot", ")", "."], "sentence-detokenized": "An articulated robot is a robot with rotating joints (e.g. a legged robot or an industrial robot).", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 23], [24, 25], [26, 31], [32, 36], [37, 45], [46, 52], [53, 54], [54, 58], [59, 60], [61, 67], [68, 73], [74, 76], [77, 79], [80, 90], [91, 96], [96, 97], [97, 98]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [5, 6, "product"], [8, 9, "product"], [13, 13, "misc"], [21, 23, "product"], [27, 30, "misc"], [33, 33, "location"], [35, 35, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 13, 13, "general-affiliation", "nationality", false, false], [0, 0, 27, 30, "usage", "", false, false], [0, 0, 33, 33, "physical", "", false, false], [5, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [33, 33, 35, 35, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "also", "known", "as", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "an", "American", "Internet", "radio", "service", "for", "music", "streaming", "and", "automated", "recommendation", "systems", "operated", "by", "the", "Music", "Genome", "Project", "and", "headquartered", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (also known as Pandora Media or Pandora Radio) is an American Internet radio service for music streaming and automated recommendation systems operated by the Music Genome Project and headquartered in Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 30], [31, 36], [37, 39], [40, 47], [48, 53], [53, 54], [55, 57], [58, 60], [61, 69], [70, 78], [79, 84], [85, 92], [93, 96], [97, 102], [103, 112], [113, 116], [117, 126], [127, 141], [142, 149], [150, 158], [159, 161], [162, 165], [166, 171], [172, 178], [179, 186], [187, 190], [191, 204], [205, 207], [208, 215], [215, 216], [217, 227], [227, 228]]}
{"doc_key": "ai-test-113", "ner": [[7, 10, "organisation"], [18, 20, "organisation"], [25, 26, "conference"], [38, 38, "conference"], [40, 40, "conference"], [42, 42, "conference"], [44, 44, "conference"], [46, 46, "conference"], [48, 48, "conference"], [50, 50, "conference"], [52, 52, "conference"], [54, 54, "conference"], [56, 56, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "board", "member", "of", "the", "International", "Machine", "Learning", "Society", ",", "has", "been", "a", "member", "of", "the", "AAAI", "Executive", "Council", ",", "was", "co-chair", "of", "ICML", "2011", "and", "has", "been", "a", "senior", "PC", "member", "for", "conferences", "such", "as", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", "and", "WWW", "."], "sentence-detokenized": "She is a board member of the International Machine Learning Society, has been a member of the AAAI Executive Council, was co-chair of ICML 2011 and has been a senior PC member for conferences such as AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM and WWW.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 14], [15, 21], [22, 24], [25, 28], [29, 42], [43, 50], [51, 59], [60, 67], [67, 68], [69, 72], [73, 77], [78, 79], [80, 86], [87, 89], [90, 93], [94, 98], [99, 108], [109, 116], [116, 117], [118, 121], [122, 130], [131, 133], [134, 138], [139, 143], [144, 147], [148, 151], [152, 156], [157, 158], [159, 165], [166, 168], [169, 175], [176, 179], [180, 191], [192, 196], [197, 199], [200, 204], [204, 205], [206, 210], [210, 211], [212, 217], [217, 218], [219, 223], [223, 224], [225, 228], [228, 229], [230, 236], [236, 237], [238, 241], [241, 242], [243, 247], [247, 248], [249, 253], [254, 257], [258, 261], [261, 262]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [5, 10, "organisation"], [12, 12, "organisation"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 10, "role", "", false, false], [12, 12, 5, 10, "named", "", false, false], [17, 17, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "has", "developed", "the", "Robocrane", ",", "in", "which", "the", "platform", "is", "suspended", "by", "six", "cables", "instead", "of", "being", "supported", "by", "six", "jacks", "."], "sentence-detokenized": "James S. Albus of the National Institute of Standards and Technology (NIST) has developed the Robocrane, in which the platform is suspended by six cables instead of being supported by six jacks.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [74, 75], [76, 79], [80, 89], [90, 93], [94, 103], [103, 104], [105, 107], [108, 113], [114, 117], [118, 126], [127, 129], [130, 139], [140, 142], [143, 146], [147, 153], [154, 161], [162, 164], [165, 170], [171, 180], [181, 183], [184, 187], [188, 193], [193, 194]]}
{"doc_key": "ai-test-115", "ner": [[3, 5, "algorithm"], [9, 10, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 3, 5, "type-of", "", false, false], [14, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "class", "of", "direct", "search", "algorithms", "are", "the", "various", "evolutionary", "algorithms", ",", "such", "as", "genetic", "algorithms", "."], "sentence-detokenized": "Another class of direct search algorithms are the various evolutionary algorithms, such as genetic algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 23], [24, 30], [31, 41], [42, 45], [46, 49], [50, 57], [58, 70], [71, 81], [81, 82], [83, 87], [88, 90], [91, 98], [99, 109], [109, 110]]}
{"doc_key": "ai-test-116", "ner": [[0, 1, "organisation"], [3, 4, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "industrial", "robots", "and", "factory", "automation", "solutions", "."], "sentence-detokenized": "KUKA is a German manufacturer of industrial robots and factory automation solutions.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-117", "ner": [[11, 11, "person"], [14, 20, "misc"], [22, 22, "person"], [25, 25, "misc"], [27, 27, "person"], [30, 31, "misc"], [33, 34, "person"], [36, 38, "misc"], [40, 41, "person"], [44, 47, "misc"], [49, 49, "person"], [52, 55, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[14, 20, 11, 11, "artifact", "", false, false], [25, 25, 22, 22, "artifact", "", false, false], [30, 31, 27, 27, "artifact", "", false, false], [36, 38, 33, 34, "artifact", "", false, false], [44, 47, 40, 41, "artifact", "", false, false], [52, 55, 49, 49, "artifact", "", false, false]], "relations_mapping_to_source": [1, 3, 5, 7, 9, 11], "sentence": ["Other", "films", "filmed", "with", "IMAX", "cameras", "between", "2016", "and", "2020", "included", "Zack", "Snyder", "'s", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", ",", "Clint", "Eastwood", "'s", "Sully", ",", "Damien", "Chazelle", "'s", "First", "Man", ",", "Patty", "Jenkins", "'", "Wonder", "Woman", "1984", ",", "Cary", "Joji", "Fukunaga", "'s", "No", "Time", "to", "Die", "and", "Joseph", "Kosinski", "'s", "Top", "Gun", ":", "Maverick", "."], "sentence-detokenized": "Other films filmed with IMAX cameras between 2016 and 2020 included Zack Snyder's Batman v Superman: Dawn of Justice, Clint Eastwood's Sully, Damien Chazelle's First Man, Patty Jenkins' Wonder Woman 1984, Cary Joji Fukunaga's No Time to Die and Joseph Kosinski's Top Gun: Maverick.", "token2charspan": [[0, 5], [6, 11], [12, 18], [19, 23], [24, 28], [29, 36], [37, 44], [45, 49], [50, 53], [54, 58], [59, 67], [68, 72], [73, 79], [79, 81], [82, 88], [89, 90], [91, 99], [99, 100], [101, 105], [106, 108], [109, 116], [116, 117], [118, 123], [124, 132], [132, 134], [135, 140], [140, 141], [142, 148], [149, 157], [157, 159], [160, 165], [166, 169], [169, 170], [171, 176], [177, 184], [184, 185], [186, 192], [193, 198], [199, 203], [203, 204], [205, 209], [210, 214], [215, 223], [223, 225], [226, 228], [229, 233], [234, 236], [237, 240], [241, 244], [245, 251], [252, 260], [260, 262], [263, 266], [267, 270], [270, 271], [272, 280], [280, 281]]}
{"doc_key": "ai-test-118", "ner": [[2, 2, "misc"], [9, 11, "organisation"], [13, 13, "organisation"], [33, 33, "country"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[9, 11, 2, 2, "usage", "", false, false], [9, 11, 33, 33, "physical", "", false, false], [13, 13, 9, 11, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["The", "sample", "MICR", "E13B", "font", "was", "shown", "to", "the", "American", "Bankers", "Association", "(", "ABA", ")", "in", "July", "1956", ",", "which", "adopted", "it", "in", "1958", "as", "the", "MICR", "standard", "for", "negotiable", "documents", "in", "the", "US", "."], "sentence-detokenized": "The sample MICR E13B font was shown to the American Bankers Association (ABA) in July 1956, which adopted it in 1958 as the MICR standard for negotiable documents in the US.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 20], [21, 25], [26, 29], [30, 35], [36, 38], [39, 42], [43, 51], [52, 59], [60, 71], [72, 73], [73, 76], [76, 77], [78, 80], [81, 85], [86, 90], [90, 91], [92, 97], [98, 105], [106, 108], [109, 111], [112, 116], [117, 119], [120, 123], [124, 128], [129, 137], [138, 141], [142, 152], [153, 162], [163, 165], [166, 169], [170, 172], [172, 173]]}
{"doc_key": "ai-test-119", "ner": [[0, 3, "misc"], [15, 16, "field"], [19, 20, "field"], [23, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 16, 0, 3, "usage", "", false, false], [19, 20, 15, 16, "part-of", "", false, false], [23, 23, 0, 3, "usage", "", false, false], [25, 26, 0, 3, "usage", "", false, false], [28, 28, 0, 3, "usage", "", false, false], [30, 30, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "are", "widely", "applied", "to", "many", "difficult", "computational", "problems", ",", "including", "problems", "in", "computer", "science", "(", "especially", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms are widely applied to many difficult computational problems, including problems in computer science (especially artificial intelligence), mathematics, operations research, engineering and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 27], [28, 34], [35, 42], [43, 45], [46, 50], [51, 60], [61, 74], [75, 83], [83, 84], [85, 94], [95, 103], [104, 106], [107, 115], [116, 123], [124, 125], [125, 135], [136, 146], [147, 159], [159, 160], [160, 161], [162, 173], [173, 174], [175, 185], [186, 194], [194, 195], [196, 207], [208, 211], [212, 226], [226, 227]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [8, 8, "location"], [10, 10, "country"], [14, 14, "country"], [22, 23, "algorithm"], [25, 25, "algorithm"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 8, 8, "physical", "", false, false], [0, 1, 14, 14, "general-affiliation", "nationality", false, false], [0, 1, 22, 23, "general-affiliation", "topic_of_study", false, false], [0, 1, 25, 25, "general-affiliation", "topic_of_study", false, false], [8, 8, 10, 10, "physical", "", false, false], [25, 25, 27, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "born", "3", "September", "1947", "in", "Wallersdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "has", "studied", "the", "use", "of", "bounded", "rationality", "and", "heuristics", "in", "decision", "-", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (born 3 September 1947 in Wallersdorf, Germany) is a German psychologist who has studied the use of bounded rationality and heuristics in decision-making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 21], [22, 23], [24, 33], [34, 38], [39, 41], [42, 53], [53, 54], [55, 62], [62, 63], [64, 66], [67, 68], [69, 75], [76, 88], [89, 92], [93, 96], [97, 104], [105, 108], [109, 112], [113, 115], [116, 123], [124, 135], [136, 139], [140, 150], [151, 153], [154, 162], [162, 163], [163, 169], [169, 170]]}
{"doc_key": "ai-test-121", "ner": [[3, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["to", "minimize", "the", "mean", "square", "error", "."], "sentence-detokenized": "to minimize the mean square error.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [21, 27], [28, 33], [33, 34]]}
{"doc_key": "ai-test-122", "ner": [[12, 13, "misc"], [16, 17, "organisation"], [33, 35, "field"], [54, 55, "misc"], [64, 66, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 16, 17, "origin", "", false, false], [54, 55, 64, 66, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["But", "even", "an", "official", "language", "with", "a", "regulating", "academy", ",", "such", "as", "Standard", "French", "with", "the", "Acad\u00e9mie", "fran\u00e7aise", ",", "is", "classified", "as", "a", "natural", "language", "(", "for", "example", ",", "in", "the", "field", "of", "natural", "language", "processing", ")", ",", "because", "its", "normative", "points", "do", "not", "make", "it", "either", "sufficiently", "constructed", "to", "be", "classified", "as", "a", "constructed", "language", "or", "sufficiently", "controlled", "to", "be", "classified", "as", "a", "controlled", "natural", "language", "."], "sentence-detokenized": "But even an official language with a regulating academy, such as Standard French with the Acad\u00e9mie fran\u00e7aise, is classified as a natural language (for example, in the field of natural language processing), because its normative points do not make it either sufficiently constructed to be classified as a constructed language or sufficiently controlled to be classified as a controlled natural language.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 20], [21, 29], [30, 34], [35, 36], [37, 47], [48, 55], [55, 56], [57, 61], [62, 64], [65, 73], [74, 80], [81, 85], [86, 89], [90, 98], [99, 108], [108, 109], [110, 112], [113, 123], [124, 126], [127, 128], [129, 136], [137, 145], [146, 147], [147, 150], [151, 158], [158, 159], [160, 162], [163, 166], [167, 172], [173, 175], [176, 183], [184, 192], [193, 203], [203, 204], [204, 205], [206, 213], [214, 217], [218, 227], [228, 234], [235, 237], [238, 241], [242, 246], [247, 249], [250, 256], [257, 269], [270, 281], [282, 284], [285, 287], [288, 298], [299, 301], [302, 303], [304, 315], [316, 324], [325, 327], [328, 340], [341, 351], [352, 354], [355, 357], [358, 368], [369, 371], [372, 373], [374, 384], [385, 392], [393, 401], [401, 402]]}
{"doc_key": "ai-test-123", "ner": [[13, 13, "metrics"], [16, 16, "metrics"], [18, 21, "metrics"], [15, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[18, 21, 16, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "a", "number", "of", "other", "metrics", ",", "the", "simplest", "of", "which", "is", "accuracy", "or", "Fraction", "Correct", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "all", "cases", "that", "are", "correctly", "categorised", "."], "sentence-detokenized": "There are a number of other metrics, the simplest of which is accuracy or Fraction Correct (FC), which measures the proportion of all cases that are correctly categorised.", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 18], [19, 21], [22, 27], [28, 35], [35, 36], [37, 40], [41, 49], [50, 52], [53, 58], [59, 61], [62, 70], [71, 73], [74, 82], [83, 90], [91, 92], [92, 94], [94, 95], [95, 96], [97, 102], [103, 111], [112, 115], [116, 126], [127, 129], [130, 133], [134, 139], [140, 144], [145, 148], [149, 158], [159, 170], [170, 171]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [6, 9, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 9, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "became", "a", "member", "of", "the", "Association", "for", "Computational", "Linguistics", "in", "2016", "."], "sentence-detokenized": "Cardie became a member of the Association for Computational Linguistics in 2016.", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 59], [60, 71], [72, 74], [75, 79], [79, 80]]}
{"doc_key": "ai-test-125", "ner": [[13, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Learning", "of", "the", "parameters", "math", "\\", "theta", "/", "math", "is", "usually", "done", "by", "maximum", "likelihood", "learning", "for", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";\\", "theta", ")", "/", "math", "."], "sentence-detokenized": "Learning of the parameters math\\ theta / math is usually done by maximum likelihood learning for mathp (Y _ i | X _ i;\\ theta) / math.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 26], [27, 31], [31, 32], [33, 38], [39, 40], [41, 45], [46, 48], [49, 56], [57, 61], [62, 64], [65, 72], [73, 83], [84, 92], [93, 96], [97, 102], [103, 104], [104, 105], [106, 107], [108, 109], [110, 111], [112, 113], [114, 115], [116, 117], [117, 119], [120, 125], [125, 126], [127, 128], [129, 133], [133, 134]]}
{"doc_key": "ai-test-126", "ner": [[0, 1, "task"], [3, 6, "algorithm"], [8, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 0, 1, "usage", "", true, false], [8, 9, 3, 6, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cluster", "analysis", "and", "factorization", "of", "non-negative", "matrices", "for", "descriptive", "mining", "."], "sentence-detokenized": "Cluster analysis and factorization of non-negative matrices for descriptive mining.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 34], [35, 37], [38, 50], [51, 59], [60, 63], [64, 75], [76, 82], [82, 83]]}
{"doc_key": "ai-test-127", "ner": [[1, 2, "field"], [5, 6, "field"], [15, 17, "field"], [19, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 17, 1, 2, "part-of", "", false, false], [15, 17, 5, 6, "part-of", "", false, false], [19, 22, 1, 2, "part-of", "", false, false], [19, 22, 5, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", "and", "the", "information", "technology", "it", "enables", ",", "the", "ability", "of", "computers", "to", "process", "natural", "languages", "and", "machine", "learning", "has", "been", "a", "long", "-", "standing", "challenge", "."], "sentence-detokenized": "In computer science and the information technology it enables, the ability of computers to process natural languages and machine learning has been a long-standing challenge.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 23], [24, 27], [28, 39], [40, 50], [51, 53], [54, 61], [61, 62], [63, 66], [67, 74], [75, 77], [78, 87], [88, 90], [91, 98], [99, 106], [107, 116], [117, 120], [121, 128], [129, 137], [138, 141], [142, 146], [147, 148], [149, 153], [153, 154], [154, 162], [163, 172], [172, 173]]}
{"doc_key": "ai-test-128", "ner": [[4, 5, "algorithm"], [9, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 9, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "The", "code", "for", "Gabor", "extraction", "from", "images", "in", "MATLAB", "is", "available", "at", "the", "following", "address"], "sentence-detokenized": "(The code for Gabor extraction from images in MATLAB is available at the following address", "token2charspan": [[0, 1], [1, 4], [5, 9], [10, 13], [14, 19], [20, 30], [31, 35], [36, 42], [43, 45], [46, 52], [53, 55], [56, 65], [66, 68], [69, 72], [73, 82], [83, 90]]}
{"doc_key": "ai-test-129", "ner": [[0, 0, "misc"], [14, 15, "algorithm"], [19, 19, "task"], [21, 21, "task"], [23, 24, "task"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 14, 15, "general-affiliation", "", false, false], [0, 0, 19, 19, "related-to", "solves_problem_of_type", false, false], [0, 0, 21, 21, "related-to", "solves_problem_of_type", false, false], [0, 0, 23, 24, "related-to", "solves_problem_of_type", false, false], [0, 0, 26, 27, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["NeuralExpert", "focuses", "the", "design", "specifications", "on", "the", "type", "of", "problem", "the", "user", "wants", "the", "neural", "network", "to", "solve", "(", "classification", ",", "prediction", ",", "function", "approximation", "or", "cluster", "analysis", ")", "."], "sentence-detokenized": "NeuralExpert focuses the design specifications on the type of problem the user wants the neural network to solve (classification, prediction, function approximation or cluster analysis).", "token2charspan": [[0, 12], [13, 20], [21, 24], [25, 31], [32, 46], [47, 49], [50, 53], [54, 58], [59, 61], [62, 69], [70, 73], [74, 78], [79, 84], [85, 88], [89, 95], [96, 103], [104, 106], [107, 112], [113, 114], [114, 128], [128, 129], [130, 140], [140, 141], [142, 150], [151, 164], [165, 167], [168, 175], [176, 184], [184, 185], [185, 186]]}
{"doc_key": "ai-test-130", "ner": [[1, 3, "misc"], [27, 30, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "quantization", "step", "(", "\u0394", ")", "is", "small", "relative", "to", "the", "variation", "in", "the", "signal", "being", "quantized", ",", "it", "is", "relatively", "easy", "to", "show", "that", "the", "root", "mean", "square", "error", "produced", "by", "such", "a", "rounding", "operation", "will", "be", "approximately", "math", "\\", "Delta", "^", "2", "/", "12", "/", "math.math"], "sentence-detokenized": "When the quantization step (\u0394) is small relative to the variation in the signal being quantized, it is relatively easy to show that the root mean square error produced by such a rounding operation will be approximately math\\ Delta ^ 2 / 12 / math.math", "token2charspan": [[0, 4], [5, 8], [9, 21], [22, 26], [27, 28], [28, 29], [29, 30], [31, 33], [34, 39], [40, 48], [49, 51], [52, 55], [56, 65], [66, 68], [69, 72], [73, 79], [80, 85], [86, 95], [95, 96], [97, 99], [100, 102], [103, 113], [114, 118], [119, 121], [122, 126], [127, 131], [132, 135], [136, 140], [141, 145], [146, 152], [153, 158], [159, 167], [168, 170], [171, 175], [176, 177], [178, 186], [187, 196], [197, 201], [202, 204], [205, 218], [219, 223], [223, 224], [225, 230], [231, 232], [233, 234], [235, 236], [237, 239], [240, 241], [242, 251]]}
{"doc_key": "ai-test-131", "ner": [[14, 14, "product"], [22, 25, "researcher"], [27, 28, "researcher"], [30, 32, "researcher"], [34, 35, "researcher"], [37, 39, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Building", "a", "comprehensive", "dictionary", "with", "an", "appropriate", "ontology", "requires", "considerable", "effort", ",", "e.g.", "the", "Wordnet", "dictionary", "required", "many", "person", "-", "years", ".", "G.", "A", ".", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "Building a comprehensive dictionary with an appropriate ontology requires considerable effort, e.g. the Wordnet dictionary required many person-years. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 8], [9, 10], [11, 24], [25, 35], [36, 40], [41, 43], [44, 55], [56, 64], [65, 73], [74, 86], [87, 93], [93, 94], [95, 99], [100, 103], [104, 111], [112, 122], [123, 131], [132, 136], [137, 143], [143, 144], [144, 149], [149, 150], [151, 153], [154, 155], [155, 156], [157, 163], [163, 164], [165, 167], [168, 176], [176, 177], [178, 180], [181, 183], [184, 192], [192, 193], [194, 196], [197, 202], [202, 203], [204, 205], [205, 206], [207, 213], [213, 214]]}
{"doc_key": "ai-test-132", "ner": [[0, 1, "organisation"], [21, 22, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 22, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kawasaki", "'s", "portfolio", "also", "includes", "retractable", "roofs", ",", "floors", "and", "other", "giant", "structures", ",", "such", "as", "the", "retractable", "surface", "of", "the", "Sapporo", "Dome", "."], "sentence-detokenized": "Kawasaki's portfolio also includes retractable roofs, floors and other giant structures, such as the retractable surface of the Sapporo Dome.", "token2charspan": [[0, 8], [8, 10], [11, 20], [21, 25], [26, 34], [35, 46], [47, 52], [52, 53], [54, 60], [61, 64], [65, 70], [71, 76], [77, 87], [87, 88], [89, 93], [94, 96], [97, 100], [101, 112], [113, 120], [121, 123], [124, 127], [128, 135], [136, 140], [140, 141]]}
{"doc_key": "ai-test-133", "ner": [[0, 3, "metrics"], [5, 7, "metrics"], [9, 11, "metrics"], [17, 18, "metrics"], [38, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 17, 18, "related-to", "", false, false], [0, 3, 38, 38, "opposite", "alternative_to", false, false], [5, 7, 0, 3, "type-of", "", false, false], [9, 11, 0, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa", "statistics", ",", "such", "as", "Fleiss", "'", "kappa", "and", "Cohen", "'s", "kappa", ",", "are", "methods", "for", "calculating", "inter-rater", "reliability", "based", "on", "different", "assumptions", "about", "marginal", "or", "priority", "distributions", ",", "and", "are", "increasingly", "used", "as", "randomly", "corrected", "alternatives", "to", "accuracy", "in", "other", "contexts", "."], "sentence-detokenized": "Kappa statistics, such as Fleiss' kappa and Cohen's kappa, are methods for calculating inter-rater reliability based on different assumptions about marginal or priority distributions, and are increasingly used as randomly corrected alternatives to accuracy in other contexts.", "token2charspan": [[0, 5], [6, 16], [16, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 39], [40, 43], [44, 49], [49, 51], [52, 57], [57, 58], [59, 62], [63, 70], [71, 74], [75, 86], [87, 98], [99, 110], [111, 116], [117, 119], [120, 129], [130, 141], [142, 147], [148, 156], [157, 159], [160, 168], [169, 182], [182, 183], [184, 187], [188, 191], [192, 204], [205, 209], [210, 212], [213, 221], [222, 231], [232, 244], [245, 247], [248, 256], [257, 259], [260, 265], [266, 274], [274, 275]]}
{"doc_key": "ai-test-134", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [18, 18, "researcher"], [27, 29, "algorithm"], [33, 36, "algorithm"], [31, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 18, 18, "role", "student_of", false, false], [7, 8, 18, 18, "role", "student_of", false, false], [10, 11, 18, 18, "role", "student_of", false, false], [13, 14, 18, 18, "role", "student_of", false, false], [33, 36, 4, 5, "origin", "", false, false], [33, 36, 7, 8, "origin", "", false, false], [33, 36, 10, 11, "origin", "", false, false], [33, 36, 13, 14, "origin", "", false, false], [33, 36, 18, 18, "origin", "", false, false], [33, 36, 27, 29, "type-of", "", false, false], [31, 31, 33, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Together", "with", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "and", "others", ",", "Schmidhuber", "published", "increasingly", "sophisticated", "versions", "of", "a", "type", "of", "recurrent", "neural", "network", "called", "LSTM", "(", "Long", "Short", "Term", "Memory", ")", "."], "sentence-detokenized": "Together with his students Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves and others, Schmidhuber published increasingly sophisticated versions of a type of recurrent neural network called LSTM (Long Short Term Memory).", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 26], [27, 31], [32, 42], [42, 43], [44, 49], [50, 54], [54, 55], [56, 60], [61, 68], [68, 69], [70, 74], [75, 81], [82, 85], [86, 92], [92, 93], [94, 105], [106, 115], [116, 128], [129, 142], [143, 151], [152, 154], [155, 156], [157, 161], [162, 164], [165, 174], [175, 181], [182, 189], [190, 196], [197, 201], [202, 203], [203, 207], [208, 213], [214, 218], [219, 225], [225, 226], [226, 227]]}
{"doc_key": "ai-test-135", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "The", "first", "Cobot", "KUKA", "LBR", "3", "is", "released", "."], "sentence-detokenized": "2004 - The first Cobot KUKA LBR 3 is released.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 22], [23, 27], [28, 31], [32, 33], [34, 36], [37, 45], [45, 46]]}
{"doc_key": "ai-test-136", "ner": [[11, 13, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "superficial", "methods", "used", "to", "train", "and", "then", "discriminate", "are", "the", "Naive", "Bayes", "classifier", "and", "the", "decision", "tree", "."], "sentence-detokenized": "Two superficial methods used to train and then discriminate are the Naive Bayes classifier and the decision tree.", "token2charspan": [[0, 3], [4, 15], [16, 23], [24, 28], [29, 31], [32, 37], [38, 41], [42, 46], [47, 59], [60, 63], [64, 67], [68, 73], [74, 79], [80, 90], [91, 94], [95, 98], [99, 107], [108, 112], [112, 113]]}
{"doc_key": "ai-test-137", "ner": [[5, 5, "misc"], [12, 13, "person"], [15, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 12, 13, "origin", "", false, false], [5, 5, 15, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "practical", "forms", "of", "photography", "were", "introduced", "in", "January", "1839", "by", "Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "The first practical forms of photography were introduced in January 1839 by Louis Daguerre and Henry Fox Talbot.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 25], [26, 28], [29, 40], [41, 45], [46, 56], [57, 59], [60, 67], [68, 72], [73, 75], [76, 81], [82, 90], [91, 94], [95, 100], [101, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-138", "ner": [[3, 4, "task"], [7, 12, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "speech", "synthesis", "combined", "with", "speech", "recognition", "makes", "it", "possible", "to", "interact", "with", "mobile", "devices", "via", "language", "processing", "interfaces", "."], "sentence-detokenized": "For example, speech synthesis combined with speech recognition makes it possible to interact with mobile devices via language processing interfaces.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [30, 38], [39, 43], [44, 50], [51, 62], [63, 68], [69, 71], [72, 80], [81, 83], [84, 92], [93, 97], [98, 104], [105, 112], [113, 116], [117, 125], [126, 136], [137, 147], [147, 148]]}
{"doc_key": "ai-test-139", "ner": [[0, 0, "product"], [14, 14, "programlang"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 14, "general-affiliation", "", false, false], [0, 0, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Phidgets", "can", "be", "programmed", "using", "a", "variety", "of", "software", "and", "programming", "languages", ",", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "Phidgets can be programmed using a variety of software and programming languages, from Java to Microsoft Excel.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 26], [27, 32], [33, 34], [35, 42], [43, 45], [46, 54], [55, 58], [59, 70], [71, 80], [80, 81], [82, 86], [87, 91], [92, 94], [95, 104], [105, 110], [110, 111]]}
{"doc_key": "ai-test-140", "ner": [[2, 3, "field"], [9, 10, "researcher"], [13, 15, "misc"], [19, 20, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 10, "origin", "", false, false], [9, 10, 19, 20, "general-affiliation", "topic_of_study", false, false], [9, 10, 22, 23, "general-affiliation", "topic_of_study", false, false], [13, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "machine", "learning", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "an", "American", "IBM", "employee", "and", "pioneer", "in", "computer", "games", "and", "artificial", "intelligence", "."], "sentence-detokenized": "The term machine learning was coined in 1959 by Arthur Samuel, an American IBM employee and pioneer in computer games and artificial intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 25], [26, 29], [30, 36], [37, 39], [40, 44], [45, 47], [48, 54], [55, 61], [61, 62], [63, 65], [66, 74], [75, 78], [79, 87], [88, 91], [92, 99], [100, 102], [103, 111], [112, 117], [118, 121], [122, 132], [133, 145], [145, 146]]}
{"doc_key": "ai-test-141", "ner": [[1, 2, "misc"], [3, 4, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Israeli", "poet", "David", "Avidan", ",", "fascinated", "by", "future", "technology", "and", "its", "relationship", "to", "art", ",", "wanted", "to", "explore", "the", "use", "of", "computers", "to", "write", "literature", "."], "sentence-detokenized": "The Israeli poet David Avidan, fascinated by future technology and its relationship to art, wanted to explore the use of computers to write literature.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 22], [23, 29], [29, 30], [31, 41], [42, 44], [45, 51], [52, 62], [63, 66], [67, 70], [71, 83], [84, 86], [87, 90], [90, 91], [92, 98], [99, 101], [102, 109], [110, 113], [114, 117], [118, 120], [121, 130], [131, 133], [134, 139], [140, 150], [150, 151]]}
{"doc_key": "ai-test-142", "ner": [[4, 5, "misc"], [9, 9, "organisation"], [16, 16, "location"], [30, 30, "location"], [27, 28, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 4, 5, "part-of", "", false, false], [27, 28, 30, 30, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "part", "of", "the", "GATEway", "project", "in", "2017", ",", "Oxbotica", "tested", "seven", "autonomous", "shuttle", "buses", "in", "Greenwich", ",", "navigating", "a", "two", "-", "mile", "river", "walk", "near", "the", "O2", "Arena", "in", "London", "on", "a", "route", "also", "used", "by", "pedestrians", "and", "cyclists", "."], "sentence-detokenized": "As part of the GATEway project in 2017, Oxbotica tested seven autonomous shuttle buses in Greenwich, navigating a two-mile river walk near the O2 Arena in London on a route also used by pedestrians and cyclists.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 30], [31, 33], [34, 38], [38, 39], [40, 48], [49, 55], [56, 61], [62, 72], [73, 80], [81, 86], [87, 89], [90, 99], [99, 100], [101, 111], [112, 113], [114, 117], [117, 118], [118, 122], [123, 128], [129, 133], [134, 138], [139, 142], [143, 145], [146, 151], [152, 154], [155, 161], [162, 164], [165, 166], [167, 172], [173, 177], [178, 182], [183, 185], [186, 197], [198, 201], [202, 210], [210, 211]]}
{"doc_key": "ai-test-143", "ner": [[10, 11, "task"], [14, 16, "metrics"], [25, 26, "misc"], [28, 28, "metrics"], [30, 30, "metrics"], [32, 32, "metrics"], [34, 34, "metrics"], [36, 38, "metrics"], [41, 41, "metrics"], [43, 43, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[14, 16, 25, 26, "related-to", "is_a", false, false], [14, 16, 28, 28, "usage", "", false, false], [14, 16, 30, 30, "usage", "", false, false], [28, 28, 32, 32, "named", "same", false, false], [30, 30, 43, 43, "named", "same", false, false], [32, 32, 41, 41, "opposite", "", false, false], [32, 32, 43, 43, "opposite", "", false, false], [34, 34, 32, 32, "named", "", false, false], [36, 38, 32, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["An", "unrelated", "but", "commonly", "used", "combination", "of", "basic", "statistics", "from", "information", "retrieval", "is", "the", "F", "-", "score", ",", "which", "is", "a", "(", "possibly", "weighted", ")", "harmonic", "mean", "of", "recall", "and", "precision", "where", "recall", "=", "sensitivity", "=", "TRUE", "positive", "rate", ",", "but", "specificity", "and", "precision", "are", "completely", "different", "measures", "."], "sentence-detokenized": "An unrelated but commonly used combination of basic statistics from information retrieval is the F-score, which is a (possibly weighted) harmonic mean of recall and precision where recall = sensitivity = TRUE positive rate, but specificity and precision are completely different measures.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 25], [26, 30], [31, 42], [43, 45], [46, 51], [52, 62], [63, 67], [68, 79], [80, 89], [90, 92], [93, 96], [97, 98], [98, 99], [99, 104], [104, 105], [106, 111], [112, 114], [115, 116], [117, 118], [118, 126], [127, 135], [135, 136], [137, 145], [146, 150], [151, 153], [154, 160], [161, 164], [165, 174], [175, 180], [181, 187], [188, 189], [190, 201], [202, 203], [204, 208], [209, 217], [218, 222], [222, 223], [224, 227], [228, 239], [240, 243], [244, 253], [254, 257], [258, 268], [269, 278], [279, 287], [287, 288]]}
{"doc_key": "ai-test-144", "ner": [[0, 1, "field"], [10, 10, "field"], [12, 12, "field"], [14, 14, "field"], [16, 17, "field"], [19, 19, "field"], [28, 29, "product"], [31, 34, "product"], [36, 37, "product"], [39, 40, "product"], [52, 54, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 10, "origin", "takes_inspiration_from", false, false], [0, 1, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 1, 14, 14, "origin", "takes_inspiration_from", false, false], [0, 1, 16, 17, "origin", "takes_inspiration_from", false, false], [0, 1, 19, 19, "origin", "takes_inspiration_from", false, false], [28, 29, 0, 1, "origin", "", false, false], [31, 34, 0, 1, "origin", "", false, false], [36, 37, 0, 1, "origin", "", false, false], [39, 40, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "is", "an", "interdisciplinary", "field", "that", "draws", "inspiration", "from", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", "and", "electronics", "to", "design", "artificial", "neural", "systems", ",", "such", "as", "vision", "systems", ",", "head", "-", "eye", "systems", ",", "auditory", "processors", "and", "autonomous", "robots", ",", "whose", "physical", "architecture", "and", "design", "principles", "are", "based", "on", "the", "biological", "nervous", "systems", "."], "sentence-detokenized": "Neuromorphic engineering is an interdisciplinary field that draws inspiration from biology, physics, mathematics, computer science and electronics to design artificial neural systems, such as vision systems, head-eye systems, auditory processors and autonomous robots, whose physical architecture and design principles are based on the biological nervous systems.", "token2charspan": [[0, 12], [13, 24], [25, 27], [28, 30], [31, 48], [49, 54], [55, 59], [60, 65], [66, 77], [78, 82], [83, 90], [90, 91], [92, 99], [99, 100], [101, 112], [112, 113], [114, 122], [123, 130], [131, 134], [135, 146], [147, 149], [150, 156], [157, 167], [168, 174], [175, 182], [182, 183], [184, 188], [189, 191], [192, 198], [199, 206], [206, 207], [208, 212], [212, 213], [213, 216], [217, 224], [224, 225], [226, 234], [235, 245], [246, 249], [250, 260], [261, 267], [267, 268], [269, 274], [275, 283], [284, 296], [297, 300], [301, 307], [308, 318], [319, 322], [323, 328], [329, 331], [332, 335], [336, 346], [347, 354], [355, 362], [362, 363]]}
{"doc_key": "ai-test-145", "ner": [[4, 10, "metrics"], [11, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 11, 4, 10, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "be", "specific", ",", "the", "BIBO", "stability", "criterion", "requires", "that", "the", "ROC", "of", "the", "system", "encompasses", "the", "unit", "circle", "."], "sentence-detokenized": "To be specific, the BIBO stability criterion requires that the ROC of the system encompasses the unit circle.", "token2charspan": [[0, 2], [3, 5], [6, 14], [14, 15], [16, 19], [20, 24], [25, 34], [35, 44], [45, 53], [54, 58], [59, 62], [63, 66], [67, 69], [70, 73], [74, 80], [81, 92], [93, 96], [97, 101], [102, 108], [108, 109]]}
{"doc_key": "ai-test-146", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "The", "program", "was", "rewritten", "in", "Java", "from", "1998", "onwards", "."], "sentence-detokenized": "2 The program was rewritten in Java from 1998 onwards.", "token2charspan": [[0, 1], [2, 5], [6, 13], [14, 17], [18, 27], [28, 30], [31, 35], [36, 40], [41, 45], [46, 53], [53, 54]]}
{"doc_key": "ai-test-147", "ner": [[0, 1, "metrics"], [8, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 8, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "MCC", "can", "be", "calculated", "directly", "from", "the", "confusion", "matrix", "using", "the", "formula", ":"], "sentence-detokenized": "The MCC can be calculated directly from the confusion matrix using the formula:", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 25], [26, 34], [35, 39], [40, 43], [44, 53], [54, 60], [61, 66], [67, 70], [71, 78], [78, 79]]}
{"doc_key": "ai-test-148", "ner": [[8, 13, "organisation"], [22, 27, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 13, 22, 27, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "developed", "by", "a", "team", "at", "the", "MIT", "-", "IBM", "Watson", "AI", "Lab", "and", "presented", "for", "the", "first", "time", "at", "the", "2018", "International", "Conference", "on", "Representation", "Learning", "."], "sentence-detokenized": "It was developed by a team at the MIT-IBM Watson AI Lab and presented for the first time at the 2018 International Conference on Representation Learning.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 29], [30, 33], [34, 37], [37, 38], [38, 41], [42, 48], [49, 51], [52, 55], [56, 59], [60, 69], [70, 73], [74, 77], [78, 83], [84, 88], [89, 91], [92, 95], [96, 100], [101, 114], [115, 125], [126, 128], [129, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-test-149", "ner": [[2, 3, "metrics"], [16, 17, "metrics"], [19, 24, "metrics"], [46, 46, "metrics"], [54, 56, "metrics"], [59, 59, "metrics"], [61, 61, "metrics"], [63, 65, "metrics"], [70, 70, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6, 7, 8, 9], "relations": [[16, 17, 46, 46, "type-of", "", false, false], [16, 17, 54, 56, "related-to", "collapses_to_identity", false, false], [19, 24, 54, 56, "related-to", "collapses_to_identity", false, false], [19, 24, 63, 65, "named", "same", false, false], [59, 59, 70, 70, "related-to", "collapses_to_identity", false, false], [61, 61, 70, 70, "related-to", "collapses_to_identity", false, false], [63, 65, 70, 70, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 3, 4, 5, 6, 7], "sentence": ["When", "the", "true", "prevalences", "of", "the", "two", "positive", "variables", "are", "equal", ",", "as", "assumed", "in", "the", "Fleiss", "kappa", "and", "F", "-", "score", ",", "i.e.", "the", "number", "of", "positive", "predictions", "equals", "the", "number", "of", "positive", "classes", "in", "the", "dichotomous", "case", "(", "two", "classes", ")", ",", "the", "different", "kappa", "and", "correlation", "measures", "collapse", "to", "identity", "with", "Youden", "'s", "J", ",", "and", "recall", ",", "precision", "and", "F", "-", "score", "are", "similarly", "identical", "with", "accuracy", "."], "sentence-detokenized": "When the true prevalences of the two positive variables are equal, as assumed in the Fleiss kappa and F-score, i.e. the number of positive predictions equals the number of positive classes in the dichotomous case (two classes), the different kappa and correlation measures collapse to identity with Youden's J, and recall, precision and F-score are similarly identical with accuracy.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 25], [26, 28], [29, 32], [33, 36], [37, 45], [46, 55], [56, 59], [60, 65], [65, 66], [67, 69], [70, 77], [78, 80], [81, 84], [85, 91], [92, 97], [98, 101], [102, 103], [103, 104], [104, 109], [109, 110], [111, 115], [116, 119], [120, 126], [127, 129], [130, 138], [139, 150], [151, 157], [158, 161], [162, 168], [169, 171], [172, 180], [181, 188], [189, 191], [192, 195], [196, 207], [208, 212], [213, 214], [214, 217], [218, 225], [225, 226], [226, 227], [228, 231], [232, 241], [242, 247], [248, 251], [252, 263], [264, 272], [273, 281], [282, 284], [285, 293], [294, 298], [299, 305], [305, 307], [308, 309], [309, 310], [311, 314], [315, 321], [321, 322], [323, 332], [333, 336], [337, 338], [338, 339], [339, 344], [345, 348], [349, 358], [359, 368], [369, 373], [374, 382], [382, 383]]}
{"doc_key": "ai-test-150", "ner": [[0, 7, "misc"], [5, 5, "misc"], [9, 9, "conference"], [14, 17, "task"], [18, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 7, 9, 9, "part-of", "", false, false], [0, 7, 9, 9, "physical", "", false, false], [0, 7, 9, 9, "temporal", "", false, false], [5, 5, 0, 7, "named", "", false, false], [14, 17, 0, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Building", "Educational", "Applications", "(", "BEA", ")", "workshop", "at", "NAACL", "2013", "hosted", "the", "first", "shared", "NLI", "task", ".", "Tetreault", "et", "al", ",", "2013", "The", "competition", "resulted", "in", "29", "entries", "from", "groups", "around", "the", "world", ",", "24", "of", "which", "also", "published", "a", "paper", "describing", "their", "system", "and", "approach", "."], "sentence-detokenized": "The Building Educational Applications (BEA) workshop at NAACL 2013 hosted the first shared NLI task. Tetreault et al, 2013 The competition resulted in 29 entries from groups around the world, 24 of which also published a paper describing their system and approach.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 37], [38, 39], [39, 42], [42, 43], [44, 52], [53, 55], [56, 61], [62, 66], [67, 73], [74, 77], [78, 83], [84, 90], [91, 94], [95, 99], [99, 100], [101, 110], [111, 113], [114, 116], [116, 117], [118, 122], [123, 126], [127, 138], [139, 147], [148, 150], [151, 153], [154, 161], [162, 166], [167, 173], [174, 180], [181, 184], [185, 190], [190, 191], [192, 194], [195, 197], [198, 203], [204, 208], [209, 218], [219, 220], [221, 226], [227, 237], [238, 243], [244, 250], [251, 254], [255, 263], [263, 264]]}
{"doc_key": "ai-test-151", "ner": [[0, 2, "algorithm"], [5, 7, "algorithm"], [15, 16, "misc"], [20, 21, "misc"], [40, 40, "algorithm"], [44, 44, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6], "relations": [[0, 2, 5, 7, "type-of", "", false, false], [0, 2, 15, 16, "related-to", "finds", false, false], [20, 21, 15, 16, "type-of", "", false, false], [44, 44, 40, 40, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Viterbi", "algorithm", "is", "a", "dynamic", "programming", "algorithm", "for", "finding", "the", "most", "likely", "sequence", "of", "hidden", "states", ",", "called", "the", "Viterbi", "path", ",", "resulting", "in", "a", "sequence", "of", "observed", "events", ",", "especially", "in", "the", "context", "of", "Markov", "information", "sources", "and", "hidden", "Markov", "models", "(", "HMMs", ")", "."], "sentence-detokenized": "The Viterbi algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states, called the Viterbi path, resulting in a sequence of observed events, especially in the context of Markov information sources and hidden Markov models (HMMs).", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 24], [25, 26], [27, 34], [35, 46], [47, 56], [57, 60], [61, 68], [69, 72], [73, 77], [78, 84], [85, 93], [94, 96], [97, 103], [104, 110], [110, 111], [112, 118], [119, 122], [123, 130], [131, 135], [135, 136], [137, 146], [147, 149], [150, 151], [152, 160], [161, 163], [164, 172], [173, 179], [179, 180], [181, 191], [192, 194], [195, 198], [199, 206], [207, 209], [210, 216], [217, 228], [229, 236], [237, 240], [241, 247], [248, 254], [255, 261], [262, 263], [263, 267], [267, 268], [268, 269]]}
{"doc_key": "ai-test-152", "ner": [[1, 1, "field"], [3, 7, "algorithm"], [8, 10, "misc"], [12, 13, "algorithm"], [15, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 7, 1, 1, "part-of", "", false, false], [3, 7, 8, 10, "general-affiliation", "", false, false], [3, 7, 12, 13, "related-to", "generalizes_from", false, false], [3, 7, 15, 18, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "multinomial", "logistic", "regression", "is", "a", "classification", "method", "that", "generalises", "logistic", "regression", "to", "multi-class", "classification", ",", "i.e.", "with", "more", "than", "two", "possible", "discrete", "outcomes", "."], "sentence-detokenized": "In statistics, multinomial logistic regression is a classification method that generalises logistic regression to multi-class classification, i.e. with more than two possible discrete outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 26], [27, 35], [36, 46], [47, 49], [50, 51], [52, 66], [67, 73], [74, 78], [79, 90], [91, 99], [100, 110], [111, 113], [114, 125], [126, 140], [140, 141], [142, 146], [147, 151], [152, 156], [157, 161], [162, 165], [166, 174], [175, 183], [184, 192], [192, 193]]}
{"doc_key": "ai-test-153", "ner": [[0, 3, "algorithm"], [9, 10, "field"], [12, 14, "field"], [17, 17, "task"], [19, 20, "task"], [22, 23, "task"], [25, 26, "researcher"], [28, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 9, 10, "part-of", "", false, false], [0, 3, 12, 14, "part-of", "", false, false], [17, 17, 0, 3, "usage", "", true, false], [19, 20, 0, 3, "usage", "", true, false], [22, 23, 0, 3, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden", "Markov", "models", "are", "known", "for", "their", "applications", "in", "reinforcement", "learning", "and", "temporal", "pattern", "recognition", ",", "e.g.", "speech", ",", "handwriting", "recognition", ",", "gesture", "recognition", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov models are known for their applications in reinforcement learning and temporal pattern recognition, e.g. speech, handwriting recognition, gesture recognition, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 30], [31, 34], [35, 40], [41, 53], [54, 56], [57, 70], [71, 79], [80, 83], [84, 92], [93, 100], [101, 112], [112, 113], [114, 118], [119, 125], [125, 126], [127, 138], [139, 150], [150, 151], [152, 159], [160, 171], [171, 172], [173, 177], [178, 185], [185, 186], [187, 191], [192, 200], [200, 201]]}
{"doc_key": "ai-test-154", "ner": [[5, 7, "misc"], [32, 34, "metrics"], [37, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 37, 38, "named", "", false, false], [32, 34, 37, 38, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "essentially", "means", "that", "if", "a", "-", "gram", "has", "been", "seen", "more", "than", "k", "times", "during", "training", ",", "the", "conditional", "probability", "of", "a", "word", "given", "it", "s", "history", "is", "proportional", "to", "the", "maximum", "likelihood", "estimate", "of", "that", "-", "gram", "."], "sentence-detokenized": "This essentially means that if a -gram has been seen more than k times during training, the conditional probability of a word given its history is proportional to the maximum likelihood estimate of that -gram.", "token2charspan": [[0, 4], [5, 16], [17, 22], [23, 27], [28, 30], [31, 32], [33, 34], [34, 38], [39, 42], [43, 47], [48, 52], [53, 57], [58, 62], [63, 64], [65, 70], [71, 77], [78, 86], [86, 87], [88, 91], [92, 103], [104, 115], [116, 118], [119, 120], [121, 125], [126, 131], [132, 134], [134, 135], [136, 143], [144, 146], [147, 159], [160, 162], [163, 166], [167, 174], [175, 185], [186, 194], [195, 197], [198, 202], [203, 204], [204, 208], [208, 209]]}
{"doc_key": "ai-test-155", "ner": [[4, 5, "task"], [7, 8, "task"], [10, 14, "task"], [17, 19, "task"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[27, 29, 17, 19, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "knowledge", "representation", ",", "logical", "reasoning", "and", "natural", "language", "understanding", ",", "and", "believes", "that", "deep", "language", "understanding", "can", "currently", "only", "be", "achieved", "through", "significant", "manual", "processing", "of", "semantically", "rich", "formalisms", "in", "combination", "with", "statistical", "preferences", "."], "sentence-detokenized": "He is interested in knowledge representation, logical reasoning and natural language understanding, and believes that deep language understanding can currently only be achieved through significant manual processing of semantically rich formalisms in combination with statistical preferences.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 29], [30, 44], [44, 45], [46, 53], [54, 63], [64, 67], [68, 75], [76, 84], [85, 98], [98, 99], [100, 103], [104, 112], [113, 117], [118, 122], [123, 131], [132, 145], [146, 149], [150, 159], [160, 164], [165, 167], [168, 176], [177, 184], [185, 196], [197, 203], [204, 214], [215, 217], [218, 230], [231, 235], [236, 246], [247, 249], [250, 261], [262, 266], [267, 278], [279, 290], [290, 291]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "JavaScript", ",", "Python", "or"], "sentence-detokenized": "In JavaScript, Python or", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 24]]}
{"doc_key": "ai-test-157", "ner": [[0, 2, "misc"], [6, 7, "misc"], [11, 11, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 7, "part-of", "", false, false], [6, 7, 11, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "awards", "are", "announced", "in", "AI", "Magazine", ",", "published", "by", "AAAI", "."], "sentence-detokenized": "The Newcomb awards are announced in AI Magazine, published by AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 32], [33, 35], [36, 38], [39, 47], [47, 48], [49, 58], [59, 61], [62, 66], [66, 67]]}
{"doc_key": "ai-test-158", "ner": [[1, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "square", "error", "of", "a", "test", "set", "of", "100", "copies", "is", "0.084", ",", "which", "is", "smaller", "than", "the", "unnormalized", "error", "."], "sentence-detokenized": "The mean square error of a test set of 100 copies is 0.084, which is smaller than the unnormalized error.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 21], [22, 24], [25, 26], [27, 31], [32, 35], [36, 38], [39, 42], [43, 49], [50, 52], [53, 58], [58, 59], [60, 65], [66, 68], [69, 76], [77, 81], [82, 85], [86, 98], [99, 104], [104, 105]]}
{"doc_key": "ai-test-159", "ner": [[0, 3, "metrics"], [10, 15, "field"], [20, 22, "task"], [24, 24, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 15, 0, 3, "usage", "", false, false], [20, 22, 10, 15, "part-of", "task_part_of_field", false, false], [24, 24, 20, 22, "named", "", false, false], [27, 28, 10, 15, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "F", "-", "score", "has", "been", "widely", "used", "in", "the", "natural", "language", "processing", "literature", ",", "e.g.", "in", "the", "evaluation", "of", "named", "entity", "recognition", "(", "NER", ")", "and", "word", "segmentation", "."], "sentence-detokenized": "The F-score has been widely used in the natural language processing literature, e.g. in the evaluation of named entity recognition (NER) and word segmentation.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 15], [16, 20], [21, 27], [28, 32], [33, 35], [36, 39], [40, 47], [48, 56], [57, 67], [68, 78], [78, 79], [80, 84], [85, 87], [88, 91], [92, 102], [103, 105], [106, 111], [112, 118], [119, 130], [131, 132], [132, 135], [135, 136], [137, 140], [141, 145], [146, 158], [158, 159]]}
{"doc_key": "ai-test-160", "ner": [[0, 0, "product"], [5, 6, "product"], [16, 17, "misc"], [19, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 16, 17, "related-to", "performs_task", false, false], [0, 0, 19, 20, "related-to", "performs_task", false, false], [5, 6, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "typically", "used", "in", "dialogue", "systems", "for", "various", "purposes", ",", "such", "as", "customer", "service", ",", "routing", "requests", "or", "information", "gathering", "."], "sentence-detokenized": "Chatbots are typically used in dialogue systems for various purposes, such as customer service, routing requests or information gathering.", "token2charspan": [[0, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 39], [40, 47], [48, 51], [52, 59], [60, 68], [68, 69], [70, 74], [75, 77], [78, 86], [87, 94], [94, 95], [96, 103], [104, 112], [113, 115], [116, 127], [128, 137], [137, 138]]}
{"doc_key": "ai-test-161", "ner": [[3, 9, "conference"], [13, 21, "conference"], [27, 37, "conference"], [47, 50, "conference"], [52, 53, "conference"]], "ner_mapping_to_source": [0, 1, 2, 4, 5], "relations": [[13, 21, 3, 9, "named", "", false, false], [27, 37, 3, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Key", "journals", "include", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "later", "renamed", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "and", "since", "September", "2014", "renamed", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "after", "merging", "with", "an", "ACM", "publication", ")", ",", "Computer", "Speech", "and", "Language", "and", "Speech", "Communication", "."], "sentence-detokenized": "Key journals include IEEE Transactions on Speech and Audio Processing (later renamed IEEE Transactions on Audio, Speech and Language Processing and since September 2014 renamed IEEE/ACM Transactions on Audio, Speech and Language Processing - after merging with an ACM publication), Computer Speech and Language and Speech Communication.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 25], [26, 38], [39, 41], [42, 48], [49, 52], [53, 58], [59, 69], [70, 71], [71, 76], [77, 84], [85, 89], [90, 102], [103, 105], [106, 111], [111, 112], [113, 119], [120, 123], [124, 132], [133, 143], [144, 147], [148, 153], [154, 163], [164, 168], [169, 176], [177, 181], [181, 182], [182, 185], [186, 198], [199, 201], [202, 207], [207, 208], [209, 215], [216, 219], [220, 228], [229, 239], [240, 241], [242, 247], [248, 255], [256, 260], [261, 263], [264, 267], [268, 279], [279, 280], [280, 281], [282, 290], [291, 297], [298, 301], [302, 310], [311, 314], [315, 321], [322, 335], [335, 336]]}
{"doc_key": "ai-test-162", "ner": [[0, 0, "algorithm"], [5, 6, "task"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 0, 0, "usage", "", false, false], [5, 6, 8, 9, "part-of", "task_part_of_field", false, false], [5, 6, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "is", "widely", "used", "for", "clustering", "data", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "EM is widely used for clustering data in machine learning and computer vision.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 17], [18, 21], [22, 32], [33, 37], [38, 40], [41, 48], [49, 57], [58, 61], [62, 70], [71, 77], [77, 78]]}
{"doc_key": "ai-test-163", "ner": [[9, 10, "metrics"], [23, 27, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 23, 27, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["Although", "there", "is", "no", "perfect", "way", "to", "describe", "the", "confusion", "matrix", "of", "true", "and", "false", "positives", "and", "negatives", "with", "a", "single", "number", ",", "Matthew", "'s", "correlation", "coefficient", "is", "generally", "considered", "to", "be", "one", "of", "the", "best", "measures", "."], "sentence-detokenized": "Although there is no perfect way to describe the confusion matrix of true and false positives and negatives with a single number, Matthew's correlation coefficient is generally considered to be one of the best measures.", "token2charspan": [[0, 8], [9, 14], [15, 17], [18, 20], [21, 28], [29, 32], [33, 35], [36, 44], [45, 48], [49, 58], [59, 65], [66, 68], [69, 73], [74, 77], [78, 83], [84, 93], [94, 97], [98, 107], [108, 112], [113, 114], [115, 121], [122, 128], [128, 129], [130, 137], [137, 139], [140, 151], [152, 163], [164, 166], [167, 176], [177, 187], [188, 190], [191, 193], [194, 197], [198, 200], [201, 204], [205, 209], [210, 218], [218, 219]]}
{"doc_key": "ai-test-164", "ner": [[12, 13, "field"], [28, 29, "field"], [36, 37, "field"], [41, 42, "algorithm"], [44, 45, "task"], [47, 48, "algorithm"], [53, 56, "algorithm"], [58, 59, "algorithm"], [65, 67, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[36, 37, 28, 29, "part-of", "subfield", false, false], [41, 42, 36, 37, "part-of", "", false, true], [44, 45, 36, 37, "part-of", "", false, true], [47, 48, 36, 37, "part-of", "", false, true], [53, 56, 36, 37, "part-of", "", false, true], [58, 59, 36, 37, "part-of", "", false, true], [65, 67, 36, 37, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "data", "sets", "have", "grown", "in", "size", "and", "complexity", ",", "direct", "practical", "data", "analysis", "has", "been", "complemented", "by", "indirect", ",", "automated", "data", "processing", ",", "using", "other", "discoveries", "in", "computer", "science", ",", "particularly", "in", "the", "field", "of", "machine", "learning", ",", "such", "as", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "learning", "of", "decision", "trees", "and", "decision", "rules", "(", "1960", "s", ")", "and", "support", "vector", "machines", "(", "1990", "s", ")", "."], "sentence-detokenized": "As data sets have grown in size and complexity, direct practical data analysis has been complemented by indirect, automated data processing, using other discoveries in computer science, particularly in the field of machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), learning of decision trees and decision rules (1960s) and support vector machines (1990s).", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 17], [18, 23], [24, 26], [27, 31], [32, 35], [36, 46], [46, 47], [48, 54], [55, 64], [65, 69], [70, 78], [79, 82], [83, 87], [88, 100], [101, 103], [104, 112], [112, 113], [114, 123], [124, 128], [129, 139], [139, 140], [141, 146], [147, 152], [153, 164], [165, 167], [168, 176], [177, 184], [184, 185], [186, 198], [199, 201], [202, 205], [206, 211], [212, 214], [215, 222], [223, 231], [231, 232], [233, 237], [238, 240], [241, 247], [248, 256], [256, 257], [258, 265], [266, 274], [274, 275], [276, 283], [284, 294], [295, 296], [296, 301], [301, 302], [302, 303], [304, 312], [313, 315], [316, 324], [325, 330], [331, 334], [335, 343], [344, 349], [350, 351], [351, 355], [355, 356], [356, 357], [358, 361], [362, 369], [370, 376], [377, 385], [386, 387], [387, 391], [391, 392], [392, 393], [393, 394]]}
{"doc_key": "ai-test-165", "ner": [[4, 4, "researcher"], [9, 10, "misc"], [18, 19, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 4, 4, "artifact", "", false, false], [9, 10, 18, 19, "artifact", "", false, false], [9, 10, 21, 22, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "autumn", "2005", ",", "Thrun", "published", "a", "textbook", "entitled", "Probabilistic", "Robotics", "together", "with", "his", "long", "-", "time", "collaborators", "Dieter", "Fox", "and", "Wolfram", "Burgard", "."], "sentence-detokenized": "In autumn 2005, Thrun published a textbook entitled Probabilistic Robotics together with his long-time collaborators Dieter Fox and Wolfram Burgard.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 21], [22, 31], [32, 33], [34, 42], [43, 51], [52, 65], [66, 74], [75, 83], [84, 88], [89, 92], [93, 97], [97, 98], [98, 102], [103, 116], [117, 123], [124, 127], [128, 131], [132, 139], [140, 147], [147, 148]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereiramath", "as", "follows", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereiramath as follows:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 49], [50, 52], [53, 60], [60, 61]]}
{"doc_key": "ai-test-167", "ner": [[0, 1, "task"], [3, 3, "task"], [7, 8, "field"], [14, 15, "field"], [17, 19, "field"], [21, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 17, 19, "part-of", "task_part_of_field", false, false], [3, 3, 0, 1, "named", "", false, false], [14, 15, 7, 8, "part-of", "subfield", false, false], [17, 19, 7, 8, "part-of", "subfield", false, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Question", "Answering", "(", "QA", ")", "is", "a", "computer", "science", "discipline", "in", "the", "fields", "of", "information", "retrieval", "and", "natural", "language", "processing", "(", "NLP", ")", ",", "which", "is", "concerned", "with", "building", "systems", "that", "automatically", "answer", "questions", "posed", "by", "humans", "in", "a", "natural", "language", "."], "sentence-detokenized": "Question Answering (QA) is a computer science discipline in the fields of information retrieval and natural language processing (NLP), which is concerned with building systems that automatically answer questions posed by humans in a natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 37], [38, 45], [46, 56], [57, 59], [60, 63], [64, 70], [71, 73], [74, 85], [86, 95], [96, 99], [100, 107], [108, 116], [117, 127], [128, 129], [129, 132], [132, 133], [133, 134], [135, 140], [141, 143], [144, 153], [154, 158], [159, 167], [168, 175], [176, 180], [181, 194], [195, 201], [202, 211], [212, 217], [218, 220], [221, 227], [228, 230], [231, 232], [233, 240], [241, 249], [249, 250]]}
{"doc_key": "ai-test-168", "ner": [[10, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "in", "the", "version", "of", "the", "measure", "used", "in", "NIST", "evaluations", "prior", "to", "2009", ",", "the", "shortest", "reference", "rate", "was", "used", "instead", "."], "sentence-detokenized": "However, in the version of the measure used in NIST evaluations prior to 2009, the shortest reference rate was used instead.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 38], [39, 43], [44, 46], [47, 51], [52, 63], [64, 69], [70, 72], [73, 77], [77, 78], [79, 82], [83, 91], [92, 101], [102, 106], [107, 110], [111, 115], [116, 123], [123, 124]]}
{"doc_key": "ai-test-169", "ner": [[5, 5, "person"], [13, 14, "organisation"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 15, 15, "related-to", "invests_in", false, false], [15, 15, 13, 14, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["On", "27", "August", "2018", ",", "Toyota", "announced", "a", "$", "500", "million", "investment", "in", "Uber", "'s", "autonomous", "cars", "."], "sentence-detokenized": "On 27 August 2018, Toyota announced a $500 million investment in Uber's autonomous cars.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 17], [17, 18], [19, 25], [26, 35], [36, 37], [38, 39], [39, 42], [43, 50], [51, 61], [62, 64], [65, 69], [69, 71], [72, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-test-170", "ner": [[5, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sampling", "maximum", "is", "the", "maximum", "likelihood", "estimate", "for", "the", "population", "maximum", ",", "but", "as", "discussed", "above", ",", "it", "is", "biased", "."], "sentence-detokenized": "The sampling maximum is the maximum likelihood estimate for the population maximum, but as discussed above, it is biased.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 23], [24, 27], [28, 35], [36, 46], [47, 55], [56, 59], [60, 63], [64, 74], [75, 82], [82, 83], [84, 87], [88, 90], [91, 100], [101, 106], [106, 107], [108, 110], [111, 113], [114, 120], [120, 121]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [4, 4, "misc"], [7, 7, "metrics"], [18, 20, "algorithm"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 4, 4, "related-to", "overcomes", false, false], [0, 0, 7, 7, "related-to", "increases", false, false], [4, 4, 18, 20, "opposite", "", false, false], [4, 4, 22, 24, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "helps", "to", "overcome", "synonyms", "by", "increasing", "recall", ",", "which", "is", "one", "of", "the", "most", "problematic", "limitations", "of", "Boolean", "keyword", "searches", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI helps to overcome synonyms by increasing recall, which is one of the most problematic limitations of Boolean keyword searches and vector space models.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 21], [22, 30], [31, 33], [34, 44], [45, 51], [51, 52], [53, 58], [59, 61], [62, 65], [66, 68], [69, 72], [73, 77], [78, 89], [90, 101], [102, 104], [105, 112], [113, 120], [121, 129], [130, 133], [134, 140], [141, 146], [147, 153], [153, 154]]}
{"doc_key": "ai-test-172", "ner": [[18, 18, "programlang"], [20, 20, "programlang"], [22, 22, "programlang"], [24, 25, "programlang"], [27, 27, "programlang"], [29, 29, "programlang"], [31, 31, "programlang"], [33, 33, "programlang"], [35, 35, "programlang"], [37, 37, "programlang"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [], "relations_mapping_to_source": [], "sentence": ["Data", "collection", "applications", "are", "usually", "controlled", "by", "software", "developed", "using", "various", "general", "purpose", "programming", "languages", ",", "such", "as", "Assembly", ",", "BASIC", ",", "C", ",", "C", "++", ",", "C#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "Data collection applications are usually controlled by software developed using various general purpose programming languages, such as Assembly, BASIC, C, C++, C#, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 32], [33, 40], [41, 51], [52, 54], [55, 63], [64, 73], [74, 79], [80, 87], [88, 95], [96, 103], [104, 115], [116, 125], [125, 126], [127, 131], [132, 134], [135, 143], [143, 144], [145, 150], [150, 151], [152, 153], [153, 154], [155, 156], [156, 158], [158, 159], [160, 162], [162, 163], [164, 171], [171, 172], [173, 177], [177, 178], [179, 186], [186, 187], [188, 192], [192, 193], [194, 200], [200, 201], [202, 206]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [10, 10, "country"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2003", ",", "Honda", "released", "its", "Cog", "advertisement", "in", "the", "UK", "and", "on", "the", "Internet", "."], "sentence-detokenized": "In 2003, Honda released its Cog advertisement in the UK and on the Internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 27], [28, 31], [32, 45], [46, 48], [49, 52], [53, 55], [56, 59], [60, 62], [63, 66], [67, 75], [75, 76]]}
{"doc_key": "ai-test-174", "ner": [[0, 4, "conference"], [6, 7, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 6, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Association", "for", "Computational", "Linguistics", "defines", "computational", "linguistics", "as", ":"], "sentence-detokenized": "The Association for Computational Linguistics defines computational linguistics as:", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 45], [46, 53], [54, 67], [68, 79], [80, 82], [82, 83]]}
{"doc_key": "ai-test-175", "ner": [[0, 2, "algorithm"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 11, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Expectation", "maximization", "algorithms", "can", "be", "used", "to", "compute", "approximate", "maximum", "-likelihood", "estimates", "of", "unknown", "state", "parameters", "within", "filters", "and", "smoothing", "methods", "with", "minimal", "variation", "."], "sentence-detokenized": "Expectation maximization algorithms can be used to compute approximate maximum-likelihood estimates of unknown state parameters within filters and smoothing methods with minimal variation.", "token2charspan": [[0, 11], [12, 24], [25, 35], [36, 39], [40, 42], [43, 47], [48, 50], [51, 58], [59, 70], [71, 78], [78, 89], [90, 99], [100, 102], [103, 110], [111, 116], [117, 127], [128, 134], [135, 142], [143, 146], [147, 156], [157, 164], [165, 169], [170, 177], [178, 187], [187, 188]]}
{"doc_key": "ai-test-176", "ner": [[5, 7, "person"], [9, 10, "person"], [12, 13, "person"], [16, 17, "misc"], [18, 19, "person"], [22, 23, "person"], [27, 27, "person"], [29, 30, "person"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "relations": [[18, 19, 16, 17, "role", "model_for", false, false], [27, 27, 29, 30, "social", "family", false, false]], "relations_mapping_to_source": [3, 4], "sentence": ["Correspondents", "included", "former", "Baywatch", "actresses", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "and", "Traci", "Bingham", ",", "former", "Playboy", "Playmate", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", "and", "identical", "twins", "Randy", "and", "Jason", "Sklar", "."], "sentence-detokenized": "Correspondents included former Baywatch actresses Donna D'Errico, Carmen Electra and Traci Bingham, former Playboy Playmate Heidi Mark, comedian Arj Barker and identical twins Randy and Jason Sklar.", "token2charspan": [[0, 14], [15, 23], [24, 30], [31, 39], [40, 49], [50, 55], [56, 58], [58, 64], [64, 65], [66, 72], [73, 80], [81, 84], [85, 90], [91, 98], [98, 99], [100, 106], [107, 114], [115, 123], [124, 129], [130, 134], [134, 135], [136, 144], [145, 148], [149, 155], [156, 159], [160, 169], [170, 175], [176, 181], [182, 185], [186, 191], [192, 197], [197, 198]]}
{"doc_key": "ai-test-177", "ner": [[8, 9, "task"], [11, 11, "task"], [16, 18, "product"], [21, 22, "task"], [24, 24, "task"], [29, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [16, 18, 8, 9, "general-affiliation", "", false, false], [24, 24, 21, 22, "named", "", false, false], [29, 30, 21, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "is", "often", "used", "to", "create", "representations", "for", "speech", "recognition", "(", "ASR", ")", ",", "e.g.", "the", "CMU", "Sphinx", "system", ",", "and", "speech", "synthesis", "(", "TTS", ")", ",", "e.g.", "the", "Festival", "system", "."], "sentence-detokenized": "It is often used to create representations for speech recognition (ASR), e.g. the CMU Sphinx system, and speech synthesis (TTS), e.g. the Festival system.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 19], [20, 26], [27, 42], [43, 46], [47, 53], [54, 65], [66, 67], [67, 70], [70, 71], [71, 72], [73, 77], [78, 81], [82, 85], [86, 92], [93, 99], [99, 100], [101, 104], [105, 111], [112, 121], [122, 123], [123, 126], [126, 127], [127, 128], [129, 133], [134, 137], [138, 146], [147, 153], [153, 154]]}
{"doc_key": "ai-test-178", "ner": [[0, 0, "metrics"], [2, 4, "metrics"], [6, 6, "metrics"], [12, 12, "metrics"], [26, 27, "metrics"], [29, 29, "metrics"], [40, 41, "metrics"], [43, 43, "metrics"], [45, 47, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 4, 0, 0, "named", "", false, false], [6, 6, 2, 4, "named", "", false, false], [12, 12, 0, 0, "named", "", false, false], [29, 29, 26, 27, "named", "", false, false], [43, 43, 40, 41, "named", "", false, false], [45, 47, 40, 41, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sensitivity", "or", "TRUE", "Positive", "Rate", "(", "TPR", ")", ",", "also", "known", "as", "recall", ",", "is", "the", "proportion", "of", "people", "who", "test", "positive", "and", "are", "positive", "(", "TRUE", "Positive", ",", "TP", ")", "out", "of", "all", "people", "who", "are", "actually", "positive", "(", "Condition", "Positive", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "Sensitivity or TRUE Positive Rate (TPR), also known as recall, is the proportion of people who test positive and are positive (TRUE Positive, TP) out of all people who are actually positive (Condition Positive, CP = TP + FN).", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 28], [29, 33], [34, 35], [35, 38], [38, 39], [39, 40], [41, 45], [46, 51], [52, 54], [55, 61], [61, 62], [63, 65], [66, 69], [70, 80], [81, 83], [84, 90], [91, 94], [95, 99], [100, 108], [109, 112], [113, 116], [117, 125], [126, 127], [127, 131], [132, 140], [140, 141], [142, 144], [144, 145], [146, 149], [150, 152], [153, 156], [157, 163], [164, 167], [168, 171], [172, 180], [181, 189], [190, 191], [191, 200], [201, 209], [209, 210], [211, 213], [214, 215], [216, 218], [219, 220], [221, 223], [223, 224], [224, 225]]}
{"doc_key": "ai-test-179", "ner": [[1, 2, "task"], [11, 11, "conference"], [13, 14, "conference"], [16, 16, "conference"], [18, 20, "conference"], [22, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6], "relations": [[11, 11, 1, 2, "topic", "", false, false], [13, 14, 1, 2, "topic", "", false, false], [16, 16, 1, 2, "topic", "", false, false], [18, 20, 1, 2, "topic", "", false, false], [22, 23, 1, 2, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5], "sentence": ["Popular", "speech", "recognition", "conferences", "held", "every", "one", "or", "two", "years", "include", "SpeechTEK", "and", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "and", "IEEE", "ASRU", "."], "sentence-detokenized": "Popular speech recognition conferences held every one or two years include SpeechTEK and SpeechTEK Europe, ICASSP, Interspeech/Eurospeech and IEEE ASRU.", "token2charspan": [[0, 7], [8, 14], [15, 26], [27, 38], [39, 43], [44, 49], [50, 53], [54, 56], [57, 60], [61, 66], [67, 74], [75, 84], [85, 88], [89, 98], [99, 105], [105, 106], [107, 113], [113, 114], [115, 126], [126, 127], [127, 137], [138, 141], [142, 146], [147, 151], [151, 152]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [3, 3, "researcher"], [17, 18, "product"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 0, 0, "artifact", "", false, false], [21, 21, 3, 3, "artifact", "", false, false], [21, 21, 17, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "worked", "with", "Engelberger", ",", "who", "was", "the", "company", "'s", "CEO", ",", "to", "design", "and", "produce", "an", "industrial", "robot", "under", "the", "Unimate", "brand", "."], "sentence-detokenized": "Devol worked with Engelberger, who was the company's CEO, to design and produce an industrial robot under the Unimate brand.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 29], [29, 30], [31, 34], [35, 38], [39, 42], [43, 50], [50, 52], [53, 56], [56, 57], [58, 60], [61, 67], [68, 71], [72, 79], [80, 82], [83, 93], [94, 99], [100, 105], [106, 109], [110, 117], [118, 123], [123, 124]]}
{"doc_key": "ai-test-181", "ner": [[1, 3, "algorithm"], [5, 5, "algorithm"], [9, 13, "algorithm"], [23, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 9, 13, "general-affiliation", "", false, false], [5, 5, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "Hidden", "Markov", "Model", "(", "HMM", ")", "is", "a", "statistical", "Markov", "model", "in", "which", "the", "system", "being", "modelled", "is", "assumed", "to", "be", "a", "Markov", "process", "with", "unsupervised", "(", "hidden", ")", "states", "."], "sentence-detokenized": "A Hidden Markov Model (HMM) is a statistical Markov model in which the system being modelled is assumed to be a Markov process with unsupervised (hidden) states.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [22, 23], [23, 26], [26, 27], [28, 30], [31, 32], [33, 44], [45, 51], [52, 57], [58, 60], [61, 66], [67, 70], [71, 77], [78, 83], [84, 92], [93, 95], [96, 103], [104, 106], [107, 109], [110, 111], [112, 118], [119, 126], [127, 131], [132, 144], [145, 146], [146, 152], [152, 153], [154, 160], [160, 161]]}
{"doc_key": "ai-test-182", "ner": [[20, 22, "metrics"], [28, 28, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "property", ",", "which", "is", "undesirable", "in", "many", "applications", ",", "has", "led", "researchers", "to", "use", "alternatives", ",", "such", "as", "the", "mean", "absolute", "error", "or", "alternatives", "based", "on", "the", "median", "."], "sentence-detokenized": "This property, which is undesirable in many applications, has led researchers to use alternatives, such as the mean absolute error or alternatives based on the median.", "token2charspan": [[0, 4], [5, 13], [13, 14], [15, 20], [21, 23], [24, 35], [36, 38], [39, 43], [44, 56], [56, 57], [58, 61], [62, 65], [66, 77], [78, 80], [81, 84], [85, 97], [97, 98], [99, 103], [104, 106], [107, 110], [111, 115], [116, 124], [125, 130], [131, 133], [134, 146], [147, 152], [153, 155], [156, 159], [160, 166], [166, 167]]}
{"doc_key": "ai-test-183", "ner": [[22, 24, "algorithm"], [31, 35, "field"], [37, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 24, 31, 35, "part-of", "", false, false], [22, 24, 37, 39, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Such", "a", "sequence", "(", "which", "depends", "on", "the", "result", "of", "the", "examination", "of", "previous", "attributes", "in", "each", "step", ")", "is", "called", "a", "decision", "tree", "and", "is", "applied", "in", "the", "field", "of", "machine", "learning", ",", "which", "is", "called", "decision", "tree", "learning", "."], "sentence-detokenized": "Such a sequence (which depends on the result of the examination of previous attributes in each step) is called a decision tree and is applied in the field of machine learning, which is called decision tree learning.", "token2charspan": [[0, 4], [5, 6], [7, 15], [16, 17], [17, 22], [23, 30], [31, 33], [34, 37], [38, 44], [45, 47], [48, 51], [52, 63], [64, 66], [67, 75], [76, 86], [87, 89], [90, 94], [95, 99], [99, 100], [101, 103], [104, 110], [111, 112], [113, 121], [122, 126], [127, 130], [131, 133], [134, 141], [142, 144], [145, 148], [149, 154], [155, 157], [158, 165], [166, 174], [174, 175], [176, 181], [182, 184], [185, 191], [192, 200], [201, 205], [206, 214], [214, 215]]}
{"doc_key": "ai-test-184", "ner": [[2, 3, "task"], [5, 5, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 5, 5, "compare", "", false, false], [16, 17, 5, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "with", "factor", "analysis", ",", "LCA", "can", "also", "be", "used", "to", "classify", "cases", "according", "to", "their", "maximum", "likelihood", "class", "membership", "."], "sentence-detokenized": "As with factor analysis, LCA can also be used to classify cases according to their maximum likelihood class membership.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 23], [23, 24], [25, 28], [29, 32], [33, 37], [38, 40], [41, 45], [46, 48], [49, 57], [58, 63], [64, 73], [74, 76], [77, 82], [83, 90], [91, 101], [102, 107], [108, 118], [118, 119]]}
{"doc_key": "ai-test-185", "ner": [[0, 2, "algorithm"], [5, 8, "metrics"], [10, 10, "metrics"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 8, "usage", "", false, false], [5, 8, 12, 13, "related-to", "", false, false], [10, 10, 5, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Supervised", "neural", "networks", "using", "a", "mean", "-", "squared", "error", "(", "MSE", ")", "cost", "function", "can", "use", "formal", "statistical", "methods", "to", "determine", "the", "reliability", "of", "the", "trained", "model", "."], "sentence-detokenized": "Supervised neural networks using a mean-squared error (MSE) cost function can use formal statistical methods to determine the reliability of the trained model.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 32], [33, 34], [35, 39], [39, 40], [40, 47], [48, 53], [54, 55], [55, 58], [58, 59], [60, 64], [65, 73], [74, 77], [78, 81], [82, 88], [89, 100], [101, 108], [109, 111], [112, 121], [122, 125], [126, 137], [138, 140], [141, 144], [145, 152], [153, 158], [158, 159]]}
{"doc_key": "ai-test-186", "ner": [[16, 17, "algorithm"], [20, 22, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 20, 22, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "expressed", "directly", "as", "a", "linear", "program", ",", "but", "it", "is", "also", "equivalent", "to", "Tikhonov", "control", "with", "the", "loss", "function", "hanging", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=\\", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "This can be expressed directly as a linear program, but it is also equivalent to Tikhonov control with the loss function hanging, mathV (f (x), y) =\\ max (0, 1 - yf (x)) / math:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 21], [22, 30], [31, 33], [34, 35], [36, 42], [43, 50], [50, 51], [52, 55], [56, 58], [59, 61], [62, 66], [67, 77], [78, 80], [81, 89], [90, 97], [98, 102], [103, 106], [107, 111], [112, 120], [121, 128], [128, 129], [130, 135], [136, 137], [137, 138], [139, 140], [140, 141], [141, 142], [142, 143], [144, 145], [145, 146], [147, 149], [150, 153], [154, 155], [155, 156], [156, 157], [158, 159], [160, 161], [162, 164], [165, 166], [166, 167], [167, 168], [168, 169], [170, 171], [172, 176], [176, 177]]}
{"doc_key": "ai-test-187", "ner": [[6, 7, "researcher"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "technique", "was", "described", "in", "Breiman", "'s", "original", "article", "and", "has", "been", "implemented", "in", "the", "R", "package", "randomForest", "."], "sentence-detokenized": "The following technique was described in Breiman's original article and has been implemented in the R package randomForest.", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 27], [28, 37], [38, 40], [41, 48], [48, 50], [51, 59], [60, 67], [68, 71], [72, 75], [76, 80], [81, 92], [93, 95], [96, 99], [100, 101], [102, 109], [110, 122], [122, 123]]}
{"doc_key": "ai-test-188", "ner": [[7, 7, "metrics"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "image", "quality", "measures", ",", "such", "as", "PSNR", ",", "are", "usually", "performed", "on", "fixed", "resolution", "images", "and", "do", "not", "take", "into", "account", "certain", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "the", "change", "in", "spatial", "resolution", "across", "the", "retina", "."], "sentence-detokenized": "Traditional image quality measures, such as PSNR, are usually performed on fixed resolution images and do not take into account certain aspects of the human visual system, such as the change in spatial resolution across the retina.", "token2charspan": [[0, 11], [12, 17], [18, 25], [26, 34], [34, 35], [36, 40], [41, 43], [44, 48], [48, 49], [50, 53], [54, 61], [62, 71], [72, 74], [75, 80], [81, 91], [92, 98], [99, 102], [103, 105], [106, 109], [110, 114], [115, 119], [120, 127], [128, 135], [136, 143], [144, 146], [147, 150], [151, 156], [157, 163], [164, 170], [170, 171], [172, 176], [177, 179], [180, 183], [184, 190], [191, 193], [194, 201], [202, 212], [213, 219], [220, 223], [224, 230], [230, 231]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [10, 12, "person"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 17, "role", "", false, false], [3, 4, 16, 17, "role", "", false, false], [6, 7, 16, 17, "role", "", false, false], [16, 17, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "and", "Macdonald", "Carey", "starred", "in", "Jack", "Broder", "'s", "colour", "production", "of", "Hannah", "Lee", ",", "which", "opened", "on", "19", "June", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru and Macdonald Carey starred in Jack Broder's colour production of Hannah Lee, which opened on 19 June 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 55], [56, 60], [61, 67], [67, 69], [70, 76], [77, 87], [88, 90], [91, 97], [98, 101], [101, 102], [103, 108], [109, 115], [116, 118], [119, 121], [122, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-190", "ner": [[4, 6, "task"], [11, 12, "field"], [17, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 11, 12, "usage", "", false, false], [17, 17, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "process", "is", "called", "image", "registration", "and", "uses", "various", "methods", "of", "computer", "vision", ",", "mainly", "related", "to", "tracking", "."], "sentence-detokenized": "This process is called image registration and uses various methods of computer vision, mainly related to tracking.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 22], [23, 28], [29, 41], [42, 45], [46, 50], [51, 58], [59, 66], [67, 69], [70, 78], [79, 85], [85, 86], [87, 93], [94, 101], [102, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-191", "ner": [[17, 18, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Now", "let", "'s", "start", "explaining", "the", "different", "possible", "relationships", "between", "the", "predicted", "and", "the", "actual", "outcome", ":", "confusion", "matrix"], "sentence-detokenized": "Now let's start explaining the different possible relationships between the predicted and the actual outcome: confusion matrix", "token2charspan": [[0, 3], [4, 7], [7, 9], [10, 15], [16, 26], [27, 30], [31, 40], [41, 49], [50, 63], [64, 71], [72, 75], [76, 85], [86, 89], [90, 93], [94, 100], [101, 108], [108, 109], [110, 119], [120, 126]]}
{"doc_key": "ai-test-192", "ner": [[0, 4, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "VOICEBOX", "number", "processing", "toolkit", "for", "MATLAB", "implements", "the", "conversion", "and", "its", "reversal", "as", "follows", ":"], "sentence-detokenized": "The VOICEBOX number processing toolkit for MATLAB implements the conversion and its reversal as follows:", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 30], [31, 38], [39, 42], [43, 49], [50, 60], [61, 64], [65, 75], [76, 79], [80, 83], [84, 92], [93, 95], [96, 103], [103, 104]]}
{"doc_key": "ai-test-193", "ner": [[0, 1, "programlang"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 8, 9, "general-affiliation", "", false, false], [0, 1, 11, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logic", "programming", "language", "associated", "with", "artificial", "intelligence", "and", "computer", "linguistics", "."], "sentence-detokenized": "Prolog is a logic programming language associated with artificial intelligence and computer linguistics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 17], [18, 29], [30, 38], [39, 49], [50, 54], [55, 65], [66, 78], [79, 82], [83, 91], [92, 103], [103, 104]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [9, 9, "field"], [11, 11, "field"], [17, 20, "organisation"], [23, 26, "organisation"], [29, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 9, 9, "related-to", "works_with_topic", false, false], [0, 0, 11, 11, "related-to", "works_with_topic", false, false], [0, 0, 17, 20, "role", "", false, false], [0, 0, 23, 26, "role", "", false, false], [0, 0, 29, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "numerous", "awards", "for", "his", "contributions", "to", "neuroscience", "and", "psychology", ",", "including", "membership", "in", "the", "Royal", "Society", "of", "London", ",", "the", "Royal", "Society", "of", "Canada", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received numerous awards for his contributions to neuroscience and psychology, including membership in the Royal Society of London, the Royal Society of Canada and the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 35], [36, 39], [40, 43], [44, 57], [58, 60], [61, 73], [74, 77], [78, 88], [88, 89], [90, 99], [100, 110], [111, 113], [114, 117], [118, 123], [124, 131], [132, 134], [135, 141], [141, 142], [143, 146], [147, 152], [153, 160], [161, 163], [164, 170], [171, 174], [175, 178], [179, 187], [188, 195], [196, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-195", "ner": [[17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 29, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["By", "combining", "these", "operators", ",", "algorithms", "can", "be", "obtained", "for", "many", "image", "processing", "tasks", ",", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "sharpening", ",", "image", "filtering", "and", "classification", "."], "sentence-detokenized": "By combining these operators, algorithms can be obtained for many image processing tasks, such as feature extraction, image segmentation, image sharpening, image filtering and classification.", "token2charspan": [[0, 2], [3, 12], [13, 18], [19, 28], [28, 29], [30, 40], [41, 44], [45, 47], [48, 56], [57, 60], [61, 65], [66, 71], [72, 82], [83, 88], [88, 89], [90, 94], [95, 97], [98, 105], [106, 116], [116, 117], [118, 123], [124, 136], [136, 137], [138, 143], [144, 154], [154, 155], [156, 161], [162, 171], [172, 175], [176, 190], [190, 191]]}
{"doc_key": "ai-test-196", "ner": [[10, 12, "university"], [20, 22, "organisation"], [24, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[24, 25, 20, 22, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "2017", ",", "he", "has", "been", "a", "professor", "at", "the", "Coll\u00e8ge", "de", "France", "and", ",", "since", "1989", ",", "head", "of", "INSERM", "Unit", "562", ",", "Cognitive", "Neuroimaging", "."], "sentence-detokenized": "Since 2017, he has been a professor at the Coll\u00e8ge de France and, since 1989, head of INSERM Unit 562, Cognitive Neuroimaging.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 14], [15, 18], [19, 23], [24, 25], [26, 35], [36, 38], [39, 42], [43, 50], [51, 53], [54, 60], [61, 64], [64, 65], [66, 71], [72, 76], [76, 77], [78, 82], [83, 85], [86, 92], [93, 97], [98, 101], [101, 102], [103, 112], [113, 125], [125, 126]]}
{"doc_key": "ai-test-197", "ner": [[11, 12, "algorithm"], [14, 17, "algorithm"], [22, 22, "algorithm"], [24, 30, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 24, 30, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "many", "approaches", "to", "learning", "these", "embeddings", ",", "notably", "using", "Bayesian", "clustering", "or", "energy", "-", "based", "frameworks", ",", "and", "more", "recently", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", "2013", ")", "."], "sentence-detokenized": "There are many approaches to learning these embeddings, notably using Bayesian clustering or energy-based frameworks, and more recently TransE (Conference on Neural Information Processing Systems 2013).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 25], [26, 28], [29, 37], [38, 43], [44, 54], [54, 55], [56, 63], [64, 69], [70, 78], [79, 89], [90, 92], [93, 99], [99, 100], [100, 105], [106, 116], [116, 117], [118, 121], [122, 126], [127, 135], [136, 142], [143, 144], [144, 154], [155, 157], [158, 164], [165, 176], [177, 187], [188, 195], [196, 200], [200, 201], [201, 202]]}
{"doc_key": "ai-test-198", "ner": [[6, 7, "metrics"], [8, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 8, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "is", "an", "alternative", "to", "the", "Word", "Error", "Rate", "used", "in", "several", "countries", "."], "sentence-detokenized": "It is an alternative to the Word Error Rate used in several countries.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 23], [24, 27], [28, 32], [33, 38], [39, 43], [44, 48], [49, 51], [52, 59], [60, 69], [69, 70]]}
{"doc_key": "ai-test-199", "ner": [[0, 0, "algorithm"], [11, 12, "task"], [14, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 27, "task"], [29, 30, "task"], [46, 46, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 0, 0, "usage", "", false, false], [14, 15, 0, 0, "usage", "", false, false], [17, 18, 0, 0, "usage", "", false, false], [20, 22, 0, 0, "usage", "", false, false], [24, 27, 0, 0, "usage", "", false, false], [29, 30, 0, 0, "usage", "", false, false], [46, 46, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "have", "been", "used", "for", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "board", "and", "video", "games", ",", "medical", "diagnostics", ",", "and", "even", "for", "activities", "traditionally", "thought", "of", "as", "reserved", "for", "humans", ",", "such", "as", "painting", "."], "sentence-detokenized": "ANNs have been used for a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, board and video games, medical diagnostics, and even for activities traditionally thought of as reserved for humans, such as painting.", "token2charspan": [[0, 4], [5, 9], [10, 14], [15, 19], [20, 23], [24, 25], [26, 33], [34, 36], [37, 42], [42, 43], [44, 53], [54, 62], [63, 69], [69, 70], [71, 77], [78, 89], [89, 90], [91, 98], [99, 110], [110, 111], [112, 118], [119, 126], [127, 136], [136, 137], [138, 143], [144, 147], [148, 153], [154, 159], [159, 160], [161, 168], [169, 180], [180, 181], [182, 185], [186, 190], [191, 194], [195, 205], [206, 219], [220, 227], [228, 230], [231, 233], [234, 242], [243, 246], [247, 253], [253, 254], [255, 259], [260, 262], [263, 271], [271, 272]]}
{"doc_key": "ai-test-200", "ner": [[0, 4, "product"], [6, 6, "product"], [26, 28, "field"], [30, 30, "field"], [35, 35, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 26, 28, "related-to", "", false, false], [0, 4, 35, 35, "general-affiliation", "", false, false], [6, 6, 0, 4, "named", "", false, false], [30, 30, 26, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "is", "an", "open", "source", "research", "platform", "and", "a", "collection", "of", "voice", ",", "audio", ",", "speech", ",", "text", "and", "natural", "language", "processing", "(", "NLP", ")", "algorithms", "written", "in", "Java", "and", "arranged", "in", "a", "modular", "and", "extensible", "framework", "that", "seeks", "to", "facilitate", "the", "addition", "of", "new", "algorithms", "."], "sentence-detokenized": "The Modular Audio Recognition Framework (MARF) is an open source research platform and a collection of voice, audio, speech, text and natural language processing (NLP) algorithms written in Java and arranged in a modular and extensible framework that seeks to facilitate the addition of new algorithms.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 29], [30, 39], [40, 41], [41, 45], [45, 46], [47, 49], [50, 52], [53, 57], [58, 64], [65, 73], [74, 82], [83, 86], [87, 88], [89, 99], [100, 102], [103, 108], [108, 109], [110, 115], [115, 116], [117, 123], [123, 124], [125, 129], [130, 133], [134, 141], [142, 150], [151, 161], [162, 163], [163, 166], [166, 167], [168, 178], [179, 186], [187, 189], [190, 194], [195, 198], [199, 207], [208, 210], [211, 212], [213, 220], [221, 224], [225, 235], [236, 245], [246, 250], [251, 256], [257, 259], [260, 270], [271, 274], [275, 283], [284, 286], [287, 290], [291, 301], [301, 302]]}
{"doc_key": "ai-test-201", "ner": [[9, 11, "organisation"], [15, 15, "country"], [19, 21, "organisation"], [24, 25, "organisation"], [32, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 6], "relations": [[19, 21, 15, 15, "physical", "", false, false], [24, 25, 15, 15, "physical", "", false, false]], "relations_mapping_to_source": [0, 3], "sentence": ["In", "2018", ",", "a", "report", "by", "civil", "liberties", "organisation", "Big", "Brother", "Watch", "revealed", "that", "two", "UK", "police", "forces", ",", "South", "Wales", "Police", "and", "the", "Metropolitan", "Police", ",", "were", "using", "real", "-", "time", "facial", "recognition", "at", "public", "events", "and", "in", "public", "places", "."], "sentence-detokenized": "In 2018, a report by civil liberties organisation Big Brother Watch revealed that two UK police forces, South Wales Police and the Metropolitan Police, were using real-time facial recognition at public events and in public places.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 20], [21, 26], [27, 36], [37, 49], [50, 53], [54, 61], [62, 67], [68, 76], [77, 81], [82, 85], [86, 88], [89, 95], [96, 102], [102, 103], [104, 109], [110, 115], [116, 122], [123, 126], [127, 130], [131, 143], [144, 150], [150, 151], [152, 156], [157, 162], [163, 167], [167, 168], [168, 172], [173, 179], [180, 191], [192, 194], [195, 201], [202, 208], [209, 212], [213, 215], [216, 222], [223, 229], [229, 230]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [5, 7, "programlang"], [14, 15, "field"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 7, "general-affiliation", "", false, false], [0, 0, 14, 15, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "has", "been", "ported", "to", "R", ",", "a", "freely", "available", "language", "and", "environment", "for", "statistical", "calculations", "and", "graphics", "."], "sentence-detokenized": "ANIMAL has been ported to R, a freely available language and environment for statistical calculations and graphics.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [23, 25], [26, 27], [27, 28], [29, 30], [31, 37], [38, 47], [48, 56], [57, 60], [61, 72], [73, 76], [77, 88], [89, 101], [102, 105], [106, 114], [114, 115]]}
{"doc_key": "ai-test-203", "ner": [[0, 5, "algorithm"], [7, 12, "algorithm"], [16, 18, "algorithm"], [20, 20, "algorithm"], [23, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 16, 18, "opposite", "alternative to", false, false], [7, 12, 0, 5, "named", "", false, false], [20, 20, 16, 18, "named", "", false, false], [23, 25, 0, 5, "usage", "", false, false], [23, 25, 16, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Time", "Inhomogeneous", "Hidden", "Bernoulli", "Model", "(", "TI", "-", "HBM", ")", "is", "an", "alternative", "to", "the", "Hidden", "Markov", "Model", "(", "HMM", ")", "for", "automatic", "speech", "recognition", "."], "sentence-detokenized": "The Time Inhomogeneous Hidden Bernoulli Model (TI-HBM) is an alternative to the Hidden Markov Model (HMM) for automatic speech recognition.", "token2charspan": [[0, 3], [4, 8], [9, 22], [23, 29], [30, 39], [40, 45], [46, 47], [47, 49], [49, 50], [50, 53], [53, 54], [55, 57], [58, 60], [61, 72], [73, 75], [76, 79], [80, 86], [87, 93], [94, 99], [100, 101], [101, 104], [104, 105], [106, 109], [110, 119], [120, 126], [127, 138], [138, 139]]}
{"doc_key": "ai-test-204", "ner": [[4, 4, "organisation"], [7, 7, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 7, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "Nvidia", "demonstrated", "during", "SIGGRAPH", "a", "new", "method", "of", "foveated", "rendering", "that", "was", "claimed", "to", "be", "invisible", "to", "users", "."], "sentence-detokenized": "In July 2016, Nvidia demonstrated during SIGGRAPH a new method of foveated rendering that was claimed to be invisible to users.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 33], [34, 40], [41, 49], [50, 51], [52, 55], [56, 62], [63, 65], [66, 74], [75, 84], [85, 89], [90, 93], [94, 101], [102, 104], [105, 107], [108, 117], [118, 120], [121, 126], [126, 127]]}
{"doc_key": "ai-test-205", "ner": [[4, 8, "misc"], [12, 13, "researcher"], [20, 21, "researcher"], [23, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 8, 12, 13, "origin", "", false, false], [4, 8, 20, 21, "origin", "", false, false], [4, 8, 23, 25, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Both", "are", "based", "on", "the", "theory", "of", "speech", "acts", ",", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "refined", "by", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both are based on the theory of speech acts, developed by John Searle in the 1960s and refined by Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 17], [18, 21], [22, 28], [29, 31], [32, 38], [39, 43], [43, 44], [45, 54], [55, 57], [58, 62], [63, 69], [70, 72], [73, 76], [77, 82], [83, 86], [87, 94], [95, 97], [98, 103], [104, 112], [113, 116], [117, 123], [124, 126], [127, 130], [131, 136], [136, 137]]}
{"doc_key": "ai-test-206", "ner": [[0, 2, "algorithm"], [21, 23, "researcher"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 21, 23, "related-to", "", false, false], [24, 24, 21, 23, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "knowledge", "structure", "have", "opened", "up", "powerful", "hierarchical", "models", "of", "knowledge", "organisation", ",", "such", "as", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "Neural network models of concept formation and knowledge structure have opened up powerful hierarchical models of knowledge organisation, such as George Miller's Wordnet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 56], [57, 66], [67, 71], [72, 78], [79, 81], [82, 90], [91, 103], [104, 110], [111, 113], [114, 123], [124, 136], [136, 137], [138, 142], [143, 145], [146, 152], [153, 159], [159, 161], [162, 169], [169, 170]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [7, 8, "field"], [11, 13, "product"], [16, 17, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 7, 8, "part-of", "", false, false], [0, 1, 16, 17, "part-of", "", false, false], [11, 13, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Template", "matching", "has", "various", "applications", ",", "including", "facial", "recognition", "(", "see", "facial", "recognition", "systems", ")", "and", "medical", "imaging", "."], "sentence-detokenized": "Template matching has various applications, including facial recognition (see facial recognition systems) and medical imaging.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 29], [30, 42], [42, 43], [44, 53], [54, 60], [61, 72], [73, 74], [74, 77], [78, 84], [85, 96], [97, 104], [104, 105], [106, 109], [110, 117], [118, 125], [125, 126]]}
{"doc_key": "ai-test-208", "ner": [[11, 12, "researcher"], [14, 15, "researcher"], [20, 29, "organisation"], [31, 31, "organisation"], [39, 40, "algorithm"], [43, 49, "conference"], [51, 51, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 12, 20, 29, "role", "", false, false], [11, 12, 43, 49, "physical", "", false, false], [11, 12, 43, 49, "temporal", "", false, false], [11, 12, 51, 51, "physical", "", false, false], [14, 15, 20, 29, "role", "", false, false], [14, 15, 43, 49, "temporal", "", false, false], [31, 31, 20, 29, "named", "", false, false], [43, 49, 39, 40, "topic", "", false, false], [51, 51, 43, 49, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "it", "s", "use", "only", "became", "widespread", "in", "2005", "when", "Navneet", "Dalal", "and", "Bill", "Triggs", ",", "researchers", "at", "the", "French", "National", "Institute", "for", "Research", "in", "Computer", "Science", "and", "Automation", "(", "INRIA", ")", ",", "presented", "their", "complementary", "work", "on", "HOG", "descriptors", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "However, its use only became widespread in 2005 when Navneet Dalal and Bill Triggs, researchers at the French National Institute for Research in Computer Science and Automation (INRIA), presented their complementary work on HOG descriptors at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 7], [7, 8], [9, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 39], [40, 42], [43, 47], [48, 52], [53, 60], [61, 66], [67, 70], [71, 75], [76, 82], [82, 83], [84, 95], [96, 98], [99, 102], [103, 109], [110, 118], [119, 128], [129, 132], [133, 141], [142, 144], [145, 153], [154, 161], [162, 165], [166, 176], [177, 178], [178, 183], [183, 184], [184, 185], [186, 195], [196, 201], [202, 215], [216, 220], [221, 223], [224, 227], [228, 239], [240, 242], [243, 246], [247, 257], [258, 260], [261, 269], [270, 276], [277, 280], [281, 288], [289, 300], [301, 302], [302, 306], [306, 307], [307, 308]]}
{"doc_key": "ai-test-209", "ner": [[17, 19, "organisation"], [21, 22, "organisation"], [35, 37, "researcher"], [39, 42, "researcher"], [45, 47, "researcher"], [50, 53, "organisation"], [57, 59, "organisation"], [64, 65, "researcher"]], "ner_mapping_to_source": [1, 2, 4, 5, 6, 7, 8, 9], "relations": [[35, 37, 21, 22, "physical", "", false, false], [35, 37, 21, 22, "role", "", false, false], [39, 42, 21, 22, "physical", "", false, false], [39, 42, 21, 22, "role", "", false, false], [45, 47, 21, 22, "physical", "", false, false], [45, 47, 21, 22, "role", "", false, false], [64, 65, 57, 59, "role", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "sentence": ["Prior", "to", "joining", "the", "Penn", "faculty", "in", "2002", ",", "he", "spent", "ten", "years", "(", "1991-2001", ")", "at", "AT", "&T", "Labs", "and", "Bell", "Labs", ",", "including", "as", "head", "of", "the", "AI", "Division", "with", "colleagues", "such", "as", "Michael", "L.", "Littman", ",", "David", "A", ".", "McAllester", ",", "and", "Richard", "S.", "Sutton", ",", "the", "Secure", "Systems", "Research", "Division", ",", "and", "the", "Machine", "Learning", "Division", "with", "members", "such", "as", "Michael", "Collins", "and", "the", "leader", ")", "."], "sentence-detokenized": "Prior to joining the Penn faculty in 2002, he spent ten years (1991-2001) at AT&T Labs and Bell Labs, including as head of the AI Division with colleagues such as Michael L. Littman, David A. McAllester, and Richard S. Sutton, the Secure Systems Research Division, and the Machine Learning Division with members such as Michael Collins and the leader).", "token2charspan": [[0, 5], [6, 8], [9, 16], [17, 20], [21, 25], [26, 33], [34, 36], [37, 41], [41, 42], [43, 45], [46, 51], [52, 55], [56, 61], [62, 63], [63, 72], [72, 73], [74, 76], [77, 79], [79, 81], [82, 86], [87, 90], [91, 95], [96, 100], [100, 101], [102, 111], [112, 114], [115, 119], [120, 122], [123, 126], [127, 129], [130, 138], [139, 143], [144, 154], [155, 159], [160, 162], [163, 170], [171, 173], [174, 181], [181, 182], [183, 188], [189, 190], [190, 191], [192, 202], [202, 203], [204, 207], [208, 215], [216, 218], [219, 225], [225, 226], [227, 230], [231, 237], [238, 245], [246, 254], [255, 263], [263, 264], [265, 268], [269, 272], [273, 280], [281, 289], [290, 298], [299, 303], [304, 311], [312, 316], [317, 319], [320, 327], [328, 335], [336, 339], [340, 343], [344, 350], [350, 351], [351, 352]]}
{"doc_key": "ai-test-210", "ner": [[5, 6, "field"], [13, 13, "field"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 13, 13, "compare", "", false, false], [23, 24, 13, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["When", "data", "is", "unlabeled", ",", "supervised", "learning", "is", "not", "possible", ",", "but", "an", "unsupervised", "learning", "method", "is", "required", "that", "attempts", "to", "find", "natural", "cluster", "analyses", "to", "groups", "and", "then", "map", "new", "data", "to", "these", "formed", "groups", "."], "sentence-detokenized": "When data is unlabeled, supervised learning is not possible, but an unsupervised learning method is required that attempts to find natural cluster analyses to groups and then map new data to these formed groups.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 22], [22, 23], [24, 34], [35, 43], [44, 46], [47, 50], [51, 59], [59, 60], [61, 64], [65, 67], [68, 80], [81, 89], [90, 96], [97, 99], [100, 108], [109, 113], [114, 122], [123, 125], [126, 130], [131, 138], [139, 146], [147, 155], [156, 158], [159, 165], [166, 169], [170, 174], [175, 178], [179, 182], [183, 187], [188, 190], [191, 196], [197, 203], [204, 210], [210, 211]]}
{"doc_key": "ai-test-211", "ner": [[3, 4, "field"], [15, 18, "organisation"], [25, 26, "field"], [28, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 15, 18, "origin", "", false, false], [3, 4, 25, 26, "part-of", "", false, false], [3, 4, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "field", "of", "computer", "science", "developed", "in", "the", "1950s", "at", "academic", "institutions", "such", "as", "the", "MIT", "A.I", ".", "Lab", ",", "originally", "as", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "This field of computer science developed in the 1950s at academic institutions such as the MIT A.I. Lab, originally as a branch of artificial intelligence and robotics.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 30], [31, 40], [41, 43], [44, 47], [48, 53], [54, 56], [57, 65], [66, 78], [79, 83], [84, 86], [87, 90], [91, 94], [95, 98], [98, 99], [100, 103], [103, 104], [105, 115], [116, 118], [119, 120], [121, 127], [128, 130], [131, 141], [142, 154], [155, 158], [159, 167], [167, 168]]}
{"doc_key": "ai-test-212", "ner": [[7, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "can", "also", "be", "replaced", "by", "the", "Log", "loss", "equation", "below", ":"], "sentence-detokenized": "It can also be replaced by the Log loss equation below:", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 23], [24, 26], [27, 30], [31, 34], [35, 39], [40, 48], [49, 54], [54, 55]]}
{"doc_key": "ai-test-213", "ner": [[0, 2, "organisation"], [6, 9, "organisation"], [13, 17, "university"], [19, 19, "university"], [21, 22, "university"], [25, 27, "university"], [30, 32, "country"], [36, 36, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 36, 36, "related-to", "research_leader_in_field", false, false], [6, 9, 0, 2, "named", "", false, false], [6, 9, 36, 36, "related-to", "research_leader_in_field", false, false], [13, 17, 36, 36, "related-to", "research_leader_in_field", false, false], [19, 19, 36, 36, "related-to", "research_leader_in_field", false, false], [21, 22, 36, 36, "related-to", "research_leader_in_field", false, false], [25, 27, 30, 32, "physical", "", false, false], [25, 27, 36, 36, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Shirley", "Ryan", "AbilityLab", "(", "formerly", "the", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "the", "University", "of", "California", "at", "Berkeley", ",", "MIT", ",", "Stanford", "University", "and", "the", "University", "of", "Twente", "in", "the", "Netherlands", "are", "the", "leading", "researchers", "in", "biocatronics", "."], "sentence-detokenized": "Shirley Ryan AbilityLab (formerly the Rehabilitation Institute of Chicago), the University of California at Berkeley, MIT, Stanford University and the University of Twente in the Netherlands are the leading researchers in biocatronics.", "token2charspan": [[0, 7], [8, 12], [13, 23], [24, 25], [25, 33], [34, 37], [38, 52], [53, 62], [63, 65], [66, 73], [73, 74], [74, 75], [76, 79], [80, 90], [91, 93], [94, 104], [105, 107], [108, 116], [116, 117], [118, 121], [121, 122], [123, 131], [132, 142], [143, 146], [147, 150], [151, 161], [162, 164], [165, 171], [172, 174], [175, 178], [179, 190], [191, 194], [195, 198], [199, 206], [207, 218], [219, 221], [222, 234], [234, 235]]}
{"doc_key": "ai-test-214", "ner": [[28, 31, "metrics"], [42, 43, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Given", "a", "set", "of", "forecast", "values", "and", "a", "corresponding", "set", "of", "actual", "values", "for", "X", "over", "different", "time", "periods", ",", "a", "common", "evaluation", "technique", "is", "to", "use", "the", "mean", "squared", "forecast", "error", ";", "other", "measures", "are", "also", "available", "(", "see", "forecasts", "#", "forecast", "accuracy", ")", "."], "sentence-detokenized": "Given a set of forecast values and a corresponding set of actual values for X over different time periods, a common evaluation technique is to use the mean squared forecast error; other measures are also available (see forecasts # forecast accuracy).", "token2charspan": [[0, 5], [6, 7], [8, 11], [12, 14], [15, 23], [24, 30], [31, 34], [35, 36], [37, 50], [51, 54], [55, 57], [58, 64], [65, 71], [72, 75], [76, 77], [78, 82], [83, 92], [93, 97], [98, 105], [105, 106], [107, 108], [109, 115], [116, 126], [127, 136], [137, 139], [140, 142], [143, 146], [147, 150], [151, 155], [156, 163], [164, 172], [173, 178], [178, 179], [180, 185], [186, 194], [195, 198], [199, 203], [204, 213], [214, 215], [215, 218], [219, 228], [229, 230], [231, 239], [240, 248], [248, 249], [249, 250]]}
{"doc_key": "ai-test-215", "ner": [[13, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "measures", ",", "such", "as", "the", "proportion", "of", "correct", "predictions", "(", "also", "called", "accuracy", ")", ",", "are", "not", "useful", "when", "the", "two", "classes", "are", "very", "different", "in", "size", "."], "sentence-detokenized": "Other measures, such as the proportion of correct predictions (also called accuracy), are not useful when the two classes are very different in size.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 20], [21, 23], [24, 27], [28, 38], [39, 41], [42, 49], [50, 61], [62, 63], [63, 67], [68, 74], [75, 83], [83, 84], [84, 85], [86, 89], [90, 93], [94, 100], [101, 105], [106, 109], [110, 113], [114, 121], [122, 125], [126, 130], [131, 140], [141, 143], [144, 148], [148, 149]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [15, 19, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 15, 19, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "released", "to", "the", "public", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "in", "2000", ",", "and", "five", "beta", "versions", "were", "released", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was released to the public at the Conference on Computer Vision and Pattern Recognition in 2000, and five beta versions were released between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 46], [47, 49], [50, 53], [54, 60], [61, 63], [64, 67], [68, 78], [79, 81], [82, 90], [91, 97], [98, 101], [102, 109], [110, 121], [122, 124], [125, 129], [129, 130], [131, 134], [135, 139], [140, 144], [145, 153], [154, 158], [159, 167], [168, 175], [176, 180], [181, 184], [185, 189], [189, 190]]}
{"doc_key": "ai-test-217", "ner": [[22, 22, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Results", "have", "been", "presented", "that", "give", "a", "correlation", "of", "up", "to", "0.964", "with", "human", "assessments", "at", "the", "corpus", "level", ",", "compared", "to", "BLEU", "'s", "result", "of", "0.817", "on", "the", "same", "data", "set", "."], "sentence-detokenized": "Results have been presented that give a correlation of up to 0.964 with human assessments at the corpus level, compared to BLEU's result of 0.817 on the same data set.", "token2charspan": [[0, 7], [8, 12], [13, 17], [18, 27], [28, 32], [33, 37], [38, 39], [40, 51], [52, 54], [55, 57], [58, 60], [61, 66], [67, 71], [72, 77], [78, 89], [90, 92], [93, 96], [97, 103], [104, 109], [109, 110], [111, 119], [120, 122], [123, 127], [127, 129], [130, 136], [137, 139], [140, 145], [146, 148], [149, 152], [153, 157], [158, 162], [163, 166], [166, 167]]}
{"doc_key": "ai-test-218", "ner": [[4, 4, "metrics"], [20, 20, "metrics"], [22, 24, "metrics"], [26, 28, "metrics"], [39, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 20, 20, "compare", "", false, false], [4, 4, 22, 24, "compare", "", false, false], [4, 4, 26, 28, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["An", "early", "version", "of", "VMAF", "has", "been", "shown", "to", "outperform", "other", "measures", "of", "image", "and", "video", "quality", ",", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", "and", "VQM", "-", "VFD", ",", "on", "three", "out", "of", "four", "datasets", "in", "terms", "of", "prediction", "accuracy", ",", "compared", "to", "subjective", "assessments", "."], "sentence-detokenized": "An early version of VMAF has been shown to outperform other measures of image and video quality, such as SSIM, PSNR -HVS and VQM-VFD, on three out of four datasets in terms of prediction accuracy, compared to subjective assessments.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 19], [20, 24], [25, 28], [29, 33], [34, 39], [40, 42], [43, 53], [54, 59], [60, 68], [69, 71], [72, 77], [78, 81], [82, 87], [88, 95], [95, 96], [97, 101], [102, 104], [105, 109], [109, 110], [111, 115], [116, 117], [117, 120], [121, 124], [125, 128], [128, 129], [129, 132], [132, 133], [134, 136], [137, 142], [143, 146], [147, 149], [150, 154], [155, 163], [164, 166], [167, 172], [173, 175], [176, 186], [187, 195], [195, 196], [197, 205], [206, 208], [209, 219], [220, 231], [231, 232]]}
{"doc_key": "ai-test-219", "ner": [[18, 19, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 25, 26, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "in", "\"", "mouse", "\"", "(", "animal", "or", "device", ")", "is", "not", "relevant", "for", "machine", "translation", ",", "but", "is", "relevant", "for", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity in \"mouse\" (animal or device) is not relevant for machine translation, but is relevant for information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 31], [31, 36], [36, 37], [38, 39], [39, 45], [46, 48], [49, 55], [55, 56], [57, 59], [60, 63], [64, 72], [73, 76], [77, 84], [85, 96], [96, 97], [98, 101], [102, 104], [105, 113], [114, 117], [118, 129], [130, 139], [139, 140]]}
{"doc_key": "ai-test-220", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 1, "usage", "", false, false], [9, 10, 6, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "hashing", "was", "originally", "proposed", "in", "computer", "vision", "for", "object", "recognition", "in", "2D", "and", "3D", ","], "sentence-detokenized": "Geometric hashing was originally proposed in computer vision for object recognition in 2D and 3D,", "token2charspan": [[0, 9], [10, 17], [18, 21], [22, 32], [33, 41], [42, 44], [45, 53], [54, 60], [61, 64], [65, 71], [72, 83], [84, 86], [87, 89], [90, 93], [94, 96], [96, 97]]}
{"doc_key": "ai-test-221", "ner": [[9, 10, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 9, 10, "part-of", "subfield", false, false], [17, 18, 9, 10, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "is", "one", "of", "the", "three", "main", "categories", "of", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "It is one of the three main categories of machine learning, along with supervised learning and reinforcement learning.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 12], [13, 16], [17, 22], [23, 27], [28, 38], [39, 41], [42, 49], [50, 58], [58, 59], [60, 65], [66, 70], [71, 81], [82, 90], [91, 94], [95, 108], [109, 117], [117, 118]]}
{"doc_key": "ai-test-222", "ner": [[5, 6, "field"], [16, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"], [27, 30, "field"], [32, 33, "field"], [35, 36, "field"], [38, 38, "field"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[5, 6, 16, 16, "part-of", "subfield", false, false], [5, 6, 18, 19, "part-of", "subfield", false, false], [5, 6, 21, 22, "part-of", "subfield", false, false], [5, 6, 24, 25, "part-of", "subfield", false, false], [5, 6, 27, 30, "part-of", "subfield", false, false], [5, 6, 32, 33, "part-of", "subfield", false, false], [5, 6, 35, 36, "part-of", "subfield", false, false], [5, 6, 38, 38, "part-of", "subfield", false, false], [5, 6, 41, 42, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Because", "of", "its", "generality", ",", "reinforcement", "learning", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "games", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimization", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", ",", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Because of its generality, reinforcement learning is studied in many other disciplines, such as games, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics, and genetic algorithms.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [25, 26], [27, 40], [41, 49], [50, 52], [53, 60], [61, 63], [64, 68], [69, 74], [75, 86], [86, 87], [88, 92], [93, 95], [96, 101], [101, 102], [103, 110], [111, 117], [117, 118], [119, 129], [130, 138], [138, 139], [140, 151], [152, 158], [158, 159], [160, 170], [170, 171], [171, 176], [177, 189], [189, 190], [191, 202], [203, 210], [210, 211], [212, 217], [218, 230], [230, 231], [232, 242], [242, 243], [244, 247], [248, 255], [256, 266], [266, 267]]}
{"doc_key": "ai-test-223", "ner": [[0, 1, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "related-to", "", false, false], [0, 1, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pattern", "recognition", "is", "closely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ","], "sentence-detokenized": "Pattern recognition is closely related to artificial intelligence and machine learning,", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 38], [39, 41], [42, 52], [53, 65], [66, 69], [70, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-224", "ner": [[10, 11, "algorithm"], [14, 15, "field"], [17, 18, "field"], [29, 30, "task"], [32, 32, "task"], [34, 35, "task"], [37, 38, "algorithm"], [40, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 14, 15, "related-to", "", false, false], [10, 11, 17, 18, "related-to", "", false, false], [29, 30, 10, 11, "usage", "", true, false], [32, 32, 10, 11, "usage", "", true, false], [34, 35, 10, 11, "usage", "", true, false], [37, 38, 10, 11, "usage", "", true, false], [40, 42, 10, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "software", "is", "used", "to", "design", ",", "train", "and", "use", "neural", "network", "models", "(", "supervised", "learning", "and", "unsupervised", "learning", ")", "to", "perform", "a", "variety", "of", "tasks", ",", "such", "as", "data", "mining", ",", "classification", ",", "feature", "approximation", ",", "multivariate", "regression", "and", "time", "series", "forecasting", "."], "sentence-detokenized": "The software is used to design, train and use neural network models (supervised learning and unsupervised learning) to perform a variety of tasks, such as data mining, classification, feature approximation, multivariate regression and time series forecasting.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [21, 23], [24, 30], [30, 31], [32, 37], [38, 41], [42, 45], [46, 52], [53, 60], [61, 67], [68, 69], [69, 79], [80, 88], [89, 92], [93, 105], [106, 114], [114, 115], [116, 118], [119, 126], [127, 128], [129, 136], [137, 139], [140, 145], [145, 146], [147, 151], [152, 154], [155, 159], [160, 166], [166, 167], [168, 182], [182, 183], [184, 191], [192, 205], [205, 206], [207, 219], [220, 230], [231, 234], [235, 239], [240, 246], [247, 258], [258, 259]]}
{"doc_key": "ai-test-225", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016, he was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-test-226", "ner": [[6, 9, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", "and", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", ","], "sentence-detokenized": "She is a member of the National Academy of Sciences (since 2005) and the American Academy of Arts and Sciences (since 2009),", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 15], [16, 18], [19, 22], [23, 31], [32, 39], [40, 42], [43, 51], [52, 53], [53, 58], [59, 63], [63, 64], [65, 68], [69, 72], [73, 81], [82, 89], [90, 92], [93, 97], [98, 101], [102, 110], [111, 112], [112, 117], [118, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-test-227", "ner": [[3, 5, "misc"], [10, 15, "product"], [17, 17, "country"], [19, 19, "country"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 15, 3, 5, "temporal", "", false, false], [10, 15, 17, 17, "physical", "", false, false], [10, 15, 19, 19, "physical", "", false, false], [10, 15, 24, 25, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "the", "1973", "Yom", "Kippur", "War", ",", "Soviet", "batteries", "of", "surface", "-", "to", "-", "air", "missiles", "in", "Egypt", "and", "Syria", "caused", "heavy", "damage", "to", "Israeli", "warplanes", "."], "sentence-detokenized": "During the 1973 Yom Kippur War, Soviet batteries of surface-to-air missiles in Egypt and Syria caused heavy damage to Israeli warplanes.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 26], [27, 30], [30, 31], [32, 38], [39, 48], [49, 51], [52, 59], [59, 60], [60, 62], [62, 63], [63, 66], [67, 75], [76, 78], [79, 84], [85, 88], [89, 94], [95, 101], [102, 107], [108, 114], [115, 117], [118, 125], [126, 135], [135, 136]]}
{"doc_key": "ai-test-228", "ner": [[9, 10, "product"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "resource", "(", "free", "but", "copyrighted", ")", "is", "the", "HTK", "book", "(", "and", "the", "associated", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another resource (free but copyrighted) is the HTK book (and the associated HTK toolkit).", "token2charspan": [[0, 7], [8, 16], [17, 18], [18, 22], [23, 26], [27, 38], [38, 39], [40, 42], [43, 46], [47, 50], [51, 55], [56, 57], [57, 60], [61, 64], [65, 75], [76, 79], [80, 87], [87, 88], [88, 89]]}
{"doc_key": "ai-test-229", "ner": [[5, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "was", "taken", "at", "the", "AAAI", "Spring", "Symposium", "2004", ",", "where", "linguists", ",", "computer", "scientists", "and", "other", "interested", "researchers", "for", "the", "first", "time", "pooled", "their", "interests", "and", "proposed", "common", "data", "and", "reference", "datasets", "for", "systematic", "computational", "research", "on", "affect", ",", "appeal", ",", "subjectivity", "and", "emotion", "in", "text", "."], "sentence-detokenized": "- was taken at the AAAI Spring Symposium 2004, where linguists, computer scientists and other interested researchers for the first time pooled their interests and proposed common data and reference datasets for systematic computational research on affect, appeal, subjectivity and emotion in text.", "token2charspan": [[0, 1], [2, 5], [6, 11], [12, 14], [15, 18], [19, 23], [24, 30], [31, 40], [41, 45], [45, 46], [47, 52], [53, 62], [62, 63], [64, 72], [73, 83], [84, 87], [88, 93], [94, 104], [105, 116], [117, 120], [121, 124], [125, 130], [131, 135], [136, 142], [143, 148], [149, 158], [159, 162], [163, 171], [172, 178], [179, 183], [184, 187], [188, 197], [198, 206], [207, 210], [211, 221], [222, 235], [236, 244], [245, 247], [248, 254], [254, 255], [256, 262], [262, 263], [264, 276], [277, 280], [281, 288], [289, 291], [292, 296], [296, 297]]}
{"doc_key": "ai-test-230", "ner": [[12, 13, "task"], [18, 19, "task"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "single", "grid", "can", "be", "analysed", "both", "in", "terms", "of", "content", "(", "visual", "inspection", ")", "and", "structure", "(", "cluster", "analysis", ",", "principal", "component", "analysis", "and", "a", "set", "of", "structural", "indices", "relating", "to", "the", "complexity", "and", "extent", "of", "the", "valuations", "are", "the", "main", "methods", "used", ")", "."], "sentence-detokenized": "A single grid can be analysed both in terms of content (visual inspection) and structure (cluster analysis, principal component analysis and a set of structural indices relating to the complexity and extent of the valuations are the main methods used).", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 17], [18, 20], [21, 29], [30, 34], [35, 37], [38, 43], [44, 46], [47, 54], [55, 56], [56, 62], [63, 73], [73, 74], [75, 78], [79, 88], [89, 90], [90, 97], [98, 106], [106, 107], [108, 117], [118, 127], [128, 136], [137, 140], [141, 142], [143, 146], [147, 149], [150, 160], [161, 168], [169, 177], [178, 180], [181, 184], [185, 195], [196, 199], [200, 206], [207, 209], [210, 213], [214, 224], [225, 228], [229, 232], [233, 237], [238, 245], [246, 250], [250, 251], [251, 252]]}
{"doc_key": "ai-test-231", "ner": [[3, 3, "organisation"], [10, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", ",", "Toyota", "was", "seen", "as", "lagging", "behind", "in", "self", "-", "driving", "cars", "and", "in", "need", "of", "innovation", "."], "sentence-detokenized": "In 2018, Toyota was seen as lagging behind in self-driving cars and in need of innovation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 24], [25, 27], [28, 35], [36, 42], [43, 45], [46, 50], [50, 51], [51, 58], [59, 63], [64, 67], [68, 70], [71, 75], [76, 78], [79, 89], [89, 90]]}
{"doc_key": "ai-test-232", "ner": [[37, 38, "misc"], [40, 41, "misc"], [43, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "targets", "include", "natural", "objects", "such", "as", "land", ",", "sea", ",", "precipitation", "(", "e.g.", "rain", ",", "snow", "or", "hail", ")", ",", "sandstorms", ",", "animals", "(", "especially", "birds", ")", ",", "atmospheric", "turbulence", "and", "other", "atmospheric", "effects", "such", "as", "ionospheric", "reflections", ",", "meteor", "trails", "and", "triangular", "scattering", "spikes", "."], "sentence-detokenized": "Such targets include natural objects such as land, sea, precipitation (e.g. rain, snow or hail), sandstorms, animals (especially birds), atmospheric turbulence and other atmospheric effects such as ionospheric reflections, meteor trails and triangular scattering spikes.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 28], [29, 36], [37, 41], [42, 44], [45, 49], [49, 50], [51, 54], [54, 55], [56, 69], [70, 71], [71, 75], [76, 80], [80, 81], [82, 86], [87, 89], [90, 94], [94, 95], [95, 96], [97, 107], [107, 108], [109, 116], [117, 118], [118, 128], [129, 134], [134, 135], [135, 136], [137, 148], [149, 159], [160, 163], [164, 169], [170, 181], [182, 189], [190, 194], [195, 197], [198, 209], [210, 221], [221, 222], [223, 229], [230, 236], [237, 240], [241, 251], [252, 262], [263, 269], [269, 270]]}
{"doc_key": "ai-test-233", "ner": [[19, 20, "product"], [40, 42, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "terms", "of", "planning", "and", "control", ",", "the", "essential", "difference", "between", "humanoids", "and", "other", "types", "of", "robots", "(", "e.g.", "industrial", "robots", ")", "is", "that", "the", "robot", "'s", "movement", "must", "be", "human", "-", "like", ",", "using", "leg", "movement", ",", "in", "particular", "bipedal", "walking", "style", "."], "sentence-detokenized": "In terms of planning and control, the essential difference between humanoids and other types of robots (e.g. industrial robots) is that the robot's movement must be human-like, using leg movement, in particular bipedal walking style.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 20], [21, 24], [25, 32], [32, 33], [34, 37], [38, 47], [48, 58], [59, 66], [67, 76], [77, 80], [81, 86], [87, 92], [93, 95], [96, 102], [103, 104], [104, 108], [109, 119], [120, 126], [126, 127], [128, 130], [131, 135], [136, 139], [140, 145], [145, 147], [148, 156], [157, 161], [162, 164], [165, 170], [170, 171], [171, 175], [175, 176], [177, 182], [183, 186], [187, 195], [195, 196], [197, 199], [200, 210], [211, 218], [219, 226], [227, 232], [232, 233]]}
{"doc_key": "ai-test-234", "ner": [[0, 2, "algorithm"], [10, 11, "misc"], [15, 15, "metrics"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "gradient", "decomposition", "may", "take", "many", "iterations", "to", "compute", "a", "local", "minimum", "with", "the", "required", "accuracy", "if", "the", "curvature", "in", "different", "directions", "is", "very", "different", "for", "the", "given", "function", "."], "sentence-detokenized": "The gradient decomposition may take many iterations to compute a local minimum with the required accuracy if the curvature in different directions is very different for the given function.", "token2charspan": [[0, 3], [4, 12], [13, 26], [27, 30], [31, 35], [36, 40], [41, 51], [52, 54], [55, 62], [63, 64], [65, 70], [71, 78], [79, 83], [84, 87], [88, 96], [97, 105], [106, 108], [109, 112], [113, 122], [123, 125], [126, 135], [136, 146], [147, 149], [150, 154], [155, 164], [165, 168], [169, 172], [173, 178], [179, 187], [187, 188]]}
{"doc_key": "ai-test-235", "ner": [[0, 7, "misc"], [17, 22, "conference"], [25, 25, "location"], [27, 29, "country"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[17, 22, 25, 25, "physical", "", false, true], [25, 25, 27, 29, "physical", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["The", "1997", "RoboCup", "2D", "Soccer", "Simulation", "League", "was", "the", "first", "RoboCup", "competition", "organised", "in", "conjunction", "with", "the", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", "held", "in", "Nagoya", ",", "Japan", ",", "on", "23", "-", "29", "August", "1997", "."], "sentence-detokenized": "The 1997 RoboCup 2D Soccer Simulation League was the first RoboCup competition organised in conjunction with the International Joint Conference on Artificial Intelligence held in Nagoya, Japan, on 23-29 August 1997.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 19], [20, 26], [27, 37], [38, 44], [45, 48], [49, 52], [53, 58], [59, 66], [67, 78], [79, 88], [89, 91], [92, 103], [104, 108], [109, 112], [113, 126], [127, 132], [133, 143], [144, 146], [147, 157], [158, 170], [171, 175], [176, 178], [179, 185], [185, 186], [187, 192], [192, 193], [194, 196], [197, 199], [199, 200], [200, 202], [203, 209], [210, 214], [214, 215]]}
{"doc_key": "ai-test-236", "ner": [[18, 18, "product"]], "ner_mapping_to_source": [2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "options", "include", "an", "embedded", "Python", "environment", "and", "an", "R", "console", ",", "as", "well", "as", "support", "for", "Rserve", "."], "sentence-detokenized": "Other programming options include an embedded Python environment and an R console, as well as support for Rserve.", "token2charspan": [[0, 5], [6, 17], [18, 25], [26, 33], [34, 36], [37, 45], [46, 52], [53, 64], [65, 68], [69, 71], [72, 73], [74, 81], [81, 82], [83, 85], [86, 90], [91, 93], [94, 101], [102, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [9, 10, "field"], [12, 12, "field"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [32, 33, "field"], [37, 38, "field"], [41, 42, "field"], [46, 47, "field"], [50, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[15, 16, 12, 12, "related-to", "contributes_to_field", true, false], [18, 19, 12, 12, "related-to", "contributes_to_field", true, false], [21, 22, 12, 12, "related-to", "contributes_to_field", true, false], [41, 42, 37, 38, "part-of", "", false, false], [46, 47, 41, 42, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["From", "Bonn", ",", "he", "has", "made", "fundamental", "contributions", "to", "artificial", "intelligence", "and", "robotics", "(", "with", "Wolfram", "Burgard", ",", "Dieter", "Fox", "and", "Sebastian", "Thrun", "among", "his", "students", ")", "and", "to", "the", "development", "of", "software", "engineering", ",", "especially", "in", "civil", "engineering", ",", "and", "information", "systems", ",", "especially", "in", "geoscience", ".", "won", "the", "AAAI", "Classic", "Paper", "Award", "2016.2014", "."], "sentence-detokenized": "From Bonn, he has made fundamental contributions to artificial intelligence and robotics (with Wolfram Burgard, Dieter Fox and Sebastian Thrun among his students) and to the development of software engineering, especially in civil engineering, and information systems, especially in geoscience. won the AAAI Classic Paper Award 2016.2014.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 13], [14, 17], [18, 22], [23, 34], [35, 48], [49, 51], [52, 62], [63, 75], [76, 79], [80, 88], [89, 90], [90, 94], [95, 102], [103, 110], [110, 111], [112, 118], [119, 122], [123, 126], [127, 136], [137, 142], [143, 148], [149, 152], [153, 161], [161, 162], [163, 166], [167, 169], [170, 173], [174, 185], [186, 188], [189, 197], [198, 209], [209, 210], [211, 221], [222, 224], [225, 230], [231, 242], [242, 243], [244, 247], [248, 259], [260, 267], [267, 268], [269, 279], [280, 282], [283, 293], [293, 294], [295, 298], [299, 302], [303, 307], [308, 315], [316, 321], [322, 327], [328, 337], [337, 338]]}
{"doc_key": "ai-test-238", "ner": [[2, 11, "conference"], [18, 19, "location"], [21, 21, "location"], [23, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 11, 18, 19, "physical", "", false, false], [18, 19, 21, 21, "physical", "", false, false], [21, 21, 23, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "US", "edition", "of", "the", "Campus", "Party", "will", "take", "place", "on", "20", "-", "22", "August", "at", "the", "TCF", "Center", "in", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "The first US edition of the Campus Party will take place on 20-22 August at the TCF Center in Detroit, Michigan.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 20], [21, 23], [24, 27], [28, 34], [35, 40], [41, 45], [46, 50], [51, 56], [57, 59], [60, 62], [62, 63], [63, 65], [66, 72], [73, 75], [76, 79], [80, 83], [84, 90], [91, 93], [94, 101], [101, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-test-239", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [10, 13, "misc"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 10, 13, "win-defeat", "", false, false], [5, 6, 10, 13, "win-defeat", "", false, false], [8, 8, 10, 13, "win-defeat", "", false, false], [10, 13, 22, 24, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Together", "with", "Yann", "LeCun", "and", "Yoshua", "Bengio", ",", "Hinton", "won", "the", "2018", "Turing", "Prize", "for", "conceptual", "and", "technical", "breakthroughs", "that", "have", "made", "deep", "neural", "networks", "a", "critical", "component", "of", "computing", "."], "sentence-detokenized": "Together with Yann LeCun and Yoshua Bengio, Hinton won the 2018 Turing Prize for conceptual and technical breakthroughs that have made deep neural networks a critical component of computing.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 24], [25, 28], [29, 35], [36, 42], [42, 43], [44, 50], [51, 54], [55, 58], [59, 63], [64, 70], [71, 76], [77, 80], [81, 91], [92, 95], [96, 105], [106, 119], [120, 124], [125, 129], [130, 134], [135, 139], [140, 146], [147, 155], [156, 157], [158, 166], [167, 176], [177, 179], [180, 189], [189, 190]]}
{"doc_key": "ai-test-240", "ner": [[0, 2, "product"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Euler", "Math", "Toolbox", "uses", "a", "matrix", "language", "similar", "to", "MATLAB", ",", "a", "system", "that", "has", "been", "developed", "since", "the", "1970s", "."], "sentence-detokenized": "Euler Math Toolbox uses a matrix language similar to MATLAB, a system that has been developed since the 1970s.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 23], [24, 25], [26, 32], [33, 41], [42, 49], [50, 52], [53, 59], [59, 60], [61, 62], [63, 69], [70, 74], [75, 78], [79, 83], [84, 93], [94, 99], [100, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-test-241", "ner": [[9, 9, "programlang"], [11, 12, "programlang"], [14, 14, "programlang"], [16, 16, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "languages", "allow", "it", "to", "be", "transferred", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "or", "D", ")", "."], "sentence-detokenized": "Some languages allow it to be transferred (e.g. Scheme, Common Lisp, Perl or D).", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 23], [24, 26], [27, 29], [30, 41], [42, 43], [43, 47], [48, 54], [54, 55], [56, 62], [63, 67], [67, 68], [69, 73], [74, 76], [77, 78], [78, 79], [79, 80]]}
{"doc_key": "ai-test-242", "ner": [[14, 15, "misc"], [3, 4, "researcher"], [6, 9, "researcher"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 15, 3, 4, "artifact", "", false, false], [14, 15, 6, 9, "artifact", "", false, false], [14, 15, 27, 28, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1969", ",", "Marvin", "Minsky", "and", "Seymour", "Papert", "showed", "in", "a", "famous", "book", "entitled", "Perceptrons", "that", "it", "was", "impossible", "for", "these", "types", "of", "networks", "to", "learn", "an", "XOR", "function", "."], "sentence-detokenized": "In 1969, Marvin Minsky and Seymour Papert showed in a famous book entitled Perceptrons that it was impossible for these types of networks to learn an XOR function.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 22], [23, 26], [27, 34], [35, 41], [42, 48], [49, 51], [52, 53], [54, 60], [61, 65], [66, 74], [75, 86], [87, 91], [92, 94], [95, 98], [99, 109], [110, 113], [114, 119], [120, 125], [126, 128], [129, 137], [138, 140], [141, 146], [147, 149], [150, 153], [154, 162], [162, 163]]}
{"doc_key": "ai-test-243", "ner": [[4, 8, "misc"], [12, 14, "product"], [18, 21, "organisation"], [25, 32, "organisation"], [33, 38, "location"], [40, 40, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 21, 12, 14, "usage", "", false, false], [18, 21, 33, 38, "physical", "", false, false], [25, 32, 18, 21, "named", "", false, false], [33, 38, 40, 40, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "large", "number", "of", "Russian", "scientific", "and", "technical", "documents", "were", "translated", "using", "SYSTRAN", "under", "the", "supervision", "of", "the", "USAF", "Foreign", "Technology", "Division", "(", "later", "the", "National", "Air", "and", "Space", "Intelligence", "Center", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", ",", "Ohio", "."], "sentence-detokenized": "A large number of Russian scientific and technical documents were translated using SYSTRAN under the supervision of the USAF Foreign Technology Division (later the National Air and Space Intelligence Center) at Wright-Patterson Air Force Base, Ohio.", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 17], [18, 25], [26, 36], [37, 40], [41, 50], [51, 60], [61, 65], [66, 76], [77, 82], [83, 90], [91, 96], [97, 100], [101, 112], [113, 115], [116, 119], [120, 124], [125, 132], [133, 143], [144, 152], [153, 154], [154, 159], [160, 163], [164, 172], [173, 176], [177, 180], [181, 186], [187, 199], [200, 206], [206, 207], [208, 210], [211, 217], [217, 218], [218, 227], [228, 231], [232, 237], [238, 242], [242, 243], [244, 248], [248, 249]]}
{"doc_key": "ai-test-244", "ner": [[0, 1, "field"], [4, 5, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-supervised", "learning", "lies", "between", "unsupervised", "learning", "(", "with", "no", "labelled", "training", "data", ")", "and", "supervised", "learning", "(", "with", "fully", "labelled", "training", "data", ")", "."], "sentence-detokenized": "Semi-supervised learning lies between unsupervised learning (with no labelled training data) and supervised learning (with fully labelled training data).", "token2charspan": [[0, 15], [16, 24], [25, 29], [30, 37], [38, 50], [51, 59], [60, 61], [61, 65], [66, 68], [69, 77], [78, 86], [87, 91], [91, 92], [93, 96], [97, 107], [108, 116], [117, 118], [118, 122], [123, 128], [129, 137], [138, 146], [147, 151], [151, 152], [152, 153]]}
{"doc_key": "ai-test-245", "ner": [[0, 4, "algorithm"], [9, 11, "algorithm"], [32, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 9, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Ann", "-", "gram", "model", "is", "a", "type", "of", "probabilistic", "language", "model", "for", "predicting", "the", "next", "point", "in", "such", "a", "sequence", "in", "the", "form", "of", "an", "(", "n", "-", "1", ")", "-order", "Markov", "model", ".", "in", "an", "efficient", "way", "."], "sentence-detokenized": "The Ann -gram model is a type of probabilistic language model for predicting the next point in such a sequence in the form of an (n - 1)-order Markov model .in an efficient way.", "token2charspan": [[0, 3], [4, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 24], [25, 29], [30, 32], [33, 46], [47, 55], [56, 61], [62, 65], [66, 76], [77, 80], [81, 85], [86, 91], [92, 94], [95, 99], [100, 101], [102, 110], [111, 113], [114, 117], [118, 122], [123, 125], [126, 128], [129, 130], [130, 131], [132, 133], [134, 135], [135, 136], [136, 142], [143, 149], [150, 155], [156, 157], [157, 159], [160, 162], [163, 172], [173, 176], [176, 177]]}
{"doc_key": "ai-test-246", "ner": [[0, 2, "organisation"], [5, 5, "product"], [9, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 5, 5, "usage", "", false, false], [9, 15, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "has", "used", "Cyc", "to", "develop", "a", "natural", "language", "search", "interface", "for", "biomedical", "information", ",", "covering", "decades", "of", "information", "on", "heart", "and", "lung", "surgery", "."], "sentence-detokenized": "The Cleveland Clinic has used Cyc to develop a natural language search interface for biomedical information, covering decades of information on heart and lung surgery.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 24], [25, 29], [30, 33], [34, 36], [37, 44], [45, 46], [47, 54], [55, 63], [64, 70], [71, 80], [81, 84], [85, 95], [96, 107], [107, 108], [109, 117], [118, 125], [126, 128], [129, 140], [141, 143], [144, 149], [150, 153], [154, 158], [159, 166], [166, 167]]}
{"doc_key": "ai-test-247", "ner": [[6, 6, "country"], [8, 8, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 6, 8, 8, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "incident", "strained", "relations", "between", "the", "US", "and", "Japan", ",", "resulting", "in", "the", "arrest", "and", "prosecution", "of", "two", "senior", "executives", "and", "the", "imposition", "of", "sanctions", "on", "the", "company", "by", "both", "countries", "."], "sentence-detokenized": "The incident strained relations between the US and Japan, resulting in the arrest and prosecution of two senior executives and the imposition of sanctions on the company by both countries.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 31], [32, 39], [40, 43], [44, 46], [47, 50], [51, 56], [56, 57], [58, 67], [68, 70], [71, 74], [75, 81], [82, 85], [86, 97], [98, 100], [101, 104], [105, 111], [112, 122], [123, 126], [127, 130], [131, 141], [142, 144], [145, 154], [155, 157], [158, 161], [162, 169], [170, 172], [173, 177], [178, 187], [187, 188]]}
{"doc_key": "ai-test-248", "ner": [[7, 9, "algorithm"], [12, 13, "field"], [22, 22, "misc"], [34, 34, "misc"], [37, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 12, 13, "type-of", "", false, false], [22, 22, 12, 13, "part-of", "", true, false], [34, 34, 12, 13, "part-of", "", true, false], [37, 37, 12, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["If", "the", "modelling", "is", "done", "using", "an", "artificial", "neural", "network", "or", "other", "machine", "learning", ",", "the", "optimisation", "of", "the", "parameters", "is", "called", "training", ",", "while", "the", "optimisation", "of", "the", "model", "'s", "hyperparameters", "is", "called", "tuning", "and", "often", "cross-validation", "is", "used", "."], "sentence-detokenized": "If the modelling is done using an artificial neural network or other machine learning, the optimisation of the parameters is called training, while the optimisation of the model's hyperparameters is called tuning and often cross-validation is used.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 24], [25, 30], [31, 33], [34, 44], [45, 51], [52, 59], [60, 62], [63, 68], [69, 76], [77, 85], [85, 86], [87, 90], [91, 103], [104, 106], [107, 110], [111, 121], [122, 124], [125, 131], [132, 140], [140, 141], [142, 147], [148, 151], [152, 164], [165, 167], [168, 171], [172, 177], [177, 179], [180, 195], [196, 198], [199, 205], [206, 212], [213, 216], [217, 222], [223, 239], [240, 242], [243, 247], [247, 248]]}
{"doc_key": "ai-test-249", "ner": [[7, 7, "country"], [9, 9, "country"], [11, 11, "country"], [18, 19, "organisation"], [16, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[18, 19, 16, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Localised", "versions", "of", "the", "site", "in", "the", "UK", ",", "India", "and", "Australia", "were", "shut", "down", "after", "Fandango", "acquired", "Rotten", "Tomatoes", "."], "sentence-detokenized": "Localised versions of the site in the UK, India and Australia were shut down after Fandango acquired Rotten Tomatoes.", "token2charspan": [[0, 9], [10, 18], [19, 21], [22, 25], [26, 30], [31, 33], [34, 37], [38, 40], [40, 41], [42, 47], [48, 51], [52, 61], [62, 66], [67, 71], [72, 76], [77, 82], [83, 91], [92, 100], [101, 107], [108, 116], [116, 117]]}
{"doc_key": "ai-test-250", "ner": [[11, 12, "metrics"], [22, 23, "task"]], "ner_mapping_to_source": [1, 2], "relations": [[11, 12, 22, 23, "related-to", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["The", "NER", "model", "is", "one", "of", "several", "methods", "for", "determining", "the", "accuracy", "of", "live", "captions", "in", "television", "broadcasts", "and", "events", "produced", "using", "speech", "recognition", "."], "sentence-detokenized": "The NER model is one of several methods for determining the accuracy of live captions in television broadcasts and events produced using speech recognition.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 31], [32, 39], [40, 43], [44, 55], [56, 59], [60, 68], [69, 71], [72, 76], [77, 85], [86, 88], [89, 99], [100, 110], [111, 114], [115, 121], [122, 130], [131, 136], [137, 143], [144, 155], [155, 156]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [4, 5, "university"], [8, 9, "university"], [11, 11, "location"], [13, 17, "university"], [19, 20, "university"], [22, 22, "location"], [25, 30, "university"], [32, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 5, "physical", "", false, false], [0, 0, 4, 5, "role", "", false, false], [0, 0, 8, 9, "physical", "", false, false], [0, 0, 8, 9, "role", "", false, false], [0, 0, 13, 17, "physical", "", false, false], [0, 0, 13, 17, "role", "", false, false], [0, 0, 19, 20, "physical", "", false, false], [0, 0, 19, 20, "role", "", false, false], [0, 0, 25, 30, "physical", "", false, false], [0, 0, 25, 30, "role", "", false, false], [8, 9, 11, 11, "physical", "", false, false], [13, 17, 22, 22, "physical", "", false, false], [19, 20, 22, 22, "physical", "", false, false], [25, 30, 32, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "has", "taught", "at", "Cambridge", "University", ",", "the", "Hebrew", "University", "of", "Jerusalem", ",", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "and", "\u00c9cole", "Polytechnique", "in", "Paris", ",", "and", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "City", "."], "sentence-detokenized": "Atran has taught at Cambridge University, the Hebrew University of Jerusalem, \u00c9cole pratique des hautes \u00e9tudes and \u00c9cole Polytechnique in Paris, and John Jay College of Criminal Justice in New York City.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 40], [40, 41], [42, 45], [46, 52], [53, 63], [64, 66], [67, 76], [76, 77], [78, 83], [84, 92], [93, 96], [97, 103], [104, 110], [111, 114], [115, 120], [121, 134], [135, 137], [138, 143], [143, 144], [145, 148], [149, 153], [154, 157], [158, 165], [166, 168], [169, 177], [178, 185], [186, 188], [189, 192], [193, 197], [198, 202], [202, 203]]}
{"doc_key": "ai-test-252", "ner": [[0, 2, "product"], [6, 9, "task"], [12, 13, "researcher"], [15, 15, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 6, 9, "origin", "", false, false], [0, 2, 6, 9, "related-to", "", false, false], [6, 9, 15, 15, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "was", "an", "early", "computer", "program", "for", "natural", "language", "understanding", "developed", "by", "Terry", "Winograd", "at", "MIT", "in", "1968", "-", "1970", "."], "sentence-detokenized": "SHRDLU was an early computer program for natural language understanding developed by Terry Winograd at MIT in 1968-1970.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 19], [20, 28], [29, 36], [37, 40], [41, 48], [49, 57], [58, 71], [72, 81], [82, 84], [85, 90], [91, 99], [100, 102], [103, 106], [107, 109], [110, 114], [114, 115], [115, 119], [119, 120]]}
{"doc_key": "ai-test-253", "ner": [[3, 5, "misc"], [7, 8, "field"], [11, 15, "university"], [17, 17, "location"], [19, 19, "country"], [28, 29, "university"], [32, 34, "misc"], [36, 39, "field"], [43, 44, "university"], [47, 49, "misc"], [51, 52, "field"], [58, 58, "misc"], [63, 67, "university"], [72, 73, "field"], [77, 78, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[3, 5, 7, 8, "topic", "", false, false], [3, 5, 11, 15, "origin", "", false, false], [11, 15, 17, 17, "physical", "", false, false], [11, 15, 28, 29, "role", "affiliated_with", false, false], [17, 17, 19, 19, "physical", "", false, false], [32, 34, 36, 39, "topic", "", false, false], [32, 34, 43, 44, "origin", "", false, false], [47, 49, 51, 52, "topic", "", false, false], [58, 58, 63, 67, "origin", "", false, false], [58, 58, 72, 73, "topic", "", false, false], [77, 78, 63, 67, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["He", "received", "a", "bachelor", "'s", "degree", "in", "electronic", "engineering", "from", "the", "B.M.S", ".", "College", "of", "Engineering", "in", "Bangalore", ",", "India", "in", "1982", ",", "when", "it", "was", "affiliated", "with", "Bangalore", "University", ",", "a", "master", "'s", "degree", "in", "electrical", "and", "computer", "engineering", "in", "1984", "from", "Drexel", "University", ",", "a", "master", "'s", "degree", "in", "computer", "science", "in", "1989", ",", "and", "a", "doctorate", "in", "1990", "from", "the", "University", "of", "Wisconsin", "-", "Madison", ",", "where", "he", "studied", "artificial", "intelligence", "and", "worked", "with", "Leonard", "Uhr", "."], "sentence-detokenized": "He received a bachelor's degree in electronic engineering from the B.M.S. College of Engineering in Bangalore, India in 1982, when it was affiliated with Bangalore University, a master's degree in electrical and computer engineering in 1984 from Drexel University, a master's degree in computer science in 1989, and a doctorate in 1990 from the University of Wisconsin-Madison, where he studied artificial intelligence and worked with Leonard Uhr.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 22], [22, 24], [25, 31], [32, 34], [35, 45], [46, 57], [58, 62], [63, 66], [67, 72], [72, 73], [74, 81], [82, 84], [85, 96], [97, 99], [100, 109], [109, 110], [111, 116], [117, 119], [120, 124], [124, 125], [126, 130], [131, 133], [134, 137], [138, 148], [149, 153], [154, 163], [164, 174], [174, 175], [176, 177], [178, 184], [184, 186], [187, 193], [194, 196], [197, 207], [208, 211], [212, 220], [221, 232], [233, 235], [236, 240], [241, 245], [246, 252], [253, 263], [263, 264], [265, 266], [267, 273], [273, 275], [276, 282], [283, 285], [286, 294], [295, 302], [303, 305], [306, 310], [310, 311], [312, 315], [316, 317], [318, 327], [328, 330], [331, 335], [336, 340], [341, 344], [345, 355], [356, 358], [359, 368], [368, 369], [369, 376], [376, 377], [378, 383], [384, 386], [387, 394], [395, 405], [406, 418], [419, 422], [423, 429], [430, 434], [435, 442], [443, 446], [446, 447]]}
{"doc_key": "ai-test-254", "ner": [[6, 8, "metrics"], [10, 10, "metrics"], [19, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "usually", "assessed", "by", "the", "word", "error", "rate", "(", "WER", ")", ",", "while", "speed", "is", "measured", "by", "the", "real", "-", "time", "factor", "."], "sentence-detokenized": "Accuracy is usually assessed by the word error rate (WER), while speed is measured by the real-time factor.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 28], [29, 31], [32, 35], [36, 40], [41, 46], [47, 51], [52, 53], [53, 56], [56, 57], [57, 58], [59, 64], [65, 70], [71, 73], [74, 82], [83, 85], [86, 89], [90, 94], [94, 95], [95, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [8, 12, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", ",", "Terry", "Winograd", "developed", "an", "early", "natural", "language", "processing", "engine", "that", "could", "interpret", "naturally", "written", "commands", "in", "a", "simple", "rule", "-", "driven", "environment", "."], "sentence-detokenized": "In 1971, Terry Winograd developed an early natural language processing engine that could interpret naturally written commands in a simple rule-driven environment.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 33], [34, 36], [37, 42], [43, 50], [51, 59], [60, 70], [71, 77], [78, 82], [83, 88], [89, 98], [99, 108], [109, 116], [117, 125], [126, 128], [129, 130], [131, 137], [138, 142], [142, 143], [143, 149], [150, 161], [161, 162]]}
{"doc_key": "ai-test-256", "ner": [[1, 2, "field"], [4, 5, "researcher"], [7, 10, "researcher"], [12, 13, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 4, 5, "related-to", "", false, false], [1, 2, 7, 10, "related-to", "", false, false], [1, 2, 12, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "artificial", "intelligence", ",", "Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "and", "Allen", "Newell", "are", "prominent", "."], "sentence-detokenized": "In artificial intelligence, Marvin Minsky, Herbert A. Simon and Allen Newell are prominent.", "token2charspan": [[0, 2], [3, 13], [14, 26], [26, 27], [28, 34], [35, 41], [41, 42], [43, 50], [51, 52], [52, 53], [54, 59], [60, 63], [64, 69], [70, 76], [77, 80], [81, 90], [90, 91]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [31, 32, "field"], [34, 35, "field"], [38, 39, "field"], [49, 52, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[31, 32, 9, 10, "origin", "", true, false], [31, 32, 9, 10, "part-of", "", false, false], [31, 32, 38, 39, "compare", "", false, false], [34, 35, 9, 10, "origin", "", true, false], [34, 35, 9, 10, "part-of", "", false, false], [34, 35, 38, 39, "compare", "", false, false], [38, 39, 9, 10, "origin", "", true, false], [38, 39, 9, 10, "part-of", "", false, false], [38, 39, 49, 52, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "the", "latter", "half", "of", "the", "20th", "century", ",", "electrical", "engineering", "was", "divided", "into", "several", "disciplines", "specialising", "in", "the", "design", "and", "analysis", "of", "systems", "that", "manipulate", "physical", "signals", ",", "such", "as", "electronics", "engineering", "and", "computer", "engineering", ",", "while", "design", "engineering", "was", "developed", "to", "deal", "with", "the", "functional", "design", "of", "interfaces", "for", "user", "machines", "."], "sentence-detokenized": "In the latter half of the 20th century, electrical engineering was divided into several disciplines specialising in the design and analysis of systems that manipulate physical signals, such as electronics engineering and computer engineering, while design engineering was developed to deal with the functional design of interfaces for user machines.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 30], [31, 38], [38, 39], [40, 50], [51, 62], [63, 66], [67, 74], [75, 79], [80, 87], [88, 99], [100, 112], [113, 115], [116, 119], [120, 126], [127, 130], [131, 139], [140, 142], [143, 150], [151, 155], [156, 166], [167, 175], [176, 183], [183, 184], [185, 189], [190, 192], [193, 204], [205, 216], [217, 220], [221, 229], [230, 241], [241, 242], [243, 248], [249, 255], [256, 267], [268, 271], [272, 281], [282, 284], [285, 289], [290, 294], [295, 298], [299, 309], [310, 316], [317, 319], [320, 330], [331, 334], [335, 339], [340, 348], [348, 349]]}
{"doc_key": "ai-test-258", "ner": [[5, 5, "metrics"], [7, 8, "metrics"], [10, 13, "metrics"], [46, 48, "metrics"], [55, 57, "metrics"], [61, 67, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 13, 7, 8, "named", "", false, false], [46, 48, 55, 57, "named", "", false, false], [55, 57, 61, 67, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Perhaps", "the", "simplest", "statistic", "is", "accuracy", "or", "Fraction", "Correct", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "all", "cases", "that", "are", "correctly", "categorised", ";", "it", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "Total", "Population", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Perhaps the simplest statistic is accuracy or Fraction Correct (FC), which measures the proportion of all cases that are correctly categorised; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN) / Total Population = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 30], [31, 33], [34, 42], [43, 45], [46, 54], [55, 62], [63, 64], [64, 66], [66, 67], [67, 68], [69, 74], [75, 83], [84, 87], [88, 98], [99, 101], [102, 105], [106, 111], [112, 116], [117, 120], [121, 130], [131, 142], [142, 143], [144, 146], [147, 149], [150, 153], [154, 159], [160, 162], [163, 166], [167, 173], [174, 176], [177, 184], [185, 200], [201, 203], [204, 207], [208, 213], [214, 220], [221, 223], [224, 231], [232, 234], [235, 244], [245, 260], [260, 261], [262, 263], [263, 265], [266, 267], [268, 270], [270, 271], [272, 273], [274, 279], [280, 290], [291, 292], [293, 294], [294, 296], [297, 298], [299, 301], [301, 302], [303, 304], [305, 306], [306, 308], [309, 310], [311, 313], [314, 315], [316, 318], [319, 320], [321, 323], [323, 324], [324, 325]]}
{"doc_key": "ai-test-259", "ner": [[12, 20, "conference"], [22, 24, "conference"], [29, 29, "location"], [34, 35, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 20, 29, 29, "physical", "", false, false], [22, 24, 12, 20, "named", "", false, false], [34, 35, 12, 20, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "academia", ",", "the", "major", "research", "forums", "began", "in", "1995", "when", "the", "first", "International", "Conference", "on", "Data", "Mining", "and", "Knowledge", "Discovery", "(", "KDD", "-", "95", ")", "was", "launched", "in", "Montreal", "under", "the", "sponsorship", "of", "the", "AAAI", "."], "sentence-detokenized": "In academia, the major research forums began in 1995 when the first International Conference on Data Mining and Knowledge Discovery (KDD-95) was launched in Montreal under the sponsorship of the AAAI.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 16], [17, 22], [23, 31], [32, 38], [39, 44], [45, 47], [48, 52], [53, 57], [58, 61], [62, 67], [68, 81], [82, 92], [93, 95], [96, 100], [101, 107], [108, 111], [112, 121], [122, 131], [132, 133], [133, 136], [136, 137], [137, 139], [139, 140], [141, 144], [145, 153], [154, 156], [157, 165], [166, 171], [172, 175], [176, 187], [188, 190], [191, 194], [195, 199], [199, 200]]}
{"doc_key": "ai-test-260", "ner": [[9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "approach", ",", "models", "are", "developed", "using", "various", "data", "mining", "and", "machine", "learning", "algorithms", "to", "predict", "users", "'", "ratings", "of", "unjudged", "items", "."], "sentence-detokenized": "In this approach, models are developed using various data mining and machine learning algorithms to predict users' ratings of unjudged items.", "token2charspan": [[0, 2], [3, 7], [8, 16], [16, 17], [18, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 57], [58, 64], [65, 68], [69, 76], [77, 85], [86, 96], [97, 99], [100, 107], [108, 113], [113, 114], [115, 122], [123, 125], [126, 134], [135, 140], [140, 141]]}
{"doc_key": "ai-test-261", "ner": [[16, 17, "algorithm"], [19, 20, "algorithm"], [24, 25, "misc"], [31, 32, "metrics"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[16, 17, 19, 20, "usage", "", false, false], [19, 20, 31, 32, "usage", "", false, false], [31, 32, 24, 25, "type-of", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["In", "light", "of", "the", "above", "discussion", ",", "we", "see", "that", "the", "SVM", "technique", "is", "equivalent", "to", "empirical", "risk", "with", "Tikhonov", "regularization", ",", "where", "the", "loss", "function", "in", "this", "case", "is", "a", "hanging", "loss", "."], "sentence-detokenized": "In light of the above discussion, we see that the SVM technique is equivalent to empirical risk with Tikhonov regularization, where the loss function in this case is a hanging loss.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 15], [16, 21], [22, 32], [32, 33], [34, 36], [37, 40], [41, 45], [46, 49], [50, 53], [54, 63], [64, 66], [67, 77], [78, 80], [81, 90], [91, 95], [96, 100], [101, 109], [110, 124], [124, 125], [126, 131], [132, 135], [136, 140], [141, 149], [150, 152], [153, 157], [158, 162], [163, 165], [166, 167], [168, 175], [176, 180], [180, 181]]}
{"doc_key": "ai-test-262", "ner": [[6, 7, "person"], [10, 11, "person"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "2015", "edition", "was", "hosted", "by", "Molly", "McGrath", ",", "with", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "as", "commentators", "."], "sentence-detokenized": "The 2015 edition was hosted by Molly McGrath, with Chris Rose and former UFC fighter Kenny Florian as commentators.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 27], [28, 30], [31, 36], [37, 44], [44, 45], [46, 50], [51, 56], [57, 61], [62, 65], [66, 72], [73, 76], [77, 84], [85, 90], [91, 98], [99, 101], [102, 114], [114, 115]]}
{"doc_key": "ai-test-263", "ner": [[3, 5, "product"], [9, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [18, 18, "researcher"], [20, 20, "researcher"], [28, 30, "task"], [32, 32, "product"], [34, 36, "researcher"], [39, 40, "task"], [42, 44, "researcher"], [47, 48, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12], "relations": [[3, 5, 9, 11, "origin", "", false, false], [3, 5, 13, 14, "origin", "", false, false], [3, 5, 16, 17, "origin", "", false, false], [3, 5, 18, 18, "origin", "", false, false], [13, 14, 34, 36, "named", "same", false, false], [16, 17, 20, 20, "named", "same", false, false], [28, 30, 32, 32, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 7], "sentence": ["A", "subset", "called", "Micro", "-", "Planner", "was", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "Sussman", "and", "Winograd", "in", "1971", "and", "used", "in", "Winograd", "'s", "natural", "language", "understanding", "program", "SHRDLU", ",", "Eugene", "Charniak", "'s", "work", "on", "understanding", "stories", ",", "Thorne", "McCarty", "'s", "work", "on", "legal", "reasoning", "and", "a", "few", "other", "projects", "."], "sentence-detokenized": "A subset called Micro-Planner was implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd Sussman and Winograd in 1971 and used in Winograd's natural language understanding program SHRDLU, Eugene Charniak's work on understanding stories, Thorne McCarty's work on legal reasoning and a few other projects.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [21, 22], [22, 29], [30, 33], [34, 45], [46, 48], [49, 55], [56, 59], [60, 67], [67, 68], [69, 75], [76, 84], [85, 88], [89, 94], [95, 103], [104, 111], [112, 115], [116, 124], [125, 127], [128, 132], [133, 136], [137, 141], [142, 144], [145, 153], [153, 155], [156, 163], [164, 172], [173, 186], [187, 194], [195, 201], [201, 202], [203, 209], [210, 218], [218, 220], [221, 225], [226, 228], [229, 242], [243, 250], [250, 251], [252, 258], [259, 266], [266, 268], [269, 273], [274, 276], [277, 282], [283, 292], [293, 296], [297, 298], [299, 302], [303, 308], [309, 317], [317, 318]]}
{"doc_key": "ai-test-264", "ner": [[0, 1, "product"], [11, 12, "product"], [15, 17, "task"], [19, 20, "task"], [22, 24, "task"], [26, 27, "task"], [29, 30, "task"], [34, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 0, 1, "usage", "", true, false], [15, 17, 11, 12, "part-of", "", true, false], [19, 20, 11, 12, "part-of", "", true, false], [22, 24, 11, 12, "part-of", "", true, false], [26, 27, 11, 12, "part-of", "", true, false], [29, 30, 11, 12, "part-of", "", true, false], [34, 36, 11, 12, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "has", "been", "used", "for", "a", "number", "of", "purposes", "in", "information", "systems", ",", "including", "word", "sense", "discrimination", ",", "information", "retrieval", ",", "automatic", "text", "classification", ",", "automatic", "summarization", ",", "machine", "translation", ",", "and", "even", "automatic", "crossword", "generation", "."], "sentence-detokenized": "WordNet has been used for a number of purposes in information systems, including word sense discrimination, information retrieval, automatic text classification, automatic summarization, machine translation, and even automatic crossword generation.", "token2charspan": [[0, 4], [4, 7], [8, 11], [12, 16], [17, 21], [22, 25], [26, 27], [28, 34], [35, 37], [38, 46], [47, 49], [50, 61], [62, 69], [69, 70], [71, 80], [81, 85], [86, 91], [92, 106], [106, 107], [108, 119], [120, 129], [129, 130], [131, 140], [141, 145], [146, 160], [160, 161], [162, 171], [172, 185], [185, 186], [187, 194], [195, 206], [206, 207], [208, 211], [212, 216], [217, 226], [227, 236], [237, 247], [247, 248]]}
{"doc_key": "ai-test-265", "ner": [[0, 0, "researcher"], [7, 7, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 7, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "was", "named", "a", "Fellow", "of", "the", "IEEE", "in", "1996", "."], "sentence-detokenized": "Keutzer was named a Fellow of the IEEE in 1996.", "token2charspan": [[0, 7], [8, 11], [12, 17], [18, 19], [20, 26], [27, 29], [30, 33], [34, 38], [39, 41], [42, 46], [46, 47]]}
{"doc_key": "ai-test-266", "ner": [[8, 10, "algorithm"], [55, 56, "misc"], [64, 65, "algorithm"], [67, 68, "algorithm"], [70, 71, "algorithm"], [73, 74, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[64, 65, 55, 56, "type-of", "", false, false], [67, 68, 55, 56, "type-of", "", false, false], [70, 71, 55, 56, "type-of", "", false, false], [73, 74, 55, 56, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "commonly", "used", "type", "of", "composition", "is", "the", "non-linear", "weighted", "sum", ",", "where", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "left", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "right", ")", "/", "math", ",", "where", "math", "\\", "textstyle", "K", "/", "math", "(", "commonly", "called", "the", "activation", "function", ")", "is", "a", "predefined", "function", ",", "e.g.", "hyperbolic", "tangent", ",", "sigmoid", "function", ",", "softmax", "function", "or", "rectifier", "function", "."], "sentence-detokenized": "A commonly used type of composition is the non-linear weighted sum, where math\\ textstyle f (x) = K\\ left (\\ sum _ i w _ i g _ i (x)\\ right) / math, where math\\ textstyle K / math (commonly called the activation function) is a predefined function, e.g. hyperbolic tangent, sigmoid function, softmax function or rectifier function.", "token2charspan": [[0, 1], [2, 10], [11, 15], [16, 20], [21, 23], [24, 35], [36, 38], [39, 42], [43, 53], [54, 62], [63, 66], [66, 67], [68, 73], [74, 78], [78, 79], [80, 89], [90, 91], [92, 93], [93, 94], [94, 95], [96, 97], [98, 99], [99, 100], [101, 105], [106, 107], [107, 108], [109, 112], [113, 114], [115, 116], [117, 118], [119, 120], [121, 122], [123, 124], [125, 126], [127, 128], [129, 130], [130, 131], [131, 132], [132, 133], [134, 139], [139, 140], [141, 142], [143, 147], [147, 148], [149, 154], [155, 159], [159, 160], [161, 170], [171, 172], [173, 174], [175, 179], [180, 181], [181, 189], [190, 196], [197, 200], [201, 211], [212, 220], [220, 221], [222, 224], [225, 226], [227, 237], [238, 246], [246, 247], [248, 252], [253, 263], [264, 271], [271, 272], [273, 280], [281, 289], [289, 290], [291, 298], [299, 307], [308, 310], [311, 320], [321, 329], [329, 330]]}
{"doc_key": "ai-test-267", "ner": [[3, 8, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "movie", "Westworld", ",", "female", "robots", "actually", "had", "sex", "with", "human", "men", "as", "part", "of", "the", "pretend", "holiday", "world", "that", "human", "customers", "paid", "to", "participate", "in", "."], "sentence-detokenized": "In the movie Westworld, female robots actually had sex with human men as part of the pretend holiday world that human customers paid to participate in.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [22, 23], [24, 30], [31, 37], [38, 46], [47, 50], [51, 54], [55, 59], [60, 65], [66, 69], [70, 72], [73, 77], [78, 80], [81, 84], [85, 92], [93, 100], [101, 106], [107, 111], [112, 117], [118, 127], [128, 132], [133, 135], [136, 147], [148, 150], [150, 151]]}
{"doc_key": "ai-test-268", "ner": [[5, 6, "task"], [20, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 20, 25, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Usually", "the", "process", "starts", "with", "extracting", "terminology", "and", "concepts", "or", "noun", "phrases", "from", "plain", "text", "using", "linguistic", "processors", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "phrase", "chunking", "."], "sentence-detokenized": "Usually the process starts with extracting terminology and concepts or noun phrases from plain text using linguistic processors such as part-of-speech tagging and phrase chunking.", "token2charspan": [[0, 7], [8, 11], [12, 19], [20, 26], [27, 31], [32, 42], [43, 54], [55, 58], [59, 67], [68, 70], [71, 75], [76, 83], [84, 88], [89, 94], [95, 99], [100, 105], [106, 116], [117, 127], [128, 132], [133, 135], [136, 140], [140, 141], [141, 143], [143, 144], [144, 150], [151, 158], [159, 162], [163, 169], [170, 178], [178, 179]]}
{"doc_key": "ai-test-269", "ner": [[18, 19, "task"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "demonstrated", "its", "performance", "on", "a", "number", "of", "problems", "of", "interest", "to", "the", "machine", "learning", "community", ",", "including", "handwriting", "recognition", "."], "sentence-detokenized": "They demonstrated its performance on a number of problems of interest to the machine learning community, including handwriting recognition.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 33], [34, 36], [37, 38], [39, 45], [46, 48], [49, 57], [58, 60], [61, 69], [70, 72], [73, 76], [77, 84], [85, 93], [94, 103], [103, 104], [105, 114], [115, 126], [127, 138], [138, 139]]}
{"doc_key": "ai-test-270", "ner": [[2, 2, "university"], [4, 4, "researcher"], [10, 13, "researcher"], [17, 17, "product"], [21, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 2, 2, "physical", "", false, false], [4, 4, 2, 2, "role", "", false, false], [17, 17, 10, 13, "origin", "", false, false], [17, 17, 21, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "at", "Stanford", ",", "Scheinman", "received", "a", "scholarship", "sponsored", "by", "George", "Devol", ",", "the", "inventor", "of", "the", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "While at Stanford, Scheinman received a scholarship sponsored by George Devol, the inventor of the Unimate, the first industrial robot.", "token2charspan": [[0, 5], [6, 8], [9, 17], [17, 18], [19, 28], [29, 37], [38, 39], [40, 51], [52, 61], [62, 64], [65, 71], [72, 77], [77, 78], [79, 82], [83, 91], [92, 94], [95, 98], [99, 106], [106, 107], [108, 111], [112, 117], [118, 128], [129, 134], [134, 135]]}
{"doc_key": "ai-test-271", "ner": [[5, 16, "task"], [11, 13, "metrics"], [9, 9, "metrics"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 16, 11, 13, "usage", "", true, false], [9, 9, 11, 13, "named", "", false, false], [21, 23, 11, 13, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Although", "originally", "used", "to", "evaluate", "machine", "translations", ",", "the", "BLEU", "(", "Bilingual", "Evaluation", "Understudy", ")", "has", "been", "successfully", "used", "to", "evaluate", "paraphrase", "generation", "models", "."], "sentence-detokenized": "Although originally used to evaluate machine translations, the BLEU (Bilingual Evaluation Understudy) has been successfully used to evaluate paraphrase generation models.", "token2charspan": [[0, 8], [9, 19], [20, 24], [25, 27], [28, 36], [37, 44], [45, 57], [57, 58], [59, 62], [63, 67], [68, 69], [69, 78], [79, 89], [90, 100], [100, 101], [102, 105], [106, 110], [111, 123], [124, 128], [129, 131], [132, 140], [141, 151], [152, 162], [163, 169], [169, 170]]}
{"doc_key": "ai-test-272", "ner": [[0, 0, "organisation"], [6, 8, "organisation"], [10, 10, "organisation"], [14, 14, "product"], [16, 16, "country"], [18, 18, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 8, "role", "licenses_to", false, false], [0, 0, 10, 10, "role", "licenses_to", false, false], [6, 8, 16, 16, "physical", "", false, false], [10, 10, 18, 18, "physical", "", false, false], [14, 14, 6, 8, "artifact", "produces", false, false], [14, 14, 10, 10, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "later", "licensed", "its", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "which", "produced", "Unimates", "in", "Japan", "and", "England", "respectively", "."], "sentence-detokenized": "Unimation later licensed its technology to Kawasaki Heavy Industries and GKN, which produced Unimates in Japan and England respectively.", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 57], [58, 68], [69, 72], [73, 76], [76, 77], [78, 83], [84, 92], [93, 101], [102, 104], [105, 110], [111, 114], [115, 122], [123, 135], [135, 136]]}
{"doc_key": "ai-test-273", "ner": [[19, 20, "conference"], [36, 37, "field"], [55, 59, "field"], [61, 63, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[36, 37, 55, 59, "compare", "", false, false], [61, 63, 55, 59, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "confusion", "between", "these", "two", "research", "groups", "(", "which", "often", "have", "separate", "conferences", "and", "journals", ",", "with", "ECML", "PKDD", "being", "a", "major", "exception", ")", "stems", "from", "the", "fundamental", "assumptions", "they", "work", "with", ":", "in", "machine", "learning", ",", "performance", "is", "usually", "evaluated", "in", "terms", "of", "the", "ability", "to", "reproduce", "known", "knowledge", ",", "while", "in", "knowledge", "discovery", "and", "data", "mining", "(", "KDD", ")", "the", "main", "task", "is", "to", "discover", "previously", "unknown", "knowledge", "."], "sentence-detokenized": "Much of the confusion between these two research groups (which often have separate conferences and journals, with ECML PKDD being a major exception) stems from the fundamental assumptions they work with: in machine learning, performance is usually evaluated in terms of the ability to reproduce known knowledge, while in knowledge discovery and data mining (KDD) the main task is to discover previously unknown knowledge.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 29], [30, 35], [36, 39], [40, 48], [49, 55], [56, 57], [57, 62], [63, 68], [69, 73], [74, 82], [83, 94], [95, 98], [99, 107], [107, 108], [109, 113], [114, 118], [119, 123], [124, 129], [130, 131], [132, 137], [138, 147], [147, 148], [149, 154], [155, 159], [160, 163], [164, 175], [176, 187], [188, 192], [193, 197], [198, 202], [202, 203], [204, 206], [207, 214], [215, 223], [223, 224], [225, 236], [237, 239], [240, 247], [248, 257], [258, 260], [261, 266], [267, 269], [270, 273], [274, 281], [282, 284], [285, 294], [295, 300], [301, 310], [310, 311], [312, 317], [318, 320], [321, 330], [331, 340], [341, 344], [345, 349], [350, 356], [357, 358], [358, 361], [361, 362], [363, 366], [367, 371], [372, 376], [377, 379], [380, 382], [383, 391], [392, 402], [403, 410], [411, 420], [420, 421]]}
{"doc_key": "ai-test-274", "ner": [[0, 0, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hidden", "Markov", "models", "are", "the", "basis", "of", "most", "modern", "automatic", "speech", "recognition", "systems", "."], "sentence-detokenized": "Hidden Markov models are the basis of most modern automatic speech recognition systems.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 28], [29, 34], [35, 37], [38, 42], [43, 49], [50, 59], [60, 66], [67, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-test-275", "ner": [[4, 4, "location"], [6, 6, "country"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 6, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": [",", "a", "company", "in", "Bangalore", ",", "India", ",", "specialising", "in", "online", "handwriting", "recognition", "software", "."], "sentence-detokenized": ", a company in Bangalore, India, specialising in online handwriting recognition software.", "token2charspan": [[0, 1], [2, 3], [4, 11], [12, 14], [15, 24], [24, 25], [26, 31], [31, 32], [33, 45], [46, 48], [49, 55], [56, 67], [68, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-276", "ner": [[24, 25, "misc"], [52, 56, "metrics"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Do", "repeated", "translations", "result", "in", "a", "single", "expression", "in", "both", "languages", "?", "I.e.", "does", "the", "translation", "method", "exhibit", "stationarity", "or", "does", "it", "produce", "a", "canonical", "form", "?", "Does", "the", "translation", "become", "stationary", "without", "losing", "the", "original", "meaning", "?", "This", "measure", "has", "been", "criticised", "for", "not", "being", "well", "correlated", "with", "the", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "score", "."], "sentence-detokenized": "Do repeated translations result in a single expression in both languages? I.e. does the translation method exhibit stationarity or does it produce a canonical form? Does the translation become stationary without losing the original meaning? This measure has been criticised for not being well correlated with the BLEU (BiLingual Evaluation Understudy) score.", "token2charspan": [[0, 2], [3, 11], [12, 24], [25, 31], [32, 34], [35, 36], [37, 43], [44, 54], [55, 57], [58, 62], [63, 72], [72, 73], [74, 78], [79, 83], [84, 87], [88, 99], [100, 106], [107, 114], [115, 127], [128, 130], [131, 135], [136, 138], [139, 146], [147, 148], [149, 158], [159, 163], [163, 164], [165, 169], [170, 173], [174, 185], [186, 192], [193, 203], [204, 211], [212, 218], [219, 222], [223, 231], [232, 239], [239, 240], [241, 245], [246, 253], [254, 257], [258, 262], [263, 273], [274, 277], [278, 281], [282, 287], [288, 292], [293, 303], [304, 308], [309, 312], [313, 317], [318, 319], [319, 328], [329, 339], [340, 350], [350, 351], [352, 357], [357, 358]]}
{"doc_key": "ai-test-277", "ner": [[6, 10, "organisation"], [13, 20, "organisation"], [22, 23, "university"], [26, 26, "university"], [29, 30, "field"], [33, 37, "organisation"], [40, 43, "organisation"], [50, 53, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[13, 20, 22, 23, "part-of", "", false, false], [26, 26, 29, 30, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "has", "received", "fellowships", "from", "the", "American", "Association", "for", "Artificial", "Intelligence", ",", "the", "Center", "for", "Advanced", "Study", "in", "the", "Behavioral", "Sciences", "at", "Stanford", "University", ",", "the", "MIT", "Center", "for", "Cognitive", "Science", ",", "the", "Canadian", "Institute", "for", "Advanced", "Research", ",", "the", "Canadian", "Psychological", "Association", "and", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "in", "1998", "."], "sentence-detokenized": "He has received fellowships from the American Association for Artificial Intelligence, the Center for Advanced Study in the Behavioral Sciences at Stanford University, the MIT Center for Cognitive Science, the Canadian Institute for Advanced Research, the Canadian Psychological Association and was elected a Fellow of the Royal Society of Canada in 1998.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 27], [28, 32], [33, 36], [37, 45], [46, 57], [58, 61], [62, 72], [73, 85], [85, 86], [87, 90], [91, 97], [98, 101], [102, 110], [111, 116], [117, 119], [120, 123], [124, 134], [135, 143], [144, 146], [147, 155], [156, 166], [166, 167], [168, 171], [172, 175], [176, 182], [183, 186], [187, 196], [197, 204], [204, 205], [206, 209], [210, 218], [219, 228], [229, 232], [233, 241], [242, 250], [250, 251], [252, 255], [256, 264], [265, 278], [279, 290], [291, 294], [295, 298], [299, 306], [307, 308], [309, 315], [316, 318], [319, 322], [323, 328], [329, 336], [337, 339], [340, 346], [347, 349], [350, 354], [354, 355]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [15, 17, "misc"], [20, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 15, 17, "part-of", "", false, false], [0, 0, 20, 23, "part-of", "", false, false], [4, 5, 15, 17, "part-of", "", false, false], [4, 5, 20, 23, "part-of", "", false, false], [7, 8, 15, 17, "part-of", "", false, false], [7, 8, 20, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "-", "along", "with", "Yoshua", "Bengio", "and", "Yann", "LeCun", "-", "is", "called", "by", "some", "the", "godfathers", "of", "AI", "and", "the", "godfathers", "of", "Deep", "Learning", "."], "sentence-detokenized": "Hinton - along with Yoshua Bengio and Yann LeCun - is called by some the godfathers of AI and the godfathers of Deep Learning.", "token2charspan": [[0, 6], [7, 8], [9, 14], [15, 19], [20, 26], [27, 33], [34, 37], [38, 42], [43, 48], [49, 50], [51, 53], [54, 60], [61, 63], [64, 68], [69, 72], [73, 83], [84, 86], [87, 89], [90, 93], [94, 97], [98, 108], [109, 111], [112, 116], [117, 125], [125, 126]]}
{"doc_key": "ai-test-279", "ner": [[6, 6, "product"], [18, 18, "misc"], [20, 21, "misc"], [22, 22, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 18, 18, "related-to", "", false, false], [6, 6, 20, 21, "related-to", "", false, false], [18, 18, 22, 22, "named", "same", false, false], [26, 27, 22, 22, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "open", "source", "lightweight", "speech", "project", "eSpeak", ",", "which", "has", "its", "own", "synthesis", "method", ",", "has", "experimented", "with", "Mandarin", "and", "Cantonese", ".", "eSpeak", "was", "used", "by", "Google", "Translate", "from", "May", "2010", "to", "2010", "."], "sentence-detokenized": "The open source lightweight speech project eSpeak, which has its own synthesis method, has experimented with Mandarin and Cantonese. eSpeak was used by Google Translate from May 2010 to 2010.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 27], [28, 34], [35, 42], [43, 49], [49, 50], [51, 56], [57, 60], [61, 64], [65, 68], [69, 78], [79, 85], [85, 86], [87, 90], [91, 103], [104, 108], [109, 117], [118, 121], [122, 131], [131, 132], [133, 139], [140, 143], [144, 148], [149, 151], [152, 158], [159, 168], [169, 173], [174, 177], [178, 182], [183, 185], [186, 190], [190, 191]]}
{"doc_key": "ai-test-280", "ner": [[0, 2, "product"], [13, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 13, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Software", "Automatic", "Mouth", ",", "also", "released", "in", "1982", ",", "was", "the", "first", "commercial", "voice", "synthesis", "program", "to", "consist", "entirely", "of", "software", "."], "sentence-detokenized": "Software Automatic Mouth, also released in 1982, was the first commercial voice synthesis program to consist entirely of software.", "token2charspan": [[0, 8], [9, 18], [19, 24], [24, 25], [26, 30], [31, 39], [40, 42], [43, 47], [47, 48], [49, 52], [53, 56], [57, 62], [63, 73], [74, 79], [80, 89], [90, 97], [98, 100], [101, 108], [109, 117], [118, 120], [121, 129], [129, 130]]}
{"doc_key": "ai-test-281", "ner": [[4, 6, "metrics"], [8, 8, "metrics"], [12, 12, "metrics"], [14, 14, "metrics"], [17, 23, "metrics"], [29, 31, "metrics"], [33, 33, "metrics"], [36, 42, "metrics"], [46, 48, "metrics"], [50, 50, "metrics"], [54, 54, "metrics"], [56, 56, "metrics"], [59, 65, "metrics"], [71, 73, "metrics"], [75, 75, "metrics"], [78, 84, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[8, 8, 4, 6, "named", "", false, false], [12, 12, 4, 6, "named", "", false, false], [14, 14, 4, 6, "named", "", false, false], [17, 23, 4, 6, "named", "", false, false], [33, 33, 29, 31, "named", "", false, false], [36, 42, 29, 31, "named", "", false, false], [50, 50, 46, 48, "named", "", false, false], [54, 54, 46, 48, "named", "", false, false], [56, 56, 46, 48, "named", "", false, false], [59, 65, 46, 48, "named", "", false, false], [75, 75, 71, 73, "named", "", false, false], [78, 84, 71, 73, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["The", "column", "ratios", "are", "TRUE", "Positive", "Rate", "(", "TPR", ",", "also", "called", "Sensitivity", "or", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "with", "the", "complement", "FALSE", "Negative", "Rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ",", "and", "TRUE", "Negative", "Rate", "(", "TNR", ",", "also", "called", "Specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "with", "the", "complement", "FALSE", "Positive", "Rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "The column ratios are TRUE Positive Rate (TPR, also called Sensitivity or recall) (TP / (TP + FN)), with the complement FALSE Negative Rate (FNR) (FN / (TP + FN)), and TRUE Negative Rate (TNR, also called Specificity, SPC) (TN / (TN + FP)), with the complement FALSE Positive Rate (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 21], [22, 26], [27, 35], [36, 40], [41, 42], [42, 45], [45, 46], [47, 51], [52, 58], [59, 70], [71, 73], [74, 80], [80, 81], [82, 83], [83, 85], [86, 87], [88, 89], [89, 91], [92, 93], [94, 96], [96, 97], [97, 98], [98, 99], [100, 104], [105, 108], [109, 119], [120, 125], [126, 134], [135, 139], [140, 141], [141, 144], [144, 145], [146, 147], [147, 149], [150, 151], [152, 153], [153, 155], [156, 157], [158, 160], [160, 161], [161, 162], [162, 163], [164, 167], [168, 172], [173, 181], [182, 186], [187, 188], [188, 191], [191, 192], [193, 197], [198, 204], [205, 216], [216, 217], [218, 221], [221, 222], [223, 224], [224, 226], [227, 228], [229, 230], [230, 232], [233, 234], [235, 237], [237, 238], [238, 239], [239, 240], [241, 245], [246, 249], [250, 260], [261, 266], [267, 275], [276, 280], [281, 282], [282, 285], [285, 286], [287, 288], [288, 290], [291, 292], [293, 294], [294, 296], [297, 298], [299, 301], [301, 302], [302, 303], [303, 304]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 15, 15, "role", "working_with", false, false], [2, 2, 15, 15, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "and", "Weber", "also", "worked", "with", "many", "other", "robots", ",", "and", "their", "experience", "working", "with", "Kismet"], "sentence-detokenized": "Edsinger and Weber also worked with many other robots, and their experience working with Kismet", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 30], [31, 35], [36, 40], [41, 46], [47, 53], [53, 54], [55, 58], [59, 64], [65, 75], [76, 83], [84, 88], [89, 95]]}
{"doc_key": "ai-test-283", "ner": [[11, 11, "programlang"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["R", "functions", "are", "available", "from", "several", "scripting", "languages", ",", "e.g", ".", "Python", ",", "are", "also", "available", "."], "sentence-detokenized": "R functions are available from several scripting languages, e.g. Python, are also available.", "token2charspan": [[0, 1], [2, 11], [12, 15], [16, 25], [26, 30], [31, 38], [39, 48], [49, 58], [58, 59], [60, 63], [63, 64], [65, 71], [71, 72], [73, 76], [77, 81], [82, 91], [91, 92]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "was", "one", "of", "the", "first", "robot", "languages", "and", "was", "used", "in", "Unimate", "robots", "."], "sentence-detokenized": "VAL was one of the first robot languages and was used in Unimate robots.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 24], [25, 30], [31, 40], [41, 44], [45, 48], [49, 53], [54, 56], [57, 64], [65, 71], [71, 72]]}
{"doc_key": "ai-test-285", "ner": [[13, 22, "conference"], [20, 20, "conference"], [24, 24, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 22, 24, 24, "physical", "", false, false], [20, 20, 13, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["They", "presented", "their", "database", "for", "the", "first", "time", "as", "a", "poster", "at", "the", "2009", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "conference", "in", "Florida", "."], "sentence-detokenized": "They presented their database for the first time as a poster at the 2009 Computer Vision and Pattern Recognition (CVPR) conference in Florida.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 29], [30, 33], [34, 37], [38, 43], [44, 48], [49, 51], [52, 53], [54, 60], [61, 63], [64, 67], [68, 72], [73, 81], [82, 88], [89, 92], [93, 100], [101, 112], [113, 114], [114, 118], [118, 119], [120, 130], [131, 133], [134, 141], [141, 142]]}
{"doc_key": "ai-test-286", "ner": [[0, 2, "misc"], [9, 10, "task"], [12, 13, "field"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 0, 2, "type-of", "", false, false], [12, 13, 0, 2, "type-of", "", false, false], [15, 16, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Categorisation", "tasks", "where", "no", "labels", "are", "provided", "are", "called", "unsupervised", "classification", ",", "unsupervised", "learning", "and", "cluster", "analysis", "."], "sentence-detokenized": "Categorisation tasks where no labels are provided are called unsupervised classification, unsupervised learning and cluster analysis.", "token2charspan": [[0, 14], [15, 20], [21, 26], [27, 29], [30, 36], [37, 40], [41, 49], [50, 53], [54, 60], [61, 73], [74, 88], [88, 89], [90, 102], [103, 111], [112, 115], [116, 123], [124, 132], [132, 133]]}
{"doc_key": "ai-test-287", "ner": [[5, 6, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "must", "be", "able", "to", "recognise", "objects", ",", "recognise", "and", "locate", "people", "and", "recognise", "emotions", "."], "sentence-detokenized": "It must be able to recognise objects, recognise and locate people and recognise emotions.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 15], [16, 18], [19, 28], [29, 36], [36, 37], [38, 47], [48, 51], [52, 58], [59, 65], [66, 69], [70, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-288", "ner": [[7, 7, "misc"], [9, 9, "misc"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "process", "is", "complex", "and", "involves", "both", "coding", "and", "recall", "."], "sentence-detokenized": "The process is complex and involves both coding and recall.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 26], [27, 35], [36, 40], [41, 47], [48, 51], [52, 58], [58, 59]]}
{"doc_key": "ai-test-289", "ner": [[10, 11, "product"], [15, 16, "product"], [35, 35, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 15, 16, "named", "", false, false], [10, 11, 35, 35, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "also", "known", "as", "parallel", "robots", "or", "generalised", "Stewart", "platforms", "(", "in", "the", "Stewart", "platform", ",", "the", "actuators", "are", "linked", "to", "each", "other", "on", "both", "the", "base", "and", "the", "platform", ")", ",", "are", "guided", "robots", "that", "use", "similar", "mechanisms", "to", "move", "either", "the", "robot", "on", "its", "base", "or", "one", "or", "more", "manipulator", "arms", "."], "sentence-detokenized": "These systems, also known as parallel robots or generalised Stewart platforms (in the Stewart platform, the actuators are linked to each other on both the base and the platform), are guided robots that use similar mechanisms to move either the robot on its base or one or more manipulator arms.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 25], [26, 28], [29, 37], [38, 44], [45, 47], [48, 59], [60, 67], [68, 77], [78, 79], [79, 81], [82, 85], [86, 93], [94, 102], [102, 103], [104, 107], [108, 117], [118, 121], [122, 128], [129, 131], [132, 136], [137, 142], [143, 145], [146, 150], [151, 154], [155, 159], [160, 163], [164, 167], [168, 176], [176, 177], [177, 178], [179, 182], [183, 189], [190, 196], [197, 201], [202, 205], [206, 213], [214, 224], [225, 227], [228, 232], [233, 239], [240, 243], [244, 249], [250, 252], [253, 256], [257, 261], [262, 264], [265, 268], [269, 271], [272, 276], [277, 288], [289, 293], [293, 294]]}
{"doc_key": "ai-test-290", "ner": [[0, 1, "field"], [4, 5, "field"], [13, 17, "field"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 5, "part-of", "subfield", false, false], [0, 1, 13, 17, "compare", "", false, false], [13, 17, 21, 22, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "vision", "as", "a", "systems", "engineering", "discipline", "can", "be", "considered", "as", "distinct", "from", "computer", "vision", ",", "which", "is", "a", "form", "of", "computer", "science", "."], "sentence-detokenized": "Machine vision as a systems engineering discipline can be considered as distinct from computer vision, which is a form of computer science.", "token2charspan": [[0, 7], [8, 14], [15, 17], [18, 19], [20, 27], [28, 39], [40, 50], [51, 54], [55, 57], [58, 68], [69, 71], [72, 80], [81, 85], [86, 94], [95, 101], [101, 102], [103, 108], [109, 111], [112, 113], [114, 118], [119, 121], [122, 130], [131, 138], [138, 139]]}
{"doc_key": "ai-test-291", "ner": [[5, 6, "algorithm"], [10, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 10, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "enabling", "function", "for", "the", "LSTM", "ports", "is", "often", "the", "logistic", "sigmoid", "function", "."], "sentence-detokenized": "The enabling function for the LSTM ports is often the logistic sigmoid function.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 25], [26, 29], [30, 34], [35, 40], [41, 43], [44, 49], [50, 53], [54, 62], [63, 70], [71, 79], [79, 80]]}
{"doc_key": "ai-test-292", "ner": [[5, 6, "metrics"], [20, 24, "metrics"], [26, 26, "metrics"], [34, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 20, 24, "named", "", false, false], [5, 6, 34, 36, "named", "", false, false], [26, 26, 20, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "the", "(", "necessarily", "unique", ")", "efficient", "estimator", ",", "and", "hence", "also", "the", "minimum", "variance", "-", "free", "estimator", "(", "MVUE", ")", ",", "in", "addition", "to", "being", "the", "maximum", "likelihood", "estimator", "."], "sentence-detokenized": "In other words, the sample mean is the (necessarily unique) efficient estimator, and hence also the minimum variance-free estimator (MVUE), in addition to being the maximum likelihood estimator.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 38], [39, 40], [40, 51], [52, 58], [58, 59], [60, 69], [70, 79], [79, 80], [81, 84], [85, 90], [91, 95], [96, 99], [100, 107], [108, 116], [116, 117], [117, 121], [122, 131], [132, 133], [133, 137], [137, 138], [138, 139], [140, 142], [143, 151], [152, 154], [155, 160], [161, 164], [165, 172], [173, 183], [184, 193], [193, 194]]}
{"doc_key": "ai-test-293", "ner": [[2, 2, "academicjournal"], [6, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [22, 22, "product"], [25, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 22, 22, "topic", "", false, false], [2, 2, 25, 26, "topic", "", false, false], [6, 8, 2, 2, "role", "", false, false], [10, 11, 2, 2, "role", "", false, false], [13, 14, 2, 2, "role", "", false, false], [22, 22, 25, 26, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "2001", "Scientific", "American", "article", "by", "Berners", "-", "Lee", ",", "James", "Hendler", "and", "Ora", "Lassila", "describes", "an", "expected", "evolution", "of", "the", "existing", "web", "into", "a", "semantic", "web", "."], "sentence-detokenized": "The 2001 Scientific American article by Berners-Lee, James Hendler and Ora Lassila describes an expected evolution of the existing web into a semantic web.", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 28], [29, 36], [37, 39], [40, 47], [47, 48], [48, 51], [51, 52], [53, 58], [59, 66], [67, 70], [71, 74], [75, 82], [83, 92], [93, 95], [96, 104], [105, 114], [115, 117], [118, 121], [122, 130], [131, 134], [135, 139], [140, 141], [142, 150], [151, 154], [154, 155]]}
{"doc_key": "ai-test-294", "ner": [[0, 1, "misc"], [12, 13, "person"], [15, 15, "person"], [23, 24, "person"], [38, 38, "person"], [44, 45, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 13, 0, 1, "role", "actor_in_work", false, false], [15, 15, 12, 13, "named", "", false, false], [15, 15, 12, 13, "origin", "", false, false], [23, 24, 15, 15, "part-of", "", false, false], [44, 45, 15, 15, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Blade", "Runner", "used", "a", "number", "of", "then", "lesser", "-", "known", "actors", ":", "Sean", "Young", "plays", "Rachael", ",", "an", "experimental", "replicant", "who", "has", "had", "Tyrell", "'s", "niece", "'s", "memories", "implanted", ",", "causing", "her", "to", "believe", "she", "is", "human", ";", "Sammon", ",", "pp.", "92", "-", "93", "Nina", "Axelrod", "auditioned", "for", "the", "role", "."], "sentence-detokenized": "Blade Runner used a number of then lesser-known actors: Sean Young plays Rachael, an experimental replicant who has had Tyrell's niece's memories implanted, causing her to believe she is human; Sammon, pp. 92-93 Nina Axelrod auditioned for the role.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 19], [20, 26], [27, 29], [30, 34], [35, 41], [41, 42], [42, 47], [48, 54], [54, 55], [56, 60], [61, 66], [67, 72], [73, 80], [80, 81], [82, 84], [85, 97], [98, 107], [108, 111], [112, 115], [116, 119], [120, 126], [126, 128], [129, 134], [134, 136], [137, 145], [146, 155], [155, 156], [157, 164], [165, 168], [169, 171], [172, 179], [180, 183], [184, 186], [187, 192], [192, 193], [194, 200], [200, 201], [202, 205], [206, 208], [208, 209], [209, 211], [212, 216], [217, 224], [225, 235], [236, 239], [240, 243], [244, 248], [248, 249]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [13, 15, "university"], [24, 26, "product"], [28, 28, "product"], [43, 43, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 13, 15, "physical", "", false, false], [3, 4, 13, 15, "physical", "", false, false], [6, 7, 13, 15, "physical", "", false, false], [9, 10, 13, 15, "physical", "", false, false], [13, 15, 43, 43, "physical", "", true, false], [24, 26, 13, 15, "temporal", "", false, false], [28, 28, 13, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "and", "Terry", "Winograd", "visited", "the", "University", "of", "Edinburgh", "in", "1971", "to", "spread", "the", "word", "about", "the", "Micro", "-", "Planner", "and", "SHRDLU", "and", "to", "challenge", "the", "uniform", "proof", "procedure", "that", "had", "been", "the", "mainstay", "of", "the", "Edinburgh", "logicians", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited the University of Edinburgh in 1971 to spread the word about the Micro-Planner and SHRDLU and to challenge the uniform proof procedure that had been the mainstay of the Edinburgh logicians.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 56], [57, 65], [66, 73], [74, 77], [78, 88], [89, 91], [92, 101], [102, 104], [105, 109], [110, 112], [113, 119], [120, 123], [124, 128], [129, 134], [135, 138], [139, 144], [144, 145], [145, 152], [153, 156], [157, 163], [164, 167], [168, 170], [171, 180], [181, 184], [185, 192], [193, 198], [199, 208], [209, 213], [214, 217], [218, 222], [223, 226], [227, 235], [236, 238], [239, 242], [243, 252], [253, 262], [262, 263]]}
{"doc_key": "ai-test-296", "ner": [[0, 1, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[0, 1, 11, 12, "role", "inspires", false, false], [0, 1, 14, 15, "role", "inspires", false, false], [0, 1, 17, 18, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Walter", "'s", "work", "inspired", "subsequent", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work inspired subsequent generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 22], [23, 33], [34, 45], [46, 48], [49, 57], [58, 69], [70, 74], [75, 77], [78, 84], [85, 91], [91, 92], [93, 97], [98, 105], [106, 109], [110, 114], [115, 121], [121, 122]]}
{"doc_key": "ai-test-297", "ner": [[7, 7, "algorithm"], [9, 10, "researcher"], [16, 23, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 9, 10, "origin", "", false, false], [7, 7, 16, 23, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Subsequently", ",", "a", "similar", "GPU", "-", "based", "CNN", "by", "Alex", "Krizhevsky", "et", "al", ".", "won", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "in", "2012", "."], "sentence-detokenized": "Subsequently, a similar GPU-based CNN by Alex Krizhevsky et al. won the ImageNet Large Scale Visual Recognition Challenge in 2012.", "token2charspan": [[0, 12], [12, 13], [14, 15], [16, 23], [24, 27], [27, 28], [28, 33], [34, 37], [38, 40], [41, 45], [46, 56], [57, 59], [60, 62], [62, 63], [64, 67], [68, 71], [72, 80], [81, 86], [87, 92], [93, 99], [100, 111], [112, 121], [122, 124], [125, 129], [129, 130]]}
{"doc_key": "ai-test-298", "ner": [[2, 3, "misc"], [9, 10, "metrics"], [13, 14, "metrics"], [20, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 2, 3, "type-of", "", false, false], [13, 14, 2, 3, "type-of", "", false, false], [13, 14, 20, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Commonly", "used", "loss", "functions", "for", "probabilistic", "classification", "are", "the", "log", "loss", "and", "the", "Brier", "score", "between", "the", "predicted", "and", "the", "true", "probability", "distribution", "."], "sentence-detokenized": "Commonly used loss functions for probabilistic classification are the log loss and the Brier score between the predicted and the true probability distribution.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 28], [29, 32], [33, 46], [47, 61], [62, 65], [66, 69], [70, 73], [74, 78], [79, 82], [83, 86], [87, 92], [93, 98], [99, 106], [107, 110], [111, 120], [121, 124], [125, 128], [129, 133], [134, 145], [146, 158], [158, 159]]}
{"doc_key": "ai-test-299", "ner": [[4, 4, "organisation"], [10, 10, "organisation"], [20, 21, "misc"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[4, 4, 20, 21, "part-of", "", false, false], [10, 10, 4, 4, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "May", "2016", ",", "NtechLab", "was", "invited", "to", "participate", "in", "NIST", "'s", "official", "testing", "of", "biometric", "technology", "among", "the", "three", "Russian", "companies", "."], "sentence-detokenized": "In May 2016, NtechLab was invited to participate in NIST's official testing of biometric technology among the three Russian companies.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [22, 25], [26, 33], [34, 36], [37, 48], [49, 51], [52, 56], [56, 58], [59, 67], [68, 75], [76, 78], [79, 88], [89, 99], [100, 105], [106, 109], [110, 115], [116, 123], [124, 133], [133, 134]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "floating", "point", "numbers", "have", "only", "a", "certain", "mathematical", "precision", "."], "sentence-detokenized": "However, floating point numbers have only a certain mathematical precision.", "token2charspan": [[0, 7], [7, 8], [9, 17], [18, 23], [24, 31], [32, 36], [37, 41], [42, 43], [44, 51], [52, 64], [65, 74], [74, 75]]}
{"doc_key": "ai-test-301", "ner": [[5, 5, "organisation"], [12, 18, "conference"], [20, 20, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 12, 18, "role", "contributes_to", false, false], [20, 20, 12, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2015", ",", "many", "of", "SenseTime", "'s", "papers", "were", "accepted", "to", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "In 2015, many of SenseTime's papers were accepted to the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 13], [14, 16], [17, 26], [26, 28], [29, 35], [36, 40], [41, 49], [50, 52], [53, 56], [57, 67], [68, 70], [71, 79], [80, 86], [87, 90], [91, 98], [99, 110], [111, 112], [112, 116], [116, 117], [117, 118]]}
{"doc_key": "ai-test-302", "ner": [[6, 8, "task"], [10, 10, "task"], [13, 14, "task"], [16, 19, "task"], [22, 22, "field"], [24, 26, "misc"], [29, 35, "conference"], [43, 45, "misc"], [47, 48, "conference"], [65, 67, "misc"], [69, 69, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[6, 8, 22, 22, "part-of", "task_part_of_field", false, false], [10, 10, 6, 8, "named", "", false, false], [13, 14, 22, 22, "part-of", "task_part_of_field", false, false], [16, 19, 13, 14, "named", "", false, false], [24, 26, 29, 35, "temporal", "", false, false], [43, 45, 47, 48, "temporal", "", false, false], [65, 67, 69, 69, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["He", "helped", "develop", "optimal", "algorithms", "for", "Structure", "From", "Motion", "(", "SFM", ",", "or", "Visual", "SLAM", ",", "simultaneous", "localization", "and", "mapping", ",", "in", "Robotics", ";", "Best", "Paper", "Award", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "1998", ")", ",", "characterized", "its", "ambiguities", "(", "David", "Marr", "Prize", "at", "ICCV", "1999", ")", ",", "and", "also", "characterized", "the", "identifiability", "and", "observability", "of", "visual", "-", "inertial", "sensor", "fusion", "(", "Best", "Paper", "Award", "at", "Robotics", "2015", ")", "."], "sentence-detokenized": "He helped develop optimal algorithms for Structure From Motion (SFM, or Visual SLAM, simultaneous localization and mapping, in Robotics; Best Paper Award at the Conference on Computer Vision and Pattern Recognition 1998), characterized its ambiguities (David Marr Prize at ICCV 1999), and also characterized the identifiability and observability of visual-inertial sensor fusion (Best Paper Award at Robotics 2015).", "token2charspan": [[0, 2], [3, 9], [10, 17], [18, 25], [26, 36], [37, 40], [41, 50], [51, 55], [56, 62], [63, 64], [64, 67], [67, 68], [69, 71], [72, 78], [79, 83], [83, 84], [85, 97], [98, 110], [111, 114], [115, 122], [122, 123], [124, 126], [127, 135], [135, 136], [137, 141], [142, 147], [148, 153], [154, 156], [157, 160], [161, 171], [172, 174], [175, 183], [184, 190], [191, 194], [195, 202], [203, 214], [215, 219], [219, 220], [220, 221], [222, 235], [236, 239], [240, 251], [252, 253], [253, 258], [259, 263], [264, 269], [270, 272], [273, 277], [278, 282], [282, 283], [283, 284], [285, 288], [289, 293], [294, 307], [308, 311], [312, 327], [328, 331], [332, 345], [346, 348], [349, 355], [355, 356], [356, 364], [365, 371], [372, 378], [379, 380], [380, 384], [385, 390], [391, 396], [397, 399], [400, 408], [409, 413], [413, 414], [414, 415]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 3, "task"], [7, 8, "field"], [10, 11, "field"], [13, 14, "field"], [18, 19, "task"], [21, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 7, 8, "part-of", "task_part_of_field", false, false], [0, 3, 10, 11, "part-of", "task_part_of_field", false, false], [0, 3, 13, 14, "part-of", "task_part_of_field", false, false], [0, 3, 18, 19, "part-of", "", false, false], [0, 3, 21, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "a", "fundamental", "tool", "in", "image", "processing", ",", "machine", "vision", "and", "computer", "vision", ",", "especially", "for", "feature", "detection", "and", "extraction", "."], "sentence-detokenized": "Edge detection is a fundamental tool in image processing, machine vision and computer vision, especially for feature detection and extraction.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 19], [20, 31], [32, 36], [37, 39], [40, 45], [46, 56], [56, 57], [58, 65], [66, 72], [73, 76], [77, 85], [86, 92], [92, 93], [94, 104], [105, 108], [109, 116], [117, 126], [127, 130], [131, 141], [141, 142]]}
{"doc_key": "ai-test-305", "ner": [[10, 11, "misc"], [28, 31, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "example", "of", "this", "is", "a", "variable", "such", "as", "the", "outdoor", "temperature", "(", "mathtemp", "/", "math", ")", ",", "which", "in", "a", "given", "application", "can", "be", "recorded", "with", "several", "decimal", "places", "of", "accuracy", "(", "depending", "on", "the", "measuring", "equipment", ")", "."], "sentence-detokenized": "An example of this is a variable such as the outdoor temperature (mathtemp / math), which in a given application can be recorded with several decimal places of accuracy (depending on the measuring equipment).", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 18], [19, 21], [22, 23], [24, 32], [33, 37], [38, 40], [41, 44], [45, 52], [53, 64], [65, 66], [66, 74], [75, 76], [77, 81], [81, 82], [82, 83], [84, 89], [90, 92], [93, 94], [95, 100], [101, 112], [113, 116], [117, 119], [120, 128], [129, 133], [134, 141], [142, 149], [150, 156], [157, 159], [160, 168], [169, 170], [170, 179], [180, 182], [183, 186], [187, 196], [197, 206], [206, 207], [207, 208]]}
{"doc_key": "ai-test-306", "ner": [[4, 5, "person"], [7, 8, "person"], [10, 11, "person"], [18, 19, "person"], [27, 28, "person"], [30, 31, "organisation"], [32, 33, "person"], [37, 39, "person"], [40, 40, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 6, 7, 8, 10, 11], "relations": [[32, 33, 30, 31, "role", "", false, false], [40, 40, 37, 39, "named", "", false, false]], "relations_mapping_to_source": [2, 4], "sentence": ["The", "returning", "judges", "are", "Fon", "Davis", ",", "Jessica", "Chobot", "and", "Leland", "Melvin", ",", "as", "well", "as", "guest", "judges", "Clark", "Gregg", ",", "MythBusters", "host", "and", "former", "Battlebots", "builder", "Adam", "Savage", ",", "NFL", "'s", "Vernon", "Davis", "and", "YouTube", "star", "Michael", "Stevens", "aka", "Vsauce", "."], "sentence-detokenized": "The returning judges are Fon Davis, Jessica Chobot and Leland Melvin, as well as guest judges Clark Gregg, MythBusters host and former Battlebots builder Adam Savage, NFL's Vernon Davis and YouTube star Michael Stevens aka Vsauce.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 24], [25, 28], [29, 34], [34, 35], [36, 43], [44, 50], [51, 54], [55, 61], [62, 68], [68, 69], [70, 72], [73, 77], [78, 80], [81, 86], [87, 93], [94, 99], [100, 105], [105, 106], [107, 118], [119, 123], [124, 127], [128, 134], [135, 145], [146, 153], [154, 158], [159, 165], [165, 166], [167, 170], [170, 172], [173, 179], [180, 185], [186, 189], [190, 197], [198, 202], [203, 210], [211, 218], [219, 222], [223, 229], [229, 230]]}
{"doc_key": "ai-test-307", "ner": [[14, 15, "algorithm"], [16, 20, "algorithm"], [22, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 22, 26, "part-of", "", false, false], [16, 20, 22, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["But", "these", "methods", "never", "won", "over", "the", "uneven", "internal", "hand", "-", "crafted", "technique", "of", "Gaussian", "mixture", "model", "/", "Hidden", "Markov", "model", "(", "GMM", "-", "HMM", ")", "which", "relies", "on", "generative", "models", "of", "numbers", "trained", "discriminatively", "."], "sentence-detokenized": "But these methods never won over the uneven internal hand-crafted technique of Gaussian mixture model/Hidden Markov model (GMM-HMM) which relies on generative models of numbers trained discriminatively.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 23], [24, 27], [28, 32], [33, 36], [37, 43], [44, 52], [53, 57], [57, 58], [58, 65], [66, 75], [76, 78], [79, 87], [88, 95], [96, 101], [101, 102], [102, 108], [109, 115], [116, 121], [122, 123], [123, 126], [126, 127], [127, 130], [130, 131], [132, 137], [138, 144], [145, 147], [148, 158], [159, 165], [166, 168], [169, 176], [177, 184], [185, 201], [201, 202]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "and", "SciPy", "offer", "practical", "ways", "to", "apply", "these", "different", "methods", "."], "sentence-detokenized": "Software packages such as MATLAB, GNU Octave, Scilab and SciPy offer practical ways to apply these different methods.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [53, 56], [57, 62], [63, 68], [69, 78], [79, 83], [84, 86], [87, 92], [93, 98], [99, 108], [109, 116], [116, 117]]}
{"doc_key": "ai-test-309", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [8, 10, "task"], [18, 19, "researcher"], [21, 22, "university"], [24, 25, "researcher"], [27, 30, "organisation"], [32, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 8, 10, "related-to", "", false, false], [0, 2, 18, 19, "origin", "", false, false], [0, 2, 24, 25, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [18, 19, 21, 22, "physical", "", false, false], [18, 19, 21, 22, "role", "", false, false], [24, 25, 27, 30, "physical", "", false, false], [24, 25, 27, 30, "role", "", false, false], [32, 32, 27, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Linear", "Predictive", "Coding", "(", "LPC", ")", ",", "a", "speech", "processing", "algorithm", ",", "was", "first", "proposed", "in", "1966", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "."], "sentence-detokenized": "Linear Predictive Coding (LPC), a speech processing algorithm, was first proposed in 1966 by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT).", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 72], [73, 81], [82, 84], [85, 89], [90, 92], [93, 101], [102, 109], [110, 112], [113, 119], [120, 130], [131, 134], [135, 140], [141, 146], [147, 149], [150, 156], [157, 166], [167, 170], [171, 180], [181, 182], [182, 185], [185, 186], [186, 187]]}
{"doc_key": "ai-test-310", "ner": [[20, 27, "conference"], [29, 29, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[29, 29, 20, 27, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2006", ",", "on", "the", "occasion", "of", "the", "25th", "anniversary", "of", "the", "algorithm", ",", "a", "workshop", "was", "organised", "at", "the", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "to", "summarise", "the", "latest", "contributions", "and", "variations", "of", "the", "original", "algorithm", ",", "mainly", "to", "improve", "the", "speed", "of", "the", "algorithm", ",", "the", "robustness", "and", "accuracy", "of", "the", "estimated", "solution", "and", "to", "reduce", "the", "dependence", "on", "user", "-", "defined", "constants", "."], "sentence-detokenized": "In 2006, on the occasion of the 25th anniversary of the algorithm, a workshop was organised at the International Conference on Computer Vision and Pattern Recognition (CVPR) to summarise the latest contributions and variations of the original algorithm, mainly to improve the speed of the algorithm, the robustness and accuracy of the estimated solution and to reduce the dependence on user-defined constants.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 24], [25, 27], [28, 31], [32, 36], [37, 48], [49, 51], [52, 55], [56, 65], [65, 66], [67, 68], [69, 77], [78, 81], [82, 91], [92, 94], [95, 98], [99, 112], [113, 123], [124, 126], [127, 135], [136, 142], [143, 146], [147, 154], [155, 166], [167, 168], [168, 172], [172, 173], [174, 176], [177, 186], [187, 190], [191, 197], [198, 211], [212, 215], [216, 226], [227, 229], [230, 233], [234, 242], [243, 252], [252, 253], [254, 260], [261, 263], [264, 271], [272, 275], [276, 281], [282, 284], [285, 288], [289, 298], [298, 299], [300, 303], [304, 314], [315, 318], [319, 327], [328, 330], [331, 334], [335, 344], [345, 353], [354, 357], [358, 360], [361, 367], [368, 371], [372, 382], [383, 385], [386, 390], [390, 391], [391, 398], [399, 408], [408, 409]]}
{"doc_key": "ai-test-311", "ner": [[5, 7, "university"], [10, 13, "organisation"], [15, 17, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "members", "went", "to", "the", "University", "of", "Debrecen", ",", "the", "Hungarian", "Academy", "of", "Sciences", ",", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "University", ",", "etc", "."], "sentence-detokenized": "The members went to the University of Debrecen, the Hungarian Academy of Sciences, E\u00f6tv\u00f6s Lor\u00e1nd University, etc.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 46], [46, 47], [48, 51], [52, 61], [62, 69], [70, 72], [73, 81], [81, 82], [83, 89], [90, 96], [97, 107], [107, 108], [109, 112], [112, 113]]}
{"doc_key": "ai-test-312", "ner": [[3, 3, "algorithm"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 17, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "extend", "the", "SVM", "to", "cases", "where", "the", "data", "are", "not", "linearly", "separable", ",", "we", "introduce", "the", "loss", "function", ","], "sentence-detokenized": "To extend the SVM to cases where the data are not linearly separable, we introduce the loss function,", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 17], [18, 20], [21, 26], [27, 32], [33, 36], [37, 41], [42, 45], [46, 49], [50, 58], [59, 68], [68, 69], [70, 72], [73, 82], [83, 86], [87, 91], [92, 100], [100, 101]]}
{"doc_key": "ai-test-313", "ner": [[0, 0, "programlang"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 10, 11, "origin", "", false, false], [0, 0, 13, 14, "origin", "", false, false], [0, 0, 16, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "is", "an", "educational", "programming", "language", "designed", "in", "1967", "by", "Wally", "Feurzeig", ",", "Seymour", "Papert", "and", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo is an educational programming language designed in 1967 by Wally Feurzeig, Seymour Papert and Cynthia Solomon.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 34], [35, 43], [44, 52], [53, 55], [56, 60], [61, 63], [64, 69], [70, 78], [78, 79], [80, 87], [88, 94], [95, 98], [99, 106], [107, 114], [114, 115]]}
{"doc_key": "ai-test-314", "ner": [[0, 3, "organisation"], [8, 12, "organisation"], [14, 17, "location"], [19, 19, "location"], [21, 21, "location"], [33, 36, "product"], [42, 49, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 8, 12, "role", "works_for", false, false], [8, 12, 14, 17, "physical", "", false, false], [14, 17, 19, 19, "physical", "", false, false], [19, 19, 21, 21, "physical", "", false, false], [33, 36, 0, 3, "origin", "", false, false], [42, 49, 33, 36, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "Eyring", "Research", "Institute", "was", "instrumental", "to", "the", "U.S.", "Air", "Force", "Missile", "Directorate", "at", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", ",", "in", "producing", ",", "in", "the", "highest", "military", "secrecy", ",", "the", "intelligent", "systems", "engineering", "software", "that", "was", "the", "basis", "for", "Reagan", "'s", "later", "-", "named", "Star", "Wars", "program", "."], "sentence-detokenized": "The Eyring Research Institute was instrumental to the U.S. Air Force Missile Directorate at Hill Air Force Base near Ogden, Utah, in producing, in the highest military secrecy, the intelligent systems engineering software that was the basis for Reagan's later-named Star Wars program.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 29], [30, 33], [34, 46], [47, 49], [50, 53], [54, 58], [59, 62], [63, 68], [69, 76], [77, 88], [89, 91], [92, 96], [97, 100], [101, 106], [107, 111], [112, 116], [117, 122], [122, 123], [124, 128], [128, 129], [130, 132], [133, 142], [142, 143], [144, 146], [147, 150], [151, 158], [159, 167], [168, 175], [175, 176], [177, 180], [181, 192], [193, 200], [201, 212], [213, 221], [222, 226], [227, 230], [231, 234], [235, 240], [241, 244], [245, 251], [251, 253], [254, 259], [259, 260], [260, 265], [266, 270], [271, 275], [276, 283], [283, 284]]}
{"doc_key": "ai-test-315", "ner": [[12, 13, "field"], [23, 26, "researcher"], [28, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Over", "the", "decades", ",", "he", "has", "researched", "and", "developed", "new", "areas", "of", "computer", "science", "from", "compilers", ",", "programming", "languages", "and", "system", "architecture", "to", "John", "F", ".", "Sowa", "and", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "Over the decades, he has researched and developed new areas of computer science from compilers, programming languages and system architecture to John F. Sowa and John Zachman (1992).", "token2charspan": [[0, 4], [5, 8], [9, 16], [16, 17], [18, 20], [21, 24], [25, 35], [36, 39], [40, 49], [50, 53], [54, 59], [60, 62], [63, 71], [72, 79], [80, 84], [85, 94], [94, 95], [96, 107], [108, 117], [118, 121], [122, 128], [129, 141], [142, 144], [145, 149], [150, 151], [151, 152], [153, 157], [158, 161], [162, 166], [167, 174], [175, 176], [176, 180], [180, 181], [181, 182]]}
{"doc_key": "ai-test-316", "ner": [[0, 2, "algorithm"], [7, 10, "algorithm"], [13, 14, "algorithm"], [19, 20, "field"], [22, 23, "field"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 10, 0, 2, "named", "", false, false], [13, 14, 0, 2, "named", "", false, false], [19, 20, 0, 2, "usage", "", false, false], [22, 23, 0, 2, "usage", "", false, false], [27, 29, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Sobel", "operator", ",", "sometimes", "called", "the", "Sobel", "-", "Feldman", "operator", "or", "the", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "particularly", "in", "edge", "detection", "algorithms", "where", "it", "creates", "an", "image", "that", "emphasises", "edges", "."], "sentence-detokenized": "The Sobel operator, sometimes called the Sobel-Feldman operator or the Sobel filter, is used in image processing and computer vision, particularly in edge detection algorithms where it creates an image that emphasises edges.", "token2charspan": [[0, 3], [4, 9], [10, 18], [18, 19], [20, 29], [30, 36], [37, 40], [41, 46], [46, 47], [47, 54], [55, 63], [64, 66], [67, 70], [71, 76], [77, 83], [83, 84], [85, 87], [88, 92], [93, 95], [96, 101], [102, 112], [113, 116], [117, 125], [126, 132], [132, 133], [134, 146], [147, 149], [150, 154], [155, 164], [165, 175], [176, 181], [182, 184], [185, 192], [193, 195], [196, 201], [202, 206], [207, 217], [218, 223], [223, 224]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [3, 3, "field"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 3, "compare", "", false, false], [0, 0, 3, 3, "type-of", "", false, false], [0, 0, 15, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "is", "a", "supervised", "learning", "algorithm", "that", "uses", "the", "labels", "of", "the", "data", ",", "while", "PCA", "is", "a", "learning", "algorithm", "that", "does", "not", "take", "the", "labels", "into", "account", "."], "sentence-detokenized": "LDA is a supervised learning algorithm that uses the labels of the data, while PCA is a learning algorithm that does not take the labels into account.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 19], [20, 28], [29, 38], [39, 43], [44, 48], [49, 52], [53, 59], [60, 62], [63, 66], [67, 71], [71, 72], [73, 78], [79, 82], [83, 85], [86, 87], [88, 96], [97, 106], [107, 111], [112, 116], [117, 120], [121, 125], [126, 129], [130, 136], [137, 141], [142, 149], [149, 150]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "linear", "classification", "algorithms", "are", "Winnow", ",", "support", "vector", "machine", "and", "logistic", "regression", "."], "sentence-detokenized": "Other linear classification algorithms are Winnow, support vector machine and logistic regression.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 38], [39, 42], [43, 49], [49, 50], [51, 58], [59, 65], [66, 73], [74, 77], [78, 86], [87, 97], [97, 98]]}
{"doc_key": "ai-test-319", "ner": [[0, 3, "product"], [7, 8, "programlang"], [16, 18, "product"], [20, 20, "programlang"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 7, 8, "general-affiliation", "", true, false], [0, 3, 16, 18, "general-affiliation", "", true, false], [0, 3, 20, 20, "general-affiliation", "", true, false], [0, 3, 22, 22, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "consists", "of", "a", "class", "library", "in", "C", "++", "and", "several", "interpreted", "interface", "layers", ",", "including", "Tcl", "/", "Tk", ",", "Java", "and", "Python", "."], "sentence-detokenized": "VTK consists of a class library in C++ and several interpreted interface layers, including Tcl/Tk, Java and Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 17], [18, 23], [24, 31], [32, 34], [35, 36], [36, 38], [39, 42], [43, 50], [51, 62], [63, 72], [73, 79], [79, 80], [81, 90], [91, 94], [94, 95], [95, 97], [97, 98], [99, 103], [104, 107], [108, 114], [114, 115]]}
{"doc_key": "ai-test-320", "ner": [[7, 9, "task"], [16, 18, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Text", "produced", "by", "processing", "spontaneous", "speech", "using", "automatic", "speech", "recognition", "and", "printed", "or", "handwritten", "text", "using", "optical", "character", "recognition", "also", "contains", "processing", "noise", "."], "sentence-detokenized": "Text produced by processing spontaneous speech using automatic speech recognition and printed or handwritten text using optical character recognition also contains processing noise.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 27], [28, 39], [40, 46], [47, 52], [53, 62], [63, 69], [70, 81], [82, 85], [86, 93], [94, 96], [97, 108], [109, 113], [114, 119], [120, 127], [128, 137], [138, 149], [150, 154], [155, 163], [164, 174], [175, 180], [180, 181]]}
{"doc_key": "ai-test-321", "ner": [[0, 0, "researcher"], [9, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 9, 11, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "wrote", "several", "books", "and", "led", "the", "development", "of", "WordNet", ",", "a", "database", "of", "online", "word", "links", "that", "can", "be", "used", "by", "computer", "programs", "."], "sentence-detokenized": "Miller wrote several books and led the development of WordNet, a database of online word links that can be used by computer programs.", "token2charspan": [[0, 6], [7, 12], [13, 20], [21, 26], [27, 30], [31, 34], [35, 38], [39, 50], [51, 53], [54, 61], [61, 62], [63, 64], [65, 73], [74, 76], [77, 83], [84, 88], [89, 94], [95, 99], [100, 103], [104, 106], [107, 111], [112, 114], [115, 123], [124, 132], [132, 133]]}
{"doc_key": "ai-test-322", "ner": [[1, 1, "field"], [5, 7, "organisation"], [10, 10, "country"], [12, 13, "person"], [15, 17, "person"], [19, 20, "person"], [22, 23, "person"], [26, 26, "country"], [28, 31, "location"], [33, 34, "misc"], [35, 36, "person"], [38, 39, "person"], [41, 41, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[5, 7, 10, 10, "physical", "", false, false], [12, 13, 26, 26, "physical", "", false, false], [15, 17, 26, 26, "physical", "", false, false], [19, 20, 26, 26, "physical", "", false, false], [22, 23, 26, 26, "physical", "", false, false], [28, 31, 1, 1, "general-affiliation", "", false, false], [28, 31, 35, 36, "artifact", "", false, false], [33, 34, 35, 36, "named", "", false, false], [38, 39, 41, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Contemporary", "automatons", "are", "represented", "by", "Cabaret", "Mechanical", "Theatre", "in", "the", "UK", ",", "Dug", "North", "and", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "in", "the", "US", ",", "Le", "D\u00e9fenseur", "du", "Temps", "by", "French", "artist", "Jacques", "Monestier", "and", "Fran\u00e7ois", "Junod", "in", "Switzerland", "."], "sentence-detokenized": "Contemporary automatons are represented by Cabaret Mechanical Theatre in the UK, Dug North and Chomick + Meder, Arthur Ganson, Joe Jones in the US, Le D\u00e9fenseur du Temps by French artist Jacques Monestier and Fran\u00e7ois Junod in Switzerland.", "token2charspan": [[0, 12], [13, 23], [24, 27], [28, 39], [40, 42], [43, 50], [51, 61], [62, 69], [70, 72], [73, 76], [77, 79], [79, 80], [81, 84], [85, 90], [91, 94], [95, 102], [103, 104], [105, 110], [110, 111], [112, 118], [119, 125], [125, 126], [127, 130], [131, 136], [137, 139], [140, 143], [144, 146], [146, 147], [148, 150], [151, 160], [161, 163], [164, 169], [170, 172], [173, 179], [180, 186], [187, 194], [195, 204], [205, 208], [209, 217], [218, 223], [224, 226], [227, 238], [238, 239]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 21, 21, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "has", "standard", "codefor", "/", "code", "and", "codewhile", "/", "code", "loops", ",", "but", "(", "as", "in", "other", "similar", "programs", "such", "as", "R", ")", "the", "use", "of", "vectorized", "notation", "is", "encouraged", "and", "is", "often", "faster", "to", "execute", "."], "sentence-detokenized": "MATLAB has standard codefor/code and codewhile/code loops, but (as in other similar programs such as R) the use of vectorized notation is encouraged and is often faster to execute.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 27], [27, 28], [28, 32], [33, 36], [37, 46], [46, 47], [47, 51], [52, 57], [57, 58], [59, 62], [63, 64], [64, 66], [67, 69], [70, 75], [76, 83], [84, 92], [93, 97], [98, 100], [101, 102], [102, 103], [104, 107], [108, 111], [112, 114], [115, 125], [126, 134], [135, 137], [138, 148], [149, 152], [153, 155], [156, 161], [162, 168], [169, 171], [172, 179], [179, 180]]}
{"doc_key": "ai-test-324", "ner": [[0, 0, "researcher"], [6, 9, "conference"], [16, 18, "field"], [19, 23, "misc"], [26, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 19, 23, "win-defeat", "", false, false], [0, 0, 26, 35, "win-defeat", "", false, false], [19, 23, 6, 9, "temporal", "", false, false], [19, 23, 16, 18, "topic", "", false, false], [26, 35, 6, 9, "temporal", "", false, false], [26, 35, 16, 18, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "in", "2007", "for", "his", "contributions", "to", "computer", "science", "education", ".", "Karlstrom", "Outstanding", "Educator", "Award", "and", "the", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contributions", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "Pausch received two awards from the Association for Computing Machinery in 2007 for his contributions to computer science education. Karlstrom Outstanding Educator Award and the ACM SIGCSE Award for Outstanding Contributions to Computer Science Education.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 26], [27, 31], [32, 35], [36, 47], [48, 51], [52, 61], [62, 71], [72, 74], [75, 79], [80, 83], [84, 87], [88, 101], [102, 104], [105, 113], [114, 121], [122, 131], [131, 132], [133, 142], [143, 154], [155, 163], [164, 169], [170, 173], [174, 177], [178, 181], [182, 188], [189, 194], [195, 198], [199, 210], [211, 224], [225, 227], [228, 236], [237, 244], [245, 254], [254, 255]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [8, 9, "product"], [15, 16, "organisation"]], "ner_mapping_to_source": [0, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 86], [87, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-test-326", "ner": [[0, 1, "algorithm"], [5, 10, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 0, 1, "usage", "", false, false], [12, 13, 5, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantic", "networks", "are", "used", "in", "natural", "language", "processing", "applications", ",", "such", "as", "semantic", "interpretation", "."], "sentence-detokenized": "Semantic networks are used in natural language processing applications, such as semantic interpretation.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 26], [27, 29], [30, 37], [38, 46], [47, 57], [58, 70], [70, 71], [72, 76], [77, 79], [80, 88], [89, 103], [103, 104]]}
{"doc_key": "ai-test-327", "ner": [[4, 5, "field"], [7, 8, "field"], [10, 11, "task"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 8, 4, 5, "usage", "", false, false], [10, 11, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Some", "successful", "applications", "of", "deep", "learning", "are", "computer", "vision", "and", "speech", "recognition", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Some successful applications of deep learning are computer vision and speech recognition. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 31], [32, 36], [37, 45], [46, 49], [50, 58], [59, 65], [66, 69], [70, 76], [77, 88], [88, 89], [90, 97], [98, 101], [101, 102], [103, 108], [109, 115], [115, 116], [117, 123], [124, 133], [133, 134], [135, 141], [142, 143], [143, 144], [145, 147], [147, 148]]}
{"doc_key": "ai-test-328", "ner": [[5, 10, "product"], [16, 16, "misc"], [19, 19, "misc"], [25, 27, "product"], [28, 29, "task"], [31, 32, "task"], [34, 35, "task"], [37, 39, "field"], [41, 42, "task"], [44, 45, "field"], [47, 48, "task"], [50, 51, "task"], [53, 54, "task"], [56, 56, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[5, 10, 16, 16, "physical", "travels_to", false, false], [5, 10, 19, 19, "physical", "travels_to", false, false], [25, 27, 5, 10, "part-of", "", false, false], [25, 27, 5, 10, "role", "maintains", false, false], [25, 27, 28, 29, "related-to", "has_ability_to", false, false], [25, 27, 31, 32, "related-to", "has_ability_to", false, false], [25, 27, 34, 35, "related-to", "has_ability_to", false, false], [25, 27, 37, 39, "related-to", "has_ability_to", false, false], [25, 27, 41, 42, "related-to", "has_ability_to", false, false], [25, 27, 44, 45, "related-to", "has_ability_to", false, false], [25, 27, 47, 48, "related-to", "has_ability_to", false, false], [25, 27, 50, 51, "related-to", "has_ability_to", false, false], [25, 27, 53, 54, "related-to", "has_ability_to", false, false], [25, 27, 56, 56, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "addition", "to", "maintaining", "the", "systems", "of", "the", "Discovery", "One", "spacecraft", "during", "the", "interplanetary", "mission", "to", "Jupiter", "(", "or", "Saturn", "in", "the", "novel", ")", ",", "HAL", "can", "perform", "speech", "synthesis", ",", "speech", "recognition", ",", "facial", "recognition", ",", "natural", "language", "processing", ",", "lip", "reading", ",", "art", "assessment", ",", "affective", "computing", ",", "automated", "reasoning", ",", "spacecraft", "guidance", "and", "chess", "."], "sentence-detokenized": "In addition to maintaining the systems of the Discovery One spacecraft during the interplanetary mission to Jupiter (or Saturn in the novel), HAL can perform speech synthesis, speech recognition, facial recognition, natural language processing, lip reading, art assessment, affective computing, automated reasoning, spacecraft guidance and chess.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 38], [39, 41], [42, 45], [46, 55], [56, 59], [60, 70], [71, 77], [78, 81], [82, 96], [97, 104], [105, 107], [108, 115], [116, 117], [117, 119], [120, 126], [127, 129], [130, 133], [134, 139], [139, 140], [140, 141], [142, 145], [146, 149], [150, 157], [158, 164], [165, 174], [174, 175], [176, 182], [183, 194], [194, 195], [196, 202], [203, 214], [214, 215], [216, 223], [224, 232], [233, 243], [243, 244], [245, 248], [249, 256], [256, 257], [258, 261], [262, 272], [272, 273], [274, 283], [284, 293], [293, 294], [295, 304], [305, 314], [314, 315], [316, 326], [327, 335], [336, 339], [340, 345], [345, 346]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [4, 4, "country"], [7, 8, "country"], [11, 11, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 4, "physical", "", false, false], [0, 1, 7, 8, "physical", "", false, false], [0, 1, 11, 11, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr", "Julesz", "emigrated", "from", "Hungary", "to", "the", "United", "States", "after", "the", "Soviet", "invasion", "of", "1956", "."], "sentence-detokenized": "Dr Julesz emigrated from Hungary to the United States after the Soviet invasion of 1956.", "token2charspan": [[0, 2], [3, 9], [10, 19], [20, 24], [25, 32], [33, 35], [36, 39], [40, 46], [47, 53], [54, 59], [60, 63], [64, 70], [71, 79], [80, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-test-330", "ner": [[0, 0, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sigmoid", "activation", "functions", "use", "a", "second", "non-linearity", "for", "large", "inputs", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+\\", "exp", "(", "-", "v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "Sigmoid activation functions use a second non-linearity for large inputs: math\\ phi (v _ i) = (1 +\\ exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 7], [8, 18], [19, 28], [29, 32], [33, 34], [35, 41], [42, 55], [56, 59], [60, 65], [66, 72], [72, 73], [74, 78], [78, 79], [80, 83], [84, 85], [85, 86], [87, 88], [89, 90], [90, 91], [92, 93], [94, 95], [95, 96], [97, 99], [100, 103], [104, 105], [105, 106], [106, 107], [108, 109], [110, 111], [111, 112], [112, 113], [114, 115], [116, 117], [117, 119], [119, 120], [121, 122], [123, 127], [127, 128]]}
{"doc_key": "ai-test-331", "ner": [[12, 14, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "probabilities", "are", "used", "to", "determine", "what", "the", "target", "is", "using", "a", "maximum", "likelihood", "decision", "."], "sentence-detokenized": "These probabilities are used to determine what the target is using a maximum likelihood decision.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 46], [47, 50], [51, 57], [58, 60], [61, 66], [67, 68], [69, 76], [77, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-332", "ner": [[6, 8, "university"], [14, 16, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1984", "he", "moved", "to", "the", "University", "of", "Konstanz", "and", "in", "1990", "to", "the", "University", "of", "Salzburg", "."], "sentence-detokenized": "In 1984 he moved to the University of Konstanz and in 1990 to the University of Salzburg.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 46], [47, 50], [51, 53], [54, 58], [59, 61], [62, 65], [66, 76], [77, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-333", "ner": [[7, 8, "metrics"], [10, 12, "metrics"], [14, 16, "metrics"], [18, 18, "metrics"], [20, 21, "metrics"], [23, 25, "metrics"], [27, 30, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 12, 7, 8, "origin", "based_on", false, false], [14, 16, 7, 8, "origin", "based_on", false, false], [18, 18, 7, 8, "origin", "based_on", false, false], [20, 21, 7, 8, "origin", "based_on", false, false], [23, 25, 7, 8, "origin", "based_on", false, false], [27, 30, 7, 8, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Some", "popular", "fitness", "functions", "based", "on", "the", "confusion", "matrix", "are", "sensitivity", "/", "specificity", ",", "recall", "/", "precision", ",", "F-measure", ",", "Jaccard", "similarity", ",", "Matthews", "correlation", "coefficient", "and", "cost", "/", "benefit", "matrix", "which", "combines", "the", "costs", "and", "benefits", "assigned", "to", "the", "four", "different", "types", "of", "classifications", "."], "sentence-detokenized": "Some popular fitness functions based on the confusion matrix are sensitivity/specificity, recall/precision, F-measure, Jaccard similarity, Matthews correlation coefficient and cost/benefit matrix which combines the costs and benefits assigned to the four different types of classifications.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 30], [31, 36], [37, 39], [40, 43], [44, 53], [54, 60], [61, 64], [65, 76], [76, 77], [77, 88], [88, 89], [90, 96], [96, 97], [97, 106], [106, 107], [108, 117], [117, 118], [119, 126], [127, 137], [137, 138], [139, 147], [148, 159], [160, 171], [172, 175], [176, 180], [180, 181], [181, 188], [189, 195], [196, 201], [202, 210], [211, 214], [215, 220], [221, 224], [225, 233], [234, 242], [243, 245], [246, 249], [250, 254], [255, 264], [265, 270], [271, 273], [274, 289], [289, 290]]}
{"doc_key": "ai-test-334", "ner": [[6, 6, "product"], [8, 8, "product"], [10, 10, "product"], [12, 12, "product"], [15, 16, "programlang"], [28, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[28, 30, 6, 6, "part-of", "", false, false], [28, 30, 8, 8, "part-of", "", false, false], [28, 30, 10, 10, "part-of", "", false, false], [28, 30, 12, 12, "part-of", "", false, false], [28, 30, 15, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Common", "numerical", "programming", "environments", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "and", "the", "R", "language", "provide", "some", "of", "the", "simpler", "techniques", "for", "extracting", "functions", "(", "e.g.", "principal", "component", "analysis", ")", "via", "built", "-", "in", "commands", "."], "sentence-detokenized": "Common numerical programming environments such as MATLAB, SciLab, NumPy, Sklearn and the R language provide some of the simpler techniques for extracting functions (e.g. principal component analysis) via built-in commands.", "token2charspan": [[0, 6], [7, 16], [17, 28], [29, 41], [42, 46], [47, 49], [50, 56], [56, 57], [58, 64], [64, 65], [66, 71], [71, 72], [73, 80], [81, 84], [85, 88], [89, 90], [91, 99], [100, 107], [108, 112], [113, 115], [116, 119], [120, 127], [128, 138], [139, 142], [143, 153], [154, 163], [164, 165], [165, 169], [170, 179], [180, 189], [190, 198], [198, 199], [200, 203], [204, 209], [209, 210], [210, 212], [213, 221], [221, 222]]}
{"doc_key": "ai-test-335", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "have", "been", "introduced", "to", "collaborate", "with", "humans", "to", "perform", "industrial", "manufacturing", "tasks", "."], "sentence-detokenized": "Industrial robots have been introduced to collaborate with humans to perform industrial manufacturing tasks.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 27], [28, 38], [39, 41], [42, 53], [54, 58], [59, 65], [66, 68], [69, 76], [77, 87], [88, 101], [102, 107], [107, 108]]}
{"doc_key": "ai-test-336", "ner": [[6, 6, "field"], [8, 11, "researcher"], [21, 22, "field"], [24, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 21, 22, "related-to", "", false, false], [6, 6, 24, 25, "related-to", "", false, false], [6, 6, 27, 28, "related-to", "", false, false], [8, 11, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "first", "published", "paper", "on", "CGs", ",", "John", "F", ".", "Sowa", "applied", "them", "to", "a", "wide", "range", "of", "topics", "in", "artificial", "intelligence", ",", "computer", "science", "and", "cognitive", "science", "."], "sentence-detokenized": "In the first published paper on CGs, John F. Sowa applied them to a wide range of topics in artificial intelligence, computer science and cognitive science.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [23, 28], [29, 31], [32, 35], [35, 36], [37, 41], [42, 43], [43, 44], [45, 49], [50, 57], [58, 62], [63, 65], [66, 67], [68, 72], [73, 78], [79, 81], [82, 88], [89, 91], [92, 102], [103, 115], [115, 116], [117, 125], [126, 133], [134, 137], [138, 147], [148, 155], [155, 156]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [4, 4, "metrics"], [10, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "in", "its", "calculation", "of", "the", "penalty", "for", "brevity", ",", "as", "small", "variations", "in", "translation", "length", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from BLEU in its calculation of the penalty for brevity, as small variations in translation length do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 46], [47, 49], [50, 53], [54, 61], [62, 65], [66, 73], [73, 74], [75, 77], [78, 83], [84, 94], [95, 97], [98, 109], [110, 116], [117, 119], [120, 123], [124, 130], [131, 134], [135, 142], [143, 148], [149, 151], [152, 156], [156, 157]]}
{"doc_key": "ai-test-338", "ner": [[0, 5, "misc"], [20, 22, "field"]], "ner_mapping_to_source": [0, 2], "relations": [[0, 5, 20, 22, "topic", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["The", "IJCAI", "Award", "for", "Research", "Excellence", "is", "a", "prize", "awarded", "every", "two", "years", "at", "the", "IJCAI", "conference", "to", "researchers", "in", "artificial", "intelligence", "in", "recognition", "of", "their", "career", "."], "sentence-detokenized": "The IJCAI Award for Research Excellence is a prize awarded every two years at the IJCAI conference to researchers in artificial intelligence in recognition of their career.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 28], [29, 39], [40, 42], [43, 44], [45, 50], [51, 58], [59, 64], [65, 68], [69, 74], [75, 77], [78, 81], [82, 87], [88, 98], [99, 101], [102, 113], [114, 116], [117, 127], [128, 140], [141, 143], [144, 155], [156, 158], [159, 164], [165, 171], [171, 172]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [6, 6, "conference"], [15, 22, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 6, "role", "", false, false], [0, 0, 15, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "was", "a", "founding", "member", "of", "AAAI", "and", "is", "the", "only", "person", "to", "serve", "on", "both", "Microsoft", "and", "Apple", "'s", "scientific", "advisory", "committees", "."], "sentence-detokenized": "Lenat was a founding member of AAAI and is the only person to serve on both Microsoft and Apple's scientific advisory committees.", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 20], [21, 27], [28, 30], [31, 35], [36, 39], [40, 42], [43, 46], [47, 51], [52, 58], [59, 61], [62, 67], [68, 70], [71, 75], [76, 85], [86, 89], [90, 95], [95, 97], [98, 108], [109, 117], [118, 128], [128, 129]]}
{"doc_key": "ai-test-340", "ner": [[0, 0, "algorithm"], [5, 6, "misc"], [10, 12, "metrics"], [17, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "related-to", "minimise", false, false], [10, 12, 5, 6, "type-of", "", false, false], [17, 17, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoders", "are", "trained", "to", "minimize", "reconstruction", "errors", "(", "e.g.", ",", "mean", "square", "error", ")", ",", "often", "called", "loss", ":"], "sentence-detokenized": "Autoencoders are trained to minimize reconstruction errors (e.g., mean square error), often called loss:", "token2charspan": [[0, 12], [13, 16], [17, 24], [25, 27], [28, 36], [37, 51], [52, 58], [59, 60], [60, 64], [64, 65], [66, 70], [71, 77], [78, 83], [83, 84], [84, 85], [86, 91], [92, 98], [99, 103], [103, 104]]}
{"doc_key": "ai-test-341", "ner": [[27, 29, "misc"], [32, 32, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[32, 32, 27, 29, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "to", "using", "the", "definitions", "is", "to", "consider", "general", "word", "sense", "relatedness", "and", "calculate", "the", "similarity", "between", "each", "pair", "of", "word", "senses", "based", "on", "a", "given", "lexical", "knowledge", "base", ",", "e.g.", "WordNet", "."], "sentence-detokenized": "An alternative to using the definitions is to consider general word sense relatedness and calculate the similarity between each pair of word senses based on a given lexical knowledge base, e.g. WordNet.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 23], [24, 27], [28, 39], [40, 42], [43, 45], [46, 54], [55, 62], [63, 67], [68, 73], [74, 85], [86, 89], [90, 99], [100, 103], [104, 114], [115, 122], [123, 127], [128, 132], [133, 135], [136, 140], [141, 147], [148, 153], [154, 156], [157, 158], [159, 164], [165, 172], [173, 182], [183, 187], [187, 188], [189, 193], [194, 201], [201, 202]]}
{"doc_key": "ai-test-342", "ner": [[0, 2, "algorithm"], [9, 12, "researcher"], [15, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 12, "origin", "", false, false], [9, 12, 15, 17, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "invented", "by", "Richard", "S.", "Sutton", "that", "builds", "on", "Arthur", "Samuel", "'s", "earlier", "work", "on", "learning", "temporal", "differences", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm invented by Richard S. Sutton that builds on Arthur Samuel's earlier work on learning temporal differences.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 42], [43, 45], [46, 53], [54, 56], [57, 63], [64, 68], [69, 75], [76, 78], [79, 85], [86, 92], [92, 94], [95, 102], [103, 107], [108, 110], [111, 119], [120, 128], [129, 140], [140, 141]]}
{"doc_key": "ai-test-343", "ner": [[1, 2, "field"], [4, 4, "field"], [6, 7, "task"], [11, 13, "task"], [15, 18, "task"], [19, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 1, 2, "part-of", "task_part_of_field", false, false], [6, 7, 4, 4, "part-of", "task_part_of_field", false, false], [11, 13, 6, 7, "named", "", false, false], [15, 18, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "data", "mining", "and", "statistics", ",", "hierarchical", "clustering", "(", "also", "called", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "cluster", "analysis", "method", "that", "aims", "to", "build", "a", "hierarchy", "of", "clusters", "."], "sentence-detokenized": "In data mining and statistics, hierarchical clustering (also called hierarchical cluster analysis or HCA) is a cluster analysis method that aims to build a hierarchy of clusters.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 29], [29, 30], [31, 43], [44, 54], [55, 56], [56, 60], [61, 67], [68, 80], [81, 88], [89, 97], [98, 100], [101, 104], [104, 105], [106, 108], [109, 110], [111, 118], [119, 127], [128, 134], [135, 139], [140, 144], [145, 147], [148, 153], [154, 155], [156, 165], [166, 168], [169, 177], [177, 178]]}
{"doc_key": "ai-test-344", "ner": [[3, 3, "algorithm"], [8, 8, "field"], [10, 11, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "concept", "of", "deconvolution", "is", "widely", "used", "in", "signal", "and", "image", "processing", "."], "sentence-detokenized": "The concept of deconvolution is widely used in signal and image processing.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 53], [54, 57], [58, 63], [64, 74], [74, 75]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [19, 20, "misc"], [23, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 19, 20, "related-to", "enhances", false, false], [0, 1, 19, 20, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "serve", "to", "build", "and", "accumulate", "spatial", "knowledge", "and", "enable", "the", "inner", "eye", "to", "visualise", "images", "to", "reduce", "cognitive", "load", "and", "improve", "memory", "and", "learning", "of", "information", "."], "sentence-detokenized": "Cognitive maps serve to build and accumulate spatial knowledge and enable the inner eye to visualise images to reduce cognitive load and improve memory and learning of information.", "token2charspan": [[0, 9], [10, 14], [15, 20], [21, 23], [24, 29], [30, 33], [34, 44], [45, 52], [53, 62], [63, 66], [67, 73], [74, 77], [78, 83], [84, 87], [88, 90], [91, 100], [101, 107], [108, 110], [111, 117], [118, 127], [128, 132], [133, 136], [137, 144], [145, 151], [152, 155], [156, 164], [165, 167], [168, 179], [179, 180]]}
{"doc_key": "ai-test-346", "ner": [[9, 9, "programlang"], [11, 12, "programlang"], [14, 14, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "which", "usually", "provides", "bindings", "to", "languages", "such", "as", "Python", ",", "C", "++", "and", "Java", ")", "."], "sentence-detokenized": ", which usually provides bindings to languages such as Python, C++ and Java).", "token2charspan": [[0, 1], [2, 7], [8, 15], [16, 24], [25, 33], [34, 36], [37, 46], [47, 51], [52, 54], [55, 61], [61, 62], [63, 64], [64, 66], [67, 70], [71, 75], [75, 76], [76, 77]]}
{"doc_key": "ai-test-347", "ner": [[1, 3, "product"], [5, 5, "product"], [16, 17, "task"], [23, 24, "task"], [28, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 16, 17, "usage", "", false, false], [1, 3, 23, 24, "usage", "", false, false], [1, 3, 28, 32, "usage", "", false, false], [5, 5, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "Voice", "User", "Interface", "(", "VUI", ")", "enables", "spoken", "interaction", "between", "human", "and", "computer", ",", "using", "speech", "recognition", "to", "understand", "spoken", "commands", "and", "query", "responses", ",", "and", "usually", "text", "-", "to", "-", "speech", "to", "play", "back", "a", "response", "."], "sentence-detokenized": "A Voice User Interface (VUI) enables spoken interaction between human and computer, using speech recognition to understand spoken commands and query responses, and usually text-to-speech to play back a response.", "token2charspan": [[0, 1], [2, 7], [8, 12], [13, 22], [23, 24], [24, 27], [27, 28], [29, 36], [37, 43], [44, 55], [56, 63], [64, 69], [70, 73], [74, 82], [82, 83], [84, 89], [90, 96], [97, 108], [109, 111], [112, 122], [123, 129], [130, 138], [139, 142], [143, 148], [149, 158], [158, 159], [160, 163], [164, 171], [172, 176], [176, 177], [177, 179], [179, 180], [180, 186], [187, 189], [190, 194], [195, 199], [200, 201], [202, 210], [210, 211]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 4, "misc"], [13, 16, "researcher"], [18, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[0, 0, 3, 4, "general-affiliation", "is_a", false, false], [0, 0, 13, 16, "origin", "", false, false], [13, 16, 18, 19, "role", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["Jess", "is", "a", "rules", "engine", "for", "the", "Java", "platform", "that", "was", "developed", "by", "Ernest", "Friedman", "-", "Hill", "at", "Sandia", "National", "."], "sentence-detokenized": "Jess is a rules engine for the Java platform that was developed by Ernest Friedman-Hill at Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 15], [16, 22], [23, 26], [27, 30], [31, 35], [36, 44], [45, 49], [50, 53], [54, 63], [64, 66], [67, 73], [74, 82], [82, 83], [83, 87], [88, 90], [91, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-349", "ner": [[1, 2, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 16, 16, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "multi-layer", "perceptrons", ",", "where", "there", "is", "a", "hidden", "layer", ",", "more", "sophisticated", "algorithms", "such", "as", "backpropagation", "must", "be", "used", "."], "sentence-detokenized": "For multi-layer perceptrons, where there is a hidden layer, more sophisticated algorithms such as backpropagation must be used.", "token2charspan": [[0, 3], [4, 15], [16, 27], [27, 28], [29, 34], [35, 40], [41, 43], [44, 45], [46, 52], [53, 58], [58, 59], [60, 64], [65, 78], [79, 89], [90, 94], [95, 97], [98, 113], [114, 118], [119, 121], [122, 126], [126, 127]]}
{"doc_key": "ai-test-350", "ner": [[0, 1, "product"], [3, 6, "product"], [10, 13, "algorithm"], [17, 20, "field"], [22, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 0, 1, "part-of", "", false, false], [3, 6, 10, 13, "usage", "", false, true], [10, 13, 17, 20, "related-to", "performs", false, false], [22, 30, 17, 20, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "Translate", "'s", "neural", "machine", "translation", "system", "uses", "a", "large", "artificial", "neural", "network", "that", "attempts", "to", "perform", "deep", "learning", ",", "in", "particular", "networks", "with", "long", "-", "term", "short", "-", "term", "memory", "."], "sentence-detokenized": "Google Translate's neural machine translation system uses a large artificial neural network that attempts to perform deep learning, in particular networks with long-term short-term memory.", "token2charspan": [[0, 6], [7, 16], [16, 18], [19, 25], [26, 33], [34, 45], [46, 52], [53, 57], [58, 59], [60, 65], [66, 76], [77, 83], [84, 91], [92, 96], [97, 105], [106, 108], [109, 116], [117, 121], [122, 130], [130, 131], [132, 134], [135, 145], [146, 154], [155, 159], [160, 164], [164, 165], [165, 169], [170, 175], [175, 176], [176, 180], [181, 187], [187, 188]]}
{"doc_key": "ai-test-351", "ner": [[13, 13, "researcher"], [15, 15, "researcher"], [17, 17, "researcher"], [19, 20, "researcher"], [22, 23, "researcher"], [25, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Various", "methods", "for", "this", "were", "developed", "in", "the", "1980s", "and", "early", "1990s", "by", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "and", "others", "."], "sentence-detokenized": "Various methods for this were developed in the 1980s and early 1990s by Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter and others.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 24], [25, 29], [30, 39], [40, 42], [43, 46], [47, 52], [53, 56], [57, 62], [63, 68], [69, 71], [72, 78], [78, 79], [80, 88], [88, 89], [90, 98], [98, 99], [100, 106], [107, 118], [118, 119], [120, 124], [125, 135], [135, 136], [137, 148], [149, 152], [153, 159], [159, 160]]}
{"doc_key": "ai-test-352", "ner": [[1, 1, "organisation"], [2, 3, "organisation"], [8, 8, "organisation"], [11, 12, "task"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 8, 8, "role", "licenses_from", false, false], [2, 3, 1, 1, "named", "", false, false], [17, 17, 1, 1, "origin", "", false, false], [17, 17, 11, 12, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc", "originally", "licensed", "software", "from", "Nuance", "to", "enable", "speech", "recognition", "for", "its", "digital", "assistant", "Siri", "."], "sentence-detokenized": "| Apple Apple Inc originally licensed software from Nuance to enable speech recognition for its digital assistant Siri.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 17], [18, 28], [29, 37], [38, 46], [47, 51], [52, 58], [59, 61], [62, 68], [69, 75], [76, 87], [88, 91], [92, 95], [96, 103], [104, 113], [114, 118], [118, 119]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [3, 5, "misc"], [8, 9, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 5, "role", "releases_movies_in_genre", false, false], [8, 9, 0, 0, "role", "directs_for", false, false], [13, 14, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "released", "several", "3D", "western", "films", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia released several 3D western films produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 28], [29, 36], [37, 42], [43, 51], [52, 54], [55, 58], [59, 66], [67, 70], [71, 79], [80, 82], [83, 90], [91, 97], [97, 98]]}
{"doc_key": "ai-test-354", "ner": [[6, 7, "field"], [9, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "encompasses", "knowledge", "and", "research", "in", "computer", "science", ",", "linguistics", "and", "computer", "engineering", "."], "sentence-detokenized": "It encompasses knowledge and research in computer science, linguistics and computer engineering.", "token2charspan": [[0, 2], [3, 14], [15, 24], [25, 28], [29, 37], [38, 40], [41, 49], [50, 57], [57, 58], [59, 70], [71, 74], [75, 83], [84, 95], [95, 96]]}
{"doc_key": "ai-test-355", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", "is", "an", "example", "of", "an", "R", "code", ":"], "sentence-detokenized": "Here is an example of an R code:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 24], [25, 26], [27, 31], [31, 32]]}
{"doc_key": "ai-test-356", "ner": [[0, 2, "metrics"], [8, 10, "metrics"], [12, 12, "metrics"], [16, 18, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 8, 10, "part-of", "plotted_into", false, false], [0, 2, 16, 18, "part-of", "plotted_into", false, false], [12, 12, 8, 10, "named", "", false, false], [20, 20, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "ROC", "curve", "is", "created", "by", "plotting", "the", "true", "positive", "rate", "(", "TPR", ")", "against", "the", "false", "positive", "rate", "(", "FPR", ")", "at", "different", "thresholds", "."], "sentence-detokenized": "The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at different thresholds.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 24], [25, 27], [28, 36], [37, 40], [41, 45], [46, 54], [55, 59], [60, 61], [61, 64], [64, 65], [66, 73], [74, 77], [78, 83], [84, 92], [93, 97], [98, 99], [99, 102], [102, 103], [104, 106], [107, 116], [117, 127], [127, 128]]}
{"doc_key": "ai-test-357", "ner": [[11, 12, "field"], [3, 4, "researcher"], [6, 8, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 11, 12, "related-to", "researches_field", false, false], [6, 8, 11, 12, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Research", "stagnated", "after", "Marvin", "Minsky", "and", "Seymour", "Papert", "'s", "research", "on", "machine", "learning", "(", "1969", ")", ","], "sentence-detokenized": "Research stagnated after Marvin Minsky and Seymour Papert's research on machine learning (1969),", "token2charspan": [[0, 8], [9, 18], [19, 24], [25, 31], [32, 38], [39, 42], [43, 50], [51, 57], [57, 59], [60, 68], [69, 71], [72, 79], [80, 88], [89, 90], [90, 94], [94, 95], [95, 96]]}
{"doc_key": "ai-test-358", "ner": [[9, 10, "programlang"], [12, 14, "product"], [16, 17, "programlang"], [19, 19, "product"], [21, 21, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "environments", "used", "to", "build", "DAQ", "applications", "are", "ladder", "logic", ",", "Visual", "C", "++", ",", "Visual", "Basic", ",", "LabVIEW", "and", "MATLAB", "."], "sentence-detokenized": "Other programming environments used to build DAQ applications are ladder logic, Visual C++, Visual Basic, LabVIEW and MATLAB.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 38], [39, 44], [45, 48], [49, 61], [62, 65], [66, 72], [73, 78], [78, 79], [80, 86], [87, 88], [88, 90], [90, 91], [92, 98], [99, 104], [104, 105], [106, 113], [114, 117], [118, 124], [124, 125]]}
{"doc_key": "ai-test-359", "ner": [[14, 17, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "method", "was", "designed", "to", "address", "some", "of", "the", "problems", "of", "the", "more", "popular", "BLEU", "method", "and", "to", "correlate", "well", "with", "human", "judgments", "at", "the", "sentence", "or", "segment", "level", "."], "sentence-detokenized": "The method was designed to address some of the problems of the more popular BLEU method and to correlate well with human judgments at the sentence or segment level.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 34], [35, 39], [40, 42], [43, 46], [47, 55], [56, 58], [59, 62], [63, 67], [68, 75], [76, 80], [81, 87], [88, 91], [92, 94], [95, 104], [105, 109], [110, 114], [115, 120], [121, 130], [131, 133], [134, 137], [138, 146], [147, 149], [150, 157], [158, 163], [163, 164]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "term", "short", "term", "memory", "are", "often", "used", "to", "exploit", "the", "semantic", "correlations", "between", "successive", "video", "images", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long term short term memory are often used to exploit the semantic correlations between successive video images.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [83, 87], [88, 93], [94, 98], [99, 105], [106, 109], [110, 115], [116, 120], [121, 123], [124, 131], [132, 135], [136, 144], [145, 157], [158, 165], [166, 176], [177, 182], [183, 189], [189, 190]]}
{"doc_key": "ai-test-361", "ner": [[3, 3, "product"], [9, 14, "product"], [34, 34, "product"]], "ner_mapping_to_source": [1, 2, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Mass", "-", "produced", "PCBs", "are", "almost", "exclusively", "manufactured", "by", "pick", "-", "and", "-", "place", "robots", ",", "usually", "with", "SCARA", "manipulators", ",", "which", "remove", "small", "electronic", "components", "from", "strips", "or", "trays", "and", "place", "them", "on", "PCBs", "with", "great", "accuracy", "."], "sentence-detokenized": "Mass-produced PCBs are almost exclusively manufactured by pick-and-place robots, usually with SCARA manipulators, which remove small electronic components from strips or trays and place them on PCBs with great accuracy.", "token2charspan": [[0, 4], [4, 5], [5, 13], [14, 18], [19, 22], [23, 29], [30, 41], [42, 54], [55, 57], [58, 62], [62, 63], [63, 66], [66, 67], [67, 72], [73, 79], [79, 80], [81, 88], [89, 93], [94, 99], [100, 112], [112, 113], [114, 119], [120, 126], [127, 132], [133, 143], [144, 154], [155, 159], [160, 166], [167, 169], [170, 175], [176, 179], [180, 185], [186, 190], [191, 193], [194, 198], [199, 203], [204, 209], [210, 218], [218, 219]]}
{"doc_key": "ai-test-362", "ner": [[4, 5, "field"], [15, 15, "algorithm"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 29, "researcher"], [37, 38, "algorithm"], [40, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 4, 5, "part-of", "", false, false], [15, 15, 20, 21, "origin", "", false, false], [15, 15, 23, 24, "origin", "", false, false], [15, 15, 26, 29, "origin", "", false, false], [15, 15, 37, 38, "type-of", "", false, false], [37, 38, 40, 41, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "context", "of", "machine", "learning", ",", "where", "it", "is", "most", "widely", "used", "today", ",", "LDA", "was", "independently", "rediscovered", "by", "David", "Blei", ",", "Andrew", "Ng", "and", "Michael", "I", ".", "Jordan", "in", "2003", "and", "was", "presented", "as", "a", "graphical", "model", "for", "topic", "discovery", "."], "sentence-detokenized": "In the context of machine learning, where it is most widely used today, LDA was independently rediscovered by David Blei, Andrew Ng and Michael I. Jordan in 2003 and was presented as a graphical model for topic discovery.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 25], [26, 34], [34, 35], [36, 41], [42, 44], [45, 47], [48, 52], [53, 59], [60, 64], [65, 70], [70, 71], [72, 75], [76, 79], [80, 93], [94, 106], [107, 109], [110, 115], [116, 120], [120, 121], [122, 128], [129, 131], [132, 135], [136, 143], [144, 145], [145, 146], [147, 153], [154, 156], [157, 161], [162, 165], [166, 169], [170, 179], [180, 182], [183, 184], [185, 194], [195, 200], [201, 204], [205, 210], [211, 220], [220, 221]]}
{"doc_key": "ai-test-363", "ner": [[9, 9, "task"], [12, 12, "misc"], [15, 15, "metrics"], [17, 17, "metrics"], [19, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 12, 12, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "measured", "performance", "of", "test", "data", "from", "eight", "na\u00efve", "WSIs", "for", "different", "tauopathies", "resulted", "in", "recall", ",", "precision", "and", "F1", "scores", "of", "0.92", ",", "0.72", "and", "0.81", ",", "respectively", "."], "sentence-detokenized": "The measured performance of test data from eight na\u00efve WSIs for different tauopathies resulted in recall, precision and F1 scores of 0.92, 0.72 and 0.81, respectively.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 27], [28, 32], [33, 37], [38, 42], [43, 48], [49, 54], [55, 59], [60, 63], [64, 73], [74, 85], [86, 94], [95, 97], [98, 104], [104, 105], [106, 115], [116, 119], [120, 122], [123, 129], [130, 132], [133, 137], [137, 138], [139, 143], [144, 147], [148, 152], [152, 153], [154, 166], [166, 167]]}
{"doc_key": "ai-test-364", "ner": [[7, 8, "field"], [16, 17, "task"]], "ner_mapping_to_source": [1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Using", "advanced", "AR", "technology", "(", "e.g.", "adding", "computer", "vision", ",", "integrating", "AR", "cameras", "into", "smartphones", "and", "object", "recognition", ")", ",", "information", "about", "the", "user", "'s", "surrounding", "real", "world", "becomes", "interactive", "and", "digitally", "manipulated", "."], "sentence-detokenized": "Using advanced AR technology (e.g. adding computer vision, integrating AR cameras into smartphones and object recognition), information about the user's surrounding real world becomes interactive and digitally manipulated.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 28], [29, 30], [30, 34], [35, 41], [42, 50], [51, 57], [57, 58], [59, 70], [71, 73], [74, 81], [82, 86], [87, 98], [99, 102], [103, 109], [110, 121], [121, 122], [122, 123], [124, 135], [136, 141], [142, 145], [146, 150], [150, 152], [153, 164], [165, 169], [170, 175], [176, 183], [184, 195], [196, 199], [200, 209], [210, 221], [221, 222]]}
{"doc_key": "ai-test-365", "ner": [[3, 3, "researcher"], [8, 8, "organisation"], [16, 18, "field"], [27, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 8, "role", "forms_company", false, false], [8, 8, 16, 18, "related-to", "works_with", false, false], [8, 8, 27, 29, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2014", ",", "Schmidhuber", "founded", "a", "company", ",", "Nnaisense", ",", "to", "work", "on", "commercial", "applications", "of", "artificial", "intelligence", "in", "areas", "such", "as", "finance", ",", "heavy", "industry", "and", "self", "-", "driving", "cars", "."], "sentence-detokenized": "In 2014, Schmidhuber founded a company, Nnaisense, to work on commercial applications of artificial intelligence in areas such as finance, heavy industry and self-driving cars.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 28], [29, 30], [31, 38], [38, 39], [40, 49], [49, 50], [51, 53], [54, 58], [59, 61], [62, 72], [73, 85], [86, 88], [89, 99], [100, 112], [113, 115], [116, 121], [122, 126], [127, 129], [130, 137], [137, 138], [139, 144], [145, 153], [154, 157], [158, 162], [162, 163], [163, 170], [171, 175], [175, 176]]}
{"doc_key": "ai-test-366", "ner": [[25, 27, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "not", "only", "alters", "the", "outcome", "of", "all", "subsequent", "tests", "of", "the", "retained", "explanatory", "model", ",", "but", "can", "also", "lead", "to", "biases", "and", "alter", "the", "mean", "square", "error", "of", "the", "estimate", "."], "sentence-detokenized": "This not only alters the outcome of all subsequent tests of the retained explanatory model, but can also lead to biases and alter the mean square error of the estimate.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 20], [21, 24], [25, 32], [33, 35], [36, 39], [40, 50], [51, 56], [57, 59], [60, 63], [64, 72], [73, 84], [85, 90], [90, 91], [92, 95], [96, 99], [100, 104], [105, 109], [110, 112], [113, 119], [120, 123], [124, 129], [130, 133], [134, 138], [139, 145], [146, 151], [152, 154], [155, 158], [159, 167], [167, 168]]}
{"doc_key": "ai-test-367", "ner": [[0, 0, "misc"], [9, 10, "task"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Bigrams", "are", "used", "in", "most", "successful", "language", "models", "for", "speech", "recognition", "."], "sentence-detokenized": "Bigrams are used in most successful language models for speech recognition.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 24], [25, 35], [36, 44], [45, 51], [52, 55], [56, 62], [63, 74], [74, 75]]}
{"doc_key": "ai-test-368", "ner": [[3, 4, "field"], [9, 11, "misc"], [17, 19, "misc"], [25, 27, "organisation"], [30, 32, "misc"], [38, 41, "organisation"], [44, 46, "misc"], [52, 56, "organisation"], [59, 61, "misc"], [67, 69, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[9, 11, 3, 4, "topic", "", false, false], [17, 19, 25, 27, "origin", "", false, false], [30, 32, 38, 41, "origin", "", false, false], [44, 46, 52, 56, "origin", "", false, false], [59, 61, 67, 69, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["His", "research", "in", "cognitive", "psychology", "has", "been", "awarded", "the", "Early", "Career", "Award", "(", "1984", ")", "and", "the", "Boyd", "McCandless", "Award", "(", "1986", ")", "from", "the", "American", "Psychological", "Association", ",", "the", "Troland", "Research", "Award", "(", "1993", ")", "from", "the", "National", "Academy", "of", "Sciences", ",", "the", "Henry", "Dale", "Prize", "(", "2004", ")", "from", "the", "Royal", "Institution", "of", "Great", "Britain", "and", "the", "George", "Miller", "Prize", "(", "2010", ")", "from", "the", "Cognitive", "Neuroscience", "Society", "."], "sentence-detokenized": "His research in cognitive psychology has been awarded the Early Career Award (1984) and the Boyd McCandless Award (1986) from the American Psychological Association, the Troland Research Award (1993) from the National Academy of Sciences, the Henry Dale Prize (2004) from the Royal Institution of Great Britain and the George Miller Prize (2010) from the Cognitive Neuroscience Society.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 25], [26, 36], [37, 40], [41, 45], [46, 53], [54, 57], [58, 63], [64, 70], [71, 76], [77, 78], [78, 82], [82, 83], [84, 87], [88, 91], [92, 96], [97, 107], [108, 113], [114, 115], [115, 119], [119, 120], [121, 125], [126, 129], [130, 138], [139, 152], [153, 164], [164, 165], [166, 169], [170, 177], [178, 186], [187, 192], [193, 194], [194, 198], [198, 199], [200, 204], [205, 208], [209, 217], [218, 225], [226, 228], [229, 237], [237, 238], [239, 242], [243, 248], [249, 253], [254, 259], [260, 261], [261, 265], [265, 266], [267, 271], [272, 275], [276, 281], [282, 293], [294, 296], [297, 302], [303, 310], [311, 314], [315, 318], [319, 325], [326, 332], [333, 338], [339, 340], [340, 344], [344, 345], [346, 350], [351, 354], [355, 364], [365, 377], [378, 385], [385, 386]]}
{"doc_key": "ai-test-369", "ner": [[1, 1, "misc"], [7, 7, "misc"], [9, 11, "product"], [15, 15, "researcher"], [17, 17, "researcher"], [24, 25, "researcher"], [27, 28, "researcher"], [30, 31, "task"], [33, 36, "researcher"], [38, 42, "researcher"], [43, 44, "task"], [46, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[1, 1, 7, 7, "named", "", false, false], [1, 1, 46, 46, "named", "", false, false], [7, 7, 15, 15, "origin", "", false, false], [7, 7, 17, 17, "origin", "", false, false], [7, 7, 30, 31, "related-to", "used_for", false, false], [9, 11, 7, 7, "usage", "", false, false], [9, 11, 43, 44, "named", "", false, false], [24, 25, 7, 7, "usage", "", false, false], [24, 25, 33, 36, "named", "same", false, false], [27, 28, 7, 7, "usage", "", false, false], [27, 28, 38, 42, "named", "same", false, false], [43, 44, 46, 46, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["An", "eigenface", "(", "the", "method", "of", "using", "eigenfaces", "for", "face", "recognition", "systems", "was", "developed", "by", "Sirovich", "and", "Kirby", "(", "1987", ")", "and", "used", "by", "Matthew", "Turk", "and", "Alex", "Pentland", "in", "face", "classification", ".", "Turk", ",", "Matthew", "A.", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "An eigenface (the method of using eigenfaces for face recognition systems was developed by Sirovich and Kirby (1987) and used by Matthew Turk and Alex Pentland in face classification. Turk, Matthew A. and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 2], [3, 12], [13, 14], [14, 17], [18, 24], [25, 27], [28, 33], [34, 44], [45, 48], [49, 53], [54, 65], [66, 73], [74, 77], [78, 87], [88, 90], [91, 99], [100, 103], [104, 109], [110, 111], [111, 115], [115, 116], [117, 120], [121, 125], [126, 128], [129, 136], [137, 141], [142, 145], [146, 150], [151, 159], [160, 162], [163, 167], [168, 182], [182, 183], [184, 188], [188, 189], [190, 197], [198, 200], [201, 204], [205, 213], [213, 214], [215, 219], [220, 221], [221, 222], [223, 227], [228, 239], [240, 245], [246, 256], [256, 257]]}
{"doc_key": "ai-test-370", "ner": [[5, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "lexical", "dictionary", "such", "as", "Word", "Net", "can", "then", "be", "used", "to", "understand", "the", "context", "."], "sentence-detokenized": "A lexical dictionary such as WordNet can then be used to understand the context.", "token2charspan": [[0, 1], [2, 9], [10, 20], [21, 25], [26, 28], [29, 33], [33, 36], [37, 40], [41, 45], [46, 48], [49, 53], [54, 56], [57, 67], [68, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-test-371", "ner": [[0, 2, "misc"], [8, 8, "misc"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 8, 8, "part-of", "", false, false], [8, 8, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hyponymy", "is", "the", "most", "frequently", "coded", "relation", "between", "synsets", "used", "in", "lexical", "databases", "such", "as", "WordNet", "."], "sentence-detokenized": "Hyponymy is the most frequently coded relation between synsets used in lexical databases such as WordNet.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 20], [21, 31], [32, 37], [38, 46], [47, 54], [55, 62], [63, 67], [68, 70], [71, 78], [79, 88], [89, 93], [94, 96], [97, 104], [104, 105]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [6, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 7, "general-affiliation", "", false, false], [0, 0, 9, 9, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "offers", "open", "source", "libraries", "in", "C", "+++", "and", "Java", ",", "but", "many", "clients", "rely", "on", "community", "-", "developed", "libraries", ",", "such", "as", "libraries", "with", "built", "-", "in", "functions", "to", "retrieve", "data", "(", "array", "-", "style", ")", "from", "DAP", "servers", "."], "sentence-detokenized": "OPeNDAP offers open source libraries in C+++ and Java, but many clients rely on community-developed libraries, such as libraries with built-in functions to retrieve data (array-style) from DAP servers.", "token2charspan": [[0, 7], [8, 14], [15, 19], [20, 26], [27, 36], [37, 39], [40, 41], [41, 44], [45, 48], [49, 53], [53, 54], [55, 58], [59, 63], [64, 71], [72, 76], [77, 79], [80, 89], [89, 90], [90, 99], [100, 109], [109, 110], [111, 115], [116, 118], [119, 128], [129, 133], [134, 139], [139, 140], [140, 142], [143, 152], [153, 155], [156, 164], [165, 169], [170, 171], [171, 176], [176, 177], [177, 182], [182, 183], [184, 188], [189, 192], [193, 200], [200, 201]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [7, 8, "product"], [13, 14, "country"], [30, 31, "misc"], [44, 45, "organisation"], [46, 46, "product"], [48, 49, "organisation"], [50, 53, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 13, 14, "opposite", "", false, false], [7, 8, 13, 14, "artifact", "", false, false], [30, 31, 7, 8, "part-of", "", false, false], [46, 46, 44, 45, "artifact", "", false, false], [50, 53, 48, 49, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "that", "page", ",", "Samurai", "Damashii", "exaggerated", "the", "Senkousha", "as", "a", "crystallization", "of", "China", "'s", "four", "thousand", "years", "of", "scientific", "knowledge", ",", "commented", "on", "the", "crude", "design", "(", "e.g.", "the", "Chinese", "cannon", "in", "the", "crotch", ")", "and", "placed", "it", "s", "image", "among", "images", "of", "Honda", "'s", "ASIMO", "and", "Sony", "'s", "QRIO", "SDR", "-", "3X", "to", "get", "a", "comparative", "picture", "."], "sentence-detokenized": "On that page, Samurai Damashii exaggerated the Senkousha as a crystallization of China's four thousand years of scientific knowledge, commented on the crude design (e.g. the Chinese cannon in the crotch) and placed its image among images of Honda's ASIMO and Sony's QRIO SDR-3X to get a comparative picture.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 21], [22, 30], [31, 42], [43, 46], [47, 56], [57, 59], [60, 61], [62, 77], [78, 80], [81, 86], [86, 88], [89, 93], [94, 102], [103, 108], [109, 111], [112, 122], [123, 132], [132, 133], [134, 143], [144, 146], [147, 150], [151, 156], [157, 163], [164, 165], [165, 169], [170, 173], [174, 181], [182, 188], [189, 191], [192, 195], [196, 202], [202, 203], [204, 207], [208, 214], [215, 217], [217, 218], [219, 224], [225, 230], [231, 237], [238, 240], [241, 246], [246, 248], [249, 254], [255, 258], [259, 263], [263, 265], [266, 270], [271, 274], [274, 275], [275, 277], [278, 280], [281, 284], [285, 286], [287, 298], [299, 306], [306, 307]]}
{"doc_key": "ai-test-374", "ner": [[8, 9, "algorithm"], [20, 20, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 20, 20, "part-of", "includes_functionality_of", false, false], [8, 9, 22, 22, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "also", "many", "programming", "libraries", "that", "contain", "neural", "network", "functionality", "and", "can", "be", "used", "in", "custom", "implementations", "(", "e.g.", "TensorFlow", ",", "Theano", ",", "etc.", ")", "."], "sentence-detokenized": "There are also many programming libraries that contain neural network functionality and can be used in custom implementations (e.g. TensorFlow, Theano, etc.).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 31], [32, 41], [42, 46], [47, 54], [55, 61], [62, 69], [70, 83], [84, 87], [88, 91], [92, 94], [95, 99], [100, 102], [103, 109], [110, 125], [126, 127], [127, 131], [132, 142], [142, 143], [144, 150], [150, 151], [152, 156], [156, 157], [157, 158]]}
{"doc_key": "ai-test-375", "ner": [[6, 9, "conference"], [11, 11, "organisation"], [13, 19, "conference"], [21, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", "and", "SPIE", "."], "sentence-detokenized": "He is a member of the Association for Computing Machinery, IEEE, American Association for the Advancement of Science, IAPR and SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 33], [34, 37], [38, 47], [48, 57], [57, 58], [59, 63], [63, 64], [65, 73], [74, 85], [86, 89], [90, 93], [94, 105], [106, 108], [109, 116], [116, 117], [118, 122], [123, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-376", "ner": [[2, 2, "organisation"], [7, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 7, 9, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "2011", "RET", "trial", "using", "cameras", "with", "facial", "recognition", "systems", "mounted", "on", "trams", "ensured", "that", "people", "banned", "from", "the", "trams", "did", "n't", "sneak", "in", "anyway", "."], "sentence-detokenized": "A 2011 RET trial using cameras with facial recognition systems mounted on trams ensured that people banned from the trams didn't sneak in anyway.", "token2charspan": [[0, 1], [2, 6], [7, 10], [11, 16], [17, 22], [23, 30], [31, 35], [36, 42], [43, 54], [55, 62], [63, 70], [71, 73], [74, 79], [80, 87], [88, 92], [93, 99], [100, 106], [107, 111], [112, 115], [116, 121], [122, 125], [125, 128], [129, 134], [135, 137], [138, 144], [144, 145]]}
{"doc_key": "ai-test-377", "ner": [[4, 4, "person"], [6, 6, "organisation"], [15, 16, "person"], [18, 19, "person"], [22, 23, "person"], [25, 26, "person"], [28, 29, "person"], [31, 32, "person"], [34, 35, "person"], [37, 38, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[4, 4, 6, 6, "role", "works_for", false, false], [15, 16, 6, 6, "role", "works_for", false, false], [18, 19, 6, 6, "role", "works_for", false, false], [22, 23, 6, 6, "role", "works_for", false, false], [25, 26, 6, 6, "role", "works_for", false, false], [28, 29, 6, 6, "role", "works_for", false, false], [31, 32, 6, 6, "role", "works_for", false, false], [34, 35, 6, 6, "role", "works_for", false, false], [37, 38, 6, 6, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Adapted", "from", "the", "popular", "Cole", "Porter", "Broadway", "musical", ",", "the", "film", "starred", "MGM", "songbird", "couple", "Howard", "Keel", "and", "Kathryn", "Grayson", ",", "with", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "and", "Tommy", "Rall", "in", "supporting", "roles", "."], "sentence-detokenized": "Adapted from the popular Cole Porter Broadway musical, the film starred MGM songbird couple Howard Keel and Kathryn Grayson, with Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar and Tommy Rall in supporting roles.", "token2charspan": [[0, 7], [8, 12], [13, 16], [17, 24], [25, 29], [30, 36], [37, 45], [46, 53], [53, 54], [55, 58], [59, 63], [64, 71], [72, 75], [76, 84], [85, 91], [92, 98], [99, 103], [104, 107], [108, 115], [116, 123], [123, 124], [125, 129], [130, 133], [134, 140], [140, 141], [142, 148], [149, 153], [153, 154], [155, 160], [161, 164], [164, 165], [166, 171], [172, 180], [180, 181], [182, 186], [187, 194], [195, 198], [199, 204], [205, 209], [210, 212], [213, 223], [224, 229], [229, 230]]}
{"doc_key": "ai-test-378", "ner": [[22, 28, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "applications", "should", "streamline", "the", "call", "flow", ",", "minimise", "the", "number", "of", "calls", ",", "eliminate", "unnecessary", "repetitions", "and", "allow", "for", "an", "elaborate", "mixed", "-initiative", "dialogue", "system", ",", "enabling", "the", "caller", "to", "provide", "several", "different", "pieces", "of", "information", "in", "a", "single", "statement", "and", "in", "any", "order", "or", "combination", "."], "sentence-detokenized": "Such applications should streamline the call flow, minimise the number of calls, eliminate unnecessary repetitions and allow for an elaborate mixed-initiative dialogue system, enabling the caller to provide several different pieces of information in a single statement and in any order or combination.", "token2charspan": [[0, 4], [5, 17], [18, 24], [25, 35], [36, 39], [40, 44], [45, 49], [49, 50], [51, 59], [60, 63], [64, 70], [71, 73], [74, 79], [79, 80], [81, 90], [91, 102], [103, 114], [115, 118], [119, 124], [125, 128], [129, 131], [132, 141], [142, 147], [147, 158], [159, 167], [168, 174], [174, 175], [176, 184], [185, 188], [189, 195], [196, 198], [199, 206], [207, 214], [215, 224], [225, 231], [232, 234], [235, 246], [247, 249], [250, 251], [252, 258], [259, 268], [269, 272], [273, 275], [276, 279], [280, 285], [286, 288], [289, 300], [300, 301]]}
{"doc_key": "ai-test-379", "ner": [[3, 4, "algorithm"], [7, 9, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 3, 4, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Traditional", "methods", "of", "gradient", "descent", "(", "or", "stochastic", "gradient", "descent", ")", "can", "be", "adapted", ",", "where", "instead", "of", "taking", "a", "step", "in", "the", "direction", "of", "the", "function", "'s", "gradient", ",", "one", "takes", "a", "step", "in", "the", "direction", "of", "a", "vector", "chosen", "from", "the", "function", "'s", "subgradient", "."], "sentence-detokenized": "Traditional methods of gradient descent (or stochastic gradient descent) can be adapted, where instead of taking a step in the direction of the function's gradient, one takes a step in the direction of a vector chosen from the function's subgradient.", "token2charspan": [[0, 11], [12, 19], [20, 22], [23, 31], [32, 39], [40, 41], [41, 43], [44, 54], [55, 63], [64, 71], [71, 72], [73, 76], [77, 79], [80, 87], [87, 88], [89, 94], [95, 102], [103, 105], [106, 112], [113, 114], [115, 119], [120, 122], [123, 126], [127, 136], [137, 139], [140, 143], [144, 152], [152, 154], [155, 163], [163, 164], [165, 168], [169, 174], [175, 176], [177, 181], [182, 184], [185, 188], [189, 198], [199, 201], [202, 203], [204, 210], [211, 217], [218, 222], [223, 226], [227, 235], [235, 237], [238, 249], [249, 250]]}
{"doc_key": "ai-test-380", "ner": [[8, 10, "metrics"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Assuming", "that", "the", "distortion", "is", "measured", "by", "the", "mean", "square", "error", ",", "the", "distortion", "D", "is", "given", "by", "the", "following", "formula", ":"], "sentence-detokenized": "Assuming that the distortion is measured by the mean square error, the distortion D is given by the following formula:", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 28], [29, 31], [32, 40], [41, 43], [44, 47], [48, 52], [53, 59], [60, 65], [65, 66], [67, 70], [71, 81], [82, 83], [84, 86], [87, 92], [93, 95], [96, 99], [100, 109], [110, 117], [117, 118]]}
{"doc_key": "ai-test-381", "ner": [[0, 0, "algorithm"], [4, 5, "field"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [27, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 5, "part-of", "", false, false], [17, 18, 0, 0, "part-of", "", false, false], [20, 21, 0, 0, "part-of", "", false, false], [23, 24, 0, 0, "part-of", "", false, false], [27, 28, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["MLP", "was", "a", "popular", "machine", "learning", "solution", "in", "the", "1980s", ",", "used", "in", "various", "fields", "such", "as", "speech", "recognition", ",", "image", "recognition", "and", "machine", "translation", "software", ",", "neural", "networks", "."], "sentence-detokenized": "MLP was a popular machine learning solution in the 1980s, used in various fields such as speech recognition, image recognition and machine translation software, neural networks.", "token2charspan": [[0, 3], [4, 7], [8, 9], [10, 17], [18, 25], [26, 34], [35, 43], [44, 46], [47, 50], [51, 56], [56, 57], [58, 62], [63, 65], [66, 73], [74, 80], [81, 85], [86, 88], [89, 95], [96, 107], [107, 108], [109, 114], [115, 126], [127, 130], [131, 138], [139, 150], [151, 159], [159, 160], [161, 167], [168, 176], [176, 177]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [1, 4, "misc"], [8, 10, "university"], [15, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 8, 10, "physical", "", false, false], [0, 0, 8, 10, "role", "", false, false], [1, 4, 0, 0, "origin", "", false, false], [15, 17, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "received", "his", "PhD", "in", "1979", "from", "the", "University", "of", "Toronto", "under", "the", "supervision", "of", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen received his PhD in 1979 from the University of Toronto under the supervision of C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 22], [23, 25], [26, 30], [31, 35], [36, 39], [40, 50], [51, 53], [54, 61], [62, 67], [68, 71], [72, 83], [84, 86], [87, 89], [90, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [5, 7, "field"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[0, 0, 5, 7, "related-to", "supports", false, false], [10, 10, 5, 7, "type-of", "", true, false], [12, 12, 5, 7, "type-of", "", true, false], [14, 14, 5, 7, "type-of", "", true, false], [24, 24, 5, 7, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5], "sentence": ["OpenCV", "supports", "some", "models", "from", "deep", "learning", "frameworks", "such", "as", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "after", "conversion", "to", "an", "ONNX", "model", ")", "and", "Caffe", "according", "to", "a", "defined", "list", "of", "supported", "layers", "."], "sentence-detokenized": "OpenCV supports some models from deep learning frameworks such as TensorFlow, Torch, PyTorch (after conversion to an ONNX model) and Caffe according to a defined list of supported layers.", "token2charspan": [[0, 6], [7, 15], [16, 20], [21, 27], [28, 32], [33, 37], [38, 46], [47, 57], [58, 62], [63, 65], [66, 76], [76, 77], [78, 83], [83, 84], [85, 92], [93, 94], [94, 99], [100, 110], [111, 113], [114, 116], [117, 121], [122, 127], [127, 128], [129, 132], [133, 138], [139, 148], [149, 151], [152, 153], [154, 161], [162, 166], [167, 169], [170, 179], [180, 186], [186, 187]]}
{"doc_key": "ai-test-384", "ner": [[2, 2, "researcher"], [8, 11, "organisation"], [13, 13, "organisation"], [17, 21, "organisation"], [25, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 8, 11, "role", "", false, false], [2, 2, 17, 21, "role", "", false, false], [2, 2, 25, 25, "related-to", "lectures_in", false, false], [13, 13, 8, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Previously", ",", "Christensen", "was", "founding", "chairman", "of", "the", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "and", "an", "IEEE", "Robotics", "and", "Automation", "Society", "Distinguished", "Lecturer", "in", "Robotics", "."], "sentence-detokenized": "Previously, Christensen was founding chairman of the European Robotics Research Network (EURON) and an IEEE Robotics and Automation Society Distinguished Lecturer in Robotics.", "token2charspan": [[0, 10], [10, 11], [12, 23], [24, 27], [28, 36], [37, 45], [46, 48], [49, 52], [53, 61], [62, 70], [71, 79], [80, 87], [88, 89], [89, 94], [94, 95], [96, 99], [100, 102], [103, 107], [108, 116], [117, 120], [121, 131], [132, 139], [140, 153], [154, 162], [163, 165], [166, 174], [174, 175]]}
{"doc_key": "ai-test-385", "ner": [[7, 7, "field"], [9, 11, "university"], [13, 13, "location"], [15, 18, "country"], [23, 23, "misc"], [25, 25, "field"], [28, 31, "organisation"], [33, 33, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 11, 13, 13, "physical", "", false, false], [13, 13, 15, 18, "physical", "", false, false], [23, 23, 25, 25, "topic", "", false, false], [28, 31, 33, 33, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "received", "his", "master", "'s", "degree", "in", "mathematics", "from", "Samarkand", "State", "University", "in", "Samarkand", ",", "Uzbek", "Soviet", "Socialist", "Republic", "in", "1958", "and", "a", "doctorate", "in", "statistics", "from", "the", "Institute", "of", "Control", "Sciences", "in", "Moscow", "in", "1964", "."], "sentence-detokenized": "He received his master's degree in mathematics from Samarkand State University in Samarkand, Uzbek Soviet Socialist Republic in 1958 and a doctorate in statistics from the Institute of Control Sciences in Moscow in 1964.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 22], [22, 24], [25, 31], [32, 34], [35, 46], [47, 51], [52, 61], [62, 67], [68, 78], [79, 81], [82, 91], [91, 92], [93, 98], [99, 105], [106, 115], [116, 124], [125, 127], [128, 132], [133, 136], [137, 138], [139, 148], [149, 151], [152, 162], [163, 167], [168, 171], [172, 181], [182, 184], [185, 192], [193, 201], [202, 204], [205, 211], [212, 214], [215, 219], [219, 220]]}
{"doc_key": "ai-test-386", "ner": [[7, 7, "organisation"], [11, 13, "product"], [34, 35, "field"], [37, 39, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 34, 35, "usage", "", false, false], [7, 7, 37, 39, "usage", "", false, false], [11, 13, 7, 7, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Increasingly", ",", "however", ",", "the", "work", "at", "Cycorp", "is", "about", "giving", "the", "Cyc", "system", "the", "ability", "to", "communicate", "with", "end-users", "in", "natural", "language", "and", "to", "assist", "in", "the", "ongoing", "process", "of", "knowledge", "creation", "through", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "Increasingly, however, the work at Cycorp is about giving the Cyc system the ability to communicate with end-users in natural language and to assist in the ongoing process of knowledge creation through machine learning and natural language understanding.", "token2charspan": [[0, 12], [12, 13], [14, 21], [21, 22], [23, 26], [27, 31], [32, 34], [35, 41], [42, 44], [45, 50], [51, 57], [58, 61], [62, 65], [66, 72], [73, 76], [77, 84], [85, 87], [88, 99], [100, 104], [105, 114], [115, 117], [118, 125], [126, 134], [135, 138], [139, 141], [142, 148], [149, 151], [152, 155], [156, 163], [164, 171], [172, 174], [175, 184], [185, 193], [194, 201], [202, 209], [210, 218], [219, 222], [223, 230], [231, 239], [240, 253], [253, 254]]}
{"doc_key": "ai-test-387", "ner": [[54, 54, "metrics"], [56, 56, "metrics"], [58, 58, "metrics"], [60, 61, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "if", "the", "most", "appropriate", "classifier", "for", "the", "problem", "is", "sought", ",", "the", "training", "dataset", "is", "used", "to", "train", "the", "candidate", "algorithms", ",", "the", "validation", "dataset", "is", "used", "to", "compare", "their", "performance", "and", "decide", "which", "one", "to", "use", ",", "and", "finally", "the", "test", "dataset", "is", "used", "to", "obtain", "performance", "properties", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", ",", "F-", "measure", "and", "so", "on", "."], "sentence-detokenized": "For example, if the most appropriate classifier for the problem is sought, the training dataset is used to train the candidate algorithms, the validation dataset is used to compare their performance and decide which one to use, and finally the test dataset is used to obtain performance properties such as accuracy, sensitivity, specificity, F-measure and so on.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 19], [20, 24], [25, 36], [37, 47], [48, 51], [52, 55], [56, 63], [64, 66], [67, 73], [73, 74], [75, 78], [79, 87], [88, 95], [96, 98], [99, 103], [104, 106], [107, 112], [113, 116], [117, 126], [127, 137], [137, 138], [139, 142], [143, 153], [154, 161], [162, 164], [165, 169], [170, 172], [173, 180], [181, 186], [187, 198], [199, 202], [203, 209], [210, 215], [216, 219], [220, 222], [223, 226], [226, 227], [228, 231], [232, 239], [240, 243], [244, 248], [249, 256], [257, 259], [260, 264], [265, 267], [268, 274], [275, 286], [287, 297], [298, 302], [303, 305], [306, 314], [314, 315], [316, 327], [327, 328], [329, 340], [340, 341], [342, 344], [344, 351], [352, 355], [356, 358], [359, 361], [361, 362]]}
{"doc_key": "ai-test-388", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "square", "error", "is", "0.15", "."], "sentence-detokenized": "The mean square error is 0.15.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 21], [22, 24], [25, 29], [29, 30]]}
{"doc_key": "ai-test-389", "ner": [[7, 11, "misc"], [4, 4, "organisation"], [15, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 7, 11, "role", "", false, false], [15, 15, 7, 11, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1979", ",", "the", "IEEE", "organised", "a", "competition", "on", "micromusks", ",", "which", "was", "presented", "in", "Spectrum", "magazine", "."], "sentence-detokenized": "In 1979, the IEEE organised a competition on micromusks, which was presented in Spectrum magazine.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 27], [28, 29], [30, 41], [42, 44], [45, 55], [55, 56], [57, 62], [63, 66], [67, 76], [77, 79], [80, 88], [89, 97], [97, 98]]}
{"doc_key": "ai-test-390", "ner": [[0, 1, "algorithm"], [11, 13, "task"], [15, 16, "task"], [18, 19, "task"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Gabor", "space", "is", "very", "useful", "in", "image", "processing", "applications", "such", "as", "optical", "character", "recognition", ",", "iris", "recognition", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "Gabor space is very useful in image processing applications such as optical character recognition, iris recognition and fingerprint recognition.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 19], [20, 26], [27, 29], [30, 35], [36, 46], [47, 59], [60, 64], [65, 67], [68, 75], [76, 85], [86, 97], [97, 98], [99, 103], [104, 115], [116, 119], [120, 131], [132, 143], [143, 144]]}
{"doc_key": "ai-test-391", "ner": [[7, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "via", "high", "-", "level", "interfaces", "to", "Java", "and", "Tcl", "."], "sentence-detokenized": "or via high-level interfaces to Java and Tcl.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [12, 17], [18, 28], [29, 31], [32, 36], [37, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-test-392", "ner": [[21, 22, "field"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "recent", "research", ",", "kernel", "-", "based", "methods", "such", "as", "support", "vector", "machines", "have", "proven", "to", "be", "superior", "in", "terms", "of", "supervised", "information", "."], "sentence-detokenized": "In recent research, kernel-based methods such as support vector machines have proven to be superior in terms of supervised information.", "token2charspan": [[0, 2], [3, 9], [10, 18], [18, 19], [20, 26], [26, 27], [27, 32], [33, 40], [41, 45], [46, 48], [49, 56], [57, 63], [64, 72], [73, 77], [78, 84], [85, 87], [88, 90], [91, 99], [100, 102], [103, 108], [109, 111], [112, 122], [123, 134], [134, 135]]}
{"doc_key": "ai-test-393", "ner": [[14, 14, "misc"], [23, 23, "researcher"], [25, 25, "researcher"], [35, 35, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 35, 35, "usage", "", false, false], [25, 25, 35, 35, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "illustrate", "the", "basic", "principles", "of", "bagging", ",", "an", "analysis", "of", "the", "relationship", "between", "ozone", "and", "temperature", "is", "shown", "below", "(", "data", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "the", "analysis", "is", "done", "in", "R", ")", "."], "sentence-detokenized": "To illustrate the basic principles of bagging, an analysis of the relationship between ozone and temperature is shown below (data from Rousseeuw and Leroy (1986), the analysis is done in R).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 34], [35, 37], [38, 45], [45, 46], [47, 49], [50, 58], [59, 61], [62, 65], [66, 78], [79, 86], [87, 92], [93, 96], [97, 108], [109, 111], [112, 117], [118, 123], [124, 125], [125, 129], [130, 134], [135, 144], [145, 148], [149, 154], [155, 156], [156, 160], [160, 161], [161, 162], [163, 166], [167, 175], [176, 178], [179, 183], [184, 186], [187, 188], [188, 189], [189, 190]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [22, 24, "product"]], "ner_mapping_to_source": [0, 3], "relations": [[22, 24, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [2], "sentence": ["Denso", "Wave", "is", "a", "subsidiary", "that", "manufactures", "products", "for", "automatic", "identification", "(", "barcode", "readers", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "Denso Wave is a subsidiary that manufactures products for automatic identification (barcode readers and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 15], [16, 26], [27, 31], [32, 44], [45, 53], [54, 57], [58, 67], [68, 82], [83, 84], [84, 91], [92, 99], [100, 103], [104, 111], [112, 120], [120, 121], [121, 122], [123, 133], [134, 140], [141, 144], [145, 157], [158, 163], [164, 175], [175, 176]]}
{"doc_key": "ai-test-395", "ner": [[2, 4, "metrics"], [7, 9, "metrics"], [22, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 4, 22, 22, "compare", "", false, false], [7, 9, 2, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "the", "Bilingual", "evaluation", "understudy", "simply", "calculates", "the", "precision", "of", "each", "individual", "ngram", "and", "gives", "equal", "weight", "to", "each", "individual", "ngram", ",", "NIST", "also", "calculates", "how", "informative", "an", "individual", "ngram", "is", "."], "sentence-detokenized": "While the Bilingual evaluation understudy simply calculates the precision of each individual ngram and gives equal weight to each individual ngram, NIST also calculates how informative an individual ngram is.", "token2charspan": [[0, 5], [6, 9], [10, 19], [20, 30], [31, 41], [42, 48], [49, 59], [60, 63], [64, 73], [74, 76], [77, 81], [82, 92], [93, 98], [99, 102], [103, 108], [109, 114], [115, 121], [122, 124], [125, 129], [130, 140], [141, 146], [146, 147], [148, 152], [153, 157], [158, 168], [169, 172], [173, 184], [185, 187], [188, 198], [199, 204], [205, 207], [207, 208]]}
{"doc_key": "ai-test-396", "ner": [[15, 15, "algorithm"], [17, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "particular", ",", "they", "are", "used", "to", "calculate", "the", "probability", "of", "a", "tree", "(", "in", "Bayesian", "and", "maximum", "likelihood", "tree", "estimation", "methods", ")", "and", "to", "estimate", "the", "evolutionary", "distance", "between", "sequences", "from", "the", "observed", "differences", "between", "the", "sequences", "."], "sentence-detokenized": "In particular, they are used to calculate the probability of a tree (in Bayesian and maximum likelihood tree estimation methods) and to estimate the evolutionary distance between sequences from the observed differences between the sequences.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 45], [46, 57], [58, 60], [61, 62], [63, 67], [68, 69], [69, 71], [72, 80], [81, 84], [85, 92], [93, 103], [104, 108], [109, 119], [120, 127], [127, 128], [129, 132], [133, 135], [136, 144], [145, 148], [149, 161], [162, 170], [171, 178], [179, 188], [189, 193], [194, 197], [198, 206], [207, 218], [219, 226], [227, 230], [231, 240], [240, 241]]}
{"doc_key": "ai-test-397", "ner": [[0, 3, "conference"], [20, 21, "misc"], [23, 23, "misc"], [47, 48, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Audio", "Engineering", "Society", "recommends", "48", "kHz", "sampling", "rate", "for", "most", "applications", ",", "but", "gives", "credit", "to", "44.1", "kHz", "for", "Compact", "Disc", "(", "CD", ")", "and", "other", "consumer", "use", ",", "32", "kHz", "for", "transmission", "-", "related", "applications", ",", "and", "96", "kHz", "for", "higher", "bandwidth", "or", "to", "reduce", "anti-aliasing", "filter", "."], "sentence-detokenized": "The Audio Engineering Society recommends 48 kHz sampling rate for most applications, but gives credit to 44.1 kHz for Compact Disc (CD) and other consumer use, 32 kHz for transmission-related applications, and 96 kHz for higher bandwidth or to reduce anti-aliasing filter.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 40], [41, 43], [44, 47], [48, 56], [57, 61], [62, 65], [66, 70], [71, 83], [83, 84], [85, 88], [89, 94], [95, 101], [102, 104], [105, 109], [110, 113], [114, 117], [118, 125], [126, 130], [131, 132], [132, 134], [134, 135], [136, 139], [140, 145], [146, 154], [155, 158], [158, 159], [160, 162], [163, 166], [167, 170], [171, 183], [183, 184], [184, 191], [192, 204], [204, 205], [206, 209], [210, 212], [213, 216], [217, 220], [221, 227], [228, 237], [238, 240], [241, 243], [244, 250], [251, 264], [265, 271], [271, 272]]}
{"doc_key": "ai-test-398", "ner": [[11, 11, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Resources", "for", "affectivity", "of", "words", "and", "concepts", "have", "been", "made", "for", "WordNet", "{", "{", "cite", "journal"], "sentence-detokenized": "Resources for affectivity of words and concepts have been made for WordNet {{cite journal", "token2charspan": [[0, 9], [10, 13], [14, 25], [26, 28], [29, 34], [35, 38], [39, 47], [48, 52], [53, 57], [58, 62], [63, 66], [67, 74], [75, 76], [76, 77], [77, 81], [82, 89]]}
{"doc_key": "ai-test-399", "ner": [[6, 8, "misc"], [19, 20, "person"], [24, 27, "person"], [34, 36, "person"], [42, 45, "organisation"], [65, 66, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[24, 27, 34, 36, "role", "acts_in", false, false], [42, 45, 34, 36, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Three", "test", "reels", "were", "presented", "in", "red", "-green", "anaglyph", ",", "including", "scenes", "from", "the", "countryside", ",", "test", "images", "by", "Marie", "Doro", ",", "part", "of", "John", "B", ".", "Mason", "playing", "a", "number", "of", "episodes", "from", "Jim", "the", "Penman", "(", "a", "film", "released", "by", "Famous", "Players", "-", "Lasky", "in", "the", "same", "year", ",", "but", "not", "in", "3D", ")", ",", "oriental", "dancers", "and", "a", "reel", "of", "images", "from", "Niagara", "Falls", "."], "sentence-detokenized": "Three test reels were presented in red-green anaglyph, including scenes from the countryside, test images by Marie Doro, part of John B. Mason playing a number of episodes from Jim the Penman (a film released by Famous Players-Lasky in the same year, but not in 3D), oriental dancers and a reel of images from Niagara Falls.", "token2charspan": [[0, 5], [6, 10], [11, 16], [17, 21], [22, 31], [32, 34], [35, 38], [38, 44], [45, 53], [53, 54], [55, 64], [65, 71], [72, 76], [77, 80], [81, 92], [92, 93], [94, 98], [99, 105], [106, 108], [109, 114], [115, 119], [119, 120], [121, 125], [126, 128], [129, 133], [134, 135], [135, 136], [137, 142], [143, 150], [151, 152], [153, 159], [160, 162], [163, 171], [172, 176], [177, 180], [181, 184], [185, 191], [192, 193], [193, 194], [195, 199], [200, 208], [209, 211], [212, 218], [219, 226], [226, 227], [227, 232], [233, 235], [236, 239], [240, 244], [245, 249], [249, 250], [251, 254], [255, 258], [259, 261], [262, 264], [264, 265], [265, 266], [267, 275], [276, 283], [284, 287], [288, 289], [290, 294], [295, 297], [298, 304], [305, 309], [310, 317], [318, 323], [323, 324]]}
{"doc_key": "ai-test-400", "ner": [[7, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "special", "way", "of", "performing", "maximum", "likelihood", "estimation", "for", "this", "problem", "."], "sentence-detokenized": "This is a special way of performing maximum likelihood estimation for this problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 17], [18, 21], [22, 24], [25, 35], [36, 43], [44, 54], [55, 65], [66, 69], [70, 74], [75, 82], [82, 83]]}
{"doc_key": "ai-test-401", "ner": [[0, 4, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Crawler", "-", "friendly", "web", "servers", ",", "integrating", "the", "features", "of", "web", "site", "maps", "and", "RSS", "feeds", "into", "a", "decentralised", "mechanism", "for", "computational", "biologists", "and", "bioinformaticians", "to", "openly", "submit", "and", "retrieve", "metadata", "about", "biomedical", "resources", "."], "sentence-detokenized": "Crawler-friendly web servers, integrating the features of web site maps and RSS feeds into a decentralised mechanism for computational biologists and bioinformaticians to openly submit and retrieve metadata about biomedical resources.", "token2charspan": [[0, 7], [7, 8], [8, 16], [17, 20], [21, 28], [28, 29], [30, 41], [42, 45], [46, 54], [55, 57], [58, 61], [62, 66], [67, 71], [72, 75], [76, 79], [80, 85], [86, 90], [91, 92], [93, 106], [107, 116], [117, 120], [121, 134], [135, 145], [146, 149], [150, 167], [168, 170], [171, 177], [178, 184], [185, 188], [189, 197], [198, 206], [207, 212], [213, 223], [224, 233], [233, 234]]}
{"doc_key": "ai-test-402", "ner": [[4, 11, "misc"], [13, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "covered", "by", "American", "National", "Standards", "Institute", "/", "NISO", "standard", "Z39.50", "and", "International", "Organization", "for", "Standardization", "standard", "23950", "."], "sentence-detokenized": "It is covered by American National Standards Institute/NISO standard Z39.50 and International Organization for Standardization standard 23950.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 25], [26, 34], [35, 44], [45, 54], [54, 55], [55, 59], [60, 68], [69, 75], [76, 79], [80, 93], [94, 106], [107, 110], [111, 126], [127, 135], [136, 141], [141, 142]]}
{"doc_key": "ai-test-403", "ner": [[13, 16, "misc"], [21, 21, "metrics"], [24, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "encoder", "and", "decoder", "are", "trained", "to", "take", "a", "phrase", "and", "reproduce", "the", "single", "distribution", "of", "a", "corresponding", "paraphrase", "by", "minimizing", "perplexity", "using", "simple", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The encoder and decoder are trained to take a phrase and reproduce the single distribution of a corresponding paraphrase by minimizing perplexity using simple stochastic gradient descent.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 45], [46, 52], [53, 56], [57, 66], [67, 70], [71, 77], [78, 90], [91, 93], [94, 95], [96, 109], [110, 120], [121, 123], [124, 134], [135, 145], [146, 151], [152, 158], [159, 169], [170, 178], [179, 186], [186, 187]]}
{"doc_key": "ai-test-404", "ner": [[8, 10, "task"], [12, 17, "task"], [28, 31, "task"], [33, 39, "task"], [41, 47, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "typical", "applications", "of", "pattern", "recognition", "techniques", "are", "automatic", "speech", "recognition", ",", "classification", "of", "text", "into", "different", "categories", "(", "e.g.", "spam", "/", "non", "-spam", "in", "e-mails", ")", ",", "handwriting", "recognition", "on", "envelopes", ",", "automatic", "recognition", "of", "images", "of", "human", "faces", "or", "extraction", "of", "handwriting", "images", "from", "medical", "forms", "."], "sentence-detokenized": "Other typical applications of pattern recognition techniques are automatic speech recognition, classification of text into different categories (e.g. spam/non-spam in e-mails), handwriting recognition on envelopes, automatic recognition of images of human faces or extraction of handwriting images from medical forms.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 29], [30, 37], [38, 49], [50, 60], [61, 64], [65, 74], [75, 81], [82, 93], [93, 94], [95, 109], [110, 112], [113, 117], [118, 122], [123, 132], [133, 143], [144, 145], [145, 149], [150, 154], [154, 155], [155, 158], [158, 163], [164, 166], [167, 174], [174, 175], [175, 176], [177, 188], [189, 200], [201, 203], [204, 213], [213, 214], [215, 224], [225, 236], [237, 239], [240, 246], [247, 249], [250, 255], [256, 261], [262, 264], [265, 275], [276, 278], [279, 290], [291, 297], [298, 302], [303, 310], [311, 316], [316, 317]]}
{"doc_key": "ai-test-405", "ner": [[0, 2, "algorithm"], [13, 14, "field"], [16, 17, "task"], [19, 20, "task"], [22, 24, "task"], [26, 30, "task"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 14, 0, 2, "usage", "", false, false], [16, 17, 0, 2, "usage", "", false, false], [19, 20, 0, 2, "usage", "", false, false], [22, 24, 0, 2, "usage", "", false, false], [26, 30, 0, 2, "usage", "", false, false], [33, 34, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Artificial", "neural", "networks", "have", "been", "used", "for", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "board", "games", "and", "video", "games", ",", "and", "medical", "diagnostics", "."], "sentence-detokenized": "Artificial neural networks have been used for a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, board games and video games, and medical diagnostics.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 36], [37, 41], [42, 45], [46, 47], [48, 55], [56, 58], [59, 64], [64, 65], [66, 75], [76, 84], [85, 91], [91, 92], [93, 99], [100, 111], [111, 112], [113, 120], [121, 132], [132, 133], [134, 140], [141, 148], [149, 158], [158, 159], [160, 165], [166, 171], [172, 175], [176, 181], [182, 187], [187, 188], [189, 192], [193, 200], [201, 212], [212, 213]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [18, 18, "organisation"], [19, 20, "product"], [22, 22, "product"], [24, 26, "product"], [28, 28, "product"], [30, 30, "programlang"], [36, 37, "field"], [48, 48, "algorithm"], [50, 50, "algorithm"], [52, 52, "algorithm"], [56, 58, "product"], [64, 65, "task"], [70, 71, "algorithm"], [75, 75, "product"], [77, 77, "product"], [80, 82, "product"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [30, 30, 36, 37, "related-to", "used_for", false, false], [48, 48, 30, 30, "part-of", "", true, false], [50, 50, 30, 30, "part-of", "", true, false], [52, 52, 30, 30, "part-of", "", true, false], [56, 58, 64, 65, "related-to", "used_for", false, false], [70, 71, 56, 58, "part-of", "", false, false]], "relations_mapping_to_source": [0, 3, 4, 6, 8, 10, 11], "sentence": ["Examples", "include", "Salford", "Systems", "CART", "(", "which", "licensed", "the", "proprietary", "code", "from", "the", "original", "CART", "authors", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "-", "source", "statistical", "computing", "software", "that", "includes", "several", "CART", "implementations", ",", "such", "as", "the", "rpart", ",", "party", "and", "randomForest", "packages", ")", ",", "Weka", "(", "a", "free", "and", "open", "-", "source", "data", "mining", "package", "that", "includes", "many", "decision", "tree", "algorithms", ")", ",", "Orange", ",", "KNIME", ",", "the", "Microsoft", "SQL", "Server", "programming", "language", ")", "."], "sentence-detokenized": "Examples include Salford Systems CART (which licensed the proprietary code from the original CART authors), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open-source statistical computing software that includes several CART implementations, such as the rpart, party and randomForest packages), Weka (a free and open-source data mining package that includes many decision tree algorithms), Orange, KNIME, the Microsoft SQL Server programming language).", "token2charspan": [[0, 8], [9, 16], [17, 24], [25, 32], [33, 37], [38, 39], [39, 44], [45, 53], [54, 57], [58, 69], [70, 74], [75, 79], [80, 83], [84, 92], [93, 97], [98, 105], [105, 106], [106, 107], [108, 111], [112, 116], [117, 124], [124, 125], [126, 136], [136, 137], [138, 141], [142, 152], [153, 158], [158, 159], [160, 166], [166, 167], [168, 169], [170, 171], [171, 173], [174, 178], [178, 179], [179, 185], [186, 197], [198, 207], [208, 216], [217, 221], [222, 230], [231, 238], [239, 243], [244, 259], [259, 260], [261, 265], [266, 268], [269, 272], [273, 278], [278, 279], [280, 285], [286, 289], [290, 302], [303, 311], [311, 312], [312, 313], [314, 318], [319, 320], [320, 321], [322, 326], [327, 330], [331, 335], [335, 336], [336, 342], [343, 347], [348, 354], [355, 362], [363, 367], [368, 376], [377, 381], [382, 390], [391, 395], [396, 406], [406, 407], [407, 408], [409, 415], [415, 416], [417, 422], [422, 423], [424, 427], [428, 437], [438, 441], [442, 448], [449, 460], [461, 469], [469, 470], [470, 471]]}
{"doc_key": "ai-test-407", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "researcher"], [13, 14, "university"], [16, 17, "researcher"], [19, 22, "organisation"], [25, 25, "organisation"], [33, 35, "researcher"], [37, 39, "researcher"], [41, 44, "organisation"], [55, 59, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 10, 11, "origin", "", false, false], [0, 2, 16, 17, "origin", "", false, false], [0, 2, 33, 35, "origin", "", false, false], [0, 2, 37, 39, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [10, 11, 13, 14, "physical", "", false, false], [10, 11, 13, 14, "role", "", false, false], [16, 17, 19, 22, "physical", "", false, false], [16, 17, 19, 22, "role", "", false, false], [25, 25, 19, 22, "named", "", false, false], [33, 35, 41, 44, "physical", "", false, false], [33, 35, 41, 44, "role", "", false, false], [37, 39, 41, 44, "physical", "", false, false], [37, 39, 41, 44, "role", "", false, false], [55, 59, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", "was", "first", "developed", "by", "Fumitada", "Itakura", "at", "Nagoya", "University", "and", "Shuzo", "Saito", "at", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", "and", "then", "further", "developed", "by", "Bishnu", "S.", "Atal", "and", "Manfred", "R.", "Schroeder", "at", "Bell", "Labs", "in", "the", "early", "and", "mid-1970s", "and", "became", "the", "basis", "for", "the", "first", "DSP", "chips", "for", "speech", "synthesis", "in", "the", "late", "1970s", "."], "sentence-detokenized": "Linear predictive coding (LPC) was first developed by Fumitada Itakura at Nagoya University and Shuzo Saito at Nippon Telegraph and Telephone (NTT) in 1966 and then further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs in the early and mid-1970s and became the basis for the first DSP chips for speech synthesis in the late 1970s.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 40], [41, 50], [51, 53], [54, 62], [63, 70], [71, 73], [74, 80], [81, 91], [92, 95], [96, 101], [102, 107], [108, 110], [111, 117], [118, 127], [128, 131], [132, 141], [142, 143], [143, 146], [146, 147], [148, 150], [151, 155], [156, 159], [160, 164], [165, 172], [173, 182], [183, 185], [186, 192], [193, 195], [196, 200], [201, 204], [205, 212], [213, 215], [216, 225], [226, 228], [229, 233], [234, 238], [239, 241], [242, 245], [246, 251], [252, 255], [256, 265], [266, 269], [270, 276], [277, 280], [281, 286], [287, 290], [291, 294], [295, 300], [301, 304], [305, 310], [311, 314], [315, 321], [322, 331], [332, 334], [335, 338], [339, 343], [344, 349], [349, 350]]}
{"doc_key": "ai-test-408", "ner": [[1, 5, "metrics"], [8, 8, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 1, 5, "part-of", "", false, false], [10, 10, 1, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "F", "-", "value", "is", "a", "combination", "of", "precision", "and", "recall", ",", "giving", "a", "single", "value", "."], "sentence-detokenized": "An F-value is a combination of precision and recall, giving a single value.", "token2charspan": [[0, 2], [3, 4], [4, 5], [5, 10], [11, 13], [14, 15], [16, 27], [28, 30], [31, 40], [41, 44], [45, 51], [51, 52], [53, 59], [60, 61], [62, 68], [69, 74], [74, 75]]}
{"doc_key": "ai-test-409", "ner": [[0, 1, "field"], [7, 8, "task"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 0, 1, "part-of", "task_part_of_field", false, false], [14, 16, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Image", "analysis", "can", "be", "as", "simple", "as", "reading", "barcodes", "or", "as", "sophisticated", "as", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Image analysis can be as simple as reading barcodes or as sophisticated as a facial recognition system.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 21], [22, 24], [25, 31], [32, 34], [35, 42], [43, 51], [52, 54], [55, 57], [58, 71], [72, 74], [75, 76], [77, 83], [84, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-test-410", "ner": [[5, 7, "algorithm"], [26, 27, "algorithm"], [34, 36, "algorithm"], [40, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[34, 36, 26, 27, "type-of", "", false, false], [40, 40, 34, 36, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "special", "case", "of", "linear", "support", "vector", "machines", "can", "be", "solved", "more", "efficiently", "with", "the", "same", "type", "of", "algorithms", "that", "optimize", "it", "s", "close", "cousin", ",", "logistic", "regression", ";", "this", "class", "of", "algorithms", "includes", "stochastic", "gradient", "descent", "(", "e.g.", ",", "PEGASOS", ")", "."], "sentence-detokenized": "The special case of linear support vector machines can be solved more efficiently with the same type of algorithms that optimize its close cousin, logistic regression; this class of algorithms includes stochastic gradient descent (e.g., PEGASOS).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 34], [35, 41], [42, 50], [51, 54], [55, 57], [58, 64], [65, 69], [70, 81], [82, 86], [87, 90], [91, 95], [96, 100], [101, 103], [104, 114], [115, 119], [120, 128], [129, 131], [131, 132], [133, 138], [139, 145], [145, 146], [147, 155], [156, 166], [166, 167], [168, 172], [173, 178], [179, 181], [182, 192], [193, 201], [202, 212], [213, 221], [222, 229], [230, 231], [231, 235], [235, 236], [237, 244], [244, 245], [245, 246]]}
{"doc_key": "ai-test-411", "ner": [[1, 1, "product"], [25, 25, "product"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "Siri", "on", "an", "iOS", "device", "is", "asked", "Do", "you", "have", "a", "pet", ",", "one", "of", "the", "answers", "is", "that", "I", "used", "to", "have", "an", "AIBO", "."], "sentence-detokenized": "When Siri on an iOS device is asked Do you have a pet, one of the answers is that I used to have an AIBO.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 15], [16, 19], [20, 26], [27, 29], [30, 35], [36, 38], [39, 42], [43, 47], [48, 49], [50, 53], [53, 54], [55, 58], [59, 61], [62, 65], [66, 73], [74, 76], [77, 81], [82, 83], [84, 88], [89, 91], [92, 96], [97, 99], [100, 104], [104, 105]]}
{"doc_key": "ai-test-412", "ner": [[1, 2, "task"], [5, 8, "metrics"], [10, 10, "metrics"], [13, 13, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 8, 1, 2, "part-of", "", false, false], [10, 10, 5, 8, "named", "", false, false], [13, 13, 1, 2, "part-of", "", false, false], [16, 16, 13, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "information", "retrieval", ",", "the", "positive", "predictive", "value", "is", "called", "precision", "and", "the", "sensitivity", "is", "called", "recall", "."], "sentence-detokenized": "In information retrieval, the positive predictive value is called precision and the sensitivity is called recall.", "token2charspan": [[0, 2], [3, 14], [15, 24], [24, 25], [26, 29], [30, 38], [39, 49], [50, 55], [56, 58], [59, 65], [66, 75], [76, 79], [80, 83], [84, 95], [96, 98], [99, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-test-413", "ner": [[9, 10, "field"], [12, 12, "task"], [14, 14, "task"], [16, 17, "task"], [35, 36, "task"], [38, 39, "task"], [41, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 12, 9, 10, "part-of", "task_part_of_field", false, false], [14, 14, 9, 10, "part-of", "task_part_of_field", false, false], [16, 17, 9, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["His", "research", "focused", "in", "particular", "on", "areas", "such", "as", "text", "mining", "(", "extraction", ",", "categorisation", ",", "news", "detection", ")", "and", "on", "new", "theoretical", "frameworks", ",", "such", "as", "a", "unified", "utility", "-", "based", "theory", "that", "bridges", "information", "retrieval", ",", "automatic", "summarisation", ",", "free", "-", "text", "response", "and", "related", "tasks", "."], "sentence-detokenized": "His research focused in particular on areas such as text mining (extraction, categorisation, news detection) and on new theoretical frameworks, such as a unified utility-based theory that bridges information retrieval, automatic summarisation, free-text response and related tasks.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 23], [24, 34], [35, 37], [38, 43], [44, 48], [49, 51], [52, 56], [57, 63], [64, 65], [65, 75], [75, 76], [77, 91], [91, 92], [93, 97], [98, 107], [107, 108], [109, 112], [113, 115], [116, 119], [120, 131], [132, 142], [142, 143], [144, 148], [149, 151], [152, 153], [154, 161], [162, 169], [169, 170], [170, 175], [176, 182], [183, 187], [188, 195], [196, 207], [208, 217], [217, 218], [219, 228], [229, 242], [242, 243], [244, 248], [248, 249], [249, 253], [254, 262], [263, 266], [267, 274], [275, 280], [280, 281]]}
{"doc_key": "ai-test-414", "ner": [[6, 7, "product"], [14, 15, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Delta", "robots", "have", "base", "-", "mounted", "rotary", "actuators", "that", "move", "a", "lightweight", ",", "rigid", "parallelogram", "arm", "."], "sentence-detokenized": "Delta robots have base-mounted rotary actuators that move a lightweight, rigid parallelogram arm.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 22], [22, 23], [23, 30], [31, 37], [38, 47], [48, 52], [53, 57], [58, 59], [60, 71], [71, 72], [73, 78], [79, 92], [93, 96], [96, 97]]}
{"doc_key": "ai-test-415", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated in a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 76], [77, 83], [84, 86], [87, 94], [94, 95]]}
{"doc_key": "ai-test-416", "ner": [[29, 30, "task"], [36, 37, "task"], [42, 44, "task"], [46, 48, "task"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "actual", "data", "mining", "task", "is", "the", "semi-automatic", "or", "automatic", "analysis", "of", "large", "amounts", "of", "data", "to", "extract", "unknown", ",", "interesting", "patterns", ",", "e.g.", "groups", "of", "data", "records", "(", "cluster", "analysis", ")", ",", "unusual", "records", "(", "anomaly", "detection", ")", "and", "dependencies", "(", "association", "rule", "mining", ",", "sequential", "pattern", "mining", ")", "."], "sentence-detokenized": "The actual data mining task is the semi-automatic or automatic analysis of large amounts of data to extract unknown, interesting patterns, e.g. groups of data records (cluster analysis), unusual records (anomaly detection) and dependencies (association rule mining, sequential pattern mining).", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 22], [23, 27], [28, 30], [31, 34], [35, 49], [50, 52], [53, 62], [63, 71], [72, 74], [75, 80], [81, 88], [89, 91], [92, 96], [97, 99], [100, 107], [108, 115], [115, 116], [117, 128], [129, 137], [137, 138], [139, 143], [144, 150], [151, 153], [154, 158], [159, 166], [167, 168], [168, 175], [176, 184], [184, 185], [185, 186], [187, 194], [195, 202], [203, 204], [204, 211], [212, 221], [221, 222], [223, 226], [227, 239], [240, 241], [241, 252], [253, 257], [258, 264], [264, 265], [266, 276], [277, 284], [285, 291], [291, 292], [292, 293]]}
{"doc_key": "ai-test-417", "ner": [[2, 3, "product"], [5, 6, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 5, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "a", "recommendation", "system", ",", "sentiment", "analysis", "has", "proven", "to", "be", "a", "valuable", "technique", "."], "sentence-detokenized": "For a recommendation system, sentiment analysis has proven to be a valuable technique.", "token2charspan": [[0, 3], [4, 5], [6, 20], [21, 27], [27, 28], [29, 38], [39, 47], [48, 51], [52, 58], [59, 61], [62, 64], [65, 66], [67, 75], [76, 85], [85, 86]]}
{"doc_key": "ai-test-418", "ner": [[0, 1, "misc"], [30, 30, "organisation"], [34, 35, "location"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[30, 30, 34, 35, "physical", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["The", "Germans", "had", "accidentally", "chosen", "the", "Wotan", "system", "'s", "frequency", "very", "badly", ";", "it", "operated", "on", "45", "MHz", ",", "which", "happened", "to", "be", "the", "frequency", "of", "the", "powerful", "but", "dormant", "BBC", "television", "transmitter", "at", "Alexandra", "Palace", "."], "sentence-detokenized": "The Germans had accidentally chosen the Wotan system's frequency very badly; it operated on 45 MHz, which happened to be the frequency of the powerful but dormant BBC television transmitter at Alexandra Palace.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 28], [29, 35], [36, 39], [40, 45], [46, 52], [52, 54], [55, 64], [65, 69], [70, 75], [75, 76], [77, 79], [80, 88], [89, 91], [92, 94], [95, 98], [98, 99], [100, 105], [106, 114], [115, 117], [118, 120], [121, 124], [125, 134], [135, 137], [138, 141], [142, 150], [151, 154], [155, 162], [163, 166], [167, 177], [178, 189], [190, 192], [193, 202], [203, 209], [209, 210]]}
{"doc_key": "ai-test-419", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated in a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 76], [77, 83], [84, 86], [87, 94], [94, 95]]}
{"doc_key": "ai-test-420", "ner": [[1, 5, "misc"], [13, 13, "misc"], [16, 16, "product"], [18, 18, "product"], [20, 22, "product"], [31, 31, "misc"], [45, 47, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[16, 16, 13, 13, "usage", "", false, false], [18, 18, 13, 13, "usage", "", false, false], [20, 22, 18, 18, "named", "", false, false], [31, 31, 13, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "applications", "on", "the", "Semantic", "Web", ",", "and", "in", "relatively", "popular", "applications", "of", "RDF", "such", "as", "RSS", "and", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "resources", "tend", "to", "be", "represented", "by", "URIs", "that", "intentionally", "specify", "and", "can", "be", "used", "to", "access", "actual", "data", "on", "the", "World", "Wide", "Web", "."], "sentence-detokenized": "In applications on the Semantic Web, and in relatively popular applications of RDF such as RSS and FOAF (Friend a Friend), resources tend to be represented by URIs that intentionally specify and can be used to access actual data on the World Wide Web.", "token2charspan": [[0, 2], [3, 15], [16, 18], [19, 22], [23, 31], [32, 35], [35, 36], [37, 40], [41, 43], [44, 54], [55, 62], [63, 75], [76, 78], [79, 82], [83, 87], [88, 90], [91, 94], [95, 98], [99, 103], [104, 105], [105, 111], [112, 113], [114, 120], [120, 121], [121, 122], [123, 132], [133, 137], [138, 140], [141, 143], [144, 155], [156, 158], [159, 163], [164, 168], [169, 182], [183, 190], [191, 194], [195, 198], [199, 201], [202, 206], [207, 209], [210, 216], [217, 223], [224, 228], [229, 231], [232, 235], [236, 241], [242, 246], [247, 250], [250, 251]]}
{"doc_key": "ai-test-421", "ner": [[0, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "has", "studied", "this", "topic", "in", "detail", "."], "sentence-detokenized": "The Association for the Advancement of Artificial Intelligence has studied this topic in detail.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 74], [75, 79], [80, 85], [86, 88], [89, 95], [95, 96]]}
{"doc_key": "ai-test-422", "ner": [[0, 6, "product"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 20, 0, 6, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "speech", "system", "in", "the", "Apple", "Macintosh", "started", "as", "a", "curiosity", "and", "has", "evolved", "into", "a", "fully", "supported", "application", ",", "PlainTalk", ",", "for", "people", "with", "vision", "problems", "."], "sentence-detokenized": "The speech system in the Apple Macintosh started as a curiosity and has evolved into a fully supported application, PlainTalk, for people with vision problems.", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 20], [21, 24], [25, 30], [31, 40], [41, 48], [49, 51], [52, 53], [54, 63], [64, 67], [68, 71], [72, 79], [80, 84], [85, 86], [87, 92], [93, 102], [103, 114], [114, 115], [116, 125], [125, 126], [127, 130], [131, 137], [138, 142], [143, 149], [150, 158], [158, 159]]}
{"doc_key": "ai-test-423", "ner": [[5, 5, "field"], [7, 8, "task"], [10, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 5, 5, "part-of", "task_part_of_field", false, false], [10, 11, 5, 5, "part-of", "task_part_of_field", false, false], [13, 14, 5, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "uses", "of", "ontologies", "in", "NLP", "include", "information", "search", ",", "information", "retrieval", "and", "automatic", "summarization", "."], "sentence-detokenized": "Other uses of ontologies in NLP include information search, information retrieval and automatic summarization.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 24], [25, 27], [28, 31], [32, 39], [40, 51], [52, 58], [58, 59], [60, 71], [72, 81], [82, 85], [86, 95], [96, 109], [109, 110]]}
{"doc_key": "ai-test-424", "ner": [[7, 15, "organisation"], [18, 22, "organisation"], [25, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Institute", "has", "worked", "closely", "with", "the", "Janelia", "Farm", "Campus", "of", "the", "Howard", "Hughes", "Medical", "Institute", ",", "the", "Allen", "Institute", "for", "Brain", "Science", "and", "the", "National", "Institutes", "of", "Health", "to", "develop", "better", "methods", "for", "reconstructing", "neuronal", "architectures", "."], "sentence-detokenized": "The Institute has worked closely with the Janelia Farm Campus of the Howard Hughes Medical Institute, the Allen Institute for Brain Science and the National Institutes of Health to develop better methods for reconstructing neuronal architectures.", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 24], [25, 32], [33, 37], [38, 41], [42, 49], [50, 54], [55, 61], [62, 64], [65, 68], [69, 75], [76, 82], [83, 90], [91, 100], [100, 101], [102, 105], [106, 111], [112, 121], [122, 125], [126, 131], [132, 139], [140, 143], [144, 147], [148, 156], [157, 167], [168, 170], [171, 177], [178, 180], [181, 188], [189, 195], [196, 203], [204, 207], [208, 222], [223, 231], [232, 245], [245, 246]]}
{"doc_key": "ai-test-425", "ner": [[2, 4, "organisation"], [5, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 2, 4, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Recently", ",", "Google", "announced", "that", "Google", "Translate", "translates", "enough", "text", "to", "fill", "one", "million", "books", "in", "one", "day", "(", "2012", ")", "."], "sentence-detokenized": "Recently, Google announced that Google Translate translates enough text to fill one million books in one day (2012).", "token2charspan": [[0, 8], [8, 9], [10, 16], [17, 26], [27, 31], [32, 38], [39, 48], [49, 59], [60, 66], [67, 71], [72, 74], [75, 79], [80, 83], [84, 91], [92, 97], [98, 100], [101, 104], [105, 108], [109, 110], [110, 114], [114, 115], [115, 116]]}
{"doc_key": "ai-test-426", "ner": [[13, 13, "country"], [15, 15, "country"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"], [23, 24, "country"], [38, 39, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Events", "are", "held", "all", "over", "the", "world", "and", "are", "most", "popular", "in", "the", "UK", ",", "USA", ",", "Japan", ",", "Singapore", ",", "India", "and", "South", "Korea", "and", "are", "becoming", "increasingly", "popular", "in", "countries", "on", "the", "subcontinent", ",", "such", "as", "Sri", "Lanka", "."], "sentence-detokenized": "Events are held all over the world and are most popular in the UK, USA, Japan, Singapore, India and South Korea and are becoming increasingly popular in countries on the subcontinent, such as Sri Lanka.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 24], [25, 28], [29, 34], [35, 38], [39, 42], [43, 47], [48, 55], [56, 58], [59, 62], [63, 65], [65, 66], [67, 70], [70, 71], [72, 77], [77, 78], [79, 88], [88, 89], [90, 95], [96, 99], [100, 105], [106, 111], [112, 115], [116, 119], [120, 128], [129, 141], [142, 149], [150, 152], [153, 162], [163, 165], [166, 169], [170, 182], [182, 183], [184, 188], [189, 191], [192, 195], [196, 201], [201, 202]]}
{"doc_key": "ai-test-427", "ner": [[6, 6, "programlang"], [12, 12, "programlang"], [14, 14, "programlang"], [16, 17, "programlang"], [19, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "mainly", "developed", "in", "R", ",", "but", "sometimes", "also", "in", "Java", ",", "C", ",", "C", "++", "and", "Fortran", "."], "sentence-detokenized": "These packages are mainly developed in R, but sometimes also in Java, C, C++ and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 25], [26, 35], [36, 38], [39, 40], [40, 41], [42, 45], [46, 55], [56, 60], [61, 63], [64, 68], [68, 69], [70, 71], [71, 72], [73, 74], [74, 76], [77, 80], [81, 88], [88, 89]]}
{"doc_key": "ai-test-428", "ner": [[5, 16, "conference"], [3, 3, "conference"], [13, 13, "researcher"], [15, 15, "researcher"], [18, 19, "researcher"], [22, 23, "algorithm"], [28, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 5, 16, "named", "", false, false], [13, 13, 5, 16, "physical", "", false, false], [13, 13, 5, 16, "role", "", false, false], [13, 13, 18, 19, "role", "teams_up_with", false, false], [13, 13, 22, 23, "usage", "", false, false], [15, 15, 5, 16, "physical", "", false, false], [15, 15, 5, 16, "role", "", false, false], [15, 15, 18, 19, "role", "teams_up_with", false, false], [15, 15, 22, 23, "usage", "", false, false], [18, 19, 5, 16, "physical", "", false, false], [18, 19, 5, 16, "role", "", false, false], [18, 19, 22, 23, "usage", "", false, false], [22, 23, 28, 33, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["As", "part", "of", "ECCV", "(", "European", "Conference", "on", "Computer", "Vision", ")", "2006", ",", "Dalal", "and", "Triggs", "collaborated", "with", "Cordelia", "Schmid", "to", "apply", "HOG", "detectors", "to", "the", "problem", "of", "detecting", "people", "in", "films", "and", "videos", "."], "sentence-detokenized": "As part of ECCV (European Conference on Computer Vision) 2006, Dalal and Triggs collaborated with Cordelia Schmid to apply HOG detectors to the problem of detecting people in films and videos.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 15], [16, 17], [17, 25], [26, 36], [37, 39], [40, 48], [49, 55], [55, 56], [57, 61], [61, 62], [63, 68], [69, 72], [73, 79], [80, 92], [93, 97], [98, 106], [107, 113], [114, 116], [117, 122], [123, 126], [127, 136], [137, 139], [140, 143], [144, 151], [152, 154], [155, 164], [165, 171], [172, 174], [175, 180], [181, 184], [185, 191], [191, 192]]}
{"doc_key": "ai-test-429", "ner": [[3, 3, "metrics"], [5, 7, "metrics"], [11, 11, "task"], [18, 20, "metrics"], [22, 22, "metrics"], [28, 28, "metrics"], [31, 33, "metrics"], [35, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 3, 11, 11, "related-to", "measured_with", false, false], [5, 7, 11, 11, "related-to", "measured_with", false, false], [18, 20, 11, 11, "related-to", "measured_with", false, false], [22, 22, 18, 20, "named", "", false, false], [28, 28, 18, 20, "named", "", false, false], [35, 35, 31, 33, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "addition", "to", "sensitivity", "and", "specificity", ",", "the", "performance", "of", "a", "binary", "classification", "test", "can", "be", "measured", "by", "positive", "predictive", "value", "(", "PPV", ")", ",", "also", "known", "as", "precision", ",", "and", "negative", "predictive", "value", "(", "NPV", ")", "."], "sentence-detokenized": "In addition to sensitivity and specificity, the performance of a binary classification test can be measured by positive predictive value (PPV), also known as precision, and negative predictive value (NPV).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 42], [42, 43], [44, 47], [48, 59], [60, 62], [63, 64], [65, 71], [72, 86], [87, 91], [92, 95], [96, 98], [99, 107], [108, 110], [111, 119], [120, 130], [131, 136], [137, 138], [138, 141], [141, 142], [142, 143], [144, 148], [149, 154], [155, 157], [158, 167], [167, 168], [169, 172], [173, 181], [182, 192], [193, 198], [199, 200], [200, 203], [203, 204], [204, 205]]}
{"doc_key": "ai-test-430", "ner": [[13, 15, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "models", "can", "give", "partial", "credit", "for", "overlapping", "matches", "(", "e.g.", "using", "the", "Jaccard", "index", "criterion", ")", "."], "sentence-detokenized": "Such models can give partial credit for overlapping matches (e.g. using the Jaccard index criterion).", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 28], [29, 35], [36, 39], [40, 51], [52, 59], [60, 61], [61, 65], [66, 71], [72, 75], [76, 83], [84, 89], [90, 99], [99, 100], [100, 101]]}
{"doc_key": "ai-test-431", "ner": [[22, 27, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", ",", "for", "estimates", "based", "on", "a", "single", "sample", ",", "it", "highlights", "philosophical", "issues", "and", "possible", "misunderstandings", "in", "the", "use", "of", "maximum", "likelihood", "estimators", "and", "likelihood", "functions", "."], "sentence-detokenized": "In addition, for estimates based on a single sample, it highlights philosophical issues and possible misunderstandings in the use of maximum likelihood estimators and likelihood functions.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 16], [17, 26], [27, 32], [33, 35], [36, 37], [38, 44], [45, 51], [51, 52], [53, 55], [56, 66], [67, 80], [81, 87], [88, 91], [92, 100], [101, 118], [119, 121], [122, 125], [126, 129], [130, 132], [133, 140], [141, 151], [152, 162], [163, 166], [167, 177], [178, 187], [187, 188]]}
