{"doc_key": "ai-test-1", "ner": [[6, 8, "algorithm"], [10, 11, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "approaches", "to", "generative", "models", "include", "naive", "Bayes", "classifiers", ",", "Gaussian", "mixture", "models", ",", "variational", "autoencoders", "and", "others", "."], "sentence-detokenized": "Typical approaches to generative models include naive Bayes classifiers, Gaussian mixture models, variational autoencoders and others.", "token2charspan": [[0, 7], [8, 18], [19, 21], [22, 32], [33, 39], [40, 47], [48, 53], [54, 59], [60, 71], [71, 72], [73, 81], [82, 89], [90, 96], [96, 97], [98, 109], [110, 122], [123, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-test-2", "ner": [[4, 4, "organisation"], [8, 8, "conference"], [12, 18, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 8, 8, "role", "", false, false], [12, 18, 8, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Every", "other", "year", ",", "ELRA", "organises", "a", "major", "LREC", "conference", ",", "the", "International", "Conference", "on", "Language", "Resources", "and", "Evaluation", "."], "sentence-detokenized": "Every other year, ELRA organises a major LREC conference, the International Conference on Language Resources and Evaluation.", "token2charspan": [[0, 5], [6, 11], [12, 16], [16, 17], [18, 22], [23, 32], [33, 34], [35, 40], [41, 45], [46, 56], [56, 57], [58, 61], [62, 75], [76, 86], [87, 89], [90, 98], [99, 108], [109, 112], [113, 123], [123, 124]]}
{"doc_key": "ai-test-3", "ner": [[7, 10, "algorithm"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "task", "is", "usually", "to", "derive", "the", "maximum", "likelihood", "estimate", "of", "the", "HMM", "parameters", "given", "the", "output", "sequences", "."], "sentence-detokenized": "The task is usually to derive the maximum likelihood estimate of the HMM parameters given the output sequences.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 22], [23, 29], [30, 33], [34, 41], [42, 52], [53, 61], [62, 64], [65, 68], [69, 72], [73, 83], [84, 89], [90, 93], [94, 100], [101, 110], [110, 111]]}
{"doc_key": "ai-test-4", "ner": [[1, 2, "algorithm"], [4, 6, "algorithm"], [9, 9, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 9, 9, "compare", "", false, false], [4, 6, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Unlike", "neural", "networks", "and", "support", "vector", "machines", ",", "the", "AdaBoost", "training", "process", "selects", "only", "those", "features", "that", "are", "known", "to", "improve", "the", "predictive", "power", "of", "the", "model", ",", "thereby", "reducing", "dimensionality", "and", "potentially", "improving", "runtime", "by", "avoiding", "the", "need", "to", "compute", "irrelevant", "features", "."], "sentence-detokenized": "Unlike neural networks and support vector machines, the AdaBoost training process selects only those features that are known to improve the predictive power of the model, thereby reducing dimensionality and potentially improving runtime by avoiding the need to compute irrelevant features.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 26], [27, 34], [35, 41], [42, 50], [50, 51], [52, 55], [56, 64], [65, 73], [74, 81], [82, 89], [90, 94], [95, 100], [101, 109], [110, 114], [115, 118], [119, 124], [125, 127], [128, 135], [136, 139], [140, 150], [151, 156], [157, 159], [160, 163], [164, 169], [169, 170], [171, 178], [179, 187], [188, 202], [203, 206], [207, 218], [219, 228], [229, 236], [237, 239], [240, 248], [249, 252], [253, 257], [258, 260], [261, 268], [269, 279], [280, 288], [288, 289]]}
{"doc_key": "ai-test-5", "ner": [[0, 0, "misc"], [13, 14, "misc"], [11, 12, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 13, 14, "part-of", "", false, false], [13, 14, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponymy", "is", "one", "of", "the", "possible", "relationships", "between", "verbs", "in", "the", "Word", "Net", "semantic", "network", "."], "sentence-detokenized": "Troponymy is one of the possible relationships between verbs in the WordNet semantic network.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 19], [20, 23], [24, 32], [33, 46], [47, 54], [55, 60], [61, 63], [64, 67], [68, 72], [72, 75], [76, 84], [85, 92], [92, 93]]}
{"doc_key": "ai-test-6", "ner": [[8, 9, "task"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "framework", "language", "is", "a", "technology", "used", "to", "represent", "knowledge", "in", "artificial", "intelligence", "."], "sentence-detokenized": "A framework language is a technology used to represent knowledge in artificial intelligence.", "token2charspan": [[0, 1], [2, 11], [12, 20], [21, 23], [24, 25], [26, 36], [37, 41], [42, 44], [45, 54], [55, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-7", "ner": [[0, 0, "metrics"], [5, 7, "metrics"], [13, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 5, 7, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "the", "Bilingual", "Evaluation", "Understudy", "in", "the", "calculation", "of", "the", "brevity", "penalty", ",", "as", "small", "differences", "in", "translation", "length", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from the Bilingual Evaluation Understudy in the calculation of the brevity penalty, as small differences in translation length do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 26], [27, 36], [37, 47], [48, 58], [59, 61], [62, 65], [66, 77], [78, 80], [81, 84], [85, 92], [93, 100], [100, 101], [102, 104], [105, 110], [111, 122], [123, 125], [126, 137], [138, 144], [145, 147], [148, 151], [152, 158], [159, 162], [163, 170], [171, 176], [177, 179], [180, 184], [184, 185]]}
{"doc_key": "ai-test-8", "ner": [[14, 16, "algorithm"], [19, 21, "algorithm"], [31, 36, "field"], [42, 43, "algorithm"], [45, 47, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 16, 31, 36, "usage", "", false, false], [19, 21, 31, 36, "usage", "", false, false], [42, 43, 31, 36, "type-of", "", false, false], [45, 47, 31, 36, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "model", "is", "first", "trained", "on", "the", "training", "dataset", ",", "The", "model", "(", "e.g.", "a", "neural", "network", "or", "a", "naive", "Bayes", "classifier", ")", "is", "trained", "on", "the", "training", "dataset", "using", "a", "supervised", "learning", "method", ",", "for", "example", "using", "optimisation", "methods", "such", "as", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The model is first trained on the training dataset, The model (e.g. a neural network or a naive Bayes classifier) is trained on the training dataset using a supervised learning method, for example using optimisation methods such as gradient descent or stochastic gradient descent.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 18], [19, 26], [27, 29], [30, 33], [34, 42], [43, 50], [50, 51], [52, 55], [56, 61], [62, 63], [63, 67], [68, 69], [70, 76], [77, 84], [85, 87], [88, 89], [90, 95], [96, 101], [102, 112], [112, 113], [114, 116], [117, 124], [125, 127], [128, 131], [132, 140], [141, 148], [149, 154], [155, 156], [157, 167], [168, 176], [177, 183], [183, 184], [185, 188], [189, 196], [197, 202], [203, 215], [216, 223], [224, 228], [229, 231], [232, 240], [241, 248], [249, 251], [252, 262], [263, 271], [272, 279], [279, 280]]}
{"doc_key": "ai-test-9", "ner": [[0, 3, "product"], [9, 9, "task"], [11, 11, "task"], [13, 15, "task"], [17, 18, "task"], [27, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 9, 0, 3, "usage", "", true, false], [11, 11, 0, 3, "usage", "", true, false], [13, 15, 0, 3, "usage", "", true, false], [17, 18, 0, 3, "usage", "", true, false], [27, 30, 0, 3, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Frame", "Net", "is", "used", "in", "applications", "such", "as", "question", "answering", ",", "paraphrasing", ",", "text", "entailment", "recognition", "and", "information", "extraction", ",", "either", "directly", "or", "with", "the", "help", "of", "semantic", "role", "labelling", "tools", "."], "sentence-detokenized": "FrameNet is used in applications such as question answering, paraphrasing, text entailment recognition and information extraction, either directly or with the help of semantic role labelling tools.", "token2charspan": [[0, 5], [5, 8], [9, 11], [12, 16], [17, 19], [20, 32], [33, 37], [38, 40], [41, 49], [50, 59], [59, 60], [61, 73], [73, 74], [75, 79], [80, 90], [91, 102], [103, 106], [107, 118], [119, 129], [129, 130], [131, 137], [138, 146], [147, 149], [150, 154], [155, 158], [159, 163], [164, 166], [167, 175], [176, 180], [181, 190], [191, 196], [196, 197]]}
{"doc_key": "ai-test-10", "ner": [[6, 9, "field"], [11, 11, "misc"], [14, 14, "product"], [17, 17, "misc"], [20, 20, "product"], [23, 24, "field"], [27, 27, "product"], [30, 32, "misc"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [42, 45, "misc"], [46, 47, "product"], [49, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[14, 14, 11, 11, "general-affiliation", "", false, false], [20, 20, 17, 17, "general-affiliation", "", false, false], [27, 27, 23, 24, "general-affiliation", "", false, false], [35, 35, 30, 32, "type-of", "", false, false], [37, 37, 30, 32, "type-of", "", false, false], [39, 39, 30, 32, "type-of", "", false, false], [46, 47, 42, 45, "general-affiliation", "", false, false], [49, 50, 42, 45, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["This", "includes", "software", "such", "as", "data", "analysis", "and", "extraction", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "general", "audit", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "e.g.", "Crystal", "Reports", "and", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "This includes software such as data analysis and extraction tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), general audit software (e.g. ACL, Arbutus, EAS), business intelligence (e.g. Crystal Reports and Business Objects), etc.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 27], [28, 30], [31, 35], [36, 44], [45, 48], [49, 59], [60, 65], [65, 66], [67, 79], [80, 81], [81, 85], [86, 91], [91, 92], [92, 93], [94, 103], [104, 105], [105, 109], [110, 116], [116, 117], [117, 118], [119, 130], [131, 139], [140, 141], [141, 145], [146, 149], [149, 150], [150, 151], [152, 159], [160, 165], [166, 174], [175, 176], [176, 180], [181, 184], [184, 185], [186, 193], [193, 194], [195, 198], [198, 199], [199, 200], [201, 209], [210, 222], [223, 224], [224, 228], [229, 236], [237, 244], [245, 248], [249, 257], [258, 265], [265, 266], [266, 267], [268, 271], [271, 272]]}
{"doc_key": "ai-test-11", "ner": [[9, 10, "organisation"], [2, 5, "researcher"], [7, 7, "organisation"], [12, 13, "product"], [18, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 10, 2, 5, "origin", "", false, false], [2, 5, 7, 7, "role", "", false, false], [12, 13, 18, 19, "type-of", "", false, false], [18, 19, 2, 5, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Founded", "by", "Rodney", "Brooks", ",", "formerly", "of", "iRobot", ",", "Rethink", "Robotics", "launched", "Baxter", "in", "September", "2012", "as", "an", "industrial", "robot", "designed", "to", "work", "safely", "with", "neighbouring", "workers", "and", "can", "be", "programmed", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "Founded by Rodney Brooks, formerly of iRobot, Rethink Robotics launched Baxter in September 2012 as an industrial robot designed to work safely with neighbouring workers and can be programmed to perform simple tasks.", "token2charspan": [[0, 7], [8, 10], [11, 17], [18, 24], [24, 25], [26, 34], [35, 37], [38, 44], [44, 45], [46, 53], [54, 62], [63, 71], [72, 78], [79, 81], [82, 91], [92, 96], [97, 99], [100, 102], [103, 113], [114, 119], [120, 128], [129, 131], [132, 136], [137, 143], [144, 148], [149, 161], [162, 169], [170, 173], [174, 177], [178, 180], [181, 191], [192, 194], [195, 202], [203, 209], [210, 215], [215, 216]]}
{"doc_key": "ai-test-12", "ner": [[1, 2, "field"], [5, 6, "task"], [8, 9, "task"], [11, 14, "task"], [16, 19, "task"], [21, 22, "task"], [24, 25, "task"], [27, 29, "task"], [36, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 6, 1, 2, "part-of", "task_part_of_field", false, false], [8, 9, 1, 2, "part-of", "task_part_of_field", false, false], [11, 14, 1, 2, "part-of", "task_part_of_field", false, false], [16, 19, 1, 2, "part-of", "task_part_of_field", false, false], [21, 22, 1, 2, "part-of", "task_part_of_field", false, false], [24, 25, 1, 2, "part-of", "task_part_of_field", false, false], [27, 29, 1, 2, "part-of", "task_part_of_field", false, false], [36, 38, 1, 2, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Typical", "text", "mining", "tasks", "include", "text", "categorisation", ",", "text", "clustering", ",", "concept", "/", "entity", "extraction", ",", "construction", "of", "granular", "taxonomies", ",", "sentiment", "analysis", ",", "document", "summarisation", "and", "entity", "relationship", "modelling", "(", "i.e.", "learning", "the", "relationships", "between", "named", "entity", "recognition", ")", "."], "sentence-detokenized": "Typical text mining tasks include text categorisation, text clustering, concept/entity extraction, construction of granular taxonomies, sentiment analysis, document summarisation and entity relationship modelling (i.e. learning the relationships between named entity recognition).", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 25], [26, 33], [34, 38], [39, 53], [53, 54], [55, 59], [60, 70], [70, 71], [72, 79], [79, 80], [80, 86], [87, 97], [97, 98], [99, 111], [112, 114], [115, 123], [124, 134], [134, 135], [136, 145], [146, 154], [154, 155], [156, 164], [165, 178], [179, 182], [183, 189], [190, 202], [203, 212], [213, 214], [214, 218], [219, 227], [228, 231], [232, 245], [246, 253], [254, 259], [260, 266], [267, 278], [278, 279], [279, 280]]}
{"doc_key": "ai-test-13", "ner": [[7, 7, "metrics"], [9, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "such", "systems", "have", "a", "reduced", "accuracy", "or", "rate", "of", "true", "negatives", "due", "to", "the", "source", "record", "."], "sentence-detokenized": "However, such systems have a reduced accuracy or rate of true negatives due to the source record.", "token2charspan": [[0, 7], [7, 8], [9, 13], [14, 21], [22, 26], [27, 28], [29, 36], [37, 45], [46, 48], [49, 53], [54, 56], [57, 61], [62, 71], [72, 75], [76, 78], [79, 82], [83, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-test-14", "ner": [[4, 5, "task"], [10, 12, "misc"], [16, 21, "misc"], [29, 29, "product"], [31, 35, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 4, 5, "temporal", "", false, false], [16, 21, 10, 12, "named", "", false, false], [29, 29, 10, 12, "usage", "", false, false], [31, 35, 10, 12, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "specific", "example", "of", "keyword", "detection", "is", "the", "detection", "of", "the", "wake", "word", "(", "also", "called", "hot", "word", ")", ",", "which", "is", "used", "by", "personal", "digital", "assistants", "such", "as", "Alexa", "or", "Siri", "to", "wake", "up", "when", "their", "name", "is", "spoken", "."], "sentence-detokenized": "A specific example of keyword detection is the detection of the wake word (also called hot word), which is used by personal digital assistants such as Alexa or Siri to wake up when their name is spoken.", "token2charspan": [[0, 1], [2, 10], [11, 18], [19, 21], [22, 29], [30, 39], [40, 42], [43, 46], [47, 56], [57, 59], [60, 63], [64, 68], [69, 73], [74, 75], [75, 79], [80, 86], [87, 90], [91, 95], [95, 96], [96, 97], [98, 103], [104, 106], [107, 111], [112, 114], [115, 123], [124, 131], [132, 142], [143, 147], [148, 150], [151, 156], [157, 159], [160, 164], [165, 167], [168, 172], [173, 175], [176, 180], [181, 186], [187, 191], [192, 194], [195, 201], [201, 202]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [9, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "and", "Java", "."], "sentence-detokenized": "Prova is an open source programming language that combines Prolog and Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 16], [17, 23], [24, 35], [36, 44], [45, 49], [50, 58], [59, 65], [66, 69], [70, 74], [74, 75]]}
{"doc_key": "ai-test-16", "ner": [[3, 4, "organisation"], [9, 11, "organisation"], [20, 23, "product"], [17, 19, "country"], [35, 38, "organisation"], [45, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 9, 11, "part-of", "", false, false], [3, 4, 9, 11, "role", "sells", false, false], [3, 4, 17, 19, "role", "sells_to", false, false], [35, 38, 45, 46, "opposite", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "1987", ",", "Tocibai", "Machine", ",", "a", "subsidiary", "of", "Toshiba", ",", "was", "accused", "of", "illegally", "selling", "to", "the", "Soviet", "Union", "CNC", "milling", "machines", "used", "to", "make", "very", "quiet", "submarine", "propellers", ",", "in", "violation", "of", "the", "CoCom", "Agreement", ",", "an", "international", "embargo", "on", "certain", "countries", "for", "COMECON", "countries", "."], "sentence-detokenized": "In 1987, Tocibai Machine, a subsidiary of Toshiba, was accused of illegally selling to the Soviet Union CNC milling machines used to make very quiet submarine propellers, in violation of the CoCom Agreement, an international embargo on certain countries for COMECON countries.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 24], [24, 25], [26, 27], [28, 38], [39, 41], [42, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 75], [76, 83], [84, 86], [87, 90], [91, 97], [98, 103], [104, 107], [108, 115], [116, 124], [125, 129], [130, 132], [133, 137], [138, 142], [143, 148], [149, 158], [159, 169], [169, 170], [171, 173], [174, 183], [184, 186], [187, 190], [191, 196], [197, 206], [206, 207], [208, 210], [211, 224], [225, 232], [233, 235], [236, 243], [244, 253], [254, 257], [258, 265], [266, 275], [275, 276]]}
{"doc_key": "ai-test-17", "ner": [[0, 1, "researcher"], [7, 10, "product"], [20, 25, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 0, 1, "artifact", "", false, false], [7, 10, 20, 25, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Engelberger", "'s", "most", "famous", "invention", ",", "the", "Unimate", "industrial", "robotic", "arm", ",", "was", "one", "of", "the", "first", "inductees", "into", "the", "Robotics", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberger's most famous invention, the Unimate industrial robotic arm, was one of the first inductees into the Robotics Hall of Fame in 2003.", "token2charspan": [[0, 11], [11, 13], [14, 18], [19, 25], [26, 35], [35, 36], [37, 40], [41, 48], [49, 59], [60, 67], [68, 71], [71, 72], [73, 76], [77, 80], [81, 83], [84, 87], [88, 93], [94, 103], [104, 108], [109, 112], [113, 121], [122, 126], [127, 129], [130, 134], [135, 137], [138, 142], [142, 143]]}
{"doc_key": "ai-test-18", "ner": [[3, 7, "misc"], [8, 8, "misc"], [10, 10, "person"], [17, 18, "field"], [14, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 7, 8, 8, "usage", "", false, false], [10, 10, 17, 18, "role", "", false, false], [17, 18, 14, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Originally", "managed", "through", "static", "html", "web", "pages", "using", "CGI", ",", "Dalton", "then", "introduced", "a", "Java", "-", "based", "augmented", "reality", "interface", "with", "limited", "success", "."], "sentence-detokenized": "Originally managed through static html web pages using CGI, Dalton then introduced a Java-based augmented reality interface with limited success.", "token2charspan": [[0, 10], [11, 18], [19, 26], [27, 33], [34, 38], [39, 42], [43, 48], [49, 54], [55, 58], [58, 59], [60, 66], [67, 71], [72, 82], [83, 84], [85, 89], [89, 90], [90, 95], [96, 105], [106, 113], [114, 123], [124, 128], [129, 136], [137, 144], [144, 145]]}
{"doc_key": "ai-test-19", "ner": [[4, 5, "task"], [8, 8, "organisation"], [23, 25, "conference"], [26, 27, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 8, 8, "origin", "", false, false], [23, 25, 26, 27, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["First", "publication", "on", "the", "LMF", "specification", "ratified", "by", "ISO", "(", "this", "paper", "became", "(", "in", "2015", ")", "the", "9th", "most", "cited", "paper", "at", "LREC", "conferences", "among", "LREC", "documents", ")", ":"], "sentence-detokenized": "First publication on the LMF specification ratified by ISO (this paper became (in 2015) the 9th most cited paper at LREC conferences among LREC documents):", "token2charspan": [[0, 5], [6, 17], [18, 20], [21, 24], [25, 28], [29, 42], [43, 51], [52, 54], [55, 58], [59, 60], [60, 64], [65, 70], [71, 77], [78, 79], [79, 81], [82, 86], [86, 87], [88, 91], [92, 95], [96, 100], [101, 106], [107, 112], [113, 115], [116, 120], [121, 132], [133, 138], [139, 143], [144, 153], [153, 154], [154, 155]]}
{"doc_key": "ai-test-20", "ner": [[0, 2, "metrics"], [15, 16, "metrics"], [17, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 0, 2, "usage", "", false, false], [15, 16, 17, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "confusion", "matrix", "or", "matching", "matrix", "is", "often", "used", "as", "a", "tool", "to", "check", "the", "accuracy", "of", "the", "k", "-", "NN", "classifier", "."], "sentence-detokenized": "The confusion matrix or matching matrix is often used as a tool to check the accuracy of the k -NN classifier.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 23], [24, 32], [33, 39], [40, 42], [43, 48], [49, 53], [54, 56], [57, 58], [59, 63], [64, 66], [67, 72], [73, 76], [77, 85], [86, 88], [89, 92], [93, 94], [95, 96], [96, 98], [99, 109], [109, 110]]}
{"doc_key": "ai-test-21", "ner": [[0, 1, "algorithm"], [12, 12, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 15, "part-of", "", false, false], [0, 1, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", "is", "one", "of", "the", "predictive", "modelling", "approaches", "used", "in", "statistics", ",", "data", "mining", "and", "machine", "learning", "."], "sentence-detokenized": "Decision tree learning is one of the predictive modelling approaches used in statistics, data mining and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 47], [48, 57], [58, 68], [69, 73], [74, 76], [77, 87], [87, 88], [89, 93], [94, 100], [101, 104], [105, 112], [113, 121], [121, 122]]}
{"doc_key": "ai-test-22", "ner": [[5, 6, "misc"], [16, 17, "field"], [21, 23, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 16, 17, "related-to", "", true, false], [21, 23, 16, 17, "type-of", "", false, false], [25, 25, 16, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["During", "execution", ",", "the", "target", "prosody", "of", "the", "sentence", "is", "overlaid", "on", "these", "minimal", "units", "using", "signal", "processing", "techniques", "such", "as", "linear", "predictive", "coding", ",", "PSOLA"], "sentence-detokenized": "During execution, the target prosody of the sentence is overlaid on these minimal units using signal processing techniques such as linear predictive coding, PSOLA", "token2charspan": [[0, 6], [7, 16], [16, 17], [18, 21], [22, 28], [29, 36], [37, 39], [40, 43], [44, 52], [53, 55], [56, 64], [65, 67], [68, 73], [74, 81], [82, 87], [88, 93], [94, 100], [101, 111], [112, 122], [123, 127], [128, 130], [131, 137], [138, 148], [149, 155], [155, 156], [157, 162]]}
{"doc_key": "ai-test-23", "ner": [[3, 4, "field"], [6, 9, "field"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 3, 4, "usage", "", true, false], [17, 18, 6, 9, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "approach", "used", "artificial", "intelligence", "and", "machine", "learning", "to", "allow", "researchers", "to", "visually", "compare", "normal", "and", "thermal", "facial", "images", "."], "sentence-detokenized": "This approach used artificial intelligence and machine learning to allow researchers to visually compare normal and thermal facial images.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 29], [30, 42], [43, 46], [47, 54], [55, 63], [64, 66], [67, 72], [73, 84], [85, 87], [88, 96], [97, 104], [105, 111], [112, 115], [116, 123], [124, 130], [131, 137], [137, 138]]}
{"doc_key": "ai-test-24", "ner": [[1, 1, "field"], [3, 4, "algorithm"], [9, 10, "task"], [14, 15, "misc"], [21, 22, "field"], [24, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 1, 1, "part-of", "", false, false], [3, 4, 9, 10, "topic", "", false, false], [9, 10, 14, 15, "origin", "", false, false], [21, 22, 1, 1, "part-of", "", false, false], [21, 22, 3, 4, "topic", "", false, false], [24, 26, 1, 1, "part-of", "", false, false], [24, 26, 3, 4, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "computing", ",", "evolutionary", "computation", "is", "a", "family", "of", "global", "optimisation", "algorithms", "inspired", "by", "biological", "evolution", ",", "and", "a", "subfield", "of", "artificial", "intelligence", "and", "soft", "computing", "that", "studies", "these", "algorithms", "."], "sentence-detokenized": "In computing, evolutionary computation is a family of global optimisation algorithms inspired by biological evolution, and a subfield of artificial intelligence and soft computing that studies these algorithms.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 26], [27, 38], [39, 41], [42, 43], [44, 50], [51, 53], [54, 60], [61, 73], [74, 84], [85, 93], [94, 96], [97, 107], [108, 117], [117, 118], [119, 122], [123, 124], [125, 133], [134, 136], [137, 147], [148, 160], [161, 164], [165, 169], [170, 179], [180, 184], [185, 192], [193, 198], [199, 209], [209, 210]]}
{"doc_key": "ai-test-25", "ner": [[8, 9, "metrics"], [15, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "a", "measure", "based", "on", "a", "confusion", "matrix", "can", "be", "combined", "with", "the", "root", "mean", "square", "error", "estimated", "between", "the", "raw", "model", "outputs", "and", "the", "actual", "values", "."], "sentence-detokenized": "For example, a measure based on a confusion matrix can be combined with the root mean square error estimated between the raw model outputs and the actual values.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 14], [15, 22], [23, 28], [29, 31], [32, 33], [34, 43], [44, 50], [51, 54], [55, 57], [58, 66], [67, 71], [72, 75], [76, 80], [81, 85], [86, 92], [93, 98], [99, 108], [109, 116], [117, 120], [121, 124], [125, 130], [131, 138], [139, 142], [143, 146], [147, 153], [154, 160], [160, 161]]}
{"doc_key": "ai-test-26", "ner": [[5, 7, "product"], [10, 10, "researcher"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 10, 10, "origin", "", false, false], [5, 7, 18, 18, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Most", "are", "the", "result", "of", "the", "word2vec", "model", "developed", "by", "Mikolov", "and", "others", ",", "or", "variants", "of", "the", "word2vec", "model", "."], "sentence-detokenized": "Most are the result of the word2vec model developed by Mikolov and others, or variants of the word2vec model.", "token2charspan": [[0, 4], [5, 8], [9, 12], [13, 19], [20, 22], [23, 26], [27, 35], [36, 41], [42, 51], [52, 54], [55, 62], [63, 66], [67, 73], [73, 74], [75, 77], [78, 86], [87, 89], [90, 93], [94, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-test-27", "ner": [[0, 10, "conference"], [13, 17, "conference"], [19, 19, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 19, 13, 17, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["During", "this", "time", ",", "43", "publications", "have", "been", "recognised", "by", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "During this time, 43 publications have been recognised by CVPR and the International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 6], [7, 11], [12, 16], [16, 17], [18, 20], [21, 33], [34, 38], [39, 43], [44, 54], [55, 57], [58, 62], [63, 66], [67, 70], [71, 84], [85, 95], [96, 98], [99, 107], [108, 114], [115, 116], [116, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-test-28", "ner": [[0, 0, "product"], [15, 16, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 15, 16, "general-affiliation", "platform_for_education_about", false, false], [22, 23, 0, 0, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["AIBO", "is", "often", "used", "as", "a", "low", "-", "cost", "platform", "for", "AI", "education", "and", "research", ",", "as", "it", "includes", "a", "computer", ",", "computer", "vision", "and", "articulators", "in", "a", "package", "that", "is", "much", "cheaper", "than", "conventional", "research", "robots", "."], "sentence-detokenized": "AIBO is often used as a low-cost platform for AI education and research, as it includes a computer, computer vision and articulators in a package that is much cheaper than conventional research robots.", "token2charspan": [[0, 4], [5, 7], [8, 13], [14, 18], [19, 21], [22, 23], [24, 27], [27, 28], [28, 32], [33, 41], [42, 45], [46, 48], [49, 58], [59, 62], [63, 71], [71, 72], [73, 75], [76, 78], [79, 87], [88, 89], [90, 98], [98, 99], [100, 108], [109, 115], [116, 119], [120, 132], [133, 135], [136, 137], [138, 145], [146, 150], [151, 153], [154, 158], [159, 166], [167, 171], [172, 184], [185, 193], [194, 200], [200, 201]]}
{"doc_key": "ai-test-29", "ner": [[6, 11, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "was", "Programme", "Chair", "of", "the", "International", "Conference", "on", "Computer", "Vision", "2021", "."], "sentence-detokenized": "She was Programme Chair of the International Conference on Computer Vision 2021.", "token2charspan": [[0, 3], [4, 7], [8, 17], [18, 23], [24, 26], [27, 30], [31, 44], [45, 55], [56, 58], [59, 67], [68, 74], [75, 79], [79, 80]]}
{"doc_key": "ai-test-30", "ner": [[11, 11, "researcher"], [5, 6, "organisation"], [15, 17, "organisation"], [23, 24, "organisation"], [34, 37, "product"], [39, 39, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 5, 6, "role", "", false, false], [11, 11, 15, 17, "role", "", true, false], [15, 17, 23, 24, "role", "develops_with", false, false], [34, 37, 15, 17, "artifact", "", false, false], [39, 39, 34, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["After", "receiving", "a", "grant", "from", "Unimation", "to", "develop", "his", "plans", ",", "Scheinman", "sold", "them", "to", "Unimation", ",", "which", ",", "with", "the", "support", "of", "General", "Motors", ",", "further", "developed", "and", "later", "marketed", "them", "as", "the", "Programmable", "Universal", "Machine", "Assembly", "(", "PUMA", ")", "."], "sentence-detokenized": "After receiving a grant from Unimation to develop his plans, Scheinman sold them to Unimation, which, with the support of General Motors, further developed and later marketed them as the Programmable Universal Machine Assembly (PUMA).", "token2charspan": [[0, 5], [6, 15], [16, 17], [18, 23], [24, 28], [29, 38], [39, 41], [42, 49], [50, 53], [54, 59], [59, 60], [61, 70], [71, 75], [76, 80], [81, 83], [84, 93], [93, 94], [95, 100], [100, 101], [102, 106], [107, 110], [111, 118], [119, 121], [122, 129], [130, 136], [136, 137], [138, 145], [146, 155], [156, 159], [160, 165], [166, 174], [175, 179], [180, 182], [183, 186], [187, 199], [200, 209], [210, 217], [218, 226], [227, 228], [228, 232], [232, 233], [233, 234]]}
{"doc_key": "ai-test-31", "ner": [[11, 12, "task"], [14, 16, "task"], [0, 0, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 12, "general-affiliation", "works_with", false, false], [0, 0, 14, 16, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Gebel", "(", "2009", ")", "gave", "an", "overview", "of", "calibration", "methods", "for", "binary", "classification", "and", "multiclass", "classification", "tasks", "."], "sentence-detokenized": "Gebel (2009) gave an overview of calibration methods for binary classification and multiclass classification tasks.", "token2charspan": [[0, 5], [6, 7], [7, 11], [11, 12], [13, 17], [18, 20], [21, 29], [30, 32], [33, 44], [45, 52], [53, 56], [57, 63], [64, 78], [79, 82], [83, 93], [94, 108], [109, 114], [114, 115]]}
{"doc_key": "ai-test-32", "ner": [[4, 6, "task"], [8, 8, "task"], [11, 12, "task"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 4, 6, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["His", "research", "interests", "include", "optical", "character", "recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "speech", "recognition", "technology", "and", "electronic", "keyboard", "instruments", "."], "sentence-detokenized": "His research interests include optical character recognition (OCR), speech synthesis, speech recognition technology and electronic keyboard instruments.", "token2charspan": [[0, 3], [4, 12], [13, 22], [23, 30], [31, 38], [39, 48], [49, 60], [61, 62], [62, 65], [65, 66], [66, 67], [68, 74], [75, 84], [84, 85], [86, 92], [93, 104], [105, 115], [116, 119], [120, 130], [131, 139], [140, 151], [151, 152]]}
{"doc_key": "ai-test-33", "ner": [[11, 12, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "newer", "and", "more", "advanced", "techniques", ",", "you", "can", "use", "the", "Kaldi", "tool", "."], "sentence-detokenized": "For newer and more advanced techniques, you can use the Kaldi tool.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 18], [19, 27], [28, 38], [38, 39], [40, 43], [44, 47], [48, 51], [52, 55], [56, 61], [62, 66], [66, 67]]}
{"doc_key": "ai-test-34", "ner": [[0, 2, "researcher"], [7, 12, "organisation"], [15, 19, "organisation"], [22, 24, "organisation"], [39, 40, "researcher"], [30, 41, "organisation"], [47, 50, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 7, 12, "role", "", false, false], [0, 2, 15, 19, "role", "", false, false], [0, 2, 22, 24, "role", "", false, false], [0, 2, 30, 41, "role", "", false, false], [0, 2, 47, 50, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson", "-", "Laird", "is", "a", "Fellow", "of", "the", "American", "Philosophical", "Society", ",", "a", "Fellow", "of", "the", "Royal", "Society", ",", "a", "Fellow", "of", "the", "British", "Academy", ",", "a", "Fellow", "of", "the", "Association", "for", "Psychological", "Science", ",", "a", "Fellow", "of", "the", "William", "James", "Society", "and", "a", "Fellow", "of", "the", "Society", "for", "Cognitive", "Science", "."], "sentence-detokenized": "Johnson-Laird is a Fellow of the American Philosophical Society, a Fellow of the Royal Society, a Fellow of the British Academy, a Fellow of the Association for Psychological Science, a Fellow of the William James Society and a Fellow of the Society for Cognitive Science.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 66], [67, 73], [74, 76], [77, 80], [81, 86], [87, 94], [94, 95], [96, 97], [98, 104], [105, 107], [108, 111], [112, 119], [120, 127], [127, 128], [129, 130], [131, 137], [138, 140], [141, 144], [145, 156], [157, 160], [161, 174], [175, 182], [182, 183], [184, 185], [186, 192], [193, 195], [196, 199], [200, 207], [208, 213], [214, 221], [222, 225], [226, 227], [228, 234], [235, 237], [238, 241], [242, 249], [250, 253], [254, 263], [264, 271], [271, 272]]}
{"doc_key": "ai-test-35", "ner": [[3, 8, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [20, 22, "algorithm"], [25, 29, "task"], [31, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 3, 8, "physical", "", false, false], [10, 11, 3, 8, "temporal", "", false, false], [13, 14, 3, 8, "physical", "", false, false], [13, 14, 3, 8, "temporal", "", false, false], [16, 17, 3, 8, "physical", "", false, false], [16, 17, 3, 8, "temporal", "", false, false], [20, 22, 16, 17, "role", "extends", false, false], [25, 29, 16, 17, "role", "extends", false, false], [31, 31, 25, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["At", "the", "2010", "IEEE", "International", "Conference", "on", "Image", "Processing", ",", "Rui", "Hu", ",", "Mark", "Banard", "and", "John", "Collomosse", "extended", "the", "HOG", "descriptor", "for", "use", "in", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the 2010 IEEE International Conference on Image Processing, Rui Hu, Mark Banard and John Collomosse extended the HOG descriptor for use in sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 30], [31, 41], [42, 44], [45, 50], [51, 61], [61, 62], [63, 66], [67, 69], [69, 70], [71, 75], [76, 82], [83, 86], [87, 91], [92, 102], [103, 111], [112, 115], [116, 119], [120, 130], [131, 134], [135, 138], [139, 141], [142, 148], [148, 149], [149, 154], [155, 160], [161, 170], [171, 172], [172, 176], [176, 177], [177, 178]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 7, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "uses", "a", "modified", "form", "of", "precision", "to", "compare", "a", "candidate", "translation", "with", "several", "reference", "translations", "."], "sentence-detokenized": "BLEU uses a modified form of precision to compare a candidate translation with several reference translations.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 20], [21, 25], [26, 28], [29, 38], [39, 41], [42, 49], [50, 51], [52, 61], [62, 73], [74, 78], [79, 86], [87, 96], [97, 109], [109, 110]]}
{"doc_key": "ai-test-37", "ner": [[35, 36, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "case", "of", "a", "general", "math", "(", "Y", ",\\", "mathcal", "{", "B", "},\\", "nu", ")", "/", "math", "basis", "space", "(", "i.e.", "a", "basis", "space", "that", "can", "not", "be", "counted", ")", ",", "we", "usually", "consider", "relative", "entropy", "."], "sentence-detokenized": "In the case of a general math (Y,\\ mathcal {B},\\ nu) / math basis space (i.e. a basis space that cannot be counted), we usually consider relative entropy.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 16], [17, 24], [25, 29], [30, 31], [31, 32], [32, 34], [35, 42], [43, 44], [44, 45], [45, 48], [49, 51], [51, 52], [53, 54], [55, 59], [60, 65], [66, 71], [72, 73], [73, 77], [78, 79], [80, 85], [86, 91], [92, 96], [97, 100], [100, 103], [104, 106], [107, 114], [114, 115], [115, 116], [117, 119], [120, 127], [128, 136], [137, 145], [146, 153], [153, 154]]}
{"doc_key": "ai-test-38", "ner": [[9, 9, "country"], [10, 12, "organisation"], [14, 14, "organisation"], [21, 22, "country"], [17, 18, "organisation"], [20, 20, "organisation"], [24, 26, "organisation"], [29, 29, "country"], [30, 35, "organisation"], [37, 37, "organisation"], [43, 43, "misc"], [44, 44, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[10, 12, 9, 9, "physical", "", false, false], [14, 14, 10, 12, "named", "", false, false], [17, 18, 21, 22, "physical", "", false, false], [20, 20, 17, 18, "named", "", false, false], [30, 35, 29, 29, "physical", "", false, false], [37, 37, 30, 35, "named", "", false, false], [43, 43, 44, 44, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "October", "2011", ",", "the", "existing", "partnership", "with", "the", "US", "National", "Park", "Service", "(", "NPS", ")", ",", "Historic", "Scotland", "(", "HS", ")", ",", "the", "World", "Monuments", "Fund", "and", "the", "Mexican", "National", "Institute", "of", "Anthropology", "and", "History", "(", "INAH", ")", "was", "significantly", "expanded", ",", "CyArk", "website"], "sentence-detokenized": "In October 2011, the existing partnership with the US National Park Service (NPS), Historic Scotland (HS), the World Monuments Fund and the Mexican National Institute of Anthropology and History (INAH) was significantly expanded, CyArk website", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [17, 20], [21, 29], [30, 41], [42, 46], [47, 50], [51, 53], [54, 62], [63, 67], [68, 75], [76, 77], [77, 80], [80, 81], [81, 82], [83, 91], [92, 100], [101, 102], [102, 104], [104, 105], [105, 106], [107, 110], [111, 116], [117, 126], [127, 131], [132, 135], [136, 139], [140, 147], [148, 156], [157, 166], [167, 169], [170, 182], [183, 186], [187, 194], [195, 196], [196, 200], [200, 201], [202, 205], [206, 219], [220, 228], [228, 229], [230, 235], [236, 243]]}
{"doc_key": "ai-test-39", "ner": [[0, 1, "algorithm"], [6, 8, "field"], [11, 11, "product"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 11, 11, "part-of", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [11, 11, 6, 8, "general-affiliation", "", false, false], [13, 13, 6, 8, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kernel", "SVMs", "are", "available", "in", "many", "machine", "learning", "tools", ",", "including", "LIBSVM", ",", "MATLAB", "and", "others", "."], "sentence-detokenized": "Kernel SVMs are available in many machine learning tools, including LIBSVM, MATLAB and others.", "token2charspan": [[0, 6], [7, 11], [12, 15], [16, 25], [26, 28], [29, 33], [34, 41], [42, 50], [51, 56], [56, 57], [58, 67], [68, 74], [74, 75], [76, 82], [83, 86], [87, 93], [93, 94]]}
{"doc_key": "ai-test-40", "ner": [[0, 2, "misc"], [12, 13, "location"], [15, 17, "location"], [19, 19, "country"], [23, 25, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 12, 13, "physical", "", false, false], [0, 2, 23, 25, "temporal", "", false, false], [12, 13, 15, 17, "physical", "", false, false], [15, 17, 19, 19, "physical", "", false, false], [23, 25, 12, 13, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Loebner", "Prize", "2009", "was", "held", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", "in", "Brighton", ",", "UK", ",", "as", "part", "of", "the", "Interspeech", "2009", "conference", "."], "sentence-detokenized": "The Loebner Prize 2009 was held on 6 September 2009 at the Brighton Centre in Brighton, UK, as part of the Interspeech 2009 conference.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 22], [23, 26], [27, 31], [32, 34], [35, 36], [37, 46], [47, 51], [52, 54], [55, 58], [59, 67], [68, 74], [75, 77], [78, 86], [86, 87], [88, 90], [90, 91], [92, 94], [95, 99], [100, 102], [103, 106], [107, 118], [119, 123], [124, 134], [134, 135]]}
{"doc_key": "ai-test-41", "ner": [[0, 3, "product"], [10, 12, "product"], [20, 23, "product"], [18, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[18, 24, 0, 3, "part-of", "", false, false], [18, 24, 10, 12, "part-of", "", false, false], [18, 24, 20, 23, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "QRIO", "humanoid", "robot", "was", "designed", "as", "a", "successor", "to", "the", "AIBO", "robot", "and", "uses", "the", "same", "basic", "operating", "system", ",", "R", "-", "CODE", "Aperios", "."], "sentence-detokenized": "The QRIO humanoid robot was designed as a successor to the AIBO robot and uses the same basic operating system, R-CODE Aperios.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 23], [24, 27], [28, 36], [37, 39], [40, 41], [42, 51], [52, 54], [55, 58], [59, 63], [64, 69], [70, 73], [74, 78], [79, 82], [83, 87], [88, 93], [94, 103], [104, 110], [110, 111], [112, 113], [113, 114], [114, 118], [119, 126], [126, 127]]}
{"doc_key": "ai-test-42", "ner": [[0, 2, "misc"], [6, 6, "algorithm"], [11, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 0, 2, "cause-effect", "", true, false], [11, 13, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Speech", "shapes", "are", "generated", "from", "the", "HMMs", "themselves", "based", "on", "a", "maximum", "likelihood", "criterion", "."], "sentence-detokenized": "Speech shapes are generated from the HMMs themselves based on a maximum likelihood criterion.", "token2charspan": [[0, 6], [7, 13], [14, 17], [18, 27], [28, 32], [33, 36], [37, 41], [42, 52], [53, 58], [59, 61], [62, 63], [64, 71], [72, 82], [83, 92], [92, 93]]}
{"doc_key": "ai-test-43", "ner": [[0, 1, "product"], [5, 8, "task"], [10, 12, "task"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 5, 8, "type-of", "", false, false], [0, 1, 10, 12, "type-of", "", false, false], [0, 1, 16, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "is", "a", "free", "multilingual", "statistical", "machine", "translation", "and", "neural", "machine", "translation", "service", "developed", "by", "Google", "that", "allows", "you", "to", "translate", "text", "and", "websites", "from", "one", "language", "into", "another", "."], "sentence-detokenized": "Google Translate is a free multilingual statistical machine translation and neural machine translation service developed by Google that allows you to translate text and websites from one language into another.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 39], [40, 51], [52, 59], [60, 71], [72, 75], [76, 82], [83, 90], [91, 102], [103, 110], [111, 120], [121, 123], [124, 130], [131, 135], [136, 142], [143, 146], [147, 149], [150, 159], [160, 164], [165, 168], [169, 177], [178, 182], [183, 186], [187, 195], [196, 200], [201, 208], [208, 209]]}
{"doc_key": "ai-test-44", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [14, 17, "field"], [21, 23, "task"], [25, 26, "task"], [28, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[21, 23, 5, 6, "part-of", "", false, true], [21, 23, 8, 9, "part-of", "", false, true], [21, 23, 11, 12, "part-of", "", false, true], [25, 26, 5, 6, "part-of", "", false, true], [25, 26, 8, 9, "part-of", "", false, true], [25, 26, 11, 12, "part-of", "", false, true], [28, 31, 5, 6, "part-of", "", false, true], [28, 31, 8, 9, "part-of", "", false, true], [28, 31, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Skeletons", "are", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", "and", "digital", "image", "processing", "for", "purposes", "such", "as", "optical", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", "or", "compression", "."], "sentence-detokenized": "Skeletons are widely used in computer vision, image analysis, pattern recognition and digital image processing for purposes such as optical character recognition, fingerprint recognition, visual inspection or compression.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 25], [26, 28], [29, 37], [38, 44], [44, 45], [46, 51], [52, 60], [60, 61], [62, 69], [70, 81], [82, 85], [86, 93], [94, 99], [100, 110], [111, 114], [115, 123], [124, 128], [129, 131], [132, 139], [140, 149], [150, 161], [161, 162], [163, 174], [175, 186], [186, 187], [188, 194], [195, 205], [206, 208], [209, 220], [220, 221]]}
{"doc_key": "ai-test-45", "ner": [[0, 6, "conference"], [9, 14, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 6, 9, 14, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "is", "an", "object", "classification", "and", "detection", "benchmark", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge is an object classification and detection benchmark with millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 59], [60, 66], [67, 81], [82, 85], [86, 95], [96, 105], [106, 110], [111, 119], [120, 122], [123, 129], [130, 133], [134, 142], [143, 145], [146, 152], [153, 160], [160, 161]]}
{"doc_key": "ai-test-46", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 13, "researcher"], [17, 20, "misc"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 17, 20, "part-of", "", false, false], [0, 2, 25, 26, "part-of", "", false, false], [4, 5, 17, 20, "part-of", "", false, false], [4, 5, 25, 26, "part-of", "", false, false], [7, 13, 17, 20, "part-of", "", false, false], [7, 13, 25, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Benga", ",", "along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "have", "been", "hailed", "by", "some", "as", "the", "godfathers", "of", "artificial", "intelligence", "and", "the", "godfathers", "of", "deep", "learning", "."], "sentence-detokenized": "Benga, along with Geoffrey Hinton and Yann LeCun, have been hailed by some as the godfathers of artificial intelligence and the godfathers of deep learning.", "token2charspan": [[0, 5], [5, 6], [7, 12], [13, 17], [18, 26], [27, 33], [34, 37], [38, 42], [43, 48], [48, 49], [50, 54], [55, 59], [60, 66], [67, 69], [70, 74], [75, 77], [78, 81], [82, 92], [93, 95], [96, 106], [107, 119], [120, 123], [124, 127], [128, 138], [139, 141], [142, 146], [147, 155], [155, 156]]}
{"doc_key": "ai-test-47", "ner": [[6, 7, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "Life", "Member", "of", "the", "IEEE", "."], "sentence-detokenized": "He is a Life Member of the IEEE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 19], [20, 22], [23, 26], [27, 31], [31, 32]]}
{"doc_key": "ai-test-48", "ner": [[0, 2, "organisation"], [13, 18, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 13, 18, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NSA", "Bethesda", "is", "responsible", "for", "base", "operational", "support", "for", "its", "main", "tenant", ",", "Walter", "Reed", "National", "Military", "Medical", "Center", "."], "sentence-detokenized": "NSA Bethesda is responsible for base operational support for its main tenant, Walter Reed National Military Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 31], [32, 36], [37, 48], [49, 56], [57, 60], [61, 64], [65, 69], [70, 76], [76, 77], [78, 84], [85, 89], [90, 98], [99, 107], [108, 115], [116, 122], [122, 123]]}
{"doc_key": "ai-test-49", "ner": [[6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "three", "main", "learning", "paradigms", "are", "supervised", "learning", ",", "unsupervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "The three main learning paradigms are supervised learning, unsupervised learning and reinforcement learning.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 23], [24, 33], [34, 37], [38, 48], [49, 57], [57, 58], [59, 71], [72, 80], [81, 84], [85, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-50", "ner": [[2, 2, "task"], [4, 8, "task"], [10, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Examples", "include", "supervision", ",", "planning", "and", "scheduling", ",", "the", "ability", "to", "answer", "diagnostic", "and", "consumer", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", "and", "facial", "recognition", "."], "sentence-detokenized": "Examples include supervision, planning and scheduling, the ability to answer diagnostic and consumer questions, handwriting recognition, natural language understanding, speech recognition and facial recognition.", "token2charspan": [[0, 8], [9, 16], [17, 28], [28, 29], [30, 38], [39, 42], [43, 53], [53, 54], [55, 58], [59, 66], [67, 69], [70, 76], [77, 87], [88, 91], [92, 100], [101, 110], [110, 111], [112, 123], [124, 135], [135, 136], [137, 144], [145, 153], [154, 167], [167, 168], [169, 175], [176, 187], [188, 191], [192, 198], [199, 210], [210, 211]]}
{"doc_key": "ai-test-51", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "founding", "member", ")", "."], "sentence-detokenized": "In 1991, he was elected a Fellow of the Association for the Advancement of Artificial Intelligence (1990, founding member).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [99, 100], [100, 104], [104, 105], [106, 114], [115, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-test-52", "ner": [[11, 12, "misc"], [15, 16, "algorithm"], [27, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "by", "formulating", "the", "problem", "as", "a", "solution", "of", "a", "Toeplitz", "matrix", "and", "using", "Levinson", "recursion", ",", "we", "can", "estimate", "the", "filter", "with", "the", "smallest", "possible", "mean", "square", "error", "relatively", "quickly", "."], "sentence-detokenized": "However, by formulating the problem as a solution of a Toeplitz matrix and using Levinson recursion, we can estimate the filter with the smallest possible mean square error relatively quickly.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 23], [24, 27], [28, 35], [36, 38], [39, 40], [41, 49], [50, 52], [53, 54], [55, 63], [64, 70], [71, 74], [75, 80], [81, 89], [90, 99], [99, 100], [101, 103], [104, 107], [108, 116], [117, 120], [121, 127], [128, 132], [133, 136], [137, 145], [146, 154], [155, 159], [160, 166], [167, 172], [173, 183], [184, 191], [191, 192]]}
{"doc_key": "ai-test-53", "ner": [[5, 8, "conference"], [14, 20, "location"], [13, 13, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 8, 14, 20, "physical", "", false, false], [14, 20, 13, 13, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2011", ",", "the", "15th", "Campus", "Party", "Spain", "will", "take", "place", "in", "Valencia", ",", "the", "city", "of", "arts", "and", "sciences", "."], "sentence-detokenized": "In July 2011, the 15th Campus Party Spain will take place in Valencia, the city of arts and sciences.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 22], [23, 29], [30, 35], [36, 41], [42, 46], [47, 51], [52, 57], [58, 60], [61, 69], [69, 70], [71, 74], [75, 79], [80, 82], [83, 87], [88, 91], [92, 100], [100, 101]]}
{"doc_key": "ai-test-54", "ner": [[14, 14, "product"], [16, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Often", "this", "is", "only", "possible", "at", "the", "very", "end", "of", "complex", "games", "such", "as", "chess", "or", "go", ",", "as", "it", "is", "not", "computationally", "feasible", "to", "look", "ahead", "to", "the", "end", "of", "the", "game", "except", "towards", "the", "end", ",", "and", "instead", "positions", "are", "assigned", "finite", "values", "as", "estimates", "of", "the", "degree", "of", "certainty", "that", "they", "will", "lead", "to", "a", "win", "for", "one", "player", "or", "the", "other", "."], "sentence-detokenized": "Often this is only possible at the very end of complex games such as chess or go, as it is not computationally feasible to look ahead to the end of the game except towards the end, and instead positions are assigned finite values as estimates of the degree of certainty that they will lead to a win for one player or the other.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 18], [19, 27], [28, 30], [31, 34], [35, 39], [40, 43], [44, 46], [47, 54], [55, 60], [61, 65], [66, 68], [69, 74], [75, 77], [78, 80], [80, 81], [82, 84], [85, 87], [88, 90], [91, 94], [95, 110], [111, 119], [120, 122], [123, 127], [128, 133], [134, 136], [137, 140], [141, 144], [145, 147], [148, 151], [152, 156], [157, 163], [164, 171], [172, 175], [176, 179], [179, 180], [181, 184], [185, 192], [193, 202], [203, 206], [207, 215], [216, 222], [223, 229], [230, 232], [233, 242], [243, 245], [246, 249], [250, 256], [257, 259], [260, 269], [270, 274], [275, 279], [280, 284], [285, 289], [290, 292], [293, 294], [295, 298], [299, 302], [303, 306], [307, 313], [314, 316], [317, 320], [321, 326], [326, 327]]}
{"doc_key": "ai-test-55", "ner": [[4, 6, "algorithm"], [25, 26, "algorithm"], [28, 30, "algorithm"], [32, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 25, 26, "compare", "", false, false], [4, 6, 28, 30, "compare", "", false, false], [4, 6, 32, 34, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "difference", "between", "the", "multinomial", "logit", "model", "and", "many", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "with", "the", "same", "basic", "set", "-", "up", "(", "perceptron", "algorithm", ",", "support", "vector", "machines", ",", "linear", "discriminant", "analysis", ",", "etc", "."], "sentence-detokenized": "The difference between the multinomial logit model and many other methods, models, algorithms, etc. with the same basic set-up (perceptron algorithm, support vector machines, linear discriminant analysis, etc.", "token2charspan": [[0, 3], [4, 14], [15, 22], [23, 26], [27, 38], [39, 44], [45, 50], [51, 54], [55, 59], [60, 65], [66, 73], [73, 74], [75, 81], [81, 82], [83, 93], [93, 94], [95, 99], [100, 104], [105, 108], [109, 113], [114, 119], [120, 123], [123, 124], [124, 126], [127, 128], [128, 138], [139, 148], [148, 149], [150, 157], [158, 164], [165, 173], [173, 174], [175, 181], [182, 194], [195, 203], [203, 204], [205, 208], [208, 209]]}
{"doc_key": "ai-test-56", "ner": [[0, 6, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "published", "by", "the"], "sentence-detokenized": "Association for Computational Linguistics, published by the", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 52], [53, 55], [56, 59]]}
{"doc_key": "ai-test-57", "ner": [[3, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "a", "computer", "face", "recognition", "system", ",", "each", "face", "is", "represented", "by", "a", "large", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In a computer face recognition system, each face is represented by a large number of pixel values.", "token2charspan": [[0, 2], [3, 4], [5, 13], [14, 18], [19, 30], [31, 37], [37, 38], [39, 43], [44, 48], [49, 51], [52, 63], [64, 66], [67, 68], [69, 74], [75, 81], [82, 84], [85, 90], [91, 97], [97, 98]]}
{"doc_key": "ai-test-58", "ner": [[5, 8, "person"], [9, 11, "organisation"], [19, 19, "country"], [22, 22, "person"], [33, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 8, 9, 11, "role", "", false, false], [5, 8, 19, 19, "physical", "", false, false], [22, 22, 33, 35, "origin", "", false, false], [22, 22, 33, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2002", ",", "his", "son", "Daniel", "Pearl", ",", "a", "Wall", "Street", "Journal", "journalist", ",", "was", "kidnapped", "and", "murdered", "in", "Pakistan", ",", "prompting", "Judea", ",", "other", "family", "members", "and", "friends", "to", "set", "up", "the", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "In 2002, his son Daniel Pearl, a Wall Street Journal journalist, was kidnapped and murdered in Pakistan, prompting Judea, other family members and friends to set up the Daniel Pearl Foundation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 23], [24, 29], [29, 30], [31, 32], [33, 37], [38, 44], [45, 52], [53, 63], [63, 64], [65, 68], [69, 78], [79, 82], [83, 91], [92, 94], [95, 103], [103, 104], [105, 114], [115, 120], [120, 121], [122, 127], [128, 134], [135, 142], [143, 146], [147, 154], [155, 157], [158, 161], [162, 164], [165, 168], [169, 175], [176, 181], [182, 192], [192, 193]]}
{"doc_key": "ai-test-59", "ner": [[6, 8, "organisation"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 18, 19, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["At", "the", "end", "of", "2006", ",", "Red", "Envelope", "Entertainment", "expanded", "into", "original", "content", "production", "with", "filmmakers", "such", "as", "John", "Waters", "."], "sentence-detokenized": "At the end of 2006, Red Envelope Entertainment expanded into original content production with filmmakers such as John Waters.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 18], [18, 19], [20, 23], [24, 32], [33, 46], [47, 55], [56, 60], [61, 69], [70, 77], [78, 88], [89, 93], [94, 104], [105, 109], [110, 112], [113, 117], [118, 124], [124, 125]]}
{"doc_key": "ai-test-60", "ner": [[7, 11, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "building", "is", "now", "part", "of", "the", "Beth", "Israel", "Deaconess", "Medical", "Centre", "."], "sentence-detokenized": "The building is now part of the Beth Israel Deaconess Medical Centre.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 31], [32, 36], [37, 43], [44, 53], [54, 61], [62, 68], [68, 69]]}
{"doc_key": "ai-test-61", "ner": [[18, 19, "field"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "common", "theme", "of", "this", "work", "is", "the", "application", "of", "a", "sign", "-", "theoretic", "perspective", "to", "issues", "of", "artificial", "intelligence", "and", "knowledge", "representation", "."], "sentence-detokenized": "The common theme of this work is the application of a sign-theoretic perspective to issues of artificial intelligence and knowledge representation.", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 19], [20, 24], [25, 29], [30, 32], [33, 36], [37, 48], [49, 51], [52, 53], [54, 58], [58, 59], [59, 68], [69, 80], [81, 83], [84, 90], [91, 93], [94, 104], [105, 117], [118, 121], [122, 131], [132, 146], [146, 147]]}
{"doc_key": "ai-test-62", "ner": [[5, 7, "task"], [9, 9, "task"], [15, 16, "task"], [40, 41, "task"], [43, 44, "task"], [47, 49, "task"], [51, 51, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 7, 15, 16, "type-of", "", false, false], [5, 7, 47, 49, "compare", "", false, false], [5, 7, 47, 49, "opposite", "", false, false], [9, 9, 5, 7, "named", "", false, false], [40, 41, 47, 49, "part-of", "", false, false], [43, 44, 47, 49, "part-of", "", false, false], [47, 49, 15, 16, "type-of", "", false, false], [51, 51, 47, 49, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["For", "example", ",", "the", "term", "neural", "machine", "translation", "(", "NMT", ")", "highlights", "the", "fact", "that", "machine", "translation", "approaches", "based", "on", "deep", "learning", "directly", "learn", "sequence", "-", "to", "-", "sequence", "transformations", ",", "thus", "removing", "the", "need", "for", "intermediate", "steps", "such", "as", "word", "alignment", "and", "language", "modelling", "used", "in", "statistical", "machine", "translation", "(", "SMT", ")", "."], "sentence-detokenized": "For example, the term neural machine translation (NMT) highlights the fact that machine translation approaches based on deep learning directly learn sequence-to-sequence transformations, thus removing the need for intermediate steps such as word alignment and language modelling used in statistical machine translation (SMT).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 36], [37, 48], [49, 50], [50, 53], [53, 54], [55, 65], [66, 69], [70, 74], [75, 79], [80, 87], [88, 99], [100, 110], [111, 116], [117, 119], [120, 124], [125, 133], [134, 142], [143, 148], [149, 157], [157, 158], [158, 160], [160, 161], [161, 169], [170, 185], [185, 186], [187, 191], [192, 200], [201, 204], [205, 209], [210, 213], [214, 226], [227, 232], [233, 237], [238, 240], [241, 245], [246, 255], [256, 259], [260, 268], [269, 278], [279, 283], [284, 286], [287, 298], [299, 306], [307, 318], [319, 320], [320, 323], [323, 324], [324, 325]]}
{"doc_key": "ai-test-63", "ner": [[8, 9, "field"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 13, 14, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "of", "the", "research", "in", "the", "field", "of", "WSD", "has", "been", "done", "using", "Word", "Net", "as", "a", "reference", "list", "of", "meanings", "."], "sentence-detokenized": "Most of the research in the field of WSD has been done using WordNet as a reference list of meanings.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 20], [21, 23], [24, 27], [28, 33], [34, 36], [37, 40], [41, 44], [45, 49], [50, 54], [55, 60], [61, 65], [65, 68], [69, 71], [72, 73], [74, 83], [84, 88], [89, 91], [92, 100], [100, 101]]}
{"doc_key": "ai-test-64", "ner": [[1, 1, "misc"], [10, 11, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 1, 1, "general-affiliation", "", false, true], [13, 14, 1, 1, "general-affiliation", "", false, true]], "relations_mapping_to_source": [0, 1], "sentence": ["Former", "PhD", "students", "and", "postdoctoral", "researchers", "in", "his", "group", "include", "Richard", "Zemel", "and", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Former PhD students and postdoctoral researchers in his group include Richard Zemel and Zoubin Ghahramani.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 23], [24, 36], [37, 48], [49, 51], [52, 55], [56, 61], [62, 69], [70, 77], [78, 83], [84, 87], [88, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-test-65", "ner": [[4, 5, "metrics"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 11, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Each", "prediction", "result", "or", "confusion", "matrix", "instance", "represents", "one", "point", "in", "ROC", "space", "."], "sentence-detokenized": "Each prediction result or confusion matrix instance represents one point in ROC space.", "token2charspan": [[0, 4], [5, 15], [16, 22], [23, 25], [26, 35], [36, 42], [43, 51], [52, 62], [63, 66], [67, 72], [73, 75], [76, 79], [80, 85], [85, 86]]}
{"doc_key": "ai-test-66", "ner": [[3, 3, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [6, 11, "product"], [22, 24, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 22, 24, "physical", "", false, false], [15, 16, 22, 24, "physical", "", false, false], [18, 19, 22, 24, "physical", "", false, false], [6, 11, 3, 3, "artifact", "", false, false], [6, 11, 15, 16, "artifact", "", false, false], [6, 11, 18, 19, "artifact", "", false, false], [6, 11, 22, 24, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1997", ",", "Thrun", "developed", "the", "world", "'s", "first", "robotic", "tour", "guide", "with", "his", "colleagues", "Wolfram", "Burgard", "and", "Dieter", "Fox", "at", "the", "Deutsches", "Museum", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "In 1997, Thrun developed the world's first robotic tour guide with his colleagues Wolfram Burgard and Dieter Fox at the Deutsches Museum Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 24], [25, 28], [29, 34], [34, 36], [37, 42], [43, 50], [51, 55], [56, 61], [62, 66], [67, 70], [71, 81], [82, 89], [90, 97], [98, 101], [102, 108], [109, 112], [113, 115], [116, 119], [120, 129], [130, 136], [137, 141], [142, 143], [143, 147], [147, 148], [148, 149]]}
{"doc_key": "ai-test-67", "ner": [[0, 1, "product"], [7, 7, "misc"], [21, 23, "field"], [25, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 1, "part-of", "", false, false], [21, 23, 0, 1, "usage", "", false, false], [25, 27, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "of", "semantic", "relations", "between", "words", "in", "more", "than", "200", "languages", ",", "used", "primarily", "for", "automatic", "natural", "language", "processing", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database of semantic relations between words in more than 200 languages, used primarily for automatic natural language processing and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 32], [33, 41], [42, 51], [52, 59], [60, 65], [66, 68], [69, 73], [74, 78], [79, 82], [83, 92], [92, 93], [94, 98], [99, 108], [109, 112], [113, 122], [123, 130], [131, 139], [140, 150], [151, 154], [155, 165], [166, 178], [179, 191], [191, 192]]}
{"doc_key": "ai-test-68", "ner": [[9, 11, "field"], [16, 19, "conference"], [22, 30, "conference"], [32, 32, "conference"], [34, 34, "conference"], [2, 3, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[16, 19, 9, 11, "topic", "", false, false], [16, 19, 2, 3, "topic", "", false, false], [22, 30, 9, 11, "topic", "", false, false], [22, 30, 2, 3, "topic", "", false, false], [32, 32, 9, 11, "topic", "", false, false], [32, 32, 2, 3, "topic", "", false, false], [34, 34, 9, 11, "topic", "", false, false], [34, 34, 2, 3, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Papers", "on", "speech", "processing", "are", "starting", "to", "appear", "at", "natural", "language", "processing", "conferences", "such", "as", "the", "Association", "for", "Computational", "Linguistics", ",", "the", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", "and", "HLT", "."], "sentence-detokenized": "Papers on speech processing are starting to appear at natural language processing conferences such as the Association for Computational Linguistics, the North American Chapter of the Association for Computational Linguistics, EMNLP and HLT.", "token2charspan": [[0, 6], [7, 9], [10, 16], [17, 27], [28, 31], [32, 40], [41, 43], [44, 50], [51, 53], [54, 61], [62, 70], [71, 81], [82, 93], [94, 98], [99, 101], [102, 105], [106, 117], [118, 121], [122, 135], [136, 147], [147, 148], [149, 152], [153, 158], [159, 167], [168, 175], [176, 178], [179, 182], [183, 194], [195, 198], [199, 212], [213, 224], [224, 225], [226, 231], [232, 235], [236, 239], [239, 240]]}
{"doc_key": "ai-test-69", "ner": [[3, 3, "programlang"], [19, 27, "misc"], [33, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "set", "of", "Java", "programs", "uses", "a", "lexicon", "to", "read", "versions", "of", "biomedical", "texts", "by", "linking", "words", "by", "their", "parts", "of", "speech", ",", "which", "can", "be", "useful", "for", "web", "searches", "or", "searching", "an", "electronic", "health", "record", "."], "sentence-detokenized": "A set of Java programs uses a lexicon to read versions of biomedical texts by linking words by their parts of speech, which can be useful for web searches or searching an electronic health record.", "token2charspan": [[0, 1], [2, 5], [6, 8], [9, 13], [14, 22], [23, 27], [28, 29], [30, 37], [38, 40], [41, 45], [46, 54], [55, 57], [58, 68], [69, 74], [75, 77], [78, 85], [86, 91], [92, 94], [95, 100], [101, 106], [107, 109], [110, 116], [116, 117], [118, 123], [124, 127], [128, 130], [131, 137], [138, 141], [142, 145], [146, 154], [155, 157], [158, 167], [168, 170], [171, 181], [182, 188], [189, 195], [195, 196]]}
{"doc_key": "ai-test-70", "ner": [[7, 7, "algorithm"], [9, 9, "algorithm"], [11, 11, "algorithm"], [13, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "many", "newer", "algorithms", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", "and", "others", "."], "sentence-detokenized": "There are many newer algorithms such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost and others.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 20], [21, 31], [32, 36], [37, 39], [40, 47], [47, 48], [49, 59], [59, 60], [61, 71], [71, 72], [73, 80], [80, 81], [82, 91], [92, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-test-71", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "of", "a", "Python", "implementation", ":"], "sentence-detokenized": "This is an example of a Python implementation:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 23], [24, 30], [31, 45], [45, 46]]}
{"doc_key": "ai-test-72", "ner": [[0, 1, "organisation"], [2, 2, "product"], [7, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 0, 1, "artifact", "made_by_company", false, false], [7, 12, 2, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mattel", "'s", "Intellivision", "game", "console", "offered", "the", "Intellivoice", "voice", "synthesis", "module", "in", "1982", "."], "sentence-detokenized": "Mattel's Intellivision game console offered the Intellivoice voice synthesis module in 1982.", "token2charspan": [[0, 6], [6, 8], [9, 22], [23, 27], [28, 35], [36, 43], [44, 47], [48, 60], [61, 66], [67, 76], [77, 83], [84, 86], [87, 91], [91, 92]]}
{"doc_key": "ai-test-73", "ner": [[5, 8, "task"], [10, 16, "task"], [19, 20, "field"], [22, 24, "task"], [27, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 16, 5, 8, "part-of", "", false, false], [19, 20, 5, 8, "part-of", "", false, false], [22, 24, 5, 8, "part-of", "", false, false], [27, 31, 22, 24, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "has", "also", "worked", "in", "machine", "translation", ",", "both", "in", "high", "-", "precision", "knowledge", "-", "based", "MT", "and", "in", "machine", "learning", "for", "statistical", "machine", "translation", "(", "e.g.", "generalised", "case", "-", "based", "MT", ")", "."], "sentence-detokenized": "He has also worked in machine translation, both in high-precision knowledge-based MT and in machine learning for statistical machine translation (e.g. generalised case-based MT).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 21], [22, 29], [30, 41], [41, 42], [43, 47], [48, 50], [51, 55], [55, 56], [56, 65], [66, 75], [75, 76], [76, 81], [82, 84], [85, 88], [89, 91], [92, 99], [100, 108], [109, 112], [113, 124], [125, 132], [133, 144], [145, 146], [146, 150], [151, 162], [163, 167], [167, 168], [168, 173], [174, 176], [176, 177], [177, 178]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [5, 5, "misc"], [20, 21, "algorithm"], [23, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 32, "field"], [34, 34, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 20, 21, "general-affiliation", "", false, false], [0, 1, 23, 24, "general-affiliation", "", false, false], [0, 1, 26, 27, "general-affiliation", "", false, false], [0, 1, 29, 29, "general-affiliation", "", false, false], [0, 1, 31, 32, "general-affiliation", "", false, false], [0, 1, 34, 34, "general-affiliation", "", false, false], [5, 5, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "commonly", "called", "Mathematica", ")", "is", "a", "modern", "technical", "computing", "system", "that", "covers", "most", "technical", "areas", "-", "including", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "data", "science", ",", "visualisations", "and", "more", "."], "sentence-detokenized": "Wolfram Mathematica (commonly called Mathematica) is a modern technical computing system that covers most technical areas - including neural networks, machine learning, image processing, geometry, data science, visualisations and more.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 29], [30, 36], [37, 48], [48, 49], [50, 52], [53, 54], [55, 61], [62, 71], [72, 81], [82, 88], [89, 93], [94, 100], [101, 105], [106, 115], [116, 121], [122, 123], [124, 133], [134, 140], [141, 149], [149, 150], [151, 158], [159, 167], [167, 168], [169, 174], [175, 185], [185, 186], [187, 195], [195, 196], [197, 201], [202, 209], [209, 210], [211, 225], [226, 229], [230, 234], [234, 235]]}
{"doc_key": "ai-test-75", "ner": [[2, 7, "product"], [12, 15, "researcher"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 18, 2, 7, "type-of", "", false, false], [18, 18, 12, 15, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "digitally", "controlled", "and", "programmable", "robot", "was", "invented", "in", "1954", "by", "George", "Devol", ",", "who", "called", "it", "Unimate", "."], "sentence-detokenized": "The first digitally controlled and programmable robot was invented in 1954 by George Devol, who called it Unimate.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 30], [31, 34], [35, 47], [48, 53], [54, 57], [58, 66], [67, 69], [70, 74], [75, 77], [78, 84], [85, 90], [90, 91], [92, 95], [96, 102], [103, 105], [106, 113], [113, 114]]}
{"doc_key": "ai-test-76", "ner": [[2, 2, "algorithm"], [4, 4, "algorithm"], [19, 20, "task"], [22, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 4, 4, "compare", "", false, false], [4, 4, 19, 20, "general-affiliation", "", false, false], [4, 4, 22, 25, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Similar", "to", "DBNs", ",", "DBMs", "can", "learn", "complex", "and", "abstract", "internal", "representations", "of", "input", "data", "in", "tasks", "such", "as", "object", "recognition", "or", "speech", "recognition", ",", "using", "limited", "labelled", "data", "to", "fine", "-", "tune", "the", "representations", "generated", "from", "a", "large", "set", "of", "unlabelled", "sensory", "input", "data", "."], "sentence-detokenized": "Similar to DBNs, DBMs can learn complex and abstract internal representations of input data in tasks such as object recognition or speech recognition, using limited labelled data to fine-tune the representations generated from a large set of unlabelled sensory input data.", "token2charspan": [[0, 7], [8, 10], [11, 15], [15, 16], [17, 21], [22, 25], [26, 31], [32, 39], [40, 43], [44, 52], [53, 61], [62, 77], [78, 80], [81, 86], [87, 91], [92, 94], [95, 100], [101, 105], [106, 108], [109, 115], [116, 127], [128, 130], [131, 137], [138, 149], [149, 150], [151, 156], [157, 164], [165, 173], [174, 178], [179, 181], [182, 186], [186, 187], [187, 191], [192, 195], [196, 211], [212, 221], [222, 226], [227, 228], [229, 234], [235, 238], [239, 241], [242, 252], [253, 260], [261, 266], [267, 271], [271, 272]]}
{"doc_key": "ai-test-77", "ner": [[5, 12, "task"], [14, 14, "conference"], [16, 16, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 5, 12, "topic", "", false, false], [16, 16, 5, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Scientific", "conferences", "where", "work", "on", "vision", "-", "based", "activity", "recognition", "is", "often", "presented", "include", "ICCV", "and", "CVPR", "."], "sentence-detokenized": "Scientific conferences where work on vision-based activity recognition is often presented include ICCV and CVPR.", "token2charspan": [[0, 10], [11, 22], [23, 28], [29, 33], [34, 36], [37, 43], [43, 44], [44, 49], [50, 58], [59, 70], [71, 73], [74, 79], [80, 89], [90, 97], [98, 102], [103, 106], [107, 111], [111, 112]]}
{"doc_key": "ai-test-78", "ner": [[1, 11, "field"], [4, 5, "algorithm"], [7, 7, "algorithm"], [17, 18, "metrics"], [20, 22, "metrics"], [25, 27, "metrics"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 5, 1, 11, "part-of", "", false, false], [4, 5, 17, 18, "related-to", "finds", false, false], [4, 5, 20, 22, "related-to", "finds", false, false], [4, 5, 38, 39, "related-to", "", false, false], [7, 7, 4, 5, "named", "", false, false], [25, 27, 20, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "statistics", ",", "the", "expectation", "maximisation", "(", "EM", ")", "algorithm", "is", "an", "iterative", "method", "for", "finding", "the", "maximum", "likelihood", "or", "maximum", "a", "posteriori", "estimate", "(", "MAP", ")", "of", "parameters", "in", "statistical", "models", "where", "the", "model", "depends", "on", "unobserved", "latent", "variables", "."], "sentence-detokenized": "In statistics, the expectation maximisation (EM) algorithm is an iterative method for finding the maximum likelihood or maximum a posteriori estimate (MAP) of parameters in statistical models where the model depends on unobserved latent variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 30], [31, 43], [44, 45], [45, 47], [47, 48], [49, 58], [59, 61], [62, 64], [65, 74], [75, 81], [82, 85], [86, 93], [94, 97], [98, 105], [106, 116], [117, 119], [120, 127], [128, 129], [130, 140], [141, 149], [150, 151], [151, 154], [154, 155], [156, 158], [159, 169], [170, 172], [173, 184], [185, 191], [192, 197], [198, 201], [202, 207], [208, 215], [216, 218], [219, 229], [230, 236], [237, 246], [246, 247]]}
{"doc_key": "ai-test-79", "ner": [[5, 16, "metrics"], [8, 10, "metrics"], [11, 12, "metrics"], [14, 14, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 10, 5, 16, "named", "", false, false], [14, 14, 11, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Similarly", ",", "investigators", "sometimes", "report", "false", "positive", "(", "FPR", ")", "and", "false", "negative", "(", "FNR", ")", "rates", "."], "sentence-detokenized": "Similarly, investigators sometimes report false positive (FPR) and false negative (FNR) rates.", "token2charspan": [[0, 9], [9, 10], [11, 24], [25, 34], [35, 41], [42, 47], [48, 56], [57, 58], [58, 61], [61, 62], [63, 66], [67, 72], [73, 81], [82, 83], [83, 86], [86, 87], [88, 93], [93, 94]]}
{"doc_key": "ai-test-80", "ner": [[6, 12, "metrics"], [14, 14, "field"], [17, 19, "metrics"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 14, 6, 12, "usage", "", false, false], [21, 22, 17, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "concept", "is", "similar", "to", "the", "signal", "-", "to", "-", "noise", "ratio", "used", "in", "science", "and", "the", "confusion", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "The concept is similar to the signal-to-noise ratio used in science and the confusion matrix used in artificial intelligence.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 25], [26, 29], [30, 36], [36, 37], [37, 39], [39, 40], [40, 45], [46, 51], [52, 56], [57, 59], [60, 67], [68, 71], [72, 75], [76, 85], [86, 92], [93, 97], [98, 100], [101, 111], [112, 124], [124, 125]]}
{"doc_key": "ai-test-81", "ner": [[5, 6, "field"], [11, 15, "researcher"], [18, 19, "researcher"], [21, 27, "researcher"], [31, 35, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 11, 15, "general-affiliation", "", false, false], [5, 6, 18, 19, "general-affiliation", "", false, false], [5, 6, 21, 27, "general-affiliation", "", false, false], [31, 35, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Code", "of", "Ethics", "on", "Human", "Augmentation", ",", "originally", "presented", "by", "Steve", "Mann", "in", "2004", "and", "refined", "by", "Ray", "Kurzweil", "and", "Marvin", "Minsky", "in", "2013", ",", "was", "finally", "endorsed", "at", "the", "Virtual", "Reality", "Conference", "in", "Toronto", "on", "25", "June", "2017", "."], "sentence-detokenized": "The Code of Ethics on Human Augmentation, originally presented by Steve Mann in 2004 and refined by Ray Kurzweil and Marvin Minsky in 2013, was finally endorsed at the Virtual Reality Conference in Toronto on 25 June 2017.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 18], [19, 21], [22, 27], [28, 40], [40, 41], [42, 52], [53, 62], [63, 65], [66, 71], [72, 76], [77, 79], [80, 84], [85, 88], [89, 96], [97, 99], [100, 103], [104, 112], [113, 116], [117, 123], [124, 130], [131, 133], [134, 138], [138, 139], [140, 143], [144, 151], [152, 160], [161, 163], [164, 167], [168, 175], [176, 183], [184, 194], [195, 197], [198, 205], [206, 208], [209, 211], [212, 216], [217, 221], [221, 222]]}
{"doc_key": "ai-test-82", "ner": [[3, 5, "person"], [11, 12, "organisation"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 11, 12, "role", "directed_for", false, false], [3, 5, 18, 19, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", ",", "Walter", "R.", "Booth", "directed", "10", "films", "for", "the", "British", "Cinoplasticon", ",", "probably", "in", "collaboration", "with", "Cecil", "Hepworth", "."], "sentence-detokenized": "In 1913, Walter R. Booth directed 10 films for the British Cinoplasticon, probably in collaboration with Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 18], [19, 24], [25, 33], [34, 36], [37, 42], [43, 46], [47, 50], [51, 58], [59, 72], [72, 73], [74, 82], [83, 85], [86, 99], [100, 104], [105, 110], [111, 119], [119, 120]]}
{"doc_key": "ai-test-83", "ner": [[9, 9, "location"], [10, 11, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 9, 9, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "new", "robot", "was", "unveiled", "in", "1961", "at", "the", "Chicago", "Cow", "Palace", "."], "sentence-detokenized": "The new robot was unveiled in 1961 at the Chicago Cow Palace.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 17], [18, 26], [27, 29], [30, 34], [35, 37], [38, 41], [42, 49], [50, 53], [54, 60], [60, 61]]}
{"doc_key": "ai-test-84", "ner": [[1, 1, "product"], [5, 6, "task"], [8, 9, "field"], [13, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 5, 6, "usage", "", false, false], [1, 1, 8, 9, "usage", "", false, false], [1, 1, 13, 16, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Some", "chatbot", "applications", "use", "extensive", "word", "sorting", ",", "natural", "language", "processors", "and", "sophisticated", "artificial", "intelligence", ",", "while", "others", "simply", "search", "for", "common", "keywords", "and", "generate", "answers", "using", "common", "phrases", "extracted", "from", "a", "linked", "library", "or", "database", "."], "sentence-detokenized": "Some chatbot applications use extensive word sorting, natural language processors and sophisticated artificial intelligence, while others simply search for common keywords and generate answers using common phrases extracted from a linked library or database.", "token2charspan": [[0, 4], [5, 12], [13, 25], [26, 29], [30, 39], [40, 44], [45, 52], [52, 53], [54, 61], [62, 70], [71, 81], [82, 85], [86, 99], [100, 110], [111, 123], [123, 124], [125, 130], [131, 137], [138, 144], [145, 151], [152, 155], [156, 162], [163, 171], [172, 175], [176, 184], [185, 192], [193, 198], [199, 205], [206, 213], [214, 223], [224, 228], [229, 230], [231, 237], [238, 245], [246, 248], [249, 257], [257, 258]]}
{"doc_key": "ai-test-85", "ner": [[1, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "WaveNet", "model", ",", "proposed", "in", "2016", ",", "achieves", "excellent", "results", "in", "speech", "quality", "."], "sentence-detokenized": "The WaveNet model, proposed in 2016, achieves excellent results in speech quality.", "token2charspan": [[0, 3], [4, 11], [12, 17], [17, 18], [19, 27], [28, 30], [31, 35], [35, 36], [37, 45], [46, 55], [56, 63], [64, 66], [67, 73], [74, 81], [81, 82]]}
{"doc_key": "ai-test-86", "ner": [[4, 4, "product"], [6, 7, "misc"], [9, 10, "misc"], [12, 13, "misc"], [15, 16, "misc"], [19, 21, "organisation"], [23, 23, "organisation"], [25, 28, "organisation"], [30, 30, "organisation"], [32, 35, "organisation"], [37, 38, "organisation"], [40, 40, "organisation"], [42, 44, "organisation"], [46, 46, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 4, 6, 7, "general-affiliation", "", false, false], [4, 4, 9, 10, "general-affiliation", "", false, false], [4, 4, 12, 13, "general-affiliation", "", false, false], [4, 4, 15, 16, "general-affiliation", "", false, false], [19, 21, 4, 4, "usage", "", false, false], [23, 23, 4, 4, "usage", "", false, false], [25, 28, 4, 4, "usage", "", false, false], [30, 30, 4, 4, "usage", "", false, false], [32, 35, 4, 4, "usage", "", false, false], [37, 38, 4, 4, "usage", "", false, false], [40, 40, 4, 4, "usage", "", false, false], [42, 44, 4, 4, "usage", "", false, false], [46, 46, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organisations", "known", "to", "use", "ALE", "for", "emergency", "management", ",", "disaster", "relief", ",", "normal", "communications", "or", "emergency", "response", ":", "the", "American", "Red", "Cross", ",", "FEMA", ",", "Disaster", "Medical", "Assistance", "Teams", ",", "NATO", ",", "Federal", "Bureau", "of", "Investigation", ",", "United", "Nations", ",", "AT&T", ",", "Civil", "Air", "Patrol", "(", "ARES", ")", "."], "sentence-detokenized": "Organisations known to use ALE for emergency management, disaster relief, normal communications or emergency response: the American Red Cross, FEMA, Disaster Medical Assistance Teams, NATO, Federal Bureau of Investigation, United Nations, AT&T, Civil Air Patrol (ARES).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 30], [31, 34], [35, 44], [45, 55], [55, 56], [57, 65], [66, 72], [72, 73], [74, 80], [81, 95], [96, 98], [99, 108], [109, 117], [117, 118], [119, 122], [123, 131], [132, 135], [136, 141], [141, 142], [143, 147], [147, 148], [149, 157], [158, 165], [166, 176], [177, 182], [182, 183], [184, 188], [188, 189], [190, 197], [198, 204], [205, 207], [208, 221], [221, 222], [223, 229], [230, 237], [237, 238], [239, 243], [243, 244], [245, 250], [251, 254], [255, 261], [262, 263], [263, 267], [267, 268], [268, 269]]}
{"doc_key": "ai-test-87", "ner": [[4, 8, "algorithm"], [15, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "simplicity", ",", "the", "Kronecker", "delta", "is", "used", "here", "(", "cf", ".", "the", "derivative", "of", "the", "sigmoid", "function", ",", "which", "is", "expressed", "by", "the", "function", "itself", ")", "."], "sentence-detokenized": "For simplicity, the Kronecker delta is used here (cf. the derivative of the sigmoid function, which is expressed by the function itself).", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 29], [30, 35], [36, 38], [39, 43], [44, 48], [49, 50], [50, 52], [52, 53], [54, 57], [58, 68], [69, 71], [72, 75], [76, 83], [84, 92], [92, 93], [94, 99], [100, 102], [103, 112], [113, 115], [116, 119], [120, 128], [129, 135], [135, 136], [136, 137]]}
{"doc_key": "ai-test-88", "ner": [[12, 13, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "theory", "is", "based", "on", "philosophical", "foundations", ",", "and", "was", "founded", "by", "Ray", "Solomonoff", "around", "1960", ".", "Samuel", "Rathmanner", "and", "Marcus", "Hutter", "."], "sentence-detokenized": "The theory is based on philosophical foundations, and was founded by Ray Solomonoff around 1960. Samuel Rathmanner and Marcus Hutter.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 36], [37, 48], [48, 49], [50, 53], [54, 57], [58, 65], [66, 68], [69, 72], [73, 83], [84, 90], [91, 95], [95, 96], [97, 103], [104, 114], [115, 118], [119, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [10, 12, "misc"], [14, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 12, "type-of", "", false, false], [0, 0, 14, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "a", "freely", "accessible", "database", "originally", "conceived", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "has", "been", "extended", "by", "adding", "definitions", "and", "is", "now", "also", "considered", "as", "a", "dictionary", "."], "sentence-detokenized": "WordNet, a freely accessible database originally conceived as a semantic network based on psycholinguistic principles, has been extended by adding definitions and is now also considered as a dictionary.", "token2charspan": [[0, 7], [7, 8], [9, 10], [11, 17], [18, 28], [29, 37], [38, 48], [49, 58], [59, 61], [62, 63], [64, 72], [73, 80], [81, 86], [87, 89], [90, 106], [107, 117], [117, 118], [119, 122], [123, 127], [128, 136], [137, 139], [140, 146], [147, 158], [159, 162], [163, 165], [166, 169], [170, 174], [175, 185], [186, 188], [189, 190], [191, 201], [201, 202]]}
{"doc_key": "ai-test-90", "ner": [[2, 7, "field"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 2, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Advances", "in", "computer", "imaging", "research", "are", "presented", "in", "several", "places", ",", "including", "SIGGRAPH", "and", "."], "sentence-detokenized": "Advances in computer imaging research are presented in several places, including SIGGRAPH and.", "token2charspan": [[0, 8], [9, 11], [12, 20], [21, 28], [29, 37], [38, 41], [42, 51], [52, 54], [55, 62], [63, 69], [69, 70], [71, 80], [81, 89], [90, 93], [93, 94]]}
{"doc_key": "ai-test-91", "ner": [[0, 0, "task"], [10, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 0, 0, "part-of", "", false, false], [13, 14, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "thought", "of", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multi-class", "classification", "."], "sentence-detokenized": "Classification can be thought of as two separate problems - binary classification and multi-class classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 29], [30, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 97], [98, 112], [112, 113]]}
{"doc_key": "ai-test-92", "ner": [[12, 12, "algorithm"], [17, 18, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 12, 12, "type-of", "", false, false], [21, 21, 17, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Advanced", "gene", "search", "engines", "for", "prokaryotic", "and", "eukaryotic", "genomes", "typically", "use", "complex", "probabilistic", "models", ",", "such", "as", "Hidden", "Markov", "Models", "(", "HMMs", ")", ",", "which", "combine", "information", "from", "different", "signal", "and", "content", "measurements", "."], "sentence-detokenized": "Advanced gene search engines for prokaryotic and eukaryotic genomes typically use complex probabilistic models, such as Hidden Markov Models (HMMs), which combine information from different signal and content measurements.", "token2charspan": [[0, 8], [9, 13], [14, 20], [21, 28], [29, 32], [33, 44], [45, 48], [49, 59], [60, 67], [68, 77], [78, 81], [82, 89], [90, 103], [104, 110], [110, 111], [112, 116], [117, 119], [120, 126], [127, 133], [134, 140], [141, 142], [142, 146], [146, 147], [147, 148], [149, 154], [155, 162], [163, 174], [175, 179], [180, 189], [190, 196], [197, 200], [201, 208], [209, 221], [221, 222]]}
{"doc_key": "ai-test-93", "ner": [[0, 0, "misc"], [2, 2, "misc"], [7, 9, "field"], [11, 12, "algorithm"], [15, 16, "algorithm"], [19, 19, "algorithm"], [29, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 7, 9, "part-of", "", false, false], [0, 0, 11, 12, "usage", "", false, false], [2, 2, 0, 0, "named", "", false, false], [15, 16, 0, 0, "origin", "", true, false], [19, 19, 15, 16, "named", "", false, false], [29, 30, 0, 0, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Neuroevolution", "or", "neuroevolution", "is", "a", "form", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "create", "artificial", "neural", "networks", "(", "ANNs", ")", ",", "parameters", ",", "topologies", "and", "rules", ".", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuroevolution or neuroevolution is a form of artificial intelligence that uses evolutionary algorithms to create artificial neural networks (ANNs), parameters, topologies and rules. and evolutionary robotics.", "token2charspan": [[0, 14], [15, 17], [18, 32], [33, 35], [36, 37], [38, 42], [43, 45], [46, 56], [57, 69], [70, 74], [75, 79], [80, 92], [93, 103], [104, 106], [107, 113], [114, 124], [125, 131], [132, 140], [141, 142], [142, 146], [146, 147], [147, 148], [149, 159], [159, 160], [161, 171], [172, 175], [176, 181], [181, 182], [183, 186], [187, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [6, 6, "metrics"], [8, 8, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "IBM", "proposed", "and", "implemented", "the", "BLEU", "system", "Papineni", "et", "al", "."], "sentence-detokenized": "Since IBM proposed and implemented the BLEU system Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 34], [35, 38], [39, 43], [44, 50], [51, 59], [60, 62], [63, 65], [65, 66]]}
{"doc_key": "ai-test-95", "ner": [[9, 16, "conference"], [18, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 20, 9, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "experts", "attended", "a", "conference", "organised", "by", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "to", "discuss", "whether", "computers", "and", "robots", "will", "be", "able", "to", "gain", "any", "autonomy", "and", "to", "what", "extent", "these", "capabilities", "could", "pose", "a", "threat", "or", "a", "danger", "."], "sentence-detokenized": "In 2009, experts attended a conference organised by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether computers and robots will be able to gain any autonomy and to what extent these capabilities could pose a threat or a danger.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 25], [26, 27], [28, 38], [39, 48], [49, 51], [52, 55], [56, 67], [68, 71], [72, 75], [76, 87], [88, 90], [91, 101], [102, 114], [115, 116], [116, 120], [120, 121], [122, 124], [125, 132], [133, 140], [141, 150], [151, 154], [155, 161], [162, 166], [167, 169], [170, 174], [175, 177], [178, 182], [183, 186], [187, 195], [196, 199], [200, 202], [203, 207], [208, 214], [215, 220], [221, 233], [234, 239], [240, 244], [245, 246], [247, 253], [254, 256], [257, 258], [259, 265], [265, 266]]}
{"doc_key": "ai-test-96", "ner": [[22, 24, "researcher"], [26, 27, "researcher"], [29, 34, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[29, 34, 22, 24, "artifact", "", false, false], [29, 34, 26, 27, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["A", "classifier", "consisting", "of", "200", "features", "can", "provide", "a", "95", "%", "detection", "rate", "at", "^", "{", "-", "5", "}", "after", "boosting", "/", "P", ".", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "A classifier consisting of 200 features can provide a 95% detection rate at ^ {-5} after boosting / P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 1], [2, 12], [13, 23], [24, 26], [27, 30], [31, 39], [40, 43], [44, 51], [52, 53], [54, 56], [56, 57], [58, 67], [68, 72], [73, 75], [76, 77], [78, 79], [79, 80], [80, 81], [81, 82], [83, 88], [89, 97], [98, 99], [100, 101], [101, 102], [103, 108], [108, 109], [110, 112], [113, 118], [118, 119], [120, 126], [127, 131], [131, 132], [132, 136], [137, 143], [144, 153], [153, 154], [155, 159], [159, 160]]}
{"doc_key": "ai-test-97", "ner": [[6, 6, "programlang"], [9, 12, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "website", "was", "originally", "based", "on", "Perl", ",", "but", "for", "security", "reasons", "IMDb", "no", "longer", "discloses", "which", "software", "it", "uses", "."], "sentence-detokenized": "The website was originally based on Perl, but for security reasons IMDb no longer discloses which software it uses.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 26], [27, 32], [33, 35], [36, 40], [40, 41], [42, 45], [46, 49], [50, 58], [59, 66], [67, 71], [72, 74], [75, 81], [82, 91], [92, 97], [98, 106], [107, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-test-98", "ner": [[9, 10, "researcher"], [12, 13, "researcher"], [15, 16, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "start", "-", "up", "was", "founded", "in", "2010", "by", "Demis", "Hassabis", ",", "Shane", "Legg", "and", "Mustafa", "Suleyman", "."], "sentence-detokenized": "The start-up was founded in 2010 by Demis Hassabis, Shane Legg and Mustafa Suleyman.", "token2charspan": [[0, 3], [4, 9], [9, 10], [10, 12], [13, 16], [17, 24], [25, 27], [28, 32], [33, 35], [36, 41], [42, 50], [50, 51], [52, 57], [58, 62], [63, 66], [67, 74], [75, 83], [83, 84]]}
{"doc_key": "ai-test-99", "ner": [[4, 5, "misc"], [8, 11, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 4, 5, "type-of", "", false, false], [24, 25, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "very", "commonly", "used", "loss", "functions", "are", "the", "root", "mean", "square", "error", ",", "mathL", "(", "a", ")", "=", "a^2", "/", "math", ",", "and", "the", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Two very commonly used loss functions are the root mean square error, mathL (a) = a^2/math, and the absolute loss, mathL (a) = | a | / math.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 27], [28, 37], [38, 41], [42, 45], [46, 50], [51, 55], [56, 62], [63, 68], [68, 69], [70, 75], [76, 77], [77, 78], [78, 79], [80, 81], [82, 85], [85, 86], [86, 90], [90, 91], [92, 95], [96, 99], [100, 108], [109, 113], [113, 114], [115, 120], [121, 122], [122, 123], [123, 124], [125, 126], [127, 128], [129, 130], [131, 132], [133, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-test-100", "ner": [[0, 5, "algorithm"], [14, 16, "algorithm"], [18, 20, "algorithm"], [21, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 5, 14, 16, "type-of", "example_of", false, false], [14, 16, 21, 23, "related-to", "", false, false], [18, 20, 14, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "support", "vector", "machine", "with", "a", "fuzzy", "frontier", "described", "above", "is", "an", "example", "of", "empirical", "risk", "minimisation", "(", "ERM", ")", "for", "exchange", "rate", "losses", "."], "sentence-detokenized": "The support vector machine with a fuzzy frontier described above is an example of empirical risk minimisation (ERM) for exchange rate losses.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 26], [27, 31], [32, 33], [34, 39], [40, 48], [49, 58], [59, 64], [65, 67], [68, 70], [71, 78], [79, 81], [82, 91], [92, 96], [97, 109], [110, 111], [111, 114], [114, 115], [116, 119], [120, 128], [129, 133], [134, 140], [140, 141]]}
{"doc_key": "ai-test-101", "ner": [[5, 7, "field"], [0, 2, "task"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[0, 2, 5, 7, "origin", "", false, false], [15, 15, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["Neural", "machine", "translation", "based", "on", "deep", "learning", "has", "advanced", "rapidly", "in", "recent", "years", ",", "and", "Google", "has", "announced", "that", "its", "translation", "services", "now", "use", "this", "technology", "instead", "of", "previous", "statistical", "methods", "."], "sentence-detokenized": "Neural machine translation based on deep learning has advanced rapidly in recent years, and Google has announced that its translation services now use this technology instead of previous statistical methods.", "token2charspan": [[0, 6], [7, 14], [15, 26], [27, 32], [33, 35], [36, 40], [41, 49], [50, 53], [54, 62], [63, 70], [71, 73], [74, 80], [81, 86], [86, 87], [88, 91], [92, 98], [99, 102], [103, 112], [113, 117], [118, 121], [122, 133], [134, 142], [143, 146], [147, 150], [151, 155], [156, 166], [167, 174], [175, 177], [178, 186], [187, 198], [199, 206], [206, 207]]}
{"doc_key": "ai-test-102", "ner": [[7, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "working", "with", "large", "corpora", "such", "as", "WordNet", ",", "this", "usually", "increases", "performance", "significantly", "."], "sentence-detokenized": "When working with large corpora such as WordNet, this usually increases performance significantly.", "token2charspan": [[0, 4], [5, 12], [13, 17], [18, 23], [24, 31], [32, 36], [37, 39], [40, 47], [47, 48], [49, 53], [54, 61], [62, 71], [72, 83], [84, 97], [97, 98]]}
{"doc_key": "ai-test-103", "ner": [[0, 3, "task"], [5, 7, "field"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 17, 19, "part-of", "", false, false], [17, 19, 5, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Face", "detection", "is", "used", "in", "biometrics", ",", "often", "as", "part", "of", "(", "or", "together", "with", ")", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Face detection is used in biometrics, often as part of (or together with) a facial recognition system.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 22], [23, 25], [26, 36], [36, 37], [38, 43], [44, 46], [47, 51], [52, 54], [55, 56], [56, 58], [59, 67], [68, 72], [72, 73], [74, 75], [76, 82], [83, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-104", "ner": [[3, 5, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["qualified", "with", "the", "highest", "probability", "score", "."], "sentence-detokenized": "qualified with the highest probability score.", "token2charspan": [[0, 9], [10, 14], [15, 18], [19, 26], [27, 38], [39, 44], [44, 45]]}
{"doc_key": "ai-test-105", "ner": [[2, 2, "country"], [4, 8, "organisation"], [10, 10, "location"], [12, 12, "country"], [16, 19, "organisation"], [21, 23, "country"], [27, 27, "organisation"], [32, 35, "organisation"], [37, 37, "country"], [47, 50, "organisation"], [52, 52, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[4, 8, 10, 10, "physical", "", false, false], [10, 10, 12, 12, "physical", "", false, false], [16, 19, 21, 23, "physical", "", false, false], [32, 35, 37, 37, "physical", "", false, false], [47, 50, 52, 52, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd.", "in", "Thailand", ",", "Komatsu", "(", "Shanghai", ")", "Ltd.", "in", "Shanghai", ",", "China", "in", "1996", ",", "Industrial", "Power", "Alliance", "Ltd.", "in", "Japan", ",", "a", "joint", "venture", "with", "Cummins", ",", "in", "1998", ",", "L&T", "-", "Komatsu", "Limited", "in", "India", "in", "1998", "(", "shares", "sold", "in", "2013", ")", "and", "Komatsu", "Brasil", "International", "Ltda.", "in", "Brazil", "in", "1998", "."], "sentence-detokenized": "Ltd. in Thailand, Komatsu (Shanghai) Ltd. in Shanghai, China in 1996, Industrial Power Alliance Ltd. in Japan, a joint venture with Cummins, in 1998, L&T-Komatsu Limited in India in 1998 (shares sold in 2013) and Komatsu Brasil International Ltda. in Brazil in 1998.", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 25], [26, 27], [27, 35], [35, 36], [37, 41], [42, 44], [45, 53], [53, 54], [55, 60], [61, 63], [64, 68], [68, 69], [70, 80], [81, 86], [87, 95], [96, 100], [101, 103], [104, 109], [109, 110], [111, 112], [113, 118], [119, 126], [127, 131], [132, 139], [139, 140], [141, 143], [144, 148], [148, 149], [150, 153], [153, 154], [154, 161], [162, 169], [170, 172], [173, 178], [179, 181], [182, 186], [187, 188], [188, 194], [195, 199], [200, 202], [203, 207], [207, 208], [209, 212], [213, 220], [221, 227], [228, 241], [242, 247], [248, 250], [251, 257], [258, 260], [261, 265], [265, 266]]}
{"doc_key": "ai-test-106", "ner": [[0, 0, "organisation"], [4, 8, "misc"], [11, 12, "person"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[11, 12, 0, 0, "physical", "", false, false], [11, 12, 4, 8, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["dgp", "also", "occasionally", "hosts", "artists", "in", "residence", "(", "e.g.", "Oscar-", "winner", "Chris", "Landreth", ")", "."], "sentence-detokenized": "dgp also occasionally hosts artists in residence (e.g. Oscar-winner Chris Landreth).", "token2charspan": [[0, 3], [4, 8], [9, 21], [22, 27], [28, 35], [36, 38], [39, 48], [49, 50], [50, 54], [55, 61], [61, 67], [68, 73], [74, 82], [82, 83], [83, 84]]}
{"doc_key": "ai-test-107", "ner": [[7, 9, "misc"], [12, 14, "misc"], [17, 20, "misc"], [24, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "currently", "includes", "four", "sub-competitions", ":", "the", "RoboMaster", "Robotics", "Competition", ",", "the", "RoboMaster", "Technical", "Challenge", ",", "the", "ICRA", "RoboMaster", "AI", "Challenge", "and", "the", "new", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "It currently includes four sub-competitions: the RoboMaster Robotics Competition, the RoboMaster Technical Challenge, the ICRA RoboMaster AI Challenge and the new RoboMaster Youth Tournament.", "token2charspan": [[0, 2], [3, 12], [13, 21], [22, 26], [27, 43], [43, 44], [45, 48], [49, 59], [60, 68], [69, 80], [80, 81], [82, 85], [86, 96], [97, 106], [107, 116], [116, 117], [118, 121], [122, 126], [127, 137], [138, 140], [141, 150], [151, 154], [155, 158], [159, 162], [163, 173], [174, 179], [180, 190], [190, 191]]}
{"doc_key": "ai-test-108", "ner": [[7, 8, "field"], [16, 18, "algorithm"], [22, 23, "algorithm"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 22, 23, "usage", "", false, false], [7, 8, 25, 26, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "the", "early", "2000s", ",", "the", "dominant", "speech", "processing", "strategy", "started", "to", "move", "away", "from", "the", "hidden", "Markov", "model", "towards", "more", "modern", "neural", "networks", "and", "deep", "learning", "."], "sentence-detokenized": "In the early 2000s, the dominant speech processing strategy started to move away from the hidden Markov model towards more modern neural networks and deep learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 18], [18, 19], [20, 23], [24, 32], [33, 39], [40, 50], [51, 59], [60, 67], [68, 70], [71, 75], [76, 80], [81, 85], [86, 89], [90, 96], [97, 103], [104, 109], [110, 117], [118, 122], [123, 129], [130, 136], [137, 145], [146, 149], [150, 154], [155, 163], [163, 164]]}
{"doc_key": "ai-test-109", "ner": [[8, 10, "misc"], [14, 16, "metrics"], [19, 21, "metrics"], [29, 31, "metrics"], [34, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 16, 19, 21, "related-to", "equal", false, false], [29, 31, 34, 36, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "equivalent", "expression", "in", "the", "case", "of", "a", "binary", "target", "rate", "is", "that", "the", "true", "positive", "rate", "and", "the", "false", "positive", "rate", "are", "the", "same", "(", "and", "therefore", "the", "false", "negative", "rate", "and", "the", "true", "negative", "rate", "are", "the", "same", ")", "for", "each", "value", "of", "the", "sensitive", "characteristics", ":"], "sentence-detokenized": "Another equivalent expression in the case of a binary target rate is that the true positive rate and the false positive rate are the same (and therefore the false negative rate and the true negative rate are the same) for each value of the sensitive characteristics:", "token2charspan": [[0, 7], [8, 18], [19, 29], [30, 32], [33, 36], [37, 41], [42, 44], [45, 46], [47, 53], [54, 60], [61, 65], [66, 68], [69, 73], [74, 77], [78, 82], [83, 91], [92, 96], [97, 100], [101, 104], [105, 110], [111, 119], [120, 124], [125, 128], [129, 132], [133, 137], [138, 139], [139, 142], [143, 152], [153, 156], [157, 162], [163, 171], [172, 176], [177, 180], [181, 184], [185, 189], [190, 198], [199, 203], [204, 207], [208, 211], [212, 216], [216, 217], [218, 221], [222, 226], [227, 232], [233, 235], [236, 239], [240, 249], [250, 265], [265, 266]]}
{"doc_key": "ai-test-110", "ner": [[0, 0, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["MATLAB", "function", ","], "sentence-detokenized": "MATLAB function,", "token2charspan": [[0, 6], [7, 15], [15, 16]]}
{"doc_key": "ai-test-111", "ner": [[0, 2, "product"], [7, 10, "misc"], [14, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 0, 2, "part-of", "", false, false], [14, 15, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "articulated", "robot", "is", "a", "robot", "with", "rotating", "joints", "(", "e.g.", "a", "legged", "or", "industrial", "robot", ")", "."], "sentence-detokenized": "An articulated robot is a robot with rotating joints (e.g. a legged or industrial robot).", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 23], [24, 25], [26, 31], [32, 36], [37, 45], [46, 52], [53, 54], [54, 58], [59, 60], [61, 67], [68, 70], [71, 81], [82, 87], [87, 88], [88, 89]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [5, 6, "product"], [8, 9, "product"], [13, 13, "misc"], [19, 21, "product"], [25, 27, "misc"], [31, 31, "location"], [33, 33, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 13, 13, "general-affiliation", "nationality", false, false], [0, 0, 25, 27, "usage", "", false, false], [0, 0, 31, 31, "physical", "", false, false], [5, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [31, 31, 33, 33, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "also", "known", "as", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "an", "American", "online", "radio", "streaming", "service", "and", "automatic", "recommendation", "system", "powered", "by", "the", "Music", "Genome", "Project", "and", "based", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (also known as Pandora Media or Pandora Radio) is an American online radio streaming service and automatic recommendation system powered by the Music Genome Project and based in Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 30], [31, 36], [37, 39], [40, 47], [48, 53], [53, 54], [55, 57], [58, 60], [61, 69], [70, 76], [77, 82], [83, 92], [93, 100], [101, 104], [105, 114], [115, 129], [130, 136], [137, 144], [145, 147], [148, 151], [152, 157], [158, 164], [165, 172], [173, 176], [177, 182], [183, 185], [186, 193], [193, 194], [195, 205], [205, 206]]}
{"doc_key": "ai-test-113", "ner": [[10, 16, "organisation"], [20, 22, "organisation"], [28, 29, "conference"], [41, 41, "conference"], [43, 43, "conference"], [45, 45, "conference"], [47, 47, "conference"], [49, 49, "conference"], [51, 51, "conference"], [53, 53, "conference"], [55, 55, "conference"], [57, 57, "conference"], [59, 59, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "member", "of", "the", "Board", "of", "Directors", "of", "the", "International", "Machine", "Learning", "Association", ",", "a", "member", "of", "the", "AAAI", "Executive", "Council", ",", "Co-", "Chair", "of", "the", "ICML", "2011", "Board", ",", "and", "a", "senior", "committee", "member", "for", "conferences", "such", "as", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", "and", "WWW", "."], "sentence-detokenized": "She is a member of the Board of Directors of the International Machine Learning Association, a member of the AAAI Executive Council, Co-Chair of the ICML 2011 Board, and a senior committee member for conferences such as AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM and WWW.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 15], [16, 18], [19, 22], [23, 28], [29, 31], [32, 41], [42, 44], [45, 48], [49, 62], [63, 70], [71, 79], [80, 91], [91, 92], [93, 94], [95, 101], [102, 104], [105, 108], [109, 113], [114, 123], [124, 131], [131, 132], [133, 136], [136, 141], [142, 144], [145, 148], [149, 153], [154, 158], [159, 164], [164, 165], [166, 169], [170, 171], [172, 178], [179, 188], [189, 195], [196, 199], [200, 211], [212, 216], [217, 219], [220, 224], [224, 225], [226, 230], [230, 231], [232, 237], [237, 238], [239, 243], [243, 244], [245, 248], [248, 249], [250, 256], [256, 257], [258, 261], [261, 262], [263, 267], [267, 268], [269, 273], [274, 277], [278, 281], [281, 282]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [5, 10, "organisation"], [12, 12, "organisation"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 10, "role", "", false, false], [12, 12, 5, 10, "named", "", false, false], [16, 18, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "has", "developed", "Robocrane", ",", "where", "the", "platform", "hangs", "on", "six", "cables", "instead", "of", "being", "supported", "by", "six", "connectors", "."], "sentence-detokenized": "James S. Albus of the National Institute of Standards and Technology (NIST) has developed Robocrane, where the platform hangs on six cables instead of being supported by six connectors.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [74, 75], [76, 79], [80, 89], [90, 99], [99, 100], [101, 106], [107, 110], [111, 119], [120, 125], [126, 128], [129, 132], [133, 139], [140, 147], [148, 150], [151, 156], [157, 166], [167, 169], [170, 173], [174, 184], [184, 185]]}
{"doc_key": "ai-test-115", "ner": [[3, 5, "algorithm"], [8, 9, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 5, "type-of", "", false, false], [12, 13, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "class", "of", "direct", "search", "algorithms", "are", "various", "evolutionary", "algorithms", ",", "e.g.", "genetic", "algorithms", "."], "sentence-detokenized": "Another class of direct search algorithms are various evolutionary algorithms, e.g. genetic algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 23], [24, 30], [31, 41], [42, 45], [46, 53], [54, 66], [67, 77], [77, 78], [79, 83], [84, 91], [92, 102], [102, 103]]}
{"doc_key": "ai-test-116", "ner": [[0, 0, "organisation"], [3, 5, "misc"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 0, 0, "named", "", false, false], [6, 7, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "industrial", "robots", "and", "factory", "automation", "solutions", "."], "sentence-detokenized": "KUKA is a German manufacturer of industrial robots and factory automation solutions.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-117", "ner": [[0, 1, "misc"], [9, 11, "person"], [12, 18, "misc"], [20, 20, "person"], [23, 23, "misc"], [25, 27, "person"], [28, 29, "misc"], [31, 36, "person"], [34, 36, "misc"], [38, 45, "person"], [40, 44, "misc"], [47, 49, "person"], [50, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[9, 11, 0, 1, "usage", "", false, false], [12, 18, 9, 11, "artifact", "", false, false], [20, 20, 0, 1, "usage", "", false, false], [23, 23, 20, 20, "artifact", "", false, false], [25, 27, 0, 1, "usage", "", false, false], [28, 29, 25, 27, "artifact", "", false, false], [31, 36, 0, 1, "usage", "", false, false], [34, 36, 31, 36, "artifact", "", false, false], [38, 45, 0, 1, "usage", "", false, false], [40, 44, 38, 45, "artifact", "", false, false], [47, 49, 0, 1, "usage", "", false, false], [50, 53, 47, 49, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Other", "IMAX", "films", "shot", "between", "2016", "and", "2020", "include", "Zack", "Snyder", "'s", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", ",", "Clint", "Eastwood", "'s", "Sully", ",", "Damien", "Chazelle", "'s", "First", "Man", ",", "Patty", "Jenkins", "'", "Wonder", "Woman", "1984", ",", "Joji", "Fukunaga", "'s", "No", "Time", "to", "Die", "Cary", "and", "Joseph", "Kosinski", "'s", "Top", "Gun", ":", "Maverick", "."], "sentence-detokenized": "Other IMAX films shot between 2016 and 2020 include Zack Snyder's Batman v Superman: Dawn of Justice, Clint Eastwood's Sully, Damien Chazelle's First Man, Patty Jenkins' Wonder Woman 1984, Joji Fukunaga's No Time to Die Cary and Joseph Kosinski's Top Gun: Maverick.", "token2charspan": [[0, 5], [6, 10], [11, 16], [17, 21], [22, 29], [30, 34], [35, 38], [39, 43], [44, 51], [52, 56], [57, 63], [63, 65], [66, 72], [73, 74], [75, 83], [83, 84], [85, 89], [90, 92], [93, 100], [100, 101], [102, 107], [108, 116], [116, 118], [119, 124], [124, 125], [126, 132], [133, 141], [141, 143], [144, 149], [150, 153], [153, 154], [155, 160], [161, 168], [168, 169], [170, 176], [177, 182], [183, 187], [187, 188], [189, 193], [194, 202], [202, 204], [205, 207], [208, 212], [213, 215], [216, 219], [220, 224], [225, 228], [229, 235], [236, 244], [244, 246], [247, 250], [251, 254], [254, 255], [256, 264], [264, 265]]}
{"doc_key": "ai-test-118", "ner": [[4, 6, "misc"], [10, 12, "organisation"], [14, 20, "organisation"], [25, 25, "misc"], [31, 32, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 25, 25, "named", "", false, false], [10, 12, 4, 6, "usage", "", false, false], [10, 12, 31, 32, "physical", "", false, false], [14, 20, 10, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "trial", "version", "of", "MICR", "E13B", "was", "presented", "to", "the", "American", "Bankers", "Association", "(", "ABA", ")", "in", "July", "1956", ",", "which", "adopted", "it", "as", "the", "MICR", "standard", "for", "portable", "documents", "in", "the", "USA", "in", "1958", "."], "sentence-detokenized": "A trial version of MICR E13B was presented to the American Bankers Association (ABA) in July 1956, which adopted it as the MICR standard for portable documents in the USA in 1958.", "token2charspan": [[0, 1], [2, 7], [8, 15], [16, 18], [19, 23], [24, 28], [29, 32], [33, 42], [43, 45], [46, 49], [50, 58], [59, 66], [67, 78], [79, 80], [80, 83], [83, 84], [85, 87], [88, 92], [93, 97], [97, 98], [99, 104], [105, 112], [113, 115], [116, 118], [119, 122], [123, 127], [128, 136], [137, 140], [141, 149], [150, 159], [160, 162], [163, 166], [167, 170], [171, 173], [174, 178], [178, 179]]}
{"doc_key": "ai-test-119", "ner": [[0, 5, "misc"], [15, 16, "field"], [19, 20, "field"], [23, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 16, 0, 5, "usage", "", false, false], [19, 20, 15, 16, "part-of", "", false, false], [23, 23, 0, 5, "usage", "", false, false], [25, 26, 0, 5, "usage", "", false, false], [28, 28, 0, 5, "usage", "", false, false], [30, 30, 0, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "are", "widely", "used", "for", "many", "hard", "computing", "problems", ",", "including", "problems", "in", "computer", "science", "(", "especially", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms are widely used for many hard computing problems, including problems in computer science (especially artificial intelligence), mathematics, operations research, engineering and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 27], [28, 34], [35, 39], [40, 43], [44, 48], [49, 53], [54, 63], [64, 72], [72, 73], [74, 83], [84, 92], [93, 95], [96, 104], [105, 112], [113, 114], [114, 124], [125, 135], [136, 148], [148, 149], [149, 150], [151, 162], [162, 163], [164, 174], [175, 183], [183, 184], [185, 196], [197, 200], [201, 215], [215, 216]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [8, 8, "location"], [10, 10, "country"], [14, 14, "country"], [22, 23, "algorithm"], [25, 25, "algorithm"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 8, 8, "physical", "", false, false], [0, 1, 14, 14, "general-affiliation", "nationality", false, false], [0, 1, 22, 23, "general-affiliation", "topic_of_study", false, false], [0, 1, 25, 25, "general-affiliation", "topic_of_study", false, false], [8, 8, 10, 10, "physical", "", false, false], [25, 25, 27, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "born", "3", "September", "1947", ",", "Wallersdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "has", "studied", "the", "use", "of", "bounded", "rationality", "and", "heuristics", "in", "decision", "-", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (born 3 September 1947, Wallersdorf, Germany) is a German psychologist who has studied the use of bounded rationality and heuristics in decision-making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 21], [22, 23], [24, 33], [34, 38], [38, 39], [40, 51], [51, 52], [53, 60], [60, 61], [62, 64], [65, 66], [67, 73], [74, 86], [87, 90], [91, 94], [95, 102], [103, 106], [107, 110], [111, 113], [114, 121], [122, 133], [134, 137], [138, 148], [149, 151], [152, 160], [160, 161], [161, 167], [167, 168]]}
{"doc_key": "ai-test-121", "ner": [[3, 6, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["to", "minimise", "the", "root", "mean", "square", "error", "."], "sentence-detokenized": "to minimise the root mean square error.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [21, 25], [26, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-test-122", "ner": [[13, 14, "misc"], [17, 18, "organisation"], [33, 40, "field"], [49, 50, "misc"], [60, 64, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 14, 17, 18, "origin", "", false, false], [49, 50, 60, 64, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "even", "an", "official", "language", "regulated", "by", "an", "academy", ",", "such", "as", "standard", "French", "with", "the", "French", "Academy", ",", "is", "classified", "as", "a", "natural", "language", "(", "for", "example", "in", "the", "field", "of", "natural", "language", "processing", ")", ",", "because", "it", "is", "not", "sufficiently", "constructed", "to", "be", "classified", "as", "a", "constructed", "language", ",", "or", "sufficiently", "controlled", "to", "be", "classified", "as", "a", "controlled", "natural", "language", ",", "due", "to", "its", "prescriptive", "scores", "."], "sentence-detokenized": "However, even an official language regulated by an academy, such as standard French with the French Academy, is classified as a natural language (for example in the field of natural language processing), because it is not sufficiently constructed to be classified as a constructed language, or sufficiently controlled to be classified as a controlled natural language, due to its prescriptive scores.", "token2charspan": [[0, 7], [7, 8], [9, 13], [14, 16], [17, 25], [26, 34], [35, 44], [45, 47], [48, 50], [51, 58], [58, 59], [60, 64], [65, 67], [68, 76], [77, 83], [84, 88], [89, 92], [93, 99], [100, 107], [107, 108], [109, 111], [112, 122], [123, 125], [126, 127], [128, 135], [136, 144], [145, 146], [146, 149], [150, 157], [158, 160], [161, 164], [165, 170], [171, 173], [174, 181], [182, 190], [191, 201], [201, 202], [202, 203], [204, 211], [212, 214], [215, 217], [218, 221], [222, 234], [235, 246], [247, 249], [250, 252], [253, 263], [264, 266], [267, 268], [269, 280], [281, 289], [289, 290], [291, 293], [294, 306], [307, 317], [318, 320], [321, 323], [324, 334], [335, 337], [338, 339], [340, 350], [351, 358], [359, 367], [367, 368], [369, 372], [373, 375], [376, 379], [380, 392], [393, 399], [399, 400]]}
{"doc_key": "ai-test-123", "ner": [[11, 11, "metrics"], [13, 14, "metrics"], [16, 19, "metrics"], [36, 37, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 19, 13, 14, "named", "", false, false], [39, 39, 36, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "a", "number", "of", "other", "metrics", ",", "the", "simplest", "being", "accuracy", "or", "proportion", "correct", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "all", "cases", "that", "are", "correctly", "categorised", ";", "the", "complementary", "one", "is", "the", "proportion", "incorrect", "(", "FiC", ")", "."], "sentence-detokenized": "There are a number of other metrics, the simplest being accuracy or proportion correct (FC), which measures the proportion of all cases that are correctly categorised; the complementary one is the proportion incorrect (FiC).", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 18], [19, 21], [22, 27], [28, 35], [35, 36], [37, 40], [41, 49], [50, 55], [56, 64], [65, 67], [68, 78], [79, 86], [87, 88], [88, 90], [90, 91], [91, 92], [93, 98], [99, 107], [108, 111], [112, 122], [123, 125], [126, 129], [130, 135], [136, 140], [141, 144], [145, 154], [155, 166], [166, 167], [168, 171], [172, 185], [186, 189], [190, 192], [193, 196], [197, 207], [208, 217], [218, 219], [219, 222], [222, 223], [223, 224]]}
{"doc_key": "ai-test-124", "ner": [[0, 2, "researcher"], [5, 11, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 5, 11, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "became", "a", "Fellow", "of", "the", "Association", "for", "Computational", "Linguistics", "in", "2016", "."], "sentence-detokenized": "Cardie became a Fellow of the Association for Computational Linguistics in 2016.", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 59], [60, 71], [72, 74], [75, 79], [79, 80]]}
{"doc_key": "ai-test-125", "ner": [[11, 14, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Learning", "the", "parameters", "of", "math\\theta", "/", "math", "is", "usually", "done", "by", "maximum", "likelihood", "learning", "for", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";", "\\", "theta", ")", "/", "math", "."], "sentence-detokenized": "Learning the parameters of math\\theta/math is usually done by maximum likelihood learning for mathp(Y _ i | X _ i;\\ theta)/math.", "token2charspan": [[0, 8], [9, 12], [13, 23], [24, 26], [27, 37], [37, 38], [38, 42], [43, 45], [46, 53], [54, 58], [59, 61], [62, 69], [70, 80], [81, 89], [90, 93], [94, 99], [99, 100], [100, 101], [102, 103], [104, 105], [106, 107], [108, 109], [110, 111], [112, 113], [113, 114], [114, 115], [116, 121], [121, 122], [122, 123], [123, 127], [127, 128]]}
{"doc_key": "ai-test-126", "ner": [[0, 1, "task"], [3, 6, "algorithm"], [8, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 0, 1, "usage", "", true, false], [8, 9, 3, 6, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cluster", "analysis", "and", "factorisation", "of", "non-negative", "matrices", "for", "descriptive", "mining", "."], "sentence-detokenized": "Cluster analysis and factorisation of non-negative matrices for descriptive mining.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 34], [35, 37], [38, 50], [51, 59], [60, 63], [64, 75], [76, 82], [82, 83]]}
{"doc_key": "ai-test-127", "ner": [[1, 1, "field"], [4, 11, "field"], [16, 18, "field"], [20, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 18, 1, 1, "part-of", "", false, false], [16, 18, 4, 11, "part-of", "", false, false], [20, 22, 1, 1, "part-of", "", false, false], [20, 22, 4, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computing", "and", "the", "information", "technology", "that", "makes", "it", "possible", ",", "the", "ability", "of", "computers", "to", "process", "natural", "language", "and", "machine", "learning", "has", "been", "a", "long", "-", "standing", "challenge", "."], "sentence-detokenized": "In computing and the information technology that makes it possible, the ability of computers to process natural language and machine learning has been a long-standing challenge.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 20], [21, 32], [33, 43], [44, 48], [49, 54], [55, 57], [58, 66], [66, 67], [68, 71], [72, 79], [80, 82], [83, 92], [93, 95], [96, 103], [104, 111], [112, 120], [121, 124], [125, 132], [133, 141], [142, 145], [146, 150], [151, 152], [153, 157], [157, 158], [158, 166], [167, 176], [176, 177]]}
{"doc_key": "ai-test-128", "ner": [[4, 7, "algorithm"], [8, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 7, 8, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "The", "code", "to", "extract", "Gabor", "features", "from", "MATLAB", "images", "is", "available", "at"], "sentence-detokenized": "(The code to extract Gabor features from MATLAB images is available at", "token2charspan": [[0, 1], [1, 4], [5, 9], [10, 12], [13, 20], [21, 26], [27, 35], [36, 40], [41, 47], [48, 54], [55, 57], [58, 67], [68, 70]]}
{"doc_key": "ai-test-129", "ner": [[0, 0, "misc"], [13, 14, "algorithm"], [18, 18, "task"], [20, 20, "task"], [22, 23, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 13, 14, "general-affiliation", "", false, false], [0, 0, 18, 18, "related-to", "solves_problem_of_type", false, false], [0, 0, 20, 20, "related-to", "solves_problem_of_type", false, false], [0, 0, 22, 23, "related-to", "solves_problem_of_type", false, false], [0, 0, 25, 26, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["NeuralExpert", "design", "specifications", "focus", "on", "the", "type", "of", "problem", "the", "user", "wants", "the", "neural", "network", "to", "solve", "(", "classification", ",", "prediction", ",", "feature", "approximation", "or", "cluster", "analysis", ")", "."], "sentence-detokenized": "NeuralExpert design specifications focus on the type of problem the user wants the neural network to solve (classification, prediction, feature approximation or cluster analysis).", "token2charspan": [[0, 12], [13, 19], [20, 34], [35, 40], [41, 43], [44, 47], [48, 52], [53, 55], [56, 63], [64, 67], [68, 72], [73, 78], [79, 82], [83, 89], [90, 97], [98, 100], [101, 106], [107, 108], [108, 122], [122, 123], [124, 134], [134, 135], [136, 143], [144, 157], [158, 160], [161, 168], [169, 177], [177, 178], [178, 179]]}
{"doc_key": "ai-test-130", "ner": [[1, 6, "misc"], [29, 34, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "size", "of", "the", "quantisation", "step", "(", "\u0394", ")", "is", "small", "relative", "to", "the", "variation", "of", "the", "quantised", "signal", ",", "it", "is", "relatively", "straightforward", "to", "show", "that", "the", "root", "mean", "square", "error", "caused", "by", "such", "a", "rounding", "operation", "will", "be", "approximately", "math", "\\", "Delta^2/12", "/math.math"], "sentence-detokenized": "When the size of the quantisation step (\u0394) is small relative to the variation of the quantised signal, it is relatively straightforward to show that the root mean square error caused by such a rounding operation will be approximately math\\Delta^2/12/math.math", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 20], [21, 33], [34, 38], [39, 40], [40, 41], [41, 42], [43, 45], [46, 51], [52, 60], [61, 63], [64, 67], [68, 77], [78, 80], [81, 84], [85, 94], [95, 101], [101, 102], [103, 105], [106, 108], [109, 119], [120, 135], [136, 138], [139, 143], [144, 148], [149, 152], [153, 157], [158, 162], [163, 169], [170, 175], [176, 182], [183, 185], [186, 190], [191, 192], [193, 201], [202, 211], [212, 216], [217, 219], [220, 233], [234, 238], [238, 239], [239, 249], [249, 259]]}
{"doc_key": "ai-test-131", "ner": [[16, 16, "product"], [24, 27, "researcher"], [29, 30, "researcher"], [32, 34, "researcher"], [36, 37, "researcher"], [39, 41, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Building", "a", "rich", "lexicon", "with", "an", "appropriate", "ontology", "requires", "a", "lot", "of", "effort", ",", "e.g.", "the", "Wordnet", "lexicon", "took", "several", "years", "of", "work", ".", "G.", "A", ".", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "Building a rich lexicon with an appropriate ontology requires a lot of effort, e.g. the Wordnet lexicon took several years of work. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 8], [9, 10], [11, 15], [16, 23], [24, 28], [29, 31], [32, 43], [44, 52], [53, 61], [62, 63], [64, 67], [68, 70], [71, 77], [77, 78], [79, 83], [84, 87], [88, 95], [96, 103], [104, 108], [109, 116], [117, 122], [123, 125], [126, 130], [130, 131], [132, 134], [135, 136], [136, 137], [138, 144], [144, 145], [146, 148], [149, 157], [157, 158], [159, 161], [162, 164], [165, 173], [173, 174], [175, 177], [178, 183], [183, 184], [185, 186], [186, 187], [188, 194], [194, 195]]}
{"doc_key": "ai-test-132", "ner": [[0, 1, "organisation"], [16, 17, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kawasaki", "'s", "portfolio", "also", "includes", "retractable", "roofs", ",", "floors", "and", "other", "giant", "structures", "such", "as", "the", "Sapporo", "Dome", "retractable", "surface", "."], "sentence-detokenized": "Kawasaki's portfolio also includes retractable roofs, floors and other giant structures such as the Sapporo Dome retractable surface.", "token2charspan": [[0, 8], [8, 10], [11, 20], [21, 25], [26, 34], [35, 46], [47, 52], [52, 53], [54, 60], [61, 64], [65, 70], [71, 76], [77, 87], [88, 92], [93, 95], [96, 99], [100, 107], [108, 112], [113, 124], [125, 132], [132, 133]]}
{"doc_key": "ai-test-133", "ner": [[0, 1, "metrics"], [5, 6, "metrics"], [8, 9, "metrics"], [15, 17, "metrics"], [37, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 15, 17, "related-to", "", false, false], [0, 1, 37, 38, "opposite", "alternative_to", false, false], [5, 6, 0, 1, "type-of", "", false, false], [8, 9, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa", "statistics", ",", "such", "as", "Fleiss", "kappa", "and", "Cohen", "kappa", ",", "are", "methods", "for", "calculating", "inter-rater", "reliability", "based", "on", "different", "assumptions", "about", "marginal", "or", "prior", "distributions", "and", "are", "increasingly", "used", "as", "a", "chance", "-", "corrected", "alternative", "to", "precision", "in", "other", "contexts", "."], "sentence-detokenized": "Kappa statistics, such as Fleiss kappa and Cohen kappa, are methods for calculating inter-rater reliability based on different assumptions about marginal or prior distributions and are increasingly used as a chance-corrected alternative to precision in other contexts.", "token2charspan": [[0, 5], [6, 16], [16, 17], [18, 22], [23, 25], [26, 32], [33, 38], [39, 42], [43, 48], [49, 54], [54, 55], [56, 59], [60, 67], [68, 71], [72, 83], [84, 95], [96, 107], [108, 113], [114, 116], [117, 126], [127, 138], [139, 144], [145, 153], [154, 156], [157, 162], [163, 176], [177, 180], [181, 184], [185, 197], [198, 202], [203, 205], [206, 207], [208, 214], [214, 215], [215, 224], [225, 236], [237, 239], [240, 249], [250, 252], [253, 258], [259, 267], [267, 268]]}
{"doc_key": "ai-test-134", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [0, 0, "researcher"], [27, 29, "algorithm"], [31, 35, "algorithm"], [37, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 0, 0, "role", "student_of", false, false], [7, 8, 0, 0, "role", "student_of", false, false], [10, 11, 0, 0, "role", "student_of", false, false], [13, 14, 0, 0, "role", "student_of", false, false], [31, 35, 4, 5, "origin", "", false, false], [31, 35, 7, 8, "origin", "", false, false], [31, 35, 10, 11, "origin", "", false, false], [31, 35, 13, 14, "origin", "", false, false], [31, 35, 0, 0, "origin", "", false, false], [31, 35, 27, 29, "type-of", "", false, false], [37, 37, 31, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Schmidhuber", "and", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "and", "others", "have", "been", "publishing", "increasingly", "sophisticated", "versions", "of", "a", "type", "of", "recurrent", "neural", "network", "called", "long", "short", "-", "term", "memory", "(", "LSTM", ")", "."], "sentence-detokenized": "Schmidhuber and his students Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves and others have been publishing increasingly sophisticated versions of a type of recurrent neural network called long short-term memory (LSTM).", "token2charspan": [[0, 11], [12, 15], [16, 19], [20, 28], [29, 33], [34, 44], [44, 45], [46, 51], [52, 56], [56, 57], [58, 62], [63, 70], [70, 71], [72, 76], [77, 83], [84, 87], [88, 94], [95, 99], [100, 104], [105, 115], [116, 128], [129, 142], [143, 151], [152, 154], [155, 156], [157, 161], [162, 164], [165, 174], [175, 181], [182, 189], [190, 196], [197, 201], [202, 207], [207, 208], [208, 212], [213, 219], [220, 221], [221, 225], [225, 226], [226, 227]]}
{"doc_key": "ai-test-135", "ner": [[4, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "The", "first", "Cobot", "KUKA", "LBR", "3", "is", "launched", "."], "sentence-detokenized": "2004 - The first Cobot KUKA LBR 3 is launched.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 22], [23, 27], [28, 31], [32, 33], [34, 36], [37, 45], [45, 46]]}
{"doc_key": "ai-test-136", "ner": [[11, 13, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "shallow", "approaches", "used", "for", "training", "and", "then", "disambiguation", "are", "the", "Naive", "Bayes", "classifier", "and", "decision", "trees", "."], "sentence-detokenized": "Two shallow approaches used for training and then disambiguation are the Naive Bayes classifier and decision trees.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 27], [28, 31], [32, 40], [41, 44], [45, 49], [50, 64], [65, 68], [69, 72], [73, 78], [79, 84], [85, 95], [96, 99], [100, 108], [109, 114], [114, 115]]}
{"doc_key": "ai-test-137", "ner": [[5, 5, "misc"], [12, 13, "person"], [15, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 12, 13, "origin", "", false, false], [5, 5, 15, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "practical", "form", "of", "photography", "was", "introduced", "in", "January", "1839", "by", "Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "The first practical form of photography was introduced in January 1839 by Louis Daguerre and Henry Fox Talbot.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 24], [25, 27], [28, 39], [40, 43], [44, 54], [55, 57], [58, 65], [66, 70], [71, 73], [74, 79], [80, 88], [89, 92], [93, 98], [99, 102], [103, 109], [109, 110]]}
{"doc_key": "ai-test-138", "ner": [[3, 5, "task"], [7, 8, "task"], [15, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 15, 17, "part-of", "task_part_of_field", false, false], [7, 8, 15, 17, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "speech", "synthesis", "combined", "with", "speech", "recognition", "allows", "interaction", "with", "mobile", "devices", "via", "speech", "processing", "interfaces", "."], "sentence-detokenized": "For example, speech synthesis combined with speech recognition allows interaction with mobile devices via speech processing interfaces.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [30, 38], [39, 43], [44, 50], [51, 62], [63, 69], [70, 81], [82, 86], [87, 93], [94, 101], [102, 105], [106, 112], [113, 123], [124, 134], [134, 135]]}
{"doc_key": "ai-test-139", "ner": [[0, 2, "product"], [14, 14, "programlang"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 14, 14, "general-affiliation", "", false, false], [0, 2, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Phidgets", "can", "be", "programmed", "with", "a", "variety", "of", "software", "and", "programming", "languages", ",", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "Phidgets can be programmed with a variety of software and programming languages, from Java to Microsoft Excel.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 26], [27, 31], [32, 33], [34, 41], [42, 44], [45, 53], [54, 57], [58, 69], [70, 79], [79, 80], [81, 85], [86, 90], [91, 93], [94, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-test-140", "ner": [[2, 4, "field"], [9, 10, "researcher"], [12, 15, "misc"], [21, 22, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 9, 10, "origin", "", false, false], [9, 10, 21, 22, "general-affiliation", "topic_of_study", false, false], [9, 10, 24, 25, "general-affiliation", "topic_of_study", false, false], [12, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "machine", "learning", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "an", "American", "IBMer", "and", "pioneer", "in", "the", "field", "of", "computer", "games", "and", "artificial", "intelligence", "."], "sentence-detokenized": "The term machine learning was coined in 1959 by Arthur Samuel, an American IBMer and pioneer in the field of computer games and artificial intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 25], [26, 29], [30, 36], [37, 39], [40, 44], [45, 47], [48, 54], [55, 61], [61, 62], [63, 65], [66, 74], [75, 80], [81, 84], [85, 92], [93, 95], [96, 99], [100, 105], [106, 108], [109, 117], [118, 123], [124, 127], [128, 138], [139, 151], [151, 152]]}
{"doc_key": "ai-test-141", "ner": [[0, 1, "misc"], [2, 3, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Israeli", "poet", "David", "Avidan", ",", "fascinated", "by", "future", "technologies", "and", "their", "relationship", "to", "art", ",", "wanted", "to", "explore", "the", "use", "of", "computers", "in", "writing", "literature", "."], "sentence-detokenized": "Israeli poet David Avidan, fascinated by future technologies and their relationship to art, wanted to explore the use of computers in writing literature.", "token2charspan": [[0, 7], [8, 12], [13, 18], [19, 25], [25, 26], [27, 37], [38, 40], [41, 47], [48, 60], [61, 64], [65, 70], [71, 83], [84, 86], [87, 90], [90, 91], [92, 98], [99, 101], [102, 109], [110, 113], [114, 117], [118, 120], [121, 130], [131, 133], [134, 141], [142, 152], [152, 153]]}
{"doc_key": "ai-test-142", "ner": [[0, 5, "misc"], [7, 7, "organisation"], [13, 13, "location"], [28, 35, "location"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[7, 7, 0, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "part", "of", "the", "GATEway", "project", ",", "Oxbotica", "tested", "seven", "autonomous", "buses", "in", "Greenwich", "in", "2017", ",", "driving", "along", "a", "two", "-", "kilometre", "river", "route", "near", "London", "'s", "O2", "Arena", ",", "which", "is", "also", "used", "by", "pedestrians", "and", "cyclists", "."], "sentence-detokenized": "As part of the GATEway project, Oxbotica tested seven autonomous buses in Greenwich in 2017, driving along a two-kilometre river route near London's O2 Arena, which is also used by pedestrians and cyclists.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 30], [30, 31], [32, 40], [41, 47], [48, 53], [54, 64], [65, 70], [71, 73], [74, 83], [84, 86], [87, 91], [91, 92], [93, 100], [101, 106], [107, 108], [109, 112], [112, 113], [113, 122], [123, 128], [129, 134], [135, 139], [140, 146], [146, 148], [149, 151], [152, 157], [157, 158], [159, 164], [165, 167], [168, 172], [173, 177], [178, 180], [181, 192], [193, 196], [197, 205], [205, 206]]}
{"doc_key": "ai-test-143", "ner": [[9, 9, "task"], [13, 18, "metrics"], [24, 26, "misc"], [27, 27, "metrics"], [29, 29, "metrics"], [32, 32, "metrics"], [34, 34, "metrics"], [36, 38, "metrics"], [41, 41, "metrics"], [43, 43, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[13, 18, 24, 26, "related-to", "is_a", false, false], [13, 18, 27, 27, "usage", "", false, false], [13, 18, 29, 29, "usage", "", false, false], [27, 27, 32, 32, "named", "same", false, false], [29, 29, 43, 43, "named", "same", false, false], [32, 32, 41, 41, "opposite", "", false, false], [32, 32, 43, 43, "opposite", "", false, false], [34, 34, 32, 32, "named", "", false, false], [36, 38, 32, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["An", "unrelated", "but", "commonly", "used", "combination", "of", "basic", "information", "retrieval", "statistics", "is", "the", "F", "-", "point", ",", "which", "is", "the", "(", "possibly", "weighted", ")", "harmonic", "mean", "of", "recall", "and", "precision", ",", "where", "recall", "=", "sensitivity", "=", "true", "positive", "rate", ",", "and", "specificity", "and", "precision", "are", "completely", "different", "measures", "."], "sentence-detokenized": "An unrelated but commonly used combination of basic information retrieval statistics is the F-point, which is the (possibly weighted) harmonic mean of recall and precision, where recall = sensitivity = true positive rate, and specificity and precision are completely different measures.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 25], [26, 30], [31, 42], [43, 45], [46, 51], [52, 63], [64, 73], [74, 84], [85, 87], [88, 91], [92, 93], [93, 94], [94, 99], [99, 100], [101, 106], [107, 109], [110, 113], [114, 115], [115, 123], [124, 132], [132, 133], [134, 142], [143, 147], [148, 150], [151, 157], [158, 161], [162, 171], [171, 172], [173, 178], [179, 185], [186, 187], [188, 199], [200, 201], [202, 206], [207, 215], [216, 220], [220, 221], [222, 225], [226, 237], [238, 241], [242, 251], [252, 255], [256, 266], [267, 276], [277, 285], [285, 286]]}
{"doc_key": "ai-test-144", "ner": [[0, 1, "field"], [10, 10, "field"], [12, 12, "field"], [14, 14, "field"], [16, 17, "field"], [19, 21, "field"], [29, 30, "product"], [32, 35, "product"], [37, 38, "product"], [40, 43, "product"], [54, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 10, "origin", "takes_inspiration_from", false, false], [0, 1, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 1, 14, 14, "origin", "takes_inspiration_from", false, false], [0, 1, 16, 17, "origin", "takes_inspiration_from", false, false], [0, 1, 19, 21, "origin", "takes_inspiration_from", false, false], [29, 30, 0, 1, "origin", "", false, false], [32, 35, 0, 1, "origin", "", false, false], [37, 38, 0, 1, "origin", "", false, false], [40, 43, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "is", "an", "interdisciplinary", "field", "that", "draws", "inspiration", "from", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", "and", "electronic", "engineering", "to", "design", "artificial", "neural", "systems", ",", "such", "as", "vision", "systems", ",", "head", "-", "vision", "systems", ",", "auditory", "processors", "and", "autonomous", "robots", ",", "whose", "physical", "architecture", "and", "design", "principles", "are", "based", "on", "those", "of", "biological", "nervous", "systems", "."], "sentence-detokenized": "Neuromorphic engineering is an interdisciplinary field that draws inspiration from biology, physics, mathematics, computer science and electronic engineering to design artificial neural systems, such as vision systems, head-vision systems, auditory processors and autonomous robots, whose physical architecture and design principles are based on those of biological nervous systems.", "token2charspan": [[0, 12], [13, 24], [25, 27], [28, 30], [31, 48], [49, 54], [55, 59], [60, 65], [66, 77], [78, 82], [83, 90], [90, 91], [92, 99], [99, 100], [101, 112], [112, 113], [114, 122], [123, 130], [131, 134], [135, 145], [146, 157], [158, 160], [161, 167], [168, 178], [179, 185], [186, 193], [193, 194], [195, 199], [200, 202], [203, 209], [210, 217], [217, 218], [219, 223], [223, 224], [224, 230], [231, 238], [238, 239], [240, 248], [249, 259], [260, 263], [264, 274], [275, 281], [281, 282], [283, 288], [289, 297], [298, 310], [311, 314], [315, 321], [322, 332], [333, 336], [337, 342], [343, 345], [346, 351], [352, 354], [355, 365], [366, 373], [374, 381], [381, 382]]}
{"doc_key": "ai-test-145", "ner": [[3, 5, "metrics"], [9, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 9, 3, 5, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Specifically", ",", "the", "BIBO", "stability", "criterion", "requires", "that", "the", "ROC", "of", "the", "system", "includes", "the", "unit", "circle", "."], "sentence-detokenized": "Specifically, the BIBO stability criterion requires that the ROC of the system includes the unit circle.", "token2charspan": [[0, 12], [12, 13], [14, 17], [18, 22], [23, 32], [33, 42], [43, 51], [52, 56], [57, 60], [61, 64], [65, 67], [68, 71], [72, 78], [79, 87], [88, 91], [92, 96], [97, 103], [103, 104]]}
{"doc_key": "ai-test-146", "ner": [[7, 9, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "The", "programme", "has", "been", "rewritten", "in", "Java", "since", "1998", "."], "sentence-detokenized": "2 The programme has been rewritten in Java since 1998.", "token2charspan": [[0, 1], [2, 5], [6, 15], [16, 19], [20, 24], [25, 34], [35, 37], [38, 42], [43, 48], [49, 53], [53, 54]]}
{"doc_key": "ai-test-147", "ner": [[0, 1, "metrics"], [8, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 8, 10, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "MCC", "can", "be", "calculated", "directly", "from", "the", "confusion", "matrix", "using", "the", "formula", ":"], "sentence-detokenized": "The MCC can be calculated directly from the confusion matrix using the formula:", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 25], [26, 34], [35, 39], [40, 43], [44, 53], [54, 60], [61, 66], [67, 70], [71, 78], [78, 79]]}
{"doc_key": "ai-test-148", "ner": [[8, 17, "organisation"], [19, 24, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 17, 19, 24, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "developed", "by", "a", "team", "at", "the", "MIT", "-", "IBM", "Watson", "AI", "Lab", "and", "first", "presented", "at", "the", "International", "Conference", "on", "Learning", "Demonstration", "2018", "."], "sentence-detokenized": "It was developed by a team at the MIT-IBM Watson AI Lab and first presented at the International Conference on Learning Demonstration 2018.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 29], [30, 33], [34, 37], [37, 38], [38, 41], [42, 48], [49, 51], [52, 55], [56, 59], [60, 65], [66, 75], [76, 78], [79, 82], [83, 96], [97, 107], [108, 110], [111, 119], [120, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-test-149", "ner": [[1, 5, "metrics"], [16, 17, "metrics"], [19, 22, "metrics"], [46, 46, "metrics"], [48, 48, "metrics"], [54, 58, "metrics"], [59, 59, "metrics"], [61, 61, "metrics"], [63, 63, "metrics"], [68, 68, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[16, 17, 46, 46, "type-of", "", false, false], [16, 17, 54, 58, "related-to", "collapses_to_identity", false, false], [19, 22, 48, 48, "type-of", "", false, false], [19, 22, 54, 58, "related-to", "collapses_to_identity", false, false], [19, 22, 63, 63, "named", "same", false, false], [59, 59, 68, 68, "related-to", "collapses_to_identity", false, false], [61, 61, 68, 68, "related-to", "collapses_to_identity", false, false], [63, 63, 68, 68, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["When", "the", "true", "prevalences", "for", "the", "two", "positive", "variables", "are", "the", "same", "as", "assumed", "for", "the", "Fleiss", "kappa", "and", "F-", "estimate", ",", "i.e.", "the", "number", "of", "positive", "predictions", "corresponds", "to", "the", "number", "of", "positive", "classes", "in", "the", "dichotomous", "case", "(", "two", "classes", ")", ",", "the", "different", "kappas", "and", "correlation", "measure", "reduce", "to", "identity", "with", "Youden", "'s", "J", ",", "where", "recall", ",", "precision", "and", "F-estimate", "are", "similarly", "identical", "with", "precision", "."], "sentence-detokenized": "When the true prevalences for the two positive variables are the same as assumed for the Fleiss kappa and F-estimate, i.e. the number of positive predictions corresponds to the number of positive classes in the dichotomous case (two classes), the different kappas and correlation measure reduce to identity with Youden's J, where recall, precision and F-estimate are similarly identical with precision.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 25], [26, 29], [30, 33], [34, 37], [38, 46], [47, 56], [57, 60], [61, 64], [65, 69], [70, 72], [73, 80], [81, 84], [85, 88], [89, 95], [96, 101], [102, 105], [106, 108], [108, 116], [116, 117], [118, 122], [123, 126], [127, 133], [134, 136], [137, 145], [146, 157], [158, 169], [170, 172], [173, 176], [177, 183], [184, 186], [187, 195], [196, 203], [204, 206], [207, 210], [211, 222], [223, 227], [228, 229], [229, 232], [233, 240], [240, 241], [241, 242], [243, 246], [247, 256], [257, 263], [264, 267], [268, 279], [280, 287], [288, 294], [295, 297], [298, 306], [307, 311], [312, 318], [318, 320], [321, 322], [322, 323], [324, 329], [330, 336], [336, 337], [338, 347], [348, 351], [352, 362], [363, 366], [367, 376], [377, 386], [387, 391], [392, 401], [401, 402]]}
{"doc_key": "ai-test-150", "ner": [[9, 15, "misc"], [13, 13, "misc"], [18, 18, "conference"], [2, 21, "task"], [22, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 15, 18, 18, "part-of", "", false, false], [9, 15, 18, 18, "physical", "", false, false], [9, 15, 18, 18, "temporal", "", false, false], [13, 13, 9, 15, "named", "", false, false], [2, 21, 9, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "first", "NLI", "Collaborative", "Task", "took", "place", "at", "the", "Building", "Educational", "Applications", "(", "BEA", ")", "workshop", "at", "the", "NAACL", "2013", "conference", ".", "Tetreault", "et", "al", ",", "2013", "29", "teams", "from", "all", "over", "the", "world", "participated", "in", "the", "competition", ",", "24", "of", "which", "also", "published", "a", "paper", "describing", "their", "systems", "and", "approaches", "."], "sentence-detokenized": "The first NLI Collaborative Task took place at the Building Educational Applications (BEA) workshop at the NAACL 2013 conference. Tetreault et al, 2013 29 teams from all over the world participated in the competition, 24 of which also published a paper describing their systems and approaches.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 27], [28, 32], [33, 37], [38, 43], [44, 46], [47, 50], [51, 59], [60, 71], [72, 84], [85, 86], [86, 89], [89, 90], [91, 99], [100, 102], [103, 106], [107, 112], [113, 117], [118, 128], [128, 129], [130, 139], [140, 142], [143, 145], [145, 146], [147, 151], [152, 154], [155, 160], [161, 165], [166, 169], [170, 174], [175, 178], [179, 184], [185, 197], [198, 200], [201, 204], [205, 216], [216, 217], [218, 220], [221, 223], [224, 229], [230, 234], [235, 244], [245, 246], [247, 252], [253, 263], [264, 269], [270, 277], [278, 281], [282, 292], [292, 293]]}
{"doc_key": "ai-test-151", "ner": [[0, 2, "algorithm"], [5, 8, "algorithm"], [15, 16, "misc"], [20, 23, "misc"], [37, 38, "misc"], [41, 42, "algorithm"], [45, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 5, 8, "type-of", "", false, false], [0, 2, 15, 16, "related-to", "finds", false, false], [20, 23, 15, 16, "type-of", "", false, false], [45, 45, 41, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Viterbi", "algorithm", "is", "a", "dynamic", "programming", "algorithm", "for", "finding", "the", "most", "likely", "sequence", "of", "hidden", "states", ",", "called", "the", "Viterbi", "path", ",", "that", "leads", "to", "a", "sequence", "of", "observed", "events", ",", "especially", "in", "the", "context", "of", "Markov", "information", "sources", "and", "Hidden", "Markov", "Models", "(", "HMMs", ")", "."], "sentence-detokenized": "The Viterbi algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states, called the Viterbi path, that leads to a sequence of observed events, especially in the context of Markov information sources and Hidden Markov Models (HMMs).", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 24], [25, 26], [27, 34], [35, 46], [47, 56], [57, 60], [61, 68], [69, 72], [73, 77], [78, 84], [85, 93], [94, 96], [97, 103], [104, 110], [110, 111], [112, 118], [119, 122], [123, 130], [131, 135], [135, 136], [137, 141], [142, 147], [148, 150], [151, 152], [153, 161], [162, 164], [165, 173], [174, 180], [180, 181], [182, 192], [193, 195], [196, 199], [200, 207], [208, 210], [211, 217], [218, 229], [230, 237], [238, 241], [242, 248], [249, 255], [256, 262], [263, 264], [264, 268], [268, 269], [269, 270]]}
{"doc_key": "ai-test-152", "ner": [[1, 1, "field"], [3, 5, "algorithm"], [8, 9, "misc"], [12, 13, "algorithm"], [16, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 1, 1, "part-of", "", false, false], [3, 5, 8, 9, "general-affiliation", "", false, false], [3, 5, 12, 13, "related-to", "generalizes_from", false, false], [3, 5, 16, 21, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "multinomial", "logistic", "regression", "is", "a", "classification", "method", "that", "generalises", "logistic", "regression", "to", "a", "multi", "-class", "classification", ",", "i.e.", "with", "more", "than", "two", "possible", "discrete", "outcomes", "."], "sentence-detokenized": "In statistics, multinomial logistic regression is a classification method that generalises logistic regression to a multi-class classification, i.e. with more than two possible discrete outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 26], [27, 35], [36, 46], [47, 49], [50, 51], [52, 66], [67, 73], [74, 78], [79, 90], [91, 99], [100, 110], [111, 113], [114, 115], [116, 121], [121, 127], [128, 142], [142, 143], [144, 148], [149, 153], [154, 158], [159, 163], [164, 167], [168, 176], [177, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-test-153", "ner": [[0, 5, "algorithm"], [9, 10, "field"], [12, 14, "field"], [18, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 5, 9, 10, "part-of", "", false, false], [0, 5, 12, 14, "part-of", "", false, false], [18, 18, 0, 5, "usage", "", true, false], [20, 21, 0, 5, "usage", "", true, false], [23, 24, 0, 5, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden", "Markov", "models", "are", "known", "for", "their", "applications", "in", "reinforcement", "learning", "and", "temporal", "pattern", "recognition", ",", "such", "as", "speech", ",", "handwriting", "recognition", ",", "gesture", "recognition", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov models are known for their applications in reinforcement learning and temporal pattern recognition, such as speech, handwriting recognition, gesture recognition, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 30], [31, 34], [35, 40], [41, 53], [54, 56], [57, 70], [71, 79], [80, 83], [84, 92], [93, 100], [101, 112], [112, 113], [114, 118], [119, 121], [122, 128], [128, 129], [130, 141], [142, 153], [153, 154], [155, 162], [163, 174], [174, 175], [176, 180], [181, 188], [188, 189], [190, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-test-154", "ner": [[27, 28, "misc"], [18, 21, "metrics"], [23, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[27, 28, 23, 26, "named", "", false, false], [18, 21, 23, 26, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "essentially", "means", "that", "the", "conditional", "probability", "of", "a", "word", "given", "it", "s", "history", "is", "proportional", "to", "the", "maximum", "probability", "score", "of", "that", "n", "-", "graph", "if", "that", "graph", "was", "seen", "more", "than", "k", "times", "during", "learning", "."], "sentence-detokenized": "This essentially means that the conditional probability of a word given its history is proportional to the maximum probability score of that n-graph if that graph was seen more than k times during learning.", "token2charspan": [[0, 4], [5, 16], [17, 22], [23, 27], [28, 31], [32, 43], [44, 55], [56, 58], [59, 60], [61, 65], [66, 71], [72, 74], [74, 75], [76, 83], [84, 86], [87, 99], [100, 102], [103, 106], [107, 114], [115, 126], [127, 132], [133, 135], [136, 140], [141, 142], [142, 143], [143, 148], [149, 151], [152, 156], [157, 162], [163, 166], [167, 171], [172, 176], [177, 181], [182, 183], [184, 189], [190, 196], [197, 205], [205, 206]]}
{"doc_key": "ai-test-155", "ner": [[4, 5, "task"], [7, 8, "task"], [10, 15, "task"], [18, 23, "task"], [30, 32, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[30, 32, 18, 23, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "knowledge", "representation", ",", "rational", "reasoning", "and", "natural", "language", "understanding", ",", "as", "he", "believes", "that", "a", "deep", "understanding", "of", "language", "can", "currently", "only", "be", "achieved", "through", "extensive", "manual", "engineering", "of", "semantically", "rich", "formalisms", "in", "conjunction", "with", "statistical", "preferences", "."], "sentence-detokenized": "He is interested in knowledge representation, rational reasoning and natural language understanding, as he believes that a deep understanding of language can currently only be achieved through extensive manual engineering of semantically rich formalisms in conjunction with statistical preferences.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 29], [30, 44], [44, 45], [46, 54], [55, 64], [65, 68], [69, 76], [77, 85], [86, 99], [99, 100], [101, 103], [104, 106], [107, 115], [116, 120], [121, 122], [123, 127], [128, 141], [142, 144], [145, 153], [154, 157], [158, 167], [168, 172], [173, 175], [176, 184], [185, 192], [193, 202], [203, 209], [210, 221], [222, 224], [225, 237], [238, 242], [243, 253], [254, 256], [257, 268], [269, 273], [274, 285], [286, 297], [297, 298]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "JavaScript", ",", "Python", "or"], "sentence-detokenized": "In JavaScript, Python or", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 24]]}
{"doc_key": "ai-test-157", "ner": [[0, 2, "misc"], [6, 9, "misc"], [11, 11, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 9, "part-of", "", false, false], [6, 9, 11, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "Awards", "are", "published", "in", "AI", "Magazine", ",", "published", "by", "AAAI", "."], "sentence-detokenized": "The Newcomb Awards are published in AI Magazine, published by AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 32], [33, 35], [36, 38], [39, 47], [47, 48], [49, 58], [59, 61], [62, 66], [66, 67]]}
{"doc_key": "ai-test-158", "ner": [[0, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "root", "mean", "square", "error", "on", "a", "test", "set", "of", "100", "specimens", "is", "0.084", ",", "which", "is", "less", "than", "the", "unnormalised", "error", "."], "sentence-detokenized": "The root mean square error on a test set of 100 specimens is 0.084, which is less than the unnormalised error.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 20], [21, 26], [27, 29], [30, 31], [32, 36], [37, 40], [41, 43], [44, 47], [48, 57], [58, 60], [61, 66], [66, 67], [68, 73], [74, 76], [77, 81], [82, 86], [87, 90], [91, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-test-159", "ner": [[0, 4, "metrics"], [8, 14, "field"], [16, 18, "task"], [20, 20, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 14, 0, 4, "usage", "", false, false], [16, 18, 8, 14, "part-of", "task_part_of_field", false, false], [20, 20, 16, 18, "named", "", false, false], [23, 24, 8, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "F", "score", "is", "widely", "used", "in", "the", "natural", "language", "processing", "literature", ",", "for", "example", "for", "Named", "Entity", "Recognition", "(", "NER", ")", "and", "word", "segmentation", "."], "sentence-detokenized": "The F score is widely used in the natural language processing literature, for example for Named Entity Recognition (NER) and word segmentation.", "token2charspan": [[0, 3], [4, 5], [6, 11], [12, 14], [15, 21], [22, 26], [27, 29], [30, 33], [34, 41], [42, 50], [51, 61], [62, 72], [72, 73], [74, 77], [78, 85], [86, 89], [90, 95], [96, 102], [103, 114], [115, 116], [116, 119], [119, 120], [121, 124], [125, 129], [130, 142], [142, 143]]}
{"doc_key": "ai-test-160", "ner": [[0, 0, "product"], [5, 8, "product"], [17, 18, "misc"], [20, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 17, 18, "related-to", "performs_task", false, false], [0, 0, 20, 21, "related-to", "performs_task", false, false], [5, 8, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "commonly", "used", "in", "chat", "systems", "for", "a", "variety", "of", "purposes", ",", "including", "customer", "service", ",", "routing", "requests", "or", "collecting", "information", "."], "sentence-detokenized": "Chatbots are commonly used in chat systems for a variety of purposes, including customer service, routing requests or collecting information.", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 26], [27, 29], [30, 34], [35, 42], [43, 46], [47, 48], [49, 56], [57, 59], [60, 68], [68, 69], [70, 79], [80, 88], [89, 96], [96, 97], [98, 105], [106, 114], [115, 117], [118, 128], [129, 140], [140, 141]]}
{"doc_key": "ai-test-161", "ner": [[3, 9, "conference"], [13, 21, "conference"], [27, 37, "conference"], [44, 45, "conference"], [48, 51, "conference"], [53, 54, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 21, 3, 9, "named", "", false, false], [27, 37, 3, 9, "named", "", false, false], [44, 45, 27, 37, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Major", "journals", "include", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "later", "renamed", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "and", "since", "September", "2014", "renamed", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "after", "the", "merger", "with", "the", "ACM", "publication", ")", ",", "Computer", "Speech", "and", "Language", "and", "Speech", "Communication", "."], "sentence-detokenized": "Major journals include IEEE Transactions on Speech and Audio Processing (later renamed IEEE Transactions on Audio, Speech and Language Processing and since September 2014 renamed IEEE/ACM Transactions on Audio, Speech and Language Processing - after the merger with the ACM publication), Computer Speech and Language and Speech Communication.", "token2charspan": [[0, 5], [6, 14], [15, 22], [23, 27], [28, 40], [41, 43], [44, 50], [51, 54], [55, 60], [61, 71], [72, 73], [73, 78], [79, 86], [87, 91], [92, 104], [105, 107], [108, 113], [113, 114], [115, 121], [122, 125], [126, 134], [135, 145], [146, 149], [150, 155], [156, 165], [166, 170], [171, 178], [179, 183], [183, 184], [184, 187], [188, 200], [201, 203], [204, 209], [209, 210], [211, 217], [218, 221], [222, 230], [231, 241], [242, 243], [244, 249], [250, 253], [254, 260], [261, 265], [266, 269], [270, 273], [274, 285], [285, 286], [286, 287], [288, 296], [297, 303], [304, 307], [308, 316], [317, 320], [321, 327], [328, 341], [341, 342]]}
{"doc_key": "ai-test-162", "ner": [[0, 0, "algorithm"], [5, 6, "task"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 0, 0, "usage", "", false, false], [5, 6, 8, 9, "part-of", "task_part_of_field", false, false], [5, 6, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "is", "often", "used", "for", "data", "clustering", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "EM is often used for data clustering in machine learning and computer vision.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 20], [21, 25], [26, 36], [37, 39], [40, 47], [48, 56], [57, 60], [61, 69], [70, 76], [76, 77]]}
{"doc_key": "ai-test-163", "ner": [[8, 11, "metrics"], [22, 24, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 11, 22, 24, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["Although", "there", "is", "no", "perfect", "way", "to", "describe", "the", "confusion", "matrix", "of", "positive", "and", "negative", "results", "with", "a", "single", "number", ",", "the", "Matthews", "correlation", "coefficient", "is", "generally", "considered", "to", "be", "one", "of", "the", "best", "such", "measures", "."], "sentence-detokenized": "Although there is no perfect way to describe the confusion matrix of positive and negative results with a single number, the Matthews correlation coefficient is generally considered to be one of the best such measures.", "token2charspan": [[0, 8], [9, 14], [15, 17], [18, 20], [21, 28], [29, 32], [33, 35], [36, 44], [45, 48], [49, 58], [59, 65], [66, 68], [69, 77], [78, 81], [82, 90], [91, 98], [99, 103], [104, 105], [106, 112], [113, 119], [119, 120], [121, 124], [125, 133], [134, 145], [146, 157], [158, 160], [161, 170], [171, 181], [182, 184], [185, 187], [188, 191], [192, 194], [195, 198], [199, 203], [204, 208], [209, 217], [217, 218]]}
{"doc_key": "ai-test-164", "ner": [[12, 14, "field"], [28, 30, "field"], [32, 35, "field"], [37, 38, "algorithm"], [40, 41, "task"], [43, 44, "algorithm"], [49, 51, "algorithm"], [53, 54, "algorithm"], [60, 62, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[32, 35, 28, 30, "part-of", "subfield", false, false], [37, 38, 32, 35, "part-of", "", false, true], [40, 41, 32, 35, "part-of", "", false, true], [43, 44, 32, 35, "part-of", "", false, true], [49, 51, 32, 35, "part-of", "", false, true], [53, 54, 32, 35, "part-of", "", false, true], [60, 62, 32, 35, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "the", "size", "and", "complexity", "of", "datasets", "increased", ",", "direct", ",", "practical", "data", "analysis", "was", "complemented", "by", "indirect", ",", "automated", "data", "processing", ",", "aided", "by", "other", "discoveries", "in", "computing", ",", "especially", "in", "machine", "learning", ",", "such", "as", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "learning", "decision", "trees", "and", "decision", "rules", "(", "1960s", ")", ",", "and", "support", "vector", "machines", "(", "1990", "s", ")", "."], "sentence-detokenized": "As the size and complexity of datasets increased, direct, practical data analysis was complemented by indirect, automated data processing, aided by other discoveries in computing, especially in machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), learning decision trees and decision rules (1960s), and support vector machines (1990s).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 15], [16, 26], [27, 29], [30, 38], [39, 48], [48, 49], [50, 56], [56, 57], [58, 67], [68, 72], [73, 81], [82, 85], [86, 98], [99, 101], [102, 110], [110, 111], [112, 121], [122, 126], [127, 137], [137, 138], [139, 144], [145, 147], [148, 153], [154, 165], [166, 168], [169, 178], [178, 179], [180, 190], [191, 193], [194, 201], [202, 210], [210, 211], [212, 216], [217, 219], [220, 226], [227, 235], [235, 236], [237, 244], [245, 253], [253, 254], [255, 262], [263, 273], [274, 275], [275, 280], [280, 281], [281, 282], [283, 291], [292, 300], [301, 306], [307, 310], [311, 319], [320, 325], [326, 327], [327, 332], [332, 333], [333, 334], [335, 338], [339, 346], [347, 353], [354, 362], [363, 364], [364, 368], [368, 369], [369, 370], [370, 371]]}
{"doc_key": "ai-test-165", "ner": [[4, 4, "researcher"], [23, 24, "misc"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 24, 4, 4, "artifact", "", false, false], [23, 24, 13, 14, "artifact", "", false, false], [23, 24, 16, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "autumn", "2005", ",", "Thrun", ",", "together", "with", "his", "long", "-", "time", "collaborators", "Dieter", "Fox", "and", "Wolfram", "Burgard", ",", "published", "a", "textbook", "entitled", "Probabilistic", "Robotics", "."], "sentence-detokenized": "In autumn 2005, Thrun, together with his long-time collaborators Dieter Fox and Wolfram Burgard, published a textbook entitled Probabilistic Robotics.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 21], [21, 22], [23, 31], [32, 36], [37, 40], [41, 45], [45, 46], [46, 50], [51, 64], [65, 71], [72, 75], [76, 79], [80, 87], [88, 95], [95, 96], [97, 106], [107, 108], [109, 117], [118, 126], [127, 140], [141, 149], [149, 150]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereiramath", ",", "as", "follows", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereiramath, as follows:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 49], [49, 50], [51, 53], [54, 61], [61, 62]]}
{"doc_key": "ai-test-167", "ner": [[0, 1, "task"], [3, 3, "task"], [7, 7, "field"], [13, 14, "field"], [16, 18, "field"], [20, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 13, 14, "part-of", "task_part_of_field", false, false], [0, 1, 16, 18, "part-of", "task_part_of_field", false, false], [3, 3, 0, 1, "named", "", false, false], [13, 14, 7, 7, "part-of", "subfield", false, false], [16, 18, 7, 7, "part-of", "subfield", false, false], [20, 24, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Question", "Answering", "(", "QA", ")", "is", "a", "computational", "discipline", "in", "the", "field", "of", "information", "retrieval", "and", "natural", "language", "processing", "(", "NLP", ")", ",", "which", "is", "concerned", "with", "building", "systems", "that", "automatically", "answer", "people", "'s", "questions", "in", "natural", "language", "."], "sentence-detokenized": "Question Answering (QA) is a computational discipline in the field of information retrieval and natural language processing (NLP), which is concerned with building systems that automatically answer people's questions in natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 42], [43, 53], [54, 56], [57, 60], [61, 66], [67, 69], [70, 81], [82, 91], [92, 95], [96, 103], [104, 112], [113, 123], [124, 125], [125, 128], [128, 129], [129, 130], [131, 136], [137, 139], [140, 149], [150, 154], [155, 163], [164, 171], [172, 176], [177, 190], [191, 197], [198, 204], [204, 206], [207, 216], [217, 219], [220, 227], [228, 236], [236, 237]]}
{"doc_key": "ai-test-168", "ner": [[10, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "in", "the", "version", "of", "the", "metric", "used", "by", "NIST", "in", "the", "evaluation", "before", "2009", ",", "the", "shortest", "reference", "phrase", "was", "used", "instead", "."], "sentence-detokenized": "However, in the version of the metric used by NIST in the evaluation before 2009, the shortest reference phrase was used instead.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 37], [38, 42], [43, 45], [46, 50], [51, 53], [54, 57], [58, 68], [69, 75], [76, 80], [80, 81], [82, 85], [86, 94], [95, 104], [105, 111], [112, 115], [116, 120], [121, 128], [128, 129]]}
{"doc_key": "ai-test-169", "ner": [[5, 5, "person"], [14, 14, "product"]], "ner_mapping_to_source": [0, 2], "relations": [[5, 5, 14, 14, "related-to", "invests_in", false, false]], "relations_mapping_to_source": [0], "sentence": ["On", "27", "August", "2018", ",", "Toyota", "announced", "a", "$", "500", "million", "investment", "in", "Uber", "autonomous", "cars", "."], "sentence-detokenized": "On 27 August 2018, Toyota announced a $500 million investment in Uber autonomous cars.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 17], [17, 18], [19, 25], [26, 35], [36, 37], [38, 39], [39, 42], [43, 50], [51, 61], [62, 64], [65, 69], [70, 80], [81, 85], [85, 86]]}
{"doc_key": "ai-test-170", "ner": [[6, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sample", "maximum", "is", "the", "maximum", "likelihood", "estimate", "of", "the", "population", "maximum", ",", "but", "as", "noted", "above", ",", "it", "is", "biased", "."], "sentence-detokenized": "The sample maximum is the maximum likelihood estimate of the population maximum, but as noted above, it is biased.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 25], [26, 33], [34, 44], [45, 53], [54, 56], [57, 60], [61, 71], [72, 79], [79, 80], [81, 84], [85, 87], [88, 93], [94, 99], [99, 100], [101, 103], [104, 106], [107, 113], [113, 114]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [4, 4, "misc"], [7, 13, "metrics"], [18, 19, "algorithm"], [21, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 4, 4, "related-to", "overcomes", false, false], [0, 0, 7, 13, "related-to", "increases", false, false], [4, 4, 18, 19, "opposite", "", false, false], [4, 4, 21, 23, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "helps", "to", "eliminate", "synonymy", "by", "increasing", "retrieval", ",", "which", "is", "one", "of", "the", "most", "problematic", "limitations", "in", "keyword", "queries", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI helps to eliminate synonymy by increasing retrieval, which is one of the most problematic limitations in keyword queries and vector space models.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 22], [23, 31], [32, 34], [35, 45], [46, 55], [55, 56], [57, 62], [63, 65], [66, 69], [70, 72], [73, 76], [77, 81], [82, 93], [94, 105], [106, 108], [109, 116], [117, 124], [125, 128], [129, 135], [136, 141], [142, 148], [148, 149]]}
{"doc_key": "ai-test-172", "ner": [[0, 1, "task"], [16, 16, "programlang"], [18, 18, "programlang"], [20, 20, "programlang"], [22, 23, "programlang"], [25, 25, "programlang"], [27, 27, "programlang"], [29, 29, "programlang"], [31, 31, "programlang"], [33, 33, "programlang"], [35, 35, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 16, 16, "general-affiliation", "", false, false], [0, 1, 18, 18, "general-affiliation", "", false, false], [0, 1, 20, 20, "general-affiliation", "", false, false], [0, 1, 22, 23, "general-affiliation", "", false, false], [0, 1, 25, 25, "general-affiliation", "", false, false], [0, 1, 27, 27, "general-affiliation", "", false, false], [0, 1, 29, 29, "general-affiliation", "", false, false], [0, 1, 31, 31, "general-affiliation", "", false, false], [0, 1, 33, 33, "general-affiliation", "", false, false], [0, 1, 35, 35, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Data", "acquisition", "applications", "are", "typically", "controlled", "by", "software", "developed", "in", "various", "common", "programming", "languages", "such", "as", "Assembly", ",", "BASIC", ",", "C", ",", "C", "++", ",", "C#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "Data acquisition applications are typically controlled by software developed in various common programming languages such as Assembly, BASIC, C, C++, C#, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 4], [5, 16], [17, 29], [30, 33], [34, 43], [44, 54], [55, 57], [58, 66], [67, 76], [77, 79], [80, 87], [88, 94], [95, 106], [107, 116], [117, 121], [122, 124], [125, 133], [133, 134], [135, 140], [140, 141], [142, 143], [143, 144], [145, 146], [146, 148], [148, 149], [150, 152], [152, 153], [154, 161], [161, 162], [163, 167], [167, 168], [169, 176], [176, 177], [178, 182], [182, 183], [184, 190], [190, 191], [192, 196]]}
{"doc_key": "ai-test-173", "ner": [[3, 8, "organisation"], [6, 13, "product"], [9, 9, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 13, 3, 8, "artifact", "", false, false], [6, 13, 9, 9, "physical", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2003", ",", "Honda", "advertised", "a", "cogwheel", "in", "the", "UK", "and", "on", "the", "internet", "."], "sentence-detokenized": "In 2003, Honda advertised a cogwheel in the UK and on the internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 27], [28, 36], [37, 39], [40, 43], [44, 46], [47, 50], [51, 53], [54, 57], [58, 66], [66, 67]]}
{"doc_key": "ai-test-174", "ner": [[0, 4, "conference"], [6, 7, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 6, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Association", "for", "Computational", "Linguistics", "defines", "computational", "linguistics", "as", ":"], "sentence-detokenized": "The Association for Computational Linguistics defines computational linguistics as:", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 45], [46, 53], [54, 67], [68, 79], [80, 82], [82, 83]]}
{"doc_key": "ai-test-175", "ner": [[0, 3, "algorithm"], [9, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 9, 12, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Expectation", "maximisation", "algorithms", "can", "be", "used", "to", "calculate", "approximate", "maximum", "likelihood", "estimates", "of", "unknown", "state", "-", "space", "parameters", "in", "minimum", "-variance", "filters", "and", "smoothers", "."], "sentence-detokenized": "Expectation maximisation algorithms can be used to calculate approximate maximum likelihood estimates of unknown state-space parameters in minimum-variance filters and smoothers.", "token2charspan": [[0, 11], [12, 24], [25, 35], [36, 39], [40, 42], [43, 47], [48, 50], [51, 60], [61, 72], [73, 80], [81, 91], [92, 101], [102, 104], [105, 112], [113, 118], [118, 119], [119, 124], [125, 135], [136, 138], [139, 146], [146, 155], [156, 163], [164, 167], [168, 177], [177, 178]]}
{"doc_key": "ai-test-176", "ner": [[4, 4, "misc"], [6, 8, "person"], [10, 11, "person"], [13, 14, "person"], [17, 18, "misc"], [19, 20, "person"], [23, 24, "person"], [28, 28, "person"], [30, 31, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 8, 4, 4, "role", "actor_in", false, false], [10, 11, 4, 4, "role", "actor_in", false, false], [13, 14, 4, 4, "role", "actor_in", false, false], [19, 20, 17, 18, "role", "model_for", false, false], [28, 28, 30, 31, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "correspondents", "included", "former", "Baywatch", "actresses", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "and", "Traci", "Bingham", ",", "former", "Playboy", "Playmate", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", "and", "identical", "twins", "Randy", "and", "Jason", "Sklar", "."], "sentence-detokenized": "The correspondents included former Baywatch actresses Donna D'Errico, Carmen Electra and Traci Bingham, former Playboy Playmate Heidi Mark, comedian Arj Barker and identical twins Randy and Jason Sklar.", "token2charspan": [[0, 3], [4, 18], [19, 27], [28, 34], [35, 43], [44, 53], [54, 59], [60, 62], [62, 68], [68, 69], [70, 76], [77, 84], [85, 88], [89, 94], [95, 102], [102, 103], [104, 110], [111, 118], [119, 127], [128, 133], [134, 138], [138, 139], [140, 148], [149, 152], [153, 159], [160, 163], [164, 173], [174, 179], [180, 185], [186, 189], [190, 195], [196, 201], [201, 202]]}
{"doc_key": "ai-test-177", "ner": [[8, 9, "task"], [11, 11, "task"], [15, 18, "product"], [21, 22, "task"], [24, 27, "task"], [28, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [15, 18, 8, 9, "general-affiliation", "", false, false], [24, 27, 21, 22, "named", "", false, false], [28, 30, 21, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "is", "commonly", "used", "to", "create", "presentations", "for", "speech", "recognition", "(", "ASR", ")", ",", "e.g.", "the", "CMU", "Sphinx", "system", ",", "and", "speech", "synthesis", "(", "TTS", ")", ",", "e.g.", "the", "Festival", "system", "."], "sentence-detokenized": "It is commonly used to create presentations for speech recognition (ASR), e.g. the CMU Sphinx system, and speech synthesis (TTS), e.g. the Festival system.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 19], [20, 22], [23, 29], [30, 43], [44, 47], [48, 54], [55, 66], [67, 68], [68, 71], [71, 72], [72, 73], [74, 78], [79, 82], [83, 86], [87, 93], [94, 100], [100, 101], [102, 105], [106, 112], [113, 122], [123, 124], [124, 127], [127, 128], [128, 129], [130, 134], [135, 138], [139, 147], [148, 154], [154, 155]]}
{"doc_key": "ai-test-178", "ner": [[0, 1, "metrics"], [3, 5, "metrics"], [7, 10, "metrics"], [13, 13, "metrics"], [28, 29, "metrics"], [31, 31, "metrics"], [42, 43, "metrics"], [45, 45, "metrics"], [47, 49, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 5, 0, 1, "named", "", false, false], [7, 10, 3, 5, "named", "", false, false], [13, 13, 0, 1, "named", "", false, false], [31, 31, 28, 29, "named", "", false, false], [45, 45, 42, 43, "named", "", false, false], [47, 49, 42, 43, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "sensitivity", "or", "TRUE", "Positive", "Rate", "(", "TPR", ")", ",", "also", "known", "as", "recall", ",", "is", "the", "proportion", "of", "people", "who", "have", "tested", "positive", "and", "are", "positive", "(", "TRUE", "Positive", ",", "TP", ")", "out", "of", "all", "people", "who", "are", "actually", "positive", "(", "Condition", "Positive", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "The sensitivity or TRUE Positive Rate (TPR), also known as recall, is the proportion of people who have tested positive and are positive (TRUE Positive, TP) out of all people who are actually positive (Condition Positive, CP = TP + FN).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 23], [24, 32], [33, 37], [38, 39], [39, 42], [42, 43], [43, 44], [45, 49], [50, 55], [56, 58], [59, 65], [65, 66], [67, 69], [70, 73], [74, 84], [85, 87], [88, 94], [95, 98], [99, 103], [104, 110], [111, 119], [120, 123], [124, 127], [128, 136], [137, 138], [138, 142], [143, 151], [151, 152], [153, 155], [155, 156], [157, 160], [161, 163], [164, 167], [168, 174], [175, 178], [179, 182], [183, 191], [192, 200], [201, 202], [202, 211], [212, 220], [220, 221], [222, 224], [225, 226], [227, 229], [230, 231], [232, 234], [234, 235], [235, 236]]}
{"doc_key": "ai-test-179", "ner": [[1, 2, "task"], [10, 10, "conference"], [12, 13, "conference"], [15, 15, "conference"], [17, 19, "conference"], [21, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6], "relations": [[10, 10, 1, 2, "topic", "", false, false], [12, 13, 1, 2, "topic", "", false, false], [15, 15, 1, 2, "topic", "", false, false], [17, 19, 1, 2, "topic", "", false, false], [21, 22, 1, 2, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5], "sentence": ["Popular", "speech", "recognition", "conferences", "held", "every", "year", "or", "two", "include", "SpeechTEK", "and", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "and", "IEEE", "ASRU", "."], "sentence-detokenized": "Popular speech recognition conferences held every year or two include SpeechTEK and SpeechTEK Europe, ICASSP, Interspeech/Eurospeech and IEEE ASRU.", "token2charspan": [[0, 7], [8, 14], [15, 26], [27, 38], [39, 43], [44, 49], [50, 54], [55, 57], [58, 61], [62, 69], [70, 79], [80, 83], [84, 93], [94, 100], [100, 101], [102, 108], [108, 109], [110, 121], [121, 122], [122, 132], [133, 136], [137, 141], [142, 146], [146, 147]]}
{"doc_key": "ai-test-180", "ner": [[0, 3, "researcher"], [5, 9, "researcher"], [17, 19, "product"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 23, 0, 3, "artifact", "", false, false], [22, 23, 5, 9, "artifact", "", false, false], [22, 23, 17, 19, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", ",", "in", "collaboration", "with", "Engelberger", ",", "who", "was", "the", "company", "'s", "president", ",", "designed", "and", "built", "an", "industrial", "robot", "under", "the", "Unimate", "brand", "."], "sentence-detokenized": "Devol, in collaboration with Engelberger, who was the company's president, designed and built an industrial robot under the Unimate brand.", "token2charspan": [[0, 5], [5, 6], [7, 9], [10, 23], [24, 28], [29, 40], [40, 41], [42, 45], [46, 49], [50, 53], [54, 61], [61, 63], [64, 73], [73, 74], [75, 83], [84, 87], [88, 93], [94, 96], [97, 107], [108, 113], [114, 119], [120, 123], [124, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-test-181", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [9, 14, "algorithm"], [23, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 9, 14, "general-affiliation", "", false, false], [5, 5, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "Hidden", "Markov", "Model", "(", "HMM", ")", "is", "a", "statistical", "Markov", "model", "in", "which", "the", "system", "being", "modelled", "is", "assumed", "to", "be", "a", "Markov", "process", "with", "unobservable", "(", "hidden", ")", "states", "."], "sentence-detokenized": "A Hidden Markov Model (HMM) is a statistical Markov model in which the system being modelled is assumed to be a Markov process with unobservable (hidden) states.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [22, 23], [23, 26], [26, 27], [28, 30], [31, 32], [33, 44], [45, 51], [52, 57], [58, 60], [61, 66], [67, 70], [71, 77], [78, 83], [84, 92], [93, 95], [96, 103], [104, 106], [107, 109], [110, 111], [112, 118], [119, 126], [127, 131], [132, 144], [145, 146], [146, 152], [152, 153], [154, 160], [160, 161]]}
{"doc_key": "ai-test-182", "ner": [[19, 21, "metrics"], [27, 27, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "feature", ",", "which", "is", "undesirable", "in", "many", "applications", ",", "has", "led", "researchers", "to", "use", "alternative", "methods", "such", "as", "mean", "absolute", "error", "or", "those", "based", "on", "the", "median", "."], "sentence-detokenized": "This feature, which is undesirable in many applications, has led researchers to use alternative methods such as mean absolute error or those based on the median.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 19], [20, 22], [23, 34], [35, 37], [38, 42], [43, 55], [55, 56], [57, 60], [61, 64], [65, 76], [77, 79], [80, 83], [84, 95], [96, 103], [104, 108], [109, 111], [112, 116], [117, 125], [126, 131], [132, 134], [135, 140], [141, 146], [147, 149], [150, 153], [154, 160], [160, 161]]}
{"doc_key": "ai-test-183", "ner": [[23, 24, "algorithm"], [32, 33, "field"], [36, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 32, 33, "part-of", "", false, false], [23, 24, 36, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Such", "a", "sequence", "(", "which", "at", "each", "stage", "depends", "on", "the", "outcome", "of", "the", "investigation", "of", "the", "previous", "attributes", ")", "is", "called", "a", "decision", "tree", "and", "is", "used", "in", "the", "field", "of", "machine", "learning", "known", "as", "decision", "tree", "learning", "."], "sentence-detokenized": "Such a sequence (which at each stage depends on the outcome of the investigation of the previous attributes) is called a decision tree and is used in the field of machine learning known as decision tree learning.", "token2charspan": [[0, 4], [5, 6], [7, 15], [16, 17], [17, 22], [23, 25], [26, 30], [31, 36], [37, 44], [45, 47], [48, 51], [52, 59], [60, 62], [63, 66], [67, 80], [81, 83], [84, 87], [88, 96], [97, 107], [107, 108], [109, 111], [112, 118], [119, 120], [121, 129], [130, 134], [135, 138], [139, 141], [142, 146], [147, 149], [150, 153], [154, 159], [160, 162], [163, 170], [171, 179], [180, 185], [186, 188], [189, 197], [198, 202], [203, 211], [211, 212]]}
{"doc_key": "ai-test-184", "ner": [[2, 3, "task"], [5, 5, "algorithm"], [15, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 5, 5, "compare", "", false, false], [15, 17, 5, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "with", "factor", "analysis", ",", "LCA", "can", "be", "used", "to", "classify", "cases", "according", "to", "their", "maximum", "likelihood", "of", "belonging", "to", "the", "classes", "."], "sentence-detokenized": "As with factor analysis, LCA can be used to classify cases according to their maximum likelihood of belonging to the classes.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 23], [23, 24], [25, 28], [29, 32], [33, 35], [36, 40], [41, 43], [44, 52], [53, 58], [59, 68], [69, 71], [72, 77], [78, 85], [86, 96], [97, 99], [100, 109], [110, 112], [113, 116], [117, 124], [124, 125]]}
{"doc_key": "ai-test-185", "ner": [[0, 3, "algorithm"], [5, 7, "metrics"], [9, 9, "metrics"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 5, 7, "usage", "", false, false], [5, 7, 11, 12, "related-to", "", false, false], [9, 9, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Supervised", "neural", "networks", "using", "the", "mean", "squared", "error", "(", "MSE", ")", "cost", "function", "can", "use", "formal", "statistical", "methods", "to", "determine", "the", "confidence", "of", "the", "learned", "model", "."], "sentence-detokenized": "Supervised neural networks using the mean squared error (MSE) cost function can use formal statistical methods to determine the confidence of the learned model.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 32], [33, 36], [37, 41], [42, 49], [50, 55], [56, 57], [57, 60], [60, 61], [62, 66], [67, 75], [76, 79], [80, 83], [84, 90], [91, 102], [103, 110], [111, 113], [114, 123], [124, 127], [128, 138], [139, 141], [142, 145], [146, 153], [154, 159], [159, 160]]}
{"doc_key": "ai-test-186", "ner": [[17, 21, "algorithm"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 21, 22, 23, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "expressed", "directly", "as", "a", "linear", "program", ",", "but", "it", "is", "also", "equivalent", "to", "a", "Tikhonov", "regularisation", "with", "a", "rate", "loss", "function", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=\\", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "This can be expressed directly as a linear program, but it is also equivalent to a Tikhonov regularisation with a rate loss function, mathV (f (x), y) =\\ max (0, 1 - yf (x)) / math:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 21], [22, 30], [31, 33], [34, 35], [36, 42], [43, 50], [50, 51], [52, 55], [56, 58], [59, 61], [62, 66], [67, 77], [78, 80], [81, 82], [83, 91], [92, 106], [107, 111], [112, 113], [114, 118], [119, 123], [124, 132], [132, 133], [134, 139], [140, 141], [141, 142], [143, 144], [144, 145], [145, 146], [146, 147], [148, 149], [149, 150], [151, 153], [154, 157], [158, 159], [159, 160], [160, 161], [162, 163], [164, 165], [166, 168], [169, 170], [170, 171], [171, 172], [172, 173], [174, 175], [176, 180], [180, 181]]}
{"doc_key": "ai-test-187", "ner": [[6, 7, "researcher"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "technique", "is", "described", "in", "Breiman", "'s", "original", "paper", "and", "is", "implemented", "in", "the", "R", "package", "randomForest", "."], "sentence-detokenized": "The following technique is described in Breiman's original paper and is implemented in the R package randomForest.", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 26], [27, 36], [37, 39], [40, 47], [47, 49], [50, 58], [59, 64], [65, 68], [69, 71], [72, 83], [84, 86], [87, 90], [91, 92], [93, 100], [101, 113], [113, 114]]}
{"doc_key": "ai-test-188", "ner": [[6, 6, "metrics"], [37, 37, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "image", "quality", "measures", "such", "as", "PSNR", "are", "usually", "performed", "on", "fixed", "resolution", "images", "and", "do", "not", "take", "into", "account", "some", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "the", "change", "in", "spatial", "resolution", "on", "the", "retina", "."], "sentence-detokenized": "Traditional image quality measures such as PSNR are usually performed on fixed resolution images and do not take into account some aspects of the human visual system, such as the change in spatial resolution on the retina.", "token2charspan": [[0, 11], [12, 17], [18, 25], [26, 34], [35, 39], [40, 42], [43, 47], [48, 51], [52, 59], [60, 69], [70, 72], [73, 78], [79, 89], [90, 96], [97, 100], [101, 103], [104, 107], [108, 112], [113, 117], [118, 125], [126, 130], [131, 138], [139, 141], [142, 145], [146, 151], [152, 158], [159, 165], [165, 166], [167, 171], [172, 174], [175, 178], [179, 185], [186, 188], [189, 196], [197, 207], [208, 210], [211, 214], [215, 221], [221, 222]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [10, 12, "person"], [16, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 21, "role", "", false, false], [3, 4, 16, 21, "role", "", false, false], [6, 7, 16, 21, "role", "", false, false], [16, 21, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "and", "Macdonald", "Carey", "starred", "in", "Jack", "Broder", "'s", "colour", "production", "of", "Hannah", "Lee", ",", "which", "premiered", "on", "19", "June", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru and Macdonald Carey starred in Jack Broder's colour production of Hannah Lee, which premiered on 19 June 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 55], [56, 60], [61, 67], [67, 69], [70, 76], [77, 87], [88, 90], [91, 97], [98, 101], [101, 102], [103, 108], [109, 118], [119, 121], [122, 124], [125, 129], [130, 134], [134, 135]]}
{"doc_key": "ai-test-190", "ner": [[4, 6, "task"], [9, 11, "field"], [16, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 9, 11, "usage", "", false, false], [16, 16, 9, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "process", "is", "called", "image", "registration", "and", "uses", "various", "computer", "vision", "methods", ",", "mostly", "related", "to", "tracking", "."], "sentence-detokenized": "This process is called image registration and uses various computer vision methods, mostly related to tracking.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 22], [23, 28], [29, 41], [42, 45], [46, 50], [51, 58], [59, 67], [68, 74], [75, 82], [82, 83], [84, 90], [91, 98], [99, 101], [102, 110], [110, 111]]}
{"doc_key": "ai-test-191", "ner": [[18, 20, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Now", "let", "'s", "start", "to", "explain", "the", "different", "possible", "relationships", "between", "the", "predicted", "and", "the", "actual", "result", ":", "the", "confusion", "matrix"], "sentence-detokenized": "Now let's start to explain the different possible relationships between the predicted and the actual result: the confusion matrix", "token2charspan": [[0, 3], [4, 7], [7, 9], [10, 15], [16, 18], [19, 26], [27, 30], [31, 40], [41, 49], [50, 63], [64, 71], [72, 75], [76, 85], [86, 89], [90, 93], [94, 100], [101, 107], [107, 108], [109, 112], [113, 122], [123, 129]]}
{"doc_key": "ai-test-192", "ner": [[0, 1, "product"], [2, 4, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 2, 4, "part-of", "", false, false], [0, 1, 2, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "VOICEBOX", "speech", "processing", "tool", "for", "MATLAB", "performs", "the", "conversion", "and", "its", "inverse", "conversion", "as", ":"], "sentence-detokenized": "The VOICEBOX speech processing tool for MATLAB performs the conversion and its inverse conversion as:", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 30], [31, 35], [36, 39], [40, 46], [47, 55], [56, 59], [60, 70], [71, 74], [75, 78], [79, 86], [87, 97], [98, 100], [100, 101]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "general-affiliation", "", false, false], [0, 0, 11, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logic", "programming", "language", "related", "to", "artificial", "intelligence", "and", "computational", "linguistics", "."], "sentence-detokenized": "Prolog is a logic programming language related to artificial intelligence and computational linguistics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 17], [18, 29], [30, 38], [39, 46], [47, 49], [50, 60], [61, 73], [74, 77], [78, 91], [92, 103], [103, 104]]}
{"doc_key": "ai-test-194", "ner": [[0, 1, "researcher"], [9, 9, "field"], [11, 11, "field"], [17, 20, "organisation"], [23, 26, "organisation"], [29, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 9, 9, "related-to", "works_with_topic", false, false], [0, 1, 11, 11, "related-to", "works_with_topic", false, false], [0, 1, 17, 20, "role", "", false, false], [0, 1, 23, 26, "role", "", false, false], [0, 1, 29, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "numerous", "awards", "for", "her", "contributions", "to", "neuroscience", "and", "psychology", ",", "including", "membership", "of", "the", "Royal", "Society", "of", "London", ",", "the", "Royal", "Society", "of", "Canada", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received numerous awards for her contributions to neuroscience and psychology, including membership of the Royal Society of London, the Royal Society of Canada and the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 35], [36, 39], [40, 43], [44, 57], [58, 60], [61, 73], [74, 77], [78, 88], [88, 89], [90, 99], [100, 110], [111, 113], [114, 117], [118, 123], [124, 131], [132, 134], [135, 141], [141, 142], [143, 146], [147, 152], [153, 160], [161, 163], [164, 170], [171, 174], [175, 178], [179, 187], [188, 195], [196, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-195", "ner": [[11, 16, "field"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 18, 11, 16, "part-of", "task_part_of_field", false, false], [20, 21, 11, 16, "part-of", "task_part_of_field", false, false], [23, 24, 11, 16, "part-of", "task_part_of_field", false, false], [26, 27, 11, 16, "part-of", "task_part_of_field", false, false], [29, 29, 11, 16, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["By", "combining", "these", "operators", ",", "we", "can", "obtain", "algorithms", "for", "many", "image", "processing", "tasks", ",", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "sharpening", ",", "image", "filtering", "and", "classification", "."], "sentence-detokenized": "By combining these operators, we can obtain algorithms for many image processing tasks, such as feature extraction, image segmentation, image sharpening, image filtering and classification.", "token2charspan": [[0, 2], [3, 12], [13, 18], [19, 28], [28, 29], [30, 32], [33, 36], [37, 43], [44, 54], [55, 58], [59, 63], [64, 69], [70, 80], [81, 86], [86, 87], [88, 92], [93, 95], [96, 103], [104, 114], [114, 115], [116, 121], [122, 134], [134, 135], [136, 141], [142, 152], [152, 153], [154, 159], [160, 169], [170, 173], [174, 188], [188, 189]]}
{"doc_key": "ai-test-196", "ner": [[7, 12, "university"], [15, 17, "organisation"], [19, 20, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 20, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "has", "been", "a", "professor", "at", "the", "Coll\u00e8ge", "de", "France", "since", "2017", "and", "Director", "of", "INSERM", "Unit", "562", ",", "Cognitive", "Neuroimaging", ",", "since", "1989", "."], "sentence-detokenized": "He has been a professor at the Coll\u00e8ge de France since 2017 and Director of INSERM Unit 562, Cognitive Neuroimaging, since 1989.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 13], [14, 23], [24, 26], [27, 30], [31, 38], [39, 41], [42, 48], [49, 54], [55, 59], [60, 63], [64, 72], [73, 75], [76, 82], [83, 87], [88, 91], [91, 92], [93, 102], [103, 115], [115, 116], [117, 122], [123, 127], [127, 128]]}
{"doc_key": "ai-test-197", "ner": [[12, 18, "algorithm"], [15, 22, "algorithm"], [24, 24, "algorithm"], [26, 32, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[24, 24, 26, 32, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "many", "approaches", "to", "learning", "these", "captures", ",", "in", "particular", "with", "Bayesian", "clustering", "or", "energy", "-", "based", "frameworks", ",", "and", "more", "recently", "with", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", "2013", ")", "."], "sentence-detokenized": "There are many approaches to learning these captures, in particular with Bayesian clustering or energy-based frameworks, and more recently with TransE (Conference on Neural Information Processing Systems 2013).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 25], [26, 28], [29, 37], [38, 43], [44, 52], [52, 53], [54, 56], [57, 67], [68, 72], [73, 81], [82, 92], [93, 95], [96, 102], [102, 103], [103, 108], [109, 119], [119, 120], [121, 124], [125, 129], [130, 138], [139, 143], [144, 150], [151, 152], [152, 162], [163, 165], [166, 172], [173, 184], [185, 195], [196, 203], [204, 208], [208, 209], [209, 210]]}
{"doc_key": "ai-test-198", "ner": [[7, 8, "metrics"], [9, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 13, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "is", "an", "alternative", "to", "the", "Word", "Error", "Rate", ",", "which", "is", "used", "in", "several", "countries", "."], "sentence-detokenized": "It is an alternative to the Word Error Rate, which is used in several countries.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 23], [24, 27], [28, 32], [33, 38], [39, 43], [43, 44], [45, 50], [51, 53], [54, 58], [59, 61], [62, 69], [70, 79], [79, 80]]}
{"doc_key": "ai-test-199", "ner": [[0, 1, "algorithm"], [9, 10, "task"], [12, 13, "task"], [15, 16, "task"], [18, 20, "task"], [22, 25, "task"], [27, 28, "task"], [43, 43, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 10, 0, 1, "usage", "", false, false], [12, 13, 0, 1, "usage", "", false, false], [15, 16, 0, 1, "usage", "", false, false], [18, 20, 0, 1, "usage", "", false, false], [22, 25, 0, 1, "usage", "", false, false], [27, 28, 0, 1, "usage", "", false, false], [43, 43, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "are", "used", "for", "a", "variety", "of", "tasks", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "social", "and", "video", "gaming", ",", "medical", "diagnostics", "and", "even", "for", "activities", "that", "have", "traditionally", "been", "reserved", "for", "humans", ",", "such", "as", "imaging", "."], "sentence-detokenized": "ANNs are used for a variety of tasks including computer vision, speech recognition, machine translation, social network filtering, social and video gaming, medical diagnostics and even for activities that have traditionally been reserved for humans, such as imaging.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 17], [18, 19], [20, 27], [28, 30], [31, 36], [37, 46], [47, 55], [56, 62], [62, 63], [64, 70], [71, 82], [82, 83], [84, 91], [92, 103], [103, 104], [105, 111], [112, 119], [120, 129], [129, 130], [131, 137], [138, 141], [142, 147], [148, 154], [154, 155], [156, 163], [164, 175], [176, 179], [180, 184], [185, 188], [189, 199], [200, 204], [205, 209], [210, 223], [224, 228], [229, 237], [238, 241], [242, 248], [248, 249], [250, 254], [255, 257], [258, 265], [265, 266]]}
{"doc_key": "ai-test-200", "ner": [[0, 4, "product"], [6, 6, "product"], [25, 27, "field"], [29, 29, "field"], [34, 34, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 25, 27, "related-to", "", false, false], [0, 4, 34, 34, "general-affiliation", "", false, false], [6, 6, 0, 4, "named", "", false, false], [29, 29, 25, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "is", "an", "open", "source", "research", "platform", "and", "collection", "of", "voice", ",", "audio", ",", "speech", ",", "text", "and", "natural", "language", "processing", "(", "NLP", ")", "algorithms", "written", "in", "Java", "and", "organized", "in", "a", "modular", "and", "extensible", "framework", "that", "seeks", "to", "facilitate", "the", "addition", "of", "new", "algorithms", "."], "sentence-detokenized": "The Modular Audio Recognition Framework (MARF) is an open source research platform and collection of voice, audio, speech, text and natural language processing (NLP) algorithms written in Java and organized in a modular and extensible framework that seeks to facilitate the addition of new algorithms.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 29], [30, 39], [40, 41], [41, 45], [45, 46], [47, 49], [50, 52], [53, 57], [58, 64], [65, 73], [74, 82], [83, 86], [87, 97], [98, 100], [101, 106], [106, 107], [108, 113], [113, 114], [115, 121], [121, 122], [123, 127], [128, 131], [132, 139], [140, 148], [149, 159], [160, 161], [161, 164], [164, 165], [166, 176], [177, 184], [185, 187], [188, 192], [193, 196], [197, 206], [207, 209], [210, 211], [212, 219], [220, 223], [224, 234], [235, 244], [245, 249], [250, 255], [256, 258], [259, 269], [270, 273], [274, 282], [283, 285], [286, 289], [290, 300], [300, 301]]}
{"doc_key": "ai-test-201", "ner": [[12, 14, "organisation"], [21, 21, "country"], [22, 24, "organisation"], [27, 35, "organisation"], [33, 34, "task"], [54, 57, "organisation"], [51, 52, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[22, 24, 21, 21, "physical", "", false, false], [22, 24, 33, 34, "usage", "", false, false], [22, 24, 54, 57, "named", "", false, false], [27, 35, 21, 21, "physical", "", false, false], [27, 35, 33, 34, "usage", "", false, false], [54, 57, 51, 52, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "a", "report", "by", "civil", "liberties", "and", "civil", "rights", "organisation", "Big", "Brother", "Watch", "revealed", "that", "two", "UK", "police", "forces", ",", "South", "Wales", "Police", "and", "the", "Metropolitan", "Police", ",", "were", "using", "live", "facial", "recognition", "at", "public", "events", "and", "in", "public", "spaces", ",", "and", "in", "September", "2019", ",", "the", "use", "of", "facial", "recognition", "by", "South", "Wales", "Police", "was", "declared", "legal", "."], "sentence-detokenized": "In 2018, a report by civil liberties and civil rights organisation Big Brother Watch revealed that two UK police forces, South Wales Police and the Metropolitan Police, were using live facial recognition at public events and in public spaces, and in September 2019, the use of facial recognition by South Wales Police was declared legal.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 20], [21, 26], [27, 36], [37, 40], [41, 46], [47, 53], [54, 66], [67, 70], [71, 78], [79, 84], [85, 93], [94, 98], [99, 102], [103, 105], [106, 112], [113, 119], [119, 120], [121, 126], [127, 132], [133, 139], [140, 143], [144, 147], [148, 160], [161, 167], [167, 168], [169, 173], [174, 179], [180, 184], [185, 191], [192, 203], [204, 206], [207, 213], [214, 220], [221, 224], [225, 227], [228, 234], [235, 241], [241, 242], [243, 246], [247, 249], [250, 259], [260, 264], [264, 265], [266, 269], [270, 273], [274, 276], [277, 283], [284, 295], [296, 298], [299, 304], [305, 310], [311, 317], [318, 321], [322, 330], [331, 336], [336, 337]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [5, 7, "programlang"], [14, 15, "field"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 7, "general-affiliation", "", false, false], [0, 0, 14, 15, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "has", "been", "ported", "to", "R", ",", "a", "freely", "available", "language", "and", "environment", "for", "statistical", "computing", "and", "graphics", "."], "sentence-detokenized": "ANIMAL has been ported to R, a freely available language and environment for statistical computing and graphics.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [23, 25], [26, 27], [27, 28], [29, 30], [31, 37], [38, 47], [48, 56], [57, 60], [61, 72], [73, 76], [77, 88], [89, 98], [99, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-test-203", "ner": [[0, 6, "algorithm"], [8, 10, "algorithm"], [16, 19, "algorithm"], [21, 21, "algorithm"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 16, 19, "opposite", "alternative to", false, false], [8, 10, 0, 6, "named", "", false, false], [21, 21, 16, 19, "named", "", false, false], [24, 26, 0, 6, "usage", "", false, false], [24, 26, 16, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Time", "-", "Inhomogeneous", "Hidden", "Bernoulli", "Model", "(", "TI", "-", "HBM", ")", "is", "an", "alternative", "to", "the", "Hidden", "Markov", "Model", "(", "HMM", ")", "for", "automatic", "speech", "recognition", "."], "sentence-detokenized": "The Time-Inhomogeneous Hidden Bernoulli Model (TI-HBM) is an alternative to the Hidden Markov Model (HMM) for automatic speech recognition.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 22], [23, 29], [30, 39], [40, 45], [46, 47], [47, 49], [49, 50], [50, 53], [53, 54], [55, 57], [58, 60], [61, 72], [73, 75], [76, 79], [80, 86], [87, 93], [94, 99], [100, 101], [101, 104], [104, 105], [106, 109], [110, 119], [120, 126], [127, 138], [138, 139]]}
{"doc_key": "ai-test-204", "ner": [[4, 4, "organisation"], [7, 8, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 7, 8, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "Nvidia", "presented", "at", "SIGGRAPH", "a", "new", "foveated", "rendering", "method", "that", "is", "supposed", "to", "be", "invisible", "to", "users", "."], "sentence-detokenized": "In July 2016, Nvidia presented at SIGGRAPH a new foveated rendering method that is supposed to be invisible to users.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 30], [31, 33], [34, 42], [43, 44], [45, 48], [49, 57], [58, 67], [68, 74], [75, 79], [80, 82], [83, 91], [92, 94], [95, 97], [98, 107], [108, 110], [111, 116], [116, 117]]}
{"doc_key": "ai-test-205", "ner": [[4, 14, "misc"], [11, 25, "researcher"], [20, 21, "researcher"], [23, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 14, 11, 25, "origin", "", false, false], [4, 14, 20, 21, "origin", "", false, false], [4, 14, 23, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Both", "are", "based", "on", "the", "theory", "of", "speech", "acts", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "built", "upon", "by", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both are based on the theory of speech acts developed by John Searle in the 1960s and built upon by Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 17], [18, 21], [22, 28], [29, 31], [32, 38], [39, 43], [44, 53], [54, 56], [57, 61], [62, 68], [69, 71], [72, 75], [76, 81], [82, 85], [86, 91], [92, 96], [97, 99], [100, 105], [106, 114], [115, 118], [119, 125], [126, 128], [129, 132], [133, 138], [138, 139]]}
{"doc_key": "ai-test-206", "ner": [[0, 3, "algorithm"], [21, 23, "researcher"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 21, 23, "related-to", "", false, false], [24, 24, 21, 23, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "knowledge", "structure", "have", "opened", "up", "powerful", "hierarchical", "models", "of", "knowledge", "organisation", ",", "such", "as", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "Neural network models of concept formation and knowledge structure have opened up powerful hierarchical models of knowledge organisation, such as George Miller's Wordnet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 56], [57, 66], [67, 71], [72, 78], [79, 81], [82, 90], [91, 103], [104, 110], [111, 113], [114, 123], [124, 136], [136, 137], [138, 142], [143, 145], [146, 152], [153, 159], [159, 161], [162, 169], [169, 170]]}
{"doc_key": "ai-test-207", "ner": [[0, 4, "algorithm"], [9, 10, "field"], [13, 15, "product"], [18, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 9, 10, "part-of", "", false, false], [0, 4, 18, 20, "part-of", "", false, false], [13, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Template", "matching", "is", "used", "in", "various", "fields", "such", "as", "face", "recognition", "(", "see", "face", "recognition", "system", ")", "and", "medical", "image", "processing", "."], "sentence-detokenized": "Template matching is used in various fields such as face recognition (see face recognition system) and medical image processing.", "token2charspan": [[0, 8], [9, 17], [18, 20], [21, 25], [26, 28], [29, 36], [37, 43], [44, 48], [49, 51], [52, 56], [57, 68], [69, 70], [70, 73], [74, 78], [79, 90], [91, 97], [97, 98], [99, 102], [103, 110], [111, 116], [117, 127], [127, 128]]}
{"doc_key": "ai-test-208", "ner": [[14, 15, "researcher"], [17, 18, "researcher"], [22, 31, "organisation"], [33, 33, "organisation"], [40, 41, "algorithm"], [44, 50, "conference"], [52, 52, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 15, 22, 31, "role", "", false, false], [14, 15, 44, 50, "physical", "", false, false], [14, 15, 44, 50, "temporal", "", false, false], [14, 15, 52, 52, "physical", "", false, false], [17, 18, 22, 31, "role", "", false, false], [17, 18, 44, 50, "temporal", "", false, false], [33, 33, 22, 31, "named", "", false, false], [44, 50, 40, 41, "topic", "", false, false], [52, 52, 44, 50, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "it", "was", "not", "until", "2005", "that", "the", "use", "became", "widespread", ",", "when", "Navneet", "Dalal", "and", "Bill", "Triggs", ",", "researchers", "at", "the", "French", "National", "Institute", "for", "Research", "in", "Computing", "and", "Automation", "(", "INRIA", ")", ",", "presented", "additional", "work", "on", "HOG", "descriptors", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "However, it was not until 2005 that the use became widespread, when Navneet Dalal and Bill Triggs, researchers at the French National Institute for Research in Computing and Automation (INRIA), presented additional work on HOG descriptors at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 15], [16, 19], [20, 25], [26, 30], [31, 35], [36, 39], [40, 43], [44, 50], [51, 61], [61, 62], [63, 67], [68, 75], [76, 81], [82, 85], [86, 90], [91, 97], [97, 98], [99, 110], [111, 113], [114, 117], [118, 124], [125, 133], [134, 143], [144, 147], [148, 156], [157, 159], [160, 169], [170, 173], [174, 184], [185, 186], [186, 191], [191, 192], [192, 193], [194, 203], [204, 214], [215, 219], [220, 222], [223, 226], [227, 238], [239, 241], [242, 245], [246, 256], [257, 259], [260, 268], [269, 275], [276, 279], [280, 287], [288, 299], [300, 301], [301, 305], [305, 306], [306, 307]]}
{"doc_key": "ai-test-209", "ner": [[3, 3, "university"], [16, 18, "organisation"], [20, 23, "organisation"], [28, 31, "field"], [35, 38, "researcher"], [40, 43, "researcher"], [45, 47, "researcher"], [49, 53, "organisation"], [57, 60, "organisation"], [64, 65, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[20, 23, 28, 31, "related-to", "", false, false], [35, 38, 20, 23, "physical", "", false, false], [35, 38, 20, 23, "role", "", false, false], [40, 43, 20, 23, "physical", "", false, false], [40, 43, 20, 23, "role", "", false, false], [45, 47, 20, 23, "physical", "", false, false], [45, 47, 20, 23, "role", "", false, false], [64, 65, 57, 60, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Before", "joining", "the", "Penn", "faculty", "in", "2002", ",", "he", "spent", "a", "decade", "(", "1991-2001", ")", "at", "AT", "&T", "Labs", "and", "Bell", "Labs", ",", "including", "as", "head", "of", "the", "Artificial", "Intelligence", "Department", "with", "colleagues", "such", "as", "Michael", "L", ".", "Littman", ",", "David", "A", ".", "McAllester", "and", "Richard", "S.", "Sutton", ",", "the", "Secure", "Systems", "Research", "Department", ",", "and", "the", "Machine", "Learning", "Department", "with", "members", "such", "as", "Michael", "Collins", "and", "the", "Head", ")", "."], "sentence-detokenized": "Before joining the Penn faculty in 2002, he spent a decade (1991-2001) at AT&T Labs and Bell Labs, including as head of the Artificial Intelligence Department with colleagues such as Michael L. Littman, David A. McAllester and Richard S. Sutton, the Secure Systems Research Department, and the Machine Learning Department with members such as Michael Collins and the Head).", "token2charspan": [[0, 6], [7, 14], [15, 18], [19, 23], [24, 31], [32, 34], [35, 39], [39, 40], [41, 43], [44, 49], [50, 51], [52, 58], [59, 60], [60, 69], [69, 70], [71, 73], [74, 76], [76, 78], [79, 83], [84, 87], [88, 92], [93, 97], [97, 98], [99, 108], [109, 111], [112, 116], [117, 119], [120, 123], [124, 134], [135, 147], [148, 158], [159, 163], [164, 174], [175, 179], [180, 182], [183, 190], [191, 192], [192, 193], [194, 201], [201, 202], [203, 208], [209, 210], [210, 211], [212, 222], [223, 226], [227, 234], [235, 237], [238, 244], [244, 245], [246, 249], [250, 256], [257, 264], [265, 273], [274, 284], [284, 285], [286, 289], [290, 293], [294, 301], [302, 310], [311, 321], [322, 326], [327, 334], [335, 339], [340, 342], [343, 350], [351, 358], [359, 362], [363, 366], [367, 371], [371, 372], [372, 373]]}
{"doc_key": "ai-test-210", "ner": [[6, 7, "field"], [14, 20, "field"], [25, 27, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 14, 20, "compare", "", false, false], [25, 27, 14, 20, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["When", "the", "data", "is", "unlabelled", ",", "supervised", "learning", "is", "not", "possible", ",", "so", "an", "unsupervised", "learning", "approach", "is", "needed", ",", "which", "attempts", "to", "find", "natural", "cluster", "analysis", "groups", "and", "then", "map", "the", "new", "data", "into", "these", "formed", "groups", "."], "sentence-detokenized": "When the data is unlabelled, supervised learning is not possible, so an unsupervised learning approach is needed, which attempts to find natural cluster analysis groups and then map the new data into these formed groups.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 27], [27, 28], [29, 39], [40, 48], [49, 51], [52, 55], [56, 64], [64, 65], [66, 68], [69, 71], [72, 84], [85, 93], [94, 102], [103, 105], [106, 112], [112, 113], [114, 119], [120, 128], [129, 131], [132, 136], [137, 144], [145, 152], [153, 161], [162, 168], [169, 172], [173, 177], [178, 181], [182, 185], [186, 189], [190, 194], [195, 199], [200, 205], [206, 212], [213, 219], [219, 220]]}
{"doc_key": "ai-test-211", "ner": [[3, 5, "field"], [15, 18, "organisation"], [25, 26, "field"], [28, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 15, 18, "origin", "", false, false], [3, 5, 25, 26, "part-of", "", false, false], [3, 5, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "field", "of", "computer", "science", "developed", "in", "the", "1950s", "in", "academic", "institutions", "such", "as", "the", "MIT", "A.I", ".", "Lab", ",", "initially", "as", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "This field of computer science developed in the 1950s in academic institutions such as the MIT A.I. Lab, initially as a branch of artificial intelligence and robotics.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 30], [31, 40], [41, 43], [44, 47], [48, 53], [54, 56], [57, 65], [66, 78], [79, 83], [84, 86], [87, 90], [91, 94], [95, 98], [98, 99], [100, 103], [103, 104], [105, 114], [115, 117], [118, 119], [120, 126], [127, 129], [130, 140], [141, 153], [154, 157], [158, 166], [166, 167]]}
{"doc_key": "ai-test-212", "ner": [[7, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "can", "also", "be", "replaced", "by", "the", "logarithm", "loss", "equation", "below", ":"], "sentence-detokenized": "It can also be replaced by the logarithm loss equation below:", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 23], [24, 26], [27, 30], [31, 40], [41, 45], [46, 54], [55, 60], [60, 61]]}
{"doc_key": "ai-test-213", "ner": [[0, 3, "organisation"], [7, 10, "organisation"], [14, 18, "university"], [20, 20, "university"], [22, 23, "university"], [26, 28, "university"], [30, 31, "country"], [39, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 39, 39, "related-to", "research_leader_in_field", false, false], [7, 10, 0, 3, "named", "", false, false], [7, 10, 39, 39, "related-to", "research_leader_in_field", false, false], [14, 18, 39, 39, "related-to", "research_leader_in_field", false, false], [20, 20, 39, 39, "related-to", "research_leader_in_field", false, false], [22, 23, 39, 39, "related-to", "research_leader_in_field", false, false], [26, 28, 30, 31, "physical", "", false, false], [26, 28, 39, 39, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "Shirley", "Ryan", "AbilityLab", "(", "formerly", "the", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "the", "University", "of", "California", "at", "Berkeley", ",", "MIT", ",", "Stanford", "University", "and", "the", "University", "of", "Twente", "in", "the", "Netherlands", "are", "leading", "researchers", "in", "the", "field", "of", "biomechatronics", "."], "sentence-detokenized": "The Shirley Ryan AbilityLab (formerly the Rehabilitation Institute of Chicago), the University of California at Berkeley, MIT, Stanford University and the University of Twente in the Netherlands are leading researchers in the field of biomechatronics.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 27], [28, 29], [29, 37], [38, 41], [42, 56], [57, 66], [67, 69], [70, 77], [77, 78], [78, 79], [80, 83], [84, 94], [95, 97], [98, 108], [109, 111], [112, 120], [120, 121], [122, 125], [125, 126], [127, 135], [136, 146], [147, 150], [151, 154], [155, 165], [166, 168], [169, 175], [176, 178], [179, 182], [183, 194], [195, 198], [199, 206], [207, 218], [219, 221], [222, 225], [226, 231], [232, 234], [235, 250], [250, 251]]}
{"doc_key": "ai-test-214", "ner": [[28, 33, "metrics"], [44, 45, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Given", "a", "set", "of", "predicted", "values", "and", "a", "corresponding", "set", "of", "actual", "values", "for", "X", "for", "different", "time", "periods", ",", "a", "common", "evaluation", "technique", "is", "to", "use", "the", "mean", "square", "error", "of", "the", "prediction", ";", "other", "measures", "are", "also", "available", "(", "see", "Prediction", "#", "Prediction", "accuracy", ")", "."], "sentence-detokenized": "Given a set of predicted values and a corresponding set of actual values for X for different time periods, a common evaluation technique is to use the mean square error of the prediction; other measures are also available (see Prediction # Prediction accuracy).", "token2charspan": [[0, 5], [6, 7], [8, 11], [12, 14], [15, 24], [25, 31], [32, 35], [36, 37], [38, 51], [52, 55], [56, 58], [59, 65], [66, 72], [73, 76], [77, 78], [79, 82], [83, 92], [93, 97], [98, 105], [105, 106], [107, 108], [109, 115], [116, 126], [127, 136], [137, 139], [140, 142], [143, 146], [147, 150], [151, 155], [156, 162], [163, 168], [169, 171], [172, 175], [176, 186], [186, 187], [188, 193], [194, 202], [203, 206], [207, 211], [212, 221], [222, 223], [223, 226], [227, 237], [238, 239], [240, 250], [251, 259], [259, 260], [260, 261]]}
{"doc_key": "ai-test-215", "ner": [[13, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "measures", ",", "such", "as", "the", "proportion", "of", "correct", "predictions", "(", "also", "called", "accuracy", ")", ",", "are", "not", "useful", "when", "the", "classes", "are", "very", "different", "in", "size", "."], "sentence-detokenized": "Other measures, such as the proportion of correct predictions (also called accuracy), are not useful when the classes are very different in size.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 20], [21, 23], [24, 27], [28, 38], [39, 41], [42, 49], [50, 61], [62, 63], [63, 67], [68, 74], [75, 83], [83, 84], [84, 85], [86, 89], [90, 93], [94, 100], [101, 105], [106, 109], [110, 117], [118, 121], [122, 126], [127, 136], [137, 139], [140, 144], [144, 145]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [13, 18, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 13, 18, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "publicly", "released", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "in", "2000", ",", "and", "five", "beta", "versions", "were", "released", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was publicly released at the Conference on Computer Vision and Pattern Recognition in 2000, and five beta versions were released between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 46], [47, 55], [56, 58], [59, 62], [63, 73], [74, 76], [77, 85], [86, 92], [93, 96], [97, 104], [105, 116], [117, 119], [120, 124], [124, 125], [126, 129], [130, 134], [135, 139], [140, 148], [149, 153], [154, 162], [163, 170], [171, 175], [176, 179], [180, 184], [184, 185]]}
{"doc_key": "ai-test-217", "ner": [[17, 17, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Results", "showing", "a", "correlation", "of", "up", "to", "0.964", "with", "human", "judgement", "at", "corpus", "level", "compared", "to", "a", "BLEU", "score", "of", "0.817", "on", "the", "same", "dataset", "were", "presented", "."], "sentence-detokenized": "Results showing a correlation of up to 0.964 with human judgement at corpus level compared to a BLEU score of 0.817 on the same dataset were presented.", "token2charspan": [[0, 7], [8, 15], [16, 17], [18, 29], [30, 32], [33, 35], [36, 38], [39, 44], [45, 49], [50, 55], [56, 65], [66, 68], [69, 75], [76, 81], [82, 90], [91, 93], [94, 95], [96, 100], [101, 106], [107, 109], [110, 115], [116, 118], [119, 122], [123, 127], [128, 135], [136, 140], [141, 150], [150, 151]]}
{"doc_key": "ai-test-218", "ner": [[4, 4, "metrics"], [14, 14, "metrics"], [16, 18, "metrics"], [20, 22, "metrics"], [27, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 14, 14, "compare", "", false, false], [4, 4, 16, 18, "compare", "", false, false], [4, 4, 20, 22, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "early", "version", "of", "VMAF", "outperformed", "other", "image", "and", "video", "quality", "metrics", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", "and", "VQM", "-", "VFD", "in", "terms", "of", "prediction", "accuracy", "compared", "to", "subjective", "ratings", "on", "three", "of", "the", "four", "datasets", "."], "sentence-detokenized": "The early version of VMAF outperformed other image and video quality metrics such as SSIM, PSNR -HVS and VQM-VFD in terms of prediction accuracy compared to subjective ratings on three of the four datasets.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 20], [21, 25], [26, 38], [39, 44], [45, 50], [51, 54], [55, 60], [61, 68], [69, 76], [77, 81], [82, 84], [85, 89], [89, 90], [91, 95], [96, 97], [97, 100], [101, 104], [105, 108], [108, 109], [109, 112], [113, 115], [116, 121], [122, 124], [125, 135], [136, 144], [145, 153], [154, 156], [157, 167], [168, 175], [176, 178], [179, 184], [185, 187], [188, 191], [192, 196], [197, 205], [205, 206]]}
{"doc_key": "ai-test-219", "ner": [[20, 23, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 23, 28, 29, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "of", "the", "word", "\"", "mouse", "\"", "(", "animal", "or", "device", ")", "is", "not", "important", "in", "machine", "translation", ",", "but", "it", "is", "important", "in", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity of the word \"mouse\" (animal or device) is not important in machine translation, but it is important in information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 33], [34, 38], [39, 40], [40, 45], [45, 46], [47, 48], [48, 54], [55, 57], [58, 64], [64, 65], [66, 68], [69, 72], [73, 82], [83, 85], [86, 93], [94, 105], [105, 106], [107, 110], [111, 113], [114, 116], [117, 126], [127, 129], [130, 141], [142, 151], [151, 152]]}
{"doc_key": "ai-test-220", "ner": [[0, 3, "algorithm"], [6, 7, "field"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 3, "usage", "", false, false], [9, 10, 6, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "hashing", "was", "originally", "proposed", "in", "computer", "vision", "for", "object", "recognition", "in", "2D", "and", "3D", ","], "sentence-detokenized": "Geometric hashing was originally proposed in computer vision for object recognition in 2D and 3D,", "token2charspan": [[0, 9], [10, 17], [18, 21], [22, 32], [33, 41], [42, 44], [45, 53], [54, 60], [61, 64], [65, 71], [72, 83], [84, 86], [87, 89], [90, 93], [94, 96], [96, 97]]}
{"doc_key": "ai-test-221", "ner": [[17, 18, "field"], [2, 3, "field"], [5, 8, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 17, 18, "part-of", "subfield", false, false], [5, 8, 17, 18, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Together", "with", "supervised", "learning", "and", "reinforcement", "learning", ",", "it", "is", "one", "of", "the", "three", "main", "categories", "of", "machine", "learning", "."], "sentence-detokenized": "Together with supervised learning and reinforcement learning, it is one of the three main categories of machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 24], [25, 33], [34, 37], [38, 51], [52, 60], [60, 61], [62, 64], [65, 67], [68, 71], [72, 74], [75, 78], [79, 84], [85, 89], [90, 100], [101, 103], [104, 111], [112, 120], [120, 121]]}
{"doc_key": "ai-test-222", "ner": [[5, 7, "field"], [15, 15, "field"], [17, 18, "field"], [20, 21, "field"], [23, 24, "field"], [26, 29, "field"], [31, 32, "field"], [34, 35, "field"], [37, 37, "field"], [39, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[5, 7, 15, 15, "part-of", "subfield", false, false], [5, 7, 17, 18, "part-of", "subfield", false, false], [5, 7, 20, 21, "part-of", "subfield", false, false], [5, 7, 23, 24, "part-of", "subfield", false, false], [5, 7, 26, 29, "part-of", "subfield", false, false], [5, 7, 31, 32, "part-of", "subfield", false, false], [5, 7, 34, 35, "part-of", "subfield", false, false], [5, 7, 37, 37, "part-of", "subfield", false, false], [5, 7, 39, 40, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Because", "of", "its", "generality", ",", "reinforcement", "learning", "is", "studied", "in", "many", "other", "disciplines", "such", "as", "games", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Because of its generality, reinforcement learning is studied in many other disciplines such as games, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [25, 26], [27, 40], [41, 49], [50, 52], [53, 60], [61, 63], [64, 68], [69, 74], [75, 86], [87, 91], [92, 94], [95, 100], [100, 101], [102, 109], [110, 116], [116, 117], [118, 128], [129, 137], [137, 138], [139, 150], [151, 157], [157, 158], [159, 169], [169, 170], [170, 175], [176, 188], [188, 189], [190, 201], [202, 209], [209, 210], [211, 216], [217, 229], [229, 230], [231, 241], [242, 245], [246, 253], [254, 264], [264, 265]]}
{"doc_key": "ai-test-223", "ner": [[0, 3, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 6, 7, "related-to", "", false, false], [0, 3, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pattern", "recognition", "is", "closely", "linked", "to", "artificial", "intelligence", "and", "machine", "learning", ","], "sentence-detokenized": "Pattern recognition is closely linked to artificial intelligence and machine learning,", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 37], [38, 40], [41, 51], [52, 64], [65, 68], [69, 76], [77, 85], [85, 86]]}
{"doc_key": "ai-test-224", "ner": [[10, 11, "algorithm"], [14, 15, "field"], [17, 20, "field"], [29, 30, "task"], [32, 32, "task"], [34, 35, "task"], [37, 38, "algorithm"], [40, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 14, 15, "related-to", "", false, false], [10, 11, 17, 20, "related-to", "", false, false], [29, 30, 10, 11, "usage", "", true, false], [32, 32, 10, 11, "usage", "", true, false], [34, 35, 10, 11, "usage", "", true, false], [37, 38, 10, 11, "usage", "", true, false], [40, 42, 10, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "software", "is", "used", "to", "design", ",", "train", "and", "use", "neural", "network", "models", "(", "supervised", "learning", "and", "unsupervised", "learning", ")", "to", "perform", "a", "wide", "variety", "of", "tasks", "such", "as", "data", "mining", ",", "classification", ",", "feature", "approximation", ",", "multivariate", "regression", "and", "time", "series", "prediction", "."], "sentence-detokenized": "The software is used to design, train and use neural network models (supervised learning and unsupervised learning) to perform a wide variety of tasks such as data mining, classification, feature approximation, multivariate regression and time series prediction.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [21, 23], [24, 30], [30, 31], [32, 37], [38, 41], [42, 45], [46, 52], [53, 60], [61, 67], [68, 69], [69, 79], [80, 88], [89, 92], [93, 105], [106, 114], [114, 115], [116, 118], [119, 126], [127, 128], [129, 133], [134, 141], [142, 144], [145, 150], [151, 155], [156, 158], [159, 163], [164, 170], [170, 171], [172, 186], [186, 187], [188, 195], [196, 209], [209, 210], [211, 223], [224, 234], [235, 238], [239, 243], [244, 250], [251, 261], [261, 262]]}
{"doc_key": "ai-test-225", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", ",", "he", "was", "elected", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016, he was elected a member of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-test-226", "ner": [[5, 9, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", "and", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", ","], "sentence-detokenized": "She is a member of the National Academy of Sciences (since 2005) and the American Academy of Arts and Sciences (since 2009),", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 15], [16, 18], [19, 22], [23, 31], [32, 39], [40, 42], [43, 51], [52, 53], [53, 58], [59, 63], [63, 64], [65, 68], [69, 72], [73, 81], [82, 89], [90, 92], [93, 97], [98, 101], [102, 110], [111, 112], [112, 117], [118, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-test-227", "ner": [[3, 5, "misc"], [8, 15, "product"], [16, 16, "country"], [18, 18, "country"], [21, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 15, 3, 5, "temporal", "", false, false], [8, 15, 16, 16, "physical", "", false, false], [8, 15, 18, 18, "physical", "", false, false], [8, 15, 21, 22, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "the", "1973", "Yom", "Kippur", "War", ",", "Soviet", "surface", "-", "to", "-", "air", "missile", "batteries", "in", "Egypt", "and", "Syria", "severely", "damaged", "Israeli", "warplanes", "."], "sentence-detokenized": "During the 1973 Yom Kippur War, Soviet surface-to-air missile batteries in Egypt and Syria severely damaged Israeli warplanes.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 26], [27, 30], [30, 31], [32, 38], [39, 46], [46, 47], [47, 49], [49, 50], [50, 53], [54, 61], [62, 71], [72, 74], [75, 80], [81, 84], [85, 90], [91, 99], [100, 107], [108, 115], [116, 125], [125, 126]]}
{"doc_key": "ai-test-228", "ner": [[12, 13, "product"], [18, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 12, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "resource", "(", "free", ",", "but", "protected", "by", "copyright", ")", "is", "the", "HTK", "book", "(", "and", "the", "accompanying", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another resource (free, but protected by copyright) is the HTK book (and the accompanying HTK toolkit).", "token2charspan": [[0, 7], [8, 16], [17, 18], [18, 22], [22, 23], [24, 27], [28, 37], [38, 40], [41, 50], [50, 51], [52, 54], [55, 58], [59, 62], [63, 67], [68, 69], [69, 72], [73, 76], [77, 89], [90, 93], [94, 101], [101, 102], [102, 103]]}
{"doc_key": "ai-test-229", "ner": [[5, 10, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "were", "adopted", "at", "the", "2004", "AAAI", "Spring", "Symposium", ",", "where", "linguists", ",", "computer", "scientists", "and", "other", "interested", "researchers", "first", "aligned", "their", "interests", "and", "proposed", "common", "tasks", "and", "reference", "datasets", "for", "systematic", "computational", "exploration", "of", "affect", ",", "attractiveness", ",", "subjectivity", "and", "mood", "in", "text", "."], "sentence-detokenized": "- were adopted at the 2004 AAAI Spring Symposium, where linguists, computer scientists and other interested researchers first aligned their interests and proposed common tasks and reference datasets for systematic computational exploration of affect, attractiveness, subjectivity and mood in text.", "token2charspan": [[0, 1], [2, 6], [7, 14], [15, 17], [18, 21], [22, 26], [27, 31], [32, 38], [39, 48], [48, 49], [50, 55], [56, 65], [65, 66], [67, 75], [76, 86], [87, 90], [91, 96], [97, 107], [108, 119], [120, 125], [126, 133], [134, 139], [140, 149], [150, 153], [154, 162], [163, 169], [170, 175], [176, 179], [180, 189], [190, 198], [199, 202], [203, 213], [214, 227], [228, 239], [240, 242], [243, 249], [249, 250], [251, 265], [265, 266], [267, 279], [280, 283], [284, 288], [289, 291], [292, 296], [296, 297]]}
{"doc_key": "ai-test-230", "ner": [[12, 13, "task"], [23, 24, "task"], [26, 28, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "single", "network", "can", "be", "analysed", "both", "in", "terms", "of", "content", "(", "ocular", "inspection", ")", "and", "structure", "(", "the", "main", "techniques", "used", "are", "cluster", "analysis", ",", "principal", "component", "analysis", "and", "various", "structural", "indices", "relating", "to", "the", "complexity", "and", "scale", "of", "the", "estimates", ")", "."], "sentence-detokenized": "A single network can be analysed both in terms of content (ocular inspection) and structure (the main techniques used are cluster analysis, principal component analysis and various structural indices relating to the complexity and scale of the estimates).", "token2charspan": [[0, 1], [2, 8], [9, 16], [17, 20], [21, 23], [24, 32], [33, 37], [38, 40], [41, 46], [47, 49], [50, 57], [58, 59], [59, 65], [66, 76], [76, 77], [78, 81], [82, 91], [92, 93], [93, 96], [97, 101], [102, 112], [113, 117], [118, 121], [122, 129], [130, 138], [138, 139], [140, 149], [150, 159], [160, 168], [169, 172], [173, 180], [181, 191], [192, 199], [200, 208], [209, 211], [212, 215], [216, 226], [227, 230], [231, 236], [237, 239], [240, 243], [244, 253], [253, 254], [254, 255]]}
{"doc_key": "ai-test-231", "ner": [[3, 3, "organisation"], [11, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", ",", "Toyota", "was", "considered", "to", "be", "lagging", "behind", "in", "self", "-", "driving", "cars", "and", "in", "need", "of", "innovation", "."], "sentence-detokenized": "In 2018, Toyota was considered to be lagging behind in self-driving cars and in need of innovation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 30], [31, 33], [34, 36], [37, 44], [45, 51], [52, 54], [55, 59], [59, 60], [60, 67], [68, 72], [73, 76], [77, 79], [80, 84], [85, 87], [88, 98], [98, 99]]}
{"doc_key": "ai-test-232", "ner": [[40, 43, "misc"], [45, 46, "misc"], [48, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "targets", "include", "natural", "objects", "such", "as", "the", "ground", ",", "the", "sea", ",", "precipitation", "(", "such", "as", "rain", ",", "snow", "or", "hail", ")", ",", "sandstorms", ",", "animals", "(", "especially", "birds", ")", ",", "atmospheric", "turbulence", "and", "other", "atmospheric", "effects", "such", "as", "reflections", "in", "the", "ionosphere", ",", "meteor", "trails", "and", "three", "-", "body", "scattering", "."], "sentence-detokenized": "Such targets include natural objects such as the ground, the sea, precipitation (such as rain, snow or hail), sandstorms, animals (especially birds), atmospheric turbulence and other atmospheric effects such as reflections in the ionosphere, meteor trails and three-body scattering.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 28], [29, 36], [37, 41], [42, 44], [45, 48], [49, 55], [55, 56], [57, 60], [61, 64], [64, 65], [66, 79], [80, 81], [81, 85], [86, 88], [89, 93], [93, 94], [95, 99], [100, 102], [103, 107], [107, 108], [108, 109], [110, 120], [120, 121], [122, 129], [130, 131], [131, 141], [142, 147], [147, 148], [148, 149], [150, 161], [162, 172], [173, 176], [177, 182], [183, 194], [195, 202], [203, 207], [208, 210], [211, 222], [223, 225], [226, 229], [230, 240], [240, 241], [242, 248], [249, 255], [256, 259], [260, 265], [265, 266], [266, 270], [271, 281], [281, 282]]}
{"doc_key": "ai-test-233", "ner": [[18, 19, "product"], [39, 40, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "design", "and", "control", ",", "the", "essential", "difference", "between", "humanoids", "and", "other", "types", "of", "robots", "(", "for", "example", "industrial", "robots", ")", "is", "that", "the", "robot", "'s", "movement", "must", "be", "human", "-", "like", ",", "using", "legged", "locomotion", ",", "in", "particular", "bipedal", "walking", "."], "sentence-detokenized": "In design and control, the essential difference between humanoids and other types of robots (for example industrial robots) is that the robot's movement must be human-like, using legged locomotion, in particular bipedal walking.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 21], [21, 22], [23, 26], [27, 36], [37, 47], [48, 55], [56, 65], [66, 69], [70, 75], [76, 81], [82, 84], [85, 91], [92, 93], [93, 96], [97, 104], [105, 115], [116, 122], [122, 123], [124, 126], [127, 131], [132, 135], [136, 141], [141, 143], [144, 152], [153, 157], [158, 160], [161, 166], [166, 167], [167, 171], [171, 172], [173, 178], [179, 185], [186, 196], [196, 197], [198, 200], [201, 211], [212, 219], [220, 227], [227, 228]]}
{"doc_key": "ai-test-234", "ner": [[8, 11, "misc"], [13, 13, "metrics"], [16, 16, "misc"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "can", "take", "many", "iterations", "to", "calculate", "the", "local", "minimum", "with", "the", "required", "accuracy", "if", "the", "curvature", "varies", "widely", "in", "different", "directions", "for", "a", "given", "function", "."], "sentence-detokenized": "It can take many iterations to calculate the local minimum with the required accuracy if the curvature varies widely in different directions for a given function.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 27], [28, 30], [31, 40], [41, 44], [45, 50], [51, 58], [59, 63], [64, 67], [68, 76], [77, 85], [86, 88], [89, 92], [93, 102], [103, 109], [110, 116], [117, 119], [120, 129], [130, 140], [141, 144], [145, 146], [147, 152], [153, 161], [161, 162]]}
{"doc_key": "ai-test-235", "ner": [[0, 5, "misc"], [9, 9, "misc"], [16, 22, "conference"], [29, 29, "location"], [31, 31, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 9, 9, "part-of", "", true, false], [16, 22, 29, 29, "physical", "", false, true], [29, 29, 31, 31, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["1997", "RoboCup", "2D", "Soccer", "Simulation", "League", "was", "the", "first", "RoboCup", "competition", "organised", "in", "conjunction", "with", "the", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", "from", "23", "to", "29", "August", "1997", "in", "Nagoya", ",", "Japan", "."], "sentence-detokenized": "1997 RoboCup 2D Soccer Simulation League was the first RoboCup competition organised in conjunction with the International Joint Conference on Artificial Intelligence from 23 to 29 August 1997 in Nagoya, Japan.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 22], [23, 33], [34, 40], [41, 44], [45, 48], [49, 54], [55, 62], [63, 74], [75, 84], [85, 87], [88, 99], [100, 104], [105, 108], [109, 122], [123, 128], [129, 139], [140, 142], [143, 153], [154, 166], [167, 171], [172, 174], [175, 177], [178, 180], [181, 187], [188, 192], [193, 195], [196, 202], [202, 203], [204, 209], [209, 210]]}
{"doc_key": "ai-test-236", "ner": [[8, 11, "programlang"], [12, 12, "programlang"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "options", "include", "the", "built", "-", "in", "Python", "environment", "and", "the", "R", "console", ",", "as", "well", "as", "support", "for", "Rserve", "."], "sentence-detokenized": "Other programming options include the built-in Python environment and the R console, as well as support for Rserve.", "token2charspan": [[0, 5], [6, 17], [18, 25], [26, 33], [34, 37], [38, 43], [43, 44], [44, 46], [47, 53], [54, 65], [66, 69], [70, 73], [74, 75], [76, 83], [83, 84], [85, 87], [88, 92], [93, 95], [96, 103], [104, 107], [108, 114], [114, 115]]}
{"doc_key": "ai-test-237", "ner": [[1, 5, "location"], [9, 10, "field"], [12, 12, "field"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [33, 36, "field"], [38, 39, "field"], [42, 45, "field"], [47, 47, "field"], [50, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[15, 16, 12, 12, "related-to", "contributes_to_field", true, false], [18, 19, 12, 12, "related-to", "contributes_to_field", true, false], [21, 22, 12, 12, "related-to", "contributes_to_field", true, false], [42, 45, 38, 39, "part-of", "", false, false], [47, 47, 42, 45, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["From", "Bonn", ",", "he", "has", "made", "significant", "contributions", "to", "artificial", "intelligence", "and", "robotics", "(", "with", "Wolfram", "Burgard", ",", "Dieter", "Fox", "and", "Sebastian", "Thrun", "among", "his", "students", ")", ",", "and", "to", "the", "development", "of", "software", "engineering", ",", "especially", "in", "civil", "engineering", ",", "and", "information", "systems", ",", "especially", "in", "geosciences.He", "received", "the", "AAAI", "Classic", "Paper", "Award", "2016.2014", "."], "sentence-detokenized": "From Bonn, he has made significant contributions to artificial intelligence and robotics (with Wolfram Burgard, Dieter Fox and Sebastian Thrun among his students), and to the development of software engineering, especially in civil engineering, and information systems, especially in geosciences.He received the AAAI Classic Paper Award 2016.2014.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 13], [14, 17], [18, 22], [23, 34], [35, 48], [49, 51], [52, 62], [63, 75], [76, 79], [80, 88], [89, 90], [90, 94], [95, 102], [103, 110], [110, 111], [112, 118], [119, 122], [123, 126], [127, 136], [137, 142], [143, 148], [149, 152], [153, 161], [161, 162], [162, 163], [164, 167], [168, 170], [171, 174], [175, 186], [187, 189], [190, 198], [199, 210], [210, 211], [212, 222], [223, 225], [226, 231], [232, 243], [243, 244], [245, 248], [249, 260], [261, 268], [268, 269], [270, 280], [281, 283], [284, 298], [299, 307], [308, 311], [312, 316], [317, 324], [325, 330], [331, 336], [337, 346], [346, 347]]}
{"doc_key": "ai-test-238", "ner": [[2, 10, "conference"], [18, 20, "location"], [21, 21, "location"], [23, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 10, 18, 20, "physical", "", false, false], [18, 20, 21, 21, "physical", "", false, false], [21, 21, 23, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "US", "edition", "of", "the", "Campus", "Party", "will", "take", "place", "from", "20", "-", "22", "August", "at", "the", "TCF", "Center", "in", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "The first US edition of the Campus Party will take place from 20-22 August at the TCF Center in Detroit, Michigan.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 20], [21, 23], [24, 27], [28, 34], [35, 40], [41, 45], [46, 50], [51, 56], [57, 61], [62, 64], [64, 65], [65, 67], [68, 74], [75, 77], [78, 81], [82, 85], [86, 92], [93, 95], [96, 103], [103, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-239", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [0, 0, "researcher"], [13, 15, "misc"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 13, 15, "win-defeat", "", false, false], [7, 8, 13, 15, "win-defeat", "", false, false], [0, 0, 13, 15, "win-defeat", "", false, false], [13, 15, 23, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Hinton", ",", "together", "with", "Yann", "LeCun", "and", "Yoshua", "Benga", ",", "won", "the", "2018", "Turing", "Prize", "for", "conceptual", "and", "engineering", "achievements", "that", "have", "made", "deep", "neural", "networks", "a", "key", "component", "of", "computing", "."], "sentence-detokenized": "Hinton, together with Yann LeCun and Yoshua Benga, won the 2018 Turing Prize for conceptual and engineering achievements that have made deep neural networks a key component of computing.", "token2charspan": [[0, 6], [6, 7], [8, 16], [17, 21], [22, 26], [27, 32], [33, 36], [37, 43], [44, 49], [49, 50], [51, 54], [55, 58], [59, 63], [64, 70], [71, 76], [77, 80], [81, 91], [92, 95], [96, 107], [108, 120], [121, 125], [126, 130], [131, 135], [136, 140], [141, 147], [148, 156], [157, 158], [159, 162], [163, 172], [173, 175], [176, 185], [185, 186]]}
{"doc_key": "ai-test-240", "ner": [[0, 3, "product"], [10, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 10, 19, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Euler", "Math", "Toolbox", "uses", "a", "matrix", "language", "similar", "to", "MATLAB", ",", "which", "has", "been", "in", "development", "since", "the", "1970s", "."], "sentence-detokenized": "The Euler Math Toolbox uses a matrix language similar to MATLAB, which has been in development since the 1970s.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 22], [23, 27], [28, 29], [30, 36], [37, 45], [46, 53], [54, 56], [57, 63], [63, 64], [65, 70], [71, 74], [75, 79], [80, 82], [83, 94], [95, 100], [101, 104], [105, 110], [110, 111]]}
{"doc_key": "ai-test-241", "ner": [[6, 6, "programlang"], [8, 9, "programlang"], [11, 11, "programlang"], [13, 13, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "languages", "allow", "this", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "or", "D", ")", "."], "sentence-detokenized": "Some languages allow this (e.g. Scheme, Common Lisp, Perl or D).", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 25], [26, 27], [27, 31], [32, 38], [38, 39], [40, 46], [47, 51], [51, 52], [53, 57], [58, 60], [61, 62], [62, 63], [63, 64]]}
{"doc_key": "ai-test-242", "ner": [[13, 13, "misc"], [3, 4, "researcher"], [6, 7, "researcher"], [23, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 13, 3, 4, "artifact", "", false, false], [13, 13, 6, 7, "artifact", "", false, false], [13, 13, 23, 24, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1969", ",", "Marvin", "Minsky", "and", "Seymour", "Papert", "showed", "in", "their", "famous", "book", "Perceptrons", "that", "these", "classes", "of", "networks", "can", "not", "learn", "the", "XOR", "function", "."], "sentence-detokenized": "In 1969, Marvin Minsky and Seymour Papert showed in their famous book Perceptrons that these classes of networks cannot learn the XOR function.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 22], [23, 26], [27, 34], [35, 41], [42, 48], [49, 51], [52, 57], [58, 64], [65, 69], [70, 81], [82, 86], [87, 92], [93, 100], [101, 103], [104, 112], [113, 116], [116, 119], [120, 125], [126, 129], [130, 133], [134, 142], [142, 143]]}
{"doc_key": "ai-test-243", "ner": [[4, 9, "misc"], [13, 15, "product"], [20, 23, "organisation"], [26, 34, "organisation"], [35, 41, "location"], [42, 42, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 23, 13, 15, "usage", "", false, false], [20, 23, 35, 41, "physical", "", false, false], [26, 34, 20, 23, "named", "", false, false], [35, 41, 42, 42, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "large", "number", "of", "Russian", "scientific", "and", "technical", "documents", "were", "translated", "by", "the", "SYSTRAN", "programme", "under", "the", "auspices", "of", "the", "USAF", "Foreign", "Technology", "Division", "(", "later", "the", "National", "Air", "and", "Space", "Intelligence", "Centre", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", "in", "Ohio", "."], "sentence-detokenized": "A large number of Russian scientific and technical documents were translated by the SYSTRAN programme under the auspices of the USAF Foreign Technology Division (later the National Air and Space Intelligence Centre) at Wright-Patterson Air Force Base in Ohio.", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 17], [18, 25], [26, 36], [37, 40], [41, 50], [51, 60], [61, 65], [66, 76], [77, 79], [80, 83], [84, 91], [92, 101], [102, 107], [108, 111], [112, 120], [121, 123], [124, 127], [128, 132], [133, 140], [141, 151], [152, 160], [161, 162], [162, 167], [168, 171], [172, 180], [181, 184], [185, 188], [189, 194], [195, 207], [208, 214], [214, 215], [216, 218], [219, 225], [225, 226], [226, 235], [236, 239], [240, 245], [246, 250], [251, 253], [254, 258], [258, 259]]}
{"doc_key": "ai-test-244", "ner": [[0, 1, "field"], [4, 5, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-supervised", "learning", "is", "between", "unsupervised", "learning", "(", "without", "labelled", "training", "data", ")", "and", "supervised", "learning", "(", "with", "fully", "labelled", "training", "data", ")", "."], "sentence-detokenized": "Semi-supervised learning is between unsupervised learning (without labelled training data) and supervised learning (with fully labelled training data).", "token2charspan": [[0, 15], [16, 24], [25, 27], [28, 35], [36, 48], [49, 57], [58, 59], [59, 66], [67, 75], [76, 84], [85, 89], [89, 90], [91, 94], [95, 105], [106, 114], [115, 116], [116, 120], [121, 126], [127, 135], [136, 144], [145, 149], [149, 150], [150, 151]]}
{"doc_key": "ai-test-245", "ner": [[0, 4, "algorithm"], [9, 12, "algorithm"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 9, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Ann", "-", "gram", "model", "is", "a", "type", "of", "probabilistic", "language", "model", "for", "predicting", "the", "next", "element", "in", "such", "a", "sequence", "in", "the", "form", "of", "an", "(", "n", "-", "1", ")", "Markov", "model", "."], "sentence-detokenized": "The Ann -gram model is a type of probabilistic language model for predicting the next element in such a sequence in the form of an (n - 1) Markov model.", "token2charspan": [[0, 3], [4, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 24], [25, 29], [30, 32], [33, 46], [47, 55], [56, 61], [62, 65], [66, 76], [77, 80], [81, 85], [86, 93], [94, 96], [97, 101], [102, 103], [104, 112], [113, 115], [116, 119], [120, 124], [125, 127], [128, 130], [131, 132], [132, 133], [134, 135], [136, 137], [137, 138], [139, 145], [146, 151], [151, 152]]}
{"doc_key": "ai-test-246", "ner": [[0, 2, "organisation"], [4, 4, "product"], [8, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 4, 4, "usage", "", false, false], [8, 15, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "used", "Cyc", "to", "develop", "a", "natural", "language", "interface", "for", "querying", "biomedical", "information", "covering", "decades", "of", "information", "on", "cardiothoracic", "surgery", "."], "sentence-detokenized": "The Cleveland Clinic used Cyc to develop a natural language interface for querying biomedical information covering decades of information on cardiothoracic surgery.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 29], [30, 32], [33, 40], [41, 42], [43, 50], [51, 59], [60, 69], [70, 73], [74, 82], [83, 93], [94, 105], [106, 114], [115, 122], [123, 125], [126, 137], [138, 140], [141, 155], [156, 163], [163, 164]]}
{"doc_key": "ai-test-247", "ner": [[6, 8, "country"], [10, 12, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 10, 12, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "incident", "has", "strained", "relations", "between", "the", "United", "States", "and", "Japan", ",", "leading", "to", "the", "arrest", "and", "prosecution", "of", "two", "executives", "and", "sanctions", "against", "the", "company", "by", "both", "countries", "."], "sentence-detokenized": "The incident has strained relations between the United States and Japan, leading to the arrest and prosecution of two executives and sanctions against the company by both countries.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 25], [26, 35], [36, 43], [44, 47], [48, 54], [55, 61], [62, 65], [66, 71], [71, 72], [73, 80], [81, 83], [84, 87], [88, 94], [95, 98], [99, 110], [111, 113], [114, 117], [118, 128], [129, 132], [133, 142], [143, 150], [151, 154], [155, 162], [163, 165], [166, 170], [171, 180], [180, 181]]}
{"doc_key": "ai-test-248", "ner": [[7, 9, "algorithm"], [12, 15, "field"], [22, 25, "misc"], [34, 34, "misc"], [38, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 12, 15, "type-of", "", false, false], [22, 25, 12, 15, "part-of", "", true, false], [34, 34, 12, 15, "part-of", "", true, false], [38, 38, 12, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["If", "the", "modelling", "is", "done", "with", "an", "artificial", "neural", "network", "or", "other", "machine", "learning", ",", "the", "optimisation", "of", "the", "parameters", "is", "called", "training", ",", "while", "the", "optimisation", "of", "the", "model", "'s", "hyperparameters", "is", "called", "tuning", "and", "often", "uses", "cross-validation", "."], "sentence-detokenized": "If the modelling is done with an artificial neural network or other machine learning, the optimisation of the parameters is called training, while the optimisation of the model's hyperparameters is called tuning and often uses cross-validation.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 24], [25, 29], [30, 32], [33, 43], [44, 50], [51, 58], [59, 61], [62, 67], [68, 75], [76, 84], [84, 85], [86, 89], [90, 102], [103, 105], [106, 109], [110, 120], [121, 123], [124, 130], [131, 139], [139, 140], [141, 146], [147, 150], [151, 163], [164, 166], [167, 170], [171, 176], [176, 178], [179, 194], [195, 197], [198, 204], [205, 211], [212, 215], [216, 221], [222, 226], [227, 243], [243, 244]]}
{"doc_key": "ai-test-249", "ner": [[12, 12, "country"], [14, 14, "country"], [16, 18, "country"], [21, 22, "organisation"], [26, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 22, 26, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "localised", "versions", "of", "the", "site", ",", "which", "were", "available", "in", "the", "UK", ",", "India", "and", "Australia", ",", "were", "discontinued", "when", "Rotten", "Tomatoes", "was", "acquired", "by", "Fandango", "."], "sentence-detokenized": "The localised versions of the site, which were available in the UK, India and Australia, were discontinued when Rotten Tomatoes was acquired by Fandango.", "token2charspan": [[0, 3], [4, 13], [14, 22], [23, 25], [26, 29], [30, 34], [34, 35], [36, 41], [42, 46], [47, 56], [57, 59], [60, 63], [64, 66], [66, 67], [68, 73], [74, 77], [78, 87], [87, 88], [89, 93], [94, 106], [107, 111], [112, 118], [119, 127], [128, 131], [132, 140], [141, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-test-250", "ner": [[0, 1, "task"], [13, 14, "metrics"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 13, 14, "related-to", "", false, false], [13, 14, 24, 25, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "NER", "model", "is", "one", "of", "a", "number", "of", "methods", "for", "determining", "the", "accuracy", "of", "live", "subtitles", "for", "TV", "programmes", "and", "events", "produced", "with", "speech", "recognition", "."], "sentence-detokenized": "The NER model is one of a number of methods for determining the accuracy of live subtitles for TV programmes and events produced with speech recognition.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 25], [26, 32], [33, 35], [36, 43], [44, 47], [48, 59], [60, 63], [64, 72], [73, 75], [76, 80], [81, 90], [91, 94], [95, 97], [98, 108], [109, 112], [113, 119], [120, 128], [129, 133], [134, 140], [141, 152], [152, 153]]}
{"doc_key": "ai-test-251", "ner": [[0, 1, "researcher"], [4, 5, "university"], [8, 10, "university"], [11, 13, "location"], [14, 18, "university"], [20, 21, "university"], [23, 23, "location"], [27, 32, "university"], [34, 35, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 1, 4, 5, "physical", "", false, false], [0, 1, 4, 5, "role", "", false, false], [0, 1, 8, 10, "physical", "", false, false], [0, 1, 8, 10, "role", "", false, false], [0, 1, 14, 18, "physical", "", false, false], [0, 1, 14, 18, "role", "", false, false], [0, 1, 20, 21, "physical", "", false, false], [0, 1, 20, 21, "role", "", false, false], [0, 1, 27, 32, "physical", "", false, false], [0, 1, 27, 32, "role", "", false, false], [8, 10, 11, 13, "physical", "", false, false], [14, 18, 23, 23, "physical", "", false, false], [20, 21, 23, 23, "physical", "", false, false], [27, 32, 34, 35, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "has", "lectured", "at", "Cambridge", "University", ",", "the", "Hebrew", "University", "of", "Jerusalem", ",", "the", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "and", "\u00c9cole", "Polytechnique", "in", "Paris", ",", "and", "the", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "."], "sentence-detokenized": "Atran has lectured at Cambridge University, the Hebrew University of Jerusalem, the \u00c9cole pratique des hautes \u00e9tudes and \u00c9cole Polytechnique in Paris, and the John Jay College of Criminal Justice in New York.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 21], [22, 31], [32, 42], [42, 43], [44, 47], [48, 54], [55, 65], [66, 68], [69, 78], [78, 79], [80, 83], [84, 89], [90, 98], [99, 102], [103, 109], [110, 116], [117, 120], [121, 126], [127, 140], [141, 143], [144, 149], [149, 150], [151, 154], [155, 158], [159, 163], [164, 167], [168, 175], [176, 178], [179, 187], [188, 195], [196, 198], [199, 202], [203, 207], [207, 208]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [7, 16, "task"], [12, 13, "researcher"], [15, 19, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 16, "origin", "", false, false], [0, 0, 7, 16, "related-to", "", false, false], [7, 16, 15, 19, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "was", "an", "early", "computer", "programme", "for", "natural", "language", "understanding", "developed", "by", "Terry", "Winograd", "at", "MIT", "in", "1968", "-", "1970", "."], "sentence-detokenized": "SHRDLU was an early computer programme for natural language understanding developed by Terry Winograd at MIT in 1968-1970.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 19], [20, 28], [29, 38], [39, 42], [43, 50], [51, 59], [60, 73], [74, 83], [84, 86], [87, 92], [93, 101], [102, 104], [105, 108], [109, 111], [112, 116], [116, 117], [117, 121], [121, 122]]}
{"doc_key": "ai-test-253", "ner": [[5, 34, "field"], [11, 16, "university"], [17, 17, "location"], [23, 23, "country"], [27, 28, "university"], [0, 32, "misc"], [7, 38, "field"], [39, 45, "university"], [72, 75, "field"], [70, 70, "misc"], [50, 80, "university"], [47, 62, "field"], [65, 69, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14], "relations": [[11, 16, 17, 17, "physical", "", false, false], [11, 16, 27, 28, "role", "affiliated_with", false, false], [17, 17, 23, 23, "physical", "", false, false], [0, 32, 7, 38, "topic", "", false, false], [0, 32, 39, 45, "origin", "", false, false], [70, 70, 50, 80, "origin", "", false, false], [70, 70, 47, 62, "topic", "", false, false], [65, 69, 50, 80, "physical", "", false, false]], "relations_mapping_to_source": [2, 3, 4, 5, 6, 8, 9, 10], "sentence": ["He", "received", "his", "B.S.", "in", "Electrical", "Engineering", "and", "Computer", "Science", "from", "B.M.S", ".", "College", "of", "Engineering", "in", "Bangalore", ",", "India", ",", "in", "1982", ",", "while", "affiliated", "with", "Bangalore", "University", ";", "his", "M.S.", "in", "Electrical", "Engineering", "and", "Computer", "Science", "from", "Drexel", "University", "in", "1984", ";", "his", "M.S.", "in", "Artificial", "Intelligence", "from", "the", "University", "of", "Wisconsin", "-", "Madison", ",", "where", "he", "studied", "Artificial", "Intelligence", "in", "collaboration", "with", "Leonard", "Uhr", ";", "and", "his", "Ph.D.", "in", "Computer", "Science", "from", "the", "University", "of", "Wisconsin", "-", "Madison", "in", "1990", "."], "sentence-detokenized": "He received his B.S. in Electrical Engineering and Computer Science from B.M.S. College of Engineering in Bangalore, India, in 1982, while affiliated with Bangalore University; his M.S. in Electrical Engineering and Computer Science from Drexel University in 1984; his M.S. in Artificial Intelligence from the University of Wisconsin-Madison, where he studied Artificial Intelligence in collaboration with Leonard Uhr; and his Ph.D. in Computer Science from the University of Wisconsin-Madison in 1990.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [21, 23], [24, 34], [35, 46], [47, 50], [51, 59], [60, 67], [68, 72], [73, 78], [78, 79], [80, 87], [88, 90], [91, 102], [103, 105], [106, 115], [115, 116], [117, 122], [122, 123], [124, 126], [127, 131], [131, 132], [133, 138], [139, 149], [150, 154], [155, 164], [165, 175], [175, 176], [177, 180], [181, 185], [186, 188], [189, 199], [200, 211], [212, 215], [216, 224], [225, 232], [233, 237], [238, 244], [245, 255], [256, 258], [259, 263], [263, 264], [265, 268], [269, 273], [274, 276], [277, 287], [288, 300], [301, 305], [306, 309], [310, 320], [321, 323], [324, 333], [333, 334], [334, 341], [341, 342], [343, 348], [349, 351], [352, 359], [360, 370], [371, 383], [384, 386], [387, 400], [401, 405], [406, 413], [414, 417], [417, 418], [419, 422], [423, 426], [427, 432], [433, 435], [436, 444], [445, 452], [453, 457], [458, 461], [462, 472], [473, 475], [476, 485], [485, 486], [486, 493], [494, 496], [497, 501], [501, 502]]}
{"doc_key": "ai-test-254", "ner": [[6, 8, "metrics"], [10, 13, "metrics"], [19, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 13, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "usually", "assessed", "by", "the", "Word", "Error", "Rate", "(", "WER", ")", ",", "while", "speed", "is", "measured", "by", "the", "Real", "Time", "Factor", "."], "sentence-detokenized": "Accuracy is usually assessed by the Word Error Rate (WER), while speed is measured by the Real Time Factor.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 28], [29, 31], [32, 35], [36, 40], [41, 46], [47, 51], [52, 53], [53, 56], [56, 57], [57, 58], [59, 64], [65, 70], [71, 73], [74, 82], [83, 85], [86, 89], [90, 94], [95, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [8, 13, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", ",", "Terry", "Winograd", "developed", "an", "early", "natural", "language", "processing", "engine", "that", "could", "interpret", "naturally", "written", "commands", "in", "a", "simple", "rule", "-", "based", "environment", "."], "sentence-detokenized": "In 1971, Terry Winograd developed an early natural language processing engine that could interpret naturally written commands in a simple rule-based environment.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 33], [34, 36], [37, 42], [43, 50], [51, 59], [60, 70], [71, 77], [78, 82], [83, 88], [89, 98], [99, 108], [109, 116], [117, 125], [126, 128], [129, 130], [131, 137], [138, 142], [142, 143], [143, 148], [149, 160], [160, 161]]}
{"doc_key": "ai-test-256", "ner": [[4, 5, "field"], [7, 8, "researcher"], [10, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 7, 8, "related-to", "", false, false], [4, 5, 10, 13, "related-to", "", false, false], [4, 5, 15, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "field", "of", "artificial", "intelligence", ",", "Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "and", "Allen", "Newell", "."], "sentence-detokenized": "In the field of artificial intelligence, Marvin Minsky, Herbert A. Simon and Allen Newell.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 26], [27, 39], [39, 40], [41, 47], [48, 54], [54, 55], [56, 63], [64, 65], [65, 66], [67, 72], [73, 76], [77, 82], [83, 89], [89, 90]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [31, 32, "field"], [34, 35, "field"], [38, 39, "field"], [48, 49, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[31, 32, 9, 10, "origin", "", true, false], [31, 32, 9, 10, "part-of", "", false, false], [31, 32, 38, 39, "compare", "", false, false], [34, 35, 9, 10, "origin", "", true, false], [34, 35, 9, 10, "part-of", "", false, false], [34, 35, 38, 39, "compare", "", false, false], [38, 39, 9, 10, "origin", "", true, false], [38, 39, 9, 10, "part-of", "", false, false], [38, 39, 48, 49, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "the", "second", "half", "of", "the", "20th", "century", ",", "electrical", "engineering", "itself", "split", "into", "several", "disciplines", "specialising", "in", "the", "design", "and", "analysis", "of", "systems", "that", "manipulate", "physical", "signals", ";", "examples", "are", "electronic", "engineering", "and", "computer", "engineering", ";", "while", "design", "engineering", "evolved", "to", "deal", "with", "the", "functional", "design", "of", "user", "interfaces", "."], "sentence-detokenized": "In the second half of the 20th century, electrical engineering itself split into several disciplines specialising in the design and analysis of systems that manipulate physical signals; examples are electronic engineering and computer engineering; while design engineering evolved to deal with the functional design of user interfaces.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 30], [31, 38], [38, 39], [40, 50], [51, 62], [63, 69], [70, 75], [76, 80], [81, 88], [89, 100], [101, 113], [114, 116], [117, 120], [121, 127], [128, 131], [132, 140], [141, 143], [144, 151], [152, 156], [157, 167], [168, 176], [177, 184], [184, 185], [186, 194], [195, 198], [199, 209], [210, 221], [222, 225], [226, 234], [235, 246], [246, 247], [248, 253], [254, 260], [261, 272], [273, 280], [281, 283], [284, 288], [289, 293], [294, 297], [298, 308], [309, 315], [316, 318], [319, 323], [324, 334], [334, 335]]}
{"doc_key": "ai-test-258", "ner": [[6, 6, "metrics"], [8, 9, "metrics"], [11, 14, "metrics"], [47, 49, "metrics"], [56, 58, "metrics"], [62, 68, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 14, 8, 9, "named", "", false, false], [47, 49, 56, 58, "named", "", false, false], [56, 58, 62, 68, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Perhaps", "the", "simplest", "statistic", "is", "the", "accuracy", "or", "proportion", "correct", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "all", "cases", "that", "are", "correctly", "classified", ";", "it", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "total", "population", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Perhaps the simplest statistic is the accuracy or proportion correct (FC), which measures the proportion of all cases that are correctly classified; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN) / total population = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 30], [31, 33], [34, 37], [38, 46], [47, 49], [50, 60], [61, 68], [69, 70], [70, 72], [72, 73], [73, 74], [75, 80], [81, 89], [90, 93], [94, 104], [105, 107], [108, 111], [112, 117], [118, 122], [123, 126], [127, 136], [137, 147], [147, 148], [149, 151], [152, 154], [155, 158], [159, 164], [165, 167], [168, 171], [172, 178], [179, 181], [182, 189], [190, 205], [206, 208], [209, 212], [213, 218], [219, 225], [226, 228], [229, 236], [237, 239], [240, 249], [250, 265], [265, 266], [267, 268], [268, 270], [271, 272], [273, 275], [275, 276], [277, 278], [279, 284], [285, 295], [296, 297], [298, 299], [299, 301], [302, 303], [304, 306], [306, 307], [308, 309], [310, 311], [311, 313], [314, 315], [316, 318], [319, 320], [321, 323], [324, 325], [326, 328], [328, 329], [329, 330]]}
{"doc_key": "ai-test-259", "ner": [[14, 22, "conference"], [24, 36, "conference"], [31, 31, "location"], [36, 36, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 22, 31, 31, "physical", "", false, false], [24, 36, 14, 22, "named", "", false, false], [36, 36, 14, 22, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "academia", ",", "the", "main", "fora", "for", "research", "started", "in", "1995", ",", "when", "the", "first", "international", "conference", "on", "Data", "Mining", "and", "Knowledge", "Discovery", "(", "KDD", "-", "95", ")", "was", "launched", "in", "Montreal", "under", "the", "auspices", "of", "AAAI", "."], "sentence-detokenized": "In academia, the main fora for research started in 1995, when the first international conference on Data Mining and Knowledge Discovery (KDD-95) was launched in Montreal under the auspices of AAAI.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 16], [17, 21], [22, 26], [27, 30], [31, 39], [40, 47], [48, 50], [51, 55], [55, 56], [57, 61], [62, 65], [66, 71], [72, 85], [86, 96], [97, 99], [100, 104], [105, 111], [112, 115], [116, 125], [126, 135], [136, 137], [137, 140], [140, 141], [141, 143], [143, 144], [145, 148], [149, 157], [158, 160], [161, 169], [170, 175], [176, 179], [180, 188], [189, 191], [192, 196], [196, 197]]}
{"doc_key": "ai-test-260", "ner": [[8, 9, "field"], [5, 6, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "approach", ",", "various", "machine", "learning", "and", "data", "mining", "algorithms", "are", "used", "to", "develop", "models", "to", "predict", "user", "ratings", "of", "unrated", "items", "."], "sentence-detokenized": "In this approach, various machine learning and data mining algorithms are used to develop models to predict user ratings of unrated items.", "token2charspan": [[0, 2], [3, 7], [8, 16], [16, 17], [18, 25], [26, 33], [34, 42], [43, 46], [47, 51], [52, 58], [59, 69], [70, 73], [74, 78], [79, 81], [82, 89], [90, 96], [97, 99], [100, 107], [108, 112], [113, 120], [121, 123], [124, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-test-261", "ner": [[12, 12, "algorithm"], [17, 18, "algorithm"], [20, 21, "algorithm"], [28, 29, "misc"], [32, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 17, 18, "related-to", "equivalent", false, false], [17, 18, 20, 21, "usage", "", false, false], [20, 21, 32, 36, "usage", "", false, false], [32, 36, 28, 29, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "light", "of", "the", "above", "discussion", ",", "we", "see", "that", "the", "SVM", "technique", "is", "equivalent", "to", "empirical", "risk", "with", "Tikhonov", "regularisation", ",", "where", "in", "this", "case", "the", "loss", "function", "is", "the", "loss", "on", "the", "exchange", "rate", "."], "sentence-detokenized": "In the light of the above discussion, we see that the SVM technique is equivalent to empirical risk with Tikhonov regularisation, where in this case the loss function is the loss on the exchange rate.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 19], [20, 25], [26, 36], [36, 37], [38, 40], [41, 44], [45, 49], [50, 53], [54, 57], [58, 67], [68, 70], [71, 81], [82, 84], [85, 94], [95, 99], [100, 104], [105, 113], [114, 128], [128, 129], [130, 135], [136, 138], [139, 143], [144, 148], [149, 152], [153, 157], [158, 166], [167, 169], [170, 173], [174, 178], [179, 181], [182, 185], [186, 194], [195, 199], [199, 200]]}
{"doc_key": "ai-test-262", "ner": [[6, 8, "person"], [12, 13, "person"], [16, 16, "organisation"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[18, 19, 16, 16, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "2015", "event", "was", "hosted", "by", "Molly", "McGrath", "and", "featured", "commentary", "by", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "."], "sentence-detokenized": "The 2015 event was hosted by Molly McGrath and featured commentary by Chris Rose and former UFC fighter Kenny Florian.", "token2charspan": [[0, 3], [4, 8], [9, 14], [15, 18], [19, 25], [26, 28], [29, 34], [35, 42], [43, 46], [47, 55], [56, 66], [67, 69], [70, 75], [76, 80], [81, 84], [85, 91], [92, 95], [96, 103], [104, 109], [110, 117], [117, 118]]}
{"doc_key": "ai-test-263", "ner": [[3, 5, "product"], [9, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [18, 18, "researcher"], [21, 21, "researcher"], [32, 34, "task"], [31, 31, "product"], [37, 37, "researcher"], [40, 42, "task"], [44, 46, "researcher"], [47, 48, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12], "relations": [[3, 5, 9, 11, "origin", "", false, false], [3, 5, 13, 14, "origin", "", false, false], [3, 5, 16, 17, "origin", "", false, false], [3, 5, 18, 18, "origin", "", false, false], [13, 14, 37, 37, "named", "same", false, false], [16, 17, 21, 21, "named", "same", false, false], [32, 34, 31, 31, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 7], "sentence": ["A", "subset", "called", "Micro", "-", "Planner", "was", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "Sussman", ",", "and", "Winograd", "1971", ",", "and", "has", "been", "used", "in", "Winograd", "'s", "SHRDLU", "natural", "language", "understanding", "programme", ",", "Eugene", "Charniak", "'s", "story", "understanding", "work", ",", "Thorne", "McCarty", "'s", "legal", "reasoning", "work", ",", "and", "several", "other", "projects", "."], "sentence-detokenized": "A subset called Micro-Planner was implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd Sussman, and Winograd 1971, and has been used in Winograd's SHRDLU natural language understanding programme, Eugene Charniak's story understanding work, Thorne McCarty's legal reasoning work, and several other projects.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [21, 22], [22, 29], [30, 33], [34, 45], [46, 48], [49, 55], [56, 59], [60, 67], [67, 68], [69, 75], [76, 84], [85, 88], [89, 94], [95, 103], [104, 111], [111, 112], [113, 116], [117, 125], [126, 130], [130, 131], [132, 135], [136, 139], [140, 144], [145, 149], [150, 152], [153, 161], [161, 163], [164, 170], [171, 178], [179, 187], [188, 201], [202, 211], [211, 212], [213, 219], [220, 228], [228, 230], [231, 236], [237, 250], [251, 255], [255, 256], [257, 263], [264, 271], [271, 273], [274, 279], [280, 289], [290, 294], [294, 295], [296, 299], [300, 307], [308, 313], [314, 322], [322, 323]]}
{"doc_key": "ai-test-264", "ner": [[0, 2, "product"], [8, 9, "product"], [12, 14, "task"], [16, 17, "task"], [19, 21, "task"], [23, 24, "task"], [26, 27, "task"], [30, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[8, 9, 0, 2, "usage", "", true, false], [12, 14, 8, 9, "part-of", "", true, false], [16, 17, 8, 9, "part-of", "", true, false], [19, 21, 8, 9, "part-of", "", true, false], [23, 24, 8, 9, "part-of", "", true, false], [26, 27, 8, 9, "part-of", "", true, false], [30, 33, 8, 9, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "is", "used", "for", "many", "purposes", "in", "information", "systems", ",", "including", "word", "sense", "disambiguation", ",", "information", "retrieval", ",", "automatic", "text", "classification", ",", "automatic", "summarisation", ",", "machine", "translation", "and", "even", "automatic", "crossword", "puzzle", "generation", "."], "sentence-detokenized": "WordNet is used for many purposes in information systems, including word sense disambiguation, information retrieval, automatic text classification, automatic summarisation, machine translation and even automatic crossword puzzle generation.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 15], [16, 19], [20, 24], [25, 33], [34, 36], [37, 48], [49, 56], [56, 57], [58, 67], [68, 72], [73, 78], [79, 93], [93, 94], [95, 106], [107, 116], [116, 117], [118, 127], [128, 132], [133, 147], [147, 148], [149, 158], [159, 172], [172, 173], [174, 181], [182, 193], [194, 197], [198, 202], [203, 212], [213, 222], [223, 229], [230, 240], [240, 241]]}
{"doc_key": "ai-test-265", "ner": [[0, 0, "researcher"], [6, 9, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 9, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "was", "appointed", "a", "Fellow", "of", "the", "IEEE", "in", "1996", "."], "sentence-detokenized": "Keutzer was appointed a Fellow of the IEEE in 1996.", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 23], [24, 30], [31, 33], [34, 37], [38, 42], [43, 45], [46, 50], [50, 51]]}
{"doc_key": "ai-test-266", "ner": [[8, 12, "algorithm"], [54, 56, "misc"], [65, 66, "algorithm"], [68, 68, "algorithm"], [70, 70, "algorithm"], [72, 73, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[65, 66, 54, 56, "type-of", "", false, false], [68, 68, 54, 56, "type-of", "", false, false], [70, 70, 54, 56, "type-of", "", false, false], [72, 73, 54, 56, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "commonly", "used", "type", "of", "structure", "is", "the", "non-linear", "weighted", "sum", ",", "where", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "left", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "right", ")", "/", "math", ",", "where", "math", "\\", "textstyle", "K", "/", "math", "(", "usually", "called", "the", "activation", "function", ")", "is", "some", "predefined", "function", "such", "as", "the", "hyperbolic", "tangent", ",", "sigmoid", ",", "softmax", "or", "router", "function", "."], "sentence-detokenized": "A commonly used type of structure is the non-linear weighted sum, where math\\ textstyle f (x) = K\\ left (\\ sum _ i w _ i g _ i (x)\\ right) / math, where math\\ textstyle K / math (usually called the activation function) is some predefined function such as the hyperbolic tangent, sigmoid, softmax or router function.", "token2charspan": [[0, 1], [2, 10], [11, 15], [16, 20], [21, 23], [24, 33], [34, 36], [37, 40], [41, 51], [52, 60], [61, 64], [64, 65], [66, 71], [72, 76], [76, 77], [78, 87], [88, 89], [90, 91], [91, 92], [92, 93], [94, 95], [96, 97], [97, 98], [99, 103], [104, 105], [105, 106], [107, 110], [111, 112], [113, 114], [115, 116], [117, 118], [119, 120], [121, 122], [123, 124], [125, 126], [127, 128], [128, 129], [129, 130], [130, 131], [132, 137], [137, 138], [139, 140], [141, 145], [145, 146], [147, 152], [153, 157], [157, 158], [159, 168], [169, 170], [171, 172], [173, 177], [178, 179], [179, 186], [187, 193], [194, 197], [198, 208], [209, 217], [217, 218], [219, 221], [222, 226], [227, 237], [238, 246], [247, 251], [252, 254], [255, 258], [259, 269], [270, 277], [277, 278], [279, 286], [286, 287], [288, 295], [296, 298], [299, 305], [306, 314], [314, 315]]}
{"doc_key": "ai-test-267", "ner": [[1, 1, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "Westworld", ",", "female", "robots", "actually", "had", "sex", "with", "human", "men", "as", "part", "of", "a", "fictional", "holiday", "world", "that", "customers", "paid", "for", "."], "sentence-detokenized": "In Westworld, female robots actually had sex with human men as part of a fictional holiday world that customers paid for.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 20], [21, 27], [28, 36], [37, 40], [41, 44], [45, 49], [50, 55], [56, 59], [60, 62], [63, 67], [68, 70], [71, 72], [73, 82], [83, 90], [91, 96], [97, 101], [102, 111], [112, 116], [117, 120], [120, 121]]}
{"doc_key": "ai-test-268", "ner": [[6, 8, "task"], [22, 27, "task"], [30, 30, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 8, 22, 27, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "process", "usually", "starts", "with", "the", "extraction", "of", "terminology", "and", "concepts", "or", "noun", "phrases", "from", "plain", "text", "using", "language", "processors", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "phrase", "fragmentation", "."], "sentence-detokenized": "The process usually starts with the extraction of terminology and concepts or noun phrases from plain text using language processors such as part-of-speech tagging and phrase fragmentation.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 26], [27, 31], [32, 35], [36, 46], [47, 49], [50, 61], [62, 65], [66, 74], [75, 77], [78, 82], [83, 90], [91, 95], [96, 101], [102, 106], [107, 112], [113, 121], [122, 132], [133, 137], [138, 140], [141, 145], [145, 146], [146, 148], [148, 149], [149, 155], [156, 163], [164, 167], [168, 174], [175, 188], [188, 189]]}
{"doc_key": "ai-test-269", "ner": [[14, 16, "field"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 20, 14, 16, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["Its", "effectiveness", "has", "been", "demonstrated", "on", "a", "number", "of", "problems", "of", "interest", "to", "the", "machine", "learning", "community", ",", "including", "handwriting", "recognition", "."], "sentence-detokenized": "Its effectiveness has been demonstrated on a number of problems of interest to the machine learning community, including handwriting recognition.", "token2charspan": [[0, 3], [4, 17], [18, 21], [22, 26], [27, 39], [40, 42], [43, 44], [45, 51], [52, 54], [55, 63], [64, 66], [67, 75], [76, 78], [79, 82], [83, 90], [91, 99], [100, 109], [109, 110], [111, 120], [121, 132], [133, 144], [144, 145]]}
{"doc_key": "ai-test-270", "ner": [[2, 2, "university"], [4, 4, "researcher"], [10, 11, "researcher"], [19, 20, "product"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 2, 2, "physical", "", false, false], [4, 4, 2, 2, "role", "", false, false], [19, 20, 10, 11, "origin", "", false, false], [19, 20, 17, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "at", "Stanford", ",", "Scheinman", "received", "a", "scholarship", "sponsored", "by", "George", "Devol", ",", "inventor", "of", "the", "first", "industrial", "robot", ",", "Unimate", "."], "sentence-detokenized": "While at Stanford, Scheinman received a scholarship sponsored by George Devol, inventor of the first industrial robot, Unimate.", "token2charspan": [[0, 5], [6, 8], [9, 17], [17, 18], [19, 28], [29, 37], [38, 39], [40, 51], [52, 61], [62, 64], [65, 71], [72, 77], [77, 78], [79, 87], [88, 90], [91, 94], [95, 100], [101, 111], [112, 117], [117, 118], [119, 126], [126, 127]]}
{"doc_key": "ai-test-271", "ner": [[7, 8, "task"], [11, 13, "metrics"], [10, 10, "metrics"], [22, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 11, 13, "usage", "", true, false], [10, 10, 11, 13, "named", "", false, false], [22, 24, 11, 13, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Although", "originally", "used", "for", "the", "evaluation", "of", "machine", "translations", ",", "BLEU", "bilingual", "evaluation", "has", "also", "been", "successfully", "used", "for", "the", "evaluation", "of", "paraphrase", "generation", "models", "."], "sentence-detokenized": "Although originally used for the evaluation of machine translations, BLEU bilingual evaluation has also been successfully used for the evaluation of paraphrase generation models.", "token2charspan": [[0, 8], [9, 19], [20, 24], [25, 28], [29, 32], [33, 43], [44, 46], [47, 54], [55, 67], [67, 68], [69, 73], [74, 83], [84, 94], [95, 98], [99, 103], [104, 108], [109, 121], [122, 126], [127, 130], [131, 134], [135, 145], [146, 148], [149, 159], [160, 170], [171, 177], [177, 178]]}
{"doc_key": "ai-test-272", "ner": [[0, 1, "organisation"], [6, 8, "organisation"], [10, 12, "organisation"], [14, 15, "product"], [17, 17, "country"], [19, 20, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 6, 8, "role", "licenses_to", false, false], [0, 1, 10, 12, "role", "licenses_to", false, false], [6, 8, 17, 17, "physical", "", false, false], [10, 12, 19, 20, "physical", "", false, false], [14, 15, 6, 8, "artifact", "produces", false, false], [14, 15, 10, 12, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "subsequently", "licensed", "its", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "which", "manufactured", "the", "Unimate", "in", "Japan", "and", "England", "respectively", "."], "sentence-detokenized": "Unimation subsequently licensed its technology to Kawasaki Heavy Industries and GKN, which manufactured the Unimate in Japan and England respectively.", "token2charspan": [[0, 9], [10, 22], [23, 31], [32, 35], [36, 46], [47, 49], [50, 58], [59, 64], [65, 75], [76, 79], [80, 83], [83, 84], [85, 90], [91, 103], [104, 107], [108, 115], [116, 118], [119, 124], [125, 128], [129, 136], [137, 149], [149, 150]]}
{"doc_key": "ai-test-273", "ner": [[20, 21, "conference"], [38, 39, "field"], [57, 61, "field"], [63, 63, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[38, 39, 57, 61, "compare", "", false, false], [63, 63, 57, 61, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "confusion", "between", "these", "two", "research", "communities", "(", "which", "often", "have", "separate", "conferences", "and", "separate", "journals", ",", "with", "ECML", "PKDD", "being", "a", "notable", "exception", ")", "stems", "from", "the", "underlying", "assumptions", "on", "which", "they", "operate", ":", "in", "machine", "learning", ",", "performance", "is", "usually", "evaluated", "in", "terms", "of", "the", "ability", "to", "reproduce", "known", "knowledge", ",", "whereas", "in", "knowledge", "discovery", "and", "data", "mining", "(", "KDD", ")", ",", "the", "key", "task", "is", "to", "discover", "previously", "unknown", "knowledge", "."], "sentence-detokenized": "Much of the confusion between these two research communities (which often have separate conferences and separate journals, with ECML PKDD being a notable exception) stems from the underlying assumptions on which they operate: in machine learning, performance is usually evaluated in terms of the ability to reproduce known knowledge, whereas in knowledge discovery and data mining (KDD), the key task is to discover previously unknown knowledge.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 29], [30, 35], [36, 39], [40, 48], [49, 60], [61, 62], [62, 67], [68, 73], [74, 78], [79, 87], [88, 99], [100, 103], [104, 112], [113, 121], [121, 122], [123, 127], [128, 132], [133, 137], [138, 143], [144, 145], [146, 153], [154, 163], [163, 164], [165, 170], [171, 175], [176, 179], [180, 190], [191, 202], [203, 205], [206, 211], [212, 216], [217, 224], [224, 225], [226, 228], [229, 236], [237, 245], [245, 246], [247, 258], [259, 261], [262, 269], [270, 279], [280, 282], [283, 288], [289, 291], [292, 295], [296, 303], [304, 306], [307, 316], [317, 322], [323, 332], [332, 333], [334, 341], [342, 344], [345, 354], [355, 364], [365, 368], [369, 373], [374, 380], [381, 382], [382, 385], [385, 386], [386, 387], [388, 391], [392, 395], [396, 400], [401, 403], [404, 406], [407, 415], [416, 426], [427, 434], [435, 444], [444, 445]]}
{"doc_key": "ai-test-274", "ner": [[0, 1, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hidden", "Markov", "models", "are", "the", "basis", "for", "most", "modern", "automatic", "speech", "recognition", "systems", "."], "sentence-detokenized": "Hidden Markov models are the basis for most modern automatic speech recognition systems.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 28], [29, 34], [35, 38], [39, 43], [44, 50], [51, 60], [61, 67], [68, 79], [80, 87], [87, 88]]}
{"doc_key": "ai-test-275", "ner": [[2, 2, "location"], [4, 6, "country"], [13, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 4, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": [",", "a", "Bangalore", ",", "India", "-", "based", "company", "specialising", "in", "web", "-", "based", "handwriting", "recognition", "software", "."], "sentence-detokenized": ", a Bangalore, India-based company specialising in web-based handwriting recognition software.", "token2charspan": [[0, 1], [2, 3], [4, 13], [13, 14], [15, 20], [20, 21], [21, 26], [27, 34], [35, 47], [48, 50], [51, 54], [54, 55], [55, 60], [61, 72], [73, 84], [85, 93], [93, 94]]}
{"doc_key": "ai-test-276", "ner": [[24, 25, "misc"], [51, 51, "metrics"], [53, 57, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[51, 51, 53, 57, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Do", "repeated", "translations", "in", "both", "languages", "converge", "to", "a", "single", "term", "?", "That", "is", ",", "does", "the", "translation", "method", "show", "stationarity", "or", "create", "a", "canonical", "form", "?", "Does", "a", "translation", "become", "stationary", "without", "losing", "its", "original", "meaning", "?", "This", "metric", "has", "been", "criticised", "because", "it", "does", "not", "correlate", "well", "with", "the", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "results", "."], "sentence-detokenized": "Do repeated translations in both languages converge to a single term? That is, does the translation method show stationarity or create a canonical form? Does a translation become stationary without losing its original meaning? This metric has been criticised because it does not correlate well with the BLEU (BiLingual Evaluation Understudy) results.", "token2charspan": [[0, 2], [3, 11], [12, 24], [25, 27], [28, 32], [33, 42], [43, 51], [52, 54], [55, 56], [57, 63], [64, 68], [68, 69], [70, 74], [75, 77], [77, 78], [79, 83], [84, 87], [88, 99], [100, 106], [107, 111], [112, 124], [125, 127], [128, 134], [135, 136], [137, 146], [147, 151], [151, 152], [153, 157], [158, 159], [160, 171], [172, 178], [179, 189], [190, 197], [198, 204], [205, 208], [209, 217], [218, 225], [225, 226], [227, 231], [232, 238], [239, 242], [243, 247], [248, 258], [259, 266], [267, 269], [270, 274], [275, 278], [279, 288], [289, 293], [294, 298], [299, 302], [303, 307], [308, 309], [309, 318], [319, 329], [330, 340], [340, 341], [342, 349], [349, 350]]}
{"doc_key": "ai-test-277", "ner": [[5, 10, "organisation"], [13, 19, "organisation"], [21, 24, "university"], [30, 30, "university"], [27, 29, "field"], [33, 37, "organisation"], [40, 47, "organisation"], [53, 56, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[13, 19, 21, 24, "part-of", "", false, false], [30, 30, 27, 29, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "has", "held", "fellowships", "from", "the", "American", "Society", "for", "Artificial", "Intelligence", ",", "the", "Centre", "for", "Advanced", "Studies", "in", "Behavioural", "Science", "at", "Stanford", "University", ",", "the", "Centre", "for", "Cognitive", "Science", "at", "MIT", ",", "the", "Canadian", "Institute", "for", "Advanced", "Research", ",", "the", "Canadian", "Psychological", "Association", ",", "and", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "in", "1998", "."], "sentence-detokenized": "He has held fellowships from the American Society for Artificial Intelligence, the Centre for Advanced Studies in Behavioural Science at Stanford University, the Centre for Cognitive Science at MIT, the Canadian Institute for Advanced Research, the Canadian Psychological Association, and was elected a Fellow of the Royal Society of Canada in 1998.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 23], [24, 28], [29, 32], [33, 41], [42, 49], [50, 53], [54, 64], [65, 77], [77, 78], [79, 82], [83, 89], [90, 93], [94, 102], [103, 110], [111, 113], [114, 125], [126, 133], [134, 136], [137, 145], [146, 156], [156, 157], [158, 161], [162, 168], [169, 172], [173, 182], [183, 190], [191, 193], [194, 197], [197, 198], [199, 202], [203, 211], [212, 221], [222, 225], [226, 234], [235, 243], [243, 244], [245, 248], [249, 257], [258, 271], [272, 283], [283, 284], [285, 288], [289, 292], [293, 300], [301, 302], [303, 309], [310, 312], [313, 316], [317, 322], [323, 330], [331, 333], [334, 340], [341, 343], [344, 348], [348, 349]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [15, 18, "misc"], [21, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 15, 18, "part-of", "", false, false], [0, 0, 21, 24, "part-of", "", false, false], [4, 5, 15, 18, "part-of", "", false, false], [4, 5, 21, 24, "part-of", "", false, false], [7, 8, 15, 18, "part-of", "", false, false], [7, 8, 21, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "-", "along", "with", "Yoshua", "Benga", "and", "Yann", "LeCun", "-", "are", "called", "by", "some", "the", "godfathers", "of", "artificial", "intelligence", "and", "the", "godfathers", "of", "deep", "learning", "."], "sentence-detokenized": "Hinton - along with Yoshua Benga and Yann LeCun - are called by some the godfathers of artificial intelligence and the godfathers of deep learning.", "token2charspan": [[0, 6], [7, 8], [9, 14], [15, 19], [20, 26], [27, 32], [33, 36], [37, 41], [42, 47], [48, 49], [50, 53], [54, 60], [61, 63], [64, 68], [69, 72], [73, 83], [84, 86], [87, 97], [98, 110], [111, 114], [115, 118], [119, 129], [130, 132], [133, 137], [138, 146], [146, 147]]}
{"doc_key": "ai-test-279", "ner": [[6, 8, "product"], [18, 18, "misc"], [20, 25, "misc"], [26, 26, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 18, 18, "related-to", "", false, false], [6, 8, 20, 25, "related-to", "", false, false], [18, 18, 26, 26, "named", "same", false, false], [28, 29, 26, 26, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "lightweight", "open", "source", "speech", "project", "eSpeak", ",", "which", "has", "its", "own", "approach", "to", "synthesis", ",", "has", "used", "Mandarin", "and", "Cantonese", "on", "a", "trial", "basis", ".", "eSpeak", "used", "Google", "Translate", "from", "May", "2010", "to", "2010", "."], "sentence-detokenized": "The lightweight open source speech project eSpeak, which has its own approach to synthesis, has used Mandarin and Cantonese on a trial basis. eSpeak used Google Translate from May 2010 to 2010.", "token2charspan": [[0, 3], [4, 15], [16, 20], [21, 27], [28, 34], [35, 42], [43, 49], [49, 50], [51, 56], [57, 60], [61, 64], [65, 68], [69, 77], [78, 80], [81, 90], [90, 91], [92, 95], [96, 100], [101, 109], [110, 113], [114, 123], [124, 126], [127, 128], [129, 134], [135, 140], [140, 141], [142, 148], [149, 153], [154, 160], [161, 170], [171, 175], [176, 179], [180, 184], [185, 187], [188, 192], [192, 193]]}
{"doc_key": "ai-test-280", "ner": [[3, 7, "product"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 7, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1982", ",", "Software", "Automatic", "Mouth", "was", "released", ",", "the", "first", "commercial", "software", "-", "based", "voice", "synthesis", "programme", "."], "sentence-detokenized": "In 1982, Software Automatic Mouth was released, the first commercial software-based voice synthesis programme.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 17], [18, 27], [28, 33], [34, 37], [38, 46], [46, 47], [48, 51], [52, 57], [58, 68], [69, 77], [77, 78], [78, 83], [84, 89], [90, 99], [100, 109], [109, 110]]}
{"doc_key": "ai-test-281", "ner": [[4, 6, "metrics"], [8, 8, "metrics"], [11, 11, "metrics"], [13, 13, "metrics"], [16, 25, "metrics"], [26, 28, "metrics"], [30, 30, "metrics"], [33, 39, "metrics"], [43, 45, "metrics"], [47, 47, "metrics"], [50, 50, "metrics"], [52, 52, "metrics"], [55, 63, "metrics"], [65, 67, "metrics"], [69, 69, "metrics"], [72, 78, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[8, 8, 4, 6, "named", "", false, false], [11, 11, 4, 6, "named", "", false, false], [13, 13, 4, 6, "named", "", false, false], [16, 25, 4, 6, "named", "", false, false], [30, 30, 26, 28, "named", "", false, false], [33, 39, 26, 28, "named", "", false, false], [47, 47, 43, 45, "named", "", false, false], [50, 50, 43, 45, "named", "", false, false], [52, 52, 43, 45, "named", "", false, false], [55, 63, 43, 45, "named", "", false, false], [69, 69, 65, 67, "named", "", false, false], [72, 78, 65, 67, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["The", "column", "ratios", "are", "TRUE", "Positive", "Rate", "(", "TPR", ",", "also", "Sensitivity", "or", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", "complemented", "by", "FALSE", "Negative", "Rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "and", "TRUE", "Negative", "Rate", "(", "TNR", ",", "also", "Specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", "complemented", "by", "FALSE", "Positive", "Rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "The column ratios are TRUE Positive Rate (TPR, also Sensitivity or recall) (TP / (TP + FN)) complemented by FALSE Negative Rate (FNR) (FN / (TP + FN)); and TRUE Negative Rate (TNR, also Specificity, SPC) (TN / (TN + FP)) complemented by FALSE Positive Rate (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 21], [22, 26], [27, 35], [36, 40], [41, 42], [42, 45], [45, 46], [47, 51], [52, 63], [64, 66], [67, 73], [73, 74], [75, 76], [76, 78], [79, 80], [81, 82], [82, 84], [85, 86], [87, 89], [89, 90], [90, 91], [92, 104], [105, 107], [108, 113], [114, 122], [123, 127], [128, 129], [129, 132], [132, 133], [134, 135], [135, 137], [138, 139], [140, 141], [141, 143], [144, 145], [146, 148], [148, 149], [149, 150], [150, 151], [152, 155], [156, 160], [161, 169], [170, 174], [175, 176], [176, 179], [179, 180], [181, 185], [186, 197], [197, 198], [199, 202], [202, 203], [204, 205], [205, 207], [208, 209], [210, 211], [211, 213], [214, 215], [216, 218], [218, 219], [219, 220], [221, 233], [234, 236], [237, 242], [243, 251], [252, 256], [257, 258], [258, 261], [261, 262], [263, 264], [264, 266], [267, 268], [269, 270], [270, 272], [273, 274], [275, 277], [277, 278], [278, 279], [279, 280]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 17, 17, "role", "working_with", false, false], [2, 2, 17, 17, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "and", "Weber", "have", "also", "worked", "on", "a", "number", "of", "other", "robots", ",", "and", "their", "experience", "with", "Kismet"], "sentence-detokenized": "Edsinger and Weber have also worked on a number of other robots, and their experience with Kismet", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 28], [29, 35], [36, 38], [39, 40], [41, 47], [48, 50], [51, 56], [57, 63], [63, 64], [65, 68], [69, 74], [75, 85], [86, 90], [91, 97]]}
{"doc_key": "ai-test-283", "ner": [[0, 2, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 11, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["R", "functions", "are", "also", "available", "from", "several", "scripting", "languages", "such", "as", "Python", "."], "sentence-detokenized": "R functions are also available from several scripting languages such as Python.", "token2charspan": [[0, 1], [2, 11], [12, 15], [16, 20], [21, 30], [31, 35], [36, 43], [44, 53], [54, 63], [64, 68], [69, 71], [72, 78], [78, 79]]}
{"doc_key": "ai-test-284", "ner": [[0, 4, "programlang"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 0, 4, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "was", "one", "of", "the", "first", "robotic", "languages", "and", "was", "used", "in", "Unimate", "robots", "."], "sentence-detokenized": "VAL was one of the first robotic languages and was used in Unimate robots.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 24], [25, 32], [33, 42], [43, 46], [47, 50], [51, 55], [56, 58], [59, 66], [67, 73], [73, 74]]}
{"doc_key": "ai-test-285", "ner": [[10, 19, "conference"], [17, 17, "conference"], [21, 21, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 19, 21, 21, "physical", "", false, false], [17, 17, 10, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["They", "first", "presented", "their", "database", "as", "a", "poster", "at", "the", "2009", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "conference", "in", "Florida", "."], "sentence-detokenized": "They first presented their database as a poster at the 2009 Computer Vision and Pattern Recognition (CVPR) conference in Florida.", "token2charspan": [[0, 4], [5, 10], [11, 20], [21, 26], [27, 35], [36, 38], [39, 40], [41, 47], [48, 50], [51, 54], [55, 59], [60, 68], [69, 75], [76, 79], [80, 87], [88, 99], [100, 101], [101, 105], [105, 106], [107, 117], [118, 120], [121, 128], [128, 129]]}
{"doc_key": "ai-test-286", "ner": [[0, 2, "misc"], [9, 10, "task"], [12, 13, "field"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 0, 2, "type-of", "", false, false], [12, 13, 0, 2, "type-of", "", false, false], [15, 16, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Classification", "tasks", "where", "no", "labels", "are", "available", "are", "called", "unsupervised", "classification", ",", "unsupervised", "learning", ",", "cluster", "analysis", "."], "sentence-detokenized": "Classification tasks where no labels are available are called unsupervised classification, unsupervised learning, cluster analysis.", "token2charspan": [[0, 14], [15, 20], [21, 26], [27, 29], [30, 36], [37, 40], [41, 50], [51, 54], [55, 61], [62, 74], [75, 89], [89, 90], [91, 103], [104, 112], [112, 113], [114, 121], [122, 130], [130, 131]]}
{"doc_key": "ai-test-287", "ner": [[3, 4, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "needs", "to", "recognise", "objects", ",", "recognise", "and", "locate", "people", "and", "furthermore", "recognise", "emotions", "."], "sentence-detokenized": "It needs to recognise objects, recognise and locate people and furthermore recognise emotions.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 21], [22, 29], [29, 30], [31, 40], [41, 44], [45, 51], [52, 58], [59, 62], [63, 74], [75, 84], [85, 93], [93, 94]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [8, 8, "misc"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "process", "is", "complex", "and", "involves", "encoding", "and", "recalling", "or", "restoring", "."], "sentence-detokenized": "The process is complex and involves encoding and recalling or restoring.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 26], [27, 35], [36, 44], [45, 48], [49, 58], [59, 61], [62, 71], [71, 72]]}
{"doc_key": "ai-test-289", "ner": [[10, 11, "product"], [15, 16, "product"], [31, 33, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 15, 16, "named", "", false, false], [10, 11, 31, 33, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "also", "known", "as", "parallel", "robots", "or", "generalised", "Stewart", "platforms", "(", "in", "a", "Stewart", "platform", ",", "actuators", "are", "paired", "on", "both", "the", "base", "and", "the", "platform", ")", ",", "are", "articulated", "robots", "that", "use", "similar", "mechanisms", "to", "move", "either", "the", "robot", "on", "the", "base", "or", "one", "or", "more", "manipulator", "arms", "."], "sentence-detokenized": "These systems, also known as parallel robots or generalised Stewart platforms (in a Stewart platform, actuators are paired on both the base and the platform), are articulated robots that use similar mechanisms to move either the robot on the base or one or more manipulator arms.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 25], [26, 28], [29, 37], [38, 44], [45, 47], [48, 59], [60, 67], [68, 77], [78, 79], [79, 81], [82, 83], [84, 91], [92, 100], [100, 101], [102, 111], [112, 115], [116, 122], [123, 125], [126, 130], [131, 134], [135, 139], [140, 143], [144, 147], [148, 156], [156, 157], [157, 158], [159, 162], [163, 174], [175, 181], [182, 186], [187, 190], [191, 198], [199, 209], [210, 212], [213, 217], [218, 224], [225, 228], [229, 234], [235, 237], [238, 241], [242, 246], [247, 249], [250, 253], [254, 256], [257, 261], [262, 273], [274, 278], [278, 279]]}
{"doc_key": "ai-test-290", "ner": [[0, 1, "field"], [6, 7, "field"], [12, 15, "field"], [20, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 7, "part-of", "subfield", false, false], [0, 1, 12, 15, "compare", "", false, false], [12, 15, 20, 21, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "vision", "as", "a", "discipline", "of", "systems", "engineering", "can", "be", "distinguished", "from", "computer", "vision", ",", "which", "is", "a", "form", "of", "computer", "science", "."], "sentence-detokenized": "Machine vision as a discipline of systems engineering can be distinguished from computer vision, which is a form of computer science.", "token2charspan": [[0, 7], [8, 14], [15, 17], [18, 19], [20, 30], [31, 33], [34, 41], [42, 53], [54, 57], [58, 60], [61, 74], [75, 79], [80, 88], [89, 95], [95, 96], [97, 102], [103, 105], [106, 107], [108, 112], [113, 115], [116, 124], [125, 132], [132, 133]]}
{"doc_key": "ai-test-291", "ner": [[4, 9, "algorithm"], [10, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 9, 10, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "activation", "function", "of", "the", "LSTM", "gate", "is", "often", "a", "logistic", "sigmoid", "function", "."], "sentence-detokenized": "The activation function of the LSTM gate is often a logistic sigmoid function.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 26], [27, 30], [31, 35], [36, 40], [41, 43], [44, 49], [50, 51], [52, 60], [61, 68], [69, 77], [77, 78]]}
{"doc_key": "ai-test-292", "ner": [[5, 6, "metrics"], [18, 23, "metrics"], [25, 28, "metrics"], [33, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 18, 23, "named", "", false, false], [5, 6, 33, 35, "named", "", false, false], [25, 28, 18, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "the", "(", "necessarily", "unique", ")", "efficient", "estimator", "and", "hence", "the", "smallest", "unbiased", "estimate", "of", "the", "variance", "(", "MVUE", ")", ",", "and", "it", "is", "also", "the", "maximum", "likelihood", "estimator", "."], "sentence-detokenized": "In other words, the sample mean is the (necessarily unique) efficient estimator and hence the smallest unbiased estimate of the variance (MVUE), and it is also the maximum likelihood estimator.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 38], [39, 40], [40, 51], [52, 58], [58, 59], [60, 69], [70, 79], [80, 83], [84, 89], [90, 93], [94, 102], [103, 111], [112, 120], [121, 123], [124, 127], [128, 136], [137, 138], [138, 142], [142, 143], [143, 144], [145, 148], [149, 151], [152, 154], [155, 159], [160, 163], [164, 171], [172, 182], [183, 192], [192, 193]]}
{"doc_key": "ai-test-293", "ner": [[17, 18, "academicjournal"], [3, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [27, 27, "product"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 18, 27, 27, "topic", "", false, false], [17, 18, 30, 31, "topic", "", false, false], [3, 5, 17, 18, "role", "", false, false], [7, 8, 17, 18, "role", "", false, false], [10, 11, 17, 18, "role", "", false, false], [27, 27, 30, 31, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2001", ",", "Berners", "-", "Lee", ",", "James", "Hendler", "and", "Ora", "Lassila", ",", "in", "an", "article", "in", "Scientific", "American", ",", "described", "the", "expected", "evolution", "of", "the", "existing", "web", "into", "a", "semantic", "web", "."], "sentence-detokenized": "In 2001, Berners-Lee, James Hendler and Ora Lassila, in an article in Scientific American, described the expected evolution of the existing web into a semantic web.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [16, 17], [17, 20], [20, 21], [22, 27], [28, 35], [36, 39], [40, 43], [44, 51], [51, 52], [53, 55], [56, 58], [59, 66], [67, 69], [70, 80], [81, 89], [89, 90], [91, 100], [101, 104], [105, 113], [114, 123], [124, 126], [127, 130], [131, 139], [140, 143], [144, 148], [149, 150], [151, 159], [160, 163], [163, 164]]}
{"doc_key": "ai-test-294", "ner": [[0, 3, "misc"], [12, 12, "person"], [19, 24, "person"]], "ner_mapping_to_source": [0, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Blade", "Runner", "featured", "a", "number", "of", "then", "lesser", "-", "known", "actors", ":", "Sammon", ",", "pp.", "92", "-", "93", ".", "Nina", "Axelrod", "auditioned", "for", "the", "role", "."], "sentence-detokenized": "Blade Runner featured a number of then lesser-known actors: Sammon, pp. 92-93. Nina Axelrod auditioned for the role.", "token2charspan": [[0, 5], [6, 12], [13, 21], [22, 23], [24, 30], [31, 33], [34, 38], [39, 45], [45, 46], [46, 51], [52, 58], [58, 59], [60, 66], [66, 67], [68, 71], [72, 74], [74, 75], [75, 77], [77, 78], [79, 83], [84, 91], [92, 102], [103, 106], [107, 110], [111, 115], [115, 116]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 18, "university"], [23, 25, "product"], [27, 27, "product"], [42, 43, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 12, 18, "physical", "", false, false], [3, 4, 12, 18, "physical", "", false, false], [6, 7, 12, 18, "physical", "", false, false], [9, 10, 12, 18, "physical", "", false, false], [12, 18, 42, 43, "physical", "", true, false], [23, 25, 12, 18, "temporal", "", false, false], [27, 27, 12, 18, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "and", "Terry", "Winograd", "visited", "the", "University", "of", "Edinburgh", "in", "1971", "to", "spread", "the", "news", "about", "Micro", "-", "Planner", "and", "SHRDLU", "and", "to", "question", "the", "Unified", "Proof", "Procedure", "approach", "that", "had", "been", "the", "mainstay", "of", "the", "Edinburgh", "logicians", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited the University of Edinburgh in 1971 to spread the news about Micro-Planner and SHRDLU and to question the Unified Proof Procedure approach that had been the mainstay of the Edinburgh logicians.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 56], [57, 65], [66, 73], [74, 77], [78, 88], [89, 91], [92, 101], [102, 104], [105, 109], [110, 112], [113, 119], [120, 123], [124, 128], [129, 134], [135, 140], [140, 141], [141, 148], [149, 152], [153, 159], [160, 163], [164, 166], [167, 175], [176, 179], [180, 187], [188, 193], [194, 203], [204, 212], [213, 217], [218, 221], [222, 226], [227, 230], [231, 239], [240, 242], [243, 246], [247, 256], [257, 266], [266, 267]]}
{"doc_key": "ai-test-296", "ner": [[0, 1, "researcher"], [6, 8, "field"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 10, 11, "role", "inspires", false, false], [0, 1, 13, 14, "role", "inspires", false, false], [0, 1, 16, 17, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Walter", "'s", "work", "inspired", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work inspired generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 22], [23, 34], [35, 37], [38, 46], [47, 58], [59, 63], [64, 66], [67, 73], [74, 80], [80, 81], [82, 86], [87, 94], [95, 98], [99, 103], [104, 110], [110, 111]]}
{"doc_key": "ai-test-297", "ner": [[7, 8, "algorithm"], [9, 10, "researcher"], [15, 21, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 9, 10, "origin", "", false, false], [7, 8, 15, 21, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Subsequently", ",", "a", "similar", "GPU", "-", "based", "CNN", "by", "Alex", "Krizhevsky", "and", "others", "won", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "2012", "."], "sentence-detokenized": "Subsequently, a similar GPU-based CNN by Alex Krizhevsky and others won the ImageNet Large Scale Visual Recognition Challenge 2012.", "token2charspan": [[0, 12], [12, 13], [14, 15], [16, 23], [24, 27], [27, 28], [28, 33], [34, 37], [38, 40], [41, 45], [46, 56], [57, 60], [61, 67], [68, 71], [72, 75], [76, 84], [85, 90], [91, 96], [97, 103], [104, 115], [116, 125], [126, 130], [130, 131]]}
{"doc_key": "ai-test-298", "ner": [[2, 4, "misc"], [9, 10, "metrics"], [13, 14, "metrics"], [19, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 2, 4, "type-of", "", false, false], [13, 14, 2, 4, "type-of", "", false, false], [13, 14, 19, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Commonly", "used", "loss", "functions", "for", "probabilistic", "classification", "include", "the", "logarithmic", "loss", "and", "the", "Brier", "estimate", "between", "the", "predicted", "and", "true", "probability", "distributions", "."], "sentence-detokenized": "Commonly used loss functions for probabilistic classification include the logarithmic loss and the Brier estimate between the predicted and true probability distributions.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 28], [29, 32], [33, 46], [47, 61], [62, 69], [70, 73], [74, 85], [86, 90], [91, 94], [95, 98], [99, 104], [105, 113], [114, 121], [122, 125], [126, 135], [136, 139], [140, 144], [145, 156], [157, 170], [170, 171]]}
{"doc_key": "ai-test-299", "ner": [[4, 4, "organisation"], [19, 19, "field"], [22, 22, "organisation"], [10, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 19, 19, "general-affiliation", "field_of_study", false, false], [4, 4, 10, 11, "part-of", "", false, false], [22, 22, 4, 4, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "May", "2016", ",", "NtechLab", "was", "one", "of", "only", "three", "Russian", "companies", "to", "be", "accepted", "for", "official", "testing", "of", "biometric", "technology", "by", "NIST", "."], "sentence-detokenized": "In May 2016, NtechLab was one of only three Russian companies to be accepted for official testing of biometric technology by NIST.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [22, 25], [26, 29], [30, 32], [33, 37], [38, 43], [44, 51], [52, 61], [62, 64], [65, 67], [68, 76], [77, 80], [81, 89], [90, 97], [98, 100], [101, 110], [111, 121], [122, 124], [125, 129], [129, 130]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["But", "floating", "-", "point", "numbers", "only", "have", "a", "certain", "mathematical", "precision", "."], "sentence-detokenized": "But floating-point numbers only have a certain mathematical precision.", "token2charspan": [[0, 3], [4, 12], [12, 13], [13, 18], [19, 26], [27, 31], [32, 36], [37, 38], [39, 46], [47, 59], [60, 69], [69, 70]]}
{"doc_key": "ai-test-301", "ner": [[5, 5, "organisation"], [12, 18, "conference"], [20, 20, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 12, 18, "role", "contributes_to", false, false], [20, 20, 12, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2015", ",", "many", "of", "SenseTime", "'s", "papers", "were", "accepted", "to", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "In 2015, many of SenseTime's papers were accepted to the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 13], [14, 16], [17, 26], [26, 28], [29, 35], [36, 40], [41, 49], [50, 52], [53, 56], [57, 67], [68, 70], [71, 79], [80, 86], [87, 90], [91, 98], [99, 110], [111, 112], [112, 116], [116, 117], [117, 118]]}
{"doc_key": "ai-test-302", "ner": [[10, 12, "task"], [14, 14, "task"], [16, 17, "task"], [19, 22, "task"], [25, 25, "field"], [27, 29, "misc"], [33, 39, "conference"], [46, 50, "misc"], [51, 53, "conference"], [70, 75, "misc"], [76, 76, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[10, 12, 25, 25, "part-of", "task_part_of_field", false, false], [14, 14, 10, 12, "named", "", false, false], [16, 17, 25, 25, "part-of", "task_part_of_field", false, false], [19, 22, 16, 17, "named", "", false, false], [27, 29, 33, 39, "temporal", "", false, false], [46, 50, 51, 53, "temporal", "", false, false], [70, 75, 76, 76, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["He", "has", "contributed", "to", "the", "development", "of", "optimal", "algorithms", "for", "Structure", "From", "Motion", "(", "SFM", "or", "Visual", "SLAM", ",", "simultaneous", "localisation", "and", "mapping", ",", "in", "robotics", ";", "best", "paper", "award", "at", "the", "1998", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ")", ",", "defined", "its", "ambiguities", "(", "David", "Marr", "award", "at", "the", "1999", "ICCV", "conference", ")", ",", "and", "defined", "the", "identifiability", "and", "observability", "of", "fusion", "of", "visual", "and", "inertial", "sensors", "(", "best", "paper", "award", "at", "the", "2015", "Robotics", "conference", ")", "."], "sentence-detokenized": "He has contributed to the development of optimal algorithms for Structure From Motion (SFM or Visual SLAM, simultaneous localisation and mapping, in robotics; best paper award at the 1998 Conference on Computer Vision and Pattern Recognition), defined its ambiguities (David Marr award at the 1999 ICCV conference), and defined the identifiability and observability of fusion of visual and inertial sensors (best paper award at the 2015 Robotics conference).", "token2charspan": [[0, 2], [3, 6], [7, 18], [19, 21], [22, 25], [26, 37], [38, 40], [41, 48], [49, 59], [60, 63], [64, 73], [74, 78], [79, 85], [86, 87], [87, 90], [91, 93], [94, 100], [101, 105], [105, 106], [107, 119], [120, 132], [133, 136], [137, 144], [144, 145], [146, 148], [149, 157], [157, 158], [159, 163], [164, 169], [170, 175], [176, 178], [179, 182], [183, 187], [188, 198], [199, 201], [202, 210], [211, 217], [218, 221], [222, 229], [230, 241], [241, 242], [242, 243], [244, 251], [252, 255], [256, 267], [268, 269], [269, 274], [275, 279], [280, 285], [286, 288], [289, 292], [293, 297], [298, 302], [303, 313], [313, 314], [314, 315], [316, 319], [320, 327], [328, 331], [332, 347], [348, 351], [352, 365], [366, 368], [369, 375], [376, 378], [379, 385], [386, 389], [390, 398], [399, 406], [407, 408], [408, 412], [413, 418], [419, 424], [425, 427], [428, 431], [432, 436], [437, 445], [446, 456], [456, 457], [457, 458]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 11, "field"], [13, 16, "field"], [21, 22, "task"], [24, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 7, 8, "part-of", "task_part_of_field", false, false], [0, 1, 10, 11, "part-of", "task_part_of_field", false, false], [0, 1, 13, 16, "part-of", "task_part_of_field", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 24, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "a", "fundamental", "tool", "in", "image", "processing", ",", "machine", "vision", "and", "computer", "vision", ",", "especially", "in", "the", "field", "of", "feature", "detection", "and", "extraction", "."], "sentence-detokenized": "Edge detection is a fundamental tool in image processing, machine vision and computer vision, especially in the field of feature detection and extraction.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 19], [20, 31], [32, 36], [37, 39], [40, 45], [46, 56], [56, 57], [58, 65], [66, 72], [73, 76], [77, 85], [86, 92], [92, 93], [94, 104], [105, 107], [108, 111], [112, 117], [118, 120], [121, 128], [129, 138], [139, 142], [143, 153], [153, 154]]}
{"doc_key": "ai-test-305", "ner": [[8, 9, "misc"], [22, 23, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "example", "is", "a", "variable", "such", "as", "the", "outside", "temperature", "(", "mathtemp", "/", "math", ")", ",", "which", "can", "be", "recorded", "to", "several", "decimal", "places", "in", "a", "given", "application", "(", "depending", "on", "the", "sensing", "apparatus", ")", "."], "sentence-detokenized": "An example is a variable such as the outside temperature (mathtemp/math), which can be recorded to several decimal places in a given application (depending on the sensing apparatus).", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 29], [30, 32], [33, 36], [37, 44], [45, 56], [57, 58], [58, 66], [66, 67], [67, 71], [71, 72], [72, 73], [74, 79], [80, 83], [84, 86], [87, 95], [96, 98], [99, 106], [107, 114], [115, 121], [122, 124], [125, 126], [127, 132], [133, 144], [145, 146], [146, 155], [156, 158], [159, 162], [163, 170], [171, 180], [180, 181], [181, 182]]}
{"doc_key": "ai-test-306", "ner": [[2, 3, "person"], [5, 6, "person"], [8, 13, "person"], [15, 16, "person"], [18, 18, "misc"], [22, 22, "misc"], [24, 25, "person"], [31, 31, "organisation"], [27, 28, "person"], [33, 33, "organisation"], [35, 38, "person"], [39, 39, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[24, 25, 18, 18, "part-of", "", false, false], [24, 25, 22, 22, "role", "", false, false], [27, 28, 31, 31, "role", "", false, false], [35, 38, 33, 33, "role", "youtuber", false, false], [39, 39, 35, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Returning", "judges", "Fon", "Davis", ",", "Jessica", "Chobot", "and", "Leland", "Melvin", "will", "be", "joined", "by", "actor", "Clark", "Gregg", ",", "MythBusters", "host", "and", "former", "Battlebots", "builder", "Adam", "Savage", ",", "Vernon", "Davis", "from", "the", "NFL", "and", "YouTube", "star", "Michael", "Stevens", ",", "aka", "Vsauce", "."], "sentence-detokenized": "Returning judges Fon Davis, Jessica Chobot and Leland Melvin will be joined by actor Clark Gregg, MythBusters host and former Battlebots builder Adam Savage, Vernon Davis from the NFL and YouTube star Michael Stevens, aka Vsauce.", "token2charspan": [[0, 9], [10, 16], [17, 20], [21, 26], [26, 27], [28, 35], [36, 42], [43, 46], [47, 53], [54, 60], [61, 65], [66, 68], [69, 75], [76, 78], [79, 84], [85, 90], [91, 96], [96, 97], [98, 109], [110, 114], [115, 118], [119, 125], [126, 136], [137, 144], [145, 149], [150, 156], [156, 157], [158, 164], [165, 170], [171, 175], [176, 179], [180, 183], [184, 187], [188, 195], [196, 200], [201, 208], [209, 216], [216, 217], [218, 221], [222, 228], [228, 229]]}
{"doc_key": "ai-test-307", "ner": [[12, 12, "algorithm"], [13, 18, "algorithm"], [20, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 20, 27, "part-of", "", false, false], [13, 18, 20, 27, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "these", "methods", "have", "never", "overcome", "the", "technology", "of", "non-uniform", "internal", "Gaussian", "mixture", "model", "/", "Hidden", "Markov", "Model", "(", "GMM", "-", "HMM", ")", "modelling", ",", "which", "is", "based", "on", "generative", "models", "of", "speech", "trained", "in", "a", "discriminative", "way", "."], "sentence-detokenized": "However, these methods have never overcome the technology of non-uniform internal Gaussian mixture model/Hidden Markov Model (GMM-HMM) modelling, which is based on generative models of speech trained in a discriminative way.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 22], [23, 27], [28, 33], [34, 42], [43, 46], [47, 57], [58, 60], [61, 72], [73, 81], [82, 90], [91, 98], [99, 104], [104, 105], [105, 111], [112, 118], [119, 124], [125, 126], [126, 129], [129, 130], [130, 133], [133, 134], [135, 144], [144, 145], [146, 151], [152, 154], [155, 160], [161, 163], [164, 174], [175, 181], [182, 184], [185, 191], [192, 199], [200, 202], [203, 204], [205, 219], [220, 223], [223, 224]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "and", "SciPy", "provide", "convenient", "ways", "to", "use", "these", "different", "methods", "."], "sentence-detokenized": "Software packages such as MATLAB, GNU Octave, Scilab and SciPy provide convenient ways to use these different methods.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [53, 56], [57, 62], [63, 70], [71, 81], [82, 86], [87, 89], [90, 93], [94, 99], [100, 109], [110, 117], [117, 118]]}
{"doc_key": "ai-test-309", "ner": [[5, 7, "algorithm"], [9, 9, "algorithm"], [2, 2, "task"], [18, 19, "researcher"], [21, 22, "university"], [24, 25, "researcher"], [27, 30, "organisation"], [32, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[5, 7, 2, 2, "related-to", "", false, false], [5, 7, 18, 19, "origin", "", false, false], [5, 7, 24, 25, "origin", "", false, false], [9, 9, 5, 7, "named", "", false, false], [18, 19, 21, 22, "physical", "", false, false], [18, 19, 21, 22, "role", "", false, false], [24, 25, 27, 30, "physical", "", false, false], [24, 25, 27, 30, "role", "", false, false], [32, 32, 27, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "speech", "processing", "algorithm", ",", "Linear", "Predictive", "Coding", "(", "LPC", ")", ",", "was", "first", "proposed", "in", "1966", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "."], "sentence-detokenized": "The speech processing algorithm, Linear Predictive Coding (LPC), was first proposed in 1966 by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT).", "token2charspan": [[0, 3], [4, 10], [11, 21], [22, 31], [31, 32], [33, 39], [40, 50], [51, 57], [58, 59], [59, 62], [62, 63], [63, 64], [65, 68], [69, 74], [75, 83], [84, 86], [87, 91], [92, 94], [95, 103], [104, 111], [112, 114], [115, 121], [122, 132], [133, 136], [137, 142], [143, 148], [149, 151], [152, 158], [159, 168], [169, 172], [173, 182], [183, 184], [184, 187], [187, 188], [188, 189]]}
{"doc_key": "ai-test-310", "ner": [[20, 27, "conference"], [29, 29, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[29, 29, 20, 27, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2006", ",", "on", "the", "occasion", "of", "the", "25th", "anniversary", "of", "the", "algorithm", ",", "a", "workshop", "was", "organised", "at", "the", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", ",", "which", "summarised", "the", "latest", "contributions", "and", "versions", "of", "the", "original", "algorithm", ",", "mainly", "aimed", "at", "improving", "the", "speed", "of", "the", "algorithm", ",", "the", "robustness", "and", "accuracy", "of", "the", "estimated", "solution", ",", "and", "reducing", "the", "dependence", "on", "user", "-", "defined", "constants", "."], "sentence-detokenized": "In 2006, on the occasion of the 25th anniversary of the algorithm, a workshop was organised at the International Conference on Computer Vision and Pattern Recognition (CVPR), which summarised the latest contributions and versions of the original algorithm, mainly aimed at improving the speed of the algorithm, the robustness and accuracy of the estimated solution, and reducing the dependence on user-defined constants.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 24], [25, 27], [28, 31], [32, 36], [37, 48], [49, 51], [52, 55], [56, 65], [65, 66], [67, 68], [69, 77], [78, 81], [82, 91], [92, 94], [95, 98], [99, 112], [113, 123], [124, 126], [127, 135], [136, 142], [143, 146], [147, 154], [155, 166], [167, 168], [168, 172], [172, 173], [173, 174], [175, 180], [181, 191], [192, 195], [196, 202], [203, 216], [217, 220], [221, 229], [230, 232], [233, 236], [237, 245], [246, 255], [255, 256], [257, 263], [264, 269], [270, 272], [273, 282], [283, 286], [287, 292], [293, 295], [296, 299], [300, 309], [309, 310], [311, 314], [315, 325], [326, 329], [330, 338], [339, 341], [342, 345], [346, 355], [356, 364], [364, 365], [366, 369], [370, 378], [379, 382], [383, 393], [394, 396], [397, 401], [401, 402], [402, 409], [410, 419], [419, 420]]}
{"doc_key": "ai-test-311", "ner": [[4, 6, "university"], [9, 12, "organisation"], [14, 16, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Members", "have", "attended", "the", "University", "of", "Debrecen", ",", "the", "Hungarian", "Academy", "of", "Sciences", ",", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "University", ",", "etc", "."], "sentence-detokenized": "Members have attended the University of Debrecen, the Hungarian Academy of Sciences, E\u00f6tv\u00f6s Lor\u00e1nd University, etc.", "token2charspan": [[0, 7], [8, 12], [13, 21], [22, 25], [26, 36], [37, 39], [40, 48], [48, 49], [50, 53], [54, 63], [64, 71], [72, 74], [75, 83], [83, 84], [85, 91], [92, 98], [99, 109], [109, 110], [111, 114], [114, 115]]}
{"doc_key": "ai-test-312", "ner": [[3, 3, "algorithm"], [16, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 16, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "extend", "the", "SVM", "to", "cases", "where", "the", "data", "are", "not", "linearly", "separable", ",", "we", "introduce", "a", "loss", "function", ","], "sentence-detokenized": "To extend the SVM to cases where the data are not linearly separable, we introduce a loss function,", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 17], [18, 20], [21, 26], [27, 32], [33, 36], [37, 41], [42, 45], [46, 49], [50, 58], [59, 68], [68, 69], [70, 72], [73, 82], [83, 84], [85, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-313", "ner": [[0, 0, "programlang"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 10, 11, "origin", "", false, false], [0, 0, 13, 14, "origin", "", false, false], [0, 0, 16, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "is", "an", "educational", "programming", "language", "designed", "in", "1967", "by", "Wally", "Feurzeig", ",", "Seymour", "Papert", "and", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo is an educational programming language designed in 1967 by Wally Feurzeig, Seymour Papert and Cynthia Solomon.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 34], [35, 43], [44, 52], [53, 55], [56, 60], [61, 63], [64, 69], [70, 78], [78, 79], [80, 87], [88, 94], [95, 98], [99, 106], [107, 114], [114, 115]]}
{"doc_key": "ai-test-314", "ner": [[0, 4, "organisation"], [8, 12, "organisation"], [14, 17, "location"], [19, 19, "location"], [21, 23, "location"], [26, 34, "product"], [37, 41, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 4, 8, 12, "role", "works_for", false, false], [8, 12, 14, 17, "physical", "", false, false], [14, 17, 19, 19, "physical", "", false, false], [19, 19, 21, 23, "physical", "", false, false], [26, 34, 0, 4, "origin", "", false, false], [37, 41, 26, 34, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "Eyring", "Research", "Institute", "was", "instrumental", "in", "the", "US", "Air", "Force", "Missile", "Directorate", "at", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", ",", "which", "produced", "the", "software", "for", "the", "intelligent", "systems", "technology", "that", "was", "the", "foundation", "of", "Reagan", "'s", "Star", "Wars", "programme", "in", "strict", "military", "secrecy", "."], "sentence-detokenized": "The Eyring Research Institute was instrumental in the US Air Force Missile Directorate at Hill Air Force Base near Ogden, Utah, which produced the software for the intelligent systems technology that was the foundation of Reagan's Star Wars programme in strict military secrecy.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 29], [30, 33], [34, 46], [47, 49], [50, 53], [54, 56], [57, 60], [61, 66], [67, 74], [75, 86], [87, 89], [90, 94], [95, 98], [99, 104], [105, 109], [110, 114], [115, 120], [120, 121], [122, 126], [126, 127], [128, 133], [134, 142], [143, 146], [147, 155], [156, 159], [160, 163], [164, 175], [176, 183], [184, 194], [195, 199], [200, 203], [204, 207], [208, 218], [219, 221], [222, 228], [228, 230], [231, 235], [236, 240], [241, 250], [251, 253], [254, 260], [261, 269], [270, 277], [277, 278]]}
{"doc_key": "ai-test-315", "ner": [[12, 15, "field"], [23, 26, "researcher"], [28, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Over", "the", "decades", ",", "he", "has", "researched", "and", "developed", "new", "areas", "of", "computer", "science", ",", "from", "compilers", ",", "programming", "languages", "and", "system", "architecture", "John", "F", ".", "Sowa", "and", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "Over the decades, he has researched and developed new areas of computer science, from compilers, programming languages and system architecture John F. Sowa and John Zachman (1992).", "token2charspan": [[0, 4], [5, 8], [9, 16], [16, 17], [18, 20], [21, 24], [25, 35], [36, 39], [40, 49], [50, 53], [54, 59], [60, 62], [63, 71], [72, 79], [79, 80], [81, 85], [86, 95], [95, 96], [97, 108], [109, 118], [119, 122], [123, 129], [130, 142], [143, 147], [148, 149], [149, 150], [151, 155], [156, 159], [160, 164], [165, 172], [173, 174], [174, 178], [178, 179], [179, 180]]}
{"doc_key": "ai-test-316", "ner": [[0, 2, "algorithm"], [7, 10, "algorithm"], [12, 15, "algorithm"], [18, 19, "field"], [21, 24, "field"], [26, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 10, 0, 2, "named", "", false, false], [12, 15, 0, 2, "named", "", false, false], [18, 19, 0, 2, "usage", "", false, false], [21, 24, 0, 2, "usage", "", false, false], [26, 30, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Sobel", "operator", ",", "sometimes", "called", "the", "Sobel", "-", "Feldman", "operator", "or", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "especially", "in", "edge", "detection", "algorithms", ",", "where", "it", "produces", "an", "image", "with", "highlighted", "edges", "."], "sentence-detokenized": "The Sobel operator, sometimes called the Sobel-Feldman operator or Sobel filter, is used in image processing and computer vision, especially in edge detection algorithms, where it produces an image with highlighted edges.", "token2charspan": [[0, 3], [4, 9], [10, 18], [18, 19], [20, 29], [30, 36], [37, 40], [41, 46], [46, 47], [47, 54], [55, 63], [64, 66], [67, 72], [73, 79], [79, 80], [81, 83], [84, 88], [89, 91], [92, 97], [98, 108], [109, 112], [113, 121], [122, 128], [128, 129], [130, 140], [141, 143], [144, 148], [149, 158], [159, 169], [169, 170], [171, 176], [177, 179], [180, 188], [189, 191], [192, 197], [198, 202], [203, 214], [215, 220], [220, 221]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [3, 4, "field"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 4, "compare", "", false, false], [0, 0, 3, 4, "type-of", "", false, false], [0, 0, 12, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "is", "a", "supervised", "learning", "algorithm", "that", "uses", "data", "labels", ",", "while", "PCA", "is", "a", "label", "-", "free", "learning", "algorithm", "."], "sentence-detokenized": "LDA is a supervised learning algorithm that uses data labels, while PCA is a label-free learning algorithm.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 19], [20, 28], [29, 38], [39, 43], [44, 48], [49, 53], [54, 60], [60, 61], [62, 67], [68, 71], [72, 74], [75, 76], [77, 82], [82, 83], [83, 87], [88, 96], [97, 106], [106, 107]]}
{"doc_key": "ai-test-318", "ner": [[6, 6, "algorithm"], [8, 10, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "algorithms", "for", "linear", "classification", "are", "Winnow", ",", "support", "vector", "machine", "and", "logistic", "regression", "."], "sentence-detokenized": "Other algorithms for linear classification are Winnow, support vector machine and logistic regression.", "token2charspan": [[0, 5], [6, 16], [17, 20], [21, 27], [28, 42], [43, 46], [47, 53], [53, 54], [55, 62], [63, 69], [70, 77], [78, 81], [82, 90], [91, 101], [101, 102]]}
{"doc_key": "ai-test-319", "ner": [[0, 2, "product"], [6, 7, "programlang"], [16, 18, "product"], [20, 20, "programlang"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 6, 7, "general-affiliation", "", true, false], [0, 2, 16, 18, "general-affiliation", "", true, false], [0, 2, 20, 20, "general-affiliation", "", true, false], [0, 2, 22, 22, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "consists", "of", "a", "library", "of", "C", "++", "classes", "and", "several", "interpreted", "interface", "layers", ",", "including", "Tcl", "/", "Tk", ",", "Java", "and", "Python", "."], "sentence-detokenized": "VTK consists of a library of C++ classes and several interpreted interface layers, including Tcl/Tk, Java and Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 17], [18, 25], [26, 28], [29, 30], [30, 32], [33, 40], [41, 44], [45, 52], [53, 64], [65, 74], [75, 81], [81, 82], [83, 92], [93, 96], [96, 97], [97, 99], [99, 100], [101, 105], [106, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-test-320", "ner": [[7, 9, "task"], [16, 19, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Text", "produced", "by", "processing", "spontaneous", "speech", "with", "automatic", "speech", "recognition", "and", "printed", "or", "handwritten", "text", "with", "optical", "character", "recognition", "also", "contains", "processing", "noise", "."], "sentence-detokenized": "Text produced by processing spontaneous speech with automatic speech recognition and printed or handwritten text with optical character recognition also contains processing noise.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 27], [28, 39], [40, 46], [47, 51], [52, 61], [62, 68], [69, 80], [81, 84], [85, 92], [93, 95], [96, 107], [108, 112], [113, 117], [118, 125], [126, 135], [136, 147], [148, 152], [153, 161], [162, 172], [173, 178], [178, 179]]}
{"doc_key": "ai-test-321", "ner": [[0, 1, "researcher"], [10, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 10, 12, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "has", "written", "several", "books", "and", "led", "the", "development", "of", "WordNet", ",", "an", "online", "database", "of", "word", "links", "that", "can", "be", "used", "by", "computer", "programs", "."], "sentence-detokenized": "Miller has written several books and led the development of WordNet, an online database of word links that can be used by computer programs.", "token2charspan": [[0, 6], [7, 10], [11, 18], [19, 26], [27, 32], [33, 36], [37, 40], [41, 44], [45, 56], [57, 59], [60, 67], [67, 68], [69, 71], [72, 78], [79, 87], [88, 90], [91, 95], [96, 101], [102, 106], [107, 110], [111, 113], [114, 118], [119, 121], [122, 130], [131, 139], [139, 140]]}
{"doc_key": "ai-test-322", "ner": [[1, 1, "field"], [7, 9, "organisation"], [12, 13, "country"], [15, 16, "person"], [18, 20, "person"], [22, 23, "person"], [25, 26, "person"], [29, 30, "country"], [32, 35, "location"], [36, 38, "misc"], [39, 40, "person"], [42, 43, "person"], [45, 45, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[7, 9, 12, 13, "physical", "", false, false], [15, 16, 29, 30, "physical", "", false, false], [18, 20, 29, 30, "physical", "", false, false], [22, 23, 29, 30, "physical", "", false, false], [25, 26, 29, 30, "physical", "", false, false], [32, 35, 1, 1, "general-affiliation", "", false, false], [32, 35, 39, 40, "artifact", "", false, false], [36, 38, 39, 40, "named", "", false, false], [42, 43, 45, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Contemporary", "automata", "are", "represented", "by", "works", "by", "Cabaret", "Mechanical", "Theatre", "in", "the", "United", "Kingdom", ",", "Dug", "North", "and", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "in", "the", "United", "States", ",", "Le", "D\u00e9fenseur", "du", "Temps", "by", "French", "artist", "Jacques", "Monestier", "and", "Fran\u00e7ois", "Junod", "in", "Switzerland", "."], "sentence-detokenized": "Contemporary automata are represented by works by Cabaret Mechanical Theatre in the United Kingdom, Dug North and Chomick + Meder, Arthur Ganson, Joe Jones in the United States, Le D\u00e9fenseur du Temps by French artist Jacques Monestier and Fran\u00e7ois Junod in Switzerland.", "token2charspan": [[0, 12], [13, 21], [22, 25], [26, 37], [38, 40], [41, 46], [47, 49], [50, 57], [58, 68], [69, 76], [77, 79], [80, 83], [84, 90], [91, 98], [98, 99], [100, 103], [104, 109], [110, 113], [114, 121], [122, 123], [124, 129], [129, 130], [131, 137], [138, 144], [144, 145], [146, 149], [150, 155], [156, 158], [159, 162], [163, 169], [170, 176], [176, 177], [178, 180], [181, 190], [191, 193], [194, 199], [200, 202], [203, 209], [210, 216], [217, 224], [225, 234], [235, 238], [239, 247], [248, 253], [254, 256], [257, 268], [268, 269]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 22, 22, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "includes", "the", "standard", "codefor", "/", "code", "and", "codewhile", "/", "code", "loops", ",", "but", "(", "as", "in", "other", "similar", "applications", "such", "as", "R", ")", "using", "vector", "notation", "is", "recommended", "and", "often", "faster", "."], "sentence-detokenized": "MATLAB includes the standard codefor/code and codewhile/code loops, but (as in other similar applications such as R) using vector notation is recommended and often faster.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 28], [29, 36], [36, 37], [37, 41], [42, 45], [46, 55], [55, 56], [56, 60], [61, 66], [66, 67], [68, 71], [72, 73], [73, 75], [76, 78], [79, 84], [85, 92], [93, 105], [106, 110], [111, 113], [114, 115], [115, 116], [117, 122], [123, 129], [130, 138], [139, 141], [142, 153], [154, 157], [158, 163], [164, 170], [170, 171]]}
{"doc_key": "ai-test-324", "ner": [[3, 3, "researcher"], [7, 14, "conference"], [17, 19, "field"], [22, 28, "misc"], [31, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 22, 28, "win-defeat", "", false, false], [3, 3, 31, 39, "win-defeat", "", false, false], [22, 28, 7, 14, "temporal", "", false, false], [22, 28, 17, 19, "topic", "", false, false], [31, 39, 7, 14, "temporal", "", false, false], [31, 39, 17, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2007", ",", "Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "for", "his", "achievements", "in", "computer", "science", "education", ":", "the", "Karl", "V", ".", "Karlstrom", "Outstanding", "Educator", "Award", "and", "the", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contribution", "to", "Computing", "Education", "."], "sentence-detokenized": "In 2007, Pausch received two awards from the Association for Computing Machinery for his achievements in computer science education: the Karl V. Karlstrom Outstanding Educator Award and the ACM SIGCSE Award for Outstanding Contribution to Computing Education.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 24], [25, 28], [29, 35], [36, 40], [41, 44], [45, 56], [57, 60], [61, 70], [71, 80], [81, 84], [85, 88], [89, 101], [102, 104], [105, 113], [114, 121], [122, 131], [131, 132], [133, 136], [137, 141], [142, 143], [143, 144], [145, 154], [155, 166], [167, 175], [176, 181], [182, 185], [186, 189], [190, 193], [194, 200], [201, 206], [207, 210], [211, 222], [223, 235], [236, 238], [239, 248], [249, 258], [258, 259]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [8, 13, "product"], [9, 9, "product"], [15, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 13, "role", "sells", false, false], [8, 13, 9, 9, "general-affiliation", "", false, false], [8, 13, 15, 18, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 86], [87, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-test-326", "ner": [[0, 2, "algorithm"], [5, 6, "field"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 2, "usage", "", false, false], [11, 12, 5, 6, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantic", "networks", "are", "used", "in", "natural", "language", "processing", "applications", "such", "as", "semantic", "parsing", "."], "sentence-detokenized": "Semantic networks are used in natural language processing applications such as semantic parsing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 26], [27, 29], [30, 37], [38, 46], [47, 57], [58, 70], [71, 75], [76, 78], [79, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-327", "ner": [[4, 5, "field"], [7, 8, "field"], [10, 11, "task"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 8, 4, 5, "usage", "", false, false], [10, 11, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Some", "successful", "applications", "of", "deep", "learning", "are", "computer", "vision", "and", "speech", "recognition", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Some successful applications of deep learning are computer vision and speech recognition. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 31], [32, 36], [37, 45], [46, 49], [50, 58], [59, 65], [66, 69], [70, 76], [77, 88], [88, 89], [90, 97], [98, 101], [101, 102], [103, 108], [109, 115], [115, 116], [117, 123], [124, 133], [133, 134], [135, 141], [142, 143], [143, 144], [145, 147], [147, 148]]}
{"doc_key": "ai-test-328", "ner": [[5, 10, "product"], [16, 16, "misc"], [19, 19, "misc"], [25, 25, "product"], [29, 30, "task"], [32, 33, "task"], [35, 36, "task"], [38, 40, "field"], [42, 43, "task"], [45, 46, "field"], [48, 49, "task"], [51, 52, "task"], [54, 56, "task"], [58, 59, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[5, 10, 16, 16, "physical", "travels_to", false, false], [5, 10, 19, 19, "physical", "travels_to", false, false], [25, 25, 5, 10, "part-of", "", false, false], [25, 25, 5, 10, "role", "maintains", false, false], [25, 25, 29, 30, "related-to", "has_ability_to", false, false], [25, 25, 32, 33, "related-to", "has_ability_to", false, false], [25, 25, 35, 36, "related-to", "has_ability_to", false, false], [25, 25, 38, 40, "related-to", "has_ability_to", false, false], [25, 25, 42, 43, "related-to", "has_ability_to", false, false], [25, 25, 45, 46, "related-to", "has_ability_to", false, false], [25, 25, 48, 49, "related-to", "has_ability_to", false, false], [25, 25, 51, 52, "related-to", "has_ability_to", false, false], [25, 25, 54, 56, "related-to", "has_ability_to", false, false], [25, 25, 58, 59, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "addition", "to", "maintaining", "the", "systems", "of", "the", "Discovery", "One", "spacecraft", "during", "its", "interplanetary", "mission", "to", "Jupiter", "(", "or", "Saturn", "in", "the", "novel", ")", ",", "HAL", "is", "capable", "of", "speech", "synthesis", ",", "speech", "recognition", ",", "facial", "recognition", ",", "natural", "language", "processing", ",", "lip", "reading", ",", "art", "appreciation", ",", "affective", "computing", ",", "automatic", "reasoning", ",", "piloting", "a", "spacecraft", "and", "playing", "chess", "."], "sentence-detokenized": "In addition to maintaining the systems of the Discovery One spacecraft during its interplanetary mission to Jupiter (or Saturn in the novel), HAL is capable of speech synthesis, speech recognition, facial recognition, natural language processing, lip reading, art appreciation, affective computing, automatic reasoning, piloting a spacecraft and playing chess.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 38], [39, 41], [42, 45], [46, 55], [56, 59], [60, 70], [71, 77], [78, 81], [82, 96], [97, 104], [105, 107], [108, 115], [116, 117], [117, 119], [120, 126], [127, 129], [130, 133], [134, 139], [139, 140], [140, 141], [142, 145], [146, 148], [149, 156], [157, 159], [160, 166], [167, 176], [176, 177], [178, 184], [185, 196], [196, 197], [198, 204], [205, 216], [216, 217], [218, 225], [226, 234], [235, 245], [245, 246], [247, 250], [251, 258], [258, 259], [260, 263], [264, 276], [276, 277], [278, 287], [288, 297], [297, 298], [299, 308], [309, 318], [318, 319], [320, 328], [329, 330], [331, 341], [342, 345], [346, 353], [354, 359], [359, 360]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [4, 4, "country"], [7, 14, "country"], [11, 11, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 4, "physical", "", false, false], [0, 1, 7, 14, "physical", "", false, false], [0, 1, 11, 11, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr", "Julesz", "emigrated", "from", "Hungary", "to", "the", "United", "States", "after", "the", "Soviet", "invasion", "in", "1956", "."], "sentence-detokenized": "Dr Julesz emigrated from Hungary to the United States after the Soviet invasion in 1956.", "token2charspan": [[0, 2], [3, 9], [10, 19], [20, 24], [25, 32], [33, 35], [36, 39], [40, 46], [47, 53], [54, 59], [60, 63], [64, 70], [71, 79], [80, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-test-330", "ner": [[4, 6, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "activation", "functions", "of", "the", "sigmoid", "function", "use", "another", "nonlinearity", "for", "large", "inputs", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+\\", "exp", "(", "-", "v", "_", "i", ")", ")", "^", "{-1}", "/math", "."], "sentence-detokenized": "The activation functions of the sigmoid function use another nonlinearity for large inputs: math\\ phi (v _ i) = (1 +\\ exp (-v _ i)) ^ {-1}/math.", "token2charspan": [[0, 3], [4, 14], [15, 24], [25, 27], [28, 31], [32, 39], [40, 48], [49, 52], [53, 60], [61, 73], [74, 77], [78, 83], [84, 90], [90, 91], [92, 96], [96, 97], [98, 101], [102, 103], [103, 104], [105, 106], [107, 108], [108, 109], [110, 111], [112, 113], [113, 114], [115, 117], [118, 121], [122, 123], [123, 124], [124, 125], [126, 127], [128, 129], [129, 130], [130, 131], [132, 133], [134, 138], [138, 143], [143, 144]]}
{"doc_key": "ai-test-331", "ner": [[10, 12, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "probabilities", "are", "used", "to", "determine", "the", "target", "using", "a", "maximum", "likelihood", "decision", "."], "sentence-detokenized": "These probabilities are used to determine the target using a maximum likelihood decision.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 45], [46, 52], [53, 58], [59, 60], [61, 68], [69, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-332", "ner": [[0, 11, "university"], [12, 14, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "moved", "to", "the", "University", "of", "Konstanz", "in", "1984", "and", "to", "the", "University", "of", "Salzburg", "in", "1990", "."], "sentence-detokenized": "He moved to the University of Konstanz in 1984 and to the University of Salzburg in 1990.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 15], [16, 26], [27, 29], [30, 38], [39, 41], [42, 46], [47, 50], [51, 53], [54, 57], [58, 68], [69, 71], [72, 80], [81, 83], [84, 88], [88, 89]]}
{"doc_key": "ai-test-333", "ner": [[7, 8, "metrics"], [10, 12, "metrics"], [14, 16, "metrics"], [18, 18, "metrics"], [20, 21, "metrics"], [23, 25, "metrics"], [28, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 12, 7, 8, "origin", "based_on", false, false], [14, 16, 7, 8, "origin", "based_on", false, false], [18, 18, 7, 8, "origin", "based_on", false, false], [20, 21, 7, 8, "origin", "based_on", false, false], [23, 25, 7, 8, "origin", "based_on", false, false], [28, 33, 7, 8, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Some", "popular", "suitability", "functions", "based", "on", "the", "confusion", "matrix", "include", "sensitivity", "/", "specificity", ",", "recall", "/", "accuracy", ",", "F-measure", ",", "Jaccard", "similarity", ",", "Matthews", "correlation", "coefficient", "and", "the", "cost", "/", "benefit", "matrix", ",", "which", "combines", "the", "costs", "and", "benefits", "assigned", "to", "4", "different", "types", "of", "classifications", "."], "sentence-detokenized": "Some popular suitability functions based on the confusion matrix include sensitivity/specificity, recall/accuracy, F-measure, Jaccard similarity, Matthews correlation coefficient and the cost/benefit matrix, which combines the costs and benefits assigned to 4 different types of classifications.", "token2charspan": [[0, 4], [5, 12], [13, 24], [25, 34], [35, 40], [41, 43], [44, 47], [48, 57], [58, 64], [65, 72], [73, 84], [84, 85], [85, 96], [96, 97], [98, 104], [104, 105], [105, 113], [113, 114], [115, 124], [124, 125], [126, 133], [134, 144], [144, 145], [146, 154], [155, 166], [167, 178], [179, 182], [183, 186], [187, 191], [191, 192], [192, 199], [200, 206], [206, 207], [208, 213], [214, 222], [223, 226], [227, 232], [233, 236], [237, 245], [246, 254], [255, 257], [258, 259], [260, 269], [270, 275], [276, 278], [279, 294], [294, 295]]}
{"doc_key": "ai-test-334", "ner": [[6, 6, "product"], [8, 8, "product"], [10, 10, "product"], [12, 12, "product"], [15, 16, "programlang"], [25, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[25, 33, 6, 6, "part-of", "", false, false], [25, 33, 8, 8, "part-of", "", false, false], [25, 33, 10, 10, "part-of", "", false, false], [25, 33, 12, 12, "part-of", "", false, false], [25, 33, 15, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Common", "numerical", "programming", "environments", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "and", "the", "R", "language", "allow", "some", "simpler", "feature", "extraction", "techniques", "(", "e.g.", "principal", "component", "analysis", ")", "with", "built", "-", "in", "commands", "."], "sentence-detokenized": "Common numerical programming environments such as MATLAB, SciLab, NumPy, Sklearn and the R language allow some simpler feature extraction techniques (e.g. principal component analysis) with built-in commands.", "token2charspan": [[0, 6], [7, 16], [17, 28], [29, 41], [42, 46], [47, 49], [50, 56], [56, 57], [58, 64], [64, 65], [66, 71], [71, 72], [73, 80], [81, 84], [85, 88], [89, 90], [91, 99], [100, 105], [106, 110], [111, 118], [119, 126], [127, 137], [138, 148], [149, 150], [150, 154], [155, 164], [165, 174], [175, 183], [183, 184], [185, 189], [190, 195], [195, 196], [196, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-335", "ner": [[0, 3, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "have", "been", "introduced", "to", "work", "with", "humans", "in", "industrial", "production", "tasks", "."], "sentence-detokenized": "Industrial robots have been introduced to work with humans in industrial production tasks.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 27], [28, 38], [39, 41], [42, 46], [47, 51], [52, 58], [59, 61], [62, 72], [73, 83], [84, 89], [89, 90]]}
{"doc_key": "ai-test-336", "ner": [[6, 6, "field"], [8, 11, "researcher"], [20, 21, "field"], [23, 24, "field"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 20, 21, "related-to", "", false, false], [6, 6, 23, 24, "related-to", "", false, false], [6, 6, 26, 27, "related-to", "", false, false], [8, 11, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "first", "published", "article", "on", "CG", ",", "John", "F", ".", "Sowa", "applied", "CG", "to", "a", "number", "of", "topics", "in", "artificial", "intelligence", ",", "computer", "science", "and", "cognitive", "science", "."], "sentence-detokenized": "In his first published article on CG, John F. Sowa applied CG to a number of topics in artificial intelligence, computer science and cognitive science.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [23, 30], [31, 33], [34, 36], [36, 37], [38, 42], [43, 44], [44, 45], [46, 50], [51, 58], [59, 61], [62, 64], [65, 66], [67, 73], [74, 76], [77, 83], [84, 86], [87, 97], [98, 110], [110, 111], [112, 120], [121, 128], [129, 132], [133, 142], [143, 150], [150, 151]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [4, 4, "metrics"], [10, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "in", "the", "calculation", "of", "the", "brevity", "penalty", ",", "as", "small", "differences", "in", "translation", "length", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from BLEU in the calculation of the brevity penalty, as small differences in translation length do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 46], [47, 49], [50, 53], [54, 61], [62, 69], [69, 70], [71, 73], [74, 79], [80, 91], [92, 94], [95, 106], [107, 113], [114, 116], [117, 120], [121, 127], [128, 131], [132, 139], [140, 145], [146, 148], [149, 153], [153, 154]]}
{"doc_key": "ai-test-338", "ner": [[0, 4, "misc"], [12, 12, "conference"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 12, 12, "temporal", "", false, false], [0, 4, 18, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "IJCAI", "Research", "Excellence", "Award", "is", "a", "bi-annual", "award", "presented", "at", "the", "IJCAI", "conference", "to", "AI", "researchers", "in", "recognition", "of", "excellence", "in", "their", "careers", "."], "sentence-detokenized": "The IJCAI Research Excellence Award is a bi-annual award presented at the IJCAI conference to AI researchers in recognition of excellence in their careers.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 29], [30, 35], [36, 38], [39, 40], [41, 50], [51, 56], [57, 66], [67, 69], [70, 73], [74, 79], [80, 90], [91, 93], [94, 96], [97, 108], [109, 111], [112, 123], [124, 126], [127, 137], [138, 140], [141, 146], [147, 154], [154, 155]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [6, 9, "conference"], [17, 23, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 9, "role", "", false, false], [0, 0, 17, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "was", "one", "of", "the", "first", "AAAI", "Fellows", "and", "is", "the", "only", "individual", "to", "serve", "on", "the", "scientific", "advisory", "boards", "of", "Microsoft", "and", "Apple", "."], "sentence-detokenized": "Lenat was one of the first AAAI Fellows and is the only individual to serve on the scientific advisory boards of Microsoft and Apple.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 16], [17, 20], [21, 26], [27, 31], [32, 39], [40, 43], [44, 46], [47, 50], [51, 55], [56, 66], [67, 69], [70, 75], [76, 78], [79, 82], [83, 93], [94, 102], [103, 109], [110, 112], [113, 122], [123, 126], [127, 132], [132, 133]]}
{"doc_key": "ai-test-340", "ner": [[0, 0, "algorithm"], [5, 6, "misc"], [10, 16, "metrics"], [20, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "related-to", "minimise", false, false], [10, 16, 5, 6, "type-of", "", false, false], [20, 20, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoders", "are", "trained", "to", "reduce", "reconstruction", "errors", "(", "such", "as", "root", "mean", "square", "error", ")", ",", "often", "referred", "to", "as", "loss", ":"], "sentence-detokenized": "Autoencoders are trained to reduce reconstruction errors (such as root mean square error), often referred to as loss:", "token2charspan": [[0, 12], [13, 16], [17, 24], [25, 27], [28, 34], [35, 49], [50, 56], [57, 58], [58, 62], [63, 65], [66, 70], [71, 75], [76, 82], [83, 88], [88, 89], [89, 90], [91, 96], [97, 105], [106, 108], [109, 111], [112, 116], [116, 117]]}
{"doc_key": "ai-test-341", "ner": [[28, 31, "misc"], [33, 33, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[33, 33, 28, 31, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "to", "using", "definitions", "is", "to", "consider", "the", "general", "similarity", "of", "word", "meanings", "and", "calculate", "the", "similarity", "of", "each", "pair", "of", "word", "meanings", "based", "on", "a", "given", "lexical", "knowledge", "base", "such", "as", "WordNet", "."], "sentence-detokenized": "An alternative to using definitions is to consider the general similarity of word meanings and calculate the similarity of each pair of word meanings based on a given lexical knowledge base such as WordNet.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 23], [24, 35], [36, 38], [39, 41], [42, 50], [51, 54], [55, 62], [63, 73], [74, 76], [77, 81], [82, 90], [91, 94], [95, 104], [105, 108], [109, 119], [120, 122], [123, 127], [128, 132], [133, 135], [136, 140], [141, 149], [150, 155], [156, 158], [159, 160], [161, 166], [167, 174], [175, 184], [185, 189], [190, 194], [195, 197], [198, 205], [205, 206]]}
{"doc_key": "ai-test-342", "ner": [[0, 2, "algorithm"], [9, 13, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 13, "origin", "", false, false], [9, 13, 17, 18, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "invented", "by", "Richard", "S.", "Sutton", "based", "on", "earlier", "work", "by", "Arthur", "Samuel", "on", "time", "-", "difference", "learning", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm invented by Richard S. Sutton based on earlier work by Arthur Samuel on time-difference learning.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 42], [43, 45], [46, 53], [54, 56], [57, 63], [64, 69], [70, 72], [73, 80], [81, 85], [86, 88], [89, 95], [96, 102], [103, 105], [106, 110], [110, 111], [111, 121], [122, 130], [130, 131]]}
{"doc_key": "ai-test-343", "ner": [[1, 2, "field"], [4, 4, "field"], [6, 7, "task"], [11, 13, "task"], [15, 15, "task"], [19, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 1, 2, "part-of", "task_part_of_field", false, false], [6, 7, 4, 4, "part-of", "task_part_of_field", false, false], [11, 13, 6, 7, "named", "", false, false], [15, 15, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "data", "mining", "and", "statistics", ",", "hierarchical", "clustering", "(", "also", "called", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "cluster", "analysis", "method", "that", "aims", "to", "build", "a", "hierarchy", "of", "clusters", "."], "sentence-detokenized": "In data mining and statistics, hierarchical clustering (also called hierarchical cluster analysis or HCA) is a cluster analysis method that aims to build a hierarchy of clusters.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 29], [29, 30], [31, 43], [44, 54], [55, 56], [56, 60], [61, 67], [68, 80], [81, 88], [89, 97], [98, 100], [101, 104], [104, 105], [106, 108], [109, 110], [111, 118], [119, 127], [128, 134], [135, 139], [140, 144], [145, 147], [148, 153], [154, 155], [156, 165], [166, 168], [169, 177], [177, 178]]}
{"doc_key": "ai-test-344", "ner": [[3, 3, "algorithm"], [8, 11, "field"], [10, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "concept", "of", "deconvolution", "is", "widely", "used", "in", "signal", "and", "image", "processing", "techniques", "."], "sentence-detokenized": "The concept of deconvolution is widely used in signal and image processing techniques.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 53], [54, 57], [58, 63], [64, 74], [75, 85], [85, 86]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [16, 17, "misc"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 16, 17, "related-to", "enhances", false, false], [0, 1, 16, 17, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "serve", "to", "build", "and", "accumulate", "spatial", "knowledge", "by", "allowing", "visualisation", "of", "images", "to", "reduce", "cognitive", "load", "and", "improve", "information", "retrieval", "and", "learning", "."], "sentence-detokenized": "Cognitive maps serve to build and accumulate spatial knowledge by allowing visualisation of images to reduce cognitive load and improve information retrieval and learning.", "token2charspan": [[0, 9], [10, 14], [15, 20], [21, 23], [24, 29], [30, 33], [34, 44], [45, 52], [53, 62], [63, 65], [66, 74], [75, 88], [89, 91], [92, 98], [99, 101], [102, 108], [109, 118], [119, 123], [124, 127], [128, 135], [136, 147], [148, 157], [158, 161], [162, 170], [170, 171]]}
{"doc_key": "ai-test-346", "ner": [[9, 9, "programlang"], [11, 12, "programlang"], [14, 14, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "which", "usually", "provides", "bindings", "for", "languages", "such", "as", "Python", ",", "C", "++", ",", "Java", ")", "."], "sentence-detokenized": ", which usually provides bindings for languages such as Python, C++, Java).", "token2charspan": [[0, 1], [2, 7], [8, 15], [16, 24], [25, 33], [34, 37], [38, 47], [48, 52], [53, 55], [56, 62], [62, 63], [64, 65], [65, 67], [67, 68], [69, 73], [73, 74], [74, 75]]}
{"doc_key": "ai-test-347", "ner": [[0, 3, "product"], [5, 5, "product"], [18, 20, "task"], [25, 36, "task"], [31, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 18, 20, "usage", "", false, false], [0, 3, 25, 36, "usage", "", false, false], [0, 3, 31, 40, "usage", "", false, false], [5, 5, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "Voice", "User", "Interface", "(", "VUI", ")", "enables", "speech", "interaction", "between", "a", "human", "and", "a", "computer", ",", "using", "speech", "recognition", "to", "understand", "spoken", "commands", "and", "answer", "questions", ",", "and", "usually", "using", "text", "-", "to", "-", "speech", "to", "play", "back", "the", "answer", "."], "sentence-detokenized": "A Voice User Interface (VUI) enables speech interaction between a human and a computer, using speech recognition to understand spoken commands and answer questions, and usually using text-to-speech to play back the answer.", "token2charspan": [[0, 1], [2, 7], [8, 12], [13, 22], [23, 24], [24, 27], [27, 28], [29, 36], [37, 43], [44, 55], [56, 63], [64, 65], [66, 71], [72, 75], [76, 77], [78, 86], [86, 87], [88, 93], [94, 100], [101, 112], [113, 115], [116, 126], [127, 133], [134, 142], [143, 146], [147, 153], [154, 163], [163, 164], [165, 168], [169, 176], [177, 182], [183, 187], [187, 188], [188, 190], [190, 191], [191, 197], [198, 200], [201, 205], [206, 210], [211, 214], [215, 221], [221, 222]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 4, "misc"], [7, 7, "programlang"], [11, 14, "researcher"], [16, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 4, "general-affiliation", "is_a", false, false], [0, 0, 7, 7, "general-affiliation", "made_with", false, false], [0, 0, 11, 14, "origin", "", false, false], [11, 14, 16, 17, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Jess", "is", "a", "rule", "engine", "for", "the", "Java", "platform", "developed", "by", "Ernest", "Friedman", "-", "Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "Jess is a rule engine for the Java platform developed by Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 14], [15, 21], [22, 25], [26, 29], [30, 34], [35, 43], [44, 53], [54, 56], [57, 63], [64, 72], [72, 73], [73, 77], [78, 80], [81, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-349", "ner": [[1, 4, "algorithm"], [16, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 4, 16, 19, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "multi-layer", "perceptrons", ",", "where", "there", "is", "a", "hidden", "layer", ",", "more", "complex", "algorithms", "such", "as", "backpropagation", "must", "be", "used", "."], "sentence-detokenized": "For multi-layer perceptrons, where there is a hidden layer, more complex algorithms such as backpropagation must be used.", "token2charspan": [[0, 3], [4, 15], [16, 27], [27, 28], [29, 34], [35, 40], [41, 43], [44, 45], [46, 52], [53, 58], [58, 59], [60, 64], [65, 72], [73, 83], [84, 88], [89, 91], [92, 107], [108, 112], [113, 115], [116, 120], [120, 121]]}
{"doc_key": "ai-test-350", "ner": [[0, 0, "product"], [2, 6, "product"], [10, 18, "algorithm"], [22, 23, "field"], [27, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 6, 0, 0, "part-of", "", false, false], [2, 6, 10, 18, "usage", "", false, true], [10, 18, 22, 23, "related-to", "performs", false, false], [27, 33, 22, 23, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "Translate", "'s", "machine", "translation", "neural", "system", "uses", "a", "large", "end", "-", "to", "-", "end", "artificial", "neural", "network", "that", "attempts", "to", "perform", "deep", "learning", ",", "in", "particular", "networks", "with", "long", "short", "-", "term", "memory", "."], "sentence-detokenized": "Google Translate's machine translation neural system uses a large end-to-end artificial neural network that attempts to perform deep learning, in particular networks with long short-term memory.", "token2charspan": [[0, 6], [7, 16], [16, 18], [19, 26], [27, 38], [39, 45], [46, 52], [53, 57], [58, 59], [60, 65], [66, 69], [69, 70], [70, 72], [72, 73], [73, 76], [77, 87], [88, 94], [95, 102], [103, 107], [108, 116], [117, 119], [120, 127], [128, 132], [133, 141], [141, 142], [143, 145], [146, 156], [157, 165], [166, 170], [171, 175], [176, 181], [181, 182], [182, 186], [187, 193], [193, 194]]}
{"doc_key": "ai-test-351", "ner": [[7, 7, "researcher"], [9, 9, "researcher"], [11, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "1980s", "and", "early", "1990s", ",", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "and", "others", "developed", "various", "methods", "for", "doing", "this", "."], "sentence-detokenized": "In the 1980s and early 1990s, Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter and others developed various methods for doing this.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 16], [17, 22], [23, 28], [28, 29], [30, 36], [36, 37], [38, 46], [46, 47], [48, 56], [56, 57], [58, 64], [65, 76], [76, 77], [78, 82], [83, 93], [93, 94], [95, 106], [107, 110], [111, 117], [118, 127], [128, 135], [136, 143], [144, 147], [148, 153], [154, 158], [158, 159]]}
{"doc_key": "ai-test-352", "ner": [[1, 1, "organisation"], [2, 4, "organisation"], [9, 9, "organisation"], [19, 20, "task"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 9, 9, "role", "licenses_from", false, false], [2, 4, 1, 1, "named", "", false, false], [15, 16, 1, 1, "origin", "", false, false], [15, 16, 19, 20, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc.", "originally", "licensed", "the", "software", "from", "Nuance", "to", "give", "its", "digital", "assistant", "Siri", "the", "ability", "to", "recognise", "speech", "."], "sentence-detokenized": "| Apple Apple Inc. originally licensed the software from Nuance to give its digital assistant Siri the ability to recognise speech.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 18], [19, 29], [30, 38], [39, 42], [43, 51], [52, 56], [57, 63], [64, 66], [67, 71], [72, 75], [76, 83], [84, 93], [94, 98], [99, 102], [103, 110], [111, 113], [114, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [4, 6, "misc"], [8, 10, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "role", "releases_movies_in_genre", false, false], [8, 10, 0, 0, "role", "directs_for", false, false], [13, 14, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "has", "released", "several", "3D", "westerns", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia has released several 3D westerns produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 29], [30, 32], [33, 41], [42, 50], [51, 53], [54, 57], [58, 65], [66, 69], [70, 78], [79, 81], [82, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-test-354", "ner": [[9, 10, "field"], [12, 12, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "integrates", "knowledge", "and", "research", "in", "the", "fields", "of", "computer", "science", ",", "linguistics", "and", "computer", "engineering", "."], "sentence-detokenized": "It integrates knowledge and research in the fields of computer science, linguistics and computer engineering.", "token2charspan": [[0, 2], [3, 13], [14, 23], [24, 27], [28, 36], [37, 39], [40, 43], [44, 50], [51, 53], [54, 62], [63, 70], [70, 71], [72, 83], [84, 87], [88, 96], [97, 108], [108, 109]]}
{"doc_key": "ai-test-355", "ner": [[5, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", "is", "an", "example", "of", "R", "code", ":"], "sentence-detokenized": "Here is an example of R code:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 23], [24, 28], [28, 29]]}
{"doc_key": "ai-test-356", "ner": [[0, 5, "metrics"], [11, 13, "metrics"], [15, 15, "metrics"], [19, 28, "metrics"], [23, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 11, 13, "part-of", "plotted_into", false, false], [0, 5, 19, 28, "part-of", "plotted_into", false, false], [15, 15, 11, 13, "named", "", false, false], [23, 23, 19, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "ROC", "curve", "is", "generated", "by", "plotting", "the", "ratio", "between", "the", "true", "positive", "rate", "(", "TPR", ")", "and", "the", "false", "positive", "rate", "(", "FPR", ")", "at", "different", "threshold", "settings", "."], "sentence-detokenized": "The ROC curve is generated by plotting the ratio between the true positive rate (TPR) and the false positive rate (FPR) at different threshold settings.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 26], [27, 29], [30, 38], [39, 42], [43, 48], [49, 56], [57, 60], [61, 65], [66, 74], [75, 79], [80, 81], [81, 84], [84, 85], [86, 89], [90, 93], [94, 99], [100, 108], [109, 113], [114, 115], [115, 118], [118, 119], [120, 122], [123, 132], [133, 142], [143, 151], [151, 152]]}
{"doc_key": "ai-test-357", "ner": [[2, 3, "field"], [6, 7, "researcher"], [9, 10, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 2, 3, "related-to", "researches_field", false, false], [9, 10, 2, 3, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["After", "the", "machine", "learning", "research", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", ",", "research", "came", "to", "a", "standstill", ","], "sentence-detokenized": "After the machine learning research of Marvin Minsky and Seymour Papert (1969), research came to a standstill,", "token2charspan": [[0, 5], [6, 9], [10, 17], [18, 26], [27, 35], [36, 38], [39, 45], [46, 52], [53, 56], [57, 64], [65, 71], [72, 73], [73, 77], [77, 78], [78, 79], [80, 88], [89, 93], [94, 96], [97, 98], [99, 109], [109, 110]]}
{"doc_key": "ai-test-358", "ner": [[6, 6, "task"], [9, 10, "programlang"], [12, 14, "product"], [16, 17, "programlang"], [19, 19, "product"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 9, 10, "related-to", "used_to_build", false, false], [6, 6, 12, 14, "related-to", "used_to_build", false, false], [6, 6, 16, 17, "related-to", "used_to_build", false, false], [6, 6, 19, 19, "related-to", "used_to_build", false, false], [6, 6, 21, 21, "related-to", "used_to_build", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "programming", "environments", "used", "to", "build", "DAQ", "applications", "include", "ladder", "logic", ",", "Visual", "C", "++", ",", "Visual", "Basic", ",", "LabVIEW", "and", "MATLAB", "."], "sentence-detokenized": "Other programming environments used to build DAQ applications include ladder logic, Visual C++, Visual Basic, LabVIEW and MATLAB.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 38], [39, 44], [45, 48], [49, 61], [62, 69], [70, 76], [77, 82], [82, 83], [84, 90], [91, 92], [92, 94], [94, 95], [96, 102], [103, 108], [108, 109], [110, 117], [118, 121], [122, 128], [128, 129]]}
{"doc_key": "ai-test-359", "ner": [[15, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "metric", "has", "been", "designed", "to", "overcome", "some", "of", "the", "problems", "of", "the", "more", "popular", "BLEU", "metric", "and", "provides", "a", "good", "correlation", "with", "human", "judgement", "at", "sentence", "or", "segment", "level", "."], "sentence-detokenized": "The metric has been designed to overcome some of the problems of the more popular BLEU metric and provides a good correlation with human judgement at sentence or segment level.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 19], [20, 28], [29, 31], [32, 40], [41, 45], [46, 48], [49, 52], [53, 61], [62, 64], [65, 68], [69, 73], [74, 81], [82, 86], [87, 93], [94, 97], [98, 106], [107, 108], [109, 113], [114, 125], [126, 130], [131, 136], [137, 146], [147, 149], [150, 158], [159, 161], [162, 169], [170, 175], [175, 176]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "-", "term", "memory", "are", "often", "used", "to", "exploit", "semantic", "correlations", "between", "successive", "video", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long-term memory are often used to exploit semantic correlations between successive video frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [82, 83], [83, 87], [88, 94], [95, 98], [99, 104], [105, 109], [110, 112], [113, 120], [121, 129], [130, 142], [143, 150], [151, 161], [162, 167], [168, 174], [174, 175]]}
{"doc_key": "ai-test-361", "ner": [[6, 6, "product"], [7, 7, "product"], [14, 19, "product"], [22, 25, "product"], [39, 42, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 14, 19, "artifact", "", false, false], [6, 6, 39, 42, "named", "", false, false], [7, 7, 6, 6, "named", "", false, false], [22, 25, 14, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Mass", "-", "produced", "printed", "circuit", "boards", "(", "PCBs", ")", "are", "almost", "exclusively", "manufactured", "by", "pick", "-", "and", "-", "place", "robots", ",", "usually", "SCARA", "manipulators", ",", "which", "remove", "small", "electronic", "components", "from", "tapes", "or", "trays", "and", "place", "them", "onto", "the", "PCB", "with", "great", "precision", "."], "sentence-detokenized": "Mass-produced printed circuit boards (PCBs) are almost exclusively manufactured by pick-and-place robots, usually SCARA manipulators, which remove small electronic components from tapes or trays and place them onto the PCB with great precision.", "token2charspan": [[0, 4], [4, 5], [5, 13], [14, 21], [22, 29], [30, 36], [37, 38], [38, 42], [42, 43], [44, 47], [48, 54], [55, 66], [67, 79], [80, 82], [83, 87], [87, 88], [88, 91], [91, 92], [92, 97], [98, 104], [104, 105], [106, 113], [114, 119], [120, 132], [132, 133], [134, 139], [140, 146], [147, 152], [153, 163], [164, 174], [175, 179], [180, 185], [186, 188], [189, 194], [195, 198], [199, 204], [205, 209], [210, 214], [215, 218], [219, 222], [223, 227], [228, 233], [234, 243], [243, 244]]}
{"doc_key": "ai-test-362", "ner": [[4, 9, "field"], [15, 15, "algorithm"], [22, 23, "researcher"], [25, 26, "researcher"], [28, 32, "researcher"], [36, 37, "algorithm"], [40, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 4, 9, "part-of", "", false, false], [15, 15, 22, 23, "origin", "", false, false], [15, 15, 25, 26, "origin", "", false, false], [15, 15, 28, 32, "origin", "", false, false], [15, 15, 36, 37, "type-of", "", false, false], [36, 37, 40, 40, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "context", "of", "machine", "learning", ",", "where", "it", "is", "most", "commonly", "used", "today", ",", "LDA", "was", "independently", "rediscovered", "in", "2003", "by", "David", "Blei", ",", "Andrew", "Ng", "and", "Michael", "I", ".", "Jordan", "and", "presented", "as", "a", "graphical", "model", "for", "topic", "discovery", "."], "sentence-detokenized": "In the context of machine learning, where it is most commonly used today, LDA was independently rediscovered in 2003 by David Blei, Andrew Ng and Michael I. Jordan and presented as a graphical model for topic discovery.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 25], [26, 34], [34, 35], [36, 41], [42, 44], [45, 47], [48, 52], [53, 61], [62, 66], [67, 72], [72, 73], [74, 77], [78, 81], [82, 95], [96, 108], [109, 111], [112, 116], [117, 119], [120, 125], [126, 130], [130, 131], [132, 138], [139, 141], [142, 145], [146, 153], [154, 155], [155, 156], [157, 163], [164, 167], [168, 177], [178, 180], [181, 182], [183, 192], [193, 198], [199, 202], [203, 208], [209, 218], [218, 219]]}
{"doc_key": "ai-test-363", "ner": [[10, 11, "task"], [13, 14, "misc"], [20, 20, "metrics"], [22, 22, "metrics"], [24, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 11, 13, 14, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "measured", "performance", "on", "the", "test", "data", "of", "eight", "na\u00efve", "WSIs", "for", "different", "tauopathies", "was", "0.92", ",", "0.72", "and", "0.81", "recall", ",", "precision", "and", "F1", "-", "score", ",", "respectively", "."], "sentence-detokenized": "The measured performance on the test data of eight na\u00efve WSIs for different tauopathies was 0.92, 0.72 and 0.81 recall, precision and F1-score, respectively.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 27], [28, 31], [32, 36], [37, 41], [42, 44], [45, 50], [51, 56], [57, 61], [62, 65], [66, 75], [76, 87], [88, 91], [92, 96], [96, 97], [98, 102], [103, 106], [107, 111], [112, 118], [118, 119], [120, 129], [130, 133], [134, 136], [136, 137], [137, 142], [142, 143], [144, 156], [156, 157]]}
{"doc_key": "ai-test-364", "ner": [[1, 4, "field"], [6, 7, "field"], [10, 10, "field"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 4, 10, 10, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Advanced", "AR", "technologies", "(", "e.g.", "adding", "computer", "vision", ",", "embedding", "AR", "cameras", "in", "smartphones", "and", "object", "recognition", ")", "make", "information", "about", "the", "real", "world", "around", "the", "user", "interactive", "and", "digitally", "manipulated", "."], "sentence-detokenized": "Advanced AR technologies (e.g. adding computer vision, embedding AR cameras in smartphones and object recognition) make information about the real world around the user interactive and digitally manipulated.", "token2charspan": [[0, 8], [9, 11], [12, 24], [25, 26], [26, 30], [31, 37], [38, 46], [47, 53], [53, 54], [55, 64], [65, 67], [68, 75], [76, 78], [79, 90], [91, 94], [95, 101], [102, 113], [113, 114], [115, 119], [120, 131], [132, 137], [138, 141], [142, 146], [147, 152], [153, 159], [160, 163], [164, 168], [169, 180], [181, 184], [185, 194], [195, 206], [206, 207]]}
{"doc_key": "ai-test-365", "ner": [[3, 3, "researcher"], [5, 5, "organisation"], [15, 16, "field"], [25, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 5, 5, "role", "forms_company", false, false], [5, 5, 15, 16, "related-to", "works_with", false, false], [5, 5, 25, 27, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2014", ",", "Schmidhuber", "founded", "Nnaisense", ",", "a", "company", "focused", "on", "the", "commercial", "application", "of", "AI", "in", "areas", "such", "as", "finance", ",", "heavy", "industry", "and", "self", "-", "driving", "cars", "."], "sentence-detokenized": "In 2014, Schmidhuber founded Nnaisense, a company focused on the commercial application of AI in areas such as finance, heavy industry and self-driving cars.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 28], [29, 38], [38, 39], [40, 41], [42, 49], [50, 57], [58, 60], [61, 64], [65, 75], [76, 87], [88, 90], [91, 93], [94, 96], [97, 102], [103, 107], [108, 110], [111, 118], [118, 119], [120, 125], [126, 134], [135, 138], [139, 143], [143, 144], [144, 151], [152, 156], [156, 157]]}
{"doc_key": "ai-test-366", "ner": [[24, 28, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "not", "only", "changes", "the", "performance", "of", "all", "subsequent", "tests", "on", "the", "retained", "explanatory", "model", ",", "but", "may", "also", "introduce", "bias", "and", "change", "the", "root", "mean", "square", "error", "of", "the", "estimation", "."], "sentence-detokenized": "This not only changes the performance of all subsequent tests on the retained explanatory model, but may also introduce bias and change the root mean square error of the estimation.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 21], [22, 25], [26, 37], [38, 40], [41, 44], [45, 55], [56, 61], [62, 64], [65, 68], [69, 77], [78, 89], [90, 95], [95, 96], [97, 100], [101, 104], [105, 109], [110, 119], [120, 124], [125, 128], [129, 135], [136, 139], [140, 144], [145, 149], [150, 156], [157, 162], [163, 165], [166, 169], [170, 180], [180, 181]]}
{"doc_key": "ai-test-367", "ner": [[0, 0, "misc"], [6, 6, "algorithm"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 0, 0, "usage", "", false, false], [6, 6, 9, 10, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Bigrams", "are", "used", "in", "most", "successful", "language", "models", "for", "speech", "recognition", "."], "sentence-detokenized": "Bigrams are used in most successful language models for speech recognition.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 24], [25, 35], [36, 44], [45, 51], [52, 55], [56, 62], [63, 74], [74, 75]]}
{"doc_key": "ai-test-368", "ner": [[3, 5, "field"], [9, 11, "misc"], [17, 19, "misc"], [23, 27, "organisation"], [30, 32, "misc"], [37, 41, "organisation"], [44, 46, "misc"], [51, 54, "organisation"], [57, 59, "misc"], [64, 68, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[9, 11, 3, 5, "topic", "", false, false], [17, 19, 23, 27, "origin", "", false, false], [30, 32, 37, 41, "origin", "", false, false], [44, 46, 51, 54, "origin", "", false, false], [57, 59, 64, 68, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["His", "research", "in", "cognitive", "psychology", "has", "been", "awarded", "the", "Early", "Career", "Award", "(", "1984", ")", "and", "the", "Boyd", "McCandless", "Award", "(", "1986", ")", "of", "the", "American", "Psychological", "Association", ",", "the", "Troland", "Research", "Award", "(", "1993", ")", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "Henry", "Dale", "Award", "(", "2004", ")", "of", "the", "British", "Royal", "Institute", "and", "the", "George", "Miller", "Award", "(", "2010", ")", "of", "the", "Society", "for", "Cognitive", "Neuroscience", "."], "sentence-detokenized": "His research in cognitive psychology has been awarded the Early Career Award (1984) and the Boyd McCandless Award (1986) of the American Psychological Association, the Troland Research Award (1993) of the National Academy of Sciences, the Henry Dale Award (2004) of the British Royal Institute and the George Miller Award (2010) of the Society for Cognitive Neuroscience.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 25], [26, 36], [37, 40], [41, 45], [46, 53], [54, 57], [58, 63], [64, 70], [71, 76], [77, 78], [78, 82], [82, 83], [84, 87], [88, 91], [92, 96], [97, 107], [108, 113], [114, 115], [115, 119], [119, 120], [121, 123], [124, 127], [128, 136], [137, 150], [151, 162], [162, 163], [164, 167], [168, 175], [176, 184], [185, 190], [191, 192], [192, 196], [196, 197], [198, 200], [201, 204], [205, 213], [214, 221], [222, 224], [225, 233], [233, 234], [235, 238], [239, 244], [245, 249], [250, 255], [256, 257], [257, 261], [261, 262], [263, 265], [266, 269], [270, 277], [278, 283], [284, 293], [294, 297], [298, 301], [302, 308], [309, 315], [316, 321], [322, 323], [323, 327], [327, 328], [329, 331], [332, 335], [336, 343], [344, 347], [348, 357], [358, 370], [370, 371]]}
{"doc_key": "ai-test-369", "ner": [[0, 0, "misc"], [6, 6, "misc"], [8, 12, "product"], [13, 13, "researcher"], [15, 15, "researcher"], [25, 26, "researcher"], [28, 29, "researcher"], [22, 24, "task"], [31, 34, "researcher"], [36, 40, "researcher"], [41, 42, "task"], [44, 44, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[0, 0, 6, 6, "named", "", false, false], [0, 0, 44, 44, "named", "", false, false], [6, 6, 13, 13, "origin", "", false, false], [6, 6, 15, 15, "origin", "", false, false], [6, 6, 22, 24, "related-to", "used_for", false, false], [8, 12, 6, 6, "usage", "", false, false], [8, 12, 41, 42, "named", "", false, false], [25, 26, 6, 6, "usage", "", false, false], [25, 26, 31, 34, "named", "same", false, false], [28, 29, 6, 6, "usage", "", false, false], [28, 29, 36, 40, "named", "same", false, false], [41, 42, 44, 44, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Eigenface", "(", "The", "approach", "of", "using", "eigenfaces", "for", "face", "recognition", "was", "developed", "by", "Sirovich", "and", "Kirby", "(", "1987", ")", "and", "applied", "to", "face", "classification", "by", "Matthew", "Turk", "and", "Alex", "Pentland", ".", "Turk", ",", "Matthew", "A", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "Eigenface (The approach of using eigenfaces for face recognition was developed by Sirovich and Kirby (1987) and applied to face classification by Matthew Turk and Alex Pentland. Turk, Matthew A and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 9], [10, 11], [11, 14], [15, 23], [24, 26], [27, 32], [33, 43], [44, 47], [48, 52], [53, 64], [65, 68], [69, 78], [79, 81], [82, 90], [91, 94], [95, 100], [101, 102], [102, 106], [106, 107], [108, 111], [112, 119], [120, 122], [123, 127], [128, 142], [143, 145], [146, 153], [154, 158], [159, 162], [163, 167], [168, 176], [176, 177], [178, 182], [182, 183], [184, 191], [192, 193], [194, 197], [198, 206], [206, 207], [208, 212], [213, 214], [214, 215], [216, 220], [221, 232], [233, 238], [239, 249], [249, 250]]}
{"doc_key": "ai-test-370", "ner": [[5, 13, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "lexical", "dictionary", "such", "as", "Word", "Net", "can", "be", "used", "to", "understand", "the", "context", "."], "sentence-detokenized": "A lexical dictionary such as WordNet can be used to understand the context.", "token2charspan": [[0, 1], [2, 9], [10, 20], [21, 25], [26, 28], [29, 33], [33, 36], [37, 40], [41, 43], [44, 48], [49, 51], [52, 62], [63, 66], [67, 74], [74, 75]]}
{"doc_key": "ai-test-371", "ner": [[0, 0, "misc"], [8, 10, "misc"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 10, "part-of", "", false, false], [8, 10, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hyponymy", "is", "the", "most", "commonly", "encoded", "relationship", "between", "synsets", "used", "in", "lexical", "databases", "such", "as", "WordNet", "."], "sentence-detokenized": "Hyponymy is the most commonly encoded relationship between synsets used in lexical databases such as WordNet.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 20], [21, 29], [30, 37], [38, 50], [51, 58], [59, 66], [67, 71], [72, 74], [75, 82], [83, 92], [93, 97], [98, 100], [101, 108], [108, 109]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [6, 7, "programlang"], [9, 11, "programlang"], [41, 42, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 7, "general-affiliation", "", false, false], [0, 0, 9, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "provides", "open", "source", "libraries", "in", "C", "++", "and", "Java", ",", "but", "many", "clients", "rely", "on", "community", "-", "developed", "libraries", ",", "such", "as", "those", "that", "include", "built", "-", "in", "capabilities", "to", "extract", "data", "(", "in", "the", "form", "of", "fields", ")", "from", "DAP", "servers", "."], "sentence-detokenized": "OPeNDAP provides open source libraries in C++ and Java, but many clients rely on community-developed libraries, such as those that include built-in capabilities to extract data (in the form of fields) from DAP servers.", "token2charspan": [[0, 7], [8, 16], [17, 21], [22, 28], [29, 38], [39, 41], [42, 43], [43, 45], [46, 49], [50, 54], [54, 55], [56, 59], [60, 64], [65, 72], [73, 77], [78, 80], [81, 90], [90, 91], [91, 100], [101, 110], [110, 111], [112, 116], [117, 119], [120, 125], [126, 130], [131, 138], [139, 144], [144, 145], [145, 147], [148, 160], [161, 163], [164, 171], [172, 176], [177, 178], [178, 180], [181, 184], [185, 189], [190, 192], [193, 199], [199, 200], [201, 205], [206, 209], [210, 217], [217, 218]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [7, 7, "product"], [16, 16, "country"], [28, 29, "misc"], [43, 43, "product"], [45, 46, "organisation"], [47, 51, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6, 7], "relations": [[4, 5, 16, 16, "opposite", "", false, false], [7, 7, 16, 16, "artifact", "", false, false], [28, 29, 7, 7, "part-of", "", false, false], [47, 51, 45, 46, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4], "sentence": ["On", "this", "page", ",", "Samurai", "Damashii", "exaggerated", "Senkousha", "as", "the", "crystallisation", "of", "four", "thousand", "years", "of", "Chinese", "scientific", "knowledge", ",", "commented", "on", "the", "crude", "form", "(", "e.g.", "the", "Chinese", "cannon", "on", "the", "crotch", ")", "and", "placed", "his", "image", "between", "images", "of", "Honda", "'s", "ASIMO", "and", "Sony", "'s", "QRIO", "SDR", "-", "3", "X", "for", "comparison", "."], "sentence-detokenized": "On this page, Samurai Damashii exaggerated Senkousha as the crystallisation of four thousand years of Chinese scientific knowledge, commented on the crude form (e.g. the Chinese cannon on the crotch) and placed his image between images of Honda's ASIMO and Sony's QRIO SDR-3X for comparison.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 21], [22, 30], [31, 42], [43, 52], [53, 55], [56, 59], [60, 75], [76, 78], [79, 83], [84, 92], [93, 98], [99, 101], [102, 109], [110, 120], [121, 130], [130, 131], [132, 141], [142, 144], [145, 148], [149, 154], [155, 159], [160, 161], [161, 165], [166, 169], [170, 177], [178, 184], [185, 187], [188, 191], [192, 198], [198, 199], [200, 203], [204, 210], [211, 214], [215, 220], [221, 228], [229, 235], [236, 238], [239, 244], [244, 246], [247, 252], [253, 256], [257, 261], [261, 263], [264, 268], [269, 272], [272, 273], [273, 274], [274, 275], [276, 279], [280, 290], [290, 291]]}
{"doc_key": "ai-test-374", "ner": [[8, 13, "algorithm"], [22, 22, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 13, 22, 22, "part-of", "includes_functionality_of", false, false], [8, 13, 24, 24, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "also", "many", "software", "libraries", "that", "contain", "neural", "network", "functionalities", "and", "can", "be", "used", "in", "their", "own", "implementations", "(", "such", "as", "TensorFlow", ",", "Theano", ",", "etc", "."], "sentence-detokenized": "There are also many software libraries that contain neural network functionalities and can be used in their own implementations (such as TensorFlow, Theano, etc.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 28], [29, 38], [39, 43], [44, 51], [52, 58], [59, 66], [67, 82], [83, 86], [87, 90], [91, 93], [94, 98], [99, 101], [102, 107], [108, 111], [112, 127], [128, 129], [129, 133], [134, 136], [137, 147], [147, 148], [149, 155], [155, 156], [157, 160], [160, 161]]}
{"doc_key": "ai-test-375", "ner": [[5, 9, "conference"], [11, 11, "organisation"], [13, 19, "conference"], [21, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", "and", "SPIE", "."], "sentence-detokenized": "He is a member of the Association for Computing Machinery, IEEE, American Association for the Advancement of Science, IAPR and SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 33], [34, 37], [38, 47], [48, 57], [57, 58], [59, 63], [63, 64], [65, 73], [74, 85], [86, 89], [90, 93], [94, 105], [106, 108], [109, 116], [116, 117], [118, 122], [123, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-376", "ner": [[5, 6, "organisation"], [10, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 10, 11, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "experiment", "carried", "out", "by", "the", "RET", "in", "2011", "with", "facial", "recognition", "cameras", "installed", "on", "trams", "ensured", "that", "people", "banned", "from", "riding", "the", "city", "'s", "trams", "did", "not", "sneak", "in", "."], "sentence-detokenized": "An experiment carried out by the RET in 2011 with facial recognition cameras installed on trams ensured that people banned from riding the city's trams did not sneak in.", "token2charspan": [[0, 2], [3, 13], [14, 21], [22, 25], [26, 28], [29, 32], [33, 36], [37, 39], [40, 44], [45, 49], [50, 56], [57, 68], [69, 76], [77, 86], [87, 89], [90, 95], [96, 103], [104, 108], [109, 115], [116, 122], [123, 127], [128, 134], [135, 138], [139, 143], [143, 145], [146, 151], [152, 155], [156, 159], [160, 165], [166, 168], [168, 169]]}
{"doc_key": "ai-test-377", "ner": [[6, 8, "person"], [4, 4, "organisation"], [15, 16, "person"], [18, 19, "person"], [22, 23, "person"], [25, 26, "person"], [28, 29, "person"], [31, 32, "person"], [34, 35, "person"], [37, 38, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[6, 8, 4, 4, "role", "works_for", false, false], [15, 16, 4, 4, "role", "works_for", false, false], [18, 19, 4, 4, "role", "works_for", false, false], [22, 23, 4, 4, "role", "works_for", false, false], [25, 26, 4, 4, "role", "works_for", false, false], [28, 29, 4, 4, "role", "works_for", false, false], [31, 32, 4, 4, "role", "works_for", false, false], [34, 35, 4, 4, "role", "works_for", false, false], [37, 38, 4, 4, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Adapted", "from", "the", "popular", "Broadway", "musical", "by", "Cole", "Porter", ",", "the", "film", "stars", "MGM", "singers", "Howard", "Keel", "and", "Kathryn", "Grayson", ",", "with", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "and", "Tommy", "Rall", "."], "sentence-detokenized": "Adapted from the popular Broadway musical by Cole Porter, the film stars MGM singers Howard Keel and Kathryn Grayson, with Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar and Tommy Rall.", "token2charspan": [[0, 7], [8, 12], [13, 16], [17, 24], [25, 33], [34, 41], [42, 44], [45, 49], [50, 56], [56, 57], [58, 61], [62, 66], [67, 72], [73, 76], [77, 84], [85, 91], [92, 96], [97, 100], [101, 108], [109, 116], [116, 117], [118, 122], [123, 126], [127, 133], [133, 134], [135, 141], [142, 146], [146, 147], [148, 153], [154, 157], [157, 158], [159, 164], [165, 173], [173, 174], [175, 179], [180, 187], [188, 191], [192, 197], [198, 202], [202, 203]]}
{"doc_key": "ai-test-378", "ner": [[21, 25, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "applications", "need", "to", "simplify", "call", "flows", ",", "reduce", "the", "number", "of", "prompts", ",", "eliminate", "unnecessary", "iterations", "and", "enable", "a", "complex", "mixed", "-initiative", "dialogue", "system", "that", "allows", "callers", "to", "enter", "multiple", "pieces", "of", "information", "in", "a", "single", "statement", "and", "in", "any", "order", "or", "combination", "."], "sentence-detokenized": "Such applications need to simplify call flows, reduce the number of prompts, eliminate unnecessary iterations and enable a complex mixed-initiative dialogue system that allows callers to enter multiple pieces of information in a single statement and in any order or combination.", "token2charspan": [[0, 4], [5, 17], [18, 22], [23, 25], [26, 34], [35, 39], [40, 45], [45, 46], [47, 53], [54, 57], [58, 64], [65, 67], [68, 75], [75, 76], [77, 86], [87, 98], [99, 109], [110, 113], [114, 120], [121, 122], [123, 130], [131, 136], [136, 147], [148, 156], [157, 163], [164, 168], [169, 175], [176, 183], [184, 186], [187, 192], [193, 201], [202, 208], [209, 211], [212, 223], [224, 226], [227, 228], [229, 235], [236, 245], [246, 249], [250, 252], [253, 256], [257, 262], [263, 265], [266, 277], [277, 278]]}
{"doc_key": "ai-test-379", "ner": [[6, 7, "algorithm"], [10, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 16, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "adapted", "from", "traditional", "gradient", "descent", "(", "or", "stochastic", "gradient", "descent", ")", "methods", ",", "where", "instead", "of", "a", "step", "in", "the", "direction", "of", "the", "gradient", "of", "the", "function", ",", "a", "step", "is", "taken", "in", "the", "direction", "of", "a", "vector", "selected", "from", "the", "subgradient", "of", "the", "function", "."], "sentence-detokenized": "This can be adapted from traditional gradient descent (or stochastic gradient descent) methods, where instead of a step in the direction of the gradient of the function, a step is taken in the direction of a vector selected from the subgradient of the function.", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 19], [20, 24], [25, 36], [37, 45], [46, 53], [54, 55], [55, 57], [58, 68], [69, 77], [78, 85], [85, 86], [87, 94], [94, 95], [96, 101], [102, 109], [110, 112], [113, 114], [115, 119], [120, 122], [123, 126], [127, 136], [137, 139], [140, 143], [144, 152], [153, 155], [156, 159], [160, 168], [168, 169], [170, 171], [172, 176], [177, 179], [180, 185], [186, 188], [189, 192], [193, 202], [203, 205], [206, 207], [208, 214], [215, 223], [224, 228], [229, 232], [233, 244], [245, 247], [248, 251], [252, 260], [260, 261]]}
{"doc_key": "ai-test-380", "ner": [[8, 16, "metrics"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Assuming", "that", "the", "distortion", "is", "measured", "by", "the", "root", "mean", "square", "error", ",", "the", "distortion", "D", "is", "given", "by", ":"], "sentence-detokenized": "Assuming that the distortion is measured by the root mean square error, the distortion D is given by:", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 28], [29, 31], [32, 40], [41, 43], [44, 47], [48, 52], [53, 57], [58, 64], [65, 70], [70, 71], [72, 75], [76, 86], [87, 88], [89, 91], [92, 97], [98, 100], [100, 101]]}
{"doc_key": "ai-test-381", "ner": [[0, 2, "algorithm"], [10, 12, "field"], [17, 18, "task"], [20, 21, "task"], [23, 25, "task"], [27, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 10, 12, "part-of", "", false, false], [17, 18, 0, 2, "part-of", "", false, false], [20, 21, 0, 2, "part-of", "", false, false], [23, 25, 0, 2, "part-of", "", false, false], [27, 28, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["MLPs", "were", "a", "popular", "machine", "learning", "solution", "in", "the", "1980s", ",", "used", "in", "various", "fields", "such", "as", "speech", "recognition", ",", "image", "recognition", "and", "machine", "translation", "software", ",", "neural", "networks", "."], "sentence-detokenized": "MLPs were a popular machine learning solution in the 1980s, used in various fields such as speech recognition, image recognition and machine translation software, neural networks.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 19], [20, 27], [28, 36], [37, 45], [46, 48], [49, 52], [53, 58], [58, 59], [60, 64], [65, 67], [68, 75], [76, 82], [83, 87], [88, 90], [91, 97], [98, 109], [109, 110], [111, 116], [117, 128], [129, 132], [133, 140], [141, 152], [153, 161], [161, 162], [163, 169], [170, 178], [178, 179]]}
{"doc_key": "ai-test-382", "ner": [[0, 1, "researcher"], [2, 3, "misc"], [6, 8, "university"], [15, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 8, "physical", "", false, false], [0, 1, 6, 8, "role", "", false, false], [2, 3, 0, 1, "origin", "", false, false], [15, 17, 0, 1, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "received", "his", "PhD", "from", "the", "University", "of", "Toronto", "in", "1979", "under", "the", "supervision", "of", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen received his PhD from the University of Toronto in 1979 under the supervision of C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 22], [23, 27], [28, 31], [32, 42], [43, 45], [46, 53], [54, 56], [57, 61], [62, 67], [68, 71], [72, 83], [84, 86], [87, 89], [90, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [5, 9, "field"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [20, 21, "product"], [24, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 9, "related-to", "supports", false, false], [10, 10, 5, 9, "type-of", "", true, false], [12, 12, 5, 9, "type-of", "", true, false], [14, 14, 5, 9, "type-of", "", true, false], [14, 14, 20, 21, "related-to", "converting_to", true, false], [24, 28, 5, 9, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["OpenCV", "supports", "some", "models", "from", "deep", "learning", "frameworks", "such", "as", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "after", "conversion", "to", "the", "ONNX", "model", ")", "and", "Caffe", ",", "according", "to", "a", "defined", "list", "of", "supported", "layers", "."], "sentence-detokenized": "OpenCV supports some models from deep learning frameworks such as TensorFlow, Torch, PyTorch (after conversion to the ONNX model) and Caffe, according to a defined list of supported layers.", "token2charspan": [[0, 6], [7, 15], [16, 20], [21, 27], [28, 32], [33, 37], [38, 46], [47, 57], [58, 62], [63, 65], [66, 76], [76, 77], [78, 83], [83, 84], [85, 92], [93, 94], [94, 99], [100, 110], [111, 113], [114, 117], [118, 122], [123, 128], [128, 129], [130, 133], [134, 139], [139, 140], [141, 150], [151, 153], [154, 155], [156, 163], [164, 168], [169, 171], [172, 181], [182, 188], [188, 189]]}
{"doc_key": "ai-test-384", "ner": [[2, 2, "researcher"], [9, 12, "organisation"], [14, 17, "organisation"], [18, 22, "organisation"], [26, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 9, 12, "role", "", false, false], [2, 2, 18, 22, "role", "", false, false], [2, 2, 26, 26, "related-to", "lectures_in", false, false], [14, 17, 9, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Previously", ",", "Christensen", "was", "the", "founding", "chair", "of", "the", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "and", "an", "IEEE", "Robotics", "and", "Automation", "Society", "Distinguished", "Lecturer", "in", "Robotics", "."], "sentence-detokenized": "Previously, Christensen was the founding chair of the European Robotics Research Network (EURON) and an IEEE Robotics and Automation Society Distinguished Lecturer in Robotics.", "token2charspan": [[0, 10], [10, 11], [12, 23], [24, 27], [28, 31], [32, 40], [41, 46], [47, 49], [50, 53], [54, 62], [63, 71], [72, 80], [81, 88], [89, 90], [90, 95], [95, 96], [97, 100], [101, 103], [104, 108], [109, 117], [118, 121], [122, 132], [133, 140], [141, 154], [155, 163], [164, 166], [167, 175], [175, 176]]}
{"doc_key": "ai-test-385", "ner": [[5, 5, "field"], [8, 10, "university"], [12, 12, "location"], [14, 25, "country"], [27, 27, "misc"], [29, 30, "field"], [32, 35, "organisation"], [37, 39, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[8, 10, 12, 12, "physical", "", false, false], [12, 12, 14, 25, "physical", "", false, false], [27, 27, 29, 30, "topic", "", false, false], [32, 35, 37, 39, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "received", "his", "MSc", "in", "mathematics", "from", "the", "Samarkand", "State", "University", ",", "Samarkand", ",", "Uzbekistan", ",", "Soviet", "Socialist", "Republic", "of", "Uzbekistan", ",", "in", "1958", ",", "and", "his", "PhD", "in", "statistics", "from", "the", "Institute", "of", "Control", "Sciences", ",", "Moscow", ",", "in", "1964", "."], "sentence-detokenized": "He received his MSc in mathematics from the Samarkand State University, Samarkand, Uzbekistan, Soviet Socialist Republic of Uzbekistan, in 1958, and his PhD in statistics from the Institute of Control Sciences, Moscow, in 1964.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 19], [20, 22], [23, 34], [35, 39], [40, 43], [44, 53], [54, 59], [60, 70], [70, 71], [72, 81], [81, 82], [83, 93], [93, 94], [95, 101], [102, 111], [112, 120], [121, 123], [124, 134], [134, 135], [136, 138], [139, 143], [143, 144], [145, 148], [149, 152], [153, 156], [157, 159], [160, 170], [171, 175], [176, 179], [180, 189], [190, 192], [193, 200], [201, 209], [209, 210], [211, 217], [217, 218], [219, 221], [222, 226], [226, 227]]}
{"doc_key": "ai-test-386", "ner": [[4, 4, "organisation"], [8, 11, "product"], [29, 30, "field"], [32, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 29, 30, "usage", "", false, false], [4, 4, 32, 34, "usage", "", false, false], [8, 11, 4, 4, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "work", "at", "Cycorp", "is", "increasingly", "about", "Cyc", "being", "able", "to", "communicate", "with", "end-users", "in", "natural", "language", "and", "to", "assist", "in", "the", "ongoing", "process", "of", "knowledge", "creation", "through", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "However, work at Cycorp is increasingly about Cyc being able to communicate with end-users in natural language and to assist in the ongoing process of knowledge creation through machine learning and natural language understanding.", "token2charspan": [[0, 7], [7, 8], [9, 13], [14, 16], [17, 23], [24, 26], [27, 39], [40, 45], [46, 49], [50, 55], [56, 60], [61, 63], [64, 75], [76, 80], [81, 90], [91, 93], [94, 101], [102, 110], [111, 114], [115, 117], [118, 124], [125, 127], [128, 131], [132, 139], [140, 147], [148, 150], [151, 160], [161, 169], [170, 177], [178, 185], [186, 194], [195, 198], [199, 206], [207, 215], [216, 229], [229, 230]]}
{"doc_key": "ai-test-387", "ner": [[53, 53, "metrics"], [55, 55, "metrics"], [57, 57, "metrics"], [59, 62, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "if", "we", "are", "looking", "for", "the", "best", "classifier", "for", "a", "problem", ",", "the", "training", "dataset", "is", "used", "to", "learn", "candidate", "algorithms", ",", "the", "validation", "dataset", "is", "used", "to", "compare", "their", "performance", "and", "decide", "which", "algorithm", "to", "choose", ",", "and", "the", "testing", "dataset", "is", "used", "to", "obtain", "performance", "characteristics", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", ",", "F-", "measure", ",", "etc", "."], "sentence-detokenized": "For example, if we are looking for the best classifier for a problem, the training dataset is used to learn candidate algorithms, the validation dataset is used to compare their performance and decide which algorithm to choose, and the testing dataset is used to obtain performance characteristics such as accuracy, sensitivity, specificity, F-measure, etc.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 18], [19, 22], [23, 30], [31, 34], [35, 38], [39, 43], [44, 54], [55, 58], [59, 60], [61, 68], [68, 69], [70, 73], [74, 82], [83, 90], [91, 93], [94, 98], [99, 101], [102, 107], [108, 117], [118, 128], [128, 129], [130, 133], [134, 144], [145, 152], [153, 155], [156, 160], [161, 163], [164, 171], [172, 177], [178, 189], [190, 193], [194, 200], [201, 206], [207, 216], [217, 219], [220, 226], [226, 227], [228, 231], [232, 235], [236, 243], [244, 251], [252, 254], [255, 259], [260, 262], [263, 269], [270, 281], [282, 297], [298, 302], [303, 305], [306, 314], [314, 315], [316, 327], [327, 328], [329, 340], [340, 341], [342, 344], [344, 351], [351, 352], [353, 356], [356, 357]]}
{"doc_key": "ai-test-388", "ner": [[0, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "root", "mean", "square", "error", "is", "0.15", "."], "sentence-detokenized": "The root mean square error is 0.15.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 20], [21, 26], [27, 29], [30, 34], [34, 35]]}
{"doc_key": "ai-test-389", "ner": [[7, 12, "misc"], [4, 4, "organisation"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 7, 12, "role", "", false, false], [15, 16, 7, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1979", ",", "the", "IEEE", "organised", "a", "competition", "for", "micromixers", ",", "which", "was", "featured", "in", "Spectrum", "magazine", "."], "sentence-detokenized": "In 1979, the IEEE organised a competition for micromixers, which was featured in Spectrum magazine.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 27], [28, 29], [30, 41], [42, 45], [46, 57], [57, 58], [59, 64], [65, 68], [69, 77], [78, 80], [81, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-390", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [11, 13, "task"], [15, 16, "task"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 7, "part-of", "", false, false], [11, 13, 6, 7, "part-of", "task_part_of_field", false, false], [15, 16, 6, 7, "part-of", "task_part_of_field", false, false], [18, 19, 6, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Gabor", "space", "is", "very", "useful", "in", "image", "processing", "applications", "such", "as", "optical", "character", "recognition", ",", "iris", "recognition", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "Gabor space is very useful in image processing applications such as optical character recognition, iris recognition and fingerprint recognition.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 19], [20, 26], [27, 29], [30, 35], [36, 46], [47, 59], [60, 64], [65, 67], [68, 75], [76, 85], [86, 97], [97, 98], [99, 103], [104, 115], [116, 119], [120, 131], [132, 143], [143, 144]]}
{"doc_key": "ai-test-391", "ner": [[8, 8, "programlang"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "via", "the", "high", "-", "level", "interfaces", "for", "Java", "and", "Tcl", "."], "sentence-detokenized": "or via the high-level interfaces for Java and Tcl.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 15], [15, 16], [16, 21], [22, 32], [33, 36], [37, 41], [42, 45], [46, 49], [49, 50]]}
{"doc_key": "ai-test-392", "ner": [[10, 13, "algorithm"], [18, 18, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 13, 18, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "recent", "research", ",", "kernel", "-", "based", "methods", "such", "as", "support", "vector", "machines", "have", "shown", "better", "performance", "in", "supervised", "."], "sentence-detokenized": "In recent research, kernel-based methods such as support vector machines have shown better performance in supervised.", "token2charspan": [[0, 2], [3, 9], [10, 18], [18, 19], [20, 26], [26, 27], [27, 32], [33, 40], [41, 45], [46, 48], [49, 56], [57, 63], [64, 72], [73, 77], [78, 83], [84, 90], [91, 102], [103, 105], [106, 116], [116, 117]]}
{"doc_key": "ai-test-393", "ner": [[14, 14, "misc"], [23, 23, "researcher"], [25, 25, "researcher"], [33, 33, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 33, 33, "usage", "", false, false], [25, 25, 33, 33, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "illustrate", "the", "basic", "principles", "of", "bagging", ",", "an", "analysis", "of", "the", "relationship", "between", "ozone", "and", "temperature", "is", "shown", "below", "(", "data", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "analysis", "done", "in", "R", ")", "."], "sentence-detokenized": "To illustrate the basic principles of bagging, an analysis of the relationship between ozone and temperature is shown below (data from Rousseeuw and Leroy (1986), analysis done in R).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 34], [35, 37], [38, 45], [45, 46], [47, 49], [50, 58], [59, 61], [62, 65], [66, 78], [79, 86], [87, 92], [93, 96], [97, 108], [109, 111], [112, 117], [118, 123], [124, 125], [125, 129], [130, 134], [135, 144], [145, 148], [149, 154], [155, 156], [156, 160], [160, 161], [161, 162], [163, 171], [172, 176], [177, 179], [180, 181], [181, 182], [182, 183]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [11, 11, "product"], [18, 19, "product"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 0, 1, "artifact", "", false, false], [18, 19, 0, 1, "artifact", "", false, false], [21, 23, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Denso", "Wave", "is", "a", "subsidiary", "that", "manufactures", "automatic", "identification", "products", "(", "barcode", "scanners", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "Denso Wave is a subsidiary that manufactures automatic identification products (barcode scanners and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 15], [16, 26], [27, 31], [32, 44], [45, 54], [55, 69], [70, 78], [79, 80], [80, 87], [88, 96], [97, 100], [101, 108], [109, 117], [117, 118], [118, 119], [120, 130], [131, 137], [138, 141], [142, 154], [155, 160], [161, 172], [172, 173]]}
{"doc_key": "ai-test-395", "ner": [[0, 5, "metrics"], [8, 9, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 5, 19, 19, "compare", "", false, false], [8, 9, 0, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "the", "bilingual", "evaluation", "study", "simply", "calculated", "the", "accuracy", "of", "the", "n-grams", "and", "gave", "each", "the", "same", "weight", ",", "NIST", "also", "calculates", "how", "informative", "each", "n-", "gram", "is", "."], "sentence-detokenized": "While the bilingual evaluation study simply calculated the accuracy of the n-grams and gave each the same weight, NIST also calculates how informative each n-gram is.", "token2charspan": [[0, 5], [6, 9], [10, 19], [20, 30], [31, 36], [37, 43], [44, 54], [55, 58], [59, 67], [68, 70], [71, 74], [75, 82], [83, 86], [87, 91], [92, 96], [97, 100], [101, 105], [106, 112], [112, 113], [114, 118], [119, 123], [124, 134], [135, 138], [139, 150], [151, 155], [156, 158], [158, 162], [163, 165], [165, 166]]}
{"doc_key": "ai-test-396", "ner": [[14, 14, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "are", "used", "in", "particular", "to", "calculate", "the", "probability", "of", "a", "tree", "(", "in", "Bayesian", "and", "maximum", "likelihood", "approaches", "to", "tree", "estimation", ")", "and", "to", "estimate", "the", "evolutionary", "distance", "between", "sequences", "based", "on", "observed", "differences", "between", "sequences", "."], "sentence-detokenized": "They are used in particular to calculate the probability of a tree (in Bayesian and maximum likelihood approaches to tree estimation) and to estimate the evolutionary distance between sequences based on observed differences between sequences.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 27], [28, 30], [31, 40], [41, 44], [45, 56], [57, 59], [60, 61], [62, 66], [67, 68], [68, 70], [71, 79], [80, 83], [84, 91], [92, 102], [103, 113], [114, 116], [117, 121], [122, 132], [132, 133], [134, 137], [138, 140], [141, 149], [150, 153], [154, 166], [167, 175], [176, 183], [184, 193], [194, 199], [200, 202], [203, 211], [212, 223], [224, 231], [232, 241], [241, 242]]}
{"doc_key": "ai-test-397", "ner": [[0, 3, "conference"], [20, 21, "misc"], [23, 23, "misc"], [45, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Audio", "Engineering", "Society", "recommends", "a", "sampling", "frequency", "of", "48", "kHz", "for", "most", "applications", ",", "but", "recognises", "44.1", "kHz", "for", "compact", "discs", "(", "CDs", ")", "and", "other", "consumer", "uses", ",", "32", "kHz", "for", "transmission", "-", "related", "applications", "and", "96", "kHz", "for", "higher", "bandwidth", "or", "relaxed", "anti-aliasing", "filters", "."], "sentence-detokenized": "The Audio Engineering Society recommends a sampling frequency of 48 kHz for most applications, but recognises 44.1 kHz for compact discs (CDs) and other consumer uses, 32 kHz for transmission-related applications and 96 kHz for higher bandwidth or relaxed anti-aliasing filters.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 40], [41, 42], [43, 51], [52, 61], [62, 64], [65, 67], [68, 71], [72, 75], [76, 80], [81, 93], [93, 94], [95, 98], [99, 109], [110, 114], [115, 118], [119, 122], [123, 130], [131, 136], [137, 138], [138, 141], [141, 142], [143, 146], [147, 152], [153, 161], [162, 166], [166, 167], [168, 170], [171, 174], [175, 178], [179, 191], [191, 192], [192, 199], [200, 212], [213, 216], [217, 219], [220, 223], [224, 227], [228, 234], [235, 244], [245, 247], [248, 255], [256, 269], [270, 277], [277, 278]]}
{"doc_key": "ai-test-398", "ner": [[9, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Word", "and", "concept", "affectivity", "resources", "have", "been", "prepared", "for", "WordNet", "{", "{", "cite", "journal"], "sentence-detokenized": "Word and concept affectivity resources have been prepared for WordNet {{cite journal", "token2charspan": [[0, 4], [5, 8], [9, 16], [17, 28], [29, 38], [39, 43], [44, 48], [49, 57], [58, 61], [62, 69], [70, 71], [71, 72], [72, 76], [77, 84]]}
{"doc_key": "ai-test-399", "ner": [[10, 13, "misc"], [23, 24, "person"], [29, 34, "person"], [38, 40, "person"], [49, 54, "organisation"], [66, 67, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[29, 34, 38, 40, "role", "acts_in", false, false], [49, 54, 38, 40, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Three", "reels", "of", "test", "shots", "were", "presented", "to", "the", "audience", "in", "red", "-green", "anaglyph", "technique", ",", "including", "rural", "scenes", ",", "test", "shots", "of", "Maria", "Doro", ",", "a", "section", "of", "John", "B", ".", "Mason", ",", "playing", "several", "excerpts", "from", "Jim", "the", "Penman", "(", "a", "film", "released", "the", "same", "year", "by", "Famous", "Players", "-", "Lasky", ",", "but", "not", "in", "3D", ")", ",", "oriental", "dancers", "and", "a", "reel", "of", "Niagara", "Falls", "footage", "."], "sentence-detokenized": "Three reels of test shots were presented to the audience in red-green anaglyph technique, including rural scenes, test shots of Maria Doro, a section of John B. Mason, playing several excerpts from Jim the Penman (a film released the same year by Famous Players-Lasky, but not in 3D), oriental dancers and a reel of Niagara Falls footage.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 19], [20, 25], [26, 30], [31, 40], [41, 43], [44, 47], [48, 56], [57, 59], [60, 63], [63, 69], [70, 78], [79, 88], [88, 89], [90, 99], [100, 105], [106, 112], [112, 113], [114, 118], [119, 124], [125, 127], [128, 133], [134, 138], [138, 139], [140, 141], [142, 149], [150, 152], [153, 157], [158, 159], [159, 160], [161, 166], [166, 167], [168, 175], [176, 183], [184, 192], [193, 197], [198, 201], [202, 205], [206, 212], [213, 214], [214, 215], [216, 220], [221, 229], [230, 233], [234, 238], [239, 243], [244, 246], [247, 253], [254, 261], [261, 262], [262, 267], [267, 268], [269, 272], [273, 276], [277, 279], [280, 282], [282, 283], [283, 284], [285, 293], [294, 301], [302, 305], [306, 307], [308, 312], [313, 315], [316, 323], [324, 329], [330, 337], [337, 338]]}
{"doc_key": "ai-test-400", "ner": [[7, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "special", "way", "of", "performing", "maximum", "likelihood", "estimation", "for", "this", "problem", "."], "sentence-detokenized": "This is a special way of performing maximum likelihood estimation for this problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 17], [18, 21], [22, 24], [25, 35], [36, 43], [44, 54], [55, 65], [66, 69], [70, 74], [75, 82], [82, 83]]}
{"doc_key": "ai-test-401", "ner": [[0, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Browser", "-", "friendly", "web", "servers", ",", "combining", "the", "features", "of", "sitemaps", "and", "RSS", "feeds", "into", "a", "decentralised", "mechanism", "for", "computational", "biologists", "and", "bioinformaticians", "to", "openly", "submit", "and", "retrieve", "metadata", "about", "biomedical", "resources", "."], "sentence-detokenized": "Browser-friendly web servers, combining the features of sitemaps and RSS feeds into a decentralised mechanism for computational biologists and bioinformaticians to openly submit and retrieve metadata about biomedical resources.", "token2charspan": [[0, 7], [7, 8], [8, 16], [17, 20], [21, 28], [28, 29], [30, 39], [40, 43], [44, 52], [53, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 83], [84, 85], [86, 99], [100, 109], [110, 113], [114, 127], [128, 138], [139, 142], [143, 160], [161, 163], [164, 170], [171, 177], [178, 181], [182, 190], [191, 199], [200, 205], [206, 216], [217, 226], [226, 227]]}
{"doc_key": "ai-test-402", "ner": [[5, 12, "misc"], [15, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "covered", "by", "the", "American", "National", "Standards", "Institute", "/", "NISO", "standard", "Z39.50", "and", "the", "International", "Organization", "for", "Standardization", "standard", "23950", "."], "sentence-detokenized": "It is covered by the American National Standards Institute/NISO standard Z39.50 and the International Organization for Standardization standard 23950.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 20], [21, 29], [30, 38], [39, 48], [49, 58], [58, 59], [59, 63], [64, 72], [73, 79], [80, 83], [84, 87], [88, 101], [102, 114], [115, 118], [119, 134], [135, 143], [144, 149], [149, 150]]}
{"doc_key": "ai-test-403", "ner": [[13, 16, "misc"], [21, 22, "metrics"], [24, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "encoder", "and", "decoder", "are", "trained", "to", "take", "a", "phrase", "and", "reproduce", "the", "unique", "distribution", "of", "the", "corresponding", "paraphrase", "by", "reducing", "perplexity", "using", "simple", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The encoder and decoder are trained to take a phrase and reproduce the unique distribution of the corresponding paraphrase by reducing perplexity using simple stochastic gradient descent.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 45], [46, 52], [53, 56], [57, 66], [67, 70], [71, 77], [78, 90], [91, 93], [94, 97], [98, 111], [112, 122], [123, 125], [126, 134], [135, 145], [146, 151], [152, 158], [159, 169], [170, 178], [179, 186], [186, 187]]}
{"doc_key": "ai-test-404", "ner": [[4, 5, "field"], [8, 10, "task"], [12, 16, "task"], [25, 29, "task"], [31, 37, "task"], [39, 45, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 10, 4, 5, "part-of", "task_part_of_field", false, false], [12, 16, 4, 5, "part-of", "task_part_of_field", false, false], [25, 29, 4, 5, "part-of", "task_part_of_field", false, false], [31, 37, 4, 5, "part-of", "task_part_of_field", false, false], [39, 45, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "typical", "applications", "of", "pattern", "recognition", "techniques", "are", "automatic", "speech", "recognition", ",", "text", "classification", "into", "several", "categories", "(", "e.g.", "spam", "/", "junk", "emails", ")", ",", "handwriting", "recognition", "on", "postal", "envelopes", ",", "automatic", "recognition", "of", "images", "of", "human", "faces", "or", "extraction", "of", "handwriting", "images", "from", "medical", "forms", "."], "sentence-detokenized": "Other typical applications of pattern recognition techniques are automatic speech recognition, text classification into several categories (e.g. spam/junk emails), handwriting recognition on postal envelopes, automatic recognition of images of human faces or extraction of handwriting images from medical forms.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 29], [30, 37], [38, 49], [50, 60], [61, 64], [65, 74], [75, 81], [82, 93], [93, 94], [95, 99], [100, 114], [115, 119], [120, 127], [128, 138], [139, 140], [140, 144], [145, 149], [149, 150], [150, 154], [155, 161], [161, 162], [162, 163], [164, 175], [176, 187], [188, 190], [191, 197], [198, 207], [207, 208], [209, 218], [219, 230], [231, 233], [234, 240], [241, 243], [244, 249], [250, 255], [256, 258], [259, 269], [270, 272], [273, 284], [285, 291], [292, 296], [297, 304], [305, 310], [310, 311]]}
{"doc_key": "ai-test-405", "ner": [[0, 6, "algorithm"], [12, 13, "field"], [15, 16, "task"], [18, 19, "task"], [21, 22, "task"], [24, 27, "task"], [30, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 13, 0, 6, "usage", "", false, false], [15, 16, 0, 6, "usage", "", false, false], [18, 19, 0, 6, "usage", "", false, false], [21, 22, 0, 6, "usage", "", false, false], [24, 27, 0, 6, "usage", "", false, false], [30, 31, 0, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Artificial", "neural", "networks", "are", "used", "in", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "filtering", ",", "social", "and", "video", "gaming", ",", "and", "medical", "diagnostics", "."], "sentence-detokenized": "Artificial neural networks are used in a variety of tasks, including computer vision, speech recognition, machine translation, social filtering, social and video gaming, and medical diagnostics.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 30], [31, 35], [36, 38], [39, 40], [41, 48], [49, 51], [52, 57], [57, 58], [59, 68], [69, 77], [78, 84], [84, 85], [86, 92], [93, 104], [104, 105], [106, 113], [114, 125], [125, 126], [127, 133], [134, 143], [143, 144], [145, 151], [152, 155], [156, 161], [162, 168], [168, 169], [170, 173], [174, 181], [182, 193], [193, 194]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [14, 15, "product"], [18, 18, "organisation"], [19, 20, "product"], [22, 22, "product"], [24, 26, "product"], [28, 28, "product"], [30, 30, "programlang"], [35, 39, "field"], [42, 42, "product"], [46, 46, "algorithm"], [48, 48, "algorithm"], [50, 50, "algorithm"], [53, 53, "product"], [61, 61, "task"], [68, 70, "algorithm"], [73, 73, "product"], [75, 75, "product"], [77, 79, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [4, 4, 14, 15, "named", "same", false, false], [4, 4, 42, 42, "named", "same", false, false], [30, 30, 35, 39, "related-to", "used_for", false, false], [46, 46, 30, 30, "part-of", "", true, false], [46, 46, 42, 42, "origin", "", true, false], [48, 48, 30, 30, "part-of", "", true, false], [48, 48, 42, 42, "origin", "", true, false], [50, 50, 30, 30, "part-of", "", true, false], [50, 50, 42, 42, "origin", "", true, false], [53, 53, 61, 61, "related-to", "used_for", false, false], [68, 70, 53, 53, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Examples", "include", "Salford", "Systems", "CART", "(", "which", "licensed", "the", "proprietary", "code", "of", "the", "original", "CART", "authors", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "source", "statistical", "computing", "software", "environment", "that", "includes", "several", "CART", "implementations", "such", "as", "rpart", ",", "party", "and", "randomForest", ")", ",", "Weka", "(", "a", "free", "and", "open", "source", "data", "mining", "package", "that", "contains", "a", "number", "of", "decision", "tree", "algorithms", ")", ",", "Orange", ",", "KNIME", ",", "Microsoft", "SQL", "Server", "programming", "language", ")", "."], "sentence-detokenized": "Examples include Salford Systems CART (which licensed the proprietary code of the original CART authors), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open source statistical computing software environment that includes several CART implementations such as rpart, party and randomForest), Weka (a free and open source data mining package that contains a number of decision tree algorithms), Orange, KNIME, Microsoft SQL Server programming language).", "token2charspan": [[0, 8], [9, 16], [17, 24], [25, 32], [33, 37], [38, 39], [39, 44], [45, 53], [54, 57], [58, 69], [70, 74], [75, 77], [78, 81], [82, 90], [91, 95], [96, 103], [103, 104], [104, 105], [106, 109], [110, 114], [115, 122], [122, 123], [124, 134], [134, 135], [136, 139], [140, 150], [151, 156], [156, 157], [158, 164], [164, 165], [166, 167], [168, 169], [169, 171], [172, 176], [177, 183], [184, 195], [196, 205], [206, 214], [215, 226], [227, 231], [232, 240], [241, 248], [249, 253], [254, 269], [270, 274], [275, 277], [278, 283], [283, 284], [285, 290], [291, 294], [295, 307], [307, 308], [308, 309], [310, 314], [315, 316], [316, 317], [318, 322], [323, 326], [327, 331], [332, 338], [339, 343], [344, 350], [351, 358], [359, 363], [364, 372], [373, 374], [375, 381], [382, 384], [385, 393], [394, 398], [399, 409], [409, 410], [410, 411], [412, 418], [418, 419], [420, 425], [425, 426], [427, 436], [437, 440], [441, 447], [448, 459], [460, 468], [468, 469], [469, 470]]}
{"doc_key": "ai-test-407", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [12, 13, "researcher"], [15, 16, "university"], [18, 19, "researcher"], [21, 24, "organisation"], [26, 29, "organisation"], [33, 35, "researcher"], [37, 39, "researcher"], [41, 44, "organisation"], [56, 65, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 12, 13, "origin", "", false, false], [0, 2, 18, 19, "origin", "", false, false], [0, 2, 33, 35, "origin", "", false, false], [0, 2, 37, 39, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [12, 13, 15, 16, "physical", "", false, false], [12, 13, 15, 16, "role", "", false, false], [18, 19, 21, 24, "physical", "", false, false], [18, 19, 21, 24, "role", "", false, false], [26, 29, 21, 24, "named", "", false, false], [33, 35, 41, 44, "physical", "", false, false], [33, 35, 41, 44, "role", "", false, false], [37, 39, 41, 44, "physical", "", false, false], [37, 39, 41, 44, "role", "", false, false], [56, 65, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Linear", "Predictive", "Coding", "(", "LPC", ")", "was", "first", "developed", "in", "1966", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", ",", "then", "further", "developed", "by", "Bishnu", "S.", "Atal", "and", "Manfred", "R.", "Schroeder", "at", "Bell", "Labs", "in", "the", "early", "and", "mid-1970s", ",", "and", "became", "the", "basis", "of", "the", "first", "DSP", "chips", "for", "a", "speech", "synthesiser", "in", "the", "late", "1970s", "."], "sentence-detokenized": "Linear Predictive Coding (LPC) was first developed in 1966 by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT), then further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs in the early and mid-1970s, and became the basis of the first DSP chips for a speech synthesiser in the late 1970s.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 40], [41, 50], [51, 53], [54, 58], [59, 61], [62, 70], [71, 78], [79, 81], [82, 88], [89, 99], [100, 103], [104, 109], [110, 115], [116, 118], [119, 125], [126, 135], [136, 139], [140, 149], [150, 151], [151, 154], [154, 155], [155, 156], [157, 161], [162, 169], [170, 179], [180, 182], [183, 189], [190, 192], [193, 197], [198, 201], [202, 209], [210, 212], [213, 222], [223, 225], [226, 230], [231, 235], [236, 238], [239, 242], [243, 248], [249, 252], [253, 262], [262, 263], [264, 267], [268, 274], [275, 278], [279, 284], [285, 287], [288, 291], [292, 297], [298, 301], [302, 307], [308, 311], [312, 313], [314, 320], [321, 332], [333, 335], [336, 339], [340, 344], [345, 350], [350, 351]]}
{"doc_key": "ai-test-408", "ner": [[0, 3, "metrics"], [8, 8, "metrics"], [10, 13, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 0, 3, "part-of", "", false, false], [10, 13, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "F", "-", "rating", "is", "a", "combination", "of", "precision", "and", "recall", ",", "representing", "a", "single", "rating", "."], "sentence-detokenized": "The F-rating is a combination of precision and recall, representing a single rating.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 12], [13, 15], [16, 17], [18, 29], [30, 32], [33, 42], [43, 46], [47, 53], [53, 54], [55, 67], [68, 69], [70, 76], [77, 83], [83, 84]]}
{"doc_key": "ai-test-409", "ner": [[0, 1, "field"], [8, 11, "task"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 0, 1, "part-of", "task_part_of_field", false, false], [16, 18, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Image", "analysis", "tasks", "can", "be", "as", "simple", "as", "reading", "barcode", "labels", "or", "as", "complex", "as", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Image analysis tasks can be as simple as reading barcode labels or as complex as a facial recognition system.", "token2charspan": [[0, 5], [6, 14], [15, 20], [21, 24], [25, 27], [28, 30], [31, 37], [38, 40], [41, 48], [49, 56], [57, 63], [64, 66], [67, 69], [70, 77], [78, 80], [81, 82], [83, 89], [90, 101], [102, 108], [108, 109]]}
{"doc_key": "ai-test-410", "ner": [[5, 8, "algorithm"], [26, 27, "algorithm"], [34, 36, "algorithm"], [39, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[34, 36, 26, 27, "type-of", "", false, false], [39, 39, 34, 36, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "special", "case", "of", "linear", "support", "-", "vector", "machines", "can", "be", "solved", "more", "efficiently", "with", "the", "same", "type", "of", "algorithms", "to", "optimise", "its", "close", "relative", ",", "logistic", "regression", ";", "this", "class", "of", "algorithms", "includes", "stochastic", "gradient", "descent", "(", "e.g.", "PEGASOS", ")", "."], "sentence-detokenized": "The special case of linear support-vector machines can be solved more efficiently with the same type of algorithms to optimise its close relative, logistic regression; this class of algorithms includes stochastic gradient descent (e.g. PEGASOS).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 34], [34, 35], [35, 41], [42, 50], [51, 54], [55, 57], [58, 64], [65, 69], [70, 81], [82, 86], [87, 90], [91, 95], [96, 100], [101, 103], [104, 114], [115, 117], [118, 126], [127, 130], [131, 136], [137, 145], [145, 146], [147, 155], [156, 166], [166, 167], [168, 172], [173, 178], [179, 181], [182, 192], [193, 201], [202, 212], [213, 221], [222, 229], [230, 231], [231, 235], [236, 243], [243, 244], [244, 245]]}
{"doc_key": "ai-test-411", "ner": [[1, 1, "product"], [3, 4, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 3, 4, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["When", "Siri", "on", "iOS", "asks", "if", "you", "have", "a", "pet", ",", "one", "of", "the", "answers", "is", "\"", "I", "used", "to", "have", "an", "AIBA", "\"", "."], "sentence-detokenized": "When Siri on iOS asks if you have a pet, one of the answers is \"I used to have an AIBA\".", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 16], [17, 21], [22, 24], [25, 28], [29, 33], [34, 35], [36, 39], [39, 40], [41, 44], [45, 47], [48, 51], [52, 59], [60, 62], [63, 64], [64, 65], [66, 70], [71, 73], [74, 78], [79, 81], [82, 86], [86, 87], [87, 88]]}
{"doc_key": "ai-test-412", "ner": [[1, 8, "task"], [4, 7, "metrics"], [10, 11, "metrics"], [12, 12, "metrics"], [15, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 7, 1, 8, "part-of", "", false, false], [10, 11, 4, 7, "named", "", false, false], [12, 12, 1, 8, "part-of", "", false, false], [15, 15, 12, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "information", "retrieval", ",", "a", "positive", "predictive", "value", "is", "called", "precision", "and", "sensitivity", "is", "called", "recall", "."], "sentence-detokenized": "In information retrieval, a positive predictive value is called precision and sensitivity is called recall.", "token2charspan": [[0, 2], [3, 14], [15, 24], [24, 25], [26, 27], [28, 36], [37, 47], [48, 53], [54, 56], [57, 63], [64, 73], [74, 77], [78, 89], [90, 92], [93, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-413", "ner": [[10, 11, "field"], [13, 13, "task"], [15, 15, "task"], [17, 20, "task"], [35, 36, "task"], [38, 39, "task"], [41, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 13, 10, 11, "part-of", "task_part_of_field", false, false], [15, 15, 10, 11, "part-of", "task_part_of_field", false, false], [17, 20, 10, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["His", "research", "has", "focused", "in", "particular", "on", "areas", "such", "as", "text", "mining", "(", "extraction", ",", "categorisation", ",", "novelty", "discovery", ")", "and", "on", "new", "theoretical", "frameworks", "such", "as", "a", "unified", "theory", "based", "on", "usability", ",", "integrating", "information", "retrieval", ",", "automatic", "summarisation", ",", "free", "text", "question", "answering", "and", "related", "tasks", "."], "sentence-detokenized": "His research has focused in particular on areas such as text mining (extraction, categorisation, novelty discovery) and on new theoretical frameworks such as a unified theory based on usability, integrating information retrieval, automatic summarisation, free text question answering and related tasks.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 24], [25, 27], [28, 38], [39, 41], [42, 47], [48, 52], [53, 55], [56, 60], [61, 67], [68, 69], [69, 79], [79, 80], [81, 95], [95, 96], [97, 104], [105, 114], [114, 115], [116, 119], [120, 122], [123, 126], [127, 138], [139, 149], [150, 154], [155, 157], [158, 159], [160, 167], [168, 174], [175, 180], [181, 183], [184, 193], [193, 194], [195, 206], [207, 218], [219, 228], [228, 229], [230, 239], [240, 253], [253, 254], [255, 259], [260, 264], [265, 273], [274, 283], [284, 287], [288, 295], [296, 301], [301, 302]]}
{"doc_key": "ai-test-414", "ner": [[0, 1, "product"], [3, 4, "product"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [16, 17, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Delta", "robots", "have", "rotary", "actuators", "mounted", "on", "the", "base", "that", "move", "a", "light", ",", "rigid", ",", "parallelogram", "arm", "."], "sentence-detokenized": "Delta robots have rotary actuators mounted on the base that move a light, rigid, parallelogram arm.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 24], [25, 34], [35, 42], [43, 45], [46, 49], [50, 54], [55, 59], [60, 64], [65, 66], [67, 72], [72, 73], [74, 79], [79, 80], [81, 94], [95, 98], [98, 99]]}
{"doc_key": "ai-test-415", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formatted", "as", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formatted as a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 33], [34, 36], [37, 38], [39, 40], [41, 42], [43, 44], [45, 56], [57, 62], [63, 65], [66, 75], [76, 82], [83, 85], [86, 93], [93, 94]]}
{"doc_key": "ai-test-416", "ner": [[4, 5, "field"], [31, 32, "task"], [38, 39, "task"], [44, 46, "task"], [48, 50, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[31, 32, 4, 5, "part-of", "task_part_of_field", false, false], [38, 39, 4, 5, "part-of", "task_part_of_field", false, false], [44, 46, 4, 5, "part-of", "task_part_of_field", false, false], [48, 50, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "actual", "task", "of", "data", "mining", "is", "the", "semi-automated", "or", "automated", "analysis", "of", "large", "amounts", "of", "data", "to", "extract", "unknown", ",", "interesting", "patterns", ",", "such", "as", "groups", "of", "data", "records", "(", "cluster", "analysis", ")", ",", "unusual", "records", "(", "anomaly", "detection", ")", "and", "dependencies", "(", "association", "rule", "mining", ",", "sequential", "pattern", "mining", ")", "."], "sentence-detokenized": "The actual task of data mining is the semi-automated or automated analysis of large amounts of data to extract unknown, interesting patterns, such as groups of data records (cluster analysis), unusual records (anomaly detection) and dependencies (association rule mining, sequential pattern mining).", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 18], [19, 23], [24, 30], [31, 33], [34, 37], [38, 52], [53, 55], [56, 65], [66, 74], [75, 77], [78, 83], [84, 91], [92, 94], [95, 99], [100, 102], [103, 110], [111, 118], [118, 119], [120, 131], [132, 140], [140, 141], [142, 146], [147, 149], [150, 156], [157, 159], [160, 164], [165, 172], [173, 174], [174, 181], [182, 190], [190, 191], [191, 192], [193, 200], [201, 208], [209, 210], [210, 217], [218, 227], [227, 228], [229, 232], [233, 245], [246, 247], [247, 258], [259, 263], [264, 270], [270, 271], [272, 282], [283, 290], [291, 297], [297, 298], [298, 299]]}
{"doc_key": "ai-test-417", "ner": [[11, 12, "product"], [0, 6, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 0, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Emotion", "analysis", "has", "proven", "to", "be", "a", "valuable", "technique", "for", "the", "recommender", "system", "."], "sentence-detokenized": "Emotion analysis has proven to be a valuable technique for the recommender system.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 27], [28, 30], [31, 33], [34, 35], [36, 44], [45, 54], [55, 58], [59, 62], [63, 74], [75, 81], [81, 82]]}
{"doc_key": "ai-test-418", "ner": [[0, 4, "misc"], [12, 15, "product"], [34, 37, "organisation"], [38, 39, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 12, 15, "usage", "", false, false], [34, 37, 38, 39, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Germans", "accidentally", "made", "a", "very", "poor", "choice", "of", "frequency", "for", "the", "Wotan", "system", ";", "it", "was", "operating", "at", "45", "MHz", ",", "which", "happened", "to", "be", "the", "frequency", "of", "the", "powerful", "but", "still", "inoperative", "BBC", "television", "transmitter", "at", "Alexandra", "Palace", "."], "sentence-detokenized": "The Germans accidentally made a very poor choice of frequency for the Wotan system; it was operating at 45 MHz, which happened to be the frequency of the powerful but still inoperative BBC television transmitter at Alexandra Palace.", "token2charspan": [[0, 3], [4, 11], [12, 24], [25, 29], [30, 31], [32, 36], [37, 41], [42, 48], [49, 51], [52, 61], [62, 65], [66, 69], [70, 75], [76, 82], [82, 83], [84, 86], [87, 90], [91, 100], [101, 103], [104, 106], [107, 110], [110, 111], [112, 117], [118, 126], [127, 129], [130, 132], [133, 136], [137, 146], [147, 149], [150, 153], [154, 162], [163, 166], [167, 172], [173, 184], [185, 188], [189, 199], [200, 211], [212, 214], [215, 224], [225, 231], [231, 232]]}
{"doc_key": "ai-test-419", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formatted", "as", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formatted as a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 33], [34, 36], [37, 38], [39, 40], [41, 42], [43, 44], [45, 56], [57, 62], [63, 65], [66, 75], [76, 82], [83, 85], [86, 93], [93, 94]]}
{"doc_key": "ai-test-420", "ner": [[1, 3, "misc"], [7, 7, "misc"], [11, 11, "product"], [13, 13, "product"], [15, 21, "product"], [25, 27, "misc"], [35, 37, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 11, 7, 7, "usage", "", false, false], [13, 13, 7, 7, "usage", "", false, false], [15, 21, 13, 13, "named", "", false, false], [25, 27, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "Semantic", "Web", "applications", "and", "relatively", "popular", "RDF", "applications", "such", "as", "RSS", "and", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "feeds", "are", "usually", "represented", "by", "URIs", ",", "which", "deliberately", "indicate", "the", "actual", "data", "on", "the", "World", "Wide", "Web", "and", "can", "be", "used", "to", "access", "it", "."], "sentence-detokenized": "In Semantic Web applications and relatively popular RDF applications such as RSS and FOAF (Friend a Friend), feeds are usually represented by URIs, which deliberately indicate the actual data on the World Wide Web and can be used to access it.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 28], [29, 32], [33, 43], [44, 51], [52, 55], [56, 68], [69, 73], [74, 76], [77, 80], [81, 84], [85, 89], [90, 91], [91, 97], [98, 99], [100, 106], [106, 107], [107, 108], [109, 114], [115, 118], [119, 126], [127, 138], [139, 141], [142, 146], [146, 147], [148, 153], [154, 166], [167, 175], [176, 179], [180, 186], [187, 191], [192, 194], [195, 198], [199, 204], [205, 209], [210, 213], [214, 217], [218, 221], [222, 224], [225, 229], [230, 232], [233, 239], [240, 242], [242, 243]]}
{"doc_key": "ai-test-421", "ner": [[0, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "has", "studied", "this", "topic", "extensively"], "sentence-detokenized": "The Association for the Advancement of Artificial Intelligence has studied this topic extensively", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 74], [75, 79], [80, 85], [86, 97]]}
{"doc_key": "ai-test-422", "ner": [[4, 11, "product"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 21, 4, 11, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "curiosity", ",", "the", "speech", "system", "on", "the", "Apple", "Macintosh", "computer", "was", "initially", "developed", "into", "a", "fully", "supported", "PlainTalk", "programme", "for", "people", "with", "vision", "problems", "."], "sentence-detokenized": "As a curiosity, the speech system on the Apple Macintosh computer was initially developed into a fully supported PlainTalk programme for people with vision problems.", "token2charspan": [[0, 2], [3, 4], [5, 14], [14, 15], [16, 19], [20, 26], [27, 33], [34, 36], [37, 40], [41, 46], [47, 56], [57, 65], [66, 69], [70, 79], [80, 89], [90, 94], [95, 96], [97, 102], [103, 112], [113, 122], [123, 132], [133, 136], [137, 143], [144, 148], [149, 155], [156, 164], [164, 165]]}
{"doc_key": "ai-test-423", "ner": [[5, 5, "field"], [7, 8, "task"], [10, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 5, 5, "part-of", "task_part_of_field", false, false], [10, 11, 5, 5, "part-of", "task_part_of_field", false, false], [13, 14, 5, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "applications", "of", "ontologies", "in", "NLP", "include", "information", "retrieval", ",", "information", "extraction", "and", "automatic", "summarisation", "."], "sentence-detokenized": "Other applications of ontologies in NLP include information retrieval, information extraction and automatic summarisation.", "token2charspan": [[0, 5], [6, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 47], [48, 59], [60, 69], [69, 70], [71, 82], [83, 93], [94, 97], [98, 107], [108, 121], [121, 122]]}
{"doc_key": "ai-test-424", "ner": [[7, 15, "organisation"], [18, 22, "organisation"], [25, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Institute", "has", "worked", "closely", "with", "the", "Janelia", "Farm", "Campus", "of", "the", "Howard", "Hughes", "Medical", "Institute", ",", "the", "Allen", "Institute", "for", "Brain", "Science", "and", "the", "National", "Institutes", "of", "Health", "to", "develop", "better", "methods", "for", "reconstructing", "neural", "architectures", "."], "sentence-detokenized": "The Institute has worked closely with the Janelia Farm Campus of the Howard Hughes Medical Institute, the Allen Institute for Brain Science and the National Institutes of Health to develop better methods for reconstructing neural architectures.", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 24], [25, 32], [33, 37], [38, 41], [42, 49], [50, 54], [55, 61], [62, 64], [65, 68], [69, 75], [76, 82], [83, 90], [91, 100], [100, 101], [102, 105], [106, 111], [112, 121], [122, 125], [126, 131], [132, 139], [140, 143], [144, 147], [148, 156], [157, 167], [168, 170], [171, 177], [178, 180], [181, 188], [189, 195], [196, 203], [204, 207], [208, 222], [223, 229], [230, 243], [243, 244]]}
{"doc_key": "ai-test-425", "ner": [[2, 2, "organisation"], [5, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 2, 2, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Recently", ",", "Google", "announced", "that", "Google", "Translate", "translates", "about", "enough", "text", "to", "fill", "1", "million", "books", "in", "a", "day", "(", "2012", ")", "."], "sentence-detokenized": "Recently, Google announced that Google Translate translates about enough text to fill 1 million books in a day (2012).", "token2charspan": [[0, 8], [8, 9], [10, 16], [17, 26], [27, 31], [32, 38], [39, 48], [49, 59], [60, 65], [66, 72], [73, 77], [78, 80], [81, 85], [86, 87], [88, 95], [96, 101], [102, 104], [105, 106], [107, 110], [111, 112], [112, 116], [116, 117], [117, 118]]}
{"doc_key": "ai-test-426", "ner": [[16, 17, "country"], [20, 21, "country"], [23, 23, "country"], [25, 25, "country"], [27, 27, "country"], [29, 33, "country"], [42, 43, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "event", "s", "take", "place", "all", "over", "the", "world", ",", "but", "are", "most", "popular", "in", "the", "United", "Kingdom", ",", "the", "United", "States", ",", "Japan", ",", "Singapore", ",", "India", "and", "South", "Korea", ",", "and", "are", "becoming", "increasingly", "popular", "in", "sub-continental", "countries", "such", "as", "Sri", "Lanka", "."], "sentence-detokenized": "The events take place all over the world, but are most popular in the United Kingdom, the United States, Japan, Singapore, India and South Korea, and are becoming increasingly popular in sub-continental countries such as Sri Lanka.", "token2charspan": [[0, 3], [4, 9], [9, 10], [11, 15], [16, 21], [22, 25], [26, 30], [31, 34], [35, 40], [40, 41], [42, 45], [46, 49], [50, 54], [55, 62], [63, 65], [66, 69], [70, 76], [77, 84], [84, 85], [86, 89], [90, 96], [97, 103], [103, 104], [105, 110], [110, 111], [112, 121], [121, 122], [123, 128], [129, 132], [133, 138], [139, 144], [144, 145], [146, 149], [150, 153], [154, 162], [163, 175], [176, 183], [184, 186], [187, 202], [203, 212], [213, 217], [218, 220], [221, 224], [225, 230], [230, 231]]}
{"doc_key": "ai-test-427", "ner": [[6, 8, "programlang"], [12, 12, "programlang"], [14, 14, "programlang"], [16, 17, "programlang"], [19, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "mostly", "developed", "in", "R", ",", "but", "sometimes", "also", "in", "Java", ",", "C", ",", "C", "++", "and", "Fortran", "."], "sentence-detokenized": "These packages are mostly developed in R, but sometimes also in Java, C, C++ and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 25], [26, 35], [36, 38], [39, 40], [40, 41], [42, 45], [46, 55], [56, 60], [61, 63], [64, 68], [68, 69], [70, 71], [71, 72], [73, 74], [74, 76], [77, 80], [81, 88], [88, 89]]}
{"doc_key": "ai-test-428", "ner": [[2, 10, "conference"], [8, 8, "conference"], [12, 12, "researcher"], [14, 14, "researcher"], [18, 19, "researcher"], [22, 25, "algorithm"], [28, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[8, 8, 2, 10, "named", "", false, false], [12, 12, 2, 10, "physical", "", false, false], [12, 12, 2, 10, "role", "", false, false], [12, 12, 18, 19, "role", "teams_up_with", false, false], [12, 12, 22, 25, "usage", "", false, false], [14, 14, 2, 10, "physical", "", false, false], [14, 14, 2, 10, "role", "", false, false], [14, 14, 18, 19, "role", "teams_up_with", false, false], [14, 14, 22, 25, "usage", "", false, false], [18, 19, 2, 10, "physical", "", false, false], [18, 19, 2, 10, "role", "", false, false], [18, 19, 22, 25, "usage", "", false, false], [22, 25, 28, 33, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["In", "the", "European", "Conference", "on", "Computer", "Vision", "(", "ECCV", ")", "2006", ",", "Dalal", "and", "Triggs", ",", "together", "with", "Cordelia", "Schmid", ",", "applied", "HOG", "detectors", "to", "the", "problem", "of", "detecting", "people", "in", "movies", "and", "videos", "."], "sentence-detokenized": "In the European Conference on Computer Vision (ECCV) 2006, Dalal and Triggs, together with Cordelia Schmid, applied HOG detectors to the problem of detecting people in movies and videos.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 26], [27, 29], [30, 38], [39, 45], [46, 47], [47, 51], [51, 52], [53, 57], [57, 58], [59, 64], [65, 68], [69, 75], [75, 76], [77, 85], [86, 90], [91, 99], [100, 106], [106, 107], [108, 115], [116, 119], [120, 129], [130, 132], [133, 136], [137, 144], [145, 147], [148, 157], [158, 164], [165, 167], [168, 174], [175, 178], [179, 185], [185, 186]]}
{"doc_key": "ai-test-429", "ner": [[3, 3, "metrics"], [5, 7, "metrics"], [10, 12, "task"], [19, 21, "metrics"], [23, 26, "metrics"], [29, 29, "metrics"], [32, 34, "metrics"], [36, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 3, 10, 12, "related-to", "measured_with", false, false], [5, 7, 10, 12, "related-to", "measured_with", false, false], [19, 21, 10, 12, "related-to", "measured_with", false, false], [23, 26, 19, 21, "named", "", false, false], [29, 29, 19, 21, "named", "", false, false], [36, 36, 32, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "addition", "to", "sensitivity", "and", "specificity", ",", "the", "performance", "of", "a", "binary", "classifier", "can", "also", "be", "measured", "by", "its", "positive", "predictive", "value", "(", "PPV", ")", ",", "also", "known", "as", "accuracy", ",", "and", "negative", "predictive", "value", "(", "NPV", ")", "."], "sentence-detokenized": "In addition to sensitivity and specificity, the performance of a binary classifier can also be measured by its positive predictive value (PPV), also known as accuracy, and negative predictive value (NPV).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 42], [42, 43], [44, 47], [48, 59], [60, 62], [63, 64], [65, 71], [72, 82], [83, 86], [87, 91], [92, 94], [95, 103], [104, 106], [107, 110], [111, 119], [120, 130], [131, 136], [137, 138], [138, 141], [141, 142], [142, 143], [144, 148], [149, 154], [155, 157], [158, 166], [166, 167], [168, 171], [172, 180], [181, 191], [192, 197], [198, 199], [199, 202], [202, 203], [203, 204]]}
{"doc_key": "ai-test-430", "ner": [[14, 15, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "models", "can", "partially", "account", "for", "overlapping", "matches", "(", "for", "example", ",", "using", "the", "Jaccard", "index", ")", "."], "sentence-detokenized": "Such models can partially account for overlapping matches (for example, using the Jaccard index).", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 25], [26, 33], [34, 37], [38, 49], [50, 57], [58, 59], [59, 62], [63, 70], [70, 71], [72, 77], [78, 81], [82, 89], [90, 95], [95, 96], [96, 97]]}
{"doc_key": "ai-test-431", "ner": [[24, 29, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", ",", "in", "the", "case", "of", "single", "-", "sample", "estimation", ",", "it", "illustrates", "the", "philosophical", "issues", "and", "potential", "misunderstandings", "in", "the", "use", "of", "maximum", "likelihood", "estimators", "and", "likelihood", "functions", "."], "sentence-detokenized": "In addition, in the case of single-sample estimation, it illustrates the philosophical issues and potential misunderstandings in the use of maximum likelihood estimators and likelihood functions.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 34], [34, 35], [35, 41], [42, 52], [52, 53], [54, 56], [57, 68], [69, 72], [73, 86], [87, 93], [94, 97], [98, 107], [108, 125], [126, 128], [129, 132], [133, 136], [137, 139], [140, 147], [148, 158], [159, 169], [170, 173], [174, 184], [185, 194], [194, 195]]}
